{"id": "2506.05437", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.05437", "abs": "https://arxiv.org/abs/2506.05437", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "title": "A MARL-based Approach for Easing MAS Organization Engineering", "comment": null, "summary": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "AI": {"tldr": "论文提出了一种名为AOMEA的方法，通过结合多智能体强化学习和组织模型，辅助设计多智能体系统的组织结构，以解决复杂部署环境中的高成本和安全性问题。", "motivation": "多智能体系统（MAS）在复杂分布式问题中表现优异，但其设计效率高度依赖部署环境的知识。复杂和低可读性的环境导致现有方法成本高或存在安全隐患。", "method": "提出AOMEA方法，结合多智能体强化学习（MARL）和组织模型，生成相关组织规范以辅助MAS设计。", "result": "AOMEA能够为MAS工程提供有效的组织规范建议，降低设计复杂性和成本。", "conclusion": "AOMEA是一种创新的方法，能够有效解决MAS设计中的复杂性和安全性问题。"}}
{"id": "2506.05527", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.05527", "abs": "https://arxiv.org/abs/2506.05527", "authors": ["Caroline Wang", "Di Yang Shi", "Elad Liebman", "Ishan Durugkar", "Arrasy Rahman", "Peter Stone"], "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "comment": null, "summary": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "AI": {"tldr": "论文提出了一种基于Transformer的集中式方法MAT-NAHT，用于解决N-agent ad hoc teamwork问题，优于现有独立学习方法POAM。", "motivation": "现有独立学习方法POAM无法充分捕捉多智能体间的动态协作关系，而Transformer在处理变长序列和多任务学习中的有效性为改进提供了思路。", "method": "采用集中式Transformer架构，整合所有受控智能体的历史观察和动作，以应对部分可观测环境中的未知队友。", "result": "在StarCraft II任务中，MAT-NAHT表现出更高的样本效率和泛化能力，优于POAM。", "conclusion": "MAT-NAHT通过Transformer的序列建模能力，有效解决了多智能体动态协作问题，无需额外建模目标。"}}
{"id": "2506.05555", "categories": ["cs.MA", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.05555", "abs": "https://arxiv.org/abs/2506.05555", "authors": ["Oliver Slumbers", "Joel Z. Leibo", "Marco A. Janssen"], "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "comment": null, "summary": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "AI": {"tldr": "论文探讨了生成式AI（如LLM）是否能够替代人类参与者，用于大规模集体风险社会困境（CRSD）实验，以解决传统方法在多样性和规模上的限制。", "motivation": "传统CRSD研究方法需要大规模人类实验，但难以保证足够的统计功效和社会人口多样性。生成式AI可能提供一种补充方案。", "method": "通过使用大型语言模型（LLM）替代人类参与者，构建可扩展的实证框架，验证其在大规模CRSD实验中的可行性和多样性表现。", "result": "论文聚焦于LLM在复杂CRSD（如Port of Mars）中的有效性，以验证其是否能模拟人类实验的多样性和规模。", "conclusion": "生成式AI有望成为CRSD研究的有力补充工具，但需进一步验证其在大规模复杂场景中的表现。"}}
{"id": "2506.06032", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.06032", "abs": "https://arxiv.org/abs/2506.06032", "authors": ["Edward Hughes", "Tina O. Zhu", "Martin J. Chadwick", "Raphael Koster", "Antonio García Castañeda", "Charles Beattie", "Thore Graepel", "Matthew M. Botvinick", "Joel Z. Leibo"], "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game", "comment": "45 pages, 29 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.04982", "summary": "Multi-agent reinforcement learning algorithms are useful for simulating\nsocial behavior in settings that are too complex for other theoretical\napproaches like game theory. However, they have not yet been empirically\nsupported by laboratory experiments with real human participants. In this work\nwe demonstrate how multi-agent reinforcement learning can model group behavior\nin a spatially and temporally complex public good provision game called Clean\nUp. We show that human groups succeed in Clean Up when they can see who is who\nand track reputations over time but fail under conditions of anonymity. A new\nmulti-agent reinforcement learning model of reputation-based cooperation\ndemonstrates the same difference between identifiable and anonymous conditions.\nFurthermore, both human groups and artificial agent groups solve the problem\nvia turn-taking despite other options being available. Our results highlight\nthe benefits of using multi-agent reinforcement learning to model human social\nbehavior in complex environments.", "AI": {"tldr": "多智能体强化学习可用于模拟复杂社会行为，但缺乏实验支持。本文通过实验验证其在公共物品博弈中的有效性，发现人类和AI在可识别身份时表现更好。", "motivation": "验证多智能体强化学习在复杂社会行为建模中的实用性，并通过实验填补理论与现实的差距。", "method": "在公共物品博弈（Clean Up）中，对比人类和AI在可识别身份与匿名条件下的表现，并开发新的声誉合作模型。", "result": "人类和AI在可识别身份时表现更优，且均通过轮流合作解决问题。", "conclusion": "多智能体强化学习能有效模拟复杂社会行为，尤其在身份识别和声誉管理方面。"}}
{"id": "2506.05437", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.05437", "abs": "https://arxiv.org/abs/2506.05437", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "title": "A MARL-based Approach for Easing MAS Organization Engineering", "comment": null, "summary": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "AI": {"tldr": "论文提出了一种辅助多智能体系统组织工程方法（AOMEA），结合多智能体强化学习和组织模型，以简化复杂环境下的MAS设计。", "motivation": "复杂和低可读性的部署环境导致传统方法成本高或存在安全隐患，需要一种更高效的方法来设计MAS组织。", "method": "AOMEA结合多智能体强化学习（MARL）和组织模型，生成相关的组织规范。", "result": "AOMEA能够为MAS工程提供有效的组织建议。", "conclusion": "AOMEA是一种有前景的方法，可简化复杂环境下的MAS组织设计。"}}
{"id": "2506.05527", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.05527", "abs": "https://arxiv.org/abs/2506.05527", "authors": ["Caroline Wang", "Di Yang Shi", "Elad Liebman", "Ishan Durugkar", "Arrasy Rahman", "Peter Stone"], "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "comment": null, "summary": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "AI": {"tldr": "本文提出了一种基于Transformer的集中式方法（MAT-NAHT），用于解决N-agent ad hoc teamwork（NAHT）问题，优于现有独立学习方法（POAM）。", "motivation": "现有独立学习方法（POAM）无法充分捕捉多智能体间的动态协作关系，而Transformer在处理变长序列方面表现出色，因此尝试将其应用于NAHT问题。", "method": "提出了一种集中式的Transformer方法（MAT-NAHT），利用所有受控智能体的历史观察和动作，以应对部分可观测环境中多样且未知的队友。", "result": "在StarCraft II任务上的实验表明，MAT-NAHT在样本效率和泛化能力上优于POAM，且无需额外的智能体建模目标。", "conclusion": "MAT-NAHT通过集中式Transformer方法有效解决了NAHT问题，展现了其在多智能体协作中的潜力。"}}
{"id": "2506.05555", "categories": ["cs.MA", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.05555", "abs": "https://arxiv.org/abs/2506.05555", "authors": ["Oliver Slumbers", "Joel Z. Leibo", "Marco A. Janssen"], "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "comment": null, "summary": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "AI": {"tldr": "论文探讨了生成式AI（如LLM）在集体风险社会困境（CRSD）研究中的可行性，以替代大规模人类实验。", "motivation": "解决CRSD研究中大规模人类实验的挑战，如统计功效和社会人口异质性不足的问题。", "method": "使用大型语言模型（LLM）模拟人类行为，验证其在复杂CRSD（如Port of Mars）中的代表性。", "result": "初步验证了LLM在模拟人类行为和多样性方面的潜力。", "conclusion": "生成式AI可作为CRSD研究的补充工具，但需进一步验证其有效性。"}}
{"id": "2506.06032", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.06032", "abs": "https://arxiv.org/abs/2506.06032", "authors": ["Edward Hughes", "Tina O. Zhu", "Martin J. Chadwick", "Raphael Koster", "Antonio García Castañeda", "Charles Beattie", "Thore Graepel", "Matthew M. Botvinick", "Joel Z. Leibo"], "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game", "comment": "45 pages, 29 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.04982", "summary": "Multi-agent reinforcement learning algorithms are useful for simulating\nsocial behavior in settings that are too complex for other theoretical\napproaches like game theory. However, they have not yet been empirically\nsupported by laboratory experiments with real human participants. In this work\nwe demonstrate how multi-agent reinforcement learning can model group behavior\nin a spatially and temporally complex public good provision game called Clean\nUp. We show that human groups succeed in Clean Up when they can see who is who\nand track reputations over time but fail under conditions of anonymity. A new\nmulti-agent reinforcement learning model of reputation-based cooperation\ndemonstrates the same difference between identifiable and anonymous conditions.\nFurthermore, both human groups and artificial agent groups solve the problem\nvia turn-taking despite other options being available. Our results highlight\nthe benefits of using multi-agent reinforcement learning to model human social\nbehavior in complex environments.", "AI": {"tldr": "多智能体强化学习可模拟复杂社会行为，但缺乏实验支持。本文通过实验验证其在公共物品游戏中的表现，发现声誉和身份可见性对合作至关重要。", "motivation": "验证多智能体强化学习在真实人类实验中的适用性，探索复杂环境下的社会行为建模。", "method": "在公共物品游戏Clean Up中对比人类和AI代理的表现，分析声誉和匿名条件的影响。", "result": "人类和AI在身份可见时成功合作，匿名时失败；均通过轮换解决问题。", "conclusion": "多智能体强化学习能有效模拟复杂社会行为，声誉机制是关键。"}}
{"id": "2506.05437", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.05437", "abs": "https://arxiv.org/abs/2506.05437", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "title": "A MARL-based Approach for Easing MAS Organization Engineering", "comment": null, "summary": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "AI": {"tldr": "论文提出了一种辅助多智能体系统组织工程方法（AOMEA），结合多智能体强化学习和组织模型，以简化复杂部署环境中的MAS设计。", "motivation": "当前MAS设计方法依赖设计师对部署环境的了解，但在复杂或低可读性环境中成本高且存在安全隐患，需更高效的方法。", "method": "AOMEA结合多智能体强化学习（MARL）和组织模型，生成相关组织规范以辅助MAS工程。", "result": "AOMEA能够为MAS设计提供有效的组织建议，降低复杂环境中的设计成本和风险。", "conclusion": "AOMEA为复杂环境中的MAS组织设计提供了一种高效且安全的解决方案。"}}
{"id": "2506.05527", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.05527", "abs": "https://arxiv.org/abs/2506.05527", "authors": ["Caroline Wang", "Di Yang Shi", "Elad Liebman", "Ishan Durugkar", "Arrasy Rahman", "Peter Stone"], "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "comment": null, "summary": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "AI": {"tldr": "论文提出了一种基于Transformer的中心化方法MAT-NAHT，用于解决多智能体强化学习中的N-agent ad hoc teamwork问题，优于现有独立学习方法POAM。", "motivation": "现有独立学习方法POAM无法充分捕捉智能体间的动态交互，而Transformer能有效处理变长序列，适合解决NAHT问题。", "method": "采用中心化的Transformer架构，整合所有受控智能体的历史观察和动作，以应对部分可观测环境中未知队友的多样性。", "result": "在StarCraft II任务中，MAT-NAHT表现优于POAM，具有更高的样本效率和泛化能力。", "conclusion": "MAT-NAHT通过Transformer有效解决了NAHT问题，无需额外建模目标即可实现高效协作。"}}
{"id": "2506.05555", "categories": ["cs.MA", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.05555", "abs": "https://arxiv.org/abs/2506.05555", "authors": ["Oliver Slumbers", "Joel Z. Leibo", "Marco A. Janssen"], "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "comment": null, "summary": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "AI": {"tldr": "本文探讨了使用生成式AI（如大型语言模型LLM）替代人类参与者进行集体风险社会困境（CRSD）研究的可行性，重点关注其在大规模、多样化实验中的有效性。", "motivation": "传统CRSD研究方法需要大规模人类实验，但难以保证统计功效和社会人口因素的多样性。生成式AI提供了一种补充方案。", "method": "利用大型语言模型（LLM）模拟人类参与者，构建可扩展的实证框架，验证其在复杂CRSD（如Port of Mars）中的适用性。", "result": "研究发现LLM可以作为一种有效工具，模拟大规模、多样化的人类实验，为CRSD研究提供新途径。", "conclusion": "生成式AI在CRSD研究中具有潜力，可作为人类实验的补充，但仍需进一步验证其多样性和真实性。"}}
{"id": "2506.06032", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.06032", "abs": "https://arxiv.org/abs/2506.06032", "authors": ["Edward Hughes", "Tina O. Zhu", "Martin J. Chadwick", "Raphael Koster", "Antonio García Castañeda", "Charles Beattie", "Thore Graepel", "Matthew M. Botvinick", "Joel Z. Leibo"], "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game", "comment": "45 pages, 29 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.04982", "summary": "Multi-agent reinforcement learning algorithms are useful for simulating\nsocial behavior in settings that are too complex for other theoretical\napproaches like game theory. However, they have not yet been empirically\nsupported by laboratory experiments with real human participants. In this work\nwe demonstrate how multi-agent reinforcement learning can model group behavior\nin a spatially and temporally complex public good provision game called Clean\nUp. We show that human groups succeed in Clean Up when they can see who is who\nand track reputations over time but fail under conditions of anonymity. A new\nmulti-agent reinforcement learning model of reputation-based cooperation\ndemonstrates the same difference between identifiable and anonymous conditions.\nFurthermore, both human groups and artificial agent groups solve the problem\nvia turn-taking despite other options being available. Our results highlight\nthe benefits of using multi-agent reinforcement learning to model human social\nbehavior in complex environments.", "AI": {"tldr": "多智能体强化学习能模拟复杂社会行为，但缺乏实验支持。本文通过实验证明其在公共物品游戏中的有效性，尤其是声誉机制的作用。", "motivation": "验证多智能体强化学习在模拟真实人类群体行为中的有效性，尤其是在复杂时空环境下的合作行为。", "method": "使用公共物品游戏Clean Up，对比人类和AI在可识别与匿名条件下的表现，提出基于声誉的合作模型。", "result": "人类和AI在可识别条件下成功合作，匿名条件下失败；双方均通过轮换解决问题。", "conclusion": "多智能体强化学习是模拟复杂环境中人类社会行为的有效工具。"}}
{"id": "2506.05437", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.05437", "abs": "https://arxiv.org/abs/2506.05437", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "title": "A MARL-based Approach for Easing MAS Organization Engineering", "comment": null, "summary": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "AI": {"tldr": "提出了一种辅助多智能体系统组织工程方法（AOMEA），结合多智能体强化学习和组织模型，以简化复杂环境中的MAS设计。", "motivation": "复杂部署环境中的高复杂性和低可读性导致现有方法成本高或存在安全隐患，需要一种更高效的设计方法。", "method": "结合多智能体强化学习（MARL）和组织模型，生成相关组织规范以辅助MAS工程。", "result": "AOMEA能够为MAS工程提供有效的组织规范建议。", "conclusion": "AOMEA为复杂环境中的MAS设计提供了一种更高效且安全的解决方案。"}}
{"id": "2506.05527", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.05527", "abs": "https://arxiv.org/abs/2506.05527", "authors": ["Caroline Wang", "Di Yang Shi", "Elad Liebman", "Ishan Durugkar", "Arrasy Rahman", "Peter Stone"], "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "comment": null, "summary": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "AI": {"tldr": "论文提出了一种基于Transformer的集中式方法MAT-NAHT，用于解决N-agent ad hoc teamwork（NAHT）问题，优于现有独立学习方法POAM。", "motivation": "现有方法POAM仅采用独立学习，无法充分捕捉多智能体协作中的动态交互，而Transformer能有效处理变长序列，适用于NAHT问题。", "method": "提出集中式Transformer方法MAT-NAHT，整合所有受控智能体的历史观察和动作，以应对部分可观测环境中多样且未知的队友。", "result": "在StarCraft II任务中，MAT-NAHT表现优于POAM，具有更高的样本效率和泛化能力，且无需额外建模目标。", "conclusion": "MAT-NAHT通过Transformer有效解决了NAHT问题，展示了集中式方法在多智能体协作中的潜力。"}}
{"id": "2506.05555", "categories": ["cs.MA", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.05555", "abs": "https://arxiv.org/abs/2506.05555", "authors": ["Oliver Slumbers", "Joel Z. Leibo", "Marco A. Janssen"], "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "comment": null, "summary": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "AI": {"tldr": "本文探讨了使用生成式AI（如大型语言模型LLM）替代人类参与者进行集体风险社会困境（CRSD）研究的可行性，重点关注其多样性和有效性。", "motivation": "解决CRSD研究中大规模人类实验的困难，如样本多样性和统计功效问题。", "method": "利用大型语言模型（LLM）模拟人类行为，验证其在复杂CRSD（如Port of Mars）中的表现。", "result": "初步验证了LLM在模拟大规模人类实验中的潜力，尤其是在多样性和复杂性方面。", "conclusion": "生成式AI可作为CRSD研究的补充工具，但仍需进一步验证其与真实人类行为的一致性。"}}
{"id": "2506.06032", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.06032", "abs": "https://arxiv.org/abs/2506.06032", "authors": ["Edward Hughes", "Tina O. Zhu", "Martin J. Chadwick", "Raphael Koster", "Antonio García Castañeda", "Charles Beattie", "Thore Graepel", "Matthew M. Botvinick", "Joel Z. Leibo"], "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game", "comment": "45 pages, 29 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.04982", "summary": "Multi-agent reinforcement learning algorithms are useful for simulating\nsocial behavior in settings that are too complex for other theoretical\napproaches like game theory. However, they have not yet been empirically\nsupported by laboratory experiments with real human participants. In this work\nwe demonstrate how multi-agent reinforcement learning can model group behavior\nin a spatially and temporally complex public good provision game called Clean\nUp. We show that human groups succeed in Clean Up when they can see who is who\nand track reputations over time but fail under conditions of anonymity. A new\nmulti-agent reinforcement learning model of reputation-based cooperation\ndemonstrates the same difference between identifiable and anonymous conditions.\nFurthermore, both human groups and artificial agent groups solve the problem\nvia turn-taking despite other options being available. Our results highlight\nthe benefits of using multi-agent reinforcement learning to model human social\nbehavior in complex environments.", "AI": {"tldr": "多智能体强化学习能模拟复杂环境中的社会行为，但缺乏实验支持。本文通过实验证明其在公共物品提供游戏中的有效性，并展示声誉机制的重要性。", "motivation": "验证多智能体强化学习在模拟人类群体行为中的实际效果，尤其是在复杂时空环境中的声誉合作机制。", "method": "在公共物品提供游戏“Clean Up”中，对比人类和人工智能体在可识别与匿名条件下的表现，并开发声誉合作模型。", "result": "人类和智能体在可识别条件下成功合作，匿名条件下失败；两者均通过轮换策略解决问题。", "conclusion": "多智能体强化学习能有效模拟复杂环境中的人类社会行为，声誉机制是关键因素。"}}
