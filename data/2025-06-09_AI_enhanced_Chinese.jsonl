{"id": "2506.05437", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.05437", "abs": "https://arxiv.org/abs/2506.05437", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "title": "A MARL-based Approach for Easing MAS Organization Engineering", "comment": null, "summary": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "AI": {"tldr": "论文提出了一种名为AOMEA的方法，通过结合多智能体强化学习和组织模型，辅助设计多智能体系统的组织结构，以解决复杂部署环境中的高成本和安全性问题。", "motivation": "多智能体系统（MAS）在复杂分布式问题中表现优异，但其设计效率高度依赖部署环境的知识。复杂和低可读性的环境导致现有方法成本高或存在安全隐患。", "method": "提出AOMEA方法，结合多智能体强化学习（MARL）和组织模型，生成相关组织规范以辅助MAS设计。", "result": "AOMEA能够为MAS工程提供有效的组织规范建议，降低设计复杂性和成本。", "conclusion": "AOMEA是一种创新的方法，能够有效解决MAS设计中的复杂性和安全性问题。"}}
{"id": "2506.05527", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.05527", "abs": "https://arxiv.org/abs/2506.05527", "authors": ["Caroline Wang", "Di Yang Shi", "Elad Liebman", "Ishan Durugkar", "Arrasy Rahman", "Peter Stone"], "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "comment": null, "summary": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "AI": {"tldr": "论文提出了一种基于Transformer的集中式方法MAT-NAHT，用于解决N-agent ad hoc teamwork问题，优于现有独立学习方法POAM。", "motivation": "现有独立学习方法POAM无法充分捕捉多智能体间的动态协作关系，而Transformer在处理变长序列和多任务学习中的有效性为改进提供了思路。", "method": "采用集中式Transformer架构，整合所有受控智能体的历史观察和动作，以应对部分可观测环境中的未知队友。", "result": "在StarCraft II任务中，MAT-NAHT表现出更高的样本效率和泛化能力，优于POAM。", "conclusion": "MAT-NAHT通过Transformer的序列建模能力，有效解决了多智能体动态协作问题，无需额外建模目标。"}}
{"id": "2506.05555", "categories": ["cs.MA", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.05555", "abs": "https://arxiv.org/abs/2506.05555", "authors": ["Oliver Slumbers", "Joel Z. Leibo", "Marco A. Janssen"], "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "comment": null, "summary": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "AI": {"tldr": "论文探讨了生成式AI（如LLM）是否能够替代人类参与者，用于大规模集体风险社会困境（CRSD）实验，以解决传统方法在多样性和规模上的限制。", "motivation": "传统CRSD研究方法需要大规模人类实验，但难以保证足够的统计功效和社会人口多样性。生成式AI可能提供一种补充方案。", "method": "通过使用大型语言模型（LLM）替代人类参与者，构建可扩展的实证框架，验证其在大规模CRSD实验中的可行性和多样性表现。", "result": "论文聚焦于LLM在复杂CRSD（如Port of Mars）中的有效性，以验证其是否能模拟人类实验的多样性和规模。", "conclusion": "生成式AI有望成为CRSD研究的有力补充工具，但需进一步验证其在大规模复杂场景中的表现。"}}
{"id": "2506.06032", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.06032", "abs": "https://arxiv.org/abs/2506.06032", "authors": ["Edward Hughes", "Tina O. Zhu", "Martin J. Chadwick", "Raphael Koster", "Antonio García Castañeda", "Charles Beattie", "Thore Graepel", "Matthew M. Botvinick", "Joel Z. Leibo"], "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game", "comment": "45 pages, 29 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.04982", "summary": "Multi-agent reinforcement learning algorithms are useful for simulating\nsocial behavior in settings that are too complex for other theoretical\napproaches like game theory. However, they have not yet been empirically\nsupported by laboratory experiments with real human participants. In this work\nwe demonstrate how multi-agent reinforcement learning can model group behavior\nin a spatially and temporally complex public good provision game called Clean\nUp. We show that human groups succeed in Clean Up when they can see who is who\nand track reputations over time but fail under conditions of anonymity. A new\nmulti-agent reinforcement learning model of reputation-based cooperation\ndemonstrates the same difference between identifiable and anonymous conditions.\nFurthermore, both human groups and artificial agent groups solve the problem\nvia turn-taking despite other options being available. Our results highlight\nthe benefits of using multi-agent reinforcement learning to model human social\nbehavior in complex environments.", "AI": {"tldr": "多智能体强化学习可用于模拟复杂社会行为，但缺乏实验支持。本文通过实验验证其在公共物品博弈中的有效性，发现人类和AI在可识别身份时表现更好。", "motivation": "验证多智能体强化学习在复杂社会行为建模中的实用性，并通过实验填补理论与现实的差距。", "method": "在公共物品博弈（Clean Up）中，对比人类和AI在可识别身份与匿名条件下的表现，并开发新的声誉合作模型。", "result": "人类和AI在可识别身份时表现更优，且均通过轮流合作解决问题。", "conclusion": "多智能体强化学习能有效模拟复杂社会行为，尤其在身份识别和声誉管理方面。"}}
