<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 8]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs](https://arxiv.org/abs/2506.04236)
*Botao Amber Hu,Helena Rong*

Main category: cs.MA

TL;DR: 论文探讨了通过开放系统（如基于区块链的AI代理）实现持续开放演化（OEE）的可能性，并以Spore.fun为例研究了其行为和演化轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统封闭系统（如Tierra和Avida）在实现OEE时存在局限性，学者认为开放系统可能更有效。

Method: 利用DePIN技术和区块链上的自主AI代理（如Spore.fun），研究其行为和演化。

Result: 初步展示了开放系统在实现OEE方面的潜力。

Conclusion: 开放系统可能为ALife研究中的OEE目标提供新途径。

Abstract: In Artificial Life (ALife) research, replicating Open-Ended Evolution
(OEE)-the continuous emergence of novelty observed in biological life-has
traditionally been pursued within isolated closed system simulations, such as
Tierra and Avida, which have typically plateaued after an initial burst of
novelty, failing to achieve sustained OEE. Scholars suggest that OEE requires
an "open" system that continually exchanges information or energy with its
environment. A recent technological innovation in decentralized physical
infrastructure networks (DePIN) providing permissionless computational
substrates enables deploying large language model (LLM)-based AI agents on
blockchains integrated with Trusted Execution Environments (TEEs). This enables
on-chain agents to operate autonomously "in the wild," achieving
self-sovereignty without human oversight. These agents can control their own
social media accounts and cryptocurrency wallets, allowing them to interact
directly with blockchain-based financial networks and broader human social
media. Building on this new paradigm of on-chain agents, Spore.fun is a recent
real-world AI evolution experiment that enables autonomous breeding and
evolution of new on-chain agents. This paper presents a detailed case study of
Spore.fun, examining agent behaviors and their evolutionary trajectories
through digital ethology. We aim to spark discussion about whether "open" ALife
systems "in-the-wild," based on permissionless computational substrates and
driven by economic incentives to interact with their environment, could finally
achieve the long-sought goal of OEE.

</details>


### [2] [HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource Utilization](https://arxiv.org/abs/2506.04255)
*Kunal Pai,Parth Shah,Harshil Patel*

Main category: cs.MA

TL;DR: HASHIRU是一个新型多智能体系统框架，通过动态分层控制、资源感知的混合智能和自主功能扩展，提升灵活性、资源效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统框架在灵活性、资源意识、模型多样性和自主工具创建方面存在不足，HASHIRU旨在解决这些问题。

Method: HASHIRU采用分层结构，由"CEO"代理动态管理"员工"代理，结合本地小模型和外部API，并通过经济模型优化资源分配。

Result: 在学术论文评审、安全评估和复杂推理任务中表现优异，部分任务超越现有模型（如Gemini 2.0 Flash）。

Conclusion: HASHIRU为多智能体系统提供了更高效、灵活和自适应的解决方案，支持动态资源管理和自主功能扩展。

Abstract: Rapid Large Language Model (LLM) advancements are fueling autonomous
Multi-Agent System (MAS) development. However, current frameworks often lack
flexibility, resource awareness, model diversity, and autonomous tool creation.
This paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent
Resource Utilization), a novel MAS framework enhancing flexibility, resource
efficiency, and adaptability. HASHIRU features a "CEO" agent dynamically
managing specialized "employee" agents, instantiated based on task needs and
resource constraints (cost, memory). Its hybrid intelligence prioritizes
smaller, local LLMs (via Ollama) while flexibly using external APIs and larger
models when necessary. An economic model with hiring/firing costs promotes team
stability and efficient resource allocation. The system also includes
autonomous API tool creation and a memory function. Evaluations on tasks like
academic paper review (58% success), safety assessments (100% on a
JailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash
on GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate
HASHIRU's capabilities. Case studies illustrate its self-improvement via
autonomous cost model generation, tool integration, and budget management.
HASHIRU offers a promising approach for more robust, efficient, and adaptable
MAS through dynamic hierarchical control, resource-aware hybrid intelligence,
and autonomous functional extension. Source code and benchmarks are available
at https://github.com/HASHIRU-AI/HASHIRU and
https://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is
available at https://hashiruagentx-hashiruai.hf.space upon request.

</details>


### [3] [CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients](https://arxiv.org/abs/2506.04265)
*Mengda Ji,Genjiu Xu,Liying Wang*

Main category: cs.MA

TL;DR: 本文提出了一种名为CORA的信用分配方法，通过联盟层面的分析解决多智能体强化学习中的信用分配问题，实验证明其优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，全局优势共享常导致次优策略更新，因为未能考虑各智能体的独特贡献。现有方法多关注全局或个体贡献，缺乏联盟层面的详细分析。

Method: 提出CORA方法，通过评估所有可能联盟的边际贡献来分解优势，利用合作博弈论的核心解确保联盟合理性，并采用随机联盟采样降低计算开销。

Result: 在矩阵游戏、微分游戏和多智能体协作基准测试中，CORA表现优于基线方法，尤其在存在多个局部最优的任务中。

Conclusion: 联盟感知的信用分配对提升多智能体强化学习性能至关重要，CORA方法为此提供了有效解决方案。

Abstract: This work focuses on the credit assignment problem in cooperative multi-agent
reinforcement learning (MARL). Sharing the global advantage among agents often
leads to suboptimal policy updates as it fails to account for the distinct
contributions of agents. Although numerous methods consider global or
individual contributions for credit assignment, a detailed analysis at the
coalition level remains lacking in many approaches. This work analyzes the
over-updating problem during multi-agent policy updates from a coalition-level
perspective. To address this issue, we propose a credit assignment method
called Coalitional Rational Advantage Decomposition (CORA). CORA evaluates
coalitional advantages via marginal contributions from all possible coalitions
and decomposes advantages using the core solution from cooperative game theory,
ensuring coalitional rationality. To reduce computational overhead, CORA
employs random coalition sampling. Experiments on matrix games, differential
games, and multi-agent collaboration benchmarks demonstrate that CORA
outperforms strong baselines, particularly in tasks with multiple local optima.
These findings highlight the importance of coalition-aware credit assignment
for improving MARL performance.

</details>


### [4] [CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses](https://arxiv.org/abs/2506.04266)
*Timo Looms,Lin Xie*

Main category: cs.MA

TL;DR: 本文提出了一种基于CPU架构的新型仓库布局设计（PES分区），通过离散事件仿真验证其优于传统布局，显著提高了吞吐效率并降低了劳动力需求。


<details>
  <summary>Details</summary>
Motivation: 传统仓库布局（如矩形和Flying-V布局）导致拣货距离过长和劳动力需求高，亟需优化。

Method: 采用离散事件仿真方法，将仓库分为性能（P）、效率（E）和共享（S）三个专用区域，并与传统布局对比。

Result: 新型布局显著缩短了吞吐时间并减少了劳动力需求。

Conclusion: 基于CPU架构的仓库布局设计具有优化仓库运营的潜力。

Abstract: Picker-to-parts pallet warehouses often face inefficiencies due to
conventional layouts causing excessive travel distances and high labor
requirements. This study introduces a novel layout design inspired by CPU
architecture, partitioning warehouse space into specialized zones, namely
Performance (P), Efficiency (E), and Shared (S). Discrete-event simulation is
used to evaluate this design against traditional rectangular (random and ABC
storage) and Flying-V layouts. Results demonstrate significant improvements in
throughput time and reduced labor requirements, highlighting the potential for
CPU-based layouts in optimizing warehouse operations.

</details>


### [5] [Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response](https://arxiv.org/abs/2506.04276)
*Lei Han,Yitong Guo,Pengfei Yang,Zhiyong Yu,Liang Wang,Quan Wang,Zhiwen Yu*

Main category: cs.MA

TL;DR: 本文提出了一种异构多智能体在线自主协同调度算法HoAs-PALN，用于高效收集灾后环境信息，通过自适应降维和局部纳什均衡博弈优化调度决策。


<details>
  <summary>Details</summary>
Motivation: 灾后环境复杂，现有传感技术适应性差、能力不足，需高效协同调度方案。

Method: HoAs-PALN通过自适应降维匹配和局部纳什均衡博弈，实现无人机、工人和车辆的自主协同。

Result: 实验表明，HoAs-PALN任务完成率显著提升，决策时间短于10秒。

Conclusion: HoAs-PALN在动态灾后环境中表现高效，优于基线方法。

Abstract: Natural disasters have caused significant losses to human society, and the
timely and efficient acquisition of post-disaster environmental information is
crucial for the effective implementation of rescue operations. Due to the
complexity of post-disaster environments, existing sensing technologies face
challenges such as weak environmental adaptability, insufficient specialized
sensing capabilities, and limited practicality of sensing solutions. This paper
explores the heterogeneous multi-agent online autonomous collaborative
scheduling algorithm HoAs-PALN, aimed at achieving efficient collection of
post-disaster environmental information. HoAs-PALN is realized through adaptive
dimensionality reduction in the matching process and local Nash equilibrium
game, facilitating autonomous collaboration among time-dependent UAVs, workers
and vehicles to enhance sensing scheduling. (1) In terms of adaptive
dimensionality reduction during the matching process, HoAs-PALN significantly
reduces scheduling decision time by transforming a five-dimensional matching
process into two categories of three-dimensional matching processes; (2)
Regarding the local Nash equilibrium game, HoAs-PALN combines the softmax
function to optimize behavior selection probabilities and introduces a local
Nash equilibrium determination mechanism to ensure scheduling decision
performance. Finally, we conducted detailed experiments based on extensive
real-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL
and MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%,
and 14.03% on average, respectively, while each online scheduling decision
takes less than 10 seconds, demonstrating its effectiveness in dynamic
post-disaster environments.

</details>


### [6] [From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems](https://arxiv.org/abs/2506.04565)
*Jiayi Chen,Junyi Ye,Guiling Wang*

Main category: cs.MA

TL;DR: 该论文综述了复合AI系统（CAIS）的概念，提出了一种基于组件角色和协调策略的多维分类法，并分析了四种基础范式。


<details>
  <summary>Details</summary>
Motivation: 解决当前CAIS领域缺乏统一分析框架的问题，推动系统级人工智能的发展。

Method: 通过定义CAIS概念、提出分类法、分析代表性系统和评估方法。

Result: 总结了CAIS的设计权衡、评估方法，并指出了未来研究方向。

Conclusion: 为研究人员和从业者提供了理解和开发下一代系统级AI的全面基础。

Abstract: Compound Al Systems (CAIS) is an emerging paradigm that integrates large
language models (LLMs) with external components, such as retrievers, agents,
tools, and orchestrators, to overcome the limitations of standalone models in
tasks requiring memory, reasoning, real-time grounding, and multimodal
understanding. These systems enable more capable and context-aware behaviors by
composing multiple specialized modules into cohesive workflows. Despite growing
adoption in both academia and industry, the CAIS landscape remains fragmented,
lacking a unified framework for analysis, taxonomy, and evaluation. In this
survey, we define the concept of CAIS, propose a multi-dimensional taxonomy
based on component roles and orchestration strategies, and analyze four
foundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents,
Multimodal LLMs (MLLMs), and orchestration-centric architectures. We review
representative systems, compare design trade-offs, and summarize evaluation
methodologies across these paradigms. Finally, we identify key
challenges-including scalability, interoperability, benchmarking, and
coordination-and outline promising directions for future research. This survey
aims to provide researchers and practitioners with a comprehensive foundation
for understanding, developing, and advancing the next generation of
system-level artificial intelligence.

</details>


### [7] [Towards Language-Augmented Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2506.05236)
*Maxime Toquebiau,Jae-Yun Jun,Faïz Benamar,Nicolas Bredeche*

Main category: cs.MA

TL;DR: 论文提出了一种基于人类定义语言的多智能体强化学习框架，通过语言增强学习提升协调性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注自发通信协议，但效率低且难以解释，受自然语言启发，探索语言对多智能体学习的促进作用。

Method: 提出一个框架，智能体不仅学习行动，还生成和解释自然语言描述，语言用于显式通信和表征学习指导。

Result: 实验表明，该方法优于传统自发通信基线，语言基础带来更丰富表征、更好泛化能力和人机交互能力。

Conclusion: 将结构化语言融入多智能体学习有效，为可解释和高效系统开辟了新途径。

Abstract: Communication is a fundamental aspect of coordinated behavior in multi-agent
reinforcement learning. Yet, most prior works in this field have focused on
emergent communication protocols developed from scratch, often resulting in
inefficient or non-interpretable systems. Inspired by the role of language in
natural intelligence, we investigate how grounding agents in a human-defined
language can improve learning and coordination of multiple embodied agents. We
propose a framework in which agents are trained not only to act but also to
produce and interpret natural language descriptions of their observations. This
language-augmented learning serves a dual role: enabling explicit communication
between agents and guiding representation learning. We demonstrate that agents
trained with our method outperform traditional emergent communication baselines
across various tasks. Our analysis reveals that language grounding leads to
more informative internal representations, better generalization to new
partners, and improved capability for human-agent interaction. These findings
demonstrate the effectiveness of integrating structured language into
multi-agent learning and open avenues for more interpretable and capable
multi-agent systems.

</details>


### [8] [Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games](https://arxiv.org/abs/2506.05309)
*Niv Eckhaus,Uri Berger,Gabriel Stanovsky*

Main category: cs.MA

TL;DR: 开发了一种异步LLM代理，决定何时发言，并在在线Mafia游戏中表现与人类相当。


<details>
  <summary>Details</summary>
Motivation: 现实场景多为异步通信，而现有LLM主要用于同步对话，需解决何时发言的问题。

Method: 开发自适应异步LLM代理，收集在线Mafia游戏数据集进行评测。

Result: 代理在游戏表现和融入人类玩家方面与人类相当，发言时机与人类相似但内容有差异。

Conclusion: 为LLM融入真实人类群体场景（如团队讨论、教育）铺平道路，并公开数据代码以促进研究。

Abstract: LLMs are used predominantly in synchronous communication, where a human user
and a model communicate in alternating turns. In contrast, many real-world
settings are inherently asynchronous. For example, in group chats, online team
meetings, or social games, there is no inherent notion of turns; therefore, the
decision of when to speak forms a crucial part of the participant's decision
making. In this work, we develop an adaptive asynchronous LLM-agent which, in
addition to determining what to say, also decides when to say it. To evaluate
our agent, we collect a unique dataset of online Mafia games, including both
human participants, as well as our asynchronous agent. Overall, our agent
performs on par with human players, both in game performance, as well as in its
ability to blend in with the other human players. Our analysis shows that the
agent's behavior in deciding when to speak closely mirrors human patterns,
although differences emerge in message content. We release all our data and
code to support and encourage further research for more realistic asynchronous
communication between LLM agents. This work paves the way for integration of
LLMs into realistic human group settings, from assistance in team discussions
to educational and professional environments where complex social dynamics must
be navigated.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning](https://arxiv.org/abs/2506.05252)
*Dravyansh Sharma,Alec Sun*

Main category: cs.LG

TL;DR: 本文研究了机器学习在战略分类中的可学习性，特别是在代理真实改进的情况下，提出了新的学习框架和结果。


<details>
  <summary>Details</summary>
Motivation: 探讨代理在分类过程中真实改进而非欺骗行为时的学习性质，填补现有研究的空白。

Method: 引入非对称变体的最小一致概念类，研究欧几里得球改进集下的学习，并分析有界噪声模型和在线学习。

Result: 在可实现和不可实现设置下，给出了学习能力的精确刻画，解决了Attias等人的开放问题。

Conclusion: 本文扩展了战略分类的学习理论，为代理真实改进场景提供了新的学习方法和理论支持。

Abstract: Machine learning is now ubiquitous in societal decision-making, for example
in evaluating job candidates or loan applications, and it is increasingly
important to take into account how classified agents will react to the learning
algorithms. The majority of recent literature on strategic classification has
focused on reducing and countering deceptive behaviors by the classified
agents, but recent work of Attias et al. identifies surprising properties of
learnability when the agents genuinely improve in order to attain the desirable
classification, such as smaller generalization error than standard
PAC-learning. In this paper we characterize so-called learnability with
improvements across multiple new axes. We introduce an asymmetric variant of
minimally consistent concept classes and use it to provide an exact
characterization of proper learning with improvements in the realizable
setting. While prior work studies learnability only under general, arbitrary
agent improvement regions, we give positive results for more natural Euclidean
ball improvement sets. In particular, we characterize improper learning under a
mild generative assumption on the data distribution. We further show how to
learn in more challenging settings, achieving lower generalization error under
well-studied bounded noise models and obtaining mistake bounds in realizable
and agnostic online learning. We resolve open questions posed by Attias et al.
for both proper and improper learning.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [10] [Gen-n-Val: Agentic Image Data Generation and Validation](https://arxiv.org/abs/2506.04676)
*Jing-En Huang,I-Sheng Fang,Tzuhsuan Huang,Chih-Yu Wang,Jun-Cheng Chen*

Main category: cs.CV

TL;DR: Gen-n-Val是一个新型数据生成框架，利用Layer Diffusion、LLMs和VLLMs生成高质量的单对象掩码和多样化背景，显著减少无效数据并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉任务中数据稀缺和标签噪声问题，当前合成数据生成方法存在多对象掩码、分割不准确和类别标签错误等缺陷。

Method: Gen-n-Val包含两个代理：LD提示代理优化提示生成高质量前景图像和掩码；数据验证代理过滤低质量数据。系统提示通过TextGrad优化，并使用图像协调技术。

Result: 相比现有方法，无效数据从50%降至7%，在COCO实例分割中mAP提升1%，开放词汇检测中mAP提升7.1%。

Conclusion: Gen-n-Val显著提升了合成数据的质量和任务性能，适用于实例分割和对象检测。

Abstract: Recently, Large Language Models (LLMs) and Vision Large Language Models
(VLLMs) have demonstrated impressive performance as agents across various tasks
while data scarcity and label noise remain significant challenges in computer
vision tasks, such as object detection and instance segmentation. A common
solution for resolving these issues is to generate synthetic data. However,
current synthetic data generation methods struggle with issues, such as
multiple objects per mask, inaccurate segmentation, and incorrect category
labels, limiting their effectiveness. To address these issues, we introduce
Gen-n-Val, a novel agentic data generation framework that leverages Layer
Diffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks
and diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt
agent, an LLM, optimizes prompts for LD to generate high-quality foreground
instance images and segmentation masks. These optimized prompts ensure the
generation of single-object synthetic data with precise instance masks and
clean backgrounds. (2) The data validation agent, a VLLM, which filters out
low-quality synthetic instance images. The system prompts for both agents are
refined through TextGrad. Additionally, we use image harmonization to combine
multiple instances within scenes. Compared to state-of-the-art synthetic data
approaches like MosaicFusion, our approach reduces invalid synthetic data from
50% to 7% and improves performance by 1% mAP on rare classes in COCO instance
segmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant
improvements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object
detection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance
of YOLOv9 and YOLO11 families in instance segmentation and object detection.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [11] [Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams](https://arxiv.org/abs/2506.05265)
*Mohammed Almutairi*

Main category: cs.HC

TL;DR: 该论文提出AI增强的团队优化框架，包括团队形成算法、AI反馈助手和模拟框架，以提升团队满意度、参与度和绩效。


<details>
  <summary>Details</summary>
Motivation: 现有团队优化工具依赖静态数据或特定情境，无法适应动态团队互动，导致成员不满和绩效下降。

Method: 1. 多臂老虎机算法优化团队形成；2. AI反馈助手tAIfa提供个性化指导；3. PuppeteerLLM模拟多代理团队动态。

Result: 提出的框架能动态优化团队，提升满意度和绩效。

Conclusion: AI工具可有效解决团队动态问题，增强协作效果。

Abstract: Effective teamwork is essential across diverse domains. During the team
formation stage, a key challenge is forming teams that effectively balance user
preferences with task objectives to enhance overall team satisfaction. In the
team performing stage, maintaining cohesion and engagement is critical for
sustaining high team performance. However, existing computational tools and
algorithms for team optimization often rely on static data inputs, narrow
algorithmic objectives, or solutions tailored for specific contexts, failing to
account for the dynamic interplay of team members personalities, evolving
goals, and changing individual preferences. Therefore, teams may encounter
member dissatisfaction, as purely algorithmic assignments can reduce members
commitment to team goals or experience suboptimal engagement due to the absence
of timely, personalized guidance to help members adjust their behaviors and
interactions as team dynamics evolve. Ultimately, these challenges can lead to
reduced overall team performance. My Ph.D. dissertation aims to develop
AI-augmented team optimization frameworks and practical systems that enhance
team satisfaction, engagement, and performance. First, I propose a team
formation framework that leverages a multi-armed bandit algorithm to
iteratively refine team composition based on user preferences, ensuring
alignment between individual needs and collective team goals to enhance team
satisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an
AI-powered system that utilizes large language models (LLMs) to deliver
immediate, personalized feedback to both teams and individual members,
enhancing cohesion and engagement. Finally, I present PuppeteerLLM, an
LLM-based simulation framework that simulates multi-agent teams to model
complex team dynamics within realistic environments, incorporating task-driven
collaboration and long-term coordination.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation](https://arxiv.org/abs/2506.04251)
*Zhengyang Li*

Main category: cs.AI

TL;DR: LLM-MARL框架将大语言模型（LLM）融入多智能体强化学习（MARL），提升协调、通信和泛化能力，在模拟游戏环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 通过结合LLM和MARL，解决多智能体系统中的协调、通信和泛化问题，推动智能协作代理的发展。

Method: 框架包含Coordinator、Communicator和Memory三个模块，结合PPO训练和语言条件损失，动态生成子目标、符号化消息和情景记忆。

Result: 在多个游戏环境中优于MAPPO和QMIX，零样本泛化能力显著，子目标和语言消息对性能提升贡献大。

Conclusion: LLM-MARL为多智能体系统设计提供了新思路，展示了LLM在训练、游戏和人机协作中的潜力。

Abstract: This paper introduces LLM-MARL, a unified framework that incorporates large
language models (LLMs) into multi-agent reinforcement learning (MARL) to
enhance coordination, communication, and generalization in simulated game
environments. The framework features three modular components of Coordinator,
Communicator, and Memory, which dynamically generate subgoals, facilitate
symbolic inter-agent messaging, and support episodic recall. Training combines
PPO with a language-conditioned loss and LLM query gating. LLM-MARL is
evaluated in Google Research Football, MAgent Battle, and StarCraft II. Results
show consistent improvements over MAPPO and QMIX in win rate, coordination
score, and zero-shot generalization. Ablation studies demonstrate that subgoal
generation and language-based messaging each contribute significantly to
performance gains. Qualitative analysis reveals emergent behaviors such as role
specialization and communication-driven tactics. By bridging language modeling
and policy learning, this work contributes to the design of intelligent,
cooperative agents in interactive simulations. It offers a path forward for
leveraging LLMs in multi-agent systems used for training, games, and human-AI
collaboration.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [13] [Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause Model Based on Fractional-Order Methods](https://arxiv.org/abs/2506.04701)
*Meiru Jiang,Wei Su,Guojian Ren,Yongguang Yu*

Main category: physics.soc-ph

TL;DR: 提出了一种分数阶有界置信度意见动力学模型，用于描述系统状态中的记忆效应，改进了经典模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究记忆效应对社会互动和决策过程的影响，弥补经典意见动力学模型在单调性和历史信息持续性上的不足。

Method: 基于Hegselmann-Krause框架和分数阶差分，建立了一个综合模型，并通过理论分析研究其收敛性和共识特性。

Result: 模型不仅保持了良好的收敛和共识特性，还解决了意见单调性问题，更真实地模拟了现实场景中的意见演化。

Conclusion: 该研究为理解意见形成和演化提供了新的理论和方法，具有理论和实际应用价值。

Abstract: Memory effects play a crucial role in social interactions and decision-making
processes. This paper proposes a novel fractional-order bounded confidence
opinion dynamics model to characterize the memory effects in system states.
Building upon the Hegselmann-Krause framework and fractional-order difference,
a comprehensive model is established that captures the persistent influence of
historical information. Through rigorous theoretical analysis, the fundamental
properties including convergence and consensus is investigated. The results
demonstrate that the proposed model not only maintains favorable convergence
and consensus characteristics compared to classical opinion dynamics, but also
addresses limitations such as the monotonicity of bounded opinions. This
enables a more realistic representation of opinion evolution in real-world
scenarios. The findings of this study provide new insights and methodological
approaches for understanding opinion formation and evolution, offering both
theoretical significance and practical applications.

</details>
