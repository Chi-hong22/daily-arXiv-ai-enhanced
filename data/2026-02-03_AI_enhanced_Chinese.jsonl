{"id": "2601.22204", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22204", "abs": "https://arxiv.org/abs/2601.22204", "authors": ["S M Ruhul Kabir Howlader", "Xiao Chen", "Yifei Xie", "Lu Liu"], "title": "FedAdaVR: Adaptive Variance Reduction for Robust Federated Learning under Limited Client Participation", "comment": null, "summary": "Federated learning (FL) encounters substantial challenges due to heterogeneity, leading to gradient noise, client drift, and partial client participation errors, the last of which is the most pervasive but remains insufficiently addressed in current literature. In this paper, we propose FedAdaVR, a novel FL algorithm aimed at solving heterogeneity issues caused by sporadic client participation by incorporating an adaptive optimiser with a variance reduction technique. This method takes advantage of the most recent stored updates from clients, even when they are absent from the current training round, thereby emulating their presence. Furthermore, we propose FedAdaVR-Quant, which stores client updates in quantised form, significantly reducing the memory requirements (by 50%, 75%, and 87.5%) of FedAdaVR while maintaining equivalent model performance. We analyse the convergence behaviour of FedAdaVR under general nonconvex conditions and prove that our proposed algorithm can eliminate partial client participation error. Extensive experiments conducted on multiple datasets, under both independent and identically distributed (IID) and non-IID settings, demonstrate that FedAdaVR consistently outperforms state-of-the-art baseline methods.", "AI": {"tldr": "FedAdaVR\u662f\u4e00\u79cd\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4f18\u5316\u5668\u548c\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u89e3\u51b3\u5ba2\u6237\u7aef\u5f02\u6784\u6027\u548c\u90e8\u5206\u53c2\u4e0e\u95ee\u9898\uff0c\u5176\u91cf\u5316\u7248\u672cFedAdaVR-Quant\u80fd\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u5f02\u6784\u6027\u6311\u6218\uff0c\u5bfc\u81f4\u68af\u5ea6\u566a\u58f0\u3001\u5ba2\u6237\u7aef\u6f02\u79fb\u548c\u90e8\u5206\u5ba2\u6237\u7aef\u53c2\u4e0e\u8bef\u5dee\uff0c\u5176\u4e2d\u90e8\u5206\u53c2\u4e0e\u95ee\u9898\u6700\u4e3a\u666e\u904d\u4f46\u73b0\u6709\u7814\u7a76\u672a\u80fd\u5145\u5206\u89e3\u51b3\u3002", "method": "\u63d0\u51faFedAdaVR\u7b97\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u4f18\u5316\u5668\u548c\u65b9\u5dee\u7f29\u51cf\u6280\u672f\uff0c\u5229\u7528\u6700\u8fd1\u5b58\u50a8\u7684\u5ba2\u6237\u7aef\u66f4\u65b0\u6a21\u62df\u7f3a\u5e2d\u5ba2\u6237\u7aef\u7684\u53c2\u4e0e\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faFedAdaVR-Quant\uff0c\u901a\u8fc7\u91cf\u5316\u5b58\u50a8\u5ba2\u6237\u7aef\u66f4\u65b0\u6765\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660eFedAdaVR\u80fd\u5728\u4e00\u822c\u975e\u51f8\u6761\u4ef6\u4e0b\u6d88\u9664\u90e8\u5206\u5ba2\u6237\u7aef\u53c2\u4e0e\u8bef\u5dee\uff1b\u5b9e\u9a8c\u8868\u660e\u5728IID\u548c\u975eIID\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1bFedAdaVR-Quant\u80fd\u51cf\u5c1150%\u300175%\u548c87.5%\u7684\u5185\u5b58\u9700\u6c42\u4e14\u4fdd\u6301\u540c\u7b49\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "FedAdaVR\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u90e8\u5206\u5ba2\u6237\u7aef\u53c2\u4e0e\u95ee\u9898\uff0c\u5176\u91cf\u5316\u7248\u672c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u9700\u6c42\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22230", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22230", "abs": "https://arxiv.org/abs/2601.22230", "authors": ["Peijia Qin", "Ruiyi Zhang", "Qi Cao", "Pengtao Xie"], "title": "DAJ: Data-Reweighted LLM Judge for Test-Time Scaling in Code Generation", "comment": null, "summary": "Test-time scaling for code generation commonly relies on Best-of-N selection, in which multiple candidate solutions are sampled from a base model, and the best one is selected by an LLM judge. However, training reliable LLM judges is challenging due to severe distribution shifts, including imbalances between easy and hard problems, mismatches between training tasks and evaluation benchmarks, and trajectory mismatch arising from training data generated by cheaper models whose behavior differs from that of inference-time models. We propose DAJ, a reasoning-based LLM judge trained with verifiable rewards under a bi-level data-reweighted learning framework. The proposed framework learns data-importance weights (either domain-level or instance-level) to optimize generalization performance on a held-out meta set aligned with target benchmarks. To the best of our knowledge, this is the first application of data reweighting to LLM-as-a-Judge training for test-time scaling. Our approach automatically emphasizes hard problems, in-distribution samples, and trajectory-aligned data, without relying on hand-crafted heuristics. Empirically, DAJ achieves state-of-the-art performance on LiveCodeBench and BigCodeBench, outperforming strong test-time scaling baselines as well as leading proprietary models.", "AI": {"tldr": "DAJ\uff1a\u57fa\u4e8e\u63a8\u7406\u7684LLM\u6cd5\u5b98\uff0c\u901a\u8fc7\u53cc\u5c42\u6570\u636e\u91cd\u52a0\u6743\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u5728\u4ee3\u7801\u751f\u6210\u6d4b\u8bd5\u65f6\u7f29\u653e\u4e2d\u5b9e\u73b0SOTA\u6027\u80fd", "motivation": "\u5f53\u524d\u4ee3\u7801\u751f\u6210\u6d4b\u8bd5\u65f6\u7f29\u653e\u4e3b\u8981\u4f9d\u8d56Best-of-N\u9009\u62e9\uff0c\u4f46\u8bad\u7ec3\u53ef\u9760\u7684LLM\u6cd5\u5b98\u9762\u4e34\u4e25\u91cd\u5206\u5e03\u504f\u79fb\u6311\u6218\uff0c\u5305\u62ec\u7b80\u5355\u4e0e\u56f0\u96be\u95ee\u9898\u4e0d\u5e73\u8861\u3001\u8bad\u7ec3\u4efb\u52a1\u4e0e\u8bc4\u4f30\u57fa\u51c6\u4e0d\u5339\u914d\u3001\u4ee5\u53ca\u7531\u5ec9\u4ef7\u6a21\u578b\u751f\u6210\u7684\u8bad\u7ec3\u6570\u636e\u4e0e\u63a8\u7406\u65f6\u6a21\u578b\u884c\u4e3a\u4e0d\u5339\u914d\u7b49\u95ee\u9898", "method": "\u63d0\u51faDAJ\uff08\u63a8\u7406\u578bLLM\u6cd5\u5b98\uff09\uff0c\u91c7\u7528\u53cc\u5c42\u6570\u636e\u91cd\u52a0\u6743\u5b66\u4e60\u6846\u67b6\uff0c\u5b66\u4e60\u6570\u636e\u91cd\u8981\u6027\u6743\u91cd\uff08\u57df\u7ea7\u6216\u5b9e\u4f8b\u7ea7\uff09\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f18\u5316\u5728\u76ee\u6807\u57fa\u51c6\u5bf9\u9f50\u7684\u5143\u96c6\u4e0a\u7684\u6cdb\u5316\u6027\u80fd", "result": "\u5728LiveCodeBench\u548cBigCodeBench\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4f18\u4e8e\u5f3a\u6d4b\u8bd5\u65f6\u7f29\u653e\u57fa\u7ebf\u548c\u9886\u5148\u7684\u4e13\u6709\u6a21\u578b", "conclusion": "DAJ\u662f\u9996\u4e2a\u5c06\u6570\u636e\u91cd\u52a0\u6743\u5e94\u7528\u4e8eLLM\u6cd5\u5b98\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u80fd\u81ea\u52a8\u5f3a\u8c03\u56f0\u96be\u95ee\u9898\u3001\u5206\u5e03\u5185\u6837\u672c\u548c\u8f68\u8ff9\u5bf9\u9f50\u6570\u636e\uff0c\u65e0\u9700\u4f9d\u8d56\u624b\u5de5\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u6cd5\u5b98\u8bad\u7ec3\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898"}}
{"id": "2601.22249", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22249", "abs": "https://arxiv.org/abs/2601.22249", "authors": ["Ruiyi Zhang", "Peijia Qin", "Qi Cao", "Eric Xue", "Pengtao Xie"], "title": "FunPRM: Function-as-Step Process Reward Model with Meta Reward Correction for Code Generation", "comment": null, "summary": "Code generation is a core application of large language models (LLMs), yet LLMs still frequently fail on complex programming tasks. Given its success in mathematical reasoning, test-time scaling approaches such as Process Reward Model (PRM)-based Best-of-N selection offer a promising way to improve performance. However, existing PRMs remain ineffective for code generation due to the lack of meaningful step decomposition in code and the noise of Monte Carlo-estimated partial-solution correctness scores (rewards). To address these challenges, we propose FunPRM. FunPRM prompts LLMs to encourage modular code generation organized into functions, with functions treated as PRM reasoning steps. Furthermore, FunPRM introduces a novel meta-learning-based reward correction mechanism that leverages clean final-solution rewards obtained via a unit-test-based evaluation system to purify noisy partial-solution rewards. Experiments on LiveCodeBench and BigCodeBench demonstrate that FunPRM consistently outperforms existing test-time scaling methods across five base LLMs, notably achieving state-of-the-art performance on LiveCodeBench when combined with O4-mini. Furthermore, FunPRM produces code that is more readable and reusable for developers.", "AI": {"tldr": "FunPRM\u662f\u4e00\u79cd\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u51fd\u6570\u5316\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\u548c\u5143\u5b66\u4e60\u5956\u52b1\u4fee\u6b63\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u6709\u6838\u5fc3\u5e94\u7528\uff0c\u4f46\u5728\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u4e0a\u4ecd\u7136\u7ecf\u5e38\u5931\u8d25\u3002\u73b0\u6709\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u56e0\u4e3a\u4ee3\u7801\u7f3a\u4e4f\u6709\u610f\u4e49\u7684\u6b65\u9aa4\u5206\u89e3\uff0c\u4ee5\u53ca\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u7684\u90e8\u5206\u89e3\u51b3\u65b9\u6848\u6b63\u786e\u6027\u5206\u6570\u5b58\u5728\u566a\u58f0\u3002", "method": "FunPRM\u91c7\u7528\u4e24\u79cd\u521b\u65b0\u65b9\u6cd5\uff1a1) \u63d0\u793a\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6a21\u5757\u5316\u7684\u51fd\u6570\u5316\u4ee3\u7801\uff0c\u5c06\u51fd\u6570\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u7684\u63a8\u7406\u6b65\u9aa4\uff1b2) \u5f15\u5165\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u5956\u52b1\u4fee\u6b63\u673a\u5236\uff0c\u5229\u7528\u5355\u5143\u6d4b\u8bd5\u8bc4\u4f30\u7cfb\u7edf\u83b7\u5f97\u7684\u5e72\u51c0\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u5956\u52b1\u6765\u51c0\u5316\u566a\u58f0\u7684\u90e8\u5206\u89e3\u51b3\u65b9\u6848\u5956\u52b1\u3002", "result": "\u5728LiveCodeBench\u548cBigCodeBench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFunPRM\u5728\u4e94\u4e2a\u57fa\u7840\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u4e0eO4-mini\u7ed3\u5408\u65f6\u5728LiveCodeBench\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0cFunPRM\u751f\u6210\u7684\u4ee3\u7801\u5bf9\u5f00\u53d1\u8005\u6765\u8bf4\u66f4\u5177\u53ef\u8bfb\u6027\u548c\u53ef\u91cd\u7528\u6027\u3002", "conclusion": "FunPRM\u901a\u8fc7\u51fd\u6570\u5316\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\u548c\u5143\u5b66\u4e60\u5956\u52b1\u4fee\u6b63\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u4ea7\u751f\u4e86\u66f4\u5b9e\u7528\u3001\u53ef\u7ef4\u62a4\u7684\u4ee3\u7801\u3002"}}
{"id": "2601.22257", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22257", "abs": "https://arxiv.org/abs/2601.22257", "authors": ["Eva Silverstein", "Daniel Kunin", "Vasudev Shyam"], "title": "Symmetry Breaking in Transformers for Efficient and Interpretable Training", "comment": "22 pages, 3 figures", "summary": "The attention mechanism in its standard implementation contains extraneous rotational degrees of freedom that are carried through computation but do not affect model activations or outputs. We introduce a simple symmetry-breaking protocol that inserts a preferred direction into this rotational space through batchwise-sampled, unlearned query and value biases. This modification has two theoretically motivated and empirically validated consequences. First, it can substantially improve the performance of simple, memory-efficient optimizers, narrowing -- and in some cases closing -- the gap to successful but more complex memory-intensive adaptive methods. We demonstrate this by pretraining 124M parameter transformer models with four optimization algorithms (AdamW, SOAP, SGDM, and Energy Conserving Descent(ECD)) and evaluating both validation loss and downstream logical reasoning. Second, it enables an interpretable use of otherwise redundant rotational degrees of freedom, selectively amplifying semantically meaningful token classes within individual attention heads. Overall, our results show that minimal, principled architectural changes can simultaneously improve performance and interpretability.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u6279\u91cf\u91c7\u6837\u7684\u65e0\u5b66\u4e60\u67e5\u8be2\u548c\u503c\u504f\u7f6e\u6765\u6253\u7834\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u65cb\u8f6c\u5bf9\u79f0\u6027\uff0c\u6539\u5584\u7b80\u5355\u4f18\u5316\u5668\u7684\u6027\u80fd\u5e76\u589e\u5f3a\u6ce8\u610f\u529b\u5934\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5b58\u5728\u4e0d\u5f71\u54cd\u6a21\u578b\u6fc0\u6d3b\u6216\u8f93\u51fa\u7684\u5197\u4f59\u65cb\u8f6c\u81ea\u7531\u5ea6\uff0c\u8fd9\u4e9b\u81ea\u7531\u5ea6\u5728\u8ba1\u7b97\u4e2d\u88ab\u4f20\u9012\u4f46\u672a\u88ab\u6709\u6548\u5229\u7528\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u7684\u5bf9\u79f0\u6027\u7834\u574f\u534f\u8bae\uff0c\u901a\u8fc7\u6279\u91cf\u91c7\u6837\u7684\u65e0\u5b66\u4e60\u67e5\u8be2\u548c\u503c\u504f\u7f6e\u5728\u65cb\u8f6c\u7a7a\u95f4\u4e2d\u63d2\u5165\u9996\u9009\u65b9\u5411\u3002", "result": "1) \u663e\u8457\u6539\u5584\u7b80\u5355\u5185\u5b58\u9ad8\u6548\u4f18\u5316\u5668\u7684\u6027\u80fd\uff0c\u7f29\u5c0f\u751a\u81f3\u6d88\u9664\u4e0e\u590d\u6742\u5185\u5b58\u5bc6\u96c6\u578b\u81ea\u9002\u5e94\u65b9\u6cd5\u7684\u5dee\u8ddd\uff1b2) \u4f7f\u539f\u672c\u5197\u4f59\u7684\u65cb\u8f6c\u81ea\u7531\u5ea6\u5177\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u9009\u62e9\u6027\u653e\u5927\u5355\u4e2a\u6ce8\u610f\u529b\u5934\u4e2d\u8bed\u4e49\u6709\u610f\u4e49\u7684token\u7c7b\u522b\u3002", "conclusion": "\u6700\u5c0f\u5316\u3001\u6709\u539f\u5219\u7684\u67b6\u6784\u53d8\u5316\u53ef\u4ee5\u540c\u65f6\u63d0\u9ad8\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.22259", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22259", "abs": "https://arxiv.org/abs/2601.22259", "authors": ["Da In Kim", "Wei Siang Lai", "Kelly W. Zhang"], "title": "Tabular Foundation Models Can Do Survival Analysis", "comment": null, "summary": "While tabular foundation models have achieved remarkable success in classification and regression, adapting them to model time-to-event outcomes for survival analysis is non-trivial due to right-censoring, where data observations may end before the event occurs. We develop a classification-based framework that reformulates both static and dynamic survival analysis as a series of binary classification problems by discretizing event times. Censored observations are naturally handled as examples with missing labels at certain time points. This classification formulation enables existing tabular foundation models to perform survival analysis through in-context learning without explicit training. We prove that under standard censoring assumptions, minimizing our binary classification loss recovers the true survival probabilities as the training set size increases. We demonstrate through evaluation across $53$ real-world datasets that off-the-shelf tabular foundation models with this classification formulation outperform classical and deep learning baselines on average over multiple survival metrics.", "AI": {"tldr": "\u5c06\u751f\u5b58\u5206\u6790\u91cd\u65b0\u6784\u5efa\u4e3a\u5206\u7c7b\u95ee\u9898\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u4e8b\u4ef6\u65f6\u95f4\u5c06\u9759\u6001\u548c\u52a8\u6001\u751f\u5b58\u5206\u6790\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u4e8c\u5206\u7c7b\u95ee\u9898\uff0c\u4f7f\u73b0\u6210\u7684\u8868\u683c\u57fa\u7840\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fdb\u884c\u751f\u5b58\u5206\u6790\u800c\u65e0\u9700\u663e\u5f0f\u8bad\u7ec3\u3002", "motivation": "\u8868\u683c\u57fa\u7840\u6a21\u578b\u5728\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u7531\u4e8e\u53f3\u5220\u5931\uff08\u6570\u636e\u89c2\u6d4b\u53ef\u80fd\u5728\u4e8b\u4ef6\u53d1\u751f\u524d\u7ed3\u675f\uff09\uff0c\u5c06\u5176\u9002\u5e94\u4e8e\u5efa\u6a21\u751f\u5b58\u5206\u6790\u7684\u65f6\u95f4\u5230\u4e8b\u4ef6\u7ed3\u679c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5206\u7c7b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u4e8b\u4ef6\u65f6\u95f4\u5c06\u751f\u5b58\u5206\u6790\u91cd\u65b0\u6784\u5efa\u4e3a\u4e00\u7cfb\u5217\u4e8c\u5206\u7c7b\u95ee\u9898\u3002\u5220\u5931\u89c2\u6d4b\u88ab\u81ea\u7136\u5730\u5904\u7406\u4e3a\u5728\u67d0\u4e9b\u65f6\u95f4\u70b9\u7f3a\u5c11\u6807\u7b7e\u7684\u793a\u4f8b\u3002\u8fd9\u79cd\u5206\u7c7b\u8868\u8ff0\u4f7f\u73b0\u6709\u8868\u683c\u57fa\u7840\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fdb\u884c\u751f\u5b58\u5206\u6790\u800c\u65e0\u9700\u663e\u5f0f\u8bad\u7ec3\u3002", "result": "\u572853\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u4f7f\u7528\u8fd9\u79cd\u5206\u7c7b\u8868\u8ff0\u7684\u73b0\u6210\u8868\u683c\u57fa\u7840\u6a21\u578b\u5728\u591a\u4e2a\u751f\u5b58\u6307\u6807\u4e0a\u5e73\u5747\u4f18\u4e8e\u7ecf\u5178\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6846\u67b6\u6210\u529f\u5730\u5c06\u751f\u5b58\u5206\u6790\u9002\u5e94\u4e8e\u8868\u683c\u57fa\u7840\u6a21\u578b\uff0c\u5728\u6807\u51c6\u5220\u5931\u5047\u8bbe\u4e0b\uff0c\u6700\u5c0f\u5316\u4e8c\u5206\u7c7b\u635f\u5931\u80fd\u591f\u968f\u7740\u8bad\u7ec3\u96c6\u5927\u5c0f\u7684\u589e\u52a0\u6062\u590d\u771f\u5b9e\u7684\u751f\u5b58\u6982\u7387\uff0c\u4e3a\u751f\u5b58\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.22265", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.22265", "abs": "https://arxiv.org/abs/2601.22265", "authors": ["Ramakant Kumar", "Pravin Kumar"], "title": "Privacy-Preserving Sensor-Based Human Activity Recognition for Low-Resource Healthcare Using Classical Machine Learning", "comment": null, "summary": "Limited access to medical infrastructure forces elderly and vulnerable patients to rely on home-based care, often leading to neglect and poor adherence to therapeutic exercises such as yoga or physiotherapy. To address this gap, we propose a low-cost and automated human activity recognition (HAR) framework based on wearable inertial sensors and machine learning. Activity data, including walking, walking upstairs, walking downstairs, sitting, standing, and lying, were collected using accelerometer and gyroscope measurements. Four classical classifiers, Logistic Regression, Random Forest, Support Vector Machine (SVM), and k-Nearest Neighbors (k-NN), were evaluated and compared with the proposed Support Tensor Machine (STM). Experimental results show that SVM achieved an accuracy of 93.33 percent, while Logistic Regression, Random Forest, and k-NN achieved 91.11 percent. In contrast, STM significantly outperformed these models, achieving a test accuracy of 96.67 percent and the highest cross-validation accuracy of 98.50 percent. Unlike conventional methods, STM leverages tensor representations to preserve spatio-temporal motion dynamics, resulting in robust classification across diverse activities. The proposed framework demonstrates strong potential for remote healthcare, elderly assistance, child activity monitoring, yoga feedback, and smart home wellness, offering a scalable solution for low-resource and rural healthcare settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u7a7f\u6234\u60ef\u6027\u4f20\u611f\u5668\u548c\u673a\u5668\u5b66\u4e60\u7684\u4f4e\u6210\u672c\u81ea\u52a8\u5316\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u6846\u67b6\uff0c\u7528\u4e8e\u8fdc\u7a0b\u533b\u7597\u548c\u8001\u5e74\u4eba\u8f85\u52a9\uff0c\u652f\u6301\u5f20\u91cf\u673a\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5206\u7c7b\u5668\u3002", "motivation": "\u533b\u7597\u57fa\u7840\u8bbe\u65bd\u6709\u9650\u5bfc\u81f4\u8001\u5e74\u4eba\u548c\u5f31\u52bf\u60a3\u8005\u4f9d\u8d56\u5bb6\u5ead\u62a4\u7406\uff0c\u4f46\u5e38\u51fa\u73b0\u5ffd\u89c6\u548c\u6cbb\u7597\u6027\u953b\u70bc\uff08\u5982\u745c\u4f3d\u6216\u7269\u7406\u6cbb\u7597\uff09\u4f9d\u4ece\u6027\u5dee\u7684\u95ee\u9898\u3002\u9700\u8981\u4f4e\u6210\u672c\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u76d1\u6d4b\u548c\u6539\u5584\u5bb6\u5ead\u62a4\u7406\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u52a0\u901f\u5ea6\u8ba1\u548c\u9640\u87ba\u4eea\u6d4b\u91cf\u6536\u96c6\u6d3b\u52a8\u6570\u636e\uff08\u884c\u8d70\u3001\u4e0a\u4e0b\u697c\u68af\u3001\u5750\u3001\u7ad9\u3001\u8eba\uff09\uff0c\u8bc4\u4f30\u56db\u79cd\u7ecf\u5178\u5206\u7c7b\u5668\uff08\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u3001SVM\u3001k-NN\uff09\uff0c\u5e76\u4e0e\u63d0\u51fa\u7684\u652f\u6301\u5f20\u91cf\u673a\uff08STM\uff09\u8fdb\u884c\u6bd4\u8f83\u3002STM\u5229\u7528\u5f20\u91cf\u8868\u793a\u4fdd\u7559\u65f6\u7a7a\u8fd0\u52a8\u52a8\u6001\u3002", "result": "SVM\u51c6\u786e\u7387\u4e3a93.33%\uff0c\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u548ck-NN\u4e3a91.11%\u3002STM\u663e\u8457\u4f18\u4e8e\u8fd9\u4e9b\u6a21\u578b\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe\u523096.67%\uff0c\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387\u6700\u9ad8\u8fbe98.50%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u8fdc\u7a0b\u533b\u7597\u3001\u8001\u5e74\u4eba\u8f85\u52a9\u3001\u513f\u7ae5\u6d3b\u52a8\u76d1\u6d4b\u3001\u745c\u4f3d\u53cd\u9988\u548c\u667a\u80fd\u5bb6\u5c45\u5065\u5eb7\u65b9\u9762\u5177\u6709\u5f3a\u5927\u6f5c\u529b\uff0c\u4e3a\u4f4e\u8d44\u6e90\u548c\u519c\u6751\u533b\u7597\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22274", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22274", "abs": "https://arxiv.org/abs/2601.22274", "authors": ["Longtao Xu", "Jian Li"], "title": "Task-Uniform Convergence and Backward Transfer in Federated Domain-Incremental Learning with Partial Participation", "comment": null, "summary": "Real-world federated systems seldom operate on static data: input distributions drift while privacy rules forbid raw-data sharing. We study this setting as Federated Domain-Incremental Learning (FDIL), where (i) clients are heterogeneous, (ii) tasks arrive sequentially with shifting domains, yet (iii) the label space remains fixed. Two theoretical pillars remain missing for FDIL under realistic deployment: a guarantee of backward knowledge transfer (BKT) and a convergence rate that holds across the sequence of all tasks with partial participation. We introduce SPECIAL (Server-Proximal Efficient Continual Aggregation for Learning), a simple, memory-free FDIL algorithm that adds a single server-side ``anchor'' to vanilla FedAvg: in each round, the server nudges the uniformly sampled participated clients update toward the previous global model with a lightweight proximal term. This anchor curbs cumulative drift without replay buffers, synthetic data, or task-specific heads, keeping communication and model size unchanged. Our theory shows that SPECIAL (i) preserves earlier tasks: a BKT bound caps any increase in prior-task loss by a drift-controlled term that shrinks with more rounds, local epochs, and participating clients; and (ii) learns efficiently across all tasks: the first communication-efficient non-convex convergence rate for FDIL with partial participation, O((E/NT)^(1/2)), with E local epochs, T communication rounds, and N participated clients per round, matching single-task FedAvg while explicitly separating optimization variance from inter-task drift. Experimental results further demonstrate the effectiveness of SPECIAL.", "AI": {"tldr": "SPECIAL\u7b97\u6cd5\u5728\u8054\u90a6\u57df\u589e\u91cf\u5b66\u4e60(FDIL)\u4e2d\uff0c\u901a\u8fc7\u6dfb\u52a0\u670d\u52a1\u5668\u7aef\"\u951a\u70b9\"\u9879\u6765\u6291\u5236\u7d2f\u79ef\u6f02\u79fb\uff0c\u65e0\u9700\u8bb0\u5fc6\u7f13\u51b2\uff0c\u5b9e\u73b0\u4e86\u5411\u540e\u77e5\u8bc6\u4f20\u9012\u4fdd\u8bc1\u548c\u8de8\u4efb\u52a1\u7684\u6536\u655b\u7387\u3002", "motivation": "\u73b0\u5b9e\u8054\u90a6\u7cfb\u7edf\u4e2d\u6570\u636e\u5206\u5e03\u4f1a\u6f02\u79fb\uff0c\u4f46\u9690\u79c1\u89c4\u5219\u7981\u6b62\u539f\u59cb\u6570\u636e\u5171\u4eab\u3002\u8054\u90a6\u57df\u589e\u91cf\u5b66\u4e60(FDIL)\u9762\u4e34\u4e24\u4e2a\u7406\u8bba\u7f3a\u5931\uff1a\u5411\u540e\u77e5\u8bc6\u4f20\u9012(BKT)\u4fdd\u8bc1\u548c\u8de8\u6240\u6709\u4efb\u52a1\u7684\u90e8\u5206\u53c2\u4e0e\u6536\u655b\u7387\u3002", "method": "SPECIAL\u7b97\u6cd5\u5728FedAvg\u57fa\u7840\u4e0a\u6dfb\u52a0\u670d\u52a1\u5668\u7aef\"\u951a\u70b9\"\u9879\uff1a\u6bcf\u8f6e\u4e2d\u670d\u52a1\u5668\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8fd1\u7aef\u9879\u5c06\u53c2\u4e0e\u5ba2\u6237\u7aef\u66f4\u65b0\u5411\u5148\u524d\u5168\u5c40\u6a21\u578b\u65b9\u5411\u5fae\u8c03\uff0c\u65e0\u9700\u8bb0\u5fc6\u7f13\u51b2\u3001\u5408\u6210\u6570\u636e\u6216\u4efb\u52a1\u7279\u5b9a\u5934\u3002", "result": "\u7406\u8bba\u8bc1\u660eSPECIAL\uff1a(1)\u4fdd\u62a4\u5148\u524d\u4efb\u52a1\uff1aBKT\u8fb9\u754c\u9650\u5236\u5148\u524d\u4efb\u52a1\u635f\u5931\u589e\u52a0\uff0c\u8be5\u8fb9\u754c\u968f\u66f4\u591a\u8f6e\u6b21\u3001\u672c\u5730\u5468\u671f\u548c\u53c2\u4e0e\u5ba2\u6237\u7aef\u800c\u7f29\u5c0f\uff1b(2)\u8de8\u4efb\u52a1\u9ad8\u6548\u5b66\u4e60\uff1a\u9996\u6b21\u5b9e\u73b0FDIL\u90e8\u5206\u53c2\u4e0e\u4e0b\u7684\u901a\u4fe1\u9ad8\u6548\u975e\u51f8\u6536\u655b\u7387O((E/NT)^(1/2))\u3002", "conclusion": "SPECIAL\u901a\u8fc7\u7b80\u5355\u670d\u52a1\u5668\u7aef\u951a\u70b9\u673a\u5236\u89e3\u51b3\u4e86FDIL\u4e2d\u7684\u5173\u952e\u7406\u8bba\u6311\u6218\uff0c\u5728\u4fdd\u6301\u901a\u4fe1\u548c\u6a21\u578b\u5927\u5c0f\u4e0d\u53d8\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5411\u540e\u77e5\u8bc6\u4f20\u9012\u4fdd\u8bc1\u548c\u8de8\u4efb\u52a1\u6536\u655b\u7387\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.22284", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22284", "abs": "https://arxiv.org/abs/2601.22284", "authors": ["Yixuan Wang", "Omkar Sudhir Patil", "Warren E. Dixon"], "title": "Riemannian Lyapunov Optimizer: A Unified Framework for Optimization", "comment": "22 pages, 4 figures", "summary": "We introduce Riemannian Lyapunov Optimizers (RLOs), a family of optimization algorithms that unifies classic optimizers within one geometric framework. Unlike heuristic improvements to existing optimizers, RLOs are systematically derived from a novel control-theoretic framework that reinterprets optimization as an extended state discrete-time controlled dynamical system on a Riemannian parameter manifold. Central to this framework is the identification of a Normally Attracting Invariant Manifold (NAIM), which organizes training dynamics into two distinct stages: rapid alignment of the speed state to a target graph, followed by controlled evolution within it. We formalize this by constructing a strict Lyapunov function that certifies convergence to a target manifold. This perspective yields a constructive ``optimizer generator\" that not only recovers classic algorithms but enables the principled design of RLOs. We validate our theory via geometric diagnostics and demonstrate that grounding optimizer design in control theory yields state-of-the-art performance in large-scale benchmarks. Overall, RLOs bridge control theory and modern machine learning optimization, providing a unified language and a systematic toolkit for designing stable, effective optimizers.", "AI": {"tldr": "Riemannian Lyapunov Optimizers (RLOs) \u662f\u4e00\u4e2a\u57fa\u4e8e\u63a7\u5236\u7406\u8bba\u7684\u4f18\u5316\u7b97\u6cd5\u5bb6\u65cf\uff0c\u5c06\u7ecf\u5178\u4f18\u5316\u5668\u7edf\u4e00\u5728\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u8bc6\u522b\u4e0d\u53d8\u6d41\u5f62\u5c06\u8bad\u7ec3\u52a8\u6001\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff0c\u5e76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u4f18\u5316\u5668\u8bbe\u8ba1\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u4f18\u5316\u7b97\u6cd5\u7684\u6539\u8fdb\u5927\u591a\u57fa\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u7406\u8bba\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u63a7\u5236\u7406\u8bba\u4e3a\u4f18\u5316\u5668\u8bbe\u8ba1\u63d0\u4f9b\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u4f18\u5316\u95ee\u9898\u91cd\u65b0\u89e3\u91ca\u4e3a\u9ece\u66fc\u6d41\u5f62\u4e0a\u7684\u79bb\u6563\u65f6\u95f4\u63a7\u5236\u7cfb\u7edf\u3002", "method": "\u63d0\u51faRiemannian Lyapunov Optimizers\u6846\u67b6\uff1a1) \u5c06\u4f18\u5316\u91cd\u65b0\u89e3\u91ca\u4e3a\u9ece\u66fc\u53c2\u6570\u6d41\u5f62\u4e0a\u7684\u6269\u5c55\u72b6\u6001\u79bb\u6563\u65f6\u95f4\u63a7\u5236\u7cfb\u7edf\uff1b2) \u8bc6\u522bNormally Attracting Invariant Manifold (NAIM)\uff0c\u5c06\u8bad\u7ec3\u52a8\u6001\u5206\u4e3a\u5feb\u901f\u5bf9\u9f50\u9636\u6bb5\u548c\u53d7\u63a7\u6f14\u5316\u9636\u6bb5\uff1b3) \u6784\u5efa\u4e25\u683c\u7684Lyapunov\u51fd\u6570\u6765\u8bc1\u660e\u6536\u655b\u6027\uff1b4) \u5f00\u53d1\"\u4f18\u5316\u5668\u751f\u6210\u5668\"\u6765\u7cfb\u7edf\u8bbe\u8ba1RLOs\u3002", "result": "RLOs\u4e0d\u4ec5\u80fd\u591f\u6062\u590d\u7ecf\u5178\u4f18\u5316\u7b97\u6cd5\uff0c\u8fd8\u80fd\u57fa\u4e8e\u63a7\u5236\u7406\u8bba\u539f\u7406\u8bbe\u8ba1\u65b0\u7684\u4f18\u5316\u5668\u3002\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u51e0\u4f55\u8bca\u65ad\u9a8c\u8bc1\u4e86\u7406\u8bba\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "RLOs\u5728\u63a7\u5236\u7406\u8bba\u548c\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4f18\u5316\u4e4b\u95f4\u5efa\u7acb\u4e86\u6865\u6881\uff0c\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8bed\u8a00\u548c\u7cfb\u7edf\u5316\u7684\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u8bbe\u8ba1\u7a33\u5b9a\u3001\u6709\u6548\u7684\u4f18\u5316\u5668\uff0c\u4e3a\u4f18\u5316\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.22285", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22285", "abs": "https://arxiv.org/abs/2601.22285", "authors": ["Luca Zhou", "Bo Zhao", "Rose Yu", "Emanuele Rodol\u00e0"], "title": "Demystifying Mergeability: Interpretable Properties to Predict Model Merging Success", "comment": "8 pages of main paper, 3 figures in the main paper, 4 tables in the main paper, many more figures and tables in the appendix", "summary": "Model merging combines knowledge from separately fine-tuned models, yet success factors remain poorly understood. While recent work treats mergeability as an intrinsic property, we show with an architecture-agnostic framework that it fundamentally depends on both the merging method and the partner tasks. Using linear optimization over a set of interpretable pairwise metrics (e.g., gradient L2 distance), we uncover properties correlating with post-merge performance across four merging methods. We find substantial variation in success drivers (46.7% metric overlap; 55.3% sign agreement), revealing method-specific \"fingerprints\". Crucially, however, subspace overlap and gradient alignment metrics consistently emerge as foundational, method-agnostic prerequisites for compatibility. These findings provide a diagnostic foundation for understanding mergeability and motivate future fine-tuning strategies that explicitly encourage these properties.", "AI": {"tldr": "\u6a21\u578b\u5408\u5e76\u7684\u6210\u529f\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u6a21\u578b\u672c\u8eab\uff0c\u8fd8\u53d6\u51b3\u4e8e\u5408\u5e76\u65b9\u6cd5\u548c\u4efb\u52a1\u7279\u6027\uff0c\u7814\u7a76\u53d1\u73b0\u5b50\u7a7a\u95f4\u91cd\u53e0\u548c\u68af\u5ea6\u5bf9\u9f50\u662f\u65b9\u6cd5\u65e0\u5173\u7684\u517c\u5bb9\u6027\u57fa\u7840\u6761\u4ef6\u3002", "motivation": "\u867d\u7136\u6a21\u578b\u5408\u5e76\u80fd\u591f\u6574\u5408\u4e0d\u540c\u5fae\u8c03\u6a21\u578b\u7684\u77e5\u8bc6\uff0c\u4f46\u6210\u529f\u56e0\u7d20\u4ecd\u4e0d\u660e\u786e\u3002\u73b0\u6709\u7814\u7a76\u5c06\u53ef\u5408\u5e76\u6027\u89c6\u4e3a\u5185\u5728\u5c5e\u6027\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u5b9e\u9645\u4e0a\u53d6\u51b3\u4e8e\u5408\u5e76\u65b9\u6cd5\u548c\u4efb\u52a1\u7279\u6027\u3002", "method": "\u4f7f\u7528\u67b6\u6784\u65e0\u5173\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u4f18\u5316\u4e00\u7ec4\u53ef\u89e3\u91ca\u7684\u6210\u5bf9\u6307\u6807\uff08\u5982\u68af\u5ea6L2\u8ddd\u79bb\uff09\uff0c\u5206\u6790\u56db\u79cd\u5408\u5e76\u65b9\u6cd5\uff0c\u8bc6\u522b\u4e0e\u5408\u5e76\u540e\u6027\u80fd\u76f8\u5173\u7684\u5c5e\u6027\u3002", "result": "\u53d1\u73b0\u6210\u529f\u9a71\u52a8\u56e0\u7d20\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0846.7%\u6307\u6807\u91cd\u53e0\uff1b55.3%\u7b26\u53f7\u4e00\u81f4\u6027\uff09\uff0c\u63ed\u793a\u4e86\u65b9\u6cd5\u7279\u5b9a\u7684\"\u6307\u7eb9\"\u3002\u4f46\u5b50\u7a7a\u95f4\u91cd\u53e0\u548c\u68af\u5ea6\u5bf9\u9f50\u6307\u6807\u59cb\u7ec8\u4f5c\u4e3a\u65b9\u6cd5\u65e0\u5173\u7684\u517c\u5bb9\u6027\u57fa\u7840\u6761\u4ef6\u51fa\u73b0\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u7406\u89e3\u53ef\u5408\u5e76\u6027\u63d0\u4f9b\u4e86\u8bca\u65ad\u57fa\u7840\uff0c\u5e76\u6fc0\u52b1\u672a\u6765\u5f00\u53d1\u660e\u786e\u9f13\u52b1\u8fd9\u4e9b\u5c5e\u6027\u7684\u5fae\u8c03\u7b56\u7565\u3002"}}
{"id": "2601.22302", "categories": ["cs.LG", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22302", "abs": "https://arxiv.org/abs/2601.22302", "authors": ["Amirhossein Taherpour", "Xiaodong Wang"], "title": "ZK-HybridFL: Zero-Knowledge Proof-Enhanced Hybrid Ledger for Federated Learning", "comment": "Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "summary": "Federated learning (FL) enables collaborative model training while preserving data privacy, yet both centralized and decentralized approaches face challenges in scalability, security, and update validation. We propose ZK-HybridFL, a secure decentralized FL framework that integrates a directed acyclic graph (DAG) ledger with dedicated sidechains and zero-knowledge proofs (ZKPs) for privacy-preserving model validation. The framework uses event-driven smart contracts and an oracle-assisted sidechain to verify local model updates without exposing sensitive data. A built-in challenge mechanism efficiently detects adversarial behavior. In experiments on image classification and language modeling tasks, ZK-HybridFL achieves faster convergence, higher accuracy, lower perplexity, and reduced latency compared to Blade-FL and ChainFL. It remains robust against substantial fractions of adversarial and idle nodes, supports sub-second on-chain verification with efficient gas usage, and prevents invalid updates and orphanage-style attacks. This makes ZK-HybridFL a scalable and secure solution for decentralized FL across diverse environments.", "AI": {"tldr": "ZK-HybridFL\u662f\u4e00\u4e2a\u5b89\u5168\u7684\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408DAG\u8d26\u672c\u3001\u4e13\u7528\u4fa7\u94fe\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u6a21\u578b\u9a8c\u8bc1\uff0c\u5728\u5bf9\u6297\u6027\u8282\u70b9\u5b58\u5728\u65f6\u4ecd\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u96c6\u4e2d\u5f0f\u548c\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u3001\u5b89\u5168\u6027\u548c\u66f4\u65b0\u9a8c\u8bc1\u65b9\u9762\u90fd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u66f4\u5b89\u5168\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faZK-HybridFL\u6846\u67b6\uff0c\u96c6\u6210\u6709\u5411\u65e0\u73af\u56fe\u8d26\u672c\u3001\u4e13\u7528\u4fa7\u94fe\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u4f7f\u7528\u4e8b\u4ef6\u9a71\u52a8\u667a\u80fd\u5408\u7ea6\u548c\u9884\u8a00\u673a\u8f85\u52a9\u7684\u4fa7\u94fe\u9a8c\u8bc1\u672c\u5730\u6a21\u578b\u66f4\u65b0\u800c\u4e0d\u66b4\u9732\u654f\u611f\u6570\u636e\uff0c\u5185\u7f6e\u6311\u6218\u673a\u5236\u68c0\u6d4b\u5bf9\u6297\u884c\u4e3a\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4Blade-FL\u548cChainFL\uff0cZK-HybridFL\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\u3001\u66f4\u9ad8\u51c6\u786e\u7387\u3001\u66f4\u4f4e\u56f0\u60d1\u5ea6\u548c\u66f4\u4f4e\u5ef6\u8fdf\uff0c\u80fd\u62b5\u6297\u5927\u91cf\u5bf9\u6297\u6027\u548c\u7a7a\u95f2\u8282\u70b9\uff0c\u652f\u6301\u4e9a\u79d2\u7ea7\u94fe\u4e0a\u9a8c\u8bc1\u548c\u9ad8\u6548gas\u4f7f\u7528\u3002", "conclusion": "ZK-HybridFL\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u5b89\u5168\u7684\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u73af\u5883\uff0c\u80fd\u6709\u6548\u9632\u6b62\u65e0\u6548\u66f4\u65b0\u548c\u5b64\u513f\u5f0f\u653b\u51fb\u3002"}}
{"id": "2601.22305", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22305", "abs": "https://arxiv.org/abs/2601.22305", "authors": ["Bo Yuan", "Yun Zhou", "Zhichao Xu", "Kiran Ramnath", "Aosong Feng", "Balasubramaniam Srinivasan"], "title": "BayesFlow: A Probability Inference Framework for Meta-Agent Assisted Workflow Generation", "comment": "EACL 2026 Finding", "summary": "Automatic workflow generation is the process of automatically synthesizing sequences of LLM calls, tool invocations, and post-processing steps for complex end-to-end tasks. Most prior methods cast this task as an optimization problem with limited theoretical grounding. We propose to cast workflow generation as Bayesian inference over a posterior distribution on workflows, and introduce \\textbf{Bayesian Workflow Generation (BWG)}, a sampling framework that builds workflows step-by-step using parallel look-ahead rollouts for importance weighting and a sequential in-loop refiner for pool-wide improvements. We prove that, without the refiner, the weighted empirical distribution converges to the target posterior. We instantiate BWG as \\textbf{BayesFlow}, a training-free algorithm for workflow construction. Across six benchmark datasets, BayesFlow improves accuracy by up to 9 percentage points over SOTA workflow generation baselines and by up to 65 percentage points over zero-shot prompting, establishing BWG as a principled upgrade to search-based workflow design. Code will be available on https://github.com/BoYuanVisionary/BayesFlow.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u5de5\u4f5c\u6d41\u751f\u6210\u65b9\u6cd5BWG\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u548c\u5e8f\u5217\u7ec6\u5316\u5668\u81ea\u52a8\u6784\u5efaLLM\u8c03\u7528\u5e8f\u5217\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5de5\u4f5c\u6d41\u751f\u6210\u65b9\u6cd5\u5927\u591a\u5c06\u5176\u89c6\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u3002\u672c\u6587\u65e8\u5728\u4e3a\u5de5\u4f5c\u6d41\u751f\u6210\u63d0\u4f9b\u66f4\u4e25\u8c28\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u65b9\u6cd5\u6539\u8fdb\u5de5\u4f5c\u6d41\u751f\u6210\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u5de5\u4f5c\u6d41\u751f\u6210(BWG)\u6846\u67b6\uff0c\u5c06\u5176\u5efa\u6a21\u4e3a\u5de5\u4f5c\u6d41\u540e\u9a8c\u5206\u5e03\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u95ee\u9898\u3002\u4f7f\u7528\u5e76\u884c\u524d\u77bb\u5c55\u5f00\u8fdb\u884c\u91cd\u8981\u6027\u52a0\u6743\uff0c\u7ed3\u5408\u5e8f\u5217\u5faa\u73af\u7ec6\u5316\u5668\u8fdb\u884c\u6574\u4f53\u6539\u8fdb\u3002\u5177\u4f53\u5b9e\u73b0\u4e3aBayesFlow\u7b97\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u6784\u5efa\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBayesFlow\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5de5\u4f5c\u6d41\u751f\u6210\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e86\u6700\u591a9\u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u96f6\u6837\u672c\u63d0\u793a\u63d0\u5347\u4e86\u6700\u591a65\u4e2a\u767e\u5206\u70b9\u3002\u8bc1\u660e\u4e86BWG\u4f5c\u4e3a\u57fa\u4e8e\u641c\u7d22\u7684\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u7684\u7406\u8bba\u5347\u7ea7\u7684\u6709\u6548\u6027\u3002", "conclusion": "BWG\u4e3a\u81ea\u52a8\u5de5\u4f5c\u6d41\u751f\u6210\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6\uff0cBayesFlow\u7b97\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u590d\u6742\u7aef\u5230\u7aef\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u548c\u65b9\u6cd5\u57fa\u7840\u3002"}}
{"id": "2601.22312", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.22312", "abs": "https://arxiv.org/abs/2601.22312", "authors": ["Can Polat", "Erchin Serpedin", "Mustafa Kurban", "Hasan Kurban"], "title": "SCALAR: Quantifying Structural Hallucination, Consistency, and Reasoning Gaps in Materials Foundation Models", "comment": null, "summary": "Large language models are increasingly applied to materials science reasoning, yet their behavior under physically structured distribution shifts remains poorly understood. We introduce SCALAR (Structural Consistency And Logic Across Regimes), a benchmark for evaluating geometric scale generalization and its connection to structural hallucination, consistency, and reasoning in materials foundation models. Given canonical crystal representations, models must reason about derived nanoparticle structures obtained through supercell expansion and geometric truncation across length scales spanning a few atoms to over 18,000 atoms, totaling $\\approx$100,000 structures from DFT-validated unit cells. SCALAR defines three tasks. (i) CIF to property prediction. (ii) A Chain-of-Thought variant with explicit physics-grounded reasoning. (iii) Inverse retrieval identifying crystals from candidates given target properties. Outputs are evaluated via structured metrics capturing numeric error, hallucination, cross-prompt consistency, monotonic reasoning, output validity, and retrieval regret. Experiments across diverse foundation models reveal large, model-dependent shifts under explicit reasoning, often reducing hallucination and error, but frequently destabilizing consistency or validity. These results demonstrate that geometric scale generalization cannot be inferred from accuracy alone. Supplementary materials are available at https://github.com/KurbanIntelligenceLab/SCALAR.", "AI": {"tldr": "SCALAR\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6750\u6599\u57fa\u7840\u6a21\u578b\u5728\u51e0\u4f55\u5c3a\u5ea6\u6cdb\u5316\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e09\u4e2a\u4efb\u52a1\uff1aCIF\u5230\u5c5e\u6027\u9884\u6d4b\u3001\u57fa\u4e8e\u7269\u7406\u63a8\u7406\u7684\u601d\u7ef4\u94fe\u53d8\u4f53\u3001\u4ee5\u53ca\u9006\u5411\u68c0\u7d22\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e86\u6a21\u578b\u5728\u4ece\u51e0\u4e2a\u539f\u5b50\u5230\u8d85\u8fc718,000\u4e2a\u539f\u5b50\u7684\u5c3a\u5ea6\u53d8\u5316\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u6750\u6599\u79d1\u5b66\u63a8\u7406\uff0c\u4f46\u5b83\u4eec\u5728\u7269\u7406\u7ed3\u6784\u5316\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u884c\u4e3a\u4ecd\u4e0d\u6e05\u695a\u3002\u9700\u8981\u8bc4\u4f30\u51e0\u4f55\u5c3a\u5ea6\u6cdb\u5316\u80fd\u529b\u53ca\u5176\u4e0e\u7ed3\u6784\u5e7b\u89c9\u3001\u4e00\u81f4\u6027\u548c\u63a8\u7406\u7684\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u4e86SCALAR\u57fa\u51c6\uff0c\u5305\u542b\u7ea6100,000\u4e2a\u4eceDFT\u9a8c\u8bc1\u7684\u6676\u80de\u901a\u8fc7\u8d85\u80de\u6269\u5c55\u548c\u51e0\u4f55\u622a\u65ad\u5f97\u5230\u7684\u7eb3\u7c73\u7ed3\u6784\u3002\u5b9a\u4e49\u4e86\u4e09\u4e2a\u4efb\u52a1\uff1aCIF\u5230\u5c5e\u6027\u9884\u6d4b\u3001\u57fa\u4e8e\u7269\u7406\u63a8\u7406\u7684\u601d\u7ef4\u94fe\u53d8\u4f53\u3001\u9006\u5411\u68c0\u7d22\u3002\u4f7f\u7528\u7ed3\u6784\u5316\u6307\u6807\u8bc4\u4f30\u6570\u503c\u8bef\u5dee\u3001\u5e7b\u89c9\u3001\u8de8\u63d0\u793a\u4e00\u81f4\u6027\u3001\u5355\u8c03\u63a8\u7406\u3001\u8f93\u51fa\u6709\u6548\u6027\u548c\u68c0\u7d22\u9057\u61be\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u5728\u663e\u5f0f\u63a8\u7406\u4e0b\u8868\u73b0\u51fa\u5927\u7684\u3001\u6a21\u578b\u4f9d\u8d56\u7684\u504f\u79fb\uff0c\u901a\u5e38\u51cf\u5c11\u5e7b\u89c9\u548c\u8bef\u5dee\uff0c\u4f46\u7ecf\u5e38\u7834\u574f\u4e00\u81f4\u6027\u6216\u6709\u6548\u6027\u3002\u51e0\u4f55\u5c3a\u5ea6\u6cdb\u5316\u4e0d\u80fd\u4ec5\u4ece\u51c6\u786e\u6027\u63a8\u65ad\u3002", "conclusion": "\u51e0\u4f55\u5c3a\u5ea6\u6cdb\u5316\u662f\u6750\u6599\u57fa\u7840\u6a21\u578b\u8bc4\u4f30\u7684\u91cd\u8981\u7ef4\u5ea6\uff0c\u9700\u8981\u8d85\u8d8a\u51c6\u786e\u6027\u7684\u7ed3\u6784\u5316\u6307\u6807\u6765\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5728\u7269\u7406\u7ed3\u6784\u5316\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2601.22313", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22313", "abs": "https://arxiv.org/abs/2601.22313", "authors": ["Yavuz Bakman", "Duygu Nur Yaldiz", "Salman Avestimehr", "Sai Praneeth Karimireddy"], "title": "Hair-Trigger Alignment: Black-Box Evaluation Cannot Guarantee Post-Update Alignment", "comment": null, "summary": "Large Language Models (LLMs) are rarely static and are frequently updated in practice. A growing body of alignment research has shown that models initially deemed \"aligned\" can exhibit misaligned behavior after fine-tuning, such as forgetting jailbreak safety features or re-surfacing knowledge that was intended to be forgotten. These works typically assume that the initial model is aligned based on static black-box evaluation, i.e., the absence of undesired responses to a fixed set of queries. In contrast, we formalize model alignment in both the static and post-update settings and uncover a fundamental limitation of black-box evaluation. We theoretically show that, due to overparameterization, static alignment provides no guarantee of post-update alignment for any update dataset. Moreover, we prove that static black-box probing cannot distinguish a model that is genuinely post-update robust from one that conceals an arbitrary amount of adversarial behavior which can be activated by even a single benign gradient update. We further validate these findings empirically in LLMs across three core alignment domains: privacy, jailbreak safety, and behavioral honesty. We demonstrate the existence of LLMs that pass all standard black-box alignment tests, yet become severely misaligned after a single benign update. Finally, we show that the capacity to hide such latent adversarial behavior increases with model scale, confirming our theoretical prediction that post-update misalignment grows with the number of parameters. Together, our results highlight the inadequacy of static evaluation protocols and emphasize the urgent need for post-update-robust alignment evaluation.", "AI": {"tldr": "\u9759\u6001\u9ed1\u76d2\u8bc4\u4f30\u65e0\u6cd5\u4fdd\u8bc1\u6a21\u578b\u66f4\u65b0\u540e\u7684\u5bf9\u9f50\u6027\uff0c\u5373\u4f7f\u901a\u8fc7\u6240\u6709\u6807\u51c6\u6d4b\u8bd5\u7684LLM\u5728\u5355\u6b21\u826f\u6027\u66f4\u65b0\u540e\u4e5f\u53ef\u80fd\u4e25\u91cd\u5931\u51c6\uff0c\u4e14\u8fd9\u79cd\u9690\u85cf\u7684\u5bf9\u6297\u884c\u4e3a\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u52a0\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u521d\u59cb\u6a21\u578b\u662f\u5bf9\u9f50\u7684\uff0c\u4f46\u5b9e\u8df5\u4e2dLLM\u9891\u7e41\u66f4\u65b0\uff0c\u800c\u9759\u6001\u9ed1\u76d2\u8bc4\u4f30\u65e0\u6cd5\u68c0\u6d4b\u6a21\u578b\u66f4\u65b0\u540e\u53ef\u80fd\u51fa\u73b0\u7684\u5931\u51c6\u884c\u4e3a\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u9759\u6001\u8bc4\u4f30\u7684\u6839\u672c\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u66f4\u65b0\u540e\u9c81\u68d2\u7684\u5bf9\u9f50\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u4ece\u7406\u8bba\u4e0a\u5f62\u5f0f\u5316\u9759\u6001\u548c\u66f4\u65b0\u540e\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u7684\u6a21\u578b\u5bf9\u9f50\u6982\u5ff5\uff0c\u8bc1\u660e\u7531\u4e8e\u8fc7\u53c2\u6570\u5316\uff0c\u9759\u6001\u5bf9\u9f50\u4e0d\u80fd\u4fdd\u8bc1\u66f4\u65b0\u540e\u5bf9\u9f50\u3002\u7136\u540e\u7406\u8bba\u8bc1\u660e\u9759\u6001\u9ed1\u76d2\u63a2\u6d4b\u65e0\u6cd5\u533a\u5206\u771f\u6b63\u66f4\u65b0\u540e\u9c81\u68d2\u7684\u6a21\u578b\u548c\u9690\u85cf\u4efb\u610f\u6570\u91cf\u5bf9\u6297\u884c\u4e3a\u7684\u6a21\u578b\u3002\u6700\u540e\u5728LLM\u7684\u4e09\u4e2a\u6838\u5fc3\u5bf9\u9f50\u9886\u57df\uff08\u9690\u79c1\u3001\u8d8a\u72f1\u5b89\u5168\u3001\u884c\u4e3a\u8bda\u5b9e\uff09\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u9759\u6001\u5bf9\u9f50\u65e0\u6cd5\u4fdd\u8bc1\u66f4\u65b0\u540e\u5bf9\u9f50\uff0c\u4e14\u9759\u6001\u9ed1\u76d2\u8bc4\u4f30\u65e0\u6cd5\u68c0\u6d4b\u9690\u85cf\u7684\u5bf9\u6297\u884c\u4e3a\u3002\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u5b58\u5728\u901a\u8fc7\u6240\u6709\u6807\u51c6\u9ed1\u76d2\u5bf9\u9f50\u6d4b\u8bd5\u7684LLM\uff0c\u5728\u5355\u6b21\u826f\u6027\u66f4\u65b0\u540e\u53d8\u5f97\u4e25\u91cd\u5931\u51c6\u3002\u540c\u65f6\u53d1\u73b0\u9690\u85cf\u8fd9\u79cd\u6f5c\u5728\u5bf9\u6297\u884c\u4e3a\u7684\u80fd\u529b\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u52a0\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\u3002", "conclusion": "\u9759\u6001\u8bc4\u4f30\u534f\u8bae\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u6a21\u578b\u66f4\u65b0\u540e\u7684\u5bf9\u9f50\u6027\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u8feb\u5207\u9700\u8981\u5f00\u53d1\u66f4\u65b0\u540e\u9c81\u68d2\u7684\u5bf9\u9f50\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6a21\u578b\u89c4\u6a21\u4e0d\u65ad\u589e\u5927\u7684\u80cc\u666f\u4e0b\u3002"}}
{"id": "2601.22315", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22315", "abs": "https://arxiv.org/abs/2601.22315", "authors": ["Xin Jennifer Chen", "Yunjin Tong"], "title": "Gaussian Process Bandit Optimization with Machine Learning Predictions and Application to Hypothesis Generation", "comment": null, "summary": "Many real-world optimization problems involve an expensive ground-truth oracle (e.g., human evaluation, physical experiments) and a cheap, low-fidelity prediction oracle (e.g., machine learning models, simulations). Meanwhile, abundant offline data (e.g., past experiments and predictions) are often available and can be used to pretrain powerful predictive models, as well as to provide an informative prior. We propose Prediction-Augmented Gaussian Process Upper Confidence Bound (PA-GP-UCB), a novel Bayesian optimization algorithm that leverages both oracles and offline data to achieve provable gains in sample efficiency for the ground-truth oracle queries. PA-GP-UCB employs a control-variates estimator derived from a joint Gaussian process posterior to correct prediction bias and reduce uncertainty. We prove that PA-GP-UCB preserves the standard regret rate of GP-UCB while achieving a strictly smaller leading constant that is explicitly controlled by prediction quality and offline data coverage. Empirically, PA-GP-UCB converges faster than Vanilla GP-UCB and naive prediction-augmented GP-UCB baselines on synthetic benchmarks and on a real-world hypothesis evaluation task grounded in human behavioral data, where predictions are provided by large language models. These results establish PA-GP-UCB as a general and sample-efficient framework for hypothesis generation under expensive feedback.", "AI": {"tldr": "\u63d0\u51faPA-GP-UCB\u7b97\u6cd5\uff0c\u5229\u7528\u6602\u8d35\u771f\u5b9e\u8bc4\u4f30\u548c\u5ec9\u4ef7\u9884\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408\u79bb\u7ebf\u6570\u636e\u63d0\u5347\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u6837\u672c\u6548\u7387", "motivation": "\u73b0\u5b9e\u4f18\u5316\u95ee\u9898\u4e2d\u5e38\u5b58\u5728\u6602\u8d35\u771f\u5b9e\u8bc4\u4f30\uff08\u5982\u4eba\u5de5\u8bc4\u4f30\u3001\u7269\u7406\u5b9e\u9a8c\uff09\u548c\u5ec9\u4ef7\u4f4e\u7cbe\u5ea6\u9884\u6d4b\uff08\u5982\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3001\u6a21\u62df\uff09\uff0c\u540c\u65f6\u6709\u5927\u91cf\u79bb\u7ebf\u6570\u636e\u53ef\u7528\u4e8e\u9884\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\u548c\u63d0\u4f9b\u5148\u9a8c\u4fe1\u606f\u3002\u9700\u8981\u5f00\u53d1\u80fd\u540c\u65f6\u5229\u7528\u4e24\u79cd\u8bc4\u4f30\u6e90\u548c\u79bb\u7ebf\u6570\u636e\u7684\u7b97\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u771f\u5b9e\u8bc4\u4f30\u7684\u6837\u672c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u9884\u6d4b\u589e\u5f3a\u9ad8\u65af\u8fc7\u7a0b\u4e0a\u7f6e\u4fe1\u754c\uff08PA-GP-UCB\uff09\u7b97\u6cd5\uff0c\u4f7f\u7528\u8054\u5408\u9ad8\u65af\u8fc7\u7a0b\u540e\u9a8c\u63a8\u5bfc\u7684\u63a7\u5236\u53d8\u91cf\u4f30\u8ba1\u5668\u6765\u6821\u6b63\u9884\u6d4b\u504f\u5dee\u5e76\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u3002\u7b97\u6cd5\u7ed3\u5408\u6602\u8d35\u771f\u5b9e\u8bc4\u4f30\u548c\u5ec9\u4ef7\u9884\u6d4b\uff0c\u5229\u7528\u79bb\u7ebf\u6570\u636e\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u7406\u8bba\u8bc1\u660ePA-GP-UCB\u4fdd\u6301\u4e86GP-UCB\u7684\u6807\u51c6\u9057\u61be\u7387\uff0c\u540c\u65f6\u83b7\u5f97\u4e86\u66f4\u5c0f\u7684\u4e3b\u5bfc\u5e38\u6570\uff0c\u8be5\u5e38\u6570\u7531\u9884\u6d4b\u8d28\u91cf\u548c\u79bb\u7ebf\u6570\u636e\u8986\u76d6\u5ea6\u660e\u786e\u63a7\u5236\u3002\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u57fa\u4e8e\u4eba\u7c7b\u884c\u4e3a\u6570\u636e\u7684\u771f\u5b9e\u5047\u8bbe\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0cPA-GP-UCB\u6bd4Vanilla GP-UCB\u548c\u6734\u7d20\u9884\u6d4b\u589e\u5f3a\u57fa\u7ebf\u6536\u655b\u66f4\u5feb\u3002", "conclusion": "PA-GP-UCB\u4e3a\u6602\u8d35\u53cd\u9988\u4e0b\u7684\u5047\u8bbe\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u6837\u672c\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u5229\u7528\u9884\u6d4b\u6a21\u578b\u548c\u79bb\u7ebf\u6570\u636e\u63d0\u5347\u4f18\u5316\u6548\u7387\u3002"}}
{"id": "2601.22318", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22318", "abs": "https://arxiv.org/abs/2601.22318", "authors": ["Baris Askin", "Shivam Patel", "Anupam Nayak", "Andrea Vigano", "Jiin Woo", "Gauri Joshi", "Carlee Joe-Wong"], "title": "Federate the Router: Learning Language Model Routers with Sparse and Decentralized Evaluations", "comment": null, "summary": "Large language models (LLMs) are increasingly accessed as remotely hosted services by edge and enterprise clients that cannot run frontier models locally. Since models vary widely in capability and price, routing queries to models that balance quality and inference cost is essential. Existing router approaches assume access to centralized query-model evaluation data. However, these data are often fragmented across clients, such as end users and organizations, and are privacy-sensitive, which makes centralizing data infeasible. Additionally, per-client router training is ineffective since local evaluation data is limited and covers only a restricted query distribution and a biased subset of model evaluations. We introduce the first federated framework for LLM routing, enabling clients to learn a shared routing policy from local offline query-model evaluation data. Our framework supports both parametric multilayer perceptron router and nonparametric K-means router under heterogeneous client query distributions and non-uniform model coverage. Across two benchmarks, federated collaboration improves the accuracy-cost frontier over client-local routers, both via increased effective model coverage and better query generalization. Our theoretical results also validate that federated training reduces routing suboptimality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8eLLM\u8def\u7531\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u5ba2\u6237\u7aef\u80fd\u591f\u4ece\u672c\u5730\u79bb\u7ebf\u67e5\u8be2-\u6a21\u578b\u8bc4\u4f30\u6570\u636e\u4e2d\u5b66\u4e60\u5171\u4eab\u8def\u7531\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u9690\u79c1\u5206\u6563\u548c\u672c\u5730\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8fdc\u7a0b\u670d\u52a1\u88ab\u8fb9\u7f18\u548c\u4f01\u4e1a\u5ba2\u6237\u7aef\u8bbf\u95ee\uff0c\u9700\u8981\u5e73\u8861\u8d28\u91cf\u548c\u63a8\u7406\u6210\u672c\u7684\u8def\u7531\u7b56\u7565\u3002\u73b0\u6709\u8def\u7531\u65b9\u6cd5\u5047\u8bbe\u53ef\u4ee5\u8bbf\u95ee\u96c6\u4e2d\u5316\u7684\u67e5\u8be2-\u6a21\u578b\u8bc4\u4f30\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u5206\u6563\u5728\u5ba2\u6237\u7aef\u4e14\u5177\u6709\u9690\u79c1\u654f\u611f\u6027\uff0c\u65e0\u6cd5\u96c6\u4e2d\u3002\u540c\u65f6\uff0c\u6bcf\u4e2a\u5ba2\u6237\u7aef\u5355\u72ec\u8bad\u7ec3\u8def\u7531\u7b56\u7565\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u672c\u5730\u8bc4\u4f30\u6570\u636e\u8986\u76d6\u8303\u56f4\u6709\u9650\u4e14\u5b58\u5728\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8eLLM\u8def\u7531\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u652f\u6301\u53c2\u6570\u5316\u7684\u591a\u5c42\u611f\u77e5\u673a\u8def\u7531\u5668\u548c\u975e\u53c2\u6570\u7684K-means\u8def\u7531\u5668\uff0c\u80fd\u591f\u5904\u7406\u5f02\u6784\u5ba2\u6237\u7aef\u67e5\u8be2\u5206\u5e03\u548c\u975e\u5747\u5300\u6a21\u578b\u8986\u76d6\u3002\u901a\u8fc7\u8054\u90a6\u534f\u4f5c\u8ba9\u5ba2\u6237\u7aef\u4ece\u672c\u5730\u79bb\u7ebf\u6570\u636e\u4e2d\u5b66\u4e60\u5171\u4eab\u8def\u7531\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8054\u90a6\u534f\u4f5c\u76f8\u6bd4\u5ba2\u6237\u7aef\u672c\u5730\u8def\u7531\u5668\u5728\u51c6\u786e\u7387-\u6210\u672c\u8fb9\u754c\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u65e2\u901a\u8fc7\u589e\u52a0\u6709\u6548\u6a21\u578b\u8986\u76d6\uff0c\u4e5f\u901a\u8fc7\u66f4\u597d\u7684\u67e5\u8be2\u6cdb\u5316\u80fd\u529b\u3002\u7406\u8bba\u7ed3\u679c\u4e5f\u9a8c\u8bc1\u4e86\u8054\u90a6\u8bad\u7ec3\u80fd\u591f\u51cf\u5c11\u8def\u7531\u6b21\u4f18\u6027\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e3aLLM\u8def\u7531\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u534f\u4f5c\u63d0\u9ad8\u8def\u7531\u7b56\u7565\u7684\u8d28\u91cf\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5206\u6563\u548c\u672c\u5730\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\u3002"}}
{"id": "2601.22320", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22320", "abs": "https://arxiv.org/abs/2601.22320", "authors": ["Nikita P. Kalinin", "Ali Najar", "Valentin Roth", "Christoph H. Lampert"], "title": "Matrix Factorization for Practical Continual Mean Estimation Under User-Level Differential Privacy", "comment": null, "summary": "We study continual mean estimation, where data vectors arrive sequentially and the goal is to maintain accurate estimates of the running mean. We address this problem under user-level differential privacy, which protects each user's entire dataset even when they contribute multiple data points. Previous work on this problem has focused on pure differential privacy. While important, this approach limits applicability, as it leads to overly noisy estimates. In contrast, we analyze the problem under approximate differential privacy, adopting recent advances in the Matrix Factorization mechanism. We introduce a novel mean estimation specific factorization, which is both efficient and accurate, achieving asymptotically lower mean-squared error bounds in continual mean estimation under user-level differential privacy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8fde\u7eed\u5747\u503c\u4f30\u8ba1\u95ee\u9898\uff0c\u5728\u7528\u6237\u7ea7\u5dee\u5206\u9690\u79c1\u4e0b\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u76f8\u6bd4\u7eaf\u5dee\u5206\u9690\u79c1\u663e\u8457\u964d\u4f4e\u8bef\u5dee", "motivation": "\u8fde\u7eed\u5747\u503c\u4f30\u8ba1\u5728\u6570\u636e\u5411\u91cf\u987a\u5e8f\u5230\u8fbe\u65f6\u9700\u8981\u4fdd\u6301\u8fd0\u884c\u5747\u503c\u7684\u51c6\u786e\u4f30\u8ba1\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7eaf\u5dee\u5206\u9690\u79c1\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u4f30\u8ba1\u566a\u58f0\u8fc7\u5927\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u56e0\u6b64\u9700\u8981\u5728\u8fd1\u4f3c\u5dee\u5206\u9690\u79c1\u4e0b\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8fd1\u4f3c\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u5229\u7528\u77e9\u9635\u5206\u89e3\u673a\u5236\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u5747\u503c\u4f30\u8ba1\u7684\u65b0\u578b\u5206\u89e3\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u65e2\u9ad8\u6548\u53c8\u51c6\u786e\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u7528\u6237\u7ea7\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u8fde\u7eed\u5747\u503c\u4f30\u8ba1\u4e2d\u5b9e\u73b0\u4e86\u6e10\u8fdb\u66f4\u4f4e\u7684\u5747\u65b9\u8bef\u5dee\u754c\u9650\uff0c\u76f8\u6bd4\u7eaf\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u8fd1\u4f3c\u5dee\u5206\u9690\u79c1\u548c\u4e13\u95e8\u8bbe\u8ba1\u7684\u77e9\u9635\u5206\u89e3\u673a\u5236\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8fde\u7eed\u5747\u503c\u4f30\u8ba1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22322", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22322", "abs": "https://arxiv.org/abs/2601.22322", "authors": ["Ayesh Abu Lehyeh", "Anastassia Gharib", "Safwan Wshah"], "title": "Spatially-Adaptive Conformal Graph Transformer for Indoor Localization in Wi-Fi Driven Networks", "comment": "Accepted to IEEE ICC 2026", "summary": "Indoor localization is a critical enabler for a wide range of location-based services in smart environments, including navigation, asset tracking, and safety-critical applications. Recent graph-based models leverage spatial relationships between Wire-less Fidelity (Wi-Fi) Access Points (APs) and devices, offering finer localization granularity, but fall short in quantifying prediction uncertainty, a key requirement for real-world deployment. In this paper, we propose Spatially-Adaptive Conformal Graph Transformer (SAC-GT), a framework for accurate and reliable indoor localization. SAC-GT integrates a Graph Transformer (GT) model that captures network's spatial topology and signal strength dynamics, with a novel Spatially-Adaptive Conformal Prediction (SACP) method that provides region-specific uncertainty estimates. This allows SAC-GT to produce not only precise two-dimensional (2D) location predictions but also statistically valid confidence regions tailored to varying environmental conditions. Extensive evaluations on a large-scale real-world dataset demonstrate that the proposed SAC-GT solution achieves state-of-the-art localization accuracy while delivering robust and spatially adaptive reliability guarantees.", "AI": {"tldr": "\u63d0\u51faSAC-GT\u6846\u67b6\uff0c\u7ed3\u5408\u56fe\u53d8\u6362\u5668\u548c\u7a7a\u95f4\u81ea\u9002\u5e94\u4fdd\u5f62\u9884\u6d4b\uff0c\u5b9e\u73b0\u7cbe\u786e\u4e14\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5ba4\u5185\u5b9a\u4f4d", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u5ba4\u5185\u5b9a\u4f4d\u6a21\u578b\u867d\u7136\u80fd\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u5b9a\u4f4d\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u91cf\u5316\uff0c\u800c\u8fd9\u5bf9\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981", "method": "SAC-GT\u6846\u67b6\u6574\u5408\u56fe\u53d8\u6362\u5668\u6a21\u578b\uff08\u6355\u6349\u7a7a\u95f4\u62d3\u6251\u548c\u4fe1\u53f7\u5f3a\u5ea6\u52a8\u6001\uff09\u548c\u65b0\u578b\u7a7a\u95f4\u81ea\u9002\u5e94\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\uff08\u63d0\u4f9b\u533a\u57df\u7279\u5b9a\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff09", "result": "\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cSAC-GT\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u540c\u65f6\u63d0\u4f9b\u9c81\u68d2\u4e14\u7a7a\u95f4\u81ea\u9002\u5e94\u7684\u53ef\u9760\u6027\u4fdd\u8bc1", "conclusion": "SAC-GT\u6846\u67b6\u80fd\u591f\u540c\u65f6\u63d0\u4f9b\u7cbe\u786e\u76842D\u4f4d\u7f6e\u9884\u6d4b\u548c\u7edf\u8ba1\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u57df\uff0c\u9002\u5e94\u4e0d\u540c\u73af\u5883\u6761\u4ef6\uff0c\u89e3\u51b3\u4e86\u5ba4\u5185\u5b9a\u4f4d\u4e2d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u95ee\u9898"}}
{"id": "2601.22323", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22323", "abs": "https://arxiv.org/abs/2601.22323", "authors": ["Qi Cao", "Shuhao Zhang", "Ruizhe Zhou", "Ruiyi Zhang", "Peijia Qin", "Pengtao Xie"], "title": "Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning", "comment": "We propose SCOPE, a model routing framework that predicts how accurate and how expensive each model will be before running it, allowing users to control cost-accuracy trade-offs and naturally handle new models", "summary": "Model routing chooses which language model to use for each query. By sending easy queries to cheaper models and hard queries to stronger ones, it can significantly reduce inference cost while maintaining high accuracy. However, most existing routers treat this as a fixed choice among a small set of models, which makes them hard to adapt to new models or changing budget constraints. In this paper, we propose SCOPE (Scalable and Controllable Outcome Performance Estimator), a routing framework that goes beyond model selection by predicting their cost and performance. Trained with reinforcement learning, SCOPE makes reasoning-based predictions by retrieving how models behave on similar problems, rather than relying on fixed model names, enabling it to work with new, unseen models. Moreover, by explicitly predicting how accurate and how expensive a model will be, it turns routing into a dynamic decision problem, allowing users to easily control the trade-off between accuracy and cost. Experiments show that SCOPE is more than just a cost-saving tool. It flexibly adapts to user needs: it can boost accuracy by up to 25.7% when performance is the priority, or cut costs by up to 95.1% when efficiency matters most.", "AI": {"tldr": "SCOPE\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u53ef\u63a7\u7684\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u6a21\u578b\u6210\u672c\u548c\u6027\u80fd\u8fdb\u884c\u52a8\u6001\u8def\u7531\u51b3\u7b56\uff0c\u800c\u975e\u56fa\u5b9a\u6a21\u578b\u9009\u62e9\uff0c\u80fd\u7075\u6d3b\u9002\u5e94\u65b0\u6a21\u578b\u548c\u9884\u7b97\u7ea6\u675f", "motivation": "\u73b0\u6709\u6a21\u578b\u8def\u7531\u65b9\u6cd5\u901a\u5e38\u5c06\u8def\u7531\u89c6\u4e3a\u5728\u5c11\u91cf\u6a21\u578b\u95f4\u7684\u56fa\u5b9a\u9009\u62e9\uff0c\u96be\u4ee5\u9002\u5e94\u65b0\u6a21\u578b\u6216\u53d8\u5316\u7684\u9884\u7b97\u7ea6\u675f\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u8def\u7531\u6846\u67b6", "method": "\u63d0\u51faSCOPE\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u57fa\u4e8e\u68c0\u7d22\u76f8\u4f3c\u95ee\u9898\u4e0a\u7684\u6a21\u578b\u884c\u4e3a\u8fdb\u884c\u63a8\u7406\u9884\u6d4b\uff0c\u800c\u975e\u4f9d\u8d56\u56fa\u5b9a\u6a21\u578b\u540d\u79f0\uff0c\u80fd\u9884\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6210\u672c", "result": "SCOPE\u80fd\u7075\u6d3b\u9002\u5e94\u7528\u6237\u9700\u6c42\uff1a\u5f53\u6027\u80fd\u4f18\u5148\u65f6\u53ef\u63d0\u5347\u51c6\u786e\u7387\u9ad8\u8fbe25.7%\uff0c\u5f53\u6548\u7387\u4f18\u5148\u65f6\u53ef\u964d\u4f4e\u6210\u672c\u9ad8\u8fbe95.1%", "conclusion": "SCOPE\u4e0d\u4ec5\u662f\u4e00\u4e2a\u6210\u672c\u8282\u7ea6\u5de5\u5177\uff0c\u66f4\u662f\u4e00\u4e2a\u52a8\u6001\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u6a21\u578b\u6210\u672c\u548c\u6027\u80fd\uff0c\u8ba9\u7528\u6237\u80fd\u8f7b\u677e\u63a7\u5236\u51c6\u786e\u6027\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861"}}
{"id": "2601.22328", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22328", "abs": "https://arxiv.org/abs/2601.22328", "authors": ["Luca Muscarnera", "Silas Ruhrberg Est\u00e9vez", "Samuel Holt", "Evgeny Saveliev", "Mihaela van der Schaar"], "title": "Knowledge-Informed Kernel State Reconstruction for Interpretable Dynamical System Discovery", "comment": null, "summary": "Recovering governing equations from data is central to scientific discovery, yet existing methods often break down under noisy, partial observations, or rely on black-box latent dynamics that obscure mechanism. We introduce MAAT (Model Aware Approximation of Trajectories), a framework for symbolic discovery built on knowledge-informed Kernel State Reconstruction. MAAT formulates state reconstruction in a reproducing kernel Hilbert space and directly incorporates structural and semantic priors such as non-negativity, conservation laws, and domain-specific observation models into the reconstruction objective, while accommodating heterogeneous sampling and measurement granularity. This yields smooth, physically consistent state estimates with analytic time derivatives, providing a principled interface between fragmented sensor data and symbolic regression. Across twelve diverse scientific benchmarks and multiple noise regimes, MAAT substantially reduces state-estimation MSE for trajectories and derivatives used by downstream symbolic regression relative to strong baselines.", "AI": {"tldr": "MAAT\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u5f15\u5bfc\u7684\u6838\u72b6\u6001\u91cd\u6784\uff0c\u4ece\u566a\u58f0\u3001\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u4e2d\u6062\u590d\u7269\u7406\u7cfb\u7edf\u7684\u63a7\u5236\u65b9\u7a0b\uff0c\u7ed3\u5408\u7ed3\u6784\u5148\u9a8c\u77e5\u8bc6\u63d0\u5347\u7b26\u53f7\u53d1\u73b0\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u566a\u58f0\u3001\u90e8\u5206\u89c2\u6d4b\u6761\u4ef6\u4e0b\u5bb9\u6613\u5931\u6548\uff0c\u6216\u4f9d\u8d56\u9ed1\u76d2\u6f5c\u5728\u52a8\u529b\u5b66\u6a21\u578b\u800c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3001\u5904\u7406\u975e\u5747\u5300\u91c7\u6837\u548c\u6d4b\u91cf\u7c92\u5ea6\u7684\u7b26\u53f7\u53d1\u73b0\u6846\u67b6\u3002", "method": "MAAT\u5728\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u6784\u5efa\u72b6\u6001\u91cd\u6784\uff0c\u76f4\u63a5\u878d\u5165\u7ed3\u6784\u5148\u9a8c\uff08\u5982\u975e\u8d1f\u6027\u3001\u5b88\u6052\u5b9a\u5f8b\u3001\u9886\u57df\u7279\u5b9a\u89c2\u6d4b\u6a21\u578b\uff09\uff0c\u83b7\u5f97\u5e73\u6ed1\u3001\u7269\u7406\u4e00\u81f4\u7684\u72b6\u6001\u4f30\u8ba1\u548c\u89e3\u6790\u65f6\u95f4\u5bfc\u6570\uff0c\u4e3a\u7b26\u53f7\u56de\u5f52\u63d0\u4f9b\u63a5\u53e3\u3002", "result": "\u572812\u4e2a\u4e0d\u540c\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u79cd\u566a\u58f0\u673a\u5236\u4e0b\uff0cMAAT\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u72b6\u6001\u4f30\u8ba1\u7684\u5747\u65b9\u8bef\u5dee\uff0c\u4e3a\u4e0b\u6e38\u7b26\u53f7\u56de\u5f52\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8f68\u8ff9\u548c\u5bfc\u6570\u6570\u636e\u3002", "conclusion": "MAAT\u901a\u8fc7\u77e5\u8bc6\u5f15\u5bfc\u7684\u72b6\u6001\u91cd\u6784\uff0c\u6709\u6548\u8fde\u63a5\u4e86\u788e\u7247\u5316\u4f20\u611f\u5668\u6570\u636e\u548c\u7b26\u53f7\u56de\u5f52\uff0c\u4e3a\u4ece\u566a\u58f0\u3001\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u4e2d\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u7269\u7406\u89c4\u5f8b\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.22331", "categories": ["cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.22331", "abs": "https://arxiv.org/abs/2601.22331", "authors": ["Aditya Narayan Ravi", "Snehal Vadvalkar", "Abhishek Pandey", "Ilan Shomorony"], "title": "Scalable Batch Correction for Cell Painting via Batch-Dependent Kernels and Adaptive Sampling", "comment": "40 pages, many figures", "summary": "Cell Painting is a microscopy-based, high-content imaging assay that produces rich morphological profiles of cells and can support drug discovery by quantifying cellular responses to chemical perturbations. At scale, however, Cell Painting data is strongly affected by batch effects arising from differences in laboratories, instruments, and protocols, which can obscure biological signal. We present BALANS (Batch Alignment via Local Affinities and Subsampling), a scalable batch-correction method that aligns samples across batches by constructing a smoothed affinity matrix from pairwise distances. Given $n$ data points, BALANS builds a sparse affinity matrix $A \\in \\mathbb{R}^{n \\times n}$ using two ideas. (i) For points $i$ and $j$, it sets a local scale using the distance from $i$ to its $k$-th nearest neighbor within the batch of $j$, then computes $A_{ij}$ via a Gaussian kernel calibrated by these batch-aware local scales. (ii) Rather than forming all $n^2$ entries, BALANS uses an adaptive sampling procedure that prioritizes rows with low cumulative neighbor coverage and retains only the strongest affinities per row, yielding a sparse but informative approximation of $A$. We prove that this sampling strategy is order-optimal in sample complexity and provides an approximation guarantee, and we show that BALANS runs in nearly linear time in $n$. Experiments on diverse real-world Cell Painting datasets and controlled large-scale synthetic benchmarks demonstrate that BALANS scales to large collections while improving runtime over native implementations of widely used batch-correction methods, without sacrificing correction quality.", "AI": {"tldr": "BALANS\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6279\u6b21\u6821\u6b63\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5e73\u6ed1\u7684\u4eb2\u548c\u77e9\u9635\u6765\u5bf9\u9f50\u8de8\u6279\u6b21\u6837\u672c\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21Cell Painting\u6570\u636e\uff0c\u5728\u4fdd\u6301\u6821\u6b63\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8fd0\u884c\u6548\u7387\u3002", "motivation": "Cell Painting\u662f\u4e00\u79cd\u57fa\u4e8e\u663e\u5fae\u955c\u7684\u9ad8\u5185\u6db5\u6210\u50cf\u6280\u672f\uff0c\u80fd\u751f\u6210\u4e30\u5bcc\u7684\u7ec6\u80de\u5f62\u6001\u7279\u5f81\uff0c\u652f\u6301\u836f\u7269\u53d1\u73b0\u3002\u4f46\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\uff0c\u5b9e\u9a8c\u5ba4\u3001\u4eea\u5668\u548c\u534f\u8bae\u5dee\u5f02\u5bfc\u81f4\u7684\u6279\u6b21\u6548\u5e94\u4f1a\u63a9\u76d6\u751f\u7269\u4fe1\u53f7\uff0c\u9700\u8981\u6709\u6548\u7684\u6279\u6b21\u6821\u6b63\u65b9\u6cd5\u3002", "method": "BALANS\u901a\u8fc7\u4e24\u4e2a\u5173\u952e\u601d\u60f3\u6784\u5efa\u7a00\u758f\u4eb2\u548c\u77e9\u9635\uff1a(1) \u4f7f\u7528\u6279\u6b21\u611f\u77e5\u7684\u5c40\u90e8\u5c3a\u5ea6\u8ba1\u7b97\u9ad8\u65af\u6838\u4eb2\u548c\u5ea6\uff1b(2) \u91c7\u7528\u81ea\u9002\u5e94\u91c7\u6837\u7b56\u7565\uff0c\u4f18\u5148\u9009\u62e9\u90bb\u5c45\u8986\u76d6\u5ea6\u4f4e\u7684\u884c\uff0c\u5e76\u4fdd\u7559\u6bcf\u884c\u6700\u5f3a\u7684\u4eb2\u548c\u5ea6\uff0c\u5f62\u6210\u7a00\u758f\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u8fd1\u4f3c\u77e9\u9635\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u8be5\u91c7\u6837\u7b56\u7565\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u662f\u987a\u5e8f\u6700\u4f18\u7684\uff0c\u5e76\u63d0\u4f9b\u8fd1\u4f3c\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u8868\u660eBALANS\u80fd\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5728\u4fdd\u6301\u6821\u6b63\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u5e7f\u6cdb\u4f7f\u7528\u7684\u6279\u6b21\u6821\u6b63\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "BALANS\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u6279\u6b21\u6821\u6b63\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21Cell Painting\u6570\u636e\u5206\u6790\uff0c\u80fd\u6709\u6548\u5904\u7406\u6279\u6b21\u6548\u5e94\u800c\u4e0d\u727a\u7272\u6821\u6b63\u8d28\u91cf\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.22334", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22334", "abs": "https://arxiv.org/abs/2601.22334", "authors": ["Nikita P. Kalinin", "Ryan McKenna", "Rasmus Pagh", "Christoph H. Lampert"], "title": "DP-$\u03bb$CGD: Efficient Noise Correlation for Differentially Private Model Training", "comment": null, "summary": "Differentially private stochastic gradient descent (DP-SGD) is the gold standard for training machine learning models with formal differential privacy guarantees. Several recent extensions improve its accuracy by introducing correlated noise across training iterations. Matrix factorization mechanisms are a prominent example, but they correlate noise across many iterations and require storing previously added noise vectors, leading to substantial memory overhead in some settings. In this work, we propose a new noise correlation strategy that correlates noise only with the immediately preceding iteration and cancels a controlled portion of it. Our method relies on noise regeneration using a pseudorandom noise generator, eliminating the need to store past noise. As a result, it requires no additional memory beyond standard DP-SGD. We show that the computational overhead is minimal and empirically demonstrate improved accuracy over DP-SGD.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u566a\u58f0\u76f8\u5173\u7b56\u7565\uff0c\u4ec5\u4e0e\u524d\u4e00\u6b21\u8fed\u4ee3\u76f8\u5173\u5e76\u53d6\u6d88\u90e8\u5206\u566a\u58f0\uff0c\u65e0\u9700\u5b58\u50a8\u5386\u53f2\u566a\u58f0\uff0c\u5185\u5b58\u5f00\u9500\u4e0e\u6807\u51c6DP-SGD\u76f8\u540c", "motivation": "\u73b0\u6709\u77e9\u9635\u5206\u89e3\u673a\u5236\u7b49DP-SGD\u6269\u5c55\u65b9\u6cd5\u867d\u7136\u901a\u8fc7\u8de8\u591a\u4e2a\u8bad\u7ec3\u8fed\u4ee3\u5f15\u5165\u76f8\u5173\u566a\u58f0\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4f46\u9700\u8981\u5b58\u50a8\u5148\u524d\u6dfb\u52a0\u7684\u566a\u58f0\u5411\u91cf\uff0c\u5728\u67d0\u4e9b\u8bbe\u7f6e\u4e0b\u5bfc\u81f4\u663e\u8457\u7684\u5185\u5b58\u5f00\u9500", "method": "\u63d0\u51fa\u65b0\u7684\u566a\u58f0\u76f8\u5173\u7b56\u7565\uff0c\u4ec5\u5c06\u566a\u58f0\u4e0e\u524d\u4e00\u6b21\u8fed\u4ee3\u76f8\u5173\uff0c\u5e76\u53d6\u6d88\u53d7\u63a7\u90e8\u5206\u7684\u566a\u58f0\u3002\u8be5\u65b9\u6cd5\u4f9d\u8d56\u4f2a\u968f\u673a\u566a\u58f0\u751f\u6210\u5668\u8fdb\u884c\u566a\u58f0\u518d\u751f\uff0c\u65e0\u9700\u5b58\u50a8\u8fc7\u53bb\u7684\u566a\u58f0", "result": "\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u5185\u5b58\uff08\u4e0e\u6807\u51c6DP-SGD\u76f8\u540c\uff09\uff0c\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u76f8\u6bd4DP-SGD\u63d0\u9ad8\u4e86\u51c6\u786e\u6027", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5185\u5b58\u9ad8\u6548\u7684\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6539\u8fdb\u65b9\u6cd5\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u566a\u58f0\u76f8\u5173\u7b56\u7565\u5728\u4fdd\u6301\u4f4e\u5185\u5b58\u5f00\u9500\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027"}}
{"id": "2601.22335", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22335", "abs": "https://arxiv.org/abs/2601.22335", "authors": ["Kaiwen Wu", "Jacob R. Gardner"], "title": "Knowledge Gradient for Preference Learning", "comment": null, "summary": "The knowledge gradient is a popular acquisition function in Bayesian optimization (BO) for optimizing black-box objectives with noisy function evaluations. Many practical settings, however, allow only pairwise comparison queries, yielding a preferential BO problem where direct function evaluations are unavailable. Extending the knowledge gradient to preferential BO is hindered by its computational challenge. At its core, the look-ahead step in the preferential setting requires computing a non-Gaussian posterior, which was previously considered intractable. In this paper, we address this challenge by deriving an exact and analytical knowledge gradient for preferential BO. We show that the exact knowledge gradient performs strongly on a suite of benchmark problems, often outperforming existing acquisition functions. In addition, we also present a case study illustrating the limitation of the knowledge gradient in certain scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7cbe\u786e\u7684\u504f\u597d\u8d1d\u53f6\u65af\u4f18\u5316\u77e5\u8bc6\u68af\u5ea6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u6210\u5bf9\u6bd4\u8f83\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u8ba1\u7b97\u96be\u9898\u3002", "motivation": "\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u7684\u77e5\u8bc6\u68af\u5ea6\u65b9\u6cd5\u5728\u5904\u7406\u542b\u566a\u58f0\u7684\u9ed1\u76d2\u51fd\u6570\u4f18\u5316\u65f6\u5f88\u6d41\u884c\uff0c\u4f46\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u53ea\u5141\u8bb8\u6210\u5bf9\u6bd4\u8f83\u67e5\u8be2\uff08\u504f\u597dBO\u95ee\u9898\uff09\uff0c\u800c\u5c06\u77e5\u8bc6\u68af\u5ea6\u6269\u5c55\u5230\u504f\u597dBO\u9762\u4e34\u8ba1\u7b97\u6311\u6218\uff0c\u56e0\u4e3a\u524d\u77bb\u6b65\u9aa4\u9700\u8981\u8ba1\u7b97\u975e\u9ad8\u65af\u540e\u9a8c\u5206\u5e03\uff0c\u4e4b\u524d\u88ab\u8ba4\u4e3a\u96be\u4ee5\u5904\u7406\u3002", "method": "\u63a8\u5bfc\u51fa\u7cbe\u786e\u4e14\u89e3\u6790\u7684\u504f\u597d\u8d1d\u53f6\u65af\u4f18\u5316\u77e5\u8bc6\u68af\u5ea6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u975e\u9ad8\u65af\u540e\u9a8c\u5206\u5e03\u7684\u8ba1\u7b97\u96be\u9898\u3002", "result": "\u7cbe\u786e\u77e5\u8bc6\u68af\u5ea6\u5728\u4e00\u7cfb\u5217\u57fa\u51c6\u95ee\u9898\u4e0a\u8868\u73b0\u5f3a\u52b2\uff0c\u901a\u5e38\u4f18\u4e8e\u73b0\u6709\u7684\u91c7\u96c6\u51fd\u6570\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u77e5\u8bc6\u68af\u5ea6\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86\u504f\u597d\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u77e5\u8bc6\u68af\u5ea6\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u6709\u6548\u7684\u7cbe\u786e\u65b9\u6cd5\uff0c\u4f46\u4e5f\u6307\u51fa\u4e86\u8be5\u65b9\u6cd5\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.22345", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22345", "abs": "https://arxiv.org/abs/2601.22345", "authors": ["Mahdi JafariRaviz", "Keivan Rezaei", "Arshia Soltani Moakhar", "Zahra Sodagar", "Yize Cheng", "Soheil Feizi"], "title": "Failing to Explore: Language Models on Interactive Tasks", "comment": null, "summary": "We evaluate language models on their ability to explore interactive environments under a limited interaction budget. We introduce three parametric tasks with controllable exploration difficulty, spanning continuous and discrete environments. Across state-of-the-art models, we find systematic under-exploration and suboptimal solutions, with performance often significantly worse than simple explore--exploit heuristic baselines and scaling weakly as the budget increases. Finally, we study two lightweight interventions: splitting a fixed budget into parallel executions, which surprisingly improves performance despite a no-gain theoretical result for our tasks, and periodically summarizing the interaction history, which preserves key discoveries and further improves exploration.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u6709\u9650\u4ea4\u4e92\u9884\u7b97\u4e0b\u63a2\u7d22\u4ea4\u4e92\u73af\u5883\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u63a2\u7d22\u4e0d\u8db3\u548c\u6b21\u4f18\u89e3\u95ee\u9898\uff0c\u6027\u80fd\u751a\u81f3\u4e0d\u5982\u7b80\u5355\u7684\u63a2\u7d22-\u5229\u7528\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u6709\u9650\u4ea4\u4e92\u9884\u7b97\u4e0b\u63a2\u7d22\u4ea4\u4e92\u73af\u5883\u7684\u80fd\u529b\uff0c\u4e86\u89e3\u5f53\u524d\u6a21\u578b\u5728\u63a2\u7d22\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u548c\u5c40\u9650\u6027\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5f15\u5165\u4e09\u4e2a\u53c2\u6570\u5316\u4efb\u52a1\uff0c\u63a7\u5236\u63a2\u7d22\u96be\u5ea6\uff0c\u6db5\u76d6\u8fde\u7eed\u548c\u79bb\u6563\u73af\u5883\uff1b2\uff09\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\uff1b3\uff09\u7814\u7a76\u4e24\u79cd\u8f7b\u91cf\u7ea7\u5e72\u9884\u63aa\u65bd\uff1a\u5c06\u56fa\u5b9a\u9884\u7b97\u5206\u5272\u4e3a\u5e76\u884c\u6267\u884c\uff0c\u4ee5\u53ca\u5b9a\u671f\u603b\u7ed3\u4ea4\u4e92\u5386\u53f2\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff1a1\uff09\u73b0\u6709\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u63a2\u7d22\u4e0d\u8db3\u548c\u6b21\u4f18\u89e3\u95ee\u9898\uff1b2\uff09\u6027\u80fd\u901a\u5e38\u663e\u8457\u4f4e\u4e8e\u7b80\u5355\u7684\u63a2\u7d22-\u5229\u7528\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff1b3\uff09\u968f\u7740\u9884\u7b97\u589e\u52a0\uff0c\u6027\u80fd\u63d0\u5347\u5fae\u5f31\uff1b4\uff09\u5e76\u884c\u6267\u884c\u9884\u7b97\u80fd\u610f\u5916\u63d0\u9ad8\u6027\u80fd\uff1b5\uff09\u5b9a\u671f\u603b\u7ed3\u4ea4\u4e92\u5386\u53f2\u80fd\u4fdd\u7559\u5173\u952e\u53d1\u73b0\u5e76\u8fdb\u4e00\u6b65\u6539\u5584\u63a2\u7d22\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u63a2\u7d22\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u4f46\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5e72\u9884\u63aa\u65bd\uff08\u5982\u9884\u7b97\u5206\u5272\u548c\u4ea4\u4e92\u5386\u53f2\u603b\u7ed3\uff09\u53ef\u4ee5\u6539\u5584\u63a2\u7d22\u6027\u80fd\uff0c\u8fd9\u4e3a\u672a\u6765\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u63a2\u7d22\u80fd\u529b\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.22355", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22355", "abs": "https://arxiv.org/abs/2601.22355", "authors": ["Binshuai Wang", "Peng Wei"], "title": "Relative Wasserstein Angle and the Problem of the $W_2$-Nearest Gaussian Distribution", "comment": null, "summary": "We study the problem of quantifying how far an empirical distribution deviates from Gaussianity under the framework of optimal transport. By exploiting the cone geometry of the relative translation invariant quadratic Wasserstein space, we introduce two novel geometric quantities, the relative Wasserstein angle and the orthogonal projection distance, which provide meaningful measures of non-Gaussianity. We prove that the filling cone generated by any two rays in this space is flat, ensuring that angles, projections, and inner products are rigorously well-defined. This geometric viewpoint recasts Gaussian approximation as a projection problem onto the Gaussian cone and reveals that the commonly used moment-matching Gaussian can \\emph{not} be the \\(W_2\\)-nearest Gaussian for a given empirical distribution. In one dimension, we derive closed-form expressions for the proposed quantities and extend them to several classical distribution families, including uniform, Laplace, and logistic distributions; while in high dimensions, we develop an efficient stochastic manifold optimization algorithm based on a semi-discrete dual formulation. Experiments on synthetic data and real-world feature distributions demonstrate that the relative Wasserstein angle is more robust than the Wasserstein distance and that the proposed nearest Gaussian provides a better approximation than moment matching in the evaluation of Fr\u00e9chet Inception Distance (FID) scores.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7406\u8bba\uff0c\u5229\u7528\u76f8\u5bf9\u5e73\u79fb\u4e0d\u53d8\u4e8c\u6b21Wasserstein\u7a7a\u95f4\u7684\u9525\u51e0\u4f55\u7ed3\u6784\uff0c\u5f15\u5165\u76f8\u5bf9Wasserstein\u89d2\u548c\u6b63\u4ea4\u6295\u5f71\u8ddd\u79bb\u4e24\u4e2a\u65b0\u51e0\u4f55\u91cf\u6765\u8861\u91cf\u7ecf\u9a8c\u5206\u5e03\u4e0e\u9ad8\u65af\u5206\u5e03\u4e4b\u95f4\u7684\u504f\u5dee\uff0c\u5e76\u8bc1\u660e\u8be5\u7a7a\u95f4\u4e2d\u7684\u586b\u5145\u9525\u662f\u5e73\u5766\u7684\uff0c\u4ece\u800c\u786e\u4fdd\u89d2\u5ea6\u3001\u6295\u5f71\u548c\u5185\u79ef\u7684\u4e25\u683c\u5b9a\u4e49\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u91cf\u5316\u7ecf\u9a8c\u5206\u5e03\u4e0e\u9ad8\u65af\u5206\u5e03\u4e4b\u95f4\u7684\u504f\u5dee\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u3002\u4f5c\u8005\u5e0c\u671b\u4ece\u51e0\u4f55\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u9ad8\u65af\u8fd1\u4f3c\u95ee\u9898\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u9ad8\u65af\u9525\u4e0a\u7684\u6295\u5f71\u95ee\u9898\uff0c\u5e76\u53d1\u73b0\u5e38\u7528\u7684\u77e9\u5339\u914d\u9ad8\u65af\u65b9\u6cd5\u5e76\u975e\u7ed9\u5b9a\u7ecf\u9a8c\u5206\u5e03\u7684Wasserstein\u6700\u8fd1\u9ad8\u65af\u5206\u5e03\u3002", "method": "1. \u5229\u7528\u76f8\u5bf9\u5e73\u79fb\u4e0d\u53d8\u4e8c\u6b21Wasserstein\u7a7a\u95f4\u7684\u9525\u51e0\u4f55\u7ed3\u6784\uff0c\u5f15\u5165\u76f8\u5bf9Wasserstein\u89d2\u548c\u6b63\u4ea4\u6295\u5f71\u8ddd\u79bb\u4e24\u4e2a\u65b0\u51e0\u4f55\u91cf\uff1b2. \u8bc1\u660e\u8be5\u7a7a\u95f4\u4e2d\u7684\u586b\u5145\u9525\u662f\u5e73\u5766\u7684\uff0c\u786e\u4fdd\u89d2\u5ea6\u3001\u6295\u5f71\u548c\u5185\u79ef\u7684\u4e25\u683c\u5b9a\u4e49\uff1b3. \u5728\u4e00\u7ef4\u60c5\u51b5\u4e0b\u63a8\u5bfc\u51fa\u95ed\u5f0f\u8868\u8fbe\u5f0f\u5e76\u6269\u5c55\u5230\u7ecf\u5178\u5206\u5e03\u65cf\uff1b4. \u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u5f00\u53d1\u57fa\u4e8e\u534a\u79bb\u6563\u5bf9\u5076\u516c\u5f0f\u7684\u9ad8\u6548\u968f\u673a\u6d41\u5f62\u4f18\u5316\u7b97\u6cd5\u3002", "result": "1. \u8bc1\u660e\u4e86\u76f8\u5bf9Wasserstein\u89d2\u6bd4Wasserstein\u8ddd\u79bb\u66f4\u9c81\u68d2\uff1b2. \u63d0\u51fa\u7684\u6700\u8fd1\u9ad8\u65af\u5206\u5e03\u6bd4\u77e9\u5339\u914d\u65b9\u6cd5\u5728Fr\u00e9chet Inception Distance\uff08FID\uff09\u5206\u6570\u8bc4\u4f30\u4e2d\u63d0\u4f9b\u66f4\u597d\u7684\u8fd1\u4f3c\uff1b3. \u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u7279\u5f81\u5206\u5e03\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ece\u51e0\u4f55\u89d2\u5ea6\u91cd\u65b0\u6784\u5efa\u4e86\u9ad8\u65af\u8fd1\u4f3c\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u76f8\u5bf9Wasserstein\u89d2\u548c\u6b63\u4ea4\u6295\u5f71\u8ddd\u79bb\u4e3a\u91cf\u5316\u975e\u9ad8\u65af\u6027\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u5ea6\u91cf\u3002\u65b9\u6cd5\u4e0d\u4ec5\u5728\u4e00\u7ef4\u60c5\u51b5\u4e0b\u6709\u95ed\u5f0f\u89e3\uff0c\u8fd8\u80fd\u901a\u8fc7\u9ad8\u6548\u7b97\u6cd5\u6269\u5c55\u5230\u9ad8\u7ef4\uff0c\u4e3a\u5206\u5e03\u5206\u6790\u548c\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2601.22362", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22362", "abs": "https://arxiv.org/abs/2601.22362", "authors": ["Julien Delavande", "Regis Pierrard", "Sasha Luccioni"], "title": "Understanding Efficiency: Quantization, Batching, and Serving Strategies in LLM Energy Use", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in production, contributing towards shifting the burden in terms of computational resources and energy demands from training to inference. While prior work has examined the energy cost of inference per prompt or per token, we highlight how \\emph{system-level design choices} - such as numerical precision, batching strategy, and request scheduling - can lead to orders-of-magnitude differences in energy consumption for the same model. We perform a detailed empirical study of LLM inference energy and latency on NVIDIA H100 GPUs, analyzing the impact of quantization, batch size, and serving configuration (e.g., with Hugging Face's Text Generation Inference server). Our results reveal that lower-precision formats only yield energy gains in compute-bound regimes; that batching improves energy efficiency, especially in memory-bound phases like decoding; and that structured request timing (arrival shaping) can reduce per-request energy by up to 100 times. We argue that sustainable LLM deployment depends not only on model internals, but also on the orchestration of the serving stack. Our findings motivate phase-aware energy profiling and system-level optimizations for greener AI services.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u63a8\u7406\u9636\u6bb5\u7684\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u9009\u62e9\u5bf9\u80fd\u8017\u7684\u663e\u8457\u5f71\u54cd\uff0c\u53d1\u73b0\u91cf\u5316\u3001\u6279\u5904\u7406\u548c\u8bf7\u6c42\u8c03\u5ea6\u7b49\u7b56\u7565\u53ef\u4ee5\u5e26\u6765\u6570\u91cf\u7ea7\u7684\u80fd\u8017\u5dee\u5f02", "motivation": "\u968f\u7740LLM\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u8ba1\u7b97\u8d44\u6e90\u548c\u80fd\u6e90\u9700\u6c42\u4ece\u8bad\u7ec3\u8f6c\u5411\u63a8\u7406\u9636\u6bb5\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6bcf\u4e2a\u63d0\u793a\u6216\u6bcf\u4e2a\u4ee4\u724c\u7684\u80fd\u8017\uff0c\u4f46\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u9009\u62e9\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76", "method": "\u5728NVIDIA H100 GPU\u4e0a\u8fdb\u884c\u8be6\u7ec6\u7684LLM\u63a8\u7406\u80fd\u8017\u548c\u5ef6\u8fdf\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u91cf\u5316\u3001\u6279\u5904\u7406\u5927\u5c0f\u548c\u670d\u52a1\u914d\u7f6e\uff08\u5982Hugging Face\u7684Text Generation Inference\u670d\u52a1\u5668\uff09\u7684\u5f71\u54cd", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u4f4e\u7cbe\u5ea6\u683c\u5f0f\u4ec5\u5728\u8ba1\u7b97\u53d7\u9650\u573a\u666f\u4e0b\u5e26\u6765\u80fd\u8017\u6536\u76ca\uff1b\u6279\u5904\u7406\u63d0\u9ad8\u80fd\u6548\uff0c\u7279\u522b\u662f\u5728\u89e3\u7801\u7b49\u5185\u5b58\u53d7\u9650\u9636\u6bb5\uff1b\u7ed3\u6784\u5316\u8bf7\u6c42\u5b9a\u65f6\uff08\u5230\u8fbe\u6574\u5f62\uff09\u53ef\u5c06\u6bcf\u4e2a\u8bf7\u6c42\u7684\u80fd\u8017\u964d\u4f4e\u9ad8\u8fbe100\u500d", "conclusion": "\u53ef\u6301\u7eed\u7684LLM\u90e8\u7f72\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u6a21\u578b\u5185\u90e8\uff0c\u8fd8\u53d6\u51b3\u4e8e\u670d\u52a1\u5806\u6808\u7684\u7f16\u6392\u3002\u7814\u7a76\u7ed3\u679c\u652f\u6301\u57fa\u4e8e\u9636\u6bb5\u7684\u80fd\u8017\u5206\u6790\u548c\u7cfb\u7edf\u7ea7\u4f18\u5316\uff0c\u4ee5\u5b9e\u73b0\u66f4\u73af\u4fdd\u7684AI\u670d\u52a1"}}
{"id": "2601.22371", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22371", "abs": "https://arxiv.org/abs/2601.22371", "authors": ["Rosen Ting-Ying Yu", "Nicholas Sung", "Faez Ahmed"], "title": "FIRE: Multi-fidelity Regression with Distribution-conditioned In-context Learning using Tabular Foundation Models", "comment": null, "summary": "Multi-fidelity (MF) regression often operates in regimes of extreme data imbalance, where the commonly-used Gaussian-process (GP) surrogates struggle with cubic scaling costs and overfit to sparse high-fidelity observations, limiting efficiency and generalization in real-world applications. We introduce FIRE, a training-free MF framework that couples tabular foundation models (TFMs) to perform zero-shot in-context Bayesian inference via a high-fidelity correction model conditioned on the low-fidelity model's posterior predictive distributions. This cross-fidelity information transfer via distributional summaries captures heteroscedastic errors, enabling robust residual learning without model retraining. Across 31 benchmark problems spanning synthetic and real-world tasks (e.g., DrivAerNet, LCBench), FIRE delivers a stronger performance-time trade-off than seven state-of-the-art GP-based or deep learning MF regression methods, ranking highest in accuracy and uncertainty quantification with runtime advantages. Limitations include context window constraints and dependence on the quality of the pre-trained TFM's.", "AI": {"tldr": "FIRE\u662f\u4e00\u4e2a\u514d\u8bad\u7ec3\u7684\u591a\u4fdd\u771f\u5ea6\u56de\u5f52\u6846\u67b6\uff0c\u4f7f\u7528\u8868\u683c\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u4e0a\u4e0b\u6587\u8d1d\u53f6\u65af\u63a8\u7406\uff0c\u901a\u8fc7\u9ad8\u4f4e\u4fdd\u771f\u6a21\u578b\u7684\u540e\u9a8c\u9884\u6d4b\u5206\u5e03\u5b9e\u73b0\u8de8\u4fdd\u771f\u5ea6\u4fe1\u606f\u4f20\u9012\uff0c\u572831\u4e2a\u57fa\u51c6\u95ee\u9898\u4e0a\u4f18\u4e8e7\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u9ad8\u65af\u8fc7\u7a0b\u591a\u4fdd\u771f\u5ea6\u56de\u5f52\u9762\u4e34\u7acb\u65b9\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u5bf9\u7a00\u758f\u9ad8\u4fdd\u771f\u89c2\u6d4b\u8fc7\u62df\u5408\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "FIRE\u6846\u67b6\u8026\u5408\u8868\u683c\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u4f4e\u4fdd\u771f\u6a21\u578b\u7684\u540e\u9a8c\u9884\u6d4b\u5206\u5e03\u4f5c\u4e3a\u6761\u4ef6\uff0c\u6784\u5efa\u9ad8\u4fdd\u771f\u6821\u6b63\u6a21\u578b\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u4e0a\u4e0b\u6587\u8d1d\u53f6\u65af\u63a8\u7406\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6355\u83b7\u5f02\u65b9\u5dee\u8bef\u5dee\u3002", "result": "\u572831\u4e2a\u5408\u6210\u548c\u5b9e\u9645\u57fa\u51c6\u95ee\u9898\uff08\u5982DrivAerNet\u3001LCBench\uff09\u4e0a\uff0cFIRE\u5728\u6027\u80fd-\u65f6\u95f4\u6743\u8861\u65b9\u9762\u4f18\u4e8e7\u79cd\u6700\u5148\u8fdb\u7684GP\u6216\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u6392\u540d\u6700\u9ad8\uff0c\u5177\u6709\u8fd0\u884c\u65f6\u4f18\u52bf\u3002", "conclusion": "FIRE\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u4fdd\u771f\u5ea6\u56de\u5f52\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u8868\u683c\u57fa\u7840\u6a21\u578b\u5b9e\u73b0\u514d\u8bad\u7ec3\u7684\u8de8\u4fdd\u771f\u5ea6\u4fe1\u606f\u4f20\u9012\uff0c\u4f46\u5b58\u5728\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u4f9d\u8d56\u9884\u8bad\u7ec3\u6a21\u578b\u8d28\u91cf\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.22397", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22397", "abs": "https://arxiv.org/abs/2601.22397", "authors": ["Jianchang Su", "Yifan Zhang", "Shengkai Lin", "Shizhen Zhao", "Yusheng Zheng", "Yiwei Yang", "Wei Zhang"], "title": "SAIR: Cost-Efficient Multi-Stage ML Pipeline Autoscaling via In-Context Reinforcement Learning", "comment": null, "summary": "Multi-stage ML inference pipelines are difficult to autoscale due to heterogeneous resources, cross-stage coupling, and dynamic bottleneck migration. We present SAIR, an autoscaling framework that uses an LLM as an in-context reinforcement learning controller, improving its policy online from reward-labeled interaction histories without gradient updates. SAIR combines Pareto-dominance reward shaping with a provable separation margin, surprisal-guided experience retrieval for context efficiency, and fine-grained GPU rate control via user-space CUDA interception. We provide regret analysis decomposing error into retrieval coverage and LLM selection components. On four ML serving pipelines under three workload patterns, SAIR achieves the best or tied-best P99 latency and effective resource cost among deployed baselines, improving P99 by up to 50% and reducing effective cost by up to 97% (under GPU rate-control assumptions), with 86% bottleneck detection accuracy and no offline training.", "AI": {"tldr": "SAIR\u662f\u4e00\u4e2a\u4f7f\u7528LLM\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u7684\u81ea\u52a8\u6269\u7f29\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u591a\u9636\u6bb5ML\u63a8\u7406\u7ba1\u9053\u7684\u8d44\u6e90\u5206\u914d\uff0c\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\u5373\u53ef\u5728\u7ebf\u6539\u8fdb\u7b56\u7565\u3002", "motivation": "\u591a\u9636\u6bb5ML\u63a8\u7406\u7ba1\u9053\u7531\u4e8e\u5f02\u6784\u8d44\u6e90\u3001\u8de8\u9636\u6bb5\u8026\u5408\u548c\u52a8\u6001\u74f6\u9888\u8fc1\u79fb\u800c\u96be\u4ee5\u81ea\u52a8\u6269\u7f29\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u667a\u80fd\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\u3002", "method": "SAIR\u7ed3\u5408\u4e86\u5e15\u7d2f\u6258\u4f18\u52bf\u5956\u52b1\u5851\u9020\u4e0e\u53ef\u8bc1\u660e\u7684\u5206\u79bb\u8fb9\u754c\u3001\u57fa\u4e8e\u610f\u5916\u5ea6\u7684\u7ecf\u9a8c\u68c0\u7d22\u4ee5\u63d0\u9ad8\u4e0a\u4e0b\u6587\u6548\u7387\uff0c\u4ee5\u53ca\u901a\u8fc7\u7528\u6237\u7a7a\u95f4CUDA\u62e6\u622a\u5b9e\u73b0\u7684\u7ec6\u7c92\u5ea6GPU\u901f\u7387\u63a7\u5236\u3002", "result": "\u5728\u56db\u79cdML\u670d\u52a1\u7ba1\u9053\u548c\u4e09\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u6a21\u5f0f\u4e0b\uff0cSAIR\u5728P99\u5ef6\u8fdf\u548c\u6709\u6548\u8d44\u6e90\u6210\u672c\u65b9\u9762\u8fbe\u5230\u6700\u4f73\u6216\u5e76\u5217\u6700\u4f73\uff0c\u5c06P99\u5ef6\u8fdf\u63d0\u5347\u9ad8\u8fbe50%\uff0c\u6709\u6548\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe97%\uff0c\u74f6\u9888\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u523086%\uff0c\u4e14\u65e0\u9700\u79bb\u7ebf\u8bad\u7ec3\u3002", "conclusion": "SAIR\u901a\u8fc7LLM\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u9636\u6bb5ML\u63a8\u7406\u7ba1\u9053\u7684\u81ea\u52a8\u6269\u7f29\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8d44\u6e90\u7ba1\u7406\u548c\u6027\u80fd\u4f18\u5316\u3002"}}
{"id": "2601.22416", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22416", "abs": "https://arxiv.org/abs/2601.22416", "authors": ["Xunkai Li", "Yuming Ai", "Yinlin Zhu", "Haodong Lu", "Yi Zhang", "Guohao Fu", "Bowen Fan", "Qiangqiang Dai", "Rong-Hua Li", "Guoren Wang"], "title": "MM-OpenFGL: A Comprehensive Benchmark for Multimodal Federated Graph Learning", "comment": "Under Review", "summary": "Multimodal-attributed graphs (MMAGs) provide a unified framework for modeling complex relational data by integrating heterogeneous modalities with graph structures. While centralized learning has shown promising performance, MMAGs in real-world applications are often distributed across isolated platforms and cannot be shared due to privacy concerns or commercial constraints. Federated graph learning (FGL) offers a natural solution for collaborative training under such settings; however, existing studies largely focus on single-modality graphs and do not adequately address the challenges unique to multimodal federated graph learning (MMFGL). To bridge this gap, we present MM-OpenFGL, the first comprehensive benchmark that systematically formalizes the MMFGL paradigm and enables rigorous evaluation. MM-OpenFGL comprises 19 multimodal datasets spanning 7 application domains, 8 simulation strategies capturing modality and topology variations, 6 downstream tasks, and 57 state-of-the-art methods implemented through a modular API. Extensive experiments investigate MMFGL from the perspectives of necessity, effectiveness, robustness, and efficiency, offering valuable insights for future research on MMFGL.", "AI": {"tldr": "MM-OpenFGL\u662f\u9996\u4e2a\u9488\u5bf9\u591a\u6a21\u6001\u8054\u90a6\u56fe\u5b66\u4e60\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u5305\u542b19\u4e2a\u6570\u636e\u96c6\u30018\u79cd\u6a21\u62df\u7b56\u7565\u30016\u4e2a\u4e0b\u6e38\u4efb\u52a1\u548c57\u79cdSOTA\u65b9\u6cd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86MMFGL\u7684\u5fc5\u8981\u6027\u3001\u6709\u6548\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u591a\u6a21\u6001\u5c5e\u6027\u56fe\u901a\u5e38\u5206\u5e03\u5728\u9694\u79bb\u5e73\u53f0\u4e0a\uff0c\u7531\u4e8e\u9690\u79c1\u6216\u5546\u4e1a\u9650\u5236\u65e0\u6cd5\u5171\u4eab\uff0c\u800c\u73b0\u6709\u7684\u8054\u90a6\u56fe\u5b66\u4e60\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u6a21\u6001\u56fe\uff0c\u7f3a\u4e4f\u9488\u5bf9\u591a\u6a21\u6001\u8054\u90a6\u56fe\u5b66\u4e60\u7684\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86MM-OpenFGL\u57fa\u51c6\uff0c\u7cfb\u7edf\u5316\u5730\u5f62\u5f0f\u5316\u4e86MMFGL\u8303\u5f0f\uff0c\u5305\u542b19\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08\u8986\u76d67\u4e2a\u5e94\u7528\u9886\u57df\uff09\u30018\u79cd\u6a21\u62df\u7b56\u7565\uff08\u6355\u6349\u6a21\u6001\u548c\u62d3\u6251\u53d8\u5316\uff09\u30016\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u6a21\u5757\u5316API\u5b9e\u73b0\u4e8657\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u4ece\u5fc5\u8981\u6027\u3001\u6709\u6548\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u56db\u4e2a\u89d2\u5ea6\u5168\u9762\u7814\u7a76\u4e86MMFGL\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "MM-OpenFGL\u586b\u8865\u4e86\u591a\u6a21\u6001\u8054\u90a6\u56fe\u5b66\u4e60\u9886\u57df\u7684\u8bc4\u4f30\u7a7a\u767d\uff0c\u4e3a\u7cfb\u7edf\u7814\u7a76\u548c\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9996\u4e2a\u7efc\u5408\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.22432", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22432", "abs": "https://arxiv.org/abs/2601.22432", "authors": ["Wenzheng Zhang", "Karl Stratos"], "title": "ReNCE: Learning to Reason by Noise Contrastive Estimation", "comment": null, "summary": "GRPO is a standard approach to endowing pretrained LLMs with reasoning capabilities. It estimates the advantage of an outcome from a group of $K$ outcomes, and promotes those with positive advantages inside a trust region. Since GRPO discriminates between good and bad outcomes softly, it benefits from additional refinements such as asymmetric clipping and zero-variance data filtering. While effective, these refinements require significant empirical insight and can be challenging to identify. We instead propose an explicit contrastive learning approach. Instead of estimating advantages, we bifurcate $K$ outcomes into positive and negative sets, then maximize the likelihood of positive outcomes. Our approach can be viewed as an online instantiation of (multi-label) noise contrastive estimation for LLM reasoning. We validate our method by demonstrating competitive performance on a suite of challenging math benchmarks against strong baselines such as DAPO and online DPO.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u663e\u5f0f\u5bf9\u6bd4\u5b66\u4e60\u7684LLM\u63a8\u7406\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684GRPO\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7ed3\u679c\u5206\u4e3a\u6b63\u8d1f\u96c6\u6765\u6700\u5927\u5316\u6b63\u7ed3\u679c\u6982\u7387", "motivation": "GRPO\u65b9\u6cd5\u867d\u7136\u6709\u6548\uff0c\u4f46\u9700\u8981\u590d\u6742\u7684\u7ecf\u9a8c\u6027\u8c03\u6574\uff08\u5982\u975e\u5bf9\u79f0\u88c1\u526a\u548c\u96f6\u65b9\u5dee\u6570\u636e\u8fc7\u6ee4\uff09\uff0c\u8fd9\u4e9b\u8c03\u6574\u96be\u4ee5\u8bc6\u522b\u4e14\u9700\u8981\u5927\u91cf\u7ecf\u9a8c\u6d1e\u5bdf", "method": "\u63d0\u51fa\u663e\u5f0f\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff1a\u5c06K\u4e2a\u7ed3\u679c\u5206\u4e3a\u6b63\u8d1f\u4e24\u4e2a\u96c6\u5408\uff0c\u7136\u540e\u6700\u5927\u5316\u6b63\u7ed3\u679c\u7684\u4f3c\u7136\u6982\u7387\uff1b\u8be5\u65b9\u6cd5\u53ef\u89c6\u4e3aLLM\u63a8\u7406\u4e2d\uff08\u591a\u6807\u7b7e\uff09\u566a\u58f0\u5bf9\u6bd4\u4f30\u8ba1\u7684\u5728\u7ebf\u5b9e\u4f8b\u5316", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0eDAPO\u548c\u5728\u7ebfDPO\u7b49\u5f3a\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8868\u73b0\u51fa\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u663e\u5f0f\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u76f4\u63a5\u3001\u66f4\u6613\u4e8e\u5b9e\u73b0\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u907f\u514d\u4e86GRPO\u6240\u9700\u7684\u590d\u6742\u7ecf\u9a8c\u8c03\u6574\uff0c\u540c\u65f6\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4fdd\u6301\u7ade\u4e89\u529b"}}
{"id": "2601.22447", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22447", "abs": "https://arxiv.org/abs/2601.22447", "authors": ["Yiting Liu", "Zhi-Hong Deng"], "title": "Beyond Activation Patterns: A Weight-Based Out-of-Context Explanation of Sparse Autoencoder Features", "comment": null, "summary": "Sparse autoencoders (SAEs) have emerged as a powerful technique for decomposing language model representations into interpretable features. Current interpretation methods infer feature semantics from activation patterns, but overlook that features are trained to reconstruct activations that serve computational roles in the forward pass. We introduce a novel weight-based interpretation framework that measures functional effects through direct weight interactions, requiring no activation data. Through three experiments on Gemma-2 and Llama-3.1 models, we demonstrate that (1) 1/4 of features directly predict output tokens, (2) features actively participate in attention mechanisms with depth-dependent structure, and (3) semantic and non-semantic feature populations exhibit distinct distribution profiles in attention circuits. Our analysis provides the missing out-of-context half of SAE feature interpretability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6743\u91cd\u7684SAE\u7279\u5f81\u89e3\u91ca\u6846\u67b6\uff0c\u65e0\u9700\u6fc0\u6d3b\u6570\u636e\uff0c\u901a\u8fc7\u76f4\u63a5\u6743\u91cd\u4ea4\u4e92\u6d4b\u91cf\u529f\u80fd\u6548\u5e94\uff0c\u53d1\u73b01/4\u7279\u5f81\u76f4\u63a5\u9884\u6d4b\u8f93\u51fatoken\uff0c\u7279\u5f81\u5728\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5177\u6709\u6df1\u5ea6\u4f9d\u8d56\u7ed3\u6784\uff0c\u8bed\u4e49\u4e0e\u975e\u8bed\u4e49\u7279\u5f81\u5728\u6ce8\u610f\u529b\u7535\u8def\u4e2d\u5206\u5e03\u4e0d\u540c", "motivation": "\u5f53\u524d\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u7279\u5f81\u89e3\u91ca\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u6fc0\u6d3b\u6a21\u5f0f\u63a8\u65ad\u7279\u5f81\u8bed\u4e49\uff0c\u4f46\u5ffd\u7565\u4e86\u8fd9\u4e9b\u7279\u5f81\u8bad\u7ec3\u7684\u76ee\u7684\u662f\u91cd\u6784\u5728\u524d\u5411\u4f20\u64ad\u4e2d\u5177\u6709\u8ba1\u7b97\u529f\u80fd\u7684\u6fc0\u6d3b\u3002\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u91ca\u6846\u67b6\u6765\u7406\u89e3SAE\u7279\u5f81\u7684\u5b9e\u9645\u529f\u80fd\u4f5c\u7528", "method": "\u5f15\u5165\u57fa\u4e8e\u6743\u91cd\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u901a\u8fc7\u76f4\u63a5\u6743\u91cd\u4ea4\u4e92\u6d4b\u91cf\u529f\u80fd\u6548\u5e94\uff0c\u65e0\u9700\u6fc0\u6d3b\u6570\u636e\u3002\u5728Gemma-2\u548cLlama-3.1\u6a21\u578b\u4e0a\u8fdb\u884c\u4e09\u4e2a\u5b9e\u9a8c\uff1a1\uff09\u5206\u6790\u7279\u5f81\u76f4\u63a5\u9884\u6d4b\u8f93\u51fatoken\u7684\u80fd\u529b\uff1b2\uff09\u7814\u7a76\u7279\u5f81\u5728\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u53c2\u4e0e\u6a21\u5f0f\uff1b3\uff09\u6bd4\u8f83\u8bed\u4e49\u548c\u975e\u8bed\u4e49\u7279\u5f81\u5728\u6ce8\u610f\u529b\u7535\u8def\u4e2d\u7684\u5206\u5e03\u7279\u5f81", "result": "1\uff09\u7ea61/4\u7684SAE\u7279\u5f81\u76f4\u63a5\u9884\u6d4b\u8f93\u51fatoken\uff1b2\uff09\u7279\u5f81\u5728\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u79ef\u6781\u53c2\u4e0e\uff0c\u5177\u6709\u6df1\u5ea6\u4f9d\u8d56\u7684\u7ed3\u6784\u6a21\u5f0f\uff1b3\uff09\u8bed\u4e49\u7279\u5f81\u548c\u975e\u8bed\u4e49\u7279\u5f81\u5728\u6ce8\u610f\u529b\u7535\u8def\u4e2d\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u5206\u5e03\u7279\u5f81", "conclusion": "\u8be5\u6743\u91cd\u57fa\u7840\u89e3\u91ca\u6846\u67b6\u63d0\u4f9b\u4e86SAE\u7279\u5f81\u89e3\u91ca\u4e2d\u7f3a\u5931\u7684\"\u4e0a\u4e0b\u6587\u5916\"\u90e8\u5206\uff0c\u63ed\u793a\u4e86\u7279\u5f81\u901a\u8fc7\u6743\u91cd\u4ea4\u4e92\u5b9e\u73b0\u7684\u5b9e\u9645\u8ba1\u7b97\u529f\u80fd\uff0c\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8868\u793a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2"}}
{"id": "2601.22448", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22448", "abs": "https://arxiv.org/abs/2601.22448", "authors": ["Weiqi Wang", "Xin Liu", "Binxuan Huang", "Hejie Cui", "Rongzhi Zhang", "Changlong Yu", "Shuowei Jin", "Jingfeng Yang", "Qingyu Yin", "Zhengyang Wang", "Zheng Li", "Yifan Gao", "Priyanka Nigam", "Bing Yin", "Lihong Li", "Yangqiu Song"], "title": "HeaPA: Difficulty-Aware Heap Sampling and On-Policy Query Augmentation for LLM Reinforcement Learning", "comment": null, "summary": "RLVR is now a standard way to train LLMs on reasoning tasks with verifiable outcomes, but when rollout generation dominates the cost, efficiency depends heavily on which prompts you sample and when. In practice, prompt pools are often static or only loosely tied to the model's learning progress, so uniform sampling can't keep up with the shifting capability frontier and ends up wasting rollouts on prompts that are already solved or still out of reach. Existing approaches improve efficiency through filtering, curricula, adaptive rollout allocation, or teacher guidance, but they typically assume a fixed pool-which makes it hard to support stable on-policy pool growth-or they add extra teacher cost and latency. We introduce HeaPA (Heap Sampling and On-Policy Query Augmentation), which maintains a bounded, evolving pool, tracks the frontier using heap-based boundary sampling, expands the pool via on-policy augmentation with lightweight asynchronous validation, and stabilizes correlated queries through topology-aware re-estimation of pool statistics and controlled reinsertion. Across two training corpora, two training recipes, and seven benchmarks, HeaPA consistently improves accuracy and reaches target performance with fewer computations while keeping wall-clock time comparable. Our analyses suggest these gains come from frontier-focused sampling and on-policy pool growth, with the benefits becoming larger as model scale increases. Our code is available at https://github.com/horizon-rl/HeaPA.", "AI": {"tldr": "HeaPA\u662f\u4e00\u79cd\u7528\u4e8eRLVR\u8bad\u7ec3\u7684\u9ad8\u6548\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u5806\u91c7\u6837\u548c\u5728\u7ebf\u67e5\u8be2\u589e\u5f3a\u6765\u4f18\u5316\u63d0\u793a\u6c60\u7ba1\u7406\uff0c\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524dRLVR\u8bad\u7ec3\u4e2d\uff0c\u63d0\u793a\u6c60\u901a\u5e38\u662f\u9759\u6001\u7684\u6216\u4e0e\u6a21\u578b\u5b66\u4e60\u8fdb\u5ea6\u677e\u6563\u5173\u8054\uff0c\u5747\u5300\u91c7\u6837\u65e0\u6cd5\u9002\u5e94\u80fd\u529b\u8fb9\u754c\u7684\u53d8\u5316\uff0c\u5bfc\u81f4\u5728\u5df2\u89e3\u51b3\u6216\u65e0\u6cd5\u89e3\u51b3\u7684\u63d0\u793a\u4e0a\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "HeaPA\u7ef4\u62a4\u4e00\u4e2a\u6709\u754c\u7684\u6f14\u5316\u63d0\u793a\u6c60\uff0c\u4f7f\u7528\u5806\u91c7\u6837\u8ddf\u8e2a\u80fd\u529b\u8fb9\u754c\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5f02\u6b65\u9a8c\u8bc1\u7684\u5728\u7ebf\u67e5\u8be2\u589e\u5f3a\u6269\u5c55\u6c60\uff0c\u5e76\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u7684\u7edf\u8ba1\u91cd\u4f30\u8ba1\u548c\u63a7\u5236\u91cd\u63d2\u5165\u6765\u7a33\u5b9a\u76f8\u5173\u67e5\u8be2\u3002", "result": "\u5728\u4e24\u4e2a\u8bad\u7ec3\u8bed\u6599\u5e93\u3001\u4e24\u79cd\u8bad\u7ec3\u65b9\u6848\u548c\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHeaPA\u6301\u7eed\u63d0\u5347\u51c6\u786e\u6027\uff0c\u4ee5\u66f4\u5c11\u7684\u8ba1\u7b97\u8fbe\u5230\u76ee\u6807\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u8bad\u7ec3\u65f6\u95f4\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\u6536\u76ca\u8d8a\u660e\u663e\u3002", "conclusion": "HeaPA\u901a\u8fc7\u8fb9\u754c\u805a\u7126\u91c7\u6837\u548c\u5728\u7ebf\u6c60\u589e\u957f\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86RLVR\u8bad\u7ec3\u7684\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u66f4\u5927\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.22466", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22466", "abs": "https://arxiv.org/abs/2601.22466", "authors": ["Yaowei Jin", "Junjie Wang", "Cheng Cao", "Penglei Wang", "Duo An", "Qian Shi"], "title": "EvoEGF-Mol: Evolving Exponential Geodesic Flow for Structure-based Drug Design", "comment": null, "summary": "Structure-Based Drug Design (SBDD) aims to discover bioactive ligands. Conventional approaches construct probability paths separately in Euclidean and probabilistic spaces for continuous atomic coordinates and discrete chemical categories, leading to a mismatch with the underlying statistical manifolds. We address this issue from an information-geometric perspective by modeling molecules as composite exponential-family distributions and defining generative flows along exponential geodesics under the Fisher-Rao metric. To avoid the instantaneous trajectory collapse induced by geodesics directly targeting Dirac distributions, we propose Evolving Exponential Geodesic Flow for SBDD (EvoEGF-Mol), which replaces static Dirac targets with dynamically concentrating distributions, ensuring stable training via a progressive-parameter-refinement architecture. Our model approaches a reference-level PoseBusters passing rate (93.4%) on CrossDock, demonstrating remarkable geometric precision and interaction fidelity, while outperforming baselines on real-world MolGenBench tasks by recovering bioactive scaffolds and generating candidates that meet established MedChem filters.", "AI": {"tldr": "EvoEGF-Mol\uff1a\u57fa\u4e8e\u4fe1\u606f\u51e0\u4f55\u7684SBDD\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6307\u6570\u6d4b\u5730\u6d41\u5728\u7edf\u8ba1\u6d41\u5f62\u4e0a\u5efa\u6a21\u5206\u5b50\u751f\u6210\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u548c\u6982\u7387\u7a7a\u95f4\u5206\u79bb\u5bfc\u81f4\u7684\u6d41\u5f62\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u8bbe\u8ba1\u65b9\u6cd5\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u548c\u6982\u7387\u7a7a\u95f4\u5206\u522b\u6784\u5efa\u6982\u7387\u8def\u5f84\uff0c\u5bfc\u81f4\u4e0e\u5e95\u5c42\u7edf\u8ba1\u6d41\u5f62\u4e0d\u5339\u914d\u3002\u9700\u8981\u4ece\u4fe1\u606f\u51e0\u4f55\u89d2\u5ea6\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f7f\u5206\u5b50\u751f\u6210\u8fc7\u7a0b\u66f4\u7b26\u5408\u7edf\u8ba1\u6d41\u5f62\u7684\u51e0\u4f55\u7ed3\u6784\u3002", "method": "\u5c06\u5206\u5b50\u5efa\u6a21\u4e3a\u590d\u5408\u6307\u6570\u65cf\u5206\u5e03\uff0c\u5728Fisher-Rao\u5ea6\u91cf\u4e0b\u5b9a\u4e49\u6cbf\u6307\u6570\u6d4b\u5730\u7ebf\u7684\u751f\u6210\u6d41\u3002\u4e3a\u907f\u514d\u76f4\u63a5\u4ee5\u72c4\u62c9\u514b\u5206\u5e03\u4e3a\u76ee\u6807\u5bfc\u81f4\u7684\u77ac\u65f6\u8f68\u8ff9\u5d29\u6e83\uff0c\u63d0\u51faEvoEGF-Mol\uff0c\u7528\u52a8\u6001\u96c6\u4e2d\u5206\u5e03\u66ff\u4ee3\u9759\u6001\u72c4\u62c9\u514b\u76ee\u6807\uff0c\u901a\u8fc7\u6e10\u8fdb\u53c2\u6570\u7cbe\u70bc\u67b6\u6784\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u5728CrossDock\u4e0a\u8fbe\u5230\u53c2\u8003\u7ea7\u522b\u7684PoseBusters\u901a\u8fc7\u7387\uff0893.4%\uff09\uff0c\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u51e0\u4f55\u7cbe\u5ea6\u548c\u76f8\u4e92\u4f5c\u7528\u4fdd\u771f\u5ea6\u3002\u5728\u771f\u5b9e\u4e16\u754c\u7684MolGenBench\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u591f\u6062\u590d\u751f\u7269\u6d3b\u6027\u9aa8\u67b6\u5e76\u751f\u6210\u7b26\u5408\u65e2\u5b9aMedChem\u8fc7\u6ee4\u5668\u7684\u5019\u9009\u5206\u5b50\u3002", "conclusion": "\u4ece\u4fe1\u606f\u51e0\u4f55\u89d2\u5ea6\u5efa\u6a21\u5206\u5b50\u751f\u6210\u8fc7\u7a0b\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edfSBDD\u65b9\u6cd5\u7684\u6d41\u5f62\u4e0d\u5339\u914d\u95ee\u9898\uff0cEvoEGF-Mol\u901a\u8fc7\u6307\u6570\u6d4b\u5730\u6d41\u5b9e\u73b0\u4e86\u7a33\u5b9a\u8bad\u7ec3\u548c\u9ad8\u7cbe\u5ea6\u5206\u5b50\u751f\u6210\uff0c\u4e3a\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.22474", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22474", "abs": "https://arxiv.org/abs/2601.22474", "authors": ["Jian Xiong", "Jingbo Zhou", "Zihan Zhou", "Yixiong Xiao", "Le Zhang", "Jingyong Ye", "Rui Qian", "Yang Zhou", "Dejing Dou"], "title": "Unrewarded Exploration in Large Language Models Reveals Latent Learning from Psychology", "comment": "17pages, 1 figure", "summary": "Latent learning, classically theorized by Tolman, shows that biological agents (e.g., rats) can acquire internal representations of their environment without rewards, enabling rapid adaptation once rewards are introduced. In contrast, from a cognitive science perspective, reward learning remains overly dependent on external feedback, limiting flexibility and generalization. Although recent advances in the reasoning capabilities of large language models (LLMs), such as OpenAI-o1 and DeepSeek-R1, mark a significant breakthrough, these models still rely primarily on reward-centric reinforcement learning paradigms. Whether and how the well-established phenomenon of latent learning in psychology can inform or emerge within LLMs' training remains largely unexplored. In this work, we present novel findings from our experiments that LLMs also exhibit the latent learning dynamics. During an initial phase of unrewarded exploration, LLMs display modest performance improvements, as this phase allows LLMs to organize task-relevant knowledge without being constrained by reward-driven biases, and performance is further enhanced once rewards are introduced. LLMs post-trained under this two-stage exploration regime ultimately achieve higher competence than those post-trained with reward-based reinforcement learning throughout. Beyond these empirical observations, we also provide theoretical analyses for our experiments explaining why unrewarded exploration yields performance gains, offering a mechanistic account of these dynamics. Specifically, we conducted extensive experiments across multiple model families and diverse task domains to establish the existence of the latent learning dynamics in LLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u65e0\u5956\u52b1\u63a2\u7d22\u9636\u6bb5\u8868\u73b0\u51fa\u6f5c\u5728\u5b66\u4e60\u52a8\u6001\uff0c\u8fd9\u79cd\u5fc3\u7406\u5b66\u73b0\u8c61\u4f7f\u6a21\u578b\u5728\u540e\u7eed\u5956\u52b1\u5f15\u5165\u65f6\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5fc3\u7406\u5b66\u4e2d\u7684\u6f5c\u5728\u5b66\u4e60\u73b0\u8c61\u8868\u660e\u751f\u7269\u4f53\u53ef\u4ee5\u5728\u65e0\u5956\u52b1\u60c5\u51b5\u4e0b\u5b66\u4e60\u73af\u5883\u8868\u5f81\uff0c\u800c\u5f53\u524dLLMs\u4e3b\u8981\u4f9d\u8d56\u5956\u52b1\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\u3002\u7814\u7a76\u63a2\u7d22LLMs\u662f\u5426\u4e5f\u5b58\u5728\u7c7b\u4f3c\u6f5c\u5728\u5b66\u4e60\u52a8\u6001\uff0c\u4ee5\u53ca\u5982\u4f55\u5229\u7528\u8fd9\u79cd\u73b0\u8c61\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1a\u7b2c\u4e00\u9636\u6bb5\u8ba9LLMs\u5728\u65e0\u5956\u52b1\u73af\u5883\u4e0b\u8fdb\u884c\u63a2\u7d22\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u5956\u52b1\u8fdb\u884c\u8bad\u7ec3\u3002\u5728\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c\u591a\u6837\u5316\u4efb\u52a1\u9886\u57df\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u5206\u6790\u89e3\u91ca\u65e0\u5956\u52b1\u63a2\u7d22\u7684\u6027\u80fd\u589e\u76ca\u673a\u5236\u3002", "result": "LLMs\u5728\u65e0\u5956\u52b1\u63a2\u7d22\u9636\u6bb5\u8868\u73b0\u51fa\u9002\u5ea6\u7684\u6027\u80fd\u6539\u8fdb\uff0c\u8fd9\u79cd\u63a2\u7d22\u4f7f\u6a21\u578b\u80fd\u591f\u7ec4\u7ec7\u4efb\u52a1\u76f8\u5173\u77e5\u8bc6\u800c\u4e0d\u53d7\u5956\u52b1\u9a71\u52a8\u504f\u89c1\u7ea6\u675f\u3002\u4e00\u65e6\u5f15\u5165\u5956\u52b1\uff0c\u6027\u80fd\u5f97\u5230\u8fdb\u4e00\u6b65\u663e\u8457\u63d0\u5347\u3002\u91c7\u7528\u8fd9\u79cd\u4e24\u9636\u6bb5\u63a2\u7d22\u673a\u5236\u7684LLMs\u6700\u7ec8\u6bd4\u5168\u7a0b\u4f7f\u7528\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u80fd\u529b\u3002", "conclusion": "LLMs\u786e\u5b9e\u8868\u73b0\u51fa\u5fc3\u7406\u5b66\u4e2d\u7684\u6f5c\u5728\u5b66\u4e60\u52a8\u6001\uff0c\u65e0\u5956\u52b1\u63a2\u7d22\u9636\u6bb5\u6709\u52a9\u4e8e\u6a21\u578b\u6784\u5efa\u66f4\u7075\u6d3b\u7684\u77e5\u8bc6\u8868\u5f81\uff0c\u51cf\u5c11\u5956\u52b1\u504f\u89c1\uff0c\u6700\u7ec8\u5b9e\u73b0\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002\u8fd9\u4e3aLLMs\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u548c\u5b9e\u8df5\u65b9\u6cd5\u3002"}}
{"id": "2601.22475", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22475", "abs": "https://arxiv.org/abs/2601.22475", "authors": ["Yuxuan Li", "Qijun He", "Mingqi Yuan", "Wen-Tse Chen", "Jeff Schneider", "Jiayu Chen"], "title": "Continual Policy Distillation from Distributed Reinforcement Learning Teachers", "comment": "19 pages (8 pages main text)", "summary": "Continual Reinforcement Learning (CRL) aims to develop lifelong learning agents to continuously acquire knowledge across diverse tasks while mitigating catastrophic forgetting. This requires efficiently managing the stability-plasticity dilemma and leveraging prior experience to rapidly generalize to novel tasks. While various enhancement strategies for both aspects have been proposed, achieving scalable performance by directly applying RL to sequential task streams remains challenging. In this paper, we propose a novel teacher-student framework that decouples CRL into two independent processes: training single-task teacher models through distributed RL and continually distilling them into a central generalist model. This design is motivated by the observation that RL excels at solving single tasks, while policy distillation -- a relatively stable supervised learning process -- is well aligned with large foundation models and multi-task learning. Moreover, a mixture-of-experts (MoE) architecture and a replay-based approach are employed to enhance the plasticity and stability of the continual policy distillation process. Extensive experiments on the Meta-World benchmark demonstrate that our framework enables efficient continual RL, recovering over 85% of teacher performance while constraining task-wise forgetting to within 10%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5e08\u751f\u6846\u67b6\uff0c\u5c06\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u89e3\u8026\u4e3a\u4e24\u4e2a\u72ec\u7acb\u8fc7\u7a0b\uff1a\u901a\u8fc7\u5206\u5e03\u5f0fRL\u8bad\u7ec3\u5355\u4efb\u52a1\u6559\u5e08\u6a21\u578b\uff0c\u5e76\u6301\u7eed\u84b8\u998f\u5230\u4e2d\u592e\u901a\u7528\u6a21\u578b\u4e2d\uff0c\u7ed3\u5408MoE\u67b6\u6784\u548c\u91cd\u653e\u673a\u5236\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u56f0\u5883\uff0c\u76f4\u63a5\u5e94\u7528RL\u5230\u8fde\u7eed\u4efb\u52a1\u6d41\u4e2d\u96be\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u80fd\u3002\u89c2\u5bdf\u5230RL\u64c5\u957f\u89e3\u51b3\u5355\u4efb\u52a1\uff0c\u800c\u7b56\u7565\u84b8\u998f\u4f5c\u4e3a\u76f8\u5bf9\u7a33\u5b9a\u7684\u76d1\u7763\u5b66\u4e60\u8fc7\u7a0b\uff0c\u66f4\u9002\u5408\u5927\u89c4\u6a21\u57fa\u7840\u6a21\u578b\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u3002", "method": "1. \u5e08\u751f\u6846\u67b6\u89e3\u8026CRL\uff1a\u5206\u5e03\u5f0fRL\u8bad\u7ec3\u5355\u4efb\u52a1\u6559\u5e08\u6a21\u578b + \u6301\u7eed\u84b8\u998f\u5230\u4e2d\u592e\u901a\u7528\u6a21\u578b\uff1b2. \u91c7\u7528\u6df7\u5408\u4e13\u5bb6(MoE)\u67b6\u6784\u589e\u5f3a\u53ef\u5851\u6027\uff1b3. \u4f7f\u7528\u57fa\u4e8e\u91cd\u653e\u7684\u65b9\u6cd5\u63d0\u5347\u7a33\u5b9a\u6027\u3002", "result": "\u5728Meta-World\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6846\u67b6\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6301\u7eedRL\uff0c\u6062\u590d\u4e86\u8d85\u8fc785%\u7684\u6559\u5e08\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u4efb\u52a1\u9057\u5fd8\u7387\u63a7\u5236\u572810%\u4ee5\u5185\u3002", "conclusion": "\u901a\u8fc7\u89e3\u8026\u5355\u4efb\u52a1RL\u8bad\u7ec3\u548c\u591a\u4efb\u52a1\u7b56\u7565\u84b8\u998f\uff0c\u7ed3\u5408MoE\u548c\u91cd\u653e\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u7684\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u56f0\u5883\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u77e5\u8bc6\u79ef\u7d2f\u548c\u8fc1\u79fb\u3002"}}
{"id": "2601.22478", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22478", "abs": "https://arxiv.org/abs/2601.22478", "authors": ["Khiem Le", "Youssef Mroueh", "Phuc Nguyen", "Chi-Heng Lin", "Shangqian Gao", "Ting Hua", "Nitesh V. Chawla"], "title": "Transform-Augmented GRPO Improves Pass@k", "comment": null, "summary": "Large language models trained via next-token prediction are fundamentally pattern-matchers: sensitive to superficial phrasing variations even when the underlying problem is identical. Group Relative Policy Optimization (GRPO) was designed to improve reasoning, but in fact it worsens this situation through two failure modes: diversity collapse, where training amplifies a single solution strategy while ignoring alternatives of gradient signal, and gradient diminishing, where a large portion of questions yield zero gradients because all rollouts receive identical rewards. We propose TA-GRPO (Transform-Augmented GRPO), which generates semantically equivalent transformed variants of each question (via paraphrasing, variable renaming, and format changes) and computes advantages by pooling rewards across the entire group. This pooled computation ensures mixed rewards even when the original question is too easy or too hard, while training on diverse phrasings promotes multiple solution strategies. We provide theoretical justification showing that TA-GRPO reduces zero-gradient probability and improves generalization via reduced train-test distribution shift. Experiments on mathematical reasoning benchmarks show consistent Pass@k improvements, with gains up to 9.84 points on competition math (AMC12, AIME24) and 5.05 points on out-of-distribution scientific reasoning (GPQA-Diamond).", "AI": {"tldr": "TA-GRPO\u901a\u8fc7\u751f\u6210\u8bed\u4e49\u7b49\u4ef7\u7684\u53d8\u6362\u95ee\u9898\u53d8\u4f53\uff0c\u89e3\u51b3\u4e86GRPO\u4e2d\u7684\u591a\u6837\u6027\u5d29\u6e83\u548c\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u6a21\u5f0f\u5339\u914d\u5668\u5bf9\u8868\u9762\u8868\u8fbe\u53d8\u5316\u654f\u611f\uff0c\u800cGRPO\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5931\u8d25\u6a21\u5f0f\uff1a\u591a\u6837\u6027\u5d29\u6e83\uff08\u8bad\u7ec3\u653e\u5927\u5355\u4e00\u89e3\u51b3\u65b9\u6848\u7b56\u7565\uff09\u548c\u68af\u5ea6\u6d88\u5931\uff08\u5927\u91cf\u95ee\u9898\u4ea7\u751f\u96f6\u68af\u5ea6\uff09\uff0c\u8fd9\u6076\u5316\u4e86\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faTA-GRPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f6c\u8ff0\u3001\u53d8\u91cf\u91cd\u547d\u540d\u548c\u683c\u5f0f\u53d8\u5316\u751f\u6210\u8bed\u4e49\u7b49\u4ef7\u7684\u53d8\u6362\u95ee\u9898\u53d8\u4f53\uff0c\u901a\u8fc7\u8de8\u6574\u4e2a\u7ec4\u6c60\u5316\u5956\u52b1\u8ba1\u7b97\u4f18\u52bf\uff0c\u786e\u4fdd\u6df7\u5408\u5956\u52b1\u5e76\u4fc3\u8fdb\u591a\u79cd\u89e3\u51b3\u65b9\u6848\u7b56\u7565\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u83b7\u5f97\u4e00\u81f4\u7684Pass@k\u6539\u8fdb\uff0c\u5728\u7ade\u8d5b\u6570\u5b66\uff08AMC12, AIME24\uff09\u4e0a\u63d0\u5347\u9ad8\u8fbe9.84\u5206\uff0c\u5728\u5206\u5e03\u5916\u79d1\u5b66\u63a8\u7406\uff08GPQA-Diamond\uff09\u4e0a\u63d0\u53475.05\u5206\u3002", "conclusion": "TA-GRPO\u901a\u8fc7\u51cf\u5c11\u96f6\u68af\u5ea6\u6982\u7387\u548c\u6539\u5584\u6cdb\u5316\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86GRPO\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u3002"}}
{"id": "2601.22484", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22484", "abs": "https://arxiv.org/abs/2601.22484", "authors": ["Seojin Lee", "ByeongJeong Kim", "Hwanhee Lee"], "title": "Mitigating Cognitive Inertia in Large Reasoning Models via Latent Spike Steering", "comment": "21 pages, 6 figures", "summary": "While Large Reasoning Models (LRMs) have achieved remarkable performance by scaling test-time compute, they frequently suffer from Cognitive Inertia, a failure pattern manifesting as either overthinking (inertia of motion) or reasoning rigidity (inertia of direction). Existing detection methods, typically relying on superficial textual heuristics like self-correction tokens, often fail to capture the model's unvoiced internal conflicts. To address this, we propose STARS (Spike-Triggered Adaptive Reasoning Steering), a training-free framework designed to rectify cognitive inertia by monitoring latent dynamics. STARS identifies Cognitive Pivots-critical moments of reasoning transition-by detecting distinct L2 distance spikes in the hidden states. Upon detection, the framework employs geometric trajectory analysis to diagnose the structural nature of the transition and injects state-aware language cues to steer the model in real-time. Our experiments across diverse benchmarks confirm that STARS efficiently curtails redundant loops while improving accuracy through the adaptive correction of erroneous trajectories. STARS offers a robust, unsupervised mechanism to optimize the reasoning process of LRMs without requiring additional fine-tuning.", "AI": {"tldr": "STARS\u6846\u67b6\u901a\u8fc7\u76d1\u6d4b\u9690\u85cf\u72b6\u6001\u4e2d\u7684L2\u8ddd\u79bb\u5c16\u5cf0\u6765\u68c0\u6d4b\u8ba4\u77e5\u60ef\u6027\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5b9e\u65f6\u7ea0\u6b63\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u867d\u7136\u901a\u8fc7\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\uff0c\u4f46\u7ecf\u5e38\u906d\u53d7\u8ba4\u77e5\u60ef\u6027\u7684\u56f0\u6270\uff0c\u8868\u73b0\u4e3a\u8fc7\u5ea6\u601d\u8003\u6216\u63a8\u7406\u50f5\u5316\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u8868\u9762\u6587\u672c\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u65e0\u6cd5\u6355\u6349\u6a21\u578b\u672a\u8868\u8fbe\u7684\u5185\u90e8\u51b2\u7a81\u3002", "method": "\u63d0\u51faSTARS\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u68c0\u6d4b\u9690\u85cf\u72b6\u6001\u4e2d\u7684L2\u8ddd\u79bb\u5c16\u5cf0\u6765\u8bc6\u522b\u8ba4\u77e5\u8f6c\u6298\u70b9\uff1b2\uff09\u4f7f\u7528\u51e0\u4f55\u8f68\u8ff9\u5206\u6790\u8bca\u65ad\u8fc7\u6e21\u7684\u7ed3\u6784\u6027\u8d28\uff1b3\uff09\u6ce8\u5165\u72b6\u6001\u611f\u77e5\u7684\u8bed\u8a00\u63d0\u793a\u6765\u5b9e\u65f6\u5f15\u5bfc\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u5b9e\uff0cSTARS\u80fd\u6709\u6548\u51cf\u5c11\u5197\u4f59\u5faa\u73af\uff0c\u540c\u65f6\u901a\u8fc7\u81ea\u9002\u5e94\u7ea0\u6b63\u9519\u8bef\u8f68\u8ff9\u6765\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "STARS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u989d\u5916\u5fae\u8c03\u7684\u9c81\u68d2\u65e0\u76d1\u7763\u673a\u5236\uff0c\u7528\u4e8e\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2601.22495", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22495", "abs": "https://arxiv.org/abs/2601.22495", "authors": ["Gudrun Thorkelsdottir", "Arindam Banerjee"], "title": "Gradual Fine-Tuning for Flow Matching Models", "comment": "Preprint. Submitted to ICML. 8 pages, 5 figures (+ appendix)", "summary": "Fine-tuning flow matching models is a central challenge in settings with limited data, evolving distributions, or strict efficiency demands, where unconstrained fine-tuning can erode the accuracy and efficiency gains learned during pretraining. Prior work has produced theoretical guarantees and empirical advances for reward-based fine-tuning formulations, but these methods often impose restrictions on permissible drift structure or training techniques. In this work, we propose Gradual Fine-Tuning (GFT), a principled framework for fine-tuning flow-based generative models when samples from the target distribution are available. For stochastic flows, GFT defines a temperature-controlled sequence of intermediate objectives that smoothly interpolate between the pretrained and target drifts, approaching the true target as the temperature approaches zero. We prove convergence results for both marginal and conditional GFT objectives, enabling the use of suitable (e.g., optimal transport) couplings during GFT while preserving correctness. Empirically, GFT improves convergence stability and shortens probability paths, resulting in faster inference, while maintaining generation quality comparable to standard fine-tuning. Our results position GFT as a theoretically grounded and practically effective alternative for scalable adaptation of flow matching models under distribution shift.", "AI": {"tldr": "GFT\u662f\u4e00\u79cd\u7528\u4e8e\u6d41\u5339\u914d\u6a21\u578b\u5fae\u8c03\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u6e29\u5ea6\u63a7\u5236\u7684\u4e2d\u95f4\u76ee\u6807\u5e73\u6ed1\u8fc7\u6e21\u9884\u8bad\u7ec3\u548c\u76ee\u6807\u5206\u5e03\uff0c\u63d0\u9ad8\u6536\u655b\u7a33\u5b9a\u6027\u5e76\u7f29\u77ed\u63a8\u7406\u8def\u5f84", "motivation": "\u5728\u6570\u636e\u6709\u9650\u3001\u5206\u5e03\u53d8\u5316\u6216\u6548\u7387\u8981\u6c42\u4e25\u683c\u7684\u573a\u666f\u4e2d\uff0c\u65e0\u7ea6\u675f\u7684\u5fae\u8c03\u4f1a\u635f\u5bb3\u9884\u8bad\u7ec3\u83b7\u5f97\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u4f18\u52bf\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u6f02\u79fb\u7ed3\u6784\u6216\u8bad\u7ec3\u6280\u672f\u6709\u9650\u5236\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u5fae\u8c03\u6846\u67b6", "method": "\u63d0\u51fa\u6e10\u8fdb\u5fae\u8c03(GFT)\u6846\u67b6\uff0c\u4e3a\u968f\u673a\u6d41\u5b9a\u4e49\u6e29\u5ea6\u63a7\u5236\u7684\u4e2d\u95f4\u76ee\u6807\u5e8f\u5217\uff0c\u5e73\u6ed1\u63d2\u503c\u9884\u8bad\u7ec3\u548c\u76ee\u6807\u6f02\u79fb\u3002\u5f53\u6e29\u5ea6\u8d8b\u8fd1\u96f6\u65f6\u63a5\u8fd1\u771f\u5b9e\u76ee\u6807\u3002\u652f\u6301\u4f7f\u7528\u5408\u9002\u7684\u8026\u5408\uff08\u5982\u6700\u4f18\u4f20\u8f93\uff09\u540c\u65f6\u4fdd\u6301\u6b63\u786e\u6027", "result": "GFT\u63d0\u9ad8\u4e86\u6536\u655b\u7a33\u5b9a\u6027\uff0c\u7f29\u77ed\u4e86\u6982\u7387\u8def\u5f84\uff0c\u5b9e\u73b0\u66f4\u5feb\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6\u5fae\u8c03\u76f8\u5f53\u7684\u751f\u6210\u8d28\u91cf\u3002\u7406\u8bba\u8bc1\u660e\u8fb9\u9645\u548c\u6761\u4ef6GFT\u76ee\u6807\u7684\u6536\u655b\u6027", "conclusion": "GFT\u4e3a\u6d41\u5339\u914d\u6a21\u578b\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u53ef\u6269\u5c55\u9002\u5e94\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u662f\u5904\u7406\u6709\u9650\u6570\u636e\u3001\u6f14\u5316\u5206\u5e03\u548c\u6548\u7387\u7ea6\u675f\u573a\u666f\u7684\u6709\u524d\u666f\u65b9\u6cd5"}}
{"id": "2601.22512", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22512", "abs": "https://arxiv.org/abs/2601.22512", "authors": ["Tian-Tian Lin", "Yi Liu", "Xiao-Wei Tang", "Yunmei Shi", "Yi Huang", "Zhongxiang Wei", "Qingqing Wu", "Yuhan Dong"], "title": "DRL-Enabled Trajectory Planing for UAV-Assisted VLC: Optimal Altitude and Reward Design", "comment": null, "summary": "Recently, the integration of unmanned aerial vehicle (UAV) and visible light communication (VLC) technologies has emerged as a promising solution to offer flexible communication and efficient lighting. This letter investigates the three-dimensional trajectory planning in a UAV-assisted VLC system, where a UAV is dispatched to collect data from ground users (GUs). The core objective is to develop a trajectory planning framework that minimizes UAV flight distance, which is equivalent to maximizing the data collection efficiency. This issue is formulated as a challenging mixed-integer non-convex optimization problem. To tackle it, we first derive a closed-form optimal flight altitude under specific VLC channel gain threshold. Subsequently, we optimize the UAV horizontal trajectory by integrating a novel pheromone-driven reward mechanism with the twin delayed deep deterministic policy gradient algorithm, which enables adaptive UAV motion strategy in complex environments. Simulation results validate that the derived optimal altitude effectively reduces the flight distance by up to 35% compared to baseline methods. Additionally, the proposed reward mechanism significantly shortens the convergence steps by approximately 50%, demonstrating notable efficiency gains in the context of UAV-assisted VLC data collection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u65e0\u4eba\u673a\u8f85\u52a9\u53ef\u89c1\u5149\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u4e09\u7ef4\u8f68\u8ff9\u89c4\u5212\uff0c\u901a\u8fc7\u4f18\u5316\u65e0\u4eba\u673a\u98de\u884c\u9ad8\u5ea6\u548c\u6c34\u5e73\u8f68\u8ff9\u6765\u6700\u5c0f\u5316\u98de\u884c\u8ddd\u79bb\uff0c\u63d0\u9ad8\u6570\u636e\u6536\u96c6\u6548\u7387\u3002", "motivation": "\u65e0\u4eba\u673a\u4e0e\u53ef\u89c1\u5149\u901a\u4fe1\u6280\u672f\u7684\u7ed3\u5408\u4e3a\u63d0\u4f9b\u7075\u6d3b\u901a\u4fe1\u548c\u9ad8\u6548\u7167\u660e\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002\u9700\u8981\u89e3\u51b3\u65e0\u4eba\u673a\u5728\u6536\u96c6\u5730\u9762\u7528\u6237\u6570\u636e\u65f6\u7684\u4e09\u7ef4\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u4ee5\u6700\u5c0f\u5316\u98de\u884c\u8ddd\u79bb\u5e76\u63d0\u9ad8\u6570\u636e\u6536\u96c6\u6548\u7387\u3002", "method": "\u9996\u5148\u63a8\u5bfc\u4e86\u5728\u7279\u5b9aVLC\u4fe1\u9053\u589e\u76ca\u9608\u503c\u4e0b\u7684\u95ed\u5f0f\u6700\u4f18\u98de\u884c\u9ad8\u5ea6\uff0c\u7136\u540e\u901a\u8fc7\u5c06\u65b0\u578b\u4fe1\u606f\u7d20\u9a71\u52a8\u5956\u52b1\u673a\u5236\u4e0e\u53cc\u5ef6\u8fdf\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u76f8\u7ed3\u5408\u6765\u4f18\u5316\u65e0\u4eba\u673a\u6c34\u5e73\u8f68\u8ff9\uff0c\u5b9e\u73b0\u590d\u6742\u73af\u5883\u4e2d\u7684\u81ea\u9002\u5e94\u8fd0\u52a8\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u63a8\u5bfc\u7684\u6700\u4f18\u9ad8\u5ea6\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u53ef\u51cf\u5c11\u9ad8\u8fbe35%\u7684\u98de\u884c\u8ddd\u79bb\u3002\u63d0\u51fa\u7684\u5956\u52b1\u673a\u5236\u663e\u8457\u7f29\u77ed\u4e86\u7ea650%\u7684\u6536\u655b\u6b65\u6570\uff0c\u5728\u65e0\u4eba\u673a\u8f85\u52a9VLC\u6570\u636e\u6536\u96c6\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u4e09\u7ef4\u8f68\u8ff9\u89c4\u5212\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u8f85\u52a9VLC\u7cfb\u7edf\u4e2d\u7684\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u9ad8\u5ea6\u4f18\u5316\u548c\u81ea\u9002\u5e94\u8f68\u8ff9\u89c4\u5212\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u6536\u96c6\u6548\u7387\uff0c\u4e3a\u65e0\u4eba\u673a-VLC\u96c6\u6210\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22538", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.22538", "abs": "https://arxiv.org/abs/2601.22538", "authors": ["Yannis Montreuil", "Letian Yu", "Axel Carlier", "Lai Xing Ng", "Wei Tsang Ooi"], "title": "Learning to Defer in Non-Stationary Time Series via Switching State-Space Models", "comment": null, "summary": "We study Learning to Defer for non-stationary time series with partial feedback and time-varying expert availability. At each time step, the router selects an available expert, observes the target, and sees only the queried expert's prediction. We model signed expert residuals using L2D-SLDS, a factorized switching linear-Gaussian state-space model with context-dependent regime transitions, a shared global factor enabling cross-expert information transfer, and per-expert idiosyncratic states. The model supports expert entry and pruning via a dynamic registry. Using one-step-ahead predictive beliefs, we propose an IDS-inspired routing rule that trades off predicted cost against information gained about the latent regime and shared factor. Experiments show improvements over contextual-bandit baselines and a no-shared-factor ablation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u7684\u5ef6\u8fdf\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u5b50\u5316\u5207\u6362\u7ebf\u6027\u9ad8\u65af\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5efa\u6a21\u4e13\u5bb6\u6b8b\u5dee\uff0c\u652f\u6301\u52a8\u6001\u4e13\u5bb6\u6ce8\u518c\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4fe1\u606f\u5bfc\u5411\u7684\u8def\u7531\u7b56\u7565", "motivation": "\u9488\u5bf9\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u4e2d\u4e13\u5bb6\u53ef\u7528\u6027\u968f\u65f6\u95f4\u53d8\u5316\u3001\u53ea\u80fd\u83b7\u5f97\u90e8\u5206\u53cd\u9988\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u52a8\u6001\u4e13\u5bb6\u73af\u5883\u3001\u5b9e\u73b0\u8de8\u4e13\u5bb6\u4fe1\u606f\u5171\u4eab\u7684\u5ef6\u8fdf\u5b66\u4e60\u6846\u67b6", "method": "\u63d0\u51faL2D-SLDS\u6a21\u578b\uff1a\u56e0\u5b50\u5316\u5207\u6362\u7ebf\u6027\u9ad8\u65af\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5305\u542b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u72b6\u6001\u8f6c\u6362\u3001\u5171\u4eab\u5168\u5c40\u56e0\u5b50\uff08\u5b9e\u73b0\u8de8\u4e13\u5bb6\u4fe1\u606f\u4f20\u9012\uff09\u548c\u4e13\u5bb6\u7279\u5b9a\u72b6\u6001\uff1b\u652f\u6301\u52a8\u6001\u4e13\u5bb6\u6ce8\u518c\uff1b\u57fa\u4e8e\u4e00\u6b65\u9884\u6d4b\u4fe1\u5ff5\u8bbe\u8ba1\u4fe1\u606f\u5bfc\u5411\u7684\u8def\u7531\u7b56\u7565", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u57fa\u7ebf\uff0c\u4e14\u4f18\u4e8e\u65e0\u5171\u4eab\u56e0\u5b50\u7684\u6d88\u878d\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u8de8\u4e13\u5bb6\u4fe1\u606f\u5171\u4eab\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684L2D-SLDS\u6a21\u578b\u548c\u4fe1\u606f\u5bfc\u5411\u8def\u7531\u7b56\u7565\u80fd\u591f\u6709\u6548\u5904\u7406\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5ef6\u8fdf\u5b66\u4e60\u95ee\u9898\uff0c\u652f\u6301\u52a8\u6001\u4e13\u5bb6\u73af\u5883\u5e76\u5b9e\u73b0\u8de8\u4e13\u5bb6\u77e5\u8bc6\u8fc1\u79fb"}}
{"id": "2601.22539", "categories": ["cs.LG", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22539", "abs": "https://arxiv.org/abs/2601.22539", "authors": ["Babak Shahbaba", "Zahra Moslemi"], "title": "Neural-Inspired Posterior Approximation (NIPA)", "comment": "13 pages, 4 tables", "summary": "Humans learn efficiently from their environment by engaging multiple interacting neural systems that support distinct yet complementary forms of control, including model-based (goal-directed) planning, model-free (habitual) responding, and episodic memory-based learning. Model-based mechanisms compute prospective action values using an internal model of the environment, supporting flexible but computationally costly planning; model-free mechanisms cache value estimates and build heuristics that enable fast, efficient habitual responding; and memory-based mechanisms allow rapid adaptation from individual experience. In this work, we aim to elucidate the computational principles underlying this biological efficiency and translate them into a sampling algorithm for scalable Bayesian inference through effective exploration of the posterior distribution. More specifically, our proposed algorithm comprises three components: a model-based module that uses the target distribution for guided but computationally slow sampling; a model-free module that uses previous samples to learn patterns in the parameter space, enabling fast, reflexive sampling without directly evaluating the expensive target distribution; and an episodic-control module that supports rapid sampling by recalling specific past events (i.e., samples). We show that this approach advances Bayesian methods and facilitates their application to large-scale statistical machine learning problems. In particular, we apply our proposed framework to Bayesian deep learning, with an emphasis on proper and principled uncertainty quantification.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53d7\u4eba\u7c7b\u591a\u7cfb\u7edf\u5b66\u4e60\u542f\u53d1\u7684\u8d1d\u53f6\u65af\u91c7\u6837\u7b97\u6cd5\uff0c\u5305\u542b\u6a21\u578b\u5bfc\u5411\u3001\u65e0\u6a21\u578b\u548c\u60c5\u666f\u63a7\u5236\u4e09\u4e2a\u6a21\u5757\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u7edf\u8ba1\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316", "motivation": "\u4eba\u7c7b\u901a\u8fc7\u591a\u4e2a\u76f8\u4e92\u4f5c\u7528\u7684\u795e\u7ecf\u7cfb\u7edf\u7684\u4e92\u8865\u63a7\u5236\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\uff0c\u5305\u62ec\u6a21\u578b\u5bfc\u5411\u89c4\u5212\u3001\u65e0\u6a21\u578b\u4e60\u60ef\u6027\u54cd\u5e94\u548c\u60c5\u666f\u8bb0\u5fc6\u5b66\u4e60\u3002\u4f5c\u8005\u5e0c\u671b\u5c06\u8fd9\u79cd\u751f\u7269\u6548\u7387\u7684\u8ba1\u7b97\u539f\u7406\u8f6c\u5316\u4e3a\u53ef\u6269\u5c55\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u91c7\u6837\u7b97\u6cd5", "method": "\u63d0\u51fa\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\u7684\u7b97\u6cd5\uff1a1\uff09\u6a21\u578b\u5bfc\u5411\u6a21\u5757\u4f7f\u7528\u76ee\u6807\u5206\u5e03\u8fdb\u884c\u5f15\u5bfc\u4f46\u8ba1\u7b97\u7f13\u6162\u7684\u91c7\u6837\uff1b2\uff09\u65e0\u6a21\u578b\u6a21\u5757\u5229\u7528\u5148\u524d\u6837\u672c\u5b66\u4e60\u53c2\u6570\u7a7a\u95f4\u6a21\u5f0f\uff0c\u5b9e\u73b0\u5feb\u901f\u53cd\u5c04\u5f0f\u91c7\u6837\uff1b3\uff09\u60c5\u666f\u63a7\u5236\u6a21\u5757\u901a\u8fc7\u56de\u5fc6\u7279\u5b9a\u8fc7\u53bb\u4e8b\u4ef6\uff08\u6837\u672c\uff09\u652f\u6301\u5feb\u901f\u91c7\u6837", "result": "\u8be5\u65b9\u6cd5\u63a8\u8fdb\u4e86\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u53d1\u5c55\uff0c\u4fc3\u8fdb\u4e86\u5176\u5728\u5927\u89c4\u6a21\u7edf\u8ba1\u673a\u5668\u5b66\u4e60\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u9002\u5f53\u548c\u539f\u5219\u6027\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316", "conclusion": "\u53d7\u4eba\u7c7b\u591a\u7cfb\u7edf\u5b66\u4e60\u673a\u5236\u542f\u53d1\u7684\u4e09\u6a21\u5757\u91c7\u6837\u7b97\u6cd5\u4e3a\u5927\u89c4\u6a21\u8d1d\u53f6\u65af\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528"}}
{"id": "2601.22541", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22541", "abs": "https://arxiv.org/abs/2601.22541", "authors": ["Sean Current", "Chandan Kumar", "Datta Gaitonde", "Srinivasan Parthasarathy"], "title": "Benchmarking Long Roll-outs of Auto-regressive Neural Operators for the Compressible Navier-Stokes Equations with Conserved Quantity Correction", "comment": null, "summary": "Deep learning has been proposed as an efficient alternative for the numerical approximation of PDE solutions, offering fast, iterative simulation of PDEs through the approximation of solution operators. However, deep learning solutions have struggle to perform well over long prediction durations due to the accumulation of auto-regressive error, which is compounded by the inability of models to conserve physical quantities. In this work, we present conserved quantity correction, a model-agnostic technique for incorporation physical conservation criteria within deep learning models. Our results demonstrate consistent improvement in the long-term stability of auto-regressive neural operator models, regardless of the model architecture. Furthermore, we analyze the performance of neural operators from the spectral domain, highlighting significant limitations of present architectures. These results highlight the need for future work to consider architectures that place specific emphasis on high frequency components, which are integral to the understanding and modeling of turbulent flows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u5b88\u6052\u91cf\u6821\u6b63\u6280\u672f\uff0c\u7528\u4e8e\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u878d\u5165\u7269\u7406\u5b88\u6052\u51c6\u5219\uff0c\u663e\u8457\u6539\u5584\u4e86\u81ea\u56de\u5f52\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u7684\u957f\u671f\u7a33\u5b9a\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4f5c\u4e3aPDE\u6570\u503c\u89e3\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u901a\u8fc7\u8fd1\u4f3c\u89e3\u7b97\u5b50\u5b9e\u73b0\u5feb\u901f\u8fed\u4ee3\u6a21\u62df\u3002\u7136\u800c\uff0c\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u81ea\u56de\u5f52\u8bef\u5dee\u7684\u7d2f\u79ef\u4ee5\u53ca\u6a21\u578b\u65e0\u6cd5\u5b88\u6052\u7269\u7406\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u5b88\u6052\u91cf\u6821\u6b63\u6280\u672f\uff0c\u5c06\u7269\u7406\u5b88\u6052\u51c6\u5219\u878d\u5165\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u7279\u5b9a\u6a21\u578b\u67b6\u6784\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u6a21\u578b\u67b6\u6784\u4e2d\u90fd\u663e\u8457\u6539\u5584\u4e86\u81ea\u56de\u5f52\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u7684\u957f\u671f\u7a33\u5b9a\u6027\u3002\u540c\u65f6\u4ece\u8c31\u57df\u5206\u6790\u4e86\u795e\u7ecf\u7b97\u5b50\u7684\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u67b6\u6784\u5728\u9ad8\u9891\u5206\u91cf\u5904\u7406\u4e0a\u7684\u663e\u8457\u5c40\u9650\u6027\u3002", "conclusion": "\u672a\u6765\u7684\u5de5\u4f5c\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u7279\u522b\u5f3a\u8c03\u9ad8\u9891\u5206\u91cf\u7684\u67b6\u6784\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u548c\u5efa\u6a21\u6e4d\u6d41\u7b49\u590d\u6742\u6d41\u52a8\u73b0\u8c61\u81f3\u5173\u91cd\u8981\u3002\u5b88\u6052\u91cf\u6821\u6b63\u6280\u672f\u4e3a\u6df1\u5ea6\u5b66\u4e60PDE\u6c42\u89e3\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2601.22593", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22593", "abs": "https://arxiv.org/abs/2601.22593", "authors": ["Zahra Moslemi", "Ziyi Liang", "Norbert Fortin", "Babak Shahbaba"], "title": "Heterogeneous Graph Alignment for Joint Reasoning and Interpretability", "comment": null, "summary": "Multi-graph learning is crucial for extracting meaningful signals from collections of heterogeneous graphs. However, effectively integrating information across graphs with differing topologies, scales, and semantics, often in the absence of shared node identities, remains a significant challenge. We present the Multi-Graph Meta-Transformer (MGMT), a unified, scalable, and interpretable framework for cross-graph learning. MGMT first applies Graph Transformer encoders to each graph, mapping structure and attributes into a shared latent space. It then selects task-relevant supernodes via attention and builds a meta-graph that connects functionally aligned supernodes across graphs using similarity in the latent space. Additional Graph Transformer layers on this meta-graph enable joint reasoning over intra- and inter-graph structure. The meta-graph provides built-in interpretability: supernodes and superedges highlight influential substructures and cross-graph alignments. Evaluating MGMT on both synthetic datasets and real-world neuroscience applications, we show that MGMT consistently outperforms existing state-of-the-art models in graph-level prediction tasks while offering interpretable representations that facilitate scientific discoveries. Our work establishes MGMT as a unified framework for structured multi-graph learning, advancing representation techniques in domains where graph-based data plays a central role.", "AI": {"tldr": "MGMT\u662f\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u591a\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u56feTransformer\u7f16\u7801\u5668\u5c06\u4e0d\u540c\u56fe\u6620\u5c04\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u6784\u5efa\u5143\u56fe\u8fdb\u884c\u8de8\u56fe\u8054\u5408\u63a8\u7406\uff0c\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u591a\u56fe\u5b66\u4e60\u9762\u4e34\u6574\u5408\u5177\u6709\u4e0d\u540c\u62d3\u6251\u3001\u89c4\u6a21\u548c\u8bed\u4e49\u7684\u5f02\u6784\u56fe\u4fe1\u606f\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7f3a\u4e4f\u5171\u4eab\u8282\u70b9\u6807\u8bc6\u7684\u60c5\u51b5\u4e0b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u6574\u5408\u8de8\u56fe\u4fe1\u606f\u5e76\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "MGMT\u9996\u5148\u4f7f\u7528\u56feTransformer\u7f16\u7801\u5668\u5c06\u6bcf\u4e2a\u56fe\u7684\u7ed3\u6784\u548c\u5c5e\u6027\u6620\u5c04\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff1b\u7136\u540e\u901a\u8fc7\u6ce8\u610f\u529b\u9009\u62e9\u4efb\u52a1\u76f8\u5173\u7684\u8d85\u8282\u70b9\uff0c\u57fa\u4e8e\u6f5c\u5728\u7a7a\u95f4\u76f8\u4f3c\u6027\u6784\u5efa\u8fde\u63a5\u8de8\u56fe\u529f\u80fd\u5bf9\u9f50\u8d85\u8282\u70b9\u7684\u5143\u56fe\uff1b\u6700\u540e\u5728\u5143\u56fe\u4e0a\u5e94\u7528\u989d\u5916\u7684\u56feTransformer\u5c42\u8fdb\u884c\u8054\u5408\u63a8\u7406\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u795e\u7ecf\u79d1\u5b66\u5e94\u7528\u4e2d\uff0cMGMT\u5728\u56fe\u7ea7\u9884\u6d4b\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u4fc3\u8fdb\u79d1\u5b66\u53d1\u73b0\u3002", "conclusion": "MGMT\u4e3a\u7ed3\u6784\u5316\u591a\u56fe\u5b66\u4e60\u5efa\u7acb\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u5728\u56fe\u6570\u636e\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\u7684\u9886\u57df\u4e2d\u63a8\u8fdb\u4e86\u8868\u793a\u6280\u672f\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u8de8\u56fe\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22601", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22601", "abs": "https://arxiv.org/abs/2601.22601", "authors": ["Hanwei Tan", "Wentai Hu", "Ligang He", "Yijun Quan"], "title": "Lethe:Adapter-Augmented Dual-Stream Update for Persistent Knowledge Erasure in Federated Unlearning", "comment": null, "summary": "Federated unlearning (FU) aims to erase designated client-level, class-level, or sample-level knowledge from a global model. Existing studies commonly assume that the collaboration ends up with the unlearning operation, overlooking the follow-up situation where the federated training continues over the remaining data.We identify a critical failure mode, termed Knowledge resurfacing, by revealing that continued training can re-activate unlearned knowledge and cause the removed influence to resurface in the global model. To address this, we propose Lethe, a novel federated unlearning method that de-correlates knowledge to be unlearned from knowledge to be retained, ensuring persistent erasure during continued training.Lethe follows a Reshape--Rectify--Restore pipeline: a temporary adapter is first trained with gradient ascent on the unlearning data to obtain magnified updates, which is then used as corrective signals to diverge layer-wise rectification on the remaining updates in two streams. Finally, the adapter is removed and a short recovery stage is performed on the retained data. Our experiments show that Lethe supports unlearning in the federated system at all levels in a unified manner and maintains superior persistence (Resurfacing Rate <1% in most cases) even after numerous rounds of follow-up training.", "AI": {"tldr": "Lethe\u662f\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u9057\u5fd8\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6301\u7eed\u8bad\u7ec3\u4e2d\u5df2\u9057\u5fd8\u77e5\u8bc6\u91cd\u65b0\u6fc0\u6d3b\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u89e3\u8026\u5f85\u9057\u5fd8\u548c\u5f85\u4fdd\u7559\u77e5\u8bc6\u786e\u4fdd\u6301\u4e45\u9057\u5fd8\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u9057\u5fd8\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u9057\u5fd8\u64cd\u4f5c\u540e\u534f\u4f5c\u7ed3\u675f\uff0c\u5ffd\u7565\u4e86\u540e\u7eed\u6301\u7eed\u8bad\u7ec3\u7684\u60c5\u51b5\u3002\u7814\u7a76\u53d1\u73b0\u6301\u7eed\u8bad\u7ec3\u4f1a\u91cd\u65b0\u6fc0\u6d3b\u5df2\u9057\u5fd8\u77e5\u8bc6\uff0c\u5bfc\u81f4\u77e5\u8bc6\u91cd\u73b0\u95ee\u9898\u3002", "method": "Lethe\u91c7\u7528\u91cd\u5851-\u4fee\u6b63-\u6062\u590d\u6d41\u7a0b\uff1a\u9996\u5148\u5728\u9057\u5fd8\u6570\u636e\u4e0a\u8bad\u7ec3\u4e34\u65f6\u9002\u914d\u5668\u83b7\u53d6\u653e\u5927\u66f4\u65b0\uff0c\u7136\u540e\u5c06\u5176\u4f5c\u4e3a\u4fee\u6b63\u4fe1\u53f7\u5bf9\u5269\u4f59\u66f4\u65b0\u8fdb\u884c\u4e24\u5c42\u5206\u6d41\u4fee\u6b63\uff0c\u6700\u540e\u79fb\u9664\u9002\u914d\u5668\u5e76\u5728\u4fdd\u7559\u6570\u636e\u4e0a\u8fdb\u884c\u77ed\u671f\u6062\u590d\u3002", "result": "Lethe\u80fd\u4ee5\u7edf\u4e00\u65b9\u5f0f\u652f\u6301\u8054\u90a6\u7cfb\u7edf\u4e2d\u6240\u6709\u7ea7\u522b\u7684\u9057\u5fd8\uff0c\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u4fdd\u6301\u4f18\u8d8a\u7684\u6301\u4e45\u6027\uff08\u91cd\u73b0\u7387<1%\uff09\uff0c\u5373\u4f7f\u7ecf\u8fc7\u591a\u8f6e\u540e\u7eed\u8bad\u7ec3\u3002", "conclusion": "Lethe\u89e3\u51b3\u4e86\u8054\u90a6\u9057\u5fd8\u4e2d\u7684\u77e5\u8bc6\u91cd\u73b0\u95ee\u9898\uff0c\u901a\u8fc7\u89e3\u8026\u77e5\u8bc6\u786e\u4fdd\u6301\u4e45\u9057\u5fd8\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u9057\u5fd8\u673a\u5236\u3002"}}
{"id": "2601.22614", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22614", "abs": "https://arxiv.org/abs/2601.22614", "authors": ["Shyam Venkatasubramanian", "Sean Moushegian", "Michael Lin", "Mir Park", "Ankit Singhal", "Connor Lee"], "title": "Stabilizing Transformer Training Through Consensus", "comment": null, "summary": "Standard attention-based transformers are known to exhibit instability under learning rate overspecification during training, particularly at high learning rates. While various methods have been proposed to improve resilience to such overspecification by modifying the optimization procedure, fundamental architectural innovations to this end remain underexplored. In this work, we illustrate that the consensus mechanism, a drop-in replacement for attention, stabilizes transformer training across a wider effective range of learning rates. We formulate consensus as a graphical model and provide extensive empirical analysis demonstrating improved stability across learning rate sweeps on text, DNA, and protein modalities. We further propose a hybrid consensus-attention framework that preserves performance while improving stability. We provide theoretical analysis characterizing the properties of consensus.", "AI": {"tldr": "\u5171\u8bc6\u673a\u5236\u4f5c\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u63d0\u5347Transformer\u5728\u4e0d\u540c\u5b66\u4e60\u7387\u4e0b\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6df7\u5408\u5171\u8bc6-\u6ce8\u610f\u529b\u6846\u67b6\u6765\u5e73\u8861\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u3002", "motivation": "\u6807\u51c6\u6ce8\u610f\u529bTransformer\u5728\u8bad\u7ec3\u65f6\u5bf9\u5b66\u4e60\u7387\u8fc7\u6307\u5b9a\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5b66\u4e60\u7387\u4e0b\u3002\u867d\u7136\u5df2\u6709\u65b9\u6cd5\u901a\u8fc7\u4fee\u6539\u4f18\u5316\u8fc7\u7a0b\u6765\u6539\u5584\u8fd9\u79cd\u8fc7\u6307\u5b9a\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u6839\u672c\u6027\u7684\u67b6\u6784\u521b\u65b0\u4ecd\u7136\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u5171\u8bc6\u673a\u5236\u4f5c\u4e3a\u6ce8\u610f\u529b\u7684\u76f4\u63a5\u66ff\u4ee3\u65b9\u6848\uff0c\u5c06\u5176\u5f62\u5f0f\u5316\u4e3a\u56fe\u6a21\u578b\uff0c\u5e76\u5728\u6587\u672c\u3001DNA\u548c\u86cb\u767d\u8d28\u6a21\u6001\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u5206\u6790\u3002\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u6df7\u5408\u5171\u8bc6-\u6ce8\u610f\u529b\u6846\u67b6\u6765\u4fdd\u6301\u6027\u80fd\u540c\u65f6\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002", "result": "\u5171\u8bc6\u673a\u5236\u5728\u66f4\u5e7f\u6cdb\u7684\u6709\u6548\u5b66\u4e60\u7387\u8303\u56f4\u5185\u7a33\u5b9a\u4e86Transformer\u8bad\u7ec3\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u7684\u5b66\u4e60\u7387\u626b\u63cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6539\u8fdb\u7684\u7a33\u5b9a\u6027\u3002\u6df7\u5408\u6846\u67b6\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\u3002", "conclusion": "\u5171\u8bc6\u673a\u5236\u662f\u6ce8\u610f\u529b\u673a\u5236\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u663e\u8457\u63d0\u5347Transformer\u8bad\u7ec3\u7684\u5b66\u4e60\u7387\u9c81\u68d2\u6027\uff0c\u6df7\u5408\u6846\u67b6\u4e3a\u5e73\u8861\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22642", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22642", "abs": "https://arxiv.org/abs/2601.22642", "authors": ["Chuxue Cao", "Jinluan Yang", "Haoran Li", "Kunhao Pan", "Zijian Zhao", "Zhengyu Chen", "Yuchen Tian", "Lijun Wu", "Conghui He", "Sirui Han", "Yike Guo"], "title": "Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification", "comment": null, "summary": "Large Language Models (LLMs) show remarkable capabilities, yet their stochastic next-token prediction creates logical inconsistencies and reward hacking that formal symbolic systems avoid. To bridge this gap, we introduce a formal logic verification-guided framework that dynamically interleaves formal symbolic verification with the natural language generation process, providing real-time feedback to detect and rectify errors as they occur. Distinguished from previous neuro-symbolic methods limited by passive post-hoc validation, our approach actively penalizes intermediate fallacies during the reasoning chain. We operationalize this framework via a novel two-stage training pipeline that synergizes formal logic verification-guided supervised fine-tuning and policy optimization. Extensive evaluation on six benchmarks spanning mathematical, logical, and general reasoning demonstrates that our 7B and 14B models outperform state-of-the-art baselines by average margins of 10.4% and 14.2%, respectively. These results validate that formal verification can serve as a scalable mechanism to significantly push the performance boundaries of advanced LLM reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5f62\u5f0f\u903b\u8f91\u9a8c\u8bc1\u4e0e\u8bed\u8a00\u751f\u6210\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u53cd\u9988\u68c0\u6d4b\u548c\u7ea0\u6b63\u63a8\u7406\u9519\u8bef\uff0c\u663e\u8457\u63d0\u5347LLM\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u968f\u673a\u6027\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u4f1a\u5bfc\u81f4\u903b\u8f91\u4e0d\u4e00\u81f4\u548c\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u800c\u5f62\u5f0f\u7b26\u53f7\u7cfb\u7edf\u53ef\u4ee5\u907f\u514d\u8fd9\u4e9b\u95ee\u9898\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u9700\u8981\u5c06\u5f62\u5f0f\u903b\u8f91\u9a8c\u8bc1\u4e0e\u81ea\u7136\u8bed\u8a00\u751f\u6210\u8fc7\u7a0b\u52a8\u6001\u7ed3\u5408\u3002", "method": "\u5f15\u5165\u5f62\u5f0f\u903b\u8f91\u9a8c\u8bc1\u5f15\u5bfc\u7684\u6846\u67b6\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a8\u6001\u4ea4\u7ec7\u5f62\u5f0f\u7b26\u53f7\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u5b9e\u65f6\u53cd\u9988\u6765\u68c0\u6d4b\u548c\u7ea0\u6b63\u9519\u8bef\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1a\u5f62\u5f0f\u903b\u8f91\u9a8c\u8bc1\u5f15\u5bfc\u7684\u76d1\u7763\u5fae\u8c03\u548c\u7b56\u7565\u4f18\u5316\uff0c\u4e3b\u52a8\u60e9\u7f5a\u63a8\u7406\u94fe\u4e2d\u7684\u4e2d\u95f4\u8c2c\u8bef\u3002", "result": "\u5728\u516d\u4e2a\u6db5\u76d6\u6570\u5b66\u3001\u903b\u8f91\u548c\u4e00\u822c\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c7B\u548c14B\u6a21\u578b\u5206\u522b\u4ee5\u5e73\u574710.4%\u548c14.2%\u7684\u4f18\u52bf\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u5f62\u5f0f\u9a8c\u8bc1\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u673a\u5236\uff0c\u663e\u8457\u63a8\u52a8\u5148\u8fdbLLM\u63a8\u7406\u7684\u6027\u80fd\u8fb9\u754c\uff0c\u9a8c\u8bc1\u4e86\u5c06\u5f62\u5f0f\u903b\u8f91\u9a8c\u8bc1\u4e0e\u8bed\u8a00\u751f\u6210\u52a8\u6001\u7ed3\u5408\u7684\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.22669", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22669", "abs": "https://arxiv.org/abs/2601.22669", "authors": ["Youngjoon Lee", "Hyukjoon Lee", "Seungrok Jung", "Andy Luo", "Jinu Gong", "Yang Cao", "Joonhyuk Kang"], "title": "Beyond Fixed Rounds: Data-Free Early Stopping for Practical Federated Learning", "comment": "10 pages", "summary": "Federated Learning (FL) facilitates decentralized collaborative learning without transmitting raw data. However, reliance on fixed global rounds or validation data for hyperparameter tuning hinders practical deployment by incurring high computational costs and privacy risks. To address this, we propose a data-free early stopping framework that determines the optimal stopping point by monitoring the task vector's growth rate using solely server-side parameters. The numerical results on skin lesion/blood cell classification demonstrate that our approach is comparable to validation-based early stopping across various state-of-the-art FL methods. In particular, the proposed framework spends an average of 47/20 (skin lesion/blood cell) rounds to achieve over 12.5%/10.3% higher performance than early stopping based on validation data. To the best of our knowledge, this is the first work to propose an early stopping framework for FL methods without using any validation data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u9a8c\u8bc1\u6570\u636e\u7684\u8054\u90a6\u5b66\u4e60\u65e9\u671f\u505c\u6b62\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u63a7\u4efb\u52a1\u5411\u91cf\u7684\u589e\u957f\u7387\u6765\u786e\u5b9a\u6700\u4f18\u505c\u6b62\u70b9\uff0c\u4ec5\u4f7f\u7528\u670d\u52a1\u5668\u7aef\u53c2\u6570", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u652f\u6301\u53bb\u4e2d\u5fc3\u5316\u534f\u4f5c\u5b66\u4e60\u800c\u4e0d\u4f20\u8f93\u539f\u59cb\u6570\u636e\uff0c\u4f46\u4f9d\u8d56\u56fa\u5b9a\u7684\u5168\u5c40\u8f6e\u6b21\u6216\u9a8c\u8bc1\u6570\u636e\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u6574\u4f1a\u5e26\u6765\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u9690\u79c1\u98ce\u9669\uff0c\u963b\u788d\u5b9e\u9645\u90e8\u7f72", "method": "\u63d0\u51fa\u6570\u636e\u65e0\u5173\u7684\u65e9\u671f\u505c\u6b62\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u63a7\u4efb\u52a1\u5411\u91cf\u7684\u589e\u957f\u7387\u6765\u786e\u5b9a\u6700\u4f18\u505c\u6b62\u70b9\uff0c\u4ec5\u4f7f\u7528\u670d\u52a1\u5668\u7aef\u53c2\u6570\uff0c\u65e0\u9700\u4efb\u4f55\u9a8c\u8bc1\u6570\u636e", "result": "\u5728\u76ae\u80a4\u75c5\u53d8/\u8840\u7ec6\u80de\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4e0e\u57fa\u4e8e\u9a8c\u8bc1\u7684\u65e9\u671f\u505c\u6b62\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\uff0c\u5e73\u5747\u4ec5\u970047/20\u8f6e\u5c31\u80fd\u83b7\u5f97\u6bd4\u57fa\u4e8e\u9a8c\u8bc1\u6570\u636e\u7684\u65e9\u671f\u505c\u6b62\u9ad8\u51fa12.5%/10.3%\u7684\u6027\u80fd", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u63d0\u51fa\u65e0\u9700\u9a8c\u8bc1\u6570\u636e\u7684\u8054\u90a6\u5b66\u4e60\u65e9\u671f\u505c\u6b62\u6846\u67b6\u7684\u5de5\u4f5c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u9690\u79c1\u98ce\u9669\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c"}}
{"id": "2601.22678", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22678", "abs": "https://arxiv.org/abs/2601.22678", "authors": ["Mengfan Liu", "Da Zheng", "Junwei Su", "Chuan Wu"], "title": "Full-Graph vs. Mini-Batch Training: Comprehensive Analysis from a Batch Size and Fan-Out Size Perspective", "comment": null, "summary": "Full-graph and mini-batch Graph Neural Network (GNN) training approaches have distinct system design demands, making it crucial to choose the appropriate approach to develop. A core challenge in comparing these two GNN training approaches lies in characterizing their model performance (i.e., convergence and generalization) and computational efficiency. While a batch size has been an effective lens in analyzing such behaviors in deep neural networks (DNNs), GNNs extend this lens by introducing a fan-out size, as full-graph training can be viewed as mini-batch training with the largest possible batch size and fan-out size. However, the impact of the batch and fan-out size for GNNs remains insufficiently explored. To this end, this paper systematically compares full-graph vs. mini-batch training of GNNs through empirical and theoretical analyses from the view points of the batch size and fan-out size. Our key contributions include: 1) We provide a novel generalization analysis using the Wasserstein distance to study the impact of the graph structure, especially the fan-out size. 2) We uncover the non-isotropic effects of the batch size and the fan-out size in GNN convergence and generalization, providing practical guidance for tuning these hyperparameters under resource constraints. Finally, full-graph training does not always yield better model performance or computational efficiency than well-tuned smaller mini-batch settings. The implementation can be found in the github link: https://github.com/LIUMENGFAN-gif/GNN_fullgraph_minibatch_training.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5168\u56fe\u4e0emini-batch GNN\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6279\u5927\u5c0f\u548c\u6247\u51fa\u5927\u5c0f\u7684\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u8fd9\u4e24\u4e2a\u8d85\u53c2\u6570\u5bf9\u6536\u655b\u548c\u6cdb\u5316\u7684\u975e\u5404\u5411\u540c\u6027\u5f71\u54cd\uff0c\u53d1\u73b0\u5168\u56fe\u8bad\u7ec3\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u8c03\u4f18\u540e\u7684mini-batch\u8bbe\u7f6e\u3002", "motivation": "\u5168\u56fe\u548cmini-batch GNN\u8bad\u7ec3\u65b9\u6cd5\u5728\u7cfb\u7edf\u8bbe\u8ba1\u9700\u6c42\u4e0a\u6709\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e24\u8005\u6027\u80fd\uff08\u6536\u655b\u548c\u6cdb\u5316\uff09\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u7cfb\u7edf\u6bd4\u8f83\u3002\u6279\u5927\u5c0f\u5728DNN\u5206\u6790\u4e2d\u6709\u6548\uff0c\u4f46GNN\u5f15\u5165\u4e86\u6247\u51fa\u5927\u5c0f\u8fd9\u4e00\u65b0\u7ef4\u5ea6\uff0c\u5176\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u7ecf\u9a8c\u5206\u6790\u548c\u7406\u8bba\u5206\u6790\uff0c\u4ece\u6279\u5927\u5c0f\u548c\u6247\u51fa\u5927\u5c0f\u7684\u89c6\u89d2\u7cfb\u7edf\u6bd4\u8f83GNN\u8bad\u7ec3\u65b9\u6cd5\u3002\u4f7f\u7528Wasserstein\u8ddd\u79bb\u8fdb\u884c\u6cdb\u5316\u5206\u6790\u4ee5\u7814\u7a76\u56fe\u7ed3\u6784\uff08\u7279\u522b\u662f\u6247\u51fa\u5927\u5c0f\uff09\u7684\u5f71\u54cd\uff0c\u5e76\u63ed\u793a\u6279\u5927\u5c0f\u548c\u6247\u51fa\u5927\u5c0f\u5728\u6536\u655b\u548c\u6cdb\u5316\u4e2d\u7684\u975e\u5404\u5411\u540c\u6027\u6548\u5e94\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6279\u5927\u5c0f\u548c\u6247\u51fa\u5927\u5c0f\u5bf9GNN\u6536\u655b\u548c\u6cdb\u5316\u5177\u6709\u975e\u5404\u5411\u540c\u6027\u5f71\u54cd\uff0c\u4e3a\u8d44\u6e90\u7ea6\u675f\u4e0b\u8c03\u6574\u8fd9\u4e9b\u8d85\u53c2\u6570\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002\u5168\u56fe\u8bad\u7ec3\u5e76\u4e0d\u603b\u662f\u6bd4\u8c03\u4f18\u540e\u7684\u8f83\u5c0fmini-batch\u8bbe\u7f6e\u4ea7\u751f\u66f4\u597d\u7684\u6a21\u578b\u6027\u80fd\u6216\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u5168\u56fe\u8bad\u7ec3\u5e76\u975e\u603b\u662f\u6700\u4f18\u9009\u62e9\uff0c\u8c03\u4f18\u7684mini-batch\u8bbe\u7f6e\u53ef\u4ee5\u5728\u6a21\u578b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u5168\u56fe\u8bad\u7ec3\u3002\u6279\u5927\u5c0f\u548c\u6247\u51fa\u5927\u5c0f\u662f\u7406\u89e3GNN\u8bad\u7ec3\u52a8\u6001\u7684\u5173\u952e\u7ef4\u5ea6\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u8d44\u6e90\u7ea6\u675f\u8fdb\u884c\u5e73\u8861\u8c03\u6574\u3002"}}
{"id": "2601.22702", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22702", "abs": "https://arxiv.org/abs/2601.22702", "authors": ["Katinka Becker", "Maximilian P. Oppelt", "Tobias S. Zech", "Martin Seyferth", "Sandie Cabon", "Vanja Miskovic", "Ivan Cimrak", "Michal Kozubek", "Giuseppe D'Avenio", "Ilaria Campioni", "Jana Fehr", "Kanjar De", "Ismail Mahmoudi", "Emilio Dolgener Cantu", "Laurenz Ottmann", "Andreas Kla\u00df", "Galaad Altares", "Jackie Ma", "Alireza Salehi M.", "Nadine R. Lang-Richter", "Tobias Schaeffter", "Daniel Schwabe"], "title": "Metric Hub: A metric library and practical selection workflow for use-case-driven data quality assessment in medical AI", "comment": null, "summary": "Machine learning (ML) in medicine has transitioned from research to concrete applications aimed at supporting several medical purposes like therapy selection, monitoring and treatment. Acceptance and effective adoption by clinicians and patients, as well as regulatory approval, require evidence of trustworthiness. A major factor for the development of trustworthy AI is the quantification of data quality for AI model training and testing. We have recently proposed the METRIC-framework for systematically evaluating the suitability (fit-for-purpose) of data for medical ML for a given task. Here, we operationalize this theoretical framework by introducing a collection of data quality metrics - the metric library - for practically measuring data quality dimensions. For each metric, we provide a metric card with the most important information, including definition, applicability, examples, pitfalls and recommendations, to support the understanding and implementation of these metrics. Furthermore, we discuss strategies and provide decision trees for choosing an appropriate set of data quality metrics from the metric library given specific use cases. We demonstrate the impact of our approach exemplarily on the PTB-XL ECG-dataset. This is a first step to enable fit-for-purpose evaluation of training and test data in practice as the base for establishing trustworthy AI in medicine.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u533b\u7597AI\u6570\u636e\u8d28\u91cf\u7684METRIC\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u5177\u4f53\u5ea6\u91cf\u6307\u6807\u7684\u5ea6\u91cf\u5e93\uff0c\u4ee5\u652f\u6301\u533b\u7597\u673a\u5668\u5b66\u4e60\u4e2d\u53ef\u4fe1AI\u7684\u53d1\u5c55\u3002", "motivation": "\u533b\u7597\u673a\u5668\u5b66\u4e60\u4ece\u7814\u7a76\u8f6c\u5411\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u4fe1AI\u3002\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u662f\u53ef\u4fe1AI\u53d1\u5c55\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u5b9e\u8df5\u65b9\u6cd5\u3002", "method": "\u5c06\u7406\u8bba\u4e0a\u7684METRIC\u6846\u67b6\u64cd\u4f5c\u5316\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u5177\u4f53\u6570\u636e\u8d28\u91cf\u5ea6\u91cf\u7684\u5ea6\u91cf\u5e93\uff0c\u4e3a\u6bcf\u4e2a\u5ea6\u91cf\u63d0\u4f9b\u5ea6\u91cf\u5361\u7247\uff08\u5305\u542b\u5b9a\u4e49\u3001\u9002\u7528\u6027\u3001\u793a\u4f8b\u3001\u9677\u9631\u548c\u5efa\u8bae\uff09\uff0c\u5e76\u63d0\u4f9b\u51b3\u7b56\u6811\u5e2e\u52a9\u7528\u6237\u6839\u636e\u5177\u4f53\u7528\u4f8b\u9009\u62e9\u5408\u9002\u7684\u5ea6\u91cf\u6307\u6807\u3002", "result": "\u5728PTB-XL\u5fc3\u7535\u56fe\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u5f71\u54cd\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u548c\u4ef7\u503c\u3002", "conclusion": "\u8fd9\u662f\u5b9e\u73b0\u533b\u7597\u9886\u57df\u53ef\u4fe1AI\u7684\u91cd\u8981\u7b2c\u4e00\u6b65\uff0c\u4e3a\u5b9e\u8df5\u4e2d\u8bc4\u4f30\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u7684\u9002\u7528\u6027\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u533b\u7597AI\u7684\u4e34\u5e8a\u63a5\u53d7\u3001\u6709\u6548\u91c7\u7528\u548c\u76d1\u7ba1\u6279\u51c6\u3002"}}
{"id": "2601.22745", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22745", "abs": "https://arxiv.org/abs/2601.22745", "authors": ["Yuanhao Pu", "Defu Lian", "Enhong Chen"], "title": "Is Softmax Loss All You Need? A Principled Analysis of Softmax-family Loss", "comment": "34 pages, 3 figures", "summary": "The Softmax loss is one of the most widely employed surrogate objectives for classification and ranking tasks. To elucidate its theoretical properties, the Fenchel-Young framework situates it as a canonical instance within a broad family of surrogates. Concurrently, another line of research has addressed scalability when the number of classes is exceedingly large, in which numerous approximations have been proposed to retain the benefits of the exact objective while improving efficiency. Building on these two perspectives, we present a principled investigation of the Softmax-family losses. We examine whether different surrogates achieve consistency with classification and ranking metrics, and analyze their gradient dynamics to reveal distinct convergence behaviors. We also introduce a systematic bias-variance decomposition for approximate methods that provides convergence guarantees, and further derive a per-epoch complexity analysis, showing explicit trade-offs between effectiveness and efficiency. Extensive experiments on a representative task demonstrate a strong alignment between consistency, convergence, and empirical performance. Together, these results establish a principled foundation and offer practical guidance for loss selections in large-class machine learning applications.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86Softmax\u65cf\u635f\u5931\u51fd\u6570\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u66ff\u4ee3\u635f\u5931\u5728\u5206\u7c7b\u548c\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u4e00\u81f4\u6027\u3001\u68af\u5ea6\u52a8\u6001\u548c\u6536\u655b\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u8fd1\u4f3c\u65b9\u6cd5\u7684\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\uff0c\u5e76\u7ed9\u51fa\u4e86\u6536\u655b\u4fdd\u8bc1\u548c\u590d\u6742\u5ea6\u5206\u6790\u3002", "motivation": "Softmax\u635f\u5931\u662f\u5206\u7c7b\u548c\u6392\u5e8f\u4efb\u52a1\u4e2d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u66ff\u4ee3\u76ee\u6807\u51fd\u6570\u3002\u867d\u7136Fenchel-Young\u6846\u67b6\u5c06\u5176\u7f6e\u4e8e\u5e7f\u6cdb\u7684\u66ff\u4ee3\u51fd\u6570\u65cf\u4e2d\uff0c\u4f46\u9762\u5bf9\u7c7b\u522b\u6570\u91cf\u6781\u5927\u7684\u60c5\u51b5\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u53ef\u6269\u5c55\u6027\u8fd1\u4f3c\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u4e00\u81f4\u6027\u548c\u5b9e\u9645\u6548\u7387\u4e24\u4e2a\u89d2\u5ea6\uff0c\u4e3aSoftmax\u65cf\u635f\u5931\u51fd\u6570\u5efa\u7acb\u539f\u5219\u6027\u57fa\u7840\u3002", "method": "1) \u5206\u6790\u4e0d\u540c\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u4e0e\u5206\u7c7b\u548c\u6392\u5e8f\u6307\u6807\u7684\u4e00\u81f4\u6027\uff1b2) \u7814\u7a76\u68af\u5ea6\u52a8\u6001\u4ee5\u63ed\u793a\u4e0d\u540c\u7684\u6536\u655b\u884c\u4e3a\uff1b3) \u4e3a\u8fd1\u4f3c\u65b9\u6cd5\u5f15\u5165\u7cfb\u7edf\u7684\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\uff0c\u63d0\u4f9b\u6536\u655b\u4fdd\u8bc1\uff1b4) \u63a8\u5bfc\u6bcf\u8f6e\u590d\u6742\u5ea6\u5206\u6790\uff0c\u5c55\u793a\u6548\u679c\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u660e\u786e\u6743\u8861\u3002", "result": "\u5728\u4ee3\u8868\u6027\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u4e00\u81f4\u6027\u3001\u6536\u655b\u6027\u548c\u5b9e\u8bc1\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u5f3a\u5bf9\u9f50\u5173\u7cfb\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5927\u89c4\u6a21\u7c7b\u522b\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\u7684\u635f\u5931\u51fd\u6570\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u4e3aSoftmax\u65cf\u635f\u5931\u51fd\u6570\u5efa\u7acb\u4e86\u539f\u5219\u6027\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u66ff\u4ee3\u635f\u5931\u7684\u7406\u8bba\u6027\u8d28\uff0c\u63d0\u4f9b\u4e86\u8fd1\u4f3c\u65b9\u6cd5\u7684\u6536\u655b\u4fdd\u8bc1\u548c\u590d\u6742\u5ea6\u5206\u6790\uff0c\u4e3a\u5927\u89c4\u6a21\u7c7b\u522b\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u635f\u5931\u51fd\u6570\u9009\u62e9\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6307\u5bfc\u3002"}}
{"id": "2601.22752", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22752", "abs": "https://arxiv.org/abs/2601.22752", "authors": ["Zhiyuan Cao", "Zeyu Ma", "Chenhao Yang", "Han Zheng", "Mingang Chen"], "title": "OSNIP: Breaking the Privacy-Utility-Efficiency Trilemma in LLM Inference via Obfuscated Semantic Null Space", "comment": null, "summary": "We propose Obfuscated Semantic Null space Injection for Privacy (OSNIP), a lightweight client-side encryption framework for privacy-preserving LLM inference. Generalizing the geometric intuition of linear kernels to the high-dimensional latent space of LLMs, we formally define the ``Obfuscated Semantic Null Space'', a high-dimensional regime that preserves semantic fidelity while enforcing near-orthogonality to the original embedding. By injecting perturbations that project the original embedding into this space, OSNIP ensures privacy without any post-processing. Furthermore, OSNIP employs a key-dependent stochastic mapping that synthesizes individualized perturbation trajectories unique to each user. Evaluations on 12 generative and classification benchmarks show that OSNIP achieves state-of-the-art performance, sharply reducing attack success rates while maintaining strong model utility under strict security constraints.", "AI": {"tldr": "OSNIP\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5ba2\u6237\u7aef\u52a0\u5bc6\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u539f\u59cb\u5d4c\u5165\u6295\u5f71\u5230\"\u6df7\u6dc6\u8bed\u4e49\u96f6\u7a7a\u95f4\"\u6765\u4fdd\u62a4LLM\u63a8\u7406\u9690\u79c1\uff0c\u65e0\u9700\u540e\u5904\u7406\u5373\u53ef\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u4e3a\u4e86\u4fdd\u62a4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9690\u79c1\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u5ba2\u6237\u7aef\u52a0\u5bc6\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u8bed\u4e49\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u63d0\u51fa\"\u6df7\u6dc6\u8bed\u4e49\u96f6\u7a7a\u95f4\"\u6982\u5ff5\uff0c\u5c06\u7ebf\u6027\u6838\u7684\u51e0\u4f55\u76f4\u89c9\u63a8\u5e7f\u5230LLM\u7684\u9ad8\u7ef4\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u6ce8\u5165\u6270\u52a8\u5c06\u539f\u59cb\u5d4c\u5165\u6295\u5f71\u5230\u8fd9\u4e2a\u7a7a\u95f4\u4e2d\uff0c\u540c\u65f6\u91c7\u7528\u5bc6\u94a5\u76f8\u5173\u7684\u968f\u673a\u6620\u5c04\u4e3a\u6bcf\u4e2a\u7528\u6237\u751f\u6210\u72ec\u7279\u7684\u6270\u52a8\u8f68\u8ff9\u3002", "result": "\u572812\u4e2a\u751f\u6210\u548c\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOSNIP\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u5728\u4e25\u683c\u7684\u5b89\u5168\u7ea6\u675f\u4e0b\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u6a21\u578b\u6548\u7528\u3002", "conclusion": "OSNIP\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4LLM\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6df7\u6dc6\u8bed\u4e49\u96f6\u7a7a\u95f4\u6ce8\u5165\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6548\u7528\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2601.22757", "categories": ["cs.LG", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.22757", "abs": "https://arxiv.org/abs/2601.22757", "authors": ["Dong Xu", "Qihua Pan", "Sisi Yuan", "Jianqiang Li", "Zexuan Zhu", "Junkai Ji"], "title": "Unveiling Scaling Behaviors in Molecular Language Models: Effects of Model Size, Data, and Representation", "comment": "34 pages, 51 figures", "summary": "Molecular generative models, often employing GPT-style language modeling on molecular string representations, have shown promising capabilities when scaled to large datasets and model sizes. However, it remains unclear and subject to debate whether these models adhere to predictable scaling laws under fixed computational budgets, which is a crucial understanding for optimally allocating resources between model size, data volume, and molecular representation. In this study, we systematically investigate the scaling behavior of molecular language models across both pretraining and downstream tasks. We train 300 models and conduct over 10,000 experiments, rigorously controlling compute budgets while independently varying model size, number of training tokens, and molecular representation. Our results demonstrate clear scaling laws in molecular models for both pretraining and downstream transfer, reveal the substantial impact of molecular representation on performance, and explain previously observed inconsistencies in scaling behavior for molecular generation. Additionally, we publicly release the largest library of molecular language models to date to facilitate future research and development. Code and models are available at https://github.com/SZU-ADDG/MLM-Scaling.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u7814\u7a76\u4e86\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u901a\u8fc7\u8bad\u7ec3300\u4e2a\u6a21\u578b\u548c\u8d85\u8fc710,000\u6b21\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u6a21\u578b\u5927\u5c0f\u3001\u8bad\u7ec3\u6570\u636e\u91cf\u548c\u5206\u5b50\u8868\u793a\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u89c4\u5f8b\u3002", "motivation": "\u5206\u5b50\u751f\u6210\u6a21\u578b\u867d\u7136\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u6a21\u578b\u5c3a\u5bf8\u4e0a\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u9075\u5faa\u53ef\u9884\u6d4b\u7684\u7f29\u653e\u89c4\u5f8b\u3002\u7406\u89e3\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u5982\u4f55\u6700\u4f18\u5206\u914d\u6a21\u578b\u5927\u5c0f\u3001\u6570\u636e\u91cf\u548c\u5206\u5b50\u8868\u793a\u7684\u8d44\u6e90\u5206\u914d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u8bad\u7ec3\u4e86300\u4e2a\u6a21\u578b\uff0c\u8fdb\u884c\u4e86\u8d85\u8fc710,000\u6b21\u5b9e\u9a8c\uff0c\u4e25\u683c\u63a7\u5236\u8ba1\u7b97\u9884\u7b97\uff0c\u540c\u65f6\u72ec\u7acb\u53d8\u5316\u6a21\u578b\u5927\u5c0f\u3001\u8bad\u7ec3token\u6570\u91cf\u548c\u5206\u5b50\u8868\u793a\uff0c\u7cfb\u7edf\u7814\u7a76\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u548c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u7f29\u653e\u884c\u4e3a\u3002", "result": "\u7ed3\u679c\u8868\u660e\u5206\u5b50\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u548c\u4e0b\u6e38\u8fc1\u79fb\u4e2d\u90fd\u5b58\u5728\u6e05\u6670\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u5206\u5b50\u8868\u793a\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u89e3\u91ca\u4e86\u5148\u524d\u89c2\u5bdf\u5230\u7684\u5206\u5b50\u751f\u6210\u7f29\u653e\u884c\u4e3a\u4e0d\u4e00\u81f4\u6027\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u5e93\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u884c\u4e3a\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u7406\u89e3\uff0c\u63ed\u793a\u4e86\u5206\u5b50\u8868\u793a\u5728\u7f29\u653e\u89c4\u5f8b\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6a21\u578b\u8d44\u6e90\u548c\u5b9e\u9a8c\u57fa\u7840\u3002"}}
{"id": "2601.22766", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22766", "abs": "https://arxiv.org/abs/2601.22766", "authors": ["Saul Santos", "Nuno Gon\u00e7alves", "Daniel C. McNamee", "Andr\u00e9 F. T Martins"], "title": "Sparse Attention as Compact Kernel Regression", "comment": "16 pages, 5 figures", "summary": "Recent work has revealed a link between self-attention mechanisms in transformers and test-time kernel regression via the Nadaraya-Watson estimator, with standard softmax attention corresponding to a Gaussian kernel. However, a kernel-theoretic understanding of sparse attention mechanisms is currently missing. In this paper, we establish a formal correspondence between sparse attention and compact (bounded support) kernels. We show that normalized ReLU and sparsemax attention arise from Epanechnikov kernel regression under fixed and adaptive normalizations, respectively. More generally, we demonstrate that widely used kernels in nonparametric density estimation -- including Epanechnikov, biweight, and triweight -- correspond to $\u03b1$-entmax attention with $\u03b1= 1 + \\frac{1}{n}$ for $n \\in \\mathbb{N}$, while the softmax/Gaussian relationship emerges in the limit $n \\to \\infty$. This unified perspective explains how sparsity naturally emerges from kernel design and provides principled alternatives to heuristic top-$k$ attention and other associative memory mechanisms. Experiments with a kernel-regression-based variant of transformers -- Memory Mosaics -- show that kernel-based sparse attention achieves competitive performance on language modeling, in-context learning, and length generalization tasks, offering a principled framework for designing attention mechanisms.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u7d27\u652f\u6838\u51fd\u6570\u4e4b\u95f4\u7684\u7406\u8bba\u5bf9\u5e94\u5173\u7cfb\uff0c\u5efa\u7acb\u4e86\u03b1-entmax\u6ce8\u610f\u529b\u4e0eEpanechnikov\u3001biweight\u3001triweight\u7b49\u6838\u51fd\u6570\u7684\u6570\u5b66\u8054\u7cfb\uff0c\u4e3a\u7a00\u758f\u6ce8\u610f\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5df2\u7ecf\u5efa\u7acb\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e0eNadaraya-Watson\u6838\u56de\u5f52\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u6807\u51c6softmax\u6ce8\u610f\u529b\u5bf9\u5e94\u9ad8\u65af\u6838\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u7f3a\u4e4f\u6838\u7406\u8bba\u7684\u7406\u89e3\uff0c\u9700\u8981\u5efa\u7acb\u7a00\u758f\u6ce8\u610f\u529b\u4e0e\u7d27\u652f\u6838\u51fd\u6570\u4e4b\u95f4\u7684\u5f62\u5f0f\u5316\u5bf9\u5e94\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5efa\u7acb\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u7d27\u652f\u6838\u51fd\u6570\u4e4b\u95f4\u7684\u6570\u5b66\u5bf9\u5e94\u5173\u7cfb\u3002\u5177\u4f53\u8bc1\u660e\u5f52\u4e00\u5316ReLU\u548csparsemax\u6ce8\u610f\u529b\u5206\u522b\u5bf9\u5e94\u56fa\u5b9a\u5f52\u4e00\u5316\u548c\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u4e0b\u7684Epanechnikov\u6838\u56de\u5f52\u3002\u66f4\u4e00\u822c\u5730\uff0c\u5c55\u793a\u975e\u53c2\u6570\u5bc6\u5ea6\u4f30\u8ba1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u6838\u51fd\u6570\uff08Epanechnikov\u3001biweight\u3001triweight\uff09\u5bf9\u5e94\u03b1-entmax\u6ce8\u610f\u529b\uff0c\u5176\u4e2d\u03b1=1+1/n\uff08n\u2208\u2115\uff09\uff0c\u800csoftmax/\u9ad8\u65af\u5173\u7cfb\u5728n\u2192\u221e\u65f6\u51fa\u73b0\u3002", "result": "\u5efa\u7acb\u4e86\u7a00\u758f\u6ce8\u610f\u529b\u4e0e\u7d27\u652f\u6838\u51fd\u6570\u7684\u7406\u8bba\u5bf9\u5e94\u5173\u7cfb\uff0c\u89e3\u91ca\u4e86\u7a00\u758f\u6027\u5982\u4f55\u4ece\u6838\u8bbe\u8ba1\u4e2d\u81ea\u7136\u4ea7\u751f\u3002\u901a\u8fc7\u57fa\u4e8e\u6838\u56de\u5f52\u7684Transformer\u53d8\u4f53Memory Mosaics\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u57fa\u4e8e\u6838\u7684\u7a00\u758f\u6ce8\u610f\u529b\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u957f\u5ea6\u6cdb\u5316\u4efb\u52a1\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6838\u7406\u8bba\u89c6\u89d2\uff0c\u89e3\u91ca\u4e86\u7a00\u758f\u6027\u7684\u7406\u8bba\u6765\u6e90\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u66ff\u4ee3\u4e86\u542f\u53d1\u5f0f\u7684top-k\u6ce8\u610f\u529b\u548c\u5176\u4ed6\u5173\u8054\u8bb0\u5fc6\u673a\u5236\u3002"}}
{"id": "2601.22801", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22801", "abs": "https://arxiv.org/abs/2601.22801", "authors": ["\u00d6mer Veysel \u00c7a\u011fatan", "Bar\u0131\u015f Akg\u00fcn", "G\u00f6zde G\u00fcl \u015eahin", "Xuandong Zhao"], "title": "Clipping-Free Policy Optimization for Large Language Models", "comment": "23 pages, 10 tables, 8 figures", "summary": "Reinforcement learning has become central to post-training large language models, yet dominant algorithms rely on clipping mechanisms that introduce optimization issues at scale, including zero-gradient regions, reward hacking, and training instability. We propose Clipping-Free Policy Optimization (CFPO), which replaces heuristic clipping with a convex quadratic penalty derived from Total Variation divergence constraints, yielding an everywhere-differentiable objective that enforces stable policy updates without hard boundaries. We evaluate CFPO across both reasoning and alignment settings. In reasoning, CFPO matches clipping-based methods on downstream benchmarks while extending the stable training regime. In alignment, CFPO mitigates verbosity exploitation and reduces capability degradation, while achieving competitive instruction-following performance. CFPO requires only a one-line code change and no additional hyperparameters. Our results suggest that CFPO is a promising drop-in alternative to clipping-based methods for LLM post-training.", "AI": {"tldr": "CFPO\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u526a\u88c1\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u51f8\u4e8c\u6b21\u60e9\u7f5a\u66ff\u4ee3\u4f20\u7edf\u526a\u88c1\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u68af\u5ea6\u6d88\u5931\u3001\u5956\u52b1\u653b\u51fb\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4f9d\u8d56\u526a\u88c1\u673a\u5236\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u4e2d\u4f1a\u5f15\u5165\u4f18\u5316\u95ee\u9898\uff0c\u5305\u62ec\u96f6\u68af\u5ea6\u533a\u57df\u3001\u5956\u52b1\u653b\u51fb\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5b9a\u3001\u65e0\u526a\u88c1\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "CFPO\u4f7f\u7528\u57fa\u4e8e\u603b\u53d8\u5dee\u6563\u5ea6\u7ea6\u675f\u7684\u51f8\u4e8c\u6b21\u60e9\u7f5a\u66ff\u4ee3\u542f\u53d1\u5f0f\u526a\u88c1\uff0c\u4ea7\u751f\u5904\u5904\u53ef\u5fae\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5b9e\u73b0\u65e0\u786c\u8fb9\u754c\u7684\u7a33\u5b9a\u7b56\u7565\u66f4\u65b0\u3002", "result": "\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cCFPO\u4e0e\u526a\u88c1\u65b9\u6cd5\u5728\u4e0b\u6e38\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u76f8\u5f53\uff0c\u540c\u65f6\u6269\u5c55\u4e86\u7a33\u5b9a\u8bad\u7ec3\u8303\u56f4\uff1b\u5728\u5bf9\u9f50\u4efb\u52a1\u4e2d\uff0cCFPO\u7f13\u89e3\u4e86\u5197\u957f\u5229\u7528\u95ee\u9898\uff0c\u51cf\u5c11\u4e86\u80fd\u529b\u9000\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u7684\u6307\u4ee4\u8ddf\u968f\u6027\u80fd\u3002", "conclusion": "CFPO\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u5373\u63d2\u5373\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u53ea\u9700\u4e00\u884c\u4ee3\u7801\u66f4\u6539\u4e14\u65e0\u9700\u989d\u5916\u8d85\u53c2\u6570\uff0c\u53ef\u66ff\u4ee3\u526a\u88c1\u65b9\u6cd5\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u3002"}}
{"id": "2601.22813", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22813", "abs": "https://arxiv.org/abs/2601.22813", "authors": ["Andrei Panferov", "Erik Schultheis", "Soroush Tabesh", "Dan Alistarh"], "title": "Quartet II: Accurate LLM Pre-Training in NVFP4 by Improved Unbiased Gradient Estimation", "comment": null, "summary": "The NVFP4 lower-precision format, supported in hardware by NVIDIA Blackwell GPUs, promises to allow, for the first time, end-to-end fully-quantized pre-training of massive models such as LLMs. Yet, existing quantized training methods still sacrifice some of the representation capacity of this format in favor of more accurate unbiased quantized gradient estimation by stochastic rounding (SR), losing noticeable accuracy relative to standard FP16 and FP8 training. In this paper, improve the state of the art for quantized training in NVFP4 via a novel unbiased quantization routine for micro-scaled formats, called MS-EDEN, that has more than 2x lower quantization error than SR. We integrate it into a novel fully-NVFP4 quantization scheme for linear layers, called Quartet II. We show analytically that Quartet II achieves consistently better gradient estimation across all major matrix multiplications, both on the forward and on the backward passes. In addition, our proposal synergizes well with recent training improvements aimed specifically at NVFP4. We further validate Quartet II on end-to-end LLM training with up to 1.9B parameters on 38B tokens. We provide kernels for execution on NVIDIA Blackwell GPUs with up to 4.2x speedup over BF16. Our code is available at https://github.com/IST-DASLab/Quartet-II .", "AI": {"tldr": "\u63d0\u51faMS-EDEN\u91cf\u5316\u65b9\u6cd5\u548cQuartet II\u65b9\u6848\uff0c\u5728NVFP4\u683c\u5f0f\u4e0b\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u91cf\u5316\u8bad\u7ec3\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u964d\u4f4e2\u500d\u91cf\u5316\u8bef\u5dee\uff0c\u57281.9B\u53c2\u6570LLM\u8bad\u7ec3\u4e2d\u9a8c\u8bc1\u6548\u679c\uff0c\u63d0\u4f9bBlackwell GPU\u5185\u6838\u5b9e\u73b04.2\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u91cf\u5316\u8bad\u7ec3\u65b9\u6cd5\u5728\u4f7f\u7528NVFP4\u683c\u5f0f\u65f6\uff0c\u4e3a\u4e86\u83b7\u5f97\u66f4\u51c6\u786e\u7684\u65e0\u504f\u68af\u5ea6\u4f30\u8ba1\uff08\u901a\u8fc7\u968f\u673a\u820d\u5165\uff09\uff0c\u727a\u7272\u4e86\u683c\u5f0f\u7684\u8868\u793a\u80fd\u529b\uff0c\u5bfc\u81f4\u76f8\u5bf9\u4e8eFP16\u548cFP8\u8bad\u7ec3\u5b58\u5728\u660e\u663e\u7684\u7cbe\u5ea6\u635f\u5931\u3002", "method": "\u63d0\u51faMS-EDEN\uff08\u5fae\u5c3a\u5ea6\u683c\u5f0f\u7684\u65e0\u504f\u91cf\u5316\u65b9\u6cd5\uff09\uff0c\u76f8\u6bd4\u968f\u673a\u820d\u5165\u964d\u4f4e2\u500d\u4ee5\u4e0a\u91cf\u5316\u8bef\u5dee\uff1b\u5c06\u5176\u96c6\u6210\u5230Quartet II\u5168NVFP4\u91cf\u5316\u65b9\u6848\u4e2d\uff0c\u7528\u4e8e\u7ebf\u6027\u5c42\u7684\u91cf\u5316\u8bad\u7ec3\uff1b\u4e0e\u9488\u5bf9NVFP4\u7684\u6700\u65b0\u8bad\u7ec3\u6539\u8fdb\u6280\u672f\u534f\u540c\u5de5\u4f5c\u3002", "result": "\u5206\u6790\u8bc1\u660eQuartet II\u5728\u6240\u6709\u4e3b\u8981\u77e9\u9635\u4e58\u6cd5\uff08\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\uff09\u4e2d\u5b9e\u73b0\u66f4\u4f18\u7684\u68af\u5ea6\u4f30\u8ba1\uff1b\u57281.9B\u53c2\u6570\u300138B tokens\u7684LLM\u7aef\u5230\u7aef\u8bad\u7ec3\u4e2d\u9a8c\u8bc1\u6548\u679c\uff1b\u63d0\u4f9bNVIDIA Blackwell GPU\u5185\u6838\uff0c\u76f8\u6bd4BF16\u5b9e\u73b04.2\u500d\u52a0\u901f\u3002", "conclusion": "MS-EDEN\u548cQuartet II\u65b9\u6848\u663e\u8457\u6539\u8fdb\u4e86NVFP4\u91cf\u5316\u8bad\u7ec3\u7684\u72b6\u6001\uff0c\u5728\u4fdd\u6301\u65e0\u504f\u68af\u5ea6\u4f30\u8ba1\u7684\u540c\u65f6\u964d\u4f4e\u91cf\u5316\u8bef\u5dee\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u6a21\u578b\u7684\u9ad8\u6548\u91cf\u5316\u9884\u8bad\u7ec3\u3002"}}
{"id": "2601.22816", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22816", "abs": "https://arxiv.org/abs/2601.22816", "authors": ["Markus Mueller", "Kathrin Gruber", "Dennis Fok"], "title": "Cascaded Flow Matching for Heterogeneous Tabular Data with Mixed-Type Features", "comment": null, "summary": "Advances in generative modeling have recently been adapted to tabular data containing discrete and continuous features. However, generating mixed-type features that combine discrete states with an otherwise continuous distribution in a single feature remains challenging. We advance the state-of-the-art in diffusion models for tabular data with a cascaded approach. We first generate a low-resolution version of a tabular data row, that is, the collection of the purely categorical features and a coarse categorical representation of numerical features. Next, this information is leveraged in the high-resolution flow matching model via a novel guided conditional probability path and data-dependent coupling. The low-resolution representation of numerical features explicitly accounts for discrete outcomes, such as missing or inflated values, and therewith enables a more faithful generation of mixed-type features. We formally prove that this cascade tightens the transport cost bound. The results indicate that our model generates significantly more realistic samples and captures distributional details more accurately, for example, the detection score increases by 40%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ea7\u8054\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u5305\u542b\u79bb\u6563\u548c\u8fde\u7eed\u7279\u5f81\u7684\u8868\u683c\u6570\u636e\uff0c\u7279\u522b\u89e3\u51b3\u4e86\u6df7\u5408\u7c7b\u578b\u7279\u5f81\u7684\u751f\u6210\u6311\u6218\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u5728\u8868\u683c\u6570\u636e\u751f\u6210\u65b9\u9762\u5df2\u6709\u8fdb\u5c55\uff0c\u4f46\u6df7\u5408\u7c7b\u578b\u7279\u5f81\uff08\u540c\u65f6\u5305\u542b\u79bb\u6563\u72b6\u6001\u548c\u8fde\u7eed\u5206\u5e03\u7684\u7279\u5f81\uff09\u7684\u751f\u6210\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u751f\u6210\u8fd9\u7c7b\u7279\u5f81\u3002", "method": "\u91c7\u7528\u7ea7\u8054\u65b9\u6cd5\uff1a\u9996\u5148\u751f\u6210\u8868\u683c\u884c\u7684\u4f4e\u5206\u8fa8\u7387\u7248\u672c\uff08\u7eaf\u5206\u7c7b\u7279\u5f81\u548c\u6570\u503c\u7279\u5f81\u7684\u7c97\u7565\u5206\u7c7b\u8868\u793a\uff09\uff0c\u7136\u540e\u901a\u8fc7\u65b0\u9896\u7684\u5f15\u5bfc\u6761\u4ef6\u6982\u7387\u8def\u5f84\u548c\u6570\u636e\u4f9d\u8d56\u8026\u5408\uff0c\u5728\u6d41\u5339\u914d\u6a21\u578b\u4e2d\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u3002", "result": "\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u6837\u672c\u7684\u771f\u5b9e\u6027\uff0c\u66f4\u51c6\u786e\u5730\u6355\u6349\u4e86\u5206\u5e03\u7ec6\u8282\uff0c\u68c0\u6d4b\u5206\u6570\u63d0\u9ad8\u4e8640%\u3002\u7406\u8bba\u8bc1\u660e\u8be5\u7ea7\u8054\u65b9\u6cd5\u6536\u7d27\u4f20\u8f93\u6210\u672c\u754c\u9650\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ea7\u8054\u6269\u6563\u6a21\u578b\u5728\u8868\u683c\u6570\u636e\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u7279\u522b\u5728\u6df7\u5408\u7c7b\u578b\u7279\u5f81\u751f\u6210\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u8868\u683c\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22848", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22848", "abs": "https://arxiv.org/abs/2601.22848", "authors": ["Camilo Carvajal Reyes", "Felipe Tobar"], "title": "Unconditional flow-based time series generation with equivariance-regularised latent spaces", "comment": "Accepted at ICASSP 2026", "summary": "Flow-based models have proven successful for time-series generation, particularly when defined in lower-dimensional latent spaces that enable efficient sampling. However, how to design latent representations with desirable equivariance properties for time-series generative modelling remains underexplored. In this work, we propose a latent flow-matching framework in which equivariance is explicitly encouraged through a simple regularisation of a pre-trained autoencoder. Specifically, we introduce an equivariance loss that enforces consistency between transformed signals and their reconstructions, and use it to fine-tune latent spaces with respect to basic time-series transformations such as translation and amplitude scaling. We show that these equivariance-regularised latent spaces improve generation quality while preserving the computational advantages of latent flow models. Experiments on multiple real-world datasets demonstrate that our approach consistently outperforms existing diffusion-based baselines in standard time-series generation metrics, while achieving orders-of-magnitude faster sampling. These results highlight the practical benefits of incorporating geometric inductive biases into latent generative models for time series.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6b63\u5219\u5316\u9884\u8bad\u7ec3\u81ea\u7f16\u7801\u5668\u6765\u9f13\u52b1\u6f5c\u5728\u7a7a\u95f4\u7b49\u53d8\u6027\u7684\u6d41\u5339\u914d\u6846\u67b6\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u751f\u6210\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u751f\u6210\u8d28\u91cf", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6d41\u7684\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u6a21\u578b\u901a\u5e38\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u4ee5\u5b9e\u73b0\u9ad8\u6548\u91c7\u6837\uff0c\u4f46\u5982\u4f55\u8bbe\u8ba1\u5177\u6709\u7406\u60f3\u7b49\u53d8\u6027\u8d28\u7684\u6f5c\u5728\u8868\u793a\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22", "method": "\u63d0\u51fa\u6f5c\u5728\u6d41\u5339\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u7b49\u53d8\u6027\u635f\u5931\u5bf9\u9884\u8bad\u7ec3\u81ea\u7f16\u7801\u5668\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u5f3a\u5236\u53d8\u6362\u4fe1\u53f7\u4e0e\u5176\u91cd\u6784\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u57fa\u672c\u53d8\u6362\uff08\u5982\u5e73\u79fb\u548c\u5e45\u5ea6\u7f29\u653e\uff09\u5fae\u8c03\u6f5c\u5728\u7a7a\u95f4", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u6570\u91cf\u7ea7\u66f4\u5feb\u7684\u91c7\u6837\u901f\u5ea6", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u5c06\u51e0\u4f55\u5f52\u7eb3\u504f\u7f6e\u7eb3\u5165\u65f6\u95f4\u5e8f\u5217\u6f5c\u5728\u751f\u6210\u6a21\u578b\u7684\u5b9e\u9645\u4f18\u52bf\uff0c\u7b49\u53d8\u6027\u6b63\u5219\u5316\u7684\u6f5c\u5728\u7a7a\u95f4\u5728\u4fdd\u6301\u6f5c\u5728\u6d41\u6a21\u578b\u8ba1\u7b97\u4f18\u52bf\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u751f\u6210\u8d28\u91cf"}}
{"id": "2601.22856", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22856", "abs": "https://arxiv.org/abs/2601.22856", "authors": ["Yilong Zuo", "Xunkai Li", "Zhihan Zhang", "Qiangqiang Dai", "Ronghua Li", "Guoren Wang"], "title": "OptiMAG: Structure-Semantic Alignment via Unbalanced Optimal Transport", "comment": null, "summary": "Multimodal Attributed Graphs (MAGs) have been widely adopted for modeling complex systems by integrating multi-modal information, such as text and images, on nodes. However, we identify a discrepancy between the implicit semantic structure induced by different modality embeddings and the explicit graph structure. For instance, neighbors in the explicit graph structure may be close in one modality but distant in another. Since existing methods typically perform message passing over the fixed explicit graph structure, they inadvertently aggregate dissimilar features, introducing modality-specific noise and impeding effective node representation learning. To address this, we propose OptiMAG, an Unbalanced Optimal Transport-based regularization framework. OptiMAG employs the Fused Gromov-Wasserstein distance to explicitly guide cross-modal structural consistency within local neighborhoods, effectively mitigating structural-semantic conflicts. Moreover, a KL divergence penalty enables adaptive handling of cross-modal inconsistencies. This framework can be seamlessly integrated into existing multimodal graph models, acting as an effective drop-in regularizer. Experiments demonstrate that OptiMAG consistently outperforms baselines across multiple tasks, ranging from graph-centric tasks (e.g., node classification, link prediction) to multimodal-centric generation tasks (e.g., graph2text, graph2image). The source code will be available upon acceptance.", "AI": {"tldr": "OptiMAG\uff1a\u57fa\u4e8e\u4e0d\u5e73\u8861\u6700\u4f18\u4f20\u8f93\u7684\u6b63\u5219\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u5c5e\u6027\u56fe\u4e2d\u663e\u5f0f\u56fe\u7ed3\u6784\u4e0e\u9690\u5f0f\u8bed\u4e49\u7ed3\u6784\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7Fused Gromov-Wasserstein\u8ddd\u79bb\u5f15\u5bfc\u8de8\u6a21\u6001\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u63d0\u5347\u8282\u70b9\u8868\u793a\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u591a\u6a21\u6001\u5c5e\u6027\u56fe\uff08MAGs\uff09\u4e2d\u663e\u5f0f\u56fe\u7ed3\u6784\u4e0e\u4e0d\u540c\u6a21\u6001\u5d4c\u5165\u8bf1\u5bfc\u7684\u9690\u5f0f\u8bed\u4e49\u7ed3\u6784\u5b58\u5728\u4e0d\u4e00\u81f4\uff0c\u4f8b\u5982\u56fe\u4e2d\u90bb\u5c45\u5728\u4e00\u4e2a\u6a21\u6001\u4e2d\u76f8\u4f3c\u4f46\u5728\u53e6\u4e00\u4e2a\u6a21\u6001\u4e2d\u53ef\u80fd\u4e0d\u76f8\u4f3c\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u56fa\u5b9a\u663e\u5f0f\u56fe\u7ed3\u6784\u4e0a\u8fdb\u884c\u6d88\u606f\u4f20\u9012\u65f6\uff0c\u4f1a\u805a\u5408\u4e0d\u76f8\u4f3c\u7684\u7279\u5f81\uff0c\u5f15\u5165\u6a21\u6001\u7279\u5b9a\u566a\u58f0\uff0c\u963b\u788d\u6709\u6548\u7684\u8282\u70b9\u8868\u793a\u5b66\u4e60\u3002", "method": "\u63d0\u51faOptiMAG\u6846\u67b6\uff0c\u57fa\u4e8e\u4e0d\u5e73\u8861\u6700\u4f18\u4f20\u8f93\uff0c\u4f7f\u7528Fused Gromov-Wasserstein\u8ddd\u79bb\u5728\u5c40\u90e8\u90bb\u57df\u5185\u663e\u5f0f\u5f15\u5bfc\u8de8\u6a21\u6001\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u7f13\u89e3\u7ed3\u6784-\u8bed\u4e49\u51b2\u7a81\u3002\u540c\u65f6\u4f7f\u7528KL\u6563\u5ea6\u60e9\u7f5a\u81ea\u9002\u5e94\u5904\u7406\u8de8\u6a21\u6001\u4e0d\u4e00\u81f4\u6027\u3002\u8be5\u6846\u67b6\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u6b63\u5219\u5316\u5668\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u591a\u6a21\u6001\u56fe\u6a21\u578b\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660eOptiMAG\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u56fe\u4e2d\u5fc3\u4efb\u52a1\uff08\u5982\u8282\u70b9\u5206\u7c7b\u3001\u94fe\u63a5\u9884\u6d4b\uff09\u548c\u591a\u6a21\u6001\u4e2d\u5fc3\u751f\u6210\u4efb\u52a1\uff08\u5982\u56fe\u5230\u6587\u672c\u3001\u56fe\u5230\u56fe\u50cf\u751f\u6210\uff09\u3002", "conclusion": "OptiMAG\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5c5e\u6027\u56fe\u4e2d\u7684\u7ed3\u6784-\u8bed\u4e49\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u80fd\u591f\u63d0\u5347\u73b0\u6709\u591a\u6a21\u6001\u56fe\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.22891", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22891", "abs": "https://arxiv.org/abs/2601.22891", "authors": ["Jacques Cloete", "Mathias Jackermeier", "Ioannis Havoutis", "Alessandro Abate"], "title": "PlatoLTL: Learning to Generalize Across Symbols in LTL Instructions for Multi-Task RL", "comment": "11 pages, 3 figures (main paper). 14 pages, 10 figures (appendix)", "summary": "A central challenge in multi-task reinforcement learning (RL) is to train generalist policies capable of performing tasks not seen during training. To facilitate such generalization, linear temporal logic (LTL) has recently emerged as a powerful formalism for specifying structured, temporally extended tasks to RL agents. While existing approaches to LTL-guided multi-task RL demonstrate successful generalization across LTL specifications, they are unable to generalize to unseen vocabularies of propositions (or \"symbols\"), which describe high-level events in LTL. We present PlatoLTL, a novel approach that enables policies to zero-shot generalize not only compositionally across LTL formula structures, but also parametrically across propositions. We achieve this by treating propositions as instances of parameterized predicates rather than discrete symbols, allowing policies to learn shared structure across related propositions. We propose a novel architecture that embeds and composes predicates to represent LTL specifications, and demonstrate successful zero-shot generalization to novel propositions and tasks across challenging environments.", "AI": {"tldr": "PlatoLTL\uff1a\u4e00\u79cd\u65b0\u9896\u7684\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u4e0d\u4ec5\u80fd\u5728LTL\u516c\u5f0f\u7ed3\u6784\u4e0a\u7ec4\u5408\u6cdb\u5316\uff0c\u8fd8\u80fd\u5728\u547d\u9898\u4e0a\u53c2\u6570\u5316\u6cdb\u5316\u3002", "motivation": "\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u662f\u8bad\u7ec3\u80fd\u591f\u6267\u884c\u8bad\u7ec3\u4e2d\u672a\u89c1\u4efb\u52a1\u7684\u901a\u7528\u7b56\u7565\u3002\u73b0\u6709LTL\u5f15\u5bfc\u7684\u591a\u4efb\u52a1RL\u65b9\u6cd5\u867d\u7136\u80fd\u5728LTL\u89c4\u8303\u4e0a\u6210\u529f\u6cdb\u5316\uff0c\u4f46\u65e0\u6cd5\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u547d\u9898\u8bcd\u6c47\u8868\uff08\u63cf\u8ff0LTL\u4e2d\u9ad8\u5c42\u4e8b\u4ef6\u7684\"\u7b26\u53f7\"\uff09\u3002", "method": "\u5c06\u547d\u9898\u89c6\u4e3a\u53c2\u6570\u5316\u8c13\u8bcd\u7684\u5b9e\u4f8b\u800c\u975e\u79bb\u6563\u7b26\u53f7\uff0c\u4f7f\u7b56\u7565\u80fd\u591f\u5b66\u4e60\u76f8\u5173\u547d\u9898\u95f4\u7684\u5171\u4eab\u7ed3\u6784\u3002\u63d0\u51fa\u65b0\u9896\u7684\u67b6\u6784\u6765\u5d4c\u5165\u548c\u7ec4\u5408\u8c13\u8bcd\u4ee5\u8868\u793aLTL\u89c4\u8303\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u65b0\u9896\u547d\u9898\u548c\u4efb\u52a1\u7684\u96f6\u6837\u672c\u6cdb\u5316\u3002", "conclusion": "PlatoLTL\u65b9\u6cd5\u901a\u8fc7\u5c06\u547d\u9898\u53c2\u6570\u5316\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5904\u7406\u672a\u89c1\u8fc7\u7684\u547d\u9898\u8bcd\u6c47\u8868\uff0c\u4e3a\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22895", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22895", "abs": "https://arxiv.org/abs/2601.22895", "authors": ["Aya Laajil", "Elnura Zhalieva", "Naomi Desobry", "Souhaib Ben Taieb"], "title": "Calibrated Multivariate Distributional Regression with Pre-Rank Regularization", "comment": "arXiv admin note: text overlap with arXiv:2510.21273", "summary": "The goal of probabilistic prediction is to issue predictive distributions that are as informative as possible, subject to being calibrated. Despite substantial progress in the univariate setting, achieving multivariate calibration remains challenging. Recent work has introduced pre-rank functions, scalar projections of multivariate forecasts and observations, as flexible diagnostics for assessing specific aspects of multivariate calibration, but their use has largely been limited to post-hoc evaluation. We propose a regularization-based calibration method that enforces multivariate calibration during training of multivariate distributional regression models using pre-rank functions. We further introduce a novel PCA-based pre-rank that projects predictions onto principal directions of the predictive distribution. Through simulation studies and experiments on 18 real-world multi-output regression datasets, we show that the proposed approach substantially improves multivariate pre-rank calibration without compromising predictive accuracy, and that the PCA pre-rank reveals dependence-structure misspecifications that are not detected by existing pre-ranks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u591a\u53d8\u91cf\u6821\u51c6\u65b9\u6cd5\uff0c\u4f7f\u7528\u9884\u6392\u5e8f\u51fd\u6570\u5728\u8bad\u7ec3\u671f\u95f4\u5f3a\u5236\u591a\u53d8\u91cf\u6821\u51c6\uff0c\u5e76\u5f15\u5165\u57fa\u4e8ePCA\u7684\u65b0\u9884\u6392\u5e8f\u51fd\u6570\u6765\u68c0\u6d4b\u4f9d\u8d56\u7ed3\u6784\u8bef\u8bbe", "motivation": "\u5c3d\u7ba1\u5355\u53d8\u91cf\u6982\u7387\u9884\u6d4b\u5df2\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5b9e\u73b0\u591a\u53d8\u91cf\u6821\u51c6\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u9884\u6392\u5e8f\u51fd\u6570\u4e3b\u8981\u7528\u4e8e\u4e8b\u540e\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f3a\u5236\u591a\u53d8\u91cf\u6821\u51c6\u7684\u65b9\u6cd5", "method": "\u63d0\u51fa\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u6821\u51c6\u65b9\u6cd5\uff0c\u5728\u8bad\u7ec3\u591a\u53d8\u91cf\u5206\u5e03\u56de\u5f52\u6a21\u578b\u65f6\u4f7f\u7528\u9884\u6392\u5e8f\u51fd\u6570\u5f3a\u5236\u591a\u53d8\u91cf\u6821\u51c6\uff1b\u5f15\u5165\u57fa\u4e8ePCA\u7684\u65b0\u9884\u6392\u5e8f\u51fd\u6570\uff0c\u5c06\u9884\u6d4b\u6295\u5f71\u5230\u9884\u6d4b\u5206\u5e03\u7684\u4e3b\u65b9\u5411\u4e0a", "result": "\u572818\u4e2a\u771f\u5b9e\u4e16\u754c\u591a\u8f93\u51fa\u56de\u5f52\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u591a\u53d8\u91cf\u9884\u6392\u5e8f\u6821\u51c6\uff0c\u4e14\u4e0d\u5f71\u54cd\u9884\u6d4b\u51c6\u786e\u6027\uff1bPCA\u9884\u6392\u5e8f\u80fd\u68c0\u6d4b\u51fa\u73b0\u6709\u9884\u6392\u5e8f\u65e0\u6cd5\u53d1\u73b0\u7684\u4f9d\u8d56\u7ed3\u6784\u8bef\u8bbe", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u53d8\u91cf\u6821\u51c6\u95ee\u9898\uff0cPCA\u9884\u6392\u5e8f\u4e3a\u8bc4\u4f30\u591a\u53d8\u91cf\u9884\u6d4b\u7684\u4f9d\u8d56\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u8bca\u65ad\u5de5\u5177"}}
{"id": "2601.22899", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22899", "abs": "https://arxiv.org/abs/2601.22899", "authors": ["Viktor Andonovikj", "Sa\u0161o D\u017eeroski", "Pavle Bo\u0161koski"], "title": "Uncertainty-Aware Extrapolation in Bayesian Oblique Trees", "comment": null, "summary": "Decision trees are widely used due to their interpretability and efficiency, but they struggle in regression tasks that require reliable extrapolation and well-calibrated uncertainty. Piecewise-constant leaf predictions are bounded by the training targets and often become overconfident under distribution shift. We propose a single-tree Bayesian model that extends VSPYCT by equipping each leaf with a GP predictor. Bayesian oblique splits provide uncertainty-aware partitioning of the input space, while GP leaves model local functional behaviour and enable principled extrapolation beyond the observed target range. We present an efficient inference and prediction scheme that combines posterior sampling of split parameters with \\gls{gp} posterior predictions, and a gating mechanism that activates GP-based extrapolation when inputs fall outside the training support of a leaf. Experiments on benchmark regression tasks show improvements in the predictive performance compared to standard variational oblique trees, and substantial performance gains in extrapolation scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8d1d\u53f6\u65af\u51b3\u7b56\u6811\u548c\u9ad8\u65af\u8fc7\u7a0b\u7684\u5355\u6811\u6a21\u578b\uff0c\u7528\u4e8e\u6539\u5584\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u5916\u63a8\u80fd\u529b\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6", "motivation": "\u4f20\u7edf\u51b3\u7b56\u6811\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u5916\u63a8\u80fd\u529b\u5dee\uff0c\u5206\u6bb5\u5e38\u6570\u9884\u6d4b\u53d7\u9650\u4e8e\u8bad\u7ec3\u76ee\u6807\u8303\u56f4\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u5bb9\u6613\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u9700\u8981\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u5916\u63a8\u673a\u5236", "method": "\u6269\u5c55VSPYCT\u6a21\u578b\uff0c\u4e3a\u6bcf\u4e2a\u53f6\u5b50\u8282\u70b9\u914d\u5907\u9ad8\u65af\u8fc7\u7a0b\u9884\u6d4b\u5668\uff1b\u4f7f\u7528\u8d1d\u53f6\u65af\u503e\u659c\u5206\u5272\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u8f93\u5165\u7a7a\u95f4\u5212\u5206\uff1bGP\u53f6\u5b50\u5efa\u6a21\u5c40\u90e8\u51fd\u6570\u884c\u4e3a\uff1b\u91c7\u7528\u9ad8\u6548\u63a8\u7406\u9884\u6d4b\u65b9\u6848\uff0c\u7ed3\u5408\u5206\u5272\u53c2\u6570\u7684\u540e\u9a8c\u91c7\u6837\u548cGP\u540e\u9a8c\u9884\u6d4b\uff1b\u5f53\u8f93\u5165\u8d85\u51fa\u53f6\u5b50\u8bad\u7ec3\u652f\u6301\u65f6\u6fc0\u6d3b\u57fa\u4e8eGP\u7684\u5916\u63a8\u673a\u5236", "result": "\u5728\u57fa\u51c6\u56de\u5f52\u4efb\u52a1\u4e2d\u76f8\u6bd4\u6807\u51c6\u53d8\u5206\u503e\u659c\u6811\u6709\u66f4\u597d\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5728\u5916\u63a8\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347", "conclusion": "\u63d0\u51fa\u7684\u5355\u6811\u8d1d\u53f6\u65af\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u51b3\u7b56\u6811\u7684\u89e3\u91ca\u6027\u548cGP\u7684\u5916\u63a8\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u51b3\u7b56\u6811\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u5916\u63a8\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u95ee\u9898"}}
{"id": "2601.22905", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22905", "abs": "https://arxiv.org/abs/2601.22905", "authors": ["Muqing Liu", "Chongjie Si", "Yuheng Jia"], "title": "FlexLoRA: Entropy-Guided Flexible Low-Rank Adaptation", "comment": "2026 ICLR. Codes in https://github.com/Chongjie-Si/Subspace-Tuning", "summary": "Large pre-trained models achieve remarkable success across diverse domains, yet fully fine-tuning incurs prohibitive computational and memory costs. Parameter-efficient fine-tuning (PEFT) has thus become a mainstream paradigm. Among them, Low-Rank Adaptation (LoRA) introduces trainable low-rank matrices and shows strong performance, nevertheless, its fixed-rank design limits flexibility. Dynamic rank allocation methods mitigate this issue by pruning redundant directions; however, they often rely on heuristic, element-level metrics that globally sort rank directions without matrix-wise distinction, and they lack mechanisms to expand capacity in layers requiring additional adaptation. To overcome these limitations, we propose FlexLoRA, an entropy-guided flexible low-rank adaptation framework that (i) evaluates matrix importance via spectral energy entropy, (ii) supports rank pruning and expansion under a global budget, and (iii) employs zero-impact initialization for newly added singular directions to ensure stability. By addressing granularity, flexibility, and stability limitations, FlexLoRA provides a more principled solution for PEFT. Extensive experiments show that FlexLoRA consistently outperforms state-of-the-art baselines across benchmarks. Codes are available at https://github.com/Chongjie-Si/Subspace-Tuning.", "AI": {"tldr": "FlexLoRA\uff1a\u57fa\u4e8e\u71b5\u5f15\u5bfc\u7684\u7075\u6d3b\u4f4e\u79e9\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u8c31\u80fd\u91cf\u71b5\u8bc4\u4f30\u77e9\u9635\u91cd\u8981\u6027\uff0c\u652f\u6301\u5168\u5c40\u9884\u7b97\u4e0b\u7684\u79e9\u526a\u679d\u548c\u6269\u5c55\uff0c\u4f7f\u7528\u96f6\u5f71\u54cd\u521d\u59cb\u5316\u786e\u4fdd\u7a33\u5b9a\u6027\uff0c\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u867d\u7136\u5728\u5404\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b8c\u5168\u5fae\u8c03\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u8fc7\u9ad8\u3002\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u6210\u4e3a\u4e3b\u6d41\u8303\u5f0f\uff0c\u5176\u4e2dLoRA\u65b9\u6cd5\u5f15\u5165\u53ef\u8bad\u7ec3\u4f4e\u79e9\u77e9\u9635\u4f46\u56fa\u5b9a\u79e9\u8bbe\u8ba1\u9650\u5236\u4e86\u7075\u6d3b\u6027\u3002\u73b0\u6709\u52a8\u6001\u79e9\u5206\u914d\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u5143\u7d20\u7ea7\u6307\u6807\uff0c\u7f3a\u4e4f\u77e9\u9635\u7ea7\u533a\u5206\uff0c\u4e14\u6ca1\u6709\u673a\u5236\u6269\u5c55\u9700\u8981\u989d\u5916\u9002\u5e94\u7684\u5c42\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faFlexLoRA\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u8c31\u80fd\u91cf\u71b5\u8bc4\u4f30\u77e9\u9635\u91cd\u8981\u6027\uff1b2\uff09\u652f\u6301\u5728\u5168\u5c40\u9884\u7b97\u4e0b\u8fdb\u884c\u79e9\u526a\u679d\u548c\u6269\u5c55\uff1b3\uff09\u5bf9\u65b0\u6dfb\u52a0\u7684\u5947\u5f02\u65b9\u5411\u91c7\u7528\u96f6\u5f71\u54cd\u521d\u59cb\u5316\u4ee5\u786e\u4fdd\u7a33\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7c92\u5ea6\u3001\u7075\u6d3b\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u9650\u5236\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFlexLoRA\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FlexLoRA\u4e3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u539f\u5219\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u7075\u6d3b\u4f4e\u79e9\u9002\u5e94\u6846\u67b6\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.22932", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22932", "abs": "https://arxiv.org/abs/2601.22932", "authors": ["Hoang Phuc Hau Luu", "Zhongjian Wang"], "title": "DC-LA: Difference-of-Convex Langevin Algorithm", "comment": null, "summary": "We study a sampling problem whose target distribution is $\u03c0\\propto \\exp(-f-r)$ where the data fidelity term $f$ is Lipschitz smooth while the regularizer term $r=r_1-r_2$ is a non-smooth difference-of-convex (DC) function, i.e., $r_1,r_2$ are convex. By leveraging the DC structure of $r$, we can smooth out $r$ by applying Moreau envelopes to $r_1$ and $r_2$ separately. In line of DC programming, we then redistribute the concave part of the regularizer to the data fidelity and study its corresponding proximal Langevin algorithm (termed DC-LA). We establish convergence of DC-LA to the target distribution $\u03c0$, up to discretization and smoothing errors, in the $q$-Wasserstein distance for all $q \\in \\mathbb{N}^*$, under the assumption that $V$ is distant dissipative. Our results improve previous work on non-log-concave sampling in terms of a more general framework and assumptions. Numerical experiments show that DC-LA produces accurate distributions in synthetic settings and reliably provides uncertainty quantification in a real-world Computed Tomography application.", "AI": {"tldr": "\u63d0\u51faDC-LA\u7b97\u6cd5\u7528\u4e8e\u91c7\u6837\u975e\u5bf9\u6570\u51f9\u5206\u5e03\uff0c\u5176\u4e2d\u6b63\u5219\u9879\u4e3aDC\u51fd\u6570\uff0c\u901a\u8fc7Moreau\u5305\u7edc\u5e73\u6ed1\u5904\u7406\uff0c\u5728q-Wasserstein\u8ddd\u79bb\u4e0b\u8bc1\u660e\u6536\u655b\u6027", "motivation": "\u7814\u7a76\u76ee\u6807\u5206\u5e03\u03c0\u221dexp(-f-r)\u7684\u91c7\u6837\u95ee\u9898\uff0c\u5176\u4e2df\u662fLipschitz\u5149\u6ed1\u7684\u6570\u636e\u4fdd\u771f\u9879\uff0cr=r1-r2\u662f\u975e\u5149\u6ed1\u7684DC\u51fd\u6570\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u975e\u5bf9\u6570\u51f9\u91c7\u6837\u65f6\u5047\u8bbe\u8f83\u4e25\u683c\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u6846\u67b6", "method": "\u5229\u7528DC\u7ed3\u6784\uff0c\u5bf9r1\u548cr2\u5206\u522b\u5e94\u7528Moreau\u5305\u7edc\u5e73\u6ed1\u6b63\u5219\u9879\uff0c\u5c06\u6b63\u5219\u9879\u7684\u51f9\u90e8\u5206\u91cd\u65b0\u5206\u914d\u5230\u6570\u636e\u4fdd\u771f\u9879\uff0c\u63d0\u51faDC-LA\uff08DC-Langevin\u7b97\u6cd5\uff09", "result": "\u5728V\u6ee1\u8db3\u8fdc\u8ddd\u79bb\u8017\u6563\u6027\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660eDC-LA\u5728q-Wasserstein\u8ddd\u79bb\u4e0b\u6536\u655b\u5230\u76ee\u6807\u5206\u5e03\u03c0\uff08\u8003\u8651\u79bb\u6563\u5316\u548c\u5e73\u6ed1\u8bef\u5dee\uff09\uff0c\u6539\u8fdb\u4e86\u5148\u524d\u975e\u5bf9\u6570\u51f9\u91c7\u6837\u5de5\u4f5c\u7684\u5047\u8bbe\u6761\u4ef6", "conclusion": "DC-LA\u7b97\u6cd5\u5728\u5408\u6210\u8bbe\u7f6e\u4e2d\u80fd\u51c6\u786e\u751f\u6210\u5206\u5e03\uff0c\u5728\u771f\u5b9e\u4e16\u754cCT\u5e94\u7528\u4e2d\u80fd\u53ef\u9760\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4e3a\u5904\u7406\u975e\u5149\u6ed1DC\u6b63\u5219\u9879\u7684\u91c7\u6837\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6"}}
{"id": "2601.22944", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22944", "abs": "https://arxiv.org/abs/2601.22944", "authors": ["Yuanchao Wang", "Zhao-Rong Lai", "Tianqi Zhong", "Fengnan Li"], "title": "Environment-Conditioned Tail Reweighting for Total Variation Invariant Risk Minimization", "comment": "8 pages", "summary": "Out-of-distribution (OOD) generalization remains challenging when models simultaneously encounter correlation shifts across environments and diversity shifts driven by rare or hard samples. Existing invariant risk minimization (IRM) methods primarily address spurious correlations at the environment level, but often overlook sample-level heterogeneity within environments, which can critically impact OOD performance. In this work, we propose Environment-Conditioned Tail Reweighting for Total Variation Invariant Risk Minimization (ECTR), a unified framework that augments TV-based invariant learning with environment-conditioned tail reweighting to jointly address both types of distribution shift. By integrating environment-level invariance with within-environment robustness, the proposed approach makes these two mechanisms complementary under mixed distribution shifts. We further extend the framework to scenarios without explicit environment annotations by inferring latent environments through a minimax formulation. Experiments across regression, tabular, time-series, and image classification benchmarks under mixed distribution shifts demonstrate consistent improvements in both worst-environment and average OOD performance.", "AI": {"tldr": "ECTR\u6846\u67b6\u901a\u8fc7\u73af\u5883\u6761\u4ef6\u5c3e\u90e8\u91cd\u52a0\u6743\u589e\u5f3aTV\u4e0d\u53d8\u98ce\u9669\u6700\u5c0f\u5316\uff0c\u540c\u65f6\u5904\u7406\u73af\u5883\u7ea7\u76f8\u5173\u504f\u79fb\u548c\u6837\u672c\u7ea7\u591a\u6837\u6027\u504f\u79fb\uff0c\u63d0\u5347OOD\u6cdb\u5316\u6027\u80fd", "motivation": "\u73b0\u6709IRM\u65b9\u6cd5\u4e3b\u8981\u5904\u7406\u73af\u5883\u7ea7\u7684\u865a\u5047\u76f8\u5173\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u73af\u5883\u5185\u6837\u672c\u7ea7\u5f02\u8d28\u6027\uff0c\u8fd9\u5728\u6df7\u5408\u5206\u5e03\u504f\u79fb\u4e0b\u4f1a\u4e25\u91cd\u5f71\u54cdOOD\u6027\u80fd", "method": "\u63d0\u51fa\u73af\u5883\u6761\u4ef6\u5c3e\u90e8\u91cd\u52a0\u6743\u603b\u53d8\u5dee\u4e0d\u53d8\u98ce\u9669\u6700\u5c0f\u5316(ECTR)\u6846\u67b6\uff0c\u5c06TV\u4e0d\u53d8\u5b66\u4e60\u4e0e\u73af\u5883\u6761\u4ef6\u5c3e\u90e8\u91cd\u52a0\u6743\u7ed3\u5408\uff0c\u5904\u7406\u73af\u5883\u7ea7\u76f8\u5173\u504f\u79fb\u548c\u6837\u672c\u7ea7\u591a\u6837\u6027\u504f\u79fb\uff1b\u5728\u6ca1\u6709\u73af\u5883\u6807\u6ce8\u65f6\u901a\u8fc7\u6781\u5c0f\u6781\u5927\u516c\u5f0f\u63a8\u65ad\u6f5c\u5728\u73af\u5883", "result": "\u5728\u56de\u5f52\u3001\u8868\u683c\u6570\u636e\u3001\u65f6\u95f4\u5e8f\u5217\u548c\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u6df7\u5408\u5206\u5e03\u504f\u79fb\u4e0b\uff0c\u6700\u5dee\u73af\u5883\u548c\u5e73\u5747OOD\u6027\u80fd\u5747\u5f97\u5230\u4e00\u81f4\u63d0\u5347", "conclusion": "ECTR\u6846\u67b6\u901a\u8fc7\u8054\u5408\u5904\u7406\u73af\u5883\u7ea7\u4e0d\u53d8\u6027\u548c\u73af\u5883\u5185\u9c81\u68d2\u6027\uff0c\u4f7f\u8fd9\u4e24\u79cd\u673a\u5236\u5728\u6df7\u5408\u5206\u5e03\u504f\u79fb\u4e0b\u4e92\u8865\uff0c\u663e\u8457\u63d0\u5347OOD\u6cdb\u5316\u80fd\u529b"}}
{"id": "2601.22969", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22969", "abs": "https://arxiv.org/abs/2601.22969", "authors": ["Dhruv Sarkar", "Nishant Pandey", "Sayak Ray Chowdhury"], "title": "Improved Algorithms for Nash Welfare in Linear Bandits", "comment": null, "summary": "Nash regret has recently emerged as a principled fairness-aware performance metric for stochastic multi-armed bandits, motivated by the Nash Social Welfare objective. Although this notion has been extended to linear bandits, existing results suffer from suboptimality in ambient dimension $d$, stemming from proof techniques that rely on restrictive concentration inequalities. In this work, we resolve this open problem by introducing new analytical tools that yield an order-optimal Nash regret bound in linear bandits. Beyond Nash regret, we initiate the study of $p$-means regret in linear bandits, a unifying framework that interpolates between fairness and utility objectives and strictly generalizes Nash regret. We propose a generic algorithmic framework, FairLinBandit, that works as a meta-algorithm on top of any linear bandit strategy. We instantiate this framework using two bandit algorithms: Phased Elimination and Upper Confidence Bound, and prove that both achieve sublinear $p$-means regret for the entire range of $p$. Extensive experiments on linear bandit instances generated from real-world datasets demonstrate that our methods consistently outperform the existing state-of-the-art baseline.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u7ebf\u6027\u8d4c\u535a\u673a\u4e2dNash\u9057\u61be\u7684\u6b21\u4f18\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\u5b9e\u73b0\u6700\u4f18Nash\u9057\u61be\u8fb9\u754c\uff0c\u5e76\u9996\u6b21\u7814\u7a76\u4e86p-\u5747\u503c\u9057\u61be\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u901a\u7528\u7684FairLinBandit\u7b97\u6cd5\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u8d4c\u535a\u673a\u4e2d\u7684Nash\u9057\u61be\u7ed3\u679c\u5b58\u5728\u7ef4\u5ea6d\u76f8\u5173\u7684\u6b21\u4f18\u6027\uff0c\u6e90\u4e8e\u4f9d\u8d56\u9650\u5236\u6027\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u7684\u8bc1\u660e\u6280\u672f\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u5f00\u653e\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u7814\u7a76\u66f4\u4e00\u822c\u7684p-\u5747\u503c\u9057\u61be\u6846\u67b6\u3002", "method": "\u5f15\u5165\u65b0\u7684\u5206\u6790\u5de5\u5177\u89e3\u51b3Nash\u9057\u61be\u6b21\u4f18\u95ee\u9898\uff1b\u63d0\u51faFairLinBandit\u901a\u7528\u7b97\u6cd5\u6846\u67b6\uff0c\u4f5c\u4e3a\u5143\u7b97\u6cd5\u9002\u7528\u4e8e\u4efb\u4f55\u7ebf\u6027\u8d4c\u535a\u673a\u7b56\u7565\uff1b\u5177\u4f53\u5b9e\u4f8b\u5316\u4e86Phased Elimination\u548cUpper Confidence Bound\u4e24\u79cd\u7b97\u6cd5\u3002", "result": "\u5b9e\u73b0\u4e86\u7ebf\u6027\u8d4c\u535a\u673a\u4e2dNash\u9057\u61be\u7684\u6700\u4f18\u8fb9\u754c\uff1b\u8bc1\u660e\u4e86\u4e24\u79cd\u7b97\u6cd5\u5728\u6574\u4e2ap\u503c\u8303\u56f4\u5185\u90fd\u80fd\u5b9e\u73b0\u6b21\u7ebf\u6027p-\u5747\u503c\u9057\u61be\uff1b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u751f\u6210\u7684\u7ebf\u6027\u8d4c\u535a\u673a\u5b9e\u4f8b\u4e0a\uff0c\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u7ebf\u6027\u8d4c\u535a\u673a\u4e2dNash\u9057\u61be\u7684\u5f00\u653e\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u66f4\u4e00\u822c\u7684p-\u5747\u503c\u9057\u61be\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u5728\u516c\u5e73\u6027\u548c\u6548\u7528\u76ee\u6807\u4e4b\u95f4\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89c6\u89d2\u3002"}}
{"id": "2601.22980", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22980", "abs": "https://arxiv.org/abs/2601.22980", "authors": ["Zekai Li", "Ji Liu", "Guanchen Li", "Yixing Xu", "Ziqiong Liu", "Xuanwu Yin", "Dong Li", "Emad Barsoum"], "title": "Learnable Permutation for Structured Sparsity on Transformer Models", "comment": null, "summary": "Structured sparsity has emerged as a popular model pruning technique, widely adopted in various architectures, including CNNs, Transformer models, and especially large language models (LLMs) in recent years. A promising direction to further improve post-pruning performance is weight permutation, which reorders model weights into patterns more amenable to pruning. However, the exponential growth of the permutation search space with the scale of Transformer architectures forces most methods to rely on greedy or heuristic algorithms, limiting the effectiveness of reordering.\n  In this work, we propose a novel end-to-end learnable permutation framework. Our method introduces a learnable permutation cost matrix to quantify the cost of swapping any two input channels of a given weight matrix, a differentiable bipartite matching solver to obtain the optimal binary permutation matrix given a cost matrix, and a sparsity optimization loss function to directly optimize the permutation operator. We extensively validate our approach on vision and language Transformers, demonstrating that our method achieves state-of-the-art permutation results for structured sparsity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u53ef\u5b66\u4e60\u7684\u6743\u91cd\u7f6e\u6362\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7f6e\u6362\u6210\u672c\u77e9\u9635\u3001\u53ef\u5fae\u5206\u4e8c\u5206\u56fe\u5339\u914d\u6c42\u89e3\u5668\u548c\u7a00\u758f\u4f18\u5316\u635f\u5931\u51fd\u6570\uff0c\u4e3a\u7ed3\u6784\u5316\u7a00\u758f\u5316\u63d0\u4f9b\u66f4\u4f18\u7684\u6743\u91cd\u91cd\u6392\u5e8f\u65b9\u6848\u3002", "motivation": "\u7ed3\u6784\u5316\u7a00\u758f\u5316\u5df2\u6210\u4e3a\u6a21\u578b\u526a\u679d\u7684\u6d41\u884c\u6280\u672f\uff0c\u6743\u91cd\u7f6e\u6362\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6539\u5584\u526a\u679d\u540e\u6027\u80fd\u3002\u7136\u800c\uff0cTransformer\u67b6\u6784\u89c4\u6a21\u5bfc\u81f4\u7f6e\u6362\u641c\u7d22\u7a7a\u95f4\u5448\u6307\u6570\u589e\u957f\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u8d2a\u5fc3\u6216\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u9650\u5236\u4e86\u91cd\u6392\u5e8f\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u53ef\u5b66\u4e60\u7684\u7f6e\u6362\u6846\u67b6\uff1a1\uff09\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u7f6e\u6362\u6210\u672c\u77e9\u9635\u91cf\u5316\u4efb\u610f\u4e24\u4e2a\u8f93\u5165\u901a\u9053\u4ea4\u6362\u7684\u6210\u672c\uff1b2\uff09\u4f7f\u7528\u53ef\u5fae\u5206\u4e8c\u5206\u56fe\u5339\u914d\u6c42\u89e3\u5668\u83b7\u53d6\u7ed9\u5b9a\u6210\u672c\u77e9\u9635\u4e0b\u7684\u6700\u4f18\u4e8c\u5143\u7f6e\u6362\u77e9\u9635\uff1b3\uff09\u8bbe\u8ba1\u7a00\u758f\u4f18\u5316\u635f\u5931\u51fd\u6570\u76f4\u63a5\u4f18\u5316\u7f6e\u6362\u7b97\u5b50\u3002", "result": "\u5728\u89c6\u89c9\u548c\u8bed\u8a00Transformer\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u9a8c\u8bc1\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u7a00\u758f\u5316\u65b9\u9762\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7f6e\u6362\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u7aef\u5230\u7aef\u53ef\u5b66\u4e60\u7f6e\u6362\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21Transformer\u67b6\u6784\u4e2d\u7684\u6743\u91cd\u7f6e\u6362\u95ee\u9898\uff0c\u4e3a\u7ed3\u6784\u5316\u7a00\u758f\u5316\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22985", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22985", "abs": "https://arxiv.org/abs/2601.22985", "authors": ["Pyo Min Hong", "Albert No"], "title": "dgMARK: Decoding-Guided Watermarking for Diffusion Language Models", "comment": "Project page: https://dgmark-watermarking.github.io", "summary": "We propose dgMARK, a decoding-guided watermarking method for discrete diffusion language models (dLLMs). Unlike autoregressive models, dLLMs can generate tokens in arbitrary order. While an ideal conditional predictor would be invariant to this order, practical dLLMs exhibit strong sensitivity to the unmasking order, creating a new channel for watermarking. dgMARK steers the unmasking order toward positions whose high-reward candidate tokens satisfy a simple parity constraint induced by a binary hash, without explicitly reweighting the model's learned probabilities. The method is plug-and-play with common decoding strategies (e.g., confidence, entropy, and margin-based ordering) and can be strengthened with a one-step lookahead variant. Watermarks are detected via elevated parity-matching statistics, and a sliding-window detector ensures robustness under post-editing operations including insertion, deletion, substitution, and paraphrasing.", "AI": {"tldr": "dgMARK\u662f\u4e00\u79cd\u7528\u4e8e\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u5f15\u5bfc\u6c34\u5370\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5bfc\u89e3\u63a9\u7801\u987a\u5e8f\u6765\u5b9e\u73b0\u6c34\u5370\u5d4c\u5165\uff0c\u65e0\u9700\u663e\u5f0f\u91cd\u65b0\u52a0\u6743\u6a21\u578b\u6982\u7387\u3002", "motivation": "\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u6309\u4efb\u610f\u987a\u5e8f\u751f\u6210\u4ee4\u724c\uff0c\u800c\u5b9e\u9645\u6a21\u578b\u5bf9\u89e3\u63a9\u7801\u987a\u5e8f\u8868\u73b0\u51fa\u5f3a\u70c8\u654f\u611f\u6027\uff0c\u8fd9\u4e3a\u6c34\u5370\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u901a\u9053\u3002", "method": "dgMARK\u5f15\u5bfc\u89e3\u63a9\u7801\u987a\u5e8f\u671d\u5411\u6ee1\u8db3\u4e8c\u8fdb\u5236\u54c8\u5e0c\u8bf1\u5bfc\u7684\u7b80\u5355\u5947\u5076\u7ea6\u675f\u7684\u9ad8\u5956\u52b1\u5019\u9009\u4ee4\u724c\u4f4d\u7f6e\uff0c\u65e0\u9700\u663e\u5f0f\u91cd\u65b0\u52a0\u6743\u6a21\u578b\u5b66\u4e60\u6982\u7387\uff0c\u53ef\u4e0e\u5e38\u89c1\u89e3\u7801\u7b56\u7565\uff08\u7f6e\u4fe1\u5ea6\u3001\u71b5\u3001\u8fb9\u9645\u6392\u5e8f\uff09\u5373\u63d2\u5373\u7528\uff0c\u5e76\u53ef\u589e\u5f3a\u4e3a\u4e00\u6b65\u524d\u77bb\u53d8\u4f53\u3002", "result": "\u901a\u8fc7\u63d0\u5347\u7684\u5947\u5076\u5339\u914d\u7edf\u8ba1\u91cf\u68c0\u6d4b\u6c34\u5370\uff0c\u6ed1\u52a8\u7a97\u53e3\u68c0\u6d4b\u5668\u786e\u4fdd\u5728\u63d2\u5165\u3001\u5220\u9664\u3001\u66ff\u6362\u548c\u6539\u5199\u7b49\u540e\u7f16\u8f91\u64cd\u4f5c\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "dgMARK\u4e3a\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u7801\u5f15\u5bfc\u6c34\u5370\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5bf9\u89e3\u63a9\u7801\u987a\u5e8f\u7684\u654f\u611f\u6027\u5b9e\u73b0\u6c34\u5370\u5d4c\u5165\uff0c\u5177\u6709\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.22993", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22993", "abs": "https://arxiv.org/abs/2601.22993", "authors": ["Rohan Tangri", "Jan-Peter Calliess"], "title": "Value-at-Risk Constrained Policy Optimization", "comment": null, "summary": "We introduce the Value-at-Risk Constrained Policy Optimization algorithm (VaR-CPO), a sample efficient and conservative method designed to optimize Value-at-Risk (VaR) constraints directly. Empirically, we demonstrate that VaR-CPO is capable of safe exploration, achieving zero constraint violations during training in feasible environments, a critical property that baseline methods fail to uphold. To overcome the inherent non-differentiability of the VaR constraint, we employ the one-sided Chebyshev inequality to obtain a tractable surrogate based on the first two moments of the cost return. Additionally, by extending the trust-region framework of the Constrained Policy Optimization (CPO) method, we provide rigorous worst-case bounds for both policy improvement and constraint violation during the training process.", "AI": {"tldr": "VaR-CPO\u7b97\u6cd5\uff1a\u4e00\u79cd\u76f4\u63a5\u4f18\u5316\u98ce\u9669\u4ef7\u503c\u7ea6\u675f\u7684\u6837\u672c\u9ad8\u6548\u4fdd\u5b88\u65b9\u6cd5\uff0c\u5728\u53ef\u884c\u73af\u5883\u4e2d\u5b9e\u73b0\u8bad\u7ec3\u671f\u95f4\u96f6\u7ea6\u675f\u8fdd\u53cd", "motivation": "\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u65e0\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u96f6\u7ea6\u675f\u8fdd\u53cd\uff0c\u800c\u5b89\u5168\u63a2\u7d22\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u4f18\u5316\u98ce\u9669\u4ef7\u503c\u7ea6\u675f\u7684\u4fdd\u5b88\u65b9\u6cd5\u3002", "method": "1. \u4f7f\u7528\u5355\u8fb9\u5207\u6bd4\u96ea\u592b\u4e0d\u7b49\u5f0f\u5904\u7406\u98ce\u9669\u4ef7\u503c\u7ea6\u675f\u7684\u975e\u53ef\u5fae\u6027\u95ee\u9898\uff0c\u57fa\u4e8e\u6210\u672c\u56de\u62a5\u7684\u524d\u4e24\u4e2a\u77e9\u83b7\u5f97\u53ef\u5904\u7406\u7684\u66ff\u4ee3\u7ea6\u675f\uff1b2. \u6269\u5c55\u7ea6\u675f\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u7684\u4fe1\u4efb\u57df\u6846\u67b6\uff0c\u63d0\u4f9b\u7b56\u7565\u6539\u8fdb\u548c\u7ea6\u675f\u8fdd\u53cd\u7684\u4e25\u683c\u6700\u574f\u60c5\u51b5\u8fb9\u754c", "result": "1. \u5728\u53ef\u884c\u73af\u5883\u4e2d\u5b9e\u73b0\u8bad\u7ec3\u671f\u95f4\u96f6\u7ea6\u675f\u8fdd\u53cd\uff1b2. \u57fa\u7ebf\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u6301\u8fd9\u4e00\u5173\u952e\u7279\u6027\uff1b3. \u63d0\u4f9b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7b56\u7565\u6539\u8fdb\u548c\u7ea6\u675f\u8fdd\u53cd\u7684\u4e25\u683c\u6700\u574f\u60c5\u51b5\u8fb9\u754c", "conclusion": "VaR-CPO\u662f\u4e00\u79cd\u6837\u672c\u9ad8\u6548\u4e14\u4fdd\u5b88\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u76f4\u63a5\u4f18\u5316\u98ce\u9669\u4ef7\u503c\u7ea6\u675f\uff0c\u5b9e\u73b0\u5b89\u5168\u63a2\u7d22\uff0c\u4e3a\u8bad\u7ec3\u8fc7\u7a0b\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1"}}
{"id": "2601.23026", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23026", "abs": "https://arxiv.org/abs/2601.23026", "authors": ["Hendrik Suhr", "David Kaltenpoth", "Jilles Vreeken"], "title": "Causal Characterization of Measurement and Mechanistic Anomalies", "comment": null, "summary": "Root cause analysis of anomalies aims to identify those features that cause the deviation from the normal process. Existing methods ignore, however, that anomalies can arise through two fundamentally different processes: measurement errors, where data was generated normally but one or more values were recorded incorrectly, and mechanism shifts, where the causal process generating the data changed. While measurement errors can often be safely corrected, mechanistic anomalies require careful consideration. We define a causal model that explicitly captures both types by treating outliers as latent interventions on latent (\"true\") and observed (\"measured\") variables. We show that they are identifiable, and propose a maximum likelihood estimation approach to put this to practice. Experiments show that our method matches state-of-the-art performance in root cause localization, while it additionally enables accurate classification of anomaly types, and remains robust even when the causal DAG is unknown.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f02\u5e38\u6839\u56e0\u5206\u6790\u65b9\u6cd5\uff0c\u80fd\u591f\u533a\u5206\u6d4b\u91cf\u8bef\u5dee\u548c\u673a\u5236\u53d8\u5316\u4e24\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u5f02\u5e38\uff0c\u5e76\u901a\u8fc7\u6f5c\u5728\u5e72\u9884\u6a21\u578b\u5b9e\u73b0\u53ef\u8bc6\u522b\u6027\u3002", "motivation": "\u73b0\u6709\u5f02\u5e38\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u5ffd\u7565\u4e86\u5f02\u5e38\u53ef\u80fd\u6e90\u4e8e\u4e24\u79cd\u6839\u672c\u4e0d\u540c\u7684\u8fc7\u7a0b\uff1a\u6d4b\u91cf\u8bef\u5dee\uff08\u6570\u636e\u6b63\u5e38\u751f\u6210\u4f46\u8bb0\u5f55\u9519\u8bef\uff09\u548c\u673a\u5236\u53d8\u5316\uff08\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u672c\u8eab\u53d1\u751f\u53d8\u5316\uff09\u3002\u6d4b\u91cf\u8bef\u5dee\u901a\u5e38\u53ef\u4ee5\u5b89\u5168\u7ea0\u6b63\uff0c\u800c\u673a\u5236\u5f02\u5e38\u9700\u8981\u4ed4\u7ec6\u8003\u8651\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u56e0\u679c\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u5f02\u5e38\u89c6\u4e3a\u5bf9\u6f5c\u5728\u53d8\u91cf\uff08\"\u771f\u5b9e\"\u53d8\u91cf\uff09\u548c\u89c2\u6d4b\u53d8\u91cf\uff08\"\u6d4b\u91cf\"\u53d8\u91cf\uff09\u7684\u6f5c\u5728\u5e72\u9884\u6765\u663e\u5f0f\u6355\u83b7\u4e24\u79cd\u5f02\u5e38\u7c7b\u578b\u3002\u8bc1\u660e\u4e86\u8fd9\u4e24\u79cd\u5f02\u5e38\u7c7b\u578b\u7684\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e00\u7406\u8bba\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6839\u56e0\u5b9a\u4f4d\u65b9\u9762\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u8fd8\u80fd\u51c6\u786e\u5206\u7c7b\u5f02\u5e38\u7c7b\u578b\uff0c\u5373\u4f7f\u5728\u56e0\u679cDAG\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u533a\u5206\u6d4b\u91cf\u8bef\u5dee\u548c\u673a\u5236\u53d8\u5316\u7684\u5f02\u5e38\u6839\u56e0\u5206\u6790\u6846\u67b6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u540c\u7c7b\u578b\u7684\u5f02\u5e38\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u8bca\u65ad\u548c\u5904\u7406\u65b9\u6cd5\u3002"}}
{"id": "2601.23027", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23027", "abs": "https://arxiv.org/abs/2601.23027", "authors": ["Arvind Mahankali", "Kaiyue Wen", "Tengyu Ma"], "title": "Divide-and-Conquer CoT: RL for Reducing Latency via Parallel Reasoning", "comment": "47 pages, 13 figures", "summary": "Long chain-of-thought reasoning (Long CoT) is now fundamental to state-of-the-art LLMs, especially in mathematical reasoning. However, LLM generation is highly sequential, and long CoTs lead to a high latency. We propose to train Divide-and-Conquer CoT (DC-CoT) to reduce the latency. With DC-CoT, the model can act as a director that identifies distinct subtasks that can be performed in parallel in its reasoning process, and then spawns workers to execute the subtasks. Our goal is to achieve high accuracy, with a low longest path length, which is a theoretical measure of the latency needed for the response. We start with a long CoT base model (DeepScaleR-1.5B-Preview), and first use SFT with a small curated demonstration set to initialize its ability to spawn workers in a certain format. Because SFT degrades the accuracy significantly, we design a multi-stage RL algorithm, with various data filtering strategies, to recover the accuracy while decreasing the longest path length. Across several benchmarks including AIME 2024 and HMMT 2025, DC-CoT achieves similar accuracy as DeepScaleR-1.5B-Preview while decreasing longest path length by 35-40%. Our code, SFT dataset and models are publicly available at https://github.com/amahankali10/DC_CoT_RL_for_Low_Latency_CoT_with_Parallel_Reasoning.", "AI": {"tldr": "\u63d0\u51faDC-CoT\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u63a8\u7406\u51cf\u5c11\u957f\u601d\u7ef4\u94fe\u7684\u5ef6\u8fdf\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u7387\u7684\u540c\u65f6\u5c06\u6700\u957f\u8def\u5f84\u957f\u5ea6\u964d\u4f4e35-40%", "motivation": "\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u5bfc\u81f4LLM\u751f\u6210\u5ef6\u8fdf\u9ad8\uff0c\u56e0\u4e3aLLM\u751f\u6210\u662f\u9ad8\u5ea6\u987a\u5e8f\u5316\u7684\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "method": "\u8bad\u7ec3Divide-and-Conquer CoT\u6a21\u578b\uff0c\u8ba9\u6a21\u578b\u4f5c\u4e3a\u5bfc\u6f14\u8bc6\u522b\u53ef\u5e76\u884c\u6267\u884c\u7684\u5b50\u4efb\u52a1\uff0c\u7136\u540e\u751f\u6210\u5de5\u4f5c\u7ebf\u7a0b\u6267\u884c\u8fd9\u4e9b\u5b50\u4efb\u52a1\u3002\u91c7\u7528\u591a\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u914d\u5408\u6570\u636e\u8fc7\u6ee4\u7b56\u7565\uff0c\u5728\u964d\u4f4e\u6700\u957f\u8def\u5f84\u957f\u5ea6\u7684\u540c\u65f6\u6062\u590d\u51c6\u786e\u7387\u3002", "result": "\u5728AIME 2024\u548cHMMT 2025\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDC-CoT\u5b9e\u73b0\u4e86\u4e0eDeepScaleR-1.5B-Preview\u76f8\u4f3c\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5c06\u6700\u957f\u8def\u5f84\u957f\u5ea6\u964d\u4f4e\u4e8635-40%\u3002", "conclusion": "DC-CoT\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u964d\u4f4e\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u5ef6\u8fdf\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u4f4e\u5ef6\u8fdf\u5e76\u884c\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.23058", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23058", "abs": "https://arxiv.org/abs/2601.23058", "authors": ["Wenzhe Niu", "Wei He", "Zongxia Xie", "Jinpeng Ou", "Huichuan Fan", "Yuchen Ge", "Yanru Sun", "Ziyin Wang", "Yizhao Sun", "Chengshun Shi", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning", "comment": null, "summary": "Reinforcement learning has become a cornerstone for enhancing the reasoning capabilities of Large Language Models, where group-based approaches such as GRPO have emerged as efficient paradigms that optimize policies by leveraging intra-group performance differences. However, these methods typically rely on absolute numerical rewards, introducing intrinsic limitations. In verifiable tasks, identical group evaluations often result in sparse supervision, while in open-ended scenarios, the score range instability of reward models undermines advantage estimation based on group means. To address these limitations, we propose Reinforcement Learning with Relative Rewards (RLRR), a framework that shifts reward shaping from absolute scoring to relative ranking. Complementing this framework, we introduce the Ranking Reward Model, a listwise preference model tailored for group-based optimization to directly generate relative rankings. By transforming raw evaluations into robust relative signals, RLRR effectively mitigates signal sparsity and reward instability. Experimental results demonstrate that RLRR yields consistent performance improvements over standard group-based baselines across reasoning benchmarks and open-ended generation tasks.", "AI": {"tldr": "\u63d0\u51faRLRR\u6846\u67b6\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1\u4ece\u7edd\u5bf9\u6570\u503c\u8f6c\u5411\u76f8\u5bf9\u6392\u540d\uff0c\u89e3\u51b3\u7fa4\u4f53\u65b9\u6cd5\u4e2d\u5956\u52b1\u7a00\u758f\u6027\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08\u5982GRPO\uff09\u4f9d\u8d56\u7edd\u5bf9\u6570\u503c\u5956\u52b1\u5b58\u5728\u56fa\u6709\u5c40\u9650\uff1a\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u76f8\u540c\u7fa4\u4f53\u8bc4\u4f30\u5bfc\u81f4\u76d1\u7763\u7a00\u758f\uff0c\u5728\u5f00\u653e\u4efb\u52a1\u4e2d\u5956\u52b1\u6a21\u578b\u5206\u6570\u8303\u56f4\u4e0d\u7a33\u5b9a\u5f71\u54cd\u4f18\u52bf\u4f30\u8ba1", "method": "\u63d0\u51faRLRR\u6846\u67b6\uff0c\u5c06\u5956\u52b1\u5851\u9020\u4ece\u7edd\u5bf9\u8bc4\u5206\u8f6c\u5411\u76f8\u5bf9\u6392\u540d\uff1b\u5f15\u5165Ranking Reward Model\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u7fa4\u4f53\u4f18\u5316\u8bbe\u8ba1\u7684\u5217\u8868\u5f0f\u504f\u597d\u6a21\u578b\uff0c\u53ef\u76f4\u63a5\u751f\u6210\u76f8\u5bf9\u6392\u540d", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRLRR\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f00\u653e\u751f\u6210\u4efb\u52a1\u4e2d\u76f8\u6bd4\u6807\u51c6\u7fa4\u4f53\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347", "conclusion": "\u901a\u8fc7\u5c06\u539f\u59cb\u8bc4\u4f30\u8f6c\u5316\u4e3a\u7a33\u5065\u7684\u76f8\u5bf9\u4fe1\u53f7\uff0cRLRR\u6709\u6548\u7f13\u89e3\u4e86\u4fe1\u53f7\u7a00\u758f\u6027\u548c\u5956\u52b1\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u4f18\u5316\u8303\u5f0f"}}
{"id": "2601.23072", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23072", "abs": "https://arxiv.org/abs/2601.23072", "authors": ["Santanu Subhash Rathod", "Pietro Li\u00f2", "Xiao Zhang"], "title": "SplineFlow: Flow Matching for Dynamical Systems with B-Spline Interpolants", "comment": "36 pages, 35 tables, 22 figures", "summary": "Flow matching is a scalable generative framework for characterizing continuous normalizing flows with wide-range applications. However, current state-of-the-art methods are not well-suited for modeling dynamical systems, as they construct conditional paths using linear interpolants that may not capture the underlying state evolution, especially when learning higher-order dynamics from irregular sampled observations. Constructing unified paths that satisfy multi-marginal constraints across observations is challenging, since na\u00efve higher-order polynomials tend to be unstable and oscillatory. We introduce SplineFlow, a theoretically grounded flow matching algorithm that jointly models conditional paths across observations via B-spline interpolation. Specifically, SplineFlow exploits the smoothness and stability of B-spline bases to learn the complex underlying dynamics in a structured manner while ensuring the multi-marginal requirements are met. Comprehensive experiments across various deterministic and stochastic dynamical systems of varying complexity, as well as on cellular trajectory inference tasks, demonstrate the strong improvement of SplineFlow over existing baselines. Our code is available at: https://github.com/santanurathod/SplineFlow.", "AI": {"tldr": "SplineFlow\u662f\u4e00\u79cd\u57fa\u4e8eB\u6837\u6761\u63d2\u503c\u7684\u6d41\u5339\u914d\u7b97\u6cd5\uff0c\u4e13\u95e8\u7528\u4e8e\u5efa\u6a21\u52a8\u6001\u7cfb\u7edf\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u5904\u7406\u4e0d\u89c4\u5219\u91c7\u6837\u89c2\u6d4b\u6570\u636e\u5e76\u5b66\u4e60\u9ad8\u9636\u52a8\u6001\u3002", "motivation": "\u73b0\u6709\u6d41\u5339\u914d\u65b9\u6cd5\u4e0d\u9002\u5408\u5efa\u6a21\u52a8\u6001\u7cfb\u7edf\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f7f\u7528\u7ebf\u6027\u63d2\u503c\u6784\u5efa\u6761\u4ef6\u8def\u5f84\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u5e95\u5c42\u72b6\u6001\u6f14\u5316\uff0c\u7279\u522b\u662f\u5728\u4ece\u4e0d\u89c4\u5219\u91c7\u6837\u89c2\u6d4b\u4e2d\u5b66\u4e60\u9ad8\u9636\u52a8\u6001\u65f6\u3002\u6784\u5efa\u6ee1\u8db3\u591a\u4e2a\u89c2\u6d4b\u8fb9\u9645\u7ea6\u675f\u7684\u7edf\u4e00\u8def\u5f84\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u7b80\u5355\u7684\u9ad8\u9636\u591a\u9879\u5f0f\u5f80\u5f80\u4e0d\u7a33\u5b9a\u4e14\u632f\u8361\u3002", "method": "SplineFlow\u5229\u7528B\u6837\u6761\u63d2\u503c\u7684\u5e73\u6ed1\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7B\u6837\u6761\u57fa\u51fd\u6570\u8054\u5408\u5efa\u6a21\u8de8\u89c2\u6d4b\u7684\u6761\u4ef6\u8def\u5f84\uff0c\u4ee5\u7ed3\u6784\u5316\u65b9\u5f0f\u5b66\u4e60\u590d\u6742\u5e95\u5c42\u52a8\u6001\uff0c\u540c\u65f6\u786e\u4fdd\u6ee1\u8db3\u591a\u8fb9\u9645\u7ea6\u675f\u8981\u6c42\u3002", "result": "\u5728\u5404\u79cd\u590d\u6742\u5ea6\u7684\u786e\u5b9a\u6027\u548c\u968f\u673a\u52a8\u6001\u7cfb\u7edf\u4ee5\u53ca\u7ec6\u80de\u8f68\u8ff9\u63a8\u65ad\u4efb\u52a1\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cSplineFlow\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "SplineFlow\u662f\u4e00\u79cd\u7406\u8bba\u4e0a\u6709\u4f9d\u636e\u7684\u6d41\u5339\u914d\u7b97\u6cd5\uff0c\u901a\u8fc7B\u6837\u6761\u63d2\u503c\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u4e2d\u7684\u8def\u5f84\u6784\u5efa\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.23096", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23096", "abs": "https://arxiv.org/abs/2601.23096", "authors": ["Nisarg Parikh", "Kunjal Panchal", "Ananya Sai", "Pannaga Shivaswamy", "Andrew Lan"], "title": "CATTO: Balancing Preferences and Confidence in Language Models", "comment": null, "summary": "Large language models (LLMs) often make accurate next token predictions but their confidence in these predictions can be poorly calibrated: high-confidence predictions are frequently wrong, and low-confidence predictions may be correct. This miscalibration is exacerbated by preference-based alignment methods breaking the link between predictive probability and correctness. We introduce a Calibration Aware Token-level Training Objective (CATTO), a calibration-aware objective that aligns predicted confidence with empirical prediction correctness, which can be combined with the original preference optimization objectives. Empirically, CATTO reduces Expected Calibration Error (ECE) by 2.22%-7.61% in-distribution and 1.46%-10.44% out-of-distribution compared to direct preference optimization (DPO), and by 0.22%-1.24% in-distribution and 1.23%-5.07% out-of-distribution compared to the strongest DPO baseline. This improvement in confidence does not come at a cost of losing task accuracy, where CATTO maintains or slightly improves multiple-choice question-answering accuracy on five datasets. We also introduce Confidence@k, a test-time scaling mechanism leveraging calibrated token probabilities for Bayes-optimal selection of output tokens.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCATTO\u6821\u51c6\u611f\u77e5\u8bad\u7ec3\u76ee\u6807\uff0c\u89e3\u51b3LLM\u7f6e\u4fe1\u5ea6\u6821\u51c6\u95ee\u9898\uff0c\u5728\u4e0d\u635f\u5931\u4efb\u52a1\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u6821\u51c6\u8bef\u5dee", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u505a\u51fa\u51c6\u786e\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\uff0c\u4f46\u5176\u7f6e\u4fe1\u5ea6\u6821\u51c6\u5f88\u5dee\uff1a\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u7ecf\u5e38\u9519\u8bef\uff0c\u4f4e\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u53cd\u800c\u53ef\u80fd\u6b63\u786e\u3002\u57fa\u4e8e\u504f\u597d\u7684\u5bf9\u9f50\u65b9\u6cd5\u8fdb\u4e00\u6b65\u7834\u574f\u4e86\u9884\u6d4b\u6982\u7387\u4e0e\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "method": "\u63d0\u51faCATTO\uff08\u6821\u51c6\u611f\u77e5token\u7ea7\u8bad\u7ec3\u76ee\u6807\uff09\uff0c\u5c06\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u4e0e\u7ecf\u9a8c\u9884\u6d4b\u6b63\u786e\u6027\u5bf9\u9f50\uff0c\u53ef\u4e0e\u539f\u59cb\u504f\u597d\u4f18\u5316\u76ee\u6807\u7ed3\u5408\u4f7f\u7528\u3002\u540c\u65f6\u5f15\u5165Confidence@k\uff0c\u4e00\u79cd\u5229\u7528\u6821\u51c6token\u6982\u7387\u8fdb\u884c\u8d1d\u53f6\u65af\u6700\u4f18\u8f93\u51fatoken\u9009\u62e9\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u673a\u5236\u3002", "result": "\u4e0eDPO\u76f8\u6bd4\uff0cCATTO\u5728\u5206\u5e03\u5185\u5c06ECE\u964d\u4f4e2.22%-7.61%\uff0c\u5728\u5206\u5e03\u5916\u964d\u4f4e1.46%-10.44%\uff1b\u4e0e\u6700\u5f3aDPO\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5728\u5206\u5e03\u5185\u964d\u4f4e0.22%-1.24%\uff0c\u5728\u5206\u5e03\u5916\u964d\u4f4e1.23%-5.07%\u3002\u7f6e\u4fe1\u5ea6\u6539\u8fdb\u7684\u540c\u65f6\u4e0d\u635f\u5931\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u7684\u591a\u9009\u9898\u56de\u7b54\u51c6\u786e\u6027\u4e0a\u4fdd\u6301\u6216\u7565\u6709\u63d0\u5347\u3002", "conclusion": "CATTO\u80fd\u6709\u6548\u6539\u5584LLM\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u95ee\u9898\uff0c\u5728\u4e0d\u727a\u7272\u4efb\u52a1\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u6821\u51c6\u8bef\u5dee\uff0c\u4e3aLLM\u7684\u53ef\u9760\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2601.23128", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23128", "abs": "https://arxiv.org/abs/2601.23128", "authors": ["Wenbo Liao", "Huipeng Huang", "Chen Jia", "Huajun Xi", "Hao Zeng", "Hongxin Wei"], "title": "Distribution-informed Efficient Conformal Prediction for Full Ranking", "comment": "21 pages, 8 figures", "summary": "Quantifying uncertainty is critical for the safe deployment of ranking models in real-world applications. Recent work offers a rigorous solution using conformal prediction in a full ranking scenario, which aims to construct prediction sets for the absolute ranks of test items based on the relative ranks of calibration items. However, relying on upper bounds of non-conformity scores renders the method overly conservative, resulting in substantially large prediction sets. To address this, we propose Distribution-informed Conformal Ranking (DCR), which produces efficient prediction sets by deriving the exact distribution of non-conformity scores. In particular, we find that the absolute ranks of calibration items follow Negative Hypergeometric distributions, conditional on their relative ranks. DCR thus uses the rank distribution to derive non-conformity score distribution and determine conformal thresholds. We provide theoretical guarantees that DCR achieves improved efficiency over the baseline while ensuring valid coverage under mild assumptions. Extensive experiments demonstrate the superiority of DCR, reducing average prediction set size by up to 36%, while maintaining valid coverage.", "AI": {"tldr": "\u63d0\u51faDCR\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cbe\u786e\u63a8\u5bfc\u975e\u4e00\u81f4\u6027\u5206\u6570\u7684\u5206\u5e03\u6765\u6784\u5efa\u9ad8\u6548\u7684\u6392\u5e8f\u9884\u6d4b\u96c6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u51cf\u5c1136%\u7684\u9884\u6d4b\u96c6\u5927\u5c0f", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u6392\u5e8f\u65b9\u6cd5\u4f9d\u8d56\u975e\u4e00\u81f4\u6027\u5206\u6570\u7684\u4e0a\u754c\uff0c\u5bfc\u81f4\u9884\u6d4b\u96c6\u8fc7\u4e8e\u4fdd\u5b88\u548c\u5e9e\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u65b9\u6cd5", "method": "\u63d0\u51fa\u5206\u5e03\u611f\u77e5\u7684\u4fdd\u5f62\u6392\u5e8f\uff08DCR\uff09\uff0c\u53d1\u73b0\u6821\u51c6\u9879\u7684\u7edd\u5bf9\u6392\u540d\u670d\u4ece\u8d1f\u8d85\u51e0\u4f55\u5206\u5e03\uff0c\u5229\u7528\u8be5\u5206\u5e03\u63a8\u5bfc\u975e\u4e00\u81f4\u6027\u5206\u6570\u5206\u5e03\u5e76\u786e\u5b9a\u4fdd\u5f62\u9608\u503c", "result": "DCR\u5728\u4fdd\u6301\u6709\u6548\u8986\u76d6\u7387\u7684\u540c\u65f6\uff0c\u5c06\u5e73\u5747\u9884\u6d4b\u96c6\u5927\u5c0f\u51cf\u5c11\u9ad8\u8fbe36%\uff0c\u7406\u8bba\u4fdd\u8bc1\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "DCR\u901a\u8fc7\u7cbe\u786e\u5efa\u6a21\u975e\u4e00\u81f4\u6027\u5206\u6570\u5206\u5e03\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6392\u5e8f\u9884\u6d4b\u96c6\u7684\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u6392\u5e8f\u6a21\u578b\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5"}}
{"id": "2601.23151", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23151", "abs": "https://arxiv.org/abs/2601.23151", "authors": ["Katherine Keegan", "Lars Ruthotto"], "title": "Manifold-Aware Perturbations for Constrained Generative Modeling", "comment": null, "summary": "Generative models have enjoyed widespread success in a variety of applications. However, they encounter inherent mathematical limitations in modeling distributions where samples are constrained by equalities, as is frequently the setting in scientific domains. In this work, we develop a computationally cheap, mathematically justified, and highly flexible distributional modification for combating known pitfalls in equality-constrained generative models. We propose perturbing the data distribution in a constraint-aware way such that the new distribution has support matching the ambient space dimension while still implicitly incorporating underlying manifold geometry. Through theoretical analyses and empirical evidence on several representative tasks, we illustrate that our approach consistently enables data distribution recovery and stable sampling with both diffusion models and normalizing flows.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ea6\u675f\u611f\u77e5\u7684\u6570\u636e\u6270\u52a8\u65b9\u6cd5\uff0c\u89e3\u51b3\u751f\u6210\u6a21\u578b\u5728\u7b49\u5f0f\u7ea6\u675f\u5206\u5e03\u5efa\u6a21\u4e2d\u7684\u6570\u5b66\u5c40\u9650\u6027\u95ee\u9898", "motivation": "\u751f\u6210\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\u4e2d\u7ecf\u5e38\u9047\u5230\u6837\u672c\u53d7\u7b49\u5f0f\u7ea6\u675f\u7684\u5206\u5e03\u5efa\u6a21\u95ee\u9898\uff0c\u5b58\u5728\u56fa\u6709\u7684\u6570\u5b66\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u7ea6\u675f\u7684\u5206\u5e03\u4fee\u6539\u65b9\u6cd5", "method": "\u63d0\u51fa\u7ea6\u675f\u611f\u77e5\u7684\u6570\u636e\u6270\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u6270\u52a8\u6570\u636e\u5206\u5e03\u4f7f\u5176\u652f\u6301\u5339\u914d\u73af\u5883\u7a7a\u95f4\u7ef4\u5ea6\uff0c\u540c\u65f6\u9690\u5f0f\u5730\u7ed3\u5408\u5e95\u5c42\u6d41\u5f62\u51e0\u4f55\u7ed3\u6784", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\u4e2d\u80fd\u591f\u4e00\u81f4\u5730\u5b9e\u73b0\u6570\u636e\u5206\u5e03\u6062\u590d\u548c\u7a33\u5b9a\u91c7\u6837\uff0c\u9002\u7528\u4e8e\u6269\u6563\u6a21\u578b\u548c\u5f52\u4e00\u5316\u6d41\u6a21\u578b", "conclusion": "\u63d0\u51fa\u7684\u7ea6\u675f\u611f\u77e5\u6270\u52a8\u65b9\u6cd5\u662f\u4e00\u79cd\u8ba1\u7b97\u5ec9\u4ef7\u3001\u6570\u5b66\u5408\u7406\u4e14\u9ad8\u5ea6\u7075\u6d3b\u7684\u5206\u5e03\u4fee\u6539\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7b49\u5f0f\u7ea6\u675f\u751f\u6210\u6a21\u578b\u7684\u5df2\u77e5\u7f3a\u9677"}}
{"id": "2601.23156", "categories": ["cs.LG", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.23156", "abs": "https://arxiv.org/abs/2601.23156", "authors": ["Damion Harvey", "Geraud Nangue Tasse", "Branden Ingram", "Benjamin Rosman", "Steven James"], "title": "Unsupervised Hierarchical Skill Discovery", "comment": "24 pages, 34 figures. Appendix by Damion Harvey. Damion Harvey is the primary author", "summary": "We consider the problem of unsupervised skill segmentation and hierarchical structure discovery in reinforcement learning. While recent approaches have sought to segment trajectories into reusable skills or options, most rely on action labels, rewards, or handcrafted annotations, limiting their applicability. We propose a method that segments unlabelled trajectories into skills and induces a hierarchical structure over them using a grammar-based approach. The resulting hierarchy captures both low-level behaviours and their composition into higher-level skills. We evaluate our approach in high-dimensional, pixel-based environments, including Craftax and the full, unmodified version of Minecraft. Using metrics for skill segmentation, reuse, and hierarchy quality, we find that our method consistently produces more structured and semantically meaningful hierarchies than existing baselines. Furthermore, as a proof of concept for utility, we demonstrate that these discovered hierarchies accelerate and stabilise learning on downstream reinforcement learning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u76d1\u7763\u6280\u80fd\u5206\u5272\u548c\u5c42\u6b21\u7ed3\u6784\u53d1\u73b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u57fa\u4e8e\u8bed\u6cd5\u7684\u65b9\u6cd5\u4ece\u672a\u6807\u8bb0\u8f68\u8ff9\u4e2d\u5206\u5272\u6280\u80fd\u5e76\u6784\u5efa\u5c42\u6b21\u7ed3\u6784\uff0c\u5728\u50cf\u7d20\u7ea7\u73af\u5883\u4e2d\u9a8c\u8bc1\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u52a8\u4f5c\u6807\u7b7e\u3001\u5956\u52b1\u6216\u4eba\u5de5\u6807\u6ce8\u6765\u5206\u5272\u8f68\u8ff9\u4e3a\u53ef\u91cd\u7528\u6280\u80fd\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u3002\u9700\u8981\u4e00\u79cd\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u65b9\u6cd5\u6765\u53d1\u73b0\u6280\u80fd\u548c\u5c42\u6b21\u7ed3\u6784", "method": "\u4f7f\u7528\u57fa\u4e8e\u8bed\u6cd5\u7684\u65b9\u6cd5\u4ece\u672a\u6807\u8bb0\u8f68\u8ff9\u4e2d\u5206\u5272\u6280\u80fd\uff0c\u5e76\u8bf1\u5bfc\u51fa\u5c42\u6b21\u7ed3\u6784\u3002\u8be5\u65b9\u6cd5\u80fd\u6355\u6349\u4f4e\u7ea7\u884c\u4e3a\u53ca\u5176\u7ec4\u5408\u6210\u9ad8\u7ea7\u6280\u80fd\u7684\u8fc7\u7a0b", "result": "\u5728Craftax\u548c\u5b8c\u6574\u672a\u4fee\u6539\u7248Minecraft\u7b49\u9ad8\u7ef4\u50cf\u7d20\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u5728\u6280\u80fd\u5206\u5272\u3001\u91cd\u7528\u548c\u5c42\u6b21\u8d28\u91cf\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u4ea7\u751f\u66f4\u5177\u7ed3\u6784\u6027\u548c\u8bed\u4e49\u610f\u4e49\u7684\u5c42\u6b21", "conclusion": "\u53d1\u73b0\u7684\u5c42\u6b21\u7ed3\u6784\u80fd\u52a0\u901f\u548c\u7a33\u5b9a\u4e0b\u6e38\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u7684\u5b66\u4e60\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u7528\u4ef7\u503c"}}
{"id": "2601.23164", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23164", "abs": "https://arxiv.org/abs/2601.23164", "authors": ["Daniel Ezer", "Alon Peled-Cohen", "Yishay Mansour"], "title": "Stochastic Linear Bandits with Parameter Noise", "comment": "8 pages", "summary": "We study the stochastic linear bandits with parameter noise model, in which the reward of action $a$ is $a^\\top \u03b8$ where $\u03b8$ is sampled i.i.d. We show a regret upper bound of $\\widetilde{O} (\\sqrt{d T \\log (K/\u03b4) \u03c3^2_{\\max})}$ for a horizon $T$, general action set of size $K$ of dimension $d$, and where $\u03c3^2_{\\max}$ is the maximal variance of the reward for any action. We further provide a lower bound of $\\widetilde\u03a9 (d \\sqrt{T \u03c3^2_{\\max}})$ which is tight (up to logarithmic factors) whenever $\\log (K) \\approx d$. For more specific action sets, $\\ell_p$ unit balls with $p \\leq 2$ and dual norm $q$, we show that the minimax regret is $\\widetilde\u0398 (\\sqrt{dT \u03c3^2_q)}$, where $\u03c3^2_q$ is a variance-dependent quantity that is always at most $4$. This is in contrast to the minimax regret attainable for such sets in the classic additive noise model, where the regret is of order $d \\sqrt{T}$. Surprisingly, we show that this optimal (up to logarithmic factors) regret bound is attainable using a very simple explore-exploit algorithm.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u53c2\u6570\u566a\u58f0\u7684\u968f\u673a\u7ebf\u6027\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9\u4e00\u822c\u52a8\u4f5c\u96c6\u548c\u7279\u5b9a\u2113_p\u7403\u52a8\u4f5c\u96c6\u7684\u7d27\u81f4\u9057\u61be\u4e0a\u4e0b\u754c\uff0c\u5e76\u5c55\u793a\u4e86\u7b80\u5355\u7684\u63a2\u7d22-\u5229\u7528\u7b97\u6cd5\u53ef\u4ee5\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u53c2\u6570\u566a\u58f0\u6a21\u578b\u4e0b\u7684\u968f\u673a\u7ebf\u6027\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u8be5\u6a21\u578b\u4e2d\u5956\u52b1\u51fd\u6570\u5305\u542b\u53c2\u6570\u566a\u58f0\u800c\u975e\u4f20\u7edf\u52a0\u6027\u566a\u58f0\uff0c\u65e8\u5728\u7406\u89e3\u8fd9\u79cd\u566a\u58f0\u7ed3\u6784\u5bf9\u9057\u61be\u754c\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790\u53c2\u6570\u566a\u58f0\u6a21\u578b\u4e0b\u7684\u9057\u61be\u4e0a\u4e0b\u754c\uff1a\u5bf9\u4e8e\u4e00\u822c\u52a8\u4f5c\u96c6\uff0c\u7ed9\u51fa\u4e0a\u754cO\u0303(\u221a(dT log(K/\u03b4)\u03c3\u00b2_max))\u548c\u4e0b\u754c\u03a9\u0303(d\u221a(T\u03c3\u00b2_max))\uff1b\u5bf9\u4e8e\u2113_p\u5355\u4f4d\u7403(p\u22642)\u53ca\u5176\u5bf9\u5076\u8303\u6570q\uff0c\u7ed9\u51fa\u7d27\u81f4\u754c\u0398\u0303(\u221a(dT\u03c3\u00b2_q))\uff0c\u5e76\u8bbe\u8ba1\u7b80\u5355\u7684\u63a2\u7d22-\u5229\u7528\u7b97\u6cd5\u3002", "result": "1) \u4e00\u822c\u52a8\u4f5c\u96c6\uff1a\u5f53log(K)\u2248d\u65f6\uff0c\u9057\u61be\u754c\u662f\u7d27\u81f4\u7684\uff1b2) \u2113_p\u7403\u52a8\u4f5c\u96c6\uff1a\u9057\u61be\u754c\u4e3a\u0398\u0303(\u221a(dT\u03c3\u00b2_q))\uff0c\u5176\u4e2d\u03c3\u00b2_q\u22644\uff0c\u663e\u8457\u4f18\u4e8e\u7ecf\u5178\u52a0\u6027\u566a\u58f0\u6a21\u578b\u7684d\u221a(T)\u9057\u61be\uff1b3) \u7b80\u5355\u7684\u63a2\u7d22-\u5229\u7528\u7b97\u6cd5\u53ef\u4ee5\u8fbe\u5230\u6700\u4f18\u9057\u61be\u754c\u3002", "conclusion": "\u53c2\u6570\u566a\u58f0\u6a21\u578b\u4e0b\u7684\u968f\u673a\u7ebf\u6027\u8d4c\u535a\u673a\u95ee\u9898\u5177\u6709\u4e0e\u7ecf\u5178\u52a0\u6027\u566a\u58f0\u6a21\u578b\u4e0d\u540c\u7684\u9057\u61be\u7279\u6027\uff0c\u5bf9\u4e8e\u2113_p\u7403\u52a8\u4f5c\u96c6\u53ef\u4ee5\u83b7\u5f97\u66f4\u4f18\u7684\u221a(dT)\u91cf\u7ea7\u9057\u61be\uff0c\u4e14\u7b80\u5355\u7b97\u6cd5\u5373\u53ef\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2601.23177", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23177", "abs": "https://arxiv.org/abs/2601.23177", "authors": ["Mikel M. Iparraguirre", "Iciar Alfaro", "David Gonzalez", "Elias Cueto"], "title": "MeshGraphNet-Transformer: Scalable Mesh-based Learned Simulation for Solid Mechanics", "comment": null, "summary": "We present MeshGraphNet-Transformer (MGN-T), a novel architecture that combines the global modeling capabilities of Transformers with the geometric inductive bias of MeshGraphNets, while preserving a mesh-based graph representation. MGN-T overcomes a key limitation of standard MGN, the inefficient long-range information propagation caused by iterative message passing on large, high-resolution meshes. A physics-attention Transformer serves as a global processor, updating all nodal states simultaneously while explicitly retaining node and edge attributes. By directly capturing long-range physical interactions, MGN-T eliminates the need for deep message-passing stacks or hierarchical, coarsened meshes, enabling efficient learning on high-resolution meshes with varying geometries, topologies, and boundary conditions at an industrial scale.\n  We demonstrate that MGN-T successfully handles industrial-scale meshes for impact dynamics, a setting in which standard MGN fails due message-passing under-reaching. The method accurately models self-contact, plasticity, and multivariate outputs, including internal, phenomenological plastic variables. Moreover, MGN-T outperforms state-of-the-art approaches on classical benchmarks, achieving higher accuracy while maintaining practical efficiency, using only a fraction of the parameters required by competing baselines.", "AI": {"tldr": "MeshGraphNet-Transformer (MGN-T) \u7ed3\u5408Transformer\u7684\u5168\u5c40\u5efa\u6a21\u80fd\u529b\u548cMeshGraphNets\u7684\u51e0\u4f55\u5f52\u7eb3\u504f\u7f6e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMGN\u5728\u5927\u89c4\u6a21\u9ad8\u5206\u8fa8\u7387\u7f51\u683c\u4e0a\u957f\u8ddd\u79bb\u4fe1\u606f\u4f20\u64ad\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfMeshGraphNets\u5728\u5927\u89c4\u6a21\u9ad8\u5206\u8fa8\u7387\u7f51\u683c\u4e0a\u5b58\u5728\u957f\u8ddd\u79bb\u4fe1\u606f\u4f20\u64ad\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u5176\u57fa\u4e8e\u8fed\u4ee3\u6d88\u606f\u4f20\u9012\u673a\u5236\uff0c\u9700\u8981\u6df1\u5ea6\u6d88\u606f\u4f20\u9012\u5806\u6808\u6216\u5206\u5c42\u7c97\u5316\u7f51\u683c\u6765\u5904\u7406\u957f\u7a0b\u7269\u7406\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u63d0\u51faMeshGraphNet-Transformer\u67b6\u6784\uff0c\u5c06\u7269\u7406\u6ce8\u610f\u529bTransformer\u4f5c\u4e3a\u5168\u5c40\u5904\u7406\u5668\uff0c\u540c\u65f6\u66f4\u65b0\u6240\u6709\u8282\u70b9\u72b6\u6001\uff0c\u663e\u5f0f\u4fdd\u7559\u8282\u70b9\u548c\u8fb9\u5c5e\u6027\u3002\u8be5\u67b6\u6784\u76f4\u63a5\u6355\u83b7\u957f\u7a0b\u7269\u7406\u76f8\u4e92\u4f5c\u7528\uff0c\u65e0\u9700\u6df1\u5ea6\u6d88\u606f\u4f20\u9012\u5806\u6808\u6216\u5206\u5c42\u7c97\u5316\u7f51\u683c\u3002", "result": "MGN-T\u6210\u529f\u5904\u7406\u5de5\u4e1a\u7ea7\u89c4\u6a21\u7684\u51b2\u51fb\u52a8\u529b\u5b66\u7f51\u683c\uff0c\u51c6\u786e\u5efa\u6a21\u81ea\u63a5\u89e6\u3001\u5851\u6027\u548c\u591a\u53d8\u91cf\u8f93\u51fa\uff08\u5305\u62ec\u5185\u90e8\u73b0\u8c61\u5b66\u5851\u6027\u53d8\u91cf\uff09\u3002\u5728\u7ecf\u5178\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u7cbe\u5ea6\u66f4\u9ad8\u4e14\u4fdd\u6301\u5b9e\u9645\u6548\u7387\uff0c\u4ec5\u9700\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5\u53c2\u6570\u7684\u4e00\u5c0f\u90e8\u5206\u3002", "conclusion": "MGN-T\u901a\u8fc7\u7ed3\u5408Transformer\u7684\u5168\u5c40\u5efa\u6a21\u80fd\u529b\u548cMeshGraphNets\u7684\u51e0\u4f55\u5f52\u7eb3\u504f\u7f6e\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u9ad8\u5206\u8fa8\u7387\u7f51\u683c\u4e0a\u7684\u957f\u8ddd\u79bb\u4fe1\u606f\u4f20\u64ad\u95ee\u9898\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u7269\u7406\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.23215", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23215", "abs": "https://arxiv.org/abs/2601.23215", "authors": ["Marcella Bona", "Nathan Heatley", "Jia-Chen Hua", "Adriana Lara", "Valeria Legaria-Santiago", "Alberto Luviano Juarez", "Fernando Moreno-Gomez", "Jocelyn Richardson", "Natan Vilchis", "Xiwen Shirley Zheng"], "title": "Tackling air quality with SAPIENS", "comment": "24 pages, 13 figures", "summary": "Air pollution is a chronic problem in large cities worldwide and awareness is rising as the long-term health implications become clearer. Vehicular traffic has been identified as a major contributor to poor air quality. In a lot of cities the publicly available air quality measurements and forecasts are coarse-grained both in space and time. However, in general, real-time traffic intensity data is openly available in various forms and is fine-grained. In this paper, we present an in-depth study of pollution sensor measurements combined with traffic data from Mexico City. We analyse and model the relationship between traffic intensity and air quality with the aim to provide hyper-local, dynamic air quality forecasts. We developed an innovative method to represent traffic intensities by transforming simple colour-coded traffic maps into concentric ring-based descriptions, enabling improved characterisation of traffic conditions. Using Partial Least Squares Regression, we predict pollution levels based on these newly defined traffic intensities. The model was optimised with various training samples to achieve the best predictive performance and gain insights into the relationship between pollutants and traffic. The workflow we have designed is straightforward and adaptable to other contexts, like other cities beyond the specifics of our dataset.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790\u58a8\u897f\u54e5\u57ce\u4ea4\u901a\u6570\u636e\u4e0e\u7a7a\u6c14\u8d28\u91cf\u5173\u7cfb\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u5c06\u5f69\u8272\u4ea4\u901a\u5730\u56fe\u8f6c\u6362\u4e3a\u540c\u5fc3\u73af\u63cf\u8ff0\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u504f\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u9884\u6d4b\u6c61\u67d3\u6c34\u5e73\uff0c\u63d0\u4f9b\u8d85\u672c\u5730\u5316\u52a8\u6001\u7a7a\u6c14\u8d28\u91cf\u9884\u62a5\u3002", "motivation": "\u7a7a\u6c14\u6c61\u67d3\u662f\u5168\u7403\u5927\u57ce\u5e02\u7684\u6162\u6027\u95ee\u9898\uff0c\u4ea4\u901a\u662f\u4e3b\u8981\u6c61\u67d3\u6e90\u3002\u73b0\u6709\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u548c\u9884\u62a5\u5728\u65f6\u7a7a\u4e0a\u8f83\u4e3a\u7c97\u7cd9\uff0c\u800c\u5b9e\u65f6\u4ea4\u901a\u6570\u636e\u901a\u5e38\u66f4\u7cbe\u7ec6\u4e14\u516c\u5f00\u53ef\u7528\u3002\u7814\u7a76\u65e8\u5728\u5229\u7528\u7cbe\u7ec6\u4ea4\u901a\u6570\u636e\u63d0\u4f9b\u8d85\u672c\u5730\u5316\u3001\u52a8\u6001\u7684\u7a7a\u6c14\u8d28\u91cf\u9884\u62a5\u3002", "method": "1. \u5f00\u53d1\u521b\u65b0\u65b9\u6cd5\u5c06\u7b80\u5355\u7684\u5f69\u8272\u7f16\u7801\u4ea4\u901a\u5730\u56fe\u8f6c\u6362\u4e3a\u57fa\u4e8e\u540c\u5fc3\u73af\u7684\u63cf\u8ff0\uff0c\u6539\u8fdb\u4ea4\u901a\u72b6\u51b5\u8868\u5f81\uff1b2. \u4f7f\u7528\u504f\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u57fa\u4e8e\u65b0\u5b9a\u4e49\u7684\u4ea4\u901a\u5f3a\u5ea6\u9884\u6d4b\u6c61\u67d3\u6c34\u5e73\uff1b3. \u901a\u8fc7\u4e0d\u540c\u8bad\u7ec3\u6837\u672c\u4f18\u5316\u6a21\u578b\u4ee5\u83b7\u5f97\u6700\u4f73\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5efa\u7acb\u4e86\u4ea4\u901a\u5f3a\u5ea6\u4e0e\u7a7a\u6c14\u8d28\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u6a21\u578b\uff0c\u80fd\u591f\u57fa\u4e8e\u7cbe\u7ec6\u4ea4\u901a\u6570\u636e\u9884\u6d4b\u6c61\u67d3\u6c34\u5e73\u3002\u6a21\u578b\u7ecf\u8fc7\u4f18\u5316\u8fbe\u5230\u6700\u4f73\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u6df1\u5165\u4e86\u89e3\u4e86\u6c61\u67d3\u7269\u4e0e\u4ea4\u901a\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u7a0b\u8bbe\u8ba1\u7b80\u5355\u4e14\u9002\u5e94\u6027\u5f3a\uff0c\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u57ce\u5e02\u73af\u5883\uff0c\u4e3a\u8d85\u672c\u5730\u5316\u52a8\u6001\u7a7a\u6c14\u8d28\u91cf\u9884\u62a5\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u57ce\u5e02\u7a7a\u6c14\u8d28\u91cf\u7ba1\u7406\u3002"}}
{"id": "2601.23221", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23221", "abs": "https://arxiv.org/abs/2601.23221", "authors": ["Gabriel Singer", "Samuel Gruffaz", "Olivier Vo Van", "Nicolas Vayatis", "Argyris Kalogeratos"], "title": "Optimal Fair Aggregation of Crowdsourced Noisy Labels using Demographic Parity Constraints", "comment": null, "summary": "As acquiring reliable ground-truth labels is usually costly, or infeasible, crowdsourcing and aggregation of noisy human annotations is the typical resort. Aggregating subjective labels, though, may amplify individual biases, particularly regarding sensitive features, raising fairness concerns. Nonetheless, fairness in crowdsourced aggregation remains largely unexplored, with no existing convergence guarantees and only limited post-processing approaches for enforcing $\\varepsilon$-fairness under demographic parity. We address this gap by analyzing the fairness s of crowdsourced aggregation methods within the $\\varepsilon$-fairness framework, for Majority Vote and Optimal Bayesian aggregation. In the small-crowd regime, we derive an upper bound on the fairness gap of Majority Vote in terms of the fairness gaps of the individual annotators. We further show that the fairness gap of the aggregated consensus converges exponentially fast to that of the ground-truth under interpretable conditions. Since ground-truth itself may still be unfair, we generalize a state-of-the-art multiclass fairness post-processing algorithm from the continuous to the discrete setting, which enforces strict demographic parity constraints to any aggregation rule. Experiments on synthetic and real datasets demonstrate the effectiveness of our approach and corroborate the theoretical insights.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4f17\u5305\u6807\u6ce8\u805a\u5408\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5206\u6790\u4e86\u591a\u6570\u6295\u7968\u548c\u8d1d\u53f6\u65af\u805a\u5408\u65b9\u6cd5\u7684\u516c\u5e73\u6027\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e86\u7406\u8bba\u754c\u9650\u548c\u6536\u655b\u4fdd\u8bc1\uff0c\u5e76\u6269\u5c55\u4e86\u591a\u7c7b\u522b\u516c\u5e73\u6027\u540e\u5904\u7406\u7b97\u6cd5\u3002", "motivation": "\u83b7\u53d6\u53ef\u9760\u7684\u771f\u5b9e\u6807\u7b7e\u901a\u5e38\u6210\u672c\u9ad8\u6602\u6216\u4e0d\u53ef\u884c\uff0c\u56e0\u6b64\u4f17\u5305\u548c\u805a\u5408\u566a\u58f0\u4eba\u5de5\u6807\u6ce8\u662f\u5e38\u7528\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u805a\u5408\u4e3b\u89c2\u6807\u7b7e\u53ef\u80fd\u4f1a\u653e\u5927\u4e2a\u4f53\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u654f\u611f\u7279\u5f81\u65b9\u9762\uff0c\u5f15\u53d1\u516c\u5e73\u6027\u62c5\u5fe7\u3002\u76ee\u524d\u4f17\u5305\u805a\u5408\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u7f3a\u4e4f\u6536\u655b\u4fdd\u8bc1\uff0c\u4e14\u4ec5\u6709\u6709\u9650\u7684\u03b5-\u516c\u5e73\u6027\u540e\u5904\u7406\u65b9\u6cd5\u3002", "method": "1) \u5728\u03b5-\u516c\u5e73\u6027\u6846\u67b6\u4e0b\u5206\u6790\u591a\u6570\u6295\u7968\u548c\u6700\u4f18\u8d1d\u53f6\u65af\u805a\u5408\u65b9\u6cd5\u7684\u516c\u5e73\u6027\uff1b2) \u5728\u5c0f\u4f17\u5305\u89c4\u6a21\u4e0b\u63a8\u5bfc\u591a\u6570\u6295\u7968\u516c\u5e73\u6027\u5dee\u8ddd\u7684\u4e0a\u754c\uff1b3) \u8bc1\u660e\u805a\u5408\u5171\u8bc6\u7684\u516c\u5e73\u6027\u5dee\u8ddd\u5728\u53ef\u89e3\u91ca\u6761\u4ef6\u4e0b\u4ee5\u6307\u6570\u901f\u5ea6\u6536\u655b\u5230\u771f\u5b9e\u6807\u7b7e\u7684\u516c\u5e73\u6027\u5dee\u8ddd\uff1b4) \u5c06\u6700\u5148\u8fdb\u7684\u591a\u7c7b\u522b\u516c\u5e73\u6027\u540e\u5904\u7406\u7b97\u6cd5\u4ece\u8fde\u7eed\u8bbe\u7f6e\u6269\u5c55\u5230\u79bb\u6563\u8bbe\u7f6e\uff0c\u4ee5\u5f3a\u5236\u6267\u884c\u4e25\u683c\u7684\u4eba\u53e3\u7edf\u8ba1\u5e73\u7b49\u7ea6\u675f\u3002", "result": "1) \u63a8\u5bfc\u4e86\u591a\u6570\u6295\u7968\u516c\u5e73\u6027\u5dee\u8ddd\u7684\u4e0a\u754c\uff1b2) \u8bc1\u660e\u4e86\u805a\u5408\u5171\u8bc6\u516c\u5e73\u6027\u5dee\u8ddd\u7684\u6307\u6570\u6536\u655b\u6027\uff1b3) \u6269\u5c55\u4e86\u591a\u7c7b\u522b\u516c\u5e73\u6027\u540e\u5904\u7406\u7b97\u6cd5\uff1b4) \u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u5e76\u652f\u6301\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u4f17\u5305\u805a\u5408\u516c\u5e73\u6027\u5206\u6790\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u65b9\u6cd5\u3002\u901a\u8fc7\u5206\u6790\u805a\u5408\u65b9\u6cd5\u7684\u516c\u5e73\u6027\u7279\u6027\u3001\u8bc1\u660e\u6536\u655b\u6027\uff0c\u5e76\u6269\u5c55\u516c\u5e73\u6027\u540e\u5904\u7406\u7b97\u6cd5\uff0c\u4e3a\u6784\u5efa\u66f4\u516c\u5e73\u7684\u4f17\u5305\u6807\u6ce8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2601.23278", "categories": ["cs.LG", "cs.AR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.23278", "abs": "https://arxiv.org/abs/2601.23278", "authors": ["Kaihua Liang", "Xin Tan", "An Zhong", "Hong Xu", "Marco Canini"], "title": "FOCUS: DLLMs Know How to Tame Their Compute Bound", "comment": "22 pages, 15 figures", "summary": "Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. We further observe a strong correlation between attention-derived token importance and token-wise decoding probability. Based on this insight, we propose FOCUS -- an inference system designed for DLLMs. By dynamically focusing computation on decodable tokens and evicting non-decodable ones on-the-fly, FOCUS increases the effective batch size, alleviating compute limitations and enabling scalable throughput. Empirical evaluations demonstrate that FOCUS achieves up to 3.52$\\times$ throughput improvement over the production-grade engine LMDeploy, while preserving or improving generation quality across multiple benchmarks. The FOCUS system is publicly available on GitHub: https://github.com/sands-lab/FOCUS.", "AI": {"tldr": "FOCUS\u7cfb\u7edf\u901a\u8fc7\u52a8\u6001\u805a\u7126\u8ba1\u7b97\u4e8e\u53ef\u89e3\u7801token\u5e76\u5b9e\u65f6\u6dd8\u6c70\u4e0d\u53ef\u89e3\u7801token\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u7801\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad83.52\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08DLLMs\uff09\u4f5c\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5176\u90e8\u7f72\u53d7\u5230\u9ad8\u89e3\u7801\u6210\u672c\u7684\u9650\u5236\u3002\u7814\u7a76\u53d1\u73b0DLLM\u89e3\u7801\u5b58\u5728\u5173\u952e\u4f4e\u6548\u95ee\u9898\uff1a\u867d\u7136\u8ba1\u7b97\u5728token\u5757\u4e0a\u5e76\u884c\u5316\uff0c\u4f46\u6bcf\u4e2a\u6269\u6563\u6b65\u9aa4\u53ea\u6709\u5c11\u91cftoken\u53ef\u89e3\u7801\uff0c\u5bfc\u81f4\u5927\u90e8\u5206\u8ba1\u7b97\u6d6a\u8d39\u5728\u4e0d\u53ef\u89e3\u7801token\u4e0a\u3002", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u5f97\u51fa\u7684token\u91cd\u8981\u6027\u4e0etoken\u89e3\u7801\u6982\u7387\u4e4b\u95f4\u7684\u5f3a\u76f8\u5173\u6027\uff0c\u63d0\u51faFOCUS\u63a8\u7406\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u52a8\u6001\u805a\u7126\u8ba1\u7b97\u4e8e\u53ef\u89e3\u7801token\uff0c\u5e76\u5b9e\u65f6\u6dd8\u6c70\u4e0d\u53ef\u89e3\u7801token\uff0c\u589e\u52a0\u6709\u6548\u6279\u5904\u7406\u5927\u5c0f\uff0c\u7f13\u89e3\u8ba1\u7b97\u9650\u5236\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u541e\u5410\u91cf\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cFOCUS\u76f8\u6bd4\u751f\u4ea7\u7ea7\u5f15\u64ceLMDeploy\u5b9e\u73b0\u4e86\u6700\u9ad83.52\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "FOCUS\u7cfb\u7edf\u901a\u8fc7\u4f18\u5316DLLM\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4e3aDLLMs\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.23280", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.23280", "abs": "https://arxiv.org/abs/2601.23280", "authors": ["Thomas Y. L. Lin", "Jiachen Yao", "Lufang Chiang", "Julius Berner", "Anima Anandkumar"], "title": "Decoupled Diffusion Sampling for Inverse Problems on Function Spaces", "comment": null, "summary": "We propose a data-efficient, physics-aware generative framework in function space for inverse PDE problems. Existing plug-and-play diffusion posterior samplers represent physics implicitly through joint coefficient-solution modeling, requiring substantial paired supervision. In contrast, our Decoupled Diffusion Inverse Solver (DDIS) employs a decoupled design: an unconditional diffusion learns the coefficient prior, while a neural operator explicitly models the forward PDE for guidance. This decoupling enables superior data efficiency and effective physics-informed learning, while naturally supporting Decoupled Annealing Posterior Sampling (DAPS) to avoid over-smoothing in Diffusion Posterior Sampling (DPS). Theoretically, we prove that DDIS avoids the guidance attenuation failure of joint models when training data is scarce. Empirically, DDIS achieves state-of-the-art performance under sparse observation, improving $l_2$ error by 11% and spectral error by 54% on average; when data is limited to 1%, DDIS maintains accuracy with 40% advantage in $l_2$ error compared to joint models.", "AI": {"tldr": "\u63d0\u51faDDIS\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u8bbe\u8ba1\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u7684PDE\u9006\u95ee\u9898\u6c42\u89e3\uff1a\u65e0\u6761\u4ef6\u6269\u6563\u5b66\u4e60\u7cfb\u6570\u5148\u9a8c\uff0c\u795e\u7ecf\u7b97\u5b50\u663e\u5f0f\u5efa\u6a21\u524d\u5411PDE\u6307\u5bfc\uff0c\u907f\u514d\u8054\u5408\u6a21\u578b\u5728\u6570\u636e\u7a00\u7f3a\u65f6\u7684\u6307\u5bfc\u8870\u51cf\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u540e\u9a8c\u91c7\u6837\u7684\u65b9\u6cd5\u901a\u8fc7\u8054\u5408\u7cfb\u6570-\u89e3\u5efa\u6a21\u9690\u5f0f\u8868\u793a\u7269\u7406\uff0c\u9700\u8981\u5927\u91cf\u914d\u5bf9\u76d1\u7763\u6570\u636e\u3002\u5728\u6570\u636e\u7a00\u7f3a\u65f6\uff0c\u8054\u5408\u6a21\u578b\u4f1a\u51fa\u73b0\u6307\u5bfc\u8870\u51cf\u95ee\u9898\uff0c\u5f71\u54cd\u9006\u95ee\u9898\u6c42\u89e3\u6548\u679c\u3002", "method": "\u63d0\u51fa\u89e3\u8026\u6269\u6563\u9006\u6c42\u89e3\u5668\uff08DDIS\uff09\uff1a1\uff09\u65e0\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5b66\u4e60\u7cfb\u6570\u5148\u9a8c\u5206\u5e03\uff1b2\uff09\u795e\u7ecf\u7b97\u5b50\u663e\u5f0f\u5efa\u6a21\u524d\u5411PDE\u7269\u7406\u7ea6\u675f\uff1b3\uff09\u5f15\u5165\u89e3\u8026\u9000\u706b\u540e\u9a8c\u91c7\u6837\uff08DAPS\uff09\u907f\u514d\u6269\u6563\u540e\u9a8c\u91c7\u6837\u4e2d\u7684\u8fc7\u5e73\u6ed1\u95ee\u9898\u3002", "result": "\u5728\u7a00\u758f\u89c2\u6d4b\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u5e73\u5747l2\u8bef\u5dee\u63d0\u534711%\uff0c\u8c31\u8bef\u5dee\u63d0\u534754%\uff1b\u5f53\u6570\u636e\u9650\u5236\u57281%\u65f6\uff0cDDIS\u76f8\u6bd4\u8054\u5408\u6a21\u578b\u5728l2\u8bef\u5dee\u4e0a\u4fdd\u630140%\u4f18\u52bf\u3002\u7406\u8bba\u8bc1\u660eDDIS\u907f\u514d\u4e86\u8054\u5408\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u65f6\u7684\u6307\u5bfc\u8870\u51cf\u95ee\u9898\u3002", "conclusion": "DDIS\u901a\u8fc7\u89e3\u8026\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u6570\u636e\u9ad8\u6548\u7684\u7269\u7406\u611f\u77e5\u751f\u6210\u6846\u67b6\uff0c\u5728PDE\u9006\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6570\u636e\u6548\u7387\u548c\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
