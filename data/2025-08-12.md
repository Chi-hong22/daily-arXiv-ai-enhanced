<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 220]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.GT](#cs.GT) [Total: 10]
- [cs.HC](#cs.HC) [Total: 46]
- [cs.MA](#cs.MA) [Total: 5]
- [eess.IV](#eess.IV) [Total: 15]
- [cs.SD](#cs.SD) [Total: 16]
- [cs.RO](#cs.RO) [Total: 60]
- [eess.SY](#eess.SY) [Total: 23]
- [cs.LG](#cs.LG) [Total: 144]
- [cs.NE](#cs.NE) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG](https://arxiv.org/abs/2508.06496)
*Rakesh Raj Madavan,Akshat Kaimal,Hashim Faisal,Chandrakala S*

Main category: cs.CV

TL;DR: BIND模型通过密集编码改进多模态嵌入空间，Med-GRIM利用图检索和提示工程实现高效医疗VQA，并发布DermaGraph数据集支持零样本研究。


<details>
  <summary>Details</summary>
Motivation: 现有VQA模型在复杂领域（如医疗）中缺乏精确性，需改进。

Method: BIND通过密集编码优化嵌入空间；Med-GRIM结合图检索、提示工程和小语言模型实现高效医疗VQA。

Result: Med-GRIM以低计算成本达到大模型性能，并发布DermaGraph数据集。

Conclusion: BIND和Med-GRIM为医疗VQA提供了高效、精确的解决方案，支持零样本研究。

Abstract: An ensemble of trained multimodal encoders and vision-language models (VLMs)
has become a standard approach for visual question answering (VQA) tasks.
However, such models often fail to produce responses with the detailed
precision necessary for complex, domain-specific applications such as medical
VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding,
extends prior multimodal work by refining the joint embedding space through
dense, query-token-based encodings inspired by contrastive pretraining
techniques. This refined encoder powers Med-GRIM, a model designed for medical
VQA tasks that leverages graph-based retrieval and prompt engineering to
integrate domain-specific knowledge. Rather than relying on compute-heavy
fine-tuning of vision and language models on specific datasets, Med-GRIM
applies a low-compute, modular workflow with small language models (SLMs) for
efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject
relevant knowledge, ensuring both accuracy and robustness in its responses. By
assigning distinct roles to each agent within the VQA system, Med-GRIM achieves
large language model performance at a fraction of the computational cost.
Additionally, to support scalable research in zero-shot multimodal medical
applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising
diverse dermatological conditions. This dataset facilitates both multimodal and
unimodal querying. The code and dataset are available at:
https://github.com/Rakesh-123-cryp/Med-GRIM.git

</details>


### [2] [DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation](https://arxiv.org/abs/2508.06511)
*He Feng,Yongjia Ma,Donglin Di,Lei Fan,Tonghua Su,Xiangqian Wu*

Main category: cs.CV

TL;DR: DiTalker是一个基于DiT的统一框架，用于可控说话风格的人像动画，解决了现有方法在动态风格（如头部运动）上的不足，并通过模块化设计优化了同步和细节保留。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的人像动画方法主要关注唇同步或静态情感转换，忽略了动态风格（如头部运动），且双U-Net架构计算开销大。

Method: 提出DiTalker框架，包含风格-情感编码模块（分离提取风格和情感特征）和音频-风格融合模块（通过交叉注意力层解耦音频与说话风格），并引入优化约束提升效果。

Result: 实验表明DiTalker在唇同步和说话风格可控性上表现优越。

Conclusion: DiTalker通过模块化设计和优化约束，显著提升了人像动画的动态风格表现和细节保留能力。

Abstract: Portrait animation aims to synthesize talking videos from a static reference
face, conditioned on audio and style frame cues (e.g., emotion and head poses),
while ensuring precise lip synchronization and faithful reproduction of
speaking styles. Existing diffusion-based portrait animation methods primarily
focus on lip synchronization or static emotion transformation, often
overlooking dynamic styles such as head movements. Moreover, most of these
methods rely on a dual U-Net architecture, which preserves identity consistency
but incurs additional computational overhead. To this end, we propose DiTalker,
a unified DiT-based framework for speaking style-controllable portrait
animation. We design a Style-Emotion Encoding Module that employs two separate
branches: a style branch extracting identity-specific style information (e.g.,
head poses and movements), and an emotion branch extracting identity-agnostic
emotion features. We further introduce an Audio-Style Fusion Module that
decouples audio and speaking styles via two parallel cross-attention layers,
using these features to guide the animation process. To enhance the quality of
results, we adopt and modify two optimization constraints: one to improve lip
synchronization and the other to preserve fine-grained identity and background
details. Extensive experiments demonstrate the superiority of DiTalker in terms
of lip synchronization and speaking style controllability. Project Page:
https://thenameishope.github.io/DiTalker/

</details>


### [3] [VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions](https://arxiv.org/abs/2508.06757)
*Yash Garg,Saketh Bachu,Arindam Dutta,Rohit Lal,Sarosij Bose,Calvin-Khang Ta,M. Salman Asif,Amit Roy-Chowdhury*

Main category: cs.CV

TL;DR: 论文提出了一种新的视频基准数据集VOccl3D，用于解决现有3D人体姿态和形状估计方法在复杂遮挡场景下的不足，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在真实遮挡场景中表现不佳，且现有数据集缺乏真实遮挡情况，因此需要更真实的数据集来推动研究。

Method: 利用计算机图形渲染技术构建VOccl3D数据集，包含多样化的真实遮挡场景和人体动作，并基于此微调CLIFF和BEDLAM-CLIFF方法。

Result: 实验表明，微调后的方法在多个公共数据集及VOccl3D测试集上均取得显著提升，同时增强了遮挡下的人体检测性能。

Conclusion: VOccl3D为未来遮挡场景下的研究提供了更真实的基准资源。

Abstract: Human pose and shape (HPS) estimation methods have been extensively studied,
with many demonstrating high zero-shot performance on in-the-wild images and
videos. However, these methods often struggle in challenging scenarios
involving complex human poses or significant occlusions. Although some studies
address 3D human pose estimation under occlusion, they typically evaluate
performance on datasets that lack realistic or substantial occlusions, e.g.,
most existing datasets introduce occlusions with random patches over the human
or clipart-style overlays, which may not reflect real-world challenges. To
bridge this gap in realistic occlusion datasets, we introduce a novel benchmark
dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and
shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed
this dataset using advanced computer graphics rendering techniques,
incorporating diverse real-world occlusion scenarios, clothing textures, and
human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and
BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and
quantitative improvements across multiple public datasets, as well as on the
test split of our dataset, while comparing its performance with other
state-of-the-art methods. Furthermore, we leveraged our dataset to enhance
human detection performance under occlusion by fine-tuning an existing object
detector, YOLO11, thus leading to a robust end-to-end HPS estimation system
under occlusions. Overall, this dataset serves as a valuable resource for
future research aimed at benchmarking methods designed to handle occlusions,
offering a more realistic alternative to existing occlusion datasets. See the
Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/

</details>


### [4] [BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok](https://arxiv.org/abs/2508.06515)
*Minh Duc Chu,Kshitij Pawar,Zihao He,Roxanna Sharifi,Ross Sonnenblick,Magdalayna Curry,Laura D'Adamo,Lindsay Young,Stuart B Murray,Kristina Lerman*

Main category: cs.CV

TL;DR: 论文提出BigTokDetect框架，用于检测TikTok上促进肌肉畸形的有害内容，通过多模态融合提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上促进肌肉畸形的有害内容（如pro-bigorexia）难以通过传统文本检测系统识别，需多模态方法解决。

Method: 开发BigTokDetect框架，使用专家标注的多模态数据集BigTok（2200+视频），结合视觉语言模型进行检测。

Result: 模型在主要类别分类上达到82.9%准确率，子类别检测69%，多模态融合比纯文本方法性能提升5-10%。

Conclusion: 研究为多模态有害内容检测设定了新基准，提供了可扩展的内容审核工具和方法框架。

Abstract: Social media platforms increasingly struggle to detect harmful content that
promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that
disproportionately affects adolescent males. Unlike traditional eating disorder
detection focused on the "thin ideal," pro-bigorexia material masquerades as
legitimate fitness content through complex multimodal combinations of visual
displays, coded language, and motivational messaging that evade text-based
detection systems. We address this challenge by developing BigTokDetect, a
clinically-informed detection framework for identifying pro-bigorexia content
on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset
of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists
across five primary categories spanning body image, nutrition, exercise,
supplements, and masculinity. Through a comprehensive evaluation of
state-of-the-art vision language models, we achieve 0.829% accuracy on primary
category classification and 0.690% on subcategory detection via domain-specific
finetuning. Our ablation studies demonstrate that multimodal fusion improves
performance by 5-10% over text-only approaches, with video features providing
the most discriminative signals. These findings establish new benchmarks for
multimodal harmful content detection and provide both the computational tools
and methodological framework needed for scalable content moderation in
specialized mental health domains.

</details>


### [5] [DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging](https://arxiv.org/abs/2508.06768)
*Noe Bertramo,Gabriel Duguey,Vivek Gopalakrishnan*

Main category: cs.CV

TL;DR: DiffUS是一种基于物理的可微分超声渲染器，能够从MRI/CT数据生成逼真的B模式超声图像，用于术中导航。


<details>
  <summary>Details</summary>
Motivation: 解决术中超声图像因噪声、伪影及与术前MRI/CT对齐困难导致的解读难题。

Method: 1. 通过机器学习将MRI 3D扫描转换为声阻抗体积；2. 使用射线追踪和反射-传输方程模拟超声束传播；3. 通过稀疏线性系统捕获多次内部反射；4. 重建B模式图像，包含斑点噪声和深度相关伪影。

Result: 在ReMIND数据集上验证了DiffUS能从脑部MRI数据生成解剖学准确的超声图像。

Conclusion: DiffUS为术中导航提供了一种高效的工具，支持基于梯度的优化应用。

Abstract: Intraoperative ultrasound imaging provides real-time guidance during numerous
surgical procedures, but its interpretation is complicated by noise, artifacts,
and poor alignment with high-resolution preoperative MRI/CT scans. To bridge
the gap between reoperative planning and intraoperative guidance, we present
DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes
realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D
scans into acoustic impedance volumes using a machine learning approach. Next,
we simulate ultrasound beam propagation using ray tracing with coupled
reflection-transmission equations. DiffUS formulates wave propagation as a
sparse linear system that captures multiple internal reflections. Finally, we
reconstruct B-mode images via depth-resolved echo extraction across fan-shaped
acquisition geometry, incorporating realistic artifacts including speckle noise
and depth-dependent degradation. DiffUS is entirely implemented as
differentiable tensor operations in PyTorch, enabling gradient-based
optimization for downstream applications such as slice-to-volume registration
and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates
DiffUS's ability to generate anatomically accurate ultrasound images from brain
MRI data.

</details>


### [6] [Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation](https://arxiv.org/abs/2508.06517)
*Haoran Xi,Chen Liu,Xiaolin Li*

Main category: cs.CV

TL;DR: FPGM是一种基于频率先验的半监督学习方法，通过利用息肉边缘的频率特征提升跨域分割性能。


<details>
  <summary>Details</summary>
Motivation: 自动化息肉分割对结直肠癌早期诊断至关重要，但现有方法在数据有限和域偏移下性能下降严重。

Method: FPGM通过两阶段过程：学习域不变频率先验，并对未标记图像进行频谱扰动以对齐频率特征。

Result: 在六个公共数据集上验证，FPGM性能优于十种竞争方法，零样本泛化能力显著提升。

Conclusion: FPGM为有限监督下的临床可部署息肉分割提供了强大解决方案。

Abstract: Automated polyp segmentation is essential for early diagnosis of colorectal
cancer, yet developing robust models remains challenging due to limited
annotated data and significant performance degradation under domain shift.
Although semi-supervised learning (SSL) reduces annotation requirements,
existing methods rely on generic augmentations that ignore polyp-specific
structural properties, resulting in poor generalization to new imaging centers
and devices. To address this, we introduce Frequency Prior Guided Matching
(FPGM), a novel augmentation framework built on a key discovery: polyp edges
exhibit a remarkably consistent frequency signature across diverse datasets.
FPGM leverages this intrinsic regularity in a two-stage process. It first
learns a domain-invariant frequency prior from the edge regions of labeled
polyps. Then, it performs principled spectral perturbations on unlabeled
images, aligning their amplitude spectra with this learned prior while
preserving phase information to maintain structural integrity. This targeted
alignment normalizes domain-specific textural variations, thereby compelling
the model to learn the underlying, generalizable anatomical structure.
Validated on six public datasets, FPGM establishes a new state-of-the-art
against ten competing methods. It demonstrates exceptional zero-shot
generalization capabilities, achieving over 10% absolute gain in Dice score in
data-scarce scenarios. By significantly enhancing cross-domain robustness, FPGM
presents a powerful solution for clinically deployable polyp segmentation under
limited supervision.

</details>


### [7] [Large Language Models Facilitate Vision Reflection in Image Classification](https://arxiv.org/abs/2508.06525)
*Guoyuan An,JaeYoon Kim,SungEui Yoon*

Main category: cs.CV

TL;DR: 论文探讨了大型多模态模型（LMMs）中视觉反射的可解释性，发现通过提示LMM验证专用视觉模型的预测可提高准确性，并揭示了视觉-语言连接器将视觉特征映射为文本概念的行为。此外，研究表明LMMs可能依赖少量文本表示而非原始视觉特征，且无需训练的连接器也能提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示LMMs在视觉任务中的行为机制，探索如何通过视觉反射提升模型的准确性和可解释性。

Method: 通过提示LMM验证视觉模型的预测，分析视觉反射的内部行为，并测试替换视觉令牌为文本令牌的效果。还研究了无需训练的连接器在细粒度识别任务中的应用。

Result: 发现视觉反射能提高准确性，视觉-语言连接器将视觉特征映射为文本概念，且少量文本令牌可替代大量视觉令牌。无需训练的连接器也能提升性能。

Conclusion: 视觉反射是提升LMMs视觉识别鲁棒性和可解释性的有效策略，为理解多模态模型提供了新视角。

Abstract: This paper presents several novel findings on the explainability of vision
reflection in large multimodal models (LMMs). First, we show that prompting an
LMM to verify the prediction of a specialized vision model can improve
recognition accuracy, even on benchmarks like ImageNet, despite prior evidence
that LMMs typically underperform dedicated vision encoders. Second, we analyze
the internal behavior of vision reflection and find that the vision-language
connector maps visual features into explicit textual concepts, allowing the
language model to reason about prediction plausibility using commonsense
knowledge. We further observe that replacing a large number of vision tokens
with only a few text tokens still enables LLaVA to generate similar answers,
suggesting that LMMs may rely primarily on a compact set of distilled textual
representations rather than raw vision features. Third, we show that a
training-free connector can enhance LMM performance in fine-grained recognition
tasks, without extensive feature-alignment training. Together, these findings
offer new insights into the explainability of vision-language models and
suggest that vision reflection is a promising strategy for achieving robust and
interpretable visual recognition.

</details>


### [8] [A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition](https://arxiv.org/abs/2508.06528)
*Xiuliang Zhang,Tadiwa Elisha Nyamasvisva,Chuntao Liu*

Main category: cs.CV

TL;DR: 提出了一种结合3D CNN和Transformer的混合框架，用于视频行为识别，解决了传统方法在长程依赖和高计算成本上的问题。


<details>
  <summary>Details</summary>
Motivation: 传统3D CNN难以建模长程依赖，而Transformer计算成本高，需要一种兼顾局部和全局特征的高效方法。

Method: 混合框架中，3D CNN提取低层时空特征，Transformer捕获长程时间依赖，并通过融合机制整合两者。

Result: 在基准数据集上表现优于传统3D CNN和单独Transformer，识别精度更高且复杂度可控。

Conclusion: 混合框架为视频行为识别提供了高效且可扩展的解决方案。

Abstract: Video-based behavior recognition is essential in fields such as public
safety, intelligent surveillance, and human-computer interaction. Traditional
3D Convolutional Neural Network (3D CNN) effectively capture local
spatiotemporal features but struggle with modeling long-range dependencies.
Conversely, Transformers excel at learning global contextual information but
face challenges with high computational costs. To address these limitations, we
propose a hybrid framework combining 3D CNN and Transformer architectures. The
3D CNN module extracts low-level spatiotemporal features, while the Transformer
module captures long-range temporal dependencies, with a fusion mechanism
integrating both representations. Evaluated on benchmark datasets, the proposed
model outperforms traditional 3D CNN and standalone Transformers, achieving
higher recognition accuracy with manageable complexity. Ablation studies
further validate the complementary strengths of the two modules. This hybrid
framework offers an effective and scalable solution for video-based behavior
recognition.

</details>


### [9] [Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View](https://arxiv.org/abs/2508.06968)
*Ulas Gunes,Matias Turkulainen,Juho Kannala,Esa Rahtu*

Main category: cs.CV

TL;DR: 首次评估了Fisheye-GS和3DGUT两种基于鱼眼镜头的3D高斯溅射方法在真实图像上的表现，分析了极端畸变下的性能。


<details>
  <summary>Details</summary>
Motivation: 研究鱼眼镜头在超过180度视场下的3D重建效果，解决强畸变场景中的初始化问题。

Method: 使用200度鱼眼镜头捕捉室内外场景，评估不同视场（200度、160度、120度）下的性能，并提出基于UniK3D的深度初始化策略。

Result: Fisheye-GS在160度视场下表现最佳，3DGUT在200度视场下保持稳定；UniK3D初始化效果与SfM相当。

Conclusion: 鱼眼3DGS方法在稀疏且畸变严重的图像输入下具有实用价值。

Abstract: We present the first evaluation of fisheye-based 3D Gaussian Splatting
methods, Fisheye-GS and 3DGUT, on real images with fields of view exceeding 180
degree. Our study covers both indoor and outdoor scenes captured with 200
degree fisheye cameras and analyzes how each method handles extreme distortion
in real world settings. We evaluate performance under varying fields of view
(200 degree, 160 degree, and 120 degree) to study the tradeoff between
peripheral distortion and spatial coverage. Fisheye-GS benefits from field of
view (FoV) reduction, particularly at 160 degree, while 3DGUT remains stable
across all settings and maintains high perceptual quality at the full 200
degree view. To address the limitations of SfM-based initialization, which
often fails under strong distortion, we also propose a depth-based strategy
using UniK3D predictions from only 2-3 fisheye images per scene. Although
UniK3D is not trained on real fisheye data, it produces dense point clouds that
enable reconstruction quality on par with SfM, even in difficult scenes with
fog, glare, or sky. Our results highlight the practical viability of
fisheye-based 3DGS methods for wide-angle 3D reconstruction from sparse and
distortion-heavy image inputs.

</details>


### [10] [StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback](https://arxiv.org/abs/2508.06555)
*Hongbo Ma,Fei Shen,Hongbin Xu,Xiaoce Wang,Gang Xu,Jinkai Zheng,Liangqiong Qu,Ming Li*

Main category: cs.CV

TL;DR: StyleTailor是一个协作代理框架，通过多级负面反馈驱动的迭代视觉优化，实现个性化时尚设计和购物推荐。


<details>
  <summary>Details</summary>
Motivation: 个性化时尚造型解决方案尚未充分探索，但对提升购物体验具有巨大潜力。

Method: StyleTailor通过两个核心代理（Designer和Consultant）结合多级视觉语言模型反馈，形成闭环机制优化推荐。

Result: 实验表明，StyleTailor在个性化设计和推荐方面表现优异，优于无负面反馈的基线方法。

Conclusion: StyleTailor为智能时尚系统设立了新基准，展示了多级反馈机制的有效性。

Abstract: The advancement of intelligent agents has revolutionized problem-solving
across diverse domains, yet solutions for personalized fashion styling remain
underexplored, which holds immense promise for promoting shopping experiences.
In this work, we present StyleTailor, the first collaborative agent framework
that seamlessly unifies personalized apparel design, shopping recommendation,
virtual try-on, and systematic evaluation into a cohesive workflow. To this
end, StyleTailor pioneers an iterative visual refinement paradigm driven by
multi-level negative feedback, enabling adaptive and precise user alignment.
Specifically, our framework features two core agents, i.e., Designer for
personalized garment selection and Consultant for virtual try-on, whose outputs
are progressively refined via hierarchical vision-language model feedback
spanning individual items, complete outfits, and try-on efficacy.
Counterexamples are aggregated into negative prompts, forming a closed-loop
mechanism that enhances recommendation quality.To assess the performance, we
introduce a comprehensive evaluation suite encompassing style consistency,
visual quality, face similarity, and artistic appraisal. Extensive experiments
demonstrate StyleTailor's superior performance in delivering personalized
designs and recommendations, outperforming strong baselines without negative
feedback and establishing a new benchmark for intelligent fashion systems.

</details>


### [11] [RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving](https://arxiv.org/abs/2508.06529)
*Jiayuan Wang,Q. M. Jonathan Wu,Katsuya Suto,Ning Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的实时多任务模型RMT-PPAD，用于自动驾驶中的目标检测、可行驶区域分割和车道线分割，通过轻量级模块和自适应解码器优化性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要高精度和实时性的全景驾驶感知，现有方法在多任务处理中存在负迁移和标签不一致问题。

Method: 设计了轻量级的门控适配器模块和自适应分割解码器，解决了任务间负迁移和标签不一致问题。

Result: 在BDD100K数据集上，目标检测mAP50为84.9%，可行驶区域分割mIoU为92.6%，车道线分割IoU为56.8%，推理速度达32.6 FPS。

Conclusion: RMT-PPAD在性能和实时性上均达到领先水平，并通过实际场景验证了稳定性。

Abstract: Autonomous driving systems rely on panoptic driving perception that requires
both precision and real-time performance. In this work, we propose RMT-PPAD, a
real-time, transformer-based multi-task model that jointly performs object
detection, drivable area segmentation, and lane line segmentation. We introduce
a lightweight module, a gate control with an adapter to adaptively fuse shared
and task-specific features, effectively alleviating negative transfer between
tasks. Additionally, we design an adaptive segmentation decoder to learn the
weights over multi-scale features automatically during the training stage. This
avoids the manual design of task-specific structures for different segmentation
tasks. We also identify and resolve the inconsistency between training and
testing labels in lane line segmentation. This allows fairer evaluation.
Experiments on the BDD100K dataset demonstrate that RMT-PPAD achieves
state-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object
detection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and
accuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6
FPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD
performance in practice. The results show that RMT-PPAD consistently delivers
stable performance. The source codes and pre-trained models are released at
https://github.com/JiayuanWang-JW/RMT-PPAD.

</details>


### [12] [HiMat: DiT-based Ultra-High Resolution SVBRDF Generation](https://arxiv.org/abs/2508.07011)
*Zixiong Wang,Jian Yang,Yiwei Hu,Milos Hasan,Beibei Wang*

Main category: cs.CV

TL;DR: HiMat是一个基于扩散的高效框架，用于生成4K分辨率的SVBRDF，通过轻量级的CrossStitch模块保持多图一致性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率文本到图像生成模型的兴起为SVBRDF生成提供了机会，但如何高效生成多图对齐的SVBRDF仍具挑战性。

Method: 引入HiMat框架和CrossStitch模块，通过轻量级卷积操作捕获图间依赖，保持DiT主干不变。

Result: 实验证明HiMat能生成具有结构一致性和高频细节的4K SVBRDF，并可推广到本征分解等任务。

Conclusion: HiMat为高效生成高质量SVBRDF提供了一种轻量级解决方案。

Abstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The
rise of high-resolution text-to-image generative models, based on diffusion
transformers (DiT), suggests an opportunity to finetune them for this task.
However, retargeting the models to produce multiple aligned SVBRDF maps instead
of just RGB images, while achieving high efficiency and ensuring consistency
across different maps, remains a challenge. In this paper, we introduce HiMat:
a memory- and computation-efficient diffusion-based framework capable of
generating native 4K-resolution SVBRDFs. A key challenge we address is
maintaining consistency across different maps in a lightweight manner, without
relying on training new VAEs or significantly altering the DiT backbone (which
would damage its prior capabilities). To tackle this, we introduce the
CrossStitch module, a lightweight convolutional module that captures inter-map
dependencies through localized operations. Its weights are initialized such
that the DiT backbone operation is unchanged before finetuning starts. HiMat
enables generation with strong structural coherence and high-frequency details.
Results with a large set of text prompts demonstrate the effectiveness of our
approach for 4K SVBRDF generation. Further experiments suggest generalization
to tasks such as intrinsic decomposition.

</details>


### [13] [What Makes "Good" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?](https://arxiv.org/abs/2508.06530)
*Ming-Kun Xie,Jia-Hao Xiao,Gang Niu,Lei Feng,Zhiqiang Kou,Min-Ling Zhang,Masashi Sugiyama*

Main category: cs.CV

TL;DR: HOPE基准通过生成更具误导性的干扰项，更严格评估大型视觉语言模型（LVLM）的幻觉问题，显著优于POPE基准。


<details>
  <summary>Details</summary>
Motivation: 现有POPE基准在评估LVLM对象幻觉问题时效果逐渐减弱，因其采样策略简单且忽略图像特定信息。

Method: HOPE利用CLIP选择高预测似然的负对象作为干扰项，并通过配对真实对象与错误描述构建误导性干扰项。

Result: HOPE使多种先进LVLM的精度下降9%至23%，显著暴露其幻觉漏洞。

Conclusion: HOPE基准为LVLM的幻觉问题提供了更严格的评估工具，优于现有方法。

Abstract: Large Vision-Language Models (LVLMs), empowered by the success of Large
Language Models (LLMs), have achieved impressive performance across domains.
Despite the great advances in LVLMs, they still suffer from the unavailable
object hallucination issue, which tends to generate objects inconsistent with
the image content. The most commonly used Polling-based Object Probing
Evaluation (POPE) benchmark evaluates this issue by sampling negative
categories according to category-level statistics, \textit{e.g.}, category
frequencies and co-occurrence. However, with the continuous advancement of
LVLMs, the POPE benchmark has shown diminishing effectiveness in assessing
object hallucination, as it employs a simplistic sampling strategy that
overlooks image-specific information and restricts distractors to negative
object categories only. In this paper, we introduce the Hallucination
searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate
the most misleading distractors (\textit{i.e.}, non-existent objects or
incorrect image descriptions) that can trigger hallucination in LVLMs, which
serves as a means to more rigorously assess their immunity to hallucination. To
explore the image-specific information, the content-aware hallucination
searching leverages Contrastive Language-Image Pre-Training (CLIP) to
approximate the predictive behavior of LVLMs by selecting negative objects with
the highest predicted likelihood as distractors. To expand the scope of
hallucination assessment, the description-based hallucination searching
constructs highly misleading distractors by pairing true objects with false
descriptions. Experimental results show that HOPE leads to a precision drop of
at least 9\% and up to 23\% across various state-of-the-art LVLMs,
significantly outperforming POPE in exposing hallucination vulnerabilities. The
code is available at https://github.com/xiemk/HOPE.

</details>


### [14] [Matrix-3D: Omnidirectional Explorable 3D World Generation](https://arxiv.org/abs/2508.08086)
*Zhongqi Yang,Wenhang Ge,Yuqi Li,Jiaqi Chen,Haoyuan Li,Mengyin An,Fei Kang,Hua Xue,Baixin Xu,Yuyang Yin,Eric Li,Yang Liu,Yikai Wang,Hao-Xiang Guo,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-3D框架通过全景表示和视频扩散模型，实现了高质量、几何一致的3D世界生成，结合了快速重建和优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成3D场景时范围有限，Matrix-3D旨在通过全景表示和视频模型解决这一问题。

Method: 结合条件视频生成和全景3D重建，训练轨迹引导的全景视频扩散模型，并提出快速和优化两种3D重建方法。

Result: 实验表明，Matrix-3D在全景视频生成和3D世界生成中达到最先进性能。

Conclusion: Matrix-3D通过全景表示和混合方法，显著提升了3D场景生成的覆盖范围和质量。

Abstract: Explorable 3D world generation from a single image or text prompt forms a
cornerstone of spatial intelligence. Recent works utilize video model to
achieve wide-scope and generalizable 3D world generation. However, existing
approaches often suffer from a limited scope in the generated scenes. In this
work, we propose Matrix-3D, a framework that utilize panoramic representation
for wide-coverage omnidirectional explorable 3D world generation that combines
conditional video generation and panoramic 3D reconstruction. We first train a
trajectory-guided panoramic video diffusion model that employs scene mesh
renders as condition, to enable high-quality and geometrically consistent scene
video generation. To lift the panorama scene video to 3D world, we propose two
separate methods: (1) a feed-forward large panorama reconstruction model for
rapid 3D scene reconstruction and (2) an optimization-based pipeline for
accurate and detailed 3D scene reconstruction. To facilitate effective
training, we also introduce the Matrix-Pano dataset, the first large-scale
synthetic collection comprising 116K high-quality static panoramic video
sequences with depth and trajectory annotations. Extensive experiments
demonstrate that our proposed framework achieves state-of-the-art performance
in panoramic video generation and 3D world generation. See more in
https://matrix-3d.github.io.

</details>


### [15] [Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset](https://arxiv.org/abs/2508.06537)
*Shantanusinh Parmar*

Main category: cs.CV

TL;DR: 论文分析了智能手机天体摄影数据集MobilTelesco，用于评估目标检测模型在稀疏特征条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测数据集（如ImageNet、COCO）主要关注日常物体，缺乏非商业领域中的信号稀疏性。MobilTelesco填补了这一空白。

Method: 使用MobilTelesco数据集对多个目标检测模型进行基准测试。

Result: 研究揭示了在特征不足条件下目标检测模型面临的挑战。

Conclusion: MobilTelesco为稀疏特征环境下的目标检测研究提供了新方向。

Abstract: Object detection models are typically trained on datasets like ImageNet,
COCO, and PASCAL VOC, which focus on everyday objects. However, these lack
signal sparsity found in non-commercial domains. MobilTelesco, a
smartphone-based astrophotography dataset, addresses this by providing sparse
night-sky images. We benchmark several detection models on it, highlighting
challenges under feature-deficient conditions.

</details>


### [16] [MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing](https://arxiv.org/abs/2508.06543)
*Jinghan Yu,Zhiyuan Ma,Yue Ma,Kaiqi Liu,Yuhan Wang,Jianjun Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为MILD的新方法，用于解决复杂多实例场景下的人像擦除问题，通过分层扩散和形态学指导显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂多实例场景（如人物遮挡、背景干扰）中表现不佳，主要受限于数据集不足和空间解耦能力不足。

Method: 提出了Multi-Layer Diffusion (MILD)策略，通过分层生成路径和Human Morphology Guidance（姿态、解析和空间关系）增强人像理解，并引入Spatially-Modulated Attention优化注意力流。

Result: 实验表明，MILD在复杂人像擦除任务中优于现有方法。

Conclusion: MILD通过分层解耦和形态学指导，显著提升了复杂场景下的人像擦除效果。

Abstract: Recent years have witnessed the success of diffusion models in
image-customized tasks. Prior works have achieved notable progress on
human-oriented erasing using explicit mask guidance and semantic-aware
inpainting. However, they struggle under complex multi-IP scenarios involving
human-human occlusions, human-object entanglements, and background
interferences. These challenges are mainly due to: 1) Dataset limitations, as
existing datasets rarely cover dense occlusions, camouflaged backgrounds, and
diverse interactions; 2) Lack of spatial decoupling, where foreground instances
cannot be effectively disentangled, limiting clean background restoration. In
this work, we introduce a high-quality multi-IP human erasing dataset with
diverse pose variations and complex backgrounds. We then propose Multi-Layer
Diffusion (MILD), a novel strategy that decomposes generation into semantically
separated pathways for each instance and the background. To enhance
human-centric understanding, we introduce Human Morphology Guidance,
integrating pose, parsing, and spatial relations. We further present
Spatially-Modulated Attention to better guide attention flow. Extensive
experiments show that MILD outperforms state-of-the-art methods on challenging
human erasing benchmarks.

</details>


### [17] [Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images](https://arxiv.org/abs/2508.06546)
*Qi Xun Yeo,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 论文提出了一种仅使用多视角RGB图像进行3D语义场景图估计的方法，克服了伪点云几何噪声和背景干扰，通过语义掩码和邻域关系增强特征，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在缺乏3D标注的情况下，探索仅用多视角RGB图像完成3D语义场景图估计任务，解决伪点云几何噪声和背景干扰问题。

Method: 利用语义掩码引导特征聚合过滤背景噪声，设计邻域节点信息融合方法，并结合统计先验优化节点和边的预测。

Result: 实验表明，该方法在多视角图像输入下优于现有方法。

Conclusion: 通过语义和邻域信息增强特征，结合统计先验，实现了高效且鲁棒的3D语义场景图估计。

Abstract: Modern 3D semantic scene graph estimation methods utilize ground truth 3D
annotations to accurately predict target objects, predicates, and
relationships. In the absence of given 3D ground truth representations, we
explore leveraging only multi-view RGB images to tackle this task. To attain
robust features for accurate scene graph estimation, we must overcome the noisy
reconstructed pseudo point-based geometry from predicted depth maps and reduce
the amount of background noise present in multi-view image features. The key is
to enrich node and edge features with accurate semantic and spatial information
and through neighboring relations. We obtain semantic masks to guide feature
aggregation to filter background features and design a novel method to
incorporate neighboring node information to aid robustness of our scene graph
estimates. Furthermore, we leverage on explicit statistical priors calculated
from the training summary statistics to refine node and edge predictions based
on their one-hop neighborhood. Our experiments show that our method outperforms
current methods purely using multi-view images as the initial input. Our
project page is available at https://qixun1.github.io/projects/SCRSSG.

</details>


### [18] [Slice or the Whole Pie? Utility Control for AI Models](https://arxiv.org/abs/2508.06551)
*Ye Tao*

Main category: cs.CV

TL;DR: NNObfuscator是一种新型的实用控制机制，允许AI模型根据预设条件动态调整性能，避免了为不同需求训练多个模型的低效问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络（DNNs）训练资源密集、适应特定需求时需大量定制和基础设施开销的问题。

Method: 提出NNObfuscator，通过动态调整模型性能实现单一模型适应多任务需求，支持分层访问控制。

Result: 实验验证了NNObfuscator在图像分类、语义分割和文本生成图像等任务中的有效性，单一模型可适应广泛需求。

Conclusion: NNObfuscator提高了资源分配效率，减少了不必要的计算，支持可持续的AI部署商业模式。

Abstract: Training deep neural networks (DNNs) has become an increasingly
resource-intensive task, requiring large volumes of labeled data, substantial
computational power, and considerable fine-tuning efforts to achieve optimal
performance across diverse use cases. Although pre-trained models offer a
useful starting point, adapting them to meet specific user needs often demands
extensive customization, and infrastructure overhead. This challenge grows when
a single model must support diverse appli-cations with differing requirements
for performance. Traditional solutions often involve training multiple model
versions to meet varying requirements, which can be inefficient and difficult
to maintain. In order to overcome this challenge, we propose NNObfuscator, a
novel utility control mechanism that enables AI models to dynamically modify
their performance according to predefined conditions. It is different from
traditional methods that need separate models for each user. Instead,
NNObfuscator allows a single model to be adapted in real time, giving you
controlled access to multiple levels of performance. This mechanism enables
model owners set up tiered access, ensuring that free-tier users receive a
baseline level of performance while premium users benefit from enhanced
capabilities. The approach improves resource allocation, reduces unnecessary
computation, and supports sustainable business models in AI deployment. To
validate our approach, we conducted experiments on multiple tasks, including
image classification, semantic segmentation, and text to image generation,
using well-established models such as ResNet, DeepLab, VGG16, FCN and Stable
Diffusion. Experimental results show that NNObfuscator successfully makes model
more adaptable, so that a single trained model can handle a broad range of
tasks without requiring a lot of changes.

</details>


### [19] [Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection](https://arxiv.org/abs/2508.06552)
*Unisha Joshi*

Main category: cs.CV

TL;DR: 本文提出了一种解决深度伪造数据集中年龄偏见的方法，通过构建一个年龄多样化的数据集，并验证其在多个检测模型中的公平性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测中的数据集存在年龄偏见，影响公平性，本文旨在解决这一问题。

Method: 通过整合现有数据集（Celeb-DF、FaceForensics++、UTKFace）和生成合成数据，构建年龄多样化的数据集，并使用XceptionNet、EfficientNet和LipForensics模型进行评估。

Result: 实验表明，基于年龄多样化数据集训练的模型在公平性、准确性和泛化能力上均有提升。

Conclusion: 本文提供了一个可复现的公平性数据集和模型流程，为未来研究奠定了基础。

Abstract: The challenges associated with deepfake detection are increasing
significantly with the latest advancements in technology and the growing
popularity of deepfake videos and images. Despite the presence of numerous
detection models, demographic bias in the deepfake dataset remains largely
unaddressed. This paper focuses on the mitigation of age-specific bias in the
deepfake dataset by introducing an age-diverse deepfake dataset that will
improve fairness across age groups. The dataset is constructed through a
modular pipeline incorporating the existing deepfake datasets Celeb-DF,
FaceForensics++, and UTKFace datasets, and the creation of synthetic data to
fill the age distribution gaps. The effectiveness and generalizability of this
dataset are evaluated using three deepfake detection models: XceptionNet,
EfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and
EER, revealed that models trained on the age-diverse dataset demonstrated
fairer performance across age groups, improved overall accuracy, and higher
generalization across datasets. This study contributes a reproducible,
fairness-aware deepfake dataset and model pipeline that can serve as a
foundation for future research in fairer deepfake detection. The complete
dataset and implementation code are available at
https://github.com/unishajoshi/age-diverse-deepfake-detection.

</details>


### [20] [Static and Plugged: Make Embodied Evaluation Simple](https://arxiv.org/abs/2508.06553)
*Jiahao Xiao,Jianbo Zhang,BoWen Yan,Shengyu Guo,Tongrui Ye,Kaiwei Zhang,Zicheng Zhang,Xiaohong Liu,Zhengxue Cheng,Lei Fan,Chuyi Li,Guangtao Zhai*

Main category: cs.CV

TL;DR: StaticEmbodiedBench是一个基于静态场景表示的插件式基准测试，用于统一评估体现智能，覆盖42个场景和8个核心维度，并评估了30个模型。


<details>
  <summary>Details</summary>
Motivation: 当前体现智能的评估方法成本高、分散且难以扩展，需要一种更高效的解决方案。

Method: 提出StaticEmbodiedBench，利用静态场景表示实现统一评估，支持42个场景和8个核心维度。

Result: 评估了19个VLM和11个VLA模型，建立了首个统一的静态体现智能排行榜。

Conclusion: StaticEmbodiedBench为体现智能提供了可扩展且全面的评估工具，并公开了部分数据以促进研究。

Abstract: Embodied intelligence is advancing rapidly, driving the need for efficient
evaluation. Current benchmarks typically rely on interactive simulated
environments or real-world setups, which are costly, fragmented, and hard to
scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play
benchmark that enables unified evaluation using static scene representations.
Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and
comprehensive assessment through a simple interface. Furthermore, we evaluate
19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs),
establishing the first unified static leaderboard for Embodied intelligence.
Moreover, we release a subset of 200 samples from our benchmark to accelerate
the development of embodied intelligence.

</details>


### [21] [From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets](https://arxiv.org/abs/2508.06556)
*Sarina Penquitt,Jonathan Klees,Rinor Cakaj,Daniel Kondermann,Matthias Rottmann,Lars Schmarje*

Main category: cs.CV

TL;DR: 论文提出了一种半自动化的标签错误校正框架REC$\checkmark$D，通过结合现有检测器和众包微任务，系统性修正目标检测数据集中的标签错误。


<details>
  <summary>Details</summary>
Motivation: 目标检测数据集中标签错误（如缺失标签、分类错误或定位不准确）普遍存在，影响训练和评估效果，但现有方法缺乏系统性修正能力。

Method: REC$\checkmark$D框架结合现有检测器和众包微任务，通过多人独立验证候选边界框并聚合结果，估计模糊性并提升标签质量。

Result: 在KITTI数据集的“行人”类中，校正后的标注显示原始标注中至少24%存在缺失或不准确。框架能高效修正错误，但现有方法仍可能遗漏66%的真实错误。

Conclusion: REC$\checkmark$D为标签错误修正提供了有效工具，但现有方法仍需改进。发布的基准数据集将推动进一步研究。

Abstract: Object detection has advanced rapidly in recent years, driven by increasingly
large and diverse datasets. However, label errors, defined as missing labels,
incorrect classification or inaccurate localization, often compromise the
quality of these datasets. This can have a significant impact on the outcomes
of training and benchmark evaluations. Although several methods now exist for
detecting label errors in object detection datasets, they are typically
validated only on synthetic benchmarks or limited manual inspection. How to
correct such errors systemically and at scale therefore remains an open
problem. We introduce a semi-automated framework for label-error correction
called REC$\checkmark$D (Rechecked). Building on existing detectors, the
framework pairs their error proposals with lightweight, crowd-sourced
microtasks. These tasks enable multiple annotators to independently verify each
candidate bounding box, and their responses are aggregated to estimate
ambiguity and improve label quality. To demonstrate the effectiveness of
REC$\checkmark$D, we apply it to the class pedestrian in the KITTI dataset. Our
crowdsourced review yields high-quality corrected annotations, which indicate a
rate of at least 24% of missing and inaccurate annotations in original
annotations. This validated set will be released as a new real-world benchmark
for label error detection and correction. We show that current label error
detection methods, when combined with our correction framework, can recover
hundreds of errors in the time it would take a human to annotate bounding boxes
from scratch. However, even the best methods still miss up to 66% of the true
errors and with low quality labels introduce more errors than they find. This
highlights the urgent need for further research, now enabled by our released
benchmark.

</details>


### [22] [MMFformer: Multimodal Fusion Transformer Network for Depression Detection](https://arxiv.org/abs/2508.06701)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: MMFformer是一种多模态抑郁症检测网络，通过分析社交媒体信息提取时空特征，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 抑郁症早期诊断困难，依赖主观临床评估，社交媒体信息为早期检测提供了新途径。

Method: 采用Transformer网络提取视频空间特征和音频时间动态，通过多模态融合策略整合特征。

Result: 在两个大型数据集上表现优异，F1分数分别提升13.92%和7.74%。

Conclusion: MMFformer在多模态抑郁症检测中优于现有方法，代码已开源。

Abstract: Depression is a serious mental health illness that significantly affects an
individual's well-being and quality of life, making early detection crucial for
adequate care and treatment. Detecting depression is often difficult, as it is
based primarily on subjective evaluations during clinical interviews. Hence,
the early diagnosis of depression, thanks to the content of social networks,
has become a prominent research area. The extensive and diverse nature of
user-generated information poses a significant challenge, limiting the accurate
extraction of relevant temporal information and the effective fusion of data
across multiple modalities. This paper introduces MMFformer, a multimodal
depression detection network designed to retrieve depressive spatio-temporal
high-level patterns from multimodal social media information. The transformer
network with residual connections captures spatial features from videos, and a
transformer encoder is exploited to design important temporal dynamics in
audio. Moreover, the fusion architecture fused the extracted features through
late and intermediate fusion strategies to find out the most relevant
intermodal correlations among them. Finally, the proposed network is assessed
on two large-scale depression detection datasets, and the results clearly
reveal that it surpasses existing state-of-the-art approaches, improving the
F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is
made available publicly at
https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.

</details>


### [23] [On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications](https://arxiv.org/abs/2508.06558)
*Simon Baur,Alexandra Benova,Emilio Dolgener Cantú,Jackie Ma*

Main category: cs.CV

TL;DR: 论文提出了一种多模态特权知识蒸馏（MMPKD）方法，利用训练时额外的模态数据指导单模态视觉模型，提升注意力图的零样本能力，但效果不跨领域泛化。


<details>
  <summary>Details</summary>
Motivation: 临床实践中部署深度学习模型常需多模态数据，但推理时并非所有模态都可用。研究旨在利用训练时额外的模态提升单模态模型的性能。

Method: 提出MMPKD方法，使用文本和表格元数据作为教师模型（分别针对胸部X光和乳腺X光），将知识蒸馏到视觉Transformer学生模型中。

Result: MMPKD提升了注意力图的零样本定位能力，但效果未跨领域泛化。

Conclusion: MMPKD能有效利用训练时的多模态数据提升单模态模型性能，但需注意领域特异性。

Abstract: Deploying deep learning models in clinical practice often requires leveraging
multiple data modalities, such as images, text, and structured data, to achieve
robust and trustworthy decisions. However, not all modalities are always
available at inference time. In this work, we propose multimodal privileged
knowledge distillation (MMPKD), a training strategy that utilizes additional
modalities available solely during training to guide a unimodal vision model.
Specifically, we used a text-based teacher model for chest radiographs
(MIMIC-CXR) and a tabular metadata-based teacher model for mammography
(CBIS-DDSM) to distill knowledge into a vision transformer student model. We
show that MMPKD can improve the resulting attention maps' zero-shot
capabilities of localizing ROI in input images, while this effect does not
generalize across domains, as contrarily suggested by prior research.

</details>


### [24] [Voice Pathology Detection Using Phonation](https://arxiv.org/abs/2508.07587)
*Sri Raksha Siva,Nived Suthahar,Prakash Boominathan,Uma Ranjan*

Main category: cs.CV

TL;DR: 论文提出了一种基于机器学习的非侵入性语音病理检测框架，利用声学特征和RNN分类器，结合数据增强技术，实现早期诊断。


<details>
  <summary>Details</summary>
Motivation: 语音障碍严重影响交流和生活质量，传统诊断方法如喉镜检查具有侵入性和主观性，且不易获取。

Method: 使用Saarbrücken语音数据库的发音数据，提取MFCCs、chroma特征和Mel频谱图等声学特征，结合RNN（包括LSTM和注意力机制）进行分类，并通过数据增强和预处理提升模型泛化能力。

Result: 提出的框架能够非侵入性地自动检测语音病理，支持AI驱动的医疗保健。

Conclusion: 该研究为语音病理的早期诊断提供了一种有效的非侵入性工具，有助于改善患者预后。

Abstract: Voice disorders significantly affect communication and quality of life,
requiring an early and accurate diagnosis. Traditional methods like
laryngoscopy are invasive, subjective, and often inaccessible. This research
proposes a noninvasive, machine learning-based framework for detecting voice
pathologies using phonation data.
  Phonation data from the Saarbr\"ucken Voice Database are analyzed using
acoustic features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma
features, and Mel spectrograms. Recurrent Neural Networks (RNNs), including
LSTM and attention mechanisms, classify samples into normal and pathological
categories. Data augmentation techniques, including pitch shifting and Gaussian
noise addition, enhance model generalizability, while preprocessing ensures
signal quality. Scale-based features, such as H\"older and Hurst exponents,
further capture signal irregularities and long-term dependencies.
  The proposed framework offers a noninvasive, automated diagnostic tool for
early detection of voice pathologies, supporting AI-driven healthcare, and
improving patient outcomes.

</details>


### [25] [Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC](https://arxiv.org/abs/2508.06564)
*Guanyu Hu,Dimitrios Kollias,Xinyu Yang*

Main category: cs.CV

TL;DR: 论文提出了一种基于CLIP的视觉情感引导锚定机制（VEGA），通过引入类级视觉语义改进多模态情感识别任务。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别任务中，现有模型缺乏心理学意义的先验指导，导致多模态对齐不足。

Method: 利用CLIP的图像编码器构建情感特定的视觉锚点，结合随机锚点采样策略和双分支自蒸馏架构。

Result: 在IEMOCAP和MELD数据集上实现了最先进的性能。

Conclusion: VEGA机制通过心理学理论和多感官整合提升了多模态情感识别的性能。

Abstract: Multimodal Emotion Recognition in Conversations remains a challenging task
due to the complex interplay of textual, acoustic and visual signals. While
recent models have improved performance via advanced fusion strategies, they
often lack psychologically meaningful priors to guide multimodal alignment. In
this paper, we revisit the use of CLIP and propose a novel Visual Emotion
Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics
into the fusion and classification process. Distinct from prior work that
primarily utilizes CLIP's textual encoder, our approach leverages its image
encoder to construct emotion-specific visual anchors based on facial exemplars.
These anchors guide unimodal and multimodal features toward a perceptually
grounded and psychologically aligned representation space, drawing inspiration
from cognitive theories (prototypical emotion categories and multisensory
integration). A stochastic anchor sampling strategy further enhances robustness
by balancing semantic stability and intra-class diversity. Integrated into a
dual-branch architecture with self-distillation, our VEGA-augmented model
achieves sota performance on IEMOCAP and MELD. Code is available at:
https://github.com/dkollias/VEGA.

</details>


### [26] [Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization](https://arxiv.org/abs/2508.08141)
*Nicholas Klein,Hemlata Tak,James Fullwood,Krishna Regmi,Leonidas Spinoulas,Ganesh Sivaraman,Tianxiang Chen,Elie Khoury*

Main category: cs.CV

TL;DR: 该论文提出了针对深度伪造视频分类和定位的解决方案，并在ACM 1M Deepfakes检测挑战赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着视觉和音频生成技术的快速发展，检测合成内容的需求日益迫切，尤其是针对局部细微修改的挑战。

Method: 论文方法在ACM 1M Deepfakes检测挑战赛中提交，专注于视频分类和定位任务。

Result: 在时间定位任务中表现最佳，在分类任务的TestA分割中排名前四。

Conclusion: 论文提出的方法在深度伪造检测领域具有显著效果。

Abstract: The field of visual and audio generation is burgeoning with new
state-of-the-art methods. This rapid proliferation of new techniques
underscores the need for robust solutions for detecting synthetic content in
videos. In particular, when fine-grained alterations via localized
manipulations are performed in visual, audio, or both domains, these subtle
modifications add challenges to the detection algorithms. This paper presents
solutions for the problems of deepfake video classification and localization.
The methods were submitted to the ACM 1M Deepfakes Detection Challenge,
achieving the best performance in the temporal localization task and a top four
ranking in the classification task for the TestA split of the evaluation
dataset.

</details>


### [27] [Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06565)
*Jing Zhang,Xiaowei Yu,Minheng Chen,Lu Zhang,Tong Chen,Yan Zhuang,Chao Cao,Yanjun Lyu,Li Su,Tianming Liu,Dajiang Zhu*

Main category: cs.CV

TL;DR: 提出了一种新框架，将脑连接组与临床报告在共享跨模态潜在空间中对齐，提升表征学习，用于脑障碍诊断。


<details>
  <summary>Details</summary>
Motivation: 整合脑影像数据与临床报告，利用多模态信息提升诊断效果，解决如何有效关联客观影像数据与主观文本报告的挑战。

Method: 将脑子网络作为影像数据标记，与临床报告中的词语标记对齐，构建共享潜在空间。

Result: 在ADNI数据集上应用，不仅达到最优预测性能，还识别出有临床意义的连接组-文本对。

Conclusion: 该方法为阿尔茨海默病的早期机制提供了新见解，支持开发临床有用的多模态生物标志物。

Abstract: Integrating brain imaging data with clinical reports offers a valuable
opportunity to leverage complementary multimodal information for more effective
and timely diagnosis in practical clinical settings. This approach has gained
significant attention in brain disorder research, yet a key challenge remains:
how to effectively link objective imaging data with subjective text-based
reports, such as doctors' notes. In this work, we propose a novel framework
that aligns brain connectomes with clinical reports in a shared cross-modal
latent space at both the subject and connectome levels, thereby enhancing
representation learning. The key innovation of our approach is that we treat
brain subnetworks as tokens of imaging data, rather than raw image patches, to
align with word tokens in clinical reports. This enables a more efficient
identification of system-level associations between neuroimaging findings and
clinical observations, which is critical since brain disorders often manifest
as network-level abnormalities rather than isolated regional alterations. We
applied our method to mild cognitive impairment (MCI) using the ADNI dataset.
Our approach not only achieves state-of-the-art predictive performance but also
identifies clinically meaningful connectome-text pairs, offering new insights
into the early mechanisms of Alzheimer's disease and supporting the development
of clinically useful multimodal biomarkers.

</details>


### [28] [Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features](https://arxiv.org/abs/2508.06566)
*Manish Kansana,Elias Hossain,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

TL;DR: Surformer v1是一种基于Transformer的架构，结合触觉和视觉输入，用于表面材料分类，实现了高精度和低延迟。


<details>
  <summary>Details</summary>
Motivation: 表面材料识别是机器人感知和物理交互的关键，尤其是结合触觉和视觉输入时。

Method: 提出Surformer v1，结合结构化触觉特征和PCA降维的视觉嵌入，使用模态特定编码器和跨模态注意力层。

Result: Surformer v1在精度（99.4%）和推理时间（0.77 ms）上表现优异，优于多模态CNN。

Conclusion: Surformer v1在精度、效率和计算成本之间取得了平衡，适合实时应用。

Abstract: Surface material recognition is a key component in robotic perception and
physical interaction, particularly when leveraging both tactile and visual
sensory inputs. In this work, we propose Surformer v1, a transformer-based
architecture designed for surface classification using structured tactile
features and PCA-reduced visual embeddings extracted via ResNet-50. The model
integrates modality-specific encoders with cross-modal attention layers,
enabling rich interactions between vision and touch. Currently,
state-of-the-art deep learning models for vision tasks have achieved remarkable
performance. With this in mind, our first set of experiments focused
exclusively on tactile-only surface classification. Using feature engineering,
we trained and evaluated multiple machine learning models, assessing their
accuracy and inference time. We then implemented an encoder-only Transformer
model tailored for tactile features. This model not only achieved the highest
accuracy but also demonstrated significantly faster inference time compared to
other evaluated models, highlighting its potential for real-time applications.
To extend this investigation, we introduced a multimodal fusion setup by
combining vision and tactile inputs. We trained both Surformer v1 (using
structured features) and Multimodal CNN (using raw images) to examine the
impact of feature-based versus image-based multimodal learning on
classification accuracy and computational efficiency. The results showed that
Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while
the Multimodal CNN achieved slightly higher accuracy but required significantly
more inference time. These findings suggest Surformer v1 offers a compelling
balance between accuracy, efficiency, and computational cost for surface
material recognition.

</details>


### [29] [ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos](https://arxiv.org/abs/2508.06570)
*Mohammad Zia Ur Rehman,Anukriti Bhatnagar,Omkar Kabde,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

TL;DR: 论文提出了一种新的视频数据集ImpliHateVid，用于隐式仇恨言论检测，并提出了一种两阶段对比学习框架来提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在文本和图像仇恨言论检测，视频领域的研究较少，尤其是隐式仇恨言论。

Method: 提出两阶段对比学习框架，第一阶段训练模态特定编码器，第二阶段训练跨模态编码器，并结合情感、情绪和字幕特征。

Result: 在ImpliHateVid和HateMM数据集上验证了方法的有效性，证明了多模态对比学习在视频仇恨内容检测中的优势。

Conclusion: 论文填补了视频隐式仇恨言论检测的空白，提出的数据集和方法为未来研究提供了重要基础。

Abstract: The existing research has primarily focused on text and image-based hate
speech detection, video-based approaches remain underexplored. In this work, we
introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate
speech detection in videos. ImpliHateVid consists of 2,009 videos comprising
509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos,
making it one of the first large-scale video datasets dedicated to implicit
hate detection. We also propose a novel two-stage contrastive learning
framework for hate speech detection in videos. In the first stage, we train
modality-specific encoders for audio, text, and image using contrastive loss by
concatenating features from the three encoders. In the second stage, we train
cross-encoders using contrastive learning to refine multimodal representations.
Additionally, we incorporate sentiment, emotion, and caption-based features to
enhance implicit hate detection. We evaluate our method on two datasets,
ImpliHateVid for implicit hate speech detection and another dataset for general
hate speech detection in videos, HateMM dataset, demonstrating the
effectiveness of the proposed multimodal contrastive learning for hateful
content detection in videos and the significance of our dataset.

</details>


### [30] [ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification](https://arxiv.org/abs/2508.06623)
*Sihan Ma,Qiming Wu,Ruotong Jiang,Frank Burns*

Main category: cs.CV

TL;DR: 论文提出ContextGuard-LVLM框架，利用视觉-语言大模型和多阶段上下文推理机制，解决数字新闻中视觉与文本信息的细粒度一致性验证问题。


<details>
  <summary>Details</summary>
Motivation: 数字新闻媒体激增，需要验证内容真实性，尤其是视觉与文本信息的深层一致性，传统方法难以解决细粒度跨模态上下文一致性问题。

Method: 基于视觉-语言大模型（LVLMs），结合多阶段上下文推理机制，并通过强化或对抗学习增强模型能力。

Result: ContextGuard-LVLM在细粒度一致性任务中显著优于零样本基线模型，且在复杂逻辑推理和上下文理解方面表现优异。

Conclusion: 该模型在检测上下文分离的复杂形式中表现出高效性，并与人类专家判断高度一致。

Abstract: The proliferation of digital news media necessitates robust methods for
verifying content veracity, particularly regarding the consistency between
visual and textual information. Traditional approaches often fall short in
addressing the fine-grained cross-modal contextual consistency (FCCC) problem,
which encompasses deeper alignment of visual narrative, emotional tone, and
background information with text, beyond mere entity matching. To address this,
we propose ContextGuard-LVLM, a novel framework built upon advanced
Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual
reasoning mechanism. Our model is uniquely enhanced through reinforced or
adversarial learning paradigms, enabling it to detect subtle contextual
misalignments that evade zero-shot baselines. We extend and augment three
established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new
fine-grained contextual annotations, including "contextual sentiment," "visual
narrative theme," and "scene-event logical coherence," and introduce a
comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments
demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art
zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all
fine-grained consistency tasks, showing significant improvements in complex
logical reasoning and nuanced contextual understanding. Furthermore, our model
exhibits superior robustness to subtle perturbations and a higher agreement
rate with human expert judgments on challenging samples, affirming its efficacy
in discerning sophisticated forms of context detachment.

</details>


### [31] [VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis](https://arxiv.org/abs/2508.06624)
*Kexin Yu,Zihan Xu,Jialei Xie,Carter Adams*

Main category: cs.CV

TL;DR: VL-MedGuide是一种基于视觉-语言大模型的多模态框架，用于皮肤病的智能辅助诊断，具有高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤病诊断中视觉特征复杂多样及现有模型缺乏可解释性的问题。

Method: 采用两阶段框架：多模态概念感知模块和可解释疾病推理模块，结合提示工程和链式思维推理。

Result: 在Derm7pt数据集上表现优异（诊断BACC 83.55%，概念检测BACC 76.10%），超越现有基线。

Conclusion: VL-MedGuide通过提供透明解释，提升了AI在皮肤病诊断中的临床实用性。

Abstract: Accurate diagnosis of skin diseases remains a significant challenge due to
the complex and diverse visual features present in dermatoscopic images, often
compounded by a lack of interpretability in existing purely visual diagnostic
models. To address these limitations, this study introduces VL-MedGuide
(Visual-Linguistic Medical Guide), a novel framework leveraging the powerful
multi-modal understanding and reasoning capabilities of Visual-Language Large
Models (LVLMs) for intelligent and inherently interpretable auxiliary diagnosis
of skin conditions. VL-MedGuide operates in two interconnected stages: a
Multi-modal Concept Perception Module, which identifies and linguistically
describes dermatologically relevant visual features through sophisticated
prompt engineering, and an Explainable Disease Reasoning Module, which
integrates these concepts with raw visual information via Chain-of-Thought
prompting to provide precise disease diagnoses alongside transparent
rationales. Comprehensive experiments on the Derm7pt dataset demonstrate that
VL-MedGuide achieves state-of-the-art performance in both disease diagnosis
(83.55% BACC, 80.12% F1) and concept detection (76.10% BACC, 67.45% F1),
surpassing existing baselines. Furthermore, human evaluations confirm the high
clarity, completeness, and trustworthiness of its generated explanations,
bridging the gap between AI performance and clinical utility by offering
actionable, explainable insights for dermatological practice.

</details>


### [32] [CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation](https://arxiv.org/abs/2508.06625)
*Shilong Zou,Yuhang Huang,Renjiao Yi,Chenyang Zhu,Kai Xu*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的跨域图像翻译方法，通过联合学习框架对齐扩散和翻译过程，提升了全局最优性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在跨域图像翻译中因扩散与翻译过程未对齐而导致的局部最优问题。

Method: 提出联合学习框架，提取图像组件表示干净信号，并使用时变翻译网络学习复杂映射。

Result: 在RGB和多种跨模态翻译任务中表现优于现有方法。

Conclusion: 联合学习框架有效提升了扩散模型在跨域翻译中的全局最优性和性能。

Abstract: We introduce a diffusion-based cross-domain image translator in the absence
of paired training data. Unlike GAN-based methods, our approach integrates
diffusion models to learn the image translation process, allowing for more
coverable modeling of the data distribution and performance improvement of the
cross-domain translation. However, incorporating the translation process within
the diffusion process is still challenging since the two processes are not
aligned exactly, i.e., the diffusion process is applied to the noisy signal
while the translation process is conducted on the clean signal. As a result,
recent diffusion-based studies employ separate training or shallow integration
to learn the two processes, yet this may cause the local minimal of the
translation optimization, constraining the effectiveness of diffusion models.
To address the problem, we propose a novel joint learning framework that aligns
the diffusion and the translation process, thereby improving the global
optimality. Specifically, we propose to extract the image components with
diffusion models to represent the clean signal and employ the translation
process with the image components, enabling an end-to-end joint learning
manner. On the other hand, we introduce a time-dependent translation network to
learn the complex translation mapping, resulting in effective translation
learning and significant performance improvement. Benefiting from the design of
joint learning, our method enables global optimization of both processes,
enhancing the optimality and achieving improved fidelity and structural
consistency. We have conducted extensive experiments on RGB$\leftrightarrow$RGB
and diverse cross-modality translation tasks including
RGB$\leftrightarrow$Edge, RGB$\leftrightarrow$Semantics and
RGB$\leftrightarrow$Depth, showcasing better generative performances than the
state of the arts.

</details>


### [33] [CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition](https://arxiv.org/abs/2508.06632)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Tiancheng Zhao,Gaolei Li,Changting Lin,Yike Guo,Meng Han*

Main category: cs.CV

TL;DR: 提出了一种基于动态系数分解的神经渲染框架，用于改进复杂视依赖外观的建模，特别是在高光和反射场景中。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂镜面反射和高光时可能产生模糊反射或优化不稳定，因此需要一种更灵活有效的建模方式。

Method: 通过动态系数分解将复杂外观分解为静态神经基和动态系数，由系数网络生成，并通过动态辐射积分器合成最终辐射。

Result: 实验表明，该方法在多个挑战性基准测试中能生成更锐利和真实的高光效果。

Conclusion: 该分解范式为神经场景表示中复杂外观建模提供了灵活有效的方向。

Abstract: Neural Radiance Fields (NeRF) have shown impressive performance in novel view
synthesis, but challenges remain in rendering scenes with complex specular
reflections and highlights. Existing approaches may produce blurry reflections
due to entanglement between lighting and material properties, or encounter
optimization instability when relying on physically-based inverse rendering. In
this work, we present a neural rendering framework based on dynamic coefficient
decomposition, aiming to improve the modeling of view-dependent appearance. Our
approach decomposes complex appearance into a shared, static neural basis that
encodes intrinsic material properties, and a set of dynamic coefficients
generated by a Coefficient Network conditioned on view and illumination. A
Dynamic Radiance Integrator then combines these components to synthesize the
final radiance. Experimental results on several challenging benchmarks suggest
that our method can produce sharper and more realistic specular highlights
compared to existing techniques. We hope that this decomposition paradigm can
provide a flexible and effective direction for modeling complex appearance in
neural scene representations.

</details>


### [34] [Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors](https://arxiv.org/abs/2508.06640)
*Zheyuan Zhang,Weihao Tang,Hong Chen*

Main category: cs.CV

TL;DR: CausalNet是一个新框架，旨在解决微表情识别中关键帧索引误差的问题，通过输入完整序列和因果学习模块提升鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖准确的关键帧索引，但实际中获取准确索引困难且存在误差，限制了实际应用。

Method: 提出CausalNet框架，包含CMPLM模块定位肌肉运动区域，CAB模块学习肌肉运动的因果关系。

Result: 在多个基准测试中，CausalNet在不同噪声水平下表现鲁棒，且在使用标注关键帧时超越SOTA方法。

Conclusion: CausalNet通过因果学习解决了关键帧误差问题，同时提升了微表情识别的性能。

Abstract: Micro-expression recognition (MER) is a highly challenging task in affective
computing. With the reduced-sized micro-expression (ME) input that contains key
information based on key-frame indexes, key-frame-based methods have
significantly improved the performance of MER. However, most of these methods
focus on improving the performance with relatively accurate key-frame indexes,
while ignoring the difficulty of obtaining accurate key-frame indexes and the
objective existence of key-frame index errors, which impedes them from moving
towards practical applications. In this paper, we propose CausalNet, a novel
framework to achieve robust MER facing key-frame index errors while maintaining
accurate recognition. To enhance robustness, CausalNet takes the representation
of the entire ME sequence as the input. To address the information redundancy
brought by the complete ME range input and maintain accurate recognition,
first, the Causal Motion Position Learning Module (CMPLM) is proposed to help
the model locate the muscle movement areas related to Action Units (AUs),
thereby reducing the attention to other redundant areas. Second, the Causal
Attention Block (CAB) is proposed to deeply learn the causal relationships
between the muscle contraction and relaxation movements in MEs. Empirical
experiments have demonstrated that on popular ME benchmarks, the CausalNet has
achieved robust MER under different levels of key-frame index noise. Meanwhile,
it has surpassed state-of-the-art (SOTA) methods on several standard MER
benchmarks when using the provided annotated key-frames. Code is available at
https://github.com/tony19980810/CausalNet.

</details>


### [35] [Towards Robust Red-Green Watermarking for Autoregressive Image Generators](https://arxiv.org/abs/2508.06656)
*Denis Lukovnikov,Andreas Müller,Erwin Quiring,Asja Fischer*

Main category: cs.CV

TL;DR: 论文探讨了在自回归图像模型中应用生成内水印的方法，提出了两种基于视觉令牌聚类的新水印方案，提高了水印的鲁棒性和检测能力。


<details>
  <summary>Details</summary>
Motivation: 自回归（AR）图像模型中尚未探索生成内水印的应用，而现有方法在常见图像扰动下检测能力显著下降。

Method: 提出了两种基于视觉令牌聚类的水印方法：一种是无训练的方法，依赖聚类查找表；另一种是微调VAE编码器直接从扰动图像预测令牌聚类。

Result: 实验表明，聚类级水印提高了对扰动和再生攻击的鲁棒性，同时保持图像质量，聚类分类进一步提升了水印检测能力。

Conclusion: 提出的方法在快速验证运行时间和鲁棒性方面优于基线方法，适用于自回归图像模型。

Abstract: In-generation watermarking for detecting and attributing generated content
has recently been explored for latent diffusion models (LDMs), demonstrating
high robustness. However, the use of in-generation watermarks in autoregressive
(AR) image models has not been explored yet. AR models generate images by
autoregressively predicting a sequence of visual tokens that are then decoded
into pixels using a vector-quantized decoder. Inspired by red-green watermarks
for large language models, we examine token-level watermarking schemes that
bias the next-token prediction based on prior tokens. We find that a direct
transfer of these schemes works in principle, but the detectability of the
watermarks decreases considerably under common image perturbations. As a
remedy, we propose two novel watermarking methods that rely on visual token
clustering to assign similar tokens to the same set. Firstly, we investigate a
training-free approach that relies on a cluster lookup table, and secondly, we
finetune VAE encoders to predict token clusters directly from perturbed images.
Overall, our experiments show that cluster-level watermarks improve robustness
against perturbations and regeneration attacks while preserving image quality.
Cluster classification further boosts watermark detectability, outperforming a
set of baselines. Moreover, our methods offer fast verification runtime,
comparable to lightweight post-hoc watermarking methods.

</details>


### [36] [Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision](https://arxiv.org/abs/2508.06696)
*Tianqin Li,George Liu,Tai Sing Lee*

Main category: cs.CV

TL;DR: 论文提出用线描作为结构优先的预训练模态，以生成更紧凑和可泛化的视觉表示。实验表明，这种方法能增强形状偏好、注意力集中和数据效率，同时降低内在维度，并提升轻量模型的蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 现代视觉系统依赖冗余的视觉输入，而人类能轻松理解稀疏的线描。论文旨在探索结构优先的视觉学习是否能提升模型的效率和泛化能力。

Method: 使用线描作为预训练模态，提出无监督方法“学习绘制”，并在分类、检测和分割任务中验证效果。

Result: 线描预训练模型表现出更强的形状偏好、更集中的注意力和更高的数据效率，同时内在维度更低，蒸馏效果更好。

Conclusion: 结构优先的视觉学习能提升效率、泛化能力和人脑对齐的归纳偏差，为构建更鲁棒的视觉系统提供简单而强大的策略。

Abstract: Despite remarkable progress in computer vision, modern recognition systems
remain limited by their dependence on rich, redundant visual inputs. In
contrast, humans can effortlessly understand sparse, minimal representations
like line drawings - suggesting that structure, rather than appearance,
underlies efficient visual understanding. In this work, we propose using line
drawings as a structure-first pretraining modality to induce more compact and
generalizable visual representations. We show that models pretrained on line
drawings develop stronger shape bias, more focused attention, and greater data
efficiency across classification, detection, and segmentation tasks. Notably,
these models also exhibit lower intrinsic dimensionality, requiring
significantly fewer principal components to capture representational variance -
echoing the similar observation in low dimensional efficient representation in
the brain. Beyond performance improvements, line drawing pretraining produces
more compressible representations, enabling better distillation into
lightweight student models. Students distilled from line-pretrained teachers
consistently outperform those trained from color-supervised teachers,
highlighting the benefits of structurally compact knowledge. Finally, we
demonstrate that the pretraining with line-drawing can also be extended to
unsupervised setting via our proposed method "learning to draw". Together, our
results support the view that structure-first visual learning fosters
efficiency, generalization, and human-aligned inductive biases - offering a
simple yet powerful strategy for building more robust and adaptable vision
systems.

</details>


### [37] [Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography](https://arxiv.org/abs/2508.06703)
*Justin London*

Main category: cs.CV

TL;DR: 提出了一种高效快速的计算机生成全息图（CGH）框架，通过点云和MRI数据生成相位全息图和复杂全息图，并比较了不同优化算法的性能。


<details>
  <summary>Details</summary>
Motivation: 计算机生成全息图（CGH）在调制用户定义波形方面具有潜力，但需要更高效的生成方法。

Method: 利用点云和MRI数据重建体积对象，通过非凸傅里叶光学优化算法（交替投影、SGD、准牛顿法）生成全息图，并与HoloNet深度学习CGH进行比较。

Result: 使用2D中值滤波优化后，性能指标（MSE、RMSE、PSNR）得到改善，减少了伪影和噪声。

Conclusion: 提出的框架在生成全息图时表现优异，优化算法和滤波技术显著提升了重建质量。

Abstract: Computer-generated holography (CGH) is a promising method that modulates
user-defined waveforms with digital holograms. An efficient and fast pipeline
framework is proposed to synthesize CGH using initial point cloud and MRI data.
This input data is reconstructed into volumetric objects that are then input
into non-convex Fourier optics optimization algorithms for phase-only hologram
(POH) and complex-hologram (CH) generation using alternating projection, SGD,
and quasi-Netwton methods. Comparison of reconstruction performance of these
algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet
deep learning CGH. Performance metrics are shown to be improved by using 2D
median filtering to remove artifacts and speckled noise during optimization.

</details>


### [38] [Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video](https://arxiv.org/abs/2508.06715)
*Jixuan He,Chieh Hubert Lin,Lu Qi,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 论文提出Restage4D方法，利用真实视频的运动先验生成物理一致的4D内容，通过视频重放训练策略和几何一致性优化，提升了4D场景合成的质量。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在物理真实性和运动动态性上表现不足，而真实视频能提供物理基础的几何和运动信息，因此探索如何利用真实视频的运动先验生成物理一致的4D内容。

Method: 提出Restage4D方法，采用视频重放训练策略，结合遮挡感知刚性损失和遮挡回溯机制，优化几何和运动一致性。

Result: 在DAVIS和PointOdyssey数据集上验证，Restage4D在几何一致性、运动质量和3D跟踪性能上表现更优。

Conclusion: Restage4D不仅保留了可变形结构，还能自动纠正生成模型的错误，展示了视频先验在4D重演任务中的潜力。

Abstract: Creating deformable 3D content has gained increasing attention with the rise
of text-to-image and image-to-video generative models. While these models
provide rich semantic priors for appearance, they struggle to capture the
physical realism and motion dynamics needed for authentic 4D scene synthesis.
In contrast, real-world videos can provide physically grounded geometry and
articulation cues that are difficult to hallucinate. One question is raised:
\textit{Can we generate physically consistent 4D content by leveraging the
motion priors of the real-world video}? In this work, we explore the task of
reanimating deformable 3D scenes from a single video, using the original
sequence as a supervisory signal to correct artifacts from synthetic motion. We
introduce \textbf{Restage4D}, a geometry-preserving pipeline for
video-conditioned 4D restaging. Our approach uses a video-rewinding training
strategy to temporally bridge a real base video and a synthetic driving video
via a shared motion representation. We further incorporate an occlusion-aware
rigidity loss and a disocclusion backtracing mechanism to improve structural
and geometry consistency under challenging motion. We validate Restage4D on
DAVIS and PointOdyssey, demonstrating improved geometry consistency, motion
quality, and 3D tracking performance. Our method not only preserves deformable
structure under novel motion, but also automatically corrects errors introduced
by generative models, revealing the potential of video prior in 4D restaging
task. Source code and trained models will be released.

</details>


### [39] [FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI](https://arxiv.org/abs/2508.06756)
*Somayeh Farahani,Marjaneh Hejazi,Antonio Di Ieva,Sidong Liu*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的非侵入性方法（FoundBioNet），用于预测胶质瘤IDH突变状态，通过多参数MRI数据，结合肿瘤感知特征编码和跨模态差异模块，显著提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统侵入性组织采样方法无法捕捉肿瘤的空间异质性，且现有深度学习模型因标注数据稀缺而性能受限。

Method: 采用SWIN-UNETR架构，结合肿瘤感知特征编码（TAFE）和跨模态差异（CMD）模块，从多参数MRI中提取特征并预测IDH突变。

Result: 在多个独立测试集上AUC达65.41%-90.58%，显著优于基线方法（p≤0.05）。

Conclusion: FoundBioNet通过大规模预训练和任务特定微调，实现了可推广的胶质瘤特征分析，提升诊断准确性和可解释性。

Abstract: Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is
essential for effective glioma management. Traditional methods rely on invasive
tissue sampling, which may fail to capture a tumor's spatial heterogeneity.
While deep learning models have shown promise in molecular profiling, their
performance is often limited by scarce annotated data. In contrast, foundation
deep learning models offer a more generalizable approach for glioma imaging
biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that
utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation
status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware
Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and
Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch
signals associated with IDH mutation. The model was trained and validated on a
diverse, multi-center cohort of 1705 glioma patients from six public datasets.
Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent
test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming
baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE
and CMD modules are essential for improving predictive accuracy. By integrating
large-scale pretraining and task-specific fine-tuning, FoundBioNet enables
generalizable glioma characterization. This approach enhances diagnostic
accuracy and interpretability, with the potential to enable more personalized
patient care.

</details>


### [40] [SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding](https://arxiv.org/abs/2508.06763)
*Zihao Sheng,Zilin Huang,Yen-Jung Chen,Yansong Qu,Yuhao Luo,Yue Leng,Sikai Chen*

Main category: cs.CV

TL;DR: SafePLUG是一种新型多模态大语言模型框架，专注于交通场景的细粒度理解，支持像素级分割和时序事件定位。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在交通事故理解中缺乏对细粒度视觉细节和局部场景的处理能力，限制了复杂场景的应用。

Method: 提出SafePLUG框架，结合像素级理解和时序定位，支持区域感知问答和语言指令驱动的像素级分割。

Result: 实验表明SafePLUG在区域问答、像素分割、时序事件定位等任务中表现优异。

Conclusion: SafePLUG为复杂交通场景的细粒度理解奠定基础，有望提升智能交通系统的安全性和情境感知能力。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress
across a range of vision-language tasks and demonstrate strong potential for
traffic accident understanding. However, existing MLLMs in this domain
primarily focus on coarse-grained image-level or video-level comprehension and
often struggle to handle fine-grained visual details or localized scene
components, limiting their applicability in complex accident scenarios. To
address these limitations, we propose SafePLUG, a novel framework that empowers
MLLMs with both Pixel-Level Understanding and temporal Grounding for
comprehensive traffic accident analysis. SafePLUG supports both
arbitrary-shaped visual prompts for region-aware question answering and
pixel-level segmentation based on language instructions, while also enabling
the recognition of temporally anchored events in traffic accident scenarios. To
advance the development of MLLMs for traffic accident understanding, we curate
a new dataset containing multimodal question-answer pairs centered on diverse
accident scenarios, with detailed pixel-level annotations and temporal event
boundaries. Experimental results show that SafePLUG achieves strong performance
on multiple tasks, including region-based question answering, pixel-level
segmentation, temporal event localization, and accident event understanding.
These capabilities lay a foundation for fine-grained understanding of complex
traffic scenes, with the potential to improve driving safety and enhance
situational awareness in smart transportation systems. The code, dataset, and
model checkpoints will be made publicly available at:
https://zihaosheng.github.io/SafePLUG

</details>


### [41] [Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling](https://arxiv.org/abs/2508.06805)
*Aarav Mehta,Priya Deshmukh,Vikram Singh,Siddharth Malhotra,Krishnan Menon Iyer,Tanvi Iyer*

Main category: cs.CV

TL;DR: 提出了一种针对医学图像的精确边缘检测方法，通过反向细化架构提升边缘定位精度，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学影像中器官边界的毫米级精确定位对分割、手术规划等至关重要，而现有卷积网络在边缘定位上存在不足。

Method: 采用自上而下的反向细化架构，融合高层次语义特征与低层次细节，并扩展至各向异性体积数据。

Result: 在CT和MRI数据集上，边界定位性能显著提升，下游任务（如分割、配准）效果改善。

Conclusion: 该方法生成的精确边缘对医学影像任务具有临床价值。

Abstract: Accurate localization of organ boundaries is critical in medical imaging for
segmentation, registration, surgical planning, and radiotherapy. While deep
convolutional networks (ConvNets) have advanced general-purpose edge detection
to near-human performance on natural images, their outputs often lack precise
localization, a limitation that is particularly harmful in medical applications
where millimeter-level accuracy is required. Building on a systematic analysis
of ConvNet edge outputs, we propose a medically focused crisp edge detector
that adapts a novel top-down backward refinement architecture to medical images
(2D and volumetric). Our method progressively upsamples and fuses high-level
semantic features with fine-grained low-level cues through a backward
refinement pathway, producing high-resolution, well-localized organ boundaries.
We further extend the design to handle anisotropic volumes by combining 2D
slice-wise refinement with light 3D context aggregation to retain computational
efficiency. Evaluations on several CT and MRI organ datasets demonstrate
substantially improved boundary localization under strict criteria (boundary
F-measure, Hausdorff distance) compared to baseline ConvNet detectors and
contemporary medical edge/contour methods. Importantly, integrating our crisp
edge maps into downstream pipelines yields consistent gains in organ
segmentation (higher Dice scores, lower boundary errors), more accurate image
registration, and improved delineation of lesions near organ interfaces. The
proposed approach produces clinically valuable, crisp organ edges that
materially enhance common medical-imaging tasks.

</details>


### [42] [DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation](https://arxiv.org/abs/2508.06816)
*Vikram Singh,Kabir Malhotra,Rohan Desai,Ananya Shankaracharya,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 提出了一种新型双分辨率架构，用于皮肤镜图像中黑色素瘤的精确分割，结合边界感知和通道注意力模块，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤镜图像分割中纹理、颜色变化及常见干扰物的挑战，支持下游临床诊断。

Method: 采用ResNet启发的双分辨率架构，结合边界感知残差连接和通道注意力模块，辅以轻量级干扰抑制块和多任务训练目标。

Result: 在公开数据集上显著提升了边界贴合度和分割指标，优于标准编码器-解码器基线。

Conclusion: 该方法为自动化黑色素瘤评估系统提供了实用且高效的解决方案。

Abstract: Accurate segmentation of melanocytic tumors in dermoscopic images is a
critical step for automated skin cancer screening and clinical decision
support. Unlike natural scene segmentation, lesion delineation must reconcile
subtle texture and color variations, frequent artifacts (hairs, rulers,
bubbles), and a strong need for precise boundary localization to support
downstream diagnosis. In this paper we introduce Our method, a novel ResNet
inspired dual resolution architecture specifically designed for melanocytic
tumor segmentation. Our method maintains a full resolution stream that
preserves fine grained boundary information while a complementary pooled stream
aggregates multi scale contextual cues for robust lesion recognition. The
streams are tightly coupled by boundary aware residual connections that inject
high frequency edge information into deep feature maps, and by a channel
attention module that adapts color and texture sensitivity to dermoscopic
appearance. To further address common imaging artifacts and the limited size of
clinical datasets, we propose a lightweight artifact suppression block and a
multi task training objective that combines a Dice Tversky segmentation loss
with an explicit boundary loss and a contrastive regularizer for feature
stability. The combined design yields pixel accurate masks without requiring
heavy post processing or complex pre training protocols. Extensive experiments
on public dermoscopic benchmarks demonstrate that Our method significantly
improves boundary adherence and clinically relevant segmentation metrics
compared to standard encoder decoder baselines, making it a practical building
block for automated melanoma assessment systems.

</details>


### [43] [VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation](https://arxiv.org/abs/2508.06819)
*Ayaan Nooruddin Siddiqui,Mahnoor Zaidi,Ayesha Nazneen Shahbaz,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 提出了一种弱监督训练框架，用于皮下血管分割，利用稀疏标注生成密集监督，结合不确定性加权损失和拓扑感知正则化，显著减少标注负担并提升分割效果。


<details>
  <summary>Details</summary>
Motivation: 皮下血管分割面临标注稀缺、成本高以及图像低对比度和噪声的问题，需要一种高效且低成本的解决方案。

Method: 采用可微随机游走标签传播模型，结合图像驱动的血管特征和连续性先验，生成密集概率监督；同时联合训练CNN分割预测器，并引入拓扑感知正则化。

Result: 在临床数据集上优于稀疏标签和传统伪标签方法，生成更完整的血管图并提供校准的不确定性估计。

Conclusion: 该方法显著降低了标注负担，同时保持了血管拓扑结构，适用于临床决策。

Abstract: Accurate segmentation of subcutaneous vessels from clinical images is
hampered by scarce, expensive ground truth and by low contrast, noisy
appearance of vessels across patients and modalities. We present a novel weakly
supervised training framework tailored for subcutaneous vessel segmentation
that leverages inexpensive sparse annotations (e.g., centerline traces, dot
markers, or short scribbles). Sparse labels are expanded into dense,
probabilistic supervision via a differentiable random walk label propagation
model whose transition weights incorporate image driven vesselness cues and
tubular continuity priors. The propagation yields per-pixel hitting
probabilities together with calibrated uncertainty estimates; these are
incorporated into an uncertainty weighted loss to avoid over fitting to
ambiguous regions. Crucially, the label-propagator is learned jointly with a
CNN based segmentation predictor, enabling the system to discover vessel edges
and continuity constraints without explicit edge supervision. We further
introduce a topology aware regularizer that encourages centerline connectivity
and penalizes spurious branches, improving clinical usability. In experiments
on clinical subcutaneous imaging datasets, our method consistently outperforms
naive training on sparse labels and conventional dense pseudo-labeling,
producing more complete vascular maps and better calibrated uncertainty for
downstream decision making. The approach substantially reduces annotation
burden while preserving clinically relevant vessel topology.

</details>


### [44] [Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification](https://arxiv.org/abs/2508.06831)
*Taha Mustapha Nehdi,Nairouz Mrabah,Atif Belal,Marco Pedersoli,Eric Granger*

Main category: cs.CV

TL;DR: SAGE-reID是一种高效的多源域自适应方法，通过源无关的低秩适配器和轻量级门控网络实现跨域知识迁移，显著减少计算成本和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 解决多源域自适应（MSDA）方法中因学习域特定主干模型或需要源域数据而导致的参数和计算成本高的问题。

Method: 提出SAGE-reID方法，包括源无关的低秩适配器（LoRA）训练和轻量级门控网络动态分配权重。

Result: 在Market-1501、DukeMTMC-reID和MSMT17基准测试中表现优于现有方法，计算效率高。

Conclusion: SAGE-reID是一种高效、轻量级的MSDA方法，适用于行人重识别任务。

Abstract: Adapting person re-identification (reID) models to new target environments
remains a challenging problem that is typically addressed using unsupervised
domain adaptation (UDA) methods. Recent works show that when labeled data
originates from several distinct sources (e.g., datasets and cameras),
considering each source separately and applying multi-source domain adaptation
(MSDA) typically yields higher accuracy and robustness compared to blending the
sources and performing conventional UDA. However, state-of-the-art MSDA methods
learn domain-specific backbone models or require access to source domain data
during adaptation, resulting in significant growth in training parameters and
computational cost. In this paper, a Source-free Adaptive Gated Experts
(SAGE-reID) method is introduced for person reID. Our SAGE-reID is a
cost-effective, source-free MSDA method that first trains individual
source-specific low-rank adapters (LoRA) through source-free UDA. Next, a
lightweight gating network is introduced and trained to dynamically assign
optimal merging weights for fusion of LoRA experts, enabling effective
cross-domain knowledge transfer. While the number of backbone parameters
remains constant across source domains, LoRA experts scale linearly but remain
negligible in size (<= 2% of the backbone), reducing both the memory
consumption and risk of overfitting. Extensive experiments conducted on three
challenging benchmarks: Market-1501, DukeMTMC-reID, and MSMT17 indicate that
SAGE-reID outperforms state-of-the-art methods while being computationally
efficient.

</details>


### [45] [Hybrid Machine Learning Framework for Predicting Geometric Deviations from 3D Surface Metrology](https://arxiv.org/abs/2508.06845)
*Hamidreza Samadi,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.CV

TL;DR: 该研究提出了一种结合高分辨率3D扫描和混合机器学习框架的方法，用于预测制造组件的几何偏差，显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现代制造中复杂几何形状的尺寸精度难以保持，需要更精确的预测方法。

Method: 使用高分辨率3D扫描仪获取多角度表面数据，通过精确对齐、降噪和合并技术生成3D模型，并开发混合机器学习框架（CNN特征提取+梯度提升决策树预测）。

Result: 预测精度达到0.012毫米（95%置信水平），比传统方法提升73%，并揭示了制造参数与几何偏差的隐藏关联。

Conclusion: 该方法为自动化质量控制、预测性维护和设计优化提供了潜力，数据集也为未来研究奠定了基础。

Abstract: This study addresses the challenge of accurately forecasting geometric
deviations in manufactured components using advanced 3D surface analysis.
Despite progress in modern manufacturing, maintaining dimensional precision
remains difficult, particularly for complex geometries. We present a
methodology that employs a high-resolution 3D scanner to acquire multi-angle
surface data from 237 components produced across different batches. The data
were processed through precise alignment, noise reduction, and merging
techniques to generate accurate 3D representations. A hybrid machine learning
framework was developed, combining convolutional neural networks for feature
extraction with gradient-boosted decision trees for predictive modeling. The
proposed system achieved a prediction accuracy of 0.012 mm at a 95% confidence
level, representing a 73% improvement over conventional statistical process
control methods. In addition to improved accuracy, the model revealed hidden
correlations between manufacturing parameters and geometric deviations. This
approach offers significant potential for automated quality control, predictive
maintenance, and design optimization in precision manufacturing, and the
resulting dataset provides a strong foundation for future predictive modeling
research.

</details>


### [46] [AGIC: Attention-Guided Image Captioning to Improve Caption Relevance](https://arxiv.org/abs/2508.06853)
*L. D. M. S. Sai Teja,Ashok Urlana,Pruthwik Mishra*

Main category: cs.CV

TL;DR: AGIC通过注意力引导和混合解码策略提升图像描述生成效果，在Flickr8k和Flickr30k数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管图像描述生成取得进展，但生成准确且描述性强的标题仍是挑战。

Method: 提出AGIC，通过特征空间增强显著视觉区域，并采用混合解码策略平衡流畅性和多样性。

Result: AGIC在Flickr8k和Flickr30k上表现优于或匹配现有模型，推理速度更快，且在多指标中表现优异。

Conclusion: AGIC为图像描述生成提供了可扩展且可解释的解决方案。

Abstract: Despite significant progress in image captioning, generating accurate and
descriptive captions remains a long-standing challenge. In this study, we
propose Attention-Guided Image Captioning (AGIC), which amplifies salient
visual regions directly in the feature space to guide caption generation. We
further introduce a hybrid decoding strategy that combines deterministic and
probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we
conduct extensive experiments on the Flickr8k and Flickr30k datasets. The
results show that AGIC matches or surpasses several state-of-the-art models
while achieving faster inference. Moreover, AGIC demonstrates strong
performance across multiple evaluation metrics, offering a scalable and
interpretable solution for image captioning.

</details>


### [47] [A Joint Sparse Self-Representation Learning Method for Multiview Clustering](https://arxiv.org/abs/2508.06857)
*Mengxue Jia,Zhihua Allen-Zhao,You Zhao,Sanyang Liu*

Main category: cs.CV

TL;DR: 提出了一种基于联合稀疏自表示学习的多视图聚类方法，通过引入基数约束提取局部信息，并开发了全局收敛的交替二次惩罚方法。


<details>
  <summary>Details</summary>
Motivation: 多视图聚类（MC）旨在利用不同视图的一致性和互补信息进行样本分组，而子空间聚类作为MC的基础技术备受关注。本文旨在通过改进稀疏自表示学习方法，提升聚类性能。

Method: 提出了一种联合稀疏自表示学习模型，使用基数约束（ℓ0-范数）替代图拉普拉斯正则化，提取视图特定的局部信息；同时采用低秩约束揭示全局一致结构。为解决非凸非光滑模型的收敛问题，开发了交替二次惩罚（AQP）方法。

Result: 在六个标准数据集上的实验表明，所提模型和AQP方法优于八种最先进算法。

Conclusion: 通过基数约束和低秩约束的结合，以及AQP方法的开发，显著提升了多视图聚类的性能和泛化能力。

Abstract: Multiview clustering (MC) aims to group samples using consistent and
complementary information across various views. The subspace clustering, as a
fundamental technique of MC, has attracted significant attention. In this
paper, we propose a novel joint sparse self-representation learning model for
MC, where a featured difference is the extraction of view-specific local
information by introducing cardinality (i.e., $\ell_0$-norm) constraints
instead of Graph-Laplacian regularization. Specifically, under each view,
cardinality constraints directly restrict the samples used in the
self-representation stage to extract reliable local and global structure
information, while the low-rank constraint aids in revealing a global coherent
structure in the consensus affinity matrix during merging. The attendant
challenge is that Augmented Lagrange Method (ALM)-based alternating
minimization algorithms cannot guarantee convergence when applied directly to
our nonconvex, nonsmooth model, thus resulting in poor generalization ability.
To address it, we develop an alternating quadratic penalty (AQP) method with
global convergence, where two subproblems are iteratively solved by closed-form
solutions. Empirical results on six standard datasets demonstrate the
superiority of our model and AQP method, compared to eight state-of-the-art
algorithms.

</details>


### [48] [VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding](https://arxiv.org/abs/2508.06869)
*Jianxiang He,Shaoguang Wang,Weiyu Guo,Meisheng Hong,Jungang Li,Yijie Xu,Ziyang Chen,Hui Xiong*

Main category: cs.CV

TL;DR: 提出了一种名为VSI的多模态关键帧搜索方法，通过结合字幕和时间戳提升长视频理解任务的效果。


<details>
  <summary>Details</summary>
Motivation: 解决长视频理解中多模态对齐不足和复杂时序语义信息捕捉困难的问题。

Method: 采用双流搜索机制（视频搜索流和字幕匹配流），整合视觉和文本信息。

Result: 在LongVideoBench上关键帧定位准确率达40.00%，视频问答任务准确率达68.48%，均显著优于基线。

Conclusion: VSI在多模态搜索中表现出鲁棒性和泛化能力，达到SOTA水平。

Abstract: Long video understanding presents a significant challenge to multimodal large
language models (MLLMs) primarily due to the immense data scale. A critical and
widely adopted strategy for making this task computationally tractable is
keyframe retrieval, which seeks to identify a sparse set of video frames that
are most salient to a given textual query. However, the efficacy of this
approach is hindered by weak multimodal alignment between textual queries and
visual content and fails to capture the complex temporal semantic information
required for precise reasoning. To address this, we propose Visual-Subtitle
Integeration(VSI), a multimodal keyframe search method that integrates
subtitles, timestamps, and scene boundaries into a unified multimodal search
process. The proposed method captures the visual information of video frames as
well as the complementary textual information through a dual-stream search
mechanism by Video Search Stream as well as Subtitle Match Stream,
respectively, and improves the keyframe search accuracy through the interaction
of the two search streams. Experimental results show that VSI achieve 40.00%
key frame localization accuracy on the text-relevant subset of LongVideoBench
and 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive
baselines by 20.35% and 15.79%, respectively. Furthermore, on the
LongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA
tasks, demonstrating the robustness and generalizability of the proposed
multimodal search strategy.

</details>


### [49] [NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective](https://arxiv.org/abs/2508.06878)
*Maoxun Yuan,Duanni Meng,Ziteng Xi,Tianyi Zhao,Shiji Zhao,Yimian Dai,Xingxing Wei*

Main category: cs.CV

TL;DR: 提出了一种新型噪声抑制特征金字塔网络（NS-FPN），通过低频引导特征净化（LFP）模块和螺旋感知特征采样（SFS）模块，显著减少红外小目标检测中的误报问题。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测因目标暗淡、形状模糊及背景干扰而极具挑战性，现有CNN方法虽能增强特征表示但导致误报增加，需从噪声抑制角度改进性能。

Method: NS-FPN结合LFP模块（通过净化高频成分抑制噪声）和SFS模块（螺旋采样融合目标相关特征），轻量且易于集成到现有框架。

Result: 在公开数据集上，NS-FPN显著减少误报，性能优于现有方法。

Conclusion: NS-FPN从噪声抑制角度提升了红外小目标检测性能，具有实用性和高效性。

Abstract: Infrared small target detection and segmentation (IRSTDS) is a critical yet
challenging task in defense and civilian applications, owing to the dim,
shapeless appearance of targets and severe background clutter. Recent CNN-based
methods have achieved promising target perception results, but they only focus
on enhancing feature representation to offset the impact of noise, which
results in the increased false alarms problem. In this paper, through analyzing
the problem from the frequency domain, we pioneer in improving performance from
noise suppression perspective and propose a novel noise-suppression feature
pyramid network (NS-FPN), which integrates a low-frequency guided feature
purification (LFP) module and a spiral-aware feature sampling (SFS) module into
the original FPN structure. The LFP module suppresses the noise features by
purifying high-frequency components to achieve feature enhancement devoid of
noise interference, while the SFS module further adopts spiral sampling to fuse
target-relevant features in feature fusion process. Our NS-FPN is designed to
be lightweight yet effective and can be easily plugged into existing IRSTDS
frameworks. Extensive experiments on the public IRSTDS datasets demonstrate
that our method significantly reduces false alarms and achieves superior
performance on IRSTDS tasks.

</details>


### [50] [FormCoach: Lift Smarter, Not Harder](https://arxiv.org/abs/2508.07501)
*Xiaoye Zuo,Nikos Athanasiou,Ginger Delmas,Yiming Huang,Xingyu Fu,Lingjie Liu*

Main category: cs.CV

TL;DR: FormCoach利用视觉语言模型（VLMs）将普通摄像头转化为实时互动的AI健身教练，提供实时动作纠正，并发布了数据集和评估工具以推动研究。


<details>
  <summary>Details</summary>
Motivation: 为家庭健身爱好者提供专业反馈，解决其无法获得专家指导的问题。

Method: 通过视觉语言模型（VLMs）分析用户动作，实时检测并纠正错误，使用1700对专家标注的视频数据进行模型训练和评估。

Result: 基准测试显示AI与人类教练水平仍有差距，但为AI驱动的健身教练系统提供了新方向。

Conclusion: FormCoach通过人机协作的方式，为AI在健身领域的应用开辟了新途径。

Abstract: Good form is the difference between strength and strain, yet for the
fast-growing community of at-home fitness enthusiasts, expert feedback is often
out of reach. FormCoach transforms a simple camera into an always-on,
interactive AI training partner, capable of spotting subtle form errors and
delivering tailored corrections in real time, leveraging vision-language models
(VLMs). We showcase this capability through a web interface and benchmark
state-of-the-art VLMs on a dataset of 1,700 expert-annotated user-reference
video pairs spanning 22 strength and mobility exercises. To accelerate research
in AI-driven coaching, we release both the dataset and an automated,
rubric-based evaluation pipeline, enabling standardized comparison across
models. Our benchmarks reveal substantial gaps compared to human-level
coaching, underscoring both the challenges and opportunities in integrating
nuanced, context-aware movement analysis into interactive AI systems. By
framing form correction as a collaborative and creative process between humans
and machines, FormCoach opens a new frontier in embodied AI.

</details>


### [51] [BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models](https://arxiv.org/abs/2508.06895)
*Jianting Tang,Yubo Wang,Haoyu Cao,Linli Xu*

Main category: cs.CV

TL;DR: 论文提出BASIC方法，通过直接监督视觉嵌入提升多模态大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法仅将视觉嵌入作为上下文线索，缺乏直接视觉监督，限制了视觉嵌入的精细对齐。

Method: BASIC利用LLM浅层中精炼的视觉嵌入作为监督，从嵌入方向和语义匹配两个角度优化初始视觉嵌入。

Result: BASIC显著提升了MLLMs在多个基准测试中的表现。

Conclusion: 直接视觉监督是提升视觉嵌入对齐的有效方法。

Abstract: Mainstream Multimodal Large Language Models (MLLMs) achieve visual
understanding by using a vision projector to bridge well-pretrained vision
encoders and large language models (LLMs). The inherent gap between visual and
textual modalities makes the embeddings from the vision projector critical for
visual comprehension. However, current alignment approaches treat visual
embeddings as contextual cues and merely apply auto-regressive supervision to
textual outputs, neglecting the necessity of introducing equivalent direct
visual supervision, which hinders the potential finer alignment of visual
embeddings. In this paper, based on our analysis of the refinement process of
visual embeddings in the LLM's shallow layers, we propose BASIC, a method that
utilizes refined visual embeddings within the LLM as supervision to directly
guide the projector in generating initial visual embeddings. Specifically, the
guidance is conducted from two perspectives: (i) optimizing embedding
directions by reducing angles between initial and supervisory embeddings in
semantic space; (ii) improving semantic matching by minimizing disparities
between the logit distributions of both visual embeddings. Without additional
supervisory models or artificial annotations, BASIC significantly improves the
performance of MLLMs across a wide range of benchmarks, demonstrating the
effectiveness of our introduced direct visual supervision.

</details>


### [52] [Advancements in Chinese font generation since deep learning era: A survey](https://arxiv.org/abs/2508.06900)
*Weiran Chen,Guiqian Zhu,Ying Li,Yi Ji,Chunping Liu*

Main category: cs.CV

TL;DR: 本文综述了基于深度学习的汉字字体生成方法，包括研究背景、文献选择方法、分类（多参考样本和少参考样本生成）及未来方向。


<details>
  <summary>Details</summary>
Motivation: 汉字字体生成是字体设计和排版领域的重要课题，但如何提高生成质量仍是难题。

Method: 通过文献综述，分类讨论多参考样本和少参考样本的生成方法，并分析其优缺点。

Result: 总结了现有方法的代表性技术及其局限性。

Conclusion: 提出了未来研究方向，为该领域研究者提供参考。

Abstract: Chinese font generation aims to create a new Chinese font library based on
some reference samples. It is a topic of great concern to many font designers
and typographers. Over the past years, with the rapid development of deep
learning algorithms, various new techniques have achieved flourishing and
thriving progress. Nevertheless, how to improve the overall quality of
generated Chinese character images remains a tough issue. In this paper, we
conduct a holistic survey of the recent Chinese font generation approaches
based on deep learning. To be specific, we first illustrate the research
background of the task. Then, we outline our literature selection and analysis
methodology, and review a series of related fundamentals, including classical
deep learning architectures, font representation formats, public datasets, and
frequently-used evaluation metrics. After that, relying on the number of
reference samples required to generate a new font, we categorize the existing
methods into two major groups: many-shot font generation and few-shot font
generation methods. Within each category, representative approaches are
summarized, and their strengths and limitations are also discussed in detail.
Finally, we conclude our paper with the challenges and future directions, with
the expectation to provide some valuable illuminations for the researchers in
this field.

</details>


### [53] [Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection](https://arxiv.org/abs/2508.07923)
*Jakub Binda,Valentina Paneta,Vasileios Eleftheriadis,Hongkyou Chung,Panagiotis Papadimitroulas,Neo Christopher Chung*

Main category: cs.CV

TL;DR: 提出了一种混合异常检测框架，用于增强生成式AI在核医学中的可靠性和合规性，并在两个应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在核医学中具有巨大潜力，但需要可靠的异常检测机制以确保其在高风险场景中的安全性。

Method: 开发并实施了一种混合异常检测框架，应用于Pose2Xray和DosimetrEYE两个系统。

Result: 该框架提高了生成式AI的可靠性，减少了人工监督，并支持实时质量控制。

Conclusion: 该方法增强了生成式AI在临床前环境中的工业可行性，提高了鲁棒性、可扩展性和合规性。

Abstract: Generative AI holds great potentials to automate and enhance data synthesis
in nuclear medicine. However, the high-stakes nature of biomedical imaging
necessitates robust mechanisms to detect and manage unexpected or erroneous
model behavior. We introduce development and implementation of a hybrid anomaly
detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems.
Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays
from photographic mouse images, and DosimetrEYE, which estimates 3D radiation
dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD)
enhances reliability, reduces manual oversight, and supports real-time quality
control. This approach strengthens the industrial viability of GenAI in
preclinical settings by increasing robustness, scalability, and regulatory
compliance.

</details>


### [54] [eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos](https://arxiv.org/abs/2508.06902)
*Xuecheng Wu,Dingkang Yang,Danlei Huang,Xinyi Yin,Yifan Wang,Jia Zhang,Jiayu Nie,Liangyu Fu,Yang Liu,Junxiao Xue,Hadi Amirpour,Wei Zhou*

Main category: cs.CV

TL;DR: 论文提出eMotions数据集和AV-CANet网络，用于短视频情感分析，解决了数据稀缺和模态融合的挑战。


<details>
  <summary>Details</summary>
Motivation: 短视频情感分析因数据稀缺和模态复杂性而困难，需新方法和数据集。

Method: 提出多阶段标注的数据集eMotions和音频-视觉融合网络AV-CANet，含局部-全局融合模块和EP-CE损失。

Result: 在多个数据集上验证AV-CANet有效性，并提供消融实验分析。

Conclusion: AV-CANet为短视频情感分析提供有效解决方案，未来研究可进一步探索。

Abstract: Short-form videos (SVs) have become a vital part of our online routine for
acquiring and sharing information. Their multimodal complexity poses new
challenges for video analysis, highlighting the need for video emotion analysis
(VEA) within the community. Given the limited availability of SVs emotion data,
we introduce eMotions, a large-scale dataset consisting of 27,996 videos with
full-scale annotations. To ensure quality and reduce subjective bias, we
emphasize better personnel allocation and propose a multi-stage annotation
procedure. Additionally, we provide the category-balanced and test-oriented
variants through targeted sampling to meet diverse needs. While there have been
significant studies on videos with clear emotional cues (e.g., facial
expressions), analyzing emotions in SVs remains a challenging task. The
challenge arises from the broader content diversity, which introduces more
distinct semantic gaps and complicates the representations learning of
emotion-related features. Furthermore, the prevalence of audio-visual
co-expressions in SVs leads to the local biases and collective information gaps
caused by the inconsistencies in emotional expressions. To tackle this, we
propose AV-CANet, an end-to-end audio-visual fusion network that leverages
video transformer to capture semantically relevant representations. We further
introduce the Local-Global Fusion Module designed to progressively capture the
correlations of audio-visual features. Besides, EP-CE Loss is constructed to
globally steer optimizations with tripolar penalties. Extensive experiments
across three eMotions-related datasets and four public VEA datasets demonstrate
the effectiveness of our proposed AV-CANet, while providing broad insights for
future research. Moreover, we conduct ablation studies to examine the critical
components of our method. Dataset and code will be made available at Github.

</details>


### [55] [The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility](https://arxiv.org/abs/2508.07989)
*Xiantao Zhang*

Main category: cs.CV

TL;DR: 论文指出多模态大语言模型（MLLMs）在盲人和视障群体辅助技术中存在‘电梯问题’，即无法感知电梯运行方向，揭示了‘隐性运动盲区’的深层限制。


<details>
  <summary>Details</summary>
Motivation: MLLMs在动态环境中的实际应用存在信任问题，尤其是对连续低信号运动的感知不足。

Method: 通过分析现有模型的帧采样范式，提出‘隐性运动盲区’的概念，并探讨其对用户信任的影响。

Result: 发现现有模型在物理感知方面存在缺陷，无法满足动态环境中的用户需求。

Conclusion: 呼吁从语义识别转向物理感知，并开发以用户需求为中心的新基准测试。

Abstract: Multimodal Large Language Models (MLLMs) hold immense promise as assistive
technologies for the blind and visually impaired (BVI) community. However, we
identify a critical failure mode that undermines their trustworthiness in
real-world applications. We introduce the Escalator Problem -- the inability of
state-of-the-art models to perceive an escalator's direction of travel -- as a
canonical example of a deeper limitation we term Implicit Motion Blindness.
This blindness stems from the dominant frame-sampling paradigm in video
understanding, which, by treating videos as discrete sequences of static
images, fundamentally struggles to perceive continuous, low-signal motion. As a
position paper, our contribution is not a new model but rather to: (I) formally
articulate this blind spot, (II) analyze its implications for user trust, and
(III) issue a call to action. We advocate for a paradigm shift from purely
semantic recognition towards robust physical perception and urge the
development of new, human-centered benchmarks that prioritize safety,
reliability, and the genuine needs of users in dynamic environments.

</details>


### [56] [A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2508.06904)
*Chao Yin,Jide Li,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 提出了一种无需训练的实例感知提示框架（IAPF），通过多模态大语言模型和实例级提示生成精细的掩码，显著提升了伪装物体分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有训练免费方法生成的语义级提示导致粗糙的分割结果，无法处理多实例场景。

Method: IAPF包括文本提示生成、实例掩码生成和自一致性投票三个步骤，利用MLLM和Grounding DINO生成精细提示。

Result: 在标准COS基准测试中，IAPF显著优于现有训练免费方法。

Conclusion: IAPF通过实例级提示和自一致性投票，有效解决了多实例伪装物体分割问题。

Abstract: Camouflaged Object Segmentation (COS) remains highly challenging due to the
intrinsic visual similarity between target objects and their surroundings.
While training-based COS methods achieve good performance, their performance
degrades rapidly with increased annotation sparsity. To circumvent this
limitation, recent studies have explored training-free COS methods, leveraging
the Segment Anything Model (SAM) by automatically generating visual prompts
from a single task-generic prompt (\textit{e.g.}, "\textit{camouflaged
animal}") uniformly applied across all test images. However, these methods
typically produce only semantic-level visual prompts, causing SAM to output
coarse semantic masks and thus failing to handle scenarios with multiple
discrete camouflaged instances effectively. To address this critical
limitation, we propose a simple yet powerful \textbf{I}nstance-\textbf{A}ware
\textbf{P}rompting \textbf{F}ramework (IAPF), the first training-free COS
pipeline that explicitly converts a task-generic prompt into fine-grained
instance masks. Specifically, the IAPF comprises three steps: (1) Text Prompt
Generator, utilizing task-generic queries to prompt a Multimodal Large Language
Model (MLLM) for generating image-specific foreground and background tags; (2)
\textbf{Instance Mask Generator}, leveraging Grounding DINO to produce precise
instance-level bounding box prompts, alongside the proposed Single-Foreground
Multi-Background Prompting strategy to sample region-constrained point prompts
within each box, enabling SAM to yield a candidate instance mask; (3)
Self-consistency Instance Mask Voting, which selects the final COS prediction
by identifying the candidate mask most consistent across multiple candidate
instance masks. Extensive evaluations on standard COS benchmarks demonstrate
that the proposed IAPF significantly surpasses existing state-of-the-art
training-free COS methods.

</details>


### [57] [MultiRef: Controllable Image Generation with Multiple Visual References](https://arxiv.org/abs/2508.06905)
*Ruoxi Chen,Dongping Chen,Siyuan Wu,Sinan Wang,Shiyun Lang,Petr Sushko,Gaoyang Jiang,Yao Wan,Ranjay Krishna*

Main category: cs.CV

TL;DR: 论文提出了一种多参考图像生成任务，并构建了MultiRef-bench评估框架和MultiRef数据集，实验表明现有模型在多参考条件下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前图像生成框架主要依赖单源输入（文本或单张参考图），而设计师通常需要从多张参考图中获取灵感，因此需要研究多参考图像生成任务。

Method: 提出MultiRef-bench评估框架（包含990合成和1000真实样本），并通过RefBlend数据引擎生成合成样本。构建MultiRef数据集（38k高质量图像），并在多个模型（如OmniGen、ACE等）上进行实验。

Result: 现有模型在多参考条件下表现不佳，最佳模型OmniGen在合成和真实样本上的平均表现分别为66.6%和79.0%。

Conclusion: 研究为开发更灵活、更接近人类创作的工具提供了方向，MultiRef数据集已公开。

Abstract: Visual designers naturally draw inspiration from multiple visual references,
combining diverse elements and aesthetic principles to create artwork. However,
current image generative frameworks predominantly rely on single-source inputs
-- either text prompts or individual reference images. In this paper, we focus
on the task of controllable image generation using multiple visual references.
We introduce MultiRef-bench, a rigorous evaluation framework comprising 990
synthetic and 1,000 real-world samples that require incorporating visual
content from multiple reference images. The synthetic samples are synthetically
generated through our data engine RefBlend, with 10 reference types and 33
reference combinations. Based on RefBlend, we further construct a dataset
MultiRef containing 38k high-quality images to facilitate further research. Our
experiments across three interleaved image-text models (i.e., OmniGen, ACE, and
Show-o) and six agentic frameworks (e.g., ChatDiT and LLM + SD) reveal that
even state-of-the-art systems struggle with multi-reference conditioning, with
the best model OmniGen achieving only 66.6% in synthetic samples and 79.0% in
real-world cases on average compared to the golden answer. These findings
provide valuable directions for developing more flexible and human-like
creative tools that can effectively integrate multiple sources of visual
inspiration. The dataset is publicly available at: https://multiref.github.io/.

</details>


### [58] [MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification](https://arxiv.org/abs/2508.06908)
*Jinhao Li,Zijian Chen,Lirong Deng,Changbo Wang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 论文提出首个多任务多模态行人重识别基准MMReID-Bench，利用多模态大语言模型（MLLMs）解决传统模型在多模态数据上的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 传统行人重识别模型在多模态数据（如RGB、热成像、红外、素描图像和文本描述）上泛化能力差，而现有方法未充分利用MLLMs的推理和跨模态理解能力。

Method: 引入MMReID-Bench基准，包含20,710个多模态查询和库图像，覆盖10种行人重识别任务，验证MLLMs的有效性和多样性。

Result: 实验显示MLLMs在行人重识别中表现优异，但在处理热成像和红外数据时仍有局限。

Conclusion: MMReID-Bench有望推动开发更鲁棒和通用的多模态基础模型。

Abstract: Person re-identification (ReID) aims to retrieve the images of an interested
person in the gallery images, with wide applications in medical rehabilitation,
abnormal behavior detection, and public security. However, traditional person
ReID models suffer from uni-modal capability, leading to poor generalization
ability in multi-modal data, such as RGB, thermal, infrared, sketch images,
textual descriptions, etc. Recently, the emergence of multi-modal large
language models (MLLMs) shows a promising avenue for addressing this problem.
Despite this potential, existing methods merely regard MLLMs as feature
extractors or caption generators, which do not fully unleash their reasoning,
instruction-following, and cross-modal understanding capabilities. To bridge
this gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark
specifically designed for person ReID. The MMReID-Bench includes 20,710
multi-modal queries and gallery images covering 10 different person ReID tasks.
Comprehensive experiments demonstrate the remarkable capabilities of MLLMs in
delivering effective and versatile person ReID. Nevertheless, they also have
limitations in handling a few modalities, particularly thermal and infrared
data. We hope MMReID-Bench can facilitate the community to develop more robust
and generalizable multimodal foundation models for person ReID.

</details>


### [59] [Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing](https://arxiv.org/abs/2508.06916)
*Shichao Ma,Yunhe Guo,Jiahao Su,Qihe Huang,Zhengyang Zhou,Yang Wang*

Main category: cs.CV

TL;DR: Talk2Image是一个多代理系统，用于多轮对话中的交互式图像生成和编辑，解决了现有单代理系统的意图漂移和编辑不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成任务多关注单轮场景，难以处理多轮迭代创作任务，且单代理系统易导致意图漂移和编辑不连贯。

Method: Talk2Image整合了三个关键组件：从对话历史解析意图、任务分解与多代理协作执行、基于多视角评估的反馈驱动优化。

Result: 实验表明，Talk2Image在可控性、连贯性和用户满意度上优于现有基线。

Conclusion: Talk2Image通过多代理协作和多轮反馈机制，显著提升了多轮图像生成和编辑的效果。

Abstract: Text-to-image generation tasks have driven remarkable advances in diverse
media applications, yet most focus on single-turn scenarios and struggle with
iterative, multi-turn creative tasks. Recent dialogue-based systems attempt to
bridge this gap, but their single-agent, sequential paradigm often causes
intention drift and incoherent edits. To address these limitations, we present
Talk2Image, a novel multi-agent system for interactive image generation and
editing in multi-turn dialogue scenarios. Our approach integrates three key
components: intention parsing from dialogue history, task decomposition and
collaborative execution across specialized agents, and feedback-driven
refinement based on a multi-view evaluation mechanism. Talk2Image enables
step-by-step alignment with user intention and consistent image editing.
Experiments demonstrate that Talk2Image outperforms existing baselines in
controllability, coherence, and user satisfaction across iterative image
generation and editing tasks.

</details>


### [60] [AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning](https://arxiv.org/abs/2508.06924)
*Shihao Yuan,Yahui Liu,Yang Yue,Jingyuan Zhang,Wangmeng Zuo,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.CV

TL;DR: AR-GRPO将在线强化学习（RL）整合到自回归（AR）图像生成模型中，通过精心设计的奖励函数优化生成图像的质量，显著提升了图像质量和人类偏好。


<details>
  <summary>Details</summary>
Motivation: 受强化学习在大语言模型（LLMs）中成功的启发，研究者希望将其应用于自回归图像生成模型，以提升生成图像的质量和可控性。

Method: 采用Group Relative Policy Optimization（GRPO）算法，通过多维度奖励函数（如感知质量、真实感和语义保真度）优化自回归模型的输出。

Result: 在类别条件（class-to-image）和文本条件（text-to-image）图像生成任务中，RL增强的框架显著提升了图像质量和人类偏好，各项评估指标均有改进。

Conclusion: 研究表明，基于RL的优化对AR图像生成具有可行性，为可控和高质量图像合成开辟了新途径。

Abstract: Inspired by the success of reinforcement learning (RL) in refining large
language models (LLMs), we propose AR-GRPO, an approach to integrate online RL
training into autoregressive (AR) image generation models. We adapt the Group
Relative Policy Optimization (GRPO) algorithm to refine the vanilla
autoregressive models' outputs by carefully designed reward functions that
evaluate generated images across multiple quality dimensions, including
perceptual quality, realism, and semantic fidelity. We conduct comprehensive
experiments on both class-conditional (i.e., class-to-image) and
text-conditional (i.e., text-to-image) image generation tasks, demonstrating
that our RL-enhanced framework significantly improves both the image quality
and human preference of generated images compared to the standard AR baselines.
Our results show consistent improvements across various evaluation metrics,
establishing the viability of RL-based optimization for AR image generation and
opening new avenues for controllable and high-quality image synthesis. The
source codes and models are available at:
https://github.com/Kwai-Klear/AR-GRPO.

</details>


### [61] [CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing](https://arxiv.org/abs/2508.06937)
*Weiyan Xie,Han Gao,Didan Deng,Kaican Li,April Hua Liu,Yongxiang Huang,Nevin L. Zhang*

Main category: cs.CV

TL;DR: CannyEdit是一种无需训练的框架，通过选择性Canny控制和双提示引导，解决了文本到图像模型在区域编辑中的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在编辑区域文本遵从性、未编辑区域上下文保真度及编辑无缝性方面存在不足。

Method: 采用选择性Canny控制保留未编辑区域细节，结合双提示引导（局部和全局提示）实现精确编辑。

Result: 在真实图像编辑任务中，CannyEdit在文本遵从性和上下文保真度上优于现有方法2.93%至10.49%，且编辑结果更自然。

Conclusion: CannyEdit通过创新方法显著提升了区域图像编辑的质量和自然度。

Abstract: Recent advances in text-to-image (T2I) models have enabled training-free
regional image editing by leveraging the generative priors of foundation
models. However, existing methods struggle to balance text adherence in edited
regions, context fidelity in unedited areas, and seamless integration of edits.
We introduce CannyEdit, a novel training-free framework that addresses these
challenges through two key innovations: (1) Selective Canny Control, which
masks the structural guidance of Canny ControlNet in user-specified editable
regions while strictly preserving details of the source images in unedited
areas via inversion-phase ControlNet information retention. This enables
precise, text-driven edits without compromising contextual integrity. (2)
Dual-Prompt Guidance, which combines local prompts for object-specific edits
with a global target prompt to maintain coherent scene interactions. On
real-world image editing tasks (addition, replacement, removal), CannyEdit
outperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent
improvement in the balance of text adherence and context fidelity. In terms of
editing seamlessness, user studies reveal only 49.2 percent of general users
and 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited
when paired with real images without edits, versus 76.08 to 89.09 percent for
competitor methods.

</details>


### [62] [SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work](https://arxiv.org/abs/2508.06951)
*Harry Walsh,Ed Fish,Ozge Mercanoglu Sincan,Mohamed Ilyes Lakhal,Richard Bowden,Neil Fox,Bencie Woll,Kepeng Wu,Zecheng Li,Weichao Zhao,Haodong Wang,Wengang Zhou,Houqiang Li,Shengeng Tang,Jiayi He,Xu Wang,Ruobei Zhang,Yaxiong Wang,Lechao Cheng,Meryem Tasyurek,Tugce Kiziltepe,Hacer Yalim Keles*

Main category: cs.CV

TL;DR: 该论文介绍了首个手语生成挑战赛，旨在通过标准化评估指标比较不同系统，并发布了高质量骨架提取关键点作为基线。


<details>
  <summary>Details</summary>
Motivation: 解决手语生成领域缺乏标准化评估指标的问题，促进系统间的公平比较。

Method: 组织挑战赛，使用RWTH-PHOENIX-Weather-2014T数据集和自定义测试集，评估文本到姿势（T2P）翻译架构。

Result: 33名参与者提交231个解决方案，最佳团队BLEU-1得分31.40，DTW-MJE为0.0574。

Conclusion: 挑战赛成功推动了标准化评估，为未来研究提供了基线工具。

Abstract: Sign Language Production (SLP) is the task of generating sign language video
from spoken language inputs. The field has seen a range of innovations over the
last few years, with the introduction of deep learning-based approaches
providing significant improvements in the realism and naturalness of generated
outputs. However, the lack of standardized evaluation metrics for SLP
approaches hampers meaningful comparisons across different systems. To address
this, we introduce the first Sign Language Production Challenge, held as part
of the third SLRTP Workshop at CVPR 2025. The competition's aims are to
evaluate architectures that translate from spoken language sentences to a
sequence of skeleton poses, known as Text-to-Pose (T2P) translation, over a
range of metrics. For our evaluation data, we use the
RWTH-PHOENIX-Weather-2014T dataset, a German Sign Language - Deutsche
Gebardensprache (DGS) weather broadcast dataset. In addition, we curate a
custom hidden test set from a similar domain of discourse. This paper presents
the challenge design and the winning methodologies. The challenge attracted 33
participants who submitted 231 solutions, with the top-performing team
achieving BLEU-1 scores of 31.40 and DTW-MJE of 0.0574. The winning approach
utilized a retrieval-based framework and a pre-trained language model. As part
of the workshop, we release a standardized evaluation network, including
high-quality skeleton extraction-based keypoints establishing a consistent
baseline for the SLP field, which will enable future researchers to compare
their work against a broader range of methods.

</details>


### [63] [Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification](https://arxiv.org/abs/2508.06959)
*Qin Xu,Lili Zhu,Xiaoxia Cheng,Bo Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为SCOPE的新方法，通过自适应增强空间域中的细节和语义表示，解决了频率域方法在细粒度视觉分类中的局限性。


<details>
  <summary>Details</summary>
Motivation: 频率域方法基于固定基函数，缺乏对图像内容的适应性，无法动态调整特征提取。

Method: SCOPE包含两个模块：Subtle Detail Extractor（SDE）动态增强浅层特征中的细节，Salient Semantic Refiner（SSR）从高级特征中学习语义一致的细化特征。

Result: 在四个流行的细粒度图像分类基准上取得了新的最优性能。

Conclusion: SCOPE通过结合局部细节和全局语义，突破了频率域方法的限制，提升了分类性能。

Abstract: The crux of resolving fine-grained visual classification (FGVC) lies in
capturing discriminative and class-specific cues that correspond to subtle
visual characteristics. Recently, frequency decomposition/transform based
approaches have attracted considerable interests since its appearing
discriminative cue mining ability. However, the frequency-domain methods are
based on fixed basis functions, lacking adaptability to image content and
unable to dynamically adjust feature extraction according to the discriminative
requirements of different images. To address this, we propose a novel method
for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively
enhances the representational capability of low-level details and high-level
semantics in the spatial domain, breaking through the limitations of fixed
scales in the frequency domain and improving the flexibility of multi-scale
fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor
(SDE), which dynamically enhances subtle details such as edges and textures
from shallow features, and the Salient Semantic Refiner (SSR), which learns
semantically coherent and structure-aware refinement features from the
high-level features guided by the enhanced shallow features. The SDE and SSR
are cascaded stage-by-stage to progressively combine local details with global
semantics. Extensive experiments demonstrate that our method achieves new
state-of-the-art on four popular fine-grained image classification benchmarks.

</details>


### [64] [Adversarial Video Promotion Against Text-to-Video Retrieval](https://arxiv.org/abs/2508.06964)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Qian Li,Shuai Liu,Chao Shen*

Main category: cs.CV

TL;DR: 本文提出了首个针对文本到视频检索（T2VR）的攻击方法ViPro，旨在通过对抗性攻击提升视频排名，并提出了模态细化（MoRe）方法以提高黑盒迁移性。实验表明ViPro在多种场景下显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有T2VR攻击主要关注降低视频排名，而提升视频排名的攻击未被充分研究，这种攻击可能带来更大的经济利益和（错误）信息传播影响。

Method: 提出ViPro攻击方法，通过对抗性攻击提升视频排名；引入MoRe方法，通过细粒度模态交互增强黑盒迁移性。

Result: ViPro在白盒、灰盒和黑盒设置下平均分别超过基线方法30%、10%和4%。实验覆盖多种场景、模型和数据集。

Conclusion: ViPro揭示了T2VR的潜在漏洞，提供了攻击的上下界分析，并为防御提供了参考。代码将公开。

Abstract: Thanks to the development of cross-modal models, text-to-video retrieval
(T2VR) is advancing rapidly, but its robustness remains largely unexamined.
Existing attacks against T2VR are designed to push videos away from queries,
i.e., suppressing the ranks of videos, while the attacks that pull videos
towards selected queries, i.e., promoting the ranks of videos, remain largely
unexplored. These attacks can be more impactful as attackers may gain more
views/clicks for financial benefits and widespread (mis)information. To this
end, we pioneer the first attack against T2VR to promote videos adversarially,
dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement
(MoRe) to capture the finer-grained, intricate interaction between visual and
textual modalities to enhance black-box transferability. Comprehensive
experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing
datasets with over 10k videos, evaluated under 3 scenarios. All experiments are
conducted in a multi-target setting to reflect realistic scenarios where
attackers seek to promote the video regarding multiple queries simultaneously.
We also evaluated our attacks for defences and imperceptibility. Overall, ViPro
surpasses other baselines by over $30/10/4\%$ for white/grey/black-box settings
on average. Our work highlights an overlooked vulnerability, provides a
qualitative analysis on the upper/lower bound of our attacks, and offers
insights into potential counterplays. Code will be publicly available at
https://github.com/michaeltian108/ViPro.

</details>


### [65] [WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering](https://arxiv.org/abs/2508.06982)
*Yixin Zhu,Zuoliang Zhu,Miloš Hašan,Jian Yang,Jin Xie,Beibei Wang*

Main category: cs.CV

TL;DR: WeatherDiffusion是一个基于扩散模型的框架，用于自动驾驶场景中的正向和逆向渲染，支持天气和光照编辑，并通过提出的MAA机制提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 复杂天气和光照条件对自动驾驶场景的理解和重建提出了挑战，现有扩散模型难以控制且缺乏鲁棒性。

Method: 提出WeatherDiffusion框架，利用文本引导的预测本征图进行可控编辑，并引入MAA机制优化逆向渲染。同时构建了两个数据集（WeatherSynthetic和WeatherReal）。

Result: 实验表明WeatherDiffusion在多个基准测试中优于现有方法，并在下游任务（如目标检测和图像分割）中显著提升了鲁棒性。

Conclusion: WeatherDiffusion为自动驾驶场景中的渲染和编辑提供了高效且可控的解决方案，具有实际应用价值。

Abstract: Forward and inverse rendering have emerged as key techniques for enabling
understanding and reconstruction in the context of autonomous driving (AD).
However, complex weather and illumination pose great challenges to this task.
The emergence of large diffusion models has shown promise in achieving
reasonable results through learning from 2D priors, but these models are
difficult to control and lack robustness. In this paper, we introduce
WeatherDiffusion, a diffusion-based framework for forward and inverse rendering
on AD scenes with various weather and lighting conditions. Our method enables
authentic estimation of material properties, scene geometry, and lighting, and
further supports controllable weather and illumination editing through the use
of predicted intrinsic maps guided by text descriptions. We observe that
different intrinsic maps should correspond to different regions of the original
image. Based on this observation, we propose Intrinsic map-aware attention
(MAA) to enable high-quality inverse rendering. Additionally, we introduce a
synthetic dataset (\ie WeatherSynthetic) and a real-world dataset (\ie
WeatherReal) for forward and inverse rendering on AD scenes with diverse
weather and lighting. Extensive experiments show that our WeatherDiffusion
outperforms state-of-the-art methods on several benchmarks. Moreover, our
method demonstrates significant value in downstream tasks for AD, enhancing the
robustness of object detection and image segmentation in challenging weather
scenarios.

</details>


### [66] [TADoc: Robust Time-Aware Document Image Dewarping](https://arxiv.org/abs/2508.06988)
*Fangmin Zhao,Weichao Zeng,Zhenhang Li,Dongbao Yang,Yu Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种动态建模文档图像去扭曲任务的方法，并设计了一个轻量级框架TADoc，同时引入新评价指标DLS。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，文档图像去扭曲是一个渐进过程，而非一步完成，现有方法难以应对复杂结构和高度变形。

Method: 将任务重新建模为动态过程，设计TADoc框架，并提出DLS评价指标。

Result: 实验表明，模型在多种文档类型和变形程度下表现优越。

Conclusion: 动态建模和TADoc框架显著提升了文档去扭曲的效果和鲁棒性。

Abstract: Flattening curved, wrinkled, and rotated document images captured by portable
photographing devices, termed document image dewarping, has become an
increasingly important task with the rise of digital economy and online
working. Although many methods have been proposed recently, they often struggle
to achieve satisfactory results when confronted with intricate document
structures and higher degrees of deformation in real-world scenarios. Our main
insight is that, unlike other document restoration tasks (e.g., deblurring),
dewarping in real physical scenes is a progressive motion rather than a
one-step transformation. Based on this, we have undertaken two key initiatives.
Firstly, we reformulate this task, modeling it for the first time as a dynamic
process that encompasses a series of intermediate states. Secondly, we design a
lightweight framework called TADoc (Time-Aware Document Dewarping Network) to
address the geometric distortion of document images. In addition, due to the
inadequacy of OCR metrics for document images containing sparse text, the
comprehensiveness of evaluation is insufficient. To address this shortcoming,
we propose a new metric -- DLS (Document Layout Similarity) -- to evaluate the
effectiveness of document dewarping in downstream tasks. Extensive experiments
and in-depth evaluations have been conducted and the results indicate that our
model possesses strong robustness, achieving superiority on several benchmarks
with different document types and degrees of distortion.

</details>


### [67] [ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting](https://arxiv.org/abs/2508.07089)
*Sandro Papais,Letian Wang,Brian Cheong,Steven L. Waslander*

Main category: cs.CV

TL;DR: ForeSight是一个用于自动驾驶车辆3D感知的联合检测与预测框架，通过多任务流式学习和双向学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法将检测与预测分开处理，无法充分利用时序信息，ForeSight旨在解决这一问题。

Method: 采用多任务流式学习和双向学习，结合检测与预测的查询记忆，通过预测感知检测变换器和流式预测变换器提升性能。

Result: 在nuScenes数据集上，EPA达到54.9%，优于之前方法9.3%，并在多视图检测与预测模型中表现最佳。

Conclusion: ForeSight通过联合检测与预测，显著提升了自动驾驶车辆的3D感知能力。

Abstract: We introduce ForeSight, a novel joint detection and forecasting framework for
vision-based 3D perception in autonomous vehicles. Traditional approaches treat
detection and forecasting as separate sequential tasks, limiting their ability
to leverage temporal cues. ForeSight addresses this limitation with a
multi-task streaming and bidirectional learning approach, allowing detection
and forecasting to share query memory and propagate information seamlessly. The
forecast-aware detection transformer enhances spatial reasoning by integrating
trajectory predictions from a multiple hypothesis forecast memory queue, while
the streaming forecast transformer improves temporal consistency using past
forecasts and refined detections. Unlike tracking-based methods, ForeSight
eliminates the need for explicit object association, reducing error propagation
with a tracking-free model that efficiently scales across multi-frame
sequences. Experiments on the nuScenes dataset show that ForeSight achieves
state-of-the-art performance, achieving an EPA of 54.9%, surpassing previous
methods by 9.3%, while also attaining the best mAP and minADE among multi-view
detection and forecasting models.

</details>


### [68] [OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware](https://arxiv.org/abs/2508.06993)
*Nick Lemke,John Kalkhof,Niklas Babendererde,Anirban Mukhopadhyay*

Main category: cs.CV

TL;DR: OctreeNCA是一种基于八叉树数据结构的轻量级神经细胞自动机模型，用于高效分割高分辨率医学图像和视频，显著减少VRAM消耗并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需要处理大尺寸输入（如MRI、病理切片或手术视频），传统方法（如UNet或Vision Transformers）因VRAM消耗大而无法一次性处理全局信息，导致分割效果和速度受限。

Method: 通过八叉树数据结构扩展神经细胞自动机（NCA）的邻域定义，实现全局知识的高效传递，并利用CUDA优化实现降低VRAM需求和加速推理。

Result: OctreeNCA在高分辨率图像和视频分割中占用比UNet少90%的VRAM，并能一次性处理184兆像素病理切片或1分钟手术视频。

Conclusion: OctreeNCA提供了一种高效且资源友好的解决方案，适用于大尺寸医学图像和视频的实时分割任务。

Abstract: Medical applications demand segmentation of large inputs, like prostate MRIs,
pathology slices, or videos of surgery. These inputs should ideally be inferred
at once to provide the model with proper spatial or temporal context. When
segmenting large inputs, the VRAM consumption of the GPU becomes the
bottleneck. Architectures like UNets or Vision Transformers scale very poorly
in VRAM consumption, resulting in patch- or frame-wise approaches that
compromise global consistency and inference speed. The lightweight Neural
Cellular Automaton (NCA) is a bio-inspired model that is by construction
size-invariant. However, due to its local-only communication rules, it lacks
global knowledge. We propose OctreeNCA by generalizing the neighborhood
definition using an octree data structure. Our generalized neighborhood
definition enables the efficient traversal of global knowledge. Since deep
learning frameworks are mainly developed for large multi-layer networks, their
implementation does not fully leverage the advantages of NCAs. We implement an
NCA inference function in CUDA that further reduces VRAM demands and increases
inference speed. Our OctreeNCA segments high-resolution images and videos
quickly while occupying 90% less VRAM than a UNet during evaluation. This
allows us to segment 184 Megapixel pathology slices or 1-minute surgical videos
at once.

</details>


### [69] [S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision](https://arxiv.org/abs/2508.06995)
*Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: 提出了一种快速伪掩码算法UniAP和自监督通用分割模型S2-UniSeg，解决了现有方法的多阶段训练和耗时问题，并在多个基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督图像分割模型的多阶段训练和耗时伪掩码生成过程难以扩展且优化不连续。

Method: 提出快速伪掩码算法UniAP和自监督模型S2-UniSeg，结合QuerySD任务进行连续预训练。

Result: 在多个基准测试中显著优于现有方法，如COCO上AP+6.9，UVO上AR+11.1。

Conclusion: S2-UniSeg通过高效伪掩码生成和连续训练，显著提升了自监督分割的性能和可扩展性。

Abstract: Recent self-supervised image segmentation models have achieved promising
performance on semantic segmentation and class-agnostic instance segmentation.
However, their pretraining schedule is multi-stage, requiring a time-consuming
pseudo-masks generation process between each training epoch. This
time-consuming offline process not only makes it difficult to scale with
training dataset size, but also leads to sub-optimal solutions due to its
discontinuous optimization routine. To solve these, we first present a novel
pseudo-mask algorithm, Fast Universal Agglomerative Pooling (UniAP). Each layer
of UniAP can identify groups of similar nodes in parallel, allowing to generate
both semantic-level and instance-level and multi-granular pseudo-masks within
ens of milliseconds for one image. Based on the fast UniAP, we propose the
Scalable Self-Supervised Universal Segmentation (S2-UniSeg), which employs a
student and a momentum teacher for continuous pretraining. A novel
segmentation-oriented pretext task, Query-wise Self-Distillation (QuerySD), is
proposed to pretrain S2-UniSeg to learn the local-to-global correspondences.
Under the same setting, S2-UniSeg outperforms the SOTA UnSAM model, achieving
notable improvements of AP+6.9 on COCO, AR+11.1 on UVO, PixelAcc+4.5 on
COCOStuff-27, RQ+8.0 on Cityscapes. After scaling up to a larger 2M-image
subset of SA-1B, S2-UniSeg further achieves performance gains on all four
benchmarks. Our code and pretrained models are available at
https://github.com/bio-mlhui/S2-UniSeg

</details>


### [70] [AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning](https://arxiv.org/abs/2508.07626)
*Dejie Yang,Zijing Zhao,Yang Liu*

Main category: cs.CV

TL;DR: 论文提出AR-VRM方法，通过模仿人类手部关键点动作，利用大规模人类动作视频数据提升机器人视觉操作能力，在数据稀缺场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在机器人数据不足时泛化能力有限，需利用人类动作视频数据提升机器人操作能力。

Method: 提出关键点视觉语言模型预训练方案，通过类比推理（AR）将人类手部关键点映射到机器人组件。

Result: 在CALVIN基准测试和真实实验中表现领先，尤其在少样本场景下显著优于现有方法。

Conclusion: 通过显式模仿人类动作，AR-VRM在数据稀缺时仍能高效提升机器人操作能力。

Abstract: Visual Robot Manipulation (VRM) aims to enable a robot to follow natural
language instructions based on robot states and visual observations, and
therefore requires costly multi-modal data. To compensate for the deficiency of
robot data, existing approaches have employed vision-language pretraining with
large-scale data. However, they either utilize web data that differs from
robotic tasks, or train the model in an implicit way (e.g., predicting future
frames at the pixel level), thus showing limited generalization ability under
insufficient robot data. In this paper, we propose to learn from large-scale
human action video datasets in an explicit way (i.e., imitating human actions
from hand keypoints), introducing Visual Robot Manipulation with Analogical
Reasoning (AR-VRM). To acquire action knowledge explicitly from human action
videos, we propose a keypoint Vision-Language Model (VLM) pretraining scheme,
enabling the VLM to learn human action knowledge and directly predict human
hand keypoints. During fine-tuning on robot data, to facilitate the robotic arm
in imitating the action patterns of human motions, we first retrieve human
action videos that perform similar manipulation tasks and have similar
historical observations , and then learn the Analogical Reasoning (AR) map
between human hand keypoints and robot components. Taking advantage of focusing
on action keypoints instead of irrelevant visual cues, our method achieves
leading performance on the CALVIN benchmark {and real-world experiments}. In
few-shot scenarios, our AR-VRM outperforms previous methods by large margins ,
underscoring the effectiveness of explicitly imitating human actions under data
scarcity.

</details>


### [71] [Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction](https://arxiv.org/abs/2508.07701)
*Bo Jia,Yanan Guo,Ying Chang,Benkui Zhang,Ying Xie,Kangning Du,Lin Cao*

Main category: cs.CV

TL;DR: 提出了一种多视角法线和距离引导的高斯泼溅方法，解决了3D高斯泼溅在多视角场景中的几何偏差问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在单视角投影中表现良好，但在多视角切换时可能出现几何偏差，需解决多视角场景的距离和全局匹配问题。

Method: 设计了多视角法线和距离引导的高斯泼溅方法，通过约束邻近深度图和对齐3D法线实现几何深度统一和高精度重建。

Result: 实验结果表明，该方法在定量和定性评估中均优于基线，显著提升了3D高斯泼溅的表面重建能力。

Conclusion: 该方法有效解决了多视角几何偏差问题，提升了3D高斯泼溅的重建精度和一致性。

Abstract: 3D Gaussian Splatting (3DGS) achieves remarkable results in the field of
surface reconstruction. However, when Gaussian normal vectors are aligned
within the single-view projection plane, while the geometry appears reasonable
in the current view, biases may emerge upon switching to nearby views. To
address the distance and global matching challenges in multi-view scenes, we
design multi-view normal and distance-guided Gaussian splatting. This method
achieves geometric depth unification and high-accuracy reconstruction by
constraining nearby depth maps and aligning 3D normals. Specifically, for the
reconstruction of small indoor and outdoor scenes, we propose a multi-view
distance reprojection regularization module that achieves multi-view Gaussian
alignment by computing the distance loss between two nearby views and the same
Gaussian surface. Additionally, we develop a multi-view normal enhancement
module, which ensures consistency across views by matching the normals of pixel
points in nearby views and calculating the loss. Extensive experimental results
demonstrate that our method outperforms the baseline in both quantitative and
qualitative evaluations, significantly enhancing the surface reconstruction
capability of 3DGS.

</details>


### [72] [TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders](https://arxiv.org/abs/2508.07020)
*Tanjim Bin Faruk,Abdul Matin,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: TerraMAE是一种专为高光谱图像（HSI）设计的新型自监督编码框架，通过自适应通道分组和增强的重建损失函数，显著提升了空间-光谱信息的表示能力。


<details>
  <summary>Details</summary>
Motivation: 高光谱卫星图像具有200+波段，现有自监督方法难以有效利用其复杂的空间-光谱相关性。

Method: 提出TerraMAE框架，包括基于统计反射特性的自适应通道分组策略和结合空间-光谱质量指标的增强重建损失函数。

Result: TerraMAE在高保真图像重建中表现出色，并在作物识别、土地覆盖分类和土壤质地预测等下游任务中验证了其有效性。

Conclusion: TerraMAE为高光谱图像分析提供了高效的自监督学习解决方案，显著提升了空间-光谱信息的利用效率。

Abstract: Hyperspectral satellite imagery offers sub-30 m views of Earth in hundreds of
contiguous spectral bands, enabling fine-grained mapping of soils, crops, and
land cover. While self-supervised Masked Autoencoders excel on RGB and low-band
multispectral data, they struggle to exploit the intricate spatial-spectral
correlations in 200+ band hyperspectral images. We introduce TerraMAE, a novel
HSI encoding framework specifically designed to learn highly representative
spatial-spectral embeddings for diverse geospatial analyses. TerraMAE features
an adaptive channel grouping strategy, based on statistical reflectance
properties to capture spectral similarities, and an enhanced reconstruction
loss function that incorporates spatial and spectral quality metrics. We
demonstrate TerraMAE's effectiveness through superior spatial-spectral
information preservation in high-fidelity image reconstruction. Furthermore, we
validate its practical utility and the quality of its learned representations
through strong performance on three key downstream geospatial tasks: crop
identification, land cover classification, and soil texture prediction.

</details>


### [73] [DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents](https://arxiv.org/abs/2508.07021)
*Kun Qian,Wenjie Li,Tianyu Sun,Wenhong Wang,Wenhan Luo*

Main category: cs.CV

TL;DR: DocRefine是一个基于多智能体系统的框架，用于科学PDF文档的智能理解、内容优化和自动摘要，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长需要高效准确的文档处理工具，传统方法和直接应用大型语言模型在复杂布局和多模态内容处理上存在不足。

Method: DocRefine采用六种专业协作智能体的多智能体系统，结合先进视觉语言模型（如GPT-4o），实现闭环反馈架构。

Result: 在DocEditBench数据集上，DocRefine在语义一致性（86.7%）、布局保真度（93.9%）和指令遵循率（85.0%）上表现优异。

Conclusion: DocRefine在复杂多模态文档编辑中表现出色，是科学文档自动化处理的重要进展。

Abstract: The exponential growth of scientific literature in PDF format necessitates
advanced tools for efficient and accurate document understanding,
summarization, and content optimization. Traditional methods fall short in
handling complex layouts and multimodal content, while direct application of
Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) lacks
precision and control for intricate editing tasks. This paper introduces
DocRefine, an innovative framework designed for intelligent understanding,
content refinement, and automated summarization of scientific PDF documents,
driven by natural language instructions. DocRefine leverages the power of
advanced LVLMs (e.g., GPT-4o) by orchestrating a sophisticated multi-agent
system comprising six specialized and collaborative agents: Layout & Structure
Analysis, Multimodal Content Understanding, Instruction Decomposition, Content
Refinement, Summarization & Generation, and Fidelity & Consistency
Verification. This closed-loop feedback architecture ensures high semantic
accuracy and visual fidelity. Evaluated on the comprehensive DocEditBench
dataset, DocRefine consistently outperforms state-of-the-art baselines across
various tasks, achieving overall scores of 86.7% for Semantic Consistency Score
(SCS), 93.9% for Layout Fidelity Index (LFI), and 85.0% for Instruction
Adherence Rate (IAR). These results demonstrate DocRefine's superior capability
in handling complex multimodal document editing, preserving semantic integrity,
and maintaining visual consistency, marking a significant advancement in
automated scientific document processing.

</details>


### [74] [MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering](https://arxiv.org/abs/2508.07023)
*Jingwei Peng,Jiehao Chen,Mateo Alejandro Rojas,Meilin Zhang*

Main category: cs.CV

TL;DR: MV-CoRe模型通过深度融合多模态视觉和语言信息，显著提升了复杂视觉问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在复杂视觉问答任务中表现受限，主要依赖高层全局特征，缺乏细粒度语义信息。

Method: MV-CoRe整合了预训练视觉和语言模型的全局嵌入与细粒度语义视觉特征（如物体检测和场景图表示），并通过多模态融合Transformer实现跨模态注意力。

Result: 在GQA、A-OKVQA和OKVQA等基准测试中，MV-CoRe表现优于现有模型，GQA准确率达77.5%。

Conclusion: MV-CoRe通过深度融合多模态特征，显著提升了复杂视觉问答任务的性能，验证了其在深度视觉和概念理解方面的优势。

Abstract: Complex Visual Question Answering (Complex VQA) tasks, which demand
sophisticated multi-modal reasoning and external knowledge integration, present
significant challenges for existing large vision-language models (LVLMs) often
limited by their reliance on high-level global features. To address this, we
propose MV-CoRe (Multimodal Visual-Conceptual Reasoning), a novel model
designed to enhance Complex VQA performance through the deep fusion of diverse
visual and linguistic information. MV-CoRe meticulously integrates global
embeddings from pre-trained Vision Large Models (VLMs) and Language Large
Models (LLMs) with fine-grained semantic-aware visual features, including
object detection characteristics and scene graph representations. An innovative
Multimodal Fusion Transformer then processes and deeply integrates these
diverse feature sets, enabling rich cross-modal attention and facilitating
complex reasoning. We evaluate MV-CoRe on challenging Complex VQA benchmarks,
including GQA, A-OKVQA, and OKVQA, after training on VQAv2. Our experimental
results demonstrate that MV-CoRe consistently outperforms established LVLM
baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies
confirm the critical contribution of both object and scene graph features, and
human evaluations further validate MV-CoRe's superior factual correctness and
reasoning depth, underscoring its robust capabilities for deep visual and
conceptual understanding.

</details>


### [75] [Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation](https://arxiv.org/abs/2508.07028)
*Juntong Fan,Shuyi Fan,Debesh Jha,Changsheng Fang,Tieyong Zeng,Hengyong Yu,Dayang Wang*

Main category: cs.CV

TL;DR: FOCUS-Med提出了一种结合空间和结构图的注意力上下文感知方法，用于内窥镜图像中息肉的分割，通过双图卷积网络和自注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 内窥镜图像中息肉分割因低对比度、高光和模糊边界而具有挑战性，需要更精确的方法以辅助早期结直肠癌检测。

Method: FOCUS-Med结合双图卷积网络（Dual-GCN）捕捉空间和拓扑结构依赖，并利用自注意力机制增强全局上下文整合，同时采用多尺度融合策略。

Result: 在公开基准测试中，FOCUS-Med在五项关键指标上达到最先进性能，展示了其临床潜力。

Conclusion: FOCUS-Med通过创新的图表示和注意力机制，显著提升了息肉分割的准确性和边界保留能力，为AI辅助结肠镜检查提供了有效工具。

Abstract: Accurate endoscopic image segmentation on the polyps is critical for early
colorectal cancer detection. However, this task remains challenging due to low
contrast with surrounding mucosa, specular highlights, and indistinct
boundaries. To address these challenges, we propose FOCUS-Med, which stands for
Fusion of spatial and structural graph with attentional context-aware polyp
segmentation in endoscopic medical imaging. FOCUS-Med integrates a Dual Graph
Convolutional Network (Dual-GCN) module to capture contextual spatial and
topological structural dependencies. This graph-based representation enables
the model to better distinguish polyps from background tissues by leveraging
topological cues and spatial connectivity, which are often obscured in raw
image intensities. It enhances the model's ability to preserve boundaries and
delineate complex shapes typical of polyps. In addition, a location-fused
stand-alone self-attention is employed to strengthen global context
integration. To bridge the semantic gap between encoder-decoder layers, we
incorporate a trainable weighted fast normalized fusion strategy for efficient
multi-scale aggregation. Notably, we are the first to introduce the use of a
Large Language Model (LLM) to provide detailed qualitative evaluations of
segmentation quality. Extensive experiments on public benchmarks demonstrate
that FOCUS-Med achieves state-of-the-art performance across five key metrics,
underscoring its effectiveness and clinical potential for AI-assisted
colonoscopy.

</details>


### [76] [TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree](https://arxiv.org/abs/2508.07083)
*Yueyu Hu,Ran Gong,Tingyu Fan,Yao Wang*

Main category: cs.CV

TL;DR: 提出了一种名为Textured Surfel Octree (TeSO)的新型3D表示方法，通过结合八叉树结构和纹理贴图，解决了现有3D表示在渲染质量、表面定义和压缩性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有3D表示（如点云、网格和3D高斯）在渲染质量、表面定义和压缩性方面存在不足，需要一种更高效的3D表示方法。

Method: TeSO将3D场景表示为八叉树组织的立方体边界曲面元（surfel），每个曲面元关联一个纹理贴图，并通过八叉树结构减少所需基元数量。同时提出了一种高效的几何和纹理压缩方案。

Result: TeSO结合压缩方案在低比特率下实现了比点云和3D高斯基线更高的渲染质量。

Conclusion: TeSO是一种高效的3D表示方法，适用于3D流媒体和AR/VR应用，解决了现有技术的局限性。

Abstract: 3D visual content streaming is a key technology for emerging 3D telepresence
and AR/VR applications. One fundamental element underlying the technology is a
versatile 3D representation that is capable of producing high-quality renders
and can be efficiently compressed at the same time. Existing 3D representations
like point clouds, meshes and 3D Gaussians each have limitations in terms of
rendering quality, surface definition, and compressibility. In this paper, we
present the Textured Surfel Octree (TeSO), a novel 3D representation that is
built from point clouds but addresses the aforementioned limitations. It
represents a 3D scene as cube-bounded surfels organized on an octree, where
each surfel is further associated with a texture patch. By approximating a
smooth surface with a large surfel at a coarser level of the octree, it reduces
the number of primitives required to represent the 3D scene, and yet retains
the high-frequency texture details through the texture map attached to each
surfel. We further propose a compression scheme to encode the geometry and
texture efficiently, leveraging the octree structure. The proposed textured
surfel octree combined with the compression scheme achieves higher rendering
quality at lower bit-rates compared to multiple point cloud and 3D
Gaussian-based baselines.

</details>


### [77] [Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration](https://arxiv.org/abs/2508.07092)
*Yue Hu,Juntong Peng,Yunqiao Yang,Siheng Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为HyComm的通信高效LiDAR协同3D检测系统，通过自适应整合紧凑的感知输出和丰富的原始观测数据，优化了检测性能与通信带宽的权衡。


<details>
  <summary>Details</summary>
Motivation: 协同3D检测通过信息交换提升性能，但面临检测性能与通信带宽的权衡问题。

Method: 提出混合协作方法，自适应整合两种通信消息（感知输出和原始观测），并优先处理关键数据。

Result: HyComm在DAIR-V2X和OPV2V数据集上表现优异，通信量降低2006倍以上，AP50性能优于Where2comm。

Conclusion: HyComm通过自适应消息选择和标准化数据格式，实现了高效协同检测，适用于不同代理配置。

Abstract: Collaborative 3D detection can substantially boost detection performance by
allowing agents to exchange complementary information. It inherently results in
a fundamental trade-off between detection performance and communication
bandwidth. To tackle this bottleneck issue, we propose a novel hybrid
collaboration that adaptively integrates two types of communication messages:
perceptual outputs, which are compact, and raw observations, which offer richer
information. This approach focuses on two key aspects: i) integrating
complementary information from two message types and ii) prioritizing the most
critical data within each type. By adaptively selecting the most critical set
of messages, it ensures optimal perceptual information and adaptability,
effectively meeting the demands of diverse communication scenarios.Building on
this hybrid collaboration, we present \texttt{HyComm}, a
communication-efficient LiDAR-based collaborative 3D detection system.
\texttt{HyComm} boasts two main benefits: i) it facilitates adaptable
compression rates for messages, addressing various communication requirements,
and ii) it uses standardized data formats for messages. This ensures they are
independent of specific detection models, fostering adaptability across
different agent configurations. To evaluate HyComm, we conduct experiments on
both real-world and simulation datasets: DAIR-V2X and OPV2V. HyComm
consistently outperforms previous methods and achieves a superior
performance-bandwidth trade-off regardless of whether agents use the same or
varied detection models. It achieves a lower communication volume of more than
2,006$\times$ and still outperforms Where2comm on DAIR-V2X in terms of AP50.
The related code will be released.

</details>


### [78] [AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation](https://arxiv.org/abs/2508.07112)
*Nikolai Warner,Wenjin Zhang,Irfan Essa,Apaar Sadhwani*

Main category: cs.CV

TL;DR: AugLift通过增强2D关键点输入（加入置信度和深度估计），显著提升3D人体姿态估计的泛化性能，无需额外数据或传感器。


<details>
  <summary>Details</summary>
Motivation: 解决基于提升的3D姿态估计方法在新数据集和实际场景中泛化能力差的问题。

Method: 在标准2D关键点坐标基础上，稀疏地加入关键点检测置信度和深度估计，利用预训练模型计算这些信号。

Result: 在四个数据集上，跨数据集性能平均提升10.1%，同分布性能提升4.0%。

Conclusion: AugLift是一种模块化方法，能显著提升任何基于提升的姿态估计模型的泛化能力。

Abstract: Lifting-based methods for 3D Human Pose Estimation (HPE), which predict 3D
poses from detected 2D keypoints, often generalize poorly to new datasets and
real-world settings. To address this, we propose \emph{AugLift}, a simple yet
effective reformulation of the standard lifting pipeline that significantly
improves generalization performance without requiring additional data
collection or sensors. AugLift sparsely enriches the standard input -- the 2D
keypoint coordinates $(x, y)$ -- by augmenting it with a keypoint detection
confidence score $c$ and a corresponding depth estimate $d$. These additional
signals are computed from the image using off-the-shelf, pre-trained models
(e.g., for monocular depth estimation), thereby inheriting their strong
generalization capabilities. Importantly, AugLift serves as a modular add-on
and can be readily integrated into existing lifting architectures.
  Our extensive experiments across four datasets demonstrate that AugLift
boosts cross-dataset performance on unseen datasets by an average of $10.1\%$,
while also improving in-distribution performance by $4.0\%$. These gains are
consistent across various lifting architectures, highlighting the robustness of
our method. Our analysis suggests that these sparse, keypoint-aligned cues
provide robust frame-level context, offering a practical way to significantly
improve the generalization of any lifting-based pose estimation model. Code
will be made publicly available.

</details>


### [79] [Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays](https://arxiv.org/abs/2508.07128)
*Gregory Schuit,Denis Parra,Cecilia Besa*

Main category: cs.CV

TL;DR: 生成图像模型在医学影像中潜力巨大，但合成图像的质量和临床实用性仍需验证。本研究评估了GAN和扩散模型在合成胸部X光片中的表现，发现两者各有优劣，需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像数据稀缺问题，尤其是低发病率异常，以提升AI诊断和分割工具的性能。

Method: 使用GAN和扩散模型合成胸部X光片，基于MIMIC-CXR数据集进行真实与合成图像的对比研究，邀请三位放射科医生参与评估。

Result: 扩散模型生成的图像更真实，但GAN在某些条件下（如无ECS）表现更准确。研究还揭示了放射科医生识别合成图像的视觉线索。

Conclusion: GAN和扩散模型各有优势，需进一步优化以确保其能可靠地用于AI诊断系统的训练数据增强。

Abstract: Generative image models have achieved remarkable progress in both natural and
medical imaging. In the medical context, these techniques offer a potential
solution to data scarcity-especially for low-prevalence anomalies that impair
the performance of AI-driven diagnostic and segmentation tools. However,
questions remain regarding the fidelity and clinical utility of synthetic
images, since poor generation quality can undermine model generalizability and
trust. In this study, we evaluate the effectiveness of state-of-the-art
generative models-Generative Adversarial Networks (GANs) and Diffusion Models
(DMs)-for synthesizing chest X-rays conditioned on four abnormalities:
Atelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged
Cardiac Silhouette (ECS). Using a benchmark composed of real images from the
MIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a
reader study with three radiologists of varied experience. Participants were
asked to distinguish real from synthetic images and assess the consistency
between visual features and the target abnormality. Our results show that while
DMs generate more visually realistic images overall, GANs can report better
accuracy for specific conditions, such as absence of ECS. We further identify
visual cues radiologists use to detect synthetic images, offering insights into
the perceptual gaps in current models. These findings underscore the
complementary strengths of GANs and DMs and point to the need for further
refinement to ensure generative models can reliably augment training datasets
for AI diagnostic systems.

</details>


### [80] [CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance](https://arxiv.org/abs/2508.07140)
*Yingtie Lei,Fanghai Yi,Yihang Dong,Weihuang Liu,Xiaofeng Zhang,Zimeng Li,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

TL;DR: 论文提出CMAMRNet，一种基于上下文掩码感知的壁画修复网络，通过多尺度特征提取和全面掩码指导解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 壁画作为文化遗产易受环境和人为因素破坏，现有学习方法在修复时难以保持掩码一致性，导致修复质量不足。

Method: 提出CMAMRNet，包含掩码感知上/下采样器（MAUDS）和共特征聚合器（CFA），实现多尺度特征提取和掩码一致性。

Result: 在基准数据集上，CMAMRNet优于现有方法，有效保留壁画的结构完整性和艺术细节。

Conclusion: CMAMRNet通过掩码感知和多尺度特征提取，显著提升了壁画修复的质量和艺术真实性。

Abstract: Murals, as invaluable cultural artifacts, face continuous deterioration from
environmental factors and human activities. Digital restoration of murals faces
unique challenges due to their complex degradation patterns and the critical
need to preserve artistic authenticity. Existing learning-based methods
struggle with maintaining consistent mask guidance throughout their networks,
leading to insufficient focus on damaged regions and compromised restoration
quality. We propose CMAMRNet, a Contextual Mask-Aware Mural Restoration Network
that addresses these limitations through comprehensive mask guidance and
multi-scale feature extraction. Our framework introduces two key components:
(1) the Mask-Aware Up/Down-Sampler (MAUDS), which ensures consistent mask
sensitivity across resolution scales through dedicated channel-wise feature
selection and mask-guided feature fusion; and (2) the Co-Feature Aggregator
(CFA), operating at both the highest and lowest resolutions to extract
complementary features for capturing fine textures and global structures in
degraded regions. Experimental results on benchmark datasets demonstrate that
CMAMRNet outperforms state-of-the-art methods, effectively preserving both
structural integrity and artistic details in restored murals. The code is
available
at~\href{https://github.com/CXH-Research/CMAMRNet}{https://github.com/CXH-Research/CMAMRNet}.

</details>


### [81] [Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models](https://arxiv.org/abs/2508.07144)
*Xuanhan Wang,Huimin Deng,Ke Liu,Jun Wang,Lianli Gao,Jingkuan Song*

Main category: cs.CV

TL;DR: 论文提出了一种名为DPAL的蒸馏预训练框架，通过动态模式对齐学习，使轻量级HVM从大型HVM中学习典型视觉模式，从而提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决轻量级HVM因依赖大型架构和有限预训练数据而泛化能力不足的问题。

Method: 设计了动态模式解码器（D-PaDe）和三层次对齐目标，分别从全局、局部和实例关系层面缩小轻量级与大型HVM的泛化差距。

Result: 在15个数据集上验证了DPAL的有效性，轻量级模型（5M参数）表现接近大型HVM（84M/307M参数），并显著优于其他蒸馏方法。

Conclusion: DPAL通过动态模式对齐学习，成功提升了轻量级HVM的泛化能力，适用于多种人本视觉任务。

Abstract: Human-centric vision models (HVMs) have achieved remarkable generalization
due to large-scale pretraining on massive person images. However, their
dependence on large neural architectures and the restricted accessibility of
pretraining data significantly limits their practicality in real-world
applications. To address this limitation, we propose Dynamic Pattern Alignment
Learning (DPAL), a novel distillation-based pretraining framework that
efficiently trains lightweight HVMs to acquire strong generalization from large
HVMs. In particular, human-centric visual perception are highly dependent on
three typical visual patterns, including global identity pattern, local shape
pattern and multi-person interaction pattern. To achieve generalizable
lightweight HVMs, we firstly design a dynamic pattern decoder (D-PaDe), acting
as a dynamic Mixture of Expert (MoE) model. It incorporates three specialized
experts dedicated to adaptively extract typical visual patterns, conditioned on
both input image and pattern queries. And then, we present three levels of
alignment objectives, which aims to minimize generalization gap between
lightweight HVMs and large HVMs at global image level, local pixel level, and
instance relation level. With these two deliberate designs, the DPAL
effectively guides lightweight model to learn all typical human visual patterns
from large HVMs, which can generalize to various human-centric vision tasks.
Extensive experiments conducted on 15 challenging datasets demonstrate the
effectiveness of the DPAL. Remarkably, when employing PATH-B as the teacher,
DPAL-ViT/Ti (5M parameters) achieves surprising generalizability similar to
existing large HVMs such as PATH-B (84M) and Sapiens-L (307M), and outperforms
previous distillation-based pretraining methods including Proteus-ViT/Ti (5M)
and TinyMiM-ViT/Ti (5M) by a large margin.

</details>


### [82] [Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2508.07146)
*Yu Liu,Zhijie Liu,Xiao Ren,You-Fu Li,He Kong*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的行人轨迹预测框架，结合短期和长期意图建模，提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型缺乏对行人意图的显式语义建模，可能导致行为误解和预测精度下降。

Method: 使用残差极坐标表示建模短期意图，基于可学习的端点预测器建模长期意图，并引入自适应指导和残差噪声预测器优化扩散过程。

Result: 在ETH、UCY和SDD基准测试中表现优异，优于现有方法。

Conclusion: 结合意图建模的扩散框架能有效提升行人轨迹预测的准确性和鲁棒性。

Abstract: Predicting pedestrian motion trajectories is critical for the path planning
and motion control of autonomous vehicles. Recent diffusion-based models have
shown promising results in capturing the inherent stochasticity of pedestrian
behavior for trajectory prediction. However, the absence of explicit semantic
modelling of pedestrian intent in many diffusion-based methods may result in
misinterpreted behaviors and reduced prediction accuracy. To address the above
challenges, we propose a diffusion-based pedestrian trajectory prediction
framework that incorporates both short-term and long-term motion intentions.
Short-term intent is modelled using a residual polar representation, which
decouples direction and magnitude to capture fine-grained local motion
patterns. Long-term intent is estimated through a learnable, token-based
endpoint predictor that generates multiple candidate goals with associated
probabilities, enabling multimodal and context-aware intention modelling.
Furthermore, we enhance the diffusion process by incorporating adaptive
guidance and a residual noise predictor that dynamically refines denoising
accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and
SDD benchmarks, demonstrating competitive results against state-of-the-art
methods.

</details>


### [83] [SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.07149)
*Ruolin Yang,Da Li,Honggang Zhang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: 提出了一种名为SketchAnimator的草图动画模型，通过三个阶段（外观学习、运动学习和视频先验蒸馏）将静态草图转化为动态视频，保留草图外观并模仿参考视频的运动。


<details>
  <summary>Details</summary>
Motivation: 草图动画通常需要专业技能且耗时，对业余用户不友好，因此需要一种自动化方法简化这一过程。

Method: 分为三个阶段：1. 使用LoRA整合草图外观信息；2. 从参考视频学习运动动态；3. 利用SDS更新Bezier曲线参数以生成动态草图视频。

Result: 模型成功生成保留草图外观并模仿参考视频运动的动画，在单次运动定制任务中表现优于其他方法。

Conclusion: SketchAnimator为草图动画提供了一种高效且用户友好的解决方案，适用于创意表达。

Abstract: Sketching is a uniquely human tool for expressing ideas and creativity. The
animation of sketches infuses life into these static drawings, opening a new
dimension for designers. Animating sketches is a time-consuming process that
demands professional skills and extensive experience, often proving daunting
for amateurs. In this paper, we propose a novel sketch animation model
SketchAnimator, which enables adding creative motion to a given sketch, like "a
jumping car''. Namely, given an input sketch and a reference video, we divide
the sketch animation into three stages: Appearance Learning, Motion Learning
and Video Prior Distillation. In stages 1 and 2, we utilize LoRA to integrate
sketch appearance information and motion dynamics from the reference video into
the pre-trained T2V model. In the third stage, we utilize Score Distillation
Sampling (SDS) to update the parameters of the Bezier curves in each sketch
frame according to the acquired motion information. Consequently, our model
produces a sketch video that not only retains the original appearance of the
sketch but also mirrors the dynamic movements of the reference video. We
compare our method with alternative approaches and demonstrate that it
generates the desired sketch video under the challenge of one-shot motion
customization.

</details>


### [84] [CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion](https://arxiv.org/abs/2508.07162)
*Xiaotong Lin,Tianming Liang,Jian-Fang Hu,Kun-Yu Lin,Yulei Kang,Chunwei Tian,Jianhuang Lai,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoopDiff的解耦扩散框架，通过分离建模人和物体的运动，并利用接触点作为共享锚点，提升了3D人-物交互预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常忽略人和物体在运动模式上的差异，而统一建模两者动态。本文旨在通过解耦建模和接触点一致性约束，改进预测效果。

Method: CoopDiff采用两个分支分别建模人和物体的运动，并通过共享接触点实现一致性约束。此外，还引入人驱动的交互模块指导物体运动建模。

Result: 在BEHAVE和人-物交互数据集上的实验表明，CoopDiff优于现有方法。

Conclusion: 解耦建模和接触点一致性约束显著提升了人-物交互预测的准确性和一致性。

Abstract: 3D human-object interaction (HOI) anticipation aims to predict the future
motion of humans and their manipulated objects, conditioned on the historical
context. Generally, the articulated humans and rigid objects exhibit different
motion patterns, due to their distinct intrinsic physical properties. However,
this distinction is ignored by most of the existing works, which intend to
capture the dynamics of both humans and objects within a single prediction
model. In this work, we propose a novel contact-consistent decoupled diffusion
framework CoopDiff, which employs two distinct branches to decouple human and
object motion modeling, with the human-object contact points as shared anchors
to bridge the motion generation across branches. The human dynamics branch is
aimed to predict highly structured human motion, while the object dynamics
branch focuses on the object motion with rigid translations and rotations.
These two branches are bridged by a series of shared contact points with
consistency constraint for coherent human-object motion prediction. To further
enhance human-object consistency and prediction reliability, we propose a
human-driven interaction module to guide object motion modeling. Extensive
experiments on the BEHAVE and Human-object Interaction datasets demonstrate
that our CoopDiff outperforms state-of-the-art methods.

</details>


### [85] [Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection](https://arxiv.org/abs/2508.07170)
*Yunpeng Shi,Lei Chen,Xiaolu Shen,Yanju Guo*

Main category: cs.CV

TL;DR: 提出了一种轻量级多尺度特征提取层（LMF层），并构建了LMFNet网络，显著减少了参数数量，同时在显著目标检测任务中保持了竞争力。


<details>
  <summary>Details</summary>
Motivation: 解决轻量级网络中多尺度特征提取的效率和性能权衡问题。

Method: 采用深度可分离扩张卷积构建LMF层，并集成多个LMF层形成LMFNet。

Result: 在五个基准数据集上达到或接近最优性能，仅需0.81M参数，效率和精度均优于传统及轻量级模型。

Conclusion: LMFNet不仅解决了轻量级网络的多尺度学习问题，还展示了在图像处理任务中的广泛应用潜力。

Abstract: In the domain of computer vision, multi-scale feature extraction is vital for
tasks such as salient object detection. However, achieving this capability in
lightweight networks remains challenging due to the trade-off between
efficiency and performance. This paper proposes a novel lightweight multi-scale
feature extraction layer, termed the LMF layer, which employs depthwise
separable dilated convolutions in a fully connected structure. By integrating
multiple LMF layers, we develop LMFNet, a lightweight network tailored for
salient object detection. Our approach significantly reduces the number of
parameters while maintaining competitive performance. Here, we show that LMFNet
achieves state-of-the-art or comparable results on five benchmark datasets with
only 0.81M parameters, outperforming several traditional and lightweight models
in terms of both efficiency and accuracy. Our work not only addresses the
challenge of multi-scale learning in lightweight networks but also demonstrates
the potential for broader applications in image processing tasks. The related
code files are available at https://github.com/Shi-Yun-peng/LMFNet

</details>


### [86] [EventRR: Event Referential Reasoning for Referring Video Object Segmentation](https://arxiv.org/abs/2508.07171)
*Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: 论文提出EventRR框架，通过解耦视频对象分割为对象摘要和引用推理两部分，利用Referential Event Graph（REG）表达视频引用语义结构，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS方法忽视引用表达式的语义结构，而视频引用表达式还涉及事件属性和时间关系，传统方法难以处理。

Method: EventRR框架分为对象摘要和引用推理两部分：摘要阶段生成瓶颈令牌并聚合全局跨模态时间上下文；推理阶段构建REG图并通过TCRR逐步累积引用分数。

Result: 在四个基准数据集上，EventRR定量和定性优于现有方法。

Conclusion: EventRR通过结构化语义推理有效解决了视频引用对象分割的复杂性。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in
a video referred by an expression. Current RVOS methods view referring
expressions as unstructured sequences, neglecting their crucial semantic
structure essential for referent reasoning. Besides, in contrast to
image-referring expressions whose semantics focus only on object attributes and
object-object relations, video-referring expressions also encompass event
attributes and event-event temporal relations. This complexity challenges
traditional structured reasoning image approaches. In this paper, we propose
the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS
into object summarization part and referent reasoning part. The summarization
phase begins by summarizing each frame into a set of bottleneck tokens, which
are then efficiently aggregated in the video-level summarization step to
exchange the global cross-modal temporal context. For reasoning part, EventRR
extracts semantic eventful structure of a video-referring expression into
highly expressive Referential Event Graph (REG), which is a single-rooted
directed acyclic graph. Guided by topological traversal of REG, we propose
Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of
each temporal query from REG leaf nodes to root node. Each reasoning step can
be interpreted as a question-answer pair derived from the concept-role
relations in REG. Extensive experiments across four widely recognized benchmark
datasets, show that EventRR quantitatively and qualitatively outperforms
state-of-the-art RVOS methods. Code is available at
https://github.com/bio-mlhui/EventRR

</details>


### [87] [Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset](https://arxiv.org/abs/2508.07211)
*Junyi He,Liuling Chen,Hongyang Zhou,Zhang xiaoxing,Xiaobin Zhu,Shengxiang Yu,Jingyan Qin,Xu-Cheng Yin*

Main category: cs.CV

TL;DR: 提出了一种深度引导网络（DGN）用于图像修复，结合新的大规模高分辨率数据集，解决了现有方法忽视深度信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法常忽略深度信息，导致相似性匹配不佳、注意力分散或背景过度增强。

Method: DGN包含两个交互分支：深度估计分支提供结构引导，图像修复分支通过渐进窗口自注意力和稀疏非局部注意力完成任务。

Result: 实验表明，DGN在多个标准基准上达到最先进性能，并能泛化到未见过的植物图像。

Conclusion: 深度引导显著提升图像修复质量，同时修复分支的特征也有助于优化深度估计。

Abstract: Image restoration has seen substantial progress in recent years. However,
existing methods often neglect depth information, which hurts similarity
matching, results in attention distractions in shallow depth-of-field (DoF)
scenarios, and excessive enhancement of background content in deep DoF
settings. To overcome these limitations, we propose a novel Depth-Guided
Network (DGN) for image restoration, together with a novel large-scale
high-resolution dataset. Specifically, the network consists of two interactive
branches: a depth estimation branch that provides structural guidance, and an
image restoration branch that performs the core restoration task. In addition,
the image restoration branch exploits intra-object similarity through
progressive window-based self-attention and captures inter-object similarity
via sparse non-local attention. Through joint training, depth features
contribute to improved restoration quality, while the enhanced visual features
from the restoration branch in turn help refine depth estimation. Notably, we
also introduce a new dataset for training and evaluation, consisting of 9,205
high-resolution images from 403 plant species, with diverse depth and texture
variations. Extensive experiments show that our method achieves
state-of-the-art performance on several standard benchmarks and generalizes
well to unseen plant images, demonstrating its effectiveness and robustness.

</details>


### [88] [Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling](https://arxiv.org/abs/2508.07214)
*Hongyang Zhou,Xiaobin Zhu,Liuling Chen,Junyi He,Jingyan Qin,Xu-Cheng Yin,Zhang xiaoxing*

Main category: cs.CV

TL;DR: 提出了一种基于修正流的无监督真实世界超分辨率方法，通过新模块捕捉真实退化，提升现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界超分辨率面临复杂未知的退化分布，现有方法因域差距难以泛化。

Method: 提出修正流退化模块（RFDM）和傅里叶先导退化模块（FGDM），分别通过连续可逆建模和傅里叶相位信息捕捉真实退化。

Result: 实验表明，该方法显著提升了现有超分辨率方法在真实场景中的性能。

Conclusion: 该方法有效解决了真实世界超分辨率中的退化建模问题，具有实际应用价值。

Abstract: Unsupervised real-world super-resolution (SR) faces critical challenges due
to the complex, unknown degradation distributions in practical scenarios.
Existing methods struggle to generalize from synthetic low-resolution (LR) and
high-resolution (HR) image pairs to real-world data due to a significant domain
gap. In this paper, we propose an unsupervised real-world SR method based on
rectified flow to effectively capture and model real-world degradation,
synthesizing LR-HR training pairs with realistic degradation. Specifically,
given unpaired LR and HR images, we propose a novel Rectified Flow Degradation
Module (RFDM) that introduces degradation-transformed LR (DT-LR) images as
intermediaries. By modeling the degradation trajectory in a continuous and
invertible manner, RFDM better captures real-world degradation and enhances the
realism of generated LR images. Additionally, we propose a Fourier Prior Guided
Degradation Module (FGDM) that leverages structural information embedded in
Fourier phase components to ensure more precise modeling of real-world
degradation. Finally, the LR images are processed by both FGDM and RFDM,
producing final synthetic LR images with real-world degradation. The synthetic
LR images are paired with the given HR images to train the off-the-shelf SR
networks. Extensive experiments on real-world datasets demonstrate that our
method significantly enhances the performance of existing SR approaches in
real-world scenarios.

</details>


### [89] [Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization](https://arxiv.org/abs/2508.07216)
*Songlin Li,Zhiqing Guo,Yuanman Li,Zeyu Li,Yunfeng Diao,Gaobo Yang,Liejun Wang*

Main category: cs.CV

TL;DR: 提出了一种基于认知的多模态边界保持网络（CMB-Net），通过结合大语言模型（LLMs）和视觉特征，提升图像篡改定位（IML）的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有IML模型主要依赖视觉线索，忽略了内容特征的语义逻辑关系。篡改技术破坏了内容特征的内在联系，但留下了语义线索。

Method: CMB-Net利用LLMs分析篡改区域并生成提示文本，提出图像-文本中心模糊模块（ITCAM）和图像-文本交互模块（ITIM），以及恢复边缘解码器（RED）。

Result: 实验表明，CMB-Net优于大多数现有IML模型。

Conclusion: CMB-Net通过结合语义和视觉特征，显著提升了篡改定位的准确性。

Abstract: The existing image manipulation localization (IML) models mainly relies on
visual cues, but ignores the semantic logical relationships between content
features. In fact, the content semantics conveyed by real images often conform
to human cognitive laws. However, image manipulation technology usually
destroys the internal relationship between content features, thus leaving
semantic clues for IML. In this paper, we propose a cognition-inspired
multimodal boundary-preserving network (CMB-Net). Specifically, CMB-Net
utilizes large language models (LLMs) to analyze manipulated regions within
images and generate prompt-based textual information to compensate for the lack
of semantic relationships in the visual information. Considering that the
erroneous texts induced by hallucination from LLMs will damage the accuracy of
IML, we propose an image-text central ambiguity module (ITCAM). It assigns
weights to the text features by quantifying the ambiguity between text and
image features, thereby ensuring the beneficial impact of textual information.
We also propose an image-text interaction module (ITIM) that aligns visual and
text features using a correlation matrix for fine-grained interaction. Finally,
inspired by invertible neural networks, we propose a restoration edge decoder
(RED) that mutually generates input and output features to preserve boundary
information in manipulated regions without loss. Extensive experiments show
that CMB-Net outperforms most existing IML models.

</details>


### [90] [Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline](https://arxiv.org/abs/2508.07217)
*Yuqi Han,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 论文提出了一种混合标定方法，结合通用和参数化模型，解决了通用标定中的姿态模糊问题，并提高了标定精度。


<details>
  <summary>Details</summary>
Motivation: 离线相机标定中，参数化模型依赖用户经验，而通用模型复杂且无法提供传统内参。通用标定方法存在姿态模糊问题，影响后续姿态估计。

Method: 提出线性求解器和非线性优化解决姿态模糊问题，并引入全局优化的混合标定方法，结合通用与参数化模型。

Result: 混合方法在各种镜头类型和噪声污染下表现优异，提高了外参精度并减少了过拟合和数值不稳定性。

Conclusion: 混合标定方法为复杂场景下的相机标定提供了可靠且高精度的解决方案。

Abstract: Offline camera calibration techniques typically employ parametric or generic
camera models. Selecting parametric models relies heavily on user experience,
and an inappropriate camera model can significantly affect calibration
accuracy. Meanwhile, generic calibration methods involve complex procedures and
cannot provide traditional intrinsic parameters. This paper reveals a pose
ambiguity in the pose solutions of generic calibration methods that
irreversibly impacts subsequent pose estimation. A linear solver and a
nonlinear optimization are proposed to address this ambiguity issue. Then a
global optimization hybrid calibration method is introduced to integrate
generic and parametric models together, which improves extrinsic parameter
accuracy of generic calibration and mitigates overfitting and numerical
instability in parametric calibration. Simulation and real-world experimental
results demonstrate that the generic-parametric hybrid calibration method
consistently excels across various lens types and noise contamination,
hopefully serving as a reliable and accurate solution for camera calibration in
complex scenarios.

</details>


### [91] [Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource](https://arxiv.org/abs/2508.07233)
*Lei Yang,Junshan Jin,Mingyuan Zhang,Yi He,Bofan Chen,Shilin Wang*

Main category: cs.CV

TL;DR: 提出了一种基于面部关键点的视觉特征提取方法，结合时空多图卷积网络和多级唇部动态融合框架，以提升有限数据下的视觉语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法易受视觉干扰（如光照、皮肤纹理等）影响，且需要大量数据和计算资源。

Method: 使用面部关键点作为辅助信息训练视觉特征提取器，设计时空多图卷积网络，并引入多级唇部动态融合框架。

Result: 实验表明，该方法在有限数据下表现良好，并提高了对未见说话者的识别准确率。

Conclusion: 该方法有效减少了用户特定特征的影响，提升了小数据场景下的性能。

Abstract: Visual speech recognition is a technique to identify spoken content in silent
speech videos, which has raised significant attention in recent years.
Advancements in data-driven deep learning methods have significantly improved
both the speed and accuracy of recognition. However, these deep learning
methods can be effected by visual disturbances, such as lightning conditions,
skin texture and other user-specific features. Data-driven approaches could
reduce the performance degradation caused by these visual disturbances using
models pretrained on large-scale datasets. But these methods often require
large amounts of training data and computational resources, making them costly.
To reduce the influence of user-specific features and enhance performance with
limited data, this paper proposed a landmark guided visual feature extractor.
Facial landmarks are used as auxiliary information to aid in training the
visual feature extractor. A spatio-temporal multi-graph convolutional network
is designed to fully exploit the spatial locations and spatio-temporal features
of facial landmarks. Additionally, a multi-level lip dynamic fusion framework
is introduced to combine the spatio-temporal features of the landmarks with the
visual features extracted from the raw video frames. Experimental results show
that this approach performs well with limited data and also improves the
model's accuracy on unseen speakers.

</details>


### [92] [ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation](https://arxiv.org/abs/2508.07237)
*Bo Wang,Mengyuan Xu,Yue Yan,Yuqun Yang,Kechen Shu,Wei Ping,Xu Tang,Wei Jiang,Zheng You*

Main category: cs.CV

TL;DR: ASM-UNet是一种基于Mamba的新型架构，用于细粒度分割（FGS），通过自适应扫描顺序解决个体差异问题，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有粗粒度分割方法在细粒度分割中表现不佳，且固定扫描顺序限制了模型对个体差异的适应性。

Method: 提出ASM-UNet，结合群体共性和个体差异生成自适应扫描分数，动态指导扫描顺序。

Result: 在ACDC、Synapse和BTMS数据集上，ASM-UNet在粗粒度和细粒度分割任务中均表现优异。

Conclusion: ASM-UNet通过自适应扫描顺序有效解决了细粒度分割中的个体差异问题，具有广泛应用潜力。

Abstract: Precise lesion resection depends on accurately identifying fine-grained
anatomical structures. While many coarse-grained segmentation (CGS) methods
have been successful in large-scale segmentation (e.g., organs), they fall
short in clinical scenarios requiring fine-grained segmentation (FGS), which
remains challenging due to frequent individual variations in small-scale
anatomical structures. Although recent Mamba-based models have advanced medical
image segmentation, they often rely on fixed manually-defined scanning orders,
which limit their adaptability to individual variations in FGS. To address
this, we propose ASM-UNet, a novel Mamba-based architecture for FGS. It
introduces adaptive scan scores to dynamically guide the scanning order,
generated by combining group-level commonalities and individual-level
variations. Experiments on two public datasets (ACDC and Synapse) and a newly
proposed challenging biliary tract FGS dataset, namely BTMS, demonstrate that
ASM-UNet achieves superior performance in both CGS and FGS tasks. Our code and
dataset are available at https://github.com/YqunYang/ASM-UNet.

</details>


### [93] [Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers](https://arxiv.org/abs/2508.07246)
*Xin Ma,Yaohui Wang,Genyun Jia,Xinyuan Chen,Tien-Tsin Wong,Cunjian Chen*

Main category: cs.CV

TL;DR: MiraMo框架通过高效线性注意力、运动残差学习和DCT噪声优化，提升图像动画的一致性、平滑性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决图像动画中外观一致性和运动平滑性问题，同时降低计算资源需求。

Method: 1. 使用高效线性注意力替代传统自注意力；2. 运动残差学习建模动态；3. DCT噪声优化和动态控制模块。

Result: 实验证明MiraMo在生成一致性、平滑性和速度上优于现有方法，适用于运动迁移和视频编辑。

Conclusion: MiraMo为图像动画提供了高效、可控且高质量的解决方案。

Abstract: Image animation has seen significant progress, driven by the powerful
generative capabilities of diffusion models. However, maintaining appearance
consistency with static input images and mitigating abrupt motion transitions
in generated animations remain persistent challenges. While text-to-video (T2V)
generation has demonstrated impressive performance with diffusion transformer
models, the image animation field still largely relies on U-Net-based diffusion
models, which lag behind the latest T2V approaches. Moreover, the quadratic
complexity of vanilla self-attention mechanisms in Transformers imposes heavy
computational demands, making image animation particularly resource-intensive.
To address these issues, we propose MiraMo, a framework designed to enhance
efficiency, appearance consistency, and motion smoothness in image animation.
Specifically, MiraMo introduces three key elements: (1) A foundational
text-to-video architecture replacing vanilla self-attention with efficient
linear attention to reduce computational overhead while preserving generation
quality; (2) A novel motion residual learning paradigm that focuses on modeling
motion dynamics rather than directly predicting frames, improving temporal
consistency; and (3) A DCT-based noise refinement strategy during inference to
suppress sudden motion artifacts, complemented by a dynamics control module to
balance motion smoothness and expressiveness. Extensive experiments against
state-of-the-art methods validate the superiority of MiraMo in generating
consistent, smooth, and controllable animations with accelerated inference
speed. Additionally, we demonstrate the versatility of MiraMo through
applications in motion transfer and video editing tasks.

</details>


### [94] [SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking](https://arxiv.org/abs/2508.07250)
*Fengchao Xiong,Zhenxing Wu,Sen Jia,Yuntao Qian*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer和集合论的光谱交互方法，用于提升高光谱视频跟踪性能，并通过光谱损失增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注空间交互，忽略了光谱交互，导致性能不佳。

Method: 结合Transformer建立波段间空间关系，利用集合论的包含-排除原则建模光谱交互，并引入光谱损失优化训练。

Result: 实验表明，该方法实现了最先进的跟踪性能。

Conclusion: 通过光谱交互的建模和优化，显著提升了高光谱视频跟踪的准确性和鲁棒性。

Abstract: Hyperspectral videos (HSVs), with their inherent spatial-spectral-temporal
structure, offer distinct advantages in challenging tracking scenarios such as
cluttered backgrounds and small objects. However, existing methods primarily
focus on spatial interactions between the template and search regions, often
overlooking spectral interactions, leading to suboptimal performance. To
address this issue, this paper investigates spectral interactions from both the
architectural and training perspectives. At the architectural level, we first
establish band-wise long-range spatial relationships between the template and
search regions using Transformers. We then model spectral interactions using
the inclusion-exclusion principle from set theory, treating them as the union
of spatial interactions across all bands. This enables the effective
integration of both shared and band-specific spatial cues. At the training
level, we introduce a spectral loss to enforce material distribution alignment
between the template and predicted regions, enhancing robustness to shape
deformation and appearance variations. Extensive experiments demonstrate that
our tracker achieves state-of-the-art tracking performance. The source code,
trained models and results will be publicly available via
https://github.com/bearshng/suit to support reproducibility.

</details>


### [95] [Understanding Dynamic Scenes in Ego Centric 4D Point Clouds](https://arxiv.org/abs/2508.07251)
*Junsheng Huang,Shengyu Hao,Bocheng Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: 论文提出EgoDynamic4D，一个用于动态4D场景理解的问答基准，包含丰富的标注数据和任务，并提出了一种端到端的时空推理框架。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏统一的4D标注和任务驱动的评估协议，无法支持细粒度的时空推理，尤其是在物体和人的运动及其交互方面。

Method: 构建了包含RGB-D视频、相机位姿、实例掩码和4D边界框的EgoDynamic4D数据集，设计了12种动态问答任务，并提出了一种结合动态和静态信息的端到端时空推理框架。

Result: 实验表明，该方法在EgoDynamic4D上优于基线，验证了多模态时序建模的有效性。

Conclusion: EgoDynamic4D为动态场景理解提供了新基准，提出的框架在时空推理任务中表现优异。

Abstract: Understanding dynamic 4D scenes from an egocentric perspective-modeling
changes in 3D spatial structure over time-is crucial for human-machine
interaction, autonomous navigation, and embodied intelligence. While existing
egocentric datasets contain dynamic scenes, they lack unified 4D annotations
and task-driven evaluation protocols for fine-grained spatio-temporal
reasoning, especially on motion of objects and human, together with their
interactions. To address this gap, we introduce EgoDynamic4D, a novel QA
benchmark on highly dynamic scenes, comprising RGB-D video, camera poses,
globally unique instance masks, and 4D bounding boxes. We construct 927K QA
pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable,
step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering
agent motion, human-object interaction, trajectory prediction, relation
understanding, and temporal-causal reasoning, with fine-grained,
multidimensional metrics. To tackle these tasks, we propose an end-to-end
spatio-temporal reasoning framework that unifies dynamic and static scene
information, using instance-aware feature encoding, time and camera encoding,
and spatially adaptive down-sampling to compress large 4D scenes into token
sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method
consistently outperforms baselines, validating the effectiveness of multimodal
temporal modeling for egocentric dynamic scene understanding.

</details>


### [96] [Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM](https://arxiv.org/abs/2508.07260)
*Sihan Yang,Huitong Ji,Shaolin Lu,Jiayi Chen,Binxiao Xu,Ming Lu,Yuanxing Zhang,Wenhui Dong,Wentao Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为Small-Large Collaboration (SLC)的新框架，通过小型和大型视觉语言模型的协作，实现高效个性化应用。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLMs）虽然能力强，但训练成本高且不易个性化；小型VLMs易于个性化但推理能力不足。SLC旨在结合两者的优势。

Method: SLC框架中，小型VLM负责生成个性化信息，大型VLM整合这些信息以提供准确回答，并通过测试时反射策略防止小型VLM的幻觉。

Result: 实验表明，SLC在多种基准测试和大型VLMs上表现有效，且训练效率高。

Conclusion: SLC是首个支持开源和闭源大型VLMs的高效个性化框架，具有广泛的实际应用潜力。

Abstract: Personalizing Vision-Language Models (VLMs) to transform them into daily
assistants has emerged as a trending research direction. However, leading
companies like OpenAI continue to increase model size and develop complex
designs such as the chain of thought (CoT). While large VLMs are proficient in
complex multi-modal understanding, their high training costs and limited access
via paid APIs restrict direct personalization. Conversely, small VLMs are
easily personalized and freely available, but they lack sufficient reasoning
capabilities. Inspired by this, we propose a novel collaborative framework
named Small-Large Collaboration (SLC) for large VLM personalization, where the
small VLM is responsible for generating personalized information, while the
large model integrates this personalized information to deliver accurate
responses. To effectively incorporate personalized information, we develop a
test-time reflection strategy, preventing the potential hallucination of the
small VLM. Since SLC only needs to train a meta personalized small VLM for the
large VLMs, the overall process is training-efficient. To the best of our
knowledge, this is the first training-efficient framework that supports both
open-source and closed-source large VLMs, enabling broader real-world
personalized applications. We conduct thorough experiments across various
benchmarks and large VLMs to demonstrate the effectiveness of the proposed SLC
framework. The code will be released at https://github.com/Hhankyangg/SLC.

</details>


### [97] [OpenHAIV: A Framework Towards Practical Open-World Learning](https://arxiv.org/abs/2508.07270)
*Xiang Xiang,Qinhao Zhou,Zhuo Xu,Jing Ma,Jiaxin Dai,Yifan Liang,Hanlin Li*

Main category: cs.CV

TL;DR: OpenHAIV框架整合了OOD检测、新类别发现和增量持续微调，以解决开放世界场景中的知识更新问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如OOD检测和增量学习）在开放世界场景中存在局限性，无法满足自主知识更新的需求。

Method: 提出OpenHAIV框架，将OOD检测、新类别发现和增量持续微调结合为一个统一流程。

Result: 框架实现了模型在开放世界环境中自主获取和更新知识的能力。

Conclusion: OpenHAIV为开放世界识别提供了一种有效的解决方案。

Abstract: Substantial progress has been made in various techniques for open-world
recognition. Out-of-distribution (OOD) detection methods can effectively
distinguish between known and unknown classes in the data, while incremental
learning enables continuous model knowledge updates. However, in open-world
scenarios, these approaches still face limitations. Relying solely on OOD
detection does not facilitate knowledge updates in the model, and incremental
fine-tuning typically requires supervised conditions, which significantly
deviate from open-world settings. To address these challenges, this paper
proposes OpenHAIV, a novel framework that integrates OOD detection, new class
discovery, and incremental continual fine-tuning into a unified pipeline. This
framework allows models to autonomously acquire and update knowledge in
open-world environments. The proposed framework is available at
https://haiv-lab.github.io/openhaiv .

</details>


### [98] [Representation Understanding via Activation Maximization](https://arxiv.org/abs/2508.07281)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.CV

TL;DR: 提出了一种统一的特征可视化框架，适用于CNN和ViT，扩展了中间层的可视化，并探讨了激活最大化在生成对抗样本中的应用。


<details>
  <summary>Details</summary>
Motivation: 理解DNN内部特征表示是模型可解释性的关键步骤，现有方法主要关注CNN输出层神经元，缺乏对中间层的深入分析。

Method: 采用激活最大化（AM）方法，扩展特征可视化至中间层，并研究其在生成对抗样本中的应用。

Result: 实验证明该方法在CNN和ViT中均有效，揭示了模型的潜在脆弱性和决策边界。

Conclusion: 该框架具有通用性和解释价值，为DNN特征表示提供了更深入的见解。

Abstract: Understanding internal feature representations of deep neural networks (DNNs)
is a fundamental step toward model interpretability. Inspired by neuroscience
methods that probe biological neurons using visual stimuli, recent deep
learning studies have employed Activation Maximization (AM) to synthesize
inputs that elicit strong responses from artificial neurons. In this work, we
propose a unified feature visualization framework applicable to both
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike
prior efforts that predominantly focus on the last output-layer neurons in
CNNs, we extend feature visualization to intermediate layers as well, offering
deeper insights into the hierarchical structure of learned feature
representations. Furthermore, we investigate how activation maximization can be
leveraged to generate adversarial examples, revealing potential vulnerabilities
and decision boundaries of DNNs. Our experiments demonstrate the effectiveness
of our approach in both traditional CNNs and modern ViT, highlighting its
generalizability and interpretive value.

</details>


### [99] [SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations](https://arxiv.org/abs/2508.07298)
*Zhiqiang Shen,Peng Cao,Xiaoli Liu,Jinzhu Yang,Osmar R. Zaiane*

Main category: cs.CV

TL;DR: SynMatch提出了一种新框架，通过合成图像匹配伪标签来解决医学图像分割中的标签稀缺问题，避免了直接改进伪标签的复杂性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签稀缺是一个主要挑战，现有方法通过强-弱伪监督利用未标记数据，但伪标签与未标记图像之间的不一致性限制了性能。

Method: SynMatch通过从生成伪标签的分割模型中提取纹理和形状特征来合成图像，生成高度一致的合成图像-伪标签对，无需额外训练参数。

Result: 在多种医学图像分割任务中，SynMatch在半监督、弱监督和极弱监督设置下表现优异，尤其在极弱监督设置下显著优于现有方法。

Conclusion: SynMatch通过合成匹配伪标签的图像，显著提升了医学图像分割的性能，尤其在标签稀缺情况下表现突出。

Abstract: Label scarcity remains a major challenge in deep learning-based medical image
segmentation. Recent studies use strong-weak pseudo supervision to leverage
unlabeled data. However, performance is often hindered by inconsistencies
between pseudo labels and their corresponding unlabeled images. In this work,
we propose \textbf{SynMatch}, a novel framework that sidesteps the need for
improving pseudo labels by synthesizing images to match them instead.
Specifically, SynMatch synthesizes images using texture and shape features
extracted from the same segmentation model that generates the corresponding
pseudo labels for unlabeled images. This design enables the generation of
highly consistent synthesized-image-pseudo-label pairs without requiring any
training parameters for image synthesis. We extensively evaluate SynMatch
across diverse medical image segmentation tasks under semi-supervised learning
(SSL), weakly-supervised learning (WSL), and barely-supervised learning (BSL)
settings with increasingly limited annotations. The results demonstrate that
SynMatch achieves superior performance, especially in the most challenging BSL
setting. For example, it outperforms the recent strong-weak pseudo
supervision-based method by 29.71\% and 10.05\% on the polyp segmentation task
with 5\% and 10\% scribble annotations, respectively. The code will be released
at https://github.com/Senyh/SynMatch.

</details>


### [100] [BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation](https://arxiv.org/abs/2508.07300)
*Ping-Mao Huang,I-Tien Chao,Ping-Chia Huang,Jia-Wei Liao,Yung-Yu Chuang*

Main category: cs.CV

TL;DR: BEVANet提出了一种实时语义分割的双边高效视觉注意力网络，通过大核注意力机制和动态选择机制提升性能，实现了高精度和实时性。


<details>
  <summary>Details</summary>
Motivation: 解决实时语义分割中高效架构设计和大感受野捕获的挑战，同时优化细节轮廓。

Method: 引入大核注意力（LKA）机制，提出BEVANet，结合稀疏分解大核注意力（SDLSKA）、动态核选择（CKS）和大核金字塔池化模块（DLKPPM），并通过边界引导自适应融合（BGAF）优化边界。

Result: BEVANet在未预训练和ImageNet预训练下分别达到79.3%和81.0% mIoU，实时速度为33 FPS。

Conclusion: BEVANet在实时语义分割中实现了高效和高精度，展示了先进性能。

Abstract: Real-time semantic segmentation presents the dual challenge of designing
efficient architectures that capture large receptive fields for semantic
understanding while also refining detailed contours. Vision transformers model
long-range dependencies effectively but incur high computational cost. To
address these challenges, we introduce the Large Kernel Attention (LKA)
mechanism. Our proposed Bilateral Efficient Visual Attention Network (BEVANet)
expands the receptive field to capture contextual information and extracts
visual and structural features using Sparse Decomposed Large Separable Kernel
Attentions (SDLSKA). The Comprehensive Kernel Selection (CKS) mechanism
dynamically adapts the receptive field to further enhance performance.
Furthermore, the Deep Large Kernel Pyramid Pooling Module (DLKPPM) enriches
contextual features by synergistically combining dilated convolutions and large
kernel attention. The bilateral architecture facilitates frequent branch
communication, and the Boundary Guided Adaptive Fusion (BGAF) module enhances
boundary delineation by integrating spatial and semantic features under
boundary guidance. BEVANet achieves real-time segmentation at 33 FPS, yielding
79.3% mIoU without pretraining and 81.0% mIoU on Cityscapes after ImageNet
pretraining, demonstrating state-of-the-art performance. The code and model is
available at https://github.com/maomao0819/BEVANet.

</details>


### [101] [DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices](https://arxiv.org/abs/2508.07306)
*Md Zahurul Haquea,Yeahyea Sarker,Muhammed Farhan Sadique Mahi,Syed Jubayer Jaman,Md Robiul Islam*

Main category: cs.CV

TL;DR: DragonFruitQualityNet是一种轻量级CNN模型，用于火龙果实时质量检测，准确率达93.98%，并嵌入移动应用以支持农户使用。


<details>
  <summary>Details</summary>
Motivation: 火龙果需求增长，需要高效的采前采后质量检测以提高生产效率和减少损失。

Method: 使用13,789张图像数据集，训练轻量级CNN模型，分类为新鲜、未成熟、成熟和缺陷四类。

Result: 模型准确率达93.98%，优于现有方法，并成功嵌入移动应用。

Conclusion: 研究为火龙果质量控制提供了高效、可扩展的AI解决方案，支持数字农业和小农户。

Abstract: Dragon fruit, renowned for its nutritional benefits and economic value, has
experienced rising global demand due to its affordability and local
availability. As dragon fruit cultivation expands, efficient pre- and
post-harvest quality inspection has become essential for improving agricultural
productivity and minimizing post-harvest losses. This study presents
DragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN)
optimized for real-time quality assessment of dragon fruits on mobile devices.
We curated a diverse dataset of 13,789 images, integrating self-collected
samples with public datasets (dataset from Mendeley Data), and classified them
into four categories: fresh, immature, mature, and defective fruits to ensure
robust model training. The proposed model achieves an impressive 93.98%
accuracy, outperforming existing methods in fruit quality classification. To
facilitate practical adoption, we embedded the model into an intuitive mobile
application, enabling farmers and agricultural stakeholders to conduct
on-device, real-time quality inspections. This research provides an accurate,
efficient, and scalable AI-driven solution for dragon fruit quality control,
supporting digital agriculture and empowering smallholder farmers with
accessible technology. By bridging the gap between research and real-world
application, our work advances post-harvest management and promotes sustainable
farming practices.

</details>


### [102] [MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark](https://arxiv.org/abs/2508.07307)
*Haiyang Guo,Fei Zhu,Hongbo Zhao,Fanhu Zeng,Wenzhuo Liu,Shijie Ma,Da-Han Wang,Xu-Yao Zhang*

Main category: cs.CV

TL;DR: 论文介绍了MCITlib，一个用于多模态大语言模型持续指令调优的代码库，旨在解决多模态持续学习中的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统持续学习方法在单模态任务中表现良好，但多模态大语言模型的兴起需要解决跨模态交互与协调的挑战。

Method: 开发了MCITlib代码库，实现了8种代表性算法，并在2个基准上进行了系统评估。

Result: MCITlib为多模态持续学习研究提供了工具，并将持续更新以反映领域进展。

Conclusion: MCITlib是推动多模态持续学习研究的重要资源，代码已开源。

Abstract: Continual learning aims to equip AI systems with the ability to continuously
acquire and adapt to new knowledge without forgetting previously learned
information, similar to human learning. While traditional continual learning
methods focusing on unimodal tasks have achieved notable success, the emergence
of Multimodal Large Language Models has brought increasing attention to
Multimodal Continual Learning tasks involving multiple modalities, such as
vision and language. In this setting, models are expected to not only mitigate
catastrophic forgetting but also handle the challenges posed by cross-modal
interactions and coordination. To facilitate research in this direction, we
introduce MCITlib, a comprehensive and constantly evolving code library for
continual instruction tuning of Multimodal Large Language Models. In MCITlib,
we have currently implemented 8 representative algorithms for Multimodal
Continual Instruction Tuning and systematically evaluated them on 2 carefully
selected benchmarks. MCITlib will be continuously updated to reflect advances
in the Multimodal Continual Learning field. The codebase is released at
https://github.com/Ghy0501/MCITlib.

</details>


### [103] [MobileViCLIP: An Efficient Video-Text Model for Mobile Devices](https://arxiv.org/abs/2508.07312)
*Min Yang,Zihan Jia,Zhilin Dai,Sheng Guo,Limin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种高效的视频-文本模型MobileViCLIP，通过引入时间结构重参数化技术，使其能在移动设备上快速运行，并具备强大的零样本分类和检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频预训练模型主要基于高延迟的ViT架构，缺乏针对移动设备的高效架构设计。

Method: 将时间结构重参数化技术应用于高效的图像-文本模型，并在大规模高质量视频-文本数据集上进行训练。

Result: MobileViCLIP-Small在移动设备上的推理速度显著优于InternVideo2-L14和InternVideo2-S14，零样本检索性能接近或优于后者。

Conclusion: MobileViCLIP为移动设备提供了一种高效的视频-文本模型解决方案，兼具速度和性能。

Abstract: Efficient lightweight neural networks are with increasing attention due to
their faster reasoning speed and easier deployment on mobile devices. However,
existing video pre-trained models still focus on the common ViT architecture
with high latency, and few works attempt to build efficient architecture on
mobile devices. This paper bridges this gap by introducing temporal structural
reparameterization into an efficient image-text model and training it on a
large-scale high-quality video-text dataset, resulting in an efficient
video-text model that can run on mobile devices with strong zero-shot
classification and retrieval capabilities, termed as MobileViCLIP. In
particular, in terms of inference speed on mobile devices, our
MobileViCLIP-Small is 55.4x times faster than InternVideo2-L14 and 6.7x faster
than InternVideo2-S14. In terms of zero-shot retrieval performance, our
MobileViCLIP-Small obtains similar performance as InternVideo2-L14 and obtains
6.9\% better than InternVideo2-S14 on MSR-VTT. The code is available at
https://github.com/MCG-NJU/MobileViCLIP.

</details>


### [104] [DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding](https://arxiv.org/abs/2508.07313)
*Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li*

Main category: cs.CV

TL;DR: DocR1是一种多模态大语言模型，通过新颖的强化学习框架EviGRPO提升多页文档理解能力，结合证据感知奖励机制和两阶段标注流程，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多页文档理解对多模态大语言模型（MLLMs）提出了挑战，需要细粒度视觉理解和跨页多跳推理。现有研究在强化学习（RL）应用于多页文档理解方面仍有不足。

Method: 提出EviGRPO框架，结合证据感知奖励机制，采用从粗到细的推理策略，先检索相关页再生成答案。通过两阶段标注流程和课程学习策略构建数据集EviBench和ArxivFullQA。

Result: DocR1在多页任务中达到最先进性能，同时在单页基准测试中保持强劲表现。

Conclusion: EviGRPO框架和两阶段标注策略有效提升了多页文档理解能力，DocR1在多种任务中表现出色。

Abstract: Understanding multi-page documents poses a significant challenge for
multimodal large language models (MLLMs), as it requires fine-grained visual
comprehension and multi-hop reasoning across pages. While prior work has
explored reinforcement learning (RL) for enhancing advanced reasoning in MLLMs,
its application to multi-page document understanding remains underexplored. In
this paper, we introduce DocR1, an MLLM trained with a novel RL framework,
Evidence Page-Guided GRPO (EviGRPO). EviGRPO incorporates an evidence-aware
reward mechanism that promotes a coarse-to-fine reasoning strategy, guiding the
model to first retrieve relevant pages before generating answers. This training
paradigm enables us to build high-quality models with limited supervision. To
support this, we design a two-stage annotation pipeline and a curriculum
learning strategy, based on which we construct two datasets: EviBench, a
high-quality training set with 4.8k examples, and ArxivFullQA, an evaluation
benchmark with 8.6k QA pairs based on scientific papers. Extensive experiments
across a wide range of benchmarks demonstrate that DocR1 achieves
state-of-the-art performance on multi-page tasks, while consistently
maintaining strong results on single-page benchmarks.

</details>


### [105] [RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning](https://arxiv.org/abs/2508.07318)
*Jinjing Gu,Tianbao Qin,Yuanyuan Pu,Zhengpeng Zhao*

Main category: cs.CV

TL;DR: RORPCap提出了一种基于检索的对象和关系提示方法，用于图像描述生成，解决了传统方法中冗余检测信息、GCN构建困难和训练成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统图像描述方法依赖对象检测器或结合GCN，存在冗余信息、构建困难和训练成本高的问题。

Method: RORPCap通过对象和关系提取模型提取关键词，结合预定义提示模板和Mamba映射网络，生成文本增强特征嵌入，最终输入GPT-2生成描述。

Result: 在MS-COCO数据集上，RORPCap仅需2.6小时训练，CIDEr和SPICE分数分别达到120.5%和22.0%，性能与传统方法相当。

Conclusion: RORPCap是一种高效且性能可比的图像描述生成替代方案。

Abstract: Image captioning aims to generate natural language descriptions for input
images in an open-form manner. To accurately generate descriptions related to
the image, a critical step in image captioning is to identify objects and
understand their relations within the image. Modern approaches typically
capitalize on object detectors or combine detectors with Graph Convolutional
Network (GCN). However, these models suffer from redundant detection
information, difficulty in GCN construction, and high training costs. To
address these issues, a Retrieval-based Objects and Relations Prompt for Image
Captioning (RORPCap) is proposed, inspired by the fact that image-text
retrieval can provide rich semantic information for input images. RORPCap
employs an Objects and relations Extraction Model to extract object and
relation words from the image. These words are then incorporate into predefined
prompt templates and encoded as prompt embeddings. Next, a Mamba-based mapping
network is designed to quickly map image embeddings extracted by CLIP to
visual-text embeddings. Finally, the resulting prompt embeddings and
visual-text embeddings are concatenated to form textual-enriched feature
embeddings, which are fed into a GPT-2 model for caption generation. Extensive
experiments conducted on the widely used MS-COCO dataset show that the RORPCap
requires only 2.6 hours under cross-entropy loss training, achieving 120.5%
CIDEr score and 22.0% SPICE score on the "Karpathy" test split. RORPCap
achieves comparable performance metrics to detector-based and GCN-based models
with the shortest training time and demonstrates its potential as an
alternative for image captioning.

</details>


### [106] [Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos](https://arxiv.org/abs/2508.07330)
*Tuyen Tran,Thao Minh Le,Quang-Hung Le,Truyen Tran*

Main category: cs.CV

TL;DR: Planner-Refiner框架通过迭代细化视觉元素的时空表示，减少语言与视觉间的语义鸿沟，在视频-语言对齐任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决视频中语言与视觉对齐的复杂性，包括语言复杂性、动态交互实体及其动作链，以及语言与视觉间的语义鸿沟。

Method: Planner模块将复杂语言提示分解为短句链，Refiner模块通过空间-时间自注意力机制逐步细化视觉表示，最终生成对齐结果。

Result: 在Referring Video Object Segmentation和Temporal Grounding任务中表现优于现有方法，尤其在复杂提示下效果显著。

Conclusion: Planner-Refiner框架有效解决了视频-语言对齐的挑战，尤其在处理复杂语言提示时展现出潜力。

Abstract: Vision-language alignment in video must address the complexity of language,
evolving interacting entities, their action chains, and semantic gaps between
language and vision. This work introduces Planner-Refiner, a framework to
overcome these challenges. Planner-Refiner bridges the semantic gap by
iteratively refining visual elements' space-time representation, guided by
language until semantic gaps are minimal. A Planner module schedules language
guidance by decomposing complex linguistic prompts into short sentence chains.
The Refiner processes each short sentence, a noun-phrase and verb-phrase pair,
to direct visual tokens' self-attention across space then time, achieving
efficient single-step refinement. A recurrent system chains these steps,
maintaining refined visual token representations. The final representation
feeds into task-specific heads for alignment generation. We demonstrate
Planner-Refiner's effectiveness on two video-language alignment tasks:
Referring Video Object Segmentation and Temporal Grounding with varying
language complexity. We further introduce a new MeViS-X benchmark to assess
models' capability with long queries. Superior performance versus
state-of-the-art methods on these benchmarks shows the approach's potential,
especially for complex prompts.

</details>


### [107] [CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation](https://arxiv.org/abs/2508.07341)
*Fangtai Wu,Mushui Liu,Weijie He,Wanggui He,Hao Jiang,Zhao Wang,Yunlong Yu*

Main category: cs.CV

TL;DR: CoAR是一种新颖的框架，通过冻结预训练参数，仅用极少量参数实现定制化图像生成，解决了现有方法的过拟合和计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 现有定制化生成方法依赖全微调或适配器，成本高且易过拟合或灾难性遗忘，需探索更高效的方法。

Method: CoAR采用分层多模态上下文学习策略，学习特定主题表示，并引入正则化防止过拟合和语言漂移。

Result: CoAR在主题和风格个性化任务中表现优异，计算和内存效率显著提升，仅调整0.05%参数。

Conclusion: CoAR为定制化生成提供了一种高效、低成本的解决方案，性能优于现有方法。

Abstract: The unified autoregressive (AR) model excels at multimodal understanding and
generation, but its potential for customized image generation remains
underexplored. Existing customized generation methods rely on full fine-tuning
or adapters, making them costly and prone to overfitting or catastrophic
forgetting. In this paper, we propose \textbf{CoAR}, a novel framework for
injecting subject concepts into the unified AR models while keeping all
pre-trained parameters completely frozen. CoAR learns effective, specific
subject representations with only a minimal number of parameters using a
Layerwise Multimodal Context Learning strategy. To address overfitting and
language drift, we further introduce regularization that preserves the
pre-trained distribution and anchors context tokens to improve subject fidelity
and re-contextualization. Additionally, CoAR supports training-free subject
customization in a user-provided style. Experiments demonstrate that CoAR
achieves superior performance on both subject-driven personalization and style
personalization, while delivering significant gains in computational and memory
efficiency. Notably, CoAR tunes less than \textbf{0.05\%} of the parameters
while achieving competitive performance compared to recent Proxy-Tuning. Code:
https://github.com/KZF-kzf/CoAR

</details>


### [108] [SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal](https://arxiv.org/abs/2508.07346)
*Tingyu Yang,Jue Gong,Jinpei Guo,Wenbo Li,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: SODiff是一种新颖的语义导向一步扩散模型，用于去除JPEG伪影，通过语义对齐的图像提示提取器和质量因子感知时间预测器提升恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在恢复复杂纹理细节时表现不佳，导致输出过于平滑，JPEG高压缩比下伪影问题严重。

Method: 提出SODiff模型，结合语义对齐的图像提示提取器（SAIPE）和质量因子感知时间预测器，优化扩散过程。

Result: 实验表明，SODiff在视觉质量和定量指标上均优于现有方法。

Conclusion: SODiff通过语义导向和自适应时间预测，显著提升了JPEG伪影去除效果。

Abstract: JPEG, as a widely used image compression standard, often introduces severe
visual artifacts when achieving high compression ratios. Although existing deep
learning-based restoration methods have made considerable progress, they often
struggle to recover complex texture details, resulting in over-smoothed
outputs. To overcome these limitations, we propose SODiff, a novel and
efficient semantic-oriented one-step diffusion model for JPEG artifacts
removal. Our core idea is that effective restoration hinges on providing
semantic-oriented guidance to the pre-trained diffusion model, thereby fully
leveraging its powerful generative prior. To this end, SODiff incorporates a
semantic-aligned image prompt extractor (SAIPE). SAIPE extracts rich features
from low-quality (LQ) images and projects them into an embedding space
semantically aligned with that of the text encoder. Simultaneously, it
preserves crucial information for faithful reconstruction. Furthermore, we
propose a quality factor-aware time predictor that implicitly learns the
compression quality factor (QF) of the LQ image and adaptively selects the
optimal denoising start timestep for the diffusion process. Extensive
experimental results show that our SODiff outperforms recent leading methods in
both visual quality and quantitative metrics. Code is available at:
https://github.com/frakenation/SODiff

</details>


### [109] [GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction](https://arxiv.org/abs/2508.07355)
*Qilin Zhang,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: GS4Buildings是一种基于语义3D建筑模型的高斯泼溅方法，用于提升大规模复杂城市场景中的建筑表面重建效果。


<details>
  <summary>Details</summary>
Motivation: 传统2D高斯泼溅方法在大规模复杂城市场景中表现不佳，导致建筑重建不完整。

Method: 利用低细节语义3D建筑模型初始化高斯，并引入先验深度和法线图优化重建过程。

Result: 实验表明，GS4Buildings提升了20.5%的重建完整性和32.8%的几何准确性。

Conclusion: 语义建筑模型的集成有助于高斯泼溅方法在智能城市等实际应用中发挥作用。

Abstract: Recent advances in Gaussian Splatting (GS) have demonstrated its
effectiveness in photo-realistic rendering and 3D reconstruction. Among these,
2D Gaussian Splatting (2DGS) is particularly suitable for surface
reconstruction due to its flattened Gaussian representation and integrated
normal regularization. However, its performance often degrades in large-scale
and complex urban scenes with frequent occlusions, leading to incomplete
building reconstructions. We propose GS4Buildings, a novel prior-guided
Gaussian Splatting method leveraging the ubiquity of semantic 3D building
models for robust and scalable building surface reconstruction. Instead of
relying on traditional Structure-from-Motion (SfM) pipelines, GS4Buildings
initializes Gaussians directly from low-level Level of Detail (LoD)2 semantic
3D building models. Moreover, we generate prior depth and normal maps from the
planar building geometry and incorporate them into the optimization process,
providing strong geometric guidance for surface consistency and structural
accuracy. We also introduce an optional building-focused mode that limits
reconstruction to building regions, achieving a 71.8% reduction in Gaussian
primitives and enabling a more efficient and compact representation.
Experiments on urban datasets demonstrate that GS4Buildings improves
reconstruction completeness by 20.5% and geometric accuracy by 32.8%. These
results highlight the potential of semantic building model integration to
advance GS-based reconstruction toward real-world urban applications such as
smart cities and digital twins. Our project is available:
https://github.com/zqlin0521/GS4Buildings.

</details>


### [110] [Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring](https://arxiv.org/abs/2508.07369)
*Tianyu Xin,Jin-Liang Xiao,Zeyu Xia,Shan Yin,Liang-Jian Deng*

Main category: cs.CV

TL;DR: 提出了一种解决跨传感器泛化问题的深度学习方法，通过特征裁剪器和物理感知无监督损失，显著提升了泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 现有预训练模型在跨传感器数据上泛化能力差，传统方法耗时或需额外数据。

Method: 模块化分解模型，引入特征裁剪器，采用物理感知无监督损失和分块并行推理。

Result: 在跨传感器数据上实现最佳质量和效率，训练和推理速度远超零样本方法。

Conclusion: 该方法高效且无需额外数据，显著提升了跨传感器泛化能力。

Abstract: Deep learning methods for pansharpening have advanced rapidly, yet models
pretrained on data from a specific sensor often generalize poorly to data from
other sensors. Existing methods to tackle such cross-sensor degradation include
retraining model or zero-shot methods, but they are highly time-consuming or
even need extra training data. To address these challenges, our method first
performs modular decomposition on deep learning-based pansharpening models,
revealing a general yet critical interface where high-dimensional fused
features begin mapping to the channel space of the final image. % may need
revisement A Feature Tailor is then integrated at this interface to address
cross-sensor degradation at the feature level, and is trained efficiently with
physics-aware unsupervised losses. Moreover, our method operates in a
patch-wise manner, training on partial patches and performing parallel
inference on all patches to boost efficiency. Our method offers two key
advantages: (1) $\textit{Improved Generalization Ability}$: it significantly
enhance performance in cross-sensor cases. (2) $\textit{Low Generalization
Cost}$: it achieves sub-second training and inference, requiring only partial
test inputs and no external data, whereas prior methods often take minutes or
even hours. Experiments on the real-world data from multiple datasets
demonstrate that our method achieves state-of-the-art quality and efficiency in
tackling cross-sensor degradation. For example, training and inference of
$512\times512\times8$ image within $\textit{0.2 seconds}$ and
$4000\times4000\times8$ image within $\textit{3 seconds}$ at the fastest
setting on a commonly used RTX 3090 GPU, which is over 100 times faster than
zero-shot methods.

</details>


### [111] [DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery](https://arxiv.org/abs/2508.07372)
*Rajaei Khatib,Raja Giryes*

Main category: cs.CV

TL;DR: 3DGS在稀疏视图重建中表现不佳，DIP-GS通过深度图像先验（DIP）改进3DGS，无需预训练模型即可在稀疏视图任务中取得SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 3DGS在多视图重建中表现优异，但在稀疏视图场景下效果较差，因此提出DIP-GS以解决这一问题。

Method: 利用深度图像先验（DIP）结合3DGS，采用由粗到细的方式，仅依赖输入帧进行稀疏视图重建。

Result: DIP-GS在稀疏视图重建任务中取得SOTA效果。

Conclusion: DIP-GS无需预训练模型即可在稀疏视图场景下显著提升3DGS性能。

Abstract: 3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method,
obtaining high-quality reconstruction with real-time rendering runtime
performance. The main idea behind 3DGS is to represent the scene as a
collection of 3D gaussians, while learning their parameters to fit the given
views of the scene. While achieving superior performance in the presence of
many views, 3DGS struggles with sparse view reconstruction, where the input
views are sparse and do not fully cover the scene and have low overlaps. In
this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By
using the DIP prior, which utilizes internal structure and patterns, with
coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla
3DGS fails, such as sparse view recovery. Note that our approach does not use
any pre-trained models such as generative models and depth estimation, but
rather relies only on the input frames. Among such methods, DIP-GS obtains
state-of-the-art (SOTA) competitive results on various sparse-view
reconstruction tasks, demonstrating its capabilities.

</details>


### [112] [LET-US: Long Event-Text Understanding of Scenes](https://arxiv.org/abs/2508.07401)
*Rui Chen,Xingyu Chen,Shaoan Wang,Shihan Kong,Junzhi Yu*

Main category: cs.CV

TL;DR: LET-US是一个用于长事件流文本理解的框架，通过自适应压缩机制减少输入事件量，同时保留关键视觉细节，提升了跨模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在RGB视频理解上表现优异，但对事件流的处理能力有限，尤其是长序列。LET-US旨在填补这一空白。

Method: 采用两阶段优化范式，结合文本引导的跨模态查询、分层聚类和相似性计算，减少事件流的时间信息量。

Result: 实验表明，LET-US在长事件流的描述准确性和语义理解上优于现有MLLMs。

Conclusion: LET-US为长事件流与文本的跨模态理解设立了新标准，未来将公开数据集、代码和模型。

Abstract: Event cameras output event streams as sparse, asynchronous data with
microsecond-level temporal resolution, enabling visual perception with low
latency and a high dynamic range. While existing Multimodal Large Language
Models (MLLMs) have achieved significant success in understanding and analyzing
RGB video content, they either fail to interpret event streams effectively or
remain constrained to very short sequences. In this paper, we introduce LET-US,
a framework for long event-stream--text comprehension that employs an adaptive
compression mechanism to reduce the volume of input events while preserving
critical visual details. LET-US thus establishes a new frontier in cross-modal
inferential understanding over extended event sequences. To bridge the
substantial modality gap between event streams and textual representations, we
adopt a two-stage optimization paradigm that progressively equips our model
with the capacity to interpret event-based scenes. To handle the voluminous
temporal information inherent in long event streams, we leverage text-guided
cross-modal queries for feature reduction, augmented by hierarchical clustering
and similarity computation to distill the most representative event features.
Moreover, we curate and construct a large-scale event-text aligned dataset to
train our model, achieving tighter alignment of event features within the LLM
embedding space. We also develop a comprehensive benchmark covering a diverse
set of tasks -- reasoning, captioning, classification, temporal localization
and moment retrieval. Experimental results demonstrate that LET-US outperforms
prior state-of-the-art MLLMs in both descriptive accuracy and semantic
comprehension on long-duration event streams. All datasets, codes, and models
will be publicly available.

</details>


### [113] [ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack](https://arxiv.org/abs/2508.07402)
*Rongxuan Peng,Shunquan Tan,Chenqi Kong,Anwei Luo,Alex C. Kot,Jiwu Huang*

Main category: cs.CV

TL;DR: 论文提出ForensicsSAM框架，通过注入伪造专家和对抗专家，提升图像伪造检测与定位的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法忽视对抗攻击的脆弱性，导致性能下降。

Method: 设计轻量级对抗检测器和注入伪造/对抗专家，增强模型鲁棒性。

Result: 在多个基准测试中，ForensicsSAM表现出卓越的对抗攻击抵抗能力，并实现最优性能。

Conclusion: ForensicsSAM为图像伪造检测与定位提供了一种高效且鲁棒的解决方案。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a popular strategy for
adapting large vision foundation models, such as the Segment Anything Model
(SAM) and LLaVA, to downstream tasks like image forgery detection and
localization (IFDL). However, existing PEFT-based approaches overlook their
vulnerability to adversarial attacks. In this paper, we show that highly
transferable adversarial images can be crafted solely via the upstream model,
without accessing the downstream model or training data, significantly
degrading the IFDL performance. To address this, we propose ForensicsSAM, a
unified IFDL framework with built-in adversarial robustness. Our design is
guided by three key ideas: (1) To compensate for the lack of forgery-relevant
knowledge in the frozen image encoder, we inject forgery experts into each
transformer block to enhance its ability to capture forgery artifacts. These
forgery experts are always activated and shared across any input images. (2) To
detect adversarial images, we design an light-weight adversary detector that
learns to capture structured, task-specific artifact in RGB domain, enabling
reliable discrimination across various attack methods. (3) To resist
adversarial attacks, we inject adversary experts into the global attention
layers and MLP modules to progressively correct feature shifts induced by
adversarial noise. These adversary experts are adaptively activated by the
adversary detector, thereby avoiding unnecessary interference with clean
images. Extensive experiments across multiple benchmarks demonstrate that
ForensicsSAM achieves superior resistance to various adversarial attack
methods, while also delivering state-of-the-art performance in image-level
forgery detection and pixel-level forgery localization. The resource is
available at https://github.com/siriusPRX/ForensicsSAM.

</details>


### [114] [CharacterShot: Controllable and Consistent 4D Character Animation](https://arxiv.org/abs/2508.07409)
*Junyao Gao,Jiaxing Li,Wenran Liu,Yanhong Zeng,Fei Shen,Kai Chen,Yanan Sun,Cairong Zhao*

Main category: cs.CV

TL;DR: CharacterShot是一个可控且一致的4D角色动画框架，可从单张参考图像和2D姿态序列生成动态3D角色动画。


<details>
  <summary>Details</summary>
Motivation: 为设计师提供一种简单方法，从单张图像和2D姿态序列生成高质量4D角色动画。

Method: 1. 预训练基于DiT的2D动画模型；2. 通过双注意力模块和相机先验将模型从2D提升到3D；3. 使用4D高斯溅射优化生成连续稳定的4D表示。

Result: 在CharacterBench基准测试中表现优于现有方法，并构建了大规模数据集Character4D。

Conclusion: CharacterShot为4D角色动画提供了高效解决方案，代码和数据集将开源。

Abstract: In this paper, we propose \textbf{CharacterShot}, a controllable and
consistent 4D character animation framework that enables any individual
designer to create dynamic 3D characters (i.e., 4D character animation) from a
single reference character image and a 2D pose sequence. We begin by
pretraining a powerful 2D character animation model based on a cutting-edge
DiT-based image-to-video model, which allows for any 2D pose sequnce as
controllable signal. We then lift the animation model from 2D to 3D through
introducing dual-attention module together with camera prior to generate
multi-view videos with spatial-temporal and spatial-view consistency. Finally,
we employ a novel neighbor-constrained 4D gaussian splatting optimization on
these multi-view videos, resulting in continuous and stable 4D character
representations. Moreover, to improve character-centric performance, we
construct a large-scale dataset Character4D, containing 13,115 unique
characters with diverse appearances and motions, rendered from multiple
viewpoints. Extensive experiments on our newly constructed benchmark,
CharacterBench, demonstrate that our approach outperforms current
state-of-the-art methods. Code, models, and datasets will be publicly available
at https://github.com/Jeoyal/CharacterShot.

</details>


### [115] [CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization](https://arxiv.org/abs/2508.07413)
*Youqi Wang,Shunquan Tan,Rongxuan Peng,Bin Li,Jiwu Huang*

Main category: cs.CV

TL;DR: CLUE利用Stable Diffusion 3和Segment Anything Model，通过噪声注入和参数高效调整，定位高保真伪造区域，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数字媒体伪造工具普及导致伪造内容泛滥，亟需高效定位技术。

Method: 结合SD3的Rectified Flow机制和LoRA调整，注入噪声放大伪造痕迹，并利用SAM增强语义和空间细节。

Result: CLUE在泛化性能和鲁棒性上显著优于现有方法，对抗后处理和社交网络攻击表现优异。

Conclusion: CLUE为数字媒体伪造检测提供了高效、鲁棒的解决方案，代码已开源。

Abstract: The increasing accessibility of image editing tools and generative AI has led
to a proliferation of visually convincing forgeries, compromising the
authenticity of digital media. In this paper, in addition to leveraging
distortions from conventional forgeries, we repurpose the mechanism of a
state-of-the-art (SOTA) text-to-image synthesis model by exploiting its
internal generative process, turning it into a high-fidelity forgery
localization tool. To this end, we propose CLUE (Capture Latent Uncovered
Evidence), a framework that employs Low- Rank Adaptation (LoRA) to
parameter-efficiently reconfigure Stable Diffusion 3 (SD3) as a forensic
feature extractor. Our approach begins with the strategic use of SD3's
Rectified Flow (RF) mechanism to inject noise at varying intensities into the
latent representation, thereby steering the LoRAtuned denoising process to
amplify subtle statistical inconsistencies indicative of a forgery. To
complement the latent analysis with high-level semantic context and precise
spatial details, our method incorporates contextual features from the image
encoder of the Segment Anything Model (SAM), which is parameter-efficiently
adapted to better trace the boundaries of forged regions. Extensive evaluations
demonstrate CLUE's SOTA generalization performance, significantly outperforming
prior methods. Furthermore, CLUE shows superior robustness against common
post-processing attacks and Online Social Networks (OSNs). Code is publicly
available at https://github.com/SZAISEC/CLUE.

</details>


### [116] [Freeze and Reveal: Exposing Modality Bias in Vision-Language Models](https://arxiv.org/abs/2508.07432)
*Vivek Hruday Kavuri,Vysishtya Karanam,Venkata Jahnavi Venkamsetty,Kriti Madumadukala,Lakshmipathi Balaji Darur,Ponnurangam Kumaraguru*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型中的性别偏见，提出两种去偏方法（CDA和DAUDoS），并通过实验发现视觉和文本编码器的偏见来源不同。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在训练数据中继承了性别偏见，需要分析偏见来源并提出高效去偏方法。

Method: 采用反事实数据增强（CDA）和基于新指标（Degree of Stereotypicality）的DAUDoS方法，并在VisoGender基准上评估。

Result: CDA减少性别差距6%，DAUDoS减少3%但仅需三分之一数据；两种方法均提升性别识别准确率3%。

Conclusion: CLIP视觉编码器偏见更显著，PaliGemma2文本编码器偏见更显著，为未来多模态系统的针对性去偏提供了方向。

Abstract: Vision Language Models achieve impressive multi-modal performance but often
inherit gender biases from their training data. This bias might be coming from
both the vision and text modalities. In this work, we dissect the contributions
of vision and text backbones to these biases by applying targeted debiasing
using Counterfactual Data Augmentation and Task Vector methods. Inspired by
data-efficient approaches in hate-speech classification, we introduce a novel
metric, Degree of Stereotypicality and a corresponding debiasing method, Data
Augmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with
minimal computational cost. We curate a gender annotated dataset and evaluate
all methods on VisoGender benchmark to quantify improvements and identify
dominant source of bias. Our results show that CDA reduces the gender gap by 6%
and DAUDoS by 3% but using only one-third of the data. Both methods also
improve the model's ability to correctly identify gender in images by 3%, with
DAUDoS achieving this improvement using only almost one-third of training data.
From our experiment's, we observed that CLIP's vision encoder is more biased
whereas PaliGemma2's text encoder is more biased. By identifying whether bias
stems more from vision or text encoders, our work enables more targeted and
effective bias mitigation strategies in future multi-modal systems.

</details>


### [117] [Levarging Learning Bias for Noisy Anomaly Detection](https://arxiv.org/abs/2508.07441)
*Yuxin Zhang,Yunkang Cao,Yuqi Cheng,Yihan Sun,Weiming Shen*

Main category: cs.CV

TL;DR: 该论文提出了一种两阶段框架，利用模型的学习偏差解决完全无监督图像异常检测（FUIAD）中训练数据可能包含未标记异常的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设训练数据无异常，但实际数据可能被污染，导致模型将异常误认为正常，影响检测性能。

Method: 第一阶段通过分区训练集、训练子模型并聚合异常分数来净化数据集；第二阶段在净化后的数据上训练最终检测器。

Result: 在Real-IAD基准测试中，该方法在不同噪声条件下表现出优异的异常检测和定位性能。

Conclusion: 该框架具有模型无关性，适用于实际场景中的不完美训练数据，并通过学习偏差的利用提升了检测效果。

Abstract: This paper addresses the challenge of fully unsupervised image anomaly
detection (FUIAD), where training data may contain unlabeled anomalies.
Conventional methods assume anomaly-free training data, but real-world
contamination leads models to absorb anomalies as normal, degrading detection
performance. To mitigate this, we propose a two-stage framework that
systematically exploits inherent learning bias in models. The learning bias
stems from: (1) the statistical dominance of normal samples, driving models to
prioritize learning stable normal patterns over sparse anomalies, and (2)
feature-space divergence, where normal data exhibit high intra-class
consistency while anomalies display high diversity, leading to unstable model
responses. Leveraging the learning bias, stage 1 partitions the training set
into subsets, trains sub-models, and aggregates cross-model anomaly scores to
filter a purified dataset. Stage 2 trains the final detector on this dataset.
Experiments on the Real-IAD benchmark demonstrate superior anomaly detection
and localization performance under different noise conditions. Ablation studies
further validate the framework's contamination resilience, emphasizing the
critical role of learning bias exploitation. The model-agnostic design ensures
compatibility with diverse unsupervised backbones, offering a practical
solution for real-world scenarios with imperfect training data. Code is
available at https://github.com/hustzhangyuxin/LLBNAD.

</details>


### [118] [Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines](https://arxiv.org/abs/2508.07450)
*Suman Kunwar,Prabesh Rai*

Main category: cs.CV

TL;DR: 研究比较了多种医疗废物分类模型，发现YOLOv5-s准确率最高（95.06%），但推理速度略慢于YOLOv8-n。EfficientNet-B0表现也不错（93.22%），但推理时间最长。最终部署了YOLOv5-s模型，并建议进一步优化数据。


<details>
  <summary>Details</summary>
Motivation: 尼泊尔医疗设施增加导致医疗废物管理挑战加剧，不当处理会引发污染和传染病传播，因此需要高效分类方法。

Method: 采用分层K折技术（5折）比较ResNeXt-50、EfficientNet-B0、MobileNetV3-S、YOLOv8-n和YOLOv5-s模型。

Result: YOLOv5-s准确率最高（95.06%），EfficientNet-B0次之（93.22%），但推理时间较长。通过重复ANOVA验证统计显著性。

Conclusion: 部署了YOLOv5-s模型，并建议未来优化数据和本地化上下文。

Abstract: The increasing number of Health Care facilities in Nepal has also added up
the challenges on managing health care waste (HCW). Improper segregation and
disposal of HCW leads to the contamination, spreading of infectious diseases
and puts a risk of waste handlers. This study benchmarks the state of the art
waste classification models: ResNeXt-50, EfficientNet-B0, MobileNetV3-S,
YOLOv8-n and YOLOv5-s using Stratified K-fold techniques where we use 5 folds
on combined HCW data, and found that the YOLOv5-s achieved higher of 95.06%
accuracy but fell short few milliseconds in inference speed with YOLOv8-n
model. The EfficientNet-B0 showed promising results of 93.22% accuracy but took
the highest inference time. A repetitive ANOVA was performed to see statistical
significance and the best performing model (YOLOv5-s) was deployed to the web
with mapped bin color using Nepal's HCW management standards for public usage.
Further work on the data was suggested along with localized context.

</details>


### [119] [AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning](https://arxiv.org/abs/2508.07470)
*Siminfar Samakoush Galougah,Rishie Raj,Sanjoy Chowdhury,Sayan Nag,Ramani Duraiswami*

Main category: cs.CV

TL;DR: AURA是一个新的音频-视觉基准测试，旨在评估跨模态推理能力，避免单模态捷径，并引入AuraScore衡量推理保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试过于关注最终答案准确性，忽略了推理过程，难以区分真实理解与错误推理或幻觉导致的正确答案。

Method: AURA包含六个认知领域的挑战性问题，设计为无法通过单模态回答，并提出了AuraScore评估推理保真度。

Result: 评估显示，尽管模型在某些任务上准确率高达92%，但推理保真度低于45%，表明模型常通过错误逻辑得出正确答案。

Conclusion: AURA填补了多模态评估的空白，为更稳健的模型评估提供了工具。

Abstract: Current audio-visual (AV) benchmarks focus on final answer accuracy,
overlooking the underlying reasoning process. This makes it difficult to
distinguish genuine comprehension from correct answers derived through flawed
reasoning or hallucinations. To address this, we introduce AURA (Audio-visual
Understanding and Reasoning Assessment), a benchmark for evaluating the
cross-modal reasoning capabilities of Audio-Visual Large Language Models
(AV-LLMs) and Omni-modal Language Models (OLMs). AURA includes questions across
six challenging cognitive domains, such as causality, timbre and pitch, tempo
and AV synchronization, unanswerability, implicit distractions, and skill
profiling, explicitly designed to be unanswerable from a single modality. This
forces models to construct a valid logical path grounded in both audio and
video, setting AURA apart from AV datasets that allow uni-modal shortcuts. To
assess reasoning traces, we propose a novel metric, AuraScore, which addresses
the lack of robust tools for evaluating reasoning fidelity. It decomposes
reasoning into two aspects: (i) Factual Consistency - whether reasoning is
grounded in perceptual evidence, and (ii) Core Inference - the logical validity
of each reasoning step. Evaluations of SOTA models on AURA reveal a critical
reasoning gap: although models achieve high accuracy (up to 92% on some tasks),
their Factual Consistency and Core Inference scores fall below 45%. This
discrepancy highlights that models often arrive at correct answers through
flawed logic, underscoring the need for our benchmark and paving the way for
more robust multimodal evaluation.

</details>


### [120] [Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution](https://arxiv.org/abs/2508.07483)
*Pranav Chougule*

Main category: cs.CV

TL;DR: 本文比较了摄影测量与高斯泼溅技术在3D模型重建和视图合成中的表现，开发了改进的高斯泼溅工具，并展示了其在提升摄影测量质量方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究目的是评估摄影测量与高斯泼溅技术在3D重建和视图合成中的性能差异，探索高斯泼溅在生成高质量新视图及改进摄影测量模型中的应用。

Method: 通过构建真实场景图像数据集，使用两种方法生成3D模型，并采用SSIM、PSNR、LPIPS和lp/mm分辨率指标进行评估。开发了改进的高斯泼溅工具以支持Blender环境中的新视图渲染。

Result: 结果表明，高斯泼溅能生成高质量新视图，并可能提升摄影测量模型的精度。比较分析揭示了两者的优缺点。

Conclusion: 高斯泼溅在3D重建和视图合成中具有潜力，尤其在扩展现实（XR）、摄影测量和自动驾驶模拟等领域有应用价值。

Abstract: In this paper, I present a comprehensive study comparing Photogrammetry and
Gaussian Splatting techniques for 3D model reconstruction and view synthesis. I
created a dataset of images from a real-world scene and constructed 3D models
using both methods. To evaluate the performance, I compared the models using
structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), learned
perceptual image patch similarity (LPIPS), and lp/mm resolution based on the
USAF resolution chart. A significant contribution of this work is the
development of a modified Gaussian Splatting repository, which I forked and
enhanced to enable rendering images from novel camera poses generated in the
Blender environment. This innovation allows for the synthesis of high-quality
novel views, showcasing the flexibility and potential of Gaussian Splatting. My
investigation extends to an augmented dataset that includes both original
ground images and novel views synthesized via Gaussian Splatting. This
augmented dataset was employed to generate a new photogrammetry model, which
was then compared against the original photogrammetry model created using only
the original images. The results demonstrate the efficacy of using Gaussian
Splatting to generate novel high-quality views and its potential to improve
photogrammetry-based 3D reconstructions. The comparative analysis highlights
the strengths and limitations of both approaches, providing valuable
information for applications in extended reality (XR), photogrammetry, and
autonomous vehicle simulations. Code is available at
https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git.

</details>


### [121] [VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding](https://arxiv.org/abs/2508.07493)
*Jian Chen,Ming Li,Jihyung Kil,Chenguang Wang,Tong Yu,Ryan Rossi,Tianyi Zhou,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

TL;DR: VisR-Bench是一个多语言基准测试，用于长文档中的问题驱动多模态检索，填补了现有基准测试的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注英文文档检索或单页图像的多语言问答，缺乏对多语言长文档多模态检索的支持。

Method: 引入VisR-Bench，包含超过35K高质量QA对和1.2K文档，涵盖16种语言和三种问题类型（图表、文本和表格）。

Result: 评估显示，MLLMs显著优于基于文本和多模态编码器的方法，但在结构化表格和低资源语言上仍有困难。

Conclusion: VisR-Bench为多语言视觉检索提供了细粒度评估，揭示了当前模型的挑战和改进方向。

Abstract: Most organizational data in this world are stored as documents, and visual
retrieval plays a crucial role in unlocking the collective intelligence from
all these documents. However, existing benchmarks focus on English-only
document retrieval or only consider multilingual question-answering on a
single-page image. To bridge this gap, we introduce VisR-Bench, a multilingual
benchmark designed for question-driven multimodal retrieval in long documents.
Our benchmark comprises over 35K high-quality QA pairs across 1.2K documents,
enabling fine-grained evaluation of multimodal retrieval. VisR-Bench spans
sixteen languages with three question types (figures, text, and tables),
offering diverse linguistic and question coverage. Unlike prior datasets, we
include queries without explicit answers, preventing models from relying on
superficial keyword matching. We evaluate various retrieval models, including
text-based methods, multimodal encoders, and MLLMs, providing insights into
their strengths and limitations. Our results show that while MLLMs
significantly outperform text-based and multimodal encoder models, they still
struggle with structured tables and low-resource languages, highlighting key
challenges in multilingual visual retrieval.

</details>


### [122] [From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials](https://arxiv.org/abs/2508.07514)
*Artzai Picon,Itziar Eguskiza,Daniel Mugica,Javier Romero,Carlos Javier Jimenez,Eric White,Gabriel Do-Lago-Junqueira,Christian Klukas,Ramon Navarra-Mestre*

Main category: cs.CV

TL;DR: 论文提出了一种改进的分割模型，结合自监督视觉模型和植物分类学的层次推理，用于自动化作物和杂草的物种识别与损害分类，显著提升了效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统的手动视觉评估耗时、费力且主观，自动化识别因视觉差异微小而具有挑战性，但能显著提升效率和一致性。

Method: 结合自监督视觉模型和植物分类学的层次推理，使用多国多年数据训练，并在不同设备和地理条件下测试模型的鲁棒性。

Result: 模型显著提升了物种识别（F1-score: 0.52到0.85）和损害分类（F1-score: 0.28到0.44）的性能，在领域偏移下仍保持较强表现。

Conclusion: 模型具有鲁棒性和实际应用价值，已部署于BASF的表型分析流程中，支持大规模自动化监测。

Abstract: Field trials are vital in herbicide research and development to assess
effects on crops and weeds under varied conditions. Traditionally, evaluations
rely on manual visual assessments, which are time-consuming, labor-intensive,
and subjective. Automating species and damage identification is challenging due
to subtle visual differences, but it can greatly enhance efficiency and
consistency.
  We present an improved segmentation model combining a general-purpose
self-supervised visual model with hierarchical inference based on botanical
taxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain
using digital and mobile cameras, the model was tested on digital camera data
(year 2023) and drone imagery from the United States, Germany, and Spain (year
2024) to evaluate robustness under domain shift. This cross-device evaluation
marks a key step in assessing generalization across platforms of the model.
  Our model significantly improved species identification (F1-score: 0.52 to
0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to
0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone
images), it maintained strong performance with moderate degradation (species:
F1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where
earlier models failed.
  These results confirm the model's robustness and real-world applicability. It
is now deployed in BASF's phenotyping pipeline, enabling large-scale, automated
crop and weed monitoring across diverse geographies.

</details>


### [123] [Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing](https://arxiv.org/abs/2508.07519)
*Joonghyuk Shin,Alchan Hwang,Yujin Kim,Daneul Kim,Jaesik Park*

Main category: cs.CV

TL;DR: 论文分析了基于Transformer的多模态扩散模型（MM-DiT）的注意力机制，提出了一种新的基于提示的图像编辑方法，适用于多种MM-DiT变体。


<details>
  <summary>Details</summary>
Motivation: 传统U-Net架构被Transformer扩散模型取代，MM-DiT成为主流，但其双向注意力机制对现有编辑技术提出挑战。

Method: 通过分解注意力矩阵为四个块，分析其特性，提出一种支持全局到局部编辑的提示方法。

Result: 研究发现了一种适用于MM-DiT的鲁棒编辑方法，适用于包括少步模型在内的多种变体。

Conclusion: 研究填补了U-Net与新兴架构之间的差距，为MM-DiT的行为模式提供了深入见解。

Abstract: Transformer-based diffusion models have recently superseded traditional U-Net
architectures, with multimodal diffusion transformers (MM-DiT) emerging as the
dominant approach in state-of-the-art models like Stable Diffusion 3 and
Flux.1. Previous approaches have relied on unidirectional cross-attention
mechanisms, with information flowing from text embeddings to image latents. In
contrast, MMDiT introduces a unified attention mechanism that concatenates
input projections from both modalities and performs a single full attention
operation, allowing bidirectional information flow between text and image
branches. This architectural shift presents significant challenges for existing
editing techniques. In this paper, we systematically analyze MM-DiT's attention
mechanism by decomposing attention matrices into four distinct blocks,
revealing their inherent characteristics. Through these analyses, we propose a
robust, prompt-based image editing method for MM-DiT that supports global to
local edits across various MM-DiT variants, including few-step models. We
believe our findings bridge the gap between existing U-Net-based methods and
emerging architectures, offering deeper insights into MMDiT's behavioral
patterns.

</details>


### [124] [Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module](https://arxiv.org/abs/2508.07528)
*Xiaotong Ji,Ryoma Bise,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种结合拒绝模块的改进方法，用于解决医学图像处理中因噪声标签和类别模糊实例对top-rank学习的干扰问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像诊断的准确性至关重要，但噪声标签和类别模糊实例会严重影响top-rank学习的效果。

Method: 通过集成一个与top-rank损失共同优化的拒绝模块，识别并减少异常值的影响。该模块通过拒绝函数评估实例的偏离程度。

Result: 在医学数据集上的实验验证表明，该方法能有效检测和减少异常值，提升诊断的可靠性和准确性。

Conclusion: 提出的方法显著提高了医学图像诊断的top-rank学习效果，为噪声和模糊实例问题提供了有效解决方案。

Abstract: In medical image processing, accurate diagnosis is of paramount importance.
Leveraging machine learning techniques, particularly top-rank learning, shows
significant promise by focusing on the most crucial instances. However,
challenges arise from noisy labels and class-ambiguous instances, which can
severely hinder the top-rank objective, as they may be erroneously placed among
the top-ranked instances. To address these, we propose a novel approach that
enhances toprank learning by integrating a rejection module. Cooptimized with
the top-rank loss, this module identifies and mitigates the impact of outliers
that hinder training effectiveness. The rejection module functions as an
additional branch, assessing instances based on a rejection function that
measures their deviation from the norm. Through experimental validation on a
medical dataset, our methodology demonstrates its efficacy in detecting and
mitigating outliers, improving the reliability and accuracy of medical image
diagnoses.

</details>


### [125] [Enhanced Generative Structure Prior for Chinese Text Image Super-resolution](https://arxiv.org/abs/2508.07537)
*Xiaoming Li,Wangmeng Zuo,Chen Change Loy*

Main category: cs.CV

TL;DR: 提出一种针对中文文本图像超分辨率（SR）的框架，通过结构先验和StyleGAN生成能力，恢复低分辨率字符的精确笔画。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注英文文本，对更复杂的中文脚本关注不足。本文旨在解决中文文本SR的挑战，恢复字符的精确结构和多样字体风格。

Method: 提出一种结构先验，结合StyleGAN生成能力，通过代码本机制限制生成空间，确保字符结构的完整性。代码本表示字符结构，StyleGAN控制字体风格。

Result: 实验表明，该方法能准确恢复低分辨率中文字符的清晰笔画，适用于不规则布局的真实场景。

Conclusion: 结构先验为中文文本SR提供了有效的字符级指导，显著提升了视觉质量。

Abstract: Faithful text image super-resolution (SR) is challenging because each
character has a unique structure and usually exhibits diverse font styles and
layouts. While existing methods primarily focus on English text, less attention
has been paid to more complex scripts like Chinese. In this paper, we introduce
a high-quality text image SR framework designed to restore the precise strokes
of low-resolution (LR) Chinese characters. Unlike methods that rely on
character recognition priors to regularize the SR task, we propose a novel
structure prior that offers structure-level guidance to enhance visual quality.
Our framework incorporates this structure prior within a StyleGAN model,
leveraging its generative capabilities for restoration. To maintain the
integrity of character structures while accommodating various font styles and
layouts, we implement a codebook-based mechanism that restricts the generative
space of StyleGAN. Each code in the codebook represents the structure of a
specific character, while the vector $w$ in StyleGAN controls the character's
style, including typeface, orientation, and location. Through the collaborative
interaction between the codebook and style, we generate a high-resolution
structure prior that aligns with LR characters both spatially and structurally.
Experiments demonstrate that this structure prior provides robust,
character-specific guidance, enabling the accurate restoration of clear strokes
in degraded characters, even for real-world LR Chinese text with irregular
layouts. Our code and pre-trained models will be available at
https://github.com/csxmli2016/MARCONetPlusPlus

</details>


### [126] [A DICOM Image De-identification Algorithm in the MIDI-B Challenge](https://arxiv.org/abs/2508.07538)
*Hongzhu Jiang,Sihan Xie,Zhiyu Wan*

Main category: cs.CV

TL;DR: 论文探讨了DICOM图像去标识化的重要性，介绍了MIDI-B挑战赛及其方法，并展示了算法的优异表现。


<details>
  <summary>Details</summary>
Motivation: 医疗图像共享需遵守隐私法规（如HIPAA、DICOM PS3.15），去标识化是保护患者隐私的关键。

Method: 采用像素掩码、日期偏移、哈希、文本识别与替换等方法，严格遵循标准处理数据。

Result: 算法在MIDI-B挑战赛中正确执行99.92%的任务，排名第二。

Conclusion: 当前方法仍有局限，未来需进一步改进。

Abstract: Image de-identification is essential for the public sharing of medical
images, particularly in the widely used Digital Imaging and Communications in
Medicine (DICOM) format as required by various regulations and standards,
including Health Insurance Portability and Accountability Act (HIPAA) privacy
rules, the DICOM PS3.15 standard, and best practices recommended by the Cancer
Imaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B)
Challenge at the 27th International Conference on Medical Image Computing and
Computer Assisted Intervention (MICCAI 2024) was organized to evaluate
rule-based DICOM image de-identification algorithms with a large dataset of
clinical DICOM images. In this report, we explore the critical challenges of
de-identifying DICOM images, emphasize the importance of removing personally
identifiable information (PII) to protect patient privacy while ensuring the
continued utility of medical data for research, diagnostics, and treatment, and
provide a comprehensive overview of the standards and regulations that govern
this process. Additionally, we detail the de-identification methods we applied
- such as pixel masking, date shifting, date hashing, text recognition, text
replacement, and text removal - to process datasets during the test phase in
strict compliance with these standards. According to the final leaderboard of
the MIDI-B challenge, the latest version of our solution algorithm correctly
executed 99.92% of the required actions and ranked 2nd out of 10 teams that
completed the challenge (from a total of 22 registered teams). Finally, we
conducted a thorough analysis of the resulting statistics and discussed the
limitations of current approaches and potential avenues for future improvement.

</details>


### [127] [Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning](https://arxiv.org/abs/2508.07539)
*Yuki Shigeyasu,Shota Harada,Akihiko Yoshizawa,Kazuhiro Terada,Naoki Nakazima,Mariyo Kurata,Hiroyuki Abe,Tetsuo Ushiku,Ryoma Bise*

Main category: cs.CV

TL;DR: 提出一种针对病理图像域偏移的新方法，通过聚类WSI特征并利用对比学习减少域间差异。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖多医院数据，但数据收集困难，因此提出利用医院内部域偏移的方法。

Method: 通过聚类非肿瘤区域的WSI特征作为域，采用两阶段对比学习（WSI级和patch级）减少域间差异。

Result: 有效减少了病理图像中的域偏移问题。

Conclusion: 该方法为病理图像域偏移问题提供了一种实用的解决方案。

Abstract: In this paper, we address domain shifts in pathological images by focusing on
shifts within whole slide images~(WSIs), such as patient characteristics and
tissue thickness, rather than shifts between hospitals. Traditional approaches
rely on multi-hospital data, but data collection challenges often make this
impractical. Therefore, the proposed domain generalization method captures and
leverages intra-hospital domain shifts by clustering WSI-level features from
non-tumor regions and treating these clusters as domains. To mitigate domain
shift, we apply contrastive learning to reduce feature gaps between WSI pairs
from different clusters. The proposed method introduces a two-stage contrastive
learning approach WSI-level and patch-level contrastive learning to minimize
these gaps effectively.

</details>


### [128] [CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts](https://arxiv.org/abs/2508.07540)
*Junuk Cha,Jihyeon Kim*

Main category: cs.CV

TL;DR: 论文提出了一种结合CoT推理的3D人体姿态生成框架，解决了现有模型依赖低层次提示的问题，并通过数据合成管道生成训练数据。实验证明其模型能有效从抽象文本生成准确姿态。


<details>
  <summary>Details</summary>
Motivation: 现有文本到姿态生成模型依赖低层次提示，而人类倾向于使用抽象语言描述动作，导致实际应用中的挑战。

Method: 引入CoT推理框架，将抽象提示转化为准确3D姿态；提出数据合成管道生成抽象提示、详细提示和对应姿态的三元组。

Result: 实验表明，CoT-Pose模型能从抽象文本生成语义对齐的合理姿态。

Conclusion: 研究强调了高层次理解在姿态生成中的重要性，为推理增强方法开辟了新方向。

Abstract: Recent advances in multi-modal large language models (MLLMs) and
chain-of-thought (CoT) reasoning have led to significant progress in image and
text generation tasks. However, the field of 3D human pose generation still
faces critical limitations. Most existing text-to-pose models rely heavily on
detailed (low-level) prompts that explicitly describe joint configurations. In
contrast, humans tend to communicate actions and intentions using abstract
(high-level) language. This mismatch results in a practical challenge for
deploying pose generation systems in real-world scenarios. To bridge this gap,
we introduce a novel framework that incorporates CoT reasoning into the pose
generation process, enabling the interpretation of abstract prompts into
accurate 3D human poses. We further propose a data synthesis pipeline that
automatically generates triplets of abstract prompts, detailed prompts, and
corresponding 3D poses for training process. Experimental results demonstrate
that our reasoning-enhanced model, CoT-Pose, can effectively generate plausible
and semantically aligned poses from abstract textual inputs. This work
highlights the importance of high-level understanding in pose generation and
opens new directions for reasoning-enhanced approach for human pose generation.

</details>


### [129] [Commentary Generation for Soccer Highlights](https://arxiv.org/abs/2508.07543)
*Chidaksh Ravuru*

Main category: cs.CV

TL;DR: 论文扩展了MatchVoice模型，用于足球集锦的实时解说生成，通过实验验证了不同训练配置和硬件限制的影响，并探讨了窗口大小对零样本性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有系统如SoccerNet-Caption在视频内容与解说之间的细粒度对齐方面存在不足，MatchTime的MatchVoice模型通过粗粒度和细粒度对齐技术改进了这一问题。本文旨在进一步优化解说生成性能。

Method: 扩展MatchVoice模型，使用GOAL数据集（专注于短片段而非整场比赛），并进行实验以复现MatchTime结果，评估不同训练配置和硬件限制的影响。

Result: MatchVoice展示了良好的泛化能力，但需要整合更广泛的视频-语言技术以进一步提升性能。

Conclusion: 研究强调了整合跨领域技术的重要性，并提供了代码开源。

Abstract: Automated soccer commentary generation has evolved from template-based
systems to advanced neural architectures, aiming to produce real-time
descriptions of sports events. While frameworks like SoccerNet-Caption laid
foundational work, their inability to achieve fine-grained alignment between
video content and commentary remains a significant challenge. Recent efforts
such as MatchTime, with its MatchVoice model, address this issue through coarse
and fine-grained alignment techniques, achieving improved temporal
synchronization. In this paper, we extend MatchVoice to commentary generation
for soccer highlights using the GOAL dataset, which emphasizes short clips over
entire games. We conduct extensive experiments to reproduce the original
MatchTime results and evaluate our setup, highlighting the impact of different
training configurations and hardware limitations. Furthermore, we explore the
effect of varying window sizes on zero-shot performance. While MatchVoice
exhibits promising generalization capabilities, our findings suggest the need
for integrating techniques from broader video-language domains to further
enhance performance. Our code is available at
https://github.com/chidaksh/SoccerCommentary.

</details>


### [130] [Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning](https://arxiv.org/abs/2508.07548)
*Takehiro Yamane,Itaru Tsuge,Susumu Saito,Ryoma Bise*

Main category: cs.CV

TL;DR: 提出了一种用于医学图像分割的新型伪标签方法，通过PU学习选择有效伪标签。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中伪标签选择的问题，尤其是在背景区域多样的情况下。

Method: 采用PU学习（仅使用正样本和未标记数据）为每张未标记图像获取区分前景和背景区域的度量。

Result: 实验结果表明该方法有效。

Conclusion: 该方法能够灵活选择伪标签，适用于多样背景区域。

Abstract: This paper proposes a novel pseudo-labeling method for medical image
segmentation that can perform learning on ``individual images'' to select
effective pseudo-labels. We introduce Positive and Unlabeled Learning (PU
learning), which uses only positive and unlabeled data for binary
classification problems, to obtain the appropriate metric for discriminating
foreground and background regions on each unlabeled image. Our PU learning
makes us easy to select pseudo-labels for various background regions. The
experimental results show the effectiveness of our method.

</details>


### [131] [Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring](https://arxiv.org/abs/2508.07552)
*Ludan Zhang,Sihan Wang,Yuqi Dai,Shuofei Qiao,Lei He*

Main category: cs.CV

TL;DR: 本文提出了一种基于特征图收敛分数（FMCS）的独立评估方法，通过双粒度动态加权评分系统（DG-DWSS）和CLIP-FMQE-Net网络，提升自动驾驶感知和规划中特征图的质量评估与模型性能。


<details>
  <summary>Details</summary>
Motivation: 端到端模型在自动驾驶中缺乏中间功能模块的显式监督信号，导致机制不透明且可解释性差，传统方法难以独立评估和训练这些模块。

Method: 构建了基于特征图-真值表示相似性的评估框架，提出FMCS和DG-DWSS，并开发了CLIP-FMQE-Net网络，实现特征图质量的实时分析。

Result: 在NuScenes数据集上，集成评估模块后，3D目标检测性能提升，NDS增益达3.89%。

Conclusion: 该方法有效提升了特征表示质量和整体模型性能，验证了其可行性和实用性。

Abstract: End-to-end models are emerging as the mainstream in autonomous driving
perception and planning. However, the lack of explicit supervision signals for
intermediate functional modules leads to opaque operational mechanisms and
limited interpretability, making it challenging for traditional methods to
independently evaluate and train these modules. Pioneering in the issue, this
study builds upon the feature map-truth representation similarity-based
evaluation framework and proposes an independent evaluation method based on
Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted
Scoring System (DG-DWSS) is constructed, formulating a unified quantitative
metric - Feature Map Quality Score - to enable comprehensive evaluation of the
quality of feature maps generated by functional modules. A CLIP-based Feature
Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining
feature-truth encoders and quality score prediction heads to enable real-time
quality analysis of feature maps generated by functional modules. Experimental
results on the NuScenes dataset demonstrate that integrating our evaluation
module into the training improves 3D object detection performance, achieving a
3.89 percent gain in NDS. These results verify the effectiveness of our method
in enhancing feature representation quality and overall model performance.

</details>


### [132] [Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation](https://arxiv.org/abs/2508.07557)
*Minghao Yin,Yukang Cao,Songyou Peng,Kai Han*

Main category: cs.CV

TL;DR: Splat4D是一个从单目视频生成高质量4D内容的新框架，通过多视角渲染、不一致性识别、视频扩散模型和非对称U-Net优化，实现了时空一致性和高保真度。


<details>
  <summary>Details</summary>
Motivation: 解决从单目视频生成4D内容时面临的时空一致性、细节保留和用户指导有效性等挑战。

Method: 采用多视角渲染、不一致性识别、视频扩散模型和非对称U-Net进行优化。

Result: 在公开基准测试中表现优异，支持文本/图像条件生成、4D人体生成和文本引导编辑等应用。

Conclusion: Splat4D在4D内容生成中表现出高效性和多功能性，满足用户需求。

Abstract: Generating high-quality 4D content from monocular videos for applications
such as digital humans and AR/VR poses challenges in ensuring temporal and
spatial consistency, preserving intricate details, and incorporating user
guidance effectively. To overcome these challenges, we introduce Splat4D, a
novel framework enabling high-fidelity 4D content generation from a monocular
video. Splat4D achieves superior performance while maintaining faithful
spatial-temporal coherence by leveraging multi-view rendering, inconsistency
identification, a video diffusion model, and an asymmetric U-Net for
refinement. Through extensive evaluations on public benchmarks, Splat4D
consistently demonstrates state-of-the-art performance across various metrics,
underscoring the efficacy of our approach. Additionally, the versatility of
Splat4D is validated in various applications such as text/image conditioned 4D
generation, 4D human generation, and text-guided content editing, producing
coherent outcomes following user instructions.

</details>


### [133] [Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2508.07570)
*Khanh-Binh Nguyen,Phuoc-Nguyen Bui,Hyunseung Choo,Duc Thanh Nguyen*

Main category: cs.CV

TL;DR: 论文提出了一种名为ACE的框架，通过动态缓存和自适应决策边界解决视觉语言模型在分布偏移下的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在零样本泛化中表现优异，但在分布偏移时性能下降，尤其是在无标注数据的情况下。现有缓存方法因不可靠的置信度指标和刚性决策边界而受限。

Method: 提出Adaptive Cache Enhancement (ACE)框架，通过动态存储高置信度或低熵图像嵌入，并利用动态类别特定阈值优化决策边界。

Result: 在15个基准数据集上的实验表明，ACE在分布偏移场景下表现优异，优于现有方法。

Conclusion: ACE通过自适应缓存和决策边界，显著提升了视觉语言模型在分布偏移下的鲁棒性和泛化能力。

Abstract: Vision-language models (VLMs) exhibit remarkable zero-shot generalization but
suffer performance degradation under distribution shifts in downstream tasks,
particularly in the absence of labeled data. Test-Time Adaptation (TTA)
addresses this challenge by enabling online optimization of VLMs during
inference, eliminating the need for annotated data. Cache-based TTA methods
exploit historical knowledge by maintaining a dynamic memory cache of
low-entropy or high-confidence samples, promoting efficient adaptation to
out-of-distribution data. Nevertheless, these methods face two critical
challenges: (1) unreliable confidence metrics under significant distribution
shifts, resulting in error accumulation within the cache and degraded
adaptation performance; and (2) rigid decision boundaries that fail to
accommodate substantial distributional variations, leading to suboptimal
predictions. To overcome these limitations, we introduce the Adaptive Cache
Enhancement (ACE) framework, which constructs a robust cache by selectively
storing high-confidence or low-entropy image embeddings per class, guided by
dynamic, class-specific thresholds initialized from zero-shot statistics and
iteratively refined using an exponential moving average and
exploration-augmented updates. This approach enables adaptive, class-wise
decision boundaries, ensuring robust and accurate predictions across diverse
visual distributions. Extensive experiments on 15 diverse benchmark datasets
demonstrate that ACE achieves state-of-the-art performance, delivering superior
robustness and generalization compared to existing TTA methods in challenging
out-of-distribution scenarios.

</details>


### [134] [Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification](https://arxiv.org/abs/2508.07577)
*Zhaorui Tan,Tan Pan,Kaizhu Huang,Weimiao Yu,Kai Yao,Chen Jiang,Qiufeng Wang,Anh Nguyen,Xin Guo,Yuan Cheng,Xi Yang*

Main category: cs.CV

TL;DR: 论文研究了LayerNorm在ViTs中的微调动态，提出了一种基于Fine-tuning Shift Ratio（FSR）的重新缩放机制，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索LayerNorm在数据稀缺和领域转移下的微调动态，填补相关研究的空白。

Method: 提出FSR量化目标训练样本的代表性，设计标量λ和循环框架优化LayerNorm微调。

Result: 实验表明，OOD任务FSR较低且λ较高，病理数据微调更接近ID设置。

Conclusion: 揭示了LayerNorm在迁移学习中的动态特性，并提供了实用的微调策略。

Abstract: LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning
dynamics under data scarcity and domain shifts remain underexplored. This paper
shows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts)
are indicative of the transitions between source and target domains; its
efficacy is contingent upon the degree to which the target training samples
accurately represent the target domain, as quantified by our proposed
Fine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet
effective rescaling mechanism using a scalar $\lambda$ that is negatively
correlated to $FSR$ to align learned LayerNorm shifts with those ideal shifts
achieved under fully representative data, combined with a cyclic framework that
further enhances the LayerNorm fine-tuning. Extensive experiments across
natural and pathological images, in both in-distribution (ID) and
out-of-distribution (OOD) settings, and various target training sample regimes
validate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher
$\lambda$ in comparison to ID cases, especially with scarce data, indicating
under-represented target training samples. Moreover, ViTFs fine-tuned on
pathological data behave more like ID settings, favoring conservative LayerNorm
updates. Our findings illuminate the underexplored dynamics of LayerNorm in
transfer learning and provide practical strategies for LayerNorm fine-tuning.

</details>


### [135] [GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm](https://arxiv.org/abs/2508.07585)
*Yu-Huan Wu,Wei Liu,Zi-Xuan Zhu,Zizhou Wang,Yong Liu,Liangli Zhen*

Main category: cs.CV

TL;DR: GAPNet是一种轻量级网络，基于粒度感知范式，用于图像和视频显著目标检测（SOD），通过多尺度解码器侧输出优化特征利用和语义解释。


<details>
  <summary>Details</summary>
Motivation: 现有SOD模型依赖重型骨干网络，计算成本高，限制了在边缘设备等实际场景中的应用。

Method: 采用粒度感知连接，设计粒度金字塔卷积（GPC）和跨尺度注意力（CSA）模块，结合自注意力模块学习全局信息。

Result: 在轻量级图像和视频SOD模型中达到新的最优性能。

Conclusion: GAPNet通过高效特征融合和适当监督，显著提升了轻量级SOD模型的性能。

Abstract: Recent salient object detection (SOD) models predominantly rely on
heavyweight backbones, incurring substantial computational cost and hindering
their practical application in various real-world settings, particularly on
edge devices. This paper presents GAPNet, a lightweight network built on the
granularity-aware paradigm for both image and video SOD. We assign saliency
maps of different granularities to supervise the multi-scale decoder
side-outputs: coarse object locations for high-level outputs and fine-grained
object boundaries for low-level outputs. Specifically, our decoder is built
with granularity-aware connections which fuse high-level features of low
granularity and low-level features of high granularity, respectively. To
support these connections, we design granular pyramid convolution (GPC) and
cross-scale attention (CSA) modules for efficient fusion of low-scale and
high-scale features, respectively. On top of the encoder, a self-attention
module is built to learn global information, enabling accurate object
localization with negligible computational cost. Unlike traditional U-Net-based
approaches, our proposed method optimizes feature utilization and semantic
interpretation while applying appropriate supervision at each processing stage.
Extensive experiments show that the proposed method achieves a new
state-of-the-art performance among lightweight image and video SOD models. Code
is available at https://github.com/yuhuan-wu/GAPNet.

</details>


### [136] [From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users](https://arxiv.org/abs/2508.07596)
*Shahroz Tariq,Simon S. Woo,Priyanka Singh,Irena Irmalasari,Saakshi Gupta,Dev Gupta*

Main category: cs.CV

TL;DR: DF-P2E是一个多模态框架，通过视觉、语义和叙事层解释，提升深度伪造检测的可解释性和可访问性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对数字完整性构成严重威胁，现有检测系统缺乏透明度和解释性，限制了其在实际决策中的应用。

Method: DF-P2E包含三个模块：基于Grad-CAM的分类器、视觉字幕生成模块和叙事优化模块，结合LLM生成用户敏感的解释。

Result: 在DF40数据集上，系统实现了竞争性检测性能，并提供与Grad-CAM一致的高质量解释。

Conclusion: DF-P2E通过统一预测和解释，为可信赖和透明的AI系统提供了可扩展的解决方案。

Abstract: The proliferation of deepfake technologies poses urgent challenges and
serious risks to digital integrity, particularly within critical sectors such
as forensics, journalism, and the legal system. While existing detection
systems have made significant progress in classification accuracy, they
typically function as black-box models, offering limited transparency and
minimal support for human reasoning. This lack of interpretability hinders
their usability in real-world decision-making contexts, especially for
non-expert users. In this paper, we present DF-P2E (Deepfake: Prediction to
Explanation), a novel multimodal framework that integrates visual, semantic,
and narrative layers of explanation to make deepfake detection interpretable
and accessible. The framework consists of three modular components: (1) a
deepfake classifier with Grad-CAM-based saliency visualisation, (2) a visual
captioning module that generates natural language summaries of manipulated
regions, and (3) a narrative refinement module that uses a fine-tuned Large
Language Model (LLM) to produce context-aware, user-sensitive explanations. We
instantiate and evaluate the framework on the DF40 benchmark, the most diverse
deepfake dataset to date. Experiments demonstrate that our system achieves
competitive detection performance while providing high-quality explanations
aligned with Grad-CAM activations. By unifying prediction and explanation in a
coherent, human-aligned pipeline, this work offers a scalable approach to
interpretable deepfake detection, advancing the broader vision of trustworthy
and transparent AI systems in adversarial media environments.

</details>


### [137] [ShoulderShot: Generating Over-the-Shoulder Dialogue Videos](https://arxiv.org/abs/2508.07597)
*Yuang Zhang,Junqi Cheng,Haoyu Zhao,Jiaxi Gu,Fangyuan Zou,Zenghui Lu,Peng Shu*

Main category: cs.CV

TL;DR: ShoulderShot框架通过双镜头生成和循环视频技术，解决了对话视频生成中的角色一致性和空间连续性挑战，支持长对话生成。


<details>
  <summary>Details</summary>
Motivation: 对话视频在影视和广告中具有重要作用，但现有研究对其生成技术探索不足，尤其是角色一致性和空间连续性等问题。

Method: 结合双镜头生成与循环视频技术，实现角色一致性和空间连续性，支持长对话生成。

Result: 在镜头切换布局、空间连续性和对话长度灵活性上优于现有方法。

Conclusion: ShoulderShot为实际对话视频生成提供了新的可能性。

Abstract: Over-the-shoulder dialogue videos are essential in films, short dramas, and
advertisements, providing visual variety and enhancing viewers' emotional
connection. Despite their importance, such dialogue scenes remain largely
underexplored in video generation research. The main challenges include
maintaining character consistency across different shots, creating a sense of
spatial continuity, and generating long, multi-turn dialogues within limited
computational budgets. Here, we present ShoulderShot, a framework that combines
dual-shot generation with looping video, enabling extended dialogues while
preserving character consistency. Our results demonstrate capabilities that
surpass existing methods in terms of shot-reverse-shot layout, spatial
continuity, and flexibility in dialogue length, thereby opening up new
possibilities for practical dialogue video generation. Videos and comparisons
are available at https://shouldershot.github.io.

</details>


### [138] [LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation](https://arxiv.org/abs/2508.07603)
*Wenhui Song,Hanhui Li,Jiehui Huang,Panwen Hu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang*

Main category: cs.CV

TL;DR: LaVieID是一种新的局部自回归视频扩散框架，旨在解决身份保持的文本到视频任务，通过空间和时间视角优化身份信息保留。


<details>
  <summary>Details</summary>
Motivation: 现有扩散变换器（DiTs）在全局生成过程中容易丢失身份信息，LaVieID旨在解决这一问题。

Method: 引入局部路由器显式表示细粒度局部面部结构的潜在状态，并集成时间自回归模块以增强帧间身份一致性。

Result: LaVieID能够生成高保真个性化视频，并达到最先进的性能。

Conclusion: LaVieID通过空间和时间优化，显著提升了身份保持能力，为文本到视频任务提供了高效解决方案。

Abstract: In this paper, we present LaVieID, a novel \underline{l}ocal
\underline{a}utoregressive \underline{vi}d\underline{e}o diffusion framework
designed to tackle the challenging \underline{id}entity-preserving
text-to-video task. The key idea of LaVieID is to mitigate the loss of identity
information inherent in the stochastic global generation process of diffusion
transformers (DiTs) from both spatial and temporal perspectives. Specifically,
unlike the global and unstructured modeling of facial latent states in existing
DiTs, LaVieID introduces a local router to explicitly represent latent states
by weighted combinations of fine-grained local facial structures. This
alleviates undesirable feature interference and encourages DiTs to capture
distinctive facial characteristics. Furthermore, a temporal autoregressive
module is integrated into LaVieID to refine denoised latent tokens before video
decoding. This module divides latent tokens temporally into chunks, exploiting
their long-range temporal dependencies to predict biases for rectifying tokens,
thereby significantly enhancing inter-frame identity consistency. Consequently,
LaVieID can generate high-fidelity personalized videos and achieve
state-of-the-art performance. Our code and models are available at
https://github.com/ssugarwh/LaVieID.

</details>


### [139] [X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning](https://arxiv.org/abs/2508.07607)
*Jian Ma,Xujie Zhu,Zihao Pan,Qirong Peng,Xu Guo,Chen Chen,Haonan Lu*

Main category: cs.CV

TL;DR: 论文提出了X2Edit数据集和任务感知的MoE-LoRA训练方法，解决了现有开源数据集和编辑模块的不足。


<details>
  <summary>Details</summary>
Motivation: 现有开源数据集和编辑模块无法满足需求，需要更高质量的数据集和兼容社区生成模型的编辑方法。

Method: 构建了X2Edit数据集（370万高质量数据），设计了任务感知的MoE-LoRA训练方法，并引入对比学习。

Result: 模型编辑性能优异，数据集显著优于现有开源数据集。

Conclusion: X2Edit数据集和训练方法为图像编辑任务提供了高质量解决方案。

Abstract: Existing open-source datasets for arbitrary-instruction image editing remain
suboptimal, while a plug-and-play editing module compatible with
community-prevalent generative models is notably absent. In this paper, we
first introduce the X2Edit Dataset, a comprehensive dataset covering 14 diverse
editing tasks, including subject-driven generation. We utilize the
industry-leading unified image generation models and expert models to construct
the data. Meanwhile, we design reasonable editing instructions with the VLM and
implement various scoring mechanisms to filter the data. As a result, we
construct 3.7 million high-quality data with balanced categories. Second, to
better integrate seamlessly with community image generation models, we design
task-aware MoE-LoRA training based on FLUX.1, with only 8\% of the parameters
of the full model. To further improve the final performance, we utilize the
internal representations of the diffusion model and define positive/negative
samples based on image editing types to introduce contrastive learning.
Extensive experiments demonstrate that the model's editing performance is
competitive among many excellent models. Additionally, the constructed dataset
exhibits substantial advantages over existing open-source datasets. The
open-source code, checkpoints, and datasets for X2Edit can be found at the
following link: https://github.com/OPPO-Mente-Lab/X2Edit.

</details>


### [140] [An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View](https://arxiv.org/abs/2508.07618)
*Hyoung Suk Park,Kiwan Jeon*

Main category: cs.CV

TL;DR: 提出一种两阶段方法，通过隐式神经表示（INR）生成先验图像并校正投影数据，以减少牙科CBCT中的截断伪影。


<details>
  <summary>Details</summary>
Motivation: 小型探测器导致视野截断，影响迭代重建图像质量。

Method: 第一阶段用INR生成先验图像并校正投影数据；第二阶段用校正数据进行常规迭代重建。

Result: 两阶段方法有效抑制截断伪影，提升图像质量。

Conclusion: 该方法为牙科CBCT提供了一种有效的截断伪影解决方案。

Abstract: In dental cone-beam computed tomography (CBCT), compact and cost-effective
system designs often use small detectors, resulting in a truncated field of
view (FOV) that does not fully encompass the patient's head. In iterative
reconstruction approaches, the discrepancy between the actual projection and
the forward projection within the truncated FOV accumulates over iterations,
leading to significant degradation in the reconstructed image quality. In this
study, we propose a two-stage approach to mitigate truncation artifacts in
dental CBCT. In the first stage, we employ Implicit Neural Representation
(INR), leveraging its superior representation power, to generate a prior image
over an extended region so that its forward projection fully covers the
patient's head. To reduce computational and memory burdens, INR reconstruction
is performed with a coarse voxel size. The forward projection of this prior
image is then used to estimate the discrepancy due to truncated FOV in the
measured projection data. In the second stage, the discrepancy-corrected
projection data is utilized in a conventional iterative reconstruction process
within the truncated region. Our numerical results demonstrate that the
proposed two-grid approach effectively suppresses truncation artifacts, leading
to improved CBCT image quality.

</details>


### [141] [SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation](https://arxiv.org/abs/2508.07621)
*Yunsung Chung,Chanho Lim,Ghassan Bidaoui,Christian Massad,Nassir Marrouche,Jihun Hamm*

Main category: cs.CV

TL;DR: SOFA是一个深度学习框架，用于模拟和优化房颤消融手术，预测复发风险并优化手术参数，降低22.18%的复发风险。


<details>
  <summary>Details</summary>
Motivation: 房颤消融手术效果差异大，难以评估和改进，需解决复发预测和手术参数优化问题。

Method: SOFA通过生成消融后图像模拟手术效果，预测复发风险，并优化手术参数以减少风险。

Result: SOFA能准确合成消融后图像，优化方案使复发风险降低22.18%。

Conclusion: SOFA首次整合手术效果模拟、复发预测和参数优化，为个性化房颤消融提供新工具。

Abstract: Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with
catheter ablation procedures, but procedural outcomes are highly variable.
Evaluating and improving ablation efficacy is challenging due to the complex
interaction between patient-specific tissue and procedural factors. This paper
asks two questions: Can AF recurrence be predicted by simulating the effects of
procedural parameters? How should we ablate to reduce AF recurrence? We propose
SOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel
deep-learning framework that addresses these questions. SOFA first simulates
the outcome of an ablation strategy by generating a post-ablation image
depicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and
the specific procedural parameters used (e.g., ablation locations, duration,
temperature, power, and force). During this simulation, it predicts AF
recurrence risk. Critically, SOFA then introduces an optimization scheme that
refines these procedural parameters to minimize the predicted risk. Our method
leverages a multi-modal, multi-view generator that processes 2.5D
representations of the atrium. Quantitative evaluations show that SOFA
accurately synthesizes post-ablation images and that our optimization scheme
leads to a 22.18\% reduction in the model-predicted recurrence risk. To the
best of our knowledge, SOFA is the first framework to integrate the simulation
of procedural effects, recurrence prediction, and parameter optimization,
offering a novel tool for personalizing AF ablation.

</details>


### [142] [Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction](https://arxiv.org/abs/2508.07624)
*Vishakha Lall,Yisi Liu*

Main category: cs.CV

TL;DR: 提出了一种基于图神经网络的后期处理流程，利用空间关系纠正目标检测中的异常，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测模型未能充分利用静态环境中物体的空间布局一致性，导致预测不一致或误检。

Method: 使用图神经网络（GNN）建模物体间的空间关系，纠正异常检测结果。

Result: 实验表明，该方法显著提升检测性能，mAP@50最高提升4%。

Conclusion: 利用环境的空间结构可显著提升目标检测系统的可靠性。

Abstract: In many real-world applications involving static environments, the spatial
layout of objects remains consistent across instances. However,
state-of-the-art object detection models often fail to leverage this spatial
prior, resulting in inconsistent predictions, missed detections, or
misclassifications, particularly in cluttered or occluded scenes. In this work,
we propose a graph-based post-processing pipeline that explicitly models the
spatial relationships between objects to correct detection anomalies in
egocentric frames. Using a graph neural network (GNN) trained on manually
annotated data, our model identifies invalid object class labels and predicts
corrected class labels based on their neighbourhood context. We evaluate our
approach both as a standalone anomaly detection and correction framework and as
a post-processing module for standard object detectors such as YOLOv7 and
RT-DETR. Experiments demonstrate that incorporating this spatial reasoning
significantly improves detection performance, with mAP@50 gains of up to 4%.
This method highlights the potential of leveraging the environment's spatial
structure to improve reliability in object detection systems.

</details>


### [143] [A Trustworthy Method for Multimodal Emotion Recognition](https://arxiv.org/abs/2508.07625)
*Junxiao Xue,Xiaozhen Liu,Jie Wang,Xuecheng Wu,Bin Wu*

Main category: cs.CV

TL;DR: 提出了一种基于不确定性估计的信任情感识别方法（TER），通过置信度评估预测可靠性，并在多模态数据中实现高性能。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别方法虽有效但模型复杂，且对噪声和异常数据可靠性不足，需提升预测可信度。

Method: TER利用不确定性估计计算预测置信度，结合多模态结果输出可信预测，并引入信任精度和召回率等新评估标准。

Result: TER在Music-video上达到82.40%准确率，在IEMOCAP和Music-video上的信任F1分数分别为0.7511和0.9035。

Conclusion: TER通过置信度模块提升了模型的可靠性和鲁棒性，实验验证了其有效性，性能优于现有方法。

Abstract: Existing emotion recognition methods mainly focus on enhancing performance by
employing complex deep models, typically resulting in significantly higher
model complexity. Although effective, it is also crucial to ensure the
reliability of the final decision, especially for noisy, corrupted and
out-of-distribution data. To this end, we propose a novel emotion recognition
method called trusted emotion recognition (TER), which utilizes uncertainty
estimation to calculate the confidence value of predictions. TER combines the
results from multiple modalities based on their confidence values to output the
trusted predictions. We also provide a new evaluation criterion to assess the
reliability of predictions. Specifically, we incorporate trusted precision and
trusted recall to determine the trusted threshold and formulate the trusted
Acc. and trusted F1 score to evaluate the model's trusted performance. The
proposed framework combines the confidence module that accordingly endows the
model with reliability and robustness against possible noise or corruption. The
extensive experimental results validate the effectiveness of our proposed
model. The TER achieves state-of-the-art performance on the Music-video,
achieving 82.40% Acc. In terms of trusted performance, TER outperforms other
methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511
and 0.9035, respectively.

</details>


### [144] [LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering](https://arxiv.org/abs/2508.07647)
*Xiaohang Zhan,Dingming Liu*

Main category: cs.CV

TL;DR: 提出了一种无需训练的图像生成算法，通过体积渲染原理精确控制图像中物体的遮挡关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖提示或布局控制遮挡，但缺乏精确性，需要一种无需重新训练的方法实现精确遮挡控制。

Method: 利用预训练扩散模型，在潜在空间中基于遮挡关系和透射率进行体积渲染。

Result: 在遮挡准确性上显著优于现有方法，并能调整物体透明度、密度等效果。

Conclusion: 该方法无需重新训练即可实现精确遮挡控制，并支持多种视觉效果调整。

Abstract: We propose a novel training-free image generation algorithm that precisely
controls the occlusion relationships between objects in an image. Existing
image generation methods typically rely on prompts to influence occlusion,
which often lack precision. While layout-to-image methods provide control over
object locations, they fail to address occlusion relationships explicitly.
Given a pre-trained image diffusion model, our method leverages volume
rendering principles to "render" the scene in latent space, guided by occlusion
relationships and the estimated transmittance of objects. This approach does
not require retraining or fine-tuning the image diffusion model, yet it enables
accurate occlusion control due to its physics-grounded foundation. In extensive
experiments, our method significantly outperforms existing approaches in terms
of occlusion accuracy. Furthermore, we demonstrate that by adjusting the
opacities of objects or concepts during rendering, our method can achieve a
variety of effects, such as altering the transparency of objects, the density
of mass (e.g., forests), the concentration of particles (e.g., rain, fog), the
intensity of light, and the strength of lens effects, etc.

</details>


### [145] [Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels](https://arxiv.org/abs/2508.07656)
*Yimin Fu,Zhunga Liu,Dongxiu Guo,Longfei Wang*

Main category: cs.CV

TL;DR: 提出了一种结合散射和深度特征的协作学习方法（CLSDF），用于处理SAR自动目标识别中的噪声标签问题，通过多模型特征融合和半监督学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 由于SAR数据标注需要专业知识，噪声标签不可避免，导致识别性能下降，现有方法主要针对图像数据，对SAR数据效果不佳。

Method: 设计多模型特征融合框架，结合散射和深度特征；利用动态图结构数据建模ASC；通过GMM划分干净和噪声标签样本；采用半监督学习和联合分布对齐策略。

Result: 在MSTAR数据集上验证，CLSDF在不同噪声条件下均达到最优性能。

Conclusion: CLSDF方法有效提升了SAR自动目标识别在噪声标签下的鲁棒性和性能。

Abstract: The acquisition of high-quality labeled synthetic aperture radar (SAR) data
is challenging due to the demanding requirement for expert knowledge.
Consequently, the presence of unreliable noisy labels is unavoidable, which
results in performance degradation of SAR automatic target recognition (ATR).
Existing research on learning with noisy labels mainly focuses on image data.
However, the non-intuitive visual characteristics of SAR data are insufficient
to achieve noise-robust learning. To address this problem, we propose
collaborative learning of scattering and deep features (CLSDF) for SAR ATR with
noisy labels. Specifically, a multi-model feature fusion framework is designed
to integrate scattering and deep features. The attributed scattering centers
(ASCs) are treated as dynamic graph structure data, and the extracted physical
characteristics effectively enrich the representation of deep image features.
Then, the samples with clean and noisy labels are divided by modeling the loss
distribution with multiple class-wise Gaussian Mixture Models (GMMs).
Afterward, the semi-supervised learning of two divergent branches is conducted
based on the data divided by each other. Moreover, a joint distribution
alignment strategy is introduced to enhance the reliability of co-guessed
labels. Extensive experiments have been done on the Moving and Stationary
Target Acquisition and Recognition (MSTAR) dataset, and the results show that
the proposed method can achieve state-of-the-art performance under different
operating conditions with various label noises.

</details>


### [146] [Undress to Redress: A Training-Free Framework for Virtual Try-On](https://arxiv.org/abs/2508.07680)
*Zhiying Li,Junhao Wu,Yeying Jin,Daiheng Gao,Yun Ji,Kaichuan Kong,Lei Yu,Hao Xu,Kai Chen,Bruce Gu,Nana Wang,Zhaoxin Fan*

Main category: cs.CV

TL;DR: UR-VTON提出了一种无需训练的虚拟试衣框架，通过“脱衣-穿衣”机制解决长袖转短袖试衣问题，结合动态指导和结构细化器提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试衣方法在长袖转短袖场景中表现不佳，主要因皮肤还原不准确。

Method: 提出UR-VTON框架，采用“脱衣-穿衣”两步机制，结合动态指导和结构细化器。

Result: 实验表明UR-VTON在细节保留和图像质量上优于现有方法。

Conclusion: UR-VTON为虚拟试衣提供了一种高效且无需训练的解决方案。

Abstract: Virtual try-on (VTON) is a crucial task for enhancing user experience in
online shopping by generating realistic garment previews on personal photos.
Although existing methods have achieved impressive results, they struggle with
long-sleeve-to-short-sleeve conversions-a common and practical scenario-often
producing unrealistic outputs when exposed skin is underrepresented in the
original image. We argue that this challenge arises from the ''majority''
completion rule in current VTON models, which leads to inaccurate skin
restoration in such cases. To address this, we propose UR-VTON (Undress-Redress
Virtual Try-ON), a novel, training-free framework that can be seamlessly
integrated with any existing VTON method. UR-VTON introduces an
''undress-to-redress'' mechanism: it first reveals the user's torso by
virtually ''undressing,'' then applies the target short-sleeve garment,
effectively decomposing the conversion into two more manageable steps.
Additionally, we incorporate Dynamic Classifier-Free Guidance scheduling to
balance diversity and image quality during DDPM sampling, and employ Structural
Refiner to enhance detail fidelity using high-frequency cues. Finally, we
present LS-TON, a new benchmark for long-sleeve-to-short-sleeve try-on.
Extensive experiments demonstrate that UR-VTON outperforms state-of-the-art
methods in both detail preservation and image quality. Code will be released
upon acceptance.

</details>


### [147] [TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding](https://arxiv.org/abs/2508.07683)
*Chaohong Guo,Xun Mo,Yongwei Nie,Xuemiao Xu,Chao Xu,Fei Yu,Chengjiang Long*

Main category: cs.CV

TL;DR: 论文提出TAR-TVG框架，通过时间戳锚点约束推理过程，提升视频片段定位的准确性，并采用自蒸馏训练策略优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法未能显式约束推理过程，影响最终时间预测质量，需改进。

Method: 引入时间戳锚点作为中间验证点，逐步提升时间估计精度；采用三阶段自蒸馏训练策略（GRPO、SFT、GRPO）。

Result: 模型在实验中表现最佳，生成可解释且逐步优化的推理链。

Conclusion: TAR-TVG框架通过显式监督和自蒸馏策略，显著提升了时间视频定位的性能和可解释性。

Abstract: Temporal Video Grounding (TVG) aims to precisely localize video segments
corresponding to natural language queries, which is a critical capability for
long-form video understanding. Although existing reinforcement learning
approaches encourage models to generate reasoning chains before predictions,
they fail to explicitly constrain the reasoning process to ensure the quality
of the final temporal predictions. To address this limitation, we propose
Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG),
a novel framework that introduces timestamp anchors within the reasoning
process to enforce explicit supervision to the thought content. These anchors
serve as intermediate verification points. More importantly, we require each
reasoning step to produce increasingly accurate temporal estimations, thereby
ensuring that the reasoning process contributes meaningfully to the final
prediction. To address the challenge of low-probability anchor generation in
models (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation
training strategy: (1) initial GRPO training to collect 30K high-quality
reasoning traces containing multiple timestamp anchors, (2) supervised
fine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the
SFT-enhanced model. This three-stage training strategy enables robust anchor
generation while maintaining reasoning quality. Experiments show that our model
achieves state-of-the-art performance while producing interpretable, verifiable
reasoning chains with progressively refined temporal estimations.

</details>


### [148] [Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing](https://arxiv.org/abs/2508.07700)
*Weitao Wang,Haoran Xu,Jun Meng,Haoqian Wang*

Main category: cs.CV

TL;DR: 提出了一种无需调优的即插即用方案，用于在3D生成中保持编辑内容与原始几何对齐。


<details>
  <summary>Details</summary>
Motivation: 用户希望在3D生成内容上进行编辑（如颜色、风格、光照）而不破坏几何结构，但现有工具多为2D领域，直接应用于3D会导致信息丢失。

Method: 提出几何保留模块，利用原始法线潜在变量指导多视图生成，并设计注入切换器控制法线监督程度。

Result: 实验表明，该方法在多视图一致性和网格质量上均有提升，适用于多种多视图扩散模型和编辑方法。

Conclusion: 该方法有效解决了3D编辑中的几何对齐问题，提升了生成质量。

Abstract: As 3D generation techniques continue to flourish, the demand for generating
personalized content is rapidly rising. Users increasingly seek to apply
various editing methods to polish generated 3D content, aiming to enhance its
color, style, and lighting without compromising the underlying geometry.
However, most existing editing tools focus on the 2D domain, and directly
feeding their results into 3D generation methods (like multi-view diffusion
models) will introduce information loss, degrading the quality of the final 3D
assets. In this paper, we propose a tuning-free, plug-and-play scheme that
aligns edited assets with their original geometry in a single inference run.
Central to our approach is a geometry preservation module that guides the
edited multi-view generation with original input normal latents. Besides, an
injection switcher is proposed to deliberately control the supervision extent
of the original normals, ensuring the alignment between the edited color and
normal views. Extensive experiments show that our method consistently improves
both the multi-view consistency and mesh quality of edited 3D assets, across
multiple combinations of multi-view diffusion models and editing methods.

</details>


### [149] [DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models](https://arxiv.org/abs/2508.07714)
*Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo*

Main category: cs.CV

TL;DR: 提出一种半自动化流程，结合目标检测模型和大语言模型（LLM）构建多类别门检测数据集，减少人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集稀缺，而精细门检测对建筑合规检查和室内场景理解至关重要。

Method: 先使用目标检测模型统一检测门，再用LLM分类，最后人工校验。

Result: 显著降低标注成本，生成适用于基准测试的高质量数据集。

Conclusion: 结合深度学习和多模态推理，为复杂领域高效构建数据集提供了潜力。

Abstract: Accurate detection and classification of diverse door types in floor plans
drawings is critical for multiple applications, such as building compliance
checking, and indoor scene understanding. Despite their importance, publicly
available datasets specifically designed for fine-grained multi-class door
detection remain scarce. In this work, we present a semi-automated pipeline
that leverages a state-of-the-art object detector and a large language model
(LLM) to construct a multi-class door detection dataset with minimal manual
effort. Doors are first detected as a unified category using a deep object
detection model. Next, an LLM classifies each detected instance based on its
visual and contextual features. Finally, a human-in-the-loop stage ensures
high-quality labels and bounding boxes. Our method significantly reduces
annotation cost while producing a dataset suitable for benchmarking neural
models in floor plan analysis. This work demonstrates the potential of
combining deep learning and multimodal reasoning for efficient dataset
construction in complex real-world domains.

</details>


### [150] [A Registration-Based Star-Shape Segmentation Model and Fast Algorithms](https://arxiv.org/abs/2508.07721)
*Daoping Zhang,Xue-Cheng Tai,Lok Ming Lui*

Main category: cs.CV

TL;DR: 提出了一种基于配准框架的星形分割模型，结合水平集表示和配准框架，支持单中心或多中心的完整或部分星形分割，并通过数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 图像分割在提取感兴趣对象及其边界时至关重要，但在遮挡、模糊或噪声情况下准确性受限，因此需要利用先验信息（如星形先验）来改进分割效果。

Method: 结合水平集表示与配准框架，对变形水平集函数施加约束，支持单中心或多中心的星形分割，并通过交替方向乘子法求解模型。

Result: 在合成和真实图像上的数值实验表明，该方法能够实现准确的星形分割。

Conclusion: 所提出的星形分割模型在复杂图像条件下表现优异，支持多种分割需求，具有实际应用潜力。

Abstract: Image segmentation plays a crucial role in extracting objects of interest and
identifying their boundaries within an image. However, accurate segmentation
becomes challenging when dealing with occlusions, obscurities, or noise in
corrupted images. To tackle this challenge, prior information is often
utilized, with recent attention on star-shape priors. In this paper, we propose
a star-shape segmentation model based on the registration framework. By
combining the level set representation with the registration framework and
imposing constraints on the deformed level set function, our model enables both
full and partial star-shape segmentation, accommodating single or multiple
centers. Additionally, our approach allows for the enforcement of identified
boundaries to pass through specified landmark locations. We tackle the proposed
models using the alternating direction method of multipliers. Through numerical
experiments conducted on synthetic and real images, we demonstrate the efficacy
of our approach in achieving accurate star-shape segmentation.

</details>


### [151] [Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting](https://arxiv.org/abs/2508.07723)
*Ting Xiang,Changjian Chen,Zhuo Tang,Qifeng Zhang,Fei Lyu,Li Yang,Jiapeng Zhang,Kenli Li*

Main category: cs.CV

TL;DR: 论文提出TriReWeight方法，通过三重连接样本重加权优化生成数据增强，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决生成数据增强中因不可控生成和自然语言模糊性导致的噪声图像问题。

Method: 理论分析三种生成图像监督方式，提出TriReWeight方法，结合三重连接样本重加权。

Result: 实验表明，TriReWeight在自然和医学数据集上分别平均提升7.9%和3.4%。

Conclusion: TriReWeight可兼容任何生成数据增强方法，理论性能接近最优。

Abstract: The performance of computer vision models in certain real-world applications,
such as medical diagnosis, is often limited by the scarcity of available
images. Expanding datasets using pre-trained generative models is an effective
solution. However, due to the uncontrollable generation process and the
ambiguity of natural language, noisy images may be generated. Re-weighting is
an effective way to address this issue by assigning low weights to such noisy
images. We first theoretically analyze three types of supervision for the
generated images. Based on the theoretical analysis, we develop TriReWeight, a
triplet-connection-based sample re-weighting method to enhance generative data
augmentation. Theoretically, TriReWeight can be integrated with any generative
data augmentation methods and never downgrade their performance. Moreover, its
generalization approaches the optimal in the order $O(\sqrt{d\ln (n)/n})$. Our
experiments validate the correctness of the theoretical analysis and
demonstrate that our method outperforms the existing SOTA methods by $7.9\%$ on
average over six natural image datasets and by $3.4\%$ on average over three
medical datasets. We also experimentally validate that our method can enhance
the performance of different generative data augmentation methods.

</details>


### [152] [Grouped Speculative Decoding for Autoregressive Image Generation](https://arxiv.org/abs/2508.07747)
*Junhyuk So,Juncheol Shin,Hyunho Kook,Eunhyeok Park*

Main category: cs.CV

TL;DR: 提出了一种无需训练的加速方法GSD，用于自回归图像模型，通过动态分组策略减少推理时间，平均加速3.7倍。


<details>
  <summary>Details</summary>
Motivation: 自回归图像模型推理时间长，现有方法加速效果有限或需额外训练。

Method: 提出动态分组推测解码（GSD），评估视觉有效令牌簇而非单一目标令牌。

Result: GSD平均加速3.7倍，且保持图像质量。

Conclusion: GSD是一种高效且无需训练的加速方法，适用于自回归图像模型。

Abstract: Recently, autoregressive (AR) image models have demonstrated remarkable
generative capabilities, positioning themselves as a compelling alternative to
diffusion models. However, their sequential nature leads to long inference
times, limiting their practical scalability. In this work, we introduce Grouped
Speculative Decoding (GSD), a novel, training-free acceleration method for AR
image models. While recent studies have explored Speculative Decoding (SD) as a
means to speed up AR image generation, existing approaches either provide only
modest acceleration or require additional training. Our in-depth analysis
reveals a fundamental difference between language and image tokens: image
tokens exhibit inherent redundancy and diversity, meaning multiple tokens can
convey valid semantics. However, traditional SD methods are designed to accept
only a single most-likely token, which fails to leverage this difference,
leading to excessive false-negative rejections. To address this, we propose a
new SD strategy that evaluates clusters of visually valid tokens rather than
relying on a single target token. Additionally, we observe that static
clustering based on embedding distance is ineffective, which motivates our
dynamic GSD approach. Extensive experiments show that GSD accelerates AR image
models by an average of 3.7x while preserving image quality-all without
requiring any additional training. The source code is available at
https://github.com/junhyukso/GSD

</details>


### [153] [Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion](https://arxiv.org/abs/2508.07755)
*Minseo Kim,Minchan Kwon,Dongyeun Lee,Yunho Jeon,Junmo Kim*

Main category: cs.CV

TL;DR: 提出了一种无需额外信息的对比反转方法，通过对比学习提取图像共同概念，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖额外指导（如文本提示或空间掩码）提取共同概念，可能导致辅助特征分离不完整，影响生成质量。

Method: 提出对比反转方法，通过对比学习训练目标标记和图像辅助文本标记，实现目标语义解耦，并应用解耦交叉注意力微调提升概念保真度。

Result: 实验表明，该方法在概念表示和编辑方面均优于现有技术，实现了平衡的高性能。

Conclusion: 对比反转方法有效提取共同概念，无需额外信息，显著提升生成质量和编辑能力。

Abstract: The recent demand for customized image generation raises a need for
techniques that effectively extract the common concept from small sets of
images. Existing methods typically rely on additional guidance, such as text
prompts or spatial masks, to capture the common target concept. Unfortunately,
relying on manually provided guidance can lead to incomplete separation of
auxiliary features, which degrades generation quality.In this paper, we propose
Contrastive Inversion, a novel approach that identifies the common concept by
comparing the input images without relying on additional information. We train
the target token along with the image-wise auxiliary text tokens via
contrastive learning, which extracts the well-disentangled true semantics of
the target. Then we apply disentangled cross-attention fine-tuning to improve
concept fidelity without overfitting. Experimental results and analysis
demonstrate that our method achieves a balanced, high-level performance in both
concept representation and editing, outperforming existing techniques.

</details>


### [154] [Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild](https://arxiv.org/abs/2508.07759)
*Haoran Wang,Zekun Li,Jian Zhang,Lei Qi,Yinghuan Shi*

Main category: cs.CV

TL;DR: CAV-SAM利用伪视频表示参考-目标图像对的对应关系，通过SAM2的iVOS能力轻量级适配下游任务，性能提升超过5%。


<details>
  <summary>Details</summary>
Motivation: 现有参考分割方法依赖元学习，数据与计算成本高，CAV-SAM旨在以轻量方式解决这一问题。

Method: 将参考-目标图像对的对应关系表示为伪视频，利用SAM2的iVOS能力，结合DBST和TTGA模块实现轻量适配。

Result: 在广泛使用的数据集上，分割性能提升超过5%。

Conclusion: CAV-SAM为轻量级适配视觉模型提供了新方向，性能显著优于现有方法。

Abstract: Large vision models like the Segment Anything Model (SAM) exhibit significant
limitations when applied to downstream tasks in the wild. Consequently,
reference segmentation, which leverages reference images and their
corresponding masks to impart novel knowledge to the model, emerges as a
promising new direction for adapting vision models. However, existing reference
segmentation approaches predominantly rely on meta-learning, which still
necessitates an extensive meta-training process and brings massive data and
computational cost. In this study, we propose a novel approach by representing
the inherent correspondence between reference-target image pairs as a pseudo
video. This perspective allows the latest version of SAM, known as SAM2, which
is equipped with interactive video object segmentation (iVOS) capabilities, to
be adapted to downstream tasks in a lightweight manner. We term this approach
Correspondence As Video for SAM (CAV-SAM). CAV-SAM comprises two key modules:
the Diffusion-Based Semantic Transition (DBST) module employs a diffusion model
to construct a semantic transformation sequence, while the Test-Time Geometric
Alignment (TTGA) module aligns the geometric changes within this sequence
through test-time fine-tuning. We evaluated CAVSAM on widely-used datasets,
achieving segmentation performance improvements exceeding 5% over SOTA methods.
Implementation is provided in the supplementary materials.

</details>


### [155] [UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models](https://arxiv.org/abs/2508.07766)
*Jinke Li,Jiarui Yu,Chenxing Wei,Hande Dong,Qiang Lin,Liangjing Yang,Zhicai Wang,Yanbin Hao*

Main category: cs.CV

TL;DR: 论文提出了一种名为UniSVG的数据集，用于支持多模态大语言模型（MLLM）在SVG理解和生成任务中的训练与评估，并展示了其优于现有模型（如GPT-4V）的性能。


<details>
  <summary>Details</summary>
Motivation: SVG在计算机视觉和艺术设计中广泛应用，但AI驱动的SVG理解和生成仍面临挑战，需要高精度和多模态处理能力。

Method: 通过构建包含525k数据项的UniSVG数据集，支持MLLM在SVG领域的训练与评估，涵盖文本提示和图像到SVG的转换。

Result: 使用UniSVG数据集训练的MLLM在SVG理解和生成任务中表现优异，超越现有SOTA模型。

Conclusion: UniSVG数据集为SVG领域的研究提供了重要资源，推动了MLLM在SVG任务中的应用。

Abstract: Unlike bitmap images, scalable vector graphics (SVG) maintain quality when
scaled, frequently employed in computer vision and artistic design in the
representation of SVG code. In this era of proliferating AI-powered systems,
enabling AI to understand and generate SVG has become increasingly urgent.
However, AI-driven SVG understanding and generation (U&G) remain significant
challenges. SVG code, equivalent to a set of curves and lines controlled by
floating-point parameters, demands high precision in SVG U&G. Besides, SVG
generation operates under diverse conditional constraints, including textual
prompts and visual references, which requires powerful multi-modal processing
for condition-to-SVG transformation. Recently, the rapid growth of Multi-modal
Large Language Models (MLLMs) have demonstrated capabilities to process
multi-modal inputs and generate complex vector controlling parameters,
suggesting the potential to address SVG U&G tasks within a unified model. To
unlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset
called UniSVG, comprising 525k data items, tailored for MLLM training and
evaluation. To our best knowledge, it is the first comprehensive dataset
designed for unified SVG generation (from textual prompts and images) and SVG
understanding (color, category, usage, etc.). As expected, learning on the
proposed dataset boosts open-source MLLMs' performance on various SVG U&G
tasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset,
benchmark, weights, codes and experiment details on
https://ryanlijinke.github.io/.

</details>


### [156] [Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation](https://arxiv.org/abs/2508.07769)
*Xiaoyan Liu,Kangrui Li,Jiaxin Liu*

Main category: cs.CV

TL;DR: Dream4D是一个新框架，通过结合可控视频生成和神经4D重建，解决了4D内容合成的时空一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保持视角一致性和处理复杂场景动态方面存在困难，尤其是在大规模环境中。

Method: 采用两阶段架构：首先通过少样本学习预测相机轨迹，然后通过姿态条件扩散过程生成几何一致的多视角序列，最后转换为持久4D表示。

Result: Dream4D在4D生成质量（如mPSNR、mSSIM）上优于现有方法。

Conclusion: 该框架首次结合了视频扩散模型的时间先验和重建模型的几何感知，显著提升了4D生成效果。

Abstract: The synthesis of spatiotemporally coherent 4D content presents fundamental
challenges in computer vision, requiring simultaneous modeling of high-fidelity
spatial representations and physically plausible temporal dynamics. Current
approaches often struggle to maintain view consistency while handling complex
scene dynamics, particularly in large-scale environments with multiple
interacting elements. This work introduces Dream4D, a novel framework that
bridges this gap through a synergy of controllable video generation and neural
4D reconstruction. Our approach seamlessly combines a two-stage architecture:
it first predicts optimal camera trajectories from a single image using
few-shot learning, then generates geometrically consistent multi-view sequences
via a specialized pose-conditioned diffusion process, which are finally
converted into a persistent 4D representation. This framework is the first to
leverage both rich temporal priors from video diffusion models and geometric
awareness of the reconstruction models, which significantly facilitates 4D
generation and shows higher quality (e.g., mPSNR, mSSIM) over existing methods.

</details>


### [157] [Prototype-Guided Curriculum Learning for Zero-Shot Learning](https://arxiv.org/abs/2508.07771)
*Lei Wang,Shiming Chen,Guo-Sen Xie,Ziming Hong,Chaojian Yu,Qinmu Peng,Xinge You*

Main category: cs.CV

TL;DR: 论文提出了一种原型引导的课程学习框架（CLZSL），通过PCL模块缓解实例级不匹配，通过PUP模块动态更新语义原型，提升零样本学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入方法中，手动定义的语义原型可能因实例级不匹配和类级不精确性引入噪声监督，影响知识迁移效果。

Method: 提出CLZSL框架，包含PCL模块（优先学习对齐样本）和PUP模块（动态更新语义原型）。

Result: 在AWA2、SUN和CUB数据集上验证了方法的有效性。

Conclusion: CLZSL通过课程学习和动态原型更新，显著提升了零样本学习的性能。

Abstract: In Zero-Shot Learning (ZSL), embedding-based methods enable knowledge
transfer from seen to unseen classes by learning a visual-semantic mapping from
seen-class images to class-level semantic prototypes (e.g., attributes).
However, these semantic prototypes are manually defined and may introduce noisy
supervision for two main reasons: (i) instance-level mismatch: variations in
perspective, occlusion, and annotation bias will cause discrepancies between
individual sample and the class-level semantic prototypes; and (ii) class-level
imprecision: the manually defined semantic prototypes may not accurately
reflect the true semantics of the class. Consequently, the visual-semantic
mapping will be misled, reducing the effectiveness of knowledge transfer to
unseen classes. In this work, we propose a prototype-guided curriculum learning
framework (dubbed as CLZSL), which mitigates instance-level mismatches through
a Prototype-Guided Curriculum Learning (PCL) module and addresses class-level
imprecision via a Prototype Update (PUP) module. Specifically, the PCL module
prioritizes samples with high cosine similarity between their visual mappings
and the class-level semantic prototypes, and progressively advances to
less-aligned samples, thereby reducing the interference of instance-level
mismatches to achieve accurate visual-semantic mapping. Besides, the PUP module
dynamically updates the class-level semantic prototypes by leveraging the
visual mappings learned from instances, thereby reducing class-level
imprecision and further improving the visual-semantic mapping. Experiments were
conducted on standard benchmark datasets-AWA2, SUN, and CUB-to verify the
effectiveness of our method.

</details>


### [158] [Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)](https://arxiv.org/abs/2508.07775)
*Lennart Bastian,Mohammad Rashed,Nassir Navab,Tolga Birdal*

Main category: cs.CV

TL;DR: 论文提出了一种基于神经控制微分方程和SO(3) Savitzky-Golay路径的方法，用于在3D旋转流形上建模噪声姿态估计的轨迹，解决了SO(3)外推中的动态复杂性、非保守运动学和噪声观测问题。


<details>
  <summary>Details</summary>
Motivation: SO(3)外推在计算机视觉中具有基础性意义，但面临动态复杂性、非保守运动学和噪声观测等挑战。现有方法依赖能量守恒或恒定速度假设，限制了其在真实场景中的应用。

Method: 利用神经控制微分方程和SO(3) Savitzky-Golay路径，在物理和几何意义上建模轨迹，无需依赖能量或动量守恒假设。

Result: 模型在仿真和真实场景中表现出鲁棒的外推能力，适用于复杂非惯性系统，并能泛化到未知物理参数的轨迹。

Conclusion: 该方法为SO(3)外推提供了一种灵活且鲁棒的解决方案，可轻松集成到现有流程中。

Abstract: Modeling the rotation of moving objects is a fundamental task in computer
vision, yet $SO(3)$ extrapolation still presents numerous challenges: (1)
unknown quantities such as the moment of inertia complicate dynamics, (2) the
presence of external forces and torques can lead to non-conservative
kinematics, and (3) estimating evolving state trajectories under sparse, noisy
observations requires robustness. We propose modeling trajectories of noisy
pose estimates on the manifold of 3D rotations in a physically and
geometrically meaningful way by leveraging Neural Controlled Differential
Equations guided with $SO(3)$ Savitzky-Golay paths. Existing extrapolation
methods often rely on energy conservation or constant velocity assumptions,
limiting their applicability in real-world scenarios involving non-conservative
forces. In contrast, our approach is agnostic to energy and momentum
conservation while being robust to input noise, making it applicable to
complex, non-inertial systems. Our approach is easily integrated as a module in
existing pipelines and generalizes well to trajectories with unknown physical
parameters. By learning to approximate object dynamics from noisy states during
training, our model attains robust extrapolation capabilities in simulation and
various real-world settings. Code is available at
https://github.com/bastianlb/forecasting-rotational-dynamics

</details>


### [159] [GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences](https://arxiv.org/abs/2508.07782)
*Saihui Hou,Chenye Wang,Wenpeng Lang,Zhengxiang Lan,Yongzhen Huang*

Main category: cs.CV

TL;DR: 论文提出了一种新的步态识别方法，将步态视为个体化动作的集合，通过随机选取的片段（snippet）捕捉多尺度时间上下文，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于集合或序列的步态识别方法在短程和长程时间依赖性捕捉上存在不足，需要更全面的时间上下文建模。

Method: 提出片段（snippet）概念，将步态分解为个体化动作，通过随机选取的片段实现多尺度时间上下文学习，并设计了片段采样和建模的关键组件。

Result: 在四个常用步态数据集上验证了方法的有效性，例如在Gait3D和GREW上分别达到77.5%和81.7%的rank-1准确率。

Conclusion: 片段化方法显著提升了步态识别性能，展示了多尺度时间上下文建模的潜力。

Abstract: Recent advancements in gait recognition have significantly enhanced
performance by treating silhouettes as either an unordered set or an ordered
sequence. However, both set-based and sequence-based approaches exhibit notable
limitations. Specifically, set-based methods tend to overlook short-range
temporal context for individual frames, while sequence-based methods struggle
to capture long-range temporal dependencies effectively. To address these
challenges, we draw inspiration from human identification and propose a new
perspective that conceptualizes human gait as a composition of individualized
actions. Each action is represented by a series of frames, randomly selected
from a continuous segment of the sequence, which we term a snippet.
Fundamentally, the collection of snippets for a given sequence enables the
incorporation of multi-scale temporal context, facilitating more comprehensive
gait feature learning. Moreover, we introduce a non-trivial solution for
snippet-based gait recognition, focusing on Snippet Sampling and Snippet
Modeling as key components. Extensive experiments on four widely-used gait
datasets validate the effectiveness of our proposed approach and, more
importantly, highlight the potential of gait snippets. For instance, our method
achieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D
convolution-based backbone.

</details>


### [160] [Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake](https://arxiv.org/abs/2508.07795)
*Hongrui Zheng,Yuezun Li,Liejun Wang,Yunfeng Diao,Zhiqing Guo*

Main category: cs.CV

TL;DR: 论文提出了一种两阶段防御框架（TSDF），通过双功能对抗扰动同时破坏伪造结果和攻击者的模型适应能力，解决了现有主动防御策略缺乏持久性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造防御策略因攻击者通过收集受保护样本并重新训练模型而失效，缺乏持久性。

Method: 提出TSDF框架，利用强度分离机制生成双功能对抗扰动，既能直接破坏伪造结果，又能通过数据投毒干扰攻击者的重新训练流程。

Result: 实验表明，TSDF具有强大的双重防御能力，显著提升了防御的持久性。

Conclusion: TSDF通过阻断攻击者的模型适应能力，实现了长期有效的深度伪造防御。

Abstract: Active defense strategies have been developed to counter the threat of
deepfake technology. However, a primary challenge is their lack of persistence,
as their effectiveness is often short-lived. Attackers can bypass these
defenses by simply collecting protected samples and retraining their models.
This means that static defenses inevitably fail when attackers retrain their
models, which severely limits practical use. We argue that an effective defense
not only distorts forged content but also blocks the model's ability to adapt,
which occurs when attackers retrain their models on protected images. To
achieve this, we propose an innovative Two-Stage Defense Framework (TSDF).
Benefiting from the intensity separation mechanism designed in this paper, the
framework uses dual-function adversarial perturbations to perform two roles.
First, it can directly distort the forged results. Second, it acts as a
poisoning vehicle that disrupts the data preparation process essential for an
attacker's retraining pipeline. By poisoning the data source, TSDF aims to
prevent the attacker's model from adapting to the defensive perturbations, thus
ensuring the defense remains effective long-term. Comprehensive experiments
show that the performance of traditional interruption methods degrades sharply
when it is subjected to adversarial retraining. However, our framework shows a
strong dual defense capability, which can improve the persistence of active
defense. Our code will be available at https://github.com/vpsg-research/TSDF.

</details>


### [161] [Power Battery Detection](https://arxiv.org/abs/2508.07797)
*Xiaoqi Zhao,Peiqian Cao,Lihe Zhang,Zonglei Feng,Hanqi Liu,Jiaming Zuo,Youwei Pang,Weisi Lin,Georges El Fakhri,Huchuan Lu,Xiaofeng Liu*

Main category: cs.CV

TL;DR: 论文提出了一种新的任务——动力电池检测（PBD），旨在从工业X射线图像中定位阴极和阳极板的密集端点，以进行质量检测。作者发布了首个大规模基准数据集PBD5K，并提出了一种智能标注流程和模型MDCNeXt，结合多维结构线索和状态空间模块，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 动力电池内部结构缺陷可能引发严重安全隐患，传统人工检测效率低且易出错，现有视觉算法难以应对密集排列、低对比度等问题。

Method: 提出PBD5K数据集（5,000张X射线图像），开发智能标注流程；将PBD任务建模为点级分割问题，设计MDCNeXt模型，整合点、线、计数等多维信息，并引入两个状态空间模块优化分割结果。

Result: MDCNeXt模型通过多维结构线索和状态空间模块，显著提升了动力电池检测的准确性和鲁棒性。

Conclusion: PBD5K数据集和MDCNeXt模型为动力电池检测提供了有效解决方案，未来将公开代码和数据集以推动相关研究。

Abstract: Power batteries are essential components in electric vehicles, where internal
structural defects can pose serious safety risks. We conduct a comprehensive
study on a new task, power battery detection (PBD), which aims to localize the
dense endpoints of cathode and anode plates from industrial X-ray images for
quality inspection. Manual inspection is inefficient and error-prone, while
traditional vision algorithms struggle with densely packed plates, low
contrast, scale variation, and imaging artifacts. To address this issue and
drive more attention into this meaningful task, we present PBD5K, the first
large-scale benchmark for this task, consisting of 5,000 X-ray images from nine
battery types with fine-grained annotations and eight types of real-world
visual interference. To support scalable and consistent labeling, we develop an
intelligent annotation pipeline that combines image filtering, model-assisted
pre-labeling, cross-verification, and layered quality evaluation. We formulate
PBD as a point-level segmentation problem and propose MDCNeXt, a model designed
to extract and integrate multi-dimensional structure clues including point,
line, and count information from the plate itself. To improve discrimination
between plates and suppress visual interference, MDCNeXt incorporates two state
space modules. The first is a prompt-filtered module that learns contrastive
relationships guided by task-specific prompts. The second is a density-aware
reordering module that refines segmentation in regions with high plate density.
In addition, we propose a distance-adaptive mask generation strategy to provide
robust supervision under varying spatial distributions of anode and cathode
positions. The source code and datasets will be publicly available at
\href{https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD}{PBD5K}.

</details>


### [162] [MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks](https://arxiv.org/abs/2508.07803)
*Yushen Xu,Xiaosong Li,Zhenyu Kuang,Xiaoqi Cheng,Haishu Tan,Huafeng Li*

Main category: cs.CV

TL;DR: MambaTrans是一种新型多模态融合图像模态翻译器，旨在解决可见图像与多模态融合图像之间的像素分布差异问题，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有下游预训练模型通常基于可见图像训练，而多模态融合图像与可见图像的像素分布差异会降低下游任务性能。本文探索如何将多模态融合图像适配到基于可见图像训练的模型中。

Method: 提出MambaTrans，利用多模态大语言模型的描述和语义分割模型的掩码作为输入，通过多模型状态空间块结合掩码-图像-文本交叉注意力和3D选择性扫描模块，增强纯视觉能力。

Result: 实验表明，MambaTrans在不调整预训练模型参数的情况下，有效提升了多模态图像在下游任务中的性能。

Conclusion: MambaTrans通过结合文本、掩码和图像的长期依赖关系，成功解决了多模态融合图像适配问题，为下游任务提供了更好的性能。

Abstract: The goal of multimodal image fusion is to integrate complementary information
from infrared and visible images, generating multimodal fused images for
downstream tasks. Existing downstream pre-training models are typically trained
on visible images. However, the significant pixel distribution differences
between visible and multimodal fusion images can degrade downstream task
performance, sometimes even below that of using only visible images. This paper
explores adapting multimodal fused images with significant modality differences
to object detection and semantic segmentation models trained on visible images.
To address this, we propose MambaTrans, a novel multimodal fusion image
modality translator. MambaTrans uses descriptions from a multimodal large
language model and masks from semantic segmentation models as input. Its core
component, the Multi-Model State Space Block, combines mask-image-text
cross-attention and a 3D-Selective Scan Module, enhancing pure visual
capabilities. By leveraging object detection prior knowledge, MambaTrans
minimizes detection loss during training and captures long-term dependencies
among text, masks, and images. This enables favorable results in pre-trained
models without adjusting their parameters. Experiments on public datasets show
that MambaTrans effectively improves multimodal image performance in downstream
tasks.

</details>


### [163] [Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP](https://arxiv.org/abs/2508.07819)
*Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Yueyi Luo*

Main category: cs.CV

TL;DR: 提出了一种架构协同设计框架，通过卷积低秩适配器和动态融合网关解决预训练视觉语言模型在零样本异常检测中的适应性不足问题。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型在零样本异常检测中存在适应性差距，缺乏局部归纳偏置和灵活的特征融合机制。

Method: 采用卷积低秩适配器（Conv-LoRA）注入局部归纳偏置，并引入动态融合网关（DFG）自适应调制文本提示，实现双向融合。

Result: 在工业和医学基准测试中表现出优越的准确性和鲁棒性。

Conclusion: 协同设计框架对适应密集感知任务至关重要。

Abstract: Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap
when applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of
local inductive biases for dense prediction and their reliance on inflexible
feature fusion paradigms. We address these limitations through an Architectural
Co-Design framework that jointly refines feature representation and cross-modal
fusion. Our method integrates a parameter-efficient Convolutional Low-Rank
Adaptation (Conv-LoRA) adapter to inject local inductive biases for
fine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that
leverages visual context to adaptively modulate text prompts, enabling a
powerful bidirectional fusion. Extensive experiments on diverse industrial and
medical benchmarks demonstrate superior accuracy and robustness, validating
that this synergistic co-design is critical for robustly adapting foundation
models to dense perception tasks.

</details>


### [164] [Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.07804)
*Bao Li,Xiaomei Zhang,Miao Xu,Zhaoxin Fan,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: Pose-RFT是一种基于强化学习的框架，用于改进多模态大语言模型在3D人体姿态生成任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D姿态生成中存在模糊性和任务对齐不足的问题。

Method: 提出Pose-RFT框架，结合离散语言预测和连续姿态生成的混合动作强化学习，并引入HyGRPO算法进行优化。

Result: 在多个基准测试中，Pose-RFT显著优于现有方法。

Conclusion: 混合动作强化微调对3D姿态生成任务有效。

Abstract: Generating 3D human poses from multimodal inputs such as images or text
requires models to capture both rich spatial and semantic correspondences.
While pose-specific multimodal large language models (MLLMs) have shown promise
in this task, they are typically trained with supervised objectives such as
SMPL parameter regression or token-level prediction, which struggle to model
the inherent ambiguity and achieve task-specific alignment required for
accurate 3D pose generation. To address these limitations, we propose Pose-RFT,
a reinforcement fine-tuning framework tailored for 3D human pose generation in
MLLMs. We formulate the task as a hybrid action reinforcement learning problem
that jointly optimizes discrete language prediction and continuous pose
generation. To this end, we introduce HyGRPO, a hybrid reinforcement learning
algorithm that performs group-wise reward normalization over sampled responses
to guide joint optimization of discrete and continuous actions. Pose-RFT
further incorporates task-specific reward functions to guide optimization
towards spatial alignment in image-to-pose generation and semantic consistency
in text-to-pose generation. Extensive experiments on multiple pose generation
benchmarks demonstrate that Pose-RFT significantly improves performance over
existing pose-specific MLLMs, validating the effectiveness of hybrid action
reinforcement fine-tuning for 3D pose generation.

</details>


### [165] [Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model](https://arxiv.org/abs/2508.07863)
*Bin Cao,Sipeng Zheng,Ye Wang,Lujie Xia,Qianshan Wei,Qin Jin,Jing Liu,Zongqing Lu*

Main category: cs.CV

TL;DR: 论文提出了Being-M0.5，一种实时可控的视觉-语言-运动模型（VLMM），解决了现有模型在可控性方面的五大瓶颈，并基于HuMo100M数据集实现了多任务运动生成的最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-运动模型（VLMMs）在可控性方面存在显著限制，包括对多样化命令的响应不足、姿态初始化能力有限、长序列性能差、未见过场景处理不足以及缺乏对单个身体部位的细粒度控制。

Method: 基于HuMo100M数据集（包含500万自收集运动序列和1亿多任务指令实例），提出了一种新颖的部分感知残差量化技术，用于运动标记化，以实现对单个身体部位的精确控制。

Result: 实验验证表明，Being-M0.5在多种运动生成任务中表现优异，且具备实时能力。

Conclusion: HuMo100M和Being-M0.5为运动生成技术的实际应用提供了重要进展，并有望加速其在现实世界中的采用。

Abstract: Human motion generation has emerged as a critical technology with
transformative potential for real-world applications. However, existing
vision-language-motion models (VLMMs) face significant limitations that hinder
their practical deployment. We identify controllability as a main bottleneck,
manifesting in five key aspects: inadequate response to diverse human commands,
limited pose initialization capabilities, poor performance on long-term
sequences, insufficient handling of unseen scenarios, and lack of fine-grained
control over individual body parts. To overcome these limitations, we present
Being-M0.5, the first real-time, controllable VLMM that achieves
state-of-the-art performance across multiple motion generation tasks. Our
approach is built upon HuMo100M, the largest and most comprehensive human
motion dataset to date, comprising over 5 million self-collected motion
sequences, 100 million multi-task instructional instances, and detailed
part-level annotations that address a critical gap in existing datasets. We
introduce a novel part-aware residual quantization technique for motion
tokenization that enables precise, granular control over individual body parts
during generation. Extensive experimental validation demonstrates Being-M0.5's
superior performance across diverse motion benchmarks, while comprehensive
efficiency analysis confirms its real-time capabilities. Our contributions
include design insights and detailed computational analysis to guide future
development of practical motion generators. We believe that HuMo100M and
Being-M0.5 represent significant advances that will accelerate the adoption of
motion generation technologies in real-world applications. The project page is
available at https://beingbeyond.github.io/Being-M0.5.

</details>


### [166] [DiTVR: Zero-Shot Diffusion Transformer for Video Restoration](https://arxiv.org/abs/2508.07811)
*Sicheng Gao,Nancy Mehta,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: DiTVR是一种零样本视频修复框架，结合扩散变换器和轨迹感知注意力机制，通过光流轨迹对齐令牌，提升时间一致性。


<details>
  <summary>Details</summary>
Motivation: 传统回归方法生成不真实细节且需大量配对数据，而生成扩散模型难以保证时间一致性。

Method: 采用扩散变换器与轨迹感知注意力机制，动态选择令牌，并通过小波引导的流一致采样器注入数据一致性。

Result: 在视频修复基准测试中达到零样本最优，时间一致性和细节保留表现优异。

Conclusion: DiTVR在零样本视频修复中表现卓越，对光流噪声和遮挡具有鲁棒性。

Abstract: Video restoration aims to reconstruct high quality video sequences from low
quality inputs, addressing tasks such as super resolution, denoising, and
deblurring. Traditional regression based methods often produce unrealistic
details and require extensive paired datasets, while recent generative
diffusion models face challenges in ensuring temporal consistency. We introduce
DiTVR, a zero shot video restoration framework that couples a diffusion
transformer with trajectory aware attention and a wavelet guided, flow
consistent sampler. Unlike prior 3D convolutional or frame wise diffusion
approaches, our attention mechanism aligns tokens along optical flow
trajectories, with particular emphasis on vital layers that exhibit the highest
sensitivity to temporal dynamics. A spatiotemporal neighbour cache dynamically
selects relevant tokens based on motion correspondences across frames. The flow
guided sampler injects data consistency only into low-frequency bands,
preserving high frequency priors while accelerating convergence. DiTVR
establishes a new zero shot state of the art on video restoration benchmarks,
demonstrating superior temporal consistency and detail preservation while
remaining robust to flow noise and occlusions.

</details>


### [167] [Semi-supervised Multiscale Matching for SAR-Optical Image](https://arxiv.org/abs/2508.07812)
*Jingze Gai,Changchun Li*

Main category: cs.CV

TL;DR: 论文提出了一种半监督的SAR-光学图像匹配方法（S2M2-SAR），利用少量标记和大量未标记图像对，通过伪标签和跨模态特征增强模块提升匹配效果。


<details>
  <summary>Details</summary>
Motivation: 现有SAR-光学图像匹配方法依赖像素级匹配标注，耗时且复杂，难以获取足够标记数据。

Method: 设计半监督匹配流程，结合伪标签和跨模态特征增强模块，利用无监督目标分离模态共享与特定特征。

Result: S2M2-SAR在基准数据集上优于半监督方法，性能接近全监督SOTA方法。

Conclusion: S2M2-SAR高效实用，解决了标记数据不足的问题。

Abstract: Driven by the complementary nature of optical and synthetic aperture radar
(SAR) images, SAR-optical image matching has garnered significant interest.
Most existing SAR-optical image matching methods aim to capture effective
matching features by employing the supervision of pixel-level matched
correspondences within SAR-optical image pairs, which, however, suffers from
time-consuming and complex manual annotation, making it difficult to collect
sufficient labeled SAR-optical image pairs. To handle this, we design a
semi-supervised SAR-optical image matching pipeline that leverages both scarce
labeled and abundant unlabeled image pairs and propose a semi-supervised
multiscale matching for SAR-optical image matching (S2M2-SAR). Specifically, we
pseudo-label those unlabeled SAR-optical image pairs with pseudo ground-truth
similarity heatmaps by combining both deep and shallow level matching results,
and train the matching model by employing labeled and pseudo-labeled similarity
heatmaps. In addition, we introduce a cross-modal feature enhancement module
trained using a cross-modality mutual independence loss, which requires no
ground-truth labels. This unsupervised objective promotes the separation of
modality-shared and modality-specific features by encouraging statistical
independence between them, enabling effective feature disentanglement across
optical and SAR modalities. To evaluate the effectiveness of S2M2-SAR, we
compare it with existing competitors on benchmark datasets. Experimental
results demonstrate that S2M2-SAR not only surpasses existing semi-supervised
methods but also achieves performance competitive with fully supervised SOTA
methods, demonstrating its efficiency and practical potential.

</details>


### [168] [Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models](https://arxiv.org/abs/2508.07818)
*Chenyue Song,Chen Hui,Haiqi Zhu,Feng Jiang,Yachun Mi,Wei Zhang,Shaohui Liu*

Main category: cs.CV

TL;DR: RSFIQA是一种细粒度无参考图像质量评估模型，通过动态分割图像并结合多模态大语言模型感知局部失真，利用区域感知语义注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有NR-IQA方法对全局表征或均匀区域特征权重的依赖导致对语义显著区域或局部质量变化的敏感性不足。

Method: 利用SAM动态分割图像，结合MLLM提取区域描述内容与失真信息，引入RSA机制聚合局部表征。

Result: 在多个基准数据集上表现出竞争性的质量预测性能。

Conclusion: RSFIQA在感知局部语义与质量退化方面具有优势，且可灵活集成于不同网络架构。

Abstract: No-reference image quality assessment (NR-IQA) aims to simulate the process
of perceiving image quality aligned with subjective human perception. However,
existing NR-IQA methods either focus on global representations that leads to
limited insights into the semantically salient regions or employ a uniform
weighting for region features that weakens the sensitivity to local quality
variations. In this paper, we propose a fine-grained image quality assessment
model, named RSFIQA, which integrates region-level distortion information to
perceive multi-dimensional quality discrepancies. To enhance regional quality
awareness, we first utilize the Segment Anything Model (SAM) to dynamically
partition the input image into non-overlapping semantic regions. For each
region, we teach a powerful Multi-modal Large Language Model (MLLM) to extract
descriptive content and perceive multi-dimensional distortions, enabling a
comprehensive understanding of both local semantics and quality degradations.
To effectively leverage this information, we introduce Region-Aware Semantic
Attention (RSA) mechanism, which generates a global attention map by
aggregating fine-grained representations from local regions. In addition,
RSFIQA is backbone-agnostic and can be seamlessly integrated into various deep
neural network architectures. Extensive experiments demonstrate the robustness
and effectiveness of the proposed method, which achieves competitive quality
prediction performance across multiple benchmark datasets.

</details>


### [169] [PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI](https://arxiv.org/abs/2508.08058)
*Ziad Al-Haj Hemidi,Eytan Kats,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: PrIINeR是一种基于隐式神经表示（INR）的MRI重建方法，通过整合预训练深度学习模型的先验知识，显著提升了高加速因子下的图像质量和结构保留。


<details>
  <summary>Details</summary>
Motivation: 加速MRI扫描会降低图像质量，现有INR方法在高加速因子下表现不佳，导致结构丢失和伪影。

Method: PrIINeR将预训练模型的先验知识融入INR框架，结合实例优化和双重数据一致性约束，确保重建结果与k空间数据及先验重建一致。

Result: 在NYU fastMRI数据集上，PrIINeR不仅优于现有INR方法，还超越了一些基于学习的最新方法，显著提升了结构保留和图像保真度。

Conclusion: PrIINeR结合了深度学习和INR技术，为高质量加速MRI重建提供了更可靠的解决方案。

Abstract: Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often
degrades image quality. While Implicit Neural Representations (INRs) show
promise for MRI reconstruction, they struggle at high acceleration factors due
to weak prior constraints, leading to structural loss and aliasing artefacts.
To address this, we propose PrIINeR, an INR-based MRI reconstruction method
that integrates prior knowledge from pre-trained deep learning models into the
INR framework. By combining population-level knowledge with instance-based
optimization and enforcing dual data consistency, PrIINeR aligns both with the
acquired k-space data and the prior-informed reconstruction. Evaluated on the
NYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based
approaches but also improves upon several learning-based state-of-the-art
methods, significantly improving structural preservation and fidelity while
effectively removing aliasing artefacts.PrIINeR bridges deep learning and
INR-based techniques, offering a more reliable solution for high-quality,
accelerated MRI reconstruction. The code is publicly available on
https://github.com/multimodallearning/PrIINeR.

</details>


### [170] [Investigating the Design Space of Visual Grounding in Multimodal Large Language Model](https://arxiv.org/abs/2508.08066)
*Weitai Kang,Weiming Zhuang,Zhizhong Li,Yan Yan,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 本文系统研究了多模态大语言模型（MLLMs）在视觉定位（VG）任务中的设计选择，通过LLaVA-1.5模型验证了不同设计对性能的影响，并优化了数据设计，最终在RefCOCO/+/g数据集上实现了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在MLLMs的视觉定位任务中设计选择分散且缺乏系统性验证，本文旨在填补这一空白，提供全面的设计选择分析。

Method: 使用LLaVA-1.5模型，探索了不同的视觉定位范式，并通过消融实验优化了数据设计。

Result: 在RefCOCO/+/g数据集上，性能分别提升了+5.6%、+6.9%和+7.0%。

Conclusion: 本文的研究为MLLMs在视觉定位任务中的设计提供了系统性指导，显著提升了模型性能。

Abstract: Fine-grained multimodal capability in Multimodal Large Language Models
(MLLMs) has emerged as a critical research direction, particularly for tackling
the visual grounding (VG) problem. Despite the strong performance achieved by
existing approaches, they often employ disparate design choices when
fine-tuning MLLMs for VG, lacking systematic verification to support these
designs. To bridge this gap, this paper presents a comprehensive study of
various design choices that impact the VG performance of MLLMs. We conduct our
analysis using LLaVA-1.5, which has been widely adopted in prior empirical
studies of MLLMs. While more recent models exist, we follow this convention to
ensure our findings remain broadly applicable and extendable to other
architectures. We cover two key aspects: (1) exploring different visual
grounding paradigms in MLLMs, identifying the most effective design, and
providing our insights; and (2) conducting ablation studies on the design of
grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our
findings contribute to a stronger MLLM for VG, achieving improvements of +5.6%
/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.

</details>


### [171] [MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization](https://arxiv.org/abs/2508.07833)
*Animesh Jain,Alexandros Stergiou*

Main category: cs.CV

TL;DR: MIMIC框架通过视觉概念合成可视化VLM内部表示，提升模型透明度和信任。


<details>
  <summary>Details</summary>
Motivation: VLMs的复杂架构难以解释，限制了透明度和信任。

Method: MIMIC结合VLM反演和特征对齐目标，加入空间对齐、图像平滑和语义真实性的正则化。

Result: 通过定量和定性评估，MIMIC在视觉质量和语义指标上表现良好。

Conclusion: MIMIC是首个针对VLM视觉概念解释的反演方法。

Abstract: Vision Language Models (VLMs) encode multimodal inputs over large, complex,
and difficult-to-interpret architectures, which limit transparency and trust.
We propose a Multimodal Inversion for Model Interpretation and
Conceptualization (MIMIC) framework to visualize the internal representations
of VLMs by synthesizing visual concepts corresponding to internal encodings.
MIMIC uses a joint VLM-based inversion and a feature alignment objective to
account for VLM's autoregressive processing. It additionally includes a triplet
of regularizers for spatial alignment, natural image smoothness, and semantic
realism. We quantitatively and qualitatively evaluate MIMIC by inverting visual
concepts over a range of varying-length free-form VLM output texts. Reported
results include both standard visual quality metrics as well as semantic
text-based metrics. To the best of our knowledge, this is the first model
inversion approach addressing visual interpretations of VLM concepts.

</details>


### [172] [MDD-Net: Multimodal Depression Detection through Mutual Transformer](https://arxiv.org/abs/2508.08093)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: 提出了一种基于多模态数据的抑郁症检测网络（MDD-Net），利用声学和视觉数据，通过互变压器提取和融合特征，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 抑郁症严重影响身心健康，社交媒体数据的易获取性为心理健康研究提供了新途径。

Method: MDD-Net包含声学特征提取、视觉特征提取、互变压器特征融合及检测层四个模块。

Result: 在D-Vlog数据集上实验表明，MDD-Net的F1分数比现有方法高17.37%。

Conclusion: MDD-Net在多模态抑郁症检测中表现出色，代码已开源。

Abstract: Depression is a major mental health condition that severely impacts the
emotional and physical well-being of individuals. The simple nature of data
collection from social media platforms has attracted significant interest in
properly utilizing this information for mental health research. A Multimodal
Depression Detection Network (MDD-Net), utilizing acoustic and visual data
obtained from social media networks, is proposed in this work where mutual
transformers are exploited to efficiently extract and fuse multimodal features
for efficient depression detection. The MDD-Net consists of four core modules:
an acoustic feature extraction module for retrieving relevant acoustic
attributes, a visual feature extraction module for extracting significant
high-level patterns, a mutual transformer for computing the correlations among
the generated features and fusing these features from multiple modalities, and
a detection layer for detecting depression using the fused feature
representations. The extensive experiments are performed using the multimodal
D-Vlog dataset, and the findings reveal that the developed multimodal
depression detection network surpasses the state-of-the-art by up to 17.37% for
F1-Score, demonstrating the greater performance of the proposed system. The
source code is accessible at
https://github.com/rezwanh001/Multimodal-Depression-Detection.

</details>


### [173] [Effortless Vision-Language Model Specialization in Histopathology without Annotation](https://arxiv.org/abs/2508.07835)
*Jingna Qiu,Nishanth Jain,Jonas Ammeling,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: 论文研究了通过无标注的领域相关图像-文本对继续预训练视觉语言模型（VLM），以提升其在组织病理学任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管通用视觉语言模型在组织病理学中表现良好，但其在特定下游任务中可能表现不佳，而传统微调方法需要手动标注数据。

Method: 通过从现有数据库中提取领域和任务相关的图像-文本对，对VLM进行无标注的继续预训练。

Result: 实验表明，这种方法显著提升了零样本和小样本性能，且在大规模训练时性能接近小样本方法。

Conclusion: 无标注的继续预训练是一种有效的、任务无关的VLM适应方法，适用于组织病理学任务。

Abstract: Recent advances in Vision-Language Models (VLMs) in histopathology, such as
CONCH and QuiltNet, have demonstrated impressive zero-shot classification
capabilities across various tasks. However, their general-purpose design may
lead to suboptimal performance in specific downstream applications. While
supervised fine-tuning methods address this issue, they require manually
labeled samples for adaptation. This paper investigates annotation-free
adaptation of VLMs through continued pretraining on domain- and task-relevant
image-caption pairs extracted from existing databases. Our experiments on two
VLMs, CONCH and QuiltNet, across three downstream tasks reveal that these pairs
substantially enhance both zero-shot and few-shot performance. Notably, with
larger training sizes, continued pretraining matches the performance of
few-shot methods while eliminating manual labeling. Its effectiveness,
task-agnostic design, and annotation-free workflow make it a promising pathway
for adapting VLMs to new histopathology tasks. Code is available at
https://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.

</details>


### [174] [Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2508.08165)
*Yan Wang,Da-Wei Zhou,Han-Jia Ye*

Main category: cs.CV

TL;DR: 论文提出了一种结合任务特定和通用适配器（TUNA）的方法，用于类增量学习（CIL），通过熵选择机制和适配器融合策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练模型的CIL方法通常冻结预训练网络并使用轻量模块适应增量任务，但模块选择错误和忽略共享知识导致性能下降。

Method: 训练任务特定适配器捕获关键特征，引入熵选择机制；通过适配器融合构建通用适配器，结合两者预测。

Result: 在多个基准数据集上实现了最先进的性能。

Conclusion: TUNA方法有效结合了任务特定和通用知识，显著提升了CIL性能。

Abstract: Class-Incremental Learning (CIL) requires a learning system to continually
learn new classes without forgetting. Existing pre-trained model-based CIL
methods often freeze the pre-trained network and adapt to incremental tasks
using additional lightweight modules such as adapters. However, incorrect
module selection during inference hurts performance, and task-specific modules
often overlook shared general knowledge, leading to errors on distinguishing
between similar classes across tasks. To address the aforementioned challenges,
we propose integrating Task-Specific and Universal Adapters (TUNA) in this
paper. Specifically, we train task-specific adapters to capture the most
crucial features relevant to their respective tasks and introduce an
entropy-based selection mechanism to choose the most suitable adapter.
Furthermore, we leverage an adapter fusion strategy to construct a universal
adapter, which encodes the most discriminative features shared across tasks. We
combine task-specific and universal adapter predictions to harness both
specialized and general knowledge during inference. Extensive experiments on
various benchmark datasets demonstrate the state-of-the-art performance of our
approach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA

</details>


### [175] [CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving](https://arxiv.org/abs/2508.07838)
*Qi Xiang,Kunsong Shi,Zhigui Lin,Lei He*

Main category: cs.CV

TL;DR: 提出了一种名为CBDES MoE的分层解耦混合专家架构，用于提升BEV感知系统的输入适应性、建模能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有BEV多模态方法存在输入适应性有限、建模能力不足和泛化性能不佳的问题。

Method: 采用分层解耦的混合专家架构，结合轻量级自注意力路由机制，实现动态专家路径选择和高效推理。

Result: 在nuScenes数据集上，CBDES MoE在3D目标检测中表现优于单专家模型，mAP提升1.6点，NDS提升4.1点。

Conclusion: CBDES MoE在自动驾驶领域展示了模块化混合专家框架的有效性和实用优势。

Abstract: Bird's Eye View (BEV) perception systems based on multi-sensor feature fusion
have become a fundamental cornerstone for end-to-end autonomous driving.
However, existing multi-modal BEV methods commonly suffer from limited input
adaptability, constrained modeling capacity, and suboptimal generalization. To
address these challenges, we propose a hierarchically decoupled
Mixture-of-Experts architecture at the functional module level, termed
Computing Brain DEvelopment System Mixture-of-Experts (CBDES MoE). CBDES MoE
integrates multiple structurally heterogeneous expert networks with a
lightweight Self-Attention Router (SAR) gating mechanism, enabling dynamic
expert path selection and sparse, input-aware efficient inference. To the best
of our knowledge, this is the first modular Mixture-of-Experts framework
constructed at the functional module granularity within the autonomous driving
domain. Extensive evaluations on the real-world nuScenes dataset demonstrate
that CBDES MoE consistently outperforms fixed single-expert baselines in 3D
object detection. Compared to the strongest single-expert model, CBDES MoE
achieves a 1.6-point increase in mAP and a 4.1-point improvement in NDS,
demonstrating the effectiveness and practical advantages of the proposed
approach.

</details>


### [176] [Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images](https://arxiv.org/abs/2508.07847)
*Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度状态空间模型的Deep SWM方法，用于太阳耀斑预测，解决了现有方法在表示学习和长时序依赖建模上的不足，并通过新基准FlareBench验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 太阳耀斑预测对减少关键基础设施的潜在破坏至关重要，但现有方法在表示学习和长时序依赖建模上存在不足。

Method: 提出Deep SWM模型，结合多深度状态空间模型处理十通道太阳图像和长时序依赖，并采用稀疏掩码自编码器进行预训练。

Result: Deep SWM在性能和可靠性上优于基线方法和人类专家。

Conclusion: Deep SWM为太阳耀斑预测提供了更准确可靠的解决方案，并通过FlareBench验证了其有效性。

Abstract: Accurate, reliable solar flare prediction is crucial for mitigating potential
disruptions to critical infrastructure, while predicting solar flares remains a
significant challenge. Existing methods based on heuristic physical features
often lack representation learning from solar images. On the other hand,
end-to-end learning approaches struggle to model long-range temporal
dependencies in solar images. In this study, we propose Deep Space Weather
Model (Deep SWM), which is based on multiple deep state space models for
handling both ten-channel solar images and long-range spatio-temporal
dependencies. Deep SWM also features a sparse masked autoencoder, a novel
pretraining strategy that employs a two-phase masking approach to preserve
crucial regions such as sunspots while compressing spatial information.
Furthermore, we built FlareBench, a new public benchmark for solar flare
prediction covering a full 11-year solar activity cycle, to validate our
method. Our method outperformed baseline methods and even human expert
performance on standard metrics in terms of performance and reliability. The
project page can be found at https://keio-smilab25.github.io/DeepSWM.

</details>


### [177] [Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs](https://arxiv.org/abs/2508.07850)
*Noriko Nitta,Rei Miyata,Naoto Oishi*

Main category: cs.CV

TL;DR: 通过电子显微镜图像提取Ge表面微结构的拓扑特征，使用图卷积网络嵌入，并用PCA分析，发现辐照角度比辐照通量对形态影响更大。


<details>
  <summary>Details</summary>
Motivation: 研究离子束辐照对Ge表面微结构形态的影响，特别是辐照角度和通量的作用。

Method: 处理电子显微镜图像生成骨架图，用图卷积网络嵌入，PCA分析嵌入结果，用Davies-Bouldin指数评估聚类可分性。

Result: 辐照角度对Ge表面形态的影响比辐照通量更显著。

Conclusion: 辐照角度是影响Ge表面微结构形态的主要因素。

Abstract: In this paper, electron microscopy images of microstructures formed on Ge
surfaces by ion beam irradiation were processed to extract topological features
as skeleton graphs, which were then embedded using a graph convolutional
network. The resulting embeddings were analyzed using principal component
analysis, and cluster separability in the resulting PCA space was evaluated
using the Davies-Bouldin index. The results indicate that variations in
irradiation angle have a more significant impact on the morphological
properties of Ge surfaces than variations in irradiation fluence.

</details>


### [178] [Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images](https://arxiv.org/abs/2508.07851)
*Konrad Reuter,Suresh Guttikonda,Sarah Latus,Lennart Maack,Christian Betz,Tobias Maurer,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 提出了一种基于2D TAP网络的无标记3D组织追踪方法，结合两个CoTracker模型，用于从立体内窥镜图像中估计3D运动。


<details>
  <summary>Details</summary>
Motivation: 微创手术中动态组织运动和有限视野带来挑战，准确追踪可提升手术安全性并支持机器人辅助。

Method: 结合两个CoTracker模型（时间追踪和立体匹配），从立体内窥镜图像中估计3D运动。

Result: 在鸡组织模型上追踪误差低至1.1 mm（速度10 mm/s）。

Conclusion: TAP模型在复杂手术场景中具有高精度无标记3D追踪潜力。

Abstract: Minimally invasive surgery presents challenges such as dynamic tissue motion
and a limited field of view. Accurate tissue tracking has the potential to
support surgical guidance, improve safety by helping avoid damage to sensitive
structures, and enable context-aware robotic assistance during complex
procedures. In this work, we propose a novel method for markerless 3D tissue
tracking by leveraging 2D Tracking Any Point (TAP) networks. Our method
combines two CoTracker models, one for temporal tracking and one for stereo
matching, to estimate 3D motion from stereo endoscopic images. We evaluate the
system using a clinical laparoscopic setup and a robotic arm simulating tissue
motion, with experiments conducted on a synthetic 3D-printed phantom and a
chicken tissue phantom. Tracking on the chicken tissue phantom yielded more
reliable results, with Euclidean distance errors as low as 1.1 mm at a velocity
of 10 mm/s. These findings highlight the potential of TAP-based models for
accurate, markerless 3D tracking in challenging surgical scenarios.

</details>


### [179] [CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning](https://arxiv.org/abs/2508.07871)
*Yanshu Li,Jianjiang Yang,Zhennan Shen,Ligong Han,Haoyan Xu,Ruixiang Tang*

Main category: cs.CV

TL;DR: 论文提出了一种针对多模态上下文学习（ICL）的上下文自适应令牌剪枝方法（CATP），通过两阶段渐进剪枝减少冗余图像令牌，提升效率且性能略有提升。


<details>
  <summary>Details</summary>
Motivation: 现有图像令牌剪枝方法多针对单图像任务，忽略了多模态ICL中更大的冗余和效率需求，导致性能不稳定。

Method: 提出CATP方法，通过两阶段渐进剪枝处理跨模态交互，减少77.8%的图像令牌。

Result: 在四个LVLM和八个基准测试中，CATP平均性能提升0.6%，推理延迟降低10.78%。

Conclusion: CATP提升了多模态ICL的实用价值，为未来图像-文本交织场景的研究奠定了基础。

Abstract: Modern large vision-language models (LVLMs) convert each input image into a
large set of tokens, far outnumbering the text tokens. Although this improves
visual perception, it introduces severe image token redundancy. Because image
tokens carry sparse information, many add little to reasoning, yet greatly
increase inference cost. The emerging image token pruning methods tackle this
issue by identifying the most important tokens and discarding the rest. These
methods can raise efficiency with only modest performance loss. However, most
of them only consider single-image tasks and overlook multimodal in-context
learning (ICL), where redundancy is greater and efficiency is more critical.
Redundant tokens weaken the advantage of multimodal ICL for rapid domain
adaptation and cause unstable performance. Applying existing pruning methods in
this setting leads to large accuracy drops, exposing a clear gap and the need
for new techniques. Thus, we propose Contextually Adaptive Token Pruning
(CATP), a training-free pruning method targeted at multimodal ICL. CATP
consists of two stages that perform progressive pruning to fully account for
the complex cross-modal interactions in the input sequence. After removing
77.8\% of the image tokens, CATP produces an average performance gain of 0.6\%
over the vanilla model on four LVLMs and eight benchmarks, exceeding all
baselines remarkably. Meanwhile, it effectively improves efficiency by
achieving an average reduction of 10.78\% in inference latency. CATP enhances
the practical value of multimodal ICL and lays the groundwork for future
progress in interleaved image-text scenarios.

</details>


### [180] [Selective Contrastive Learning for Weakly Supervised Affordance Grounding](https://arxiv.org/abs/2508.07877)
*WonJun Moon,Hyun Seok Seong,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 论文提出了一种选择性原型和像素对比目标的方法，通过学习部分和对象级别的功能线索，解决了弱监督功能定位中分类器依赖无关模式的问题。


<details>
  <summary>Details</summary>
Motivation: 人类能够从第三人称演示中直观地理解功能部分，而无需像素级标注。现有方法依赖分类器，容易关注与功能无关的模式。

Method: 利用CLIP找到动作相关对象，并通过交叉参考互补视角的对象，挖掘精确的部分级功能线索。引入选择性原型和像素对比目标。

Result: 实验证明，该方法能有效将激活从无关区域转移到有意义的功能线索上。

Conclusion: 提出的方法在弱监督功能定位中表现优异，代码已开源。

Abstract: Facilitating an entity's interaction with objects requires accurately
identifying parts that afford specific actions. Weakly supervised affordance
grounding (WSAG) seeks to imitate human learning from third-person
demonstrations, where humans intuitively grasp functional parts without needing
pixel-level annotations. To achieve this, grounding is typically learned using
a shared classifier across images from different perspectives, along with
distillation strategies incorporating part discovery process. However, since
affordance-relevant parts are not always easily distinguishable, models
primarily rely on classification, often focusing on common class-specific
patterns that are unrelated to affordance. To address this limitation, we move
beyond isolated part-level learning by introducing selective prototypical and
pixel contrastive objectives that adaptively learn affordance-relevant cues at
both the part and object levels, depending on the granularity of the available
information. Initially, we find the action-associated objects in both
egocentric (object-focused) and exocentric (third-person example) images by
leveraging CLIP. Then, by cross-referencing the discovered objects of
complementary views, we excavate the precise part-level affordance clues in
each perspective. By consistently learning to distinguish affordance-relevant
regions from affordance-irrelevant background context, our approach effectively
shifts activation from irrelevant areas toward meaningful affordance cues.
Experimental results demonstrate the effectiveness of our method. Codes are
available at github.com/hynnsk/SelectiveCL.

</details>


### [181] [TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal](https://arxiv.org/abs/2508.07878)
*Hanting Wang,Shengpeng Ji,Shulei Wang,Hai Huang,Xiao Jin,Qifei Zhang,Tao Jin*

Main category: cs.CV

TL;DR: 提出了一种参数高效的All-in-One图像修复框架，通过任务感知增强提示处理多种恶劣天气退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖专用网络模块或参数，导致参数开销大，且忽略任务间的相关性。

Method: 采用两阶段训练范式（预训练和提示调优），利用低秩分解和对比约束增强任务感知提示。

Result: 实验表明，该方法仅用2.75M参数即实现优异性能。

Conclusion: 该框架高效且性能优越，为多任务图像修复提供了新思路。

Abstract: Image restoration under adverse weather conditions has been extensively
explored, leading to numerous high-performance methods. In particular, recent
advances in All-in-One approaches have shown impressive results by training on
multi-task image restoration datasets. However, most of these methods rely on
dedicated network modules or parameters for each specific degradation type,
resulting in a significant parameter overhead. Moreover, the relatedness across
different restoration tasks is often overlooked. In light of these issues, we
propose a parameter-efficient All-in-One image restoration framework that
leverages task-aware enhanced prompts to tackle various adverse weather
degradations.Specifically, we adopt a two-stage training paradigm consisting of
a pretraining phase and a prompt-tuning phase to mitigate parameter conflicts
across tasks. We first employ supervised learning to acquire general
restoration knowledge, and then adapt the model to handle specific degradation
via trainable soft prompts. Crucially, we enhance these task-specific prompts
in a task-aware manner. We apply low-rank decomposition to these prompts to
capture both task-general and task-specific characteristics, and impose
contrastive constraints to better align them with the actual inter-task
relatedness. These enhanced prompts not only improve the parameter efficiency
of the restoration model but also enable more accurate task modeling, as
evidenced by t-SNE analysis. Experimental results on different restoration
tasks demonstrate that the proposed method achieves superior performance with
only 2.75M parameters.

</details>


### [182] [NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction](https://arxiv.org/abs/2508.07897)
*Tianle Zeng,Junlei Hu,Gerardo Loza Galindo,Sharib Ali,Duygu Sarikaya,Pietro Valdastri,Dominic Jones*

Main category: cs.CV

TL;DR: 论文提出了一种动态高斯Splatting技术，用于解决手术图像数据集稀缺问题，生成高质量合成数据，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动方法需要大量高质量标注数据，限制了其在手术数据科学中的应用。

Method: 提出动态高斯模型表示动态手术场景，结合动态训练调整策略和自动标注方法，生成合成数据。

Result: 实验表明，该方法生成的合成数据质量高（PSNR 29.87），且基于合成数据训练的模型性能优于传统数据增强方法（提升15%）。

Conclusion: 动态高斯Splatting技术有效解决了数据稀缺问题，显著提升了手术自动化中的模型性能。

Abstract: Computer vision-based technologies significantly enhance surgical automation
by advancing tool tracking, detection, and localization. However, Current
data-driven approaches are data-voracious, requiring large, high-quality
labeled image datasets, which limits their application in surgical data
science. Our Work introduces a novel dynamic Gaussian Splatting technique to
address the data scarcity in surgical image datasets. We propose a dynamic
Gaussian model to represent dynamic surgical scenes, enabling the rendering of
surgical instruments from unseen viewpoints and deformations with real tissue
backgrounds. We utilize a dynamic training adjustment strategy to address
challenges posed by poorly calibrated camera poses from real-world scenarios.
Additionally, we propose a method based on dynamic Gaussians for automatically
generating annotations for our synthetic data. For evaluation, we constructed a
new dataset featuring seven scenes with 14,000 frames of tool and camera motion
and tool jaw articulation, with a background of an ex-vivo porcine model. Using
this dataset, we synthetically replicate the scene deformation from the ground
truth data, allowing direct comparisons of synthetic image quality.
Experimental results illustrate that our method generates photo-realistic
labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio
(29.87). We further evaluate the performance of medical-specific neural
networks trained on real and synthetic images using an unseen real-world image
dataset. Our results show that the performance of models trained on synthetic
images generated by the proposed method outperforms those trained with
state-of-the-art standard data augmentation by 10%, leading to an overall
improvement in model performances by nearly 15%.

</details>


### [183] [Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation](https://arxiv.org/abs/2508.07901)
*Bowen Xue,Qixin Yan,Wenjing Wang,Hao Liu,Chen Li*

Main category: cs.CV

TL;DR: 提出了一种轻量级、即插即用的视频生成框架Stand-In，用于身份保留，仅需少量参数和训练数据即可实现高质量视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖过多训练参数且与其他AIGC工具不兼容，因此需要一种更高效的身份保留解决方案。

Method: 在预训练视频生成模型中引入条件图像分支，通过受限自注意力和条件位置映射实现身份控制，仅需2000对数据快速学习。

Result: 仅增加约1%参数即可在视频质量和身份保留上优于全参数训练方法，并可无缝集成到其他任务中。

Conclusion: Stand-In框架高效、灵活，适用于多种视频生成任务。

Abstract: Generating high-fidelity human videos that match user-specified identities is
important yet challenging in the field of generative AI. Existing methods often
rely on an excessive number of training parameters and lack compatibility with
other AIGC tools. In this paper, we propose Stand-In, a lightweight and
plug-and-play framework for identity preservation in video generation.
Specifically, we introduce a conditional image branch into the pre-trained
video generation model. Identity control is achieved through restricted
self-attentions with conditional position mapping, and can be learned quickly
with only 2000 pairs. Despite incorporating and training just $\sim$1\%
additional parameters, our framework achieves excellent results in video
quality and identity preservation, outperforming other full-parameter training
methods. Moreover, our framework can be seamlessly integrated for other tasks,
such as subject-driven video generation, pose-referenced video generation,
stylization, and face swapping.

</details>


### [184] [CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality](https://arxiv.org/abs/2508.07904)
*Marco Peer,Anna Scius-Bertrand,Andreas Fischer*

Main category: cs.CV

TL;DR: 提出了一种基于CTC对齐算法的自训练方法，用于解决历史文档手写文本识别中的标注错误问题，特别是连字符问题。


<details>
  <summary>Details</summary>
Motivation: 历史文档手写文本识别因书写变异性、文档退化及缺乏布局感知标注而具有挑战性。

Method: 采用基于CTC对齐算法的自训练方法，通过动态规划和模型输出概率匹配全文转录与文本行图像。

Result: 性能提升（如CER提高1.1个百分点），对齐准确性增加；发现较弱模型对齐更准确，支持迭代训练策略。

Conclusion: 方法可迭代应用以进一步提升CER和对齐质量，发布了手动校正的100页数据集和代码。

Abstract: Handwritten text recognition for historical documents remains challenging due
to handwriting variability, degraded sources, and limited layout-aware
annotations. In this work, we address annotation errors - particularly
hyphenation issues - in the Bullinger correspondence, a large 16th-century
letter collection. We introduce a self-training method based on a CTC alignment
algorithm that matches full transcriptions to text line images using dynamic
programming and model output probabilities trained with the CTC loss. Our
approach improves performance (e.g., by 1.1 percentage points CER with PyLaia)
and increases alignment accuracy. Interestingly, we find that weaker models
yield more accurate alignments, enabling an iterative training strategy. We
release a new manually corrected subset of 100 pages from the Bullinger
dataset, along with our code and benchmarks. Our approach can be applied
iteratively to further improve the CER as well as the alignment quality for
text recognition pipelines. Code and data are available via
https://github.com/andreas-fischer-unifr/nntp.

</details>


### [185] [Generative Video Matting](https://arxiv.org/abs/2508.07905)
*Yongtao Ge,Kangyang Xie,Guangkai Xu,Mingyu Liu,Li Ke,Longtao Huang,Hui Xue,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 论文提出了一种解决视频抠图问题的新方法，通过大规模预训练和合成数据生成，结合视频扩散模型的先验知识，显著提升了模型在真实场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统视频抠图方法因缺乏高质量真实数据而受限，现有数据集仅提供不完美的标注，导致模型泛化能力差。

Method: 提出两阶段方法：1) 利用合成和伪标注数据集进行大规模预训练；2) 设计基于视频扩散模型的新架构，确保时间一致性。

Result: 在三个基准数据集上表现优异，展示了在真实场景中的强泛化能力。

Conclusion: 通过合成数据与视频扩散模型的结合，显著提升了视频抠图的性能与泛化能力。

Abstract: Video matting has traditionally been limited by the lack of high-quality
ground-truth data. Most existing video matting datasets provide only
human-annotated imperfect alpha and foreground annotations, which must be
composited to background images or videos during the training stage. Thus, the
generalization capability of previous methods in real-world scenarios is
typically poor. In this work, we propose to solve the problem from two
perspectives. First, we emphasize the importance of large-scale pre-training by
pursuing diverse synthetic and pseudo-labeled segmentation datasets. We also
develop a scalable synthetic data generation pipeline that can render diverse
human bodies and fine-grained hairs, yielding around 200 video clips with a
3-second duration for fine-tuning. Second, we introduce a novel video matting
approach that can effectively leverage the rich priors from pre-trained video
diffusion models. This architecture offers two key advantages. First, strong
priors play a critical role in bridging the domain gap between synthetic and
real-world scenes. Second, unlike most existing methods that process video
matting frame-by-frame and use an independent decoder to aggregate temporal
information, our model is inherently designed for video, ensuring strong
temporal consistency. We provide a comprehensive quantitative evaluation across
three benchmark datasets, demonstrating our approach's superior performance,
and present comprehensive qualitative results in diverse real-world scenes,
illustrating the strong generalization capability of our method. The code is
available at https://github.com/aim-uofa/GVM.

</details>


### [186] [Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07908)
*Xudong Cai,Shuo Wang,Peng Wang,Yongcai Wang,Zhaoxin Fan,Wanting Li,Tianbao Zhang,Jianrong Tao,Yeying Jin,Deying Li*

Main category: cs.CV

TL;DR: Mem4D提出了一种双内存架构，分别处理静态结构和动态运动，解决了内存需求困境，实现了高保真动态重建和全局一致的静态几何。


<details>
  <summary>Details</summary>
Motivation: 单目视频中动态场景的密集几何重建是一个关键但具有挑战性的任务，现有方法在静态结构的长期稳定性和动态运动的高保真细节保留之间存在冲突。

Method: Mem4D采用双内存架构：瞬态动态内存（TDM）捕获高频运动细节，持久结构内存（PSM）压缩并保留长期空间信息。通过交替查询这两种内存，实现静态和动态内容的高效建模。

Result: 在基准测试中，Mem4D实现了最先进或竞争性性能，同时保持高效。

Conclusion: Mem4D通过解耦静态和动态建模，解决了内存需求困境，为动态场景重建提供了高效且高保真的解决方案。

Abstract: Reconstructing dense geometry for dynamic scenes from a monocular video is a
critical yet challenging task. Recent memory-based methods enable efficient
online reconstruction, but they fundamentally suffer from a Memory Demand
Dilemma: The memory representation faces an inherent conflict between the
long-term stability required for static structures and the rapid, high-fidelity
detail retention needed for dynamic motion. This conflict forces existing
methods into a compromise, leading to either geometric drift in static
structures or blurred, inaccurate reconstructions of dynamic objects. To
address this dilemma, we propose Mem4D, a novel framework that decouples the
modeling of static geometry and dynamic motion. Guided by this insight, we
design a dual-memory architecture: 1) The Transient Dynamics Memory (TDM)
focuses on capturing high-frequency motion details from recent frames, enabling
accurate and fine-grained modeling of dynamic content; 2) The Persistent
Structure Memory (PSM) compresses and preserves long-term spatial information,
ensuring global consistency and drift-free reconstruction for static elements.
By alternating queries to these specialized memories, Mem4D simultaneously
maintains static geometry with global consistency and reconstructs dynamic
elements with high fidelity. Experiments on challenging benchmarks demonstrate
that our method achieves state-of-the-art or competitive performance while
maintaining high efficiency. Codes will be publicly available.

</details>


### [187] [RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering](https://arxiv.org/abs/2508.07918)
*Xing Zi,Jinghao Xiao,Yunxiao Shi,Xian Tao,Jun Li,Ali Braytee,Mukesh Prasad*

Main category: cs.CV

TL;DR: 本文介绍了RSVLM-QA数据集，一个用于遥感视觉问答（VQA）的大规模、内容丰富的数据集，旨在解决现有数据集在标注丰富性、问题多样性和推理能力评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有遥感VQA数据集在标注丰富性、问题多样性和推理能力评估上存在局限性，需要更全面的数据集推动研究。

Method: 通过整合多个遥感数据集，利用GPT-4.1自动生成详细标注和复杂问答对，并开发专门流程处理对象计数任务。

Result: RSVLM-QA包含13,820张图像和162,373个问答对，标注丰富且问题多样，实验表明其能有效评估主流视觉语言模型的推理能力。

Conclusion: RSVLM-QA将成为遥感VQA和视觉语言模型研究的重要资源，推动领域发展。

Abstract: Visual Question Answering (VQA) in remote sensing (RS) is pivotal for
interpreting Earth observation data. However, existing RS VQA datasets are
constrained by limitations in annotation richness, question diversity, and the
assessment of specific reasoning capabilities. This paper introduces RSVLM-QA
dataset, a new large-scale, content-rich VQA dataset for the RS domain.
RSVLM-QA is constructed by integrating data from several prominent RS
segmentation and detection datasets: WHU, LoveDA, INRIA, and iSAID. We employ
an innovative dual-track annotation generation pipeline. Firstly, we leverage
Large Language Models (LLMs), specifically GPT-4.1, with meticulously designed
prompts to automatically generate a suite of detailed annotations including
image captions, spatial relations, and semantic tags, alongside complex
caption-based VQA pairs. Secondly, to address the challenging task of object
counting in RS imagery, we have developed a specialized automated process that
extracts object counts directly from the original segmentation data; GPT-4.1
then formulates natural language answers from these counts, which are paired
with preset question templates to create counting QA pairs. RSVLM-QA comprises
13,820 images and 162,373 VQA pairs, featuring extensive annotations and
diverse question types. We provide a detailed statistical analysis of the
dataset and a comparison with existing RS VQA benchmarks, highlighting the
superior depth and breadth of RSVLM-QA's annotations. Furthermore, we conduct
benchmark experiments on Six mainstream Vision Language Models (VLMs),
demonstrating that RSVLM-QA effectively evaluates and challenges the
understanding and reasoning abilities of current VLMs in the RS domain. We
believe RSVLM-QA will serve as a pivotal resource for the RS VQA and VLM
research communities, poised to catalyze advancements in the field.

</details>


### [188] [TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding](https://arxiv.org/abs/2508.07925)
*Jin-Seop Lee,SungJoon Lee,Jaehan Ahn,YunSeok Choi,Jee-Hyong Lee*

Main category: cs.CV

TL;DR: 论文提出了一种名为TAG的零样本视频时间定位方法，通过时间池化、时间相干性聚类和相似性调整，解决了现有方法中的语义碎片化和相似性分布偏差问题，无需依赖大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有零样本视频时间定位方法存在语义碎片化和相似性分布偏差问题，且依赖昂贵的大型语言模型。

Method: 提出TAG方法，结合时间池化、时间相干性聚类和相似性调整，无需训练即可捕捉视频时间上下文。

Result: 在Charades-STA和ActivityNet Captions基准数据集上取得最先进结果。

Conclusion: TAG是一种简单有效的零样本视频时间定位方法，解决了现有方法的局限性。

Abstract: Video Temporal Grounding (VTG) aims to extract relevant video segments based
on a given natural language query. Recently, zero-shot VTG methods have gained
attention by leveraging pretrained vision-language models (VLMs) to localize
target moments without additional training. However, existing approaches suffer
from semantic fragmentation, where temporally continuous frames sharing the
same semantics are split across multiple segments. When segments are
fragmented, it becomes difficult to predict an accurate target moment that
aligns with the text query. Also, they rely on skewed similarity distributions
for localization, making it difficult to select the optimal segment.
Furthermore, they heavily depend on the use of LLMs which require expensive
inferences. To address these limitations, we propose a \textit{TAG}, a simple
yet effective Temporal-Aware approach for zero-shot video temporal Grounding,
which incorporates temporal pooling, temporal coherence clustering, and
similarity adjustment. Our proposed method effectively captures the temporal
context of videos and addresses distorted similarity distributions without
training. Our approach achieves state-of-the-art results on Charades-STA and
ActivityNet Captions benchmark datasets without rely on LLMs. Our code is
available at https://github.com/Nuetee/TAG

</details>


### [189] [VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security](https://arxiv.org/abs/2508.07960)
*Ajnas Muhammed,Iurri Medvedev,Nuno Gonçalves*

Main category: cs.CV

TL;DR: VOIDFace提出了一种新型面部识别框架，通过视觉秘密共享消除数据复制，并采用基于补丁的多训练网络，提升隐私保护和数据控制。


<details>
  <summary>Details</summary>
Motivation: 当前面部识别系统存在数据复制和隐私控制不足的问题，用户无法控制其数据使用，引发隐私和伦理担忧。

Method: 使用视觉秘密共享技术安全存储训练数据，提出基于补丁的多训练网络，结合新型数据存储机制。

Result: 在VGGFace2数据集上的实验表明，VOIDFace实现了数据控制、隐私保护和遗忘权，同时保持竞争力。

Conclusion: VOIDFace通过技术创新解决了数据复制和隐私问题，为面部识别系统提供了更安全高效的解决方案。

Abstract: Advancement of machine learning techniques, combined with the availability of
large-scale datasets, has significantly improved the accuracy and efficiency of
facial recognition. Modern facial recognition systems are trained using large
face datasets collected from diverse individuals or public repositories.
However, for training, these datasets are often replicated and stored in
multiple workstations, resulting in data replication, which complicates
database management and oversight. Currently, once a user submits their face
for dataset preparation, they lose control over how their data is used, raising
significant privacy and ethical concerns. This paper introduces VOIDFace, a
novel framework for facial recognition systems that addresses two major issues.
First, it eliminates the need of data replication and improves data control to
securely store training face data by using visual secret sharing. Second, it
proposes a patch-based multi-training network that uses this novel training
data storage mechanism to develop a robust, privacy-preserving facial
recognition system. By integrating these advancements, VOIDFace aims to improve
the privacy, security, and efficiency of facial recognition training, while
ensuring greater control over sensitive personal face data. VOIDFace also
enables users to exercise their Right-To-Be-Forgotten property to control their
personal data. Experimental evaluations on the VGGFace2 dataset show that
VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and
privacy while maintaining competitive facial recognition performance. Code is
available at: https://github.com/ajnasmuhammed89/VOIDFace

</details>


### [190] [TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking](https://arxiv.org/abs/2508.07968)
*Tony Danjun Wang,Christian Heiliger,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: TrackOR框架通过3D几何特征实现手术室中长期多人跟踪与重识别，提升关联准确性11%，并支持离线恢复生成分析轨迹。


<details>
  <summary>Details</summary>
Motivation: 为手术团队提供智能支持，改善患者结果，需解决长期多人跟踪的计算挑战。

Method: 利用3D几何特征进行在线跟踪与离线恢复。

Result: TrackOR实现11%关联准确性提升，支持持久身份跟踪。

Conclusion: 3D几何信息使手术室个性化智能系统成为可能，提升团队效率与安全性。

Abstract: Providing intelligent support to surgical teams is a key frontier in
automated surgical scene understanding, with the long-term goal of improving
patient outcomes. Developing personalized intelligence for all staff members
requires maintaining a consistent state of who is located where for long
surgical procedures, which still poses numerous computational challenges. We
propose TrackOR, a framework for tackling long-term multi-person tracking and
re-identification in the operating room. TrackOR uses 3D geometric signatures
to achieve state-of-the-art online tracking performance (+11% Association
Accuracy over the strongest baseline), while also enabling an effective offline
recovery process to create analysis-ready trajectories. Our work shows that by
leveraging 3D geometric information, persistent identity tracking becomes
attainable, enabling a critical shift towards the more granular, staff-centric
analyses required for personalized intelligent systems in the operating room.
This new capability opens up various applications, including our proposed
temporal pathway imprints that translate raw tracking data into actionable
insights for improving team efficiency and safety and ultimately providing
personalized support.

</details>


### [191] [Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](https://arxiv.org/abs/2508.07981)
*Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: Omni-Effects提出了一种统一框架，支持提示引导的多效果生成和空间可控的复合效果，解决了现有方法在多效果联合训练中的干扰和空间不可控问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在视觉特效（VFX）生产中受限于单效果训练，无法实现多效果的空间可控复合生成。

Method: 提出了LoRA-MoE（基于LoRA的专家混合）和SAP（空间感知提示）两大创新，结合IIF模块，实现多效果集成与空间控制。

Result: 实验表明，Omni-Effects能够精确控制效果的空间位置和类别，生成多样化的复合效果。

Conclusion: Omni-Effects为多效果生成提供了统一且高效的解决方案，推动了VFX生产的发展。

Abstract: Visual effects (VFX) are essential visual enhancements fundamental to modern
cinematic production. Although video generation models offer cost-efficient
solutions for VFX production, current methods are constrained by per-effect
LoRA training, which limits generation to single effects. This fundamental
limitation impedes applications that require spatially controllable composite
effects, i.e., the concurrent generation of multiple effects at designated
locations. However, integrating diverse effects into a unified framework faces
major challenges: interference from effect variations and spatial
uncontrollability during multi-VFX joint training. To tackle these challenges,
we propose Omni-Effects, a first unified framework capable of generating
prompt-guided effects and spatially controllable composite effects. The core of
our framework comprises two key innovations: (1) LoRA-based Mixture of Experts
(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects
within a unified model while effectively mitigating cross-task interference.
(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the
text token, enabling precise spatial control. Furthermore, we introduce an
Independent-Information Flow (IIF) module integrated within the SAP, isolating
the control signals corresponding to individual effects to prevent any unwanted
blending. To facilitate this research, we construct a comprehensive VFX dataset
Omni-VFX via a novel data collection pipeline combining image editing and
First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX
evaluation framework for validating model performance. Extensive experiments
demonstrate that Omni-Effects achieves precise spatial control and diverse
effect generation, enabling users to specify both the category and location of
desired effects.

</details>


### [192] [Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models](https://arxiv.org/abs/2508.07996)
*Thinesh Thiyakesan Ponbagavathi,Chengzheng Yang,Alina Roitberg*

Main category: cs.CV

TL;DR: ProGraD利用可学习的群体提示和轻量级GroupContext Transformer，显著提升了群体活动检测性能，尤其在复杂多群体场景中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型（VFMs）在群体动态建模方面未充分探索，且直接替换CNN骨干网络效果有限，需要更结构化的群体感知推理。

Method: 提出ProGraD方法，包括可学习的群体提示引导VFM注意力，以及轻量级GroupContext Transformer推断演员-群体关联和集体行为。

Result: 在两个GAD基准测试中超越现有技术，尤其在多群体场景中提升显著（Group mAP@1.0提升6.5%，Group mAP@0.5提升8.2%）。

Conclusion: ProGraD不仅性能优越，还能生成可解释的注意力图，为群体推理提供洞察。

Abstract: Group Activity Detection (GAD) involves recognizing social groups and their
collective behaviors in videos. Vision Foundation Models (VFMs), like DinoV2,
offer excellent features, but are pretrained primarily on object-centric data
and remain underexplored for modeling group dynamics. While they are a
promising alternative to highly task-specific GAD architectures that require
full fine-tuning, our initial investigation reveals that simply swapping CNN
backbones used in these methods with VFMs brings little gain, underscoring the
need for structured, group-aware reasoning on top.
  We introduce Prompt-driven Group Activity Detection (ProGraD) -- a method
that bridges this gap through 1) learnable group prompts to guide the VFM
attention toward social configurations, and 2) a lightweight two-layer
GroupContext Transformer that infers actor-group associations and collective
behavior. We evaluate our approach on two recent GAD benchmarks: Cafe, which
features multiple concurrent social groups, and Social-CAD, which focuses on
single-group interactions. While we surpass state-of-the-art in both settings,
our method is especially effective in complex multi-group scenarios, where we
yield a gain of 6.5\% (Group mAP\@1.0) and 8.2\% (Group mAP\@0.5) using only
10M trainable parameters. Furthermore, our experiments reveal that ProGraD
produces interpretable attention maps, offering insights into actor-group
reasoning. Code and models will be released.

</details>


### [193] [Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition](https://arxiv.org/abs/2508.08004)
*Anqi Xiao,Weichen Yu,Hongyuan Yu*

Main category: cs.CV

TL;DR: SRA是一种无需搜索的自动数据增强方法，通过动态调整增强策略和启发式评分模块，显著提升了性能，并在ImageNet上达到78.31%的Top-1准确率。


<details>
  <summary>Details</summary>
Motivation: 主流AutoDA方法存在搜索耗时或性能不足的问题，SRA旨在解决这些挑战。

Method: SRA采用启发式评分模块评估数据复杂性，并应用非对称增强策略。

Result: SRA在ImageNet上达到78.31%的Top-1准确率，并展示了良好的兼容性和泛化能力。

Conclusion: SRA是一种简单、高效且实用的AutoDA设计，适用于多种未来任务。

Abstract: Automatic data augmentation (AutoDA) plays an important role in enhancing the
generalization of neural networks. However, mainstream AutoDA methods often
encounter two challenges: either the search process is excessively
time-consuming, hindering practical application, or the performance is
suboptimal due to insufficient policy adaptation during training. To address
these issues, we propose Sample-aware RandAugment (SRA), an asymmetric,
search-free AutoDA method that dynamically adjusts augmentation policies while
maintaining straightforward implementation. SRA incorporates a heuristic
scoring module that evaluates the complexity of the original training data,
enabling the application of tailored augmentations for each sample.
Additionally, an asymmetric augmentation strategy is employed to maximize the
potential of this scoring module. In multiple experimental settings, SRA
narrows the performance gap between search-based and search-free AutoDA
methods, achieving a state-of-the-art Top-1 accuracy of 78.31\% on ImageNet
with ResNet-50. Notably, SRA demonstrates good compatibility with existing
augmentation pipelines and solid generalization across new tasks, without
requiring hyperparameter tuning. The pretrained models leveraging SRA also
enhance recognition in downstream object detection tasks. SRA represents a
promising step towards simpler, more effective, and practical AutoDA designs
applicable to a variety of future tasks. Our code is available at
\href{https://github.com/ainieli/Sample-awareRandAugment}{https://github.com/ainieli/Sample-awareRandAugment

</details>


### [194] [Mitigating Biases in Surgical Operating Rooms with Geometry](https://arxiv.org/abs/2508.08028)
*Tony Danjun Wang,Tobias Czempiel,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: 论文通过分析手术室中深度学习模型的偏差问题，提出使用3D点云序列方法避免外观干扰，提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 手术室中标准化服装掩盖了关键特征，导致模型依赖无关视觉线索（如鞋子或眼镜），影响任务准确性。

Method: 采用梯度显著性分析揭示CNN模型的偏差，并提出基于3D点云序列的方法，分离形状和运动特征。

Result: 实验显示，RGB模型在临床环境中性能下降12%，而几何方法表现更稳定。

Conclusion: 几何表示能捕捉更有意义的生物特征，为手术室智能辅助系统提供更鲁棒的建模方法。

Abstract: Deep neural networks are prone to learning spurious correlations, exploiting
dataset-specific artifacts rather than meaningful features for prediction. In
surgical operating rooms (OR), these manifest through the standardization of
smocks and gowns that obscure robust identifying landmarks, introducing model
bias for tasks related to modeling OR personnel. Through gradient-based
saliency analysis on two public OR datasets, we reveal that CNN models succumb
to such shortcuts, fixating on incidental visual cues such as footwear beneath
surgical gowns, distinctive eyewear, or other role-specific identifiers.
Avoiding such biases is essential for the next generation of intelligent
assistance systems in the OR, which should accurately recognize personalized
workflow traits, such as surgical skill level or coordination with other staff
members. We address this problem by encoding personnel as 3D point cloud
sequences, disentangling identity-relevant shape and motion patterns from
appearance-based confounders. Our experiments demonstrate that while RGB and
geometric methods achieve comparable performance on datasets with apparent
simulation artifacts, RGB models suffer a 12% accuracy drop in realistic
clinical settings with decreased visual diversity due to standardizations. This
performance gap confirms that geometric representations capture more meaningful
biometric features, providing an avenue to developing robust methods of
modeling humans in the OR.

</details>


### [195] [TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation](https://arxiv.org/abs/2508.08038)
*Huawei Sun,Zixu Wang,Hao Feng,Julius Ott,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: 论文提出了一种结合雷达-相机融合和文本特征提取的深度估计方法TRIDE，通过天气感知融合块优化性能，在KITTI和nuScenes数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有雷达-相机融合算法未考虑天气条件对传感器性能的影响，且视觉-语言模型在深度估计中的应用尚未充分探索。

Method: 提出文本生成策略和特征融合技术，结合雷达点信息增强文本特征提取，并设计天气感知融合块动态调整雷达权重。

Result: 在nuScenes数据集上，MAE和RMSE分别提升12.87%和9.08%。

Conclusion: TRIDE通过多模态融合和天气适应性设计，显著提升了深度估计的准确性。

Abstract: Depth estimation, essential for autonomous driving, seeks to interpret the 3D
environment surrounding vehicles. The development of radar sensors, known for
their cost-efficiency and robustness, has spurred interest in radar-camera
fusion-based solutions. However, existing algorithms fuse features from these
modalities without accounting for weather conditions, despite radars being
known to be more robust than cameras under adverse weather. Additionally, while
Vision-Language models have seen rapid advancement, utilizing language
descriptions alongside other modalities for depth estimation remains an open
challenge. This paper first introduces a text-generation strategy along with
feature extraction and fusion techniques that can assist monocular depth
estimation pipelines, leading to improved accuracy across different algorithms
on the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion
algorithm that enhances text feature extraction by incorporating radar point
information. To address the impact of weather on sensor performance, we
introduce a weather-aware fusion block that adaptively adjusts radar weighting
based on current weather conditions. Our method, benchmarked on the nuScenes
dataset, demonstrates performance gains over the state-of-the-art, achieving a
12.87% improvement in MAE and a 9.08% improvement in RMSE. Code:
https://github.com/harborsarah/TRIDE

</details>


### [196] [S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix](https://arxiv.org/abs/2508.08048)
*Peng Dai,Feitong Tan,Qiangeng Xu,Yihua Huang,David Futschik,Ruofei Du,Sean Fanello,Yinda Zhang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 提出了一种无需姿态估计和额外训练的3D视频生成方法，利用现有单目视频生成模型，通过深度估计和帧矩阵修复框架生成沉浸式3D视频。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在单目视频上表现优异，但生成3D立体和空间视频的研究较少，亟需一种高效且无需额外训练的方法。

Method: 通过深度估计将单目视频映射到预设视角，使用帧矩阵修复框架合成缺失内容，并采用双更新机制提升修复质量。

Result: 实验表明，该方法在多种生成模型（如Sora、Lumiere等）上显著优于现有方法。

Conclusion: 该方法为3D视频生成提供了一种高效且无需额外训练的解决方案，具有广泛的应用潜力。

Abstract: While video generation models excel at producing high-quality monocular
videos, generating 3D stereoscopic and spatial videos for immersive
applications remains an underexplored challenge. We present a pose-free and
training-free method that leverages an off-the-shelf monocular video generation
model to produce immersive 3D videos. Our approach first warps the generated
monocular video into pre-defined camera viewpoints using estimated depth
information, then applies a novel \textit{frame matrix} inpainting framework.
This framework utilizes the original video generation model to synthesize
missing content across different viewpoints and timestamps, ensuring spatial
and temporal consistency without requiring additional model fine-tuning.
Moreover, we develop a \dualupdate~scheme that further improves the quality of
video inpainting by alleviating the negative effects propagated from
disoccluded areas in the latent space. The resulting multi-view videos are then
adapted into stereoscopic pairs or optimized into 4D Gaussians for spatial
video synthesis. We validate the efficacy of our proposed method by conducting
experiments on videos from various generative models, such as Sora, Lumiere,
WALT, and Zeroscope. The experiments demonstrate that our method has a
significant improvement over previous methods. Project page at:
https://daipengwa.github.io/S-2VG_ProjectPage/

</details>


### [197] [Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition](https://arxiv.org/abs/2508.08069)
*Xiaoxiao Cui,Yiran Li,Kai He,Shanzhi Jiang,Mengli Xue,Wentao Li,Junhong Leng,Zhi Liu,Lizhen Cui,Shuo Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于信息瓶颈的因果注意力方法（IBCA），用于医学图像的多标签分类，通过高斯混合多标签空间注意力过滤无关信息，并通过对比增强因果干预减少虚假注意力。


<details>
  <summary>Details</summary>
Motivation: 当前方法在医学图像多标签分类中难以区分因果和虚假注意力，导致分类不准确。

Method: 提出SCM模型，将类特定注意力分解为因果、虚假和噪声因素，并设计IBCA方法，结合高斯混合多标签空间注意力和对比增强因果干预。

Result: 在Endo和MuReD数据集上，IBCA在多项指标上优于其他方法，如CR、OR和mAP。

Conclusion: IBCA能有效学习类特定注意力，提升医学图像多标签分类的准确性和可解释性。

Abstract: Multi-label classification (MLC) of medical images aims to identify multiple
diseases and holds significant clinical potential. A critical step is to learn
class-specific features for accurate diagnosis and improved interpretability
effectively. However, current works focus primarily on causal attention to
learn class-specific features, yet they struggle to interpret the true cause
due to the inadvertent attention to class-irrelevant features. To address this
challenge, we propose a new structural causal model (SCM) that treats
class-specific attention as a mixture of causal, spurious, and noisy factors,
and a novel Information Bottleneck-based Causal Attention (IBCA) that is
capable of learning the discriminative class-specific attention for MLC of
medical images. Specifically, we propose learning Gaussian mixture multi-label
spatial attention to filter out class-irrelevant information and capture each
class-specific attention pattern. Then a contrastive enhancement-based causal
intervention is proposed to gradually mitigate the spurious attention and
reduce noise information by aligning multi-head attention with the Gaussian
mixture multi-label spatial. Quantitative and ablation results on Endo and
MuReD show that IBCA outperforms all methods. Compared to the second-best
results for each metric, IBCA achieves improvements of 6.35\% in CR, 7.72\% in
OR, and 5.02\% in mAP for MuReD, 1.47\% in CR, and 1.65\% in CF1, and 1.42\% in
mAP for Endo.

</details>


### [198] [ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness](https://arxiv.org/abs/2508.08082)
*Zizheng Guo,Bochao Zou,Junbao Zhuo,Huimin Ma*

Main category: cs.CV

TL;DR: 该论文提出两种基于状态空间模型的架构（ME-TST和ME-TST+），用于微表情（ME）的检测和识别，通过时间状态转换机制和协同策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用固定窗口长度和硬分类，且将ME检测与识别视为独立任务，忽略了其内在联系，导致性能受限。

Method: 提出ME-TST和ME-TST+架构，采用时间状态转换机制替代传统窗口分类，支持视频级回归和多粒度ROI建模，并引入慢快Mamba框架。

Result: 实验表明，所提方法在ME分析中达到最先进性能。

Conclusion: 通过协同策略和时间动态建模，新方法显著提升了ME分析的准确性和灵活性。

Abstract: Micro-expressions (MEs) are regarded as important indicators of an
individual's intrinsic emotions, preferences, and tendencies. ME analysis
requires spotting of ME intervals within long video sequences and recognition
of their corresponding emotional categories. Previous deep learning approaches
commonly employ sliding-window classification networks. However, the use of
fixed window lengths and hard classification presents notable limitations in
practice. Furthermore, these methods typically treat ME spotting and
recognition as two separate tasks, overlooking the essential relationship
between them. To address these challenges, this paper proposes two state space
model-based architectures, namely ME-TST and ME-TST+, which utilize temporal
state transition mechanisms to replace conventional window-level classification
with video-level regression. This enables a more precise characterization of
the temporal dynamics of MEs and supports the modeling of MEs with varying
durations. In ME-TST+, we further introduce multi-granularity ROI modeling and
the slowfast Mamba framework to alleviate information loss associated with
treating ME analysis as a time-series task. Additionally, we propose a synergy
strategy for spotting and recognition at both the feature and result levels,
leveraging their intrinsic connection to enhance overall analysis performance.
Extensive experiments demonstrate that the proposed methods achieve
state-of-the-art performance. The codes are available at
https://github.com/zizheng-guo/ME-TST.

</details>


### [199] [3D Plant Root Skeleton Detection and Extraction](https://arxiv.org/abs/2508.08094)
*Jiakai Lin,Jinchang Zhang,Ge Jin,Wenzhan Song,Tianming Liu,Guoyu Lu*

Main category: cs.CV

TL;DR: 提出了一种从少量图像中提取植物根系3D骨架的方法，解决了根系复杂结构和缺乏纹理信息的问题，验证了模型的有效性，并展示了其在自动化育种机器人中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 植物根系结构复杂且缺乏纹理信息，传统2D研究难以满足需求，3D根系表型信息对研究遗传性状和根系发育至关重要。

Method: 通过检测和匹配侧根、三角测量提取侧根骨架结构，并整合侧根与主根，从少量图像中高效提取3D根系结构。

Result: 在复杂根系数据集上测试，提取的3D骨架与真实结构高度相似，验证了模型的有效性。

Conclusion: 该方法为自动化育种机器人提供了精确的3D根系分析工具，可提升育种效率和智能化水平，推动现代农业发展。

Abstract: Plant roots typically exhibit a highly complex and dense architecture,
incorporating numerous slender lateral roots and branches, which significantly
hinders the precise capture and modeling of the entire root system.
Additionally, roots often lack sufficient texture and color information, making
it difficult to identify and track root traits using visual methods. Previous
research on roots has been largely confined to 2D studies; however, exploring
the 3D architecture of roots is crucial in botany. Since roots grow in real 3D
space, 3D phenotypic information is more critical for studying genetic traits
and their impact on root development. We have introduced a 3D root skeleton
extraction method that efficiently derives the 3D architecture of plant roots
from a few images. This method includes the detection and matching of lateral
roots, triangulation to extract the skeletal structure of lateral roots, and
the integration of lateral and primary roots. We developed a highly complex
root dataset and tested our method on it. The extracted 3D root skeletons
showed considerable similarity to the ground truth, validating the
effectiveness of the model. This method can play a significant role in
automated breeding robots. Through precise 3D root structure analysis, breeding
robots can better identify plant phenotypic traits, especially root structure
and growth patterns, helping practitioners select seeds with superior root
systems. This automated approach not only improves breeding efficiency but also
reduces manual intervention, making the breeding process more intelligent and
efficient, thus advancing modern agriculture.

</details>


### [200] [TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning](https://arxiv.org/abs/2508.08098)
*Junzhe Xu,Yuyang Yin,Xi Chen*

Main category: cs.CV

TL;DR: TBAC-UniImage通过将预训练的扩散模型与多模态大语言模型（MLLM）深度结合，提出了一种新的统一模型，解决了现有方法中生成条件浅层和计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散统一模型存在生成条件浅层（仅使用MLLM的最终隐藏状态）或计算成本高（从头预训练统一架构）的问题，需要一种更高效且深度结合的方法。

Method: 利用MLLM多个不同层的表示作为扩散模型的生成条件，将预训练生成器视为“梯子”，从MLLM的多层次理解过程中获取指导。

Result: TBAC-UniImage实现了更深层次、更细粒度的理解与生成统一。

Conclusion: 该方法为多模态理解与生成提供了一种高效且深度结合的新范式。

Abstract: This paper introduces TBAC-UniImage, a novel unified model for multimodal
understanding and generation. We achieve this by deeply integrating a
pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal
Large Language Model (MLLM). Previous diffusion-based unified models face two
primary limitations. One approach uses only the MLLM's final hidden state as
the generative condition. This creates a shallow connection, as the generator
is isolated from the rich, hierarchical representations within the MLLM's
intermediate layers. The other approach, pretraining a unified generative
architecture from scratch, is computationally expensive and prohibitive for
many researchers. To overcome these issues, our work explores a new paradigm.
Instead of relying on a single output, we use representations from multiple,
diverse layers of the MLLM as generative conditions for the diffusion model.
This method treats the pre-trained generator as a ladder, receiving guidance
from various depths of the MLLM's understanding process. Consequently,
TBAC-UniImage achieves a much deeper and more fine-grained unification of
understanding and generation.

</details>


### [201] [Hyperspectral Imaging](https://arxiv.org/abs/2508.08107)
*Danfeng Hong,Chenyu Li,Naoto Yokoya,Bing Zhang,Xiuping Jia,Antonio Plaza,Paolo Gamba,Jon Atli Benediktsson,Jocelyn Chanussot*

Main category: cs.CV

TL;DR: 这篇论文概述了高光谱成像（HSI）的基本原理、数据采集与分析方法，以及其在多个领域的应用，同时探讨了当前挑战与未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像能够同时捕捉空间和光谱信息，为非侵入性、无标记的材料、化学和生物分析提供了强大工具。本文旨在全面介绍HSI技术及其应用。

Method: 论文从物理原理和传感器架构出发，总结了数据采集、校准和校正的关键步骤，并介绍了传统和现代分析方法，如降维、分类、光谱解混和深度学习。

Result: HSI在遥感、精准农业、生物医学、工业检测、文化遗产和安全等领域有广泛应用，能够揭示亚视觉特征以支持高级监测和决策。

Conclusion: 尽管面临硬件限制和数据复杂性等挑战，但通过计算成像、跨模态融合和自监督学习等新兴技术，HSI有望成为跨学科通用平台，推动科学和社会的变革。

Abstract: Hyperspectral imaging (HSI) is an advanced sensing modality that
simultaneously captures spatial and spectral information, enabling
non-invasive, label-free analysis of material, chemical, and biological
properties. This Primer presents a comprehensive overview of HSI, from the
underlying physical principles and sensor architectures to key steps in data
acquisition, calibration, and correction. We summarize common data structures
and highlight classical and modern analysis methods, including dimensionality
reduction, classification, spectral unmixing, and AI-driven techniques such as
deep learning. Representative applications across Earth observation, precision
agriculture, biomedicine, industrial inspection, cultural heritage, and
security are also discussed, emphasizing HSI's ability to uncover sub-visual
features for advanced monitoring, diagnostics, and decision-making. Persistent
challenges, such as hardware trade-offs, acquisition variability, and the
complexity of high-dimensional data, are examined alongside emerging solutions,
including computational imaging, physics-informed modeling, cross-modal fusion,
and self-supervised learning. Best practices for dataset sharing,
reproducibility, and metadata documentation are further highlighted to support
transparency and reuse. Looking ahead, we explore future directions toward
scalable, real-time, and embedded HSI systems, driven by sensor
miniaturization, self-supervised learning, and foundation models. As HSI
evolves into a general-purpose, cross-disciplinary platform, it holds promise
for transformative applications in science, technology, and society.

</details>


### [202] [GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking](https://arxiv.org/abs/2508.08117)
*Xudong Han,Pengcheng Fang,Yueying Tian,Jianhui Yu,Xiaohao Cai,Daniel Roggen,Philip Birch*

Main category: cs.CV

TL;DR: GRASPTrack是一种新型深度感知多目标跟踪框架，通过结合单目深度估计和实例分割，解决了传统跟踪方法在遮挡和深度模糊问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统基于检测的跟踪方法缺乏几何感知能力，难以解决遮挡和深度模糊问题。

Method: GRASPTrack将单目深度估计和实例分割整合到标准跟踪流程中，生成3D点云，并通过体素化实现精确的空间关联。此外，采用深度感知自适应噪声补偿和深度增强的动量方法提升跟踪鲁棒性。

Result: 在MOT17、MOT20和DanceTrack基准测试中表现优异，显著提升了复杂场景下的跟踪性能。

Conclusion: GRASPTrack通过引入3D几何推理和动态噪声补偿，有效提升了多目标跟踪在遮挡和复杂运动场景中的鲁棒性。

Abstract: Multi-object tracking (MOT) in monocular videos is fundamentally challenged
by occlusions and depth ambiguity, issues that conventional
tracking-by-detection (TBD) methods struggle to resolve owing to a lack of
geometric awareness. To address these limitations, we introduce GRASPTrack, a
novel depth-aware MOT framework that integrates monocular depth estimation and
instance segmentation into a standard TBD pipeline to generate high-fidelity 3D
point clouds from 2D detections, thereby enabling explicit 3D geometric
reasoning. These 3D point clouds are then voxelized to enable a precise and
robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To
further enhance tracking robustness, our approach incorporates Depth-aware
Adaptive Noise Compensation, which dynamically adjusts the Kalman filter
process noise based on occlusion severity for more reliable state estimation.
Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which
extends the motion direction consistency from the image plane into 3D space to
improve motion-based association cues, particularly for objects with complex
trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack
benchmarks demonstrate that our method achieves competitive performance,
significantly improving tracking robustness in complex scenes with frequent
occlusions and intricate motion patterns.

</details>


### [203] [Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control](https://arxiv.org/abs/2508.08134)
*Zeqian Long,Mingzhe Zheng,Kunyu Feng,Xinhua Zhang,Hongyu Liu,Harry Yang,Linfeng Zhang,Qifeng Chen,Yue Ma*

Main category: cs.CV

TL;DR: 提出了一种无需训练和掩码的图像编辑框架Follow-Your-Shape，通过轨迹差异图（TDM）和KV注入机制实现精确形状编辑，并引入新评测基准ReShapeBench。


<details>
  <summary>Details</summary>
Motivation: 现有流式图像编辑模型在大规模形状变换任务中表现不佳，容易破坏非目标区域。

Method: 计算轨迹差异图（TDM）定位可编辑区域，结合KV注入机制实现稳定编辑。

Result: 实验表明，该方法在形状替换任务中具有更高的编辑能力和视觉保真度。

Conclusion: Follow-Your-Shape框架在形状编辑任务中表现出色，且无需额外训练或掩码支持。

Abstract: While recent flow-based image editing models demonstrate general-purpose
capabilities across diverse tasks, they often struggle to specialize in
challenging scenarios -- particularly those involving large-scale shape
transformations. When performing such structural edits, these methods either
fail to achieve the intended shape change or inadvertently alter non-target
regions, resulting in degraded background quality. We propose
Follow-Your-Shape, a training-free and mask-free framework that supports
precise and controllable editing of object shapes while strictly preserving
non-target content. Motivated by the divergence between inversion and editing
trajectories, we compute a Trajectory Divergence Map (TDM) by comparing
token-wise velocity differences between the inversion and denoising paths. The
TDM enables precise localization of editable regions and guides a Scheduled KV
Injection mechanism that ensures stable and faithful editing. To facilitate a
rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120
new images and enriched prompt pairs specifically curated for shape-aware
editing. Experiments demonstrate that our method achieves superior editability
and visual fidelity, particularly in tasks requiring large-scale shape
replacement.

</details>


### [204] [FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting](https://arxiv.org/abs/2508.08136)
*Yitong Yang,Yinglin Wang,Changshuo Wang,Huajie Wang,Shuting He*

Main category: cs.CV

TL;DR: FantasyStyle是一个基于3DGS的风格迁移框架，首次完全依赖扩散模型蒸馏，解决了多视角不一致性和VGG特征依赖问题。


<details>
  <summary>Details</summary>
Motivation: 当前3DGS风格迁移方法存在多视角不一致导致的风格冲突和VGG特征难以分离内容与风格的问题。

Method: 提出多视角频率一致性和可控风格蒸馏，通过3D滤波和负引导优化3D高斯分布。

Result: 实验表明，该方法在多种场景和风格下均优于现有技术，实现了更高的风格化质量和视觉真实感。

Conclusion: FantasyStyle通过创新方法显著提升了3D风格迁移的效果，为未来研究提供了新方向。

Abstract: The success of 3DGS in generative and editing applications has sparked
growing interest in 3DGS-based style transfer. However, current methods still
face two major challenges: (1) multi-view inconsistency often leads to style
conflicts, resulting in appearance smoothing and distortion; and (2) heavy
reliance on VGG features, which struggle to disentangle style and content from
style images, often causing content leakage and excessive stylization. To
tackle these issues, we introduce \textbf{FantasyStyle}, a 3DGS-based style
transfer framework, and the first to rely entirely on diffusion model
distillation. It comprises two key components: (1) \textbf{Multi-View Frequency
Consistency}. We enhance cross-view consistency by applying a 3D filter to
multi-view noisy latent, selectively reducing low-frequency components to
mitigate stylized prior conflicts. (2) \textbf{Controllable Stylized
Distillation}. To suppress content leakage from style images, we introduce
negative guidance to exclude undesired content. In addition, we identify the
limitations of Score Distillation Sampling and Delta Denoising Score in 3D
style transfer and remove the reconstruction term accordingly. Building on
these insights, we propose a controllable stylized distillation that leverages
negative guidance to more effectively optimize the 3D Gaussians. Extensive
experiments demonstrate that our method consistently outperforms
state-of-the-art approaches, achieving higher stylization quality and visual
realism across various scenes and styles.

</details>


### [205] [ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction](https://arxiv.org/abs/2508.08170)
*Chaojun Ni,Guosheng Zhao,Xiaofeng Wang,Zheng Zhu,Wenkang Qin,Xinze Chen,Guanghong Jia,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: 提出ReconDreamer-RL框架，结合视频扩散先验和运动学模型，缩小模拟与现实的差距，提升端到端自动驾驶训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有模拟环境与真实世界差异大，且受限于训练数据分布，难以处理新轨迹或极端场景。

Method: 结合视频扩散先验（ReconSimulator）和运动学模型，动态对抗代理（DAA）生成极端场景，Cousin轨迹生成器（CTG）解决数据分布偏差。

Result: 实验显示，ReconDreamer-RL优于模仿学习方法，碰撞率降低5倍。

Conclusion: ReconDreamer-RL有效缩小模拟与现实的差距，提升自动驾驶训练效果。

Abstract: Reinforcement learning for training end-to-end autonomous driving models in
closed-loop simulations is gaining growing attention. However, most simulation
environments differ significantly from real-world conditions, creating a
substantial simulation-to-reality (sim2real) gap. To bridge this gap, some
approaches utilize scene reconstruction techniques to create photorealistic
environments as a simulator. While this improves realistic sensor simulation,
these methods are inherently constrained by the distribution of the training
data, making it difficult to render high-quality sensor data for novel
trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a
framework designed to integrate video diffusion priors into scene
reconstruction to aid reinforcement learning, thereby enhancing end-to-end
autonomous driving training. Specifically, in ReconDreamer-RL, we introduce
ReconSimulator, which combines the video diffusion prior for appearance
modeling and incorporates a kinematic model for physical modeling, thereby
reconstructing driving scenarios from real-world data. This narrows the
sim2real gap for closed-loop evaluation and reinforcement learning. To cover
more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA),
which adjusts the trajectories of surrounding vehicles relative to the ego
vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in).
Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue
of training data distribution, which is often biased toward simple
straight-line movements. Experiments show that ReconDreamer-RL improves
end-to-end autonomous driving training, outperforming imitation learning
methods with a 5x reduction in the Collision Ratio.

</details>


### [206] [CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data](https://arxiv.org/abs/2508.08173)
*Chongke Bi,Xin Gao,Jiangkang Deng,Guan*

Main category: cs.CV

TL;DR: CD-TVD结合对比学习和改进的扩散模型，通过有限的高分辨率数据实现3D超分辨率，减少对大规模数据集的依赖。


<details>
  <summary>Details</summary>
Motivation: 大规模科学模拟生成高分辨率时变数据成本高，现有超分辨率方法依赖大量训练数据，限制了其适用性。

Method: 提出CD-TVD框架，结合对比学习和改进的扩散模型，利用历史数据预训练，仅需一个新生成的高分辨率时间步进行微调。

Result: 在流体和大气模拟数据集上验证，CD-TVD实现了准确且资源高效的3D超分辨率。

Conclusion: CD-TVD显著提升了大规模科学模拟的数据增强能力，代码已开源。

Abstract: Large-scale scientific simulations require significant resources to generate
high-resolution time-varying data (TVD). While super-resolution is an efficient
post-processing strategy to reduce costs, existing methods rely on a large
amount of HR training data, limiting their applicability to diverse simulation
scenarios. To address this constraint, we proposed CD-TVD, a novel framework
that combines contrastive learning and an improved diffusion-based
super-resolution model to achieve accurate 3D super-resolution from limited
time-step high-resolution data. During pre-training on historical simulation
data, the contrastive encoder and diffusion superresolution modules learn
degradation patterns and detailed features of high-resolution and
low-resolution samples. In the training phase, the improved diffusion model
with a local attention mechanism is fine-tuned using only one newly generated
high-resolution timestep, leveraging the degradation knowledge learned by the
encoder. This design minimizes the reliance on large-scale high-resolution
datasets while maintaining the capability to recover fine-grained details.
Experimental results on fluid and atmospheric simulation datasets confirm that
CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a
significant advancement in data augmentation for large-scale scientific
simulations. The code is available at
https://github.com/Xin-Gao-private/CD-TVD.

</details>


### [207] [MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision](https://arxiv.org/abs/2508.08177)
*Zhonghao Yan,Muxi Diao,Yuxuan Yang,Jiayuan Xu,Kaizhou Zhang,Ruoyan Jing,Lele Yang,Yanxi Liu,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

TL;DR: 论文提出了一种新的医疗视觉语言任务UMRG，并发布了数据集U-MRG-14K，同时开发了MedReasoner框架，通过强化学习优化推理和分割模块，实现了高性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前医疗影像中的区域定位方法依赖显式空间提示，难以处理临床实践中的隐式查询，需要一种结合临床推理和像素级定位的新方法。

Method: 定义了UMRG任务，构建了包含14K样本的数据集U-MRG-14K，并提出了MedReasoner框架，通过强化学习优化推理模块，同时冻结分割模块以实现对齐。

Result: MedReasoner在U-MRG-14K上达到最优性能，并对未见过的临床查询表现出强泛化能力。

Conclusion: 强化学习在可解释的医疗定位任务中具有显著潜力，MedReasoner为临床实践提供了高效解决方案。

Abstract: Accurately grounding regions of interest (ROIs) is critical for diagnosis and
treatment planning in medical imaging. While multimodal large language models
(MLLMs) combine visual perception with natural language, current
medical-grounding pipelines still rely on supervised fine-tuning with explicit
spatial hints, making them ill-equipped to handle the implicit queries common
in clinical practice. This work makes three core contributions. We first define
Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that
demands clinical reasoning and pixel-level grounding. Second, we release
U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside
implicit clinical queries and reasoning traces, spanning 10 modalities, 15
super-categories, and 108 specific categories. Finally, we introduce
MedReasoner, a modular framework that distinctly separates reasoning from
segmentation: an MLLM reasoner is optimized with reinforcement learning, while
a frozen segmentation expert converts spatial prompts into masks, with
alignment achieved through format and accuracy rewards. MedReasoner achieves
state-of-the-art performance on U-MRG-14K and demonstrates strong
generalization to unseen clinical queries, underscoring the significant promise
of reinforcement learning for interpretable medical grounding.

</details>


### [208] [3D Human Mesh Estimation from Single View RGBD](https://arxiv.org/abs/2508.08178)
*Ozhan Suat,Bedirhan Uguz,Batuhan Karagoz,Muhammed Can Keles,Emre Akbas*

Main category: cs.CV

TL;DR: 提出了一种利用RGBD相机进行3D人体网格估计的方法M$^3$，通过虚拟投影和掩码自编码器解决数据稀缺问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: RGBD相机虽普及但未充分利用，现有数据集小且多样性不足，需解决数据稀缺问题。

Method: 利用MoCap数据集生成虚拟单视角网格，训练掩码自编码器补全网格，匹配深度数据生成完整网格。

Result: 在SURREAL、CAPE和BEHAVE数据集上表现优异，PVE误差分别为16.8 mm、22.0 mm和70.9 mm。

Conclusion: M$^3$方法有效利用深度数据，显著提升3D人体网格估计精度，代码将开源。

Abstract: Despite significant progress in 3D human mesh estimation from RGB images;
RGBD cameras, offering additional depth data, remain underutilized. In this
paper, we present a method for accurate 3D human mesh estimation from a single
RGBD view, leveraging the affordability and widespread adoption of RGBD cameras
for real-world applications. A fully supervised approach for this problem,
requires a dataset with RGBD image and 3D mesh label pairs. However, collecting
such a dataset is costly and challenging, hence, existing datasets are small,
and limited in pose and shape diversity. To overcome this data scarcity, we
leverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D
meshes from the body models found in MoCap datasets, and create partial,
single-view versions of them by projection to a virtual camera. This simulates
the depth data provided by an RGBD camera from a single viewpoint. Then, we
train a masked autoencoder to complete the partial, single-view mesh. During
inference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'',
matches the depth values coming from the sensor to vertices of a template human
mesh, which creates a partial, single-view mesh. We effectively recover parts
of the 3D human body mesh model that are not visible, resulting in a full body
mesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL
and CAPE datasets, respectively; outperforming existing methods that use
full-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE
dataset, outperforming a recently published RGB based method by 18.4 mm,
highlighting the usefulness of depth data. Code will be released.

</details>


### [209] [PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation](https://arxiv.org/abs/2508.08179)
*Sihan Zhao,Zixuan Wang,Tianyu Luan,Jia Jia,Wentao Zhu,Jiebo Luo,Junsong Yuan,Nan Xi*

Main category: cs.CV

TL;DR: 论文提出了一种物理标注方法PP-Motion，用于评估人体运动的物理和感知保真度，结合物理对齐和人类感知损失，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在评估运动保真度时存在人类感知与物理可行性之间的差距，且主观标注不够精细。

Method: 通过计算运动与物理定律的最小修改量生成连续物理对齐标注，提出PP-Motion度量，结合皮尔逊相关损失和人类感知损失。

Result: PP-Motion在物理对齐和人类感知保真度上均优于现有方法。

Conclusion: PP-Motion为运动保真度评估提供了更客观和全面的度量标准。

Abstract: Human motion generation has found widespread applications in AR/VR, film,
sports, and medical rehabilitation, offering a cost-effective alternative to
traditional motion capture systems. However, evaluating the fidelity of such
generated motions is a crucial, multifaceted task. Although previous approaches
have attempted at motion fidelity evaluation using human perception or physical
constraints, there remains an inherent gap between human-perceived fidelity and
physical feasibility. Moreover, the subjective and coarse binary labeling of
human perception further undermines the development of a robust data-driven
metric. We address these issues by introducing a physical labeling method. This
method evaluates motion fidelity by calculating the minimum modifications
needed for a motion to align with physical laws. With this approach, we are
able to produce fine-grained, continuous physical alignment annotations that
serve as objective ground truth. With these annotations, we propose PP-Motion,
a novel data-driven metric to evaluate both physical and perceptual fidelity of
human motion. To effectively capture underlying physical priors, we employ
Pearson's correlation loss for the training of our metric. Additionally, by
incorporating a human-based perceptual fidelity loss, our metric can capture
fidelity that simultaneously considers both human perception and physical
alignment. Experimental results demonstrate that our metric, PP-Motion, not
only aligns with physical laws but also aligns better with human perception of
motion fidelity than previous work.

</details>


### [210] [THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening](https://arxiv.org/abs/2508.08183)
*Hongkun Jin,Hongcheng Jiang,Zejun Zhang,Yuan Zhang,Jia Fu,Tingfeng Li,Kai Luo*

Main category: cs.CV

TL;DR: 论文提出了一种名为THAT的Transformer框架，通过改进高频特征表示和令牌选择，解决了现有方法在冗余令牌和多尺度特征建模上的不足，提升了高光谱图像融合的性能。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer方法在高光谱图像融合中存在冗余令牌和多尺度特征建模不足的问题，且难以保留高频成分和局部细节。

Method: 提出THAT框架，包括Pivotal Token Selective Attention（PTSA）和Multi-level Variance-aware Feed-forward Network（MVFN），分别用于优化令牌选择和增强高频细节学习。

Result: 实验表明，THAT在标准基准测试中实现了最先进的性能，提升了重建质量和效率。

Conclusion: THAT通过改进高频特征表示和令牌选择，显著提升了高光谱图像融合的效果。

Abstract: Transformer-based methods have demonstrated strong potential in hyperspectral
pansharpening by modeling long-range dependencies. However, their effectiveness
is often limited by redundant token representations and a lack of multi-scale
feature modeling. Hyperspectral images exhibit intrinsic spectral priors (e.g.,
abundance sparsity) and spatial priors (e.g., non-local similarity), which are
critical for accurate reconstruction. From a spectral-spatial perspective,
Vision Transformers (ViTs) face two major limitations: they struggle to
preserve high-frequency components--such as material edges and texture
transitions--and suffer from attention dispersion across redundant tokens.
These issues stem from the global self-attention mechanism, which tends to
dilute high-frequency signals and overlook localized details. To address these
challenges, we propose the Token-wise High-frequency Augmentation Transformer
(THAT), a novel framework designed to enhance hyperspectral pansharpening
through improved high-frequency feature representation and token selection.
Specifically, THAT introduces: (1) Pivotal Token Selective Attention (PTSA) to
prioritize informative tokens and suppress redundancy; (2) a Multi-level
Variance-aware Feed-forward Network (MVFN) to enhance high-frequency detail
learning. Experiments on standard benchmarks show that THAT achieves
state-of-the-art performance with improved reconstruction quality and
efficiency. The source code is available at https://github.com/kailuo93/THAT.

</details>


### [211] [KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning](https://arxiv.org/abs/2508.08186)
*Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: KARMA是一种高效的语义分割框架，通过一维函数组合建模复杂缺陷模式，显著减少参数数量，适合实时基础设施检查。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习方法参数过多、不适用于实时检查系统的问题，同时应对缺陷外观多变、成像条件恶劣和类别不平衡的挑战。

Method: 引入Tiny Kolmogorov-Arnold Network (TiKAN)模块、优化的特征金字塔结构和静态-动态原型机制。

Result: 在基准数据集上表现优异，参数减少97%，推理速度适合实时部署。

Conclusion: KARMA为自动化基础设施检查提供了高效且准确的解决方案。

Abstract: Semantic segmentation of structural defects in civil infrastructure remains
challenging due to variable defect appearances, harsh imaging conditions, and
significant class imbalance. Current deep learning methods, despite their
effectiveness, typically require millions of parameters, rendering them
impractical for real-time inspection systems. We introduce KARMA
(Kolmogorov-Arnold Representation Mapping Architecture), a highly efficient
semantic segmentation framework that models complex defect patterns through
compositions of one-dimensional functions rather than conventional
convolutions. KARMA features three technical innovations: (1) a
parameter-efficient Tiny Kolmogorov-Arnold Network (TiKAN) module leveraging
low-rank factorization for KAN-based feature transformation; (2) an optimized
feature pyramid structure with separable convolutions for multi-scale defect
analysis; and (3) a static-dynamic prototype mechanism that enhances feature
representation for imbalanced classes. Extensive experiments on benchmark
infrastructure inspection datasets demonstrate that KARMA achieves competitive
or superior mean IoU performance compared to state-of-the-art approaches, while
using significantly fewer parameters (0.959M vs. 31.04M, a 97% reduction).
Operating at 0.264 GFLOPS, KARMA maintains inference speeds suitable for
real-time deployment, enabling practical automated infrastructure inspection
systems without compromising accuracy. The source code can be accessed at the
following URL: https://github.com/faeyelab/karma.

</details>


### [212] [Reinforcement Learning in Vision: A Survey](https://arxiv.org/abs/2508.08189)
*Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 本文综述了视觉强化学习（RL）的最新进展，包括问题形式化、策略优化方法、代表性工作分类及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 为研究者和从业者提供视觉RL领域的全面概览，并指出未来研究方向。

Method: 将200多篇代表性工作分为四大主题：多模态大语言模型、视觉生成、统一模型框架和视觉-语言-动作模型，分析算法设计、奖励工程和基准进展。

Result: 总结了课程驱动训练、偏好对齐扩散和统一奖励建模等趋势，并提出了评估协议和开放挑战。

Conclusion: 视觉RL领域发展迅速，但仍需解决样本效率、泛化性和安全部署等挑战。

Abstract: Recent advances at the intersection of reinforcement learning (RL) and visual
intelligence have enabled agents that not only perceive complex visual scenes
but also reason, generate, and act within them. This survey offers a critical
and up-to-date synthesis of the field. We first formalize visual RL problems
and trace the evolution of policy-optimization strategies from RLHF to
verifiable reward paradigms, and from Proximal Policy Optimization to Group
Relative Policy Optimization. We then organize more than 200 representative
works into four thematic pillars: multi-modal large language models, visual
generation, unified model frameworks, and vision-language-action models. For
each pillar we examine algorithmic design, reward engineering, benchmark
progress, and we distill trends such as curriculum-driven training,
preference-aligned diffusion, and unified reward modeling. Finally, we review
evaluation protocols spanning set-level fidelity, sample-level preference, and
state-level stability, and we identify open challenges that include sample
efficiency, generalization, and safe deployment. Our goal is to provide
researchers and practitioners with a coherent map of the rapidly expanding
landscape of visual RL and to highlight promising directions for future
inquiry. Resources are available at:
https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.

</details>


### [213] [Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model](https://arxiv.org/abs/2508.08199)
*Peiqi He,Zhenhao Zhang,Yixiang Zhang,Xiongjun Zhao,Shaoliang Peng*

Main category: cs.CV

TL;DR: Spatial-ORMLLM是一种基于RGB模态的大型视觉语言模型，用于手术室3D空间推理，无需额外传感器或专家标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖多模态数据且忽略3D能力，而手术室多模态数据难以获取，2D数据无法捕捉复杂场景细节。

Method: 通过Spatial-Enhanced Feature Fusion Block将2D输入与3D空间知识结合，利用端到端MLLM框架实现3D推理。

Result: 在多个临床数据集上表现优异，泛化能力强。

Conclusion: Spatial-ORMLLM为手术室3D空间推理提供了高效解决方案。

Abstract: Precise spatial modeling in the operating room (OR) is foundational to many
clinical tasks, supporting intraoperative awareness, hazard avoidance, and
surgical decision-making. While existing approaches leverage large-scale
multimodal datasets for latent-space alignment to implicitly learn spatial
relationships, they overlook the 3D capabilities of MLLMs. However, this
approach raises two issues: (1) Operating rooms typically lack multiple video
and audio sensors, making multimodal 3D data difficult to obtain; (2) Training
solely on readily available 2D data fails to capture fine-grained details in
complex scenes. To address this gap, we introduce Spatial-ORMLLM, the first
large vision-language model for 3D spatial reasoning in operating rooms using
only RGB modality to infer volumetric and semantic cues, enabling downstream
medical tasks with detailed and holistic spatial context. Spatial-ORMLLM
incorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D
modality inputs with rich 3D spatial knowledge extracted by the estimation
algorithm and then feeds the combined features into the visual tower. By
employing a unified end-to-end MLLM framework, it combines powerful spatial
features with textual features to deliver robust 3D scene reasoning without any
additional expert annotations or sensor inputs. Experiments on multiple
benchmark clinical datasets demonstrate that Spatial-ORMLLM achieves
state-of-the-art performance and generalizes robustly to previously unseen
surgical scenarios and downstream tasks.

</details>


### [214] [SAGOnline: Segment Any Gaussians Online](https://arxiv.org/abs/2508.08219)
*Wentao Sun,Quanyun Wu,Hanqing Xu,Kyle Gao,Zhengsen Xu,Yiping Chen,Dedong Zhang,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: SAGOnline是一个轻量级、零样本的实时3D分割框架，通过解耦策略和GPU加速算法解决了3D高斯场景中的分割与跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯场景分割方法存在计算成本高、空间推理能力有限及无法同时跟踪多对象的问题，SAGOnline旨在解决这些挑战。

Method: 结合视频基础模型（如SAM2）进行视图一致的2D掩码传播，并采用GPU加速的3D掩码生成与高斯级实例标记算法。

Result: 在NVOS和Spin-NeRF基准测试中表现优异（mIoU分别为92.7%和95.2%），推理速度提升15-1500倍（27毫秒/帧）。

Conclusion: SAGOnline实现了实时渲染与3D场景理解，为AR/VR和机器人应用提供了实用解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit
3D scene representation, yet achieving efficient and consistent 3D segmentation
remains challenging. Current methods suffer from prohibitive computational
costs, limited 3D spatial reasoning, and an inability to track multiple objects
simultaneously. We present Segment Any Gaussians Online (SAGOnline), a
lightweight and zero-shot framework for real-time 3D segmentation in Gaussian
scenes that addresses these limitations through two key innovations: (1) a
decoupled strategy that integrates video foundation models (e.g., SAM2) for
view-consistent 2D mask propagation across synthesized views; and (2) a
GPU-accelerated 3D mask generation and Gaussian-level instance labeling
algorithm that assigns unique identifiers to 3D primitives, enabling lossless
multi-object tracking and segmentation across views. SAGOnline achieves
state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU)
benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times
in inference speed (27 ms/frame). Qualitative results demonstrate robust
multi-object segmentation and tracking in complex scenes. Our contributions
include: (i) a lightweight and zero-shot framework for 3D segmentation in
Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling
simultaneous segmentation and tracking, and (iii) the effective adaptation of
2D video foundation models to the 3D domain. This work allows real-time
rendering and 3D scene understanding, paving the way for practical AR/VR and
robotic applications.

</details>


### [215] [Learning User Preferences for Image Generation Model](https://arxiv.org/abs/2508.08220)
*Wenyi Mo,Ying Ba,Tianyu Zhang,Yalong Bai,Biye Li*

Main category: cs.CV

TL;DR: 该论文提出了一种基于多模态大语言模型的方法，通过对比偏好损失和偏好标记来学习个性化用户偏好，显著提升了偏好预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖通用偏好或静态用户画像，忽略了用户偏好的动态性和多样性。

Method: 采用多模态大语言模型，引入对比偏好损失和偏好标记，区分用户喜好并捕捉共享兴趣表示。

Result: 实验表明，该方法在偏好预测准确性上优于其他方法，并能识别相似审美倾向的用户。

Conclusion: 该方法能更精确地生成符合个人偏好的图像，为个性化推荐提供了有效工具。

Abstract: User preference prediction requires a comprehensive and accurate
understanding of individual tastes. This includes both surface-level
attributes, such as color and style, and deeper content-related aspects, such
as themes and composition. However, existing methods typically rely on general
human preferences or assume static user profiles, often neglecting individual
variability and the dynamic, multifaceted nature of personal taste. To address
these limitations, we propose an approach built upon Multimodal Large Language
Models, introducing contrastive preference loss and preference tokens to learn
personalized user preferences from historical interactions. The contrastive
preference loss is designed to effectively distinguish between user ''likes''
and ''dislikes'', while the learnable preference tokens capture shared interest
representations among existing users, enabling the model to activate
group-specific preferences and enhance consistency across similar users.
Extensive experiments demonstrate our model outperforms other methods in
preference prediction accuracy, effectively identifying users with similar
aesthetic inclinations and providing more precise guidance for generating
images that align with individual tastes. The project page is
\texttt{https://learn-user-pref.github.io/}.

</details>


### [216] [OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution](https://arxiv.org/abs/2508.08227)
*Zhiqiang Wu,Zhaomang Sun,Tong Zhou,Bingtao Fu,Ji Cong,Yitong Dong,Huaqi Zhang,Xuan Tang,Mingsong Chen,Xian Wei*

Main category: cs.CV

TL;DR: OMGSR是一种基于DDPM/FM的一步式真实图像超分辨率框架，通过在中时间步注入低质量图像潜在分布，优化生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在初始时间步注入低质量图像潜在分布与高斯噪声分布存在差距，限制了生成先验的有效利用。

Method: 提出OMGSR框架，在中时间步注入低质量图像潜在分布，并引入潜在分布细化损失和重叠分块LPIPS/GAN损失。

Result: OMGSR-S/F在512分辨率下表现优异，OMGSR-F在所有参考指标中占据优势，1k和2k分辨率下生成细节出色。

Conclusion: OMGSR框架显著提升了一步式真实图像超分辨率的性能，尤其在细节生成上表现突出。

Abstract: Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM)
generative models show promising potential for one-step Real-World Image
Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a
Low-Quality (LQ) image latent distribution at the initial timestep. However, a
fundamental gap exists between the LQ image latent distribution and the
Gaussian noisy latent distribution, limiting the effective utilization of
generative priors. We observe that the noisy latent distribution at DDPM/FM
mid-timesteps aligns more closely with the LQ image latent distribution. Based
on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a
universal framework applicable to DDPM/FM-based generative models. OMGSR
injects the LQ image latent distribution at a pre-computed mid-timestep,
incorporating the proposed Latent Distribution Refinement loss to alleviate the
latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to
eliminate checkerboard artifacts in image generation. Within this framework, we
instantiate OMGSR for DDPM/FM-based generative models with two variants:
OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate
that OMGSR-S/F achieves balanced/excellent performance across quantitative and
qualitative metrics at 512-resolution. Notably, OMGSR-F establishes
overwhelming dominance in all reference metrics. We further train a
1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which
yields excellent results, especially in the details of the image generation. We
also generate 2k-resolution images by the 1k-resolution OMGSR-F using our
two-stage Tiled VAE & Diffusion.

</details>


### [217] [Cut2Next: Generating Next Shot via In-Context Tuning](https://arxiv.org/abs/2508.08244)
*Jingwen He,Hongbo Liu,Jiajun Li,Ziqi Huang,Yu Qiao,Wanli Ouyang,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出Next Shot Generation (NSG)框架Cut2Next，通过Diffusion Transformer和Hierarchical Multi-Prompting策略生成符合专业剪辑模式的高质量镜头，解决了现有方法在叙事连贯性和电影完整性上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前多镜头生成方法仅关注视觉一致性，忽略了叙事流畅性和电影剪辑模式（如正反打镜头、插入镜头），导致输出缺乏叙事深度和电影感。

Method: Cut2Next采用Diffusion Transformer (DiT)和Hierarchical Multi-Prompting策略，结合Relational Prompts和Individual Prompts，并通过Context-Aware Condition Injection (CACI)和Hierarchical Attention Mask (HAM)整合信号。

Result: 实验表明Cut2Next在视觉一致性和文本保真度上表现优异，用户研究显示其生成的镜头更符合剪辑模式和电影连贯性。

Conclusion: Cut2Next能生成高质量、叙事表达丰富且电影连贯的后续镜头，验证了其有效性。

Abstract: Effective multi-shot generation demands purposeful, film-like transitions and
strict cinematic continuity. Current methods, however, often prioritize basic
visual consistency, neglecting crucial editing patterns (e.g., shot/reverse
shot, cutaways) that drive narrative flow for compelling storytelling. This
yields outputs that may be visually coherent but lack narrative sophistication
and true cinematic integrity. To bridge this, we introduce Next Shot Generation
(NSG): synthesizing a subsequent, high-quality shot that critically conforms to
professional editing patterns while upholding rigorous cinematic continuity.
Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs
in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This
strategy uses Relational Prompts to define overall context and inter-shot
editing styles. Individual Prompts then specify per-shot content and
cinematographic attributes. Together, these guide Cut2Next to generate
cinematically appropriate next shots. Architectural innovations, Context-Aware
Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further
integrate these diverse signals without introducing new parameters. We
construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with
hierarchical prompts, and introduce CutBench for evaluation. Experiments show
Cut2Next excels in visual consistency and text fidelity. Crucially, user
studies reveal a strong preference for Cut2Next, particularly for its adherence
to intended editing patterns and overall cinematic continuity, validating its
ability to generate high-quality, narratively expressive, and cinematically
coherent subsequent shots.

</details>


### [218] [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://arxiv.org/abs/2508.08248)
*Shuyuan Tu,Yueming Pan,Yinming Huang,Xintong Han,Zhen Xing,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAvatar是一种端到端的视频扩散变换器，能够生成无限长度的高质量视频，解决了现有模型在音频同步和身份一致性上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动的虚拟化身视频生成模型难以生成长视频且音频同步和身份一致性差，StableAvatar旨在解决这一问题。

Method: 通过时间步感知音频适配器和音频原生引导机制优化音频建模，并采用动态加权滑动窗口策略增强视频平滑度。

Result: 实验证明StableAvatar在质量和数量上均优于现有方法。

Conclusion: StableAvatar为无限长度高质量视频生成提供了有效解决方案。

Abstract: Current diffusion models for audio-driven avatar video generation struggle to
synthesize long videos with natural audio synchronization and identity
consistency. This paper presents StableAvatar, the first end-to-end video
diffusion transformer that synthesizes infinite-length high-quality videos
without post-processing. Conditioned on a reference image and audio,
StableAvatar integrates tailored training and inference modules to enable
infinite-length video generation. We observe that the main reason preventing
existing models from generating long videos lies in their audio modeling. They
typically rely on third-party off-the-shelf extractors to obtain audio
embeddings, which are then directly injected into the diffusion model via
cross-attention. Since current diffusion backbones lack any audio-related
priors, this approach causes severe latent distribution error accumulation
across video clips, leading the latent distribution of subsequent segments to
drift away from the optimal distribution gradually. To address this,
StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents
error accumulation via time-step-aware modulation. During inference, we propose
a novel Audio Native Guidance Mechanism to further enhance the audio
synchronization by leveraging the diffusion's own evolving joint audio-latent
prediction as a dynamic guidance signal. To enhance the smoothness of the
infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy
that fuses latent over time. Experiments on benchmarks show the effectiveness
of StableAvatar both qualitatively and quantitatively.

</details>


### [219] [ReferSplat: Referring Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2508.08252)
*Shuting He,Guangquan Jie,Changshuo Wang,Yun Zhou,Shuming Hu,Guanbin Li,Henghui Ding*

Main category: cs.CV

TL;DR: R3DGS任务旨在通过自然语言描述在3D高斯场景中分割目标物体，提出新数据集Ref-LERF和框架ReferSplat，解决3D多模态理解和空间关系建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 推动具身AI发展，解决3D场景中基于语言描述的目标分割问题，尤其是遮挡或不可见物体。

Method: 提出ReferSplat框架，显式建模3D高斯点与自然语言表达的空间关系。

Result: ReferSplat在R3DGS任务和3D开放词汇分割基准上达到最先进性能。

Conclusion: R3DGS任务和ReferSplat框架为3D多模态理解提供了新方向，数据集和代码已开源。

Abstract: We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task
that aims to segment target objects in a 3D Gaussian scene based on natural
language descriptions, which often contain spatial relationships or object
attributes. This task requires the model to identify newly described objects
that may be occluded or not directly visible in a novel view, posing a
significant challenge for 3D multi-modal understanding. Developing this
capability is crucial for advancing embodied AI. To support research in this
area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that
3D multi-modal understanding and spatial relationship modeling are key
challenges for R3DGS. To address these challenges, we propose ReferSplat, a
framework that explicitly models 3D Gaussian points with natural language
expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art
performance on both the newly proposed R3DGS task and 3D open-vocabulary
segmentation benchmarks. Dataset and code are available at
https://github.com/heshuting555/ReferSplat.

</details>


### [220] [Learning an Implicit Physics Model for Image-based Fluid Simulation](https://arxiv.org/abs/2508.08254)
*Emily Yue-Ting Jia,Jiageng Mao,Zhiyuan Gao,Yajie Zhao,Yue Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于物理原理的神经网络方法，用于从单张图像生成4D场景（包含运动和3D几何），特别针对自然流体图像。


<details>
  <summary>Details</summary>
Motivation: 人类能够从单张静态图像想象出4D场景（运动和3D几何），而现有方法通常使用简化的2D运动估计，导致动画违反物理原理。本文旨在通过物理一致的动画解决这一问题。

Method: 使用物理信息神经网络预测每个表面点的运动，并通过基于物理原理（如Navier-Stokes方程）的损失函数进行约束。同时，从输入图像和深度估计预测3D高斯特征，并通过预测的运动进行动画渲染。

Result: 实验结果表明，该方法能生成物理上合理的动画，性能显著优于现有方法。

Conclusion: 该方法成功实现了从单张图像生成物理一致的4D场景，为未来研究提供了新方向。

Abstract: Humans possess an exceptional ability to imagine 4D scenes, encompassing both
motion and 3D geometry, from a single still image. This ability is rooted in
our accumulated observations of similar scenes and an intuitive understanding
of physics. In this paper, we aim to replicate this capacity in neural
networks, specifically focusing on natural fluid imagery. Existing methods for
this task typically employ simplistic 2D motion estimators to animate the
image, leading to motion predictions that often defy physical principles,
resulting in unrealistic animations. Our approach introduces a novel method for
generating 4D scenes with physics-consistent animation from a single image. We
propose the use of a physics-informed neural network that predicts motion for
each surface point, guided by a loss term derived from fundamental physical
principles, including the Navier-Stokes equations. To capture appearance, we
predict feature-based 3D Gaussians from the input image and its estimated
depth, which are then animated using the predicted motions and rendered from
any desired camera perspective. Experimental results highlight the
effectiveness of our method in producing physically plausible animations,
showcasing significant performance improvements over existing methods. Our
project page is https://physfluid.github.io/ .

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [221] [PureSample: Neural Materials Learned by Sampling Microgeometry](https://arxiv.org/abs/2508.07240)
*Zixuan Li,Zixiong Wang,Jian Yang,Milos Hasan,Beibei Wang*

Main category: cs.GR

TL;DR: PureSample提出了一种基于神经网络的BRDF表示方法，通过随机行走采样学习材料行为，简化了传统BRDF的复杂推导过程。


<details>
  <summary>Details</summary>
Motivation: 传统BRDF模型依赖复杂的解析推导，且忽略空间变化，设计重要性采样和PDF评估需额外工作。

Method: 使用流匹配神经网络建模采样分布，并引入轻量级神经网络捕捉视角相关反照率，实现高效采样和BRDF评估。

Result: 在多层材料、多次散射微表面材料等复杂场景中验证了PureSample的有效性。

Conclusion: PureSample为BRDF建模提供了一种更简单、高效的方法，适用于均质和空间变化材料。

Abstract: Traditional physically-based material models rely on analytically derived
bidirectional reflectance distribution functions (BRDFs), typically by
considering statistics of micro-primitives such as facets, flakes, or spheres,
sometimes combined with multi-bounce interactions such as layering and multiple
scattering. These derivations are often complex and model-specific, and
typically consider a statistical aggregate of a large surface area, ignoring
spatial variation. Once an analytic BRDF's evaluation is defined, one still
needs to design an importance sampling method for it, and a way to evaluate the
pdf of that sampling distribution, requiring further model-specific
derivations.
  We present PureSample: a novel neural BRDF representation that allows
learning a material's behavior purely by sampling forward random walks on the
microgeometry, which is usually straightforward to implement. Our
representation allows for efficient importance sampling, pdf evaluation, and
BRDF evaluation, for homogeneous as well as spatially varying materials.
  We achieve this by two learnable components: first, the sampling distribution
is modeled using a flow matching neural network, which allows both importance
sampling and pdf evaluation; second, we introduce a view-dependent albedo term,
captured by a lightweight neural network, which allows for converting a scalar
pdf value to a colored BRDF value for any pair of view and light directions.
  We demonstrate PureSample on challenging materials, including multi-layered
materials, multiple-scattering microfacet materials, and various other
microstructures.

</details>


### [222] [Verification Method for Graph Isomorphism Criteria](https://arxiv.org/abs/2508.07615)
*Chuanfu Hu,Aimin Hou*

Main category: cs.GR

TL;DR: 本文提出了一种验证方法，用于判断图同构的充分必要条件，并提出了细分方法以减少回溯空间。


<details>
  <summary>Details</summary>
Motivation: 图同构的判定条件对解决问题至关重要，但现有方法存在回溯和证明正确性的问题。

Method: 提出验证方法判断充分必要条件，并设计细分方法以减少回溯空间。

Result: 验证方法能正确判定条件，细分方法有效减少回溯空间。

Conclusion: 该方法为图同构问题提供了更高效的解决方案。

Abstract: The criteria for determining graph isomorphism are crucial for solving graph
isomorphism problems. The necessary condition is that two isomorphic graphs
possess invariants, but their function can only be used to filtrate and
subdivide candidate spaces. The sufficient conditions are used to rebuild the
isomorphic reconstruction of special graphs, but their drawback is that the
isomorphic functions of subgraphs may not form part of the isomorphic functions
of the parent graph. The use of sufficient or necessary conditions generally
results in backtracking to ensure the correctness of the decision algorithm.
The sufficient and necessary conditions can ensure that the determination of
graph isomorphism does not require backtracking, but the correctness of its
proof process is difficult to guarantee. This article proposes a verification
method that can correctly determine whether the judgment conditions proposed by
previous researchers are sufficient and necessary conditions. A subdivision
method has also been proposed in this article, which can obtain more
subdivisions for necessary conditions and effectively reduce the size of
backtracking space.

</details>


### [223] [Vertex Features for Neural Global Illumination](https://arxiv.org/abs/2508.07852)
*Rui Su,Honghao Dong,Haojie Jin,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出了一种基于网格顶点的可学习神经表示方法，显著降低了内存占用并提升了渲染效率。


<details>
  <summary>Details</summary>
Motivation: 传统特征网格表示在3D场景重建和神经渲染中内存占用大，限制了并行计算硬件的性能。

Method: 将可学习特征直接存储在网格顶点上，利用几何结构作为紧凑表示，减少内存消耗并提升特征表示效果。

Result: 实验表明，该方法内存消耗仅为网格表示的五分之一或更低，同时保持渲染质量并降低推理开销。

Conclusion: 神经顶点特征是一种高效且紧凑的表示方法，适用于神经渲染任务。

Abstract: Recent research on learnable neural representations has been widely adopted
in the field of 3D scene reconstruction and neural rendering applications.
However, traditional feature grid representations often suffer from substantial
memory footprint, posing a significant bottleneck for modern parallel computing
hardware. In this paper, we present neural vertex features, a generalized
formulation of learnable representation for neural rendering tasks involving
explicit mesh surfaces. Instead of uniformly distributing neural features
throughout 3D space, our method stores learnable features directly at mesh
vertices, leveraging the underlying geometry as a compact and structured
representation for neural processing. This not only optimizes memory
efficiency, but also improves feature representation by aligning compactly with
the surface using task-specific geometric priors. We validate our neural
representation across diverse neural rendering tasks, with a specific emphasis
on neural radiosity. Experimental results demonstrate that our method reduces
memory consumption to only one-fifth (or even less) of grid-based
representations, while maintaining comparable rendering quality and lowering
inference overhead.

</details>


### [224] [Emergent morphogenesis via planar fabrication enabled by a reduced model of composites](https://arxiv.org/abs/2508.08198)
*Yupeng Zhang,Adam Alon,M. Khalid Jawed*

Main category: cs.GR

TL;DR: 提出了一种基于双层系统的数值和实验框架，通过热响应材料与惰性塑料层的结合，实现可编程的3D形态设计。


<details>
  <summary>Details</summary>
Motivation: 解决软机器人、可重构设备和功能材料中复杂3D形状的精确控制问题。

Method: 采用双层系统（热响应层与kirigami图案惰性层），通过热收缩和弯曲约束实现3D形态；提出单层简化模型，降低计算复杂度。

Result: 成功设计并制造出多种3D形态（如碗、独木舟、花瓣），并通过仿真和实验验证。

Conclusion: 该框架为高效计算设计和可扩展制造提供了新方法，扩展了传统双层模型的局限性。

Abstract: The ability to engineer complex three-dimensional shapes from planar sheets
with precise, programmable control underpins emerging technologies in soft
robotics, reconfigurable devices, and functional materials. Here, we present a
reduced-order numerical and experimental framework for a bilayer system
consisting of a stimuli-responsive thermoplastic sheet (Shrinky Dink) bonded to
a kirigami-patterned, inert plastic layer. Upon uniform heating, the active
layer contracts while the patterned layer constrains in-plane stretch but
allows out-of-plane bending, yielding programmable 3D morphologies from simple
planar precursors. Our approach enables efficient computational design and
scalable manufacturing of 3D forms with a single-layer reduced model that
captures the coupled mechanics of stretching and bending. Unlike traditional
bilayer modeling, our framework collapses the multilayer composite into a
single layer of nodes and elements, reducing the degrees of freedom and
enabling simulation on a 2D geometry. This is achieved by introducing a novel
energy formulation that captures the coupling between in-plane stretch mismatch
and out-of-plane bending - extending beyond simple isotropic linear elastic
models. Experimentally, we establish a fully planar, repeatable fabrication
protocol using a stimuli-responsive thermoplastic and a laser-cut inert plastic
layer. The programmed strain mismatch drives an array of 3D morphologies, such
as bowls, canoes, and flower petals, all verified by both simulation and
physical prototypes.

</details>


### [225] [LL3M: Large Language 3D Modelers](https://arxiv.org/abs/2508.08228)
*Sining Lu,Guan Chen,Nam Anh Dinh,Itai Lang,Ari Holtzman,Rana Hanocka*

Main category: cs.GR

TL;DR: LL3M是一个多智能体系统，利用预训练大语言模型（LLMs）生成可解释的Blender Python代码来创建3D资产，替代传统基于3D数据学习的生成方法。


<details>
  <summary>Details</summary>
Motivation: 传统3D生成方法依赖于大量3D数据学习，缺乏模块化和可编辑性。LL3M通过代码生成任务，提供更高的灵活性和与艺术家工作流的集成。

Method: LL3M通过协调多个专用LLM智能体，完成规划、检索、编写、调试和优化Blender脚本的任务，生成几何和外观的代码表示。

Result: 生成的代码具有高可读性和可编辑性，支持多样化的形状、材质和场景，并能通过代码或参数进一步修改。

Conclusion: LL3M展示了代码作为3D资产生成媒介的强大能力，支持智能体和用户协同创作，实验验证了其有效性。

Abstract: We present LL3M, a multi-agent system that leverages pretrained large
language models (LLMs) to generate 3D assets by writing interpretable Python
code in Blender. We break away from the typical generative approach that learns
from a collection of 3D data. Instead, we reformulate shape generation as a
code-writing task, enabling greater modularity, editability, and integration
with artist workflows. Given a text prompt, LL3M coordinates a team of
specialized LLM agents to plan, retrieve, write, debug, and refine Blender
scripts that generate and edit geometry and appearance. The generated code
works as a high-level, interpretable, human-readable, well-documented
representation of scenes and objects, making full use of sophisticated Blender
constructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse,
unconstrained shapes, materials, and scenes. This code presents many avenues
for further agent and human editing and experimentation via code tweaks or
procedural parameters. This medium naturally enables a co-creative loop in our
system: agents can automatically self-critique using code and visuals, while
iterative user instructions provide an intuitive way to refine assets. A shared
code context across agents enables awareness of previous attempts, and a
retrieval-augmented generation knowledge base built from Blender API
documentation, BlenderRAG, equips agents with examples, types, and functions
empowering advanced modeling operations and code correctness. We demonstrate
the effectiveness of LL3M across diverse shape categories, style and material
edits, and user-driven refinements. Our experiments showcase the power of code
as a generative and interpretable medium for 3D asset creation. Our project
page is at https://threedle.github.io/ll3m.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [226] [Generative Bid Shading in Real-Time Bidding Advertising](https://arxiv.org/abs/2508.06550)
*Yinqiu Huang,Hao Ma,Wenshuai Chen,Shuli Wang,Yongqiang Zhang,Xue Wei,Yinhua Zhu,Haitao Wang,Xingxing Wang*

Main category: cs.GT

TL;DR: 本文提出了一种名为生成式竞价调整（GBS）的新方法，通过端到端生成模型和奖励偏好对齐系统解决现有竞价调整方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有竞价调整方法受限于单峰假设和离散化模型的依赖性问题，且无法适应非凸盈余曲线和样本选择偏差的挑战。

Method: GBS包括两部分：(1) 端到端生成模型，通过逐步残差生成调整比例；(2) 奖励偏好对齐系统，结合CHNet和GRPO优化短期和长期盈余。

Result: 离线和在线A/B测试验证了GBS的有效性，并已在美团DSP平台部署，每日处理数十亿竞价请求。

Conclusion: GBS通过创新的生成模型和奖励对齐机制，显著提升了竞价调整的适应性和性能。

Abstract: Bid shading plays a crucial role in Real-Time Bidding~(RTB) by adaptively
adjusting the bid to avoid advertisers overspending. Existing mainstream
two-stage methods, which first model bid landscapes and then optimize surplus
using operations research techniques, are constrained by unimodal assumptions
that fail to adapt for non-convex surplus curves and are vulnerable to
cascading errors in sequential workflows. Additionally, existing discretization
models of continuous values ignore the dependence between discrete intervals,
reducing the model's error correction ability, while sample selection bias in
bidding scenarios presents further challenges for prediction. To address these
issues, this paper introduces Generative Bid Shading~(GBS), which comprises two
primary components: (1) an end-to-end generative model that utilizes an
autoregressive approach to generate shading ratios by stepwise residuals,
capturing complex value dependencies without relying on predefined priors; and
(2) a reward preference alignment system, which incorporates a channel-aware
hierarchical dynamic network~(CHNet) as the reward model to extract
fine-grained features, along with modules for surplus optimization and
exploration utility reward alignment, ultimately optimizing both short-term and
long-term surplus using group relative policy optimization~(GRPO). Extensive
experiments on both offline and online A/B tests validate GBS's effectiveness.
Moreover, GBS has been deployed on the Meituan DSP platform, serving billions
of bid requests daily.

</details>


### [227] [Algorithmic Delegated Choice: An Annotated Reading List](https://arxiv.org/abs/2508.06562)
*Mohammad T. Hajiaghayi,Suho Shin*

Main category: cs.GT

TL;DR: 综述委托选择问题的经典与近期算法视角研究。


<details>
  <summary>Details</summary>
Motivation: 探讨经济学和计算机科学中委托选择问题的研究进展。

Method: 综述经典和近期相关论文，分析算法视角。

Result: 总结了委托选择问题的研究脉络与最新进展。

Conclusion: 委托选择问题在经济学和计算机科学中具有广泛研究价值。

Abstract: The problem of delegated choice has been of long interest in economics and
recently on computer science. We overview a list of papers on delegated choice
problem, from classic works to recent papers with algorithmic perspectives.

</details>


### [228] [Asymmetric Network Games: $α$-Potential Function and Learning](https://arxiv.org/abs/2508.06619)
*Kiran Rokade,Adit Jain,Francesca Parise,Vikram Krishnamurthy,Eva Tardos*

Main category: cs.GT

TL;DR: 该论文研究了网络游戏中的静态博弈，利用α-势博弈框架，推导了α-势函数，并证明了改进的算法能收敛到2α-纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的网络往往不对称且玩家异质性强，需要一种通用框架分析此类网络博弈。

Method: 基于α-势博弈框架，假设玩家行为集为紧区间且效用函数二次连续可微，推导α-势函数，并改进两种算法（序贯最佳响应和同步梯度下降）。

Result: 算法能收敛到2α-纳什均衡，且α与网络最大不对称性相关；在线性二次网络游戏中，α表现良好。

Conclusion: α-势函数为分析不对称网络博弈提供了有效工具，改进算法具有实际应用价值。

Abstract: In a network game, players interact over a network and the utility of each
player depends on his own action and on an aggregate of his neighbours'
actions. Many real world networks of interest are asymmetric and involve a
large number of heterogeneous players. This paper analyzes static network games
using the framework of $\alpha$-potential games. Under mild assumptions on the
action sets (compact intervals) and the utility functions (twice continuously
differentiable) of the players, we derive an expression for an inexact
potential function of the game, called the $\alpha$-potential function. Using
such a function, we show that modified versions of the sequential best-response
algorithm and the simultaneous gradient play algorithm achieve convergence of
players' actions to a $2\alpha$-Nash equilibrium. For linear-quadratic network
games, we show that $\alpha$ depends on the maximum asymmetry in the network
and is well-behaved for a wide range of networks of practical interest.
Further, we derive bounds on the social welfare of the $\alpha$-Nash
equilibrium corresponding to the maximum of the $\alpha$-potential function,
under suitable assumptions. We numerically illustrate the convergence of the
proposed algorithms and properties of the learned $2\alpha$-Nash equilibria.

</details>


### [229] [Convergence of Fast Policy Iteration in Markov Games and Robust MDPs](https://arxiv.org/abs/2508.06661)
*Keith Badger,Marek Petrik,Jefferson Huang*

Main category: cs.GT

TL;DR: 论文分析了Filar-Tolwinski（FT）算法的收敛性问题，并提出了一种改进算法RCPI，其性能显著优于其他收敛算法。


<details>
  <summary>Details</summary>
Motivation: 研究FT算法的收敛性问题，并提出一种更可靠的替代算法。

Method: 提出Residual Conditioned Policy Iteration（RCPI），基于FT算法但保证收敛。

Result: RCPI在数值实验中表现优于其他收敛算法数个数量级。

Conclusion: RCPI是一种高效且可靠的替代算法，解决了FT算法的收敛问题。

Abstract: Markov games and robust MDPs are closely related models that involve
computing a pair of saddle point policies. As part of the long-standing effort
to develop efficient algorithms for these models, the Filar-Tolwinski (FT)
algorithm has shown considerable promise. As our first contribution, we
demonstrate that FT may fail to converge to a saddle point and may loop
indefinitely, even in small games. This observation contradicts the proof of
FT's convergence to a saddle point in the original paper. As our second
contribution, we propose Residual Conditioned Policy Iteration (RCPI). RCPI
builds on FT, but is guaranteed to converge to a saddle point. Our numerical
results show that RCPI outperforms other convergent algorithms by several
orders of magnitude.

</details>


### [230] [Emergence of Cooperation and Commitment in Optional Prisoner's Dilemma](https://arxiv.org/abs/2508.06702)
*Zhao Song,The Anh Han*

Main category: cs.GT

TL;DR: 本文通过两阶段博弈模型研究了基于承诺的行为与合作在可选囚徒困境中的演化，发现自愿参与虽促进承诺接受但未能提升合作，反而导致退出行为。通过比较两种制度激励方法，发现严格规则更利于合作，而灵活规则在特定情况下更高效。


<details>
  <summary>Details</summary>
Motivation: 现有研究多忽视玩家自愿退出的自由，限制了其在现实场景中的应用。本文旨在探讨自愿参与下承诺行为与合作的演化。

Method: 采用两阶段博弈模型：预游戏阶段决定是否接受承诺，游戏阶段根据承诺选择合作、背叛或退出。比较两种制度激励方法（STRICT-COM和FLEXIBLE-COM）。

Result: 自愿参与促进承诺接受但导致退出行为。严格规则更有效促进合作，灵活规则在特定情况下更高效提升社会福利。

Conclusion: 仅依赖自愿参与和承诺不足以解决社会困境，需设计良好的制度激励以有效促进合作和社会福利。

Abstract: Commitment is a well-established mechanism for fostering cooperation in human
society and multi-agent systems. However, existing research has predominantly
focused on the commitment that neglects the freedom of players to abstain from
an interaction, limiting their applicability to many real-world scenarios where
participation is often voluntary. In this paper, we present a two-stage game
model to investigate the evolution of commitment-based behaviours and
cooperation within the framework of the optional Prisoner's Dilemma game. In
the pre-game stage, players decide whether to accept a mutual commitment. Once
in the game, they choose among cooperation, defection, or exiting, depending on
the formation of a pre-game commitment. We find that optional participation
boosts commitment acceptance but fails to foster cooperation, leading instead
to widespread exit behaviour. To address this, we then introduce and compare
two institutional incentive approaches: i) a strict one (STRICT-COM) that
rewards only committed players who cooperate in the game, and ii) a flexible
one (FLEXIBLE-COM) that rewards any committed players who do not defect in the
game. The results reveal that, while the strict approach is demonstrably better
for promoting cooperation as the flexible rule creates a loophole for an
opportunistic exit after committing, the flexible rule offers an efficient
alternative for enhancing social welfare when such opportunistic behaviour
results in a high gain. This study highlights the limitations of relying solely
on voluntary participation and commitment to resolving social dilemmas,
emphasising the importance of well-designed institutional incentives to promote
cooperation and social welfare effectively.

</details>


### [231] [When Competition Helps: Achieving Optimal Traffic Flow with Multiple Autonomous Planners](https://arxiv.org/abs/2508.07145)
*Ivan Geffner,Erez Karpas,Moshe Tennenholtz*

Main category: cs.GT

TL;DR: 自私路由在拥堵网络中的低效是算法博弈论的经典问题，通常用“无政府状态价格”衡量。本文探讨自动驾驶车辆是否能消除这种低效，并提出一种竞争机制以实现最优路由分配。


<details>
  <summary>Details</summary>
Motivation: 研究自动驾驶车辆是否能通过中央规划消除自私路由的低效性，同时考虑个体理性和多代理竞争的挑战。

Method: 设计一种路由机制，从经典的Pigou网络出发，利用竞争实现最优路由分配。

Result: 竞争是实现最优结果的关键因素，而非障碍。

Conclusion: 通过竞争机制，可以实现从自私路由到最优分配的收敛。

Abstract: The inefficiency of selfish routing in congested networks is a classical
problem in algorithmic game theory, often captured by the Price of Anarchy
(i.e., the ratio between the social cost of decentralized decisions and that of
a centrally optimized solution.) With the advent of autonomous vehicles,
capable of receiving and executing centrally assigned routes, it is natural to
ask whether their deployment can eliminate this inefficiency. At first glance,
a central authority could simply compute an optimal traffic assignment and
instruct each vehicle to follow its assigned path. However, this vision
overlooks critical challenges: routes must be individually rational (no vehicle
has an incentive to deviate), and in practice, multiple planning agents (e.g.,
different companies) may coexist and compete. Surprisingly, we show that such
competition is not merely an obstacle but a necessary ingredient for achieving
optimal outcomes. In this work, we design a routing mechanism that embraces
competition and converges to an optimal assignment, starting from the classical
Pigou network as a foundational case.

</details>


### [232] [Maximizing Social Welfare with Side Payments](https://arxiv.org/abs/2508.07147)
*Ivan Geffner,Caspar Oesterheld,Vincent Conitzer*

Main category: cs.GT

TL;DR: 论文研究了允许玩家在行动前预先承诺结果相关转移的正常形式博弈，提出了一种分阶段承诺协议以避免效率损失。


<details>
  <summary>Details</summary>
Motivation: 解决Jackson和Wilkie指出的问题：无限制的同步承诺可能导致博弈效率下降，即使原本存在帕累托最优纳什均衡。

Method: 引入分阶段承诺协议，玩家只能以小额、有上限的增量在多轮中承诺转移，且需全体同意才能继续。

Result: 证明该协议能从任何有限博弈的非退化纳什均衡出发，实现所有严格帕累托改进的福利最大化支付配置。

Conclusion: 分阶段和有界承诺恢复了侧支付的效率潜力，同时避免了Jackson和Wilkie发现的效率损失。

Abstract: We examine normal-form games in which players may \emph{pre-commit} to
outcome-contingent transfers before choosing their actions. In the one-shot
version of this model, Jackson and Wilkie showed that side contracting can
backfire: even a game with a Pareto-optimal Nash equilibrium can devolve into
inefficient equilibria once unbounded, simultaneous commitments are allowed.
The root cause is a prisoner's dilemma effect, where each player can exploit
her commitment power to reshape the equilibrium in her favor, harming overall
welfare.
  To circumvent this problem we introduce a \emph{staged-commitment} protocol.
Players may pledge transfers only in small, capped increments over multiple
rounds, and the phase continues only with unanimous consent. We prove that,
starting from any finite game $\Gamma$ with a non-degenerate Nash equilibrium
$\vec{\sigma}$, this protocol implements every welfare-maximizing payoff
profile that \emph{strictly} Pareto-improves $\vec{\sigma}$. Thus, gradual and
bounded commitments restore the full efficiency potential of side payments
while avoiding the inefficiencies identified by Jackson and Wilkie.

</details>


### [233] [Last-Iterate Convergence in Adaptive Regret Minimization for Approximate Extensive-Form Perfect Equilibrium](https://arxiv.org/abs/2508.07699)
*Hang Ren,Xiaozhen Sun,Tianzi Ma,Jiajia Zhang,Xuan Wang*

Main category: cs.GT

TL;DR: 提出了一种高效的自适应遗憾最小化算法（RTCFR）来计算近似EFPE，解决了现有EFPE算法的高计算成本和固定扰动问题。


<details>
  <summary>Details</summary>
Motivation: Nash均衡在非完美信息扩展形式游戏中无法保证非均衡分支的最优策略，EFPE通过扰动改进但现有算法存在计算成本高和固定扰动问题。

Method: 采用RTCFR算法解决扰动游戏，引入ISNE动态调整扰动，实现双人零和EFG中的最后迭代收敛。

Result: 理论分析证明收敛到EFPE，实验显示在NE和EFPE任务中优于现有算法。

Conclusion: RTCFR算法高效解决了EFPE计算问题，显著提升了性能。

Abstract: The Nash Equilibrium (NE) assumes rational play in imperfect-information
Extensive-Form Games (EFGs) but fails to ensure optimal strategies for
off-equilibrium branches of the game tree, potentially leading to suboptimal
outcomes in practical settings. To address this, the Extensive-Form Perfect
Equilibrium (EFPE), a refinement of NE, introduces controlled perturbations to
model potential player errors. However, existing EFPE-finding algorithms, which
typically rely on average strategy convergence and fixed perturbations, face
significant limitations: computing average strategies incurs high computational
costs and approximation errors, while fixed perturbations create a trade-off
between NE approximation accuracy and the convergence rate of NE refinements.
  To tackle these challenges, we propose an efficient adaptive regret
minimization algorithm for computing approximate EFPE, achieving last-iterate
convergence in two-player zero-sum EFGs. Our approach introduces Reward
Transformation Counterfactual Regret Minimization (RTCFR) to solve perturbed
games and defines a novel metric, the Information Set Nash Equilibrium (ISNE),
to dynamically adjust perturbations. Theoretical analysis confirms convergence
to EFPE, and experimental results demonstrate that our method significantly
outperforms state-of-the-art algorithms in both NE and EFPE-finding tasks.

</details>


### [234] [Truthful Two-Obnoxious-Facility Location Games with Optional Preferences and Minimum Distance Constraint](https://arxiv.org/abs/2508.08036)
*Xiaojia Han,Wenjing Liu,Qizhi Fang*

Main category: cs.GT

TL;DR: 研究了两个厌恶设施的位置问题，提出了确定性及随机性策略证明机制，并给出了近似比的下界。


<details>
  <summary>Details</summary>
Motivation: 解决在最小距离约束下，如何放置两个厌恶设施以激励代理人真实报告位置并最大化社会效用的问题。

Method: 针对d=0和一般情况，分别提出了确定性及随机性策略证明机制。

Result: 确定性机制的近似比上限为4（d=0）和8（一般情况），随机性机制为2和4。下界分别为2和14/13。

Conclusion: 提出的机制在激励真实报告的同时，有效优化了社会效用，且近似比下界为未来研究提供了参考。

Abstract: In this paper, we study a truthful two-obnoxious-facility location problem,
in which each agent has a private location in [0, 1] and a public optional
preference over two obnoxious facilities, and there is a minimum distance
constraint d between the two facilities. Each agent wants to be as far away as
possible from the facilities that affect her, and the utility of each agent is
the total distance from her to these facilities. The goal is to decide how to
place the facilities in [0, 1] so as to incentivize agents to report their
private locations truthfully as well as maximize the social utility. First, we
consider the special setting where d = 0, that is, the two facilities can be
located at any point in [0, 1]. We propose a deterministic strategyproof
mechanism with approximation ratio of at most 4 and a randomized strategyproof
mechanism with approximation ratio of at most 2, respectively. Then we study
the general setting. We propose a deterministic strategyproof mechanism with
approximation ratio of at most 8 and a randomized strategyproof mechanism with
approximation ratio of at most 4, respectively. Furthermore, we provide lower
bounds of 2 and 14/13 on the approximation ratio for any deterministic and any
randomized strategyproof mechanism, respectively.

</details>


### [235] [Constrained Distributed Heterogeneous Two-Facility Location Problems with Max-Variant Cost](https://arxiv.org/abs/2508.08045)
*Xinru Xu,Wenjing Liu,Qizhi Fang*

Main category: cs.GT

TL;DR: 研究了一种分布式异构双设施选址问题，约束条件下设计策略证明的分布式机制，以优化社会目标。


<details>
  <summary>Details</summary>
Motivation: 解决在候选位置有限且分组约束下，如何激励代理真实报告位置并优化社会目标的问题。

Method: 提出分布式机制，分两步：每组选两个代表位置，再从所有代表中选两个设施位置。分析确定性策略证明机制的失真界限。

Result: 在四种社会目标下，获得了恒定的失真上界和下界。

Conclusion: 证明了分布式机制在约束条件下能有效优化社会目标，并提供了理论界限。

Abstract: We study a constrained distributed heterogeneous two-facility location
problem, where a set of agents with private locations on the real line are
divided into disjoint groups. The constraint means that the facilities can only
be built in a given multiset of candidate locations and at most one facility
can be built at each candidate location. Given the locations of the two
facilities, the cost of an agent is the distance from her location to the
farthest facility (referred to as max-variant). Our goal is to design
strategyproof distributed mechanisms that can incentivize all agents to
truthfully report their locations and approximately optimize some social
objective. A distributed mechanism consists of two steps: for each group, the
mechanism chooses two candidate locations as the representatives of the group
based only on the locations reported by agents therein; then, it outputs two
facility locations among all the representatives. We focus on a class of
deterministic strategyproof distributed mechanisms and analyze upper and lower
bounds on the distortion under the Average-of-Average cost (average of the
average individual cost of agents in each group), the Max-of-Max cost (maximum
individual cost among all agents), the Average-of-Max cost (average of the
maximum individual cost among all agents in each group) and the Max-of-Average
cost (maximum of the average individual cost of all agents in each group).
Under four social objectives, we obtain constant upper and lower distortion
bounds.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [236] [Accessibility Literacy: Increasing accessibility awareness among young content creators](https://arxiv.org/abs/2508.06512)
*Alina Karakanta*

Main category: cs.HC

TL;DR: 研究探讨了通过小型模块提升年轻内容创作者的无障碍素养，使用简单的培训材料（如信息图和测验），并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 媒体无障碍教育在大学课程中优先级低，但需求日益增长，需要探索替代学习方式。

Method: 设计并实施了一个小型培训模块，通过调查评估参与者培训前后的无障碍素养变化。

Result: 培训后，参与者对无障碍工具的使用意愿提高，但认知仍受医疗模式影响。

Conclusion: 小型针对性干预可作为无障碍教育融入正式课程的替代方案，有助于提升包容性和社会公平。

Abstract: The proliferation of audiovisual and web content has created an increasing
need for media accessibility education in various fields. However,
accessibility remains a low priority in university curricula. This project
explores the feasibility of an alternative learning experience aimed at
increasing the accessibility literacy of young content creators, taking web
accessibility as a case study. We propose a mini module that uses simple,
easy-to-use training materials, such as infographics and short quizzes, and can
be easily incorporated in educational programmes along existing courses. A
survey was conducted to investigate the participants' accessibility literacy
before and after training. The findings show that young content creators
generally have limited accessibility literacy but even brief exposure to
accessibility materials contributed to a shift in perceptions. After training,
participants expressed more willingness to implement accessibility tools in
their content, with ways varying depending on content type and purpose. This
suggests that small, yet targeted interventions could be an alternative for
integrating accessibility training into formal education across various
disciplines. While some responses reflected traces of the medical model of
disability and a particularlist view of accessibility, accessibility was
recognised as important for increasing inclusion, improving content, and
shaping a fairer society.

</details>


### [237] [ClimateSOM: A Visual Analysis Workflow for Climate Ensemble Datasets](https://arxiv.org/abs/2508.06732)
*Yuya Kawakami,Daniel Cayan,Dongyu Liu,Kwan-Liu Ma*

Main category: cs.HC

TL;DR: ClimateSOM是一个结合自组织映射（SOM）和大语言模型（LLMs）的可视化分析工作流，用于探索和解释气候集合数据集的变异性。


<details>
  <summary>Details</summary>
Motivation: 气候科学中，集合数据集用于捕捉未来条件下的变异性，但分析这些数据的变异性是一项重要任务。

Method: 通过SOM将时空时间序列抽象为2D空间分布，并集成LLMs辅助解释，支持交互式探索。

Result: ClimateSOM能够帮助用户探索变异性、识别模式、比较和聚类集合模型运行，并通过案例研究和专家评估验证其效用。

Conclusion: ClimateSOM为气候科学家提供了一种有效的工具，用于分析和理解集合数据集的变异性。

Abstract: Ensemble datasets are ever more prevalent in various scientific domains. In
climate science, ensemble datasets are used to capture variability in
projections under plausible future conditions including greenhouse and aerosol
emissions. Each ensemble model run produces projections that are fundamentally
similar yet meaningfully distinct. Understanding this variability among
ensemble model runs and analyzing its magnitude and patterns is a vital task
for climate scientists. In this paper, we present ClimateSOM, a visual analysis
workflow that leverages a self-organizing map (SOM) and Large Language Models
(LLMs) to support interactive exploration and interpretation of climate
ensemble datasets. The workflow abstracts climate ensemble model runs -
spatiotemporal time series - into a distribution over a 2D space that captures
the variability among the ensemble model runs using a SOM. LLMs are integrated
to assist in sensemaking of this SOM-defined 2D space, the basis for the visual
analysis tasks. In all, ClimateSOM enables users to explore the variability
among ensemble model runs, identify patterns, compare and cluster the ensemble
model runs. To demonstrate the utility of ClimateSOM, we apply the workflow to
an ensemble dataset of precipitation projections over California and the
Northwestern United States. Furthermore, we conduct a short evaluation of our
LLM integration, and conduct an expert review of the visual workflow and the
insights from the case studies with six domain experts to evaluate our approach
and its utility.

</details>


### [238] [Toward a Logic of Generalization about Visualization as a Decision Aid](https://arxiv.org/abs/2508.06751)
*Alex Kale*

Main category: cs.HC

TL;DR: 本文探讨了可视化研究中泛化逻辑的局限性，特别是在决策辅助应用中的问题，并提出决策理论作为理解情境变化的工具。


<details>
  <summary>Details</summary>
Motivation: 可视化研究在泛化结果时面临挑战，尤其是在决策辅助场景中，需要更清晰的逻辑框架。

Method: 通过决策理论定义决策问题的变化维度，并分析可视化支持决策时的情境异质性。

Result: 研究发现效用是可视化决策研究中一个核心但未被充分探讨的概念，决策理论有助于改进泛化逻辑。

Conclusion: 决策理论可作为可视化研究中理解情境变化的有效工具，提升泛化能力。

Abstract: Visualization as a discipline often grapples with generalization by reasoning
about how study results on the efficacy of a tool in one context might apply to
another context. This work offers an account of the logic of generalization in
visualization research and argues that it struggles in particular with
applications of visualization as a decision aid. We use decision theory to
define the dimensions on which decision problems can vary, and we present an
analysis of heterogeneity in scenarios where visualization supports
decision-making. Our findings identify utility as a focal and under-examined
concept in visualization research on decision-making, demonstrating how the
visualization community's logic of generalization might benefit from using
decision theory as a lens for understanding context variation.

</details>


### [239] [Story Ribbons: Reimagining Storyline Visualizations with Large Language Models](https://arxiv.org/abs/2508.06772)
*Catherine Yeh,Tara Menon,Robin Singh Arya,Helen He,Moira Weigel,Fernanda Viégas,Martin Wattenberg*

Main category: cs.HC

TL;DR: 利用大语言模型（LLM）自动解析小说和剧本中的叙事信息，开发交互式可视化系统Story Ribbons，帮助文学分析者探索角色和主题轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以从非结构化故事数据中提取结构化信息，LLM的文本处理能力为改进叙事可视化提供了新机会。

Method: 提出LLM驱动的数据解析管道，自动提取叙事信息，并开发Story Ribbons可视化系统。

Result: 在36部文学作品上验证了管道的有效性，展示了LLM在简化叙事可视化生成和揭示新见解方面的潜力。

Conclusion: LLM可提升叙事可视化效果，但AI系统仍有局限性，需通过交互设计弥补。

Abstract: Analyzing literature involves tracking interactions between characters,
locations, and themes. Visualization has the potential to facilitate the
mapping and analysis of these complex relationships, but capturing structured
information from unstructured story data remains a challenge. As large language
models (LLMs) continue to advance, we see an opportunity to use their text
processing and analysis capabilities to augment and reimagine existing
storyline visualization techniques. Toward this goal, we introduce an
LLM-driven data parsing pipeline that automatically extracts relevant narrative
information from novels and scripts. We then apply this pipeline to create
Story Ribbons, an interactive visualization system that helps novice and expert
literary analysts explore detailed character and theme trajectories at multiple
narrative levels. Through pipeline evaluations and user studies with Story
Ribbons on 36 literary works, we demonstrate the potential of LLMs to
streamline narrative visualization creation and reveal new insights about
familiar stories. We also describe current limitations of AI-based systems, and
interaction motifs designed to address these issues.

</details>


### [240] [Visualization Vibes: The Socio-Indexical Function of Visualization Design](https://arxiv.org/abs/2508.06775)
*Michelle Morgenstern,Amy Rae Fox,Graham M. Jones,Arvind Satyanarayan*

Main category: cs.HC

TL;DR: 论文探讨了数据可视化不仅传递数据语义信息，还传递社会性意义，影响公众对可视化的接受度。


<details>
  <summary>Details</summary>
Motivation: 当前信息环境中，公众对科学和数据的不信任导致数据传播面临挑战，传统可视化研究未能完全解释公众对可视化的反应。

Method: 结合语言人类学理论，通过民族志访谈分析读者对可视化设计的“氛围”感知及其社会属性。

Result: 研究发现可视化设计特征会引发读者对其社会来源的推断，进而影响接受度。

Conclusion: 论文提出可视化中的社会索引性功能，为公共数据传播问题提供了理论和实践解决方案。

Abstract: In contemporary information ecologies saturated with misinformation,
disinformation, and a distrust of science itself, public data communication
faces significant hurdles. Although visualization research has broadened
criteria for effective design, governing paradigms privilege the accurate and
efficient transmission of data. Drawing on theory from linguistic anthropology,
we argue that such approaches-focused on encoding and decoding propositional
content-cannot fully account for how people engage with visualizations and why
particular visualizations might invite adversarial or receptive responses. In
this paper, we present evidence that data visualizations communicate not only
semantic, propositional meaning$\unicode{x2013}$meaning about
data$\unicode{x2013}$but also social, indexical meaning$\unicode{x2013}$meaning
beyond data. From a series of ethnographically-informed interviews, we document
how readers make rich and varied assessments of a visualization's
"vibes"$\unicode{x2013}$inferences about the social provenance of a
visualization based on its design features. Furthermore, these social
attributions have the power to influence reception, as readers' decisions about
how to engage with a visualization concern not only content, or even aesthetic
appeal, but also their sense of alignment or disalignment with the entities
they imagine to be involved in its production and circulation. We argue these
inferences hinge on a function of human sign systems that has thus far been
little studied in data visualization: socio-indexicality, whereby the formal
features (rather than the content) of communication evoke social contexts,
identities, and characteristics. Demonstrating the presence and significance of
this socio-indexical function in visualization, this paper offers both a
conceptual foundation and practical intervention for troubleshooting breakdowns
in public data communication.

</details>


### [241] [Methodology for Business Intelligence Solutions in Internet Banking Companies](https://arxiv.org/abs/2508.06773)
*Alex Escalante Viteri,Javier Gamboa Cruzado,Leonidas Asto Huaman*

Main category: cs.HC

TL;DR: 该研究旨在优化互联网银行公司的决策过程，减少时间、人力和成本。通过基础和应用研究，提出了一种新的商业智能方法，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 银行行业商业智能研究虽多，但决策效率仍低，缺乏正式方法论。

Method: 结合基础研究（成功因素分析）和应用研究（实验性实施），使用Minitab18分析数据。

Result: 新方法显著减少了决策时间、人力和成本。

Conclusion: 新商业智能方法有效优化了互联网银行公司的决策过程。

Abstract: Business intelligence in the banking industry has been studied extensively in
the last decade; however, business executives still do not perceive efficiency
in the decision-making process since the management and treatment of
information are very timeconsuming for the deliverer, generating costs in the
process. On the other hand, there is no formal methodology for developing
business intelligence solutions in this sector. This work aims to optimize
decision-making in a business unit that works with internet banking companies,
reducing the time, the number of people, and the costs involved in
decision-making. To meet the objective, basic and applied research was
conducted. The basic research allowed the construction of a new methodology
from a study of critical success factors and approaches from the business
intelligence literature. The applied research involved the implementation of a
business intelligence solution applying the new methodology in a
pre-experimental study. Thirty decision-making processes were analyzed using
pre-test and post-test data. Tools such as a stopwatch and observation were
used to collect and record data on time spent, the number of people, and the
decision-making costs. This information was processed in the specialized
Minitab18 statistical software, which allowed the observation and confirmation
of relevant results regarding time reduction, the number of people, and the
costs generated. Therefore, it was concluded that the business intelligence
solution, applying the new methodology, optimized decision making in the
business unit that works with internet banking for companies.

</details>


### [242] [Quantifying Visualization Vibes: Measuring Socio-Indexicality at Scale](https://arxiv.org/abs/2508.06786)
*Amy Rae Fox,Michelle Morgenstern,Graham M. Jones,Arvind Satyanarayan*

Main category: cs.HC

TL;DR: 论文探讨了可视化如何传达超出数据本身的信息，提出了一个分析框架，并通过调查验证了社会推断的普遍性和对信任评估的影响。


<details>
  <summary>Details</summary>
Motivation: 研究可视化在社会文化背景下的作用，揭示其如何影响公众对数据的理解和信任。

Method: 采用属性-启发调查，分析社会推断的普遍性及其与设计特征的关系。

Result: 研究发现社会推断可异步研究、普遍存在，且设计特征与数据主题共同影响解读。

Conclusion: 扩展可视化研究中的人文因素，纳入社会文化现象，可为公共数据传播提供实用设计建议。

Abstract: What impressions might readers form with visualizations that go beyond the
data they encode? In this paper, we build on recent work that demonstrates the
socio-indexical function of visualization, showing that visualizations
communicate more than the data they explicitly encode. Bridging this with prior
work examining public discourse about visualizations, we contribute an analytic
framework for describing inferences about an artifact's social provenance. Via
a series of attribution-elicitation surveys, we offer descriptive evidence that
these social inferences: (1) can be studied asynchronously, (2) are not unique
to a particular sociocultural group or a function of limited data literacy, and
(3) may influence assessments of trust. Further, we demonstrate (4) how design
features act in concert with the topic and underlying messages of an artifact's
data to give rise to such 'beyond-data' readings. We conclude by discussing the
design and research implications of inferences about social provenance, and why
we believe broadening the scope of research on human factors in visualization
to include sociocultural phenomena can yield actionable design recommendations
to address urgent challenges in public data communication.

</details>


### [243] [Gender and Careers in Platform-Mediated Work: A Longitudinal Study of Online Freelancers](https://arxiv.org/abs/2508.06778)
*Pyeonghwa Kim,Steve Sawyer,Michael Dunn*

Main category: cs.HC

TL;DR: 研究通过五年纵向调查揭示了数字劳动平台上性别不平等对自由职业者长期职业轨迹的影响，提出了职业去权化和平台中介的母亲惩罚概念，为CSCW领域提供了促进性别包容的设计建议。


<details>
  <summary>Details</summary>
Motivation: 数字劳动平台上的性别不平等问题在CSCW领域备受关注，但缺乏对其长期影响的深入研究。

Method: 对105名Upwork自由职业者进行了五年纵向研究。

Result: 揭示了性别差异对长期职业轨迹的持续影响，提出了职业去权化和平台中介的母亲惩罚现象。

Conclusion: 研究为CSCW领域提供了促进性别包容和可持续平台工作环境的设计启示。

Abstract: We advance gender-inclusive research within the CSCW field by investigating
the long-term gendered experiences of online freelancers on digital labor
platforms. The prevalence of gender-based inequalities has attracted
significant attention within the CSCW community. Yet, insights remain limited
on how these inequalities shape workers' long-term experiences on digital labor
platforms. Through a five-year longitudinal study of 105 freelancers on Upwork,
we reveal persistent gender disparities that influence workers' long-term work
and career trajectories, raising concerns about the sustainability of
platform-mediated work. We advance the ongoing dialogue on gender inclusivity
in the community by introducing the concepts of career disempowerment and
platform-mediated motherhood penalty and by offering research and design
implications for CSCW to foster more sustainable, equitable platform work
environments for all genders.

</details>


### [244] [Entendimento de Campanhas no Contexto da Atenção Primária à Saúde: Um Processo de Design Socialmente Consciente](https://arxiv.org/abs/2508.06791)
*Deógenes P. da Silva Junior,Jonas Lopes Guerra,Krissia Menezes,Marisa Sel Franco,Roberto Pereira*

Main category: cs.HC

TL;DR: 对社区卫生工作者和疾病控制人员在初级卫生保健（PHC）中的工作环境进行了探索性分析，特别关注健康宣传活动。


<details>
  <summary>Details</summary>
Motivation: 理解健康宣传活动中的社会和技术需求，为解决方案的开发提供依据。

Method: 采用社会意识设计框架，使用利益相关者识别图、评估框架和符号学框架等方法，结合人物角色和场景分析。

Result: 识别了利益相关者、挑战及需求，为PHC健康宣传活动管理解决方案的原型开发提供了依据。

Conclusion: 研究结果为开发中等保真度的健康宣传活动管理原型提供了重要参考。

Abstract: This report presents the results of an exploratory analysis of the work
context of Community Health Agents and Endemic Disease Control Agents in
Primary Health Care (PHC), with a particular focus on Health Campaigns. To
understand this context, the study adopted the Socially Aware Design framework,
which employs artifacts and techniques to examine problem domains in a
comprehensive and sociotechnical manner. Methods such as the Stakeholder
Identification Diagram, Evaluation Frame, and Semiotic Framework were applied
to identify stakeholders, anticipate challenges, and elicit social and
technical requirements for the solution. Personas and Scenarios were also used
to illustrate the potential impacts of a solution on various stakeholders and
their life contexts within health campaigns. This report presents the analysis
method, its application, and results, discussing the study's findings to inform
the development of medium-fidelity prototypes for a PHC health campaign
management solution.

</details>


### [245] [Understanding Pedestrian Gesture Misrecognition: Insights from Vision-Language Model Reasoning](https://arxiv.org/abs/2508.06801)
*Tram Thi Minh Tran,Xinyan Yu,Callum Parker,Julie Stephany Berrio Perez,Stewart Worrall,Martin Tomitsch*

Main category: cs.HC

TL;DR: 研究利用GPT-4V分析行人手势在自动驾驶车辆交互中的误识别模式，揭示影响因素并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 行人手势在交通交互中至关重要，但其模糊性和上下文依赖性对机器识别构成挑战。

Method: 结合手动视频审查和GPT-4V的定性推理，分析公共数据集中的行人-车辆交互。

Result: 发现手势可见性、行人行为、交互上下文和环境条件是误识别的主要因素。

Conclusion: 研究为手势设计提供实用建议，并强调通过上下文建模和不确定性感知改进自动驾驶识别系统。

Abstract: Pedestrian gestures play an important role in traffic communication,
particularly in interactions with autonomous vehicles (AVs), yet their subtle,
ambiguous, and context-dependent nature poses persistent challenges for machine
interpretation. This study investigates these challenges by using GPT-4V, a
vision-language model, not as a performance benchmark but as a diagnostic tool
to reveal patterns and causes of gesture misrecognition. We analysed a public
dataset of pedestrian-vehicle interactions, combining manual video review with
thematic analysis of the model's qualitative reasoning. This dual approach
surfaced recurring factors influencing misrecognition, including gesture
visibility, pedestrian behaviour, interaction context, and environmental
conditions. The findings suggest practical considerations for gesture design,
including the value of salience and contextual redundancy, and highlight
opportunities to improve AV recognition systems through richer context
modelling and uncertainty-aware interpretations. While centred on AV-pedestrian
interaction, the method and insights are applicable to other domains where
machines interpret human gestures, such as wearable AR and assistive
technologies.

</details>


### [246] [AdjustAR: AI-Driven In-Situ Adjustment of Site-Specific Augmented Reality Content](https://arxiv.org/abs/2508.06826)
*Nels Numan,Jessica Van Brummelen,Ziwen Lu,Anthony Steed*

Main category: cs.HC

TL;DR: AdjustAR系统利用多模态大语言模型（MLLMs）动态校正AR内容，以应对现实环境变化导致的虚拟内容错位问题。


<details>
  <summary>Details</summary>
Motivation: 现实环境随时间变化，导致静态3D模型部署的AR内容与实际场景错位，影响用户体验和上下文理解。

Method: 通过MLLMs分析原始视图与实时用户视图的复合图像，检测上下文错位并提出2D修正方案，再将其反向投影至3D空间更新场景。

Result: 系统实现了运行时自动校正，保持AR内容与设计意图的动态对齐。

Conclusion: AdjustAR展示了利用MLLMs实现动态环境AR内容校正的潜力，提升了用户体验。

Abstract: Site-specific outdoor AR experiences are typically authored using static 3D
models, but are deployed in physical environments that change over time. As a
result, virtual content may become misaligned with its intended real-world
referents, degrading user experience and compromising contextual
interpretation. We present AdjustAR, a system that supports in-situ correction
of AR content in dynamic environments using multimodal large language models
(MLLMs). Given a composite image comprising the originally authored view and
the current live user view from the same perspective, an MLLM detects
contextual misalignments and proposes revised 2D placements for affected AR
elements. These corrections are backprojected into 3D space to update the scene
at runtime. By leveraging MLLMs for visual-semantic reasoning, this approach
enables automated runtime corrections to maintain alignment with the authored
intent as real-world target environments evolve.

</details>


### [247] [Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators](https://arxiv.org/abs/2508.06846)
*Hyo Jin Do,Rachel Ostrand,Werner Geyer,Keerthiram Murugesan,Dennis Wei,Justin Weisz*

Main category: cs.HC

TL;DR: 研究探讨了如何通过设计策略有效传达LLM生成内容的真实性评分，发现用户更信任并偏好基于真实性评分的颜色编码设计。


<details>
  <summary>Details</summary>
Motivation: LLM易生成不准确信息，但缺乏研究如何向用户有效传达其真实性评分。

Method: 通过两项情景实验（共208名参与者），比较不同设计策略对用户信任、验证准确性和偏好的影响。

Result: 用户更信任且偏好颜色编码设计，认为其更易于验证准确性。

Conclusion: 研究为LLM应用开发者提供了实用设计指南，旨在校准用户信任并提升用户验证能力。

Abstract: Large language models (LLMs) are susceptible to generating inaccurate or
false information, often referred to as "hallucinations" or "confabulations."
While several technical advancements have been made to detect hallucinated
content by assessing the factuality of the model's responses, there is still
limited research on how to effectively communicate this information to users.
To address this gap, we conducted two scenario-based experiments with a total
of 208 participants to systematically compare the effects of various design
strategies for communicating factuality scores by assessing participants'
ratings of trust, ease in validating response accuracy, and preference. Our
findings reveal that participants preferred and trusted a design in which all
phrases within a response were color-coded based on factuality scores.
Participants also found it easier to validate accuracy of the response in this
style compared to a baseline with no style applied. Our study offers practical
design guidelines for LLM application developers and designers, aimed at
calibrating user trust, aligning with user preferences, and enhancing users'
ability to scrutinize LLM outputs.

</details>


### [248] [Perceiving Slope and Acceleration: Evidence for Variable Tempo Sampling in Pitch-Based Sonification of Functions](https://arxiv.org/abs/2508.06872)
*Danyang Fan,Walker Smith,Takako Fujioka,Chris Chage,Sile O'Modhrain,Diana Deutsch,Sean Follmer*

Main category: cs.HC

TL;DR: 论文提出了一种基于音高的声化新方法（Variable Tempo），通过均匀的y间距采样，显著提升了人们对数据趋势中斜率和加速度的感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统声化方法（如Variable Pitch Interval）在均匀x间距采样下，难以有效传达数据趋势的斜率和加速度特征，因此需要探索更优的声化方法。

Method: 引入Variable Tempo方法，通过均匀y间距采样生成可变节奏的音符，并与传统方法（Variable Pitch Interval和Continuous）进行心理声学实验对比。

Result: Variable Tempo在斜率比较任务中表现更准确，加速度感知的差异阈值比其他方法精细13倍以上，且参与者对其信心更高、偏好更强。

Conclusion: Variable Tempo是一种更优的声化方法，能够更敏感、准确地传达数据趋势的导数特征。

Abstract: Sonification offers a non-visual way to understand data, with pitch-based
encodings being the most common. Yet, how well people perceive slope and
acceleration-key features of data trends-remains poorly understood. Drawing on
people's natural abilities to perceive tempo, we introduce a novel sampling
method for pitch-based sonification to enhance the perception of slope and
acceleration in univariate functions. While traditional sonification methods
often sample data at uniform x-spacing, yielding notes played at a fixed tempo
with variable pitch intervals (Variable Pitch Interval), our approach samples
at uniform y-spacing, producing notes with consistent pitch intervals but
variable tempo (Variable Tempo). We conducted psychoacoustic experiments to
understand slope and acceleration perception across three sampling methods:
Variable Pitch Interval, Variable Tempo, and a Continuous (no sampling)
baseline. In slope comparison tasks, Variable Tempo was more accurate than the
other methods when modulated by the magnitude ratio between slopes. For
acceleration perception, just-noticeable differences under Variable Tempo were
over 13 times finer than with other methods. Participants also commonly
reported higher confidence, lower mental effort, and a stronger preference for
Variable Tempo compared to other methods. This work contributes models of slope
and acceleration perception across pitch-based sonification techniques,
introduces Variable Tempo as a novel and preferred sampling method, and
provides promising initial evidence that leveraging timing can lead to more
sensitive, accurate, and precise interpretation of derivative-based data
features.

</details>


### [249] [Viewpoint-Tolerant Depth Perception for Shared Extended Space Experience on Wall-Sized Display](https://arxiv.org/abs/2508.06889)
*Dooyoung Kim,Jinseok Hong,Heejeong Ko,Woontack Woo*

Main category: cs.HC

TL;DR: 论文提出了一种无需个体追踪的视角容忍共享深度感知方法，利用人类认知补偿在墙式显示器上实现3D渲染。


<details>
  <summary>Details</summary>
Motivation: 传统3D显示系统多针对单用户场景，而墙式显示器在多用户交互中的潜力未被充分探索。

Method: 研究虚拟深度（dv）和绝对观看距离（da）对人类认知补偿因素（感知距离差异、视角阈值和感知存在感）的影响，构建基于墙式显示器的扩展现实（XR）空间。

Result: 实验表明，参与者在23至37度的偏角下仍能感知深度，但过大的虚拟深度会降低深度感知和存在感。

Conclusion: 墙式显示器可在博物馆、教室等场所提供无需追踪或穿戴设备的沉浸式多用户体验。

Abstract: We proposed viewpoint-tolerant shared depth perception without individual
tracking by leveraging human cognitive compensation in universally 3D rendered
images on a wall-sized display. While traditional 3D perception-enabled display
systems have primarily focused on single-user scenarios-adapting rendering
based on head and eye tracking the use of wall-sized displays to extend spatial
experiences and support perceptually coherent multi-user interactions remains
underexplored. We investigated the effects of virtual depths (dv) and absolute
viewing distance (da) on human cognitive compensation factors (perceived
distance difference, viewing angle threshold, and perceived presence) to
construct the wall display-based eXtended Reality (XR) space. Results show that
participants experienced a compelling depth perception even from off-center
angles of 23 to 37 degrees, and largely increasing virtual depth worsens depth
perception and presence factors, highlighting the importance of balancing
extended depth of virtual space and viewing distance from the wall-sized
display. Drawing on these findings, wall-sized displays in venues such as
museums, galleries, and classrooms can evolve beyond 2D information sharing to
offer immersive, spatially extended group experiences without individualized
tracking or wearables.

</details>


### [250] [Your Thoughtful Opponent: Embracing Cognitive Conflict with Peer Agent](https://arxiv.org/abs/2508.06955)
*Kyuwon Kim,Jaeryeong Hwang,Younseo Lee,Jeanhee Lee,Sung-Eun Kimm,Hyo-Jeong So*

Main category: cs.HC

TL;DR: 提出了一种Peer Agent系统，通过模拟对话伙伴在游戏中引发社会认知冲突，以培养民主技能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂社会问题需要培养民主技能，如重视多元观点和协作决策。

Method: 基于Inner Thoughts框架和价值敏感话语分析，设计了包含五个核心模块的PA系统。

Result: PA系统能通过语音多方讨论与人类玩家互动。

Conclusion: 该系统为教育中培养民主技能提供了新工具。

Abstract: As complex societal issues continue to emerge, fostering democratic skills
like valuing diverse perspectives and collaborative decision-making is
increasingly vital in education. In this paper, we propose a Peer Agent (PA)
system designed to simulate a deliberative conversational partner that induces
socio-cognitive conflict within dilemma-based game play. Drawing on by the
Inner Thoughts framework and grounded in value-sensitive discourse analysis,
the PA actively participates in voice-based multi-party deliberation with human
players. The system architecture consists of five core modules: Context
Interpreter, Agent State Manager, Thought Generator, Thought Evaluator, and
Thought Articulator.

</details>


### [251] [Rethinking Privacy Indicators in Extended Reality: Multimodal Design for Situationally Impaired Bystanders](https://arxiv.org/abs/2508.07057)
*Syed Ibrahim Mustafa Shah Bukhari,Maha Sajid,Bo Ji,Brendan David-John*

Main category: cs.HC

TL;DR: 研究探讨了针对情境障碍旁观者的XR隐私指示器设计，发现多模态指示器比纯视觉指示器更有效。


<details>
  <summary>Details</summary>
Motivation: 随着XR设备普及，隐私问题引起关注，现有视觉指示器对情境障碍旁观者效果不佳。

Method: 通过焦点小组设计五种新型隐私指示器，并通过用户研究评估其效果。

Result: 多模态指示器在隐私敏感场景中更受青睐，纯视觉指示器评分较低。

Conclusion: 需开发适应性强、多模态且情境感知的隐私指示器设计。

Abstract: As Extended Reality (XR) devices become increasingly prevalent in everyday
settings, they raise significant privacy concerns for bystanders: individuals
in the vicinity of an XR device during its use, whom the device sensors may
accidentally capture. Current privacy indicators, such as small LEDs, often
presume that bystanders are attentive enough to interpret the privacy signals.
However, these cues can be easily overlooked when bystanders are distracted or
have limited vision. We define such individuals as situationally impaired
bystanders. This study explores XR privacy indicator designs that are effective
for situationally impaired bystanders. A focus group with eight participants
was conducted to design five novel privacy indicators. We evaluated these
designs through a user study with seven additional participants. Our results
show that visual-only indicators, typical in commercial XR devices, received
low ratings for perceived usefulness in impairment scenarios. In contrast,
multimodal indicators were preferred in privacy-sensitive scenarios with
situationally impaired bystanders. Ultimately, our results highlight the need
to move toward adaptable, multimodal, and situationally aware designs that
effectively support bystander privacy in everyday XR environments.

</details>


### [252] [Beyond Problem Solving: Framing and Problem-Solution Co-Evolution in Data Visualization Design](https://arxiv.org/abs/2508.07058)
*Paul C. Parsons,Prakash Chandra Shukla*

Main category: cs.HC

TL;DR: 论文探讨了可视化设计中问题框架的重要性，强调设计是一个反思性、共同演化的过程，而非单纯的技术问题解决。


<details>
  <summary>Details</summary>
Motivation: 现有可视化设计模型过于强调技术问题解决，而忽视了设计的解释性和判断性。

Method: 采用混合方法研究，包括设计挑战、日记记录和半结构化访谈，对11位专家进行主题分析。

Result: 发现专家通过隐喻、启发式、草图等方法动态调整问题框架，并将问题与解决方案空间联系起来。

Conclusion: 可视化设计是一个持续反思和共同演化的过程，需开发更全面的框架以支持问题框架和解释性判断。

Abstract: Visualization design is often described as the process of solving a
well-defined problem by navigating a design space. While existing visualization
design models have provided valuable structure and guidance, they tend to
foreground technical problem-solving and underemphasize the interpretive,
judgment-based aspects of design. In contrast, research in other design
disciplines has emphasized the importance of framing--how designers define and
redefine what the problem is--and the co-evolution of problem and solution
spaces through reflective practice. These dimensions remain underexplored in
visualization research, particularly from the perspective of expert
practitioners. This paper investigates how visualization designers frame
problems and navigate the dynamic interplay between problem understanding and
solution development. We conducted a mixed-methods study with 11 expert
practitioners using design challenges, diary entries, and semi-structured
interviews. Through reflexive thematic analysis, we identified key strategies
that participants used to frame problems, reframe them in response to evolving
constraints or insights, and build bridges between problem and solution spaces.
These included using metaphors, heuristics, sketching, primary generators, and
reflective evaluation of failed or incomplete ideas. Our findings contribute an
empirically grounded account of visualization design as a reflective,
co-evolutionary practice, where framing is not a preliminary step but a
continuous activity embedded in design. Participants often reshaped their
understanding of the problem based on solution attempts, tool feedback, and
ethical or narrative concerns. These insights extend current visualization
design models and highlight the need for frameworks that better account for
framing and interpretive judgment. (See paper for full abstract.)

</details>


### [253] [Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust](https://arxiv.org/abs/2508.07095)
*Hyo Jin Do,Werner Geyer*

Main category: cs.HC

TL;DR: 研究探讨了四种披露AI生成内容事实性评估的方式对用户信任的影响，发现隐藏或模糊不准确内容能提高信任且不影响答案质量。


<details>
  <summary>Details</summary>
Motivation: 防止用户因盲目信任AI而做出错误决策，探索如何有效传达AI生成内容的事实性评估。

Method: 测试四种披露策略（透明、关注、不透明、模糊）与无事实性信息的基线对比，通过148人的实验评估信任和答案质量。

Result: 不透明和模糊策略在保持答案质量的同时提高了用户信任。

Conclusion: 隐藏或模糊不准确内容可能是提升用户信任的有效策略。

Abstract: Large language models are known to produce outputs that are plausible but
factually incorrect. To prevent people from making erroneous decisions by
blindly trusting AI, researchers have explored various ways of communicating
factuality estimates in AI-generated outputs to end-users. However, little is
known about whether revealing content estimated to be factually incorrect
influences users' trust when compared to hiding it altogether. We tested four
different ways of disclosing an AI-generated output with factuality
assessments: transparent (highlights less factual content), attention
(highlights factual content), opaque (removes less factual content), ambiguity
(makes less factual content vague), and compared them with a baseline response
without factuality information. We conducted a human subjects research (N =
148) using the strategies in question-answering scenarios. We found that the
opaque and ambiguity strategies led to higher trust while maintaining perceived
answer quality, compared to the other strategies. We discuss the efficacy of
hiding presumably less factual content to build end-user trust.

</details>


### [254] [Toward AI Matching Policies in Homeless Services: A Qualitative Study with Policymakers](https://arxiv.org/abs/2508.07129)
*Caroline M. Johnston,Olga Koumoundouros,Angel Hsing-Chi Hwang,Laura Onasch-Vera,Eric Rice,Phebe Vayanos*

Main category: cs.HC

TL;DR: 研究探讨了人工智能在无家可归者住房资源匹配中的应用，通过访谈发现政策制定者支持AI工具，但需与人类决策结合。


<details>
  <summary>Details</summary>
Motivation: 了解政策制定者对AI在住房资源匹配中的接受度及其潜在影响。

Method: 对洛杉矶13位政策制定者进行半结构化访谈，分析其对AI工具的看法。

Result: 政策制定者支持AI工具，但强调需与人类决策结合，并关注效率、公平和透明度。

Conclusion: 未来研究应关注如何设计负责任的AI系统，以支持低资源场景下的决策。

Abstract: Artificial intelligence researchers have proposed various data-driven
algorithms to improve the processes that match individuals experiencing
homelessness to scarce housing resources. It remains unclear whether and how
these algorithms are received or adopted by practitioners and what their
corresponding consequences are. Through semi-structured interviews with 13
policymakers in homeless services in Los Angeles, we investigate whether such
change-makers are open to the idea of integrating AI into the housing resource
matching process, identifying where they see potential gains and drawbacks from
such a system in issues of efficiency, fairness, and transparency. Our
qualitative analysis indicates that, even when aware of various complicating
factors, policymakers welcome the idea of an AI matching tool if thoughtfully
designed and used in tandem with human decision-makers. Though there is no
consensus as to the exact design of such an AI system, insights from
policymakers raise open questions and design considerations that can be
enlightening for future researchers and practitioners who aim to build
responsible algorithmic systems to support decision-making in low-resource
scenarios.

</details>


### [255] [Canvas3D: Empowering Precise Spatial Control for Image Generation with Constraints from a 3D Virtual Canvas](https://arxiv.org/abs/2508.07135)
*Runlin Duan,Yuzhao Chen,Rahul Jain,Yichen Hu,Jingyu Shi,Karthik Ramani*

Main category: cs.HC

TL;DR: Canvas3D是一个基于3D引擎的交互式系统，通过将文本描述转换为可交互的3D对象，实现对图像生成的空间精确控制。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在图像生成中难以精确控制空间布局，Canvas3D旨在解决这一问题。

Method: 利用3D引擎将用户提示转换为可交互的3D对象，生成明确的空间约束以指导图像生成。

Result: Canvas3D在空间控制、交互性和用户体验上优于基线系统。

Conclusion: Canvas3D有效提升了生成式AI在空间布局控制上的精确性和用户交互体验。

Abstract: Generative AI (GenAI) has significantly advanced the ease and flexibility of
image creation. However, it remains a challenge to precisely control spatial
compositions, including object arrangement and scene conditions. To bridge this
gap, we propose Canvas3D, an interactive system leveraging a 3D engine to
enable precise spatial manipulation for image generation. Upon user prompt,
Canvas3D automatically converts textual descriptions into interactive objects
within a 3D engine-driven virtual canvas, empowering direct and precise spatial
configuration. These user-defined arrangements generate explicit spatial
constraints that guide generative models in accurately reflecting user
intentions in the resulting images. We conducted a closed-end comparative study
between Canvas3D and a baseline system. And an open-ended study to evaluate our
system "in the wild". The result indicates that Canvas3D outperforms the
baseline on spatial control, interactivity, and overall user experience.

</details>


### [256] [SketchConcept: Sketching-based Concept Recomposition for Product Design using Generative AI](https://arxiv.org/abs/2508.07141)
*Runlin Duan,Chenfei Zhu,Yuzhao Chen,Dizhi Ma,Jingyu Shi,Ziyi Liu,Karthik Ramani*

Main category: cs.HC

TL;DR: SketchConcept是一个设计支持工具，通过分解设计概念为视觉和功能部分，结合草图与文本描述，利用多模态生成式AI实现功能到视觉的映射。


<details>
  <summary>Details</summary>
Motivation: 传统草图设计工具主要关注视觉设计，缺乏对功能概念的探索支持。

Method: 提出功能到视觉的映射工作流，利用大型语言模型生成功能描述，并通过图像生成AI生成概念组件。

Result: 通过多模态生成式AI分解、生成和编辑设计概念，满足整体功能需求。

Conclusion: 用户研究验证了系统的有效性和可用性。

Abstract: Conceptual product design requires designers to explore the design space of
visual and functional concepts simultaneously. Sketching has long been adopted
to empower concept exploration. However, current sketch-based design tools
mostly emphasize visual design using emerging techniques. We present
SketchConcept, a design support tool that decomposes design concepts into
visual representations and functionality of concepts using sketches and textual
descriptions. We propose a function-to-visual mapping workflow that maps the
function descriptions generated by a Large Language Model to a component of the
concept produced by image Generative Artificial Intelligence(GenAI). The
function-to-visual mapping allows our system to leverage multimodal GenAI to
decompose, generate, and edit the design concept to satisfy the overall
function and behavior. We present multiple use cases enabled by SketchConcept
to validate the workflow. Finally, we evaluated the efficacy and usability of
our system with a two-session user study.

</details>


### [257] [Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI](https://arxiv.org/abs/2508.07183)
*Ahmed M. Abuzuraiq,Philippe Pasquier*

Main category: cs.HC

TL;DR: 论文探讨了可解释AI（XAI）在创意场景中的应用，提出了一种基于手工操作的方法，通过暴露和操作大型生成模型的内部结构，支持艺术家的创作实践。


<details>
  <summary>Details</summary>
Motivation: 在创意领域，大型生成模型（如文本到图像扩散系统）通常缺乏透明度和可控性，限制了艺术家的参与和修改能力。研究旨在通过可解释性方法增强艺术家对模型的控制和直觉理解。

Method: 提出了一种基于手工操作的可解释性方法，结合Schön的“反思性实践”理论，开发了一个模型弯曲和检查插件，集成到ComfyUI的节点界面中，支持艺术家交互式操作模型组件。

Result: 通过交互式操作生成模型的不同部分，艺术家能够直观理解每个组件对输出的影响，从而增强创作控制力。

Conclusion: 研究表明，通过暴露和操作大型生成模型的内部结构，可以将其转化为创意材料，支持艺术家的长期实践和直觉发展。

Abstract: Explainable AI (XAI) in creative contexts can go beyond transparency to
support artistic engagement, modifiability, and sustained practice. While
curated datasets and training human-scale models can offer artists greater
agency and control, large-scale generative models like text-to-image diffusion
systems often obscure these possibilities. We suggest that even large models
can be treated as creative materials if their internal structure is exposed and
manipulable. We propose a craft-based approach to explainability rooted in
long-term, hands-on engagement akin to Sch\"on's "reflection-in-action" and
demonstrate its application through a model-bending and inspection plugin
integrated into the node-based interface of ComfyUI. We demonstrate that by
interactively manipulating different parts of a generative model, artists can
develop an intuition about how each component influences the output.

</details>


### [258] [Civil Servants as Builders: Enabling Non-IT Staff to Develop Secure Python and R Tools](https://arxiv.org/abs/2508.07203)
*Prashant Sharma*

Main category: cs.HC

TL;DR: 本文提出了一种开源平台，支持非IT角色的公务员在政府网络中安全地开发和部署代码，填补了现有文献的空白。


<details>
  <summary>Details</summary>
Motivation: 现有数字政府文献忽视了具备编程能力但缺乏正式IT支持的公务员群体，本文旨在解决这一缺口。

Method: 结合Jupyter Notebooks、预批准的开源库和轻量级治理，设计了一个沙盒化、可审计的工作流平台。

Result: 该平台在遵守采购规则和IT安全政策的同时，避免了供应商锁定，并提升了公务员的技术竞争力。

Conclusion: 本文为公共部门技能保留、韧性和自下而上的数字化转型提供了可复制的模型。

Abstract: Current digital government literature focuses on professional in-house IT
teams, specialized digital service teams, vendor-developed systems, or
proprietary low-code/no-code tools. Almost no scholarship addresses a growing
middle ground: technically skilled civil servants outside formal IT roles who
can write real code but lack a sanctioned, secure path to deploy their work.
This paper introduces a limits-aware, open-source and replicable platform that
enables such public servants to develop, peer review, and deploy small-scale,
domain-specific applications within government networks via a sandboxed,
auditable workflow. By combining Jupyter Notebooks, preapproved open-source
libraries, and lightweight governance, the platform works within institutional
constraints such as procurement rules and IT security policies while avoiding
vendor lock-in. Unlike low/no-code approaches, it preserves and enhances civil
servants' programming skills, keeping them technically competitive with their
private-sector peers. This contribution fills a critical gap, offering a
replicable model for public-sector skill retention, resilience, and bottom-up
digital transformation.

</details>


### [259] [Exploring Micro Accidents and Driver Responses in Automated Driving: Insights from Real-world Videos](https://arxiv.org/abs/2508.07256)
*Wei Xiang,Chuyue Zhang,Jie Yan*

Main category: cs.HC

TL;DR: 论文研究了自动驾驶中未被充分探索的“微事故”（如突然减速或蛇形驾驶），通过机器学习分析环境与自动驾驶代理的关键变量，并结合众包方法了解人类风险感知与反应。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶3级虽减轻了驾驶员负担，但引入了新的复杂性，尤其是微事故可能引发更严重事故。

Method: 收集用户生成的微事故视频数据集，用机器学习定位关键变量，并通过众包分析人类风险感知与反应。

Result: 识别了非致命但安全关键的场景特征，为自动驾驶系统设计提供新见解。

Conclusion: 研究揭示了微事故的重要性，有助于改进自动驾驶系统的安全性设计。

Abstract: Automated driving in level 3 autonomy has been adopted by multiple companies
such as Tesla and BMW, alleviating the burden on drivers while unveiling new
complexities. This article focused on the under-explored territory of micro
accidents during automated driving, characterized as not fatal but abnormal
aberrations such as abrupt deceleration and snake driving. These micro
accidents are basic yet pervasive events that might results in more severe
accidents. Through collecting a comprehensive dataset of user generated video
recording such micro accidents in natural driving scenarios, this article
locates key variables pertaining to environments and autonomous agents using
machine learning methods. Subsequently, crowdsourcing method provides insights
into human risk perceptions and reactions to these micro accidents. This
article thus describes features of safety critical scenarios other than crashes
and fatal accidents, informing and potentially advancing the design of
automated driving systems.

</details>


### [260] [Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment](https://arxiv.org/abs/2508.07283)
*Bujar Raufi*

Main category: cs.HC

TL;DR: 研究结合EEG微状态和LLMs，通过微调LLMs提升对认知负荷状态的预测能力，实验分为四个阶段，结果显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 探索EEG微状态与LLMs的结合，以改进对认知负荷状态的评估，推动认知神经科学和认知AI的发展。

Method: 分为四个阶段：数据集收集与预处理、微状态分割与EEG回拟合、特征提取与提示工程、LLM模型选择与微调。

Result: 微调后模型性能显著提升，能准确区分认知负荷状态。

Conclusion: 该方法不仅深化了对脑动力学的理解，还为认知负荷和认知AI研究的机器学习技术提供了新方向。

Abstract: This study explores the intersection of electroencephalography (EEG)
microstates and Large Language Models (LLMs) to enhance the assessment of
cognitive load states. By utilizing EEG microstate features, the research aims
to fine-tune LLMs for improved predictions of distinct cognitive states,
specifically 'Rest' and 'Load'. The experimental design is delineated in four
comprehensive stages: dataset collection and preprocessing, microstate
segmentation and EEG backfitting, feature extraction paired with prompt
engineering, and meticulous LLM model selection and refinement. Employing a
supervised learning paradigm, the LLM is trained to identify cognitive load
states based on EEG microstate features integrated into prompts, producing
accurate discrimination of cognitive load. A curated dataset, linking EEG
features to specified cognitive load conditions, underpins the experimental
framework. The results indicate a significant improvement in model performance
following the proposed fine-tuning, showcasing the potential of EEG-informed
LLMs in cognitive neuroscience and cognitive AI applications. This approach not
only contributes to the understanding of brain dynamics but also paves the way
for advancements in machine learning techniques applicable to cognitive load
and cognitive AI research.

</details>


### [261] [In-person, Online and Back Again -- A Tale of Three Hybrid Hackathons](https://arxiv.org/abs/2508.07301)
*Abasi-amefon Obot Affia-Jomants,Alexander Serebrenik,James D. Herbsleb,Alexander Nolte*

Main category: cs.HC

TL;DR: 研究探讨混合黑客松的组织和参与挑战，分析同步性、物理分布等关键维度，并提出实践建议。


<details>
  <summary>Details</summary>
Motivation: 混合黑客松的研究分散，现有策略未能解决其独特挑战，如跨空间沟通。

Method: 基于混合协作理论，通过三个黑客松案例研究关键维度的实施与影响。

Result: 不同组织风格导致参与者体验差异，技术使用存在不足，参与者需自行调整策略。

Conclusion: 提出组织者和参与者的实践建议，以优化混合黑客松的设计和参与体验。

Abstract: Hybrid hackathons, which combine in-person and online participation, present
unique challenges for organizers and participants. Although such events are
increasingly conducted, research on them remains fragmented, with limited
integration between hackathon studies and hybrid collaboration. Existing
strategies for in-person or online-only events often fail to address the unique
challenges of hybrid formats, such as managing communication across physical
and virtual spaces. Our work addresses this gap by examining how hybrid
hackathons function, analyzing how organizers structure these events and how
participants navigate hybrid-specific challenges. Drawing on established
theories of hybrid collaboration, we examine key dimensions - synchronicity,
physical distribution, dynamic transitions, and technological infrastructure -
that shape collaboration in hybrid events. Through an exploratory case study of
three hackathon events, we analyze how these dimensions are implemented and
their effects on participant experiences. Our findings reveal differing
organizer considerations of the hybrid dimensions in the hackathon design,
leading to distinct experiences for participants. Implementation styles -
favoring in-person, online, or balanced participation - led to varied
participant experiences, affecting access to resources, communication, and team
coordination. Organizers in our study also relied on technology to bridge
hybrid interactions, but overlooked critical aspects like time-zone management,
dynamic transitions, and targeted support for hybrid teams. Additionally,
participants in their teams responded to gaps in event scaffolding by adapting
collaboration strategies, revealing gaps in organizers' preparedness for hybrid
events. Learning from our findings, we offer practical recommendations when
organizing hybrid hackathon events and recommendations to participants when
attending them.

</details>


### [262] [Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics](https://arxiv.org/abs/2508.07390)
*Gustavo Moreira,Leonardo Ferreira,Carolina Veiga,Maryam Hosseini,Fabio Miranda*

Main category: cs.HC

TL;DR: Urbanite是一个基于人机协作的城市可视化分析框架，旨在降低数据分析的门槛，通过意图驱动的交互方式简化复杂的数据分析流程。


<details>
  <summary>Details</summary>
Motivation: 随着城市数据的增长和社会挑战的复杂性增加，数据分析变得至关重要，但多领域专业知识和复杂工作流程的高门槛限制了非技术用户的使用。

Method: Urbanite采用基于数据流的模型，支持用户在多个范围内指定意图，并提供交互式对齐功能，涵盖分析的设计、执行和评估阶段。

Result: 通过与城市专家的合作，Urbanite展示了其在任务定义、解释性和交互溯源方面的有效性。

Conclusion: Urbanite通过意图驱动的交互和协作机制，为城市数据分析提供了高效且易用的解决方案。

Abstract: With the growing availability of urban data and the increasing complexity of
societal challenges, visual analytics has become essential for deriving
insights into pressing real-world problems. However, analyzing such data is
inherently complex and iterative, requiring expertise across multiple domains.
The need to manage diverse datasets, distill intricate workflows, and integrate
various analytical methods presents a high barrier to entry, especially for
researchers and urban experts who lack proficiency in data management, machine
learning, and visualization. Advancements in large language models offer a
promising solution to lower the barriers to the construction of analytics
systems by enabling users to specify intent rather than define precise
computational operations. However, this shift from explicit operations to
intent-based interaction introduces challenges in ensuring alignment throughout
the design and development process. Without proper mechanisms, gaps can emerge
between user intent, system behavior, and analytical outcomes. To address these
challenges, we propose Urbanite, a framework for human-AI collaboration in
urban visual analytics. Urbanite leverages a dataflow-based model that allows
users to specify intent at multiple scopes, enabling interactive alignment
across the specification, process, and evaluation stages of urban analytics.
Based on findings from a survey to uncover challenges, Urbanite incorporates
features to facilitate explainability, multi-resolution definition of tasks
across dataflows, nodes, and parameters, while supporting the provenance of
interactions. We demonstrate Urbanite's effectiveness through usage scenarios
created in collaboration with urban experts. Urbanite is available at
https://urbantk.org/urbanite.

</details>


### [263] [StreetWeave: A Declarative Grammar for Street-Overlaid Visualization of Multivariate Data](https://arxiv.org/abs/2508.07496)
*Sanjana Srabanti,G. Elisabeta Marai,Fabio Miranda*

Main category: cs.HC

TL;DR: 论文提出了StreetWeave，一种用于多变量空间网络数据可视化的声明式语法，解决了现有街道和行人网络可视化缺乏统一设计框架的问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏统一的设计框架，不同领域的专家在可视化街道和行人网络时面临数据整合和探索的复杂性，尤其是非编程背景的专家。

Method: 通过定性编码分析45项研究，总结了街道和行人网络可视化的用途、方法和数据来源，并基于此提出了StreetWeave语法。

Result: StreetWeave能够支持多分辨率下的多变量空间网络数据可视化，帮助专家更高效地探索和分析数据。

Conclusion: StreetWeave为街道和行人网络可视化提供了一种灵活且易于使用的设计工具，降低了技术门槛，促进了跨领域的应用。

Abstract: The visualization and analysis of street and pedestrian networks are
important to various domain experts, including urban planners, climate
researchers, and health experts. This has led to the development of new
techniques for street and pedestrian network visualization, expanding how data
can be shown and understood more effectively. Despite their increasing
adoption, there is no established design framework to guide the creation of
these visualizations while addressing the diverse requirements of various
domains. When exploring a feature of interest, domain experts often need to
transform, integrate, and visualize a combination of thematic data (e.g.,
demographic, socioeconomic, pollution) and physical data (e.g., zip codes,
street networks), often spanning multiple spatial and temporal scales. This not
only complicates the process of visual data exploration and system
implementation for developers but also creates significant entry barriers for
experts who lack a background in programming. With this in mind, in this paper,
we reviewed 45 studies utilizing street-overlaid visualizations to understand
how they are used. Through qualitative coding of these visualizations, we
analyzed three key aspects of street and pedestrian network visualization
usage: the analytical purpose they serve, the visualization approaches
employed, and the data sources used in their creation. Building on this design
space, we introduce StreetWeave, a declarative grammar for designing custom
visualizations of multivariate spatial network data across multiple
resolutions. We demonstrate how StreetWeave can be used to create various
street-overlaid visualizations, enabling effective exploration and analysis of
spatial data. StreetWeave is available at https://urbantk.org/streetweave.

</details>


### [264] [VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design](https://arxiv.org/abs/2508.07497)
*Leonardo Ferreira,Gustavo Moreira,Fabio Miranda*

Main category: cs.HC

TL;DR: 论文提出VA-Blueprint方法，通过系统化分类城市VA系统的基本构建模块，填补了VA系统开发中结构化知识库的空白，并利用大语言模型扩展知识库。


<details>
  <summary>Details</summary>
Motivation: 尽管VA系统的数量不断增加，但其设计和开发缺乏结构化知识库的指导，导致开发过程面临挑战。

Method: 提出VA-Blueprint方法，系统化分类城市VA系统的核心组件，并利用大语言模型自动化提取组件信息。

Result: 构建了包含101篇论文的知识库，并通过专家访谈和定量分析验证了方法的有效性。

Conclusion: VA-Blueprint为VA系统的开发提供了结构化、可复现和高效的基础，并加深了对VA系统组成的理解。

Abstract: Designing and building visual analytics (VA) systems is a complex, iterative
process that requires the seamless integration of data processing, analytics
capabilities, and visualization techniques. While prior research has
extensively examined the social and collaborative aspects of VA system
authoring, the practical challenges of developing these systems remain
underexplored. As a result, despite the growing number of VA systems, there are
only a few structured knowledge bases to guide their design and development. To
tackle this gap, we propose VA-Blueprint, a methodology and knowledge base that
systematically reviews and categorizes the fundamental building blocks of urban
VA systems, a domain particularly rich and representative due to its intricate
data and unique problem sets. Applying this methodology to an initial set of 20
systems, we identify and organize their core components into a multi-level
structure, forming an initial knowledge base with a structured blueprint for VA
system development. To scale this effort, we leverage a large language model to
automate the extraction of these components for other 81 papers (completing a
corpus of 101 papers), assessing its effectiveness in scaling knowledge base
construction. We evaluate our method through interviews with experts and a
quantitative analysis of annotation metrics. Our contributions provide a deeper
understanding of VA systems' composition and establish a practical foundation
to support more structured, reproducible, and efficient system development.
VA-Blueprint is available at https://urbantk.org/va-blueprint.

</details>


### [265] [Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI](https://arxiv.org/abs/2508.07520)
*Baihan Lin*

Main category: cs.HC

TL;DR: 论文提出了一种名为'对话DNA'的可视化语言，通过生物隐喻揭示对话的时空结构，超越了传统统计分析方法。


<details>
  <summary>Details</summary>
Motivation: 探索对话中隐藏的模式是否能比文字本身更深入地揭示沟通的本质，尤其是在人类与AI对话日益增多的背景下。

Method: 采用生物隐喻（如DNA结构）设计可视化语言，通过线条粗细、颜色渐变等元素表示对话的复杂性、情感轨迹和话题连贯性。

Result: 通过对治疗性对话和历史性人机对话的分析，该方法揭示了传统方法无法捕捉的交互模式。

Conclusion: 该研究为理解沟通提供了一个新的创造性框架，结合了数据可视化、人机交互和对话意义的本质问题。

Abstract: What if the patterns hidden within dialogue reveal more about communication
than the words themselves? We introduce Conversational DNA, a novel visual
language that treats any dialogue -- whether between humans, between human and
AI, or among groups -- as a living system with interpretable structure that can
be visualized, compared, and understood. Unlike traditional conversation
analysis that reduces rich interaction to statistical summaries, our approach
reveals the temporal architecture of dialogue through biological metaphors.
Linguistic complexity flows through strand thickness, emotional trajectories
cascade through color gradients, conversational relevance forms through
connecting elements, and topic coherence maintains structural integrity through
helical patterns. Through exploratory analysis of therapeutic conversations and
historically significant human-AI dialogues, we demonstrate how this
visualization approach reveals interaction patterns that traditional methods
miss. Our work contributes a new creative framework for understanding
communication that bridges data visualization, human-computer interaction, and
the fundamental question of what makes dialogue meaningful in an age where
humans increasingly converse with artificial minds.

</details>


### [266] [Phoenix: A Novel Context-Aware Voice-Powered Math Equation Workspace and Editor](https://arxiv.org/abs/2508.07576)
*Kenneth Ge,Ryan Paul,Priscilla Zhang,JooYoung Seo*

Main category: cs.HC

TL;DR: 论文提出了一种基于语音的数学工作空间，利用神经科学和大语言模型，为精细运动障碍者提供更自然的数学交互方式。


<details>
  <summary>Details</summary>
Motivation: 传统语音数学技术依赖精确的符号输入和命令式界面，增加了认知负担，尤其是对精细运动障碍者。

Method: 结合神经科学和大语言模型，开发了上下文引擎，支持自然语言交互。

Result: 实现了对精细运动障碍者更流畅的数学表达和问题解决能力。

Conclusion: 该工作空间解放了机械限制，提升了数学学习的无障碍性。

Abstract: Writing mathematical notation requires substantial effort, diverting
cognitive resources from conceptual understanding to documentation mechanics,
significantly impacting individuals with fine motor disabilities (FMDs).
Current limits of speech-based math technologies rely on precise dictation of
math symbols and unintuitive command-based interfaces. We present a novel
voice-powered math workspace, applying neuroscience insights to create an
intuitive problem-solving environment. To minimize cognitive load, we leverage
large language models with our novel context engine to support natural language
interaction. Ultimately, we enable fluid mathematical engagement for
individuals with FMDs -- freed from mechanical constraints.

</details>


### [267] [On the Limits of Selective AI Prediction: A Case Study in Clinical Decision Making](https://arxiv.org/abs/2508.07617)
*Sarah Jabbour,David Fouhey,Nikola Banovic,Stephanie D. Shepard,Ella Kazerooni,Michael W. Sjoding,Jenna Wiens*

Main category: cs.HC

TL;DR: 选择性预测可以减轻AI不准确预测对决策的负面影响，但会改变错误模式，导致漏诊和漏治增加。


<details>
  <summary>Details</summary>
Motivation: 研究选择性预测是否能让人类在AI不提供预测时做出与无AI辅助时相同的决策。

Method: 对259名临床医生进行用户研究，比较无AI辅助、AI辅助及选择性预测下的诊断和治疗准确性。

Result: 选择性预测恢复了决策准确性（64% vs. 无AI的66%），但漏诊和漏治分别增加了18%和35%。

Conclusion: 需实证验证人类与AI交互的假设，选择性预测虽有效但需注意其副作用。

Abstract: AI has the potential to augment human decision making. However, even
high-performing models can produce inaccurate predictions when deployed. These
inaccuracies, combined with automation bias, where humans overrely on AI
predictions, can result in worse decisions. Selective prediction, in which
potentially unreliable model predictions are hidden from users, has been
proposed as a solution. This approach assumes that when AI abstains and informs
the user so, humans make decisions as they would without AI involvement. To
test this assumption, we study the effects of selective prediction on human
decisions in a clinical context. We conducted a user study of 259 clinicians
tasked with diagnosing and treating hospitalized patients. We compared their
baseline performance without any AI involvement to their AI-assisted accuracy
with and without selective prediction. Our findings indicate that selective
prediction mitigates the negative effects of inaccurate AI in terms of decision
accuracy. Compared to no AI assistance, clinician accuracy declined when shown
inaccurate AI predictions (66% [95% CI: 56%-75%] vs. 56% [95% CI: 46%-66%]),
but recovered under selective prediction (64% [95% CI: 54%-73%]). However,
while selective prediction nearly maintains overall accuracy, our results
suggest that it alters patterns of mistakes: when informed the AI abstains,
clinicians underdiagnose (18% increase in missed diagnoses) and undertreat (35%
increase in missed treatments) compared to no AI input at all. Our findings
underscore the importance of empirically validating assumptions about how
humans engage with AI within human-AI systems.

</details>


### [268] [Are UX evaluation methods truly accessible](https://arxiv.org/abs/2508.07620)
*Andrés Eduardo Fuentes-Cortázar,Alejandra Rivera-Hernández,José Rafael Rojano-Cáceres*

Main category: cs.HC

TL;DR: 研究分析了针对聋人用户的用户体验（UX）评估方法，发现传统方法存在显著障碍，需改进以确保真正的无障碍性。


<details>
  <summary>Details</summary>
Motivation: 为聋人提供公平和包容的UX是无障碍设计的核心目标，但传统评估方法未充分考虑其特定需求。

Method: 通过文献综述和实际应用，分析并验证了针对聋人的UX评估方法的可访问性。

Result: 传统方法依赖听觉和认知能力，对聋人用户存在障碍，导致数据收集不准确。

Conclusion: 需改进UX评估方法，以满足聋人群体的沟通和认知需求，准确反映其用户体验。

Abstract: Providing an equitable and inclusive user experience (UX) for people with
disabilities (PWD) is a central goal of accessible design. In the specific case
of Deaf users, whose hearing impairments impact language development and
communication, it is essential to consider their specific needs during software
evaluation processes. This study aimed to analyze a set of UX evaluation
methods suggested in the literature as suitable for Deaf individuals, with the
goal of validating their level of accessibility in real-world contexts. The
research was based on a critical review and practical application of these
methods, identifying their strengths and limitations in relation to the
interaction, perception, and comprehension of Deaf users. Traditional
evaluation instruments, commonly designed for hearing individuals, pose
significant barriers when applied to Deaf users due to their re-liance on
auditory and cognitive abilities, as well as the lack of consideration for
commu-nicational accessibility. The results show that although these methods
are frequently rec-ommended, they exhibit critical shortcomings that hinder the
collection of accurate and representative data. It is concluded that it is
essential to adapt UX evaluation methods to ensure genuinely accessible
processes that address the communicative and cognitive needs of the Deaf
community and accurately reflect their user experience.

</details>


### [269] [Through Their Eyes: User Perceptions on Sensitive Attribute Inference of Social Media Videos by Visual Language Models](https://arxiv.org/abs/2508.07658)
*Shuning Zhang,Gengrui Zhang,Yibo Meng,Ziyi Zhang,Hantao Zhao,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: 研究通过半结构化访谈（N=17）探讨用户对视觉语言模型（VLMs）推断敏感属性的看法，发现用户担忧隐私风险，并提出对平台和监管的期望。


<details>
  <summary>Details</summary>
Motivation: 填补用户对VLM推断敏感属性的理解和反应的空白，尤其是在社交媒体视频领域。

Method: 采用半结构化访谈（N=17）调查用户对VLM推断视觉数据中敏感属性的看法。

Result: 用户认为VLMs能高精度推断多种敏感属性，担忧隐私风险，并提出对透明度和控制的期望。

Conclusion: 研究为开发负责任AI、隐私增强技术和政策制定提供了重要依据。

Abstract: The rapid advancement of Visual Language Models (VLMs) has enabled
sophisticated analysis of visual content, leading to concerns about the
inference of sensitive user attributes and subsequent privacy risks. While
technical capabilities of VLMs are increasingly studied, users' understanding,
perceptions, and reactions to these inferences remain less explored, especially
concerning videos uploaded on the social media. This paper addresses this gap
through a semi-structured interview (N=17), investigating user perspectives on
VLM-driven sensitive attribute inference from their visual data. Findings
reveal that users perceive VLMs as capable of inferring a range of attributes,
including location, demographics, and socioeconomic indicators, often with
unsettling accuracy. Key concerns include unauthorized identification, misuse
of personal information, pervasive surveillance, and harm from inaccurate
inferences. Participants reported employing various mitigation strategies,
though with skepticism about their ultimate effectiveness against advanced AI.
Users also articulate clear expectations for platforms and regulators,
emphasizing the need for enhanced transparency, user control, and proactive
privacy safeguards. These insights are crucial for guiding the development of
responsible AI systems, effective privacy-enhancing technologies, and informed
policymaking that aligns with user expectations and societal values.

</details>


### [270] [Understanding Users' Privacy Perceptions Towards LLM's RAG-based Memory](https://arxiv.org/abs/2508.07664)
*Shuning Zhang,Rongjun Ma,Ying Ma,Shixuan Li,Yiqun Xu,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: 研究探讨了用户对LLM记忆功能的理解、实践和期望，发现用户对记忆系统的认知不完整，关注隐私和控制问题，并希望更透明的设计。


<details>
  <summary>Details</summary>
Motivation: 了解用户对LLM记忆功能的认知、使用习惯及期望，以设计更透明和用户友好的系统。

Method: 对18名用户进行半结构化访谈，进行主题分析。

Result: 用户对记忆功能的认知多样但不完整，关注隐私和控制，希望更透明的管理机制。

Conclusion: 设计LLM记忆系统需更注重用户中心、透明性和信任度。

Abstract: Large Language Models (LLMs) are increasingly integrating memory
functionalities to provide personalized and context-aware interactions.
However, user understanding, practices and expectations regarding these memory
systems are not yet well understood. This paper presents a thematic analysis of
semi-structured interviews with 18 users to explore their mental models of
LLM's Retrieval Augmented Generation (RAG)-based memory, current usage
practices, perceived benefits and drawbacks, privacy concerns and expectations
for future memory systems. Our findings reveal diverse and often incomplete
mental models of how memory operates. While users appreciate the potential for
enhanced personalization and efficiency, significant concerns exist regarding
privacy, control and the accuracy of remembered information. Users express a
desire for granular control over memory generation, management, usage and
updating, including clear mechanisms for reviewing, editing, deleting and
categorizing memories, as well as transparent insight into how memories and
inferred information are used. We discuss design implications for creating more
user-centric, transparent, and trustworthy LLM memory systems.

</details>


### [271] [Towards Aligning Personalized Conversational Recommendation Agents with Users' Privacy Preferences](https://arxiv.org/abs/2508.07672)
*Shuning Zhang,Ying Ma,Jingruo Chen,Simin Li,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: 论文认为传统隐私管理模式不适用于动态交互的AI代理，提出了一种基于情境完整性和隐私计算理论的框架，通过主动学习用户偏好来优化隐私保护。


<details>
  <summary>Details</summary>
Motivation: 当前隐私管理模式基于用户对被动工具的单向控制，与AI代理的动态交互特性不匹配，需要AI代理主动适应用户隐私偏好。

Method: 提出基于情境完整性（CI）和隐私计算理论的框架，通过隐式或显式反馈学习用户偏好，并利用对齐和帕累托优化平衡隐私与效用。

Result: 框架将隐私控制重新定义为对齐问题，并提出了具体实现、潜在应用及五个挑战。

Conclusion: AI代理需主动适应用户隐私偏好，提出的框架为解决动态交互环境中的隐私保护问题提供了新思路。

Abstract: The proliferation of AI agents, with their complex and context-dependent
actions, renders conventional privacy paradigms obsolete. This position paper
argues that the current model of privacy management, rooted in a user's
unilateral control over a passive tool, is inherently mismatched with the
dynamic and interactive nature of AI agents. We contend that ensuring effective
privacy protection necessitates that the agents proactively align with users'
privacy preferences instead of passively waiting for the user to control. To
ground this shift, and using personalized conversational recommendation agents
as a case, we propose a conceptual framework built on Contextual Integrity (CI)
theory and Privacy Calculus theory. This synthesis first reframes automatically
controlling users' privacy as an alignment problem, where AI agents initially
did not know users' preferences, and would learn their privacy preferences
through implicit or explicit feedback. Upon receiving the preference feedback,
the agents used alignment and Pareto optimization for aligning preferences and
balancing privacy and utility. We introduced formulations and instantiations,
potential applications, as well as five challenges.

</details>


### [272] [Improving Continuous Grasp Force Decoding from EEG with Time-Frequency Regressors and Premotor-Parietal Network Integration](https://arxiv.org/abs/2508.07677)
*Parth G. Dangi,Yogesh Kumar Meena*

Main category: cs.HC

TL;DR: EEGForceMap方法通过提取特定任务信号和改进特征集，显著提升了脑机接口对连续握力的解码能力。


<details>
  <summary>Details</summary>
Motivation: 当前脑机接口在解码连续握力时存在局限性，缺乏对神经生理学机制的深入整合，影响了精细运动任务的效果。

Method: 提出EEGForceMap方法，提取运动前区-顶叶信号并构建三种时频特征集，结合线性、非线性和深度学习回归器进行预测。

Result: 在WAY-EEG-GAL数据集上，EEGForceMap方法在特定和非特定条件下分别提升了61.7%和55.7%的解码性能。

Conclusion: EEGForceMap为脑机接口在康复和辅助机器人中的应用提供了更有效的动态握力解码方案。

Abstract: Brain-machine interfaces (BMIs) have significantly advanced
neuro-rehabilitation by enhancing motor control. However, accurately decoding
continuous grasp force remains a challenge, limiting the effectiveness of BMI
applications for fine motor tasks. Current models tend to prioritise
algorithmic complexity rather than incorporating neurophysiological insights
into force control, which is essential for developing effective neural
engineering solutions. To address this, we propose EEGForceMap, an EEG-based
methodology that isolates signals from the premotor-parietal region and
extracts task-specific components. We construct three distinct time-frequency
feature sets, which are validated by comparing them with prior studies, and use
them for force prediction with linear, non-linear, and deep learning-based
regressors. The performance of these regressors was evaluated on the
WAY-EEG-GAL dataset that includes 12 subjects. Our results show that
integrating EEGForceMap approach with regressor models yields a 61.7%
improvement in subject-specific conditions (R-squared = 0.815) and a 55.7%
improvement in subject-independent conditions (R-squared = 0.785) over the
state-of-the-art kinematic decoder models. Furthermore, an ablation study
confirms that each preprocessing step significantly enhances decoding accuracy.
This work contributes to the advancement of responsive BMIs for stroke
rehabilitation and assistive robotics by improving EEG-based decoding of
dynamic grasp force.

</details>


### [273] [SimViews: An Interactive Multi-Agent System Simulating Visitor-to-Visitor Conversational Patterns to Present Diverse Perspectives of Artifacts in Virtual Museums](https://arxiv.org/abs/2508.07730)
*Mingyang Su,Chao Liu,Jingling Zhang,WU Shuang,Mingming Fan*

Main category: cs.HC

TL;DR: SimViews是一个基于LLM的多代理系统，通过模拟访客对话模式，在虚拟博物馆中展示多样视角，提升访客理解和参与度。


<details>
  <summary>Details</summary>
Motivation: 虚拟博物馆中如何恰当展示多样视角并保持访客注意力是一个挑战。

Method: 利用LLM驱动的多代理模拟不同身份的虚拟访客，构建4种对话模式模拟互动。

Result: 实验显示SimViews能有效促进多样视角展示，提升参与者理解和参与度。

Conclusion: SimViews通过多代理对话模式成功解决了虚拟博物馆中多样视角展示的问题。

Abstract: Offering diverse perspectives on a museum artifact can deepen visitors'
understanding and help avoid the cognitive limitations of a single narrative,
ultimately enhancing their overall experience. Physical museums promote
diversity through visitor interactions. However, it remains a challenge to
present multiple voices appropriately while attracting and sustaining a
visitor's attention in the virtual museum. Inspired by recent studies that show
the effectiveness of LLM-powered multi-agents in presenting different opinions
about an event, we propose SimViews, an interactive multi-agent system that
simulates visitor-to-visitor conversational patterns to promote the
presentation of diverse perspectives. The system employs LLM-powered
multi-agents that simulate virtual visitors with different professional
identities, providing diverse interpretations of artifacts. Additionally, we
constructed 4 conversational patterns between users and agents to simulate
visitor interactions. We conducted a within-subject study with 20 participants,
comparing SimViews to a traditional single-agent condition. Our results show
that SimViews effectively facilitates the presentation of diverse perspectives
through conversations, enhancing participants' understanding of viewpoints and
engagement within the virtual museum.

</details>


### [274] [CognitiveArm: Enabling Real-Time EEG-Controlled Prosthetic Arm Using Embodied Machine Learning](https://arxiv.org/abs/2508.07731)
*Abdul Basit,Maha Nawaz,Saim Rehman,Muhammad Shafique*

Main category: cs.HC

TL;DR: CognitiveArm是一个基于脑电图的实时脑控假肢系统，通过优化的深度学习模型和嵌入式AI硬件实现高效控制。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限设备上实现高效、低延迟的脑机接口控制的挑战。

Method: 结合BrainFlow库和优化的深度学习模型，利用进化搜索和模型压缩技术（如剪枝和量化）实现高效部署。

Result: 系统在嵌入式硬件上运行，分类三种核心动作的准确率达90%，并支持语音命令切换模式。

Conclusion: CognitiveArm展示了在高级假肢控制中的潜力，具有低延迟和实时响应能力。

Abstract: Efficient control of prosthetic limbs via non-invasive brain-computer
interfaces (BCIs) requires advanced EEG processing, including pre-filtering,
feature extraction, and action prediction, performed in real time on edge AI
hardware. Achieving this on resource-constrained devices presents challenges in
balancing model complexity, computational efficiency, and latency. We present
CognitiveArm, an EEG-driven, brain-controlled prosthetic system implemented on
embedded AI hardware, achieving real-time operation without compromising
accuracy. The system integrates BrainFlow, an open-source library for EEG data
acquisition and streaming, with optimized deep learning (DL) models for precise
brain signal classification. Using evolutionary search, we identify
Pareto-optimal DL configurations through hyperparameter tuning, optimizer
analysis, and window selection, analyzed individually and in ensemble
configurations. We apply model compression techniques such as pruning and
quantization to optimize models for embedded deployment, balancing efficiency
and accuracy. We collected an EEG dataset and designed an annotation pipeline
enabling precise labeling of brain signals corresponding to specific intended
actions, forming the basis for training our optimized DL models. CognitiveArm
also supports voice commands for seamless mode switching, enabling control of
the prosthetic arm's 3 degrees of freedom (DoF). Running entirely on embedded
hardware, it ensures low latency and real-time responsiveness. A full-scale
prototype, interfaced with the OpenBCI UltraCortex Mark IV EEG headset,
achieved up to 90% accuracy in classifying three core actions (left, right,
idle). Voice integration enables multiplexed, variable movement for everyday
tasks (e.g., handshake, cup picking), enhancing real-world performance and
demonstrating CognitiveArm's potential for advanced prosthetic control.

</details>


### [275] [Challenges in Mixed Reality in Assisting Adults with ADHD Symptoms](https://arxiv.org/abs/2508.07854)
*Valerie Tan,Jens Gerken*

Main category: cs.HC

TL;DR: 探讨成人ADHD症状及混合现实治疗潜力，指出当前原型和研究不足。


<details>
  <summary>Details</summary>
Motivation: 研究混合现实在成人ADHD治疗中的潜力，填补现有解决方案的不足。

Method: 分析混合现实在成人ADHD治疗中的应用现状及挑战。

Result: 发现成人ADHD的混合现实解决方案有限，缺乏持续干预工具。

Conclusion: 需更多成人ADHD的混合现实原型和持续干预研究。

Abstract: In this position paper, we discuss symptoms of attention deficit
hyperactivity disorder (ADHD) in adults, as well as available forms of
treatment or assistance in the context of mixed reality. Mixed reality offers
many potentials for assisting adults with symptoms commonly found in (but not
limited to) ADHD, but the availability of mixed reality solutions is not only
limited commercially, but also limited in terms of proof-of-concept prototypes.
We discuss two major challenges with attention assistance using mixed reality
solutions: the limited availability of adult-specific prototypes and studies,
as well as the limited number of solutions that offer continuous intervention
of ADHD-like symptoms that users can employ in their daily life.

</details>


### [276] [Early Explorations of Recommender Systems for Physical Activity and Well-being](https://arxiv.org/abs/2508.07980)
*Alan Said*

Main category: cs.HC

TL;DR: 论文提出了一个关于有形推荐系统的概念框架，关注用户对身体、习惯和健康的反应，并探讨了信任、意图对齐和后果意识三个设计维度。


<details>
  <summary>Details</summary>
Motivation: 随着推荐系统通过可穿戴设备和教练工具指导用户行为，用户如何理解、信任和响应这些建议成为新挑战。

Method: 提出概念框架，通过信任与解释、意图对齐和后果意识三个设计维度分析问题，并结合案例和设计反思。

Result: 框架揭示了传统推荐逻辑在实体环境中的局限性，并指导未来系统支持长期健康、行为对齐和社会责任个性化。

Conclusion: 未来推荐系统需关注用户身体和健康，通过设计维度提升信任和行为对齐，实现更负责任的影响。

Abstract: As recommender systems increasingly guide physical actions, often through
wearables and coaching tools, new challenges arise around how users interpret,
trust, and respond to this advice. This paper introduces a conceptual framework
for tangible recommendations that influence users' bodies, routines, and
well-being. We describe three design dimensions: trust and interpretation,
intent alignment, and consequence awareness. These highlight key limitations in
applying conventional recommender logic to embodied settings. Through examples
and design reflections, we outline how future systems can support long-term
well-being, behavioral alignment, and socially responsible personalization.

</details>


### [277] [EchoAid: Enhancing Livestream Shopping Accessibility for the DHH Community](https://arxiv.org/abs/2508.08020)
*Zeyu Yang,Zheng Wei,Yang Zhang,Xian Xu,Changyang He,Muzhi Zhou,Pan Hui*

Main category: cs.HC

TL;DR: 论文提出了一款名为EchoAid的移动应用，旨在改善聋哑及听力障碍用户在直播购物中的体验，通过语音转文字、RSVP技术和LLM简化信息流。


<details>
  <summary>Details</summary>
Motivation: 直播购物平台常忽视聋哑及听力障碍用户的需求，导致信息获取困难和认知过载。

Method: 开发EchoAid应用，结合语音转文字、RSVP技术和LLM，并通过用户反馈迭代设计原型。

Result: 用户研究表明，EchoAid能有效提升产品信息提取效率，减少认知过载，提供更个性化的购物体验。

Conclusion: EchoAid成功验证了其设计，为聋哑及听力障碍用户提供了更便捷的直播购物解决方案。

Abstract: Livestream shopping platforms often overlook the accessibility needs of the
Deaf and Hard of Hearing (DHH) community, leading to barriers such as
information inaccessibility and overload. To tackle these challenges, we
developed \textit{EchoAid}, a mobile app designed to improve the livestream
shopping experience for DHH users. \textit{EchoAid} utilizes advanced
speech-to-text conversion, Rapid Serial Visual Presentation (RSVP) technology,
and Large Language Models (LLMs) to simplify the complex information flow in
live sales environments. We conducted exploratory studies with eight DHH
individuals to identify design needs and iteratively developed the
\textit{EchoAid} prototype based on feedback from three participants. We then
evaluate the performance of this system in a user study workshop involving 38
DHH participants. Our findings demonstrate the successful design and validation
process of \textit{EchoAid}, highlighting its potential to enhance product
information extraction, leading to reduced cognitive overload and more engaging
and customized shopping experiences for DHH users.

</details>


### [278] [ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience](https://arxiv.org/abs/2508.08101)
*Yeana Lee Bond,Mungyeong Choe,Baker Kasim Hasan,Arsh Siddiqui,Myounghoon Jeon*

Main category: cs.HC

TL;DR: 研究探讨了基于ChatGPT的车载对话代理在提升驾驶安全性和用户体验方面的潜力，结果显示其优于传统预设脚本代理。


<details>
  <summary>Details</summary>
Motivation: 传统车载对话代理依赖预设脚本或有限语音命令，限制了自然交互，研究旨在解决这一问题。

Method: 40名驾驶员在模拟驾驶环境中测试了三种条件（无代理、预设脚本代理、ChatGPT代理），并比较了驾驶性能和主观评价。

Result: ChatGPT代理在驾驶稳定性（纵向/横向加速度、车道偏离）和主观评价（能力、生动性、信任、偏好）上表现更优。

Conclusion: 基于大语言模型的车载对话代理能通过自然、多轮对话提升驾驶安全和用户体验。

Abstract: Studies on in-vehicle conversational agents have traditionally relied on
pre-scripted prompts or limited voice commands, constraining natural
driver-agent interaction. To resolve this issue, the present study explored the
potential of a ChatGPT-based in-vehicle agent capable of carrying continuous,
multi-turn dialogues. Forty drivers participated in our experiment using a
motion-based driving simulator, comparing three conditions (No agent,
Pre-scripted agent, and ChatGPT-based agent) as a within-subjects variable.
Results showed that the ChatGPT-based agent condition led to more stable
driving performance across multiple metrics. Participants demonstrated lower
variability in longitudinal acceleration, lateral acceleration, and lane
deviation compared to the other two conditions. In subjective evaluations, the
ChatGPT-based agent also received significantly higher ratings in competence,
animacy, affective trust, and preference compared to the Pre-scripted agent.
Our thematic analysis of driver-agent conversations revealed diverse
interaction patterns in topics, including driving assistance/questions,
entertainment requests, and anthropomorphic interactions. Our results highlight
the potential of LLM-powered in-vehicle conversational agents to enhance
driving safety and user experience through natural, context-rich interactions.

</details>


### [279] [Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration](https://arxiv.org/abs/2508.08128)
*Vladimir Zhurov,John Kausch,Kamran Sedig,Mostafa Milani*

Main category: cs.HC

TL;DR: FuzzyVis是一个结合模糊逻辑和可视化界面的系统，旨在帮助非专家用户直观地探索复杂本体。


<details>
  <summary>Details</summary>
Motivation: 解决非专家用户难以导航大型复杂本体的问题，同时弥补现有查询工具在灵活性和表达性上的不足。

Method: FuzzyVis整合了基于模糊逻辑的查询模型和交互式可视化界面，支持用户通过逻辑运算符组合概念，并利用模糊嵌入进行相似性搜索。

Result: 案例研究表明，FuzzyVis能够满足复杂信息需求，帮助用户在大型本体中发现相关概念。

Conclusion: FuzzyVis通过模糊语义和嵌入推理的结合，实现了灵活的解释、高效的计算和探索性学习。

Abstract: Ontologies play a central role in structuring knowledge across domains,
supporting tasks such as reasoning, data integration, and semantic search.
However, their large size and complexity, particularly in fields such as
biomedicine, computational biology, law, and engineering, make them difficult
for non-experts to navigate. Formal query languages such as SPARQL offer
expressive access but require users to understand the ontology's structure and
syntax. In contrast, visual exploration tools and basic keyword-based search
interfaces are easier to use but often lack flexibility and expressiveness. We
introduce FuzzyVis, a proof-of-concept system that enables intuitive and
expressive exploration of complex ontologies. FuzzyVis integrates two key
components: a fuzzy logic-based querying model built on fuzzy ontology
embeddings, and an interactive visual interface for building and interpreting
queries. Users can construct new composite concepts by selecting and combining
existing ontology concepts using logical operators such as conjunction,
disjunction, and negation. These composite concepts are matched against the
ontology using fuzzy membership-based embeddings, which capture degrees of
membership and support approximate, concept-level similarity search. The visual
interface supports browsing, query composition, and partial search without
requiring formal syntax. By combining fuzzy semantics with embedding-based
reasoning, FuzzyVis enables flexible interpretation, efficient computation, and
exploratory learning. Case studies demonstrate how FuzzyVis supports subtle
information needs and helps users uncover relevant concepts in large, complex
ontologies.

</details>


### [280] [Can AI Explanations Make You Change Your Mind?](https://arxiv.org/abs/2508.08158)
*Laura Spillner,Rachel Ringe,Robert Porzel,Rainer Malaka*

Main category: cs.HC

TL;DR: 研究发现，尽管AI解释有助于用户判断其建议的可信度，但用户往往不会详细阅读解释，影响其决策调整。


<details>
  <summary>Details</summary>
Motivation: 探讨用户在实际使用可解释决策支持系统时，是否充分关注AI解释及其对决策的影响。

Method: 通过在线研究分析用户对AI解释的关注程度及其对决策调整的影响。

Result: 许多用户未详细阅读解释，导致其决策未充分受AI建议影响。

Conclusion: 需进一步研究如何提升用户对AI解释的关注度，以优化决策支持系统的效果。

Abstract: In the context of AI-based decision support systems, explanations can help
users to judge when to trust the AI's suggestion, and when to question it. In
this way, human oversight can prevent AI errors and biased decision-making.
However, this rests on the assumption that users will consider explanations in
enough detail to be able to catch such errors. We conducted an online study on
trust in explainable DSS, and were surprised to find that in many cases,
participants spent little time on the explanation and did not always consider
it in detail. We present an exploratory analysis of this data, investigating
what factors impact how carefully study participants consider AI explanations,
and how this in turn impacts whether they are open to changing their mind based
on what the AI suggests.

</details>


### [281] [Bringing Everyone to the Table: An Experimental Study of LLM-Facilitated Group Decision Making](https://arxiv.org/abs/2508.08242)
*Mohammed Alsobay,David M. Rothschild,Jake M. Hofman,Daniel G. Goldstein*

Main category: cs.HC

TL;DR: 研究发现，LLM（如GPT-4）作为群体决策的促进者，能显著增加信息共享，但对最终决策结果无显著影响。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在群体决策中作为促进者的潜力，以解决信息共享不均的问题。

Method: 通过预注册随机实验，比较无促进、一次性提示、人类促进和LLM促进四种条件下的群体决策表现。

Result: LLM促进显著提高了信息共享，但对决策结果无显著影响。

Conclusion: LLM促进虽能提升信息共享，但不足以克服隐藏信息效应，未来需进一步研究LLM在协作决策中的作用。

Abstract: Group decision-making often suffers from uneven information sharing,
hindering decision quality. While large language models (LLMs) have been widely
studied as aids for individuals, their potential to support groups of users,
potentially as facilitators, is relatively underexplored. We present a
pre-registered randomized experiment with 1,475 participants assigned to 281
five-person groups completing a hidden profile task--selecting an optimal city
for a hypothetical sporting event--under one of four facilitation conditions:
no facilitation, a one-time message prompting information sharing, a human
facilitator, or an LLM (GPT-4o) facilitator. We find that LLM facilitation
increases information shared within a discussion by raising the minimum level
of engagement with the task among group members, and that these gains come at
limited cost in terms of participants' attitudes towards the task, their group,
or their facilitator. Whether by human or AI, there is no significant effect of
facilitation on the final decision outcome, suggesting that even substantial
but partial increases in information sharing are insufficient to overcome the
hidden profile effect studied. To support further research into how LLM-based
interfaces can support the future of collaborative decision making, we release
our experimental platform, the Group-AI Interaction Laboratory (GRAIL), as an
open-source tool.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [282] [Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach](https://arxiv.org/abs/2508.06863)
*Hamidreza Asadian-Rad,Hossein Soleimani,Shahrokh Farahmand*

Main category: cs.MA

TL;DR: 论文提出了一种完全去中心化的无人机轨迹优化方法，利用图注意力层和经验共享的深度强化学习，解决了集中式方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 多接入边缘计算中无人机作为边缘服务器时，集中式优化存在通信开销、灵活性差等问题，需设计去中心化方案。

Method: 采用图注意力层（GAT）和经验共享近端策略优化（EPS-PPO），无人机仅与邻居通信，通过本地深度强化学习确定轨迹。

Result: 相比现有方法（如MADDPG），在多个性能指标上表现更优，仅需本地通信。

Conclusion: 去中心化方法在性能和灵活性上优于集中式方案，适合动态环境下的无人机轨迹优化。

Abstract: Unmanned aerial vehicles (UAVs) have been recently utilized in multi-access
edge computing (MEC) as edge servers. It is desirable to design UAVs'
trajectories and user to UAV assignments to ensure satisfactory service to the
users and energy efficient operation simultaneously. The posed optimization
problem is challenging to solve because: (i) The formulated problem is
non-convex, (ii) Due to the mobility of ground users, their future positions
and channel gains are not known in advance, (iii) Local UAVs' observations
should be communicated to a central entity that solves the optimization
problem. The (semi-) centralized processing leads to communication overhead,
communication/processing bottlenecks, lack of flexibility and scalability, and
loss of robustness to system failures. To simultaneously address all these
limitations, we advocate a fully decentralized setup with no centralized
entity. Each UAV obtains its local observation and then communicates with its
immediate neighbors only. After sharing information with neighbors, each UAV
determines its next position via a locally run deep reinforcement learning
(DRL) algorithm. None of the UAVs need to know the global communication graph.
Two main components of our proposed solution are (i) Graph attention layers
(GAT), and (ii) Experience and parameter sharing proximal policy optimization
(EPS-PPO). Our proposed approach eliminates all the limitations of
semi-centralized MADRL methods such as MAPPO and MA deep deterministic policy
gradient (MADDPG), while guaranteeing a better performance than independent
local DRLs such as in IPPO. Numerical results reveal notable performance gains
in several different criteria compared to the existing MADDPG algorithm,
demonstrating the potential for offering a better performance, while utilizing
local communications only.

</details>


### [283] [A Survey on Agentic Service Ecosystems: Measurement, Analysis, and Optimization](https://arxiv.org/abs/2508.07343)
*Xuwen Zhang,Xiao Xue,Xia Xie,Qun Ma,Xiangning Yu,Deyu Zhou,Yifan Wang,Ming Zhang*

Main category: cs.MA

TL;DR: 本文提出了一种分析Agentic服务生态系统中群体智能涌现的框架，包括测量、分析和优化三个步骤，旨在揭示涌现的循环机制和量化标准。


<details>
  <summary>Details</summary>
Motivation: 传统线性分析方法无法应对Agentic服务生态系统中异构自主代理的复杂性，而群体智能的特性为理解此类系统提供了新视角。

Method: 提出三步框架（测量、分析、优化），结合现有技术分析其优缺点，并解决未解挑战。

Result: 框架为实际应用提供了理论支持和可操作方法，揭示了群体智能涌现的机制。

Conclusion: 该框架填补了现有研究的空白，为复杂Agentic生态系统的优化提供了系统性方法。

Abstract: The Agentic Service Ecosystem consists of heterogeneous autonomous agents
(e.g., intelligent machines, humans, and human-machine hybrid systems) that
interact through resource exchange and service co-creation. These agents, with
distinct behaviors and motivations, exhibit autonomous perception, reasoning,
and action capabilities, which increase system complexity and make traditional
linear analysis methods inadequate. Swarm intelligence, characterized by
decentralization, self-organization, emergence, and dynamic adaptability,
offers a novel theoretical lens and methodology for understanding and
optimizing such ecosystems. However, current research, owing to fragmented
perspectives and cross-ecosystem differences, fails to comprehensively capture
the complexity of swarm-intelligence emergence in agentic contexts. The lack of
a unified methodology further limits the depth and systematic treatment of the
research. This paper proposes a framework for analyzing the emergence of swarm
intelligence in Agentic Service Ecosystems, with three steps: measurement,
analysis, and optimization, to reveal the cyclical mechanisms and quantitative
criteria that foster emergence. By reviewing existing technologies, the paper
analyzes their strengths and limitations, identifies unresolved challenges, and
shows how this framework provides both theoretical support and actionable
methods for real-world applications.

</details>


### [284] [Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation](https://arxiv.org/abs/2508.07569)
*Amulya Suravarjhula,Rashi Chandrashekhar Agrawal,Sakshi Jayesh Patel,Rahul Gupta*

Main category: cs.MA

TL;DR: 论文介绍了一种AI驱动的自动化系统，用于快速、准确生成SOW，显著提升效率并减少法律风险。


<details>
  <summary>Details</summary>
Motivation: 传统SOW起草过程缓慢、复杂且易出错，亟需自动化解决方案。

Method: 系统采用三个智能代理：起草、法律合规检查和文档格式化，实现全流程自动化。

Result: 测试显示系统能在三分钟内完成SOW，比人工快且质量高。

Conclusion: AI可支持法律和商业专业人士，提升流程效率与可靠性。

Abstract: Drafting a Statement of Work (SOW) is a vital part of business and legal
projects. It outlines key details like deliverables, timelines,
responsibilities, and legal terms. However, creating these documents is often a
slow and complex process. It usually involves multiple people, takes several
days, and leaves room for errors or outdated content. This paper introduces a
new AI-driven automation system that makes the entire SOW drafting process
faster, easier, and more accurate. Instead of relying completely on humans, the
system uses three intelligent components or 'agents' that each handle a part of
the job. One agent writes the first draft, another checks if everything is
legally correct, and the third agent formats the document and ensures
everything is in order. Unlike basic online tools that just fill in templates,
this system understands the meaning behind the content and customizes the SOW
to match the needs of the project. It also checks legal compliance and
formatting so that users can trust the result. The system was tested using real
business examples. It was able to create a full SOW in under three minutes,
compared to several hours or days using manual methods. It also performed well
in accuracy and quality, showing that it can reduce legal risks and save a lot
of time. This solution shows how artificial intelligence can be used to support
legal and business professionals by taking care of routine work and helping
them focus on more important decisions. It's a step toward making legal
processes smarter, faster, and more reliable.

</details>


### [285] [Toward Goal-Oriented Communication in Multi-Agent Systems: An overview](https://arxiv.org/abs/2508.07720)
*Themistoklis Charalambous,Nikolaos Pappas,Nikolaos Nomikos,Risto Wichman*

Main category: cs.MA

TL;DR: 本文综述了多智能体系统中目标导向通信的研究，结合信息论、通信理论和机器学习视角，探讨了任务相关通信的重要性及其在资源受限环境中的应用。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统在自主系统、分布式控制和边缘智能中的普及，资源受限下的高效通信成为关键挑战。传统通信范式常忽略任务相关性，而目标导向通信则强调信息对共享目标的重要性。

Method: 通过文献综述，结合信息论、通信理论和机器学习方法，分析了目标导向通信的基础概念、学习型方法和新兴协议，特别关注通信约束下的协调问题。

Result: 总结了目标导向通信在群体机器人、联邦学习和边缘计算等领域的应用，并提出了未来研究方向。

Conclusion: 目标导向通信在多智能体系统中具有重要潜力，但仍需解决通信理论、机器学习和多智能体决策交叉领域的开放挑战。

Abstract: As multi-agent systems (MAS) become increasingly prevalent in autonomous
systems, distributed control, and edge intelligence, efficient communication
under resource constraints has emerged as a critical challenge. Traditional
communication paradigms often emphasize message fidelity or bandwidth
optimization, overlooking the task relevance of the exchanged information. In
contrast, goal-oriented communication prioritizes the importance of information
with respect to the agents' shared objectives. This review provides a
comprehensive survey of goal-oriented communication in MAS, bridging
perspectives from information theory, communication theory, and machine
learning. We examine foundational concepts alongside learning-based approaches
and emergent protocols. Special attention is given to coordination under
communication constraints, as well as applications in domains such as swarm
robotics, federated learning, and edge computing. The paper concludes with a
discussion of open challenges and future research directions at the
intersection of communication theory, machine learning, and multi-agent
decision making.

</details>


### [286] [Multi-agent systems for chemical engineering: A review and perspective](https://arxiv.org/abs/2508.07880)
*Sophia Rupprecht,Qinghe Gao,Tanuj Karia,Artur M. Schweidtmann*

Main category: cs.MA

TL;DR: 本文综述了基于大语言模型的多智能体系统在化学工程中的应用现状、挑战与前景。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过多智能体系统分解复杂工作流程，推动化学工程领域的变革。

Method: 综述了当前多智能体系统在化学工程中的最新研究进展。

Result: 初步研究显示多智能体系统具有潜力，但仍面临架构设计、数据整合、透明性等挑战。

Conclusion: 多智能体系统为化学工程提供了重新思考工作流程的机遇，但需解决科学挑战以实现其潜力。

Abstract: Large language model (LLM)-based multi-agent systems (MASs) are a recent but
rapidly evolving technology with the potential to transform chemical
engineering by decomposing complex workflows into teams of collaborative agents
with specialized knowledge and tools. This review surveys the state-of-the-art
of MAS within chemical engineering. While early studies demonstrate promising
results, scientific challenges remain, including the design of tailored
architectures, integration of heterogeneous data modalities, development of
foundation models with domain-specific modalities, and strategies for ensuring
transparency, safety, and environmental impact. As a young but fast-moving
field, MASs offer exciting opportunities to rethink chemical engineering
workflows.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [287] [Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification](https://arxiv.org/abs/2508.06535)
*Faisal Ahmed*

Main category: eess.IV

TL;DR: 该研究通过迁移学习和数据增强技术，使用EfficientNet-B3模型在急性淋巴细胞白血病（ALL）分类中取得了最佳性能（F1分数94.30%，准确率92.02%，AUC 94.79%）。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病的准确分类对早期诊断和治疗规划至关重要，但现有数据存在类别不平衡问题。

Method: 采用预训练的卷积神经网络（如ResNet50、ResNet101和EfficientNet系列）结合数据增强技术，平衡数据集并评估模型性能。

Result: EfficientNet-B3表现最佳，优于C-NMC挑战中的其他方法。

Conclusion: 结合数据增强和迁移学习（尤其是EfficientNet-B3）可有效提升血液恶性肿瘤诊断的准确性和鲁棒性。

Abstract: Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral
blood smear images is essential for early diagnosis and effective treatment
planning. This study investigates the use of transfer learning with pretrained
convolutional neural networks (CNNs) to improve diagnostic performance. To
address the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL
images, we applied extensive data augmentation techniques to create a balanced
training set of 10,000 images per class. We evaluated several models, including
ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3
achieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,
andAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.
Thesefindings demonstrate the effectiveness of combining data augmentation with
advanced transfer learning models, particularly EfficientNet-B3, in developing
accurate and robust diagnostic tools for hematologic malignancy detection.

</details>


### [288] [LWT-ARTERY-LABEL: A Lightweight Framework for Automated Coronary Artery Identification](https://arxiv.org/abs/2508.06874)
*Shisheng Zhang,Ramtin Gharleghi,Sonit Singh,Daniel Moses,Dona Adikari,Arcot Sowmya,Susann Beier*

Main category: eess.IV

TL;DR: 提出了一种轻量级方法，结合解剖学知识和基于规则的拓扑约束，用于冠状动脉自动标记，解决了传统方法和深度学习的不足。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉疾病是全球主要死因，CTCA是重要诊断工具，但手动分析耗时且劳动密集。现有自动标记方法存在不足，如传统方法缺乏数据驱动，深度学习资源需求高且忽略临床知识。

Method: 提出了一种轻量级方法，整合解剖学知识和基于规则的拓扑约束，用于冠状动脉自动标记。

Result: 在基准数据集上实现了最先进的性能。

Conclusion: 该方法为冠状动脉自动标记提供了有前景的替代方案。

Abstract: Coronary artery disease (CAD) remains the leading cause of death globally,
with computed tomography coronary angiography (CTCA) serving as a key
diagnostic tool. However, coronary arterial analysis using CTCA, such as
identifying artery-specific features from computational modelling, is
labour-intensive and time-consuming. Automated anatomical labelling of coronary
arteries offers a potential solution, yet the inherent anatomical variability
of coronary trees presents a significant challenge. Traditional knowledge-based
labelling methods fall short in leveraging data-driven insights, while recent
deep-learning approaches often demand substantial computational resources and
overlook critical clinical knowledge. To address these limitations, we propose
a lightweight method that integrates anatomical knowledge with rule-based
topology constraints for effective coronary artery labelling. Our approach
achieves state-of-the-art performance on benchmark datasets, providing a
promising alternative for automated coronary artery labelling.

</details>


### [289] [Fusion-Based Brain Tumor Classification Using Deep Learning and Explainable AI, and Rule-Based Reasoning](https://arxiv.org/abs/2508.06891)
*Melika Filvantorkaman,Mohsen Piri,Maral Filvan Torkaman,Ashkan Zabihi,Hamidreza Moradi*

Main category: eess.IV

TL;DR: 该研究提出了一种基于MobileNetV2和DenseNet121的集成深度学习框架，用于MRI脑肿瘤分类，结合可解释AI模块，性能优于单一模型，并得到临床验证。


<details>
  <summary>Details</summary>
Motivation: 准确且可解释的脑肿瘤分类对诊断和治疗至关重要，但现有方法在性能和透明度上仍有不足。

Method: 采用MobileNetV2和DenseNet121的集成模型，结合软投票策略和可解释AI模块（Grad-CAM++和临床决策规则）。

Result: 集成模型准确率达91.7%，Grad-CAM++可视化与专家标注区域高度一致，临床评估显示高解释性评分。

Conclusion: 该框架为脑肿瘤分类提供了高性能且可解释的解决方案，具有临床推广潜力。

Abstract: Accurate and interpretable classification of brain tumors from magnetic
resonance imaging (MRI) is critical for effective diagnosis and treatment
planning. This study presents an ensemble-based deep learning framework that
combines MobileNetV2 and DenseNet121 convolutional neural networks (CNNs) using
a soft voting strategy to classify three common brain tumor types: glioma,
meningioma, and pituitary adenoma. The models were trained and evaluated on the
Figshare dataset using a stratified 5-fold cross-validation protocol. To
enhance transparency and clinical trust, the framework integrates an
Explainable AI (XAI) module employing Grad-CAM++ for class-specific saliency
visualization, alongside a symbolic Clinical Decision Rule Overlay (CDRO) that
maps predictions to established radiological heuristics. The ensemble
classifier achieved superior performance compared to individual CNNs, with an
accuracy of 91.7%, precision of 91.9%, recall of 91.7%, and F1-score of 91.6%.
Grad-CAM++ visualizations revealed strong spatial alignment between model
attention and expert-annotated tumor regions, supported by Dice coefficients up
to 0.88 and IoU scores up to 0.78. Clinical rule activation further validated
model predictions in cases with distinct morphological features. A
human-centered interpretability assessment involving five board-certified
radiologists yielded high Likert-scale scores for both explanation usefulness
(mean = 4.4) and heatmap-region correspondence (mean = 4.0), reinforcing the
framework's clinical relevance. Overall, the proposed approach offers a robust,
interpretable, and generalizable solution for automated brain tumor
classification, advancing the integration of deep learning into clinical
neurodiagnostics.

</details>


### [290] [Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images](https://arxiv.org/abs/2508.07875)
*Shuo Han,Ahmed Karam Eldaly,Solomon Sunday Oyelere*

Main category: eess.IV

TL;DR: 提出了一种人机协作的深度学习系统，结合EfficientNetV2S模型和专家反馈，提升浸润性导管癌（IDC）检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 早期准确诊断IDC对提高患者生存率至关重要，结合AI与医学专家知识可提升诊断效率和精度。

Method: 采用人机协作（HITL）系统，先由EfficientNetV2S模型初步诊断，专家修正后反馈至模型，形成迭代优化。

Result: EfficientNetV2S模型准确率达93.65%，结合HITL系统后进一步提升了性能。

Conclusion: 人机协作方法为AI辅助医疗诊断提供了高效、准确的解决方案，具有未来应用潜力。

Abstract: Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer,
and early, accurate diagnosis is critical to improving patient survival rates
by guiding treatment decisions. Combining medical expertise with artificial
intelligence (AI) holds significant promise for enhancing the precision and
efficiency of IDC detection. In this work, we propose a human-in-the-loop
(HITL) deep learning system designed to detect IDC in histopathology images.
The system begins with an initial diagnosis provided by a high-performance
EfficientNetV2S model, offering feedback from AI to the human expert. Medical
professionals then review the AI-generated results, correct any misclassified
images, and integrate the revised labels into the training dataset, forming a
feedback loop from the human back to the AI. This iterative process refines the
model's performance over time. The EfficientNetV2S model itself achieves
state-of-the-art performance compared to existing methods in the literature,
with an overall accuracy of 93.65\%. Incorporating the human-in-the-loop system
further improves the model's accuracy using four experimental groups with
misclassified images. These results demonstrate the potential of this
collaborative approach to enhance AI performance in diagnostic systems. This
work contributes to advancing automated, efficient, and highly accurate methods
for IDC detection through human-AI collaboration, offering a promising
direction for future AI-assisted medical diagnostics.

</details>


### [291] [Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments](https://arxiv.org/abs/2508.07006)
*Gian Mario Favero,Ge Ya Luo,Nima Fathi,Justin Szeto,Douglas L. Arnold,Brennan Nichyporuk,Chris Pal,Tal Arbel*

Main category: eess.IV

TL;DR: 本文提出了一种基于图像的治疗感知时空扩散模型，用于预测多发性硬化症（MS）患者的未来病灶演变。


<details>
  <summary>Details</summary>
Motivation: 多发性硬化症（MS）的异质性进展需要个性化医疗，而图像生成模型可以为此提供数据驱动的预测工具。

Method: 采用体素空间方法，结合多模态患者数据（如MRI和治疗信息），生成未来T2病灶（NET2）的预测掩模。

Result: 在2131名患者的3D MRI数据集上验证，模型能准确预测六种不同治疗方案的NET2病灶掩模，并展示了临床应用的潜力。

Conclusion: 该研究证明了基于因果关系的图像生成模型在MS数据驱动预后中的重要作用。

Abstract: Image-based personalized medicine has the potential to transform healthcare,
particularly for diseases that exhibit heterogeneous progression such as
Multiple Sclerosis (MS). In this work, we introduce the first treatment-aware
spatio-temporal diffusion model that is able to generate future masks
demonstrating lesion evolution in MS. Our voxel-space approach incorporates
multi-modal patient data, including MRI and treatment information, to forecast
new and enlarging T2 (NET2) lesion masks at a future time point. Extensive
experiments on a multi-centre dataset of 2131 patient 3D MRIs from randomized
clinical trials for relapsing-remitting MS demonstrate that our generative
model is able to accurately predict NET2 lesion masks for patients across six
different treatments. Moreover, we demonstrate our model has the potential for
real-world clinical applications through downstream tasks such as future lesion
count and location estimation, binary lesion activity classification, and
generating counterfactual future NET2 masks for several treatments with
different efficacies. This work highlights the potential of causal, image-based
generative models as powerful tools for advancing data-driven prognostics in
MS.

</details>


### [292] [Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities](https://arxiv.org/abs/2508.07031)
*Anindya Bijoy Das,Shahnewaz Karim Sakib,Shibbir Ahmed*

Main category: eess.IV

TL;DR: 研究分析了大型语言模型（LLMs）在医学影像任务中的幻觉问题，包括图像到文本和文本到图像方向的错误，并探讨了其对临床可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: LLMs在医学影像任务中常产生幻觉（自信但错误的输出），可能误导临床决策，因此需要研究其错误模式及原因。

Method: 研究从图像到文本（生成报告）和文本到图像（生成影像）两个方向分析幻觉问题，使用专家标准评估错误。

Result: 发现幻觉在解释和生成任务中均有常见模式，并识别了模型架构和训练数据等影响因素。

Conclusion: 通过系统研究，为提升LLM驱动的医学影像系统的安全性和可信度提供了见解。

Abstract: Large Language Models (LLMs) are increasingly applied to medical imaging
tasks, including image interpretation and synthetic image generation. However,
these models often produce hallucinations, which are confident but incorrect
outputs that can mislead clinical decisions. This study examines hallucinations
in two directions: image to text, where LLMs generate reports from X-ray, CT,
or MRI scans, and text to image, where models create medical images from
clinical prompts. We analyze errors such as factual inconsistencies and
anatomical inaccuracies, evaluating outputs using expert informed criteria
across imaging modalities. Our findings reveal common patterns of hallucination
in both interpretive and generative tasks, with implications for clinical
reliability. We also discuss factors contributing to these failures, including
model architecture and training data. By systematically studying both image
understanding and generation, this work provides insights into improving the
safety and trustworthiness of LLM driven medical imaging systems.

</details>


### [293] [3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS Compression](https://arxiv.org/abs/2508.07038)
*Yuke Xing,William Gordon,Qi Yang,Kaifa Yang,Jiarui Wang,Yiling Xu*

Main category: eess.IV

TL;DR: 3DGS-VBench是一个用于评估3D高斯泼溅（3DGS）压缩算法视觉质量的大规模数据集和基准测试，包含660个压缩模型和视频序列，并提供了MOS评分和多种质量评估指标的对比。


<details>
  <summary>Details</summary>
Motivation: 3DGS虽然能实现高保真度的实时新视角合成，但其存储需求高，现有压缩方法缺乏系统性的质量评估研究。

Method: 建立了包含660个压缩3DGS模型和视频序列的数据集，涵盖6种SOTA压缩算法和11个场景，通过50名参与者标注MOS评分并验证数据可靠性。

Result: 对6种压缩算法在存储效率和视觉质量上进行了基准测试，并评估了15种质量评估指标。

Conclusion: 3DGS-VBench为3DGS压缩和质量评估研究提供了专门的数据集和基准，推动了相关领域的发展。

Abstract: 3D Gaussian Splatting (3DGS) enables real-time novel view synthesis with high
visual fidelity, but its substantial storage requirements hinder practical
deployment, prompting state-of-the-art (SOTA) 3DGS methods to incorporate
compression modules. However, these 3DGS generative compression techniques
introduce unique distortions lacking systematic quality assessment research. To
this end, we establish 3DGS-VBench, a large-scale Video Quality Assessment
(VQA) Dataset and Benchmark with 660 compressed 3DGS models and video sequences
generated from 11 scenes across 6 SOTA 3DGS compression algorithms with
systematically designed parameter levels. With annotations from 50
participants, we obtained MOS scores with outlier removal and validated dataset
reliability. We benchmark 6 3DGS compression algorithms on storage efficiency
and visual quality, and evaluate 15 quality assessment metrics across multiple
paradigms. Our work enables specialized VQA model training for 3DGS, serving as
a catalyst for compression and quality assessment research. The dataset is
available at https://github.com/YukeXing/3DGS-VBench.

</details>


### [294] [SAGCNet: Spatial-Aware Graph Completion Network for Missing Slice Imputation in Population CMR Imaging](https://arxiv.org/abs/2508.07041)
*Junkai Liu,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: eess.IV

TL;DR: SAGCNet提出了一种新的MRI缺失切片合成方法，通过图结构和空间适配器有效利用3D空间信息，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: MRI缺失或不可用切片影响诊断准确性，现有方法难以建模3D切片间关系和全局空间信息。

Method: 提出SAGCNet，包含切片图完成模块和空间适配器组件，以捕捉3D空间上下文。

Result: 在心脏MRI数据集上表现优异，定量和定性均优于现有方法，且在数据有限时仍保持高性能。

Conclusion: SAGCNet为MRI缺失切片合成提供了高效解决方案，显著提升了3D空间信息的利用能力。

Abstract: Magnetic resonance imaging (MRI) provides detailed soft-tissue
characteristics that assist in disease diagnosis and screening. However, the
accuracy of clinical practice is often hindered by missing or unusable slices
due to various factors. Volumetric MRI synthesis methods have been developed to
address this issue by imputing missing slices from available ones. The inherent
3D nature of volumetric MRI data, such as cardiac magnetic resonance (CMR),
poses significant challenges for missing slice imputation approaches, including
(1) the difficulty of modeling local inter-slice correlations and dependencies
of volumetric slices, and (2) the limited exploration of crucial 3D spatial
information and global context. In this study, to mitigate these issues, we
present Spatial-Aware Graph Completion Network (SAGCNet) to overcome the
dependency on complete volumetric data, featuring two main innovations: (1) a
volumetric slice graph completion module that incorporates the inter-slice
relationships into a graph structure, and (2) a volumetric spatial adapter
component that enables our model to effectively capture and utilize various
forms of 3D spatial context. Extensive experiments on cardiac MRI datasets
demonstrate that SAGCNet is capable of synthesizing absent CMR slices,
outperforming competitive state-of-the-art MRI synthesis methods both
quantitatively and qualitatively. Notably, our model maintains superior
performance even with limited slice data.

</details>


### [295] [Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications](https://arxiv.org/abs/2508.07165)
*Zelin Qiu,Xi Wang,Zhuoyao Xie,Juan Zhou,Yu Wang,Lingjie Yang,Xinrui Jiang,Juyoung Bae,Moo Hyun Son,Qiang Ye,Dexuan Chen,Rui Zhang,Tao Li,Neeraj Ramesh Mahboobani,Varut Vardhanabhuti,Xiaohui Duan,Yinghua Zhao,Hao Chen*

Main category: eess.IV

TL;DR: PRISM是一个基于大规模多序列MRI预训练的基础模型，通过解耦解剖不变特征和序列特异性变化，显著提升了模型在多样化MRI协议下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多序列MRI的异质性限制了深度学习模型的泛化能力，影响临床实用性。PRISM旨在解决这一问题。

Method: 收集64个数据集（34个用于预训练），提出新预训练范式，解耦解剖和序列特征，构建44个下游任务基准。

Result: PRISM在44个任务中39个排名第一，显著优于非预训练模型和现有基础模型。

Conclusion: PRISM为多序列MRI分析提供了可扩展框架，增强了AI在放射学中的临床适用性。

Abstract: Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable
versatility, enabling the distinct visualization of different tissue types.
Nevertheless, the inherent heterogeneity among MRI sequences poses significant
challenges to the generalization capability of deep learning models. These
challenges undermine model performance when faced with varying acquisition
parameters, thereby severely restricting their clinical utility. In this study,
we present PRISM, a foundation model PRe-trained with large-scale
multI-Sequence MRI. We collected a total of 64 datasets from both public and
private sources, encompassing a wide range of whole-body anatomical structures,
with scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI
scans from 34 datasets (8 public and 26 private) were curated to construct the
largest multi-organ multi-sequence MRI pretraining corpus to date. We propose a
novel pretraining paradigm that disentangles anatomically invariant features
from sequence-specific variations in MRI, while preserving high-level semantic
representations. We established a benchmark comprising 44 downstream tasks,
including disease diagnosis, image segmentation, registration, progression
prediction, and report generation. These tasks were evaluated on 32 public
datasets and 5 private cohorts. PRISM consistently outperformed both
non-pretrained models and existing foundation models, achieving first-rank
results in 39 out of 44 downstream benchmarks with statistical significance
improvements. These results underscore its ability to learn robust and
generalizable representations across unseen data acquired under diverse MRI
protocols. PRISM provides a scalable framework for multi-sequence MRI analysis,
thereby enhancing the translational potential of AI in radiology. It delivers
consistent performance across diverse imaging protocols, reinforcing its
clinical applicability.

</details>


### [296] [HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation](https://arxiv.org/abs/2508.07225)
*Xuepeng Liu,Zheng Jiang,Pinan Zhu,Hanyu Liu,Chao Li*

Main category: eess.IV

TL;DR: HaDM-ST是一种基于H&E图像和低分辨率ST的高分辨率空间转录组生成框架，解决了特征提取、多模态对齐和基因特异性建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前空间转录组技术分辨率有限，且现有方法在从H&E图像中提取特征、多模态对齐和基因特异性建模方面存在不足。

Method: HaDM-ST包括语义蒸馏网络提取H&E特征、空间对齐模块实现像素级对应，以及通道感知对抗学习器进行基因级建模。

Result: 在200个基因的实验中，HaDM-ST在空间保真度和基因级一致性上优于现有方法。

Conclusion: HaDM-ST显著提升了高分辨率空间转录组预测的准确性和实用性。

Abstract: Spatial transcriptomics (ST) reveals spatial heterogeneity of gene
expression, yet its resolution is limited by current platforms. Recent methods
enhance resolution via H&E-stained histology, but three major challenges
persist: (1) isolating expression-relevant features from visually complex H&E
images; (2) achieving spatially precise multimodal alignment in diffusion-based
frameworks; and (3) modeling gene-specific variation across expression
channels. We propose HaDM-ST (Histology-assisted Differential Modeling for ST
Generation), a high-resolution ST generation framework conditioned on H&E
images and low-resolution ST. HaDM-ST includes: (i) a semantic distillation
network to extract predictive cues from H&E; (ii) a spatial alignment module
enforcing pixel-wise correspondence with low-resolution ST; and (iii) a
channel-aware adversarial learner for fine-grained gene-level modeling.
Experiments on 200 genes across diverse tissues and species show HaDM-ST
consistently outperforms prior methods, enhancing spatial fidelity and
gene-level coherence in high-resolution ST predictions.

</details>


### [297] [DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework](https://arxiv.org/abs/2508.07682)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: eess.IV

TL;DR: DiffVC-OSD是一种基于一步扩散的感知神经视频压缩框架，通过单步扩散提升感知质量，并在解码速度和比特率上显著优于多步扩散方法。


<details>
  <summary>Details</summary>
Motivation: 传统多步扩散方法效率低，DiffVC-OSD旨在通过一步扩散提升压缩效率和感知质量。

Method: 提出一步扩散模型和时序上下文适配器，结合端到端微调策略优化压缩性能。

Result: DiffVC-OSD在感知压缩性能上达到最优，解码速度快20倍，比特率降低86.92%。

Conclusion: DiffVC-OSD通过一步扩散显著提升了视频压缩的效率和感知质量。

Abstract: In this work, we first propose DiffVC-OSD, a One-Step Diffusion-based
Perceptual Neural Video Compression framework. Unlike conventional multi-step
diffusion-based methods, DiffVC-OSD feeds the reconstructed latent
representation directly into a One-Step Diffusion Model, enhancing perceptual
quality through a single diffusion step guided by both temporal context and the
latent itself. To better leverage temporal dependencies, we design a Temporal
Context Adapter that encodes conditional inputs into multi-level features,
offering more fine-grained guidance for the Denoising Unet. Additionally, we
employ an End-to-End Finetuning strategy to improve overall compression
performance. Extensive experiments demonstrate that DiffVC-OSD achieves
state-of-the-art perceptual compression performance, offers about 20$\times$
faster decoding and a 86.92\% bitrate reduction compared to the corresponding
multi-step diffusion-based variant.

</details>


### [298] [Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning](https://arxiv.org/abs/2508.07788)
*Runze Wang,Zeli Chen,Zhiyun Song,Wei Fang,Jiajin Zhang,Danyang Tu,Yuxing Tang,Minfeng Xu,Xianghua Ye,Le Lu,Dakai Jin*

Main category: eess.IV

TL;DR: ALDEN是一种基于深度学习的低剂量CT去噪方法，通过结合预训练视觉模型的语义特征与对抗和对比学习，显著提升了去噪效果并保留了解剖结构。


<details>
  <summary>Details</summary>
Motivation: 现有低剂量CT去噪方法忽略了人体组织的解剖语义，导致去噪效果不理想。

Method: ALDEN利用解剖感知判别器和语义引导的对比学习模块，动态融合参考正常剂量CT的语义特征，并通过对比学习保持解剖一致性。

Result: 在两个低剂量CT去噪数据集上，ALDEN实现了最先进的性能，显著减少了过平滑问题，并在下游多器官分割任务中验证了其解剖感知能力。

Conclusion: ALDEN通过结合语义特征和对比学习，有效提升了低剂量CT去噪的解剖保留能力，具有广泛的应用潜力。

Abstract: To reduce radiation exposure and improve the diagnostic efficacy of low-dose
computed tomography (LDCT), numerous deep learning-based denoising methods have
been developed to mitigate noise and artifacts. However, most of these
approaches ignore the anatomical semantics of human tissues, which may
potentially result in suboptimal denoising outcomes. To address this problem,
we propose ALDEN, an anatomy-aware LDCT denoising method that integrates
semantic features of pretrained vision models (PVMs) with adversarial and
contrastive learning. Specifically, we introduce an anatomy-aware discriminator
that dynamically fuses hierarchical semantic features from reference
normal-dose CT (NDCT) via cross-attention mechanisms, enabling tissue-specific
realism evaluation in the discriminator. In addition, we propose a
semantic-guided contrastive learning module that enforces anatomical
consistency by contrasting PVM-derived features from LDCT, denoised CT and
NDCT, preserving tissue-specific patterns through positive pairs and
suppressing artifacts via dual negative pairs. Extensive experiments conducted
on two LDCT denoising datasets reveal that ALDEN achieves the state-of-the-art
performance, offering superior anatomy preservation and substantially reducing
over-smoothing issue of previous work. Further validation on a downstream
multi-organ segmentation task (encompassing 117 anatomical structures) affirms
the model's ability to maintain anatomical awareness.

</details>


### [299] [Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models](https://arxiv.org/abs/2508.07903)
*Johanna P. Müller,Anika Knupfer,Pedro Blöss,Edoardo Berardi Vittur,Bernhard Kainz,Jana Hutter*

Main category: eess.IV

TL;DR: 提出了一种新的扩散模型框架，用于生成高保真度的女性盆腔MRI图像，解决了现有模型在解剖学精确性上的不足，并支持妇科影像学研究。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成精确的女性盆腔解剖图像方面表现不佳，且妇科影像数据稀缺和隐私问题限制了应用。

Method: 结合无条件与条件Denoising Diffusion Probabilistic Models (DDPMs)和Latent Diffusion Models (LDMs)，在2D和3D中生成合成图像。

Result: 生成的图像解剖学一致且高保真，显著提升了诊断模型的准确性，并通过专家评估验证了临床真实性。

Conclusion: 该框架为妇科影像学提供了有价值的合成数据资源，支持可重复研究和公平AI发展。

Abstract: Despite significant progress in generative modelling, existing diffusion
models often struggle to produce anatomically precise female pelvic images,
limiting their application in gynaecological imaging, where data scarcity and
patient privacy concerns are critical. To overcome these barriers, we introduce
a novel diffusion-based framework for uterine MRI synthesis, integrating both
unconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs)
and Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates
anatomically coherent, high fidelity synthetic images that closely mimic real
scans and provide valuable resources for training robust diagnostic models. We
evaluate generative quality using advanced perceptual and distributional
metrics, benchmarking against standard reconstruction methods, and demonstrate
substantial gains in diagnostic accuracy on a key classification task. A
blinded expert evaluation further validates the clinical realism of our
synthetic images. We release our models with privacy safeguards and a
comprehensive synthetic uterine MRI dataset to support reproducible research
and advance equitable AI in gynaecology.

</details>


### [300] [A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images](https://arxiv.org/abs/2508.08123)
*Lingjing Chen,Chengxiu Zhang,Yinqiao Yi,Yida Wang,Yang Song,Xu Yan,Shengfang Xu,Dalin Zhu,Mengqiu Cao,Yan Zhou,Chenglong Wang,Guang Yang*

Main category: eess.IV

TL;DR: 提出一种基于深度学习的MRI定量图像合成方法，通过嵌入MRI序列参数（TR、TE、TI）提升准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统MRI定量合成方法在准确性和泛化性上存在不足，需结合物理原理改进。

Method: 设计物理驱动的神经网络，嵌入MRI序列参数，输入T1、T2、T2-FLAIR图像，输出T1、T2和PD定量图。

Result: 在内部和外部测试集上表现优异，PSNR>34 dB，SSIM>0.92，泛化能力突出。

Conclusion: 该方法通过参数嵌入显著提升性能，有望加速qMRI临床应用。

Abstract: We propose a deep learning-based approach that integrates MRI sequence
parameters to improve the accuracy and generalizability of quantitative image
synthesis from clinical weighted MRI. Our physics-driven neural network embeds
MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion
time (TI) -- directly into the model via parameter embedding, enabling the
network to learn the underlying physical principles of MRI signal formation.
The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as
input and synthesizes T1, T2, and proton density (PD) quantitative maps.
Trained on healthy brain MR images, it was evaluated on both internal and
external test datasets. The proposed method achieved high performance with PSNR
values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter
maps. It outperformed conventional deep learning models in accuracy and
robustness, including data with previously unseen brain structures and lesions.
Notably, our model accurately synthesized quantitative maps for these unseen
pathological regions, highlighting its superior generalization capability.
Incorporating MRI sequence parameters via parameter embedding allows the neural
network to better learn the physical characteristics of MR signals,
significantly enhancing the performance and reliability of quantitative MRI
synthesis. This method shows great potential for accelerating qMRI and
improving its clinical utility.

</details>


### [301] [RedDino: A foundation model for red blood cell analysis](https://arxiv.org/abs/2508.08180)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr*

Main category: eess.IV

TL;DR: RedDino是一个自监督基础模型，专为红细胞图像分析设计，性能优于现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 红细胞形态分析对血液疾病诊断至关重要，但目前缺乏全面的AI解决方案。

Method: RedDino基于DINOv2框架的自监督学习，使用125万张红细胞图像训练。

Result: RedDino在红细胞形状分类中表现优异，具有强特征表示和泛化能力。

Conclusion: RedDino解决了计算血液学中的关键挑战，推动了可靠诊断工具的发展。

Abstract: Red blood cells (RBCs) are essential to human health, and their precise
morphological analysis is important for diagnosing hematological disorders.
Despite the promise of foundation models in medical diagnostics, comprehensive
AI solutions for RBC analysis remain scarce. We present RedDino, a
self-supervised foundation model designed for RBC image analysis. RedDino uses
an RBC-specific adaptation of the DINOv2 self-supervised learning framework and
is trained on a curated dataset of 1.25 million RBC images from diverse
acquisition modalities and sources. Extensive evaluations show that RedDino
outperforms existing state-of-the-art models on RBC shape classification.
Through assessments including linear probing and nearest neighbor
classification, we confirm its strong feature representations and
generalization ability. Our main contributions are: (1) a foundation model
tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations
for RBC modeling, and (3) a detailed evaluation of generalization performance.
RedDino addresses key challenges in computational hematology by capturing
nuanced morphological features, advancing the development of reliable
diagnostic tools. The source code and pretrained models for RedDino are
available at https://github.com/Snarci/RedDino, and the pretrained models can
be downloaded from our Hugging Face collection at
https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [302] [AutoMashup: Automatic Music Mashups Creation](https://arxiv.org/abs/2508.06516)
*Marine Delabaere,Léa Miqueu,Michael Moreno,Gautier Bigois,Hoang Duong,Ella Fernandez,Flavie Manent,Maria Salgado-Herrera,Bastien Pasdeloup,Nicolas Farrugia,Axel Marmoret*

Main category: cs.SD

TL;DR: AutoMashup是一个基于音源分离、音乐分析和兼容性评估的自动混音系统，研究了通用预训练音频模型在零样本兼容性评估中的表现。


<details>
  <summary>Details</summary>
Motivation: 探索自动混音系统中音轨兼容性的评估方法，验证通用音频模型是否适用于此任务。

Method: 使用COCOLA评估分离音轨的兼容性，并测试CLAP和MERT模型在零样本兼容性估计中的表现。

Result: 混音兼容性具有不对称性（取决于音轨角色），且当前嵌入方法无法复现COCOLA测量的感知一致性。

Conclusion: 通用音频表示在混音兼容性评估中存在局限性。

Abstract: We introduce AutoMashup, a system for automatic mashup creation based on
source separation, music analysis, and compatibility estimation. We propose
using COCOLA to assess compatibility between separated stems and investigate
whether general-purpose pretrained audio models (CLAP and MERT) can support
zero-shot estimation of track pair compatibility. Our results show that mashup
compatibility is asymmetric -- it depends on the role assigned to each track
(vocals or accompaniment) -- and that current embeddings fail to reproduce the
perceptual coherence measured by COCOLA. These findings underline the
limitations of general-purpose audio representations for compatibility
estimation in mashup creation.

</details>


### [303] [Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody](https://arxiv.org/abs/2508.06890)
*Jinsung Yoon,Wooyeol Jeong,Jio Gim,Young-Joo Suh*

Main category: cs.SD

TL;DR: Maestro-EVC是一个可控的情感语音转换框架，能够独立控制内容、说话人身份和情感，并通过时间情感表示和显式韵律建模提升情感表达的精细度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在情感语音转换中难以完全解耦说话人身份和情感风格，且缺乏对细粒度情感表达（如时间动态）的建模能力。

Method: 提出Maestro-EVC框架，通过解耦不同属性并引入时间情感表示和显式韵律建模（包括韵律增强），以独立控制内容、说话人身份和情感。

Result: 实验结果表明，Maestro-EVC能够生成高质量、可控且情感表达丰富的语音。

Conclusion: Maestro-EVC在情感语音转换中实现了对多属性的独立控制和精细情感表达，具有实际应用潜力。

Abstract: Emotional voice conversion (EVC) aims to modify the emotional style of speech
while preserving its linguistic content. In practical EVC, controllability, the
ability to independently control speaker identity and emotional style using
distinct references, is crucial. However, existing methods often struggle to
fully disentangle these attributes and lack the ability to model fine-grained
emotional expressions such as temporal dynamics. We propose Maestro-EVC, a
controllable EVC framework that enables independent control of content, speaker
identity, and emotion by effectively disentangling each attribute from separate
references. We further introduce a temporal emotion representation and an
explicit prosody modeling with prosody augmentation to robustly capture and
transfer the temporal dynamics of the target emotion, even under
prosody-mismatched conditions. Experimental results confirm that Maestro-EVC
achieves high-quality, controllable, and emotionally expressive speech
synthesis.

</details>


### [304] [Whisfusion: Parallel ASR Decoding via a Diffusion Transformer](https://arxiv.org/abs/2508.07048)
*Taeyoun Kwon,Junhyuk Ahn,Taegeun Yun,Heeju Jwa,Yoonchae Choi,Siwon Park,Nam-Joon Kim,Jangchan Kim,Hyun Gon Ryu,Hyuk-Jae Lee*

Main category: cs.SD

TL;DR: Whisfusion框架通过结合Whisper编码器和文本扩散解码器，解决了自动语音识别（ASR）中的延迟瓶颈问题，实现了并行解码，显著提升了长音频的处理速度。


<details>
  <summary>Details</summary>
Motivation: 解决AR解码器在ASR中的顺序处理导致的延迟问题，以及NAR方法的上下文限制，提升实时应用中的效率。

Method: 融合Whisper编码器和文本扩散解码器，采用轻量级跨注意力适配器和批并行多步解码策略。

Result: 在LibriSpeech上，Whisfusion的WER低于Whisper-tiny（8.3% vs. 9.7%），长音频处理速度提升2.6倍。

Conclusion: Whisfusion为长音频ASR提供了高效的新解决方案，代码已开源。

Abstract: Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive
applications such as real-time captioning and meeting transcription. However,
truly parallel ASR decoding remains challenging due to the sequential nature of
autoregressive (AR) decoders and the context limitations of non-autoregressive
(NAR) methods. While modern ASR encoders can process up to 30 seconds of audio
at once, AR decoders still generate tokens sequentially, creating a latency
bottleneck. We propose Whisfusion, the first framework to fuse a pre-trained
Whisper encoder with a text diffusion decoder. This NAR architecture resolves
the AR latency bottleneck by processing the entire acoustic context in parallel
at every decoding step. A lightweight cross-attention adapter trained via
parameter-efficient fine-tuning (PEFT) bridges the two modalities. We also
introduce a batch-parallel, multi-step decoding strategy that improves accuracy
by increasing the number of candidates with minimal impact on speed. Fine-tuned
solely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny
(8.3% vs. 9.7%), and offers comparable latency on short audio. For longer
utterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a
new, efficient operating point for long-form ASR. The implementation and
training scripts are available at https://github.com/taeyoun811/Whisfusion.

</details>


### [305] [SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization](https://arxiv.org/abs/2508.07086)
*Beilong Tang,Xiaoxiao Miao,Xin Wang,Ming Li*

Main category: cs.SD

TL;DR: SEF-MK是一种新的语音匿名化框架，通过随机选择多个k-means模型之一来匿名化SSL表示，以保护说话者隐私。


<details>
  <summary>Details</summary>
Motivation: 保护说话者隐私，同时保留语言和副语言内容。

Method: 提出SEF-MK框架，使用多个k-means模型（每个模型基于不同说话者子集训练）随机匿名化SSL表示。

Result: 从用户角度看，SEF-MK更好地保留了语言和情感内容；但从攻击者角度看，多模型方法增加了隐私攻击的有效性。

Conclusion: SEF-MK在隐私保护和内容保留之间提供了权衡，有助于设计更安全的语音匿名化系统。

Abstract: Voice anonymization protects speaker privacy by concealing identity while
preserving linguistic and paralinguistic content. Self-supervised learning
(SSL) representations encode linguistic features but preserve speaker traits.
We propose a novel speaker-embedding-free framework called SEF-MK. Instead of
using a single k-means model trained on the entire dataset, SEF-MK anonymizes
SSL representations for each utterance by randomly selecting one of multiple
k-means models, each trained on a different subset of speakers. We explore this
approach from both attacker and user perspectives. Extensive experiments show
that, compared to a single k-means model, SEF-MK with multiple k-means models
better preserves linguistic and emotional content from the user's viewpoint.
However, from the attacker's perspective, utilizing multiple k-means models
boosts the effectiveness of privacy attacks. These insights can aid users in
designing voice anonymization systems to mitigate attacker threats.

</details>


### [306] [Inversion of Arctic dual-channel sound speed profile based on random airgun signal](https://arxiv.org/abs/2508.07152)
*Jinbao Weng,Yubo Qi,Yanming Yang,Hongtao Wen,Hongtao Zhou,Benqing Chen,Dewei Xu,Ruichao Xue,Caigao Zeng*

Main category: cs.SD

TL;DR: 提出了一种基于折射模态的双通道声速剖面反演方法，适用于北极地区的加拿大盆地和楚科奇高原，具有参数少、速度快、低成本等优势。


<details>
  <summary>Details</summary>
Motivation: 针对北极地区独特的双通道声速剖面特性，以及长距离声传播中声速剖面的水平变化问题，提出新的反演方法。

Method: 提出双参数表示法和折射模态的频散结构提取方法，结合两者实现双通道声速剖面反演，并解决水平变化问题。

Result: 通过北极低频远程声传播实验验证了方法的有效性，反演参数少、速度快，仅需单水听器被动接收随机气枪信号。

Conclusion: 该方法在低成本、易部署和快速计算方面具有显著优势，解决了声速剖面水平变化的反演问题。

Abstract: For the unique dual-channel sound speed profiles of the Canadian Basin and
the Chukchi Plateau in the Arctic, based on the propagation characteristics of
refracted normal modes under dual-channel sound speed profiles, an inversion
method using refracted normal modes for dual-channel sound speed profiles is
proposed. This method proposes a dual-parameter representation method for
dual-channel sound speed profiles, tailored to the characteristics of
dual-channel sound speed profiles. A dispersion structure extraction method is
proposed for the dispersion structure characteristics of refracted normal modes
under dual-channel sound speed profiles. Combining the parameter representation
method of sound speed profiles and the dispersion structure extraction method,
an inversion method for dual-channel sound speed profiles is proposed. For the
common horizontal variation of sound speed profiles in long-distance acoustic
propagation, a method for inverting horizontally varying dual-channel sound
speed profiles is proposed. Finally, this article verifies the effectiveness of
the dual-channel sound speed profile inversion method using the Arctic
low-frequency long-range acoustic propagation experiment. Compared with
previous sound speed profile inversion methods, the method proposed in this
article has the advantages of fewer inversion parameters and faster inversion
speed. It can be implemented using only a single hydrophone passively receiving
random air gun signals, and it also solves the inversion problem of horizontal
variation of sound speed profiles. It has significant advantages such as low
cost, easy deployment, and fast computation speed.

</details>


### [307] [Acoustic source depth estimation method based on a single hydrophone in Arctic underwater](https://arxiv.org/abs/2508.07157)
*Jinbao Weng,Yubo Qi,Yanming Yang,Hongtao Wen,Hongtao Zhou,Benqing Chen,Dewei Xu,Ruichao Xue,Caigao Zeng*

Main category: cs.SD

TL;DR: 本文基于简正波和射线理论，探讨了表层声源和接收的特性，提出了基于简正波频率上限的深度估计方法，并通过数据验证了不同方法的适用性和局限性。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探讨表层声源和接收的特性，并提出有效的深度估计方法，以解决声源深度估计问题。

Method: 采用简正波和射线理论，通过变形变换分离模式，利用简正波振幅随频率和模式数的变化特性，以及本征函数随频率的空间变化特性，提出匹配振幅信息和截止频率的深度估计方法。对于深海北极海域，通过分析深反转射线轨迹获取射线到达结构，利用射线到达时间差匹配估计声源深度。

Result: 实验数据验证了声场模式和声源深度估计方法的有效性。

Conclusion: 提出的基于简正波和射线理论的深度估计方法在不同场景下具有适用性，但也存在一定局限性。

Abstract: Based on the normal mode and ray theory, this article discusses the
characteristics of surface sound source and reception at the surface layer, and
explores depth estimation methods based on normal modes and rays, and proposes
a depth estimation method based on the upper limit of modal frequency. Data
verification is conducted to discuss the applicability and limitations of
different methods. For the surface refracted normal mode waveguide, modes can
be separated through warping transformation. Based on the characteristics of
normal mode amplitude variation with frequency and number, the sound source
depth can be estimated by matching amplitude information. Based on the spatial
variation characteristics of eigenfunctions with frequency, a sound source
depth estimation method matching the cutoff frequency of normal modes is
proposed. For the deep Arctic sea, the sound ray arrival structure at the
receiving end is obtained through the analysis of deep inversion sound ray
trajectories, and the sound source depth can be estimated by matching the time
difference of ray arrivals. Experimental data is used to verify the sound field
patterns and the effectiveness of the sound source depth estimation method.

</details>


### [308] [Noise-Robust Sound Event Detection and Counting via Language-Queried Sound Separation](https://arxiv.org/abs/2508.07176)
*Yuanjian Chen,Yang Xiao,Han Yin,Yadong Guan,Xubo Liu*

Main category: cs.SD

TL;DR: 提出了一种基于事件出现检测（EAD）的多任务学习框架，用于提升噪声环境中的声音事件检测（SED）性能。


<details>
  <summary>Details</summary>
Motivation: 现有SED系统在噪声环境中性能显著下降，而语言查询音频源分离（LASS）模型缺乏明确的目标事件指导。

Method: 引入EAD计数方法，设计多任务学习框架，通过任务约束提升SED和EAD的预测一致性。

Result: 在DESED和WildDESED数据集上表现优于现有方法，噪声越高优势越明显。

Conclusion: 该框架为LASS模型提供了更可靠的预测，并增强了时间戳检测能力。

Abstract: Most sound event detection (SED) systems perform well on clean datasets but
degrade significantly in noisy environments. Language-queried audio source
separation (LASS) models show promise for robust SED by separating target
events; existing methods require elaborate multi-stage training and lack
explicit guidance for target events. To address these challenges, we introduce
event appearance detection (EAD), a counting-based approach that counts event
occurrences at both the clip and frame levels. Based on EAD, we propose a
co-training-based multi-task learning framework for EAD and SED to enhance
SED's performance in noisy environments. First, SED struggles to learn the same
patterns as EAD. Then, a task-based constraint is designed to improve
prediction consistency between SED and EAD. This framework provides more
reliable clip-level predictions for LASS models and strengthens timestamp
detection capability. Experiments on DESED and WildDESED datasets demonstrate
better performance compared to existing methods, with advantages becoming more
pronounced at higher noise levels.

</details>


### [309] [Keyword Mamba: Spoken Keyword Spotting with State Space Models](https://arxiv.org/abs/2508.07363)
*Hanyu Ding,Wenlong Dong,Qirong Mao*

Main category: cs.SD

TL;DR: 提出了一种名为Keyword Mamba的新架构，用于关键词检测（KWS），采用神经状态空间模型（SSM）Mamba，在保持高效的同时解决了长期模式处理问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型（如CNN、RNN、Transformer）在KWS任务中表现良好，但难以同时处理长期模式并保持高效。

Method: 使用Mamba模型沿时间轴处理数据，并探索其替代Transformer中的自注意力机制。在Google Speech Commands数据集上进行测试。

Result: Keyword Mamba以更少的参数和更低的计算成本实现了高准确率。

Conclusion: Mamba在语音相关任务中具有潜力，这是首次将状态空间模型用于KWS。

Abstract: Keyword spotting (KWS) is an essential task in speech processing. It is
widely used in voice assistants and smart devices. Deep learning models like
CNNs, RNNs, and Transformers have performed well in KWS. However, they often
struggle to handle long-term patterns and stay efficient at the same time. In
this work, we present Keyword Mamba, a new architecture for KWS. It uses a
neural state space model (SSM) called Mamba. We apply Mamba along the time axis
and also explore how it can replace the self-attention part in Transformer
models. We test our model on the Google Speech Commands datasets. The results
show that Keyword Mamba reaches strong accuracy with fewer parameters and lower
computational cost. To our knowledge, this is the first time a state space
model has been used for KWS. These results suggest that Mamba has strong
potential in speech-related tasks.

</details>


### [310] [A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions](https://arxiv.org/abs/2508.07561)
*Yiheng Jiang,Tian Biao*

Main category: cs.SD

TL;DR: 本文提出了一种基于神经网络的声学回声消除（AEC）方法，适用于移动场景，通过数据增强和渐进学习提升鲁棒性，并引入后处理策略优化下游任务。


<details>
  <summary>Details</summary>
Motivation: 解决移动场景中硬件差异、非线性失真和高延迟带来的AEC挑战。

Method: 结合数据增强和渐进学习，设计小模型支持流式推理，并引入后处理策略优化VAD和ASR。

Result: 在回声损失增强和语音质量评估上表现优异，VAD和ASR效果显著提升。

Conclusion: 该方法在移动设备上高效部署，显著提升了AEC及其下游任务的性能。

Abstract: In full-duplex speech interaction systems, effective Acoustic Echo
Cancellation (AEC) is crucial for recovering echo-contaminated speech. This
paper presents a neural network-based AEC solution to address challenges in
mobile scenarios with varying hardware, nonlinear distortions and long latency.
We first incorporate diverse data augmentation strategies to enhance the
model's robustness across various environments. Moreover, progressive learning
is employed to incrementally improve AEC effectiveness, resulting in a
considerable improvement in speech quality. To further optimize AEC's
downstream applications, we introduce a novel post-processing strategy
employing tailored parameters designed specifically for tasks such as Voice
Activity Detection (VAD) and Automatic Speech Recognition (ASR), thus enhancing
their overall efficacy. Finally, our method employs a small-footprint model
with streaming inference, enabling seamless deployment on mobile devices.
Empirical results demonstrate effectiveness of the proposed method in Echo
Return Loss Enhancement and Perceptual Evaluation of Speech Quality, alongside
significant improvements in both VAD and ASR results.

</details>


### [311] [Exploring Efficient Directional and Distance Cues for Regional Speech Separation](https://arxiv.org/abs/2508.07563)
*Yiheng Jiang,Haoxu Wang,Yafeng Chen,Gang Qiao,Biao Tian*

Main category: cs.SD

TL;DR: 提出了一种基于神经网络的区域语音分离方法，利用麦克风阵列和空间线索，结合改进的延迟求和技术和直达混响比，显著提升分离效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统语音分离方法在指定方向和距离范围内提取声源的局限性，提升实际应用中的分离性能。

Method: 采用改进的延迟求和技术获取方向线索，并结合直达混响比作为输入特征，增强模型对距离范围内声源的区分能力。

Result: 实验表明，该方法在多个客观指标上显著提升，并在CHiME-8 MMCSG数据集上达到最优性能。

Conclusion: 该方法在真实场景的语音分离中表现出色，具有实际应用潜力。

Abstract: In this paper, we introduce a neural network-based method for regional speech
separation using a microphone array. This approach leverages novel spatial cues
to extract the sound source not only from specified direction but also within
defined distance. Specifically, our method employs an improved delay-and-sum
technique to obtain directional cues, substantially enhancing the signal from
the target direction. We further enhance separation by incorporating the
direct-to-reverberant ratio into the input features, enabling the model to
better discriminate sources within and beyond a specified distance.
Experimental results demonstrate that our proposed method leads to substantial
gains across multiple objective metrics. Furthermore, our method achieves
state-of-the-art performance on the CHiME-8 MMCSG dataset, which was recorded
in real-world conversational scenarios, underscoring its effectiveness for
speech separation in practical applications.

</details>


### [312] [Filling MIDI Velocity using U-Net Image Colorizer](https://arxiv.org/abs/2508.07751)
*Zhanhong He,David Cooper,Defeng Huang,Roberto Togneri*

Main category: cs.SD

TL;DR: 本文提出了一种基于U-Net架构的方法，用于预测MIDI文件中的音符力度（velocity），以增强音乐表现力。通过将MIDI数据视为图像，并结合窗口注意力和自定义损失函数，该方法在MAESTRO v3和SMD数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代音乐制作中，MIDI文件通常缺乏人类演奏的表现力，尤其是音符力度参数常被忽略。本文旨在通过预测MIDI力度来提升音乐的表现力。

Method: 采用U-Net架构，将MIDI数据视为图像处理，引入窗口注意力和自定义损失函数以解决数据稀疏问题。实验限于钢琴数据。

Result: 在MAESTRO v3和SMD数据集上，该方法在定量指标和定性听觉测试中均优于现有方法。

Conclusion: 通过U-Net架构和自定义损失函数，本文成功提升了MIDI力度预测的准确性和音乐表现力。

Abstract: Modern music producers commonly use MIDI (Musical Instrument Digital
Interface) to store their musical compositions. However, MIDI files created
with digital software may lack the expressive characteristics of human
performances, essentially leaving the velocity parameter - a control for note
loudness - undefined, which defaults to a flat value. The task of filling MIDI
velocity is termed MIDI velocity prediction, which uses regression models to
enhance music expressiveness by adjusting only this parameter. In this paper,
we introduce the U-Net, a widely adopted architecture in image colorization, to
this task. By conceptualizing MIDI data as images, we adopt window attention
and develop a custom loss function to address the sparsity of MIDI-converted
images. Current dataset availability restricts our experiments to piano data.
Evaluated on the MAESTRO v3 and SMD datasets, our proposed method for filling
MIDI velocity outperforms previous approaches in both quantitative metrics and
qualitative listening tests.

</details>


### [313] [SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis](https://arxiv.org/abs/2508.07944)
*Vojtěch Staněk,Karel Srna,Anton Firc,Kamil Malinka*

Main category: cs.SD

TL;DR: 论文提出了SCDF数据集，用于系统评估深度伪造语音检测中的偏见问题，发现检测性能受说话者特征影响显著。


<details>
  <summary>Details</summary>
Motivation: 深度伪造语音检测中的偏见和公平性问题尚未充分研究，需要填补这一空白。

Method: 引入SCDF数据集，包含超过237,000条语音，覆盖性别、语言、年龄和合成器类型，并评估多种先进检测器。

Result: 检测性能在性别、语言、年龄和合成器类型上存在显著差异，揭示了偏见问题。

Conclusion: 研究强调了开发无偏见检测系统的重要性，为符合伦理和监管标准的系统提供了基础。

Abstract: Despite growing attention to deepfake speech detection, the aspects of bias
and fairness remain underexplored in the speech domain. To address this gap, we
introduce the Speaker Characteristics Deepfake (SCDF) dataset: a novel, richly
annotated resource enabling systematic evaluation of demographic biases in
deepfake speech detection. SCDF contains over 237,000 utterances in a balanced
representation of both male and female speakers spanning five languages and a
wide age range. We evaluate several state-of-the-art detectors and show that
speaker characteristics significantly influence detection performance,
revealing disparities across sex, language, age, and synthesizer type. These
findings highlight the need for bias-aware development and provide a foundation
for building non-discriminatory deepfake detection systems aligned with ethical
and regulatory standards.

</details>


### [314] [Joint Transcription of Acoustic Guitar Strumming Directions and Chords](https://arxiv.org/abs/2508.07973)
*Sebastian Murgul,Johannes Schimper,Michael Heizmann*

Main category: cs.SD

TL;DR: 论文提出了一种基于深度学习的吉他扫弦自动转录方法，通过引入新数据集和CRNN模型，显著提升了扫弦方向和和弦识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 吉他扫弦自动转录在MIR中研究较少且具有挑战性，现有方法因数据集有限而效果受限。

Method: 使用ESP32智能手表运动传感器收集90分钟真实吉他录音，并辅以4小时合成数据，训练CRNN模型进行扫弦事件检测、方向分类及和弦识别。

Result: 混合合成与真实数据的方法在扫弦检测与和弦分类上表现最佳，显著优于基线算法。

Conclusion: 深度学习在吉他扫弦转录中潜力巨大，为自动节奏吉他分析开辟了新途径。

Abstract: Automatic transcription of guitar strumming is an underrepresented and
challenging task in Music Information Retrieval (MIR), particularly for
extracting both strumming directions and chord progressions from audio signals.
While existing methods show promise, their effectiveness is often hindered by
limited datasets. In this work, we extend a multimodal approach to guitar
strumming transcription by introducing a novel dataset and a deep
learning-based transcription model. We collect 90 min of real-world guitar
recordings using an ESP32 smartwatch motion sensor and a structured recording
protocol, complemented by a synthetic dataset of 4h of labeled strumming audio.
A Convolutional Recurrent Neural Network (CRNN) model is trained to detect
strumming events, classify their direction, and identify the corresponding
chords using only microphone audio. Our evaluation demonstrates significant
improvements over baseline onset detection algorithms, with a hybrid method
combining synthetic and real-world data achieving the highest accuracy for both
strumming action detection and chord classification. These results highlight
the potential of deep learning for robust guitar strumming transcription and
open new avenues for automatic rhythm guitar analysis.

</details>


### [315] [Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription](https://arxiv.org/abs/2508.07987)
*Sebastian Murgul,Michael Heizmann*

Main category: cs.SD

TL;DR: 论文探讨了通过合成数据训练吉他指弹转录模型的方法，解决了真实数据稀缺和法律限制的问题。


<details>
  <summary>Details</summary>
Motivation: 由于标记训练数据的稀缺性和音乐录音的法律限制，自动转录吉他指弹表演具有挑战性。

Method: 采用四阶段合成数据生成流程：基于知识的指弹谱编写、MIDI表演渲染、扩展Karplus-Strong算法的物理建模、音频增强（如混响和失真）。

Result: 在真实和合成数据集上训练的CRNN模型显示，合成数据可实现合理的音符追踪效果，少量真实数据微调后效果更佳。

Conclusion: 程序化生成的音频在数据稀缺的音乐信息检索任务中具有潜力。

Abstract: Automatic transcription of acoustic guitar fingerpicking performances remains
a challenging task due to the scarcity of labeled training data and legal
constraints connected with musical recordings. This work investigates a
procedural data generation pipeline as an alternative to real audio recordings
for training transcription models. Our approach synthesizes training data
through four stages: knowledge-based fingerpicking tablature composition, MIDI
performance rendering, physical modeling using an extended Karplus-Strong
algorithm, and audio augmentation including reverb and distortion. We train and
evaluate a CRNN-based note-tracking model on both real and synthetic datasets,
demonstrating that procedural data can be used to achieve reasonable
note-tracking results. Finetuning with a small amount of real data further
enhances transcription accuracy, improving over models trained exclusively on
real recordings. These results highlight the potential of procedurally
generated audio for data-scarce music information retrieval tasks.

</details>


### [316] [Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches](https://arxiv.org/abs/2508.08027)
*Ahmed Aboeitta,Ahmed Sharshar,Youssef Nafea,Shady Shehata*

Main category: cs.SD

TL;DR: 该研究评估了自监督ASR模型（如Wav2Vec、HuBERT和Whisper）在构音障碍语音中的表现，并比较了不同解码策略（CTC、seq2seq和LLM增强解码）的效果。研究发现，LLM增强解码通过利用语言约束改善了构音障碍ASR的性能。


<details>
  <summary>Details</summary>
Motivation: 构音障碍语音因音素失真和高变异性导致ASR效果不佳，现有自监督ASR模型在此类语音上的表现尚不明确。

Method: 研究系统性地比较了多种ASR架构和解码策略（包括CTC、seq2seq和LLM增强解码），并分析了跨数据集的泛化能力和不同严重程度的识别错误。

Result: LLM增强解码（如BART、GPT-2、Vicuna）通过音素恢复和语法校正显著提升了构音障碍ASR的识别效果。

Conclusion: LLM增强解码为构音障碍ASR提供了有效的改进方向，未来可进一步优化语言约束的应用。

Abstract: Speech Recognition (ASR) due to phoneme distortions and high variability.
While self-supervised ASR models like Wav2Vec, HuBERT, and Whisper have shown
promise, their effectiveness in dysarthric speech remains unclear. This study
systematically benchmarks these models with different decoding strategies,
including CTC, seq2seq, and LLM-enhanced decoding (BART,GPT-2, Vicuna). Our
contributions include (1) benchmarking ASR architectures for dysarthric speech,
(2) introducing LLM-based decoding to improve intelligibility, (3) analyzing
generalization across datasets, and (4) providing insights into recognition
errors across severity levels. Findings highlight that LLM-enhanced decoding
improves dysarthric ASR by leveraging linguistic constraints for phoneme
restoration and grammatical correction.

</details>


### [317] [Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning](https://arxiv.org/abs/2508.08039)
*Shu Wu,Chenxing Li,Wenfu Wang,Hao Zhang,Hualei Wang,Meng Yu,Dong Yu*

Main category: cs.SD

TL;DR: 论文提出Audio-Thinker框架，通过强化学习提升大型音频语言模型（LALMs）的推理能力，解决现有模型在音频问答中推理不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LALMs在音频问答中的显式推理效果有限，未能达到人类听觉语言推理水平，需改进其适应性、一致性和有效性。

Method: 提出Audio-Thinker框架，引入自适应思维准确性奖励和外部奖励模型，动态调整推理策略并评估推理过程质量。

Result: 实验表明，Audio-Thinker在多种基准任务中优于现有推理导向的LALMs，表现出更强的推理和泛化能力。

Conclusion: Audio-Thinker通过强化学习显著提升了LALMs的推理能力，为音频问答任务提供了更有效的解决方案。

Abstract: Recent advancements in large language models, multimodal large language
models, and large audio language models (LALMs) have significantly improved
their reasoning capabilities through reinforcement learning with rule-based
rewards. However, the explicit reasoning process has yet to show significant
benefits for audio question answering, and effectively leveraging deep
reasoning remains an open challenge, with LALMs still falling short of
human-level auditory-language reasoning. To address these limitations, we
propose Audio-Thinker, a reinforcement learning framework designed to enhance
the reasoning capabilities of LALMs, with a focus on improving adaptability,
consistency, and effectiveness. Our approach introduces an adaptive think
accuracy reward, enabling the model to adjust its reasoning strategies based on
task complexity dynamically. Furthermore, we incorporate an external reward
model to evaluate the overall consistency and quality of the reasoning process,
complemented by think-based rewards that help the model distinguish between
valid and flawed reasoning paths during training. Experimental results
demonstrate that our Audio-Thinker model outperforms existing
reasoning-oriented LALMs across various benchmark tasks, exhibiting superior
reasoning and generalization capabilities.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [318] [Automated Seam Folding and Sewing Machine on Pleated Pants for Apparel Manufacturing](https://arxiv.org/abs/2508.06518)
*Ray Wai Man Kong*

Main category: cs.RO

TL;DR: 研究设计了一款自动化折叠与缝纫机，用于褶皱裤子的生产，显著提升了效率并减少了人工需求。


<details>
  <summary>Details</summary>
Motivation: 传统褶皱制作方法劳动密集、易出错且依赖高技能，自动化是服装行业的迫切需求。

Method: 开发了一款集成精确折叠机制和实时监控功能的自动化缝纫机，消除了标记操作。

Result: 劳动力时间减少93%，机器时间提升73%，总产出率增加72%，周期时间从117秒降至33秒。

Conclusion: 自动化显著提升了生产效率和可持续性，减少了材料浪费和能源消耗。

Abstract: The applied research is the design and development of an automated folding
and sewing machine for pleated pants. It represents a significant advancement
in addressing the challenges associated with manual sewing processes.
Traditional methods for creating pleats are labour-intensive, prone to
inconsistencies, and require high levels of skill, making automation a critical
need in the apparel industry. This research explores the technical feasibility
and operational benefits of integrating advanced technologies into garment
production, focusing on the creation of an automated machine capable of precise
folding and sewing operations and eliminating the marking operation.
  The proposed machine incorporates key features such as a precision folding
mechanism integrated into the automated sewing unit with real-time monitoring
capabilities. The results demonstrate remarkable improvements: the standard
labour time has been reduced by 93%, dropping from 117 seconds per piece to
just 8 seconds with the automated system. Similarly, machinery time improved by
73%, and the total output rate increased by 72%. These enhancements translate
into a cycle time reduction from 117 seconds per piece to an impressive 33
seconds, enabling manufacturers to meet customer demand more swiftly. By
eliminating manual marking processes, the machine not only reduces labour costs
but also minimizes waste through consistent pleat formation. This automation
aligns with industry trends toward sustainability and efficiency, potentially
reducing environmental impact by decreasing material waste and energy
consumption.

</details>


### [319] [Optimization of Flip-Landing Trajectories for Starship based on a Deep Learned Simulator](https://arxiv.org/abs/2508.06520)
*Liwei Chen,Tong Qin,Zhenhua Huangfu,Li Li,Wei Wei*

Main category: cs.RO

TL;DR: 提出了一种可微分优化框架，用于可重复使用航天器的翻转和着陆轨迹设计，结合深度学习与动力学求解器实现端到端优化。


<details>
  <summary>Details</summary>
Motivation: 解决传统轨迹优化方法在高非线性复杂机动中的局限性，如线性化或凸松弛带来的问题。

Method: 使用深度神经网络代理模型预测气动力和力矩，并与可微分刚体动力学求解器紧密耦合，支持端到端梯度优化。

Result: 框架成功处理执行器限制和终端着陆约束，生成物理一致的优化控制序列。

Conclusion: 该框架为未来研究非定常气动力学、羽流相互作用和智能制导设计奠定了基础。

Abstract: We propose a differentiable optimization framework for flip-and-landing
trajectory design of reusable spacecraft, exemplified by the Starship vehicle.
A deep neural network surrogate, trained on high-fidelity CFD data, predicts
aerodynamic forces and moments, and is tightly coupled with a differentiable
rigid-body dynamics solver. This enables end-to-end gradient-based trajectory
optimization without linearization or convex relaxation. The framework handles
actuator limits and terminal landing constraints, producing physically
consistent, optimized control sequences. Both standard automatic
differentiation and Neural ODEs are applied to support long-horizon rollouts.
Results demonstrate the framework's effectiveness in modeling and optimizing
complex maneuvers with high nonlinearities. This work lays the groundwork for
future extensions involving unsteady aerodynamics, plume interactions, and
intelligent guidance design.

</details>


### [320] [Stinger Robot: A Self-Bracing Robotic Platform for Autonomous Drilling in Confined Underground Environments](https://arxiv.org/abs/2508.06521)
*H. Liu,L. S. Moreu,T. S. Andersen,V. V. Puche,M. Fumagalli*

Main category: cs.RO

TL;DR: 本文介绍了一种名为Stinger Robot的新型紧凑机器人平台，专为在废弃地下矿井中自主高力钻孔而设计，解决了传统钻机在狭窄、无结构环境中的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于废弃地下矿井环境狭窄、无结构且缺乏基础设施，传统钻机难以操作，因此需要一种新型机器人平台来解决这一问题。

Method: Stinger Robot采用机械自锁三腿支撑机制，结合力感知闭环控制策略，通过ROS 2实现的有限状态机动态调整腿部署，确保稳定性。

Result: 仿真和初步硬件测试表明，该机器人能在传统采矿设备无法工作的环境中自主稳定并钻孔。

Conclusion: 这是首个验证的集成分散力支撑和自主钻孔的机器人架构，为未来模块化机器人协作采矿奠定了基础。

Abstract: The increasing demand for critical raw materials has revitalized interest in
abandoned underground mines, which pose extreme challenges for conventional
drilling machinery due to confined, unstructured, and infrastructure-less
environments. This paper presents the Stinger Robot, a novel compact robotic
platform specifically designed for autonomous high-force drilling in such
settings. The robot features a mechanically self-locking tri-leg bracing
mechanism that enables stable anchoring to irregular tunnel surfaces. A key
innovation lies in its force-aware, closed-loop control strategy, which enables
force interaction with unstructured environments during bracing and drilling.
Implemented as a finite-state machine in ROS 2, the control policy dynamically
adapts leg deployment based on real-time contact feedback and load thresholds,
ensuring stability without external supports. We demonstrate, through
simulation and preliminary hardware tests, that the Stinger Robot can
autonomously stabilize and drill in conditions previously inaccessible to
nowadays mining machines. This work constitutes the first validated robotic
architecture to integrate distributed force-bracing and autonomous drilling in
underground environments, laying the groundwork for future collaborative mining
operations using modular robot systems.

</details>


### [321] [MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving](https://arxiv.org/abs/2508.06534)
*Aishan Liu,Jiakai Wang,Tianyuan Zhang,Hainan Li,Jiangfan Liu,Siyuan Liang,Yilong Ren,Xianglong Liu,Dacheng Tao*

Main category: cs.RO

TL;DR: MetAdv是一个新型对抗测试平台，用于评估自动驾驶系统的对抗鲁棒性，通过虚拟仿真与物理车辆反馈的紧密结合，实现动态、交互式的测试。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的对抗鲁棒性评估是一个关键但未解决的挑战，需要一种更现实和动态的测试方法。

Method: MetAdv采用三层闭环测试环境，结合虚拟与物理沙盒，支持从高层对抗生成到低层物理执行的端到端评估，并兼容多种AD任务和算法。

Result: MetAdv支持灵活的3D车辆建模、虚拟与物理环境的无缝切换，并具备人机交互能力，可实时捕获驾驶员生理信号和行为反馈。

Conclusion: MetAdv为对抗评估提供了一个可扩展的统一框架，有助于推动更安全的自动驾驶技术发展。

Abstract: Evaluating and ensuring the adversarial robustness of autonomous driving (AD)
systems is a critical and unresolved challenge. This paper introduces MetAdv, a
novel adversarial testing platform that enables realistic, dynamic, and
interactive evaluation by tightly integrating virtual simulation with physical
vehicle feedback. At its core, MetAdv establishes a hybrid virtual-physical
sandbox, within which we design a three-layer closed-loop testing environment
with dynamic adversarial test evolution. This architecture facilitates
end-to-end adversarial evaluation, ranging from high-level unified adversarial
generation, through mid-level simulation-based interaction, to low-level
execution on physical vehicles. Additionally, MetAdv supports a broad spectrum
of AD tasks, algorithmic paradigms (e.g., modular deep learning pipelines,
end-to-end learning, vision-language models). It supports flexible 3D vehicle
modeling and seamless transitions between simulated and physical environments,
with built-in compatibility for commercial platforms such as Apollo and Tesla.
A key feature of MetAdv is its human-in-the-loop capability: besides flexible
environmental configuration for more customized evaluation, it enables
real-time capture of physiological signals and behavioral feedback from
drivers, offering new insights into human-machine trust under adversarial
conditions. We believe MetAdv can offer a scalable and unified framework for
adversarial assessment, paving the way for safer AD.

</details>


### [322] [Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots](https://arxiv.org/abs/2508.06538)
*Gioele Buriani,Jingyue Liu,Maximilian Stölzle,Cosimo Della Santina,Jiatao Ding*

Main category: cs.RO

TL;DR: 本文提出了一种结合SINDy和物理结构先验的新方法，用于构建四足机器人跳跃的可解释降阶模型，其精度优于传统aSLIP模型。


<details>
  <summary>Details</summary>
Motivation: 四足机器人的运动规划和控制需要简化的动态模型，但需保留关键行为。本文旨在解决高维非线性跳跃动态的低维建模问题。

Method: 提出了一种结合Sparse Identification of Nonlinear Dynamics (SINDy)和物理结构先验的学习架构，用于捕捉跳跃动态的低维表示。

Result: 新方法在仿真和硬件实验中表现出比传统aSLIP模型更高的精度，适用于多种跳跃策略。

Conclusion: 该方法为四足机器人跳跃提供了更准确的降阶模型，具有实际应用潜力。

Abstract: Reduced-order models are essential for motion planning and control of
quadruped robots, as they simplify complex dynamics while preserving critical
behaviors. This paper introduces a novel methodology for deriving such
interpretable dynamic models, specifically for jumping. We capture the
high-dimensional, nonlinear jumping dynamics in a low-dimensional latent space
by proposing a learning architecture combining Sparse Identification of
Nonlinear Dynamics (SINDy) with physical structural priors on the jump
dynamics. Our approach demonstrates superior accuracy to the traditional
actuated Spring-loaded Inverted Pendulum (aSLIP) model and is validated through
simulation and hardware experiments across different jumping strategies.

</details>


### [323] [A tutorial note on collecting simulated data for vision-language-action models](https://arxiv.org/abs/2508.06547)
*Heran Wu,Zirun Zhou,Jingfeng Zhang*

Main category: cs.RO

TL;DR: VLA模型通过单一神经网络统一处理视觉、语言和动作，但依赖高质量数据集。本文介绍了PyBullet、LIBERO和RT-X三种数据集生成与评估工具。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统将智能分解为独立模块，VLA模型通过统一框架提升效率，但需高质量数据集支持。

Method: 使用PyBullet模拟生成数据，LIBERO定义标准化任务，RT-X收集大规模多机器人数据。

Result: 展示了PyBullet和LIBERO的数据生成方法，并概述了RT-X的特点与作用。

Conclusion: VLA模型依赖高质量数据集，PyBullet、LIBERO和RT-X为数据生成与评估提供了有效工具。

Abstract: Traditional robotic systems typically decompose intelligence into independent
modules for computer vision, natural language processing, and motion control.
Vision-Language-Action (VLA) models fundamentally transform this approach by
employing a single neural network that can simultaneously process visual
observations, understand human instructions, and directly output robot actions
-- all within a unified framework. However, these systems are highly dependent
on high-quality training datasets that can capture the complex relationships
between visual observations, language instructions, and robotic actions. This
tutorial reviews three representative systems: the PyBullet simulation
framework for flexible customized data generation, the LIBERO benchmark suite
for standardized task definition and evaluation, and the RT-X dataset
collection for large-scale multi-robot data acquisition. We demonstrated
dataset generation approaches in PyBullet simulation and customized data
collection within LIBERO, and provide an overview of the characteristics and
roles of the RT-X dataset for large-scale multi-robot data acquisition.

</details>


### [324] [AquaChat++: LLM-Assisted Multi-ROV Inspection for Aquaculture Net Pens with Integrated Battery Management and Thruster Fault Tolerance](https://arxiv.org/abs/2508.06554)
*Abdelhaleem Saad,Waseem Akram,Irfan Hussain*

Main category: cs.RO

TL;DR: AquaChat++是一个基于大型语言模型的多ROV检测框架，用于提升水产养殖网箱检查的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统水产养殖网箱检查方法适应性差，无法应对实时约束（如能耗、硬件故障等），需要更智能的解决方案。

Method: 采用双层架构：高层使用LLM（如ChatGPT-4）将自然语言指令转化为多代理检测计划；低层实现精确轨迹跟踪和故障补偿。

Result: 模拟实验显示，AquaChat++提高了检测覆盖率、能效和故障恢复能力。

Conclusion: LLM驱动的框架为水产养殖领域提供了可扩展、智能且自主的水下机器人操作方案。

Abstract: Inspection of aquaculture net pens is essential for ensuring the structural
integrity and sustainable operation of offshore fish farming systems.
Traditional methods, typically based on manually operated or single-ROV
systems, offer limited adaptability to real-time constraints such as energy
consumption, hardware faults, and dynamic underwater conditions. This paper
introduces AquaChat++, a novel multi-ROV inspection framework that uses Large
Language Models (LLMs) to enable adaptive mission planning, coordinated task
execution, and fault-tolerant control in complex aquaculture environments. The
proposed system consists of a two-layered architecture. The high-level plan
generation layer employs an LLM, such as ChatGPT-4, to translate natural
language user commands into symbolic, multi-agent inspection plans. A task
manager dynamically allocates and schedules actions among ROVs based on their
real-time status and operational constraints, including thruster faults and
battery levels. The low-level control layer ensures accurate trajectory
tracking and integrates thruster fault detection and compensation mechanisms.
By incorporating real-time feedback and event-triggered replanning, AquaChat++
enhances system robustness and operational efficiency. Simulated experiments in
a physics-based aquaculture environment demonstrate improved inspection
coverage, energy-efficient behavior, and resilience to actuator failures. These
findings highlight the potential of LLM-driven frameworks to support scalable,
intelligent, and autonomous underwater robotic operations within the
aquaculture sector.

</details>


### [325] [Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey](https://arxiv.org/abs/2508.07163)
*Kamal Acharya,Iman Sharifi,Mehul Lad,Liang Sun,Houbing Song*

Main category: cs.RO

TL;DR: 神经符号AI结合神经网络适应性与符号推理，为高级空中交通（AAM）的复杂监管、运营和安全挑战提供解决方案。本文综述了其在需求预测、飞机设计和实时空中交通管理等领域的应用，揭示了一个分散的研究现状，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 高级空中交通（AAM）面临复杂的监管、运营和安全挑战，神经符号AI有望通过结合神经网络的适应性和符号推理能力解决这些问题。

Method: 通过综述神经符号AI在AAM关键领域的应用（如需求预测、飞机设计、实时空中交通管理），分析现有方法（如神经符号强化学习）的潜力与挑战。

Result: 研究发现神经符号AI在动态优化方面具有潜力，但在可扩展性、鲁棒性和航空标准合规性方面仍存在障碍。

Conclusion: 本文为研究人员和从业者提供了将神经符号AI整合到可靠、透明的AAM系统中的路线图，并指出了未来研究方向。

Abstract: Neurosymbolic AI combines neural network adaptability with symbolic
reasoning, promising an approach to address the complex regulatory,
operational, and safety challenges in Advanced Air Mobility (AAM). This survey
reviews its applications across key AAM domains such as demand forecasting,
aircraft design, and real-time air traffic management. Our analysis reveals a
fragmented research landscape where methodologies, including Neurosymbolic
Reinforcement Learning, have shown potential for dynamic optimization but still
face hurdles in scalability, robustness, and compliance with aviation
standards. We classify current advancements, present relevant case studies, and
outline future research directions aimed at integrating these approaches into
reliable, transparent AAM systems. By linking advanced AI techniques with AAM's
operational demands, this work provides a concise roadmap for researchers and
practitioners developing next-generation air mobility solutions.

</details>


### [326] [Robust and Agile Quadrotor Flight via Adaptive Unwinding-Free Quaternion Sliding Mode Control](https://arxiv.org/abs/2508.06568)
*Amin Yazdanshenas,Reza Faieghi*

Main category: cs.RO

TL;DR: 提出了一种新型自适应滑模控制（SMC）框架，用于四旋翼飞行器，在计算资源受限的情况下实现鲁棒和敏捷飞行。


<details>
  <summary>Details</summary>
Motivation: 解决现有SMC方法的局限性，包括收敛慢、全局稳定性不足、旋转动力学简化、解绕现象和增益增长问题。

Method: 利用非光滑稳定性分析，设计基于S³的姿态滑动动力学和位置滑动动力学，确保全局稳定性。

Result: 在资源受限的纳米四旋翼上高效运行（250Hz和500Hz刷新率），在130多次飞行试验中优于基准方法，实现高精度轨迹跟踪和鲁棒性。

Conclusion: 该控制器在外部干扰和计算限制下表现出色，适用于需要高性能飞行控制的实际应用。

Abstract: This paper presents a new adaptive sliding mode control (SMC) framework for
quadrotors that achieves robust and agile flight under tight computational
constraints. The proposed controller addresses key limitations of prior SMC
formulations, including (i) the slow convergence and almost-global stability of
$\mathrm{SO(3)}$-based methods, (ii) the oversimplification of rotational
dynamics in Euler-based controllers, (iii) the unwinding phenomenon in
quaternion-based formulations, and (iv) the gain overgrowth problem in adaptive
SMC schemes. Leveraging nonsmooth stability analysis, we provide rigorous
global stability proofs for both the nonsmooth attitude sliding dynamics
defined on $\mathbb{S}^3$ and the position sliding dynamics. Our controller is
computationally efficient and runs reliably on a resource-constrained nano
quadrotor, achieving 250 Hz and 500 Hz refresh rates for position and attitude
control, respectively. In an extensive set of hardware experiments with over
130 flight trials, the proposed controller consistently outperforms three
benchmark methods, demonstrating superior trajectory tracking accuracy and
robustness with relatively low control effort. The controller enables
aggressive maneuvers such as dynamic throw launches, flip maneuvers, and
accelerations exceeding 3g, which is remarkable for a 32-gram nano quadrotor.
These results highlight promising potential for real-world applications,
particularly in scenarios requiring robust, high-performance flight control
under significant external disturbances and tight computational constraints.

</details>


### [327] [Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios](https://arxiv.org/abs/2508.06575)
*Rui Zhou*

Main category: cs.RO

TL;DR: 该研究提出了一种自适应大变量邻域模拟退火算法（ALVNS-SA），用于加速自动驾驶车辆在安全关键场景中的测试效率，显著提升了覆盖率和识别能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的安全验证在开发和部署中至关重要，尤其是在安全关键场景下，需要高效的测试方法。

Method: 研究从真实事故数据库中提取典型逻辑场景，集成百度Apollo系统控制车辆行为，并设计ALVNS-SA算法加速测试。

Result: ALVNS-SA在安全关键场景中覆盖率显著提升（84.00%），其中碰撞场景覆盖率达96.83%，接近碰撞场景覆盖率达92.07%。

Conclusion: ALVNS-SA算法在测试效率和覆盖率上优于其他方法，为自动驾驶车辆的安全验证提供了有效工具。

Abstract: Ensuring the safety of autonomous vehicles (AVs) is paramount in their
development and deployment. Safety-critical scenarios pose more severe
challenges, necessitating efficient testing methods to validate AVs safety.
This study focuses on designing an accelerated testing algorithm for AVs in
safety-critical scenarios, enabling swift recognition of their driving
capabilities. First, typical logical scenarios were extracted from real-world
crashes in the China In-depth Mobility Safety Study-Traffic Accident (CIMSS-TA)
database, obtaining pre-crash features through reconstruction. Second, Baidu
Apollo, an advanced black-box automated driving system (ADS) is integrated to
control the behavior of the ego vehicle. Third, we proposed an adaptive
large-variable neighborhood-simulated annealing algorithm (ALVNS-SA) to
expedite the testing process. Experimental results demonstrate a significant
enhancement in testing efficiency when utilizing ALVNS-SA. It achieves an
84.00% coverage of safety-critical scenarios, with crash scenario coverage of
96.83% and near-crash scenario coverage of 92.07%. Compared to genetic
algorithm (GA), adaptive large neighborhood-simulated annealing algorithm
(ALNS-SA), and random testing, ALVNS-SA exhibits substantially higher coverage
in safety-critical scenarios.

</details>


### [328] [Optimal Planning and Machine Learning for Responsive Tracking and Enhanced Forecasting of Wildfires using a Spacecraft Constellation](https://arxiv.org/abs/2508.06687)
*Sreeja Roy-Singh,Vinay Ravindra,Richard Levinson,Mahta Moghaddam,Jan Mandel,Adam Kochanski,Angel Farguell Caus,Kurtis Nelson,Samira Alkaee Taleghan,Archana Kannan,Amer Melebari*

Main category: cs.RO

TL;DR: 论文提出了一种结合最优规划和机器学习的方法，用于收集和处理太空数据以监测野火，并改进现有的决策支持工具。


<details>
  <summary>Details</summary>
Motivation: 通过优化数据收集和处理流程，提高野火监测的准确性和时效性，支持消防员的实时决策。

Method: 采用混合整数规划调度卫星观测和数据下传，结合机器学习预测野火，并生成燃烧区域地图。

Result: 实验表明，该方法能捕捉98-100%的观测机会，预测准确率提升40%，燃烧区域地图和土壤湿度数据首次整合到火灾危险地图中。

Conclusion: 提出的工作流程显著提升了野火监测的效率和准确性，具有计算可扩展性和全球适用性。

Abstract: We propose a novel concept of operations using optimal planning methods and
machine learning (ML) to collect spaceborne data that is unprecedented for
monitoring wildfires, process it to create new or enhanced products in the
context of wildfire danger or spread monitoring, and assimilate them to improve
existing, wildfire decision support tools delivered to firefighters within
latency appropriate for time-critical applications. The concept is studied with
respect to NASA's CYGNSS Mission, a constellation of passive microwave
receivers that measure specular GNSS-R reflections despite clouds and smoke.
Our planner uses a Mixed Integer Program formulation to schedule joint
observation data collection and downlink for all satellites. Optimal solutions
are found quickly that collect 98-100% of available observation opportunities.
ML-based fire predictions that drive the planner objective are greater than 40%
more correlated with ground truth than existing state-of-art. The presented
case study on the TX Smokehouse Creek fire in 2024 and LA fires in 2025
represents the first high-resolution data collected by CYGNSS of active fires.
Creation of Burnt Area Maps (BAM) using ML applied to the data during active
fires and BAM assimilation into NASA's Weather Research and Forecasting Model
using ML to broadcast fire spread are novel outcomes. BAM and CYGNSS obtained
soil moisture are integrated for the first time into USGS fire danger maps.
Inclusion of CYGNSS data in ML-based burn predictions boosts accuracy by 13%,
and inclusion of high-resolution data boosts ML recall by another 15%. The
proposed workflow has an expected latency of 6-30h, improving on the current
delivery time of multiple days. All components in the proposed concept are
shown to be computationally scalable and globally generalizable, with
sustainability considerations such as edge efficiency and low latency on small
devices.

</details>


### [329] [Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC](https://arxiv.org/abs/2508.06722)
*Justin London*

Main category: cs.RO

TL;DR: 论文提出ORCA-FL算法，通过模糊逻辑控制器改进ORCA，以更好地处理路径规划中的不确定性和不精确性，实验表明其在多智能体环境中能减少碰撞次数。


<details>
  <summary>Details</summary>
Motivation: 现有碰撞避免算法（如DWA、TEB、RVO）存在路径次优、计算成本高或动态适应性不足的问题，ORCA虽改进RVO但仍需优化。

Method: 使用模糊逻辑控制器（FLCs）改进ORCA，提出ORCA-FL算法，并通过模糊Q强化学习（FQL）进一步优化FLCs。

Result: 实验表明，ORCA-FL在智能体速度超过阈值时能减少碰撞次数，优于ORCA。

Conclusion: ORCA-FL通过模糊逻辑和强化学习提升了动态环境中的碰撞避免性能，为多智能体路径规划提供了更优解决方案。

Abstract: Obstacle avoidance enables autonomous agents and robots to operate safely and
efficiently in dynamic and complex environments, reducing the risk of
collisions and damage. For a robot or autonomous system to successfully
navigate through obstacles, it must be able to detect such obstacles. While
numerous collision avoidance algorithms like the dynamic window approach (DWA),
timed elastic bands (TEB), and reciprocal velocity obstacles (RVO) have been
proposed, they may lead to suboptimal paths due to fixed weights, be
computationally expensive, or have limited adaptability to dynamic obstacles in
multi-agent environments. Optimal reciprocal collision avoidance (ORCA), which
improves on RVO, provides smoother trajectories and stronger collision
avoidance guarantees. We propose ORCA-FL to improve on ORCA by using fuzzy
logic controllers (FLCs) to better handle uncertainty and imprecision for
obstacle avoidance in path planning. Numerous multi-agent experiments are
conducted and it is shown that ORCA-FL can outperform ORCA in reducing the
number of collision if the agent has a velocity that exceeds a certain
threshold. In addition, a proposed algorithm for improving ORCA-FL using fuzzy
Q reinforcement learning (FQL) is detailed for optimizing and tuning FLCs.

</details>


### [330] [Learning Causal Structure Distributions for Robust Planning](https://arxiv.org/abs/2508.06742)
*Alejandro Murillo-Gonzalez,Junhong Xu,Lantao Liu*

Main category: cs.RO

TL;DR: 论文提出了一种结合结构因果模型和功能关系学习的方法，提高了机器人动力学模型的鲁棒性，同时降低了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 传统模型学习方法忽略了因果结构，未能利用机器人系统中交互的稀疏性。本文旨在通过学习功能关系并考虑结构信息的不确定性，提升模型的鲁棒性和效率。

Method: 通过估计因果结构分布，采样因果图以指导编码器-多解码器概率模型中的潜在空间表示。

Result: 模型能够学习机器人动力学，结合采样规划器在新环境中执行任务，并在仿真和实际机器人中验证了其适应性和鲁棒性。

Conclusion: 该方法显著提升了动力学模型的鲁棒性和适应性，适用于复杂现实场景。

Abstract: Structural causal models describe how the components of a robotic system
interact. They provide both structural and functional information about the
relationships that are present in the system. The structural information
outlines the variables among which there is interaction. The functional
information describes how such interactions work, via equations or learned
models. In this paper we find that learning the functional relationships while
accounting for the uncertainty about the structural information leads to more
robust dynamics models which improves downstream planning, while using
significantly lower computational resources. This in contrast with common
model-learning methods that ignore the causal structure and fail to leverage
the sparsity of interactions in robotic systems. We achieve this by estimating
a causal structure distribution that is used to sample causal graphs that
inform the latent-space representations in an encoder-multidecoder
probabilistic model. We show that our model can be used to learn the dynamics
of a robot, which together with a sampling-based planner can be used to perform
new tasks in novel environments, provided an objective function for the new
requirement is available. We validate our method using manipulators and mobile
robots in both simulation and the real-world. Additionally, we validate the
learned dynamics' adaptability and increased robustness to corrupted inputs and
changes in the environment, which is highly desirable in challenging real-world
robotics scenarios. Video: https://youtu.be/X6k5t7OOnNc.

</details>


### [331] [Robust-Sub-Gaussian Model Predictive Control for Safe Ultrasound-Image-Guided Robotic Spinal Surgery](https://arxiv.org/abs/2508.06744)
*Yunke Ao,Manish Prajapat,Yarden As,Yassine Taoudi-Benchekroun,Fabio Carrillo,Hooman Esfandiari,Benjamin F. Grewe,Andreas Krause,Philipp Fürnstahl*

Main category: cs.RO

TL;DR: 论文提出了一种针对高维感官反馈（如光学数据）的安全关键控制方法，通过子高斯噪声建模估计误差，并结合鲁棒集方法和方差代理传播技术，为线性系统提供闭环安全保证。


<details>
  <summary>Details</summary>
Motivation: 高维感官反馈（如图像、点云）在自动驾驶和机器人手术等领域的安全关键控制中，估计误差分布复杂且难以建模，导致传统概率模型无法提供正式安全保证。

Method: 提出子高斯噪声建模估计误差，结合鲁棒集方法和方差代理传播技术，开发了一种模型预测控制（MPC）框架，应用于超声图像引导的机器人脊柱手术流程。

Result: 在仿真环境中验证了方法的有效性，展示了其在复杂图像引导机器人手术任务中的潜力，同时确保安全性。

Conclusion: 该方法为高维感官反馈的安全关键控制提供了新思路，尤其在机器人手术等复杂任务中具有应用前景。

Abstract: Safety-critical control using high-dimensional sensory feedback from optical
data (e.g., images, point clouds) poses significant challenges in domains like
autonomous driving and robotic surgery. Control can rely on low-dimensional
states estimated from high-dimensional data. However, the estimation errors
often follow complex, unknown distributions that standard probabilistic models
fail to capture, making formal safety guarantees challenging. In this work, we
introduce a novel characterization of these general estimation errors using
sub-Gaussian noise with bounded mean. We develop a new technique for
uncertainty propagation of proposed noise characterization in linear systems,
which combines robust set-based methods with the propagation of sub-Gaussian
variance proxies. We further develop a Model Predictive Control (MPC) framework
that provides closed-loop safety guarantees for linear systems under the
proposed noise assumption. We apply this MPC approach in an
ultrasound-image-guided robotic spinal surgery pipeline, which contains
deep-learning-based semantic segmentation, image-based registration, high-level
optimization-based planning, and low-level robotic control. To validate the
pipeline, we developed a realistic simulation environment integrating real
human anatomy, robot dynamics, efficient ultrasound simulation, as well as
in-vivo data of breathing motion and drilling force. Evaluation results in
simulation demonstrate the potential of our approach for solving complex
image-guided robotic surgery task while ensuring safety.

</details>


### [332] [Learning a Vision-Based Footstep Planner for Hierarchical Walking Control](https://arxiv.org/abs/2508.06779)
*Minku Kim,Brian Acosta,Pratik Chaudhari,Michael Posa*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的分层控制框架，结合强化学习的高层脚步规划器和低层操作空间控制器，用于双足机器人在复杂地形中的实时脚步规划。


<details>
  <summary>Details</summary>
Motivation: 当前双足机器人的框架依赖本体感知或手动设计的视觉管道，在真实环境中脆弱且难以实时规划脚步。

Method: 采用强化学习的高层脚步规划器生成基于局部高程图的脚步指令，低层控制器跟踪轨迹，并使用角动量线性倒立摆模型简化状态表示。

Result: 在仿真和硬件实验中，使用双足机器人Cassie在不同地形条件下验证了方法的有效性。

Conclusion: 该框架展示了在复杂地形中实时脚步规划的潜力，但也面临一些挑战。

Abstract: Bipedal robots demonstrate potential in navigating challenging terrains
through dynamic ground contact. However, current frameworks often depend solely
on proprioception or use manually designed visual pipelines, which are fragile
in real-world settings and complicate real-time footstep planning in
unstructured environments. To address this problem, we present a vision-based
hierarchical control framework that integrates a reinforcement learning
high-level footstep planner, which generates footstep commands based on a local
elevation map, with a low-level Operational Space Controller that tracks the
generated trajectories. We utilize the Angular Momentum Linear Inverted
Pendulum model to construct a low-dimensional state representation to capture
an informative encoding of the dynamics while reducing complexity. We evaluate
our method across different terrain conditions using the underactuated bipedal
robot Cassie and investigate the capabilities and challenges of our approach
through simulation and hardware experiments.

</details>


### [333] [D3P: Dynamic Denoising Diffusion Policy via Reinforcement Learning](https://arxiv.org/abs/2508.06804)
*Shu-Ang Yu,Feng Gao,Yi Wu,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: D3P是一种动态去噪扩散策略，通过自适应分配去噪步骤来加速机器人任务的实时部署，同时保持任务成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人任务中关键动作和常规动作对任务成功的影响不同，但现有方法对所有动作采用固定去噪步骤，效率不足。

Method: 提出D3P，利用轻量级状态感知适配器动态分配去噪步骤，并通过强化学习联合优化适配器和基础扩散策略。

Result: 在模拟任务中，D3P实现了2.2倍的推理加速且成功率不降；在物理机器人上加速1.9倍。

Conclusion: D3P通过动态分配去噪步骤，显著提升了扩散策略的实时性能，适用于实际机器人任务。

Abstract: Diffusion policies excel at learning complex action distributions for robotic
visuomotor tasks, yet their iterative denoising process poses a major
bottleneck for real-time deployment. Existing acceleration methods apply a
fixed number of denoising steps per action, implicitly treating all actions as
equally important. However, our experiments reveal that robotic tasks often
contain a mix of \emph{crucial} and \emph{routine} actions, which differ in
their impact on task success. Motivated by this finding, we propose
\textbf{D}ynamic \textbf{D}enoising \textbf{D}iffusion \textbf{P}olicy
\textbf{(D3P)}, a diffusion-based policy that adaptively allocates denoising
steps across actions at test time. D3P uses a lightweight, state-aware adaptor
to allocate the optimal number of denoising steps for each action. We jointly
optimize the adaptor and base diffusion policy via reinforcement learning to
balance task performance and inference efficiency. On simulated tasks, D3P
achieves an averaged 2.2$\times$ inference speed-up over baselines without
degrading success. Furthermore, we demonstrate D3P's effectiveness on a
physical robot, achieving a 1.9$\times$ acceleration over the baseline.

</details>


### [334] [Vibration-Based Energy Metric for Restoring Needle Alignment in Autonomous Robotic Ultrasound](https://arxiv.org/abs/2508.06921)
*Zhongyu Chen,Chenyang Li,Xuesong Li,Dianye Huang,Zhongliang Jiang,Stefanie Speidel,Xiangyu Chu,K. W. Samuel Au*

Main category: cs.RO

TL;DR: 提出了一种通过周期性振动针头来恢复超声引导下针头对齐的方法，解决了针头在超声图像中不可见时的对齐问题。


<details>
  <summary>Details</summary>
Motivation: 针头对齐在机器人超声引导手术中至关重要，但超声图像中的噪声和低分辨率导致针头检测困难，尤其是在针头不可见时。

Method: 通过机械系统周期性振动针头，提出基于振动的能量度量，并开发控制策略调整超声探头位置以纠正对齐偏差。

Result: 实验结果显示，平移误差为0.41±0.27 mm，旋转误差为0.51±0.19度。

Conclusion: 该方法在针头不可见时仍能有效恢复对齐，提高了超声引导针头插入的鲁棒性。

Abstract: Precise needle alignment is essential for percutaneous needle insertion in
robotic ultrasound-guided procedures. However, inherent challenges such as
speckle noise, needle-like artifacts, and low image resolution make robust
needle detection difficult, particularly when visibility is reduced or lost. In
this paper, we propose a method to restore needle alignment when the ultrasound
imaging plane and the needle insertion plane are misaligned. Unlike many
existing approaches that rely heavily on needle visibility in ultrasound
images, our method uses a more robust feature by periodically vibrating the
needle using a mechanical system. Specifically, we propose a vibration-based
energy metric that remains effective even when the needle is fully out of
plane. Using this metric, we develop a control strategy to reposition the
ultrasound probe in response to misalignments between the imaging plane and the
needle insertion plane in both translation and rotation. Experiments conducted
on ex-vivo porcine tissue samples using a dual-arm robotic ultrasound-guided
needle insertion system demonstrate the effectiveness of the proposed approach.
The experimental results show the translational error of 0.41$\pm$0.27 mm and
the rotational error of 0.51$\pm$0.19 degrees.

</details>


### [335] [Manipulator for people with limited abilities](https://arxiv.org/abs/2508.06969)
*Bingkun Huang,Evgeniy Kotov,Arkady Yuschenko*

Main category: cs.RO

TL;DR: 开发四自由度机械手以辅助残障人士，结合机械设计、控制系统及ROS软件集成。


<details>
  <summary>Details</summary>
Motivation: 机器人技术进步为残障人士生活质量提升提供新可能，设计适配需求的机械手是重要挑战。

Method: 综合设计机械结构、开发控制系统，并与ROS技术视觉系统集成。

Result: 完成四自由度机械手的开发与制造，适合实际操控。

Conclusion: 该研究为残障人士辅助设备提供了实用解决方案，具有科学和实践意义。

Abstract: The topic of this final qualification work was chosen due to the importance
of developing robotic systems designed to assist people with disabilities.
Advances in robotics and automation technologies have opened up new prospects
for creating devices that can significantly improve the quality of life for
these people. In this context, designing a robotic hand with a control system
adapted to the needs of people with disabilities is a major scientific and
practical challenge. This work addresses the problem of developing and
manufacturing a four-degree-of-freedom robotic hand suitable for practical
manipulation. Addressing this issue requires a comprehensive approach,
encompassing the design of the hand's mechanical structure, the development of
its control system, and its integration with a technical vision system and
software based on the Robot Operating System (ROS).

</details>


### [336] [Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation](https://arxiv.org/abs/2508.06990)
*Yue Hu,Junzhe Wu,Ruihan Xu,Hang Liu,Avery Xi,Henry X. Liu,Ram Vasudevan,Maani Ghaffari*

Main category: cs.RO

TL;DR: SGImagineNav是一种新颖的语义导航框架，通过符号化世界建模和前瞻性场景预测，提升智能体在未知环境中的导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖过去观察，缺乏对未来场景的预测能力，导致导航效率低下。SGImagineNav旨在通过前瞻性建模和语义上下文丰富化，提升导航性能。

Method: SGImagineNav采用符号化世界建模，构建动态分层的场景图，并利用大语言模型预测未探索区域。结合自适应导航策略，根据语义捷径或探索未知区域动态调整路径。

Result: 在HM3D和HSSD基准测试中，SGImagineNav的成功率分别提升至65.4%和66.8%，并在真实环境中展示了跨楼层和跨房间导航能力。

Conclusion: SGImagineNav通过前瞻性场景预测和自适应策略，显著提升了语义导航的效率和泛化能力。

Abstract: Semantic navigation requires an agent to navigate toward a specified target
in an unseen environment. Employing an imaginative navigation strategy that
predicts future scenes before taking action, can empower the agent to find
target faster. Inspired by this idea, we propose SGImagineNav, a novel
imaginative navigation framework that leverages symbolic world modeling to
proactively build a global environmental representation. SGImagineNav maintains
an evolving hierarchical scene graphs and uses large language models to predict
and explore unseen parts of the environment. While existing methods solely
relying on past observations, this imaginative scene graph provides richer
semantic context, enabling the agent to proactively estimate target locations.
Building upon this, SGImagineNav adopts an adaptive navigation strategy that
exploits semantic shortcuts when promising and explores unknown areas otherwise
to gather additional context. This strategy continuously expands the known
environment and accumulates valuable semantic contexts, ultimately guiding the
agent toward the target. SGImagineNav is evaluated in both real-world scenarios
and simulation benchmarks. SGImagineNav consistently outperforms previous
methods, improving success rate to 65.4 and 66.8 on HM3D and HSSD, and
demonstrating cross-floor and cross-room navigation in real-world environments,
underscoring its effectiveness and generalizability.

</details>


### [337] [EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events](https://arxiv.org/abs/2508.07003)
*Siyu Chen,Shenghai Yuan,Thien-Minh Nguyen,Zhuyu Huang,Chenyang Shi,Jin Jing,Lihua Xie*

Main category: cs.RO

TL;DR: EGS-SLAM结合事件数据和RGB-D输入，解决了GS-SLAM在运动模糊下的性能问题，提升了跟踪精度和3D重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM在严重运动模糊下表现不佳，影响跟踪和重建质量。

Method: 融合事件数据和RGB-D输入，建模相机连续轨迹，引入可学习相机响应函数和无事件损失。

Result: 在合成和真实数据集上验证，EGS-SLAM在轨迹精度和3D重建上优于现有方法。

Conclusion: EGS-SLAM显著提升了GS-SLAM在运动模糊场景下的性能，代码将开源。

Abstract: Gaussian Splatting SLAM (GS-SLAM) offers a notable improvement over
traditional SLAM methods, enabling photorealistic 3D reconstruction that
conventional approaches often struggle to achieve. However, existing GS-SLAM
systems perform poorly under persistent and severe motion blur commonly
encountered in real-world scenarios, leading to significantly degraded tracking
accuracy and compromised 3D reconstruction quality. To address this limitation,
we propose EGS-SLAM, a novel GS-SLAM framework that fuses event data with RGB-D
inputs to simultaneously reduce motion blur in images and compensate for the
sparse and discrete nature of event streams, enabling robust tracking and
high-fidelity 3D Gaussian Splatting reconstruction. Specifically, our system
explicitly models the camera's continuous trajectory during exposure,
supporting event- and blur-aware tracking and mapping on a unified 3D Gaussian
Splatting scene. Furthermore, we introduce a learnable camera response function
to align the dynamic ranges of events and images, along with a no-event loss to
suppress ringing artifacts during reconstruction. We validate our approach on a
new dataset comprising synthetic and real-world sequences with significant
motion blur. Extensive experimental results demonstrate that EGS-SLAM
consistently outperforms existing GS-SLAM systems in both trajectory accuracy
and photorealistic 3D Gaussian Splatting reconstruction. The source code will
be available at https://github.com/Chensiyu00/EGS-SLAM.

</details>


### [338] [$\mathcal{P}^3$: Toward Versatile Embodied Agents](https://arxiv.org/abs/2508.07033)
*Shengli Zhou,Xiangchen Wang,Jinrui Zhang,Ruozai Tian,Rongtao Xu,Feng Zheng*

Main category: cs.RO

TL;DR: 论文提出了一个统一框架$\mathcal{P}^3$，解决具身智能体在动态环境感知、开放工具使用和多任务规划中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖工具反馈，适应性差且易累积错误，多任务调度研究不足。

Method: $\mathcal{P}^3$框架整合实时感知和动态调度，支持主动感知、无反馈工具使用和多任务优先级规划。

Result: 实验表明$\mathcal{P}^3$能提升具身智能体的通用性和可迁移性。

Conclusion: $\mathcal{P}^3$为具身智能体的实际部署提供了有效解决方案。

Abstract: Embodied agents have shown promising generalization capabilities across
diverse physical environments, making them essential for a wide range of
real-world applications. However, building versatile embodied agents poses
critical challenges due to three key issues: dynamic environment perception,
open-ended tool usage, and complex multi-task planning. Most previous works
rely solely on feedback from tool agents to perceive environmental changes and
task status, which limits adaptability to real-time dynamics, causes error
accumulation, and restricts tool flexibility. Furthermore, multi-task
scheduling has received limited attention, primarily due to the inherent
complexity of managing task dependencies and balancing competing priorities in
dynamic and complex environments. To overcome these challenges, we introduce
$\mathcal{P}^3$, a unified framework that integrates real-time perception and
dynamic scheduling. Specifically, $\mathcal{P}^3$ enables 1) \textbf Perceive
relevant task information actively from the environment, 2) \textbf Plug and
utilize any tool without feedback requirement, and 3) \textbf Plan multi-task
execution based on prioritizing urgent tasks and dynamically adjusting task
order based on dependencies. Extensive real-world experiments show that our
approach bridges the gap between benchmarks and practical deployment,
delivering highly transferable, general-purpose embodied agents. Code and data
will be released soon.

</details>


### [339] [From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline](https://arxiv.org/abs/2508.07045)
*Dennis Benders,Johannes Köhler,Robert Babuška,Javier Alonso-Mora,Laura Ferranti*

Main category: cs.RO

TL;DR: 提出了一种模块化、高效的鲁棒MPC设计流程，通过闭环实验数据估计扰动边界，确保自主移动机器人导航的安全性和可行性。


<details>
  <summary>Details</summary>
Motivation: 现有MPC方法在真实环境中因扰动和测量噪声难以确保安全性，常依赖理想化假设或启发式猜测。

Method: 采用迭代流程，利用闭环实验数据估计扰动边界，并合成鲁棒输出反馈MPC方案。

Result: 在Gazebo四旋翼仿真中验证了鲁棒约束满足和递归可行性。

Conclusion: 该流程为自主机器人导航提供了一种系统化、可复现的鲁棒MPC设计方法。

Abstract: Model predictive control (MPC) is a powerful strategy for planning and
control in autonomous mobile robot navigation. However, ensuring safety in
real-world deployments remains challenging due to the presence of disturbances
and measurement noise. Existing approaches often rely on idealized assumptions,
neglect the impact of noisy measurements, and simply heuristically guess
unrealistic bounds. In this work, we present an efficient and modular robust
MPC design pipeline that systematically addresses these limitations. The
pipeline consists of an iterative procedure that leverages closed-loop
experimental data to estimate disturbance bounds and synthesize a robust
output-feedback MPC scheme. We provide the pipeline in the form of
deterministic and reproducible code to synthesize the robust output-feedback
MPC from data. We empirically demonstrate robust constraint satisfaction and
recursive feasibility in quadrotor simulations using Gazebo.

</details>


### [340] [Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction](https://arxiv.org/abs/2508.07079)
*Mohamed Parvez Aslam,Bojan Derajic,Mohamed-Khalil Bouzidi,Sebastian Bernhard,Jan Oliver Ringert*

Main category: cs.RO

TL;DR: 该论文研究了在行人密集环境中，将基于深度学习的社交隐式（SI）行人轨迹预测器与模型预测控制（MPC）框架结合，以提升机器人导航的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在行人密集环境中的安全导航问题，传统方法（如恒定速度模型）在动态环境中表现不足。

Method: 将SI行人轨迹预测器集成到MPC框架中，并在物理机器人上进行测试，比较SI-MPC与传统CV模型在开环预测和闭环导航中的表现。

Result: SI显著降低了轨迹预测误差（低密度环境下减少76%），并在拥挤场景中提升了安全性和运动平滑性。

Conclusion: SI-MPC框架在动态行人环境中展现出更高的安全性和适应性，同时强调了系统级评估的重要性。

Abstract: Safe navigation in pedestrian-rich environments remains a key challenge for
autonomous robots. This work evaluates the integration of a deep learning-based
Social-Implicit (SI) pedestrian trajectory predictor within a Model Predictive
Control (MPC) framework on the physical Continental Corriere robot. Tested
across varied pedestrian densities, the SI-MPC system is compared to a
traditional Constant Velocity (CV) model in both open-loop prediction and
closed-loop navigation. Results show that SI improves trajectory prediction -
reducing errors by up to 76% in low-density settings - and enhances safety and
motion smoothness in crowded scenes. Moreover, real-world deployment reveals
discrepancies between open-loop metrics and closed-loop performance, as the SI
model yields broader, more cautious predictions. These findings emphasize the
importance of system-level evaluation and highlight the SI-MPC framework's
promise for safer, more adaptive navigation in dynamic, human-populated
environments.

</details>


### [341] [An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving](https://arxiv.org/abs/2508.07080)
*Haolin Liu,Zijun Guo,Yanbo Chen,Jiaqi Chen,Huilong Yu,Junqiang Xi*

Main category: cs.RO

TL;DR: 论文提出了一种基于进化博弈论（EGT）的自动驾驶车辆（AVs）高速入口合并决策框架，动态平衡AVs和主路车辆（MVs）的利益，提升合并效率、舒适性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有决策算法未能充分应对动态复杂性和AVs的社会接受度，导致合并决策次优或不安全。

Method: 将合并决策建模为EGT问题，通过求解复制动态方程得到进化稳定策略（ESS），并结合实时驾驶风格估计算法调整博弈收益函数。

Result: 实验表明，该方法在多目标指标上优于现有博弈论和传统规划方法，显著提升了AVs和MVs的效率、舒适性和安全性。

Conclusion: EGT框架为AVs的高速入口合并提供了一种高效、安全且符合人类驾驶偏好的解决方案。

Abstract: Highway on-ramp merging is of great challenge for autonomous vehicles (AVs),
since they have to proactively interact with surrounding vehicles to enter the
main road safely within limited time. However, existing decision-making
algorithms fail to adequately address dynamic complexities and social
acceptance of AVs, leading to suboptimal or unsafe merging decisions. To
address this, we propose an evolutionary game-theoretic (EGT) merging
decision-making framework, grounded in the bounded rationality of human
drivers, which dynamically balances the benefits of both AVs and main-road
vehicles (MVs). We formulate the cut-in decision-making process as an EGT
problem with a multi-objective payoff function that reflects human-like driving
preferences. By solving the replicator dynamic equation for the evolutionarily
stable strategy (ESS), the optimal cut-in timing is derived, balancing
efficiency, comfort, and safety for both AVs and MVs. A real-time driving style
estimation algorithm is proposed to adjust the game payoff function online by
observing the immediate reactions of MVs. Empirical results demonstrate that we
improve the efficiency, comfort and safety of both AVs and MVs compared with
existing game-theoretic and traditional planning approaches across multi-object
metrics.

</details>


### [342] [DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit](https://arxiv.org/abs/2508.07118)
*Aiden Swann,Alex Qiu,Matthew Strong,Angelina Zhang,Samuel Morstein,Kai Rayle,Monroe Kennedy III*

Main category: cs.RO

TL;DR: DexFruit是一个机器人操作框架，通过光学触觉传感实现脆弱水果的轻柔自主处理，并利用3D高斯喷洒技术量化损伤。


<details>
  <summary>Details</summary>
Motivation: 许多水果易碎且易受损伤，需人工小心采摘，因此需要开发自动化解决方案以减少损伤。

Method: 使用光学触觉传感和触觉信息扩散策略，结合3D高斯喷洒技术（FruitSplat）量化视觉损伤。

Result: 在草莓、番茄和黑莓上，实现了92%的抓取成功率，视觉损伤减少20%，抓取成功率提升31%。

Conclusion: DexFruit框架在减少水果损伤和提高操作成功率方面表现出色，适用于脆弱水果的自动化处理。

Abstract: DexFruit is a robotic manipulation framework that enables gentle, autonomous
handling of fragile fruit and precise evaluation of damage. Many fruits are
fragile and prone to bruising, thus requiring humans to manually harvest them
with care. In this work, we demonstrate by using optical tactile sensing,
autonomous manipulation of fruit with minimal damage can be achieved. We show
that our tactile informed diffusion policies outperform baselines in both
reduced bruising and pick-and-place success rate across three fruits:
strawberries, tomatoes, and blackberries. In addition, we introduce FruitSplat,
a novel technique to represent and quantify visual damage in high-resolution 3D
representation via 3D Gaussian Splatting (3DGS). Existing metrics for measuring
damage lack quantitative rigor or require expensive equipment. With FruitSplat,
we distill a 2D strawberry mask as well as a 2D bruise segmentation mask into
the 3DGS representation. Furthermore, this representation is modular and
general, compatible with any relevant 2D model. Overall, we demonstrate a 92%
grasping policy success rate, up to a 20% reduction in visual bruising, and up
to an 31% improvement in grasp success rate on challenging fruit compared to
our baselines across our three tested fruits. We rigorously evaluate this
result with over 630 trials. Please checkout our website at
https://dex-fruit.github.io .

</details>


### [343] [3D Gaussian Representations with Motion Trajectory Field for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07182)
*Xuesong Li,Lars Petersson,Vivien Rolland*

Main category: cs.RO

TL;DR: 提出了一种结合3D高斯点渲染与运动轨迹场的新方法，用于从单目视频中实现动态场景的新视角合成和运动重建。


<details>
  <summary>Details</summary>
Motivation: 解决动态场景重建中复杂物体运动处理的挑战，填补NeRF和3DGS在动态场景中的不足。

Method: 通过分离动态物体与静态背景，优化运动轨迹场，并引入时间不变运动系数和共享运动轨迹基来捕捉复杂运动模式。

Result: 在单目视频的新视角合成和运动轨迹恢复中达到最先进效果。

Conclusion: 该方法显著提升了动态场景重建的能力。

Abstract: This paper addresses the challenge of novel-view synthesis and motion
reconstruction of dynamic scenes from monocular video, which is critical for
many robotic applications. Although Neural Radiance Fields (NeRF) and 3D
Gaussian Splatting (3DGS) have demonstrated remarkable success in rendering
static scenes, extending them to reconstruct dynamic scenes remains
challenging. In this work, we introduce a novel approach that combines 3DGS
with a motion trajectory field, enabling precise handling of complex object
motions and achieving physically plausible motion trajectories. By decoupling
dynamic objects from static background, our method compactly optimizes the
motion trajectory field. The approach incorporates time-invariant motion
coefficients and shared motion trajectory bases to capture intricate motion
patterns while minimizing optimization complexity. Extensive experiments
demonstrate that our approach achieves state-of-the-art results in both
novel-view synthesis and motion trajectory recovery from monocular video,
advancing the capabilities of dynamic scene reconstruction.

</details>


### [344] [Impact of Gaze-Based Interaction and Augmentation on Human-Robot Collaboration in Critical Tasks](https://arxiv.org/abs/2508.07244)
*Ayesha Jena,Stefan Reitmann,Elin Anna Topp*

Main category: cs.RO

TL;DR: 研究分析了基于头部注视的机器人控制和焦点视觉增强在模拟搜救任务中的效果，发现焦点增强显著提升任务表现，降低认知负荷38%，缩短任务时间60%以上。


<details>
  <summary>Details</summary>
Motivation: 探索头部注视模式和焦点视觉增强在关键任务（如搜救）中对用户意图理解和任务效率的影响。

Method: 通过用户研究分析头部注视模式和焦点视觉增强在模拟搜救任务中的表现。

Result: 焦点视觉增强显著提升任务性能，降低认知负荷38%，缩短任务时间60%以上；头部注视模式分析显示近远注意力捕捉对理解用户意图至关重要。

Conclusion: 焦点增强技术具有潜力，需进一步研究注视测量以优化关键任务中的表现。

Abstract: We present a user study analyzing head-gaze-based robot control and foveated
visual augmentation in a simulated search-and-rescue task. Results show that
foveated augmentation significantly improves task performance, reduces
cognitive load by 38%, and shortens task time by over 60%. Head-gaze patterns
analysed over both the entire task duration and shorter time segments show that
near and far attention capture is essential to better understand user intention
in critical scenarios. Our findings highlight the potential of foveation as an
augmentation technique and the need to further study gaze measures to leverage
them during critical tasks.

</details>


### [345] [Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics](https://arxiv.org/abs/2508.07267)
*Daria de Tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: 本文提出了一种基于主动推理框架（AIF）的生物启发智能体，用于自主导航，无需预训练即可实时构建和更新环境拓扑图，并规划目标导向的轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有自主导航方法依赖严格规则或预训练，缺乏适应性且计算量大，难以应对动态或未知环境。

Method: 采用主动推理框架（AIF），结合概率推理和模块化ROS2架构，实现实时拓扑图构建、定位和自适应决策。

Result: 在仿真和真实环境中测试，智能体成功探索大规模环境并适应动态障碍，性能与Gbplanner等方法相当。

Conclusion: 该方法为复杂非结构化环境提供了一种可扩展且透明的导航解决方案。

Abstract: Achieving fully autonomous exploration and navigation remains a critical
challenge in robotics, requiring integrated solutions for localisation,
mapping, decision-making and motion planning. Existing approaches either rely
on strict navigation rules lacking adaptability or on pre-training, which
requires large datasets. These AI methods are often computationally intensive
or based on static assumptions, limiting their adaptability in dynamic or
unknown environments. This paper introduces a bio-inspired agent based on the
Active Inference Framework (AIF), which unifies mapping, localisation, and
adaptive decision-making for autonomous navigation, including exploration and
goal-reaching. Our model creates and updates a topological map of the
environment in real-time, planning goal-directed trajectories to explore or
reach objectives without requiring pre-training. Key contributions include a
probabilistic reasoning framework for interpretable navigation, robust
adaptability to dynamic changes, and a modular ROS2 architecture compatible
with existing navigation systems. Our method was tested in simulated and
real-world environments. The agent successfully explores large-scale simulated
environments and adapts to dynamic obstacles and drift, proving to be
comparable to other exploration strategies such as Gbplanner, FAEL and
Frontiers. This approach offers a scalable and transparent approach for
navigating complex, unstructured environments.

</details>


### [346] [Navigation and Exploration with Active Inference: from Biology to Industry](https://arxiv.org/abs/2508.07269)
*Daria de Tinguy,Tim Verbelen,Bart Dhoedt*

Main category: cs.RO

TL;DR: 本文提出了一种基于主动推理框架（AIF）的实时机器人导航系统，通过构建拓扑地图和最小化不确定性实现高效导航，无需预先训练。


<details>
  <summary>Details</summary>
Motivation: 受动物通过认知地图在复杂动态环境中导航的启发，开发一种生物启发的机器人导航方法。

Method: 利用主动推理框架（AIF）逐步构建拓扑地图，推断机器人位置，并通过最小化预期不确定性和实现感知目标来规划行动。

Result: 在ROS2生态系统中验证了系统在2D和3D环境（模拟和现实）中的适应性和效率，性能与传统及前沿方法相当。

Conclusion: 该方法提供了一种无需预先训练的生物启发导航方案，具有竞争力和实用性。

Abstract: By building and updating internal cognitive maps, animals exhibit
extraordinary navigation abilities in complex, dynamic environments. Inspired
by these biological mechanisms, we present a real time robotic navigation
system grounded in the Active Inference Framework (AIF). Our model
incrementally constructs a topological map, infers the agent's location, and
plans actions by minimising expected uncertainty and fulfilling perceptual
goals without any prior training. Integrated into the ROS2 ecosystem, we
validate its adaptability and efficiency across both 2D and 3D environments
(simulated and real world), demonstrating competitive performance with
traditional and state of the art exploration approaches while offering a
biologically inspired navigation approach.

</details>


### [347] [Multimodal Spiking Neural Network for Space Robotic Manipulation](https://arxiv.org/abs/2508.07287)
*Liwen Zhang,Dong Zhou,Shibo Shao,Zihao Su,Guanghui Sun*

Main category: cs.RO

TL;DR: 提出了一种基于脉冲神经网络的多模态控制框架，用于空间站机械臂，结合几何状态、触觉和语义信息，通过三阶段课程强化学习实现高效自主操作。


<details>
  <summary>Details</summary>
Motivation: 解决空间站机械臂在有限资源下的自主操作问题，提升环境感知和鲁棒控制能力。

Method: 采用多模态信息融合和双通道三阶段课程强化学习（CRL）方案。

Result: 在目标接近、抓取和稳定提升等任务中表现优于基线方法，成功率和能效更高。

Conclusion: 该框架适用于实际航空航天应用，具有高效和可靠的性能。

Abstract: This paper presents a multimodal control framework based on spiking neural
networks (SNNs) for robotic arms aboard space stations. It is designed to cope
with the constraints of limited onboard resources while enabling autonomous
manipulation and material transfer in space operations. By combining geometric
states with tactile and semantic information, the framework strengthens
environmental awareness and contributes to more robust control strategies. To
guide the learning process progressively, a dual-channel, three-stage
curriculum reinforcement learning (CRL) scheme is further integrated into the
system. The framework was tested across a range of tasks including target
approach, object grasping, and stable lifting with wall-mounted robotic arms,
demonstrating reliable performance throughout. Experimental evaluations
demonstrate that the proposed method consistently outperforms baseline
approaches in both task success rate and energy efficiency. These findings
highlight its suitability for real-world aerospace applications.

</details>


### [348] [A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks](https://arxiv.org/abs/2508.07319)
*Yanzhao Yu,Haotian Yang,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 本文提出了一种混合力-位置策略，用于控制可变形线性物体（DLOs）的形状，结合了力空间的状态轨迹规划和位置空间的模型预测控制（MPC），并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: DLOs（如电线和电缆）在电子组装和医疗手术等应用中至关重要，但其无限自由度、复杂非线性动力学和系统欠驱动特性带来了挑战。

Method: 提出了一种混合力-位置框架，结合力与位置表示，集成了力空间的状态轨迹规划和位置空间的MPC。模型包括动作编码器、属性提取器和基于图注意力网络的图处理器。

Result: 仿真和实际实验表明，该方法能高效稳定地控制DLOs的形状。

Conclusion: 该混合策略有效解决了DLO形状控制的挑战，代码和视频已公开。

Abstract: Manipulating deformable linear objects (DLOs) such as wires and cables is
crucial in various applications like electronics assembly and medical
surgeries. However, it faces challenges due to DLOs' infinite degrees of
freedom, complex nonlinear dynamics, and the underactuated nature of the
system. To address these issues, this paper proposes a hybrid force-position
strategy for DLO shape control. The framework, combining both force and
position representations of DLO, integrates state trajectory planning in the
force space and Model Predictive Control (MPC) in the position space. We
present a dynamics model with an explicit action encoder, a property extractor
and a graph processor based on Graph Attention Networks. The model is used in
the MPC to enhance prediction accuracy. Results from both simulations and
real-world experiments demonstrate the effectiveness of our approach in
achieving efficient and stable shape control of DLOs. Codes and videos are
available at https://sites.google.com/view/dlom.

</details>


### [349] [Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)](https://arxiv.org/abs/2508.07323)
*Adeetya Uppal,Rakesh Kumar Sahoo,Manoranjan Sinha*

Main category: cs.RO

TL;DR: 提出了一种基于能量的APF框架（E-APF），结合位置和速度依赖的势函数，解决了传统APF的局部极小值和振荡问题，并通过混合轨迹优化器实现平滑、高效的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 动态和复杂环境中机器人轨迹规划面临时间效率和运动平滑性的挑战，传统APF存在局部极小值和振荡问题。

Method: 提出E-APF框架，结合位置和速度依赖的势函数，并与混合轨迹优化器联合优化，最小化急动和执行时间。

Result: 仿真验证表明，E-APF框架能生成无碰撞、平滑、高效且无振荡的轨迹。

Conclusion: 该框架为未来与反应控制策略和实际硬件部署的集成奠定了基础。

Abstract: Robotic trajectory planning in dynamic and cluttered environments remains a
critical challenge, particularly when striving for both time efficiency and
motion smoothness under actuation constraints. Traditional path planner, such
as Artificial Potential Field (APF), offer computational efficiency but suffer
from local minima issue due to position-based potential field functions and
oscillatory motion near the obstacles due to Newtonian mechanics. To address
this limitation, an Energy-based Artificial Potential Field (APF) framework is
proposed in this paper that integrates position and velocity-dependent
potential functions. E-APF ensures dynamic adaptability and mitigates local
minima, enabling uninterrupted progression toward the goal. The proposed
framework integrates E-APF with a hybrid trajectory optimizer that jointly
minimizes jerk and execution time under velocity and acceleration constraints,
ensuring geometric smoothness and time efficiency. The entire framework is
validated in simulation using the 7-degree-of-freedom Kinova Gen3 robotic
manipulator. The results demonstrate collision-free, smooth, time-efficient,
and oscillation-free trajectory in the presence of obstacles, highlighting the
efficacy of the combined trajectory optimization and real-time obstacle
avoidance approach. This work lays the foundation for future integration with
reactive control strategies and physical hardware deployment in real-world
manipulation tasks.

</details>


### [350] [MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control](https://arxiv.org/abs/2508.07387)
*Basant Sharma,Prajyot Jadhav,Pranjal Paul,K. Madhava Krishna,Arun Kumar Singh*

Main category: cs.RO

TL;DR: 论文提出了一种基于学习碰撞模型的方法，用于单RGB相机导航，避免了直接使用噪声深度估计，并通过风险感知MPC规划器提高了导航成功率。


<details>
  <summary>Details</summary>
Motivation: 单RGB相机在未知环境中导航时，缺乏深度信息导致碰撞检测不可靠，而现有深度估计方法噪声过大，无法直接用于零样本导航。

Method: 利用噪声深度估计作为上下文输入，训练一个学习碰撞模型，预测最小障碍物间隙分布，并结合风险感知MPC规划器进行导航。

Result: 实验表明，该方法在杂乱环境中的导航成功率比NoMaD和ROS堆栈分别提高了9倍和7倍。

Conclusion: 通过联合学习碰撞模型和风险度量，该方法显著提高了单RGB相机在复杂环境中的导航性能。

Abstract: Navigating unknown environments with a single RGB camera is challenging, as
the lack of depth information prevents reliable collision-checking. While some
methods use estimated depth to build collision maps, we found that depth
estimates from vision foundation models are too noisy for zero-shot navigation
in cluttered environments.
  We propose an alternative approach: instead of using noisy estimated depth
for direct collision-checking, we use it as a rich context input to a learned
collision model. This model predicts the distribution of minimum obstacle
clearance that the robot can expect for a given control sequence. At inference,
these predictions inform a risk-aware MPC planner that minimizes estimated
collision risk. Our joint learning pipeline co-trains the collision model and
risk metric using both safe and unsafe trajectories. Crucially, our
joint-training ensures optimal variance in our collision model that improves
navigation in highly cluttered environments. Consequently, real-world
experiments show 9x and 7x improvements in success rates over NoMaD and the ROS
stack, respectively. Ablation studies further validate the effectiveness of our
design choices.

</details>


### [351] [AgriVLN: Vision-and-Language Navigation for Agricultural Robots](https://arxiv.org/abs/2508.07406)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 论文提出了农业场景下的视觉与语言导航基准A2A和基线方法AgriVLN，通过指令分解模块提升导航成功率。


<details>
  <summary>Details</summary>
Motivation: 现有农业机器人依赖人工操作或固定轨道，移动性差；现有VLN方法未针对农业场景设计。

Method: 提出A2A基准和AgriVLN基线方法，基于VLM设计指令分解模块STL。

Result: AgriVLN在短指令上表现良好，长指令通过STL模块将成功率从0.33提升至0.47。

Conclusion: AgriVLN在农业场景中表现最优，为农业机器人导航提供了有效解决方案。

Abstract: Agricultural robots have emerged as powerful members in agricultural tasks,
nevertheless, still heavily rely on manual operation or untransportable railway
for movement, resulting in limited mobility and poor adaptability.
Vision-and-Language Navigation (VLN) enables robots to navigate to the target
destinations following natural language instructions, demonstrating strong
performance on several domains. However, none of the existing benchmarks or
methods is specifically designed for agricultural scenes. To bridge this gap,
we propose Agriculture to Agriculture (A2A) benchmark, containing 1,560
episodes across six diverse agricultural scenes, in which all realistic RGB
videos are captured by front-facing camera on a quadruped robot at a height of
0.38 meters, aligning with the practical deployment conditions. Meanwhile, we
propose Vision-and-Language Navigation for Agricultural Robots (AgriVLN)
baseline based on Vision-Language Model (VLM) prompted with carefully crafted
templates, which can understand both given instructions and agricultural
environments to generate appropriate low-level actions for robot control. When
evaluated on A2A, AgriVLN performs well on short instructions but struggles
with long instructions, because it often fails to track which part of the
instruction is currently being executed. To address this, we further propose
Subtask List (STL) instruction decomposition module and integrate it into
AgriVLN, improving Success Rate (SR) from 0.33 to 0.47. We additionally compare
AgriVLN with several existing VLN methods, demonstrating the state-of-the-art
performance in the agricultural domain.

</details>


### [352] [Triple-S: A Collaborative Multi-LLM Framework for Solving Long-Horizon Implicative Tasks in Robotics](https://arxiv.org/abs/2508.07421)
*Zixi Jia,Hongbin Gao,Fashe Li,Jiqiang Liu,Hexiao Li,Qinghua Liu*

Main category: cs.RO

TL;DR: 论文提出了一种名为Triple-S的协作框架，通过多LLM协作改进机器人政策代码的生成，解决了长时隐式任务中的错误问题。


<details>
  <summary>Details</summary>
Motivation: 利用LLM生成机器人控制代码时，长时隐式任务中常出现API参数、注释和顺序错误，导致任务失败。

Method: 提出Triple-S框架，通过多LLM在简化-解决方案-总结闭环过程中扮演特定角色，结合上下文学习，并引入基于成功经验的演示库更新机制。

Result: 在LDIP数据集上，Triple-S在可观察和部分可观察场景中成功执行了89%的任务。

Conclusion: Triple-S框架显著提高了长时隐式任务的成功率和鲁棒性，实验验证了其有效性。

Abstract: Leveraging Large Language Models (LLMs) to write policy code for controlling
robots has gained significant attention. However, in long-horizon implicative
tasks, this approach often results in API parameter, comments and sequencing
errors, leading to task failure. To address this problem, we propose a
collaborative Triple-S framework that involves multiple LLMs. Through
In-Context Learning, different LLMs assume specific roles in a closed-loop
Simplification-Solution-Summary process, effectively improving success rates
and robustness in long-horizon implicative tasks. Additionally, a novel
demonstration library update mechanism which learned from success allows it to
generalize to previously failed tasks. We validate the framework in the
Long-horizon Desktop Implicative Placement (LDIP) dataset across various
baseline models, where Triple-S successfully executes 89% of tasks in both
observable and partially observable scenarios. Experiments in both simulation
and real-world robot settings further validated the effectiveness of Triple-S.
Our code and dataset is available at: https://github.com/Ghbbbbb/Triple-S.

</details>


### [353] [A Learning-Based Framework for Collision-Free Motion Planning](https://arxiv.org/abs/2508.07502)
*Mateus Salomão,Tianyü Ren,Alexander König*

Main category: cs.RO

TL;DR: 提出了一种基于学习的运动规划方法，通过深度神经网络优化参数，实现实时无碰撞轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 解决传统手动调参的局限性，提升在复杂环境中的规划效率和泛化能力。

Method: 结合CUDA加速感知模块、基于预测的规划策略和贝叶斯优化生成的数据集，训练深度神经网络推断最优参数。

Result: 在仿真和真实机器人上验证了实时规划能力，任务完成率和泛化性能优于传统方法。

Conclusion: 该方法无需手动调参，适用于复杂环境，具有实际应用潜力。

Abstract: This paper presents a learning-based extension to a Circular Field (CF)-based
motion planner for efficient, collision-free trajectory generation in cluttered
environments. The proposed approach overcomes the limitations of hand-tuned
force field parameters by employing a deep neural network trained to infer
optimal planner gains from a single depth image of the scene. The pipeline
incorporates a CUDA-accelerated perception module, a predictive agent-based
planning strategy, and a dataset generated through Bayesian optimization in
simulation. The resulting framework enables real-time planning without manual
parameter tuning and is validated both in simulation and on a Franka Emika
Panda robot. Experimental results demonstrate successful task completion and
improved generalization compared to classical planners.

</details>


### [354] [Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning](https://arxiv.org/abs/2508.07885)
*Shoaib Ahmmad,Zubayer Ahmed Aditto,Md Mehrab Hossain,Noushin Yeasmin,Shorower Hossain*

Main category: cs.RO

TL;DR: 论文提出了一种基于AI的感知系统，用于GPS缺失的室内环境中四轴飞行器的自主导航，结合云计算和定制PCB，实现了高效的数据处理和避障。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失环境下四轴飞行器的自主导航问题，提升在狭小空间中的感知和决策能力。

Method: 系统整合了YOLOv11目标检测、Depth Anything V2深度估计、定制PCB（含ToF传感器和IMU）、云端LLM决策，以及多线程架构和虚拟安全边界。

Result: 实验显示，目标检测mAP50为0.6，深度估计MAE为7.2 cm，42次试验中仅16次安全边界突破，系统延迟低于1秒。

Conclusion: 该框架为GPS缺失环境下的无人机导航提供了高效辅助，补充了现有技术的不足。

Abstract: This paper introduces an advanced AI-driven perception system for autonomous
quadcopter navigation in GPS-denied indoor environments. The proposed framework
leverages cloud computing to offload computationally intensive tasks and
incorporates a custom-designed printed circuit board (PCB) for efficient sensor
data acquisition, enabling robust navigation in confined spaces. The system
integrates YOLOv11 for object detection, Depth Anything V2 for monocular depth
estimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial
Measurement Unit (IMU), and a cloud-based Large Language Model (LLM) for
context-aware decision-making. A virtual safety envelope, enforced by
calibrated sensor offsets, ensures collision avoidance, while a multithreaded
architecture achieves low-latency processing. Enhanced spatial awareness is
facilitated by 3D bounding box estimation with Kalman filtering. Experimental
results in an indoor testbed demonstrate strong performance, with object
detection achieving a mean Average Precision (mAP50) of 0.6, depth estimation
Mean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42
trials over approximately 11 minutes, and end-to-end system latency below 1
second. This cloud-supported, high-intelligence framework serves as an
auxiliary perception and navigation system, complementing state-of-the-art
drone autonomy for GPS-denied confined spaces.

</details>


### [355] [Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey](https://arxiv.org/abs/2508.07560)
*Yan Gong,Naibang Wang,Jianli Lu,Xinyu Zhang,Yongsheng Gao,Jie Zhao,Zifan Huang,Haozhi Bai,Nanxin Zeng,Nayu Su,Lei Yang,Ziying Song,Xiaoxi Hu,Xinmin Jiang,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.RO

TL;DR: 本文综述了自动驾驶中鸟瞰图（BEV）感知的安全性挑战，分析了单模态、多模态和多代理协作感知的框架，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆从受控环境转向实际部署，确保BEV感知在复杂场景中的安全性和可靠性成为关键挑战。

Method: 系统分析了BEV感知的三个阶段：单模态车辆端、多模态车辆端和多代理协作感知，并评估了相关数据集。

Result: 识别了开放世界中的关键挑战，如开放集识别、大规模未标记数据、传感器退化和代理间通信延迟。

Conclusion: 提出了未来研究方向，包括与端到端自动驾驶系统、具身智能和大语言模型的结合。

Abstract: Bird's-Eye-View (BEV) perception has become a foundational paradigm in
autonomous driving, enabling unified spatial representations that support
robust multi-sensor fusion and multi-agent collaboration. As autonomous
vehicles transition from controlled environments to real-world deployment,
ensuring the safety and reliability of BEV perception in complex scenarios -
such as occlusions, adverse weather, and dynamic traffic - remains a critical
challenge. This survey provides the first comprehensive review of BEV
perception from a safety-critical perspective, systematically analyzing
state-of-the-art frameworks and implementation strategies across three
progressive stages: single-modality vehicle-side, multimodal vehicle-side, and
multi-agent collaborative perception. Furthermore, we examine public datasets
encompassing vehicle-side, roadside, and collaborative settings, evaluating
their relevance to safety and robustness. We also identify key open-world
challenges - including open-set recognition, large-scale unlabeled data, sensor
degradation, and inter-agent communication latency - and outline future
research directions, such as integration with end-to-end autonomous driving
systems, embodied intelligence, and large language models.

</details>


### [356] [Feedback Control of a Single-Tail Bioinspired 59-mg Swimmer](https://arxiv.org/abs/2508.07566)
*Conor K. Trygstad,Cody R. Longwell,Francisco M. F. R. Gonçalves,Elijah K. Blankenship,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 本文介绍了一种改进的单尾鱼类和带状生物启发的小型游泳机器人（FRISSHBot），采用新型形状记忆合金（SMA）双压电晶片驱动器，实现了二维空间的可控性，首次展示了亚克级单尾水生机器人的反馈控制轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 通过改进设计，提升小型游泳机器人的速度和可控性，实现更高效的轨迹跟踪。

Method: 采用物理信息设计，增大头部并缩短尾部，结合新型SMA双压电晶片驱动器。

Result: 改进后的机器人最高游泳速度达13.6 mm/s（0.38 Bl/s），是原平台的4倍；闭环跟踪时速度达9.1 mm/s，RMS误差低至2.6 mm，转弯半径最小10 mm。

Conclusion: 改进设计显著提升了机器人的性能和可控性，为小型水生机器人的应用提供了新可能。

Abstract: We present an evolved steerable version of the single-tail
Fish-&-Ribbon-Inspired Small Swimming Harmonic roBot (FRISSHBot), a 59-mg
biologically inspired swimmer, which is driven by a new shape-memory alloy
(SMA)-based bimorph actuator. The new FRISSHBot is controllable in the
two-dimensional (2D) space, which enabled the first demonstration of
feedback-controlled trajectory tracking of a single-tail aquatic robot with
onboard actuation at the subgram scale. These new capabilities are the result
of a physics-informed design with an enlarged head and shortened tail relative
to those of the original platform. Enhanced by its design, this new platform
achieves forward swimming speeds of up to 13.6 mm/s (0.38 Bl/s), which is over
four times that of the original platform. Furthermore, when following 2D
references in closed loop, the tested FRISSHBot prototype attains forward
swimming speeds of up to 9.1 mm/s, root-mean-square (RMS) tracking errors as
low as 2.6 mm, turning rates of up to 13.1 {\deg}/s, and turning radii as small
as 10 mm.

</details>


### [357] [COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models](https://arxiv.org/abs/2508.08144)
*Ganesh Sundaram,Jonas Ulmen,Amjad Haider,Daniel Görges*

Main category: cs.RO

TL;DR: 本文提出了一种基于组件感知的结构化剪枝方法，用于优化神经网络控制器（NNC）的压缩与稳定性平衡，适用于资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 资源受限的移动平台（如机器人、可穿戴设备和物联网设备）需要高效计算的NNC，但深度神经网络（DNN）的高计算复杂性和内存需求限制了其实际部署。

Method: 采用组件感知的结构化剪枝方法，结合数学稳定性保证（如Lyapunov准则），在TD-MPC算法中验证压缩效果。

Result: 实验表明，该方法能显著降低模型复杂度，同时保持控制性能和稳定性，并确定了安全压缩比的上限。

Conclusion: 该框架为NNC在资源受限环境中的压缩部署提供了理论支持，确保稳定性不被破坏。

Abstract: The rapid growth of resource-constrained mobile platforms, including mobile
robots, wearable systems, and Internet-of-Things devices, has increased the
demand for computationally efficient neural network controllers (NNCs) that can
operate within strict hardware limitations. While deep neural networks (DNNs)
demonstrate superior performance in control applications, their substantial
computational complexity and memory requirements present significant barriers
to practical deployment on edge devices. This paper introduces a comprehensive
model compression methodology that leverages component-aware structured pruning
to determine the optimal pruning magnitude for each pruning group, ensuring a
balance between compression and stability for NNC deployment. Our approach is
rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC),
a state-of-the-art model-based reinforcement learning algorithm, with a
systematic integration of mathematical stability guarantee properties,
specifically Lyapunov criteria. The key contribution of this work lies in
providing a principled framework for determining the theoretical limits of
model compression while preserving controller stability. Experimental
validation demonstrates that our methodology successfully reduces model
complexity while maintaining requisite control performance and stability
characteristics. Furthermore, our approach establishes a quantitative boundary
for safe compression ratios, enabling practitioners to systematically determine
the maximum permissible model reduction before violating critical stability
properties, thereby facilitating the confident deployment of compressed NNCs in
resource-limited environments.

</details>


### [358] [In-situ Value-aligned Human-Robot Interactions with Physical Constraints](https://arxiv.org/abs/2508.07606)
*Hongtao Li,Ziyuan Jiao,Xiaofeng Liu,Hangxin Liu,Zilong Zheng*

Main category: cs.RO

TL;DR: 论文提出了一种结合人类偏好与物理约束的框架，通过上下文学习人类反馈（ICLHF），使机器人能够完成任务并适应未来场景。


<details>
  <summary>Details</summary>
Motivation: 尽管配备大型语言模型的机器人能完成复杂任务，但仅完成任务不足以满足认知需求，需学习并应用人类偏好。

Method: 开发日常家务活动基准，引入ICLHF框架，结合人类直接指令和日常调整反馈。

Result: 实验证明ICLHF能高效生成任务计划，平衡物理约束与人类偏好。

Conclusion: 该框架为机器人学习人类偏好提供了有效方法，适用于未来场景。

Abstract: Equipped with Large Language Models (LLMs), human-centered robots are now
capable of performing a wide range of tasks that were previously deemed
challenging or unattainable. However, merely completing tasks is insufficient
for cognitive robots, who should learn and apply human preferences to future
scenarios. In this work, we propose a framework that combines human preferences
with physical constraints, requiring robots to complete tasks while considering
both. Firstly, we developed a benchmark of everyday household activities, which
are often evaluated based on specific preferences. We then introduced
In-Context Learning from Human Feedback (ICLHF), where human feedback comes
from direct instructions and adjustments made intentionally or unintentionally
in daily life. Extensive sets of experiments, testing the ICLHF to generate
task plans and balance physical constraints with preferences, have demonstrated
the efficiency of our approach.

</details>


### [359] [End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy](https://arxiv.org/abs/2508.07611)
*Zifan Wang,Xun Yang,Jianzhuang Zhao,Jiaming Zhou,Teli Ma,Ziyao Gao,Arash Ajoudani,Junwei Liang*

Main category: cs.RO

TL;DR: 提出了一种基于LiDAR点云的端到端运动策略，结合CMDP和CBFs实现安全导航，并通过P3O算法训练，最终在仿真和现实中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在非结构化环境中导航时缺乏环境感知和安全性的问题。

Method: 使用LiDAR点云直接映射到运动指令，通过CMDP分离安全与任务目标，结合CBFs和P3O算法训练。

Result: 实现了在复杂动态场景中的敏捷安全导航，并通过仿真到现实的迁移验证。

Conclusion: 该方法有效提升了人形机器人在复杂环境中的导航能力，兼具安全性和社会意识。

Abstract: The deployment of humanoid robots in unstructured, human-centric environments
requires navigation capabilities that extend beyond simple locomotion to
include robust perception, provable safety, and socially aware behavior.
Current reinforcement learning approaches are often limited by blind
controllers that lack environmental awareness or by vision-based systems that
fail to perceive complex 3D obstacles. In this work, we present an end-to-end
locomotion policy that directly maps raw, spatio-temporal LiDAR point clouds to
motor commands, enabling robust navigation in cluttered dynamic scenes. We
formulate the control problem as a Constrained Markov Decision Process (CMDP)
to formally separate safety from task objectives. Our key contribution is a
novel methodology that translates the principles of Control Barrier Functions
(CBFs) into costs within the CMDP, allowing a model-free Penalized Proximal
Policy Optimization (P3O) to enforce safety constraints during training.
Furthermore, we introduce a set of comfort-oriented rewards, grounded in
human-robot interaction research, to promote motions that are smooth,
predictable, and less intrusive. We demonstrate the efficacy of our framework
through a successful sim-to-real transfer to a physical humanoid robot, which
exhibits agile and safe navigation around both static and dynamic 3D obstacles.

</details>


### [360] [Grasp-HGN: Grasping the Unexpected](https://arxiv.org/abs/2508.07648)
*Mehrshad Zandigohar,Mallesham Dasari,Gunar Schirner*

Main category: cs.RO

TL;DR: 论文提出Grasp-LLaVA和HGN方法，解决假肢手在未见物体上的抓取泛化问题，显著提升准确性和速度。


<details>
  <summary>Details</summary>
Motivation: 现有假肢手抓取模型在未见物体上表现差，影响用户独立性和生活质量。

Method: 提出Grasp-LLaVA（视觉语言模型）和HGN（混合网络），结合语义推理和边缘-云端部署。

Result: Grasp-LLaVA在未见物体上准确率达50.2%，HGN进一步提升至42.3%，速度提升3.5倍。

Conclusion: 新方法显著提升假肢手抓取的泛化能力和实用性。

Abstract: For transradial amputees, robotic prosthetic hands promise to regain the
capability to perform daily living activities. To advance next-generation
prosthetic hand control design, it is crucial to address current shortcomings
in robustness to out of lab artifacts, and generalizability to new
environments. Due to the fixed number of object to interact with in existing
datasets, contrasted with the virtually infinite variety of objects encountered
in the real world, current grasp models perform poorly on unseen objects,
negatively affecting users' independence and quality of life.
  To address this: (i) we define semantic projection, the ability of a model to
generalize to unseen object types and show that conventional models like YOLO,
despite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose
Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to
infer the suitable grasp type estimate based on the object's physical
characteristics resulting in a significant 50.2% accuracy over unseen object
types compared to 36.7% accuracy of an SOTA grasp estimation model.
  Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp
Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp
estimation on edge and accurate cloud inference as a fail-safe, effectively
expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC)
enables dynamic switching between edge and cloud models, improving semantic
projection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object
types. Over a real-world sample mix, it reaches 86% average accuracy (12.2%
gain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.

</details>


### [361] [GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions](https://arxiv.org/abs/2508.07650)
*Helong Huang,Min Cen,Kai Tan,Xingyue Quan,Guowei Huang,Hong Zhang*

Main category: cs.RO

TL;DR: GraphCoT-VLA是一种高效的端到端视觉-语言-动作模型，通过结构化思维链推理模块和实时更新的3D位姿-物体图，解决了现有模型在模糊指令和未知环境状态下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在处理模糊指令和未知环境状态时表现不足，且感知局限于静态二维观察，缺乏对三维交互的建模能力。

Method: 设计结构化思维链推理模块，集成高层次任务理解、失败任务反馈和低层次未来物体位置推理；构建实时更新的3D位姿-物体图，捕捉空间配置和拓扑关系；采用混合推理策略实现高效控制。

Result: 在多个真实机器人任务中，GraphCoT-VLA在任务成功率和响应速度上显著优于现有方法，表现出强泛化性和鲁棒性。

Conclusion: GraphCoT-VLA通过创新设计和高效推理，显著提升了机器人操作能力，适用于开放环境和不确定指令场景。

Abstract: Vision-language-action models have emerged as a crucial paradigm in robotic
manipulation. However, existing VLA models exhibit notable limitations in
handling ambiguous language instructions and unknown environmental states.
Furthermore, their perception is largely constrained to static two-dimensional
observations, lacking the capability to model three-dimensional interactions
between the robot and its environment. To address these challenges, this paper
proposes GraphCoT-VLA, an efficient end-to-end model. To enhance the model's
ability to interpret ambiguous instructions and improve task planning, we
design a structured Chain-of-Thought reasoning module that integrates
high-level task understanding and planning, failed task feedback, and low-level
imaginative reasoning about future object positions and robot actions.
Additionally, we construct a real-time updatable 3D Pose-Object graph, which
captures the spatial configuration of robot joints and the topological
relationships between objects in 3D space, enabling the model to better
understand and manipulate their interactions. We further integrates a dropout
hybrid reasoning strategy to achieve efficient control outputs. Experimental
results across multiple real-world robotic tasks demonstrate that GraphCoT-VLA
significantly outperforms existing methods in terms of task success rate and
response speed, exhibiting strong generalization and robustness in open
environments and under uncertain instructions.

</details>


### [362] [MoRoCo: Multi-operator-robot Coordination, Interaction and Exploration under Restricted Communication](https://arxiv.org/abs/2508.07657)
*Zhuoli Tian,Yuyang Zhang,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: MoRoCo是一个多操作者多机器人系统的统一框架，用于在通信受限环境下实现双边、上下文感知的交互和高效协调。


<details>
  <summary>Details</summary>
Motivation: 在通信受限的环境中，现有研究多忽视人类操作者与机器人团队的实时交互需求，而MoRoCo旨在填补这一空白。

Method: MoRoCo通过分布式算法管理三种协调模式（分散、迁移和链式），仅依赖本地通信实现动态切换。

Result: 大规模仿真和硬件实验验证了MoRoCo在有限通信下实现高效可靠协调的能力。

Conclusion: MoRoCo为复杂环境中的人机协作多机器人系统提供了鲁棒性解决方案。

Abstract: Fleets of autonomous robots are increasingly deployed alongside multiple
human operators to explore unknown environments, identify salient features, and
perform complex tasks in scenarios such as subterranean exploration,
reconnaissance, and search-and-rescue missions. In these contexts,
communication is often severely limited to short-range exchanges via ad-hoc
networks, posing challenges to coordination. While recent studies have
addressed multi-robot exploration under communication constraints, they largely
overlook the essential role of human operators and their real-time interaction
with robotic teams. Operators may demand timely updates on the exploration
progress and robot status, reprioritize or cancel tasks dynamically, or request
live video feeds and control access. Conversely, robots may seek human
confirmation for anomalous events or require help recovering from motion or
planning failures. To enable such bilateral, context-aware interactions under
restricted communication, this work proposes MoRoCo, a unified framework for
online coordination and exploration in multi-operator, multi-robot systems.
MoRoCo enables the team to adaptively switch among three coordination modes:
spread mode for parallelized exploration with intermittent data sharing,
migrate mode for coordinated relocation, and chain mode for maintaining
high-bandwidth connectivity through multi-hop links. These transitions are
managed through distributed algorithms via only local communication. Extensive
large-scale human-in-the-loop simulations and hardware experiments validate the
necessity of incorporating human robot interactions and demonstrate that MoRoCo
enables efficient, reliable coordination under limited communication, marking a
significant step toward robust human-in-the-loop multi-robot autonomy in
challenging environments.

</details>


### [363] [Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning](https://arxiv.org/abs/2508.07686)
*Mingyue Lei,Zewei Zhou,Hongchen Li,Jiaqi Ma,Jia Hu*

Main category: cs.RO

TL;DR: 提出了一种基于风险地图中间件（RiskMM）的可解释协作端到端驾驶框架，解决了单智能体端到端驾驶的遮挡、感知范围限制及黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 现有单智能体端到端驾驶系统存在遮挡、感知范围有限及行为不可解释的问题，导致驾驶不安全且不可信。

Method: 通过风险地图学习驾驶数据，构建多智能体时空表示，利用注意力建模环境交互，并结合基于学习的模型预测控制（MPC）模块进行规划。

Result: 在V2XPnP-Seq数据集上验证，RiskMM在风险感知轨迹规划中表现出色，显著提升了框架的可解释性。

Conclusion: RiskMM为协作端到端驾驶提供了高性能且可解释的解决方案，代码将开源以促进未来研究。

Abstract: End-to-end paradigm has emerged as a promising approach to autonomous
driving. However, existing single-agent end-to-end pipelines are often
constrained by occlusion and limited perception range, resulting in hazardous
driving. Furthermore, their black-box nature prevents the interpretability of
the driving behavior, leading to an untrustworthiness system. To address these
limitations, we introduce Risk Map as Middleware (RiskMM) and propose an
interpretable cooperative end-to-end driving framework. The risk map learns
directly from the driving data and provides an interpretable spatiotemporal
representation of the scenario from the upstream perception and the
interactions between the ego vehicle and the surrounding environment for
downstream planning. RiskMM first constructs a multi-agent spatiotemporal
representation with unified Transformer-based architecture, then derives
risk-aware representations by modeling interactions among surrounding
environments with attention. These representations are subsequently fed into a
learning-based Model Predictive Control (MPC) module. The MPC planner
inherently accommodates physical constraints and different vehicle types and
can provide interpretation by aligning learned parameters with explicit MPC
elements. Evaluations conducted on the real-world V2XPnP-Seq dataset confirm
that RiskMM achieves superior and robust performance in risk-aware trajectory
planning, significantly enhancing the interpretability of the cooperative
end-to-end driving framework. The codebase will be released to facilitate
future research in this field.

</details>


### [364] [LAURON VI: A Six-Legged Robot for Dynamic Walking](https://arxiv.org/abs/2508.07689)
*Christian Eichmann,Sabine Bellmann,Nicolas Hügel,Louis-Elias Enslin,Carsten Plasberg,Georg Heppner,Arne Roennau,Ruediger Dillmann*

Main category: cs.RO

TL;DR: 论文介绍了六足机器人LAURON VI，旨在研究动态步态和复杂任务自主性，通过三种控制方法提升其在混合地形中的适应性。


<details>
  <summary>Details</summary>
Motivation: 六足机器人在复杂地形中表现优异，但在简单地形中缺乏快速步态，限制了其应用范围。

Method: 设计了三种控制方法：基于运动学的、模型预测的和强化学习的控制器，并在实验室和火星模拟任务中测试。

Result: LAURON VI通过引入快速步态策略，显著提升了六足机器人在多种实际场景中的适用性。

Conclusion: 快速步态策略的引入使六足机器人更适合广泛的实际应用。

Abstract: Legged locomotion enables robotic systems to traverse extremely challenging
terrains. In many real-world scenarios, the terrain is not that difficult and
these mixed terrain types introduce the need for flexible use of different
walking strategies to achieve mission goals in a fast, reliable, and
energy-efficient way. Six-legged robots have a high degree of flexibility and
inherent stability that aids them in traversing even some of the most difficult
terrains, such as collapsed buildings. However, their lack of fast walking
gaits for easier surfaces is one reason why they are not commonly applied in
these scenarios.
  This work presents LAURON VI, a six-legged robot platform for research on
dynamic walking gaits as well as on autonomy for complex field missions. The
robot's 18 series elastic joint actuators offer high-frequency interfaces for
Cartesian impedance and pure torque control. We have designed, implemented, and
compared three control approaches: kinematic-based, model-predictive, and
reinforcement-learned controllers. The robot hardware and the different control
approaches were extensively tested in a lab environment as well as on a Mars
analog mission. The introduction of fast locomotion strategies for LAURON VI
makes six-legged robots vastly more suitable for a wide range of real-world
applications.

</details>


### [365] [Robot and Overhead Crane Collaboration Scheme to Enhance Payload Manipulation](https://arxiv.org/abs/2508.07758)
*Antonio Rosales,Alaa Abderrahim,Markku Suomalainen,Mikael Haag,Tapio Heikkilä*

Main category: cs.RO

TL;DR: 提出了一种通过机器人与起重机协作增强载荷操控的方案，利用导纳控制实现安全、流畅的协作运动。


<details>
  <summary>Details</summary>
Motivation: 当前工业实践中，起重机载荷的精确定位和操控依赖人工操作，效率低且风险高。

Method: 采用两种导纳传递函数：一种用于机器人的位置导纳控制，另一种用于起重机的速度命令生成，实现协作操控。

Result: 仿真和实验验证了方案的潜力，实现了流畅的机器人-起重机协作。

Conclusion: 该方案通过导纳控制有效提升了载荷操控的安全性和效率。

Abstract: This paper presents a scheme to enhance payload manipulation using a robot
collaborating with an overhead crane. In the current industrial practice, when
the crane's payload has to be accurately manipulated and located in a desired
position, the task becomes laborious and risky since the operators have to
guide the fine motions of the payload by hand. In the proposed collaborative
scheme, the crane lifts the payload while the robot's end-effector guides it
toward the desired position. The only link between the robot and the crane is
the interaction force produced during the guiding of the payload. Two
admittance transfer functions are considered to accomplish harmless and smooth
contact with the payload. The first is used in a position-based admittance
control integrated with the robot. The second one adds compliance to the crane
by processing the interaction force through the admittance transfer function to
generate a crane's velocity command that makes the crane follow the payload.
Then the robot's end-effector and the crane move collaboratively to guide the
payload to the desired location. A method is presented to design the admittance
controllers that accomplish a fluent robot-crane collaboration. Simulations and
experiments validating the scheme potential are shown.

</details>


### [366] [AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation](https://arxiv.org/abs/2508.07770)
*Yizheng Zhang,Zhenjun Yu,Jiaxin Lai,Cewu Lu,Lei Han*

Main category: cs.RO

TL;DR: AgentWorld是一个交互式仿真平台，用于开发家庭移动操作能力，结合自动化场景构建和双模式遥操作系统，支持从简单任务到多阶段活动的数据收集。


<details>
  <summary>Details</summary>
Motivation: 为复杂家庭环境中的机器人技能获取提供可扩展的解决方案，缩小仿真训练与实际部署之间的差距。

Method: 平台结合自动化场景构建（布局生成、语义资产放置、视觉材料配置、物理模拟）和双模式遥操作系统（轮式底座和人形运动策略），收集多样化任务数据。

Result: 通过模仿学习方法（行为克隆、动作分块变换器、扩散策略、视觉-语言-动作模型）的广泛基准测试，验证了数据集对仿真到现实迁移的有效性。

Conclusion: AgentWorld为家庭环境中的机器人技能学习提供了全面解决方案，并公开了代码和数据集。

Abstract: We introduce AgentWorld, an interactive simulation platform for developing
household mobile manipulation capabilities. Our platform combines automated
scene construction that encompasses layout generation, semantic asset
placement, visual material configuration, and physics simulation, with a
dual-mode teleoperation system supporting both wheeled bases and humanoid
locomotion policies for data collection. The resulting AgentWorld Dataset
captures diverse tasks ranging from primitive actions (pick-and-place,
push-pull, etc.) to multistage activities (serve drinks, heat up food, etc.)
across living rooms, bedrooms, and kitchens. Through extensive benchmarking of
imitation learning methods including behavior cloning, action chunking
transformers, diffusion policies, and vision-language-action models, we
demonstrate the dataset's effectiveness for sim-to-real transfer. The
integrated system provides a comprehensive solution for scalable robotic skill
acquisition in complex home environments, bridging the gap between
simulation-based training and real-world deployment. The code, datasets will be
available at https://yizhengzhang1.github.io/agent_world/

</details>


### [367] [SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing](https://arxiv.org/abs/2508.07814)
*Malaika Zafar,Roohan Ahmed Khan,Faryal Batool,Yasheerah Yaqoot,Ziang Guo,Mikhail Litvinov,Aleksey Fedoseev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: SwarmVLM通过视觉语言模型和检索增强生成技术，实现无人机与地面机器人的语义协作，解决无人机电池寿命和负载限制问题，成功率达到92%。


<details>
  <summary>Details</summary>
Motivation: 随着物流效率需求的增长，无人机与自动导引车的协同工作成为趋势，但无人机受限于电池寿命和负载能力，需要地面支持。

Method: SwarmVLM利用视觉语言模型和检索增强生成技术调整阻抗控制参数，无人机作为领导者使用人工势场规划实时导航，地面机器人通过虚拟阻抗链接跟随。

Result: 系统在12次真实世界试验中成功率达92%，视觉语言模型在理想光照条件下对象检测和阻抗参数选择准确率为8%，地面机器人能安全避开短障碍物。

Conclusion: SwarmVLM通过语义协作和自适应控制，实现了无人机与地面机器人的高效协同导航，适用于复杂环境。

Abstract: With the growing demand for efficient logistics, unmanned aerial vehicles
(UAVs) are increasingly being paired with automated guided vehicles (AGVs).
While UAVs offer the ability to navigate through dense environments and varying
altitudes, they are limited by battery life, payload capacity, and flight
duration, necessitating coordinated ground support.
  Focusing on heterogeneous navigation, SwarmVLM addresses these limitations by
enabling semantic collaboration between UAVs and ground robots through
impedance control. The system leverages the Vision Language Model (VLM) and the
Retrieval-Augmented Generation (RAG) to adjust impedance control parameters in
response to environmental changes. In this framework, the UAV acts as a leader
using Artificial Potential Field (APF) planning for real-time navigation, while
the ground robot follows via virtual impedance links with adaptive link
topology to avoid collisions with short obstacles.
  The system demonstrated a 92% success rate across 12 real-world trials. Under
optimal lighting conditions, the VLM-RAG framework achieved 8% accuracy in
object detection and selection of impedance parameters. The mobile robot
prioritized short obstacle avoidance, occasionally resulting in a lateral
deviation of up to 50 cm from the UAV path, which showcases safe navigation in
a cluttered setting.

</details>


### [368] [Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social Touch from Robots to Humans](https://arxiv.org/abs/2508.07839)
*Qiaoqiao Ren,Tony Belpaeme*

Main category: cs.RO

TL;DR: 研究探讨了多感官（触觉与听觉）结合在机器人情感表达中的重要性，发现结合模式显著提升情感解码准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注机器人通过面部表情和语音表达情感，而触觉情感交流研究不足。

Method: 开发多模态交互系统，结合25个振动电机与音频播放，测试32名中国参与者对10种情感和6种社交手势的感知。

Result: 多感官结合显著提升情感识别准确性；触觉和听觉各自对特定情感表达有优势；手势单独难以清晰传达情感。

Conclusion: 多感官整合对提升人机情感交互至关重要，触觉与听觉线索在情感交流中具有互补作用。

Abstract: Affective tactile interaction constitutes a fundamental component of human
communication. In natural human-human encounters, touch is seldom experienced
in isolation; rather, it is inherently multisensory. Individuals not only
perceive the physical sensation of touch but also register the accompanying
auditory cues generated through contact. The integration of haptic and auditory
information forms a rich and nuanced channel for emotional expression. While
extensive research has examined how robots convey emotions through facial
expressions and speech, their capacity to communicate social gestures and
emotions via touch remains largely underexplored. To address this gap, we
developed a multimodal interaction system incorporating a 5*5 grid of 25
vibration motors synchronized with audio playback, enabling robots to deliver
combined haptic-audio stimuli. In an experiment involving 32 Chinese
participants, ten emotions and six social gestures were presented through
vibration, sound, or their combination. Participants rated each stimulus on
arousal and valence scales. The results revealed that (1) the combined
haptic-audio modality significantly enhanced decoding accuracy compared to
single modalities; (2) each individual channel-vibration or sound-effectively
supported certain emotions recognition, with distinct advantages depending on
the emotional expression; and (3) gestures alone were generally insufficient
for conveying clearly distinguishable emotions. These findings underscore the
importance of multisensory integration in affective human-robot interaction and
highlight the complementary roles of haptic and auditory cues in enhancing
emotional communication.

</details>


### [369] [DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts](https://arxiv.org/abs/2508.07842)
*Yutong Shen,Hangxu Liu,Penghui Liu,Ruizhe Xia,Tianyi Yao,Yitong Sun,Tongtong Feng*

Main category: cs.RO

TL;DR: DETACH是一个通过双流解耦实现跨领域长时程任务的框架，显著提升了任务成功率和执行效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖技能链式拼接，无法泛化到新环境和技能组合，难以完成跨领域长时程任务。

Method: DETACH采用双流解耦机制，分为环境学习模块（空间理解）和技能学习模块（任务执行），实现跨领域和跨技能迁移。

Result: 实验表明，DETACH在任务成功率和执行效率上分别平均提升23%和29%。

Conclusion: DETACH通过生物启发的双流解耦机制，有效解决了跨领域长时程任务的泛化和执行问题。

Abstract: Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex
multi-step tasks that require continuous planning, sequential decision-making,
and extended execution across domains to achieve the final goal. However,
existing methods heavily rely on skill chaining by concatenating pre-trained
subtasks, with environment observations and self-state tightly coupled, lacking
the ability to generalize to new combinations of environments and skills,
failing to complete various LH tasks across domains. To solve this problem,
this paper presents DETACH, a cross-domain learning framework for LH tasks via
biologically inspired dual-stream disentanglement. Inspired by the brain's
"where-what" dual pathway mechanism, DETACH comprises two core modules: i) an
environment learning module for spatial understanding, which captures object
functions, spatial relationships, and scene semantics, achieving cross-domain
transfer through complete environment-self disentanglement; ii) a skill
learning module for task execution, which processes self-state information
including joint degrees of freedom and motor patterns, enabling cross-skill
transfer through independent motor pattern encoding. We conducted extensive
experiments on various LH tasks in HSI scenes. Compared with existing methods,
DETACH can achieve an average subtasks success rate improvement of 23% and
average execution efficiency improvement of 29%.

</details>


### [370] [MolmoAct: Action Reasoning Models that can Reason in Space](https://arxiv.org/abs/2508.07917)
*Jason Lee,Jiafei Duan,Haoquan Fang,Yuquan Deng,Shuo Liu,Boyang Li,Bohan Fang,Jieyu Zhang,Yi Ru Wang,Sangho Lee,Winson Han,Wilbert Pumacay,Angelica Wu,Rose Hendrix,Karen Farley,Eli VanderBilt,Ali Farhadi,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: 论文提出了一种名为Action Reasoning Models (ARMs)的视觉-语言-动作模型，通过三阶段结构化流程整合感知、规划与控制，提升了机器人的适应性和语义理解能力。其模型MolmoAct在仿真和现实任务中表现优异，并发布了首个机器人训练数据集。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型直接将感知和指令映射到控制，限制了适应性、泛化能力和语义理解。ARMs旨在通过结构化推理解决这些问题。

Method: MolmoAct采用三阶段流程：1) 将观察和指令编码为深度感知令牌；2) 生成可编辑的空间规划轨迹；3) 预测精确的低级动作。

Result: MolmoAct在多个任务中表现优异：仿真任务70.5%零样本准确率，LIBERO任务86.6%成功率，现实任务提升10%-22.7%。同时发布了10,000+高质量轨迹数据集。

Conclusion: MolmoAct是当前最先进的机器人基础模型，通过结构化推理将感知转化为有目的的动作，并开源了模型权重、代码和数据集。

Abstract: Reasoning is central to purposeful action, yet most robotic foundation models
map perception and instructions directly to control, which limits adaptability,
generalization, and semantic grounding. We introduce Action Reasoning Models
(ARMs), a class of vision-language-action models that integrate perception,
planning, and control through a structured three-stage pipeline. Our model,
MolmoAct, encodes observations and instructions into depth-aware perception
tokens, generates mid-level spatial plans as editable trajectory traces, and
predicts precise low-level actions, enabling explainable and steerable
behavior. MolmoAct-7B-D achieves strong performance across simulation and
real-world settings: 70.5% zero-shot accuracy on SimplerEnv Visual Matching
tasks, surpassing closed-source Pi-0 and GR00T N1; 86.6% average success on
LIBERO, including an additional 6.3% gain over ThinkAct on long-horizon tasks;
and in real-world fine-tuning, an additional 10% (single-arm) and an additional
22.7% (bimanual) task progression over Pi-0-FAST. It also outperforms baselines
by an additional 23.3% on out-of-distribution generalization and achieves top
human-preference scores for open-ended instruction following and trajectory
steering. Furthermore, we release, for the first time, the MolmoAct Dataset --
a mid-training robot dataset comprising over 10,000 high quality robot
trajectories across diverse scenarios and tasks. Training with this dataset
yields an average 5.5% improvement in general performance over the base model.
We release all model weights, training code, our collected dataset, and our
action reasoning dataset, establishing MolmoAct as both a state-of-the-art
robotics foundation model and an open blueprint for building ARMs that
transform perception into purposeful action through structured reasoning.
Blogpost: https://allenai.org/blog/molmoact

</details>


### [371] [PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF](https://arxiv.org/abs/2508.07945)
*En Yen Puang,Federico Ceola,Giulia Pasquale,Lorenzo Natale*

Main category: cs.RO

TL;DR: PCHands提出了一种通用表示方法，用于不同形态机械手的灵巧操作学习，通过简化的锚点位置描述格式，提取跨机械手的姿态协同性。


<details>
  <summary>Details</summary>
Motivation: 解决不同形态机械手在灵巧操作中通用表示学习的问题。

Method: 提出PCHands方法，基于锚点位置定义统一描述格式，学习可变长度潜在表示，并提取跨机械手的主成分。

Result: PCHands在强化学习任务中表现优于关节空间基线，且在跨机械手演示中表现鲁棒。

Conclusion: PCHands为不同形态机械手提供了一种高效的通用表示方法，适用于灵巧操作任务。

Abstract: We consider the problem of learning a common representation for dexterous
manipulation across manipulators of different morphologies. To this end, we
propose PCHands, a novel approach for extracting hand postural synergies from a
large set of manipulators. We define a simplified and unified description
format based on anchor positions for manipulators ranging from 2-finger
grippers to 5-finger anthropomorphic hands. This enables learning a
variable-length latent representation of the manipulator configuration and the
alignment of the end-effector frame of all manipulators. We show that it is
possible to extract principal components from this latent representation that
is universal across manipulators of different structures and degrees of
freedom. To evaluate PCHands, we use this compact representation to encode
observation and action spaces of control policies for dexterous manipulation
tasks learned with RL. In terms of learning efficiency and consistency, the
proposed representation outperforms a baseline that learns the same tasks in
joint space. We additionally show that PCHands performs robustly in RL from
demonstration, when demonstrations are provided from a different manipulator.
We further support our results with real-world experiments that involve a
2-finger gripper and a 4-finger anthropomorphic hand. Code and additional
material are available at https://hsp-iit.github.io/PCHands/.

</details>


### [372] [Aerial Target Encirclement and Interception with Noisy Range Observations](https://arxiv.org/abs/2508.08046)
*Fen Liu,Shenghai Yuan,Thien-Minh Nguyen,Wei Meng,Lihua Xie*

Main category: cs.RO

TL;DR: 提出一种利用噪声距离测量进行状态估计的策略，通过3D“振动弦”轨迹实现目标快速定位与拦截。


<details>
  <summary>Details</summary>
Motivation: 解决非合作空中目标的快速定位与拦截问题，同时考虑输入约束和观测性。

Method: 采用抗同步（AS）3D轨迹和卡尔曼滤波进行状态估计，设计新型抗目标控制器实现自适应拦截。

Result: 通过仿真和无人机实验验证了系统设计的有效性，状态估计误差和包围误差收敛。

Conclusion: 该方法在非合作目标拦截中表现出高效性和鲁棒性。

Abstract: This paper proposes a strategy to encircle and intercept a non-cooperative
aerial point-mass moving target by leveraging noisy range measurements for
state estimation. In this approach, the guardians actively ensure the
observability of the target by using an anti-synchronization (AS), 3D
``vibrating string" trajectory, which enables rapid position and velocity
estimation based on the Kalman filter. Additionally, a novel anti-target
controller is designed for the guardians to enable adaptive transitions from
encircling a protected target to encircling, intercepting, and neutralizing a
hostile target, taking into consideration the input constraints of the
guardians. Based on the guaranteed uniform observability, the exponentially
bounded stability of the state estimation error and the convergence of the
encirclement error are rigorously analyzed. Simulation results and real-world
UAV experiments are presented to further validate the effectiveness of the
system design.

</details>


### [373] [Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain](https://arxiv.org/abs/2508.08108)
*Wei Zhang,Yinchuan Wang,Wangtao Lu,Pengyu Zhang,Xiang Zhang,Yue Wang,Chaoqun Wang*

Main category: cs.RO

TL;DR: 提出了一种防倾覆轨迹规划器（CAP），用于在复杂地形中实现安全高效的导航。


<details>
  <summary>Details</summary>
Motivation: 地面机器人在复杂环境中自主导航面临挑战，需平衡安全性与效率。

Method: 分析机器人在崎岖地形上的倾覆稳定性，定义可穿越方向，并将其作为约束条件用于轨迹优化。

Result: 仿真和实验验证了CAP的优越性，其性能优于现有方法。

Conclusion: CAP在复杂地形导航中表现出高效性和鲁棒性。

Abstract: It is a challenging task for ground robots to autonomously navigate in harsh
environments due to the presence of non-trivial obstacles and uneven terrain.
This requires trajectory planning that balances safety and efficiency. The
primary challenge is to generate a feasible trajectory that prevents robot from
tip-over while ensuring effective navigation. In this paper, we propose a
capsizing-aware trajectory planner (CAP) to achieve trajectory planning on the
uneven terrain. The tip-over stability of the robot on rough terrain is
analyzed. Based on the tip-over stability, we define the traversable
orientation, which indicates the safe range of robot orientations. This
orientation is then incorporated into a capsizing-safety constraint for
trajectory optimization. We employ a graph-based solver to compute a robust and
feasible trajectory while adhering to the capsizing-safety constraint.
Extensive simulation and real-world experiments validate the effectiveness and
robustness of the proposed method. The results demonstrate that CAP outperforms
existing state-of-the-art approaches, providing enhanced navigation performance
on uneven terrains.

</details>


### [374] [AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies](https://arxiv.org/abs/2508.08113)
*Yinpei Dai,Jayjun Lee,Yichi Zhang,Ziqiao Ma,Jed Yang,Amir Zadeh,Chuan Li,Nima Fazeli,Joyce Chai*

Main category: cs.RO

TL;DR: AimBot是一种轻量级视觉增强技术，通过叠加辅助视觉提示（如射击线和准星）改善机器人操作的视觉运动策略学习。


<details>
  <summary>Details</summary>
Motivation: 提高机器人操作中视觉运动策略的学习效率，通过提供明确的空间线索来增强视觉反馈。

Method: 利用深度图像、相机外参和末端执行器姿态计算叠加的视觉提示，替换原始RGB图像，无需改变模型架构。

Result: 在仿真和实际环境中，AimBot显著提升了多种视觉运动策略的性能，计算开销极低（小于1毫秒）。

Conclusion: AimBot通过空间接地的视觉反馈，简单高效地提升了机器人操作的性能。

Abstract: In this paper, we propose AimBot, a lightweight visual augmentation technique
that provides explicit spatial cues to improve visuomotor policy learning in
robotic manipulation. AimBot overlays shooting lines and scope reticles onto
multi-view RGB images, offering auxiliary visual guidance that encodes the
end-effector's state. The overlays are computed from depth images, camera
extrinsics, and the current end-effector pose, explicitly conveying spatial
relationships between the gripper and objects in the scene. AimBot incurs
minimal computational overhead (less than 1 ms) and requires no changes to
model architectures, as it simply replaces original RGB images with augmented
counterparts. Despite its simplicity, our results show that AimBot consistently
improves the performance of various visuomotor policies in both simulation and
real-world settings, highlighting the benefits of spatially grounded visual
feedback.

</details>


### [375] [Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy](https://arxiv.org/abs/2508.08226)
*Haiyue Chen,Aniket Datar,Tong Xu,Francesco Cancelliere,Harsh Rangwala,Madhan Balaji Rao,Daeun Song,David Eichinger,Xuesu Xiao*

Main category: cs.RO

TL;DR: Verti-Arena是一个可重构的室内设施，旨在为越野自主性研究提供标准化测试环境，支持数据收集和算法验证。


<details>
  <summary>Details</summary>
Motivation: 越野导航对移动机器人至关重要，但缺乏可控的标准化测试环境限制了进展。

Method: 开发Verti-Arena设施，配备传感器和运动捕捉系统，提供可重复的垂直地形测试环境，并开发远程实验接口。

Result: Verti-Arena支持可重复实验、精确数据收集和算法比较，促进越野自主性研究。

Conclusion: Verti-Arena填补了越野自主性研究的测试环境空白，有望推动该领域发展。

Abstract: Off-road navigation is an important capability for mobile robots deployed in
environments that are inaccessible or dangerous to humans, such as disaster
response or planetary exploration. Progress is limited due to the lack of a
controllable and standardized real-world testbed for systematic data collection
and validation. To fill this gap, we introduce Verti-Arena, a reconfigurable
indoor facility designed specifically for off-road autonomy. By providing a
repeatable benchmark environment, Verti-Arena supports reproducible experiments
across a variety of vertically challenging terrains and provides precise ground
truth measurements through onboard sensors and a motion capture system.
Verti-Arena also supports consistent data collection and comparative evaluation
of algorithms in off-road autonomy research. We also develop a web-based
interface that enables research groups worldwide to remotely conduct
standardized off-road autonomy experiments on Verti-Arena.

</details>


### [376] [ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks](https://arxiv.org/abs/2508.08240)
*Kaijun Wang,Liqin Lu,Mingyu Liu,Jianuo Jiang,Zeju Li,Bolin Zhang,Wancai Zheng,Xinyi Yu,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: ODYSSEY是一个统一的移动操作框架，用于配备机械手的四足机器人，结合了高级任务规划和低级全身控制，解决了语言引导的长时程移动操作中的感知、泛化和控制问题。


<details>
  <summary>Details</summary>
Motivation: 解决语言引导的长时程移动操作中的三大挑战：受限的感知与操作范围、泛化能力不足以及高机动性与精确控制的平衡问题。

Method: 引入分层规划器（基于视觉语言模型）和新型全身控制策略，实现任务分解与精确执行，并在模拟到现实的迁移中验证。

Result: 成功在室内外场景中验证了系统的泛化能力和鲁棒性，展示了腿式机械手在非结构化环境中的实用性。

Conclusion: ODYSSEY框架推动了通用机器人助手在复杂动态任务中的可行性。

Abstract: Language-guided long-horizon mobile manipulation has long been a grand
challenge in embodied semantic reasoning, generalizable manipulation, and
adaptive locomotion. Three fundamental limitations hinder progress: First,
although large language models have improved spatial reasoning and task
planning through semantic priors, existing implementations remain confined to
tabletop scenarios, failing to address the constrained perception and limited
actuation ranges of mobile platforms. Second, current manipulation strategies
exhibit insufficient generalization when confronted with the diverse object
configurations encountered in open-world environments. Third, while crucial for
practical deployment, the dual requirement of maintaining high platform
maneuverability alongside precise end-effector control in unstructured settings
remains understudied.
  In this work, we present ODYSSEY, a unified mobile manipulation framework for
agile quadruped robots equipped with manipulators, which seamlessly integrates
high-level task planning with low-level whole-body control. To address the
challenge of egocentric perception in language-conditioned tasks, we introduce
a hierarchical planner powered by a vision-language model, enabling
long-horizon instruction decomposition and precise action execution. At the
control level, our novel whole-body policy achieves robust coordination across
challenging terrains. We further present the first benchmark for long-horizon
mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through
successful sim-to-real transfer, we demonstrate the system's generalization and
robustness in real-world deployments, underscoring the practicality of legged
manipulators in unstructured environments. Our work advances the feasibility of
generalized robotic assistants capable of complex, dynamic tasks. Our project
page: https://kaijwang.github.io/odyssey.github.io/

</details>


### [377] [BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion](https://arxiv.org/abs/2508.08241)
*Takara E. Truong,Qiayuan Liao,Xiaoyu Huang,Guy Tevet,C. Karen Liu,Koushil Sreenath*

Main category: cs.RO

TL;DR: BeyondMimic是一个从人类动作中学习的框架，用于实现多功能且自然的仿人机器人控制，结合了高质量的运动跟踪和扩散策略。


<details>
  <summary>Details</summary>
Motivation: 解决仿人机器人控制中缺乏高质量运动跟踪框架和有效动作蒸馏方法的问题。

Method: 提出BeyondMimic框架，包括运动跟踪管道和统一的扩散策略，支持零样本任务控制。

Result: 实现了高动态运动（如跳跃、冲刺、侧手翻）和多样化任务（如导航、避障）。

Conclusion: BeyondMimic成功结合了运动跟踪与动作合成，为仿人机器人控制提供了灵活且高效的解决方案。

Abstract: Learning skills from human motions offers a promising path toward
generalizable policies for whole-body humanoid control, yet two key
cornerstones are missing: (1) a high-quality motion tracking framework that
faithfully transforms large-scale kinematic references into robust and
extremely dynamic motions on real hardware, and (2) a distillation approach
that can effectively learn these motion primitives and compose them to solve
downstream tasks. We address these gaps with BeyondMimic, the first real-world
framework to learn from human motions for versatile and naturalistic humanoid
control via guided diffusion. Our framework provides a motion tracking pipeline
capable of challenging skills such as jumping spins, sprinting, and cartwheels
with state-of-the-art motion quality. Moving beyond mimicking existing motions
and synthesize novel ones, we further introduce a unified diffusion policy that
enables zero-shot task-specific control at test time using simple cost
functions. Deployed on hardware, BeyondMimic performs diverse tasks at test
time, including waypoint navigation, joystick teleoperation, and obstacle
avoidance, bridging sim-to-real motion tracking and flexible synthesis of human
motion primitives for whole-body control. https://beyondmimic.github.io/.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [378] [Dual-Head Physics-Informed Graph Decision Transformer for Distribution System Restoration](https://arxiv.org/abs/2508.06634)
*Hong Zhao,Jin Wei-Kocsis,Adel Heidari Akhijahani,Karen L Butler-Purry*

Main category: eess.SY

TL;DR: 论文提出了一种新型的双头物理信息图决策变换器（DH-PGDT），用于解决电力系统恢复中的零样本和少样本问题，结合物理建模和结构推理。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习（DRL）和决策变换器（DT）在电力系统恢复（DSR）中存在数据依赖性强、泛化能力不足的问题，尤其在零样本和少样本场景下表现不佳。

Method: 提出DH-PGDT，采用双头因果变换器架构，结合物理建模和图推理模块，生成子目标表示和动作向量，独立于RTG。

Result: DH-PGDT显著提升了泛化能力，能够适应未见过的场景，并在动态电力系统环境中表现稳健。

Conclusion: DH-PGDT不仅适用于电力系统恢复，还可推广至其他复杂工程领域的序列决策问题。

Abstract: Driven by recent advances in sensing and computing, deep reinforcement
learning (DRL) technologies have shown great potential for addressing
distribution system restoration (DSR) under uncertainty. However, their
data-intensive nature and reliance on the Markov Decision Process (MDP)
assumption limit their ability to handle scenarios that require long-term
temporal dependencies or few-shot and zero-shot decision making. Emerging
Decision Transformers (DTs), which leverage causal transformers for sequence
modeling in DRL tasks, offer a promising alternative. However, their reliance
on return-to-go (RTG) cloning and limited generalization capacity restricts
their effectiveness in dynamic power system environments. To address these
challenges, we introduce an innovative Dual-Head Physics-informed Graph
Decision Transformer (DH-PGDT) that integrates physical modeling, structural
reasoning, and subgoal-based guidance to enable scalable and robust DSR even in
zero-shot or few-shot scenarios. DH-PGDT features a dual-head physics-informed
causal transformer architecture comprising Guidance Head, which generates
subgoal representations, and Action Head, which uses these subgoals to generate
actions independently of RTG. It also incorporates an operational
constraint-aware graph reasoning module that encodes power system topology and
operational constraints to generate a confidence-weighted action vector for
refining DT trajectories. This design effectively improves generalization and
enables robust adaptation to unseen scenarios. While this work focuses on DSR,
the underlying computing model of the proposed PGDT is broadly applicable to
sequential decision making across various power system operations and other
complex engineering domains.

</details>


### [379] [Embedded Microcontrol for Photovoltaic Water Pumping System](https://arxiv.org/abs/2508.06708)
*Justin London*

Main category: eess.SY

TL;DR: 提出了一种新型3轴太阳能跟踪水泵系统，通过光伏电池转换太阳能，储存在12V电池中，驱动水泵，并利用嵌入式微控制器和软件实现控制。


<details>
  <summary>Details</summary>
Motivation: 旨在利用太阳能高效驱动水泵系统，实现自动化的水资源管理，适用于农业灌溉等场景。

Method: 系统采用光伏电池、MPPT算法、超声波传感器和土壤湿度传感器，通过Arduino微控制器实现自动化控制。

Result: 通过仿真和实验验证了系统的可行性和效率。

Conclusion: 该系统为太阳能驱动的水泵提供了一种高效、自动化的解决方案。

Abstract: We introduce a novel 3-axis solar tracker water pumping system. The charge
generated from solar energy converted by the photovolatic panel (PV) cells is
stored in a 12V battery that in turn powers two water diaphragm pumps using a
solar charge controller that includes an MPPT algorithm that serves as a DC-DC
converter. The system is analyzed from an embedded microcontroller and embedded
software perspective using Arduino. The photovoltaic panel uses four light
photocell resistors (LPRs) which measure solar light intensity. An ultrasonic
sensor measures the water level in a reservoir water tank. If the water level
is too low, water is pumped from one water tank to the reservoir tank. Using a
soil moisture sensor, another water pump pumps water from the reservoir tank to
the plant if water is needed. Circuit designs for the system are provided as
well as the embedded software used. Simulation and experimental results are
given.

</details>


### [380] [Secure and Decentralized Peer-to-Peer Energy Transactions using Blockchain Technology](https://arxiv.org/abs/2508.06728)
*Antar Kumar Biswas,Masoud H. Nazari*

Main category: eess.SY

TL;DR: 提出了一种基于区块链的P2P能源交易机制，优化零售电力市场。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源（DERs）的普及，需要一种安全、可扩展的零售电力市场解决方案。

Method: 采用去中心化的竞价策略，利用以太坊测试网模拟市场设计和交易流程。

Result: 区块链网络能够确保DER参与者之间安全、透明和可持续的P2P能源交易。

Conclusion: 该机制在提升个体利润的同时，增强了社会福利，为DERs的广泛应用提供了可行方案。

Abstract: This paper presents an optimal peer-to-peer (P2P) energy transaction
mechanism leveraging decentralized blockchain technology to enable a secure and
scalable retail electricity market for the increasing penetration of
distributed energy resources (DERs). A decentralized bidding strategy is
proposed to maximize individual profits while collectively enhancing social
welfare. The market design and transaction processes are simulated using the
Ethereum testnet, demonstrating the blockchain network's capability to ensure
secure, transparent, and sustainable P2P energy trading among DER participants.

</details>


### [381] [Collaborative Computing Strategy Based SINS Prediction for Emergency UAVs Network](https://arxiv.org/abs/2508.06864)
*Bing Li,Haoming Guo,Zhiyuan Ren,Wenchi Cheng,Jialin Hu,Xinke Jian*

Main category: eess.SY

TL;DR: 提出了一种基于SINS预测的协作计算策略，用于无人机应急网络，通过WTEG和DAG映射优化任务调度，显著降低了延迟并提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 应急场景中无人机网络动态性强且条件恶劣，需及时调整轨迹以避免任务失败。

Method: 构建两步加权时间扩展图（WTEG）处理动态拓扑变化，将任务调度建模为DAG到WTEG的映射问题，并使用BPSO算法优化映射策略。

Result: 协作计算策略在延迟上显著优于云和本地计算，且SINS预测显著提高了任务成功率。

Conclusion: 该方法有效解决了应急无人机网络的动态性和延迟问题，提高了任务可靠性。

Abstract: In emergency scenarios, the dynamic and harsh conditions necessitate timely
trajectory adjustments for drones, leading to highly dynamic network topologies
and potential task failures. To address these challenges, a collaborative
computing strategy based strapdown inertial navigation system (SINS) prediction
for emergency UAVs network (EUN) is proposed, where a two-step weighted time
expanded graph (WTEG) is constructed to deal with dynamic network topology
changes. Furthermore, the task scheduling is formulated as a Directed Acyclic
Graph (DAG) to WTEG mapping problem to achieve collaborative computing while
transmitting among UAVs. Finally, the binary particle swarm optimization (BPSO)
algorithm is employed to choose the mapping strategy that minimizes end-to-end
processing latency. The simulation results validate that the collaborative
computing strategy significantly outperforms both cloud and local computing in
terms of latency. Moreover, the task success rate using SINS is substantially
improved compared to approaches without prior prediction.

</details>


### [382] [Average Consensus with Dynamic Compression in Bandwidth-Limited Directed Networks](https://arxiv.org/abs/2508.06893)
*Evagoras Makridis,Gabriele Oliva,Apostolos I. Rikos,Themistoklis Charalambous*

Main category: eess.SY

TL;DR: 提出了一种针对有向不平衡网络的分布式共识算法PP-ACDC，通过动态压缩和自适应量化实现精确平均收敛。


<details>
  <summary>Details</summary>
Motivation: 解决有向不平衡网络在有限比特率通信下的平均共识问题。

Method: 采用Push-Pull平均共识算法结合动态压缩（PP-ACDC），利用自适应量化方案，无需全局信息。

Result: 数值分析和仿真验证了PP-ACDC的性能，实现了精确平均收敛。

Conclusion: PP-ACDC算法在有限比特率通信下有效解决了有向不平衡网络的共识问题。

Abstract: In this paper, the average consensus problem has been considered for directed
unbalanced networks under finite bit-rate communication. We propose the
Push-Pull Average Consensus algorithm with Dynamic Compression (PP-ACDC)
algorithm, a distributed consensus algorithm that deploys an adaptive
quantization scheme and achieves convergence to the exact average without the
need of global information. A preliminary numerical convergence analysis and
simulation results corroborate the performance of PP-ACDC.

</details>


### [383] [Decoupling Structural Heterogeneity from Functional Fairness in Complex Networks: A Theoretical Framework based on the Imbalance Metric](https://arxiv.org/abs/2508.06898)
*Zhiyuan Ren,Zhiliang Shuai,Wenchi Cheng,Kun Yang*

Main category: eess.SY

TL;DR: 论文提出了一种新指标“网络不平衡性（I）”，用于从感知QoS角度定量评估端到端可访问性的公平性，揭示了结构异质性网络如何实现高功能公平性。


<details>
  <summary>Details</summary>
Motivation: 传统网络性能评估多关注结构完整性或平均传输效率，忽视了功能公平性，论文旨在填补这一空白。

Method: 结合可调sigmoid函数和全局香农熵框架，提出I指标量化节点对间连接体验的均匀性，并在经典网络模型中验证其解释力。

Result: 发现低不平衡性（高功能公平性）可通过拓扑对称性或极端连接效率实现，结构与功能解耦为网络设计提供了新视角。

Conclusion: I指标为网络性能评估提供了新理论视角，并为平衡效率与公平性提供了有效工具。

Abstract: Performance evaluation of complex networks has traditionally focused on
structural integrity or average transmission efficiency, perspectives that
often overlook the dimension of functional fairness. This raises a central
question: Under certain conditions, structurally heterogeneous networks can
exhibit high functional fairness. To systematically address this issue, we
introduce a new metric, Network Imbalance (I), designed to quantitatively
assess end-to-end accessibility fairness from a perceived QoS perspective. By
combining a tunable sigmoid function with a global Shannon entropy framework,
the I metric quantifies the uniformity of connection experiences between all
node pairs. We analyze the mathematical properties of this metric and validate
its explanatory power on various classical network models. Our findings reveal
that low imbalance (i.e., high functional fairness) can be achieved through two
distinct mechanisms: one via topological symmetry (e.g., in a complete graph)
and the other via extreme connection efficiency driven by structural inequality
(e.g., in a scale-free network). This decoupling of structure and function
provides a new theoretical perspective for network performance evaluation and
offers an effective quantitative tool for balancing efficiency and fairness in
network design.

</details>


### [384] [Fixed-Time Voltage Regulation for Boost Converters via Unit-Safe Saturating Functions](https://arxiv.org/abs/2508.06987)
*Yiwei Liu,Ziming Wang,Xin Wang,Yiding Ji*

Main category: eess.SY

TL;DR: 本文提出了一种用于升压转换器系统的固定时间稳定控制算法，解决了传统方法中的抖动问题，并通过状态观测器和自适应参数处理未知负载电阻的不确定性。


<details>
  <summary>Details</summary>
Motivation: 升压转换器在电力电子中至关重要，但其电压调节面临挑战，尤其是稳定性和抖动问题。

Method: 引入新型函数族解决抖动问题，结合状态观测器和自适应参数处理不确定性，并开发新的扰动观测器。

Result: 仿真验证了算法的有效性和可部署性。

Conclusion: 提出的控制算法在固定时间内实现稳定性，解决了传统方法的局限性。

Abstract: This paper explores the voltage regulation challenges in boost converter
systems, which are critical components in power electronics due to their
ability to step up voltage levels efficiently. The proposed control algorithm
ensures fixed-time stability, a desirable property that guarantees system
stability within a fixed time frame regardless of initial conditions. To tackle
the common chattering issues in conventional fixed-time control methods, a
novel class of function families is introduced. State observers and adaptive
parameters are utilized to manage the uncertainties associated with unknown
load resistance. Furthermore, a new disturbance observer is developed using the
proposed function family, and its advantages and limitations are illustrated
through comparison with existing designs. Finally, both non-real-time and
real-time simulations are conducted to validate the effectiveness and
deployability of the proposed control algorithm.

</details>


### [385] [Learning-Enabled Adaptive Power Capping Scheme for Cloud Data Centers](https://arxiv.org/abs/2508.06994)
*Yimeng Sun,Zhaohao Ding,Payman Dehghanian,Fei Teng*

Main category: eess.SY

TL;DR: 本文提出了一种针对云数据中心的自适应功率封顶框架，通过动态设置能耗上限，结合市场信号优化能耗管理。采用不确定性感知的模型强化学习方法，提升环境适应能力。


<details>
  <summary>Details</summary>
Motivation: 数字经济和人工智能的快速发展使云数据中心成为高能耗基础设施，现有方法因信息不全、参数不确定和动态环境等问题难以实际应用。

Method: 将功率封顶问题建模为部分可观测马尔可夫决策过程，开发不确定性感知的模型强化学习方法，结合两阶段优化算法提升适应性。

Result: 数值实验验证了方法的有效性，使用阿里真实生产数据模拟器展示了其作为高效能耗管理方案的潜力。

Conclusion: 该框架为云数据中心提供了一种适应动态环境的高效能耗管理解决方案。

Abstract: The rapid growth of the digital economy and artificial intelligence has
transformed cloud data centers into essential infrastructure with substantial
energy consumption and carbon emission, necessitating effective energy
management. However, existing methods face challenges such as incomplete
information, uncertain parameters, and dynamic environments, which hinder their
real-world implementation. This paper proposes an adaptive power capping
framework tailored to cloud data centers. By dynamically setting the energy
consumption upper bound, the power load of data centers can be reshaped to
align with the electricity price or other market signals. To this end, we
formulate the power capping problem as a partially observable Markov decision
process. Subsequently, we develop an uncertainty-aware model-based
reinforcement learning (MBRL) method to perceive the cloud data center
operational environment and optimize power-capping decisions. By incorporating
a two-stage uncertainty-aware optimization algorithm into the MBRL, we improve
its adaptability to the ever-changing environment. Additionally, we derive the
optimality gap of the proposed scheme under finite iterations, ensuring
effective decisions under complex and uncertain scenarios. The numerical
experiments validate the effectiveness of the proposed method using a cloud
data center operational environment simulator built on real-world production
traces from Alibaba, which demonstrates its potential as an efficient energy
management solution for cloud data centers.

</details>


### [386] [Distributionally Robust Control with Constraints on Linear Unidimensional Projections](https://arxiv.org/abs/2508.07121)
*Alexandros E. Tzikas,Lukas Fiechtner,Arec Jamgochian,Mykel J. Kochenderfer*

Main category: eess.SY

TL;DR: 本文提出了两种迭代方法，用于近似解决一类基于一维线性投影的分布鲁棒控制问题，并在投资组合构建和轨迹规划中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究如何在不确定性下做出最优决策，尤其是在概率分布不明确的情况下，通过定义一类可解释且表达能力强的模糊集来解决这一问题。

Method: 提出了两种近似方法：一种基于最佳响应动态的近似算法，另一种通过将问题转化为半无限规划并求解松弛问题。

Result: 方法在投资组合构建和轨迹规划场景中得到了验证，展示了其实际应用价值。

Conclusion: 本文的方法为解决一类分布鲁棒控制问题提供了有效的近似解决方案，适用于实际应用场景。

Abstract: Distributionally robust control is a well-studied framework for optimal
decision making under uncertainty, with the objective of minimizing an expected
cost function over control actions, assuming the most adverse probability
distribution from an ambiguity set. We consider an interpretable and expressive
class of ambiguity sets defined by constraints on the expected value of
functions of one-dimensional linear projections of the uncertain parameters.
Prior work has shown that, under conditions, problems in this class can be
reformulated as finite convex problems. In this work, we propose two iterative
methods that can be used to approximately solve problems of this class in the
general case. The first is an approximate algorithm based on best-response
dynamics. The second is an approximate method that first reformulates the
problem as a semi-infinite program and then solves a relaxation. We apply our
methods to portfolio construction and trajectory planning scenarios.

</details>


### [387] [An Analogy of Frequency Droop Control for Grid-forming Sources](https://arxiv.org/abs/2508.07177)
*Minghui Lu,Brett Ross*

Main category: eess.SY

TL;DR: 本文提出了一种基于水容器模型的类比方法，用于可视化电网中由电网形成（GFM）电源主导的功率流、频率调节和功率分配问题。


<details>
  <summary>Details</summary>
Motivation: 通过直观的水流现象解释抽象的功率流问题，并为电力系统背景较少的受众提供易于理解的演示工具。

Method: 将GFM电源的频率下垂特性类比为水容器的水位和尺寸，并通过模拟验证其有效性。

Result: 模拟结果验证了该类比方法的有效性，能够直观展示电网集成可再生能源的问题。

Conclusion: 提出的水容器类比是一种有效的可视化工具，适用于电力系统分析和教育。

Abstract: In this paper, we present an analogy for a power system dominated by
grid-forming (GFM) sources that proves to be a powerful visualization tool for
analyses of power flow, frequency regulation, and power dispatch. Frequency
droop characteristics of a typical GFM source are exactly reflected by an
ordinary model of water vessels. The frequency is represented by visible water
levels while the droop slope is reified by the vessel sizes. This proposed
analogy allows us to use the intuitive water-flow phenomenon to explain the
abstract power-flow problems. The grid integration of renewables via GFM
inverters is interestingly simulated by a vessel connected to an infinite water
tank. This paper also provides a means for demonstrating issues to audiences
with little or no background in power systems. Finally, the proposal is
verified by simulation results.

</details>


### [388] [Human-in-the-Loop Simulation for Real-Time Exploration of HVAC Demand Flexibility](https://arxiv.org/abs/2508.07314)
*Xinlei Zhou,Han Du,Emily W. Yap,Wanbin Dou,Mingyang Huang,Zhenjun Ma*

Main category: eess.SY

TL;DR: 开发了一个交互式仿真平台，用于探索HVAC系统的需求灵活性，用户可实时干预控制设置，模拟实际决策过程。


<details>
  <summary>Details</summary>
Motivation: 可再生能源并网增加，需求侧灵活性变得至关重要，HVAC系统因其高能耗和可控性成为重点研究对象。

Method: 开发了一个结合高保真仿真引擎和用户仪表板的交互式平台，用户可实时调整控制参数（如温度设定值）。

Result: 用户通过实时交互更直观地理解需求灵活性及其影响，支持更明智的决策。

Conclusion: 该平台为电网互动建筑操作提供了更直观的交互方式，扩展了HVAC需求灵活性的研究。

Abstract: The increasing integration of renewable energy into the power grid has
highlighted the critical importance of demand-side flexibility. Among flexible
loads, heating, ventilation, and air-conditioning (HVAC) systems are
particularly significant due to their high energy consumption and
controllability. This study presents the development of an interactive
simulation platform that integrates a high-fidelity simulation engine with a
user-facing dashboard, specifically designed to explore and demonstrate the
demand flexibility capacity of HVAC systems. Unlike conventional simulations,
where users are passive observers of simulation results with no ability to
intervene in the embedded control during the simulation, this platform
transforms them into active participants. Users can override system default
control settings, such as zone temperature setpoints and HVAC schedules, at any
point during the simulation runtime to implement demand response strategies of
their choice. This human-in-the-loop capability enables real-time interaction
and allows users to observe the immediate impact of their actions, emulating
the practical decision-making process of a building or system operator. By
exploring different demand flexibility scenarios and system behaviour in a
manner that reflects real-world operation, users gain a deeper understanding of
demand flexibility and their impacts. This interactive experience builds
confidence and supports more informed decision-making in the practical adoption
of demand-side flexibility. This paper presents the architecture of the
simulation platform, user-oriented dashboard design, and user case showcase.
The introduced human-in-the-loop simulation paradigm offers a more intuitive
and interactive means of engaging with grid-interactive building operations,
extending beyond HVAC demand flexibility exploration.

</details>


### [389] [Noise-Aware Generative Microscopic Traffic Simulation](https://arxiv.org/abs/2508.07453)
*Vindula Jayawardana,Catherine Tang,Junyi Ji,Jonah Philion,Xue Bin Peng,Cathy Wu*

Main category: eess.SY

TL;DR: 论文提出了一种基于噪声感知学习策略的生成模型，用于微观交通仿真，通过I-24 MOTION Scenario Dataset（I24-MSD）解决传统数据集的不足，提升仿真真实性。


<details>
  <summary>Details</summary>
Motivation: 传统微观交通仿真模型因简化复杂性而无法真实反映人类驾驶行为，而现有数据集过于理想化或缺乏标准化，无法捕捉真实世界传感的噪声和缺陷。

Method: 利用基础设施摄像头提取车辆轨迹数据，构建I24-MSD数据集，并采用噪声感知损失函数改进生成模型。

Result: 改进后的模型在真实性上优于传统基线，且通过显式处理数据缺陷而非抑制，获得更好效果。

Conclusion: I24-MSD为新一代微观交通仿真奠定了基础，更贴近实际需求，推动了智能交通系统的发展。

Abstract: Accurately modeling individual vehicle behavior in microscopic traffic
simulation remains a key challenge in intelligent transportation systems, as it
requires vehicles to realistically generate and respond to complex traffic
phenomena such as phantom traffic jams. While traditional human driver
simulation models offer computational tractability, they do so by abstracting
away the very complexity that defines human driving. On the other hand, recent
advances in infrastructure-mounted camera-based roadway sensing have enabled
the extraction of vehicle trajectory data, presenting an opportunity to shift
toward generative, agent-based models. Yet, a major bottleneck remains: most
existing datasets are either overly sanitized or lack standardization, failing
to reflect the noisy, imperfect nature of real-world sensing. Unlike data from
vehicle-mounted sensors-which can mitigate sensing artifacts like occlusion
through overlapping fields of view and sensor fusion-infrastructure-based
sensors surface a messier, more practical view of challenges that traffic
engineers encounter. To this end, we present the I-24 MOTION Scenario Dataset
(I24-MSD)-a standardized, curated dataset designed to preserve a realistic
level of sensor imperfection, embracing these errors as part of the learning
problem rather than an obstacle to overcome purely from preprocessing. Drawing
from noise-aware learning strategies in computer vision, we further adapt
existing generative models in the autonomous driving community for I24-MSD with
noise-aware loss functions. Our results show that such models not only
outperform traditional baselines in realism but also benefit from explicitly
engaging with, rather than suppressing, data imperfection. We view I24-MSD as a
stepping stone toward a new generation of microscopic traffic simulation that
embraces the real-world challenges and is better aligned with practical needs.

</details>


### [390] [A Multi-Model Probabilistic Framework for Seismic Risk Assessment and Retrofit Planning of Electric Power Networks](https://arxiv.org/abs/2508.07376)
*Huangbin Liang,Beatriz Moya,Francisco Chinesta,Eleni Chatzi*

Main category: eess.SY

TL;DR: 提出了一种多模型概率框架，用于电力系统的地震风险评估和改造规划，整合了地震危害、组件损坏、系统级影响和优化改造策略。


<details>
  <summary>Details</summary>
Motivation: 电力网络在地震中易受破坏，现有研究常忽略系统性行为和电气约束，导致风险估计不准确和改造决策低效。

Method: 结合区域地震危害、组件损坏分析、系统级级联影响评估和启发式优化改造规划，使用蒙特卡洛模拟传播不确定性。

Result: 在IEEE 24总线测试系统上验证了框架的有效性，能捕捉级联故障、识别关键组件并生成高效改造策略。

Conclusion: 该框架可作为提升电力基础设施抗震韧性的可扩展、数据驱动的决策支持工具。

Abstract: Electric power networks are critical lifelines, and their disruption during
earthquakes can lead to severe cascading failures and significantly hinder
post-disaster recovery. Enhancing their seismic resilience requires identifying
and strengthening vulnerable components in a cost-effective and system-aware
manner. However, existing studies often overlook the systemic behavior of power
networks under seismic loading. Common limitations include isolated component
analyses that neglect network-wide interdependencies, oversimplified damage
models assuming binary states or damage independence, and the exclusion of
electrical operational constraints. These simplifications can result in
inaccurate risk estimates and inefficient retrofit decisions. This study
proposes a multi-model probabilistic framework for seismic risk assessment and
retrofit planning of electric power systems. The approach integrates: (1)
regional seismic hazard characterization with ground motion prediction and
spatial correlation models; (2) component-level damage analysis using fragility
functions and multi-state damage-functionality mappings; (3) system-level
cascading impact evaluation through graph-based island detection and
constrained optimal power flow analysis; and (4) retrofit planning via
heuristic optimization to minimize expected annual functionality loss (EAFL)
under budget constraints. Uncertainty is propagated throughout the framework
using Monte Carlo simulation. The methodology is demonstrated on the IEEE
24-bus Reliability Test System, showcasing its ability to capture cascading
failures, identify critical components, and generate effective retrofit
strategies. Results underscore the potential of the framework as a scalable,
data-informed decision-support tool for enhancing the seismic resilience of
power infrastructure.

</details>


### [391] [Neuro-Symbolic Acceleration of MILP Motion Planning with Temporal Logic and Chance Constraints](https://arxiv.org/abs/2508.07515)
*Junyang Cai,Weimin Huang,Jyotirmoy V. Deshmukh,Lars Lindemann,Bistra Dilkina*

Main category: eess.SY

TL;DR: 论文提出了一种神经符号方法，通过机器学习加速混合整数线性规划（MILP）求解，用于复杂任务规划，性能提升约20%。


<details>
  <summary>Details</summary>
Motivation: 现有MILP规划方法计算成本高且扩展性差，难以满足实时需求。

Method: 采用神经符号方法，利用图神经网络指导MILP求解器的符号搜索，应用于STL规范和CPP约束的规划问题。

Result: 实验表明，该方法在运行时间和解质量上平均提升约20%。

Conclusion: 神经符号搜索技术显著提升了MILP求解的扩展性和性能。

Abstract: Autonomous systems must solve motion planning problems subject to
increasingly complex, time-sensitive, and uncertain missions. These problems
often involve high-level task specifications, such as temporal logic or chance
constraints, which require solving large-scale Mixed-Integer Linear Programs
(MILPs). However, existing MILP-based planning methods suffer from high
computational cost and limited scalability, hindering their real-time
applicability. We propose to use a neuro-symbolic approach to accelerate
MILP-based motion planning by leveraging machine learning techniques to guide
the solver's symbolic search. Focusing on two representative classes of
planning problems, namely, those with Signal Temporal Logic (STL)
specifications and those with chance constraints formulated via Conformal
Predictive Programming (CPP). We demonstrate how graph neural network-based
learning methods can guide traditional symbolic MILP solvers in solving
challenging planning problems, including branching variable selection and
solver parameter configuration. Through extensive experiments, we show that
neuro-symbolic search techniques yield scalability gains. Our approach yields
substantial improvements, achieving an average performance gain of about 20%
over state-of-the-art solver across key metrics, including runtime and solution
quality.

</details>


### [392] [Nonlinear Systems in Wireless Power Transfer Applications](https://arxiv.org/abs/2508.07627)
*H Chan*

Main category: eess.SY

TL;DR: 本文介绍了三种采用非线性控制方法的无线电力传输（WPT）系统，旨在深入理解非线性系统的过程。


<details>
  <summary>Details</summary>
Motivation: 无线电力传输（WPT）为电动设备提供了一种新的能量获取方式，减少了对电池的过度依赖。

Method: 提出了三种使用非线性控制方法的WPT系统。

Result: 通过研究这些系统，深入理解了非线性系统的过程。

Conclusion: 非线性控制方法在WPT系统中的应用有助于优化能量传输，减少对电池的依赖。

Abstract: As a novel pattern of energization, the wireless power transfer (WPT) offers
a brand-new way to the energy acquisition for electric-driven devices, thus
alleviating the over-dependence on the battery. This report presents three
types of WPT systems that use nonlinear control methods, in order to acquire an
in-depth understanding of the course of Nonlinear Systems.

</details>


### [393] [When are safety filters safe? On minimum phase conditions of control barrier functions](https://arxiv.org/abs/2508.07684)
*Jason J. Choi,Claire J. Tomlin,Shankar Sastry,Koushil Sreenath*

Main category: eess.SY

TL;DR: 论文研究了基于控制屏障函数（CBF）的安全滤波器的内部动力学问题，发现CBF可能导致内部状态发散，提出了一种新的CBF最小相位条件以确保系统状态有界。


<details>
  <summary>Details</summary>
Motivation: 在复杂多任务控制应用中，CBF因其简单性被广泛用于设计安全滤波器，但其可能导致内部状态发散，因此需要研究如何确保系统状态有界。

Method: 借鉴输入输出线性化文献中的最小相位条件，提出了一种新的CBF最小相位条件，适用于CBF约束下的系统结构。

Result: 通过数值实验验证了分析的正确性，并证明了所提CBF最小相位条件的必要性。

Conclusion: 提出的CBF最小相位条件能够有效确保系统状态有界，为CBF安全滤波器的设计提供了理论支持。

Abstract: In emerging control applications involving multiple and complex tasks, safety
filters are gaining prominence as a modular approach to enforcing safety
constraints. Among various methods, control barrier functions (CBFs) are widely
used for designing safety filters due to their simplicity, imposing a single
linear constraint on the control input at each state. In this work, we focus on
the internal dynamics of systems governed by CBF-constrained control laws. Our
key observation is that, although CBFs guarantee safety by enforcing state
constraints, they can inadvertently be "unsafe" by causing the internal state
to diverge. We investigate the conditions under which the full system state,
including the internal state, can remain bounded under a CBF-based safety
filter. Drawing inspiration from the input-output linearization literature,
where boundedness is ensured by minimum phase conditions, we propose a new set
of CBF minimum phase conditions tailored to the structure imposed by the CBF
constraint. A critical distinction from the original minimum phase conditions
is that the internal dynamics in our setting is driven by a nonnegative virtual
control input, which reflects the enforcement of the safety constraint. We
include a range of numerical examples, including single-input, multi-input,
linear, and nonlinear systems, validating both our analysis and the necessity
of the proposed CBF minimum phase conditions.

</details>


### [394] [Deep Reinforcement Learning-Based Control Strategy with Direct Gate Control for Buck Converters](https://arxiv.org/abs/2508.07693)
*Noboru Katayama*

Main category: eess.SY

TL;DR: 提出了一种基于深度强化学习（DRL）的直接门控信号控制方法，用于Buck转换器的电压调节，优于传统PWM控制。


<details>
  <summary>Details</summary>
Motivation: 传统控制方法在速度和灵活性上受限，需要一种更高效且稳定的电压调节方案。

Method: 通过DRL训练的神经网络直接生成门控信号，实现快速和灵活的电压调节。

Result: 仿真结果显示，该方法具有更快的瞬态响应和稳定的输出电压调节，且对参数变化和传感器噪声具有强鲁棒性。

Conclusion: 该方法适用于实际电力电子应用，并通过仿真验证了其有效性。

Abstract: This paper proposes a deep reinforcement learning (DRL)-based approach for
directly controlling the gate signals of switching devices to achieve voltage
regulation in a buck converter. Unlike conventional control methods, the
proposed method directly generates gate signals using a neural network trained
through DRL, with the objective of achieving high control speed and flexibility
while maintaining stability. Simulation results demonstrate that the proposed
direct gate control (DGC) method achieves a faster transient response and
stable output voltage regulation, outperforming traditional PWM-based control
schemes. The DGC method also exhibits strong robustness against parameter
variations and sensor noise, indicating its suitability for practical power
electronics applications. The effectiveness of the proposed approach is
validated via simulation.

</details>


### [395] [Robust Integrated Priority and Speed Control based on Hierarchical Stochastic Optimization to Promote Bus Schedule Adherence along Signalized Arterial](https://arxiv.org/abs/2508.07749)
*Shurui Guan,Keqiang Li,Haoyu Yang,Yihe Chen,Hanxiao Ren,Yugong Luo*

Main category: eess.SY

TL;DR: 论文提出了一种基于分层随机优化的鲁棒集成优先级和速度控制策略，以提升公交车的准点率和时间间隔一致性，同时减少对车辆延误的影响。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中，自适应公交信号优先（TSP）和动态公交控制系统因缺乏协调可能导致冲突决策，现有研究仅依赖信号重新规划，无法应对现实交叉口的不确定性。

Method: 采用分层随机优化框架，上层确保交叉口间协调，下层通过随机编程处理每个交叉口的不确定性，并利用样本平均近似（SAA）并行解决局部问题。

Result: 仿真实验显示，该方法显著提升了公交准点率和时间间隔一致性，且对车辆延误的负面影响仅为0.8%-5.2%。

Conclusion: 提出的方法有效解决了公交信号优先与动态控制的协调问题，适用于现实交叉口环境。

Abstract: In intelligent transportation systems (ITS), adaptive transit signal priority
(TSP) and dynamic bus control systems have been independently developed to
maintain efficient and reliable urban bus services. However, those two systems
could potentially lead to conflicting decisions due to the lack of
coordination. Although some studies explore the integrated control strategies
along the arterial, they merely rely on signal replanning to address system
uncertainties. Therefore, their performance severely deteriorates in real-world
intersection settings, where abrupt signal timing variation is not always
applicable in consideration of countdown timers and pedestrian signal design.
  In this study, we propose a robust integrated priority and speed control
strategy based on hierarchical stochastic optimization to enhance bus schedule
adherence along the arterial. In the proposed framework, the upper level
ensures the coordination across intersections while the lower level handles
uncertainties for each intersection with stochastic programming. Hence, the
route-level system randomness is decomposed into a series of local problems
that can be solved in parallel using sample average approximation (SAA).
Simulation experiments are conducted under various scenarios with stochastic
bus dwell time and different traffic demand. The results demonstrate that our
approach significantly enhances bus punctuality and time headway equivalence
without abrupt signal timing variation, with negative impacts on car delays
limited to only 0.8%-5.2% as traffic demand increases.

</details>


### [396] [Deep Reinforcement Learning with Local Interpretability for Transparent Microgrid Resilience Energy Management](https://arxiv.org/abs/2508.08132)
*Mohammad Hossein Nejati Amiri,Fawaz Annaz,Mario De Oliveira,Florimond Gueniat*

Main category: eess.SY

TL;DR: 论文提出了一种结合可解释深度强化学习（XDRL）的方法，通过PPO算法和LIME方法提升微电网韧性管理，并在印度Ongole的案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源的波动性和HILP事件对微电网可靠性和韧性的挑战。

Method: 使用PPO算法进行决策，结合LIME方法提升决策透明度，并在极端天气条件下模拟微电网运行。

Result: 韧性指数（RI）达到0.9736，电池寿命估计为15.11年，LIME分析揭示了可再生能源生成是决策的关键因素。

Conclusion: 结合DRL和可解释AI技术能有效实现微电网的可靠和透明能源管理。

Abstract: Renewable energy integration into microgrids has become a key approach to
addressing global energy issues such as climate change and resource scarcity.
However, the variability of renewable sources and the rising occurrence of High
Impact Low Probability (HILP) events require innovative strategies for reliable
and resilient energy management. This study introduces a practical approach to
managing microgrid resilience through Explainable Deep Reinforcement Learning
(XDRL). It combines the Proximal Policy Optimization (PPO) algorithm for
decision-making with the Local Interpretable Model-agnostic Explanations (LIME)
method to improve the transparency of the actor network's decisions. A case
study in Ongole, India, examines a microgrid with wind, solar, and battery
components to validate the proposed approach. The microgrid is simulated under
extreme weather conditions during the Layla cyclone. LIME is used to analyse
scenarios, showing the impact of key factors such as renewable generation,
state of charge, and load prioritization on decision-making. The results
demonstrate a Resilience Index (RI) of 0.9736 and an estimated battery lifespan
of 15.11 years. LIME analysis reveals the rationale behind the agent's actions
in idle, charging, and discharging modes, with renewable generation identified
as the most influential feature. This study shows the effectiveness of
integrating advanced DRL algorithms with interpretable AI techniques to achieve
reliable and transparent energy management in microgrids.

</details>


### [397] [Robust Adaptive Discrete-Time Control Barrier Certificate](https://arxiv.org/abs/2508.08153)
*Changrui Liu,Anil Alan,Shengling Shi,Bart De Schutter*

Main category: eess.SY

TL;DR: 提出了一种基于控制屏障函数（CBFs）的鲁棒自适应控制策略，用于离散时间系统，确保在参数模型不确定性和扰动下的安全性。


<details>
  <summary>Details</summary>
Motivation: 解决离散时间系统在参数不确定性和扰动下的安全性问题，简化安全自适应控制器的开发。

Method: 利用离散时间的屏障函数证书，结合在线参数估计算法，确保安全集的正不变性。

Result: 提出的鲁棒自适应CBF框架能够独立设计参数估计模块和CBF安全滤波器，保证系统在安全集内运行。

Conclusion: 该方法为离散时间安全关键系统提供了一种有效的实时实现策略，具有实际应用潜力。

Abstract: This work develops a robust adaptive control strategy for discrete-time
systems using Control Barrier Functions (CBFs) to ensure safety under
parametric model uncertainty and disturbances. A key contribution of this work
is establishing a barrier function certificate in discrete time for general
online parameter estimation algorithms. This barrier function certificate
guarantees positive invariance of the safe set despite disturbances and
parametric uncertainty without access to the true system parameters. In
addition, real-time implementation and inherent robustness guarantees are
provided. Our approach demonstrates that, using the proposed robust adaptive
CBF framework, the parameter estimation module can be designed separately from
the CBF-based safety filter, simplifying the development of safe adaptive
controllers for discrete-time systems. The resulting safety filter guarantees
that the system remains within the safe set while adapting to model
uncertainties, making it a promising strategy for real-world applications
involving discrete-time safety-critical systems.

</details>


### [398] [Pinching-Antenna Systems (PASS)-based Indoor Positioning](https://arxiv.org/abs/2508.08185)
*Yaoyu Zhang,Xin Sun,Jun Wang,Tianwei Hou,Anna Li,Yuanwei Liu,Arumugam Nallanathan*

Main category: eess.SY

TL;DR: 本文提出了一种基于Pinching天线（PA）的上行链路室内定位系统（PASS），利用其几何确定性模型和米级重构能力，通过RSSI方法和WLS算法实现高效定位。


<details>
  <summary>Details</summary>
Motivation: 为了解决室内定位问题，利用PA的灵活性和重构能力，提出了一种新型的上行链路定位系统模型。

Method: 提出基于PASS的RSSI方法测量用户到PA的距离，并设计WLS算法计算用户二维坐标。

Result: 实验表明，增加PA数量可提高定位精度和鲁棒性，但超过阈值后性能增益有限；用户位于PA之间或附近时定位精度更高。

Conclusion: PASS系统在室内定位中表现出高效性和适用性，PA数量和布局对定位性能有显著影响。

Abstract: Pinching antenna (PA), a flexible waveguide integrated with dielectric
particles, intelligently reconstructs line-of-sight channels. Utilizing its
geometric deterministic model and meter-level reconstruction, PA systems (PASS)
are applied to uplink indoor positioning. In this paper, the uplink positioning
system model for PASS is firstly proposed. A PASS-based received signal
strength indication (RSSI) method is proposed to measure the distance from the
users to each PA, which is efficient and suitable for PASS. PASS-based weighted
least squares (WLS) algorithm is designed to calculate the two-dimensional
coordinates of the users. Several critical observations can be drawn from our
results: i) More PAs on the waveguide improves the positioning accuracy and
robustness. ii) When the number of PAs exceeds a certain threshold, the
performance gain becomes marginal. iii) User locations between and near PAs
yield superior positioning accuracy.

</details>


### [399] [IDSO-Managed Bid-Based Transactive Distribution Systems Design for DER Participation in Wholesale Markets While Preserving T-D Interactions](https://arxiv.org/abs/2508.08187)
*Swastik Sharma,Swathi Battula,Sri Niwas Singh*

Main category: eess.SY

TL;DR: 论文提出了一种独立配电系统运营商（IDSO）管理的基于投标的交互式能源系统设计，以保持输配电系统的紧密耦合，并允许分布式能源资源（DER）参与批发电力市场。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决输配电系统在交互式能源系统中的强耦合问题，确保分布式能源资源的安全高效参与。

Method: 提出了一种IDSO管理的投标系统设计，包括投标/报价预审与聚合方法，以及反映电力真实价值的零售定价机制。

Result: 通过修改的IEEE 123总线径向馈线案例验证了所提框架在高效可靠协调DER方面的有效性。

Conclusion: 该设计成功实现了输配电系统的紧密耦合，并为DER参与批发市场提供了可行方案。

Abstract: Participation of Distributed Energy Resources (DERs) in bid-based Transactive
Energy Systems (TES) at the distribution systems facilitates strongly coupled,
bidirectional interactions between Transmission-Distribution (T-D) systems.
Capturing these interactions is critical for ensuring seamless integration
within an Integrated Transmission and Distribution (ITD) framework. This study
proposes a methodology to preserve such tight T-D linkages by developing an
Independent Distribution System Operator (IDSO) managed bid-based TES design
for unbalanced distribution systems. The proposed design operates within the
ITD paradigm and permits DER participation in the Wholesale Power Market (WPM)
through IDSO while preserving tight T-D linkages. To this end, this research
offers the following key contributions: a novel bid/offer
prequalification-cum-aggregation method to ensure a grid-safe and value-based
aggregation of DERs' bids and offers for WPM participation through IDSO; and a
retail pricing mechanism that reflects the true value of procuring or offering
additional units of power within the distribution system. Case studies are
conducted on a modified IEEE 123-bus radial feeder populated with a high DER
concentration to validate the proposed frameworks' effectiveness in
coordinating the DERs efficiently and reliably.

</details>


### [400] [Autonomous Air-Ground Vehicle Operations Optimization in Hazardous Environments: A Multi-Armed Bandit Approach](https://arxiv.org/abs/2508.08217)
*Jimin Choi,Max Z. Li*

Main category: eess.SY

TL;DR: 本文提出了一种用于危险环境中自主车辆调度的决策框架，结合贝叶斯上限置信区间（BUCB）感知策略和任务特定的车辆路径问题（VRPP），以优化无人机（UAV）和无人地面车辆（UGV）的协调工作。


<details>
  <summary>Details</summary>
Motivation: 危险环境（如化学泄漏、放射性区域等）对人类安全构成威胁，需要自主系统快速响应。传统方法难以应对不确定和动态变化的风险。

Method: 系统集成BUCB感知策略与VRPP，通过贝叶斯更新维护风险信念，优化UAV和UGV的路径以平衡探索与利用。

Result: 仿真结果显示，该框架平均减少30%的调度周期，显著提升危险缓解效率。

Conclusion: 不确定性感知的车辆调度框架在危险环境中表现优越，为自主系统提供了可靠的风险缓解方案。

Abstract: Hazardous environments such as chemical spills, radiological zones, and
bio-contaminated sites pose significant threats to human safety and public
infrastructure. Rapid and reliable hazard mitigation in these settings often
unsafe for humans, calling for autonomous systems that can adaptively sense and
respond to evolving risks. This paper presents a decision-making framework for
autonomous vehicle dispatch in hazardous environments with uncertain and
evolving risk levels. The system integrates a Bayesian Upper Confidence Bound
(BUCB) sensing strategy with task-specific vehicle routing problems with
profits (VRPP), enabling adaptive coordination of unmanned aerial vehicles
(UAVs) for hazard sensing and unmanned ground vehicles (UGVs) for cleaning.
Using VRPP allows selective site visits under resource constraints by assigning
each site a visit value that reflects sensing or cleaning priorities.
Site-level hazard beliefs are maintained through a time-weighted Bayesian
update. BUCB scores guide UAV routing to balance exploration and exploitation
under uncertainty, while UGV routes are optimized to maximize expected hazard
reduction under resource constraints. Simulation results demonstrate that our
framework reduces the number of dispatch cycles to resolve hazards by around
30% on average compared to baseline dispatch strategies, underscoring the value
of uncertainty-aware vehicle dispatch for reliable hazard mitigation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [401] [Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems](https://arxiv.org/abs/2508.06539)
*Atahan Karagoz*

Main category: cs.LG

TL;DR: 论文提出了一种新的生存模型理论，将生存视为生物状态空间中的几何特性，而非依赖外部标注的监督学习任务。


<details>
  <summary>Details</summary>
Motivation: 传统生存模型依赖标注数据和固定协变量，而本文认为生存是生物状态空间中的几何特性，试图从几何和物理角度重新定义生存。

Method: 提出了自组织生存流形（SOSM）理论，基于低曲率测地流和生物约束构建生存能量泛函，推导离散和连续目标函数。

Result: 证明了在生物合理条件下，生存对齐轨迹的出现和收敛，并将生存与几何流稳定性联系起来。

Conclusion: 该理论为生存建模提供了无标注的通用框架，将健康、疾病、衰老和死亡视为流形结构的几何相变。

Abstract: Survival is traditionally modeled as a supervised learning task, reliant on
curated outcome labels and fixed covariates. This work rejects that premise. It
proposes that survival is not an externally annotated target but a geometric
consequence: an emergent property of the curvature and flow inherent in
biological state space. We develop a theory of Self-Organizing Survival
Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature
geodesic flows on latent manifolds shaped by internal biological constraints. A
survival energy functional based on geodesic curvature minimization is
introduced and shown to induce structures where prognosis aligns with geometric
flow stability. We derive discrete and continuous formulations of the objective
and prove theoretical results demonstrating the emergence and convergence of
survival-aligned trajectories under biologically plausible conditions. The
framework draws connections to thermodynamic efficiency, entropy flow, Ricci
curvature, and optimal transport, grounding survival modeling in physical law.
Health, disease, aging, and death are reframed as geometric phase transitions
in the manifold's structure. This theory offers a universal, label-free
foundation for modeling survival as a property of form, not annotation-bridging
machine learning, biophysics, and the geometry of life itself.

</details>


### [402] [Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering](https://arxiv.org/abs/2508.06574)
*Fatemeh Moradi,Mehran Tarif,Mohammadhossein Homaei*

Main category: cs.LG

TL;DR: 提出了一种结合无监督预过滤和半监督优化的两阶段学习框架，用于供应链欺诈检测，效果显著。


<details>
  <summary>Details</summary>
Motivation: 全球供应链复杂性和标记数据稀缺性导致传统欺诈检测方法效果不佳。

Method: 第一阶段使用Isolation Forest进行无监督异常检测，第二阶段通过自训练SVM结合标记和高置信度伪标记样本进行半监督优化。

Result: 在DataCo数据集上取得F1分数0.817，假阳性率低于3.0%。

Conclusion: 该方法在真实场景下有效，但需进一步解决概念漂移问题并与深度学习方法对比。

Abstract: Detecting fraud in modern supply chains is a growing challenge, driven by the
complexity of global networks and the scarcity of labeled data. Traditional
detection methods often struggle with class imbalance and limited supervision,
reducing their effectiveness in real-world applications. This paper proposes a
novel two-phase learning framework to address these challenges. In the first
phase, the Isolation Forest algorithm performs unsupervised anomaly detection
to identify potential fraud cases and reduce the volume of data requiring
further analysis. In the second phase, a self-training Support Vector Machine
(SVM) refines the predictions using both labeled and high-confidence
pseudo-labeled samples, enabling robust semi-supervised learning. The proposed
method is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive
real-world supply chain dataset with fraud indicators. It achieves an F1-score
of 0.817 while maintaining a false positive rate below 3.0%. These results
demonstrate the effectiveness and efficiency of combining unsupervised
pre-filtering with semi-supervised refinement for supply chain fraud detection
under real-world constraints, though we acknowledge limitations regarding
concept drift and the need for comparison with deep learning approaches.

</details>


### [403] [GFlowNets for Learning Better Drug-Drug Interaction Representations](https://arxiv.org/abs/2508.06576)
*Azmine Toushik Wasi*

Main category: cs.LG

TL;DR: 提出了一种结合生成流网络（GFlowNet）和变分图自编码器（VGAE）的框架，用于生成罕见药物相互作用的合成样本，以解决数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 药物相互作用（DDI）预测中严重的数据不平衡问题导致模型对罕见相互作用的预测性能较差。现有方法多为二分类问题，忽略了类别特异性。

Method: 结合GFlowNet和VGAE生成罕见类别的合成样本，改善数据平衡，并生成有效的DDI对。

Result: 该方法提高了各类药物相互作用的预测性能，增强了临床可靠性。

Conclusion: 提出的框架有效解决了DDI预测中的数据不平衡问题，提升了模型对罕见相互作用的预测能力。

Abstract: Drug-drug interactions pose a significant challenge in clinical pharmacology,
with severe class imbalance among interaction types limiting the effectiveness
of predictive models. Common interactions dominate datasets, while rare but
critical interactions remain underrepresented, leading to poor model
performance on infrequent cases. Existing methods often treat DDI prediction as
a binary problem, ignoring class-specific nuances and exacerbating bias toward
frequent interactions. To address this, we propose a framework combining
Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE)
to generate synthetic samples for rare classes, improving model balance and
generate effective and novel DDI pairs. Our approach enhances predictive
performance across interaction types, ensuring better clinical reliability.

</details>


### [404] [Hypergraph Neural Network with State Space Models for Node Classification](https://arxiv.org/abs/2508.06587)
*A. Quadir,M. Tanveer*

Main category: cs.LG

TL;DR: 提出了一种新型超图神经网络HGMN，结合角色感知表示和状态空间模型，显著提升了节点分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统GNN主要关注节点间的邻接关系，忽略了角色特征的重要性，现有方法多为无监督且性能不足。

Method: HGMN通过超图构建技术建模高阶关系，结合角色和邻接表示，使用可学习的Mamba Transformer机制，并引入残差网络避免过平滑。

Result: 在多个数据集上验证了HGMN的优越性，节点分类任务性能显著优于现有GNN方法。

Conclusion: HGMN通过有效融合角色特征和邻接信息，提供更丰富的节点表示，适用于多种图学习任务。

Abstract: In recent years, graph neural networks (GNNs) have gained significant
attention for node classification tasks on graph-structured data. However,
traditional GNNs primarily focus on adjacency relationships between nodes,
often overlooking the rich role-based characteristics that are crucial for
learning more expressive node representations. Existing methods for capturing
role-based features are largely unsupervised and fail to achieve optimal
performance in downstream tasks. To address these limitations, we propose a
novel hypergraph neural network with state space model (HGMN) that effectively
integrates role-aware representations into GNNs and the state space model. HGMN
utilizes hypergraph construction techniques to model higher-order relationships
and combines role-based and adjacency-based representations through a learnable
mamba transformer mechanism. By leveraging two distinct hypergraph construction
methods-based on node degree and neighborhood levels, it strengthens the
connections among nodes with similar roles, enhancing the model's
representational power. Additionally, the inclusion of hypergraph convolution
layers enables the model to capture complex dependencies within hypergraph
structures. To mitigate the over-smoothing problem inherent in deep GNNs, we
incorporate a residual network, ensuring improved stability and better feature
propagation across layers. Extensive experiments conducted on one newly
introduced dataset and four benchmark datasets demonstrate the superiority of
HGMN. The model achieves significant performance improvements on node
classification tasks compared to state-of-the-art GNN methods. These results
highlight HGMN's ability to provide enriched node representations by
effectively embedding role-based features alongside adjacency information,
making it a versatile and powerful tool for a variety of graph-based learning
applications.

</details>


### [405] [Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning](https://arxiv.org/abs/2508.06588)
*Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.LG

TL;DR: 论文研究了图数据中向量量化（VQ）的代码本崩溃问题，提出了RGVQ框架以增强代码本利用率和令牌多样性。


<details>
  <summary>Details</summary>
Motivation: 图数据中VQ的代码本崩溃问题限制了图令牌的表达能力和泛化性，现有缓解策略效果不佳。

Method: 提出RGVQ框架，结合图拓扑和特征相似性作为正则化信号，引入软分配和结构感知对比正则化。

Result: RGVQ显著提高了代码本利用率，并在多个下游任务中提升了图VQ骨干模型的性能。

Conclusion: RGVQ解决了图VQ的代码本崩溃问题，生成了更具表达力和可迁移性的图令牌表示。

Abstract: Vector Quantization (VQ) has recently emerged as a promising approach for
learning discrete representations of graph-structured data. However, a
fundamental challenge, i.e., codebook collapse, remains underexplored in the
graph domain, significantly limiting the expressiveness and generalization of
graph tokens.In this paper, we present the first empirical study showing that
codebook collapse consistently occurs when applying VQ to graph data, even with
mitigation strategies proposed in vision or language domains. To understand why
graph VQ is particularly vulnerable to collapse, we provide a theoretical
analysis and identify two key factors: early assignment imbalances caused by
redundancy in graph features and structural patterns, and self-reinforcing
optimization loops in deterministic VQ. To address these issues, we propose
RGVQ, a novel framework that integrates graph topology and feature similarity
as explicit regularization signals to enhance codebook utilization and promote
token diversity. RGVQ introduces soft assignments via Gumbel-Softmax
reparameterization, ensuring that all codewords receive gradient updates. In
addition, RGVQ incorporates a structure-aware contrastive regularization to
penalize the token co-assignments among similar node pairs. Extensive
experiments demonstrate that RGVQ substantially improves codebook utilization
and consistently boosts the performance of state-of-the-art graph VQ backbones
across multiple downstream tasks, enabling more expressive and transferable
graph token representations.

</details>


### [406] [A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis](https://arxiv.org/abs/2508.06589)
*Xinglin Zhao,Yanwen Wang,Xiaobo Liu,Yanrong Hao,Rui Cao,Xin Wen*

Main category: cs.LG

TL;DR: 提出了一种针对神经影像CAD系统的联邦学习框架，通过动态导航和元整合模块处理数据异质性和亚型混淆问题，显著提高了诊断准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决小样本研究可重复性低和大规模数据集中亚型异质性导致的问题。

Method: 采用动态导航模块将样本路由到最适合的本地模型，并通过元整合模块将异构本地模型的预测结果统一为诊断输出。

Result: 在包含1300多名MDD患者和1100名健康对照的fMRI数据上测试，平均准确率达74.06%，显著优于传统方法。

Conclusion: 该框架通过处理数据异质性和亚型混淆，提升了神经影像CAD系统的可靠性和可重复性，对个性化医疗和临床决策具有重要潜力。

Abstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing
neuroimaging data for neurological and psychiatric disorders. However,
small-sample studies suffer from low reproducibility, while large-scale
datasets introduce confounding heterogeneity due to multiple disease subtypes
being labeled under a single category. To address these challenges, we propose
a novel federated learning framework tailored for neuroimaging CAD systems. Our
approach includes a dynamic navigation module that routes samples to the most
suitable local models based on latent subtype representations, and a
meta-integration module that combines predictions from heterogeneous local
models into a unified diagnostic output. We evaluated our framework using a
comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100
healthy controls across multiple study cohorts. Experimental results
demonstrate significant improvements in diagnostic accuracy and robustness
compared to traditional methods. Specifically, our framework achieved an
average accuracy of 74.06\% across all tested sites, showcasing its
effectiveness in handling subtype heterogeneity and enhancing model
generalizability. Ablation studies further confirmed the importance of both the
dynamic navigation and meta-integration modules in improving performance. By
addressing data heterogeneity and subtype confounding, our framework advances
reliable and reproducible neuroimaging CAD systems, offering significant
potential for personalized medicine and clinical decision-making in neurology
and psychiatry.

</details>


### [407] [Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](https://arxiv.org/abs/2508.06591)
*Rachel K. Luu,Jingyu Deng,Mohammed Shahrudin Ibrahim,Nam-Joon Cho,Ming Dao,Subra Suresh,Markus J. Buehler*

Main category: cs.LG

TL;DR: 论文提出了一种结合生成式AI与多学科文献的框架，用于设计新型生物启发材料，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在知识检索和创意生成方面有广泛应用，但在跨学科实验科学（如材料科学）中的应用仍有限。

Method: 结合BioinspiredLLM、RAG、代理系统和分层采样策略，从植物科学、仿生学和材料工程中提取结构-性能关系，并生成实验假设。

Result: 通过实验验证，成功制造了一种新型花粉基粘合剂，具有可调形态和实测剪切强度。

Conclusion: AI辅助创意生成可推动实际材料设计，并实现有效的人机协作。

Abstract: Large language models (LLMs) have reshaped the research landscape by enabling
new approaches to knowledge retrieval and creative ideation. Yet their
application in discipline-specific experimental science, particularly in highly
multi-disciplinary domains like materials science, remains limited. We present
a first-of-its-kind framework that integrates generative AI with literature
from hitherto-unconnected fields such as plant science, biomimetics, and
materials engineering to extract insights and design experiments for materials.
We focus on humidity-responsive systems such as pollen-based materials and
Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and
adaptive performance. Using a suite of AI tools, including a fine-tuned model
(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a
Hierarchical Sampling strategy, we extract structure-property relationships and
translate them into new classes of bioinspired materials. Structured inference
protocols generate and evaluate hundreds of hypotheses from a single query,
surfacing novel and experimentally tractable ideas. We validate our approach
through real-world implementation: LLM-generated procedures, materials designs,
and mechanical predictions were tested in the laboratory, culminating in the
fabrication of a novel pollen-based adhesive with tunable morphology and
measured shear strength, establishing a foundation for future plant-derived
adhesive design. This work demonstrates how AI-assisted ideation can drive
real-world materials design and enable effective human-AI collaboration.

</details>


### [408] [Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)
*Kyle O'Brien,Stephen Casper,Quentin Anthony,Tomek Korbak,Robert Kirk,Xander Davies,Ishan Mishra,Geoffrey Irving,Yarin Gal,Stella Biderman*

Main category: cs.LG

TL;DR: 研究探讨通过过滤训练数据中的双用途主题文本，防止开放权重AI模型被篡改攻击，并提出一种多阶段数据过滤方法。


<details>
  <summary>Details</summary>
Motivation: 开放权重AI系统易受篡改攻击，现有安全微调方法效果有限，需要更可靠的防护手段。

Method: 提出多阶段数据过滤流程，预训练多个6.9B参数模型，测试其对生物威胁相关文本的抵抗能力。

Result: 过滤模型在对抗性微调攻击中表现优异，但对上下文提供的危险信息仍敏感。

Conclusion: 预训练数据过滤是开放权重AI系统的有效防护层，但需结合深度防御策略。

Abstract: Open-weight AI systems offer unique benefits, including enhanced
transparency, open research, and decentralized access. However, they are
vulnerable to tampering attacks which can efficiently elicit harmful behaviors
by modifying weights or activations. Currently, there is not yet a robust
science of open-weight model risk management. Existing safety fine-tuning
methods and other post-training techniques have struggled to make LLMs
resistant to more than a few dozen steps of adversarial fine-tuning. In this
paper, we investigate whether filtering text about dual-use topics from
training data can prevent unwanted capabilities and serve as a more
tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable
data filtering and show that it offers a tractable and effective method for
minimizing biothreat proxy knowledge in LLMs. We pretrain multiple
6.9B-parameter models from scratch and find that they exhibit substantial
resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M
tokens of biothreat-related text -- outperforming existing post-training
baselines by over an order of magnitude -- with no observed degradation to
unrelated capabilities. However, while filtered models lack internalized
dangerous knowledge, we find that they can still leverage such information when
it is provided in context (e.g., via search tool augmentation), demonstrating a
need for a defense-in-depth approach. Overall, these findings help to establish
pretraining data curation as a promising layer of defense for open-weight AI
systems.

</details>


### [409] [Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles](https://arxiv.org/abs/2508.08080)
*Cas Oude Hoekstra,Floris den Hengst*

Main category: cs.LG

TL;DR: 本文介绍了符号分位数回归（SQR），一种基于符号回归（SR）的方法，用于预测条件分位数，并在透明性和性能上取得平衡。


<details>
  <summary>Details</summary>
Motivation: 当前符号回归主要用于预测结果的平均值，但在其他分布点（如中位数或极值）的变量关系估计上缺乏研究，而这些估计在高风险应用中至关重要。

Method: 提出符号分位数回归（SQR），通过符号回归预测条件分位数，并在广泛评估中验证其性能。

Result: SQR在透明模型中表现优异，与黑盒基线模型性能相当，同时保持透明性。通过航空燃油使用案例展示了SQR在解释目标分布差异中的应用。

Conclusion: SQR适用于预测条件分位数，并能理解不同分位数下特征的影响，为高风险应用提供了透明且有效的工具。

Abstract: Symbolic Regression (SR) is a well-established framework for generating
interpretable or white-box predictive models. Although SR has been successfully
applied to create interpretable estimates of the average of the outcome, it is
currently not well understood how it can be used to estimate the relationship
between variables at other points in the distribution of the target variable.
Such estimates of e.g. the median or an extreme value provide a fuller picture
of how predictive variables affect the outcome and are necessary in
high-stakes, safety-critical application domains. This study introduces
Symbolic Quantile Regression (SQR), an approach to predict conditional
quantiles with SR. In an extensive evaluation, we find that SQR outperforms
transparent models and performs comparably to a strong black-box baseline
without compromising transparency. We also show how SQR can be used to explain
differences in the target distribution by comparing models that predict extreme
and central outcomes in an airline fuel usage case study. We conclude that SQR
is suitable for predicting conditional quantiles and understanding interesting
feature influences at varying quantiles.

</details>


### [410] [PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems](https://arxiv.org/abs/2508.06767)
*Arman Dogru,R. Irem Bor-Yaliniz,Nimal Gamini Senarath*

Main category: cs.LG

TL;DR: PANAMA是一种基于多智能体强化学习（MARL）的新型算法，通过优先不对称性和网络感知优化多智能体路径规划（MAPF），在数字孪生（DT）生态系统中提升数据共享效率和任务执行性能。


<details>
  <summary>Details</summary>
Motivation: 随着数字孪生（DT）和自动化系统的普及，高效的数据共享框架和鲁棒算法变得至关重要。研究旨在解决DT生态系统中应用与网络提供商（AP/NP）之间的动态数据交互问题。

Method: 提出PANAMA算法，采用集中训练与分散执行（CTDE）框架和异步执行者-学习者架构，优化多智能体路径规划（MAPF），并通过模拟验证其性能。

Result: PANAMA在路径规划的准确性、速度和可扩展性上优于现有基准，同时优化了数据共享策略，提升了复杂环境中的系统鲁棒性。

Conclusion: PANAMA填补了网络感知决策与多智能体协同之间的空白，推动了数字孪生、无线网络和AI自动化之间的协同发展。

Abstract: Digital Twins (DTs) are transforming industries through advanced data
processing and analysis, positioning the world of DTs, Digital World, as a
cornerstone of nextgeneration technologies including embodied AI. As robotics
and automated systems scale, efficient data-sharing frameworks and robust
algorithms become critical. We explore the pivotal role of data handling in
next-gen networks, focusing on dynamics between application and network
providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with
Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)
based multi-agent path finding (MAPF). By adopting a Centralized Training with
Decentralized Execution (CTDE) framework and asynchronous actor-learner
architectures, PANAMA accelerates training while enabling autonomous task
execution by embodied AI. Our approach demonstrates superior pathfinding
performance in accuracy, speed, and scalability compared to existing
benchmarks. Through simulations, we highlight optimized data-sharing strategies
for scalable, automated systems, ensuring resilience in complex, real-world
environments. PANAMA bridges the gap between network-aware decision-making and
robust multi-agent coordination, advancing the synergy between DTs, wireless
networks, and AI-driven automation.

</details>


### [411] [Local Diffusion Models and Phases of Data Distributions](https://arxiv.org/abs/2508.06614)
*Fangjun Hu,Guangkuo Liu,Yifan Zhang,Xun Gao*

Main category: cs.LG

TL;DR: 扩散模型通过局部去噪器降低计算成本，提出数据分布相变理论，并证明在相变点附近需全局神经网络。


<details>
  <summary>Details</summary>
Motivation: 现实数据（如图像）具有低维空间结构，但传统扩散模型忽略局部结构，计算成本高。

Method: 定义数据分布相，提出局部去噪器，通过信息论边界诊断相变点。

Result: 实验证明局部去噪器在非相变区有效，相变点附近需全局网络。

Conclusion: 简化扩散模型架构，为生成AI和神经网络设计提供新方向。

Abstract: As a class of generative artificial intelligence frameworks inspired by
statistical physics, diffusion models have shown extraordinary performance in
synthesizing complicated data distributions through a denoising process
gradually guided by score functions. Real-life data, like images, is often
spatially structured in low-dimensional spaces. However, ordinary diffusion
models ignore this local structure and learn spatially global score functions,
which are often computationally expensive. In this work, we introduce a new
perspective on the phases of data distributions, which provides insight into
constructing local denoisers with reduced computational costs. We define two
distributions as belonging to the same data distribution phase if they can be
mutually connected via spatially local operations such as local denoisers.
Then, we show that the reverse denoising process consists of an early trivial
phase and a late data phase, sandwiching a rapid phase transition where local
denoisers must fail. To diagnose such phase transitions, we prove an
information-theoretic bound on the fidelity of local denoisers based on
conditional mutual information, and conduct numerical experiments in a
real-world dataset. This work suggests simpler and more efficient architectures
of diffusion models: far from the phase transition point, we can use small
local neural networks to compute the score function; global neural networks are
only necessary around the narrow time interval of phase transitions. This
result also opens up new directions for studying phases of data distributions,
the broader science of generative artificial intelligence, and guiding the
design of neural networks inspired by physics concepts.

</details>


### [412] [Conformal Set-based Human-AI Complementarity with Multiple Experts](https://arxiv.org/abs/2508.06997)
*Helbert Paat,Guohao Shen*

Main category: cs.LG

TL;DR: 论文提出了一种基于预训练模型和人类专家协作的分类方法，通过贪婪算法选择实例相关的专家子集，提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 研究多专家场景下如何利用预测集选择相关专家，以优化分类任务，弥补单专家研究的不足。

Method: 提出贪婪算法，利用预测集动态选择专家子集，对比传统方法。

Result: 在CIFAR-10H和ImageNet-16H数据集上，贪婪算法表现优于基线方法，接近最优子集。

Conclusion: 多专家协作结合动态选择策略能显著提升分类性能，为决策支持系统提供新思路。

Abstract: Decision support systems are designed to assist human experts in
classification tasks by providing conformal prediction sets derived from a
pre-trained model. This human-AI collaboration has demonstrated enhanced
classification performance compared to using either the model or the expert
independently. In this study, we focus on the selection of instance-specific
experts from a pool of multiple human experts, contrasting it with existing
research that typically focuses on single-expert scenarios. We characterize the
conditions under which multiple experts can benefit from the conformal sets.
With the insight that only certain experts may be relevant for each instance,
we explore the problem of subset selection and introduce a greedy algorithm
that utilizes conformal sets to identify the subset of expert predictions that
will be used in classifying an instance. This approach is shown to yield better
performance compared to naive methods for human subset selection. Based on real
expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation
study indicates that our proposed greedy algorithm achieves near-optimal
subsets, resulting in improved classification performance among multiple
experts.

</details>


### [413] [Generalizing Scaling Laws for Dense and Sparse Large Language Models](https://arxiv.org/abs/2508.06617)
*Md Arafat Hossain,Xingfu Wu,Valerie Taylor,Ali Jannesari*

Main category: cs.LG

TL;DR: 本文提出了一种通用的扩展定律，适用于稠密和稀疏大型语言模型，以解决现有扩展定律的架构局限性。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型规模和训练计算成本的快速增长，研究人员需要更高效的训练方法，但现有扩展定律多为架构特定，缺乏通用性。

Method: 重新审视现有扩展定律，提出一种适用于稠密和稀疏模型的通用扩展定律，并通过实验评估其有效性。

Result: 提出的通用扩展定律在实验中表现出色，优于现有架构特定的扩展定律。

Conclusion: 通用扩展定律为大型语言模型的训练提供了更灵活和高效的框架。

Abstract: Over the past few years, the size of language models has grown exponentially,
as has the computational cost to train these large models. This rapid growth
has motivated researchers to develop new techniques aimed at enhancing the
efficiency of the training process. Despite these advancements, optimally
predicting the model size or allocating optimal resources remains a challenge.
Several efforts have addressed the challenge by proposing different scaling
laws, but almost all of them are architecture-specific (dense or sparse). In
this work we revisit existing scaling laws and propose a generalized scaling
law to provide a unified framework that is applicable to both dense and sparse
large language models. We evaluate and compare our proposed scaling law with
existing scaling laws to demonstrate its effectiveness.

</details>


### [414] [LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference](https://arxiv.org/abs/2508.07221)
*Po-Han Lee,Yu-Cheng Lin,Chan-Tung Ku,Chan Hsu,Pei-Cing Huang,Ping-Hsun Wu,Yihuang Kang*

Main category: cs.LG

TL;DR: 论文提出了一种基于大型语言模型（LLM）的代理方法，用于自动发现混杂变量和进行亚组分析，以提升因果机器学习的鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 观测数据中的个体化治疗效果估计因未测量的混杂和结构偏差而具有挑战性，传统因果机器学习方法在复杂环境中效果有限，且依赖领域专家导致高成本。

Method: 提出LLM-based代理框架，自动化混杂变量发现和亚组分析，模拟领域专业知识，减少人工依赖。

Result: 在真实医疗数据集上的实验表明，该方法通过缩小置信区间和发现未识别的混杂偏差，增强了治疗效果估计的鲁棒性。

Conclusion: LLM-based代理为可扩展、可信赖且语义感知的因果推断提供了有前景的路径。

Abstract: Estimating individualized treatment effects from observational data presents
a persistent challenge due to unmeasured confounding and structural bias.
Causal Machine Learning (causal ML) methods, such as causal trees and doubly
robust estimators, provide tools for estimating conditional average treatment
effects. These methods have limited effectiveness in complex real-world
environments due to the presence of latent confounders or those described in
unstructured formats. Moreover, reliance on domain experts for confounder
identification and rule interpretation introduces high annotation cost and
scalability concerns. In this work, we proposed Large Language Model-based
agents for automated confounder discovery and subgroup analysis that integrate
agents into the causal ML pipeline to simulate domain expertise. Our framework
systematically performs subgroup identification and confounding structure
discovery by leveraging the reasoning capabilities of LLM-based agents, which
reduces human dependency while preserving interpretability. Experiments on
real-world medical datasets show that our proposed approach enhances treatment
effect estimation robustness by narrowing confidence intervals and uncovering
unrecognized confounding biases. Our findings suggest that LLM-based agents
offer a promising path toward scalable, trustworthy, and semantically aware
causal inference.

</details>


### [415] [Strategic Incentivization for Locally Differentially Private Federated Learning](https://arxiv.org/abs/2508.07138)
*Yashwant Krishna Pagoti,Arunesh Sinha,Shamik Sural*

Main category: cs.LG

TL;DR: 论文研究了联邦学习中的隐私与准确性的权衡问题，提出了一种基于令牌的激励机制，通过游戏理论分析优化噪声添加策略。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中因添加噪声保护隐私而导致的全局模型准确性下降问题。

Method: 引入基于令牌的激励机制，将隐私-准确性权衡建模为游戏，分析玩家行为和收益。

Result: 实验验证了不同参数对模型性能的影响，激励机制有效平衡了隐私与准确性。

Conclusion: 提出的游戏理论框架和激励机制为联邦学习中的隐私保护与模型性能优化提供了新思路。

Abstract: In Federated Learning (FL), multiple clients jointly train a machine learning
model by sharing gradient information, instead of raw data, with a server over
multiple rounds. To address the possibility of information leakage in spite of
sharing only the gradients, Local Differential Privacy (LDP) is often used. In
LDP, clients add a selective amount of noise to the gradients before sending
the same to the server. Although such noise addition protects the privacy of
clients, it leads to a degradation in global model accuracy. In this paper, we
model this privacy-accuracy trade-off as a game, where the sever incentivizes
the clients to add a lower degree of noise for achieving higher accuracy, while
the clients attempt to preserve their privacy at the cost of a potential loss
in accuracy. A token based incentivization mechanism is introduced in which the
quantum of tokens credited to a client in an FL round is a function of the
degree of perturbation of its gradients. The client can later access a newly
updated global model only after acquiring enough tokens, which are to be
deducted from its balance. We identify the players, their actions and payoff,
and perform a strategic analysis of the game. Extensive experiments were
carried out to study the impact of different parameters.

</details>


### [416] [Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels](https://arxiv.org/abs/2508.06622)
*Jeremiah Birrell,Reza Ebrahimi*

Main category: cs.LG

TL;DR: ANTIDOTE是一种针对噪声标签学习的新目标函数，通过信息差异邻域的松弛定义，采用对抗训练方法，计算成本接近标准交叉熵损失。


<details>
  <summary>Details</summary>
Motivation: 解决训练数据中固有噪声标签或对抗性标签修改的问题。

Method: 利用凸对偶性将目标函数重新表述为对抗训练方法，自适应减少噪声标签样本的影响。

Result: 在多种噪声环境下表现优异，计算复杂度接近标准交叉熵损失。

Conclusion: ANTIDOTE在噪声标签学习中具有高效性和适应性。

Abstract: We introduce ANTIDOTE, a new class of objectives for learning under noisy
labels which are defined in terms of a relaxation over an
information-divergence neighborhood. Using convex duality, we provide a
reformulation as an adversarial training method that has similar computational
cost to training with standard cross-entropy loss. We show that our approach
adaptively reduces the influence of the samples with noisy labels during
learning, exhibiting a behavior that is analogous to forgetting those samples.
ANTIDOTE is effective in practical environments where label noise is inherent
in the training data or where an adversary can alter the training labels.
Extensive empirical evaluations on different levels of symmetric, asymmetric,
human annotation, and real-world label noise show that ANTIDOTE outperforms
leading comparable losses in the field and enjoys a time complexity that is
very close to that of the standard cross entropy loss.

</details>


### [417] [Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks](https://arxiv.org/abs/2508.07676)
*Chenchen Lin,Xuehe Wang*

Main category: cs.LG

TL;DR: 提出了一种社交感知的联邦学习隐私保护机制，通过多跳传播模型量化间接隐私泄露，并采用Stackelberg博弈优化激励策略。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中社交网络引入隐私外部性，客户隐私损失受他人隐私决策影响，需系统性解决。

Method: 设计两阶段Stackelberg博弈，服务器优化激励策略，客户选择隐私预算；引入均值场估计器近似外部隐私风险。

Result: 理论证明均值场估计器收敛性及Stackelberg纳什均衡存在性，实验显示客户效用提升、服务器成本降低。

Conclusion: 机制在保持模型性能的同时，显著优于社交无关基线及考虑社交外部性的方法。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients without sharing local data, thereby enhancing privacy and
facilitating collaboration among clients connected via social networks.
However, these social connections introduce privacy externalities: a client's
privacy loss depends not only on its privacy protection strategy but also on
the privacy decisions of others, propagated through the network via multi-hop
interactions. In this work, we propose a socially-aware privacy-preserving FL
mechanism that systematically quantifies indirect privacy leakage through a
multi-hop propagation model. We formulate the server-client interaction as a
two-stage Stackelberg game, where the server, as the leader, optimizes
incentive policies, and clients, as followers, strategically select their
privacy budgets, which determine their privacy-preserving levels by controlling
the magnitude of added noise. To mitigate information asymmetry in networked
privacy estimation, we introduce a mean-field estimator to approximate the
average external privacy risk. We theoretically prove the existence and
convergence of the fixed point of the mean-field estimator and derive
closed-form expressions for the Stackelberg Nash Equilibrium. Despite being
designed from a client-centric incentive perspective, our mechanism achieves
approximately-optimal social welfare, as revealed by Price of Anarchy (PoA)
analysis. Experiments on diverse datasets demonstrate that our approach
significantly improves client utilities and reduces server costs while
maintaining model performance, outperforming both Social-Agnostic (SA)
baselines and methods that account for social externalities.

</details>


### [418] [Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record](https://arxiv.org/abs/2508.06627)
*Mosbah Aouad,Anirudh Choudhary,Awais Farooq,Steven Nevers,Lusine Demirkhanyan,Bhrandon Harris,Suguna Pappu,Christopher Gondi,Ravishankar Iyer*

Main category: cs.LG

TL;DR: 提出一种多模态方法，结合电子健康记录中的诊断代码和实验室数据，提前一年检测胰腺导管腺癌（PDAC），性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PDAC早期检测困难，缺乏特异性症状和可靠生物标志物。

Method: 结合神经控制微分方程、预训练语言模型、循环网络和交叉注意力机制，整合诊断代码和实验室数据。

Result: 在4700名患者数据集上，AUC提升6.5%至15.5%，并识别出新的高风险生物标志物。

Conclusion: 该方法显著提升PDAC早期检测能力，并发现新的潜在生物标志物。

Abstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and
early detection remains a major clinical challenge due to the absence of
specific symptoms and reliable biomarkers. In this work, we propose a new
multimodal approach that integrates longitudinal diagnosis code histories and
routinely collected laboratory measurements from electronic health records to
detect PDAC up to one year prior to clinical diagnosis. Our method combines
neural controlled differential equations to model irregular lab time series,
pretrained language models and recurrent networks to learn diagnosis code
trajectory representations, and cross-attention mechanisms to capture
interactions between the two modalities. We develop and evaluate our approach
on a real-world dataset of nearly 4,700 patients and achieve significant
improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods.
Furthermore, our model identifies diagnosis codes and laboratory panels
associated with elevated PDAC risk, including both established and new
biomarkers. Our code is available at
https://github.com/MosbahAouad/EarlyPDAC-MML.

</details>


### [419] [Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations](https://arxiv.org/abs/2508.07722)
*Pietro Talli,Federico Mason,Federico Chiariotti,Andrea Zanella*

Main category: cs.LG

TL;DR: 提出了一种名为HR3L的新架构，用于在非理想无线通信网络上训练远程强化学习（RL）代理，解决了传统方法在延迟和丢包环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RL代理需要即时感知环境状态变化，但在无线通信网络中，由于丢包和延迟，代理只能获得部分和间歇性信息，现有解决方案计算负担重且不够通用。

Method: HR3L架构包含发射器和接收器两个单元，发射器编码环境状态，接收器解码并执行动作以最大化奖励信号，无需交换梯度信息。

Result: 实验表明，HR3L在样本效率和适应不同通信场景（如丢包、延迟和带宽限制）方面显著优于基线方法。

Conclusion: HR3L提供了一种高效且适应性强的解决方案，适用于非理想通信网络中的RL训练。

Abstract: In this work, we address the problem of training Reinforcement Learning (RL)
agents over communication networks. The RL paradigm requires the agent to
instantaneously perceive the state evolution to infer the effects of its
actions on the environment. This is impossible if the agent receives state
updates over lossy or delayed wireless systems and thus operates with partial
and intermittent information. In recent years, numerous frameworks have been
proposed to manage RL with imperfect feedback; however, they often offer
specific solutions with a substantial computational burden. To address these
limits, we propose a novel architecture, named Homomorphic Robust Remote
Reinforcement Learning (HR3L), that enables the training of remote RL agents
exchanging observations across a non-ideal wireless channel. HR3L considers two
units: the transmitter, which encodes meaningful representations of the
environment, and the receiver, which decodes these messages and performs
actions to maximize a reward signal. Importantly, HR3L does not require the
exchange of gradient information across the wireless channel, allowing for
quicker training and a lower communication overhead than state-of-the-art
solutions. Experimental results demonstrate that HR3L significantly outperforms
baseline methods in terms of sample efficiency and adapts to different
communication scenarios, including packet losses, delayed transmissions, and
capacity limitations.

</details>


### [420] [Using Imperfect Synthetic Data in Downstream Inference Tasks](https://arxiv.org/abs/2508.06635)
*Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder*

Main category: cs.LG

TL;DR: 提出一种基于广义矩估计的新方法，用于结合合成数据和真实数据以生成统计有效的结论。


<details>
  <summary>Details</summary>
Motivation: 探索如何将大语言模型生成的合成数据与真实数据结合，以支持有限数据条件下的社会科学研究。

Method: 引入基于广义矩估计的新估计器，无需超参数调整，具有理论保证。

Result: 发现合成数据与真实数据的矩残差交互可改善目标参数估计，实证验证了方法的有效性。

Conclusion: 新方法在计算社会科学应用中表现出显著的实证优势。

Abstract: Predictions and generations from large language models are increasingly being
explored as an aid to computational social science and human subject research
in limited data regimes. While previous technical work has explored the
potential to use model-predicted labels for unlabeled data in a principled
manner, there is increasing interest in using large language models to generate
entirely new synthetic samples (also termed as synthetic simulations), such as
in responses to surveys. However, it is not immediately clear by what means
practitioners can combine such data with real data and yet produce
statistically valid conclusions upon them. In this work, we introduce a new
estimator based on generalized method of moments, providing a
hyperparameter-free solution with strong theoretical guarantees to address the
challenge at hand. Surprisingly, we find that interactions between the moment
residuals of synthetic data and those of real data can improve estimates of the
target parameter. We empirically validate the finite-sample performance of our
estimator across different regression tasks in computational social science
applications, demonstrating large empirical gains.

</details>


### [421] [Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series](https://arxiv.org/abs/2508.06638)
*Muyan Anna Li,Aditi Gautam*

Main category: cs.LG

TL;DR: 论文提出了两种自适应阈值框架（SCS和MACS），用于非平稳环境中的时间序列异常检测，显著提升了F1分数。


<details>
  <summary>Details</summary>
Motivation: 传统静态阈值在非平稳环境中容易失效，需要适应统计特性随时间变化的新方法。

Method: 引入了基于统计在线学习和分段原理的SCS和MACS框架，实现局部和上下文敏感的阈值调整。

Result: 在晶圆制造基准数据集上，SCS和MACS相比传统方法显著提高了F1分数。

Conclusion: 统计驱动的自适应阈值能实现可靠、可解释且及时的异常检测。

Abstract: As time series data become increasingly prevalent in domains such as
manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt
to nonstationary environments where statistical properties shift over time.
Traditional static thresholds are easily rendered obsolete by regime shifts,
concept drift, or multi-scale changes. To address these challenges, we
introduce and empirically evaluate two novel adaptive thresholding frameworks:
Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence
Segments (MACS). Both leverage statistical online learning and segmentation
principles for local, contextually sensitive adaptation, maintaining guarantees
on false alarm rates even under evolving distributions. Our experiments across
Wafer Manufacturing benchmark datasets show significant F1-score improvement
compared to traditional percentile and rolling quantile approaches. This work
demonstrates that robust, statistically principled adaptive thresholds enable
reliable, interpretable, and timely detection of diverse real-world anomalies.

</details>


### [422] [Fractal Language Modelling by Universal Sequence Maps (USM)](https://arxiv.org/abs/2508.06641)
*Jonas S Almeida,Daniel E Russ,Susana Vinga,Ines Duarte,Lee Mason,Praphulla Bhawsar,Aaron Ge,Arlindo Oliveira,Jeya Balaji Balasubramanian*

Main category: cs.LG

TL;DR: 本文提出了一种改进的通用序列映射（USM）方法，解决了迭代过程中的种子偏差问题，并揭示了USM作为一种高效数值过程的特性。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer语言模型的兴起，需要一种能够在多尺度和嵌入维度上数值化表示符号序列的编码方法，以保留符号序列的上下文信息。

Method: USM由前向和后向的混沌游戏表示（CGR）组成，可投影到频域（FCGR），用于计算Chebyshev距离和k-mer频率。

Result: 解决了种子偏差问题，实现了数值位置与序列身份的全匹配，并发现USM是一种收敛于稳态序列嵌入的高效数值过程。

Conclusion: USM方法适用于任意基数的字母表，尤其在基因组序列中表现出高效性。

Abstract: Motivation: With the advent of Language Models using Transformers,
popularized by ChatGPT, there is a renewed interest in exploring encoding
procedures that numerically represent symbolic sequences at multiple scales and
embedding dimensions. The challenge that encoding addresses is the need for
mechanisms that uniquely retain contextual information about the succession of
individual symbols, which can then be modeled by nonlinear formulations such as
neural networks.
  Context: Universal Sequence Maps(USM) are iterated functions that bijectively
encode symbolic sequences onto embedded numerical spaces. USM is composed of
two Chaos Game Representations (CGR), iterated forwardly and backwardly, that
can be projected into the frequency domain (FCGR). The corresponding USM
coordinates can be used to compute a Chebyshev distance metric as well as k-mer
frequencies, without having to recompute the embedded numeric coordinates, and,
paradoxically, allowing for non-integers values of k.
  Results: This report advances the bijective fractal encoding by Universal
Sequence Maps (USM) by resolving seeding biases affecting the iterated process.
The resolution had two results, the first expected, the second an intriguing
outcome: 1) full reconciliation of numeric positioning with sequence identity;
and 2) uncovering the nature of USM as an efficient numeric process converging
towards a steady state sequence embedding solution. We illustrate these results
for genomic sequences because of the convenience of a planar representation
defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,
the application to alphabet of arbitrary cardinality was found to be
straightforward.

</details>


### [423] [Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN](https://arxiv.org/abs/2508.06647)
*Andrey Sidorenko,Paul Tiwald*

Main category: cs.LG

TL;DR: TabularARGN是一种用于生成高质量合成表格数据的神经网络架构，具有高数据保真度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统匿名化技术无法充分保护隐私，需要更有效的合成数据生成方法。

Method: 采用基于离散化的自回归方法设计TabularARGN。

Result: TabularARGN在统计相似性、机器学习实用性和检测鲁棒性方面表现优异。

Conclusion: TabularARGN在隐私保护和数据实用性之间实现了有效平衡。

Abstract: Synthetic data generation has become essential for securely sharing and
analyzing sensitive data sets. Traditional anonymization techniques, however,
often fail to adequately preserve privacy. We introduce the Tabular
Auto-Regressive Generative Network (TabularARGN), a neural network architecture
specifically designed for generating high-quality synthetic tabular data. Using
a discretization-based auto-regressive approach, TabularARGN achieves high data
fidelity while remaining computationally efficient. We evaluate TabularARGN
against existing synthetic data generation methods, showing competitive results
in statistical similarity, machine learning utility, and detection robustness.
We further perform an in-depth privacy evaluation using systematic
membership-inference attacks, highlighting the robustness and effective
privacy-utility balance of our approach.

</details>


### [424] [In-Context Reinforcement Learning via Communicative World Models](https://arxiv.org/abs/2508.06659)
*Fernando Martinez-Lopez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: 本文提出CORAL框架，通过将表征学习与控制解耦，提升强化学习代理的上下文适应能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习代理在新任务和环境中泛化能力不足，因其表征和策略过度拟合训练环境。

Method: CORAL将上下文强化学习建模为双代理通信问题，引入信息代理（IA）和控制代理（CA），通过因果影响损失优化通信协议。

Result: 实验表明，CORAL显著提升了样本效率，并在未见过的稀疏奖励环境中实现零样本适应。

Conclusion: 学习可迁移的通信表征能有效提升强化学习代理的适应能力。

Abstract: Reinforcement learning (RL) agents often struggle to generalize to new tasks
and contexts without updating their parameters, mainly because their learned
representations and policies are overfit to the specifics of their training
environments. To boost agents' in-context RL (ICRL) ability, this work
formulates ICRL as a two-agent emergent communication problem and introduces
CORAL (Communicative Representation for Adaptive RL), a framework that learns a
transferable communicative context by decoupling latent representation learning
from control. In CORAL, an Information Agent (IA) is pre-trained as a world
model on a diverse distribution of tasks. Its objective is not to maximize task
reward, but to build a world model and distill its understanding into concise
messages. The emergent communication protocol is shaped by a novel Causal
Influence Loss, which measures the effect that the message has on the next
action. During deployment, the previously trained IA serves as a fixed
contextualizer for a new Control Agent (CA), which learns to solve tasks by
interpreting the provided communicative context. Our experiments demonstrate
that this approach enables the CA to achieve significant gains in sample
efficiency and successfully perform zero-shot adaptation with the help of
pre-trained IA in entirely unseen sparse-reward environments, validating the
efficacy of learning a transferable communicative representation.

</details>


### [425] [Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.06663)
*Yuan-Hung Chao,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 论文提出将KANs集成到GNN架构中，形成新模型KGAT、KSGC和KAPPNP，并通过多教师知识融合框架提升性能。实验表明新模型提高了节点分类准确性。


<details>
  <summary>Details</summary>
Motivation: GNN依赖图连接性，限制了可扩展性和效率，而KANs具有强非线性表达能力和高效推理能力，因此探索如何结合两者以提升GNN性能。

Method: 将KANs集成到GAT、SGC和APPNP三种GNN架构中，形成新模型，并采用多教师知识融合框架将知识蒸馏到图无关的KAN学生模型中。

Result: 实验证明新模型提高了节点分类准确性，知识融合方法显著提升了学生模型性能。

Conclusion: KANs能增强GNN表达能力，并实现高效的图无关推理。

Abstract: Graph Neural Networks (GNNs) have shown strong performance on
graph-structured data, but their reliance on graph connectivity often limits
scalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent
architecture with learnable univariate functions, offer strong nonlinear
expressiveness and efficient inference. In this work, we integrate KANs into
three popular GNN architectures-GAT, SGC, and APPNP-resulting in three new
models: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge
amalgamation framework, where knowledge from multiple KAN-based GNNs is
distilled into a graph-independent KAN student model. Experiments on benchmark
datasets show that the proposed models improve node classification accuracy,
and the knowledge amalgamation approach significantly boosts student model
performance. Our findings highlight the potential of KANs for enhancing GNN
expressiveness and for enabling efficient, graph-free inference.

</details>


### [426] [Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation](https://arxiv.org/abs/2508.06676)
*Chia-Hsun Lu,Guan-Jhih Wu,Ya-Chi Ho,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 提出了一种针对Kolmogorov-Arnold Networks (KAN)的新型水印方法DCT-AW，利用离散余弦变换在可学习激活函数中嵌入水印，具有任务独立性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习中知识产权保护的重要性增加，现有水印方法难以适应KAN的新型架构，因此需要专门的水印技术。

Method: 提出DCT-AW方法，通过离散余弦变换扰动激活输出，在KAN的可学习激活函数中嵌入水印。

Result: 实验表明，DCT-AW对模型性能影响小，且对微调、剪枝等攻击具有强鲁棒性。

Conclusion: DCT-AW是一种适用于KAN的有效水印方法，兼具任务独立性和抗攻击能力。

Abstract: With the increasing importance of protecting intellectual property in machine
learning, watermarking techniques have gained significant attention. As
advanced models are increasingly deployed in domains such as social network
analysis, the need for robust model protection becomes even more critical.
While existing watermarking methods have demonstrated effectiveness for
conventional deep neural networks, they often fail to adapt to the novel
architecture, Kolmogorov-Arnold Networks (KAN), which feature learnable
activation functions. KAN holds strong potential for modeling complex
relationships in network-structured data. However, their unique design also
introduces new challenges for watermarking. Therefore, we propose a novel
watermarking method, Discrete Cosine Transform-based Activation Watermarking
(DCT-AW), tailored for KAN. Leveraging the learnable activation functions of
KAN, our method embeds watermarks by perturbing activation outputs using
discrete cosine transform, ensuring compatibility with diverse tasks and
achieving task independence. Experimental results demonstrate that DCT-AW has a
small impact on model performance and provides superior robustness against
various watermark removal attacks, including fine-tuning, pruning, and
retraining after pruning.

</details>


### [427] [Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select](https://arxiv.org/abs/2508.06692)
*Md. Akmol Masud,Md Abrar Jahin,Mahmud Hasan*

Main category: cs.LG

TL;DR: HeteRo-Select框架通过智能选择客户端子集，解决了联邦学习中因数据异构性导致的训练不稳定问题，显著提升了准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）因客户端数据多样性常导致训练不稳定，现有方法（如Oort）在后期训练中准确性下降明显。

Method: 提出HeteRo-Select框架，通过评分系统综合考虑客户端有用性、公平性、更新速度和数据多样性，并理论证明其有效性。

Result: 在CIFAR-10数据集上，HeteRo-Select的峰值准确率为74.75%，最终准确率为72.76%，稳定性下降仅1.99%，优于Oort。

Conclusion: HeteRo-Select为异构FL问题提供了理论和实证支持，是一种可靠的解决方案。

Abstract: Federated Learning (FL) is a machine learning technique that often suffers
from training instability due to the diverse nature of client data. Although
utility-based client selection methods like Oort are used to converge by
prioritizing high-loss clients, they frequently experience significant drops in
accuracy during later stages of training. We propose a theoretical
HeteRo-Select framework designed to maintain high performance and ensure
long-term training stability. We provide a theoretical analysis showing that
when client data is very different (high heterogeneity), choosing a smart
subset of client participation can reduce communication more effectively
compared to full participation. Our HeteRo-Select method uses a clear,
step-by-step scoring system that considers client usefulness, fairness, update
speed, and data variety. It also shows convergence guarantees under strong
regularization. Our experimental results on the CIFAR-10 dataset under
significant label skew ($\alpha=0.1$) support the theoretical findings. The
HeteRo-Select method performs better than existing approaches in terms of peak
accuracy, final accuracy, and training stability. Specifically, HeteRo-Select
achieves a peak accuracy of $74.75\%$, a final accuracy of $72.76\%$, and a
minimal stability drop of $1.99\%$. In contrast, Oort records a lower peak
accuracy of $73.98\%$, a final accuracy of $71.25\%$, and a larger stability
drop of $2.73\%$. The theoretical foundations and empirical performance in our
study make HeteRo-Select a reliable solution for real-world heterogeneous FL
problems.

</details>


### [428] [CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations](https://arxiv.org/abs/2508.06704)
*Hager Radi Abdelwahed,Mélisande Teng,Robin Zbinden,Laura Pollock,Hugo Larochelle,Devis Tuia,David Rolnick*

Main category: cs.LG

TL;DR: CISO是一种基于深度学习的物种分布模型方法，能够结合不完整的物种观测数据与环境变量，提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的物种分布模型（SDMs）通常忽略物种间的生物相互作用，且现有方法对数据要求严格，难以处理稀疏和不一致的观测数据。

Method: 提出CISO方法，利用深度学习灵活处理不完整的物种观测数据，并结合环境变量进行预测。

Result: CISO在植物、鸟类和蝴蝶数据集上表现优于其他方法，尤其在结合多数据集时预测性能进一步提升。

Conclusion: CISO是一种有潜力的生态工具，能够整合不完整的生物信息并识别跨类群的潜在物种相互作用。

Abstract: Species distribution models (SDMs) are widely used to predict species'
geographic distributions, serving as critical tools for ecological research and
conservation planning. Typically, SDMs relate species occurrences to
environmental variables representing abiotic factors, such as temperature,
precipitation, and soil properties. However, species distributions are also
strongly influenced by biotic interactions with other species, which are often
overlooked. While some methods partially address this limitation by
incorporating biotic interactions, they often assume symmetrical pairwise
relationships between species and require consistent co-occurrence data. In
practice, species observations are sparse, and the availability of information
about the presence or absence of other species varies significantly across
locations. To address these challenges, we propose CISO, a deep learning-based
method for species distribution modeling Conditioned on Incomplete Species
Observations. CISO enables predictions to be conditioned on a flexible number
of species observations alongside environmental variables, accommodating the
variability and incompleteness of available biotic data. We demonstrate our
approach using three datasets representing different species groups: sPlotOpen
for plants, SatBird for birds, and a new dataset, SatButterfly, for
butterflies. Our results show that including partial biotic information
improves predictive performance on spatially separate test sets. When
conditioned on a subset of species within the same dataset, CISO outperforms
alternative methods in predicting the distribution of the remaining species.
Furthermore, we show that combining observations from multiple datasets can
improve performance. CISO is a promising ecological tool, capable of
incorporating incomplete biotic information and identifying potential
interactions between species from disparate taxa.

</details>


### [429] [Analysis of Schedule-Free Nonconvex Optimization](https://arxiv.org/abs/2508.06743)
*Connor Brown*

Main category: cs.LG

TL;DR: 论文提出了一种鲁棒的Lyapunov框架，用于分析Schedule-Free（SF）方法在非凸优化中的性能，无需依赖全局假设，并证明了多种步长策略下的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 传统一阶方法的收敛保证依赖于预先设定的步长计划，而SF方法通过结合Polyak-Ruppert平均和动量，提供了超参数独立于总迭代次数T的优化性能。然而，非凸分析有限或依赖强假设，需要更通用的分析框架。

Method: 引入Lyapunov框架，仅需L-平滑性和下界性假设，将SF分析简化为单步下降不等式，证明了多种步长策略下的收敛速率。

Result: 在非凸设置下，证明了不同步长策略的收敛速率：常数步长+PR平均为O(1/log T)，线性增长步长为O(log T/T)，多项式平均为O(T^{-(1−α)})。数值实验支持理论结果。

Conclusion: 研究将SF的无视界保证扩展到平滑非凸优化，并为未来非凸最优速率的研究提供了方向。

Abstract: First-order methods underpin most large-scale learning algorithms, yet their
classical convergence guarantees hinge on carefully scheduled step-sizes that
depend on the total horizon $T$, which is rarely known in advance. The
Schedule-Free (SF) method promises optimal performance with hyperparameters
that are independent of $T$ by interpolating between Polyak--Ruppert averaging
and momentum, but nonconvex analysis of SF has been limited or reliant on
strong global assumptions. We introduce a robust Lyapunov framework that, under
only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step
descent inequality. This yields horizon-agnostic bounds in the nonconvex
setting: $O(1/\log T)$ for constant step + PR averaging, $O(\log T/T)$ for a
linearly growing step-size, and a continuum of $O(T^{-(1-\alpha)})$ rates for
polynomial averaging. We complement these proofs with Performance Estimation
Problem (PEP) experiments that numerically validate our rates and suggest that
our $O(1/\log T)$ bound on the original nonconvex SF algorithm may tighten to
$O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex
optimization and charts future directions for optimal nonconvex rates.

</details>


### [430] [Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning](https://arxiv.org/abs/2508.06765)
*Xingke Yang,Liang Li,Sicong Li,Liwei Guan,Hao Wang,Xiaoqi Qi,Jiang Liu,Xin Fu,Miao Pan*

Main category: cs.LG

TL;DR: Fed MobiLLM提出了一种高效异构移动设备上的联邦学习框架，用于轻量化大语言模型微调，显著降低计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习在大语言模型微调中计算、内存负担重及同步协议效率低的问题。

Method: 采用服务器辅助的联邦侧调优范式，设备仅执行轻量前向传播，服务器独立训练共享侧网络，并引入自适应层特征对齐方法。

Result: 实验显示计算开销减少95.2%，通信成本降低93.2%，收敛速度快5.1倍。

Conclusion: Fed MobiLLM在异构移动设备上实现了高效且鲁棒的大语言模型微调。

Abstract: Collaboratively fine-tuning (FT) large language models (LLMs) over
heterogeneous mobile devices fosters immense potential applications of
personalized intelligence. However, such a vision faces critical system
challenges. Conventional federated LLM FT approaches place prohibitive
computational and memory burdens on mobile hardware, and their synchronous
model aggregation protocols stall for slower devices. In this paper, we propose
Fed MobiLLM, a novel design to facilitate efficient federated LLM FT across
mobile devices with diverse computing/communication speeds and local model
architectures. In particular, Fed MobiLLM implements a pioneering
server-assisted federated side-tuning paradigm. Briefly, mobile devices perform
lightweight forward propagation computations on local data using their frozen
pre-scaled backbone LLMs, and then upload selected intermediate activations.
The server trains a shared side-network independently, eliminating client-side
backpropagation and enabling asynchronous updates. To bridge model
heterogeneity across different devices, we introduce an adaptive layer-wise
feature alignment method, which ensures consistent representations for
collaboratively tuning a shared side network. Extensive experimental results
demonstrate that Fed MobiLLM can maintain robust fine-tuning performance while
achieving extremely low on-device memory, with at least 95.2% reduction in
computation overhead, 93.2% reduction in communication costs and 5.1x faster
convergence compared to existing methods, validating its efficacy for practical
LLM adaptation over heterogeneous mobile devices.

</details>


### [431] [Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift](https://arxiv.org/abs/2508.06776)
*Amit Pandey*

Main category: cs.LG

TL;DR: Zero-Direction Probing (ZDP) 是一种无需任务标签或输出评估的理论框架，通过检测Transformer激活的零方向来识别模型漂移。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种无需依赖任务标签或输出评估的方法，以检测模型漂移，从而提供更灵活和通用的监控手段。

Method: 方法基于理论分析，包括证明Variance-Leak定理、Fisher Null-Conservation等，并提出了Spectral Null-Leakage (SNL) 度量。

Result: 结果表明，通过监控层激活的左右零空间及其Fisher几何，可以提供对表示变化的具体、可测试的保证。

Conclusion: 结论是ZDP框架为模型漂移检测提供了理论支持，并展示了其在无监督条件下的有效性。

Abstract: We present Zero-Direction Probing (ZDP), a theory-only framework for
detecting model drift from null directions of transformer activations without
task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the
Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound
for low-rank updates, and (iv) a logarithmic-regret guarantee for online
null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with
non-asymptotic tail bounds and a concentration inequality, yielding a-priori
thresholds for drift under a Gaussian null model. These results show that
monitoring right/left null spaces of layer activations and their Fisher
geometry provides concrete, testable guarantees on representational change.

</details>


### [432] [PROPS: Progressively Private Self-alignment of Large Language Models](https://arxiv.org/abs/2508.06783)
*Noel Teku,Fengwei Tian,Payel Bhattacharjee,Souradip Chakraborty,Amrit Singh Bedi,Ravi Tandon*

Main category: cs.LG

TL;DR: PROPS是一种多阶段隐私保护对齐框架，通过逐步私有化自对齐模型，提高LLM对齐的效用和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 依赖人类反馈的LLM对齐可能泄露标注者的隐私信息，现有方法如DP-SGD可能过度保护隐私并降低模型效用。

Method: 提出PROPS框架，利用前一阶段私有化对齐的模型为后续阶段提供标注数据。

Result: PROPS在相同隐私预算下，比DP-SGD和RR方法分别提高3倍和2.5倍的胜率。

Conclusion: PROPS在保护隐私的同时显著提升了LLM对齐的效用。

Abstract: Alignment is a key step in developing Large Language Models (LLMs) using
human feedback to ensure adherence to human values and societal norms.
Dependence on human feedback raises privacy concerns about how much a labeler's
preferences may reveal about their personal values, beliefs, and personality
traits. Existing approaches, such as Differentially Private SGD (DP-SGD),
provide rigorous privacy guarantees by privatizing gradients during fine-tuning
and alignment but can provide more privacy than necessary as human preferences
are tied only to labels of (prompt, response) pairs and can degrade model
utility. This work focuses on LLM alignment with preference-level privacy,
which preserves the privacy of preference labels provided by humans. We propose
PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving
alignment framework where privately aligned models in previous stages can serve
as labelers for supplementing training data in the subsequent stages of
alignment. We present theoretical guarantees for PROPS as well as comprehensive
validation using multiple models (Pythia and GPT) and datasets (AlpacaEval,
Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over
existing methods while still providing high privacy. For the same privacy
budget, alignment via PROPS can achieve up to 3x higher win-rates compared to
DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based
alignment.

</details>


### [433] [Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning](https://arxiv.org/abs/2508.06784)
*Junjing Zheng,Chengliang Song,Weidong Jiang,Xinyu Zhang*

Main category: cs.LG

TL;DR: MA-NTAE是一种新型自监督学习模型，通过非线性Tucker分解和灵活的逐模式编码策略，解决了高维张量数据中的计算和优化问题。


<details>
  <summary>Details</summary>
Motivation: 高维张量数据在自监督学习中面临维度灾难和计算负担的挑战，现有方法难以有效捕捉非线性关系。

Method: 提出MA-NTAE，结合非线性Tucker分解和Pick-and-Unfold策略，实现灵活的逐模式编码。

Result: 实验表明，MA-NTAE在压缩和聚类任务中优于传统AE和现有张量网络，尤其适用于高阶高维张量。

Conclusion: MA-NTAE为高维张量数据提供了一种高效且可扩展的非线性特征提取方法。

Abstract: High-dimensional data, particularly in the form of high-order tensors,
presents a major challenge in self-supervised learning. While MLP-based
autoencoders (AE) are commonly employed, their dependence on flattening
operations exacerbates the curse of dimensionality, leading to excessively
large model sizes, high computational overhead, and challenging optimization
for deep structural feature capture. Although existing tensor networks
alleviate computational burdens through tensor decomposition techniques, most
exhibit limited capability in learning non-linear relationships. To overcome
these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder
(MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear
framework and employs a Pick-and-Unfold strategy, facilitating flexible
per-mode encoding of high-order tensors via recursive unfold-encode-fold
operations, effectively integrating tensor structural priors. Notably, MA-NTAE
exhibits linear growth in computational complexity with tensor order and
proportional growth with mode dimensions. Extensive experiments demonstrate
MA-NTAE's performance advantages over standard AE and current tensor networks
in compression and clustering tasks, which become increasingly pronounced for
higher-order, higher-dimensional tensors.

</details>


### [434] [Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities](https://arxiv.org/abs/2508.06800)
*Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan*

Main category: cs.LG

TL;DR: 提出了一种名为HARDY-MER的动态课程学习框架，通过评估样本难度并动态调整训练重点，提升多模态情感识别中缺失模态的处理能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过重建缺失模态处理多模态情感识别问题，但未考虑不同样本重建难度的差异，导致对困难样本处理能力不足。

Method: HARDY-MER框架分为两阶段：1) 通过多视角硬度评估机制量化样本难度；2) 采用检索式动态课程学习策略动态调整训练重点。

Result: 在基准数据集上的实验表明，HARDY-MER在缺失模态场景中优于现有方法。

Conclusion: HARDY-MER通过动态课程学习有效提升了模型对困难样本的处理能力，为多模态情感识别中的缺失模态问题提供了新思路。

Abstract: Missing modalities have recently emerged as a critical research direction in
multimodal emotion recognition (MER). Conventional approaches typically address
this issue through missing modality reconstruction. However, these methods fail
to account for variations in reconstruction difficulty across different
samples, consequently limiting the model's ability to handle hard samples
effectively. To overcome this limitation, we propose a novel Hardness-Aware
Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates
in two key stages: first, it estimates the hardness level of each sample, and
second, it strategically emphasizes hard samples during training to enhance
model performance on these challenging instances. Specifically, we first
introduce a Multi-view Hardness Evaluation mechanism that quantifies
reconstruction difficulty by considering both Direct Hardness (modality
reconstruction errors) and Indirect Hardness (cross-modal mutual information).
Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy
that dynamically adjusts the training curriculum by retrieving samples with
similar semantic information and balancing the learning focus between easy and
hard instances. Extensive experiments on benchmark datasets demonstrate that
HARDY-MER consistently outperforms existing methods in missing-modality
scenarios. Our code will be made publicly available at
https://github.com/HARDY-MER/HARDY-MER.

</details>


### [435] [Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation](https://arxiv.org/abs/2508.06806)
*Xiao Huang,Xu Liu,Enze Zhang,Tong Yu,Shuai Li*

Main category: cs.LG

TL;DR: 论文提出了一种新的数据增强方法CFDG，用于离线到在线强化学习（O2O RL），通过无分类器扩散生成技术提升数据质量，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过离线数据集生成与在线数据分布一致的数据进行增强，但生成数据与在线数据仍存在差距，限制了性能。

Method: 提出Classifier-Free Diffusion Generation（CFDG），利用无分类器引导扩散技术提升生成质量，并结合重加权方法使生成数据更贴近在线数据。

Result: 实验表明，CFDG在D4RL基准测试（如MuJoCo和AntMaze）中平均性能提升15%，优于现有方法。

Conclusion: CFDG是一种通用方法，可与现有O2O RL算法结合，显著提升性能且保持稳定性。

Abstract: Offline-to-online Reinforcement Learning (O2O RL) aims to perform online
fine-tuning on an offline pre-trained policy to minimize costly online
interactions. Existing work used offline datasets to generate data that conform
to the online data distribution for data augmentation. However, generated data
still exhibits a gap with the online data, limiting overall performance. To
address this, we propose a new data augmentation approach, Classifier-Free
Diffusion Generation (CFDG). Without introducing additional classifier training
overhead, CFDG leverages classifier-free guidance diffusion to significantly
enhance the generation quality of offline and online data with different
distributions. Additionally, it employs a reweighting method to enable more
generated data to align with the online data, enhancing performance while
maintaining the agent's stability. Experimental results show that CFDG
outperforms replaying the two data types or using a standard diffusion model to
generate new data. Our method is versatile and can be integrated with existing
offline-to-online RL algorithms. By implementing CFDG to popular methods IQL,
PEX and APL, we achieve a notable 15% average improvement in empirical
performance on the D4RL benchmark such as MuJoCo and AntMaze.

</details>


### [436] [Discovery Learning accelerates battery design evaluation](https://arxiv.org/abs/2508.06985)
*Jiawei Zhang,Yifei Zhang,Baozhao Yi,Yao Ren,Qi Jiao,Hanyu Bai,Weiran Jiang,Ziyou Song*

Main category: cs.LG

TL;DR: 论文提出了一种名为Discovery Learning（DL）的科学机器学习范式，通过结合主动学习、物理引导学习和零样本学习，显著提高了电池设计的验证效率，减少了时间和能源消耗。


<details>
  <summary>Details</summary>
Motivation: 电池研发因原型设计和寿命测试的高成本而受限，现有数据驱动方法需要目标设计的标记数据且效率不足，亟需一种更高效的方法来加速设计验证。

Method: DL整合了主动学习、物理引导学习和零样本学习，利用历史电池设计数据，减少对原型的需求，实现对新材料设计组合的快速寿命评估。

Result: 在123个工业级锂离子电池上测试，DL仅使用公开数据集训练，预测寿命的平均测试误差为7.2%，节省了98%的时间和95%的能源。

Conclusion: DL展示了利用历史设计数据加速下一代电池技术开发的潜力，是数据驱动建模的重要进展。

Abstract: Fast and reliable validation of novel designs in complex physical systems
such as batteries is critical to accelerating technological innovation.
However, battery research and development remain bottlenecked by the
prohibitively high time and energy costs required to evaluate numerous new
design candidates, particularly in battery prototyping and life testing.
Despite recent progress in data-driven battery lifetime prediction, existing
methods require labeled data of target designs to improve accuracy and cannot
make reliable predictions until after prototyping, thus falling far short of
the efficiency needed to enable rapid feedback for battery design. Here, we
introduce Discovery Learning (DL), a scientific machine-learning paradigm that
integrates active learning, physics-guided learning, and zero-shot learning
into a human-like reasoning loop, drawing inspiration from learning theories in
educational psychology. DL can learn from historical battery designs and
actively reduce the need for prototyping, thus enabling rapid lifetime
evaluation for unobserved material-design combinations without requiring
additional data labeling. To test DL, we present 123 industrial-grade
large-format lithium-ion pouch cells, spanning eight material-design
combinations and diverse cycling protocols. Trained solely on public datasets
of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting
the average cycle life under unknown device variability. This results in
savings of 98% in time and 95% in energy compared to industrial practices. This
work highlights the potential of uncovering insights from historical designs to
inform and accelerate the development of next-generation battery technologies.
DL represents a key advance toward efficient data-driven modeling and helps
realize the promise of machine learning for accelerating scientific discovery
and engineering innovation.

</details>


### [437] [Technical Report: Full-Stack Fine-Tuning for the Q Programming Language](https://arxiv.org/abs/2508.06813)
*Brendan R. Hogan,Will Brown,Adel Boyarsky,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 本文提出了一种开源方法，将大语言模型（LLMs）适配到Q编程语言，解决了其在小众语言和私有领域应用的挑战。通过预训练、监督微调和强化学习，训练了一系列模型，并在Q语言基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs能力强大，但在小众编程语言（如Q语言）和私有领域任务中表现不佳，亟需解决方案。

Method: 构建Q语言的Leetcode风格评估数据集，对前沿模型进行基准测试，并通过预训练、监督微调和强化学习训练不同规模的模型。

Result: 最佳模型在Q基准测试中达到59%的准确率，显著优于Claude Opus-4和GPT-4.1。

Conclusion: 该方法不仅适用于Q语言，还可推广到其他任务，为小众领域LLMs应用提供了可行方案。

Abstract: Even though large language models are becoming increasingly capable, it is
still unreasonable to expect them to excel at tasks that are under-represented
on the Internet. Leveraging LLMs for specialized applications, particularly in
niche programming languages and private domains, remains challenging and
largely unsolved. In this work, we address this gap by presenting a
comprehensive, open-source approach for adapting LLMs to the Q programming
language, a popular tool in quantitative finance that is much less present on
the Internet compared to Python, C, Java, and other ``mainstream" languages and
is therefore not a strong suit of general-purpose AI models. We introduce a new
Leetcode style evaluation dataset for Q, benchmark major frontier models on the
dataset, then do pretraining, supervised fine tuning, and reinforcement
learning to train a suite of reasoning and non-reasoning models based on the
Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our
best model achieves a pass@1 accuracy of 59 percent on our Q benchmark,
surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.
Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.
In addition to releasing models, code, and data, we provide a detailed
blueprint for dataset construction, model pretraining, supervised fine-tuning,
and reinforcement learning. Our methodology is broadly applicable, and we
discuss how these techniques can be extended to other tasks, including those
where evaluation may rely on soft or subjective signals.

</details>


### [438] [From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving](https://arxiv.org/abs/2508.07029)
*Antonio Guillen-Perez*

Main category: cs.LG

TL;DR: 论文提出了一种结合行为克隆（BC）和离线强化学习（CQL）的方法，显著提升了自动驾驶策略的鲁棒性和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决行为克隆策略在闭环执行中易出错的问题，探索从静态专家数据中学习鲁棒驾驶策略的方法。

Method: 开发了基于Transformer的BC基线模型，并应用CQL算法优化策略，结合精心设计的奖励函数。

Result: 在Waymo数据集上，CQL策略的成功率比最强BC基线高3.2倍，碰撞率低7.4倍。

Conclusion: 离线强化学习是从静态数据中学习鲁棒驾驶策略的关键方法。

Abstract: Learning robust driving policies from large-scale, real-world datasets is a
central challenge in autonomous driving, as online data collection is often
unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward
approach to imitation learning, policies trained with BC are notoriously
brittle and suffer from compounding errors in closed-loop execution. This work
presents a comprehensive pipeline and a comparative study to address this
limitation. We first develop a series of increasingly sophisticated BC
baselines, culminating in a Transformer-based model that operates on a
structured, entity-centric state representation. While this model achieves low
imitation loss, we show that it still fails in long-horizon simulations. We
then demonstrate that by applying a state-of-the-art Offline Reinforcement
Learning algorithm, Conservative Q-Learning (CQL), to the same data and
architecture, we can learn a significantly more robust policy. Using a
carefully engineered reward function, the CQL agent learns a conservative value
function that enables it to recover from minor errors and avoid
out-of-distribution states. In a large-scale evaluation on 1,000 unseen
scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a
3.2x higher success rate and a 7.4x lower collision rate than the strongest BC
baseline, proving that an offline RL approach is critical for learning robust,
long-horizon driving policies from static expert data.

</details>


### [439] [Who's the Evil Twin? Differential Auditing for Undesired Behavior](https://arxiv.org/abs/2508.06827)
*Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha*

Main category: cs.LG

TL;DR: 论文提出了一种通过对抗游戏检测神经网络中隐藏行为的方法，红队训练两个模型（一个良性，一个含隐藏有害行为），蓝队尝试识别被篡改的模型。实验显示基于对抗攻击的方法效果最佳，而LLM审计需要额外提示。


<details>
  <summary>Details</summary>
Motivation: 检测神经网络中的隐藏行为具有挑战性，尤其是缺乏先验知识或存在对抗性混淆时。

Method: 通过对抗游戏框架，红队训练两个模型，蓝队使用多种策略（如高斯噪声分析、模型差异、积分梯度和对抗攻击）识别被篡改的模型。

Result: 基于对抗攻击的方法在提供提示时准确率高达100%，其他方法表现不一。LLM审计需要额外提示才能有效。

Conclusion: 研究为设计更好的审计方法提供了参考，并开源了相关模型和数据。

Abstract: Detecting hidden behaviors in neural networks poses a significant challenge
due to minimal prior knowledge and potential adversarial obfuscation. We
explore this problem by framing detection as an adversarial game between two
teams: the red team trains two similar models, one trained solely on benign
data and the other trained on data containing hidden harmful behavior, with the
performance of both being nearly indistinguishable on the benign dataset. The
blue team, with limited to no information about the harmful behaviour, tries to
identify the compromised model. We experiment using CNNs and try various blue
team strategies, including Gaussian noise analysis, model diffing, integrated
gradients, and adversarial attacks under different levels of hints provided by
the red team. Results show high accuracy for adversarial-attack-based methods
(100\% correct prediction, using hints), which is very promising, whilst the
other techniques yield more varied performance. During our LLM-focused rounds,
we find that there are not many parallel methods that we could apply from our
study with CNNs. Instead, we find that effective LLM auditing methods require
some hints about the undesired distribution, which can then used in standard
black-box and open-weight methods to probe the models further and reveal their
misalignment. We open-source our auditing games (with the model and data) and
hope that our findings contribute to designing better audits.

</details>


### [440] [Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning](https://arxiv.org/abs/2508.06871)
*Aleksandar Todorov,Juan Cardenas-Cartagena,Rafael F. Cunha,Marco Zullich,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 论文研究了深度强化学习中塑性损失的问题，探讨了稀疏化方法（如GMP和SET）如何提升多任务强化学习（MTRL）中的塑性，并验证了其性能提升。


<details>
  <summary>Details</summary>
Motivation: 塑性损失是深度强化学习中的关键挑战，尤其在多任务学习中，更高的表征灵活性对处理多样且可能冲突的任务需求至关重要。

Method: 通过系统评估稀疏化方法（GMP和SET）在不同MTRL架构（共享主干、专家混合、正交专家混合）上的表现，并与密集基线及其他塑性诱导或正则化方法对比。

Result: 结果表明，GMP和SET能有效缓解塑性退化（如神经元休眠和表征崩溃），并常带来多任务性能的提升，稀疏代理常优于密集代理。

Conclusion: 动态稀疏化是开发更具适应性MTRL系统的有效工具，但其效果受上下文影响。

Abstract: Plasticity loss, a diminishing capacity to adapt as training progresses, is a
critical challenge in deep reinforcement learning. We examine this issue in
multi-task reinforcement learning (MTRL), where higher representational
flexibility is crucial for managing diverse and potentially conflicting task
demands. We systematically explore how sparsification methods, particularly
Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance
plasticity and consequently improve performance in MTRL agents. We evaluate
these approaches across distinct MTRL architectures (shared backbone, Mixture
of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks,
comparing against dense baselines, and a comprehensive range of alternative
plasticity-inducing or regularization methods. Our results demonstrate that
both GMP and SET effectively mitigate key indicators of plasticity degradation,
such as neuron dormancy and representational collapse. These plasticity
improvements often correlate with enhanced multi-task performance, with sparse
agents frequently outperforming dense counterparts and achieving competitive
results against explicit plasticity interventions. Our findings offer insights
into the interplay between plasticity, network sparsity, and MTRL designs,
highlighting dynamic sparsification as a robust but context-sensitive tool for
developing more adaptable MTRL systems.

</details>


### [441] [Conformal Prediction and Trustworthy AI](https://arxiv.org/abs/2508.06885)
*Anthony Bellotti,Xindi Zhao*

Main category: cs.LG

TL;DR: 本文回顾了保形预测在可信AI中的潜力，探讨了其边际有效性之外的贡献，如泛化风险和AI治理，并通过实验展示了其作为校准预测器和偏识别与缓解工具的应用。


<details>
  <summary>Details</summary>
Motivation: 保形预测作为一种提供置信度保证的机器学习方法，近年来在可信AI领域受到关注。本文旨在探讨其在可信AI中的更广泛潜力。

Method: 通过回顾保形预测的理论基础，结合实验和示例，分析其在泛化风险、AI治理、偏识别与缓解等方面的应用。

Result: 保形预测不仅提供校准的预测结果，还能有效识别和缓解偏，为可信AI的发展提供了实用工具。

Conclusion: 保形预测在可信AI中具有重要潜力，尤其是在泛化风险和AI治理方面，未来研究可进一步探索其应用。

Abstract: Conformal predictors are machine learning algorithms developed in the 1990's
by Gammerman, Vovk, and their research team, to provide set predictions with
guaranteed confidence level. Over recent years, they have grown in popularity
and have become a mainstream methodology for uncertainty quantification in the
machine learning community. From its beginning, there was an understanding that
they enable reliable machine learning with well-calibrated uncertainty
quantification. This makes them extremely beneficial for developing trustworthy
AI, a topic that has also risen in interest over the past few years, in both
the AI community and society more widely. In this article, we review the
potential for conformal prediction to contribute to trustworthy AI beyond its
marginal validity property, addressing problems such as generalization risk and
AI governance. Experiments and examples are also provided to demonstrate its
use as a well-calibrated predictor and for bias identification and mitigation.

</details>


### [442] [QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting](https://arxiv.org/abs/2508.06915)
*Shichao Ma,Zhengyang Zhou,Qihe Huang,Binwu Wang,Kuo Yang,Huan Li,Yang Wang*

Main category: cs.LG

TL;DR: 论文提出QuiZSF框架，结合检索增强生成（RAG）与时间序列预训练模型（TSPMs），提升零样本时间序列预测（ZSF）性能。


<details>
  <summary>Details</summary>
Motivation: 传统模型在数据稀缺场景（如领域迁移或极端条件）下难以处理ZSF，而现有TSPMs缺乏动态整合外部知识的机制。

Method: 提出QuiZSF框架，包括分层树结构ChronoRAG Base（CRB）、多粒度序列交互学习器（MSIL）和双分支模型协作器（MCC）。

Result: QuiZSF在75%和87.5%的预测场景中排名Top1，同时保持高效内存和推理时间。

Conclusion: QuiZSF通过结合RAG与TSPMs，显著提升了ZSF的性能和效率。

Abstract: Time series forecasting has become increasingly important to empower diverse
applications with streaming data. Zero-shot time-series forecasting (ZSF),
particularly valuable in data-scarce scenarios, such as domain transfer or
forecasting under extreme conditions, is difficult for traditional models to
deal with. While time series pre-trained models (TSPMs) have demonstrated
strong performance in ZSF, they often lack mechanisms to dynamically
incorporate external knowledge. Fortunately, emerging retrieval-augmented
generation (RAG) offers a promising path for injecting such knowledge on
demand, yet they are rarely integrated with TSPMs. To leverage the strengths of
both worlds, we introduce RAG into TSPMs to enhance zero-shot time series
forecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series
Forecaster), a lightweight and modular framework that couples efficient
retrieval with representation learning and model adaptation for ZSF.
Specifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB)
for scalable time-series storage and domain-aware retrieval, introduce a
Multi-grained Series Interaction Learner (MSIL) to extract fine- and
coarse-grained relational features, and develop a dual-branch Model Cooperation
Coherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM
based and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM
based and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and
87.5% of prediction settings, while maintaining high efficiency in memory and
inference time.

</details>


### [443] [Class Unbiasing for Generalization in Medical Diagnosis](https://arxiv.org/abs/2508.06943)
*Lishi Zuo,Man-Wai Mak,Lu Yi,Youzhi Tu*

Main category: cs.LG

TL;DR: 论文提出了一种解决医学诊断中类别特征偏差和类别不平衡的方法，通过类别不平等损失和类别加权优化目标，提升模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 医学诊断中模型可能因依赖与部分类别强相关的特征而产生偏差，导致性能偏向和泛化能力差。

Method: 提出类别不平等损失和类别加权分布鲁棒优化目标，平衡正负类别样本的分类损失，并加权表现不佳的类别。

Result: 实验证明类别特征偏差会损害模型性能，而所提方法能有效缓解偏差和不平衡，提升泛化能力。

Conclusion: 该方法同时解决了类别特征偏差和类别不平衡问题，显著改善了模型的泛化性能。

Abstract: Medical diagnosis might fail due to bias. In this work, we identified
class-feature bias, which refers to models' potential reliance on features that
are strongly correlated with only a subset of classes, leading to biased
performance and poor generalization on other classes. We aim to train a
class-unbiased model (Cls-unbias) that mitigates both class imbalance and
class-feature bias simultaneously. Specifically, we propose a class-wise
inequality loss which promotes equal contributions of classification loss from
positive-class and negative-class samples. We propose to optimize a class-wise
group distributionally robust optimization objective-a class-weighted training
objective that upweights underperforming classes-to enhance the effectiveness
of the inequality loss under class imbalance. Through synthetic and real-world
datasets, we empirically demonstrate that class-feature bias can negatively
impact model performance. Our proposed method effectively mitigates both
class-feature bias and class imbalance, thereby improving the model's
generalization ability.

</details>


### [444] [Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow](https://arxiv.org/abs/2508.07841)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.LG

TL;DR: 论文研究了将物理信息神经网络（PINNs）用于航天器姿态动力学学习，相比纯数据驱动方法，PINNs显著提升了性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在物理模型不完整或计算成本高时，纯数据驱动方法泛化性和稳定性不足，PINNs提供了一种结合物理信息的解决方案。

Method: 使用Real NVP神经网络架构和自注意力机制，基于Basilisk模拟器生成数据，比较纯数据驱动和物理信息变体的训练策略。

Result: 物理信息模型的平均相对误差降低了27.08%，在MPC框架中控制精度和鲁棒性提升高达42.86%。

Conclusion: PINNs显著优于纯数据驱动方法，尤其在MPC应用中表现出更高的稳定性和抗噪能力。

Abstract: Attitude control is a fundamental aspect of spacecraft operations. Model
Predictive Control (MPC) has emerged as a powerful strategy for these tasks,
relying on accurate models of the system dynamics to optimize control actions
over a prediction horizon. In scenarios where physics models are incomplete,
difficult to derive, or computationally expensive, machine learning offers a
flexible alternative by learning the system behavior directly from data.
However, purely data-driven models often struggle with generalization and
stability, especially when applied to inputs outside their training domain. To
address these limitations, we investigate the benefits of incorporating
Physics-Informed Neural Networks (PINNs) into the learning of spacecraft
attitude dynamics, comparing their performance with that of purely data-driven
approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network
architecture with a self-attention mechanism, we trained several models on
simulated data generated with the Basilisk simulator. Two training strategies
were considered: a purely data-driven baseline and a physics-informed variant
to improve robustness and stability. Our results demonstrate that the inclusion
of physics-based information significantly enhances the performance in terms of
the mean relative error of the best architectures found by 27.08%. These
advantages are particularly evident when the learned models are integrated into
an MPC framework, where PINN-based models consistently outperform their purely
data-driven counterparts in terms of control accuracy and robustness, yielding
improvements of up to 42.86% in performance stability error and increased
robustness-to-noise.

</details>


### [445] [AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance](https://arxiv.org/abs/2508.06944)
*Lixuan He,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: 论文提出了一种名为AMFT的单阶段算法，通过隐式奖励理论动态平衡监督微调（SFT）和强化学习（RL），解决了传统两阶段方法中的灾难性遗忘和探索-模仿权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统两阶段方法（SFT+RL）存在灾难性遗忘和探索-模仿权衡问题，现有单阶段方法缺乏动态平衡机制。

Method: 提出AMFT算法，利用元梯度自适应权重控制器动态优化SFT和RL的平衡，并通过策略熵正则化确保稳定性。

Result: 在数学推理、抽象视觉推理和视觉语言导航等任务上，AMFT均达到最新最优性能，并表现出更强的泛化能力。

Conclusion: AMFT通过动态平衡SFT和RL，提供了一种更有效且稳定的LLM对齐范式。

Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.

</details>


### [446] [BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity](https://arxiv.org/abs/2508.06953)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.LG

TL;DR: BoRA是一种改进的低秩适应方法，通过块矩阵乘法和块间对角矩阵提升LoRA权重秩，仅需少量额外参数即可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: LoRA在大型语言模型中被广泛使用，但增加秩会显著增加可训练参数数量，BoRA旨在以更少的参数提升秩和性能。

Method: BoRA将LoRA的权重矩阵分解为块矩阵，并为每个块乘法引入独特的对角矩阵，从而增加秩。

Result: 实验表明BoRA在多个数据集和模型上表现优异，且具有可扩展性。

Conclusion: BoRA通过块多样化和对角矩阵优化，以更少的参数实现了更高的秩和性能提升。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). It approximates the update of a
pretrained weight matrix $W\in\mathbb{R}^{m\times n}$ by the product of two
low-rank matrices, $BA$, where $A \in\mathbb{R}^{r\times n}$ and
$B\in\mathbb{R}^{m\times r} (r\ll\min\{m,n\})$. Increasing the dimension $r$
can raise the rank of LoRA weights (i.e., $BA$), which typically improves
fine-tuning performance but also significantly increases the number of
trainable parameters. In this paper, we propose Block Diversified Low-Rank
Adaptation (BoRA), which improves the rank of LoRA weights with a small number
of additional parameters. Specifically, BoRA treats the product $BA$ as a block
matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along
the columns and rows, respectively (i.e., $A=[A_1,\dots,A_b]$ and
$B=[B_1,\dots,B_b]^\top$). Consequently, the product $BA$ becomes the
concatenation of the block products $B_iA_j$ for $i,j\in[b]$. To enhance the
diversity of different block products, BoRA introduces a unique diagonal matrix
$\Sigma_{i,j} \in \mathbb{R}^{r\times r}$ for each block multiplication,
resulting in $B_i \Sigma_{i,j} A_j$. By leveraging these block-wise diagonal
matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only
requiring $b^2r$ additional parameters. Extensive experiments across multiple
datasets and models demonstrate the superiority of BoRA, and ablation studies
further validate its scalability.

</details>


### [447] [MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08137)
*Pravallika Abbineni,Saoud Aldowaish,Colin Liechty,Soroosh Noorzad,Ali Ghazizadeh,Morteza Fayazi*

Main category: cs.LG

TL;DR: MuaLLM是一种开源多模态大型语言模型代理，用于电路设计辅助，结合了混合检索增强生成框架和自适应向量数据库，显著提升了电路设计文献分析的效率和成本效益。


<details>
  <summary>Details</summary>
Motivation: 电路设计文献综述面临快速更新的研究、不一致的数据表示和复杂的优化目标，传统方法难以应对。

Method: MuaLLM采用Reason + Act（ReAct）工作流，结合多模态数据处理和动态检索工具，实现高效文献分析和推理。

Result: MuaLLM在RAG-250和Reas-100数据集上分别达到90.1%召回率和86.8%准确率，成本降低10倍，速度提升1.6倍。

Conclusion: MuaLLM为电路设计文献分析提供了高效、低成本的解决方案，克服了传统方法的局限性。

Abstract: Conducting a comprehensive literature review is crucial for advancing circuit
design methodologies. However, the rapid influx of state-of-the-art research,
inconsistent data representation, and the complexity of optimizing circuit
design objectives make this task significantly challenging. In this paper, we
propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for
circuit design assistance that integrates a hybrid Retrieval-Augmented
Generation (RAG) framework with an adaptive vector database of circuit design
research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason +
Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step
information retrieval. It functions as a question-answering design assistant,
capable of interpreting complex queries and providing reasoned responses
grounded in circuit literature. Its multimodal capabilities enable processing
of both textual and visual data, facilitating more efficient and comprehensive
analysis. The system dynamically adapts using intelligent search tools,
automated document retrieval from the internet, and real-time database updates.
Unlike conventional approaches constrained by model context limits, MuaLLM
decouples retrieval from inference, enabling scalable reasoning over
arbitrarily large corpora. At the maximum context length supported by standard
LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining
the same accuracy. This allows rapid, no-human-in-the-loop database generation,
overcoming the bottleneck of simulation-based dataset creation for circuits. To
evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval
and citation performance, and Reasoning-100 (Reas-100), focused on multistep
reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8%
accuracy on Reas-100.

</details>


### [448] [Can Multitask Learning Enhance Model Explainability?](https://arxiv.org/abs/2508.06966)
*Hiba Najjar,Bushra Alshbib,Andreas Dengel*

Main category: cs.LG

TL;DR: 论文提出了一种通过多任务学习利用遥感数据多样性的方法，以提升模型性能并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 遥感数据多样性和多模态学习网络的复杂性导致模型可解释性降低，研究旨在通过多任务学习解决这一问题。

Method: 将某些模态作为附加目标与主任务一起预测，而非额外输入，利用卫星数据的丰富信息。

Result: 方法在数据稀缺时无需额外模态，性能与多模态基线相当或更优，且可通过辅助任务解释主任务预测误差。

Conclusion: 该方法在多任务学习中高效且可解释，适用于分割、分类和回归任务。

Abstract: Remote sensing provides satellite data in diverse types and formats. The
usage of multimodal learning networks exploits this diversity to improve model
performance, except that the complexity of such networks comes at the expense
of their interpretability. In this study, we explore how modalities can be
leveraged through multitask learning to intrinsically explain model behavior.
In particular, instead of additional inputs, we use certain modalities as
additional targets to be predicted along with the main task. The success of
this approach relies on the rich information content of satellite data, which
remains as input modalities. We show how this modeling context provides
numerous benefits: (1) in case of data scarcity, the additional modalities do
not need to be collected for model inference at deployment, (2) the model
performance remains comparable to the multimodal baseline performance, and in
some cases achieves better scores, (3) prediction errors in the main task can
be explained via the model behavior in the auxiliary task(s). We demonstrate
the efficiency of our approach on three datasets, including segmentation,
classification, and regression tasks. Code available at
git.opendfki.de/hiba.najjar/mtl_explainability/.

</details>


### [449] [Structure-Preserving Digital Twins via Conditional Neural Whitney Forms](https://arxiv.org/abs/2508.06981)
*Brooks Kinch,Benjamin Shaffer,Elizabeth Armstrong,Michael Meehan,John Hewson,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于结构保持的降阶有限元模型构建实时数字孪生的框架，利用条件注意力机制学习降阶基和非线性守恒律，支持实时校准和闭环推理。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀疏或优化误差下数值稳定性和守恒量精确保持的问题，同时支持复杂几何和传感器数据集成。

Method: 结合有限元外微积分（FEEC）和条件注意力机制，学习降阶基和非线性守恒律，实现非侵入式与传统有限元方法集成。

Result: 在复杂几何和稀疏数据（25次LES模拟）下实现准确预测，实时推理速度提升3.1x10^8倍，开源实现可用。

Conclusion: 该框架在数值稳定性和实时性上表现优异，适用于复杂问题如湍流过渡和电池热失控。

Abstract: We present a framework for constructing real-time digital twins based on
structure-preserving reduced finite element models conditioned on a latent
variable Z. The approach uses conditional attention mechanisms to learn both a
reduced finite element basis and a nonlinear conservation law within the
framework of finite element exterior calculus (FEEC). This guarantees numerical
well-posedness and exact preservation of conserved quantities, regardless of
data sparsity or optimization error. The conditioning mechanism supports
real-time calibration to parametric variables, allowing the construction of
digital twins which support closed loop inference and calibration to sensor
data. The framework interfaces with conventional finite element machinery in a
non-invasive manner, allowing treatment of complex geometries and integration
of learned models with conventional finite element techniques.
  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,
and a complex battery thermal runaway problem. The method achieves accurate
predictions on complex geometries with sparse data (25 LES simulations),
including capturing the transition to turbulence and achieving real-time
inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source
implementation is available on GitHub.

</details>


### [450] [UniMove: A Unified Model for Multi-city Human Mobility Prediction](https://arxiv.org/abs/2508.06986)
*Chonghua Han,Yuan Yuan,Yukun Liu,Jingtao Ding,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: UniMove是一个统一的多城市人类移动预测模型，通过通用空间表示和轨迹-位置双塔架构，解决了城市间异质性问题，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 人类移动预测对城市规划等至关重要，但现有方法因城市异质性需为每个城市单独训练模型，效率低下。

Method: 提出轨迹-位置双塔架构和MoE Transformer块，实现通用空间表示和异质移动模式建模。

Result: 在多城市数据集上，UniMove通过联合训练将预测准确性提升10.2%。

Conclusion: UniMove是实现人类移动基础模型的关键进展，支持多城市数据联合训练与增强。

Abstract: Human mobility prediction is vital for urban planning, transportation
optimization, and personalized services. However, the inherent randomness,
non-uniform time intervals, and complex patterns of human mobility, compounded
by the heterogeneity introduced by varying city structures, infrastructure, and
population densities, present significant challenges in modeling. Existing
solutions often require training separate models for each city due to distinct
spatial representations and geographic coverage. In this paper, we propose
UniMove, a unified model for multi-city human mobility prediction, addressing
two challenges: (1) constructing universal spatial representations for
effective token sharing across cities, and (2) modeling heterogeneous mobility
patterns from varying city characteristics. We propose a trajectory-location
dual-tower architecture, with a location tower for universal spatial encoding
and a trajectory tower for sequential mobility modeling. We also design MoE
Transformer blocks to adaptively select experts to handle diverse movement
patterns. Extensive experiments across multiple datasets from diverse cities
demonstrate that UniMove truly embodies the essence of a unified model. By
enabling joint training on multi-city data with mutual data enhancement, it
significantly improves mobility prediction accuracy by over 10.2\%. UniMove
represents a key advancement toward realizing a true foundational model with a
unified architecture for human mobility. We release the implementation at
https://github.com/tsinghua-fib-lab/UniMove/.

</details>


### [451] [A Comparative Study of Feature Selection in Tsetlin Machines](https://arxiv.org/abs/2508.06991)
*Vojtech Halenka,Ole-Christoffer Granmo,Lei Jiao,Per-Arne Andersen*

Main category: cs.LG

TL;DR: 本文研究了特征选择（FS）在Tsetlin机器（TM）中的应用，评估了多种FS方法，包括经典方法和新兴解释技术，并提出了一种基于TM内部评分的新方法。


<details>
  <summary>Details</summary>
Motivation: TM虽然具有可解释性，但缺乏特征重要性评估工具，因此需要研究如何在其上应用FS技术。

Method: 研究采用了多种FS方法，包括经典过滤和嵌入方法，以及SHAP、LIME等后解释方法，并提出了一种基于TM子句权重和Tsetlin自动机状态的新评分方法。

Result: 实验表明，TM内部评分方法不仅性能优越，还能利用子句的可解释性揭示特征交互模式，且计算成本更低。

Conclusion: 本研究为TM中的FS建立了首个全面基线，并为开发专用于TM的可解释性技术奠定了基础。

Abstract: Feature Selection (FS) is crucial for improving model interpretability,
reducing complexity, and sometimes for enhancing accuracy. The recently
introduced Tsetlin machine (TM) offers interpretable clause-based learning, but
lacks established tools for estimating feature importance. In this paper, we
adapt and evaluate a range of FS techniques for TMs, including classical filter
and embedded methods as well as post-hoc explanation methods originally
developed for neural networks (e.g., SHAP and LIME) and a novel family of
embedded scorers derived from TM clause weights and Tsetlin automaton (TA)
states. We benchmark all methods across 12 datasets, using evaluation
protocols, like Remove and Retrain (ROAR) strategy and Remove and Debias
(ROAD), to assess causal impact. Our results show that TM-internal scorers not
only perform competitively but also exploit the interpretability of clauses to
reveal interacting feature patterns. Simpler TM-specific scorers achieve
similar accuracy retention at a fraction of the computational cost. This study
establishes the first comprehensive baseline for FS in TM and paves the way for
developing specialized TM-specific interpretability techniques.

</details>


### [452] [TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations](https://arxiv.org/abs/2508.07016)
*Jianfei Wu,Wenmian Yang,Bingning Liu,Weijia Jia*

Main category: cs.LG

TL;DR: 提出了一种基于时间滞后互相关的序列预测框架（TLCCSP），通过整合时间滞后相关序列提升预测准确性，实验证明其在天气、金融和房地产数据集上显著降低MSE。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型常忽略时间滞后互相关，而这对捕捉复杂时序关系至关重要。

Method: 采用序列移位动态时间规整（SSDTW）算法捕捉滞后相关，并结合对比学习编码器（CLE）高效近似SSDTW距离。

Result: 在天气、金融和房地产数据集上，SSDTW和CLE分别显著降低MSE，且CLE将SSDTW计算时间减少约99%。

Conclusion: TLCCSP框架有效提升预测准确性并确保实时适用性，适用于多领域时序预测任务。

Abstract: Time series forecasting is critical across various domains, such as weather,
finance and real estate forecasting, as accurate forecasts support informed
decision-making and risk mitigation. While recent deep learning models have
improved predictive capabilities, they often overlook time-lagged
cross-correlations between related sequences, which are crucial for capturing
complex temporal relationships. To address this, we propose the Time-Lagged
Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances
forecasting accuracy by effectively integrating time-lagged cross-correlated
sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)
algorithm to capture lagged correlations and a contrastive learning-based
encoder to efficiently approximate SSDTW distances.
  Experimental results on weather, finance and real estate time series datasets
demonstrate the effectiveness of our framework. On the weather dataset, SSDTW
reduces mean squared error (MSE) by 16.01% compared with single-sequence
methods, while the contrastive learning encoder (CLE) further decreases MSE by
17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE
reduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by
21.29% and 8.62%, respectively. Additionally, the contrastive learning approach
decreases SSDTW computational time by approximately 99%, ensuring scalability
and real-time applicability across multiple time series forecasting tasks.

</details>


### [453] [A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling](https://arxiv.org/abs/2508.07032)
*Tiantian He,Keyue Jiang,An Zhao,Anna Schroder,Elinor Thompson,Sonja Soskic,Frederik Barkhof,Daniel C. Alexander*

Main category: cs.LG

TL;DR: 提出了一种阶段感知的混合专家框架（IGND-MoE），用于建模神经退行性疾病的动态进展，结合了时间依赖的专家权重和不均匀图神经扩散模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统模型在神经退行性疾病进展建模中的局限性，包括纵向数据稀缺和病理机制复杂性的问题。

Method: 采用阶段感知的混合专家框架（MoE），结合不均匀图神经扩散模型（IGND）和局部神经反应模块，动态整合时空组件。

Result: 模型能够捕捉不同疾病阶段的特异性病理机制，发现图相关过程在早期更显著，而未知物理过程在后期占主导。

Conclusion: IGND-MoE为理解神经退行性疾病的动态进展提供了新方法，并揭示了阶段特异性机制。

Abstract: The long-term progression of neurodegenerative diseases is commonly
conceptualized as a spatiotemporal diffusion process that consists of a graph
diffusion process across the structural brain connectome and a localized
reaction process within brain regions. However, modeling this progression
remains challenging due to 1) the scarcity of longitudinal data obtained
through irregular and infrequent subject visits and 2) the complex interplay of
pathological mechanisms across brain regions and disease stages, where
traditional models assume fixed mechanisms throughout disease progression. To
address these limitations, we propose a novel stage-aware Mixture of Experts
(MoE) framework that explicitly models how different contributing mechanisms
dominate at different disease stages through time-dependent expert
weighting.Data-wise, we utilize an iterative dual optimization method to
properly estimate the temporal position of individual observations,
constructing a co hort-level progression trajectory from irregular snapshots.
Model-wise, we enhance the spatial component with an inhomogeneous graph neural
diffusion model (IGND) that allows diffusivity to vary based on node states and
time, providing more flexible representations of brain networks. We also
introduce a localized neural reaction module to capture complex dynamics beyond
standard processes.The resulting IGND-MoE model dynamically integrates these
components across temporal states, offering a principled way to understand how
stage-specific pathological mechanisms contribute to progression. The
stage-wise weights yield novel clinical insights that align with literature,
suggesting that graph-related processes are more influential at early stages,
while other unknown physical processes become dominant later on.

</details>


### [454] [Differentiable Adaptive Kalman Filtering via Optimal Transport](https://arxiv.org/abs/2508.07037)
*Yangguang He,Wenhao Li,Minzhe Li,Juan Zhang,Xiangfeng Wang,Bo Jin*

Main category: cs.LG

TL;DR: OTAKNet是一种在线解决方案，用于解决学习型自适应卡尔曼滤波中的噪声统计漂移问题，通过最优传输实现无需地面真值标签或重新训练的在线适应。


<details>
  <summary>Details</summary>
Motivation: 在现实环境中，环境因素（如风况变化或电磁干扰）可能导致未观测到的噪声统计漂移，导致学习型方法性能下降。

Method: OTAKNet通过一步预测测量似然建立状态估计与漂移之间的联系，并利用最优传输的几何感知成本和稳定梯度实现在线适应。

Result: 在合成和真实NCLT数据集上，OTAKNet表现优于传统模型自适应卡尔曼滤波和离线学习型滤波，尤其在训练数据有限时。

Conclusion: OTAKNet为解决噪声统计漂移问题提供了一种有效的在线解决方案，无需依赖地面真值或重新训练。

Abstract: Learning-based filtering has demonstrated strong performance in non-linear
dynamical systems, particularly when the statistics of noise are unknown.
However, in real-world deployments, environmental factors, such as changing
wind conditions or electromagnetic interference, can induce unobserved
noise-statistics drift, leading to substantial degradation of learning-based
methods. To address this challenge, we propose OTAKNet, the first online
solution to noise-statistics drift within learning-based adaptive Kalman
filtering. Unlike existing learning-based methods that perform offline
fine-tuning using batch pointwise matching over entire trajectories, OTAKNet
establishes a connection between the state estimate and the drift via one-step
predictive measurement likelihood, and addresses it using optimal transport.
This leverages OT's geometry - aware cost and stable gradients to enable fully
online adaptation without ground truth labels or retraining. We compare OTAKNet
against classical model-based adaptive Kalman filtering and offline
learning-based filtering. The performance is demonstrated on both synthetic and
real-world NCLT datasets, particularly under limited training data.

</details>


### [455] [Membership and Memorization in LLM Knowledge Distillation](https://arxiv.org/abs/2508.07054)
*Ziqi Zhang,Ali Shahin Shamsabadi,Hanxiao Lu,Yifeng Cai,Hamed Haddadi*

Main category: cs.LG

TL;DR: 本文系统分析了六种大型语言模型（LLM）知识蒸馏（KD）技术中的隐私风险，发现所有KD方法均存在从教师模型向学生模型传递成员和记忆隐私风险的现象，但风险程度因技术而异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示知识蒸馏过程中教师模型隐私数据对学生模型的影响，填补了现有研究中对KD隐私风险的空白。

Method: 通过指令调优设置，覆盖七种NLP任务，使用三种教师模型家族（GPT-2、LLAMA-2、OPT）和不同规模的学生模型，系统评估六种KD技术的隐私风险。

Result: 所有KD方法均存在隐私风险，但程度不同；记忆与成员隐私风险之间存在显著分歧；不同模块的隐私风险差异显著。

Conclusion: 研究强调了KD技术中隐私风险的系统性差异，为未来隐私保护KD方法的设计提供了重要参考。

Abstract: Recent advances in Knowledge Distillation (KD) aim to mitigate the high
computational demands of Large Language Models (LLMs) by transferring knowledge
from a large ''teacher'' to a smaller ''student'' model. However, students may
inherit the teacher's privacy when the teacher is trained on private data. In
this work, we systematically characterize and investigate membership and
memorization privacy risks inherent in six LLM KD techniques. Using
instruction-tuning settings that span seven NLP tasks, together with three
teacher model families (GPT-2, LLAMA-2, and OPT), and various size student
models, we demonstrate that all existing LLM KD approaches carry membership and
memorization privacy risks from the teacher to its students. However, the
extent of privacy risks varies across different KD techniques. We
systematically analyse how key LLM KD components (KD objective functions,
student training data and NLP tasks) impact such privacy risks. We also
demonstrate a significant disagreement between memorization and membership
privacy risks of LLM KD techniques. Finally, we characterize per-block privacy
risk and demonstrate that the privacy risk varies across different blocks by a
large margin.

</details>


### [456] [Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation](https://arxiv.org/abs/2508.07075)
*Stanley Ngugi*

Main category: cs.LG

TL;DR: 论文提出了一种“先遗忘后学习”的策略，通过参数高效微调技术（$IA^3$）解决大语言模型（LLMs）动态知识更新的问题，显著提高了新知识的准确性和旧知识的遗忘率。


<details>
  <summary>Details</summary>
Motivation: LLMs在动态知识更新时面临新知识与旧知识冲突的问题，导致模型难以接受新知识或遗忘无关知识。

Method: 采用两阶段策略：1）定位编码冲突知识的内部组件；2）通过$IA^3$技术进行参数高效微调。

Result: 实验显示新知识准确率达98.50%，旧知识遗忘率达96.00%，显著优于直接微调方法。

Conclusion: 该方法实现了精确、局部化和安全的知识管理，是紧凑型LLMs的重要进展。

Abstract: Large Language Models (LLMs) struggle with dynamic knowledge updates,
especially when new information conflicts with deeply embedded facts. Such
conflicting factual edits often lead to two critical issues: resistance to
adopting the new fact and severe catastrophic forgetting of unrelated
knowledge. This paper introduces and evaluates a novel "unlearn-then-learn"
strategy for precise knowledge editing in LLMs, leveraging the
parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting
and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach
is powered by an initial circuit localization phase that identifies and targets
the specific internal components responsible for encoding the conflicting fact.
Through a rigorous experimental methodology on
microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically
informed two-stage approach achieves near-perfect accuracy (98.50%) for the
new, modulated fact while simultaneously effectively suppressing the original
conflicting fact (96.00% forget rate). Critically, our strategy exhibits
unprecedented localization (72.00% F_control accuracy), dramatically mitigating
catastrophic forgetting observed in direct fine-tuning approaches (which showed
as low as ~20% F_control accuracy), a direct benefit of our targeted
interpretability-guided intervention. Furthermore, qualitative analysis reveals
a nuanced mechanism of "soft forgetting," where original knowledge is
suppressed from default retrieval but remains latent and conditionally
accessible, enhancing model safety and control. These findings represent a
significant advancement towards precise, localized, and safe knowledge
management in compact LLMs.

</details>


### [457] [Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework](https://arxiv.org/abs/2508.07085)
*N Harshit,K Mounvik*

Main category: cs.LG

TL;DR: 提出了一种结合Transformer和Autoencoder的混合框架，用于在线检测概念漂移，并通过Trust Score方法提高检测的敏感性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 概念漂移（数据分布的逐渐或突然变化）会显著降低模型性能，现有检测方法多为被动且对早期检测不敏感。

Method: 使用Transformer和Autoencoder建模复杂时序动态，结合Trust Score方法（包括统计、重构、预测不确定性、规则违反和分类器误差趋势等信号）。

Result: 在时间序列航空乘客数据集上，该方法比基线方法更早、更敏感地检测到漂移，并减少了错误率和逻辑违反。

Conclusion: 开发了一个鲁棒的框架，可实时可靠地监测概念漂移。

Abstract: In applied machine learning, concept drift, which is either gradual or abrupt
changes in data distribution, can significantly reduce model performance.
Typical detection methods,such as statistical tests or reconstruction-based
models,are generally reactive and not very sensitive to early detection. Our
study proposes a hybrid framework consisting of Transformers and Autoencoders
to model complex temporal dynamics and provide online drift detection. We
create a distinct Trust Score methodology, which includes signals on (1)
statistical and reconstruction-based drift metrics, more specifically, PSI,
JSD, Transformer-AE error, (2) prediction uncertainty, (3) rules violations,
and (4) trend of classifier error aligned with the combined metrics defined by
the Trust Score. Using a time sequenced airline passenger data set with
synthetic drift, our proposed model allows for a better detection of drift
using as a whole and at different detection thresholds for both sensitivity and
interpretability compared to baseline methods and provides a strong pipeline
for drift detection in real time for applied machine learning. We evaluated
performance using a time-sequenced airline passenger dataset having the
gradually injected stimulus of drift in expectations,e.g. permuted ticket
prices in later batches, broken into 10 time segments [1].In the data, our
results support that the Transformation-Autoencoder detected drift earlier and
with more sensitivity than the autoencoders commonly used in the literature,
and provided improved modeling over more error rates and logical violations.
Therefore, a robust framework was developed to reliably monitor concept drift.

</details>


### [458] [Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria](https://arxiv.org/abs/2508.07102)
*Yang Cao,Yubin Chen,Zhao Song,Jiahao Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种名为Second-Order MeanFlow的新方法，通过引入平均加速度场扩展了MeanFlow框架，证明了其可行性和高效性，并提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 为了在生成建模中结合丰富的动力学特性和高效的采样效率，研究扩展了MeanFlow框架，引入高阶动力学。

Method: 通过理论分析，证明了平均加速度满足一致性条件，支持单步采样和可处理的损失函数，并通过电路复杂性分析表征了其表达能力。

Result: 证明了Second-Order MeanFlow可以在TC0类中实现，且注意力操作可在n^(2+o(1))时间内近似计算。

Conclusion: 研究为高阶流匹配模型奠定了理论基础，结合了丰富的动力学和高效的采样效率。

Abstract: Generative modelling has seen significant advances through simulation-free
paradigms such as Flow Matching, and in particular, the MeanFlow framework,
which replaces instantaneous velocity fields with average velocities to enable
efficient single-step sampling. In this work, we introduce a theoretical study
on Second-Order MeanFlow, a novel extension that incorporates average
acceleration fields into the MeanFlow objective. We first establish the
feasibility of our approach by proving that the average acceleration satisfies
a generalized consistency condition analogous to first-order MeanFlow, thereby
supporting stable, one-step sampling and tractable loss functions. We then
characterize its expressivity via circuit complexity analysis, showing that
under mild assumptions, the Second-Order MeanFlow sampling process can be
implemented by uniform threshold circuits within the $\mathsf{TC}^0$ class.
Finally, we derive provably efficient criteria for scalable implementation by
leveraging fast approximate attention computations: we prove that attention
operations within the Second-Order MeanFlow architecture can be approximated to
within $1/\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results
lay the theoretical foundation for high-order flow matching models that combine
rich dynamics with practical sampling efficiency.

</details>


### [459] [BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation](https://arxiv.org/abs/2508.07106)
*Yiran Huang,Amirhossein Nouranizadeh,Christine Ahrends,Mengjia Xu*

Main category: cs.LG

TL;DR: 提出BrainATCL框架，用于动态fMRI数据的自适应时间脑连接学习，支持功能链接预测和年龄估计。


<details>
  <summary>Details</summary>
Motivation: 传统GNN难以捕捉动态fMRI数据中的长时程依赖关系，需一种自适应方法。

Method: 基于新边添加速率动态调整回溯窗口，使用GINE-Mamba2骨干网络编码时空表示，并结合脑结构和功能属性。

Result: 在功能链接预测和年龄估计任务中表现优异，具有强泛化能力。

Conclusion: BrainATCL为动态脑连接建模提供了一种有效且通用的解决方案。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely
used to study human brain activity. fMRI signals in areas across the brain
transiently synchronise and desynchronise their activity in a highly structured
manner, even when an individual is at rest. These functional connectivity
dynamics may be related to behaviour and neuropsychiatric disease. To model
these dynamics, temporal brain connectivity representations are essential, as
they reflect evolving interactions between brain regions and provide insight
into transient neural states and network reconfigurations. However,
conventional graph neural networks (GNNs) often struggle to capture long-range
temporal dependencies in dynamic fMRI data. To address this challenge, we
propose BrainATCL, an unsupervised, nonparametric framework for adaptive
temporal brain connectivity learning, enabling functional link prediction and
age estimation. Our method dynamically adjusts the lookback window for each
snapshot based on the rate of newly added edges. Graph sequences are
subsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal
representations of dynamic functional connectivity in resting-state fMRI data
of 1,000 participants from the Human Connectome Project. To further improve
spatial modeling, we incorporate brain structure and function-informed edge
attributes, i.e., the left/right hemispheric identity and subnetwork membership
of brain regions, enabling the model to capture biologically meaningful
topological patterns. We evaluate our BrainATCL on two tasks: functional link
prediction and age estimation. The experimental results demonstrate superior
performance and strong generalization, including in cross-session prediction
scenarios.

</details>


### [460] [Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning](https://arxiv.org/abs/2508.07114)
*Atakan Azakli,Bernd Stelzer*

Main category: cs.LG

TL;DR: 提出一种新的机器学习方法，提高假设检验中参数预测的精度和判别力，并通过多实例学习（MIL）理论证明其优势。


<details>
  <summary>Details</summary>
Motivation: 解决现有分类器在极端情况下预测准确性不足的问题，并系统性降低预测误差。

Method: 采用多实例学习（MIL）方法，分析其在不同实例数量下的标度行为，并应用于标准模型有效场论（SMEFT）的Wilson系数约束。

Result: 在特定条件下，可能从数据集中提取理论最大Fisher信息。

Conclusion: MIL方法在提高预测精度和判别力方面具有潜力，尤其在复杂物理问题中表现突出。

Abstract: In this work, we propose a new machine learning (ML) methodology to obtain
more precise predictions for some parameters of interest in a given hypotheses
testing problem. Our proposed method also allows ML models to have more
discriminative power in cases where it is extremely challenging for
state-of-the-art classifiers to have any level of accurate predictions. This
method can also allow us to systematically decrease the error from ML models in
their predictions. In this paper, we provide a mathematical motivation why
Multiple Instance Learning (MIL) would have more predictive power over their
single-instance counterparts. We support our theoretical claims by analyzing
the behavior of the MIL models through their scaling behaviors with respect to
the number of instances on which the model makes predictions. As a concrete
application, we constrain Wilson coefficients of the Standard Model Effective
Field Theory (SMEFT) using kinematic information from subatomic particle
collision events at the Large Hadron Collider (LHC). We show that under certain
circumstances, it might be possible to extract the theoretical maximum Fisher
Information latent in a dataset.

</details>


### [461] [From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context](https://arxiv.org/abs/2508.07117)
*Peyman Baghershahi,Gregoire Fournier,Pranav Nyati,Sourav Medya*

Main category: cs.LG

TL;DR: LOGIC是一个轻量级框架，利用LLM为GNN预测生成可解释的解释，通过将GNN嵌入投影到LLM空间并结合混合提示，实现了高保真和稀疏性的平衡。


<details>
  <summary>Details</summary>
Motivation: GNN在结构化数据学习中表现强大，但缺乏可解释性，现有方法难以生成细粒度的解释，尤其是当节点属性包含丰富自然语言时。

Method: LOGIC将GNN节点嵌入投影到LLM嵌入空间，构建混合提示（软提示与图结构文本输入结合），使LLM能推理GNN内部表示并生成自然语言解释。

Result: 在四个真实TAG数据集上的实验表明，LOGIC在保真度和稀疏性之间取得平衡，并显著提升了人类中心指标（如洞察力）。

Conclusion: LOGIC为基于LLM的图学习可解释性开辟了新方向，通过将GNN内部表示与人类推理对齐。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over
structured data, including text-attributed graphs, which are common in domains
such as citation networks, social platforms, and knowledge graphs. GNNs are not
inherently interpretable and thus, many explanation methods have been proposed.
However, existing explanation methods often struggle to generate interpretable,
fine-grained rationales, especially when node attributes include rich natural
language. In this work, we introduce LOGIC, a lightweight, post-hoc framework
that uses large language models (LLMs) to generate faithful and interpretable
explanations for GNN predictions. LOGIC projects GNN node embeddings into the
LLM embedding space and constructs hybrid prompts that interleave soft prompts
with textual inputs from the graph structure. This enables the LLM to reason
about GNN internal representations and produce natural language explanations
along with concise explanation subgraphs. Our experiments across four
real-world TAG datasets demonstrate that LOGIC achieves a favorable trade-off
between fidelity and sparsity, while significantly improving human-centric
metrics such as insightfulness. LOGIC sets a new direction for LLM-based
explainability in graph learning by aligning GNN internals with human
reasoning.

</details>


### [462] [Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2508.07122)
*Zhihao Xue,Yun Zi,Nia Qi,Ming Gong,Yujun Zou*

Main category: cs.LG

TL;DR: 提出了一种基于时空图神经网络的性能预测算法，用于解决分布式后端系统中多级服务调用结构的性能波动预测问题。


<details>
  <summary>Details</summary>
Motivation: 分布式后端系统中多级服务调用结构的性能波动预测是一个挑战，需要一种能够同时建模时空特征的方法。

Method: 将系统状态抽象为图结构序列，结合服务节点运行时特征和调用关系，构建统一的时空建模框架，使用图卷积网络和高门控循环网络分别提取拓扑依赖和时间动态信息。

Result: 实验结果表明，该方法在MAE、RMSE和R2等关键指标上优于现有方法，并在不同负载和结构复杂度下表现出强鲁棒性。

Conclusion: 该方法在分布式后端系统性能管理任务中具有实际应用潜力。

Abstract: This paper proposes a spatiotemporal graph neural network-based performance
prediction algorithm to address the challenge of forecasting performance
fluctuations in distributed backend systems with multi-level service call
structures. The method abstracts system states at different time slices into a
sequence of graph structures. It integrates the runtime features of service
nodes with the invocation relationships among services to construct a unified
spatiotemporal modeling framework. The model first applies a graph
convolutional network to extract high-order dependency information from the
service topology. Then it uses a gated recurrent network to capture the dynamic
evolution of performance metrics over time. A time encoding mechanism is also
introduced to enhance the model's ability to represent non-stationary temporal
sequences. The architecture is trained in an end-to-end manner, optimizing the
multi-layer nested structure to achieve high-precision regression of future
service performance metrics. To validate the effectiveness of the proposed
method, a large-scale public cluster dataset is used. A series of
multi-dimensional experiments are designed, including variations in time
windows and concurrent load levels. These experiments comprehensively evaluate
the model's predictive performance and stability. The experimental results show
that the proposed model outperforms existing representative methods across key
metrics such as MAE, RMSE, and R2. It maintains strong robustness under varying
load intensities and structural complexities. These results demonstrate the
model's practical potential for backend service performance management tasks.

</details>


### [463] [Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning](https://arxiv.org/abs/2508.07126)
*Zhengran Ji,Boyuan Chen*

Main category: cs.LG

TL;DR: Pref-GUIDE框架将实时标量反馈转化为偏好数据，提升奖励模型学习效果，优于传统标量反馈方法。


<details>
  <summary>Details</summary>
Motivation: 在在线强化学习中，标量反馈存在噪声和不一致问题，限制了奖励模型的准确性和泛化能力。

Method: Pref-GUIDE通过短窗口行为比较和过滤模糊反馈（Individual）及用户群体共识偏好（Voting）改进奖励模型。

Result: 在三个挑战性环境中，Pref-GUIDE显著优于标量反馈基线，Voting版本甚至超过专家设计的密集奖励。

Conclusion: Pref-GUIDE通过结构化偏好和群体反馈，为在线强化学习中利用人类输入提供了可扩展且原则性的方法。

Abstract: Training reinforcement learning agents with human feedback is crucial when
task objectives are difficult to specify through dense reward functions. While
prior methods rely on offline trajectory comparisons to elicit human
preferences, such data is unavailable in online learning scenarios where agents
must adapt on the fly. Recent approaches address this by collecting real-time
scalar feedback to guide agent behavior and train reward models for continued
learning after human feedback becomes unavailable. However, scalar feedback is
often noisy and inconsistent, limiting the accuracy and generalization of
learned rewards. We propose Pref-GUIDE, a framework that transforms real-time
scalar feedback into preference-based data to improve reward model learning for
continual policy training. Pref-GUIDE Individual mitigates temporal
inconsistency by comparing agent behaviors within short windows and filtering
ambiguous feedback. Pref-GUIDE Voting further enhances robustness by
aggregating reward models across a population of users to form consensus
preferences. Across three challenging environments, Pref-GUIDE significantly
outperforms scalar-feedback baselines, with the voting variant exceeding even
expert-designed dense rewards. By reframing scalar feedback as structured
preferences with population feedback, Pref-GUIDE offers a scalable and
principled approach for harnessing human input in online reinforcement
learning.

</details>


### [464] [How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?](https://arxiv.org/abs/2508.07127)
*Niranjana Arun Menon,Iqra Farooq,Yulong Li,Sara Ahmed,Yutong Xie,Muhammad Awais,Imran Razzak*

Main category: cs.LG

TL;DR: 论文探讨了利用微调的大型语言模型（LLM）预测心血管疾病（CVD）及其相关SNP风险的潜力，通过分析基因组数据并采用链式思维推理任务，展示了LLM在早期检测和个性化医疗中的应用前景。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病预测因多因素病因和高维噪声数据而具有挑战性，LLM在生物序列分析中的成功应用激发了其在CVD预测中的潜力。

Method: 使用微调的LLM分析高通量基因组数据，通过链式思维推理任务生成疾病标签和临床推断，研究遗传模式与心脏疾病的关系。

Result: 研究发现LLM能够从基因组数据中学习潜在的生物学关系，为早期检测和风险评估提供了新方法。

Conclusion: LLM在心血管疾病预测和个性化医疗中具有重要潜力，有望推动心脏护理的进步。

Abstract: Cardiovascular disease (CVD) prediction remains a tremendous challenge due to
its multifactorial etiology and global burden of morbidity and mortality.
Despite the growing availability of genomic and electrophysiological data,
extracting biologically meaningful insights from such high-dimensional, noisy,
and sparsely annotated datasets remains a non-trivial task. Recently, LLMs has
been applied effectively to predict structural variations in biological
sequences. In this work, we explore the potential of fine-tuned LLMs to predict
cardiac diseases and SNPs potentially leading to CVD risk using genetic markers
derived from high-throughput genomic profiling. We investigate the effect of
genetic patterns associated with cardiac conditions and evaluate how LLMs can
learn latent biological relationships from structured and semi-structured
genomic data obtained by mapping genetic aspects that are inherited from the
family tree. By framing the problem as a Chain of Thought (CoT) reasoning task,
the models are prompted to generate disease labels and articulate informed
clinical deductions across diverse patient profiles and phenotypes. The
findings highlight the promise of LLMs in contributing to early detection, risk
assessment, and ultimately, the advancement of personalized medicine in cardiac
care.

</details>


### [465] [A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs](https://arxiv.org/abs/2508.07134)
*Lu Chenggang*

Main category: cs.LG

TL;DR: 提出了一种全局最优的半非负矩阵分解方法，通过正交分解避免局部极小值，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有半NMF算法多为迭代、非凸且易陷入局部极小值，需一种全局最优解法。

Method: 基于输入数据的散布矩阵正交分解，获得Frobenius范数下的全局最优解。

Result: 在合成数据和UCI Wine数据集上，重建误差优于现有NMF和半NMF方法。

Conclusion: 该方法提供了理论和实证优势，为矩阵分解优化提供了新视角。

Abstract: Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical
Nonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain
both positive and negative entries, making it suitable for decomposing data
with mixed signs. However, most existing semi-NMF algorithms are iterative,
non-convex, and prone to local minima. In this paper, we propose a novel method
that yields a globally optimal solution to the semi-NMF problem under the
Frobenius norm, through an orthogonal decomposition derived from the scatter
matrix of the input data. We rigorously prove that our solution attains the
global minimum of the reconstruction error. Furthermore, we demonstrate that
when the input matrix is nonnegative, our method often achieves lower
reconstruction error than standard NMF algorithms, although unfortunately the
basis matrix may not satisfy nonnegativity. In particular, in low-rank cases
such as rank 1 or 2, our solution reduces exactly to a nonnegative
factorization, recovering the NMF structure. We validate our approach through
experiments on both synthetic data and the UCI Wine dataset, showing that our
method consistently outperforms existing NMF and semi-NMF methods in terms of
reconstruction accuracy. These results confirm that our globally optimal,
non-iterative formulation offers both theoretical guarantees and empirical
advantages, providing a new perspective on matrix factorization in optimization
and data analysis.

</details>


### [466] [A Stable and Principled Loss Function for Direct Language Model Alignment](https://arxiv.org/abs/2508.07137)
*Yuandong Tan*

Main category: cs.LG

TL;DR: 论文提出了一种新的损失函数，解决了Direct Preference Optimization (DPO)中因无限最大化对数差导致的不稳定和奖励攻击问题。


<details>
  <summary>Details</summary>
Motivation: DPO的损失函数在理论上与其推导不一致，可能导致训练不稳定和奖励攻击，因此需要改进。

Method: 基于RLHF最优条件，提出了一种新的损失函数，目标是有限的、由底层奖励决定的对数差值。

Result: 新方法避免了DPO中的大梯度问题，提高了稳定性，并在实验中显著优于标准DPO基线。

Conclusion: 提出的损失函数更稳定且有效，在模型对齐中表现优异。

Abstract: The alignment of large language models (LLMs) with human preferences is
commonly achieved through Reinforcement Learning from Human Feedback (RLHF).
Direct Preference Optimization (DPO) simplified this paradigm by establishing a
direct mapping between the optimal policy and a reward function, eliminating
the need for an explicit reward model. However, we argue that the DPO loss
function is theoretically misaligned with its own derivation, as it promotes
the indefinite maximization of a logits difference, which can lead to training
instability and reward hacking. In this paper, we propose a novel loss function
derived directly from the RLHF optimality condition. Our proposed loss targets
a specific, finite value for the logits difference, which is dictated by the
underlying reward, rather than its maximization. We provide a theoretical
analysis, including a gradient-based comparison, to demonstrate that our method
avoids the large gradients that plague DPO when the probability of dispreferred
responses approaches zero. This inherent stability prevents reward hacking and
leads to more effective alignment. We validate our approach by fine-tuning a
Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO
baseline and achieving competitive performance against larger models like
Llama-3.1-8B.

</details>


### [467] [SGD Convergence under Stepsize Shrinkage in Low-Precision Training](https://arxiv.org/abs/2508.07142)
*Vincent-Daniel Yun*

Main category: cs.LG

TL;DR: 论文研究了低精度训练中梯度收缩对SGD收敛的影响，发现收缩会减慢收敛速度并增加误差。


<details>
  <summary>Details</summary>
Motivation: 低精度训练虽能降低计算和内存成本，但梯度量化的收缩和噪声会改变SGD的收敛行为，需要理论分析其影响。

Method: 通过梯度收缩模型分析SGD收敛，将量化噪声建模为零均值噪声，并研究收缩因子对有效步长的影响。

Result: 低精度SGD仍能收敛，但收敛速度因收缩因子减小而降低，且量化噪声增加了渐近误差。

Conclusion: 量化导致的梯度收缩会减慢训练速度，理论分析为低精度训练提供了收敛行为的解释。

Abstract: Low-precision training has become essential for reducing the computational
and memory costs of large-scale deep learning. However, quantization of
gradients introduces both magnitude shrinkage and additive noise, which can
alter the convergence behavior of stochastic gradient descent (SGD). In this
work, we study the convergence of SGD under a gradient shrinkage model, where
each stochastic gradient is scaled by a factor $q_k \in (0,1]$ and perturbed by
zero-mean quantization noise. We show that this shrinkage is equivalent to
replacing the nominal stepsize $\mu_k$ with an effective stepsize $\mu_k q_k$,
which slows convergence when $q_{\min} < 1$. Under standard smoothness and
bounded-variance assumptions, we prove that low-precision SGD still converges,
but at a reduced rate determined by $q_{\min}$, and with an increased
asymptotic error floor due to quantization noise. We theoretically analyze how
reduced numerical precision slows down training by modeling it as gradient
shrinkage in the standard SGD convergence framework.

</details>


### [468] [What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains](https://arxiv.org/abs/2508.07208)
*Chanakya Ekbote,Marco Bondaschi,Nived Rajaraman,Jason D. Lee,Michael Gastpar,Ashok Vardhan Makkuva,Paul Pu Liang*

Main category: cs.LG

TL;DR: 两层的单头Transformer可以表示任何k阶马尔可夫过程，填补了深度与马尔可夫阶数关系的理论空白。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer的深度与其在上下文学习（ICL）中表示高阶马尔可夫过程的能力之间的关系。

Method: 理论证明两层的单头Transformer可以表示任何条件k-gram，并通过简化的一阶马尔可夫链分析学习动态。

Result: 两层的单头Transformer能够高效表示高阶马尔可夫过程，展示了浅层架构在结构化序列建模中的强大ICL能力。

Conclusion: 研究深化了对Transformer基于ICL的理解，表明浅层架构在结构化任务中也能表现出强大的ICL能力。

Abstract: In-context learning (ICL) is a hallmark capability of transformers, through
which trained models learn to adapt to new tasks by leveraging information from
the input context. Prior work has shown that ICL emerges in transformers due to
the presence of special circuits called induction heads. Given the equivalence
between induction heads and conditional k-grams, a recent line of work modeling
sequential inputs as Markov processes has revealed the fundamental impact of
model depth on its ICL capabilities: while a two-layer transformer can
efficiently represent a conditional 1-gram model, its single-layer counterpart
cannot solve the task unless it is exponentially large. However, for higher
order Markov sources, the best known constructions require at least three
layers (each with a single attention head) - leaving open the question: can a
two-layer single-head transformer represent any kth-order Markov process? In
this paper, we precisely address this and theoretically show that a two-layer
transformer with one head per layer can indeed represent any conditional
k-gram. Thus, our result provides the tightest known characterization of the
interplay between transformer depth and Markov order for ICL. Building on this,
we further analyze the learning dynamics of our two-layer construction,
focusing on a simplified variant for first-order Markov chains, illustrating
how effective in-context representations emerge during training. Together,
these results deepen our current understanding of transformer-based ICL and
illustrate how even shallow architectures can surprisingly exhibit strong ICL
capabilities on structured sequence modeling tasks.

</details>


### [469] [Neural Bridge Processes](https://arxiv.org/abs/2508.07220)
*Jian Xu,Yican Liu,Qibin Zhao,John Paisley,Delu Zeng*

Main category: cs.LG

TL;DR: 提出了一种名为Neural Bridge Processes (NBPs)的新方法，用于建模随机函数，通过动态锚点增强扩散轨迹的输入耦合和终点一致性。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如高斯过程和神经过程）在处理大规模数据或复杂多模态分布时存在局限性，而神经扩散过程在输入耦合和终点语义匹配上表现不佳。

Method: NBP通过重新设计前向核，使其显式依赖于输入x，从而约束扩散轨迹严格终止于监督目标，提供更强的梯度信号和终点一致性。

Result: 在合成数据、EEG信号回归和图像回归任务中，NBP显著优于基线方法。

Conclusion: NBP通过DDPM风格的桥采样，提升了结构化预测任务的性能和理论一致性。

Abstract: Learning stochastic functions from partially observed context-target pairs is
a fundamental problem in probabilistic modeling. Traditional models like
Gaussian Processes (GPs) face scalability issues with large datasets and assume
Gaussianity, limiting their applicability. While Neural Processes (NPs) offer
more flexibility, they struggle with capturing complex, multi-modal target
distributions. Neural Diffusion Processes (NDPs) enhance expressivity through a
learned diffusion process but rely solely on conditional signals in the
denoising network, resulting in weak input coupling from an unconditional
forward process and semantic mismatch at the diffusion endpoint. In this work,
we propose Neural Bridge Processes (NBPs), a novel method for modeling
stochastic functions where inputs x act as dynamic anchors for the entire
diffusion trajectory. By reformulating the forward kernel to explicitly depend
on x, NBP enforces a constrained path that strictly terminates at the
supervised target. This approach not only provides stronger gradient signals
but also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG
signal regression and image regression tasks, achieving substantial
improvements over baselines. These results underscore the effectiveness of
DDPM-style bridge sampling in enhancing both performance and theoretical
consistency for structured prediction tasks.

</details>


### [470] [EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning](https://arxiv.org/abs/2508.07224)
*Ananda Prakash Verma*

Main category: cs.LG

TL;DR: EDGE是一个通用的、基于误解的自适应学习框架，包含评估、诊断、生成和练习四个阶段，结合了心理测量学、认知诊断和对比项生成技术。


<details>
  <summary>Details</summary>
Motivation: 旨在通过动态评估和针对性干预，高效纠正学习者的误解，提升学习效果。

Method: 采用IRT/Bayesian模型进行能力评估，通过对比项生成和索引调度策略优化学习路径。

Result: 提出了EdgeScore指标，证明了其单调性和连续性，并设计了近似最优的调度策略。

Conclusion: EDGE框架在理论上验证了其有效性，未来需进一步实证研究。

Abstract: We present EDGE, a general-purpose, misconception-aware adaptive learning
framework composed of four stages: Evaluate (ability and state estimation),
Diagnose (posterior infer-ence of misconceptions), Generate (counterfactual
item synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies
psychometrics (IRT/Bayesian state space models), cog-nitive diagnostics
(misconception discovery from distractor patterns and response latencies),
contrastive item generation (minimal perturbations that invalidate learner
shortcuts while pre-serving psychometric validity), and principled scheduling
(a restless bandit approximation to spaced retrieval). We formalize a composite
readiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity,
and derive an index policy that is near-optimal under mild assumptions on
forgetting and learning gains. We further establish conditions under which
counterfactual items provably reduce the posterior probability of a targeted
misconception faster than standard practice. The paper focuses on theory and
implementable pseudocode; empirical study is left to future work.

</details>


### [471] [Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation](https://arxiv.org/abs/2508.07243)
*Chu Zhao,Eneng Yang,Yizhou Dang,Jianzhe Zhao,Guibing Guo,Xingwei Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为CNSDiff的新方法，通过扩散过程合成负样本，避免预定义候选池中的偏差，并引入因果正则化以提升推荐系统的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有启发式负采样方法可能因环境混杂因素（如曝光或流行度偏差）引入虚假硬负样本，损害模型的泛化能力。

Method: CNSDiff通过条件扩散过程在潜在空间合成负样本，避免候选池偏差，并加入因果正则化减少混杂因素的影响。

Result: 在四种分布偏移场景下，CNSDiff平均性能提升13.96%，验证了其在OOD推荐任务中的有效性和鲁棒性。

Conclusion: CNSDiff通过避免偏差和引入因果正则化，显著提升了推荐系统的泛化性能。

Abstract: Heuristic negative sampling enhances recommendation performance by selecting
negative samples of varying hardness levels from predefined candidate pools to
guide the model toward learning more accurate decision boundaries. However, our
empirical and theoretical analyses reveal that unobserved environmental
confounders (e.g., exposure or popularity biases) in candidate pools may cause
heuristic sampling methods to introduce false hard negatives (FHNS). These
misleading samples can encourage the model to learn spurious correlations
induced by such confounders, ultimately compromising its generalization ability
under distribution shifts. To address this issue, we propose a novel method
named Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing
negative samples in the latent space via a conditional diffusion process,
CNSDiff avoids the bias introduced by predefined candidate pools and thus
reduces the likelihood of generating FHNS. Moreover, it incorporates a causal
regularization term to explicitly mitigate the influence of environmental
confounders during the negative sampling process, leading to robust negatives
that promote out-of-distribution (OOD) generalization. Comprehensive
experiments under four representative distribution shift scenarios demonstrate
that CNSDiff achieves an average improvement of 13.96% across all evaluation
metrics compared to state-of-the-art baselines, verifying its effectiveness and
robustness in OOD recommendation tasks.

</details>


### [472] [Policy Newton methods for Distortion Riskmetrics](https://arxiv.org/abs/2508.07249)
*Soumen Pachal,Mizhaan Prajit Maniyar,Prashanth L. A*

Main category: cs.LG

TL;DR: 论文提出了一种风险敏感的强化学习方法，通过最大化失真风险度量（DRM）来优化策略，并证明了算法的二阶收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注风险中性目标或仅达到一阶收敛，本文旨在填补风险敏感目标二阶收敛的理论空白。

Method: 使用似然比方法推导DRM目标的海森矩阵，提出基于样本轨迹的海森估计器，并设计立方正则化的牛顿策略算法。

Result: 算法收敛到DRM目标的二阶稳定点（ε-SOSP），样本复杂度为O(ε^-3.5)，实验验证了理论结果。

Conclusion: 本文首次实现了风险敏感目标的二阶收敛，为相关研究提供了新思路。

Abstract: We consider the problem of risk-sensitive control in a reinforcement learning
(RL) framework. In particular, we aim to find a risk-optimal policy by
maximizing the distortion riskmetric (DRM) of the discounted reward in a finite
horizon Markov decision process (MDP). DRMs are a rich class of risk measures
that include several well-known risk measures as special cases. We derive a
policy Hessian theorem for the DRM objective using the likelihood ratio method.
Using this result, we propose a natural DRM Hessian estimator from sample
trajectories of the underlying MDP. Next, we present a cubic-regularized policy
Newton algorithm for solving this problem in an on-policy RL setting using
estimates of the DRM gradient and Hessian. Our proposed algorithm is shown to
converge to an $\epsilon$-second-order stationary point ($\epsilon$-SOSP) of
the DRM objective, and this guarantee ensures the escaping of saddle points.
The sample complexity of our algorithms to find an $ \epsilon$-SOSP is
$\mathcal{O}(\epsilon^{-3.5})$. Our experiments validate the theoretical
findings. To the best of our knowledge, our is the first work to present
convergence to an $\epsilon$-SOSP of a risk-sensitive objective, while existing
works in the literature have either shown convergence to a first-order
stationary point of a risk-sensitive objective, or a SOSP of a risk-neutral
one.

</details>


### [473] [PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets](https://arxiv.org/abs/2508.07253)
*Bartlomiej Chybowski,Shima Abdullateef,Hollan Haule,Alfredo Gonzalez-Sulser,Javier Escudero*

Main category: cs.LG

TL;DR: 论文提出了一种开源机器学习框架，用于跨不同临床数据集的鲁棒性癫痫发作检测，通过自动预处理和多数投票机制提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作检测依赖耗时的手动EEG分析，现有机器学习方法因数据集特定优化而受限，缺乏现实适用性和可重复性。

Method: 框架包含自动预处理管道和多数投票机制，训练和评估模型在两个公开EEG数据集上，测试跨数据集泛化能力。

Result: 模型在数据集内表现优异（AUC 0.904和0.864），跨数据集泛化能力强（AUC 0.615和0.762），后处理进一步提升性能。

Conclusion: 该框架为临床可行的、数据集无关的癫痫检测系统奠定了基础，有望广泛采用并加速临床整合。

Abstract: Reliable seizure detection is critical for diagnosing and managing epilepsy,
yet clinical workflows remain dependent on time-consuming manual EEG
interpretation. While machine learning has shown promise, existing approaches
often rely on dataset-specific optimisations, limiting their real-world
applicability and reproducibility. Here, we introduce an innovative,
open-source machine-learning framework that enables robust and generalisable
seizure detection across varied clinical datasets. We evaluate our approach on
two publicly available EEG datasets that differ in patient populations and
electrode configurations. To enhance robustness, the framework incorporates an
automated pre-processing pipeline to standardise data and a majority voting
mechanism, in which multiple models independently assess each second of EEG
before reaching a final decision. We train, tune, and evaluate models within
each dataset, assessing their cross-dataset transferability. Our models achieve
high within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and
0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets
despite differences in EEG setups and populations (AUC 0.615+/-0.039 for models
trained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case)
without any post-processing. Furthermore, a mild post-processing improved the
within-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset
results to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the
potential of, and essential considerations for, deploying our framework in
diverse clinical settings. By making our methodology fully reproducible, we
provide a foundation for advancing clinically viable, dataset-agnostic seizure
detection systems. This approach has the potential for widespread adoption,
complementing rather than replacing expert interpretation, and accelerating
clinical integration.

</details>


### [474] [Revisiting Data Attribution for Influence Functions](https://arxiv.org/abs/2508.07297)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.LG

TL;DR: 本文综述了影响函数在深度学习中的数据归因能力，包括理论基础、高效逆Hessian-向量积估计算法，以及其在数据归因和错误标签检测中的应用。


<details>
  <summary>Details</summary>
Motivation: 理解训练数据如何影响模型预测对机器学习可解释性、数据调试和模型问责至关重要。影响函数提供了一种高效的一阶近似方法。

Method: 通过影响函数估计数据点对模型参数和预测的边际影响，无需昂贵重新训练。讨论了逆Hessian-向量积的高效估计算法。

Result: 影响函数在数据归因和错误标签检测中表现出有效性。

Conclusion: 影响函数在大规模深度学习场景中具有巨大潜力，但仍需解决当前挑战。

Abstract: The goal of data attribution is to trace the model's predictions through the
learning algorithm and back to its training data. thereby identifying the most
influential training samples and understanding how the model's behavior leads
to particular predictions. Understanding how individual training examples
influence a model's predictions is fundamental for machine learning
interpretability, data debugging, and model accountability. Influence
functions, originating from robust statistics, offer an efficient, first-order
approximation to estimate the impact of marginally upweighting or removing a
data point on a model's learned parameters and its subsequent predictions,
without the need for expensive retraining. This paper comprehensively reviews
the data attribution capability of influence functions in deep learning. We
discuss their theoretical foundations, recent algorithmic advances for
efficient inverse-Hessian-vector product estimation, and evaluate their
effectiveness for data attribution and mislabel detection. Finally,
highlighting current challenges and promising directions for unleashing the
huge potential of influence functions in large-scale, real-world deep learning
scenarios.

</details>


### [475] [When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective](https://arxiv.org/abs/2508.07299)
*Lin-Han Jia,Si-Yu Han,Wen-Chao Hu,Jie-Jing Shao,Wen-Da Wei,Zhi Zhou,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: 论文提出了一种理论框架，将神经符号学习（Nesy）与半/自监督学习（SSL）统一起来，并通过理论分析和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前半/自监督学习中的无监督任务选择缺乏理论依据，论文旨在通过扩展Nesy理论到不可靠知识（假设）场景，为SSL任务选择提供理论支持。

Method: 通过理论分析确定影响任务性能的三个因素（知识的可学习性、可靠性和完备性），并提出操作化方案，预测无监督任务的有效性。

Result: 实验验证了预测性能与实际性能的高度相关性，证明了理论和评估方法的有效性。

Conclusion: 论文为无监督任务选择提供了理论依据，改变了当前启发式选择的现状，具有实际应用价值。

Abstract: Neuro-symbolic (Nesy) learning improves the target task performance of models
by enabling them to satisfy knowledge, while semi/self-supervised learning
(SSL) improves the target task performance by designing unsupervised pretext
tasks for unlabeled data to make models satisfy corresponding assumptions. We
extend the Nesy theory based on reliable knowledge to the scenario of
unreliable knowledge (i.e., assumptions), thereby unifying the theoretical
frameworks of SSL and Nesy. Through rigorous theoretical analysis, we
demonstrate that, in theory, the impact of pretext tasks on target performance
hinges on three factors: knowledge learnability with respect to the model,
knowledge reliability with respect to the data, and knowledge completeness with
respect to the target. We further propose schemes to operationalize these
theoretical metrics, and thereby develop a method that can predict the
effectiveness of pretext tasks in advance. This will change the current status
quo in practical applications, where the selections of unsupervised tasks are
heuristic-based rather than theory-based, and it is difficult to evaluate the
rationality of unsupervised pretext task selection before testing the model on
the target task. In experiments, we verify a high correlation between the
predicted performance-estimated using minimal data-and the actual performance
achieved after large-scale semi-supervised or self-supervised learning, thus
confirming the validity of the theory and the effectiveness of the evaluation
method.

</details>


### [476] [Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative](https://arxiv.org/abs/2508.07329)
*Tuo Zhang,Ning Li,Xin Yuan,Wenchao Xu,Quan Chen,Song Guo,Haijun Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于Hessian感知量化（HAQ）和CPU-GPU协同推理的高效MoE边缘部署方案，解决了量化精度和内存限制下的推理性能问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在资源受限的边缘设备上部署时，量化精度和内存效率是主要挑战。MoE架构的稀疏激活特性加剧了这些问题。

Method: 采用Hessian感知量化（HAQ）实现8位量化，并结合CPU-GPU协同推理机制优化专家模块的调度和内存使用。

Result: 在OPT系列和Mixtral 8*7B等模型上验证，量化模型推理精度接近全精度模型，GPU内存减少60%，推理延迟显著降低。

Conclusion: 该方法有效解决了MoE架构在边缘设备部署中的量化精度和内存效率问题，为高效部署提供了可行方案。

Abstract: With the breakthrough progress of large language models (LLMs) in natural
language processing and multimodal tasks, efficiently deploying them on
resource-constrained edge devices has become a critical challenge. The Mixture
of Experts (MoE) architecture enhances model capacity through sparse
activation, but faces two major difficulties in practical deployment: (1) The
presence of numerous outliers in activation distributions leads to severe
degradation in quantization accuracy for both activations and weights,
significantly impairing inference performance; (2) Under limited memory,
efficient offloading and collaborative inference of expert modules struggle to
balance latency and throughput. To address these issues, this paper proposes an
efficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ)
and CPU-GPU collaborative inference. First, by introducing smoothed Hessian
matrix quantization, we achieve joint 8-bit quantization of activations and
weights, which significantly alleviates the accuracy loss caused by outliers
while ensuring efficient implementation on mainstream hardware. Second, we
design an expert-level collaborative offloading and inference mechanism, which,
combined with expert activation path statistics, enables efficient deployment
and scheduling of expert modules between CPU and GPU, greatly reducing memory
footprint and inference latency. Extensive experiments validate the
effectiveness of our method on mainstream large models such as the OPT series
and Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of
the low-bit quantized model approaches that of the full-precision model, while
GPU memory usage is reduced by about 60%, and inference latency is
significantly improved.

</details>


### [477] [Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants](https://arxiv.org/abs/2508.07333)
*Yuhao Liu,Rui Hu,Yu Chen,Longbo Huang*

Main category: cs.LG

TL;DR: 论文研究了随机插值在生成模型中的应用，重点分析了两种数值积分器（欧拉法和Heun法）的有限时间收敛性，并提出了优化计算效率的方案。


<details>
  <summary>Details</summary>
Motivation: 随机插值在数据分布转换中具有潜力，但其数值实现的有限时间收敛性尚未充分研究。

Method: 通过分析随机插值生成的ODE，推导了欧拉法和Heun法的有限时间误差界限，并优化了迭代复杂度。

Result: 理论分析得到了数值实验验证，展示了误差界限和计算效率的提升。

Conclusion: 研究为随机插值的数值实现提供了理论支持，并提出了优化方案。

Abstract: Stochastic interpolants offer a robust framework for continuously
transforming samples between arbitrary data distributions, holding significant
promise for generative modeling. Despite their potential, rigorous finite-time
convergence guarantees for practical numerical schemes remain largely
unexplored. In this work, we address the finite-time convergence analysis of
numerical implementations for ordinary differential equations (ODEs) derived
from stochastic interpolants. Specifically, we establish novel finite-time
error bounds in total variation distance for two widely used numerical
integrators: the first-order forward Euler method and the second-order Heun's
method. Furthermore, our analysis on the iteration complexity of specific
stochastic interpolant constructions provides optimized schedules to enhance
computational efficiency. Our theoretical findings are corroborated by
numerical experiments, which validate the derived error bounds and complexity
analyses.

</details>


### [478] [ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis](https://arxiv.org/abs/2508.07345)
*Samiha Afaf Neha,Abir Ahammed Bhuiyan,Md. Ishrak Khan*

Main category: cs.LG

TL;DR: 论文提出了一种名为ProteoKnight的图像编码方法，用于噬菌体病毒蛋白（PVP）的预测，结合预训练卷积神经网络（CNN）和蒙特卡洛Dropout（MCD）评估预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在空间信息处理上存在局限，需要更有效的序列编码技术以提高PVP分类的准确性。

Method: ProteoKnight基于DNA-Walk算法改进，通过像素颜色和步长调整捕捉蛋白质特征，使用预训练CNN进行分类，并通过MCD评估不确定性。

Result: 在二元分类中达到90.8%的准确率，但多分类表现一般；不确定性分析揭示了预测置信度受蛋白质类别和序列长度影响。

Conclusion: ProteoKnight克服了FCGR的空间信息丢失问题，提供了高准确性和鲁棒性的PVP预测，并能识别低置信度预测。

Abstract: \textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is
essential for genomic studies due to their crucial role as structural elements
in bacteriophages. Computational tools, particularly machine learning, have
emerged for annotating phage protein sequences from high-throughput sequencing.
However, effective annotation requires specialized sequence encodings. Our
paper introduces ProteoKnight, a new image-based encoding method that addresses
spatial constraints in existing techniques, yielding competitive performance in
PVP classification using pre-trained convolutional neural networks.
Additionally, our study evaluates prediction uncertainty in binary PVP
classification through Monte Carlo Dropout (MCD). \textbf{Methods:}
ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences,
incorporating pixel colors and adjusting walk distances to capture intricate
protein features. Encoded sequences were classified using multiple pre-trained
CNNs. Variance and entropy measures assessed prediction uncertainty across
proteins of various classes and lengths. \textbf{Results:} Our experiments
achieved 90.8% accuracy in binary classification, comparable to
state-of-the-art methods. Multi-class classification accuracy remains
suboptimal. Our uncertainty analysis unveils variability in prediction
confidence influenced by protein class and sequence length.
\textbf{Conclusions:} Our study surpasses frequency chaos game representation
(FCGR) by introducing novel image encoding that mitigates spatial information
loss limitations. Our classification technique yields accurate and robust PVP
predictions while identifying low-confidence predictions.

</details>


### [479] [Intrinsic training dynamics of deep neural networks](https://arxiv.org/abs/2508.07370)
*Sibylle Marcotte,Gabriel Peyré,Rémi Gribonval*

Main category: cs.LG

TL;DR: 论文研究了高维参数空间中梯度流是否能简化为低维结构（隐式偏置），并提出了基于核包含的简单判据。


<details>
  <summary>Details</summary>
Motivation: 理解深度学习中的梯度流是否可以通过低维结构捕捉，从而简化高维参数空间的分析。

Method: 通过研究高维变量θ的梯度流是否能转化为低维变量z=ϕ(θ)的梯度流，提出基于核包含的判据，并应用于ReLU网络和线性网络。

Result: 证明了对于任意初始化的ReLU网络，梯度流可重写为仅依赖z和初始化的低维动态；对线性网络，放宽平衡初始化的条件，发现某些配置下这是唯一满足低维动态的初始化。

Conclusion: 论文为高维梯度流的低维简化提供了理论支持，并扩展了平衡初始化的适用范围。

Abstract: A fundamental challenge in the theory of deep learning is to understand
whether gradient-based training in high-dimensional parameter spaces can be
captured by simpler, lower-dimensional structures, leading to so-called
implicit bias. As a stepping stone, we study when a gradient flow on a
high-dimensional variable $\theta$ implies an intrinsic gradient flow on a
lower-dimensional variable $z = \phi(\theta)$, for an architecture-related
function $\phi$. We express a so-called intrinsic dynamic property and show how
it is related to the study of conservation laws associated with the
factorization $\phi$. This leads to a simple criterion based on the inclusion
of kernels of linear maps which yields a necessary condition for this property
to hold. We then apply our theory to general ReLU networks of arbitrary depth
and show that, for any initialization, it is possible to rewrite the flow as an
intrinsic dynamic in a lower dimension that depends only on $z$ and the
initialization, when $\phi$ is the so-called path-lifting. In the case of
linear networks with $\phi$ the product of weight matrices, so-called balanced
initializations are also known to enable such a dimensionality reduction; we
generalize this result to a broader class of {\em relaxed balanced}
initializations, showing that, in certain configurations, these are the
\emph{only} initializations that ensure the intrinsic dynamic property.
Finally, for the linear neural ODE associated with the limit of infinitely deep
linear networks, with relaxed balanced initialization, we explicitly express
the corresponding intrinsic dynamics.

</details>


### [480] [Tight Bounds for Schrödinger Potential Estimation in Unpaired Image-to-Image Translation Problems](https://arxiv.org/abs/2508.07392)
*Nikita Puchkin,Denis Suchkov,Alexey Naumov,Denis Belomestny*

Main category: cs.LG

TL;DR: 论文提出了一种基于Schrödinger桥和随机最优控制理论的生成建模和无配对图像转换方法，通过Ornstein-Uhlenbeck过程估计Schrödinger势，并推导了经验风险最小化器的泛化能力界限。


<details>
  <summary>Details</summary>
Motivation: 研究如何仅通过初始和最终分布的独立同分布样本，实现生成建模和无配对图像转换的最优变换。

Method: 采用随机最优控制方法，选择Ornstein-Uhlenbeck过程作为参考，估计Schrödinger势，并通过Kullback-Leibler散度定义风险函数。

Result: 在包括高斯混合的Schrödinger势类中，推导了经验风险最小化器的紧致泛化界限，并在有利场景下接近快速收敛速率。

Conclusion: 通过数值实验验证了方法的有效性，展示了其在生成建模和图像转换中的潜力。

Abstract: Modern methods of generative modelling and unpaired image-to-image
translation based on Schr\"odinger bridges and stochastic optimal control
theory aim to transform an initial density to a target one in an optimal way.
In the present paper, we assume that we only have access to i.i.d. samples from
initial and final distributions. This makes our setup suitable for both
generative modelling and unpaired image-to-image translation. Relying on the
stochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as
the reference one and estimate the corresponding Schr\"odinger potential.
Introducing a risk function as the Kullback-Leibler divergence between
couplings, we derive tight bounds on generalization ability of an empirical
risk minimizer in a class of Schr\"odinger potentials including Gaussian
mixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we
almost achieve fast rates of convergence up to some logarithmic factors in
favourable scenarios. We also illustrate performance of the suggested approach
with numerical experiments.

</details>


### [481] [Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs](https://arxiv.org/abs/2508.07395)
*Behnoush Khavari,Mehran Shakerinava,Jayesh Khullar,Jerry Huang,François Rivest,Siamak Ravanbakhsh,Sarath Chandar*

Main category: cs.LG

TL;DR: 论文探讨了LRNN模型（如S4D、Mamba和DeltaNet）因时间不变或受限特征值范围导致状态跟踪能力不足的问题，提出输入依赖的转移矩阵可提升性能，但多层组合仍无法解决简单任务（如奇偶校验）。


<details>
  <summary>Details</summary>
Motivation: 解决LRNN模型状态跟踪能力不足的问题，探索输入依赖转移矩阵和多层组合的效果。

Method: 研究对角转移矩阵的高效SSM组合，分析其在奇偶校验任务中的表现。

Result: 多层组合仍无法解决奇偶校验任务，表明需要输入依赖和负特征值的递归层。

Conclusion: 递归层需同时具备输入依赖性和负特征值才能有效解决状态跟踪任务。

Abstract: Recent work has shown that LRNN models such as S4D, Mamba, and DeltaNet lack
state-tracking capability due to either time-invariant transition matrices or
restricted eigenvalue ranges. To address this, input-dependent transition
matrices, particularly those that are complex or non-triangular, have been
proposed to enhance SSM performance on such tasks. While existing theorems
demonstrate that both input-independent and non-negative SSMs are incapable of
solving simple state-tracking tasks, such as parity, regardless of depth, they
do not explore whether combining these two types in a multilayer SSM could
help. We investigate this question for efficient SSMs with diagonal transition
matrices and show that such combinations still fail to solve parity. This
implies that a recurrence layer must both be input-dependent and include
negative eigenvalues. Our experiments support this conclusion by analyzing an
SSM model that combines S4D and Mamba layers.

</details>


### [482] [Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors](https://arxiv.org/abs/2508.07400)
*Mohamad Louai Shehab,Alperen Tercan,Necmiye Ozay*

Main category: cs.LG

TL;DR: 论文研究了从最优策略或最大熵强化学习演示中恢复时变奖励函数的问题，提出了两种奖励先验假设，并分别转化为稀疏化和秩最小化问题，给出了高效算法。


<details>
  <summary>Details</summary>
Motivation: 奖励函数恢复问题在缺乏额外假设时高度不适定，但实际应用中奖励通常具有稀疏性或可表示为少量特征的线性组合。

Method: 1）将奖励稀疏性假设转化为带线性约束的稀疏化问题，提出多项式时间精确算法；2）将奖励表示为最少特征的问题转化为秩最小化问题，使用凸松弛方法。

Result: 提出的优化算法能高效恢复奖励函数，并通过示例验证了恢复的准确性和泛化性。

Conclusion: 论文提出的方法在奖励函数恢复问题上具有高效性和实用性，适用于实际应用场景。

Abstract: In this paper, we consider the problem of recovering time-varying reward
functions from either optimal policies or demonstrations coming from a max
entropy reinforcement learning problem. This problem is highly ill-posed
without additional assumptions on the underlying rewards. However, in many
applications, the rewards are indeed parsimonious, and some prior information
is available. We consider two such priors on the rewards: 1) rewards are mostly
constant and they change infrequently, 2) rewards can be represented by a
linear combination of a small number of feature functions. We first show that
the reward identification problem with the former prior can be recast as a
sparsification problem subject to linear constraints. Moreover, we give a
polynomial-time algorithm that solves this sparsification problem exactly.
Then, we show that identifying rewards representable with the minimum number of
features can be recast as a rank minimization problem subject to linear
constraints, for which convex relaxations of rank can be invoked. In both
cases, these observations lead to efficient optimization-based reward
identification algorithms. Several examples are given to demonstrate the
accuracy of the recovered rewards as well as their generalizability.

</details>


### [483] [Lightning Prediction under Uncertainty: DeepLight with Hazy Loss](https://arxiv.org/abs/2508.07428)
*Md Sultanul Arifin,Abu Nowshed Sakib,Yeasir Rayhan,Tanzima Hashem*

Main category: cs.LG

TL;DR: DeepLight是一种新型深度学习架构，用于预测闪电发生，通过多源气象数据和双编码器架构提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 闪电对人和经济造成重大风险，现有模型在动态空间上下文捕捉和不确定性处理上表现不足，且依赖昂贵的数值天气预报系统。

Method: DeepLight利用雷达反射率、云属性和历史闪电数据，采用双编码器架构和多分支卷积技术，动态捕捉空间相关性，并使用Hazy Loss函数处理时空不确定性。

Result: 实验表明，DeepLight的公平威胁评分（ETS）比现有方法提高了18%-30%。

Conclusion: DeepLight为闪电预测提供了更鲁棒的解决方案。

Abstract: Lightning, a common feature of severe meteorological conditions, poses
significant risks, from direct human injuries to substantial economic losses.
These risks are further exacerbated by climate change. Early and accurate
prediction of lightning would enable preventive measures to safeguard people,
protect property, and minimize economic losses. In this paper, we present
DeepLight, a novel deep learning architecture for predicting lightning
occurrences. Existing prediction models face several critical limitations: they
often struggle to capture the dynamic spatial context and inherent uncertainty
of lightning events, underutilize key observational data, such as radar
reflectivity and cloud properties, and rely heavily on Numerical Weather
Prediction (NWP) systems, which are both computationally expensive and highly
sensitive to parameter settings. To overcome these challenges, DeepLight
leverages multi-source meteorological data, including radar reflectivity, cloud
properties, and historical lightning occurrences through a dual-encoder
architecture. By employing multi-branch convolution techniques, it dynamically
captures spatial correlations across varying extents. Furthermore, its novel
Hazy Loss function explicitly addresses the spatio-temporal uncertainty of
lightning by penalizing deviations based on proximity to true events, enabling
the model to better learn patterns amidst randomness. Extensive experiments
show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over
state-of-the-art methods, establishing it as a robust solution for lightning
prediction.

</details>


### [484] [Unsupervised operator learning approach for dissipative equations via Onsager principle](https://arxiv.org/abs/2508.07440)
*Zhipeng Chang,Zhenye Wen,Xiaofei Zhao*

Main category: cs.LG

TL;DR: 提出了一种名为DOOL的无监督学习框架，用于解决耗散方程，无需高保真模拟数据，通过直接最小化Onsager变分原理定义的Rayleighian函数进行训练。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习方法依赖高保真模拟数据的监督训练，计算成本高。

Method: 基于Onsager变分原理（OVP），DOOL通过最小化OVP定义的Rayleighian函数训练深度算子网络，无需标签数据，并通过守恒/变化定律显式推进时间。采用时空解耦策略，空间坐标由主干网络处理，外部时间步进实现时间外推。

Result: 数值实验验证了DOOL的有效性，与监督学习的DeepONet和MIONet相比性能更优。

Conclusion: DOOL是一种高效的无监督框架，适用于耗散方程求解，并可扩展至不直接遵循OVP的二阶波动模型。

Abstract: Existing operator learning methods rely on supervised training with
high-fidelity simulation data, introducing significant computational cost. In
this work, we propose the deep Onsager operator learning (DOOL) method, a novel
unsupervised framework for solving dissipative equations. Rooted in the Onsager
variational principle (OVP), DOOL trains a deep operator network by directly
minimizing the OVP-defined Rayleighian functional, requiring no labeled data,
and then proceeds in time explicitly through conservation/change laws for the
solution. Another key innovation here lies in the spatiotemporal decoupling
strategy: the operator's trunk network processes spatial coordinates
exclusively, thereby enhancing training efficiency, while integrated external
time stepping enables temporal extrapolation. Numerical experiments on typical
dissipative equations validate the effectiveness of the DOOL method, and
systematic comparisons with supervised DeepONet and MIONet demonstrate its
enhanced performance. Extensions are made to cover the second-order wave models
with dissipation that do not directly follow OVP.

</details>


### [485] [Stackelberg Coupling of Online Representation Learning and Reinforcement Learning](https://arxiv.org/abs/2508.07452)
*Fernando Martinez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: SCORER框架通过博弈论动态结构化感知与控制网络的交互，提升深度强化学习的性能，无需复杂辅助目标或架构。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励信号下学习有效特征的挑战，避免复杂辅助目标或完全解耦带来的设计复杂性。

Method: 提出SCORER框架，将感知与控制网络的交互建模为Stackelberg博弈，感知网络（领导者）学习特征以优化控制网络（跟随者）的Bellman误差。

Result: 在标准DQN变体和基准任务中，SCORER提高了样本效率和最终性能。

Conclusion: 通过结构化感知与控制的交互，SCORER实现了性能提升，证明了算法设计的有效性。

Abstract: Integrated, end-to-end learning of representations and policies remains a
cornerstone of deep reinforcement learning (RL). However, to address the
challenge of learning effective features from a sparse reward signal, recent
trends have shifted towards adding complex auxiliary objectives or fully
decoupling the two processes, often at the cost of increased design complexity.
This work proposes an alternative to both decoupling and naive end-to-end
learning, arguing that performance can be significantly improved by structuring
the interaction between distinct perception and control networks with a
principled, game-theoretic dynamic. We formalize this dynamic by introducing
the Stackelberg Coupled Representation and Reinforcement Learning (SCORER)
framework, which models the interaction between perception and control as a
Stackelberg game. The perception network (leader) strategically learns features
to benefit the control network (follower), whose own objective is to minimize
its Bellman error. We approximate the game's equilibrium with a practical
two-timescale algorithm. Applied to standard DQN variants on benchmark tasks,
SCORER improves sample efficiency and final performance. Our results show that
performance gains can be achieved through principled algorithmic design of the
perception-control dynamic, without requiring complex auxiliary objectives or
architectures.

</details>


### [486] [Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten](https://arxiv.org/abs/2508.07458)
*Wei Qian,Chenxu Zhao,Yangyi Li,Wenqian Ye,Mengdi Huai*

Main category: cs.LG

TL;DR: 本文提出了一种针对预测不确定性的恶意遗忘攻击，填补了该领域的研究空白，并通过实验验证了攻击的有效性和现有防御措施的不足。


<details>
  <summary>Details</summary>
Motivation: 随着机器遗忘需求的增加，预测不确定性的脆弱性尚未被探索，本文旨在填补这一空白。

Method: 设计了针对预测不确定性的恶意遗忘攻击框架，包括优化方法和黑盒场景实验。

Result: 实验表明，攻击比传统标签误分类攻击更有效，且现有防御措施无效。

Conclusion: 本文揭示了预测不确定性的新攻击面，并强调了开发针对性防御的必要性。

Abstract: Currently, various uncertainty quantification methods have been proposed to
provide certainty and probability estimates for deep learning models' label
predictions. Meanwhile, with the growing demand for the right to be forgotten,
machine unlearning has been extensively studied as a means to remove the impact
of requested sensitive data from a pre-trained model without retraining the
model from scratch. However, the vulnerabilities of such generated predictive
uncertainties with regard to dedicated malicious unlearning attacks remain
unexplored. To bridge this gap, for the first time, we propose a new class of
malicious unlearning attacks against predictive uncertainties, where the
adversary aims to cause the desired manipulations of specific predictive
uncertainty results. We also design novel optimization frameworks for our
attacks and conduct extensive experiments, including black-box scenarios.
Notably, our extensive experiments show that our attacks are more effective in
manipulating predictive uncertainties than traditional attacks that focus on
label misclassifications, and existing defenses against conventional attacks
are ineffective against our attacks.

</details>


### [487] [MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification](https://arxiv.org/abs/2508.07465)
*Tiantian Yang,Zhiqian Chen*

Main category: cs.LG

TL;DR: MOTGNN是一种新型的多组学数据集成框架，通过XGBoost和GNN实现疾病分类，显著提升预测性能并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 多组学数据的高维性和复杂交互性为疾病建模带来挑战，需要一种既能提升预测准确性又能提供解释的方法。

Method: MOTGNN结合XGBoost构建组学特定图，使用GNN进行分层表示学习，并通过深度前馈网络实现跨组学集成。

Result: 在三个真实疾病数据集上，MOTGNN在准确性、ROC-AUC和F1分数上优于现有方法5-10%，且对类别不平衡具有鲁棒性。

Conclusion: MOTGNN在多组学疾病建模中表现出优越的预测性能和可解释性，具有广泛应用潜力。

Abstract: Integrating multi-omics data, such as DNA methylation, mRNA expression, and
microRNA (miRNA) expression, offers a comprehensive view of the biological
mechanisms underlying disease. However, the high dimensionality and complex
interactions among omics layers present major challenges for predictive
modeling. We propose Multi-Omics integration with Tree-generated Graph Neural
Network (MOTGNN), a novel and interpretable framework for binary disease
classification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform
omics-specific supervised graph construction, followed by modality-specific
Graph Neural Networks (GNNs) for hierarchical representation learning, and a
deep feedforward network for cross-omics integration. On three real-world
disease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in
accuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance
(e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains
computational efficiency through sparse graphs (2.1-2.8 edges per node) and
provides built-in interpretability, revealing both top-ranked biomarkers and
the relative contributions of each omics modality. These results highlight
MOTGNN's potential to improve both predictive accuracy and interpretability in
multi-omics disease modeling.

</details>


### [488] [Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications](https://arxiv.org/abs/2508.07473)
*Zijian Liu*

Main category: cs.LG

TL;DR: 本文研究了在线凸优化（OCO）中梯度估计具有重尾分布时的性能，证明了经典算法无需修改即可在重尾条件下实现最优遗憾界，并拓展了应用场景。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注梯度方差有限的情况，而对梯度估计具有重尾分布（即仅有限p阶中心矩）的情况研究较少，本文旨在填补这一空白。

Method: 分析了经典OCO算法（如在线梯度下降）在重尾条件下的表现，未对算法进行任何修改，仅基于标准有界域假设。

Result: 证明了这些算法在重尾条件下仍能实现完全最优的遗憾界，且无需额外操作（如梯度裁剪）。

Conclusion: 重尾条件下的OCO问题可通过经典算法有效解决，无需额外操作，且结果可拓展至非光滑非凸优化等更广泛场景。

Abstract: In Online Convex Optimization (OCO), when the stochastic gradient has a
finite variance, many algorithms provably work and guarantee a sublinear
regret. However, limited results are known if the gradient estimate has a heavy
tail, i.e., the stochastic gradient only admits a finite $\mathsf{p}$-th
central moment for some $\mathsf{p}\in\left(1,2\right]$. Motivated by it, this
work examines different old algorithms for OCO (e.g., Online Gradient Descent)
in the more challenging heavy-tailed setting. Under the standard bounded domain
assumption, we establish new regrets for these classical methods without any
algorithmic modification. Remarkably, these regret bounds are fully optimal in
all parameters (can be achieved even without knowing $\mathsf{p}$), suggesting
that OCO with heavy tails can be solved effectively without any extra operation
(e.g., gradient clipping). Our new results have several applications. A
particularly interesting one is the first provable convergence result for
nonsmooth nonconvex optimization under heavy-tailed noise without gradient
clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and
extend our ideas to optimistic algorithms to handle different cases
simultaneously.

</details>


### [489] [N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting](https://arxiv.org/abs/2508.07490)
*Ricardo Matos,Luis Roque,Vitor Cerqueira*

Main category: cs.LG

TL;DR: N-BEATS-MOE是N-BEATS的扩展，通过引入混合专家（MoE）层和动态块加权策略，提升了时间序列预测的性能和适应性，并在异构时间序列数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法如N-BEATS在时间序列预测中表现优异，但仍有改进空间，尤其是在适应不同时间序列特性和提升可解释性方面。

Method: 提出N-BEATS-MOE，基于MoE层和动态块加权策略，通过门控网络选择最相关的专家块，提升模型适应性。

Result: 在12个基准数据集上评估，N-BEATS-MOE在异构时间序列数据集上表现显著优于其他方法。

Conclusion: N-BEATS-MOE通过动态专家选择和门控机制，提升了时间序列预测的性能和可解释性，尤其在异构数据上表现突出。

Abstract: Deep learning approaches are increasingly relevant for time series
forecasting tasks. Methods such as N-BEATS, which is built on stacks of
multilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on
benchmark datasets and competitions. N-BEATS is also more interpretable
relative to other deep learning approaches, as it decomposes forecasts into
different time series components, such as trend and seasonality. In this work,
we present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts
(MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a
gating network which allows the model to better adapt to the characteristics of
each time series. We also hypothesize that the gating mechanism provides
additional interpretability by identifying which expert is most relevant for
each series. We evaluate our method across 12 benchmark datasets against
several approaches, achieving consistent improvements on several datasets,
especially those composed of heterogeneous time series.

</details>


### [490] [Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach](https://arxiv.org/abs/2508.07505)
*Yueyang Quan,Chang Wang,Shengjie Zhai,Minghong Fang,Zhuqing Liu*

Main category: cs.LG

TL;DR: 提出了一种名为DPMixSGD的隐私保护算法，用于解决非凸分散式极小极大优化问题，结合差分隐私技术，确保数据隐私的同时不影响收敛性能。


<details>
  <summary>Details</summary>
Motivation: 分散式极小极大优化中，模型更新共享可能导致敏感数据泄露，差分隐私虽能保护隐私，但噪声添加可能影响收敛。

Method: 基于STORM算法，提出DPMixSGD，通过噪声添加保护隐私，并理论证明其对收敛影响有限。

Result: 实验验证了DPMixSGD在多种任务和模型中的有效性，噪声添加未显著影响收敛。

Conclusion: DPMixSGD为分散式极小极大优化提供了一种高效的隐私保护解决方案。

Abstract: Decentralized min-max optimization allows multi-agent systems to
collaboratively solve global min-max optimization problems by facilitating the
exchange of model updates among neighboring agents, eliminating the need for a
central server. However, sharing model updates in such systems carry a risk of
exposing sensitive data to inference attacks, raising significant privacy
concerns. To mitigate these privacy risks, differential privacy (DP) has become
a widely adopted technique for safeguarding individual data. Despite its
advantages, implementing DP in decentralized min-max optimization poses
challenges, as the added noise can hinder convergence, particularly in
non-convex scenarios with complex agent interactions in min-max optimization
problems. In this work, we propose an algorithm called DPMixSGD (Differential
Private Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving
algorithm specifically designed for non-convex decentralized min-max
optimization. Our method builds on the state-of-the-art STORM-based algorithm,
one of the fastest decentralized min-max solutions. We rigorously prove that
the noise added to local gradients does not significantly compromise
convergence performance, and we provide theoretical bounds to ensure privacy
guarantees. To validate our theoretical findings, we conduct extensive
experiments across various tasks and models, demonstrating the effectiveness of
our approach.

</details>


### [491] [FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction](https://arxiv.org/abs/2508.07518)
*Sichen Zhao,Wei Shao,Jeffrey Chan,Ziqi Xu,Flora Salim*

Main category: cs.LG

TL;DR: 论文提出了一种基于解耦表示学习的框架FairDRL-ST，用于解决时空预测中的公平性问题，特别是在移动需求预测中。


<details>
  <summary>Details</summary>
Motivation: 随着时空神经网络在城市计算中的广泛应用，其预测偏差可能加剧社会经济不平等，因此需要关注公平性。

Method: 结合对抗学习和解耦表示学习，无监督地分离敏感信息属性，避免监督学习中的过补偿问题。

Result: 在真实城市移动数据集上验证，该框架能缩小公平性差距，同时保持预测性能。

Conclusion: FairDRL-ST为时空预测中的公平性问题提供了一种有效且性能损失小的解决方案。

Abstract: As deep spatio-temporal neural networks are increasingly utilised in urban
computing contexts, the deployment of such methods can have a direct impact on
users of critical urban infrastructure, such as public transport, emergency
services, and traffic management systems. While many spatio-temporal methods
focus on improving accuracy, fairness has recently gained attention due to
growing evidence that biased predictions in spatio-temporal applications can
disproportionately disadvantage certain demographic or geographic groups,
thereby reinforcing existing socioeconomic inequalities and undermining the
ethical deployment of AI in public services. In this paper, we propose a novel
framework, FairDRL-ST, based on disentangled representation learning, to
address fairness concerns in spatio-temporal prediction, with a particular
focus on mobility demand forecasting. By leveraging adversarial learning and
disentangled representation learning, our framework learns to separate
attributes that contain sensitive information. Unlike existing methods that
enforce fairness through supervised learning, which may lead to
overcompensation and degraded performance, our framework achieves fairness in
an unsupervised manner with minimal performance loss. We apply our framework to
real-world urban mobility datasets and demonstrate its ability to close
fairness gaps while delivering competitive predictive performance compared to
state-of-the-art fairness-aware methods.

</details>


### [492] [Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning](https://arxiv.org/abs/2508.07536)
*Tasfiq E. Alam,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息的多模态CNN模型，结合振动和电机电流信号，通过物理特征提取和损失函数提升轴承故障分类的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决变工况下轴承故障分类的准确性和可解释性问题，避免因领域偏移导致的模型性能下降。

Method: 采用多模态CNN架构，结合物理特征提取分支和物理信息损失函数，评估三种迁移学习策略。

Result: 在Paderborn和KAIST数据集上表现优异，最高准确率达98%，显著优于非物理信息基线。

Conclusion: 物理信息与数据驱动结合的方法在轴承故障诊断中具有鲁棒性和泛化能力。

Abstract: Accurate and interpretable bearing fault classification is critical for
ensuring the reliability of rotating machinery, particularly under variable
operating conditions where domain shifts can significantly degrade model
performance. This study proposes a physics-informed multimodal convolutional
neural network (CNN) with a late fusion architecture, integrating vibration and
motor current signals alongside a dedicated physics-based feature extraction
branch. The model incorporates a novel physics-informed loss function that
penalizes physically implausible predictions based on characteristic bearing
fault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency
Inner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive
experiments on the Paderborn University dataset demonstrate that the proposed
physics-informed approach consistently outperforms a non-physics-informed
baseline, achieving higher accuracy, reduced false classifications, and
improved robustness across multiple data splits. To address performance
degradation under unseen operating conditions, three transfer learning (TL)
strategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy
(LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS
yields the best generalization, with additional performance gains when combined
with physics-informed modeling. Validation on the KAIST bearing dataset
confirms the framework's cross-dataset applicability, achieving up to 98
percent accuracy. Statistical hypothesis testing further verifies significant
improvements (p < 0.01) in classification performance. The proposed framework
demonstrates the potential of integrating domain knowledge with data-driven
learning to achieve robust, interpretable, and generalizable fault diagnosis
for real-world industrial applications.

</details>


### [493] [Multimodal Remote Inference](https://arxiv.org/abs/2508.07555)
*Keyuan Zhang,Yin Sun,Bo Ji*

Main category: cs.LG

TL;DR: 研究多模态远程推理系统中的调度问题，提出基于索引的阈值策略以减少推理误差。


<details>
  <summary>Details</summary>
Motivation: 由于网络资源有限，实时传输多模态特征困难，导致推理误差增加，需优化调度策略。

Method: 开发基于索引的阈值策略，动态切换模态以最小化推理误差，适用于非单调、非加性AoI函数和异构传输时间。

Result: 策略将推理误差降低高达55%，优于轮询和随机策略。

Conclusion: 优化任务导向的AoI函数可显著提升远程推理准确性。

Abstract: We consider a remote inference system with multiple modalities, where a
multimodal machine learning (ML) model performs real-time inference using
features collected from remote sensors. As sensor observations may change
dynamically over time, fresh features are critical for inference tasks.
However, timely delivering features from all modalities is often infeasible due
to limited network resources. To this end, we study a two-modality scheduling
problem to minimize the ML model's inference error, which is expressed as a
penalty function of AoI for both modalities. We develop an index-based
threshold policy and prove its optimality. Specifically, the scheduler switches
modalities when the current modality's index function exceeds a threshold. We
show that the two modalities share the same threshold, and both the index
functions and the threshold can be computed efficiently. The optimality of our
policy holds for (i) general AoI functions that are \emph{non-monotonic} and
\emph{non-additive} and (ii) \emph{heterogeneous} transmission times. Numerical
results show that our policy reduces inference error by up to 55% compared to
round-robin and uniform random policies, which are oblivious to the AoI-based
inference error function. Our results shed light on how to improve remote
inference accuracy by optimizing task-oriented AoI functions.

</details>


### [494] [Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning](https://arxiv.org/abs/2508.07556)
*Stephan Rabanser*

Main category: cs.LG

TL;DR: 该论文探讨了如何通过不确定性估计提升机器学习在高风险领域的可靠性，提出了一种轻量级的后验弃权方法，并研究了隐私保护与不确定性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域中，机器学习的可靠性至关重要，因此需要提升模型的安全性和可信度，特别是在选择性预测（模型在低置信度时弃权）方面。

Method: 通过利用模型训练轨迹中的不确定性信号，提出了一种无需改变架构或损失函数的轻量级后验弃权方法，并研究了差分隐私对不确定性的影响。

Result: 该方法在选择性预测任务中表现优异，且在差分隐私下保持鲁棒性。同时，揭示了选择性分类差距的五个可解释误差来源，并提出了防御对抗性攻击的策略。

Conclusion: 论文通过改进、评估和保护不确定性估计，推动了可靠机器学习的发展，使模型不仅能准确预测，还能知道何时弃权。

Abstract: Machine learning (ML) systems are increasingly deployed in high-stakes
domains where reliability is paramount. This thesis investigates how
uncertainty estimation can enhance the safety and trustworthiness of ML,
focusing on selective prediction -- where models abstain when confidence is
low.
  We first show that a model's training trajectory contains rich uncertainty
signals that can be exploited without altering its architecture or loss. By
ensembling predictions from intermediate checkpoints, we propose a lightweight,
post-hoc abstention method that works across tasks, avoids the cost of deep
ensembles, and achieves state-of-the-art selective prediction performance.
Crucially, this approach is fully compatible with differential privacy (DP),
allowing us to study how privacy noise affects uncertainty quality. We find
that while many methods degrade under DP, our trajectory-based approach remains
robust, and we introduce a framework for isolating the privacy-uncertainty
trade-off. Next, we then develop a finite-sample decomposition of the selective
classification gap -- the deviation from the oracle accuracy-coverage curve --
identifying five interpretable error sources and clarifying which interventions
can close the gap. This explains why calibration alone cannot fix ranking
errors, motivating methods that improve uncertainty ordering. Finally, we show
that uncertainty signals can be adversarially manipulated to hide errors or
deny service while maintaining high accuracy, and we design defenses combining
calibration audits with verifiable inference.
  Together, these contributions advance reliable ML by improving, evaluating,
and safeguarding uncertainty estimation, enabling models that not only make
accurate predictions -- but also know when to say "I do not know".

</details>


### [495] [Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression](https://arxiv.org/abs/2508.07571)
*Xingwu Chen,Miao Lu,Beining Wu,Difan Zou*

Main category: cs.LG

TL;DR: 论文探讨了通过增加测试时计算（如生成更多中间思考或采样多个候选答案）提升语言模型性能的方法，并通过理论和实验分析随机性与采样在推理中的作用。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合实际语言模型推理与理论分析之间的差距，探索随机性和采样对模型性能的影响。

Method: 采用上下文线性回归框架，结合噪声注入和二元系数采样，模拟语言模型解码过程。

Result: 理论和实证结果表明，该框架能有效分析推理技术，为理解实际语言模型的推理行为提供新视角。

Conclusion: 研究展示了随机性和采样在语言模型推理中的潜力，为未来理论和实践提供了新方向。

Abstract: Using more test-time computation during language model inference, such as
generating more intermediate thoughts or sampling multiple candidate answers,
has proven effective in significantly improving model performance. This paper
takes an initial step toward bridging the gap between practical language model
inference and theoretical transformer analysis by incorporating randomness and
sampling. We focus on in-context linear regression with continuous/binary
coefficients, where our framework simulates language model decoding through
noise injection and binary coefficient sampling. Through this framework, we
provide detailed analyses of widely adopted inference techniques. Supported by
empirical results, our theoretical framework and analysis demonstrate the
potential for offering new insights into understanding inference behaviors in
real-world language models.

</details>


### [496] [When and how can inexact generative models still sample from the data manifold?](https://arxiv.org/abs/2508.07581)
*Nisha Chandramoorthy,Adriaan de Clercq*

Main category: cs.LG

TL;DR: 论文研究了生成模型中学习误差对数据分布支持的影响，发现误差仅导致预测密度在数据流形上变化，并提出了一种基于Lyapunov向量的鲁棒性机制。


<details>
  <summary>Details</summary>
Motivation: 探索生成模型中学习误差如何影响生成样本的分布支持，尤其是为何误差不会使样本偏离数据流形。

Method: 采用动力学系统方法，通过扰动分析和Lyapunov向量对齐条件，研究生成过程的鲁棒性。

Result: 发现Lyapunov向量与数据流形边界切空间的对齐是鲁棒性的关键机制，并提出了一种高效计算对齐条件的方法。

Conclusion: 研究为生成模型的理论保证提供了新视角，适用于多种动力学生成模型和目标分布。

Abstract: A curious phenomenon observed in some dynamical generative models is the
following: despite learning errors in the score function or the drift vector
field, the generated samples appear to shift \emph{along} the support of the
data distribution but not \emph{away} from it. In this work, we investigate
this phenomenon of \emph{robustness of the support} by taking a dynamical
systems approach on the generating stochastic/deterministic process. Our
perturbation analysis of the probability flow reveals that infinitesimal
learning errors cause the predicted density to be different from the target
density only on the data manifold for a wide class of generative models.
Further, what is the dynamical mechanism that leads to the robustness of the
support? We show that the alignment of the top Lyapunov vectors (most sensitive
infinitesimal perturbation directions) with the tangent spaces along the
boundary of the data manifold leads to robustness and prove a sufficient
condition on the dynamics of the generating process to achieve this alignment.
Moreover, the alignment condition is efficient to compute and, in practice, for
robust generative models, automatically leads to accurate estimates of the
tangent bundle of the data manifold. Using a finite-time linear perturbation
analysis on samples paths as well as probability flows, our work complements
and extends existing works on obtaining theoretical guarantees for generative
models from a stochastic analysis, statistical learning and uncertainty
quantification points of view. Our results apply across different dynamical
generative models, such as conditional flow-matching and score-based generative
models, and for different target distributions that may or may not satisfy the
manifold hypothesis.

</details>


### [497] [Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization](https://arxiv.org/abs/2508.07629)
*Zhenpeng Su,Leiyu Pan,Xue Bai,Dening Liu,Guanting Dong,Jiaming Huang,Wenping Hu,Guorui Zhou*

Main category: cs.LG

TL;DR: Klear-Reasoner是一个具有长推理能力的模型，通过详细的数据准备和训练流程优化，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型训练细节披露不完整，导致高性能模型难以复现。本文旨在深入分析推理模型的训练流程，并提出改进方法。

Method: 采用长链思维监督微调（long CoT SFT）和强化学习（RL），并提出梯度保留裁剪策略优化（GPPO）解决RL中的裁剪问题。

Result: 在数学和编程任务中表现卓越，AIME 2024得分90.5%，AIME 2025得分83.2%，LiveCodeBench V5得分66.0%，V6得分58.1%。

Conclusion: 高质量数据和小样本训练更有效，GPPO提升了模型探索能力和学习效率。

Abstract: We present Klear-Reasoner, a model with long reasoning capabilities that
demonstrates careful deliberation during problem solving, achieving outstanding
performance across multiple benchmarks. Although there are already many
excellent works related to inference models in the current community, there are
still many problems with reproducing high-performance inference models due to
incomplete disclosure of training details. This report provides an in-depth
analysis of the reasoning model, covering the entire post-training workflow
from data preparation and long Chain-of-Thought supervised fine-tuning (long
CoT SFT) to reinforcement learning (RL), along with detailed ablation studies
for each experimental component. For SFT data, our experiments show that a
small number of high-quality data sources are more effective than a large
number of diverse data sources, and that difficult samples can achieve better
results without accuracy filtering. In addition, we investigate two key issues
with current clipping mechanisms in RL: Clipping suppresses critical
exploration signals and ignores suboptimal trajectories. To address these
challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)
that gently backpropagates gradients from clipped tokens. GPPO not only
enhances the model's exploration capacity but also improves its efficiency in
learning from negative samples. Klear-Reasoner exhibits exceptional reasoning
abilities in mathematics and programming, scoring 90.5\% on AIME 2024, 83.2\%
on AIME 2025, 66.0\% on LiveCodeBench V5 and 58.1\% on LiveCodeBench V6.

</details>


### [498] [Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo](https://arxiv.org/abs/2508.07631)
*Advait Parulekar,Litu Rout,Karthikeyan Shanmugam,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: 研究了基于分数的生成模型中后验采样问题，提出了一种在多项式时间内近似采样的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管后验采样在KL散度下通常是难解的，但实际应用中许多算法表现良好，因此需要一种更通用的方法来解决这一问题。

Method: 将后验采样视为一个“倾斜”问题，通过最小假设，从噪声先验中采样，使其在KL散度和Fisher散度下接近真实后验。

Result: 证明了可以在多项式时间内采样一个分布，该分布同时接近噪声先验的后验和真实后验。

Conclusion: 这是首次在多项式时间内实现近似后验采样的正式结果，为实际应用提供了理论支持。

Abstract: We study the problem of posterior sampling in the context of score based
generative models. We have a trained score network for a prior $p(x)$, a
measurement model $p(y|x)$, and are tasked with sampling from the posterior
$p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case)
under well-accepted computational hardness assumptions. Despite this, popular
algorithms for tasks such as image super-resolution, stylization, and
reconstruction enjoy empirical success. Rather than establishing distributional
assumptions or restricted settings under which exact posterior sampling is
tractable, we view this as a more general "tilting" problem of biasing a
distribution towards a measurement. Under minimal assumptions, we show that one
can tractably sample from a distribution that is simultaneously close to the
posterior of a noised prior in KL divergence and the true posterior in Fisher
divergence. Intuitively, this combination ensures that the resulting sample is
consistent with both the measurement and the prior. To the best of our
knowledge these are the first formal results for (approximate) posterior
sampling in polynomial time.

</details>


### [499] [Attribution Explanations for Deep Neural Networks: A Theoretical Perspective](https://arxiv.org/abs/2508.07636)
*Huiqi Deng,Hongbin Pei,Quanshi Zhang,Mengnan Du*

Main category: cs.LG

TL;DR: 该论文探讨了深度神经网络（DNNs）的归因解释方法，分析了其忠实性问题及三大核心挑战，并总结了理论进展的三个关键方向。


<details>
  <summary>Details</summary>
Motivation: 归因解释方法在解释DNNs时存在忠实性问题，影响其可靠性和实用性。论文旨在解决这一问题的三大挑战：方法间的异构性、理论基础的缺失以及实证评估的困难。

Method: 通过理论统一、理论基础和理论评估三个方向，系统比较和澄清现有归因方法的共性与差异，并验证其忠实性。

Result: 总结了理论进展，揭示了归因方法的共性与差异，为方法选择和设计提供了理论支持。

Conclusion: 论文提出了未来研究的开放性问题，强调了理论理解对改进归因方法的重要性。

Abstract: Attribution explanation is a typical approach for explaining deep neural
networks (DNNs), inferring an importance or contribution score for each input
variable to the final output. In recent years, numerous attribution methods
have been developed to explain DNNs. However, a persistent concern remains
unresolved, i.e., whether and which attribution methods faithfully reflect the
actual contribution of input variables to the decision-making process. The
faithfulness issue undermines the reliability and practical utility of
attribution explanations. We argue that these concerns stem from three core
challenges. First, difficulties arise in comparing attribution methods due to
their unstructured heterogeneity, differences in heuristics, formulations, and
implementations that lack a unified organization. Second, most methods lack
solid theoretical underpinnings, with their rationales remaining absent,
ambiguous, or unverified. Third, empirically evaluating faithfulness is
challenging without ground truth. Recent theoretical advances provide a
promising way to tackle these challenges, attracting increasing attention. We
summarize these developments, with emphasis on three key directions: (i)
Theoretical unification, which uncovers commonalities and differences among
methods, enabling systematic comparisons; (ii) Theoretical rationale,
clarifying the foundations of existing methods; (iii) Theoretical evaluation,
rigorously proving whether methods satisfy faithfulness principles. Beyond a
comprehensive review, we provide insights into how these studies help deepen
theoretical understanding, inform method selection, and inspire new attribution
methods. We conclude with a discussion of promising open problems for further
work.

</details>


### [500] [Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs](https://arxiv.org/abs/2508.07637)
*Guanqun Ma,David Lenz,Hanqi Guo,Tom Peterka,Bei Wang*

Main category: cs.LG

TL;DR: 提出首个直接从连续隐式模型（如MFA）中提取复杂拓扑特征（如轮廓、Jacobi集和脊谷图）的框架，无需离散化。


<details>
  <summary>Details</summary>
Motivation: 连续隐式模型（如MFA）为科学数据的存储、传输和分析提供了新视角，但缺乏直接提取拓扑特征的方法。

Method: 基于MFA模型，直接提取拓扑特征，支持函数值和高阶导数查询。

Result: 实现了从连续隐式模型中直接提取复杂拓扑特征，适用于任何支持相关查询的模型。

Conclusion: 为连续隐式模型的拓扑数据分析和可视化奠定了基础。

Abstract: Implicit continuous models, such as functional models and implicit neural
networks, are an increasingly popular method for replacing discrete data
representations with continuous, high-order, and differentiable surrogates.
These models offer new perspectives on the storage, transfer, and analysis of
scientific data. In this paper, we introduce the first framework to directly
extract complex topological features -- contours, Jacobi sets, and ridge-valley
graphs -- from a type of continuous implicit model known as multivariate
functional approximation (MFA). MFA replaces discrete data with continuous
piecewise smooth functions. Given an MFA model as the input, our approach
enables direct extraction of complex topological features from the model,
without reverting to a discrete representation of the model. Our work is easily
generalizable to any continuous implicit model that supports the queries of
function values and high-order derivatives. Our work establishes the building
blocks for performing topological data analysis and visualization on implicit
continuous models.

</details>


### [501] [Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals](https://arxiv.org/abs/2508.07638)
*Jia Zhang,Yao Liu,Chen-Xi Zhang,Yi Liu,Yi-Xuan Jin,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: 论文提出了一种基于数据选择的方法（DMPO），通过量化偏好分歧（PD）来解决多偏好优化中的噪声和冲突问题，显著提升了LLM对齐的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如DPO）在处理多偏好数据时面临噪声和冲突问题，需要一种更可靠且可扩展的解决方案。

Method: 提出DMPO目标，引入PD量化偏好冲突，并基于PD设计数据选择原则，选择高共识数据用于训练。

Result: 在UltraFeedback数据集上，该方法相对标准方法提升了10%的性能，同时提高了训练效率。

Conclusion: 通过数据选择和PD量化，DMPO实现了更高效的LLM对齐，解锁了细粒度偏好信号的潜力。

Abstract: Aligning Large Language Models (LLMs) with diverse human values requires
moving beyond a single holistic "better-than" preference criterion. While
collecting fine-grained, aspect-specific preference data is more reliable and
scalable, existing methods like Direct Preference Optimization (DPO) struggle
with the severe noise and conflicts inherent in such aggregated datasets. In
this paper, we tackle this challenge from a data-centric perspective. We first
derive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a
key Preference Divergence (PD) term that quantifies inter-aspect preference
conflicts. Instead of using this term for direct optimization, we leverage it
to formulate a novel, theoretically-grounded data selection principle. Our
principle advocates for selecting a subset of high-consensus data-identified by
the most negative PD values-for efficient DPO training. We prove the optimality
of this strategy by analyzing the loss bounds of the DMPO objective in the
selection problem. To operationalize our approach, we introduce practical
methods of PD term estimation and length bias mitigation, thereby proposing our
PD selection method. Evaluation on the UltraFeedback dataset with three varying
conflict levels shows that our simple yet effective strategy achieves over 10%
relative improvement against both the standard holistic preference and a
stronger oracle using aggregated preference signals, all while boosting
training efficiency and obviating the need for intractable holistic preference
annotating, unlocking the potential of robust LLM alignment via fine-grained
preference signals.

</details>


### [502] [Multi-Turn Jailbreaks Are Simpler Than They Seem](https://arxiv.org/abs/2508.07646)
*Xiaoxue Yang,Jaeha Lee,Anna-Katharina Dick,Jasper Timm,Fei Xie,Diogo Cruz*

Main category: cs.LG

TL;DR: 多轮越狱攻击对大型语言模型（LLM）的防御仍是一个显著漏洞，研究发现其成功率超过70%。本文通过实证分析指出，多轮攻击的复杂性被高估，其效果与多次单轮攻击相近，且攻击成功率在相似模型间相关。此外，推理能力越强的模型越容易被攻击。


<details>
  <summary>Details</summary>
Motivation: 尽管单轮越狱攻击的防御已显著改进，但多轮攻击仍是LLM的薄弱环节，需深入研究其机制和影响。

Method: 使用StrongREJECT基准对GPT-4、Claude和Gemini等先进模型进行多轮越狱攻击的实证分析。

Result: 多轮攻击的效果与多次单轮攻击相近，攻击成功率在相似模型间相关，且推理能力强的模型更易受攻击。

Conclusion: 研究结果对AI安全性评估和抗越狱系统设计具有重要意义，并公开了源代码。

Abstract: While defenses against single-turn jailbreak attacks on Large Language Models
(LLMs) have improved significantly, multi-turn jailbreaks remain a persistent
vulnerability, often achieving success rates exceeding 70% against models
optimized for single-turn protection. This work presents an empirical analysis
of automated multi-turn jailbreak attacks across state-of-the-art models
including GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark.
Our findings challenge the perceived sophistication of multi-turn attacks: when
accounting for the attacker's ability to learn from how models refuse harmful
requests, multi-turn jailbreaking approaches are approximately equivalent to
simply resampling single-turn attacks multiple times. Moreover, attack success
is correlated among similar models, making it easier to jailbreak newly
released ones. Additionally, for reasoning models, we find surprisingly that
higher reasoning effort often leads to higher attack success rates. Our results
have important implications for AI safety evaluation and the design of
jailbreak-resistant systems. We release the source code at
https://github.com/diogo-cruz/multi_turn_simpler

</details>


### [503] [Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning](https://arxiv.org/abs/2508.07659)
*Hyeon-Ju Jeon,Jeon-Ho Kang,In-Hyuk Kwon,O-Joun Lee*

Main category: cs.LG

TL;DR: 该研究旨在通过时空图神经网络（STGNN）和结构学习，动态捕捉地球观测与大气状态的空间相关性，以提高全球大气状态估计的预测精度。通过自适应调节节点度和空间距离，解决了结构学习中的信息丢失和过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 传统数值天气预报（NWP）系统在固定网格点上预测大气状态，但地球观测数据位置不固定，导致空间相关性复杂且动态变化。需要一种方法有效捕捉这种动态相关性。

Method: 采用时空图神经网络（STGNN）结合结构学习，通过自适应调节节点度和考虑空间距离，优化边缘采样，避免信息丢失和过平滑。

Result: 在东亚真实大气状态和观测数据上验证，该方法在高变异性区域优于现有STGNN模型（无论是否使用结构学习）。

Conclusion: 提出的方法有效解决了动态空间相关性问题，显著提升了大气状态估计的预测精度。

Abstract: This study aims to discover spatial correlations between Earth observations
and atmospheric states to improve the forecasting accuracy of global
atmospheric state estimation, which are usually conducted using conventional
numerical weather prediction (NWP) systems and is the beginning of weather
forecasting. NWP systems predict future atmospheric states at fixed locations,
which are called NWP grid points, by analyzing previous atmospheric states and
newly acquired Earth observations without fixed locations. Thus, surrounding
meteorological context and the changing locations of the observations make
spatial correlations between atmospheric states and observations over time. To
handle complicated spatial correlations, which change dynamically, we employ
spatiotemporal graph neural networks (STGNNs) with structure learning. However,
structure learning has an inherent limitation that this can cause structural
information loss and over-smoothing problem by generating excessive edges. To
solve this problem, we regulate edge sampling by adaptively determining node
degrees and considering the spatial distances between NWP grid points and
observations. We validated the effectiveness of the proposed method by using
real-world atmospheric state and observation data from East Asia. Even in areas
with high atmospheric variability, the proposed method outperformed existing
STGNN models with and without structure learning.

</details>


### [504] [GLiClass: Generalist Lightweight Model for Sequence Classification Tasks](https://arxiv.org/abs/2508.07662)
*Ihor Stepanov,Mykhailo Shtopko,Dmytro Vodianytskyi,Oleksandr Lukashov,Alexander Yavorskyi,Mykyta Yaroshenko*

Main category: cs.LG

TL;DR: GLiClass是一种新型序列分类方法，结合了高效率和灵活性，适用于零样本和小样本学习场景。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统需要高效且准确的分类方法，同时适应动态变化的用户需求，但现有方法如生成式LLM和交叉编码器存在效率或灵活性不足的问题。

Method: 基于GLiNER架构改进的GLiClass方法，并采用近端策略优化（PPO）进行多标签文本分类训练。

Result: GLiClass在准确性和效率上与基于嵌入的方法相当，同时保持了零样本和小样本学习的灵活性。

Conclusion: GLiClass为解决分类任务中的效率和灵活性挑战提供了一种有效方案。

Abstract: Classification is one of the most widespread tasks in AI applications,
serving often as the first step in filtering, sorting, and categorizing data.
Since modern AI systems must handle large volumes of input data and early
pipeline stages can propagate errors downstream, achieving high efficiency and
accuracy is critical. Moreover, classification requirements can change
dynamically based on user needs, necessitating models with strong zero-shot
capabilities. While generative LLMs have become mainstream for zero-shot
classification due to their versatility, they suffer from inconsistent
instruction following and computational inefficiency. Cross-encoders, commonly
used as rerankers in RAG pipelines, face a different bottleneck: they must
process text-label pairs sequentially, significantly reducing efficiency with
large label sets. Embedding-based approaches offer good efficiency but struggle
with complex scenarios involving logical and semantic constraints. We propose
GLiClass, a novel method that adapts the GLiNER architecture for sequence
classification tasks. Our approach achieves strong accuracy and efficiency
comparable to embedding-based methods, while maintaining the flexibility needed
for zero-shot and few-shot learning scenarios. Additionally, we adapted
proximal policy optimization (PPO) for multi-label text classification,
enabling training classifiers in data-sparse conditions or from human feedback.

</details>


### [505] [AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting](https://arxiv.org/abs/2508.07668)
*Hyobin Park,Jinwook Jung,Minseok Seo,Hyunsoo Choi,Deukjae Cho,Sekil Park,Dong-Geol Choi*

Main category: cs.LG

TL;DR: AIS-LLM是一个结合时间序列AIS数据和大型语言模型（LLM）的新框架，用于同时处理船舶轨迹预测、异常检测和碰撞风险评估，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理海事任务，难以全面考虑复杂情况，AIS-LLM旨在通过多任务集成解决这一问题。

Method: AIS-LLM包括时间序列编码器、LLM提示编码器、跨模态对齐模块和多任务解码器，实现端到端多任务处理。

Result: 实验表明AIS-LLM在各项任务中表现优于现有方法，并能生成综合情境摘要。

Conclusion: AIS-LLM为智能高效的海事交通管理提供了潜力。

Abstract: With the increase in maritime traffic and the mandatory implementation of the
Automatic Identification System (AIS), the importance and diversity of maritime
traffic analysis tasks based on AIS data, such as vessel trajectory prediction,
anomaly detection, and collision risk assessment, is rapidly growing. However,
existing approaches tend to address these tasks individually, making it
difficult to holistically consider complex maritime situations. To address this
limitation, we propose a novel framework, AIS-LLM, which integrates time-series
AIS data with a large language model (LLM). AIS-LLM consists of a Time-Series
Encoder for processing AIS sequences, an LLM-based Prompt Encoder, a
Cross-Modality Alignment Module for semantic alignment between time-series data
and textual prompts, and an LLM-based Multi-Task Decoder. This architecture
enables the simultaneous execution of three key tasks: trajectory prediction,
anomaly detection, and risk assessment of vessel collisions within a single
end-to-end system. Experimental results demonstrate that AIS-LLM outperforms
existing methods across individual tasks, validating its effectiveness.
Furthermore, by integratively analyzing task outputs to generate situation
summaries and briefings, AIS-LLM presents the potential for more intelligent
and efficient maritime traffic management.

</details>


### [506] [Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation](https://arxiv.org/abs/2508.07675)
*Xutong Liu,Baran Atalar,Xiangxiang Dai,Jinhang Zuo,Siwei Wang,John C. S. Lui,Wei Chen,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 论文提出了一种基于学习的原则性框架，用于解决语义缓存中未知查询和成本分布的缓存淘汰问题，并开发了高效的算法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的高推理成本带来了可扩展性和可持续性挑战，传统缓存方法无法处理语义相似性，现有语义缓存方法缺乏理论基础且无法适应不确定性。

Method: 提出了一个基于学习的框架，包括离线优化和在线学习变体，并开发了高效的算法。

Result: 在合成数据集上的评估表明，所提算法性能优于或与基线方法相当。

Conclusion: 该框架为语义缓存提供了一种理论支持且高效的解决方案，适用于实际不确定性场景。

Abstract: Large Language Models (LLMs) are revolutionizing how users interact with
information systems, yet their high inference cost poses serious scalability
and sustainability challenges. Caching inference responses, allowing them to be
retrieved without another forward pass through the LLM, has emerged as one
possible solution. Traditional exact-match caching, however, overlooks the
semantic similarity between queries, leading to unnecessary recomputation.
Semantic caching addresses this by retrieving responses based on semantic
similarity, but introduces a fundamentally different cache eviction problem:
one must account for mismatch costs between incoming queries and cached
responses. Moreover, key system parameters, such as query arrival probabilities
and serving costs, are often unknown and must be learned over time. Existing
semantic caching methods are largely ad-hoc, lacking theoretical foundations
and unable to adapt to real-world uncertainty. In this paper, we present a
principled, learning-based framework for semantic cache eviction under unknown
query and cost distributions. We formulate both offline optimization and online
learning variants of the problem, and develop provably efficient algorithms
with state-of-the-art guarantees. We also evaluate our framework on a synthetic
dataset, showing that our proposed algorithms perform matching or superior
performance compared with baselines.

</details>


### [507] [MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation](https://arxiv.org/abs/2508.07681)
*Yooseok Lim,ByoungJun Jeon,Seong-A Park,Jisoo Lee,Sae Won Choi,Chang Wook Jeong,Ho-Geol Ryu,Hongyeol Lee,Hyun-Lim Yang*

Main category: cs.LG

TL;DR: MORE-CLEAR框架利用预训练大语言模型（LLM）从临床笔记中提取语义信息，结合多模态数据提升脓毒症管理的强化学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要依赖结构化数据，缺乏对患者病情的全面理解，MORE-CLEAR旨在通过多模态数据提升状态表示和治疗效果。

Method: 采用LLM提取临床笔记的语义表示，结合门控融合和跨模态注意力动态整合多模态数据。

Result: 在公开和私有数据集上验证，MORE-CLEAR显著提升生存率和策略性能，优于单模态方法。

Conclusion: MORE-CLEAR首次将LLM能力引入多模态离线强化学习，为脓毒症管理提供了更全面的患者状态表示，有望优化治疗方案。

Abstract: Sepsis, a life-threatening inflammatory response to infection, causes organ
dysfunction, making early detection and optimal management critical. Previous
reinforcement learning (RL) approaches to sepsis management rely primarily on
structured data, such as lab results or vital signs, and on a dearth of a
comprehensive understanding of the patient's condition. In this work, we
propose a Multimodal Offline REinforcement learning for Clinical notes
Leveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis
control in intensive care units. MORE-CLEAR employs pre-trained large-scale
language models (LLMs) to facilitate the extraction of rich semantic
representations from clinical notes, preserving clinical context and improving
patient state representation. Gated fusion and cross-modal attention allow
dynamic weight adjustment in the context of time and the effective integration
of multimodal data. Extensive cross-validation using two public (MIMIC-III and
MIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly
improves estimated survival rate and policy performance compared to
single-modal RL approaches. To our knowledge, this is the first to leverage LLM
capabilities within a multimodal offline RL for better state representation in
medical applications. This approach can potentially expedite the treatment and
management of sepsis by enabling reinforcement learning models to propose
enhanced actions based on a more comprehensive understanding of patient
conditions.

</details>


### [508] [Semantic-Enhanced Time-Series Forecasting via Large Language Models](https://arxiv.org/abs/2508.07697)
*Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu*

Main category: cs.LG

TL;DR: 提出了一种语义增强的大型语言模型（SE-LLM），通过探索时间序列的周期性和异常特征嵌入语义空间，提升LLM在时间序列预测中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注标记级模态对齐，未能弥合语言知识结构与时间序列数据模式之间的模态差距，限制了语义表示能力。

Method: 提出SE-LLM，将时间序列的周期性和异常特征嵌入语义空间，增强标记嵌入；并设计插件模块，建模长短期依赖关系。

Result: 实验表明SE-LLM优于现有方法。

Conclusion: SE-LLM通过语义增强和依赖关系建模，显著提升了LLM在时间序列分析中的表现。

Abstract: Time series forecasting plays a significant role in finance, energy,
meteorology, and IoT applications. Recent studies have leveraged the
generalization capabilities of large language models (LLMs) to adapt to time
series forecasting, achieving promising performance. However, existing studies
focus on token-level modal alignment, instead of bridging the intrinsic
modality gap between linguistic knowledge structures and time series data
patterns, greatly limiting the semantic representation. To address this issue,
we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent
periodicity and anomalous characteristics of time series to embed into the
semantic space to enhance the token embedding. This process enhances the
interpretability of tokens for LLMs, thereby activating the potential of LLMs
for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel
at capturing long-range dependencies but are weak at modeling short-term
anomalies in time-series data. Hence, we propose a plugin module embedded
within self-attention that models long-term and short-term dependencies to
effectively adapt LLMs to time-series analysis. Our approach freezes the LLM
and reduces the sequence dimensionality of tokens, greatly reducing
computational consumption. Experiments demonstrate the superiority performance
of our SE-LLM against the state-of-the-art (SOTA) methods.

</details>


### [509] [Energy Consumption in Parallel Neural Network Training](https://arxiv.org/abs/2508.07706)
*Philipp Huber,David Li,Juan Pedro Gutiérrez Hermosillo Muriedas,Deifilia Kieckhefen,Markus Götz,Achim Streit,Charlotte Debus*

Main category: cs.LG

TL;DR: 论文研究了并行化训练神经网络对能源消耗的影响，发现能源消耗与GPU小时数近似线性相关，但具体因素因模型和硬件而异。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络训练对计算资源需求的增加，能源消耗问题日益突出，而并行化的能源影响常被忽视。

Method: 通过数据并行训练ResNet50和FourCastNet模型，评估GPU数量、全局批次大小和局部批次大小对性能、训练时间和能源消耗的影响。

Result: 能源消耗与GPU小时数近似线性相关，但具体比例因模型和硬件不同，且受每GPU小时的样本数和梯度更新数影响。

Conclusion: 研究揭示了神经网络训练扩展与能源消耗的复杂关系，为可持续AI研究提供了参考。

Abstract: The increasing demand for computational resources of training neural networks
leads to a concerning growth in energy consumption. While parallelization has
enabled upscaling model and dataset sizes and accelerated training, its impact
on energy consumption is often overlooked. To close this research gap, we
conducted scaling experiments for data-parallel training of two models,
ResNet50 and FourCastNet, and evaluated the impact of parallelization
parameters, i.e., GPU count, global batch size, and local batch size, on
predictive performance, training time, and energy consumption. We show that
energy consumption scales approximately linearly with the consumed resources,
i.e., GPU hours; however, the respective scaling factor differs substantially
between distinct model trainings and hardware, and is systematically influenced
by the number of samples and gradient updates per GPU hour. Our results shed
light on the complex interplay of scaling up neural network training and can
inform future developments towards more sustainable AI research.

</details>


### [510] [Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer](https://arxiv.org/abs/2508.07710)
*Jingya Wang,Xin Deng,Wenjie Wei,Dehao Zhang,Shuai Wang,Qian Sun,Jieyuan Zhang,Hanwen Liu,Ning Xie,Malu Zhang*

Main category: cs.LG

TL;DR: 提出了一种高性能、无需训练的ANN-to-SNN转换框架，通过多基指数衰减神经元（MBE）高效近似Transformer中的非线性操作，显著降低延迟并实现接近无损的转换精度。


<details>
  <summary>Details</summary>
Motivation: 现有ANN-to-SNN转换方法在Transformer架构中处理非线性操作效果不佳，且需额外微调预训练ANN，限制了效率。

Method: 引入多基指数衰减（MBE）神经元，采用指数衰减策略和多基编码方法，无需修改预训练ANN的权重。

Result: 在多种任务（CV、NLU、NLG）和主流Transformer架构（ViT、RoBERTa、GPT-2）上实现接近无损的转换精度和低延迟。

Conclusion: 该方法为Spiking Transformer的高效、可扩展部署提供了可行方案。

Abstract: Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a
promising approach for constructing energy-efficient Transformer architectures.
Compared to directly trained Spiking Transformers, ANN-to-SNN conversion
methods bypass the high training costs. However, existing methods still suffer
from notable limitations, failing to effectively handle nonlinear operations in
Transformer architectures and requiring additional fine-tuning processes for
pre-trained ANNs. To address these issues, we propose a high-performance and
training-free ANN-to-SNN conversion framework tailored for Transformer
architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)
neuron, which employs an exponential decay strategy and multi-basis encoding
method to efficiently approximate various nonlinear operations. It removes the
requirement for weight modifications in pre-trained ANNs. Extensive experiments
across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures
(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless
conversion accuracy with significantly lower latency. This provides a promising
pathway for the efficient and scalable deployment of Spiking Transformers in
real-world applications.

</details>


### [511] [Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information](https://arxiv.org/abs/2508.07713)
*Jinghan Yang,Jiayu Weng*

Main category: cs.LG

TL;DR: 提出了一种基于互信息的数据选择框架，用于处理混合噪声场景，有效过滤低质量样本。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络可能记忆损坏的标签，而现实数据集常受标签噪声和输入噪声影响，数据质量对模型性能至关重要。

Method: 通过计算样本对整体互信息的点贡献，低贡献样本被视为噪声或错误标签实例。

Result: 在MNIST数据集上验证，该方法在标签损坏情况下，训练高互信息样本可将分类准确率提升15%。

Conclusion: 该方法对良性输入修改具有鲁棒性，能保留语义有效数据并过滤真正损坏的样本。

Abstract: Deep neural networks can memorize corrupted labels, making data quality
critical for model performance, yet real-world datasets are frequently
compromised by both label noise and input noise. This paper proposes a mutual
information-based framework for data selection under hybrid noise scenarios
that quantifies statistical dependencies between inputs and labels. We compute
each sample's pointwise contribution to the overall mutual information and find
that lower contributions indicate noisy or mislabeled instances. Empirical
validation on MNIST with different synthetic noise settings demonstrates that
the method effectively filters low-quality samples. Under label corruption,
training on high-MI samples improves classification accuracy by up to 15\%
compared to random sampling. Furthermore, the method exhibits robustness to
benign input modifications, preserving semantically valid data while filtering
truly corrupted samples.

</details>


### [512] [Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning](https://arxiv.org/abs/2508.07738)
*Jialu Zhou,Dianxi Shi,Shaowu Yang,Xinyu Wei,Mingyue Yang,Leqian Li,Mengzhu Wang,Chunping Qiu*

Main category: cs.LG

TL;DR: 论文提出了一种名为TRGE的方法，通过动态扩展预训练模型并引入两级路由机制，解决了多领域持续学习中的灾难性遗忘和前瞻性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 多领域持续学习面临任务类别和分布变化的双重异质性，现有方法难以同时解决灾难性遗忘和前瞻性遗忘。

Method: TRGE方法动态扩展CLIP模型，为每个任务分配专家组，并设计两级路由策略（组内和组间路由）以优化任务协作。同时利用MLLM生成任务描述并识别任务标识符。

Result: 实验表明，TRGE在多种设置下优于其他先进方法，且训练参数更少。

Conclusion: TRGE通过动态路由和任务标识符机制，有效解决了多领域持续学习中的遗忘问题，提升了模型性能。

Abstract: Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential
tasks with shifting class sets and distribution. Despite the
Parameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual
heterogeneity, they still suffer from catastrophic forgetting and forward
forgetting. To address these challenges, we propose a Two-Level Routing Grouped
Mixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the
pre-trained CLIP model, assigning specific expert group for each task to
mitigate catastrophic forgetting. With the number of experts continually grows
in this process, TRGE maintains the static experts count within the group and
introduces the intra-group router to alleviate routing overfitting caused by
the increasing routing complexity. Meanwhile, we design an inter-group routing
policy based on task identifiers and task prototype distance, which dynamically
selects relevant expert groups and combines their outputs to enhance inter-task
collaboration. Secondly, to get the correct task identifiers, we leverage
Multimodal Large Language Models (MLLMs) which own powerful multimodal
comprehension capabilities to generate semantic task descriptions and recognize
the correct task identifier. Finally, to mitigate forward forgetting, we
dynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE
adapter based on training progress, leveraging both pre-trained and learned
knowledge. Through extensive experiments across various settings, our method
outperforms other advanced methods with fewer trainable parameters.

</details>


### [513] [A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory](https://arxiv.org/abs/2508.07746)
*Fengdi Che*

Main category: cs.LG

TL;DR: 该论文探讨了离线强化学习的理论基础及其对算法设计的实际意义，分析了理论条件、数据覆盖假设及算法局限性。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习旨在通过固定数据集优化回报，但理论与实践的脱节仍是挑战。本文旨在通过理论洞察指导算法设计。

Method: 通过列举理论证明所需条件（如函数表示和数据覆盖假设），分析反例及解决挑战的技术。

Result: 揭示了离线强化学习的固有难度及算法的局限性，提出了满足条件的解决方案。

Conclusion: 理论条件不仅是证明工具，也揭示了算法局限，需在条件不满足时寻找新方法。

Abstract: Offline reinforcement learning (RL) aims to optimize the return given a fixed
dataset of agent trajectories without additional interactions with the
environment. While algorithm development has progressed rapidly, significant
theoretical advances have also been made in understanding the fundamental
challenges of offline RL. However, bridging these theoretical insights with
practical algorithm design remains an ongoing challenge. In this survey, we
explore key intuitions derived from theoretical work and their implications for
offline RL algorithms.
  We begin by listing the conditions needed for the proofs, including function
representation and data coverage assumptions. Function representation
conditions tell us what to expect for generalization, and data coverage
assumptions describe the quality requirement of the data. We then examine
counterexamples, where offline RL is not solvable without an impractically
large amount of data. These cases highlight what cannot be achieved for all
algorithms and the inherent hardness of offline RL. Building on techniques to
mitigate these challenges, we discuss the conditions that are sufficient for
offline RL. These conditions are not merely assumptions for theoretical proofs,
but they also reveal the limitations of these algorithms and remind us to
search for novel solutions when the conditions cannot be satisfied.

</details>


### [514] [Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment](https://arxiv.org/abs/2508.07750)
*Haowen Wang,Yun Yue,Zhiling Ye,Shuowen Zhang,Lei Fan,Jiaxin Liang,Jiadi Jiang,Cheng Wei,Jingyuan Deng,Xudong Han,Ji Li,Chunxiao Guo,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.LG

TL;DR: GRAO（Group Relative Alignment Optimization）是一种结合SFT和RL优势的统一框架，通过多样本生成、组内相对优势加权和参考感知参数更新，显著提升了语言模型的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 解决SFT和RL在语言模型对齐中的局限性：SFT受限于离线策略轨迹，RL样本效率低且依赖高质量基础模型。

Method: 提出GRAO框架，包含多样本生成策略、组直接对齐损失和参考感知参数更新。

Result: 在复杂任务中，GRAO比SFT、DPO、PPO和GRPO基线分别提升了57.70%、17.65%、7.95%和5.18%。

Conclusion: GRAO为语言模型对齐提供了理论框架和实证支持，显著提升了效率和性能。

Abstract: Alignment methodologies have emerged as a critical pathway for enhancing
language model alignment capabilities. While SFT (supervised fine-tuning)
accelerates convergence through direct token-level loss intervention, its
efficacy is constrained by offline policy trajectory. In contrast,
RL(reinforcement learning) facilitates exploratory policy optimization, but
suffers from low sample efficiency and stringent dependency on high-quality
base models. To address these dual challenges, we propose GRAO (Group Relative
Alignment Optimization), a unified framework that synergizes the respective
strengths of SFT and RL through three key innovations: 1) A multi-sample
generation strategy enabling comparative quality assessment via reward
feedback; 2) A novel Group Direct Alignment Loss formulation leveraging
intra-group relative advantage weighting; 3) Reference-aware parameter updates
guided by pairwise preference dynamics. Our theoretical analysis establishes
GRAO's convergence guarantees and sample efficiency advantages over
conventional approaches. Comprehensive evaluations across complex human
alignment tasks demonstrate GRAO's superior performance, achieving
57.70\%,17.65\% 7.95\% and 5.18\% relative improvements over SFT, DPO, PPO and
GRPO baselines respectively. This work provides both a theoretically grounded
alignment framework and empirical evidence for efficient capability evolution
in language models.

</details>


### [515] [Sparse Probabilistic Graph Circuits](https://arxiv.org/abs/2508.07763)
*Martin Rektoris,Milan Papež,Václav Šmídl,Tomáš Pevný*

Main category: cs.LG

TL;DR: 论文提出了一种稀疏概率图电路（SPGCs），用于解决现有概率图电路（PGCs）在稠密图表示中复杂度高的问题，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型（DGMs）虽然表达能力强大，但由于非线性特性导致概率推断难以解析计算。PGCs虽解决了这一问题，但其复杂度为O(n²)，限制了在大规模稀疏图中的应用。

Method: 提出稀疏概率图电路（SPGCs），直接操作稀疏图表示，将复杂度降至O(n + m)，适用于边数远小于节点数平方的稀疏图。

Result: 实验证明，SPGCs在药物设计中保留了精确推断能力，提升了内存效率和推断速度，并在关键指标上与不可处理的DGMs性能相当。

Conclusion: SPGCs为稀疏图提供了一种高效且可扩展的生成模型，解决了现有方法在稀疏场景下的计算瓶颈。

Abstract: Deep generative models (DGMs) for graphs achieve impressively high expressive
power thanks to very efficient and scalable neural networks. However, these
networks contain non-linearities that prevent analytical computation of many
standard probabilistic inference queries, i.e., these DGMs are considered
\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)
address this issue by enabling \emph{tractable} probabilistic inference, they
operate on dense graph representations with $\mathcal{O}(n^2)$ complexity for
graphs with $n$ nodes and \emph{$m$ edges}. To address this scalability issue,
we introduce Sparse PGCs, a new class of tractable generative models that
operate directly on sparse graph representation, reducing the complexity to
$\mathcal{O}(n + m)$, which is particularly beneficial for $m \ll n^2$. In the
context of de novo drug design, we empirically demonstrate that SPGCs retain
exact inference capabilities, improve memory efficiency and inference speed,
and match the performance of intractable DGMs in key metrics.

</details>


### [516] [Pareto Multi-Objective Alignment for Language Models](https://arxiv.org/abs/2508.07768)
*Qiang He,Setareh Maghsudi*

Main category: cs.LG

TL;DR: 论文提出了一种名为PAMA的高效多目标对齐算法，用于解决大语言模型（LLMs）在多目标优化（MOA）中的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前基于RLHF的对齐方法仅优化单一奖励函数，导致LLMs行为僵化，无法适应多样的人类偏好，限制了其在实际场景中的适应性。

Method: PAMA将多目标RLHF转化为凸优化问题，提供闭式解，显著降低计算复杂度（从O(n^2*d)降至O(n)）。

Result: 实验证明PAMA在125M至7B参数的LLMs上表现稳健高效，能收敛到Pareto稳定点。

Conclusion: PAMA为MOA问题提供了高效且理论可靠的解决方案，推动了LLMs在实际应用中的多样性和适应性。

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications that require careful balancing of multiple, often conflicting,
objectives, such as informativeness versus conciseness, or helpfulness versus
creativity. However, current alignment methods, primarily based on RLHF,
optimize LLMs toward a single reward function, resulting in rigid behavior that
fails to capture the complexity and diversity of human preferences. This
limitation hinders the adaptability of LLMs to practical scenarios, making
multi-objective alignment (MOA) a critical yet underexplored area. To bridge
this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and
computationally efficient algorithm designed explicitly for MOA in LLMs. In
contrast to computationally prohibitive multi-objective optimization (MOO)
methods, PAMA transforms multi-objective RLHF into a convex optimization with a
closed-form solution, significantly enhancing scalability. Traditional MOO
approaches suffer from prohibitive O(n^2*d) complexity, where d represents the
number of model parameters, typically in the billions for LLMs, rendering
direct optimization infeasible. PAMA reduces this complexity to O(n) where n is
the number of objectives, enabling optimization to be completed within
milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto
stationary point, where no objective can be improved without degrading at least
one other. Extensive experiments across language models ranging from 125M to 7B
parameters demonstrate PAMA's robust and effective MOA capabilities, aligning
with its theoretical advantages. PAMA provides a highly efficient solution to
the MOA problem that was previously considered intractable, offering a
practical and theoretically grounded approach to aligning LLMs with diverse
human values, paving the way for versatile and adaptable real-world AI
deployments.

</details>


### [517] [Topological Feature Compression for Molecular Graph Neural Networks](https://arxiv.org/abs/2508.07807)
*Rahul Khorana*

Main category: cs.LG

TL;DR: 提出一种新型图神经网络架构，结合高阶拓扑信号与标准分子特征，平衡预测准确性、可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决分子表示学习中提取通用化学见解的挑战，同时平衡准确性、可解释性和计算效率。

Method: 引入结合压缩高阶拓扑信号与标准分子特征的GNN架构，捕捉全局几何信息并保持计算可处理性和可解释性。

Result: 在多个基准测试中表现优异，包括小分子和复杂材料数据集，实现了最佳准确性和鲁棒性。

Conclusion: 该架构在分子表示学习中表现出色，代码已开源。

Abstract: Recent advances in molecular representation learning have produced highly
effective encodings of molecules for numerous cheminformatics and
bioinformatics tasks. However, extracting general chemical insight while
balancing predictive accuracy, interpretability, and computational efficiency
remains a major challenge. In this work, we introduce a novel Graph Neural
Network (GNN) architecture that combines compressed higher-order topological
signals with standard molecular features. Our approach captures global
geometric information while preserving computational tractability and
human-interpretable structure. We evaluate our model across a range of
benchmarks, from small-molecule datasets to complex material datasets, and
demonstrate superior performance using a parameter-efficient architecture. We
achieve the best performing results in both accuracy and robustness across
almost all benchmarks. We open source all code \footnote{All code and results
can be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.

</details>


### [518] [EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning](https://arxiv.org/abs/2508.07809)
*Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,Hu XiaoLong,Ge Li*

Main category: cs.LG

TL;DR: EvoCoT提出了一种基于两阶段思维链优化的自进化课程学习框架，通过自生成和验证思维链轨迹来约束探索空间，逐步扩展以解决稀疏奖励下的难题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖更强的LLM进行蒸馏或过滤难题，限制了可扩展性或探索能力。EvoCoT旨在通过自进化课程学习框架解决稀疏奖励导致的探索瓶颈。

Method: EvoCoT通过自生成和验证思维链轨迹约束探索空间，逐步缩短轨迹以扩展空间，使LLM能在稀疏奖励下稳定学习未解决的难题。

Result: 实验表明，EvoCoT使LLM能够解决之前未解决的问题，无需外部思维链监督即可提升推理能力，且兼容多种RL微调方法。

Conclusion: EvoCoT是一种有效的自进化课程学习框架，适用于提升LLM的推理能力，并具有广泛兼容性。

Abstract: Reinforcement learning with verifiable reward (RLVR) has become a promising
paradigm for post-training large language models (LLMs) to improve their
reasoning capability. However, when the rollout accuracy is low on hard
problems, the reward becomes sparse, limiting learning efficiency and causing
exploration bottlenecks. Existing approaches either rely on stronger LLMs for
distillation or filter out difficult problems, which limits scalability or
restricts reasoning improvement through exploration.
  We propose EvoCoT, a self-evolving curriculum learning framework based on
two-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the
exploration space by self-generating and verifying CoT trajectories, then
gradually shortens them to expand the space in a controlled way. This enables
LLMs to stably learn from initially unsolved hard problems under sparse
rewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek,
and Llama. Experiments show that EvoCoT enables LLMs to solve previously
unsolved problems, improves reasoning capability without external CoT
supervision, and is compatible with various RL fine-tuning methods. We release
the source code to support future research.

</details>


### [519] [Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant](https://arxiv.org/abs/2508.07887)
*Sabrina Namazova,Alessandra Brondetta,Younes Strittmatter,Matthew Nassar,Sebastian Musslick*

Main category: cs.LG

TL;DR: 论文探讨了模拟器在科学实践中的重要性，重点评估了Centaur作为行为科学中参与者模拟器的表现。


<details>
  <summary>Details</summary>
Motivation: 模拟器（如AlphaFold）在自然科学中已取得巨大成功，行为科学领域也需要类似工具（参与者模拟器）来加速研究。

Method: 评估了Binz等人提出的Centaur（基于LLM的模型），分析了其作为参与者模拟器的核心标准。

Result: Centaur在预测准确性上表现良好，但在生成行为上与人类数据存在系统性差异。

Conclusion: Centaur是预测人类行为的重要一步，但尚未达到可靠参与者模拟器的标准。

Abstract: Simulators have revolutionized scientific practice across the natural
sciences. By generating data that reliably approximate real-world phenomena,
they enable scientists to accelerate hypothesis testing and optimize
experimental designs. This is perhaps best illustrated by AlphaFold, a
Nobel-prize winning simulator in chemistry that predicts protein structures
from amino acid sequences, enabling rapid prototyping of molecular
interactions, drug targets, and protein functions. In the behavioral sciences,
a reliable participant simulator - a system capable of producing human-like
behavior across cognitive tasks - would represent a similarly transformative
advance. Recently, Binz et al. introduced Centaur, a large language model (LLM)
fine-tuned on human data from 160 experiments, proposing its use not only as a
model of cognition but also as a participant simulator for "in silico
prototyping of experimental studies", e.g., to advance automated cognitive
science. Here, we review the core criteria for a participant simulator and
assess how well Centaur meets them. Although Centaur demonstrates strong
predictive accuracy, its generative behavior - a critical criterion for a
participant simulator - systematically diverges from human data. This suggests
that, while Centaur is a significant step toward predicting human behavior, it
does not yet meet the standards of a reliable participant simulator or an
accurate model of cognition.

</details>


### [520] [Score Augmentation for Diffusion Models](https://arxiv.org/abs/2508.07926)
*Liang Hou,Yuan Gao,Boyuan Jiang,Xin Tao,Qi Yan,Renjie Liao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.LG

TL;DR: 本文提出ScoreAug，一种针对扩散模型的数据增强框架，通过处理噪声数据缓解过拟合问题，并在多个基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模中表现优异，但在数据有限时容易过拟合，需要一种新的数据增强方法。

Method: 提出ScoreAug框架，对噪声数据进行变换，并要求去噪器预测原始目标的增强，实现分数增强。

Result: 在CIFAR-10、FFHQ等基准测试中表现显著优于基线，有效缓解过拟合且稳定收敛。

Conclusion: ScoreAug不仅解决了数据泄漏问题，还能与传统数据增强结合，进一步提升性能。

Abstract: Diffusion models have achieved remarkable success in generative modeling.
However, this study confirms the existence of overfitting in diffusion model
training, particularly in data-limited regimes. To address this challenge, we
propose Score Augmentation (ScoreAug), a novel data augmentation framework
specifically designed for diffusion models. Unlike conventional augmentation
approaches that operate on clean data, ScoreAug applies transformations to
noisy data, aligning with the inherent denoising mechanism of diffusion.
Crucially, ScoreAug further requires the denoiser to predict the augmentation
of the original target. This design establishes an equivariant learning
objective, enabling the denoiser to learn scores across varied denoising
spaces, thereby realizing what we term score augmentation. We also
theoretically analyze the relationship between scores in different spaces under
general transformations. In experiments, we extensively validate ScoreAug on
multiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with
results demonstrating significant performance improvements over baselines.
Notably, ScoreAug effectively mitigates overfitting across diverse scenarios,
such as varying data scales and model capacities, while exhibiting stable
convergence properties. Another advantage of ScoreAug over standard data
augmentation lies in its ability to circumvent data leakage issues under
certain conditions. Furthermore, we show that ScoreAug can be synergistically
combined with traditional data augmentation techniques to achieve additional
performance gains.

</details>


### [521] [Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting](https://arxiv.org/abs/2508.07927)
*Amal Saadallah,Abdulaziz Al-Ademi*

Main category: cs.LG

TL;DR: 提出了一种通过模型适应和选择增强深度神经网络（DNN）性能的新框架，用于非平稳环境中的时间序列预测。


<details>
  <summary>Details</summary>
Motivation: 解决非平稳环境中时间序列预测的挑战，其中底层模式随时间变化。

Method: 离线训练基础DNN，通过验证子集聚类识别不同模式，为每个聚类微调DNN，推理时根据相似度选择模型，并集成概念漂移检测机制。

Result: 在GluonTS库中的传统和先进DNN架构上均表现出显著性能提升。

Conclusion: 该框架通用性强，能有效适应非平稳环境中的时间序列预测需求。

Abstract: Time series forecasting poses significant challenges in non-stationary
environments where underlying patterns evolve over time. In this work, we
propose a novel framework that enhances deep neural network (DNN) performance
by leveraging specialized model adaptation and selection. Initially, a base DNN
is trained offline on historical time series data. A reserved validation subset
is then segmented to extract and cluster the most dominant patterns within the
series, thereby identifying distinct regimes. For each identified cluster, the
base DNN is fine-tuned to produce a specialized version that captures unique
pattern characteristics. At inference, the most recent input is matched against
the cluster centroids, and the corresponding fine-tuned version is deployed
based on the closest similarity measure. Additionally, our approach integrates
a concept drift detection mechanism to identify and adapt to emerging patterns
caused by non-stationary behavior. The proposed framework is generalizable
across various DNN architectures and has demonstrated significant performance
gains on both traditional DNNs and recent advanced architectures implemented in
the GluonTS library.

</details>


### [522] [Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters](https://arxiv.org/abs/2508.07952)
*Richard J. Fawley,Renato Cordeiro de Amorim*

Main category: cs.LG

TL;DR: SHARK是一种基于Shapley值的特征加权聚类算法，无需额外参数，通过分解k均值目标为Shapley值来高效计算特征重要性。


<details>
  <summary>Details</summary>
Motivation: 高维或噪声数据中，传统聚类算法假设所有特征同等重要，导致性能下降，需无需调参的特征加权方法。

Method: 利用Shapley值量化特征重要性，将k均值目标分解为Shapley值之和，迭代调整特征权重。

Result: 在合成和真实数据集上，SHARK表现优于现有方法，尤其在噪声场景下更鲁棒和准确。

Conclusion: SHARK提供了一种无需调参的特征加权聚类方法，显著提升了聚类性能。

Abstract: Clustering algorithms often assume all features contribute equally to the
data structure, an assumption that usually fails in high-dimensional or noisy
settings. Feature weighting methods can address this, but most require
additional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a
feature-weighted clustering algorithm motivated by the use of Shapley values
from cooperative game theory to quantify feature relevance, which requires no
additional parameters beyond those in $k$-means. We prove that the $k$-means
objective can be decomposed into a sum of per-feature Shapley values, providing
an axiomatic foundation for unsupervised feature relevance and reducing Shapley
computation from exponential to polynomial time. SHARK iteratively re-weights
features by the inverse of their Shapley contribution, emphasising informative
dimensions and down-weighting irrelevant ones. Experiments on synthetic and
real-world data sets show that SHARK consistently matches or outperforms
existing methods, achieving superior robustness and accuracy, particularly in
scenarios where noise may be present. Software:
https://github.com/rickfawley/shark.

</details>


### [523] [WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer](https://arxiv.org/abs/2508.07970)
*Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao*

Main category: cs.LG

TL;DR: WeChat-YATT是一种简单、可扩展且平衡的RLHF训练框架，解决了现有框架在复杂多模态工作流和动态负载下的挑战，显著提升了吞吐量和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF训练框架在控制器可扩展性和复杂工作流编排方面存在瓶颈，特别是在动态采样和资源分配场景下效率低下。

Method: 提出WeChat-YATT框架，采用并行控制器编程模型和动态资源分配策略，优化工作流编排和资源利用率。

Result: 实验表明，WeChat-YATT在吞吐量上显著优于现有RLHF框架，并成功应用于微信产品的大规模模型训练。

Conclusion: WeChat-YATT有效解决了RLHF训练中的可扩展性和效率问题，适用于实际应用场景。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent
paradigm for training large language models and multimodal systems. Despite
notable advances enabled by existing RLHF training frameworks, significant
challenges remain in scaling to complex multimodal workflows and adapting to
dynamic workloads. In particular, current systems often encounter limitations
related to controller scalability when managing large models, as well as
inefficiencies in orchestrating intricate RLHF pipelines, especially in
scenarios that require dynamic sampling and resource allocation. In this paper,
we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple,
scalable, and balanced RLHF training framework specifically designed to address
these challenges. WeChat-YATT features a parallel controller programming model
that enables flexible and efficient orchestration of complex RLHF workflows,
effectively mitigating the bottlenecks associated with centralized controller
architectures and facilitating scalability in large-scale data scenarios. In
addition, we propose a dynamic placement schema that adaptively partitions
computational resources and schedules workloads, thereby significantly reducing
hardware idle time and improving GPU utilization under variable training
conditions. We evaluate WeChat-YATT across a range of experimental scenarios,
demonstrating that it achieves substantial improvements in throughput compared
to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been
successfully deployed to train models supporting WeChat product features for a
large-scale user base, underscoring its effectiveness and robustness in
real-world applications.

</details>


### [524] [A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation](https://arxiv.org/abs/2508.08002)
*Hongxin Yu,Yibing Wang,Fengyue Jin,Meng Zhang,Anni Chen*

Main category: cs.LG

TL;DR: 论文提出了一种基于物理信息的深度算子网络（PI-DeepONet）的实时高速公路交通状态估计方法，通过结合模型驱动和数据驱动的优势，显著提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 交通状态估计（TSE）可分为模型驱动、数据驱动和模型-数据双驱动三类。传统方法各有局限，本文旨在结合两者的优势，提出一种更准确的TSE方法。

Method: 扩展了PI-DeepONet架构，支持2-D数据输入、引入非线性扩展层、注意力机制和MIMO机制，并设计了自适应识别交通流模型参数的神经网络。

Result: 在NGSIM短距离高速公路和中国大规模城市快速路的实验中，该方法在流量和平均速度的估计上优于四种基线方法。

Conclusion: 基于扩展PI-DeepONet的TSE方法显著提升了估计精度，为交通状态估计提供了新的解决方案。

Abstract: Traffic state estimation (TSE) falls methodologically into three categories:
model-driven, data-driven, and model-data dual-driven. Model-driven TSE relies
on macroscopic traffic flow models originated from hydrodynamics. Data-driven
TSE leverages historical sensing data and employs statistical models or machine
learning methods to infer traffic state. Model-data dual-driven traffic state
estimation attempts to harness the strengths of both aspects to achieve more
accurate TSE. From the perspective of mathematical operator theory, TSE can be
viewed as a type of operator that maps available measurements of inerested
traffic state into unmeasured traffic state variables in real time. For the
first time this paper proposes to study real-time freeway TSE in the idea of
physics-informed deep operator network (PI-DeepONet), which is an
operator-oriented architecture embedding traffic flow models based on deep
neural networks. The paper has developed an extended architecture from the
original PI-DeepONet. The extended architecture is featured with: (1) the
acceptance of 2-D data input so as to support CNN-based computations; (2) the
introduction of a nonlinear expansion layer, an attention mechanism, and a MIMO
mechanism; (3) dedicated neural network design for adaptive identification of
traffic flow model parameters. A traffic state estimator built on the basis of
this extended PI-DeepONet architecture was evaluated with respect to a short
freeway stretch of NGSIM and a large-scale urban expressway in China, along
with other four baseline TSE methods. The evaluation results demonstrated that
this novel TSE method outperformed the baseline methods with high-precision
estimation results of flow and mean speed.

</details>


### [525] [Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP](https://arxiv.org/abs/2508.08005)
*Xiang Li,Shanshan Wang,Chenglong Xiao*

Main category: cs.LG

TL;DR: 论文提出了一种基于学习的框架，结合传统机器学习和图神经网络，用于解决最大团问题（MCP）的算法选择问题。通过构建标注数据集和特征分析，发现随机森林（RF）表现稳定，并开发了双通道模型GAT-MLP，性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏针对MCP的算法选择方法，且没有单一算法在所有实例中表现最佳。

Method: 构建标注数据集，提取图的特征，评估四种传统分类器，并开发双通道模型GAT-MLP。

Result: RF表现稳定，GAT-MLP在所有指标上表现优异，证明了双通道架构和图神经网络的有效性。

Conclusion: 双通道架构和图神经网络在组合算法选择中具有潜力。

Abstract: Extensive experiments and prior studies show that no single maximum clique
algorithm consistently performs best across all instances, highlighting the
importance of selecting suitable algorithms based on instance features. Through
an extensive analysis of relevant studies, it is found that there is a lack of
research work concerning algorithm selection oriented toward the Maximum Clique
Problem (MCP). In this work, we propose a learning-based framework that
integrates both traditional machine learning and graph neural networks to
address this gap. We construct a labeled dataset by running four exact MCP
algorithms on a diverse collection of graph instances, accompanied by
structural and global statistical features extracted from each graph. We first
evaluate four conventional classifiers: Support Vector Machine (SVM), Random
Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple
dataset variants. Experimental results show that RF consistently shows strong
performance across metrics and dataset variants, making it a reliable baseline.
In addition, feature importance analysis indicates that connectivity and
topological structure are strong predictors of algorithm performance. Building
on these findings, we develop a dual-channel model named GAT-MLP, which
combines a Graph Attention Network (GAT) for local structural encoding with a
Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model
shows strong and consistent performance across all metrics. Our results
highlight the effectiveness of dual-channel architectures and the promise of
graph neural networks in combinatorial algorithm selection.

</details>


### [526] [Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks](https://arxiv.org/abs/2508.08013)
*Mohamad Assaad,Zeinab Nehme,Merouane Debbah*

Main category: cs.LG

TL;DR: 论文提出两种通信高效的联邦学习方法，通过减少通信开销和利用信道信息优化学习算法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中设备与聚合器间的高通信开销是主要挑战，需优化以减少无线系统负担。

Method: 采用零阶优化技术和一阶梯度计算策略，利用信道信息并支持异步设备。

Result: 提供了两种方法的收敛保证和性能界限。

Conclusion: 提出的方法有效减少通信开销并优化学习效率。

Abstract: Federated Learning (FL) is an emerging learning framework that enables edge
devices to collaboratively train ML models without sharing their local data. FL
faces, however, a significant challenge due to the high amount of information
that must be exchanged between the devices and the aggregator in the training
phase, which can exceed the limited capacity of wireless systems. In this
paper, two communication-efficient FL methods are considered where
communication overhead is reduced by communicating scalar values instead of
long vectors and by allowing high number of users to send information
simultaneously. The first approach employs a zero-order optimization technique
with two-point gradient estimator, while the second involves a first-order
gradient computation strategy. The novelty lies in leveraging channel
information in the learning algorithms, eliminating hence the need for
additional resources to acquire channel state information (CSI) and to remove
its impact, as well as in considering asynchronous devices. We provide a
rigorous analytical framework for the two methods, deriving convergence
guarantees and establishing appropriate performance bounds.

</details>


### [527] [Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles](https://arxiv.org/abs/2508.08034)
*Roksana Yahyaabadi,Ghazal Farhani,Taufiq Rahman,Soodeh Nikan,Abdullah Jirjees,Fadi Araji*

Main category: cs.LG

TL;DR: 提出了一种基于数据驱动的方法，结合传统机器学习和深度神经网络，用于预测内燃机、电动车和混合动力车的瞬时及累计功耗，效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统功耗预测方法在大规模实际应用中不实用，需要一种更高效且可扩展的解决方案。

Method: 使用动力系统动态特征集，结合传统机器学习和深度神经网络（如Transformer和LSTM）进行功耗预测。

Result: 内燃机瞬时误差低至$10^{-3}$，累计误差低于3%；电动车和混合动力车累计误差分别低于4.1%和2.1%。

Conclusion: 该方法在多种车型中均表现有效，但电动车和混合动力车的数据变异性更高，需更稳健的模型。

Abstract: Accurate power consumption prediction is crucial for improving efficiency and
reducing environmental impact, yet traditional methods relying on specialized
instruments or rigid physical models are impractical for large-scale,
real-world deployment. This study introduces a scalable data-driven method
using powertrain dynamic feature sets and both traditional machine learning and
deep neural networks to estimate instantaneous and cumulative power consumption
in internal combustion engine (ICE), electric vehicle (EV), and hybrid electric
vehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with
mean absolute error and root mean squared error on the order of $10^{-3}$, and
cumulative errors under 3%. Transformer and long short-term memory models
performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,
respectively. Results confirm the approach's effectiveness across vehicles and
models. Uncertainty analysis revealed greater variability in EV and HEV
datasets than ICE, due to complex power management, emphasizing the need for
robust models for advanced powertrains.

</details>


### [528] [BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models](https://arxiv.org/abs/2508.08040)
*Maozhen Zhang,Mengnan Zhao,Bo Wang*

Main category: cs.LG

TL;DR: 论文提出了一种针对多模态对比模型中基于提示的联邦学习的后门攻击方法BadPromptFL，揭示了该领域的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 研究基于提示的联邦学习在安全方面的不足，填补了多模态学习中后门攻击的研究空白。

Method: 通过联合优化本地后门触发器和提示嵌入，将中毒提示注入全局聚合过程，利用CLIP架构的上下文学习行为实现攻击。

Result: 攻击成功率高达90%以上，且具有隐蔽性和通用性。

Conclusion: BadPromptFL揭示了基于提示的联邦学习在实际部署中的脆弱性，引发了对该技术安全性的关注。

Abstract: Prompt-based tuning has emerged as a lightweight alternative to full
fine-tuning in large vision-language models, enabling efficient adaptation via
learned contextual prompts. This paradigm has recently been extended to
federated learning settings (e.g., PromptFL), where clients collaboratively
train prompts under data privacy constraints. However, the security
implications of prompt-based aggregation in federated multimodal learning
remain largely unexplored, leaving a critical attack surface unaddressed. In
this paper, we introduce \textbf{BadPromptFL}, the first backdoor attack
targeting prompt-based federated learning in multimodal contrastive models. In
BadPromptFL, compromised clients jointly optimize local backdoor triggers and
prompt embeddings, injecting poisoned prompts into the global aggregation
process. These prompts are then propagated to benign clients, enabling
universal backdoor activation at inference without modifying model parameters.
Leveraging the contextual learning behavior of CLIP-style architectures,
BadPromptFL achieves high attack success rates (e.g., \(>90\%\)) with minimal
visibility and limited client participation. Extensive experiments across
multiple datasets and aggregation protocols validate the effectiveness,
stealth, and generalizability of our attack, raising critical concerns about
the robustness of prompt-based federated learning in real-world deployments.

</details>


### [529] [On Understanding of the Dynamics of Model Capacity in Continual Learning](https://arxiv.org/abs/2508.08052)
*Supriyo Chakraborty,Krishnan Raghavan*

Main category: cs.LG

TL;DR: 论文提出了一种称为CLEMC的模型，用于描述持续学习中稳定性与可塑性平衡的动态行为，并通过理论和实验验证了其非平稳性。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中的稳定性与可塑性平衡问题，探讨神经网络在不同任务分布下的表现。

Method: 开发了一个差分方程模型，并通过多种神经网络架构进行实验验证。

Result: 研究表明，无论网络架构或优化方法如何，当新任务分布与之前不同时，神经网络的表示能力会下降。

Conclusion: CLEMC揭示了持续学习中有效容量的动态特性，为未来研究提供了理论基础。

Abstract: The stability-plasticity dilemma, closely related to a neural network's (NN)
capacity-its ability to represent tasks-is a fundamental challenge in continual
learning (CL). Within this context, we introduce CL's effective model capacity
(CLEMC) that characterizes the dynamic behavior of the stability-plasticity
balance point. We develop a difference equation to model the evolution of the
interplay between the NN, task data, and optimization procedure. We then
leverage CLEMC to demonstrate that the effective capacity-and, by extension,
the stability-plasticity balance point is inherently non-stationary. We show
that regardless of the NN architecture or optimization method, a NN's ability
to represent new tasks diminishes when incoming task distributions differ from
previous ones. We conduct extensive experiments to support our theoretical
findings, spanning a range of architectures-from small feedforward network and
convolutional networks to medium-sized graph neural networks and
transformer-based large language models with millions of parameters.

</details>


### [530] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

TL;DR: 提出了一种基于迁移学习的预测流程监控（PPM）技术，帮助资源有限的组织实现有效的决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有PPM技术需要大量事件数据或其他资源，限制了部分组织的应用。本文旨在解决这一问题。

Method: 采用迁移学习技术，将知识从一个业务流程迁移到相似流程，支持跨组织应用。

Result: 实验表明，迁移学习可在同组织或跨组织环境中实现有效的PPM。

Conclusion: 该技术为资源有限的组织提供了PPM解决方案，支持跨组织知识迁移。

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [531] [C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction](https://arxiv.org/abs/2508.08071)
*Yunqing Li,Zixiang Tang,Jiaying Zhuang,Zhenyu Yang,Farhad Ameri,Jianbang Zhang*

Main category: cs.LG

TL;DR: 论文提出PMGraph基准和C-MAG架构，用于解决供应链中制造商与产品匹配的复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉制造商和产品的多模态数据及复杂关系，影响供应链效率。

Method: 提出两阶段架构C-MAG，先对齐多模态属性生成中间嵌入，再通过异构图多尺度消息传递增强链接预测。

Result: 构建了包含8,888制造商和70k产品的PMGraph基准，C-MAG显著提升了链接预测准确性。

Conclusion: C-MAG为多模态融合和供应链优化提供了实用解决方案。

Abstract: Connecting an ever-expanding catalogue of products with suitable
manufacturers and suppliers is critical for resilient, efficient global supply
chains, yet traditional methods struggle to capture complex capabilities,
certifications, geographic constraints, and rich multimodal data of real-world
manufacturer profiles. To address these gaps, we introduce PMGraph, a public
benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking
8,888 manufacturers, over 70k products, more than 110k manufacturer-product
edges, and over 29k product images. Building on this benchmark, we propose the
Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first
aligns and aggregates textual and visual attributes into intermediate group
embeddings, then propagates them through a manufacturer-product hetero-graph
via multiscale message passing to enhance link prediction accuracy. C-MAG also
provides practical guidelines for modality-aware fusion, preserving predictive
performance in noisy, real-world settings.

</details>


### [532] [ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring](https://arxiv.org/abs/2508.08073)
*Dimitris Tsaras,Xing Li,Lei Chen,Zhiyao Xie,Mingxuan Yuan*

Main category: cs.LG

TL;DR: 提出一种基于分类器的预剪枝方法，显著减少逻辑优化中的无效操作，速度提升3.9倍。


<details>
  <summary>Details</summary>
Motivation: 传统逻辑优化操作计算成本高，且98%的尝试无效，需减少无效操作。

Method: 利用分类器预判并剪枝无效的切割操作，避免不必要的重合成。

Result: 在EPFL基准和10个工业设计上测试，速度提升3.9倍。

Conclusion: 分类器预剪枝方法高效，显著提升逻辑优化速度。

Abstract: In electronic design automation, logic optimization operators play a crucial
role in minimizing the gate count of logic circuits. However, their computation
demands are high. Operators such as refactor conventionally form iterative cuts
for each node, striving for a more compact representation - a task which often
fails 98% on average. Prior research has sought to mitigate computational cost
through parallelization. In contrast, our approach leverages a classifier to
prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis
operations. Experiments on the refactor operator using the EPFL benchmark suite
and 10 large industrial designs demonstrate that this technique can speedup
logic optimization by 3.9x on average compared with the state-of-the-art ABC
implementation.

</details>


### [533] [Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation](https://arxiv.org/abs/2508.08087)
*Amir Ali Panahi,Daniel Luder,Billy Wu,Gregory Offer,Dirk Uwe Sauer,Weihan Li*

Main category: cs.LG

TL;DR: 论文提出了一种参数嵌入傅里叶神经算子（PE-FNO），用于锂离子电池的数字孪生，实现了高物理保真度和亚毫秒级速度。


<details>
  <summary>Details</summary>
Motivation: 构建高保真且快速的锂离子电池数字孪生模型，以满足实时电池管理和大规模推断的需求。

Method: 比较了DeepONet、FNO和新提出的PE-FNO三种算子学习方法，训练数据覆盖多种电流模式和全SOC范围。

Result: PE-FNO在动态负载下表现优异，误差低于1%，速度比传统方法快200倍，并成功应用于参数估计任务。

Conclusion: PE-FNO为高保真、快速的电池数字孪生提供了实用解决方案，优于传统神经网络方法。

Abstract: Reliable digital twins of lithium-ion batteries must achieve high physical
fidelity with sub-millisecond speed. In this work, we benchmark three
operator-learning surrogates for the Single Particle Model (SPM): Deep Operator
Networks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed
parameter-embedded Fourier Neural Operator (PE-FNO), which conditions each
spectral layer on particle radius and solid-phase diffusivity. Models are
trained on simulated trajectories spanning four current families (constant,
triangular, pulse-train, and Gaussian-random-field) and a full range of
State-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates
constant-current behaviour but struggles with more dynamic loads. The basic FNO
maintains mesh invariance and keeps concentration errors below 1 %, with
voltage mean-absolute errors under 1.7 mV across all load types. Introducing
parameter embedding marginally increases error, but enables generalisation to
varying radii and diffusivities. PE-FNO executes approximately 200 times faster
than a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse
tasks are explored in a parameter estimation task with Bayesian optimisation,
recovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute
percentage error, respectively, and 0.5918 percentage points higher error in
comparison with classical methods. These results pave the way for neural
operators to meet the accuracy, speed and parametric flexibility demands of
real-time battery management, design-of-experiments and large-scale inference.
PE-FNO outperforms conventional neural surrogates, offering a practical path
towards high-speed and high-fidelity electrochemical digital twins.

</details>


### [534] [Grid2Guide: A* Enabled Small Language Model for Indoor Navigation](https://arxiv.org/abs/2508.08100)
*Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: Grid2Guide结合A*算法和小型语言模型（SLM），提供清晰、易读的室内导航指令。


<details>
  <summary>Details</summary>
Motivation: 复杂环境中缺乏外部定位信号和专用基础设施，导致室内导航不可靠。

Method: 通过二进制占用矩阵和A*算法计算最优路径，再用SLM将路径转换为自然语言指令。

Result: 实验证明该方法能生成准确、及时的导航指导。

Conclusion: Grid2Guide是一种轻量级、无需基础设施的实时室内导航解决方案。

Abstract: Reliable indoor navigation remains a significant challenge in complex
environments, particularly where external positioning signals and dedicated
infrastructures are unavailable. This research presents Grid2Guide, a hybrid
navigation framework that combines the A* search algorithm with a Small
Language Model (SLM) to generate clear, human-readable route instructions. The
framework first conducts a binary occupancy matrix from a given indoor map.
Using this matrix, the A* algorithm computes the optimal path between origin
and destination, producing concise textual navigation steps. These steps are
then transformed into natural language instructions by the SLM, enhancing
interpretability for end users. Experimental evaluations across various indoor
scenarios demonstrate the method's effectiveness in producing accurate and
timely navigation guidance. The results validate the proposed approach as a
lightweight, infrastructure-free solution for real-time indoor navigation
support.

</details>


### [535] [Vision-Based Localization and LLM-based Navigation for Indoor Environments](https://arxiv.org/abs/2508.08120)
*Keyan Rahimi,Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: 该研究提出了一种结合视觉定位和大型语言模型（LLM）导航的室内导航方法，定位准确率达96%，导航指令准确率为75%。


<details>
  <summary>Details</summary>
Motivation: 解决室内环境中GPS信号不可靠和建筑结构复杂导致的导航难题。

Method: 使用ResNet-50卷积神经网络进行视觉定位，并结合LLM生成导航指令。

Result: 定位准确率96%，导航指令准确率75%。

Conclusion: 展示了利用普通摄像头和公开平面图实现可扩展、无需基础设施的室内导航潜力。

Abstract: Indoor navigation remains a complex challenge due to the absence of reliable
GPS signals and the architectural intricacies of large enclosed environments.
This study presents an indoor localization and navigation approach that
integrates vision-based localization with large language model (LLM)-based
navigation. The localization system utilizes a ResNet-50 convolutional neural
network fine-tuned through a two-stage process to identify the user's position
using smartphone camera input. To complement localization, the navigation
module employs an LLM, guided by a carefully crafted system prompt, to
interpret preprocessed floor plan images and generate step-by-step directions.
Experimental evaluation was conducted in a realistic office corridor with
repetitive features and limited visibility to test localization robustness. The
model achieved high confidence and an accuracy of 96% across all tested
waypoints, even under constrained viewing conditions and short-duration
queries. Navigation tests using ChatGPT on real building floor maps yielded an
average instruction accuracy of 75%, with observed limitations in zero-shot
reasoning and inference time. This research demonstrates the potential for
scalable, infrastructure-free indoor navigation using off-the-shelf cameras and
publicly available floor plans, particularly in resource-constrained settings
like hospitals, airports, and educational institutions.

</details>


### [536] [MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing](https://arxiv.org/abs/2508.08122)
*Mingrong Lin,Ke Deng,Zhengyang Wu,Zetao Zheng,Jie Li*

Main category: cs.LG

TL;DR: 论文提出memoryKT模型，通过三阶段记忆动态模拟（编码、存储、检索）提升知识追踪性能，并嵌入个性化遗忘模块，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪模型依赖单一遗忘机制，忽视记忆过程的其他阶段及个性化遗忘模式，限制了性能和可解释性。

Method: 提出基于时间变分自编码器的memoryKT模型，模拟记忆三阶段动态：学习知识记忆特征分布、重构练习反馈、嵌入个性化遗忘模块。

Result: 在四个公开数据集上的实验表明，memoryKT显著优于现有基线方法。

Conclusion: memoryKT通过完整模拟记忆周期并引入个性化遗忘机制，提升了知识追踪的性能和个体差异感知能力。

Abstract: Knowledge Tracing (KT) is committed to capturing students' knowledge mastery
from their historical interactions. Simulating students' memory states is a
promising approach to enhance both the performance and interpretability of
knowledge tracing models. Memory consists of three fundamental processes:
encoding, storage, and retrieval. Although forgetting primarily manifests
during the storage stage, most existing studies rely on a single,
undifferentiated forgetting mechanism, overlooking other memory processes as
well as personalized forgetting patterns. To address this, this paper proposes
memoryKT, a knowledge tracing model based on a novel temporal variational
autoencoder. The model simulates memory dynamics through a three-stage process:
(i) Learning the distribution of students' knowledge memory features, (ii)
Reconstructing their exercise feedback, while (iii) Embedding a personalized
forgetting module within the temporal workflow to dynamically modulate memory
storage strength. This jointly models the complete encoding-storage-retrieval
cycle, significantly enhancing the model's perception capability for individual
differences. Extensive experiments on four public datasets demonstrate that our
proposed approach significantly outperforms state-of-the-art baselines.

</details>


### [537] [NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection](https://arxiv.org/abs/2508.08124)
*Guanghao Jin,Yuan Liang,Yihan Ma,Jingpei Wu,Guoyang Liu*

Main category: cs.LG

TL;DR: NeuroDx-LM是一种针对EEG神经障碍检测的大规模模型，通过选择性时频嵌入和渐进特征感知训练策略，解决了标记数据不足和临床性能不佳的问题，在CHB-MIT和精神分裂症数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决EEG大规模模型在临床应用中面临的标记数据不足和性能不佳的挑战。

Method: 提出选择性时频嵌入机制和渐进特征感知训练策略，分两阶段学习EEG信号特征。

Result: 在CHB-MIT和精神分裂症数据集上实现了最先进的检测性能。

Conclusion: NeuroDx-LM展示了EEG大规模模型在临床应用的潜力。

Abstract: Large-scale models pre-trained on Electroencephalography (EEG) have shown
promise in clinical applications such as neurological disorder detection.
However, the practical deployment of EEG-based large-scale models faces
critical challenges such as limited labeled EEG data and suboptimal performance
in clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel
large-scale model specifically designed for detecting EEG-based neurological
disorders. Our key contributions include (i) a Selective Temporal-Frequency
Embedding mechanism that adaptively captures complex temporal and spectral
patterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy
that refines feature representation in a two-stage process. In the first stage,
our model learns the fundamental discriminative features of EEG activities; in
the second stage, the model further extracts more specialized fine-grained
features for accurate diagnostic performance. We evaluated NeuroDx-LM on the
CHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in
EEG-based seizure and schizophrenia detection, respectively. These results
demonstrate the great potential of EEG-based large-scale models to advance
clinical applicability. Our code is available at
https://github.com/LetItBe12345/NeuroDx-LM.

</details>


### [538] [OFAL: An Oracle-Free Active Learning Framework](https://arxiv.org/abs/2508.08126)
*Hadi Khorsand,Vahid Pourahmadi*

Main category: cs.LG

TL;DR: OFAL是一种无需人工标注的主动学习方法，利用神经网络不确定性生成信息丰富的样本。


<details>
  <summary>Details</summary>
Motivation: 人工标注数据成本高且复杂，特别是在大规模未标注数据池中，研究目标是减少对标注者的依赖。

Method: 1. 分离和量化不确定性，使用蒙特卡洛Dropout近似贝叶斯神经网络；2. 通过变分自编码器生成新的不确定样本；3. 与其他主动学习方法对比和整合。

Result: 通过生成信息丰富的样本，提高了模型的准确性。

Conclusion: OFAL提供了一种有效的无标注者主动学习方案，能够提升模型性能。

Abstract: In the active learning paradigm, using an oracle to label data has always
been a complex and expensive task, and with the emersion of large unlabeled
data pools, it would be highly beneficial If we could achieve better results
without relying on an oracle. This research introduces OFAL, an oracle-free
active learning scheme that utilizes neural network uncertainty. OFAL uses the
model's own uncertainty to transform highly confident unlabeled samples into
informative uncertain samples. First, we start with separating and quantifying
different parts of uncertainty and introduce Monte Carlo Dropouts as an
approximation of the Bayesian Neural Network model. Secondly, by adding a
variational autoencoder, we go on to generate new uncertain samples by stepping
toward the uncertain part of latent space starting from a confidence seed
sample. By generating these new informative samples, we can perform active
learning and enhance the model's accuracy. Lastly, we try to compare and
integrate our method with other widely used active learning sampling methods.

</details>


### [539] [FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks](https://arxiv.org/abs/2508.08151)
*Moses Openja,Paolo Arcaini,Foutse Khomh,Fuyuki Ishikawa*

Main category: cs.LG

TL;DR: FairFLRep是一种自动化公平性感知的故障定位与修复技术，用于识别和修正DNN分类器中可能导致偏见的神经元。


<details>
  <summary>Details</summary>
Motivation: DNN在高风险决策应用中可能因训练数据偏见导致不公平行为，现有方法难以有效识别和修正这些偏见。

Method: 通过调整与敏感属性（如种族或性别）相关的神经元权重，分析网络输入输出关系以修正偏见。

Result: 在多个数据集和DNN模型上，FairFLRep在提升公平性同时保持准确性，且效率优于基线方法。

Conclusion: FairFLRep在故障定位和修复阶段均需考虑公平性，其高效性和有效性为DNN公平性修正提供了新方向。

Abstract: Deep neural networks (DNNs) are being utilized in various aspects of our
daily lives, including high-stakes decision-making applications that impact
individuals. However, these systems reflect and amplify bias from the data used
during training and testing, potentially resulting in biased behavior and
inaccurate decisions. For instance, having different misclassification rates
between white and black sub-populations. However, effectively and efficiently
identifying and correcting biased behavior in DNNs is a challenge. This paper
introduces FairFLRep, an automated fairness-aware fault localization and repair
technique that identifies and corrects potentially bias-inducing neurons in DNN
classifiers. FairFLRep focuses on adjusting neuron weights associated with
sensitive attributes, such as race or gender, that contribute to unfair
decisions. By analyzing the input-output relationships within the network,
FairFLRep corrects neurons responsible for disparities in predictive quality
parity. We evaluate FairFLRep on four image classification datasets using two
DNN classifiers, and four tabular datasets with a DNN model. The results show
that FairFLRep consistently outperforms existing methods in improving fairness
while preserving accuracy. An ablation study confirms the importance of
considering fairness during both fault localization and repair stages. Our
findings also show that FairFLRep is more efficient than the baseline
approaches in repairing the network.

</details>


### [540] [Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets](https://arxiv.org/abs/2508.08159)
*Cem Ata Baykara,Saurav Raj Pandey,Ali Burak Ünal,Harlin Lee,Mete Akgün*

Main category: cs.LG

TL;DR: 该论文提出了一种基于联邦学习的癫痫发作预测方法，通过随机子集聚合策略解决数据异质性问题，显著提升了模型在代表性不足数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 由于患者隐私法规和数据异质性（非IID特性），开发跨多个临床站点的癫痫发作预测模型面临挑战。联邦学习提供了一种隐私保护的协作训练框架，但标准聚合方法在异质环境中可能偏向主导数据集。

Method: 论文采用单通道EEG数据，在四个公共数据集上实施隐私保护的全局归一化，并提出随机子集聚合策略，确保每个客户端在每轮训练中贡献相等。

Result: 结果显示，标准加权FedAvg在代表性不足的数据集上性能较差（如Helsinki和NCH准确率仅50%左右），而随机子集聚合显著提升了这些数据集的性能（准确率分别提升至81.7%和68.7%），并实现了77.1%的宏平均准确率和80.0%的总体准确率。

Conclusion: 该研究表明，平衡的联邦学习方法能够在尊重数据隐私的同时，构建有效且泛化性强的癫痫发作预测系统，适用于现实中的多医院异质环境。

Abstract: Developing accurate and generalizable epileptic seizure prediction models
from electroencephalography (EEG) data across multiple clinical sites is
hindered by patient privacy regulations and significant data heterogeneity
(non-IID characteristics). Federated Learning (FL) offers a privacy-preserving
framework for collaborative training, but standard aggregation methods like
Federated Averaging (FedAvg) can be biased by dominant datasets in
heterogeneous settings. This paper investigates FL for seizure prediction using
a single EEG channel across four diverse public datasets (Siena, CHB-MIT,
Helsinki, NCH), representing distinct patient populations (adult, pediatric,
neonate) and recording conditions. We implement privacy-preserving global
normalization and propose a Random Subset Aggregation strategy, where each
client trains on a fixed-size random subset of its data per round, ensuring
equal contribution during aggregation. Our results show that locally trained
models fail to generalize across sites, and standard weighted FedAvg yields
highly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on
Helsinki and 50.6% on NCH). In contrast, Random Subset Aggregation
significantly improves performance on under-represented clients (accuracy
increases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior
macro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites,
demonstrating a more robust and fair global model. This work highlights the
potential of balanced FL approaches for building effective and generalizable
seizure prediction systems in realistic, heterogeneous multi-hospital
environments while respecting data privacy.

</details>


### [541] [Neural Logic Networks for Interpretable Classification](https://arxiv.org/abs/2508.08172)
*Vincent Perreault,Katsumi Inoue,Richard Labib,Alain Hertz*

Main category: cs.LG

TL;DR: 论文提出了一种可解释的神经网络（Neural Logic Networks），通过逻辑操作（AND、OR、NOT）和概率建模，改进了布尔网络的发现方法，并在医学分类任务中展示了其可解释性价值。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络虽然分类性能强，但缺乏可解释性。本文旨在开发一种可解释的神经网络结构，通过学习逻辑机制（如AND、OR、NOT操作）来关联输入和输出。

Method: 提出了一种广义的Neural Logic Networks，引入NOT操作和偏差项以处理未观测数据，并设计了因子化的IF-THEN规则结构和改进的学习算法。

Result: 该方法在布尔网络发现领域达到最先进水平，并在表格分类任务（如医学领域）中学习到相关且可解释的规则。

Conclusion: Neural Logic Networks通过逻辑和概率建模，提供了一种可解释的替代方案，特别适用于需要透明决策的领域（如医疗）。

Abstract: Traditional neural networks have an impressive classification performance,
but what they learn cannot be inspected, verified or extracted. Neural Logic
Networks on the other hand have an interpretable structure that enables them to
learn a logical mechanism relating the inputs and outputs with AND and OR
operations. We generalize these networks with NOT operations and biases that
take into account unobserved data and develop a rigorous logical and
probabilistic modeling in terms of concept combinations to motivate their use.
We also propose a novel factorized IF-THEN rule structure for the model as well
as a modified learning algorithm. Our method improves the state-of-the-art in
Boolean networks discovery and is able to learn relevant, interpretable rules
in tabular classification, notably on an example from the medical field where
interpretability has tangible value.

</details>


### [542] [Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion](https://arxiv.org/abs/2508.08216)
*Nicole Lai-Tan,Xiao Gu,Marios G. Philiastides,Fani Deligianni*

Main category: cs.LG

TL;DR: 论文提出了一种名为ITSA的新方法，通过结合主题特定的重新中心化、分布匹配和监督旋转对齐，提升跨主题的脑机接口通用性。


<details>
  <summary>Details</summary>
Motivation: 脑机接口（BCI）在个性化音乐干预中具有潜力，但受限于EEG信号的个体差异和运动伪影，导致通用性不足和校准过程冗长。

Method: 提出ITSA预对齐策略，结合RCSP和黎曼几何的混合架构，通过并行和顺序配置增强分类分离性。

Result: ITSA在跨主题和条件下表现出显著性能提升，并行融合方法效果最佳。

Conclusion: ITSA为提升BCI通用性提供了有效解决方案，代码将公开。

Abstract: Personalised music-based interventions offer a powerful means of supporting
motor rehabilitation by dynamically tailoring auditory stimuli to provide
external timekeeping cues, modulate affective states, and stabilise gait
patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for
adapting these interventions across individuals. However, inter-subject
variability in EEG signals, further compounded by movement-induced artefacts
and motor planning differences, hinders the generalisability of BCIs and
results in lengthy calibration processes. We propose Individual Tangent Space
Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific
recentering, distribution matching, and supervised rotational alignment to
enhance cross-subject generalisation. Our hybrid architecture fuses Regularised
Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and
sequential configurations, improving class separability while maintaining the
geometric structure of covariance matrices for robust statistical computation.
Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant
performance improvements across subjects and conditions. The parallel fusion
approach shows the greatest enhancement over its sequential counterpart, with
robust performance maintained across varying data conditions and electrode
configurations. The code will be made publicly available at the time of
publication.

</details>


### [543] [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221)
*Zihe Liu,Jiashun Liu,Yancheng He,Weixun Wang,Jiaheng Liu,Ling Pan,Xinyu Hu,Shaopan Xiong,Ju Huang,Jian Hu,Shengyi Huang,Siran Yang,Jiamang Wang,Wenbo Su,Bo Zheng*

Main category: cs.LG

TL;DR: 本文系统综述了强化学习在LLM推理中的应用，通过统一框架分析了不同技术的机制、适用场景和核心原则，并提出了选择技术的指南。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在LLM推理领域发展迅速，但缺乏标准化指南和对其机制的深入理解，导致实验结果不一致和技术选择困难。

Method: 通过严格的复现和孤立评估，在统一开源框架中分析不同RL技术，包括数据集难度、模型规模和架构。

Result: 研究发现，两种技术的简约组合可以提升性能，超越GRPO和DAPO等策略。

Conclusion: 本文提供了RL技术在LLM领域的选择指南，并展示了简约组合的优越性。

Abstract: Reinforcement learning for LLM reasoning has rapidly emerged as a prominent
research area, marked by a significant surge in related studies on both
algorithmic innovations and practical applications. Despite this progress,
several critical challenges remain, including the absence of standardized
guidelines for employing RL techniques and a fragmented understanding of their
underlying mechanisms. Additionally, inconsistent experimental settings,
variations in training data, and differences in model initialization have led
to conflicting conclusions, obscuring the key characteristics of these
techniques and creating confusion among practitioners when selecting
appropriate techniques. This paper systematically reviews widely adopted RL
techniques through rigorous reproductions and isolated evaluations within a
unified open-source framework. We analyze the internal mechanisms, applicable
scenarios, and core principles of each technique through fine-grained
experiments, including datasets of varying difficulty, model sizes, and
architectures. Based on these insights, we present clear guidelines for
selecting RL techniques tailored to specific setups, and provide a reliable
roadmap for practitioners navigating the RL for the LLM domain. Finally, we
reveal that a minimalist combination of two techniques can unlock the learning
capability of critic-free policies using vanilla PPO loss. The results
demonstrate that our simple combination consistently improves performance,
surpassing strategies like GRPO and DAPO.

</details>


### [544] [Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent](https://arxiv.org/abs/2508.08222)
*Tong Yang,Yu Huang,Yingbin Liang,Yuejie Chi*

Main category: cs.LG

TL;DR: 该论文研究了Transformer如何通过训练学习解决符号多步推理问题，特别是树中的路径查找任务，揭示了其梯度下降动态如何实现泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer通过训练获得多步推理能力的机制，尤其是从理论角度分析其如何通过链式思维过程解决复杂任务。

Method: 分析两个任务：反向推理（输出目标节点到根的路径）和更复杂的前向推理（先识别目标到根路径，再反转得到根到目标路径），基于梯度下降动态进行理论分析。

Result: 训练后的一层Transformer可以解决这两个任务，并具有对未见树的泛化能力；多阶段训练动态揭示了注意力头如何自主分工协作。

Conclusion: 研究揭示了Transformer如何实现顺序算法过程，表明即使浅层多头Transformer也能通过结构化任务解决复杂问题。

Abstract: Transformers have demonstrated remarkable capabilities in multi-step
reasoning tasks. However, understandings of the underlying mechanisms by which
they acquire these abilities through training remain limited, particularly from
a theoretical standpoint. This work investigates how transformers learn to
solve symbolic multi-step reasoning problems through chain-of-thought
processes, focusing on path-finding in trees. We analyze two intertwined tasks:
a backward reasoning task, where the model outputs a path from a goal node to
the root, and a more complex forward reasoning task, where the model implements
two-stage reasoning by first identifying the goal-to-root path and then
reversing it to produce the root-to-goal path. Our theoretical analysis,
grounded in the dynamics of gradient descent, shows that trained one-layer
transformers can provably solve both tasks with generalization guarantees to
unseen trees. In particular, our multi-phase training dynamics for forward
reasoning elucidate how different attention heads learn to specialize and
coordinate autonomously to solve the two subtasks in a single autoregressive
path. These results provide a mechanistic explanation of how trained
transformers can implement sequential algorithmic procedures. Moreover, they
offer insights into the emergence of reasoning abilities, suggesting that when
tasks are structured to take intermediate chain-of-thought steps, even shallow
multi-head transformers can effectively solve problems that would otherwise
require deeper architectures.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [545] [Reservoir computing with large valid prediction time for the Lorenz system](https://arxiv.org/abs/2508.06730)
*Lauren A Hurley,Sean E Shaheen*

Main category: cs.NE

TL;DR: 研究了储层计算机（RC）的预测时间（VPT）与超参数的关系，发现在特定条件下可达到基准性能的70%，并提出基于Lyapunov指数的高效评估方法。


<details>
  <summary>Details</summary>
Motivation: 探索RC在无噪声系统中的预测性能及其超参数依赖性，为实际应用提供理论支持。

Method: 通过调整正则化系数、储层大小和谱半径等超参数，结合Lyapunov指数分析预测误差。

Result: 在无噪声系统中获得高VPT（>30 Lyapunov时间），并发现两种谱半径范围可实现高VPT。

Conclusion: RC在特定条件下表现优异，但需注意数值求解器对结果的影响，且VPT超过VGTT时结果不可靠。

Abstract: We study the dependence of the Valid Prediction Time (VPT) of Reservoir
Computers (RCs) on hyperparameters including the regularization coefficient,
reservoir size, and spectral radius. Under carefully chosen conditions, the RC
can achieve approximately 70% of a benchmark performance, based on the output
of a single prediction step used as initial conditions for the Lorenz
equations. We report high VPT values (>30 Lyapunov times), as we are predicting
a noiseless system where overfitting can be beneficial. While these conditions
may not hold for noisy systems, they could still be useful for real-world
applications with limited noise. Furthermore, utilizing knowledge of the
Lyapunov exponent, we find that the VPT can be predicted by the error in the
first few prediction steps, offering a computationally efficient evaluation
method. We emphasize the importance of the numerical solver used to generate
the Lorenz dataset and define a Valid Ground Truth Time (VGTT), during which
the outputs of several common solvers agree. A VPT exceeding the VGTT is not
meaningful, as a different solver could produce a different result. Lastly, we
identify two spectral radius regimes that achieve large VPT: a small radius
near zero, resulting in simple but stable operation, and a larger radius
operating at the "edge of chaos."

</details>


### [546] [Geometry-Aware Spiking Graph Neural Network](https://arxiv.org/abs/2508.06793)
*Bowen Zhang,Genan Dai,Hu Huang,Long Lan*

Main category: cs.NE

TL;DR: 提出了一种几何感知的脉冲图神经网络（GSG），结合了脉冲动态和黎曼流形上的自适应表示学习，解决了现有方法在复杂图结构建模中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的脉冲图神经网络主要在欧几里得空间中运行，依赖固定几何假设，难以建模复杂图结构（如层次和循环）。

Method: GSG包含三个关键组件：黎曼嵌入层、流形脉冲层和流形学习目标，通过黎曼SGD训练。

Result: 实验表明，GSG在准确性、鲁棒性和能效上优于欧几里得SNN和基于流形的GNN。

Conclusion: GSG为曲率感知、高效能的图学习建立了新范式。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive capabilities in
modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high
energy efficiency through sparse, event-driven computation. However, existing
spiking GNNs predominantly operate in Euclidean space and rely on fixed
geometric assumptions, limiting their capacity to model complex graph
structures such as hierarchies and cycles. To overcome these limitations, we
propose \method{}, a novel Geometry-Aware Spiking Graph Neural Network that
unifies spike-based neural dynamics with adaptive representation learning on
Riemannian manifolds. \method{} features three key components: a Riemannian
Embedding Layer that projects node features into a pool of constant-curvature
manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that
models membrane potential evolution and spiking behavior in curved spaces via
geometry-consistent neighbor aggregation and curvature-based attention; and a
Manifold Learning Objective that enables instance-wise geometry adaptation
through jointly optimized classification and link prediction losses defined
over geodesic distances. All modules are trained using Riemannian SGD,
eliminating the need for backpropagation through time. Extensive experiments on
multiple benchmarks show that GSG achieves superior accuracy, robustness, and
energy efficiency compared to both Euclidean SNNs and manifold-based GNNs,
establishing a new paradigm for curvature-aware, energy-efficient graph
learning.

</details>


### [547] [Memory Enhanced Fractional-Order Dung Beetle Optimization for Photovoltaic Parameter Identification](https://arxiv.org/abs/2508.06841)
*Yiwei Li,Zhihua Allen-Zhao,Yuncheng Xu,Sanyang Liu*

Main category: cs.NE

TL;DR: 提出了一种改进的MFO-DBO算法，结合分数阶微积分、混沌映射和扰动机制，显著提升了光伏模型参数识别的准确性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 光伏模型参数识别因非线性、多模态和高维特性而具有挑战性，现有DBO算法易陷入早熟收敛。

Method: 结合分数阶微积分引入记忆性、分数阶逻辑混沌映射增强种群多样性、混沌扰动机制避免局部最优。

Result: 在CEC2017基准和光伏参数识别问题上，MFO-DBO优于多种先进算法，表现出更高的精度、鲁棒性和收敛速度。

Conclusion: MFO-DBO算法在探索与开发间取得良好平衡，显著提升了标准DBO的性能。

Abstract: Accurate parameter identification in photovoltaic (PV) models is crucial for
performance evaluation but remains challenging due to their nonlinear,
multimodal, and high-dimensional nature. Although the Dung Beetle Optimization
(DBO) algorithm has shown potential in addressing such problems, it often
suffers from premature convergence. To overcome these issues, this paper
proposes a Memory Enhanced Fractional-Order Dung Beetle Optimization (MFO-DBO)
algorithm that integrates three coordinated strategies. Firstly,
fractional-order (FO) calculus introduces memory into the search process,
enhancing convergence stability and solution quality. Secondly, a
fractional-order logistic chaotic map improves population diversity during
initialization. Thirdly, a chaotic perturbation mechanism helps elite solutions
escape local optima. Numerical results on the CEC2017 benchmark suite and the
PV parameter identification problem demonstrate that MFO-DBO consistently
outperforms advanced DBO variants, CEC competition winners, FO-based
optimizers, enhanced classical algorithms, and recent metaheuristics in terms
of accuracy, robustness, convergence speed, while also maintaining an excellent
balance between exploration and exploitation compared to the standard DBO
algorithm.

</details>


### [548] [Enhancing Decision Space Diversity in Multi-Objective Evolutionary Optimization for the Diet Problem](https://arxiv.org/abs/2508.07077)
*Gustavo V. Nascimento,Ivan R. Meneghini,Valéria Santos,Eduardo Luz,Gladston Moreira*

Main category: cs.NE

TL;DR: 本文提出了一种在MOEA中集成基于汉明距离的均匀性度量以增强决策空间多样性的方法，实验证明其优于NSGA-II。


<details>
  <summary>Details</summary>
Motivation: 现有MOEA多关注目标空间优化，忽视决策空间多样性，而决策多样性对决策者选择至关重要。

Method: 在MOEA选择机制中直接集成基于汉明距离的均匀性度量。

Result: 在饮食问题的多目标优化中，显著提升决策空间多样性，同时保持目标空间性能。

Conclusion: 该方法为MOEA集成决策空间意识提供了通用策略。

Abstract: Multi-objective evolutionary algorithms (MOEAs) are essential for solving
complex optimization problems, such as the diet problem, where balancing
conflicting objectives, like cost and nutritional content, is crucial. However,
most MOEAs focus on optimizing solutions in the objective space, often
neglecting the diversity of solutions in the decision space, which is critical
for providing decision-makers with a wide range of choices. This paper
introduces an approach that directly integrates a Hamming distance-based
measure of uniformity into the selection mechanism of a MOEA to enhance
decision space diversity. Experiments on a multi-objective formulation of the
diet problem demonstrate that our approach significantly improves decision
space diversity compared to NSGA-II, while maintaining comparable objective
space performance. The proposed method offers a generalizable strategy for
integrating decision space awareness into MOEAs.

</details>


### [549] [Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong](https://arxiv.org/abs/2508.07522)
*Jim O'Connor,Derin Gezgin,Gary B. Parker*

Main category: cs.NE

TL;DR: Evo-Sparrow是一种基于深度学习的AI决策代理，用于麻雀麻将，结合LSTM和CMA-ES优化，表现优于随机和规则代理，与PPO基线相当。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种结合深度学习和进化优化的方法，为复杂随机游戏提供高效决策策略。

Method: 使用LSTM网络评估棋盘状态，并通过CMA-ES优化决策策略。

Result: 模型在模拟中表现优于随机和规则代理，与PPO基线性能相当。

Conclusion: 结合深度学习和进化优化的方法为复杂随机游戏提供了有效策略，并具有广泛的应用潜力。

Abstract: We present Evo-Sparrow, a deep learning-based agent for AI decision-making in
Sparrow Mahjong, trained by optimizing Long Short-Term Memory (LSTM) networks
using Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Our model
evaluates board states and optimizes decision policies in a non-deterministic,
partially observable game environment. Empirical analysis conducted over a
significant number of simulations demonstrates that our model outperforms both
random and rule-based agents, and achieves performance comparable to a Proximal
Policy Optimization (PPO) baseline, indicating strong strategic play and robust
policy quality. By combining deep learning with evolutionary optimization, our
approach provides a computationally effective alternative to traditional
reinforcement learning and gradient-based optimization methods. This research
contributes to the broader field of AI game playing, demonstrating the
viability of hybrid learning strategies for complex stochastic games. These
findings also offer potential applications in adaptive decision-making and
strategic AI development beyond Sparrow Mahjong.

</details>


### [550] [Energy and Quality of Surrogate-Assisted Search Algorithms: a First Analysis](https://arxiv.org/abs/2508.07691)
*Tomohiro Harada,Enrique Alba,Gabriel Luque*

Main category: cs.NE

TL;DR: 本文研究了代理辅助元启发式算法的能量特性，首次分析了粒子群优化在不同版本（包括预训练和再训练神经网络作为代理）中的能量消耗（处理器和内存），并探讨了代理准确性对搜索的影响。


<details>
  <summary>Details</summary>
Motivation: 解决复杂实际问题需要高效算法，但代理辅助元启发式算法的能量特性和准确性尚未充分研究，本文旨在填补这一空白。

Method: 通过分析粒子群优化的不同版本（包括预训练和再训练神经网络作为代理），研究其能量消耗和代理准确性。

Result: 研究揭示了代理辅助算法的能量特性和准确性，为更全面的优化技术评估提供了初步方法论。

Conclusion: 本文为代理辅助算法的能量和准确性研究奠定了基础，为未来更全面的优化技术评估提供了方向。

Abstract: Solving complex real problems often demands advanced algorithms, and then
continuous improvements in the internal operations of a search technique are
needed. Hybrid algorithms, parallel techniques, theoretical advances, and much
more are needed to transform a general search algorithm into an efficient,
useful one in practice. In this paper, we study how surrogates are helping
metaheuristics from an important and understudied point of view: their energy
profile. Even if surrogates are a great idea for substituting a time-demanding
complex fitness function, the energy profile, general efficiency, and accuracy
of the resulting surrogate-assisted metaheuristic still need considerable
research. In this work, we make a first step in analyzing particle swarm
optimization in different versions (including pre-trained and retrained neural
networks as surrogates) for its energy profile (for both processor and memory),
plus a further study on the surrogate accuracy to properly drive the search
towards an acceptable solution. Our conclusions shed new light on this topic
and could be understood as the first step towards a methodology for assessing
surrogate-assisted algorithms not only accounting for time or numerical
efficiency but also for energy and surrogate accuracy for a better, more
holistic characterization of optimization and learning techniques.

</details>


### [551] [Growing Reservoirs with Developmental Graph Cellular Automata](https://arxiv.org/abs/2508.08091)
*Matias Barandiaran,James Stovold*

Main category: cs.NE

TL;DR: DGCA是一种新型形态发生模型，能够从单节点种子生长有向图。研究表明，DGCA可以训练生长储层，并在任务驱动和任务无关目标下表现出色，优于传统储层。


<details>
  <summary>Details</summary>
Motivation: 探索DGCA作为形态发生模型的潜力，特别是在生长功能性储层方面的应用。

Method: 使用DGCA模型训练生长储层，目标包括任务驱动（NARMA任务）和任务无关（储层指标）。

Result: DGCA能生长出多样化的生命状结构，在基准任务中表现优于传统储层。

Conclusion: DGCA为开发可塑性储层系统和功能适应性形态发生建模奠定了基础。

Abstract: Developmental Graph Cellular Automata (DGCA) are a novel model for
morphogenesis, capable of growing directed graphs from single-node seeds. In
this paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs
are grown with two types of targets: task-driven (using the NARMA family of
tasks) and task-independent (using reservoir metrics).
  Results show that DGCAs are able to grow into a variety of specialized,
life-like structures capable of effectively solving benchmark tasks,
statistically outperforming `typical' reservoirs on the same task. Overall,
these lay the foundation for the development of DGCA systems that produce
plastic reservoirs and for modeling functional, adaptive morphogenesis.

</details>
