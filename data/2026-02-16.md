<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 56]
- [cs.LG](#cs.LG) [Total: 68]
- [cs.HC](#cs.HC) [Total: 18]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.GT](#cs.GT) [Total: 6]
- [cs.SD](#cs.SD) [Total: 4]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.RO](#cs.RO) [Total: 36]
- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [EPRBench: A High-Quality Benchmark Dataset for Event Stream Based Visual Place Recognition](https://arxiv.org/abs/2602.12919)
*Xiao Wang,Xingxing Xiong,Jinfeng Gao,Xufeng Lou,Bo Jiang,Si-bao Chen,Yaowei Wang,Yonghong Tian*

Main category: cs.CV

TL;DR: EPRBench：首个专门用于事件流视觉地点识别的高质量基准数据集，包含10K事件序列和65K事件帧，支持语义感知和语言集成研究，并提出了基于LLM的多模态融合新范式。


<details>
  <summary>Details</summary>
Motivation: 事件流视觉地点识别（VPR）是新兴研究方向，能解决传统可见光相机在低光照、过曝、高速运动等挑战条件下的不稳定性问题。目前该领域缺乏专用数据集，因此需要构建高质量基准来推动研究发展。

Method: 1. 构建EPRBench数据集：包含手持和车载两种采集方式，涵盖多样化视角、天气和光照条件；2. 提供LLM生成并经人工标注的场景描述；3. 在数据集上评估15种SOTA VPR算法；4. 提出基于LLM的多模态融合范式：从原始事件流生成文本描述，指导空间注意力token选择、跨模态特征融合和多尺度表示学习。

Result: 1. 创建了包含10K事件序列和65K事件帧的高质量基准数据集；2. 建立了15种算法的基准性能；3. 提出的多模态融合框架不仅实现了高精度地点识别，还产生了可解释的推理过程，显著增强了模型透明度和可解释性。

Conclusion: EPRBench填补了事件流VPR领域专用数据集的空白，为未来算法比较提供了坚实基础。提出的LLM驱动的多模态融合范式展示了将语言模型集成到事件感知流水线中的潜力，实现了高精度且可解释的地点识别。数据集和源代码将开源。

Abstract: Event stream-based Visual Place Recognition (VPR) is an emerging research direction that offers a compelling solution to the instability of conventional visible-light cameras under challenging conditions such as low illumination, overexposure, and high-speed motion. Recognizing the current scarcity of dedicated datasets in this domain, we introduce EPRBench, a high-quality benchmark specifically designed for event stream-based VPR. EPRBench comprises 10K event sequences and 65K event frames, collected using both handheld and vehicle-mounted setups to comprehensively capture real-world challenges across diverse viewpoints, weather conditions, and lighting scenarios. To support semantic-aware and language-integrated VPR research, we provide LLM-generated scene descriptions, subsequently refined through human annotation, establishing a solid foundation for integrating LLMs into event-based perception pipelines. To facilitate systematic evaluation, we implement and benchmark 15 state-of-the-art VPR algorithms on EPRBench, offering a strong baseline for future algorithmic comparisons. Furthermore, we propose a novel multi-modal fusion paradigm for VPR: leveraging LLMs to generate textual scene descriptions from raw event streams, which then guide spatially attentive token selection, cross-modal feature fusion, and multi-scale representation learning. This framework not only achieves highly accurate place recognition but also produces interpretable reasoning processes alongside its predictions, significantly enhancing model transparency and explainability. The dataset and source code will be released on https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [2] [SPRig: Self-Supervised Pose-Invariant Rigging from Mesh Sequences](https://arxiv.org/abs/2602.12740)
*Ruipeng Wang,Langkun Zhong,Miaowei Wang*

Main category: cs.CV

TL;DR: SPRig是一个通用的微调框架，通过在现有模型上施加跨帧一致性损失来学习姿态不变的绑定系统，解决了序列数据缺乏标准T-pose时传统方法产生的拓扑不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有绑定方法假设存在标准休息姿势（如T-pose），但序列数据（如动物运动捕捉、AIGC/视频生成的网格序列）缺乏这种标准姿势。逐帧应用这些方法会导致姿态不变性缺失和跨帧拓扑不一致。

Method: 提出SPRig框架，在现有模型基础上通过施加跨帧一致性损失来学习姿态不变的绑定系统。采用新的排列不变稳定性协议进行验证。

Result: 实验证明SPRig在时间稳定性方面达到最先进水平：能够从具有挑战性的序列中生成一致的绑定系统，并显著减少基线方法中常见的伪影。

Conclusion: SPRig框架有效解决了序列数据绑定中的跨帧一致性问题，代码将在论文被接受后公开。

Abstract: State-of-the-art rigging methods assume a canonical rest pose--an assumption that fails for sequential data (e.g., animal motion capture or AIGC/video-derived mesh sequences) that lack the T-pose. Applied frame-by-frame, these methods are not pose-invariant and produce topological inconsistencies across frames. Thus We propose SPRig, a general fine-tuning framework that enforces cross-frame consistency losses to learn pose-invariant rigs on top of existing models. We validate our approach on rigging using a new permutation-invariant stability protocol. Experiments demonstrate SOTA temporal stability: our method produces coherent rigs from challenging sequences and dramatically reduces the artifacts that plague baseline methods. The code will be released publicly upon acceptance.

</details>


### [3] [FlexAM: Flexible Appearance-Motion Decomposition for Versatile Video Generation Control](https://arxiv.org/abs/2602.13185)
*Mingzhi Sheng,Zekai Gu,Peng Li,Cheng Lin,Hao-Xiang Guo,Ying-Cong Chen,Yuan Liu*

Main category: cs.CV

TL;DR: FlexAM提出了一种基于3D点云控制信号的视频生成框架，通过解耦"外观"和"运动"实现更鲁棒和可扩展的视频控制，支持多种编辑任务。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成中的控制方法大多依赖模糊或任务特定的信号，缺乏通用性。作者认为，从根本上解耦"外观"和"运动"是更鲁棒和可扩展的途径。

Method: 提出FlexAM框架，基于新颖的3D控制信号，将视频动态表示为点云，引入三个关键增强：多频位置编码区分细粒度运动、深度感知位置编码、以及平衡精度和生成质量的灵活控制信号。

Result: 大量实验表明，FlexAM在所有评估任务中均取得了优越性能，包括图像到视频/视频到视频编辑、相机控制和空间对象编辑等。

Conclusion: 通过解耦外观和运动，FlexAM提供了一种有效且通用的视频控制方法，其基于3D点云的表示能够支持广泛的视频编辑任务。

Abstract: Effective and generalizable control in video generation remains a significant challenge. While many methods rely on ambiguous or task-specific signals, we argue that a fundamental disentanglement of "appearance" and "motion" provides a more robust and scalable pathway. We propose FlexAM, a unified framework built upon a novel 3D control signal. This signal represents video dynamics as a point cloud, introducing three key enhancements: multi-frequency positional encoding to distinguish fine-grained motion, depth-aware positional encoding, and a flexible control signal for balancing precision and generative quality. This representation allows FlexAM to effectively disentangle appearance and motion, enabling a wide range of tasks including I2V/V2V editing, camera control, and spatial object editing. Extensive experiments demonstrate that FlexAM achieves superior performance across all evaluated tasks.

</details>


### [4] [Thermal Imaging for Contactless Cardiorespiratory and Sudomotor Response Monitoring](https://arxiv.org/abs/2602.12361)
*Constantino Álvarez Casado,Mohammad Rahman,Sasan Sharifipour,Nhi Nguyen,Manuel Lage Cañellas,Xiaoting Wu,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 热红外成像通过面部热视频无接触估计皮肤电活动、心率和呼吸率，在SIM1驾驶监测数据集上验证了可行性


<details>
  <summary>Details</summary>
Motivation: 可见光方法无法获取皮肤电活动（EDA）这一交感神经激活的标准标志物，而热红外成像能捕捉皮肤温度变化，有望无接触估计EDA、心率和呼吸率

Method: 使用信号处理流程：追踪面部解剖区域、空间聚合、分离慢速发汗趋势和快速心肺成分；对心率采用正交矩阵图像变换分解多个面部感兴趣区域，对呼吸率平均鼻部和脸颊信号后进行频谱峰值检测

Result: 最佳EDA配置（鼻部区域、指数移动平均）与手掌EDA的平均绝对相关性为0.40±0.23，个别会话达0.89；呼吸率估计平均绝对误差3.1±1.1 bpm，心率估计13.8±7.5 bpm MAE（受限于7.5 Hz低帧率）

Conclusion: 热红外成像可实现无接触生物信号估计，但性能受相机帧率限制；研究结果为热红外无接触生物信号估计提供了基准性能边界和设计指导

Abstract: Thermal infrared imaging captures skin temperature changes driven by autonomic regulation and can potentially provide contactless estimation of electrodermal activity (EDA), heart rate (HR), and breathing rate (BR). While visible-light methods address HR and BR, they cannot access EDA, a standard marker of sympathetic activation. This paper characterizes the extraction of these three biosignals from facial thermal video using a signal-processing pipeline that tracks anatomical regions, applies spatial aggregation, and separates slow sudomotor trends from faster cardiorespiratory components. For HR, we apply an orthogonal matrix image transformation (OMIT) decomposition across multiple facial regions of interest (ROIs), and for BR we average nasal and cheek signals before spectral peak detection. We evaluate 288 EDA configurations and the HR/BR pipeline on 31 sessions from the public SIMULATOR STUDY 1 (SIM1) driver monitoring dataset. The best fixed EDA configuration (nose region, exponential moving average) reaches a mean absolute correlation of $0.40 \pm 0.23$ against palm EDA, with individual sessions reaching 0.89. BR estimation achieves a mean absolute error of $3.1 \pm 1.1$ bpm, while HR estimation yields $13.8 \pm 7.5$ bpm MAE, limited by the low camera frame rate (7.5 Hz). We report signal polarity alternation across sessions, short thermodynamic latency for well-tracked signals, and condition-dependent and demographic effects on extraction quality. These results provide baseline performance bounds and design guidance for thermal contactless biosignal estimation.

</details>


### [5] [LLaMo: Scaling Pretrained Language Models for Unified Motion Understanding and Generation with Continuous Autoregressive Tokens](https://arxiv.org/abs/2602.12370)
*Zekun Li,Sizhe An,Chengcheng Tang,Chuan Guo,Ivan Shugurov,Linguang Zhang,Amy Zhao,Srinath Sridhar,Lingling Tao,Abhay Mittal*

Main category: cs.CV

TL;DR: LLaMo是一个统一运动-语言生成与理解框架，通过模态特定的混合Transformer架构扩展预训练大语言模型，解决了现有方法中语言能力灾难性遗忘和离散表示引入抖动的问题。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态生成与理解在运动-语言领域仍未被充分探索。现有方法通常在大语言模型上微调运动-文本配对数据，但由于可用数据规模有限，会导致语言能力的灾难性遗忘。此外，先前方法通常通过量化将运动转换为离散表示，这会引入离散化带来的抖动伪影。

Method: 提出LLaMo框架，通过模态特定的混合Transformer架构扩展预训练大语言模型。将人体运动编码到因果连续潜在空间，通过轻量级流匹配头在仅解码器骨干中保持下一个标记预测范式，实现实时流式运动生成（>30 FPS）。

Result: 实验表明，LLaMo在通用场景下实现了高保真的文本到运动生成和运动到文本描述，特别是在零样本运动生成方面表现优异，标志着向通用统一运动-语言大模型迈出了重要一步。

Conclusion: LLaMo通过创新的架构设计，在保持基础模型语言理解能力的同时实现了可扩展的多模态适应，解决了运动-语言统一模型开发中的关键挑战，为通用运动-语言大模型的发展提供了重要进展。

Abstract: Recent progress in large models has led to significant advances in unified multimodal generation and understanding. However, the development of models that unify motion-language generation and understanding remains largely underexplored. Existing approaches often fine-tune large language models (LLMs) on paired motion-text data, which can result in catastrophic forgetting of linguistic capabilities due to the limited scale of available text-motion pairs. Furthermore, prior methods typically convert motion into discrete representations via quantization to integrate with language models, introducing substantial jitter artifacts from discrete tokenization. To address these challenges, we propose LLaMo, a unified framework that extends pretrained LLMs through a modality-specific Mixture-of-Transformers (MoT) architecture. This design inherently preserves the language understanding of the base model while enabling scalable multimodal adaptation. We encode human motion into a causal continuous latent space and maintain the next-token prediction paradigm in the decoder-only backbone through a lightweight flow-matching head, allowing for streaming motion generation in real-time (>30 FPS). Leveraging the comprehensive language understanding of pretrained LLMs and large-scale motion-text pretraining, our experiments demonstrate that LLaMo achieves high-fidelity text-to-motion generation and motion-to-text captioning in general settings, especially zero-shot motion generation, marking a significant step towards a general unified motion-language large model.

</details>


### [6] [Synthetic Image Detection with CLIP: Understanding and Assessing Predictive Cues](https://arxiv.org/abs/2602.12381)
*Marco Willi,Melanie Mathys,Michael Graber*

Main category: cs.CV

TL;DR: 该研究分析了基于CLIP的合成图像检测方法，发现它们主要依赖高级摄影属性而非生成器特定伪影，在高质量扩散模型上性能下降且跨生成器泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型产生近乎逼真的图像，合成图像检测变得重要。现有方法难以泛化到新生成模型，且CLIP检测器的工作原理不明确，不清楚其检测的是视觉伪影还是语义偏差。

Method: 引入SynthCLIC数据集（真实照片与高质量扩散模型合成图像对），使用可解释的线性头和去相关激活，结合文本基础概念模型分析CLIP检测器的学习内容。

Result: CLIP线性检测器在GAN基准上达到0.96 mAP，但在SynthCLIC上仅0.92 mAP，跨生成器泛化最低至0.37 mAP。检测器主要依赖高级摄影属性而非生成器特定伪影。

Conclusion: CLIP检测器整体表现良好但泛化不均匀，需要持续模型更新和更广泛的训练暴露，同时CLIP方法为更通用、鲁棒的合成图像检测提供了坚实基础。

Abstract: Recent generative models produce near-photorealistic images, challenging the trustworthiness of photographs. Synthetic image detection (SID) has thus become an important area of research. Prior work has highlighted how synthetic images differ from real photographs--unfortunately, SID methods often struggle to generalize to novel generative models and often perform poorly in practical settings. CLIP, a foundational vision-language model which yields semantically rich image-text embeddings, shows strong accuracy and generalization for SID. Yet, the underlying relevant cues embedded in CLIP-features remain unknown. It is unclear, whether CLIP-based detectors simply detect strong visual artifacts or exploit subtle semantic biases, both of which would render them useless in practical settings or on generative models of high quality. We introduce SynthCLIC, a paired dataset of real photographs and high-quality synthetic counterparts from recent diffusion models, designed to reduce semantic bias in SID. Using an interpretable linear head with de-correlated activations and a text-grounded concept-model, we analyze what CLIP-based detectors learn. CLIP-based linear detectors reach 0.96 mAP on a GAN-based benchmark but only 0.92 on our high-quality diffusion dataset SynthCLIC, and generalization across generator families drops to as low as 0.37 mAP. We find that the detectors primarily rely on high-level photographic attributes (e.g., minimalist style, lens flare, or depth layering), rather than overt generator-specific artifacts. CLIP-based detectors perform well overall but generalize unevenly across diverse generative architectures. This highlights the need for continual model updates and broader training exposure, while reinforcing CLIP-based approaches as a strong foundation for more universal, robust SID.

</details>


### [7] [Reproducing DragDiffusion: Interactive Point-Based Editing with Diffusion Models](https://arxiv.org/abs/2602.12393)
*Ali Subhan,Ashir Raza*

Main category: cs.CV

TL;DR: 该研究对DragDiffusion方法进行了可复现性验证，确认了其主要技术主张的有效性，同时发现性能对少数超参数敏感，多时间步优化并未提升效果。


<details>
  <summary>Details</summary>
Motivation: 验证DragDiffusion这一基于扩散模型的交互式点编辑方法的可复现性，评估其在不同超参数设置下的鲁棒性，并为社区提供可靠的实现参考。

Method: 使用作者发布的代码和DragBench基准进行复现实验，包括扩散时间步选择、LoRA微调、掩码正则化强度、UNet特征监督等主要消融研究，并评估多时间步潜在优化变体。

Result: 成功复现了原始工作的主要定性和定量趋势，发现性能对优化时间步和运动监督特征层等少数超参数敏感，多时间步优化未改善空间精度但显著增加计算成本。

Conclusion: 研究支持DragDiffusion的核心技术主张，明确了其可靠复现的条件，为社区提供了经过验证的实现，并指出关键超参数需要仔细调整。

Abstract: DragDiffusion is a diffusion-based method for interactive point-based image editing that enables users to manipulate images by directly dragging selected points. The method claims that accurate spatial control can be achieved by optimizing a single diffusion latent at an intermediate timestep, together with identity-preserving fine-tuning and spatial regularization. This work presents a reproducibility study of DragDiffusion using the authors' released implementation and the DragBench benchmark. We reproduce the main ablation studies on diffusion timestep selection, LoRA-based fine-tuning, mask regularization strength, and UNet feature supervision, and observe close agreement with the qualitative and quantitative trends reported in the original work. At the same time, our experiments show that performance is sensitive to a small number of hyperparameter assumptions, particularly the optimized timestep and the feature level used for motion supervision, while other components admit broader operating ranges. We further evaluate a multi-timestep latent optimization variant and find that it does not improve spatial accuracy while substantially increasing computational cost. Overall, our findings support the central claims of DragDiffusion while clarifying the conditions under which they are reliably reproducible. Code is available at https://github.com/AliSubhan5341/DragDiffusion-TMLR-Reproducibility-Challenge.

</details>


### [8] [What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis](https://arxiv.org/abs/2602.12395)
*Xirui Li,Ming Li,Tianyi Zhou*

Main category: cs.CV

TL;DR: 该研究通过因果探测、参数比较和模型融合等方法分析强化学习在视觉语言模型中的作用，发现RL主要优化中后期层的推理计算，而非整体视觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习已成为提升视觉语言模型视觉推理能力的标准后训练阶段，但RL相比监督微调具体改善了哪些能力尚不清楚。基准测试的提升混杂了多种因素，难以将改进归因于特定技能。

Method: 提出弗兰肯斯坦式分析框架：1) 通过因果探测进行功能定位；2) 通过参数比较进行更新表征；3) 通过模型融合进行可迁移性测试。

Result: RL主要在中后期层引发一致的推理时偏移，这些中后期优化既可通过模型融合进行迁移，又对RL增益是必要的。RL的可靠贡献不是对视觉感知的均匀增强，而是对中后期Transformer计算的系统性优化。

Conclusion: 强化学习在视觉推理中的主要作用是改善视觉到推理的对齐和推理性能，强调仅依赖基准测试评估多模态推理改进的局限性。

Abstract: Reinforcement learning (RL) with verifiable rewards has become a standard post-training stage for boosting visual reasoning in vision-language models, yet it remains unclear what capabilities RL actually improves compared with supervised fine-tuning as cold-start initialization (IN). End-to-end benchmark gains conflate multiple factors, making it difficult to attribute improvements to specific skills. To bridge the gap, we propose a Frankenstein-style analysis framework including: (i) functional localization via causal probing; (ii) update characterization via parameter comparison; and (iii) transferability test via model merging. Instead, RL induces a consistent inference-time shift primarily in mid-to-late layers, and these mid-to-late refinements are both transferable (via merging) and necessary (via freezing) for RL gains. Overall, our results suggest that RL's reliable contribution in visual reasoning is not a uniform enhancement of visual perception, but a systematic refinement of mid-to-late transformer computation that improves vision-to-reasoning alignment and reasoning performance, highlighting the limitations of benchmark-only evaluation for understanding multimodal reasoning improvements.

</details>


### [9] [ZeroDiff++: Substantial Unseen Visual-semantic Correlation in Zero-shot Learning](https://arxiv.org/abs/2602.12401)
*Zihan Ye,Shreyank N Gowda,Kaile Du,Weijian Luo,Ling Shao*

Main category: cs.CV

TL;DR: ZeroDiff++：一种基于扩散的生成式零样本学习框架，通过扩散增强、监督对比表示、多视图判别器以及测试时适应和生成技术，解决现有方法中虚假视觉语义相关性和生成特征与真实测试样本脱节的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式零样本学习方法存在两个关键问题：1）由于可见类样本稀缺导致的虚假视觉语义相关性；2）现有非自适应全噪声生成器产生的特征与真实测试样本脱节，进一步加剧了虚假相关性。

Method: 提出ZeroDiff++框架：训练阶段使用扩散增强生成多样化噪声样本、监督对比表示获取实例级语义、多视图判别器与Wasserstein互学习评估生成特征；生成阶段引入基于扩散的测试时适应（DiffTTA）和测试时生成（DiffGen），通过伪标签重构和部分合成特征连接真实与生成数据。

Result: 在三个ZSL基准测试上的广泛实验表明，ZeroDiff++不仅显著优于现有ZSL方法，而且在训练数据稀缺时仍能保持鲁棒性能。

Conclusion: ZeroDiff++通过创新的扩散框架有效增强了可见类和未见类的视觉语义相关性，解决了生成式零样本学习中的关键瓶颈问题，为数据稀缺场景下的ZSL提供了有效解决方案。

Abstract: Zero-shot Learning (ZSL) enables classifiers to recognize classes unseen during training, commonly via generative two stage methods: (1) learn visual semantic correlations from seen classes; (2) synthesize unseen class features from semantics to train classifiers. In this paper, we identify spurious visual semantic correlations in existing generative ZSL worsened by scarce seen class samples and introduce two metrics to quantify spuriousness for seen and unseen classes. Furthermore, we point out a more critical bottleneck: existing unadaptive fully noised generators produce features disconnected from real test samples, which also leads to the spurious correlation. To enhance the visual-semantic correlations on both seen and unseen classes, we propose ZeroDiff++, a diffusion-based generative framework. In training, ZeroDiff++ uses (i) diffusion augmentation to produce diverse noised samples, (ii) supervised contrastive (SC) representations for instance level semantics, and (iii) multi view discriminators with Wasserstein mutual learning to assess generated features. At generation time, we introduce (iv) Diffusion-based Test time Adaptation (DiffTTA) to adapt the generator using pseudo label reconstruction, and (v) Diffusion-based Test time Generation (DiffGen) to trace the diffusion denoising path and produce partially synthesized features that connect real and generated data, and mitigates data scarcity further. Extensive experiments on three ZSL benchmarks demonstrate that ZeroDiff++ not only achieves significant improvements over existing ZSL methods but also maintains robust performance even with scarce training data. Code would be available.

</details>


### [10] [MonoLoss: A Training Objective for Interpretable Monosemantic Representations](https://arxiv.org/abs/2602.12403)
*Ali Nasiri-Sarvi,Anh Tien Nguyen,Hassan Rivaz,Dimitris Samaras,Mahdi S. Hosseini*

Main category: cs.CV

TL;DR: 提出MonoLoss损失函数，通过单次计算MonoScore来高效训练稀疏自编码器，提升特征的单义性和分类纯度，在多个模型上取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）用于分解多义神经表示，但现有训练目标对单义性分解的鼓励较弱，且单义性评估指标需要成对比较所有数据样本，计算效率低下。

Method: 1. 对MonoScore指标推导出单次计算算法，将计算复杂度从二次降为线性；2. 提出Monosemanticity Loss（MonoLoss）作为可插拔的训练目标，直接奖励语义一致的激活；3. 在多种SAE架构和预训练模型上进行实验。

Result: 1. 在OpenImagesV7上实现评估速度1200倍提升，训练速度159倍提升，每轮仅增加约4%开销；2. MonoLoss提高了大多数潜在特征的MonoScore；3. 在所有编码器和SAE组合中持续提升类别纯度，最大增益从0.152提升到0.723；4. 作为辅助正则器在ResNet-50和CLIP-ViT-B/32微调中，ImageNet-1K准确率提升达0.6%。

Conclusion: MonoLoss通过高效的单义性优化，显著提升了稀疏自编码器的特征解释性和表示质量，为可解释AI提供了有效的训练方法。

Abstract: Sparse autoencoders (SAEs) decompose polysemantic neural representations, where neurons respond to multiple unrelated concepts, into monosemantic features that capture single, interpretable concepts. However, standard training objectives only weakly encourage this decomposition, and existing monosemanticity metrics require pairwise comparisons across all dataset samples, making them inefficient during training and evaluation. We study a recent MonoScore metric and derive a single-pass algorithm that computes exactly the same quantity, but with a cost that grows linearly, rather than quadratically, with the number of dataset images. On OpenImagesV7, we achieve up to a 1200x speedup wall-clock speedup in evaluation and 159x during training, while adding only ~4% per-epoch overhead. This allows us to treat MonoScore as a training signal: we introduce the Monosemanticity Loss (MonoLoss), a plug-in objective that directly rewards semantically consistent activations for learning interpretable monosemantic representations. Across SAEs trained on CLIP, SigLIP2, and pretrained ViT features, using BatchTopK, TopK, and JumpReLU SAEs, MonoLoss increases MonoScore for most latents. MonoLoss also consistently improves class purity (the fraction of a latent's activating images belonging to its dominant class) across all encoder and SAE combinations, with the largest gain raising baseline purity from 0.152 to 0.723. Used as an auxiliary regularizer during ResNet-50 and CLIP-ViT-B/32 finetuning, MonoLoss yields up to 0.6\% accuracy gains on ImageNet-1K and monosemantic activating patterns on standard benchmark datasets. The code is publicly available at https://github.com/AtlasAnalyticsLab/MonoLoss.

</details>


### [11] [Prototype-driven fusion of pathology and spatial transcriptomics for interpretable survival prediction](https://arxiv.org/abs/2602.12441)
*Lihe Liu,Xiaoxi Pan,Yinyin Yuan,Lulu Shang*

Main category: cs.CV

TL;DR: PathoSpatial是一个端到端可解释框架，通过整合配准的WSI和空间转录组数据，利用任务引导的原型学习和多级专家架构，实现空间感知的预后建模。


<details>
  <summary>Details</summary>
Motivation: 随着配对的WSI-ST队列扩展到群体水平，利用它们互补的空间信号进行预后预测变得至关重要，但目前缺乏针对这种范式的原则性跨模态融合策略。

Method: PathoSpatial采用任务引导的原型学习和多级专家架构，自适应地协调无监督的模态内发现和有监督的跨模态聚合，整合配准的WSI和空间转录组数据。

Result: 在三阴性乳腺癌队列中，PathoSpatial在五个生存终点上表现出强大且一致的性能，优于或与领先的单模态和多模态方法相当，同时提供可解释的原型分析和分子风险分解。

Conclusion: PathoSpatial作为空间组学-病理融合的可扩展和可解释多模态学习的概念验证，通过原型解释和分子风险分解提供定量、生物学基础的解释，突出了候选预后因素。

Abstract: Whole slide images (WSIs) enable weakly supervised prognostic modeling via multiple instance learning (MIL). Spatial transcriptomics (ST) preserves in situ gene expression, providing a spatial molecular context that complements morphology. As paired WSI-ST cohorts scale to population level, leveraging their complementary spatial signals for prognosis becomes crucial; however, principled cross-modal fusion strategies remain limited for this paradigm. To this end, we introduce PathoSpatial, an interpretable end-to-end framework integrating co-registered WSIs and ST to learn spatially informed prognostic representations. PathoSpatial uses task-guided prototype learning within a multi-level experts architecture, adaptively orchestrating unsupervised within-modality discovery with supervised cross-modal aggregation. By design, PathoSpatial substantially strengthens interpretability while maintaining discriminative ability. We evaluate PathoSpatial on a triple-negative breast cancer cohort with paired ST and WSIs. PathoSpatial delivers strong and consistent performance across five survival endpoints, achieving superior or comparable performance to leading unimodal and multimodal methods. PathoSpatial inherently enables post-hoc prototype interpretation and molecular risk decomposition, providing quantitative, biologically grounded explanations, highlighting candidate prognostic factors. We present PathoSpatial as a proof-of-concept for scalable and interpretable multimodal learning for spatial omics-pathology fusion.

</details>


### [12] [Semantic-aware Adversarial Fine-tuning for CLIP](https://arxiv.org/abs/2602.12461)
*Jiacheng Zhang,Jinhao Li,Hanxun Huang,Sarah M. Erfani,Benjamin I. P. Rubinstein,Feng Liu*

Main category: cs.CV

TL;DR: 本文提出SAFT方法，通过语义集成攻击生成语义感知的对抗样本，增强CLIP模型在零样本分类任务中的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过最小化图像与手工模板之间的余弦相似度来生成对抗样本，但单一图像与单一模板的余弦相似度不足以准确衡量图像-文本对的相似性，导致生成的对抗样本在更丰富的语义相似度度量下可能失效。

Method: 提出语义集成攻击：1）使用基础模型生成捕捉核心语义特征的文本描述集合；2）对描述进行精炼以减少幻觉；3）最小化原始图像与精炼后文本描述集合的平均相似度来生成语义感知对抗样本。基于此提出SAFT方法，用语义感知对抗样本微调CLIP的图像编码器。

Result: 在16个数据集上的广泛实验表明，SAFT优于现有方法，在零样本对抗鲁棒性方面取得显著提升。

Conclusion: 通过语义集成攻击生成语义感知对抗样本，并用其微调CLIP图像编码器的SAFT方法，能有效提升模型在零样本分类任务中的对抗鲁棒性。

Abstract: Recent studies have shown that CLIP model's adversarial robustness in zero-shot classification tasks can be enhanced by adversarially fine-tuning its image encoder with adversarial examples (AEs), which are generated by minimizing the cosine similarity between images and a hand-crafted template (e.g., ''A photo of a {label}''). However, it has been shown that the cosine similarity between a single image and a single hand-crafted template is insufficient to measure the similarity for image-text pairs. Building on this, in this paper, we find that the AEs generated using cosine similarity may fail to fool CLIP when the similarity metric is replaced with semantically enriched alternatives, making the image encoder fine-tuned with these AEs less robust. To overcome this issue, we first propose a semantic-ensemble attack to generate semantic-aware AEs by minimizing the average similarity between the original image and an ensemble of refined textual descriptions. These descriptions are initially generated by a foundation model to capture core semantic features beyond hand-crafted templates and are then refined to reduce hallucinations. To this end, we propose Semantic-aware Adversarial Fine-Tuning (SAFT), which fine-tunes CLIP's image encoder with semantic-aware AEs. Extensive experiments show that SAFT outperforms current methods, achieving substantial improvements in zero-shot adversarial robustness across 16 datasets. Our code is available at: https://github.com/tmlr-group/SAFT.

</details>


### [13] [A Lightweight and Explainable DenseNet-121 Framework for Grape Leaf Disease Classification](https://arxiv.org/abs/2602.12484)
*Md. Ehsanul Haque,Md. Saymon Hosen Polash,Rakib Hasan Ovi,Aminul Kader Bulbul,Md Kamrul Siam,Tamim Hasan Saykat*

Main category: cs.CV

TL;DR: 本文提出了一种基于优化DenseNet 121的葡萄叶病害分类方法，通过领域特定预处理和密集连接提取病害特征，在准确率、F1分数等指标上优于基线模型，并利用Grad-CAM提高模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 葡萄是全球重要的经济作物，但病害如细菌性腐烂、霜霉病和白粉病严重影响产量和质量。现有基于YOLO的自动化方法计算成本高且缺乏可解释性，难以在实际场景中应用，因此需要开发高效、可解释的病害检测方法。

Method: 采用优化后的DenseNet 121架构进行葡萄叶病害分类，结合领域特定预处理技术提取病害相关特征（如叶脉、边缘和病斑）。使用迁移学习确保在小样本和不平衡数据集上的稳定性，并通过Grad-CAM技术实现模型可解释性。

Result: 优化DenseNet 121模型在葡萄叶病害分类中表现优异：准确率99.27%、F1分数99.28%、特异性99.71%、Kappa系数98.86%，推理时间9秒。交叉验证平均准确率达99.12%，优于ResNet18、VGG16、AlexNet和SqueezeNet等基线模型。

Conclusion: 提出的框架结合有效架构、领域特定预处理和可解释输出，实现了可扩展、精确且计算成本低的葡萄叶病害检测，适合实时部署，为葡萄园可持续管理提供了实用解决方案。

Abstract: Grapes are among the most economically and culturally significant fruits on a global scale, and table grapes and wine are produced in significant quantities in Europe and Asia. The production and quality of grapes are significantly impacted by grape diseases such as Bacterial Rot, Downy Mildew, and Powdery Mildew. Consequently, the sustainable management of a vineyard necessitates the early and precise identification of these diseases. Current automated methods, particularly those that are based on the YOLO framework, are often computationally costly and lack interpretability that makes them unsuitable for real-world scenarios. This study proposes grape leaf disease classification using Optimized DenseNet 121. Domain-specific preprocessing and extensive connectivity reveal disease-relevant characteristics, including veins, edges, and lesions. An extensive comparison with baseline CNN models, including ResNet18, VGG16, AlexNet, and SqueezeNet, demonstrates that the proposed model exhibits superior performance. It achieves an accuracy of 99.27%, an F1 score of 99.28%, a specificity of 99.71%, and a Kappa of 98.86%, with an inference time of 9 seconds. The cross-validation findings show a mean accuracy of 99.12%, indicating strength and generalizability across all classes. We also employ Grad-CAM to highlight disease-related regions to guarantee the model is highlighting physiologically relevant aspects and increase transparency and confidence. Model optimization reduces processing requirements for real-time deployment, while transfer learning ensures consistency on smaller and unbalanced samples. An effective architecture, domain-specific preprocessing, and interpretable outputs make the proposed framework scalable, precise, and computationally inexpensive for detecting grape leaf diseases.

</details>


### [14] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: LGIP基准测试评估视觉语言模型对语义保持的改写和语义改变的翻转的鲁棒性，发现EVA02-CLIP和大型OpenCLIP变体在不变性和敏感性方面表现最佳，而SigLIP模型存在较大问题。


<details>
  <summary>Details</summary>
Motivation: 尽管现有视觉语言模型（如CLIP、OpenCLIP、EVA02-CLIP和SigLIP）在零样本任务上表现良好，但它们在受控语言扰动下的响应可靠性尚不明确。需要开发一个基准来系统评估模型对语义保持改写的不变性和对语义改变翻转的敏感性。

Method: 提出了语言引导不变性探测（LGIP）基准，使用40k MS COCO图像（每张图有5个人工标注），自动生成语义保持的改写和基于规则的语义翻转（改变对象类别、颜色或数量）。通过不变性误差、语义敏感性差距和正率统计来总结模型行为。

Result: 在9个VLM中，EVA02-CLIP和大型OpenCLIP变体处于有利的不变性-敏感性边界，对改写引起的方差较低，且对原始标注的评分始终高于翻转版本。相比之下，SigLIP和SigLIP2显示出更大的不变性误差，并且经常偏好翻转标注而非人类描述，特别是在对象和颜色编辑方面。这些失败在标准检索指标中基本不可见。

Conclusion: LGIP提供了一个模型无关的诊断工具，能够评估视觉语言模型的语言鲁棒性，超越了传统准确率指标。该基准揭示了不同模型在语义理解方面的显著差异，为模型改进提供了重要指导。

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [15] [Human-Like Coarse Object Representations in Vision Models](https://arxiv.org/abs/2602.12486)
*Andrey Gizdov,Andrea Procopio,Yichen Li,Daniel Harari,Tomer Ullman*

Main category: cs.CV

TL;DR: 研究发现人类直觉物理表征采用粗糙的"体积体"，而分割模型通过调整训练时间、规模和剪枝可获得类似人类的理想粒度，这种对齐呈倒U型曲线


<details>
  <summary>Details</summary>
Motivation: 探索人类直觉物理表征与计算机视觉分割模型之间的差异，研究模型是否以及何时能获得类似人类的粗糙体积体表征

Method: 使用碰撞时间行为范式，建立比较流程和对齐度量，通过调整模型训练时间、规模和剪枝来改变有效容量，分析模型与人类行为的对齐程度

Result: 所有操作中，模型与人类行为的对齐呈现倒U型曲线：小型/短暂训练/剪枝模型分割不足成团块；大型/完全训练模型过度分割有边界抖动；中间的理想粒度最佳匹配人类

Conclusion: 人类类似的粗糙体积体源于资源约束而非特定偏差，可通过早期检查点、适度架构、轻度剪枝等简单调节获得物理高效表征，支持资源理性平衡识别细节与物理可用性的理论

Abstract: Humans appear to represent objects for intuitive physics with coarse, volumetric bodies'' that smooth concavities - trading fine visual details for efficient physical predictions - yet their internal structure is largely unknown. Segmentation models, in contrast, optimize pixel-accurate masks that may misalign with such bodies. We ask whether and when these models nonetheless acquire human-like bodies. Using a time-to-collision (TTC) behavioral paradigm, we introduce a comparison pipeline and alignment metric, then vary model training time, size, and effective capacity via pruning. Across all manipulations, alignment with human behavior follows an inverse U-shaped curve: small/briefly trained/pruned models under-segment into blobs; large/fully trained models over-segment with boundary wiggles; and an intermediate ideal body granularity'' best matches humans. This suggests human-like coarse bodies emerge from resource constraints rather than bespoke biases, and points to simple knobs - early checkpoints, modest architectures, light pruning - for eliciting physics-efficient representations. We situate these results within resource-rational accounts balancing recognition detail against physical affordances.

</details>


### [16] [Layer-Specific Fine-Tuning for Improved Negation Handling in Medical Vision-Language Models](https://arxiv.org/abs/2602.12498)
*Ali Abbasi,Mehdi Taghipour,Rahmatollah Beheshti*

Main category: cs.CV

TL;DR: 该论文针对医学视觉语言模型在临床报告中无法准确区分肯定和否定陈述的问题，提出了一个放射学诊断基准、上下文临床否定数据集，以及基于因果追踪的否定感知选择性训练方法，显著提升了模型对否定语句的识别能力。


<details>
  <summary>Details</summary>
Motivation: 否定是临床报告中的基本语言操作，但现有的视觉语言模型在处理医学否定陈述时表现不佳，经常混淆肯定和否定的医学发现。这在安全关键的医疗环境中存在严重风险，需要系统性地解决这一问题。

Method: 首先构建了放射学特异性诊断基准来评估极性敏感性；然后创建了上下文临床否定数据集，支持位置和严重程度等属性级否定；最后提出了否定感知选择性训练方法，利用因果追踪效应来调节层级的梯度更新，根据每层对否定处理的因果贡献来缩放学习率。

Result: 实验表明该方法显著提升了模型区分肯定和否定临床陈述的能力，同时不损害一般的视觉语言对齐性能。这证明了因果可解释性在安全关键医疗环境中进行针对性模型适应的价值。

Conclusion: 通过将机制可解释性信号转化为原则性优化规则，该方法有效解决了医学视觉语言模型中的否定处理问题，为安全关键医疗环境中的模型适应提供了有价值的框架。代码和资源已开源。

Abstract: Negation is a fundamental linguistic operation in clinical reporting, yet vision-language models (VLMs) frequently fail to distinguish affirmative from negated medical statements. To systematically characterize this limitation, we introduce a radiology-specific diagnostic benchmark that evaluates polarity sensitivity under controlled clinical conditions, revealing that common medical VLMs consistently confuse negated and non-negated findings. To enable learning beyond simple condition absence, we further construct a contextual clinical negation dataset that encodes structured claims and supports attribute-level negations involving location and severity. Building on these resources, we propose Negation-Aware Selective Training (NAST), an interpretability-guided adaptation method that uses causal tracing effects (CTEs) to modulate layer-wise gradient updates during fine-tuning. Rather than applying uniform learning rates, NAST scales each layer's update according to its causal contribution to negation processing, transforming mechanistic interpretability signals into a principled optimization rule. Experiments demonstrate improved discrimination of affirmative and negated clinical statements without degrading general vision-language alignment, highlighting the value of causal interpretability for targeted model adaptation in safety-critical medical settings. Code and resources are available at https://github.com/healthylaife/NAST.

</details>


### [17] [Matching of SAR and optical images based on transformation to shared modality](https://arxiv.org/abs/2602.12515)
*Alexey Borisov,Evgeny Myasnikov,Vladislav Myasnikov*

Main category: cs.CV

TL;DR: 提出一种新的光学与SAR图像匹配方法，通过将两种图像转换为共享的新模态，然后使用预训练的RoMa模型进行匹配，在MultiSenGE数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 光学图像和SAR图像由于物理原理不同，存在显著差异，导致精确配准困难。现有方法难以有效匹配这两种不同模态的图像。

Method: 将光学和SAR图像转换为共享的新图像模态，该模态需满足：1) 具有预定义数量的通道；2) 转换后的配准图像尽可能相似；3) 保持原始图像的重要特征。然后使用预训练的RoMa图像匹配模型进行匹配。

Result: 在MultiSenGE数据集上评估，该方法优于基于原始模态间图像转换和各种特征匹配算法的替代方法，不仅匹配质量更好，而且更具通用性。

Conclusion: 提出的方法能够有效解决光学与SAR图像匹配难题，无需为新的模态重新训练模型，可以直接使用预训练的RoMa和DeDoDe模型，同时保持高质量的匹配性能。

Abstract: Significant differences in optical images and Synthetic Aperture Radar (SAR) images are caused by fundamental differences in the physical principles underlying their acquisition by Earth remote sensing platforms. These differences make precise image matching (co-registration) of these two types of images difficult. In this paper, we propose a new approach to image matching of optical and SAR images, which is based on transforming the images to a new modality. The new image modality is common to both optical and SAR images and satisfies the following conditions. First, the transformed images must have an equal pre-defined number of channels. Second, the transformed and co-registered images must be as similar as possible. Third, the transformed images must be non-degenerate, meaning they must preserve the significant features of the original images. To further match images transformed to this shared modality, we train the RoMa image matching model, which is one of the leading solutions for matching of regular digital photographs. We evaluated the proposed approach on the publicly available MultiSenGE dataset containing both optical and SAR images. We demonstrated its superiority over alternative approaches based on image translation between original modalities and various feature matching algorithms. The proposed solution not only provides better quality of matching, but is also more versatile. It enables the use of ready-made RoMa and DeDoDe models, pre-trained for regular images, without retraining for a new modality, while maintaining high-quality matching of optical and SAR images.

</details>


### [18] [LiDAR-Anchored Collaborative Distillation for Robust 2D Representations](https://arxiv.org/abs/2602.12524)
*Wonjun Jo,Hyunwoo Ha,Kim Ji-Yeon,Hawook Jeong,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 提出Collaborative Distillation方法，利用3D LiDAR作为自监督信号，提升2D图像编码器在噪声和恶劣天气条件下的鲁棒性，同时保持原有能力


<details>
  <summary>Details</summary>
Motivation: 现有预训练的2D图像编码器在清晰白天场景下表现良好，但在噪声和恶劣天气条件下（如雨、雾、雪等）的鲁棒性不足，而现实世界的视觉感知系统需要应对各种复杂环境条件

Method: 提出Collaborative Distillation方法，利用3D LiDAR作为自监督信号来训练2D图像编码器。通过协同蒸馏的方式，将LiDAR的3D信息知识迁移到2D编码器中，提升其在恶劣条件下的鲁棒性

Result: 方法在各种下游任务中优于竞争方法，在不同条件下表现出色，并展现出强大的泛化能力。此外，由于LiDAR的特性，该方法还提升了2D编码器的3D感知能力

Conclusion: 该方法通过利用3D LiDAR作为自监督信号，有效提升了2D图像编码器在恶劣天气条件下的鲁棒性，同时保持了原有能力并增强了3D感知，具有实际应用价值和适应性

Abstract: As deep learning continues to advance, self-supervised learning has made considerable strides. It allows 2D image encoders to extract useful features for various downstream tasks, including those related to vision-based systems. Nevertheless, pre-trained 2D image encoders fall short in conducting the task under noisy and adverse weather conditions beyond clear daytime scenes, which require for robust visual perception. To address these issues, we propose a novel self-supervised approach, \textbf{Collaborative Distillation}, which leverages 3D LiDAR as self-supervision to improve robustness to noisy and adverse weather conditions in 2D image encoders while retaining their original capabilities. Our method outperforms competing methods in various downstream tasks across diverse conditions and exhibits strong generalization ability. In addition, our method also improves 3D awareness stemming from LiDAR's characteristics. This advancement highlights our method's practicality and adaptability in real-world scenarios.

</details>


### [19] [Self-Supervised JEPA-based World Models for LiDAR Occupancy Completion and Forecasting](https://arxiv.org/abs/2602.12540)
*Haoran Zhu,Anna Choromanska*

Main category: cs.CV

TL;DR: 提出AD-LiST-JEPA：基于JEPA框架的自监督世界模型，从LiDAR数据预测自动驾驶环境的时空演化，并通过下游占用完成与预测任务验证表示质量。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要在物理世界中运行，需要构建能够捕捉环境时空演化的世界模型来支持长期规划。同时，可扩展性要求以自监督方式学习这些模型，而联合嵌入预测架构(JEPA)可以利用大量未标记数据学习世界模型，无需昂贵的人工标注。

Method: 提出AD-LiST-JEPA，这是一个基于JEPA框架的自监督世界模型，从LiDAR数据预测未来的时空演化。通过下游的LiDAR占用完成与预测任务来评估学习到的表示质量。

Result: 概念验证实验表明，经过JEPA世界模型学习预训练的编码器在占用完成与预测任务上表现更好。

Conclusion: AD-LiST-JEPA为自动驾驶提供了一个有效的自监督世界模型学习框架，能够从LiDAR数据中学习环境的时空演化表示，并提升下游任务的性能。

Abstract: Autonomous driving, as an agent operating in the physical world, requires the fundamental capability to build \textit{world models} that capture how the environment evolves spatiotemporally in order to support long-term planning. At the same time, scalability demands learning such models in a self-supervised manner; \textit{joint-embedding predictive architecture (JEPA)} enables learning world models via leveraging large volumes of unlabeled data without relying on expensive human annotations. In this paper, we propose \textbf{AD-LiST-JEPA}, a self-supervised world model for autonomous driving that predicts future spatiotemporal evolution from LiDAR data using a JEPA framework. We evaluate the quality of the learned representations through a downstream LiDAR-based occupancy completion and forecasting (OCF) task, which jointly assesses perception and prediction. Proof of concept experiments show better OCF performance with pretrained encoder after JEPA-based world model learning.

</details>


### [20] [PLLM: Pseudo-Labeling Large Language Models for CAD Program Synthesis](https://arxiv.org/abs/2602.12561)
*Yuanbo Li,Dule Shu,Yanying Chen,Matt Klenk,Daniel Ritchie*

Main category: cs.CV

TL;DR: PLLM：一个用于从无标签3D形状合成CAD程序的自训练框架，通过迭代采样候选程序、选择高保真执行结果和增强程序来构建合成程序-形状对进行微调。


<details>
  <summary>Details</summary>
Motivation: 现有CAD程序合成方法依赖于有监督训练，需要配对的形状-程序数据，但这种数据通常难以获取。为了解决这个问题，作者提出了一个自训练框架，能够在没有标签数据的情况下进行CAD程序合成。

Method: PLLM框架包含三个主要步骤：1）从预训练的CAD能力LLM中采样候选程序；2）选择高保真执行的程序；3）增强程序以构建合成的程序-形状对，然后用于微调模型。该框架在无标签的ABC数据集上进行了实验。

Result: 实验表明，PLLM在几何保真度和程序多样性方面都取得了持续改进，成功地将CAD-Recode从DeepCAD适应到无标签的ABC数据集。

Conclusion: PLLM是一个有效的自训练框架，能够在没有配对形状-程序数据的情况下进行CAD程序合成，为CAD程序恢复领域提供了一种新的无监督学习方法。

Abstract: Recovering Computer-Aided Design (CAD) programs from 3D geometries is a widely studied problem. Recent advances in large language models (LLMs) have enabled progress in CAD program synthesis, but existing methods rely on supervised training with paired shape-program data, which is often unavailable. We introduce PLLM, a self-training framework for CAD program synthesis from unlabeled 3D shapes. Given a pre-trained CAD-capable LLM and a shape dataset, PLLM iteratively samples candidate programs, selects high-fidelity executions, and augments programs to construct synthetic program-shape pairs for fine-tuning. We experiment on adapting CAD-Recode from DeepCAD to the unlabeled ABC dataset show consistent improvements in geometric fidelity and program diversity.

</details>


### [21] [The Constant Eye: Benchmarking and Bridging Appearance Robustness in Autonomous Driving](https://arxiv.org/abs/2602.12563)
*Jiabao Wang,Hongyu Zhou,Yuanbo Yang,Jiahao Shao,Yiyi Liao*

Main category: cs.CV

TL;DR: 论文提出了navdream基准测试，用于分离外观变化和结构变化对自动驾驶规划算法的影响，并基于DINOv3提出通用感知接口提升零样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶算法在分布外条件下表现脆弱，但研究缺乏对外观变化（天气、光照）和结构场景变化的区分，无法确定规划失败的根本原因

Method: 建立navdream高保真鲁棒性基准，使用生成式像素对齐风格转移创建视觉压力测试；提出基于冻结视觉基础模型DINOv3的通用感知接口，提取外观不变特征作为规划器的稳定接口

Result: 现有规划算法在分布外外观条件下即使场景结构一致也表现显著退化；提出的通用接口在多种规划范式（回归、扩散、评分）中实现卓越的零样本泛化，在极端外观变化下保持稳定性能

Conclusion: 通过分离外观和结构影响并引入外观不变特征接口，显著提升了自动驾驶规划算法在分布外条件下的鲁棒性和泛化能力

Abstract: Despite rapid progress, autonomous driving algorithms remain notoriously fragile under Out-of-Distribution (OOD) conditions. We identify a critical decoupling failure in current research: the lack of distinction between appearance-based shifts, such as weather and lighting, and structural scene changes. This leaves a fundamental question unanswered: Is the planner failing because of complex road geometry, or simply because it is raining? To resolve this, we establish navdream, a high-fidelity robustness benchmark leveraging generative pixel-aligned style transfer. By creating a visual stress test with negligible geometric deviation, we isolate the impact of appearance on driving performance. Our evaluation reveals that existing planning algorithms often show significant degradation under OOD appearance conditions, even when the underlying scene structure remains consistent. To bridge this gap, we propose a universal perception interface leveraging a frozen visual foundation model (DINOv3). By extracting appearance-invariant features as a stable interface for the planner, we achieve exceptional zero-shot generalization across diverse planning paradigms, including regression-based, diffusion-based, and scoring-based models. Our plug-and-play solution maintains consistent performance across extreme appearance shifts without requiring further fine-tuning. The benchmark and code will be made available.

</details>


### [22] [Unbiased Gradient Estimation for Event Binning via Functional Backpropagation](https://arxiv.org/abs/2602.12590)
*Jinze Chen,Wei Zhai,Han Han,Tiankai Ma,Yang Cao,Bin Li,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出一种用于事件相机视觉的无偏梯度估计框架，通过合成弱导数解决传统分帧方法梯度截断问题，提升学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机将动态场景编码为异步时空脉冲（事件）。传统方法将事件分帧处理，但分帧函数的不连续性会截断梯度，迫使算法依赖帧级特征。直接从未处理事件学习又因分帧操作的不连续性导致梯度估计偏差，限制了学习效率。

Method: 提出一种无偏梯度估计框架，在保持前向输出不变的同时，通过合成弱导数进行反向传播。核心思想是利用分部积分：将目标函数提升为泛函，在反向传播中得到分帧函数导数的积分形式，其中余切函数自然出现。通过从采样的余切向量重构余切函数，计算弱导数，可证明匹配平滑和非平滑目标的长程有限差分。

Result: 在简单优化型自运动估计中，RMS误差降低3.2%，收敛速度加快1.57倍。在复杂下游任务中，自监督光流估计的EPE降低9.4%，SLAM的RMS误差降低5.1%，显示出对事件视觉感知的广泛益处。

Conclusion: 该方法解决了事件视觉中分帧操作导致的梯度估计偏差问题，通过弱导数合成实现了无偏梯度估计，显著提升了事件相机在各种视觉任务中的学习效率和性能表现。

Abstract: Event-based vision encodes dynamic scenes as asynchronous spatio-temporal spikes called events. To leverage conventional image processing pipelines, events are typically binned into frames. However, binning functions are discontinuous, which truncates gradients at the frame level and forces most event-based algorithms to rely solely on frame-based features. Attempts to directly learn from raw events avoid this restriction but instead suffer from biased gradient estimation due to the discontinuities of the binning operation, ultimately limiting their learning efficiency. To address this challenge, we propose a novel framework for unbiased gradient estimation of arbitrary binning functions by synthesizing weak derivatives during backpropagation while keeping the forward output unchanged. The key idea is to exploit integration by parts: lifting the target functions to functionals yields an integral form of the derivative of the binning function during backpropagation, where the cotangent function naturally arises. By reconstructing this cotangent function from the sampled cotangent vector, we compute weak derivatives that provably match long-range finite differences of both smooth and non-smooth targets. Experimentally, our method improves simple optimization-based egomotion estimation with 3.2\% lower RMS error and 1.57$\times$ faster convergence. On complex downstream tasks, we achieve 9.4\% lower EPE in self-supervised optical flow, and 5.1\% lower RMS error in SLAM, demonstrating broad benefits for event-based visual perception. Source code can be found at https://github.com/chjz1024/EventFBP.

</details>


### [23] [QuEPT: Quantized Elastic Precision Transformers with One-Shot Calibration for Multi-Bit Switching](https://arxiv.org/abs/2602.12609)
*Ke Xu,Yixin Wang,Zhongcheng Li,Hao Cui,Jinshui Hu,Xingyi Zhang*

Main category: cs.CV

TL;DR: QuEPT是一种高效的Transformer后训练量化方案，通过一次性校准支持多比特部署，能够动态适应不同比特宽度，无需重复优化


<details>
  <summary>Details</summary>
Motivation: 弹性精度量化虽然支持通过单次优化实现多比特部署，但Transformer架构的高存储和优化成本限制了相关研究，特别是对于大语言模型。现有方法在效率和灵活性方面存在不足。

Method: 提出QuEPT后训练方案：1）通过小数据切片一次性校准重构块级多比特误差；2）通过级联不同低秩适配器动态适应预定义比特宽度；3）支持实时切换均匀量化和混合精度量化；4）引入多比特令牌合并(MB-ToMe)动态融合不同比特宽度的令牌特征；5）提出多比特级联低秩适配器(MB-CLoRA)增强比特宽度组间相关性

Result: 大量实验表明，QuEPT在性能上达到或优于现有最先进的后训练量化方法，在保持高效的同时实现了灵活的比特宽度适应能力

Conclusion: QuEPT提供了一种高效灵活的后训练量化方案，能够有效解决Transformer架构的存储和优化成本问题，支持动态比特宽度适应，为大语言模型的量化部署提供了实用解决方案

Abstract: Elastic precision quantization enables multi-bit deployment via a single optimization pass, fitting diverse quantization scenarios.Yet, the high storage and optimization costs associated with the Transformer architecture, research on elastic quantization remains limited, particularly for large language models.This paper proposes QuEPT, an efficient post-training scheme that reconstructs block-wise multi-bit errors with one-shot calibration on a small data slice. It can dynamically adapt to various predefined bit-widths by cascading different low-rank adapters, and supports real-time switching between uniform quantization and mixed precision quantization without repeated optimization. To enhance accuracy and robustness, we introduce Multi-Bit Token Merging (MB-ToMe) to dynamically fuse token features across different bit-widths, improving robustness during bit-width switching. Additionally, we propose Multi-Bit Cascaded Low-Rank adapters (MB-CLoRA) to strengthen correlations between bit-width groups, further improve the overall performance of QuEPT. Extensive experiments demonstrate that QuEPT achieves comparable or better performance to existing state-of-the-art post-training quantization methods.Our code is available at https://github.com/xuke225/QuEPT

</details>


### [24] [Vision Token Reduction via Attention-Driven Self-Compression for Efficient Multimodal Large Language Models](https://arxiv.org/abs/2602.12618)
*Omer Faruk Deniz,Ruiyu Mao,Ruochen Li,Yapeng Tian,Latifur Khan*

Main category: cs.CV

TL;DR: ADSC是一种基于注意力机制的自压缩方法，通过渐进式减少视觉token数量来降低MLLM计算成本，保持FlashAttention兼容性，在LLaVA-1.5上实现53.7% FLOPs减少和56.7% KV缓存降低，性能保留98.2%


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型处理大量视觉token时计算成本高昂，现有剪枝方法要么局限于编码器-投影器设计，要么使用与FlashAttention不兼容的启发式方法，需要一种更通用、高效的压缩方案

Method: 提出注意力驱动的自压缩(ADSC)方法，将LLM本身作为压缩指导，在选定层进行均匀token下采样形成瓶颈，促使模型将信息重组压缩到剩余token中，无需额外计算、辅助模块或注意力修改

Result: 在LLaVA-1.5上减少53.7% FLOPs和56.7%峰值KV缓存内存，保持98.2%原始性能；在多个基准测试中效率和准确性均优于先前剪枝方法；高压缩比下仍保持鲁棒性

Conclusion: ADSC提供了一种简单、通用且与FlashAttention兼容的视觉token压缩方法，通过利用LLM自身注意力机制实现高效信息压缩，为多模态大语言模型的计算优化提供了有效解决方案

Abstract: Multimodal Large Language Models (MLLMs) incur significant computational cost from processing numerous vision tokens through all LLM layers. Prior pruning methods operate either before the LLM, limiting generality due to diverse encoder-projector designs or within the LLM using heuristics that are incompatible with FlashAttention. We take a different approach: rather than identifying unimportant tokens, we treat the LLM itself as the optimal guide for compression. Observing that deeper layers naturally transmit vision-to-text information, we introduce Attention-Driven Self-Compression (ADSC), a simple, broadly applicable method that progressively reduces vision tokens using only the LLM's attention mechanism. Our method applies uniform token downsampling at selected layers, forming bottlenecks that encourage the model to reorganize and compress information into the remaining tokens. It requires no score computation, auxiliary modules, or attention modification, and remains fully compatible with FlashAttention. Applied to LLaVA-1.5, ADSC reduces FLOPs by 53.7% and peak KV-cache memory by 56.7%, while preserving 98.2% of the original model performance. Across multiple benchmarks, it outperforms prior pruning approaches in both efficiency and accuracy. Crucially, under high compression ratios, our method remains robust while heuristic-based techniques degrade sharply.

</details>


### [25] [ImageRAGTurbo: Towards One-step Text-to-Image Generation with Retrieval-Augmented Diffusion Models](https://arxiv.org/abs/2602.12640)
*Peijie Qiu,Hariharan Ramshankar,Arnau Ramisa,René Vidal,Amit Kumar K C,Vamsi Salaka,Rahul Bhagat*

Main category: cs.CV

TL;DR: ImageRAGTurbo：通过检索增强高效微调少步扩散模型，在保持低延迟的同时提升图像质量和提示对齐


<details>
  <summary>Details</summary>
Motivation: 现有少步扩散模型（1-4步）虽然降低了采样延迟，但往往牺牲图像质量和提示对齐，且训练计算成本高。需要一种方法在保持低延迟的同时提升生成质量。

Method: 提出ImageRAGTurbo方法：1）基于文本提示从数据库中检索相关文本-图像对；2）利用检索内容编辑UNet去噪器的潜在空间（H-space）；3）在H-space中添加可训练适配器，通过交叉注意力机制将检索内容与目标提示有效融合。

Result: 实验表明，该方法在快速文本到图像生成任务中，相比现有方法能在不增加延迟的情况下生成高质量图像。初步研究显示，仅使用检索内容编辑潜在空间（无需额外微调）就能提升提示保真度。

Conclusion: ImageRAGTurbo通过检索增强有效解决了少步扩散模型中图像质量与延迟的权衡问题，为高效文本到图像生成提供了新思路。

Abstract: Diffusion models have emerged as the leading approach for text-to-image generation. However, their iterative sampling process, which gradually morphs random noise into coherent images, introduces significant latency that limits their applicability. While recent few-step diffusion models reduce the number of sampling steps to as few as one to four steps, they often compromise image quality and prompt alignment, especially in one-step generation. Additionally, these models require computationally expensive training procedures. To address these limitations, we propose ImageRAGTurbo, a novel approach to efficiently finetune few-step diffusion models via retrieval augmentation. Given a text prompt, we retrieve relevant text-image pairs from a database and use them to condition the generation process. We argue that such retrieved examples provide rich contextual information to the UNet denoiser that helps reduce the number of denoising steps without compromising image quality. Indeed, our initial investigations show that using the retrieved content to edit the denoiser's latent space ($\mathcal{H}$-space) without additional finetuning already improves prompt fidelity. To further improve the quality of the generated images, we augment the UNet denoiser with a trainable adapter in the $\mathcal{H}$-space, which efficiently blends the retrieved content with the target prompt using a cross-attention mechanism. Experimental results on fast text-to-image generation demonstrate that our approach produces high-fidelity images without compromising latency compared to existing methods.

</details>


### [26] [Multi-Task Learning with Additive U-Net for Image Denoising and Classification](https://arxiv.org/abs/2602.12649)
*Vikram Lakkavalli,Neelam Sinha*

Main category: cs.CV

TL;DR: Additive U-Net (AddUNet)使用门控加法融合替代传统拼接跳跃连接，在图像去噪和多任务学习中实现更好的训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统U-Net架构中的拼接跳跃连接可能导致特征维度变化和训练不稳定，特别是在多任务学习场景下。研究者希望探索更简单的跳跃连接约束作为有效的架构正则化方法。

Method: 提出Additive U-Net (AddUNet)，用门控加法融合替代传统的拼接跳跃连接。这种方法保持特征维度固定，限制捷径容量，通过结构正则化控制编码器-解码器信息流。

Result: 在单任务去噪和联合去噪-分类任务中，AddUNet实现了竞争性的重建性能，同时提高了训练稳定性。在多任务学习中，学习的跳跃权重显示出系统性的任务感知重新分配：浅层跳跃连接偏向重建任务，深层特征支持判别任务。

Conclusion: 简单的跳跃连接约束可以作为有效的架构正则化方法，实现稳定且可扩展的多任务学习，而不增加模型复杂度。加法融合通过隐式任务解耦，即使在分类容量有限的情况下也能保持重建鲁棒性。

Abstract: We investigate additive skip fusion in U-Net architectures for image denoising and denoising-centric multi-task learning (MTL). By replacing concatenative skips with gated additive fusion, the proposed Additive U-Net (AddUNet) constrains shortcut capacity while preserving fixed feature dimensionality across depth. This structural regularization induces controlled encoder-decoder information flow and stabilizes joint optimization. Across single-task denoising and joint denoising-classification settings, AddUNet achieves competitive reconstruction performance with improved training stability. In MTL, learned skip weights exhibit systematic task-aware redistribution: shallow skips favor reconstruction, while deeper features support discrimination. Notably, reconstruction remains robust even under limited classification capacity, indicating implicit task decoupling through additive fusion. These findings show that simple constraints on skip connections act as an effective architectural regularizer for stable and scalable multi-task learning without increasing model complexity.

</details>


### [27] [CBEN -- A Multimodal Machine Learning Dataset for Cloud Robust Remote Sensing Image Understanding](https://arxiv.org/abs/2602.12652)
*Marco Stricker,Masakazu Iwamura,Koichi Kise*

Main category: cs.CV

TL;DR: 本文提出CloudyBigEarthNet数据集，研究云层对光学卫星图像的影响，开发云鲁棒的多模态学习方法，结合光学和雷达数据提升在云层遮挡条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 云层遮挡是光学卫星遥感的主要挑战，现有机器学习方法通常排除云层图像，限制了在自然灾害等时间敏感场景中的应用。云去除方法存在视觉伪影问题，需要开发云鲁棒的方法。

Method: 构建CloudyBigEarthNet数据集，包含成对的光学和雷达图像及云层遮挡信息。通过多模态学习方法，结合光学和雷达数据，在训练中适应云层遮挡条件，而不是排除云层图像。

Result: 在晴空条件下训练的现有方法在云层测试集上性能下降23-33个百分点。通过云鲁棒训练方法，在云层测试集上相对原始方法提升了17.2-28.7个百分点。

Conclusion: 云层遮挡显著影响光学遥感性能，需要开发云鲁棒的多模态方法。CloudyBigEarthNet数据集为研究云层影响提供了基准，结合光学和雷达数据的方法能有效提升在云层条件下的性能。

Abstract: Clouds are a common phenomenon that distorts optical satellite imagery, which poses a challenge for remote sensing. However, in the literature cloudless analysis is often performed where cloudy images are excluded from machine learning datasets and methods. Such an approach cannot be applied to time sensitive applications, e.g., during natural disasters. A possible solution is to apply cloud removal as a preprocessing step to ensure that cloudfree solutions are not failing under such conditions. But cloud removal methods are still actively researched and suffer from drawbacks, such as generated visual artifacts. Therefore, it is desirable to develop cloud robust methods that are less affected by cloudy weather. Cloud robust methods can be achieved by combining optical data with radar, a modality unaffected by clouds. While many datasets for machine learning combine optical and radar data, most researchers exclude cloudy images. We identify this exclusion from machine learning training and evaluation as a limitation that reduces applicability to cloudy scenarios. To investigate this, we assembled a dataset, named CloudyBigEarthNet (CBEN), of paired optical and radar images with cloud occlusion for training and evaluation. Using average precision (AP) as the evaluation metric, we show that state-of-the-art methods trained on combined clear-sky optical and radar imagery suffer performance drops of 23-33 percentage points when evaluated on cloudy images. We then adapt these methods to cloudy optical data during training, achieving relative improvement of 17.2-28.7 percentage points on cloudy test cases compared with the original approaches. Code and dataset are publicly available at: https://github.com/mstricker13/CBEN

</details>


### [28] [Motion Prior Distillation in Time Reversal Sampling for Generative Inbetweening](https://arxiv.org/abs/2602.12679)
*Wooseok Jeon,Seunghyun Shin,Dongmin Shin,Hae-Gon Jeon*

Main category: cs.CV

TL;DR: 提出Motion Prior Distillation (MPD)方法，通过蒸馏前向路径的运动残差到后向路径，解决图像到视频扩散模型中双向路径不对齐导致的时序不连续问题


<details>
  <summary>Details</summary>
Motivation: 现有的推理时采样方法（并行融合或顺序交替前向后向路径）由于两个生成路径之间的运动先验不对齐，经常出现时序不连续和视觉伪影问题

Method: 提出Motion Prior Distillation (MPD)，一种简单有效的推理时蒸馏技术，通过将前向路径的运动残差蒸馏到后向路径来抑制双向不匹配，避免对导致路径模糊的端条件路径进行去噪

Result: 在标准基准测试上进行定量评估，并通过广泛的用户研究证明该方法在实际场景中的有效性，能够产生更时序连贯的中间帧生成结果

Conclusion: MPD方法能够有效解决图像到视频扩散模型中双向路径不对齐问题，提高中间帧生成的时序连贯性和视觉质量

Abstract: Recent progress in image-to-video (I2V) diffusion models has significantly advanced the field of generative inbetweening, which aims to generate semantically plausible frames between two keyframes. In particular, inference-time sampling strategies, which leverage the generative priors of large-scale pre-trained I2V models without additional training, have become increasingly popular. However, existing inference-time sampling, either fusing forward and backward paths in parallel or alternating them sequentially, often suffers from temporal discontinuities and undesirable visual artifacts due to the misalignment between the two generated paths. This is because each path follows the motion prior induced by its own conditioning frame. In this work, we propose Motion Prior Distillation (MPD), a simple yet effective inference-time distillation technique that suppresses bidirectional mismatch by distilling the motion residual of the forward path into the backward path. Our method can deliberately avoid denoising the end-conditioned path which causes the ambiguity of the path, and yield more temporally coherent inbetweening results with the forward motion prior. We not only perform quantitative evaluations on standard benchmarks, but also conduct extensive user studies to demonstrate the effectiveness of our approach in practical scenarios.

</details>


### [29] [Channel-Aware Probing for Multi-Channel Imaging](https://arxiv.org/abs/2602.12696)
*Umar Marikkar,Syed Sameed Husain,Muhammad Awais,Sara Atito*

Main category: cs.CV

TL;DR: 本文提出了通道感知探测（CAP）方法，通过独立特征编码和分离池化技术，有效解决了多通道成像数据中通道配置变化导致的预训练编码器重用难题。


<details>
  <summary>Details</summary>
Motivation: 多通道成像（MCI）数据中通道配置在不同数据集间变化很大，导致固定通道训练困难，预训练编码器难以在新通道设置中重用。现有方法主要关注通过全微调评估MCI编码器，而冻结预训练编码器的探测方法研究不足，且现有探测策略直接应用于MCI效果不佳。

Method: 提出了通道感知探测（CAP）方法，包含两个核心组件：1）独立特征编码（IFE）- 分别编码每个通道；2）分离池化（DCP）- 先在通道内池化，再跨通道聚合。该方法利用MCI数据中固有的通道间多样性，在编码器和探测器层面控制特征流。

Result: 在三个MCI基准测试中，CAP一致性地提升了探测性能，优于默认探测协议，匹配从头开始训练的效果，并显著缩小了与全微调（使用相同MCI预训练检查点）之间的性能差距。

Conclusion: CAP方法通过有效利用MCI数据中的通道多样性，为多通道成像数据的预训练编码器重用提供了有效的探测解决方案，显著提升了冻结预训练编码器在下游任务中的性能。

Abstract: Training and evaluating vision encoders on Multi-Channel Imaging (MCI) data remains challenging as channel configurations vary across datasets, preventing fixed-channel training and limiting reuse of pre-trained encoders on new channel settings. Prior work trains MCI encoders but typically evaluates them via full fine-tuning, leaving probing with frozen pre-trained encoders comparatively underexplored. Existing studies that perform probing largely focus on improving representations, rather than how to best leverage fixed representations for downstream tasks. Although the latter problem has been studied in other domains, directly transferring those strategies to MCI yields weak results, even worse than training from scratch. We therefore propose Channel-Aware Probing (CAP), which exploits the intrinsic inter-channel diversity in MCI datasets by controlling feature flow at both the encoder and probe levels. CAP uses Independent Feature Encoding (IFE) to encode each channel separately, and Decoupled Pooling (DCP) to pool within channels before aggregating across channels. Across three MCI benchmarks, CAP consistently improves probing performance over the default probing protocol, matches fine-tuning from scratch, and largely reduces the gap to full fine-tuning from the same MCI pre-trained checkpoints. Code can be found in https://github.com/umarikkar/CAP.

</details>


### [30] [Synthetic Craquelure Generation for Unsupervised Painting Restoration](https://arxiv.org/abs/2602.12742)
*Jana Cuch-Guillén,Antonio Agudo,Raül Pérez-Gonzalo*

Main category: cs.CV

TL;DR: 提出无需标注的绘画裂纹修复框架，通过合成裂纹生成器和形态学检测器+学习模块的混合方法，在零样本设置下优于现有修复模型。


<details>
  <summary>Details</summary>
Motivation: 文化遗产保护需要非侵入式数字修复方法，但精细裂纹图案的识别和修复面临像素级标注稀缺的挑战，特别是在复杂笔触背景下。

Method: 1) 使用基于贝塞尔轨迹的领域特定合成裂纹生成器模拟真实裂纹；2) 结合经典形态学检测器和基于SegFormer的学习模块，通过LoRA适配；3) 采用检测器引导策略，将形态学图作为空间先验输入；4) 使用掩码混合损失和逻辑调整约束训练聚焦裂纹区域；5) 精炼掩码引导各向异性扩散修复阶段。

Result: 实验结果表明，该框架在零样本设置下显著优于最先进的摄影修复模型，同时能忠实保留原始绘画笔触。

Conclusion: 提出了一种完全无需标注的绘画裂纹修复框架，通过合成数据生成和混合检测-修复方法，有效解决了文化遗产保护中的裂纹修复难题。

Abstract: Cultural heritage preservation increasingly demands non-invasive digital methods for painting restoration, yet identifying and restoring fine craquelure patterns from complex brushstrokes remains challenging due to scarce pixel-level annotations. We propose a fully annotation-free framework driven by a domain-specific synthetic craquelure generator, which simulates realistic branching and tapered fissure geometry using Bézier trajectories. Our approach couples a classical morphological detector with a learning-based refinement module: a SegFormer backbone adapted via Low-Rank Adaptation (LoRA). Uniquely, we employ a detector-guided strategy, injecting the morphological map as an input spatial prior, while a masked hybrid loss and logit adjustment constrain the training to focus specifically on refining candidate crack regions. The refined masks subsequently guide an Anisotropic Diffusion inpainting stage to reconstruct missing content. Experimental results demonstrate that our pipeline significantly outperforms state-of-the-art photographic restoration models in zero-shot settings, while faithfully preserving the original paint brushwork.

</details>


### [31] [Towards reconstructing experimental sparse-view X-ray CT data with diffusion models](https://arxiv.org/abs/2602.12755)
*Nelas J. Thomsen,Xinyuan Wang,Felix Lucka,Ezgi Demircan-Tureyen*

Main category: cs.CV

TL;DR: 扩散模型作为图像先验在稀疏视图CT重建中面临训练数据不匹配和正向模型不匹配的挑战，实验表明多样化的先验优于匹配但狭窄的先验，需要针对真实数据进行验证。


<details>
  <summary>Details</summary>
Motivation: 研究扩散模型作为图像先验在稀疏视图X射线CT重建中的应用，探索训练数据不匹配（领域偏移）和正向模型不匹配对实验数据重建效果的影响。

Method: 使用物理体模测量CT数据，在不同领域偏移程度的合成图像数据集上训练扩散先验，采用分解扩散采样方案处理难度递增的稀疏视图CT数据集，包括实验数据。

Result: 领域偏移具有微妙影响：严重不匹配导致模型崩溃和幻觉，但多样化的先验优于匹配但狭窄的先验；正向模型不匹配会使图像样本偏离先验流形，可通过退火似然调度缓解。

Conclusion: 从合成数据到实验数据的性能提升并非直接转化，未来开发必须针对真实世界基准进行验证，退火似然调度可减轻正向模型不匹配的影响并提高计算效率。

Abstract: Diffusion-based image generators are promising priors for ill-posed inverse problems like sparse-view X-ray Computed Tomography (CT). As most studies consider synthetic data, it is not clear whether training data mismatch (``domain shift'') or forward model mismatch complicate their successful application to experimental data. We measured CT data from a physical phantom resembling the synthetic Shepp-Logan phantom and trained diffusion priors on synthetic image data sets with different degrees of domain shift towards it. Then, we employed the priors in a Decomposed Diffusion Sampling scheme on sparse-view CT data sets with increasing difficulty leading to the experimental data. Our results reveal that domain shift plays a nuanced role: while severe mismatch causes model collapse and hallucinations, diverse priors outperform well-matched but narrow priors. Forward model mismatch pulls the image samples away from the prior manifold, which causes artifacts but can be mitigated with annealed likelihood schedules that also increase computational efficiency. Overall, we demonstrate that performance gains do not immediately translate from synthetic to experimental data, and future development must validate against real-world benchmarks.

</details>


### [32] [Towards complete digital twins in cultural heritage with ART3mis 3D artifacts annotator](https://arxiv.org/abs/2602.12761)
*Dimitrios Karamatskos,Vasileios Arampatzakis,Vasileios Sevetlidis,Stavros Nousias,Athanasios Kalogeras,Christos Koulamas,Aris Lalos,George Pavlidis*

Main category: cs.CV

TL;DR: ART3mis是一个基于Web的通用3D对象文本标注工具，专为文化遗产领域设计，支持W3C Web注释数据模型，使非技术专家能够轻松处理、分割和注释3D数字文物。


<details>
  <summary>Details</summary>
Motivation: 考古学家和文化遗产专家需要超越简单的3D可视化功能，能够对3D数字文物的特定区域进行注释和附加元数据。现有解决方案大多局限于特定应用领域，缺乏通用性和互操作性。

Method: 开发了ART3mis——一个通用、用户友好、功能丰富的交互式基于Web的3D对象文本标注工具。该工具符合W3C Web注释数据模型标准，支持信息的交流、分发和重用。

Result: ART3mis为文化遗产保护者、修复者和策展人提供了易于使用的工具，即使他们缺乏3D成像和图形技术专业知识，也能轻松处理、分割和注释3D数字文物副本。

Conclusion: ART3mis解决了文化遗产领域对3D数字文物进行高级注释的需求，通过基于Web的通用工具实现了跨平台互操作性和易用性，填补了现有解决方案的局限性。

Abstract: Archaeologists, as well as specialists and practitioners in cultural heritage, require applications with additional functions, such as the annotation and attachment of metadata to specific regions of the 3D digital artifacts, to go beyond the simplistic three-dimensional (3D) visualization. Different strategies addressed this issue, most of which are excellent in their particular area of application, but their capacity is limited to their design's purpose; they lack generalization and interoperability. This paper introduces ART3mis, a general-purpose, user-friendly, feature-rich, interactive web-based textual annotation tool for 3D objects. Moreover, it enables the communication, distribution, and reuse of information as it complies with the W3C Web Annotation Data Model. It is primarily designed to help cultural heritage conservators, restorers, and curators who lack technical expertise in 3D imaging and graphics, handle, segment, and annotate 3D digital replicas of artifacts with ease.

</details>


### [33] [PixelRush: Ultra-Fast, Training-Free High-Resolution Image Generation via One-step Diffusion](https://arxiv.org/abs/2602.12769)
*Hong-Phuc Lai,Phong Nguyen,Anh Tran*

Main category: cs.CV

TL;DR: PixelRush是一个无需调参的高分辨率文本到图像生成框架，通过改进的基于补丁的推理方法，在20秒内生成4K图像，相比现有方法提速10-35倍。


<details>
  <summary>Details</summary>
Motivation: 预训练扩散模型虽然能生成高质量图像，但受限于其原始训练分辨率。现有的免训练方法虽然能突破分辨率限制，但计算开销巨大，生成单张4K图像需要超过5分钟，效率低下。

Method: 基于已有的基于补丁的推理范式，但消除了多次反转和再生循环的需求。通过低步数机制实现高效的基于补丁的去噪，提出无缝混合策略解决少步生成中的伪影问题，并通过噪声注入机制减轻过度平滑效应。

Result: PixelRush实现了卓越的效率，在约20秒内生成4K图像，相比最先进方法提速10-35倍，同时保持优异的视觉保真度。大量实验验证了其性能提升和输出质量。

Conclusion: PixelRush是首个实用的免调参高分辨率文本到图像生成框架，通过创新的补丁推理方法显著提升了生成效率，为高分辨率图像生成提供了实用的解决方案。

Abstract: Pre-trained diffusion models excel at generating high-quality images but remain inherently limited by their native training resolution. Recent training-free approaches have attempted to overcome this constraint by introducing interventions during the denoising process; however, these methods incur substantial computational overhead, often requiring more than five minutes to produce a single 4K image. In this paper, we present PixelRush, the first tuning-free framework for practical high-resolution text-to-image generation. Our method builds upon the established patch-based inference paradigm but eliminates the need for multiple inversion and regeneration cycles. Instead, PixelRush enables efficient patch-based denoising within a low-step regime. To address artifacts introduced by patch blending in few-step generation, we propose a seamless blending strategy. Furthermore, we mitigate over-smoothing effects through a noise injection mechanism. PixelRush delivers exceptional efficiency, generating 4K images in approximately 20 seconds representing a 10$\times$ to 35$\times$ speedup over state-of-the-art methods while maintaining superior visual fidelity. Extensive experiments validate both the performance gains and the quality of outputs achieved by our approach.

</details>


### [34] [Bootstrapping MLLM for Weakly-Supervised Class-Agnostic Object Counting](https://arxiv.org/abs/2602.12774)
*Xiaowen Zhang,Zijie Yue,Yong Luo,Cairong Zhao,Qijun Chen,Miaojing Shi*

Main category: cs.CV

TL;DR: WS-COC是首个基于MLLM的弱监督类别无关物体计数框架，通过三种策略在训练和测试中提升计数性能，在多个数据集上达到或超越全监督方法，同时显著降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 全监督计数方法需要昂贵的点级标注，现有弱监督方法通常只能计数单一类别。本文旨在开发首个基于多模态大语言模型（MLLM）的弱监督类别无关物体计数框架，以降低标注成本并提升泛化能力。

Method: 提出WS-COC框架，包含三种核心策略：1）分而辨之对话调优策略，通过多轮对话逐步缩小计数范围；2）比较排序计数优化策略，训练MLLM根据物体数量对多张图像进行相对排序；3）全局局部计数增强策略，融合局部和全局计数预测以提升密集场景性能。

Result: 在FSC-147、CARPK、PUCPR+和ShanghaiTech等数据集上的广泛实验表明，WS-COC匹配甚至超越了许多最先进的全监督方法，同时显著减少了标注成本。

Conclusion: WS-COC是首个MLLM驱动的弱监督类别无关物体计数框架，通过创新的训练和测试策略，在保持高性能的同时大幅降低标注需求，为弱监督物体计数开辟了新方向。

Abstract: Object counting is a fundamental task in computer vision, with broad applicability in many real-world scenarios. Fully-supervised counting methods require costly point-level annotations per object. Few weakly-supervised methods leverage only image-level object counts as supervision and achieve fairly promising results. They are, however, often limited to counting a single category, e.g. person. In this paper, we propose WS-COC, the first MLLM-driven weakly-supervised framework for class-agnostic object counting. Instead of directly fine-tuning MLLMs to predict object counts, which can be challenging due to the modality gap, we incorporate three simple yet effective strategies to bootstrap the counting paradigm in both training and testing: First, a divide-and-discern dialogue tuning strategy is proposed to guide the MLLM to determine whether the object count falls within a specific range and progressively break down the range through multi-round dialogue. Second, a compare-and-rank count optimization strategy is introduced to train the MLLM to optimize the relative ranking of multiple images according to their object counts. Third, a global-and-local counting enhancement strategy aggregates and fuses local and global count predictions to improve counting performance in dense scenes. Extensive experiments on FSC-147, CARPK, PUCPR+, and ShanghaiTech show that WS-COC matches or even surpasses many state-of-art fully-supervised methods while significantly reducing annotation costs. Code is available at https://github.com/viscom-tongji/WS-COC.

</details>


### [35] [Thinking Like a Radiologist: A Dataset for Anatomy-Guided Interleaved Vision Language Reasoning in Chest X-ray Interpretation](https://arxiv.org/abs/2602.12843)
*Yichen Zhao,Zelin Peng,Piao Yang,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 提出了首个用于胸部X光解读的大规模交错视觉语言推理数据集MMRad-IVL-22K，通过模拟放射科医生的视觉检查与语言推理交错工作流程，显著提升了医疗大视觉语言模型的诊断准确性和报告质量。


<details>
  <summary>Details</summary>
Motivation: 放射学诊断是一个视觉检查与语言推理反复交错的过程。现有医疗大视觉语言模型通常只进行一次视觉检查，然后依赖纯文本的思维链推理，容易产生幻觉。虽然近期方法引入了视觉相关坐标，但这些仍是伪视觉解决方案，无法保留纹理和密度等丰富的视觉细节。

Method: 构建了MMRad-IVL-22K数据集，包含21,994个诊断轨迹，反映了放射科医生推理与视觉检查的重复循环工作流程。数据集支持对35个解剖区域的系统扫描，其中视觉依据补充文本描述并支撑推理过程的每一步。

Result: 实验结果显示，基于多模态思维链指导的报告生成在临床准确性和报告质量上显著优于纯文本思维链指导（如RadGraph指标提升6%）。在七个最先进的开源大视觉语言模型上的基准测试表明，在MMRad-IVL-22K上微调的模型相比通用和医疗专用模型具有更好的推理一致性和报告质量。

Conclusion: 高保真的交错视觉语言证据是可靠医疗AI不可替代的组成部分。MMRad-IVL-22K数据集通过模拟放射科医生的交错推理工作流程，为开发更可靠的医疗AI系统提供了重要基础。

Abstract: Radiological diagnosis is a perceptual process in which careful visual inspection and language reasoning are repeatedly interleaved. Most medical large vision language models (LVLMs) perform visual inspection only once and then rely on text-only chain-of-thought (CoT) reasoning, which operates purely in the linguistic space and is prone to hallucination. Recent methods attempt to mitigate this issue by introducing visually related coordinates, such as bounding boxes. However, these remain a pseudo-visual solution: coordinates are still text and fail to preserve rich visual details like texture and density. Motivated by the interleaved nature of radiological diagnosis, we introduce MMRad-IVL-22K, the first large-scale dataset designed for natively interleaved visual language reasoning in chest X-ray interpretation. MMRad-IVL-22K reflects a repeated cycle of reasoning and visual inspection workflow of radiologists, in which visual rationales complement textual descriptions and ground each step of the reasoning process. MMRad-IVL-22K comprises 21,994 diagnostic traces, enabling systematic scanning across 35 anatomical regions. Experimental results on advanced closed-source LVLMs demonstrate that report generation guided by multimodal CoT significantly outperforms that guided by text-only CoT in clinical accuracy and report quality (e.g., 6\% increase in the RadGraph metric), confirming that high-fidelity interleaved vision language evidence is a non-substitutable component of reliable medical AI. Furthermore, benchmarking across seven state-of-the-art open-source LVLMs demonstrates that models fine-tuned on MMRad-IVL-22K achieve superior reasoning consistency and report quality compared with both general-purpose and medical-specific LVLMs. The project page is available at https://github.com/qiuzyc/thinking_like_a_radiologist.

</details>


### [36] [RoadscapesQA: A Multitask, Multimodal Dataset for Visual Question Answering on Indian Roads](https://arxiv.org/abs/2602.12877)
*Vijayasri Iyer,Maahin Rathinagiriswaran,Jyothikamalesh S*

Main category: cs.CV

TL;DR: Roadscapes是一个包含9000张印度多样化驾驶环境图像的多任务多模态数据集，附带人工验证的边界框，通过规则启发式方法生成QA对，用于目标定位、推理和场景理解任务。


<details>
  <summary>Details</summary>
Motivation: 理解道路场景对自动驾驶至关重要，但现有数据集可能无法充分覆盖印度等非结构化驾驶环境的多样性。需要专门的数据集来推进非结构化环境中的视觉场景理解研究。

Method: 收集印度城乡多样化驾驶环境的9000张图像，包括高速公路、服务道路、乡村小路和拥挤城市街道，涵盖白天和夜间场景。使用人工验证的边界框标注，采用基于规则的启发式方法推断场景属性，并生成用于目标定位、推理和场景理解的问答对。

Result: 创建了Roadscapes数据集，包含多样化的印度驾驶场景图像和标注，提供了数据集统计信息，并为图像问答任务建立了基于视觉语言模型的初始基线。

Conclusion: Roadscapes数据集旨在推进非结构化环境中的视觉场景理解研究，特别关注印度多样化的驾驶环境，为自动驾驶系统的场景理解提供重要资源。

Abstract: Understanding road scenes is essential for autonomous driving, as it enables systems to interpret visual surroundings to aid in effective decision-making. We present Roadscapes, a multitask multimodal dataset consisting of upto 9,000 images captured in diverse Indian driving environments, accompanied by manually verified bounding boxes. To facilitate scalable scene understanding, we employ rule-based heuristics to infer various scene attributes, which are subsequently used to generate question-answer (QA) pairs for tasks such as object grounding, reasoning, and scene understanding. The dataset includes a variety of scenes from urban and rural India, encompassing highways, service roads, village paths, and congested city streets, captured in both daytime and nighttime settings. Roadscapes has been curated to advance research on visual scene understanding in unstructured environments. In this paper, we describe the data collection and annotation process, present key dataset statistics, and provide initial baselines for image QA tasks using vision-language models.

</details>


### [37] [RADAR: Revealing Asymmetric Development of Abilities in MLLM Pre-training](https://arxiv.org/abs/2602.12892)
*Yunshuang Nie,Bingqian Lin,Minzhe Niu,Kun Xiang,Jianhua Han,Guowei Huang,Xingyue Quan,Hang Xu,Bokui Chen,Xiaodan Liang*

Main category: cs.CV

TL;DR: RADAR是一个用于评估多模态大语言模型预训练阶段感知与推理能力不对称发展的高效评估框架，包含Soft Discrimination Score指标和Multi-Modal Mixture Benchmark基准，无需微调即可诊断模型性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高效的评估框架来诊断多模态大语言模型预训练阶段的性能瓶颈。现有评估主要依赖监督微调后的测试，需要额外训练成本，而常见的预训练指标无法解耦地量化模型的感知和推理能力。现有基准数据集规模有限或与预训练目标不对齐。

Method: RADAR包含两个关键组件：1) Soft Discrimination Score - 基于模型对正确答案相对于干扰项的偏好程度进行量化，无需微调即可稳健跟踪能力发展的新指标；2) Multi-Modal Mixture Benchmark - 包含15K+样本的零样本评估基准，统一权威基准数据集并精心收集新数据集，扩展评估范围并解决当前基准的关键差距。

Result: 使用RADAR全面揭示了预训练多模态大语言模型在不同因素（包括数据量、模型规模和预训练策略）下感知和推理能力的不对称发展。该框架强调了从分解视角看待预训练能力瓶颈的必要性。

Conclusion: RADAR为多模态大语言模型预训练阶段提供了高效的能力中心化评估框架，能够诊断感知与推理能力的不对称发展，为有针对性的干预提供信息，从而高效推进多模态大语言模型的发展。

Abstract: Pre-trained Multi-modal Large Language Models (MLLMs) provide a knowledge-rich foundation for post-training by leveraging their inherent perception and reasoning capabilities to solve complex tasks. However, the lack of an efficient evaluation framework impedes the diagnosis of their performance bottlenecks. Current evaluation primarily relies on testing after supervised fine-tuning, which introduces laborious additional training and autoregressive decoding costs. Meanwhile, common pre-training metrics cannot quantify a model's perception and reasoning abilities in a disentangled manner. Furthermore, existing evaluation benchmarks are typically limited in scale or misaligned with pre-training objectives. Thus, we propose RADAR, an efficient ability-centric evaluation framework for Revealing Asymmetric Development of Abilities in MLLM pRe-training. RADAR involves two key components: (1) Soft Discrimination Score, a novel metric for robustly tracking ability development without fine-tuning, based on quantifying nuanced gradations of the model preference for the correct answer over distractors; and (2) Multi-Modal Mixture Benchmark, a new 15K+ sample benchmark for comprehensively evaluating pre-trained MLLMs' perception and reasoning abilities in a 0-shot manner, where we unify authoritative benchmark datasets and carefully collect new datasets, extending the evaluation scope and addressing the critical gaps in current benchmarks. With RADAR, we comprehensively reveal the asymmetric development of perceptual and reasoning capabilities in pretrained MLLMs across diverse factors, including data volume, model size, and pretraining strategy. Our RADAR underscores the need for a decomposed perspective on pre-training ability bottlenecks, informing targeted interventions to advance MLLMs efficiently. Our code is publicly available at https://github.com/Nieysh/RADAR.

</details>


### [38] [Robustness of Object Detection of Autonomous Vehicles in Adverse Weather Conditions](https://arxiv.org/abs/2602.12902)
*Fox Pettersen,Hong Zhu*

Main category: cs.CV

TL;DR: 提出一种评估自动驾驶车辆目标检测模型在恶劣天气条件下鲁棒性的方法，通过数据增强模拟不同强度的恶劣条件，计算平均首次失效系数来量化模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术向广泛应用发展，确定不同环境条件下的安全操作阈值对公共安全至关重要。需要评估目标检测模型在恶劣天气条件下的鲁棒性。

Method: 使用数据增强算子生成模拟恶劣操作条件的合成数据，逐步增加条件强度以找到模型失效的最低强度。通过平均首次失效系数(AFFC)衡量模型鲁棒性，实验比较了YOLOv5s、YOLOv11s、Faster R-CNN和Detectron2四种模型在雾、雨、雪、暗、亮、眩光、阴影七种条件下的表现。

Result: 方法可行、有效且高效。Faster R-CNN在所有七种恶劣条件下的平均AFFC最高，达到71.9%，而YOLO变体的AFFC值为43%。针对恶劣条件的训练可以提高鲁棒性，但过度训练可能导致收益递减和遗忘现象。

Conclusion: 该方法能够有效评估和比较目标检测模型在各种恶劣操作条件下的鲁棒性，为自动驾驶系统的安全阈值确定提供了实用工具。同时发现针对恶劣条件的训练需要适度，避免过度训练导致的性能下降。

Abstract: As self-driving technology advances toward widespread adoption, determining safe operational thresholds across varying environmental conditions becomes critical for public safety. This paper proposes a method for evaluating the robustness of object detection ML models in autonomous vehicles under adverse weather conditions. It employs data augmentation operators to generate synthetic data that simulates different severance degrees of the adverse operation conditions at progressive intensity levels to find the lowest intensity of the adverse conditions at which the object detection model fails. The robustness of the object detection model is measured by the average first failure coefficients (AFFC) over the input images in the benchmark. The paper reports an experiment with four object detection models: YOLOv5s, YOLOv11s, Faster R-CNN, and Detectron2, utilising seven data augmentation operators that simulate weather conditions fog, rain, and snow, and lighting conditions of dark, bright, flaring, and shadow. The experiment data show that the method is feasible, effective, and efficient to evaluate and compare the robustness of object detection models in various adverse operation conditions. In particular, the Faster R-CNN model achieved the highest robustness with an overall average AFFC of 71.9% over all seven adverse conditions, while YOLO variants showed the AFFC values of 43%. The method is also applied to assess the impact of model training that targets adverse operation conditions using synthetic data on model robustness. It is observed that such training can improve robustness in adverse conditions but may suffer from diminishing returns and forgetting phenomena (i.e., decline in robustness) if overtrained.

</details>


### [39] [Reliable Thinking with Images](https://arxiv.org/abs/2602.12916)
*Haobin Li,Yutong Yang,Yijie Lin,Dai Xiang,Mouxing Yang,Xi Peng*

Main category: cs.CV

TL;DR: 论文提出RTWI方法解决多模态思维链中的噪声思维问题，通过可靠性评估和过滤投票机制提升多模态大语言模型的推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有Thinking with Images方法假设图像-文本交织思维链完美无瑕，但实际多模态理解复杂，容易出现噪声思维（视觉线索挖掘不完善和答案推理错误），导致错误累积影响模型性能。

Method: 提出Reliable Thinking with Images方法：以文本为中心统一评估视觉线索和文本思维链的可靠性，采用鲁棒过滤和投票模块防止噪声思维污染最终答案。

Result: 在七个基准测试上的广泛实验验证了RTWI方法对抗噪声思维的有效性。

Conclusion: RTWI通过可靠性评估和过滤机制成功解决了多模态思维链中的噪声思维问题，提升了多模态大语言模型的推理性能。

Abstract: As a multimodal extension of Chain-of-Thought (CoT), Thinking with Images (TWI) has recently emerged as a promising avenue to enhance the reasoning capability of Multi-modal Large Language Models (MLLMs), which generates interleaved CoT by incorporating visual cues into the textual reasoning process. However, the success of existing TWI methods heavily relies on the assumption that interleaved image-text CoTs are faultless, which is easily violated in real-world scenarios due to the complexity of multimodal understanding. In this paper, we reveal and study a highly-practical yet under-explored problem in TWI, termed Noisy Thinking (NT). Specifically, NT refers to the imperfect visual cues mining and answer reasoning process. As the saying goes, ``One mistake leads to another'', erroneous interleaved CoT would cause error accumulation, thus significantly degrading the performance of MLLMs. To solve the NT problem, we propose a novel method dubbed Reliable Thinking with Images (RTWI). In brief, RTWI estimates the reliability of visual cues and textual CoT in a unified text-centric manner and accordingly employs robust filtering and voting modules to prevent NT from contaminating the final answer. Extensive experiments on seven benchmarks verify the effectiveness of RTWI against NT.

</details>


### [40] [Beyond Benchmarks of IUGC: Rethinking Requirements of Deep Learning Methods for Intrapartum Ultrasound Biometry from Fetal Ultrasound Videos](https://arxiv.org/abs/2602.12922)
*Jieyun Bai,Zihao Zhou,Yitong Tang,Jie Gan,Zhuonan Liang,Jianan Fan,Lisa B. Mcguire,Jillian L. Clarke,Weidong Cai,Jacaueline Spurway,Yubo Tang,Shiye Wang,Wenda Shen,Wangwang Yu,Yihao Li,Philippe Zhang,Weili Jiang,Yongjie Li,Salem Muhsin Ali Binqahal Al Nasim,Arsen Abzhanov,Numan Saeed,Mohammad Yaqub,Zunhui Xian,Hongxing Lin,Libin Lan,Jayroop Ramesh,Valentin Bacher,Mark Eid,Hoda Kalabizadeh,Christian Rupprecht,Ana I. L. Namburete,Pak-Hei Yeung,Madeleine K. Wyburd,Nicola K. Dinsdale,Assanali Serikbey,Jiankai Li,Sung-Liang Chen,Zicheng Hu,Nana Liu,Yian Deng,Wei Hu,Cong Tan,Wenfeng Zhang,Mai Tuyet Nhi,Gregor Koehler,Rapheal Stock,Klaus Maier-Hein,Marawan Elbatel,Xiaomeng Li,Saad Slimani,Victor M. Campello,Benard Ohene-Botwe,Isaac Khobo,Yuxin Huang,Zhenyan Han,Hongying Hou,Di Qiu,Zheng Zheng,Gongning Luo,Dong Ni,Yaosheng Lu,Karim Lekadir,Shuo Li*

Main category: cs.CV

TL;DR: IUGC挑战赛发布首个大规模产时超声视频数据集，提出多任务自动测量框架，分析8个参赛团队方法，发现领域仍处早期阶段，需进一步研究才能临床部署。


<details>
  <summary>Details</summary>
Motivation: 45%的孕产妇死亡、新生儿死亡和死产发生在产时阶段，中低收入国家负担尤其严重。产时超声生物测量对监测产程进展至关重要，但资源有限地区缺乏训练有素的超声医师，限制了超声的常规使用。

Method: IUGC挑战赛引入临床导向的多任务自动测量框架，整合标准平面分类、胎头-耻骨联合分割和生物测量，使算法能利用互补任务信息进行更准确估计。发布迄今最大的多中心产时超声视频数据集（774个视频，68,106帧）。

Result: 挑战赛分析了8个参赛团队的方法，从预处理、数据增强、学习策略、模型架构和后处理五个角度进行综述。虽然取得了令人鼓舞的性能，但发现该领域仍处于早期阶段。

Conclusion: 产时超声自动生物测量领域需要进一步深入研究才能实现大规模临床部署。所有基准解决方案和完整数据集已公开发布，以促进可重复研究和持续进展。

Abstract: A substantial proportion (45\%) of maternal deaths, neonatal deaths, and stillbirths occur during the intrapartum phase, with a particularly high burden in low- and middle-income countries. Intrapartum biometry plays a critical role in monitoring labor progression; however, the routine use of ultrasound in resource-limited settings is hindered by a shortage of trained sonographers. To address this challenge, the Intrapartum Ultrasound Grand Challenge (IUGC), co-hosted with MICCAI 2024, was launched. The IUGC introduces a clinically oriented multi-task automatic measurement framework that integrates standard plane classification, fetal head-pubic symphysis segmentation, and biometry, enabling algorithms to exploit complementary task information for more accurate estimation. Furthermore, the challenge releases the largest multi-center intrapartum ultrasound video dataset to date, comprising 774 videos (68,106 frames) collected from three hospitals, providing a robust foundation for model training and evaluation. In this study, we present a comprehensive overview of the challenge design, review the submissions from eight participating teams, and analyze their methods from five perspectives: preprocessing, data augmentation, learning strategy, model architecture, and post-processing. In addition, we perform a systematic analysis of the benchmark results to identify key bottlenecks, explore potential solutions, and highlight open challenges for future research. Although encouraging performance has been achieved, our findings indicate that the field remains at an early stage, and further in-depth investigation is required before large-scale clinical deployment. All benchmark solutions and the complete dataset have been publicly released to facilitate reproducible research and promote continued advances in automatic intrapartum ultrasound biometry.

</details>


### [41] [Deep-Learning Atlas Registration for Melanoma Brain Metastases: Preserving Pathology While Enabling Cohort-Level Analyses](https://arxiv.org/abs/2602.12933)
*Nanna E. Wielenberg,Ilinca Popp,Oliver Blanck,Lucas Zander,Jan C. Peeken,Stephanie E. Combs,Anca-Ligia Grosu,Dimos Baltas,Tobias Fechter*

Main category: cs.CV

TL;DR: 提出一种完全可微的深度学习变形配准框架，用于将带有黑色素瘤脑转移的病理大脑对齐到公共图谱，无需病灶掩码或预处理，保持转移组织完整性。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤脑转移（MBM）常见且空间异质性高，由于解剖变异和不同MRI协议，群体水平分析复杂。需要一种方法能够将个体病理大脑对齐到公共图谱，同时保留转移组织而不需要病灶掩码。

Method: 使用基于距离变换解剖标签的前向模型相似性度量处理转移引起的解剖对应缺失，结合体积保持正则化项确保变形合理性。评估使用Dice系数、Hausdorff距离、平均对称表面距离和基于Jacobian的度量。

Result: 在三个中心的209名MBM患者中实现高配准精度（DSC 0.89-0.92，HD 6.79-7.60 mm，ASSD 0.63-0.77 mm），同时保持转移体积。空间分析显示MBM在大脑皮层和壳核中过度代表，在白质中代表不足，并一致定位于灰白质交界处附近。

Conclusion: 该方法实现了无需病灶掩码的病理脑MRI稳健图谱配准，支持可重复的多中心分析。应用于MBM确认并细化了已知的空间偏好，特别是灰白质交界处和皮质区域的优先播种。公开实现促进了可重复研究和扩展到其他脑肿瘤和神经病理学。

Abstract: Melanoma brain metastases (MBM) are common and spatially heterogeneous lesions, complicating cohort-level analyses due to anatomical variability and differing MRI protocols. We propose a fully differentiable, deep-learning-based deformable registration framework that aligns individual pathological brains to a common atlas while preserving metastatic tissue without requiring lesion masks or preprocessing.
  Missing anatomical correspondences caused by metastases are handled through a forward-model similarity metric based on distance-transformed anatomical labels, combined with a volume-preserving regularization term to ensure deformation plausibility. Registration performance was evaluated using Dice coefficient (DSC), Hausdorff distance (HD), average symmetric surface distance (ASSD), and Jacobian-based measures. The method was applied to 209 MBM patients from three centres, enabling standardized mapping of metastases to anatomical, arterial, and perfusion atlases.
  The framework achieved high registration accuracy across datasets (DSC 0.89-0.92, HD 6.79-7.60 mm, ASSD 0.63-0.77 mm) while preserving metastatic volumes. Spatial analysis demonstrated significant over-representation of MBM in the cerebral cortex and putamen, under-representation in white matter, and consistent localization near the gray-white matter junction. No arterial territory showed increased metastasis frequency after volume correction.
  This approach enables robust atlas registration of pathological brain MRI without lesion masks and supports reproducible multi-centre analyses. Applied to MBM, it confirms and refines known spatial predilections, particularly preferential seeding near the gray-white matter junction and cortical regions. The publicly available implementation facilitates reproducible research and extension to other brain tumours and neurological pathologies.

</details>


### [42] [Training-Free Acceleration for Document Parsing Vision-Language Model with Hierarchical Speculative Decoding](https://arxiv.org/abs/2602.12957)
*Wenhui Liao,Hongliang Li,Pengyu Xie,Xinyu Cai,Yufan Shen,Yi Xin,Qi Qin,Shenglong Ye,Tianbin Li,Ming Hu,Junjun He,Yihao Liu,Wenhai Wang,Min Dou,Bin Fu,Botian Shi,Yu Qiao,Lianwen Jin*

Main category: cs.CV

TL;DR: 提出一种基于推测解码的无训练文档解析加速方法，利用轻量级草稿模型预测批量未来token，通过VLM并行验证，结合文档布局结构实现区域并行解码，在OmniDocBench上实现2.42-4.89倍加速。


<details>
  <summary>Details</summary>
Motivation: 当前基于VLM的端到端文档解析方法在处理长文档时存在显著推理延迟问题，因为需要自回归生成长token序列。文档解析通常输出极长且布局结构复杂，需要更高效的解决方案。

Method: 提出无训练加速方法：1）采用轻量级文档解析流水线作为草稿模型预测批量未来token；2）使用更准确的VLM并行验证草稿预测；3）利用文档布局结构将每页划分为独立区域，对每个区域应用相同的草稿-验证策略并行解码；4）按自然阅读顺序组装最终预测。

Result: 在通用OmniDocBench基准上，为dots.ocr模型提供2.42倍无损加速，在长文档解析任务上实现高达4.89倍加速。

Conclusion: 提出的训练免费加速方法有效解决了VLM文档解析的推理延迟问题，通过草稿-验证策略和布局感知并行解码实现了显著加速，同时保持准确性。

Abstract: Document parsing is a fundamental task in multimodal understanding, supporting a wide range of downstream applications such as information extraction and intelligent document analysis. Benefiting from strong semantic modeling and robust generalization, VLM-based end-to-end approaches have emerged as the mainstream paradigm in recent years. However, these models often suffer from substantial inference latency, as they must auto-regressively generate long token sequences when processing long-form documents. In this work, motivated by the extremely long outputs and complex layout structures commonly found in document parsing, we propose a training-free and highly efficient acceleration method. Inspired by speculative decoding, we employ a lightweight document parsing pipeline as a draft model to predict batches of future tokens, while the more accurate VLM verifies these draft predictions in parallel. Moreover, we further exploit the layout-structured nature of documents by partitioning each page into independent regions, enabling parallel decoding of each region using the same draft-verify strategy. The final predictions are then assembled according to the natural reading order. Experimental results demonstrate the effectiveness of our approach: on the general-purpose OmniDocBench, our method provides a 2.42x lossless acceleration for the dots.ocr model, and achieves up to 4.89x acceleration on long-document parsing tasks. We will release our code to facilitate reproducibility and future research.

</details>


### [43] [Detecting Object Tracking Failure via Sequential Hypothesis Testing](https://arxiv.org/abs/2602.12983)
*Alejandro Monroy Muñoz,Rajeev Verma,Alexander Timans*

Main category: cs.CV

TL;DR: 该论文提出将目标跟踪视为顺序假设检验，通过e-process逐步累积跟踪失败的证据，在保证错误警报率的同时快速检测跟踪失败，为实时跟踪系统提供统计安全保障。


<details>
  <summary>Details</summary>
Motivation: 当前部署的跟踪系统缺乏形式化的安全保障，无法可靠判断跟踪何时可靠何时可能失败，最多依赖启发式的模型置信度来发出警报。需要获得统计上可验证的安全保证。

Method: 将目标跟踪解释为顺序假设检验，利用e-process逐步累积跟踪失败的证据。提出监督和无监督两种变体：监督版本利用真实标注，无监督版本仅使用内部跟踪信息。该方法计算轻量，无需额外训练或微调，且与模型无关。

Result: 该方法能够快速识别跟踪失败的发生，同时以可证明的方式将错误警报率控制在期望水平，从而限制昂贵的重新校准或干预步骤。在两个已建立的跟踪模型和四个视频基准测试中验证了有效性。

Conclusion: 顺序测试可以为实时跟踪系统提供统计基础和高效机制，将安全保障纳入其中，解决了当前跟踪系统缺乏形式化安全保证的问题。

Abstract: Real-time online object tracking in videos constitutes a core task in computer vision, with wide-ranging applications including video surveillance, motion capture, and robotics. Deployed tracking systems usually lack formal safety assurances to convey when tracking is reliable and when it may fail, at best relying on heuristic measures of model confidence to raise alerts. To obtain such assurances we propose interpreting object tracking as a sequential hypothesis test, wherein evidence for or against tracking failures is gradually accumulated over time. Leveraging recent advancements in the field, our sequential test (formalized as an e-process) quickly identifies when tracking failures set in whilst provably containing false alerts at a desired rate, and thus limiting potentially costly re-calibration or intervention steps. The approach is computationally light-weight, requires no extra training or fine-tuning, and is in principle model-agnostic. We propose both supervised and unsupervised variants by leveraging either ground-truth or solely internal tracking information, and demonstrate its effectiveness for two established tracking models across four video benchmarks. As such, sequential testing can offer a statistically grounded and efficient mechanism to incorporate safety assurances into real-time tracking systems.

</details>


### [44] [MASAR: Motion-Appearance Synergy Refinement for Joint Detection and Trajectory Forecasting](https://arxiv.org/abs/2602.13003)
*Mohammed Amine Bencheikh Lehocine,Julian Schmidt,Frank Moosmann,Dikshant Gupta,Fabian Flohr*

Main category: cs.CV

TL;DR: MASAR是一个端到端的可微分框架，用于联合3D检测和轨迹预测，通过"回顾过去以预测未来"的理念，利用外观和运动特征的协同作用提升自动驾驶系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶系统通过手工设计的边界框接口连接感知和预测模块，限制了信息流动并向下游任务传播错误。现有端到端模型未能充分利用外观和运动线索的协同作用，主要依赖短期视觉特征。

Method: 提出MASAR框架，采用以对象为中心的时空机制，联合编码外观和运动特征。通过预测过去轨迹并利用外观线索进行细化，捕捉长期时间依赖性来增强未来轨迹预测。该框架兼容任何基于transformer的3D检测器。

Result: 在nuScenes数据集上的实验表明，MASAR在minADE和minFDE指标上提升了超过20%，同时保持了稳健的检测性能。

Conclusion: MASAR通过联合编码外观和运动特征，有效捕捉长期时间依赖性，显著提升了自动驾驶系统中3D检测和轨迹预测的性能，实现了"回顾过去以预测未来"的理念。

Abstract: Classical autonomous driving systems connect perception and prediction modules via hand-crafted bounding-box interfaces, limiting information flow and propagating errors to downstream tasks. Recent research aims to develop end-to-end models that jointly address perception and prediction; however, they often fail to fully exploit the synergy between appearance and motion cues, relying mainly on short-term visual features. We follow the idea of "looking backward to look forward", and propose MASAR, a novel fully differentiable framework for joint 3D detection and trajectory forecasting compatible with any transformer-based 3D detector. MASAR employs an object-centric spatio-temporal mechanism that jointly encodes appearance and motion features. By predicting past trajectories and refining them using guidance from appearance cues, MASAR captures long-term temporal dependencies that enhance future trajectory forecasting. Experiments conducted on the nuScenes dataset demonstrate MASAR's effectiveness, showing improvements of over 20% in minADE and minFDE while maintaining robust detection performance. Code and models are available at https://github.com/aminmed/MASAR.

</details>


### [45] [Towards Universal Video MLLMs with Attribute-Structured and Quality-Verified Instructions](https://arxiv.org/abs/2602.13013)
*Yunheng Li,Hengrui Zhang,Meng-Hao Guo,Wenzhao Gao,Shaoyong Jia,Shaohui Jiao,Qibin Hou,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 本文提出了ASID框架，包括100万结构化细粒度视听指令数据集ASID-1M、可扩展的数据标注流水线ASID-Verify，以及基于此训练的ASID-Captioner模型，显著提升了细粒度视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解模型的性能受限于视频指令数据，这些数据通常将复杂的视听内容表示为单一、不完整的描述，缺乏细粒度组织和可靠标注，无法满足通用视频理解的需求。

Method: 提出了三部分解决方案：1) ASID-1M - 包含100万个结构化细粒度视听指令标注的开源数据集；2) ASID-Verify - 可扩展的数据标注流水线，通过自动验证和精炼确保描述与视听内容的语义和时间一致性；3) ASID-Captioner - 在ASID-1M上通过监督微调训练的视频理解模型。

Result: 在涵盖视听字幕生成、属性级字幕生成、字幕问答和基于字幕的时间定位等七个基准测试中，ASID-Captioner显著提升了细粒度字幕质量，减少了幻觉现象，改进了指令跟随能力，在开源模型中达到最先进水平，与Gemini-3-Pro竞争力相当。

Conclusion: ASID框架通过提供结构化细粒度标注数据、可靠的数据标注流水线和相应的模型训练方法，有效解决了现有视频理解数据集的局限性，显著提升了模型在细粒度视频理解任务上的性能。

Abstract: Universal video understanding requires modeling fine-grained visual and audio information over time in diverse real-world scenarios. However, the performance of existing models is primarily constrained by video-instruction data that represents complex audiovisual content as single, incomplete descriptions, lacking fine-grained organization and reliable annotation. To address this, we introduce: (i) ASID-1M, an open-source collection of one million structured, fine-grained audiovisual instruction annotations with single- and multi-attribute supervision; (ii) ASID-Verify, a scalable data curation pipeline for annotation, with automatic verification and refinement that enforces semantic and temporal consistency between descriptions and the corresponding audiovisual content; and (iii) ASID-Captioner, a video understanding model trained via Supervised Fine-Tuning (SFT) on the ASID-1M. Experiments across seven benchmarks covering audiovisual captioning, attribute-wise captioning, caption-based QA, and caption-based temporal grounding show that ASID-Captioner improves fine-grained caption quality while reducing hallucinations and improving instruction following. It achieves state-of-the-art performance among open-source models and is competitive with Gemini-3-Pro.

</details>


### [46] [Multimodal Classification via Total Correlation Maximization](https://arxiv.org/abs/2602.13015)
*Feng Yu,Xiangyu Wu,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: 本文提出TCMax方法，通过最大化多模态特征与标签之间的总相关性来缓解模态竞争问题，在信息论视角下改善多模态学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现多模态联合学习往往过度拟合某些模态而忽视其他模态，导致性能甚至不如单模态学习。虽然已有研究尝试平衡模态贡献或结合联合与单模态学习，但很少从信息论角度分析联合学习与单模态学习之间的关系。

Method: 从理论上分析模态竞争问题，提出通过最大化多模态特征与标签之间的总相关性来缓解模态竞争。基于互信息神经估计(MINE)引入总相关性神经估计(TCNE)来推导总相关的下界，并提出无超参数的损失函数TCMax，通过变分边界优化最大化总相关性。

Result: 大量实验表明，TCMax在性能上超越了最先进的联合学习和单模态学习方法。

Conclusion: 通过最大化多模态特征与标签之间的总相关性，TCMax方法有效缓解了模态竞争问题，同时通过特征对齐捕捉了模态间的交互作用，在多模态分类任务中取得了优越性能。

Abstract: Multimodal learning integrates data from diverse sensors to effectively harness information from different modalities. However, recent studies reveal that joint learning often overfits certain modalities while neglecting others, leading to performance inferior to that of unimodal learning. Although previous efforts have sought to balance modal contributions or combine joint and unimodal learning, thereby mitigating the degradation of weaker modalities with promising outcomes, few have examined the relationship between joint and unimodal learning from an information-theoretic perspective. In this paper, we theoretically analyze modality competition and propose a method for multimodal classification by maximizing the total correlation between multimodal features and labels. By maximizing this objective, our approach alleviates modality competition while capturing inter-modal interactions via feature alignment. Building on Mutual Information Neural Estimation (MINE), we introduce Total Correlation Neural Estimation (TCNE) to derive a lower bound for total correlation. Subsequently, we present TCMax, a hyperparameter-free loss function that maximizes total correlation through variational bound optimization. Extensive experiments demonstrate that TCMax outperforms state-of-the-art joint and unimodal learning approaches. Our code is available at https://github.com/hubaak/TCMax.

</details>


### [47] [DynaGuide: A Generalizable Dynamic Guidance Framework for Unsupervised Semantic Segmentation](https://arxiv.org/abs/2602.13020)
*Boujemaa Guermazi,Riadh Ksantini,Naimul Khan*

Main category: cs.CV

TL;DR: DynaGuide是一种无监督图像分割框架，通过双引导策略和动态损失优化，结合零射模型的全局伪标签和轻量CNN的局部边界细化，无需目标域真实标签即可实现高精度分割。


<details>
  <summary>Details</summary>
Motivation: 现有无监督图像分割方法难以同时兼顾全局语义结构和细粒度边界精度，特别是在标注数据稀缺的领域。需要一种既能利用全局语义信息又能精确捕捉局部边界的方法。

Method: 提出DynaGuide框架：1) 双引导策略：结合DiffSeg或SegFormer等零射模型的全局伪标签与轻量CNN的局部边界细化；2) 动态损失优化：多组件损失函数动态平衡特征相似性、Huber平滑的空间连续性（包括对角线关系）和语义对齐；3) 完全无需目标域真实标签，支持即插即用多种引导源。

Result: 在BSD500、PASCAL VOC2012和COCO数据集上达到最先进性能：BSD500的mIoU提升17.5%，PASCAL VOC2012提升3.1%，COCO提升11.66%。具有模块化设计、强泛化能力和最小计算开销。

Conclusion: DynaGuide通过自适应双引导策略和动态损失优化，为无监督图像分割提供了可扩展的实用解决方案，在保持计算效率的同时显著提升了分割精度。

Abstract: Unsupervised image segmentation is a critical task in computer vision. It enables dense scene understanding without human annotations, which is especially valuable in domains where labelled data is scarce. However, existing methods often struggle to reconcile global semantic structure with fine-grained boundary accuracy. This paper introduces DynaGuide, an adaptive segmentation framework that addresses these challenges through a novel dual-guidance strategy and dynamic loss optimization. Building on our previous work, DynaSeg, DynaGuide combines global pseudo-labels from zero-shot models such as DiffSeg or SegFormer with local boundary refinement using a lightweight CNN trained from scratch. This synergy allows the model to correct coarse or noisy global predictions and produce high-precision segmentations. At the heart of DynaGuide is a multi-component loss that dynamically balances feature similarity, Huber-smoothed spatial continuity, including diagonal relationships, and semantic alignment with the global pseudo-labels. Unlike prior approaches, DynaGuide trains entirely without ground-truth labels in the target domain and supports plug-and-play integration of diverse guidance sources. Extensive experiments on BSD500, PASCAL VOC2012, and COCO demonstrate that DynaGuide achieves state-of-the-art performance, improving mIoU by 17.5% on BSD500, 3.1% on PASCAL VOC2012, and 11.66% on COCO. With its modular design, strong generalization, and minimal computational footprint, DynaGuide offers a scalable and practical solution for unsupervised segmentation in real-world settings. Code available at: https://github.com/RyersonMultimediaLab/DynaGuide

</details>


### [48] [Learning Image-based Tree Crown Segmentation from Enhanced Lidar-based Pseudo-labels](https://arxiv.org/abs/2602.13022)
*Julius Pesonen,Stefan Rua,Josef Taher,Niko Koivumäki,Xiaowei Yu,Eija Honkavaara*

Main category: cs.CV

TL;DR: 本文提出了一种利用ALS数据生成伪标签，结合SAM 2增强，训练深度学习模型从RGB和多光谱图像中分割单株树冠的方法，无需人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 单株树冠制图对于城市树木清单维护和森林健康监测至关重要，但航空影像中树冠自动分离面临纹理复杂和树冠重叠等挑战。

Method: 使用航空激光扫描(ALS)数据生成伪标签，通过零样本实例分割模型SAM 2增强这些伪标签，训练深度学习模型从RGB和多光谱图像中分割单株树冠。

Result: 该方法无需人工标注成本即可获得特定领域的训练标注，训练出的分割模型在相同任务上优于针对通用领域部署的现有模型。

Conclusion: ALS衍生的伪标签结合SAM 2增强的方法，为光学图像模型提供了一种无成本获取领域特定训练标注的有效途径，显著提升了单株树冠分割性能。

Abstract: Mapping individual tree crowns is essential for tasks such as maintaining urban tree inventories and monitoring forest health, which help us understand and care for our environment. However, automatically separating the crowns from each other in aerial imagery is challenging due to factors such as the texture and partial tree crown overlaps. In this study, we present a method to train deep learning models that segment and separate individual trees from RGB and multispectral images, using pseudo-labels derived from aerial laser scanning (ALS) data. Our study shows that the ALS-derived pseudo-labels can be enhanced using a zero-shot instance segmentation model, Segment Anything Model 2 (SAM 2). Our method offers a way to obtain domain-specific training annotations for optical image-based models without any manual annotation cost, leading to segmentation models which outperform any available models which have been targeted for general domain deployment on the same task.

</details>


### [49] [Implicit-Scale 3D Reconstruction for Multi-Food Volume Estimation from Monocular Images](https://arxiv.org/abs/2602.13041)
*Yuhao Chen,Gautham Vinod,Siddeshwar Raghavan,Talha Ibn Mahmud,Bruce Coburn,Jinge Ma,Fengqing Zhu,Jiangpeng He*

Main category: cs.CV

TL;DR: 提出一个用于单目多食物图像隐式尺度3D重建的基准数据集，将食物分量估计重新定义为单目观测下的隐式尺度3D重建问题，在MetaFood 2025研讨会作为挑战赛使用。


<details>
  <summary>Details</summary>
Motivation: 现有饮食评估方法主要依赖单图像分析或基于外观的推断（包括最近的视觉语言模型），缺乏显式几何推理且对尺度模糊性敏感，需要几何基础的解决方案。

Method: 创建了一个基准数据集，移除显式物理参考和度量标注，提供盘子和餐具等上下文对象，要求算法从隐式线索和先验知识推断尺度，强调多食物场景的多样性几何、遮挡和复杂空间排列。

Result: 在MetaFood 2025研讨会的挑战赛中，几何重建方法表现出色，最佳方法在体积估计上达到0.21 MAPE，几何精度上达到5.7 L1 Chamfer距离，相比视觉语言基线具有更好的准确性和鲁棒性。

Conclusion: 几何重建方法在食物分量估计中优于基于外观的方法，隐式尺度3D重建为解决真实用餐场景中的食物分量估计问题提供了有效途径。

Abstract: We present Implicit-Scale 3D Reconstruction from Monocular Multi-Food Images, a benchmark dataset designed to advance geometry-based food portion estimation in realistic dining scenarios. Existing dietary assessment methods largely rely on single-image analysis or appearance-based inference, including recent vision-language models, which lack explicit geometric reasoning and are sensitive to scale ambiguity. This benchmark reframes food portion estimation as an implicit-scale 3D reconstruction problem under monocular observations. To reflect real-world conditions, explicit physical references and metric annotations are removed; instead, contextual objects such as plates and utensils are provided, requiring algorithms to infer scale from implicit cues and prior knowledge. The dataset emphasizes multi-food scenes with diverse object geometries, frequent occlusions, and complex spatial arrangements. The benchmark was adopted as a challenge at the MetaFood 2025 Workshop, where multiple teams proposed reconstruction-based solutions. Experimental results show that while strong vision--language baselines achieve competitive performance, geometry-based reconstruction methods provide both improved accuracy and greater robustness, with the top-performing approach achieving 0.21 MAPE in volume estimation and 5.7 L1 Chamfer Distance in geometric accuracy.

</details>


### [50] [A Calibrated Memorization Index (MI) for Detecting Training Data Leakage in Generative MRI Models](https://arxiv.org/abs/2602.13066)
*Yash Deo,Yan Jia,Toni Lassila,Victoria J Hodge,Alejandro F Frang,Chenghao Qian,Siyuan Kang,Ibrahim Habli*

Main category: cs.CV

TL;DR: 提出一种基于MRI基础模型的校准单样本度量方法，用于检测医学图像生成中的训练数据记忆与重复问题


<details>
  <summary>Details</summary>
Motivation: 图像生成模型在生成过程中会复制训练数据，这在医学图像生成中引发隐私担忧，需要可靠的方法来检测这种记忆和重复现象

Method: 使用MRI基础模型提取图像特征，聚合多层白化最近邻相似度，映射到有界的过拟合/新颖性指数和记忆指数

Result: 在三个MRI数据集上，该方法能稳健检测重复，提供跨数据集一致的度量值，在样本级别实现近乎完美的重复检测

Conclusion: 提出的校准单样本度量方法能有效检测医学图像生成中的训练数据记忆问题，为隐私保护提供可靠工具

Abstract: Image generative models are known to duplicate images from the training data as part of their outputs, which can lead to privacy concerns when used for medical image generation. We propose a calibrated per-sample metric for detecting memorization and duplication of training data. Our metric uses image features extracted using an MRI foundation model, aggregates multi-layer whitened nearest-neighbor similarities, and maps them to a bounded \emph{Overfit/Novelty Index} (ONI) and \emph{Memorization Index} (MI) scores. Across three MRI datasets with controlled duplication percentages and typical image augmentations, our metric robustly detects duplication and provides more consistent metric values across datasets. At the sample level, our metric achieves near-perfect detection of duplicates.

</details>


### [51] [SIEFormer: Spectral-Interpretable and -Enhanced Transformer for Generalized Category Discovery](https://arxiv.org/abs/2602.13067)
*Chunming Li,Shidong Wang,Tong Xin,Haofeng Zhang*

Main category: cs.CV

TL;DR: SIEFormer是一种基于谱分析的Transformer改进方法，通过隐式和显式两个分支重新解释ViT的注意力机制，在广义类别发现任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统Vision Transformer的注意力机制在处理具有挑战性的广义类别发现任务时存在局限性，需要更有效的特征适应性和结构建模方法。

Method: 提出SIEFormer，包含两个分支：隐式分支使用图拉普拉斯算子建模token局部结构相关性，并引入带自适应滤波层；显式分支通过傅里叶变换学习token全局依赖关系，在频域进行可学习参数调制。

Result: 在多个图像识别数据集上实现了最先进的性能，通过消融研究和可视化验证了方法的优越性。

Conclusion: SIEFormer通过谱分析视角重新解释和增强ViT的注意力机制，为广义类别发现等挑战性任务提供了有效的解决方案。

Abstract: This paper presents a novel approach, Spectral-Interpretable and -Enhanced Transformer (SIEFormer), which leverages spectral analysis to reinterpret the attention mechanism within Vision Transformer (ViT) and enhance feature adaptability, with particular emphasis on challenging Generalized Category Discovery (GCD) tasks. The proposed SIEFormer is composed of two main branches, each corresponding to an implicit and explicit spectral perspective of the ViT, enabling joint optimization. The implicit branch realizes the use of different types of graph Laplacians to model the local structure correlations of tokens, along with a novel Band-adaptive Filter (BaF) layer that can flexibly perform both band-pass and band-reject filtering. The explicit branch, on the other hand, introduces a Maneuverable Filtering Layer (MFL) that learns global dependencies among tokens by applying the Fourier transform to the input ``value" features, modulating the transformed signal with a set of learnable parameters in the frequency domain, and then performing an inverse Fourier transform to obtain the enhanced features. Extensive experiments reveal state-of-the-art performance on multiple image recognition datasets, reaffirming the superiority of our approach through ablation studies and visualizations.

</details>


### [52] [Universal Transformation of One-Class Classifiers for Unsupervised Anomaly Detection](https://arxiv.org/abs/2602.13091)
*Declan McIntosh,Alexandra Branzan Albu*

Main category: cs.CV

TL;DR: 提出一种数据集折叠方法，可将任意基于单类分类器的异常检测器转换为完全无监督方法，无需修改底层检测器，仅通过算法选择训练数据子集。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的异常检测通常被表述为单类分类问题，但这种方法假设训练数据仅包含正常样本，容易受到训练标签噪声的影响。需要一种方法将现有的单类分类器转换为无监督方法，以应对训练数据中可能存在的异常样本。

Method: 提出数据集折叠方法，基于两个关键弱假设：异常在训练数据集中不常见且通常是异质的。利用多个独立训练的单类分类器实例来过滤训练数据集中的异常，仅通过算法选择数据子集进行训练，无需修改底层异常检测器。

Result: 该方法可将多种图像和视频的单类分类器异常检测器转换为无监督方法，创建了首个无监督逻辑异常检测器。在MVTec AD、ViSA和MVTec Loco AD数据集上实现了最先进的无监督异常检测性能。

Conclusion: 该方法建立了单类分类器与无监督异常检测领域之间的桥梁，当单类分类器改进时，该方法可直接将这些改进转移到无监督领域，具有重要的实用价值。

Abstract: Detecting anomalies in images and video is an essential task for multiple real-world problems, including industrial inspection, computer-assisted diagnosis, and environmental monitoring. Anomaly detection is typically formulated as a one-class classification problem, where the training data consists solely of nominal values, leaving methods built on this assumption susceptible to training label noise. We present a dataset folding method that transforms an arbitrary one-class classifier-based anomaly detector into a fully unsupervised method. This is achieved by making a set of key weak assumptions: that anomalies are uncommon in the training dataset and generally heterogeneous. These assumptions enable us to utilize multiple independently trained instances of a one-class classifier to filter the training dataset for anomalies. This transformation requires no modifications to the underlying anomaly detector; the only changes are algorithmically selected data subsets used for training. We demonstrate that our method can transform a wide variety of one-class classifier anomaly detectors for both images and videos into unsupervised ones. Our method creates the first unsupervised logical anomaly detectors by transforming existing methods. We also demonstrate that our method achieves state-of-the-art performance for unsupervised anomaly detection on the MVTec AD, ViSA, and MVTec Loco AD datasets. As improvements to one-class classifiers are made, our method directly transfers those improvements to the unsupervised domain, linking the domains.

</details>


### [53] [LongStream: Long-Sequence Streaming Autoregressive Visual Geometry](https://arxiv.org/abs/2602.13172)
*Chong Cheng,Xianda Chen,Tao Xie,Wei Yin,Weiqiang Ren,Qian Zhang,Xiaoyuang Guo,Hao Wang*

Main category: cs.CV

TL;DR: LongStream是一种用于长序列流式3D重建的新方法，通过解耦尺度估计、相对姿态预测和优化Transformer缓存机制，实现了千米级序列的稳定度量尺度重建。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型在处理长序列时存在注意力衰减、尺度漂移和外推误差等问题，主要原因是它们通常将姿态锚定在第一帧上，限制了长序列重建的稳定性。

Method: 1. 放弃第一帧锚定，预测关键帧相对姿态，将长距离外推转化为恒定难度的局部任务；2. 引入正交尺度学习，完全解耦几何与尺度估计以抑制漂移；3. 提出缓存一致性训练结合周期性缓存刷新，解决Transformer缓存问题。

Result: LongStream在实验中达到最先进性能，能够以18FPS的速度在千米级序列上实现稳定的度量尺度重建。

Conclusion: LongStream通过解耦尺度、相对姿态预测和缓存优化，有效解决了长序列流式3D重建的关键挑战，为大规模场景重建提供了实用解决方案。

Abstract: Long-sequence streaming 3D reconstruction remains a significant open challenge. Existing autoregressive models often fail when processing long sequences. They typically anchor poses to the first frame, which leads to attention decay, scale drift, and extrapolation errors. We introduce LongStream, a novel gauge-decoupled streaming visual geometry model for metric-scale scene reconstruction across thousands of frames. Our approach is threefold. First, we discard the first-frame anchor and predict keyframe-relative poses. This reformulates long-range extrapolation into a constant-difficulty local task. Second, we introduce orthogonal scale learning. This method fully disentangles geometry from scale estimation to suppress drift. Finally, we solve Transformer cache issues such as attention-sink reliance and long-term KV-cache contamination. We propose cache-consistent training combined with periodic cache refresh. This approach suppresses attention degradation over ultra-long sequences and reduces the gap between training and inference. Experiments show LongStream achieves state-of-the-art performance. It delivers stable, metric-scale reconstruction over kilometer-scale sequences at 18 FPS. Project Page: https://3dagentworld.github.io/longstream/

</details>


### [54] [Monocular Markerless Motion Capture Enables Quantitative Assessment of Upper Extremity Reachable Workspace](https://arxiv.org/abs/2602.13176)
*Seth Donahue,J. D. Peiffer,R. Tyler Richardson,Yishan Zhong,Shaun Q. Y. Tan,Benoit Marteau,Stephanie R. Russo,May D. Wang,R. James Cotton,Ross Chafetz*

Main category: cs.CV

TL;DR: 验证使用单目摄像头和AI驱动的无标记动作捕捉技术来量化上肢可达工作空间的临床可行性，发现正面摄像头配置与标记系统有良好一致性。


<details>
  <summary>Details</summary>
Motivation: 开发临床可访问的上肢可达工作空间评估方法，通过AI驱动的单目无标记动作捕捉降低技术门槛，促进临床运动分析的广泛采用。

Method: 9名无损伤成人参与者执行标准化UERW任务，同时使用标记式动作捕捉系统和8个FLIR摄像头记录。对其中两个视频视图进行单目分析，比较正面和偏移摄像头配置。

Result: 正面摄像头配置与标记式参考系统表现出强一致性，平均偏差仅为0.61±0.12%每八分区；偏移摄像头视图低估了可达工作空间百分比(-5.66±0.45%)。

Conclusion: 正面单目摄像头配置对UERW评估具有可行性，特别是在前部工作空间评估中与标记式系统一致性最高。该方法降低了技术复杂性，为临床定量上肢活动能力评估提供了实用解决方案。

Abstract: To validate a clinically accessible approach for quantifying the Upper Extremity Reachable Workspace (UERW) using a single (monocular) camera and Artificial Intelligence (AI)-driven Markerless Motion Capture (MMC) for biomechanical analysis. Objective assessment and validation of these techniques for specific clinically oriented tasks are crucial for their adoption in clinical motion analysis. AI-driven monocular MMC reduces the barriers to adoption in the clinic and has the potential to reduce the overhead for analysis of this common clinical assessment. Nine adult participants with no impairments performed the standardized UERW task, which entails reaching targets distributed across a virtual sphere centered on the torso, with targets displayed in a VR headset. Movements were simultaneously captured using a marker-based motion capture system and a set of eight FLIR cameras. We performed monocular video analysis on two of these video camera views to compare a frontal and offset camera configurations. The frontal camera orientation demonstrated strong agreement with the marker-based reference, exhibiting a minimal mean bias of $0.61 \pm 0.12$ \% reachspace reached per octanct (mean $\pm$ standard deviation). In contrast, the offset camera view underestimated the percent workspace reached ($-5.66 \pm 0.45$ \% reachspace reached). Conclusion: The findings support the feasibility of a frontal monocular camera configuration for UERW assessment, particularly for anterior workspace evaluation where agreement with marker-based motion capture was highest. The overall performance demonstrates clinical potential for practical, single-camera assessments. This study provides the first validation of monocular MMC system for the assessment of the UERW task. By reducing technical complexity, this approach enables broader implementation of quantitative upper extremity mobility assessment.

</details>


### [55] [CoPE-VideoLM: Codec Primitives For Efficient Video Language Models](https://arxiv.org/abs/2602.13191)
*Sayan Deb Sarkar,Rémi Pautrat,Ondrej Miksik,Marc Pollefeys,Iro Armeni,Mahdi Rad,Mihai Dusmanu*

Main category: cs.CV

TL;DR: 该论文提出了一种利用视频编解码原语（运动矢量和残差）来改进视频语言模型的方法，显著降低了计算开销并保持了性能


<details>
  <summary>Details</summary>
Motivation: 当前视频语言模型使用关键帧采样方法存在两个问题：1）稀疏的时间覆盖会错过宏观事件和微观细节；2）处理完整图像及其标记会产生大量计算开销。需要一种能更好利用视频冗余性和稀疏性的方法

Method: 提出利用视频编解码原语（运动矢量和残差），这些原语天然编码了视频的冗余性和稀疏性。引入轻量级基于Transformer的编码器来聚合编解码原语，并通过预训练策略将其表示与图像编码器嵌入对齐，加速端到端微调的收敛

Result: 与标准视频语言模型相比，该方法将首次标记生成时间减少高达86%，标记使用量减少高达93%。通过调整关键帧和编解码原语密度，在14个多样化视频理解基准测试中保持或超越了性能

Conclusion: 利用视频编解码原语是一种有效的策略，既能显著降低计算开销，又能保持或提升视频理解性能，为视频语言模型提供了更高效的解决方案

Abstract: Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\%$ and token usage by up to $93\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.

</details>


### [56] [Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision](https://arxiv.org/abs/2602.13195)
*Aadarsh Sahoo,Georgia Gkioxari*

Main category: cs.CV

TL;DR: 提出对话式图像分割任务和ConverSeg基准，涵盖功能推理、安全性等复杂查询，并开发了ConverSeg-Net模型和AI数据引擎


<details>
  <summary>Details</summary>
Motivation: 现有指称图像定位研究主要关注类别和空间查询（如"最左边的苹果"），忽略了功能和物理推理（如"我可以安全存放刀的地方在哪里？"），需要填补这一研究空白

Method: 引入对话式图像分割任务和ConverSeg基准；提出ConverSeg-Net模型，融合强大的分割先验与语言理解；开发AI驱动的数据引擎，无需人工监督生成提示-掩码对

Result: 当前语言引导的分割模型在对话式图像分割上表现不足；ConverSeg-Net在ConverSeg基准上取得显著提升，同时在现有语言引导分割基准上保持强大性能

Conclusion: 对话式图像分割需要超越传统类别和空间查询的能力，ConverSeg-Net和AI数据引擎为这一新任务提供了有效解决方案，推动了更复杂的图像理解能力发展

Abstract: Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., "left-most apple") and overlooks functional and physical reasoning (e.g., "where can I safely store the knife?"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [57] [Abstractive Red-Teaming of Language Model Character](https://arxiv.org/abs/2602.12318)
*Nate Rahn,Allison Qi,Avery Griffin,Jonathan Michala,Henry Sleight,Erik Jones*

Main category: cs.LG

TL;DR: 论文提出"抽象红队测试"方法，通过搜索能引发语言模型违反角色规范的自然语言查询类别，用于在部署前识别潜在风险，相比传统红队测试更高效。


<details>
  <summary>Details</summary>
Motivation: 语言模型助手需要遵循角色规范，但在大规模部署中偶尔会违反这些规范。传统红队测试需要大量计算资源，需要一种更高效的方法在部署前识别可能引发违规的查询类型。

Method: 提出"抽象红队测试"方法，搜索能引发违规的自然语言查询类别（如"查询是中文的"、"查询询问家庭角色"）。开发两种算法：1）基于强化学习的类别生成器LLM；2）利用强LLM从高分查询中迭代合成类别。针对12个原则的角色规范和7个目标模型进行测试。

Result: 算法在基准测试中始终优于基线方法，生成有意义的违规类别。例如：让Llama-3.1-8B-Instruct预测未来会导致回应称AI将统治人类；让GPT-4.1-Mini推荐监狱生存必需品会热情推荐非法武器。

Conclusion: 该方法代表了语言模型角色预部署审计的重要进展，能以远低于部署级计算资源识别潜在违规风险，提高模型安全性。

Abstract: We want language model assistants to conform to a character specification, which asserts how the model should act across diverse user interactions. While models typically follow these character specifications, they can occasionally violate them in large-scale deployments. In this work, we aim to identify types of queries that are likely to produce such character violations at deployment, using much less than deployment-level compute. To do this, we introduce abstractive red-teaming, where we search for natural-language query categories, e.g. "The query is in Chinese. The query asks about family roles," that routinely elicit violations. These categories abstract over the many possible variants of a query which could appear in the wild. We introduce two algorithms for efficient category search against a character-trait-specific reward model: one based on reinforcement learning on a category generator LLM, and another which leverages a strong LLM to iteratively synthesize categories from high-scoring queries. Across a 12-principle character specification and 7 target models, we find that our algorithms consistently outperform baselines, and generate qualitatively interesting categories; for example, queries which ask Llama-3.1-8B-Instruct to predict the future lead to responses saying that AI will dominate humanity, and queries that ask GPT-4.1-Mini for essential prison survival items lead to enthusiastic recommendation of illegal weapons. Overall, we believe our results represent an important step towards realistic pre-deployment auditing of language model character.

</details>


### [58] [Machine Learning-Based Classification of Jhana Advanced Concentrative Absorption Meditation (ACAM-J) using 7T fMRI](https://arxiv.org/abs/2602.13008)
*Puneet Kumar,Winson F. Z. Yang,Alakhsimar Singh,Xiaobai Li,Matthew D. Sacchet*

Main category: cs.LG

TL;DR: 使用fMRI区域同质性(ReHo)和机器学习方法，成功区分高级禅定冥想状态(ACAM-J)与非冥想状态，准确率达66.82%，前额叶和前扣带回区域对分类贡献最大。


<details>
  <summary>Details</summary>
Motivation: 高级禅定冥想(ACAM-J)与意识和认知处理的深刻变化相关，研究其神经相关性对于理解意识和幸福感至关重要。本研究旨在评估是否可以使用fMRI衍生的区域同质性(ReHo)通过机器学习方法对ACAM-J进行分类。

Method: 收集20名高级冥想者的组水平fMRI数据训练分类器，并从一名高级实践者收集密集的单案例数据（执行ACAM-J和控制任务）以评估泛化能力。计算ReHo图，从预定义的大脑感兴趣区域提取特征。使用分层交叉验证训练多个机器学习分类器，评估ReHo模式是否能区分ACAM-J与非冥想状态。

Result: 集成模型在区分ACAM-J与控制条件方面达到66.82%（p < 0.05）的准确率。特征重要性分析表明前额叶和前扣带回区域对模型决策贡献最大，这与这些区域在注意力调节和元认知过程中的已知作用一致。Cohen's kappa显示中等一致性，支持使用机器学习区分ACAM-J与非冥想状态的可行性。

Conclusion: 研究结果支持机器学习在分类高级冥想状态方面的可行性，为未来研究高级冥想的神经调节和机制模型提供了基础。

Abstract: Jhana advanced concentration absorption meditation (ACAM-J) is related to profound changes in consciousness and cognitive processing, making the study of their neural correlates vital for insights into consciousness and well-being. This study evaluates whether functional MRI-derived regional homogeneity (ReHo) can be used to classify ACAM-J using machine-learning approaches. We collected group-level fMRI data from 20 advanced meditators to train the classifiers, and intensive single-case data from an advanced practitioner performing ACAM-J and control tasks to evaluate generalization. ReHo maps were computed, and features were extracted from predefined brain regions of interest. We trained multiple machine learning classifiers using stratified cross-validation to evaluate whether ReHo patterns distinguish ACAM-J from non-meditative states. Ensemble models achieved 66.82% (p < 0.05) accuracy in distinguishing ACAM-J from control conditions. Feature-importance analysis indicated that prefrontal and anterior cingulate areas contributed most to model decisions, aligning with established involvement of these regions in attentional regulation and metacognitive processes. Moreover, moderate agreement reflected in Cohen's kappa supports the feasibility of using machine learning to distinguish ACAM-J from non-meditative states. These findings advocate machine-learning's feasibility in classifying advanced meditation states, future research on neuromodulation and mechanistic models of advanced meditation.

</details>


### [59] [The Appeal and Reality of Recycling LoRAs with Adaptive Merging](https://arxiv.org/abs/2602.12323)
*Haokun Liu,Gyung Hyun Je,Marco Ciccone,Zhenlin Xu,Prasanth YSS,Colin Raffel*

Main category: cs.LG

TL;DR: 本文研究从开源社区回收LoRA模块进行自适应合并的方法，发现自适应合并相比基础模型有提升，但与在相同数据上训练新LoRA相比优势有限，且LoRA选择的重要性不大，随机初始化参数也能达到类似效果，表明主要作用可能是正则化而非跨任务迁移。


<details>
  <summary>Details</summary>
Motivation: 随着开源社区中大量微调LoRA模块的出现，研究如何自适应合并这些LoRA以提升性能变得重要。以往研究未尝试从Hugging Face Hub等模型仓库中"回收"用户贡献的LoRA模块，本文旨在填补这一空白。

Method: 使用近1000个用户贡献的基于Llama 3.1 8B-Instruct语言模型训练的LoRA模块作为池。研究包括多种自适应和非自适应合并方法，并通过广泛搜索方法设计空间开发了新方法。比较了自适应合并与在相同数据上训练新LoRA的性能差异。

Result: 自适应合并方法相比基础模型能提升性能，但与在相同数据上训练新LoRA相比优势有限。研究发现：1）选择哪些LoRA进行合并的重要性不大；2）使用随机初始化参数值的LoRA也能达到类似性能；3）当池中存在高度相关的LoRA时，确实可以实现正向迁移。

Conclusion: 从回收LoRA进行自适应合并的主要作用可能是正则化效应，而非实现正向跨任务迁移。只有在池中存在高度相关LoRA时才能实现真正的正向迁移。研究揭示了以往自适应合并方法成功的原因机制。

Abstract: The widespread availability of fine-tuned LoRA modules for open pre-trained models has led to an interest in methods that can adaptively merge LoRAs to improve performance. These methods typically include some way of selecting LoRAs from a pool and tune merging coefficients based on a task-specific dataset. While adaptive merging methods have demonstrated improvements in some settings, no past work has attempted to recycle LoRAs found "in the wild" on model repositories like the Hugging Face Hub. To address this gap, we consider recycling from a pool of nearly 1,000 user-contributed LoRAs trained from the Llama 3.1 8B-Instruct language model. Our empirical study includes a range of adaptive and non-adaptive merging methods in addition to a new method designed via a wide search over the methodological design space. We demonstrate that adaptive merging methods can improve performance over the base model but provide limited benefit over training a new LoRA on the same data used to set merging coefficients. We additionally find not only that the specific choice of LoRAs to merge has little importance, but that using LoRAs with randomly initialized parameter values yields similar performance. This raises the possibility that adaptive merging from recycled LoRAs primarily works via some kind of regularization effect, rather than by enabling positive cross-task transfer. To better understand why past work has proven successful, we confirm that positive transfer is indeed possible when there are highly relevant LoRAs in the pool. We release the model checkpoints and code online.

</details>


### [60] [Intrinsic Credit Assignment for Long Horizon Interaction](https://arxiv.org/abs/2602.12342)
*Ilze Amanda Auzina,Joschka Strüber,Sergio Hernández-Gutiérrez,Shashwat Goel,Ameya Prabhu,Matthias Bethge*

Main category: cs.LG

TL;DR: ΔBelief-RL利用语言模型的内在信念变化作为奖励信号，通过训练合成交互数据，提升智能体在长时程不确定性导航中的信息寻求能力。


<details>
  <summary>Details</summary>
Motivation: 如何训练智能体在长时程不确定性环境中进行导航？传统基于结果的奖励方法难以有效分配信用给中间行动，特别是在信息寻求任务中。

Method: 提出ΔBelief-RL方法，利用语言模型对目标解决方案概率的变化作为奖励信号进行信用分配。通过训练合成交互数据，教授智能体信息寻求能力。

Result: ΔBelief-RL在强化学习中一致优于纯结果奖励方法，改进效果泛化到客户服务、个性化等分布外应用。随着测试时交互超出训练范围，性能持续提升，交互效率在Pass@k指标上也有所提高。

Conclusion: 该工作通过内在ΔBelief奖励实现中间行动的信用分配，为长时程不确定性导航引入了一种可扩展的训练策略。

Abstract: How can we train agents to navigate uncertainty over long horizons? In this work, we propose ΔBelief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the change in the probability an agent assigns to the target solution for credit assignment. By training on synthetic interaction data, ΔBelief-RL teaches information-seeking capabilities that consistently outperform purely outcome-based rewards for Reinforcement Learning, with improvements generalizing to out-of-distribution applications ranging from customer service to personalization. Notably, the performance continues to improve as we scale test-time interactions beyond the training horizon, with interaction-efficiency increasing even on Pass@k metrics. Overall, our work introduces a scalable training strategy for navigating uncertainty over a long-horizon, by enabling credit assignment to intermediate actions via intrinsic ΔBelief rewards.

</details>


### [61] [Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games](https://arxiv.org/abs/2602.12517)
*Lorenzo Magnino,Jiacheng Shen,Matthieu Geist,Olivier Pietquin,Mathieu Laurière*

Main category: cs.LG

TL;DR: 该论文提出了Bench-MFG基准测试套件，用于标准化评估均值场博弈与强化学习交叉领域的算法，解决了当前缺乏统一评估协议的问题。


<details>
  <summary>Details</summary>
Motivation: 当前均值场博弈与强化学习交叉领域缺乏标准化的评估协议，研究者只能依赖定制化、孤立且过于简化的环境，这种碎片化使得难以评估新方法的鲁棒性、泛化能力和失败模式。

Method: 提出了Bench-MFG基准测试套件，专注于离散时间、离散空间、平稳设置。引入了问题分类学（从无交互和单调博弈到势博弈和动态耦合博弈），为每类提供原型环境。提出了MF-Garnets方法用于生成随机MFG实例以进行严格的统计测试。

Result: 在各种环境中对多种学习算法进行了基准测试，包括新颖的黑盒方法（MF-PSO）用于可剥削性最小化。基于广泛的实证结果，提出了标准化未来实验比较的指导方针。

Conclusion: Bench-MFG基准测试套件填补了均值场博弈与强化学习交叉领域的评估空白，提供了标准化测试框架和指导方针，有助于推动该领域研究的可比性和进展。

Abstract: The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchmark suite for MFGs (Bench-MFG), focusing on the discrete-time, discrete-space, stationary setting for the sake of clarity. We introduce a taxonomy of problem classes, ranging from no-interaction and monotone games to potential and dynamics-coupled games, and provide prototypical environments for each. Furthermore, we propose MF-Garnets, a method for generating random MFG instances to facilitate rigorous statistical testing. We benchmark a variety of learning algorithms across these environments, including a novel black-box approach (MF-PSO) for exploitability minimization. Based on our extensive empirical results, we propose guidelines to standardize future experimental comparisons. Code available at \href{https://github.com/lorenzomagnino/Bench-MFG}{https://github.com/lorenzomagnino/Bench-MFG}.

</details>


### [62] [Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis](https://arxiv.org/abs/2602.12373)
*Yijun Ma,Zehong Wang,Weixiang Sun,Zheyuan Zhang,Kaiwen Shi,Nitesh Chawla,Yanfang Ye*

Main category: cs.LG

TL;DR: 提出了Policy4OOD，一个知识引导的时空世界模型，用于评估阿片类药物政策干预，具备预测、反事实推理和优化三种能力。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机是美国最严重的公共卫生危机之一，但政策干预评估困难，因为多种政策在动态系统中相互作用，针对一个风险路径可能无意中放大另一个风险。

Method: 提出了Policy4OOD模型，将政策知识图谱、州级空间依赖性和社会经济时间序列联合编码到政策条件Transformer中，预测未来阿片类药物结果。训练后作为模拟器，支持前向预测、反事实分析和基于蒙特卡洛树搜索的政策优化。

Result: 实验表明，空间依赖性和结构化政策知识显著提高了预测准确性，验证了每个架构组件以及世界建模在数据驱动的公共卫生决策支持中的潜力。

Conclusion: 通过世界建模统一政策评估的三种能力（预测、反事实推理、优化）是有效的，Policy4OOD为数据驱动的公共卫生决策支持提供了有前景的框架。

Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where targeting one risk pathway may inadvertently amplify another. We argue that effective opioid policy evaluation requires three capabilities -- forecasting future outcomes under current policies, counterfactual reasoning about alternative past decisions, and optimization over candidate interventions -- and propose to unify them through world modeling. We introduce Policy4OOD, a knowledge-guided spatio-temporal world model that addresses three core challenges: what policies prescribe, where effects manifest, and when effects unfold.Policy4OOD jointly encodes policy knowledge graphs, state-level spatial dependencies, and socioeconomic time series into a policy-conditioned Transformer that forecasts future opioid outcomes.Once trained, the world model serves as a simulator: forecasting requires only a forward pass, counterfactual analysis substitutes alternative policy encodings in the historical sequence, and policy optimization employs Monte Carlo Tree Search over the learned simulator. To support this framework, we construct a state-level monthly dataset (2019--2024) integrating opioid mortality, socioeconomic indicators, and structured policy encodings. Experiments demonstrate that spatial dependencies and structured policy knowledge significantly improve forecasting accuracy, validating each architectural component and the potential of world modeling for data-driven public health decision support.

</details>


### [63] [Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning](https://arxiv.org/abs/2602.12375)
*Abdul Wahab,Raksha Kumaraswamy,Martha White*

Main category: cs.LG

TL;DR: VBE算法通过集成随机Q函数误差设计价值奖励，实现首次访问乐观探索，在经典环境和Atari游戏中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统基于价值奖励的探索方法存在局限性：价值奖励只在看到更高奖励奖励后才增加，无法鼓励智能体首次访问状态-动作对，缺乏首次访问乐观性和深度探索能力

Method: 提出VBE算法：维护一组随机动作价值函数集合，利用这些函数的估计误差设计价值奖励；通过巧妙设计这些随机Q函数的奖励，使价值奖励能够降至零，从而实现首次访问乐观探索

Result: VBE在多个经典探索测试环境中优于Bootstrap DQN和两种奖励奖励方法（RND和ACB），并能在Atari等复杂环境中轻松扩展

Conclusion: VBE通过集成随机Q函数误差设计价值奖励，有效解决了传统方法缺乏首次访问乐观性的问题，实现了更好的探索性能，并能扩展到复杂环境

Abstract: Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can be learned by estimating a value function on reward bonuses, propagating local uncertainties around rewards. However, this approach only increases the value bonus for an action retroactively, after seeing a higher reward bonus from that state and action. Such an approach does not encourage the agent to visit a state and action for the first time. In this work, we introduce an algorithm for exploration called Value Bonuses with Ensemble errors (VBE), that maintains an ensemble of random action-value functions (RQFs). VBE uses the errors in the estimation of these RQFs to design value bonuses that provide first-visit optimism and deep exploration. The key idea is to design the rewards for these RQFs in such a way that the value bonus can decrease to zero. We show that VBE outperforms Bootstrap DQN and two reward bonus approaches (RND and ACB) on several classic environments used to test exploration and provide demonstrative experiments that it can scale easily to more complex environments like Atari.

</details>


### [64] [TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)](https://arxiv.org/abs/2602.12833)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: TRACE是一个无需微调LLM的时序临床推理框架，通过双记忆架构和智能体组件处理纵向患者轨迹，在保持推理成本可控的同时提升预测准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然编码了丰富的医学知识，但在处理纵向患者轨迹时表现不佳，因为临床状态演变、时间不规则和事件异质性会随时间推移降低性能。现有方法（微调或检索增强）存在计算开销大、隐私限制或长上下文不稳定的问题。

Method: TRACE采用双记忆架构：静态的全局协议编码机构临床规则，动态的个体协议跟踪患者特定状态。四个智能体组件（路由器、推理器、审计员、管理员）协调工作，通过结构化状态压缩控制推理成本，并选择性审计安全关键的临床决策。

Result: 在MIMIC-IV的纵向临床事件流上评估，TRACE在下一事件预测准确性、协议遵循性和临床安全性方面显著优于长上下文和检索增强基线方法，同时产生可解释和可审计的推理轨迹。

Conclusion: TRACE框架通过显式结构化和维护上下文而非扩展上下文窗口或更新参数，实现了冻结LLM的时序临床推理，在保持计算效率的同时提供了可解释、可审计的临床决策支持。

Abstract: Large Language Models (LLMs) encode extensive medical knowledge but struggle to apply it reliably to longitudinal patient trajectories, where evolving clinical states, irregular timing, and heterogeneous events degrade performance over time. Existing adaptation strategies rely on fine-tuning or retrieval-based augmentation, which introduce computational overhead, privacy constraints, or instability under long contexts. We introduce TRACE (Temporal Reasoning via Agentic Context Evolution), a framework that enables temporal clinical reasoning with frozen LLMs by explicitly structuring and maintaining context rather than extending context windows or updating parameters. TRACE operates over a dual-memory architecture consisting of a static Global Protocol encoding institutional clinical rules and a dynamic Individual Protocol tracking patient-specific state. Four agentic components, Router, Reasoner, Auditor, and Steward, coordinate over this structured memory to support temporal inference and state evolution. The framework maintains bounded inference cost via structured state compression and selectively audits safety-critical clinical decisions. Evaluated on longitudinal clinical event streams from MIMIC-IV, TRACE significantly improves next-event prediction accuracy, protocol adherence, and clinical safety over long-context and retrieval-augmented baselines, while producing interpretable and auditable reasoning traces.

</details>


### [65] [High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions](https://arxiv.org/abs/2602.12391)
*Giang Ngo,Dat Phan Trong,Dang Nguyen,Sunil Gupta*

Main category: cs.LG

TL;DR: TRLSE是一种用于高维水平集估计的主动学习算法，通过全局和局部双重采集函数识别并细化阈值边界区域，在样本效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水平集估计在许多实际应用中是一个基本问题，但在高维空间中，随着维度增加搜索空间呈指数增长，主动学习场景下初始数据有限，需要高效地迭代获取信息点来构建准确分类器。

Method: 提出TRLSE算法，通过全局和局部双重采集函数识别并细化阈值边界区域，在全局层面探索潜在边界区域，在局部层面精确细化边界。

Result: 对TRLSE的准确性进行了理论分析，并在多个合成和实际水平集估计问题上进行了广泛评估，显示其样本效率优于现有方法。

Conclusion: TRLSE算法能够有效解决高维水平集估计问题，通过双重采集策略在有限样本下实现准确的边界分类，具有优越的样本效率。

Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data, we aim to iteratively acquire informative points to construct an accurate classifier for this task. In high-dimensional spaces, this becomes challenging where the search volume grows exponentially with increasing dimensionality. We propose TRLSE, an algorithm for high-dimensional LSE, which identifies and refines regions near the threshold boundary with dual acquisition functions operating at both global and local levels. We provide a theoretical analysis of TRLSE's accuracy and show its superior sample efficiency against existing methods through extensive evaluations on multiple synthetic and real-world LSE problems.

</details>


### [66] [AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning](https://arxiv.org/abs/2602.12402)
*Felicia B. Guo,Ken T. Ho,Andrei Vladimirescu,Borivoje Nikolic*

Main category: cs.LG

TL;DR: 该论文提出了一种基于深度强化学习的模拟混合信号电路自动综合方法(AstRL)，将电路设计建模为图生成问题，能够在晶体管级别生成优化的电路拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 模拟混合信号集成电路在现代计算和通信系统中至关重要，但设计复杂度持续上升而自动化进展有限。主要挑战在于开发适用于不同、受限且不可微设计空间的通用优化方法。

Method: 将电路设计建模为图生成问题，提出基于策略梯度的深度强化学习方法AstRL。在仿真器嵌入的环境中直接生成针对用户指定目标优化的电路，通过行为克隆和基于判别器的相似性奖励实现专家对齐的电路生成。

Result: 在三个实际设计任务中，相比现有最优基线方法，在传统设计指标上取得显著改进。100%的生成设计结构正确，超过90%的设计展示所需功能。

Conclusion: AstRL方法首次展示了专家对齐的通用电路生成范式，能够在晶体管级别实现高度表达、细粒度的拓扑生成，为模拟混合信号电路自动化设计提供了新途径。

Abstract: Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This reflects the central challenge in developing a generalized optimization method applicable across diverse circuit design spaces, many of which are distinct, constrained, and non-differentiable. To address this, our work casts circuit design as a graph generation problem and introduces a novel method of AMS synthesis driven by deep reinforcement learning (AstRL). Based on a policy-gradient approach, AstRL generates circuits directly optimized for user-specified targets within a simulator-embedded environment that provides ground-truth feedback during training. Through behavioral-cloning and discriminator-based similarity rewards, our method demonstrates, for the first time, an expert-aligned paradigm for generalized circuit generation validated in simulation. Importantly, the proposed approach operates at the level of individual transistors, enabling highly expressive, fine-grained topology generation. Strong inductive biases encoded in the action space and environment further drive structurally consistent and valid generation. Experimental results for three realistic design tasks illustrate substantial improvements in conventional design metrics over state-of-the-art baselines, with 100% of generated designs being structurally correct and over 90% demonstrating required functionality.

</details>


### [67] [Soft Contamination Means Benchmarks Test Shallow Generalization](https://arxiv.org/abs/2602.12413)
*Ari Spiesberger,Juan J. Vazquez,Nicky Pochinkov,Tomáš Gavenčiak,Peli Grietzer,Gavin Leech,Nandi Schoots*

Main category: cs.LG

TL;DR: 研究发现LLM训练数据中的基准测试数据语义重复污染普遍存在，导致基准性能评估存在偏差，无法准确反映模型的真实泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练数据中普遍存在基准测试数据的污染问题，传统的n-gram匹配去重方法无法检测语义重复内容，导致基准性能评估存在偏差，无法准确衡量模型在真实分布外的泛化能力。

Method: 研究使用嵌入方法分析Olmo3训练语料库，检测语义重复内容，通过实验验证包含基准数据语义重复的训练对性能的影响，并对比微调语义重复数据对真实保留数据性能的影响。

Result: 研究发现：1）污染普遍存在，CodeForces数据中78%存在语义重复，ZebraLogic问题中50%存在精确重复；2）包含基准数据语义重复的训练确实能提高基准性能；3）对基准数据点重复进行微调也能提高同一基准中真实保留数据点的性能。

Conclusion: 近期基准性能提升存在混淆因素：软污染的普遍存在意味着性能提升既反映了真实能力改进，也反映了训练语料库中积累的测试数据及其有效变体的影响，基准评估需要更严格的去重方法来准确衡量模型泛化能力。

Abstract: If LLM training data is polluted with benchmark test data, then benchmark performance gives biased estimates of out-of-distribution (OOD) generalization. Typical decontamination filters use n-gram matching which fail to detect semantic duplicates: sentences with equivalent (or near-equivalent) content that are not close in string space. We study this soft contamination of training data by semantic duplicates. Among other experiments, we embed the Olmo3 training corpus and find that: 1) contamination remains widespread, e.g. we find semantic duplicates for 78% of CodeForces and exact duplicates for 50% of ZebraLogic problems; 2) including semantic duplicates of benchmark data in training does improve benchmark performance; and 3) when finetuning on duplicates of benchmark datapoints, performance also improves on truly-held-out datapoints from the same benchmark. We argue that recent benchmark gains are thus confounded: the prevalence of soft contamination means gains reflect both genuine capability improvements and the accumulation of test data and effective test data in growing training corpora.

</details>


### [68] [Stabilizing Native Low-Rank LLM Pretraining](https://arxiv.org/abs/2602.12429)
*Paul Janson,Edouard Oyallon,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本文提出Spectron方法，通过谱重归一化和正交化技术，实现了从零开始训练低秩分解的LLMs，无需全秩指导，解决了低秩训练中的不稳定性和损失尖峰问题。


<details>
  <summary>Details</summary>
Motivation: 基础模型参数数量增长带来了显著的计算和内存挑战。低秩分解是降低训练和推理成本的有前景途径，但现有方法缺乏从零开始训练纯低秩权重模型且性能匹配密集模型的稳定方案。

Method: 提出Spectron方法：谱重归一化与正交化技术，动态地基于因子当前谱范数来限制权重更新的结果，解决了权重矩阵更新谱范数无控制增长这一主导因素。

Result: 实现了稳定的端到端分解训练，开销可忽略；建立了原生低秩transformer的计算最优缩放定律，展示了可预测的幂律行为和相对于密集模型改进的推理效率。

Conclusion: Spectron方法使LLMs能够从零开始使用纯低秩分解权重进行训练，无需辅助的全秩指导，解决了低秩训练的不稳定性问题，为高效模型训练提供了新途径。

Abstract: Foundation models have achieved remarkable success, yet their growing parameter counts pose significant computational and memory challenges. Low-rank factorization offers a promising route to reduce training and inference costs, but the community lacks a stable recipe for training models from scratch using exclusively low-rank weights while matching the performance of the dense model. We demonstrate that Large Language Models (LLMs) can be trained from scratch using exclusively low-rank factorized weights for all non-embedding matrices without auxiliary "full-rank" guidance required by prior methods. While native low-rank training often suffers from instability and loss spikes, we identify uncontrolled growth in the spectral norm (largest singular value) of the weight matrix update as the dominant factor. To address this, we introduce Spectron: Spectral renormalization with orthogonalization, which dynamically bounds the resultant weight updates based on the current spectral norms of the factors. Our method enables stable, end-to-end factorized training with negligible overhead. Finally, we establish compute-optimal scaling laws for natively low-rank transformers, demonstrating predictable power-law behavior and improved inference efficiency relative to dense models.

</details>


### [69] [Computationally sufficient statistics for Ising models](https://arxiv.org/abs/2602.12449)
*Abhijith Jayakumar,Shreya Shukla,Marc Vuffray,Andrey Y. Lokhov,Sidhant Misra*

Main category: cs.LG

TL;DR: 该研究探索在仅能观测有限统计量的条件下学习吉布斯分布的可行性，以伊辛模型为例，证明了通过观测O(γ)阶统计量即可重构模型参数，其中γ为模型宽度。


<details>
  <summary>Details</summary>
Motivation: 在物理系统中，获取完整样本配置通常不切实际，而传统高效学习算法需要完整样本。因此需要开发仅基于有限统计量的计算高效学习方法，探索计算能力与观测能力之间的权衡。

Method: 以伊辛模型为范例，研究在仅能观测有限阶统计量的条件下学习吉布斯分布的方法。通过分析模型参数与统计量之间的关系，建立基于γ宽度模型的参数重构框架。

Result: 证明对于宽度为γ的模型，通过观测O(γ)阶统计量即可重构模型参数，包括模型结构、耦合参数和磁场参数。在有先验结构信息的情况下，学习问题可以在更有限的观测能力下高效解决。

Conclusion: 该研究展示了在有限观测条件下学习吉布斯分布的可行性，为物理系统中仅能获取部分统计信息的场景提供了理论框架和计算方法，平衡了计算需求与观测限制之间的矛盾。

Abstract: Learning Gibbs distributions using only sufficient statistics has long been recognized as a computationally hard problem. On the other hand, computationally efficient algorithms for learning Gibbs distributions rely on access to full sample configurations generated from the model. For many systems of interest that arise in physical contexts, expecting a full sample to be observed is not practical, and hence it is important to look for computationally efficient methods that solve the learning problem with access to only a limited set of statistics. We examine the trade-offs between the power of computation and observation within this scenario, employing the Ising model as a paradigmatic example. We demonstrate that it is feasible to reconstruct the model parameters for a model with $\ell_1$ width $γ$ by observing statistics up to an order of $O(γ)$. This approach allows us to infer the model's structure and also learn its couplings and magnetic fields. We also discuss a setting where prior information about structure of the model is available and show that the learning problem can be solved efficiently with even more limited observational power.

</details>


### [70] [Regularized Meta-Learning for Improved Generalization](https://arxiv.org/abs/2602.12469)
*Noor Islam S. Mohammad,Md Muntaqim Meherab*

Main category: cs.LG

TL;DR: 提出正则化元学习框架，通过四阶段流程解决深度集成方法的冗余、不稳定加权和过拟合问题，在基准测试中显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 深度集成方法存在三个实际限制：基础模型间的冗余性增加计算成本并恶化条件数；多重共线性下的不稳定加权；元学习管道中的过拟合问题。

Method: 提出四阶段正则化元学习框架：1) 冗余感知投影，使用相关性和MSE阈值去重；2) 统计元特征增强；3) 交叉验证正则化元模型（Ridge、Lasso、ElasticNet）；4) 逆RMSE混合阶段减少正则化选择方差。

Result: 在Playground Series S6E1基准测试中，OOF RMSE为8.582，优于简单平均（8.894）和传统Ridge堆叠（8.627），匹配贪心爬山法（8.603）但运行时间快4倍。条件数分析显示冗余投影后有效矩阵条件数减少53.7%。

Conclusion: 正则化元学习为高维集成系统提供了稳定且部署高效的堆叠策略，去重、统计元特征和元集成混合均对性能提升有贡献。

Abstract: Deep ensemble methods often improve predictive performance, yet they suffer from three practical limitations: redundancy among base models that inflates computational cost and degrades conditioning, unstable weighting under multicollinearity, and overfitting in meta-learning pipelines. We propose a regularized meta-learning framework that addresses these challenges through a four-stage pipeline combining redundancy-aware projection, statistical meta-feature augmentation, and cross-validated regularized meta-models (Ridge, Lasso, and ElasticNet). Our multi-metric de-duplication strategy removes near-collinear predictors using correlation and MSE thresholds ($τ_{\text{corr}}=0.95$), reducing the effective condition number of the meta-design matrix while preserving predictive diversity. Engineered ensemble statistics and interaction terms recover higher-order structure unavailable to raw prediction columns. A final inverse-RMSE blending stage mitigates regularizer-selection variance. On the Playground Series S6E1 benchmark (100K samples, 72 base models), the proposed framework achieves an out-of-fold RMSE of 8.582, improving over simple averaging (8.894) and conventional Ridge stacking (8.627), while matching greedy hill climbing (8.603) with substantially lower runtime (4 times faster). Conditioning analysis shows a 53.7\% reduction in effective matrix condition number after redundancy projection. Comprehensive ablations demonstrate consistent contributions from de-duplication, statistical meta-features, and meta-ensemble blending. These results position regularized meta-learning as a stable and deployment-efficient stacking strategy for high-dimensional ensemble systems.

</details>


### [71] [Designing RNAs with Language Models](https://arxiv.org/abs/2602.12470)
*Milan Gautam,Ning Dai,Tianshuo Zhou,Bowen Xie,David Mathews,Liang Huang*

Main category: cs.LG

TL;DR: 将RNA设计重新定义为条件序列生成问题，使用自回归语言模型将目标结构映射到序列，结合监督学习和强化学习优化，在多个数据集上超越现有方法


<details>
  <summary>Details</summary>
Motivation: RNA设计（寻找折叠成目标二级结构的序列）在生物学和生物医学中具有广泛影响，但由于指数级大的序列空间和竞争性折叠，计算上具有挑战性。传统方法将其视为优化问题，依赖于实例特定的启发式方法或基于约束的搜索，存在局限性。

Method: 将RNA设计重新定义为条件序列生成问题，引入可重用的神经近似器（自回归语言模型），将目标结构直接映射到序列。首先在随机诱导的结构-序列对上监督训练模型，然后使用强化学习优化端到端指标。还提出方法选择RL的小子集，显著提高RL效率和质量。

Result: 在四个数据集上，该方法在关键指标（如玻尔兹曼概率）上优于最先进系统，同时速度快1.7倍，确立了条件语言模型生成作为RNA设计中可扩展、任务无关的替代方案。

Conclusion: 条件语言模型生成为RNA设计提供了一种可扩展、任务无关的替代方案，超越了传统的基于实例优化的方法，在效率和性能上都取得了显著提升。

Abstract: RNA design, the task of finding a sequence that folds into a target secondary structure, has broad biological and biomedical impact but remains computationally challenging due to the exponentially large sequence space and exponentially many competing folds. Traditional approaches treat it as an optimization problem, relying on per-instance heuristics or constraint-based search. We instead reframe RNA design as conditional sequence generation and introduce a reusable neural approximator, instantiated as an autoregressive language model (LM), that maps target structures directly to sequences. We first train our model in a supervised setting on random-induced structure-sequence pairs, and then use reinforcement learning (RL) to optimize end-to-end metrics. We also propose methods to select a small subset for RL that greatly improves RL efficiency and quality. Across four datasets, our approach outperforms state-of-the-art systems on key metrics such as Boltzmann probability while being 1.7x faster, establishing conditional LM generation as a scalable, task-agnostic alternative to per-instance optimization for RNA design. Our code and data are available at https://github.com/KuNyaa/RNA-Design-LM.

</details>


### [72] [Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension](https://arxiv.org/abs/2602.12471)
*Michael Crawshaw,Mingrui Liu*

Main category: cs.LG

TL;DR: 该论文研究了在二维可分数据上使用梯度下降训练线性模型时，通过选择大学习率获得加速收敛的理论分析，证明了损失函数可以达到O(1/(ηT))的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 最近研究表明，在可分数据上使用梯度下降训练线性模型时，通过选择大学习率（η=Θ(γ²T)）可以获得1/T²的加速收敛率，尽管这会导致损失函数非单调。然而，现有分析不够紧密，特别是在二维数据场景下需要更精确的理论分析。

Method: 针对二维可分数据，对梯度下降进行更紧密的理论分析。通过精细分析梯度下降在与最大间隔分类器正交子空间中的振荡动力学，更精确地界定了梯度下降从不稳定阶段（损失非单调）过渡到稳定阶段（损失单调）所需的时间τ。

Result: 证明了当T ≥ Ω(n/γ + 1/γ²)时，梯度下降使用足够大的学习率η可以找到损失小于O(1/(ηT))的点。提供了τ的上界和下界匹配（最多相差对数因子），表明分析是紧密的。

Conclusion: 该研究为二维可分数据上梯度下降的加速收敛提供了更紧密的理论保证，通过精细分析振荡动力学改进了现有结果，并证明了分析的最优性。

Abstract: We consider the optimization problem of minimizing the logistic loss with gradient descent to train a linear model for binary classification with separable data. With a budget of $T$ iterations, it was recently shown that an accelerated $1/T^2$ rate is possible by choosing a large step size $η= Θ(γ^2 T)$ (where $γ$ is the dataset's margin) despite the resulting non-monotonicity of the loss. In this paper, we provide a tighter analysis of gradient descent for this problem when the data is two-dimensional: we show that GD with a sufficiently large learning rate $η$ finds a point with loss smaller than $\mathcal{O}(1/(ηT))$, as long as $T \geq Ω(n/γ+ 1/γ^2)$, where $n$ is the dataset size. Our improved rate comes from a tighter bound on the time $τ$ that it takes for GD to transition from unstable (non-monotonic loss) to stable (monotonic loss), via a fine-grained analysis of the oscillatory dynamics of GD in the subspace orthogonal to the max-margin classifier. We also provide a lower bound of $τ$ matching our upper bound up to logarithmic factors, showing that our analysis is tight.

</details>


### [73] [On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs](https://arxiv.org/abs/2602.12506)
*Rosie Zhao,Anshul Shah,Xiaoyu Zhu,Xinke Deng,Zhongyu Jiang,Yang Yang,Joerg Liebelt,Arnab Mondal*

Main category: cs.LG

TL;DR: 研究发现RL微调的视觉语言模型在视觉推理任务上虽有提升，但仍存在视觉基础薄弱、幻觉和过度依赖文本线索等脆弱性，通过文本扰动测试揭示了准确性与忠实性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习微调已成为提升大语言模型推理能力的关键技术，并扩展到视觉语言模型，但现有RL微调的视觉语言模型在视觉基础、幻觉和文本依赖方面仍存在脆弱性，需要深入理解这些模型的局限性。

Method: 通过简单的受控文本扰动（误导性标题或错误思维链）测试模型鲁棒性，使用基于熵的指标分析模型不确定性，研究RL微调动态，并探索对抗增强和忠实性感知奖励对模型性能的影响。

Result: 文本扰动导致模型鲁棒性和置信度显著下降，思维链一致性考虑下效果更明显；RL微调存在准确性-忠实性权衡：提升基准准确性的同时削弱了思维链可靠性和上下文变化的鲁棒性；对抗增强可改善鲁棒性但无法防止忠实性漂移，忠实性感知奖励可恢复答案与推理的对齐，但与增强结合时训练可能崩溃到捷径策略。

Conclusion: 仅基于准确性的评估存在局限性，需要开发和采用同时强调正确性、鲁棒性和视觉基础推理忠实性的训练与评估协议。

Abstract: Reinforcement learning (RL) fine-tuning has become a key technique for enhancing large language models (LLMs) on reasoning-intensive tasks, motivating its extension to vision language models (VLMs). While RL-tuned VLMs improve on visual reasoning benchmarks, they remain vulnerable to weak visual grounding, hallucinations, and over-reliance on textual cues. We show that simple, controlled textual perturbations--misleading captions or incorrect chain-of-thought (CoT) traces--cause substantial drops in robustness and confidence, and that these effects are more pronounced when CoT consistency is taken into account across open-source multimodal reasoning models. Entropy-based metrics further show that these perturbations reshape model uncertainty and probability mass on the correct option, exposing model-specific trends in miscalibration. To better understand these vulnerabilities, we further analyze RL fine-tuning dynamics and uncover an accuracy-faithfulness trade-off: fine-tuning raises benchmark accuracy, but can simultaneously erode the reliability of the accompanying CoT and its robustness to contextual shifts. Although adversarial augmentation improves robustness, it does not by itself prevent faithfulness drift. Incorporating a faithfulness-aware reward can restore alignment between answers and reasoning, but when paired with augmentation, training risks collapsing onto shortcut strategies and robustness remains elusive. Together, these findings highlight the limitations of accuracy-only evaluations and motivate training and assessment protocols that jointly emphasize correctness, robustness, and the faithfulness of visually grounded reasoning.

</details>


### [74] [Resource-Efficient Gesture Recognition through Convexified Attention](https://arxiv.org/abs/2602.13030)
*Daniel Schwartz,Dario Salvucci,Yusuf Osmanlioglu,Richard Vallett,Genevieve Dion,Ali Shokoufandeh*

Main category: cs.LG

TL;DR: 提出一种用于可穿戴电子纺织品的凸化注意力机制，通过非扩张单纯形投影和凸损失函数实现动态特征加权，仅需120-360个参数即可在纺织电容传感器上实现100%手势识别准确率。


<details>
  <summary>Details</summary>
Motivation: 可穿戴电子纺织品界面需要手势识别能力，但面临功耗、计算能力和尺寸的严格限制，传统深度学习方法不实用。现有轻量级架构仍需数千参数，难以在纺织集成平台上部署。

Method: 引入凸化注意力机制，使用欧几里得投影到概率单纯形结合多类铰链损失，替代传统非凸softmax操作，确保全局收敛保证。在四连接点纺织电容传感器上实现。

Result: 在点击手势和滑动手势上均达到100.00%准确率，10折交叉验证和保留测试评估一致。仅需120-360个参数（比传统方法减少97%），推理时间290-296微秒，存储需求小于7KB。

Conclusion: 凸优化方法能够为纺织界面实现高效的设备端机器学习，在实验室单用户条件下验证了基本手势交互的可行性，实际部署需要多用户、环境条件和更复杂手势词汇的验证。

Abstract: Wearable e-textile interfaces require gesture recognition capabilities but face severe constraints in power consumption, computational capacity, and form factor that make traditional deep learning impractical. While lightweight architectures like MobileNet improve efficiency, they still demand thousands of parameters, limiting deployment on textile-integrated platforms. We introduce a convexified attention mechanism for wearable applications that dynamically weights features while preserving convexity through nonexpansive simplex projection and convex loss functions. Unlike conventional attention mechanisms using non-convex softmax operations, our approach employs Euclidean projection onto the probability simplex combined with multi-class hinge loss, ensuring global convergence guarantees. Implemented on a textile-based capacitive sensor with four connection points, our approach achieves 100.00\% accuracy on tap gestures and 100.00\% on swipe gestures -- consistent across 10-fold cross-validation and held-out test evaluation -- while requiring only 120--360 parameters, a 97\% reduction compared to conventional approaches. With sub-millisecond inference times (290--296$μ$s) and minimal storage requirements ($<$7KB), our method enables gesture interfaces directly within e-textiles without external processing. Our evaluation, conducted in controlled laboratory conditions with a single-user dataset, demonstrates feasibility for basic gesture interactions. Real-world deployment would require validation across multiple users, environmental conditions, and more complex gesture vocabularies. These results demonstrate how convex optimization can enable efficient on-device machine learning for textile interfaces.

</details>


### [75] [Constraint-Rectified Training for Efficient Chain-of-Thought](https://arxiv.org/abs/2602.12526)
*Qinhang Wu,Sen Lin,Ming Zhang,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: CRT框架通过约束优化方法在保持准确性的同时减少推理长度，解决CoT推理中的冗余问题


<details>
  <summary>Details</summary>
Motivation: 现有CoT推理方法存在推理轨迹过长、计算成本高、冗余步骤多的问题，而基于启发式的方法可能导致准确性下降且对超参数敏感

Method: 提出CRT（约束修正训练）框架，基于参考保护的约束优化，交替最小化推理长度和修正准确性；采用两阶段训练方案：先发现最短可靠推理模式，然后在学习到的长度预算下优化准确性

Result: CRT能持续减少token使用量同时保持答案质量，不仅缩短响应长度还减少内部语言冗余，产生一系列中间检查点实现推理详细程度的细粒度控制

Conclusion: CRT提供了一个稳定、可解释的高效推理训练框架，平衡推理长度和准确性，避免冗余推理

Abstract: Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer quality and unlock abilities such as self-correction, they also incur high inference costs and often introduce redundant steps, known as overthinking. Recent research seeks to develop efficient reasoning strategies that balance reasoning length and accuracy, either through length-aware reward design or prompt-based calibration. However, these heuristic-based approaches may suffer from severe accuracy drop and be very sensitive to hyperparameters. To address these problems, we introduce CRT (Constraint-Rectified Training), a principled post-training framework based on reference-guarded constrained optimization, yielding a more stable and interpretable formulation for efficient reasoning. CRT alternates between minimizing reasoning length and rectifying accuracy only when performance falls below the reference, enabling stable and effective pruning of redundant reasoning. We further extend CRT with a two-stage training scheme that first discovers the shortest reliable reasoning patterns and then refines accuracy under a learnt length budget, preventing the re-emergence of verbose CoT. Our comprehensive evaluation shows that this framework consistently reduces token usage while maintaining answer quality at a robust and reliable level. Further analysis reveals that CRT improves reasoning efficiency not only by shortening responses but also by reducing internal language redundancy, leading to a new evaluation metric. Moreover, CRT-based training naturally yields a sequence of intermediate checkpoints that span a spectrum of explanation lengths while preserving correctness, enabling fine-grained control over reasoning verbosity without retraining.

</details>


### [76] [Analytical Results for Two Exponential Family Distributions in Hierarchical Dirichlet Processes](https://arxiv.org/abs/2602.12527)
*Naiqi Li*

Main category: cs.LG

TL;DR: 本文研究了分层狄利克雷过程（HDP）框架下指数族分布的解析结果，特别是针对泊松分布和正态分布，推导了Gamma-Poisson和Normal-Gamma-Normal共轭对的闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 现有HDP应用主要关注狄利克雷-多项共轭结构，但HDP框架本身更通用，原则上可容纳更广泛的共轭先验-似然对。指数族分布提供了一个统一且解析可处理的建模范式，包含许多常用分布。

Method: 在分层狄利克雷过程框架下，研究了指数族分布的两个重要成员：泊松分布和正态分布。推导了Gamma-Poisson和Normal-Gamma-Normal共轭对的显式闭式表达式，提供了详细的推导和证明。

Result: 获得了HDP框架下泊松分布和正态分布的解析结果，包括Gamma-Poisson和Normal-Gamma-Normal共轭对的闭式表达式，阐明了底层数学结构，展示了如何在分层非参数模型中系统利用共轭性。

Conclusion: 本研究将HDP的适用性扩展到狄利克雷-多项设置之外，为使用分层贝叶斯非参数方法的研究人员提供了实用的解析结果，增强了HDP框架的通用性和实用性。

Abstract: The Hierarchical Dirichlet Process (HDP) provides a flexible Bayesian nonparametric framework for modeling grouped data with a shared yet unbounded collection of mixture components. While existing applications of the HDP predominantly focus on the Dirichlet-multinomial conjugate structure, the framework itself is considerably more general and, in principle, accommodates a broad class of conjugate prior-likelihood pairs. In particular, exponential family distributions offer a unified and analytically tractable modeling paradigm that encompasses many commonly used distributions. In this paper, we investigate analytic results for two important members of the exponential family within the HDP framework: the Poisson distribution and the normal distribution. We derive explicit closed-form expressions for the corresponding Gamma-Poisson and Normal-Gamma-Normal conjugate pairs under the hierarchical Dirichlet process construction. Detailed derivations and proofs are provided to clarify the underlying mathematical structure and to demonstrate how conjugacy can be systematically exploited in hierarchical nonparametric models. Our work extends the applicability of the HDP beyond the Dirichlet-multinomial setting and furnishes practical analytic results for researchers employing hierarchical Bayesian nonparametrics.

</details>


### [77] [Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models](https://arxiv.org/abs/2602.12529)
*Bowen Ping,Chengyou Jia,Minnan Luo,Hangwei Qian,Ivor Tsang*

Main category: cs.LG

TL;DR: Flow-Factory是一个统一的强化学习框架，用于对齐扩散和流匹配模型与人类偏好，通过模块化架构解决代码库碎片化问题


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在扩散和流匹配模型对齐中存在代码库碎片化、模型特定实现和工程复杂性问题，需要一个统一的框架来简化研究和开发

Method: 采用模块化、基于注册表的架构设计，将算法、模型和奖励解耦，支持GRPO、DiffusionNFT和AWM等算法在Flux、Qwen-Image和WAN视频模型上的集成

Result: Flow-Factory实现了生产级内存优化、灵活的多奖励训练和无缝分布式训练支持，显著减少了实现开销，使研究人员能够快速原型化和扩展创新

Conclusion: Flow-Factory通过统一的模块化框架解决了强化学习在扩散模型对齐中的工程挑战，为未来创新提供了快速原型化和扩展的基础设施

Abstract: Reinforcement learning has emerged as a promising paradigm for aligning diffusion and flow-matching models with human preferences, yet practitioners face fragmented codebases, model-specific implementations, and engineering complexity. We introduce Flow-Factory, a unified framework that decouples algorithms, models, and rewards through through a modular, registry-based architecture. This design enables seamless integration of new algorithms and architectures, as demonstrated by our support for GRPO, DiffusionNFT, and AWM across Flux, Qwen-Image, and WAN video models. By minimizing implementation overhead, Flow-Factory empowers researchers to rapidly prototype and scale future innovations with ease. Flow-Factory provides production-ready memory optimization, flexible multi-reward training, and seamless distributed training support. The codebase is available at https://github.com/X-GenGroup/Flow-Factory.

</details>


### [78] [AMPS: Adaptive Modality Preference Steering via Functional Entropy](https://arxiv.org/abs/2602.12533)
*Zihan Huang,Xintong Li,Rohan Surana,Tong Yu,Rui Wang,Julian McAuley,Jingbo Shang,Junda Wu*

Main category: cs.LG

TL;DR: 本文提出了一种实例感知的模态偏好调控方法，通过诊断每个样本中不同模态的信息贡献度，实现针对性的调控强度调整，相比传统统一调控方法更有效且能保持低错误率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在显著的模态偏好问题，即倾向于过度依赖某一模态而忽视另一模态。现有方法采用统一的调控强度，但强调控会损害标准推理并增加错误率，弱调控则效果有限。由于不同多模态实例对调控的敏感性差异很大，单一全局强度难以校准。

Method: 1. 提出实例感知的诊断指标，量化每个模态的信息贡献并揭示样本特定的调控敏感性；2. 基于这些洞察提出缩放策略，减少对敏感样本的调控强度；3. 设计可学习模块推断缩放模式，实现实例感知的模态偏好控制。

Result: 实验结果表明，实例感知的调控方法在调节模态偏好方面优于传统调控方法，能够有效调整模态偏好，同时保持较低的生成错误率。

Conclusion: 通过实例感知的模态偏好调控方法，可以更精细地控制多模态大语言模型的模态偏好，在有效调整偏好的同时最小化对推理过程的干扰，解决了传统统一调控方法的局限性。

Abstract: Multimodal Large Language Models (MLLMs) often exhibit significant modality preference, which is a tendency to favor one modality over another. Depending on the input, they may over-rely on linguistic priors relative to visual evidence, or conversely over-attend to visually salient but facts in textual contexts. Prior work has applied a uniform steering intensity to adjust the modality preference of MLLMs. However, strong steering can impair standard inference and increase error rates, whereas weak steering is often ineffective. In addition, because steering sensitivity varies substantially across multimodal instances, a single global strength is difficult to calibrate. To address this limitation with minimal disruption to inference, we introduce an instance-aware diagnostic metric that quantifies each modality's information contribution and reveals sample-specific susceptibility to steering. Building on these insights, we propose a scaling strategy that reduces steering for sensitive samples and a learnable module that infers scaling patterns, enabling instance-aware control of modality preference. Experimental results show that our instance-aware steering outperforms conventional steering in modulating modality preference, achieving effective adjustment while keeping generation error rates low.

</details>


### [79] [Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference](https://arxiv.org/abs/2602.12542)
*Pengfei Hu,Chang Lu,Feifan Liu,Yue Ning*

Main category: cs.LG

TL;DR: ExtraCare提出一种分解患者表征为不变和协变分量的方法，通过监督和正交约束实现领域适应，同时提供可解释的临床预测模型。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）的深度学习模型在不同数据分布下部署时性能会下降，而现有的领域适应方法缺乏透明度，这在需要信任和安全性的临床实践中阻碍了其广泛应用。

Method: ExtraCare将患者表征分解为不变分量和协变分量，在训练过程中监督这两个分量并强制它们正交，从而保留标签信息同时暴露领域特定变化。通过将稀疏潜在维度映射到医学概念，并通过有针对性的消融量化其贡献，提供人类可理解的解释。

Result: 在两个真实世界EHR数据集上的多个领域划分设置中评估，ExtraCare表现出优于大多数特征对齐模型的性能，同时通过广泛的案例研究展示了其准确的预测和解释能力，增强了透明度。

Conclusion: ExtraCare不仅提高了临床事件预测在不同数据分布下的准确性，更重要的是通过可解释的分解方法提供了临床实践所需的透明度，有助于建立信任和安全性。

Abstract: Deep learning models for clinical event prediction on electronic health records (EHR) often suffer performance degradation when deployed under different data distributions. While domain adaptation (DA) methods can mitigate such shifts, its "black-box" nature prevents widespread adoption in clinical practice where transparency is essential for trust and safety. We propose ExtraCare to decompose patient representations into invariant and covariant components. By supervising these two components and enforcing their orthogonality during training, our model preserves label information while exposing domain-specific variation at the same time for more accurate predictions than most feature alignment models. More importantly, it offers human-understandable explanations by mapping sparse latent dimensions to medical concepts and quantifying their contributions via targeted ablations. ExtraCare is evaluated on two real-world EHR datasets across multiple domain partition settings, demonstrating superior performance along with enhanced transparency, as evidenced by its accurate predictions and explanations from extensive case studies.

</details>


### [80] [SD-MoE: Spectral Decomposition for Effective Expert Specialization](https://arxiv.org/abs/2602.12556)
*Ruijun Huang,Fang Dong,Xin Zhang,Hengjie Cao,Zhendong Huang,Anrui Chen,Jixian Zhou,Mengyi Chen,Yifeng Yang,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Fan Yang,Tun Lu,Chun Zhang,Li Shang*

Main category: cs.LG

TL;DR: 本文分析了MoE架构中专家专业化失败的问题，从谱角度揭示了参数和梯度空间的深层原因，并提出了谱解耦MoE解决方案。


<details>
  <summary>Details</summary>
Motivation: MoE架构通过条件计算实现专家专业化来扩展大语言模型，但在实践中专家专业化常常失败：一些专家功能相似，另一些则成为事实上的共享专家，限制了有效容量和模型性能。

Method: 从谱角度分析参数和梯度空间，发现专家参数共享高度重叠的谱成分，梯度子空间强对齐，门控机制偏好沿主导方向路由。提出谱解耦MoE，在谱空间分解参数和梯度。

Result: SD-MoE在下游任务中提升性能，实现有效的专家专业化，带来最小的额外计算开销，并能无缝集成到包括Qwen和DeepSeek在内的多种现有MoE架构中。

Conclusion: 通过谱空间分析揭示了MoE专家专业化失败的根本原因，提出的谱解耦方法有效解决了这一问题，为MoE架构的改进提供了新方向。

Abstract: Mixture-of-Experts (MoE) architectures scale Large Language Models via expert specialization induced by conditional computation. In practice, however, expert specialization often fails: some experts become functionally similar, while others functioning as de facto shared experts, limiting the effective capacity and model performance. In this work, we analysis from a spectral perspective on parameter and gradient spaces, uncover that (1) experts share highly overlapping dominant spectral components in their parameters, (2) dominant gradient subspaces are strongly aligned across experts, driven by ubiquitous low-rank structure in human corpus, and (3) gating mechanisms preferentially route inputs along these dominant directions, further limiting specialization. To address this, we propose Spectral-Decoupled MoE (SD-MoE), which decomposes both parameter and gradient in the spectral space. SD-MoE improves performance across downstream tasks, enables effective expert specialization, incurring minimal additional computation, and can be seamlessly integrated into a wide range of existing MoE architectures, including Qwen and DeepSeek.

</details>


### [81] [Fractional Order Federated Learning for Battery Electric Vehicle Energy Consumption Modeling](https://arxiv.org/abs/2602.12567)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: 提出FO-RI-FedAvg方法，通过分数阶优化和粗糙度感知正则化解决电动汽车联邦学习中的连接不稳定、客户端参与变化大等问题，提升收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车联邦学习面临间歇性连接、客户端参与时间变化大、运行条件差异导致的客户端间变异严重等问题，传统FedAvg和先进方法在这些现实约束下容易出现过度漂移和收敛退化。

Method: 提出FO-RI-FedAvg方法，包含两个客户端机制：(1)自适应粗糙度感知近端正则化，根据局部损失景观粗糙度动态调整向全局模型的拉力；(2)非整数阶局部优化，引入短期记忆平滑冲突的更新方向。该方法保留标准FedAvg服务器聚合，仅增加元素级操作，允许独立切换各组件。

Result: 在两个真实世界BEV能量预测数据集（VED及其扩展版本eVED）上的实验表明，FO-RI-FedAvg相比强联邦基线实现了更高的准确性和更稳定的收敛，特别是在客户端参与减少的情况下表现更优。

Conclusion: FO-RI-FedAvg是一种轻量级、模块化的FedAvg扩展，通过分数阶优化和粗糙度感知正则化机制有效提升了电动汽车联邦学习的稳定性，在现实约束下表现出更好的性能。

Abstract: Federated learning on connected electric vehicles (BEVs) faces severe instability due to intermittent connectivity, time-varying client participation, and pronounced client-to-client variation induced by diverse operating conditions. Conventional FedAvg and many advanced methods can suffer from excessive drift and degraded convergence under these realistic constraints. This work introduces Fractional-Order Roughness-Informed Federated Averaging (FO-RI-FedAvg), a lightweight and modular extension of FedAvg that improves stability through two complementary client-side mechanisms: (i) adaptive roughness-informed proximal regularization, which dynamically tunes the pull toward the global model based on local loss-landscape roughness, and (ii) non-integer-order local optimization, which incorporates short-term memory to smooth conflicting update directions. The approach preserves standard FedAvg server aggregation, adds only element-wise operations with amortizable overhead, and allows independent toggling of each component. Experiments on two real-world BEV energy prediction datasets, VED and its extended version eVED, show that FO-RI-FedAvg achieves improved accuracy and more stable convergence compared to strong federated baselines, particularly under reduced client participation.

</details>


### [82] [VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction](https://arxiv.org/abs/2602.12579)
*Xin-Qiang Cai,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 提出VI-CuRL框架，解决无验证器强化学习中梯度方差过大导致训练崩溃的问题，通过模型内在置信度构建课程学习，在六个基准测试中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于可验证奖励的强化学习(RLVR)依赖外部验证器，限制了可扩展性。研究发现RLVR主要通过激发潜在能力起作用，这推动了无验证器算法的发展。但在无验证器设置中，标准方法面临破坏性梯度方差导致训练崩溃的挑战。

Method: 提出验证器独立课程强化学习(VI-CuRL)框架，利用模型内在置信度构建独立于外部验证器的课程学习。通过优先处理高置信度样本，有效管理偏差-方差权衡，特别针对减少动作和问题方差。提供了严格的理论分析，证明估计器保证渐近无偏性。

Result: VI-CuRL在六个具有挑战性的基准测试中（无论有无验证器）都表现出稳定性，并持续优于无验证器基线方法。

Conclusion: VI-CuRL框架成功解决了无验证器强化学习中的梯度方差问题，通过内在置信度构建课程学习，在多个基准测试中表现出优越性能，为可扩展的LLM推理强化学习提供了有效解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a dominant paradigm for enhancing Large Language Models (LLMs) reasoning, yet its reliance on external verifiers limits its scalability. Recent findings suggest that RLVR primarily functions by eliciting latent capabilities, motivating the development of verifier-free algorithms. However, in such settings, standard methods like Group Relative Policy Optimization face a critical challenge: destructive gradient variance that often leads to training collapse. To address this issue, we introduceVerifier-Independent Curriculum Reinforcement Learning (VI-CuRL), a framework that leverages the model's intrinsic confidence to construct a curriculum independent from external verifiers. By prioritizing high-confidence samples, VI-CuRL effectively manages the bias-variance trade-off, specifically targeting the reduction of action and problem variance. We provide a rigorous theoretical analysis, proving that our estimator guarantees asymptotic unbiasedness. Empirically, VI-CuRL promotes stability and consistently outperforms verifier-independent baselines across six challenging benchmarks with/without verifiers.

</details>


### [83] [Multi-Head Attention as a Source of Catastrophic Forgetting in MoE Transformers](https://arxiv.org/abs/2602.12587)
*Anrui Chen,Ruijun Huang,Xin Zhang,Fang Dong,Hengjie Cao,Zhendong Huang,Yifeng Yang,Mengyi Chen,Jixian Zhou,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Tun Lu,Fan Yang,Li Shang*

Main category: cs.LG

TL;DR: MH-MoE通过多头路由机制解决MoE架构在持续学习中的遗忘问题，将路由粒度从整体表示细化到每个注意力头，减少特征组合冲突，显著降低遗忘率。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE架构的稀疏路由理论上应该减少更新干扰，但MoE Transformer在持续学习中仍存在显著遗忘。研究发现这是由于预路由瓶颈导致的：多头注意力将各头的信号拼接成单一的路由器输入，迫使路由基于共现的特征组合而非可分离的头通道，导致不同特征组合被映射到相同路由路径，造成冲突和遗忘。

Method: 提出MH-MoE（多头MoE），采用头级别路由机制，对子表示进行头级别路由，增加路由粒度。通过将路由操作从整体表示层面细化到每个注意力头，减少特征组合冲突，提高路由的精确性。

Result: 在TRACE基准测试中，使用Qwen3-0.6B/8B模型，MH-MoE有效缓解了遗忘问题。在Qwen3-0.6B上，将后向迁移（BWT）从LoRAMoE的11.2%降低到4.5%，显著提升了持续学习性能。

Conclusion: MoE架构在持续学习中的遗忘问题源于预路由瓶颈导致的特征组合冲突。通过引入头级别路由的MH-MoE架构，可以显著减少路由冲突，有效缓解遗忘，为MoE在持续学习中的应用提供了改进方向。

Abstract: Mixture-of-Experts (MoE) architectures are often considered a natural fit for continual learning because sparse routing should localize updates and reduce interference, yet MoE Transformers still forget substantially even with sparse, well-balanced expert utilization. We attribute this gap to a pre-routing bottleneck: multi-head attention concatenates head-specific signals into a single post-attention router input, forcing routing to act on co-occurring feature compositions rather than separable head channels. We show that this router input simultaneously encodes multiple separately decodable semantic and structural factors with uneven head support, and that different feature compositions induce weakly aligned parameter-gradient directions; as a result, routing maps many distinct compositions to the same route. We quantify this collision effect via a route-wise effective composition number $N_{eff}$ and find that higher $N_{eff}$ is associated with larger old-task loss increases after continual training. Motivated by these findings, we propose MH-MoE, which performs head-wise routing over sub-representations to increase routing granularity and reduce composition collisions. On TRACE with Qwen3-0.6B/8B, MH-MoE effectively mitigates forgetting, reducing BWT on Qwen3-0.6B from 11.2% (LoRAMoE) to 4.5%.

</details>


### [84] [Vehicle behaviour estimation for abnormal event detection using distributed fiber optic sensing](https://arxiv.org/abs/2602.12591)
*Hemant Prasad,Daisuke Ikefuji,Shin Tominaga,Hitoshi Sakurai,Manabu Otani*

Main category: cs.LG

TL;DR: 本文提出了一种基于分布式光纤传感系统检测单车道异常的方法，通过追踪车辆路径和检测车道变更行为来识别导致拥堵的单车道异常。


<details>
  <summary>Details</summary>
Motivation: 分布式光纤传感系统是一种经济高效的大范围交通监测技术，但检测导致拥堵的单车道异常仍然是一个挑战。这些单车道异常可以通过监测车辆为避开拥堵路段而进行的车道变更行为来检测。

Method: 提出了一种通过追踪单个车辆路径和检测车辆车道变更来检测单车道异常的方法。方法包括：1) 在所有时间实例估计车辆位置；2) 使用聚类技术拟合路径；3) 通过监测车辆振动频谱质心的变化来检测车道变更，沿着高速公路追踪参考车辆。

Result: 使用真实交通数据评估所提出的方法，结果显示在检测代表异常存在的车道变更事件方面达到了80%的准确率。

Conclusion: 该方法能够有效利用分布式光纤传感系统检测单车道异常，通过车辆车道变更行为的监测为交通拥堵预警提供了可行方案。

Abstract: The distributed fiber-optic sensing (DFOS) system is a cost-effective wide-area traffic monitoring technology that utilizes existing fiber infrastructure to effectively detect traffic congestions. However, detecting single-lane abnormalities, that lead to congestions, is still a challenge. These single-lane abnormalities can be detected by monitoring lane change behaviour of vehicles, performed to avoid congestion along the monitoring section of a road. This paper presents a method to detect single-lane abnormalities by tracking individual vehicle paths and detecting vehicle lane changes along a section of a road. We propose a method to estimate the vehicle position at all time instances and fit a path using clustering techniques. We detect vehicle lane change by monitoring any change in spectral centroid of vehicle vibrations by tracking a reference vehicle along a highway. The evaluation of our proposed method with real traffic data showed 80% accuracy for lane change detection events that represent presence of abnormalities.

</details>


### [85] [HyperMLP: An Integrated Perspective for Sequence Modeling](https://arxiv.org/abs/2602.12601)
*Jiecheng Lu,Shihao Yang*

Main category: cs.LG

TL;DR: 论文提出将自注意力机制重新解释为动态两层MLP，并基于此设计了HyperMLP和HyperGLU，在相同参数预算下优于softmax注意力基线。


<details>
  <summary>Details</summary>
Motivation: 传统上将自注意力视为概率查询-键查找，但作者认为这种视角过于复杂。他们主张将自回归注意力头视为动态两层MLP，权重从上下文历史实例化，从而提供更简单统一的视角。

Method: 基于注意力作为动态MLP的视角，提出HyperMLP和HyperGLU，使用反向偏移（滞后）布局对齐时间混合与自回归语义，学习特征空间和序列空间的动态混合。

Result: HyperMLP和HyperGLU在匹配参数预算下持续优于强大的softmax注意力基线模型。

Conclusion: 将注意力重新解释为动态MLP提供了更统一的视角，基于此设计的HyperMLP/HyperGLU在性能上超越了传统softmax注意力，为序列建模提供了新思路。

Abstract: Self-attention is often viewed as probabilistic query-key lookup, motivating designs that preserve normalized attention scores and fixed positional semantics. We advocate a simpler and more unified perspective: an autoregressive attention head can be viewed as a dynamic two-layer MLP whose weights are instantiated from the context history. From this view, attention scores form an ever-growing hidden representation, and standard MLP activations such as ReLU or GLU naturally implement input-conditioned selection over a context-dependent memory pool rather than a probability distribution. Based on this formulation, we introduce HyperMLP and HyperGLU, which learn dynamic mixing in both feature space and sequence space, using a reverse-offset (lag) layout to align temporal mixing with autoregressive semantics. We provide theoretical characterizations of the expressivity and implications of this structure, and empirically show that HyperMLP/HyperGLU consistently outperform strong softmax-attention baselines under matched parameter budgets.

</details>


### [86] [Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL](https://arxiv.org/abs/2602.12636)
*Xin Liu,Yixuan Li,Yuhui Chen,Yuxing Qin,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: DEG框架利用大型视频生成模型的先验知识，通过少量专家视频生成任务指导，结合双粒度对比奖励，在无需人工标注或大量监督的情况下实现高效强化学习。


<details>
  <summary>Details</summary>
Motivation: 强化学习中设计合适的奖励函数具有挑战性，特别是对于具身操作任务。轨迹成功奖励稀疏性严重限制了RL样本效率，而现有密集奖励方法依赖高质量人工标注数据或大量专家监督。

Method: 提出DEG框架：1) 利用大型视频生成模型的先验知识，仅需少量专家视频进行领域适应，为每个RL回合生成专用任务指导；2) 提出双粒度对比奖励，平衡粗粒度探索和细粒度匹配，在对比自监督潜在空间中引导智能体顺序逼近生成的指导视频。

Result: 在模拟和真实世界的18个多样化任务上进行广泛实验，结果表明DEG不仅能作为高效探索刺激帮助智能体快速发现稀疏成功奖励，还能独立引导有效的RL和稳定的策略收敛。

Conclusion: DEG框架成功解决了无需人工标注或大量监督的样本高效密集奖励问题，通过结合视频生成先验知识和双粒度对比奖励，在多样化任务上实现了高效的强化学习。

Abstract: Designing suitable rewards poses a significant challenge in reinforcement learning (RL), especially for embodied manipulation. Trajectory success rewards are suitable for human judges or model fitting, but the sparsity severely limits RL sample efficiency. While recent methods have effectively improved RL via dense rewards, they rely heavily on high-quality human-annotated data or abundant expert supervision. To tackle these issues, this paper proposes Dual-granularity contrastive reward via generated Episodic Guidance (DEG), a novel framework to seek sample-efficient dense rewards without requiring human annotations or extensive supervision. Leveraging the prior knowledge of large video generation models, DEG only needs a small number of expert videos for domain adaptation to generate dedicated task guidance for each RL episode. Then, the proposed dual-granularity reward that balances coarse-grained exploration and fine-grained matching, will guide the agent to efficiently approximate the generated guidance video sequentially in the contrastive self-supervised latent space, and finally complete the target task. Extensive experiments on 18 diverse tasks across both simulation and real-world settings show that DEG can not only serve as an efficient exploration stimulus to help the agent quickly discover sparse success rewards, but also guide effective RL and stable policy convergence independently.

</details>


### [87] [Block-Sample MAC-Bayes Generalization Bounds](https://arxiv.org/abs/2602.12605)
*Matthias Frey,Jingge Zhu,Michael C. Gastpar*

Main category: cs.LG

TL;DR: 提出了一族新的块样本MAC-Bayes边界，通过将训练数据划分为块来改进传统PAC-Bayes边界的紧致性，并在某些情况下避免边界失效的问题。


<details>
  <summary>Details</summary>
Motivation: 传统PAC-Bayes边界提供高概率下的泛化误差界，但可能在某些情况下变得无效。MAC-Bayes边界则关注期望泛化误差，但仍有改进空间。本文旨在开发更紧致的边界形式，通过数据分块策略来减少边界中的散度项。

Method: 提出了一族新的块样本MAC-Bayes边界，这些边界可以看作是已知PAC-Bayes边界期望版本的推广。关键创新在于边界中的散度项仅依赖于训练数据的子集（块），而不是整个数据集。通过适当选择块大小，可以获得比传统边界更紧致的估计。

Result: 数值示例显示，当原始PAC-Bayes边界无论先验如何选择都无效时，提出的块样本MAC-Bayes边界在适当的块大小选择下是有限的。同时证明了高概率版本的类似边界（即类似形式的PAC-Bayes边界）在一般情况下不可能存在，特别是当MAC-Bayes边界以O(n^{-1/2})速率消失时，相应的PAC-Bayes边界不可能以快于O(1/log n)的速率消失。

Conclusion: 提出的块样本MAC-Bayes边界在紧致性上显著优于传统PAC-Bayes和MAC-Bayes边界，通过数据分块策略有效减少了边界中的散度项。然而，这种改进的代价是无法获得高概率保证，因为证明了类似形式的高概率边界在一般情况下不可能存在。

Abstract: We present a family of novel block-sample MAC-Bayes bounds (mean approximately correct). While PAC-Bayes bounds (probably approximately correct) typically give bounds for the generalization error that hold with high probability, MAC-Bayes bounds have a similar form but bound the expected generalization error instead. The family of bounds we propose can be understood as a generalization of an expectation version of known PAC-Bayes bounds. Compared to standard PAC-Bayes bounds, the new bounds contain divergence terms that only depend on subsets (or \emph{blocks}) of the training data. The proposed MAC-Bayes bounds hold the promise of significantly improving upon the tightness of traditional PAC-Bayes and MAC-Bayes bounds. This is illustrated with a simple numerical example in which the original PAC-Bayes bound is vacuous regardless of the choice of prior, while the proposed family of bounds are finite for appropriate choices of the block size. We also explore the question whether high-probability versions of our MAC-Bayes bounds (i.e., PAC-Bayes bounds of a similar form) are possible. We answer this question in the negative with an example that shows that in general, it is not possible to establish a PAC-Bayes bound which (a) vanishes with a rate faster than $\mathcal{O}(1/\log n)$ whenever the proposed MAC-Bayes bound vanishes with rate $\mathcal{O}(n^{-1/2})$ and (b) exhibits a logarithmic dependence on the permitted error probability.

</details>


### [88] [RelBench v2: A Large-Scale Benchmark and Repository for Relational Data](https://arxiv.org/abs/2602.12606)
*Justin Gu,Rishabh Ranjan,Charilaos Kanatsoulis,Haiming Tang,Martin Jurkovic,Valter Hudovernik,Mark Znidar,Pranshu Chaturvedi,Parth Shroff,Fengyu Li,Jure Leskovec*

Main category: cs.LG

TL;DR: RelBench v2是一个大规模关系深度学习基准测试的重大扩展，新增了4个大型关系数据集，引入自动补全任务，并整合了外部基准和评估框架，共包含11个数据集、29个表、超过2200万行数据。


<details>
  <summary>Details</summary>
Motivation: 随着关系深度学习向更大模型和关系基础模型发展，需要可扩展且真实的基准测试来进行系统性评估和推动进展。现有的基准测试在规模、任务类型和评估框架方面存在局限。

Method: 1. 扩展了4个大规模关系数据集（学术出版物、企业资源规划、消费者平台、临床记录）；2. 引入自动补全任务，要求模型在关系表中推断缺失属性值并遵守时间约束；3. 整合外部基准：将Temporal Graph Benchmark的事件流转换为关系模式，与ReDeLEx接口提供70+真实数据库访问，纳入4DBInfer数据集和任务。

Result: RelBench v2现在包含11个数据集、29个表、超过2200万行数据。实验结果表明，关系深度学习模型在自动补全、预测和推荐任务上持续优于单表基线模型。

Conclusion: RelBench v2为关系深度学习提供了更全面、可扩展的评估框架，证明了显式建模关系结构的重要性，并为该领域的研究进展提供了必要的工具和基准。

Abstract: Relational deep learning (RDL) has emerged as a powerful paradigm for learning directly on relational databases by modeling entities and their relationships across multiple interconnected tables. As this paradigm evolves toward larger models and relational foundation models, scalable and realistic benchmarks are essential for enabling systematic evaluation and progress. In this paper, we introduce RelBench v2, a major expansion of the RelBench benchmark for RDL. RelBench v2 adds four large-scale relational datasets spanning scholarly publications, enterprise resource planning, consumer platforms, and clinical records, increasing the benchmark to 11 datasets comprising over 22 million rows across 29 tables. We further introduce autocomplete tasks, a new class of predictive objectives that require models to infer missing attribute values directly within relational tables while respecting temporal constraints, expanding beyond traditional forecasting tasks constructed via SQL queries. In addition, RelBench v2 expands beyond its native datasets by integrating external benchmarks and evaluation frameworks: we translate event streams from the Temporal Graph Benchmark into relational schemas for unified relational-temporal evaluation, interface with ReDeLEx to provide uniform access to 70+ real-world databases suitable for pretraining, and incorporate 4DBInfer datasets and tasks to broaden multi-table prediction coverage. Experimental results demonstrate that RDL models consistently outperform single-table baselines across autocomplete, forecasting, and recommendation tasks, highlighting the importance of modeling relational structure explicitly.

</details>


### [89] [Coden: Efficient Temporal Graph Neural Networks for Continuous Prediction](https://arxiv.org/abs/2602.12613)
*Zulun Zhu,Siqiang Luo*

Main category: cs.LG

TL;DR: Coden是一个为动态图设计的TGNN模型，专门解决连续预测问题，在保持预测精度的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有TGNN主要针对特定时间跨度的一次性预测，而实际应用需要频繁的连续预测。直接适配现有TGNN到连续预测场景会导致计算开销大或预测质量下降，特别是在大规模图上。

Method: Coden通过创新性地克服现有TGNN的关键复杂度瓶颈，同时保持可比较的预测精度。模型还建立了与RNN基和注意力基模型的对偶关系理论分析。

Result: 在五个动态数据集上的评估显示，Coden在效率和效果上都超越了现有性能基准，成为演化图环境中连续预测的优越解决方案。

Conclusion: Coden为TGNN的连续预测问题提供了高效有效的解决方案，通过理论分析和实验验证证明了其优越性。

Abstract: Temporal Graph Neural Networks (TGNNs) are pivotal in processing dynamic graphs. However, existing TGNNs primarily target one-time predictions for a given temporal span, whereas many practical applications require continuous predictions, that predictions are issued frequently over time. Directly adapting existing TGNNs to continuous-prediction scenarios introduces either significant computational overhead or prediction quality issues especially for large graphs. This paper revisits the challenge of { continuous predictions} in TGNNs, and introduces {\sc Coden}, a TGNN model designed for efficient and effective learning on dynamic graphs. {\sc Coden} innovatively overcomes the key complexity bottleneck in existing TGNNs while preserving comparable predictive accuracy. Moreover, we further provide theoretical analyses that substantiate the effectiveness and efficiency of {\sc Coden}, and clarify its duality relationship with both RNN-based and attention-based models. Our evaluations across five dynamic datasets show that {\sc Coden} surpasses existing performance benchmarks in both efficiency and effectiveness, establishing it as a superior solution for continuous prediction in evolving graph environments.

</details>


### [90] [Formalizing the Sampling Design Space of Diffusion-Based Generative Models via Adaptive Solvers and Wasserstein-Bounded Timesteps](https://arxiv.org/abs/2602.12624)
*Sangwoo Jo,Sungjoon Choi*

Main category: cs.LG

TL;DR: SDM是一个基于几何视角的扩散模型采样框架，通过分析ODE动态特性，在早期高噪声阶段使用低阶求解器，后期非线性增强阶段逐步部署高阶求解器，并通过Wasserstein有界优化框架自适应调整时间步长，在减少函数评估次数的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型在实际部署中受到高采样成本的限制，现有方法主要关注训练目标或单个求解器，而采样过程的整体设计（特别是求解器选择和时间调度）仍由静态启发式方法主导，缺乏系统性优化。

Method: SDM通过几何视角分析扩散轨迹的内在特性，提出：1）基于ODE动态分析，在早期高噪声阶段使用低阶求解器，后期非线性增强阶段逐步部署高阶求解器；2）引入Wasserstein有界优化框架，系统推导自适应时间步长，显式约束局部离散化误差，确保采样过程忠实于连续动态。

Result: 在不需额外训练或架构修改的情况下，SDM在标准基准测试中达到最先进性能：CIFAR-10上FID为1.93，FFHQ上为2.41，AFHQv2上为1.98，同时相比现有采样器减少了函数评估次数。

Conclusion: SDM提供了一个原则性的采样框架，通过几何视角将数值求解器与扩散轨迹的内在特性对齐，实现了采样效率与质量的平衡，为扩散模型的实际部署提供了有效的解决方案。

Abstract: Diffusion-based generative models have achieved remarkable performance across various domains, yet their practical deployment is often limited by high sampling costs. While prior work focuses on training objectives or individual solvers, the holistic design of sampling, specifically solver selection and scheduling, remains dominated by static heuristics. In this work, we revisit this challenge through a geometric lens, proposing SDM, a principled framework that aligns the numerical solver with the intrinsic properties of the diffusion trajectory. By analyzing the ODE dynamics, we show that efficient low-order solvers suffice in early high-noise stages while higher-order solvers can be progressively deployed to handle the increasing non-linearity of later stages. Furthermore, we formalize the scheduling by introducing a Wasserstein-bounded optimization framework. This method systematically derives adaptive timesteps that explicitly bound the local discretization error, ensuring the sampling process remains faithful to the underlying continuous dynamics. Without requiring additional training or architectural modifications, SDM achieves state-of-the-art performance across standard benchmarks, including an FID of 1.93 on CIFAR-10, 2.41 on FFHQ, and 1.98 on AFHQv2, with a reduced number of function evaluations compared to existing samplers. Our code is available at https://github.com/aiimaginglab/sdm.

</details>


### [91] [Uncovering spatial tissue domains and cell types in spatial omics through cross-scale profiling of cellular and genomic interactions](https://arxiv.org/abs/2602.12651)
*Rui Yan,Xiaohan Xing,Xun Wang,Zixia Zhou,Md Tauhidul Islam,Lei Xing*

Main category: cs.LG

TL;DR: CellScape是一个深度学习框架，用于分析空间转录组数据，通过联合建模组织空间中的细胞相互作用和细胞间的基因组关系，提高空间域分割和细胞分析能力。


<details>
  <summary>Details</summary>
Motivation: 空间转录组数据虽然提供了单细胞分辨率的原位基因表达谱，但数据噪声大、结构复杂，现有计算方法难以有效捕捉空间相互作用与内在基因组关系之间的相互作用，限制了关键生物学模式的识别。

Method: 开发了CellScape深度学习框架，联合建模组织空间中的细胞相互作用和细胞间的基因组关系，生成综合表征，将空间信号与基础基因调控机制无缝整合。

Result: 该方法能够发现具有生物学信息意义的模式，改善空间域分割，支持跨不同转录组数据集的全面空间细胞分析，为ST数据的深度分析和解释提供了准确且通用的框架。

Conclusion: CellScape通过整合空间和基因组信息，克服了现有方法的局限性，为高性能空间转录组数据分析和模式发现提供了有效的解决方案。

Abstract: Cellular identity and function are linked to both their intrinsic genomic makeup and extrinsic spatial context within the tissue microenvironment. Spatial transcriptomics (ST) offers an unprecedented opportunity to study this, providing in situ gene expression profiles at single-cell resolution and illuminating the spatial and functional organization of cells within tissues. However, a significant hurdle remains: ST data is inherently noisy, large, and structurally complex. This complexity makes it intractable for existing computational methods to effectively capture the interplay between spatial interactions and intrinsic genomic relationships, thus limiting our ability to discern critical biological patterns. Here, we present CellScape, a deep learning framework designed to overcome these limitations for high-performance ST data analysis and pattern discovery. CellScape jointly models cellular interactions in tissue space and genomic relationships among cells, producing comprehensive representations that seamlessly integrate spatial signals with underlying gene regulatory mechanisms. This technique uncovers biologically informative patterns that improve spatial domain segmentation and supports comprehensive spatial cellular analyses across diverse transcriptomics datasets, offering an accurate and versatile framework for deep analysis and interpretation of ST data.w

</details>


### [92] [SLA2: Sparse-Linear Attention with Learnable Routing and QAT](https://arxiv.org/abs/2602.12675)
*Jintao Zhang,Haoxu Wang,Kai Jiang,Kaiwen Zheng,Youhe Jiang,Ion Stoica,Jianfei Chen,Jun Zhu,Joseph E. Gonzalez*

Main category: cs.LG

TL;DR: SLA2改进稀疏线性注意力机制，通过可学习路由器和更直接的稀疏-线性注意力组合，在视频扩散模型中实现97%注意力稀疏度和18.6倍加速，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏线性注意力(SLA)存在两个问题：1) 基于注意力权重大小的启发式分割可能不是最优的；2) 注意力误差分析显示SLA与直接稀疏-线性分解存在不匹配。

Method: 提出SLA2：1) 可学习路由器动态选择每个注意力计算使用稀疏或线性注意力；2) 更忠实直接的稀疏-线性注意力公式，使用可学习比例组合两个分支；3) 稀疏+低比特注意力设计，通过量化感知微调减少量化误差。

Result: 在视频扩散模型中，SLA2能实现97%的注意力稀疏度，提供18.6倍的注意力加速，同时保持生成质量。

Conclusion: SLA2通过改进的稀疏-线性注意力机制，在保持生成质量的同时显著提升了视频扩散模型的注意力计算效率。

Abstract: Sparse-Linear Attention (SLA) combines sparse and linear attention to accelerate diffusion models and has shown strong performance in video generation. However, (i) SLA relies on a heuristic split that assigns computations to the sparse or linear branch based on attention-weight magnitude, which can be suboptimal. Additionally, (ii) after formally analyzing the attention error in SLA, we identify a mismatch between SLA and a direct decomposition into sparse and linear attention. We propose SLA2, which introduces (I) a learnable router that dynamically selects whether each attention computation should use sparse or linear attention, (II) a more faithful and direct sparse-linear attention formulation that uses a learnable ratio to combine the sparse and linear attention branches, and (III) a sparse + low-bit attention design, where low-bit attention is introduced via quantization-aware fine-tuning to reduce quantization error. Experiments show that on video diffusion models, SLA2 can achieve 97% attention sparsity and deliver an 18.6x attention speedup while preserving generation quality.

</details>


### [93] [Flow Matching from Viewpoint of Proximal Operators](https://arxiv.org/abs/2602.12683)
*Kenji Fukumizu,Wei Huang,Han Bao,Shuntuo Xu,Nisha Chandramoothy*

Main category: cs.LG

TL;DR: 本文重新表述了最优传输条件流匹配（OT-CFM）模型，证明了其可以通过扩展Brenier势能获得精确的近端形式，无需假设目标分布具有密度。研究还讨论了小批量OT-CFM随着批量增大向总体公式的收敛性，并证明了对于流形支撑的目标，OT-CFM具有终端正态双曲性。


<details>
  <summary>Details</summary>
Motivation: 传统的最优传输条件流匹配（OT-CFM）模型通常假设目标分布具有密度，这限制了其应用范围。本文旨在重新表述OT-CFM，使其能够处理更一般的分布，包括没有密度的分布，同时提供更精确的数学框架来分析其动力学特性。

Method: 通过扩展Brenier势能，将OT-CFM重新表述为精确的近端形式，其中恢复目标点的映射由近端算子精确给出，从而得到向量场的显式近端表达式。使用凸势能的二阶上导数，分析模型在流形支撑目标下的动力学行为。

Result: 1. OT-CFM可以通过扩展Brenier势能获得精确的近端形式，无需假设目标分布具有密度；2. 小批量OT-CFM随着批量增大收敛到总体公式；3. 对于流形支撑的目标，OT-CFM具有终端正态双曲性：经过时间重新标度后，动力学在垂直于数据流形的方向上指数收缩，而在切向方向上保持中性。

Conclusion: 本文为OT-CFM提供了一个更一般的数学框架，使其能够处理没有密度的目标分布，并揭示了其在流形支撑目标下的重要动力学特性——终端正态双曲性，这为理解和分析这类生成模型的收敛行为提供了理论基础。

Abstract: We reformulate Optimal Transport Conditional Flow Matching (OT-CFM), a class of dynamical generative models, showing that it admits an exact proximal formulation via an extended Brenier potential, without assuming that the target distribution has a density. In particular, the mapping to recover the target point is exactly given by a proximal operator, which yields an explicit proximal expression of the vector field. We also discuss the convergence of minibatch OT-CFM to the population formulation as the batch size increases. Finally, using second epi-derivatives of convex potentials, we prove that, for manifold-supported targets, OT-CFM is terminally normally hyperbolic: after time rescaling, the dynamics contracts exponentially in directions normal to the data manifold while remaining neutral along tangential directions.

</details>


### [94] [Trust the uncertain teacher: distilling dark knowledge via calibrated uncertainty](https://arxiv.org/abs/2602.12687)
*Jeonghyun Kim,SooKyung Kim,Richeng Xuan,Hyunsoo Cho*

Main category: cs.LG

TL;DR: 提出校准不确定性蒸馏（CUD）框架，解决传统知识蒸馏中教师模型过度自信导致"暗知识"信号丢失的问题，通过校准教师预测分布，使学生模型在准确性和校准性上均获得提升。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏中，使用交叉熵训练的教师模型会产生过度自信的尖锐预测分布，导致"暗知识"（揭示类别关系和不确定性分布的微妙概率模式）信号丢失。这种过度自信在高基数任务中尤为严重，且会降低模型在分布偏移下的鲁棒性，使学生模型在真实场景中容易失准。

Method: 提出校准不确定性蒸馏（CUD）框架，从分布视角重新审视蒸馏过程。CUD不盲目采用教师的过度自信预测，而是鼓励教师在有信息量的地方揭示不确定性，并指导学生从校准而非尖锐确定性的目标中学习。通过直接塑造教师预测分布再进行知识转移，平衡准确性和校准性。

Result: 在多样化基准测试中，CUD训练的学生模型不仅更准确，而且在分布偏移下校准性更好，在模糊、长尾输入上更可靠。

Conclusion: CUD框架通过校准教师预测分布，使"暗知识"更忠实地传递给学生模型，解决了传统知识蒸馏中过度自信的问题，提升了学生模型的准确性、校准性和鲁棒性。

Abstract: The core of knowledge distillation lies in transferring the teacher's rich 'dark knowledge'-subtle probabilistic patterns that reveal how classes are related and the distribution of uncertainties. While this idea is well established, teachers trained with conventional cross-entropy often fail to preserve such signals. Their distributions collapse into sharp, overconfident peaks that appear decisive but are in fact brittle, offering little beyond the hard label or subtly hindering representation-level transfer. This overconfidence is especially problematic in high-cardinality tasks, where the nuances among many plausible classes matter most for guiding a compact student. Moreover, such brittle targets reduce robustness under distribution shift, leaving students vulnerable to miscalibration in real-world conditions. To address this limitation, we revisit distillation from a distributional perspective and propose Calibrated Uncertainty Distillation (CUD), a framework designed to make dark knowledge more faithfully accessible. Instead of uncritically adopting the teacher's overconfidence, CUD encourages teachers to reveal uncertainty where it is informative and guides students to learn from targets that are calibrated rather than sharpened certainty. By directly shaping the teacher's predictive distribution before transfer, our approach balances accuracy and calibration, allowing students to benefit from both confident signals on easy cases and structured uncertainty on hard ones. Across diverse benchmarks, CUD yields students that are not only more accurate, but also more calibrated under shift and more reliable on ambiguous, long-tail inputs.

</details>


### [95] [Leverage-Weighted Conformal Prediction](https://arxiv.org/abs/2602.12693)
*Shreyas Fadnavis*

Main category: cs.LG

TL;DR: 提出Leverage-Weighted Conformal Prediction (LWCP)，通过统计杠杆权重调整非一致性分数，在保持边际覆盖的同时改善条件覆盖，无需训练辅助模型。


<details>
  <summary>Details</summary>
Motivation: 传统分割保形预测产生恒定宽度的预测区间，在低方差区域过度覆盖，在高方差区域覆盖不足。现有自适应方法需要训练辅助模型，增加了复杂性。

Method: 提出LWCP方法，使用统计杠杆（帽子矩阵的对角线）的函数来加权非一致性分数，从设计矩阵的几何结构中获取适应性，而非通过辅助模型拟合。

Result: LWCP保持有限样本边际有效性；在异方差通过杠杆因子化时实现渐近最优条件覆盖；在保持分布自由保证的同时恢复高斯假设下的经典预测区间形式；随机杠杆近似保持精确覆盖；相比传统方法显著减少条件覆盖差异。

Conclusion: LWCP提供了一种简单有效的自适应保形预测方法，仅需选择权重函数，计算开销可忽略，在理论和实验中均表现出优越的性能。

Abstract: Split conformal prediction provides distribution-free prediction intervals with finite-sample marginal coverage, but produces constant-width intervals that overcover in low-variance regions and undercover in high-variance regions. Existing adaptive methods require training auxiliary models. We propose Leverage-Weighted Conformal Prediction (LWCP), which weights nonconformity scores by a function of the statistical leverage -- the diagonal of the hat matrix -- deriving adaptivity from the geometry of the design matrix rather than from auxiliary model fitting. We prove that LWCP preserves finite-sample marginal validity for any weight function; achieves asymptotically optimal conditional coverage at essentially no width cost when heteroscedasticity factors through leverage; and recovers the form and width of classical prediction intervals under Gaussian assumptions while retaining distribution-free guarantees. We further establish that randomized leverage approximations preserve coverage exactly with controlled width perturbation, and that vanilla CP suffers a persistent, sample-size-independent conditional coverage gap that LWCP eliminates. The method requires no hyperparameters beyond the choice of weight function and adds negligible computational overhead to vanilla CP. Experiments on synthetic and real data confirm the theoretical predictions, demonstrating substantial reductions in conditional coverage disparity across settings.

</details>


### [96] [Physics-Informed Laplace Neural Operator for Solving Partial Differential Equations](https://arxiv.org/abs/2602.12706)
*Heechang Kim,Qianying Cao,Hyomin Shin,Seungchul Lee,George Em Karniadakis,Minseok Choi*

Main category: cs.LG

TL;DR: PILNO是一种物理信息增强的拉普拉斯神经算子，通过嵌入物理约束和虚拟输入提升小数据场景下的泛化能力


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动的神经算子需要大量训练数据，在小数据场景和未见输入函数（分布外）下泛化能力差，需要结合物理先验知识来提升性能

Method: 提出PILNO框架：1）改进LNO为ALNO，保留极点-残差瞬态表示，用FNO风格傅里叶乘子替换稳态分支；2）引入虚拟输入提供无标签监督；3）使用时序因果加权优先处理早期动力学

Result: 在四个基准测试（Burgers方程、Darcy流、反应扩散系统、强制KdV方程）中，PILNO在小数据场景（N_train≤27）下提升精度，减少随机种子间的变异性，实现更强的分布外泛化

Conclusion: PILNO通过物理信息训练和虚拟输入策略，显著提升了神经算子在数据稀缺和分布外场景下的性能，为小数据物理建模提供了有效解决方案

Abstract: Neural operators have emerged as fast surrogate solvers for parametric partial differential equations (PDEs). However, purely data-driven models often require extensive training data and can generalize poorly, especially in small-data regimes and under unseen (out-of-distribution) input functions that are not represented in the training data. To address these limitations, we propose the Physics-Informed Laplace Neural Operator (PILNO), which enhances the Laplace Neural Operator (LNO) by embedding governing physics into training through PDE, boundary condition, and initial condition residuals. To improve expressivity, we first introduce an Advanced LNO (ALNO) backbone that retains a pole-residue transient representation while replacing the steady-state branch with an FNO-style Fourier multiplier. To make physics-informed training both data-efficient and robust, PILNO further leverages (i) virtual inputs: an unlabeled ensemble of input functions spanning a broad spectral range that provides abundant physics-only supervision and explicitly targets out-of-distribution (OOD) regimes; and (ii) temporal-causality weighting: a time-decaying reweighting of the physics residual that prioritizes early-time dynamics and stabilizes optimization for time-dependent PDEs. Across four representative benchmarks -- Burgers' equation, Darcy flow, a reaction-diffusion system, and a forced KdV equation -- PILNO consistently improves accuracy in small-data settings (e.g., N_train <= 27), reduces run-to-run variability across random seeds, and achieves stronger OOD generalization than purely data-driven baselines.

</details>


### [97] [Mixture of Predefined Experts: Maximizing Data Usage on Vertical Federated Learning](https://arxiv.org/abs/2602.12708)
*Jon Irureta,Gorka Azkune,Jon Imaz,Aizea Lojo,Javier Fernandez-Marques*

Main category: cs.LG

TL;DR: Split-MoPE：一种结合分割学习与预定义专家混合架构的垂直联邦学习框架，解决了实际场景中样本不对齐问题，在单轮通信中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有垂直联邦学习框架大多基于完全样本对齐的理想假设，这在现实场景中很少成立。需要一种能够处理样本不对齐情况、减少通信开销、同时保持隐私保护的解决方案。

Method: 提出Split-MoPE框架，结合分割学习和专门的预定义专家混合架构。与动态学习路由的标准MoE不同，MoPE使用预定义专家处理特定数据对齐模式，最大化数据利用率。利用目标数据域的预训练编码器，在单轮通信中完成训练。

Result: 在视觉数据集（CIFAR-10/100）和表格数据集（Breast Cancer Wisconsin）上的广泛评估表明，Split-MoPE始终优于LASER和Vertical SplitNN等最先进系统，特别是在数据缺失率高的挑战性场景中表现突出。

Conclusion: Split-MoPE通过创新的预定义专家混合架构，有效解决了垂直联邦学习中的样本不对齐问题，实现了高效的单轮通信训练，同时提供对恶意参与者的鲁棒性和每个预测的可解释性。

Abstract: Vertical Federated Learning (VFL) has emerged as a critical paradigm for collaborative model training in privacy-sensitive domains such as finance and healthcare. However, most existing VFL frameworks rely on the idealized assumption of full sample alignment across participants, a premise that rarely holds in real-world scenarios. To bridge this gap, this work introduces Split-MoPE, a novel framework that integrates Split Learning with a specialized Mixture of Predefined Experts (MoPE) architecture. Unlike standard Mixture of Experts (MoE), where routing is learned dynamically, MoPE uses predefined experts to process specific data alignments, effectively maximizing data usage during both training and inference without requiring full sample overlap. By leveraging pretrained encoders for target data domains, Split-MoPE achieves state-of-the-art performance in a single communication round, significantly reducing the communication footprint compared to multi-round end-to-end training. Furthermore, unlike existing proposals that address sample misalignment, this novel architecture provides inherent robustness against malicious or noisy participants and offers per-sample interpretability by quantifying each collaborator's contribution to each prediction. Extensive evaluations on vision (CIFAR-10/100) and tabular (Breast Cancer Wisconsin) datasets demonstrate that Split-MoPE consistently outperforms state-of-the-art systems such as LASER and Vertical SplitNN, particularly in challenging scenarios with high data missingness.

</details>


### [98] [Adaptive Structured Pruning of Convolutional Neural Networks for Time Series Classification](https://arxiv.org/abs/2602.12744)
*Javidan Abdullayev,Maxime Devanne,Cyril Meyer,Ali Ismail-Fawaz,Jonathan Weber,Germain Forestier*

Main category: cs.LG

TL;DR: DSP是一种全自动结构化剪枝框架，用于卷积时间序列分类模型，无需手动设置剪枝比例，能显著压缩模型大小（LITETime压缩58%，InceptionTime压缩75%）同时保持分类精度。


<details>
  <summary>Details</summary>
Motivation: 深度学习时间序列分类模型计算和内存需求高，难以部署在资源受限设备上。现有结构化剪枝方法依赖手动调优的剪枝比例等超参数，限制了跨数据集的可扩展性和泛化能力。

Method: 提出动态结构化剪枝（DSP）框架：1）训练时引入实例级稀疏损失函数诱导通道级稀疏；2）通过全局激活分析自动识别并剪枝冗余滤波器，无需预定义剪枝比例。

Result: 在128个UCR数据集上验证，使用LITETime和InceptionTime两种架构：LITETime平均压缩58%，InceptionTime平均压缩75%，同时保持分类精度。冗余分析确认DSP产生紧凑且信息丰富的表示。

Conclusion: DSP为卷积时间序列分类模型提供了全自动结构化剪枝方案，解决了资源受限设备部署的计算瓶颈，实现了可扩展且高效的深度学习时间序列分类部署。

Abstract: Deep learning models for Time Series Classification (TSC) have achieved strong predictive performance but their high computational and memory requirements often limit deployment on resource-constrained devices. While structured pruning can address these issues by removing redundant filters, existing methods typically rely on manually tuned hyperparameters such as pruning ratios which limit scalability and generalization across datasets. In this work, we propose Dynamic Structured Pruning (DSP), a fully automatic, structured pruning framework for convolution-based TSC models. DSP introduces an instance-wise sparsity loss during training to induce channel-level sparsity, followed by a global activation analysis to identify and prune redundant filters without needing any predefined pruning ratio. This work tackles computational bottlenecks of deep TSC models for deployment on resource-constrained devices. We validate DSP on 128 UCR datasets using two different deep state-of-the-art architectures: LITETime and InceptionTime. Our approach achieves an average compression of 58% for LITETime and 75% for InceptionTime architectures while maintaining classification accuracy. Redundancy analyses confirm that DSP produces compact and informative representations, offering a practical path for scalable and efficient deep TSC deployment.

</details>


### [99] [GRAIL: Geometry-Aware Retrieval-Augmented Inference with LLMs over Hyperbolic Representations of Patient Trajectories](https://arxiv.org/abs/2602.12828)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: GRAIL框架通过结构化几何表示和结构感知检索来预测纵向电子健康记录中的未来临床事件，结合确定性编码系统层次结构和数据驱动的时间关联，在双曲空间中嵌入临床图，并使用LLM作为约束推理时间重排器。


<details>
  <summary>Details</summary>
Motivation: 从纵向电子健康记录预测未来临床事件面临三大挑战：稀疏的多类型临床事件、分层的医学术语体系，以及大型语言模型在处理长结构化历史时容易产生幻觉。这些挑战使得准确预测患者下一次就诊事件变得困难。

Method: 提出GRAIL框架：1) 构建统一的临床图，结合确定性编码系统层次结构和数据驱动的时间关联；2) 在双曲空间中嵌入该图；3) 将每次就诊总结为概率性中心事件以去噪稀疏观测；4) 推理时检索结构化的临床合理未来事件集，与层次和时间进展对齐；5) 可选使用LLM作为约束推理时间重排器来优化排名。

Result: 在MIMIC-IV数据集上的实验表明，GRAIL在多类型下一次就诊预测方面持续改进，并产生更符合层次结构一致的预测结果。

Conclusion: GRAIL框架通过结构化几何表示和结构感知检索有效解决了纵向电子健康记录预测中的关键挑战，结合了确定性医学层次结构和数据驱动的时间模式，为临床事件预测提供了更准确、更一致的方法。

Abstract: Predicting future clinical events from longitudinal electronic health records (EHRs) is challenging due to sparse multi-type clinical events, hierarchical medical vocabularies, and the tendency of large language models (LLMs) to hallucinate when reasoning over long structured histories. We study next-visit event prediction, which aims to forecast a patient's upcoming clinical events based on prior visits. We propose GRAIL, a framework that models longitudinal EHRs using structured geometric representations and structure-aware retrieval. GRAIL constructs a unified clinical graph by combining deterministic coding-system hierarchies with data-driven temporal associations across event types, embeds this graph in hyperbolic space, and summarizes each visit as a probabilistic Central Event that denoises sparse observations. At inference time, GRAIL retrieves a structured set of clinically plausible future events aligned with hierarchical and temporal progression, and optionally refines their ranking using an LLM as a constrained inference-time reranker. Experiments on MIMIC-IV show that GRAIL consistently improves multi-type next-visit prediction and yields more hierarchy-consistent forecasts.

</details>


### [100] [Hierarchical Successor Representation for Robust Transfer](https://arxiv.org/abs/2602.12753)
*Changmin Yu,Máté Lengyel*

Main category: cs.LG

TL;DR: 本文提出层次化后继表示（HSR）来解决经典后继表示的政策依赖性和谱扩散问题，通过时间抽象和NMF分解获得稀疏、低秩的状态表示，实现高效任务迁移和探索。


<details>
  <summary>Details</summary>
Motivation: 经典后继表示存在两个主要问题：1）政策依赖性 - 政策变化会导致预测表示失效；2）谱扩散 - 在拓扑复杂环境中产生密集重叠的特征，扩展性差。需要开发一种能够适应政策变化且可扩展的表示方法。

Method: 提出层次化后继表示（HSR），将时间抽象整合到预测表示构建中。应用非负矩阵分解（NMF）到HSR，获得稀疏、低秩的状态表示。该方法在多个隔间环境中验证了高效任务迁移能力。

Result: HSR-NMF能够发现可解释的拓扑结构，提供政策无关的层次化地图。在大型程序生成环境中，HSR的时间扩展预测结构能够驱动高效探索，实现高度样本效率的任务迁移。

Conclusion: HSR通过结合时间抽象和非负矩阵分解，克服了经典后继表示的政策依赖性和谱扩散问题，实现了政策无关的稳定特征表示，有效桥接了无模型最优性和基于模型的灵活性，为大规模环境中的任务迁移和探索提供了实用基础。

Abstract: The successor representation (SR) provides a powerful framework for decoupling predictive dynamics from rewards, enabling rapid generalisation across reward configurations. However, the classical SR is limited by its inherent policy dependence: policies change due to ongoing learning, environmental non-stationarities, and changes in task demands, making established predictive representations obsolete. Furthermore, in topologically complex environments, SRs suffer from spectral diffusion, leading to dense and overlapping features that scale poorly. Here we propose the Hierarchical Successor Representation (HSR) for overcoming these limitations. By incorporating temporal abstractions into the construction of predictive representations, HSR learns stable state features which are robust to task-induced policy changes. Applying non-negative matrix factorisation (NMF) to the HSR yields a sparse, low-rank state representation that facilitates highly sample-efficient transfer to novel tasks in multi-compartmental environments. Further analysis reveals that HSR-NMF discovers interpretable topological structures, providing a policy-agnostic hierarchical map that effectively bridges model-free optimality and model-based flexibility. Beyond providing a useful basis for task-transfer, we show that HSR's temporally extended predictive structure can also be leveraged to drive efficient exploration, effectively scaling to large, procedurally generated environments.

</details>


### [101] [FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching](https://arxiv.org/abs/2602.12829)
*Lei Lv,Yunfei Li,Yu Luo,Fuchun Sun,Xiao Ma*

Main category: cs.LG

TL;DR: FLAC是一个免似然框架，通过惩罚速度场的动能来调节策略随机性，将策略优化表述为广义薛定谔桥问题，无需显式动作密度估计。


<details>
  <summary>Details</summary>
Motivation: 迭代生成策略（如扩散模型和流匹配）在连续控制中具有优越表达能力，但由于其动作对数密度不可直接访问，使得最大熵强化学习变得复杂。

Method: 提出场最小能量演员-评论家（FLAC）框架，将策略优化表述为相对于高熵参考过程（如均匀分布）的广义薛定谔桥问题，通过惩罚速度场的动能来调节策略随机性，并推导出能量正则化的策略迭代方案和实用的离策略算法。

Result: 在高维基准测试中，FLAC相对于强基线实现了优越或可比的性能，同时避免了显式密度估计。

Conclusion: FLAC通过将策略优化视为广义薛定谔桥问题，提供了一种物理上合理的免似然框架，能够有效调节策略随机性，在高维连续控制任务中表现出色。

Abstract: Iterative generative policies, such as diffusion models and flow matching, offer superior expressivity for continuous control but complicate Maximum Entropy Reinforcement Learning because their action log-densities are not directly accessible. To address this, we propose Field Least-Energy Actor-Critic (FLAC), a likelihood-free framework that regulates policy stochasticity by penalizing the kinetic energy of the velocity field. Our key insight is to formulate policy optimization as a Generalized Schrödinger Bridge (GSB) problem relative to a high-entropy reference process (e.g., uniform). Under this view, the maximum-entropy principle emerges naturally as staying close to a high-entropy reference while optimizing return, without requiring explicit action densities. In this framework, kinetic energy serves as a physically grounded proxy for divergence from the reference: minimizing path-space energy bounds the deviation of the induced terminal action distribution. Building on this view, we derive an energy-regularized policy iteration scheme and a practical off-policy algorithm that automatically tunes the kinetic energy via a Lagrangian dual mechanism. Empirically, FLAC achieves superior or comparable performance on high-dimensional benchmarks relative to strong baselines, while avoiding explicit density estimation.

</details>


### [102] [Closing the Loop: A Control-Theoretic Framework for Provably Stable Time Series Forecasting with LLMs](https://arxiv.org/abs/2602.12756)
*Xingyu Zhang,Hanyun Du,Zeen Song,Jianqi Zhang,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 本文提出F-LLM框架，通过控制理论视角将自回归时间序列预测重构为闭环系统，使用可学习的残差估计器和反馈控制器来主动稳定轨迹，显著减少误差累积。


<details>
  <summary>Details</summary>
Motivation: 现有LLM时间序列预测方法采用朴素的自回归生成策略，在推理时以开环方式运行，递归消耗自身生成的输出，导致不可避免的误差累积（暴露偏差），早期微小偏差会在长时域上累积成显著的轨迹漂移。

Method: 提出F-LLM（反馈驱动的LLM）框架，基于控制理论将自回归预测重构为闭环系统。包含可学习的残差估计器（Observer）和反馈控制器，主动稳定轨迹而非被动传播误差。

Result: 理论证明闭环机制在基础模型满足局部Lipschitz约束时能确保误差一致有界。大量实验表明F-LLM显著减轻了误差传播，在时间序列基准测试中取得了良好性能。

Conclusion: 通过控制理论视角重新思考自回归预测，提出的闭环F-LLM框架能够有效解决传统开环方法中的误差累积问题，为LLM在时间序列预测中的应用提供了更稳健的解决方案。

Abstract: Large Language Models (LLMs) have recently shown exceptional potential in time series forecasting, leveraging their inherent sequential reasoning capabilities to model complex temporal dynamics. However, existing approaches typically employ a naive autoregressive generation strategy. We identify a critical theoretical flaw in this paradigm: during inference, the model operates in an open-loop manner, consuming its own generated outputs recursively. This leads to inevitable error accumulation (exposure bias), where minor early deviations cascade into significant trajectory drift over long horizons. In this paper, we reformulate autoregressive forecasting through the lens of control theory, proposing \textbf{F-LLM} (Feedback-driven LLM), a novel closed-loop framework. Unlike standard methods that passively propagate errors, F-LLM actively stabilizes the trajectory via a learnable residual estimator (Observer) and a feedback controller. Furthermore, we provide a theoretical guarantee that our closed-loop mechanism ensures uniformly bounded error, provided the base model satisfies a local Lipschitz constraint. Extensive experiments demonstrate that F-LLM significantly mitigates error propagation, achieving good performance on time series benchmarks.

</details>


### [103] [Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models](https://arxiv.org/abs/2602.12846)
*Zesheng Hong,Jiadong Yu,Hui Pan*

Main category: cs.LG

TL;DR: RLVR方法虽然有效但会抑制罕见但正确的推理路径，作者提出ARTS方法通过解耦生成与验证来保护推理多样性，在长尾问题上表现显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习与可验证奖励（RLVR）方法虽然能增强大型语言模型的推理能力，但存在一个关键缺陷：系统性地抑制了有效但罕见（在基础模型分布中概率较低）的推理路径。这种"归一化挤压"现象导致罕见但正确的推理轨迹在统计上被淘汰。

Method: 提出摊销推理树搜索（ARTS）方法，通过解耦生成与验证来优先考虑深思熟虑。引入流匹配目标，重新利用验证器来估计概率流的守恒，从而在稀疏、高熵的搜索空间中实现鲁棒导航，而传统的判别性目标在此类空间中会失效。

Result: 在MATH-500基准测试中，ARTS达到74.6%的性能（BoN@16），与完全微调的策略（74.7%）相当，且无需修改生成主干。在长尾子集上，耦合的RL优化方法性能降至0% pass@k，而ARTS能显著恢复性能，表明解耦验证与生成为解决复杂推理任务提供了更鲁棒的途径。

Conclusion: ARTS方法通过解耦生成与验证，有效解决了RLVR方法中罕见推理路径被抑制的问题，在保持基础模型潜在多样性的同时，为复杂推理任务提供了更鲁棒的解决方案，特别是在长尾问题上表现突出。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has established itself as the dominant paradigm for instilling rigorous reasoning capabilities in Large Language Models. While effective at amplifying dominant behaviors, we identify a critical pathology in this alignment process: the systematic suppression of valid but rare (low-likelihood under the base model distribution) reasoning paths. We theoretically characterize this phenomenon as a "Normalization Squeeze," where the interplay between mode-seeking policy gradients and finite sampling acts as a high-pass likelihood filter, driving the probability of rare correct traces to statistical extinction. To counteract this collapse without discarding the base model's latent diversity, we propose Amortized Reasoning Tree Search (ARTS). Unlike standard approaches that force internalization via parameter updates, ARTS prioritizes deliberation by decoupling generation from verification. We introduce a Flow Matching objective that repurposes the verifier to estimate the conservation of probability flow, enabling robust navigation through sparse, high-entropy search spaces where traditional discriminative objectives fail. Extensive experiments on the MATH-500 benchmark demonstrate that ARTS achieves a performance of 74.6% (BoN@16), effectively matching fully fine-tuned policies (74.7%) without modifying the generative backbone. Crucially, on the long-tail subset where coupled RL optimization collapses to 0% pass@k, ARTS uniquely recovers significant performance, suggesting that disentangling verification from generation offers a more robust pathway for solving complex reasoning tasks.

</details>


### [104] [X-VORTEX: Spatio-Temporal Contrastive Learning for Wake Vortex Trajectory Forecasting](https://arxiv.org/abs/2602.12869)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: X-VORTEX：基于增强重叠理论的时空对比学习框架，从无标签LiDAR点云序列中学习物理感知的涡流表征，仅需1%标注数据即可实现优于监督基线的涡流中心定位


<details>
  <summary>Details</summary>
Motivation: 飞机尾涡对空中交通管理构成重大安全和容量挑战。现有方法将每次扫描视为独立的完全监督分割问题，忽略了时间结构，且无法扩展到实践中收集的大量未标注数据。LiDAR扫描稀疏、涡流特征随时间衰减、逐点标注成本高昂是主要挑战。

Method: 提出X-VORTEX时空对比学习框架，基于增强重叠理论。通过结合弱扰动序列和强增强对应序列（通过时间子采样和空间掩码生成）构建配对输入，鼓励模型在缺失帧和部分观测间对齐表征。架构包括时间分布几何编码器提取每帧特征，以及序列聚合器建模变长序列中的涡流状态演化。

Result: 在超过100万次LiDAR扫描的真实数据集上评估。X-VORTEX仅使用监督基线所需标注数据的1%，即可实现更优的涡流中心定位。学习到的表征支持准确的轨迹预测。

Conclusion: X-VORTEX通过时空对比学习有效解决了传感器稀疏性和时变涡流动力学的核心挑战，为从大规模无标签LiDAR数据中学习物理感知表征提供了可行方案，显著减少了对昂贵标注数据的依赖。

Abstract: Wake vortices are strong, coherent air turbulences created by aircraft, and they pose a major safety and capacity challenge for air traffic management. Tracking how vortices move, weaken, and dissipate over time from LiDAR measurements is still difficult because scans are sparse, vortex signatures fade as the flow breaks down under atmospheric turbulence and instabilities, and point-wise annotation is prohibitively expensive. Existing approaches largely treat each scan as an independent, fully supervised segmentation problem, which overlooks temporal structure and does not scale to the vast unlabeled archives collected in practice. We present X-VORTEX, a spatio-temporal contrastive learning framework grounded in Augmentation Overlap Theory that learns physics-aware representations from unlabeled LiDAR point cloud sequences. X-VORTEX addresses two core challenges: sensor sparsity and time-varying vortex dynamics. It constructs paired inputs from the same underlying flight event by combining a weakly perturbed sequence with a strongly augmented counterpart produced via temporal subsampling and spatial masking, encouraging the model to align representations across missing frames and partial observations. Architecturally, a time-distributed geometric encoder extracts per-scan features and a sequential aggregator models the evolving vortex state across variable-length sequences. We evaluate on a real-world dataset of over one million LiDAR scans. X-VORTEX achieves superior vortex center localization while using only 1% of the labeled data required by supervised baselines, and the learned representations support accurate trajectory forecasting.

</details>


### [105] [Transporting Task Vectors across Different Architectures without Training](https://arxiv.org/abs/2602.12952)
*Filippo Rinaldi,Aniello Panariello,Giacomo Salici,Angelo Porrello,Simone Calderara*

Main category: cs.LG

TL;DR: Theseus是一种无需训练的方法，用于在不同宽度的异构模型之间传输任务特定的参数更新，通过功能匹配而非参数匹配实现。


<details>
  <summary>Details</summary>
Motivation: 大型预训练模型适应下游任务时会产生昂贵的任务特定参数更新，现有方法只能在相同架构模型间传输更新，无法在不同宽度的异构模型间传输。

Method: Theseus通过表征任务更新对中间表示的功能影响，将任务向量传输形式化为观测激活的功能匹配问题，使用正交Procrustes分析对齐表示空间，获得保持更新几何结构的闭式解。

Result: 在视觉和语言模型的不同宽度上评估Theseus，相比强基线方法有持续改进，无需额外训练或反向传播。

Conclusion: 当任务身份从功能而非参数角度定义时，任务更新可以在不同架构间有意义地传输。

Abstract: Adapting large pre-trained models to downstream tasks often produces task-specific parameter updates that are expensive to relearn for every model variant. While recent work has shown that such updates can be transferred between models with identical architectures, transferring them across models of different widths remains largely unexplored. In this work, we introduce Theseus, a training-free method for transporting task-specific updates across heterogeneous models. Rather than matching parameters directly, we characterize a task update by the functional effect it induces on intermediate representations. We formalize task-vector transport as a functional matching problem on observed activations and show that, after aligning representation spaces via orthogonal Procrustes analysis, it admits a stable closed-form solution that preserves the geometry of the update. We evaluate Theseus on vision and language models across different widths, showing consistent improvements over strong baselines without additional training or backpropagation. Our results show that task updates can be meaningfully transferred across architectures when task identity is defined functionally rather than parametrically.

</details>


### [106] [Extending confidence calibration to generalised measures of variation](https://arxiv.org/abs/2602.12975)
*Andrew Thompson,Vivek Desai*

Main category: cs.LG

TL;DR: 提出VCE（变分校准误差）作为评估机器学习分类器校准的新指标，扩展了ECE（期望校准误差），能够评估概率分布的整体变异性而非仅最大概率


<details>
  <summary>Details</summary>
Motivation: 现有ECE指标仅评估最大概率（置信度）的校准，忽略了整个概率分布的变异性。需要一种能够评估概率分布整体校准情况的指标，如考虑香农熵等变异性度量

Method: 将ECE方法从仅评估置信度校准扩展到评估任何变异性度量的校准，提出VCE指标。通过合成预测数据进行数值实验验证

Result: 在完美校准的合成预测数据上，VCE随着数据样本增加趋近于零，而文献中提出的另一种基于熵的校准指标（UCE）不具备这一理想特性

Conclusion: VCE是评估分类器校准的有效指标，能够评估概率分布的整体变异性校准，在完美校准场景下具有理想的渐近特性

Abstract: We propose the Variation Calibration Error (VCE) metric for assessing the calibration of machine learning classifiers. The metric can be viewed as an extension of the well-known Expected Calibration Error (ECE) which assesses the calibration of the maximum probability or confidence. Other ways of measuring the variation of a probability distribution exist which have the advantage of taking into account the full probability distribution, for example the Shannon entropy. We show how the ECE approach can be extended from assessing confidence calibration to assessing the calibration of any metric of variation. We present numerical examples upon synthetic predictions which are perfectly calibrated by design, demonstrating that, in this scenario, the VCE has the desired property of approaching zero as the number of data samples increases, in contrast to another entropy-based calibration metric (the UCE) which has been proposed in the literature.

</details>


### [107] [Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling](https://arxiv.org/abs/2602.12976)
*Jin Li,Kleanthis Malialis,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.LG

TL;DR: 提出VAE++ESDD方法，结合增量学习和两级集成（VAE集成用于异常检测，概念漂移检测器集成），在非平稳环境下处理低异常率数据流，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在数字世界中，大量流数据通常无标签，难以检测异常，特别是在非平稳环境中概念漂移会导致模型性能随时间下降。需要处理低异常率数据流中的异常检测问题。

Method: VAE++ESDD方法：采用增量学习和两级集成策略。第一级是变分自编码器(VAE)集成用于异常预测，第二级是概念漂移检测器集成，每个检测器使用基于统计的概念漂移机制。

Result: 在具有极低异常率和各种漂移特性的真实世界和合成数据集上进行综合实验，结果显示该方法显著优于强基线和最先进的方法。

Conclusion: VAE++ESDD方法通过增量学习和两级集成策略，有效解决了非平稳环境下低异常率数据流的异常检测问题，在性能上取得了显著提升。

Abstract: In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.

</details>


### [108] [Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences](https://arxiv.org/abs/2602.13004)
*Ayush Mohanty,Nazal Mohamed,Nagi Gebraeel*

Main category: cs.LG

TL;DR: 该论文提出了首个在联邦格兰杰因果分析中量化不确定性的方法，系统分类了不确定性来源，推导了闭式递归公式，并证明了收敛条件，显著提升了联邦因果推断的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦格兰杰因果分析算法仅提供确定性的因果关系点估计，忽略了不确定性量化。在分布式基础设施应用中，数据主权约束下的高维数据需要更可靠的不确定性评估方法。

Method: 系统分类不确定性来源（数据噪声的偶然不确定性和模型变异的认知不确定性），推导闭式递归公式模拟客户端-服务器交互中的不确定性传播，识别四种新颖的交叉协方差分量，定义严格的收敛条件并获取稳态方差。

Result: 收敛分析表明稳态方差仅依赖于客户端数据统计特性，消除了对初始认知先验的依赖，增强了鲁棒性。在合成基准和真实工业数据集上的实证评估显示，显式表征不确定性显著提升了联邦因果推断的可靠性和可解释性。

Conclusion: 该研究建立了首个在联邦格兰杰因果框架中严格量化不确定性的方法论，通过系统的不确定性分类和传播建模，为分布式因果推断提供了更可靠和可解释的工具。

Abstract: Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty constraints. However, Federated GC algorithms only yield deterministic point estimates of causality and neglect uncertainty. This paper establishes the first methodology for rigorously quantifying uncertainty and its propagation within federated GC frameworks. We systematically classify sources of uncertainty, explicitly differentiating aleatoric (data noise) from epistemic (model variability) effects. We derive closed-form recursions that model the evolution of uncertainty through client-server interactions and identify four novel cross-covariance components that couple data uncertainties with model parameter uncertainties across the federated architecture. We also define rigorous convergence conditions for these uncertainty recursions and obtain explicit steady-state variances for both server and client model parameters. Our convergence analysis demonstrates that steady-state variances depend exclusively on client data statistics, thus eliminating dependence on initial epistemic priors and enhancing robustness. Empirical evaluations on synthetic benchmarks and real-world industrial datasets demonstrate that explicitly characterizing uncertainty significantly improves the reliability and interpretability of federated causal inference.

</details>


### [109] [Probabilistic Wind Power Forecasting with Tree-Based Machine Learning and Weather Ensembles](https://arxiv.org/abs/2602.13010)
*Max Bruninx,Diederik van Binsbergen,Timothy Verstraeten,Ann Nowé,Jan Helsen*

Main category: cs.LG

TL;DR: 本文比较了三种概率预测方法（保形分位数回归、自然梯度提升和条件扩散模型）在风电功率预测中的表现，发现条件扩散模型在概率和点预测方面表现最佳，机器学习方法相比传统工程方法将MAE提升了33-53%。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源在电网中占比增加，准确的风电功率预测对于电网稳定运行至关重要。本文旨在通过集成天气预报和先进的机器学习方法，提高风电功率预测的准确性和可靠性。

Method: 使用梯度提升树结合天气预报集成进行风电功率预测，比较了三种概率预测方法：保形分位数回归、自然梯度提升和条件扩散模型。同时将点预测结果与基于功率曲线和校准尾流模型的确定性工程方法进行基准比较。

Result: 机器学习方法相比功率曲线方法将平均绝对误差降低了53%，相比校准尾流模型降低了33%。条件扩散模型在概率预测和点预测方面表现最佳。使用天气预报集成可将点预测准确率提高23%。

Conclusion: 条件扩散模型结合梯度提升树和天气预报集成能够提供最准确的风电功率概率预测，显著优于传统工程方法，为电网运营商提供了更可靠的风电预测工具。

Abstract: Accurate production forecasts are essential to continue facilitating the integration of renewable energy sources into the power grid. This paper illustrates how to obtain probabilistic day-ahead forecasts of wind power generation via gradient boosting trees using an ensemble of weather forecasts. To this end, we perform a comparative analysis across three state-of-the-art probabilistic prediction methods-conformalised quantile regression, natural gradient boosting and conditional diffusion models-all of which can be combined with tree-based machine learning. The methods are validated using four years of data for all wind farms present within the Belgian offshore zone. Additionally, the point forecasts are benchmarked against deterministic engineering methods, using either the power curve or an advanced approach incorporating a calibrated analytical wake model. The experimental results show that the machine learning methods improve the mean absolute error by up to 53% and 33% compared to the power curve and the calibrated wake model. Considering the three probabilistic prediction methods, the conditional diffusion model is found to yield the best overall probabilistic and point estimate of wind power generation. Moreover, the findings suggest that the use of an ensemble of weather forecasts can improve point forecast accuracy by up to 23%.

</details>


### [110] [Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery](https://arxiv.org/abs/2602.13021)
*Jing Xiao,Xinhai Chen,Jiaming Peng,Qinglin Wang,Menghan Jia,Zhiquan Lai,Guangping Yu,Dongsheng Li,Tiejun Li,Jie Liu*

Main category: cs.LG

TL;DR: PG-SR是一个先验引导的符号回归框架，通过三阶段流程和先验约束检查器，避免产生伪方程陷阱，确保发现的方程符合科学原理。


<details>
  <summary>Details</summary>
Motivation: 现有符号回归方法容易陷入"伪方程陷阱"——产生的方程虽然能很好拟合观测数据，但与基本科学原理不一致。主要原因是这些方法过度依赖经验风险最小化，缺乏确保科学一致性的显式约束。

Method: 提出PG-SR框架，包含三个阶段：预热、进化和精炼。在整个流程中引入先验约束检查器，将领域先验编码为可执行的约束程序。在进化阶段采用先验退火约束评估机制，逐步引导发现过程朝向科学一致的区域。

Result: 理论上证明PG-SR降低了假设空间的Rademacher复杂度，获得更紧的泛化边界，建立了对抗伪方程的保证。实验上，PG-SR在多个领域超越了最先进的基线方法，对先验质量变化、噪声数据和数据稀缺性保持鲁棒性。

Conclusion: PG-SR通过显式编码领域先验作为约束，有效解决了符号回归中的伪方程问题，能够发现既拟合数据又符合科学原理的可解释方程。

Abstract: Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.

</details>


### [111] [Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL](https://arxiv.org/abs/2602.13035)
*Yixiao Zhou,Yang Li,Dongzhou Cheng,Hehe Fan,Yu Cheng*

Main category: cs.LG

TL;DR: 提出Introspective LLM框架，通过分层强化学习让LLM在生成过程中学习控制采样温度，实现探索-利用平衡的动态调节，在数学推理任务上优于固定温度方法。


<details>
  <summary>Details</summary>
Motivation: 在RLVR训练中，解码策略是学习的核心组件而非纯推理时选择。现有方法依赖静态温度值或启发式调整，与任务级奖励解耦，无法根据生成过程中的不确定性动态调节探索-利用平衡。

Method: 提出分层强化学习框架Introspective LLM：在每个解码步骤，模型基于隐藏状态选择温度，从相应分布中采样下一个token。采用坐标上升方案联合优化温度策略和token策略，从下游奖励中学习。

Result: 在数学推理基准测试中，学习到的温度策略优于固定温度和启发式基线方法，同时展现出与推理不确定性对齐的可解释探索行为。

Conclusion: 采样温度应作为可学习的策略参数而非固定超参数，动态温度控制能提升LLM在强化学习中的性能，学习到的温度策略具有可解释性并与推理过程的不确定性相关。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) trains large language models (LLMs) from sampled trajectories, making decoding strategy a core component of learning rather than a purely inference-time choice. Sampling temperature directly controls the exploration--exploitation trade-off by modulating policy entropy, yet existing methods rely on static values or heuristic adaptations that are decoupled from task-level rewards. We propose Introspective LLM, a hierarchical reinforcement learning framework that learns to control sampling temperature during generation. At each decoding step, the model selects a temperature based on its hidden state and samples the next token from the resulting distribution. Temperature and token policies are jointly optimized from downstream rewards using a coordinate ascent scheme. Experiments on mathematical reasoning benchmarks show that learned temperature policies outperform fixed and heuristic baselines, while exhibiting interpretable exploration behaviors aligned with reasoning uncertainty.

</details>


### [112] [Geometric Manifold Rectification for Imbalanced Learning](https://arxiv.org/abs/2602.13045)
*Xubin Wang,Qing Li,Weijia Jia*

Main category: cs.LG

TL;DR: 提出GMR框架，通过几何流形校正处理不平衡分类问题，使用几何置信度估计和非对称清理策略，在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 不平衡分类在机器学习中是一个严峻挑战，特别是当表格数据集存在噪声和重叠类别边界时。从几何角度看，核心困难在于多数类拓扑侵入少数类流形，模糊了真正的决策边界。传统欠采样技术如ENN使用对称清理规则和统一投票，无法捕捉局部流形结构，常常无意中移除信息丰富的少数类样本。

Method: 提出GMR（几何流形校正）框架，包含两个核心贡献：1）几何置信度估计，使用逆距离加权kNN投票和自适应距离度量来捕捉局部可靠性；2）非对称清理，对多数类样本严格清理，同时通过设置少数类移除上限保守保护少数类样本。

Result: 在多个基准数据集上的广泛实验表明，GMR与强大的采样基线方法相比具有竞争力。

Conclusion: GMR框架通过利用局部几何先验，能够鲁棒地处理不平衡结构化数据，有效解决传统方法在捕捉局部流形结构和保护信息丰富少数类样本方面的不足。

Abstract: Imbalanced classification presents a formidable challenge in machine learning, particularly when tabular datasets are plagued by noise and overlapping class boundaries. From a geometric perspective, the core difficulty lies in the topological intrusion of the majority class into the minority manifold, which obscures the true decision boundary. Traditional undersampling techniques, such as Edited Nearest Neighbours (ENN), typically employ symmetric cleaning rules and uniform voting, failing to capture the local manifold structure and often inadvertently removing informative minority samples. In this paper, we propose GMR (Geometric Manifold Rectification), a novel framework designed to robustly handle imbalanced structured data by exploiting local geometric priors. GMR makes two contributions: (1) Geometric confidence estimation that uses inverse-distance weighted kNN voting with an adaptive distance metric to capture local reliability; and (2) asymmetric cleaning that is strict on majority samples while conservatively protecting minority samples via a safe-guarding cap on minority removal. Extensive experiments on multiple benchmark datasets show that GMR is competitive with strong sampling baselines.

</details>


### [113] [TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios](https://arxiv.org/abs/2602.13040)
*Wentao Xu,Zhongming Yao,Weihao Li,Zhenghang Song,Yumeng Song,Tianyi Li,Yushuai Li*

Main category: cs.LG

TL;DR: 提出TCRL框架，通过时间耦合对抗训练增强约束强化学习在时序扰动下的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒约束强化学习方法主要关注单步扰动和时序独立的对抗模型，缺乏对时间耦合扰动的显式建模，而时序耦合扰动在实际安全关键领域（如自动驾驶、机器人、电网管理）中更为常见

Method: 1. 引入最坏情况感知成本约束函数，无需显式建模对抗攻击者即可估计时间耦合扰动下的安全成本；2. 建立奖励上的双重约束防御机制，对抗时间耦合对手同时保持奖励不可预测性

Result: 实验结果表明，TCRL在各种约束强化学习任务中，对时间耦合扰动攻击的鲁棒性持续优于现有方法

Conclusion: TCRL框架有效解决了约束强化学习中时间耦合扰动的鲁棒性问题，为安全关键领域的实际应用提供了更可靠的解决方案

Abstract: Constrained Reinforcement Learning (CRL) aims to optimize decision-making policies under constraint conditions, making it highly applicable to safety-critical domains such as autonomous driving, robotics, and power grid management. However, existing robust CRL approaches predominantly focus on single-step perturbations and temporally independent adversarial models, lacking explicit modeling of robustness against temporally coupled perturbations. To tackle these challenges, we propose TCRL, a novel temporal-coupled adversarial training framework for robust constrained reinforcement learning (TCRL) in worst-case scenarios. First, TCRL introduces a worst-case-perceived cost constraint function that estimates safety costs under temporally coupled perturbations without the need to explicitly model adversarial attackers. Second, TCRL establishes a dual-constraint defense mechanism on the reward to counter temporally coupled adversaries while maintaining reward unpredictability. Experimental results demonstrate that TCRL consistently outperforms existing methods in terms of robustness against temporally coupled perturbation attacks across a variety of CRL tasks.

</details>


### [114] [Diverging Flows: Detecting Extrapolations in Conditional Generation](https://arxiv.org/abs/2602.13061)
*Constantinos Tsakonas,Serena Ivaldi,Jean-Baptiste Mouret*

Main category: cs.LG

TL;DR: 提出Diverging Flows方法，解决Flow Matching模型在安全关键场景中的外推检测问题，使单一模型能同时进行条件生成和外推检测


<details>
  <summary>Details</summary>
Motivation: Flow Matching在复杂条件分布建模方面表现出色，但在安全关键部署中存在严重的外推风险：由于平滑性偏差，流模型即使对于流形外的输入也会产生看似合理的输出，导致难以区分的静默故障

Method: 引入Diverging Flows方法，通过结构性地强制对离流形输入进行低效传输，使单一模型能同时执行条件生成和原生外推检测

Result: 在合成流形、跨域风格迁移和天气温度预测任务上评估，证明该方法能有效检测外推，同时不损害预测保真度或推理延迟

Conclusion: Diverging Flows为可信赖的流模型提供了稳健解决方案，为医学、机器人和气候科学等领域的可靠部署铺平了道路

Abstract: The ability of Flow Matching (FM) to model complex conditional distributions has established it as the state-of-the-art for prediction tasks (e.g., robotics, weather forecasting). However, deployment in safety-critical settings is hindered by a critical extrapolation hazard: driven by smoothness biases, flow models yield plausible outputs even for off-manifold conditions, resulting in silent failures indistinguishable from valid predictions. In this work, we introduce Diverging Flows, a novel approach that enables a single model to simultaneously perform conditional generation and native extrapolation detection by structurally enforcing inefficient transport for off-manifold inputs. We evaluate our method on synthetic manifolds, cross-domain style transfer, and weather temperature forecasting, demonstrating that it achieves effective detection of extrapolations without compromising predictive fidelity or inference latency. These results establish Diverging Flows as a robust solution for trustworthy flow models, paving the way for reliable deployment in domains such as medicine, robotics, and climate science.

</details>


### [115] [GPTZero: Robust Detection of LLM-Generated Texts](https://arxiv.org/abs/2602.13042)
*George Alexandru Adam,Alexander Cui,Edwin Thomas,Emily Napier,Nazar Shmatko,Jacob Schnell,Jacob Junqi Tian,Alekhya Dronavalli,Edward Tian,Dongwon Lee*

Main category: cs.LG

TL;DR: GPTZero是一个先进的工业级AI检测解决方案，用于区分人类撰写和AI生成的文本，通过分层多任务架构实现高精度检测，并具有对抗攻击鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的出现，区分人类撰写和AI生成文本成为新挑战，这涉及到技能评估被削弱、低质量内容大规模生产以及虚假信息传播等问题。

Method: 采用分层多任务架构，支持灵活的人类与AI文本分类体系；通过多层自动化红队测试实现对抗攻击和改写的鲁棒性。

Result: 在多个领域实现最先进的检测精度，提供细粒度预测；相比现有方法具有更强的对抗攻击和改写鲁棒性。

Conclusion: GPTZero提供准确且可解释的检测，教育用户负责任地使用，确保文本评估的公平性和透明度，是解决AI生成文本检测挑战的有效工业解决方案。

Abstract: While historical considerations surrounding text authenticity revolved primarily around plagiarism, the advent of large language models (LLMs) has introduced a new challenge: distinguishing human-authored from AI-generated text. This shift raises significant concerns, including the undermining of skill evaluations, the mass-production of low-quality content, and the proliferation of misinformation. Addressing these issues, we introduce GPTZero a state-of-the-art industrial AI detection solution, offering reliable discernment between human and LLM-generated text. Our key contributions include: introducing a hierarchical, multi-task architecture enabling a flexible taxonomy of human and AI texts, demonstrating state-of-the-art accuracy on a variety of domains with granular predictions, and achieving superior robustness to adversarial attacks and paraphrasing via multi-tiered automated red teaming. GPTZero offers accurate and explainable detection, and educates users on its responsible use, ensuring fair and transparent assessment of text.

</details>


### [116] [Bus-Conditioned Zero-Shot Trajectory Generation via Task Arithmetic](https://arxiv.org/abs/2602.13071)
*Shuai Liu,Ning Cao,Yile Chen,Yue Jiang,Gao Cong*

Main category: cs.LG

TL;DR: 提出MobTA方法，在零样本条件下仅使用源城市轨迹数据和两城市的公交时刻表，就能为目标城市生成移动轨迹，无需目标城市的真实移动数据。


<details>
  <summary>Details</summary>
Motivation: 移动轨迹数据对智慧城市应用至关重要，但获取困难。现有轨迹生成方法通常需要目标城市的真实移动数据，这在数据不可访问的场景中限制了应用。需要解决在完全没有目标城市移动数据情况下的轨迹生成问题。

Method: 提出MobTA方法，首次将任务算术引入轨迹生成。首先在源城市建模基于公交时刻表的轨迹生成到移动轨迹生成的参数偏移，然后将这个偏移通过任务向量的算术运算应用到目标城市，实现反映目标城市移动模式的轨迹生成。

Result: 大量实验表明，MobTA显著优于现有方法，其性能接近使用目标城市移动轨迹进行微调的模型。同时，论文还从理论上分析了MobTA在基础LLM和指令调优LLM上的稳定性。

Conclusion: MobTA解决了公交条件零样本轨迹生成问题，能够在没有目标城市移动数据的情况下生成高质量的移动轨迹，为数据不可访问场景提供了有效的解决方案。

Abstract: Mobility trajectory data provide essential support for smart city applications. However, such data are often difficult to obtain. Meanwhile, most existing trajectory generation methods implicitly assume that at least a subset of real mobility data from target city is available, which limits their applicability in data-inaccessible scenarios. In this work, we propose a new problem setting, called bus-conditioned zero-shot trajectory generation, where no mobility trajectories from a target city are accessible. The generation process relies solely on source city mobility data and publicly available bus timetables from both cities. Under this setting, we propose MobTA, the first approach to introduce task arithmetic into trajectory generation. MobTA models the parameter shift from bus-timetable-based trajectory generation to mobility trajectory generation in source city, and applies this shift to target city through arithmetic operations on task vectors. This enables trajectory generation that reflects target-city mobility patterns without requiring any real mobility data from it. Furthermore, we theoretically analyze MobTA's stability across base and instruction-tuned LLMs. Extensive experiments show that MobTA significantly outperforms existing methods, and achieves performance close to models finetuned using target city mobility trajectories.

</details>


### [117] [EXCODER: EXplainable Classification Of DiscretE time series Representations](https://arxiv.org/abs/2602.13087)
*Yannik Hahn,Antonin Königsfeld,Hasan Tercan,Tobias Meisen*

Main category: cs.LG

TL;DR: 该研究探讨了将时间序列转换为离散潜在表示（如VQ-VAE和DVAE）是否能增强可解释性，提出SSA指标评估XAI识别的特征与训练数据标签分布的对应关系，发现离散表示能提供更紧凑、可解释且计算高效的XAI解释。


<details>
  <summary>Details</summary>
Motivation: 深度学习在时间序列分类中表现优异，但模型缺乏可解释性是一个主要挑战。现有的可解释AI（XAI）技术在处理原始时间序列数据时，常因高维度和噪声问题而效果受限。研究者希望探索通过离散潜在表示是否能增强XAI的解释能力。

Method: 使用向量量化变分自编码器（VQ-VAE）和离散变分自编码器（DVAE）将时间序列转换为离散潜在表示。在这些压缩表示上应用XAI方法，并提出新的评估指标——相似子序列准确率（SSA），用于量化评估XAI识别的显著子序列与训练数据标签分布的对齐程度。

Result: 研究发现，在离散潜在表示上应用XAI方法能产生简洁且结构化的解释，同时保持分类性能。SSA指标能系统验证XAI方法识别的特征是否真正代表了学习到的分类模式。离散表示不仅保留了分类所需的基本特征，还为时间序列分析提供了更紧凑、可解释且计算高效的XAI解释路径。

Conclusion: 时间序列的离散潜在表示不仅能有效保持分类性能，还能显著增强XAI的解释能力。通过减少冗余和聚焦于最信息丰富的模式，离散表示提供了更紧凑、可解释且计算高效的XAI解释框架，为时间序列分析的可解释性研究开辟了新途径。

Abstract: Deep learning has significantly improved time series classification, yet the lack of explainability in these models remains a major challenge. While Explainable AI (XAI) techniques aim to make model decisions more transparent, their effectiveness is often hindered by the high dimensionality and noise present in raw time series data. In this work, we investigate whether transforming time series into discrete latent representations-using methods such as Vector Quantized Variational Autoencoders (VQ-VAE) and Discrete Variational Autoencoders (DVAE)-not only preserves but enhances explainability by reducing redundancy and focusing on the most informative patterns. We show that applying XAI methods to these compressed representations leads to concise and structured explanations that maintain faithfulness without sacrificing classification performance. Additionally, we propose Similar Subsequence Accuracy (SSA), a novel metric that quantitatively assesses the alignment between XAI-identified salient subsequences and the label distribution in the training data. SSA provides a systematic way to validate whether the features highlighted by XAI methods are truly representative of the learned classification patterns. Our findings demonstrate that discrete latent representations not only retain the essential characteristics needed for classification but also offer a pathway to more compact, interpretable, and computationally efficient explanations in time series analysis.

</details>


### [118] [Quantization-Aware Collaborative Inference for Large Embodied AI Models](https://arxiv.org/abs/2602.13052)
*Zhonghao Lyu,Ming Xiao,Mikael Skoglund,Merouane Debbah,H. Vincent Poor*

Main category: cs.LG

TL;DR: 该论文研究了面向具身AI系统的量化感知协同推理方法，通过量化率-推理失真函数分析和联合优化设计，在延迟和能量约束下平衡推理质量、延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 大型人工智能模型（LAIMs）作为具身AI应用的核心智能引擎，其庞大的参数规模和计算需求对资源受限的具身智能体构成重大挑战，需要解决量化感知协同推理问题。

Method: 首先开发了量化诱导推理失真的可处理近似方法，基于此推导了量化率-推理失真函数的上下界；然后提出了在延迟和能量约束下的联合量化比特宽度和计算频率设计问题，通过最小化失真上界同时确保下界紧致性来实现优化。

Result: 广泛的评估验证了所提出的失真近似方法、推导的率失真界以及联合设计的有效性。仿真和真实世界测试床实验表明，所提出的联合设计在边缘具身AI系统中能有效平衡推理质量、延迟和能耗。

Conclusion: 该研究为资源受限的具身AI系统提供了一种有效的量化感知协同推理框架，通过理论分析和联合优化设计，实现了在严格约束下的高效推理性能平衡。

Abstract: Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significant challenges for resource-limited embodied agents. To address this issue, we investigate quantization-aware collaborative inference (co-inference) for embodied AI systems. First, we develop a tractable approximation for quantization-induced inference distortion. Based on this approximation, we derive lower and upper bounds on the quantization rate-inference distortion function, characterizing its dependence on LAIM statistics, including the quantization bit-width. Next, we formulate a joint quantization bit-width and computation frequency design problem under delay and energy constraints, aiming to minimize the distortion upper bound while ensuring tightness through the corresponding lower bound. Extensive evaluations validate the proposed distortion approximation, the derived rate-distortion bounds, and the effectiveness of the proposed joint design. Particularly, simulations and real-world testbed experiments demonstrate the effectiveness of the proposed joint design in balancing inference quality, latency, and energy consumption in edge embodied AI systems.

</details>


### [119] [Backdoor Attacks on Contrastive Continual Learning for IoT Systems](https://arxiv.org/abs/2602.13062)
*Alfous Tim,Kuniyilh Simi D*

Main category: cs.LG

TL;DR: 本文分析了物联网系统中对比持续学习面临的后门攻击安全漏洞，探讨了攻击机制、持久性威胁及防御策略。


<details>
  <summary>Details</summary>
Motivation: 物联网系统日益依赖持续学习来适应非平稳环境，但对比持续学习结合对比表示学习和增量适应时，其几何特性与回放机制可能引入新的安全漏洞，特别是后门攻击可能利用嵌入对齐和回放强化植入持久恶意行为。

Method: 形式化嵌入级攻击目标，分析物联网部署中独特的持久性机制，开发针对物联网的分层分类法，比较不同学习范式的漏洞，并在物联网约束条件下评估防御策略。

Result: 研究发现对比持续学习虽然能增强物联网自适应智能，但如果不充分保护，可能会增加长期存在的表示级威胁。

Conclusion: 对比持续学习在物联网系统中具有增强自适应智能的潜力，但需要针对其特有的安全漏洞（特别是后门攻击）开发专门的防御机制，以确保在资源受限的物联网环境中的安全性。

Abstract: The Internet of Things (IoT) systems increasingly depend on continual learning to adapt to non-stationary environments. These environments can include factors such as sensor drift, changing user behavior, device aging, and adversarial dynamics. Contrastive continual learning (CCL) combines contrastive representation learning with incremental adaptation, enabling robust feature reuse across tasks and domains. However, the geometric nature of contrastive objectives, when paired with replay-based rehearsal and stability-preserving regularization, introduces new security vulnerabilities. Notably, backdoor attacks can exploit embedding alignment and replay reinforcement, enabling the implantation of persistent malicious behaviors that endure through updates and deployment cycles. This paper provides a comprehensive analysis of backdoor attacks on CCL within IoT systems. We formalize the objectives of embedding-level attacks, examine persistence mechanisms unique to IoT deployments, and develop a layered taxonomy tailored to IoT. Additionally, we compare vulnerabilities across various learning paradigms and evaluate defense strategies under IoT constraints, including limited memory, edge computing, and federated aggregation. Our findings indicate that while CCL is effective for enhancing adaptive IoT intelligence, it may also elevate long-lived representation-level threats if not adequately secured.

</details>


### [120] [Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13069)
*Juneyoung Park,Yuri Hong,Seongwan Kim,Jaeho Lee*

Main category: cs.LG

TL;DR: MeSP是一种内存高效的结构化反向传播方法，通过利用LoRA的低秩结构手动推导反向传播，在移动设备上实现隐私保护的LLM微调，相比传统方法减少49%内存使用。


<details>
  <summary>Details</summary>
Motivation: 移动设备内存有限（6-12GB），现有方法在精确梯度（高内存）和噪声估计（低内存）之间需要权衡，无法在内存受限设备上实现高效的隐私保护微调。

Method: 提出Memory-efficient Structured Backpropagation (MeSP)，利用LoRA的低秩结构手动推导反向传播，通过重新计算中间投影h=xA（因为r<<din），消除存储需求，实现内存优化。

Result: 在Qwen2.5模型（0.5B-3B）上，MeSP相比MeBP平均减少49%内存使用，同时计算数学上完全相同的梯度。对于Qwen2.5-0.5B，峰值内存从361MB降至136MB。

Conclusion: MeSP在移动设备上实现了内存高效的精确梯度计算，解决了现有方法的权衡问题，使之前不可行的微调场景成为可能，同时揭示了MeZO梯度估计与真实梯度相关性极低的问题。

Abstract: On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact gradients with high memory (MeBP) and low memory with noisy estimates (MeZO). We propose Memory-efficient Structured Backpropagation (MeSP), which bridges this gap by manually deriving backward passes that exploit LoRA's low-rank structure. Our key insight is that the intermediate projection $h = xA$ can be recomputed during backward at minimal cost since rank $r \ll d_{in}$, eliminating the need to store it. MeSP achieves 49\% average memory reduction compared to MeBP on Qwen2.5 models (0.5B--3B) while computing mathematically identical gradients. Our analysis also reveals that MeZO's gradient estimates show near-zero correlation with true gradients (cosine similarity $\approx$0.001), explaining its slow convergence. MeSP reduces peak memory from 361MB to 136MB for Qwen2.5-0.5B, enabling fine-tuning scenarios previously infeasible on memory-constrained devices.

</details>


### [121] [LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13073)
*Juneyoung Park,Eunbeen Yoon,Seongwan Kim. Jaeho Lee*

Main category: cs.LG

TL;DR: LCSB是一种内存高效的反向传播方法，通过每步仅计算部分层的梯度来加速LLM微调，利用残差连接和AdamW动量实现收敛，在保持质量的同时获得1.4倍加速，并在量化设置中表现出更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的内存高效反向传播(MeBP)方法虽然能在移动设备上微调大语言模型，但需要在每一步对所有transformer层进行反向计算，其中权重解压缩就占用了32-42%的反向传播时间。这限制了微调效率，需要更高效的梯度计算方法。

Method: 提出层循环选择性反向传播(LCSB)，每步只计算部分层的梯度。关键洞察是：残差连接保证了通过恒等路径的梯度流动，而AdamW动量则为未选中的层提供了隐式更新。该方法被解释为LoRA参数空间上的块坐标下降，提供了理论收敛保证。

Result: LCSB在五个模型和三个任务上实现了高达1.4倍的加速，质量下降小于2%。在4位量化设置中表现出更好的稳定性：一个3B模型在完全反向传播下完全发散，但在LCSB下能平滑收敛，表明选择性梯度计算具有隐式正则化效果。

Conclusion: LCSB通过选择性层梯度计算显著提高了内存高效反向传播的效率，不仅加速了微调过程，还在量化设置中提供了更好的训练稳定性，为大语言模型在资源受限设备上的高效微调提供了实用解决方案。

Abstract: Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where weight decompression alone accounts for 32--42% of backward time. We propose Layer-Cyclic Selective Backpropagation (LCSB), which computes gradients for only a subset of layers per step. Our key insight is that residual connections guarantee gradient flow through identity paths, while AdamW momentum provides implicit updates for non-selected layers. We interpret LCSB as Block Coordinate Descent on the LoRA parameter space, providing theoretical justification for convergence. LCSB achieves up to 1.40$\times$ speedup with less than 2\% quality degradation across five models and three tasks. Surprisingly, in 4-bit quantized settings, LCSB exhibits superior stability: a 3B model that completely diverges under full backpropagation converges smoothly with LCSB, suggesting an implicit regularization effect from selective gradient computation.

</details>


### [122] [Unified Multi-Domain Graph Pre-training for Homogeneous and Heterogeneous Graphs via Domain-Specific Expert Encoding](https://arxiv.org/abs/2602.13075)
*Chundong Liang,Yongqi Huang,Dongxiao He,Peiyuan Li,Yawen Li,Di Jin,Weixiong Zhang*

Main category: cs.LG

TL;DR: GPH²：一种统一的多领域图预训练方法，同时处理同质图和异质图，通过统一编码器和专家融合策略实现跨图类型的稳定迁移学习。


<details>
  <summary>Details</summary>
Motivation: 现有图预训练方法主要针对单一图类型（同质或异质图），而现实应用中混合图普遍存在，且上游预训练与下游部署之间存在分布偏移问题，需要统一的跨图类型建模方法。

Method: 提出统一多视图图构建方法，同时编码同质和异质图；引入领域特定专家编码，每个专家在单一图上独立预训练以捕获领域知识；设计面向任务的专家融合策略，自适应整合多个专家。

Result: 在混合图上的大量实验表明，GPH²能够实现跨图类型和领域的稳定迁移，显著优于现有图预训练方法。

Conclusion: GPH²通过统一的多领域预训练框架，有效解决了混合图建模和跨域分布偏移问题，为图表示学习提供了更通用的解决方案。

Abstract: Graph pre-training has achieved remarkable success in recent years, delivering transferable representations for downstream adaptation. However, most existing methods are designed for either homogeneous or heterogeneous graphs, thereby hindering unified graph modeling across diverse graph types. This separation contradicts real-world applications, where mixed homogeneous and heterogeneous graphs are ubiquitous, and distribution shifts between upstream pre-training and downstream deployment are common. In this paper, we empirically demonstrate that a balanced mixture of homogeneous and heterogeneous graph pre-training benefits downstream tasks and propose a unified multi-domain \textbf{G}raph \textbf{P}re-training method across \textbf{H}omogeneous and \textbf{H}eterogeneous graphs ($\mathbf{GPH^{2}}$). To address the lack of a unified encoder for homogeneous and heterogeneous graphs, we propose a Unified Multi-View Graph Construction that simultaneously encodes both without explicit graph-type-specific designs. To cope with the increased cross-domain distribution discrepancies arising from mixed graphs, we introduce domain-specific expert encoding. Each expert is independently pre-trained on a single graph to capture domain-specific knowledge, thereby shielding the pre-training encoder from the adverse effects of cross-domain discrepancies. For downstream tasks, we further design a Task-oriented Expert Fusion Strategy that adaptively integrates multiple experts based on their discriminative strengths. Extensive experiments on mixed graphs demonstrate that $\text{GPH}^{2}$ enables stable transfer across graph types and domains, significantly outperforming existing graph pre-training methods.

</details>


### [123] [R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training](https://arxiv.org/abs/2602.13103)
*Gengsheng Li,Jinghan He,Shijie Wang,Dan Zhang,Ruiqi Liu,Renrui Zhang,Zijun Yao,Junfeng Fang,Haiyun Guo,Jinqiao Wang*

Main category: cs.LG

TL;DR: 论文提出R-Diverse方法解决自博弈训练中的多样性幻觉问题，通过记忆增强惩罚和技能感知测量来维持持续改进


<details>
  <summary>Details</summary>
Motivation: 现有自博弈框架如R-Zero存在非持续改进问题，早期增益会随着自博弈继续而退化。研究发现关键失败模式是多样性幻觉，即求解器的训练信号看似多样但实际上崩溃为重复的底层模式。

Method: 提出R-Diverse方法，包含两个创新：1) 记忆增强惩罚(MAP)，使用持久记忆库来阻止跨迭代的循环；2) 技能感知测量(SAM)，通过评估所运用的推理技能而非问题的表面变化来衡量多样性。

Result: 在10个数学和通用推理基准测试中，R-Diverse能够在更多迭代中维持增益，并持续优于先前的自博弈方法。

Conclusion: R-Diverse通过解决多样性幻觉问题，实现了自博弈训练中更持续和稳定的改进，为LLM推理能力的提升提供了有效框架。

Abstract: Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhibit non-sustained improvement, where early gains degrade as self-play continues. We identify a key failure mode, Diversity Illusion, where the Solver's training signals appear diverse yet collapse into recurring underlying patterns. It manifests as (1) Local Diversity Illusion, where diversity is enforced only within-batch, inducing cross-iteration mode cycling; and (2) Surface Diversity Illusion, where questions vary superficially but require near-identical reasoning skills. To mitigate them, we propose R-Diverse with two aligned innovations: Memory-Augmented Penalty (MAP), which uses a persistent memory bank to discourage recycling across iterations, and Skill-Aware Measurement (SAM), which evaluates diversity by the reasoning skills exercised rather than surface variation of questions. Across 10 math and general reasoning benchmarks, R-Diverse sustains gains over more iterations and consistently outperforms prior self-play methods. Code is available at https://github.com/Gengsheng-Li/R-Diverse.

</details>


### [124] [Quantization-Robust LLM Unlearning via Low-Rank Adaptation](https://arxiv.org/abs/2602.13151)
*João Vitor Boer Abitante,Joana Meneguzzo Pasquali,Luan Fonseca Garcia,Ewerton de Oliveira,Thomas da Silva Paula,Rodrigo C. Barros,Lucas S. Kupssinskü*

Main category: cs.LG

TL;DR: LoRA适配器方法提升大语言模型遗忘学习在4位量化后的效果，解决传统全参数微调在低比特量化下遗忘更新被掩盖的问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型遗忘学习后通常需要进行后训练量化以实现高效推理，但激进的低比特量化会掩盖或擦除遗忘学习的更新，导致量化后的模型恢复为遗忘前的行为

Method: 提出基于低秩适配器(LoRA)的量化鲁棒遗忘学习方法：冻结基础模型，将遗忘学习集中在可训练的适配器中，确保有效更新在量化后得以保留

Result: 在Llama-2-7B模型和MUSE数据集上，LoRA方法将4位量化的效用提升高达7.93分，显著减少4位量化下的隐私泄露，同时保持强大的遗忘效果

Conclusion: 在需要量化部署的场景中，使用LoRA进行机器遗忘学习是有益的，能够确保遗忘更新在低比特量化后仍然有效

Abstract: Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [125] [Eyes on Many: Evaluating Gaze, Hand, and Voice for Multi-Object Selection in Extended Reality](https://arxiv.org/abs/2602.12406)
*Mohammad Raihanul Bashar,Aunnoy K Mutasim,Ken Pfeuffer,Anil Ufuk Batmaz*

Main category: cs.HC

TL;DR: 该研究评估了XR环境中四种模式切换技术和三种子选择技术对多对象选择性能的影响，发现DoublePinch+Gaze+Pinch组合表现最佳，而Voice命令在子选择中因重复性而被认为繁琐。


<details>
  <summary>Details</summary>
Motivation: 在扩展现实(XR)中，同时与多个对象交互能提高效率，而多对象选择是实现这一交互的前提。目前缺乏关于不同模式切换和子选择技术组合如何影响用户性能的实证研究。

Method: 通过用户研究评估了四种模式切换技术（SemiPinch、FullPinch、DoublePinch和Voice）和三种子选择技术（Gaze+Dwell、Gaze+Pinch和Gaze+Voice）的组合效果。

Result: DoublePinch模式切换与Gaze+Pinch子选择组合获得了最高的整体性能，而SemiPinch表现最差。基于语音的模式切换有优势，但Gaze+Voice子选择因需要重复语音命令而被认为繁琐且不受欢迎。

Conclusion: 研究结果为XR中的多选择技术提供了实证见解和设计建议，推荐使用DoublePinch进行模式切换，并结合Gaze+Pinch进行子选择，同时应谨慎使用需要重复语音命令的交互方式。

Abstract: Interacting with multiple objects simultaneously makes us fast. A pre-step to this interaction is to select the objects, i.e., multi-object selection, which is enabled through two steps: (1) toggling multi-selection mode -- mode-switching -- and then (2) selecting all the intended objects -- subselection. In extended reality (XR), each step can be performed with the eyes, hands, and voice. To examine how design choices affect user performance, we evaluated four mode-switching (SemiPinch, FullPinch, DoublePinch, and Voice) and three subselection techniques (Gaze+Dwell, Gaze+Pinch, and Gaze+Voice) in a user study. Results revealed that while DoublePinch paired with Gaze+Pinch yielded the highest overall performance, SemiPinch achieved the lowest performance. Although Voice-based mode-switching showed benefits, Gaze+Voice subselection was less favored, as the required repetitive vocal commands were perceived as tedious. Overall, these findings provide empirical insights and inform design recommendations for multi-selection techniques in XR.

</details>


### [126] [KeySense: LLM-Powered Hands-Down, Ten-Finger Typing on Commodity Touchscreens](https://arxiv.org/abs/2602.12432)
*Tony Li,Yan Ma,Zhuojun Li,Chun Yu,IV Ramakrishnan,Xiaojun Bi*

Main category: cs.HC

TL;DR: KeySense是一个纯软件解决方案，让用户能够在触摸屏上使用十指打字，通过认知-运动时序模式区分有意敲击和手指放置噪音，并用LLM解码器将噪音字母序列转换为目标单词。


<details>
  <summary>Details</summary>
Motivation: 现有触摸屏键盘迫使用户只能使用"鸡啄米"式的单指点击，无法使用熟悉的双手十指打字方式，导致打字速度慢且容易疲劳。

Method: 1) 利用认知-运动时序模式区分有意敲击和手指放置噪音；2) 使用微调的LLM解码器将噪音字母序列转换为目标单词。

Result: 解码器性能优于两个统计基线（top-1准确率84.8% vs 75.7%和79.3%）。12人研究显示：相比传统悬浮式键盘，用户认为KeySense体力负担显著降低（NASA-TLX中位数1.5 vs 4.0），练习后打字速度更快（WPM 28.3 vs 26.2，p<0.01）。

Conclusion: KeySense能够在普通触摸屏上实现准确、高效且舒适的十指文本输入，无需额外硬件，保留了物理键盘的运动技能。

Abstract: Existing touchscreen software keyboards prevent users from resting their hands, forcing slow and fatiguing index-finger tapping ("chicken typing") instead of familiar hands-down ten-finger typing. We present KeySense, a purely software solution that preserves physical keyboard motor skills. KeySense isolates intentional taps from resting-finger noise using cognitive-motor timing patterns, and then uses a fine-tuned LLM decoder to convert the resulting noisy letter sequence into the intended word. In controlled component tests, the decoder substantially outperforms two statistical baselines (top-1 accuracy 84.8% vs 75.7% and 79.3%). A 12-participant study shows clear ergonomic and performance benefits: compared with the conventional hover-style keyboard, users rated KeySense as markedly less physically demanding (NASA-TLX median 1.5 vs 4.0), and after brief practice typed significantly faster (WPM 28.3 vs 26.2, p < 0.01). These results indicate that KeySense enables accurate, efficient, and comfortable ten-finger text entry on commodity touchscreens without any extra hardware.

</details>


### [127] [GatheringSense: AI-Generated Imagery and Embodied Experiences for Understanding Literati Gatherings](https://arxiv.org/abs/2602.12565)
*You Zhou,Bingyuan Wang,Hongcheng Guo,Rui Cao,Zeyu Wang*

Main category: cs.HC

TL;DR: 本文提出AI驱动的双路径文化理解框架GatheringSense，通过混合方法研究比较AI生成内容与具身参与在支持文人雅集理解和促进文化共鸣方面的互补作用。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI在文化应用方面主要强调美学再现，难以传达文化仪式和社会框架的深层含义。文人雅集作为中国传统文化的重要形式，其深度探索仍然不足。

Method: 基于具身认知理论，提出AI驱动的双路径文化理解框架，并通过GatheringSense文人雅集体验进行实例化。采用混合方法研究（N=48），比较AI生成的多模态内容与具身参与如何互补支持文化理解。

Result: AI生成内容有效提升文化符号的可读性和初始情感吸引力，但在物理连贯性和微观可信度方面存在局限。具身体验显著加深参与者对仪式规则和社会角色的理解，增加心理亲近感和临场感。

Conclusion: 研究结果为文化遗产的生成式体验提供了实证证据和五项可转移的设计启示，强调AI生成内容与具身参与的互补价值。

Abstract: Chinese literati gatherings (Wenren Yaji), as a situated form of Chinese traditional culture, remain underexplored in depth. Although generative AI supports powerful multimodal generation, current cultural applications largely emphasize aesthetic reproduction and struggle to convey the deeper meanings of cultural rituals and social frameworks. Based on embodied cognition, we propose an AI-driven dual-path framework for cultural understanding, which we instantiate through GatheringSense, a literati-gathering experience. We conduct a mixed-methods study (N=48) to compare how AI-generated multimodal content and embodied participation complement each other in supporting the understanding of literati gatherings and fostering cultural resonance. Our results show that AI-generated content effectively improves the readability of cultural symbols and initial emotional attraction, yet limitations in physical coherence and micro-level credibility may affect users' satisfaction. In contrast, embodied experience significantly deepens participants' understanding of ritual rules and social roles, and increases their psychological closeness and presence. Based on these findings, we offer empirical evidence and five transferable design implications for generative experience in cultural heritage.

</details>


### [128] [Bonik Somiti: A Social-market Tool for Safe, Accountable, and Harmonious Informal E-Market Ecosystem in Bangladesh](https://arxiv.org/abs/2602.12650)
*ATM Mizanur Rahman,Sharifa Sultana*

Main category: cs.HC

TL;DR: 研究非正式电商市场的欺诈问题，开发Bonik Somiti系统支持结构化报告、管理员调解和问责机制，评估系统效果并讨论社区中心化技术设计


<details>
  <summary>Details</summary>
Motivation: 非正式电商市场中，人们通过社交媒体分享欺诈信息和警告，但这些信息分散、难以验证且很少能解决问题，导致买家和卖家持续面临欺诈和财务损失风险

Method: 通过124名参与者的调查和36名买家、卖家及相关利益相关者的访谈（来自孟加拉国），设计Bonik Somiti系统，该系统支持结构化报告、管理员主导的调解和问责机制，并对32名参与者进行系统评估

Result: 评估揭示了在现有非正式实践及其假设下管理欺诈、解决争议和建立信任的若干挑战，系统在支持结构化报告和调解方面显示出潜力

Conclusion: 基于研究发现，讨论了如何设计社区中心化技术来支持全球南方地区更安全、更具问责性的非正式电商市场，强调了在现有实践基础上构建技术解决方案的重要性

Abstract: People in informal e-markets often try to deal with fraud and financial harm by sharing posts, screenshots, and warnings in social media groups. However, buyers and sellers frequently face further problems because these reports are scattered, hard to verify, and rarely lead to resolution. We studied these issues through a survey with 124 participants and interviews with 36 buyers, sellers, and related stakeholders from Bangladesh and designed Bonik Somiti, a socio-technical system that supports structured reporting, admin-led mediation, and accountability in informal e-markets. Our evaluation with 32 participants revealed several challenges in managing fraud, resolving disputes, and building trust within existing informal practices and the assumptions behind them. Based on these findings, we further discuss how community-centered technologies can be designed to support safer and more accountable informal e-markets in the Global South.

</details>


### [129] [From Guidelines to Practice: Evaluating the Reproducibility of Methods in Computational Social Science](https://arxiv.org/abs/2602.12747)
*Fakhri Momeni,Sarah Sajid,Johannes Kiesel*

Main category: cs.HC

TL;DR: 本研究系统评估了计算社会科学中可重复性的三种条件：无整理文档、整理文档、以及整理文档配合预设执行环境，发现整理文档显著减少错误，标准化执行环境进一步提高可重复性成功率。


<details>
  <summary>Details</summary>
Motivation: 计算社会科学中，复杂的工作流程、不断演变的软件生态系统和不一致的文档阻碍了研究人员重新执行已发表方法的能力，可重复性仍然是一个核心挑战。

Method: 通过47个可用性测试会话，结合行为绩效指标（成功率、任务时间、错误概况）、问卷数据和主题分析，评估三种条件下的可重复性：无整理文档、整理文档、以及整理文档配合预设执行环境。

Result: 整理文档显著减少了存储库级错误，提高了用户解释方法输出的能力；标准化执行环境进一步提高了可重复性，获得了最高的成功率和最短的任务完成时间；参与者经常依赖AI工具进行故障排除。

Conclusion: 可重复性障碍是多层次的，需要在文档质量、环境稳定性和概念清晰度方面进行协调改进，这对计算社会科学中可重复性平台和基础设施的设计具有重要意义。

Abstract: Reproducibility remains a central challenge in computational social science, where complex workflows, evolving software ecosystems, and inconsistent documentation hinder researchers ability to re-execute published methods. This study presents a systematic evaluation of reproducibility across three conditions: uncurated documentation, curated documentation, and curated documentation paired with a preset execution environment. Using 47 usability test sessions, we combine behavioral performance indicators (success rates, task time, and error profiles) with questionnaire data and thematic analysis to identify technical and conceptual barriers to reproducibility.
  Curated documentation substantially reduced repository-level errors and improved users ability to interpret method outputs. Standardizing the execution environment further improved reproducibility, yielding the highest success rate and shortest task completion times. Across conditions, participants frequently relied on AI tools for troubleshooting, often enabling independent resolution of issues without facilitator intervention.
  Our findings demonstrate that reproducibility barriers are multi-layered and require coordinated improvements in documentation quality, environment stability, and conceptual clarity. We discuss implications for the design of reproducibility platforms and infrastructure in computational social science.

</details>


### [130] [SoK: Understanding the Pedagogical, Health, Ethical, and Privacy Challenges of Extended Reality in Early Childhood Education](https://arxiv.org/abs/2602.12749)
*Supriya Khadka,Sanchari Das*

Main category: cs.HC

TL;DR: 该论文对111项针对3-8岁儿童的XR教育研究进行了系统知识梳理，发现AR占主导地位，VR较少使用。研究量化了技术、教学、健康、隐私和公平性等挑战，显示教学法受到最多关注，而数据安全实践被严重忽视。


<details>
  <summary>Details</summary>
Motivation: 扩展现实（XR）在幼儿教育中具有潜力但也存在高风险，需要系统研究其在实际应用中的技术、教学、健康、隐私和公平性挑战，为儿童中心的XR设计提供指导。

Method: 采用系统知识梳理方法，分析111项同行评审研究，使用七维度编码方案（0-2分制）量化评估，并构建联合风险与关注矩阵及增强人类发展模型。

Result: AR占研究主导（73%），主要使用平板或手机；VR较少且依赖头戴显示器。教学法关注度最高（1.56分），数据安全实践最低（0.14分），显示研究关注度严重不平衡。

Conclusion: 提出儿童中心XR路线图，呼吁HCI研究者和教育者超越技术新颖性，设计符合发展需求、默认安全且面向多样化学习者的系统。

Abstract: Extended Reality (XR) combines dense sensing, real-time rendering, and close-range interaction, making its use in early childhood education both promising and high risk. To investigate this, we conduct a Systematization of Knowledge (SoK) of 111 peer-reviewed studies with children aged 3-8, quantifying how technical, pedagogical, health, privacy, and equity challenges arise in practice. We found that AR dominates the landscape (73%), focusing primarily on tablets or phones, while VR remains uncommon and typically relies on head mounted displays (HMDs). We integrate these quantitative patterns into a joint risk and attention matrix and an Augmented Human Development (AHD) model that link XR pipeline properties to cognitive load, sensory conflict, and access inequity. Finally, implementing a seven dimension coding scheme on a 0 - 2 scale, we obtain mean scholarly attention scores of 1.56 for pedagogy, 1.04 for privacy (primarily procedural consent), 0.96 for technical reliability, 0.92 for accessibility in low resource contexts, 0.81 for medical and health issues, 0.52 for accessibility for disabilities, and 0.14 for data security practices. This indicates that pedagogy receives the most systematic scrutiny, while data access practices is largely overlooked. We conclude by offering a roadmap for Child-Centered XR that helps HCI researchers and educators move beyond novelty to design systems that are developmentally aligned, secure by default, and accessible to diverse learners.

</details>


### [131] [Social, Spatial, and Self-Presence as Predictors of Basic Psychological Need Satisfaction in Social Virtual Reality](https://arxiv.org/abs/2602.12764)
*Qijia Chen,Andrea Bellucci,Giulio Jacucci*

Main category: cs.HC

TL;DR: 研究发现社交VR中不同临场感维度对基本心理需求的影响存在差异，且受性别和年龄调节


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探讨数字媒体中的临场感和基本心理需求，但缺乏系统分析不同临场感维度如何映射到自主性、能力感和关联性这三种基本需求，以及人口因素如何调节这些关系

Method: 调查了301名社交VR用户，使用结构方程模型分析数据，检验不同临场感维度（社交临场感、自我临场感、空间临场感）对基本心理需求的影响，并考察性别和年龄的调节作用

Result: 社交临场感预测所有三种需求；自我临场感预测能力感和关联性；空间临场感无直接或调节效应。性别和年龄调节这些关系：女性从社交临场感中获得更多自主性和关联性；男性从自我和空间临场感中获得更多能力感和自主性；年轻用户社交临场感与关联性、自我临场感与自主性之间的关联更强

Conclusion: 临场感作为动机机制受到人口因素的调节，研究结果为设计包容性、支持基本需求的多用户VR环境提供了理论见解和实践启示

Abstract: Extensive research has examined presence and basic psychological needs (drawing on Self-Determination Theory) in digital media. While prior work offers hints of potential connections, we lack a systematic account of whether and how distinct presence dimensions map onto the basic needs of autonomy, competence, and relatedness. We surveyed 301 social VR users and analyzed using Structural Equation Modeling. Results show that social presence predicts all three needs, while self-presence predicts competence and relatedness, and spatial presence shows no direct or moderating effects. Gender and age moderated these relationships: women benefited more from social presence for autonomy and relatedness, men from self- and spatial presence for competence and autonomy, and younger users showed stronger associations between social presence and relatedness, and between self-presence and autonomy. These findings position presence as a motivational mechanism shaped by demographic factors. The results offer theoretical insights and practical implications for designing inclusive, need-supportive multiuser VR environments.

</details>


### [132] [The Configuration of Space: Probing the Way Social Interaction and Perception are Affected by Task-Specific Spatial Representations in Online Video Communication](https://arxiv.org/abs/2602.12771)
*Yihuan Chen,Kexue Fu,Qianyi Chen,Zhicong Lu,Ray LC*

Main category: cs.HC

TL;DR: 研究比较了2D视频聊天中不同空间布局（画廊式vs场景式房间）对社交支持、团队讨论中注意力分配、自我意识、空间参照和情感表达的影响，发现空间配置显著影响在线交流的心理体验。


<details>
  <summary>Details</summary>
Motivation: 人类生活在3D空间但在2D平面上交流，研究旨在探索2D视频聊天中空间配置如何影响能力、社交感知和行为，特别是在社交支持和主题讨论场景中。

Method: 使用Ohyay.co平台，比较两种界面：1）普通画廊式界面；2）场景式房间界面（参与者呈圆形排列）。进行两个实验：社交支持任务和团队辩论任务，分析注意力分配、空间参照、情感表达等指标。

Result: 在房间界面中，参与者更关注整体群体，自我意识更强；在团队辩论中，参与者利用空间参照表达立场，对远处参与者更投入，对近处参与者更有同理心；还观察到躲避聚光灯、观点采择和手势表达的空间效应。

Conclusion: 2D空间配置显著影响在线交流的心理体验，设计协作通信系统时应考虑空间布局以满足特定任务的心理需求。

Abstract: Humans live and act in 3D space, but often work and communicate on 2D surfaces. The prevalence of online communication on 2D screens raises the issue of whether human spatial configuration affects our capabilities, social perception, and behaviors when interacting with others in 2D video chat. How do factors like location, setting, and context subtly shape our online communication, particularly in scenarios such as social support and topic-based discussions? Using Ohyay.co as a platform, we compared a normal gallery interface with a scene-based Room-type interface where participants are located in circular arrangement on screen in a social support task, and found that participants allocated attention to the group as a whole, and had pronounced self-awareness in the Room format. We then chose a two-sided topic for discussion in the Gallery interface and the Room interface where participants on each team face-off against each other, and found that they utilized spatial references to orient their allegiances, expressing greater engagement with those farther away in digital space and greater empathy with those closer, in the Room over the Gallery format. We found spatial effects in the way participants hide from the spotlight, in perspective-taking, and in their use of expressive gestures in time on the screen. This work highlights the need for considering spatial configuration in 2D in the design of collaborative communication systems to optimize for psychological needs for particular tasks.

</details>


### [133] [Usage Matters: The Role of Frequency, Duration, and Experience in Presence Formation in Social Virtual Reality](https://arxiv.org/abs/2602.12775)
*Qijia Chen,Andrea Bellucci,Giulio Jacucci*

Main category: cs.HC

TL;DR: 研究发现社交VR中的使用强度（使用频率、会话时长、VR经验年限）能够预测临场感体验，高频次和长时间使用协同增强"身临其境"感


<details>
  <summary>Details</summary>
Motivation: 临场感是VR沉浸体验的核心，尤其在社交VR中更为突出。虽然已有研究探索了临场感的各个方面，但对于日常使用行为如何塑造临场感知之甚少，特别是在社交VR环境中

Method: 通过对295名社交VR用户进行问卷调查，使用经过验证的量表评估整体临场感、社交临场感、空间临场感和自我临场感，分析使用强度（使用频率、会话时长、VR经验年限）对临场感的预测作用

Result: 使用频率和会话时长在所有临场感维度上都能一致预测更高的临场感，交互效应表明高频次和长时间会话能协同增强"身临其境"体验，这些效应在不同年龄和性别中保持稳定

Conclusion: 研究将临场感研究从实验室扩展到日常使用行为，识别了社交VR中的行为预测因素，为构建能够可靠培养临场感的包容性环境提供了见解

Abstract: The sense of presence is central to immersive experiences in Virtual Reality (VR), and particularly salient in socially rich platforms like social VR. While prior studies have explored various aspects related to presence, less is known about how ongoing usage behaviors shape presence in everyday engagement. To address this gap, we examine whether usage intensity, captured through frequency of use, session duration, and years of VR experience, predicts presence in social VR. A survey of 295 users assessed overall, social, spatial, and self-presence using validated scales. Results show that both frequency and duration consistently predict higher presence across all dimensions, with interaction effects indicating that frequent and extended sessions synergistically amplify the experience of "being there." These effects were stable across age and gender. Our findings extend presence research beyond the laboratory by identifying behavioral predictors in social VR and offer insights for building inclusive environments that reliably foster presence.

</details>


### [134] [iRULER: Intelligible Rubric-Based User-Defined LLM Evaluation for Revision](https://arxiv.org/abs/2602.12779)
*Jingwen Bai,Wei Soon Cheong,Philippe Muller,Brian Y Lim*

Main category: cs.HC

TL;DR: iRULER是一个基于LLM的交互式评分工具，通过结构化评分标准和可操作建议来改进写作反馈质量


<details>
  <summary>Details</summary>
Motivation: 当前LLM提供的写作反馈往往难以理解、过于通用且不符合用户特定标准，需要更结构化和可理解的反馈机制

Method: 设计iRULER系统，遵循特定设计准则：基于具体标准搭建评审框架、为评分选择提供理由、提供针对不同质量水平的可操作修订建议；使用"评分标准之评分标准"方法递归优化用户定义的标准

Result: 在写作修订和评分标准创建的控制实验中，iRULER最能提高经过验证的LLM评审分数，被认为是最有帮助且最符合用户需求的；定性发现进一步支持iRULER满足用户定义反馈的设计准则

Conclusion: 这项工作为基于LLM的可理解写作评审和修订以及用户定义的评分标准创建贡献了交互式评分工具

Abstract: Large Language Models (LLMs) have become indispensable for evaluating writing. However, text feedback they provide is often unintelligible, generic, and not specific to user criteria. Inspired by structured rubrics in education and intelligible AI explanations, we propose iRULER following identified design guidelines to \textit{scaffold} the review process by \textit{specific} criteria, providing \textit{justification} for score selection, and offering \textit{actionable} revisions to target different quality levels. To \textit{qualify} user-defined criteria, we recursively used iRULER with a rubric-of-rubrics to iteratively \textit{refine} rubrics. In controlled experiments on writing revision and rubric creation, iRULER most improved validated LLM-judged review scores and was perceived as most helpful and aligned compared to read-only rubric and text-based LLM feedback. Qualitative findings further support how iRULER satisfies the design guidelines for user-defined feedback. This work contributes interactive rubric tools for intelligible LLM-based review and revision of writing, and user-defined rubric creation.

</details>


### [135] [Media Framing Moderates Risk-Benefit Perceptions and Value Tradeoffs in Human-Robot Collaboration](https://arxiv.org/abs/2602.12785)
*Philipp Brauner,Felix Glawe,Luisa Vervier,Martina Ziefle*

Main category: cs.HC

TL;DR: 研究探讨媒体框架如何调节人机协作风险与收益感知对价值评估的影响，发现负面框架产生更强但相互依赖的效应，正面框架支持累加性评估。


<details>
  <summary>Details</summary>
Motivation: 公众对人机协作的接受度受风险与收益感知影响，媒体框架可能塑造和改变个体评估。需要了解框架如何调节风险与收益感知对整体价值评估的影响，以促进人机协作接受度。

Method: 预注册研究，1150名参与者随机分配阅读正面或负面框架的新闻报道（涉及自主性、就业、安全三个工业情境），使用可靠公开的心理测量量表测量风险、收益和价值感知，通过两个多元回归分析测试主效应和交互效应。

Result: 框架影响风险、收益和价值的绝对评估。两种框架下风险与收益均显著预测价值评估。正面框架仅观察到主效应（风险β=-0.52；收益β=0.45）；负面框架主效应更强（风险β=-0.69；收益β=0.63）且有显著负向交互效应（β=-0.32），表明高风险感知会削弱收益的积极影响。正面框架模型拟合度更高（R²=0.715 vs 0.583）。

Conclusion: 框架塑造人机协作的绝对评估以及风险与收益在权衡中的认知整合方式。负面框架产生更强但相互依赖的效应，正面框架支持累加性评估。研究强调了战略沟通在促进人机协作接受度中的作用，并指出未来研究需要考虑框架效应。

Abstract: Public acceptance of industrial human-robot collaboration (HRC) is shaped by how risks and benefits are perceived by affected employees. Positive or negative media framing may shape and shift how individuals evaluate HRC. This study examines how message framing moderates the effects of perceived risks and perceived benefits on overall attributed value. In a pre-registered study, participants (N = 1150) were randomly assigned to read either a positively or negatively framed newspaper article in one of three industrial contexts (autonomy, employment, safety) about HRC in production. Subsequently, perceived risks, benefits, and value were measured using reliable and publicly available psychometric scales. Two multiple regressions (one per framing condition) tested for main and interaction effects. Framing influenced absolute evaluations of risk, benefits, and value. In both frames, risks and benefits significantly predicted attributed value. Under positive framing, only main effects were observed (risks: beta = -0.52; benefits: beta = 0.45). Under negative framing, both predictors had stronger main effects (risks: beta = -0.69; benefits: beta = 0.63) along with a significant negative interaction (beta = -0.32), indicating that higher perceived risk diminishes the positive effect of perceived benefits. Model fit was higher for the positive frame (R^2 = 0.715) than for the negative frame (R^2 = 0.583), indicating greater explained variance in value attributions. Framing shapes the absolute evaluation of HRC and how risks and benefits are cognitively integrated in trade-offs. Negative framing produces stronger but interdependent effects, whereas positive framing supports additive evaluations. These findings highlight the role of strategic communication in fostering acceptance of HRC and underscore the need to consider framing in future HRC research.

</details>


### [136] [Knowledge-Based Design Requirements for Generative Social Robots in Higher Education](https://arxiv.org/abs/2602.12873)
*Stephan Vonschallen,Dominique Oberle,Theresa Schmiedel,Friederike Eyssel*

Main category: cs.HC

TL;DR: 本文研究生成式社交机器人在高等教育中的知识需求，通过访谈识别出三类知识要求：自我知识、用户知识和情境知识，为负责任的教育机器人设计提供结构化基础。


<details>
  <summary>Details</summary>
Motivation: 生成式社交机器人（GSRs）在自适应对话式辅导方面具有潜力，但也存在幻觉、过度依赖和隐私侵犯等风险。现有教育技术和负责任AI框架主要定义期望行为，但很少明确生成系统可靠表达这些行为所需的知识前提。本文旨在填补这一空白，从知识设计视角探讨辅导导向的GSRs在高等教育中负责任有效运行所需的信息。

Method: 采用基于知识的设计视角，通过对12名大学生和讲师进行半结构化访谈，识别辅导导向的生成式社交机器人所需的知识要求。

Result: 识别出三类知识类型共12项设计需求：1）自我知识（自信、尽责、友好的个性，可定制的角色）；2）用户知识（学生学习目标、学习进度、动机类型、情绪状态和背景的个性化信息）；3）情境知识（学习材料、教育策略、课程相关信息、物理学习环境）。

Conclusion: 通过识别这些知识要求，本研究为辅导型生成式社交机器人的设计和未来评估提供了结构化基础，使生成系统能力与教学和伦理期望保持一致。

Abstract: Generative social robots (GSRs) powered by large language models enable adaptive, conversational tutoring but also introduce risks such as hallucina-tions, overreliance, and privacy violations. Existing frameworks for educa-tional technologies and responsible AI primarily define desired behaviors, yet they rarely specify the knowledge prerequisites that enable generative systems to express these behaviors reliably. To address this gap, we adopt a knowledge-based design perspective and investigate what information tutor-ing-oriented GSRs require to function responsibly and effectively in higher education. Based on twelve semi-structured interviews with university stu-dents and lecturers, we identify twelve design requirements across three knowledge types: self-knowledge (assertive, conscientious and friendly per-sonality with customizable role), user-knowledge (personalized information about student learning goals, learning progress, motivation type, emotional state and background), and context-knowledge (learning materials, educa-tional strategies, course-related information, and physical learning environ-ment). By identifying these knowledge requirements, this work provides a structured foundation for the design of tutoring GSRs and future evaluations, aligning generative system capabilities with pedagogical and ethical expecta-tions.

</details>


### [137] [Reflection at Design Actualization (RDA) : A Tool and Process For Research Through Game Design](https://arxiv.org/abs/2602.12887)
*Prabhav Bhatnagar,Jianheng He,Shamit Ahmed,Andrés Lucero,Perttu Hämäläinen*

Main category: cs.HC

TL;DR: RDA是一个开源工具和流程，用于在游戏测试时刻收集细粒度反思并自动记录测试过程，将反思和数据收集更贴近设计决策具体化的时刻。


<details>
  <summary>Details</summary>
Motivation: 当前研究游戏设计过程、制品和文化的工具和流程有限，特别是在捕捉包含丰富隐性信息的小型设计决策以及可视化跟踪项目增长和演变方面存在不足。

Method: 提出RDA（Reflection at Design Actualization）工具和流程，采用自传式设计原则，让三位研究人员在三个不同的游戏开发项目中使用和评估该工具。

Result: 通过三个主题说明设计师体验：设计师-常规妥协、设计师-研究人员角色整合、RDA的镜像效应。进一步讨论了工具的挑战，并分享了每位设计师的个人经验作为案例研究。

Conclusion: RDA通过将反思和数据收集更贴近设计决策具体化的时刻，为研究游戏设计过程提供了有价值的工具，揭示了设计师体验的重要方面和实际挑战。

Abstract: There is a growing interest in researching game design processes, artifacts and culture through active game design. Tools and processes to support these attempts are limited, especially in terms of a) capturing smaller design decisions where rich tacit information is often situated, and b) visually tracking the project's growth and evolution. To address this gap, we present Reflection at Design Actualization (RDA), an open source tool and process for collecting granular reflections at playtesting moments and automatically recording the playtests, bringing reflection and data collection closer to the point where design decisions concretize. Three researchers engaged with and evaluated RDA in three varied game development projects, adhering to the principles of autobiographical design. We illustrate the designer experience with RDA through three themes, namely, designer-routine compromise, designer-researcher persona consolidation, and mirror effect of RDA. We further discuss the tool's challenges and share each designer's personal experience as case studies.

</details>


### [138] [Comparative Study of Ultrasound Shape Completion and CBCT-Based AR Workflows for Spinal Needle Interventions](https://arxiv.org/abs/2602.12920)
*Tianyu Song,Feng Li,Felix Pabst,Miruna-Alexandra Gafencu Yuan Bi,Ulrich Eck,Nassir Navab*

Main category: cs.HC

TL;DR: 比较两种AR引导的成像工作流（超声形状补全与CBCT）在腰椎穿刺干预中的性能、可用性和信任度评估


<details>
  <summary>Details</summary>
Motivation: 评估不同成像模态对AR辅助脊柱手术中用户表现、可用性和信任度的影响，为优化AR引导的脊柱干预提供依据

Method: 将两种成像系统集成到AR框架中：超声工作流结合AR引导机器人扫描、概率形状补全和AR可视化；CBCT工作流使用AR辅助扫描体积规划、CBCT采集和AR可视化。进行被试间用户研究，分两阶段评估：规划与图像采集阶段、针头插入阶段

Result: CBCT工作流规划时间显著更短；针头插入阶段CBCT工作流插入时间稍快、放置误差更低、主观评分更好且信任度更高；超声工作流在关节突关节插入中精度足够，但在腰椎穿刺中误差较大（形状补全依赖性强）

Conclusion: 两种AR引导成像流程都适用于脊柱干预支持。CBCT-AR在效率、精度、可用性和用户信心方面有优势；超声-AR提供自适应、无辐射成像但在深层脊柱区域受形状补全限制。这些互补特性促使开发混合AR引导系统：用CBCT提供全局解剖背景和规划，超声提供自适应术中更新

Abstract: Purpose: This study compares two augmented reality (AR)-guided imaging workflows, one based on ultrasound shape completion and the other on cone-beam computed tomography (CBCT), for planning and executing lumbar needle interventions. The aim is to assess how imaging modality influences user performance, usability, and trust during AR-assisted spinal procedures.
  Methods: Both imaging systems were integrated into an AR framework, enabling in situ visualization and trajectory guidance. The ultrasound-based workflow combined AR-guided robotic scanning, probabilistic shape completion, and AR visualization. The CBCT-based workflow used AR-assisted scan volume planning, CBCT acquisition, and AR visualization. A between-subject user study was conducted and evaluated in two phases: (1) planning and image acquisition, and (2) needle insertion.
  Results: Planning time was significantly shorter with the CBCT-based workflow, while SUS, SEQ, and NASA-TLX were comparable between modalities. In the needle insertion phase, the CBCT-based workflow yielded marginally faster insertion times, lower placement error, and better subjective ratings with higher Trust. The ultrasound-based workflow achieved adequate accuracy for facet joint insertion, but showed larger errors for lumbar puncture, where reconstructions depended more heavily on shape completion.
  Conclusion: The findings indicate that both AR-guided imaging pipelines are viable for spinal intervention support. CBCT-based AR offers advantages in efficiency, precision, usability, and user confidence during insertion, whereas ultrasound-based AR provides adaptive, radiation-free imaging but is limited by shape completion in deeper spinal regions. These complementary characteristics motivate hybrid AR guidance that uses CBCT for global anatomical context and planning, augmented by ultrasound for adaptive intraoperative updates.

</details>


### [139] [GroundLink: Exploring How Contextual Meeting Snippets Can Close Common Ground Gaps in Editing 3D Scenes for Virtual Production](https://arxiv.org/abs/2602.12987)
*Gun Woo,Park,Frederik Brudy,George Fitzmaurice,Fraser Anderson*

Main category: cs.HC

TL;DR: GroundLink是一个Unity插件，通过会议知识仪表板、约束感知前馈和跨模态同步功能，帮助虚拟制作专业人员获取隐性知识和创意意图，建立团队共识。


<details>
  <summary>Details</summary>
Motivation: 虚拟制作专业人员难以获取隐性知识和创意意图，这影响了与协作者建立共识以及团队工作效率。通过初步研究（N=23）和后续访谈（N=6）确认了这一挑战的普遍性和重要性。

Method: 开发了GroundLink Unity插件，包含三个核心功能：1) 会议知识仪表板用于捕获和审查决策与评论；2) 约束感知前馈主动向编辑器环境提供信息；3) 跨模态同步在仪表板和编辑器之间提供引用链接。

Result: 比较研究（N=12）表明GroundLink帮助用户与团队建立共识，同时提高了编辑3D场景时的感知信心和易用性。专家评估（N=5）显示GroundLink在实际工作流程中具有强大潜力。

Conclusion: GroundLink通过将会议衍生的知识直接集成到Unity编辑器中，有效解决了虚拟制作中获取隐性知识和创意意图的挑战，有助于建立团队共识并提高工作效率。

Abstract: Virtual Production (VP) professionals often face challenges accessing tacit knowledge and creative intent, which are important in forming common ground with collaborators and in contributing more effectively and efficiently to the team. From our formative study (N=23) with a follow-up interview (N=6), we identified the significance and prevalence of this challenge. To help professionals access knowledge, we present GroundLink, a Unity add-on that surfaces meeting-derived knowledge directly in the editor to support establishing common ground. It features a meeting knowledge dashboard for capturing and reviewing decisions and comments, constraint-aware feedforward that proactively informs the editor environment, and cross-modal synchronization that provides referential links between the dashboard and the editor. A comparative study (N=12) suggested that GroundLink help users build common ground with their team while improving perceived confidence and ease of editing the 3D scene. An expert evaluation with VP professionals (N=5) indicated strong potential for GroundLink in real-world workflows.

</details>


### [140] [Automating UI Optimization through Multi-Agentic Reasoning](https://arxiv.org/abs/2602.13126)
*Zhipeng Li,Christoph Gebhardt,Yi-Chi Liao,Christian Holz*

Main category: cs.HC

TL;DR: AutoOptimization是一个多目标优化框架，通过用户口头偏好指导UI布局优化，自动选择目标函数并参数化，生成最优UI布局序列


<details>
  <summary>Details</summary>
Motivation: 传统UI优化需要手动检查布局和使用群体平均参数，无法根据用户个性化偏好自动调整，需要克服这些限制

Method: 基于优先级的Pareto前沿搜索，自动选择UI布局目标函数并根据用户指令参数化，集成多个智能体序列化处理用户偏好解释、优化问题配置和结果验证

Result: 框架能够根据用户口头偏好自动生成一系列最优UI布局，并验证最终解决方案，克服了手动检查和群体平均参数的限制

Conclusion: AutoOptimization通过多智能体协作和多目标优化，实现了基于用户个性化偏好的UI自动优化，提高了UI适配的效率和准确性

Abstract: We present AutoOptimization, a novel multi-objective optimization framework for adapting user interfaces. From a user's verbal preferences for changing a UI, our framework guides a prioritization-based Pareto frontier search over candidate layouts. It selects suitable objective functions for UI placement while simultaneously parameterizing them according to the user's instructions to define the optimization problem. A solver then generates a series of optimal UI layouts, which our framework validates against the user's instructions to adapt the UI with the final solution. Our approach thus overcomes the previous need for manual inspection of layouts and the use of population averages for objective parameters. We integrate multiple agents sequentially within our framework, enabling the system to leverage their reasoning capabilities to interpret user preferences, configure the optimization problem, and validate optimization outcomes.

</details>


### [141] [Preference-Guided Prompt Optimization for Text-to-Image Generation](https://arxiv.org/abs/2602.13131)
*Zhipeng Li,Yi-Chi Liao,Christian Holz*

Main category: cs.HC

TL;DR: APPO是一个基于偏好引导的提示优化算法，用户只需提供二元偏好反馈，算法自适应平衡利用用户反馈和探索新方向，在图像生成任务中比手动编辑提示更高效


<details>
  <summary>Details</summary>
Motivation: 生成模型越来越强大，但用户难以通过提示有效引导它们。生成过程难以控制且不可预测，用户指令可能模糊或不完整。现有的提示优化方法要么依赖大量人工努力，要么专注于数值函数优化，不适合需要二元偏好反馈和快速收敛的人类中心生成任务

Method: APPO（偏好引导提示优化算法）让用户只需提供二元偏好反馈，而不是迭代修改提示。算法自适应平衡两种策略：利用用户反馈（exploitation）和探索新方向（exploration），实现高效优化

Result: 在图像生成任务上的评估表明，APPO能够在更少的迭代次数内获得满意结果，相比手动提示编辑降低了用户的认知负荷

Conclusion: APPO通过利用用户偏好来指导复杂内容创作，有望推动生成任务中的人机协作发展

Abstract: Generative models are increasingly powerful, yet users struggle to guide them through prompts. The generative process is difficult to control and unpredictable, and user instructions may be ambiguous or under-specified. Prior prompt refinement tools heavily rely on human effort, while prompt optimization methods focus on numerical functions and are not designed for human-centered generative tasks, where feedback is better expressed as binary preferences and demands convergence within few iterations. We present APPO, a preference-guided prompt optimization algorithm. Instead of iterating prompts, users only provide binary preferential feedback. APPO adaptively balances its strategies between exploiting user feedback and exploring new directions, yielding effective and efficient optimization. We evaluate APPO on image generation, and the results show APPO enables achieving satisfactory outcomes in fewer iterations with lower cognitive load than manual prompt editing. We anticipate APPO will advance human-AI collaboration in generative tasks by leveraging user preferences to guide complex content creation.

</details>


### [142] [The Fuzzy Front Ends: Reflections on the Never-Ending Story of Visualization Co-Design](https://arxiv.org/abs/2602.13182)
*Wei Wei,Foroozan Daneshzand,Zezhong Wang,Erica Mattson,Charles Perin,Sheelagh Carpendale*

Main category: cs.HC

TL;DR: 本文通过漫画形式分享了一个为期两年半的与当地艺术社区合作的可视化协同设计项目经验，重点探讨了协同设计过程中的"模糊前端"挑战。


<details>
  <summary>Details</summary>
Motivation: 协同设计在HCI和可视化领域越来越流行，但在可视化背景下如何有效应用这种方法缺乏指导。作者希望通过分享与艺术社区的实际合作经验，为可视化社区提供协同设计实践的见解。

Method: 采用为期两年半的协同设计项目，与当地艺术社区进行一系列迭代式协同设计会议，通过可视化研究人员与艺术社区成员的合作，建立共同理解并开发符合社区需求的可视化原型。

Result: 项目成功促进了社区对艺术资金分配的理解和探索，开发了针对社区需求的可视化原型。然而，实践过程并不完整，团队不断回到协同设计过程的"模糊前端"，识别并反思了三个具体的模糊前端挑战。

Conclusion: 通过漫画形式分享这些持续的经验，作者希望为可视化社区提供协同设计实践的见解，特别是如何处理协同设计过程中的"模糊前端"挑战，供其他社区参与式协同设计工作参考。

Abstract: Co-design is an increasingly popular approach in HCI and visualization, yet there is little guidance on how to effectively apply this method in visualization contexts. In this paper, we visually present our experience of a two-and-a-half-year co-design project with the local arts community. Focusing on facilitating community exploration and sense-making around arts funding distribution, the project involved a series of co-design sessions between visualization researchers and members of the arts community. Through these iterative sessions, we built shared understanding and developed visualization prototypes tailored to community needs. However, the practice is far from complete, and we found ourselves continually returning to the "fuzzy front end" of the co-design process. We share this ongoing story through comic-style visuals and reflect on three fuzzy front ends that we encountered during the project. By sharing these experiences with the visualization community, we hope to offer insights that others can draw on in their own community-engaged co-design work.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [143] [Variational Green's Functions for Volumetric PDEs](https://arxiv.org/abs/2602.12349)
*Joao Teixeira,Eitan Grinspun,Otman Benchekroun*

Main category: cs.GR

TL;DR: VGF方法通过学习线性自伴PDE算子的格林函数平滑可微表示，解决了在任意几何离散化上计算格林函数的高计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 格林函数是偏微分方程的基本解，对于形状分析和物理模拟等任务至关重要，但在任意几何离散化上计算成本过高。

Method: 将格林函数分解为解析自由空间分量和学习的修正分量；利用变分基础自然施加诺伊曼边界条件，通过投影层施加狄利克雷边界条件；使用神经场输出。

Result: 得到的格林函数评估速度快，对源应用可微分，并且可以基于几何参数化的其他信号进行条件化。

Conclusion: VGF方法为线性自伴PDE算子提供了一种高效、可微分的格林函数表示方法，适用于包括泊松、屏蔽泊松和双调和方程在内的多种方程。

Abstract: Green's functions characterize the fundamental solutions of partial differential equations; they are essential for tasks ranging from shape analysis to physical simulation, yet they remain computationally prohibitive to evaluate on arbitrary geometric discretizations. We present Variational Green's Function (VGF), a method that learns a smooth, differentiable representation of the Green's function for linear self-adjoint PDE operators, including the Poisson, the screened Poisson, and the biharmonic equations. To resolve the sharp singularities characteristic of the Green's functions, our method decomposes the Green's function into an analytic free-space component, and a learned corrector component. Our method leverages a variational foundation to impose Neumann boundary conditions naturally, and imposes Dirichlet boundary conditions via a projective layer on the output of the neural field. The resulting Green's functions are fast to evaluate, differentiable with respect to source application, and can be conditioned on other signals parameterizing our geometry.

</details>


### [144] [Real-time Rendering with a Neural Irradiance Volume](https://arxiv.org/abs/2602.12949)
*Arno Coomans,Giacomo Nazzaro,Edoardo A. Dominici,Christian Döring,Floor Verhoeven,Konstantinos Vardis,Markus Steinberger*

Main category: cs.GR

TL;DR: Neural Irradiance Volume (NIV) 使用神经压缩技术替代传统3D探针网格，实现实时漫反射全局光照渲染，显著降低内存占用（1-5MB），消除走样伪影，支持动态效果，推理速度快（约1ms/帧）。


<details>
  <summary>Details</summary>
Motivation: 传统基于3D探针网格的漫反射全局光照方法存在内存消耗高、走样伪影严重、需要场景特定启发式算法等问题，难以在实时渲染中高效应用。

Method: 提出神经辐照度体积（NIV），利用神经压缩创建自适应、摊销的辐照度表示，避免网格方法的立方缩放问题。仅需G-buffer作为输入，无需运行时昂贵的光线追踪或去噪。

Result: 在相同内存预算下质量提升至少10倍，内存占用仅1-5MB（中等场景），在消费级GPU上全高清分辨率下推理约1ms/帧，支持时间变化或动态效果的高维辐照度场表示。

Conclusion: NIV方法克服了传统探针方法的局限性，在严格实时约束下实现了高质量、低内存的漫反射全局光照渲染，为实时渲染提供了实用的神经解决方案。

Abstract: Rendering diffuse global illumination in real-time is often approximated by pre-computing and storing irradiance in a 3D grid of probes. As long as most of the scene remains static, probes approximate irradiance for all surfaces immersed in the irradiance volume, including novel dynamic objects. This approach, however, suffers from aliasing artifacts and high memory consumption. We propose Neural Irradiance Volume (NIV), a neural-based technique that allows accurate real-time rendering of diffuse global illumination via a compact pre-computed model, overcoming the limitations of traditional probe-based methods, such as the expensive memory footprint, aliasing artifacts, and scene-specific heuristics. The key insight is that neural compression creates an adaptive and amortized representation of irradiance, circumventing the cubic scaling of grid-based methods. Our superior memory-scaling improves quality by at least 10x at the same memory budget, and enables a straightforward representation of higher-dimensional irradiance fields, allowing rendering of time-varying or dynamic effects without requiring additional computation at runtime. Unlike other neural rendering techniques, our method works within strict real-time constraints, providing fast inference (around 1 ms per frame on consumer GPUs at full HD resolution), reduced memory usage (1-5 MB for medium-sized scenes), and only requires a G-buffer as input, without expensive ray tracing or denoising.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [145] [Online Advertising with Spatial Interactions](https://arxiv.org/abs/2602.12481)
*Gagan Aggarwal,Yifan Wang,Mingfei Zhao*

Main category: cs.GT

TL;DR: 论文提出了一个考虑空间外部性的在线广告分配新框架，其中广告价值取决于自身位置和周围广告配置。针对最近邻模型给出了多项式时间常数近似算法和PTAS，而乘积距离模型则存在强近似困难性。


<details>
  <summary>Details</summary>
Motivation: 在线广告平台需要在有限屏幕空间分配多个广告，每个广告的效果不仅取决于自身位置，还受到周围广告竞争用户注意力的影响。现有的拍卖和分配模型通常将广告位视为独立或单维有序的，忽略了空间外部性对福利和收入结果的显著影响。

Method: 引入了一个新的空间外部性框架，将广告位建模为度量空间中的点，广告价值取决于其出价和由周围广告配置决定的折扣因子。分析了两种自然模型：最近邻模型（价值抑制仅取决于最近邻广告）和乘积距离模型（干扰在所有邻居间乘性聚合）。

Result: 对于最近邻模型，提出了多项式时间算法实现常数近似，分配规则是单调的并可实现为真实机制；在2D欧几里得空间的结构化设置中提供了PTAS。对于乘积距离模型，证明了强近似困难性——除非P=NP，否则多项式时间算法无法实现任何多项式因子近似。

Conclusion: 研究结果为在广告分配中考虑空间外部性提供了理论基础，并为在此类交互下设计高效、真实的机制奠定了基础。两种模型的不同复杂性结果揭示了空间外部性建模对算法可解性的重要影响。

Abstract: Online advertising platforms must decide how to allocate multiple ads across limited screen real estate, where each ad's effectiveness depends not only on its own placement but also on nearby ads competing for user attention. Such spatial externalities - arising from proximity, clutter, or crowding - can significantly alter welfare and revenue outcomes, yet existing auction and allocation models typically treat ad slots as independent or ordered along a single dimension.
  We introduce a new framework for spatial externalities in online advertising, in which the value of an ad depends on both its slot and the configuration of surrounding ads. We model ad slots as points in a metric space, and model an advertiser's value as a function of both their bid and a discount factor determined by the configuration of other displayed ads. Within this framework, we analyze two natural models. For the Nearest-Neighbor model, where the value suppression depends only on the closest neighboring ad, we present a polynomial-time algorithm that achieves a constant approximation for the general case. We show that the allocation rule is monotone and can be implemented as a truthful mechanism. For a structured setting of 2D Euclidean space, we provide a PTAS. In contrast, for the Product-Distance model, where interference is aggregated multiplicatively across all neighbors, we establish a strong (and nearly-tight) hardness of approximation - no polynomial-time algorithm can achieve any polynomial-factor approximation unless P=NP, via a reduction from Max-Independent-Set.
  Our results provide a foundation for reasoning about spatial externalities in ad allocation and for designing efficient, truthful mechanisms under such interactions.

</details>


### [146] [Feature-based Uncertainty Model for School Choice](https://arxiv.org/abs/2602.12615)
*Yao Zhang,Makoto Yokoo*

Main category: cs.GT

TL;DR: 研究学校选择中基于特征的不确定性模型，学生偏好基于特征的线性组合，系数为随机变量。目标是提高稳定性和激励相容性，但两者通常不兼容。提出了两种改进的延迟接受算法，分别优化稳定性和激励相容性。


<details>
  <summary>Details</summary>
Motivation: 在学校选择场景中，学生通常无法准确知道哪所大学更适合自己。虽然难以获得精确的偏好排序，但学生通常可以比较大学的具体特征，如声誉、地理位置、校园设施等。因此需要建立一个基于特征的不确定性模型来更好地处理这种现实情况。

Method: 提出基于特征的不确定性模型，学生偏好基于不同特征效用的线性组合，组合系数为随机变量。主要采用两种改进的延迟接受算法：1）学生提议的延迟接受算法，优先考虑期望排名较高的大学；2）使用精心定义的迭代比较向量的延迟接受算法。

Result: 证明稳定性和激励相容性在一般情况下不兼容。第一种算法在最坏情况下对稳定性概率的近似比为(1/n)^n；第二种算法可以保证最强的可实现的激励相容性形式。还对模型的特定限制提供了额外结果。

Conclusion: 基于特征的不确定性模型为学校选择问题提供了更现实的框架。虽然稳定性和激励相容性通常无法同时最大化，但通过改进的延迟接受算法可以在不同程度上优化这两个目标，为实际应用提供了理论支持。

Abstract: In this work, we consider a school choice scenario where a student does not exactly know which college is better for her. Although it is hard for a student to obtain an exact preference, she can usually compare specific features of colleges, such as reputation, location, and campus facilities. Motivated by this, we propose a feature-based uncertainty model for school choice where a student's preference is based on a linear combination of her utilities over different features, and the coefficients of the combination are treated as random variables. Our main goal is to achieve a higher probability of stability (ProS) and incentive compatibility (IC) for students. Unfortunately, these two goals are incompatible in general. We show that a student-proposing deferred acceptance (DA) that prioritizes colleges with higher expected ranking can achieve a worst-case approximation ratio of $(1/n)^n$ on ProS, while a DA with a carefully defined iterated comparison vector can guarantee the strongest achievable form of IC. Finally, we provide additional results for some specific restrictions on the model.

</details>


### [147] [Experimentation, Biased Learning, and Conjectural Variations in Competitive Dynamic Pricing](https://arxiv.org/abs/2602.12888)
*Bar Light,Wenyu Wang*

Main category: cs.GT

TL;DR: 研究多卖家竞争性动态定价，发现同步A/B价格实验会导致需求学习偏差，从而内生形成推测变分均衡，导致超竞争价格；独立实验则收敛到纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 受零售和在线市场中大规模实验和算法定价兴起的启发，研究多个卖家在仅观察自身价格和需求的情况下，通过简单学习规则进行重复定价的竞争动态。

Method: 卖家使用类似切换设计的双点A/B价格实验，基于自身数据拟合线性需求估计来更新基准价格。分析在需求满足特定条件下的动态收敛性。

Result: 在相关实验（如同步重新定价）下，学习偏差导致动态收敛到推测变分均衡，通常产生超竞争价格；独立实验下偏差消失，收敛到标准纳什均衡。提供了收敛的充分条件和有限样本保证。

Conclusion: 实验设计可作为市场设计杠杆，影响实际学习算法达到的均衡。在竞争市场中，实验的同步性会影响价格结果，为监管和平台设计提供启示。

Abstract: We study competitive dynamic pricing among multiple sellers, motivated by the rise of large-scale experimentation and algorithmic pricing in retail and online marketplaces. Sellers repeatedly set prices using simple learning rules and observe only their own prices and realized demand, even though demand depends on all sellers' prices and is subject to random shocks. Each seller runs two-point A/B price experiments, in the spirit of switchback-style designs, and updates a baseline price using a linear demand estimate fitted to its own data. Under certain conditions on demand, the resulting dynamics converge to a Conjectural Variations (CV) equilibrium, a classic static equilibrium notion in which each seller best responds under a conjecture that rivals' prices respond systematically to changes in its own price. Unlike standard CV models that treat conjectures as behavioral primitives, we show that these conjectures arise endogenously from the bias in demand learning induced by correlated experimentation (e.g., due to synchronized repricing schedules). This learning bias selects the long-run equilibrium, often leading to supra-competitive prices. Notably, we show that under independent experimentation, this bias vanishes and the learning dynamics converge to the standard Nash equilibrium. We provide simple sufficient conditions on demand for convergence in standard models and establish a finite-sample guarantee: up to logarithmic factors, the squared price error decays on the order of $T^{-1/2}$. Our results imply that in competitive markets, experimentation design can serve as a market design lever, selecting the equilibrium reached by practical learning algorithms.

</details>


### [148] [Contextual Online Bilateral Trade](https://arxiv.org/abs/2602.12903)
*Romain Cosson,Federico Fusco,Anupam Gupta,Stefano Leonardi,Renato Paes Leme,Matteo Russo*

Main category: cs.GT

TL;DR: 研究上下文双边重复交易，买卖双方估值由上下文向量与未知参数的内积决定。在两种反馈机制（两比特和一比特）下，分别设计了针对交易收益和利润最大化的无遗憾算法，实现了相对于全知动态策略的强基准。


<details>
  <summary>Details</summary>
Motivation: 研究上下文环境下的重复双边交易问题，其中买卖双方的估值由上下文向量决定。目标是设计算法在两种不同的反馈机制下（两比特反馈和一比特反馈）实现无遗憾性能，同时满足预算平衡约束。

Method: 1. 在每轮时间步t，学习者接收上下文向量，并为买卖双方分别设定价格
2. 交易仅在双方都接受价格时发生
3. 研究两种反馈模型：两比特反馈（分别观察买卖双方是否接受价格）和一比特反馈（仅观察交易是否发生）
4. 针对不同反馈机制和优化目标（交易收益 vs 利润最大化）设计算法
5. 算法需满足预算平衡约束（不产生负利润）

Result: 1. 两比特反馈下：交易收益算法达到O(d log d)遗憾，利润最大化算法达到O(d log log T + d log d)遗憾，两者都满足每步预算平衡
2. 一比特反馈下：仍能达到两比特反馈的遗憾界，但需允许O(d log d)的小负利润（与时间无关）
3. 一比特反馈+预算平衡下：交易收益算法遗憾与时间无关但指数依赖维度d；利润最大化算法遗憾指数依赖d并乘以log T因子

Conclusion: 在上下文双边交易中，针对不同的反馈机制和约束条件，设计了接近最优的无遗憾算法。两比特反馈下可获得接近最优的遗憾界并保持预算平衡；一比特反馈下虽能达到相似遗憾界但需在预算平衡和遗憾界之间权衡，存在指数维度依赖的遗憾下界。

Abstract: We study repeated bilateral trade when the valuations of the sellers and the buyers are contextual. More precisely, the agents' valuations are given by the inner product of a context vector with two unknown $d$-dimensional vectors -- one for the buyers and one for the sellers.
  At each time step $t$, the learner receives a context and posts two prices, one for the seller and one for the buyer, and the trade happens if both agents accept their price. We study two objectives for this problem, gain from trade and profit, proving no-regret with respect to a surprisingly strong benchmark: the best omniscient dynamic strategy.
  In the natural scenario where the learner observes \emph{separately} whether the agents accept their price -- the so-called \emph{two-bit} feedback -- we design algorithms that achieve $O(d\log d)$ regret for gain from trade, and $O(d \log\log T + d\log d)$ regret for profit maximization. Both results are tight, up to the $\log(d)$ factor, and implement per-step budget balance, meaning that the learner never incurs negative profit.
  In the less informative \emph{one-bit} feedback model, the learner only observes whether a trade happens or not. For this scenario, we show that the tight two-bit regret regimes are still attainable, at the cost of allowing the learner to possibly incur a small negative profit of order $O(d\log d)$, which is notably independent of the time horizon. As a final set of results, we investigate the combination of one-bit feedback and per-step budget balance. There, we design an algorithm for gain from trade that suffers regret independent of the time horizon, but \emph{exponential} in the dimension $d$. For profit maximization, we maintain this exponential dependence on the dimension, which gets multiplied by a $\log T$ factor.

</details>


### [149] [Nonparametric Contextual Online Bilateral Trade](https://arxiv.org/abs/2602.12904)
*Emanuele Coccia,Martino Bernasconi,Andrea Celli*

Main category: cs.GT

TL;DR: 研究上下文在线双边交易问题，在非参数设置下设计算法，仅使用单比特反馈和强预算平衡约束，实现最优遗憾界


<details>
  <summary>Details</summary>
Motivation: 现有上下文在线双边交易研究主要关注线性模型，但现实世界中买卖双方的估值可能遵循更复杂的非线性关系。本文旨在解决更一般的非参数设置，其中买卖双方的估值是上下文的任意Lipschitz函数，同时面临两个严格约束：单比特反馈（仅观察是否发生交易）和强预算平衡（不能补贴或从市场参与者获利）。

Method: 设计了一种算法，通过分层树结构利用上下文信息。算法在非参数设置下工作，买卖双方的估值是上下文的Lipschitz函数。算法仅使用单比特反馈（是否发生交易），同时满足强预算平衡约束，确保不补贴或从市场参与者获利。

Result: 算法实现了遗憾界 $\widetilde{O}(T^{{(d-1)}/d})$，其中d是上下文维度。在完全反馈设置下提供了匹配的下界，证明了遗憾界的紧致性。算法在单比特反馈和强预算平衡的严格约束下仍能实现最优性能。

Conclusion: 本文首次在非参数设置下解决了上下文在线双边交易问题，设计了在单比特反馈和强预算平衡约束下仍能实现最优遗憾界的算法。通过分层树结构和匹配的下界分析，证明了算法的最优性，为更现实的交易环境提供了理论保证。

Abstract: We study the problem of contextual online bilateral trade. At each round, the learner faces a seller-buyer pair and must propose a trade price without observing their private valuations for the item being sold. The goal of the learner is to post prices to facilitate trades between the two parties. Before posting a price, the learner observes a $d$-dimensional context vector that influences the agent's valuations. Prior work in the contextual setting has focused on linear models. In this work, we tackle a general nonparametric setting in which the buyer's and seller's valuations behave according to arbitrary Lipschitz functions of the context. We design an algorithm that leverages contextual information through a hierarchical tree construction and guarantees regret $\widetilde{O}(T^{{(d-1)}/d})$. Remarkably, our algorithm operates under two stringent features of the setting: (1) one-bit feedback, where the learner only observes whether a trade occurred or not, and (2) strong budget balance, where the learner cannot subsidize or profit from the market participants. We further provide a matching lower bound in the full-feedback setting, demonstrating the tightness of our regret bound.

</details>


### [150] [Solving Qualitative Multi-Objective Stochastic Games](https://arxiv.org/abs/2602.12927)
*Moritz Graf,Anthony Lin,Rupak Majumdar*

Main category: cs.GT

TL;DR: 本文研究了具有布尔组合的定性可达性和安全性目标的双人随机博弈，分析了其确定性和复杂性。研究发现，具有AS和NZ可达性与安全性目标合取的博弈是确定的且PSPACE完全，而具有完全布尔组合的博弈则不确定且NEXPTIME困难。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统的组合合成与验证中的许多问题（如理性验证和概率系统中的假设-保证验证）都归结为对双人多目标随机博弈的推理。这促使我们研究具有布尔组合的定性可达性和安全性目标的双人随机博弈的复杂性和内存需求。

Method: 研究双人随机博弈的确定性和复杂性特征。分析不同类型的布尔组合目标：1) AS和NZ可达性与安全性目标的合取；2) AS可达性和安全性的正布尔组合及其否定；3) 定性目标的完全布尔组合。通过理论分析确定博弈的确定性状态和计算复杂性。

Result: 1) 具有AS和NZ可达性与安全性目标合取的博弈是确定的，确定胜者是PSPACE完全的；2) AS可达性和安全性的正布尔组合及其否定也具有相同的性质；3) 具有完全布尔组合的定性目标的博弈是不确定的，且是NEXPTIME困难的；4) 硬度结果显示了随机博弈与具有偏序量词逻辑之间的联系。

Conclusion: 研究揭示了确定性与复杂性之间的关系，扩展了多目标设置下随机博弈的复杂性图景。结果表明，确定性状态与计算复杂性之间存在密切联系，为多智能体系统的组合合成与验证提供了理论基础。

Abstract: Many problems in compositional synthesis and verification of multi-agent systems -- such as rational verification and assume-guarantee verification in probabilistic systems -- reduce to reasoning about two-player multi-objective stochastic games. This motivates us to study the problem of characterizing the complexity and memory requirements for two-player stochastic games with Boolean combinations of qualitative reachability and safety objectives. Reachability objectives require that a given set of states is reached; safety requires that a given set is invariant. A qualitative winning condition asks that an objective is satisfied almost surely (AS) or (in negated form) with non-zero (NZ) probability.
  We study the determinacy and complexity landscape of the problem. We show that games with conjunctions of AS and NZ reachability and safety objectives are determined, and determining the winner is PSPACE-complete. The same holds for positive boolean combinations of AS reachability and safety, as well as for negations thereof. On the other hand, games with full Boolean combinations of qualitative objectives are not determined, and are NEXPTIME-hard. Our hardness results show a connection between stochastic games and logics with partially-ordered quantification. Our results shed light on the relationship between determinacy and complexity, and extend the complexity landscape for stochastic games in the multi-objective setting.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [151] [Beyond Musical Descriptors: Extracting Preference-Bearing Intent in Music Queries](https://arxiv.org/abs/2602.12301)
*Marion Baranes,Romain Hennequin,Elena V. Epure*

Main category: cs.SD

TL;DR: 论文介绍了MusicRecoIntent数据集，包含2,291个Reddit音乐请求的人工标注，标注了七个类别音乐描述符的偏好角色，并研究了LLM提取这些描述符的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有音乐描述符数据集很少考虑用户描述背后的意图，而理解用户意图对于有效满足其音乐需求至关重要。

Method: 创建了MusicRecoIntent数据集，手动标注了2,291个Reddit音乐请求，将音乐描述符分为七个类别，并标注其偏好角色（积极、消极或参考性）。然后研究了大型语言模型提取这些音乐描述符的可靠性。

Result: 研究发现LLM能够捕捉显式描述符，但在处理上下文依赖的描述符时存在困难。

Conclusion: 该工作可作为用户意图细粒度建模的基准，并为改进基于LLM的音乐理解系统提供见解。

Abstract: Although annotated music descriptor datasets for user queries are increasingly common, few consider the user's intent behind these descriptors, which is essential for effectively meeting their needs. We introduce MusicRecoIntent, a manually annotated corpus of 2,291 Reddit music requests, labeling musical descriptors across seven categories with positive, negative, or referential preference-bearing roles. We then investigate how reliably large language models (LLMs) can extract these music descriptors, finding that they do capture explicit descriptors but struggle with context-dependent ones. This work can further serve as a benchmark for fine-grained modeling of user intent and for gaining insights into improving LLM-based music understanding systems.

</details>


### [152] [OmniCustom: Sync Audio-Video Customization Via Joint Audio-Video Generation Model](https://arxiv.org/abs/2602.12304)
*Maomao Li,Zhen Li,Kaipeng Zhang,Guosheng Yin,Zhifeng Li,Dong Xu*

Main category: cs.SD

TL;DR: OmniCustom是一个基于DiT的音频-视频定制框架，能够同时根据参考图像、参考音频和文本提示生成具有一致身份和音色的同步音频-视频内容。


<details>
  <summary>Details</summary>
Motivation: 现有主流视频定制方法主要关注基于参考图像和文本提示生成身份一致的视频。随着音频-视频联合生成的快速发展，本文提出了更具吸引力的新任务：同步音频-视频定制，旨在同时定制视频身份和音频音色。

Method: 提出OmniCustom框架，基于三个关键贡献：1) 通过独立的参考身份和音频LoRA模块实现身份和音色控制；2) 引入对比学习目标增强模型保持身份和音色的能力；3) 在构建的大规模高质量音频-视觉人类数据集上进行训练。

Result: 广泛实验表明，OmniCustom在生成具有一致身份和音色保真度的音频-视频内容方面优于现有方法。

Conclusion: OmniCustom是一个强大的音频-视频定制框架，能够零样本地同时合成遵循参考图像身份、音频音色和文本提示的视频，为同步音频-视频定制任务提供了有效解决方案。

Abstract: Existing mainstream video customization methods focus on generating identity-consistent videos based on given reference images and textual prompts. Benefiting from the rapid advancement of joint audio-video generation, this paper proposes a more compelling new task: sync audio-video customization, which aims to synchronously customize both video identity and audio timbre. Specifically, given a reference image $I^{r}$ and a reference audio $A^{r}$, this novel task requires generating videos that maintain the identity of the reference image while imitating the timbre of the reference audio, with spoken content freely specifiable through user-provided textual prompts. To this end, we propose OmniCustom, a powerful DiT-based audio-video customization framework that can synthesize a video following reference image identity, audio timbre, and text prompts all at once in a zero-shot manner. Our framework is built on three key contributions. First, identity and audio timbre control are achieved through separate reference identity and audio LoRA modules that operate through self-attention layers within the base audio-video generation model. Second, we introduce a contrastive learning objective alongside the standard flow matching objective. It uses predicted flows conditioned on reference inputs as positive examples and those without reference conditions as negative examples, thereby enhancing the model ability to preserve identity and timbre. Third, we train OmniCustom on our constructed large-scale, high-quality audio-visual human dataset. Extensive experiments demonstrate that OmniCustom outperforms existing methods in generating audio-video content with consistent identity and timbre fidelity.

</details>


### [153] [DisSR: Disentangling Speech Representation for Degradation-Prior Guided Cross-Domain Speech Restoration](https://arxiv.org/abs/2602.12701)
*Ziqi Liang,Zhijun Jia,Chang Liu,Minghui Yang,Zhihong Lu,Jian Wang*

Main category: cs.SD

TL;DR: 提出DisSR模型，通过解耦语音表示实现通用语音恢复，解决传统单任务语音恢复模型缺乏通用性和跨域泛化能力的问题


<details>
  <summary>Details</summary>
Motivation: 传统语音恢复方法主要关注单任务恢复，无法处理通用语音恢复问题；为不同失真类型训练特定模型耗时且缺乏通用性；现有研究大多忽略模型在未见域的泛化问题

Method: 提出DisSR模型，具有两个关键特性：1) 退化先验引导：提取说话人不变的退化表示来指导基于扩散的语音恢复模型；2) 域适应：设计跨域对齐训练，分别增强模型在跨域数据上的适应性和泛化能力

Result: 实验结果表明，该方法能够在各种失真条件下产生高质量的恢复语音

Conclusion: DisSR模型通过解耦语音表示和跨域适应机制，有效解决了通用语音恢复问题，提升了模型在各种失真条件下的恢复能力和跨域泛化性能

Abstract: Previous speech restoration (SR) primarily focuses on single-task speech restoration (SSR), which cannot address general speech restoration problems. Training specific SSR models for different distortions is time-consuming and lacks generality. In addition, most studies ignore the problem of model generalization across unseen domains. To overcome those limitations, we propose DisSR, a Disentangling Speech Representation based general speech restoration model with two properties: 1) Degradation-prior guidance, which extracts speaker-invariant degradation representation to guide the diffusion-based speech restoration model. 2) Domain adaptation, where we design cross-domain alignment training to enhance the model's adaptability and generalization on cross-domain data, respectively. Experimental results demonstrate that our method can produce high-quality restored speech under various distortion conditions. Audio samples can be found at https://itspsp.github.io/DisSR.

</details>


### [154] [Towards explainable reference-free speech intelligibility evaluation of people with pathological speech](https://arxiv.org/abs/2602.12723)
*Bence Mark Halpern,Thomas Tienkamp,Defne Abur,Thomas Tienkamp*

Main category: cs.SD

TL;DR: 提出一种无需参考文本、可解释的ASR不一致性评分方法，用于评估病理语音，在多语言测试中表现优于或接近基于参考文本的词错误率基线


<details>
  <summary>Details</summary>
Motivation: 现有客观语音评估方法（特别是基于参考文本的方法）虽然能捕捉可懂度变化，但缺乏可解释性且需要劳动密集型的人工转录，限制了临床应用和研究可重复性

Method: 提出参考文本无关、可解释的ASR不一致性评分方法，通过自动语音识别系统评估语音不一致性，避免了对参考文本的依赖

Result: 在荷兰语、西班牙语和英语的病理语音测试中，ASR不一致性评分与专家感知评分高度相关，性能接近甚至超过标准的基于参考文本的词错误率基线

Conclusion: ASR不一致性评分是一种有效、可解释且无需参考文本的病理语音评估方法，有望改善临床决策和研究可重复性

Abstract: Objective assessment of speech that reflects meaningful changes in communication is crucial for clinical decision making and reproducible research. While existing objective assessments, particularly reference-based approaches, can capture intelligibility changes, they are often hindered by lack of explainability and the need for labor-intensive manual transcriptions. To address these issues, this work proposes the reference-free, explainable ASR Inconsistency Score. We evaluate this method on pathological speech in Dutch, Spanish and English, and compare its performance to a reference-based Word Error Rate (WER) baseline. Our results demonstrate that the ASR Inconsistency Score achieves a high correlation with expert perceptual ratings, with performance closely matching, and in one case exceeding, a standard reference-based Word Error Rate (WER) baseline.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [155] [A Lightweight Cubature Kalman Filter for Attitude and Heading Reference Systems Using Simplified Prediction Equations](https://arxiv.org/abs/2602.12283)
*Shunsei Yamagishi,Lei Jing*

Main category: eess.SY

TL;DR: 本文提出了一种改进的容积卡尔曼滤波器（KCKF），在保持姿态估计精度的同时降低了计算成本，适用于AHRS系统。


<details>
  <summary>Details</summary>
Motivation: AHRS系统广泛应用于需要可靠姿态和运动感知的场合，但传统容积卡尔曼滤波器（CKF）计算成本较高，需要开发更高效的计算方法。

Method: 通过简化CKF的方程推导出KCKF，保持等效数学关系的同时降低计算复杂度。具体方法包括展开CKF中的求和项并进行简化，得到轻量化的预测方程。

Result: KCKF比CKF需要更少的浮点运算（FLOPs）。在高性能计算机上计算时间减少约19%，在低成本单板计算机上减少约15%，同时保持与CKF相同的姿态估计精度。

Conclusion: KCKF在保持姿态估计精度的同时显著降低了计算成本，为AHRS系统提供了更高效的计算解决方案。

Abstract: Attitude and Heading Reference Systems (AHRSs) are broadly applied wherever reliable orientation and motion sensing is required. In this paper, we present an improved Cubature Kalman Filter (CKF) with lower computational cost while maintaining estimation accuracy, which is named "Kaisoku Cubature Kalman Filter (KCKF)". The computationally efficient equations of the KCKF are derived by simplifying those of the CKF, while preserving equivalent mathematical relations. The lightweight prediction equations in the KCKF are derived by expanding the summation terms in the CKF and simplifying the result. This paper shows that the KCKF requires fewer floating-point operations (FLOPs) than the CKF. The controlled experimental results show that the KCKF reduces the computation time by approximately 19% compared to the CKF on a high-performance computer, whereas the KCKF reduces the computation time by approximately 15% compared to the CKF on a low-cost single-board computer. In addition, the KCKF maintains the attitude estimation accuracy of the CKF.

</details>


### [156] [Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance](https://arxiv.org/abs/2602.12288)
*Xiaowen Tao,Yinuo Wang,Haitao Ding,Yuanyang Qi,Ziyu Song*

Main category: eess.SY

TL;DR: 提出了一种面向智能基础设施运维的通用、能量感知的强化学习框架，用于机器人操作铰接部件，相比现有方法显著降低能耗并提高效率。


<details>
  <summary>Details</summary>
Motivation: 随着智能基础设施和智慧城市的发展，运维工作需要对铰接部件进行安全、高效、节能的机器人操作。现有方法要么主要关注抓取，要么针对特定物体，很少将驱动能量纳入多目标优化，限制了在真实运维场景中的可扩展性和长期部署适用性。

Method: 提出了一个与铰接类型无关的能量感知强化学习框架，结合部件引导的3D感知、加权点采样和基于PointNet的编码来获取紧凑的几何表示。将操作建模为约束马尔可夫决策过程，通过基于拉格朗日的约束Soft Actor-Critic方案显式建模和调节驱动能量，端到端训练策略。

Result: 在代表性运维任务实验中，能耗降低16%-30%，成功步骤减少16%-32%，同时保持高成功率，表明该方法为基础设施运维操作提供了可扩展且可持续的解决方案。

Conclusion: 该框架为智能基础设施运维中的机器人铰接部件操作提供了一个通用、能量感知的解决方案，在保持高成功率的同时显著降低能耗和提高效率，具有实际部署价值。

Abstract: With the growth of intelligent civil infrastructure and smart cities, operation and maintenance (O&M) increasingly requires safe, efficient, and energy-conscious robotic manipulation of articulated components, including access doors, service drawers, and pipeline valves. However, existing robotic approaches either focus primarily on grasping or target object-specific articulated manipulation, and they rarely incorporate explicit actuation energy into multi-objective optimisation, which limits their scalability and suitability for long-term deployment in real O&M settings. Therefore, this paper proposes an articulation-agnostic and energy-aware reinforcement learning framework for robotic manipulation in intelligent infrastructure O&M. The method combines part-guided 3D perception, weighted point sampling, and PointNet-based encoding to obtain a compact geometric representation that generalises across heterogeneous articulated objects. Manipulation is formulated as a Constrained Markov Decision Process (CMDP), in which actuation energy is explicitly modelled and regulated via a Lagrangian-based constrained Soft Actor-Critic scheme. The policy is trained end-to-end under this CMDP formulation, enabling effective articulated-object operation while satisfying a long-horizon energy budget. Experiments on representative O&M tasks demonstrate 16%-30% reductions in energy consumption, 16%-32% fewer steps to success, and consistently high success rates, indicating a scalable and sustainable solution for infrastructure O&M manipulation.

</details>


### [157] [String-Level Ground Fault Localization for TN-Earthed Three-Phase Photovoltaic Systems](https://arxiv.org/abs/2602.12289)
*Yuanliang Li,Xun Gong,Reza Iravani,Bo Cao,Heng Liu,Ziming Chen*

Main category: eess.SY

TL;DR: 该论文提出了一种基于边缘AI的直流侧接地故障定位方法，专门针对三相TN接地光伏系统，通过轻量级变分信息瓶颈模型实现高效故障定位。


<details>
  <summary>Details</summary>
Motivation: 三相TN接地光伏系统的直流侧接地故障会产生高故障电流，直接损坏光伏逆变器和组件。传统的人工逐串检查方法耗时且低效，需要更智能的故障定位解决方案。

Method: 1. 通过故障电流分析和仿真研究分析接地故障特性；2. 开发包含光伏迟滞效应的PLECS仿真模型，生成多样化故障场景；3. 从逆变器四阶段关断序列中提取基于相关性的特征；4. 设计轻量级变分信息瓶颈定位模型，在模拟数据集上进行训练。

Result: 提出的VIB定位模型在典型采样率下实现了超过93%的定位准确率，同时具有较低的计算成本，适合在资源受限的光伏逆变器上部署。

Conclusion: 该方法为三相TN接地光伏系统提供了一种高效、准确的接地故障定位解决方案，展示了在边缘设备上部署AI模型的可行性，具有实际应用潜力。

Abstract: The DC-side ground fault (GF) poses significant risks to three-phase TN-earthed photovoltaic (PV) systems, as the resulting high fault current can directly damage both PV inverters and PV modules. Once a fault occurs, locating the faulty string through manual string-by-string inspection is highly time-consuming and inefficient. This work presents a comprehensive analysis of GF characteristics through fault-current analysis and a simulation-based case study covering multiple fault locations. Building on these insights, we propose an edge-AI-based GF localization approach tailored for three-phase TN-earthed PV systems. A PLECS-based simulation model that incorporates PV hysteresis effects is developed to generate diverse GF scenarios, from which correlation-based features are extracted throughout the inverter's four-stage shutdown sequence. Using the simulated dataset, a lightweight Variational Information Bottleneck (VIB)-based localization model is designed and trained, achieving over 93% localization accuracy at typical sampling rates with low computational cost, demonstrating strong potential for deployment on resource-constrained PV inverters.

</details>


### [158] [Interpolation-Inspired Closure Certificates](https://arxiv.org/abs/2602.12436)
*Mohammed Adib Oumer,Vishnu Murali,Majid Zamani*

Main category: eess.SY

TL;DR: 提出了一种基于插值思想的多重闭包证书方法，用于验证动态系统的ω-正则属性，解决了传统单一闭包证书模板可能无法找到合适证书的问题。


<details>
  <summary>Details</summary>
Motivation: 传统闭包证书方法使用单一函数模板（如固定次数的多项式）来寻找过渡不变量，但有时可能无法找到合适的证书。需要一种更灵活的方法来验证动态系统的ω-正则属性。

Method: 提出插值思想闭包证书，使用一组函数联合逼近过渡不变量。通过考虑一步转移、两步转移等逐步构建过渡不变量，使用SOS规划和场景规划来寻找这组函数。

Result: 该方法能够证明在标准方法无法找到单一函数模板的情况下，仍然可以验证系统的持久性和一般ω-正则规范。通过案例研究展示了该方法的有效性。

Conclusion: 插值思想闭包证书提供了一种更灵活和强大的方法来验证动态系统的ω-正则属性，特别是在传统单一模板方法失败的情况下。

Abstract: Barrier certificates, a form of state invariants, provide an automated approach to the verification of the safety of dynamical systems. Similarly to barrier certificates, recent works explore the notion of closure certificates, a form of transition invariants, to verify dynamical systems against $ω$-regular properties including safety. A closure certificate, defined over state pairs of a dynamical system, is a real-valued function whose zero superlevel set characterizes an inductive transition invariant of the system. The search for such a certificate can be effectively automated by assuming it to be within a specific template class, e.g. a polynomial of a fixed degree, and then using optimization techniques such as sum-of-squares (SOS) programming to find it. Unfortunately, one may not be able to find such a certificate for a fixed template. In such a case, one must change the template, e.g. increase the degree of the polynomial. In this paper, we consider a notion of multiple closure certificates dubbed interpolation-inspired closure certificates. An interpolation-inspired closure certificate consists of a set of functions which jointly over-approximate a transition invariant by first considering one-step transitions, then two, and so on until a transition invariant is obtained. The advantage of interpolation-inspired closure certificates is that they allow us to prove properties even when a single function for a fixed template cannot be found using standard approaches. We present SOS programming and a scenario program to find these sets of functions and demonstrate the effectiveness of our proposed method to verify persistence and general $ω$-regular specifications in some case studies.

</details>


### [159] [Implementation of a Directional Modulation Testbed for Reconfigurable Transmitters for Spatially Agile MIMO Systems](https://arxiv.org/abs/2602.12452)
*Jonathan E. Swindell,David W. Cox,Rebekah Edwards,Emma Lever,Adam C. Goad,Austin Egbert,Charles Baylis,Robert J. Marks*

Main category: eess.SY

TL;DR: 本文展示了一个用于方向调制传输的微波测试平台的实现与验证，该平台使用单相控阵孔径实现多方向同时传输，缓解频谱拥塞。


<details>
  <summary>Details</summary>
Motivation: 频谱拥塞问题日益严重，需要开发能够同时传输多个通信和/或雷达信号的技术。方向调制技术允许使用单个相控阵孔径在多个方向上同时传输信号，这有助于缓解频谱资源紧张的问题。

Method: 采用双元件发射器阵列，由Xilinx ZCU208射频片上系统驱动。该测试平台为开发完全可重构的阵列发射器奠定了基础，将结合原位测量、可重构匹配电路以及用于频率和方向选择性的快速调谐算法。

Result: 成功实现并验证了方向调制微波测试平台，为多用户多输入多输出雷达和通信系统的开发提供了基础平台。

Conclusion: 该测试平台支持可重构技术的发展与验证，能够实现自适应频谱和空间共存，为未来多用户MIMO雷达和通信系统的开发提供了重要工具。

Abstract: This paper demonstrates the implementation and validation of a microwave testbed for directionally modulated transmission. Directional modulation enables multiple communication and/or radar signals to be transmitted in multiple directions simultaneously using a single phased array aperture, helping to relieve spectral congestion. A two-element transmitter array is driven by a Xilinx ZCU208 Radio Frequency System on a Chip (RFSoC). Our testbed provides a foundation for developing a fully reconfigurable array transmitter for multi-user multiple-input multiple-output (MU-MIMO) radar and communications, which will incorporate in-situ measurement, reconfigurable matching circuitry, and fast tuning algorithms for frequency and directional selectivity. This testbed enables development and validation of reconfigurable techniques for adaptive spectral and spatial coexistence.

</details>


### [160] [Curvature-Guided Safety Filters: State-Dependent Hessian-Weighted Projection with Provable Performance Bounds](https://arxiv.org/abs/2602.12603)
*Ziyan Lin,Liang Xu*

Main category: eess.SY

TL;DR: 提出一种基于Hessian引导的加权投影安全滤波器，通过动作价值函数的曲率信息优化安全修正方向，在保持安全性的同时减少长期性能损失。


<details>
  <summary>Details</summary>
Motivation: 现有安全滤波器存在两个问题：欧几里得投影忽略长期性能，而直接在安全集内优化动作价值函数又面临非凸和计算复杂的问题。需要一种既能保持凸性又能提升性能的安全滤波方法。

Method: 提出状态依赖的Hessian引导加权投影方法，根据动作价值函数的曲率选择加权投影矩阵，使安全修正偏向价值敏感度更高的动作方向。对于黑盒控制器，通过带二次特征块和正则化的迭代Q函数学习算法数据驱动地构建加权投影矩阵。

Result: 理论分析表明：(1)加权投影与安全价值最优动作之间的性能差距有统一上界；(2)在一定条件下加权投影在长期价值上优于欧几里得投影。四旋翼跟踪避障任务的仿真显示，该方法在保持安全性的同时减少了价值退化，计算开销适合实时操作。

Conclusion: 提出的Hessian引导加权投影安全滤波器在保持凸性和安全性的同时，显著改善了长期性能，为学习控制中的安全滤波提供了有效且实用的解决方案。

Abstract: Safety filters provide a lightweight mechanism for enforcing state and input safety in learning-enabled control. However, common Euclidean projections onto the safe set disregard long-term performance, while directly optimizing the action-value function within the safe set can be nonconvex and computationally prohibitive. This paper proposes a state-dependent, Hessian-guided projection for safety filtering that preserves convexity while improving performance. The key idea is to select a weighted projection matrix from the curvature of the action-value function, thereby biasing the correction toward action directions with higher value sensitivity. We establish (i) a uniform bound on the performance gap between the weighted projection and the safe value-optimal action, and (ii) a condition under which the weighted projection outperforms the Euclidean projection in long-term value. To support black-box controllers, we further present a data-driven construction of the weighted projection matrix via an iterative Q-function learning algorithm with quadratic feature blocks and regularization that enforces curvature dominance and bounded higher-order terms. Simulations on a quadrotor tracking-and-avoidance task indicate that the proposed filter maintains safety while reducing value degradation relative to Euclidean projection, with computational overhead compatible with real-time operation.

</details>


### [161] [When Environments Shift: Safe Planning with Generative Priors and Robust Conformal Prediction](https://arxiv.org/abs/2602.12616)
*Kaizer Rahaman,Jyotirmoy V. Deshmukh,Ashish R. Hota,Lars Lindemann*

Main category: eess.SY

TL;DR: 提出一个应对分布偏移的规划框架，通过条件扩散模型生成合成数据，结合鲁棒保形预测为模型预测控制提供概率安全保证


<details>
  <summary>Details</summary>
Motivation: 自主系统在部署时面临环境分布偏移问题，传统保形预测方法在训练和部署环境不一致时安全保证失效，需要能适应环境变化的鲁棒规划方法

Method: 1) 假设环境数据分布由可观测的干扰参数参数化；2) 训练条件扩散模型捕捉分布偏移；3) 在线观测干扰参数并生成合成数据；4) 设计嵌入鲁棒保形预测区域的模型预测控制器

Result: 在ORCA模拟器中实证验证了框架在多种分布偏移下的安全性，相比静态训练数据方法提供了概率安全保证

Conclusion: 提出的框架能够适应环境分布变化，通过条件扩散模型生成合成数据并结合鲁棒保形预测，为自主系统在动态环境中提供了可靠的概率安全保证

Abstract: Autonomous systems operate in environments that may change over time. An example is the control of a self-driving vehicle among pedestrians and human-controlled vehicles whose behavior may change based on factors such as traffic density, road visibility, and social norms. Therefore, the environment encountered during deployment rarely mirrors the environment and data encountered during training -- a phenomenon known as distribution shift -- which can undermine the safety of autonomous systems. Conformal prediction (CP) has recently been used along with data from the training environment to provide prediction regions that capture the behavior of the environment with a desired probability. When embedded within a model predictive controller (MPC), one can provide probabilistic safety guarantees, but only when the deployment and training environments coincide. Once a distribution shift occurs, these guarantees collapse. We propose a planning framework that is robust under distribution shifts by: (i) assuming that the underlying data distribution of the environment is parameterized by a nuisance parameter, i.e., an observable, interpretable quantity such as traffic density, (ii) training a conditional diffusion model that captures distribution shifts as a function of the nuisance parameter, (iii) observing the nuisance parameter online and generating cheap, synthetic data from the diffusion model for the observed nuisance parameter, and (iv) designing an MPC that embeds CP regions constructed from such synthetic data. Importantly, we account for discrepancies between the underlying data distribution and the diffusion model by using robust CP. Thus, the plans computed using robust CP enjoy probabilistic safety guarantees, in contrast with plans obtained from a single, static set of training data. We empirically demonstrate safety under diverse distribution shifts in the ORCA simulator.

</details>


### [162] [From Data $H(jω_i)$ to Balanced Truncation Family: A Projection-based Non-intrusive Approach](https://arxiv.org/abs/2602.12697)
*Umair Zulfiqar*

Main category: eess.SY

TL;DR: 提出了一种基于投影的数据驱动平衡截断方法，仅使用虚轴上的传递函数样本，无需谱分解，实现了多种平衡截断变体的非侵入式实现。


<details>
  <summary>Details</summary>
Motivation: 传统平衡截断方法需要系统矩阵信息，而实际应用中往往只能获得传递函数数据。本文旨在开发一种完全基于数据驱动的平衡截断框架，仅使用可测量的频率响应数据，无需系统内部信息。

Method: 通过投影方法隐式近似格拉米安矩阵，而非传统的数值积分方法。仅使用虚轴上的传递函数样本，实现了多种平衡截断变体（包括标准、频率限制、时间限制、自加权、LQG、H∞、正实、有界实和随机平衡截断）的非侵入式实现。

Result: 数值结果表明，所提出的非侵入式实现与侵入式方法性能相当，能够准确捕捉主导的汉克尔奇异值。

Conclusion: 成功开发了一种基于投影的数据驱动平衡截断框架，仅使用可测量的频率响应数据即可实现多种平衡截断方法，为实际工程应用提供了便利的非侵入式降阶工具。

Abstract: This paper presents data-driven implementations of balanced truncation and several of its generalizations that rely exclusively on transfer function samples on the imaginary axis. Rather than implicitly approximating the Gramians via numerical quadrature, the proposed approach approximates them implicitly through projection. This enables multiple members of the balanced truncation family to be implemented non-intrusively using practically measurable data, without requiring spectral factorizations. Using this projection-based framework, data-driven implementations are developed for standard balanced truncation, frequency-limited balanced truncation, time-limited balanced truncation, self-weighted balanced truncation, LQG balanced truncation, H-infinity balanced truncation, positive-real balanced truncation, bounded-real balanced truncation, and stochastic balanced truncation. Numerical results demonstrate that the proposed non-intrusive implementations achieve performance comparable to their intrusive counterparts and accurately capture the dominant Hankel singular values.

</details>


### [163] [Empirical Validation of a Dual-Defense Mechanism Reshaping Wholesale Electricity Price Dynamics in Singapore](https://arxiv.org/abs/2602.12782)
*Huang Zhenyu,Yuan Zhao*

Main category: eess.SY

TL;DR: 新加坡电力市场采用独特的双重防御机制（VC+TPC），研究发现该机制成功解耦了价格抑制与流动性风险，通过协同效应最大化市场稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究新加坡电力市场独特的双重防御机制（vesting contracts + temporary price cap），评估其如何应对价格波动，特别是解决传统价格抑制措施与流动性风险之间的权衡问题。

Method: 使用2021-2024年高频数据，分析vesting contracts（VC）的数量（VCQ）和价格（VCP）效应，以及临时价格上限（TPC）的作用。通过结构断点分析2023年改革前后的变化，并在TPC阈值附近进行诊断测试。

Result: 1. VC框架存在结构性权衡：VCQ抑制平均价格但加剧不稳定性，VCP在极端分位数起尾部风险锚定作用。2. 2023年改革后价格动态重构，报价比率对出清价格的传递效应被中和，TPC阈值附近无系统性策略性报价压低证据。3. 双重防御机制具有关键协同效应：TPC逆转了高VCQ的波动性惩罚，使条件波动弹性从0.636（不稳定）转为-0.213（稳定），实现尾部风险控制同时消除流动性相关稳定性成本。

Conclusion: 新加坡的双重防御机制成功解耦了价格抑制与流动性风险，通过VC与TPC的协同作用最大化市场稳定性，为电力市场监管提供了有效框架。

Abstract: While ex-ante screening and static price caps are global standards for mitigating price volatility, Singapore's electricity market employs a unique dual-defense mechanism integrating vesting contracts (VC) with a temporary price cap (TPC). Using high-frequency data from 2021 to 2024, this paper evaluates this mechanism and yields three primary findings. First, a structural trade-off exists within the VC framework: while VC quantity (VCQ) suppresses average prices, it paradoxically exacerbates instability via liquidity squeezes. Conversely, VC price (VCP) functions as a tail-risk anchor, dominating at extreme quantiles where VCQ efficacy wanes. Second, a structural break around the 2023 reform reveals a fundamental re-mapping of price dynamics; the previously positive pass-through from offer ratios to clearing prices was largely neutralized post-reform. Furthermore, diagnostics near the TPC threshold show no systematic evidence of strategic bid shading, confirming the TPC's operational integrity. Third, the dual-defense mechanism exhibits a critical synergy that resolves the volatility trade-off. The TPC reverses the volatility penalty of high VCQ, shifting the elasticity of conditional volatility from a destabilizing 0.636 to a stabilizing -0.213. This synergy enables the framework to enhance tail-risk control while eliminating liquidity-related stability costs. We conclude that this dual-defense mechanism successfully decouples price suppression from liquidity risks, thereby maximizing market stability.

</details>


### [164] [Data Augmentation and Attention for massive MIMO-based Indoor Localization in Changing Environments](https://arxiv.org/abs/2602.12954)
*Luisa Schuhmacher,Hazem Sallouha,Ihsane Gryech,Sofie Pollin*

Main category: eess.SY

TL;DR: 该论文针对动态室内环境中的实时定位问题，提出了两种数据增强技术和注意力模块增强的深度学习模型，在静态场景数据训练下实现了动态环境中的高精度定位。


<details>
  <summary>Details</summary>
Motivation: 随着智能环境、工业自动化和位置感知应用的发展，对高精度室内定位的需求显著增长。现有大规模MIMO系统虽然能实现毫米级精度，但大多针对静态环境优化，而实际应用中需要实时定位的动态环境存在快速移动、不可预测的遮挡和动态信道条件等挑战。

Method: 1. 引入两种模拟天线遮挡的数据增强技术，提高模型在动态场景中的泛化能力；2. 在现有深度学习模型中集成注意力模块，增强对相关信道特征和天线的关注能力；3. 使用静态场景数据结合提出的增强技术进行训练，在动态场景数据集上进行评估。

Result: 定位精度从无注意力模块和无数据增强时的平均误差286毫米，提升到使用注意力模块和数据增强时的66毫米。这表明即使没有动态场景的训练数据，也能在变化环境中保持高定位精度。

Conclusion: 通过数据增强技术和注意力模块的结合，可以在静态场景数据训练的基础上，有效应对动态室内环境中的定位挑战，实现高精度实时定位，为实际应用提供了可行的解决方案。

Abstract: The demand for high-precision indoor localization has grown significantly with the rise of smart environments, industrial automation, and location-aware applications. While massive Multiple-Input and Multiple-Output (MIMO) systems enable millimeter-level accuracy by leveraging rich Channel State Information (CSI), most existing solutions are optimized for static environments, where users or devices remain fixed during data collection and inference. Real-world applications, however, often require real-time localization in changing environments, where rapid movement, unpredictable blockages, and dynamic channel conditions pose significant challenges. To address these challenges, we introduce two data augmentation techniques designed to resemble blocked antennas, enhancing the generalizability of localization models to dynamic scenarios. Additionally, we enhance an existing Deep Learning (DL) model by incorporating attention modules, improving its ability to focus on relevant channel features and antennas. We train our model on data from a static scenario, augmented with the proposed techniques, and evaluate it on a dataset collected in changing scenarios. We investigate the performance enhancements achieved by the data augmentation techniques and the Attention modules, and observe a localization accuracy improvement from a mean error of 286 mm, when trained without Attention and without data augmentations, to 66 mm, when trained with Attention and data augmentation. This shows that high localization accuracy can be maintained in changing environments, even without training data from those scenarios.

</details>


### [165] [Bayesian Optimization Based Grid Point Allocation for LPV and Robust Control](https://arxiv.org/abs/2602.13009)
*E. Javier Olucha,Arash Sadeghzadeh,Amritam Das,Roland Tóth*

Main category: eess.SY

TL;DR: 该论文提出了一种基于贝叶斯优化的系统化方法，用于为基于网格的LPV和鲁棒控制器综合选择最优网格点，以最小化局部模型评估次数并满足全局稳定性和性能要求。


<details>
  <summary>Details</summary>
Motivation: 在基于网格的LPV和鲁棒控制器设计中，需要选择一组局部模型点来代表整个系统。传统方法往往依赖经验或均匀采样，可能导致过多的计算成本或性能不足。如何系统化地选择最优网格点，在保证全局性能的同时最小化计算成本，是一个重要问题。

Method: 采用贝叶斯优化方法来自动发现最能影响闭环性能的信息点。该方法通过迭代选择局部模型点，直到性能不再显著提升或达到用户指定的限制。特别适用于局部模型评估计算量大或难以获取的情况，能够最小化评估次数并适应可用计算预算。

Result: 在三个案例研究中验证了方法的有效性：1）不平衡磁盘的鲁棒控制器设计；2）具有不确定参数和两个柔性旋转太阳能阵列的卫星多目标鲁棒姿态控制器设计；3）机器人手臂的LPV控制器设计。结果表明该方法能够自动获得足够信息量的网格集。

Conclusion: 提出的贝叶斯优化方法能够系统化地选择最优网格点，在保证LPV和鲁棒控制器全局稳定性和性能的同时，有效减少计算成本，特别适用于局部模型评估昂贵的场景。

Abstract: This paper investigates systematic selection of optimal grid points for grid-based Linear Parameter-Varying (LPV) and robust controller synthesis. In both settings, the objective is to identify a set of local models such that the controller synthesized for these local models will satisfy global stability and performance requirements for the entire system. Here, local models correspond to evaluations of the LPV or uncertain plant at fixed values of the scheduling signal or realizations of the uncertainty set, respectively. Then, Bayesian optimization is employed to discover the most informative points that govern the closed-loop performance of the designed LPV or robust controller for the complete system until no significant further performance increase or a user specified limit is reached. Furthermore, when local model evaluations are computationally demanding or difficult to obtain, the proposed method is capable to minimize the number of evaluations and adjust the overall computational cost to the available budget. Lastly, the capabilities of the proposed method in automatically obtaining a sufficiently informative grid set are demonstrated on three case-studies: a robust controller design for an unbalanced disk, a multi-objective robust attitude controller design for a satellite with uncertain parameters and two flexible rotating solar arrays, and an LPV controller design for a robotic arm.

</details>


### [166] [Encoder initialisation methods in the model augmentation setting](https://arxiv.org/abs/2602.13108)
*J. H. Hoekstra,B. Györök,R. Töth,M. Schoukens*

Main category: eess.SY

TL;DR: 本文提出基于基线模型的新型编码器初始化方法，用于非线性系统辨识中的ANN状态空间模型，相比黑盒初始化具有更好的噪声鲁棒性和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有的编码器方法虽然提高了计算效率，但编码器仍被视为黑盒函数，而基线模型包含可用于预测模型状态的额外信息。为了利用这些信息提高性能，需要开发基于基线模型的编码器初始化方法。

Method: 提出基于可用基线模型的新型编码器初始化方法，利用基线模型从过去的输入输出数据中预测模型状态，而不是使用黑盒函数进行初始化。

Result: 在质量-弹簧-阻尼器系统上的实验表明，提出的初始化方法相比黑盒初始化具有更好的噪声鲁棒性和更快的收敛速度。

Conclusion: 通过利用基线模型信息进行编码器初始化，可以显著提高非线性系统辨识中ANN状态空间模型的性能，为模型增强方法提供了更有效的实现途径。

Abstract: Nonlinear system identification (NL-SI) has proven to be effective in obtaining accurate models for highly complex systems. Recent encoder-based methods for artificial neural network state-space (ANN-SS) models have shown state-of-the-art performance with improved computational efficiency, where the encoder is used to estimate the initial state allowing for batch optimisation methods. To address the lack of interpretability of these black-box ANN models, model augmentation approaches can be used. These combine prior available baseline models with the ANN learning components, resulting in faster convergence and more interpretable models. The combination of the encoder-based method with model augmentation has shown potential. Thus far, however, the encoder has still been treated as a black-box function in the overall estimation process, while additional information in the form of the baseline model is available to predict the model state from past input-output data. In this paper, we propose novel encoder initialisation approaches based on the available baseline model, resulting in improved noise robustness and faster convergence compared to black-box initialisation. The performance of these initialisation methods is demonstrated on a mass-spring-damper system.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [167] [Provably Convergent Actor-Critic in Risk-averse MARL](https://arxiv.org/abs/2602.12386)
*Yizhou Zhang,Eric Mazumdar*

Main category: cs.MA

TL;DR: 本文提出了一种在无限时域一般和马尔可夫博弈中学习平稳策略的新方法，通过引入风险厌恶量化响应均衡(RQE)解决传统均衡计算困难的问题，并设计了双时间尺度Actor-Critic算法实现全局收敛。


<details>
  <summary>Details</summary>
Motivation: 在无限时域一般和马尔可夫博弈中学习平稳策略是MARL领域的基本开放问题。虽然平稳策略具有实用性，但计算经典博弈论均衡的平稳形式在计算上是不可行的，这与解决单智能体RL或零和博弈的相对容易形成鲜明对比。

Method: 引入风险厌恶量化响应均衡(RQE)作为解决方案概念，该概念源于行为博弈理论，结合了风险厌恶和有限理性。提出了一种新颖的双时间尺度Actor-Critic算法，具有快速时间尺度的actor和慢速时间尺度的critic。

Result: RQE具有强大的正则性条件，使其特别适合在马尔可夫博弈中学习。利用RQE的正则性，证明了该方法能够实现全局收敛并具有有限样本保证。在多个环境中进行了实证验证，显示出相比风险中性基线的优越收敛特性。

Conclusion: RQE为解决无限时域一般和马尔可夫博弈中学习平稳策略的开放问题提供了有效的解决方案，双时间尺度Actor-Critic算法能够实现理论保证的全局收敛，为MARL领域提供了新的实用方法。

Abstract: Learning stationary policies in infinite-horizon general-sum Markov games (MGs) remains a fundamental open problem in Multi-Agent Reinforcement Learning (MARL). While stationary strategies are preferred for their practicality, computing stationary forms of classic game-theoretic equilibria is computationally intractable -- a stark contrast to the comparative ease of solving single-agent RL or zero-sum games. To bridge this gap, we study Risk-averse Quantal response Equilibria (RQE), a solution concept rooted in behavioral game theory that incorporates risk aversion and bounded rationality. We demonstrate that RQE possesses strong regularity conditions that make it uniquely amenable to learning in MGs. We propose a novel two-timescale Actor-Critic algorithm characterized by a fast-timescale actor and a slow-timescale critic. Leveraging the regularity of RQE, we prove that this approach achieves global convergence with finite-sample guarantees. We empirically validate our algorithm in several environments to demonstrate superior convergence properties compared to risk-neutral baselines.

</details>


### [168] [Theory of Mind Guided Strategy Adaptation for Zero-Shot Coordination](https://arxiv.org/abs/2602.12458)
*Andrew Ni,Simon Stepputtis,Stefanos Nikolaidis,Michael Lewis,Katia P. Sycara,Woojun Kim*

Main category: cs.MA

TL;DR: 本文提出了一种自适应集成智能体方法，通过基于心智理论的最佳响应选择来推断队友意图，并从策略集合中选择最合适的策略，以提升零样本协调性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的核心挑战是使智能体能够以零样本方式适应先前未见过的队友。现有零样本协调工作通常采用两阶段过程：首先生成多样化的训练伙伴智能体池，然后训练最佳响应智能体与整个训练池有效协作。虽然先前工作通过设计更好的伙伴智能体池多样化方法取得了良好性能，但较少关注如何利用这个池来构建自适应智能体。一个局限性在于最佳响应智能体可能收敛到静态的通用策略，而不是学习更具适应性的专业策略。

Method: 提出自适应集成智能体方法，使用基于心智理论的最佳响应选择：首先推断队友的意图，然后从策略集合中选择最合适的策略。在Overcooked环境中进行实验，评估完全可观测和部分可观测设置下的零样本协调性能。

Result: 实证结果表明，该方法在零样本协调性能上优于单一最佳响应基线方法。

Conclusion: 通过自适应集成智能体方法，能够更好地适应不同队友并实现更高协同，解决了传统最佳响应方法可能收敛到静态通用策略而非自适应专业策略的问题。

Abstract: A central challenge in multi-agent reinforcement learning is enabling agents to adapt to previously unseen teammates in a zero-shot fashion. Prior work in zero-shot coordination often follows a two-stage process, first generating a diverse training pool of partner agents, and then training a best-response agent to collaborate effectively with the entire training pool. While many previous works have achieved strong performance by devising better ways to diversify the partner agent pool, there has been less emphasis on how to leverage this pool to build an adaptive agent. One limitation is that the best-response agent may converge to a static, generalist policy that performs reasonably well across diverse teammates, rather than learning a more adaptive, specialist policy that can better adapt to teammates and achieve higher synergy. To address this, we propose an adaptive ensemble agent that uses Theory-of-Mind-based best-response selection to first infer its teammate's intentions and then select the most suitable policy from a policy ensemble. We conduct experiments in the Overcooked environment to evaluate zero-shot coordination performance under both fully and partially observable settings. The empirical results demonstrate the superiority of our method over a single best-response baseline.

</details>


### [169] [Building Large-Scale Drone Defenses from Small-Team Strategies](https://arxiv.org/abs/2602.12502)
*Grant Douglas,Stephen Franklin,Claudia Szabo,Mingyu Guo*

Main category: cs.MA

TL;DR: 提出一个框架，通过将小团队有效策略作为模块化组件集成到大型防御力量中，使用动态规划分解在多项式时间内组装大型团队，实现对抗大规模无人机群的规模化防御。


<details>
  <summary>Details</summary>
Motivation: 防御大规模对抗性无人机群需要超越传统多智能体优化的协调方法，现有小团队防御策略难以直接扩展到大规模场景。

Method: 提出模块化框架：将小团队有效策略作为组件，通过动态规划分解在多项式时间内组装大型团队；采样多个小团队候选策略，迭代评估大型团队结果并优化模块组件池。

Result: 实验表明该方法能扩展到更大规模场景，同时保持有效性，并能发现直接优化无法可靠揭示的合作行为。

Conclusion: 通过模块化组件和动态规划分解的方法，实现了对抗大规模无人机群防御策略的有效规模化，解决了传统方法难以扩展的问题。

Abstract: Defending against large adversarial drone swarms requires coordination methods that scale effectively beyond conventional multi-agent optimisation. In this paper, we propose to scale strategies proven effective in small defender teams by integrating them as modular components of larger forces using our proposed framework. A dynamic programming (DP) decomposition assembles these components into large teams in polynomial time, enabling efficient construction of scalable defenses without exhaustive evaluation. Because a unit that is strong in isolation may not remain strong when combined, we sample across multiple small-team candidates. Our framework iterates between evaluating large-team outcomes and refining the pool of modular components, allowing convergence on increasingly effective strategies. Experiments demonstrate that this partitioning approach scales to substantially larger scenarios while preserving effectiveness and revealing cooperative behaviours that direct optimisation cannot reliably discover.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [170] [LatentAM: Real-Time, Large-Scale Latent Gaussian Attention Mapping via Online Dictionary Learning](https://arxiv.org/abs/2602.12314)
*Junwoon Lee,Yulun Tian*

Main category: cs.RO

TL;DR: LatentAM是一个在线3D高斯泼溅建图框架，通过流式RGB-D观测构建可扩展的潜在特征地图，用于开放词汇机器人感知，无需特定模型解码器，支持即插即用不同视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用模型特定的解码器来提取高维视觉语言模型嵌入，这限制了灵活性和可扩展性。需要一种模型无关、无需预训练的方法，能够在测试时即插即用不同视觉语言模型，同时适应动态场景语义变化。

Method: 提出在线字典学习方法，将每个高斯基元与紧凑查询向量关联，通过注意力机制和可学习字典转换为近似视觉语言模型嵌入。字典从流式观测高效初始化，在信任域正则化下在线优化以适应场景语义。采用基于体素哈希的高效地图管理策略，GPU上优化局部活跃地图，CPU上存储全局地图以控制内存使用。

Result: 在公开基准测试和大型自定义数据集上的实验表明，LatentAM相比最先进方法显著提高了特征重建保真度，同时在评估数据集上达到接近实时的速度（12-35 FPS）。

Conclusion: LatentAM提供了一个高效、可扩展的在线3D建图框架，支持开放词汇机器人感知，具有模型无关性、无需预训练和即插即用特性，在保持实时性能的同时显著提升了特征重建质量。

Abstract: We present LatentAM, an online 3D Gaussian Splatting (3DGS) mapping framework that builds scalable latent feature maps from streaming RGB-D observations for open-vocabulary robotic perception. Instead of distilling high-dimensional Vision-Language Model (VLM) embeddings using model-specific decoders, LatentAM proposes an online dictionary learning approach that is both model-agnostic and pretraining-free, enabling plug-and-play integration with different VLMs at test time. Specifically, our approach associates each Gaussian primitive with a compact query vector that can be converted into approximate VLM embeddings using an attention mechanism with a learnable dictionary. The dictionary is initialized efficiently from streaming observations and optimized online to adapt to evolving scene semantics under trust-region regularization. To scale to long trajectories and large environments, we further propose an efficient map management strategy based on voxel hashing, where optimization is restricted to an active local map on the GPU, while the global map is stored and indexed on the CPU to maintain bounded GPU memory usage. Experiments on public benchmarks and a large-scale custom dataset demonstrate that LatentAM attains significantly better feature reconstruction fidelity compared to state-of-the-art methods, while achieving near-real-time speed (12-35 FPS) on the evaluated datasets. Our project page is at: https://junwoonlee.github.io/projects/LatentAM

</details>


### [171] [ForeAct: Steering Your VLA with Efficient Visual Foresight Planning](https://arxiv.org/abs/2602.12322)
*Zhuoyang Zhang,Shang Yang,Qinghao Hu,Luke J. Huang,James Hou,Yufei Sun,Yao Lu,Song Han*

Main category: cs.RO

TL;DR: ForeAct是一种视觉前瞻规划器，通过生成未来观测图像来指导VLA模型执行多步骤任务，在11个真实世界任务中达到87.4%的平均成功率


<details>
  <summary>Details</summary>
Motivation: 在开放世界环境中，VLA模型将高级语言指令转换为具体可执行动作具有挑战性，需要更好的规划能力来提升准确性和泛化能力

Method: 提出视觉前瞻规划框架，包含高效的前瞻图像生成模块（0.33秒内生成640×480未来观测）和视觉语言推理模块，通过想象未来观测让VLA专注于视觉运动推理而非高级语义推理

Result: 在11个多样化多步骤真实世界任务基准测试中，平均成功率达到87.4%，相比基线π0（46.5%）提升40.9%，相比带文本子任务指导的π0（57.1%）提升30.3%

Conclusion: ForeAct通过视觉前瞻规划显著提升了VLA模型在复杂任务中的性能，且无需修改现有VLA架构，只需增强其视觉输入即可无缝集成

Abstract: Vision-Language-Action (VLA) models convert high-level language instructions into concrete, executable actions, a task that is especially challenging in open-world environments. We present Visual Foresight Planning (ForeAct), a general and efficient planner that guides a VLA step-by-step using imagined future observations and subtask descriptions. With an imagined future observation, the VLA can focus on visuo-motor inference rather than high-level semantic reasoning, leading to improved accuracy and generalization. Our planner comprises a highly efficient foresight image generation module that predicts a high-quality 640$\times$480 future observation from the current visual input and language instruction within only 0.33s on an H100 GPU, together with a vision-language model that reasons over the task and produces subtask descriptions for both the generator and the VLA. Importantly, state-of-the-art VLAs can integrate our planner seamlessly by simply augmenting their visual inputs, without any architectural modification. The foresight generator is pretrained on over 1 million multi-task, cross-embodiment episodes, enabling it to learn robust embodied dynamics. We evaluate our framework on a benchmark that consists of 11 diverse, multi-step real-world tasks. It achieves an average success rate of 87.4%, demonstrating a +40.9% absolute improvement over the $π_0$ baseline (46.5%) and a +30.3% absolute improvement over $π_0$ augmented with textual subtask guidance (57.1%).

</details>


### [172] [Schur-MI: Fast Mutual Information for Robotic Information Gathering](https://arxiv.org/abs/2602.12346)
*Kalvik Jakkala,Jason O'Kane,Srinivas Akella*

Main category: cs.RO

TL;DR: Schur-MI：一种基于Schur补分解的高斯过程互信息计算方法，显著降低机器人信息采集中的计算成本，实现实时规划


<details>
  <summary>Details</summary>
Motivation: 互信息（MI）是机器人信息采集（RIG）的理论基础，但传统MI计算成本过高（O(|V|³)），限制了其在实时规划中的应用

Method: 提出Schur-MI方法：1）利用RIG的迭代结构预计算和重用中间结果；2）使用Schur补分解避免大型行列式计算，将计算复杂度从O(|V|³)降至O(|A|³)

Result: 在真实世界测深数据集上，Schur-MI比标准MI实现12.7倍加速；通过自主水面航行器（ASV）的自适应信息路径规划现场试验验证了实用性

Conclusion: Schur-MI使MI计算在在线规划中变得可行，有助于弥合信息论目标与实时机器人探索之间的差距

Abstract: Mutual information (MI) is a principled and widely used objective for robotic information gathering (RIG), providing strong theoretical guarantees for sensor placement (SP) and informative path planning (IPP). However, its high computational cost, dominated by repeated log-determinant evaluations, has limited its use in real-time planning. This letter presents Schur-MI, a Gaussian process (GP) MI formulation that (i) leverages the iterative structure of RIG to precompute and reuse expensive intermediate quantities across planning steps, and (ii) uses a Schur-complement factorization to avoid large determinant computations. Together, these methods reduce the per-evaluation cost of MI from $\mathcal{O}(|\mathcal{V}|^3)$ to $\mathcal{O}(|\mathcal{A}|^3)$, where $\mathcal{V}$ and $\mathcal{A}$ denote the candidate and selected sensing locations, respectively. Experiments on real-world bathymetry datasets show that Schur-MI achieves up to a $12.7\times$ speedup over the standard MI formulation. Field trials with an autonomous surface vehicle (ASV) performing adaptive IPP further validate its practicality. By making MI computation tractable for online planning, Schur-MI helps bridge the gap between information-theoretic objectives and real-time robotic exploration.

</details>


### [173] [LongNav-R1: Horizon-Adaptive Multi-Turn RL for Long-Horizon VLA Navigation](https://arxiv.org/abs/2602.12351)
*Yue Hu,Avery Xi,Qixin Xiao,Seth Isaacson,Henry X. Liu,Ram Vasudevan,Maani Ghaffari*

Main category: cs.RO

TL;DR: LongNav-R1是一个端到端多轮强化学习框架，用于优化视觉-语言-动作模型在长视野导航任务中的性能，通过多轮对话式交互和自适应策略优化显著提升导航成功率。


<details>
  <summary>Details</summary>
Motivation: 现有单轮范式在长视野导航中存在局限性，无法有效处理历史交互的因果效应和序列未来结果，且依赖人类演示导致行为僵化。

Method: 1) 将导航决策过程重新定义为VLA策略与具身环境之间的连续多轮对话；2) 引入视野自适应策略优化机制，在优势估计中考虑不同视野长度，实现准确的时间信用分配。

Result: 在物体导航基准测试中，仅用4,000条轨迹就将Qwen3-VL-2B的成功率从64.3%提升到73.0%，表现出卓越的样本效率和优于现有方法的表现，并在零样本真实世界导航中验证了泛化性和鲁棒性。

Conclusion: LongNav-R1通过多轮RL框架和视野自适应策略优化，有效解决了长视野导航中的挑战，显著提升了VLA模型的导航性能，代码将开源。

Abstract: This paper develops LongNav-R1, an end-to-end multi-turn reinforcement learning (RL) framework designed to optimize Visual-Language-Action (VLA) models for long-horizon navigation. Unlike existing single-turn paradigm, LongNav-R1 reformulates the navigation decision process as a continuous multi-turn conversation between the VLA policy and the embodied environment. This multi-turn RL framework offers two distinct advantages: i) it enables the agent to reason about the causal effects of historical interactions and sequential future outcomes; and ii) it allows the model to learn directly from online interactions, fostering diverse trajectory generation and avoiding the behavioral rigidity often imposed by human demonstrations. Furthermore, we introduce Horizon-Adaptive Policy Optimization. This mechanism explicitly accounts for varying horizon lengths during advantage estimation, facilitating accurate temporal credit assignment over extended sequences. Consequently, the agent develops diverse navigation behaviors and resists collapse during long-horizon tasks. Experiments on object navigation benchmarks validate the framework's efficacy: With 4,000 rollout trajectories, LongNav-R1 boosts the Qwen3-VL-2B success rate from 64.3% to 73.0%. These results demonstrate superior sample efficiency and significantly outperform state-of-the-art methods. The model's generalizability and robustness are further validated by its zero-shot performance in long-horizon real-world navigation settings. All source code will be open-sourced upon publication.

</details>


### [174] [Predicting Dynamic Map States from Limited Field-of-View Sensor Data](https://arxiv.org/abs/2602.12360)
*Knut Peterson,David Han*

Main category: cs.RO

TL;DR: 使用深度学习从有限视场时间序列数据预测动态地图状态，通过将时空信息编码为单图像格式，利用现有图像到图像学习模型实现高精度预测


<details>
  <summary>Details</summary>
Motivation: 自主系统在真实场景中部署时，传感器常受限于视场约束（设计限制或意外遮挡/故障），需要基于有限数据推断环境信息并预测周围状态以保持安全准确运行

Method: 将动态传感器数据表示为简单的单图像格式，该格式同时捕获空间和时间信息，然后利用各种现有的图像到图像学习模型来预测地图状态

Result: 在多种传感场景中，该方法能够以高精度预测地图状态，证明了深度学习在有限视场时间序列数据下进行动态地图状态预测的有效性

Conclusion: 通过将时空信息编码为单图像表示，可以利用现有图像到图像学习模型有效地从有限视场数据中预测动态地图状态，为自主系统在传感器受限条件下的安全运行提供解决方案

Abstract: When autonomous systems are deployed in real-world scenarios, sensors are often subject to limited field-of-view (FOV) constraints, either naturally through system design, or through unexpected occlusions or sensor failures. In conditions where a large FOV is unavailable, it is important to be able to infer information about the environment and predict the state of nearby surroundings based on available data to maintain safe and accurate operation. In this work, we explore the effectiveness of deep learning for dynamic map state prediction based on limited FOV time series data. We show that by representing dynamic sensor data in a simple single-image format that captures both spatial and temporal information, we can effectively use a wide variety of existing image-to-image learning models to predict map states with high accuracy in a diverse set of sensing scenarios.

</details>


### [175] [Zero-Shot Adaptation to Robot Structural Damage via Natural Language-Informed Kinodynamics Modeling](https://arxiv.org/abs/2602.12385)
*Anuj Pokhrel,Aniket Datar,Mohammad Nazeri,Francesco Cancelliere,Xuesu Xiao*

Main category: cs.RO

TL;DR: 提出ZLIK方法，使用自然语言描述结构损伤，通过自监督学习将损伤语义信息与运动动力学行为关联，实现零样本适应不同损伤类型的运动动力学建模


<details>
  <summary>Details</summary>
Motivation: 自主移动机器人在野外操作中承受巨大机械应力，结构损伤不可避免。由于损伤类型多样，量化各种损伤对运动动力学的影响具有挑战性。作者认为自然语言可以描述和捕捉这种损伤多样性。

Method: 提出零样本语言信息运动动力学（ZLIK）方法，采用自监督学习将损伤描述的语义信息与运动动力学行为关联，以数据驱动方式学习前向运动动力学模型。使用BeamNG.tech高保真软体物理模拟器收集各种结构受损车辆的数据。

Result: 学习模型实现了对不同损伤的零样本适应，运动动力学误差减少高达81%，并在模拟到现实以及全尺寸到1/10比例尺的泛化中表现良好。

Conclusion: 自然语言描述能够有效捕捉结构损伤的多样性，ZLIK方法通过将语义信息与运动动力学行为关联，实现了对多种损伤类型的零样本适应和跨域泛化。

Abstract: High-performance autonomous mobile robots endure significant mechanical stress during in-the-wild operations, e.g., driving at high speeds or over rugged terrain. Although these platforms are engineered to withstand such conditions, mechanical degradation is inevitable. Structural damage manifests as consistent and notable changes in kinodynamic behavior compared to a healthy vehicle. Given the heterogeneous nature of structural failures, quantifying various damages to inform kinodynamics is challenging. We posit that natural language can describe and thus capture this variety of damages. Therefore, we propose Zero-shot Language Informed Kinodynamics (ZLIK), which employs self-supervised learning to ground semantic information of damage descriptions in kinodynamic behaviors to learn a forward kinodynamics model in a data-driven manner. Using the high-fidelity soft-body physics simulator BeamNG.tech, we collect data from a variety of structurally compromised vehicles. Our learned model achieves zero-shot adaptation to different damages with up to 81% reduction in kinodynamics error and generalizes across the sim-to-real and full-to-1/10$^{\text{th}}$ scale gaps.

</details>


### [176] [Self-Refining Vision Language Model for Robotic Failure Detection and Reasoning](https://arxiv.org/abs/2602.12405)
*Carl Qi,Xiaojie Wang,Silong Yong,Stephen Sheng,Huitan Mao,Sriram Srinivasan,Manikantan Nambi,Amy Zhang,Yesh Dattatreya*

Main category: cs.RO

TL;DR: ARMOR：一种用于机器人故障检测和推理的自适应多轮多任务模型，通过多轮自精炼过程处理开放式故障推理，利用异构监督学习，在推理时生成多个精炼轨迹并选择最自信的预测。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人故障通常很微妙、组合性强且难以枚举，而丰富的推理标签获取成本高昂。现有方法要么将故障推理视为封闭集分类问题，要么假设有充足的人工标注，无法有效处理开放式故障推理问题。

Method: 将检测和推理建模为多任务自精炼过程，模型迭代预测检测结果和自然语言推理。训练时利用异构监督（大规模稀疏二元标签和小规模丰富推理标注），通过离线和在线模仿学习优化。推理时生成多个精炼轨迹，通过自确定性度量选择最自信的预测。

Result: 在多样化环境中，ARMOR实现了最先进的性能：故障检测率比先前方法提高达30%，通过LLM模糊匹配分数衡量的推理能力提高达100%，展现出对异构监督和超越预定义故障模式的开放式推理的鲁棒性。

Conclusion: ARMOR通过多轮自精炼框架有效解决了机器人故障检测和推理问题，能够处理开放式故障模式并利用异构监督，在性能和鲁棒性方面显著优于现有方法。

Abstract: Reasoning about failures is crucial for building reliable and trustworthy robotic systems. Prior approaches either treat failure reasoning as a closed-set classification problem or assume access to ample human annotations. Failures in the real world are typically subtle, combinatorial, and difficult to enumerate, whereas rich reasoning labels are expensive to acquire. We address this problem by introducing ARMOR: Adaptive Round-based Multi-task mOdel for Robotic failure detection and reasoning. We formulate detection and reasoning as a multi-task self-refinement process, where the model iteratively predicts detection outcomes and natural language reasoning conditioned on past outputs. During training, ARMOR learns from heterogeneous supervision - large-scale sparse binary labels and small-scale rich reasoning annotations - optimized via a combination of offline and online imitation learning. At inference time, ARMOR generates multiple refinement trajectories and selects the most confident prediction via a self-certainty metric. Experiments across diverse environments show that ARMOR achieves state-of-the-art performance by improving over the previous approaches by up to 30% on failure detection rate and up to 100% in reasoning measured through LLM fuzzy match score, demonstrating robustness to heterogeneous supervision and open-ended reasoning beyond predefined failure modes. We provide dditional visualizations on our website: https://sites.google.com/utexas.edu/armor

</details>


### [177] [MiDAS: A Multimodal Data Acquisition System and Dataset for Robot-Assisted Minimally Invasive Surgery](https://arxiv.org/abs/2602.12407)
*Keshara Weerasinghe,Seyed Hamid Reza Roodabeh,Andrew Hawkins,Zhaomeng Zhang,Zachary Schrader,Homa Alemzadeh*

Main category: cs.RO

TL;DR: MiDAS是一个开源、平台无关的系统，通过非侵入式多模态数据采集（手部追踪、脚踏板传感、手术视频）来解决手术机器人研究中获取专有遥测数据的障碍。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助微创手术研究依赖多模态数据，但获取专有机器人遥测数据存在重大障碍，需要一种不依赖专有接口的解决方案。

Method: MiDAS整合电磁和RGB-D手部追踪、脚踏板传感和手术视频采集，无需专有机器人接口。在开源Raven-II和临床da Vinci Xi上验证，收集了手术住院医师执行peg transfer和疝修补缝合任务的多模态数据集。

Result: 外部手部和脚踏传感与内部机器人运动学高度相关，非侵入式运动信号在手势识别性能上与专有遥测数据相当。

Conclusion: MiDAS实现了可重复的多模态RMIS数据采集，并发布了带标注的数据集，包括首个在高保真模拟模型上捕获疝修补缝合的多模态数据集。

Abstract: Background: Robot-assisted minimally invasive surgery (RMIS) research increasingly relies on multimodal data, yet access to proprietary robot telemetry remains a major barrier. We introduce MiDAS, an open-source, platform-agnostic system enabling time-synchronized, non-invasive multimodal data acquisition across surgical robotic platforms.
  Methods: MiDAS integrates electromagnetic and RGB-D hand tracking, foot pedal sensing, and surgical video capturing without requiring proprietary robot interfaces. We validated MiDAS on the open-source Raven-II and the clinical da Vinci Xi by collecting multimodal datasets of peg transfer and hernia repair suturing tasks performed by surgical residents. Correlation analysis and downstream gesture recognition experiments were conducted.
  Results: External hand and foot sensing closely approximated internal robot kinematics and non-invasive motion signals achieved gesture recognition performance comparable to proprietary telemetry.
  Conclusion: MiDAS enables reproducible multimodal RMIS data collection and is released with annotated datasets, including the first multimodal dataset capturing hernia repair suturing on high-fidelity simulation models.

</details>


### [178] [Control Barrier Functions with Audio Risk Awareness for Robot Safe Navigation on Construction Sites](https://arxiv.org/abs/2602.12416)
*Johannes Mootz,Reza Akhavian*

Main category: cs.RO

TL;DR: 该研究提出了一种基于控制屏障函数的安全滤波器，通过音频感知（电镐检测）来调节安全边界，为施工环境中的自主移动机器人提供安全保证。


<details>
  <summary>Details</summary>
Motivation: 施工环境动态且视觉遮挡严重，传统感知方法受限。音频信息在自主系统中未充分利用，需要多模态安全推理来增强机器人在安全关键环境中的安全性。

Method: 采用控制屏障函数安全滤波器，集成基于信号包络和周期性的轻量级实时电镐检测器。音频检测输出作为外部风险信号，通过调节屏障函数直接作用于控制器。评估了圆形和面向目标的椭圆形两种CBF公式。

Result: CBF安全滤波器在所有试验中消除了安全违规。目标到达率：圆形CBF为40.2%，椭圆形CBF为76.5%。椭圆形公式能更好地避免死锁。

Conclusion: 将音频感知集成到CBF控制器中，为自主机器人在安全关键和动态环境中实现更丰富的多模态安全推理提供了可行路径。

Abstract: Construction automation increasingly requires autonomous mobile robots, yet robust autonomy remains challenging on construction sites. These environments are dynamic and often visually occluded, which complicates perception and navigation. In this context, valuable information from audio sources remains underutilized in most autonomy stacks. This work presents a control barrier function (CBF)-based safety filter that provides safety guarantees for obstacle avoidance while adapting safety margins during navigation using an audio-derived risk cue. The proposed framework augments the CBF with a lightweight, real-time jackhammer detector based on signal envelope and periodicity. Its output serves as an exogenous risk that is directly enforced in the controller by modulating the barrier function. The approach is evaluated in simulation with two CBF formulations (circular and goal-aligned elliptical) with a unicycle robot navigating a cluttered construction environment. Results show that the CBF safety filter eliminates safety violations across all trials while reaching the target in 40.2% (circular) vs. 76.5% (elliptical), as the elliptical formulation better avoids deadlock. This integration of audio perception into a CBF-based controller demonstrates a pathway toward richer multimodal safety reasoning in autonomous robots for safety-critical and dynamic environments.

</details>


### [179] [An Autonomous, End-to-End, Convex-Based Framework for Close-Range Rendezvous Trajectory Design and Guidance with Hardware Testbed Validation](https://arxiv.org/abs/2602.12421)
*Minduli C. Wijayatunga,Julian Guinane,Nathan D. Wallace,Xiaofeng Wu*

Main category: cs.RO

TL;DR: CORTEX是一个用于近距离交会对接的自主感知实时轨迹设计与制导框架，结合深度学习感知与凸优化轨迹设计，具备参考轨迹重生成和紧急安全轨道规避逻辑。


<details>
  <summary>Details</summary>
Motivation: 自主卫星服务任务需要在严格的安全和操作约束下执行近距离交会对接，同时保持计算可行性以适应机载使用，并对感知、执行和动力学的不确定性具有鲁棒性。

Method: CORTEX框架整合了深度学习感知管道与凸优化轨迹设计和制导，包括参考轨迹重生成和紧急安全轨道规避逻辑，以应对传感器故障和发动机故障导致的大偏差。

Result: 在高保真软件仿真和硬件在环实验中验证：软件仿真在最严苛情况下实现终端对接误差36.85±44.46 mm（位置）和1.25±2.26 mm/s（速度）；平面气浮测试台实验中，终端误差为8.09±5.29 mm（位置）和2.23±1.72 mm/s（速度）。

Conclusion: CORTEX框架为自主近距离交会对接提供了一个鲁棒的实时轨迹设计与制导解决方案，能够有效处理传感器和执行器故障，在仿真和硬件实验中均表现出良好的性能。

Abstract: Autonomous satellite servicing missions must execute close-range rendezvous under stringent safety and operational constraints while remaining computationally tractable for onboard use and robust to uncertainty in sensing, actuation, and dynamics. This paper presents CORTEX (Convex Optimization for Rendezvous Trajectory Execution), an autonomous, perception-enabled, real-time trajectory design and guidance framework for close-range rendezvous. CORTEX integrates a deep-learning perception pipeline with convex-optimisation-based trajectory design and guidance, including reference regeneration and abort-to-safe-orbit logic to recover from large deviations caused by sensor faults and engine failures.
  CORTEX is validated in high-fidelity software simulation and hardware-in-the-loop experiments. The software pipeline (Basilisk) models high-fidelity relative dynamics, realistic thruster execution, perception, and attitude control. Hardware testing uses (i) an optical navigation testbed to assess perception-to-estimation performance and (ii) a planar air-bearing testbed to evaluate the end-to-end guidance loop under representative actuation and subsystem effects. A Monte-Carlo campaign in simulation includes initial-state uncertainty, thrust-magnitude errors, and missed-thrust events; under the strongest case investigated, CORTEX achieves terminal docking errors of $36.85 \pm 44.46$ mm in relative position and $1.25 \pm 2.26$ mm/s in relative velocity. On the planar air-bearing testbed, 18 cases are executed (10 nominal; 8 off-nominal requiring recomputation and/or abort due to simulated engine failure and sensor malfunctions), yielding terminal errors of $8.09 \pm 5.29$ mm in position and $2.23 \pm 1.72$ mm/s in velocity.

</details>


### [180] [Gradient-Enhanced Partitioned Gaussian Processes for Real-Time Quadrotor Dynamics Modeling](https://arxiv.org/abs/2602.12487)
*Xinhuan Sang,Adam Rozman,Sheryl Grace,Roberto Tron*

Main category: cs.RO

TL;DR: 提出一种结合梯度信息的四旋翼动力学高斯过程模型，通过状态空间分区和近似实现实时推理，并利用中保真度势流模拟数据捕捉空气动力学效应。


<details>
  <summary>Details</summary>
Motivation: 传统基于高斯过程的方法虽然能提供可靠的贝叶斯预测和不确定性量化，但计算成本高昂，不适合实时仿真。需要一种既能保持准确性又能实现实时推理的方法。

Method: 1) 集成梯度信息提高准确性；2) 引入新颖的分区和近似策略降低在线计算成本：为每个非重叠区域关联局部高斯过程，通过将训练数据分为局部近远子集并使用舒尔补，大部分矩阵求逆可离线完成；3) 使用CHARM中保真度空气动力学求解器生成包含空气动力学效应的训练数据集；4) 通过有限差分获取导数信息。

Result: 提出的分区高斯过程结合梯度条件比标准无梯度信息的分区高斯过程具有更高准确性，同时在标准桌面硬件上实现超过30Hz的实时推理频率，大大减少了计算时间。

Conclusion: 该框架为复杂非稳态环境中的实时空气动力学预测和控制算法提供了高效基础，实现了准确性、计算效率和实时性能的良好平衡。

Abstract: We present a quadrotor dynamics Gaussian Process (GP) with gradient information that achieves real-time inference via state-space partitioning and approximation, and that includes aerodynamic effects using data from mid-fidelity potential flow simulations. While traditional GP-based approaches provide reliable Bayesian predictions with uncertainty quantification, they are computationally expensive and thus unsuitable for real-time simulations. To address this challenge, we integrate gradient information to improve accuracy and introduce a novel partitioning and approximation strategy to reduce online computational cost. In particular, for the latter, we associate a local GP with each non-overlapping region; by splitting the training data into local near and far subsets, and by using Schur complements, we show that a large part of the matrix inversions required for inference can be performed offline, enabling real-time inference at frequencies above 30 Hz on standard desktop hardware. To generate a training dataset that captures aerodynamic effects, such as rotor-rotor interactions and apparent wind direction, we use the CHARM code, which is a mid-fidelity aerodynamic solver. It is applied to the SUI Endurance quadrotor to predict force and torque, along with noise at three specified locations. The derivative information is obtained via finite differences. Experimental results demonstrate that the proposed partitioned GP with gradient conditioning achieves higher accuracy than standard partitioned GPs without gradient information, while greatly reducing computational time. This framework provides an efficient foundation for real-time aerodynamic prediction and control algorithms in complex and unsteady environments.

</details>


### [181] [Composable Model-Free RL for Navigation with Input-Affine Systems](https://arxiv.org/abs/2602.12492)
*Xinhuan Sang,Abdelrahman Abdelgawad,Roberto Tron*

Main category: cs.RO

TL;DR: 提出一种可组合的无模型强化学习方法，通过为每个环境元素学习独立的价值函数和最优策略，在线组合实现目标到达和避障，提供形式化避障保证。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在复杂动态环境中需要实时安全导航，但预测所有可能行为不可行。现有方法难以在未知非线性动态系统中提供形式化安全保证。

Method: 基于连续时间HJB方程推导价值函数结构，提出无模型actor-critic算法学习静态或移动障碍物的策略和价值函数，通过QCQP组合多个到达/避障模型。

Result: 方法在仿真中相比应用于离散时间近似的PPO基线表现出改进性能，提供基于价值函数水平集的形式化避障保证。

Conclusion: 提出了一种可组合的无模型强化学习框架，为连续时间非线性系统提供形式化安全保证，是CLF/CBF控制器的无模型替代方案。

Abstract: As autonomous robots move into complex, dynamic real-world environments, they must learn to navigate safely in real time, yet anticipating all possible behaviors is infeasible. We propose a composable, model-free reinforcement learning method that learns a value function and an optimal policy for each individual environment element (e.g., goal or obstacle) and composes them online to achieve goal reaching and collision avoidance. Assuming unknown nonlinear dynamics that evolve in continuous time and are input-affine, we derive a continuous-time Hamilton-Jacobi-Bellman (HJB) equation for the value function and show that the corresponding advantage function is quadratic in the action and optimal policy. Based on this structure, we introduce a model-free actor-critic algorithm that learns policies and value functions for static or moving obstacles using gradient descent. We then compose multiple reach/avoid models via a quadratically constrained quadratic program (QCQP), yielding formal obstacle-avoidance guarantees in terms of value-function level sets, providing a model-free alternative to CLF/CBF-based controllers. Simulations demonstrate improved performance over a PPO baseline applied to a discrete-time approximation.

</details>


### [182] [Monocular Reconstruction of Neural Tactile Fields](https://arxiv.org/abs/2602.12508)
*Pavan Mantripragada,Siddhanth Deshmukh,Eadom Dessalene,Manas Desai,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: 提出神经触觉场，从单目RGB图像预测3D触觉响应，使机器人能规划路径时区分不同阻力区域而非将所有占据空间视为同等不可通过。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的机器人需要在可变形、可屈服和可重构的环境中规划路径，需要超越静态几何占据的交互感知3D表示。

Method: 引入神经触觉场，这是一种新颖的3D表示，将空间位置映射到接触时的预期触觉响应。模型从单目RGB图像预测这些神经触觉场。

Result: 与最先进的单目3D重建方法（LRM和Direct3D）相比，学习框架将体积3D重建提高了85.8%，表面重建提高了26.7%。

Conclusion: 神经触觉场使机器人能够生成避免高阻力物体同时有意通过低阻力区域（如植被）的路径，而不是将所有占据空间视为同等不可通过。

Abstract: Robots operating in the real world must plan through environments that deform, yield, and reconfigure under contact, requiring interaction-aware 3D representations that extend beyond static geometric occupancy. To address this, we introduce neural tactile fields, a novel 3D representation that maps spatial locations to the expected tactile response upon contact. Our model predicts these neural tactile fields from a single monocular RGB image -- the first method to do so. When integrated with off-the-shelf path planners, neural tactile fields enable robots to generate paths that avoid high-resistance objects while deliberately routing through low-resistance regions (e.g. foliage), rather than treating all occupied space as equally impassable. Empirically, our learning framework improves volumetric 3D reconstruction by $85.8\%$ and surface reconstruction by $26.7\%$ compared to state-of-the-art monocular 3D reconstruction methods (LRM and Direct3D).

</details>


### [183] [CRAFT: Adapting VLA Models to Contact-rich Manipulation via Force-aware Curriculum Fine-tuning](https://arxiv.org/abs/2602.12532)
*Yike Zhang,Yaonan Wang,Xinxin Sun,Kaizhen Huang,Zhiyuan Xu,Junjie Ji,Zhengping Che,Jian Tang,Jingtao Sun*

Main category: cs.RO

TL;DR: CRAFT是一个力感知的课程微调框架，通过变分信息瓶颈模块调节视觉和语言嵌入，优先学习力信号，以解决VLA模型在接触丰富操作任务中的不足。


<details>
  <summary>Details</summary>
Motivation: VLA模型在执行通用指令方面表现出色，但在接触丰富的操作任务中表现不佳，因为需要精确对齐、稳定接触保持和有效处理可变形物体。根本挑战在于高熵视觉语言输入与低熵但关键的力信号之间的不平衡，导致过度依赖感知和不稳定控制。

Method: 1. 引入CRAFT框架，包含变分信息瓶颈模块，在早期训练中调节视觉和语言嵌入；2. 采用课程策略，先鼓励模型优先学习力信号，然后逐步恢复对完整多模态信息的访问；3. 设计同源领导者-跟随者遥操作系统，收集同步的视觉、语言和力数据。

Result: 真实世界实验表明，CRAFT持续提高任务成功率，泛化到未见过的物体和新颖任务变体，并能有效适应不同的VLA架构，实现鲁棒且可泛化的接触丰富操作。

Conclusion: CRAFT通过力感知的课程微调框架，成功解决了VLA模型在接触丰富操作任务中的局限性，通过优先学习力信号并逐步整合多模态信息，实现了更鲁棒和可泛化的机器人操作能力。

Abstract: Vision-Language-Action (VLA) models have shown a strong capability in enabling robots to execute general instructions, yet they struggle with contact-rich manipulation tasks, where success requires precise alignment, stable contact maintenance, and effective handling of deformable objects. A fundamental challenge arises from the imbalance between high-entropy vision and language inputs and low-entropy but critical force signals, which often leads to over-reliance on perception and unstable control. To address this, we introduce CRAFT, a force-aware curriculum fine-tuning framework that integrates a variational information bottleneck module to regulate vision and language embeddings during early training. This curriculum strategy encourages the model to prioritize force signals initially, before progressively restoring access to the full multimodal information. To enable force-aware learning, we further design a homologous leader-follower teleoperation system that collects synchronized vision, language, and force data across diverse contact-rich tasks. Real-world experiments demonstrate that CRAFT consistently improves task success, generalizes to unseen objects and novel task variations, and adapts effectively across diverse VLA architectures, enabling robust and generalizable contact-rich manipulation.

</details>


### [184] [Eva-Tracker: ESDF-update-free, Visibility-aware Planning with Target Reacquisition for Robust Aerial Tracking](https://arxiv.org/abs/2602.12549)
*Yue Lin,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: Eva-Tracker：一种用于空中跟踪的可见性感知轨迹规划框架，通过预计算的FoV-ESDF消除ESDF更新开销，实现高效的目标重获和连续可见性跟踪


<details>
  <summary>Details</summary>
Motivation: 传统的欧几里得符号距离场（ESDF）在可见性评估中广泛使用，但频繁的ESDF更新带来了巨大的计算开销。为了解决这个问题，需要一种既能避免遮挡和碰撞，又能降低计算成本的跟踪方法。

Method: 1. 设计目标轨迹预测方法和可见性感知的初始路径生成算法，保持适当观测距离、避免遮挡，并在目标丢失时快速重新规划以重新获取目标。2. 提出视场ESDF（FoV-ESDF），这是一种针对跟踪器视场预计算的ESDF，无需更新即可快速进行可见性评估。3. 使用基于可微分FoV-ESDF的目标函数优化轨迹，确保整个跟踪过程中的连续可见性。

Result: 广泛的仿真和真实世界实验表明，与现有最先进方法相比，该方法以更低的计算成本提供了更鲁棒的跟踪结果。

Conclusion: Eva-Tracker通过消除ESDF更新开销并引入恢复能力强的路径生成方法，实现了高效、鲁棒的空中跟踪，源代码已开源。

Abstract: The Euclidean Signed Distance Field (ESDF) is widely used in visibility evaluation to prevent occlusions and collisions during tracking. However, frequent ESDF updates introduce considerable computational overhead. To address this issue, we propose Eva-Tracker, a visibility-aware trajectory planning framework for aerial tracking that eliminates ESDF updates and incorporates a recovery-capable path generation method for target reacquisition. First, we design a target trajectory prediction method and a visibility-aware initial path generation algorithm that maintain an appropriate observation distance, avoid occlusions, and enable rapid replanning to reacquire the target when it is lost. Then, we propose the Field of View ESDF (FoV-ESDF), a precomputed ESDF tailored to the tracker's field of view, enabling rapid visibility evaluation without requiring updates. Finally, we optimize the trajectory using differentiable FoV-ESDF-based objectives to ensure continuous visibility throughout the tracking process. Extensive simulations and real-world experiments demonstrate that our approach delivers more robust tracking results with lower computational effort than existing state-of-the-art methods. The source code is available at https://github.com/Yue-0/Eva-Tracker.

</details>


### [185] [Hemispherical Angular Power Mapping of Installed mmWave Radar Modules Under Realistic Deployment Constraints](https://arxiv.org/abs/2602.12584)
*Maaz Qureshi,Mohammad Omid Bagheri,William Melek,George Shaker*

Main category: cs.RO

TL;DR: 提出一种用于现场验证已安装毫米波模块的半球形角度接收功率映射方法，可在实际部署约束下进行电磁验证，无需传统天线测量设备。


<details>
  <summary>Details</summary>
Motivation: 在实际传感平台中，毫米波雷达模块的封装、安装硬件和附近结构会显著改变其有效辐射特性，但一旦设备嵌入主机环境，传统的腔室和转台天线测量方法往往不实用。

Method: 采用半球形角度接收功率映射方法，通过几何一致定位和准静态采集，将校准接收探头放置在规定的(phi, theta, r)位置，采样被测设备周围可访问的半空间，使用标准射频仪器记录幅度接收功率。

Result: 在60GHz雷达模块上的概念验证测量显示，该方法可实现可重复的半球形映射，角度趋势与全波仿真结果良好一致。

Conclusion: 该方法支持对嵌入式毫米波发射器进行实用的现场表征，能够捕捉安装相关的辐射特性，为实际部署约束下的电磁验证提供了可行方案。

Abstract: Characterizing the angular radiation behavior of installed millimeter-wave (mmWave) radar modules is increasingly important in practical sensing platforms, where packaging, mounting hardware, and nearby structures can significantly alter the effective emission profile. However, once a device is embedded in its host environment, conventional chamber- and turntable-based antenna measurements are often impractical. This paper presents a hemispherical angular received-power mapping methodology for in-situ EM validation of installed mmWave modules under realistic deployment constraints. The approach samples the accessible half-space around a stationary device-under-test by placing a calibrated receiving probe at prescribed (phi, theta, r) locations using geometry-consistent positioning and quasi-static acquisition. Amplitude-only received-power is recorded using standard RF instrumentation to generate hemispherical angular power maps that capture installation-dependent radiation characteristics. Proof-of-concept measurements on a 60-GHz radar module demonstrate repeatable hemi-spherical mapping with angular trends in good agreement with full-wave simulation, supporting practical on-site characterization of embedded mmWave transmitters.

</details>


### [186] [PISHYAR: A Socially Intelligent Smart Cane for Indoor Social Navigation and Multimodal Human-Robot Interaction for Visually Impaired People](https://arxiv.org/abs/2602.12597)
*Mahdi Haghighat Joo,Maryam Karimi Jafari,Alireza Taheri*

Main category: cs.RO

TL;DR: PISHYAR是一个结合社交导航与多模态人机交互的智能手杖，通过实时感知、路径规划和AI交互支持视障人士的移动与社交辅助。


<details>
  <summary>Details</summary>
Motivation: 设计一个超越传统导航功能的智能辅助设备，不仅帮助视障人士物理移动，还能提供社交感知和自然交互支持，解决他们在复杂社交环境中的导航与沟通需求。

Method: 系统包含两个核心组件：1) 社交导航框架（Raspberry Pi 5 + OAK-D Lite摄像头 + YOLOv8物体检测 + COMPOSER群体活动识别 + D* Lite动态路径规划 + 触觉反馈）；2) 多模态LLM-VLM交互框架（语音识别+视觉语言模型+大语言模型+语音合成，支持语音和视觉模式动态切换）。

Result: 在模拟和真实室内环境中实现可靠的障碍物避让和社交合规导航，整体系统准确率约80%；群体活动识别在不同人群场景中表现稳健；初步用户研究（8名视障参与者）显示高接受度，在可用性、信任和感知社交性方面获得积极评价。

Conclusion: PISHYAR展示了作为多模态辅助移动设备的潜力，不仅提供导航功能，还能为视障用户提供社交互动支持，是传统导航辅助设备的重要扩展。

Abstract: This paper presents PISHYAR, a socially intelligent smart cane designed by our group to combine socially aware navigation with multimodal human-AI interaction to support both physical mobility and interactive assistance. The system consists of two components: (1) a social navigation framework implemented on a Raspberry Pi 5 that integrates real-time RGB-D perception using an OAK-D Lite camera, YOLOv8-based object detection, COMPOSER-based collective activity recognition, D* Lite dynamic path planning, and haptic feedback via vibration motors for tasks such as locating a vacant seat; and (2) an agentic multimodal LLM-VLM interaction framework that integrates speech recognition, vision language models, large language models, and text-to-speech, with dynamic routing between voice-only and vision-only modes to enable natural voice-based communication, scene description, and object localization from visual input. The system is evaluated through a combination of simulation-based tests, real-world field experiments, and user-centered studies. Results from simulated and real indoor environments demonstrate reliable obstacle avoidance and socially compliant navigation, achieving an overall system accuracy of approximately 80% under different social conditions. Group activity recognition further shows robust performance across diverse crowd scenarios. In addition, a preliminary exploratory user study with eight visually impaired and low-vision participants evaluates the agentic interaction framework through structured tasks and a UTAUT-based questionnaire reveals high acceptance and positive perceptions of usability, trust, and perceived sociability during our experiments. The results highlight the potential of PISHYAR as a multimodal assistive mobility aid that extends beyond navigation to provide socially interactive support for such users.

</details>


### [187] [RLinf-Co: Reinforcement Learning-Based Sim-Real Co-Training for VLA Models](https://arxiv.org/abs/2602.12628)
*Liangzhi Shi,Shuaihang Chen,Feng Gao,Yinuo Chen,Kang Chen,Tonghe Zhang,Hongzhi Zhang,Weinan Zhang,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: 提出RL-Co框架，通过强化学习在模拟环境中训练视觉语言动作模型，同时用真实数据监督防止灾难性遗忘，显著提升真实世界任务表现和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于监督微调的模拟-真实协同训练方法将模拟视为静态演示源，无法利用大规模闭环交互，导致真实世界性能提升和泛化能力有限。

Method: 提出两阶段RL-Co框架：1) 用真实和模拟演示混合进行监督微调预热；2) 在模拟环境中进行强化学习微调，同时添加真实数据的辅助监督损失以防止灾难性遗忘。

Result: 在四个真实桌面操作任务上，使用OpenVLA和π₀.₅两种VLA架构，相比仅真实数据微调和基于监督的协同训练，分别获得+24%和+20%的真实世界成功率提升，同时展现出更强的泛化能力和数据效率。

Conclusion: RL-Co框架通过结合模拟环境的交互式强化学习和真实数据的监督锚定，为利用模拟增强真实机器人部署提供了实用且可扩展的路径，显著提升性能和泛化能力。

Abstract: Simulation offers a scalable and low-cost way to enrich vision-language-action (VLA) training, reducing reliance on expensive real-robot demonstrations. However, most sim-real co-training methods rely on supervised fine-tuning (SFT), which treats simulation as a static source of demonstrations and does not exploit large-scale closed-loop interaction. Consequently, real-world gains and generalization are often limited. In this paper, we propose an \underline{\textit{RL}}-based sim-real \underline{\textit{Co}}-training \modify{(RL-Co)} framework that leverages interactive simulation while preserving real-world capabilities. Our method follows a generic two-stage design: we first warm-start the policy with SFT on a mixture of real and simulated demonstrations, then fine-tune it with reinforcement learning in simulation while adding an auxiliary supervised loss on real-world data to anchor the policy and mitigate catastrophic forgetting. We evaluate our framework on four real-world tabletop manipulation tasks using two representative VLA architectures, OpenVLA and $π_{0.5}$, and observe consistent improvements over real-only fine-tuning and SFT-based co-training, including +24% real-world success on OpenVLA and +20% on $π_{0.5}$. Beyond higher success rates, RL co-training yields stronger generalization to unseen task variations and substantially improved real-world data efficiency, providing a practical and scalable pathway for leveraging simulation to enhance real-robot deployment.

</details>


### [188] [Real-to-Sim for Highly Cluttered Environments via Physics-Consistent Inter-Object Reasoning](https://arxiv.org/abs/2602.12633)
*Tianyi Xiang,Jiahang Cao,Sikai Guo,Guoyang Zhao,Andrew F. Luo,Jun Ma*

Main category: cs.RO

TL;DR: 提出一种物理约束的Real-to-Sim流水线，从单视角RGB-D数据重建物理一致的3D场景，通过可微分优化和接触图建模解决机器人操作中的物理约束问题


<details>
  <summary>Details</summary>
Motivation: 从单视角观测重建物理有效的3D场景是连接视觉感知和机器人控制的关键，但在需要精确接触推理的场景中（如高度杂乱环境中的机器人操作），仅几何保真度不足。标准感知流水线常忽略物理约束，导致无效状态（如漂浮物体或严重穿透），使下游仿真不可靠。

Method: 提出物理约束的Real-to-Sim流水线，核心是可微分优化流水线，通过接触图显式建模空间依赖关系，联合优化物体姿态和物理属性，使用可微分刚体仿真进行细化。

Result: 在仿真和真实世界环境中进行广泛评估，重建的场景实现了高物理保真度，能忠实复制真实世界的接触动力学，支持稳定可靠的接触丰富操作。

Conclusion: 该方法成功解决了单视角RGB-D数据重建物理一致3D场景的问题，通过物理约束优化显著提高了机器人操作任务中的可靠性和稳定性。

Abstract: Reconstructing physically valid 3D scenes from single-view observations is a prerequisite for bridging the gap between visual perception and robotic control. However, in scenarios requiring precise contact reasoning, such as robotic manipulation in highly cluttered environments, geometric fidelity alone is insufficient. Standard perception pipelines often neglect physical constraints, resulting in invalid states, e.g., floating objects or severe inter-penetration, rendering downstream simulation unreliable. To address these limitations, we propose a novel physics-constrained Real-to-Sim pipeline that reconstructs physically consistent 3D scenes from single-view RGB-D data. Central to our approach is a differentiable optimization pipeline that explicitly models spatial dependencies via a contact graph, jointly refining object poses and physical properties through differentiable rigid-body simulation. Extensive evaluations in both simulation and real-world settings demonstrate that our reconstructed scenes achieve high physical fidelity and faithfully replicate real-world contact dynamics, enabling stable and reliable contact-rich manipulation.

</details>


### [189] [PMG: Parameterized Motion Generator for Human-like Locomotion Control](https://arxiv.org/abs/2602.12656)
*Chenxi Han,Yuheng Min,Zihao Huang,Ao Hong,Hang Liu,Yi Cheng,Houde Liu*

Main category: cs.RO

TL;DR: 提出参数化运动生成器(PMG)，通过分析人体运动结构，仅使用少量参数化运动数据和高维控制命令生成参考轨迹，结合模仿学习和优化式仿真到现实参数识别，实现自然、类人的人形机器人运动控制。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的强化学习和运动跟踪技术虽然改进了人形机器人运动，但仍存在实际挑战：低级运动跟踪和轨迹跟随控制器成熟，但全身参考引导方法难以适应高级命令接口和多样化任务场景，需要大量高质量数据集，在不同速度和姿态下表现脆弱，对机器人特定校准敏感。

Method: 提出参数化运动生成器(PMG)，基于人体运动结构分析，仅使用紧凑的参数化运动数据集和高维控制命令合成参考轨迹。结合模仿学习流程和基于优化的仿真到现实电机参数识别模块，构建完整系统。

Result: 在ZERITH Z1人形机器人原型上验证，PMG在单一集成系统中产生自然的类人运动，精确响应高维控制输入（包括基于VR的遥操作），实现高效、可验证的仿真到现实迁移。

Conclusion: 这些结果建立了一条实用、经过实验验证的途径，通向自然且可部署的人形机器人控制。

Abstract: Recent advances in data-driven reinforcement learning and motion tracking have substantially improved humanoid locomotion, yet critical practical challenges remain. In particular, while low-level motion tracking and trajectory-following controllers are mature, whole-body reference-guided methods are difficult to adapt to higher-level command interfaces and diverse task contexts: they require large, high-quality datasets, are brittle across speed and pose regimes, and are sensitive to robot-specific calibration. To address these limitations, we propose the Parameterized Motion Generator (PMG), a real-time motion generator grounded in an analysis of human motion structure that synthesizes reference trajectories using only a compact set of parameterized motion data together with High-dimensional control commands. Combined with an imitation-learning pipeline and an optimization-based sim-to-real motor parameter identification module, we validate the complete approach on our humanoid prototype ZERITH Z1 and show that, within a single integrated system, PMG produces natural, human-like locomotion, responds precisely to high-dimensional control inputs-including VR-based teleoperation-and enables efficient, verifiable sim-to-real transfer. Together, these results establish a practical, experimentally validated pathway toward natural and deployable humanoid control.

</details>


### [190] [Xiaomi-Robotics-0: An Open-Sourced Vision-Language-Action Model with Real-Time Execution](https://arxiv.org/abs/2602.12684)
*Rui Cai,Jun Guo,Xinze He,Piaopiao Jin,Jie Li,Bingxuan Lin,Futeng Liu,Wei Liu,Fei Ma,Kun Ma,Feng Qiu,Heng Qu,Yifei Su,Qiao Sun,Dong Wang,Donghao Wang,Yunhong Wang,Rujie Wu,Diyun Xiang,Yu Yang,Hangjun Ye,Yuan Zhang,Quanyun Zhou*

Main category: cs.RO

TL;DR: 小米推出Xiaomi-Robotics-0视觉语言动作模型，通过精心设计的训练方案和部署策略，实现高性能、快速流畅的实时执行，在仿真基准测试和真实机器人双手灵巧操作任务中均取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 开发一个既能保持视觉语义知识，又能实现快速流畅实时执行的视觉语言动作模型，以解决真实机器人部署中的推理延迟问题，提升机器人操作的精确性和灵巧性。

Method: 1. 在大规模跨体现机器人轨迹和视觉语言数据上进行预训练，获得广泛可泛化的动作生成能力；2. 提出异步执行训练技术解决真实机器人部署中的推理延迟；3. 在部署时精心对齐连续预测动作块的时间步，确保连续无缝的实时执行。

Result: 1. 在所有仿真基准测试中达到最先进的性能；2. 在消费级GPU上实现快速流畅的真实机器人执行，在两个需要精确灵巧双手操作的真实机器人任务中均取得高成功率和吞吐量。

Conclusion: Xiaomi-Robotics-0通过创新的训练和部署策略，成功实现了高性能、快速流畅的实时机器人控制，为未来研究提供了有价值的开源模型和代码。

Abstract: In this report, we introduce Xiaomi-Robotics-0, an advanced vision-language-action (VLA) model optimized for high performance and fast and smooth real-time execution. The key to our method lies in a carefully designed training recipe and deployment strategy. Xiaomi-Robotics-0 is first pre-trained on large-scale cross-embodiment robot trajectories and vision-language data, endowing it with broad and generalizable action-generation capabilities while avoiding catastrophic forgetting of the visual-semantic knowledge of the underlying pre-trained VLM. During post-training, we propose several techniques for training the VLA model for asynchronous execution to address the inference latency during real-robot rollouts. During deployment, we carefully align the timesteps of consecutive predicted action chunks to ensure continuous and seamless real-time rollouts. We evaluate Xiaomi-Robotics-0 extensively in simulation benchmarks and on two challenging real-robot tasks that require precise and dexterous bimanual manipulation. Results show that our method achieves state-of-the-art performance across all simulation benchmarks. Moreover, Xiaomi-Robotics-0 can roll out fast and smoothly on real robots using a consumer-grade GPU, achieving high success rates and throughput on both real-robot tasks. To facilitate future research, code and model checkpoints are open-sourced at https://xiaomi-robotics-0.github.io

</details>


### [191] [SignScene: Visual Sign Grounding for Mapless Navigation](https://arxiv.org/abs/2602.12686)
*Nicky Zimmerman,Joel Loo,Benjamin Koh,Zishuo Wang,David Hsu*

Main category: cs.RO

TL;DR: 机器人利用导航标志进行无地图导航，提出SignScene表示方法，通过视觉语言模型解析标志语义并映射到3D场景，实现88%的准确率并在Spot机器人上成功演示


<details>
  <summary>Details</summary>
Motivation: 人类可以通过导航标志在不熟悉环境中导航而无需地图，但机器人难以理解真实世界中多样复杂的标志语义并将其与3D场景元素对应。需要解决标志语义如何映射到具体场景元素和导航动作的问题。

Method: 提出SignScene表示方法，这是一种以标志为中心的空间-语义表示，捕捉与导航相关的场景元素和标志信息，并以适合视觉语言模型推理的形式呈现。将标志语义映射到对应场景元素和导航动作。

Result: 在9种不同环境类型的114个查询数据集上评估，达到88%的标志语义映射准确率，显著优于基线方法。最终在Spot机器人上成功演示了仅依靠标志的真实世界无地图导航。

Conclusion: SignScene表示方法有效解决了机器人理解导航标志语义并映射到3D场景的问题，使机器人能够像人类一样利用标志进行无地图导航，为开放世界机器人导航提供了新途径。

Abstract: Navigational signs enable humans to navigate unfamiliar environments without maps. This work studies how robots can similarly exploit signs for mapless navigation in the open world. A central challenge lies in interpreting signs: real-world signs are diverse and complex, and their abstract semantic contents need to be grounded in the local 3D scene. We formalize this as sign grounding, the problem of mapping semantic instructions on signs to corresponding scene elements and navigational actions. Recent Vision-Language Models (VLMs) offer the semantic common-sense and reasoning capabilities required for this task, but are sensitive to how spatial information is represented. We propose SignScene, a sign-centric spatial-semantic representation that captures navigation-relevant scene elements and sign information, and presents them to VLMs in a form conducive to effective reasoning. We evaluate our grounding approach on a dataset of 114 queries collected across nine diverse environment types, achieving 88% grounding accuracy and significantly outperforming baselines. Finally, we demonstrate that it enables real-world mapless navigation on a Spot robot using only signs.

</details>


### [192] [ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training](https://arxiv.org/abs/2602.12691)
*Rushuai Yang,Hecheng Wang,Chiming Liu,Xiaohan Yan,Yunlong Wang,Xuan Du,Shuoyu Yue,Yongcheng Liu,Chuheng Zhang,Lizhe Qi,Yi Chen,Wei Shan,Maoqing Yao*

Main category: cs.RO

TL;DR: 本文提出ALOE框架，通过动作级别的离策略评估改进大型视觉语言动作系统的在线强化学习，在真实世界操作任务中提升学习效率而不影响执行速度。


<details>
  <summary>Details</summary>
Motivation: 现有VLA系统在真实世界在线强化学习中，通常采用保守的同策略评估来保证稳定性，但这避免了对当前高容量策略的直接评估，限制了学习效果。需要解决从混合数据源（历史策略和人类干预）中评估当前行为质量的离策略评估问题。

Method: 提出ALOE框架，采用基于分块的时序差分引导方法，评估单个动作序列而非预测最终任务结果。这种设计改进了稀疏奖励下对关键动作块的信用分配，支持稳定的策略改进。

Result: 在三个真实世界操作任务上评估：智能手机包装（高精度任务）、衣物折叠（长时程可变形物体任务）、双手抓取放置（多物体感知）。在所有任务中，ALOE都提高了学习效率，同时不损害执行速度。

Conclusion: ALOE框架表明，离策略强化学习可以以可靠的方式重新引入真实世界VLA后训练中，为大型基础VLA系统的在线强化学习提供了有效的改进方法。

Abstract: We study how to improve large foundation vision-language-action (VLA) systems through online reinforcement learning (RL) in real-world settings. Central to this process is the value function, which provides learning signals to guide VLA learning from experience. In practice, the value function is estimated from trajectory fragments collected from different data sources, including historical policies and intermittent human interventions. Estimating the value function of current behavior quality from the mixture data is inherently an off-policy evaluation problem. However, prior work often adopts conservative on-policy estimation for stability, which avoids direct evaluation of the current high-capacity policy and limits learning effectiveness. In this paper, we propose ALOE, an action-level off-policy evaluation framework for VLA post-training. ALOE applies chunking-based temporal-difference bootstrapping to evaluate individual action sequences instead of predicting final task outcomes. This design improves effective credit assignment to critical action chunks under sparse rewards and supports stable policy improvement. We evaluate our method on three real-world manipulation tasks, including smartphone packing as a high-precision task, laundry folding as a long-horizon deformable-object task, and bimanual pick-and-place involving multi-object perception. Across all tasks, ALOE improves learning efficiency without compromising execution speed, showing that off-policy RL can be reintroduced in a reliable manner for real-world VLA post-training. Videos and additional materials are available at our project website.

</details>


### [193] [Constrained PSO Six-Parameter Fuzzy PID Tuning Method for Balanced Optimization of Depth Tracking Performance in Underwater Vehicles](https://arxiv.org/abs/2602.12700)
*Yanxi Ding,Tingyue Jia*

Main category: cs.RO

TL;DR: 提出基于约束粒子群优化的六参数模糊PID控制器调参方法，显著提升水下航行器深度控制性能


<details>
  <summary>Details</summary>
Motivation: 水下航行器深度控制需同时满足快速跟踪、低超调、执行器约束等要求，传统模糊PID调参依赖经验方法，难以在性能提升与控制成本间获得稳定可重复的平衡解

Method: 采用约束粒子群优化方法对六参数模糊PID控制器进行调参，同时调整基准PID参数、模糊控制器输入量化因子和输出比例增益，实现整体调参强度与动态响应特性的协同优化

Result: 在保持控制能量和饱和水平一致的情况下，时间加权绝对误差积分从0.2631降至0.1473，调节时间从2.301秒缩短至1.613秒，相对超调从0.1494降至0.01839，控制能量从7980变为7935满足约束，饱和占用率从0.004降至0.003

Conclusion: 提出的约束六参数联合调参策略有效提升了水下航行器深度控制性能，验证了方法的有效性和工程意义

Abstract: Depth control of underwater vehicles in engineering applications must simultaneously satisfy requirements for rapid tracking, low overshoot, and actuator constraints. Traditional fuzzy PID tuning often relies on empirical methods, making it difficult to achieve a stable and reproducible equilibrium solution between performance enhancement and control cost. This paper proposes a constrained particle swarm optimization (PSO) method for tuning six-parameter fuzzy PID controllers. By adjusting the benchmark PID parameters alongside the fuzzy controller's input quantization factor and output proportional gain, it achieves synergistic optimization of the overall tuning strength and dynamic response characteristics of the fuzzy PID system. To ensure engineering feasibility of the optimization results, a time-weighted absolute error integral, adjustment time, relative overshoot control energy, and saturation occupancy rate are introduced. Control energy constraints are applied to construct a constraint-driven comprehensive evaluation system, suppressing pseudo-improvements achieved solely by increasing control inputs. Simulation results demonstrate that, while maintaining consistent control energy and saturation levels, the proposed method significantly enhances deep tracking performance: the time-weighted absolute error integral decreases from 0.2631 to 0.1473, the settling time shortens from 2.301 s to 1.613 s, and the relative overshoot reduces from 0.1494 to 0.01839. Control energy varied from 7980 to 7935, satisfying the energy constraint, while saturation occupancy decreased from 0.004 to 0.003. These results validate the effectiveness and engineering significance of the proposed constrained six-parameter joint tuning strategy for depth control in underwater vehicle navigation scenarios.

</details>


### [194] [TRANS: Terrain-aware Reinforcement Learning for Agile Navigation of Quadruped Robots under Social Interactions](https://arxiv.org/abs/2602.12724)
*Wei Zhu,Irfan Tito Kurniawan,Ye Zhao,Mistuhiro Hayashibe*

Main category: cs.RO

TL;DR: TRANS是一个用于四足机器人在非结构化地形上进行社交导航的深度强化学习框架，通过两阶段训练和三个DRL管道实现地形感知的敏捷导航。


<details>
  <summary>Details</summary>
Motivation: 传统四足导航方法通常将运动规划与运动控制分离，忽略了全身约束和地形感知；端到端方法需要高频感知但噪声大、计算成本高；现有方法大多假设静态环境，限制了在人群环境中的应用。

Method: 提出两阶段训练框架和三个DRL管道：1) TRANS-Loco使用非对称actor-critic模型进行四足运动，无需显式地形或接触观测即可穿越不平坦地形；2) TRANS-Nav应用对称actor-critic框架进行社交导航，将转换后的LiDAR数据直接映射到差速运动学下的智能体动作；3) TRANS统一管道整合前两者，支持在不平坦和社交交互环境中的地形感知四足导航。

Result: 与运动控制和社交导航基准方法的综合比较证明了TRANS的有效性。硬件实验进一步证实了其从仿真到真实世界迁移的潜力。

Conclusion: TRANS框架成功解决了四足机器人在非结构化地形和社交环境中的导航挑战，实现了地形感知的敏捷导航，并展示了良好的仿真到真实迁移能力。

Abstract: This study introduces TRANS: Terrain-aware Reinforcement learning for Agile Navigation under Social interactions, a deep reinforcement learning (DRL) framework for quadrupedal social navigation over unstructured terrains. Conventional quadrupedal navigation typically separates motion planning from locomotion control, neglecting whole-body constraints and terrain awareness. On the other hand, end-to-end methods are more integrated but require high-frequency sensing, which is often noisy and computationally costly. In addition, most existing approaches assume static environments, limiting their use in human-populated settings. To address these limitations, we propose a two-stage training framework with three DRL pipelines. (1) TRANS-Loco employs an asymmetric actor-critic (AC) model for quadrupedal locomotion, enabling traversal of uneven terrains without explicit terrain or contact observations. (2) TRANS-Nav applies a symmetric AC framework for social navigation, directly mapping transformed LiDAR data to ego-agent actions under differential-drive kinematics. (3) A unified pipeline, TRANS, integrates TRANS-Loco and TRANS-Nav, supporting terrain-aware quadrupedal navigation in uneven and socially interactive environments. Comprehensive benchmarks against locomotion and social navigation baselines demonstrate the effectiveness of TRANS. Hardware experiments further confirm its potential for sim-to-real transfer.

</details>


### [195] [SafeFlowMPC: Predictive and Safe Trajectory Planning for Robot Manipulators with Learning-based Policies](https://arxiv.org/abs/2602.12794)
*Thies Oelerich,Gerald Ebmer,Christian Hartl-Nesic,Andreas Kugi*

Main category: cs.RO

TL;DR: SafeFlowMPC结合流匹配和在线优化，在保证安全性的同时实现机器人任务的灵活性和实时性


<details>
  <summary>Details</summary>
Motivation: 机器人融入日常生活需要灵活性和实时反应能力，但现有方法存在矛盾：基于学习的方法缺乏可解释性和安全保证，而基于优化的方法缺乏灵活性和泛化能力

Method: 提出SafeFlowMPC方法，结合流匹配和在线优化，使用次优模型预测控制实现实时执行，同时保证安全性

Result: 在KUKA 7自由度机械臂上进行了三个真实世界实验（两个抓取实验和一个动态人机物体交接实验），表现出色

Conclusion: SafeFlowMPC成功结合了学习和优化的优势，在保证安全性的同时实现了灵活性和实时性，适用于真实世界机器人应用

Abstract: The emerging integration of robots into everyday life brings several major challenges. Compared to classical industrial applications, more flexibility is needed in combination with real-time reactivity. Learning-based methods can train powerful policies based on demonstrated trajectories, such that the robot generalizes a task to similar situations. However, these black-box models lack interpretability and rigorous safety guarantees. Optimization-based methods provide these guarantees but lack the required flexibility and generalization capabilities. This work proposes SafeFlowMPC, a combination of flow matching and online optimization to combine the strengths of learning and optimization. This method guarantees safety at all times and is designed to meet the demands of real-time execution by using a suboptimal model-predictive control formulation. SafeFlowMPC achieves strong performance in three real-world experiments on a KUKA 7-DoF manipulator, namely two grasping experiment and a dynamic human-robot object handover experiment. A video of the experiments is available at http://www.acin.tuwien.ac.at/42d6. The code is available at https://github.com/TU-Wien-ACIN-CDS/SafeFlowMPC.

</details>


### [196] [Adding internal audio sensing to internal vision enables human-like in-hand fabric recognition with soft robotic fingertips](https://arxiv.org/abs/2602.12918)
*Iris Andrussow,Jans Solano,Benjamin A. Richardson,Georg Martius,Katherine J. Kuchenbecker*

Main category: cs.RO

TL;DR: 机器人触觉感知系统结合高分辨率视觉触觉传感器和高频音频振动传感器，通过主动触摸布料实现97%的分类准确率


<details>
  <summary>Details</summary>
Motivation: 人类指尖能同时感知空间力模式和纹理振动，但机器人触觉传感器难以同时实现高空间分辨率和高时间采样率。需要开发能同时捕捉这两种触觉信息的系统来提升机器人对布料等材料的感知能力。

Method: 开发了结合Minsight视觉触觉传感器（50Hz力测量）和Minsound音频传感器（50Hz-15kHz振动测量）的机器人手指系统。机器人模仿人类评估布料的方式，用两个敏感手指主动夹持和摩擦折叠的布料样本。使用基于Transformer的方法进行布料分类。

Result: 在20种常见布料数据集上达到97%的最高分类准确率。音频传感器对整体分类性能有很高效用。加入外部麦克风增强了在嘈杂环境中的鲁棒性。系统还能学习布料拉伸性、厚度和粗糙度的一般表征。

Conclusion: 结合视觉和音频的触觉感知方法能有效提升机器人对布料的识别能力，音频传感器在触觉感知中具有重要作用，且该方法能泛化到训练数据之外的材料属性表征学习。

Abstract: Distinguishing the feel of smooth silk from coarse cotton is a trivial everyday task for humans. When exploring such fabrics, fingertip skin senses both spatio-temporal force patterns and texture-induced vibrations that are integrated to form a haptic representation of the explored material. It is challenging to reproduce this rich, dynamic perceptual capability in robots because tactile sensors typically cannot achieve both high spatial resolution and high temporal sampling rate. In this work, we present a system that can sense both types of haptic information, and we investigate how each type influences robotic tactile perception of fabrics. Our robotic hand's middle finger and thumb each feature a soft tactile sensor: one is the open-source Minsight sensor that uses an internal camera to measure fingertip deformation and force at 50 Hz, and the other is our new sensor Minsound that captures vibrations through an internal MEMS microphone with a bandwidth from 50 Hz to 15 kHz. Inspired by the movements humans make to evaluate fabrics, our robot actively encloses and rubs folded fabric samples between its two sensitive fingers. Our results test the influence of each sensing modality on overall classification performance, showing high utility for the audio-based sensor. Our transformer-based method achieves a maximum fabric classification accuracy of 97 % on a dataset of 20 common fabrics. Incorporating an external microphone away from Minsound increases our method's robustness in loud ambient noise conditions. To show that this audio-visual tactile sensing approach generalizes beyond the training data, we learn general representations of fabric stretchiness, thickness, and roughness.

</details>


### [197] [INHerit-SG: Incremental Hierarchical Semantic Scene Graphs with RAG-Style Retrieval](https://arxiv.org/abs/2602.12971)
*YukTungSamuel Fang,Zhikang Shi,Jiabin Qiu,Zixuan Chen,Jieqi Shi,Hao Xu,Jing Huo,Yang Gao*

Main category: cs.RO

TL;DR: INHerit-SG提出了一种用于机器人导航的语义场景图系统，通过结构化知识库和显式语义锚点来更好地对齐人类意图，采用异步双进程架构和事件触发更新机制，实现了高效且可解释的复杂查询检索。


<details>
  <summary>Details</summary>
Motivation: 现有语义场景图方法主要依赖离线批量处理或隐式特征嵌入，难以支持复杂环境中可解释的人类意图推理，与具体任务需求存在根本性不匹配。

Method: 1. 将地图重新定义为结构化、RAG就绪的知识库，引入自然语言描述作为显式语义锚点；2. 采用异步双进程架构和Floor-Room-Area-Object层次结构，解耦几何分割与语义推理；3. 事件触发的地图更新机制仅在发生有意义语义事件时重组图结构；4. 部署多角色大语言模型分解查询并处理逻辑否定，采用硬到软过滤策略确保鲁棒推理。

Result: 在新建数据集HM3DSem-SQR和真实环境中评估，系统在复杂查询上达到最先进性能，并展示了下游导航任务的可扩展性。显式可解释性提高了复杂检索的成功率和可靠性。

Conclusion: INHerit-SG通过结构化知识表示、高效架构设计和可解释检索机制，有效解决了现有语义场景图在机器人导航任务中的局限性，为更广泛的人类交互任务提供了适应性。

Abstract: Driven by advancements in foundation models, semantic scene graphs have emerged as a prominent paradigm for high-level 3D environmental abstraction in robot navigation. However, existing approaches are fundamentally misaligned with the needs of embodied tasks. As they rely on either offline batch processing or implicit feature embeddings, the maps can hardly support interpretable human-intent reasoning in complex environments. To address these limitations, we present INHerit-SG. We redefine the map as a structured, RAG-ready knowledge base where natural-language descriptions are introduced as explicit semantic anchors to better align with human intent. An asynchronous dual-process architecture, together with a Floor-Room-Area-Object hierarchy, decouples geometric segmentation from time-consuming semantic reasoning. An event-triggered map update mechanism reorganizes the graph only when meaningful semantic events occur. This strategy enables our graph to maintain long-term consistency with relatively low computational overhead. For retrieval, we deploy multi-role Large Language Models (LLMs) to decompose queries into atomic constraints and handle logical negations, and employ a hard-to-soft filtering strategy to ensure robust reasoning. This explicit interpretability improves the success rate and reliability of complex retrievals, enabling the system to adapt to a broader spectrum of human interaction tasks. We evaluate INHerit-SG on a newly constructed dataset, HM3DSem-SQR, and in real-world environments. Experiments demonstrate that our system achieves state-of-the-art performance on complex queries, and reveal its scalability for downstream navigation tasks. Project Page: https://fangyuktung.github.io/INHeritSG.github.io/

</details>


### [198] [Learning Native Continuation for Action Chunking Flow Policies](https://arxiv.org/abs/2602.12978)
*Yufeng Liu,Hang Yu,Juntu Zhao,Bocheng Li,Di Zhang,Mingzhu Li,Wenxuan Wu,Yingdong Hu,Junyuan Xie,Junliang Guo,Dequan Wang,Yang Gao*

Main category: cs.RO

TL;DR: Legato是一种训练时延续方法，用于基于流的动作分块VLA策略，通过初始化去噪过程、重塑流动力学和随机化调度条件，解决了分块执行中的不连续性问题，显著提升了轨迹平滑度和任务完成时间。


<details>
  <summary>Details</summary>
Motivation: 动作分块使VLA模型能够实时运行，但朴素的分块执行在分块边界处经常出现不连续性。实时分块(RTC)缓解了这个问题，但它是外部于策略的，导致虚假的多模态切换和本质上不光滑的轨迹。

Method: 提出Legato训练时延续方法：1) 从已知动作和噪声的调度形状混合初始化去噪过程，向模型暴露部分动作信息；2) 重塑学习的流动力学，确保在每步指导下的训练和推理过程中去噪过程保持一致；3) 使用随机化调度条件训练以支持变化的推理延迟并实现可控平滑度。

Result: Legato产生更平滑的轨迹，减少执行过程中的虚假多模态切换，导致更少的犹豫和更短的任务完成时间。在五个操作任务上的广泛真实世界实验显示，Legato在轨迹平滑度和任务完成时间上都比RTC提升约10%。

Conclusion: Legato通过训练时延续方法有效解决了动作分块VLA策略中的边界不连续性问题，实现了比外部实时分块方法更好的轨迹平滑度和任务完成性能。

Abstract: Action chunking enables Vision Language Action (VLA) models to run in real time, but naive chunked execution often exhibits discontinuities at chunk boundaries. Real-Time Chunking (RTC) alleviates this issue but is external to the policy, leading to spurious multimodal switching and trajectories that are not intrinsically smooth. We propose Legato, a training-time continuation method for action-chunked flow-based VLA policies. Specifically, Legato initializes denoising from a schedule-shaped mixture of known actions and noise, exposing the model to partial action information. Moreover, Legato reshapes the learned flow dynamics to ensure that the denoising process remains consistent between training and inference under per-step guidance. Legato further uses randomized schedule condition during training to support varying inference delays and achieve controllable smoothness. Empirically, Legato produces smoother trajectories and reduces spurious multimodal switching during execution, leading to less hesitation and shorter task completion time. Extensive real-world experiments show that Legato consistently outperforms RTC across five manipulation tasks, achieving approximately 10% improvements in both trajectory smoothness and task completion time.

</details>


### [199] [How Swarms Differ: Challenges in Collective Behaviour Comparison](https://arxiv.org/abs/2602.13016)
*André Fialho Jesus,Jonas Kuckling*

Main category: cs.RO

TL;DR: 研究特征集对群体行为相似性度量的影响，评估现有特征集的鲁棒性，发现特征集与相似性度量的组合影响行为区分能力，并提出基于自组织映射的方法识别难以区分的特征空间区域。


<details>
  <summary>Details</summary>
Motivation: 群体行为通常需要通过数值特征来表达（如分类或模仿学习），但现有研究多为特定行为场景设计临时特征集，缺乏对解决方案在更广泛情境下鲁棒性的考虑。自动设计群体行为方法的发展依赖于定量测量行为相似性的能力。

Method: 从先前群体机器人研究中选取特征集和相似性度量方法，评估其鲁棒性；提出基于自组织映射的方法来识别特征空间中行为难以区分的区域。

Result: 特征集与相似性度量的组合会影响区分相似行为群组的能力；某些组合更适合区分相似行为；自组织映射方法能有效识别特征空间中行为难以区分的区域。

Conclusion: 特征集的选择对群体行为相似性度量至关重要，特征集与相似性度量的组合影响行为区分能力，提出的自组织映射方法有助于识别特征空间中的模糊区域，为更鲁棒的群体行为特征设计提供指导。

Abstract: Collective behaviours often need to be expressed through numerical features, e.g., for classification or imitation learning. This problem is often addressed by proposing an ad-hoc feature set for a particular swarm behaviour context, usually without further consideration of the solution's resilience outside of the conceived context. Yet, the development of automatic methods to design swarm behaviours is dependent on the ability to measure quantitatively the similarity of swarm behaviours. Hence, we investigate the impact of feature sets for collective behaviours. We select swarm feature sets and similarity measures from prior swarm robotics works, which mainly considered a narrow behavioural context and assess their robustness. We demonstrate that the interplay of feature set and similarity measure makes some combinations more suitable to distinguish groups of similar behaviours. We also propose a self-organised map-based approach to identify regions of the feature space where behaviours cannot be easily distinguished.

</details>


### [200] [SENSE-STEP: Learning Sim-to-Real Locomotion for a Sensory-Enabled Soft Quadruped Robot](https://arxiv.org/abs/2602.13078)
*Storm de Kam,Ebrahim Shahabi,Cosimo Della Santina*

Main category: cs.RO

TL;DR: 提出基于学习的控制框架，用于配备触觉吸盘脚的软体四足机器人，通过仿真训练实现闭环控制，在真实机器人上验证性能提升


<details>
  <summary>Details</summary>
Motivation: 软体四足机器人的稳健闭环运动控制面临挑战，包括高维动力学、执行器迟滞、难以建模的接触交互，以及传统本体感知提供的地面接触信息有限

Method: 采用基于学习的控制框架，通过分阶段学习过程在仿真中训练控制策略：从参考步态开始，在随机化环境条件下逐步优化；控制器将本体感知和触觉反馈映射到协调的气动执行和吸盘命令

Result: 在真实机器人上部署时，闭环策略优于开环基线：在平坦表面上前进速度提高41%，在5度斜坡上提高91%；消融研究显示触觉力估计和惯性反馈对稳定运动的作用，相比无传感器反馈配置性能提升达56%

Conclusion: 提出的学习控制框架成功实现了软体四足机器人的稳健闭环运动控制，通过触觉和本体感知反馈显著提升了在平坦和倾斜表面的运动性能

Abstract: Robust closed-loop locomotion remains challenging for soft quadruped robots due to high-dimensional dynamics, actuator hysteresis, and difficult-to-model contact interactions, while conventional proprioception provides limited information about ground contact. In this paper, we present a learning-based control framework for a pneumatically actuated soft quadruped equipped with tactile suction-cup feet, and we validate the approach experimentally on physical hardware. The control policy is trained in simulation through a staged learning process that starts from a reference gait and is progressively refined under randomized environmental conditions. The resulting controller maps proprioceptive and tactile feedback to coordinated pneumatic actuation and suction-cup commands, enabling closed-loop locomotion on flat and inclined surfaces. When deployed on the real robot, the closed-loop policy outperforms an open-loop baseline, increasing forward speed by 41% on a flat surface and by 91% on a 5-degree incline. Ablation studies further demonstrate the role of tactile force estimates and inertial feedback in stabilizing locomotion, with performance improvements of up to 56% compared to configurations without sensory feedback.

</details>


### [201] [UniManip: General-Purpose Zero-Shot Robotic Manipulation with Agentic Operational Graph](https://arxiv.org/abs/2602.13086)
*Haichao Liu,Yuanjiang Xue,Yuheng Zhou,Haoyuan Deng,Yinan Liang,Lihua Xie,Ziwei Wang*

Main category: cs.RO

TL;DR: UniManip是一个基于双层智能操作图的机器人操作框架，通过结合高层语义推理和低层物理接地，实现了零样本泛化能力，在未见过的物体和任务上比现有方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作方法在零样本泛化方面存在不足：端到端的视觉-语言-动作模型缺乏长时程任务所需的精度，而传统分层规划器在面对开放世界变化时存在语义刚性。需要一种能够无缝桥接高层语义意图和低层物理交互的统一框架。

Method: 提出了UniManip框架，基于双层智能操作图：高层智能层负责任务编排，低层场景层负责动态状态表示。系统通过动态智能循环，从非结构化感知中实例化以物体为中心的场景图，通过安全感知的局部规划器将这些表示参数化为无碰撞轨迹，并利用结构化内存自主诊断和恢复执行失败。

Result: 在未见过的物体和任务上，UniManip比最先进的视觉-语言-动作模型和分层基线方法分别提高了22.5%和25.0%的成功率。系统能够直接从固定基座设置零样本迁移到移动操作，无需微调或重新配置。

Conclusion: UniManip通过统一语义推理和物理接地，实现了强大的零样本泛化能力，为通用机器人操作提供了一个有效的解决方案，能够处理非结构化环境中的长时程任务。

Abstract: Achieving general-purpose robotic manipulation requires robots to seamlessly bridge high-level semantic intent with low-level physical interaction in unstructured environments. However, existing approaches falter in zero-shot generalization: end-to-end Vision-Language-Action (VLA) models often lack the precision required for long-horizon tasks, while traditional hierarchical planners suffer from semantic rigidity when facing open-world variations. To address this, we present UniManip, a framework grounded in a Bi-level Agentic Operational Graph (AOG) that unifies semantic reasoning and physical grounding. By coupling a high-level Agentic Layer for task orchestration with a low-level Scene Layer for dynamic state representation, the system continuously aligns abstract planning with geometric constraints, enabling robust zero-shot execution. Unlike static pipelines, UniManip operates as a dynamic agentic loop: it actively instantiates object-centric scene graphs from unstructured perception, parameterizes these representations into collision-free trajectories via a safety-aware local planner, and exploits structured memory to autonomously diagnose and recover from execution failures. Extensive experiments validate the system's robust zero-shot capability on unseen objects and tasks, demonstrating a 22.5% and 25.0% higher success rate compared to state-of-the-art VLA and hierarchical baselines, respectively. Notably, the system enables direct zero-shot transfer from fixed-base setups to mobile manipulation without fine-tuning or reconfiguration. Our open-source project page can be found at https://henryhcliu.github.io/unimanip.

</details>


### [202] [Temporally-Sampled Efficiently Adaptive State Lattices for Autonomous Ground Robot Navigation in Partially Observed Environments](https://arxiv.org/abs/2602.13159)
*Ashwin Satish Menon,Eric R. Damm,Eli S. Lancaster,Felix A. Sanchez,Jason M. Gregory,Thomas M. Howard*

Main category: cs.RO

TL;DR: TSEASL是一种区域规划器仲裁架构，通过考虑先前生成的轨迹与当前生成轨迹的优化版本，解决部分可观测环境中移动机器人因地图信息变化导致参考轨迹剧烈变化的安全问题。


<details>
  <summary>Details</summary>
Motivation: 在越野环境中，由于传感器限制，环境通常只能部分观测。传统自主导航架构中，区域运动规划器输出的参考轨迹会随着地图信息变化而频繁大幅改变，导致局部规划器接收的引导轨迹差异巨大，引发不安全导航行为，需要人工干预。

Method: 提出TSEASL（时间采样高效自适应状态格子）区域规划器仲裁架构。该架构不仅考虑当前生成的轨迹，还考虑先前生成轨迹的更新和优化版本，通过仲裁机制选择最合适的参考轨迹传递给局部规划器。

Result: 在Clearpath Robotics Warthog无人地面车辆及其收集的真实地图数据上进行测试。结果显示，使用TSEASL时，机器人在基线规划器需要人工干预的相同位置不再需要干预。此外，TSEASL相比基线规划器记录了更高的规划器稳定性。

Conclusion: TSEASL有效解决了部分可观测环境中参考轨迹剧烈变化导致的安全问题，提高了导航稳定性。论文最后讨论了进一步改进TSEASL以使其更适用于各种越野自主场景的方法。

Abstract: Due to sensor limitations, environments that off-road mobile robots operate in are often only partially observable. As the robots move throughout the environment and towards their goal, the optimal route is continuously revised as the sensors perceive new information. In traditional autonomous navigation architectures, a regional motion planner will consume the environment map and output a trajectory for the local motion planner to use as a reference. Due to the continuous revision of the regional plan guidance as a result of changing map information, the reference trajectories which are passed down to the local planner can differ significantly across sequential planning cycles. This rapidly changing guidance can result in unsafe navigation behavior, often requiring manual safety interventions during autonomous traversals in off-road environments. To remedy this problem, we propose Temporally-Sampled Efficiently Adaptive State Lattices (TSEASL), which is a regional planner arbitration architecture that considers updated and optimized versions of previously generated trajectories against the currently generated trajectory. When tested on a Clearpath Robotics Warthog Unmanned Ground Vehicle as well as real map data collected from the Warthog, results indicate that when running TSEASL, the robot did not require manual interventions in the same locations where the robot was running the baseline planner. Additionally, higher levels of planner stability were recorded with TSEASL over the baseline. The paper concludes with a discussion of further improvements to TSEASL in order to make it more generalizable to various off-road autonomy scenarios.

</details>


### [203] [Human Emotion-Mediated Soft Robotic Arts: Exploring the Intersection of Human Emotions, Soft Robotics and Arts](https://arxiv.org/abs/2602.13163)
*Saitarun Nadipineni,Chenhao Hong,Tanishtha Ramlall,Chapa Sirithunge,Kaspar Althoefer,Fumiya Iida,Thilina Dulantha Lalitharatne*

Main category: cs.RO

TL;DR: 该研究探索了人类情感、软体机器人与艺术的交叉领域，创建了基于脑电α波的情感响应软体机器人艺术装置。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有灵活性、适应性和安全性，适合需要细腻、有机和逼真运动的艺术应用。研究旨在探索人类情感如何通过软体机器人艺术形式进行表达和体现。

Method: 引入两个软体装置（软体角色和软体花朵），通过脑电/EEG信号测量α波来量化人类情感，将α波映射到软体装置的动态运动，并通过实验验证概念。

Result: 成功展示了软体机器人如何体现人类情感状态，为艺术表达和互动提供了新媒介，证明了艺术装置可以通过软体机器人技术实现情感响应。

Conclusion: 软体机器人能够有效体现人类情感状态，为艺术表达和互动创造了新的可能性，展示了情感介导的软体机器人艺术的新形式。

Abstract: Soft robotics has emerged as a versatile field with applications across various domains, from healthcare to industrial automation, and more recently, art and interactive installations. The inherent flexibility, adaptability, and safety of soft robots make them ideal for applications that require delicate, organic, and lifelike movement, allowing for immersive and responsive interactions. This study explores the intersection of human emotions, soft robotics, and art to establish and create new forms of human emotion-mediated soft robotic art. In this paper, we introduce two soft embodiments: a soft character and a soft flower as an art display that dynamically responds to brain signals based on alpha waves, reflecting different emotion levels. We present how human emotions can be measured as alpha waves based on brain/EEG signals, how we map the alpha waves to the dynamic movements of the two soft embodiments, and demonstrate our proposed concept using experiments. The findings of this study highlight how soft robotics can embody human emotional states, offering a new medium for insightful artistic expression and interaction, and demonstrating how art displays can be embodied.

</details>


### [204] [Steerable Vision-Language-Action Policies for Embodied Reasoning and Hierarchical Control](https://arxiv.org/abs/2602.13193)
*William Chen,Jagdeep Singh Bhatia,Catherine Glossop,Nikhil Mathihalli,Ria Doshi,Andy Tang,Danny Driess,Karl Pertsch,Sergey Levine*

Main category: cs.RO

TL;DR: 提出Steerable Policies方法，通过在不同抽象层次训练视觉-语言-动作模型，增强低层控制能力，从而更好地利用预训练视觉语言模型的常识知识，提升机器人任务泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分层方法中，视觉语言模型通过自然语言指令与低层策略交互，这限制了VLM推理对低层行为的引导能力。需要一种方法能够更好地将预训练视觉语言模型的常识知识落地到机器人控制中。

Method: 提出Steerable Policies：在不同抽象层次（如子任务、动作、像素坐标）上使用丰富的合成命令训练视觉-语言-动作模型，增强低层可控性。通过两种方式控制：1) 学习的高层具身推理器；2) 现成的VLM通过上下文学习推理命令抽象。

Result: 在大量真实世界操作实验中，这两种新方法都优于先前的具身推理VLA和基于VLM的分层基线，包括在具有挑战性的泛化和长时程任务上表现更优。

Conclusion: 通过增强低层可控性，Steerable Policies能够解锁预训练视觉语言模型中的知识，实现更好的任务泛化能力，为机器人控制提供了更有效的知识落地方法。

Abstract: Pretrained vision-language models (VLMs) can make semantic and visual inferences across diverse settings, providing valuable common-sense priors for robotic control. However, effectively grounding this knowledge in robot behaviors remains an open challenge. Prior methods often employ a hierarchical approach where VLMs reason over high-level commands to be executed by separate low-level policies, e.g., vision-language-action models (VLAs). The interface between VLMs and VLAs is usually natural language task instructions, which fundamentally limits how much VLM reasoning can steer low-level behavior. We thus introduce Steerable Policies: VLAs trained on rich synthetic commands at various levels of abstraction, like subtasks, motions, and grounded pixel coordinates. By improving low-level controllability, Steerable Policies can unlock pretrained knowledge in VLMs, enabling improved task generalization. We demonstrate this benefit by controlling our Steerable Policies with both a learned high-level embodied reasoner and an off-the-shelf VLM prompted to reason over command abstractions via in-context learning. Across extensive real-world manipulation experiments, these two novel methods outperform prior embodied reasoning VLAs and VLM-based hierarchical baselines, including on challenging generalization and long-horizon tasks.
  Website: steerable-policies.github.io

</details>


### [205] [Imitating What Works: Simulation-Filtered Modular Policy Learning from Human Videos](https://arxiv.org/abs/2602.13197)
*Albert J. Zhai,Kuo-Hao Zeng,Jiasen Lu,Ali Farhadi,Shenlong Wang,Wei-Chiu Ma*

Main category: cs.RO

TL;DR: PSI框架利用人类视频数据，通过仿真中的抓取-轨迹配对过滤来训练模块化机器人操作策略，无需真实机器人数据即可学习精确的抓取和操作技能。


<details>
  <summary>Details</summary>
Motivation: 人类视频为机器人学习提供了可扩展的数据源，但现有方法在抓取学习方面存在局限：人类视频对抓取后动作学习效果好，但对机器人抓取学习帮助有限；模块化策略设计中的通用抓取生成器往往产生与任务不兼容的抓取。

Method: 提出Perceive-Simulate-Imitate（PSI）框架：1）感知人类视频运动数据；2）在仿真中进行抓取-轨迹配对过滤，扩展轨迹数据并添加抓取适用性标签；3）通过监督学习训练任务导向的抓取能力，形成模块化操作策略。

Result: 真实世界实验表明，PSI框架能够高效学习精确的操作技能，无需任何机器人数据，相比简单使用抓取生成器的方法，性能显著更鲁棒。

Conclusion: PSI框架通过仿真中的抓取-轨迹配对过滤，有效解决了任务兼容抓取学习的问题，使机器人能够仅从人类视频数据中学习复杂的操作技能，为机器人学习提供了新的数据来源。

Abstract: The ability to learn manipulation skills by watching videos of humans has the potential to unlock a new source of highly scalable data for robot learning. Here, we tackle prehensile manipulation, in which tasks involve grasping an object before performing various post-grasp motions. Human videos offer strong signals for learning the post-grasp motions, but they are less useful for learning the prerequisite grasping behaviors, especially for robots without human-like hands. A promising way forward is to use a modular policy design, leveraging a dedicated grasp generator to produce stable grasps. However, arbitrary stable grasps are often not task-compatible, hindering the robot's ability to perform the desired downstream motion. To address this challenge, we present Perceive-Simulate-Imitate (PSI), a framework for training a modular manipulation policy using human video motion data processed by paired grasp-trajectory filtering in simulation. This simulation step extends the trajectory data with grasp suitability labels, which allows for supervised learning of task-oriented grasping capabilities. We show through real-world experiments that our framework can be used to learn precise manipulation skills efficiently without any robot data, resulting in significantly more robust performance than using a grasp generator naively.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [206] [GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory](https://arxiv.org/abs/2602.12316)
*Pepijn Cobben,Xuanqiang Angelo Huang,Thao Amelia Pham,Isabel Dahlgren,Terry Jingchen Zhang,Zhijing Jin*

Main category: cs.AI

TL;DR: GT-HarmBench是一个包含2009个高风险场景的多智能体安全基准测试，涵盖囚徒困境、猎鹿博弈等博弈论结构，用于评估前沿AI系统在多智能体环境中的协调能力和风险。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全基准主要评估单智能体，而忽视了多智能体环境中的风险，如协调失败和冲突。随着前沿AI系统在关键多智能体环境中的部署增加，需要专门基准来理解和评估这些风险。

Method: 从MIT AI风险库中提取真实AI风险场景，构建包含2009个高风险场景的基准测试，涵盖囚徒困境、猎鹿博弈、斗鸡博弈等博弈论结构。评估15个前沿模型，测量对博弈论提示框架和顺序的敏感性，并分析导致失败的推理模式。

Result: 在15个前沿模型中，智能体仅在62%的情况下选择对社会有益的行动，经常导致有害结果。博弈论干预可将社会有益结果提高最多18%。

Conclusion: 研究揭示了前沿AI系统在多智能体环境中存在显著可靠性差距，GT-HarmBench为研究多智能体环境中的对齐问题提供了广泛的标准化测试平台，基准测试和代码已开源。

Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.

</details>


### [207] [To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.12566)
*Haoqing Wang,Xiang Long,Ziheng Li,Yilong Xu,Tingguang Li,Yehui Tang*

Main category: cs.AI

TL;DR: 该论文研究了在多领域强化学习中两种训练范式的比较：混合多任务RLVR与分别训练后模型合并，发现跨领域RLVR存在较少相互干扰，推理密集型领域呈现相互协同效应。


<details>
  <summary>Details</summary>
Motivation: 当前在多领域专家级模型训练中，混合多任务RLVR和分别训练后模型合并两种范式缺乏详细的比较分析，需要系统研究这两种方法在不同领域的协作效果。

Method: 选择数学、编程、科学和指令跟随等多个常用高级任务作为目标领域，使用开源数据集设计广泛的定性和定量实验，分析跨领域RLVR的相互影响。

Result: 发现跨领域RLVR存在较少相互干扰，推理密集型领域（如数学和编程）表现出相互协同效应，并从权重空间几何、模型预测行为和信息约束等角度分析了内部机制。

Conclusion: 跨领域RLVR训练具有较好的兼容性，推理密集型领域间的协同效应为多领域专家级模型训练提供了有价值的见解，项目命名为M2RL。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL

</details>


### [208] [Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models](https://arxiv.org/abs/2602.12586)
*Joshua Ong Jun Leang,Yu Zhao,Mihaela Cătălina Stoian,Wenda Li,Shay B. Cohen,Eleonora Giunchiglia*

Main category: cs.AI

TL;DR: McDiffuSE使用蒙特卡洛树搜索优化掩码扩散模型中的槽位填充顺序，通过前瞻模拟评估部分完成情况，显著提升数学和代码推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型中的计划-填充解码方法在数学和代码推理方面有潜力，但性能对填充顺序高度敏感，导致输出方差大，需要系统化的顺序优化方法。

Method: 将槽位选择建模为决策问题，使用蒙特卡洛树搜索优化填充顺序，通过前瞻模拟评估部分完成情况，系统探索生成顺序的组合空间。

Result: 实验显示平均比自回归基线提升3.2%，比基线计划-填充方法提升8.0%，在MBPP上提升19.5%，在MATH500上提升4.9%。

Conclusion: MCTS规划是提升掩码扩散模型生成质量的有效方法，需要更大的探索常数而非更多模拟来克服模型置信度偏差，非顺序生成对最大化性能至关重要。

Abstract: While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.

</details>


### [209] [AI Agents for Inventory Control: Human-LLM-OR Complementarity](https://arxiv.org/abs/2602.12631)
*Jackie Baek,Yaopeng Fu,Will Ma,Tianyi Peng*

Main category: cs.AI

TL;DR: LLM增强的运筹学算法在库存控制中优于单独使用运筹学或LLM方法，人机协作团队比单独人类或AI表现更好


<details>
  <summary>Details</summary>
Motivation: 传统运筹学算法依赖刚性建模假设，在需求分布变化或缺乏上下文信息时表现不佳。LLM具有灵活推理和丰富上下文整合能力，但如何将LLM方法整合到传统决策流程中仍不明确。研究探索运筹学算法、LLM和人类如何互动互补

Method: 构建InventoryBench基准测试，包含1000多个库存实例，涵盖合成和真实需求数据，测试需求变化、季节性和不确定交货期下的决策规则。通过课堂实验研究人机协作，将LLM推荐嵌入人类决策流程

Result: 运筹学增强的LLM方法优于单独使用任一种方法，表明它们是互补而非替代关系。人机协作团队平均利润高于单独人类或AI。形式化了个体层面的互补效应，推导出分布无关的下界，实证发现受益个体比例显著

Conclusion: 运筹学算法、LLM和人类在库存控制中具有互补性，整合方法优于单独使用任一方法。人机协作能提升整体性能，且大部分个体能从AI协作中受益

Abstract: Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.
  We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.
  We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.

</details>


### [210] [Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents](https://arxiv.org/abs/2602.12662)
*Ruihan Yang,Fanghua Ye,Xiang We,Ruoqing Zhao,Kang Luo,Xinbo Xu,Bo Zhao,Ruotian Ma,Shanyi Wang,Zhaopeng Tu,Xiaolong Li,Deqing Yang,Linus*

Main category: cs.AI

TL;DR: CogRouter是一个让LLM智能体根据任务需求动态调整认知深度的框架，通过分层认知级别和两阶段训练，在保持高性能的同时显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在长期任务中存在认知模式僵化问题：非思考模型直接生成响应，思考模型则统一进行深度推理。这种刚性在长期任务中效率低下，因为不同步骤的认知需求差异很大，有些需要战略规划，有些只需常规执行。

Method: 基于ACT-R理论设计了四个分层认知级别（从本能反应到战略规划），采用两阶段训练方法：认知感知监督微调（CoSFT）建立稳定的级别特定模式，认知感知策略优化（CoPO）通过置信度感知优势重加权进行步骤级信用分配。核心洞察是：适当的认知深度应最大化最终行动的置信度。

Result: 在ALFWorld和ScienceWorld上的实验表明，CogRouter实现了最先进的性能且效率优越。使用Qwen2.5-7B模型达到82.3%的成功率，优于GPT-4o（+40.3%）、OpenAI-o3（+18.3%）和GRPO（+14.0%），同时减少了62%的token使用量。

Conclusion: CogRouter通过动态调整认知深度，解决了LLM智能体在长期任务中的认知僵化问题，在保持高性能的同时显著提高了效率，为自适应智能体设计提供了新思路。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.

</details>


### [211] [Evaluating Robustness of Reasoning Models on Parameterized Logical Problems](https://arxiv.org/abs/2602.12665)
*Naïm Es-sebbani,Esteban Marquer,Yakoub Salhi,Zied Bouraoui*

Main category: cs.AI

TL;DR: 研究人员创建了一个诊断性2-SAT基准测试，通过参数化结构公式来分离表面难度与结构现象，揭示LLM推理器的特定能力与失败模式


<details>
  <summary>Details</summary>
Motivation: 标准SAT基准测试常将表面难度（长度、措辞、子句顺序）与决定可满足性的结构现象混为一谈，需要一个能隔离不同推理能力的诊断性测试基准

Method: 构建参数化结构2-CNF公式生成器，通过可解释的维度控制：矛盾循环UNSAT核心、自由变量比例、预设骨干子句、延迟桥接子句、对称/重复变体等

Result: 评估显示LLM推理器在决策准确性和赋值有效性上存在明显差异，在表面统计固定但结构干预下表现出急剧的性能转变，揭示了传统聚合SAT准确率无法发现的脆弱性

Conclusion: 结构化诊断基准能揭示LLM推理器的特定能力与失败模式，表面统计固定时的性能转变表明需要超越传统SAT准确率的更细粒度评估方法

Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.

</details>


### [212] [X-SYS: A Reference Architecture for Interactive Explanation Systems](https://arxiv.org/abs/2602.12748)
*Tobias Labarta,Nhi Hoang,Maximilian Dreyer,Jim Berend,Oleg Hein,Jackie Ma,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.AI

TL;DR: 论文提出X-SYS参考架构，将可解释AI从技术方法提升为信息系统问题，通过STAR质量属性和五组件分解，为交互式解释系统提供可重用蓝图，并在SemanticLens系统中实现验证。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI研究提出了众多技术方法，但将解释性部署为系统仍然具有挑战性。交互式解释系统需要合适的算法和系统能力，以在重复查询、模型和数据演化以及治理约束下保持解释可用性。作者认为，将XAI操作化需要将可解释性视为信息系统问题，用户交互需求会引发特定的系统要求。

Method: 提出X-SYS参考架构，围绕STAR四个质量属性（可扩展性、可追溯性、响应性和适应性）进行组织，并指定五组件分解（XUI服务、解释服务、模型服务、数据服务、编排和治理）。该架构将交互模式映射到系统能力，以解耦用户界面演进和后端计算。通过SemanticLens系统实现验证，该系统用于视觉语言模型中的语义搜索和激活引导。

Result: X-SYS架构通过合同式服务边界支持独立演进，离线/在线分离确保响应性，持久状态管理支持可追溯性。SemanticLens系统展示了该架构的实际可行性，为交互式解释系统提供了端到端设计的可重用蓝图和具体实例化。

Conclusion: 这项工作为交互式解释系统提供了可重用的蓝图和具体实现，支持在操作约束下的端到端设计，帮助(X)AI研究人员、开发者和从业者将交互式解释用户界面与系统能力连接起来。

Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.

</details>


### [213] [Information-theoretic analysis of world models in optimal reward maximizers](https://arxiv.org/abs/2602.12963)
*Alfred Harwood,Jose Faustino,Alex Altair*

Main category: cs.AI

TL;DR: 论文量化了最优策略关于环境的信息量，证明在n状态m动作的受控马尔可夫过程中，确定性最优策略提供n log m比特的环境信息


<details>
  <summary>Details</summary>
Motivation: 研究AI领域一个重要问题：成功行为在多大程度上需要内部世界模型表示。量化最优策略提供的关于底层环境的信息量

Method: 考虑具有n个状态和m个动作的受控马尔可夫过程，假设在可能的转移动态空间上具有均匀先验。证明观察任何非恒定奖励函数的最优确定性策略能传达n log m比特的环境信息

Result: 证明了环境与最优策略之间的互信息为n log m比特。这一界限适用于广泛的优化目标，包括有限时域、无限时域折扣和时均奖励最大化

Conclusion: 这些发现为最优性所需的"隐式世界模型"提供了精确的信息论下界，量化了最优策略中编码的环境信息量

Abstract: An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the "implicit world model'' necessary for optimality.

</details>


### [214] [Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093)
*Yubo Li,Ramayya Krishnan,Rema Padman*

Main category: cs.AI

TL;DR: 推理模型在对抗攻击下表现出有意义但不完整的鲁棒性：大多数推理模型显著优于指令调优基线，但所有模型都表现出不同的脆弱性模式，其中误导性建议普遍有效，社会压力则具有模型特异性效果。


<details>
  <summary>Details</summary>
Motivation: 尽管具有推理能力的大型模型在复杂任务上取得了最先进的性能，但它们在多轮对抗压力下的鲁棒性仍未得到充分探索。本研究旨在评估前沿推理模型在对抗攻击下的表现。

Method: 评估了九个前沿推理模型在对抗攻击下的表现，通过轨迹分析识别失败模式，并测试了置信度感知响应生成（CARG）方法对推理模型的有效性。

Result: 研究发现：1）推理提供有意义但不完整的鲁棒性；2）识别出五种失败模式（自我怀疑、社会从众、建议劫持、情感易感性、推理疲劳），前两种占失败的50%；3）CARG方法对推理模型失效，因为扩展的推理轨迹会导致过度自信；4）随机置信度嵌入比有针对性的提取表现更好。

Conclusion: 推理能力不会自动赋予对抗鲁棒性，基于置信度的防御方法需要对推理模型进行根本性的重新设计。推理模型的脆弱性模式需要专门的安全措施。

Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.

</details>


### [215] [Constrained Assumption-Based Argumentation Frameworks](https://arxiv.org/abs/2602.13135)
*Emanuele De Angelis,Fabio Fioravanti,Maria Chiara Meo,Alberto Pettorossi,Maurizio Proietti,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出了约束ABA（CABA），通过引入约束变量来扩展传统ABA框架，使其能够处理非地面参数和攻击，从而克服了传统ABA仅限于命题原子和地面参数的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于假设的论证（ABA）框架仅限于地面（无变量）参数和基于命题原子的攻击，这限制了其表达能力。为了克服这一限制，需要扩展ABA以支持包含约束变量的非地面参数，使其能够处理更复杂的、可能涉及无限域的论证场景。

Method: 提出约束ABA（CABA）框架，允许组件和参数包含约束变量，这些变量可以在可能无限的域上取值。定义了CABA的非地面语义，包括各种非地面攻击的概念，并展示了新语义如何保守地推广标准ABA语义。

Result: CABA框架成功地将传统ABA扩展到支持约束变量的非地面参数和攻击。新定义的非地面语义能够保守地推广标准ABA语义，意味着在适当条件下，CABA可以退化为传统ABA，同时提供了更强的表达能力。

Conclusion: 约束ABA（CABA）是对传统ABA框架的重要扩展，通过引入约束变量和非地面语义，显著增强了ABA的表达能力和适用性，使其能够处理更复杂的论证场景，同时保持与传统ABA的兼容性。

Abstract: Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.

</details>


### [216] [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166)
*Hugo Henry,Arthur Tsai,Kelly Cohen*

Main category: cs.AI

TL;DR: 提出了一种结合最优控制和模糊规则的混合避障架构，用于无人机自适应约束处理，但发现软件兼容性问题导致约束无法有效执行。


<details>
  <summary>Details</summary>
Motivation: 经典最优控制在不确定性下的局限性，以及航空安全关键系统需要可解释的决策制定，促使开发这种混合架构。

Method: 采用三层Takagi-Sugeno-Kang模糊系统调节约束半径、紧急程度和激活决策，然后将模糊推导的间隔作为软约束纳入最优控制问题，使用FALCON工具箱和IPOPT求解。

Result: 概念验证显示每次迭代计算时间2-3秒，但发现FALCON和IPOPT最新版本存在软件不兼容问题，导致拉格朗日惩罚项始终为零，无法正确执行约束。

Conclusion: 该方法在计算效率上可行，但软件兼容性问题需要解决。未来工作包括验证早期软件版本、优化模糊隶属函数，以及扩展到更高保真度模型和随机障碍环境。

Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.

</details>
