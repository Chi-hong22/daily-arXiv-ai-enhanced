<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ICP-Based Pallet Tracking for Unloading on Inclined Surfaces by Autonomous Forklifts](https://arxiv.org/abs/2602.16744)
*Takuro Kato,Mitsuharu Morisawa*

Main category: cs.RO

TL;DR: 提出一种自主叉车在倾斜表面卸货的控制方法，使用ICP算法实时追踪托盘与货叉的相对位置和姿态，使货叉与目标表面平行对齐，防止卸货时托盘被拖动。


<details>
  <summary>Details</summary>
Motivation: 传统自主叉车在倾斜表面卸货时，货叉与托盘之间的不对齐会导致托盘被拖动，造成货物损坏和操作效率低下。需要一种能够实时调整货叉姿态以适应倾斜表面的控制方法。

Method: 使用迭代最近点（ICP）算法处理托盘上区域测量的点云数据，实时追踪托盘与货叉之间的相对位置和姿态角度差异。根据追踪结果调整货叉姿态，使其与目标倾斜表面平行对齐，然后沿倾斜方向撤回货叉完成卸货。

Result: 通过动态仿真和真实叉车实验验证了该方法的有效性，成功在卡车倾斜床板上完成了卸货操作，避免了托盘被拖动的问题。

Conclusion: 提出的基于ICP算法的控制方法能够有效解决自主叉车在倾斜表面卸货时的对齐问题，实现平稳无拖动的卸货操作，提高了自主叉车在复杂工况下的适用性。

Abstract: This paper proposes a control method for autonomous forklifts to unload pallets on inclined surfaces, enabling the fork to be withdrawn without dragging the pallets. The proposed method applies the Iterative Closest Point (ICP) algorithm to point clouds measured from the upper region of the pallet and thereby tracks the relative position and attitude angle difference between the pallet and the fork during the unloading operation in real-time. According to the tracking result, the fork is aligned parallel to the target surface. After the fork is aligned, it is possible to complete the unloading process by withdrawing the fork along the tilt, preventing any dragging of the pallet. The effectiveness of the proposed method is verified through dynamic simulations and experiments using a real forklift that replicate unloading operations onto the inclined bed of a truck.

</details>


### [2] [Smooth trajectory generation and hybrid B-splines-Quaternions based tool path interpolation for a 3T1R parallel kinematic milling robot](https://arxiv.org/abs/2602.16758)
*Sina Akhbari,Mehran Mahboubkhah*

Main category: cs.RO

TL;DR: 提出了一种用于四自由度并联铣削机器人的平滑轨迹生成方法，结合B样条和四元数插值技术，通过分段贝塞尔曲线同步位置和姿态数据，实现多智能体轨迹的空间和时间约束。


<details>
  <summary>Details</summary>
Motivation: 传统插值方法在四自由度并联铣削机器人轨迹生成中存在精度不足、速度波动大和计算效率低的问题，需要一种能够同时处理解耦位置和姿态数据、确保平滑连续运动的方法。

Method: 采用B样条和四元数插值技术管理解耦的位置和姿态数据点，通过分段贝塞尔曲线拟合实现路径长度与工具姿态的非线性关系同步，利用贝塞尔曲线的凸包特性确保空间和时间分离约束，使用单位四元数进行姿态插值避免万向节锁，位置插值使用修正多项式，采用两阶段最小急动度时间最优分段贝塞尔曲线优化时间轨迹。

Result: 实验结果表明，与传统插值方法相比，所提方法具有更高的精度、更小的速度波动和更好的计算效率。

Conclusion: 该方法成功实现了四自由度并联铣削机器人的平滑轨迹生成，通过创新的同步技术和优化策略，在精度、平滑性和计算效率方面均优于传统方法，可在低成本微控制器上实现。

Abstract: This paper presents a smooth trajectory generation method for a four-degree-of-freedom parallel kinematic milling robot. The proposed approach integrates B-spline and Quaternion interpolation techniques to manage decoupled position and orientation data points. The synchronization of orientation and arc-length-parameterized position data is achieved through the fitting of smooth piece-wise Bezier curves, which describe the non-linear relationship between path length and tool orientation, solved via sequential quadratic programming. By leveraging the convex hull properties of Bezier curves, the method ensures spatial and temporal separation constraints for multi-agent trajectory generation. Unit quaternions are employed for orientation interpolation, providing a robust and efficient representation that avoids gimbal lock and facilitates smooth, continuous rotation. Modifier polynomials are used for position interpolation. Temporal trajectories are optimized using minimum jerk, time-optimal piece-wise Bezier curves in two stages: task space followed by joint space, implemented on a low-cost microcontroller. Experimental results demonstrate that the proposed method offers enhanced accuracy, reduced velocity fluctuations, and computational efficiency compared to conventional interpolation methods.

</details>


### [3] [RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness](https://arxiv.org/abs/2602.16825)
*Ahmad Ahmad,Shuo Liu,Roberto Tron,Calin Belta*

Main category: cs.RO

TL;DR: RRT^η：一种结合算术几何平均鲁棒性度量的采样运动规划框架，用于满足信号时序逻辑规范，在复杂时空约束下表现优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统基于采样运动规划与信号时序逻辑结合的方法依赖最小-最大鲁棒性度量，只关注关键时间点和子公式，导致非平滑优化景观和尖锐决策边界，阻碍高效的树探索

Method: 提出RRT^η框架，集成算术几何平均鲁棒性度量评估所有时间点和子公式的满足程度；包括AGM鲁棒性区间语义用于树构建中的部分轨迹推理、高效增量监控算法计算这些区间、以及利用满足优先级逻辑增强满意度增加方向向量

Result: 在三个机器人系统上验证：双积分点机器人、独轮车移动机器人和7自由度机械臂，在有限引导信号的多约束场景中表现出优于传统STL鲁棒性规划器的性能

Conclusion: RRT^η框架能够合成满足STL规范的高鲁棒性动态可行控制序列，同时保持RRT*的概率完备性和渐近最优性，在复杂时空约束下提供更优的规划性能

Abstract: Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-dimensional configuration spaces. When combined with Signal Temporal Logic (STL), a temporal logic widely used for formalizing interpretable robotic tasks, these methods can address complex spatiotemporal constraints. However, traditional approaches rely on min-max robustness measures that focus only on critical time points and subformulae, creating non-smooth optimization landscapes with sharp decision boundaries that hinder efficient tree exploration.
  We propose RRT$^η$, a sampling-based planning framework that integrates the Arithmetic-Geometric Mean (AGM) robustness measure to evaluate satisfaction across all time points and subformulae. Our key contributions include: (1) AGM robustness interval semantics for reasoning about partial trajectories during tree construction, (2) an efficient incremental monitoring algorithm computing these intervals, and (3) enhanced Direction of Increasing Satisfaction vectors leveraging Fulfillment Priority Logic (FPL) for principled objective composition. Our framework synthesizes dynamically feasible control sequences satisfying STL specifications with high robustness while maintaining the probabilistic completeness and asymptotic optimality of RRT$^\ast$. We validate our approach on three robotic systems. A double integrator point robot, a unicycle mobile robot, and a 7-DOF robot arm, demonstrating superior performance over traditional STL robustness-based planners in multi-constraint scenarios with limited guidance signals.

</details>


### [4] [Sound of Touch: Active Acoustic Tactile Sensing via String Vibrations](https://arxiv.org/abs/2602.16846)
*Xili Yi,Ying Xing,Zachary Manchester,Nima Fazeli*

Main category: cs.RO

TL;DR: Sound of Touch：一种基于振动弦的主动声学触觉传感方法，通过少量拾音器检测接触引起的频谱变化，实现接触位置、法向力和滑移的实时检测。


<details>
  <summary>Details</summary>
Motivation: 分布式触觉传感在大面积应用时面临挑战：密集传感器阵列增加布线、成本和脆弱性，而许多替代方案覆盖有限或无法捕捉快速交互动态。

Method: 使用振动张紧弦作为传感元件，通过电磁连续激励弦，用少量接触式麦克风观察接触引起的频谱变化。开发基于物理的弦振动模拟器预测接触位置和力如何改变振动模式，并建立实时推理管道将振动测量映射到接触状态。

Result: 实验证明毫米级定位精度、可靠的力量估计和实时滑移检测能力。

Conclusion: 提出了一种轻量级、可扩展的弦基触觉传感硬件概念，适用于机器人扩展表面；开发了基于物理的模拟分析工具和实时推理管道，为大面积触觉传感提供了新解决方案。

Abstract: Distributed tactile sensing remains difficult to scale over large areas: dense sensor arrays increase wiring, cost, and fragility, while many alternatives provide limited coverage or miss fast interaction dynamics. We present Sound of Touch, an active acoustic tactile-sensing methodology that uses vibrating tensioned strings as sensing elements. The string is continuously excited electromagnetically, and a small number of pickups (contact microphones) observe spectral changes induced by contact. From short-duration audio signals, our system estimates contact location and normal force, and detects slip. To guide design and interpret the sensing mechanism, we derive a physics-based string-vibration simulator that predicts how contact position and force shift vibration modes. Experiments demonstrate millimeter-scale localization, reliable force estimation, and real-time slip detection. Our contributions are: (i) a lightweight, scalable string-based tactile sensing hardware concept for instrumenting extended robot surfaces; (ii) a physics-grounded simulation and analysis tool for contact-induced spectral shifts; and (iii) a real-time inference pipeline that maps vibration measurements to contact state.

</details>


### [5] ["Hello, I'm Delivering. Let Me Pass By": Navigating Public Pathways with Walk-along with Robots in Crowded City Streets](https://arxiv.org/abs/2602.16861)
*EunJeong Cheon,Do Yeon Shin*

Main category: cs.RO

TL;DR: 提出"Walk-Along with Robots"方法，用于研究公共场所自主移动机器人


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人在公共场所日益增多，现有HRI研究方法（如受控实验、Wizard of Oz技术）难以研究实际运营中的自主机器人，需要新的研究方法

Method: 借鉴城市研究、地理学和社会学中的公共领域民族志方法，提出Walk-Along with Robots方法，包括方法特征、实施步骤、独特见解和评估方式

Result: 提出了系统的WawR方法论框架，为研究公共场所自主机器人提供新途径

Conclusion: WawR方法能够有效研究公共场所自主机器人，希望促进该领域研究方法论的进一步讨论

Abstract: As the presence of autonomous robots in public spaces increases-whether navigating campus walkways or neighborhood sidewalks-understanding how to carefully study these robots becomes critical. While HRI research has conducted field studies in public spaces, these are often limited to controlled experiments with prototype robots or structured observational methods, such as the Wizard of Oz technique. However, the autonomous mobile robots we encounter today, particularly delivery robots, operate beyond the control of researchers, navigating dynamic routes and unpredictable environments. To address this challenge, a more deliberate approach is required. Drawing inspiration from public realm ethnography in urban studies, geography, and sociology, this paper proposes the Walk-Along with Robots (WawR) methodology. We outline the key features of this method, the steps we applied in our study, the unique insights it offers, and the ways it can be evaluated. We hope this paper stimulates further discussion on research methodologies for studying autonomous robots in public spaces.

</details>


### [6] [SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation](https://arxiv.org/abs/2602.16863)
*Kushal Kedia,Tyler Ga Wei Lum,Jeannette Bohg,C. Karen Liu*

Main category: cs.RO

TL;DR: SimToolReal：一种通过程序化生成多样化工具状物体并训练单一强化学习策略的sim-to-real方法，实现零样本通用工具操作


<details>
  <summary>Details</summary>
Motivation: 工具操作是机器人面临的重要挑战，需要精细的抓取、旋转和力量交互。传统方法需要为每个任务单独建模和调优，工程量大且难以泛化

Method: 在仿真中程序化生成大量工具状物体基元，训练单一RL策略以随机目标姿态操作这些物体，实现通用工具操作能力

Result: 性能超越先前重定向和固定抓取方法37%，与针对特定对象任务训练的专家策略相当；在真实世界中零样本泛化到120次实验，涵盖24个任务、12个对象实例和6种工具类别

Conclusion: SimToolReal展示了通过程序化生成多样化训练对象和通用目标设定，可以实现强大的零样本工具操作泛化能力，为通用机器人操作提供了有前景的方向

Abstract: The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behaviors is challenging, sim-to-real reinforcement learning (RL) is a promising alternative. However, prior approaches typically require substantial engineering effort to model objects and tune reward functions for each task. In this work, we propose SimToolReal, taking a step towards generalizing sim-to-real RL policies for tool manipulation. Instead of focusing on a single object and task, we procedurally generate a large variety of tool-like object primitives in simulation and train a single RL policy with the universal goal of manipulating each object to random goal poses. This approach enables SimToolReal to perform general dexterous tool manipulation at test-time without any object or task-specific training. We demonstrate that SimToolReal outperforms prior retargeting and fixed-grasp methods by 37% while matching the performance of specialist RL policies trained on specific target objects and tasks. Finally, we show that SimToolReal generalizes across a diverse set of everyday tools, achieving strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.

</details>


### [7] [Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads](https://arxiv.org/abs/2602.16870)
*Daniil Lisus,Katya M. Papais,Cedric Le Gentil,Elliot Preston-Krebs,Andrew Lambert,Keith Y. K. Leung,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: Boreas-RT数据集扩展了原有的Boreas数据集，包含9条真实世界路线的60个序列，总计643公里驾驶数据，用于评估自动驾驶算法在多样化挑战性环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶算法通常在简单驾驶环境中表现良好，但在多样化、挑战性的真实世界环境中性能会显著下降。需要一个新的数据集来评估多模态算法在不同道路条件下的鲁棒性。

Method: 使用配备多种传感器的数据采集平台（包括5MP相机、360度雷达、128通道激光雷达、FMCW激光雷达、IMU和轮编码器），在9条不同路线上收集643公里驾驶数据，每条路线多次遍历以评估不同交通和天气条件下的表现。

Result: 基准测试显示，许多最先进的里程计和定位算法在简单的驾驶环境中过拟合，在更具挑战性的Boreas-RT路线上性能显著下降。该数据集提供了厘米级地面真值、精确标定和公开开发工具包。

Conclusion: Boreas-RT为评估多模态算法在多样化道路条件下的性能提供了统一的数据集，揭示了现有算法在复杂环境中的局限性，并提供了公开的开发工具包和排行榜来促进研究。

Abstract: The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose challenges for modern autonomous driving algorithms. Boreas-RT comprises 60 sequences collected over 9 real-world routes, totalling 643 km of driving. Each route is traversed multiple times, enabling evaluation in identical environments under varying traffic and, in some cases, weather conditions. The data collection platform includes a 5MP FLIR Blackfly S camera, a 360 degree Navtech RAS6 Doppler-enabled spinning radar, a 128-channel 360 degree Velodyne Alpha Prime lidar, an Aeva Aeries II FMCW Doppler-enabled lidar, a Silicon Sensing DMU41 inertial measurement unit, and a Dynapar wheel encoder. Centimetre-level ground truth is provided via post-processed Applanix POS LV GNSS-INS data. The dataset includes precise extrinsic and intrinsic calibrations, a publicly available development kit, and a live leaderboard for odometry and metric localization. Benchmark results show that many state-of-the-art odometry and localization algorithms overfit to simple driving environments and degrade significantly on the more challenging Boreas-RT routes. Boreas-RT provides a unified dataset for evaluating multi-modal algorithms across diverse road conditions. The dataset, leaderboard, and development kit are available at www.boreas.utias.utoronto.ca.

</details>


### [8] [SparTa: Sparse Graphical Task Models from a Handful of Demonstrations](https://arxiv.org/abs/2602.16911)
*Adrian Röfer,Nick Heppert,Abhinav Valada*

Main category: cs.RO

TL;DR: 该论文提出了一种基于图形关系表示的长时程机器人操作任务学习方法，通过演示分割和池化提取操作图，学习任务目标而非具体动作执行方式。


<details>
  <summary>Details</summary>
Motivation: 当前机器人从演示中学习长时程操作任务的方法主要集中在动作域的直接学习，但作者认为应该关注机器人应该实现什么任务目标，而不是如何实现。现有基于图的方法只能捕捉部分交互或短时间窗口，无法完整捕获从控制开始到操作结束的完整对象交互。

Method: 1. 使用图形对象关系表示演化场景状态；2. 提出演示分割和池化方法，提取操作图并估计任务各阶段的对象状态分布；3. 使用预训练视觉特征进行对象匹配以提高多演示学习的鲁棒性；4. 捕获从控制开始到操作结束的完整对象交互。

Result: 1. 在广泛实验中评估了演示分割准确性；2. 验证了从多演示中学习对于找到期望最小任务模型的效用；3. 在仿真和真实机器人上部署了拟合模型，证明所得任务表示支持跨环境的可靠执行。

Conclusion: 该方法能够有效学习长时程机器人操作任务，通过图形关系表示和演示分割池化技术，实现了对任务目标的推断而非具体动作的学习，支持跨环境的可靠执行。

Abstract: Learning long-horizon manipulation tasks efficiently is a central challenge in robot learning from demonstration. Unlike recent endeavors that focus on directly learning the task in the action domain, we focus on inferring what the robot should achieve in the task, rather than how to do so. To this end, we represent evolving scene states using a series of graphical object relationships. We propose a demonstration segmentation and pooling approach that extracts a series of manipulation graphs and estimates distributions over object states across task phases. In contrast to prior graph-based methods that capture only partial interactions or short temporal windows, our approach captures complete object interactions spanning from the onset of control to the end of the manipulation. To improve robustness when learning from multiple demonstrations, we additionally perform object matching using pre-trained visual features. In extensive experiments, we evaluate our method's demonstration segmentation accuracy and the utility of learning from multiple demonstrations for finding a desired minimal task model. Finally, we deploy the fitted models both in simulation and on a real robot, demonstrating that the resulting task representations support reliable execution across environments.

</details>


### [9] [Benchmarking the Effects of Object Pose Estimation and Reconstruction on Robotic Grasping Success](https://arxiv.org/abs/2602.17101)
*Varun Burde,Pavel Burget,Torsten Sattler*

Main category: cs.RO

TL;DR: 该论文提出了一个基于物理的大规模基准测试，用于评估6D姿态估计器和3D网格模型在机器人抓取任务中的功能有效性，分析重建质量对下游操作性能的影响。


<details>
  <summary>Details</summary>
Motivation: 当前3D重建方法虽然能产生视觉和几何上令人印象深刻的网格，但标准的几何评估无法反映重建质量如何影响机器人操作等下游任务性能。需要填补这一空白，评估感知系统与物体操作之间的关系。

Method: 引入大规模物理基准测试，通过在重建的3D网格上生成抓取姿态并在真实模型上执行，模拟使用不完美模型生成的抓取姿态如何影响与真实物体的交互，评估姿态误差、抓取鲁棒性和3D重建几何误差的综合影响。

Result: 重建伪影显著减少了抓取姿态候选数量，但在姿态准确估计的情况下对抓取性能影响可忽略；抓取成功与姿态误差的关系主要由空间误差主导，即使简单的平移误差也能为对称物体的抓取姿态成功提供洞察。

Conclusion: 这项工作为理解感知系统如何影响机器人物体操作提供了重要见解，建立了重建质量与下游操作任务性能之间的评估框架。

Abstract: 3D reconstruction serves as the foundational layer for numerous robotic perception tasks, including 6D object pose estimation and grasp pose generation. Modern 3D reconstruction methods for objects can produce visually and geometrically impressive meshes from multi-view images, yet standard geometric evaluations do not reflect how reconstruction quality influences downstream tasks such as robotic manipulation performance. This paper addresses this gap by introducing a large-scale, physics-based benchmark that evaluates 6D pose estimators and 3D mesh models based on their functional efficacy in grasping. We analyze the impact of model fidelity by generating grasps on various reconstructed 3D meshes and executing them on the ground-truth model, simulating how grasp poses generated with an imperfect model affect interaction with the real object. This assesses the combined impact of pose error, grasp robustness, and geometric inaccuracies from 3D reconstruction. Our results show that reconstruction artifacts significantly decrease the number of grasp pose candidates but have a negligible effect on grasping performance given an accurately estimated pose. Our results also reveal that the relationship between grasp success and pose error is dominated by spatial error, and even a simple translation error provides insight into the success of the grasping pose of symmetric objects. This work provides insight into how perception systems relate to object manipulation using robots.

</details>


### [10] [Grasp Synthesis Matching From Rigid To Soft Robot Grippers Using Conditional Flow Matching](https://arxiv.org/abs/2602.17110)
*Tanisha Parulekar,Ge Shi,Josh Pinskier,David Howard,Jen Jen Chung*

Main category: cs.RO

TL;DR: 本文提出了一种基于条件流匹配（CFM）的框架，将刚性夹爪的抓取姿态映射到软体Fin-ray夹爪，解决了刚性抓取合成方法不适用于软体夹爪的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的抓取合成方法（如Anygrasp）主要针对刚性平行夹爪设计，直接应用于软体夹爪时无法捕捉其独特的顺应行为，导致数据密集且不准确的模型。需要一种方法来弥合刚性夹爪和软体夹爪之间的表示差距。

Method: 提出基于条件流匹配（CFM）的生成模型框架，通过数据收集管道生成配对的刚性-软体抓取姿态。使用U-Net自编码器从深度图像中提取物体几何信息作为CFM的条件，学习从初始Anygrasp姿态到稳定Fin-ray夹爪姿态的连续映射。

Result: 在7自由度机器人上验证，CFM生成的姿态在软体夹爪执行时，对已见和未见物体的总体成功率分别为34%和46%，显著优于基线刚性姿态的6%和25%。特别是对圆柱体（已见50%，未见100%）和球体（已见25%，未见31%）有显著改进，并能成功泛化到未见物体。

Conclusion: CFM作为一种数据高效且有效的方法，能够成功地将抓取策略从刚性夹爪转移到软体夹爪，为其他软体机器人系统提供了可扩展的方法论。

Abstract: A representation gap exists between grasp synthesis for rigid and soft grippers. Anygrasp [1] and many other grasp synthesis methods are designed for rigid parallel grippers, and adapting them to soft grippers often fails to capture their unique compliant behaviors, resulting in data-intensive and inaccurate models. To bridge this gap, this paper proposes a novel framework to map grasp poses from a rigid gripper model to a soft Fin-ray gripper. We utilize Conditional Flow Matching (CFM), a generative model, to learn this complex transformation. Our methodology includes a data collection pipeline to generate paired rigid-soft grasp poses. A U-Net autoencoder conditions the CFM model on the object's geometry from a depth image, allowing it to learn a continuous mapping from an initial Anygrasp pose to a stable Fin-ray gripper pose. We validate our approach on a 7-DOF robot, demonstrating that our CFM-generated poses achieve a higher overall success rate for seen and unseen objects (34% and 46% respectively) compared to the baseline rigid poses (6% and 25% respectively) when executed by the soft gripper. The model shows significant improvements, particularly for cylindrical (50% and 100% success for seen and unseen objects) and spherical objects (25% and 31% success for seen and unseen objects), and successfully generalizes to unseen objects. This work presents CFM as a data-efficient and effective method for transferring grasp strategies, offering a scalable methodology for other soft robotic systems.

</details>


### [11] [Physical Human-Robot Interaction for Grasping in Augmented Reality via Rigid-Soft Robot Synergy](https://arxiv.org/abs/2602.17128)
*Huishi Huang,Jack Klusmann,Haozhe Wang,Shuchen Ji,Fengkang Ying,Yiyuan Zhang,John Nassour,Gordon Cheng,Daniela Rus,Jun Liu,Marcelo H Ang,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出基于增强现实的混合刚软机器人遥操作框架，通过AR头显实现虚拟仿真与物理系统的叠加，引入实-仿参数识别确保一致性


<details>
  <summary>Details</summary>
Motivation: 混合刚软机器人结合了刚性机械臂的精确性和软体手臂的顺应性，在非结构化环境中具有应用潜力，但由于建模、感知和跨域运动学的困难，协调控制仍然具有挑战性

Method: 开发AR物理人机交互框架，用户通过AR头显与集成到通用物理引擎的机器人仿真模型交互，模型叠加在真实系统上；引入实-仿参数识别管道，利用软体机器人的几何特性准确建模其静态/动态行为及控制系统响应

Result: 实现了混合刚软机器人的直接遥操作，支持简单的到达和抓取任务，确保虚拟机器人与物理机器人行为一致性

Conclusion: AR-based框架为混合刚软机器人提供直观的交互方式，实-仿参数识别确保准确建模，为复杂环境中的机器人操作提供新途径

Abstract: Hybrid rigid-soft robots combine the precision of rigid manipulators with the compliance and adaptability of soft arms, offering a promising approach for versatile grasping in unstructured environments. However, coordinating hybrid robots remains challenging, due to difficulties in modeling, perception, and cross-domain kinematics. In this work, we present a novel augmented reality (AR)-based physical human-robot interaction framework that enables direct teleoperation of a hybrid rigid-soft robot for simple reaching and grasping tasks. Using an AR headset, users can interact with a simulated model of the robotic system integrated into a general-purpose physics engine, which is superimposed on the real system, allowing simulated execution prior to real-world deployment. To ensure consistent behavior between the virtual and physical robots, we introduce a real-to-simulation parameter identification pipeline that leverages the inherent geometric properties of the soft robot, enabling accurate modeling of its static and dynamic behavior as well as the control system's response.

</details>


### [12] [Geometric Inverse Flight Dynamics on SO(3) and Application to Tethered Fixed-Wing Aircraft](https://arxiv.org/abs/2602.17166)
*Antonio Franchi,Chiara Gabellieri*

Main category: cs.RO

TL;DR: 提出了一种基于SO(3)的固定翼飞机逆飞行动力学坐标无关公式，通过几何定义气动力方向，在协调飞行条件下推导出闭式轨迹到输入的映射，并应用于球形平行线上的系留飞行分析。


<details>
  <summary>Details</summary>
Motivation: 连接航空领域的逆仿真与机器人学的几何建模，为轨迹设计和可行性检查提供严格的数学基础，避免局部姿态坐标的复杂性。

Method: 采用坐标无关的SO(3)公式，在世界坐标系中写平移力平衡，在机体坐标系中写旋转动力学；几何定义气动力方向（阻力、升力、侧力）；在无侧滑的协调飞行条件下推导闭式轨迹到输入的映射。

Result: 获得了姿态、角速度、推力-攻角对的闭式映射，恢复了气动力矩系数分量；应用于球形平行线上的系留飞行，得到了所需滚转角的解析表达式，并识别出零滚转轨迹；在简单升阻定律下，最小推力攻角有闭式解。

Conclusion: 该框架为轨迹设计和可行性检查提供了严格的构建模块，当轨迹和旋转动力学时不变时，点式准稳态反演解成为稳态飞行配平，实现了航空逆仿真与机器人几何建模的桥梁作用。

Abstract: We present a robotics-oriented, coordinate-free formulation of inverse flight dynamics for fixed-wing aircraft on SO(3). Translational force balance is written in the world frame and rotational dynamics in the body frame; aerodynamic directions (drag, lift, side) are defined geometrically, avoiding local attitude coordinates. Enforcing coordinated flight (no sideslip), we derive a closed-form trajectory-to-input map yielding the attitude, angular velocity, and thrust-angle-of-attack pair, and we recover the aerodynamic moment coefficients component-wise. Applying such a map to tethered flight on spherical parallels, we obtain analytic expressions for the required bank angle and identify a specific zero-bank locus where the tether tension exactly balances centrifugal effects, highlighting the decoupling between aerodynamic coordination and the apparent gravity vector. Under a simple lift/drag law, the minimal-thrust angle of attack admits a closed form. These pointwise quasi-steady inversion solutions become steady-flight trim when the trajectory and rotational dynamics are time-invariant. The framework bridges inverse simulation in aeronautics with geometric modeling in robotics, providing a rigorous building block for trajectory design and feasibility checks.

</details>


### [13] [Nonlinear Predictive Control of the Continuum and Hybrid Dynamics of a Suspended Deformable Cable for Aerial Pick and Place](https://arxiv.org/abs/2602.17199)
*Antonio Rapuano,Yaolei Shen,Federico Califano,Chiara Gabellieri,Antonio Franchi*

Main category: cs.RO

TL;DR: 提出一个结合PDE高保真模型和降阶模型的框架，用于无人机携带可伸缩电缆的空中操作实时控制


<details>
  <summary>Details</summary>
Motivation: 无人机携带柔性电缆进行空中操作时，需要处理复杂的电缆动力学和实时控制需求，传统方法计算复杂度高，难以实现实时控制

Method: 使用有限差分法离散化PDE模型，采用本征正交分解提取降阶模型，基于降阶模型设计非线性模型预测控制器

Result: 降阶模型保持了稳定性、效率和鲁棒性，控制器能有效调节电缆动力学，在多种工况下稳定电缆振荡并处理负载连接/断开等混合过渡

Conclusion: 该框架实现了无人机携带悬挂柔性电缆的实时动力学感知控制，展示了在受限环境中轨迹规划的适用性

Abstract: This paper presents a framework for aerial manipulation of an extensible cable that combines a high-fidelity model based on partial differential equations (PDEs) with a reduced-order representation suitable for real-time control. The PDEs are discretised using a finite-difference method, and proper orthogonal decomposition is employed to extract a reduced-order model (ROM) that retains the dominant deformation modes while significantly reducing computational complexity. Based on this ROM, a nonlinear model predictive control scheme is formulated, capable of stabilizing cable oscillations and handling hybrid transitions such as payload attachment and detachment. Simulation results confirm the stability, efficiency, and robustness of the ROM, as well as the effectiveness of the controller in regulating cable dynamics under a range of operating conditions. Additional simulations illustrate the application of the ROM for trajectory planning in constrained environments, demonstrating the versatility of the proposed approach. Overall, the framework enables real-time, dynamics-aware control of unmanned aerial vehicles (UAVs) carrying suspended flexible cables.

</details>


### [14] [Multi-session Localization and Mapping Exploiting Topological Information](https://arxiv.org/abs/2602.17226)
*Lorenzo Montano-Olivan,Julio A. Placed,Luis Montano,Maria T. Lazaro*

Main category: cs.RO

TL;DR: 提出了一种基于地图定位的多会话框架，通过拓扑感知的决策机制选择性触发建图和闭环检测，提高重复环境中的地图全局一致性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶、勘测和机器人等自主系统经常需要在重复访问的环境中操作，这对建图和定位提出了重大挑战。现有方法通常贪婪地运行完整SLAM会话并尝试在生成的地图之间建立对应关系，这种方法存在局限性。

Method: 提出了一种新颖的多会话框架，基于地图定位而非完整SLAM。采用拓扑感知、不确定性感知的决策机制，分析位姿图结构以检测低连通性区域，选择性触发建图和闭环检测模块。生成的图和位姿图无缝集成到现有模型中。

Result: 在数据集的重叠序列上验证了该方法，并在真实世界的矿井类环境中展示了其有效性。该方法能够减少累积误差并增强全局一致性。

Conclusion: 该多会话框架通过智能决策机制选择性触发建图和闭环检测，在重复访问环境中实现了更高效、更一致的地图构建和定位，优于传统的贪婪SLAM方法。

Abstract: Operating in previously visited environments is becoming increasingly crucial for autonomous systems, with direct applications in autonomous driving, surveying, and warehouse or household robotics. This repeated exposure to observing the same areas poses significant challenges for mapping and localization -- key components for enabling any higher-level task. In this work, we propose a novel multi-session framework that builds on map-based localization, in contrast to the common practice of greedily running full SLAM sessions and trying to find correspondences between the resulting maps. Our approach incorporates a topology-informed, uncertainty-aware decision-making mechanism that analyzes the pose-graph structure to detect low-connectivity regions, selectively triggering mapping and loop closing modules. The resulting map and pose-graph are seamlessly integrated into the existing model, reducing accumulated error and enhancing global consistency. We validate our method on overlapping sequences from datasets and demonstrate its effectiveness in a real-world mine-like environment.

</details>


### [15] [FRAPPE: Infusing World Modeling into Generalist Policies via Multiple Future Representation Alignment](https://arxiv.org/abs/2602.17259)
*Han Zhao,Jingbo Wang,Wenxuan Song,Shuai Chen,Yang Liu,Yan Wang,Haoang Li,Donglin Wang*

Main category: cs.RO

TL;DR: FRAPPE方法通过两阶段微调策略解决VLA模型世界建模中的像素级重建过度强调和误差累积问题，提升机器人策略的世界感知能力


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在环境动态预测（世界建模）中存在两个主要问题：1. 训练目标迫使模型过度强调像素级重建，限制了语义学习和泛化能力；2. 推理时依赖预测的未来观测导致误差累积。这些问题影响了机器人推理和泛化能力的提升。

Method: 提出FRAPPE方法，采用两阶段微调策略：1. 中期训练阶段：模型学习预测未来观测的潜在表示；2. 后期训练阶段：并行扩展计算工作量，同时与多个不同的视觉基础模型对齐表示。该方法显著提高了微调效率，减少了对动作标注数据的依赖。

Result: 在RoboTwin基准测试和真实世界任务中，FRAPPE优于最先进的方法，在长时域和未见场景中表现出强大的泛化能力。

Conclusion: FRAPPE为增强通用机器人策略的世界感知能力提供了一条可扩展且数据高效的途径，通过解决当前世界建模方法的局限性，显著提升了机器人推理和泛化性能。

Abstract: Enabling VLA models to predict environmental dynamics, known as world modeling, has been recognized as essential for improving robotic reasoning and generalization. However, current approaches face two main issues: 1. The training objective forces models to over-emphasize pixel-level reconstruction, which constrains semantic learning and generalization 2. Reliance on predicted future observations during inference often leads to error accumulation. To address these challenges, we introduce Future Representation Alignment via Parallel Progressive Expansion (FRAPPE). Our method adopts a two-stage fine-tuning strategy: In the mid-training phase, the model learns to predict the latent representations of future observations; In the post-training phase, we expand the computational workload in parallel and align the representation simultaneously with multiple different visual foundation models. By significantly improving fine-tuning efficiency and reducing dependence on action-annotated data, FRAPPE provides a scalable and data-efficient pathway to enhance world-awareness in generalist robotic policies. Experiments on the RoboTwin benchmark and real-world tasks demonstrate that FRAPPE outperforms state-of-the-art approaches and shows strong generalization in long-horizon and unseen scenarios.

</details>


### [16] [Contact-Anchored Proprioceptive Odometry for Quadruped Robots](https://arxiv.org/abs/2602.17393)
*Minxing Sun,Yao Mao*

Main category: cs.RO

TL;DR: 本文提出了一种仅使用IMU和电机测量的纯本体感知状态估计器，通过将接触腿作为运动学锚点、基于关节扭矩的足部力估计选择可靠接触点，以及引入高度聚类和时间衰减校正来抑制长期漂移。


<details>
  <summary>Details</summary>
Motivation: 对于没有摄像头或激光雷达的腿式机器人，可靠的里程计仍然具有挑战性，主要问题在于IMU漂移和关节速度传感噪声。需要一种仅依赖本体感知的解决方案来估计身体姿态和速度。

Method: 1. 将接触腿作为运动学锚点，通过关节扭矩估计足部力来选择可靠接触点；2. 引入轻量级高度聚类和时间衰减校正来抑制高度漂移；3. 使用逆运动学立方卡尔曼滤波器直接从关节角度和速度滤波足端速度；4. 通过多接触几何一致性减轻偏航漂移。

Result: 在四个四足机器人平台上进行评估：Astrall点足机器人A完成约200米水平环路误差0.1638米，约15米垂直环路误差0.219米；轮腿机器人B相应误差为0.2264米和0.199米；轮腿机器人C约700米水平环路误差7.68米，约20米垂直环路误差0.540米；Unitree Go2 EDU约120米水平环路误差2.2138米，约8米垂直环路垂直误差小于0.1米。

Conclusion: 该方法为双足、四足和轮腿机器人提供了一种统一的纯本体感知状态估计框架，能够有效抑制长期漂移，在多种机器人平台上表现出良好的性能。

Abstract: Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents a purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with a unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as a kinematic anchor: joint-torque--based foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce a lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to a kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and a Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot~A, a $\sim$200\,m horizontal loop and a $\sim$15\,m vertical loop return with 0.1638\,m and 0.219\,m error, respectively; on wheel-legged robot~B, the corresponding errors are 0.2264\,m and 0.199\,m. On wheel-legged robot~C, a $\sim$700\,m horizontal loop yields 7.68\,m error and a $\sim$20\,m vertical loop yields 0.540\,m error. Unitree Go2 EDU closes a $\sim$120\,m horizontal loop with 2.2138\,m error and a $\sim$8\,m vertical loop with less than 0.1\,m vertical error. github.com/ShineMinxing/Ros2Go2Estimator.git

</details>


### [17] [Distributed Virtual Model Control for Scalable Human-Robot Collaboration in Shared Workspace](https://arxiv.org/abs/2602.17415)
*Yi Zhang,Omar Faris,Chapa Sirithunge,Kai-Fung Chu,Fumiya Iida,Fulvio Forni*

Main category: cs.RO

TL;DR: 提出基于虚拟模型控制的去中心化、智能体无关、安全感知的人机协作控制框架，通过虚拟弹簧阻尼器实现运动，无需显式轨迹规划，有效解决死锁问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决人机协作中的安全问题和死锁问题，特别是在多智能体环境下需要去中心化、可扩展的控制框架。

Method: 基于虚拟模型控制(VMC)，将人和机器人嵌入同一虚拟组件形状的工作空间，通过虚拟弹簧和阻尼器实现运动交互；采用去中心化的力基停滞检测器识别死锁，并通过协商解决。

Result: 在实验中，将机器人卡死在块放置任务中的概率从最高61.2%降至零；在实验中安全协作最多2个机器人和2个人，在仿真中最多4个机器人，保持智能体间约20厘米的分离距离。

Conclusion: 该方法通过调整控制参数直观地塑造机器人行为，在所有测试场景中实现了跨团队规模的无死锁操作，分布式实现使框架无需结构变化即可扩展。

Abstract: We present a decentralized, agent agnostic, and safety-aware control framework for human-robot collaboration based on Virtual Model Control (VMC). In our approach, both humans and robots are embedded in the same virtual-component-shaped workspace, where motion is the result of the interaction with virtual springs and dampers rather than explicit trajectory planning. A decentralized, force-based stall detector identifies deadlocks, which are resolved through negotiation. This reduces the probability of robots getting stuck in the block placement task from up to 61.2% to zero in our experiments. The framework scales without structural changes thanks to the distributed implementation: in experiments we demonstrate safe collaboration with up to two robots and two humans, and in simulation up to four robots, maintaining inter-agent separation at around 20 cm. Results show that the method shapes robot behavior intuitively by adjusting control parameters and achieves deadlock-free operation across team sizes in all tested scenarios.

</details>


### [18] [3D-printed Soft Optical sensor with a Lens (SOLen) for light guidance in mechanosensing](https://arxiv.org/abs/2602.17421)
*Diana Cafiso,Petr Trunin,Carolina Gay,Lucia Beccai*

Main category: cs.RO

TL;DR: 提出了一种名为SOLen的3D打印软光学传感方法，通过打印透镜在Y形波导中实现变形诱导的光学功率重分配，用于软机器人传感


<details>
  <summary>Details</summary>
Motivation: 增材制造使软机器人几何形状日益复杂，需要与单材料、一步制造兼容的传感方案。现有光学软传感器性能常受光传播问题影响，而缓解策略通常需要多材料界面

Method: 在Y形波导前放置打印透镜，利用变形引起的透镜旋转和焦点平移，在两个分支间重新分配光功率，产生编码运动方向和幅度的差分输出。使用改性丙烯酸聚氨酯树脂提高柔性和透光性，通过单层光学表征获取波长相关折射率和透射率，设计并打印具有亚毫米精度的透镜轮廓

Result: 旋转测试显示在多个周期内可重复的分支选择性信号切换，建立了从材料到光学的可转移工作流程

Conclusion: SOLen方法为软光学传感器提供了一种可转移的材料-光学工作流程，为下一代软机器人提供了具有新功能的光学透镜传感方案

Abstract: Additive manufacturing is enabling soft robots with increasingly complex geometries, creating a demand for sensing solutions that remain compatible with single-material, one-step fabrication. Optical soft sensors are attractive for monolithic printing, but their performance is often degraded by uncontrolled light propagation (ambient coupling, leakage, scattering), while common miti- gation strategies typically require multimaterial interfaces. Here, we present an approach for 3D printed soft optical sensing (SOLen), in which a printed lens is placed in front of an emitter within a Y-shaped waveguide. The sensing mechanism relies on deformation-induced lens rotation and focal-spot translation, redistributing optical power between the two branches to generate a differential output that encodes both motion direction and amplitude. An acrylate polyurethane resin was modified with lauryl acrylate to improve compliance and optical transmittance, and single-layer optical characterization was used to derive wavelength-dependent refractive index and transmittance while minimizing DLP layer-related artifacts. The measured refractive index was used in simulations to design a lens profile for a target focal distance, which was then printed with sub-millimeter fidelity. Rotational tests demonstrated reproducible branch-selective signal switching over multiple cycles. These results establish a transferable material-to-optics workflow for soft optical sensors with lens with new functionalities for next-generation soft robots

</details>


### [19] [A Cost-Effective and Climate-Resilient Air Pressure System for Rain Effect Reduction on Automated Vehicle Cameras](https://arxiv.org/abs/2602.17472)
*Mohamed Sabry,Joseba Gorospe,Cristina Olaverri-Monreal*

Main category: cs.RO

TL;DR: 提出一种低成本硬件解决方案，用于雨天条件下提高自动驾驶车辆感知性能，支持多摄像头兼容，将行人检测准确率从8.3%提升至41.6%


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶车辆在恶劣天气条件下的感知研究主要集中在软件算法改进，硬件解决方案有限。现有方法如亲水/疏水镜头和喷雾剂只能部分缓解问题，工业级保护系统成本高且难以在汽车领域规模化部署。

Method: 提出一种成本效益高的硬件解决方案，专门针对雨天条件设计，能够同时兼容多个摄像头。该系统与现有基于摄像头的感知平台兼容，无需额外的高成本传感器或硬件更换。

Result: 提出的系统能够将深度学习模型的行人检测准确率从8.3%显著提高到41.6%。该系统支持可持续交通目标，减少资源消耗，支持模块化升级，促进自动驾驶技术在恶劣天气条件下更经济高效的部署。

Conclusion: 该硬件解决方案有效解决了自动驾驶车辆在雨天条件下的感知挑战，具有成本效益、可扩展性和可持续性优势，能够在不增加高成本传感器的情况下提高系统可靠性，减少因系统故障导致的低效率和排放增加。

Abstract: Recent advances in automated vehicles have focused on improving perception performance under adverse weather conditions; however, research on physical hardware solutions remains limited, despite their importance for perception critical applications such as vehicle platooning. Existing approaches, such as hydrophilic or hydrophobic lenses and sprays, provide only partial mitigation, while industrial protection systems imply high cost and they do not enable scalability for automotive deployment.
  To address these limitations, this paper presents a cost-effective hardware solution for rainy conditions, designed to be compatible with multiple cameras simultaneously.
  Beyond its technical contribution, the proposed solution supports sustainability goals in transportation systems. By enabling compatibility with existing camera-based sensing platforms, the system extends the operational reliability of automated vehicles without requiring additional high-cost sensors or hardware replacements. This approach reduces resource consumption, supports modular upgrades, and promotes more cost-efficient deployment of automated vehicle technologies, particularly in challenging weather conditions where system failures would otherwise lead to inefficiencies and increased emissions. The proposed system was able to increase pedestrian detection accuracy of a Deep Learning model from 8.3% to 41.6%.

</details>


### [20] [Optically Sensorized Electro-Ribbon Actuator (OS-ERA)](https://arxiv.org/abs/2602.17474)
*Carolina Gay,Petr Trunin,Diana Cafiso,Yuejun Xu,Majid Taghavi,Lucia Beccai*

Main category: cs.RO

TL;DR: OS-ERA：一种光学传感的Electro-Ribbon执行器，通过嵌入软光波导传感器实现高保真弯曲状态分类，解决了传统电容传感器精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统Electro-Ribbon执行器（ERAs）虽然具有超高的位移和快速运动能力，但其嵌入式传感依赖于精度有限的电容传感器，这阻碍了精确控制。需要一种不影响执行性能的可靠传感解决方案。

Method: 设计了OS-ERA，在ERA中嵌入两个软光波导传感器来分析复杂曲率运动。训练分类器将传感信号映射到八个弯曲状态，并在六个保留试验中验证模型。

Result: 传感输出信号遵循训练流形，预测序列反映真实性能并确认可重复性。即使在执行速度故意不匹配的情况下，信号轨迹保持形状，分类保持准确，展示了电压和速度不变性。

Conclusion: OS-ERA能够高保真地分类弯曲状态，快速且可重复，解决了ERA长期存在的瓶颈问题，为实现闭环控制迈出了重要一步。

Abstract: Electro-Ribbon Actuators (ERAs) are lightweight flexural actuators that exhibit ultrahigh displacement and fast movement. However, their embedded sensing relies on capacitive sensors with limited precision, which hinders accurate control. We introduce OS-ERA, an optically sensorized ERA that yields reliable proprioceptive information, and we focus on the design and integration of a sensing solution without affecting actuation. To analyse the complex curvature of an ERA in motion, we design and embed two soft optical waveguide sensors. A classifier is trained to map the sensing signals in order to distinguish eight bending states. We validate our model on six held-out trials and compare it against signals' trajectories learned from training runs. Across all tests, the sensing output signals follow the training manifold, and the predicted sequence mirrors real performance and confirms repeatability. Despite deliberate train-test mismatches in actuation speed, the signal trajectories preserve their shape, and classification remains consistently accurate, demonstrating practical voltage- and speed-invariance. As a result, OS-ERA classifies bending states with high fidelity; it is fast and repeatable, solving a longstanding bottleneck of the ERA, enabling steps toward closed-loop control.

</details>


### [21] [Proximal powered knee placement: a case study](https://arxiv.org/abs/2602.17502)
*Kyle R. Embry,Lorenzo Vianello,Jim Lipsey,Frank Ursetta,Michael Stephens,Zhi Wang,Ann M. Simon,Andrea J. Ikeda,Suzanne B. Finucane,Shawana Anarwala,Levi J. Hargrove*

Main category: cs.RO

TL;DR: 探索性研究评估了动力假肢膝关节的膝上动力系统布置可行性，相比膝下布置，膝上配置在步行速度和步频方面有所改善，证明了通过优化质量分布而非简单减重来平衡动力辅助效益与额外重量负面影响的可能性。


<details>
  <summary>Details</summary>
Motivation: 下肢截肢影响全球数百万人，导致行动能力受损、步行速度降低和日常社交活动受限。动力假肢膝关节可以通过主动辅助膝关节扭矩来部分恢复行动能力，但动力组件的额外质量可能削弱这些效益，对步态力学产生负面影响并增加代谢成本。

Method: 在小规模队列中进行探索性研究，评估动力假肢膝关节膝上动力系统布置的可行性，与膝下布置进行对比。测试包括平地行走、坡道和楼梯等多种运动任务，评估步行速度、步频、步态对称性、膝关节活动范围和峰值速度等指标。

Result: 膝上配置相比膝下布置显示出改善的步行速度（一名参与者+9.2%）和步频（+3.6%），但对步态对称性的影响不一致。运动学测量显示两种配置的膝关节活动范围和峰值速度相似。在坡道和楼梯上的额外测试证实了控制策略在多种运动任务中的鲁棒性。

Conclusion: 初步结果表明膝上布置在功能上是可行的，通过仔细的质量分布可以在保持动力辅助效益的同时减轻额外重量的负面影响。需要进一步研究来确认这些趋势并为设计和临床建议提供指导。

Abstract: Lower limb amputation affects millions worldwide, leading to impaired mobility, reduced walking speed, and limited participation in daily and social activities. Powered prosthetic knees can partially restore mobility by actively assisting knee joint torque, improving gait symmetry, sit-to-stand transitions, and walking speed. However, added mass from powered components may diminish these benefits, negatively affecting gait mechanics and increasing metabolic cost. Consequently, optimizing mass distribution, rather than simply minimizing total mass, may provide a more effective and practical solution. In this exploratory study, we evaluated the feasibility of above-knee powertrain placement for a powered prosthetic knee in a small cohort. Compared to below-knee placement, the above-knee configuration demonstrated improved walking speed (+9.2% for one participant) and cadence (+3.6%), with mixed effects on gait symmetry. Kinematic measures indicated similar knee range of motion and peak velocity across configurations. Additional testing on ramps and stairs confirmed the robustness of the control strategy across multiple locomotion tasks. These preliminary findings suggest that above-knee placement is functionally feasible and that careful mass distribution can preserve the benefits of powered assistance while mitigating adverse effects of added weight. Further studies are needed to confirm these trends and guide design and clinical recommendations.

</details>


### [22] [IRIS: Learning-Driven Task-Specific Cinema Robot Arm for Visuomotor Motion Control](https://arxiv.org/abs/2602.17537)
*Qilong Cheng,Matthew Mackay,Ali Bereyhi*

Main category: cs.RO

TL;DR: IRIS是一个低成本、基于学习的6自由度机器人相机系统，通过模仿学习和Transformer架构实现自主电影级运动控制


<details>
  <summary>Details</summary>
Motivation: 工业级机器人相机系统成本高、操作复杂，限制了其在动态摄影中的应用。需要开发低成本、易用、基于学习的自主相机控制系统。

Method: 采用全3D打印的轻量化硬件设计，结合基于Action Chunking with Transformers (ACT)的目标条件视觉运动模仿学习框架，直接从人类演示中学习物体感知和平滑的相机轨迹。

Result: 系统成本低于1000美元，支持1.5公斤负载，重复精度约1毫米。实验显示能准确跟踪轨迹、可靠自主执行，并能泛化到多种电影级运动。

Conclusion: IRIS证明了低成本机器人相机系统通过模仿学习实现自主电影级运动控制的可行性，消除了显式几何编程的需求，为动态摄影提供了可访问的解决方案。

Abstract: Robotic camera systems enable dynamic, repeatable motion beyond human capabilities, yet their adoption remains limited by the high cost and operational complexity of industrial-grade platforms. We present the Intelligent Robotic Imaging System (IRIS), a task-specific 6-DOF manipulator designed for autonomous, learning-driven cinematic motion control. IRIS integrates a lightweight, fully 3D-printed hardware design with a goal-conditioned visuomotor imitation learning framework based on Action Chunking with Transformers (ACT). The system learns object-aware and perceptually smooth camera trajectories directly from human demonstrations, eliminating the need for explicit geometric programming. The complete platform costs under $1,000 USD, supports a 1.5 kg payload, and achieves approximately 1 mm repeatability. Real-world experiments demonstrate accurate trajectory tracking, reliable autonomous execution, and generalization across diverse cinematic motions.

</details>


### [23] [FR-GESTURE: An RGBD Dataset For Gesture-based Human-Robot Interaction In First Responder Operations](https://arxiv.org/abs/2602.17573)
*Konstantinos Foteinos,Georgios Angelidis,Aggelos Psiris,Vasileios Argyriou,Panagiotis Sarigiannidis,Georgios Th. Papadopoulos*

Main category: cs.RO

TL;DR: 该论文提出了首个专门为急救人员设计的基于手势控制无人地面车辆的数据集FR-GESTURE，包含12种手势命令、3312个RGBD数据对，并提供了基准实验和评估协议。


<details>
  <summary>Details</summary>
Motivation: 灾难强度和频率不断增加，使得急救人员的工作更加困难。人工智能和机器人解决方案可以协助他们的操作，弥补这些困难。目前缺乏专门为急救人员手势控制无人地面车辆设计的数据集。

Method: 设计了12个手势命令，灵感来源于急救人员现有手势和战术手语，并整合了经验丰富的急救人员的反馈。从2个视角和7个距离收集了3312个RGBD数据对。定义了评估协议并进行基准实验。

Result: 创建了FR-GESTURE数据集，这是首个专门为急救人员手势控制无人地面车辆设计的数据集。数据已公开可用，为未来研究提供了基础。

Conclusion: 该数据集填补了急救人员手势控制机器人领域的研究空白，为基于人工智能的急救人员辅助系统开发提供了重要资源，并鼓励未来研究改进基准性能。

Abstract: The ever increasing intensity and number of disasters make even more difficult the work of First Responders (FRs). Artificial intelligence and robotics solutions could facilitate their operations, compensating these difficulties. To this end, we propose a dataset for gesture-based UGV control by FRs, introducing a set of 12 commands, drawing inspiration from existing gestures used by FRs and tactical hand signals and refined after incorporating feedback from experienced FRs. Then we proceed with the data collection itself, resulting in 3312 RGBD pairs captured from 2 viewpoints and 7 distances. To the best of our knowledge, this is the first dataset especially intended for gesture-based UGV guidance by FRs. Finally we define evaluation protocols for our RGBD dataset, termed FR-GESTURE, and we perform baseline experiments, which are put forward for improvement. We have made data publicly available to promote future research on the domain: https://doi.org/10.5281/zenodo.18131333.

</details>


### [24] [Hybrid System Planning using a Mixed-Integer ADMM Heuristic and Hybrid Zonotopes](https://arxiv.org/abs/2602.17574)
*Joshua A. Robbins,Andrew F. Thompson,Jonah J. Glunt,Herschel C. Pangborn*

Main category: cs.RO

TL;DR: 本文提出了一种基于混合zonotopes和ADMM启发式算法的混合系统运动规划框架，用于解决嵌入式优化规划中的混合整数规划计算复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 嵌入式混合系统优化规划面临混合整数规划计算强度大、对数值公式敏感的问题，需要更高效的规划方法。

Method: 使用混合zonotopes（高级集合表示）进行分段仿射系统可达性分析，结合新的ADMM混合整数规划启发式算法，构建最优规划问题。

Result: 提出的方法比现有技术产生更低内存复杂度和更紧凸松弛的集合；ADMM启发式算法在混合zonotopes规划问题上比现有混合整数规划启发式算法收敛更快。

Conclusion: 该方法成功应用于自动驾驶中的行为与运动规划场景，为嵌入式硬件上的混合系统规划提供了有效解决方案。

Abstract: Embedded optimization-based planning for hybrid systems is challenging due to the use of mixed-integer programming, which is computationally intensive and often sensitive to the specific numerical formulation. To address that challenge, this article proposes a framework for motion planning of hybrid systems that pairs hybrid zonotopes - an advanced set representation - with a new alternating direction method of multipliers (ADMM) mixed-integer programming heuristic. A general treatment of piecewise affine (PWA) system reachability analysis using hybrid zonotopes is presented and extended to formulate optimal planning problems. Sets produced using the proposed identities have lower memory complexity and tighter convex relaxations than equivalent sets produced from preexisting techniques. The proposed ADMM heuristic makes efficient use of the hybrid zonotope structure. For planning problems formulated as hybrid zonotopes, the proposed heuristic achieves improved convergence rates as compared to state-of-the-art mixed-integer programming heuristics. The proposed methods for hybrid system planning on embedded hardware are experimentally applied in a combined behavior and motion planning scenario for autonomous driving.

</details>


### [25] [Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space](https://arxiv.org/abs/2602.17586)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: Deep-Flow是一个基于最优传输条件流匹配的无监督安全关键异常检测框架，通过PCA瓶颈约束生成过程到低秩谱流形，实现稳定、确定性的对数似然估计，用于自动驾驶安全验证。


<details>
  <summary>Details</summary>
Motivation: 当前L4级自动驾驶车辆的安全验证受限于传统基于规则启发式方法无法有效检测罕见、高风险的长尾场景，需要一种可扩展的解决方案。

Method: 采用最优传输条件流匹配(OT-CFM)表征专家人类驾驶行为的连续概率密度；通过PCA瓶颈将生成过程约束到低秩谱流形；使用带有车道感知目标条件的早期融合Transformer编码器解决多模态模糊性；引入运动学复杂度加权方案优先处理高能量机动。

Result: 在Waymo开放运动数据集(WOMD)上，框架对安全关键事件的AUC-ROC达到0.766；揭示了运动学危险与语义违规之间的根本区别；识别出传统安全过滤器忽略的分布外行为。

Conclusion: 该工作为定义统计安全门提供了数学严谨的基础，实现了客观、数据驱动的自动驾驶车队安全部署验证，能够检测传统方法忽略的预测性差距。

Abstract: Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.

</details>
