<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 54]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Design and Biomechanical Evaluation of a Lightweight Low-Complexity Soft Bilateral Ankle Exoskeleton](https://arxiv.org/abs/2602.18569)
*Josée Mallah,Zakii Javed,Zafer Azak,Thomas Stone,Luigi G. Occhipinti*

Main category: cs.RO

TL;DR: 开发了一款轻量、低复杂度、双侧软性踝关节外骨骼，用于跖屈辅助，可安装在任何鞋子上方，不干扰正常步态。


<details>
  <summary>Details</summary>
Motivation: 许多人（无论是医疗还是非医疗目的）都能从步态外骨骼辅助中受益，但传统外骨骼存在重量大、结构复杂、需要补偿等问题。

Method: 设计了轻量、低复杂度的双侧软性踝关节外骨骼，采用可安装在任何鞋子上方的鞋附着设计，并在零扭矩模式下进行实验测试。

Result: 实验显示，在零扭矩模式下穿戴外骨骼与不穿戴外骨骼相比，下肢运动学和动力学没有显著差异，证明设备不干扰健康步态，具有顺应性和舒适性。

Conclusion: 该设备有望提供有效辅助，已开发控制系统，正在进行额外测试。

Abstract: Many people could benefit from exoskeleton assistance during gait, for either medical or nonmedical purposes. But exoskeletons bring added mass and structure, which in turn require compensating for. In this work, we present a lightweight, low-complexity, soft bilateral ankle exoskeleton for plantarflexion assistance, with a shoe attachment design that can be mounted on top of any pair of shoes. Experimental tests show no significant difference in lower limb kinematics and kinetics when wearing the exoskeleton in zero-torque mode relative to not wearing an exoskeleton, showing that our device does not obstruct healthy gait, and proving it as a compliant and comfortable device, promising to provide effective assistance. Hence, a control system was developed, and additional tests are underway.

</details>


### [2] [Enhancing Goal Inference via Correction Timing](https://arxiv.org/abs/2602.18603)
*Anjiabei Wang,Shuangge Wang,Tesca Fitzgerald*

Main category: cs.RO

TL;DR: 研究探索机器人从人类纠正行为中学习的时机信号价值，发现纠正时机能改进机器人运动特征识别和目标推断


<details>
  <summary>Details</summary>
Motivation: 现有研究将人类纠正视为新演示或偏好，但忽略了人类决定干预机器人行为的时机这一重要信号，该时机受多种因素影响，可能包含有价值的任务相关信息

Method: 研究纠正时机作为学习信号，探索其在三个潜在应用中的价值：(1)识别可能引发人类纠正的机器人运动特征，(2)基于纠正时机和初始方向快速推断人类纠正的最终目标，(3)学习更精确的任务目标约束

Result: 纠正时机在前两个应用中（识别引发纠正的运动特征、快速推断纠正目标）能显著改进学习效果，为机器人学习提供了有价值的信号

Conclusion: 纠正时机作为机器人学习信号具有重要价值，特别是对于识别可能引发纠正的机器人运动特征和快速推断人类纠正目标，为机器人从人类反馈中学习提供了新视角

Abstract: Corrections offer a natural modality for people to provide feedback to a robot, by (i) intervening in the robot's behavior when they believe the robot is failing (or will fail) the task objectives and (ii) modifying the robot's behavior to successfully fulfill the task. Each correction offers information on what the robot should and should not do, where the corrected behavior is more aligned with task objectives than the original behavior. Most prior work on learning from corrections involves interpreting a correction as a new demonstration (consisting of the modified robot behavior), or a preference (for the modified trajectory compared to the robot's original behavior). However, this overlooks one essential element of the correction feedback, which is the human's decision to intervene in the robot's behavior in the first place. This decision can be influenced by multiple factors including the robot's task progress, alignment with human expectations, dynamics, motion legibility, and optimality. In this work, we investigate whether the timing of this decision can offer a useful signal for inferring these task-relevant influences. In particular, we investigate three potential applications for this learning signal: (1) identifying features of a robot's motion that may prompt people to correct it, (2) quickly inferring the final goal of a human's correction based on the timing and initial direction of their correction motion, and (3) learning more precise constraints for task objectives. Our results indicate that correction timing results in improved learning for the first two of these applications. Overall, our work provides new insights on the value of correction timing as a signal for robot learning.

</details>


### [3] [OVerSeeC: Open-Vocabulary Costmap Generation from Satellite Images and Natural Language](https://arxiv.org/abs/2602.18606)
*Rwik Rana,Jesse Quattrociocchi,Dongmyeong Lee,Christian Ellis,Amanda Adkins,Adam Uccello,Garrett Warnell,Joydeep Biswas*

Main category: cs.RO

TL;DR: OVerSeeC是一个零样本模块化框架，通过分解为解释-定位-合成三个步骤，直接从卫星图像生成用于长距离规划的全局成本图，能够处理自然语言表达的实体和任务特定遍历规则。


<details>
  <summary>Details</summary>
Motivation: 自主导航需要全局上下文进行路径规划，但现有方法无法处理测试时自然语言表达的动态任务要求和未知地形实体。固定本体和静态成本映射无法适应任务需求变化、未知实体部署和组合遍历逻辑。

Method: 提出OVerSeeC框架，分为三个模块：1) LLM提取实体和排名偏好；2) 开放词汇分割管道从高分辨率图像识别这些实体；3) LLM使用用户自然语言偏好和掩码合成可执行成本图代码。

Result: OVerSeeC能够处理新颖实体，尊重排名和组合偏好，在不同区域产生与人工绘制轨迹一致的路由，展示了对分布偏移的鲁棒性。

Conclusion: 基础模型的模块化组合能够实现开放词汇、偏好对齐的成本图生成，支持可扩展、任务自适应的全局规划。

Abstract: Aerial imagery provides essential global context for autonomous navigation, enabling route planning at scales inaccessible to onboard sensing. We address the problem of generating global costmaps for long-range planning directly from satellite imagery when entities and mission-specific traversal rules are expressed in natural language at test time. This setting is challenging since mission requirements vary, terrain entities may be unknown at deployment, and user prompts often encode compositional traversal logic. Existing approaches relying on fixed ontologies and static cost mappings cannot accommodate such flexibility. While foundation models excel at language interpretation and open-vocabulary perception, no single model can simultaneously parse nuanced mission directives, locate arbitrary entities in large-scale imagery, and synthesize them into an executable cost function for planners. We therefore propose OVerSeeC, a zero-shot modular framework that decomposes the problem into Interpret-Locate-Synthesize: (i) an LLM extracts entities and ranked preferences, (ii) an open-vocabulary segmentation pipeline identifies these entities from high-resolution imagery, and (iii) the LLM uses the user's natural language preferences and masks to synthesize executable costmap code. Empirically, OVerSeeC handles novel entities, respects ranked and compositional preferences, and produces routes consistent with human-drawn trajectories across diverse regions, demonstrating robustness to distribution shifts. This shows that modular composition of foundation models enables open-vocabulary, preference-aligned costmap generation for scalable, mission-adaptive global planning.

</details>


### [4] [FORMICA: Decision-Focused Learning for Communication-Free Multi-Robot Task Allocation](https://arxiv.org/abs/2602.18622)
*Antonio Lopez,Jack Muirhead,Carlo Pinciroli*

Main category: cs.RO

TL;DR: FORMICA：无需机器人间通信的隐式协调任务分配框架，通过预测队友出价分布来优化任务选择，在有限带宽环境下表现优异


<details>
  <summary>Details</summary>
Motivation: 传统多机器人任务分配方法依赖通信来协调冲突，但在带宽受限、基础设施退化或对抗干扰的环境中性能急剧下降，需要一种无需通信的协调方法

Method: 提出FORMICA框架，让机器人通过预测队友的出价分布进行隐式协调；采用端到端训练，最小化任务分配遗憾而非预测误差；使用均值场近似将复杂度从O(NT)降至O(T)

Result: 在16个机器人和64个任务的场景中，系统奖励提升17%，接近最优MILP解；在更大规模场景（256个机器人，4096个任务）中，性能提升7%；训练仅需21秒

Conclusion: FORMICA在无需机器人间通信的情况下实现了高质量的任务分配，能够适应任务聚类和空间异质性，具有良好的可扩展性和泛化能力

Abstract: Most multi-robot task allocation methods rely on communication to resolve conflicts and reach consistent assignments. In environments with limited bandwidth, degraded infrastructure, or adversarial interference, existing approaches degrade sharply. We introduce a learning-based framework that achieves high-quality task allocation without any robot-to-robot communication. The key idea is that robots coordinate implicitly by predicting teammates' bids: if each robot can anticipate competition for a task, it can adjust its choices accordingly. Our method predicts bid distributions to correct systematic errors in analytical mean-field approximations. While analytical predictions assume idealized conditions (uniform distributions, known bid functions), our learned approach adapts to task clustering and spatial heterogeneity. Inspired by Smart Predict-then-Optimize (SPO), we train predictors end-to-end to minimize Task Allocation Regret rather than prediction error. To scale to large swarms, we develop a mean-field approximation where each robot predicts the distribution of competing bids rather than individual bids, reducing complexity from $O(NT)$ to $O(T)$. We call our approach FORMICA: Field-Oriented Regret-Minimizing Implicit Coordination Algorithm. Experiments show FORMICA substantially outperforms a natural analytical baseline. In scenarios with 16 robots and 64 tasks, our approach improves system reward by 17% and approaches the optimal MILP solution. When deployed on larger scenarios (256 robots, 4096 tasks), the same model improves performance by 7%, demonstrating strong generalization. Training requires only 21 seconds on a laptop, enabling rapid adaptation to new environments.

</details>


### [5] [Soft Surfaced Vision-Based Tactile Sensing for Bipedal Robot Applications](https://arxiv.org/abs/2602.18638)
*Jaeeun Kim,Junhee Lim,Yu She*

Main category: cs.RO

TL;DR: 该论文提出了一种用于双足机器人的软表面视觉触觉脚传感器，通过光学捕捉接触变形将足地交互转化为丰富的触觉信号，从而提升机器人的平衡控制和地形感知能力。


<details>
  <summary>Details</summary>
Motivation: 腿式运动受益于具身感知，其中感知源于身体与环境之间的物理交互。目前机器人主要依赖本体感知，缺乏对足地接触的丰富触觉反馈，限制了平衡控制和地形适应性。

Method: 开发了软表面视觉触觉脚传感器，在双足机器人脚部集成皮肤状可变形层，通过光学方式捕捉接触变形。从接触图像流中估计接触姿态（位置和方向）、可视化剪切力、计算压力中心、分类地形并检测接触斑块的几何特征。

Result: 在倾斜平台和视觉遮挡条件下验证了传感器能力，显示足部触觉反馈相比仅依赖本体感知能显著改善平衡控制和地形感知。传感器能准确估计接触参数并识别地形特征。

Conclusion: 将触觉感知集成到腿式机器人脚部能提高稳定性、适应性和环境感知能力，为实现更柔顺和智能的运动系统提供了有前景的方向。

Abstract: Legged locomotion benefits from embodied sensing, where perception emerges from the physical interaction between body and environment. We present a soft-surfaced, vision-based tactile foot sensor that endows a bipedal robot with a skin-like deformable layer that captures contact deformations optically, turning foot-ground interactions into rich haptic signals. From a contact image stream, our method estimates contact pose (position and orientation), visualizes shear, computes center of pressure (CoP), classifies terrain, and detects geometric features of the contact patch. We validate these capabilities on a tilting platform and in visually obscured conditions, showing that foot-borne tactile feedback improves balance control and terrain awareness beyond proprioception alone. These findings suggest that integrating tactile perception into legged robot feet improves stability, adaptability, and environmental awareness, offering a promising direction toward more compliant and intelligent locomotion systems. For the supplementary video, please visit: https://youtu.be/ceJiy9q_2Aw

</details>


### [6] [Robotic Fruits with Tunable Stiffness and Sensing: Towards a Methodology for Developing Realistic Physical Twins of Fruits](https://arxiv.org/abs/2602.18661)
*Saitarun Nadipineni,Keshav Pandiyan,Kaspar Althoefer,Shinichi Hirai,Thilina Dulantha Lalitharatne*

Main category: cs.RO

TL;DR: 开发可调节软体物理孪生体模拟不同成熟度水果的刚度特性，为机器人抓取器提供可持续、可控的测试平台


<details>
  <summary>Details</summary>
Motivation: 全球农业食品行业面临劳动力短缺、高消费需求和供应链中断等挑战，导致大量未收获农产品损失。机器人采摘成为有前景的替代方案，但由于自然产品的机械特性高度可变，评估和训练软体抓取器对脆弱水果的抓取仍然困难。现有测试方法依赖大量真实水果来捕捉这种变异性，导致效率低下、成本增加和浪费。

Method: 开发可调节软体物理孪生体，模拟真实水果在不同成熟度下的刚度特性。设计并制造了猕猴桃的纤维增强气动物理孪生体，能够复制不同成熟度水平的刚度。通过实验验证物理孪生体刚度的可调节精度，并使用商业机器人抓取器进行抓取任务测试。

Result: 实验结果显示，物理孪生体的刚度可以在多次试验中精确调节（97.35-99.43%的准确度）。抓取任务表明，物理孪生体的传感器反馈能够反映施加的抓取力。经过50次循环的压力测试显示，物理孪生体能够可靠地维持所需刚度（0.56-1.10%的误差）。

Conclusion: 机器人物理孪生体能够调整其刚度以模拟真实水果的刚度特性，为机器人抓取器的基准测试和训练提供了一个可持续、可控的平台，解决了现有测试方法依赖大量真实水果导致的效率低下、成本增加和浪费问题。

Abstract: The global agri-food sector faces increasing challenges from labour shortages, high consumer demand, and supply-chain disruptions, resulting in substantial losses of unharvested produce. Robotic harvesting has emerged as a promising alternative; however, evaluating and training soft grippers for delicate fruits remains difficult due to the highly variable mechanical properties of natural produce. This makes it difficult to establish reliable benchmarks or data-driven control strategies. Existing testing practices rely on large quantities of real fruit to capture this variability, leading to inefficiency, higher costs, and waste. The methodology presented in this work aims to address these limitations by developing tunable soft physical twins that emulate the stiffness characteristics of real fruits at different ripeness levels. A fiber-reinforced pneumatic physical twin of a kiwi fruit was designed and fabricated to replicate the stiffness at different ripeness levels. Experimental results show that the stiffness of the physical twin can be tuned accurately over multiple trials (97.35 - 99.43% accuracy). Gripping tasks with a commercial robotic gripper showed that sensor feedback from the physical twin can reflect the applied gripping forces. Finally, a stress test was performed over 50 cycles showed reliable maintenance of desired stiffness (0.56 - 1.10% error). This work shows promise that robotic physical twins could adjust their stiffness to resemble that of real fruits. This can provide a sustainable, controllable platform for benchmarking and training robotic grippers.

</details>


### [7] [Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL)](https://arxiv.org/abs/2602.18663)
*Harry Robertshaw,Nikola Fischer,Lennart Karstensen,Benjamin Jackson,Xingyu Chen,S. M. Hadi Sadati,Christos Bergeles,Alejandro Granados,Thomas C Booth*

Main category: cs.RO

TL;DR: 提出了一种分层模块化多智能体强化学习框架，用于体外自主双设备导航，实现高效且可泛化的血管内导航，在模拟和体外测试中验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 机械取栓是治疗大血管闭塞性急性缺血性卒中的最佳方法，但受地理和后勤障碍限制，可及性有限。强化学习在自主血管内导航中显示出潜力，但在"长"导航任务中的泛化能力仍然具有挑战性。

Method: 提出了分层模块化多智能体强化学习框架，用于自主双设备导航。采用模块化多智能体方法将复杂导航任务分解为专门子任务，每个子任务使用Soft Actor-Critic强化学习进行训练。在模拟和体外测试平台上验证框架的泛化能力和实际可行性。

Result: 在模拟中，单血管模型在个体解剖结构上达到92-100%成功率，多血管模型在多个患者解剖结构上达到56-80%成功率。在体外测试中，两种HM-MARL模型从股动脉到右颈总动脉的成功率为100%，到右颈内动脉为80%，但在左侧血管的超人挑战中失败。

Conclusion: 该研究首次展示了机械取栓血管内体外自主导航。虽然HM-MARL实现了跨解剖结构的泛化，但仿真到现实的转换带来了挑战。未来工作将使用世界模型改进强化学习策略，并在未见过的体外数据上验证性能，推动自主机械取栓向临床转化。

Abstract: Mechanical thrombectomy (MT) is typically the optimal treatment for acute ischemic stroke involving large vessel occlusions, but access is limited due to geographic and logistical barriers. Reinforcement learning (RL) shows promise in autonomous endovascular navigation, but generalization across 'long' navigation tasks remains challenging. We propose a Hierarchical Modular Multi-Agent Reinforcement Learning (HM-MARL) framework for autonomous two-device navigation in vitro, enabling efficient and generalizable navigation. HM-MARL was developed to autonomously navigate a guide catheter and guidewire from the femoral artery to the internal carotid artery (ICA). A modular multi-agent approach was used to decompose the complex navigation task into specialized subtasks, each trained using Soft Actor-Critic RL. The framework was validated in both in silico and in vitro testbeds to assess generalization and real-world feasibility. In silico, a single-vasculature model achieved 92-100% success rates on individual anatomies, while a multi-vasculature model achieved 56-80% across multiple patient anatomies. In vitro, both HM-MARL models successfully navigated 100% of trials from the femoral artery to the right common carotid artery and 80% to the right ICA but failed on the left-side vessel superhuman challenge due to the anatomy and catheter type used in navigation. This study presents the first demonstration of in vitro autonomous navigation in MT vasculature. While HM-MARL enables generalization across anatomies, the simulation-to-real transition introduces challenges. Future work will refine RL strategies using world models and validate performance on unseen in vitro data, advancing autonomous MT towards clinical translation.

</details>


### [8] [Scout-Rover cooperation: online terrain strength mapping and traversal risk estimation for planetary-analog explorations](https://arxiv.org/abs/2602.18688)
*Shipeng Liu,J. Diego Caporale,Yifeng Zhang,Xingjue Liao,William Hoganson,Wilson Hu,Shivangi Misra,Neha Peddinti,Rachel Holladay,Ethan Fulcher,Akshay Ram Panyam,Andrik Puentes,Jordan M. Bretzfelder,Michael Zanetti,Uland Wong,Daniel E. Koditschek,Mark Yim,Douglas Jerolmack,Cynthia Sung,Feifei Qian*

Main category: cs.RO

TL;DR: 提出了一种腿式侦察机器人与轮式漫游车协同框架，通过腿式机器人的本体感知腿-地形交互在线估计土壤强度，构建地形图并评估轮式漫游车通行风险，实现可变形行星地形下的安全导航。


<details>
  <summary>Details</summary>
Motivation: 行星表面存在许多科学价值区域（如火星沙丘、月球陨石坑），但由于松软可变形表土的危害性难以安全访问。现有机器人系统在可变形地形中面临移动性挑战，需要新的方法来扩展安全访问范围。

Method: 采用腿式机器人作为移动侦察员，利用其本体感知的腿-地形交互作用在线估计表土强度，构建空间分辨地形图。将这些地图与漫游车移动模型集成，评估通行风险并指导路径规划，形成异构机器人协同框架。

Result: 在NASA艾姆斯月球模拟试验场和白沙沙丘场的模拟任务中验证了框架有效性：1）实现了腿式移动中的在线地形强度映射；2）漫游车特定通行风险评估能够实现安全导航至科学目标。侦察生成的地形图可靠捕捉空间变异性并预测移动故障模式。

Conclusion: 通过结合本体地形感知与异构漫游车协同，该框架增强了操作鲁棒性，扩展了可变形行星环境中可到达的科学工作空间，为危险地形探索提供了新方法。

Abstract: Robot-aided exploration of planetary surfaces is essential for understanding geologic processes, yet many scientifically valuable regions, such as Martian dunes and lunar craters, remain hazardous due to loose, deformable regolith. We present a scout-rover cooperation framework that expands safe access to such terrain using a hybrid team of legged and wheeled robots. In our approach, a high-mobility legged robot serves as a mobile scout, using proprioceptive leg-terrain interactions to estimate regolith strength during locomotion and construct spatially resolved terrain maps. These maps are integrated with rover locomotion models to estimate traversal risk and inform path planning.
  We validate the framework through analogue missions at the NASA Ames Lunar Simulant Testbed and the White Sands Dune Field. Experiments demonstrate (1) online terrain strength mapping from legged locomotion and (2) rover-specific traversal-risk estimation enabling safe navigation to scientific targets. Results show that scout-generated terrain maps reliably capture spatial variability and predict mobility failure modes, allowing risk-aware path planning that avoids hazardous regions. By combining embodied terrain sensing with heterogeneous rover cooperation, this framework enhances operational robustness and expands the reachable science workspace in deformable planetary environments.

</details>


### [9] [CLASH: Collision Learning via Augmented Sim-to-real Hybridization to Bridge the Reality Gap](https://arxiv.org/abs/2602.18707)
*Haotian He,Ning Guo,Siqi Shi,Qipeng Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: CLASH框架通过少量真实数据学习碰撞模型，创建高保真混合仿真器，显著缩小sim-to-real差距，提升策略迁移成功率


<details>
  <summary>Details</summary>
Motivation: 传统物理引擎在模拟接触丰富的动力学（如碰撞）时存在精度与计算速度的权衡，导致仿真与现实之间存在差距，阻碍了仿真训练策略的直接迁移

Method: 提出CLASH框架：1）从有缺陷的仿真器（MuJoCo）中提取基础模型获取物理先验；2）用极少量的真实世界交互数据（少至10个样本）进行微调，修正仿真器固有误差；3）创建高保真混合仿真器

Result: 混合仿真器不仅预测精度更高，还将碰撞计算时间减少近50%；使用该仿真器训练的策略在真实世界迁移更鲁棒，强化学习顺序推动任务成功率翻倍，基于模型的控制任务性能显著提升

Conclusion: CLASH框架通过数据高效的方式学习碰撞模型，有效缩小sim-to-real差距，为机器人策略从仿真到现实的迁移提供了实用解决方案

Abstract: The sim-to-real gap, particularly in the inaccurate modeling of contact-rich dynamics like collisions, remains a primary obstacle to deploying robot policies trained in simulation. Conventional physics engines often trade accuracy for computational speed, leading to discrepancies that prevent direct policy transfer. To address this, we introduce Collision Learning via Augmented Sim-to-real Hybridization (CLASH), a data-efficient framework that creates a high-fidelity hybrid simulator by learning a surrogate collision model from a minimal set of real-world data. In CLASH, a base model is first distilled from an imperfect simulator (MuJoCo) to capture general physical priors; this model is then fine-tuned with a remarkably small number of real-world interactions (as few as 10 samples) to correct for the simulator's inherent inaccuracies. The resulting hybrid simulator not only achieves higher predictive accuracy but also reduces collision computation time by nearly 50\%. We demonstrate that policies obtained with our hybrid simulator transfer more robustly to the real world, doubling the success rate in sequential pushing tasks with reinforecement learning and significantly increase the task performance with model-based control.

</details>


### [10] [RoboCurate: Harnessing Diversity with Action-Verified Neural Trajectory for Robot Learning](https://arxiv.org/abs/2602.18742)
*Seungku Kim,Suhyeok Jang,Byungjun Yoon,Dongyoung Kim,John Won,Jinwoo Shin*

Main category: cs.RO

TL;DR: RoboCurate：通过仿真回放验证动作质量的新型机器人合成数据生成框架，显著提升机器人学习性能


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型生成的合成数据存在动作质量不一致的问题，而视觉语言模型在验证视频质量时无法准确评估生成动作的物理准确性

Method: 1. 在仿真器中回放预测动作，通过比较仿真回放与生成视频之间的运动一致性来评估动作质量；2. 通过图像到图像编辑解锁超出可用数据集的观察多样性；3. 应用保持动作的视频到视频转换来进一步增强外观

Result: 相比仅使用真实数据，RoboCurate生成的合成数据在多个任务上显著提升成功率：GR-1 Tabletop（300演示）+70.1%，DexMimicGen预训练设置+16.1%，ALLEX人形灵巧操作任务+179.9%

Conclusion: RoboCurate通过仿真验证机制有效解决了合成机器人数据中动作质量不一致的问题，为机器人学习提供了高质量、可扩展的数据生成框架

Abstract: Synthetic data generated by video generative models has shown promise for robot learning as a scalable pipeline, but it often suffers from inconsistent action quality due to imperfectly generated videos. Recently, vision-language models (VLMs) have been leveraged to validate video quality, but they have limitations in distinguishing physically accurate videos and, even then, cannot directly evaluate the generated actions themselves. To tackle this issue, we introduce RoboCurate, a novel synthetic robot data generation framework that evaluates and filters the quality of annotated actions by comparing them with simulation replay. Specifically, RoboCurate replays the predicted actions in a simulator and assesses action quality by measuring the consistency of motion between the simulator rollout and the generated video. In addition, we unlock observation diversity beyond the available dataset via image-to-image editing and apply action-preserving video-to-video transfer to further augment appearance. We observe RoboCurate's generated data yield substantial relative improvements in success rates compared to using real data only, achieving +70.1% on GR-1 Tabletop (300 demos), +16.1% on DexMimicGen in the pre-training setup, and +179.9% in the challenging real-world ALLEX humanoid dexterous manipulation setting.

</details>


### [11] [Learning to Localize Reference Trajectories in Image-Space for Visual Navigation](https://arxiv.org/abs/2602.18803)
*Finn Lukas Busch,Matti Vahs,Quantao Yang,Jesús Gerardo Ortega Peimbert,Yixi Cai,Jana Tumova,Olov Andersson*

Main category: cs.RO

TL;DR: LoTIS是一个视觉导航模型，通过将参考RGB轨迹定位到机器人当前视图中，提供机器人无关的图像空间引导，无需相机标定、位姿或机器人特定训练。


<details>
  <summary>Details</summary>
Motivation: 传统视觉导航方法通常与特定机器人绑定，需要相机标定、位姿信息或机器人特定训练。LoTIS旨在创建机器人无关的视觉引导系统，能够零样本适应不同机器人平台，简化部署过程。

Method: 模型预测参考轨迹在机器人当前视图中的图像空间坐标，而不是预测与特定机器人绑定的动作。通过解耦感知与动作，学习定位轨迹点而非模仿行为先验，采用跨轨迹训练策略增强对视角和相机变化的鲁棒性。

Result: 在传统前向导航任务中，比最先进方法提升20-50个百分点，在多样仿真和真实环境中达到94-98%的成功率。在具有挑战性的任务（如后向遍历）上，比基线方法提升5倍以上，基线方法在这些任务上完全失败。

Conclusion: LoTIS提供了一种简单有效的机器人无关视觉导航方案，仅需手机拍摄的视频即可让不同机器人导航到轨迹上的任意点，实现了零样本跨机器人部署，显著提升了导航系统的通用性和易用性。

Abstract: We present LoTIS, a model for visual navigation that provides robot-agnostic image-space guidance by localizing a reference RGB trajectory in the robot's current view, without requiring camera calibration, poses, or robot-specific training. Instead of predicting actions tied to specific robots, we predict the image-space coordinates of the reference trajectory as they would appear in the robot's current view. This creates robot-agnostic visual guidance that easily integrates with local planning. Consequently, our model's predictions provide guidance zero-shot across diverse embodiments. By decoupling perception from action and learning to localize trajectory points rather than imitate behavioral priors, we enable a cross-trajectory training strategy for robustness to viewpoint and camera changes. We outperform state-of-the-art methods by 20-50 percentage points in success rate on conventional forward navigation, achieving 94-98% success rate across diverse sim and real environments. Furthermore, we achieve over 5x improvements on challenging tasks where baselines fail, such as backward traversal. The system is straightforward to use: we show how even a video from a phone camera directly enables different robots to navigate to any point on the trajectory. Videos, demo, and code are available at https://finnbusch.com/lotis.

</details>


### [12] [Habilis-$β$: A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model](https://arxiv.org/abs/2602.18813)
*Tommoro Robotics,:,Jesoon Kang,Taegeon Park,Jisu An,Soo Min Kimm,Jaejoon Kim,Jinu Pahk,Byungju Kim,Junseok Lee,Namheon Baek,Sungwan Ha,Hojun Baek,Eduardo Ayerve Cruz,Wontae Kim,Junghyeon Choi,Yousuk Lee,Joonmo Han,Sunghyun Cho,Sunghyun Kwon,Soyoung Lee,Jun Ki Lee,Seung-Joon Yi,Byoung-Tak Zhang,Theo Taeyeong Kim*

Main category: cs.RO

TL;DR: Habilis-β是一个快速运动、持久运行的设备端视觉-语言-动作模型，通过新的评估指标PRP（任务每小时和平均干预间隔时间）在连续运行协议下评估性能，在仿真和真实环境中都显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型的评估主要局限于单次试验成功率，无法捕捉实际应用中所需的快速运动和持久运行能力。需要新的评估框架来衡量模型在实际部署中的生产力与可靠性。

Method: 1) 在大规模游戏数据上进行无语言预训练以获得鲁棒交互先验；2) 在循环任务演示上进行后训练以捕捉连续任务迭代中的状态漂移；3) 使用ESPADA进行相位自适应运动整形以加速自由空间传输；4) 采用整流流蒸馏实现边缘设备上的高频控制；5) 使用无分类器引导作为部署时调节旋钮，动态平衡指令遵循和学习的交互先验。

Result: 在1小时连续运行评估中：仿真环境中达到572.6 TPH和39.2秒MTBI（vs. π0.5的120.5 TPH和30.5秒）；真实世界人形物流工作流中达到124 TPH和137.4秒MTBI（vs. π0.5的19 TPH和46.1秒）。在标准RoboTwin 2.0排行榜上获得最高性能。

Conclusion: Habilis-β通过创新的训练方法和评估框架，在快速运动和持久运行能力方面显著优于现有方法，为实际部署的VLA模型提供了有效的解决方案，在复杂操作场景中表现出色。

Abstract: We introduce Habilis-$β$, a fast-motion and long-lasting on-device vision-language-action (VLA) model designed for real-world deployment. Current VLA evaluation remains largely confined to single-trial success rates under curated resets, which fails to capture the fast-motion and long-lasting capabilities essential for practical operation. To address this, we introduce the Productivity-Reliability Plane (PRP), which evaluates performance through Tasks per Hour (TPH) and Mean Time Between Intervention (MTBI) under a continuous-run protocol that demands both high-speed execution and sustained robustness. Habilis-$β$ achieves high performance by integrating language-free pre-training on large-scale play data for robust interaction priors with post-training on cyclic task demonstrations that capture state drift across consecutive task iterations. The system further employs ESPADA for phase-adaptive motion shaping to accelerate free-space transit, utilizes rectified-flow distillation to enable high-frequency control on edge devices, and incorporates classifier-free guidance (CFG) as a deployment-time knob to dynamically balance instruction adherence and learned interaction priors. In 1-hour continuous-run evaluations, Habilis-$β$ achieves strong performance under the PRP metrics, compared to $π_{0.5}$ in both simulation and real-world environments. In simulation, Habilis-$β$ achieves 572.6 TPH and 39.2 s MTBI (vs. 120.5 TPH and 30.5 s for $π_{0.5}$), while in a real-world humanoid logistics workflow it achieves 124 TPH and 137.4 s MTBI (vs. 19 TPH and 46.1 s for $π_{0.5}$). Finally, Habilis-$β$ achieves the highest reported performance on the standard RoboTwin 2.0 leaderboard across representative tasks, validating its effectiveness in complex manipulation scenarios.

</details>


### [13] [RotorSuite: A MATLAB/Simulink Toolbox for Tilt Multi-Rotor UAV Modeling](https://arxiv.org/abs/2602.18814)
*Nicola Cigarini,Giulia Michieletto,Angelo Cenedese*

Main category: cs.RO

TL;DR: 开发了一个名为RotorSuite的MATLAB/Simulink工具箱，用于建模和模拟多种多旋翼平台的动力学特性，支持解析和物理两种方法。


<details>
  <summary>Details</summary>
Motivation: 近年来，空中平台从被动的飞行传感器发展为多功能、接触感知的机器人系统，平台设计快速发展。标准共面和共线四旋翼被现代倾斜和可倾斜多旋翼平台补充，这些平台具有增强的机动性。为了正确分析、控制和验证这些新兴平台的性能，需要精确的建模步骤，但这个过程可能耗时、依赖用户且容易出错。

Method: 提出了一个MATLAB/Simulink工具箱，通过解析和物理两种方法对广泛类别的多旋翼平台进行动力学建模和仿真。该工具箱名为RotorSuite，提供全面的文档和示例用例。

Result: RotorSuite工具箱成为教学、研究和工业开发的有价值工具，能够准确建模和模拟多种多旋翼平台的动力学特性。

Conclusion: RotorSuite工具箱解决了多旋翼平台建模耗时、依赖用户且容易出错的问题，为分析、控制和验证新兴多旋翼平台的性能提供了有效的解决方案。

Abstract: In recent years, aerial platforms have evolved from passive flying sensors into versatile, contact-aware robotic systems, leading to rapid advances in platform design. Standard coplanar and collinear quadrotors have been complemented by modern tilted and tilting multi-rotor platforms with enhanced maneuverability. To properly analyze, control, and validate the performance of these emerging platforms, an accurate modeling step is required; however, this can be time-consuming, user-dependent and error-prone. To address this issue, we propose a MATLAB/Simulink toolbox for modeling and simulating the dynamics of a broad class of multi-rotor platforms through both an analytical and physics-based approaches. The toolbox, named RotorSuite, is provided with comprehensive documentation and example use cases, representing a valuable tool for didactic, research, and industrial development purposes.

</details>


### [14] [GRAB: A Systematic Real-World Grasping Benchmark for Robotic Food Waste Sorting](https://arxiv.org/abs/2602.18835)
*Moniesha Thilakarathna,Xing Wang,Min Wang,David Hinwood,Shuangzhe Liu,Damith Herath*

Main category: cs.RO

TL;DR: GRAB框架为食品废物分拣中的机器人抓取提供全面基准测试，通过1750次抓取实验评估不同抓取模式，发现物体质量是影响性能的主要因素


<details>
  <summary>Details</summary>
Motivation: 食品废物管理中的无机污染物阻碍回收潜力，机器人自动化可加速分拣过程，但现有基准测试框架依赖有限模拟数据，仅关注简单指标，忽略了关键的抓取前条件

Method: 提出GRAB（Grasping Real-World Article Benchmarking）框架，整合多样化可变形物体、先进的抓取姿态估计视觉系统，以及关键的抓取前条件，建立了一套关键的可抓取性指标。通过4个高保真场景中的1750次食品污染物抓取尝试，系统比较工业抓取模式

Result: 大规模评估揭示了不同夹爪的优缺点：在杂乱环境中，物体质量是主导性能因素，视觉质量和杂乱程度起中等作用。这些发现强调了多模态夹爪技术的重要性

Conclusion: 研究结果突出了关键设计考虑因素，并强调了开发能够实现稳健跨类别性能的多模态夹爪技术的必要性，以实现有效的机器人食品废物分拣

Abstract: Food waste management is critical for sustainability, yet inorganic contaminants hinder recycling potential. Robotic automation presents a compelling approach to this challenge by accelerating the sorting process through automated contaminant removal. Still, the diverse and unpredictable nature of contaminants creates major challenges for robotic grasping. Benchmarking frameworks are critical for evaluating challenges from various perspectives. However, existing protocols rely on limited simulation datasets, prioritise simple metrics such as success rate, and overlook key object and environment-related pre-grasp conditions. This paper introduces GRAB, a comprehensive Grasping Real-World Article Benchmarking framework that addresses this gap by integrating diverse deformable objects, advanced grasp-pose-estimation vision, and, importantly, pre-grasp conditions, establishing a set of critical graspability metrics. It systematically compares industrial grasping modalities through an in-depth experimental evaluation involving 1,750 food contaminant grasp attempts across four high-fidelity scenes. This large-scale evaluation provides an extensive assessment of grasp performance for food waste sorting, offering a level of depth that has rarely been explored in previous studies. The results reveal distinct gripper strengths and limitations, with object quality emerging as the dominant performance factor in cluttered environments, while vision quality and clutter levels play moderate roles. These findings highlight essential design considerations and reinforce the necessity of developing multimodal gripper technologies capable of robust cross-category performance for effective robotic food waste sorting.

</details>


### [15] [When the Inference Meets the Explicitness or Why Multimodality Can Make Us Forget About the Perfect Predictor](https://arxiv.org/abs/2602.18850)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 该研究比较了四种人机协作通信系统在物体搬运任务中的表现，包括两种意图预测系统和两种显式通信系统，发现人类更喜欢自然的系统，即使失败率更高，最佳方案是两者的结合。


<details>
  <summary>Details</summary>
Motivation: 由于人类行为的随机性导致意图预测模型存在不确定性，研究者开始倡导使用显式通信系统来明确获取人类意图。本研究旨在分析不同通信系统在人机协作物体搬运任务中的表现。

Method: 使用IVO移动社交机器人，集成了四种通信系统：基于力预测的意图预测器、增强速度预测算法、按钮接口和语音命令识别系统。75名志愿者在5-7米距离的障碍环境中完成255次物体搬运任务，分为三组测试不同系统组合。

Result: 1) 一旦系统达到足够性能，人类不再注意并积极评价技术改进；2) 人类更喜欢更自然的系统，即使失败率更高；3) 最佳选择是两种系统的适当结合。

Conclusion: 在人机协作中，显式通信和意图预测系统的结合是最佳方案，人类偏好自然的交互方式，即使存在技术缺陷，系统设计应平衡技术性能和用户体验。

Abstract: Although in the literature it is common to find predictors and inference systems that try to predict human intentions, the uncertainty of these models due to the randomness of human behavior has led some authors to start advocating the use of communication systems that explicitly elicit human intention. In this work, it is analyzed the use of four different communication systems with a human-robot collaborative object transportation task as experimental testbed: two intention predictors (one based on force prediction and another with an enhanced velocity prediction algorithm) and two explicit communication methods (a button interface and a voice-command recognition system). These systems were integrated into IVO, a custom mobile social robot equipped with force sensor to detect the force exchange between both agents and LiDAR to detect the environment. The collaborative task required transporting an object over a 5-7 meter distance with obstacles in the middle, demanding rapid decisions and precise physical coordination. 75 volunteers perform a total of 255 executions divided into three groups, testing inference systems in the first round, communication systems in the second, and the combined strategies in the third. The results show that, 1) once sufficient performance is achieved, the human no longer notices and positively assesses technical improvements; 2) the human prefers systems that are more natural to them even though they have higher failure rates; and 3) the preferred option is the right combination of both systems.

</details>


### [16] [Gait Asymmetry from Unilateral Weakness and Improvement With Ankle Assistance: a Reinforcement Learning based Simulation Study](https://arxiv.org/abs/2602.18862)
*Yifei Yuan,Ghaith Androwis,Xianlian Zhou*

Main category: cs.RO

TL;DR: 该研究使用强化学习驱动的肌肉骨骼模拟框架，量化单侧肌肉无力对步态对称性的影响，并评估踝关节外骨骼辅助在受损条件下的改善效果。


<details>
  <summary>Details</summary>
Motivation: 单侧肌肉无力常导致不对称步态，破坏肢体间协调和站立时间。本研究旨在建立基于模拟和学习的流程，支持在患者实验前进行早期控制器开发。

Method: 采用强化学习驱动的肌肉骨骼模拟框架，通过将右腿肌肉力量减少到基线水平的75%、50%和25%来诱导不对称步态。使用离地时间、峰值接触力和关节级对称性指标量化步态不对称性，并评估踝关节外骨骼辅助效果。

Result: 肌肉无力增加导致时间和运动学不对称性逐渐增大，踝关节最为明显。踝关节活动范围对称性从100%力量时的近对称（SI=+6.4%；r=0.974）恶化到25%力量时的严重不对称（SI=-47.1%，r=0.889）。在50%力量时，踝关节外骨骼辅助改善了运动学对称性，将踝关节SI从25.8%降低到18.5%，相关性从r=0.948提高到0.966。

Conclusion: 该框架支持对损伤严重程度和辅助策略进行受控评估，为未来在人体实验中的验证提供了基础，展示了模拟和强化学习在步态康复研究中的潜力。

Abstract: Unilateral muscle weakness often leads to asymmetric gait, disrupting interlimb coordination and stance timing. This study presents a reinforcement learning (RL) based musculoskeletal simulation framework to (1) quantify how progressive unilateral muscle weakness affects gait symmetry and (2) evaluate whether ankle exoskeleton assistance can improve gait symmetry under impaired conditions. The overarching goal is to establish a simulation- and learning-based workflow that supports early controller development prior to patient experiments. Asymmetric gait was induced by reducing right-leg muscle strength to 75%, 50%, and 25% of baseline. Gait asymmetry was quantified using toe-off timing, peak contact forces, and joint-level symmetry metrics. Increasing weakness produced progressively larger temporal and kinematic asymmetry, most pronounced at the ankle. Ankle range of motion symmetry degraded from near-symmetric behavior at 100% strength (symmetry index, SI = +6.4%; correlation r=0.974) to severe asymmetry at 25% strength (SI = -47.1%, r=0.889), accompanied by a load shift toward the unimpaired limb. At 50% strength, ankle exoskeleton assistance improved kinematic symmetry relative to the unassisted impaired condition, reducing the magnitude of ankle SI from 25.8% to 18.5% and increasing ankle correlation from r=0.948 to 0.966, although peak loading remained biased toward the unimpaired side. Overall, this framework supports controlled evaluation of impairment severity and assistive strategies, and provides a basis for future validation in human experiments.

</details>


### [17] [Equivalence and Divergence of Bayesian Log-Odds and Dempster's Combination Rule for 2D Occupancy Grids](https://arxiv.org/abs/2602.18872)
*Tatiana Berlenko,Kirill Krinkin*

Main category: cs.RO

TL;DR: 提出了一种基于pignistic变换的方法，用于公平比较贝叶斯对数赔率和Dempster组合规则在占据栅格地图中的应用，通过匹配每观测决策概率来隔离融合规则与传感器参数化的影响。


<details>
  <summary>Details</summary>
Motivation: 需要一种公平的方法来比较贝叶斯融合和Dempster组合规则在占据栅格地图中的性能，避免传感器参数化对比较结果的影响。

Method: 采用pignistic变换方法，匹配每观测决策概率来隔离融合规则与传感器参数化的影响。在模拟、两个真实激光雷达数据集和下游路径规划任务中进行评估，使用BetP匹配和归一化似真性匹配两种标准。

Result: 在BetP匹配下，贝叶斯融合始终表现更优（15/15方向一致性，p=3.1e-5），绝对差异较小（0.001-0.022）。在归一化似真性匹配下，结果方向反转，表明结果依赖于匹配标准的选择。

Conclusion: 该方法为未来任何贝叶斯/信念函数比较提供了可重复使用的方法论，表明比较结果高度依赖于选择的匹配标准，在BetP匹配下贝叶斯融合表现更优。

Abstract: We introduce a pignistic-transform-based methodology for fair comparison of Bayesian log-odds and Dempster's combination rule in occupancy grid mapping, matching per-observation decision probabilities to isolate the fusion rule from sensor parameterization. Under BetP matching across simulation, two real lidar datasets, and downstream path planning, Bayesian fusion is consistently favored (15/15 directional consistency, p = 3.1e-5) with small absolute differences (0.001-0.022). Under normalized plausibility matching, the direction reverses, confirming the result is matching-criterion-specific. The methodology is reusable for any future Bayesian/belief function comparison.

</details>


### [18] [Temporal-Logic-Aware Frontier-Based Exploration](https://arxiv.org/abs/2602.18951)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 该论文提出了一种在未知环境中实现时间逻辑运动规划的新方法，通过引入"承诺状态"来捕捉不可逆动作的中间任务进展，并开发了基于前沿的探索算法来指导机器人完成任务。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，当机器人需要满足时间逻辑规范但目标位置未知时，传统方法难以有效规划。特别是某些动作具有不可逆后果，可能关闭未来满足任务的可能性，需要新的方法来处理这种不确定性。

Method: 提出"承诺状态"概念来捕捉不可逆动作带来的中间任务进展，开发了基于前沿的探索算法，该算法在引导机器人向任务进展的同时保留所有可能的任务满足路径。

Result: 提出的方法是可靠且完备的，通过仿真验证了其有效性，能够成功指导机器人在未知环境中满足时间逻辑规范。

Conclusion: 引入承诺状态和相应的探索算法为解决未知环境中时间逻辑运动规划问题提供了有效解决方案，特别适用于处理具有不可逆后果的动作场景。

Abstract: This paper addresses the problem of temporal logic motion planning for an autonomous robot operating in an unknown environment. The objective is to enable the robot to satisfy a syntactically co-safe Linear Temporal Logic (scLTL) specification when the exact locations of the desired labels are not known a priori. We introduce a new type of automaton state, referred to as commit states. These states capture intermediate task progress resulting from actions whose consequences are irreversible. In other words, certain future paths to satisfaction become not feasible after taking those actions that lead to the commit states. By leveraging commit states, we propose a sound and complete frontier-based exploration algorithm that strategically guides the robot to make progress toward the task while preserving all possible ways of satisfying it. The efficacy of the proposed method is validated through simulations.

</details>


### [19] [TactEx: An Explainable Multimodal Robotic Interaction Framework for Human-Like Touch and Hardness Estimation](https://arxiv.org/abs/2602.18967)
*Felix Verstraete,Lan Wei,Wen Fan,Dandan Zhang*

Main category: cs.RO

TL;DR: TactEx是一个可解释的多模态机器人交互框架，融合视觉、触觉和语言进行类人硬度感知和交互指导，在水果成熟度评估任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确感知物体硬度对于安全灵巧的接触式机器人操作至关重要，需要结合触觉感知和上下文理解。

Method: 融合GelSight-Mini触觉流、RGB观察和语言提示；使用ResNet50+LSTM模型从序列触觉数据估计硬度；跨模态对齐模块结合视觉线索和大型语言模型指导；比较YOLO与Grounded-SAM进行接触点选择；轻量级LLM解析用户指令并生成自然语言解释。

Result: 系统在水果成熟度区分上实现统计显著的类别分离（所有水果对p<0.01）；Grounded-SAM在细粒度分割和接触点选择上更鲁棒；端到端评估中，简单用户查询任务成功率达90%，并能泛化到新任务而无需大规模调优。

Conclusion: 结合预训练的视觉和触觉模型与语言基础化，有望推进机器人中可解释的、类人的触觉感知和决策制定。

Abstract: Accurate perception of object hardness is essential for safe and dexterous contact-rich robotic manipulation. Here, we present TactEx, an explainable multimodal robotic interaction framework that unifies vision, touch, and language for human-like hardness estimation and interactive guidance. We evaluate TactEx on fruit-ripeness assessment, a representative task that requires both tactile sensing and contextual understanding. The system fuses GelSight-Mini tactile streams with RGB observations and language prompts. A ResNet50+LSTM model estimates hardness from sequential tactile data, while a cross-modal alignment module combines visual cues with guidance from a large language model (LLM). This explainable multimodal interface allows users to distinguish ripeness levels with statistically significant class separation (p < 0.01 for all fruit pairs). For touch placement, we compare YOLO with Grounded-SAM (GSAM) and find GSAM to be more robust for fine-grained segmentation and contact-site selection. A lightweight LLM parses user instructions and produces grounded natural-language explanations linked to the tactile outputs. In end-to-end evaluations, TactEx attains 90% task success on simple user queries and generalises to novel tasks without large-scale tuning. These results highlight the promise of combining pretrained visual and tactile models with language grounding to advance explainable, human-like touch perception and decision-making in robotics.

</details>


### [20] [Bumper Drone: Elastic Morphology Design for Aerial Physical Interaction](https://arxiv.org/abs/2602.18976)
*Pongporn Supa,Alex Dunnett,Feng Xiao,Rui Wu,Mirko Kovac,Basaran Bahadir Kocer*

Main category: cs.RO

TL;DR: 无人机平台通过弹性触角实现"接触即走"机动，利用被动动力学响应实现近障碍物导航，无需主动避障控制。


<details>
  <summary>Details</summary>
Motivation: 传统空中机器人主要避免障碍物，而本文旨在探索如何利用环境接触交互进行导航、探索和操作。关键挑战在于处理未知目标上的不确定接触力，这通常需要精确传感和主动控制。

Method: 设计带有弹性触角的无人机平台，实现"接触即走"机动。这种自调节的连续碰撞运动使无人机能够保持靠近墙壁而无需主动避障。利用环境交互作为体现控制形式，低层稳定和近障碍物导航从无人机-障碍物系统的被动动态响应中涌现，类似于质量-弹簧-阻尼系统。

Result: 实验显示弹性触角能吸收冲击能量同时保持飞行器稳定性，与刚性触角配置相比减少38%的俯仰振荡。较低的触角布置进一步减少约54%的俯仰振荡。除了间歇接触外，配备弹性触角的平台还能与静态物体保持稳定持续接触，仅依赖标准姿态PID控制器。

Conclusion: 通过弹性触角实现的被动动力学响应为空中物理交互提供了一种简化控制的方法，使无人机能够在复杂环境中进行稳定的接触式导航和操作，减少了对复杂传感和主动控制的需求。

Abstract: Aerial robots are evolving from avoiding obstacles to exploiting the environmental contact interactions for navigation, exploration and manipulation. A key challenge in such aerial physical interactions lies in handling uncertain contact forces on unknown targets, which typically demand accurate sensing and active control. We present a drone platform with elastic horns that enables touch-and-go manoeuvres - a self-regulated, consecutive bumping motion that allows the drone to maintain proximity to a wall without relying on active obstacle avoidance. It leverages environmental interaction as a form of embodied control, where low-level stabilisation and near-obstacle navigation emerge from the passive dynamic responses of the drone-obstacle system that resembles a mass-spring-damper system. Experiments show that the elastic horn can absorb impact energy while maintaining vehicle stability, reducing pitch oscillations by 38% compared to the rigid horn configuration. The lower horn arrangement was found to reduce pitch oscillations by approximately 54%. In addition to intermittent contact, the platform equipped with elastic horns also demonstrates stable, sustained contact with static objects, relying on a standard attitude PID controller.

</details>


### [21] [FruitTouch: A Perceptive Gripper for Gentle and Scalable Fruit Harvesting](https://arxiv.org/abs/2602.18991)
*Ruohan Zhang,Mohammad Amin Mirzaee,Wenzhen Yuan*

Main category: cs.RO

TL;DR: FruitTouch是一种紧凑型夹持器，集成了高分辨率视觉触觉传感，用于水果自动采摘，能够稳定抓取不同尺寸水果并实时监测力、滑移和软度。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺推动水果采摘自动化需求，需要紧凑、能稳定抓取多种水果并提供可靠反馈的传感器化夹持器。

Method: 通过优化光学设计，集成高分辨率视觉触觉传感，嵌入式摄像头捕捉触觉图像，实现实时力估计、滑移检测和软度预测。

Result: 在真实水果采摘实验中验证了夹持器的抓取稳定性和有效防止损伤的能力。

Conclusion: FruitTouch提供了一种低成本、机械简单且能适应多种水果尺寸的解决方案，在水果自动采摘中具有实用价值。

Abstract: The automation of fruit harvesting has gained increasing significance in response to rising labor shortages. A sensorized gripper is a key component of this process, which must be compact enough for confined spaces, able to stably grasp diverse fruits, and provide reliable feedback on fruit conditions for efficient harvesting. To address this need, we propose FruitTouch, a compact gripper that integrates high-resolution, vision-based tactile sensing through an optimized optical design. This configuration accommodates a wide range of fruit sizes while maintaining low cost and mechanical simplicity. Tactile images captured by an embedded camera provide rich information for real-time force estimation, slip detection, and softness prediction. We validate the gripper in real-world fruit harvesting experiments, demonstrating robust grasp stability and effective damage prevention.

</details>


### [22] [Path planning for unmanned surface vehicle based on predictive artificial potential field. International Journal of Advanced Robotic Systems](https://arxiv.org/abs/2602.19062)
*Jia Song,Ce Hao,Jiangcheng Su*

Main category: cs.RO

TL;DR: 本文提出了一种新的预测人工势场方法，通过引入时间信息和预测势能来规划更平滑的路径，解决了高速无人水面艇路径规划中的转弯角度限制、航行时间缩短和智能避障问题。


<details>
  <summary>Details</summary>
Motivation: 高速无人水面艇的路径规划需要更复杂的解决方案来减少航行时间和节省能源。传统人工势场方法在全局和局部路径规划中存在不足，特别是在处理车辆动力学和局部最小值可达性方面。

Method: 提出了预测人工势场方法，包含三个关键改进：角度限制、速度调整和预测势能。该方法考虑了车辆动力学和局部最小值可达性，通过时间信息和预测势能来规划更平滑的路径。

Result: 与传统人工势场相比，预测人工势场成功限制了最大转弯角度，缩短了航行时间，并能智能避障。仿真结果表明该方法解决了凹形局部最小值问题，提高了特殊场景下的可达性。

Conclusion: 预测人工势场方法为高速无人水面艇生成了更高效的路径，减少了航行时间并节省了能源，在路径规划的平滑性和可行性方面表现出显著优势。

Abstract: Path planning for high-speed unmanned surface vehicles requires more complex solutions to reduce sailing time and save energy. This article proposes a new predictive artificial potential field that incorporates time information and predictive potential to plan smoother paths. It explores the principles of the artificial potential field, considering vehicle dynamics and local minimum reachability. The study first analyzes the most advanced traditional artificial potential field and its drawbacks in global and local path planning. It then introduces three modifications to the predictive artificial potential field-angle limit, velocity adjustment, and predictive potential to enhance the feasibility and flatness of the generated path. A comparison between the traditional and predictive artificial potential fields demonstrates that the latter successfully restricts the maximum turning angle, shortens sailing time, and intelligently avoids obstacles. Simulation results further verify that the predictive artificial potential field addresses the concave local minimum problem and improves reachability in special scenarios, ultimately generating a more efficient path that reduces sailing time and conserves energy for unmanned surface vehicles.

</details>


### [23] [Design, Locomotion, and Control of Amphibious Robots: Recent Advances](https://arxiv.org/abs/2602.19077)
*Yi Jin,Chang Liu,Roger D. Quinn,Robert J. Wood,C. Chase Cao*

Main category: cs.RO

TL;DR: 这篇综述论文回顾了水陆两栖机器人的最新进展，重点关注运动机制、驱动技术和传感控制集成，并指出了该领域未来的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 水陆两栖机器人在环境保护、灾害响应和国防等领域具有重要应用价值，但其性能受到运动机制、驱动技术和控制系统的限制，需要系统性的综述来指导未来研究。

Method: 采用文献综述方法，系统分析水陆两栖机器人在运动策略、材料基驱动器、控制系统等方面的最新研究进展。

Result: 总结了水陆两栖机器人在运动机制、驱动技术和传感控制集成方面的最新进展，识别了当前的技术瓶颈和发展趋势。

Conclusion: 水陆两栖机器人领域面临诸多挑战，但也存在重要机遇，未来研究应致力于开发更高效、更具韧性和多功能性的系统。

Abstract: Amphibious robots, operating seamlessly across land and water, are advancing applications in conservation, disaster response, and defense. Their performance depends on locomotion mechanisms, actuation technologies, and sensor-control integration. This review highlights recent progress in these areas, examining movement strategies, material-based actuators, and control systems for autonomy and adaptability. Challenges and opportunities are outlined to guide future research toward more efficient, resilient, and multifunctional amphibious robots.

</details>


### [24] [A User-driven Design Framework for Robotaxi](https://arxiv.org/abs/2602.19107)
*Yue Deng,Changyang He*

Main category: cs.RO

TL;DR: 研究通过实地访谈和体验调查真实世界无人驾驶出租车的用户体验，发现用户被低成本、社交推荐和好奇心吸引，但面临灵活性不足、透明度不够、管理困难等挑战，并提出了覆盖全旅程的用户驱动设计框架。


<details>
  <summary>Details</summary>
Motivation: 当前无人驾驶出租车研究主要关注技术驾驶性能，而忽视了乘客在没有人类司机情况下的实际体验和评价。先前研究多依赖模拟或假设场景，存在局限性，需要调查真实世界的使用体验。

Method: 采用18次半结构化访谈和自民族志乘车体验，调查真实世界无人驾驶出租车的使用情况，收集用户的实际体验数据。

Result: 用户被低成本、社交推荐和好奇心吸引；重视增强的自主感、一致的驾驶行为和标准化体验；但面临灵活性有限、透明度不足、管理困难、边缘情况鲁棒性问题和紧急处理担忧。隐私、安全、伦理和信任是核心影响因素。

Conclusion: 提出覆盖端到端旅程的用户驱动设计框架，包括乘车前配置、上下文感知接客、行程中可解释性和事后问责反馈，以指导无人驾驶出租车的交互和服务设计。

Abstract: Robotaxis are emerging as a promising form of urban mobility, yet research has largely emphasized technical driving performance while leaving open how passengers experience and evaluate rides without a human driver. To address the limitations of prior work that often relies on simulated or hypothetical settings, we investigate real-world robotaxi use through 18 semi-structured interviews and autoethnographic ride experiences. We found that users were drawn to robotaxis by low cost, social recommendation, and curiosity. They valued a distinctive set of benefits, such as an increased sense of agency, and consistent driving behavioral consistency and standardized ride experiences. However, they encountered persistent challenges around limited flexibility, insufficient transparency, management difficulty, robustness concerns in edge cases, and emergency handling concerns. Robotaxi experiences were shaped by privacy, safety, ethics, and trust. Users were often privacy-indifferent yet sensitive to opaque access and leakage risks; safety perceptions were polarized; and ethical considerations surfaced round issues such as accountability, feedback responsibility and absence of human-like social norms. Based on these findings, we propose a user-driven design framework spanning the end-to-end journey, such as pre-ride configuration (hailing), context-aware pickup facilitation (pick-up) in-ride explainability (traveling), and accountable post-ride feedback (drop-off) to guide robotaxi interaction and service design.

</details>


### [25] [Understanding Fire Through Thermal Radiation Fields for Mobile Robots](https://arxiv.org/abs/2602.19108)
*Anton R. Wagner,Madhan Balaji Rao,Xuesu Xiao,Sören Pirk*

Main category: cs.RO

TL;DR: 本文提出了一种让移动机器人在火灾环境中安全导航的新方法，通过构建实时热辐射场来理解火灾，并将热约束嵌入到路径规划中，使机器人能够避开危险区域并到达目标位置。


<details>
  <summary>Details</summary>
Motivation: 火灾环境中的自主移动机器人对于灾难响应至关重要，但现有方法缺乏对火灾热辐射的实时理解和安全导航能力，限制了机器人在火灾场景中的有效部署。

Method: 通过配准深度图像和热图像获得带有温度值的3D点云，识别火灾区域，利用斯特藩-玻尔兹曼定律估算空区域的热辐射，构建连续的热辐射场，并将热约束嵌入到代价地图中进行路径规划。

Result: 在波士顿动力Spot机器人上的受控实验验证了该方法能够使机器人避开危险区域并成功到达导航目标，展示了在火灾环境中安全导航的能力。

Conclusion: 该方法为移动机器人在火灾环境中的自主部署铺平了道路，在搜救、消防和危险物质响应等领域具有潜在应用价值，实现了热安全约束下的自主导航。

Abstract: Safely moving through environments affected by fire is a critical capability for autonomous mobile robots deployed in disaster response. In this work, we present a novel approach for mobile robots to understand fire through building real-time thermal radiation fields. We register depth and thermal images to obtain a 3D point cloud annotated with temperature values. From these data, we identify fires and use the Stefan-Boltzmann law to approximate the thermal radiation in empty spaces. This enables the construction of a continuous thermal radiation field over the environment. We show that this representation can be used for robot navigation, where we embed thermal constraints into the cost map to compute collision-free and thermally safe paths. We validate our approach on a Boston Dynamics Spot robot in controlled experimental settings. Our experiments demonstrate the robot's ability to avoid hazardous regions while still reaching navigation goals. Our approach paves the way toward mobile robots that can be autonomously deployed in fire-affected environments, with potential applications in search-and-rescue, firefighting, and hazardous material response.

</details>


### [26] [Distributed and Consistent Multi-Robot Visual-Inertial-Ranging Odometry on Lie Groups](https://arxiv.org/abs/2602.19173)
*Ziwei Kang,Yizhi Zhou*

Main category: cs.RO

TL;DR: 提出分布式协作视觉-惯性-测距里程计(DC-VIRO)框架，在多机器人系统中融合VIO和UWB测量，解决GPS拒止环境下的定位漂移问题，同时实现锚点自校准。


<details>
  <summary>Details</summary>
Motivation: 在GPS拒止环境中，多机器人系统需要可靠的定位。VIO虽然轻量准确但存在累积漂移，UWB提供全局观测但现有方法多为单机器人设计且依赖预校准锚点，限制了实际应用的鲁棒性。

Method: 提出分布式协作VIRO框架，将锚点位置纳入系统状态以处理校准不确定性，通过机器人间通信共享锚点观测提供额外几何约束，采用李群上的右不变误差公式保持VIO的可观测性。

Result: 多机器人仿真结果表明，DC-VIRO显著提高了定位精度和鲁棒性，同时在分布式设置中实现了锚点自校准。

Conclusion: DC-VIRO框架通过紧密融合多机器人VIO和UWB测量，解决了GPS拒止环境下的定位问题，提高了系统鲁棒性并实现了锚点自校准，适用于分布式多机器人系统。

Abstract: Reliable localization is a fundamental requirement for multi-robot systems operating in GPS-denied environments. Visual-inertial odometry (VIO) provides lightweight and accurate motion estimation but suffers from cumulative drift in the absence of global references. Ultra-wideband (UWB) ranging offers complementary global observations, yet most existing UWB-aided VIO methods are designed for single-robot scenarios and rely on pre-calibrated anchors, which limits their robustness in practice. This paper proposes a distributed collaborative visual-inertial-ranging odometry (DC-VIRO) framework that tightly fuses VIO and UWB measurements across multiple robots. Anchor positions are explicitly included in the system state to address calibration uncertainty, while shared anchor observations are exploited through inter-robot communication to provide additional geometric constraints. By leveraging a right-invariant error formulation on Lie groups, the proposed approach preserves the observability properties of standard VIO, ensuring estimator consistency. Simulation results with multiple robots demonstrate that DC-VIRO significantly improves localization accuracy and robustness, while simultaneously enabling anchor self-calibration in distributed settings.

</details>


### [27] [Visual Prompt Guided Unified Pushing Policy](https://arxiv.org/abs/2602.19193)
*Hieu Bui,Ziyan Gao,Yuya Hosoda,Joo-Ho Lee*

Main category: cs.RO

TL;DR: 提出了一种统一的推动策略，通过轻量级提示机制指导生成反应式、多模态的推动动作，可用于各种规划问题


<details>
  <summary>Details</summary>
Motivation: 现有的推动方法通常依赖多步推动计划和预定义的推动原语，应用范围有限，效率和通用性在不同场景中受到限制

Method: 将轻量级提示机制融入流匹配策略中，形成统一的推动策略，视觉提示可由高层规划器指定，使推动策略能在各种规划问题中重复使用

Result: 实验结果表明，所提出的统一推动策略不仅优于现有基线方法，还能有效作为VLM引导规划框架中的底层原语，高效解决桌面清理任务

Conclusion: 该统一推动策略通过提示机制实现了更高效、通用的物体重排能力，可作为模块化组件集成到更复杂的规划系统中

Abstract: As one of the simplest non-prehensile manipulation skills, pushing has been widely studied as an effective means to rearrange objects. Existing approaches, however, typically rely on multi-step push plans composed of pre-defined pushing primitives with limited application scopes, which restrict their efficiency and versatility across different scenarios. In this work, we propose a unified pushing policy that incorporates a lightweight prompting mechanism into a flow matching policy to guide the generation of reactive, multimodal pushing actions. The visual prompt can be specified by a high-level planner, enabling the reuse of the pushing policy across a wide range of planning problems. Experimental results demonstrate that the proposed unified pushing policy not only outperforms existing baselines but also effectively serves as a low-level primitive within a VLM-guided planning framework to solve table-cleaning tasks efficiently.

</details>


### [28] [The Price Is Not Right: Neuro-Symbolic Methods Outperform VLAs on Structured Long-Horizon Manipulation Tasks with Significantly Lower Energy Consumption](https://arxiv.org/abs/2602.19260)
*Timothy Duggan,Pierrick Lorang,Hong Lu,Matthias Scheutz*

Main category: cs.RO

TL;DR: 该研究比较了视觉-语言-动作模型与神经符号架构在结构化长时程机器人操作任务上的表现，发现神经符号方法在成功率、泛化能力和能源效率方面显著优于VLA模型。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉-语言-动作模型被提出作为通用机器人策略的途径，但其在结构化、长时程操作任务上的有效性和效率尚不明确，需要与传统的神经符号方法进行实证比较。

Method: 研究对微调的开源VLA模型π0与结合PDDL符号规划和学习的低级控制的神经符号架构进行了头对头比较，在模拟环境中评估了它们在结构化汉诺塔操作任务上的表现，同时测量了训练和执行期间的任务性能和能耗。

Result: 在3块任务中，神经符号模型达到95%成功率，而最佳VLA仅为34%。神经符号模型还能泛化到未见过的4块变体（78%成功率），而两种VLA均无法完成任务。在训练期间，VLA微调消耗的能源比神经符号方法高出近两个数量级。

Conclusion: 研究结果突显了端到端基础模型方法与结构化推理架构在长时程机器人操作中的重要权衡，强调了显式符号结构在提高可靠性、数据效率和能源效率方面的作用。

Abstract: Vision-Language-Action (VLA) models have recently been proposed as a pathway toward generalist robotic policies capable of interpreting natural language and visual inputs to generate manipulation actions. However, their effectiveness and efficiency on structured, long-horizon manipulation tasks remain unclear. In this work, we present a head-to-head empirical comparison between a fine-tuned open-weight VLA model π0 and a neuro-symbolic architecture that combines PDDL-based symbolic planning with learned low-level control. We evaluate both approaches on structured variants of the Towers of Hanoi manipulation task in simulation while measuring both task performance and energy consumption during training and execution. On the 3-block task, the neuro-symbolic model achieves 95% success compared to 34% for the best-performing VLA. The neuro-symbolic model also generalizes to an unseen 4-block variant (78% success), whereas both VLAs fail to complete the task. During training, VLA fine-tuning consumes nearly two orders of magnitude more energy than the neuro-symbolic approach. These results highlight important trade-offs between end-to-end foundation-model approaches and structured reasoning architectures for long-horizon robotic manipulation, emphasizing the role of explicit symbolic structure in improving reliability, data efficiency, and energy efficiency. Code and models are available at https://price-is-not-right.github.io

</details>


### [29] [3D Shape Control of Extensible Multi-Section Soft Continuum Robots via Visual Servoing](https://arxiv.org/abs/2602.19273)
*Abhinav Gandhi,Shou-Shan Chiang,Cagdas D. Onal,Berk Calli*

Main category: cs.RO

TL;DR: 提出基于视觉的软体连续体机械臂全身形状控制算法，无需本体感受传感器，利用外部摄像头实现全局稳定收敛


<details>
  <summary>Details</summary>
Motivation: 现有视觉控制算法主要调节机器人末端位姿，无法利用软体机械臂的运动学冗余性；现有方法需要参考姿态图像且存在局部最小值问题

Method: 提出基于模型的2.5D形状视觉伺服控制，通过外部摄像头获取机器人全身形状图像，利用逆运动学求解器生成参考特征，无需参考姿态图像

Result: 在多段连续体机械臂上验证，能精确调节全身形状，末端定位精度在1mm内，瞬态响应平滑；成功完成堆叠、倾倒、拉动等物体操作任务

Conclusion: 该视觉控制算法能有效调节软体连续体机械臂的全身形状，无需本体感受传感器，具有全局稳定收敛性，适用于无传感能力的软体机器人

Abstract: In this paper, we propose a novel vision-based control algorithm for regulating the whole body shape of extensible multisection soft continuum manipulators. Contrary to existing vision-based control algorithms in the literature that regulate the robot's end effector pose, our proposed control algorithm regulates the robot's whole body configuration, enabling us to leverage its kinematic redundancy. Additionally, our model-based 2.5D shape visual servoing provides globally stable asymptotic convergence in the robot's 3D workspace compared to the closest works in the literature that report local minima. Unlike existing visual servoing algorithms in the literature, our approach does not require information from proprioceptive sensors, making it suitable for continuum manipulators without such capabilities. Instead, robot state is estimated from images acquired by an external camera that observes the robot's whole body shape and is also utilized to close the shape control loop. Traditionally, visual servoing schemes require an image of the robot at its reference pose to generate the reference features. In this work, we utilize an inverse kinematics solver to generate reference features for the desired robot configuration and do not require images of the robot at the reference. Experiments are performed on a multisection continuum manipulator demonstrating the controller's capability to regulate the robot's whole body shape while precisely positioning the robot's end effector. Results validate our controller's ability to regulate the shape of continuum robots while demonstrating a smooth transient response and a steady-state error within 1 mm. Proof-of-concept object manipulation experiments including stacking, pouring, and pulling tasks are performed to demonstrate our controller's applicability.

</details>


### [30] [Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation](https://arxiv.org/abs/2602.19304)
*Haojun Shi,Suyu Ye,Katherine M. Guerrerio,Jianzhi Shen,Yifan Yin,Daniel Khashabi,Chien-Ming Huang,Tianmin Shu*

Main category: cs.RO

TL;DR: CaPE是一个安全可解释的多模态路径规划方法，通过视觉语言模型生成路径编辑程序，结合基于模型的规划器验证，实现机器人根据环境和其他智能体语言通信调整路径规划。


<details>
  <summary>Details</summary>
Motivation: 在去中心化智能体协作中，当智能体无法可靠预测彼此意图和计划时，语言通信对确保安全至关重要。特别是在路径级协作场景中，智能体需要相互调整路径以避免碰撞或完成物理协作任务。

Method: 提出CaPE方法：1）使用视觉语言模型基于环境和其他智能体的语言通信合成路径编辑程序；2）通过基于模型的规划器验证程序安全性；3）将通信安全地、可解释地落实到路径计划更新中。

Result: 在模拟和真实世界的多种场景中评估，包括自动驾驶、家庭环境和联合搬运任务中的多机器人及人机协作。CaPE可作为即插即用模块集成到不同机器人系统中，显著提升机器人根据其他机器人或人类语言通信调整计划的能力。

Conclusion: CaPE结合VLM路径编辑程序合成和基于模型的规划安全性，使机器人能够在保持安全和可解释性的同时实现开放式协作，为去中心化智能体协作提供了有效的路径规划解决方案。

Abstract: Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In this work, we focus on path-level cooperation in which agents must adapt their paths to one another in order to avoid collisions or perform physical collaboration such as joint carrying. In particular, we propose a safe and interpretable multimodal path planning method, CaPE (Code as Path Editor), which generates and updates path plans for an agent based on the environment and language communication from other agents. CaPE leverages a vision-language model (VLM) to synthesize a path editing program verified by a model-based planner, grounding communication to path plan updates in a safe and interpretable way. We evaluate our approach in diverse simulated and real-world scenarios, including multi-robot and human-robot cooperation in autonomous driving, household, and joint carrying tasks. Experimental results demonstrate that CaPE can be integrated into different robotic systems as a plug-and-play module, greatly enhancing a robot's ability to align its plan to language communication from other robots or humans. We also show that the combination of the VLM-based path editing program synthesis and model-based planning safety enables robots to achieve open-ended cooperation while maintaining safety and interpretability.

</details>


### [31] [WildOS: Open-Vocabulary Object Search in the Wild](https://arxiv.org/abs/2602.19308)
*Hardik Shah,Erica Tevere,Deegan Atha,Marcel Kaufmann,Shehryar Khattak,Manthan Patel,Marco Hutter,Jonas Frey,Patrick Spieler*

Main category: cs.RO

TL;DR: WildOS是一个用于长距离、开放词汇对象搜索的统一系统，结合了安全几何探索与语义视觉推理，在复杂无结构户外环境中实现自主导航。


<details>
  <summary>Details</summary>
Motivation: 在复杂无结构的户外环境中，机器人需要在没有先验地图和有限深度感知的情况下进行长距离操作。仅依赖几何前沿进行探索往往不足，需要能够语义推理去哪里以及什么是安全可通行的能力。

Method: WildOS构建稀疏导航图来维护空间记忆，同时利用基于基础模型的视觉模块ExploRFM对图的边界节点进行评分。ExploRFM同时预测可通行性、视觉边界和图像空间中的对象相似性。此外，引入了基于粒子滤波的方法对开放词汇目标查询进行粗略定位。

Result: 在各种越野和城市地形中的闭环现场实验表明，WildOS实现了稳健的导航，在效率和自主性方面显著优于纯几何和纯视觉基线方法。

Conclusion: 研究结果突显了视觉基础模型在驱动开放世界机器人行为方面的潜力，这些行为既具有语义信息又基于几何基础。

Abstract: Autonomous navigation in complex, unstructured outdoor environments requires robots to operate over long ranges without prior maps and limited depth sensing. In such settings, relying solely on geometric frontiers for exploration is often insufficient. In such settings, the ability to reason semantically about where to go and what is safe to traverse is crucial for robust, efficient exploration. This work presents WildOS, a unified system for long-range, open-vocabulary object search that combines safe geometric exploration with semantic visual reasoning. WildOS builds a sparse navigation graph to maintain spatial memory, while utilizing a foundation-model-based vision module, ExploRFM, to score frontier nodes of the graph. ExploRFM simultaneously predicts traversability, visual frontiers, and object similarity in image space, enabling real-time, onboard semantic navigation tasks. The resulting vision-scored graph enables the robot to explore semantically meaningful directions while ensuring geometric safety. Furthermore, we introduce a particle-filter-based method for coarse localization of the open-vocabulary target query, that estimates candidate goal positions beyond the robot's immediate depth horizon, enabling effective planning toward distant goals. Extensive closed-loop field experiments across diverse off-road and urban terrains demonstrate that WildOS enables robust navigation, significantly outperforming purely geometric and purely vision-based baselines in both efficiency and autonomy. Our results highlight the potential of vision foundation models to drive open-world robotic behaviors that are both semantically informed and geometrically grounded. Project Page: https://leggedrobotics.github.io/wildos/

</details>


### [32] [TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics](https://arxiv.org/abs/2602.19313)
*Shirui Chen,Cole Harrison,Ying-Chun Lee,Angela Jin Yang,Zhongzheng Ren,Lillian J. Ratliff,Jiafei Duan,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: TOPReward是一种基于概率的时间价值函数，利用预训练视频视觉语言模型的潜在世界知识来估计机器人任务进度，在零样本评估中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在强化学习中的进展受到样本效率低和现实世界稀疏奖励的限制，需要开发可泛化的过程奖励模型来提供细粒度反馈。

Method: TOPReward从预训练视频VLM的内部token对数概率中直接提取任务进度，而不是让VLM直接输出进度值，避免了数值表示错误的问题。

Result: 在130多个不同的现实世界任务和多个机器人平台上，TOPReward在Qwen3-VL上实现了0.947的平均价值顺序相关性，显著优于接近零相关性的GVL基线。

Conclusion: TOPReward可作为下游应用的多功能工具，包括成功检测和奖励对齐的行为克隆，为机器人强化学习提供了有效的泛化过程奖励模型。

Abstract: While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, their advancement in Reinforcement Learning (RL) remains hampered by low sample efficiency and sparse rewards in real-world settings. Developing generalizable process reward models is essential for providing the fine-grained feedback necessary to bridge this gap, yet existing temporal value functions often fail to generalize beyond their training domains. We introduce TOPReward, a novel, probabilistically grounded temporal value function that leverages the latent world knowledge of pretrained video Vision-Language Models (VLMs) to estimate robotic task progress. Unlike prior methods that prompt VLMs to directly output progress values, which are prone to numerical misrepresentation, TOPReward extracts task progress directly from the VLM's internal token logits. In zero-shot evaluations across 130+ distinct real-world tasks and multiple robot platforms (e.g., Franka, YAM, SO-100/101), TOPReward achieves 0.947 mean Value-Order Correlation (VOC) on Qwen3-VL, dramatically outperforming the state-of-the-art GVL baseline which achieves near-zero correlation on the same open-source model. We further demonstrate that TOPReward serves as a versatile tool for downstream applications, including success detection and reward-aligned behavior cloning.

</details>


### [33] [Online Navigation Planning for Long-term Autonomous Operation of Underwater Gliders](https://arxiv.org/abs/2602.19315)
*Victor-Alexandru Darvariu,Charlotte Z. Reed,Jan Stratmann,Bruno Lacerda,Benjamin Allsup,Stephen Woodward,Elizabeth Siddle,Trishna Saeharaseelan,Owain Jones,Dan Jones,Tobias Ferreira,Chloe Baker,Kevin Chaplin,James Kirk,Ashley Morris,Ryan Patmore,Jeff Polton,Charlotte Williams,Alexandra Kokkinaki,Alvaro Lorenzo Lopez,Justin J. H. Buck,Nick Hawes*

Main category: cs.RO

TL;DR: 该论文提出了一种基于蒙特卡洛树搜索的在线规划方法，用于水下滑翔机器人的自主导航，通过物理信息模拟器处理控制不确定性和洋流预测，并在北海进行了为期3个月、1000公里的实地验证。


<details>
  <summary>Details</summary>
Motivation: 水下滑翔机器人已成为海洋采样的重要工具，但大规模机队的自主长期部署仍然稀缺，缺乏合适的方法和系统来管理日益庞大的滑翔机舰队。

Method: 将滑翔机导航规划建模为随机最短路径马尔可夫决策过程，提出基于蒙特卡洛树搜索的样本在线规划器，使用物理信息模拟器生成样本，模拟控制不确定性和洋流预测，并通过历史数据拟合模拟器参数，集成到Slocum滑翔机的自主指挥控制系统中实现闭环重规划。

Result: 在北海进行了两次实地部署，总计约3个月、1000公里的自主操作，验证了系统有效性，相比直线导航提高了效率，证明了样本规划在长期海洋自主性中的实用性。

Conclusion: 该研究提出了一种实用的样本规划方法，能够有效处理水下滑翔机器人导航中的不确定性，为长期海洋自主操作提供了可行的解决方案，展示了在实际部署中的成功应用。

Abstract: Underwater glider robots have become an indispensable tool for ocean sampling. Although stakeholders are calling for tools to manage increasingly large fleets of gliders, successful autonomous long-term deployments have thus far been scarce, which hints at a lack of suitable methodologies and systems. In this work, we formulate glider navigation planning as a stochastic shortest-path Markov Decision Process and propose a sample-based online planner based on Monte Carlo Tree Search. Samples are generated by a physics-informed simulator that captures uncertain execution of controls and ocean current forecasts while remaining computationally tractable. The simulator parameters are fitted using historical glider data. We integrate these methods into an autonomous command-and-control system for Slocum gliders that enables closed-loop replanning at each surfacing. The resulting system was validated in two field deployments in the North Sea totalling approximately 3 months and 1000 km of autonomous operation. Results demonstrate improved efficiency compared to straight-to-goal navigation and show the practicality of sample-based planning for long-term marine autonomy.

</details>


### [34] [Design and Control of Modular Magnetic Millirobots for Multimodal Locomotion and Shape Reconfiguration](https://arxiv.org/abs/2602.19346)
*Erik Garcia Oyono,Jialin Lin,Dandan Zhang*

Main category: cs.RO

TL;DR: 提出一种模块化磁控毫米机器人平台，包含三种功能模块，通过二维磁场控制实现运动、重构和货物操作，在受限环境中具有多模态适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有模块化磁控机器人通常依赖工作空间碰撞进行重构，使用笨重的三维电磁系统，缺乏稳健的单模块控制，限制了在生物医学等场景的应用。

Method: 设计包含三种立方体模块的平台：自由模块（支持自组装和重构）、固定模块（实现翻转行走运动）、夹持模块（货物操作）。通过可编程的二维均匀和梯度磁场组合进行驱动控制。

Result: 实验展示了基于实时视觉反馈和A*路径规划的闭环导航，实现了稳健的单模块控制。系统在低场强下完成自组装、多模态转换和拆卸，链到夹持转换成功率90%，链到方形转换一致性较低，表明模块几何形状影响重构可靠性。

Conclusion: 该平台具备多模态行为和稳健控制能力，为受限环境中可扩展和自适应任务执行提供了有前景的途径。

Abstract: Modular small-scale robots offer the potential for on-demand assembly and disassembly, enabling task-specific adaptation in dynamic and constrained environments. However, existing modular magnetic platforms often depend on workspace collisions for reconfiguration, employ bulky three-dimensional electromagnetic systems, and lack robust single-module control, which limits their applicability in biomedical settings. In this work, we present a modular magnetic millirobotic platform comprising three cube-shaped modules with embedded permanent magnets, each designed for a distinct functional role: a free module that supports self-assembly and reconfiguration, a fixed module that enables flip-and-walk locomotion, and a gripper module for cargo manipulation. Locomotion and reconfiguration are actuated by programmable combinations of time-varying two-dimensional uniform and gradient magnetic field inputs. Experiments demonstrate closed-loop navigation using real-time vision feedback and A* path planning, establishing robust single-module control capabilities. Beyond locomotion, the system achieves self-assembly, multimodal transformations, and disassembly at low field strengths. Chain-to-gripper transformations succeeded in 90% of trials, while chain-to-square transformations were less consistent, underscoring the role of module geometry in reconfiguration reliability. These results establish a versatile modular robotic platform capable of multimodal behavior and robust control, suggesting a promising pathway toward scalable and adaptive task execution in confined environments.

</details>


### [35] [Vid2Sid: Videos Can Help Close the Sim2Real Gap](https://arxiv.org/abs/2602.19359)
*Kevin Qiu,Yu Zhang,Marek Cygan,Josie Hughes*

Main category: cs.RO

TL;DR: Vid2Sid：基于视频的系统识别框架，利用基础模型感知和VLM优化器分析仿真-真实配对视频，诊断物理参数不匹配并提供自然语言解释的物理参数更新建议。


<details>
  <summary>Details</summary>
Motivation: 机器人仿真器物理参数（摩擦、阻尼、材料刚度）校准通常依赖手动调整或黑盒优化器，这些方法能减少误差但无法解释哪些物理差异导致误差。在仅使用外部相机感知时，问题进一步复杂化，因为存在感知噪声且缺乏直接的力或状态测量。

Method: 提出Vid2Sid系统识别流程，结合基础模型感知和VLM-in-the-loop优化器，分析配对仿真-真实视频，诊断具体不匹配，并通过自然语言推理提出物理参数更新建议。在肌腱驱动手指（MuJoCo刚体动力学）和可变形连续体触手（PyElastica软体动力学）上进行评估。

Result: 在训练期间未见过的sim2real保留控制任务中，Vid2Sid在所有设置中取得最佳平均排名，匹配或超越黑盒优化器，同时独特地在每次迭代中提供可解释推理。Sim2sim验证显示Vid2Sid最准确地恢复地面真实参数（平均相对误差低于13% vs. 28-98%）。消融分析揭示了三种校准机制。

Conclusion: 当感知清晰且仿真器表达能力足够时，VLM引导的优化表现出色，而模型类别限制在更具挑战性的设置中限制了性能。Vid2Sid在保持可解释性的同时实现了竞争性的校准性能。

Abstract: Calibrating a robot simulator's physics parameters (friction, damping, material stiffness) to match real hardware is often done by hand or with black-box optimizers that reduce error but cannot explain which physical discrepancies drive the error. When sensing is limited to external cameras, the problem is further compounded by perception noise and the absence of direct force or state measurements. We present Vid2Sid, a video-driven system identification pipeline that couples foundation-model perception with a VLM-in-the-loop optimizer that analyzes paired sim-real videos, diagnoses concrete mismatches, and proposes physics parameter updates with natural language rationales. We evaluate our approach on a tendon-actuated finger (rigid-body dynamics in MuJoCo) and a deformable continuum tentacle (soft-body dynamics in PyElastica). On sim2real holdout controls unseen during training, Vid2Sid achieves the best average rank across all settings, matching or exceeding black-box optimizers while uniquely providing interpretable reasoning at each iteration. Sim2sim validation confirms that Vid2Sid recovers ground-truth parameters most accurately (mean relative error under 13\% vs. 28--98\%), and ablation analysis reveals three calibration regimes. VLM-guided optimization excels when perception is clean and the simulator is expressive, while model-class limitations bound performance in more challenging settings.

</details>


### [36] [Seeing Farther and Smarter: Value-Guided Multi-Path Reflection for VLM Policy Optimization](https://arxiv.org/abs/2602.19372)
*Yanting Yang,Shenyuan Gao,Qingwen Bu,Li Chen,Dimitris N. Metaxas*

Main category: cs.RO

TL;DR: 提出了一种新的测试时计算框架，将状态评估与动作生成解耦，通过显式建模动作计划的优势并使用可扩展的批评器估计，结合波束搜索探索多个未来路径，显著提升了机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂、长时程的机器人操作任务需要物理交互的深度理解、长期后果的推理和精确的高层规划。现有基于视觉语言模型的反思规划方法存在效率低下、评估单一贪婪未来、推理延迟高等问题。

Method: 提出测试时计算框架，将状态评估与动作生成解耦；显式建模动作计划的优势（通过减少到目标距离来量化）；使用可扩展的批评器进行估计；采用波束搜索探索多个未来路径并在解码时聚合以建模期望长期回报；引入基于置信度的轻量级触发机制，仅在必要时进行反思。

Result: 在多样化的未见多阶段机器人操作任务上，相比最先进的基线方法，成功率提升了24.6%，同时推理时间显著减少了56.5%。

Conclusion: 该方法通过解耦状态评估与动作生成、显式建模动作优势、多路径探索和智能触发机制，有效解决了现有反思规划方法的局限性，在机器人操作任务中实现了更高的成功率和更低的推理延迟。

Abstract: Solving complex, long-horizon robotic manipulation tasks requires a deep understanding of physical interactions, reasoning about their long-term consequences, and precise high-level planning. Vision-Language Models (VLMs) offer a general perceive-reason-act framework for this goal. However, previous approaches using reflective planning to guide VLMs in correcting actions encounter significant limitations. These methods rely on inefficient and often inaccurate implicit learning of state-values from noisy foresight predictions, evaluate only a single greedy future, and suffer from substantial inference latency. To address these limitations, we propose a novel test-time computation framework that decouples state evaluation from action generation. This provides a more direct and fine-grained supervisory signal for robust decision-making. Our method explicitly models the advantage of an action plan, quantified by its reduction in distance to the goal, and uses a scalable critic to estimate. To address the stochastic nature of single-trajectory evaluation, we employ beam search to explore multiple future paths and aggregate them during decoding to model their expected long-term returns, leading to more robust action generation. Additionally, we introduce a lightweight, confidence-based trigger that allows for early exit when direct predictions are reliable, invoking reflection only when necessary. Extensive experiments on diverse, unseen multi-stage robotic manipulation tasks demonstrate a 24.6% improvement in success rate over state-of-the-art baselines, while significantly reducing inference time by 56.5%.

</details>


### [37] [Hilbert-Augmented Reinforcement Learning for Scalable Multi-Robot Coverage and Exploration](https://arxiv.org/abs/2602.19400)
*Tamil Selvan Gurunathan,Aryya Gangopadhyay*

Main category: cs.RO

TL;DR: 将希尔伯特空间填充先验集成到去中心化多机器人学习与执行中，通过希尔伯特空间索引增强DQN和PPO算法，提高稀疏奖励环境中的探索效率和覆盖率，并在波士顿动力Spot机器人上验证了轨迹生成的有效性。


<details>
  <summary>Details</summary>
Motivation: 在稀疏奖励环境中，多机器人系统面临探索效率低、冗余覆盖严重的问题。传统强化学习方法如DQN和PPO在探索策略上缺乏结构化指导，导致收敛速度慢且覆盖效率不高。需要引入几何先验知识来指导机器人的探索行为。

Method: 1. 将希尔伯特空间填充曲线作为先验知识集成到去中心化多机器人学习框架中；2. 使用希尔伯特空间索引增强DQN和PPO算法，结构化探索过程；3. 开发航点接口，将希尔伯特排序转换为曲率有界、时间参数化的SE(2)轨迹（平面(x, y, θ)）；4. 在资源受限的机器人上实现轨迹执行可行性。

Result: 1. 在多机器人网格覆盖任务中，相比DQN/PPO基线方法，覆盖效率、冗余度和收敛速度均有显著提升；2. 在波士顿动力Spot腿式机器人上的实验验证了该方法在室内环境中的可靠性，实现了低冗余的可靠覆盖；3. 证明了几何先验能够提高群体机器人和腿式机器人的自主性和可扩展性。

Conclusion: 希尔伯特空间填充先验能够有效提高多机器人系统在稀疏奖励环境中的学习效率和覆盖性能。该方法不仅改善了强化学习算法的探索策略，还通过轨迹生成接口实现了在实际机器人平台上的可行执行，为群体机器人和腿式机器人的自主覆盖任务提供了可扩展的解决方案。

Abstract: We present a coverage framework that integrates Hilbert space-filling priors into decentralized multi-robot learning and execution. We augment DQN and PPO with Hilbert-based spatial indices to structure exploration and reduce redundancy in sparse-reward environments, and we evaluate scalability in multi-robot grid coverage. We further describe a waypoint interface that converts Hilbert orderings into curvature-bounded, time-parameterized SE(2) trajectories (planar (x, y, θ)), enabling onboard feasibility on resource-constrained robots. Experiments show improvements in coverage efficiency, redundancy, and convergence speed over DQN/PPO baselines. In addition, we validate the approach on a Boston Dynamics Spot legged robot, executing the generated trajectories in indoor environments and observing reliable coverage with low redundancy. These results indicate that geometric priors improve autonomy and scalability for swarm and legged robotics.

</details>


### [38] [Anticipate, Adapt, Act: A Hybrid Framework for Task Planning](https://arxiv.org/abs/2602.19518)
*Nabanita Dash,Ayush Kaura,Shivam Singh,Ramandeep Singh,Snehasis Banerjee,Mohan Sridharan,K. Madhava Krishna*

Main category: cs.RO

TL;DR: 提出一个混合框架，将LLM的通用预测能力与RDDL的概率序列决策能力相结合，使机器人能够预测和适应人机协作中的潜在失败


<details>
  <summary>Details</summary>
Motivation: 尽管现有AI规划系统和LLM表现优异，但在复杂人机协作中预测和适应失败仍然面临挑战，主要原因是任务及其结果的不确定性

Method: 提出混合框架：结合LLM的通用预测能力和RDDL的概率序列决策能力。机器人能够推理任务和人类能力，预测因能力不足或领域对象缺失导致的失败，并执行预防或恢复行动

Result: 在VirtualHome 3D仿真环境中的实验评估显示，相比现有最先进基线方法，性能有显著提升

Conclusion: 该混合框架通过整合LLM和RDDL，有效提升了机器人在复杂人机协作中预测和适应失败的能力

Abstract: Anticipating and adapting to failures is a key capability robots need to collaborate effectively with humans in complex domains. This continues to be a challenge despite the impressive performance of state of the art AI planning systems and Large Language Models (LLMs) because of the uncertainty associated with the tasks and their outcomes. Toward addressing this challenge, we present a hybrid framework that integrates the generic prediction capabilities of an LLM with the probabilistic sequential decision-making capability of Relational Dynamic Influence Diagram Language. For any given task, the robot reasons about the task and the capabilities of the human attempting to complete it; predicts potential failures due to lack of ability (in the human) or lack of relevant domain objects; and executes actions to prevent such failures or recover from them. Experimental evaluation in the VirtualHome 3D simulation environment demonstrates substantial improvement in performance compared with state of the art baselines.

</details>


### [39] [Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial](https://arxiv.org/abs/2602.19534)
*Yousef Emami,Hao Zhou,Radha Reddy,Atefeh Hajijamali Arani,Biliang Wang,Kai Li,Luis Almeida,Zhu Han*

Main category: cs.RO

TL;DR: 本文系统综述了大型语言模型（LLMs）与无人机（UAVs）技术的融合，提出了一个统一框架，涵盖LLM在无人机系统中的架构、方法和应用，旨在实现更智能、自适应的空中系统。


<details>
  <summary>Details</summary>
Motivation: 无人机因其移动性和灵活性被广泛应用，但传统优化和学习方法在环境理解、集群协调和高级任务推理方面存在局限。LLMs的发展为提升无人机智能提供了变革性机会，使其能够实现更自适应和上下文感知的空中操作。

Method: 提出系统化的LLM-UAV融合框架：1）建立LLM适应无人机技术的分类法，包括预训练、微调、检索增强生成和提示工程；2）分析LLM辅助的无人机通信与操作，涵盖导航、任务规划、集群控制等；3）探讨多模态LLMs在人机交互、感知导航和协同控制中的应用；4）讨论伦理考虑和未来研究方向。

Result: 构建了一个全面的LLM-UAV集成框架，系统整理了现有架构、方法和应用，为智能自适应空中系统奠定了基础。该框架展示了LLMs如何增强无人机的环境理解、集群协调、移动优化和高级任务推理能力。

Conclusion: LLM辅助的无人机代表了智能自适应空中系统的未来发展方向。通过系统整合LLMs与无人机技术，可以实现更高级的环境感知、自主决策和协同操作能力，同时需要关注伦理考虑和人类监督机制。

Abstract: Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and context-aware aerial operations. This survey systematically explores the intersection of LLMs and UAV technologies and proposes a unified framework that consolidates existing architectures, methodologies, and applications for UAVs. We first present a structured taxonomy of LLM adaptation techniques for UAVs, including pretraining, fine-tuning, Retrieval-Augmented Generation (RAG), and prompt engineering, along with key reasoning capabilities such as Chain-of-Thought (CoT) and In-Context Learning (ICL). We then examine LLM-assisted UAV communications and operations, covering navigation, mission planning, swarm control, safety, autonomy, and network management. After that, the survey further discusses Multimodal LLMs (MLLMs) for human-swarm interaction, perception-driven navigation, and collaborative control. Finally, we address ethical considerations, including bias, transparency, accountability, and Human-in-the-Loop (HITL) strategies, and outline future research directions. Overall, this work positions LLM-assisted UAVs as a foundation for intelligent and adaptive aerial systems.

</details>


### [40] [Cost-Aware Diffusion Active Search](https://arxiv.org/abs/2602.19538)
*Arundhati Banerjee,Jeff Schneider*

Main category: cs.RO

TL;DR: 本文提出了一种基于扩散模型的主动搜索方法，通过序列建模能力采样前瞻动作序列，在无需构建完整搜索树的情况下平衡探索与利用，解决了传统树搜索算法的计算效率问题。


<details>
  <summary>Details</summary>
Motivation: 主动搜索需要在未知环境中平衡探索与利用，传统的前瞻算法依赖计算昂贵的搜索树构建和模拟，限制了实际应用效率。扩散模型具有序列建模能力，可以避免构建完整搜索树，但现有扩散强化学习方法在主动搜索中存在乐观偏差问题。

Method: 利用扩散模型的序列建模能力采样前瞻动作序列，平衡探索与利用的权衡。针对主动搜索场景中扩散强化学习方法的乐观偏差问题，提出了缓解解决方案，支持单智能体和多智能体团队的高效成本感知决策。

Result: 提出的算法在离线强化学习中优于标准基线方法，在完全恢复率方面表现更好。在成本感知主动决策中，比树搜索方法计算效率更高。

Conclusion: 扩散模型可以有效地用于主动搜索决策，通过序列建模采样前瞻动作序列，避免了传统树搜索的计算负担，同时解决了现有扩散强化学习方法在主动搜索中的乐观偏差问题，实现了更高效的探索与利用平衡。

Abstract: Active search for recovering objects of interest through online, adaptive decision making with autonomous agents requires trading off exploration of unknown environments with exploitation of prior observations in the search space. Prior work has proposed information gain and Thompson sampling based myopic, greedy approaches for agents to actively decide query or search locations when the number of targets is unknown. Decision making algorithms in such partially observable environments have also shown that agents capable of lookahead over a finite horizon outperform myopic policies for active search. Unfortunately, lookahead algorithms typically rely on building a computationally expensive search tree that is simulated and updated based on the agent's observations and a model of the environment dynamics. Instead, in this work, we leverage the sequence modeling abilities of diffusion models to sample lookahead action sequences that balance the exploration-exploitation trade-off for active search without building an exhaustive search tree. We identify the optimism bias in prior diffusion based reinforcement learning approaches when applied to the active search setting and propose mitigating solutions for efficient cost-aware decision making with both single and multi-agent teams. Our proposed algorithm outperforms standard baselines in offline reinforcement learning in terms of full recovery rate and is computationally more efficient than tree search in cost-aware active decision making.

</details>


### [41] [Chasing Ghosts: A Simulation-to-Real Olfactory Navigation Stack with Optional Vision Augmentation](https://arxiv.org/abs/2602.19577)
*Kordel K. France,Ovidiu Daescu,Latifur Khan,Rohith Peddi*

Main category: cs.RO

TL;DR: 基于无人机的嗅觉导航系统，使用最小传感器套件在线定位气味源，无需外部定位系统或显式气体分布图


<details>
  <summary>Details</summary>
Motivation: 自主气味源定位对空中机器人具有挑战性，现有系统依赖预定义覆盖模式、外部基础设施或大量传感协调，需要更简单有效的解决方案

Method: 开发了完整的开源无人机系统，集成定制嗅觉硬件、机载传感和基于学习的导航策略，在仿真中训练并在真实四旋翼上部署，视觉作为可选补充模态

Result: 在大型室内环境中使用乙醇源进行真实飞行实验验证，在现实气流条件下展示了一致的源定位行为

Conclusion: 提供了一个可复现的系统和方法框架，用于在最小传感假设下进行基于无人机的嗅觉导航和源定位，开源了所有硬件设计和软件代码

Abstract: Autonomous odor source localization remains a challenging problem for aerial robots due to turbulent airflow, sparse and delayed sensory signals, and strict payload and compute constraints. While prior unmanned aerial vehicle (UAV)-based olfaction systems have demonstrated gas distribution mapping or reactive plume tracing, they rely on predefined coverage patterns, external infrastructure, or extensive sensing and coordination. In this work, we present a complete, open-source UAV system for online odor source localization using a minimal sensor suite. The system integrates custom olfaction hardware, onboard sensing, and a learning-based navigation policy trained in simulation and deployed on a real quadrotor. Through our minimal framework, the UAV is able to navigate directly toward an odor source without constructing an explicit gas distribution map or relying on external positioning systems. Vision is incorporated as an optional complementary modality to accelerate navigation under certain conditions. We validate the proposed system through real-world flight experiments in a large indoor environment using an ethanol source, demonstrating consistent source-finding behavior under realistic airflow conditions. The primary contribution of this work is a reproducible system and methodological framework for UAV-based olfactory navigation and source finding under minimal sensing assumptions. We elaborate on our hardware design and open source our UAV firmware, simulation code, olfaction-vision dataset, and circuit board to the community. Code, data, and designs will be made available at https://github.com/KordelFranceTech/ChasingGhosts.

</details>


### [42] [Denoising Particle Filters: Learning State Estimation with Single-Step Objectives](https://arxiv.org/abs/2602.19651)
*Lennart Röstel,Berthold Bäuml*

Main category: cs.RO

TL;DR: 提出了一种基于粒子滤波的新型状态估计算法，通过单独训练状态转移模型来替代端到端序列建模，利用机器人系统的马尔可夫性质，在推理时近似求解贝叶斯滤波方程。


<details>
  <summary>Details</summary>
Motivation: 基于学习的方法通常将机器人状态估计视为序列建模问题，这种方法虽然能最大化端到端性能，但模型难以解释且训练成本高（需要展开时间序列预测）。作者希望找到一种替代端到端训练的方法。

Method: 提出了一种新颖的粒子滤波算法，其中模型从单个状态转移中训练，充分利用机器人系统的马尔可夫性质。测量模型通过最小化去噪分数匹配目标隐式学习。在推理时，使用学习到的去噪器与（学习到的）动力学模型一起，在每个时间步近似求解贝叶斯滤波方程，有效引导预测状态向测量信息的数据流形靠近。

Result: 在具有挑战性的机器人状态估计仿真任务中评估了所提出的方法，展示了与调优的端到端训练基线相比具有竞争力的性能。

Conclusion: 该方法提供了经典滤波算法所期望的可组合性，允许在不重新训练的情况下整合先验信息和外部传感器模型，同时避免了端到端训练的高成本和可解释性问题。

Abstract: Learning-based methods commonly treat state estimation in robotics as a sequence modeling problem. While this paradigm can be effective at maximizing end-to-end performance, models are often difficult to interpret and expensive to train, since training requires unrolling sequences of predictions in time. As an alternative to end-to-end trained state estimation, we propose a novel particle filtering algorithm in which models are trained from individual state transitions, fully exploiting the Markov property in robotic systems. In this framework, measurement models are learned implicitly by minimizing a denoising score matching objective. At inference, the learned denoiser is used alongside a (learned) dynamics model to approximately solve the Bayesian filtering equation at each time step, effectively guiding predicted states toward the data manifold informed by measurements. We evaluate the proposed method on challenging robotic state estimation tasks in simulation, demonstrating competitive performance compared to tuned end-to-end trained baselines. Importantly, our method offers the desirable composability of classical filtering algorithms, allowing prior information and external sensor models to be incorporated without retraining.

</details>


### [43] [Scalable Low-Density Distributed Manipulation Using an Interconnected Actuator Array](https://arxiv.org/abs/2602.19653)
*Bailey Dacre,Rodrigo Moreno,Jørn Lambertsen,Kasper Stoy,Andrés Faíña*

Main category: cs.RO

TL;DR: 该论文提出了一种由模块化3自由度机器人瓦片和柔性表层组成的分布式操纵系统，通过柔性层允许更大的执行器间距，在保持对小物体操纵能力的同时显著降低执行器密度。


<details>
  <summary>Details</summary>
Motivation: 传统分布式操纵系统需要密集的执行器阵列来有效操纵小物体，这增加了系统复杂性和成本。需要一种能够在减少执行器密度的同时仍能有效操纵小物体的解决方案。

Method: 采用模块化3自由度机器人瓦片，通过柔性表层相互连接形成连续可控的操纵表面。柔性层允许增加执行器间距而不影响物体操纵能力。开发了阵列耦合工作空间表征方法和能够将物体移动到N×N阵列内任意位置的操纵策略。

Result: 使用最小的2×2原型进行了实验验证，成功操纵了各种形状和大小的物体。柔性表层显著减少了执行器密度，同时保持了强大的控制能力。

Conclusion: 提出的系统通过柔性表层实现了执行器密度的显著降低，同时保持了对小物体的有效操纵能力。模块化设计和柔性连接为分布式操纵系统提供了一种更高效、成本更低的解决方案。

Abstract: Distributed Manipulator Systems, composed of arrays of robotic actuators necessitate dense actuator arrays to effectively manipulate small objects. This paper presents a system composed of modular 3-DoF robotic tiles interconnected by a compliant surface layer, forming a continuous, controllable manipulation surface. The compliant layer permits increased actuator spacing without compromising object manipulation capabilities, significantly reducing actuator density while maintaining robust control, even for smaller objects. We characterize the coupled workspace of the array and develop a manipulation strategy capable of translating objects to arbitrary positions within an N X N array. The approach is validated experimentally using a minimal 2 X 2 prototype, demonstrating the successful manipulation of objects with varied shapes and sizes.

</details>


### [44] [CACTO-BIC: Scalable Actor-Critic Learning via Biased Sampling and GPU-Accelerated Trajectory Optimization](https://arxiv.org/abs/2602.19699)
*Elisa Alboni,Pietro Noah Crestaz,Elias Fontanari,Andrea Del Prete*

Main category: cs.RO

TL;DR: CACTO-BIC改进了CACTO方法，通过利用局部最优策略值函数的特性进行初始状态采样偏置来提高数据效率，并利用GPU加速减少计算时间，能够扩展到高维系统并适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 轨迹优化(TO)和强化学习(RL)在解决最优控制问题中各具优势：TO能高效计算局部最优解但难以处理非凸问题，RL对非凸问题更鲁棒但计算成本高。CACTO方法结合两者优势，但可扩展性有限，系统复杂度增加会显著提高TO计算成本。

Method: 提出CACTO-BIC方法：1) 利用局部最优策略相关值函数的特性进行初始状态采样偏置，提高数据效率；2) 利用GPU加速减少计算时间；3) 保持CACTO框架，学习引导TO求解器找到低成本轨迹的预热策略。

Result: 实验评估显示：1) 相比CACTO，CACTO-BIC提高了样本效率并加快了计算速度；2) 与PPO相比，能在更短时间内获得相似质量的解；3) 在AlienGO四足机器人上的实验证明该方法能扩展到高维系统并适用于实时应用。

Conclusion: CACTO-BIC通过改进初始状态采样策略和利用GPU加速，有效解决了CACTO的可扩展性限制，能够在高维系统中实现高效计算并适用于实时控制应用，为结合TO和RL优势提供了更实用的解决方案。

Abstract: Trajectory Optimization (TO) and Reinforcement Learning (RL) offer complementary strengths for solving optimal control problems. TO efficiently computes locally optimal solutions but can struggle with non-convexity, while RL is more robust to non-convexity at the cost of significantly higher computational demands. CACTO (Continuous Actor-Critic with Trajectory Optimization) was introduced to combine these advantages by learning a warm-start policy that guides the TO solver towards low-cost trajectories. However, scalability remains a key limitation, as increasing system complexity significantly raises the computational cost of TO. This work introduces CACTO-BIC to address these challenges. CACTO-BIC improves data efficiency by biasing initial-state sampling leveraging a property of the value function associated with locally optimal policies; moreover, it reduces computation time by exploiting GPU acceleration. Empirical evaluations show improved sample efficiency and faster computation compared to CACTO. Comparisons with PPO demonstrate that our approach can achieve similar solutions in less time. Finally, experiments on the AlienGO quadruped robot demonstrate that CACTO-BIC can scale to high-dimensional systems and is suitable for real-time applications.

</details>


### [45] [Towards Dexterous Embodied Manipulation via Deep Multi-Sensory Fusion and Sparse Expert Scaling](https://arxiv.org/abs/2602.19764)
*Yirui Sun,Guangyu Zhuge,Keliang Liu,Jie Gu,Zhihao xia,Qionglin Ren,Chunxu tian,Zhongxue Ga*

Main category: cs.RO

TL;DR: DeMUSE框架通过扩散变换器整合RGB、深度和6轴力传感器，采用自适应模态归一化和稀疏专家混合实现高效多模态融合，在仿真和真实环境中达到83.2%和72.5%的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前以视觉为中心的范式在复杂操作任务中忽视了关键的力和几何反馈，而实现灵巧的具身操作需要深度整合异构多模态感官输入。

Method: 提出DeMUSE框架：1) 使用扩散变换器将RGB、深度和6轴力整合为统一序列化流；2) 采用自适应模态特定归一化重新校准模态感知特征；3) 利用稀疏专家混合增加模型容量；4) 联合去噪目标同步合成环境演化和动作序列。

Result: 在仿真环境中达到83.2%的成功率，在真实世界试验中达到72.5%的成功率，展示了最先进的性能表现。

Conclusion: DeMUSE验证了深度多感官整合对于复杂物理交互的必要性，为具身操作提供了有效的多模态融合解决方案。

Abstract: Realizing dexterous embodied manipulation necessitates the deep integration of heterogeneous multimodal sensory inputs. However, current vision-centric paradigms often overlook the critical force and geometric feedback essential for complex tasks. This paper presents DeMUSE, a Deep Multimodal Unified Sparse Experts framework leveraging a Diffusion Transformer to integrate RGB, depth, and 6-axis force into a unified serialized stream. Adaptive Modality-specific Normalization (AdaMN) is employed to recalibrate modality-aware features, mitigating representation imbalance and harmonizing the heterogeneous distributions of multi-sensory signals. To facilitate efficient scaling, the architecture utilizes a Sparse Mixture-of-Experts (MoE) with shared experts, increasing model capacity for physical priors while maintaining the low inference latency required for real-time control. A Joint denoising objective synchronously synthesizes environmental evolution and action sequences to ensure physical consistency. Achieving success rates of 83.2% and 72.5% in simulation and real-world trials, DeMUSE demonstrates state-of-the-art performance, validating the necessity of deep multi-sensory integration for complex physical interactions.

</details>


### [46] [TactiVerse: Generalizing Multi-Point Tactile Sensing in Soft Robotics Using Single-Point Data](https://arxiv.org/abs/2602.19850)
*Junhui Lee,Hyosung Kim,Saekwang Nam*

Main category: cs.RO

TL;DR: TactiVerse：基于U-Net的软体触觉传感器框架，通过空间热图预测实现单点/多点接触几何估计，显著提升软体机器人触觉感知能力


<details>
  <summary>Details</summary>
Motivation: 软体机器人中高度柔性材料的实时变形预测是重大挑战。现有基于学习的3D接触估计模型严重依赖训练数据集，难以泛化到多点感知等复杂场景

Method: 提出TactiVerse框架，将接触几何估计建模为空间热图预测任务，采用U-Net架构。即使仅用单点压痕的有限数据集训练，也能实现准确感知

Result: 单点感知平均绝对误差0.0589mm（优于传统CNN基线的0.0612mm）；加入多点接触数据训练后，两点辨别平均MAE从1.214mm显著提升至0.383mm

Conclusion: 该方法能从基本交互中推断复杂接触几何，实现多点和大面积形状感知，显著简化基于标记的软体传感器开发，为实际触觉感知提供高度可扩展方案

Abstract: Real-time prediction of deformation in highly compliant soft materials remains a significant challenge in soft robotics. While vision-based soft tactile sensors can track internal marker displacements, learning-based models for 3D contact estimation heavily depend on their training datasets, inherently limiting their ability to generalize to complex scenarios such as multi-point sensing. To address this limitation, we introduce TactiVerse, a U-Net-based framework that formulates contact geometry estimation as a spatial heatmap prediction task. Even when trained exclusively on a limited dataset of single-point indentations, our architecture achieves highly accurate single-point sensing, yielding a superior mean absolute error of 0.0589 mm compared to the 0.0612 mm of a conventional regression-based CNN baseline. Furthermore, we demonstrate that augmenting the training dataset with multi-point contact data substantially enhances the sensor's multi-point sensing capabilities, significantly improving the overall mean MAE for two-point discrimination from 1.214 mm to 0.383 mm. By successfully extrapolating complex contact geometries from fundamental interactions, this methodology unlocks advanced multi-point and large-area shape sensing. Ultimately, it significantly streamlines the development of marker-based soft sensors, offering a highly scalable solution for real-world tactile perception.

</details>


### [47] [Athena: An Autonomous Open-Hardware Tracked Rescue Robot Platform](https://arxiv.org/abs/2602.19898)
*Stefan Fabian,Aljoscha Schmidt,Jonas Süß,Dishant,Aum Oza,Oskar von Stryk*

Main category: cs.RO

TL;DR: Athena是一个开源硬件救援地面机器人研究平台，具有四个独立可重构的履带臂和低成本远程急停解决方案，专为灾难响应和地形导航设计。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应和态势评估中，机器人可以降低救援人员的安全风险。由于任务环境和机器人能力需求差异很大且难以预先知晓，需要异构机器人编队来覆盖广泛的任务需求。无人机可以快速勘察环境但负载能力有限，地面机器人可以携带必要载荷但需要应对困难地形。

Method: 开发了Athena救援地面机器人研究平台，具有四个独立可重构的履带臂（flippers），采用工业聚氨酯皮带和齿形插入件的新型安装方案，允许更换和测试不同的履带轮廓。配备最大伸展距离1.54米的机械臂，以及可靠的低成本远程急停解决方案。

Result: 成功开发了一个完整的开源救援机器人平台，包括完整的CAD和PCB文件以及所有底层软件，作为开源贡献发布。该平台特别适合在具有挑战性的地形中导航，能够操作门、阀门和其他感兴趣的对象。

Conclusion: Athena作为一个开源硬件救援地面机器人平台，通过可重构的履带臂设计和低成本远程急停方案，为灾难响应研究提供了有效的工具，特别适合在困难地形中导航和执行操作任务。

Abstract: In disaster response and situation assessment, robots have great potential in reducing the risks to the safety and health of first responders. As the situations encountered and the required capabilities of the robots deployed in such missions differ wildly and are often not known in advance, heterogeneous fleets of robots are needed to cover a wide range of mission requirements. While UAVs can quickly survey the mission environment, their ability to carry heavy payloads such as sensors and manipulators is limited. UGVs can carry required payloads to assess and manipulate the mission environment, but need to be able to deal with difficult and unstructured terrain such as rubble and stairs. The ability of tracked platforms with articulated arms (flippers) to reconfigure their geometry makes them particularly effective for navigating challenging terrain. In this paper, we present Athena, an open-hardware rescue ground robot research platform with four individually reconfigurable flippers and a reliable low-cost remote emergency stop (E-Stop) solution. A novel mounting solution using an industrial PU belt and tooth inserts allows the replacement and testing of different track profiles. The manipulator with a maximum reach of 1.54m can be used to operate doors, valves, and other objects of interest. Full CAD & PCB files, as well as all low-level software, are released as open-source contributions.

</details>


### [48] [Scaling Law of Neural Koopman Operators](https://arxiv.org/abs/2602.19943)
*Abulikemu Abuduweili,Yuyang Pang,Feihan Li,Changliu Liu*

Main category: cs.RO

TL;DR: 本文为神经Koopman算子理论建立了缩放定律，揭示了样本量、潜在空间维度与控制质量之间的关系，并提出了两种轻量级正则化方法来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的神经Koopman算子理论已成为线性化和控制非线性机器人系统的强大工具，但其性能受样本量与模型维度之间权衡的影响，这种关系的缩放定律一直不明确。

Method: 1. 推导Koopman近似误差的理论上界，将其分解为采样误差和投影误差；2. 基于理论结果引入两种轻量级正则化器：协方差损失用于稳定学习到的潜在特征，逆控制损失确保模型与物理驱动对齐；3. 在六个机器人环境中进行系统实验验证。

Result: 实验结果表明：1. 模型拟合误差遵循推导出的缩放定律；2. 正则化器提高了动态模型拟合保真度；3. 增强了闭环控制性能。

Conclusion: 研究结果为学习Koopman动力学控制时，在数据收集和模型容量之间的努力分配提供了简单指导方案。

Abstract: Data-driven neural Koopman operator theory has emerged as a powerful tool for linearizing and controlling nonlinear robotic systems. However, the performance of these data-driven models fundamentally depends on the trade-off between sample size and model dimensions, a relationship for which the scaling laws have remained unclear. This paper establishes a rigorous framework to address this challenge by deriving and empirically validating scaling laws that connect sample size, latent space dimension, and downstream control quality. We derive a theoretical upper bound on the Koopman approximation error, explicitly decomposing it into sampling error and projection error. We show that these terms decay at specific rates relative to dataset size and latent dimension, providing a rigorous basis for the scaling law. Based on the theoretical results, we introduce two lightweight regularizers for the neural Koopman operator: a covariance loss to help stabilize the learned latent features and an inverse control loss to ensure the model aligns with physical actuation. The results from systematic experiments across six robotic environments confirm that model fitting error follows the derived scaling laws, and the regularizers improve dynamic model fitting fidelity, with enhanced closed-loop control performance. Together, our results provide a simple recipe for allocating effort between data collection and model capacity when learning Koopman dynamics for control.

</details>


### [49] [Contextual Safety Reasoning and Grounding for Open-World Robots](https://arxiv.org/abs/2602.19983)
*Zachary Ravichadran,David Snyder,Alexander Robey,Hamed Hassani,Vijay Kumar,George J. Pappas*

Main category: cs.RO

TL;DR: CORE是一个安全框架，通过视觉语言模型在线推理上下文相关的安全规则，无需环境先验知识，在开放世界中实现上下文感知的安全行为


<details>
  <summary>Details</summary>
Motivation: 机器人在开放世界环境中运行时，安全行为高度依赖上下文（如人群密度、紧急情况等）。传统安全方法在用户指定的固定上下文中强制执行约束，无法处理现实世界部署中的开放上下文变化性

Method: CORE使用视觉语言模型直接从视觉观察中持续推理上下文相关的安全规则，将这些规则在物理环境中进行空间定位，并通过控制屏障函数强制执行由此产生的空间定义的安全集

Result: CORE在未见过的环境中强制执行上下文适当的行为，显著优于缺乏在线上下文推理的先前语义安全方法。消融研究验证了理论保证，并强调了VLM推理和空间定位在强制执行上下文安全中的重要性

Conclusion: CORE框架通过在线上下文推理、定位和执行，解决了开放世界环境中机器人安全行为的上下文依赖性问题，为处理现实世界部署中的开放上下文变化性提供了有效解决方案

Abstract: Robots are increasingly operating in open-world environments where safe behavior depends on context: the same hallway may require different navigation strategies when crowded versus empty, or during an emergency versus normal operations. Traditional safety approaches enforce fixed constraints in user-specified contexts, limiting their ability to handle the open-ended contextual variability of real-world deployment. We address this gap via CORE, a safety framework that enables online contextual reasoning, grounding, and enforcement without prior knowledge of the environment (e.g., maps or safety specifications). CORE uses a vision-language model (VLM) to continuously reason about context-dependent safety rules directly from visual observations, grounds these rules in the physical environment, and enforces the resulting spatially-defined safe sets via control barrier functions. We provide probabilistic safety guarantees for CORE that account for perceptual uncertainty, and we demonstrate through simulation and real-world experiments that CORE enforces contextually appropriate behavior in unseen environments, significantly outperforming prior semantic safety methods that lack online contextual reasoning. Ablation studies validate our theoretical guarantees and underscore the importance of both VLM-based reasoning and spatial grounding for enforcing contextual safety in novel settings. We provide additional resources at https://zacravichandran.github.io/CORE.

</details>


### [50] [Hydrodynamic Performance Enhancement of Unmanned Underwater Gliders with Soft Robotic Morphing Wings for Agility Improvement](https://arxiv.org/abs/2602.20054)
*A. Giordano,G. De Meurichy,V. Telazzi,C. Mucignat,I. Lunati,D. A. L. M. Louchard,M. Iovieno,S. F. Armanini,M. Kovac*

Main category: cs.RO

TL;DR: 软变形机翼相比传统刚性机翼可为水下无人航行器带来9.75%的整体效率提升


<details>
  <summary>Details</summary>
Motivation: 评估软变形机翼在水下无人航行器中的水动力效率，相比传统刚性机翼，软变形机翼能够按需改变其空气动力学特性，提高效率可延长航行器作业范围并决定任务可行性

Method: 对软变形机翼及搭载该机翼的水下无人航行器进行了结构和计算流体动力学模拟，与等效的传统刚性机翼系统进行对比

Result: 采用软机翼的水下无人航行器比采用传统刚性机翼的等效航行器整体效率提高9.75%

Conclusion: 软机器人技术有潜力显著提升水下航行器性能，特别是在需要压力无关操作的应用中

Abstract: This work assesses the hydrodynamic efficiency of Underwater Unmanned Vehicles (UUVs) equipped with soft morphing wings compared to conventional rigid wings. Unlike rigid wings, deformable counterparts can alter their aerodynamic properties on demand. Improvements in hydrodynamic efficiency extend a UUV's operational range and may determine mission feasibility. Structural and Computational Fluid Dynamics (CFD) simulations were conducted for both a soft morphing wing and a UUV incorporating it. The results show that a UUV employing soft wings achieves 9.75 percent higher overall efficiency than an equivalent vehicle with traditional rigid wings. These findings confirm the potential of soft robotics to enhance underwater vehicle performance, particularly in applications requiring pressure-agnostic operation.

</details>


### [51] [To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation](https://arxiv.org/abs/2602.20055)
*Apoorva Vashisth,Manav Kulshrestha,Pranav Bakshi,Damon Conover,Guillaume Sartoretti,Aniket Bera*

Main category: cs.RO

TL;DR: 论文提出了一种终身交互式导航问题，让具有操作能力的移动机器人能够移动杂物来开辟路径，以完成顺序物体放置任务。作者提出了一个基于LLM的约束规划框架，结合主动感知来解决环境变化累积的长期效应。


<details>
  <summary>Details</summary>
Motivation: 传统视觉导航假设起点和目标之间存在至少一条无障碍路径，但在现实场景（如家庭环境和仓库）中，杂物可能阻塞所有路线。针对这种情况，需要机器人具备移动杂物来开辟路径的能力，以完成顺序物体放置任务。

Method: 提出了一个LLM驱动的约束规划框架，结合主动感知。LLM在结构化场景图上进行推理，决定移动哪个物体、放置到哪里以及下一步查看哪里以发现任务相关信息。标准运动规划器执行相应的导航-拾取-放置或绕行序列。

Result: 在物理模拟器ProcTHOR-10k中评估，该方法优于非学习和学习基线方法。还在真实硬件上进行了定性演示，验证了方法的有效性。

Conclusion: 提出的终身交互式导航框架使机器人能够在杂物阻塞的环境中通过移动物体来开辟路径，完成顺序物体放置任务。LLM驱动的推理与主动感知相结合，使机器人能够探索对任务完成有贡献的区域，而不是穷尽地映射整个环境。

Abstract: Visual navigation typically assumes the existence of at least one obstacle-free path between start and goal, which must be discovered/planned by the robot. However, in real-world scenarios, such as home environments and warehouses, clutter can block all routes. Targeted at such cases, we introduce the Lifelong Interactive Navigation problem, where a mobile robot with manipulation abilities can move clutter to forge its own path to complete sequential object- placement tasks - each involving placing an given object (eg. Alarm clock, Pillow) onto a target object (eg. Dining table, Desk, Bed). To address this lifelong setting - where effects of environment changes accumulate and have long-term effects - we propose an LLM-driven, constraint-based planning framework with active perception. Our framework allows the LLM to reason over a structured scene graph of discovered objects and obstacles, deciding which object to move, where to place it, and where to look next to discover task-relevant information. This coupling of reasoning and active perception allows the agent to explore the regions expected to contribute to task completion rather than exhaustively mapping the environment. A standard motion planner then executes the corresponding navigate-pick-place, or detour sequence, ensuring reliable low-level control. Evaluated in physics-enabled ProcTHOR-10k simulator, our approach outperforms non-learning and learning-based baselines. We further demonstrate our approach qualitatively on real-world hardware.

</details>


### [52] [AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation](https://arxiv.org/abs/2602.20057)
*Ge Yuan,Qiyuan Qiao,Jing Zhang,Dong Xu*

Main category: cs.RO

TL;DR: AdaWorldPolicy是一个结合世界模型和扩散策略的机器人操作框架，通过在线自适应学习和力-扭矩反馈来增强动态环境下的操作能力。


<details>
  <summary>Details</summary>
Motivation: 机器人操作需要能够预测物理结果并适应真实环境的策略。现有方法在动态条件下需要大量人工干预，难以应对视觉和物理领域的偏移。

Method: 提出AdaWorldPolicy框架，包含三个模块：世界模型、动作专家和力预测器，均采用Flow Matching Diffusion Transformers实现。通过多模态自注意力层连接，提出在线自适应学习策略，在动作生成模式和未来想象模式间动态切换。

Result: 在模拟和真实机器人基准测试中，AdaWorldPolicy取得了最先进的性能，对分布外场景具有动态适应能力。

Conclusion: 世界模型提供强监督信号，结合在线自适应学习和力-扭矩反馈，能够有效增强机器人操作在动态环境中的适应能力，减少人工干预需求。

Abstract: Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. In this work, we introduce a unified framework, World-Model-Driven Diffusion Policy with Online Adaptive Learning (AdaWorldPolicy) to enhance robotic manipulation under dynamic conditions with minimal human involvement. Our core insight is that world models provide strong supervision signals, enabling online adaptive learning in dynamic environments, which can be complemented by force-torque feedback to mitigate dynamic force shifts. Our AdaWorldPolicy integrates a world model, an action expert, and a force predictor-all implemented as interconnected Flow Matching Diffusion Transformers (DiT). They are interconnected via the multi-modal self-attention layers, enabling deep feature exchange for joint learning while preserving their distinct modularity characteristics. We further propose a novel Online Adaptive Learning (AdaOL) strategy that dynamically switches between an Action Generation mode and a Future Imagination mode to drive reactive updates across all three modules. This creates a powerful closed-loop mechanism that adapts to both visual and physical domain shifts with minimal overhead. Across a suite of simulated and real-robot benchmarks, our AdaWorldPolicy achieves state-of-the-art performance, with dynamical adaptive capacity to out-of-distribution scenarios.

</details>


### [53] [NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning](https://arxiv.org/abs/2602.20119)
*Jiahui Fu,Junyu Nan,Lingfeng Sun,Hongyu Li,Jianing Qian,Jennifer L. Barry,Kris Kitani,George Konidaris*

Main category: cs.RO

TL;DR: NovaPlan是一个分层框架，结合了视觉语言模型规划、视频生成和几何基础机器人执行，用于零样本长时程操作任务。


<details>
  <summary>Details</summary>
Motivation: 解决长时程任务需要机器人整合高层语义推理和低层物理交互。现有的视觉语言模型和视频生成模型虽然能分解任务和想象结果，但缺乏真实世界执行所需的物理基础。

Method: 采用分层框架：高层使用视觉语言模型规划器分解任务为子目标并闭环监控执行；低层从生成视频中提取任务相关物体关键点和人手姿态作为运动学先验，通过切换机制选择更好的参考来计算机器人动作。

Result: 在三个长时程任务和功能操作基准测试中，NovaPlan能够执行复杂装配任务并展现灵巧的错误恢复行为，无需任何先验演示或训练。

Conclusion: NovaPlan通过统一闭环视觉语言模型规划、视频规划和几何基础机器人执行，实现了零样本长时程操作，展示了在复杂任务中的有效性和鲁棒性。

Abstract: Solving long-horizon tasks requires robots to integrate high-level semantic reasoning with low-level physical interaction. While vision-language models (VLMs) and video generation models can decompose tasks and imagine outcomes, they often lack the physical grounding necessary for real-world execution. We introduce NovaPlan, a hierarchical framework that unifies closed-loop VLM and video planning with geometrically grounded robot execution for zero-shot long-horizon manipulation. At the high level, a VLM planner decomposes tasks into sub-goals and monitors robot execution in a closed loop, enabling the system to recover from single-step failures through autonomous re-planning. To compute low-level robot actions, we extract and utilize both task-relevant object keypoints and human hand poses as kinematic priors from the generated videos, and employ a switching mechanism to choose the better one as a reference for robot actions, maintaining stable execution even under heavy occlusion or depth inaccuracy. We demonstrate the effectiveness of NovaPlan on three long-horizon tasks and the Functional Manipulation Benchmark (FMB). Our results show that NovaPlan can perform complex assembly tasks and exhibit dexterous error recovery behaviors without any prior demonstrations or training. Project page: https://nova-plan.github.io/

</details>


### [54] [Simulation-Ready Cluttered Scene Estimation via Physics-aware Joint Shape and Pose Optimization](https://arxiv.org/abs/2602.20150)
*Wei-Cheng Huang,Jiaheng Han,Xiaohan Ye,Zherong Pan,Kris Hauser*

Main category: cs.RO

TL;DR: 提出了一种基于优化的统一框架，用于从真实世界观测中估计仿真就绪的场景，能够联合恢复多个刚性物体的形状和姿态，并满足物理约束。


<details>
  <summary>Details</summary>
Motivation: 现有方法在杂乱环境中存在计算成本高、鲁棒性差、扩展到多物体交互时泛化能力受限等问题，而准确估计仿真就绪场景对于下游规划和策略学习任务至关重要。

Method: 采用基于优化的统一框架，结合两个关键技术：1）利用全局可微的接触模型进行物体几何和姿态的联合优化；2）利用增广拉格朗日海森矩阵的结构稀疏性开发高效线性系统求解器。构建端到端流水线，包括基于学习的物体初始化、物理约束的联合形状-姿态优化和可微纹理细化。

Result: 在包含最多5个物体和22个凸包的杂乱场景实验中，该方法能够鲁棒地重建物理有效、仿真就绪的物体形状和姿态。

Conclusion: 该方法为解决杂乱环境中的真实到仿真场景估计问题提供了一个高效、鲁棒且可扩展的解决方案，能够生成物理有效的仿真就绪场景。

Abstract: Estimating simulation-ready scenes from real-world observations is crucial for downstream planning and policy learning tasks. Regretfully, existing methods struggle in cluttered environments, often exhibiting prohibitive computational cost, poor robustness, and restricted generality when scaling to multiple interacting objects. We propose a unified optimization-based formulation for real-to-sim scene estimation that jointly recovers the shapes and poses of multiple rigid objects under physical constraints. Our method is built on two key technical innovations. First, we leverage the recently introduced shape-differentiable contact model, whose global differentiability permits joint optimization over object geometry and pose while modeling inter-object contacts. Second, we exploit the structured sparsity of the augmented Lagrangian Hessian to derive an efficient linear system solver whose computational cost scales favorably with scene complexity. Building on this formulation, we develop an end-to-end real-to-sim scene estimation pipeline that integrates learning-based object initialization, physics-constrained joint shape-pose optimization, and differentiable texture refinement. Experiments on cluttered scenes with up to 5 objects and 22 convex hulls demonstrate that our approach robustly reconstructs physically valid, simulation-ready object shapes and poses.

</details>
