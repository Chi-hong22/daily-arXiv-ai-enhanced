<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 95]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.LG](#cs.LG) [Total: 67]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.HC](#cs.HC) [Total: 16]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.RO](#cs.RO) [Total: 38]
- [eess.SY](#eess.SY) [Total: 20]
- [cs.SD](#cs.SD) [Total: 5]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Post-Disaster Affected Area Segmentation with a Vision Transformer (ViT)-based EVAP Model using Sentinel-2 and Formosat-5 Imagery](https://arxiv.org/abs/2507.16849)
*Yi-Shan Chu,Hsuan-Cheng Wei*

Main category: cs.CV

TL;DR: 提出基于视觉变换器(ViT)的深度学习框架，用于改进遥感影像中灾害影响区域分割，通过弱监督学习和多波段输入支持台湾太空署的紧急增值产品开发


<details>
  <summary>Details</summary>
Motivation: 现有灾害区域分割方法在准确标注数据有限的情况下性能不佳，需要开发一种可扩展的方法来支持和增强台湾太空署的紧急增值产品(EVAP)，在缺乏精确真值标签时仍能实现可靠的灾害制图

Method: 1) 从少量手动标注区域开始；2) 应用基于主成分分析(PCA)的特征空间分析并构建置信度指数(CI)来扩展标签，生成弱监督训练集；3) 使用扩展标签训练基于ViT的编码器-解码器模型，支持Sentinel-2和Formosat-5影像的多波段输入；4) 架构支持多种解码器变体和多阶段损失策略以在有限监督下提升性能

Result: 在2022年鄱阳湖干旱和2023年罗德岛野火案例研究中，该框架改善了分割结果的平滑性和可靠性。模型预测与高分辨率EVAP输出比较显示良好的空间一致性和分割连贯性

Conclusion: 提出的ViT框架为灾害制图提供了一种可扩展的方法，在缺乏精确真值标签的情况下仍能实现可靠的灾害影响区域分割，有效支持紧急响应和灾害监测应用

Abstract: We propose a vision transformer (ViT)-based deep learning framework to refine
disaster-affected area segmentation from remote sensing imagery, aiming to
support and enhance the Emergent Value Added Product (EVAP) developed by the
Taiwan Space Agency (TASA). The process starts with a small set of manually
annotated regions. We then apply principal component analysis (PCA)-based
feature space analysis and construct a confidence index (CI) to expand these
labels, producing a weakly supervised training set. These expanded labels are
then used to train ViT-based encoder-decoder models with multi-band inputs from
Sentinel-2 and Formosat-5 imagery. Our architecture supports multiple decoder
variants and multi-stage loss strategies to improve performance under limited
supervision. During the evaluation, model predictions are compared with
higher-resolution EVAP output to assess spatial coherence and segmentation
consistency. Case studies on the 2022 Poyang Lake drought and the 2023 Rhodes
wildfire demonstrate that our framework improves the smoothness and reliability
of segmentation results, offering a scalable approach for disaster mapping when
accurate ground truth is unavailable.

</details>


### [2] [Coarse-to-fine crack cue for robust crack detection](https://arxiv.org/abs/2507.16851)
*Zelong Liu,Yuliang Gu,Zhichao Sun,Huachao Zhu,Xin Xiao,Bo Du,Laurent Najman,Yongchao Xu*

Main category: cs.CV

TL;DR: 本文提出CrackCue方法，通过粗到细的裂缝线索生成来提升深度学习裂缝检测模型的跨域泛化能力和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 深度学习裂缝检测方法虽然在数据集内表现优异，但在跨域泛化方面仍存在困难，且以往方法往往忽略了裂缝的细长结构特性

Method: 提出CrackCue方法：首先通过最大池化和上采样操作获得粗糙的无裂缝背景，然后利用重建网络生成精细的无裂缝背景，原图与精细背景的差值形成包含鲁棒先验信息的精细裂缝线索，该线索不受复杂背景、阴影和光照变化影响

Result: 将CrackCue作为即插即用模块集成到三个先进的裂缝检测网络中，实验结果表明该方法显著提升了基线方法的泛化能力和鲁棒性

Conclusion: CrackCue通过充分利用裂缝的细长结构特性，生成鲁棒的裂缝线索来指导检测，有效提升了深度学习裂缝检测方法的跨域性能，且具有良好的通用性

Abstract: Crack detection is an important task in computer vision. Despite impressive
in-dataset performance, deep learning-based methods still struggle in
generalizing to unseen domains. The thin structure property of cracks is
usually overlooked by previous methods. In this work, we introduce CrackCue, a
novel method for robust crack detection based on coarse-to-fine crack cue
generation. The core concept lies on leveraging the thin structure property to
generate a robust crack cue, guiding the crack detection. Specifically, we
first employ a simple max-pooling and upsampling operation on the crack image.
This results in a coarse crack-free background, based on which a fine
crack-free background can be obtained via a reconstruction network. The
difference between the original image and fine crack-free background provides a
fine crack cue. This fine cue embeds robust crack prior information which is
unaffected by complex backgrounds, shadow, and varied lighting. As a
plug-and-play method, we incorporate the proposed CrackCue into three advanced
crack detection networks. Extensive experimental results demonstrate that the
proposed CrackCue significantly improves the generalization ability and
robustness of the baseline methods. The source code will be publicly available.

</details>


### [3] [Toward a Real-Time Framework for Accurate Monocular 3D Human Pose Estimation with Geometric Priors](https://arxiv.org/abs/2507.16850)
*Mohamed Adjel*

Main category: cs.CV

TL;DR: 提出了一个结合实时2D关键点检测和几何感知2D-to-3D提升的框架，利用相机内参和解剖学先验知识进行单目3D人体姿态估计，旨在实现快速、个性化且准确的边缘设备3D人体动作捕捉。


<details>
  <summary>Details</summary>
Motivation: 单目3D人体姿态估计仍然是一个具有挑战性的病态问题，特别是在实时设置和无约束环境中。直接的图像到3D方法需要大量标注数据集和重型模型，而2D-to-3D提升方法提供了更轻量化和灵活的替代方案，特别是在结合先验知识时。

Method: 提出了一个结合实时2D关键点检测与几何感知2D-to-3D提升的框架，明确利用已知的相机内参和特定主体的解剖学先验。该方法基于自校准和生物力学约束逆运动学的最新进展，从MoCap和合成数据集生成大规模、合理的2D-3D训练对。

Result: 该方法能够实现快速、个性化且准确的单目图像3D姿态估计，无需专门硬件，可在边缘设备上进行野外3D人体动作捕捉。

Conclusion: 通过桥接数据驱动学习和基于模型的先验知识，可以提高3D人体动作捕捉在边缘设备野外应用中的准确性、可解释性和可部署性。该提案旨在促进相关讨论。

Abstract: Monocular 3D human pose estimation remains a challenging and ill-posed
problem, particularly in real-time settings and unconstrained environments.
While direct imageto-3D approaches require large annotated datasets and heavy
models, 2D-to-3D lifting offers a more lightweight and flexible
alternative-especially when enhanced with prior knowledge. In this work, we
propose a framework that combines real-time 2D keypoint detection with
geometry-aware 2D-to-3D lifting, explicitly leveraging known camera intrinsics
and subject-specific anatomical priors. Our approach builds on recent advances
in self-calibration and biomechanically-constrained inverse kinematics to
generate large-scale, plausible 2D-3D training pairs from MoCap and synthetic
datasets. We discuss how these ingredients can enable fast, personalized, and
accurate 3D pose estimation from monocular images without requiring specialized
hardware. This proposal aims to foster discussion on bridging data-driven
learning and model-based priors to improve accuracy, interpretability, and
deployability of 3D human motion capture on edge devices in the wild.

</details>


### [4] [CLAMP: Contrastive Learning with Adaptive Multi-loss and Progressive Fusion for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.16854)
*Xiaoqiang He*

Main category: cs.CV

TL;DR: 本文提出CLAMP框架，通过渐进式注意力融合、多任务对比学习和自适应多损失聚合来解决多模态方面级情感分析中的跨模态对齐噪声和细粒度表示一致性不足问题


<details>
  <summary>Details</summary>
Motivation: 现有多模态方面级情感分析方法面临跨模态对齐噪声和细粒度表示一致性不足的挑战，全局模态对齐方法常忽略方面词与对应局部视觉区域的连接，文本和图像表示差距仍需解决

Method: 提出端到端对比学习框架CLAMP，包含三个核心模块：1)渐进式注意力融合网络通过分层多阶段跨模态交互增强文本特征与图像区域的细粒度对齐；2)多任务对比学习结合全局模态对比和局部粒度对齐提升跨模态表示一致性；3)自适应多损失聚合采用基于动态不确定性的权重机制校准损失贡献

Result: 在标准公开基准数据集上的评估表明，CLAMP持续优于绝大多数现有最先进方法

Conclusion: CLAMP框架通过渐进式注意力融合、多任务对比学习和自适应损失聚合有效解决了多模态方面级情感分析中的关键挑战，在标准基准上取得了优于现有方法的性能表现

Abstract: Multimodal aspect-based sentiment analysis(MABSA) seeks to identify aspect
terms within paired image-text data and determine their fine grained sentiment
polarities, representing a fundamental task for improving the effectiveness of
applications such as product review systems and public opinion monitoring.
Existing methods face challenges such as cross modal alignment noise and
insufficient consistency in fine-grained representations. While global modality
alignment methods often overlook the connection between aspect terms and their
corresponding local visual regions, bridging the representation gap between
text and images remains a challenge. To address these limitations, this paper
introduces an end to end Contrastive Learning framework with Adaptive
Multi-loss and Progressive Attention Fusion(CLAMP). The framework is composed
of three novel modules: Progressive Attention Fusion network, Multi-task
Contrastive Learning, and Adaptive Multi-loss Aggregation. The Progressive
Attention Fusion network enhances fine-grained alignment between textual
features and image regions via hierarchical, multi-stage cross modal
interactions, effectively suppressing irrelevant visual noise. Secondly,
multi-task contrastive learning combines global modal contrast and local
granularity alignment to enhance cross modal representation consistency.
Adaptive Multi-loss Aggregation employs a dynamic uncertainty based weighting
mechanism to calibrate loss contributions according to each task's uncertainty,
thereby mitigating gradient interference. Evaluation on standard public
benchmarks demonstrates that CLAMP consistently outperforms the vast majority
of existing state of the art methods.

</details>


### [5] [SIA: Enhancing Safety via Intent Awareness for Vision-Language Models](https://arxiv.org/abs/2507.16856)
*Youngjin Na,Sangheon Jeong,Youngwan Lee*

Main category: cs.CV

TL;DR: 本文提出SIA（Safety via Intent Awareness）框架，通过三阶段推理过程（视觉抽象、意图推理、意图条件响应优化）来检测和缓解视觉-语言模型中的潜在有害意图，在多个安全基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言模型在现实应用中的部署，图像和文本的微妙交互产生了新的安全风险。看似无害的输入组合可能揭示有害意图，导致不安全的模型响应。现有的基于后验过滤或静态拒绝提示的方法难以检测这种潜在风险，特别是当危害性仅从输入组合中显现时。

Method: 提出SIA（Safety via Intent Awareness）框架，这是一个无需训练的提示工程框架，采用三阶段推理过程：(1)通过字幕生成进行视觉抽象，(2)通过少样本思维链提示进行意图推理，(3)基于意图的响应优化。SIA不依赖预定义规则或分类器，而是动态适应从图像-文本对中推断出的隐含意图。

Result: 在SIUO、MM-SafetyBench和HoliSafe等安全关键基准测试上进行了广泛实验，证明SIA实现了显著的安全性改进，性能优于先前方法。虽然SIA在MMStar的一般推理准确性上有轻微下降，但相应的安全性收益突显了意图感知推理的价值。

Conclusion: SIA框架通过意图感知推理有效提升了视觉-语言模型的安全性，能够检测和缓解多模态输入中的有害意图。尽管在一般推理任务上有轻微性能损失，但安全性的显著提升证明了该方法在使VLM与人类价值观保持一致方面的重要价值。

Abstract: As vision-language models (VLMs) are increasingly deployed in real-world
applications, new safety risks arise from the subtle interplay between images
and text. In particular, seemingly innocuous inputs can combine to reveal
harmful intent, leading to unsafe model responses. Despite increasing attention
to multimodal safety, previous approaches based on post hoc filtering or static
refusal prompts struggle to detect such latent risks, especially when
harmfulness emerges only from the combination of inputs. We propose SIA (Safety
via Intent Awareness), a training-free prompt engineering framework that
proactively detects and mitigates harmful intent in multimodal inputs. SIA
employs a three-stage reasoning process: (1) visual abstraction via captioning,
(2) intent inference through few-shot chain-of-thought prompting, and (3)
intent-conditioned response refinement. Rather than relying on predefined rules
or classifiers, SIA dynamically adapts to the implicit intent inferred from the
image-text pair. Through extensive experiments on safety-critical benchmarks
including SIUO, MM-SafetyBench, and HoliSafe, we demonstrate that SIA achieves
substantial safety improvements, outperforming prior methods. Although SIA
shows a minor reduction in general reasoning accuracy on MMStar, the
corresponding safety gains highlight the value of intent-aware reasoning in
aligning VLMs with human-centric values.

</details>


### [6] [Look Before You Fuse: 2D-Guided Cross-Modal Alignment for Robust 3D Detection](https://arxiv.org/abs/2507.16861)
*Xiang Li*

Main category: cs.CV

TL;DR: 本文提出一种解决LiDAR和相机融合中特征错位问题的方法，通过2D目标先验引导的深度校准、不连续感知几何融合和结构引导深度调制器，在nuScenes数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前LiDAR和相机融合方法存在特征错位问题，导致相机分支深度监督不准确和跨模态特征聚合错误。错位的根本原因是投影误差，源于外参标定不准确和车辆运动时LiDAR的滚动快门效应。作者发现这些投影误差主要集中在目标-背景边界处，可通过2D检测器识别，因此提出利用2D目标先验来预对齐跨模态特征。

Method: 提出三个核心组件：1) Prior Guided Depth Calibration (PGDC) - 利用2D先验校正局部错位并保持正确的跨模态特征对；2) Discontinuity Aware Geometric Fusion (DAGF) - 处理PGDC校准结果，抑制噪声并显式增强目标-背景边界的尖锐过渡；3) Structural Guidance Depth Modulator (SGDM) - 使用门控注意力机制有效融合对齐的深度和图像特征。

Result: 在nuScenes验证数据集上达到最先进性能，mAP达到71.5%，NDS达到73.6%。

Conclusion: 通过识别投影误差主要集中在目标-背景边界的关键洞察，成功利用2D目标先验解决了LiDAR-相机融合中的特征错位问题，显著提升了自动驾驶车辆的3D感知能力。

Abstract: Integrating LiDAR and camera inputs into a unified Bird's-Eye-View (BEV)
representation is crucial for enhancing 3D perception capabilities of
autonomous vehicles. However, current methods are often affected by
misalignment between camera and LiDAR features. This misalignment leads to
inaccurate depth supervision in camera branch and erroneous fusion during
cross-modal feature aggregation. The root cause of this misalignment lies in
projection errors, stemming from minor extrinsic calibration inaccuracies and
rolling shutter effect of LiDAR during vehicle motion. In this work, our key
insight is that these projection errors are predominantly concentrated at
object-background boundaries, which are readily identified by 2D detectors.
Based on this, our main motivation is to utilize 2D object priors to pre-align
cross-modal features before fusion. To address local misalignment, we propose
Prior Guided Depth Calibration (PGDC), which leverages 2D priors to correct
local misalignment and preserve correct cross-modal feature pairs. To resolve
global misalignment, we introduce Discontinuity Aware Geometric Fusion (DAGF)
to process calibrated results from PGDC, suppressing noise and explicitly
enhancing sharp transitions at object-background boundaries. To effectively
utilize these transition-aware depth representations, we incorporate Structural
Guidance Depth Modulator (SGDM), using a gated attention mechanism to
efficiently fuse aligned depth and image features. Our proposed method achieves
state-of-the-art performance on nuScenes validation dataset, with its mAP and
NDS reaching 71.5% and 73.6% respectively.

</details>


### [7] [AURA: A Multi-Modal Medical Agent for Understanding, Reasoning & Annotation](https://arxiv.org/abs/2507.16940)
*Nima Fathi,Amar Kumar,Tal Arbel*

Main category: cs.CV

TL;DR: 本文介绍了AURA，首个专门用于医学图像分析、解释和评估的视觉语言可解释性智能体，通过动态交互、上下文解释和假设验证，将医学图像分析从静态预测转变为交互式决策支持系统。


<details>
  <summary>Details</summary>
Motivation: 大语言模型催生了从静态预测系统向智能体AI的范式转变，但在医学影像领域的应用仍处于起步阶段。现有医学图像分析系统缺乏透明度、适应性和临床对齐性，需要一个能够进行动态交互、提供上下文解释并支持假设验证的智能体系统。

Method: 基于Qwen-32B大语言模型架构，AURA集成了模块化工具箱，包括：(1)分割套件，具备阶段定位、病理分割和解剖分割功能；(2)反事实图像生成模块，支持通过图像级解释进行推理；(3)评估工具集，包括像素级差异图分析、分类和先进的最新技术组件，用于评估诊断相关性和视觉可解释性。

Result: AURA实现了医学图像的综合分析、解释和评估，能够定位临床意义区域、生成反事实图像进行推理分析，并提供多维度的评估工具来评估诊断相关性和视觉可解释性，展现了智能体AI在医学影像领域的应用前景。

Conclusion: AURA代表了向更透明、适应性更强且与临床更好对齐的AI系统的重大进步，突出了智能体AI将医学图像分析从静态预测转变为交互式决策支持的巨大潜力，为医学影像AI的发展开辟了新的方向。

Abstract: Recent advancements in Large Language Models (LLMs) have catalyzed a paradigm
shift from static prediction systems to agentic AI agents capable of reasoning,
interacting with tools, and adapting to complex tasks. While LLM-based agentic
systems have shown promise across many domains, their application to medical
imaging remains in its infancy. In this work, we introduce AURA, the first
visual linguistic explainability agent designed specifically for comprehensive
analysis, explanation, and evaluation of medical images. By enabling dynamic
interactions, contextual explanations, and hypothesis testing, AURA represents
a significant advancement toward more transparent, adaptable, and clinically
aligned AI systems. We highlight the promise of agentic AI in transforming
medical image analysis from static predictions to interactive decision support.
Leveraging Qwen-32B, an LLM-based architecture, AURA integrates a modular
toolbox comprising: (i) a segmentation suite with phase grounding, pathology
segmentation, and anatomy segmentation to localize clinically meaningful
regions; (ii) a counterfactual image-generation module that supports reasoning
through image-level explanations; and (iii) a set of evaluation tools including
pixel-wise difference-map analysis, classification, and advanced
state-of-the-art components to assess diagnostic relevance and visual
interpretability.

</details>


### [8] [Pixels, Patterns, but No Poetry: To See The World like Humans](https://arxiv.org/abs/2507.16863)
*Hongcheng Gao,Zihao Huang,Lin Xu,Jingyi Tang,Xinhao Li,Yue Liu,Haoyang Li,Taihang Hu,Minhua Lin,Xinlong Yang,Ge Wu,Balong Bi,Hongyu Chen,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出了图灵眼测试(TET)，一个专注于感知能力的基准测试，发现当前最先进的多模态大语言模型在人类直觉处理的合成图像任务上表现极差，揭示了视觉塔泛化能力与人类感知之间的关键差距。


<details>
  <summary>Details</summary>
Motivation: 尽管近期研究主要关注提升多模态大语言模型的推理能力，但一个根本问题仍然存在：多模态大语言模型能否真正像人类一样感知世界？本文将焦点从推理转向感知，探索模型在基础感知任务上的表现。

Method: 引入图灵眼测试(TET)，这是一个具有挑战性的感知导向基准测试，包含四个诊断任务，用于评估多模态大语言模型在人类直觉处理的合成图像上的表现。测试了上下文学习、语言骨干训练和视觉塔微调等不同方法的效果。

Result: 研究发现最先进的多模态大语言模型在对人类来说微不足道的感知任务上出现灾难性失败。上下文学习和语言骨干训练在这些任务上无法提升性能，而视觉塔微调能够实现快速适应，表明基准测试主要挑战的是视觉塔的泛化能力而非语言骨干的知识和推理能力。

Conclusion: 当前多模态大语言模型与人类感知之间存在关键差距，主要体现在视觉塔的泛化能力不足。本研究为理解和改进多模态模型的感知能力提供了重要见解，未来工作将引入更多样化的任务和方法来增强视觉泛化能力。

Abstract: Achieving human-like perception and reasoning in Multimodal Large Language
Models (MLLMs) remains a central challenge in artificial intelligence. While
recent research has primarily focused on enhancing reasoning capabilities in
MLLMs, a fundamental question persists: Can Multimodal Large Language Models
truly perceive the world as humans do? This paper shifts focus from reasoning
to perception. Rather than constructing benchmarks specifically for reasoning,
we introduce the Turing Eye Test (TET), a challenging perception-oriented
benchmark comprising four diagnostic tasks that evaluate MLLMs' performance on
synthetic images that humans process intuitively. Our findings reveal that
state-of-the-art MLLMs exhibit catastrophic failures on our perceptual tasks
trivial for humans. Both in-context learning and training on language
backbone-effective for previous benchmarks-fail to improve performance on our
tasks, while fine-tuning the vision tower enables rapid adaptation, suggesting
that our benchmark poses challenges for vision tower generalization rather than
for the knowledge and reasoning capabilities of the language backbone-a key gap
between current MLLMs and human perception. We release a representative subset
of TET tasks in this version, and will introduce more diverse tasks and methods
to enhance visual generalization in future work.

</details>


### [9] [HIPPO-Video: Simulating Watch Histories with Large Language Models for Personalized Video Highlighting](https://arxiv.org/abs/2507.16873)
*Jeongeun Lee,Youngjae Yu,Dongha Lee*

Main category: cs.CV

TL;DR: 本文介绍了HIPPO-Video数据集，这是一个用于个性化视频高亮的新颖数据集，并提出了HiPHer方法来预测基于用户偏好的视频片段显著性分数


<details>
  <summary>Details</summary>
Motivation: 现有视频数据集缺乏个性化特征，通常依赖孤立视频或简单文本查询，无法捕捉用户行为的复杂性。随着视频内容的指数增长，个性化视频高亮成为一项重要任务，因为用户偏好具有高度可变性和复杂性

Method: 使用基于LLM的用户模拟器创建HIPPO-Video数据集，生成反映多样化用户偏好的真实观看历史。提出HiPHer方法，利用个性化观看历史来预测基于偏好条件的片段级显著性分数

Result: HIPPO-Video数据集包含2,040个（观看历史，显著性分数）对，覆盖170个语义类别的20,400个视频。通过广泛实验证明，该方法在性能上超越了现有的通用和基于查询的方法

Conclusion: 本文成功构建了个性化视频高亮数据集，并提出了有效的预测方法，展现了在真实场景中进行高度以用户为中心的视频高亮的潜力

Abstract: The exponential growth of video content has made personalized video
highlighting an essential task, as user preferences are highly variable and
complex. Existing video datasets, however, often lack personalization, relying
on isolated videos or simple text queries that fail to capture the intricacies
of user behavior. In this work, we introduce HIPPO-Video, a novel dataset for
personalized video highlighting, created using an LLM-based user simulator to
generate realistic watch histories reflecting diverse user preferences. The
dataset includes 2,040 (watch history, saliency score) pairs, covering 20,400
videos across 170 semantic categories. To validate our dataset, we propose
HiPHer, a method that leverages these personalized watch histories to predict
preference-conditioned segment-wise saliency scores. Through extensive
experiments, we demonstrate that our method outperforms existing generic and
query-based approaches, showcasing its potential for highly user-centric video
highlighting in real-world scenarios.

</details>


### [10] [ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension](https://arxiv.org/abs/2507.16877)
*Yizhi Hu,Zezhao Tian,Xingqun Qi,Chen Su,Bingkun Yang,Junhui Yin,Muyi Sun,Man Zhang,Zhenan Sun*

Main category: cs.CV

TL;DR: 本文提出了ReMeREC框架来解决多实体指称表达理解问题，通过构建关系感知数据集ReMeX和设计文本自适应多实体感知器(TMP)以及实体间关系推理器(EIR)，在多实体定位和关系预测任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的指称表达理解方法主要处理单实体定位，忽略了多实体场景中复杂的实体间关系，限制了准确性和可靠性。同时，缺乏高质量的细粒度图像-文本-关系配对标注数据集阻碍了进一步发展。

Method: 构建了关系感知的多实体REC数据集ReMeX；提出ReMeREC框架，包含文本自适应多实体感知器(TMP)来动态推断实体数量和范围，以及实体间关系推理器(EIR)来增强关系推理和全局场景理解；还构建了辅助数据集EntityText来改善细粒度提示的语言理解。

Result: 在四个基准数据集上的实验表明，ReMeREC在多实体定位和关系预测任务上达到了最先进的性能，大幅超越了现有方法。

Conclusion: 通过联合利用视觉和文本线索建模实体间关系，ReMeREC有效解决了多实体指称表达理解中的语义歧义和关系推理问题，为该领域的发展提供了新的解决方案。

Abstract: Referring Expression Comprehension (REC) aims to localize specified entities
or regions in an image based on natural language descriptions. While existing
methods handle single-entity localization, they often ignore complex
inter-entity relationships in multi-entity scenes, limiting their accuracy and
reliability. Additionally, the lack of high-quality datasets with fine-grained,
paired image-text-relation annotations hinders further progress. To address
this challenge, we first construct a relation-aware, multi-entity REC dataset
called ReMeX, which includes detailed relationship and textual annotations. We
then propose ReMeREC, a novel framework that jointly leverages visual and
textual cues to localize multiple entities while modeling their
inter-relations. To address the semantic ambiguity caused by implicit entity
boundaries in language, we introduce the Text-adaptive Multi-entity Perceptron
(TMP), which dynamically infers both the quantity and span of entities from
fine-grained textual cues, producing distinctive representations. Additionally,
our Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and
global scene understanding. To further improve language comprehension for
fine-grained prompts, we also construct a small-scale auxiliary dataset,
EntityText, generated using large language models. Experiments on four
benchmark datasets show that ReMeREC achieves state-of-the-art performance in
multi-entity grounding and relation prediction, outperforming existing
approaches by a large margin.

</details>


### [11] [CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos](https://arxiv.org/abs/2507.16878)
*Xuchen Li,Xuzhao Li,Shiyu Hu,Kaiqi Huang,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出了CausalStep基准测试，专门评估大语言模型在视频中的逐步因果推理能力，发现当前模型与人类水平存在显著差距


<details>
  <summary>Details</summary>
Motivation: 现有视频基准测试主要评估浅层理解，允许模型利用全局上下文走捷径，无法严格评估真正的因果和逐步推理能力，因此需要一个专门的基准来评估视频中的逐步因果推理

Method: 设计CausalStep基准测试：将视频分割为因果关联的单元，强制执行严格的逐步问答协议，要求顺序回答并防止捷径解决方案；构建包含干扰项的多选题，基于错误类型分类法确保诊断价值；引入七个诊断指标进行综合评估

Result: 基准包含6个类别的100个视频和1,852个多选问答对；通过对主流专有和开源模型以及人类基线的实验，发现当前模型与人类水平的逐步推理能力存在显著差距

Conclusion: CausalStep为推动鲁棒且可解释的视频推理进展提供了严格的基准测试，揭示了当前大语言模型在视频因果推理方面的不足

Abstract: Recent advances in large language models (LLMs) have improved reasoning in
text and image domains, yet achieving robust video reasoning remains a
significant challenge. Existing video benchmarks mainly assess shallow
understanding and reasoning and allow models to exploit global context, failing
to rigorously evaluate true causal and stepwise reasoning. We present
CausalStep, a benchmark designed for explicit stepwise causal reasoning in
videos. CausalStep segments videos into causally linked units and enforces a
strict stepwise question-answer (QA) protocol, requiring sequential answers and
preventing shortcut solutions. Each question includes carefully constructed
distractors based on error type taxonomy to ensure diagnostic value. The
benchmark features 100 videos across six categories and 1,852 multiple-choice
QA pairs. We introduce seven diagnostic metrics for comprehensive evaluation,
enabling precise diagnosis of causal reasoning capabilities. Experiments with
leading proprietary and open-source models, as well as human baselines, reveal
a significant gap between current models and human-level stepwise reasoning.
CausalStep provides a rigorous benchmark to drive progress in robust and
interpretable video reasoning.

</details>


### [12] [Finding Dori: Memorization in Text-to-Image Diffusion Models Is Less Local Than Assumed](https://arxiv.org/abs/2507.16880)
*Antoni Kowalczuk,Dominik Hintersdorf,Lukas Struppek,Kristian Kersting,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: 该研究揭示了现有文本到图像扩散模型中基于权重剪枝的数据记忆化防护方法存在严重脆弱性，提出了一种对抗性微调方法来增强模型的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型可能会无意中记忆和复制训练数据，引发数据隐私和知识产权问题。现有的基于权重剪枝的缓解方法假设记忆化可以被局部化，但这种防护策略的鲁棒性尚未得到充分评估

Method: 1) 评估现有剪枝方法的鲁棒性，通过调整文本嵌入来测试是否能重新触发数据复制；2) 挑战记忆化局部性假设，证明复制可以从文本嵌入空间的不同位置触发；3) 提出一种新颖的对抗性微调方法，迭代搜索复制触发器并更新模型以增强鲁棒性

Result: 研究发现即使在剪枝后，对输入提示的文本嵌入进行微小调整就足以重新触发数据复制，证明了这些防护措施的脆弱性。同时证明复制可以从文本嵌入空间的多个不同位置触发，并在模型中遵循不同路径，挑战了记忆化局部性的基本假设

Conclusion: 现有的缓解策略不足以解决记忆化问题，需要开发真正移除记忆内容而非仅仅抑制其检索的方法。研究为理解文本到图像扩散模型中记忆化的本质提供了新见解，并为构建更值得信赖和合规的生成式AI奠定了基础

Abstract: Text-to-image diffusion models (DMs) have achieved remarkable success in
image generation. However, concerns about data privacy and intellectual
property remain due to their potential to inadvertently memorize and replicate
training data. Recent mitigation efforts have focused on identifying and
pruning weights responsible for triggering replication, based on the assumption
that memorization can be localized. Our research assesses the robustness of
these pruning-based approaches. We demonstrate that even after pruning, minor
adjustments to text embeddings of input prompts are sufficient to re-trigger
data replication, highlighting the fragility of these defenses. Furthermore, we
challenge the fundamental assumption of memorization locality, by showing that
replication can be triggered from diverse locations within the text embedding
space, and follows different paths in the model. Our findings indicate that
existing mitigation strategies are insufficient and underscore the need for
methods that truly remove memorized content, rather than attempting to suppress
its retrieval. As a first step in this direction, we introduce a novel
adversarial fine-tuning method that iteratively searches for replication
triggers and updates the model to increase robustness. Through our research, we
provide fresh insights into the nature of memorization in text-to-image DMs and
a foundation for building more trustworthy and compliant generative AI.

</details>


### [13] [Sparser2Sparse: Single-shot Sparser-to-Sparse Learning for Spatial Transcriptomics Imputation with Natural Image Co-learning](https://arxiv.org/abs/2507.16886)
*Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee A. Cooper,Bo Zhou*

Main category: cs.CV

TL;DR: 本文提出了S2S-ST框架，通过稀疏到稀疏的自监督学习和自然图像协同训练，实现了仅需单个低成本稀疏空间转录组数据就能进行高精度插值重建的方法


<details>
  <summary>Details</summary>
Motivation: 空间转录组学(ST)技术成本高昂且高分辨率数据稀缺，限制了其在生物医学研究中的广泛应用，需要开发能够从稀疏数据重建高质量ST数据的方法

Method: 提出S2S-ST框架，包含三个核心创新：(1)稀疏到稀疏的自监督学习策略利用ST数据内在空间模式；(2)与自然图像进行跨域协同学习增强特征表示；(3)级联数据一致性插值网络(CDCIN)迭代优化预测并保持采样基因数据保真度

Result: 在乳腺癌、肝脏和淋巴组织等多种组织类型上的广泛实验表明，该方法在插值精度上优于现有最先进方法，能够从稀疏输入实现鲁棒的ST重建

Conclusion: 该框架显著减少了对昂贵高分辨率数据的依赖，有望促进空间转录组学技术在生物医学研究和临床应用中的更广泛采用

Abstract: Spatial transcriptomics (ST) has revolutionized biomedical research by
enabling high resolution gene expression profiling within tissues. However, the
high cost and scarcity of high resolution ST data remain significant
challenges. We present Single-shot Sparser-to-Sparse (S2S-ST), a novel
framework for accurate ST imputation that requires only a single and low-cost
sparsely sampled ST dataset alongside widely available natural images for
co-training. Our approach integrates three key innovations: (1) a
sparser-to-sparse self-supervised learning strategy that leverages intrinsic
spatial patterns in ST data, (2) cross-domain co-learning with natural images
to enhance feature representation, and (3) a Cascaded Data Consistent
Imputation Network (CDCIN) that iteratively refines predictions while
preserving sampled gene data fidelity. Extensive experiments on diverse tissue
types, including breast cancer, liver, and lymphoid tissue, demonstrate that
our method outperforms state-of-the-art approaches in imputation accuracy. By
enabling robust ST reconstruction from sparse inputs, our framework
significantly reduces reliance on costly high resolution data, facilitating
potential broader adoption in biomedical research and clinical applications.

</details>


### [14] [Toward Long-Tailed Online Anomaly Detection through Class-Agnostic Concepts](https://arxiv.org/abs/2507.16946)
*Chiao-An Yang,Kuan-Chuan Peng,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 本文提出了长尾在线异常检测(LTOAD)这一新任务，并开发了一个类别无关的框架来解决在线环境中无法获得类别标签的挑战，在工业制造和医疗领域都取得了优于现有方法的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的长尾异常检测(LTAD)方法依赖类别标签，无法直接应用于在线学习环境。作者希望将长尾分布和在线学习两个方向结合，解决更现实的长尾在线异常检测问题。

Method: 提出了一个类别无关的长尾异常检测框架，然后将其适配到在线学习环境中。该方法不需要类别标签信息，能够处理长尾分布的训练数据并支持在线学习。

Result: 在离线LTAD设置中超越了现有最佳方法，在MVTec数据集上相比有类别标签访问权限的方法提升了4.63%的image-AUROC。在最具挑战性的长尾在线设置中，相比基线方法提升了0.53%的image-AUROC。

Conclusion: 成功解决了长尾在线异常检测这一新颖且具有挑战性的任务，提出的类别无关框架在工业制造和医疗领域都表现出色，为实际应用场景提供了有效的解决方案。

Abstract: Anomaly detection (AD) identifies the defect regions of a given image. Recent
works have studied AD, focusing on learning AD without abnormal images, with
long-tailed distributed training data, and using a unified model for all
classes. In addition, online AD learning has also been explored. In this work,
we expand in both directions to a realistic setting by considering the novel
task of long-tailed online AD (LTOAD). We first identified that the offline
state-of-the-art LTAD methods cannot be directly applied to the online setting.
Specifically, LTAD is class-aware, requiring class labels that are not
available in the online setting. To address this challenge, we propose a
class-agnostic framework for LTAD and then adapt it to our online learning
setting. Our method outperforms the SOTA baselines in most offline LTAD
settings, including both the industrial manufacturing and the medical domain.
In particular, we observe +4.63% image-AUROC on MVTec even compared to methods
that have access to class labels and the number of classes. In the most
challenging long-tailed online setting, we achieve +0.53% image-AUROC compared
to baselines. Our LTOAD benchmark is released here:
https://doi.org/10.5281/zenodo.16283852 .

</details>


### [15] [Divisive Decisions: Improving Salience-Based Training for Generalization in Binary Classification Tasks](https://arxiv.org/abs/2507.17000)
*Jacob Piland,Chris Sweet,Adam Czajka*

Main category: cs.CV

TL;DR: 本文提出了一种新的显著性引导训练方法，通过同时考虑真类和假类的类激活图(CAM)来改进深度学习模型的泛化能力，在多个二分类任务上验证了该方法相比传统方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的显著性引导训练方法只关注真类CAM与人类参考显著性图的比较，忽略了假类CAM。作者假设在二分类任务中，真类和假类CAM应该在人类识别的重要分类特征上产生分歧，这一观察可以用来改进模型训练。

Method: 提出了三种新的显著性引导训练方法，将真类和假类的模型CAM都纳入训练策略中，并开发了一个用于识别重要特征的后验工具。方法基于真假类CAM在重要分类特征上应该分歧的假设。

Result: 在多个不同的二分类任务上进行评估，包括合成人脸检测、生物特征表示攻击检测和胸部X光异常分类等封闭集和开放集分类任务。结果显示提出的方法相比传统的显著性引导训练方法能够改进深度学习模型的泛化能力。

Conclusion: 通过同时利用真类和假类CAM的新型显著性引导训练方法能够有效提升模型在各种二分类任务上的泛化性能，为深度学习模型的可解释性和鲁棒性提供了新的训练策略。

Abstract: Existing saliency-guided training approaches improve model generalization by
incorporating a loss term that compares the model's class activation map (CAM)
for a sample's true-class ({\it i.e.}, correct-label class) against a human
reference saliency map. However, prior work has ignored the false-class CAM(s),
that is the model's saliency obtained for incorrect-label class. We hypothesize
that in binary tasks the true and false CAMs should diverge on the important
classification features identified by humans (and reflected in human saliency
maps). We use this hypothesis to motivate three new saliency-guided training
methods incorporating both true- and false-class model's CAM into the training
strategy and a novel post-hoc tool for identifying important features. We
evaluate all introduced methods on several diverse binary close-set and
open-set classification tasks, including synthetic face detection, biometric
presentation attack detection, and classification of anomalies in chest X-ray
scans, and find that the proposed methods improve generalization capabilities
of deep learning models over traditional (true-class CAM only) saliency-guided
training approaches. We offer source codes and model weights\footnote{GitHub
repository link removed to preserve anonymity} to support reproducible
research.

</details>


### [16] [Bringing Balance to Hand Shape Classification: Mitigating Data Imbalance Through Generative Models](https://arxiv.org/abs/2507.17008)
*Gaston Gustavo Rios,Pedro Dal Bianco,Franco Ronchetti,Facundo Quiroga,Oscar Stanchi,Santiago Ponte Ahón,Waldo Hasperué*

Main category: cs.CV

TL;DR: 该论文通过使用生成对抗网络(GAN)生成合成数据来增强手语手形分类器的训练数据，以解决手语手形数据集规模小且不平衡的问题。使用ReACGAN和SPADE两种GAN架构，在RWTH德语手语数据集上实现了5%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 手语手形数据集普遍存在规模小、类别不平衡的严重限制，这给有效的模型训练带来了重大挑战。现有数据集的局限性阻碍了手语识别技术的发展。

Method: 使用EfficientNet分类器在RWTH德语手语手形数据集上训练，并采用两种GAN架构生成合成数据：1) ReACGAN - 使用标签信息通过辅助分类器来条件化数据生成过程；2) SPADE - 利用空间自适应归一化根据姿态信息来条件化生成。探索了不同策略来组合生成图像和真实图像。

Result: 提出的技术将RWTH数据集上的最新准确率提高了5%，成功解决了小规模和不平衡数据集的局限性。该方法还展示了通过在大规模HaGRID数据集上训练的基于姿态的生成模型实现跨不同手语数据集泛化的能力，在无需重新训练生成器的情况下达到了与单源训练分类器相当的性能。

Conclusion: 通过生成对抗网络生成合成数据可以有效改善手语手形分类的性能，特别是在处理小规模和不平衡数据集时。ReACGAN和SPADE两种方法各有优势，分别在标签对齐和空间配置准确性方面表现出色。该方法具有良好的泛化能力，为手语识别技术的发展提供了新的解决方案。

Abstract: Most sign language handshape datasets are severely limited and unbalanced,
posing significant challenges to effective model training. In this paper, we
explore the effectiveness of augmenting the training data of a handshape
classifier by generating synthetic data. We use an EfficientNet classifier
trained on the RWTH German sign language handshape dataset, which is small and
heavily unbalanced, applying different strategies to combine generated and real
images. We compare two Generative Adversarial Networks (GAN) architectures for
data generation: ReACGAN, which uses label information to condition the data
generation process through an auxiliary classifier, and SPADE, which utilizes
spatially-adaptive normalization to condition the generation on pose
information. ReACGAN allows for the generation of realistic images that align
with specific handshape labels, while SPADE focuses on generating images with
accurate spatial handshape configurations. Our proposed techniques improve the
current state-of-the-art accuracy on the RWTH dataset by 5%, addressing the
limitations of small and unbalanced datasets. Additionally, our method
demonstrates the capability to generalize across different sign language
datasets by leveraging pose-based generation trained on the extensive HaGRID
dataset. We achieve comparable performance to single-source trained classifiers
without the need for retraining the generator.

</details>


### [17] [Transformer Based Building Boundary Reconstruction using Attraction Field Maps](https://arxiv.org/abs/2507.17038)
*Muhammad Kamran,Mohammad Moein Sheikholeslami,Andreas Wichmann,Gunho Sohn*

Main category: cs.CV

TL;DR: 本文提出了一种基于图卷积网络(GCN)的深度学习方法Decoupled-PolyGCN，用于从单张卫星图像中自动提取建筑物轮廓，通过融合几何规律性、多尺度特征和吸引力场图，在AP和AR指标上分别超越现有方法6%和10%


<details>
  <summary>Details</summary>
Motivation: 随着遥感卫星数量激增，从卫星图像重建空间地图的需求日益增长，但基于原语的对象表示在计算机视觉中仍是持续挑战，高质量空间地图往往依赖劳动密集型的手工过程，需要一种可扩展且精确的自动化建筑物轮廓提取解决方案

Method: 提出基于图卷积网络(GCN)的Decoupled-PolyGCN方法，通过以下创新点：1)将几何规律性融入建筑边界；2)集成多尺度和多分辨率特征；3)将吸引力场图嵌入网络架构中，实现从单张卫星图像进行自动化建筑物轮廓提取

Result: Decoupled-PolyGCN模型在性能上显著优于现有方法，在AP(平均精度)指标上提升6%，在AR(平均召回率)指标上提升10%，能够在多样化和具有挑战性的场景中提供准确且规则化的建筑物轮廓

Conclusion: 该方法为从卫星图像自动提取建筑物轮廓提供了可扩展且精确的解决方案，为城市规划、灾害管理和大规模空间分析等重要应用领域铺平了道路，证明了在复杂计算机视觉任务中融合几何约束和多尺度特征的有效性

Abstract: In recent years, the number of remote satellites orbiting the Earth has grown
significantly, streaming vast amounts of high-resolution visual data to support
diverse applications across civil, public, and military domains. Among these
applications, the generation and updating of spatial maps of the built
environment have become critical due to the extensive coverage and detailed
imagery provided by satellites. However, reconstructing spatial maps from
satellite imagery is a complex computer vision task, requiring the creation of
high-level object representations, such as primitives, to accurately capture
the built environment. While the past decade has witnessed remarkable
advancements in object detection and representation using visual data,
primitives-based object representation remains a persistent challenge in
computer vision. Consequently, high-quality spatial maps often rely on
labor-intensive and manual processes. This paper introduces a novel deep
learning methodology leveraging Graph Convolutional Networks (GCNs) to address
these challenges in building footprint reconstruction. The proposed approach
enhances performance by incorporating geometric regularity into building
boundaries, integrating multi-scale and multi-resolution features, and
embedding Attraction Field Maps into the network. These innovations provide a
scalable and precise solution for automated building footprint extraction from
a single satellite image, paving the way for impactful applications in urban
planning, disaster management, and large-scale spatial analysis. Our model,
Decoupled-PolyGCN, outperforms existing methods by 6% in AP and 10% in AR,
demonstrating its ability to deliver accurate and regularized building
footprints across diverse and challenging scenarios.

</details>


### [18] [Controllable Hybrid Captioner for Improved Long-form Video Understanding](https://arxiv.org/abs/2507.17047)
*Kuleen Sasse,Efsun Sarioglu Kayi,Arun Reddy*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本记忆的视频理解系统，通过将长视频分割成短片段并生成文本描述，结合大语言模型来回答复杂的自然语言查询。系统使用LaViLa视频字幕生成器和LLaVA视觉语言模型来生成包含动作和场景信息的混合字幕。


<details>
  <summary>Details</summary>
Motivation: 长视频数据密度极高且维度复杂，直接处理计算成本昂贵。现有的视频字幕主要关注人类动作，但查询可能涉及场景中的其他信息。需要一种更高效的方法来理解视频内容并回答复杂的自然语言问题。

Method: 1) 将长视频分割成有意义的短片段；2) 使用LaViLa视频字幕生成器对短片段生成动作描述；3) 结合LLaVA视觉语言模型生成静态场景描述；4) 微调LaViLa模型使其能够根据特殊输入标记生成动作和场景两种类型的字幕；5) 构建文本记忆库供大语言模型推理使用。

Result: 成功开发了可控制的混合字幕生成器，能够根据视频中检测到的场景变化在不同类型的字幕之间切换。相比使用独立的字幕模型处理两个任务，显著提高了字幕生成管道的效率。扩展了可从文本记忆中回答的问题范围。

Conclusion: 通过渐进式构建基于文本的记忆系统，结合动作和场景描述，成功实现了高效的长视频理解。混合字幕生成器的开发大大提升了系统效率，为复杂视频问答任务提供了有效解决方案。

Abstract: Video data, especially long-form video, is extremely dense and
high-dimensional. Text-based summaries of video content offer a way to
represent query-relevant content in a much more compact manner than raw video.
In addition, textual representations are easily ingested by state-of-the-art
large language models (LLMs), which enable reasoning over video content to
answer complex natural language queries. To solve this issue, we rely on the
progressive construction of a text-based memory by a video captioner operating
on shorter chunks of the video, where spatio-temporal modeling is
computationally feasible. We explore ways to improve the quality of the
activity log comprised solely of short video captions. Because the video
captions tend to be focused on human actions, and questions may pertain to
other information in the scene, we seek to enrich the memory with static scene
descriptions using Vision Language Models (VLMs). Our video understanding
system relies on the LaViLa video captioner in combination with a LLM to answer
questions about videos. We first explored different ways of partitioning the
video into meaningful segments such that the textual descriptions more
accurately reflect the structure of the video content. Furthermore, we
incorporated static scene descriptions into the captioning pipeline using LLaVA
VLM, resulting in a more detailed and complete caption log and expanding the
space of questions that are answerable from the textual memory. Finally, we
have successfully fine-tuned the LaViLa video captioner to produce both action
and scene captions, significantly improving the efficiency of the captioning
pipeline compared to using separate captioning models for the two tasks. Our
model, controllable hybrid captioner, can alternate between different types of
captions according to special input tokens that signals scene changes detected
in the video.

</details>


### [19] [Toward Scalable Video Narration: A Training-free Approach Using Multimodal Large Language Models](https://arxiv.org/abs/2507.17050)
*Tz-Ying Wu,Tahani Trigui,Sharath Nittur Sridhar,Anand Bodas,Subarna Tripathi*

Main category: cs.CV

TL;DR: 本文提出VideoNarrator，一个无需训练的管道系统，用于生成带有精确时间戳的密集视频字幕，通过多个多模态大语言模型的协同工作来减少幻觉并改善时间对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视频理解中存在时间对齐困难和容易产生幻觉的问题，特别是在不熟悉的场景中，因此需要一种更可靠的方法来生成准确的时间戳视频描述。

Method: 设计了一个灵活的无需训练管道，其中现成的多模态大语言模型(MLLMs)和视觉-语言模型(VLMs)可以作为字幕生成器、上下文提供者或字幕验证器协同工作，通过多组件的协同交互来提升视频叙述质量。

Result: 实验结果表明，这些组件的协同交互显著提升了视频叙述的质量和准确性，有效减少了幻觉现象并改善了时间对齐效果。

Conclusion: VideoNarrator不仅增强了视频理解能力，还促进了下游任务如视频摘要和视频问答的发展，并且可以潜在地扩展到广告和营销应用中。

Abstract: In this paper, we introduce VideoNarrator, a novel training-free pipeline
designed to generate dense video captions that offer a structured snapshot of
video content. These captions offer detailed narrations with precise
timestamps, capturing the nuances present in each segment of the video. Despite
advancements in multimodal large language models (MLLMs) for video
comprehension, these models often struggle with temporally aligned narrations
and tend to hallucinate, particularly in unfamiliar scenarios. VideoNarrator
addresses these challenges by leveraging a flexible pipeline where
off-the-shelf MLLMs and visual-language models (VLMs) can function as caption
generators, context providers, or caption verifiers. Our experimental results
demonstrate that the synergistic interaction of these components significantly
enhances the quality and accuracy of video narrations, effectively reducing
hallucinations and improving temporal alignment. This structured approach not
only enhances video understanding but also facilitates downstream tasks such as
video summarization and video question answering, and can be potentially
extended for advertising and marketing applications.

</details>


### [20] [Yume: An Interactive World Generation Model](https://arxiv.org/abs/2507.17744)
*Xiaofeng Mao,Shaoheng Lin,Zhen Li,Chuanhao Li,Wenshuo Peng,Tong He,Jiangmiao Pang,Mingmin Chi,Yu Qiao,Kaipeng Zhang*

Main category: cs.CV

TL;DR: Yume是一个从输入图像创建动态交互世界的系统，用户可以通过键盘操作探索该世界，采用了相机运动量化、掩码视频扩散变换器、反伪影机制和模型加速等技术实现高保真度的交互式视频世界生成。


<details>
  <summary>Details</summary>
Motivation: 现有技术无法从单张图像生成可交互、逼真且动态的世界环境，用户缺乏通过外设或神经信号探索和控制虚拟世界的有效手段。研究者希望开发一个能够从图像、文本或视频输入创建交互式世界的系统。

Method: 提出了一个包含四个主要组件的框架：1）相机运动量化，实现稳定训练和用户友好的键盘交互；2）带有记忆模块的掩码视频扩散变换器(MVDT)，用于自回归方式的无限视频生成；3）无训练的反伪影机制(AAM)和基于随机微分方程的时间旅行采样(TTS-SDE)；4）通过对抗蒸馏和缓存机制的协同优化实现模型加速。

Result: 在高质量世界探索数据集Sekai上训练后，Yume在多样化场景和应用中取得了显著效果，能够从输入图像创建动态世界并支持键盘操作探索。所有数据、代码库和模型权重均已开源发布。

Conclusion: 成功开发了Yume预览版本，实现了从单张图像生成可交互动态世界的目标。该系统通过创新的技术框架在视觉质量和控制精度方面达到了优异表现，为交互式虚拟世界生成提供了新的解决方案。项目将持续月度更新以实现最终目标。

Abstract: Yume aims to use images, text, or videos to create an interactive, realistic,
and dynamic world, which allows exploration and control using peripheral
devices or neural signals. In this report, we present a preview version of
\method, which creates a dynamic world from an input image and allows
exploration of the world using keyboard actions. To achieve this high-fidelity
and interactive video world generation, we introduce a well-designed framework,
which consists of four main components, including camera motion quantization,
video generation architecture, advanced sampler, and model acceleration. First,
we quantize camera motions for stable training and user-friendly interaction
using keyboard inputs. Then, we introduce the Masked Video Diffusion
Transformer~(MVDT) with a memory module for infinite video generation in an
autoregressive manner. After that, training-free Anti-Artifact Mechanism (AAM)
and Time Travel Sampling based on Stochastic Differential Equations (TTS-SDE)
are introduced to the sampler for better visual quality and more precise
control. Moreover, we investigate model acceleration by synergistic
optimization of adversarial distillation and caching mechanisms. We use the
high-quality world exploration dataset \sekai to train \method, and it achieves
remarkable results in diverse scenes and applications. All data, codebase, and
model weights are available on https://github.com/stdstu12/YUME. Yume will
update monthly to achieve its original goal. Project page:
https://stdstu12.github.io/YUME-Project/.

</details>


### [21] [Few-Shot Learning in Video and 3D Object Detection: A Survey](https://arxiv.org/abs/2507.17079)
*Md Meftahul Ferdaus,Kendall N. Niles,Joe Tom,Mahdi Abdelguerfi,Elias Ioup*

Main category: cs.CV

TL;DR: 这是一篇关于少样本学习在视频和3D目标检测中应用的综述论文，探讨了如何通过少量标注样本实现新类别的检测，从而减少昂贵的人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测需要大量标注数据，成本高昂。特别是在视频中跨帧标注对象和3D数据标注更加费时费力。因此需要探索少样本学习方法来降低标注需求，使模型能够仅用少量样本就识别新类别。

Method: 论文综述了视频和3D目标检测中的少样本学习方法。视频方面包括管道提议和时序匹配网络等技术，利用时空结构传播信息。3D检测方面将少样本学习与专门的点云网络结合，并设计了针对类别不平衡的损失函数。核心方法涉及原型匹配、跨模态信息利用等。

Result: 少样本学习在视频和3D目标检测中展现出良好前景，能够有效减少标注需求。视频检测通过利用时空结构可以从少量样本中检测新类别，3D检测能够应对稀疏性和纹理缺失等挑战，为自动驾驶等实际应用的部署提供了可能。

Conclusion: 少样本学习有望显著减少标注需求，通过有效利用特征、时序和数据模态间的信息，使视频、3D等实际应用场景的部署成为可能。该技术在平衡泛化能力与过拟合、整合原型匹配、处理数据模态特性等方面仍存在挑战，但总体前景广阔。

Abstract: Few-shot learning (FSL) enables object detection models to recognize novel
classes given only a few annotated examples, thereby reducing expensive manual
data labeling. This survey examines recent FSL advances for video and 3D object
detection. For video, FSL is especially valuable since annotating objects
across frames is more laborious than for static images. By propagating
information across frames, techniques like tube proposals and temporal matching
networks can detect new classes from a couple examples, efficiently leveraging
spatiotemporal structure. FSL for 3D detection from LiDAR or depth data faces
challenges like sparsity and lack of texture. Solutions integrate FSL with
specialized point cloud networks and losses tailored for class imbalance.
Few-shot 3D detection enables practical autonomous driving deployment by
minimizing costly 3D annotation needs. Core issues in both domains include
balancing generalization and overfitting, integrating prototype matching, and
handling data modality properties. In summary, FSL shows promise for reducing
annotation requirements and enabling real-world video, 3D, and other
applications by efficiently leveraging information across feature, temporal,
and data modalities. By comprehensively surveying recent advancements, this
paper illuminates FSL's potential to minimize supervision needs and enable
deployment across video, 3D, and other real-world applications.

</details>


### [22] [SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction](https://arxiv.org/abs/2507.17083)
*Zaipeng Duan,Chenxu Dang,Xuzhong Hu,Pei An,Junfeng Ding,Jie Zhan,Yunbiao Xu,Jie Ma*

Main category: cs.CV

TL;DR: 提出了SDG-OCC多模态3D占用预测网络，通过语义和深度引导的视图变换以及融合到占用驱动的主动蒸馏，解决了现有单模态方法的局限性，在保持实时性能的同时达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D占用预测方法主要是单模态的：基于相机的方法缺乏深度信息，而基于LiDAR的方法难以处理遮挡问题。当前的轻量级方法主要依赖LSS管道，存在深度估计不准确且无法充分利用3D LiDAR点的几何和语义信息的问题。

Method: 提出SDG-OCC网络，包含两个核心组件：1）联合语义和深度引导的视图变换，通过扩散和双线性离散化整合像素语义和共点深度来构建准确的深度分布；2）融合到占用驱动的主动蒸馏，从多模态数据中提取丰富的语义信息，并基于LiDAR识别的区域选择性地将知识传递给图像特征。还提出了SDG-Fusion（仅使用融合）和SDG-KL（集成融合和蒸馏以实现更快推理）两个变体。

Result: 在Occ3D-nuScenes数据集上达到了最先进性能并实现实时处理，在更具挑战性的SurroundOcc-nuScenes数据集上也表现出可比较的性能，证明了方法的有效性和鲁棒性。

Conclusion: SDG-OCC通过有效融合相机和LiDAR的优势，克服了单模态方法的局限性，在多模态3D占用预测任务中取得了突破性进展，为自动驾驶中的环境感知提供了更准确和高效的解决方案。

Abstract: Multimodal 3D occupancy prediction has garnered significant attention for its
potential in autonomous driving. However, most existing approaches are
single-modality: camera-based methods lack depth information, while LiDAR-based
methods struggle with occlusions. Current lightweight methods primarily rely on
the Lift-Splat-Shoot (LSS) pipeline, which suffers from inaccurate depth
estimation and fails to fully exploit the geometric and semantic information of
3D LiDAR points. Therefore, we propose a novel multimodal occupancy prediction
network called SDG-OCC, which incorporates a joint semantic and depth-guided
view transformation coupled with a fusion-to-occupancy-driven active
distillation. The enhanced view transformation constructs accurate depth
distributions by integrating pixel semantics and co-point depth through
diffusion and bilinear discretization. The fusion-to-occupancy-driven active
distillation extracts rich semantic information from multimodal data and
selectively transfers knowledge to image features based on LiDAR-identified
regions. Finally, for optimal performance, we introduce SDG-Fusion, which uses
fusion alone, and SDG-KL, which integrates both fusion and distillation for
faster inference. Our method achieves state-of-the-art (SOTA) performance with
real-time processing on the Occ3D-nuScenes dataset and shows comparable
performance on the more challenging SurroundOcc-nuScenes dataset, demonstrating
its effectiveness and robustness. The code will be released at
https://github.com/DzpLab/SDGOCC.

</details>


### [23] [FedVLM: Scalable Personalized Vision-Language Models through Federated Learning](https://arxiv.org/abs/2507.17088)
*Arkajyoti Mitra,Afia Anjum,Paul Agbaje,Mert Pesé,Habeeb Olufowobi*

Main category: cs.CV

TL;DR: 提出了FedVLM框架，通过个性化LoRA(pLoRA)在联邦学习环境中高效微调视觉-语言模型，在非独立同分布数据上相比标准LoRA提升24.5%性能


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在联邦环境中的大规模微调面临挑战，特别是在数据去中心化和客户端间数据非独立同分布的情况下，现有的参数高效调优方法如LoRA在异构客户端数据上表现不佳，泛化能力欠佳

Method: 提出FedVLM联邦LoRA微调框架，引入个性化LoRA(pLoRA)方法，动态适应每个客户端独特的数据分布，在保持全局模型聚合的同时显著改善本地适应性，实现去中心化的VLM适应并保护模型隐私

Result: 在RLAIF-V数据集上的实验表明，pLoRA相比标准LoRA在客户端特定性能上提升了24.5%，在非独立同分布设置中展现出卓越的适应能力

Conclusion: FedVLM为联邦设置中的VLM微调提供了可扩展且高效的解决方案，推进了分布式学习场景中的个性化适应技术发展

Abstract: Vision-language models (VLMs) demonstrate impressive zero-shot and few-shot
learning capabilities, making them essential for several downstream tasks.
However, fine-tuning these models at scale remains challenging, particularly in
federated environments where data is decentralized and non-iid across clients.
Existing parameter-efficient tuning methods like LoRA (Low-Rank Adaptation)
reduce computational overhead but struggle with heterogeneous client data,
leading to suboptimal generalization. To address these challenges, we propose
FedVLM, a federated LoRA fine-tuning framework that enables decentralized
adaptation of VLMs while preserving model privacy and reducing reliance on
centralized training. To further tackle data heterogeneity, we introduce
personalized LoRA (pLoRA), which dynamically adapts LoRA parameters to each
client's unique data distribution, significantly improving local adaptation
while maintaining global model aggregation. Experiments on the RLAIF-V dataset
show that pLoRA improves client-specific performance by 24.5% over standard
LoRA, demonstrating superior adaptation in non-iid settings. FedVLM provides a
scalable and efficient solution for fine-tuning VLMs in federated settings,
advancing personalized adaptation in distributed learning scenarios.

</details>


### [24] [IONext: Unlocking the Next Era of Inertial Odometry](https://arxiv.org/abs/2507.17089)
*Shanshan Zhang,Siyue Wang,Tianshui Wen,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.CV

TL;DR: 提出了IONext，一个基于CNN的惯性里程计骨干网络，通过双翼自适应动态混合器(DADM)和时空门控单元(STGU)有效捕获全局和局部运动特征，在六个公开数据集上超越了现有的Transformer和CNN方法


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型在惯性里程计中虽然擅长建模长程依赖，但对局部细粒度运动变化敏感性有限，缺乏固有归纳偏置，影响定位精度和泛化能力；而CNN方法在时序建模方面存在局限性

Method: 提出双翼自适应动态混合器(DADM)模块，能够自适应捕获全局运动模式和局部细粒度运动特征；引入时空门控单元(STGU)改善时序建模，选择性提取具有代表性的任务相关运动特征；基于DADM和STGU构建IONext骨干网络

Result: 在六个公开数据集上的广泛实验表明，IONext持续优于最先进的Transformer和CNN方法；在RNIN数据集上，相比代表性模型iMOT，平均ATE降低10%，平均RTE降低12%

Conclusion: IONext通过结合CNN的局部特征提取能力和改进的时序建模机制，成功解决了现有方法在惯性里程计任务中的局限性，实现了更好的定位精度和泛化性能

Abstract: Researchers have increasingly adopted Transformer-based models for inertial
odometry. While Transformers excel at modeling long-range dependencies, their
limited sensitivity to local, fine-grained motion variations and lack of
inherent inductive biases often hinder localization accuracy and
generalization. Recent studies have shown that incorporating large-kernel
convolutions and Transformer-inspired architectural designs into CNN can
effectively expand the receptive field, thereby improving global motion
perception. Motivated by these insights, we propose a novel CNN-based module
called the Dual-wing Adaptive Dynamic Mixer (DADM), which adaptively captures
both global motion patterns and local, fine-grained motion features from
dynamic inputs. This module dynamically generates selective weights based on
the input, enabling efficient multi-scale feature aggregation. To further
improve temporal modeling, we introduce the Spatio-Temporal Gating Unit (STGU),
which selectively extracts representative and task-relevant motion features in
the temporal domain. This unit addresses the limitations of temporal modeling
observed in existing CNN approaches. Built upon DADM and STGU, we present a new
CNN-based inertial odometry backbone, named Next Era of Inertial Odometry
(IONext). Extensive experiments on six public datasets demonstrate that IONext
consistently outperforms state-of-the-art (SOTA) Transformer- and CNN-based
methods. For instance, on the RNIN dataset, IONext reduces the average ATE by
10% and the average RTE by 12% compared to the representative model iMOT.

</details>


### [25] [Robust Five-Class and binary Diabetic Retinopathy Classification Using Transfer Learning and Data Augmentation](https://arxiv.org/abs/2507.17121)
*Faisal Ahmed,Mohammad Alfrad Nobel Bhuiyan*

Main category: cs.CV

TL;DR: 本文提出了一个基于深度学习的糖尿病视网膜病变诊断框架，使用迁移学习和数据增强技术，在二分类任务中达到98.9%的准确率，在五分类任务中达到84.6%的准确率


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是全球视力丧失的主要原因，通过自动化视网膜图像分析进行早期诊断可以显著降低失明风险。现有方法面临类别不平衡和训练数据有限的挑战

Method: 提出了一个鲁棒的深度学习框架，结合迁移学习和广泛的数据增强技术来解决类别不平衡问题。评估了多种预训练卷积神经网络架构，包括ResNet和EfficientNet的变体，使用APTOS 2019数据集进行训练和测试

Result: 二分类任务：准确率98.9%，精确率98.6%，召回率99.3%，F1分数98.9%，AUC为99.4%。五分类严重程度分类任务：准确率84.6%，AUC为94.1%。EfficientNet-B0和ResNet34在准确性和计算效率之间提供了最佳平衡

Conclusion: 研究表明类别平衡增强与迁移学习相结合对于高性能糖尿病视网膜病变诊断非常有效。所提出的框架为糖尿病视网膜病变筛查提供了可扩展且准确的解决方案，具有在真实临床环境中部署的潜力

Abstract: Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, and
early diagnosis through automated retinal image analysis can significantly
reduce the risk of blindness. This paper presents a robust deep learning
framework for both binary and five-class DR classification, leveraging transfer
learning and extensive data augmentation to address the challenges of class
imbalance and limited training data. We evaluate a range of pretrained
convolutional neural network architectures, including variants of ResNet and
EfficientNet, on the APTOS 2019 dataset.
  For binary classification, our proposed model achieves a state-of-the-art
accuracy of 98.9%, with a precision of 98.6%, recall of 99.3%, F1-score of
98.9%, and an AUC of 99.4%. In the more challenging five-class severity
classification task, our model obtains a competitive accuracy of 84.6% and an
AUC of 94.1%, outperforming several existing approaches. Our findings also
demonstrate that EfficientNet-B0 and ResNet34 offer optimal trade-offs between
accuracy and computational efficiency across both tasks.
  These results underscore the effectiveness of combining class-balanced
augmentation with transfer learning for high-performance DR diagnosis. The
proposed framework provides a scalable and accurate solution for DR screening,
with potential for deployment in real-world clinical environments.

</details>


### [26] [ScSAM: Debiasing Morphology and Distributional Variability in Subcellular Semantic Segmentation](https://arxiv.org/abs/2507.17149)
*Bo Fang,Jianan Fan,Dongnan Liu,Hang Chang,Gerald J. Shami,Filip Braet,Weidong Cai*

Main category: cs.CV

TL;DR: 本文提出ScSAM方法，通过融合预训练SAM和MAE引导的细胞先验知识来解决亚细胞器官分割中的形态分布变异性和训练偏差问题，在多个数据集上超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 亚细胞组件的形态和分布变异性巨大，导致基于学习的细胞器分割模型存在偏差特征学习风险。现有方法依赖单一映射关系，忽视特征多样性。虽然SAM提供丰富特征表示，但在亚细胞场景中面临两个挑战：(1)形态分布变异性在标签空间产生缺口，导致模型学习虚假偏差特征；(2)SAM专注全局上下文理解，忽略细粒度空间细节，难以捕获微妙结构变化和应对倾斜数据分布。

Method: 提出ScSAM方法，通过融合预训练SAM与MAE引导的细胞先验知识来增强特征鲁棒性，缓解数据不平衡导致的训练偏差。具体包括：(1)设计特征对齐和融合模块，将预训练嵌入对齐到相同特征空间并有效结合不同表示；(2)提出基于余弦相似度矩阵的类提示编码器，激活类特定特征以识别亚细胞类别。

Result: 在多个不同的亚细胞图像数据集上进行了广泛实验，ScSAM在性能上超越了现有的最先进方法，证明了该方法在亚细胞器官分割任务中的有效性。

Conclusion: ScSAM成功解决了亚细胞器官分割中的关键挑战，通过融合SAM和MAE的优势，有效缓解了训练偏差问题，提升了特征鲁棒性，为亚细胞图像分析提供了更准确可靠的解决方案。

Abstract: The significant morphological and distributional variability among
subcellular components poses a long-standing challenge for learning-based
organelle segmentation models, significantly increasing the risk of biased
feature learning. Existing methods often rely on single mapping relationships,
overlooking feature diversity and thereby inducing biased training. Although
the Segment Anything Model (SAM) provides rich feature representations, its
application to subcellular scenarios is hindered by two key challenges: (1) The
variability in subcellular morphology and distribution creates gaps in the
label space, leading the model to learn spurious or biased features. (2) SAM
focuses on global contextual understanding and often ignores fine-grained
spatial details, making it challenging to capture subtle structural alterations
and cope with skewed data distributions. To address these challenges, we
introduce ScSAM, a method that enhances feature robustness by fusing
pre-trained SAM with Masked Autoencoder (MAE)-guided cellular prior knowledge
to alleviate training bias from data imbalance. Specifically, we design a
feature alignment and fusion module to align pre-trained embeddings to the same
feature space and efficiently combine different representations. Moreover, we
present a cosine similarity matrix-based class prompt encoder to activate
class-specific features to recognize subcellular categories. Extensive
experiments on diverse subcellular image datasets demonstrate that ScSAM
outperforms state-of-the-art methods.

</details>


### [27] [UNICE: Training A Universal Image Contrast Enhancer](https://arxiv.org/abs/2507.17157)
*Ruodai Cui,Lei Zhang*

Main category: cs.CV

TL;DR: 提出了一个通用图像对比度增强方法UNICE，通过从单张sRGB图像生成多曝光序列并融合来实现各种对比度增强任务，在多个任务上表现出强泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有图像对比度增强方法通常针对特定任务设计，在不同任务甚至同一任务的不同数据集间泛化性能较差，因此需要探索能够处理各种对比度增强任务的通用模型

Method: 收集46,928张HDR原始图像，渲染328,496张sRGB图像构建多曝光序列数据集；训练两个网络：第一个从单张sRGB图像生成多曝光序列，第二个将生成的多曝光序列融合为增强图像

Result: UNICE在跨任务和任务内都表现出比现有方法更强的泛化性能，在多个无参考图像质量指标上甚至超越人工创建的真值标准

Conclusion: 通过模拟HDR成像过程和多曝光融合，可以实现无需昂贵人工标注的通用图像对比度增强，该方法具有出色的跨任务泛化能力

Abstract: Existing image contrast enhancement methods are typically designed for
specific tasks such as under-/over-exposure correction, low-light and backlit
image enhancement, etc. The learned models, however, exhibit poor
generalization performance across different tasks, even across different
datasets of a specific task. It is important to explore whether we can learn a
universal and generalized model for various contrast enhancement tasks. In this
work, we observe that the common key factor of these tasks lies in the need of
exposure and contrast adjustment, which can be well-addressed if high-dynamic
range (HDR) inputs are available. We hence collect 46,928 HDR raw images from
public sources, and render 328,496 sRGB images to build multi-exposure
sequences (MES) and the corresponding pseudo sRGB ground-truths via
multi-exposure fusion. Consequently, we train a network to generate an MES from
a single sRGB image, followed by training another network to fuse the generated
MES into an enhanced image. Our proposed method, namely UNiversal Image
Contrast Enhancer (UNICE), is free of costly human labeling. However, it
demonstrates significantly stronger generalization performance than existing
image contrast enhancement methods across and within different tasks, even
outperforming manually created ground-truths in multiple no-reference image
quality metrics. The dataset, code and model are available at
https://github.com/BeyondHeaven/UNICE.

</details>


### [28] [DOOMGAN:High-Fidelity Dynamic Identity Obfuscation Ocular Generative Morphing](https://arxiv.org/abs/2507.17158)
*Bharath Krishnamurthy,Ajita Rattani*

Main category: cs.CV

TL;DR: 本文提出了DOOMGAN，一种针对可见光谱眼部生物识别的形态攻击生成模型，通过地标驱动编码、注意力引导生成和动态损失加权，实现了比基线方法高20%的攻击成功率


<details>
  <summary>Details</summary>
Motivation: 可见光谱眼部生物识别虽然具有高精度、抗欺骗性和非侵入性等优势，但面临形态攻击（morphing attacks）的威胁。现有研究主要集中在近红外虹膜和人脸生物识别的形态攻击上，而可见光谱眼部数据的形态攻击研究仍然不足，需要先进的生成模型来处理非受控条件下的详细眼部特征

Method: 提出DOOMGAN模型，包含三个核心组件：1）地标驱动的可见光眼部解剖结构编码；2）注意力引导的真实形态合成生成；3）多方面损失的动态加权以优化收敛过程

Result: DOOMGAN在严格阈值下实现了比基线方法高20%的攻击成功率，椭圆虹膜结构生成提升20%，凝视一致性改善30%。同时发布了首个综合性眼部形态攻击数据集

Conclusion: DOOMGAN成功解决了可见光谱眼部生物识别中形态攻击生成的挑战，显著提升了攻击效果和生成质量，为该领域的安全性评估和防护研究提供了重要工具和数据支持

Abstract: Ocular biometrics in the visible spectrum have emerged as a prominent
modality due to their high accuracy, resistance to spoofing, and non-invasive
nature. However, morphing attacks, synthetic biometric traits created by
blending features from multiple individuals, threaten biometric system
integrity. While extensively studied for near-infrared iris and face
biometrics, morphing in visible-spectrum ocular data remains underexplored.
Simulating such attacks demands advanced generation models that handle
uncontrolled conditions while preserving detailed ocular features like iris
boundaries and periocular textures. To address this gap, we introduce DOOMGAN,
that encompasses landmark-driven encoding of visible ocular anatomy,
attention-guided generation for realistic morph synthesis, and dynamic
weighting of multi-faceted losses for optimized convergence. DOOMGAN achieves
over 20% higher attack success rates than baseline methods under stringent
thresholds, along with 20% better elliptical iris structure generation and 30%
improved gaze consistency. We also release the first comprehensive ocular
morphing dataset to support further research in this domain.

</details>


### [29] [Multi-Scale PCB Defect Detection with YOLOv8 Network Improved via Pruning and Lightweight Network](https://arxiv.org/abs/2507.17176)
*Li Pingzhen,Xu Sheng,Chen Jing,Su Chengyue*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLOv8改进的多尺度PCB缺陷检测方法，通过微小目标敏感策略、网络轻量化和自适应剪枝的综合策略，实现了高精度和实时检测微小缺陷的要求。


<details>
  <summary>Details</summary>
Motivation: 传统PCB缺陷检测模型难以兼顾精度和计算成本，无法满足高精度和实时检测微小缺陷的要求。随着PCB设计的高密度化和生产的高速化，需要一种既能保证检测精度又能满足实时性要求的缺陷检测方法。

Method: 采用综合策略改进YOLOv8：1）骨干网络使用参数较少的Ghost-HGNetv2结构，利用多层次特征提取图像语义特征；2）颈部网络集成参数较少的C2f-Faster增强多层次特征融合能力；3）头部设计新的GCDetect检测头，使边界框预测和类别预测共享GroupConv权重；4）设计Inner-MPDIoU边界损失函数改善微小目标检测和定位；5）通过优化的自适应剪枝率对模型进行剪枝。

Result: 在公开的PCB缺陷数据集上，mAP0.5达到99.32%，mAP0.5:0.9达到75.18%，相比YOLOv8n提高了10.13%。模型在精度和速度方面都表现出优势。

Conclusion: 通过多尺度特征提取、轻量化网络设计、新型检测头和自适应剪枝等综合策略，成功改进了YOLOv8模型，实现了PCB缺陷检测的高精度和实时性要求，为工业质量检测提供了有效的解决方案。

Abstract: With the high density of printed circuit board (PCB) design and the high
speed of production, the traditional PCB defect detection model is difficult to
take into account the accuracy and computational cost, and cannot meet the
requirements of high accuracy and real-time detection of tiny defects.
Therefore, in this paper, a multi-scale PCB defect detection method is improved
with YOLOv8 using a comprehensive strategy of tiny target sensitivity strategy,
network lightweighting and adaptive pruning, which is able to improve the
detection speed and accuracy by optimizing the backbone network, the neck
network and the detection head, the loss function and the adaptive pruning
rate. Firstly, a Ghost-HGNetv2 structure with fewer parameters is used in the
backbone network, and multilevel features are used to extract image semantic
features to discover accurate defects. Secondly, we integrate C2f-Faster with
small number of parameters in the neck section to enhance the ability of
multi-level feature fusion. Next, in the Head part, we design a new GCDetect
detection head, which allows the prediction of bounding boxes and categories to
share the weights of GroupConv, and uses a small number of grouping
convolutions to accomplish the regression and classification tasks, which
significantly reduces the number of parameters while maintaining the accuracy
of detection. We also design the Inner-MPDIoU boundary loss function to improve
the detection and localization of tiny targets. Finally, the model was pruned
by an optimized adaptive pruning rate to further reduce the complexity of the
model. Experimental results show that the model exhibits advantages in terms of
accuracy and speed. On the publicly available PCB defect dataset, mAP0.5
reaches 99.32% and mAP0.5:0.9 reaches 75.18%, which is 10.13% higher compared
to YOLOv8n.

</details>


### [30] [Hierarchical Fusion and Joint Aggregation: A Multi-Level Feature Representation Method for AIGC Image Quality Assessment](https://arxiv.org/abs/2507.17182)
*Linghe Meng,Jiarun Song*

Main category: cs.CV

TL;DR: 本文提出了一个多级视觉表示范式来解决AI生成内容(AIGC)质量评估中的多维挑战，通过开发MGLF-Net和MPEF-Net两个网络，分别针对感知质量评估和文本-图像对应性评估，在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成内容质量评估方法通常依赖单级视觉特征，限制了它们捕捉AIGC图像中复杂失真的能力。AIGC质量评估面临从低级视觉感知到高级语义理解的多维挑战，需要更全面的评估方法。

Method: 提出了一个多级视觉表示范式，包含三个阶段：多级特征提取、分层融合和联合聚合。基于此范式开发了两个网络：1) MGLF-Net用于感知质量评估，通过双CNN和Transformer视觉骨干网络提取互补的局部和全局特征；2) MPEF-Net针对文本-图像对应性评估，将提示语义嵌入到各特征级别的视觉特征融合过程中。

Result: 在基准测试上的实验表明，两个网络在各自任务上都表现出色，验证了所提出的多级视觉评估范式的有效性。融合的多级特征经过聚合后能够进行最终评估。

Conclusion: 多级视觉表示范式有效解决了AIGC质量评估的多维挑战。通过多级特征提取、分层融合和联合聚合的三阶段方法，开发的MGLF-Net和MPEF-Net网络在感知质量评估和文本-图像对应性评估任务上都取得了优异性能，证明了该方法的有效性和实用性。

Abstract: The quality assessment of AI-generated content (AIGC) faces multi-dimensional
challenges, that span from low-level visual perception to high-level semantic
understanding. Existing methods generally rely on single-level visual features,
limiting their ability to capture complex distortions in AIGC images. To
address this limitation, a multi-level visual representation paradigm is
proposed with three stages, namely multi-level feature extraction, hierarchical
fusion, and joint aggregation. Based on this paradigm, two networks are
developed. Specifically, the Multi-Level Global-Local Fusion Network (MGLF-Net)
is designed for the perceptual quality assessment, extracting complementary
local and global features via dual CNN and Transformer visual backbones. The
Multi-Level Prompt-Embedded Fusion Network (MPEF-Net) targets Text-to-Image
correspondence by embedding prompt semantics into the visual feature fusion
process at each feature level. The fused multi-level features are then
aggregated for final evaluation. Experiments on benchmarks demonstrate
outstanding performance on both tasks, validating the effectiveness of the
proposed multi-level visual assessment paradigm.

</details>


### [31] [Asymmetric Lesion Detection with Geometric Patterns and CNN-SVM Classification](https://arxiv.org/abs/2507.17185)
*M. A. Rasel,Sameem Abdul Kareem,Zhenli Kwan,Nik Aimee Azizah Faheem,Winn Hui Han,Rebecca Kai Jan Choong,Shin Shen Yong,Unaizah Obaidellah*

Main category: cs.CV

TL;DR: 本文提出了一种基于皮肤镜图像的病灶形状分析方法，结合几何模式分析和CNN特征提取技术，用于辅助黑色素瘤诊断中的不对称病灶检测


<details>
  <summary>Details</summary>
Motivation: 在皮肤镜图像中，病灶形状的不对称性是诊断黑色素瘤的重要临床标准之一。现有方法缺乏有效的自动化技术来帮助非专家理解和识别不对称病灶的几何模式特征

Method: 首先基于临床评估对未标注数据集进行对称性信息标注；然后提出监督学习图像处理算法分析病灶形状的几何模式；最后利用预训练CNN从皮肤镜图像中提取形状、颜色和纹理特征，训练多类支持向量机(SVM)分类器

Result: 几何模式实验中，皮肤病不对称病灶检测率达到99.00%；CNN实验中，病灶形状分类(不对称、半对称、对称)的最佳性能为：Kappa分数94%、宏平均F1分数95%、加权F1分数97%

Conclusion: 提出的方法在病灶形状分析方面超越了现有文献中的最先进方法，为非专家提供了有效的不对称病灶识别工具，在黑色素瘤辅助诊断方面具有重要应用价值

Abstract: In dermoscopic images, which allow visualization of surface skin structures
not visible to the naked eye, lesion shape offers vital insights into skin
diseases. In clinically practiced methods, asymmetric lesion shape is one of
the criteria for diagnosing melanoma. Initially, we labeled data for a
non-annotated dataset with symmetrical information based on clinical
assessments. Subsequently, we propose a supporting technique, a supervised
learning image processing algorithm, to analyze the geometrical pattern of
lesion shape, aiding non-experts in understanding the criteria of an asymmetric
lesion. We then utilize a pre-trained convolutional neural network (CNN) to
extract shape, color, and texture features from dermoscopic images for training
a multiclass support vector machine (SVM) classifier, outperforming
state-of-the-art methods from the literature. In the geometry-based experiment,
we achieved a 99.00% detection rate for dermatological asymmetric lesions. In
the CNN-based experiment, the best performance is found with 94% Kappa Score,
95% Macro F1-score, and 97% Weighted F1-score for classifying lesion shapes
(Asymmetric, Half-Symmetric, and Symmetric).

</details>


### [32] [Vec2Face+ for Face Dataset Generation](https://arxiv.org/abs/2507.17192)
*Haiyu Wu,Jaskirat Singh,Sicong Tian,Liang Zheng,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 本文提出Vec2Face+生成模型，通过保持类内身份一致性的同时增加类内属性变化，生成高质量的人脸识别训练数据集，首次实现合成数据集在多个真实测试集上超越CASIA-WebFace的性能。


<details>
  <summary>Details</summary>
Motivation: 现有人脸合成方法在增加类内变化时忽略了维持类内身份一致性的必要性，导致合成数据集质量不高，无法有效训练人脸识别模型。

Method: 提出Vec2Face+生成模型，采用三种策略：1）采样足够不同的向量生成分离良好的身份；2）提出AttrOP算法增加通用属性变化；3）提出基于LoRA的姿态控制生成侧脸图像，比AttrOP更高效且更好地保持身份。

Result: 生成的VFace10K数据集（1万身份）使人脸识别模型在7个真实测试集上达到最先进精度；扩展至VFace100K和VFace300K数据集在5个真实测试集上超越CASIA-WebFace，这是首次合成数据集在平均精度上击败CASIA-WebFace。

Conclusion: Vec2Face+能够生成高质量的合成人脸数据集，在保持类间分离性和类内变化的同时维持身份一致性，首次实现合成数据集超越真实数据集的性能，但也发现合成身份训练的模型存在更多偏见等问题需要进一步研究。

Abstract: When synthesizing identities as face recognition training data, it is
generally believed that large inter-class separability and intra-class
attribute variation are essential for synthesizing a quality dataset. % This
belief is generally correct, and this is what we aim for. However, when
increasing intra-class variation, existing methods overlook the necessity of
maintaining intra-class identity consistency. % To address this and generate
high-quality face training data, we propose Vec2Face+, a generative model that
creates images directly from image features and allows for continuous and easy
control of face identities and attributes. Using Vec2Face+, we obtain datasets
with proper inter-class separability and intra-class variation and identity
consistency using three strategies: 1) we sample vectors sufficiently different
from others to generate well-separated identities; 2) we propose an AttrOP
algorithm for increasing general attribute variations; 3) we propose LoRA-based
pose control for generating images with profile head poses, which is more
efficient and identity-preserving than AttrOP. % Our system generates VFace10K,
a synthetic face dataset with 10K identities, which allows an FR model to
achieve state-of-the-art accuracy on seven real-world test sets. Scaling the
size to 4M and 12M images, the corresponding VFace100K and VFace300K datasets
yield higher accuracy than the real-world training dataset, CASIA-WebFace, on
five real-world test sets. This is the first time a synthetic dataset beats the
CASIA-WebFace in average accuracy. In addition, we find that only 1 out of 11
synthetic datasets outperforms random guessing (\emph{i.e., 50\%}) in twin
verification and that models trained with synthetic identities are more biased
than those trained with real identities. Both are important aspects for future
investigation.

</details>


### [33] [DesignLab: Designing Slides Through Iterative Detection and Correction](https://arxiv.org/abs/2507.17202)
*Jooyeol Yun,Heng Wang,Yotaro Shimose,Jaegul Choo,Shingo Takamatsu*

Main category: cs.CV

TL;DR: 本文提出DesignLab系统，通过将设计过程分解为设计审查者和设计贡献者两个角色，实现迭代式幻灯片设计优化，显著提升了自动化设计工具的输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化幻灯片设计工具虽然能够建议布局和配色方案，但缺乏自我完善能力，无法像真实工作流程那样对输出结果进行迭代优化，这对非专业用户来说是一个重大挑战。

Method: 提出DesignLab系统，将设计过程分解为两个角色：设计审查者（识别设计问题）和设计贡献者（修正问题）。通过微调大语言模型来实现这两个角色，并通过引入受控扰动来模拟中间草稿，让审查者学习识别设计错误，贡献者学习如何修复错误，形成持续的迭代优化循环。

Result: 实验表明DesignLab在设计生成方法上优于现有方法，包括商业工具。通过拥抱设计的迭代本质，能够产生精美、专业的幻灯片，达到了以前无法实现的质量水平。

Conclusion: 通过将设计过程分解为审查和贡献两个独立角色，并建立迭代优化机制，DesignLab成功解决了现有自动化设计工具缺乏自我完善能力的问题，为非专业用户提供了更高质量的幻灯片设计解决方案。

Abstract: Designing high-quality presentation slides can be challenging for non-experts
due to the complexity involved in navigating various design choices. Numerous
automated tools can suggest layouts and color schemes, yet often lack the
ability to refine their own output, which is a key aspect in real-world
workflows. We propose DesignLab, which separates the design process into two
roles, the design reviewer, who identifies design-related issues, and the
design contributor who corrects them. This decomposition enables an iterative
loop where the reviewer continuously detects issues and the contributor
corrects them, allowing a draft to be further polished with each iteration,
reaching qualities that were unattainable. We fine-tune large language models
for these roles and simulate intermediate drafts by introducing controlled
perturbations, enabling the design reviewer learn design errors and the
contributor learn how to fix them. Our experiments show that DesignLab
outperforms existing design-generation methods, including a commercial tool, by
embracing the iterative nature of designing which can result in polished,
professional slides.

</details>


### [34] [VBCD: A Voxel-Based Framework for Personalized Dental Crown Design](https://arxiv.org/abs/2507.17205)
*Linda Wei,Chang Liu,Wenran Zhang,Zengji Zhang,Shaoting Zhang,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于体素的自动化牙冠设计框架(VBCD)，通过粗糙-精细两阶段生成和距离感知监督，结合曲率边缘线惩罚损失和FDI位置提示，实现了个性化牙冠的自动化设计，在大规模数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的修复性牙冠设计需要牙科技师从口内扫描数据进行大量手工劳动，过程繁琐且耗时，因此需要开发自动化的牙冠设计方法来解决这一挑战。

Method: 提出基于体素的牙冠设计框架(VBCD)，包含两个主要组件：1)从体素化口内扫描生成初始粗糙牙冠；2)融合距离感知监督的精细化改进器提升精度和质量。训练阶段采用曲率和边缘线惩罚损失(CMPL)增强生成牙冠与边缘线的对齐，并引入基于FDI牙齿编号系统的位置提示。

Result: 在大规模口内扫描数据集上的评估表明，该方法优于现有方法，为个性化牙冠设计提供了鲁棒的解决方案。

Conclusion: VBCD框架成功实现了从口内扫描到牙冠设计的自动化流程，通过体素化表示、两阶段生成策略、专门设计的损失函数和位置提示机制，显著提升了牙冠设计的准确性和质量，为牙科修复领域提供了有效的自动化工具。

Abstract: The design of restorative dental crowns from intraoral scans is
labor-intensive for dental technicians. To address this challenge, we propose a
novel voxel-based framework for automated dental crown design (VBCD). The VBCD
framework generates an initial coarse dental crown from voxelized intraoral
scans, followed by a fine-grained refiner incorporating distance-aware
supervision to improve accuracy and quality. During the training stage, we
employ the Curvature and Margin line Penalty Loss (CMPL) to enhance the
alignment of the generated crown with the margin line. Additionally, a
positional prompt based on the FDI tooth numbering system is introduced to
further improve the accuracy of the generated dental crowns. Evaluation on a
large-scale dataset of intraoral scans demonstrated that our approach
outperforms existing methods, providing a robust solution for personalized
dental crown design.

</details>


### [35] [A Low-Cost Machine Learning Approach for Timber Diameter Estimation](https://arxiv.org/abs/2507.17219)
*Fatemeh Hasanzadeh Fard,Sanaz Hasanzadeh Fard,Mehdi Jonoobi*

Main category: cs.CV

TL;DR: 本研究开发了一个基于YOLOv5的木材原木直径自动估算系统，使用标准RGB图像在真实工业环境下工作，实现了0.64的mAP@0.5精度，为中小型木材加工企业提供了成本效益高的自动化解决方案。


<details>
  <summary>Details</summary>
Motivation: 木材加工行业中的物种识别和厚度测量传统上依赖专家人工操作，存在速度慢、不一致且容易出错的问题，特别是在大批量处理时。需要开发实用且成本效益高的机器学习框架来自动化木材原木直径估算。

Method: 采用YOLOv5目标检测算法，在公开数据集TimberSeg 1.0上进行微调，通过边界框尺寸来检测单个木材原木并估算厚度。模型使用在典型工业棚屋中木材交付期间拍摄的标准RGB图像进行训练，无需昂贵的传感器或受控环境。

Result: 实验结果显示模型达到了0.64的平均精度(mAP@0.5)，即使在有限的计算资源下也能实现可靠的原木检测。该轻量级、可扩展的解决方案适合实际集成到现有工作流程中。

Conclusion: 该研究提供了一个实用的机器学习解决方案，能够在真实工业条件下自动估算木材原木直径，特别适用于中小型木材加工企业的现场库存管理和初步分拣，具有良好的实用价值和推广前景。

Abstract: The wood processing industry, particularly in facilities such as sawmills and
MDF production lines, requires accurate and efficient identification of species
and thickness of the wood. Although traditional methods rely heavily on expert
human labor, they are slow, inconsistent, and prone to error, especially when
processing large volumes. This study focuses on practical and cost-effective
machine learning frameworks that automate the estimation of timber log diameter
using standard RGB images captured under real-world working conditions. We
employ the YOLOv5 object detection algorithm, fine-tuned on a public dataset
(TimberSeg 1.0), to detect individual timber logs and estimate thickness
through bounding-box dimensions. Unlike previous methods that require expensive
sensors or controlled environments, this model is trained on images taken in
typical industrial sheds during timber delivery. Experimental results show that
the model achieves a mean Average Precision (mAP@0.5) of 0.64, demonstrating
reliable log detection even with modest computing resources. This lightweight,
scalable solution holds promise for practical integration into existing
workflows, including on-site inventory management and preliminary sorting,
particularly in small and medium-sized operations.

</details>


### [36] [PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models](https://arxiv.org/abs/2507.17220)
*Jiansong Wan,Chengming Zhou,Jinkua Liu,Xiangge Huang,Xiaoyu Chen,Xiaohan Yi,Qisen Yang,Baiting Zhu,Xin-Qiang Cai,Lixing Liu,Rushuai Yang,Chuheng Zhang,Sherif Abdelfattah,Hayong Shin,Pushi Zhang,Li Zhao,Jiang Bian*

Main category: cs.CV

TL;DR: 本文提出PIG-Nav，一种预训练的视觉目标导航模型，通过早期融合网络结构和辅助任务设计，以及利用游戏视频数据集的新颖预处理管道，在零样本和微调设置下相比现有模型分别提升22.6%和37.5%的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉导航模型在跨环境泛化能力和零样本性能方面仍有不足，需要进一步探索更有效的预训练策略和数据利用方法，以实现更好的导航性能和实际部署潜力。

Method: 提出PIG-Nav方法，包含两个关键设计：（1）采用早期融合网络结构，通过预训练的ViT图像编码器结合视觉观察和目标图像；（2）引入合适的辅助任务增强全局导航表征学习。此外，开发了一个新颖的数据预处理管道，用于高效标注大规模游戏视频数据集用于导航模型训练。

Result: 在两个复杂仿真环境和一个真实环境中，模型在零样本设置下平均提升22.6%，在微调设置下提升37.5%。模型在需要显著更少微调数据的情况下仍保持竞争性能，展现了在最少标注监督下的实际部署潜力。

Conclusion: PIG-Nav成功推进了预训练图像目标导航模型的最新技术水平，通过改进的网络架构设计、辅助任务学习和数据增强策略，实现了显著的性能提升，为实际机器人导航应用提供了更有效的解决方案。

Abstract: Recent studies have explored pretrained (foundation) models for vision-based
robotic navigation, aiming to achieve generalizable navigation and positive
transfer across diverse environments while enhancing zero-shot performance in
unseen settings. In this work, we introduce PIG-Nav (Pretrained Image-Goal
Navigation), a new approach that further investigates pretraining strategies
for vision-based navigation models and contributes in two key areas.
Model-wise, we identify two critical design choices that consistently improve
the performance of pretrained navigation models: (1) integrating an
early-fusion network structure to combine visual observations and goal images
via appropriately pretrained Vision Transformer (ViT) image encoder, and (2)
introducing suitable auxiliary tasks to enhance global navigation
representation learning, thus further improving navigation performance.
Dataset-wise, we propose a novel data preprocessing pipeline for efficiently
labeling large-scale game video datasets for navigation model training. We
demonstrate that augmenting existing open navigation datasets with diverse
gameplay videos improves model performance. Our model achieves an average
improvement of 22.6% in zero-shot settings and a 37.5% improvement in
fine-tuning settings over existing visual navigation foundation models in two
complex simulated environments and one real-world environment. These results
advance the state-of-the-art in pretrained image-goal navigation models.
Notably, our model maintains competitive performance while requiring
significantly less fine-tuning data, highlighting its potential for real-world
deployment with minimal labeled supervision.

</details>


### [37] [MaskedCLIP: Bridging the Masked and CLIP Space for Semi-Supervised Medical Vision-Language Pre-training](https://arxiv.org/abs/2507.17239)
*Lei Zhu,Jun Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.CV

TL;DR: 提出了MaskedCLIP框架，通过结合掩码图像建模和对比语言-图像预训练，在半监督视觉-语言预训练中同时利用配对和非配对图像数据，学习更通用的图像特征用于医学图像分析


<details>
  <summary>Details</summary>
Motivation: 现有基础模型要么仅使用配对图像-文本数据进行视觉-语言预训练，要么仅使用非配对图像数据进行自监督预训练，这限制了模型学习更丰富和全面图像特征的能力。需要充分利用配对和非配对图像数据的潜力

Method: 提出MaskedCLIP框架，结合掩码图像建模和对比语言-图像预训练进行半监督视觉-语言预训练。使用桥接变换器连接掩码特征空间和CLIP特征空间，并提出掩码知识蒸馏损失将CLIP特征空间中的语义知识蒸馏回掩码特征空间

Result: 在视网膜图像分析上的大量实验证明了该方法的有效性和数据效率，能够有效利用配对和非配对图像数据学习更通用的图像特征

Conclusion: MaskedCLIP通过创新的互动设计有效结合了配对和非配对图像数据，克服了不兼容特征空间的挑战，为医学图像分析中的基础模型学习提供了新的解决方案

Abstract: Foundation models have recently gained tremendous popularity in medical image
analysis. State-of-the-art methods leverage either paired image-text data via
vision-language pre-training or unpaired image data via self-supervised
pre-training to learn foundation models with generalizable image features to
boost downstream task performance. However, learning foundation models
exclusively on either paired or unpaired image data limits their ability to
learn richer and more comprehensive image features. In this paper, we
investigate a novel task termed semi-supervised vision-language pre-training,
aiming to fully harness the potential of both paired and unpaired image data
for foundation model learning. To this end, we propose MaskedCLIP, a
synergistic masked image modeling and contrastive language-image pre-training
framework for semi-supervised vision-language pre-training. The key challenge
in combining paired and unpaired image data for learning a foundation model
lies in the incompatible feature spaces derived from these two types of data.
To address this issue, we propose to connect the masked feature space with the
CLIP feature space with a bridge transformer. In this way, the more semantic
specific CLIP features can benefit from the more general masked features for
semantic feature extraction. We further propose a masked knowledge distillation
loss to distill semantic knowledge of original image features in CLIP feature
space back to the predicted masked image features in masked feature space. With
this mutually interactive design, our framework effectively leverages both
paired and unpaired image data to learn more generalizable image features for
downstream tasks. Extensive experiments on retinal image analysis demonstrate
the effectiveness and data efficiency of our method.

</details>


### [38] [Perceptual Classifiers: Detecting Generative Images using Perceptual Features](https://arxiv.org/abs/2507.17240)
*Krishna Srikar Durbha,Asvin Kumar Venkataramanan,Rajesh Sureddi,Alan C. Bovik*

Main category: cs.CV

TL;DR: 本研究利用图像质量评估(IQA)模型的特征空间来检测AI生成的图像，通过两层网络在多种生成模型上实现了最先进的假图像检测性能，同时对图像退化具有显著的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的快速发展，互联网上AI生成内容大量涌现，现有的GenAI内容检测方法虽有进步但仍需改进。研究者发现IQA模型能够有效捕捉真实图像在带通统计空间中的流形特征，因此希望利用这一能力来区分真实图像和AI生成图像。

Method: 研究采用现有的图像质量评估(IQA)模型作为特征提取器，利用其能够捕捉真实图像流形的能力。在IQA模型的特征空间基础上，训练一个两层神经网络来进行GenAI图像检测分类任务。

Result: 基于IQA模型特征空间训练的两层网络在检测来自不同生成模型的假图像方面表现出最先进的性能，同时对各种图像退化具有显著的鲁棒性，展现出良好的泛化能力。

Conclusion: IQA模型的特征表示能够有效用于GenAI图像检测任务，通过简单的两层网络架构就能实现优异的检测性能和鲁棒性，为AI生成内容检测提供了一种新的有效方法。

Abstract: Image Quality Assessment (IQA) models are employed in many practical image
and video processing pipelines to reduce storage, minimize transmission costs,
and improve the Quality of Experience (QoE) of millions of viewers. These
models are sensitive to a diverse range of image distortions and can accurately
predict image quality as judged by human viewers. Recent advancements in
generative models have resulted in a significant influx of "GenAI" content on
the internet. Existing methods for detecting GenAI content have progressed
significantly with improved generalization performance on images from unseen
generative models. Here, we leverage the capabilities of existing IQA models,
which effectively capture the manifold of real images within a bandpass
statistical space, to distinguish between real and AI-generated images. We
investigate the generalization ability of these perceptual classifiers to the
task of GenAI image detection and evaluate their robustness against various
image degradations. Our results show that a two-layer network trained on the
feature space of IQA models demonstrates state-of-the-art performance in
detecting fake images across generative models, while maintaining significant
robustness against image degradations.

</details>


### [39] [Unsupervised Exposure Correction](https://arxiv.org/abs/2507.17252)
*Ruodai Cui,Li Niu,Guosheng Hu*

Main category: cs.CV

TL;DR: 本文提出了一种无监督曝光校正(UEC)方法，无需人工标注，利用模拟图像信号处理管道的配对数据进行训练，在保持图像细节的同时仅使用最先进监督方法0.01%的参数量就达到了更好的性能，并在边缘检测等下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有曝光校正方法面临三个挑战：劳动密集型配对数据标注、泛化能力有限、以及在低级计算机视觉任务中性能下降。需要一种无需人工标注、泛化性更强、在下游任务中表现更好的曝光校正方法。

Method: 提出无监督曝光校正(UEC)方法，使用模拟图像信号处理(ISP)管道的免费配对数据进行训练；构建大规模辐射校正数据集，专门强调曝光变化以促进无监督学习；开发保持图像细节的变换函数，参数量仅为监督方法的0.01%。

Result: 所提方法在保持图像细节方面表现优异，仅使用最先进监督方法0.01%的参数量就超越了其性能；在边缘检测等下游任务中有效缓解了不良曝光对低级特征的负面影响；提供了公开可用的源代码和数据集。

Conclusion: 无监督曝光校正方法成功解决了传统方法的三个主要挑战：消除了人工标注需求，提高了泛化能力，增强了在低级计算机视觉下游任务中的性能，为曝光校正领域提供了一个更实用和高效的解决方案。

Abstract: Current exposure correction methods have three challenges, labor-intensive
paired data annotation, limited generalizability, and performance degradation
in low-level computer vision tasks. In this work, we introduce an innovative
Unsupervised Exposure Correction (UEC) method that eliminates the need for
manual annotations, offers improved generalizability, and enhances performance
in low-level downstream tasks. Our model is trained using freely available
paired data from an emulated Image Signal Processing (ISP) pipeline. This
approach does not need expensive manual annotations, thereby minimizing
individual style biases from the annotation and consequently improving its
generalizability. Furthermore, we present a large-scale Radiometry Correction
Dataset, specifically designed to emphasize exposure variations, to facilitate
unsupervised learning. In addition, we develop a transformation function that
preserves image details and outperforms state-of-the-art supervised methods
[12], while utilizing only 0.01% of their parameters. Our work further
investigates the broader impact of exposure correction on downstream tasks,
including edge detection, demonstrating its effectiveness in mitigating the
adverse effects of poor exposure on low-level features. The source code and
dataset are publicly available at https://github.com/BeyondHeaven/uec_code.

</details>


### [40] [VisionTrap: Unanswerable Questions On Visual Data](https://arxiv.org/abs/2507.17262)
*Asir Saadat,Syem Aziz,Shahriar Mahmud,Abdullah Ibne Masud Mahi,Sabbir Ahmed*

Main category: cs.CV

TL;DR: 该研究探讨视觉语言模型在面对无法回答的问题时的表现，引入VisionTrap数据集测试模型是否能识别自身知识局限性并适当拒绝回答


<details>
  <summary>Details</summary>
Motivation: 现有VQA研究主要关注模型如何回答基于真实图像的可回答问题，但对模型如何处理无法回答的问题缺乏深入探索，特别是在模型应该拒绝回答的情况下

Method: 构建VisionTrap数据集，包含三类无法回答的问题：(1)融合物体和动物的混合实体，(2)处于非常规或不可能场景中的物体，(3)虚构或不存在的人物。测试模型是否能正确识别自身局限性

Result: 研究发现将此类问题纳入VQA基准测试的重要性，用于评估模型是否倾向于强行回答本应拒绝的问题

Conclusion: 强调了在VQA基准测试中加入无法回答问题的重要性，以评估模型在应该拒绝回答时是否仍倾向于提供答案

Abstract: Visual Question Answering (VQA) has been a widely studied topic, with
extensive research focusing on how VLMs respond to answerable questions based
on real-world images. However, there has been limited exploration of how these
models handle unanswerable questions, particularly in cases where they should
abstain from providing a response. This research investigates VQA performance
on unrealistically generated images or asking unanswerable questions, assessing
whether models recognize the limitations of their knowledge or attempt to
generate incorrect answers. We introduced a dataset, VisionTrap, comprising
three categories of unanswerable questions across diverse image types: (1)
hybrid entities that fuse objects and animals, (2) objects depicted in
unconventional or impossible scenarios, and (3) fictional or non-existent
figures. The questions posed are logically structured yet inherently
unanswerable, testing whether models can correctly recognize their limitations.
Our findings highlight the importance of incorporating such questions into VQA
benchmarks to evaluate whether models tend to answer, even when they should
abstain.

</details>


### [41] [PolarAnything: Diffusion-based Polarimetric Image Synthesis](https://arxiv.org/abs/2507.17268)
*Kailong Zhang,Youwei Lyu,Heng Guo,Si Li,Zhanyu Ma,Boxin Shi*

Main category: cs.CV

TL;DR: 提出了PolarAnything方法，能够从单张RGB图像生成具有真实感和物理准确性的偏振图像，解决了现有偏振相机可获得性有限和偏振图像合成困难的问题


<details>
  <summary>Details</summary>
Motivation: 偏振图像在图像增强和3D重建任务中很有用，但偏振相机的有限可获得性阻碍了其广泛应用。现有的偏振模拟器Mitsuba依赖参数化偏振图像形成模型，需要大量3D资产（包括形状和PBR材料），无法生成大规模真实感图像

Method: 提出基于扩散模型的生成框架PolarAnything，利用预训练扩散模型的零样本性能，引入有效的表示策略来保持偏振特性的保真度，能够从单张RGB输入合成偏振图像

Result: 实验表明该模型能够生成高质量的偏振图像，并支持基于偏振的形状重建等下游任务

Conclusion: PolarAnything成功解决了偏振图像合成的关键问题，消除了对3D资产集合的依赖，实现了从单张RGB图像生成具有真实感和物理准确性的偏振图像

Abstract: Polarization images facilitate image enhancement and 3D reconstruction tasks,
but the limited accessibility of polarization cameras hinders their broader
application. This gap drives the need for synthesizing photorealistic
polarization images.The existing polarization simulator Mitsuba relies on a
parametric polarization image formation model and requires extensive 3D assets
covering shape and PBR materials, preventing it from generating large-scale
photorealistic images. To address this problem, we propose PolarAnything,
capable of synthesizing polarization images from a single RGB input with both
photorealism and physical accuracy, eliminating the dependency on 3D asset
collections. Drawing inspiration from the zero-shot performance of pretrained
diffusion models, we introduce a diffusion-based generative framework with an
effective representation strategy that preserves the fidelity of polarization
properties. Experiments show that our model generates high-quality polarization
images and supports downstream tasks like shape from polarization.

</details>


### [42] [Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation](https://arxiv.org/abs/2507.17281)
*Huanli Zhuo,Leilei Ma,Haifeng Zhao,Shiwei Zhou,Dengdi Sun,Yanping Fu*

Main category: cs.CV

TL;DR: FA-SAM是一个针对医学图像分割的单源域泛化框架，通过自动生成提示和融合图像-提示嵌入来实现完全自动化的SAM分割，解决了SAM依赖专家标注提示和错误提示影响分割效果的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的医学图像分割模型面临两个主要挑战：1）SAM高度依赖领域特定的专家标注提示，阻碍了完全自动化的医学图像分割；2）提供不良提示（如过小或过大的边界框）会误导SAM生成错误的掩码结果，限制了其在临床环境中的应用。

Method: 提出FA-SAM框架，包含两个关键创新：1）配备浅层特征不确定性建模（SUFM）模块的自动提示生成模型（AGM）分支，通过建模浅层特征的不确定性分布来为目标域生成边界框提示；2）集成到SAM掩码解码器中的图像-提示嵌入融合（IPEF）模块，融合SAM图像嵌入和提示嵌入的多尺度信息来捕获目标对象的全局和局部细节。

Result: 在公开的前列腺和眼底血管数据集上进行的广泛实验验证了FA-SAM的有效性，证明了该方法在解决上述挑战方面的潜力。

Conclusion: FA-SAM成功实现了完全自动化的SAM医学图像分割，通过自动提示生成和图像-提示嵌入融合有效缓解了SAM对专家标注提示的依赖以及不良提示对分割性能的负面影响，为医学图像分割在临床应用中的部署提供了有效解决方案。

Abstract: Although SAM-based single-source domain generalization models for medical
image segmentation can mitigate the impact of domain shift on the model in
cross-domain scenarios, these models still face two major challenges. First,
the segmentation of SAM is highly dependent on domain-specific expert-annotated
prompts, which prevents SAM from achieving fully automated medical image
segmentation and therefore limits its application in clinical settings. Second,
providing poor prompts (such as bounding boxes that are too small or too large)
to the SAM prompt encoder can mislead SAM into generating incorrect mask
results. Therefore, we propose the FA-SAM, a single-source domain
generalization framework for medical image segmentation that achieves fully
automated SAM. FA-SAM introduces two key innovations: an Auto-prompted
Generation Model (AGM) branch equipped with a Shallow Feature Uncertainty
Modeling (SUFM) module, and an Image-Prompt Embedding Fusion (IPEF) module
integrated into the SAM mask decoder. Specifically, AGM models the uncertainty
distribution of shallow features through the SUFM module to generate bounding
box prompts for the target domain, enabling fully automated segmentation with
SAM. The IPEF module integrates multiscale information from SAM image
embeddings and prompt embeddings to capture global and local details of the
target object, enabling SAM to mitigate the impact of poor prompts. Extensive
experiments on publicly available prostate and fundus vessel datasets validate
the effectiveness of FA-SAM and highlight its potential to address the above
challenges.

</details>


### [43] [PointLAMA: Latent Attention meets Mamba for Efficient Point Cloud Pretraining](https://arxiv.org/abs/2507.17296)
*Xuanyu Lin,Xiaona Zeng,Xianwei Zheng,Xutao Li*

Main category: cs.CV

TL;DR: PointLAMA是一个点云预训练框架，结合了任务感知的点云序列化、混合编码器（集成潜在注意力和Mamba块）以及基于Mamba主干的条件扩散机制，在保持高效率的同时提升了点云建模的局部几何结构捕获能力。


<details>
  <summary>Details</summary>
Motivation: Mamba模型在点云建模中缺乏局部归纳偏置，限制了其捕获3D数据中精细几何结构的能力。现有方法在全局序列建模效率和局部几何特征提取之间存在权衡问题。

Method: 提出PointLAMA框架，包含三个核心组件：1）任务感知的点云序列化，使用Hilbert/Trans-Hilbert空间填充曲线和轴向排序来结构化对齐点标记；2）混合编码器，集成轻量级潜在注意力块和Mamba块，其中点级多头潜在注意力（PMLA）模块专门设计用于与Mamba架构对齐；3）条件扩散机制，在预训练期间对扰动的特征序列进行去噪，无需依赖显式的点级重建。

Result: 在多个基准数据集上取得了竞争性性能，同时保持了最小的参数数量和FLOPs，验证了该方法在高效点云预训练方面的有效性。实验结果表明PointLAMA成功平衡了效率和性能。

Conclusion: PointLAMA成功解决了Mamba在点云建模中缺乏局部归纳偏置的问题，通过创新的混合架构设计和条件扩散预训练策略，实现了高效的点云表示学习，为点云建模提供了一个有效的预训练框架。

Abstract: Mamba has recently gained widespread attention as a backbone model for point
cloud modeling, leveraging a state-space architecture that enables efficient
global sequence modeling with linear complexity. However, its lack of local
inductive bias limits its capacity to capture fine-grained geometric structures
in 3D data. To address this limitation, we propose \textbf{PointLAMA}, a point
cloud pretraining framework that combines task-aware point cloud serialization,
a hybrid encoder with integrated Latent Attention and Mamba blocks, and a
conditional diffusion mechanism built upon the Mamba backbone. Specifically,
the task-aware point cloud serialization employs Hilbert/Trans-Hilbert
space-filling curves and axis-wise sorting to structurally align point tokens
for classification and segmentation tasks, respectively. Our lightweight Latent
Attention block features a Point-wise Multi-head Latent Attention (PMLA)
module, which is specifically designed to align with the Mamba architecture by
leveraging the shared latent space characteristics of PMLA and Mamba. This
enables enhanced local context modeling while preserving overall efficiency. To
further enhance representation learning, we incorporate a conditional diffusion
mechanism during pretraining, which denoises perturbed feature sequences
without relying on explicit point-wise reconstruction. Experimental results
demonstrate that PointLAMA achieves competitive performance on multiple
benchmark datasets with minimal parameter count and FLOPs, validating its
effectiveness for efficient point cloud pretraining.

</details>


### [44] [VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization](https://arxiv.org/abs/2507.17455)
*Sania Waheed,Na Min An,Michael Milford,Sarvapali D. Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 该论文提出了一种结合视觉-语言模型(VLM)和检索式视觉位置识别(VPR)的混合地理定位框架，通过VLM生成地理先验来指导检索搜索空间，再结合重排序机制提升单图像全球尺度地理定位的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于检索的地理定位方法存在可扩展性和感知混淆问题，基于分类的方法缺乏泛化能力且需要大量训练数据。虽然视觉-语言模型在地理定位方面表现出色，但容易产生幻觉且缺乏可解释性，作为独立解决方案不够可靠。因此需要一种结合两者优势的混合框架。

Method: 提出混合地理定位框架：首先利用VLM生成地理先验来指导和约束检索搜索空间；然后执行检索步骤；最后采用重排序机制，基于特征相似性和与初始估计坐标的接近程度选择最符合地理合理性的匹配结果。

Result: 在多个地理定位基准测试中评估，该方法持续超越先前的最先进方法，特别是在街道级别（提升高达4.51%）和城市级别（提升高达13.52%）的准确性方面表现突出。

Conclusion: VLM生成的地理先验与VPR相结合能够构建可扩展、鲁棒且准确的地理定位系统，有效解决了单一方法的局限性，为全球尺度的单图像地理定位提供了可靠的解决方案。

Abstract: Geo-localization from a single image at planet scale (essentially an advanced
or extreme version of the kidnapped robot problem) is a fundamental and
challenging task in applications such as navigation, autonomous driving and
disaster response due to the vast diversity of locations, environmental
conditions, and scene variations. Traditional retrieval-based methods for
geo-localization struggle with scalability and perceptual aliasing, while
classification-based approaches lack generalization and require extensive
training data. Recent advances in vision-language models (VLMs) offer a
promising alternative by leveraging contextual understanding and reasoning.
However, while VLMs achieve high accuracy, they are often prone to
hallucinations and lack interpretability, making them unreliable as standalone
solutions. In this work, we propose a novel hybrid geo-localization framework
that combines the strengths of VLMs with retrieval-based visual place
recognition (VPR) methods. Our approach first leverages a VLM to generate a
prior, effectively guiding and constraining the retrieval search space. We then
employ a retrieval step, followed by a re-ranking mechanism that selects the
most geographically plausible matches based on feature similarity and proximity
to the initially estimated coordinates. We evaluate our approach on multiple
geo-localization benchmarks and show that it consistently outperforms prior
state-of-the-art methods, particularly at street (up to 4.51%) and city level
(up to 13.52%). Our results demonstrate that VLM-generated geographic priors in
combination with VPR lead to scalable, robust, and accurate geo-localization
systems.

</details>


### [45] [Learning-based Stage Verification System in Manual Assembly Scenarios](https://arxiv.org/abs/2507.17304)
*Xingjian Zhang,Yutong Duan,Zaishu Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种基于多机器学习模型的工业4.0装配过程监控方法，仅使用最少的视觉传感器就能实现92%以上的准确率，有效降低了对昂贵硬件的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统的装配过程监控方法通常需要多种传感器类型或复杂的硬件设置才能达到高精度，这在成本和动态工业环境实施方面存在挑战。因此需要开发一种仅依赖最少视觉传感器的高精度监控方案。

Method: 提出了一种基于多机器学习模型的新方法，通过整合相同时间戳的状态信息来检测和确认装配过程的当前阶段，同时提供增强的错误检测和可视化功能。

Result: 该方法在装配过程监控中实现了平均超过92%的准确率，在错误检测和可视化能力方面超越了传统方法，能够为操作员提供实时、可操作的指导。

Conclusion: 该方法不仅提高了装配监控的准确性和效率，还减少了对昂贵硬件解决方案的依赖，使其成为现代工业应用中更实用的选择。

Abstract: In the context of Industry 4.0, effective monitoring of multiple targets and
states during assembly processes is crucial, particularly when constrained to
using only visual sensors. Traditional methods often rely on either multiple
sensor types or complex hardware setups to achieve high accuracy in monitoring,
which can be cost-prohibitive and difficult to implement in dynamic industrial
environments. This study presents a novel approach that leverages multiple
machine learning models to achieve precise monitoring under the limitation of
using a minimal number of visual sensors. By integrating state information from
identical timestamps, our method detects and confirms the current stage of the
assembly process with an average accuracy exceeding 92%. Furthermore, our
approach surpasses conventional methods by offering enhanced error detection
and visuali-zation capabilities, providing real-time, actionable guidance to
operators. This not only improves the accuracy and efficiency of assembly
monitoring but also re-duces dependency on expensive hardware solutions, making
it a more practical choice for modern industrial applications.

</details>


### [46] [CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance](https://arxiv.org/abs/2507.17312)
*Peiqi Chen,Lei Yu,Yi Wan,Yingying Pei,Xinyi Liu,Yongxiang Yao,Yingying Zhang,Lixiang Ru,Liheng Zhong,Jingdong Chen,Ming Yang,Yongjun Zhang*

Main category: cs.CV

TL;DR: 提出了CasP方法，通过级联对应先验来改进半密集特征匹配，采用两阶段渐进式匹配和区域选择性交叉注意力机制，在提高精度的同时显著提升了计算效率


<details>
  <summary>Details</summary>
Motivation: 现有半密集特征匹配方法依赖全局搜索来建立粗匹配，这种方式限制了精度和效率的进一步提升，特别是在高分辨率场景下计算成本过高

Method: 提出CasP管道，将匹配阶段分解为两个渐进阶段：第一阶段识别一对多先验区域，第二阶段在限制的搜索范围内确定一对一匹配；采用区域选择性交叉注意力机制增强特征判别能力；结合高级特征降低低级特征提取的计算成本

Result: 在1152分辨率下，轻量级模型相比最高效方法ELoFTR实现约2.2倍加速；在几何估计任务中表现优异，特别是在跨域泛化方面；加速增益随分辨率提高而增加

Conclusion: CasP方法成功解决了半密集特征匹配中精度与效率的平衡问题，通过级联先验指导和两阶段匹配策略，实现了显著的性能提升，特别适用于SLAM和无人机系统等对延迟敏感且需要高鲁棒性的应用场景

Abstract: Semi-dense feature matching methods have shown strong performance in
challenging scenarios. However, the existing pipeline relies on a global search
across the entire feature map to establish coarse matches, limiting further
improvements in accuracy and efficiency. Motivated by this limitation, we
propose a novel pipeline, CasP, which leverages cascaded correspondence priors
for guidance. Specifically, the matching stage is decomposed into two
progressive phases, bridged by a region-based selective cross-attention
mechanism designed to enhance feature discriminability. In the second phase,
one-to-one matches are determined by restricting the search range to the
one-to-many prior areas identified in the first phase. Additionally, this
pipeline benefits from incorporating high-level features, which helps reduce
the computational costs of low-level feature extraction. The acceleration gains
of CasP increase with higher resolution, and our lite model achieves a speedup
of $\sim2.2\times$ at a resolution of 1152 compared to the most efficient
method, ELoFTR. Furthermore, extensive experiments demonstrate its superiority
in geometric estimation, particularly with impressive cross-domain
generalization. These advantages highlight its potential for latency-sensitive
and high-robustness applications, such as SLAM and UAV systems. Code is
available at https://github.com/pq-chen/CasP.

</details>


### [47] [From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding](https://arxiv.org/abs/2507.17585)
*Anna-Maria Halacheva,Jan-Nico Zaech,Sombit Dey,Luc Van Gool,Danda Pani Paudel*

Main category: cs.CV

TL;DR: 本文提出了一种基于USD的统一标注集成方法，用于有效利用真实世界3D场景扫描数据，并在LLM场景编辑和机器人仿真两个下游应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 真实世界3D场景级扫描数据虽然具有真实性并能提高下游应用的泛化能力，但面临数据体量大、标注格式多样化、工具兼容性等挑战，限制了其实际应用。

Method: 提出基于USD（Universal Scene Description）的统一标注集成方法，开发应用特定的USD变体，识别并制定了利用整体真实世界扫描数据集的挑战缓解策略。

Result: 在两个下游应用中验证了方法的有效性：LLM场景编辑任务达到80%的成功率，机器人仿真中的策略学习达到87%的成功率。

Conclusion: 所提出的USD统一标注集成方法能够有效解决真实世界3D场景扫描数据的利用挑战，为LLM场景理解和机器人仿真等应用提供了可行的解决方案。

Abstract: Real-world 3D scene-level scans offer realism and can enable better
real-world generalizability for downstream applications. However, challenges
such as data volume, diverse annotation formats, and tool compatibility limit
their use. This paper demonstrates a methodology to effectively leverage these
scans and their annotations. We propose a unified annotation integration using
USD, with application-specific USD flavors. We identify challenges in utilizing
holistic real-world scan datasets and present mitigation strategies. The
efficacy of our approach is demonstrated through two downstream applications:
LLM-based scene editing, enabling effective LLM understanding and adaptation of
the data (80% success), and robotic simulation, achieving an 87% success rate
in policy learning.

</details>


### [48] [CartoonAlive: Towards Expressive Live2D Modeling from Single Portraits](https://arxiv.org/abs/2507.17327)
*Chao He,Jianqiang Ren,Jianjing Xiang,Xiejie Shen*

Main category: cs.CV

TL;DR: CartoonAlive是一种从单张肖像图片快速生成高质量Live2D数字人的创新方法，能在30秒内创建具有高表现力和视觉准确性的交互式2D卡通角色。


<details>
  <summary>Details</summary>
Motivation: 当前数字人技术主要集中在3D模型和2D视频表示上，而交互式2D卡通风格数字人关注度较低。相比于需要复杂建模和高渲染成本的3D数字人，以及缺乏灵活性和实时交互性的2D视频方案，Live2D模型提供了更高效和富有表现力的替代方案。

Method: CartoonAlive利用3D面部建模中常用的形状基础概念来构建适合Live2D的面部混合形状，然后基于从输入图像检测到的面部关键点推断相应的混合形状权重，通过分层分割模拟类似3D的运动而无需传统3D建模。

Result: 该方法能够在不到半分钟的时间内快速生成与输入肖像高度相似的Live2D模型，具有高表现力和视觉准确性，实现了动态和实时操控。

Conclusion: CartoonAlive为创建交互式2D卡通角色提供了实用且可扩展的解决方案，在数字内容创作和虚拟角色动画领域开辟了新的可能性。

Abstract: With the rapid advancement of large foundation models, AIGC, cloud rendering,
and real-time motion capture technologies, digital humans are now capable of
achieving synchronized facial expressions and body movements, engaging in
intelligent dialogues driven by natural language, and enabling the fast
creation of personalized avatars. While current mainstream approaches to
digital humans primarily focus on 3D models and 2D video-based representations,
interactive 2D cartoon-style digital humans have received relatively less
attention. Compared to 3D digital humans that require complex modeling and high
rendering costs, and 2D video-based solutions that lack flexibility and
real-time interactivity, 2D cartoon-style Live2D models offer a more efficient
and expressive alternative. By simulating 3D-like motion through layered
segmentation without the need for traditional 3D modeling, Live2D enables
dynamic and real-time manipulation. In this technical report, we present
CartoonAlive, an innovative method for generating high-quality Live2D digital
humans from a single input portrait image. CartoonAlive leverages the shape
basis concept commonly used in 3D face modeling to construct facial blendshapes
suitable for Live2D. It then infers the corresponding blendshape weights based
on facial keypoints detected from the input image. This approach allows for the
rapid generation of a highly expressive and visually accurate Live2D model that
closely resembles the input portrait, within less than half a minute. Our work
provides a practical and scalable solution for creating interactive 2D cartoon
characters, opening new possibilities in digital content creation and virtual
character animation. The project homepage is
https://human3daigc.github.io/CartoonAlive_webpage/.

</details>


### [49] [PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.17596)
*Maciej K. Wozniak,Lianhang Liu,Yixi Cai,Patric Jensfelt*

Main category: cs.CV

TL;DR: PRIX是一个仅使用相机数据的端到端自动驾驶模型，通过新颖的Context-aware Recalibration Transformer (CaRT)模块直接从原始像素预测安全轨迹，在保持最先进性能的同时显著提高了效率，使其更适合实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶模型存在模型体积大、依赖昂贵的LiDAR传感器、需要计算密集的BEV特征表示等问题，限制了其在仅配备相机的大众市场车辆中的可扩展性和实际部署。

Method: 提出PRIX架构，仅使用相机数据运行，无需显式BEV表示和LiDAR。核心组件包括视觉特征提取器和生成式规划头，以及新颖的Context-aware Recalibration Transformer (CaRT)模块来增强多级视觉特征以实现更稳健的规划。

Result: 在NavSim和nuScenes基准测试中达到最先进性能，与更大的多模态扩散规划器性能相匹配，但在推理速度和模型大小方面显著更高效。

Conclusion: PRIX为实际部署提供了一个实用的解决方案，证明了仅使用相机数据就能实现高效且高性能的端到端自动驾驶，代码将开源发布。

Abstract: While end-to-end autonomous driving models show promising results, their
practical deployment is often hindered by large model sizes, a reliance on
expensive LiDAR sensors and computationally intensive BEV feature
representations. This limits their scalability, especially for mass-market
vehicles equipped only with cameras. To address these challenges, we propose
PRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving
architecture operates using only camera data, without explicit BEV
representation and forgoing the need for LiDAR. PRIX leverages a visual feature
extractor coupled with a generative planning head to predict safe trajectories
from raw pixel inputs directly. A core component of our architecture is the
Context-aware Recalibration Transformer (CaRT), a novel module designed to
effectively enhance multi-level visual features for more robust planning. We
demonstrate through comprehensive experiments that PRIX achieves
state-of-the-art performance on the NavSim and nuScenes benchmarks, matching
the capabilities of larger, multimodal diffusion planners while being
significantly more efficient in terms of inference speed and model size, making
it a practical solution for real-world deployment. Our work is open-source and
the code will be at https://maxiuw.github.io/prix.

</details>


### [50] [PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image](https://arxiv.org/abs/2507.17332)
*Hyeongjin Nam,Donghwan Kim,Gyeongsik Moon,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: PARTE是一个利用3D人体部位信息来重建高质量人体纹理的框架，通过部位分割和部位引导纹理模块解决了现有方法中人体不同部位纹理错位的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体重建方法存在人体不同部位纹理错位的问题，如夹克和裤子的纹理会混合在一起。人体部位的结构一致性是推断单张图像中不可见区域纹理的重要线索，但大多数现有方法没有明确利用这种部位分割先验知识。

Method: 提出PARTE框架，包含两个核心组件：1) 3D部位分割模块(PartSegmenter)：从单张图像推断3D人体部位信息，首先重建无纹理的人体表面，然后基于该表面预测人体部位标签；2) 部位引导纹理模块(PartTexturer)：将部位信息融入纹理重建，从预训练的图像生成网络中获取人体部位纹理对齐的先验知识。

Result: 大量实验表明该框架在3D人体重建质量方面达到了最先进的水平。

Conclusion: 通过明确利用3D人体部位信息作为关键指导，PARTE成功解决了3D人体重建中的纹理错位问题，实现了更高质量的人体纹理重建效果。

Abstract: The misaligned human texture across different human parts is one of the main
limitations of existing 3D human reconstruction methods. Each human part, such
as a jacket or pants, should maintain a distinct texture without blending into
others. The structural coherence of human parts serves as a crucial cue to
infer human textures in the invisible regions of a single image. However, most
existing 3D human reconstruction methods do not explicitly exploit such part
segmentation priors, leading to misaligned textures in their reconstructions.
In this regard, we present PARTE, which utilizes 3D human part information as a
key guide to reconstruct 3D human textures. Our framework comprises two core
components. First, to infer 3D human part information from a single image, we
propose a 3D part segmentation module (PartSegmenter) that initially
reconstructs a textureless human surface and predicts human part labels based
on the textureless surface. Second, to incorporate part information into
texture reconstruction, we introduce a part-guided texturing module
(PartTexturer), which acquires prior knowledge from a pre-trained image
generation network on texture alignment of human parts. Extensive experiments
demonstrate that our framework achieves state-of-the-art quality in 3D human
reconstruction. The project page is available at
https://hygenie1228.github.io/PARTE/.

</details>


### [51] [Monocular Semantic Scene Completion via Masked Recurrent Networks](https://arxiv.org/abs/2507.17661)
*Xuzhi Wang,Xinran Wu,Song Wang,Lingdong Kong,Ziping Zhao*

Main category: cs.CV

TL;DR: 提出了MonoMRN框架，将单目语义场景补全分解为两阶段：粗略补全和掩码循环网络细化，通过MS-GRU和距离注意力投影机制显著提升了室内外场景的语义补全性能


<details>
  <summary>Details</summary>
Motivation: 现有单目语义场景补全方法采用单阶段框架同时处理可见区域分割和遮挡区域推理，受到深度估计不准确的影响，在复杂场景中性能欠佳，需要更有效的解决方案

Method: 提出两阶段框架：1）粗略单目语义场景补全；2）掩码循环网络细化。核心组件包括掩码稀疏门控循环单元(MS-GRU)，通过掩码更新机制专注于占用区域，稀疏GRU设计降低计算成本；距离注意力投影根据到观测表面的距离分配不同注意力分数以减少投影误差

Result: 在NYUv2和SemanticKITTI数据集上达到最先进性能，有效支持室内外场景，鲁棒性分析显示掩码循环网络增强了模型对各种干扰的抵抗能力

Conclusion: MonoMRN通过两阶段分解和创新的掩码循环机制成功解决了单目语义场景补全的挑战，在多个基准数据集上取得突破性性能，证明了该方法的有效性和鲁棒性

Abstract: Monocular Semantic Scene Completion (MSSC) aims to predict the voxel-wise
occupancy and semantic category from a single-view RGB image. Existing methods
adopt a single-stage framework that aims to simultaneously achieve visible
region segmentation and occluded region hallucination, while also being
affected by inaccurate depth estimation. Such methods often achieve suboptimal
performance, especially in complex scenes. We propose a novel two-stage
framework that decomposes MSSC into coarse MSSC followed by the Masked
Recurrent Network. Specifically, we propose the Masked Sparse Gated Recurrent
Unit (MS-GRU) which concentrates on the occupied regions by the proposed mask
updating mechanism, and a sparse GRU design is proposed to reduce the
computation cost. Additionally, we propose the distance attention projection to
reduce projection errors by assigning different attention scores according to
the distance to the observed surface. Experimental results demonstrate that our
proposed unified framework, MonoMRN, effectively supports both indoor and
outdoor scenes and achieves state-of-the-art performance on the NYUv2 and
SemanticKITTI datasets. Furthermore, we conduct robustness analysis under
various disturbances, highlighting the role of the Masked Recurrent Network in
enhancing the model's resilience to such challenges. The source code is
publicly available.

</details>


### [52] [Temporal Point-Supervised Signal Reconstruction: A Human-Annotation-Free Framework for Weak Moving Target Detection](https://arxiv.org/abs/2507.17334)
*Weihua Gao,Chunxu Ren,Wenlong Niu,Xiaodong Peng*

Main category: cs.CV

TL;DR: 提出了一种时间点监督(TPS)框架，通过时序信号重构网络(TSRNet)和动态多尺度注意力机制，实现了低空监控系统中弱运动目标的无标注高性能检测


<details>
  <summary>Details</summary>
Motivation: 低空监控预警系统中弱运动目标检测面临信号能量低、空间范围小、背景杂波复杂等挑战，现有方法在鲁棒特征提取方面存在困难，且缺乏可靠的标注数据

Method: 提出时间点监督(TPS)框架，将检测任务重新表述为像素级时序信号建模问题；开发时序信号重构网络(TSRNet)，采用编码器-解码器架构并集成动态多尺度注意力模块；采用基于图的轨迹挖掘策略抑制虚警并确保时序一致性

Result: 在专门构建的低信噪比数据集上的实验表明，该框架在无需人工标注的情况下超越了最先进的方法，实现了强大的检测性能，运行速度超过1000 FPS

Conclusion: 所提出的TPS框架成功解决了弱运动目标检测中的关键挑战，在保持高检测性能的同时实现了实时处理能力，为实际场景的部署展现了巨大潜力

Abstract: In low-altitude surveillance and early warning systems, detecting weak moving
targets remains a significant challenge due to low signal energy, small spatial
extent, and complex background clutter. Existing methods struggle with
extracting robust features and suffer from the lack of reliable annotations. To
address these limitations, we propose a novel Temporal Point-Supervised (TPS)
framework that enables high-performance detection of weak targets without any
manual annotations.Instead of conventional frame-based detection, our framework
reformulates the task as a pixel-wise temporal signal modeling problem, where
weak targets manifest as short-duration pulse-like responses. A Temporal Signal
Reconstruction Network (TSRNet) is developed under the TPS paradigm to
reconstruct these transient signals.TSRNet adopts an encoder-decoder
architecture and integrates a Dynamic Multi-Scale Attention (DMSAttention)
module to enhance its sensitivity to diverse temporal patterns. Additionally, a
graph-based trajectory mining strategy is employed to suppress false alarms and
ensure temporal consistency.Extensive experiments on a purpose-built low-SNR
dataset demonstrate that our framework outperforms state-of-the-art methods
while requiring no human annotations. It achieves strong detection performance
and operates at over 1000 FPS, underscoring its potential for real-time
deployment in practical scenarios.

</details>


### [53] [Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras](https://arxiv.org/abs/2507.17664)
*Lingdong Kong,Dongyue Lu,Ao Liang,Rong Li,Yuhao Dong,Tianshuai Hu,Lai Xing Ng,Wei Tsang Ooi,Benoit R. Cottereau*

Main category: cs.CV

TL;DR: 本文提出了Talk2Event，这是首个大规模事件相机语言引导目标定位基准数据集，包含超过30,000个验证的指称表达式，并开发了EventRefer框架，通过混合事件-属性专家网络实现多属性表示的动态融合


<details>
  <summary>Details</summary>
Motivation: 事件相机具有微秒级延迟和运动模糊鲁棒性，适合理解动态环境，但将异步事件流与人类语言连接仍是开放挑战。现有研究缺乏大规模的语言驱动事件感知基准数据集

Method: 构建了Talk2Event基准数据集，包含真实驾驶数据中的30,000+指称表达式，每个表达式都包含外观、状态、与观察者关系、与其他物体关系四个定位属性。提出EventRefer框架，采用混合事件-属性专家网络(MoEE)动态融合多属性表示

Result: 在仅事件、仅帧、事件-帧融合三种设置下，相比最先进基线方法都取得了一致的性能提升。方法能够适应不同模态和场景动态

Conclusion: 建立了首个大规模事件相机语言定位基准，为推进多模态、时序感知、语言驱动的真实世界机器人和自主系统感知奠定了基础

Abstract: Event cameras offer microsecond-level latency and robustness to motion blur,
making them ideal for understanding dynamic environments. Yet, connecting these
asynchronous streams to human language remains an open challenge. We introduce
Talk2Event, the first large-scale benchmark for language-driven object
grounding in event-based perception. Built from real-world driving data, we
provide over 30,000 validated referring expressions, each enriched with four
grounding attributes -- appearance, status, relation to viewer, and relation to
other objects -- bridging spatial, temporal, and relational reasoning. To fully
exploit these cues, we propose EventRefer, an attribute-aware grounding
framework that dynamically fuses multi-attribute representations through a
Mixture of Event-Attribute Experts (MoEE). Our method adapts to different
modalities and scene dynamics, achieving consistent gains over state-of-the-art
baselines in event-only, frame-only, and event-frame fusion settings. We hope
our dataset and approach will establish a foundation for advancing multimodal,
temporally-aware, and language-driven perception in real-world robotics and
autonomy.

</details>


### [54] [TransLPRNet: Lite Vision-Language Network for Single/Dual-line Chinese License Plate Recognition](https://arxiv.org/abs/2507.17335)
*Guangzhu Xu,Zhi Ke,Pengcheng Zuo,Bangjun Lei*

Main category: cs.CV

TL;DR: 提出了一种统一的车牌识别解决方案，结合轻量级视觉编码器和文本解码器，通过预训练框架处理单双行中文车牌，引入透视校正网络提升识别精度，在CCPD测试集上达到99.34%-99.58%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有CNN和CRNN方法在车牌识别中存在局限性，开放环境下车牌类型多样性和成像条件复杂性带来挑战，双行车牌数据集稀缺问题需要解决。

Method: 构建了一个统一框架，集成轻量级视觉编码器和文本解码器的预训练模型；通过图像合成、纹理映射和真实车牌图像融合构建单双行车牌数据集；引入透视校正网络(PTN)，采用车牌角点坐标回归作为隐变量，由车牌视角分类信息监督。

Result: 在粗定位干扰下的CCPD测试集上达到99.34%平均识别准确率，精定位干扰下提升至99.58%；双行车牌测试集上达到98.70%平均识别准确率；处理速度高达167帧/秒。

Conclusion: 提出的算法在单双行中文车牌识别任务中表现优异，透视校正网络提供了更好的稳定性、可解释性和低标注成本，具有强大的实用性和应用前景。

Abstract: License plate recognition in open environments is widely applicable across
various domains; however, the diversity of license plate types and imaging
conditions presents significant challenges. To address the limitations
encountered by CNN and CRNN-based approaches in license plate recognition, this
paper proposes a unified solution that integrates a lightweight visual encoder
with a text decoder, within a pre-training framework tailored for single and
double-line Chinese license plates. To mitigate the scarcity of double-line
license plate datasets, we constructed a single/double-line license plate
dataset by synthesizing images, applying texture mapping onto real scenes, and
blending them with authentic license plate images. Furthermore, to enhance the
system's recognition accuracy, we introduce a perspective correction network
(PTN) that employs license plate corner coordinate regression as an implicit
variable, supervised by license plate view classification information. This
network offers improved stability, interpretability, and low annotation costs.
The proposed algorithm achieves an average recognition accuracy of 99.34% on
the corrected CCPD test set under coarse localization disturbance. When
evaluated under fine localization disturbance, the accuracy further improves to
99.58%. On the double-line license plate test set, it achieves an average
recognition accuracy of 98.70%, with processing speeds reaching up to 167
frames per second, indicating strong practical applicability.

</details>


### [55] [Perspective-Invariant 3D Object Detection](https://arxiv.org/abs/2507.17665)
*Ao Liang,Lingdong Kong,Dongyue Lu,Youquan Liu,Jian Fang,Huaici Zhao,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: 本文介绍了Pi3DET，首个包含车辆、四足机器人和无人机多平台LiDAR数据的3D目标检测基准数据集，并提出跨平台适应框架，实现从车辆平台向其他平台的知识迁移，为开发通用化3D感知系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有3D目标检测数据集和方法主要专注于车载平台，其他自主平台研究不足。为填补这一空白，需要构建多平台数据集并研究跨平台3D检测方法，以促进非车辆平台的3D目标检测研究和跨平台检测技术发展。

Method: 构建Pi3DET多平台基准数据集，包含车辆、四足机器人和无人机三个平台的LiDAR数据和3D边界框标注。提出跨平台适应框架，通过几何和特征层面的鲁棒对齐实现透视不变的3D检测，将车辆平台的知识迁移到其他平台。建立基准测试评估当前3D检测器在跨平台场景下的适应性和鲁棒性。

Result: 在具有挑战性的跨平台任务上进行广泛实验，验证了所提方法的有效性，相比现有适应方法取得显著提升。建立了跨平台3D检测的基准测试，为开发自适应3D感知系统提供有价值的见解。

Conclusion: 本工作为开发可泛化的统一3D感知系统铺平道路，能够适应多样化和复杂的环境。Pi3DET数据集、跨平台基准测试套件和标注工具包已公开发布，将促进跨平台3D目标检测领域的进一步研究发展。

Abstract: With the rise of robotics, LiDAR-based 3D object detection has garnered
significant attention in both academia and industry. However, existing datasets
and methods predominantly focus on vehicle-mounted platforms, leaving other
autonomous platforms underexplored. To bridge this gap, we introduce Pi3DET,
the first benchmark featuring LiDAR data and 3D bounding box annotations
collected from multiple platforms: vehicle, quadruped, and drone, thereby
facilitating research in 3D object detection for non-vehicle platforms as well
as cross-platform 3D detection. Based on Pi3DET, we propose a novel
cross-platform adaptation framework that transfers knowledge from the
well-studied vehicle platform to other platforms. This framework achieves
perspective-invariant 3D detection through robust alignment at both geometric
and feature levels. Additionally, we establish a benchmark to evaluate the
resilience and robustness of current 3D detectors in cross-platform scenarios,
providing valuable insights for developing adaptive 3D perception systems.
Extensive experiments validate the effectiveness of our approach on challenging
cross-platform tasks, demonstrating substantial gains over existing adaptation
methods. We hope this work paves the way for generalizable and unified 3D
perception systems across diverse and complex environments. Our Pi3DET dataset,
cross-platform benchmark suite, and annotation toolkit have been made publicly
available.

</details>


### [56] [DeMo++: Motion Decoupling for Autonomous Driving](https://arxiv.org/abs/2507.17342)
*Bozhou Zhang,Nan Song,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: DeMo++是一个将运动估计解耦为整体运动意图和精细时空状态两个组件的框架，结合注意力机制和Mamba架构，在多个自动驾驶基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的运动预测和规划方法采用一查询一轨迹范式，虽然能产生多样化的运动意图，但在建模轨迹复杂的时空演化方面存在不足，可能导致碰撞或次优结果。

Method: 提出DeMo++框架，将运动估计解耦为两个组件：捕获多样化潜在运动方向的整体运动意图，以及跟踪智能体场景内动态进展的精细时空状态。引入跨场景轨迹交互机制探索相邻场景中运动之间的关系。开发了结合注意力机制和Mamba的混合模型架构。

Result: 在多个基准测试中取得最先进性能，包括运动预测（Argoverse 2和nuScenes）、运动规划（nuPlan）和端到端规划（NAVSIM）。

Conclusion: DeMo++通过解耦运动估计和引入跨场景交互机制，能够全面建模运动意图的多样性和每个轨迹的时空演化，有效提升了自动驾驶系统中运动预测和规划的安全性和效率。

Abstract: Motion forecasting and planning are tasked with estimating the trajectories
of traffic agents and the ego vehicle, respectively, to ensure the safety and
efficiency of autonomous driving systems in dynamically changing environments.
State-of-the-art methods typically adopt a one-query-one-trajectory paradigm,
where each query corresponds to a unique trajectory for predicting multi-mode
trajectories. While this paradigm can produce diverse motion intentions, it
often falls short in modeling the intricate spatiotemporal evolution of
trajectories, which can lead to collisions or suboptimal outcomes. To overcome
this limitation, we propose DeMo++, a framework that decouples motion
estimation into two distinct components: holistic motion intentions to capture
the diverse potential directions of movement, and fine spatiotemporal states to
track the agent's dynamic progress within the scene and enable a
self-refinement capability. Further, we introduce a cross-scene trajectory
interaction mechanism to explore the relationships between motions in adjacent
scenes. This allows DeMo++ to comprehensively model both the diversity of
motion intentions and the spatiotemporal evolution of each trajectory. To
effectively implement this framework, we developed a hybrid model combining
Attention and Mamba. This architecture leverages the strengths of both
mechanisms for efficient scene information aggregation and precise trajectory
state sequence modeling. Extensive experiments demonstrate that DeMo++ achieves
state-of-the-art performance across various benchmarks, including motion
forecasting (Argoverse 2 and nuScenes), motion planning (nuPlan), and
end-to-end planning (NAVSIM).

</details>


### [57] [Principled Multimodal Representation Learning](https://arxiv.org/abs/2507.17343)
*Xiaohao Liu,Xiaobo Xia,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态表示学习框架PMRL，通过优化表示矩阵的主奇异值实现多模态的同步对齐，无需依赖锚点模态，解决了传统方法的局限性和不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 传统的多模态表示学习方法依赖成对对比学习和预定义的锚点模态，限制了所有模态间的对齐效果。现有的多模态同步对齐方法存在固定锚点限制和奇异值乘积优化导致的不稳定性问题。

Method: 提出PMRL框架，基于完全对齐对应于rank-1格拉姆矩阵的理论洞察，通过优化表示矩阵的主奇异值来沿共享主方向对齐模态。使用基于softmax的损失函数将奇异值作为logits来优先考虑最大奇异值，并采用主特征向量的实例对比正则化来维持实例间分离性并防止表示坍塌。

Result: 在多种任务上的广泛实验表明，PMRL相比基线方法表现出优越性能，有效实现了多模态的稳定对齐。

Conclusion: PMRL成功解决了多模态表示学习中的锚点依赖和优化不稳定问题，为多模态理解提供了更有效的统一表示空间，在多个任务上验证了其有效性。

Abstract: Multimodal representation learning seeks to create a unified representation
space by integrating diverse data modalities to improve multimodal
understanding. Traditional methods often depend on pairwise contrastive
learning, which relies on a predefined anchor modality, restricting alignment
across all modalities. Recent advances have investigated the simultaneous
alignment of multiple modalities, yet several challenges remain, such as
limitations imposed by fixed anchor points and instability arising from
optimizing the product of singular values. To address the challenges, in this
paper, we propose Principled Multimodal Representation Learning (PMRL), a novel
framework that achieves simultaneous alignment of multiple modalities without
anchor dependency in a more stable manner. Specifically, grounded in the
theoretical insight that full alignment corresponds to a rank-1 Gram matrix,
PMRL optimizes the dominant singular value of the representation matrix to
align modalities along a shared leading direction. We propose a softmax-based
loss function that treats singular values as logits to prioritize the largest
singular value. Besides, instance-wise contrastive regularization on the
leading eigenvectors maintains inter-instance separability and prevents
representation collapse. Extensive experiments across diverse tasks demonstrate
PMRL's superiority compared to baseline methods. The source code will be
publicly available.

</details>


### [58] [Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation](https://arxiv.org/abs/2507.17347)
*Haotian Chen,Zhiyong Xiao*

Main category: cs.CV

TL;DR: 本文提出了Swin-TUNA，一种参数高效的食品图像语义分割方法，通过在Swin Transformer中集成多尺度可训练适配器，仅更新4%的参数就实现了优于FoodSAM的性能，同时将参数量减少98.7%。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模Transformer模型（如FoodSAM）在食品图像处理中面临参数量庞大、计算资源需求高的问题，难以满足实际部署需求，因此需要开发高效的轻量化语义分割技术。

Method: 提出TUNable Adapter模块（Swin-TUNA），这是一种参数高效微调（PEFT）方法，将多尺度可训练适配器集成到Swin Transformer架构中。核心创新包括：1）分层特征适应机制；2）设计深度可分离卷积和不同尺度的维度映射来处理浅层和深层网络特征差异；3）任务无关和任务特定特征的动态平衡策略。

Result: 在FoodSeg103数据集上达到50.56% mIoU，在UECFoodPix Complete数据集上达到74.94% mIoU，超越了完全参数化的FoodSAM模型，同时参数量减少98.7%（仅8.13M参数）。此外，该方法在低数据场景下表现出更快的收敛速度和更强的泛化能力。

Conclusion: Swin-TUNA为轻量化食品图像语义分割提供了高效解决方案，通过参数高效微调技术成功平衡了模型性能与计算效率，为食品图像处理的工业应用提供了实用的部署方案。

Abstract: In the field of food image processing, efficient semantic segmentation
techniques are crucial for industrial applications. However, existing
large-scale Transformer-based models (such as FoodSAM) face challenges in
meeting practical deploymentrequirements due to their massive parameter counts
and high computational resource demands. This paper introduces TUNable Adapter
module (Swin-TUNA), a Parameter Efficient Fine-Tuning (PEFT) method that
integrates multiscale trainable adapters into the Swin Transformer
architecture, achieving high-performance food image segmentation by updating
only 4% of the parameters. The core innovation of Swin-TUNA lies in its
hierarchical feature adaptation mechanism: it designs separable convolutions in
depth and dimensional mappings of varying scales to address the differences in
features between shallow and deep networks, combined with a dynamic balancing
strategy for tasks-agnostic and task-specific features. Experiments demonstrate
that this method achieves mIoU of 50.56% and 74.94% on the FoodSeg103 and
UECFoodPix Complete datasets, respectively, surpassing the fully parameterized
FoodSAM model while reducing the parameter count by 98.7% (to only 8.13M).
Furthermore, Swin-TUNA exhibits faster convergence and stronger generalization
capabilities in low-data scenarios, providing an efficient solution for
assembling lightweight food image.

</details>


### [59] [Exploring Active Learning for Label-Efficient Training of Semantic Neural Radiance Field](https://arxiv.org/abs/2507.17351)
*Yuzhe Zhu,Lile Cai,Kangkang Lu,Fayao Liu,Xulei Yang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种主动学习方法来减少语义感知NeRF训练中的标注成本，通过考虑3D几何约束的新颖选择策略，相比随机采样实现了超过2倍的标注成本减少。


<details>
  <summary>Details</summary>
Motivation: 语义感知NeRF的训练通常需要像素级类别标签，这种标注成本极其昂贵且难以获取，因此需要探索主动学习方法来减轻标注负担。

Method: 研究了语义感知NeRF主动学习的各种设计选择，包括选择粒度和选择策略，并提出了一种考虑3D几何约束的新颖主动学习策略来进行样本选择。

Result: 实验表明主动学习能够有效减少训练语义感知NeRF的标注成本，相比随机采样实现了超过2倍的标注成本减少。

Conclusion: 主动学习是解决语义感知NeRF标注成本过高问题的有效方案，特别是结合3D几何约束的选择策略能够显著提高标注效率。

Abstract: Neural Radiance Field (NeRF) models are implicit neural scene representation
methods that offer unprecedented capabilities in novel view synthesis.
Semantically-aware NeRFs not only capture the shape and radiance of a scene,
but also encode semantic information of the scene. The training of
semantically-aware NeRFs typically requires pixel-level class labels, which can
be prohibitively expensive to collect. In this work, we explore active learning
as a potential solution to alleviate the annotation burden. We investigate
various design choices for active learning of semantically-aware NeRF,
including selection granularity and selection strategies. We further propose a
novel active learning strategy that takes into account 3D geometric constraints
in sample selection. Our experiments demonstrate that active learning can
effectively reduce the annotation cost of training semantically-aware NeRF,
achieving more than 2X reduction in annotation cost compared to random
sampling.

</details>


### [60] [Exploring Active Learning for Semiconductor Defect Segmentation](https://arxiv.org/abs/2507.17359)
*Lile Cai,Ramanpreet Singh Pahwa,Xun Xu,Jie Wang,Richard Chang,Lining Zhang,Chuan-Sheng Foo*

Main category: cs.CV

TL;DR: 本文提出了一种主动学习方法来减少半导体X射线显微镜扫描图像语义分割任务中的标注负担，通过对比预训练和稀有性感知的采样函数来解决领域偏移和类别不平衡问题


<details>
  <summary>Details</summary>
Motivation: 深度学习模型需要大量标注数据进行训练，在半导体XRM扫描的语义分割任务中获取标注数据耗时且昂贵，因此需要通过主动学习来减少标注负担

Method: 提出了针对半导体XRM扫描的主动学习方法：(1)在未标注数据上进行对比预训练获得初始化权重；(2)设计稀有性感知的采样函数，优先选择包含稀有类别的样本

Result: 在由高带宽存储器结构的XRM扫描组成的半导体数据集上评估，该方法达到了最先进的性能表现

Conclusion: 所提出的主动学习方法能够有效解决半导体XRM扫描中的大域偏移和严重类别不平衡问题，在减少标注负担的同时实现优秀的语义分割性能

Abstract: The development of X-Ray microscopy (XRM) technology has enabled
non-destructive inspection of semiconductor structures for defect
identification. Deep learning is widely used as the state-of-the-art approach
to perform visual analysis tasks. However, deep learning based models require
large amount of annotated data to train. This can be time-consuming and
expensive to obtain especially for dense prediction tasks like semantic
segmentation. In this work, we explore active learning (AL) as a potential
solution to alleviate the annotation burden. We identify two unique challenges
when applying AL on semiconductor XRM scans: large domain shift and severe
class-imbalance. To address these challenges, we propose to perform contrastive
pretraining on the unlabelled data to obtain the initialization weights for
each AL cycle, and a rareness-aware acquisition function that favors the
selection of samples containing rare classes. We evaluate our method on a
semiconductor dataset that is compiled from XRM scans of high bandwidth memory
structures composed of logic and memory dies, and demonstrate that our method
achieves state-of-the-art performance.

</details>


### [61] [Exploring Spatial Diversity for Region-based Active Learning](https://arxiv.org/abs/2507.17367)
*Lile Cai,Xun Xu,Lining Zhang,Chuan-Sheng Foo*

Main category: cs.CV

TL;DR: 本文提出了一种基于区域的主动学习框架，通过结合空间多样性和传统的不确定性选择标准来减少语义分割任务的标注成本，仅使用5-9%的标注像素就能达到全监督方法95%的性能。


<details>
  <summary>Details</summary>
Motivation: 语义分割任务需要大规模标注数据集，但获取像素级标注成本高昂。现有的基于区域的主动学习方法未充分考虑空间多样性，导致选择的区域可能过于集中，影响学习效果。

Method: 提出了一个统一的优化框架，将局部空间多样性与传统的主动选择标准（如数据样本不确定性）相结合，用于基于区域的主动学习。该方法选择信息量大且空间分布多样的图像区域进行标注，而非整张图像。

Result: 在Cityscapes和PASCAL VOC数据集上的实验表明，加入空间多样性有效提升了基于不确定性和特征多样性的主动学习方法性能。该框架仅使用5-9%的标注像素就达到了全监督方法95%的性能，超越了所有现有的基于区域的语义分割主动学习方法。

Conclusion: 通过在主动学习中强制执行局部空间多样性，可以显著提高基于区域的语义分割主动学习的效果，大幅降低标注成本的同时保持高性能，为解决语义分割任务中的标注瓶颈提供了有效解决方案。

Abstract: State-of-the-art methods for semantic segmentation are based on deep neural
networks trained on large-scale labeled datasets. Acquiring such datasets would
incur large annotation costs, especially for dense pixel-level prediction tasks
like semantic segmentation. We consider region-based active learning as a
strategy to reduce annotation costs while maintaining high performance. In this
setting, batches of informative image regions instead of entire images are
selected for labeling. Importantly, we propose that enforcing local spatial
diversity is beneficial for active learning in this case, and to incorporate
spatial diversity along with the traditional active selection criterion, e.g.,
data sample uncertainty, in a unified optimization framework for region-based
active learning. We apply this framework to the Cityscapes and PASCAL VOC
datasets and demonstrate that the inclusion of spatial diversity effectively
improves the performance of uncertainty-based and feature diversity-based
active learning methods. Our framework achieves $95\%$ performance of fully
supervised methods with only $5-9\%$ of the labeled pixels, outperforming all
state-of-the-art region-based active learning methods for semantic
segmentation.

</details>


### [62] [SFUOD: Source-Free Unknown Object Detection](https://arxiv.org/abs/2507.17373)
*Keon-Hee Park,Seun-An Choe,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: 提出了一种无源未知目标检测(SFUOD)方法CollaPAUL，能够在不使用源域标记数据的情况下，既检测已知目标又发现未定义的未知目标，通过协作调优和基于主轴的未知标记实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无源目标检测方法局限于封闭集设置，只能检测源域中预定义的目标，无法发现目标域中的未定义目标。为了缓解这一限制，需要开发能够同时识别已知目标和检测未知目标的方法。

Method: 提出CollaPAUL框架，包含两个核心组件：1）协作调优：通过跨域注意力机制整合辅助编码器的目标域相关知识和预训练检测器的源域相关知识；2）基于主轴的未知标记：通过主轴投影估计目标性并结合模型预测的置信度分数为未知目标分配伪标签。

Result: 在SFUOD基准测试中实现了最先进的性能，大量实验验证了方法的有效性，能够成功检测已知目标并发现未知目标。

Conclusion: CollaPAUL成功解决了无源目标检测中的未知目标发现问题，通过协作调优和主轴未知标记机制，在保持已知目标检测性能的同时有效识别未知目标，为实际应用中的开放世界目标检测提供了新的解决方案。

Abstract: Source-free object detection adapts a detector pre-trained on a source domain
to an unlabeled target domain without requiring access to labeled source data.
While this setting is practical as it eliminates the need for the source
dataset during domain adaptation, it operates under the restrictive assumption
that only pre-defined objects from the source domain exist in the target
domain. This closed-set setting prevents the detector from detecting undefined
objects. To ease this assumption, we propose Source-Free Unknown Object
Detection (SFUOD), a novel scenario which enables the detector to not only
recognize known objects but also detect undefined objects as unknown objects.
To this end, we propose CollaPAUL (Collaborative tuning and Principal
Axis-based Unknown Labeling), a novel framework for SFUOD. Collaborative tuning
enhances knowledge adaptation by integrating target-dependent knowledge from
the auxiliary encoder with source-dependent knowledge from the pre-trained
detector through a cross-domain attention mechanism. Additionally, principal
axes-based unknown labeling assigns pseudo-labels to unknown objects by
estimating objectness via principal axes projection and confidence scores from
model predictions. The proposed CollaPAUL achieves state-of-the-art
performances on SFUOD benchmarks, and extensive experiments validate its
effectiveness.

</details>


### [63] [A Conditional Probability Framework for Compositional Zero-shot Learning](https://arxiv.org/abs/2507.17377)
*Peng Wu,Qiuxia Lai,Hao Fang,Guo-Sen Xie,Yilong Yin,Xiankai Lu,Wenguan Wang*

Main category: cs.CV

TL;DR: 本文提出了一个条件概率框架(CPF)来解决组合零样本学习中属性-对象依赖性建模问题，通过分解组合概率为对象似然和条件属性似然，并使用文本描述符增强对象特征学习，最终在多个基准数据集上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统的组合零样本学习方法将属性和对象视为独立实体进行学习，忽略了组合内部的语义约束和上下文依赖关系。例如，某些属性天然与特定对象配对，同一属性在不同上下文中表现不同，因此捕获属性-对象相互依赖性是CZSL中一个基础但长期被忽视的挑战。

Method: 采用条件概率框架(CPF)显式建模属性-对象依赖关系，将组合概率分解为对象似然和条件属性似然两部分。引入文本描述符来增强对象特征学习，突出语义相关的图像区域。增强的对象特征通过交叉注意力机制指导属性学习，确保更好的上下文对齐。联合优化对象似然和条件属性似然。

Result: 在多个CZSL基准数据集上进行的大量实验证明了该方法的优越性，能够有效捕获组合依赖关系并很好地泛化到未见过的组合。

Conclusion: 通过条件概率框架显式建模属性-对象依赖关系，结合文本描述符增强的对象特征和交叉注意力机制，该方法成功解决了组合零样本学习中的核心挑战，在识别未见组合方面表现出色。

Abstract: Compositional Zero-Shot Learning (CZSL) aims to recognize unseen combinations
of known objects and attributes by leveraging knowledge from previously seen
compositions. Traditional approaches primarily focus on disentangling
attributes and objects, treating them as independent entities during learning.
However, this assumption overlooks the semantic constraints and contextual
dependencies inside a composition. For example, certain attributes naturally
pair with specific objects (e.g., "striped" applies to "zebra" or "shirts" but
not "sky" or "water"), while the same attribute can manifest differently
depending on context (e.g., "young" in "young tree" vs. "young dog"). Thus,
capturing attribute-object interdependence remains a fundamental yet
long-ignored challenge in CZSL. In this paper, we adopt a Conditional
Probability Framework (CPF) to explicitly model attribute-object dependencies.
We decompose the probability of a composition into two components: the
likelihood of an object and the conditional likelihood of its attribute. To
enhance object feature learning, we incorporate textual descriptors to
highlight semantically relevant image regions. These enhanced object features
then guide attribute learning through a cross-attention mechanism, ensuring
better contextual alignment. By jointly optimizing object likelihood and
conditional attribute likelihood, our method effectively captures compositional
dependencies and generalizes well to unseen compositions. Extensive experiments
on multiple CZSL benchmarks demonstrate the superiority of our approach. Code
is available at here.

</details>


### [64] [EndoGen: Conditional Autoregressive Endoscopic Video Generation](https://arxiv.org/abs/2507.17388)
*Xinyu Liu,Hengyu Liu,Cheng Wang,Tianming Liu,Yixuan Yuan*

Main category: cs.CV

TL;DR: 本文提出了首个条件内镜视频生成框架EndoGen，通过自回归模型和时空网格帧模式化策略，实现高质量的条件引导内镜视频生成，并提升下游息肉分割任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有内镜视频生成方法要么局限于静态图像缺乏动态上下文，要么依赖无条件生成无法为临床医生提供有意义的参考，因此需要开发条件内镜视频生成框架来推进医学影像和增强诊断能力。

Method: 构建了带有定制时空网格帧模式化(SGP)策略的自回归模型，将多帧生成学习重新表述为基于网格的图像生成模式；提出语义感知令牌掩码(SAT)机制，通过在生成过程中选择性关注语义有意义的区域来增强模型产生丰富多样内容的能力。

Result: 通过广泛实验证明了框架在生成高质量条件引导内镜内容方面的有效性，并改善了下游息肉分割任务的性能表现。

Conclusion: EndoGen作为首个条件内镜视频生成框架，成功结合了时空网格帧模式化和语义感知令牌掩码技术，实现了高质量的条件内镜视频生成，为医学影像诊断提供了有价值的工具。

Abstract: Endoscopic video generation is crucial for advancing medical imaging and
enhancing diagnostic capabilities. However, prior efforts in this field have
either focused on static images, lacking the dynamic context required for
practical applications, or have relied on unconditional generation that fails
to provide meaningful references for clinicians. Therefore, in this paper, we
propose the first conditional endoscopic video generation framework, namely
EndoGen. Specifically, we build an autoregressive model with a tailored
Spatiotemporal Grid-Frame Patterning (SGP) strategy. It reformulates the
learning of generating multiple frames as a grid-based image generation
pattern, which effectively capitalizes the inherent global dependency modeling
capabilities of autoregressive architectures. Furthermore, we propose a
Semantic-Aware Token Masking (SAT) mechanism, which enhances the model's
ability to produce rich and diverse content by selectively focusing on
semantically meaningful regions during the generation process. Through
extensive experiments, we demonstrate the effectiveness of our framework in
generating high-quality, conditionally guided endoscopic content, and improves
the performance of downstream task of polyp segmentation. Code released at
https://www.github.com/CUHK-AIM-Group/EndoGen.

</details>


### [65] [HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs](https://arxiv.org/abs/2507.17394)
*Zhaolin Cai,Fan Li,Ziwei Zheng,Yanjun Qin*

Main category: cs.CV

TL;DR: 提出了HiProbe-VAD框架，利用预训练多模态大语言模型的中间隐藏状态进行视频异常检测，无需微调即可实现优异性能


<details>
  <summary>Details</summary>
Motivation: 传统视频异常检测方法面临计算需求大、依赖大量标注数据的问题，限制了实际应用。需要开发更实用、可扩展的解决方案

Method: 提出动态层显著性探测(DLSP)机制，智能识别并提取多模态大语言模型最优中间层的信息丰富隐藏状态，结合轻量级异常评分器和时间定位模块进行异常检测

Result: 在UCF-Crime和XD-Violence数据集上超越现有免训练方法和大多数传统方法，在不同多模态大语言模型间展现出卓越的跨模型泛化能力

Conclusion: HiProbe-VAD成功利用预训练多模态大语言模型的中间隐藏状态实现了高效的视频异常检测，为更实用和可扩展的视频异常检测解决方案铺平了道路

Abstract: Video Anomaly Detection (VAD) aims to identify and locate deviations from
normal patterns in video sequences. Traditional methods often struggle with
substantial computational demands and a reliance on extensive labeled datasets,
thereby restricting their practical applicability. To address these
constraints, we propose HiProbe-VAD, a novel framework that leverages
pre-trained Multimodal Large Language Models (MLLMs) for VAD without requiring
fine-tuning. In this paper, we discover that the intermediate hidden states of
MLLMs contain information-rich representations, exhibiting higher sensitivity
and linear separability for anomalies compared to the output layer. To
capitalize on this, we propose a Dynamic Layer Saliency Probing (DLSP)
mechanism that intelligently identifies and extracts the most informative
hidden states from the optimal intermediate layer during the MLLMs reasoning.
Then a lightweight anomaly scorer and temporal localization module efficiently
detects anomalies using these extracted hidden states and finally generate
explanations. Experiments on the UCF-Crime and XD-Violence datasets demonstrate
that HiProbe-VAD outperforms existing training-free and most traditional
approaches. Furthermore, our framework exhibits remarkable cross-model
generalization capabilities in different MLLMs without any tuning, unlocking
the potential of pre-trained MLLMs for video anomaly detection and paving the
way for more practical and scalable solutions.

</details>


### [66] [HLFormer: Enhancing Partially Relevant Video Retrieval with Hyperbolic Learning](https://arxiv.org/abs/2507.17402)
*Li Jun,Wang Jinpeng,Tan Chaolei,Lian Niu,Chen Long,Zhang Min,Wang Yaowei,Xia Shu-Tao,Chen Bin*

Main category: cs.CV

TL;DR: 本文提出HLFormer，首个用于部分相关视频检索的双曲空间建模框架，通过混合空间编码和层次约束损失函数来解决现有方法在欧几里得空间中的几何失真问题


<details>
  <summary>Details</summary>
Motivation: 现有的部分相关视频检索方法在欧几里得空间中存在几何失真问题，无法准确表示视频的内在层次结构，忽略了某些层次语义，导致时序建模效果不佳

Method: 提出HLFormer框架，集成洛伦兹注意力块和欧几里得注意力块在混合空间中编码视频嵌入，使用均值引导自适应交互模块动态融合特征，并引入部分序保持损失通过洛伦兹锥约束强化"文本<视频"层次关系

Result: 广泛实验表明HLFormer在部分相关视频检索任务上超越了现有最先进方法的性能表现

Conclusion: 双曲空间学习能够有效补偿欧几里得空间在层次建模方面的不足，通过混合空间建模和层次约束可以显著提升部分相关视频检索的跨模态匹配效果

Abstract: Partially Relevant Video Retrieval (PRVR) addresses the critical challenge of
matching untrimmed videos with text queries describing only partial content.
Existing methods suffer from geometric distortion in Euclidean space that
sometimes misrepresents the intrinsic hierarchical structure of videos and
overlooks certain hierarchical semantics, ultimately leading to suboptimal
temporal modeling. To address this issue, we propose the first hyperbolic
modeling framework for PRVR, namely HLFormer, which leverages hyperbolic space
learning to compensate for the suboptimal hierarchical modeling capabilities of
Euclidean space. Specifically, HLFormer integrates the Lorentz Attention Block
and Euclidean Attention Block to encode video embeddings in hybrid spaces,
using the Mean-Guided Adaptive Interaction Module to dynamically fuse features.
Additionally, we introduce a Partial Order Preservation Loss to enforce "text <
video" hierarchy through Lorentzian cone constraints. This approach further
enhances cross-modal matching by reinforcing partial relevance between video
content and text queries. Extensive experiments show that HLFormer outperforms
state-of-the-art methods. Code is released at
https://github.com/lijun2005/ICCV25-HLFormer.

</details>


### [67] [Physics-based Human Pose Estimation from a Single Moving RGB Camera](https://arxiv.org/abs/2507.17406)
*Ayce Idil Aytekin,Chuqiao Li,Diogo Luvizon,Rishabh Dabral,Martin Oswald,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 本文提出了MoviCam数据集和PhysDynPose方法，解决了在移动相机和非平面场景中进行人体姿态跟踪的挑战性问题


<details>
  <summary>Details</summary>
Motivation: 现有的单目和基于物理的人体姿态跟踪方法在非严格平面地面或相机移动的场景中会产生伪影，且缺乏包含真实相机运动、场景几何和人体运动的高质量数据集

Method: 提出PhysDynPose方法，结合运动学估计器获取人体姿态，使用SLAM方法捕获动态相机轨迹，然后通过场景感知的物理优化器来细化姿态估计

Result: 在新的MoviCam基准数据集上，即使是最先进的方法在移动相机和非平面环境中也表现困难，而本文方法能够稳健地估计世界坐标系下的人体和相机姿态

Conclusion: MoviCam是首个包含真实相机轨迹、场景几何和3D人体运动的非合成数据集，PhysDynPose方法有效解决了移动相机和复杂场景下的人体姿态跟踪问题

Abstract: Most monocular and physics-based human pose tracking methods, while achieving
state-of-the-art results, suffer from artifacts when the scene does not have a
strictly flat ground plane or when the camera is moving. Moreover, these
methods are often evaluated on in-the-wild real world videos without
ground-truth data or on synthetic datasets, which fail to model the real world
light transport, camera motion, and pose-induced appearance and geometry
changes. To tackle these two problems, we introduce MoviCam, the first
non-synthetic dataset containing ground-truth camera trajectories of a
dynamically moving monocular RGB camera, scene geometry, and 3D human motion
with human-scene contact labels. Additionally, we propose PhysDynPose, a
physics-based method that incorporates scene geometry and physical constraints
for more accurate human motion tracking in case of camera motion and non-flat
scenes. More precisely, we use a state-of-the-art kinematics estimator to
obtain the human pose and a robust SLAM method to capture the dynamic camera
trajectory, enabling the recovery of the human pose in the world frame. We then
refine the kinematic pose estimate using our scene-aware physics optimizer.
From our new benchmark, we found that even state-of-the-art methods struggle
with this inherently challenging setting, i.e. a moving camera and non-planar
environments, while our method robustly estimates both human and camera poses
in world coordinates.

</details>


### [68] [Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging](https://arxiv.org/abs/2507.17412)
*Farnaz Khun Jush,Steffen Vogler,Matthias Lenga*

Main category: cs.CV

TL;DR: 本研究提出了C-MIR，一种新颖的三维医学图像检索重排序方法，无需预分割数据即可有效进行肿瘤检索和定位，在结肠癌和肺癌检测方面表现出显著改进。


<details>
  <summary>Details</summary>
Motivation: 医学图像数量激增给放射科医生检索相关病例带来挑战，现有的基于内容的图像检索(CBIR)系统缺乏标准化评估和全面研究，且依赖预分割数据和器官特定数据集，与临床实践中的大型非结构化图像存档系统(PACS)不匹配。

Method: 提出了一个无需预分割数据的框架，引入C-MIR这一新颖的体积重排序方法，将ColBERT的上下文化后期交互机制适配到3D医学成像中。使用三种特征提取器和三种数据库配置在四个肿瘤部位进行综合评估。

Result: C-MIR展现出显著优势，成功将后期交互原理适配到体积医学图像，实现有效的上下文感知重排序。能够有效定位感兴趣区域，无需数据集预分割。在肿瘤标记方面表现出有希望的改进，特别是在结肠癌和肺癌检测上取得显著改善(p<0.05)。在肿瘤分期方面也显示出潜力。

Conclusion: C-MIR提供了一种计算效率高的替代方案，无需昂贵的数据富化步骤，成功弥合了先进检索技术与医疗保健实际应用之间的差距，为改善诊断流程铺平了道路。

Abstract: The increasing volume of medical images poses challenges for radiologists in
retrieving relevant cases. Content-based image retrieval (CBIR) systems offer
potential for efficient access to similar cases, yet lack standardized
evaluation and comprehensive studies. Building on prior studies for tumor
characterization via CBIR, this study advances CBIR research for volumetric
medical images through three key contributions: (1) a framework eliminating
reliance on pre-segmented data and organ-specific datasets, aligning with large
and unstructured image archiving systems, i.e. PACS in clinical practice; (2)
introduction of C-MIR, a novel volumetric re-ranking method adapting ColBERT's
contextualized late interaction mechanism for 3D medical imaging; (3)
comprehensive evaluation across four tumor sites using three feature extractors
and three database configurations. Our evaluations highlight the significant
advantages of C-MIR. We demonstrate the successful adaptation of the late
interaction principle to volumetric medical images, enabling effective
context-aware re-ranking. A key finding is C-MIR's ability to effectively
localize the region of interest, eliminating the need for pre-segmentation of
datasets and offering a computationally efficient alternative to systems
relying on expensive data enrichment steps. C-MIR demonstrates promising
improvements in tumor flagging, achieving improved performance, particularly
for colon and lung tumors (p<0.05). C-MIR also shows potential for improving
tumor staging, warranting further exploration of its capabilities. Ultimately,
our work seeks to bridge the gap between advanced retrieval techniques and
their practical applications in healthcare, paving the way for improved
diagnostic processes.

</details>


### [69] [CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality Optimization in Computed Tomography](https://arxiv.org/abs/2507.17420)
*Sneha George Gnanakalavathy,Hairil Abdul Razak,Robert Meertens,Jonathan E. Fieldsend,Xujiong Ye,Mohammed M. Abdelsamea*

Main category: cs.CV

TL;DR: 提出了CAPRI-CT框架，这是一个因果感知的深度学习系统，通过整合CT图像数据和采集参数来优化CT成像质量，同时最小化辐射暴露。该系统使用变分自编码器集成来建模因果关系，预测信噪比，并支持反事实推理来模拟不同扫描参数的效果。


<details>
  <summary>Details</summary>
Motivation: 在CT成像中，如何在保证高图像质量的同时最小化辐射暴露仍然是一个关键的临床挑战。现有方法缺乏对影响图像质量的潜在因果关系的深入理解，需要一个能够建模这些复杂关系并提供可解释性预测的框架。

Method: 提出CAPRI-CT框架，整合CT图像数据和采集元数据（如管电压、管电流、造影剂类型等），使用变分自编码器(VAE)集成来提取有意义的特征并生成因果表示。通过特征融合来预测信噪比(SNR)，支持反事实推理，实现对造影剂变化或扫描参数调整的假设情景模拟。采用集成学习方法进行训练和验证。

Result: CAPRI-CT在预测性能方面表现出色，能够有效预测CT图像的信噪比。系统成功实现了反事实推理功能，可以模拟不同造影剂类型、浓度或扫描参数变化对图像质量的影响，为临床决策提供了有价值的洞察。

Conclusion: CAPRI-CT通过结合预测能力和可解释性，为放射科医生和技术人员提供了可操作的见解，有助于设计更高效的CT扫描协议，避免重复的物理扫描。该框架在优化CT成像质量和减少辐射暴露方面具有重要的临床应用潜力。

Abstract: In computed tomography (CT), achieving high image quality while minimizing
radiation exposure remains a key clinical challenge. This paper presents
CAPRI-CT, a novel causal-aware deep learning framework for Causal Analysis and
Predictive Reasoning for Image Quality Optimization in CT imaging. CAPRI-CT
integrates image data with acquisition metadata (such as tube voltage, tube
current, and contrast agent types) to model the underlying causal relationships
that influence image quality. An ensemble of Variational Autoencoders (VAEs) is
employed to extract meaningful features and generate causal representations
from observational data, including CT images and associated imaging parameters.
These input features are fused to predict the Signal-to-Noise Ratio (SNR) and
support counterfactual inference, enabling what-if simulations, such as changes
in contrast agents (types and concentrations) or scan parameters. CAPRI-CT is
trained and validated using an ensemble learning approach, achieving strong
predictive performance. By facilitating both prediction and interpretability,
CAPRI-CT provides actionable insights that could help radiologists and
technicians design more efficient CT protocols without repeated physical scans.
The source code and dataset are publicly available at
https://github.com/SnehaGeorge22/capri-ct.

</details>


### [70] [Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection](https://arxiv.org/abs/2507.17436)
*Yehao Lu,Minghe Weng,Zekang Xiao,Rui Jiang,Wei Su,Guangcong Zheng,Ping Lu,Xi Li*

Main category: cs.CV

TL;DR: 本文提出了Dynamic-DINO，将Grounding DINO 1.5 Edge从密集模型扩展为动态推理框架，通过MoE架构在实时开放词汇目标检测中实现了性能提升，仅用156万开源数据就超越了在私有2000万数据集上预训练的基准模型。


<details>
  <summary>Details</summary>
Motivation: 混合专家(MoE)架构在大型视觉语言模型中表现出色，但其在实时开放词汇目标检测器中的潜力尚未被探索。现有的实时检测器虽然也利用大规模视觉语言数据集，但使用的是较小的模型，如何在这种场景下有效应用MoE架构是一个值得研究的问题。

Method: 提出Dynamic-DINO框架，包含三个关键技术：1) 高效的MoE-Tuning策略，将Grounding DINO 1.5 Edge扩展为动态推理框架；2) 粒度分解机制，将基础模型的前馈网络分解为多个较小的专家网络，扩大子网搜索空间；3) 预训练权重分配策略和特定的路由器初始化，防止微调初期的性能下降。推理时只激活与输入相关的专家形成紧凑子网。

Result: 实验表明，Dynamic-DINO仅使用156万开源数据进行预训练，就超越了在私有Grounding20M数据集(2000万样本)上预训练的Grounding DINO 1.5 Edge的性能。研究还发现在浅层，专家倾向于与多样化的伙伴合作以扩大搜索空间；而在深层，出现了固定的协作结构，每个专家维持2-3个固定伙伴，不同的专家组合专门处理特定模式。

Conclusion: MoE架构在实时开放词汇目标检测中展现出巨大潜力，通过合理的架构设计和训练策略，可以在使用更少数据的情况下获得更好的性能。专家网络在不同深度层表现出不同的协作模式，为未来的模型设计提供了有价值的洞察。

Abstract: The Mixture of Experts (MoE) architecture has excelled in Large
Vision-Language Models (LVLMs), yet its potential in real-time open-vocabulary
object detectors, which also leverage large-scale vision-language datasets but
smaller models, remains unexplored. This work investigates this domain,
revealing intriguing insights. In the shallow layers, experts tend to cooperate
with diverse peers to expand the search space. While in the deeper layers,
fixed collaborative structures emerge, where each expert maintains 2-3 fixed
partners and distinct expert combinations are specialized in processing
specific patterns. Concretely, we propose Dynamic-DINO, which extends Grounding
DINO 1.5 Edge from a dense model to a dynamic inference framework via an
efficient MoE-Tuning strategy. Additionally, we design a granularity
decomposition mechanism to decompose the Feed-Forward Network (FFN) of base
model into multiple smaller expert networks, expanding the subnet search space.
To prevent performance degradation at the start of fine-tuning, we further
propose a pre-trained weight allocation strategy for the experts, coupled with
a specific router initialization. During inference, only the input-relevant
experts are activated to form a compact subnet. Experiments show that,
pretrained with merely 1.56M open-source data, Dynamic-DINO outperforms
Grounding DINO 1.5 Edge, pretrained on the private Grounding20M dataset.

</details>


### [71] [Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection](https://arxiv.org/abs/2507.17456)
*Francesco Tonini,Lorenzo Vaquero,Alessandro Conti,Cigdem Beyan,Elisa Ricci*

Main category: cs.CV

TL;DR: 提出了DYSCO，一个无需训练的人物-物体交互检测框架，通过多模态注册表和创新的交互签名机制，在稀有交互检测上表现优异


<details>
  <summary>Details</summary>
Motivation: 现有HOI检测方法严重依赖大量手工标注数据，这些标注成本高、容易不一致，且限制了对新领域和稀有交互的扩展性。视觉-语言模型的发展为增强交互表示提供了未开发的潜力

Method: 提出DYSCO框架，采用多模态注册表有效利用文本和视觉交互表示，结合创新的交互签名改善动词语义对齐，并设计多头注意力机制自适应加权视觉和文本特征贡献

Result: DYSCO在无需训练的情况下超越了现有最先进模型，与基于训练的方法具有竞争力，特别在稀有交互检测方面表现突出

Conclusion: 通过多模态注册表和创新的交互签名机制，DYSCO框架实现了鲁棒且细致的交互理解，为HOI检测提供了一种有效的无训练解决方案，特别适用于稀有交互场景

Abstract: Human-Object Interaction (HOI) detection aims to identify humans and objects
within images and interpret their interactions. Existing HOI methods rely
heavily on large datasets with manual annotations to learn interactions from
visual cues. These annotations are labor-intensive to create, prone to
inconsistency, and limit scalability to new domains and rare interactions. We
argue that recent advances in Vision-Language Models (VLMs) offer untapped
potential, particularly in enhancing interaction representation. While prior
work has injected such potential and even proposed training-free methods, there
remain key gaps. Consequently, we propose a novel training-free HOI detection
framework for Dynamic Scoring with enhanced semantics (DYSCO) that effectively
utilizes textual and visual interaction representations within a multimodal
registry, enabling robust and nuanced interaction understanding. This registry
incorporates a small set of visual cues and uses innovative interaction
signatures to improve the semantic alignment of verbs, facilitating effective
generalization to rare interactions. Additionally, we propose a unique
multi-head attention mechanism that adaptively weights the contributions of the
visual and textual features. Experimental results demonstrate that our DYSCO
surpasses training-free state-of-the-art models and is competitive with
training-based approaches, particularly excelling in rare interactions. Code is
available at https://github.com/francescotonini/dysco.

</details>


### [72] [ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents](https://arxiv.org/abs/2507.17462)
*Chang Nie,Guangming Wang,Zhe Lie,Hesheng Wang*

Main category: cs.CV

TL;DR: 本文提出ERMV框架，用于编辑机器人多视角4D序列数据以进行数据增强，通过EMA-Attn机制、稀疏时空模块和反馈干预机制解决了视角一致性、计算效率和语义完整性问题，显著提升了VLA模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿学习依赖4D多视角序列图像，但数据收集成本高昂且高质量数据稀缺，严重制约了VLA模型等具身智能策略的泛化和应用。虽然数据增强是克服数据稀缺的有效策略，但目前缺乏针对操作任务的4D多视角序列图像编辑方法。

Method: 提出ERMV数据增强框架，包含三个核心创新：(1)极线运动感知注意力机制(EMA-Attn)，通过学习运动引起的像素偏移来确保时空一致性；(2)稀疏时空模块(STT)，通过解耦时间和空间视角并稀疏采样来降低计算需求；(3)反馈干预机制，使用多模态大语言模型检查编辑不一致性并在必要时请求专家指导。

Result: 广泛实验表明，ERMV增强的数据显著提升了VLA模型在仿真和真实环境中的鲁棒性和泛化能力。该方法成功解决了动态视角和长时间序列中的几何和外观一致性维护、低计算成本的工作窗口扩展，以及机器人手臂等关键对象的语义完整性保持问题。

Conclusion: ERMV框架为机器人学习中的4D多视角序列数据增强提供了有效解决方案，通过创新的注意力机制、稀疏采样策略和智能反馈系统，成功克服了现有方法的局限性，为提升具身智能模型的性能和实用性开辟了新途径。

Abstract: Robot imitation learning relies on 4D multi-view sequential images. However,
the high cost of data collection and the scarcity of high-quality data severely
constrain the generalization and application of embodied intelligence policies
like Vision-Language-Action (VLA) models. Data augmentation is a powerful
strategy to overcome data scarcity, but methods for editing 4D multi-view
sequential images for manipulation tasks are currently lacking. Thus, we
propose ERMV (Editing Robotic Multi-View 4D data), a novel data augmentation
framework that efficiently edits an entire multi-view sequence based on
single-frame editing and robot state conditions. This task presents three core
challenges: (1) maintaining geometric and appearance consistency across dynamic
views and long time horizons; (2) expanding the working window with low
computational costs; and (3) ensuring the semantic integrity of critical
objects like the robot arm. ERMV addresses these challenges through a series of
innovations. First, to ensure spatio-temporal consistency in motion blur, we
introduce a novel Epipolar Motion-Aware Attention (EMA-Attn) mechanism that
learns pixel shift caused by movement before applying geometric constraints.
Second, to maximize the editing working window, ERMV pioneers a Sparse
Spatio-Temporal (STT) module, which decouples the temporal and spatial views
and remodels a single-frame multi-view problem through sparse sampling of the
views to reduce computational demands. Third, to alleviate error accumulation,
we incorporate a feedback intervention Mechanism, which uses a Multimodal Large
Language Model (MLLM) to check editing inconsistencies and request targeted
expert guidance only when necessary. Extensive experiments demonstrate that
ERMV-augmented data significantly boosts the robustness and generalization of
VLA models in both simulated and real-world environments.

</details>


### [73] [Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls](https://arxiv.org/abs/2507.17467)
*Elena Pitta,Tom Kouwenhoven,Tessa Verhoef*

Main category: cs.CV

TL;DR: 本研究以LLaMA 3.2 11B Vision模型为例，探索视觉蕴含（VE）任务作为多模态语言模型视觉-语言理解能力探测工具的可靠性。通过零样本、少样本和微调实验，发现三样本推理效果最佳，微调后在e-SNLI-VE数据集上达到83.3%准确率，但模型在缺乏视觉信息时容易产生幻觉，质疑了VE任务的视觉基础性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态语言模型的视觉-语言理解能力评估方法存在局限性，需要深入探索视觉蕴含（VE）任务作为诊断工具的有效性和可靠性，特别是理解其背后的可能性和限制。

Method: 使用LLaMA 3.2 11B Vision模型进行系列实验，包括零样本、少样本（few-shot）和微调设置；探索提示设计、上下文示例数量和顺序、视觉信息访问等因素对VE性能的影响；采用基于解释的评估方法探测模型推理过程；对比有限视觉条件下的模型表现。

Result: 三样本推理优于零样本基线，但更多示例会引入噪声；提示中标签顺序对预测结果影响显著；缺乏视觉信息时模型倾向于幻觉和想象内容；微调后在e-SNLI-VE数据集上达到83.3%准确率，超越最先进的OFA-X模型；解释评估显示微调模型提供与人类相似的语义有意义解释，BERTScore F1得分达89.2%。

Conclusion: 研究揭示了VE任务作为视觉-语言理解诊断工具的实用性和局限性。虽然微调能获得强劲性能，但有限视觉条件下的相似BERTScore结果质疑了该任务的视觉基础性。研究为改进多模态评估方法指明了方向，强调需要更好地理解模型对语言先验的过度依赖问题。

Abstract: This study investigates the extent to which the Visual Entailment (VE) task
serves as a reliable probe of vision-language understanding in multimodal
language models, using the LLaMA 3.2 11B Vision model as a test case. Beyond
reporting performance metrics, we aim to interpret what these results reveal
about the underlying possibilities and limitations of the VE task. We conduct a
series of experiments across zero-shot, few-shot, and fine-tuning settings,
exploring how factors such as prompt design, the number and order of in-context
examples and access to visual information might affect VE performance. To
further probe the reasoning processes of the model, we used explanation-based
evaluations. Results indicate that three-shot inference outperforms the
zero-shot baselines. However, additional examples introduce more noise than
they provide benefits. Additionally, the order of the labels in the prompt is a
critical factor that influences the predictions. In the absence of visual
information, the model has a strong tendency to hallucinate and imagine
content, raising questions about the model's over-reliance on linguistic
priors. Fine-tuning yields strong results, achieving an accuracy of 83.3% on
the e-SNLI-VE dataset and outperforming the state-of-the-art OFA-X model.
Additionally, the explanation evaluation demonstrates that the fine-tuned model
provides semantically meaningful explanations similar to those of humans, with
a BERTScore F1-score of 89.2%. We do, however, find comparable BERTScore
results in experiments with limited vision, questioning the visual grounding of
this task. Overall, our results highlight both the utility and limitations of
VE as a diagnostic task for vision-language understanding and point to
directions for refining multimodal evaluation methods.

</details>


### [74] [SRMambaV2: Biomimetic Attention for Sparse Point Cloud Upsampling in Autonomous Driving](https://arxiv.org/abs/2507.17479)
*Chuang Chen,Xiaolin Qin,Jing Hu,Wenyi Ge*

Main category: cs.CV

TL;DR: 提出了SRMambaV2方法，通过仿生2D选择性扫描自注意力机制和双分支网络架构，有效解决自动驾驶场景中稀疏LiDAR点云上采样问题，在远距离稀疏区域重建方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶场景中LiDAR点云上采样面临重大挑战，现有方法将3D空间场景转换为2D图像超分辨率任务，但由于距离图像的稀疏和模糊特征表示，难以准确重建详细复杂的空间拓扑结构。

Method: 提出SRMambaV2方法，包含三个核心组件：1）受人类驾驶员视觉感知启发的仿生2D选择性扫描自注意力(2DSSA)机制，用于建模远距离稀疏区域的特征分布；2）双分支网络架构增强稀疏特征表示；3）渐进式自适应损失(PAL)函数优化细粒度细节重建。

Result: 实验结果表明SRMambaV2在定性和定量评估中都取得了优异性能，在汽车稀疏点云上采样任务中显示出有效性和实用价值，特别是在长距离稀疏区域的上采样精度方面表现突出。

Conclusion: SRMambaV2成功解决了自动驾驶场景中稀疏LiDAR点云上采样的关键挑战，通过创新的仿生机制和网络架构设计，在保持整体几何重建质量的同时提升了长距离稀疏区域的上采样精度，为自动驾驶中的点云处理提供了有效解决方案。

Abstract: Upsampling LiDAR point clouds in autonomous driving scenarios remains a
significant challenge due to the inherent sparsity and complex 3D structures of
the data. Recent studies have attempted to address this problem by converting
the complex 3D spatial scenes into 2D image super-resolution tasks. However,
due to the sparse and blurry feature representation of range images, accurately
reconstructing detailed and complex spatial topologies remains a major
difficulty. To tackle this, we propose a novel sparse point cloud upsampling
method named SRMambaV2, which enhances the upsampling accuracy in long-range
sparse regions while preserving the overall geometric reconstruction quality.
Specifically, inspired by human driver visual perception, we design a
biomimetic 2D selective scanning self-attention (2DSSA) mechanism to model the
feature distribution in distant sparse areas. Meanwhile, we introduce a
dual-branch network architecture to enhance the representation of sparse
features. In addition, we introduce a progressive adaptive loss (PAL) function
to further refine the reconstruction of fine-grained details during the
upsampling process. Experimental results demonstrate that SRMambaV2 achieves
superior performance in both qualitative and quantitative evaluations,
highlighting its effectiveness and practical value in automotive sparse point
cloud upsampling tasks.

</details>


### [75] [Unsupervised anomaly detection using Bayesian flow networks: application to brain FDG PET in the context of Alzheimer's disease](https://arxiv.org/abs/2507.17486)
*Hugues Roy,Reuben Dorent,Ninon Burgos*

Main category: cs.CV

TL;DR: 本文提出了AnoBFN，一种基于贝叶斯流网络的无监督异常检测方法，用于神经影像中的阿尔茨海默病相关异常检测，在FDG PET图像上优于现有的VAE、GAN和扩散模型方法。


<details>
  <summary>Details</summary>
Motivation: 无监督异常检测在神经影像学中对识别健康受试者数据的偏差和促进神经系统疾病诊断具有重要作用。贝叶斯流网络作为一种新型生成模型，尚未应用于医学影像或异常检测领域，具有结合扩散框架和贝叶斯推理优势的潜力。

Method: 提出AnoBFN，这是贝叶斯流网络在无监督异常检测方面的扩展。该方法设计用于：1）在高水平空间相关噪声下执行条件图像生成；2）通过在整个生成过程中融入来自输入图像的递归反馈来保持受试者特异性。

Result: 在FDG PET图像的阿尔茨海默病相关异常检测任务上，AnoBFN优于基于VAE（beta-VAE）、GAN（f-AnoGAN）和扩散模型（AnoDDPM）的其他最先进方法，在检测异常的同时降低了假阳性率。

Conclusion: AnoBFN作为首个将贝叶斯流网络应用于医学影像异常检测的方法，成功证明了其在神经影像学异常检测方面的有效性，为该领域提供了一种新的强有力的工具。

Abstract: Unsupervised anomaly detection (UAD) plays a crucial role in neuroimaging for
identifying deviations from healthy subject data and thus facilitating the
diagnosis of neurological disorders. In this work, we focus on Bayesian flow
networks (BFNs), a novel class of generative models, which have not yet been
applied to medical imaging or anomaly detection. BFNs combine the strength of
diffusion frameworks and Bayesian inference. We introduce AnoBFN, an extension
of BFNs for UAD, designed to: i) perform conditional image generation under
high levels of spatially correlated noise, and ii) preserve subject specificity
by incorporating a recursive feedback from the input image throughout the
generative process. We evaluate AnoBFN on the challenging task of Alzheimer's
disease-related anomaly detection in FDG PET images. Our approach outperforms
other state-of-the-art methods based on VAEs (beta-VAE), GANs (f-AnoGAN), and
diffusion models (AnoDDPM), demonstrating its effectiveness at detecting
anomalies while reducing false positive rates.

</details>


### [76] [DFDNet: Dynamic Frequency-Guided De-Flare Network](https://arxiv.org/abs/2507.17489)
*Minglong Xue,Aoxiang Ning,Shivakumara Palaiahnakote,Mingliang Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种动态频域引导的去光晕网络(DFDNet)，通过在频域分离内容信息和光晕伪影，有效去除夜间摄影中的大规模光晕伪影并修复光源附近的结构损伤。


<details>
  <summary>Details</summary>
Motivation: 现有去光晕方法在处理大规模光晕伪影和修复光源附近结构损伤方面效果不佳。研究发现光晕伪影在频域比空域表现出更明显的差异性，这为频域处理提供了新的思路。

Method: 提出DFDNet网络，包含两个主要模块：1) 全局动态频域引导模块(GDFG)，通过动态优化全局频域特征来感知光晕特征并分离光晕信息；2) 局部细节引导模块(LDGM)，采用对比学习策略对齐光源局部特征与参考图像，减少去光晕过程中的局部细节损伤。

Result: 实验结果表明，所提出的方法在性能上优于现有的最先进方法，能够有效去除大规模光晕伪影并改善细粒度图像修复效果。

Conclusion: DFDNet通过频域处理和对比学习策略，成功解决了夜间摄影中大规模光晕去除和结构修复的挑战性问题，为图像去光晕领域提供了新的有效解决方案。

Abstract: Strong light sources in nighttime photography frequently produce flares in
images, significantly degrading visual quality and impacting the performance of
downstream tasks. While some progress has been made, existing methods continue
to struggle with removing large-scale flare artifacts and repairing structural
damage in regions near the light source. We observe that these challenging
flare artifacts exhibit more significant discrepancies from the reference
images in the frequency domain compared to the spatial domain. Therefore, this
paper presents a novel dynamic frequency-guided deflare network (DFDNet) that
decouples content information from flare artifacts in the frequency domain,
effectively removing large-scale flare artifacts. Specifically, DFDNet consists
mainly of a global dynamic frequency-domain guidance (GDFG) module and a local
detail guidance module (LDGM). The GDFG module guides the network to perceive
the frequency characteristics of flare artifacts by dynamically optimizing
global frequency domain features, effectively separating flare information from
content information. Additionally, we design an LDGM via a contrastive learning
strategy that aligns the local features of the light source with the reference
image, reduces local detail damage from flare removal, and improves
fine-grained image restoration. The experimental results demonstrate that the
proposed method outperforms existing state-of-the-art methods in terms of
performance. The code is available at
\href{https://github.com/AXNing/DFDNet}{https://github.com/AXNing/DFDNet}.

</details>


### [77] [Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation](https://arxiv.org/abs/2507.17508)
*Jorgen Cani,Christos Diou,Spyridon Evangelatos,Vasileios Argyriou,Panagiotis Radoglou-Grammatikis,Panagiotis Sarigiannidis,Iraklis Varlamis,Georgios Th. Papadopoulos*

Main category: cs.CV

TL;DR: 本文对基于深度学习的X光违禁品检测方法进行了系统性的比较评估，使用6个大规模公开数据集和10种最先进的目标检测方案，提供了全面的性能分析和关键洞察。


<details>
  <summary>Details</summary>
Motivation: 自动化X光检测在安全检查中至关重要，但面临物体遮挡、物理属性变化、设备多样性和训练数据有限等挑战。现有研究的实验评估往往不完整且结果冲突，需要系统性的比较研究来阐明研究现状并促进进一步发展。

Method: 开发了一个综合评估框架，包括：a) 6个大规模公开X光违禁品检测数据集（OPIXray、CLCXray、SIXray、EDS、HiXray和PIDray）；b) 10种不同的最先进目标检测方案，涵盖通用CNN、定制CNN、通用变换器和混合CNN-变换器架构；c) 多种检测指标（mAP50和mAP50:95）和时间/计算复杂度指标（推理时间、参数大小、计算负载）。

Result: 通过全面分析得出了关键观察和洞察，重点关注：a) 目标检测方案的整体行为；b) 物体级检测性能；c) 数据集特定观察；d) 时间效率和计算复杂度分析。为支持结果的可重现性，评估代码和模型权重已公开发布。

Conclusion: 该研究提供了X光违禁品检测领域首个系统性的比较评估，为研究人员提供了重要的基准和洞察，有助于推动该领域的进一步发展。通过公开评估框架和结果，促进了研究的透明度和可重现性。

Abstract: Automated X-ray inspection is crucial for efficient and unobtrusive security
screening in various public settings. However, challenges such as object
occlusion, variations in the physical properties of items, diversity in X-ray
scanning devices, and limited training data hinder accurate and reliable
detection of illicit items. Despite the large body of research in the field,
reported experimental evaluations are often incomplete, with frequently
conflicting outcomes. To shed light on the research landscape and facilitate
further research, a systematic, detailed, and thorough comparative evaluation
of recent Deep Learning (DL)-based methods for X-ray object detection is
conducted. For this, a comprehensive evaluation framework is developed,
composed of: a) Six recent, large-scale, and widely used public datasets for
X-ray illicit item detection (OPIXray, CLCXray, SIXray, EDS, HiXray, and
PIDray), b) Ten different state-of-the-art object detection schemes covering
all main categories in the literature, including generic Convolutional Neural
Network (CNN), custom CNN, generic transformer, and hybrid CNN-transformer
architectures, and c) Various detection (mAP50 and mAP50:95) and
time/computational-complexity (inference time (ms), parameter size (M), and
computational load (GFLOPS)) metrics. A thorough analysis of the results leads
to critical observations and insights, emphasizing key aspects such as: a)
Overall behavior of the object detection schemes, b) Object-level detection
performance, c) Dataset-specific observations, and d) Time efficiency and
computational complexity analysis. To support reproducibility of the reported
experimental results, the evaluation code and model weights are made publicly
available at https://github.com/jgenc/xray-comparative-evaluation.

</details>


### [78] [Accelerating Parallel Diffusion Model Serving with Residual Compression](https://arxiv.org/abs/2507.17511)
*Jiajun Luo,Yicheng Xiao,Jianru Xu,Yangxiu You,Rongwei Lu,Chen Tang,Jingyan Jiang,Zhi Wang*

Main category: cs.CV

TL;DR: CompactFusion是一个压缩框架，通过残差压缩技术显著减少扩散模型并行推理中的通信开销，在保持生成质量的同时实现了3.0x的加速。


<details>
  <summary>Details</summary>
Motivation: 扩散模型需要多加速器并行推理来实现实时部署，但并行推理会产生大量通信开销，因为需要在设备间交换大型激活值，这限制了效率和可扩展性。扩散激活值存在强时间冗余性，相邻步骤产生高度相似的激活值，导致带宽被近似重复数据饱和。

Method: 提出CompactFusion压缩框架，核心方法是残差压缩(Residual Compression)，只传输压缩的残差(步骤间激活值差异)而非完整激活值。同时集成轻量级误差反馈机制防止误差累积。基于经验分析和理论证明，该方法能有效去除冗余数据。

Result: 在4xL20上实现3.0x加速的同时大幅提升保真度。在慢速网络上支持序列并行等通信密集策略，相比先前的重叠方法实现6.7x加速。方法广泛适用于各种扩散模型和并行设置，易于集成且无需重构管道。

Conclusion: CompactFusion为并行扩散推理建立了新范式，通过残差压缩技术有效解决了通信瓶颈问题，在降低延迟的同时显著提高生成质量，为扩散模型的实时部署提供了有效解决方案。

Abstract: Diffusion models produce realistic images and videos but require substantial
computational resources, necessitating multi-accelerator parallelism for
real-time deployment. However, parallel inference introduces significant
communication overhead from exchanging large activations between devices,
limiting efficiency and scalability. We present CompactFusion, a compression
framework that significantly reduces communication while preserving generation
quality. Our key observation is that diffusion activations exhibit strong
temporal redundancy-adjacent steps produce highly similar activations,
saturating bandwidth with near-duplicate data carrying little new information.
To address this inefficiency, we seek a more compact representation that
encodes only the essential information. CompactFusion achieves this via
Residual Compression that transmits only compressed residuals (step-wise
activation differences). Based on empirical analysis and theoretical
justification, we show that it effectively removes redundant data, enabling
substantial data reduction while maintaining high fidelity. We also integrate
lightweight error feedback to prevent error accumulation. CompactFusion
establishes a new paradigm for parallel diffusion inference, delivering lower
latency and significantly higher generation quality than prior methods. On
4xL20, it achieves 3.0x speedup while greatly improving fidelity. It also
uniquely supports communication-heavy strategies like sequence parallelism on
slow networks, achieving 6.7x speedup over prior overlap-based method.
CompactFusion applies broadly across diffusion models and parallel settings,
and integrates easily without requiring pipeline rework. Portable
implementation demonstrated on xDiT is publicly available at
https://github.com/Cobalt-27/CompactFusion

</details>


### [79] [URPO: A Unified Reward & Policy Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.17515)
*Songshuo Lu,Hua Wang,Zhi Chen,Yaohua Tang*

Main category: cs.CV

TL;DR: 提出了URPO框架，将指令遵循和奖励建模统一在单一模型中进行训练，消除了传统对齐流程中独立奖励模型的需求，在Qwen2.5-7B上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统大规模对齐流程需要独立训练的奖励模型，其参数在强化学习过程中保持冻结，这种分离创造了复杂且资源密集的流程，并且由于静态奖励信号而存在性能上限。

Method: 提出统一奖励与策略优化(URPO)框架，将指令遵循("玩家")和奖励建模("裁判")统一在单一模型和单一训练阶段中。将所有对齐数据(包括偏好对、可验证推理和开放式指令)重塑为统一的生成格式，通过单一的群体相对策略优化(GRPO)循环进行优化。

Result: 在Qwen2.5-7B模型上的实验表明，URPO显著优于使用独立生成奖励模型的强基线，在AlpacaEval上的指令遵循得分从42.24提升到44.84，复合推理平均得分从32.66提升到35.66。此外，URPO作为训练的副产品培养出了优秀的内部评估器，在RewardBench上获得85.15分，超越了它所替代的专用奖励模型(83.55分)。

Conclusion: 通过消除对独立奖励模型的需求并促进生成和评估之间的协同进化动态，URPO为实现稳健对齐的语言模型提供了一条更简单、更高效、更有效的路径。

Abstract: Large-scale alignment pipelines typically pair a policy model with a
separately trained reward model whose parameters remain frozen during
reinforcement learning (RL). This separation creates a complex,
resource-intensive pipeline and suffers from a performance ceiling due to a
static reward signal. We propose a novel framework, Unified Reward & Policy
Optimization (URPO), that unifies instruction-following ("player") and reward
modeling ("referee") within a single model and a single training phase. Our
method recasts all alignment data-including preference pairs, verifiable
reasoning, and open-ended instructions-into a unified generative format
optimized by a single Group-Relative Policy Optimization (GRPO) loop. This
enables the model to learn from ground-truth preferences and verifiable logic
while simultaneously generating its own rewards for open-ended tasks.
Experiments on the Qwen2.5-7B model demonstrate URPO's superiority. Our unified
model significantly outperforms a strong baseline using a separate generative
reward model, boosting the instruction-following score on AlpacaEval from 42.24
to 44.84 and the composite reasoning average from 32.66 to 35.66. Furthermore,
URPO cultivates a superior internal evaluator as a byproduct of training,
achieving a RewardBench score of 85.15 and surpassing the dedicated reward
model it replaces (83.55). By eliminating the need for a separate reward model
and fostering a co-evolutionary dynamic between generation and evaluation, URPO
presents a simpler, more efficient, and more effective path towards robustly
aligned language models.

</details>


### [80] [STQE: Spatial-Temporal Quality Enhancement for G-PCC Compressed Dynamic Point Clouds](https://arxiv.org/abs/2507.17522)
*Tian Guo,Hui Yuan,Xiaolong Mao,Shiqi Jiang,Raouf Hamzaoui,Sam Kwong*

Main category: cs.CV

TL;DR: 本文提出了一种空间-时间属性质量增强(STQE)网络，通过利用空间和时间相关性来提升G-PCC压缩动态点云的视觉质量，在Luma、Cb、Cr分量上分别获得了0.855 dB、0.682 dB、0.828 dB的PSNR提升，BD码率分别降低了25.2%、31.6%、32.5%。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，针对压缩动态点云质量增强的工作很少，特别是点云帧间空间-时间相关性的有效利用仍然未被充分探索，因此需要设计能够同时利用空间和时间相关性的网络来改善G-PCC压缩动态点云的视觉质量。

Method: 提出了空间-时间属性质量增强(STQE)网络，包含四个核心模块：1)基于重着色的运动补偿模块，用于将参考属性信息映射到当前帧几何结构实现精确的帧间几何对齐；2)通道感知时间注意力模块，动态突出双向参考帧中的相关区域；3)高斯引导的邻域特征聚合模块，有效捕获几何和颜色属性之间的空间依赖关系；4)基于皮尔逊相关系数的联合损失函数，用于缓解逐点均方误差优化的过度平滑效应。

Result: 在最新的G-PCC测试模型上，STQE在Luma、Cb、Cr分量上分别获得了0.855 dB、0.682 dB、0.828 dB的增量PSNR改善，Bjøntegaard Delta码率(BD-rate)分别降低了-25.2%、-31.6%、-32.5%。

Conclusion: STQE网络通过有效利用空间-时间相关性，显著提升了G-PCC压缩动态点云的视觉质量，在多个评价指标上都取得了显著的性能提升，为压缩动态点云的质量增强提供了有效的解决方案。

Abstract: Very few studies have addressed quality enhancement for compressed dynamic
point clouds. In particular, the effective exploitation of spatial-temporal
correlations between point cloud frames remains largely unexplored. Addressing
this gap, we propose a spatial-temporal attribute quality enhancement (STQE)
network that exploits both spatial and temporal correlations to improve the
visual quality of G-PCC compressed dynamic point clouds. Our contributions
include a recoloring-based motion compensation module that remaps reference
attribute information to the current frame geometry to achieve precise
inter-frame geometric alignment, a channel-aware temporal attention module that
dynamically highlights relevant regions across bidirectional reference frames,
a Gaussian-guided neighborhood feature aggregation module that efficiently
captures spatial dependencies between geometry and color attributes, and a
joint loss function based on the Pearson correlation coefficient, designed to
alleviate over-smoothing effects typical of point-wise mean squared error
optimization. When applied to the latest G-PCC test model, STQE achieved
improvements of 0.855 dB, 0.682 dB, and 0.828 dB in delta PSNR, with
Bj{\o}ntegaard Delta rate (BD-rate) reductions of -25.2%, -31.6%, and -32.5%
for the Luma, Cb, and Cr components, respectively.

</details>


### [81] [Multi-modal Multi-task Pre-training for Improved Point Cloud Understanding](https://arxiv.org/abs/2507.17533)
*Liwen Liu,Weidong Yang,Lipeng Ma,Ben Fei*

Main category: cs.CV

TL;DR: 提出了MMPT多模态多任务预训练框架，通过三个预训练任务（token级重建、点级重建、多模态对比学习）增强点云理解能力，无需3D标注且可扩展到大数据集


<details>
  <summary>Details</summary>
Motivation: 现有多模态预训练框架主要依赖单一预训练任务来收集3D应用中的多模态数据，这种限制阻止模型获得其他相关任务提供的丰富信息，从而影响在下游任务中的性能，特别是在复杂多样的领域中

Method: 提出MMPT多模态多任务预训练框架，包含三个预训练任务：(1)Token级重建(TLR)恢复被遮罩的点token；(2)点级重建(PLR)直接预测被遮罩点的位置；(3)多模态对比学习(MCL)结合模态内和模态间的特征对应关系，以自监督方式从3D点云和2D图像模态中获得丰富的学习信号

Result: 在广泛使用的基准测试中，与最先进方法相比，该框架在各种判别和生成应用中表现出良好的性能。训练的编码器可以有效地迁移到各种下游任务

Conclusion: MMPT框架通过多任务预训练有效增强了点云理解能力，无需3D标注使其具有良好的可扩展性，能够在多种下游任务中取得优秀的性能表现

Abstract: Recent advances in multi-modal pre-training methods have shown promising
effectiveness in learning 3D representations by aligning multi-modal features
between 3D shapes and their corresponding 2D counterparts. However, existing
multi-modal pre-training frameworks primarily rely on a single pre-training
task to gather multi-modal data in 3D applications. This limitation prevents
the models from obtaining the abundant information provided by other relevant
tasks, which can hinder their performance in downstream tasks, particularly in
complex and diverse domains. In order to tackle this issue, we propose MMPT, a
Multi-modal Multi-task Pre-training framework designed to enhance point cloud
understanding. Specifically, three pre-training tasks are devised: (i)
Token-level reconstruction (TLR) aims to recover masked point tokens, endowing
the model with representative learning abilities. (ii) Point-level
reconstruction (PLR) is integrated to predict the masked point positions
directly, and the reconstructed point cloud can be considered as a transformed
point cloud used in the subsequent task. (iii) Multi-modal contrastive learning
(MCL) combines feature correspondences within and across modalities, thus
assembling a rich learning signal from both 3D point cloud and 2D image
modalities in a self-supervised manner. Moreover, this framework operates
without requiring any 3D annotations, making it scalable for use with large
datasets. The trained encoder can be effectively transferred to various
downstream tasks. To demonstrate its effectiveness, we evaluated its
performance compared to state-of-the-art methods in various discriminant and
generative applications under widely-used benchmarks.

</details>


### [82] [An h-space Based Adversarial Attack for Protection Against Few-shot Personalization](https://arxiv.org/abs/2507.17554)
*Xide Xu,Sandesh Kamath,Muhammad Atif Butt,Bogdan Raducanu*

Main category: cs.CV

TL;DR: 提出了HAAD和HAAD-KV两种基于h空间的对抗攻击方法，通过在扩散模型的语义潜在空间中生成扰动来防止未经授权的图像定制，有效保护隐私内容


<details>
  <summary>Details</summary>
Motivation: 扩散模型能够从少量样本生成定制图像的能力引发了严重的隐私担忧，特别是对私人内容的未经授权修改。现有的基于对抗攻击的保护机制需要改进，研究发现扩散模型在其语义潜在空间(h空间)中表现出高度抽象性，该空间编码了生成连贯和有意义内容的关键高级特征

Method: 提出HAAD(基于h空间的扩散模型对抗攻击)方法，利用对抗攻击在h空间中制作扰动来有效降解图像生成过程。进一步提出HAAD-KV变体，仅基于h空间的KV参数构建扰动，提供更强的保护且计算成本更低

Result: 尽管方法简单，但HAAD和HAAD-KV都超越了现有最先进的对抗攻击方法，显示出其有效性。HAAD-KV在提供更强保护的同时计算成本更低

Conclusion: 基于h空间的对抗攻击方法能够有效防止扩散模型的未经授权定制，为保护隐私内容提供了一种简单而有效的解决方案，其中HAAD-KV变体在效率和效果之间取得了更好的平衡

Abstract: The versatility of diffusion models in generating customized images from few
samples raises significant privacy concerns, particularly regarding
unauthorized modifications of private content. This concerning issue has
renewed the efforts in developing protection mechanisms based on adversarial
attacks, which generate effective perturbations to poison diffusion models. Our
work is motivated by the observation that these models exhibit a high degree of
abstraction within their semantic latent space (`h-space'), which encodes
critical high-level features for generating coherent and meaningful content. In
this paper, we propose a novel anti-customization approach, called HAAD
(h-space based Adversarial Attack for Diffusion models), that leverages
adversarial attacks to craft perturbations based on the h-space that can
efficiently degrade the image generation process. Building upon HAAD, we
further introduce a more efficient variant, HAAD-KV, that constructs
perturbations solely based on the KV parameters of the h-space. This strategy
offers a stronger protection, that is computationally less expensive. Despite
their simplicity, our methods outperform state-of-the-art adversarial attacks,
highlighting their effectiveness.

</details>


### [83] [Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors](https://arxiv.org/abs/2507.17577)
*Chen Ma,Xinjie Xu,Shuyu Cheng,Qi Xuan*

Main category: cs.CV

TL;DR: 本文提出了一种基于先验指导的硬标签黑盒对抗攻击方法，通过利用代理模型的迁移先验信息来改进射线搜索效率，在ImageNet和CIFAR-10数据集上显著优于现有方法的查询效率。


<details>
  <summary>Details</summary>
Motivation: 硬标签黑盒对抗攻击是最实用且具有挑战性的攻击类型之一，现有方法使用"符号技巧"进行梯度估计以减少查询次数，但查询成本仍然很高。因此需要提高射线搜索的效率，减少查询次数。

Method: 提出基于先验指导的方法来改进射线搜索效率。具体来说，利用代理模型的迁移先验信息，通过近似真实梯度在先验方向和随机方向张成的子空间上的投影，以查询高效的方式适当地集成这些先验信息到梯度估计器中。

Result: 在ImageNet和CIFAR-10数据集上的大量实验表明，该方法在查询效率方面显著优于11种最先进的方法。理论分析推导了获得的梯度估计器与真实梯度之间的期望余弦相似度，并证明了结合先验信息带来的改进。

Conclusion: 通过理论分析梯度估计质量并提出先验指导的方法，成功改进了硬标签黑盒对抗攻击的射线搜索效率，将连续优化问题的查询成本显著降低，在多个数据集上验证了方法的有效性。

Abstract: One of the most practical and challenging types of black-box adversarial
attacks is the hard-label attack, where only the top-1 predicted label is
available. One effective approach is to search for the optimal ray direction
from the benign image that minimizes the $\ell_p$-norm distance to the
adversarial region. The unique advantage of this approach is that it transforms
the hard-label attack into a continuous optimization problem. The objective
function value is the ray's radius, which can be obtained via binary search at
a high query cost. Existing methods use a "sign trick" in gradient estimation
to reduce the number of queries. In this paper, we theoretically analyze the
quality of this gradient estimation and propose a novel prior-guided approach
to improve ray search efficiency both theoretically and empirically.
Specifically, we utilize the transfer-based priors from surrogate models, and
our gradient estimators appropriately integrate them by approximating the
projection of the true gradient onto the subspace spanned by these priors and
random directions, in a query-efficient manner. We theoretically derive the
expected cosine similarities between the obtained gradient estimators and the
true gradient, and demonstrate the improvement achieved by incorporating
priors. Extensive experiments on the ImageNet and CIFAR-10 datasets show that
our approach significantly outperforms 11 state-of-the-art methods in terms of
query efficiency.

</details>


### [84] [Dual-branch Prompting for Multimodal Machine Translation](https://arxiv.org/abs/2507.17588)
*Jie Wang,Zhendong Yang,Liansong Zong,Xiaobo Zhang,Dexian Wang,Ji Zhang*

Main category: cs.CV

TL;DR: 提出了D2P-MMT，一个基于扩散模型的双分支提示框架，用于鲁棒的视觉引导翻译。该方法仅需源文本和重构图像，通过双分支训练策略和分布对齐损失提升翻译性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态机器翻译方法在推理时需要配对的图像-文本输入，且对无关视觉噪声敏感，限制了其鲁棒性和实用性。

Method: 提出D2P-MMT框架，使用预训练扩散模型生成重构图像来过滤干扰视觉细节，采用双分支提示策略同时学习真实和重构图像，并引入分布对齐损失来减少训练-推理差异。

Result: 在Multi30K数据集上的广泛实验表明，D2P-MMT相比现有最先进方法实现了更优的翻译性能。

Conclusion: D2P-MMT通过扩散模型重构图像和双分支训练策略，成功解决了多模态机器翻译中的鲁棒性问题，在保持语义信息的同时过滤视觉噪声，提升了翻译质量。

Abstract: Multimodal Machine Translation (MMT) typically enhances text-only translation
by incorporating aligned visual features. Despite the remarkable progress,
state-of-the-art MMT approaches often rely on paired image-text inputs at
inference and are sensitive to irrelevant visual noise, which limits their
robustness and practical applicability. To address these issues, we propose
D2P-MMT, a diffusion-based dual-branch prompting framework for robust
vision-guided translation. Specifically, D2P-MMT requires only the source text
and a reconstructed image generated by a pre-trained diffusion model, which
naturally filters out distracting visual details while preserving semantic
cues. During training, the model jointly learns from both authentic and
reconstructed images using a dual-branch prompting strategy, encouraging rich
cross-modal interactions. To bridge the modality gap and mitigate
training-inference discrepancies, we introduce a distributional alignment loss
that enforces consistency between the output distributions of the two branches.
Extensive experiments on the Multi30K dataset demonstrate that D2P-MMT achieves
superior translation performance compared to existing state-of-the-art
approaches.

</details>


### [85] [RemixFusion: Residual-based Mixed Representation for Large-scale Online RGB-D Reconstruction](https://arxiv.org/abs/2507.17594)
*Yuqing Lan,Chenyang Zhu,Shuaifeng Zhi,Jiazhao Zhang,Zhoufeng Wang,Renjiao Yi,Yijie Wang,Kai Xu*

Main category: cs.CV

TL;DR: RemixFusion提出了一种基于残差的混合表示方法，结合显式TSDF网格和隐式神经模块，实现了高质量、大规模在线RGB-D重建，在映射和跟踪精度方面超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经隐式表示方法在大规模在线重建中存在重建细节不足和学习耗时的问题，限制了其广泛应用。传统显式表示方法虽然效率高但重建完整性和内存效率有限。

Method: 提出RemixFusion方法，采用基于残差的混合表示：1）结合显式粗糙TSDF网格和隐式神经模块生成细粒度残差细节；2）通过束调整优化姿态变化而非直接优化姿态；3）采用自适应梯度放大技术；4）使用局部移动体积分解混合场景表示。

Result: 在大规模场景上的映射和跟踪精度方面，该方法超越了所有最先进的方法，包括基于显式和隐式表示的方法。实现了在有限时间和内存预算下的细节丰富重建。

Conclusion: RemixFusion成功解决了神经隐式表示在大规模在线重建中的局限性，通过混合表示和优化策略的创新，实现了高质量、高效的场景重建和相机姿态估计。

Abstract: The introduction of the neural implicit representation has notably propelled
the advancement of online dense reconstruction techniques. Compared to
traditional explicit representations, such as TSDF, it improves the mapping
completeness and memory efficiency. However, the lack of reconstruction details
and the time-consuming learning of neural representations hinder the widespread
application of neural-based methods to large-scale online reconstruction. We
introduce RemixFusion, a novel residual-based mixed representation for scene
reconstruction and camera pose estimation dedicated to high-quality and
large-scale online RGB-D reconstruction. In particular, we propose a
residual-based map representation comprised of an explicit coarse TSDF grid and
an implicit neural module that produces residuals representing fine-grained
details to be added to the coarse grid. Such mixed representation allows for
detail-rich reconstruction with bounded time and memory budget, contrasting
with the overly-smoothed results by the purely implicit representations, thus
paving the way for high-quality camera tracking. Furthermore, we extend the
residual-based representation to handle multi-frame joint pose optimization via
bundle adjustment (BA). In contrast to the existing methods, which optimize
poses directly, we opt to optimize pose changes. Combined with a novel
technique for adaptive gradient amplification, our method attains better
optimization convergence and global optimality. Furthermore, we adopt a local
moving volume to factorize the mixed scene representation with a
divide-and-conquer design to facilitate efficient online learning in our
residual-based framework. Extensive experiments demonstrate that our method
surpasses all state-of-the-art ones, including those based either on explicit
or implicit representations, in terms of the accuracy of both mapping and
tracking on large-scale scenes.

</details>


### [86] [InvRGB+L: Inverse Rendering of Complex Scenes with Unified Color and LiDAR Reflectance Modeling](https://arxiv.org/abs/2507.17613)
*Xiaoxue Chen,Bhargav Chandaka,Chih-Hao Lin,Ya-Qin Zhang,David Forsyth,Hao Zhao,Shenlong Wang*

Main category: cs.CV

TL;DR: InvRGB+L是一个新颖的逆渲染模型，通过结合RGB和LiDAR数据重建大规模、可重新照明的动态场景，利用LiDAR强度信息改善材质估计，在城市场景逆渲染和LiDAR仿真方面超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统逆图形学方法主要依赖RGB观测，仅将LiDAR用于几何信息获取，由于可见光干扰导致材质估计不理想。LiDAR在不同光谱范围内的主动照明强度值为在变化光照下的鲁棒材质估计提供了互补线索。

Method: InvRGB+L通过两个关键创新来利用LiDAR强度线索：(1) 基于物理的LiDAR着色模型；(2) RGB-LiDAR材质一致性损失函数。该方法克服了以RGB为中心的逆图形学固有挑战。

Result: 该模型能够生成城市和室内场景的新视角RGB和LiDAR渲染结果，支持重新照明、夜间仿真和动态物体插入功能，在场景级城市逆渲染和LiDAR仿真方面的表现超越了当前最先进的方法。

Conclusion: InvRGB+L成功地将LiDAR强度信息集成到逆渲染过程中，通过物理建模和一致性约束显著改善了材质估计质量，为大规模场景的逆渲染和仿真提供了新的解决方案。

Abstract: We present InvRGB+L, a novel inverse rendering model that reconstructs large,
relightable, and dynamic scenes from a single RGB+LiDAR sequence. Conventional
inverse graphics methods rely primarily on RGB observations and use LiDAR
mainly for geometric information, often resulting in suboptimal material
estimates due to visible light interference. We find that LiDAR's intensity
values-captured with active illumination in a different spectral range-offer
complementary cues for robust material estimation under variable lighting.
Inspired by this, InvRGB+L leverages LiDAR intensity cues to overcome
challenges inherent in RGB-centric inverse graphics through two key
innovations: (1) a novel physics-based LiDAR shading model and (2) RGB-LiDAR
material consistency losses. The model produces novel-view RGB and LiDAR
renderings of urban and indoor scenes and supports relighting, night
simulations, and dynamic object insertions, achieving results that surpass
current state-of-the-art methods in both scene-level urban inverse rendering
and LiDAR simulation.

</details>


### [87] [Vision Transformer attention alignment with human visual perception in aesthetic object evaluation](https://arxiv.org/abs/2507.17616)
*Miguel Carrasco,César González-Martín,José Aranda,Luis Oliveros*

Main category: cs.CV

TL;DR: 本研究通过眼动追踪实验比较了人类视觉注意力与Vision Transformer(ViT)注意力机制在评估手工艺品时的相关性，发现ViT的某些注意力头可以近似人类视觉行为，但整体上ViT表现出更全局的注意力模式。


<details>
  <summary>Details</summary>
Motivation: 尽管Vision Transformer在计算机视觉任务中表现出色，但其注意力机制与人类视觉注意力模式的一致性，特别是在美学评估方面仍未得到充分探索。理解这种一致性对于产品设计和美学评估具有重要意义。

Method: 研究采用眼动追踪实验，30名参与者观看20件手工艺品（篮子包和姜罐），使用Pupil Labs眼动仪记录注视模式并生成热图。同时使用预训练的ViT-DINO模型分析相同物体，提取12个注意力头的注意力图。通过Kullback-Leibler散度比较人类和ViT注意力分布，测试不同高斯参数（sigma=0.1到3.0）。

Result: 在sigma=2.4±0.03时发现最优相关性，注意力头#12与人类视觉模式显示出最强的一致性。注意力头之间存在显著差异，头#7和#9与人类注意力差异最大（p<0.05）。ViT表现出比人类焦点注意力更全局的注意力模式，但某些注意力头可以近似人类视觉行为，特别是对特定物体特征如篮子的扣环。

Conclusion: 研究表明ViT注意力机制在产品设计和美学评估方面具有潜在应用价值，同时突出了人类感知与当前AI模型在注意力策略上的根本差异。某些ViT注意力头能够近似人类视觉行为，但整体上仍存在显著差异。

Abstract: Visual attention mechanisms play a crucial role in human perception and
aesthetic evaluation. Recent advances in Vision Transformers (ViTs) have
demonstrated remarkable capabilities in computer vision tasks, yet their
alignment with human visual attention patterns remains underexplored,
particularly in aesthetic contexts. This study investigates the correlation
between human visual attention and ViT attention mechanisms when evaluating
handcrafted objects. We conducted an eye-tracking experiment with 30
participants (9 female, 21 male, mean age 24.6 years) who viewed 20 artisanal
objects comprising basketry bags and ginger jars. Using a Pupil Labs
eye-tracker, we recorded gaze patterns and generated heat maps representing
human visual attention. Simultaneously, we analyzed the same objects using a
pre-trained ViT model with DINO (Self-DIstillation with NO Labels), extracting
attention maps from each of the 12 attention heads. We compared human and ViT
attention distributions using Kullback-Leibler divergence across varying
Gaussian parameters (sigma=0.1 to 3.0). Statistical analysis revealed optimal
correlation at sigma=2.4 +-0.03, with attention head #12 showing the strongest
alignment with human visual patterns. Significant differences were found
between attention heads, with heads #7 and #9 demonstrating the greatest
divergence from human attention (p< 0.05, Tukey HSD test). Results indicate
that while ViTs exhibit more global attention patterns compared to human focal
attention, certain attention heads can approximate human visual behavior,
particularly for specific object features like buckles in basketry items. These
findings suggest potential applications of ViT attention mechanisms in product
design and aesthetic evaluation, while highlighting fundamental differences in
attention strategies between human perception and current AI models.

</details>


### [88] [Reusing Attention for One-stage Lane Topology Understanding](https://arxiv.org/abs/2507.17617)
*Yang Li,Zongzheng Zhang,Xuchong Qiu,Xinrun Li,Ziming Liu,Leichen Wang,Ruikai Li,Zhenxin Zhu,Huan-ang Gao,Xiaojian Lin,Zhiyong Cui,Hang Zhao,Hao Zhao*

Main category: cs.CV

TL;DR: 提出了一种单阶段架构，同时预测交通元素、车道中心线和拓扑关系，通过复用transformer解码器中的注意力资源来提高自动驾驶中车道拓扑理解的准确性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的两阶段方法存在错误传播和计算开销增加导致的效率低下问题，需要更准确高效的车道拓扑关系理解方法来确保自动驾驶安全。

Method: 设计单阶段架构同时预测交通元素、车道中心线和拓扑关系；通过在不同transformer解码器中复用中间注意力资源，利用元素检测模块中的固有关系知识来建模拓扑关系，避免使用额外的计算昂贵的图网络；首次展示从使用标准定义地图的模型向不使用SD地图的模型进行知识蒸馏。

Result: 在OpenLane-V2数据集上的大量实验表明，该方法在准确性和效率方面都优于基线方法，在车道检测、交通元素识别和拓扑推理方面取得了优异结果；即使在没有SD地图的情况下也能实现卓越性能。

Conclusion: 通过单阶段架构和注意力资源复用策略，成功提高了车道拓扑理解的准确性和推理速度，并通过知识蒸馏实现了在无SD地图条件下的优异性能，为自动驾驶中的车道拓扑理解提供了更高效的解决方案。

Abstract: Understanding lane toplogy relationships accurately is critical for safe
autonomous driving. However, existing two-stage methods suffer from
inefficiencies due to error propagations and increased computational overheads.
To address these challenges, we propose a one-stage architecture that
simultaneously predicts traffic elements, lane centerlines and topology
relationship, improving both the accuracy and inference speed of lane topology
understanding for autonomous driving. Our key innovation lies in reusing
intermediate attention resources within distinct transformer decoders. This
approach effectively leverages the inherent relational knowledge within the
element detection module to enable the modeling of topology relationships among
traffic elements and lanes without requiring additional computationally
expensive graph networks. Furthermore, we are the first to demonstrate that
knowledge can be distilled from models that utilize standard definition (SD)
maps to those operates without using SD maps, enabling superior performance
even in the absence of SD maps. Extensive experiments on the OpenLane-V2
dataset show that our approach outperforms baseline methods in both accuracy
and efficiency, achieving superior results in lane detection, traffic element
identification, and topology reasoning. Our code is available at
https://github.com/Yang-Li-2000/one-stage.git.

</details>


### [89] [The Early Bird Identifies the Worm: You Can't Beat a Head Start in Long-Term Body Re-ID (ECHO-BID)](https://arxiv.org/abs/2507.17640)
*Thomas M. Metz,Matthew Q. Hill,Alice J. O'Toole*

Main category: cs.CV

TL;DR: 该论文提出了ECHO-BID模型，基于EVA-02 Large骨干网络的长期人员重识别方法，在换衣服和遮挡场景下达到了最先进的性能表现


<details>
  <summary>Details</summary>
Motivation: 在无约束环境下进行人员识别面临距离、视角、成像条件和服装变化等重大挑战，现有方法在长期重识别特别是换衣服场景下性能不佳

Method: 构建了基于对象预训练EVA-02 Large骨干网络的ECHO-BID模型，采用掩码图像建模进行预训练，并在最具挑战性的换衣服数据上进行迁移学习，系统性比较了不同骨干架构、模型规模、预训练规模和迁移学习协议

Result: ECHO-BID在长期重识别任务上达到最先进结果，显著优于其他方法；在遮挡场景下也大幅超越其他方法；较小但更具挑战性的迁移学习数据集在跨数据集泛化方面表现更好

Conclusion: 增大模型规模和预训练期间的掩码图像建模是ECHO-BID强性能的基础；选择正确的预训练骨干架构和迁移学习协议能显著提升长期重识别性能；在最困难数据上，大数据集配合额外微调步骤效果最佳

Abstract: Person identification in unconstrained viewing environments presents
significant challenges due to variations in distance, viewpoint, imaging
conditions, and clothing. We introduce $\textbf{E}$va $\textbf{C}$lothes-Change
from $\textbf{H}$idden $\textbf{O}$bjects - $\textbf{B}$ody
$\textbf{ID}$entification (ECHO-BID), a class of long-term re-id models built
on object-pretrained EVA-02 Large backbones. We compare ECHO-BID to 9 other
models that vary systematically in backbone architecture, model size, scale of
object classification pretraining, and transfer learning protocol. Models were
evaluated on benchmark datasets across constrained, unconstrained, and occluded
settings. ECHO-BID, with transfer learning on the most challenging
clothes-change data, achieved state-of-the-art results on long-term re-id --
substantially outperforming other methods. ECHO-BID also surpassed other
methods by a wide margin in occluded viewing scenarios. A combination of
increased model size and Masked Image Modeling during pretraining underlie
ECHO-BID's strong performance on long-term re-id. Notably, a smaller, but more
challenging transfer learning dataset, generalized better across datasets than
a larger, less challenging one. However, the larger dataset with an additional
fine-tuning step proved best on the most difficult data. Selecting the correct
pretrained backbone architecture and transfer learning protocols can drive
substantial gains in long-term re-id performance.

</details>


### [90] [CNS-Bench: Benchmarking Image Classifier Robustness Under Continuous Nuisance Shifts](https://arxiv.org/abs/2507.17651)
*Olaf Dünkel,Artur Jesslen,Jiahao Xie,Christian Theobalt,Christian Rupprecht,Adam Kortylewski*

Main category: cs.CV

TL;DR: 本文提出CNS-Bench，一个连续噪声偏移基准测试，用于评估图像分类器在现实生成噪声偏移下的分布外鲁棒性，通过LoRA适配器应用于扩散模型来生成连续严重程度的噪声偏移。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机视觉模型在真实世界应用中面临分布外(OOD)场景的挑战，传统的合成损坏测试无法捕捉真实世界中的细微偏移，而现有扩散模型生成的基准测试局限于二元噪声偏移。

Method: 引入CNS-Bench连续噪声偏移基准，通过将LoRA适配器应用于扩散模型来生成具有连续严重程度的各种单独噪声偏移，并提出过滤机制来解决失效案例，实现可靠的生成模型基准测试。

Result: 对40多个分类器进行大规模研究评估，发现模型排名会随不同偏移和偏移尺度而变化，这在应用常见二元偏移时无法捕捉。连续尺度评估能够识别模型失效点，提供更细致的模型鲁棒性理解。

Conclusion: CNS-Bench为评估图像分类器的OOD鲁棒性提供了更现实和连续的基准测试方法，揭示了传统二元偏移测试的局限性，为理解模型在真实世界场景中的表现提供了更深入的见解。

Abstract: An important challenge when using computer vision models in the real world is
to evaluate their performance in potential out-of-distribution (OOD) scenarios.
While simple synthetic corruptions are commonly applied to test OOD robustness,
they often fail to capture nuisance shifts that occur in the real world.
Recently, diffusion models have been applied to generate realistic images for
benchmarking, but they are restricted to binary nuisance shifts. In this work,
we introduce CNS-Bench, a Continuous Nuisance Shift Benchmark to quantify OOD
robustness of image classifiers for continuous and realistic generative
nuisance shifts. CNS-Bench allows generating a wide range of individual
nuisance shifts in continuous severities by applying LoRA adapters to diffusion
models. To address failure cases, we propose a filtering mechanism that
outperforms previous methods, thereby enabling reliable benchmarking with
generative models. With the proposed benchmark, we perform a large-scale study
to evaluate the robustness of more than 40 classifiers under various nuisance
shifts. Through carefully designed comparisons and analyses, we find that model
rankings can change for varying shifts and shift scales, which cannot be
captured when applying common binary shifts. Additionally, we show that
evaluating the model performance on a continuous scale allows the
identification of model failure points, providing a more nuanced understanding
of model robustness. Project page including code and data:
https://genintel.github.io/CNS.

</details>


### [91] [Attention (as Discrete-Time Markov) Chains](https://arxiv.org/abs/2507.17657)
*Yotam Erel,Olaf Dünkel,Rishabh Dabral,Vladislav Golyanik,Christian Theobalt,Amit H. Bermano*

Main category: cs.CV

TL;DR: 本文将注意力矩阵重新解释为离散时间马尔可夫链，通过分析元稳态和TokenRank实现了零样本分割的最佳性能，并改进了无条件图像生成


<details>
  <summary>Details</summary>
Motivation: 现有的注意力机制研究只关注直接的注意力效应，缺乏统一框架来理解注意力分数的选择、求和和平均等操作，同时忽略了通过注意力传播的间接效应

Method: 将注意力矩阵解释为离散时间马尔可夫链，通过矩阵乘法和特征值分析计算元稳态及其流行度，定义TokenRank作为马尔可夫链的稳态向量来衡量全局token重要性

Result: 在零样本分割任务上达到了最先进的性能，TokenRank在无条件图像生成中带来了性能提升，证明了该框架在现代视觉Transformer中的有效性

Conclusion: 马尔可夫链框架为理解现代视觉Transformer中的token注意力机制提供了全新视角，通过元稳态分析和TokenRank能够有效改进多种视觉任务的性能

Abstract: We introduce a new interpretation of the attention matrix as a discrete-time
Markov chain. Our interpretation sheds light on common operations involving
attention scores such as selection, summation, and averaging in a unified
framework. It further extends them by considering indirect attention,
propagated through the Markov chain, as opposed to previous studies that only
model immediate effects. Our main observation is that tokens corresponding to
semantically similar regions form a set of metastable states, where the
attention clusters, while noisy attention scores tend to disperse. Metastable
states and their prevalence can be easily computed through simple matrix
multiplication and eigenanalysis, respectively. Using these lightweight tools,
we demonstrate state-of-the-art zero-shot segmentation. Lastly, we define
TokenRank -- the steady state vector of the Markov chain, which measures global
token importance. We demonstrate that using it brings improvements in
unconditional image generation. We believe our framework offers a fresh view of
how tokens are being attended in modern visual transformers.

</details>


### [92] [See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2507.17659)
*Junjie Wang,Yunhan Tang,Yijie Wang,Zhihao Yuan,Huan Wang,Yangfan He,Bin Li*

Main category: cs.CV

TL;DR: 提出了Synergos-VQA框架，通过融合整体证据、结构证据和因果证据三种互补的证据流，解决多模态大语言模型在知识基础视觉问答中依赖单一维度证据的局限性，在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在知识基础视觉问答任务中存在"只见树木不见森林"的问题，即过度依赖单一维度的证据进行推理，这种局限性阻碍了模型实现稳健、多面向的理解能力。

Method: 提出Synergos-VQA协同推理框架，在推理时并发生成并融合三种互补的证据流：(1)整体证据感知整个场景("森林")，(2)原型驱动模块提供的结构证据识别关键对象("树木")，(3)反事实探测提供的因果证据确保推理过程稳健可靠。通过协同融合这些多面向证据实现更全面可靠的推理过程。

Result: 在三个具有挑战性的基准测试(包括OK-VQA和A-OKVQA)上确立了新的最先进性能，展现出强大的即插即用能力，能够显著提升各种开源多模态大语言模型的表现，证明了优秀的方法设计可以超越单纯的模型规模扩展。

Conclusion: Synergos-VQA通过协同融合多维度证据流的创新方法，成功解决了现有多模态大语言模型在知识基础视觉问答中的推理瓶颈，为该领域提供了一个更加全面和可靠的推理框架，并证明了方法论创新的重要价值。

Abstract: Multimodal Large Language Models (MLLMs) have pushed the frontiers of
Knowledge-Based Visual Question Answering (KBVQA), yet their reasoning is
fundamentally bottlenecked by a reliance on uni-dimensional evidence. This
"seeing only the trees, but not the forest" approach prevents robust,
multi-faceted understanding. Inspired by the principle of seeing both the
forest and trees, we propose Synergos-VQA, a novel synergistic reasoning
framework. At its core, Synergos-VQA concurrently generates and fuses three
complementary evidence streams at inference time: (1) Holistic Evidence to
perceive the entire scene (the "forest"), (2) Structural Evidence from a
prototype-driven module to identify key objects (the "trees"), and (3) Causal
Evidence from a counterfactual probe to ensure the reasoning is robustly
grounded. By synergistically fusing this multi-faceted evidence, our framework
achieves a more comprehensive and reliable reasoning process. Extensive
experiments show that Synergos-VQA decisively establishes a new
state-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA.
Furthermore, our approach demonstrates strong plug-and-play capabilities,
significantly boosting various open-source MLLMs and proving that superior
methodological design can outperform sheer model scale.

</details>


### [93] [BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems](https://arxiv.org/abs/2507.17722)
*Malsha Ashani Mahawatta Dona,Beatriz Cabrero-Daniel,Yinan Yu,Christian Berger*

Main category: cs.CV

TL;DR: 研究评估了三个最先进视觉语言模型(VLMs)在交通场景理解中的幻觉问题，发现尽管VLMs在图像理解方面表现出色，但仍存在幻觉现象，可能危及自动驾驶系统安全，因此提出了BetterCheck等幻觉检测策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型在汽车感知系统中具有潜在应用价值，能够理解复杂交通情况，但存在幻觉问题——可能错误地检测不存在的交通参与者或忽略实际存在的脆弱道路使用者，这对自动驾驶系统安全构成威胁。

Method: 系统性评估3个最先进VLMs在Waymo开放数据集的多样化交通情况子集上的性能，分析其在交通场景理解中的幻觉现象，并提出BetterCheck等幻觉检测策略来为VLM支持的感知系统提供安全防护。

Result: 发现专有和开源VLMs都展现出卓越的图像理解能力，甚至能关注到人类难以发现的细节，但仍然容易在描述中编造元素，产生幻觉现象。

Conclusion: 尽管VLMs在交通场景理解方面表现优异，但幻觉问题仍然存在，需要像BetterCheck这样的幻觉检测策略来确保VLM支持的感知系统的安全性。

Abstract: Large language models (LLMs) are growingly extended to process multimodal
data such as text and video simultaneously. Their remarkable performance in
understanding what is shown in images is surpassing specialized neural networks
(NNs) such as Yolo that is supporting only a well-formed but very limited
vocabulary, ie., objects that they are able to detect. When being
non-restricted, LLMs and in particular state-of-the-art vision language models
(VLMs) show impressive performance to describe even complex traffic situations.
This is making them potentially suitable components for automotive perception
systems to support the understanding of complex traffic situations or edge case
situation. However, LLMs and VLMs are prone to hallucination, which mean to
either potentially not seeing traffic agents such as vulnerable road users who
are present in a situation, or to seeing traffic agents who are not there in
reality. While the latter is unwanted making an ADAS or autonomous driving
systems (ADS) to unnecessarily slow down, the former could lead to disastrous
decisions from an ADS. In our work, we are systematically assessing the
performance of 3 state-of-the-art VLMs on a diverse subset of traffic
situations sampled from the Waymo Open Dataset to support safety guardrails for
capturing such hallucinations in VLM-supported perception systems. We observe
that both, proprietary and open VLMs exhibit remarkable image understanding
capabilities even paying thorough attention to fine details sometimes difficult
to spot for us humans. However, they are also still prone to making up elements
in their descriptions to date requiring hallucination detection strategies such
as BetterCheck that we propose in our work.

</details>


### [94] [A Comprehensive Evaluation Framework for the Study of the Effects of Facial Filters on Face Recognition Accuracy](https://arxiv.org/abs/2507.17729)
*Kagan Ozturk,Louisa Conwill,Jacob Gutierrez,Kevin Bowyer,Walter J. Scheirer*

Main category: cs.CV

TL;DR: 本文提出了一个大规模研究面部滤镜对自动人脸识别影响的框架，通过分析Instagram、Snapchat、美图和Pitu等应用的滤镜，发现了跨文化差异，并提出了改善人脸识别性能的方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅关注少数特定风格的手工挑选滤镜对人脸识别的影响，无法有效涵盖社交媒体应用中广泛存在的各种滤镜类型，需要建立更全面的研究框架来评估滤镜对自动识别系统的影响。

Method: 建立了一个包含三个核心组件的研究框架：（1）构建受控的人脸图像数据集；（2）设计有原则的滤镜选择过程，选择具有代表性的滤镜进行实验；（3）设计一系列实验来评估滤镜对识别性能的影响，并通过案例研究分析不同文化背景下的应用差异。

Result: 通过对美国应用（Instagram、Snapchat）和中国应用（美图、Pitu）的案例研究，发现了滤镜效果存在跨文化差异。同时证明了在人脸嵌入空间中可以有效检测和恢复滤镜效果，从而改善人脸识别性能。

Conclusion: 该框架为大规模研究面部滤镜对自动人脸识别的影响提供了有效工具，揭示了不同文化背景下滤镜应用的差异性，并提出了通过检测和恢复滤镜效果来改善识别性能的解决方案。

Abstract: Facial filters are now commonplace for social media users around the world.
Previous work has demonstrated that facial filters can negatively impact
automated face recognition performance. However, these studies focus on small
numbers of hand-picked filters in particular styles. In order to more
effectively incorporate the wide ranges of filters present on various social
media applications, we introduce a framework that allows for larger-scale study
of the impact of facial filters on automated recognition. This framework
includes a controlled dataset of face images, a principled filter selection
process that selects a representative range of filters for experimentation, and
a set of experiments to evaluate the filters' impact on recognition. We
demonstrate our framework with a case study of filters from the American
applications Instagram and Snapchat and the Chinese applications Meitu and Pitu
to uncover cross-cultural differences. Finally, we show how the filtering
effect in a face embedding space can easily be detected and restored to improve
face recognition performance.

</details>


### [95] [Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention](https://arxiv.org/abs/2507.17745)
*Yiwen Chen,Zhihao Li,Yikai Wang,Hu Zhang,Qin Li,Chi Zhang,Guosheng Lin*

Main category: cs.CV

TL;DR: Ultra3D是一个高效的3D生成框架，通过VecSet表示和Part Attention机制显著加速稀疏体素建模，在保持高质量的同时实现最高6.7倍的生成速度提升，支持1024³分辨率的高分辨率3D内容生成。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏体素3D生成框架虽然能够生成高质量的3D内容，但由于两阶段扩散管道中注意力机制的二次复杂度，存在严重的计算效率问题，需要在不损失质量的前提下显著提升生成速度。

Method: 提出Ultra3D框架，包含两个关键创新：1）利用紧凑的VecSet表示在第一阶段高效生成粗糙对象布局，减少token数量并加速体素坐标预测；2）引入Part Attention几何感知局部注意力机制，将注意力计算限制在语义一致的部件区域内，同时构建可扩展的部件标注管道将原始网格转换为部件标记的稀疏体素。

Result: 实验表明Ultra3D支持1024³分辨率的高分辨率3D生成，在潜在特征生成阶段实现最高6.7倍的速度提升，在视觉保真度和用户偏好方面达到最先进性能，有效平衡了生成质量和计算效率。

Conclusion: Ultra3D成功解决了稀疏体素3D生成中的计算效率瓶颈，通过创新的表示方法和注意力机制设计，实现了高质量、高效率的3D内容生成，为实际应用中的大规模3D内容创建提供了可行的解决方案。

Abstract: Recent advances in sparse voxel representations have significantly improved
the quality of 3D content generation, enabling high-resolution modeling with
fine-grained geometry. However, existing frameworks suffer from severe
computational inefficiencies due to the quadratic complexity of attention
mechanisms in their two-stage diffusion pipelines. In this work, we propose
Ultra3D, an efficient 3D generation framework that significantly accelerates
sparse voxel modeling without compromising quality. Our method leverages the
compact VecSet representation to efficiently generate a coarse object layout in
the first stage, reducing token count and accelerating voxel coordinate
prediction. To refine per-voxel latent features in the second stage, we
introduce Part Attention, a geometry-aware localized attention mechanism that
restricts attention computation within semantically consistent part regions.
This design preserves structural continuity while avoiding unnecessary global
attention, achieving up to 6.7x speed-up in latent generation. To support this
mechanism, we construct a scalable part annotation pipeline that converts raw
meshes into part-labeled sparse voxels. Extensive experiments demonstrate that
Ultra3D supports high-resolution 3D generation at 1024 resolution and achieves
state-of-the-art performance in both visual fidelity and user preference.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [96] [Controllable Video Generation: A Survey](https://arxiv.org/abs/2507.16869)
*Yue Ma,Kunyu Feng,Zhongyuan Hu,Xinyu Wang,Yucheng Wang,Mingzhe Zheng,Xuanhua He,Chenyang Zhu,Hongyu Liu,Yingqing He,Zeyu Wang,Zhifeng Li,Xiu Li,Wei Liu,Dan Xu,Linfeng Zhang,Qifeng Chen*

Main category: cs.GR

TL;DR: 这是一篇关于可控视频生成的综述论文，系统回顾了当前视频生成基础模型的控制机制，从单一条件、多条件到通用可控生成方法进行了分类分析。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成基础模型主要基于文本到视频的生成，但仅靠文本提示难以表达复杂、多模态和细粒度的用户需求，使得用户难以精确控制生成的视频内容，因此需要整合额外的非文本条件来实现更可控的视频合成。

Method: 通过系统性综述的方法，首先介绍关键概念和开源视频生成模型，然后重点分析视频扩散模型中的控制机制，研究如何将不同类型的条件（如相机运动、深度图、人体姿态等）融入去噪过程来指导生成，最后根据控制信号类型对现有方法进行分类。

Result: 建立了可控视频生成领域的系统性分类框架，将现有方法分为单一条件生成、多条件生成和通用可控生成三大类，并提供了完整的文献库供研究者参考。

Conclusion: 通过整合额外的非文本控制条件，可以有效扩展预训练视频生成模型的能力，实现更精确和灵活的视频合成，提升AIGC驱动视频生成系统的实用性和可控性。

Abstract: With the rapid development of AI-generated content (AIGC), video generation
has emerged as one of its most dynamic and impactful subfields. In particular,
the advancement of video generation foundation models has led to growing demand
for controllable video generation methods that can more accurately reflect user
intent. Most existing foundation models are designed for text-to-video
generation, where text prompts alone are often insufficient to express complex,
multi-modal, and fine-grained user requirements. This limitation makes it
challenging for users to generate videos with precise control using current
models. To address this issue, recent research has explored the integration of
additional non-textual conditions, such as camera motion, depth maps, and human
pose, to extend pretrained video generation models and enable more controllable
video synthesis. These approaches aim to enhance the flexibility and practical
applicability of AIGC-driven video generation systems. In this survey, we
provide a systematic review of controllable video generation, covering both
theoretical foundations and recent advances in the field. We begin by
introducing the key concepts and commonly used open-source video generation
models. We then focus on control mechanisms in video diffusion models,
analyzing how different types of conditions can be incorporated into the
denoising process to guide generation. Finally, we categorize existing methods
based on the types of control signals they leverage, including single-condition
generation, multi-condition generation, and universal controllable generation.
For a complete list of the literature on controllable video generation
reviewed, please visit our curated repository at
https://github.com/mayuelala/Awesome-Controllable-Video-Generation.

</details>


### [97] [StreamME: Simplify 3D Gaussian Avatar within Live Stream](https://arxiv.org/abs/2507.17029)
*Luchuan Song,Yang Zhou,Zhan Xu,Yi Zhou,Deepali Aneja,Chenliang Xu*

Main category: cs.GR

TL;DR: StreamME是一种快速3D头像重建方法，能够同步录制和重建实时视频流中的头像，无需预缓存数据，采用基于3D高斯散点的即时训练策略，通过主要点简化策略优化效率，可应用于VR系统、在线会议等场景。


<details>
  <summary>Details</summary>
Motivation: 现有3D头像重建方法通常需要预缓存数据且训练速度慢，无法满足实时应用需求。为了实现无缝集成到下游应用中，需要一种能够从实时视频流中快速重建头像的方法，同时保护面部隐私并减少VR系统或在线会议中的通信带宽。

Method: 提出StreamME方法，基于3D高斯散点技术（3DGS），消除对可变形3DGS中MLP的依赖，仅依靠几何信息来显著提高对面部表情的适应速度。引入基于主要点的简化策略，在面部表面更稀疏地分布点云，在保持渲染质量的同时优化点数量，实现即时训练能力。

Result: 实现了从实时视频流中同步录制和重建头像，无需预缓存数据。方法具有出色的即时训练能力，能够快速适应面部表情变化，同时保持高质量的渲染效果。可以直接应用于动画、卡通化、重光照等下游任务。

Conclusion: StreamME成功实现了快速3D头像重建，通过基于3D高斯散点的即时训练策略和主要点简化方法，显著提高了训练效率和表情适应速度。该方法在保护面部隐私、减少通信带宽方面具有优势，可广泛应用于VR系统、在线会议以及各种下游应用场景。

Abstract: We propose StreamME, a method focuses on fast 3D avatar reconstruction. The
StreamME synchronously records and reconstructs a head avatar from live video
streams without any pre-cached data, enabling seamless integration of the
reconstructed appearance into downstream applications. This exceptionally fast
training strategy, which we refer to as on-the-fly training, is central to our
approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating
the reliance on MLPs in deformable 3DGS and relying solely on geometry, which
significantly improves the adaptation speed to facial expression. To further
ensure high efficiency in on-the-fly training, we introduced a simplification
strategy based on primary points, which distributes the point clouds more
sparsely across the facial surface, optimizing points number while maintaining
rendering quality. Leveraging the on-the-fly training capabilities, our method
protects the facial privacy and reduces communication bandwidth in VR system or
online conference. Additionally, it can be directly applied to downstream
application such as animation, toonify, and relighting. Please refer to our
project page for more details: https://songluchuan.github.io/StreamME/.

</details>


### [98] [GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP](https://arxiv.org/abs/2507.17174)
*Myeongwon Jung,Takanori Fujiwara,Jaemin Jo*

Main category: cs.GR

TL;DR: 本文针对UMAP降维方法的随机优化过程导致的结果不稳定问题，提出了(r,d)-stability框架来分析数据点在投影空间中的随机定位，并开发了可视化工具来评估投影的稳定性。


<details>
  <summary>Details</summary>
Motivation: UMAP作为广泛使用的降维方法，其随机优化过程对结果的影响尚未得到充分探索。研究发现UMAP经常产生不稳定的结果，数据点的投影位置更多由随机性决定而非邻域结构。

Method: 引入(r,d)-stability框架分析数据点在投影空间中的随机定位；使用"幽灵点"（数据点的副本）来表示由随机性导致的潜在位置变化；定义如果数据点的幽灵点在初始投影中被扰动在半径r的圆内，最终位置仍限制在半径d的圆内，则该数据点的投影为(r,d)-stable；开发自适应丢弃方案来高效计算幽灵投影。

Result: 自适应丢弃方案相比未优化基线减少了高达60%的运行时间，同时保持约90%的不稳定点检测准确率；开发了支持交互式探索数据点(r,d)-stability的可视化工具；在真实世界数据集上验证了框架的有效性。

Conclusion: 提出的(r,d)-stability框架能够有效分析和可视化UMAP投影的稳定性，为用户提供了评估降维结果可靠性的工具，并给出了框架有效使用的指导原则。

Abstract: Despite the widespread use of Uniform Manifold Approximation and Projection
(UMAP), the impact of its stochastic optimization process on the results
remains underexplored. We observed that it often produces unstable results
where the projections of data points are determined mostly by chance rather
than reflecting neighboring structures. To address this limitation, we
introduce (r,d)-stability to UMAP: a framework that analyzes the stochastic
positioning of data points in the projection space. To assess how stochastic
elements, specifically initial projection positions and negative sampling,
impact UMAP results, we introduce "ghosts", or duplicates of data points
representing potential positional variations due to stochasticity. We define a
data point's projection as (r,d)-stable if its ghosts perturbed within a circle
of radius r in the initial projection remain confined within a circle of radius
d for their final positions. To efficiently compute the ghost projections, we
develop an adaptive dropping scheme that reduces a runtime up to 60% compared
to an unoptimized baseline while maintaining approximately 90% of unstable
points. We also present a visualization tool that supports the interactive
exploration of the (r,d)-stability of data points. Finally, we demonstrate the
effectiveness of our framework by examining the stability of projections of
real-world datasets and present usage guidelines for the effective use of our
framework.

</details>


### [99] [A Scientist Question: Research on the Impact of Super Structured Quadrilateral Meshes on Convergence and Accuracy of Finite Element Analysis](https://arxiv.org/abs/2507.17184)
*Hui Zhao*

Main category: cs.GR

TL;DR: 本文提出了一个全新的研究方向：探索超结构化四边形网格的全局排列结构对有限元计算收敛性和精度的影响，旨在解决当前网格生成过度依赖"经验"的问题。


<details>
  <summary>Details</summary>
Motivation: 当前工业界和学术界的有限元计算收敛性和精度高度依赖网格生成的方法和质量，而国内学术界主要关注四边形和六面体的局部质量，缺乏对全局排列结构影响的系统研究，导致网格生成阶段严重依赖"经验"而缺乏理论指导。

Method: 提出探索超结构化四边形网格的整体全局排列结构和模式对有限元计算影响的研究方向，需要运用大量现代二维和三维几何拓扑理论，包括模空间、Teichmüller空间、调和叶状结构、动力系统、曲面映射、亚纯二次微分等理论工具。

Result: 通过建立这一新的研究领域，可以为网格生成提供理论指导，明确判断哪种全局网格排列能够确保有限元计算的收敛性，从而摆脱对经验的过度依赖。

Conclusion: 该研究方向的建立将有助于解决当前仿真中网格生成阶段缺乏理论依据的问题，为生成具有可控整体排列结构的超结构化四边形网格提供科学方法，提升有限元计算的可靠性和精度。

Abstract: In the current practices of both industry and academia, the convergence and
accuracy of finite element calculations are closely related to the methods and
quality of mesh generation. For years, the research on high-quality mesh
generation in the domestic academic field has mainly referred to the local
quality of quadrilaterals and hexahedrons approximating that of squares and
cubes. The main contribution of this paper is to propose a brand-new research
direction and content: it is necessary to explore and study the influence of
the overall global arrangement structure and pattern of super structured
quadrilateral meshes on the convergence and calculation accuracy of finite
element calculations. Through the research in this new field, it can help solve
the non-rigorous state of serious reliance on "experience" in the mesh
generation stage during simulation in the current industry and academia, and
make clear judgments on which global arrangements of mesh generation can ensure
the convergence of finite element calculations. In order to generate and design
super-structured quadrilateral meshes with controllable overall arrangement
structures, a large number of modern two-dimensional and three-dimensional
geometric topology theories are required, such as moduli space, Teichm\"uller
space, harmonic foliations, dynamical systems, surface mappings, meromorphic
quadratic differentials, surface mappings, etc.

</details>


### [100] [Visualization-Driven Illumination for Density Plots](https://arxiv.org/abs/2507.17265)
*Xin Chen,Yunhai Wang,Huaiwei Bao,Kecheng Lu,Jaemin Jo,Chi-Wing Fu,Jean-Daniel Fekete*

Main category: cs.GR

TL;DR: 本文提出了一种新的可视化驱动光照模型来增强密度图，能够有效揭示高密度和中密度区域的详细结构以及低密度区域的异常值，同时避免密度场颜色的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 在可视化大规模稠密离散点样本时，散点图和点密度图常常遭受过度绘制问题，而现有的密度图光照模型可能产生颜色失真并隐藏低密度区域的细节，使得密度值查找、比较和异常值发现变得困难。

Method: 提出了两个关键技术创新：（1）一个可视化驱动的光照模型，天然支持密度图特定的分析任务；（2）一种新的图像合成技术，用于减少图像阴影与颜色编码密度值之间的干扰。

Result: 通过定量研究、受控实验的实证评估以及两个案例研究，在包含多达200万数据点样本的12个数据集上验证了该技术的有效性。

Conclusion: 该可视化驱动光照模型能够有效增强密度图的可视化效果，既能揭示高密度区域的详细结构，又能突出显示低密度区域的异常值，同时避免了传统方法中的颜色失真问题。

Abstract: We present a novel visualization-driven illumination model for density plots,
a new technique to enhance density plots by effectively revealing the detailed
structures in high- and medium-density regions and outliers in low-density
regions, while avoiding artifacts in the density field's colors. When
visualizing large and dense discrete point samples, scatterplots and dot
density maps often suffer from overplotting, and density plots are commonly
employed to provide aggregated views while revealing underlying structures.
Yet, in such density plots, existing illumination models may produce color
distortion and hide details in low-density regions, making it challenging to
look up density values, compare them, and find outliers. The key novelty in
this work includes (i) a visualization-driven illumination model that
inherently supports density-plot-specific analysis tasks and (ii) a new image
composition technique to reduce the interference between the image shading and
the color-encoded density values. To demonstrate the effectiveness of our
technique, we conducted a quantitative study, an empirical evaluation of our
technique in a controlled study, and two case studies, exploring twelve
datasets with up to two million data point samples.

</details>


### [101] [Temporal Smoothness-Aware Rate-Distortion Optimized 4D Gaussian Splatting](https://arxiv.org/abs/2507.17336)
*Hyeongmin Lee,Kyungjune Baek*

Main category: cs.GR

TL;DR: 本文提出了一种针对4D高斯喷射(4DGS)的端到端RD优化压缩框架，通过小波变换处理运动轨迹，实现了高达91倍的压缩比，同时保持高视觉保真度，解决了4DGS在实际部署中的存储和传输挑战。


<details>
  <summary>Details</summary>
Motivation: 动态4D高斯喷射虽然有效扩展了3D高斯喷射的高速渲染能力来表示体积视频，但存在高斯数量庞大、时间冗余严重以及缺乏熵感知压缩框架等问题，导致存储需求巨大，给实际部署、边缘设备处理和数据传输带来重大挑战。

Method: 基于Ex4DGS方法，从现有3DGS压缩方法出发确保兼容性，同时有效解决时间轴引入的额外挑战。关键创新是采用小波变换来处理运动轨迹而非独立存储每个点的运动轨迹，利用真实世界的平滑性先验显著提升存储效率，并提供用户可控的压缩效率与渲染质量平衡。

Result: 广泛实验证明了方法的有效性，相比原始Ex4DGS模型实现了高达91倍的压缩比，同时保持了高视觉保真度。结果突出了该框架在从资源受限的边缘设备到高性能环境等多样化场景中进行实时动态场景渲染的适用性。

Conclusion: 提出的端到端RD优化压缩框架成功解决了4DGS的存储和传输挑战，通过小波变换技术实现了显著的压缩改进，为4DGS在各种计算平台上的灵活、高保真渲染奠定了基础，具有重要的实际应用价值。

Abstract: Dynamic 4D Gaussian Splatting (4DGS) effectively extends the high-speed
rendering capabilities of 3D Gaussian Splatting (3DGS) to represent volumetric
videos. However, the large number of Gaussians, substantial temporal
redundancies, and especially the absence of an entropy-aware compression
framework result in large storage requirements. Consequently, this poses
significant challenges for practical deployment, efficient edge-device
processing, and data transmission. In this paper, we introduce a novel
end-to-end RD-optimized compression framework tailored for 4DGS, aiming to
enable flexible, high-fidelity rendering across varied computational platforms.
Leveraging Fully Explicit Dynamic Gaussian Splatting (Ex4DGS), one of the
state-of-the-art 4DGS methods, as our baseline, we start from the existing 3DGS
compression methods for compatibility while effectively addressing additional
challenges introduced by the temporal axis. In particular, instead of storing
motion trajectories independently per point, we employ a wavelet transform to
reflect the real-world smoothness prior, significantly enhancing storage
efficiency. This approach yields significantly improved compression ratios and
provides a user-controlled balance between compression efficiency and rendering
quality. Extensive experiments demonstrate the effectiveness of our method,
achieving up to 91x compression compared to the original Ex4DGS model while
maintaining high visual fidelity. These results highlight the applicability of
our framework for real-time dynamic scene rendering in diverse scenarios, from
resource-constrained edge devices to high-performance environments.

</details>


### [102] [Parametric Integration with Neural Integral Operators](https://arxiv.org/abs/2507.17440)
*Christoph Schied,Alexander Keller*

Main category: cs.GR

TL;DR: 提出了一种材质无关的去噪方法(MAD)，通过在材质着色前去除噪声来提升实时渲染图像质量，使用神经网络近似光传输积分算子实现参数化积分


<details>
  <summary>Details</summary>
Motivation: 实时渲染由于采样预算限制经常产生噪声图像，传统去噪器虽能生成无噪声图像但是在已着色的噪声图像上进行滤波，存在改进空间

Method: 在材质着色之前进行去噪处理，采用材质无关的去噪方法(MAD)，利用神经网络近似光传输积分算子，通过神经算子执行参数化积分

Result: 该方法可实时运行，仅需单帧数据，能与现有去噪器和时间抗锯齿技术无缝集成，训练效率高，易于与基于物理的渲染算法结合

Conclusion: 通过在着色前去噪的新策略，结合神经网络近似光传输积分，实现了高效的实时渲染图像质量提升，为实时渲染去噪提供了新的解决方案

Abstract: Real-time rendering imposes strict limitations on the sampling budget for
light transport simulation, often resulting in noisy images. However, denoisers
have demonstrated that it is possible to produce noise-free images through
filtering. We enhance image quality by removing noise before material shading,
rather than filtering already shaded noisy images. This approach allows for
material-agnostic denoising (MAD) and leverages machine learning by
approximating the light transport integral operator with a neural network,
effectively performing parametric integration with neural operators. Our method
operates in real-time, requires data from only a single frame, seamlessly
integrates with existing denoisers and temporal anti-aliasing techniques, and
is efficient to train. Additionally, it is straightforward to incorporate with
physically based rendering algorithms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [103] [Evaluating Artificial Intelligence Algorithms for the Standardization of Transtibial Prosthetic Socket Shape Design](https://arxiv.org/abs/2507.16818)
*C. H. E. Jordaan,M. van der Stelt,T. J. J. Maal,V. M. A. Stirler,R. Leijendekkers,T. Kachman,G. A. de Jong*

Main category: cs.LG

TL;DR: 本研究开发了多种人工智能方法来标准化经胫假肢接受腔设计，通过对118名患者数据的分析，发现随机森林模型在预测假肢师适应性调整方面表现最佳，中位表面距离误差为1.24毫米。


<details>
  <summary>Details</summary>
Motivation: 经胫假肢接受腔的质量依赖于假肢师的手工技能和专业知识，缺乏标准化。研究旨在利用人工智能技术帮助标准化经胫假肢接受腔设计过程，减少对个人技能的依赖。

Method: 收集118名患者的残肢三维扫描数据和对应的假肢师设计接受腔模型。采用形态模型和主成分分析进行数据预处理、对齐、标准化和压缩。开发三种算法：3D神经网络、前馈神经网络和随机森林，用于预测最终接受腔形状或假肢师的适应性调整。

Result: 所有算法中，估计所需适应性调整的性能都优于直接预测最终接受腔形状。随机森林模型在适应性预测方面表现最佳，中位表面距离误差为1.24毫米，第一四分位数为1.03毫米，第三四分位数为1.54毫米。

Conclusion: 人工智能方法，特别是随机森林模型，能够有效辅助经胫假肢接受腔设计的标准化。通过预测假肢师的适应性调整而非直接预测最终形状，可以获得更好的性能表现，为假肢制作提供了有前景的技术支持。

Abstract: The quality of a transtibial prosthetic socket depends on the prosthetist's
skills and expertise, as the fitting is performed manually. This study
investigates multiple artificial intelligence (AI) approaches to help
standardize transtibial prosthetic socket design. Data from 118 patients were
collected by prosthetists working in the Dutch healthcare system. This data
consists of a three-dimensional (3D) scan of the residual limb and a
corresponding 3D model of the prosthetist-designed socket. Multiple data
pre-processing steps are performed for alignment, standardization and
optionally compression using Morphable Models and Principal Component Analysis.
Afterward, three different algorithms - a 3D neural network, Feedforward neural
network, and random forest - are developed to either predict 1) the final
socket shape or 2) the adaptations performed by a prosthetist to predict the
socket shape based on the 3D scan of the residual limb. Each algorithm's
performance was evaluated by comparing the prosthetist-designed socket with the
AI-generated socket, using two metrics in combination with the error location.
First, we measure the surface-to-surface distance to assess the overall surface
error between the AI-generated socket and the prosthetist-designed socket.
Second, distance maps between the AI-generated and prosthetist sockets are
utilized to analyze the error's location. For all algorithms, estimating the
required adaptations outperformed direct prediction of the final socket shape.
The random forest model applied to adaptation prediction yields the lowest
error with a median surface-to-surface distance of 1.24 millimeters, a first
quartile of 1.03 millimeters, and a third quartile of 1.54 millimeters.

</details>


### [104] [Exploring the Frontiers of kNN Noisy Feature Detection and Recovery for Self-Driving Labs](https://arxiv.org/abs/2507.16833)
*Qiuyu Shi,Kangming Li,Yao Fehlis,Daniel Persaud,Robert Black,Jason Hattrick-Simpers*

Main category: cs.LG

TL;DR: 本研究开发了一个自动化工作流程，用于系统性检测自驱动实验室(SDL)中的噪声特征、确定可纠正的样本-特征配对并恢复正确的特征值，以提高材料发现中的数据质量和实验精度。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室在材料发现中具有加速潜力，但输入参数捕获中的错误可能破坏用于建模系统性能的特征，从而影响当前和未来的研究活动。因此需要开发方法来检测和纠正噪声特征，以增强数据质量。

Method: 开发了一个自动化工作流程，包括：1）系统性检测噪声特征；2）确定可以纠正的样本-特征配对；3）恢复正确的特征值。使用kNN插补方法进行数据恢复，并系统性研究数据集大小、噪声强度和特征值分布对噪声特征检测和恢复能力的影响。

Result: 研究发现：1）高强度噪声和大型训练数据集有利于噪声特征的检测和纠正；2）低强度噪声会降低检测和恢复效果，但可通过更大的清洁训练数据集来补偿；3）连续和分散特征分布相比离散或窄分布特征显示出更好的可恢复性；4）为材料数据集中的kNN插补提供了切实的基准。

Conclusion: 该研究展示了一个模型无关的框架，用于在存在噪声、有限数据和不同特征分布情况下进行合理的数据恢复，最终旨在提高自动化材料发现中的数据质量和实验精度。

Abstract: Self-driving laboratories (SDLs) have shown promise to accelerate materials
discovery by integrating machine learning with automated experimental
platforms. However, errors in the capture of input parameters may corrupt the
features used to model system performance, compromising current and future
campaigns. This study develops an automated workflow to systematically detect
noisy features, determine sample-feature pairings that can be corrected, and
finally recover the correct feature values. A systematic study is then
performed to examine how dataset size, noise intensity, and feature value
distribution affect both the detectability and recoverability of noisy
features. In general, high-intensity noise and large training datasets are
conducive to the detection and correction of noisy features. Low-intensity
noise reduces detection and recovery but can be compensated for by larger clean
training data sets. Detection and correction results vary between features with
continuous and dispersed feature distributions showing greater recoverability
compared to features with discrete or narrow distributions. This systematic
study not only demonstrates a model agnostic framework for rational data
recovery in the presence of noise, limited data, and differing feature
distributions but also provides a tangible benchmark of kNN imputation in
materials data sets. Ultimately, it aims to enhance data quality and
experimental precision in automated materials discovery.

</details>


### [105] [TD-Interpreter: Enhancing the Understanding of Timing Diagrams with Visual-Language Learning](https://arxiv.org/abs/2507.16844)
*Jie He,Vincent Theo Willem Kenbeek,Zhantao Yang,Meixun Qu,Ezio Bartocci,Dejan Ničković,Radu Grosu*

Main category: cs.LG

TL;DR: 本文介绍了TD-Interpreter，一个专门帮助工程师理解复杂时序图的机器学习工具，通过微调7B多模态大语言模型LLaVA实现，并开发了合成数据生成流程来解决训练数据不足问题。


<details>
  <summary>Details</summary>
Motivation: 工程师在设计和验证过程中需要理解来自第三方的复杂时序图，但现有工具在这方面支持不足，因此需要一个专门的视觉问答环境来帮助工程师查询和理解时序图。

Method: 通过微调轻量级7B多模态大语言模型LLaVA来实现TD-Interpreter；开发了一个合成数据生成工作流程，将视觉信息与其文本解释对齐，以解决训练数据有限的问题；构建了一个视觉问答环境，允许工程师输入时序图并进行设计和验证查询。

Result: 实验评估表明TD-Interpreter在评估基准上大幅超越了未调优的GPT-4o，证明了该工具的有效性和实用性。

Conclusion: TD-Interpreter成功地为工程师提供了一个有效的工具来理解和查询复杂的时序图，通过多模态学习和合成数据生成的方法克服了数据稀缺的挑战，在性能上显著优于现有的通用模型。

Abstract: We introduce TD-Interpreter, a specialized ML tool that assists engineers in
understanding complex timing diagrams (TDs), originating from a third party,
during their design and verification process. TD-Interpreter is a visual
question-answer environment which allows engineers to input a set of TDs and
ask design and verification queries regarding these TDs. We implemented
TD-Interpreter with multimodal learning by fine-tuning LLaVA, a lightweight 7B
Multimodal Large Language Model (MLLM). To address limited training data
availability, we developed a synthetic data generation workflow that aligns
visual information with its textual interpretation. Our experimental evaluation
demonstrates the usefulness of TD-Interpreter which outperformed untuned GPT-4o
by a large margin on the evaluated benchmarks.

</details>


### [106] [Reinforcement Learning in hyperbolic space for multi-step reasoning](https://arxiv.org/abs/2507.16864)
*Tao Xu,Dung-Yang Lee,Momiao Xiong*

Main category: cs.LG

TL;DR: 本文提出了一种将双曲变换器集成到强化学习中的新框架，用于多步推理任务。该方法利用双曲嵌入有效建模层次结构，在FrontierMath和非线性最优控制问题上相比传统变换器RL方法显著提升了准确性（32%-45%）并减少了计算时间（16%-32%）。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在处理复杂推理任务时面临信用分配、高维状态表示和稳定性等挑战。多步推理是人工智能的基础挑战，在数学问题求解到动态环境决策等应用中都很重要。需要新的方法来克服这些限制并提升多步推理能力。

Method: 提出了一种将双曲变换器集成到强化学习中的新框架。该方法利用双曲嵌入来有效建模层次结构，结合了变换器架构和双曲几何的最新进展。文章提供了理论见解和算法细节来实现这一集成。

Result: 在FrontierMath基准测试中，准确性提升32%-44%，计算时间减少16%-32%；在非线性最优控制基准测试中，准确性提升43%-45%，计算时间减少16%-17%。这些结果相比使用普通变换器的强化学习方法都有显著改进。

Conclusion: 双曲变换器在强化学习中具有巨大潜力，特别是在涉及层次结构的多步推理任务中。该框架成功解决了传统RL方法的局限性，为复杂推理任务提供了更有效的解决方案，在准确性和计算效率方面都实现了显著提升。

Abstract: Multi-step reasoning is a fundamental challenge in artificial intelligence,
with applications ranging from mathematical problem-solving to decision-making
in dynamic environments. Reinforcement Learning (RL) has shown promise in
enabling agents to perform multi-step reasoning by optimizing long-term
rewards. However, conventional RL methods struggle with complex reasoning tasks
due to issues such as credit assignment, high-dimensional state
representations, and stability concerns. Recent advancements in Transformer
architectures and hyperbolic geometry have provided novel solutions to these
challenges. This paper introduces a new framework that integrates hyperbolic
Transformers into RL for multi-step reasoning. The proposed approach leverages
hyperbolic embeddings to model hierarchical structures effectively. We present
theoretical insights, algorithmic details, and experimental results that
include Frontier Math and nonlinear optimal control problems. Compared to RL
with vanilla transformer, the hyperbolic RL largely improves accuracy by
(32%~44%) on FrontierMath benchmark, (43%~45%) on nonlinear optimal control
benchmark, while achieving impressive reduction in computational time by
(16%~32%) on FrontierMath benchmark, (16%~17%) on nonlinear optimal control
benchmark. Our work demonstrates the potential of hyperbolic Transformers in
reinforcement learning, particularly for multi-step reasoning tasks that
involve hierarchical structures.

</details>


### [107] [Diffusion-Modeled Reinforcement Learning for Carbon and Risk-Aware Microgrid Optimization](https://arxiv.org/abs/2507.16867)
*Yunyi Zhao,Wei Zhang,Cheng Xiang,Hongyang Du,Dusit Niyato,Shuhua Gao*

Main category: cs.LG

TL;DR: 本文提出了DiffCarl，一种基于扩散模型的碳感知和风险感知强化学习算法，用于多微电网系统的智能运行，通过将扩散模型集成到深度强化学习框架中，实现了在不确定性下的自适应能源调度，同时显著降低了运营成本和碳排放


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源集成度不断提高和系统复杂性增加，微电网社区在不确定性条件下面临实时能源调度和优化的重大挑战，需要开发能够同时考虑碳排放和运营风险的智能调度算法

Method: 将扩散模型集成到深度强化学习(DRL)框架中，通过去噪生成过程学习动作分布，增强DRL策略的表达能力，使其能够在动态和不确定的微电网环境中实现碳感知和风险感知的调度

Result: 实验研究表明，DiffCarl相比经典算法和最先进的DRL解决方案，运营成本降低了2.3-30.1%，相比碳不敏感变体减少了28.7%的碳排放，并且降低了性能变异性

Conclusion: DiffCarl是一个实用且前瞻性的解决方案，其灵活的设计允许高效适应不同的系统配置和目标，支持在不断发展的能源系统中的实际部署

Abstract: This paper introduces DiffCarl, a diffusion-modeled carbon- and risk-aware
reinforcement learning algorithm for intelligent operation of multi-microgrid
systems. With the growing integration of renewables and increasing system
complexity, microgrid communities face significant challenges in real-time
energy scheduling and optimization under uncertainty. DiffCarl integrates a
diffusion model into a deep reinforcement learning (DRL) framework to enable
adaptive energy scheduling under uncertainty and explicitly account for carbon
emissions and operational risk. By learning action distributions through a
denoising generation process, DiffCarl enhances DRL policy expressiveness and
enables carbon- and risk-aware scheduling in dynamic and uncertain microgrid
environments. Extensive experimental studies demonstrate that it outperforms
classic algorithms and state-of-the-art DRL solutions, with 2.3-30.1% lower
operational cost. It also achieves 28.7% lower carbon emissions than those of
its carbon-unaware variant and reduces performance variability. These results
highlight DiffCarl as a practical and forward-looking solution. Its flexible
design allows efficient adaptation to different system configurations and
objectives to support real-world deployment in evolving energy systems.

</details>


### [108] [Navigation through Non-Compact Symmetric Spaces: a mathematical perspective on Cartan Neural Networks](https://arxiv.org/abs/2507.16871)
*Pietro Giuseppe Fré,Federico Milanesio,Guido Sanguinetti,Matteo Santoro*

Main category: cs.LG

TL;DR: 这篇论文探讨了基于非紧对称空间U/H的卡坦神经网络的数学基础，旨在发展几何一致的神经网络理论，实现协变性和几何可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络缺乏几何一致性和可解释性，需要利用齐次流形和群论结构来构建具有几何意义的神经网络理论。

Method: 基于非紧对称空间U/H作为齐次流形，详细分析卡坦神经网络的数学结构，包括层的几何性质以及层间映射如何与这些结构相互作用。

Result: 展示了卡坦神经网络的协变性和几何可解释性，证明了这些几何概念在机器学习环境中的可行性和性能。

Conclusion: 这项工作与配套论文一起，构成了利用群论结构发展完全几何可解释神经网络理论的第一步，为神经网络的几何理论奠定了基础。

Abstract: Recent work has identified non-compact symmetric spaces U/H as a promising
class of homogeneous manifolds to develop a geometrically consistent theory of
neural networks. An initial implementation of these concepts has been presented
in a twin paper under the moniker of Cartan Neural Networks, showing both the
feasibility and the performance of these geometric concepts in a machine
learning context. The current paper expands on the mathematical structures
underpinning Cartan Neural Networks, detailing the geometric properties of the
layers and how the maps between layers interact with such structures to make
Cartan Neural Networks covariant and geometrically interpretable. Together,
these twin papers constitute a first step towards a fully geometrically
interpretable theory of neural networks exploiting group-theoretic structures

</details>


### [109] [Confidence Optimization for Probabilistic Encoding](https://arxiv.org/abs/2507.16881)
*Pengjiu Xia,Yidian Huang,Wenchao Wei,Yuwen Tan*

Main category: cs.LG

TL;DR: 提出了一种置信度优化概率编码(CPE)方法，通过置信度感知机制和L2正则化改进概率编码中的距离测量可靠性，在BERT和RoBERTa模型上显著提升了自然语言分类任务的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 概率编码虽然能够实现从确定性到不确定性状态的平滑过渡并增强泛化能力，但高斯噪声的随机性会扭曲分类任务中基于点的距离测量，影响分类效果的可靠性。

Method: 提出置信度优化概率编码(CPE)方法，包含两个关键策略：1）引入置信度感知机制来调整距离计算，确保概率编码分类任务中的一致性和可靠性；2）用简单的L2正则化项替代基于不可靠先验假设的传统KL散度方差正则化，直接约束方差。

Result: 在自然语言分类任务上进行了广泛实验，该方法在BERT和RoBERTa模型上都显著提高了性能和泛化能力。该方法具有模型无关性，可以应用于不同的神经网络架构。

Conclusion: CPE方法成功解决了概率编码中高斯噪声导致的距离测量失真问题，通过置信度感知机制和L2正则化有效提升了分类任务的可靠性和泛化性能，为概率编码在自然语言处理领域的应用提供了有效的改进方案。

Abstract: Probabilistic encoding introduces Gaussian noise into neural networks,
enabling a smooth transition from deterministic to uncertain states and
enhancing generalization ability. However, the randomness of Gaussian noise
distorts point-based distance measurements in classification tasks. To mitigate
this issue, we propose a confidence optimization probabilistic encoding (CPE)
method that improves distance reliability and enhances representation learning.
Specifically, we refine probabilistic encoding with two key strategies: First,
we introduce a confidence-aware mechanism to adjust distance calculations,
ensuring consistency and reliability in probabilistic encoding classification
tasks. Second, we replace the conventional KL divergence-based variance
regularization, which relies on unreliable prior assumptions, with a simpler L2
regularization term to directly constrain variance. The method we proposed is
model-agnostic, and extensive experiments on natural language classification
tasks demonstrate that our method significantly improves performance and
generalization on both the BERT and the RoBERTa model.

</details>


### [110] [SplitMeanFlow: Interval Splitting Consistency in Few-Step Generative Modeling](https://arxiv.org/abs/2507.16884)
*Yi Guo,Wei Wang,Zhihang Yuan,Rong Cao,Kuan Chen,Zhengyang Chen,Yuanyuan Huo,Yang Zhang,Yuping Wang,Shouda Liu,Yuxuan Wang*

Main category: cs.LG

TL;DR: 本文提出SplitMeanFlow方法，通过区间分割一致性的代数恒等式来学习平均速度场，相比MeanFlow的微分方法更高效，在语音合成中实现20倍加速


<details>
  <summary>Details</summary>
Motivation: Flow Matching等生成模型虽然性能优秀，但迭代采样过程计算开销大。现有的MeanFlow方法通过微分恒等式学习平均速度场来实现少步或单步生成，但微分方法存在局限性，需要JVP计算，实现复杂且训练不稳定

Method: 回归平均速度的第一性原理，利用定积分的可加性，推导出纯代数的"区间分割一致性"恒等式。该恒等式在不同时间区间上建立平均速度场的自引用关系，无需微分算子。基于此原理构建SplitMeanFlow训练框架，直接将代数一致性作为学习目标

Result: 理论上证明了当区间分割趋于无穷小时，SplitMeanFlow的代数一致性收敛到MeanFlow的微分恒等式。实践中，该方法消除了JVP计算需求，实现更简单，训练更稳定，硬件兼容性更广。在大规模语音合成产品中成功部署，实现20倍加速

Conclusion: SplitMeanFlow为学习平均速度场提供了更通用和高效的理论基础，通过纯代数方法克服了现有微分方法的限制，在保持理论严谨性的同时显著提升了实用性和效率

Abstract: Generative models like Flow Matching have achieved state-of-the-art
performance but are often hindered by a computationally expensive iterative
sampling process. To address this, recent work has focused on few-step or
one-step generation by learning the average velocity field, which directly maps
noise to data. MeanFlow, a leading method in this area, learns this field by
enforcing a differential identity that connects the average and instantaneous
velocities. In this work, we argue that this differential formulation is a
limiting special case of a more fundamental principle. We return to the first
principles of average velocity and leverage the additivity property of definite
integrals. This leads us to derive a novel, purely algebraic identity we term
Interval Splitting Consistency. This identity establishes a self-referential
relationship for the average velocity field across different time intervals
without resorting to any differential operators. Based on this principle, we
introduce SplitMeanFlow, a new training framework that enforces this algebraic
consistency directly as a learning objective. We formally prove that the
differential identity at the core of MeanFlow is recovered by taking the limit
of our algebraic consistency as the interval split becomes infinitesimal. This
establishes SplitMeanFlow as a direct and more general foundation for learning
average velocity fields. From a practical standpoint, our algebraic approach is
significantly more efficient, as it eliminates the need for JVP computations,
resulting in simpler implementation, more stable training, and broader hardware
compatibility. One-step and two-step SplitMeanFlow models have been
successfully deployed in large-scale speech synthesis products (such as
Doubao), achieving speedups of 20x.

</details>


### [111] [SiLQ: Simple Large Language Model Quantization-Aware Training](https://arxiv.org/abs/2507.16933)
*Steven K. Esser,Jeffrey L. McKinstry,Deepika Bablani,Rathinakumar Appuswamy,Dharmendra S. Modha*

Main category: cs.LG

TL;DR: 提出了一种简单的端到端量化感知训练方法，仅增加不到0.1%的训练预算就能在多个现代基准测试中大幅超越现有量化方法，适用于不同模型架构且无需额外操作。


<details>
  <summary>Details</summary>
Motivation: 大语言模型量化可以减少推理延迟、模型大小和能耗，提升用户体验并降低成本。但现有方法在保持精度的同时实现高效量化仍面临挑战，特别是需要与专用推理加速器兼容。

Method: 采用简单的端到端量化感知训练方法，该方法可以应用于激活值、缓存和权重的量化，不需要在模型中引入除量化本身之外的任何额外操作，且能够跨不同模型架构进行泛化。

Result: 在多个现代基准测试中，该方法在基础模型和指令调优模型变体上都大幅超越了领先的已发表量化方法，同时训练预算增加不到0.1%。

Conclusion: 该研究展示了一种高效的量化感知训练方法，能够以极小的训练成本显著提升量化模型性能，具有良好的通用性和实用性，适合与专用推理加速器配合使用。

Abstract: Large language models can be quantized to reduce inference time latency,
model size, and energy consumption, thereby delivering a better user experience
at lower cost. A challenge exists to deliver quantized models with minimal loss
of accuracy in reasonable time, and in particular to do so without requiring
mechanisms incompatible with specialized inference accelerators. Here, we
demonstrate a simple, end-to-end quantization-aware training approach that,
with an increase in total model training budget of less than 0.1%, outperforms
the leading published quantization methods by large margins on several modern
benchmarks, with both base and instruct model variants. The approach easily
generalizes across different model architectures, can be applied to
activations, cache, and weights, and requires the introduction of no additional
operations to the model other than the quantization itself.

</details>


### [112] [Hierarchical Reinforcement Learning Framework for Adaptive Walking Control Using General Value Functions of Lower-Limb Sensor Signals](https://arxiv.org/abs/2507.16983)
*Sonny T. Jones,Grange M. Simpson,Patrick M. Pilarski,Ashley N. Dalrymple*

Main category: cs.LG

TL;DR: 研究团队使用分层强化学习(HRL)开发下肢外骨骼的自适应控制策略，通过预测传感器信号提高在不同地形上的行走决策准确性


<details>
  <summary>Details</summary>
Motivation: 为运动障碍患者开发能够增强移动性和自主性的下肢外骨骼控制系统，需要解决在复杂多变地形环境下的自适应控制问题

Method: 采用分层强化学习方法，将外骨骼控制分解为高层地形策略适应和低层预测信息提供两个框架。通过持续学习一般价值函数(GVFs)来预测来自肌电图、压力鞋垫和关节角度计等多种传感器的未来信号值，并将实际和预测信号整合到策略网络中

Result: 添加GVFs预测信息显著提高了网络整体准确性。在平地、不平地面、上下坡道和转弯等容易被误分类的地形上，地形特定性能都有所提升。预测信息在不确定性情况下能够有效辅助决策制定

Conclusion: 预测信息能够在地形分类不确定性高的情况下辅助决策制定，为分层强化学习和外骨骼开发提供了新见解，有助于实现在不同行走环境中的安全过渡和穿越

Abstract: Rehabilitation technology is a natural setting to study the shared learning
and decision-making of human and machine agents. In this work, we explore the
use of Hierarchical Reinforcement Learning (HRL) to develop adaptive control
strategies for lower-limb exoskeletons, aiming to enhance mobility and autonomy
for individuals with motor impairments. Inspired by prominent models of
biological sensorimotor processing, our investigated HRL approach breaks down
the complex task of exoskeleton control adaptation into a higher-level
framework for terrain strategy adaptation and a lower-level framework for
providing predictive information; this latter element is implemented via the
continual learning of general value functions (GVFs). GVFs generated temporal
abstractions of future signal values from multiple wearable lower-limb sensors,
including electromyography, pressure insoles, and goniometers. We investigated
two methods for incorporating actual and predicted sensor signals into a policy
network with the intent to improve the decision-making capacity of the control
system of a lower-limb exoskeleton during ambulation across varied terrains. As
a key result, we found that the addition of predictions made from GVFs
increased overall network accuracy. Terrain-specific performance increases were
seen while walking on even ground, uneven ground, up and down ramps, and turns,
terrains that are often misclassified without predictive information. This
suggests that predictive information can aid decision-making during
uncertainty, e.g., on terrains that have a high chance of being misclassified.
This work, therefore, contributes new insights into the nuances of HRL and the
future development of exoskeletons to facilitate safe transitioning and
traversing across different walking environments.

</details>


### [113] [PyG 2.0: Scalable Learning on Real World Graphs](https://arxiv.org/abs/2507.16991)
*Matthias Fey,Jinu Sunil,Akihiro Nitta,Rishi Puri,Manan Shah,Blaž Stojanovič,Ramona Bendias,Alexandria Barghi,Vid Kocijan,Zecheng Zhang,Xinwei He,Jan Eric Lenssen,Jure Leskovec*

Main category: cs.LG

TL;DR: PyG 2.0是对PyTorch Geometric框架的重大更新，显著提升了可扩展性和实际应用能力，支持异构图和时序图，并在关系深度学习和大语言模型等重要领域得到广泛应用。


<details>
  <summary>Details</summary>
Motivation: 随着图神经网络应用的不断扩展，原有的PyG框架需要在可扩展性和实际应用能力方面进行重大改进，以支持大规模图学习问题和更多样化的应用场景。

Method: PyG 2.0采用了增强的架构设计，包括支持异构图和时序图、可扩展的特征/图存储、多种优化技术等，同时提供了对关系深度学习和大语言模型等重要应用领域的深度支持。

Result: PyG 2.0成功建立了其作为图神经网络领域领先框架的地位，能够高效处理大规模图学习问题，并在多个应用领域得到广泛支持和使用。

Conclusion: PyG 2.0通过架构增强和功能扩展，为研究人员和从业者提供了一个功能强大、可扩展的图学习框架，能够有效解决实际应用中的复杂图学习挑战。

Abstract: PyG (PyTorch Geometric) has evolved significantly since its initial release,
establishing itself as a leading framework for Graph Neural Networks. In this
paper, we present Pyg 2.0 (and its subsequent minor versions), a comprehensive
update that introduces substantial improvements in scalability and real-world
application capabilities. We detail the framework's enhanced architecture,
including support for heterogeneous and temporal graphs, scalable feature/graph
stores, and various optimizations, enabling researchers and practitioners to
tackle large-scale graph learning problems efficiently. Over the recent years,
PyG has been supporting graph learning in a large variety of application areas,
which we will summarize, while providing a deep dive into the important areas
of relational deep learning and large language modeling.

</details>


### [114] [Should Bias Always be Eliminated? A Principled Framework to Use Data Bias for OOD Generation](https://arxiv.org/abs/2507.17001)
*Yan Li,Guangyi Chen,Yunlong Deng,Zijian Li,Zeyu Tang,Anpeng Wu,Kun Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一个新颖的框架，通过策略性地利用偏差来补充不变表示，而不是简单地消除偏差，从而提高模型在分布外域上的适应性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分布外域适应方法主要依赖不变表示学习来消除偏差特征的影响，但偏差是否总是应该被消除？何时应该保留偏差，以及如何有效利用偏差？这些问题促使作者重新思考偏差在域适应中的作用。

Method: 提出了一个策略性利用偏差的框架，包含两个关键组件：(1) 使用不变性作为指导从偏差中提取预测性成分；(2) 利用识别出的偏差来估计环境条件，并使用它来探索适当的偏差感知预测器以缓解环境差距。该方法在推理过程中将偏差与不变表示相结合。

Result: 在合成数据集和标准域泛化基准测试上的实验结果一致表明，该方法优于现有方法，证明了其鲁棒性和适应性。理论分析探索了偏差特征能够被识别和有效利用的条件。

Conclusion: 偏差不应总是被消除，而应该被策略性地利用。通过合理地结合偏差和不变表示，可以显著提高模型在分布外域上的泛化性能。该框架为域适应提供了新的视角和有效的解决方案。

Abstract: Most existing methods for adapting models to out-of-distribution (OOD)
domains rely on invariant representation learning to eliminate the influence of
biased features. However, should bias always be eliminated -- and if not, when
should it be retained, and how can it be leveraged? To address these questions,
we first present a theoretical analysis that explores the conditions under
which biased features can be identified and effectively utilized. Building on
this theoretical foundation, we introduce a novel framework that strategically
leverages bias to complement invariant representations during inference. The
framework comprises two key components that leverage bias in both direct and
indirect ways: (1) using invariance as guidance to extract predictive
ingredients from bias, and (2) exploiting identified bias to estimate the
environmental condition and then use it to explore appropriate bias-aware
predictors to alleviate environment gaps. We validate our approach through
experiments on both synthetic datasets and standard domain generalization
benchmarks. Results consistently demonstrate that our method outperforms
existing approaches, underscoring its robustness and adaptability.

</details>


### [115] [laplax -- Laplace Approximations with JAX](https://arxiv.org/abs/2507.17013)
*Tobias Weber,Bálint Mucsányi,Lenard Rommel,Thomas Christie,Lars Kasüschke,Marvin Pförtner,Philipp Hennig*

Main category: cs.LG

TL;DR: 本文介绍了laplax，一个基于JAX的开源Python包，用于在深度神经网络中执行拉普拉斯近似以量化权重空间的不确定性，为贝叶斯神经网络研究提供了灵活高效的工具。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络需要可扩展且高效的方法来量化权重空间的不确定性，以便应用贝叶斯工具进行预测不确定性估计和模型选择，但缺乏合适的开源工具包来支持相关研究。

Method: 开发了laplax这一基于JAX的Python包，采用模块化和纯函数式架构设计，具有最小的外部依赖，通过拉普拉斯近似技术来量化深度神经网络中的权重空间不确定性。

Result: 成功构建了一个灵活且对研究者友好的框架，能够支持快速原型开发和实验，为贝叶斯神经网络、深度学习不确定性量化以及改进拉普拉斯近似技术的研究提供了有效工具。

Conclusion: laplax包为深度学习中的贝叶斯方法研究提供了一个高效、可扩展的解决方案，有助于促进贝叶斯神经网络、不确定性量化和拉普拉斯近似技术的进一步发展。

Abstract: The Laplace approximation provides a scalable and efficient means of
quantifying weight-space uncertainty in deep neural networks, enabling the
application of Bayesian tools such as predictive uncertainty and model
selection via Occam's razor. In this work, we introduce laplax, a new
open-source Python package for performing Laplace approximations with jax.
Designed with a modular and purely functional architecture and minimal external
dependencies, laplax offers a flexible and researcher-friendly framework for
rapid prototyping and experimentation. Its goal is to facilitate research on
Bayesian neural networks, uncertainty quantification for deep learning, and the
development of improved Laplace approximation techniques.

</details>


### [116] [Causal Graph Fuzzy LLMs: A First Introduction and Applications in Time Series Forecasting](https://arxiv.org/abs/2507.17016)
*Omid Orang,Patricia O. Lucas,Gabriel I. F. Paiva,Petronio C. L. Silva,Felipe Augusto Rocha da Silva,Adriano Alonso Veloso,Frederico Gadelha Guimaraes*

Main category: cs.LG

TL;DR: 本研究提出了CGF-LLM框架，首次将GPT-2与模糊时间序列和因果图结合用于多变量时间序列预测，通过模糊化和因果分析将数值序列转换为可解释的文本表示，在四个数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型在时间序列预测中的应用引起了研究者的广泛关注，但现有方法缺乏将数值时间序列转换为可解释形式的有效途径，难以实现语义理解和结构洞察的结合。

Method: 提出CGF-LLM框架，结合GPT-2、模糊时间序列(FTS)和因果图技术。通过并行应用模糊化和因果分析，将数值时间序列转换为可解释的文本表示，使预训练的GPT-2模型能够同时获得语义理解和结构洞察能力。

Result: 在四个不同的多变量时间序列数据集上验证了所提出模型的有效性，文本表示形式能够更好地反映原始时间序列背后的复杂动态特性。

Conclusion: CGF-LLM成功实现了大语言模型在时间序列预测中的创新应用，为基于模糊时间序列的LLM时间序列预测领域开辟了有前景的未来发展方向。

Abstract: In recent years, the application of Large Language Models (LLMs) to time
series forecasting (TSF) has garnered significant attention among researchers.
This study presents a new frame of LLMs named CGF-LLM using GPT-2 combined with
fuzzy time series (FTS) and causal graph to predict multivariate time series,
marking the first such architecture in the literature. The key objective is to
convert numerical time series into interpretable forms through the parallel
application of fuzzification and causal analysis, enabling both semantic
understanding and structural insight as input for the pretrained GPT-2 model.
The resulting textual representation offers a more interpretable view of the
complex dynamics underlying the original time series. The reported results
confirm the effectiveness of our proposed LLM-based time series forecasting
model, as demonstrated across four different multivariate time series datasets.
This initiative paves promising future directions in the domain of TSF using
LLMs based on FTS.

</details>


### [117] [BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part II: Efficient Uncertainty Quantification with Low-Rank Adaptation](https://arxiv.org/abs/2507.17019)
*Ray Zirui Zhang,Christopher E. Miles,Xiaohui Xie,John S. Lowengrub*

Main category: cs.LG

TL;DR: 本文提出了一种基于双层局部算子学习(BiLO)的贝叶斯推断框架，用于求解PDE约束的不确定性量化和逆问题，通过梯度MCMC和低秩适应实现高效采样，避免了传统贝叶斯神经网络在高维权重空间采样的挑战


<details>
  <summary>Details</summary>
Motivation: 传统的基于贝叶斯神经网络的方法在处理PDE约束的不确定性量化问题时，需要在高维神经网络权重空间进行采样，这带来了巨大的计算挑战，且需要为神经网络解指定先验分布。现有方法难以在保证计算效率的同时实现准确的参数推断和不确定性量化

Method: 提出双层局部算子学习(BiLO)的贝叶斯推断扩展：下层通过最小化局部算子损失训练网络逼近局部解算子；上层从后验分布中采样PDE参数。采用基于梯度的马尔可夫链蒙特卡罗(MCMC)方法和低秩适应(LoRA)技术实现高效采样，强制执行强PDE约束来提升精度

Result: 通过多种PDE模型的数值实验验证，该方法在保持高计算效率的同时，能够准确进行推断和不确定性量化。分析了MCMC采样器中梯度的动态误差和下层问题不精确最小化导致的后验分布静态误差，证明了下层问题求解容差与不确定性量化精度之间的直接联系

Conclusion: 所提出的方法成功绕过了在高维神经网络权重空间采样的挑战，无需为神经网络解指定先验分布，不确定性能够通过PDE约束从数据中自然传播。通过强制执行强PDE约束，该方法在参数推断和不确定性量化方面都提升了精度，为PDE约束的贝叶斯推断问题提供了一个高效且准确的解决方案

Abstract: Uncertainty quantification and inverse problems governed by partial
differential equations (PDEs) are central to a wide range of scientific and
engineering applications. In this second part of a two part series, we extend
Bilevel Local Operator Learning (BiLO) for PDE-constrained optimization
problems developed in Part 1 to the Bayesian inference framework. At the lower
level, we train a network to approximate the local solution operator by
minimizing the local operator loss with respect to the weights of the neural
network. At the upper level, we sample the PDE parameters from the posterior
distribution. We achieve efficient sampling through gradient-based Markov Chain
Monte Carlo (MCMC) methods and low-rank adaptation (LoRA). Compared with
existing methods based on Bayesian neural networks, our approach bypasses the
challenge of sampling in the high-dimensional space of neural network weights
and does not require specifying a prior distribution on the neural network
solution. Instead, uncertainty propagates naturally from the data through the
PDE constraints. By enforcing strong PDE constraints, the proposed method
improves the accuracy of both parameter inference and uncertainty
quantification. We analyze the dynamic error of the gradient in the MCMC
sampler and the static error in the posterior distribution due to inexact
minimization of the lower level problem and demonstrate a direct link between
the tolerance for solving the lower level problem and the accuracy of the
resulting uncertainty quantification. Through numerical experiments across a
variety of PDE models, we demonstrate that our method delivers accurate
inference and quantification of uncertainties while maintaining high
computational efficiency.

</details>


### [118] [Pragmatic Policy Development via Interpretable Behavior Cloning](https://arxiv.org/abs/2507.17056)
*Anton Matsson,Yaochen Rao,Heather J. Litman,Fredrik D. Johansson*

Main category: cs.LG

TL;DR: 提出了一种基于决策树的可解释离线强化学习方法，通过分析数据中最常选择的治疗行为来制定医疗决策策略，在类风湿性关节炎和脓毒症治疗中展现出优于现有实践的效果。


<details>
  <summary>Details</summary>
Motivation: 传统离线强化学习在安全关键领域（如医疗）面临两大挑战：1）策略的黑箱性质导致可解释性差；2）离策略评估对行为策略的偏离敏感，特别是使用重要性采样方法时评估不可靠。

Method: 提出基于决策树的可解释替代方案：1）使用可解释模型估计行为策略；2）从每个患者状态下最常选择的行动中推导治疗策略；3）通过树状结构自然分组状态和治疗方案；4）通过调整考虑的行动数量来控制与行为策略的重叠度，确保可靠的离策略评估。

Result: 在类风湿性关节炎和脓毒症护理的真实世界案例中，该框架推导的策略能够超越当前实践表现，同时提供比传统离线强化学习更好的可解释性替代方案。

Conclusion: 这种务实的策略开发方法通过标准化频繁的治疗模式，捕获了数据中嵌入的集体临床判断，为医疗决策提供了一个既有效又可解释的离线强化学习解决方案。

Abstract: Offline reinforcement learning (RL) holds great promise for deriving optimal
policies from observational data, but challenges related to interpretability
and evaluation limit its practical use in safety-critical domains.
Interpretability is hindered by the black-box nature of unconstrained RL
policies, while evaluation -- typically performed off-policy -- is sensitive to
large deviations from the data-collecting behavior policy, especially when
using methods based on importance sampling. To address these challenges, we
propose a simple yet practical alternative: deriving treatment policies from
the most frequently chosen actions in each patient state, as estimated by an
interpretable model of the behavior policy. By using a tree-based model, which
is specifically designed to exploit patterns in the data, we obtain a natural
grouping of states with respect to treatment. The tree structure ensures
interpretability by design, while varying the number of actions considered
controls the degree of overlap with the behavior policy, enabling reliable
off-policy evaluation. This pragmatic approach to policy development
standardizes frequent treatment patterns, capturing the collective clinical
judgment embedded in the data. Using real-world examples in rheumatoid
arthritis and sepsis care, we demonstrate that policies derived under this
framework can outperform current practice, offering interpretable alternatives
to those obtained via offline RL.

</details>


### [119] [Risk In Context: Benchmarking Privacy Leakage of Foundation Models in Synthetic Tabular Data Generation](https://arxiv.org/abs/2507.17066)
*Jessup Byun,Xiaofeng Lin,Joshua Ward,Guang Cheng*

Main category: cs.LG

TL;DR: 该研究首次系统评估了基础模型在表格数据合成中的隐私风险，发现GPT-4o-mini、LLaMA 3.3 70B和TabPFN v2等模型存在严重的成员推理攻击漏洞，并提出了三种零成本提示优化策略来改善隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在小数据集上容易过拟合和泄露敏感记录，而基于大型预训练Transformer的上下文学习方法虽然避免了重训练，但会逐字重复种子行，引入新的隐私风险。在表格合成中，单行数据可能识别个人身份，但这种风险的严重程度尚不明确，缺乏系统性研究。

Method: 构建首个针对表格数据合成的隐私风险基准测试，使用3个基础模型（GPT-4o-mini、LLaMA 3.3 70B、TabPFN v2）和4个基线模型，在35个来自健康、金融和政策领域的真实表格上进行评估。评估指标包括统计保真度、下游效用和成员推理泄露。采用因子实验设计研究提示优化策略的效果。

Result: 基础模型始终表现出最高的隐私风险，LLaMA 3.3 70B在1%假阳性率下的真阳性率比最安全基线高出54个百分点。CTGAN和GPT-4o-mini提供更好的隐私-效用权衡。三种零成本提示优化策略（小批量大小、低温度、使用汇总统计）可将最坏情况AUC降低14点，稀有类泄露降低39点，同时保持90%以上的保真度。

Conclusion: 基础模型在表格数据合成中存在显著隐私风险，但通过适当的提示工程策略可以有效缓解这些风险。研究为在低数据环境下使用基础模型进行更安全的表格数据合成提供了实用指导，强调了在追求合成数据效用的同时平衡隐私保护的重要性。

Abstract: Synthetic tabular data is essential for machine learning workflows,
especially for expanding small or imbalanced datasets and enabling
privacy-preserving data sharing. However, state-of-the-art generative models
(GANs, VAEs, diffusion models) rely on large datasets with thousands of
examples. In low-data settings, often the primary motivation for synthetic
data, these models can overfit, leak sensitive records, and require frequent
retraining. Recent work uses large pre-trained transformers to generate rows
via in-context learning (ICL), which needs only a few seed examples and no
parameter updates, avoiding retraining. But ICL repeats seed rows verbatim,
introducing a new privacy risk that has only been studied in text. The severity
of this risk in tabular synthesis-where a single row may identify a
person-remains unclear. We address this gap with the first benchmark of three
foundation models (GPT-4o-mini, LLaMA 3.3 70B, TabPFN v2) against four
baselines on 35 real-world tables from health, finance, and policy. We evaluate
statistical fidelity, downstream utility, and membership inference leakage.
Results show foundation models consistently have the highest privacy risk.
LLaMA 3.3 70B reaches up to 54 percentage points higher true-positive rate at
1% FPR than the safest baseline. GPT-4o-mini and TabPFN are also highly
vulnerable. We plot the privacy-utility frontier and show that CTGAN and
GPT-4o-mini offer better tradeoffs. A factorial study finds that three
zero-cost prompt tweaks-small batch size, low temperature, and using summary
statistics-can reduce worst-case AUC by 14 points and rare-class leakage by up
to 39 points while maintaining over 90% fidelity. Our benchmark offers a
practical guide for safer low-data synthesis with foundation models.

</details>


### [120] [Advancing Robustness in Deep Reinforcement Learning with an Ensemble Defense Approach](https://arxiv.org/abs/2507.17070)
*Adithya Mohan,Dominik Rößle,Daniel Cremers,Torsten Schön*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的集成防御架构，用于提高自动驾驶中深度强化学习模型对抗对抗性攻击的鲁棒性，相比基线方法在FGSM攻击下实现了213%的奖励提升和82%的碰撞率降低。


<details>
  <summary>Details</summary>
Motivation: 虽然深度强化学习在多个领域取得了显著进展，但其在面对对抗性攻击时的鲁棒性仍存在关键问题。现有的防御机制如对抗训练和蒸馏虽能提升模型韧性，但在自动驾驶场景中缺乏多重防御集成的研究，存在重要的研究空白。

Method: 提出了一种新颖的基于集成的防御架构，专门用于缓解自动驾驶中的对抗性攻击。该方法整合多种防御策略，针对自动驾驶场景的特殊需求进行优化设计。

Result: 在FGSM攻击下，相比基线方法，集成防御架构在高速公路和合并场景中将平均奖励从5.87提升至18.38（提升超过213%），同时将平均碰撞率从0.50降低至0.09（降低82%），性能超越所有单独的防御策略。

Conclusion: 所提出的集成防御架构显著增强了深度强化学习模型在自动驾驶场景中的鲁棒性，有效抵御对抗性攻击，为自动驾驶系统的安全性提供了重要保障。

Abstract: Recent advancements in Deep Reinforcement Learning (DRL) have demonstrated
its applicability across various domains, including robotics, healthcare,
energy optimization, and autonomous driving. However, a critical question
remains: How robust are DRL models when exposed to adversarial attacks? While
existing defense mechanisms such as adversarial training and distillation
enhance the resilience of DRL models, there remains a significant research gap
regarding the integration of multiple defenses in autonomous driving scenarios
specifically. This paper addresses this gap by proposing a novel ensemble-based
defense architecture to mitigate adversarial attacks in autonomous driving. Our
evaluation demonstrates that the proposed architecture significantly enhances
the robustness of DRL models. Compared to the baseline under FGSM attacks, our
ensemble method improves the mean reward from 5.87 to 18.38 (over 213%
increase) and reduces the mean collision rate from 0.50 to 0.09 (an 82%
decrease) in the highway scenario and merge scenario, outperforming all
standalone defense strategies.

</details>


### [121] [Sensor Drift Compensation in Electronic-Nose-Based Gas Recognition Using Knowledge Distillation](https://arxiv.org/abs/2507.17071)
*Juntao Lin,Xianghao Zhan*

Main category: cs.LG

TL;DR: 本文针对电子鼻系统中传感器漂移导致的气体分类性能下降问题，提出了基于知识蒸馏(KD)的新型漂移补偿方法，在UCI气体传感器阵列漂移数据集上的实验表明，KD方法在准确率和F1分数上分别比现有最佳方法提升了18%和15%。


<details>
  <summary>Details</summary>
Motivation: 环境变化和传感器老化导致电子鼻系统在实际部署中出现传感器漂移，影响气体分类性能。现有研究缺乏统计学严格性验证，且可能过度补偿传感器漂移而丢失类别相关的方差信息。

Method: 设计了两种领域适应任务来模拟不同的应用场景，系统性测试了三种方法：新提出的知识蒸馏(KD)方法、基准方法域正则化成分分析(DRCA)以及混合方法KD-DRCA。在UCI数据集上进行30次随机测试集划分的统计学验证。

Result: 知识蒸馏方法在所有测试中一致优于DRCA和KD-DRCA方法，在准确率上提升高达18%，在F1分数上提升高达15%，显著超越了之前的最先进方法DRCA。

Conclusion: 这是首次将知识蒸馏应用于电子鼻漂移缓解的研究，证明了KD方法在传感器漂移补偿方面的卓越有效性，提高了传感器漂移补偿在真实环境中的可靠性。

Abstract: Due to environmental changes and sensor aging, sensor drift challenges the
performance of electronic nose systems in gas classification during real-world
deployment. Previous studies using the UCI Gas Sensor Array Drift Dataset
reported promising drift compensation results but lacked robust statistical
experimental validation and may overcompensate for sensor drift, losing
class-related variance.To address these limitations and improve sensor drift
compensation with statistical rigor, we first designed two domain adaptation
tasks based on the same electronic nose dataset: using the first batch to
predict the remaining batches, simulating a controlled laboratory setting; and
predicting the next batch using all prior batches, simulating continuous
training data updates for online training. We then systematically tested three
methods: our proposed novel Knowledge Distillation (KD) method, the benchmark
method Domain Regularized Component Analysis (DRCA), and a hybrid method
KD-DRCA, across 30 random test set partitions on the UCI dataset. We showed
that KD consistently outperformed both DRCA and KD-DRCA, achieving up to an 18%
improvement in accuracy and 15% in F1-score, demonstrating KD's superior
effectiveness in drift compensation. This is the first application of KD for
electronic nose drift mitigation, significantly outperforming the previous
state-of-the-art DRCA method and enhancing the reliability of sensor drift
compensation in real-world environments.

</details>


### [122] [ZORMS-LfD: Learning from Demonstrations with Zeroth-Order Random Matrix Search](https://arxiv.org/abs/2507.17096)
*Olivia Dry,Timothy L. Molloy,Wanxin Jin,Iman Shames*

Main category: cs.LG

TL;DR: 本文提出了ZORMS-LfD方法，这是一种零阶随机矩阵搜索算法，用于从专家演示中学习约束最优控制问题的成本、约束和动态，无需梯度计算，在连续和离散时间问题上都表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的一阶方法需要计算成本、约束、动态和学习损失相对于状态、控制和参数的梯度，且需要学习损失景观的平滑性。大多数现有方法仅适用于离散时间，对连续时间约束问题关注不足。

Method: 提出了零阶随机矩阵搜索从演示学习方法(ZORMS-LfD)，该方法能够在不需要梯度计算和平滑性假设的情况下，从专家演示中学习连续和离散时间约束最优控制问题的成本、约束和动态。

Result: 在多个基准问题上，ZORMS-LfD在学习损失和计算时间方面匹配或超越了现有最先进方法的性能。在无约束连续时间基准问题上，ZORMS-LfD达到了与最先进一阶方法相似的损失性能，但计算时间减少了80%以上。在约束连续时间基准问题上，ZORMS-LfD优于常用的无梯度Nelder-Mead优化方法。

Conclusion: ZORMS-LfD为从演示学习约束最优控制问题提供了一种有效的零阶方法，特别适用于连续时间问题，在保持或提升学习性能的同时显著降低了计算复杂度。

Abstract: We propose Zeroth-Order Random Matrix Search for Learning from Demonstrations
(ZORMS-LfD). ZORMS-LfD enables the costs, constraints, and dynamics of
constrained optimal control problems, in both continuous and discrete time, to
be learned from expert demonstrations without requiring smoothness of the
learning-loss landscape. In contrast, existing state-of-the-art first-order
methods require the existence and computation of gradients of the costs,
constraints, dynamics, and learning loss with respect to states, controls
and/or parameters. Most existing methods are also tailored to discrete time,
with constrained problems in continuous time receiving only cursory attention.
We demonstrate that ZORMS-LfD matches or surpasses the performance of
state-of-the-art methods in terms of both learning loss and compute time across
a variety of benchmark problems. On unconstrained continuous-time benchmark
problems, ZORMS-LfD achieves similar loss performance to state-of-the-art
first-order methods with an over $80$\% reduction in compute time. On
constrained continuous-time benchmark problems where there is no specialized
state-of-the-art method, ZORMS-LfD is shown to outperform the commonly used
gradient-free Nelder-Mead optimization method.

</details>


### [123] [Reinforcement Learning Fine-Tunes a Sparse Subnetwork in Large Language Models](https://arxiv.org/abs/2507.17107)
*Andrii Balashov*

Main category: cs.LG

TL;DR: 研究发现强化学习微调大语言模型时，只有5-30%的参数会被修改，其余参数保持不变，这种稀疏性现象在多种RL算法和模型家族中普遍存在。


<details>
  <summary>Details</summary>
Motivation: 挑战传统假设，即强化学习微调需要更新模型的大部分参数。研究者想要探究RL微调过程中参数更新的真实模式，以及这种模式是否具有普遍性和可转移性。

Method: 通过分析多种RL算法（PPO、DPO、SimPO、PRIME）在不同模型家族（OpenAI、Meta、开源LLM）上的参数更新模式，观察和量化RL引起的参数更新稀疏性。研究不同随机种子、数据集和算法间子网络的重叠程度，并测试仅微调稀疏子网络的性能。

Result: 发现RL微调只修改5-30%的权重参数，且更新的子网络在不同条件下具有显著重叠性，远超随机概率。仅微调这个稀疏子网络就能恢复完整模型性能，获得与全量微调几乎相同的参数。KL惩罚、梯度裁剪和在策略动态对稀疏模式影响有限。

Conclusion: RL适应模型的方式不是通过改变所有权重，而是专注于训练一个小而一致的子网络。这种稀疏性的出现是因为RL在模型原始分布附近操作，只需要有针对性的改变。这一发现为更高效的RL方法提供了可能，并从彩票假说的角度重新理解了稀疏性。

Abstract: Reinforcement learning (RL) is a key post-pretraining step for aligning large
language models (LLMs) with complex tasks and human preferences. While it is
often assumed that RL fine-tuning requires updating most of a model's
parameters, we challenge this assumption with a surprising finding: RL
fine-tuning consistently modifies only a small subnetwork (typically 5-30% of
weights), leaving most parameters unchanged. We call this phenomenon RL-induced
parameter update sparsity. It arises naturally, without any sparsity
constraints or parameter-efficient tuning, and appears across multiple RL
algorithms (e.g., PPO, DPO, SimPO, PRIME) and model families (e.g., OpenAI,
Meta, and open-source LLMs). Moreover, the subnetworks updated by RL show
substantial overlap across different seeds, datasets, and algorithms-far
exceeding chance-suggesting a partially transferable structure in the
pretrained model. We show that fine-tuning only this sparse subnetwork recovers
full model performance and yields parameters nearly identical to the fully
fine-tuned model. Our analysis suggests this sparsity emerges because RL
operates near the model's original distribution, requiring only targeted
changes. KL penalties, gradient clipping, and on-policy dynamics have limited
effect on the sparsity pattern. These findings shed new light on how RL adapts
models: not by shifting all weights, but by focusing training on a small,
consistently updated subnetwork. This insight enables more efficient RL methods
and reframes sparsity through the lens of the lottery ticket hypothesis.

</details>


### [124] [Probabilistic Graphical Models: A Concise Tutorial](https://arxiv.org/abs/2507.17116)
*Jacqueline Maasch,Willie Neiswanger,Stefano Ermon,Volodymyr Kuleshov*

Main category: cs.LG

TL;DR: 这是一篇关于概率图模型的教程论文，介绍了该框架的形式化方法、学习算法和推理算法，为不确定性环境下的建模和决策提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 概率图模型作为机器学习的重要分支，能够使用概率分布来描述世界、进行预测和支持不确定性环境下的决策制定。需要一个简洁的教程来介绍这一建模框架的形式化方法、方法和应用。

Method: 本教程首先回顾基础概率论和图论知识，然后围绕三个主要主题展开：(1) 使用直观的图形语言表示多变量分布；(2) 从数据中学习模型参数和图结构的算法；(3) 精确和近似推理算法。

Result: 该教程提供了概率图建模框架的完整介绍，涵盖了表示、学习和推理三个核心方面，为读者提供了理解和应用概率图模型的系统性知识。

Conclusion: 概率图模型框架结合了概率论和图论两个数学传统，提供了联合概率分布的紧凑而富有表现力的表示方法，为概率推理提供了强大的生成模型。这一框架在不确定性建模和决策支持方面具有重要价值。

Abstract: Probabilistic graphical modeling is a branch of machine learning that uses
probability distributions to describe the world, make predictions, and support
decision-making under uncertainty. Underlying this modeling framework is an
elegant body of theory that bridges two mathematical traditions: probability
and graph theory. This framework provides compact yet expressive
representations of joint probability distributions, yielding powerful
generative models for probabilistic reasoning.
  This tutorial provides a concise introduction to the formalisms, methods, and
applications of this modeling framework. After a review of basic probability
and graph theory, we explore three dominant themes: (1) the representation of
multivariate distributions in the intuitive visual language of graphs, (2)
algorithms for learning model parameters and graphical structures from data,
and (3) algorithms for inference, both exact and approximate.

</details>


### [125] [Computer Vision for Real-Time Monkeypox Diagnosis on Embedded Systems](https://arxiv.org/abs/2507.17123)
*Jacob M. Delgado-López,Ricardo A. Morell-Rodriguez,Sebastián O. Espinosa-Del Rosario,Wilfredo E. Lugo-Beauchamp*

Main category: cs.LG

TL;DR: 本研究开发了一个基于AI的猴痘诊断工具，在NVIDIA Jetson Orin Nano上部署，使用MobileNetV2架构实现93.07%的F1分数，通过TensorRT优化降低了模型大小和功耗，适用于资源受限环境的实时诊断。


<details>
  <summary>Details</summary>
Motivation: 传染性疾病如猴痘需要快速诊断以实现有效控制和治疗，特别是在资源受限的环境中。现有诊断方法在偏远地区部署困难，需要开发适合低资源医疗环境的高效、可扩展且节能的诊断解决方案。

Method: 使用预训练的MobileNetV2架构进行二分类，在开源猴痘皮肤病变数据集上训练模型。采用TensorRT框架对FP32进行推理加速，对FP16和INT8格式进行训练后量化优化。系统配备WiFi热点和基于Web的界面，支持移动设备直接上传和分析图像。

Result: 模型达到93.07%的F1分数，在精确率和召回率之间实现良好平衡。TensorRT优化将模型大小、推理速度和功耗降低约一半，同时保持原始准确性。功耗分析确认优化模型在推理过程中显著降低能耗。

Conclusion: 该诊断工具定位为高效、可扩展且节能的解决方案，能够解决服务不足地区的诊断挑战，为低资源医疗环境的广泛应用铺平道路。系统的简单访问性和无缝连接性使其适用于实际应用场景。

Abstract: The rapid diagnosis of infectious diseases, such as monkeypox, is crucial for
effective containment and treatment, particularly in resource-constrained
environments. This study presents an AI-driven diagnostic tool developed for
deployment on the NVIDIA Jetson Orin Nano, leveraging the pre-trained
MobileNetV2 architecture for binary classification. The model was trained on
the open-source Monkeypox Skin Lesion Dataset, achieving a 93.07% F1-Score,
which reflects a well-balanced performance in precision and recall. To optimize
the model, the TensorRT framework was used to accelerate inference for FP32 and
to perform post-training quantization for FP16 and INT8 formats. TensorRT's
mixed-precision capabilities enabled these optimizations, which reduced the
model size, increased inference speed, and lowered power consumption by
approximately a factor of two, all while maintaining the original accuracy.
Power consumption analysis confirmed that the optimized models used
significantly less energy during inference, reinforcing their suitability for
deployment in resource-constrained environments. The system was deployed with a
Wi-Fi Access Point (AP) hotspot and a web-based interface, enabling users to
upload and analyze images directly through connected devices such as mobile
phones. This setup ensures simple access and seamless connectivity, making the
tool practical for real-world applications. These advancements position the
diagnostic tool as an efficient, scalable, and energy-conscious solution to
address diagnosis challenges in underserved regions, paving the way for broader
adoption in low-resource healthcare settings.

</details>


### [126] [Model Compression Engine for Wearable Devices Skin Cancer Diagnosis](https://arxiv.org/abs/2507.17125)
*Jacob M. Delgado-López,Andrea P. Seda-Hernandez,Juan D. Guadalupe-Rosado,Luis E. Fernandez Ramirez,Miguel Giboyeaux-Camilo,Wilfredo E. Lugo-Beauchamp*

Main category: cs.LG

TL;DR: 本研究开发了一个基于MobileNetV2和TensorRT优化的皮肤癌AI诊断工具，专门针对资源受限的嵌入式设备设计，在NVIDIA Jetson Orin Nano上实现了高性能和低功耗的皮肤病变分类。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是最常见且可预防的癌症之一，但在医疗资源有限的地区，缺乏专业医疗服务使得早期检测面临挑战。研究旨在开发适用于嵌入式系统的AI诊断工具来解决这一问题。

Method: 采用迁移学习方法，基于MobileNetV2架构进行皮肤病变的二分类（"皮肤癌"和"其他"）。使用TensorRT框架对模型进行压缩和优化，以便在NVIDIA Jetson Orin Nano上部署，在性能和能效之间取得平衡。

Result: 优化后的模型保持了良好的性能，F1分数达到87.18%，精确率为93.18%，召回率为81.91%。压缩后模型大小减少至原来的0.41倍，推理速度和吞吐量得到提升，INT8精度下能耗降低至原来的0.93倍。

Conclusion: 研究验证了在资源受限的边缘设备上部署高性能、高能效诊断工具的可行性。该方法不仅适用于皮肤癌检测，还可扩展到其他医疗诊断和需要高效AI解决方案的领域，有潜力革命化医疗诊断，缩小先进技术与医疗资源不足地区之间的差距。

Abstract: Skin cancer is one of the most prevalent and preventable types of cancer, yet
its early detection remains a challenge, particularly in resource-limited
settings where access to specialized healthcare is scarce. This study proposes
an AI-driven diagnostic tool optimized for embedded systems to address this
gap. Using transfer learning with the MobileNetV2 architecture, the model was
adapted for binary classification of skin lesions into "Skin Cancer" and
"Other." The TensorRT framework was employed to compress and optimize the model
for deployment on the NVIDIA Jetson Orin Nano, balancing performance with
energy efficiency. Comprehensive evaluations were conducted across multiple
benchmarks, including model size, inference speed, throughput, and power
consumption. The optimized models maintained their performance, achieving an
F1-Score of 87.18% with a precision of 93.18% and recall of 81.91%.
Post-compression results showed reductions in model size of up to 0.41, along
with improvements in inference speed and throughput, and a decrease in energy
consumption of up to 0.93 in INT8 precision. These findings validate the
feasibility of deploying high-performing, energy-efficient diagnostic tools on
resource-constrained edge devices. Beyond skin cancer detection, the
methodologies applied in this research have broader applications in other
medical diagnostics and domains requiring accessible, efficient AI solutions.
This study underscores the potential of optimized AI systems to revolutionize
healthcare diagnostics, thereby bridging the divide between advanced technology
and underserved regions.

</details>


### [127] [Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance](https://arxiv.org/abs/2507.17131)
*Yufei He,Ruoyu Li,Alex Chen,Yue Liu,Yulin Chen,Yuan Sui,Cheng Chen,Yi Zhu,Luca Luo,Frank Yang,Bryan Hooi*

Main category: cs.LG

TL;DR: 本文提出了ARIA框架，一个能够在测试时持续学习更新领域知识的LLM智能体，通过结构化自我对话评估不确定性，主动识别知识缺口并向人类专家请求指导，在TikTok Pay等动态环境中显著提升了适应性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM智能体在规则和领域知识频繁变化的环境中表现不佳，如监管合规和用户风险筛查。传统的离线微调和标准提示方法无法在实际操作中有效适应新知识，因此需要一个能够在测试时持续学习的智能体框架。

Method: 提出自适应反思交互智能体(ARIA)框架，包括：1) 通过结构化自我对话评估不确定性；2) 主动识别知识缺口并向人类专家请求有针对性的解释或纠正；3) 系统性地更新带时间戳的内部知识库；4) 通过比较和澄清查询检测并解决冲突或过时的知识。

Result: 在TikTok Pay的客户尽职调查姓名筛查任务和公开动态知识任务上进行评估，相比使用标准离线微调和现有自我改进智能体的基线方法，ARIA在适应性和准确性方面都有显著提升。ARIA已部署在为超过1.5亿月活用户服务的TikTok Pay中。

Conclusion: ARIA框架成功解决了LLM智能体在动态环境中的知识适应问题，通过主动学习和知识更新机制，在实际部署中证明了其实用性和有效性，为快速变化环境中的智能体应用提供了新的解决方案。

Abstract: Large language model (LLM) agents often struggle in environments where rules
and required domain knowledge frequently change, such as regulatory compliance
and user risk screening. Current approaches, like offline fine-tuning and
standard prompting, are insufficient because they cannot effectively adapt to
new knowledge during actual operation. To address this limitation, we propose
the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework
designed specifically to continuously learn updated domain knowledge at test
time. ARIA assesses its own uncertainty through structured self-dialogue,
proactively identifying knowledge gaps and requesting targeted explanations or
corrections from human experts. It then systematically updates an internal,
timestamped knowledge repository with provided human guidance, detecting and
resolving conflicting or outdated knowledge through comparisons and
clarification queries. We evaluate ARIA on the realistic customer due diligence
name screening task on TikTok Pay, alongside publicly available dynamic
knowledge tasks. Results demonstrate significant improvements in adaptability
and accuracy compared to baselines using standard offline fine-tuning and
existing self-improving agents. ARIA is deployed within TikTok Pay serving over
150 million monthly active users, confirming its practicality and effectiveness
for operational use in rapidly evolving environments.

</details>


### [128] [SADA: Stability-guided Adaptive Diffusion Acceleration](https://arxiv.org/abs/2507.17135)
*Ting Jiang,Yixiao Wang,Hancheng Ye,Zishan Shao,Jingwei Sun,Jingyang Zhang,Zekai Chen,Jianyi Zhang,Yiran Chen,Hai Li*

Main category: cs.LG

TL;DR: 提出了SADA（稳定性引导的自适应扩散加速）方法，通过统一的稳定性准则同时优化步骤和token级别的稀疏性决策，实现了扩散模型1.8倍以上的加速，同时保持了高保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型虽然在生成任务中表现出色，但由于迭代采样过程和二次注意力成本导致计算开销高。现有的无训练加速策略虽然能减少采样时间，但相比原始基线保真度较低。作者假设这种保真度差距源于：(a)不同提示对应不同的去噪轨迹，(b)这些方法未考虑底层ODE公式及其数值解。

Method: 提出SADA方法，通过单一稳定性准则统一步骤级和token级的稀疏性决策来加速基于ODE的生成模型。针对问题(a)，SADA根据采样轨迹自适应分配稀疏性；针对问题(b)，SADA引入利用数值ODE求解器精确梯度信息的原理性近似方案。

Result: 在SD-2、SDXL和Flux上使用EDM和DPM++求解器的综合评估显示，相比未修改的基线实现了≥1.8倍的一致加速，同时保持最小的保真度下降（LPIPS≤0.10，FID≤4.5），显著优于先前方法。SADA还能无缝适应其他管道和模态：可在不做任何修改的情况下加速ControlNet，并以~0.01频谱图LPIPS将MusicLDM加速1.8倍。

Conclusion: SADA通过稳定性引导的自适应策略成功解决了扩散模型加速中的保真度问题，在多种模型和任务上都展现出优异的性能，为扩散模型的实际应用提供了有效的加速解决方案。

Abstract: Diffusion models have achieved remarkable success in generative tasks but
suffer from high computational costs due to their iterative sampling process
and quadratic attention costs. Existing training-free acceleration strategies
that reduce per-step computation cost, while effectively reducing sampling
time, demonstrate low faithfulness compared to the original baseline. We
hypothesize that this fidelity gap arises because (a) different prompts
correspond to varying denoising trajectory, and (b) such methods do not
consider the underlying ODE formulation and its numerical solution. In this
paper, we propose Stability-guided Adaptive Diffusion Acceleration (SADA), a
novel paradigm that unifies step-wise and token-wise sparsity decisions via a
single stability criterion to accelerate sampling of ODE-based generative
models (Diffusion and Flow-matching). For (a), SADA adaptively allocates
sparsity based on the sampling trajectory. For (b), SADA introduces principled
approximation schemes that leverage the precise gradient information from the
numerical ODE solver. Comprehensive evaluations on SD-2, SDXL, and Flux using
both EDM and DPM++ solvers reveal consistent $\ge 1.8\times$ speedups with
minimal fidelity degradation (LPIPS $\leq 0.10$ and FID $\leq 4.5$) compared to
unmodified baselines, significantly outperforming prior methods. Moreover, SADA
adapts seamlessly to other pipelines and modalities: It accelerates ControlNet
without any modifications and speeds up MusicLDM by $1.8\times$ with $\sim
0.01$ spectrogram LPIPS.

</details>


### [129] [PICore: Physics-Informed Unsupervised Coreset Selection for Data Efficient Neural Operator Training](https://arxiv.org/abs/2507.17151)
*Anirudh Satheesh,Anant Khandelwal,Mucong Ding,Radu Balan*

Main category: cs.LG

TL;DR: 提出PICore，一个无监督核心集选择框架，通过物理信息损失识别最有价值的训练样本，无需真实PDE解标签，显著提高神经算子训练效率并降低标注成本


<details>
  <summary>Details</summary>
Motivation: 神经算子训练存在两个主要瓶颈：需要大量训练数据学习函数空间映射，且数据需要通过昂贵的数值求解器仿真获得标签，训练成本高昂

Method: 设计PICore无监督核心集选择框架，利用物理信息损失评估未标记输入对算子学习的潜在贡献，选择最具信息量的紧凑子集进行数值求解标注，然后在缩减的标记数据集上训练神经算子

Result: 在四个不同PDE基准测试和多种核心集选择策略上，PICore相比监督核心集选择方法平均训练效率提升78%，准确率基本保持不变，同时显著减少训练时间和标注成本

Conclusion: PICore框架成功解决了神经算子训练中的数据需求和标注成本问题，通过无监督的智能样本选择实现了高效的PDE求解器学习，为科学计算领域提供了实用的解决方案

Abstract: Neural operators offer a powerful paradigm for solving partial differential
equations (PDEs) that cannot be solved analytically by learning mappings
between function spaces. However, there are two main bottlenecks in training
neural operators: they require a significant amount of training data to learn
these mappings, and this data needs to be labeled, which can only be accessed
via expensive simulations with numerical solvers. To alleviate both of these
issues simultaneously, we propose PICore, an unsupervised coreset selection
framework that identifies the most informative training samples without
requiring access to ground-truth PDE solutions. PICore leverages a
physics-informed loss to select unlabeled inputs by their potential
contribution to operator learning. After selecting a compact subset of inputs,
only those samples are simulated using numerical solvers to generate labels,
reducing annotation costs. We then train the neural operator on the reduced
labeled dataset, significantly decreasing training time as well. Across four
diverse PDE benchmarks and multiple coreset selection strategies, PICore
achieves up to 78% average increase in training efficiency relative to
supervised coreset selection methods with minimal changes in accuracy. We
provide code at https://github.com/Asatheesh6561/PICore.

</details>


### [130] [Tabular Diffusion based Actionable Counterfactual Explanations for Network Intrusion Detection](https://arxiv.org/abs/2507.17161)
*Vinura Galwaduge,Jagath Samarabandu*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的反事实解释框架，用于网络入侵检测系统的可解释AI，能够提供可操作的解释并生成全局规则来过滤攻击查询。


<details>
  <summary>Details</summary>
Motivation: 现代网络入侵检测系统使用深度学习模型具有"黑盒"特性，缺乏透明度，难以理解检测决策，影响信任度并阻碍及时采取对策。现有可解释AI方法提供的解释难以转换为可操作的对策。

Method: 提出了一种新颖的基于扩散模型的反事实解释框架，专门用于网络入侵攻击的可操作性解释。该方法能够生成最小化、多样化的反事实解释，并将其总结为全局规则。

Result: 在3个现代网络入侵数据集上评估，与其他公开可用的反事实解释算法相比，该方法能够更高效地提供最小化、多样化的反事实解释，减少了生成解释的时间。生成的全局反事实规则能够有效过滤传入的攻击查询。

Conclusion: 该方法不仅在实例级别提供可操作的解释，还能在全局级别为入侵攻击提供指导，生成的全局反事实规则对于高效的入侵检测和防御机制至关重要。这是首次在网络入侵检测系统背景下对现有反事实解释算法进行比较分析的工作。

Abstract: Modern network intrusion detection systems (NIDS) frequently utilize the
predictive power of complex deep learning models. However, the "black-box"
nature of such deep learning methods adds a layer of opaqueness that hinders
the proper understanding of detection decisions, trust in the decisions and
prevent timely countermeasures against such attacks. Explainable AI (XAI)
methods provide a solution to this problem by providing insights into the
causes of the predictions. The majority of the existing XAI methods provide
explanations which are not convenient to convert into actionable
countermeasures. In this work, we propose a novel diffusion-based
counterfactual explanation framework that can provide actionable explanations
for network intrusion attacks. We evaluated our proposed algorithm against
several other publicly available counterfactual explanation algorithms on 3
modern network intrusion datasets. To the best of our knowledge, this work also
presents the first comparative analysis of existing counterfactual explanation
algorithms within the context of network intrusion detection systems. Our
proposed method provide minimal, diverse counterfactual explanations out of the
tested counterfactual explanation algorithms in a more efficient manner by
reducing the time to generate explanations. We also demonstrate how
counterfactual explanations can provide actionable explanations by summarizing
them to create a set of global rules. These rules are actionable not only at
instance level but also at the global level for intrusion attacks. These global
counterfactual rules show the ability to effectively filter out incoming attack
queries which is crucial for efficient intrusion detection and defense
mechanisms.

</details>


### [131] [Met$^2$Net: A Decoupled Two-Stage Spatio-Temporal Forecasting Model for Complex Meteorological Systems](https://arxiv.org/abs/2507.17189)
*Shaohan Li,Hao Yang,Min Chen,Xiaolin Qin*

Main category: cs.LG

TL;DR: 该论文提出了一种隐式两阶段训练方法Met2Net来改进天气预测，通过为每个变量配置独立的编码器和解码器，以及引入自注意力机制进行多变量融合，在近地面气温和相对湿度预测上分别降低了28.82%和23.39%的MSE。


<details>
  <summary>Details</summary>
Motivation: 由于全球气候变化导致极端天气事件频发，迫切需要准确的天气预测。现有的端到端深度学习方法在多变量集成中存在表示不一致性问题，难以有效捕捉复杂天气系统中变量间的依赖关系。虽然将不同变量视为不同模态并应用两阶段训练可以部分缓解这个问题，但由于两个阶段训练任务的不一致性，结果往往不够理想。

Method: 提出了一种隐式两阶段训练方法，为每个变量配置独立的编码器和解码器。第一阶段：冻结翻译器，让编码器和解码器学习共享的潜在空间；第二阶段：冻结编码器和解码器，让翻译器捕捉变量间的交互进行预测。此外，在潜在空间中引入自注意力机制进行多变量融合，进一步提升性能。

Result: 广泛的实验表明该方法达到了最先进的性能。具体来说，在近地面气温和相对湿度预测方面，MSE分别降低了28.82%和23.39%。源代码已在GitHub上开源。

Conclusion: 该研究成功解决了多变量天气预测中表示不一致性和变量依赖关系捕捉的关键问题，通过隐式两阶段训练和自注意力机制的结合，显著提升了天气预测的准确性，为应对气候变化带来的极端天气事件提供了有效的技术支持。

Abstract: The increasing frequency of extreme weather events due to global climate
change urges accurate weather prediction. Recently, great advances have been
made by the \textbf{end-to-end methods}, thanks to deep learning techniques,
but they face limitations of \textit{representation inconsistency} in
multivariable integration and struggle to effectively capture the dependency
between variables, which is required in complex weather systems. Treating
different variables as distinct modalities and applying a \textbf{two-stage
training approach} from multimodal models can partially alleviate this issue,
but due to the inconformity in training tasks between the two stages, the
results are often suboptimal. To address these challenges, we propose an
implicit two-stage training method, configuring separate encoders and decoders
for each variable. In detailed, in the first stage, the Translator is frozen
while the Encoders and Decoders learn a shared latent space, in the second
stage, the Encoders and Decoders are frozen, and the Translator captures
inter-variable interactions for prediction. Besides, by introducing a
self-attention mechanism for multivariable fusion in the latent space, the
performance achieves further improvements. Empirically, extensive experiments
show the state-of-the-art performance of our method. Specifically, it reduces
the MSE for near-surface air temperature and relative humidity predictions by
28.82\% and 23.39\%, respectively. The source code is available at
https://github.com/ShremG/Met2Net.

</details>


### [132] [Filter-And-Refine: A MLLM Based Cascade System for Industrial-Scale Video Content Moderation](https://arxiv.org/abs/2507.17204)
*Zixuan Wang,Jinghao Shi,Hanzhong Liang,Xiang Shen,Vera Wen,Zhiqian Chen,Yifan Wu,Zhixin Zhang,Hongyu Xiong*

Main category: cs.LG

TL;DR: 本文提出了一种基于多模态大语言模型(MLLM)的视频内容审核系统，通过路由器-排序级联架构实现了高效的工业级部署，在提升审核效果的同时大幅降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统视频分类模型在处理隐式有害内容和上下文歧义等复杂场景时表现不佳，而多模态大语言模型虽然具有优秀的跨模态推理和上下文理解能力，但面临计算成本高和生成模型向判别分类任务适配困难两大挑战，阻碍了其在工业界的应用。

Method: 首先提出了一种高效方法，使用最少的判别训练数据将生成式MLLM转换为多模态分类器；然后设计了路由器-排序级联系统，将MLLM与轻量级路由器模型集成，实现工业规模部署。

Result: 离线实验显示，基于MLLM的方法相比传统分类器F1分数提升66.50%，仅需要2%的微调数据；在线评估表明系统将自动内容审核量提升41%，级联部署将计算成本降低至直接全规模部署的1.5%。

Conclusion: 通过路由器-排序级联架构，成功解决了MLLM在视频内容审核中的部署难题，实现了效果提升与成本控制的平衡，为工业级多模态内容审核提供了可行的解决方案。

Abstract: Effective content moderation is essential for video platforms to safeguard
user experience and uphold community standards. While traditional video
classification models effectively handle well-defined moderation tasks, they
struggle with complicated scenarios such as implicit harmful content and
contextual ambiguity. Multimodal large language models (MLLMs) offer a
promising solution to these limitations with their superior cross-modal
reasoning and contextual understanding. However, two key challenges hinder
their industrial adoption. First, the high computational cost of MLLMs makes
full-scale deployment impractical. Second, adapting generative models for
discriminative classification remains an open research problem. In this paper,
we first introduce an efficient method to transform a generative MLLM into a
multimodal classifier using minimal discriminative training data. To enable
industry-scale deployment, we then propose a router-ranking cascade system that
integrates MLLMs with a lightweight router model. Offline experiments
demonstrate that our MLLM-based approach improves F1 score by 66.50% over
traditional classifiers while requiring only 2% of the fine-tuning data. Online
evaluations show that our system increases automatic content moderation volume
by 41%, while the cascading deployment reduces computational cost to only 1.5%
of direct full-scale deployment.

</details>


### [133] [Dataset Distillation as Data Compression: A Rate-Utility Perspective](https://arxiv.org/abs/2507.17221)
*Youneng Bao,Yiping Liu,Zhuo Chen,Yongsheng Liang,Mu Li,Kede Ma*

Main category: cs.LG

TL;DR: 本文提出了一种联合速率-效用优化的数据集蒸馏方法，通过将合成样本参数化为可优化的潜在编码并用轻量级网络解码，在保持性能的同时实现高达170倍的压缩比。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习追求"规模就是一切"的范式，需要越来越大的数据集和模型，导致计算和存储需求过高。现有的数据集蒸馏方法要么在固定存储预算下最大化性能，要么寻求合适的合成数据表示来去除冗余，但没有联合优化这两个目标。

Method: 提出联合速率-效用优化方法：1）将合成样本参数化为可优化的潜在编码，通过极轻量级网络解码；2）估计量化潜在编码的香农熵作为速率度量；3）使用任何现有蒸馏损失作为效用度量；4）通过拉格朗日乘数在速率和效用之间进行权衡；5）引入每类比特数(bpc)作为精确的存储度量标准。

Result: 在CIFAR-10、CIFAR-100和ImageNet-128数据集上，该方法在保持相当精度的情况下实现了比标准蒸馏高达170倍的压缩比。在不同的bpc预算、蒸馏损失和骨干架构下，该方法始终建立了更好的速率-效用权衡。

Conclusion: 通过联合优化存储效率和模型性能，该方法在数据集蒸馏领域建立了新的技术标准，为处理大规模机器学习中的存储和计算挑战提供了有效解决方案。

Abstract: Driven by the ``scale-is-everything'' paradigm, modern machine learning
increasingly demands ever-larger datasets and models, yielding prohibitive
computational and storage requirements. Dataset distillation mitigates this by
compressing an original dataset into a small set of synthetic samples, while
preserving its full utility. Yet, existing methods either maximize performance
under fixed storage budgets or pursue suitable synthetic data representations
for redundancy removal, without jointly optimizing both objectives. In this
work, we propose a joint rate-utility optimization method for dataset
distillation. We parameterize synthetic samples as optimizable latent codes
decoded by extremely lightweight networks. We estimate the Shannon entropy of
quantized latents as the rate measure and plug any existing distillation loss
as the utility measure, trading them off via a Lagrange multiplier. To enable
fair, cross-method comparisons, we introduce bits per class (bpc), a precise
storage metric that accounts for sample, label, and decoder parameter costs. On
CIFAR-10, CIFAR-100, and ImageNet-128, our method achieves up to $170\times$
greater compression than standard distillation at comparable accuracy. Across
diverse bpc budgets, distillation losses, and backbone architectures, our
approach consistently establishes better rate-utility trade-offs.

</details>


### [134] [P3SL: Personalized Privacy-Preserving Split Learning on Heterogeneous Edge Devices](https://arxiv.org/abs/2507.17228)
*Wei Fan,JinYi Yoon,Xiaochang Li,Huajie Shao,Bo Ji*

Main category: cs.LG

TL;DR: 本文提出了P3SL框架，一个针对异构资源受限边缘设备的个性化隐私保护分割学习方法，通过双层优化技术让客户端自主确定最优分割点，在保护隐私的同时平衡能耗和模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有的分割学习方法在异构环境中面临挑战，忽略了个性化隐私需求和不同环境条件下的本地模型定制化问题。边缘设备在计算资源、通信能力、环境条件和隐私要求方面存在差异，需要一个能够适应这些差异的个性化隐私保护框架。

Method: 提出P3SL（个性化隐私保护分割学习）框架，包含两个核心贡献：1）设计个性化序列分割学习管道，允许每个客户端实现定制化隐私保护和个性化本地模型；2）采用双层优化技术，使客户端能够在不向服务器共享敏感信息的情况下确定最优个性化分割点。

Result: 在由7个设备组成的测试平台上实现和评估P3SL，包括4个Jetson Nano P3450设备、2个树莓派和1台笔记本电脑，使用多样化的模型架构和数据集在不同环境条件下进行测试，证明了该方法在平衡能耗、隐私泄露风险和模型精度方面的有效性。

Conclusion: P3SL框架成功解决了异构边缘设备环境中分割学习的个性化隐私保护问题，通过双层优化技术实现了在不泄露敏感信息的前提下的最优分割点确定，为资源受限的边缘设备提供了有效的隐私保护机器学习解决方案。

Abstract: Split Learning (SL) is an emerging privacy-preserving machine learning
technique that enables resource constrained edge devices to participate in
model training by partitioning a model into client-side and server-side
sub-models. While SL reduces computational overhead on edge devices, it
encounters significant challenges in heterogeneous environments where devices
vary in computing resources, communication capabilities, environmental
conditions, and privacy requirements. Although recent studies have explored
heterogeneous SL frameworks that optimize split points for devices with varying
resource constraints, they often neglect personalized privacy requirements and
local model customization under varying environmental conditions. To address
these limitations, we propose P3SL, a Personalized Privacy-Preserving Split
Learning framework designed for heterogeneous, resource-constrained edge device
systems. The key contributions of this work are twofold. First, we design a
personalized sequential split learning pipeline that allows each client to
achieve customized privacy protection and maintain personalized local models
tailored to their computational resources, environmental conditions, and
privacy needs. Second, we adopt a bi-level optimization technique that empowers
clients to determine their own optimal personalized split points without
sharing private sensitive information (i.e., computational resources,
environmental conditions, privacy requirements) with the server. This approach
balances energy consumption and privacy leakage risks while maintaining high
model accuracy. We implement and evaluate P3SL on a testbed consisting of 7
devices including 4 Jetson Nano P3450 devices, 2 Raspberry Pis, and 1 laptop,
using diverse model architectures and datasets under varying environmental
conditions.

</details>


### [135] [Eco-Friendly AI: Unleashing Data Power for Green Federated Learning](https://arxiv.org/abs/2507.17241)
*Mattia Sabella,Monica Vitali*

Main category: cs.LG

TL;DR: 本文提出了一种以数据为中心的绿色联邦学习方法，通过减少训练数据量和选择环境影响最小的节点来降低AI/ML的碳排放和能耗，并开发了一个交互式推荐系统来优化联邦学习配置。


<details>
  <summary>Details</summary>
Motivation: 随着AI和机器学习的广泛应用，其能耗和碳排放带来的环境影响日益严重。联邦学习虽然能减少数据传输成本并增强隐私保护，但也面临数据源异构性和环境影响等挑战。因此需要创新解决方案来减轻AI的生态足迹。

Method: 提出以数据为中心的绿色联邦学习方法：1）分析联邦数据集特征；2）基于质量指标选择最优数据子集；3）选择环境影响最低的联邦节点；4）开发综合方法论检验数据质量、数据量等因素对FL训练性能和碳排放的影响；5）构建交互式推荐系统优化FL配置。

Result: 将该方法应用于时间序列分类任务，在减少联邦学习任务的环境影响方面展现出promising的结果，证明了通过数据减少来最小化训练过程中环境影响的有效性。

Conclusion: 本研究通过提出数据中心化的绿色联邦学习方法，成功推进了绿色AI的发展，证明了通过优化数据选择和节点配置可以有效减少联邦学习的环境足迹，为可持续的AI发展提供了新的解决方案。

Abstract: The widespread adoption of Artificial Intelligence (AI) and Machine Learning
(ML) comes with a significant environmental impact, particularly in terms of
energy consumption and carbon emissions. This pressing issue highlights the
need for innovative solutions to mitigate AI's ecological footprint. One of the
key factors influencing the energy consumption of ML model training is the size
of the training dataset. ML models are often trained on vast amounts of data
continuously generated by sensors and devices distributed across multiple
locations. To reduce data transmission costs and enhance privacy, Federated
Learning (FL) enables model training without the need to move or share raw
data. While FL offers these advantages, it also introduces challenges due to
the heterogeneity of data sources (related to volume and quality),
computational node capabilities, and environmental impact.
  This paper contributes to the advancement of Green AI by proposing a
data-centric approach to Green Federated Learning. Specifically, we focus on
reducing FL's environmental impact by minimizing the volume of training data.
Our methodology involves the analysis of the characteristics of federated
datasets, the selecting of an optimal subset of data based on quality metrics,
and the choice of the federated nodes with the lowest environmental impact. We
develop a comprehensive methodology that examines the influence of data-centric
factors, such as data quality and volume, on FL training performance and carbon
emissions. Building on these insights, we introduce an interactive
recommendation system that optimizes FL configurations through data reduction,
minimizing environmental impact during training. Applying this methodology to
time series classification has demonstrated promising results in reducing the
environmental impact of FL tasks.

</details>


### [136] [DistrAttention: An Efficient and Flexible Self-Attention Mechanism on Modern GPUs](https://arxiv.org/abs/2507.17245)
*Haolin Jin,Mengbai Xiao,Yuan Yuan,Xiao Zhang,Dongxiao Yu,Guanghui Zhang,Haoliang Wang*

Main category: cs.LG

TL;DR: 本文提出了DistrAttention，一种高效灵活的自注意力机制，通过在嵌入维度上对数据进行分组来保持完整上下文信息，同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: Transformer架构中的自注意力机制存在相对于输入序列长度的二次时间复杂度问题，这限制了Transformer的可扩展性。现有的自注意力优化方法要么丢失完整的上下文信息，要么缺乏灵活性。

Method: 设计了DistrAttention机制，通过在嵌入维度d上对数据进行分组来实现高效且灵活的自注意力计算。采用轻量级的采样和融合方法，利用局部敏感哈希来分组相似数据。进一步设计了块状分组框架来限制局部敏感哈希引入的误差，并通过优化块大小选择来与FlashAttention-2集成。

Result: 实验结果显示，DistrAttention在自注意力计算上比FlashAttention-2快37%。在ViT推理中，DistrAttention在近似自注意力机制中表现最快且最准确。在Llama3-1B模型上，DistrAttention实现了最低的推理时间，准确率损失仅为1%。

Conclusion: DistrAttention成功解决了自注意力机制的效率问题，在保持完整上下文信息的同时显著提升了计算速度，为Transformer架构的可扩展性提供了有效解决方案。该方法在多个任务和模型上都展现了优异的性能表现。

Abstract: The Transformer architecture has revolutionized deep learning, delivering the
state-of-the-art performance in areas such as natural language processing,
computer vision, and time series prediction. However, its core component,
self-attention, has the quadratic time complexity relative to input sequence
length, which hinders the scalability of Transformers. The exsiting approaches
on optimizing self-attention either discard full-contextual information or lack
of flexibility. In this work, we design DistrAttention, an effcient and
flexible self-attention mechanism with the full context. DistrAttention
achieves this by grouping data on the embedding dimensionality, usually
referred to as $d$. We realize DistrAttention with a lightweight sampling and
fusion method that exploits locality-sensitive hashing to group similar data. A
block-wise grouping framework is further designed to limit the errors
introduced by locality sensitive hashing. By optimizing the selection of block
sizes, DistrAttention could be easily integrated with FlashAttention-2, gaining
high-performance on modern GPUs. We evaluate DistrAttention with extensive
experiments. The results show that our method is 37% faster than
FlashAttention-2 on calculating self-attention. In ViT inference,
DistrAttention is the fastest and the most accurate among approximate
self-attention mechanisms. In Llama3-1B, DistrAttention still achieves the
lowest inference time with only 1% accuray loss.

</details>


### [137] [Rethinking VAE: From Continuous to Discrete Representations Without Probabilistic Assumptions](https://arxiv.org/abs/2507.17255)
*Songxuan Shi*

Main category: cs.LG

TL;DR: 本文探索了自编码器的生成能力，提出了一种新的VAE训练方法来增强数据紧凑性，并揭示了VAE和VQ-VAE之间的内在联系，发现编码空间的紧凑性和分散性对生成建模的关键作用。


<details>
  <summary>Details</summary>
Motivation: 传统自编码器在生成任务中存在编码空间未定义区域的问题，限制了其生成能力。作者希望通过建立VAE和VQ-VAE之间的联系，找到改进生成模型的新方法。

Method: 提出了一种新的VAE训练框架，引入聚类中心来增强数据紧凑性，确保潜在空间的良好定义，无需依赖传统的KL散度或重参数化技术。将该方法扩展到多个可学习向量，观察其向VQ-VAE模型的自然演进。

Result: 在MNIST、CelebA和FashionMNIST数据集上实现了平滑的插值过渡，但仍存在模糊问题。当编码器输出多个向量时，模型退化为离散自编码器（VQ-AE），只能组合图像片段而无法学习语义表示。

Conclusion: 编码空间的紧凑性和分散性在生成建模中起关键作用。该研究揭示了VAE和VQ-VAE之间的内在联系，为理解这些模型的设计和局限性提供了新的视角。

Abstract: This paper explores the generative capabilities of Autoencoders (AEs) and
establishes connections between Variational Autoencoders (VAEs) and Vector
Quantized-Variational Autoencoders (VQ-VAEs) through a reformulated training
framework. We demonstrate that AEs exhibit generative potential via latent
space interpolation and perturbation, albeit limited by undefined regions in
the encoding space. To address this, we propose a new VAE-like training method
that introduces clustering centers to enhance data compactness and ensure
well-defined latent spaces without relying on traditional KL divergence or
reparameterization techniques. Experimental results on MNIST, CelebA, and
FashionMNIST datasets show smooth interpolative transitions, though blurriness
persists. Extending this approach to multiple learnable vectors, we observe a
natural progression toward a VQ-VAE-like model in continuous space. However,
when the encoder outputs multiple vectors, the model degenerates into a
discrete Autoencoder (VQ-AE), which combines image fragments without learning
semantic representations. Our findings highlight the critical role of encoding
space compactness and dispersion in generative modeling and provide insights
into the intrinsic connections between VAEs and VQ-VAEs, offering a new
perspective on their design and limitations.

</details>


### [138] [Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance](https://arxiv.org/abs/2507.17273)
*Rishi Parekh,Saisubramaniam Gopalakrishnan,Zishan Ahmad,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 该研究提出了一个结合知识图谱(KG)和大语言模型(LLM)代理的框架，用于分析仓库操作的离散事件仿真(DES)数据，自动识别瓶颈和效率问题，相比基线方法表现更优，能够实现近乎完美的效率问题定位。


<details>
  <summary>Details</summary>
Motivation: 分析大型复杂的仓库操作离散事件仿真输出数据以识别瓶颈和效率问题是一项关键但具有挑战性的任务，通常需要大量人工工作或专门的分析工具，现有方法存在局限性。

Method: 构建了一个集成知识图谱和大语言模型代理的框架：1)将原始DES数据转换为语义丰富的知识图谱，捕获仿真事件和实体之间的关系；2)LLM代理使用迭代推理，生成相互依赖的子问题；3)为每个子问题创建Cypher查询与知识图谱交互，提取信息并进行自我反思来纠正错误；4)通过这种自适应、迭代和自我纠错过程模拟人类分析来识别操作问题。

Result: 在设备故障和流程异常的仓库瓶颈识别测试中，该方法优于基线方法。对于操作性问题，在精确定位效率问题方面达到了近乎完美的通过率。对于复杂的调查性问题，展现了卓越的诊断能力，能够发现微妙的、相互关联的问题。

Conclusion: 该工作成功桥接了仿真建模和人工智能(知识图谱+大语言模型)，为获得可操作的洞察提供了更直观的方法，减少了获得洞察的时间，实现了自动化的仓库效率评估和诊断。

Abstract: Analyzing large, complex output datasets from Discrete Event Simulations
(DES) of warehouse operations to identify bottlenecks and inefficiencies is a
critical yet challenging task, often demanding significant manual effort or
specialized analytical tools. Our framework integrates Knowledge Graphs (KGs)
and Large Language Model (LLM)-based agents to analyze complex Discrete Event
Simulation (DES) output data from warehouse operations. It transforms raw DES
data into a semantically rich KG, capturing relationships between simulation
events and entities. An LLM-based agent uses iterative reasoning, generating
interdependent sub-questions. For each sub-question, it creates Cypher queries
for KG interaction, extracts information, and self-reflects to correct errors.
This adaptive, iterative, and self-correcting process identifies operational
issues mimicking human analysis. Our DES approach for warehouse bottleneck
identification, tested with equipment breakdowns and process irregularities,
outperforms baseline methods. For operational questions, it achieves
near-perfect pass rates in pinpointing inefficiencies. For complex
investigative questions, we demonstrate its superior diagnostic ability to
uncover subtle, interconnected issues. This work bridges simulation modeling
and AI (KG+LLM), offering a more intuitive method for actionable insights,
reducing time-to-insight, and enabling automated warehouse inefficiency
evaluation and diagnosis.

</details>


### [139] [Decentralized Federated Learning of Probabilistic Generative Classifiers](https://arxiv.org/abs/2507.17285)
*Aritz Pérez,Carlos Echegoyen,Guzmán Santafé*

Main category: cs.LG

TL;DR: 本文提出了一种去中心化联邦学习方法，通过节点间共享局部统计信息来协作学习概率生成分类器，无需中央服务器即可实现全局模型收敛。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习主要依赖中央服务器架构，但在去中心化环境中，需要一种能让异构用户直接协作、无需共享私有数据的方法来构建全局模型。

Method: 提出了一个基于通信网络的框架，每个节点拥有本地数据和更新规则，通过与邻居节点共享局部统计信息，聚合邻居信息并迭代学习本地分类器，最终收敛到全局模型。

Result: 大量实验表明，该算法在各种网络拓扑、网络规模、本地数据集大小和极端非独立同分布数据分布下都能一致收敛到全局竞争性模型。

Conclusion: 该方法成功实现了去中心化环境下的联邦学习，能够在不依赖中央服务器的情况下，通过节点间协作有效学习概率生成分类器并达到全局最优性能。

Abstract: Federated learning is a paradigm of increasing relevance in real world
applications, aimed at building a global model across a network of
heterogeneous users without requiring the sharing of private data. We focus on
model learning over decentralized architectures, where users collaborate
directly to update the global model without relying on a central server. In
this context, the current paper proposes a novel approach to collaboratively
learn probabilistic generative classifiers with a parametric form. The
framework is composed by a communication network over a set of local nodes,
each of one having its own local data, and a local updating rule. The proposal
involves sharing local statistics with neighboring nodes, where each node
aggregates the neighbors' information and iteratively learns its own local
classifier, which progressively converges to a global model. Extensive
experiments demonstrate that the algorithm consistently converges to a globally
competitive model across a wide range of network topologies, network sizes,
local dataset sizes, and extreme non-i.i.d. data distributions.

</details>


### [140] [R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning](https://arxiv.org/abs/2507.17307)
*Zhuokun Chen,Zeren Chen,Jiahao He,Mingkui Tan,Jianfei Cai,Bohan Zhuang*

Main category: cs.LG

TL;DR: 本文提出R-Stitch框架，通过在小语言模型和大语言模型之间基于置信度进行智能切换，实现了思维链推理的高效加速，在数学推理任务上达到85%的延迟减少且准确率几乎无损失。


<details>
  <summary>Details</summary>
Motivation: 思维链推理虽然能提升大语言模型的问题解决能力，但因依赖长序列的自回归解码而带来巨大计算开销。现有加速策略要么通过早停或压缩奖励设计减少序列长度，要么通过小模型的推测解码提升速度，但这些方法存在局限性：推测解码在大小模型一致性低时加速有限，且未能充分利用小模型产生简洁中间推理的潜在优势。

Method: 提出R-Stitch，一个基于置信度的token级混合解码框架。该方法默认使用小语言模型生成token，仅当小模型置信度低于阈值时才切换到大语言模型。这种设计避免了全序列回滚，选择性地在不确定步骤调用大模型，同时保持效率和答案质量。R-Stitch具有模型无关性、无需训练、与标准解码管道兼容的特点。

Result: 在数学推理基准测试中，R-Stitch实现了高达85%的推理延迟减少，同时准确率几乎没有下降，证明了其在加速思维链推理方面的实际有效性。

Conclusion: R-Stitch成功解决了思维链推理的计算效率问题，通过智能的大小模型切换策略，在保持推理质量的同时显著提升了推理速度，为大语言模型的实际部署提供了有效的加速解决方案。

Abstract: Chain-of-thought (CoT) reasoning enhances the problem-solving capabilities of
large language models by encouraging step-by-step intermediate reasoning during
inference. While effective, CoT introduces substantial computational overhead
due to its reliance on autoregressive decoding over long token sequences.
Existing acceleration strategies either reduce sequence length through early
stopping or compressive reward designs, or improve decoding speed via
speculative decoding with smaller models. However, speculative decoding suffers
from limited speedup when the agreement between small and large models is low,
and fails to exploit the potential advantages of small models in producing
concise intermediate reasoning. In this paper, we present R-Stitch, a
token-level, confidence-based hybrid decoding framework that accelerates CoT
inference by switching between a small language model (SLM) and a large
language model (LLM) along the reasoning trajectory. R-Stitch uses the SLM to
generate tokens by default and delegates to the LLM only when the SLM's
confidence falls below a threshold. This design avoids full-sequence rollback
and selectively invokes the LLM on uncertain steps, preserving both efficiency
and answer quality. R-Stitch is model-agnostic, training-free, and compatible
with standard decoding pipelines. Experiments on math reasoning benchmarks
demonstrate that R-Stitch achieves up to 85\% reduction in inference latency
with negligible accuracy drop, highlighting its practical effectiveness in
accelerating CoT reasoning.

</details>


### [141] [Confounded Causal Imitation Learning with Instrumental Variables](https://arxiv.org/abs/2507.17309)
*Yan Zeng,Shenglan Nie,Feng Xie,Libo Huang,Peng Wu,Zhi Geng*

Main category: cs.LG

TL;DR: 本文提出了混淆因果模仿学习(C2L)模型，通过工具变量方法解决模仿学习中未测量混淆变量导致的偏差问题，设计了两阶段框架：先识别有效工具变量，再进行策略优化。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习受到未测量混淆变量的影响，这些变量会对状态和动作产生混淆效应，如果忽略这些因素会导致策略估计出现偏差。现有方法无法很好地处理跨多个时间步影响动作的混淆因子。

Method: 提出混淆因果模仿学习(C2L)模型，利用工具变量(IV)的强大能力。设计两阶段模仿学习框架：第一阶段基于定义的伪变量构建测试准则来识别有效的工具变量；第二阶段利用识别出的工具变量提出两种候选策略学习方法（基于仿真器的方法和离线方法）。

Result: 大量实验验证了识别有效工具变量以及学习策略的有效性。所提出的方法能够成功处理跨多个时间步的混淆因子影响，相比传统方法在策略学习上取得了更好的效果。

Conclusion: C2L模型通过工具变量方法有效解决了模仿学习中的混淆变量问题。两阶段框架不仅提供了工具变量有效性的充分必要条件，还实现了无偏的策略学习。该方法为处理复杂时序混淆效应的模仿学习提供了新的解决方案。

Abstract: Imitation learning from demonstrations usually suffers from the confounding
effects of unmeasured variables (i.e., unmeasured confounders) on the states
and actions. If ignoring them, a biased estimation of the policy would be
entailed. To break up this confounding gap, in this paper, we take the best of
the strong power of instrumental variables (IV) and propose a Confounded Causal
Imitation Learning (C2L) model. This model accommodates confounders that
influence actions across multiple timesteps, rather than being restricted to
immediate temporal dependencies. We develop a two-stage imitation learning
framework for valid IV identification and policy optimization. In particular,
in the first stage, we construct a testing criterion based on the defined
pseudo-variable, with which we achieve identifying a valid IV for the C2L
models. Such a criterion entails the sufficient and necessary identifiability
conditions for IV validity. In the second stage, with the identified IV, we
propose two candidate policy learning approaches: one is based on a simulator,
while the other is offline. Extensive experiments verified the effectiveness of
identifying the valid IV as well as learning the policy.

</details>


### [142] [EarthLink: Interpreting Climate Signals with Self-Evolving AI Agents](https://arxiv.org/abs/2507.17311)
*Zijie Guo,Jiong Wang,Xiaoyu Yue,Wangxu Wei,Zhe Jiang,Wanghan Xu,Ben Fei,Wenlong Zhang,Xinyu Gu,Lijing Cheng,Jing-Jia Luo,Chao Li,Yaqiang Wang,Tao Chen,Wanli Ouyang,Fenghua Ling,Lei Bai*

Main category: cs.LG

TL;DR: 研究团队开发了EarthLink，这是首个专为地球科学家设计的AI智能体，能够自动化完成从规划到分析的端到端研究工作流程，并通过动态反馈循环持续学习改进，在气候变化相关科学任务中表现出与初级研究员相当的分析能力。


<details>
  <summary>Details</summary>
Motivation: 现代地球科学面临重大瓶颈：地球系统数据庞大、分散且复杂，加上日益复杂的分析需求，严重阻碍了快速科学发现的进程。传统的静态诊断工具无法满足现代地球科学研究的需要。

Method: 开发EarthLink AI智能体，作为地球科学家的交互式副驾驶。该系统能够自动化端到端研究工作流程，包括规划、代码生成和多场景分析。关键特性包括：1）从用户交互中学习；2）通过动态反馈循环持续改进能力；3）提供透明、可审计的工作流程；4）采用自然语言界面。

Result: 在多项气候变化核心科学任务中验证了EarthLink的性能，涵盖模型-观测比较到复杂现象诊断。多专家评估显示，EarthLink能够产生科学合理的分析结果，其分析能力在特定方面与人类初级研究员的工作流程相当。系统使科学家能够从繁重的手动执行转向战略监督和假设生成。

Conclusion: EarthLink标志着地球系统研究向高效、可信和协作范式迈出的关键一步，特别适应了全球变化加速的时代需求。该系统为地球科学研究提供了新的工具和方法论，有望显著提升研究效率和科学发现速度。

Abstract: Modern Earth science is at an inflection point. The vast, fragmented, and
complex nature of Earth system data, coupled with increasingly sophisticated
analytical demands, creates a significant bottleneck for rapid scientific
discovery. Here we introduce EarthLink, the first AI agent designed as an
interactive copilot for Earth scientists. It automates the end-to-end research
workflow, from planning and code generation to multi-scenario analysis. Unlike
static diagnostic tools, EarthLink can learn from user interaction,
continuously refining its capabilities through a dynamic feedback loop. We
validated its performance on a number of core scientific tasks of climate
change, ranging from model-observation comparisons to the diagnosis of complex
phenomena. In a multi-expert evaluation, EarthLink produced scientifically
sound analyses and demonstrated an analytical competency that was rated as
comparable to specific aspects of a human junior researcher's workflow.
Additionally, its transparent, auditable workflows and natural language
interface empower scientists to shift from laborious manual execution to
strategic oversight and hypothesis generation. EarthLink marks a pivotal step
towards an efficient, trustworthy, and collaborative paradigm for Earth system
research in an era of accelerating global change.

</details>


### [143] [A Learning-based Domain Decomposition Method](https://arxiv.org/abs/2507.17328)
*Rui Wu,Nikola Kovachki,Burigede Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于学习的域分解方法(L-DDM)，通过将预训练的神经算子作为代理模型集成到域分解方案中，有效解决复杂几何形状下大规模偏微分方程的计算问题。该方法在保持分辨率不变性的同时，能够很好地泛化到训练时未见的微结构模式。


<details>
  <summary>Details</summary>
Motivation: 传统的有限元方法在处理大规模复杂几何问题时存在计算成本高和可扩展性差的问题，而现有的神经网络方法主要局限于简单域，难以应用于涉及复杂几何的实际偏微分方程问题。因此需要开发能够高效处理复杂大规模结构分析的新方法。

Method: 提出基于学习的域分解方法(L-DDM)，使用单个在简单域上预训练的神经算子作为域分解方案中的代理模型。该方法结合了物理预训练神经算子(PPNO)，并提供了在抽象偏微分方程域分解求解中神经算子近似存在性的一般理论结果。

Result: 该方法成功地近似求解了复杂几何中具有不连续微结构的椭圆型偏微分方程，在这些具有挑战性的问题上超越了当前最先进的方法。同时展现了分辨率不变性和对训练时未见微结构模式的强泛化能力。

Conclusion: L-DDM方法通过将预训练神经算子集成到域分解框架中，成功解决了神经网络方法在复杂几何问题上的局限性，为大规模复杂结构的高效建模和分析提供了新的解决方案，具有良好的计算效率和泛化性能。

Abstract: Recent developments in mechanical, aerospace, and structural engineering have
driven a growing need for efficient ways to model and analyse structures at
much larger and more complex scales than before. While established numerical
methods like the Finite Element Method remain reliable, they often struggle
with computational cost and scalability when dealing with large and
geometrically intricate problems. In recent years, neural network-based methods
have shown promise because of their ability to efficiently approximate
nonlinear mappings. However, most existing neural approaches are still largely
limited to simple domains, which makes it difficult to apply to real-world PDEs
involving complex geometries. In this paper, we propose a learning-based domain
decomposition method (L-DDM) that addresses this gap. Our approach uses a
single, pre-trained neural operator-originally trained on simple domains-as a
surrogate model within a domain decomposition scheme, allowing us to tackle
large and complicated domains efficiently. We provide a general theoretical
result on the existence of neural operator approximations in the context of
domain decomposition solution of abstract PDEs. We then demonstrate our method
by accurately approximating solutions to elliptic PDEs with discontinuous
microstructures in complex geometries, using a physics-pretrained neural
operator (PPNO). Our results show that this approach not only outperforms
current state-of-the-art methods on these challenging problems, but also offers
resolution-invariance and strong generalization to microstructural patterns
unseen during training.

</details>


### [144] [DeCo-SGD: Joint Optimization of Delay Staleness and Gradient Compression Ratio for Distributed SGD](https://arxiv.org/abs/2507.17346)
*Rongwei Lu,Jingyan Jiang,Chunyang Li,Haotian Dong,Xingguang Wei,Delin Cai,Zhi Wang*

Main category: cs.LG

TL;DR: 本文提出了DeCo-SGD算法，通过动态调整梯度压缩比和延迟聚合参数来优化分布式机器学习在高延迟、低带宽网络环境下的性能，相比传统方法实现了显著的加速效果。


<details>
  <summary>Details</summary>
Motivation: 分布式SGD在高延迟、低带宽网络环境下面临严重的吞吐量下降问题。现有方法通常采用梯度压缩和延迟聚合策略，但这些策略的组合引入了压缩比、延迟步数和模型收敛率之间复杂的三方权衡问题，且缺乏理论指导，无法根据网络条件动态调整参数。

Method: 提出了新的理论工具，将联合优化问题分解为传统收敛率分析和多个可分析的噪声项。首次揭示了延迟会指数级放大梯度压缩对训练性能的负面影响。基于收敛率分析和网络感知的时间最小化条件，提出DeCo-SGD算法，能够根据实时网络条件和训练任务动态调整压缩比和延迟参数。

Result: 在高延迟、低带宽变化的网络环境中，DeCo-SGD相比传统D-SGD实现了最高5.07倍的加速，相比静态策略实现了1.37倍的加速。实验证明了该方法在不同网络条件下的有效性和适应性。

Conclusion: 本研究填补了压缩延迟梯度对训练影响的理论空白，提出的DeCo-SGD算法通过动态参数调整有效解决了分布式机器学习在challenging网络环境下的性能问题，为分布式优化提供了新的理论基础和实用解决方案。

Abstract: Distributed machine learning in high end-to-end latency and low, varying
bandwidth network environments undergoes severe throughput degradation. Due to
its low communication requirements, distributed SGD (D-SGD) remains the
mainstream optimizer in such challenging networks, but it still suffers from
significant throughput reduction. To mitigate these limitations, existing
approaches typically employ gradient compression and delayed aggregation to
alleviate low bandwidth and high latency, respectively. To address both
challenges simultaneously, these strategies are often combined, introducing a
complex three-way trade-off among compression ratio, staleness (delayed
synchronization steps), and model convergence rate. To achieve the balance
under varying bandwidth conditions, an adaptive policy is required to
dynamically adjust these parameters. Unfortunately, existing works rely on
static heuristic strategies due to the lack of theoretical guidance, which
prevents them from achieving this goal. This study fills in this theoretical
gap by introducing a new theoretical tool, decomposing the joint optimization
problem into a traditional convergence rate analysis with multiple analyzable
noise terms. We are the first to reveal that staleness exponentially amplifies
the negative impact of gradient compression on training performance, filling a
critical gap in understanding how compressed and delayed gradients affect
training. Furthermore, by integrating the convergence rate with a network-aware
time minimization condition, we propose DeCo-SGD, which dynamically adjusts the
compression ratio and staleness based on the real-time network condition and
training task. DeCo-SGD achieves up to 5.07 and 1.37 speed-ups over D-SGD and
static strategy in high-latency and low, varying bandwidth networks,
respectively.

</details>


### [145] [TOC-UCO: a comprehensive repository of tabular ordinal classification datasets](https://arxiv.org/abs/2507.17348)
*Rafael Ayllón-Gavilán,David Guijo-Rubio,Antonio Manuel Gómez-Orellana,David Guijo-Rubio,Francisco Bérchez-Moreno,Víctor Manuel Vargas-Yun,Pedro A. Gutiérrez*

Main category: cs.LG

TL;DR: 科尔多瓦大学提供了一个包含46个表格式有序分类数据集的公开仓库TOC-UCO，用于有序分类方法的基准测试和验证。


<details>
  <summary>Details</summary>
Motivation: 有序分类领域缺乏一个全面的数据集集合来对新方法进行基准测试，这阻碍了该领域的发展。现有的有序分类方法需要在统一的框架下进行公平比较和验证。

Method: 构建了TOC-UCO仓库，包含46个表格式有序数据集，在统一框架下进行预处理，确保合理的样本数量和适当的类别分布。提供30个不同随机训练-测试划分的索引以促进实验的可重现性。

Result: 成功建立了TOC-UCO公开仓库，包含经过预处理的46个有序分类数据集，并提供了数据源、预处理步骤和基准测试指南。

Conclusion: TOC-UCO仓库为有序分类领域提供了标准化的基准测试平台，有助于新方法的公平比较和该领域的进一步发展。通过提供统一的预处理框架和可重现的实验设置，推动了有序分类研究的标准化。

Abstract: An ordinal classification (OC) problem corresponds to a special type of
classification characterised by the presence of a natural order relationship
among the classes. This type of problem can be found in a number of real-world
applications, motivating the design and development of many ordinal
methodologies over the last years. However, it is important to highlight that
the development of the OC field suffers from one main disadvantage: the lack of
a comprehensive set of datasets on which novel approaches to the literature
have to be benchmarked. In order to approach this objective, this manuscript
from the University of C\'ordoba (UCO), which have previous experience on the
OC field, provides the literature with a publicly available repository of
tabular data for a robust validation of novel OC approaches, namely TOC-UCO
(Tabular Ordinal Classification repository of the UCO). Specifically, this
repository includes a set of $46$ tabular ordinal datasets, preprocessed under
a common framework and ensured to have a reasonable number of patterns and an
appropriate class distribution. We also provide the sources and preprocessing
steps of each dataset, along with details on how to benchmark a novel approach
using the TOC-UCO repository. For this, indices for $30$ different randomised
train-test partitions are provided to facilitate the reproducibility of the
experiments.

</details>


### [146] [DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning](https://arxiv.org/abs/2507.17365)
*Chuzhan Hao,Wenfeng Feng,Yuewei Zhang,Hao Wang*

Main category: cs.LG

TL;DR: DynaSearcher是一个基于动态知识图谱和多奖励强化学习的搜索代理，通过结构化知识指导和精细化训练目标控制，在多跳问答任务中实现了最先进的准确性，同时使用更小规模的模型和更少的计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的多步代理检索系统在复杂信息搜索任务中表现出色，但仍面临生成事实不一致的中间查询和低效搜索轨迹的挑战，这可能导致推理偏差或冗余计算。

Method: 提出DynaSearcher系统，结合动态知识图谱作为外部结构化知识来指导搜索过程，通过显式建模实体关系确保中间查询的事实一致性；采用多奖励强化学习框架对检索准确性、效率和响应质量等训练目标进行细粒度控制。

Result: 在六个多跳问答数据集上实现了最先进的答案准确性，在仅使用小规模模型和有限计算资源的情况下达到了前沿大语言模型的性能水平，并在不同检索环境和更大规模模型上展现出强泛化性和鲁棒性。

Conclusion: DynaSearcher通过动态知识图谱和多奖励强化学习的结合，有效解决了多步检索系统中的事实一致性和效率问题，在保持高准确性的同时显著降低了计算成本，证明了该方法的广泛适用性。

Abstract: Multi-step agentic retrieval systems based on large language models (LLMs)
have demonstrated remarkable performance in complex information search tasks.
However, these systems still face significant challenges in practical
applications, particularly in generating factually inconsistent intermediate
queries and inefficient search trajectories, which can lead to reasoning
deviations or redundant computations. To address these issues, we propose
DynaSearcher, an innovative search agent enhanced by dynamic knowledge graphs
and multi-reward reinforcement learning (RL). Specifically, our system
leverages knowledge graphs as external structured knowledge to guide the search
process by explicitly modeling entity relationships, thereby ensuring factual
consistency in intermediate queries and mitigating biases from irrelevant
information. Furthermore, we employ a multi-reward RL framework for
fine-grained control over training objectives such as retrieval accuracy,
efficiency, and response quality. This framework promotes the generation of
high-quality intermediate queries and comprehensive final answers, while
discouraging unnecessary exploration and minimizing information omissions or
redundancy. Experimental results demonstrate that our approach achieves
state-of-the-art answer accuracy on six multi-hop question answering datasets,
matching frontier LLMs while using only small-scale models and limited
computational resources. Furthermore, our approach demonstrates strong
generalization and robustness across diverse retrieval environments and
larger-scale models, highlighting its broad applicability.

</details>


### [147] [ViRN: Variational Inference and Distribution Trilateration for Long-Tailed Continual Representation Learning](https://arxiv.org/abs/2507.17368)
*Hao Dai,Chong Tang,Jagmohan Chauhan*

Main category: cs.LG

TL;DR: 提出了ViRN框架，结合变分推理和分布三角测量技术，解决连续学习中长尾数据分布的挑战，在六个基准测试中相比现有方法平均准确率提升10.24%


<details>
  <summary>Details</summary>
Motivation: 现实世界AI系统面临连续学习中长尾数据分布的关键挑战，模型需要在保持旧类别知识的同时适应新类别，但存在严重的类别不平衡问题。现有方法难以平衡稳定性和可塑性，在极端样本稀缺情况下经常失效

Method: 提出ViRN框架，集成变分推理和分布三角测量：1）通过变分自编码器建模类别条件分布以减轻对头部类别的偏向；2）通过基于Wasserstein距离的邻域检索和几何融合重构尾部类别分布，实现尾部类别表示的样本高效对齐

Result: 在六个长尾分类基准测试（包括语音任务如罕见声学事件、口音识别和图像任务）上进行评估，ViRN相比最先进方法平均准确率提升10.24%

Conclusion: ViRN框架通过结合变分推理和分布三角测量技术，有效解决了连续学习中长尾数据分布的挑战，在多个基准测试上显著提升了性能，为实际AI系统处理不平衡数据的连续学习提供了有效解决方案

Abstract: Continual learning (CL) with long-tailed data distributions remains a
critical challenge for real-world AI systems, where models must sequentially
adapt to new classes while retaining knowledge of old ones, despite severe
class imbalance. Existing methods struggle to balance stability and plasticity,
often collapsing under extreme sample scarcity. To address this, we propose
ViRN, a novel CL framework that integrates variational inference (VI) with
distributional trilateration for robust long-tailed learning. First, we model
class-conditional distributions via a Variational Autoencoder to mitigate bias
toward head classes. Second, we reconstruct tail-class distributions via
Wasserstein distance-based neighborhood retrieval and geometric fusion,
enabling sample-efficient alignment of tail-class representations. Evaluated on
six long-tailed classification benchmarks, including speech (e.g., rare
acoustic events, accents) and image tasks, ViRN achieves a 10.24% average
accuracy gain over state-of-the-art methods.

</details>


### [148] [Continual Generalized Category Discovery: Learning and Forgetting from a Bayesian Perspective](https://arxiv.org/abs/2507.17382)
*Hao Dai,Jagmohan Chauhan*

Main category: cs.LG

TL;DR: 本文提出了VB-CGCD框架，通过变分推理和协方差感知的最近类均值分类来解决持续广义类别发现中的灾难性遗忘问题，在标准基准测试中实现了15.21%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 持续广义类别发现(C-GCD)面临关键挑战：需要从无标签数据流中增量学习新类别，同时保持对旧类别的知识。现有方法在处理灾难性遗忘方面存在困难，特别是当无标签数据混合了已知和新颖类别时。

Method: 提出了变分贝叶斯C-GCD(VB-CGCD)框架，该框架将变分推理与协方差感知的最近类均值分类相结合。通过贝叶斯视角分析C-GCD的遗忘动态，发现新旧类别间的协方差不对齐是性能下降的主要原因。VB-CGCD通过随机变分更新自适应地对齐类别分布，同时抑制伪标签噪声。

Result: 在标准基准测试中，VB-CGCD在最终会话的整体准确率上超越现有技术15.21%。在新提出的挑战性基准测试中（仅有10%标记数据和扩展的在线阶段），VB-CGCD达到67.86%的最终准确率，显著高于最先进方法的38.55%。

Conclusion: VB-CGCD通过变分推理有效解决了持续广义类别发现中的协方差不对齐问题，在多种场景下展现出强大的适用性和显著的性能提升，为持续学习领域提供了新的解决思路。

Abstract: Continual Generalized Category Discovery (C-GCD) faces a critical challenge:
incrementally learning new classes from unlabeled data streams while preserving
knowledge of old classes. Existing methods struggle with catastrophic
forgetting, especially when unlabeled data mixes known and novel categories. We
address this by analyzing C-GCD's forgetting dynamics through a Bayesian lens,
revealing that covariance misalignment between old and new classes drives
performance degradation. Building on this insight, we propose Variational Bayes
C-GCD (VB-CGCD), a novel framework that integrates variational inference with
covariance-aware nearest-class-mean classification. VB-CGCD adaptively aligns
class distributions while suppressing pseudo-label noise via stochastic
variational updates. Experiments show VB-CGCD surpasses prior art by +15.21%
with the overall accuracy in the final session on standard benchmarks. We also
introduce a new challenging benchmark with only 10% labeled data and extended
online phases, VB-CGCD achieves a 67.86% final accuracy, significantly higher
than state-of-the-art (38.55%), demonstrating its robust applicability across
diverse scenarios. Code is available at: https://github.com/daihao42/VB-CGCD

</details>


### [149] [A Comprehensive Evaluation on Quantization Techniques for Large Language Models](https://arxiv.org/abs/2507.17417)
*Yutong Liu,Cairong Zhao,Guosheng Hu*

Main category: cs.LG

TL;DR: 该论文对大语言模型的训练后量化方法进行了全面的综述和公平比较，将量化方法解耦为预量化变换和量化误差缓解两个步骤，并评估了最新的MXFP4数据格式性能。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法的实验缺乏统一标准，难以进行公平比较；缺乏对不同量化方法理论联系的深入分析；需要对最新的MXFP4数据格式进行系统评估。

Method: 将现有量化方法解耦为两个步骤：1）预量化变换：在量化前应用预处理步骤来减少异常值影响，使数据分布更平坦；2）量化误差缓解：采用技术来抵消量化过程中引入的误差。在统一实验环境下对不同组件进行评估和分析。

Result: 优化的旋转和缩放在预量化变换中表现最佳；低秩补偿与GPTQ的结合在量化误差缓解方面偶尔优于单独使用GPTQ；INT4的最优预量化变换策略无法很好地推广到MXFP4格式。

Conclusion: 通过系统的理论分析和公平的实验比较，为大语言模型量化领域提供了重要见解，特别是揭示了不同量化组件的效果和MXFP4格式的特性，为未来的量化研究提供了指导方向。

Abstract: For large language models (LLMs), post-training quantization (PTQ) can
significantly reduce memory footprint and computational overhead. Model
quantization is a rapidly evolving research field. Though many papers have
reported breakthrough performance, they may not conduct experiments on the same
ground since one quantization method usually contains multiple components. In
addition, analyzing the theoretical connections among existing methods is
crucial for in-depth understanding. To bridge these gaps, we conduct an
extensive review of state-of-the-art methods and perform comprehensive
evaluations on the same ground to ensure fair comparisons. To our knowledge,
this fair and extensive investigation remains critically important yet
underexplored. To better understand the theoretical connections, we decouple
the published quantization methods into two steps: pre-quantization
transformation and quantization error mitigation. We define the former as a
preprocessing step applied before quantization to reduce the impact of
outliers, making the data distribution flatter and more suitable for
quantization. Quantization error mitigation involves techniques that offset the
errors introduced during quantization, thereby enhancing model performance. We
evaluate and analyze the impact of different components of quantization
methods. Additionally, we analyze and evaluate the latest MXFP4 data format and
its performance. Our experimental results demonstrate that optimized rotation
and scaling yield the best performance for pre-quantization transformation, and
combining low-rank compensation with GPTQ occasionally outperforms using GPTQ
alone for quantization error mitigation. Furthermore, we explore the potential
of the latest MXFP4 quantization and reveal that the optimal pre-quantization
transformation strategy for INT4 does not generalize well to MXFP4, inspiring
further investigation.

</details>


### [150] [Generalized Advantage Estimation for Distributional Policy Gradients](https://arxiv.org/abs/2507.17530)
*Shahil Shaik,Jonathon M. Smereka,Yue Wang*

Main category: cs.LG

TL;DR: 本文提出了分布式广义优势估计(DGAE)，通过引入基于最优传输理论的类Wasserstein方向性度量来改进传统GAE，使其能够处理分布式强化学习中的价值分布，在多个OpenAI Gym环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的广义优势估计(GAE)虽然能够降低策略梯度估计的方差，但无法处理分布式强化学习中的价值分布。分布式强化学习能够捕获系统的固有随机性，对系统噪声更加鲁棒，因此需要一种能够处理价值分布的优势估计方法。

Method: 提出基于最优传输理论的类Wasserstein方向性度量，该度量能够同时衡量概率分布之间的距离和方向差异。结合指数加权估计，利用这一度量推导出分布式广义优势估计(DGAE)，使其能够处理价值分布并提供低方差、可控偏差的优势估计。

Result: 将DGAE集成到三种不同的策略梯度方法中，在多个OpenAI Gym环境中进行评估，与使用传统GAE的基线方法进行对比，验证了DGAE的性能优势。

Conclusion: DGAE成功扩展了传统GAE的能力，使其能够处理分布式强化学习中的价值分布，同时保持低方差和可控偏差的优势估计特性，为基于优势估计的策略梯度算法提供了更鲁棒的解决方案。

Abstract: Generalized Advantage Estimation (GAE) has been used to mitigate the
computational complexity of reinforcement learning (RL) by employing an
exponentially weighted estimation of the advantage function to reduce the
variance in policy gradient estimates. Despite its effectiveness, GAE is not
designed to handle value distributions integral to distributional RL, which can
capture the inherent stochasticity in systems and is hence more robust to
system noises. To address this gap, we propose a novel approach that utilizes
the optimal transport theory to introduce a Wasserstein-like directional
metric, which measures both the distance and the directional discrepancies
between probability distributions. Using the exponentially weighted estimation,
we leverage this Wasserstein-like directional metric to derive distributional
GAE (DGAE). Similar to traditional GAE, our proposed DGAE provides a
low-variance advantage estimate with controlled bias, making it well-suited for
policy gradient algorithms that rely on advantage estimation for policy
updates. We integrated DGAE into three different policy gradient methods.
Algorithms were evaluated across various OpenAI Gym environments and compared
with the baselines with traditional GAE to assess the performance.

</details>


### [151] [Persistent Patterns in Eye Movements: A Topological Approach to Emotion Recognition](https://arxiv.org/abs/2507.17450)
*Arsha Niksa,Hooman Zare,Ali Shahrabi,Hanieh Hatami,Mohammadreza Razvan*

Main category: cs.LG

TL;DR: 本文提出了一种基于拓扑学的眼动数据多类情感识别管道，通过对视线轨迹的延迟嵌入进行持久同调分析，从持久图中提取形状特征，使用随机森林分类器在四类情感上达到75.6%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的眼动数据情感识别方法可能无法充分捕捉复杂的视线动态模式。研究者希望探索拓扑学方法在情感计算和人类行为分析中的潜力，特别是利用持久同调来分析视线轨迹的几何结构特征。

Method: 采用拓扑学管道进行自动化多类情感识别：1）对眼动轨迹数据进行延迟嵌入；2）使用持久同调分析嵌入后的数据；3）从生成的持久图中提取基于形状的特征，包括平均持久性、最大持久性和熵；4）使用随机森林分类器对这些特征进行训练和分类。

Result: 在情感环形模型的四个象限（四类情感）上，随机森林分类器达到了75.6%的分类准确率。结果表明持久图的几何结构能够有效编码具有判别性的视线动态特征。

Conclusion: 持久图几何结构能够有效编码视线动态的判别特征，证明了拓扑学方法在情感计算和人类行为分析领域的应用前景。这种基于拓扑学的方法为眼动数据的情感识别提供了一个有前途的新途径。

Abstract: We present a topological pipeline for automated multiclass emotion
recognition from eye-tracking data. Delay embeddings of gaze trajectories are
analyzed using persistent homology. From the resulting persistence diagrams, we
extract shape-based features such as mean persistence, maximum persistence, and
entropy. A random forest classifier trained on these features achieves up to
$75.6\%$ accuracy on four emotion classes, which are the quadrants the
Circumplex Model of Affect. The results demonstrate that persistence diagram
geometry effectively encodes discriminative gaze dynamics, suggesting a
promising topological approach for affective computing and human behavior
analysis.

</details>


### [152] [Efficient Neural Network Verification via Order Leading Exploration of Branch-and-Bound Trees](https://arxiv.org/abs/2507.17453)
*Guanqin Zhang,Kota Fukuda,Zhenya Zhang,H. M. N. Dilum Bandara,Shiping Chen,Jianjun Zhao,Yulei Sui*

Main category: cs.LG

TL;DR: 本文提出了Oliva框架，通过优先探索更可能包含反例的子问题来改进神经网络分支界定验证方法的效率，在MNIST和CIFAR10数据集上分别实现了最高25倍和80倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的分支界定(BaB)神经网络验证方法虽然能够识别需要分割的子问题，但采用"先到先服务"的朴素方式探索子问题空间，导致验证效率低下。

Method: 提出Oliva验证框架，基于子问题包含反例的可能性建立排序机制，优先探索更可能找到反例的子问题。包含两个变体：贪心策略Oliva^{GR}和受模拟退火启发的平衡策略Oliva^{SA}。

Result: 在690个验证问题上进行实验评估，涵盖5个模型和MNIST、CIFAR10数据集。相比最先进方法，在MNIST上实现最高25倍加速，在CIFAR10上实现最高80倍加速。

Conclusion: Oliva框架通过智能子问题排序和优先级策略，显著提高了神经网络形式化验证的效率，即使无法找到反例也不会导致性能下降，为神经网络验证提供了更高效的解决方案。

Abstract: The vulnerability of neural networks to adversarial perturbations has
necessitated formal verification techniques that can rigorously certify the
quality of neural networks. As the state-of-the-art, branch and bound (BaB) is
a "divide-and-conquer" strategy that applies off-the-shelf verifiers to
sub-problems for which they perform better. While BaB can identify the
sub-problems that are necessary to be split, it explores the space of these
sub-problems in a naive "first-come-first-serve" manner, thereby suffering from
an issue of inefficiency to reach a verification conclusion. To bridge this
gap, we introduce an order over different sub-problems produced by BaB,
concerning with their different likelihoods of containing counterexamples.
Based on this order, we propose a novel verification framework Oliva that
explores the sub-problem space by prioritizing those sub-problems that are more
likely to find counterexamples, in order to efficiently reach the conclusion of
the verification. Even if no counterexample can be found in any sub-problem, it
only changes the order of visiting different sub-problem and so will not lead
to a performance degradation. Specifically, Oliva has two variants, including
$Oliva^{GR}$, a greedy strategy that always prioritizes the sub-problems that
are more likely to find counterexamples, and $Oliva^{SA}$, a balanced strategy
inspired by simulated annealing that gradually shifts from exploration to
exploitation to locate the globally optimal sub-problems. We experimentally
evaluate the performance of Oliva on 690 verification problems spanning over 5
models with datasets MNIST and CIFAR10. Compared to the state-of-the-art
approaches, we demonstrate the speedup of Oliva for up to 25X in MNIST, and up
to 80X in CIFAR10.

</details>


### [153] [C3RL: Rethinking the Combination of Channel-independence and Channel-mixing from Representation Learning](https://arxiv.org/abs/2507.17454)
*Shusen Ma,Yun-Bo Zhao,Yu Kang*

Main category: cs.LG

TL;DR: 本文提出C3RL框架，通过对比学习联合建模通道混合(CM)和通道独立(CI)策略，解决多变量时间序列预测中两种策略各自局限性的问题，在七个模型上实验显示显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有多变量时间序列预测方法采用CM策略能捕获变量间依赖但无法识别变量特定的时间模式，CI策略改善了这一问题但无法充分利用跨变量依赖关系，基于特征融合的混合策略泛化性和可解释性有限，需要一个能同时发挥两种策略优势的框架。

Method: 提出C3RL表示学习框架，受计算机视觉对比学习启发，将CM和CI策略的输入视为转置视图，构建孪生网络架构：一种策略作为主干网络，另一种作为补充；通过自适应加权联合优化对比损失和预测损失，平衡表示学习和预测性能。

Result: 在七个模型上的广泛实验表明，C3RL将基于CI策略的模型最佳性能率提升至81.4%，基于CM策略的模型最佳性能率提升至76.3%，展现出强大的泛化能力和有效性。

Conclusion: C3RL框架成功解决了多变量时间序列预测中CM和CI策略的局限性问题，通过对比学习有效融合两种策略的优势，在多个模型上实现显著性能提升，具有良好的泛化性和实用性。

Abstract: Multivariate time series forecasting has drawn increasing attention due to
its practical importance. Existing approaches typically adopt either
channel-mixing (CM) or channel-independence (CI) strategies. CM strategy can
capture inter-variable dependencies but fails to discern variable-specific
temporal patterns. CI strategy improves this aspect but fails to fully exploit
cross-variable dependencies like CM. Hybrid strategies based on feature fusion
offer limited generalization and interpretability. To address these issues, we
propose C3RL, a novel representation learning framework that jointly models
both CM and CI strategies. Motivated by contrastive learning in computer
vision, C3RL treats the inputs of the two strategies as transposed views and
builds a siamese network architecture: one strategy serves as the backbone,
while the other complements it. By jointly optimizing contrastive and
prediction losses with adaptive weighting, C3RL balances representation and
forecasting performance. Extensive experiments on seven models show that C3RL
boosts the best-case performance rate to 81.4\% for models based on CI strategy
and to 76.3\% for models based on CM strategy, demonstrating strong
generalization and effectiveness. The code will be available once the paper is
accepted.

</details>


### [154] [BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision Assessment on Semi-Structured Profiles](https://arxiv.org/abs/2507.17472)
*Junhua Liu,Roy Ka-Wei Lee,Kwan Hui Lim*

Main category: cs.LG

TL;DR: 本文提出BGM-HAN模型来改进大学招生等高风险决策领域的决策质量，通过分层学习和多头注意力机制有效处理半结构化申请者数据，在真实招生数据上显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 人类在高风险决策领域虽然依赖专业知识和启发式方法，但容易受到难以察觉的认知偏见影响，威胁公平性和长期结果。因此需要通过技术手段增强复杂决策工作流程。

Method: 提出BGM-HAN（增强型字节对编码门控多头分层注意力网络），集成分层学习和多种增强技术，专门设计用于有效建模半结构化申请者数据，捕获对细致评估至关重要的多层次表示。

Result: 在真实招生数据上的实验结果表明，所提出的模型显著优于从传统机器学习到大语言模型的最新基线方法，在可解释性和预测性能方面都有提升。

Conclusion: BGM-HAN为在结构、上下文和公平性都很重要的领域中增强决策制定提供了一个有前景的框架，能够有效改善高风险决策的质量和公平性。

Abstract: Human decision-making in high-stakes domains often relies on expertise and
heuristics, but is vulnerable to hard-to-detect cognitive biases that threaten
fairness and long-term outcomes. This work presents a novel approach to
enhancing complex decision-making workflows through the integration of
hierarchical learning alongside various enhancements. Focusing on university
admissions as a representative high-stakes domain, we propose BGM-HAN, an
enhanced Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network,
designed to effectively model semi-structured applicant data. BGM-HAN captures
multi-level representations that are crucial for nuanced assessment, improving
both interpretability and predictive performance. Experimental results on real
admissions data demonstrate that our proposed model significantly outperforms
both state-of-the-art baselines from traditional machine learning to large
language models, offering a promising framework for augmenting decision-making
in domains where structure, context, and fairness matter. Source code is
available at: https://github.com/junhua/bgm-han.

</details>


### [155] [DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD](https://arxiv.org/abs/2507.17501)
*Xianbiao Qi,Marco Chen,Wenjie Xiao,Jiaquan Ye,Yelin He,Chun-Guang Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: 论文提出了深度归一化Transformer(DNT)，通过在关键位置集成归一化技术，使得模型能够使用简单的动量SGD优化器进行训练，而不需要AdamW等自适应学习率优化器，同时保持相当的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型通常需要AdamW等自适应学习率优化器才能有效训练，而无法使用简单的动量SGD，这主要是由于梯度分布的重尾特性导致的。作者希望设计一种能够使用vanilla动量SGD进行训练的Transformer架构。

Method: 提出深度归一化Transformer(DNT)，在Transformer的适当位置策略性地集成归一化技术，通过有效调制每层的雅可比矩阵，平衡权重、激活及其交互的影响，从而使梯度分布更加集中，支持使用vanilla动量SGD进行训练。

Result: 在ViT和GPT两种流行的Transformer架构上进行了广泛的实验评估，结果表明：1)DNT优于其对应的基线模型(ViT和GPT)；2)DNT可以有效地使用vanilla动量SGD进行训练。

Conclusion: 通过精心设计的归一化技术集成，DNT成功解决了Transformer训练中对自适应优化器的依赖问题，实现了使用简单动量SGD进行有效训练，同时保持了与AdamW训练的Transformer相当的性能，为Transformer的优化提供了新的思路。

Abstract: Transformers have become the de facto backbone of modern deep learning, yet
their training typically demands an advanced optimizer with adaptive learning
rate like AdamW, rather than a momentum SGDW (mSGDW). Previous works show that
it is mainly due to a heavy-tailed distribution of the gradients. In this
paper, we introduce a Deeply Normalized Transformer (DNT), which is
meticulously engineered to overcome this limitation enabling seamless training
with vanilla mSGDW while yielding comparable performance to the Transformers
trained via AdamW. To be specific, in DNT, we strategically integrate
normalization techniques at proper positions in the Transformers to effectively
modulate the Jacobian matrices of each layer, balance the influence of weights,
activations, and their interactions, and thus enable the distributions of
gradients concentrated. We provide both theoretical justifications of the
normalization technique used in our DNT and extensive empirical evaluation on
two popular Transformer architectures to validate that: a) DNT outperforms its
counterparts (\ie, ViT and GPT), and b) DNT can be effectively trained with
vanilla mSGDW.

</details>


### [156] [HOTA: Hamiltonian framework for Optimal Transport Advection](https://arxiv.org/abs/2507.17513)
*Nazar Buzun,Daniil Shlenskii,Maxim Bobrin,Dmitry V. Dylov*

Main category: cs.LG

TL;DR: 本文提出了HOTA方法，通过Hamilton-Jacobi-Bellman方程解决最优传输问题，避免了显式密度建模，在非光滑代价函数情况下也能有效工作，在标准基准和自定义数据集上都优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型大多假设简单几何结构（如欧几里得空间）并依赖强密度估计假设，导致轨迹不符合底层流形的真正最优性原理。需要一种能够在复杂流形上进行有效轨迹优化的方法。

Method: 提出了哈密顿最优传输平流（HOTA）方法，基于Hamilton-Jacobi-Bellman方程，通过Kantorovich势函数显式处理对偶动态最优传输问题，实现高效可扩展的轨迹优化。

Result: HOTA在标准基准测试和带有非可微代价函数的自定义数据集上均优于所有基线方法，在可行性和最优性方面都表现出色。该方法有效避免了显式密度建模的需求，即使在代价函数非光滑的情况下也能良好工作。

Conclusion: HOTA为最优传输引导的概率流提供了一个有效的框架，通过Hamilton-Jacobi-Bellman方法解决了传统方法在复杂几何和非光滑代价函数下的局限性，为生成模型的轨迹优化提供了新的解决方案。

Abstract: Optimal transport (OT) has become a natural framework for guiding the
probability flows. Yet, the majority of recent generative models assume trivial
geometry (e.g., Euclidean) and rely on strong density-estimation assumptions,
yielding trajectories that do not respect the true principles of optimality in
the underlying manifold. We present Hamiltonian Optimal Transport Advection
(HOTA), a Hamilton-Jacobi-Bellman based method that tackles the dual dynamical
OT problem explicitly through Kantorovich potentials, enabling efficient and
scalable trajectory optimization. Our approach effectively evades the need for
explicit density modeling, performing even when the cost functionals are
non-smooth. Empirically, HOTA outperforms all baselines in standard benchmarks,
as well as in custom datasets with non-differentiable costs, both in terms of
feasibility and optimality.

</details>


### [157] [Generalized Low-Rank Matrix Contextual Bandits with Graph Information](https://arxiv.org/abs/2507.17528)
*Yao Wang,Jiannan Li,Yue Kang,Shanxing Gao,Zhenxin Xiao*

Main category: cs.LG

TL;DR: 本文提出了一种新的矩阵上下文赌博机算法框架，通过结合低秩结构和图信息来改进序列决策性能，在理论和实验上都展现出优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的矩阵上下文赌博机方法仅利用低秩结构，忽略了真实场景中用户/物品之间的图关系信息（如在线广告和推荐系统中的相似性关系），导致决策策略效果不佳。

Method: 提出基于经典置信上界（UCB）框架的新算法，通过求解联合核范数和矩阵拉普拉斯正则化问题，然后实现基于图的广义线性UCB算法，统一整合低秩结构和图信息。

Result: 理论分析证明该方法在累积遗憾界方面优于多种流行的替代方法，合成数据和真实数据实验进一步验证了算法的优越性。

Conclusion: 通过有效利用图信息，所提出的矩阵上下文赌博机框架能够显著提升序列决策性能，为涉及低秩结构和图关系的实际应用提供了更有效的解决方案。

Abstract: The matrix contextual bandit (CB), as an extension of the well-known
multi-armed bandit, is a powerful framework that has been widely applied in
sequential decision-making scenarios involving low-rank structure. In many
real-world scenarios, such as online advertising and recommender systems,
additional graph information often exists beyond the low-rank structure, that
is, the similar relationships among users/items can be naturally captured
through the connectivity among nodes in the corresponding graphs. However,
existing matrix CB methods fail to explore such graph information, and thereby
making them difficult to generate effective decision-making policies. To fill
in this void, we propose in this paper a novel matrix CB algorithmic framework
that builds upon the classical upper confidence bound (UCB) framework. This new
framework can effectively integrate both the low-rank structure and graph
information in a unified manner. Specifically, it involves first solving a
joint nuclear norm and matrix Laplacian regularization problem, followed by the
implementation of a graph-based generalized linear version of the UCB
algorithm. Rigorous theoretical analysis demonstrates that our procedure
outperforms several popular alternatives in terms of cumulative regret bound,
owing to the effective utilization of graph information. A series of synthetic
and real-world data experiments are conducted to further illustrate the merits
of our procedure.

</details>


### [158] [Federated Majorize-Minimization: Beyond Parameter Aggregation](https://arxiv.org/abs/2507.17534)
*Aymeric Dieuleveut,Gersende Fort,Mahmoud Hegazy,Hoi-To Wai*

Main category: cs.LG

TL;DR: 本文提出了一个统一的随机优化算法框架，能够鲁棒地扩展到联邦学习环境中，通过Majorize-Minimization方法设计了SSMM和QSMM算法，解决了数据异构性、部分参与和通信约束等关键问题。


<details>
  <summary>Details</summary>
Motivation: 现有的随机优化算法在联邦学习环境中面临数据异构性、部分参与和通信约束等挑战，需要一个能够统一处理这些问题的鲁棒算法框架。

Method: 提出基于Majorize-Minimization（MM）问题的统一框架，该框架具有线性参数化的主化代理函数族。开发了随机逼近随机代理MM算法（SSMM），并将其扩展到联邦设置中得到QSMM算法。QSMM的创新在于本地学习后聚合表征代理主化函数的信息，而非传统的聚合原始参数。

Result: SSMM算法统一了多种现有的随机MM过程作为特殊实例，包括（正则化）光滑目标的（邻近）梯度算法和期望最大化算法。QSMM成功解决了联邦学习中的关键瓶颈问题，并展示了在联邦环境下计算最优传输映射的应用潜力。

Conclusion: 该方法提供了一个灵活且统一的框架来设计适用于联邦学习的随机优化算法，通过聚合代理函数信息而非原始参数的创新方式，有效应对了联邦学习的各种挑战，并具有广泛的应用前景。

Abstract: This paper proposes a unified approach for designing stochastic optimization
algorithms that robustly scale to the federated learning setting. Our work
studies a class of Majorize-Minimization (MM) problems, which possesses a
linearly parameterized family of majorizing surrogate functions. This framework
encompasses (proximal) gradient-based algorithms for (regularized) smooth
objectives, the Expectation Maximization algorithm, and many problems seen as
variational surrogate MM. We show that our framework motivates a unifying
algorithm called Stochastic Approximation Stochastic Surrogate MM (\SSMM),
which includes previous stochastic MM procedures as special instances. We then
extend \SSMM\ to the federated setting, while taking into consideration common
bottlenecks such as data heterogeneity, partial participation, and
communication constraints; this yields \QSMM. The originality of \QSMM\ is to
learn locally and then aggregate information characterizing the
\textit{surrogate majorizing function}, contrary to classical algorithms which
learn and aggregate the \textit{original parameter}. Finally, to showcase the
flexibility of this methodology beyond our theoretical setting, we use it to
design an algorithm for computing optimal transport maps in the federated
setting.

</details>


### [159] [Enhancing Quantum Federated Learning with Fisher Information-Based Optimization](https://arxiv.org/abs/2507.17580)
*Amandeep Singh Bhatia,Sabre Kais*

Main category: cs.LG

TL;DR: 本文提出了一种基于Fisher信息的量子联邦学习算法，通过识别和保护关键参数来提升异构数据环境下的模型性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临高通信成本、异构客户端数据、处理时间长和隐私威胁等挑战。量子联邦学习的兴起为医疗和金融等领域带来了新机遇，但现有方法在处理异构数据分布时仍存在不足。Fisher信息能够量化量子态在参数变化下携带的信息量，可用于解决上述挑战。

Method: 提出了一种利用Fisher信息的量子联邦学习算法。该方法在本地客户端模型上计算Fisher信息，识别对量子模型性能有重大影响的关键参数，并在聚合过程中确保这些关键参数得到保护。算法处理分布在异构分区上的数据。

Result: 在ADNI和MNIST数据集上的实验结果表明，相比量子联邦平均方法，所提出的方法在性能和鲁棒性方面都有显著提升。验证了在量子联邦学习环境中结合Fisher信息的有效性和可行性。

Conclusion: 基于Fisher信息的量子联邦学习算法能够有效解决传统联邦学习面临的挑战，在保护数据隐私的同时实现更好的模型性能。该方法为量子联邦学习在实际应用中的部署提供了新的解决方案。

Abstract: Federated Learning (FL) has become increasingly popular across different
sectors, offering a way for clients to work together to train a global model
without sharing sensitive data. It involves multiple rounds of communication
between the global model and participating clients, which introduces several
challenges like high communication costs, heterogeneous client data, prolonged
processing times, and increased vulnerability to privacy threats. In recent
years, the convergence of federated learning and parameterized quantum circuits
has sparked significant research interest, with promising implications for
fields such as healthcare and finance. By enabling decentralized training of
quantum models, it allows clients or institutions to collaboratively enhance
model performance and outcomes while preserving data privacy. Recognizing that
Fisher information can quantify the amount of information that a quantum state
carries under parameter changes, thereby providing insight into its geometric
and statistical properties. We intend to leverage this property to address the
aforementioned challenges. In this work, we propose a Quantum Federated
Learning (QFL) algorithm that makes use of the Fisher information computed on
local client models, with data distributed across heterogeneous partitions.
This approach identifies the critical parameters that significantly influence
the quantum model's performance, ensuring they are preserved during the
aggregation process. Our research assessed the effectiveness and feasibility of
QFL by comparing its performance against other variants, and exploring the
benefits of incorporating Fisher information in QFL settings. Experimental
results on ADNI and MNIST datasets demonstrate the effectiveness of our
approach in achieving better performance and robustness against the quantum
federated averaging method.

</details>


### [160] [XStacking: Explanation-Guided Stacked Ensemble Learning](https://arxiv.org/abs/2507.17650)
*Moncef Garouani,Ayah Barhrhouj,Olivier Teste*

Main category: cs.LG

TL;DR: 本文提出了XStacking框架，通过集成动态特征转换和Shapley加性解释，解决了集成机器学习（特别是stacking）缺乏可解释性的问题，在保持预测准确性的同时实现了模型的内在可解释性。


<details>
  <summary>Details</summary>
Motivation: 集成机器学习技术（尤其是stacking）虽然能通过组合多个基础模型来提高预测性能，但经常因缺乏可解释性而受到批评。现有的集成方法在提升预测能力的同时，往往牺牲了模型的可解释性，这在需要负责任的机器学习应用中是一个重要限制。

Method: 提出XStacking框架，该框架通过集成动态特征转换与模型无关的Shapley加性解释来解决可解释性问题。该方法能够使堆叠模型在保持预测准确性的同时获得内在的可解释性，为集成学习提供了一个既有效又可解释的解决方案。

Result: 在29个数据集上验证了框架的有效性，结果显示XStacking在学习空间的预测效果和结果模型的可解释性两方面都取得了改进。该框架为负责任的机器学习提供了实用且可扩展的解决方案。

Conclusion: XStacking成功解决了集成机器学习缺乏可解释性的核心问题，通过动态特征转换和Shapley解释的集成，实现了预测性能和可解释性的双重提升，为负责任的机器学习应用提供了有价值的工具。

Abstract: Ensemble Machine Learning (EML) techniques, especially stacking, have been
shown to improve predictive performance by combining multiple base models.
However, they are often criticized for their lack of interpretability. In this
paper, we introduce XStacking, an effective and inherently explainable
framework that addresses this limitation by integrating dynamic feature
transformation with model-agnostic Shapley additive explanations. This enables
stacked models to retain their predictive accuracy while becoming inherently
explainable. We demonstrate the effectiveness of the framework on 29 datasets,
achieving improvements in both the predictive effectiveness of the learning
space and the interpretability of the resulting models. XStacking offers a
practical and scalable solution for responsible ML.

</details>


### [161] [How Should We Meta-Learn Reinforcement Learning Algorithms?](https://arxiv.org/abs/2507.17668)
*Alexander David Goldie,Zilin Wang,Jakob Nicolaus Foerster,Shimon Whiteson*

Main category: cs.LG

TL;DR: 本文对不同元学习算法在强化学习中的应用进行了首次系统性的实证比较，包括进化算法和大语言模型等方法，并基于性能、可解释性、样本成本等多维度评估提出了元学习强化学习算法的指导原则。


<details>
  <summary>Details</summary>
Motivation: 尽管元学习在强化学习中显示出巨大潜力，能够自动设计算法而非依赖人工设计，但目前严重缺乏对不同元学习方法（如进化优化黑盒函数、大语言模型生成代码等）的系统性比较研究。

Method: 对多种元学习算法进行实证比较，这些算法针对强化学习流程的不同部分。评估维度包括元训练和元测试性能、可解释性、样本成本和训练时间等多个因素。

Result: 通过系统性比较不同元学习方法在强化学习中的表现，获得了关于各种方法在不同评估维度上的性能数据和特征分析。

Conclusion: 基于实验发现，提出了元学习新强化学习算法的若干指导原则，这些原则有助于确保未来学习到的算法具有尽可能高的性能。

Abstract: The process of meta-learning algorithms from data, instead of relying on
manual design, is growing in popularity as a paradigm for improving the
performance of machine learning systems. Meta-learning shows particular promise
for reinforcement learning (RL), where algorithms are often adapted from
supervised or unsupervised learning despite their suboptimality for RL.
However, until now there has been a severe lack of comparison between different
meta-learning algorithms, such as using evolution to optimise over black-box
functions or LLMs to propose code. In this paper, we carry out this empirical
comparison of the different approaches when applied to a range of meta-learned
algorithms which target different parts of the RL pipeline. In addition to
meta-train and meta-test performance, we also investigate factors including the
interpretability, sample cost and train time for each meta-learning algorithm.
Based on these findings, we propose several guidelines for meta-learning new RL
algorithms which will help ensure that future learned algorithms are as
performant as possible.

</details>


### [162] [Generalized Dual Discriminator GANs](https://arxiv.org/abs/2507.17684)
*Penukonda Naga Chandana,Tejas Srivastava,Gowtham R. Kurri,V. Lalitha*

Main category: cs.LG

TL;DR: 本文提出了双判别器α-GANs（D2α-GANs）和广义双判别器GANs，通过结合双判别器和可调损失函数来解决GAN中的模式坍塌问题，并在理论上证明其优化目标可简化为f-散度和反向f-散度的线性组合。


<details>
  <summary>Details</summary>
Motivation: 传统GANs存在模式坍塌问题，虽然双判别器GANs（D2GANs）能够缓解这个问题，但仍缺乏灵活的损失函数调节机制。作者希望结合双判别器的优势与可调损失函数的灵活性，进一步改进GAN的性能。

Method: 提出双判别器α-GANs（D2α-GANs），结合双判别器机制和α-损失函数；进一步将方法推广到定义在正实数上的任意函数，形成广义双判别器GANs；使用两个判别器，一个奖励真实数据分布的样本，另一个偏好生成器产生的样本。

Result: 理论分析表明，所提出模型的最小-最大优化问题可以简化为f-散度和反向f-散度的线性组合的最小化问题，这推广了D2-GANs中目标函数简化为KL散度和反向KL散度线性组合的已知结果；在2D合成数据上的实验验证了方法的有效性。

Conclusion: 双判别器α-GANs和广义双判别器GANs成功结合了双判别器的优势和灵活的损失函数，在理论上提供了新的散度组合解释，在实验中展现了改进的性能，为解决GAN模式坍塌问题提供了新的思路。

Abstract: Dual discriminator generative adversarial networks (D2 GANs) were introduced
to mitigate the problem of mode collapse in generative adversarial networks. In
D2 GANs, two discriminators are employed alongside a generator: one
discriminator rewards high scores for samples from the true data distribution,
while the other favors samples from the generator. In this work, we first
introduce dual discriminator $\alpha$-GANs (D2 $\alpha$-GANs), which combines
the strengths of dual discriminators with the flexibility of a tunable loss
function, $\alpha$-loss. We further generalize this approach to arbitrary
functions defined on positive reals, leading to a broader class of models we
refer to as generalized dual discriminator generative adversarial networks. For
each of these proposed models, we provide theoretical analysis and show that
the associated min-max optimization reduces to the minimization of a linear
combination of an $f$-divergence and a reverse $f$-divergence. This generalizes
the known simplification for D2-GANs, where the objective reduces to a linear
combination of the KL-divergence and the reverse KL-divergence. Finally, we
perform experiments on 2D synthetic data and use multiple performance metrics
to capture various advantages of our GANs.

</details>


### [163] [Towards Effective Open-set Graph Class-incremental Learning](https://arxiv.org/abs/2507.17687)
*Jiazhen Chen,Zheng Ma,Sichao Fu,Mingbin Feng,Tony S. Wirjanto,Weihua Ou*

Main category: cs.LG

TL;DR: 本文提出了OGCIL框架，解决开放集图类增量学习中的灾难性遗忘和未知类检测问题，通过原型条件变分自编码器生成伪样本嵌入和混合策略生成分布外样本，实现了对未知类的鲁棒检测。


<details>
  <summary>Details</summary>
Motivation: 现有的图类增量学习方法主要基于封闭集假设，即所有测试样本都属于已知类别，这限制了它们在真实场景中的适用性。在实际应用中，未知类别会在推理过程中自然出现，但在训练期间却不存在，因此需要解决开放集图类增量学习中的两个挑战：旧类的灾难性遗忘和不充分的开放集识别。

Method: 提出OGCIL框架，包含三个核心组件：1）设计原型条件变分自编码器来合成旧类的节点嵌入，实现知识重放而无需存储原始图数据；2）采用基于混合的策略从伪分布内和当前节点嵌入中生成分布外样本来处理未知类；3）提出新颖的原型超球分类损失，将分布内嵌入锚定到各自的类原型，同时排斥分布外嵌入。

Result: 在五个基准数据集上的大量实验表明，OGCIL在现有的图类增量学习和开放集图神经网络方法上表现出显著的有效性，能够有效缓解灾难性遗忘并实现对未知类的鲁棒检测。

Conclusion: OGCIL框架成功解决了开放集图类增量学习中的关键挑战，通过原型感知的拒绝区域明确地将未知样本建模为异常值，确保了鲁棒的开放集识别，为图神经网络在动态环境中的应用提供了新的解决方案。

Abstract: Graph class-incremental learning (GCIL) allows graph neural networks (GNNs)
to adapt to evolving graph analytical tasks by incrementally learning new class
knowledge while retaining knowledge of old classes. Existing GCIL methods
primarily focus on a closed-set assumption, where all test samples are presumed
to belong to previously known classes. Such an assumption restricts their
applicability in real-world scenarios, where unknown classes naturally emerge
during inference, and are absent during training. In this paper, we explore a
more challenging open-set graph class-incremental learning scenario with two
intertwined challenges: catastrophic forgetting of old classes, which impairs
the detection of unknown classes, and inadequate open-set recognition, which
destabilizes the retention of learned knowledge. To address the above problems,
a novel OGCIL framework is proposed, which utilizes pseudo-sample embedding
generation to effectively mitigate catastrophic forgetting and enable robust
detection of unknown classes. To be specific, a prototypical conditional
variational autoencoder is designed to synthesize node embeddings for old
classes, enabling knowledge replay without storing raw graph data. To handle
unknown classes, we employ a mixing-based strategy to generate
out-of-distribution (OOD) samples from pseudo in-distribution and current node
embeddings. A novel prototypical hypersphere classification loss is further
proposed, which anchors in-distribution embeddings to their respective class
prototypes, while repelling OOD embeddings away. Instead of assigning all
unknown samples into one cluster, our proposed objective function explicitly
models them as outliers through prototype-aware rejection regions, ensuring a
robust open-set recognition. Extensive experiments on five benchmarks
demonstrate the effectiveness of OGCIL over existing GCIL and open-set GNN
methods.

</details>


### [164] [Joint Asymmetric Loss for Learning with Noisy Labels](https://arxiv.org/abs/2507.17692)
*Jialiang Wang,Xianming Liu,Xiong Zhou,Gangfeng Hu,Deming Zhai,Junjun Jiang,Xiangyang Ji*

Main category: cs.LG

TL;DR: 该论文提出了联合非对称损失(JAL)框架来解决带噪声标签的深度学习问题。通过引入非对称均方误差(AMSE)作为被动损失，克服了传统对称损失的欠拟合问题，在标签噪声缓解方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的对称损失函数在处理标签噪声时存在欠拟合问题，而新兴的非对称损失虽然理论上具有优越性，但无法与现有的优化框架(如APL)兼容，限制了其应用潜力。

Method: 提出了非对称均方误差(AMSE)作为新的非对称损失函数，并建立了AMSE满足非对称条件的充分必要条件。将AMSE替换APL框架中的传统对称被动损失，构建了联合非对称损失(JAL)框架。

Result: 广泛的实验表明该方法在缓解标签噪声方面具有有效性，JAL框架成功地将非对称损失的优势与先进的优化框架相结合。

Conclusion: 成功地将非对称损失扩展到复杂的被动损失场景，提出的JAL框架有效解决了标签噪声问题，为噪声标签学习提供了新的解决方案。

Abstract: Learning with noisy labels is a crucial task for training accurate deep
neural networks. To mitigate label noise, prior studies have proposed various
robust loss functions, particularly symmetric losses. Nevertheless, symmetric
losses usually suffer from the underfitting issue due to the overly strict
constraint. To address this problem, the Active Passive Loss (APL) jointly
optimizes an active and a passive loss to mutually enhance the overall fitting
ability. Within APL, symmetric losses have been successfully extended, yielding
advanced robust loss functions. Despite these advancements, emerging
theoretical analyses indicate that asymmetric losses, a new class of robust
loss functions, possess superior properties compared to symmetric losses.
However, existing asymmetric losses are not compatible with advanced
optimization frameworks such as APL, limiting their potential and
applicability. Motivated by this theoretical gap and the prospect of asymmetric
losses, we extend the asymmetric loss to the more complex passive loss scenario
and propose the Asymetric Mean Square Error (AMSE), a novel asymmetric loss. We
rigorously establish the necessary and sufficient condition under which AMSE
satisfies the asymmetric condition. By substituting the traditional symmetric
passive loss in APL with our proposed AMSE, we introduce a novel robust loss
framework termed Joint Asymmetric Loss (JAL). Extensive experiments demonstrate
the effectiveness of our method in mitigating label noise. Code available at:
https://github.com/cswjl/joint-asymmetric-loss

</details>


### [165] [HydraOpt: Navigating the Efficiency-Performance Trade-off of Adapter Merging](https://arxiv.org/abs/2507.17706)
*Taha Ceritli,Ondrej Bohdal,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.LG

TL;DR: HydraOpt是一种新的模型合并技术，通过利用低秩适配器矩阵间的相似性，在大幅减少存储需求（48%）的同时保持竞争性能（仅0.2-1.8%性能下降），解决了大语言模型适配器存储成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型使用适配器在下游任务上取得强性能，但为每个任务存储单独的适配器会显著增加内存需求，在移动设备等资源受限环境中构成挑战。现有模型合并技术虽能降低存储成本，但通常会导致性能大幅下降。

Method: 提出HydraOpt，一种新的模型合并技术，利用低秩适配器矩阵之间的固有相似性。与现有方法产生存储大小和性能之间固定权衡不同，HydraOpt允许在效率和性能谱系中灵活导航。

Result: 实验显示HydraOpt相比存储所有适配器显著减少存储大小（48%减少），同时实现竞争性能（0.2-1.8%下降）。在相同或稍差的存储效率下，性能优于现有合并技术。

Conclusion: HydraOpt成功解决了适配器存储与性能之间的权衡问题，为资源受限环境下的大语言模型部署提供了有效解决方案，在保持高性能的同时大幅降低了存储需求。

Abstract: Large language models (LLMs) often leverage adapters, such as low-rank-based
adapters, to achieve strong performance on downstream tasks. However, storing a
separate adapter for each task significantly increases memory requirements,
posing a challenge for resource-constrained environments such as mobile
devices. Although model merging techniques can reduce storage costs, they
typically result in substantial performance degradation. In this work, we
introduce HydraOpt, a new model merging technique that capitalizes on the
inherent similarities between the matrices of low-rank adapters. Unlike
existing methods that produce a fixed trade-off between storage size and
performance, HydraOpt allows us to navigate this spectrum of efficiency and
performance. Our experiments show that HydraOpt significantly reduces storage
size (48% reduction) compared to storing all adapters, while achieving
competitive performance (0.2-1.8% drop). Furthermore, it outperforms existing
merging techniques in terms of performance at the same or slightly worse
storage efficiency.

</details>


### [166] [On the Interaction of Compressibility and Adversarial Robustness](https://arxiv.org/abs/2507.17725)
*Melih Barsbey,Antônio H. Ribeiro,Umut Şimşekli,Tolga Birdal*

Main category: cs.LG

TL;DR: 本文研究了神经网络压缩性与对抗鲁棒性之间的根本性冲突，发现压缩会在表示空间中产生少数高敏感方向，使对手能够利用这些方向构造有效的对抗扰动


<details>
  <summary>Details</summary>
Motivation: 现代神经网络需要同时满足多个理想属性：准确拟合训练数据、泛化到未见输入、参数和计算效率，以及对抗扰动的鲁棒性。虽然压缩性和鲁棒性都已被广泛研究，但对它们相互作用的统一理解仍然缺乏

Method: 开发了一个原理性框架来分析不同形式的压缩性（如神经元级稀疏性和谱压缩性）如何影响对抗鲁棒性。通过理论分析得出了一个简单而有指导意义的鲁棒性界限，并通过合成和现实任务的实证评估验证理论预测

Result: 发现压缩可以在表示空间中诱导少数高敏感方向，对手可以利用这些方向构造有效扰动。无论压缩是通过正则化、架构偏置还是隐式学习动力学实现，这些漏洞都会出现。这些漏洞在对抗训练和迁移学习下持续存在，并有助于通用对抗扰动的出现

Conclusion: 研究表明结构化压缩性与鲁棒性之间存在根本性张力，并提出了设计既高效又安全的模型的新途径。发现了神经元和谱压缩性通过对学习表示的影响来影响L∞和L2鲁棒性的机制

Abstract: Modern neural networks are expected to simultaneously satisfy a host of
desirable properties: accurate fitting to training data, generalization to
unseen inputs, parameter and computational efficiency, and robustness to
adversarial perturbations. While compressibility and robustness have each been
studied extensively, a unified understanding of their interaction still remains
elusive. In this work, we develop a principled framework to analyze how
different forms of compressibility - such as neuron-level sparsity and spectral
compressibility - affect adversarial robustness. We show that these forms of
compression can induce a small number of highly sensitive directions in the
representation space, which adversaries can exploit to construct effective
perturbations. Our analysis yields a simple yet instructive robustness bound,
revealing how neuron and spectral compressibility impact $L_\infty$ and $L_2$
robustness via their effects on the learned representations. Crucially, the
vulnerabilities we identify arise irrespective of how compression is achieved -
whether via regularization, architectural bias, or implicit learning dynamics.
Through empirical evaluations across synthetic and realistic tasks, we confirm
our theoretical predictions, and further demonstrate that these vulnerabilities
persist under adversarial training and transfer learning, and contribute to the
emergence of universal adversarial perturbations. Our findings show a
fundamental tension between structured compressibility and robustness, and
suggest new pathways for designing models that are both efficient and secure.

</details>


### [167] [Flow Matching Meets Biology and Life Science: A Survey](https://arxiv.org/abs/2507.17731)
*Zihao Li,Zhichen Zeng,Xiao Lin,Feihao Fang,Yanru Qu,Zhe Xu,Zhining Liu,Xuying Ning,Tianxin Wei,Ge Liu,Hanghang Tong,Jingrui He*

Main category: cs.LG

TL;DR: 这是第一篇关于流匹配(flow matching)在生物学领域应用的综合性综述论文，系统回顾了流匹配的基础理论和在生物序列建模、分子生成设计、肽和蛋白质生成三大领域的应用进展。


<details>
  <summary>Details</summary>
Motivation: 生成式建模在过去十年中显著推动了生物研究和发现，包括分子设计、蛋白质生成、药物发现等领域。流匹配作为扩散模型的强大替代方案正在兴起，但缺乏对其在生物学领域应用的系统性综述。

Method: 采用综合性文献综述方法，首先系统回顾流匹配的基础理论和变体，然后将其生物学应用分为三个主要领域进行分类整理：生物序列建模、分子生成和设计、肽和蛋白质生成，并总结常用数据集和软件工具。

Result: 提供了流匹配在生物学领域应用的全面梳理，涵盖了理论基础、主要应用领域的最新进展，整理了相关数据集和工具资源，并在GitHub上提供了策划的资源集合。

Conclusion: 流匹配作为一种高效的生成建模方法，在生物学领域展现出巨大潜力，未来在生物序列建模、分子设计、蛋白质生成等方向有广阔的发展前景，为生物学研究和药物发现提供了新的技术路径。

Abstract: Over the past decade, advances in generative modeling, such as generative
adversarial networks, masked autoencoders, and diffusion models, have
significantly transformed biological research and discovery, enabling
breakthroughs in molecule design, protein generation, drug discovery, and
beyond. At the same time, biological applications have served as valuable
testbeds for evaluating the capabilities of generative models. Recently, flow
matching has emerged as a powerful and efficient alternative to diffusion-based
generative modeling, with growing interest in its application to problems in
biology and life sciences. This paper presents the first comprehensive survey
of recent developments in flow matching and its applications in biological
domains. We begin by systematically reviewing the foundations and variants of
flow matching, and then categorize its applications into three major areas:
biological sequence modeling, molecule generation and design, and peptide and
protein generation. For each, we provide an in-depth review of recent progress.
We also summarize commonly used datasets and software tools, and conclude with
a discussion of potential future directions. The corresponding curated
resources are available at
https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.

</details>


### [168] [Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains](https://arxiv.org/abs/2507.17746)
*Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Bing Liu,Sean Hendryx*

Main category: cs.LG

TL;DR: 该论文提出了"Rubrics as Rewards"(RaR)框架，使用结构化清单式评分标准作为可解释的奖励信号来训练语言模型，在HealthBench-1k上相比传统方法取得了28%的相对提升。


<details>
  <summary>Details</summary>
Motivation: 在现实世界任务中，强化学习往往缺乏单一明确的真实标准来定义可靠的奖励信号，而传统的偏好方法依赖于不透明且容易产生虚假关联的奖励函数，因此需要更可解释和可靠的奖励机制。

Method: 提出"Rubrics as Rewards"(RaR)框架，使用结构化的清单式评分标准作为可解释的奖励信号，结合GRPO进行在线策略训练，将评分标准视为结构化奖励信号来指导模型训练。

Result: 在HealthBench-1k数据集上，最佳RaR方法相比简单的李克特量表方法取得了高达28%的相对改进，同时匹配或超越了基于专家编写参考答案的奖励信号性能。

Conclusion: RaR框架能够使小规模判断模型更好地与人类偏好对齐，并在不同模型规模下保持稳健的性能表现，为强化学习提供了更可解释和有效的奖励机制。

Abstract: Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world
tasks often requires balancing objective and subjective evaluation criteria.
However, many such tasks lack a single, unambiguous ground truth-making it
difficult to define reliable reward signals for post-training language models.
While traditional preference-based methods offer a workaround, they rely on
opaque reward functions that are difficult to interpret and prone to spurious
correlations. We introduce $\textbf{Rubrics as Rewards}$ (RaR), a framework
that uses structured, checklist-style rubrics as interpretable reward signals
for on-policy training with GRPO. Our best RaR method yields up to a $28\%$
relative improvement on HealthBench-1k compared to simple Likert-based
approaches, while matching or surpassing the performance of reward signals
derived from expert-written references. By treating rubrics as structured
reward signals, we show that RaR enables smaller-scale judge models to better
align with human preferences and sustain robust performance across model
scales.

</details>


### [169] [Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility](https://arxiv.org/abs/2507.17748)
*Melih Barsbey,Lucas Prieto,Stefanos Zafeiriou,Tolga Birdal*

Main category: cs.LG

TL;DR: 本文发现大学习率能够同时实现模型对虚假关联的鲁棒性和网络压缩性，并在多个数据集和模型上验证了这一发现。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型需要同时具备鲁棒性和资源效率，但这两个特性很难同时实现。作者希望找到一种能够同时满足这两个要求的方法。

Method: 将大学习率作为同时实现对虚假关联鲁棒性和网络可压缩性的促进因子。通过在多种虚假关联数据集、模型和优化器上进行实验，分析大学习率对不变特征利用、类别分离和激活稀疏性等表示属性的影响。

Result: 实验结果表明，大学习率能够产生理想的表示属性，包括不变特征利用、类别分离和激活稀疏性。相比其他超参数和正则化方法，大学习率在同时满足鲁棒性和压缩性方面表现更加一致和优秀。

Conclusion: 大学习率是一个有效的工具，能够同时提升模型的鲁棒性和资源效率。此外，作者还提出大学习率在标准分类任务中的成功可能是由于其能够处理训练数据集中隐藏的或罕见的虚假关联。

Abstract: Robustness and resource-efficiency are two highly desirable properties for
modern machine learning models. However, achieving them jointly remains a
challenge. In this paper, we position high learning rates as a facilitator for
simultaneously achieving robustness to spurious correlations and network
compressibility. We demonstrate that large learning rates also produce
desirable representation properties such as invariant feature utilization,
class separation, and activation sparsity. Importantly, our findings indicate
that large learning rates compare favorably to other hyperparameters and
regularization methods, in consistently satisfying these properties in tandem.
In addition to demonstrating the positive effect of large learning rates across
diverse spurious correlation datasets, models, and optimizers, we also present
strong evidence that the previously documented success of large learning rates
in standard classification tasks is likely due to its effect on addressing
hidden/rare spurious correlations in the training dataset.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [170] [Regret Minimization in Population Network Games: Vanishing Heterogeneity and Convergence to Equilibria](https://arxiv.org/abs/2507.17183)
*Die Hu,Shuyue Hu,Chunjiang Mu,Shiqi Fan,Chen Chu,Jinzhuo Liu,Zhen Wang*

Main category: cs.GT

TL;DR: 本文研究大规模多智能体系统中异质性对均衡形成的影响，发现通过平滑后悔匹配算法，异质智能体的后悔分布方差随时间减小，最终形成一致性行为并收敛到量子响应均衡。


<details>
  <summary>Details</summary>
Motivation: 理解和预测大规模多智能体游戏中的行为仍然是多智能体系统的基本挑战，需要深入研究异质性在均衡形成中的作用机制。

Method: 将系统状态建模为后悔的概率分布，通过连续性方程分析其演化过程，使用平滑后悔匹配算法驱动具有不同初始策略的大量异质智能体。

Result: 发现了多样化多智能体环境中的关键现象：后悔分布的方差随时间减小，导致异质性消失和智能体间一致性的出现，这一普遍结果适用于竞争和合作多智能体环境。

Conclusion: 证明了系统在竞争和合作多智能体环境中都能收敛到量子响应均衡，推进了多智能体学习的理论理解，为多样化博弈论场景中的均衡选择提供了新的视角。

Abstract: Understanding and predicting the behavior of large-scale multi-agents in
games remains a fundamental challenge in multi-agent systems. This paper
examines the role of heterogeneity in equilibrium formation by analyzing how
smooth regret-matching drives a large number of heterogeneous agents with
diverse initial policies toward unified behavior. By modeling the system state
as a probability distribution of regrets and analyzing its evolution through
the continuity equation, we uncover a key phenomenon in diverse multi-agent
settings: the variance of the regret distribution diminishes over time, leading
to the disappearance of heterogeneity and the emergence of consensus among
agents. This universal result enables us to prove convergence to quantal
response equilibria in both competitive and cooperative multi-agent settings.
Our work advances the theoretical understanding of multi-agent learning and
offers a novel perspective on equilibrium selection in diverse game-theoretic
scenarios.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [171] [Assessing Medical Training Skills via Eye and Head Movements](https://arxiv.org/abs/2507.16819)
*Kayhan Latifzadeh,Luis A. Leiva,Klen Čopič Pucihar,Matjaž Kljun,Iztok Devetak,Lili Steblovnik*

Main category: cs.HC

TL;DR: 研究通过眼动和头动追踪技术来评估医疗技能发展，在模拟婴儿分娩训练中区分有经验和无经验的医护人员，为临床技能评估提供了新的计算模型方法。


<details>
  <summary>Details</summary>
Motivation: 传统的临床技能评估主要依赖主观评分方法，缺乏客观、量化的评估手段。研究者希望通过眼动和头动追踪技术开发出能够客观评估医护人员技能水平的计算模型，为临床技能培训和评估提供补充工具。

Method: 招募24名医护人员参与模拟婴儿分娩训练，使用商用眼动追踪眼镜收集数据，计算关键指标包括瞳孔反应率、注视持续时间和角速度等眼动和头动特征，然后建立计算模型来区分有经验和无经验的医护人员。

Result: 头部相关特征在区分有经验和无经验医护人员方面表现最佳，F1分数达到0.85，AUC为0.86；瞳孔相关特征的F1分数为0.77，AUC为0.85。眼动和头动追踪技术能够有效区分不同技能水平的医护人员，特别是在分娩任务中表现突出。

Conclusion: 眼动和头动追踪技术可以作为传统主观评分方法的有效补充，为临床环境中的隐性技能评估和培训提供计算模型支持。这项研究为开发基于生理信号的客观技能评估系统奠定了基础。

Abstract: We examined eye and head movements to gain insights into skill development in
clinical settings. A total of 24 practitioners participated in simulated baby
delivery training sessions. We calculated key metrics, including pupillary
response rate, fixation duration, or angular velocity. Our findings indicate
that eye and head tracking can effectively differentiate between trained and
untrained practitioners, particularly during labor tasks. For example,
head-related features achieved an F1 score of 0.85 and AUC of 0.86, whereas
pupil-related features achieved F1 score of 0.77 and AUC of 0.85. The results
lay the groundwork for computational models that support implicit skill
assessment and training in clinical settings by using commodity eye-tracking
glasses as a complementary device to more traditional evaluation methods such
as subjective scores.

</details>


### [172] [Write, Rank, or Rate: Comparing Methods for Studying Visualization Affordances](https://arxiv.org/abs/2507.17024)
*Chase Stokes,Kylie Lin,Cindy Xiong Bearfield*

Main category: cs.HC

TL;DR: 该研究探索了四种可扩展的研究方法来评估图表设计对读者解读的影响，发现排序和评分方法的组合可以有效替代劳动密集型的自由回答研究，同时测试了GPT-4o作为人类参与者代理的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统的可视化设计影响研究需要大量的众包自由回答文本分析，成本高且耗时。研究者需要找到更具可扩展性的替代方法来评估图表设计选择如何影响读者的理解和结论。

Method: 测试了四种人类受试者研究的启发方法：自由回答、可视化排序、结论排序和显著性评分。比较了这些方法在引出读者对折线图、点图和热力图解读方面的有效性。此外，还进行了GPT-4o的案例研究，探索大语言模型作为人类参与者代理的可能性。

Result: 发现虽然没有单一方法能完全复制自由回答结论中观察到的视觉功能特性，但排序和评分方法的组合可以在大规模研究中作为有效的替代方案。两种排序方法受到参与者对特定图表类型偏好的影响。评分结论显著性无法捕捉其他方法观察到的图表类型间的具体差异。GPT-4o在显著性评分方法中表现最佳，但在其他领域存在严重限制。

Conclusion: 不同启发方法（包括GPT-4o）在视觉功能特性方面存在差异，强调了有意识地选择和组合方法以及评估权衡的重要性。研究为可视化研究提供了更高效的方法论选择，但需要根据具体研究目标谨慎选择合适的方法组合。

Abstract: A growing body of work on visualization affordances highlights how specific
design choices shape reader takeaways from information visualizations. However,
mapping the relationship between design choices and reader conclusions often
requires labor-intensive crowdsourced studies, generating large corpora of
free-response text for analysis. To address this challenge, we explored
alternative scalable research methodologies to assess chart affordances. We
test four elicitation methods from human-subject studies: free response,
visualization ranking, conclusion ranking, and salience rating, and compare
their effectiveness in eliciting reader interpretations of line charts, dot
plots, and heatmaps. Overall, we find that while no method fully replicates
affordances observed in free-response conclusions, combinations of ranking and
rating methods can serve as an effective proxy at a broad scale. The two
ranking methodologies were influenced by participant bias towards certain chart
types and the comparison of suggested conclusions. Rating conclusion salience
could not capture the specific variations between chart types observed in the
other methods. To supplement this work, we present a case study with GPT-4o,
exploring the use of large language models (LLMs) to elicit human-like chart
interpretations. This aligns with recent academic interest in leveraging LLMs
as proxies for human participants to improve data collection and analysis
efficiency. GPT-4o performed best as a human proxy for the salience rating
methodology but suffered from severe constraints in other areas. Overall, the
discrepancies in affordances we found between various elicitation
methodologies, including GPT-4o, highlight the importance of intentionally
selecting and combining methods and evaluating trade-offs.

</details>


### [173] [Evaluation of the effects of frame time variation on VR task performance](https://arxiv.org/abs/2507.17139)
*Benjamin Watson,Victoria Spaulding,Neff Walker,William Ribarsky*

Main category: cs.HC

TL;DR: 研究了虚拟环境中帧时间变化对任务性能的影响，发现在可接受的帧时间范围内，较大的时间偏差不会显著影响任务性能，但在沉浸式VR的最低帧时间要求下，帧时间变化会对闭环任务性能产生显著影响。


<details>
  <summary>Details</summary>
Motivation: 虚拟环境和沉浸式应用的设计者经常需要控制帧时间变化，因为VE中图形和其他复杂性会产生大幅波动，但缺乏关于帧时间变化如何影响用户任务性能的系统性研究。

Method: 选择典型的开环和闭环任务进行实验，测试帧时间偏差幅度和波动周期对虚拟环境中任务性能的影响，涵盖当前应用中常见的任务类型以及未来可能重要的任务类型。

Result: 在许多应用认为可接受的帧时间范围内，相当大的时间偏差幅度和相当宽的周期范围不会显著影响任务性能；但在通常被认为是沉浸式VR最低要求的帧时间下，帧时间变化确实会对闭环任务性能产生显著影响。

Conclusion: 研究结果为虚拟环境和沉浸式应用的设计者提供了有用的指导，帮助他们在面对VE中复杂性大幅波动时更好地控制帧时间变化，特别是在设计需要精确交互的闭环任务时需要更加注意帧时间的稳定性。

Abstract: We present a first study of the effects of frame time variations, in both
deviation around mean frame times and period of fluctuation, on task
performance in a virtual environment (VE). Chosen are open and closed loop
tasks that are typical for current applications or likely to be prominent in
future ones. The results show that at frame times in the range deemed
acceptable for many applications, fairly large deviations in amplitude over a
fairly wide range of periods do not significantly affect task performance.
However, at a frame time often considered a minimum for immersive VR, frame
time variations do produce significant effects on closed loop task performance.
The results will be of use to designers of VEs and immersive applications, who
often must control frame time variations due to large fluctuations of
complexity (graphical and otherwise) in the VE.

</details>


### [174] [HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery](https://arxiv.org/abs/2507.17209)
*Haoran Jiang,Shaohan Shi,Yunjie Yao,Chang Jiang,Quan Li*

Main category: cs.HC

TL;DR: HypoChainer是一个协作可视化框架，结合人类专业知识、大语言模型推理和知识图谱，通过三阶段流程（探索与情境化、假设链形成、验证优先级排序）来增强科学假设的生成和验证，解决了传统研究方法的认知局限性和深度学习模型输出筛选困难的问题。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现面临整合大量异构知识的挑战，传统假设驱动研究受到人类认知局限、生物系统复杂性和高昂试错成本的制约。虽然图神经网络能加速预测生成，但大量输出使人工筛选验证变得不可扩展。大语言模型在过滤和假设生成方面有潜力，但存在幻觉问题且缺乏结构化知识基础，限制了可靠性。

Method: 提出HypoChainer协作可视化框架，分三个阶段运作：1）探索与情境化阶段：专家使用检索增强LLMs和降维技术导航大规模GNN预测，辅以交互式解释；2）假设链形成阶段：专家迭代检查预测周围的知识图谱关系和语义关联实体，通过LLM和KG建议完善假设；3）验证优先级排序阶段：基于KG支持的证据过滤精炼假设，识别高优先级实验候选，通过视觉分析进一步加强推理中的薄弱环节。

Result: 通过两个领域的案例研究和专家访谈验证了HypoChainer的有效性，展示了其在支持可解释、可扩展和基于知识的科学发现方面的潜力。该框架成功整合了人类专业知识、AI推理能力和结构化知识，为科学假设生成和验证提供了新的解决方案。

Conclusion: HypoChainer框架有效解决了现代科学发现中的关键挑战，通过人机协作的方式结合了各种AI技术的优势，为生物医学和药物开发等领域的科学发现提供了可解释、可扩展且基于知识的支持工具，具有推动科学突破的重要潜力。

Abstract: Modern scientific discovery faces growing challenges in integrating vast and
heterogeneous knowledge critical to breakthroughs in biomedicine and drug
development. Traditional hypothesis-driven research, though effective, is
constrained by human cognitive limits, the complexity of biological systems,
and the high cost of trial-and-error experimentation. Deep learning models,
especially graph neural networks (GNNs), have accelerated prediction
generation, but the sheer volume of outputs makes manual selection for
validation unscalable. Large language models (LLMs) offer promise in filtering
and hypothesis generation, yet suffer from hallucinations and lack grounding in
structured knowledge, limiting their reliability. To address these issues, we
propose HypoChainer, a collaborative visualization framework that integrates
human expertise, LLM-driven reasoning, and knowledge graphs (KGs) to enhance
hypothesis generation and validation. HypoChainer operates in three stages:
First, exploration and contextualization -- experts use retrieval-augmented
LLMs (RAGs) and dimensionality reduction to navigate large-scale GNN
predictions, assisted by interactive explanations. Second, hypothesis chain
formation -- experts iteratively examine KG relationships around predictions
and semantically linked entities, refining hypotheses with LLM and KG
suggestions. Third, validation prioritization -- refined hypotheses are
filtered based on KG-supported evidence to identify high-priority candidates
for experimentation, with visual analytics further strengthening weak links in
reasoning. We demonstrate HypoChainer's effectiveness through case studies in
two domains and expert interviews, highlighting its potential to support
interpretable, scalable, and knowledge-grounded scientific discovery.

</details>


### [175] [OceanVive: An Immersive Visualization System for Communicating Complex Oceanic Phenomena](https://arxiv.org/abs/2507.17218)
*Yang Ouyang,Yuchen Wu,Xiyuan Wang,Laixin Xie,Weicong Cheng,Jianping Gan,Quan Li,Xiaojuan Ma*

Main category: cs.HC

TL;DR: OceanVive是一个沉浸式交互可视化系统，将复杂的海洋数据集转化为可导航的空间叙事，以改善海洋科学传播效果


<details>
  <summary>Details</summary>
Motivation: 传统的静态可视化和文本报告在传达海洋变化动态（如缺氧和酸化）方面存在不足，海洋科学传播面临持续挑战

Method: 开发了OceanVive系统，结合桌面平板电脑的探索面板管理大屏幕沉浸式内容，集成自适应视觉编码、情境化叙事和直观导航路径

Result: 通过专家访谈验证了系统的有效性，展示了其在增强科学传播和促进公众深入理解方面的潜力

Conclusion: OceanVive系统能够有效支持海洋科学传播，帮助公众更好地理解复杂的海洋现象

Abstract: Communicating the complexity of oceanic phenomena-such as hypoxia and
acidification-poses a persistent challenge for marine science. Despite advances
in sensing technologies and computational models, conventional formats like
static visualizations and text-based reports often fall short in conveying the
dynamics of ocean changes. To address this gap, we present OceanVive, an
immersive and interactive visualization system that transforms complex ocean
datasets into navigable spatial narratives. OceanVive incorporates an
exploratory panel on a table-sized tablet for managing immersive content on a
large screen and integrates adaptive visual encodings, contextual storytelling,
and intuitive navigation pathways to support effective communication. We
validate the system through expert interviews, demonstrating its potential to
enhance science communication and promote deeper public understanding.

</details>


### [176] [A "watch your replay videos" reflection assignment on comparing programming without versus with generative AI: learning about programming, critical AI use and limitations, and reflection](https://arxiv.org/abs/2507.17226)
*Sarah "Magz" Fernandez,Greg L Nelson*

Main category: cs.HC

TL;DR: 研究设计了一种对比视频反思作业，让学生分别录制不使用和使用生成式AI编程的过程，然后通过结构化反思问题分析自己的编程行为，结果显示这种方法能有效提升学生的元认知技能和编程学习能力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在颠覆计算机教育，但大多数干预措施专注于教授GenAI的使用，而非帮助学生理解AI如何改变他们的编程过程。需要一种新的教学方法来帮助学生更好地理解和反思自己的编程学习过程。

Method: 设计并部署了一种基于DEAL框架（描述、检查、然后阐述学习）的新颖对比视频反思作业。在入门软件工程课程中，学生在团队项目期间录制两次编程过程：第一次不使用生成式AI，第二次使用生成式AI。然后学生使用一套结构化的反思问题分析自己的视频，包括编程过程以及人力、互联网和AI求助行为。

Result: 通过定性主题分析发现，学生在规划、调试和求助行为方面产生了超越AI使用的深刻见解。学生学会了在编写或生成代码前放慢速度并理解问题，识别了解决问题方法中的模式，并明确表达了具体的过程改进方案。学生还学习和反思了AI的局限性和缺点，以及更批判性地使用AI的策略。

Conclusion: 结构化的编程会话视频反思能够培养在使用和不使用生成式AI进行编程时都必需的元认知技能，对于在不断发展的领域中进行终身学习具有重要意义。这种对比反思方法还意外地促进了对不涉及AI使用的编程的反思，甚至让学生自发地设定未来采用视频和其他定期反思的目标。

Abstract: Generative AI is disrupting computing education. Most interventions focus on
teaching GenAI use rather than helping students understand how AI changes their
programming process. We designed and deployed a novel comparative video
reflection assignment adapting the Describe, Examine, then Articulate Learning
(DEAL) framework. In an introductory software engineering course, students
recorded themselves programming during their team project two times: first
without, then with using generative AI. Students then analyzed their own videos
using a scaffolded set of reflection questions, including on their programming
process and human, internet, and AI help-seeking. We conducted a qualitative
thematic analysis of the reflections, finding students developed insights about
planning, debugging, and help-seeking behaviors that transcended AI use.
Students reported learning to slow down and understand before writing or
generating code, recognized patterns in their problem-solving approaches, and
articulated specific process improvements. Students also learned and reflected
on AI limits and downsides, and strategies to use AI more critically, including
better prompting but also to benefit their learning instead of just completing
tasks. Unexpectedly, the comparative reflection also scaffolded reflection on
programming not involving AI use, and even led to students spontaneously
setting future goals to adopt video and other regular reflection. This work
demonstrates structured reflection on programming session videos can develop
metacognitive skills essential for programming with and without generative AI
and also lifelong learning in our evolving field.

</details>


### [177] [Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations](https://arxiv.org/abs/2507.17248)
*Xiaoan Liu,Difan Jia,Xianhao Carton Liu,Mar Gonzalez-Franco,Chen Zhu-Tian*

Main category: cs.HC

TL;DR: Reality Proxy是一个混合现实系统，通过引入代理对象（抽象表示）来解耦物理对象与交互约束，使用AI增强代理的语义属性和空间关系，实现了复杂的多对象选择和操作，无需新手势或菜单系统。


<details>
  <summary>Details</summary>
Motivation: 在混合现实中与真实世界物体交互时，当物体拥挤、距离远或部分被遮挡时往往很困难，这是因为交互直接在物理对象上进行，输入与物理约束紧密耦合。

Method: 提出Reality Proxy系统，通过引入代理对象（物理对象的抽象表示）来解耦交互与物理约束；在选择过程中将交互目标从物理对象无缝转移到其代理；使用AI为代理enrichment语义属性和层次化空间关系。

Result: 系统能够实现浏览、基于属性的过滤、嵌套组导航和复杂多对象选择等新颖交互，无需新手势或菜单系统；在办公信息检索、大规模空间导航和多无人机控制等多样化场景中验证了系统的通用性。

Conclusion: 专家评估表明该系统具有实用性和可用性，基于代理的抽象为未来混合现实系统提供了强大且可泛化的交互范式。

Abstract: Interacting with real-world objects in Mixed Reality (MR) often proves
difficult when they are crowded, distant, or partially occluded, hindering
straightforward selection and manipulation. We observe that these difficulties
stem from performing interaction directly on physical objects, where input is
tightly coupled to their physical constraints. Our key insight is to decouple
interaction from these constraints by introducing proxies-abstract
representations of real-world objects. We embody this concept in Reality Proxy,
a system that seamlessly shifts interaction targets from physical objects to
their proxies during selection. Beyond facilitating basic selection, Reality
Proxy uses AI to enrich proxies with semantic attributes and hierarchical
spatial relationships of their corresponding physical objects, enabling novel
and previously cumbersome interactions in MR - such as skimming,
attribute-based filtering, navigating nested groups, and complex multi object
selections - all without requiring new gestures or menu systems. We demonstrate
Reality Proxy's versatility across diverse scenarios, including office
information retrieval, large-scale spatial navigation, and multi-drone control.
An expert evaluation suggests the system's utility and usability, suggesting
that proxy-based abstractions offer a powerful and generalizable interaction
paradigm for future MR systems.

</details>


### [178] [Designing for Learning with Generative AI is a Wicked Problem: An Illustrative Longitudinal Qualitative Case Series](https://arxiv.org/abs/2507.17230)
*Clara Scalzer,Saurav Pokhrel,Sara Hunt,Greg L Nelson*

Main category: cs.HC

TL;DR: 研究发现在生成式AI教育中，学生的学习、技能发展、伦理意识和职业动机之间存在复杂的权衡关系，提升某一方面可能会损害其他方面，这是一个需要多维度评估和设计的"棘手问题"。


<details>
  <summary>Details</summary>
Motivation: 计算机教育者面临如何为学生准备日益受生成式AI影响的职业生涯的挑战，需要在支持学习、动机、伦理和职业发展等多个目标之间取得平衡。

Method: 采用纵向定性研究方法，对参与生成式AI集成创意媒体课程的学生进行追踪研究，分析两名学生的具体经历来展示问题的复杂性。课程包括提示工程、伦理与偏见教学以及行业专家讲座。

Result: 发现了两种矛盾模式：1）提升GenAI使用技能可能降低伦理意识（如Pat从避免使用到依赖，自称"作弊者"）；2）增强伦理意识可能阻碍技能发展（如Jay因环保担忧自我限制使用，并对职业前景产生恐惧）。GenAI熟练度的提升并未改善学生的职业信心。

Conclusion: 在生成式AI时代支持学生发展是一个"棘手问题"，需要多维度的评估和设计方法，而不是单独优化学习、GenAI技能、伦理或职业动机中的任何一个方面。

Abstract: Students continue their education when they feel their learning is meaningful
and relevant for their future careers. Computing educators now face the
challenge of preparing students for careers increasingly shaped by generative
AI (GenAI) with the goals of supporting their learning, motivation, ethics, and
career development. Our longitudinal qualitative study of students in a
GenAI-integrated creative media course shows how this is a "wicked" problem:
progress on one goal can then impede progress on other goals. Students
developed concerning patterns despite extensive instruction in critical and
ethical GenAI use including prompt engineering, ethics and bias, and industry
panels on GenAI's career impact. We present an analysis of two students'
experiences to showcase this complexity. Increasing GenAI use skills can lower
ethics; for example, Pat started from purposefully avoiding GenAI use, to
dependency. He described himself as a "notorious cheater" who now uses GenAi to
"get all the right answers" while acknowledging he's learning less. Increasing
ethical awareness can lower the learning of GenAI use skills; for example,
Jay's newfound environmental concerns led to self-imposed usage limits that
impeded skill development, and new serious fears that GenAI would eliminate
creative careers they had been passionate about. Increased GenAI proficiency, a
potential career skill, did not improve their career confidence. These findings
suggest that supporting student development in the GenAI era is a "wicked"
problem requiring multi-dimensional evaluation and design, rather than
optimizing learning, GenAI skills, ethics, or career motivation individually.

</details>


### [179] [High-Density EEG Enables the Fastest Visual Brain-Computer Interfaces](https://arxiv.org/abs/2507.17242)
*Gege Ming,Weihua Pei,Sen Tian,Xiaogang Chen,Xiaorong Gao,Yijun Wang*

Main category: cs.HC

TL;DR: 本研究提出了频率-相位-空间融合编码方法，结合256通道高密度脑电图，开发出高速脑机接口系统，在线系统实现了平均472.7 bpm的信息传输率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉脑机接口系统信息传输率不足，无法满足实际应用需求。空间信息作为视觉感知的关键组成部分，由于记录方法的空间分辨率限制，在现有系统中未得到充分利用，难以捕获大脑信号丰富的时空动态特性。

Method: 提出频率-相位-空间融合编码方法，集成256通道高密度脑电图记录技术。在经典的频率-相位编码40目标BCI范式基础上，测试了256-66、128-32、64-21等不同电极配置，并开发了频率-相位-空间编码200目标BCI范式。

Result: 在40目标BCI范式中，256-66、128-32、64-21电极配置相比传统64-9设置分别带来83.66%、79.99%、55.50%的理论信息传输率提升。在200目标BCI范式中，提升幅度分别达到195.56%、153.08%、103.07%。在线BCI系统实现平均472.7 bpm的实际信息传输率。

Conclusion: 研究证明了高密度脑电图在解码视觉刺激时空信息方面的重要作用和巨大潜力，为开发高速实用的脑机接口系统提供了新的技术途径。

Abstract: Brain-computer interface (BCI) technology establishes a direct communication
pathway between the brain and external devices. Current visual BCI systems
suffer from insufficient information transfer rates (ITRs) for practical use.
Spatial information, a critical component of visual perception, remains
underexploited in existing systems because the limited spatial resolution of
recording methods hinders the capture of the rich spatiotemporal dynamics of
brain signals. This study proposed a frequency-phase-space fusion encoding
method, integrated with 256-channel high-density electroencephalogram (EEG)
recordings, to develop high-speed BCI systems. In the classical frequency-phase
encoding 40-target BCI paradigm, the 256-66, 128-32, and 64-21 electrode
configurations brought theoretical ITR increases of 83.66%, 79.99%, and 55.50%
over the traditional 64-9 setup. In the proposed frequency-phase-space encoding
200-target BCI paradigm, these increases climbed to 195.56%, 153.08%, and
103.07%. The online BCI system achieved an average actual ITR of 472.7 bpm.
This study demonstrates the essential role and immense potential of
high-density EEG in decoding the spatiotemporal information of visual stimuli.

</details>


### [180] [EventLines: Time Compression for Discrete Event Timelines](https://arxiv.org/abs/2507.17320)
*Yuet Ling Wong,Niklas Elmqvist*

Main category: cs.HC

TL;DR: 本文提出了EventLines技术，通过动态调整时间轴来更好地可视化具有突发性特征的离散事件序列，解决了传统线性时间轴在表示聚集事件时的空间利用效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统的线性时间轴在可视化具有突发性行为的离散事件序列时存在问题：事件聚集期间区域过于拥挤，而其他时间段则空间利用不足，导致可视化效果不佳且屏幕空间使用效率低下。

Method: 提出EventLines技术，核心方法是动态调整时间尺度以匹配底层事件分布，通过时间轴的视觉表示本身来传达不同的尺度变化，从而实现更高效的屏幕空间利用。

Result: 通过众包图形感知研究，探索了不同时间尺度表示方式对时间感知的影响，验证了EventLines在处理突发性事件序列可视化方面的有效性。

Conclusion: EventLines技术成功解决了传统线性时间轴在可视化突发性事件序列时的局限性，通过非线性时间缩放和创新的视觉表示方法，实现了更高效的屏幕空间利用和更清晰的事件模式展示。

Abstract: Discrete event sequences serve as models for numerous real-world datasets,
including publications over time, project milestones, and medication dosing
during patient treatments. These event sequences typically exhibit bursty
behavior, where events cluster together in rapid succession, interspersed with
periods of inactivity. Standard timeline charts with linear time axes fail to
adequately represent such data, resulting in cluttered regions during event
bursts while leaving other areas unutilized. We introduce EventLines, a novel
technique that dynamically adjusts the time scale to match the underlying event
distribution, enabling more efficient use of screen space. To address the
challenges of non-linear time scaling, EventLines employs the time axis's
visual representation itself to communicate the varying scale. We present
findings from a crowdsourced graphical perception study that examines how
different time scale representations influence temporal perception.

</details>


### [181] [Layered Interactions: Exploring Non-Intrusive Digital Craftsmanship Design Through Lacquer Art Interfaces](https://arxiv.org/abs/2507.17430)
*Yan Dong,Hanjie Yu,Yanran Chen,Zipeng Zhang,Qiong Wu*

Main category: cs.HC

TL;DR: 本文提出了分层交互设计方法，将人机交互技术与传统漆器工艺相结合，通过在漆器层间嵌入交互电路和可编程硬件，创造出支持多样化交互的有形界面，增强了传统工艺在数字环境中的适应性。


<details>
  <summary>Details</summary>
Motivation: 数字工艺领域中，如何将技术与传统工艺的独特特征相结合已成为关键问题。传统工艺需要在现代数字环境中保持其文化价值的同时获得新的适应性和实用性。

Method: 提出分层交互（Layered Interactions）设计方法，利用漆器的多层结构和材料特性，在漆器层间嵌入交互电路和集成可编程硬件，创建支持多样化交互的有形界面。开发了漆器工具包，并通过用户实验和半结构化访谈进行验证。

Result: 该方法不仅让传统工匠更容易接触技术，还增强了交互界面的物质性和情感品质，促进了工匠与技术专家之间的相互学习与合作。实验和访谈结果验证了方法的有效性。

Conclusion: 研究为人机交互社区引入了跨学科视角，拓宽了交互界面的材料和设计可能性，为数字工艺领域的发展提供了新的思路和方法。

Abstract: Integrating technology with the distinctive characteristics of craftsmanship
has become a key issue in the field of digital craftsmanship. This paper
introduces Layered Interactions, a design approach that seamlessly merges
Human-Computer Interaction (HCI) technologies with traditional lacquerware
craftsmanship. By leveraging the multi-layer structure and material properties
of lacquerware, we embed interactive circuits and integrate programmable
hardware within the layers, creating tangible interfaces that support diverse
interactions. This method enhances the adaptability and practicality of
traditional crafts in modern digital contexts. Through the development of a
lacquerware toolkit, along with user experiments and semi-structured
interviews, we demonstrate that this approach not only makes technology more
accessible to traditional artisans but also enhances the materiality and
emotional qualities of interactive interfaces. Additionally, it fosters mutual
learning and collaboration between artisans and technologists. Our research
introduces a cross-disciplinary perspective to the HCI community, broadening
the material and design possibilities for interactive interfaces.

</details>


### [182] [SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition](https://arxiv.org/abs/2507.17524)
*Jiahao Tang,Youjun Li,Xiangting Fan,Yangxuan Zheng,Siyuan Lu,Xueping Li,Peng Fang,Chenxi Li,Zi-Gang Huang*

Main category: cs.HC

TL;DR: 提出了一种无监督的语义-动态一致性域适应网络(SDC-Net)，用于跨被试脑电情感识别，通过同被试同试次混合策略、动态分布对齐模块和双域相似性一致性学习机制，在SEED、SEED-IV和Faced数据集上实现了最先进的情感识别性能。


<details>
  <summary>Details</summary>
Motivation: 基于脑电图(EEG)的情感识别在情感脑机接口(aBCIs)中具有巨大潜力，但由于被试间变异性大和目标域缺乏标注数据，实际部署仍面临挑战。需要解决完全无标签的跨被试EEG情感识别问题。

Method: 提出SDC-Net网络，包含三个核心组件：1)同被试同试次混合策略，通过试次内插值生成增强样本；2)在再生核希尔伯特空间中构建动态分布对齐模块，联合对齐边际和条件分布；3)双域相似性一致性学习机制，基于潜在成对相似性强制跨域结构约束。

Result: 在SEED、SEED-IV和Faced三个基准数据集上进行了广泛实验，与现有无监督域适应方法相比，SDC-Net在跨被试和跨会话条件下均实现了最先进的情感识别性能，显著提高了情感解码的准确性和泛化能力。

Conclusion: SDC-Net显著改善了情感解码的准确性和泛化能力，为个性化情感脑机接口的实际应用奠定了坚实基础。该方法在无监督域适应情感识别任务中达到了最先进水平。

Abstract: Electroencephalography(EEG) based emotion recognition holds great promise for
affective brain-computer interfaces (aBCIs), yet practical deployment remains
challenging due to substantial inter-subject variability and the lack of
labeled data in target domains. To overcome these limitations, we present a
novel unsupervised Semantic-Dynamic Consistency domain adaptation network for
fully label-free cross-subject EEG emotion recognition. First, we introduce a
Same-Subject Same-Trial Mixup strategy that generates augmented samples via
intra-trial interpolation, enhancing data diversity while explicitly preserving
individual identity to mitigate label ambiguity. Second, we construct a dynamic
distribution alignment module in reproducing kernel Hilbert space (RKHS),
jointly aligning marginal and conditional distributions through multi-objective
kernel mean embedding, and leveraging a confidence-aware pseudo-labeling
strategy to ensure stable adaptation. Third, we propose a dual-domain
similarity consistency learning mechanism that enforces cross-domain structural
constraints based on latent pairwise similarities, enabling semantic boundary
learning without relying on temporal synchronization or label priors. To
validate the effectiveness and robustness of the proposed SDC-Net, extensive
experiments are conducted on three widely used EEG benchmark datasets: SEED,
SEED-IV, and Faced. Comparative results against existing unsupervised domain
adaptation methods demonstrate that SDC-Net achieves state-of-the-art
performance in emotion recognition under both cross-subject and cross-session
conditions. This advancement significantly improves the accuracy and
generalization capability of emotion decoding, and lays a solid foundation for
real-world applications of personalized affective brain-computer interfaces
(aBCIs). The source code will be released at
https://github.com/XuanSuTrum/SDC-Net.

</details>


### [183] [Anticipate, Simulate, Reason (ASR): A Comprehensive Generative AI Framework for Combating Messaging Scams](https://arxiv.org/abs/2507.17543)
*Xue Wen Tan,Kenneth See,Stanley Kok*

Main category: cs.HC

TL;DR: 本文提出了ASR（预测-模拟-推理）框架，一个基于生成式AI的方法，帮助用户主动识别和理解即时通讯平台中的诈骗信息，并开发了专门的ScamGPT-J模型


<details>
  <summary>Details</summary>
Motivation: 随着即时通讯诈骗的快速增长，用户安全和财务安全面临日益严峻的挑战，需要一种主动识别和理解诈骗的有效方法

Method: 提出ASR（Anticipate, Simulate, Reason）框架，使用大语言模型预测诈骗者响应、创建真实的诈骗对话，并提供实时可解释的支持；开发ScamGPT-J，一个在高质量诈骗对话数据集上微调的领域专用语言模型

Result: ASR框架显著提升了诈骗检测能力，特别是在工作诈骗等具有挑战性的场景中；揭示了用户脆弱性和对AI生成辅助感知的重要人口统计学模式；发现风险最高的用户往往最不愿意接受AI支持

Conclusion: 这项工作在对抗不断演变的数字威胁方面，推进了可解释的、以人为中心的AI系统的实用和理论基础，强调了在AI驱动的欺诈防护中以用户为中心设计的重要性

Abstract: The rapid growth of messaging scams creates an escalating challenge for user
security and financial safety. In this paper, we present the Anticipate,
Simulate, Reason (ASR) framework, a generative AI method that enables users to
proactively identify and comprehend scams within instant messaging platforms.
Using large language models, ASR predicts scammer responses, creates realistic
scam conversations, and delivers real-time, interpretable support to end-users.
We develop ScamGPT-J, a domain-specific language model fine-tuned on a new,
high-quality dataset of scam conversations covering multiple scam types.
Thorough experimental evaluation shows that the ASR framework substantially
enhances scam detection, particularly in challenging contexts such as job
scams, and uncovers important demographic patterns in user vulnerability and
perceptions of AI-generated assistance. Our findings reveal a contradiction
where those most at risk are often least receptive to AI support, emphasizing
the importance of user-centered design in AI-driven fraud prevention. This work
advances both the practical and theoretical foundations for interpretable,
human-centered AI systems in combating evolving digital threats.

</details>


### [184] [Explainable AI for Collaborative Assessment of 2D/3D Registration Quality](https://arxiv.org/abs/2507.17597)
*Sue Min Cho,Alexander Do,Russell H. Taylor,Mathias Unberath*

Main category: cs.HC

TL;DR: 该研究提出了首个专门用于2D/3D配准质量验证的人工智能框架，结合可解释性特征帮助手术操作员检测配准错误，通过四种条件对比评估发现可解释AI能提升用户信任度但整体性能未超过单独AI系统。


<details>
  <summary>Details</summary>
Motivation: 随着手术数字化转型，2D/3D配准成为图像引导手术导航的关键技术，但配准算法偶尔会产生不准确结果，即使微小的配准错误也可能导致翻修手术或不可逆的手术错误。当前基于可视化的策略无法让人类可靠地检测配准错误，因此需要强有力的质量保证机制。

Method: 开发了首个专门针对2D/3D配准质量验证的人工智能框架，增加了可解释性特征来阐明模型的决策过程。通过算法中心和人本中心的评估方法，系统性地比较了四种条件：仅AI、仅人类、人类-AI协作、人类-可解释AI协作。

Result: 研究发现可解释性特征能够适度提升用户信任度和纠正AI错误的意愿，但在整体性能上并未超过单独的AI系统。四种条件的对比评估为理解人机协作在医疗质量保证中的作用提供了重要见解。

Conclusion: 虽然当前的可解释AI方法在整体性能上未超越单独AI系统，但未来在算法设计和人类-可解释AI协作要素方面的扩展工作有望实现更强大的2D/3D配准质量保证，为手术安全提供更可靠的保障。

Abstract: As surgery embraces digital transformation--integrating sophisticated
imaging, advanced algorithms, and robotics to support and automate complex
sub-tasks--human judgment of system correctness remains a vital safeguard for
patient safety. This shift introduces new "operator-type" roles tasked with
verifying complex algorithmic outputs, particularly at critical junctures of
the procedure, such as the intermediary check before drilling or implant
placement. A prime example is 2D/3D registration, a key enabler of image-based
surgical navigation that aligns intraoperative 2D images with preoperative 3D
data. Although registration algorithms have advanced significantly, they
occasionally yield inaccurate results. Because even small misalignments can
lead to revision surgery or irreversible surgical errors, there is a critical
need for robust quality assurance. Current visualization-based strategies alone
have been found insufficient to enable humans to reliably detect 2D/3D
registration misalignments. In response, we propose the first artificial
intelligence (AI) framework trained specifically for 2D/3D registration quality
verification, augmented by explainability features that clarify the model's
decision-making. Our explainable AI (XAI) approach aims to enhance informed
decision-making for human operators by providing a second opinion together with
a rationale behind it. Through algorithm-centric and human-centered
evaluations, we systematically compare four conditions: AI-only, human-only,
human-AI, and human-XAI. Our findings reveal that while explainability features
modestly improve user trust and willingness to override AI errors, they do not
exceed the standalone AI in aggregate performance. Nevertheless, future work
extending both the algorithmic design and the human-XAI collaboration elements
holds promise for more robust quality assurance of 2D/3D registration.

</details>


### [185] [Mindfulness Meditation and Respiration: Accelerometer-Based Respiration Rate and Mindfulness Progress Estimation to Enhance App Engagement and Mindfulness Skills](https://arxiv.org/abs/2507.17688)
*Mohammad Nur Hossain Khan,David creswell,Jordan Albert,Patrick O'Connell,Shawn Fallon,Mathew Polowitz,Xuhai "orson" Xu,Bashima islam*

Main category: cs.HC

TL;DR: 本研究开发了基于智能手机加速度计的呼吸追踪算法和正念技能评估框架，通过生物信号反馈提升数字正念训练的用户体验和技能发展效果。


<details>
  <summary>Details</summary>
Motivation: 数字正念应用虽然让冥想训练更易获得，但维持用户长期参与仍是挑战。研究者希望通过呼吸生物信号反馈和正念技能评估来增强系统可用性和技能发展效果。

Method: 开发基于智能手机加速度计的呼吸追踪算法，无需额外可穿戴设备；创建首个基于加速度计呼吸数据的正念技能量化评估框架，评估专注力、感知清晰度和平静心三个维度；在261个正念训练会话中测试算法，包括对照和真实环境。

Result: 呼吸追踪模型达到1.6次/分钟的平均绝对误差，与真实数据高度吻合；正念技能评估在追踪技能进展方面达到80-84%的F1分数；用户研究显示呼吸反馈组相比标准应用对照组在系统可用性方面有显著提升。

Conclusion: 通过将呼吸追踪和正念评估集成到商业应用中，证明了智能手机传感器在增强数字正念训练方面的潜力，为提高用户参与度和训练效果提供了有效解决方案。

Abstract: Mindfulness training is widely recognized for its benefits in reducing
depression, anxiety, and loneliness. With the rise of smartphone-based
mindfulness apps, digital meditation has become more accessible, but sustaining
long-term user engagement remains a challenge. This paper explores whether
respiration biosignal feedback and mindfulness skill estimation enhance system
usability and skill development. We develop a smartphone's accelerometer-based
respiration tracking algorithm, eliminating the need for additional wearables.
Unlike existing methods, our approach accurately captures slow breathing
patterns typical of mindfulness meditation. Additionally, we introduce the
first quantitative framework to estimate mindfulness skills-concentration,
sensory clarity, and equanimity-based on accelerometer-derived respiration
data. We develop and test our algorithms on 261 mindfulness sessions in both
controlled and real-world settings. A user study comparing an experimental
group receiving biosignal feedback with a control group using a standard app
shows that respiration feedback enhances system usability. Our respiration
tracking model achieves a mean absolute error (MAE) of 1.6 breaths per minute,
closely aligning with ground truth data, while our mindfulness skill estimation
attains F1 scores of 80-84% in tracking skill progression. By integrating
respiration tracking and mindfulness estimation into a commercial app, we
demonstrate the potential of smartphone sensors to enhance digital mindfulness
training.

</details>


### [186] [DataWink: Reusing and Adapting SVG-based Visualization Examples with Large Multimodal Models](https://arxiv.org/abs/2507.17734)
*Liwenhan Xie,Yanna Lin,Can Liu,Huamin Qu,Xinhuan Shu*

Main category: cs.HC

TL;DR: DataWink是一个通过改编高质量示例来帮助用户创建自定义数据可视化的系统，利用大型多模态模型从SVG可视化示例中提取数据编码，通过对话代理和交互界面让用户能够修改数据映射和视觉设计元素，同时保持原始可视化的美学质量。


<details>
  <summary>Details</summary>
Motivation: 为缺乏设计专业知识或可视化工具使用经验的用户创建美观的数据可视化仍然具有挑战性，需要一个能够降低可视化创建门槛、使其民主化的解决方案。

Method: 结合大型多模态模型(LMMs)从现有基于SVG的可视化示例中提取数据编码，采用连接原始SVG和可视化程序的中间表示形式，通过对话代理让用户表达改编目标，并通过按需生成的控件来控制视觉外观，提供交互界面让用户修改数据映射和视觉设计元素。

Result: 通过用户研究(N=12)包含复制和自由探索任务的评估显示，DataWink在可学习性和个性化创作任务的有效性方面得到认可，证明了示例驱动方法在可视化创建民主化方面的潜力。

Conclusion: DataWink系统成功展示了基于示例驱动的方法在降低数据可视化创建门槛方面的有效性，为可视化创建的民主化提供了有前景的解决方案，使没有专业设计背景的用户也能够创建高质量的个性化数据可视化。

Abstract: Creating aesthetically pleasing data visualizations remains challenging for
users without design expertise or familiarity with visualization tools. To
address this gap, we present DataWink, a system that enables users to create
custom visualizations by adapting high-quality examples. Our approach combines
large multimodal models (LMMs) to extract data encoding from existing SVG-based
visualization examples, featuring an intermediate representation of
visualizations that bridges primitive SVG and visualization programs. Users may
express adaptation goals to a conversational agent and control the visual
appearance through widgets generated on demand. With an interactive interface,
users can modify both data mappings and visual design elements while
maintaining the original visualization's aesthetic quality. To evaluate
DataWink, we conduct a user study (N=12) with replication and free-form
exploration tasks. As a result, DataWink is recognized for its learnability and
effectiveness in personalized authoring tasks. Our results demonstrate the
potential of example-driven approaches for democratizing visualization
creation.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [187] [Fractional Spike Differential Equations Neural Network with Efficient Adjoint Parameters Training](https://arxiv.org/abs/2507.16937)
*Chengjie Ge,Yufeng Peng,Xueyang Fu,Qiyu Kang,Xuhao Li,Qixin Zhang,Junhao Ren,Zheng-Jun Zha*

Main category: cs.NE

TL;DR: 提出了分数阶脉冲微分方程神经网络(fspikeDE)，通过分数阶动力学捕获膜电压和脉冲序列中的长期依赖关系，相比传统脉冲神经网络在准确性、能效和鲁棒性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统脉冲神经网络假设单一时间常数的神经元膜电压动力学，使用一阶常微分方程建模，具有马尔可夫特性，电压状态仅依赖于前一时刻值，限制了网络表达能力。而真实神经元表现出受长期相关性和分形树突结构影响的复杂动力学，呈现非马尔可夫行为。

Method: 提出分数阶脉冲微分方程神经网络(fspikeDE)，通过分数阶动力学捕获膜电压和脉冲序列中的长期依赖关系。为高效训练fspikeDE，引入梯度下降算法，通过伴随敏感性方法求解增广分数阶常微分方程来优化参数。

Result: 在多种图像和图数据集上的广泛实验表明，fspikeDE始终优于传统脉冲神经网络，实现了更高的准确性、相当的能效、更少的训练内存使用量以及增强的抗噪声鲁棒性。

Conclusion: 该方法为分数阶脉冲神经网络提供了新颖的开源计算工具箱，广泛适用于各种现实世界任务，通过分数阶动力学实现了比整数阶模型更强的时间模式表达能力。

Abstract: Spiking Neural Networks (SNNs) draw inspiration from biological neurons to
create realistic models for brain-like computation, demonstrating effectiveness
in processing temporal information with energy efficiency and biological
realism. Most existing SNNs assume a single time constant for neuronal membrane
voltage dynamics, modeled by first-order ordinary differential equations (ODEs)
with Markovian characteristics. Consequently, the voltage state at any time
depends solely on its immediate past value, potentially limiting network
expressiveness. Real neurons, however, exhibit complex dynamics influenced by
long-term correlations and fractal dendritic structures, suggesting
non-Markovian behavior. Motivated by this, we propose the Fractional SPIKE
Differential Equation neural network (fspikeDE), which captures long-term
dependencies in membrane voltage and spike trains through fractional-order
dynamics. These fractional dynamics enable more expressive temporal patterns
beyond the capability of integer-order models. For efficient training of
fspikeDE, we introduce a gradient descent algorithm that optimizes parameters
by solving an augmented fractional-order ODE (FDE) backward in time using
adjoint sensitivity methods. Extensive experiments on diverse image and graph
datasets demonstrate that fspikeDE consistently outperforms traditional SNNs,
achieving superior accuracy, comparable energy efficiency, reduced training
memory usage, and enhanced robustness against noise. Our approach provides a
novel open-sourced computational toolbox for fractional-order SNNs, widely
applicable to various real-world tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [188] [Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development](https://arxiv.org/abs/2507.16839)
*Gregory Beale,Gibran Ali*

Main category: cs.RO

TL;DR: 本文提出了一种处理大规模自然驾驶研究数据的方法，用于分析五种车辆指标的驾驶行为，并开发了交互式在线分析工具来可视化和比较不同群体的驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 为了通过描述标准化驾驶行为来辅助车辆安全和智能交通系统的开发，需要一种有效的方法来处理和分析大规模自然驾驶研究数据，并能够根据道路特征、车辆类别和驾驶员人口统计学特征来进行情境化分析。

Method: 使用SHRP 2自然驾驶研究数据（包含超过3400名驾驶员的3400万英里驾驶数据），通过车辆、GPS和前置雷达数据生成五种驾驶指标（速度、超速、车道保持、跟车距离和车头时距）的摘要，并开发交互式在线分析工具来实现动态数据选择和分组的可视化比较。

Result: 研究发现在65英里/小时道路上，16-19岁女性驾驶员超速（7.5-15英里/小时）的频率略高于同龄男性驾驶员，年轻驾驶员保持1.5秒以下车头时距的频率比年长驾驶员更高。成功开发了支持跨群体比较的分析工具。

Conclusion: 该工作通过量化标准化驾驶行为支持了更好的车辆系统和更安全的基础设施建设，并为分析自然驾驶研究数据集进行跨群体比较提供了有效的方法论。

Abstract: This paper presents a methodology to process large-scale naturalistic driving
studies (NDS) to describe the driving behavior for five vehicle metrics,
including speed, speeding, lane keeping, following distance, and headway,
contextualized by roadway characteristics, vehicle classes, and driver
demographics. Such descriptions of normative driving behaviors can aid in the
development of vehicle safety and intelligent transportation systems. The
methodology is demonstrated using data from the Second Strategic Highway
Research Program (SHRP 2) NDS, which includes over 34 million miles of driving
across more than 3,400 drivers. Summaries of each driving metric were generated
using vehicle, GPS, and forward radar data. Additionally, interactive online
analytics tools were developed to visualize and compare driving behavior across
groups through dynamic data selection and grouping. For example, among drivers
on 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit
by 7.5 to 15 mph slightly more often than their male counterparts, and younger
drivers maintained headways under 1.5 seconds more frequently than older
drivers. This work supports better vehicle systems and safer infrastructure by
quantifying normative driving behaviors and offers a methodology for analyzing
NDS datasets for cross group comparisons.

</details>


### [189] [AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens](https://arxiv.org/abs/2507.16841)
*Waseem Akram,Muhayy Ud Din,Abdelhaleem Saad,Irfan Hussain*

Main category: cs.RO

TL;DR: 本文提出了AquaChat，一个集成大语言模型的智能水下机器人框架，用于水产养殖网箱的自适应检查，通过自然语言交互实现更灵活高效的检查操作。


<details>
  <summary>Details</summary>
Motivation: 传统的水产养殖网箱检查方法依赖预编程任务或人工控制，对动态水下环境和用户特定需求的适应性有限，缺乏灵活性和智能化程度。

Method: 设计了AquaChat多层架构框架：(1)高级规划层使用大语言模型解释自然语言用户命令并生成符号化任务计划；(2)中级任务管理器将计划转换为ROV控制序列；(3)低级运动控制层精确执行导航和检查任务。系统具备实时反馈和事件触发重规划功能。

Result: 在仿真和受控水环境中进行了验证实验，结果表明系统在任务灵活性、检查精度和操作效率方面均有显著改善。

Conclusion: AquaChat展示了将基于语言的人工智能与海洋机器人技术相结合的潜力，能够实现智能化、用户交互式的检查系统，为可持续水产养殖操作提供支持。

Abstract: Inspection of aquaculture net pens is essential for maintaining the
structural integrity, biosecurity, and operational efficiency of fish farming
systems. Traditional inspection approaches rely on pre-programmed missions or
manual control, offering limited adaptability to dynamic underwater conditions
and user-specific demands. In this study, we propose AquaChat, a novel Remotely
Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs)
for intelligent and adaptive net pen inspection. The system features a
multi-layered architecture: (1) a high-level planning layer that interprets
natural language user commands using an LLM to generate symbolic task plans;
(2) a mid-level task manager that translates plans into ROV control sequences;
and (3) a low-level motion control layer that executes navigation and
inspection tasks with precision. Real-time feedback and event-triggered
replanning enhance robustness in challenging aquaculture environments. The
framework is validated through experiments in both simulated and controlled
aquatic environments representative of aquaculture net pens. Results
demonstrate improved task flexibility, inspection accuracy, and operational
efficiency. AquaChat illustrates the potential of integrating language-based AI
with marine robotics to enable intelligent, user-interactive inspection systems
for sustainable aquaculture operations.

</details>


### [190] [Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning](https://arxiv.org/abs/2507.16842)
*Yinan Meng,Kun Qian,Jiong Yang,Renbo Su,Zhenhong Li,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 本文提出了一种传感器空间模仿学习运动学控制(SS-ILKC)框架，通过双重学习策略解决软体机械手在执行器饱和和环境约束下的鲁棒控制问题，并实现了零样本的仿真到现实迁移。


<details>
  <summary>Details</summary>
Motivation: 冗余软体机械手具有内在柔顺性和高自由度，能够实现安全交互和灵活任务执行，但其有效的运动学控制极具挑战性。主要问题包括：需要处理未知外部载荷引起的变形，避免因不当零空间调节导致的执行器饱和，特别是在受限环境中的控制难题。

Method: 提出SS-ILKC框架，采用双重学习策略：(1)基于强化学习原理的多目标传感器空间控制框架，在仿真中训练以开发开放空间的鲁棒控制策略；(2)生成对抗模仿学习方法，从稀疏专家演示中学习受限空间的有效策略。同时提出预处理的仿真到现实迁移机制，以减轻仿真与现实差距并准确表征执行器饱和限制。

Result: 实验结果表明，该方法能够有效控制气动软体机械手，在未知载荷条件下的受限环境中实现精确的路径跟踪和物体操作。方法实现了零样本的真实世界部署。

Conclusion: SS-ILKC框架成功解决了软体机械手在复杂环境约束和执行器限制下的控制问题，通过结合强化学习和模仿学习的双重策略，以及有效的仿真到现实迁移机制，实现了在未知载荷和受限空间中的鲁棒控制性能。

Abstract: The intrinsic compliance and high degree of freedom (DoF) of redundant soft
manipulators facilitate safe interaction and flexible task execution. However,
effective kinematic control remains highly challenging, as it must handle
deformations caused by unknown external loads and avoid actuator saturation due
to improper null-space regulation - particularly in confined environments. In
this paper, we propose a Sensor-Space Imitation Learning Kinematic Control
(SS-ILKC) framework to enable robust kinematic control under actuator
saturation and restrictive environmental constraints. We employ a dual-learning
strategy: a multi-goal sensor-space control framework based on reinforcement
learning principle is trained in simulation to develop robust control policies
for open spaces, while a generative adversarial imitation learning approach
enables effective policy learning from sparse expert demonstrations for
confined spaces. To enable zero-shot real-world deployment, a pre-processed
sim-to-real transfer mechanism is proposed to mitigate the
simulation-to-reality gap and accurately characterize actuator saturation
limits. Experimental results demonstrate that our method can effectively
control a pneumatically actuated soft manipulator, achieving precise
path-following and object manipulation in confined environments under unknown
loading conditions.

</details>


### [191] [Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates](https://arxiv.org/abs/2507.16846)
*Qing Tang,Xianbiao Hu*

Main category: cs.RO

TL;DR: 本文提出了一种自动驾驶车辆高速公路汇流控制的分析方法，通过动态规划模型同时优化交通效率和安全性，在汇流点推导出考虑多阶段动态汇流过程的有效排放率闭式公式。


<details>
  <summary>Details</summary>
Motivation: 传统的汇流排队模型基于需求-供给交互且假设固定容量，但实际观察显示汇流处的流量率在拥堵时会因交叉交通影响而下降，这一因素在基本图中被忽略。需要开发新的分析方法来表征和控制自动驾驶车辆的动态多阶段汇流过程。

Method: 首次通过闭式公式分析推导汇流点的有效排放率，该排放率受多阶段动态汇流过程影响而降低。基于此表达式推导队列长度和交通延误等性能指标作为第一目标，建立碰撞风险函数定量评估汇流过程中的潜在碰撞作为第二目标。将问题建模为动态规划模型，以汇流位置和速度为决策变量，联合最小化延误和碰撞风险。采用逆向归纳法求解最小成本方案。

Result: 使用NGSIM数据集验证了推导的有效排放率。数值实验结果表明，所提出的模型优于两种基准算法，实现了更高效和更安全的汇流过程。

Conclusion: 本文成功建立了考虑多阶段动态汇流过程影响的分析框架，通过动态规划方法实现了交通效率和安全性的联合优化，为自动驾驶车辆高速公路汇流控制提供了新的理论基础和实用解决方案。

Abstract: The core of the freeway merging control problem lies in dynamic queue
propagation and dissipation linked to merging vehicle behavior. Traditionally,
queuing is modeled through demand-supply interactions with time varying demand
and fixed capacity. However, field observations show flow rates decrease during
congestion at freeway merges due to the impact of intersecting traffic, a
factor overlooked in fundamental diagrams. This manuscript introduces an
analytical approach to characterize and control the dynamic multi-stage merging
of autonomous vehicles, prioritizing traffic efficiency and safety. For the
first time, the effective discharge rate at the merging point, reduced by the
multi-stage dynamic merging process, is analytically derived using a closed
form formulation. Leveraging this expression, performance metrics such as queue
length and traffic delay are derived as the first objective. Additionally, a
crash risk function is established to quantitatively assess potential
collisions during the merging process, serving as the second objective.
Finally, the problem is formulated as a dynamic programming model to jointly
minimize delay and crash risk, with the merging location and speed as decision
variables. Given the terminal state, the ramp vehicle merging task is
formulated as a recursive optimization problem, employing backward induction to
find the minimum cost solution. Numerical experiments using the NGSIM dataset
validate the derived effective discharge rate. The results indicate that the
proposed model outperforms two benchmark algorithms, leading to a more
efficient and safer merging process.

</details>


### [192] [MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation](https://arxiv.org/abs/2507.16853)
*Ning Li,Xiangmou Qu,Jiamu Zhou,Jun Wang,Muning Wen,Kounianhua Du,Xingyu Lou,Qiuying Peng,Jun Wang,Weinan Zhang*

Main category: cs.RO

TL;DR: 本文提出了MobileUse，一个用于移动设备自动化任务执行的GUI智能体，通过分层反思架构和主动探索模块解决了长序列任务执行、错误恢复和冷启动问题，在AndroidWorld和AndroidLab基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在移动设备真实场景应用中面临三大挑战：长序列任务执行困难、错误恢复能力不足，以及在陌生环境中的冷启动问题。这些问题限制了移动智能体在复杂任务自动化中的实际应用效果。

Method: 提出MobileUse框架，包含两个核心模块：1）分层反思架构，能够在多个时间尺度上进行自我监控、错误检测和恢复，从单个动作到整体任务完成，并采用按需反思策略保持效率；2）主动探索模块，通过自主规划的探索来丰富智能体对环境的理解，解决冷启动问题。

Result: 在AndroidWorld和AndroidLab基准测试中，MobileUse达到了新的最先进性能，成功率分别为62.9%和44.2%。同时发布了一个开箱即用的工具包，支持在物理移动设备上进行自动化任务执行。

Conclusion: MobileUse通过创新的分层反思架构和主动探索机制，有效解决了移动智能体在实际应用中的关键挑战，显著提升了长序列任务的执行成功率和环境适应性，为移动设备自动化开辟了新的可能性。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled the
development of mobile agents that can understand visual inputs and follow user
instructions, unlocking new possibilities for automating complex tasks on
mobile devices. However, applying these models to real-world mobile scenarios
remains a significant challenge due to the long-horizon task execution,
difficulty in error recovery, and the cold-start problem in unfamiliar
environments. To address these challenges, we propose MobileUse, a GUI agent
designed for robust and adaptive mobile task execution. To improve resilience
in long-horizon tasks and dynamic environments, we introduce a hierarchical
reflection architecture that enables the agent to self-monitor, detect, and
recover from errors across multiple temporal scales-ranging from individual
actions to overall task completion-while maintaining efficiency through a
reflection-on-demand strategy. To tackle cold-start issues, we further
introduce a proactive exploration module, which enriches the agent's
understanding of the environment through self-planned exploration. Evaluations
on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse
establishes new state-of-the-art performance, achieving success rates of 62.9%
and 44.2%, respectively. To facilitate real-world applications, we release an
out-of-the-box toolkit for automated task execution on physical mobile devices,
which is available at https://github.com/MadeAgents/mobile-use.

</details>


### [193] [Leveraging multi-source and heterogeneous signals for fatigue detection](https://arxiv.org/abs/2507.16859)
*Luobin Cui,Yanlai Wu,Tang Ying,Weikai Li*

Main category: cs.RO

TL;DR: 本文提出了一个异构多源疲劳检测框架，能够在传感器受限的真实环境中有效检测疲劳，通过利用来自不同传感器配置源域的知识来提高目标域的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有疲劳检测方法依赖高端传感器和受控环境，在真实世界应用中存在局限性。航空、采矿、长途运输等安全关键应用需要能够在传感器受限场景下工作的实用疲劳检测系统。

Method: 提出异构多源疲劳检测框架，该框架能够自适应地利用目标域中可用的传感器模态，同时从源域的多样化传感器配置中获益，实现跨域知识迁移。

Result: 在真实部署的传感器设置和两个公开数据集上的实验表明，该方法具有实用性、鲁棒性，并改善了泛化能力，在传感器受限场景下实现了有效的疲劳监测。

Conclusion: 该框架为在传感器受限的真实环境中进行有效疲劳监测铺平了实用道路，解决了现有方法在真实世界应用中的局限性问题。

Abstract: Fatigue detection plays a critical role in safety-critical applications such
as aviation, mining, and long-haul transport. However, most existing methods
rely on high-end sensors and controlled environments, limiting their
applicability in real world settings. This paper formally defines a practical
yet underexplored problem setting for real world fatigue detection, where
systems operating with context-appropriate sensors aim to leverage knowledge
from differently instrumented sources including those using impractical sensors
deployed in controlled environments. To tackle this challenge, we propose a
heterogeneous and multi-source fatigue detection framework that adaptively
utilizes the available modalities in the target domain while benefiting from
the diverse configurations present in source domains. Our experiments,
conducted using a realistic field-deployed sensor setup and two publicly
available datasets, demonstrate the practicality, robustness, and improved
generalization of our approach, paving the practical way for effective fatigue
monitoring in sensor-constrained scenarios.

</details>


### [194] [ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry](https://arxiv.org/abs/2507.16865)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Huiru Zheng,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种基于ResChebyKAN骨干网络和EKSA模块的惯性定位方法，通过切比雪夫多项式建模复杂运动模式，在多个公开数据集上显著降低了轨迹误差


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的惯性定位方法难以捕获IMU数据中的非线性运动特征和长期依赖关系，限制了定位精度的提升

Method: 提出ResChebyKAN作为通用骨干网络，利用切比雪夫多项式的非线性逼近能力建模复杂运动模式；引入高效核自注意力(EKSA)模块捕获上下文信息并增强长期依赖建模

Result: 在RIDI、RoNIN、RNIN-VIO、OxIOD、IMUNet和TLIO等公开数据集上，相比现有基准方法，绝对轨迹误差降低了3.79%到42.32%；实验还显示从加速度数据中去除重力分量能显著提升定位性能

Conclusion: ResChebyKAN网络结合EKSA模块能够有效建模IMU数据的非线性特征和长期依赖，显著提升惯性定位精度，为低成本精确定位提供了新的解决方案

Abstract: Inertial Measurement Unit (IMU) has become a key technology for achieving
low-cost and precise positioning. However, traditional CNN-based inertial
positioning methods struggle to capture the nonlinear motion characteristics
and long-term dependencies in IMU data. To address this limitation, we propose
a novel inertial positioning network with a generic backbone called
ResChebyKAN, which leverages the nonlinear approximation capabilities of
Chebyshev polynomials to model complex motion patterns. Additionally, we
introduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively
capture contextual information and enhance long-term dependency modeling.
Experimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD,
IMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory
error by 3.79% to 42.32% compared to existing benchmark methods. Furthermore,
we release a preprocessed dataset and empirically show that removing the
gravity component from acceleration data significantly improves inertial
positioning performance.

</details>


### [195] [Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection](https://arxiv.org/abs/2507.16941)
*Daniel Correa,Tero Kaarlela,Jose Fuentes,Paulo Padrao,Alain Duran,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习环境，用于开发自主水下机器人珊瑚采样智能体，结合数字孪生仿真训练和水下动作捕捉系统验证，实现了零样本仿真到现实的迁移策略。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁保护和研究需要自主水下机器人进行珊瑚采样，这是一项关键但具有挑战性的任务，需要开发能够在复杂水下环境中精确操作的AI控制器。

Method: 采用软件在环(SIL)和硬件在环(HIL)方法，在通用游戏引擎构建的数字孪生仿真环境中使用深度强化学习训练AI控制器，并结合水下动作捕捉(MOCAP)系统提供实时3D位置和姿态反馈进行验证。

Result: 成功开发了RL训练的AI控制器，在仿真中完成训练后能够在物理实验中得到验证，实现了数字域和物理域之间的精确同步。

Conclusion: 通过结合通用游戏引擎仿真、深度强化学习和实时水下动作捕捉技术，成功实现了有效的零样本仿真到现实迁移策略，为水下机器人珊瑚采样任务提供了创新解决方案。

Abstract: This paper presents a reinforcement learning (RL) environment for developing
an autonomous underwater robotic coral sampling agent, a crucial coral reef
conservation and research task. Using software-in-the-loop (SIL) and
hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI)
controller is developed using a digital twin (DT) in simulation and
subsequently verified in physical experiments. An underwater motion capture
(MOCAP) system provides real-time 3D position and orientation feedback during
verification testing for precise synchronization between the digital and
physical domains. A key novelty of this approach is the combined use of a
general-purpose game engine for simulation, deep RL, and real-time underwater
motion capture for an effective zero-shot sim-to-real strategy.

</details>


### [196] [RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics](https://arxiv.org/abs/2507.16988)
*Maaz Qureshi,Mohammad Omid Bagheri,Abdelrahman Elbadrawy,William Melek,George Shaker*

Main category: cs.RO

TL;DR: 本文提出了RAPTAR系统，一个基于协作机器人的便携式自主系统，用于测量集成雷达模块的3D辐射模式，无需专用消声室设施


<details>
  <summary>Details</summary>
Motivation: 现有探针台技术在表征现代片上天线时存在角度覆盖有限、依赖定制硬件、需要频繁手动对准等挑战，且传统测量设置在车辆、无人机、AR/VR头戴设备、生物医学设备等真实配置中不实用

Method: 设计了基于7自由度Franka协作机器人的RAPTAR系统，机器人持有接收探针，通过实时运动规划在半球空间域进行无碰撞操作，校准精度RMS误差低于0.9mm，角度分辨率达2.5度，与RF仪器无缝集成进行近场和远场功率测量

Result: 对60GHz雷达模块的实验扫描显示，与全波电磁仿真基准相比，平均绝对误差小于2dB；与基线方法对比，平均绝对误差降低36.5%，展现了RAPTAR的精度和重复性

Conclusion: RAPTAR系统成功解决了集成雷达模块在复杂真实环境中的3D辐射模式测量问题，提供了便携、精确、自主的测量解决方案，显著提高了测量精度和效率

Abstract: Accurate characterization of modern on-chip antennas remains challenging, as
current probe-station techniques offer limited angular coverage, rely on
bespoke hardware, and require frequent manual alignment. This research
introduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a
portable, state-of-the-art, and autonomous system based on collaborative
robotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar
modules without dedicated anechoic facilities. The system is designed to
address the challenges of testing radar modules mounted in diverse real-world
configurations, including vehicles, UAVs, AR/VR headsets, and biomedical
devices, where traditional measurement setups are impractical. A
7-degree-of-freedom Franka cobot holds the receiver probe and performs
collision-free manipulation across a hemispherical spatial domain, guided by
real-time motion planning and calibration accuracy with RMS error below 0.9 mm.
The system achieves an angular resolution upto 2.5 degree and integrates
seamlessly with RF instrumentation for near- and far-field power measurements.
Experimental scans of a 60 GHz radar module show a mean absolute error of less
than 2 dB compared to full-wave electromagnetic simulations ground truth.
Benchmarking against baseline method demonstrates 36.5% lower mean absolute
error, highlighting RAPTAR accuracy and repeatability.

</details>


### [197] [Shared Control of Holonomic Wheelchairs through Reinforcement Learning](https://arxiv.org/abs/2507.17055)
*Jannis Bähler,Diego Paez-Granados,Jorge Peña-Queralta*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的智能电动轮椅共享控制方法，将2D用户输入转换为3D运动，实现了首个全向移动平台的强化学习共享控制真实世界应用


<details>
  <summary>Details</summary>
Motivation: 现有的全向系统共享控制方法往往导致用户体验不直观，无法充分利用全向驾驶的潜力，因此需要开发一种能够提高用户舒适度并减少驾驶员认知负荷的智能控制方法

Method: 采用强化学习方法，接收2D用户输入并输出3D运动控制；在Isaac Gym中训练模型，在Gazebo仿真环境中测试；比较不同的强化学习智能体架构和奖励函数设计

Result: 实现了无碰撞导航，智能调整轮椅朝向，在平滑性方面与非学习方法相比表现更好或具有竞争力；成功完成了从仿真到真实环境的迁移，实现了首个全向移动平台的强化学习共享控制真实世界应用

Conclusion: 提出的强化学习共享控制方法能够有效提升智能电动轮椅的用户体验，确保安全导航的同时提高用户舒适度并降低认知负荷，为全向移动平台的智能控制提供了新的解决方案

Abstract: Smart electric wheelchairs can improve user experience by supporting the
driver with shared control. State-of-the-art work showed the potential of
shared control in improving safety in navigation for non-holonomic robots.
However, for holonomic systems, current approaches often lead to unintuitive
behavior for the user and fail to utilize the full potential of omnidirectional
driving. Therefore, we propose a reinforcement learning-based method, which
takes a 2D user input and outputs a 3D motion while ensuring user comfort and
reducing cognitive load on the driver. Our approach is trained in Isaac Gym and
tested in simulation in Gazebo. We compare different RL agent architectures and
reward functions based on metrics considering cognitive load and user comfort.
We show that our method ensures collision-free navigation while smartly
orienting the wheelchair and showing better or competitive smoothness compared
to a previous non-learning-based method. We further perform a sim-to-real
transfer and demonstrate, to the best of our knowledge, the first real-world
implementation of RL-based shared control for an omnidirectional mobility
platform.

</details>


### [198] [Deformable Cluster Manipulation via Whole-Arm Policy Learning](https://arxiv.org/abs/2507.17085)
*Jayadeep Jacob,Wenzheng Zhang,Houston Warren,Paulo Borges,Tirthankar Bandyopadhyay,Fabio Ramos*

Main category: cs.RO

TL;DR: 本文提出了一个结合3D点云和本体感受触觉指示器的无模型强化学习框架，用于操控可变形物体集群，特别是在电力线清理场景中实现了从仿真到现实的零样本策略迁移。


<details>
  <summary>Details</summary>
Motivation: 操控可变形物体集群是一个具有广泛适用性的重大挑战，需要接触丰富的全臂交互。现有方法在真实模型合成能力有限、感知不确定性高、缺乏高效空间抽象等方面存在问题，因此需要一个能够处理这些挑战的新框架。

Method: 提出了一个整合3D点云和本体感受触觉指示器两种模态的无模型策略学习框架，强调具有全身接触感知的操作方式。采用分布式状态表示和核均值嵌入的强化学习框架来提高训练效率和实时推理能力，并提出了一种新颖的上下文无关遮挡启发式方法来清理目标区域的可变形物体。

Result: 在电力线清理场景中部署该框架，观察到智能体能够生成利用多个手臂链节进行去遮挡的创造性策略。成功实现了零样本仿真到现实的策略迁移，使机械臂能够清理具有未知遮挡模式、未见拓扑结构和不确定动力学的真实树枝。

Conclusion: 该框架成功解决了可变形物体集群操控的关键挑战，通过多模态感知和分布式状态表示实现了高效的策略学习，并在实际应用中展现了良好的泛化能力和零样本迁移性能。

Abstract: Manipulating clusters of deformable objects presents a substantial challenge
with widespread applicability, but requires contact-rich whole-arm
interactions. A potential solution must address the limited capacity for
realistic model synthesis, high uncertainty in perception, and the lack of
efficient spatial abstractions, among others. We propose a novel framework for
learning model-free policies integrating two modalities: 3D point clouds and
proprioceptive touch indicators, emphasising manipulation with full body
contact awareness, going beyond traditional end-effector modes. Our
reinforcement learning framework leverages a distributional state
representation, aided by kernel mean embeddings, to achieve improved training
efficiency and real-time inference. Furthermore, we propose a novel
context-agnostic occlusion heuristic to clear deformables from a target region
for exposure tasks. We deploy the framework in a power line clearance scenario
and observe that the agent generates creative strategies leveraging multiple
arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy
transfer, allowing the arm to clear real branches with unknown occlusion
patterns, unseen topology, and uncertain dynamics.

</details>


### [199] [MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments](https://arxiv.org/abs/2507.17130)
*Seokhwan Jeong,Hogyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 本文提出了一种基于球形目标的LiDAR-相机外参标定方法，专门针对多机器人系统的户外环境，能够处理目标和传感器的损坏情况。


<details>
  <summary>Details</summary>
Motivation: 在户外多机器人系统中，LiDAR和相机的外参标定面临目标损坏和传感器噪声的挑战，需要一种鲁棒的标定方法来处理这些实际应用中的问题。

Method: 从图像中提取2D椭圆中心，从点云中提取3D球心，然后配对计算变换矩阵。使用SAM模型分解图像，设计新算法从可能损坏的球体中提取椭圆，并修正透视投影误差。对于LiDAR点云，采用分层加权求和处理噪声点云以准确提取球体。

Result: 实验证明该方法在两种损坏情况下都能鲁棒地检测球体，性能优于其他目标。使用三种不同类型的LiDAR（旋转式、固态、非重复式）和三个不同位置的相机进行了验证，并在行星测试和野外环境中验证了对目标损坏的鲁棒性。

Conclusion: 提出的球形目标标定方法在处理目标和传感器损坏方面表现出色，适用于户外多机器人系统的LiDAR-相机外参标定，具有良好的鲁棒性和实用性。

Abstract: This paper presents a novel spherical target-based LiDAR-camera extrinsic
calibration method designed for outdoor environments with multi-robot systems,
considering both target and sensor corruption. The method extracts the 2D
ellipse center from the image and the 3D sphere center from the pointcloud,
which are then paired to compute the transformation matrix. Specifically, the
image is first decomposed using the Segment Anything Model (SAM). Then, a novel
algorithm extracts an ellipse from a potentially corrupted sphere, and the
extracted center of ellipse is corrected for errors caused by the perspective
projection model. For the LiDAR pointcloud, points on the sphere tend to be
highly noisy due to the absence of flat regions. To accurately extract the
sphere from these noisy measurements, we apply a hierarchical weighted sum to
the accumulated pointcloud. Through experiments, we demonstrated that the
sphere can be robustly detected even under both types of corruption,
outperforming other targets. We evaluated our method using three different
types of LiDARs (spinning, solid-state, and non-repetitive) with cameras
positioned in three different locations. Furthermore, we validated the
robustness of our method to target corruption by experimenting with spheres
subjected to various types of degradation. These experiments were conducted in
both a planetary test and a field environment. Our code is available at
https://github.com/sparolab/MARSCalib.

</details>


### [200] [Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot](https://arxiv.org/abs/2507.17132)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文基于蚂蚁腿部结构设计了建筑机器人腿部结构，提出了新的结构优化方法，通过拉格朗日动力学建模和几何参数优化，实现了关节扭矩和能耗降低超过20%，为重载高性能建筑机器人设计提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 建筑行业快速发展带来了恶劣工作环境、高强度高风险任务和劳动力短缺等问题，这推动了对低能耗、高机动性和高负载能力建筑机器人的需求，因此需要设计和优化建筑机器人的腿部结构以提升其动态性能。

Method: 首先基于自然界蚂蚁的腿部构型设计机器人腿部结构；其次提出新的结构优化方法，使用拉格朗日方法建立腿部动力学模型；将动力学模型与腿部运动轨迹结合，制定多个动态评估指标，对各腿段几何参数进行综合优化研究；最后使用ADAMS进行动力学仿真实验验证。

Result: 优化后的腿部结构将峰值关节扭矩和能耗降低了超过20%；ADAMS动力学仿真实验显示优化后各关节的驱动功率显著降低，验证了所提策略的有效性和合理性。

Conclusion: 本研究为重载、高性能建筑机器人的设计提供了理论基础和技术支持，所提出的基于仿生结构和动力学优化的腿部设计方法能够有效提升建筑机器人的动态性能并降低能耗。

Abstract: With the rapid development of the construction industry, issues such as harsh
working environments, high-intensity and high-risk tasks, and labor shortages
have become increasingly prominent. This drives higher demands for construction
robots in terms of low energy consumption, high mobility, and high load
capacity. This paper focuses on the design and optimization of leg structures
for construction robots, aiming to improve their dynamic performance, reduce
energy consumption, and enhance load-bearing capabilities. Firstly, based on
the leg configuration of ants in nature, we design a structure for the robot's
leg. Secondly, we propose a novel structural optimization method. Using the
Lagrangian approach, a dynamic model of the leg was established. Combining the
dynamic model with the leg's motion trajectory, we formulated multiple dynamic
evaluation metrics and conducted a comprehensive optimization study on the
geometric parameters of each leg segment. The results show that the optimized
leg structure reduces peak joint torques and energy consumption by over 20%.
Finally, dynamic simulation experiments were conducted using ADAMS. The results
demonstrate a significant reduction in the driving power of each joint after
optimization, validating the effectiveness and rationality of the proposed
strategy. This study provides a theoretical foundation and technical support
for the design of heavy-load, high-performance construction robots.

</details>


### [201] [Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm](https://arxiv.org/abs/2507.17136)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Wei Feng*

Main category: cs.RO

TL;DR: 本文设计了用于幕墙安装的液压驱动机械臂，并提出了动态参数识别方法，通过D-H模型和Stribeck摩擦模型构建复合参数系统，实现高精度动态参数识别，提升幕墙安装作业的智能化水平。


<details>
  <summary>Details</summary>
Motivation: 传统建筑施工方法无法满足现代对效率和质量的需求，幕墙安装作为建筑项目的关键组成部分，需要更智能化的解决方案来提高安装精度和效率。

Method: 建立基于测量机械臂结构参数的D-H模型，集成液压缸动力学构建由Stribeck摩擦模型驱动的复合参数系统；设计高信噪比位移激励信号并结合傅里叶级数构建满足关节约束的最优激励轨迹；提出分层递进参数识别策略，采用最小二乘估计分别识别和联合标定液压缸和机械臂的动态参数。

Result: 在机械臂平台上的实验验证显示，理论与测量关节扭矩之间的残差标准偏差低于0.4 Nm，证实了液压驱动幕墙安装机械臂的高精度动态参数识别，并获得了各关节的Stribeck模型曲线。

Conclusion: 成功实现了液压驱动幕墙安装机械臂的高精度动态参数识别，显著提升了幕墙安装作业的智能化水平，为建筑行业的自动化和智能化发展提供了重要技术支撑。

Abstract: In the construction industry, traditional methods fail to meet the modern
demands for efficiency and quality. The curtain wall installation is a critical
component of construction projects. We design a hydraulically driven robotic
arm for curtain wall installation and a dynamic parameter identification
method. We establish a Denavit-Hartenberg (D-H) model based on measured robotic
arm structural parameters and integrate hydraulic cylinder dynamics to
construct a composite parametric system driven by a Stribeck friction model. By
designing high-signal-to-noise ratio displacement excitation signals for
hydraulic cylinders and combining Fourier series to construct optimal
excitation trajectories that satisfy joint constraints, this method effectively
excites the characteristics of each parameter in the minimal parameter set of
the dynamic model of the robotic arm. On this basis, a hierarchical progressive
parameter identification strategy is proposed: least squares estimation is
employed to separately identify and jointly calibrate the dynamic parameters of
both the hydraulic cylinder and the robotic arm, yielding Stribeck model curves
for each joint. Experimental validation on a robotic arm platform demonstrates
residual standard deviations below 0.4 Nm between theoretical and measured
joint torques, confirming high-precision dynamic parameter identification for
the hydraulic-driven curtain wall installation robotic arm. This significantly
contributes to enhancing the intelligence level of curtain wall installation
operations.

</details>


### [202] [Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation](https://arxiv.org/abs/2507.17140)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文提出了一种用于幕墙安装的机械臂多目标轨迹优化方法，设计了集成串联、并联和折叠臂元素的机械臂，并开发了NSGA-III-FO算法来解决复杂建筑环境中的多目标约束问题。


<details>
  <summary>Details</summary>
Motivation: 在劳动力短缺和成本上升的背景下，建筑机器人被视为改革传统建筑方法、提高建筑行业效率和质量的关键。传统的单目标轨迹优化方法难以满足复杂多变建筑环境的复杂要求，因此需要开发多目标轨迹优化方法来确保建筑机器人能够在复杂建筑环境中高效准确地执行任务。

Method: 首先设计了一个用于幕墙安装的机械臂，集成了串联、并联和折叠臂元素，同时考虑其物理特性和运动特征。然后提出了NSGA-III-FO算法（带有聚焦算子的NSGA-III），该算法融合了聚焦算子筛选机制，加速算法向帕累托前沿收敛，从而有效平衡建筑机器人的多目标约束。

Result: 在DTLZ3和WFG3测试函数上进行的十次连续试验中，NSGA-III-FO算法与NSGA-III、MOEA/D和MSOPS-II相比，显示出明显更好的收敛效率。在设计的机械臂平台上进行的两组实验证实了NSGA-III-FO算法在解决幕墙安装任务多目标轨迹规划问题方面的效率和实用性。

Conclusion: 研究成功开发了适用于幕墙安装的机械臂多目标轨迹优化方法，NSGA-III-FO算法在收敛效率方面优于现有算法，实验验证了该方法在实际幕墙安装任务中的有效性和实用性，为建筑机器人在复杂环境中的应用提供了有效解决方案。

Abstract: In the context of labor shortages and rising costs, construction robots are
regarded as the key to revolutionizing traditional construction methods and
improving efficiency and quality in the construction industry. In order to
ensure that construction robots can perform tasks efficiently and accurately in
complex construction environments, traditional single-objective trajectory
optimization methods are difficult to meet the complex requirements of the
changing construction environment. Therefore, we propose a multi-objective
trajectory optimization for the robotic arm used in the curtain wall
installation. First, we design a robotic arm for curtain wall installation,
integrating serial, parallel, and folding arm elements, while considering its
physical properties and motion characteristics. In addition, this paper
proposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO)
that incorporates a focus operator screening mechanism to accelerate the
convergence of the algorithm towards the Pareto front, thereby effectively
balancing the multi-objective constraints of construction robots. The proposed
algorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive
trials on the DTLZ3 and WFG3 test functions, showing significantly better
convergence efficiency than the other algorithms. Finally, we conduct two sets
of experiments on the designed robotic arm platform, which confirm the
efficiency and practicality of the NSGA-III-FO algorithm in solving
multi-objective trajectory planning problems for curtain wall installation
tasks.

</details>


### [203] [Towards Human-level Intelligence via Human-like Whole-Body Manipulation](https://arxiv.org/abs/2507.17141)
*Guang Gao,Jianan Wang,Jinbo Zuo,Junnan Jiang,Jingfan Zhang,Xianwen Zeng,Yuejiang Zhu,Lianyang Ma,Ke Chen,Minhua Sheng,Ruirui Zhang,Zhaohui An*

Main category: cs.RO

TL;DR: Astribot Suite是一个面向通用日常任务的全身机器人操控学习套件，通过安全的机器人硬件、直观的全身遥操作接口和从人类演示中学习全身视觉运动策略的算法，实现了需要全身协调、广泛可达性、人类级灵巧性和敏捷性的多种活动。


<details>
  <summary>Details</summary>
Motivation: 构建通用智能机器人是机器人学的基本目标。现有方法面临三个核心挑战：(1)设计具有人类级物理能力的安全机器人硬件；(2)开发用于数据收集的直观可扩展全身遥操作接口；(3)创建能够从人类演示中学习全身视觉运动策略的算法。需要一个统一的框架来解决这些挑战。

Method: 提出Astribot Suite机器人学习套件，采用模仿人类进化轨迹的方法，通过与环境的持续交互学习，早期进展由模仿人类行为驱动。该套件整合了三个关键组件：安全的机器人硬件设计、直观的全身遥操作数据收集接口，以及从人类演示中学习全身视觉运动策略的算法。

Result: 系统在需要全身协调、广泛可达性、人类级灵巧性和敏捷性的广泛活动中展现了有效性。Astribot实现了embodiment（具身化）、遥操作接口和学习流水线的cohesive integration（内聚集成），在多样化环境中完成通用日常任务方面取得了显著进展。

Conclusion: Astribot Suite的embodiment、遥操作接口和学习流水线的cohesive integration标志着向真实世界通用全身机器人操控迈出的重要一步，为下一代智能机器人奠定了基础。该工作证明了通过统一框架解决机器人学习三大核心挑战的可行性。

Abstract: Building general-purpose intelligent robots has long been a fundamental goal
of robotics. A promising approach is to mirror the evolutionary trajectory of
humans: learning through continuous interaction with the environment, with
early progress driven by the imitation of human behaviors. Achieving this goal
presents three core challenges: (1) designing safe robotic hardware with
human-level physical capabilities; (2) developing an intuitive and scalable
whole-body teleoperation interface for data collection; and (3) creating
algorithms capable of learning whole-body visuomotor policies from human
demonstrations. To address these challenges in a unified framework, we propose
Astribot Suite, a robot learning suite for whole-body manipulation aimed at
general daily tasks across diverse environments. We demonstrate the
effectiveness of our system on a wide range of activities that require
whole-body coordination, extensive reachability, human-level dexterity, and
agility. Our results show that Astribot's cohesive integration of embodiment,
teleoperation interface, and learning pipeline marks a significant step towards
real-world, general-purpose whole-body robotic manipulation, laying the
groundwork for the next generation of intelligent robots.

</details>


### [204] [Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning](https://arxiv.org/abs/2507.17144)
*Kazuki Numazato,Keiichiro Kan,Masaki Kitagawa,Yunong Li,Johannes Kubel,Moju Zhao*

Main category: cs.RO

TL;DR: 本研究首次实现了扑翼无人机与人类的接触式交互，提出了一种类似鹰猎术的交互系统，让扑翼无人机能够安全地降落在人类手掌上。


<details>
  <summary>Details</summary>
Motivation: 扑翼无人机因其仿生飞行特性受到关注，具有低噪音和柔性机翼等人性化特点，适合人机交互。然而，很少有研究探索人类与扑翼无人机的实际交互。受鹰猎术启发，将人体视为动态降落平台，可应用于拥挤或空间受限的环境中。

Method: 设计了一种轨迹规划方法，同时考虑人类安全的物理和心理因素，如无人机的速度和与用户的距离。使用商业扑翼平台实现运动规划，并进行实验评估手掌降落性能和安全性。

Result: 实验结果表明，该方法能够实现安全、平稳的手掌降落交互。成功演示了扑翼无人机在人类手掌上的降落动作。

Conclusion: 这是首次实现扑翼无人机与人类之间基于接触的交互，为人机交互领域开辟了新的可能性，特别是在需要近距离、安全交互的应用场景中。

Abstract: Flapping-wing drones have attracted significant attention due to their
biomimetic flight. They are considered more human-friendly due to their
characteristics such as low noise and flexible wings, making them suitable for
human-drone interactions. However, few studies have explored the practical
interaction between humans and flapping-wing drones. On establishing a physical
interaction system with flapping-wing drones, we can acquire inspirations from
falconers who guide birds of prey to land on their arms. This interaction
interprets the human body as a dynamic landing platform, which can be utilized
in various scenarios such as crowded or spatially constrained environments.
Thus, in this study, we propose a falconry-like interaction system in which a
flapping-wing drone performs a palm landing motion on a human hand. To achieve
a safe approach toward humans, we design a trajectory planning method that
considers both physical and psychological factors of the human safety such as
the drone's velocity and distance from the user. We use a commercial flapping
platform with our implemented motion planning and conduct experiments to
evaluate the palm landing performance and safety. The results demonstrate that
our approach enables safe and smooth hand landing interactions. To the best of
our knowledge, it is the first time to achieve a contact-based interaction
between flapping-wing drones and humans.

</details>


### [205] [JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction](https://arxiv.org/abs/2507.17152)
*Fangze Lin,Ying He,Fei Yu,Hong Zhang*

Main category: cs.RO

TL;DR: 本文提出了一个名为JAM的两阶段多智能体交互预测框架，通过分类感知的边际提议和关键点引导的联合预测来解决自动驾驶中低概率模式生成质量差的问题，在Waymo数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体联合预测中低概率模式生成质量差的挑战，这是自动驾驶中预测道路参与者未来运动的关键问题。

Method: 提出两阶段框架JAM：第一阶段是边际预测过程，按轨迹类型对查询进行分类以学习所有轨迹类别；第二阶段是联合预测过程，结合场景上下文和第一阶段的边际提议学习最终联合分布，并引入关键路径点来指导联合预测模块。

Result: 在Waymo开放运动数据集的交互预测基准上进行了广泛实验，方法取得了竞争力的性能，在框架比较实验中JAM超越了其他预测框架，在交互轨迹预测中达到了最先进的性能。

Conclusion: JAM框架有效解决了多智能体联合预测中的低质量生成问题，通过两阶段设计和关键点引导实现了交互轨迹预测的最先进性能，为自动驾驶中的运动预测提供了有效解决方案。

Abstract: Predicting the future motion of road participants is a critical task in
autonomous driving. In this work, we address the challenge of low-quality
generation of low-probability modes in multi-agent joint prediction. To tackle
this issue, we propose a two-stage multi-agent interactive prediction framework
named \textit{keypoint-guided joint prediction after classification-aware
marginal proposal} (JAM). The first stage is modeled as a marginal prediction
process, which classifies queries by trajectory type to encourage the model to
learn all categories of trajectories, providing comprehensive mode information
for the joint prediction module. The second stage is modeled as a joint
prediction process, which takes the scene context and the marginal proposals
from the first stage as inputs to learn the final joint distribution. We
explicitly introduce key waypoints to guide the joint prediction module in
better capturing and leveraging the critical information from the initial
predicted trajectories. We conduct extensive experiments on the real-world
Waymo Open Motion Dataset interactive prediction benchmark. The results show
that our approach achieves competitive performance. In particular, in the
framework comparison experiments, the proposed JAM outperforms other prediction
frameworks and achieves state-of-the-art performance in interactive trajectory
prediction. The code is available at https://github.com/LinFunster/JAM to
facilitate future research.

</details>


### [206] [The Wilhelm Tell Dataset of Affordance Demonstrations](https://arxiv.org/abs/2507.17401)
*Rachel Ringe,Mihai Pomarlan,Nikolaos Tsiogkas,Stefano De Giorgis,Maria Hedblom,Rainer Malaka*

Main category: cs.RO

TL;DR: 本文提出了一个新的视频数据集，用于训练机器人识别家庭环境中的物体可供性（affordances），包含第一人称和第三人称视角的任务演示视频，旨在帮助机器人更好地理解人类环境中的行动可能性。


<details>
  <summary>Details</summary>
Motivation: 现有的可供性学习方法主要基于静态图像或形状的标注数据进行训练，缺乏动态的、真实的人类任务演示。机器人在人类环境中操作需要感知环境和物体提供的行动可能性，因此需要更丰富的训练数据来识别可供性的表现形式。

Method: 构建了一个包含常见家庭任务的视频序列数据集，从第一人称和第三人称视角记录任务演示，并提供关于任务中体现的可供性的元数据。数据收集来自多个参与者，总共记录了约七小时的人类活动，涵盖了任务执行的多样性和准备性操作。

Result: 成功构建了一个新颖的可供性学习数据集，包含多角度的视频演示和相应的可供性元数据。数据集记录了约七小时的人类活动，涵盖了不同参与者的任务执行方式，还包括了人们为完成任务而进行的准备性操作，如任务空间的安排。

Conclusion: 该数据集为训练感知系统识别可供性表现提供了宝贵资源，不仅包含了丰富的任务演示视频，还记录了任务准备阶段的行为，这对于协作服务机器人的发展具有重要意义。通过多样化的任务执行方式，该数据集有助于机器人更好地理解和适应人类环境中的各种情况。

Abstract: Affordances - i.e. possibilities for action that an environment or objects in
it provide - are important for robots operating in human environments to
perceive. Existing approaches train such capabilities on annotated static
images or shapes. This work presents a novel dataset for affordance learning of
common household tasks. Unlike previous approaches, our dataset consists of
video sequences demonstrating the tasks from first- and third-person
perspectives, along with metadata about the affordances that are manifested in
the task, and is aimed towards training perception systems to recognize
affordance manifestations. The demonstrations were collected from several
participants and in total record about seven hours of human activity. The
variety of task performances also allows studying preparatory maneuvers that
people may perform for a task, such as how they arrange their task space, which
is also relevant for collaborative service robots.

</details>


### [207] [Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints](https://arxiv.org/abs/2507.17163)
*Botao Lin,Shuang Song,Jiaole Wang*

Main category: cs.RO

TL;DR: 本文提出了一种配备创新可锁定关节的可重构腱驱动机器人(RTR)，通过选择性激活目标机器人段来消除段间耦合，仅用6个电机实现7关节机器人的精确控制和复杂环境操作。


<details>
  <summary>Details</summary>
Motivation: 传统腱驱动机器人虽然具有大工作空间和良好机动性，但增加机器人段数会引入严重的段间耦合问题，需要复杂的模型和更多电机来实现精确控制，这限制了其实际应用。

Method: 设计了配备可锁定关节的可重构腱驱动机器人，每个关节状态(锁定/自由)可通过一对拮抗腱独立控制，无需持续供电维持状态。操作员可选择性激活目标机器人段，从根本上消除段间耦合，避免复杂的协调控制需求。建立了RTR的运动学和静力学模型。

Result: 通过仿真比较了RTR与传统TDR的工作空间，RTR显示出明显优势。使用7关节RTR原型进行了验证实验和演示，证明了其可重构性和在复杂环境中的运动能力，仅使用包含6个电机的执行器包即可实现控制。

Conclusion: 可重构腱驱动机器人通过创新的可锁定关节设计，成功解决了传统腱驱动机器人的段间耦合问题，在减少电机数量的同时提高了控制精度和操作灵活性，为复杂环境中的机器人应用提供了新的解决方案。

Abstract: With a slender redundant body, the tendon-driven robot (TDR) has a large
workspace and great maneuverability while working in complex environments. TDR
comprises multiple independently controlled robot segments, each with a set of
driving tendons. While increasing the number of robot segments enhances
dexterity and expands the workspace, this structural expansion also introduces
intensified inter-segmental coupling. Therefore, achieving precise TDR control
requires more complex models and additional motors. This paper presents a
reconfigurable tendon-driven robot (RTR) equipped with innovative lockable
joints. Each joint's state (locked/free) can be individually controlled through
a pair of antagonistic tendons, and its structure eliminates the need for a
continuous power supply to maintain the state. Operators can selectively
actuate the targeted robot segments, and this scheme fundamentally eliminates
the inter-segmental coupling, thereby avoiding the requirement for complex
coordinated control between segments. The workspace of RTR has been simulated
and compared with traditional TDRs' workspace, and RTR's advantages are further
revealed. The kinematics and statics models of the RTR have been derived and
validation experiments have been conducted. Demonstrations have been performed
using a seven-joint RTR prototype to show its reconfigurability and moving
ability in complex environments with an actuator pack comprising only six
motors.

</details>


### [208] [FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second](https://arxiv.org/abs/2507.17210)
*Chunran Zheng,Fu Zhang*

Main category: cs.RO

TL;DR: 本文提出了FAST-Calib，一种基于定制3D标靶的快速用户友好的LiDAR-相机外参标定工具，支持机械式和固态LiDAR，具有高精度和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR-相机外参标定方法存在精度不足、速度较慢或对不同LiDAR扫描模式适应性差的问题，需要一种快速、准确且通用的标定解决方案

Method: 设计定制3D标靶，开发与LiDAR扫描模式无关的高效边缘提取算法，通过椭圆拟合补偿LiDAR光斑扩散导致的边缘扩张伪影，支持多场景联合优化

Result: 在三种LiDAR模型（Ouster、Avia、Mid360）上验证，点对点配准误差均低于6.5mm，总处理时间不到0.7秒，相比现有方法展现出更优的精度和鲁棒性

Conclusion: FAST-Calib提供了一个高效、准确且基于标靶的自动标定流程，已开源代码和数据集，为机器人学社区提供了实用的LiDAR-相机标定解决方案

Abstract: This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera
extrinsic calibration tool based on a custom-made 3D target. FAST-Calib
supports both mechanical and solid-state LiDARs by leveraging an efficient and
reliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It
also compensates for edge dilation artifacts caused by LiDAR spot spread
through ellipse fitting, and supports joint optimization across multiple
scenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and
Mid360), each paired with a wide-angle camera. Experimental results demonstrate
superior accuracy and robustness compared to existing methods. With
point-to-point registration errors consistently below 6.5mm and total
processing time under 0.7s, FAST-Calib provides an efficient, accurate, and
target-based automatic calibration pipeline. We have open-sourced our code and
dataset on GitHub to benefit the robotics community.

</details>


### [209] [Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology](https://arxiv.org/abs/2507.17253)
*Maharshi Shastri,Ujjval Shrivastav*

Main category: cs.RO

TL;DR: 本研究开发了一个AI集成的无人机配送系统，采用YOLOv4 Tiny进行物体检测，结合GPS导航和实时通信模块，解决最后一公里配送问题，在配送时间、准确性和安全性方面相比传统地面物流有显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着对快速且经济高效的最后一公里配送解决方案需求不断增长，需要开发先进的无人机物流系统来满足现代配送要求，同时解决电池效率、监管合规和安全考虑等关键挑战。

Method: 采用YOLOv4 Tiny轻量级模型进行物体检测，使用NEO 6M GPS模块实现导航，A7670 SIM模块提供实时通信；通过机器学习技术、物联网设备和加密协议的集成来解决系统挑战；进行轻量级AI模型和硬件组件的对比分析以确定最优配置。

Result: 初步研究显示相比传统地面物流在配送时间方面有所改善，通过人脸识别实现高准确度的收件人身份验证；系统在路径优化、物体检测、安全包裹处理和实时跟踪方面表现良好。

Conclusion: 该AI集成无人机配送系统在技术可行性和实用性方面显示出良好前景，同时考虑了伦理影响和社会接受度，确保符合FAA、EASA和DGCA等监管标准，为无人机物流领域提供了有价值的解决方案架构。

Abstract: The increasing demand for fast and cost effective last mile delivery
solutions has catalyzed significant advancements in drone based logistics. This
research describes the development of an AI integrated drone delivery system,
focusing on route optimization, object detection, secure package handling, and
real time tracking. The proposed system leverages YOLOv4 Tiny for object
detection, the NEO 6M GPS module for navigation, and the A7670 SIM module for
real time communication. A comparative analysis of lightweight AI models and
hardware components is conducted to determine the optimal configuration for
real time UAV based delivery. Key challenges including battery efficiency,
regulatory compliance, and security considerations are addressed through the
integration of machine learning techniques, IoT devices, and encryption
protocols. Preliminary studies demonstrate improvement in delivery time
compared to conventional ground based logistics, along with high accuracy
recipient authentication through facial recognition. The study also discusses
ethical implications and societal acceptance of drone deliveries, ensuring
compliance with FAA, EASA and DGCA regulatory standards. Note: This paper
presents the architecture, design, and preliminary simulation results of the
proposed system. Experimental results, simulation benchmarks, and deployment
statistics are currently being acquired. A comprehensive analysis will be
included in the extended version of this work.

</details>


### [210] [Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning](https://arxiv.org/abs/2507.17275)
*Po-Yen Wu,Cheng-Yu Kuo,Yuki Kadokawa,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习框架，通过将工具寿命作为策略优化的考虑因素，使机器人学会既能完成任务又能延长工具使用寿命的策略。该方法在仿真和实际环境中都能有效延长工具寿命（仿真中最高达8.01倍）。


<details>
  <summary>Details</summary>
Motivation: 在不可达环境中，机器人常使用通用工具但缺乏预定义使用策略，工具寿命对使用方式高度敏感。如何让机器人学会既完成任务又延长工具寿命的策略是一个根本性挑战。

Method: 引入强化学习框架，将工具寿命纳入策略优化；利用有限元分析(FEA)和Miner定律基于累积应力估计剩余使用寿命(RUL)；将RUL集成到RL奖励中指导策略学习；提出自适应奖励归一化(ARN)机制动态调整奖励尺度，确保稳定的学习信号。

Result: 在仿真和实际工具使用任务（包括物体移动和开门任务）中验证了方法的有效性。学习到的策略能持续延长工具寿命（仿真中最高达8.01倍），并能有效迁移到实际环境中。

Conclusion: 该方法成功解决了机器人在使用通用工具时平衡任务完成和工具寿命延长的挑战，展示了学习寿命导向工具使用策略的实用价值，为机器人在复杂环境中的可持续工具使用提供了有效解决方案。

Abstract: In inaccessible environments with uncertain task demands, robots often rely
on general-purpose tools that lack predefined usage strategies. These tools are
not tailored for particular operations, making their longevity highly sensitive
to how they are used. This creates a fundamental challenge: how can a robot
learn a tool-use policy that both completes the task and prolongs the tool's
lifespan? In this work, we address this challenge by introducing a
reinforcement learning (RL) framework that incorporates tool lifespan as a
factor during policy optimization. Our framework leverages Finite Element
Analysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based
on accumulated stress, and integrates the RUL into the RL reward to guide
policy learning toward lifespan-guided behavior. To handle the fact that RUL
can only be estimated after task execution, we introduce an Adaptive Reward
Normalization (ARN) mechanism that dynamically adjusts reward scaling based on
estimated RULs, ensuring stable learning signals. We validate our method across
simulated and real-world tool use tasks, including Object-Moving and
Door-Opening with multiple general-purpose tools. The learned policies
consistently prolong tool lifespan (up to 8.01x in simulation) and transfer
effectively to real-world settings, demonstrating the practical value of
learning lifespan-guided tool use strategies.

</details>


### [211] [VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback](https://arxiv.org/abs/2507.17294)
*Jianxin Bi,Kevin Yuchen Ma,Ce Hao,Mike Zheng Shou,Harold Soh*

Main category: cs.RO

TL;DR: VLA-Touch是一种无需微调基础VLA模型就能为通用机器人策略增加触觉感知能力的方法，通过预训练的触觉-语言模型和基于扩散的控制器实现双层次触觉反馈集成。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作(VLA)模型缺乏解释和使用触觉信号的能力，这限制了它们在接触丰富任务中的有效性。由于缺乏大型多模态数据集，将触觉反馈整合到这些系统中具有挑战性。

Method: 提出VLA-Touch方法，包含两个关键创新：(1)利用预训练触觉-语言模型为高级任务规划提供语义触觉反馈的管道；(2)基于扩散的控制器，使用触觉信号细化VLA生成的动作以进行接触丰富的操作。

Result: 通过真实世界实验证明，双层次触觉反馈集成提高了任务规划效率，同时增强了执行精度。

Conclusion: VLA-Touch成功地在不微调基础VLA模型的情况下，通过双层次触觉反馈集成显著改善了机器人在接触丰富任务中的表现，为机器人触觉感知提供了有效的解决方案。

Abstract: Tactile feedback is generally recognized to be crucial for effective
interaction with the physical world. However, state-of-the-art
Vision-Language-Action (VLA) models lack the ability to interpret and use
tactile signals, limiting their effectiveness in contact-rich tasks.
Incorporating tactile feedback into these systems is challenging due to the
absence of large multi-modal datasets. We present VLA-Touch, an approach that
enhances generalist robot policies with tactile sensing \emph{without
fine-tuning} the base VLA. Our method introduces two key innovations: (1) a
pipeline that leverages a pretrained tactile-language model that provides
semantic tactile feedback for high-level task planning, and (2) a
diffusion-based controller that refines VLA-generated actions with tactile
signals for contact-rich manipulation. Through real-world experiments, we
demonstrate that our dual-level integration of tactile feedback improves task
planning efficiency while enhancing execution precision. Code is open-sourced
at \href{https://github.com/jxbi1010/VLA-Touch}{this URL}.

</details>


### [212] [HuNavSim 2.0](https://arxiv.org/abs/2507.17317)
*Miguel Escudero-Jiménez,Noé Pérez-Higueras,Andrés Martínez-Silva,Fernando Caballero,Luis Merino*

Main category: cs.RO

TL;DR: 该论文介绍了人类导航模拟器(HuNavSim)的新版本，这是一个开源工具，用于模拟移动机器人场景中不同的人-智能体导航行为，基于ROS 2框架开发，可与Gazebo或NVidia Isaac Sim等机器人仿真器配合使用。


<details>
  <summary>Details</summary>
Motivation: 为了促进人机感知机器人导航系统在仿真环境中的开发和评估，需要一个能够模拟复杂且真实的人类导航行为的工具。

Method: 开发了基于ROS 2框架的人类导航模拟器(HuNavSim)，该工具可以与多种知名的机器人仿真器(如Gazebo和NVidia Isaac Sim)集成使用，并通过行为树(Behavior Trees)组合扩展的动作和条件集合来构建复杂的人类行为。

Result: 新版本的HuNavSim改进了多项功能并添加了新特性，特别是扩展了可在行为树中组合的动作和条件集合，能够构建更加复杂和真实的人类行为模式。

Conclusion: HuNavSim作为一个开源仿真工具，为人机感知机器人导航系统的开发和评估提供了有效的平台，通过其增强的功能和与主流仿真器的兼容性，能够更好地支持复杂人类导航行为的建模。

Abstract: This work presents a new iteration of the Human Navigation Simulator
(HuNavSim), a novel open-source tool for the simulation of different
human-agent navigation behaviors in scenarios with mobile robots. The tool,
programmed under the ROS 2 framework, can be used together with different
well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main
goal is to facilitate the development and evaluation of human-aware robot
navigation systems in simulation. In this new version, several features have
been improved and new ones added, such as the extended set of actions and
conditions that can be combined in Behavior Trees to compound complex and
realistic human behaviors.

</details>


### [213] [Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks](https://arxiv.org/abs/2507.17338)
*Corrado Pezzato,Ozan Çatal,Toon Van de Maele,Riddhi J. Pitliya,Tim Verbelen*

Main category: cs.RO

TL;DR: 提出了一个分层主动推理架构，用于机器人复杂长期任务的目标导向行为控制，在Habitat基准测试中超越了现有最先进方法，首次证明主动推理可以扩展到现代机器人基准的复杂性。


<details>
  <summary>Details</summary>
Motivation: 尽管主动推理在机器人控制方面引起了越来越多的关注，但其在复杂长期任务中的应用仍未得到测试，需要解决主动推理在现实机器人环境中处理复杂任务的可扩展性问题。

Method: 引入了一个完全分层的主动推理架构，结合高级主动推理模型（选择离散技能）和全身主动推理控制器（实现技能），这种统一方法支持灵活的技能组合、在线适应性和任务失败恢复，无需离线训练。

Result: 在Habitat移动操作基准测试中，该方法在三个长期任务上均优于最先进的基线方法，首次证明主动推理可以扩展到现代机器人基准的复杂性水平。

Conclusion: 分层主动推理架构成功解决了主动推理在复杂长期机器人任务中的可扩展性问题，为主动推理在现实机器人应用中的广泛应用奠定了基础。

Abstract: Despite growing interest in active inference for robotic control, its
application to complex, long-horizon tasks remains untested. We address this
gap by introducing a fully hierarchical active inference architecture for
goal-directed behavior in realistic robotic settings. Our model combines a
high-level active inference model that selects among discrete skills realized
via a whole-body active inference controller. This unified approach enables
flexible skill composition, online adaptability, and recovery from task
failures without requiring offline training. Evaluated on the Habitat Benchmark
for mobile manipulation, our method outperforms state-of-the-art baselines
across the three long-horizon tasks, demonstrating for the first time that
active inference can scale to the complexity of modern robotics benchmarks.

</details>


### [214] [An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness](https://arxiv.org/abs/2507.17376)
*Tianshu Ruan,Aniketh Ramesh,Rustam Stolkin,Manolis Chiou*

Main category: cs.RO

TL;DR: 该研究探讨了高级语义信息对人机团队协作的影响，通过灾难响应任务实验发现，语义信息能够减轻操作员工作负荷、提高态势感知信任度并缩短反应时间


<details>
  <summary>Details</summary>
Motivation: 现有研究中高级语义信息如何惠及人机团队范式尚未充分探索，且往往模糊难以处理。在灾难响应等复杂任务中，人类操作员面临高工作负荷和压力，需要在多个机器人和任务间切换注意力，难以快速建立态势感知能力

Method: 采用基于语义的框架，在模拟灾难响应任务中应用，该框架能够揭示环境的不同指标（即存在多少语义信息）。通过实验评估语义信息对人机团队协作和人机交互的影响

Result: 实验结果表明，所提出的语义信息能够：1）减轻人类操作员的感知工作负荷；2）增加操作员对态势感知的信任；3）帮助减少在需要时切换自主级别的反应时间。此外，发现对系统信任度较高的参与者更倾向于在高级语义信息的鼓励下使用遥控操作模式

Conclusion: 高级语义信息在人机团队协作中具有显著的积极作用，能够有效改善操作员的工作体验和系统性能。语义信息不仅减轻了认知负担，还提高了操作员的信任度和响应效率，为未来的人机协作系统设计提供了重要指导

Abstract: In this paper, we investigate the impact of high-level semantics (evaluation
of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction
(HRI) in the context of mobile robot deployments. Although semantics has been
widely researched in AI, how high-level semantics can benefit the HRT paradigm
is underexplored, often fuzzy, and intractable. We applied a semantics-based
framework that could reveal different indicators of the environment (i.e. how
much semantic information exists) in a mock-up disaster response mission. In
such missions, semantics are crucial as the HRT should handle complex
situations and respond quickly with correct decisions, where humans might have
a high workload and stress. Especially when human operators need to shift their
attention between robots and other tasks, they will struggle to build
Situational Awareness (SA) quickly. The experiment suggests that the presented
semantics: 1) alleviate the perceived workload of human operators; 2) increase
the operator's trust in the SA; and 3) help to reduce the reaction time in
switching the level of autonomy when needed. Additionally, we find that
participants with higher trust in the system are encouraged by high-level
semantics to use teleoperation mode more.

</details>


### [215] [Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models](https://arxiv.org/abs/2507.17379)
*Shen Tan,Dong Zhou,Xiangyu Shao,Junqiao Wang,Guanghui Sun*

Main category: cs.RO

TL;DR: 本文提出了LOVMM框架，结合大语言模型和视觉语言模型来解决开放词汇移动操作任务，能够在家庭环境中处理未见过的物体并执行自然语言指令。


<details>
  <summary>Details</summary>
Motivation: 开放词汇移动操作(OVMM)需要机器人在不同工作空间中处理新颖和未见过的物体，这对现实世界的机器人应用来说仍然是一个重大挑战。

Method: 提出了语言条件开放词汇移动操作框架LOVMM，该框架结合了大语言模型(LLM)和视觉语言模型(VLM)来处理家庭环境中的各种移动操作任务。

Result: 在复杂家庭环境的仿真实验中展现了强大的零样本泛化能力和多任务学习能力，能够处理自由形式的自然语言指令，并在多个桌面操作任务上取得了比其他最先进方法更好的成功率。

Conclusion: LOVMM框架成功地解决了开放词汇移动操作的挑战，通过结合LLM和VLM实现了对未见物体的有效处理和自然语言指令的准确执行，在零样本泛化和多任务学习方面表现优异。

Abstract: Open-vocabulary mobile manipulation (OVMM) that involves the handling of
novel and unseen objects across different workspaces remains a significant
challenge for real-world robotic applications. In this paper, we propose a
novel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named
LOVMM, incorporating the large language model (LLM) and vision-language model
(VLM) to tackle various mobile manipulation tasks in household environments.
Our approach is capable of solving various OVMM tasks with free-form natural
language instructions (e.g. "toss the food boxes on the office room desk to the
trash bin in the corner", and "pack the bottles from the bed to the box in the
guestroom"). Extensive experiments simulated in complex household environments
show strong zero-shot generalization and multi-task learning abilities of
LOVMM. Moreover, our approach can also generalize to multiple tabletop
manipulation tasks and achieve better success rates compared to other
state-of-the-art methods.

</details>


### [216] [Confidence Calibration in Vision-Language-Action Models](https://arxiv.org/abs/2507.17383)
*Thomas P Zollo,Richard Zemel*

Main category: cs.RO

TL;DR: 本研究首次系统性地研究了视觉-语言-行动(VLA)基础模型的置信度校准问题，提出了提示集成和动作维度校准方法来提高机器人行为的可信度和不确定性量化能力。


<details>
  <summary>Details</summary>
Motivation: 可信的机器人行为不仅需要高任务成功率，还需要机器人能够可靠地量化其成功的可能性。现有的视觉-语言-行动基础模型缺乏对置信度校准的系统性研究，这限制了机器人在实际应用中的可信度。

Method: 1) 对多个数据集和VLA变体进行广泛基准测试，分析任务成功率与校准误差的关系；2) 提出提示集成算法，通过对释义指令的置信度进行平均来改善校准；3) 分析任务时间范围内的校准情况；4) 提出动作维度的Platt缩放方法，独立重新校准每个动作维度。

Result: 发现任务性能和校准之间不存在冲突；提示集成算法能够持续改善校准效果；置信度在取得一定进展后往往最为可靠，为风险感知干预提供了自然时机；不同动作维度存在差异性误校准现象。

Conclusion: 通过开发必要的工具和概念理解，本研究为使VLA模型既具有高性能又具有高可信度奠定了基础，通过可靠的不确定性量化实现了这一目标。研究为机器人行为的置信度校准提供了系统性的解决方案。

Abstract: Trustworthy robot behavior requires not only high levels of task success but
also that the robot can reliably quantify how likely it is to succeed. To this
end, we present the first systematic study of confidence calibration in
vision-language-action (VLA) foundation models, which map visual observations
and natural-language instructions to low-level robot motor commands. We begin
with extensive benchmarking to understand the critical relationship between
task success and calibration error across multiple datasets and VLA variants,
finding that task performance and calibration are not in tension. Next, we
introduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm
that averages confidence across paraphrased instructions and consistently
improves calibration. We further analyze calibration over the task time
horizon, showing that confidence is often most reliable after making some
progress, suggesting natural points for risk-aware intervention. Finally, we
reveal differential miscalibration across action dimensions and propose
action-wise Platt scaling, a method to recalibrate each action dimension
independently to produce better confidence estimates. Our aim in this study is
to begin to develop the tools and conceptual understanding necessary to render
VLAs both highly performant and highly trustworthy via reliable uncertainty
quantification.

</details>


### [217] [IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception](https://arxiv.org/abs/2507.17445)
*Haichuan Li,Changda Tian,Panos Trahanias,Tomi Westerlund*

Main category: cs.RO

TL;DR: 本文提出IndoorBEV，一种基于掩码的鸟瞰视角方法，用于室内移动机器人在复杂3D点云中进行多样化物体检测，通过将3D场景投影到2D BEV网格来处理遮挡并区分静态障碍物和动态目标。


<details>
  <summary>Details</summary>
Motivation: 传统边界框方法在复杂室内3D点云环境中检测多样化物体时存在局限性，特别是在处理不同物体形状、杂乱环境以及静态和动态元素共存的场景时表现不佳，需要更鲁棒的解决方案。

Method: 提出IndoorBEV方法，将3D场景投影到2D鸟瞰视角网格中，使用轴紧凑编码器和基于窗口的骨干网络从BEV地图中提取丰富的空间特征，然后通过基于查询的解码器头使用学习到的物体查询同时预测物体类别和实例掩码。

Result: 在包含静态物体和动态元素（如机器人和杂项物品）的定制室内数据集上验证了IndoorBEV的有效性，展示了其在鲁棒室内场景理解方面的潜力，生成的2D BEV结果可直接用于导航、运动预测和规划等下游机器人任务。

Conclusion: IndoorBEV提供了一种基于掩码的替代方案来替代边界框回归，能够有效捕获静态和动态物体的足迹而不受其形状限制，为室内移动机器人感知提供了更鲁棒的解决方案。

Abstract: Detecting diverse objects within complex indoor 3D point clouds presents
significant challenges for robotic perception, particularly with varied object
shapes, clutter, and the co-existence of static and dynamic elements where
traditional bounding box methods falter. To address these limitations, we
propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor
mobile robots.
  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles
naturally occlusions and provides a consistent top-down view aiding to
distinguish static obstacles from dynamic agents. The obtained 2D BEV results
is directly usable to downstream robotic tasks like navigation, motion
prediction, and planning. Our architecture utilizes an axis compact encoder and
a window-based backbone to extract rich spatial features from this BEV map. A
query-based decoder head then employs learned object queries to concurrently
predict object classes and instance masks in the BEV space. This mask-centric
formulation effectively captures the footprint of both static and dynamic
objects regardless of their shape, offering a robust alternative to bounding
box regression. We demonstrate the effectiveness of IndoorBEV on a custom
indoor dataset featuring diverse object classes including static objects
  and dynamic elements like robots and miscellaneous items, showcasing its
potential for robust indoor scene understanding.

</details>


### [218] [Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners](https://arxiv.org/abs/2507.17519)
*Kostas Karakontis,Thanos Petsanis,Athanasios Ch. Kapoutsis,Pavlos Ch. Kapoutsis,Elias B. Kosmatopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种模块化算法，将商业二维路径规划器扩展为地形感知的三维规划器，通过调整高度和相机方向改善无人机群覆盖路径规划，特别是在垂直特征区域的3D重建效果


<details>
  <summary>Details</summary>
Motivation: 现有商业软件中的多无人机覆盖路径规划算法仅将感兴趣区域视为2D平面，忽略了重要的3D结构特征，导致3D重建不完整，特别是在遮挡或垂直表面周围

Method: 提出了一种模块化算法，可以扩展商业二维路径规划器以实现地形感知规划，通过调整高度和相机方向来改善规划效果。具体扩展了知名的DARP算法，产生了DARP-3D算法

Result: 在多个3D环境中进行仿真测试，并使用大疆硬件进行了真实世界飞行测试。与基线方法相比，该方法在3D重建方面表现一致更好，特别是在具有显著垂直特征的区域

Conclusion: 所提出的模块化算法能够有效改善多无人机覆盖路径规划的3D重建质量，特别是在处理垂直结构和遮挡区域方面表现出色，并提供了开源实现

Abstract: Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial
software typically treat a Region of Interest (RoI) only as a 2D plane,
ignoring important3D structure characteristics. This leads to incomplete
3Dreconstructions, especially around occluded or vertical surfaces. In this
paper, we propose a modular algorithm that can extend commercial
two-dimensional path planners to facilitate terrain-aware planning by adjusting
altitude and camera orientations. To demonstrate it, we extend the well-known
DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm
and produce DARP-3D. We present simulation results in multiple 3D environments
and a real-world flight test using DJI hardware. Compared to baseline, our
approach consistently captures improved 3D reconstructions, particularly in
areas with significant vertical features. An open-source implementation of the
algorithm is available here:https://github.com/konskara/TerraPlan

</details>


### [219] [InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation](https://arxiv.org/abs/2507.17520)
*Shuai Yang,Hao Li,Yilun Chen,Bin Wang,Yang Tian,Tai Wang,Hanqing Wang,Feng Zhao,Yiyi Liao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: InstructVLA是一个端到端的视觉-语言-动作模型，通过新颖的VLA-IT训练范式，在保持大型视觉语言模型灵活推理能力的同时，实现了领先的机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型往往在多模态推理和精确动作生成之间存在权衡，能力局限于特定任务的操作数据，并且会遭受预训练视觉语言能力的灾难性遗忘问题。需要一个能够同时保持灵活推理能力和优秀操作性能的统一模型。

Method: 提出了视觉-语言-动作指令调优(VLA-IT)的新训练范式，采用混合专家适应的多模态训练方法，在标准VLM语料库和精心策划的65万样本VLA-IT数据集上联合优化文本推理和动作生成。

Result: 在域内SimplerEnv任务上比SpatialVLA提升30.5%；在新提出的80任务SimplerEnv-Instruct基准测试中，比微调的OpenVLA提升92%，比GPT-4o辅助的动作专家提升29%；在多模态任务上超越基线VLM，并展现了推理时间缩放能力。

Conclusion: InstructVLA成功桥接了直观可控的人机交互与高效的策略学习，证明了其在保持视觉语言推理能力的同时实现优秀机器人操作性能的潜力，为未来的人机协作提供了新的解决方案。

Abstract: To operate effectively in the real world, robots must integrate multimodal
reasoning with precise action generation. However, existing
vision-language-action (VLA) models often sacrifice one for the other, narrow
their abilities to task-specific manipulation data, and suffer catastrophic
forgetting of pre-trained vision-language capabilities. To bridge this gap, we
introduce InstructVLA, an end-to-end VLA model that preserves the flexible
reasoning of large vision-language models (VLMs) while delivering leading
manipulation performance. InstructVLA introduces a novel training paradigm,
Vision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal
training with mixture-of-experts adaptation to jointly optimize textual
reasoning and action generation on both standard VLM corpora and a curated
650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves
30.5% improvement over SpatialVLA. To evaluate generalization, we introduce
SimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and
high-level instruction understanding, where it outperforms a fine-tuned OpenVLA
by 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA
surpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling
by leveraging textual reasoning to boost manipulation performance in both
simulated and real-world settings. These results demonstrate InstructVLA's
potential for bridging intuitive and steerable human-robot interaction with
efficient policy learning.

</details>


### [220] [When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment](https://arxiv.org/abs/2507.17531)
*Abdel-Raouf Dannaoui,Johann Laconte,Christophe Debain,Francois Pomerleau,Paul Checchin*

Main category: cs.RO

TL;DR: 本研究针对动态户外环境中的3D激光雷达重定位问题，提供了一个高分辨率短期多时间数据集，并比较了两种ICP算法在不同环境条件下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 自主系统在动态户外环境中的鲁棒重定位仍然是一个关键挑战，特别是短期环境变化（数天或数周内发生）在实际应用中具有重要意义但研究不足，需要提供结构化数据集和评估框架来分析这类问题。

Method: 构建了一个从2025年2月到4月每周收集的高分辨率短期多时间数据集，包含高密度点云地图、360度全景图像和轨迹数据；使用两种迭代最近点（ICP）算法变体（点对点和点对面）评估投影激光雷达扫描与真值的对齐精度。

Result: 点对面ICP算法在配准稳定性和精度方面显著优于点对点ICP，特别是在稀疏特征区域或密集植被环境中表现更佳；研究揭示了局部几何形状和环境变化如何影响定位成功率。

Conclusion: 该研究为评估短期定位鲁棒性提供了结构化数据集，建立了在噪声条件下分析扫描到地图对齐的可重现框架，并为设计更具弹性的机器人系统提供了重要见解。

Abstract: Robust relocalization in dynamic outdoor environments remains a key challenge
for autonomous systems relying on 3D lidar. While long-term localization has
been widely studied, short-term environmental changes, occurring over days or
weeks, remain underexplored despite their practical significance. To address
this gap, we present a highresolution, short-term multi-temporal dataset
collected weekly from February to April 2025 across natural and semi-urban
settings. Each session includes high-density point cloud maps, 360 deg
panoramic images, and trajectory data. Projected lidar scans, derived from the
point cloud maps and modeled with sensor-accurate occlusions, are used to
evaluate alignment accuracy against the ground truth using two Iterative
Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show
that Point-to-Plane offers significantly more stable and accurate registration,
particularly in areas with sparse features or dense vegetation. This study
provides a structured dataset for evaluating short-term localization
robustness, a reproducible framework for analyzing scan-to-map alignment under
noise, and a comparative evaluation of ICP performance in evolving outdoor
environments. Our analysis underscores how local geometry and environmental
variability affect localization success, offering insights for designing more
resilient robotic systems.

</details>


### [221] [Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper](https://arxiv.org/abs/2507.17561)
*Lorenzo Vianello,Matthew Short,Julia Manczurowsky,Emek Barış Küçüktabak,Francesco Di Tommaso,Alessia Noccaro,Laura Bandini,Shoshana Clark,Alaina Fiorenza,Francesca Lunardini,Alberto Canton,Marta Gandolla,Alessandra L. G. Pedrocchi,Emilia Ambrosini,Manuel Murie-Fernandez,Carmen B. Roman,Jesus Tornero,Natacha Leon,Andrew Sawers,Jim Patton,Domenico Formica,Nevio Luigi Tagliamonte,Georg Rauter,Kilian Baur,Fabian Just,Christopher J. Hasson,Vesna D. Novak,Jose L. Pons*

Main category: cs.RO

TL;DR: 本文提出了一种新的神经康复方法——机器人介导的人-人物理交互，旨在结合治疗师的临床专业知识与机器人的精确性和可重复性，为神经损伤患者提供更好的康复治疗。


<details>
  <summary>Details</summary>
Motivation: 传统神经康复依赖患者与物理治疗师的直接交互，而现有机器人系统虽能改善物理反馈，但未充分利用训练有素的治疗师的适应性和临床专业知识。需要一种新方法来整合两者优势。

Method: 提出机器人介导的人-人物理交互框架，使两个人能够通过机器人设备进行物理交互。该方法基于多学科团队合作，采用统一的分类体系描述机器人介导康复、基于社会心理学的交互框架，以及使机器人系统成为自然人-人交互无缝促进者的技术方法。

Result: 该框架已在不同研究团队中得到研究，最近作为连接传统手工治疗和康复机器人的有前景的桥梁出现，能够协调两种方法的优势。

Conclusion: 机器人介导的人-人物理交互为神经康复提供了新的解决方案，通过整合治疗师的临床专业知识与机器人的技术优势，有望改善康复治疗效果，为传统康复治疗和机器人康复之间建立了有效的桥梁。

Abstract: Neurorehabilitation conventionally relies on the interaction between a
patient and a physical therapist. Robotic systems can improve and enrich the
physical feedback provided to patients after neurological injury, but they
under-utilize the adaptability and clinical expertise of trained therapists. In
this position paper, we advocate for a novel approach that integrates the
therapist's clinical expertise and nuanced decision-making with the strength,
accuracy, and repeatability of robotics: Robot-mediated physical Human-Human
Interaction. This framework, which enables two individuals to physically
interact through robotic devices, has been studied across diverse research
groups and has recently emerged as a promising link between conventional manual
therapy and rehabilitation robotics, harmonizing the strengths of both
approaches. This paper presents the rationale of a multidisciplinary
team-including engineers, doctors, and physical therapists-for conducting
research that utilizes: a unified taxonomy to describe robot-mediated
rehabilitation, a framework of interaction based on social psychology, and a
technological approach that makes robotic systems seamless facilitators of
natural human-human interaction.

</details>


### [222] [KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming](https://arxiv.org/abs/2507.17572)
*Antoine Groudiev,Fabian Schramm,Éloïse Berthier,Justin Carpentier,Frederike Dümbgen*

Main category: cs.RO

TL;DR: 该论文将核平方和(KernelSOS)框架应用于控制和估计问题的全局优化，展示了其在处理具有局部最小值的非多项式和非参数问题上的优势，既可作为独立方法也可作为局部求解器的初始化方法。


<details>
  <summary>Details</summary>
Motivation: 传统的控制和估计问题常常存在局部最小值问题，现有的多项式优化方法在处理非多项式和非参数问题时存在局限性。需要一种既能利用平方和方法的理论基础，又能发挥核方法表达能力的全局优化框架。

Method: 采用核平方和(KernelSOS)框架，该方法结合了多项式优化中的平方和方法与机器学习中广泛使用的核方法。利用KernelSOS基于样本的特性，将其应用于轨迹优化问题，将集成仿真器视为黑盒处理。

Result: KernelSOS在控制和估计领域的多个问题上表现良好，在估计问题上与其他平方和方法具有竞争力，同时能够处理非多项式和非参数问题。作为独立方法和局部求解器初始化方法都能有效发现更好的解决方案。

Conclusion: KernelSOS框架为解决控制和估计中的全局优化问题提供了一个强大的工具，特别适用于具有复杂局部最小值结构的非多项式问题，既可独立使用也可与传统局部求解器结合使用以提高求解质量。

Abstract: Global optimization has gained attraction over the past decades, thanks to
the development of both theoretical foundations and efficient numerical
routines to cope with optimization problems of various complexities. Among
recent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful
framework, leveraging the potential of sum of squares methods from the
polynomial optimization community with the expressivity of kernel methods
widely used in machine learning. This paper applies the kernel sum of squares
framework for solving control and estimation problems, which exhibit poor local
minima. We demonstrate that KernelSOS performs well on a selection of problems
from both domains. In particular, we show that KernelSOS is competitive with
other sum of squares approaches on estimation problems, while being applicable
to non-polynomial and non-parametric formulations. The sample-based nature of
KernelSOS allows us to apply it to trajectory optimization problems with an
integrated simulator treated as a black box, both as a standalone method and as
a powerful initialization method for local solvers, facilitating the discovery
of better solutions.

</details>


### [223] [Event Detection for Active Lower Limb Prosthesis](https://arxiv.org/abs/2507.17649)
*J. D. Clark,P. Ellison*

Main category: cs.RO

TL;DR: 本研究探讨了在假肢膝关节设计中使用双髁膝关节和十字韧带拉伸来改进步态事件检测的方法，发现韧带拉伸模式可以用作预测步态关键事件的指标。


<details>
  <summary>Details</summary>
Motivation: 传统的销轴关节设计过于简化，丢失了自然膝关节的复杂运动学特性。准确的事件检测对半被动和动力假肢的成功设计至关重要，因此需要研究更接近自然膝关节的设计方案。

Method: 使用双髁膝关节设计，通过前后十字韧带类似物进行约束。使用平行于Russell膝关节韧带的LVDT传感器记录韧带拉伸情况。在跑步机上以3种不同速度进行数据采集实验。

Result: 发现十字韧带拉伸存在速度依赖性，主要出现在步态周期的5%和80%处。循环轮廓随速度保持一致，在步态周期90%和95%处的转折点特征可用作初始接触的预测前兆，同样的转折点也可用于预测足平期。

Conclusion: 双髁膝关节设计可以改善步态周期中事件的检测，从而提高动力假肢后续控制器的准确性。韧带拉伸模式为步态事件检测提供了新的可靠指标。

Abstract: Accurate event detection is key to the successful design of semi-passive and
powered prosthetics. Kinematically, the natural knee is complex, with
translation and rotation components that have a substantial impact on gait
characteristics. When simplified to a pin joint, some of this behaviour is
lost. This study investigates the role of cruciate ligament stretch in event
detection. A bicondylar knee design was used, constrained by analogues of the
anterior and posterior cruciate ligaments. This offers the ability to
characterize knee kinematics by the stretch of the ligaments. The ligament
stretch was recorded using LVDTs parallel to the ligaments of the Russell knee
on a bent knee crutch. Which was used to capture data on a treadmill at 3
speeds. This study finds speed dependence within the stretch of the cruciate
ligaments, prominently around 5\% and 80\% of the gait cycle for the posterior
and anterior. The cycle profile remains consistent with speed; therefore, other
static events such as the turning point feature at around 90\% and 95\% of the
cycle, for the posterior and anterior, respectively, could be used as a
predictive precursor for initial contact. Likewise at 90\% and 95\%, another
pair of turning points that in this case could be used to predict foot flat.
This concludes that the use of a bicondylar knee design could improve the
detection of events during the gait cycle, and therefore could increase the
accuracy of subsequent controllers for powered prosthetics.

</details>


### [224] [Safety Assurance for Quadrotor Kinodynamic Motion Planning](https://arxiv.org/abs/2507.17679)
*Theodoros Tavoulareas,Marzia Cescon*

Main category: cs.RO

TL;DR: 本文提出了一种结合运行时安全保障的无人机运动规划方法，通过采样几何规划器和低级安全保障滤波器确保无人机在导航过程中满足安全约束


<details>
  <summary>Details</summary>
Motivation: 现有的无人机运动规划技术虽然能够生成无碰撞轨迹，但在创建运动计划时没有固有地考虑系统的安全操作区域，导致在部署过程中可能违反安全约束，从而可能造成系统物理损坏、环境污染甚至人员伤亡

Method: 提出了一种在运动动力学规划方案中利用运行时安全保障的方法：首先使用基于采样的几何规划器在用户定义空间内确定高级无碰撞路径；其次设计低级安全保障滤波器为线性二次调节器(LQR)的控制输入提供安全保证

Result: 在限制性3D仿真环境中使用Crazyflie 2.0无人机模型验证了所提出的方法，证明了该方法能够有效保障无人机运行安全

Conclusion: 所提出的结合运行时安全保障的运动规划方法能够有效满足无人机系统的操作约束，为自主无人机的安全部署提供了可行的解决方案

Abstract: Autonomous drones have gained considerable attention for applications in
real-world scenarios, such as search and rescue, inspection, and delivery. As
their use becomes ever more pervasive in civilian applications, failure to
ensure safe operation can lead to physical damage to the system, environmental
pollution, and even loss of human life. Recent work has demonstrated that
motion planning techniques effectively generate a collision-free trajectory
during navigation. However, these methods, while creating the motion plans, do
not inherently consider the safe operational region of the system, leading to
potential safety constraints violation during deployment. In this paper, we
propose a method that leverages run time safety assurance in a kinodynamic
motion planning scheme to satisfy the system's operational constraints. First,
we use a sampling-based geometric planner to determine a high-level
collision-free path within a user-defined space. Second, we design a low-level
safety assurance filter to provide safety guarantees to the control input of a
Linear Quadratic Regulator (LQR) designed with the purpose of trajectory
tracking. We demonstrate our proposed approach in a restricted 3D simulation
environment using a model of the Crazyflie 2.0 drone.

</details>


### [225] [CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation](https://arxiv.org/abs/2507.17727)
*Robel Mamo,Taeyeong Choi*

Main category: cs.RO

TL;DR: 本文提出了一种名为Crop-Aligned Cutout (CA-Cut)的新型数据增强方法，通过在作物行周围进行空间分布式遮挡来提升农业机器人在冠层下导航的鲁棒性，相比传统增强方法可减少36.9%的预测误差。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习视觉导航模型需要大量训练数据来确保可靠性，但数据收集成本高昂，传统的数据增强技术（如颜色抖动、高斯模糊等）在复杂的冠层下环境中可能导致次优性能，特别是在频繁遮挡、碎片和作物间距不均匀的情况下。

Method: 提出Crop-Aligned Cutout (CA-Cut)增强方法，在输入图像中随机遮挡作物行两侧空间分布的区域，迫使训练模型即使在细粒度信息被遮挡时也能捕获高级上下文特征。该方法将遮罩分布偏向作物行来模拟真实的遮挡情况。

Result: 在公开玉米田数据集上的广泛实验表明，基于遮挡的增强方法有效模拟了遮挡情况，显著提高了视觉导航语义关键点预测的鲁棒性。CA-Cut方法在预测准确性和跨环境泛化能力方面都有显著提升，预测误差最多减少36.9%。

Conclusion: CA-Cut数据增强方法通过针对作物行进行空间分布式遮挡，有效提升了农业机器人冠层下导航模型的性能和鲁棒性。研究还通过消融实验确定了遮挡数量、大小和空间分布的最优参数配置，为农业视觉导航提供了一种有效的数据增强策略。

Abstract: State-of-the-art visual under-canopy navigation methods are designed with
deep learning-based perception models to distinguish traversable space from
crop rows. While these models have demonstrated successful performance, they
require large amounts of training data to ensure reliability in real-world
field deployment. However, data collection is costly, demanding significant
human resources for in-field sampling and annotation. To address this
challenge, various data augmentation techniques are commonly employed during
model training, such as color jittering, Gaussian blur, and horizontal flip, to
diversify training data and enhance model robustness. In this paper, we
hypothesize that utilizing only these augmentation techniques may lead to
suboptimal performance, particularly in complex under-canopy environments with
frequent occlusions, debris, and non-uniform spacing of crops. Instead, we
propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut)
which masks random regions out in input images that are spatially distributed
around crop rows on the sides to encourage trained models to capture high-level
contextual features even when fine-grained information is obstructed. Our
extensive experiments with a public cornfield dataset demonstrate that
masking-based augmentations are effective for simulating occlusions and
significantly improving robustness in semantic keypoint predictions for visual
navigation. In particular, we show that biasing the mask distribution toward
crop rows in CA-Cut is critical for enhancing both prediction accuracy and
generalizability across diverse environments achieving up to a 36.9% reduction
in prediction error. In addition, we conduct ablation studies to determine the
number of masks, the size of each mask, and the spatial distribution of masks
to maximize overall performance.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [226] [Stable and Fair Benefit Allocation in Mixed-Energy Truck Platooning: A Coalitional Game Approach](https://arxiv.org/abs/2507.16923)
*Ting Bai,Karl Henrik Johansson,Jonas Mårtensson,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: 本文研究混合能源卡车队列中燃油卡车和电动卡车之间的收益分配问题，提出了基于联盟博弈理论的稳定且公平的收益分配方案


<details>
  <summary>Details</summary>
Motivation: 混合能源卡车队列编队中，不同类型卡车（燃油卡车和电动卡车）在能源节约和队列角色（领导者或跟随者）方面存在异质性，需要设计合理的收益分配机制来激励卡车参与合作并防止偏离联盟

Method: 将卡车队列编队中的交互建模为可转移效用的联盟博弈，设计考虑卡车异质性的稳定收益分配方案，建立核稳定性条件；提出基于Shapley值的封闭形式分配方法；在Shapley值不在核内时，开发基于稳定收益的替代分配方案

Result: 提供了分配方案既公平又核稳定的充分条件；证明了当Shapley值在核外时，替代分配方案与Shapley值的平均相对偏差上界为1；数值研究验证了理论结果的有效性

Conclusion: 所提出的框架能够在混合能源卡车队列中实现稳定、公平和可持续的合作，在稳定性和公平性之间取得了良好的权衡

Abstract: This paper addresses the benefit allocation in a mixed-energy truck platoon
composed of fuel-powered and electric trucks. The interactions among trucks
during platoon formation are modeled as a coalitional game with transferable
utility. We first design a stable payoff allocation scheme that accounts for
truck heterogeneity in energy savings and platoon roles (leader or follower),
establishing core-stability conditions to ensure that no subset of trucks has
an incentive to deviate for greater benefit. To enhance payoff fairness, we
then propose a closed-form, Shapley value-based allocation approach that is
computationally efficient and independent of the platoon size. Sufficient
conditions under which the allocation is both fair and core-stable are
provided. In scenarios where the Shapley value falls outside the core, we
develop an alternative allocation based on the stable payoff that minimizes the
mean relative deviation from the Shapley value while preserving core stability.
This deviation is further proved to be upper-bounded by $1$, showing a
favorable trade-off between stability and fairness. Finally, extensive
numerical studies validate the theoretical results and demonstrate the
effectiveness of the proposed framework in facilitating stable, equitable, and
sustainable cooperation in mixed-energy truck platooning.

</details>


### [227] [Fast Distribution Grid Topology Estimation via Subset Sum](https://arxiv.org/abs/2507.16924)
*Yueyao Xu,Yize Chen*

Main category: eess.SY

TL;DR: 本文提出了一种基于分层子集和方法的超快速配电网拓扑识别算法，能够利用有限的智能电表功率测量数据快速准确地识别配电网拓扑结构，适用于实时应用场景并对测量噪声具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源渗透率不断提高和配电网能量管理快速发展，配电网拓扑识别成为重要且基础的任务。由于电网拓扑通常对公用事业公司来说是未知或不完整的，因此迫切需要利用有限的测量数据高效识别配电网网络拓扑结构，以支持负荷监测、运行控制和故障检测等关键功能。

Method: 采用分层结构适配子集和方法，通过智能电表功率测量的少量样本推断整体电网拓扑。该方法将子集和算法与分层结构相结合，能够在减少所需测量样本数量的同时提高拓扑识别的速度和准确性。

Result: 所提出的分层算法能够实现超快速的拓扑识别，可在拓扑快速变化的场景下进行实时应用，同时对测量噪声表现出良好的鲁棒性，能够从较少的智能电表功率测量样本中准确推断出配电网拓扑结构。

Conclusion: 本文成功开发了一种新颖的超快速配电网拓扑识别方法，通过分层子集和算法实现了高效准确的拓扑推断。该方法具有实时应用能力和抗噪声干扰特性，为配电网的运行监控、控制管理和故障检测提供了有力的技术支撑。

Abstract: Faced with increasing penetration of distributed energy resources and fast
development of distribution grid energy management, topology identification of
distribution grid becomes an important and fundamental task. As the underlying
grid topology is usually unknown or incomplete to the utilities, it is becoming
a fundamental task to efficiently identify the distribution grid network
topology using limited measurements. A fast and accurate topology
identification can help achieving the tasks of load monitoring, operation and
control of power distribution system as well as outage detection. In this
paper, we propose a novel and ultra-fast topology identification method. By
adapting the subset sum method with a hierarchical structure, the overall grid
topology can be inferred from fewer samples of smart meter power measurements.
Such techniques can be applied in real time under the scenarios with fast
topology change, and the proposed hierarchical algorithm is also robust against
measurement noises.

</details>


### [228] [Impact of Communication Delay and Sampling on Small-Signal Stability of IBR-rich Power Systems](https://arxiv.org/abs/2507.16963)
*Saugat Ghimire,Vaithianathan "Mani" Venkatasubramanian,Gilles Torresan*

Main category: eess.SY

TL;DR: 本文分析了逆变器基础资源(IBR)电厂中工厂级控制与逆变器级控制之间的通信延迟和采样对电力系统小信号稳定性的影响，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着逆变器基础资源(IBR)的广泛应用，电力系统出现了前所未有的动态特性和宽频率范围的振荡。工厂级控制与逆变器级控制之间的通信延迟被认为是引起振荡和影响系统稳定性的原因之一，但其具体影响机制尚需深入分析。

Method: 重新审视通信延迟和采样的基础理论，分析工厂级控制和逆变器级控制之间控制信号的通信延迟和采样对跟网型IBR电厂小信号稳定性的影响机制。

Result: 研究发现通信延迟和采样周期对IBR密集型电力系统的稳定性具有独特影响，揭示了这些因素对系统响应的具体作用机制。

Conclusion: 强调了通信延迟和采样周期对IBR密集型电力系统稳定性的独特影响，提出了缓解其不利影响的策略，并指出需要更精确的小信号稳定性分析方法来分析此类系统。

Abstract: The growing adoption of inverter-based resources (IBRs) has introduced
unprecedented dynamics in power systems, resulting in oscillations across a
broad spectrum of frequencies. Communication delay between the plant-level
control and the inverter-level control in IBR plants has been recognized as one
of the causes of such oscillations and a factor that impacts the system's
stability. The control signals from the plant-level controller also experience
sampling, with the sampled values held constant by the hold elements for the
duration of the sampling period. This also has a bearing on the response of IBR
plants. In this paper, we analyze the impacts of communication delay and
sampling of control signals between plant-level control and inverter-level
control of grid-following IBR plants on the small-signal stability of power
systems. The underlying fundamentals of communication delay and sampling are
revisited to explain the observed responses. Our findings emphasize the unique
effects of communication delay and sampling period on the stability of IBR-rich
power systems and suggest strategies to mitigate their detrimental impacts. The
work also highlights the need for more accurate approaches for small-signal
stability analysis of such systems.

</details>


### [229] [Extension of Simple and Accurate Inductance Estimation for Rectangular Planar Windings](https://arxiv.org/abs/2507.16982)
*Theofilos Papadopoulos,Antonios Antonopoulos*

Main category: eess.SY

TL;DR: 本文提出了一种将正方形平面绕组电感估算方程推广到矩形形状的方法，通过使用广义均值的最优p范数来实现，并通过超过2600次仿真和实验验证了方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的电感估算方程（如Wheeler、Rosa和Monomial方程）仅适用于正方形等规则多边形平面绕组，需要将这些已验证准确性的方程推广到矩形形状的平面绕组中。

Method: 利用广义均值或幂均值(PM)的最优p范数来替代原方程中的外边长参数。对于矩形情况，用两个外边长的幂均值替代单一外边长参数，无需进一步修改原方程。基于包含超过2600次不同矩形绕组仿真的数据集来选择最优p范数值。

Result: 通过大量仿真数据验证了最优p值的选择方法，并通过实验室测量验证了所选平面电感器的估算准确性。成功将三个经典电感估算方程推广到矩形平面绕组。

Conclusion: 提出的基于广义均值最优p范数的方法能够有效地将正方形平面绕组的电感估算方程推广到矩形形状，在保持原方程结构不变的情况下显著提高了矩形绕组电感估算的准确性。

Abstract: This paper proposes a method to generalize the equations estimating the
inductance of square-shape planar windings to rectangle shape. This is done by
utilizing the optimal p-norm of the Generalized Mean Value or Power Mean (PM).
Three well-established equations with verified accuracy are examined, namely
Wheeler, Rosa, and the Monomial, which by definition consider only regular
polygons. One critical parameter of the original equations is the outer-side
length of the winding, which for the rectangle case, can be substituted by the
PM of the two outer-side lengths, without the need for any further
modifications. A methodology to select the optimal p-norm for the PM is
presented in terms of achieving the best accuracy for this estimation. The
selection of the optimal p is based on results from datasets containing more
than 2600 simulations of different rectangle-shaped windings. Finally, the
estimation accuracy is verified by laboratory measurements for a selection of
planar inductors.

</details>


### [230] [An Energy-Autonomous and Battery-Free Resistive Sensor using a Time-Domain to Digital Conversion with Bluetooth Low Energy connectivity](https://arxiv.org/abs/2507.17011)
*Mario Costanza,Antonino Pagano,Samuel Margueron,Ilenia Tinnirello,Roberto La Rosa*

Main category: eess.SY

TL;DR: 本文提出了一种能量自主无线传感节点(EAWSN)，通过收集环境光能供电，结合时域到数字转换技术进行阻性传感器测量，并通过低功耗蓝牙进行无线数据传输，实现了免维护的长期运行。


<details>
  <summary>Details</summary>
Motivation: 解决传统无线传感器节点的功耗限制问题，特别是在难以接入有线电源的环境中，通过环境能量收集技术实现传感器节点的能量自主性，消除对电池的依赖。

Method: 设计了一种结合环境光能量收集、时域到数字转换(TDDC)技术和低功耗蓝牙(BLE)通信的能量自主无线传感节点。该节点通过收集环境光能为系统供电，使用TDDC技术对阻性传感器进行高效准确的测量，并通过BLE将数据无线传输到基站。

Result: 实验结果表明，在传感器工作范围内，测试电阻R_m与测量的时钟脉冲数N_m之间存在线性关系，验证了系统测量的准确性和有效性。

Conclusion: 成功开发了一种能量自主的无线传感节点，通过环境光能量收集实现了免电池运行，结合TDDC技术和BLE通信，为各种应用场景提供了有前景的解决方案，特别适用于需要长期免维护运行的环境。

Abstract: This paper introduces an innovative Energy-Autonomous Wireless Sensing Node
(EAWSN) that addresses power constraints by harnessing ambient light for
energy. It combines this energy harvesting capability with the Time Domain to
Digital Conversion (TDDC) technique for efficient and accurate measurements of
resistive sensors. Bluetooth Low Energy (BLE) communication ensures data can be
transmitted wirelessly to a base station, providing a promising solution for
various applications, particularly in environments with limited access to wired
power sources, enabling long-term, maintenance-free operation by eliminating
batteries. Experimental results showed a linear relationship between the test
resistance R_m and the measured number of clock pulses N_m within the sensor's
operating range.

</details>


### [231] [Transient Stability-Driven Planning for the Optimal Sizing of Resilient AC/DC Hybrid Microgrids](https://arxiv.org/abs/2507.17110)
*Yi Wang,Goran Strbac*

Main category: eess.SY

TL;DR: 本文提出了一个瞬态稳定性驱动的AC/DC混合微电网最优规划框架，通过防御者-攻击者-防御者架构和新颖的瞬态稳定约束最优潮流算法，实现了在不同故障情况下考虑频率-电压耦合动态的成本效益投资决策优化。


<details>
  <summary>Details</summary>
Motivation: 现有的AC/DC混合微电网规划方法缺乏对瞬态稳定性的充分考虑，特别是在不同类型故障情况下，需要同时满足频率和电压稳定性要求，以及捕捉AC/DC互联变换器的频率-电压耦合动态特性，因此需要开发一个comprehensive的规划框架。

Method: 采用防御者-攻击者-防御者(DAD)架构将规划问题分解为上层和下层问题，使用增强遗传算法求解；提出瞬态稳定约束最优潮流(TSC-OPF)算法处理静态和瞬态运行；开发Lyapunov优化方法处理储能系统的时间耦合特性，实现小时级求解和秒级分辨率的协同优化。

Result: 案例研究验证了所提规划框架的有效性，能够在满足不同故障情况下瞬态稳定性要求的同时，为各种资源获得成本效益的投资决策，实现了静态和瞬态稳定性要求的协同优化。

Conclusion: 提出的瞬态稳定性驱动规划框架成功解决了AC/DC混合微电网在复杂故障场景下的最优规模配置问题，通过创新的算法设计实现了计算效率和稳定性要求的平衡，为弹性微电网规划提供了有效的技术方案。

Abstract: This paper proposes a transient stability-driven planning framework for the
optimal sizing problem of resilient AC/DC hybrid microgrids (HMGs) under
different types of contingencies, capturing frequency and voltage stability
requirements as well as the frequency-voltage coupling dynamics of AC/DC
interlinking converters (ICs). The planning model is formulated into a
defender-attacker-defender (DAD) architecture, which can be further merged into
two levels, i.e., upper-level and low-level problems, and then iteratively
solved by an enhanced genetic algorithm with sparsity calculation and local
search. Regarding the operation stage, a novel transient stability-constrained
optimal power flow (TSC-OPF) algorithm is proposed for static and transient
operations of HMGs, capturing governor dynamics and automatic voltage regulator
of conventional generators as well as the droop control dynamics of
inverter-based resources (IBRs) for frequency control and voltage control,
respectively. Furthermore, a Lyapunov optimisation approach is developed to
capture the time-coupling property of energy storages (ESs) and then allow the
TSC-OPF to be solved on an hourly basis with a second-scale resolution,
achieving the co-optimisation of static and transient stability requirements.
Case studies have been conducted to verify the effectiveness of the proposed
planning framework in obtaining cost-effective investment decisions for various
resources while respecting transient stability requirements under different
contingencies.

</details>


### [232] [Multi-Angle Rotational Actuation in a 0.8-mm-Thick Preload-Free Piezoelectric Micromotor](https://arxiv.org/abs/2507.17155)
*Haijia Yu,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: 本文提出了一种新的压电电机驱动原理，设计出了一种厚度仅0.8mm的微型压电电机，可在大角度范围内旋转（高达80度），无需外壳增大或外部配重，在OCT内窥镜和血栓切除磨头等医疗应用中具有重要潜力。


<details>
  <summary>Details</summary>
Motivation: 现有实验室微型压电电机为了追求小型化往往省略外壳，导致功能缺陷：只能单向旋转或需要外部配重来增加预载荷，这些问题严重降低了微型压电电机的实用价值。因此需要设计一种既能保持小型化又能克服这些功能缺陷的新型微型压电电机。

Method: 提出了一种新的压电电机驱动原理，基于此原理设计微型压电电机，使其能够在不增加电机外壳尺寸且不需要外部配重的情况下，实现大角度范围的旋转运动。

Result: 成功设计出定子厚度仅为0.8mm的微型压电电机，该电机能够在大角度范围内旋转（可达80度），无需外部配重，克服了传统微型压电电机的功能局限性。

Conclusion: 所提出的新驱动原理成功解决了微型压电电机的功能缺陷问题，设计的电机在保持超薄结构的同时实现了大角度旋转能力，在OCT内窥镜和血栓切除磨头等微医疗检测和治疗领域具有重要的应用潜力。

Abstract: Micro motors can be used in numerous fields like Micro medical testing and
treatment. To achieve a smaller size, micro piezoelectric motors in
laboratories often omit the outer casing, which can lead to functional defects
such as rotation only in one fixed direction or the need for external weights
(which are not counted within the motors volume) to increase preload. However,
this significantly reduces the practical value of micro piezoelectric motors.
This paper proposes a new driving principle for piezoelectric motors to design
a micro piezoelectric motor that can rotate at a wide range of angles (e.g. up
to 80)without increasing the motors casing and does not require external
weights, with a stator thickness of only 0.8 mm. This motor has significant
application potential in OCT endoscopes and thrombectomy grinding heads

</details>


### [233] [Maintenance-free condition monitoring system based on lora](https://arxiv.org/abs/2507.17156)
*Honglin Zhang,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: 本研究设计了一个基于LoRa模块LM401的免维护铁路轨道无线监测系统，通过分布式传感器节点实时监测轨道振动、温度和气压数据，并通过云端平台进行数据分析，相比传统人工巡检方法显著提高了监测效率并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 传统铁路轨道检测主要依赖人工巡检和大型检测设备，存在检测频率低、响应滞后、风险高、成本高、容易漏检等问题。随着铁路运输量不断增长，迫切需要一种更高效、更可靠的轨道监测解决方案。

Method: 设计了基于LoRa模块LM401的无线监测系统，每个监测节点包含STM32微控制器、LM401 LoRa收发器、低功耗ADXL362三轴加速度传感器、数字温度传感器LMT85和数字气压传感器RSCM17100KP101。系统采用LoRa星型拓扑结构，在500米范围内将数据发送到集中式网关，网关通过4G模块实时上传到支持MQTT协议的云服务器。

Result: 实验室测试和现场部署表明，系统能够实现0.01g的加速度分辨率，维护成本降低约70%，监测效率提高5倍以上。系统为智能轨道健康管理提供了可靠手段。

Conclusion: 该系统成功解决了传统轨道检测的局限性，为铁路轨道智能化监测提供了有效解决方案。未来计划引入射频能量收集技术实现无电池自动唤醒，并扩展到城市桥梁、隧道和环境监测等多场景应用。

Abstract: With the rising volume of railroad transportation, the traditional track
inspection mainly relies on manual inspection and large-scale inspection
equipment, which not only has low inspection frequency and lagging response,
but also has the defects of high risk, high cost and easy to miss inspection.
To this end, this study designs and realizes a maintenance-free railroad track
wireless monitoring system based on LoRa module LM401. Each monitoring node
consists of an STM32 microcontroller, an LM401 LoRa transceiver, a low-power
ADXL362 triaxial acceleration sensor, a digital temperature sensor (LMT85), and
a digital barometric pressure sensor (RSCM17100KP101). The system collects
vibration data through the SPI1 interface at the node end, periodically reads
the temperature and barometric pressure information, and packages and sends the
data to a centralized gateway within a range of 500 m using the LoRa star
topology; the gateway then uploads the data in real time to a cloud server
through a 4G module, which supports the MQTT protocol. MQTT protocol is
supported. Laboratory tests and field deployments show that the system can
realize acceleration resolution of 0.01 g, reduce maintenance cost by about
70%, and improve monitoring efficiency by more than 5 times. The system
provides a reliable means for intelligent rail health management, and in the
future, it is planned to introduce RF energy collection technology to realize
automatic wake-up without battery, and expand to urban bridges, tunnels and
environmental monitoring and other multi-scenario applications.

</details>


### [234] [Ontological Definition of Seamless Digital Engineering Based on ISO/IEC 25000-Series SQuaRE Product Quality Model](https://arxiv.org/abs/2507.17171)
*James S. Wheaton,Daniel R. Herber*

Main category: eess.SY

TL;DR: 本文基于基础形式本体论(BFO)和通用核心本体论(CCO)构建了一个经过验证的一致性本体，定义了无缝数字工程作为数字工具范式，通过形式化验证数字接口来提供数字工程环境保证完整性的系统级认证。


<details>
  <summary>Details</summary>
Motivation: 数字工程概念自2018年引入以来，各组织和行业团体需要解释DE概念以建立一致的元模型用于DE流程和工具集成。现有国际标准（如ISO/IEC/IEEE系列）的概念协调仍需改进，需要通过Web本体语言(OWL 2 DL)的描述逻辑来更有效地实现。

Method: 基于基础形式本体论(BFO)和通用核心本体论(CCO)构建验证一致的本体论；定义类和等价公理，仅使用BFO和CCO定义的对象属性；通过案例研究正式定义与更新的ISO 25010 SQuaRE产品质量模型相关的"无缝"质量；使用BFO/CCO本体框架解决ISO元模型不一致性。

Result: 成功构建了定义无缝数字工程的本体论框架，识别并解决了ISO元模型的不一致性问题，将"无缝"定义为系统集成质量和人机界面使用质量两个方面，为未来DE相关本体论发展提供了基线分析。

Conclusion: 通过BFO/CCO本体框架成功定义了无缝数字工程概念，解决了数字工程环境中的概念歧义问题，为数字工程领域的标准化和工具集成提供了形式化基础，有助于建立一致的数字工程元模型和流程。

Abstract: Since the introduction of Digital Engineering (DE) as a well-defined concept
in 2018, organizations and industry groups have been working to interpret the
DE concepts to establish consistent meta-models of those interrelated concepts
for integration into their DE processes and tools. To reach the breadth and
depth of DE concept definitions, the interpretation of international standard
sources is necessary, including ISO/IEC/IEEE 15288, 24765, 42000-series, 15408,
15206, 27000-series, and 25000-series, to effectively model the knowledge
domain where digital engineering applies. The harmonization of the concepts
used in these international standards continues to improve with each revision,
but it may be more effectively accomplished by relying on the descriptive logic
formalized in the Web Ontology Language (OWL 2 DL). This paper presents a
verified and consistent ontology based on the Basic Formal Ontology (BFO) and
Common Core Ontologies (CCO) that defines Seamless Digital Engineering as a
digital tooling paradigm that relies on formal verification of digital
interfaces to provide a system-level qualification of the assured integrity of
a Digital Engineering Environment. The present work defines classes and
equivalence axioms, while using only the BFO- and CCO-defined object properties
that relate them, to provide a baseline analysis that may inform future
DE-related ontology development, using a case study to formally define the
`seamless' quality in relation to the updated ISO 25010 SQuaRE product quality
model. We identified ISO meta-model inconsistencies that are resolvable using
the BFO/CCO ontological framework, and define `seamless' as both a system
integration quality and a Human-Computer Interface quality-in-use, working to
disambiguate this concept in the context of DE.

</details>


### [235] [Dispatch-Aware Deep Neural Network for Optimal Transmission Switching: Toward Real-Time and Feasibility Guaranteed Operation](https://arxiv.org/abs/2507.17194)
*Minsoo Kim,Jip Kim*

Main category: eess.SY

TL;DR: 本文提出了一种调度感知深度神经网络(DA-DNN)来加速直流最优传输开关(DC-OTS)问题求解，通过预测线路状态并结合可微分DC-OPF层，在保证物理约束的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 最优传输开关(OTS)能够通过选择性开断传输线路来改善最优潮流(OPF)，但其混合整数规划形式增加了计算复杂度，特别是在大型电网中变得难以处理，因此需要一种既能保持OTS经济优势又具有可扩展性的求解方法。

Method: 提出调度感知深度神经网络(DA-DNN)，该网络预测线路状态并通过可微分DC-OPF层传递，使用生成成本作为损失函数，确保所有物理网络约束在训练和推理过程中得到满足。同时采用定制的权重-偏置初始化方法，使每次前向传播从第一次迭代开始就保持可行性。

Result: 训练完成后，DA-DNN能够在与求解DCOPF相同的时间内产生可证明可行的拓扑和调度对，而传统的混合整数求解器在大型电网上变得难以处理。该方法成功在大型电网上实现了稳定学习。

Conclusion: 所提出的方法成功捕获了OTS的经济优势，同时保持了良好的可扩展性，为大规模电网的最优传输开关问题提供了高效的求解方案。

Abstract: Optimal transmission switching (OTS) improves optimal power flow (OPF) by
selectively opening transmission lines, but its mixed-integer formulation
increases computational complexity, especially on large grids. To deal with
this, we propose a dispatch-aware deep neural network (DA-DNN) that accelerates
DC-OTS without relying on pre-solved labels. DA-DNN predicts line states and
passes them through a differentiable DC-OPF layer, using the resulting
generation cost as the loss function so that all physical network constraints
are enforced throughout training and inference. In addition, we adopt a
customized weight-bias initialization that keeps every forward pass feasible
from the first iteration, which allows stable learning on large grids. Once
trained, the proposed DA-DNN produces a provably feasible topology and dispatch
pair in the same time as solving the DCOPF, whereas conventional mixed-integer
solvers become intractable. As a result, the proposed method successfully
captures the economic advantages of OTS while maintaining scalability.

</details>


### [236] [On the Construction of Barrier Certificate: A Dynamic Programming Perspective](https://arxiv.org/abs/2507.17222)
*Yu Chen,Shaoyuan Li,Xiang Yin*

Main category: eess.SY

TL;DR: 本文重新审视了随机动态系统在有限时间范围内的形式化验证问题，提出了一种基于屏障证书的新方法，该方法比现有方法更加精确且保守性更低。


<details>
  <summary>Details</summary>
Motivation: 现有基于c-鞅的屏障证书方法在不安全状态上过于保守，导致安全概率界限不够紧致。需要从动态规划算子的角度重新理解现有方法的条件，并提出更精确的屏障证书条件。

Method: 从动态规划算子的角度分析现有鞅屏障证书条件，证明其本质上提供了动态规划解的界限。基于此新视角，提出了保守性更低的安全屏障证书条件，并将方法扩展到到达-避免规范。使用平方和(SOS)规划来搜索新的屏障证书。

Result: 提出的新屏障证书条件严格比现有条件保守性更低，为安全验证提供了更紧致的概率界限。成功将方法扩展到到达-避免规范，并通过两个数值实例验证了方法相比现有方法的优势。

Conclusion: 通过动态规划的新视角重新理解屏障证书，成功提出了保守性更低的屏障证书条件，为随机动态系统的形式化验证提供了更精确的方法，并在数值实验中展现了明显优势。

Abstract: In this paper, we revisit the formal verification problem for stochastic
dynamical systems over finite horizon using barrier certificates. Most existing
work on this topic focuses on safety properties by constructing barrier
certificates based on the notion of $c$-martingales. In this work, we first
provide a new insight into the conditions of existing martingale-based barrier
certificates from the perspective of dynamic programming operators.
Specifically, we show that the existing conditions essentially provide a bound
on the dynamic programming solution, which exactly characterizes the safety
probability. Based on this new perspective, we demonstrate that the barrier
conditions in existing approaches are unnecessarily conservative over unsafe
states. To address this, we propose a new set of safety barrier certificate
conditions that are strictly less conservative than existing ones, thereby
providing tighter probability bounds for safety verification. We further extend
our approach to the case of reach-avoid specifications by providing a set of
new barrier certificate conditions. We also illustrate how to search for these
new barrier certificates using sum-of-squares (SOS) programming. Finally, we
use two numerical examples to demonstrate the advantages of our method compared
to existing approaches.

</details>


### [237] [Integrating Grid impedance estimation method into Advanced Angle Estimation Kalman Filter in GFL inverter](https://arxiv.org/abs/2507.17325)
*Phuoc Sang Nguyen,Ghavameddin Nourbakhsh,Gerard Ledwich*

Main category: eess.SY

TL;DR: 本文提出了一种基于离散傅里叶变换的实时电网阻抗估计方法，与AAEKF-LQR控制器集成，用于改善并网逆变器系统在弱电网条件下的稳定性和相角估计精度。


<details>
  <summary>Details</summary>
Motivation: 随着电力电子变换器接口的分布式能源资源在现代电力系统中的日益集成，给系统监测、保护和控制带来了重大挑战。电网阻抗在并网逆变器系统的运行和稳定性评估中起着关键作用，因此需要准确的实时电网阻抗估计方法。

Method: 提出了一种基于离散傅里叶变换（DFT）的实时电网阻抗估计方法，并将其与使用线性二次调节器电流控制器的高级角度估计卡尔曼滤波器（AAEKF-LQR）集成，利用阻抗信息辅助精确的瞬时相角估计。

Result: 仿真结果证实所提出的阻抗估计方法与AAEKF-LQR控制器有效交互，在弱电网条件下保持稳定的系统性能。该方法还展示了在电网条件运行变化期间提供快速准确阻抗估计的能力。

Conclusion: 所提出的方法能够支持稳定的逆变器运行，通过准确的实时电网阻抗估计和相角估计，有效应对弱电网条件下的挑战，为现代电力系统中分布式能源资源的稳定集成提供了技术支持。

Abstract: The growing integration of power electronic converter-interfaced distributed
energy resources into modern power systems presents significant challenges for
system monitoring, protection, and control. Grid impedance plays a critical
role in the operation and stability assessment of grid-connected inverter
systems. This study presents a real-time grid impedance estimation method based
on the Discrete Fourier Transform. The proposed method is integrated with the
Advanced Angle Estimation Kalman Filter using a Linear Quadratic Regulator
current controller (AAEKF-LQR), assisting the use of impedance information for
accurate instantaneous phase angle estimation. Simulation results confirm that
the proposed impedance estimation method interacts effectively with the
AAEKF-LQR controller, maintaining stable system performance under weak grid
conditions. The approach also demonstrates the ability to deliver fast and
accurate impedance estimation during operational variations in grid conditions,
thereby supporting stable inverter operation.

</details>


### [238] [Optimizing Car Resequencing on Mixed-Model Assembly Lines: Algorithm Development and Deployment](https://arxiv.org/abs/2507.17422)
*Andreas Karrenbauer,Bernd Kuhn,Kurt Mehlhorn,Paolo Luigi Rinaldi*

Main category: eess.SY

TL;DR: 本文提出了一种多目标算法来解决混合装配线(MMAL)的重新排序问题，在福特汽车厂实际部署后，实现了批次大小提升30%、换色次数减少23%、交付延误风险降低10%的显著改进。


<details>
  <summary>Details</summary>
Motivation: 混合装配线虽然能在同一条生产线上制造不同车型，提供高度的产品定制化和灵活性，但也带来了挑战：需要找到满足多重约束和目标的最优模型序列，包括最小化喷漆车间的换色次数、平衡装配线工作负载和设置时间、满足客户需求和交付期限等复杂问题。

Method: 提出了一种多目标算法来同时考虑所有相关方面，解决混合装配线的重新排序问题。该算法能够综合处理生产性能、质量和交付等多个目标的优化。

Result: 在福特汽车萨尔路易斯工厂部署4周后的实证结果显示：平均批次大小改善约30%，换色次数减少23%，特定日期计划车辆的分散度降低10%，从而减少了交付延误的风险。

Conclusion: 该算法在改善生产性能和质量方面表现出有效性和鲁棒性，同时文中也讨论了算法的权衡取舍和局限性，证明了多目标优化方法在实际工业生产中的应用价值。

Abstract: The mixed-model assembly line (MMAL) is a production system used in the
automobile industry to manufacture different car models on the same conveyor,
offering a high degree of product customization and flexibility. However, the
MMAL also poses challenges, such as finding optimal sequences of models
satisfying multiple constraints and objectives related to production
performance, quality, and delivery -- including minimizing the number of color
changeovers in the Paint Shop, balancing the workload and setup times on the
assembly line, and meeting customer demand and delivery deadlines. We propose a
multi-objective algorithm to solve the MMAL resequencing problem under
consideration of all these aspects simultaneously. We also present empirical
results obtained from recorded event data of the production process over $4$
weeks following the deployment of our algorithm in the Saarlouis plant of
Ford-Werke GmbH. We achieved an improvement of the average batch size of about
$30\%$ over the old control software translating to a $23\%$ reduction of color
changeovers. Moreover, we reduced the spread of cars planned for a specific
date by $10\%$, reducing the risk of delays in delivery. We discuss
effectiveness and robustness of our algorithm in improving production
performance and quality as well as trade-offs and limitations.

</details>


### [239] [Output Feedback Design for Parameter Varying Systems subject to Persistent Disturbances and Control Rate Constraints](https://arxiv.org/abs/2507.17475)
*Jackson G. Ernesto,Eugenio B. Castelan,Walter Lucia*

Main category: eess.SY

TL;DR: 本文提出了一种针对受持续扰动约束的线性参数变化系统的输出反馈控制器设计技术，通过鲁棒正不变集概念和扩展Farkas引理，解决控制速率、状态和控制幅值约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有的线性参数变化系统控制方法在面对持续扰动和多重约束（控制速率约束、状态约束、控制幅值约束）时存在局限性，需要开发能够同时处理这些约束条件的鲁棒输出反馈控制策略。

Method: 开发增量参数变化输出反馈控制律，基于鲁棒正不变集概念，应用扩展Farkas引理推导代数条件来定义控制增益和满足约束的鲁棒正不变多面体，将问题转化为双线性优化问题来确定输出反馈增益和相关的多面体鲁棒正不变区域。

Result: 获得的控制器确保从多面体出发的任何闭环轨迹在有限时间内收敛到原点周围更小的内部多面体集合，轨迹在持续扰动和系统参数变化下保持最终有界。优化方法还能同时扩大外部集合并最小化内部集合。

Conclusion: 所提出的输出反馈控制器设计方法能够有效处理线性参数变化系统中的多重约束、持续扰动和参数变化问题，通过数值例子验证了方法的有效性，为约束系统的鲁棒控制提供了新的解决方案。

Abstract: This paper presents a technique for designing output feedback controllers for
constrained linear parameter-varying systems that are subject to persistent
disturbances. Specifically, we develop an incremental parameter-varying output
feedback control law to address control rate constraints, as well as state and
control amplitude constraints. The proposal is based on the concept of robust
positively invariant sets and applies the extended Farkas' lemma to derive a
set of algebraic conditions that define both the control gains and a robust
positively invariant polyhedron that satisfies the control and state
constraints. These algebraic conditions are formulated into a bilinear
optimization problem aimed at determining the output feedback gains and the
associated polyedral robust positively invariant region. The obtained
controller ensures that any closed-loop trajectory originating from the
polyhedron converges to another smaller inner polyhedral set around the origin
in finite time, where the trajectory remains ultimately bounded regardless of
the persistent disturbances and variations in system parameters. Furthermore,
by including the sizes of the two polyhedral sets inside the objective
function, the proposed optimization can also jointly enlarge the outer set
while minimizing the inner one. Numerical examples are presented to demonstrate
the effectiveness of our proposal in managing the specified constraints,
disturbances, and parameter variations.

</details>


### [240] [Integrating Physics-Based and Data-Driven Approaches for Probabilistic Building Energy Modeling](https://arxiv.org/abs/2507.17526)
*Leandro Von Krannichfeldt,Kristina Orehounig,Olga Fink*

Main category: eess.SY

TL;DR: 本研究评估了五种混合方法在概率建筑能耗建模中的表现，发现残差学习与前馈神经网络组合效果最佳，并证明了分位数保形预测在室内温度建模中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的混合建筑能耗建模方法主要关注确定性建模，忽略了天气波动和居住者行为等因素造成的不确定性，且缺乏在概率建模框架内的系统性比较。

Method: 评估五种代表性混合方法进行概率建筑能耗建模，重点关注真实案例研究中建筑热力学的分位数预测，并使用分位数保形预测来校准预测结果。

Result: 残差学习与前馈神经网络的组合在平均性能上表现最佳，是唯一能在分布外测试数据上产生物理直观预测的模型。分位数保形预测在室内温度建模的分位数预测校准中表现有效。

Conclusion: 混合方法的性能因建筑房间类型而异，但残差学习方法整体表现最优且具有更好的物理可解释性。分位数保形预测是校准室内温度建模分位数预测的有效工具。

Abstract: Building energy modeling is a key tool for optimizing the performance of
building energy systems. Historically, a wide spectrum of methods has been
explored -- ranging from conventional physics-based models to purely
data-driven techniques. Recently, hybrid approaches that combine the strengths
of both paradigms have gained attention. These include strategies such as
learning surrogates for physics-based models, modeling residuals between
simulated and observed data, fine-tuning surrogates with real-world
measurements, using physics-based outputs as additional inputs for data-driven
models, and integrating the physics-based output into the loss function the
data-driven model. Despite this progress, two significant research gaps remain.
First, most hybrid methods focus on deterministic modeling, often neglecting
the inherent uncertainties caused by factors like weather fluctuations and
occupant behavior. Second, there has been little systematic comparison within a
probabilistic modeling framework. This study addresses these gaps by evaluating
five representative hybrid approaches for probabilistic building energy
modeling, focusing on quantile predictions of building thermodynamics in a
real-world case study. Our results highlight two main findings. First, the
performance of hybrid approaches varies across different building room types,
but residual learning with a Feedforward Neural Network performs best on
average. Notably, the residual approach is the only model that produces
physically intuitive predictions when applied to out-of-distribution test data.
Second, Quantile Conformal Prediction is an effective procedure for calibrating
quantile predictions in case of indoor temperature modeling.

</details>


### [241] [Model Predictive Control for Unlocking Energy Flexibility of Heat Pump and Thermal Energy Storage Systems: Experimental Results](https://arxiv.org/abs/2507.17552)
*Weihong Tang,Yun Li,Shalika Walker,Tamas Keviczky*

Main category: eess.SY

TL;DR: 本文提出了一个基于模型预测控制(MPC)的热泵热储能系统(HPTES)需求侧管理策略，通过两步框架实现灵活性评估和利用，以缓解可再生能源渗透率增加带来的电网拥堵问题。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源渗透率增加和能源系统电气化，需要通过需求侧管理来缓解电网拥堵。热泵热储能系统作为高效节能解决方案，在家庭电力消耗中占重要份额，有望为需求侧管理做出贡献。

Method: 提出了一个系统性设计框架，包括面向控制的建模过程和能量灵活的模型预测控制设计。采用两步需求侧管理框架：第一步通过求解混合整数经济MPC问题进行灵活性评估；第二步通过响应可行的需求响应请求实现灵活性利用，同时满足系统约束。

Result: 基于真实HPTES安装进行了数值仿真和实际实验，验证了所提设计的可行性和有效性。实验结果展示了该MPC策略在实际应用中的表现。

Conclusion: 所提出的基于MPC的需求侧管理策略为HPTES系统提供了创新的高效DSM解决方案，能够有效评估和利用系统的灵活性潜力，为缓解电网拥堵问题提供了可行的技术路径。

Abstract: Increasing penetration of renewable energy sources (RES) and electrification
of energy systems necessitates the engagement of demand-side management (DSM)
to help alleviate congestion in electricity grid. Heat pump and thermal energy
storage (HPTES) systems, being energy efficient solutions, are becoming popular
in modern buildings and are promising to contribute to demand-side management
(DSM) due to their significant share in household electricity consumption. For
typical HPTES systems, this paper presents a systematic design framework
covering a control-oriented modeling process and energy-flexible model
predictive control (MPC) design. The proposed MPC-based DSM strategy offers an
innovative solution for efficient DSM by following a two-step DSM framework. In
the first step, flexibility assessment is performed to quantitatively evaluate
the flexibility potential of the HPTES system by solving a mixed-integer
economic MPC problem. In the second step, flexibility exploitation is achieved
through reacting to feasible demand response (DR) requests while respecting
system constraints. Both numerical simulations and real-world experiments are
performed based on a real HPTES installation to showcase the viability and
effectiveness of the proposed design.

</details>


### [242] [A Joint Planning Model for Fixed and Mobile Electric Vehicle Charging Stations Considering Flexible Capacity Strategy](https://arxiv.org/abs/2507.17587)
*Zhe Yu,Xue Hu,Qin Wang*

Main category: eess.SY

TL;DR: 提出了一个两阶段联合规划模型，用于固定充电站和移动充电站的协同规划，采用改进的ADMM算法来优化电动汽车充电系统的社会成本，同时保障电力供应可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车的广泛普及，对交通和电力系统的需求显著增加，给系统稳定运行带来挑战。需要通过固定充电站和移动充电站的协同规划来支持日益增长的电动汽车充电需求，将大规模电动汽车集成的潜在负面影响转化为正面效果。

Method: 采用两阶段联合规划模型：第一阶段开发固定充电站选址评估框架，包括电动汽车承载能力和电压稳定性评估；第二阶段建立固定充电站和移动充电站联合规划模型。使用改进的ADMM算法结合混合整数线性规划、排队理论和序列二次规划来求解。引入耦合约束实现选址和容量配置决策的一致性，支持分布式优化框架。

Result: 通过案例研究和对比实验验证了所提出模型和求解方法的有效性。该方法能够协调电动汽车用户、移动充电站运营商和配电系统运营商的利益，实现多方利益相关者的协同合作。提出的灵活容量规划策略考虑了充电站的多期发展潜力，降低了固定充电站建设的复杂性和投资需求。

Conclusion: 所提出的两阶段联合规划模型能够有效地将大规模电动汽车集成的挑战转化为机遇，通过多方利益相关者的协同合作提升社会福利。改进的ADMM算法为固定充电站和移动充电站的联合规划提供了有效的求解方案，实现了充电系统社会成本的最小化和电力供应可靠性的保障。

Abstract: The widespread adoption of electric vehicles (EVs) has significantly
increased demand on both transportation and power systems, posing challenges to
their stable operation. To support the growing need for EV charging, both fixed
charging stations (FCSs) and mobile charging stations (MCSs) have been
introduced, serving as key interfaces between the power grid and traffic
network. Recognizing the importance of collaborative planning across these
sectors, this paper presents a two-stage joint planning model for FCSs and
MCSs, utilizing an improved alternating direction method of multipliers (ADMM)
algorithm. The primary goal of the proposed model is to transform the potential
negative impacts of large-scale EV integration into positive outcomes, thereby
enhancing social welfare through collaboration among multiple stakeholders. In
the first stage, we develop a framework for evaluating FCS locations,
incorporating assessments of EV hosting capacity and voltage stability. The
second stage introduces a joint planning model for FCSs and MCSs, aiming to
minimize the overall social costs of the EV charging system while maintaining a
reliable power supply. To solve the planning problem, we employ a combination
of mixed-integer linear programming, queueing theory, and sequential quadratic
programming. The improved ADMM algorithm couples the siting and sizing
decisions consistently by introducing coupling constraints, and supports a
distributed optimization framework that coordinates the interests of EV users,
MCS operators, and distribution system operators. Additionally, a flexible
capacity planning strategy that accounts for the multi-period development
potential of EVCS is proposed to reduce both the complexity and the investment
required for FCS construction. Finally, a case study with comparative
experiments demonstrates the effectiveness of the proposed models and solution
methods.

</details>


### [243] [Toward Federated DeePC: borrowing data from similar systems](https://arxiv.org/abs/2507.17610)
*Gert Vankan,Valentina Breschi,Simone Formentin*

Main category: eess.SY

TL;DR: 本文提出了一种联邦化的数据驱动预测控制方法（federated DeePC），通过利用多个相似系统的输入/输出轨迹数据来改进预测控制性能，并通过数值实验分析了这种方法的潜在优势和可能的缺点。


<details>
  <summary>Details</summary>
Motivation: 传统的数据驱动预测控制（DeePC）方法通常只使用被控系统自身的数据，但随着系统连接性的增强以及大规模生产系统的固有相似性，可以利用来自多个相似系统的大量信息来改进控制任务的执行效果。

Method: 提出了DeePC的联邦化扩展版本，该方法结合利用来自多个相似系统的输入/输出轨迹数据进行预测控制设计，而不仅仅依赖单一被控系统的数据。

Result: 通过一系列数值实验验证了所提方法的有效性，展示了利用相似系统信息的潜在优势，同时也识别出了可能存在的缺点和局限性。

Conclusion: 联邦化DeePC方法能够有效利用多个相似系统的数据来改进预测控制性能，为数据驱动控制领域提供了新的发展方向，但在实际应用中需要权衡其优势和潜在风险。

Abstract: Data-driven predictive control approaches, in general, and Data-enabled
Predictive Control (DeePC), in particular, exploit matrices of raw input/output
trajectories for control design. These data are typically gathered only from
the system to be controlled. Nonetheless, the increasing connectivity and
inherent similarity of (mass-produced) systems have the potential to generate a
considerable amount of information that can be exploited to undertake a control
task. In light of this, we propose a preliminary federated extension of DeePC
that leverages a combination of input/output trajectories from multiple similar
systems for predictive control. Supported by a suite of numerical examples, our
analysis unveils the potential benefits of exploiting information from similar
systems and its possible downsides.

</details>


### [244] [Learning clusters of partially observed linear dynamical systems](https://arxiv.org/abs/2507.17638)
*Maryann Rui,Munther A. Dahleh*

Main category: eess.SY

TL;DR: 本文研究了从多个输入输出轨迹中学习部分观测线性动力系统聚类的问题，提出了一种两阶段算法：先从个体轨迹估计短脉冲响应并聚类，再利用多个轨迹联合估计每个聚类的精细模型。


<details>
  <summary>Details</summary>
Motivation: 当单个数据源的观测有限（如短轨迹）时，直接估计具有挑战性。通过整合多个相关数据源的数据可以改善学习效果，特别是在部分观测线性动力系统的聚类学习场景中。

Method: 提出一种两阶段估计算法：第一阶段从个体轨迹估计短脉冲响应并进行聚类；第二阶段利用聚类和系统识别任务的不同数据需求，使用多个轨迹联合估计每个聚类的精细模型。

Result: 建立了估计马尔可夫参数和状态空间实现的端到端有限样本保证，并揭示了观测系统数量、轨迹长度和底层模型复杂性之间的权衡关系。

Conclusion: 该算法能够有效处理短轨迹数据的聚类和系统识别问题，通过两阶段方法充分利用不同任务的数据需求特点，在理论上提供了有限样本保证并明确了关键参数间的权衡。

Abstract: We study the problem of learning clusters of partially observed linear
dynamical systems from multiple input-output trajectories. This setting is
particularly relevant when there are limited observations (e.g., short
trajectories) from individual data sources, making direct estimation
challenging. In such cases, incorporating data from multiple related sources
can improve learning. We propose an estimation algorithm that leverages
different data requirements for the tasks of clustering and system
identification. First, short impulse responses are estimated from individual
trajectories and clustered. Then, refined models for each cluster are jointly
estimated using multiple trajectories. We establish end-to-end finite sample
guarantees for estimating Markov parameters and state space realizations and
highlight trade-offs among the number of observed systems, the trajectory
lengths, and the complexity of the underlying models.

</details>


### [245] [Piecewise Control Barrier Functions for Stochastic Systems](https://arxiv.org/abs/2507.17703)
*Rayan Mazouz,Luca Laurenti,Morteza Lahijanian*

Main category: eess.SY

TL;DR: 本文提出了一种同时合成障碍证书和安全控制器的方法，用于离散时间非线性随机系统，通过分段随机控制障碍函数将合成问题转化为极小极大优化，并使用零间隙对偶线性规划精确求解。


<details>
  <summary>Details</summary>
Motivation: 现有方法在为离散时间非线性随机系统设计安全控制器时，往往将障碍证书和控制器的合成分开进行，缺乏统一的框架来同时优化两者，且难以为随机系统提供形式化的概率安全保证。

Method: 基于分段随机控制障碍函数的方法，将障碍证书和安全控制器的联合合成问题转化为极小极大优化问题，然后使用零间隙对偶线性规划进行精确求解。该方法适用于具有加性噪声的随机动力学和有界连续控制集。

Result: 合成的控制器和障碍证书能够为概率安全性提供形式化保证的下界。通过线性和非线性随机系统的案例研究验证了方法的有效性。

Conclusion: 提出的方法成功实现了障碍证书和安全控制器的同时合成，为离散时间非线性随机系统提供了具有形式化概率安全保证的统一框架，并通过案例研究证明了其实用性和有效性。

Abstract: This paper presents a method for the simultaneous synthesis of a barrier
certificate and a safe controller for discrete-time nonlinear stochastic
systems. Our approach, based on piecewise stochastic control barrier functions,
reduces the synthesis problem to a minimax optimization, which we solve exactly
using a dual linear program with zero gap. This enables the joint optimization
of the barrier certificate and safe controller within a single formulation. The
method accommodates stochastic dynamics with additive noise and a bounded
continuous control set. The synthesized controllers and barrier certificates
provide a formally guaranteed lower bound on probabilistic safety. Case studies
on linear and nonlinear stochastic systems validate the effectiveness of our
approach.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [246] [Weak Supervision Techniques towards Enhanced ASR Models in Industry-level CRM Systems](https://arxiv.org/abs/2507.16843)
*Zhongsheng Wang,Sijie Wang,Jia Wang,Yung-I Liang,Yuxi Zhang,Jiamou Liu*

Main category: cs.SD

TL;DR: 本文提出了一种针对客户关系管理(CRM)系统的行业特定自动语音识别(ASR)模型微调解决方案，显著提升了ASR模型在行业应用中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 在CRM系统设计中，准确识别客户类型并提供个性化服务是提升客户满意度和忠诚度的关键，但通用预训练ASR模型难以有效处理行业特定的语音识别任务，存在识别客户语音和意图的挑战。

Method: 创新性地提出了一种行业特定ASR模型的微调解决方案，通过针对性的模型优化来改善ASR在特定行业场景下的识别效果。

Result: 实验结果表明，该方法显著提升了微调后ASR模型在行业应用中的性能，大幅改善了ASR模型在行业CRM系统中的关键辅助作用。

Conclusion: 所提出的行业特定ASR模型微调方案有效解决了通用ASR模型在行业应用中的局限性，已被实际工业应用采用，为CRM系统中的客户语音识别提供了实用的技术解决方案。

Abstract: In the design of customer relationship management (CRM) systems, accurately
identifying customer types and offering personalized services are key to
enhancing customer satisfaction and loyalty. However, this process faces the
challenge of discerning customer voices and intentions, and general pre-trained
automatic speech recognition (ASR) models make it difficult to effectively
address industry-specific speech recognition tasks. To address this issue, we
innovatively proposed a solution for fine-tuning industry-specific ASR models,
which significantly improved the performance of the fine-tuned ASR models in
industry applications. Experimental results show that our method substantially
improves the crucial auxiliary role of the ASR model in industry CRM systems,
and this approach has also been adopted in actual industrial applications.

</details>


### [247] [On Temporal Guidance and Iterative Refinement in Audio Source Separation](https://arxiv.org/abs/2507.17297)
*Tobias Morocutti,Jonathan Greif,Paul Primus,Florian Schmid,Gerhard Widmer*

Main category: cs.SD

TL;DR: 本文提出了一种新的空间语义音频场景分割(S5)方法，通过增强事件检测和声源分离阶段的协同作用，显著提升了音频标注和声源分离性能，在DCASE Challenge 2025任务4中获得第二名。


<details>
  <summary>Details</summary>
Motivation: 传统的空间语义音频场景分割系统采用两阶段流水线（音频标注+标签条件声源分离），但缺乏有效分离所需的细粒度时间信息，限制了系统性能。

Method: 提出三个关键贡献：1）微调预训练Transformer进行活跃声音类别检测；2）使用该微调Transformer的独立实例执行声音事件检测(SED)，为分离模块提供详细的时变指导；3）实现迭代优化机制，通过递归重用分离器前次迭代的输出来逐步提升分离质量。

Result: 在音频标注和声源分离性能方面取得显著改进，在DCASE Challenge 2025任务4中获得第二名的成绩。

Conclusion: 通过增强事件检测和声源分离阶段的协同作用，提出的方法有效解决了传统两阶段流水线缺乏细粒度时间信息的问题，显著提升了空间语义音频场景分割的整体性能。

Abstract: Spatial semantic segmentation of sound scenes (S5) involves the accurate
identification of active sound classes and the precise separation of their
sources from complex acoustic mixtures. Conventional systems rely on a
two-stage pipeline - audio tagging followed by label-conditioned source
separation - but are often constrained by the absence of fine-grained temporal
information critical for effective separation. In this work, we address this
limitation by introducing a novel approach for S5 that enhances the synergy
between the event detection and source separation stages. Our key contributions
are threefold. First, we fine-tune a pre-trained Transformer to detect active
sound classes. Second, we utilize a separate instance of this fine-tuned
Transformer to perform sound event detection (SED), providing the separation
module with detailed, time-varying guidance. Third, we implement an iterative
refinement mechanism that progressively enhances separation quality by
recursively reusing the separator's output from previous iterations. These
advancements lead to significant improvements in both audio tagging and source
separation performance, as demonstrated by our system's second-place finish in
Task 4 of the DCASE Challenge 2025. Our implementation and model checkpoints
are available in our GitHub repository: https://github.com/theMoro/dcase25task4 .

</details>


### [248] [Application of Whisper in Clinical Practice: the Post-Stroke Speech Assessment during a Naming Task](https://arxiv.org/abs/2507.17326)
*Milena Davudova,Ziyuan Cai,Valentina Giunchiglia,Dragos C. Gruia,Giulia Sanguedolce,Adam Hampshire,Fatemeh Geranmayeh*

Main category: cs.SD

TL;DR: 本研究评估了Whisper语音识别基础模型在中风患者语言障碍评估中的应用效果，发现经过微调的Whisper在转录准确性和语言功能预测方面表现良好，但在跨域泛化能力上存在局限性。


<details>
  <summary>Details</summary>
Motivation: 中风后语言障碍的详细评估仍然是一项认知复杂且需要大量临床医生参与的任务，限制了及时和可扩展的诊断。需要探索自动语音识别基础模型是否能够通过智能系统增强人工评估，但其在语音和语言障碍背景下的有效性仍不确定。

Method: 使用Whisper这一最先进的自动语音识别基础模型，对中风患者在常用图片命名任务中的语音进行转录和分析。评估了逐字转录准确性和模型支持下游语言功能预测的能力，并通过微调来改善模型性能。

Result: 基线Whisper模型在单词语音话语上表现较差，但微调后显著提高了转录准确性（健康语音的词错误率降低87.72%，患者语音降低71.22%）。模型的学习表征能够准确预测语音质量（健康人群平均F1宏观得分0.74，患者0.75）。然而，在未见过的TORGO数据集上评估显示泛化能力有限。

Conclusion: 虽然在跨域泛化方面仍存在挑战，但研究结果表明，经过适当微调的基础模型具有推进中风相关语言障碍自动化语音和语言评估及康复的潜力。强调了需要将模型适应特定临床人群的重要性。

Abstract: Detailed assessment of language impairment following stroke remains a
cognitively complex and clinician-intensive task, limiting timely and scalable
diagnosis. Automatic Speech Recognition (ASR) foundation models offer a
promising pathway to augment human evaluation through intelligent systems, but
their effectiveness in the context of speech and language impairment remains
uncertain. In this study, we evaluate whether Whisper, a state-of-the-art ASR
foundation model, can be applied to transcribe and analyze speech from patients
with stroke during a commonly used picture-naming task. We assess both verbatim
transcription accuracy and the model's ability to support downstream prediction
of language function, which has major implications for outcomes after stroke.
Our results show that the baseline Whisper model performs poorly on single-word
speech utterances. Nevertheless, fine-tuning Whisper significantly improves
transcription accuracy (reducing Word Error Rate by 87.72% in healthy speech
and 71.22% in speech from patients). Further, learned representations from the
model enable accurate prediction of speech quality (average F1 Macro of 0.74
for healthy, 0.75 for patients). However, evaluations on an unseen (TORGO)
dataset reveal limited generalizability, highlighting the inability of Whisper
to perform zero-shot transcription of single-word utterances on out-of-domain
clinical speech and emphasizing the need to adapt models to specific clinical
populations. While challenges remain in cross-domain generalization, these
findings highlight the potential of foundation models, when appropriately
fine-tuned, to advance automated speech and language assessment and
rehabilitation for stroke-related impairments.

</details>


### [249] [BoSS: Beyond-Semantic Speech](https://arxiv.org/abs/2507.17563)
*Qing Wang,Zehan Li,Hang Lv,Hongjie Chen,Yaodong Song,Jian Kang,Jie Lian,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.SD

TL;DR: 本文提出了Beyond-Semantic Speech (BoSS)框架，用于捕获语音交流中超越显式语义的信息（如情感、语境等），并建立了分层的语音交互系统能力等级(L1-L5)来评估语音智能的发展水平。


<details>
  <summary>Details</summary>
Motivation: 现有语音技术（如ASR和TTS）往往无法捕获语音交流中的隐式信号和语境线索，这些超语义维度对于理解真正的交流意图至关重要，因此需要建立新的框架来表征和评估更高级的语音智能能力。

Method: 提出了Spoken Interaction System Capability Levels (L1-L5)分层框架来描述语音对话系统的演进；建立了Beyond-Semantic Speech (BoSS)形式化框架，利用认知相关性理论和机器学习模型分析时间和语境的语音动态；从五个不同维度评估BoSS相关属性。

Result: 评估结果显示，当前的口语语言模型(SLMs)难以完全解释超语义信号，在处理情感线索、语境动态和隐式语义等多维特征方面存在不足。

Conclusion: 研究强调了推进BoSS研究的必要性，以实现更丰富、更具语境感知能力的人机交流，为未来语音技术发展指明了从基础命令识别向类人社交互动演进的方向。

Abstract: Human communication involves more than explicit semantics, with implicit
signals and contextual cues playing a critical role in shaping meaning.
However, modern speech technologies, such as Automatic Speech Recognition (ASR)
and Text-to-Speech (TTS) often fail to capture these beyond-semantic
dimensions. To better characterize and benchmark the progression of speech
intelligence, we introduce Spoken Interaction System Capability Levels (L1-L5),
a hierarchical framework illustrated the evolution of spoken dialogue systems
from basic command recognition to human-like social interaction. To support
these advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which
refers to the set of information in speech communication that encompasses but
transcends explicit semantics. It conveys emotions, contexts, and modifies or
extends meanings through multidimensional features such as affective cues,
contextual dynamics, and implicit semantics, thereby enhancing the
understanding of communicative intentions and scenarios. We present a
formalized framework for BoSS, leveraging cognitive relevance theories and
machine learning models to analyze temporal and contextual speech dynamics. We
evaluate BoSS-related attributes across five different dimensions, reveals that
current spoken language models (SLMs) are hard to fully interpret
beyond-semantic signals. These findings highlight the need for advancing BoSS
research to enable richer, more context-aware human-machine communication.

</details>


### [250] [Audio-Vision Contrastive Learning for Phonological Class Recognition](https://arxiv.org/abs/2507.17682)
*Daiqi Liu,Tomás Arias-Vergara,Jana Hutter,Andreas Maier,Paula Andrea Pérez-Toro*

Main category: cs.SD

TL;DR: 本文提出了一个结合实时磁共振成像(rtMRI)和语音信号的多模态深度学习框架，用于分类发音的关键维度，在USC-TIMIT数据集上通过对比学习方法达到了0.81的F1分数，比单模态基线提升了0.23。


<details>
  <summary>Details</summary>
Motivation: 准确分类发音-音韵特征对理解人类语音产生和开发稳健的语音技术至关重要，特别是在临床环境中，针对性的音素分析和治疗可以提高疾病诊断准确性和个性化康复效果。

Method: 提出多模态深度学习框架，结合实时磁共振成像(rtMRI)和语音信号，对发音方式、发音部位和声化三个关键发音维度进行分类。评估了四种音频/视觉配置：单模态rtMRI、单模态音频信号、多模态中间融合和基于对比学习的音频-视觉融合。

Result: 在USC-TIMIT数据集上的实验结果显示，基于对比学习的方法达到了最先进的性能，平均F1分数为0.81，比单模态基线绝对提升了0.23。

Conclusion: 结果证实了对比表征学习在多模态发音分析中的有效性。研究团队将公开发布代码和处理后的数据集以支持未来的研究。

Abstract: Accurate classification of articulatory-phonological features plays a vital
role in understanding human speech production and developing robust speech
technologies, particularly in clinical contexts where targeted phonemic
analysis and therapy can improve disease diagnosis accuracy and personalized
rehabilitation. In this work, we propose a multimodal deep learning framework
that combines real-time magnetic resonance imaging (rtMRI) and speech signals
to classify three key articulatory dimensions: manner of articulation, place of
articulation, and voicing. We perform classification on 15 phonological classes
derived from the aforementioned articulatory dimensions and evaluate the system
with four audio/vision configurations: unimodal rtMRI, unimodal audio signals,
multimodal middle fusion, and contrastive learning-based audio-vision fusion.
Experimental results on the USC-TIMIT dataset show that our contrastive
learning-based approach achieves state-of-the-art performance, with an average
F1-score of 0.81, representing an absolute increase of 0.23 over the unimodal
baseline. The results confirm the effectiveness of contrastive representation
learning for multimodal articulatory analysis. Our code and processed dataset
will be made publicly available at
https://github.com/DaE-plz/AC_Contrastive_Phonology to support future research.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [251] [Budget Allocation Policies for Real-Time Multi-Agent Path Finding](https://arxiv.org/abs/2507.16874)
*Raz Beck,Roni Stern*

Main category: cs.MA

TL;DR: 研究了实时多智能体路径规划(RT-MAPF)中的规划预算分配策略，发现将预算分配给各个智能体比共享预算池的基线方法更有效


<details>
  <summary>Details</summary>
Motivation: 现有的RT-MAPF解决方案在每个规划周期中迭代调用MAPF算法的窗口化版本，但没有明确考虑规划预算的大小，存在研究空白需要填补

Method: 探索了在标准MAPF算法(优先级规划PrP和MAPF-LNS2)的窗口化版本中分配规划预算的不同策略，对比了共享预算池和预算分配给各智能体的方法

Result: 基线方法(所有智能体从共享规划预算池中提取)在过度约束情况下效果不佳，而将规划预算分配给各智能体的策略能够以更小的完工时间解决更多问题

Conclusion: 在RT-MAPF中，将规划预算分配给各个智能体的策略比共享预算池的方法更有效，特别是在过度约束的环境中表现更好

Abstract: Multi-Agent Pathfinding (MAPF) is the problem of finding paths for a set of
agents such that each agent reaches its desired destination while avoiding
collisions with the other agents. Many MAPF solvers are designed to run
offline, that is, first generate paths for all agents and then execute them.
Real-Time MAPF (RT-MAPF) embodies a realistic MAPF setup in which one cannot
wait until a complete path for each agent has been found before they start to
move. Instead, planning and execution are interleaved, where the agents must
commit to a fixed number of steps in a constant amount of computation time,
referred to as the planning budget. Existing solutions to RT-MAPF iteratively
call windowed versions of MAPF algorithms in every planning period, without
explicitly considering the size of the planning budget. We address this gap and
explore different policies for allocating the planning budget in windowed
versions of standard MAPF algorithms, namely Prioritized Planning (PrP) and
MAPF-LNS2. Our exploration shows that the baseline approach in which all agents
draw from a shared planning budget pool is ineffective in over-constrained
situations. Instead, policies that distribute the planning budget over the
agents are able to solve more problems with a smaller makespan.

</details>


### [252] [Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems](https://arxiv.org/abs/2507.17061)
*Chengxuan Xia,Qianye Wu,Sixuan Tian,Yilun Hao*

Main category: cs.MA

TL;DR: 本文提出了一个自适应多智能体协调框架，通过动态任务路由、双向反馈和并行智能体评估三个核心机制，显著提升了大语言模型智能体在复杂开放任务中的协作效果。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体框架往往依赖静态工作流、固定角色和有限的智能体间通信，这降低了它们在开放式、高复杂度领域中的有效性。因此需要一个更加灵活自适应的协调框架来解决这些局限性。

Method: 提出了一个基于三个核心机制的协调框架：1）动态任务路由 - 允许智能体根据置信度和工作负载重新分配任务；2）双向反馈 - 交换结构化批评以迭代改进输出；3）并行智能体评估 - 在高歧义子任务上进行竞争，通过评估器驱动选择最合适的结果。将这些原则实例化为模块化架构。

Result: 与静态和部分自适应基线相比，该框架在事实覆盖率、连贯性和效率方面都取得了显著改进。实验结果证明了自适应性和结构化竞争机制的有效性。

Conclusion: 研究发现在多智能体大语言模型系统中结合自适应性和结构化竞争具有显著优势，为构建更高效的协作智能体系统提供了新的思路和方法。

Abstract: Large language model (LLM) agents have shown increasing promise for
collaborative task completion. However, existing multi-agent frameworks often
rely on static workflows, fixed roles, and limited inter-agent communication,
reducing their effectiveness in open-ended, high-complexity domains. This paper
proposes a coordination framework that enables adaptiveness through three core
mechanisms: dynamic task routing, bidirectional feedback, and parallel agent
evaluation. The framework allows agents to reallocate tasks based on confidence
and workload, exchange structured critiques to iteratively improve outputs, and
crucially compete on high-ambiguity subtasks with evaluator-driven selection of
the most suitable result. We instantiate these principles in a modular
architecture and demonstrate substantial improvements in factual coverage,
coherence, and efficiency over static and partially adaptive baselines. Our
findings highlight the benefits of incorporating both adaptiveness and
structured competition in multi-agent LLM systems.

</details>


### [253] [Resilient Multi-Agent Negotiation for Medical Supply Chains:Integrating LLMs and Blockchain for Transparent Coordination](https://arxiv.org/abs/2507.17134)
*Mariam ALMutairi,Hyungmin Kim*

Main category: cs.MA

TL;DR: 本文提出了一个结合区块链技术和大语言模型驱动的多智能体谈判系统的混合框架，用于在健康危机期间增强医疗供应链的韧性和问责制。


<details>
  <summary>Details</summary>
Motivation: COVID-19等全球健康紧急事件暴露了传统医疗供应链的关键弱点，包括资源配置效率低下、缺乏透明度和对动态中断的适应性差等问题。

Method: 设计了一个混合框架，将区块链技术与去中心化的大语言模型驱动的多智能体谈判系统相结合。系统中的自主智能体代表制造商、分销商和医疗机构，通过LLM进行结构化的、上下文感知的谈判和决策过程。链下智能体层支持自适应推理和本地决策，链上区块链层通过智能合约确保决策的不可变、透明和可审计执行。

Result: 通过模拟疫情场景的仿真环境评估系统性能，结果显示在谈判效率、分配公平性、供应链响应性和可审计性方面都有显著改善。

Conclusion: 该研究提供了一种创新方法，将区块链的信任保障与LLM驱动智能体的自适应智能相结合，为不确定性条件下的关键供应链协调提供了稳健且可扩展的解决方案。

Abstract: Global health emergencies, such as the COVID-19 pandemic, have exposed
critical weaknesses in traditional medical supply chains, including
inefficiencies in resource allocation, lack of transparency, and poor
adaptability to dynamic disruptions. This paper presents a novel hybrid
framework that integrates blockchain technology with a decentralized, large
language model (LLM) powered multi-agent negotiation system to enhance the
resilience and accountability of medical supply chains during crises. In this
system, autonomous agents-representing manufacturers, distributors, and
healthcare institutions-engage in structured, context-aware negotiation and
decision-making processes facilitated by LLMs, enabling rapid and ethical
allocation of scarce medical resources. The off-chain agent layer supports
adaptive reasoning and local decision-making, while the on-chain blockchain
layer ensures immutable, transparent, and auditable enforcement of decisions
via smart contracts. The framework also incorporates a formal cross-layer
communication protocol to bridge decentralized negotiation with institutional
enforcement. A simulation environment emulating pandemic scenarios evaluates
the system's performance, demonstrating improvements in negotiation efficiency,
fairness of allocation, supply chain responsiveness, and auditability. This
research contributes an innovative approach that synergizes blockchain trust
guarantees with the adaptive intelligence of LLM-driven agents, providing a
robust and scalable solution for critical supply chain coordination under
uncertainty.

</details>


### [254] [Fair Compromises in Participatory Budgeting: a Multi-Agent Deep Reinforcement Learning Approach](https://arxiv.org/abs/2507.17433)
*Hugh Adams,Srijoni Majumdar,Evangelos Pournaras*

Main category: cs.MA

TL;DR: 该论文提出了一种基于多智能体深度强化学习的参与式预算决策支持方法，通过分支神经网络架构解决可扩展性问题，帮助选民优化投票策略并支持政策制定者设计更公平的选举机制。


<details>
  <summary>Details</summary>
Motivation: 参与式预算中选民面临"选择过载"问题，需要在众多项目中做出决策。现有方法缺乏有效的决策支持工具来帮助选民制定投票策略，同时政策制定者也需要了解如何设计更公平的选举机制来实现项目的公平妥协。

Method: 采用多智能体深度强化学习建模方法，引入新颖的分支神经网络架构来克服多智能体强化学习的可扩展性挑战。通过优化选民行为来增加选民偏好在获胜项目集合中的代表性，以去中心化的方式寻找公平妥协。该方法在伦理上保持一致，为选民和政策制定者提供决策支持。

Result: 使用真实世界的参与式预算数据进行实验评估，发现了公平妥协的一个重要模式：通过成本较小的项目更容易实现公平妥协。该方法能够有效识别增加选民投票获胜比例的投票策略，并为政策制定者提供选举设计方面的洞察。

Conclusion: 该研究成功开发了一种基于多智能体深度强化学习的参与式预算决策支持系统，不仅能帮助选民制定更好的投票策略，还能为政策制定者提供设计公平选举机制的指导。研究发现小成本项目在实现公平妥协方面具有优势，为未来的参与式预算实践提供了重要参考。

Abstract: Participatory budgeting is a method of collectively understanding and
addressing spending priorities where citizens vote on how a budget is spent, it
is regularly run to improve the fairness of the distribution of public funds.
Participatory budgeting requires voters to make decisions on projects which can
lead to ``choice overload". A multi-agent reinforcement learning approach to
decision support can make decision making easier for voters by identifying
voting strategies that increase the winning proportion of their vote. This
novel approach can also support policymakers by highlighting aspects of
election design that enable fair compromise on projects. This paper presents a
novel, ethically aligned approach to decision support using multi-agent deep
reinforcement learning modelling. This paper introduces a novel use of a
branching neural network architecture to overcome scalability challenges of
multi-agent reinforcement learning in a decentralized way. Fair compromises are
found through optimising voter actions towards greater representation of voter
preferences in the winning set. Experimental evaluation with real-world
participatory budgeting data reveals a pattern in fair compromise: that it is
achievable through projects with smaller cost.

</details>
