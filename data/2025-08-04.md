<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.LG](#cs.LG) [Total: 62]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.HC](#cs.HC) [Total: 18]
- [eess.SY](#eess.SY) [Total: 9]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
*Jie Zhu,Yiyang Su,Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 提出了一种名为QME的新型框架，通过学习性分数融合策略提升全身生物特征识别性能，解决了传统方法中分数分布变化和数据质量差异的问题。


<details>
  <summary>Details</summary>
Motivation: 传统全身生物特征识别方法通过分数融合（如加权平均）处理多模态数据，但忽略了各模态分数分布的差异，限制了性能提升。

Method: QME框架结合了Mixture of Experts（MoE）和伪质量损失函数，通过模态特定的质量估计器（QE）和分数三元组损失优化性能。

Result: 在多个数据集上的实验表明，QME在各项指标上均优于基线方法，达到了最先进的性能。

Conclusion: QME框架有效解决了多模态和多模型中的关键挑战，如相似性分数域中的模型不对齐和数据质量变化。

Abstract: Whole-body biometric recognition is a challenging multimodal task that
integrates various biometric modalities, including face, gait, and body. This
integration is essential for overcoming the limitations of unimodal systems.
Traditionally, whole-body recognition involves deploying different models to
process multiple modalities, achieving the final outcome by score-fusion (e.g.,
weighted averaging of similarity matrices from each model). However, these
conventional methods may overlook the variations in score distributions of
individual modalities, making it challenging to improve final performance. In
this work, we present \textbf{Q}uality-guided \textbf{M}ixture of score-fusion
\textbf{E}xperts (QME), a novel framework designed for improving whole-body
biometric recognition performance through a learnable score-fusion strategy
using a Mixture of Experts (MoE). We introduce a novel pseudo-quality loss for
quality estimation with a modality-specific Quality Estimator (QE), and a score
triplet loss to improve the metric performance. Extensive experiments on
multiple whole-body biometric datasets demonstrate the effectiveness of our
proposed approach, achieving state-of-the-art results across various metrics
compared to baseline methods. Our method is effective for multimodal and
multi-model, addressing key challenges such as model misalignment in the
similarity score domain and variability in data quality.

</details>


### [2] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
*Raiyaan Abdullah,Jared Claypoole,Michael Cogswell,Ajay Divakaran,Yogesh Rawat*

Main category: cs.CV

TL;DR: 论文探讨了动作识别模型在跨多样上下文中的高级运动概念迁移能力，发现模型在新场景中识别高级动作时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 研究动作识别模型是否能有效迁移高级运动概念到不同上下文，尤其是在类似分布中。

Method: 引入一个运动迁移性框架，使用三个数据集（Syn-TA、Kinetics400-TA、Something-Something-v2-TA）评估13个最先进模型。

Result: 模型在新场景中识别高级动作时性能显著下降，多模态模型在细粒度未知动作上表现更差，Syn-TA数据集挑战性与真实数据集相当。

Conclusion: 研究为评估动作识别中的运动迁移性建立了重要基准，并探讨了解耦粗粒度和细粒度运动对提升识别性能的潜力。

Abstract: Action recognition models demonstrate strong generalization, but can they
effectively transfer high-level motion concepts across diverse contexts, even
within similar distributions? For example, can a model recognize the broad
action "punching" when presented with an unseen variation such as "punching
person"? To explore this, we introduce a motion transferability framework with
three datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)
Kinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural
video datasets. We evaluate 13 state-of-the-art models on these benchmarks and
observe a significant drop in performance when recognizing high-level actions
in novel contexts. Our analysis reveals: 1) Multimodal models struggle more
with fine-grained unknown actions than with coarse ones; 2) The bias-free
Syn-TA proves as challenging as real-world datasets, with models showing
greater performance drops in controlled settings; 3) Larger models improve
transferability when spatial cues dominate but struggle with intensive temporal
reasoning, while reliance on object and background cues hinders generalization.
We further explore how disentangling coarse and fine motions can improve
recognition in temporally challenging datasets. We believe this study
establishes a crucial benchmark for assessing motion transferability in action
recognition. Datasets and relevant code:
https://github.com/raiyaan-abdullah/Motion-Transfer.

</details>


### [3] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
*Angelos Vlachos,Giorgos Filandrianos,Maria Lymperaiou,Nikolaos Spanos,Ilias Mitsouras,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出了一种基于双代理的协作框架，用于多图像推理，无需训练即可泛化多种任务。


<details>
  <summary>Details</summary>
Motivation: 解决跨数据集和任务格式的多模态推理挑战。

Method: 使用语言代理PromptEngineer生成任务提示，视觉代理VisionReasoner进行推理。

Result: 在18个数据集上表现优异，Claude 3.7在TQA、DocVQA等任务中接近天花板性能。

Conclusion: LVLMs在多图像推理中表现优异，提示设计对性能有显著影响。

Abstract: We present a Collaborative Agent-Based Framework for Multi-Image Reasoning.
Our approach tackles the challenge of interleaved multimodal reasoning across
diverse datasets and task formats by employing a dual-agent system: a
language-based PromptEngineer, which generates context-aware, task-specific
prompts, and a VisionReasoner, a large vision-language model (LVLM) responsible
for final inference. The framework is fully automated, modular, and
training-free, enabling generalization across classification, question
answering, and free-form generation tasks involving one or multiple input
images. We evaluate our method on 18 diverse datasets from the 2025 MIRAGE
Challenge (Track A), covering a broad spectrum of visual reasoning tasks
including document QA, visual comparison, dialogue-based understanding, and
scene-level inference. Our results demonstrate that LVLMs can effectively
reason over multiple images when guided by informative prompts. Notably, Claude
3.7 achieves near-ceiling performance on challenging tasks such as TQA (99.13%
accuracy), DocVQA (96.87%), and MMCoQA (75.28 ROUGE-L). We also explore how
design choices-such as model selection, shot count, and input length-influence
the reasoning performance of different LVLMs.

</details>


### [4] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
*Mateo de Mayo,Daniel Cremers,Taihú Pire*

Main category: cs.CV

TL;DR: 论文介绍了Monado SLAM数据集，旨在解决现有VIO/SLAM系统在头戴设备应用中面临的挑战性问题。


<details>
  <summary>Details</summary>
Motivation: 现有VIO/SLAM系统在头戴设备应用中难以应对高动态运动、遮挡、低纹理环境等现实问题，缺乏相关数据集支持。

Method: 通过收集多款虚拟现实头戴设备的真实序列数据，构建Monado SLAM数据集。

Result: 发布了Monado SLAM数据集，采用CC BY 4.0许可，促进VIO/SLAM研究发展。

Conclusion: Monado SLAM数据集填补了现有空白，有助于改进头戴设备中的跟踪系统。

Abstract: Humanoid robots and mixed reality headsets benefit from the use of
head-mounted sensors for tracking. While advancements in visual-inertial
odometry (VIO) and simultaneous localization and mapping (SLAM) have produced
new and high-quality state-of-the-art tracking systems, we show that these are
still unable to gracefully handle many of the challenging settings presented in
the head-mounted use cases. Common scenarios like high-intensity motions,
dynamic occlusions, long tracking sessions, low-textured areas, adverse
lighting conditions, saturation of sensors, to name a few, continue to be
covered poorly by existing datasets in the literature. In this way, systems may
inadvertently overlook these essential real-world issues. To address this, we
present the Monado SLAM dataset, a set of real sequences taken from multiple
virtual reality headsets. We release the dataset under a permissive CC BY 4.0
license, to drive advancements in VIO/SLAM research and development.

</details>


### [5] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 论文提出了一种基于卷积神经网络（CNN）的模型，利用眼周区域的颜色图像进行性别分类，在两个数据集上分别达到99%和96%的准确率。


<details>
  <summary>Details</summary>
Motivation: 性别分类在安全、人机交互等领域至关重要，但化妆品和伪装等因素会影响准确性。研究专注于眼周区域以解决这一问题。

Method: 使用CNN模型分析眼周区域的颜色图像，提取关键特征进行分类。

Result: 在CVBL数据集上达到99%准确率，在(Female and Male)数据集上达到96%准确率，参数较少（7,235,089）。

Conclusion: 模型在性别分类中表现出色，适用于安全和监控等实际应用。

Abstract: Gender classification has emerged as a crucial aspect in various fields,
including security, human-machine interaction, surveillance, and advertising.
Nonetheless, the accuracy of this classification can be influenced by factors
such as cosmetics and disguise. Consequently, our study is dedicated to
addressing this concern by concentrating on gender classification using color
images of the periocular region. The periocular region refers to the area
surrounding the eye, including the eyelids, eyebrows, and the region between
them. It contains valuable visual cues that can be used to extract key features
for gender classification. This paper introduces a sophisticated Convolutional
Neural Network (CNN) model that utilizes color image databases to evaluate the
effectiveness of the periocular region for gender classification. To validate
the model's performance, we conducted tests on two eye datasets, namely CVBL
and (Female and Male). The recommended architecture achieved an outstanding
accuracy of 99% on the previously unused CVBL dataset while attaining a
commendable accuracy of 96% with a small number of learnable parameters
(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of
our proposed model for gender classification using the periocular region, we
evaluated its performance through an extensive range of metrics and compared it
with other state-of-the-art approaches. The results unequivocally demonstrate
the efficacy of our model, thereby suggesting its potential for practical
application in domains such as security and surveillance.

</details>


### [6] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
*Akshat Rakheja,Aarsh Ashdhir,Aryan Bhattacharjee,Vanshika Sharma*

Main category: cs.CV

TL;DR: World Consistency Score (WCS) 是一种新的统一评估指标，用于生成视频模型，强调生成视频的内部世界一致性。它整合了四个可解释的子组件，并通过学习权重公式生成与人类判断一致的分数。


<details>
  <summary>Details</summary>
Motivation: 现有视频评估指标主要关注视觉保真度或提示对齐，忽略了视频的时空和物理一致性。WCS旨在填补这一空白。

Method: WCS 结合四个子指标（物体持久性、关系稳定性、因果合规性和闪烁惩罚），使用开源工具计算，并通过人类偏好数据训练权重。

Result: WCS 在多个基准测试中验证了与人类评估的相关性，并与其他指标（如FVD、CLIPScore）进行了比较。

Conclusion: WCS 提供了一个全面且可解释的框架，用于评估视频生成模型在保持世界一致性方面的能力。

Abstract: We introduce World Consistency Score (WCS), a novel unified evaluation metric
for generative video models that emphasizes internal world consistency of the
generated videos. WCS integrates four interpretable sub-components - object
permanence, relation stability, causal compliance, and flicker penalty - each
measuring a distinct aspect of temporal and physical coherence in a video.
These submetrics are combined via a learned weighted formula to produce a
single consistency score that aligns with human judgments. We detail the
motivation for WCS in the context of existing video evaluation metrics,
formalize each submetric and how it is computed with open-source tools
(trackers, action recognizers, CLIP embeddings, optical flow), and describe how
the weights of the WCS combination are trained using human preference data. We
also outline an experimental validation blueprint: using benchmarks like
VBench-2.0, EvalCrafter, and LOVE to test WCS's correlation with human
evaluations, performing sensitivity analyses, and comparing WCS against
established metrics (FVD, CLIPScore, VBench, FVMD). The proposed WCS offers a
comprehensive and interpretable framework for evaluating video generation
models on their ability to maintain a coherent "world" over time, addressing
gaps left by prior metrics focused only on visual fidelity or prompt alignment.

</details>


### [7] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
*Li Mi,Manon Bechaz,Zeming Chen,Antoine Bosselut,Devis Tuia*

Main category: cs.CV

TL;DR: GeoExplorer通过内在奖励驱动的探索方法提升主动地理定位的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于距离奖励的强化学习方法在目标或环境未知时表现不佳，探索策略不可靠。

Method: 提出GeoExplorer，采用好奇心驱动的内在奖励进行目标无关的探索。

Result: 在四个AGL基准测试中验证了GeoExplorer的有效性，尤其在未知目标和环境中表现优异。

Conclusion: GeoExplorer通过好奇心驱动探索提升了AGL任务的鲁棒性和泛化能力。

Abstract: Active Geo-localization (AGL) is the task of localizing a goal, represented
in various modalities (e.g., aerial images, ground-level images, or text),
within a predefined search area. Current methods approach AGL as a
goal-reaching reinforcement learning (RL) problem with a distance-based reward.
They localize the goal by implicitly learning to minimize the relative distance
from it. However, when distance estimation becomes challenging or when
encountering unseen targets and environments, the agent exhibits reduced
robustness and generalization ability due to the less reliable exploration
strategy learned during training. In this paper, we propose GeoExplorer, an AGL
agent that incorporates curiosity-driven exploration through intrinsic rewards.
Unlike distance-based rewards, our curiosity-driven reward is goal-agnostic,
enabling robust, diverse, and contextually relevant exploration based on
effective environment modeling. These capabilities have been proven through
extensive experiments across four AGL benchmarks, demonstrating the
effectiveness and generalization ability of GeoExplorer in diverse settings,
particularly in localizing unfamiliar targets and environments.

</details>


### [8] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
*Bhavya Goyal,Felipe Gutierrez-Barragan,Wei Lin,Andreas Velten,Yin Li,Mohit Gupta*

Main category: cs.CV

TL;DR: 论文提出了一种名为概率点云（PPC）的新型3D场景表示方法，通过为每个点添加概率属性来封装原始数据中的测量不确定性，从而提升3D物体检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代LiDAR在远距离或低反射率物体等场景中会产生稀疏或错误的点云，传统3D处理流程未保留原始测量中的不确定性信息，导致下游感知模型精度下降。

Method: 提出PPC表示方法，为点云中的每个点添加概率属性，并设计基于PPC的轻量级推理模块，用于鲁棒的3D物体检测。

Result: 实验表明，PPC方法在室内外复杂场景中优于LiDAR及相机-LiDAR融合模型，尤其在处理小、远距离和低反射率物体时表现突出。

Conclusion: PPC通过保留测量不确定性信息，显著提升了3D感知任务的精度，为实际应用提供了更可靠的解决方案。

Abstract: LiDAR-based 3D sensors provide point clouds, a canonical 3D representation
used in various scene understanding tasks. Modern LiDARs face key challenges in
several real-world scenarios, such as long-distance or low-albedo objects,
producing sparse or erroneous point clouds. These errors, which are rooted in
the noisy raw LiDAR measurements, get propagated to downstream perception
models, resulting in potentially severe loss of accuracy. This is because
conventional 3D processing pipelines do not retain any uncertainty information
from the raw measurements when constructing point clouds.
  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation
where each point is augmented with a probability attribute that encapsulates
the measurement uncertainty (or confidence) in the raw data. We further
introduce inference approaches that leverage PPC for robust 3D object
detection; these methods are versatile and can be used as computationally
lightweight drop-in modules in 3D inference pipelines. We demonstrate, via both
simulations and real captures, that PPC-based 3D inference methods outperform
several baselines using LiDAR as well as camera-LiDAR fusion models, across
challenging indoor and outdoor scenarios involving small, distant, and
low-albedo objects, as well as strong ambient light.
  Our project webpage is at https://bhavyagoyal.github.io/ppc .

</details>


### [9] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 论文提出了一种选择性模态转移（SMS）方法，用于量化视觉语言模型（VLMs）在二元分类任务中对每种模态的依赖，揭示了模型对文本输入的显著依赖。


<details>
  <summary>Details</summary>
Motivation: 临床决策需要综合分析医学图像和相关报告，但现有视觉语言模型可能偏向某一模态，忽略关键视觉信息。

Method: 通过选择性模态转移（SMS），在二元分类任务中系统地交换图像或文本样本，评估模型对模态的依赖。

Result: 实验表明，模型在医学图像数据集中对文本输入有显著依赖，视觉信息常被忽视。

Conclusion: 设计多模态医学模型时需真正整合视觉和文本信息，避免依赖单一模态信号。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [10] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
*Eric Mjolsness,Cory B. Scott*

Main category: cs.CV

TL;DR: 论文定义了结构化图“谱系”，支持层次化增长，并推导了高效的代数操作，适用于层次化模型架构和算法。


<details>
  <summary>Details</summary>
Motivation: 为机器学习和计算科学中的模型架构提供一种层次化图结构，支持高效操作和逼近连续极限。

Method: 定义图谱系和“分级图”类别，推导低成本的代数操作和类型构造器，并应用于深度神经网络和多网格数值方法。

Result: 提出了一种代数类型理论，适用于层次化模型架构和算法，并在实际应用中验证了其有效性。

Conclusion: 该方法为层次化模型和算法提供了高效的理论框架，具有广泛的应用潜力。

Abstract: Graphs, and sequences of growing graphs, can be used to specify the
architecture of mathematical models in many fields including machine learning
and computational science. Here we define structured graph "lineages" (ordered
by level number) that grow in a hierarchical fashion, so that: (1) the number
of graph vertices and edges increases exponentially in level number; (2)
bipartite graphs connect successive levels within a graph lineage and, as in
multigrid methods, can constrain matrices relating successive levels; (3) using
prolongation maps within a graph lineage, process-derived distance measures
between graphs at successive levels can be defined; (4) a category of "graded
graphs" can be defined, and using it low-cost "skeletal" variants of standard
algebraic graph operations and type constructors (cross product, box product,
disjoint sum, and function types) can be derived for graded graphs and hence
hierarchical graph lineages; (5) these skeletal binary operators have similar
but not identical algebraic and category-theoretic properties to their standard
counterparts; (6) graph lineages and their skeletal product constructors can
approach continuum limit objects. Additional space-efficient unary operators on
graded graphs are also derived: thickening, which creates a graph lineage of
multiscale graphs, and escalation to a graph lineage of search frontiers
(useful as a generalization of adaptive grids and in defining "skeletal"
functions). The result is an algebraic type theory for graded graphs and
(hierarchical) graph lineages. The approach is expected to be well suited to
defining hierarchical model architectures - "hierarchitectures" - and local
sampling, search, or optimization algorithms on them. We demonstrate such
application to deep neural networks (including visual and feature scale spaces)
and to multigrid numerical methods.

</details>


### [11] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
*Xiangyu Kong,Hengde Zhu,Haoqin Sun,Zhihao Guo,Jiayan Gu,Xinyi Ni,Wei Zhang,Shizhe Liu,Siyang Song*

Main category: cs.CV

TL;DR: 提出了一种基于个性化内部认知的自动真实人格识别方法，通过模拟个体特有的认知过程，利用2D图神经网络从外部行为推断真实人格特征。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常作为外部观察者推断人格印象，与真实人格存在显著偏差，导致识别性能不佳。

Method: 通过模拟个性化内部认知，构建包含二维节点和边特征的图，并设计2D-GNN进行人格特征推断。采用端到端策略联合训练认知模拟、图构建和人格识别模块。

Result: 提出的方法能够从易获取的外部音频-视觉行为中高效模拟个性化认知，进而准确识别真实人格特征。

Conclusion: 该方法通过模拟内部认知显著提升了真实人格识别的性能，为相关领域提供了新思路。

Abstract: Automatic real personality recognition (RPR) aims to evaluate human real
personality traits from their expressive behaviours. However, most existing
solutions generally act as external observers to infer observers' personality
impressions based on target individuals' expressive behaviours, which
significantly deviate from their real personalities and consistently lead to
inferior recognition performance. Inspired by the association between real
personality and human internal cognition underlying the generation of
expressive behaviours, we propose a novel RPR approach that efficiently
simulates personalised internal cognition from easy-accessible external short
audio-visual behaviours expressed by the target individual. The simulated
personalised cognition, represented as a set of network weights that enforce
the personalised network to reproduce the individual-specific facial reactions,
is further encoded as a novel graph containing two-dimensional node and edge
feature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for
inferring real personality traits from it. To simulate real personality-related
cognition, an end-to-end strategy is designed to jointly train our cognition
simulation, 2D graph construction, and personality recognition modules.

</details>


### [12] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
*Shayan Jalilian,Abdul Bais*

Main category: cs.CV

TL;DR: SAM-PTx通过轻量级适配器设计，将CLIP文本嵌入注入SAM的图像编码器，提升语义引导的分割性能。


<details>
  <summary>Details</summary>
Motivation: 探索语义文本提示在分割任务中的潜力，弥补传统空间提示的不足。

Method: 提出Parallel-Text适配器，仅修改MLP并行分支，保留注意力路径，使用冻结的CLIP文本嵌入作为语义指导。

Result: 在COD10K、COCO和ADE20K数据集上，语义提示显著优于纯空间提示基线。

Conclusion: 将语义条件集成到SAM架构中，提供了一种高效且可扩展的适应路径。

Abstract: The Segment Anything Model (SAM) has demonstrated impressive generalization
in prompt-based segmentation. Yet, the potential of semantic text prompts
remains underexplored compared to traditional spatial prompts like points and
boxes. This paper introduces SAM-PTx, a parameter-efficient approach for
adapting SAM using frozen CLIP-derived text embeddings as class-level semantic
guidance. Specifically, we propose a lightweight adapter design called
Parallel-Text that injects text embeddings into SAM's image encoder, enabling
semantics-guided segmentation while keeping most of the original architecture
frozen. Our adapter modifies only the MLP-parallel branch of each transformer
block, preserving the attention pathway for spatial reasoning. Through
supervised experiments and ablations on the COD10K dataset as well as low-data
subsets of COCO and ADE20K, we show that incorporating fixed text embeddings as
input improves segmentation performance over purely spatial prompt baselines.
To our knowledge, this is the first work to use text prompts for segmentation
on the COD10K dataset. These results suggest that integrating semantic
conditioning into SAM's architecture offers a practical and scalable path for
efficient adaptation with minimal computational complexity.

</details>


### [13] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.CV

TL;DR: 在少样本图像分类中，通过引入物体局部位置信息显著提升性能，尤其是使用Segment Anything Model或非监督前景提取方法。


<details>
  <summary>Details</summary>
Motivation: 解决少样本图像分类中因图像模糊（多物体或复杂背景）导致的性能下降问题。

Method: 利用物体局部位置信息，结合Segment Anything Model（仅需标记一个像素）或非监督前景提取方法。

Result: 在多个基准测试中显著提升了分类性能。

Conclusion: 局部位置信息和简单标记方法可有效提升少样本分类性能。

Abstract: In the domain of Few-Shot Image Classification, operating with as little as
one example per class, the presence of image ambiguities stemming from multiple
objects or complex backgrounds can significantly deteriorate performance. Our
research demonstrates that incorporating additional information about the local
positioning of an object within its image markedly enhances classification
across established benchmarks. More importantly, we show that a significant
fraction of the improvement can be achieved through the use of the Segment
Anything Model, requiring only a pixel of the object of interest to be pointed
out, or by employing fully unsupervised foreground object extraction methods.

</details>


### [14] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
*Chenggang Guo,Hao Xu,XianMing Wan*

Main category: cs.CV

TL;DR: 提出了一种多尺度融合U形Mamba模型（MSF-UM），用于深度图超分辨率，结合Mamba的高效状态空间建模和多尺度U形结构，显著提升重建精度并减少参数。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在处理长距离依赖和全局上下文信息时存在局限性，而Transformer的计算复杂度和内存消耗较高，限制了其在高分辨率深度图处理中的应用。

Method: 设计了一种结合残差密集通道注意力块和Mamba状态空间模块的结构，利用多尺度跨模态融合策略，通过彩色图像的高频纹理信息引导深度图超分辨率。

Result: MSF-UM在减少模型参数的同时，实现了更好的重建精度，并在多个公开数据集上验证了有效性，尤其在大规模深度图超分辨率任务中表现出色。

Conclusion: MSF-UM模型通过结合局部特征提取和长距离依赖建模，以及多尺度融合策略，显著提升了深度图超分辨率的性能。

Abstract: Depth map super-resolution technology aims to improve the spatial resolution
of low-resolution depth maps and effectively restore high-frequency detail
information. Traditional convolutional neural network has limitations in
dealing with long-range dependencies and are unable to fully model the global
contextual information in depth maps. Although transformer can model global
dependencies, its computational complexity and memory consumption are
quadratic, which significantly limits its ability to process high-resolution
depth maps. In this paper, we propose a multi-scale fusion U-shaped Mamba
(MSF-UM) model, a novel guided depth map super-resolution framework. The core
innovation of this model is to integrate Mamba's efficient state-space modeling
capabilities into a multi-scale U-shaped fusion structure guided by a color
image. The structure combining the residual dense channel attention block and
the Mamba state space module is designed, which combines the local feature
extraction capability of the convolutional layer with the modeling advantage of
the state space model for long-distance dependencies. At the same time, the
model adopts a multi-scale cross-modal fusion strategy to make full use of the
high-frequency texture information from the color image to guide the
super-resolution process of the depth map. Compared with existing mainstream
methods, the proposed MSF-UM significantly reduces the number of model
parameters while achieving better reconstruction accuracy. Extensive
experiments on multiple publicly available datasets validate the effectiveness
of the model, especially showing excellent generalization ability in the task
of large-scale depth map super-resolution.

</details>


### [15] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
*Wentao Sun,Hanqing Xu,Quanyun Wu,Dedong Zhang,Yiping Chen,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: PointGauss提出了一种基于点云的实时多目标分割框架，通过高斯泼溅表示实现高效3D分割，显著提升了多视角一致性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在初始化时间长和多视角一致性差的问题，PointGauss旨在解决这些问题。

Method: 采用点云分割驱动的高斯基元解码器和GPU加速的2D掩模渲染系统。

Result: 在多视角mIoU上性能提升1.89%至31.78%，并保持高效计算。

Conclusion: PointGauss在3D分割中表现出色，同时提出了新数据集DesktopObjects-360以解决现有基准的局限性。

Abstract: We introduce PointGauss, a novel point cloud-guided framework for real-time
multi-object segmentation in Gaussian Splatting representations. Unlike
existing methods that suffer from prolonged initialization and limited
multi-view consistency, our approach achieves efficient 3D segmentation by
directly parsing Gaussian primitives through a point cloud segmentation-driven
pipeline. The key innovation lies in two aspects: (1) a point cloud-based
Gaussian primitive decoder that generates 3D instance masks within 1 minute,
and (2) a GPU-accelerated 2D mask rendering system that ensures multi-view
consistency. Extensive experiments demonstrate significant improvements over
previous state-of-the-art methods, achieving performance gains of 1.89 to
31.78% in multi-view mIoU, while maintaining superior computational efficiency.
To address the limitations of current benchmarks (single-object focus,
inconsistent 3D evaluation, small scale, and partial coverage), we present
DesktopObjects-360, a novel comprehensive dataset for 3D segmentation in
radiance fields, featuring: (1) complex multi-object scenes, (2) globally
consistent 2D annotations, (3) large-scale training data (over 27 thousand 2D
masks), (4) full 360{\deg} coverage, and (5) 3D evaluation masks.

</details>


### [16] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
*Hyundong Jin,Hyung Jin Chang,Eunwoo Kim*

Main category: cs.CV

TL;DR: 提出了一种新框架，通过混合视觉投影器和专家推荐策略，解决生成视觉语言模型在持续学习中忽视语言指令的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在持续学习中可能过度关注视觉输入而忽视语言指令，尤其是在重复文本指令的任务中。

Method: 引入混合视觉投影器作为专家，基于指令上下文进行视觉到语言的翻译，并采用专家推荐和修剪策略。

Result: 在多样化视觉语言任务中，该方法优于现有持续学习方法，生成更符合指令的响应。

Conclusion: 新框架有效平衡了视觉和语言信息的处理，提升了模型在持续学习中的表现。

Abstract: Continual learning enables pre-trained generative vision-language models
(VLMs) to incorporate knowledge from new tasks without retraining data from
previous ones. Recent methods update a visual projector to translate visual
information for new tasks, connecting pre-trained vision encoders with large
language models. However, such adjustments may cause the models to prioritize
visual inputs over language instructions, particularly learning tasks with
repetitive types of textual instructions. To address the neglect of language
instructions, we propose a novel framework that grounds the translation of
visual information on instructions for language models. We introduce a mixture
of visual projectors, each serving as a specialized visual-to-language
translation expert based on the given instruction context to adapt to new
tasks. To avoid using experts for irrelevant instruction contexts, we propose
an expert recommendation strategy that reuses experts for tasks similar to
those previously learned. Additionally, we introduce expert pruning to
alleviate interference from the use of experts that cumulatively activated in
previous tasks. Extensive experiments on diverse vision-language tasks
demonstrate that our method outperforms existing continual learning approaches
by generating instruction-following responses.

</details>


### [17] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
*Henghui Ding,Song Tang,Shuting He,Chang Liu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文综述了多模态指代分割领域，涵盖背景、方法、性能比较及应用。


<details>
  <summary>Details</summary>
Motivation: 多模态指代分割在基于用户指令的精确对象感知中具有重要应用价值，近年来因深度学习的进展而备受关注。

Method: 提出统一元架构，总结图像、视频和3D场景中的代表性方法，并讨论广义指代表达（GREx）方法。

Result: 提供了标准基准上的性能比较，并跟踪相关研究进展。

Conclusion: 多模态指代分割是一个快速发展的领域，未来需进一步解决现实世界复杂性问题。

Abstract: Multimodal referring segmentation aims to segment target objects in visual
scenes, such as images, videos, and 3D scenes, based on referring expressions
in text or audio format. This task plays a crucial role in practical
applications requiring accurate object perception based on user instructions.
Over the past decade, it has gained significant attention in the multimodal
community, driven by advances in convolutional neural networks, transformers,
and large language models, all of which have substantially improved multimodal
perception capabilities. This paper provides a comprehensive survey of
multimodal referring segmentation. We begin by introducing this field's
background, including problem definitions and commonly used datasets. Next, we
summarize a unified meta architecture for referring segmentation and review
representative methods across three primary visual scenes, including images,
videos, and 3D scenes. We further discuss Generalized Referring Expression
(GREx) methods to address the challenges of real-world complexity, along with
related tasks and practical applications. Extensive performance comparisons on
standard benchmarks are also provided. We continually track related works at
https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

</details>


### [18] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
*Wenyue Chong*

Main category: cs.CV

TL;DR: 该论文提出了一个评估语义对应在恶劣条件下鲁棒性的新基准，包含14种常见挑战场景，并发现现有方法在这些条件下表现显著下降，同时探讨了大规模视觉模型和任务特定设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 语义对应是计算机视觉中的基础任务，但在恶劣条件下的鲁棒性研究不足，因此需要建立一个基准来评估和改进现有方法。

Method: 通过构建包含14种挑战场景的基准数据集，并评估现有语义对应方法（如DINO和Stable Diffusion）及其融合策略的性能。

Result: 发现现有方法在恶劣条件下表现下降，大规模视觉模型（如DINO）表现更优，但微调会降低鲁棒性；任务特定设计比通用数据增强更有效。

Conclusion: 语义对应在恶劣条件下的鲁棒性需要进一步研究，任务特定设计是提升性能的关键。

Abstract: Semantic correspondence aims to identify semantically meaningful
relationships between different images and is a fundamental challenge in
computer vision. It forms the foundation for numerous tasks such as 3D
reconstruction, object tracking, and image editing. With the progress of
large-scale vision models, semantic correspondence has achieved remarkable
performance in controlled and high-quality conditions. However, the robustness
of semantic correspondence in challenging scenarios is much less investigated.
In this work, we establish a novel benchmark for evaluating semantic
correspondence in adverse conditions. The benchmark dataset comprises 14
distinct challenging scenarios that reflect commonly encountered imaging
issues, including geometric distortion, image blurring, digital artifacts, and
environmental occlusion. Through extensive evaluations, we provide several key
insights into the robustness of semantic correspondence approaches: (1) All
existing methods suffer from noticeable performance drops under adverse
conditions; (2) Using large-scale vision models can enhance overall robustness,
but fine-tuning on these models leads to a decline in relative robustness; (3)
The DINO model outperforms the Stable Diffusion in relative robustness, and
their fusion achieves better absolute robustness; Moreover, We evaluate common
robustness enhancement strategies for semantic correspondence and find that
general data augmentations are ineffective, highlighting the need for
task-specific designs. These results are consistent across both our dataset and
real-world benchmarks.

</details>


### [19] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
*Tran Viet Khoa,Do Hai Son,Mohammad Abu Alsheikh,Yibeltal F Alem,Dinh Thai Hoang*

Main category: cs.CV

TL;DR: 提出了一种基于空间自注意力机制和LSTM的驾驶员疲劳检测框架，结合联邦学习和梯度相似性比较，实现了89.9%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是交通事故的主要原因之一，但现有方法在分散和多样化的真实数据中表现不佳。

Method: 结合空间自注意力机制（SSA）和LSTM网络提取关键面部特征，采用梯度相似性比较（GSC）优化联邦学习模型聚合。

Result: 在联邦学习设置下达到89.9%的检测准确率，优于现有方法。

Conclusion: 该框架能有效处理真实数据多样性，有望应用于智能交通系统提升道路安全。

Abstract: Driver drowsiness is one of the main causes of road accidents and is
recognized as a leading contributor to traffic-related fatalities. However,
detecting drowsiness accurately remains a challenging task, especially in
real-world settings where facial data from different individuals is
decentralized and highly diverse. In this paper, we propose a novel framework
for drowsiness detection that is designed to work effectively with
heterogeneous and decentralized data. Our approach develops a new Spatial
Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM)
network to better extract key facial features and improve detection
performance. To support federated learning, we employ a Gradient Similarity
Comparison (GSC) that selects the most relevant trained models from different
operators before aggregation. This improves the accuracy and robustness of the
global model while preserving user privacy. We also develop a customized tool
that automatically processes video data by extracting frames, detecting and
cropping faces, and applying data augmentation techniques such as rotation,
flipping, brightness adjustment, and zooming. Experimental results show that
our framework achieves a detection accuracy of 89.9% in the federated learning
settings, outperforming existing methods under various deployment scenarios.
The results demonstrate the effectiveness of our approach in handling
real-world data variability and highlight its potential for deployment in
intelligent transportation systems to enhance road safety through early and
reliable drowsiness detection.

</details>


### [20] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
*Christian Simon,Masato Ishii,Akio Hayakawa,Zhi Zhong,Shusuke Takahashi,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 提出了一种名为TITAN-Guide的训练自由指导框架，解决了现有方法在内存需求和控制效果上的不足，特别适用于计算密集型的文本到视频（T2V）扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有的训练自由指导框架要么内存需求高，要么控制效果不佳，限制了其在计算密集型任务（如T2V扩散模型）中的应用。

Method: 开发了一种无需反向传播的高效扩散潜在优化方法，研究了前向梯度下降在指导扩散任务中的应用。

Result: 实验表明，该方法在内存管理和潜在优化方面优于现有方法，显著提升了T2V性能。

Conclusion: TITAN-Guide不仅降低了内存需求，还显著提升了扩散模型在T2V任务中的性能。

Abstract: In the recent development of conditional diffusion models still require heavy
supervised fine-tuning for performing control on a category of tasks.
Training-free conditioning via guidance with off-the-shelf models is a
favorable alternative to avoid further fine-tuning on the base model. However,
the existing training-free guidance frameworks either have heavy memory
requirements or offer sub-optimal control due to rough estimation. These
shortcomings limit the applicability to control diffusion models that require
intense computation, such as Text-to-Video (T2V) diffusion models. In this
work, we propose Taming Inference Time Alignment for Guided Text-to-Video
Diffusion Model, so-called TITAN-Guide, which overcomes memory space issues,
and provides more optimal control in the guidance process compared to the
counterparts. In particular, we develop an efficient method for optimizing
diffusion latents without backpropagation from a discriminative guiding model.
In particular, we study forward gradient descents for guided diffusion tasks
with various options on directional directives. In our experiments, we
demonstrate the effectiveness of our approach in efficiently managing memory
during latent optimization, while previous methods fall short. Our proposed
approach not only minimizes memory requirements but also significantly enhances
T2V performance across a range of diffusion guidance benchmarks. Code, models,
and demo are available at https://titanguide.github.io.

</details>


### [21] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
*Danzhen Fu,Jiagao Hu,Daiguo Zhou,Fei Wang,Zepeng Wang,Wenhua Liao*

Main category: cs.CV

TL;DR: 提出了一种多视角行人视频编辑框架，通过结合视频修复和人体运动控制技术，增强自动驾驶数据集的多样性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统中行人检测模型因训练数据缺乏危险场景而鲁棒性不足的问题。

Method: 识别多视角行人区域，扩展检测框并拼接成统一画布，通过姿态序列控制条件进行行人编辑（插入、替换、删除）。

Result: 实验表明该方法能高质量完成行人编辑，具有视觉真实感、时空一致性和多视角一致性。

Conclusion: 该方法为自动驾驶数据增强和场景模拟提供了强大且通用的解决方案。

Abstract: Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.

</details>


### [22] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
*Jin Lyu,Liang An,Li Lin,Pujin Cheng,Yebin Liu,Xiaoying Tang*

Main category: cs.CV

TL;DR: AniMer+扩展了AniMer框架，通过高容量的Vision Transformer和MoE设计，统一重建哺乳动物和鸟类的姿态与形状，并利用扩散模型生成合成数据集提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法网络容量不足和多物种数据集稀缺的问题，以支持生物研究中的定量分析。

Method: 采用家族感知的Vision Transformer（ViT）和Mixture-of-Experts（MoE）设计，结合扩散模型生成合成数据集CtrlAni3D和CtrlAVES3D。

Result: 在41.3k哺乳动物和12.4k鸟类图像上训练，性能优于现有方法，尤其在Animal Kingdom数据集上表现突出。

Conclusion: AniMer+的网络架构和合成数据集有效提升了真实场景中的应用性能。

Abstract: In the era of foundation models, achieving a unified understanding of
different dynamic objects through a single network has the potential to empower
stronger spatial intelligence. Moreover, accurate estimation of animal pose and
shape across diverse species is essential for quantitative analysis in
biological research. However, this topic remains underexplored due to the
limited network capacity of previous methods and the scarcity of comprehensive
multi-species datasets. To address these limitations, we introduce AniMer+, an
extended version of our scalable AniMer framework. In this paper, we focus on a
unified approach for reconstructing mammals (mammalia) and birds (aves). A key
innovation of AniMer+ is its high-capacity, family-aware Vision Transformer
(ViT) incorporating a Mixture-of-Experts (MoE) design. Its architecture
partitions network layers into taxa-specific components (for mammalia and aves)
and taxa-shared components, enabling efficient learning of both distinct and
common anatomical features within a single model. To overcome the critical
shortage of 3D training data, especially for birds, we introduce a
diffusion-based conditional image generation pipeline. This pipeline produces
two large-scale synthetic datasets: CtrlAni3D for quadrupeds and CtrlAVES3D for
birds. To note, CtrlAVES3D is the first large-scale, 3D-annotated dataset for
birds, which is crucial for resolving single-view depth ambiguities. Trained on
an aggregated collection of 41.3k mammalian and 12.4k avian images (combining
real and synthetic data), our method demonstrates superior performance over
existing approaches across a wide range of benchmarks, including the
challenging out-of-domain Animal Kingdom dataset. Ablation studies confirm the
effectiveness of both our novel network architecture and the generated
synthetic datasets in enhancing real-world application performance.

</details>


### [23] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
*M. A. Pérez-Cutiño,J. Valverde,J. Capitán,J. M. Díaz-Báñez*

Main category: cs.CV

TL;DR: 论文提出AerialCSP虚拟数据集，用于模拟CSP工厂的航拍图像，以减少对大量手动标注数据的依赖，并提升模型在真实场景中的缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: CSP工厂的航拍图像具有高反射表面和领域特定元素，现有通用数据集训练的模型难以直接应用，而手动标注成本高且耗时。

Method: 创建AerialCSP虚拟数据集，模拟真实CSP工厂的航拍图像，用于预训练模型，并评估其在物体检测和图像分割任务上的表现。

Result: 预训练在AerialCSP上的模型显著提升了真实场景中的缺陷检测能力，尤其是对小而罕见的缺陷。

Conclusion: AerialCSP为CSP相关视觉任务提供了高质量合成数据，减少了手动标注需求，推动了工业应用的快速部署。

Abstract: In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.

</details>


### [24] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 提出一种基于上下文感知的运动检索框架，用于自动驾驶系统中罕见人类行为的检索，并在WayMoCo数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在涉及脆弱道路使用者（VRUs）的复杂场景中可靠运行，但大规模数据集中罕见行为的检索具有挑战性。

Method: 结合SMPL运动序列和视频帧，编码到多模态嵌入空间，支持通过文本查询检索人类行为及其上下文。

Result: 在WayMoCo数据集上，运动-上下文检索准确率比现有方法高27.5%。

Conclusion: 提出的框架为自动驾驶系统提供了高效的人类行为检索方法，支持更鲁棒的评估和泛化。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


### [25] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于事件相机的低光图像增强方法，通过解耦增强流程为可见性恢复和结构细化两阶段，结合动态对齐和对比损失，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用事件相机和帧相机的模态优势，限制了低光图像增强的性能。

Method: 1. 可见性恢复网络设计，利用傅里叶空间的振幅-相位关系；2. 动态对齐的融合策略解决模态间空间不匹配；3. 空间频率插值生成负样本，引入对比损失。

Result: 实验表明，该方法优于现有最先进模型。

Conclusion: 通过解耦增强流程和动态对齐策略，有效提升了低光图像增强的性能。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [26] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
*Yufeng Zhong,Zhixiong Zeng,Lei Chen,Longrong Yang,Liming Zheng,Jing Huang,Siqi Yang,Lin Ma*

Main category: cs.CV

TL;DR: DocTron-Formula是一个基于通用视觉语言模型的统一框架，用于数学公式OCR，无需专用架构。结合CSFormula数据集，通过监督微调实现最优性能。


<details>
  <summary>Details</summary>
Motivation: 数学公式OCR在科学文献智能分析中至关重要，但现有模型难以处理其结构多样性和复杂性。

Method: 提出DocTron-Formula框架，利用通用视觉语言模型，并引入CSFormula数据集进行监督微调。

Result: 实验表明，该方法在准确性、鲁棒性上超越专用模型，适用于多种风格和复杂布局。

Conclusion: DocTron-Formula为复杂科学文档的自动理解提供了新范式。

Abstract: Optical Character Recognition (OCR) for mathematical formula is essential for
the intelligent analysis of scientific literature. However, both task-specific
and general vision-language models often struggle to handle the structural
diversity, complexity, and real-world variability inherent in mathematical
content. In this work, we present DocTron-Formula, a unified framework built
upon general vision-language models, thereby eliminating the need for
specialized architectures. Furthermore, we introduce CSFormula, a large-scale
and challenging dataset that encompasses multidisciplinary and structurally
complex formulas at the line, paragraph, and page levels. Through
straightforward supervised fine-tuning, our approach achieves state-of-the-art
performance across a variety of styles, scientific domains, and complex
layouts. Experimental results demonstrate that our method not only surpasses
specialized models in terms of accuracy and robustness, but also establishes a
new paradigm for the automated understanding of complex scientific documents.

</details>


### [27] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
*Wenxuan Guo,Xiuwei Xu,Hang Yin,Ziwei Wang,Jianjiang Feng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: IGL-Nav提出了一种基于3D高斯表示的增量式图像目标导航框架，通过粗定位和细优化实现高效3D感知导航。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法充分建模3D环境与目标图像之间的几何关系，且计算效率低。

Method: 采用增量式3D高斯表示，结合粗定位（离散空间匹配）和细优化（可微渲染）策略。

Result: IGL-Nav在多种实验配置下显著优于现有方法，并能处理自由视角图像目标导航。

Conclusion: IGL-Nav高效且3D感知能力强，适用于实际机器人平台。

Abstract: Visual navigation with an image as goal is a fundamental and challenging
problem. Conventional methods either rely on end-to-end RL learning or
modular-based policy with topological graph or BEV map as memory, which cannot
fully model the geometric relationship between the explored 3D environment and
the goal image. In order to efficiently and accurately localize the goal image
in 3D space, we build our navigation system upon the renderable 3D gaussian
(3DGS) representation. However, due to the computational intensity of 3DGS
optimization and the large search space of 6-DoF camera pose, directly
leveraging 3DGS for image localization during agent exploration process is
prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D
Gaussian Localization framework for efficient and 3D-aware image-goal
navigation. Specifically, we incrementally update the scene representation as
new images arrive with feed-forward monocular prediction. Then we coarsely
localize the goal by leveraging the geometric information for discrete space
matching, which can be equivalent to efficient 3D convolution. When the agent
is close to the goal, we finally solve the fine target pose with optimization
via differentiable rendering. The proposed IGL-Nav outperforms existing
state-of-the-art methods by a large margin across diverse experimental
configurations. It can also handle the more challenging free-view image-goal
setting and be deployed on real-world robotic platform using a cellphone to
capture goal image at arbitrary pose. Project page:
https://gwxuan.github.io/IGL-Nav/.

</details>


### [28] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
*Suhang Cai,Xiaohao Peng,Chong Wang,Xiaojie Cai,Jiangbo Qian*

Main category: cs.CV

TL;DR: 提出了一种基于生成视频增强的弱监督视频异常检测框架（GV-VAD），利用文本条件视频生成模型生成可控且物理合理的合成视频，以低成本扩充训练数据，并通过合成样本损失缩放策略优化训练效果。


<details>
  <summary>Details</summary>
Motivation: 解决真实异常数据稀缺、不可预测且标注成本高的问题，提升视频异常检测模型的性能和泛化能力。

Method: 利用文本条件视频生成模型生成合成视频，并通过合成样本损失缩放策略控制合成样本对训练的影响。

Result: 在UCF-Crime数据集上优于现有最优方法。

Conclusion: GV-VAD框架通过低成本生成合成视频有效提升了视频异常检测的性能和泛化能力。

Abstract: Video anomaly detection (VAD) plays a critical role in public safety
applications such as intelligent surveillance. However, the rarity,
unpredictability, and high annotation cost of real-world anomalies make it
difficult to scale VAD datasets, which limits the performance and
generalization ability of existing models. To address this challenge, we
propose a generative video-enhanced weakly-supervised video anomaly detection
(GV-VAD) framework that leverages text-conditioned video generation models to
produce semantically controllable and physically plausible synthetic videos.
These virtual videos are used to augment training data at low cost. In
addition, a synthetic sample loss scaling strategy is utilized to control the
influence of generated synthetic samples for efficient training. The
experiments show that the proposed framework outperforms state-of-the-art
methods on UCF-Crime datasets. The code is available at
https://github.com/Sumutan/GV-VAD.git.

</details>


### [29] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
*Sunghyun Park,Seokeon Choi,Hyoungwoo Park,Sungrack Yun*

Main category: cs.CV

TL;DR: 提出一种个性化引导方法，通过未学习的弱模型和动态权重插值，平衡目标分布对齐和文本编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CFG和AG）在少样本微调时无法有效平衡目标分布对齐和原始模型知识保留。

Method: 利用未学习的弱模型和动态权重插值，在推理时控制未学习程度。

Result: 实验表明，该方法能提升文本对齐和目标分布保真度，且无需额外计算开销。

Conclusion: 个性化引导方法有效解决了现有方法的局限性，实现了更好的平衡。

Abstract: Personalizing text-to-image diffusion models is crucial for adapting the
pre-trained models to specific target concepts, enabling diverse image
generation. However, fine-tuning with few images introduces an inherent
trade-off between aligning with the target distribution (e.g., subject
fidelity) and preserving the broad knowledge of the original model (e.g., text
editability). Existing sampling guidance methods, such as classifier-free
guidance (CFG) and autoguidance (AG), fail to effectively guide the output
toward well-balanced space: CFG restricts the adaptation to the target
distribution, while AG compromises text alignment. To address these
limitations, we propose personalization guidance, a simple yet effective method
leveraging an unlearned weak model conditioned on a null text prompt. Moreover,
our method dynamically controls the extent of unlearning in a weak model
through weight interpolation between pre-trained and fine-tuned models during
inference. Unlike existing guidance methods, which depend solely on guidance
scales, our method explicitly steers the outputs toward a balanced latent space
without additional computational overhead. Experimental results demonstrate
that our proposed guidance can improve text alignment and target distribution
fidelity, integrating seamlessly with various fine-tuning strategies.

</details>


### [30] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
*Lilika Makabe,Hiroaki Santo,Fumio Okura,Michael S. Brown,Yasuyuki Matsushita*

Main category: cs.CV

TL;DR: 提出了一种使用衍射光栅校准相机光谱灵敏度的实用且准确的方法，仅需未校准的衍射光栅片即可实现。


<details>
  <summary>Details</summary>
Motivation: 相机光谱灵敏度的准确校准对计算机视觉任务（如颜色校正、光照估计和材料分析）至关重要。现有方法需要专用窄带滤波器或已知光谱反射率的目标，而本方法更简单实用。

Method: 通过捕获直接光照及其通过衍射光栅片的衍射图案图像，以闭式方式估计相机光谱灵敏度和衍射光栅参数。

Result: 在合成和真实数据上的实验表明，本方法优于传统的基于参考目标的方法。

Conclusion: 该方法有效且实用，为相机光谱灵敏度校准提供了更简便的解决方案。

Abstract: This paper introduces a practical and accurate calibration method for camera
spectral sensitivity using a diffraction grating. Accurate calibration of
camera spectral sensitivity is crucial for various computer vision tasks,
including color correction, illumination estimation, and material analysis.
Unlike existing approaches that require specialized narrow-band filters or
reference targets with known spectral reflectances, our method only requires an
uncalibrated diffraction grating sheet, readily available off-the-shelf. By
capturing images of the direct illumination and its diffracted pattern through
the grating sheet, our method estimates both the camera spectral sensitivity
and the diffraction grating parameters in a closed-form manner. Experiments on
synthetic and real-world data demonstrate that our method outperforms
conventional reference target-based methods, underscoring its effectiveness and
practicality.

</details>


### [31] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
*Yan Gong,Mengjun Chen,Hao Liu,Gao Yongsheng,Lei Yang,Naibang Wang,Ziying Song,Haoqun Ma*

Main category: cs.CV

TL;DR: 论文提出了一种速度引导的可学习卡尔曼滤波器（SG-LKF），通过动态调整不确定性建模以适应车辆速度，显著提高了动态场景中的跟踪稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统多目标跟踪方法依赖静态坐标变换，忽略了车辆速度对观测噪声和参考帧变化的影响，导致动态高速场景下跟踪性能下降。

Method: 提出SG-LKF，结合MotionScaleNet（MSNet）动态预测关键参数，并引入自监督轨迹一致性损失以增强帧间关联和轨迹连续性。

Result: SG-LKF在KITTI 2D MOT上以79.59% HOTA排名第一，KITTI 3D MOT上达到82.03% HOTA，nuScenes 3D MOT上比SimpleTrack高2.2% AMOTA。

Conclusion: SG-LKF通过动态适应车辆速度，显著提升了多目标跟踪在动态高速场景中的性能。

Abstract: Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.

</details>


### [32] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
*Zongheng Tang,Yi Liu,Yifan Sun,Yulu Gao,Jinyu Chen,Runsheng Xu,Si Liu*

Main category: cs.CV

TL;DR: 论文提出了一种高效的协作感知方法CoST，通过统一时空空间同时聚合多智能体和多时间观测，提升了特征传输效率和融合性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法将多智能体和多时间融合分步处理的问题，提出统一时空空间以提升效率和准确性。

Method: 提出协作感知时空变换器（CoST），统一时空空间同时聚合多智能体和多时间观测。

Result: CoST在效率和准确性上均有提升，兼容多数现有方法，减少传输带宽需求。

Conclusion: CoST通过统一时空空间实现了高效的协作感知，适用于多种场景，具有广泛兼容性。

Abstract: Collaborative perception shares information among different agents and helps
solving problems that individual agents may face, e.g., occlusions and small
sensing range. Prior methods usually separate the multi-agent fusion and
multi-time fusion into two consecutive steps. In contrast, this paper proposes
an efficient collaborative perception that aggregates the observations from
different agents (space) and different times into a unified spatio-temporal
space simultanesouly. The unified spatio-temporal space brings two benefits,
i.e., efficient feature transmission and superior feature fusion. 1) Efficient
feature transmission: each static object yields a single observation in the
spatial temporal space, and thus only requires transmission only once (whereas
prior methods re-transmit all the object features multiple times). 2) superior
feature fusion: merging the multi-agent and multi-time fusion into a unified
spatial-temporal aggregation enables a more holistic perspective, thereby
enhancing perception performance in challenging scenarios. Consequently, our
Collaborative perception with Spatio-temporal Transformer (CoST) gains
improvement in both efficiency and accuracy. Notably, CoST is not tied to any
specific method and is compatible with a majority of previous methods,
enhancing their accuracy while reducing the transmission bandwidth.

</details>


### [33] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 提出了一种基于机器学习的蜂蜜植物来源自动分类方法，包括数据准备、特征提取和分类三步骤，实验结果显示其分类准确率最高达95.13%。


<details>
  <summary>Details</summary>
Motivation: 蜂蜜的植物来源分类对品质评估和真实性验证至关重要，传统方法效率低且准确性不足，需自动化高效解决方案。

Method: 采用类转换方法优化数据准备，使用LDA进行特征提取和降维，并利用SVM和KNN模型进行分类。

Result: 在标准蜂蜜高光谱成像数据集上，分类准确率最高达95.13%，表现优异。

Conclusion: 该方法在蜂蜜植物来源分类中表现出色，为相关领域提供了高效自动化解决方案。

Abstract: In this paper, we propose a machine learning-based method for automatically
classifying honey botanical origins. Dataset preparation, feature extraction,
and classification are the three main steps of the proposed method. We use a
class transformation method in the dataset preparation phase to maximize the
separability across classes. The feature extraction phase employs the Linear
Discriminant Analysis (LDA) technique for extracting relevant features and
reducing the number of dimensions. In the classification phase, we use Support
Vector Machines (SVM) and K-Nearest Neighbors (KNN) models to classify the
extracted features of honey samples into their botanical origins. We evaluate
our system using a standard honey hyperspectral imaging (HSI) dataset.
Experimental findings demonstrate that the proposed system produces
state-of-the-art results on this dataset, achieving the highest classification
accuracy of 95.13% for hyperspectral image-based classification and 92.80% for
hyperspectral instance-based classification.

</details>


### [34] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
*Liang Han,Xu Zhang,Haichuan Song,Kanle Shi,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: SparseRecon提出了一种新的神经隐式重建方法，通过特征一致性和不确定性引导的深度约束，解决了稀疏视图重建中的泛化和几何细节问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在泛化性和重建质量上存在局限，SparseRecon旨在通过新方法提升稀疏视图重建的效果。

Method: 结合体积渲染的特征一致性损失和不确定性引导的深度约束，优化神经隐式场。

Result: 实验表明，SparseRecon在稀疏视图输入下优于现有方法，尤其在视图重叠较少时表现更佳。

Conclusion: SparseRecon通过新设计的约束方法，显著提升了稀疏视图重建的质量和泛化能力。

Abstract: Surface reconstruction from sparse views aims to reconstruct a 3D shape or
scene from few RGB images. The latest methods are either generalization-based
or overfitting-based. However, the generalization-based methods do not
generalize well on views that were unseen during training, while the
reconstruction quality of overfitting-based methods is still limited by the
limited geometry clues. To address this issue, we propose SparseRecon, a novel
neural implicit reconstruction method for sparse views with volume
rendering-based feature consistency and uncertainty-guided depth constraint.
Firstly, we introduce a feature consistency loss across views to constrain the
neural implicit field. This design alleviates the ambiguity caused by
insufficient consistency information of views and ensures completeness and
smoothness in the reconstruction results. Secondly, we employ an
uncertainty-guided depth constraint to back up the feature consistency loss in
areas with occlusion and insignificant features, which recovers geometry
details for better reconstruction quality. Experimental results demonstrate
that our method outperforms the state-of-the-art methods, which can produce
high-quality geometry with sparse-view input, especially in the scenarios with
small overlapping views. Project page: https://hanl2010.github.io/SparseRecon/.

</details>


### [35] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
*Joonmyung Choi,Sanghyeok Lee,Byungoh Ko,Eunseo Kim,Jihyung Kil,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出了一种名为Representation Shift的训练无关、模型无关的度量方法，用于衡量每个token表示的变化程度，从而与FlashAttention兼容，实现有效的token压缩。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂度的增加，Transformer模型和token数量增加，导致自注意力的二次计算成本和GPU内存访问开销上升。现有token压缩方法依赖注意力图，与FlashAttention不兼容。

Method: 提出Representation Shift度量方法，无需训练或注意力图，直接测量token表示的变化程度，实现与FlashAttention兼容的token压缩。

Result: 实验表明，该方法在视频-文本检索和视频QA任务中分别实现了5.5%和4.4%的速度提升。

Conclusion: Representation Shift是一种高效且通用的token压缩方法，适用于多种模型，包括Transformer、CNN和状态空间模型。

Abstract: Transformers have demonstrated remarkable success across vision, language,
and video. Yet, increasing task complexity has led to larger models and more
tokens, raising the quadratic cost of self-attention and the overhead of GPU
memory access. To reduce the computation cost of self-attention, prior work has
proposed token compression techniques that drop redundant or less informative
tokens. Meanwhile, fused attention kernels such as FlashAttention have been
developed to alleviate memory overhead by avoiding attention map construction
and its associated I/O to HBM. This, however, makes it incompatible with most
training-free token compression methods, which rely on attention maps to
determine token importance. Here, we propose Representation Shift, a
training-free, model-agnostic metric that measures the degree of change in each
token's representation. This seamlessly integrates token compression with
FlashAttention, without attention maps or retraining. Our method further
generalizes beyond Transformers to CNNs and state space models. Extensive
experiments show that Representation Shift enables effective token compression
compatible with FlashAttention, yielding significant speedups of up to 5.5% and
4.4% in video-text retrieval and video QA, respectively. Code is available at
https://github.com/mlvlab/Representation-Shift.

</details>


### [36] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: BiAnt通过结合前向和后向预测，利用大语言模型改进视频长期动作预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法因单向性限制了性能，难以捕捉场景中语义不同的子动作。

Method: 结合前向和后向预测，使用大语言模型（BiAnt）。

Result: 在Ego4D数据集上，BiAnt在编辑距离上优于基线方法。

Conclusion: BiAnt通过双向预测提升长期动作预测性能。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [37] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 论文提出Adapt-WeldNet框架，结合预训练模型和可解释性分析（DDIA），提升焊接缺陷检测的性能和透明度。


<details>
  <summary>Details</summary>
Motivation: 传统无损检测方法难以发现细微或内部缺陷，现有神经网络方法缺乏可解释性，影响安全性。

Method: Adapt-WeldNet系统评估预训练架构、迁移学习策略和优化器；DDIA框架结合XAI技术和专家验证。

Result: 优化了缺陷检测性能，并通过可解释性分析增强了系统透明度和信任度。

Conclusion: 该工作提升了焊接缺陷检测系统的可靠性、安全性和可解释性，适用于海洋和离岸环境。

Abstract: Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.

</details>


### [38] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
*Won June Cho,Hongjun Yoon,Daeky Jeong,Hyeongyeol Lim,Yosep Chong*

Main category: cs.CV

TL;DR: 论文提出了一种结合状态空间模型（SSMs）和ViT的混合架构$MV_{Hybrid}$，用于从病理图像预测空间基因表达，性能优于现有ViT模型。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学成本高且技术复杂，限制了临床应用。从常规病理图像预测基因表达是一种实用替代方案，但现有ViT模型性能不足。

Method: 提出$MV_{Hybrid}$架构，结合SSMs和ViT，利用负实特征值初始化SSMs以增强低频模式捕捉能力。

Result: 在LOSO评估中，$MV_{Hybrid}$比最佳ViT模型相关性高57%，性能下降减少43%，且在下游任务中表现优异。

Conclusion: $MV_{Hybrid}$是一种有前景的下一代病理视觉基础模型架构。

Abstract: Spatial transcriptomics reveals gene expression patterns within tissue
context, enabling precision oncology applications such as treatment response
prediction, but its high cost and technical complexity limit clinical adoption.
Predicting spatial gene expression (biomarkers) from routine histopathology
images offers a practical alternative, yet current vision foundation models
(VFMs) in pathology based on Vision Transformer (ViT) backbones perform below
clinical standards. Given that VFMs are already trained on millions of diverse
whole slide images, we hypothesize that architectural innovations beyond ViTs
may better capture the low-frequency, subtle morphological patterns correlating
with molecular phenotypes. By demonstrating that state space models initialized
with negative real eigenvalues exhibit strong low-frequency bias, we introduce
$MV_{Hybrid}$, a hybrid backbone architecture combining state space models
(SSMs) with ViT. We compare five other different backbone architectures for
pathology VFMs, all pretrained on identical colorectal cancer datasets using
the DINOv2 self-supervised learning method. We evaluate all pretrained models
using both random split and leave-one-study-out (LOSO) settings of the same
biomarker dataset. In LOSO evaluation, $MV_{Hybrid}$ achieves 57% higher
correlation than the best-performing ViT and shows 43% smaller performance
degradation compared to random split in gene expression prediction,
demonstrating superior performance and robustness, respectively. Furthermore,
$MV_{Hybrid}$ shows equal or better downstream performance in classification,
patch retrieval, and survival prediction tasks compared to that of ViT, showing
its promise as a next-generation pathology VFM backbone. Our code is publicly
available at: https://github.com/deepnoid-ai/MVHybrid.

</details>


### [39] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
*Guanjie Huang,Danny H. K. Tsang,Shan Yang,Guangzhi Lei,Li Liu*

Main category: cs.CV

TL;DR: 提出了一种名为Cued-Agent的多智能体系统，用于自动识别Cued Speech（CS），通过四个子智能体协作解决手部和唇部动作的异步问题，并在有限数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在CS识别中因手部和唇部动作异步及数据有限导致的性能不足问题。

Method: 设计四个子智能体：基于多模态大语言模型的手部识别、基于Transformer的唇部识别、动态整合手部提示的代理，以及自校正音素到词转换代理。

Result: 在正常和听力受损场景下，Cued-Agent表现优于现有方法。

Conclusion: Cued-Agent通过多智能体协作有效提升了CS识别的性能，尤其在数据有限的情况下。

Abstract: Cued Speech (CS) is a visual communication system that combines lip-reading
with hand coding to facilitate communication for individuals with hearing
impairments. Automatic CS Recognition (ACSR) aims to convert CS hand gestures
and lip movements into text via AI-driven methods. Traditionally, the temporal
asynchrony between hand and lip movements requires the design of complex
modules to facilitate effective multimodal fusion. However, constrained by
limited data availability, current methods demonstrate insufficient capacity
for adequately training these fusion mechanisms, resulting in suboptimal
performance. Recently, multi-agent systems have shown promising capabilities in
handling complex tasks with limited data availability. To this end, we propose
the first collaborative multi-agent system for ACSR, named Cued-Agent. It
integrates four specialized sub-agents: a Multimodal Large Language Model-based
Hand Recognition agent that employs keyframe screening and CS expert prompt
strategies to decode hand movements, a pretrained Transformer-based Lip
Recognition agent that extracts lip features from the input video, a Hand
Prompt Decoding agent that dynamically integrates hand prompts with lip
features during inference in a training-free manner, and a Self-Correction
Phoneme-to-Word agent that enables post-process and end-to-end conversion from
phoneme sequences to natural language sentences for the first time through
semantic refinement. To support this study, we expand the existing Mandarin CS
dataset by collecting data from eight hearing-impaired cuers, establishing a
mixed dataset of fourteen subjects. Extensive experiments demonstrate that our
Cued-Agent performs superbly in both normal and hearing-impaired scenarios
compared with state-of-the-art methods. The implementation is available at
https://github.com/DennisHgj/Cued-Agent.

</details>


### [40] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
*Fei Zhang,Tianfei Zhou,Jiangchao Yao,Ya Zhang,Ivor W. Tsang,Yanfeng Wang*

Main category: cs.CV

TL;DR: DAPT提出了一种基于解耦对齐的提示调优框架，解决了视觉-语言模型中信息不对称的问题，通过解耦视觉模态为前景和背景表示，并分别对齐文本模态，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决提示调优（PT）中视觉模态与文本模态信息不对称的问题，避免模型因粗对齐而偏向关注上下文区域。

Method: 提出DAPT框架，包括视觉模态的前景与背景解耦、分别与文本对齐，以及视觉拉-推正则化以增强视觉注意力。

Result: 在少样本学习、基础到新类泛化和数据高效学习中表现出优越性能。

Conclusion: DAPT通过解耦对齐和视觉正则化，有效解决了模态信息不对称问题，提升了模型性能。

Abstract: Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm,
has showcased remarkable effectiveness in improving the task-specific
transferability of vision-language models. This paper delves into a previously
overlooked information asymmetry issue in PT, where the visual modality mostly
conveys more context than the object-oriented textual modality.
Correspondingly, coarsely aligning these two modalities could result in the
biased attention, driving the model to merely focus on the context area. To
address this, we propose DAPT, an effective PT framework based on an intuitive
decouple-before-align concept. First, we propose to explicitly decouple the
visual modality into the foreground and background representation via
exploiting coarse-and-fine visual segmenting cues, and then both of these
decoupled patterns are aligned with the original foreground texts and the
hand-crafted background classes, thereby symmetrically strengthening the modal
alignment. To further enhance the visual concentration, we propose a visual
pull-push regularization tailored for the foreground-background patterns,
directing the original visual representation towards unbiased attention on the
region-of-interest object. We demonstrate the power of architecture-free DAPT
through few-shot learning, base-to-novel generalization, and data-efficient
learning, all of which yield superior performance across prevailing benchmarks.
Our code will be released at https://github.com/Ferenas/DAPT.

</details>


### [41] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
*Xi Xue,Kunio Suzuki,Nabarun Goswami,Takuya Shintate*

Main category: cs.CV

TL;DR: 提出了一种基于空间-时间一致性的视频伪造检测框架，结合RGB外观特征和光流残差，通过双分支架构检测AI生成视频中的不一致性。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成的视频越来越逼真，现有方法难以捕捉细粒度的时间不一致性，尤其是在高视觉保真度和连贯运动的AI生成视频中。

Method: 采用双分支架构，一支分析RGB帧以检测外观级伪影，另一支处理光流残差以揭示由不完美时间合成引起的细微运动异常。

Result: 在十种不同生成模型的文本到视频和图像到视频任务上进行了广泛实验，证明了方法的鲁棒性和强泛化能力。

Conclusion: 通过整合互补特征，该方法能有效检测多种伪造视频。

Abstract: The rapid advancement of diffusion-based video generation models has led to
increasingly realistic synthetic content, presenting new challenges for video
forgery detection. Existing methods often struggle to capture fine-grained
temporal inconsistencies, particularly in AI-generated videos with high visual
fidelity and coherent motion. In this work, we propose a detection framework
that leverages spatial-temporal consistency by combining RGB appearance
features with optical flow residuals. The model adopts a dual-branch
architecture, where one branch analyzes RGB frames to detect appearance-level
artifacts, while the other processes flow residuals to reveal subtle motion
anomalies caused by imperfect temporal synthesis. By integrating these
complementary features, the proposed method effectively detects a wide range of
forged videos. Extensive experiments on text-to-video and image-to-video tasks
across ten diverse generative models demonstrate the robustness and strong
generalization ability of the proposed approach.

</details>


### [42] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
*Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: iSafetyBench是一个专为工业环境设计的视频语言基准测试，用于评估模型在正常和危险场景下的表现，揭示了现有模型在识别危险活动方面的不足。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在高风险工业领域中的能力，填补现有研究在安全关键场景中的空白。

Method: 构建iSafetyBench数据集，包含1,100个工业场景视频片段，标注了98种常规和67种危险动作类别，并通过多选题进行单标签和多标签评估。

Result: 评估了8种最先进的视频语言模型，发现它们在识别危险活动及多标签场景中表现不佳。

Conclusion: iSafetyBench为工业应用中的安全感知多模态模型提供了首个测试平台，揭示了现有模型的性能差距。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
generalization across diverse video understanding tasks under zero-shot
settings. However, their capabilities in high-stakes industrial domains-where
recognizing both routine operations and safety-critical anomalies is
essential-remain largely underexplored. To address this gap, we introduce
iSafetyBench, a new video-language benchmark specifically designed to evaluate
model performance in industrial environments across both normal and hazardous
scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world
industrial settings, annotated with open-vocabulary, multi-label action tags
spanning 98 routine and 67 hazardous action categories. Each clip is paired
with multiple-choice questions for both single-label and multi-label
evaluation, enabling fine-grained assessment of VLMs in both standard and
safety-critical contexts. We evaluate eight state-of-the-art video-language
models under zero-shot conditions. Despite their strong performance on existing
video benchmarks, these models struggle with iSafetyBench-particularly in
recognizing hazardous activities and in multi-label scenarios. Our results
reveal significant performance gaps, underscoring the need for more robust,
safety-aware multimodal models for industrial applications. iSafetyBench
provides a first-of-its-kind testbed to drive progress in this direction. The
dataset is available at: https://github.com/raiyaan-abdullah/iSafety-Bench.

</details>


### [43] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
*Janika Deborah Gajo,Gerarld Paul Merales,Jerome Escarcha,Brenden Ashley Molina,Gian Nartea,Emmanuel G. Maminta,Juan Carlos Roldan,Rowel O. Atienza*

Main category: cs.CV

TL;DR: Sari Sandbox是一个高保真、逼真的3D零售店模拟环境，用于评估具身代理在购物任务中与人类表现的对比。


<details>
  <summary>Details</summary>
Motivation: 填补零售领域具身代理训练模拟环境的空白。

Method: 提供包含250多种交互式杂货商品的三种商店配置，支持VR和VLM驱动的具身代理，并附带SariBench数据集。

Result: 具身代理能够导航、检查和操作零售商品，并与人类表现进行基准对比。

Conclusion: 提出了性能分析和改进建议，代码开源。

Abstract: We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store
simulation for benchmarking embodied agents against human performance in
shopping tasks. Addressing a gap in retail-specific sim environments for
embodied agent training, Sari Sandbox features over 250 interactive grocery
items across three store configurations, controlled via an API. It supports
both virtual reality (VR) for human interaction and a vision language model
(VLM)-powered embodied agent. We also introduce SariBench, a dataset of
annotated human demonstrations across varied task difficulties. Our sandbox
enables embodied agents to navigate, inspect, and manipulate retail items,
providing baselines against human performance. We conclude with benchmarks,
performance analysis, and recommendations for enhancing realism and
scalability. The source code can be accessed via
https://github.com/upeee/sari-sandbox-env.

</details>


### [44] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
*Tao Wu,Jingyuan Ye,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种动态效率指数（DEI）和多阶段视频恢复框架（PMR），用于解决大气湍流导致的视频质量下降问题，特别是在强湍流和复杂动态场景下。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以恢复边缘细节和消除混合失真，尤其是在强湍流和复杂动态条件下。

Method: 引入DEI量化视频动态强度，并提出PMR框架，包括去倾斜、运动分割增强和去模糊三个阶段。

Result: 实验表明，该方法能有效抑制运动拖尾伪影、恢复边缘细节，并具有强泛化能力。

Conclusion: PMR框架在高效性和高质量恢复之间取得了平衡，适用于高湍流和复杂动态场景。

Abstract: Geometric distortions and blurring caused by atmospheric turbulence degrade
the quality of long-range dynamic scene videos. Existing methods struggle with
restoring edge details and eliminating mixed distortions, especially under
conditions of strong turbulence and complex dynamics. To address these
challenges, we introduce a Dynamic Efficiency Index ($DEI$), which combines
turbulence intensity, optical flow, and proportions of dynamic regions to
accurately quantify video dynamic intensity under varying turbulence conditions
and provide a high-dynamic turbulence training dataset. Additionally, we
propose a Physical Model-Driven Multi-Stage Video Restoration ($PMR$) framework
that consists of three stages: \textbf{de-tilting} for geometric stabilization,
\textbf{motion segmentation enhancement} for dynamic region refinement, and
\textbf{de-blurring} for quality restoration. $PMR$ employs lightweight
backbones and stage-wise joint training to ensure both efficiency and high
restoration quality. Experimental results demonstrate that the proposed method
effectively suppresses motion trailing artifacts, restores edge details and
exhibits strong generalization capability, especially in real-world scenarios
characterized by high-turbulence and complex dynamics. We will make the code
and datasets openly available.

</details>


### [45] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
*Hanqi Chen,Xu Zhang,Xiaoliu Guan,Lielin Jiang,Guanzhong Wang,Zeyu Chen,Yi Liu*

Main category: cs.CV

TL;DR: Sortblock是一种无需训练的推理加速框架，通过动态缓存块级特征和选择性跳过冗余计算，显著提升Diffusion Transformers的推理速度。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers（DiTs）因其顺序去噪过程导致高推理延迟，限制了实时应用。现有加速方法未能充分利用去噪阶段和Transformer块的语义变化。

Method: 提出Sortblock框架，动态缓存块级特征，基于相邻时间步的相似性排序残差演化，自适应确定重计算比例，并引入轻量级线性预测机制减少误差。

Result: 实验表明，Sortblock在多种任务和DiT架构上实现超过2倍的推理加速，且输出质量损失极小。

Conclusion: Sortblock为扩散生成模型提供了一种高效且通用的加速解决方案。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable generative
capabilities, particularly benefiting from Transformer architectures that
enhance visual and artistic fidelity. However, their inherently sequential
denoising process results in high inference latency, limiting their deployment
in real-time scenarios. Existing training-free acceleration approaches
typically reuse intermediate features at fixed timesteps or layers, overlooking
the evolving semantic focus across denoising stages and Transformer blocks.To
address this, we propose Sortblock, a training-free inference acceleration
framework that dynamically caches block-wise features based on their similarity
across adjacent timesteps. By ranking the evolution of residuals, Sortblock
adaptively determines a recomputation ratio, selectively skipping redundant
computations while preserving generation quality. Furthermore, we incorporate a
lightweight linear prediction mechanism to reduce accumulated errors in skipped
blocks.Extensive experiments across various tasks and DiT architectures
demonstrate that Sortblock achieves over 2$\times$ inference speedup with
minimal degradation in output quality, offering an effective and generalizable
solution for accelerating diffusion-based generative models.

</details>


### [46] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
*Junyu Chen,Dongyun Zou,Wenkun He,Junsong Chen,Enze Xie,Song Han,Han Cai*

Main category: cs.CV

TL;DR: DC-AE 1.5是一种新型深度压缩自编码器，通过结构化潜在空间和增强扩散训练策略，解决了高分辨率扩散模型中潜在通道增加导致的收敛慢和生成质量下降问题。


<details>
  <summary>Details</summary>
Motivation: 潜在通道增加虽能提升重建质量，但会导致扩散模型收敛慢，限制生成质量上限。

Method: 提出结构化潜在空间和增强扩散训练策略，优化潜在空间结构和加速收敛。

Result: DC-AE 1.5在ImageNet 512x512上生成质量优于DC-AE，且速度快4倍。

Conclusion: DC-AE 1.5通过创新方法显著提升了扩散模型的性能和效率。

Abstract: We present DC-AE 1.5, a new family of deep compression autoencoders for
high-resolution diffusion models. Increasing the autoencoder's latent channel
number is a highly effective approach for improving its reconstruction quality.
However, it results in slow convergence for diffusion models, leading to poorer
generation quality despite better reconstruction quality. This issue limits the
quality upper bound of latent diffusion models and hinders the employment of
autoencoders with higher spatial compression ratios. We introduce two key
innovations to address this challenge: i) Structured Latent Space, a
training-based approach to impose a desired channel-wise structure on the
latent space with front latent channels capturing object structures and latter
latent channels capturing image details; ii) Augmented Diffusion Training, an
augmented diffusion training strategy with additional diffusion training
objectives on object latent channels to accelerate convergence. With these
techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling
results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better
image generation quality than DC-AE-f32c32 while being 4x faster. Code:
https://github.com/dc-ai-projects/DC-Gen.

</details>


### [47] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
*Sangwoo Youn,Minji Lee,Nokap Tony Park,Yeonggyoo Jeon,Taeyoung Na*

Main category: cs.CV

TL;DR: 论文提出了一种基于视频修复模型的视频外绘方法，通过改进判别器设计和损失函数，解决了现有方法在扩展视频边界时模糊的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频外绘方法在扩展边界时往往仅生成背景，导致结果模糊，无法保持内容一致性。

Method: 采用视频修复模型，设计分层判别器以区分全局和局部目标，并开发专用外绘损失函数。

Result: 提出的方法在定量和定性上均优于现有技术。

Conclusion: 通过改进判别器和损失函数，实现了视觉吸引力和全局一致性的视频外绘。

Abstract: Video outpainting presents a unique challenge of extending the borders while
maintaining consistency with the given content. In this paper, we suggest the
use of video inpainting models that excel in object flow learning and
reconstruction in outpainting rather than solely generating the background as
in existing methods. However, directly applying or fine-tuning inpainting
models to outpainting has shown to be ineffective, often leading to blurry
results. Our extensive experiments on discriminator designs reveal that a
critical component missing in the outpainting fine-tuning process is a
discriminator capable of effectively assessing the perceptual quality of the
extended areas. To tackle this limitation, we differentiate the objectives of
adversarial training into global and local goals and introduce a hierarchical
discriminator that meets both objectives. Additionally, we develop a
specialized outpainting loss function that leverages both local and global
features of the discriminator. Fine-tuning on this adversarial loss function
enhances the generator's ability to produce both visually appealing and
globally coherent outpainted scenes. Our proposed method outperforms
state-of-the-art methods both quantitatively and qualitatively. Supplementary
materials including the demo video and the code are available in SigPort.

</details>


### [48] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
*Runmin Cong,Zongji Yu,Hao Fang,Haoyan Sun,Sam Kwong*

Main category: cs.CV

TL;DR: 提出首个基于Mamba的水下实例分割模型UIS-Mamba，通过动态树扫描（DTS）和隐藏状态弱化（HSW）模块解决水下场景的挑战，并在性能上达到最优。


<details>
  <summary>Details</summary>
Motivation: 水下实例分割任务因水下场景的特殊性（如颜色失真和模糊边界）面临挑战，现有固定补丁扫描机制无法保持实例连续性，复杂背景也会干扰实例理解。

Method: 设计了DTS模块（动态调整补丁偏移和缩放以保持特征连续性）和HSW模块（基于Ncut的隐藏状态弱化机制抑制背景干扰）。

Result: 在UIIS和USIS10K数据集上达到最优性能，同时保持低参数和计算复杂度。

Conclusion: UIS-Mamba成功将Mamba迁移至水下任务，为水下实例分割提供了高效解决方案。

Abstract: Underwater Instance Segmentation (UIS) tasks are crucial for underwater
complex scene detection. Mamba, as an emerging state space model with
inherently linear complexity and global receptive fields, is highly suitable
for processing image segmentation tasks with long sequence features. However,
due to the particularity of underwater scenes, there are many challenges in
applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot
maintain the internal continuity of scanned instances in the presence of
severely underwater color distortion and blurred instance boundaries, and the
hidden state of the complex underwater background can also inhibit the
understanding of instance objects. In this work, we propose the first
Mamba-based underwater instance segmentation model UIS-Mamba, and design two
innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to
migrate Mamba to the underwater task. DTS module maintains the continuity of
the internal features of the instance objects by allowing the patches to
dynamically offset and scale, thereby guiding the minimum spanning tree and
providing dynamic local receptive fields. HSW module suppresses the
interference of complex backgrounds and effectively focuses the information
flow of state propagation to the instances themselves through the Ncut-based
hidden state weakening mechanism. Experimental results show that UIS-Mamba
achieves state-of-the-art performance on both UIIS and USIS10K datasets, while
maintaining a low number of parameters and computational complexity. Code is
available at https://github.com/Maricalce/UIS-Mamba.

</details>


### [49] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
*Seunggeun Chi,Enna Sachdeva,Pin-Hao Huang,Kwonjoon Lee*

Main category: cs.CV

TL;DR: 提出了一种结合物理先验知识和多区域修复技术的新方法，用于动态场景中遮挡物体的完整推断，显著提升了人-物交互（HOI）场景下的完成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如预训练扩散模型）在动态场景中因对人-物交互理解有限，难以生成合理的完成结果。

Method: 利用人类拓扑和接触信息的物理约束，定义主次区域，并在扩散模型中采用定制化的去噪策略进行多区域修复。

Result: 实验表明，该方法在HOI场景中显著优于现有方法，且在无真实接触标注时仍具鲁棒性。

Conclusion: 该方法提升了机器感知的动态环境理解能力，适用于3D重建和新视角/姿态合成等任务。

Abstract: Amodal completion, which is the process of inferring the full appearance of
objects despite partial occlusions, is crucial for understanding complex
human-object interactions (HOI) in computer vision and robotics. Existing
methods, such as those that use pre-trained diffusion models, often struggle to
generate plausible completions in dynamic scenarios because they have a limited
understanding of HOI. To solve this problem, we've developed a new approach
that uses physical prior knowledge along with a specialized multi-regional
inpainting technique designed for HOI. By incorporating physical constraints
from human topology and contact information, we define two distinct regions:
the primary region, where occluded object parts are most likely to be, and the
secondary region, where occlusions are less probable. Our multi-regional
inpainting method uses customized denoising strategies across these regions
within a diffusion model. This improves the accuracy and realism of the
generated completions in both their shape and visual detail. Our experimental
results show that our approach significantly outperforms existing methods in
HOI scenarios, moving machine perception closer to a more human-like
understanding of dynamic environments. We also show that our pipeline is robust
even without ground-truth contact annotations, which broadens its applicability
to tasks like 3D reconstruction and novel view/pose synthesis.

</details>


### [50] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
*Jiale Zhou,Wenhan Wang,Shikun Li,Xiaolei Qu,Xin Guo,Yizhong Liu,Wenzhong Tang,Xun Lin,Yefeng Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种针对管状结构分割（TSS）的测试时适应框架TopoTTA，通过两阶段方法解决领域偏移问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 管状结构分割对领域偏移特别敏感，传统方法在未见目标域中性能下降明显，因此需要专门的方法来保持拓扑结构的完整性。

Method: TopoTTA分为两阶段：1）使用TopoMDCs适应跨域拓扑差异；2）通过TopoHG生成硬样本并利用伪标签优化拓扑连续性。

Result: 在四个场景和十个数据集上的实验表明，TopoTTA平均提升了31.81%的clDice分数。

Conclusion: TopoTTA是一种有效的即插即用解决方案，适用于基于CNN的TSS模型。

Abstract: Tubular structure segmentation (TSS) is important for various applications,
such as hemodynamic analysis and route navigation. Despite significant progress
in TSS, domain shifts remain a major challenge, leading to performance
degradation in unseen target domains. Unlike other segmentation tasks, TSS is
more sensitive to domain shifts, as changes in topological structures can
compromise segmentation integrity, and variations in local features
distinguishing foreground from background (e.g., texture and contrast) may
further disrupt topological continuity. To address these challenges, we propose
Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time
adaptation framework designed specifically for TSS. TopoTTA consists of two
stages: Stage 1 adapts models to cross-domain topological discrepancies using
the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance
topological representation without altering pre-trained parameters; Stage 2
improves topological continuity by a novel Topology Hard sample Generation
(TopoHG) strategy and prediction alignment on hard samples with pseudo-labels
in the generated pseudo-break regions. Extensive experiments across four
scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling
topological distribution shifts, achieving an average improvement of 31.81% in
clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS
models.

</details>


### [51] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
*Longfei Huang,Yu Liang,Hao Zhang,Jinwei Chen,Wei Dong,Lunde Chen,Wanyu Liu,Bo Li,Pengtao Jiang*

Main category: cs.CV

TL;DR: SDMatte利用扩散模型的强大先验和视觉提示驱动的交互能力，提出了一种新的交互式抠图方法，显著提升了边缘细节的提取能力。


<details>
  <summary>Details</summary>
Motivation: 现有交互式抠图方法在提取边缘区域的细粒度细节方面表现不足，而扩散模型在建模复杂数据分布和合成真实纹理细节方面表现出色。

Method: SDMatte通过将文本驱动的交互能力转化为视觉提示驱动的交互能力，结合坐标嵌入和不透明度嵌入，并引入掩码自注意力机制。

Result: 在多个数据集上的实验表明，SDMatte在交互式抠图中表现出色。

Conclusion: SDMatte通过扩散模型和视觉提示驱动的交互能力，有效提升了抠图的精度和细节提取能力。

Abstract: Recent interactive matting methods have shown satisfactory performance in
capturing the primary regions of objects, but they fall short in extracting
fine-grained details in edge regions. Diffusion models trained on billions of
image-text pairs, demonstrate exceptional capability in modeling highly complex
data distributions and synthesizing realistic texture details, while exhibiting
robust text-driven interaction capabilities, making them an attractive solution
for interactive matting. To this end, we propose SDMatte, a diffusion-driven
interactive matting model, with three key contributions. First, we exploit the
powerful priors of diffusion models and transform the text-driven interaction
capability into visual prompt-driven interaction capability to enable
interactive matting. Second, we integrate coordinate embeddings of visual
prompts and opacity embeddings of target objects into U-Net, enhancing
SDMatte's sensitivity to spatial position information and opacity information.
Third, we propose a masked self-attention mechanism that enables the model to
focus on areas specified by visual prompts, leading to better performance.
Extensive experiments on multiple datasets demonstrate the superior performance
of our method, validating its effectiveness in interactive matting. Our code
and model are available at https://github.com/vivoCameraResearch/SDMatte.

</details>


### [52] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
*Hongyi Cai,Mohammad Mahdinur Rahman,Mingkang Dong,Jie Li,Muxin Pu,Zhili Fang,Yinan Peng,Hanjun Luo,Yang Liu*

Main category: cs.CV

TL;DR: AutoDebias是一个自动识别并减少文本到图像（T2I）模型中社会偏见的框架，无需预先知道具体偏见类型。


<details>
  <summary>Details</summary>
Motivation: T2I模型常表现出未提及的社会偏见（如性别或种族刻板印象），现有方法难以处理复杂或重叠的偏见。

Method: 利用视觉语言模型检测偏见模式，生成包容性提示作为公平指南，并通过CLIP引导的训练过程优化模型。

Result: 在25种偏见场景中，AutoDebias检测准确率达91.6%，将偏见输出从90%降至可忽略水平，同时保持图像质量。

Conclusion: AutoDebias能有效处理复杂偏见，显著减少偏见输出，且不影响模型性能。

Abstract: Text-to-Image (T2I) models generate high-quality images from text prompts but
often exhibit unintended social biases, such as gender or racial stereotypes,
even when these attributes are not mentioned. Existing debiasing methods work
well for simple or well-known cases but struggle with subtle or overlapping
biases. We propose AutoDebias, a framework that automatically identifies and
mitigates harmful biases in T2I models without prior knowledge of specific bias
types. Specifically, AutoDebias leverages vision-language models to detect
biased visual patterns and constructs fairness guides by generating inclusive
alternative prompts that reflect balanced representations. These guides drive a
CLIP-guided training process that promotes fairer outputs while preserving the
original model's image quality and diversity. Unlike existing methods,
AutoDebias effectively addresses both subtle stereotypes and multiple
interacting biases. We evaluate the framework on a benchmark covering over 25
bias scenarios, including challenging cases where multiple biases occur
simultaneously. AutoDebias detects harmful patterns with 91.6% accuracy and
reduces biased outputs from 90% to negligible levels, while preserving the
visual fidelity of the original model.

</details>


### [53] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
*Anju Rani,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.CV

TL;DR: CLIPTime是一种基于CLIP架构的多模态多任务框架，旨在通过图像和文本输入预测真菌生长的发育阶段和时间戳，无需显式时间输入。


<details>
  <summary>Details</summary>
Motivation: 理解生物生长的时间动态对微生物学、农业等领域至关重要，但现有视觉语言模型在捕捉时间进展方面效果有限。

Method: 基于CLIP架构，CLIPTime学习联合视觉-文本嵌入，通过分类和回归预测离散生长阶段和连续时间戳，并使用合成数据集进行训练和评估。

Result: 实验表明，CLIPTime能有效建模生物进展，并生成可解释的时间相关输出。

Conclusion: CLIPTime展示了视觉语言模型在生物监测应用中的潜力。

Abstract: Understanding the temporal dynamics of biological growth is critical across
diverse fields such as microbiology, agriculture, and biodegradation research.
Although vision-language models like Contrastive Language Image Pretraining
(CLIP) have shown strong capabilities in joint visual-textual reasoning, their
effectiveness in capturing temporal progression remains limited. To address
this, we propose CLIPTime, a multimodal, multitask framework designed to
predict both the developmental stage and the corresponding timestamp of fungal
growth from image and text inputs. Built upon the CLIP architecture, our model
learns joint visual-textual embeddings and enables time-aware inference without
requiring explicit temporal input during testing. To facilitate training and
evaluation, we introduce a synthetic fungal growth dataset annotated with
aligned timestamps and categorical stage labels. CLIPTime jointly performs
classification and regression, predicting discrete growth stages alongside
continuous timestamps. We also propose custom evaluation metrics, including
temporal accuracy and regression error, to assess the precision of time-aware
predictions. Experimental results demonstrate that CLIPTime effectively models
biological progression and produces interpretable, temporally grounded outputs,
highlighting the potential of vision-language models in real-world biological
monitoring applications.

</details>


### [54] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: PIF-Net 是一个多光谱和高光谱图像融合框架，通过引入不适定先验和可逆 Mamba 架构，解决了数据对齐问题，同时保持计算效率和模型轻量化。


<details>
  <summary>Details</summary>
Motivation: 多光谱和高光谱图像融合任务由于光谱与空间信息的固有权衡和数据对齐问题，具有不适定性。现有方法未能有效解决这一问题。

Method: 提出 PIF-Net，结合不适定先验和可逆 Mamba 架构，设计 Fusion-Aware Low-Rank Adaptation 模块动态校准特征。

Result: 在多个基准数据集上，PIF-Net 显著优于现有方法，同时保持高效。

Conclusion: PIF-Net 有效解决了图像融合中的不适定问题，提升了性能并保持了模型效率。

Abstract: The goal of multispectral and hyperspectral image fusion (MHIF) is to
generate high-quality images that simultaneously possess rich spectral
information and fine spatial details. However, due to the inherent trade-off
between spectral and spatial information and the limited availability of
observations, this task is fundamentally ill-posed. Previous studies have not
effectively addressed the ill-posed nature caused by data misalignment. To
tackle this challenge, we propose a fusion framework named PIF-Net, which
explicitly incorporates ill-posed priors to effectively fuse multispectral
images and hyperspectral images. To balance global spectral modeling with
computational efficiency, we design a method based on an invertible Mamba
architecture that maintains information consistency during feature
transformation and fusion, ensuring stable gradient flow and process
reversibility. Furthermore, we introduce a novel fusion module called the
Fusion-Aware Low-Rank Adaptation module, which dynamically calibrates spectral
and spatial features while keeping the model lightweight. Extensive experiments
on multiple benchmark datasets demonstrate that PIF-Net achieves significantly
better image restoration performance than current state-of-the-art methods
while maintaining model efficiency.

</details>


### [55] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
*Yiwen Wang,Xinning Chai,Yuhong Zhang,Zhengxue Cheng,Jun Zhao,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: SeTe-VSR是一种结合语义和时空引导的视频超分辨率方法，显著提升了细节恢复和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频超分辨率模型在生成过程中难以同时保证高保真度和时间一致性。

Method: 提出SeTe-VSR，通过在潜在扩散空间中引入语义和时空引导信息。

Result: 实验表明，SeTe-VSR在细节恢复和感知质量上优于现有方法。

Conclusion: SeTe-VSR有效解决了复杂视频超分辨率任务中的挑战。

Abstract: Recent advancements in video super-resolution (VSR) models have demonstrated
impressive results in enhancing low-resolution videos. However, due to
limitations in adequately controlling the generation process, achieving high
fidelity alignment with the low-resolution input while maintaining temporal
consistency across frames remains a significant challenge. In this work, we
propose Semantic and Temporal Guided Video Super-Resolution (SeTe-VSR), a novel
approach that incorporates both semantic and temporal-spatio guidance in the
latent diffusion space to address these challenges. By incorporating high-level
semantic information and integrating spatial and temporal information, our
approach achieves a seamless balance between recovering intricate details and
ensuring temporal coherence. Our method not only preserves high-reality visual
content but also significantly enhances fidelity. Extensive experiments
demonstrate that SeTe-VSR outperforms existing methods in terms of detail
recovery and perceptual quality, highlighting its effectiveness for complex
video super-resolution tasks.

</details>


### [56] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: 提出了一种基于双曲时空变换器（HyPCV-Former）的视频异常检测方法，利用双曲空间捕捉层次事件结构，并通过双曲多头自注意力机制建模时间动态，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在RGB或深度域中使用欧几里得表示，难以捕捉层次事件结构和时空连续性，因此需要一种新的方法来克服这些限制。

Method: 通过点云提取器提取每帧空间特征，并将其嵌入洛伦兹双曲空间，引入双曲多头自注意力机制（HMHA）建模时间动态，直接在双曲空间中进行特征变换和异常评分。

Result: 在TIMo数据集上性能提升7%，在DAD数据集上提升5.6%，优于现有基准方法。

Conclusion: HyPCV-Former通过双曲空间建模显著提升了视频异常检测性能，为复杂事件结构分析提供了新思路。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


### [57] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
*Yuzhuo Chen,Zehua Ma,Jianhua Wang,Kai Kang,Shunyu Yao,Weiming Zhang*

Main category: cs.CV

TL;DR: LAMIC是一种无需训练即可将单参考扩散模型扩展到多参考场景的布局感知多图像合成框架，通过两种注意力机制和三个新指标实现卓越性能。


<details>
  <summary>Details</summary>
Motivation: 解决多参考图像合成中空间布局一致性和连贯性的挑战。

Method: 基于MMDiT模型，引入Group Isolation Attention (GIA)和Region-Modulated Attention (RMA)两种注意力机制。

Result: 在ID-S、BG-S、IN-R和AVG等指标上优于现有基线，展示了零样本泛化能力。

Conclusion: LAMIC为可控多图像合成提供了一种无需训练的新范式，具有强大的零样本泛化能力。

Abstract: In controllable image synthesis, generating coherent and consistent images
from multiple references with spatial layout awareness remains an open
challenge. We present LAMIC, a Layout-Aware Multi-Image Composition framework
that, for the first time, extends single-reference diffusion models to
multi-reference scenarios in a training-free manner. Built upon the MMDiT
model, LAMIC introduces two plug-and-play attention mechanisms: 1) Group
Isolation Attention (GIA) to enhance entity disentanglement; and 2)
Region-Modulated Attention (RMA) to enable layout-aware generation. To
comprehensively evaluate model capabilities, we further introduce three
metrics: 1) Inclusion Ratio (IN-R) and Fill Ratio (FI-R) for assessing layout
control; and 2) Background Similarity (BG-S) for measuring background
consistency. Extensive experiments show that LAMIC achieves state-of-the-art
performance across most major metrics: it consistently outperforms existing
multi-reference baselines in ID-S, BG-S, IN-R and AVG scores across all
settings, and achieves the best DPG in complex composition tasks. These results
demonstrate LAMIC's superior abilities in identity keeping, background
preservation, layout control, and prompt-following, all achieved without any
training or fine-tuning, showcasing strong zero-shot generalization ability. By
inheriting the strengths of advanced single-reference models and enabling
seamless extension to multi-image scenarios, LAMIC establishes a new
training-free paradigm for controllable multi-image composition. As foundation
models continue to evolve, LAMIC's performance is expected to scale
accordingly. Our implementation is available at:
https://github.com/Suchenl/LAMIC.

</details>


### [58] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: SAMSA 2.0是一个交互式分割框架，通过结合光谱角度提示和空间线索，提升了高光谱医学图像的分割准确性。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱医学图像分割中光谱信息利用不足的问题，提升分割精度和鲁棒性。

Method: 引入光谱角度提示，将光谱相似性与空间线索结合，指导Segment Anything Model (SAM)。

Result: 无需重新训练，SAMSA 2.0的Dice分数比RGB模型高3.8%，比现有光谱融合方法高3.1%。

Conclusion: SAMSA 2.0在少样本和零样本场景下表现优异，适用于临床图像中的低数据和噪声挑战。

Abstract: We present SAMSA 2.0, an interactive segmentation framework for hyperspectral
medical imaging that introduces spectral angle prompting to guide the Segment
Anything Model (SAM) using spectral similarity alongside spatial cues. This
early fusion of spectral information enables more accurate and robust
segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0
achieves up to +3.8% higher Dice scores compared to RGB-only models and up to
+3.1% over prior spectral fusion methods. Our approach enhances few-shot and
zero-shot performance, demonstrating strong generalization in challenging
low-data and noisy scenarios common in clinical imaging.

</details>


### [59] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
*Mohammed Kamran,Maria Bernathova,Raoul Varga,Christian Singer,Zsuzsanna Bago-Horvath,Thomas Helbich,Georg Langs,Philipp Seeböck*

Main category: cs.CV

TL;DR: LesiOnTime是一种新的3D分割方法，结合纵向影像和BI-RADS评分，显著提升了小病灶分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要针对大病灶，忽略了纵向和临床信息，而早期癌症检测需要这些信息。

Method: 提出Temporal Prior Attention（TPA）块和BI-RADS Consistency Regularization（BCR）损失函数，整合纵向数据和临床评分。

Result: 在DCE-MRI数据集上，Dice分数比现有方法提升5%。

Conclusion: 结合时间和临床信息对小病灶分割至关重要，LesiOnTime为乳腺癌筛查提供了可靠工具。

Abstract: Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced
MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk
patients. While recent deep learning methods have advanced lesion segmentation,
they primarily target large lesions and neglect valuable longitudinal and
clinical information routinely used by radiologists. In real-world screening,
detecting subtle or emerging lesions requires radiologists to compare across
timepoints and consider previous radiology assessments, such as the BI-RADS
score. We propose LesiOnTime, a novel 3D segmentation approach that mimics
clinical diagnostic workflows by jointly leveraging longitudinal imaging and
BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA)
block that dynamically integrates information from previous and current scans;
and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent
space alignment for scans with similar radiological assessments, thus embedding
domain knowledge into the training process. Evaluated on a curated in-house
longitudinal dataset of high-risk patients with DCE-MRI, our approach
outperforms state-of-the-art single-timepoint and longitudinal baselines by 5%
in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute
complementary performance gains. These results highlight the importance of
incorporating temporal and clinical context for reliable early lesion
segmentation in real-world breast cancer screening. Our code is publicly
available at https://github.com/cirmuw/LesiOnTime

</details>


### [60] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
*Tulsi Patel,Mark W. Jones,Thomas Redfern*

Main category: cs.CV

TL;DR: 提出了一种无监督的遥感图像标注方法，利用卷积和图神经网络进行分割和特征编码，提高了标注的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 遥感图像标注通常依赖专家分析，耗时且成本高。现有方法需要预标注数据，限制了其应用范围。

Method: 结合卷积神经网络和图神经网络，对图像进行分割和特征编码，通过颜色和空间相似性分组像素，并利用图神经网络聚合周围信息。

Result: 减少了标注中的异常值，支持细粒度标注，并在编码空间中形成旋转不变的语义关系。

Conclusion: 该方法克服了现有方法的局限性，提供了一种更高效的遥感图像标注工具。

Abstract: Machine learning for remote sensing imaging relies on up-to-date and accurate
labels for model training and testing. Labelling remote sensing imagery is time
and cost intensive, requiring expert analysis. Previous labelling tools rely on
pre-labelled data for training in order to label new unseen data. In this work,
we define an unsupervised pipeline for finding and labelling geographical areas
of similar context and content within Sentinel-2 satellite imagery. Our
approach removes limitations of previous methods by utilising segmentation with
convolutional and graph neural networks to encode a more robust feature space
for image comparison. Unlike previous approaches we segment the image into
homogeneous regions of pixels that are grouped based on colour and spatial
similarity. Graph neural networks are used to aggregate information about the
surrounding segments enabling the feature representation to encode the local
neighbourhood whilst preserving its own local information. This reduces
outliers in the labelling tool, allows users to label at a granular level, and
allows a rotationally invariant semantic relationship at the image level to be
formed within the encoding space.

</details>


### [61] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 论文提出EgoMask，首个针对第一人称视频的像素级时空定位基准，通过自动标注流程构建，并创建大规模训练数据集EgoMask-Train。实验表明现有模型在EgoMask上表现不佳，但微调后显著提升。


<details>
  <summary>Details</summary>
Motivation: 第一人称视频（如增强现实和机器人应用）的时空定位研究较少，现有方法主要针对第三人称视频。论文揭示了两者的差异（如物体持续时间短、轨迹稀疏等），并提出了解决方案。

Method: 提出EgoMask基准，通过自动标注流程生成包含短、中、长期视频的标注数据，并构建EgoMask-Train训练集。

Result: 现有模型在EgoMask上表现不佳，但通过EgoMask-Train微调后性能显著提升，且不影响在第三人称数据集上的表现。

Conclusion: EgoMask为第一人称视频理解提供了关键资源和见解，推动了该领域的发展。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [62] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
*Jinsong Yang,Zeyuan Hu,Yichen Li*

Main category: cs.CV

TL;DR: 提出了一种高效路径聚合网络（EPANet），用于水下鱼类检测，通过互补特征集成实现轻量级且准确的检测。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类检测因低分辨率、背景干扰和目标与环境的视觉相似性而具有挑战性，现有方法常以增加模型复杂性为代价。

Method: EPANet包含高效路径聚合特征金字塔网络（EPA-FPN）和多尺度多样化短路径瓶颈（MS-DDSP瓶颈），通过长程跳跃连接和跨层融合路径提升特征集成效率。

Result: 在基准数据集上，EPANet在检测精度和推理速度上优于现有方法，同时保持较低的参数复杂度。

Conclusion: EPANet为水下鱼类检测提供了一种高效且轻量级的解决方案。

Abstract: Underwater fish detection (UFD) remains a challenging task in computer vision
due to low object resolution, significant background interference, and high
visual similarity between targets and surroundings. Existing approaches
primarily focus on local feature enhancement or incorporate complex attention
mechanisms to highlight small objects, often at the cost of increased model
complexity and reduced efficiency. To address these limitations, we propose an
efficient path aggregation network (EPANet), which leverages complementary
feature integration to achieve accurate and lightweight UFD. EPANet consists of
two key components: an efficient path aggregation feature pyramid network
(EPA-FPN) and a multi-scale diverse-division short path bottleneck (MS-DDSP
bottleneck). The EPA-FPN introduces long-range skip connections across
disparate scales to improve semantic-spatial complementarity, while cross-layer
fusion paths are adopted to enhance feature integration efficiency. The MS-DDSP
bottleneck extends the conventional bottleneck structure by introducing
finer-grained feature division and diverse convolutional operations, thereby
increasing local feature diversity and representation capacity. Extensive
experiments on benchmark UFD datasets demonstrate that EPANet outperforms
state-of-the-art methods in terms of detection accuracy and inference speed,
while maintaining comparable or even lower parameter complexity.

</details>


### [63] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
*Seunghyun Shin,Dongmin Shin,Jisu Shin,Hae-Gon Jeon,Joon-Young Lee*

Main category: cs.CV

TL;DR: 提出了一种基于参考的视频色彩分级框架，通过扩散模型生成查找表（LUT）实现色彩属性对齐，并结合用户偏好进行低层次特征增强。


<details>
  <summary>Details</summary>
Motivation: 视频色彩分级通常需要专业技能，限制了非专业人士的使用。本文旨在简化这一过程，实现自动化且高质量的色彩分级。

Method: 采用扩散模型生成LUT，对齐参考场景与输入视频的色彩属性，同时结合文本提示调整低层次特征。

Result: 实验和用户研究表明，该方法在保持视频结构细节的同时，实现了快速且有效的色彩分级。

Conclusion: 提出的框架为视频色彩分级提供了一种高效且用户友好的解决方案，代码已开源。

Abstract: Different from color correction and transfer, color grading involves
adjusting colors for artistic or storytelling purposes in a video, which is
used to establish a specific look or mood. However, due to the complexity of
the process and the need for specialized editing skills, video color grading
remains primarily the domain of professional colorists. In this paper, we
present a reference-based video color grading framework. Our key idea is
explicitly generating a look-up table (LUT) for color attribute alignment
between reference scenes and input video via a diffusion model. As a training
objective, we enforce that high-level features of the reference scenes like
look, mood, and emotion should be similar to that of the input video. Our
LUT-based approach allows for color grading without any loss of structural
details in the whole video frames as well as achieving fast inference. We
further build a pipeline to incorporate a user-preference via text prompts for
low-level feature enhancement such as contrast and brightness, etc.
Experimental results, including extensive user studies, demonstrate the
effectiveness of our approach for video color grading. Codes are publicly
available at https://github.com/seunghyuns98/VideoColorGrading.

</details>


### [64] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
*Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski*

Main category: cs.CV

TL;DR: 评估了先进视觉语言模型（VLMs）在医学图像中定位解剖结构相对位置的能力，发现其表现不佳，并提出视觉提示和基准数据集MIRP以促进研究。


<details>
  <summary>Details</summary>
Motivation: 临床决策依赖解剖结构的相对位置信息，但VLMs在此任务上的能力尚未充分探索。

Method: 测试了GPT-4o、Llama3.2等VLMs的表现，并尝试使用视觉提示（如标记）提升性能。

Result: 所有模型均表现不佳，视觉提示仅带来有限改进，且VLMs过度依赖先验知识而非图像内容。

Conclusion: 引入MIRP数据集以系统性评估医学图像中的相对定位能力，推动未来研究。

Abstract: Clinical decision-making relies heavily on understanding relative positions
of anatomical structures and anomalies. Therefore, for Vision-Language Models
(VLMs) to be applicable in clinical practice, the ability to accurately
determine relative positions on medical images is a fundamental prerequisite.
Despite its importance, this capability remains highly underexplored. To
address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o,
Llama3.2, Pixtral, and JanusPro, and find that all models fail at this
fundamental task. Inspired by successful approaches in computer vision, we
investigate whether visual prompts, such as alphanumeric or colored markers
placed on anatomical structures, can enhance performance. While these markers
provide moderate improvements, results remain significantly lower on medical
images compared to observations made on natural images. Our evaluations suggest
that, in medical imaging, VLMs rely more on prior anatomical knowledge than on
actual image content for answering relative position questions, often leading
to incorrect conclusions. To facilitate further research in this area, we
introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset,
designed to systematically evaluate the capability to identify relative
positions in medical images.

</details>


### [65] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
*Chihan Huang,Belal Alsinglawi,Islam Al-qudah*

Main category: cs.CV

TL;DR: 提出了一种高效的对抗净化框架DBLP，通过噪声桥蒸馏和自适应语义增强，实现了SOTA的鲁棒性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散对抗净化方法需要大量迭代去噪，限制了实际应用。

Method: 采用噪声桥蒸馏目标，构建对抗噪声分布与干净数据分布的对齐，并结合自适应语义增强。

Result: 在多个数据集上实现了SOTA鲁棒准确性和图像质量，推理时间约0.2秒。

Conclusion: DBLP为实时对抗净化迈出了重要一步。

Abstract: Recent advances in deep neural networks (DNNs) have led to remarkable success
across a wide range of tasks. However, their susceptibility to adversarial
perturbations remains a critical vulnerability. Existing diffusion-based
adversarial purification methods often require intensive iterative denoising,
severely limiting their practical deployment. In this paper, we propose
Diffusion Bridge Distillation for Purification (DBLP), a novel and efficient
diffusion-based framework for adversarial purification. Central to our approach
is a new objective, noise bridge distillation, which constructs a principled
alignment between the adversarial noise distribution and the clean data
distribution within a latent consistency model (LCM). To further enhance
semantic fidelity, we introduce adaptive semantic enhancement, which fuses
multi-scale pyramid edge maps as conditioning input to guide the purification
process. Extensive experiments across multiple datasets demonstrate that DBLP
achieves state-of-the-art (SOTA) robust accuracy, superior image quality, and
around 0.2s inference time, marking a significant step toward real-time
adversarial purification.

</details>


### [66] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
*Jizhihui Liu,Feiyi Du,Guangdao Zhu,Niu Lian,Jun Li,Bin Chen*

Main category: cs.CV

TL;DR: HiPrune是一种无需训练、模型无关的视觉令牌修剪框架，利用视觉编码器的分层注意力结构，显著提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型中视觉令牌序列过长导致的计算开销大和推理效率低的问题。

Method: 通过分层注意力结构选择三种信息丰富的令牌：锚定令牌、缓冲令牌和注册令牌，无需重新训练。

Result: 在多个模型上实现最先进的修剪性能，保留99.3%的任务准确率，仅使用33.3%的令牌，推理FLOPs和延迟降低9倍。

Conclusion: HiPrune是一种高效、通用的令牌修剪方法，适用于多种视觉语言模型和任务。

Abstract: Vision-Language Models (VLMs) encode images into lengthy sequences of visual
tokens, leading to excessive computational overhead and limited inference
efficiency. While prior efforts prune or merge tokens to address this issue,
they often rely on special tokens (e.g., CLS) or require task-specific
training, hindering scalability across architectures. In this paper, we propose
HiPrune, a training-free and model-agnostic token Pruning framework that
exploits the Hierarchical attention structure within vision encoders. We
identify that middle layers attend to object-centric regions, while deep layers
capture global contextual features. Based on this observation, HiPrune selects
three types of informative tokens: (1) Anchor tokens with high attention in
object-centric layers, (2) Buffer tokens adjacent to anchors for spatial
continuity, and (3) Register tokens with strong attention in deep layers for
global summarization. Our method requires no retraining and integrates
seamlessly with any ViT-based VLM. Extensive experiments on LLaVA-1.5,
LLaVA-NeXT, and Qwen2.5-VL demonstrate that HiPrune achieves state-of-the-art
pruning performance, preserving up to 99.3% task accuracy with only 33.3%
tokens, and maintaining 99.5% accuracy with just 11.1% tokens. Meanwhile, it
reduces inference FLOPs and latency by up to 9$\times$, showcasing strong
generalization across models and tasks. Code is available at
https://github.com/Danielement321/HiPrune.

</details>


### [67] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
*Qi Chen,Lingxiao Yang,Yun Chen,Nailong Zhao,Jianhuang Lai,Jie Shao,Xiaohua Xie*

Main category: cs.CV

TL;DR: FreeCP是一个无需训练的分类净化框架，用于解决开放词汇语义分割中的类别冗余和视觉语言模糊性问题，显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视类别冗余和视觉语言模糊性，导致次优的类别激活图，FreeCP旨在解决这些问题。

Method: 提出FreeCP框架，通过净化语义类别和纠正冗余与模糊性引起的错误，生成最终分割预测。

Result: 在八个基准测试中验证，FreeCP作为即插即用模块显著提升分割性能。

Conclusion: FreeCP有效解决了开放词汇语义分割中的关键挑战，提升了性能。

Abstract: Fine-tuning pre-trained vision-language models has emerged as a powerful
approach for enhancing open-vocabulary semantic segmentation (OVSS). However,
the substantial computational and resource demands associated with training on
large datasets have prompted interest in training-free methods for OVSS.
Existing training-free approaches primarily focus on modifying model
architectures and generating prototypes to improve segmentation performance.
However, they often neglect the challenges posed by class redundancy, where
multiple categories are not present in the current test image, and
visual-language ambiguity, where semantic similarities among categories create
confusion in class activation. These issues can lead to suboptimal class
activation maps and affinity-refined activation maps. Motivated by these
observations, we propose FreeCP, a novel training-free class purification
framework designed to address these challenges. FreeCP focuses on purifying
semantic categories and rectifying errors caused by redundancy and ambiguity.
The purified class representations are then leveraged to produce final
segmentation predictions. We conduct extensive experiments across eight
benchmarks to validate FreeCP's effectiveness. Results demonstrate that FreeCP,
as a plug-and-play module, significantly boosts segmentation performance when
combined with other OVSS methods.

</details>


### [68] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
*Jens U. Kreber,Joerg Stueckler*

Main category: cs.CV

TL;DR: PhysNAP是一种基于扩散模型的新方法，用于生成与部分点云对齐且物理合理的铰接物体。


<details>
  <summary>Details</summary>
Motivation: 铰接物体是日常环境中重要的可交互对象，但现有方法在物理合理性和点云对齐方面存在不足。

Method: 使用带符号距离函数（SDFs）表示部件形状，通过点云对齐损失和物理约束（非穿透性和移动性）指导反向扩散过程。

Result: 在PartNet-Mobility数据集上评估，PhysNAP在约束一致性和生成能力之间提供了权衡，优于无指导的扩散模型。

Conclusion: PhysNAP能够生成物理合理且与点云对齐的铰接物体，为相关领域提供了有效工具。

Abstract: Articulated objects are an important type of interactable objects in everyday
environments. In this paper, we propose PhysNAP, a novel diffusion model-based
approach for generating articulated objects that aligns them with partial point
clouds and improves their physical plausibility. The model represents part
shapes by signed distance functions (SDFs). We guide the reverse diffusion
process using a point cloud alignment loss computed using the predicted SDFs.
Additionally, we impose non-penetration and mobility constraints based on the
part SDFs for guiding the model to generate more physically plausible objects.
We also make our diffusion approach category-aware to further improve point
cloud alignment if category information is available. We evaluate the
generative ability and constraint consistency of samples generated with PhysNAP
using the PartNet-Mobility dataset. We also compare it with an unguided
baseline diffusion model and demonstrate that PhysNAP can improve constraint
consistency and provides a tradeoff with generative ability.

</details>


### [69] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
*Hannah Kniesel,Leon Sick,Tristan Payer,Tim Bergner,Kavitha Shaga Devan,Clarissa Read,Paul Walther,Timo Ropinski*

Main category: cs.CV

TL;DR: 提出了一种基于图像级注释的弱监督目标检测算法，通过预训练模型生成伪标签，用于训练目标检测模型，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 获取目标检测所需的边界框标注成本高且耗时，尤其需要领域专家参与。为了解决这一问题，研究提出了一种仅需图像级注释的弱监督方法。

Method: 利用预训练模型的知识蒸馏生成伪标签，通过优化方法和缩小感受野直接提取病毒颗粒，无需特定网络架构。

Result: 实验表明，生成的伪标签更易获取，且在标注时间有限的情况下，性能优于其他弱标注方法甚至真实标注。

Conclusion: 该方法显著降低了标注成本，同时保持了高性能，适用于领域特定的目标检测任务。

Abstract: Current state-of-the-art methods for object detection rely on annotated
bounding boxes of large data sets for training. However, obtaining such
annotations is expensive and can require up to hundreds of hours of manual
labor. This poses a challenge, especially since such annotations can only be
provided by experts, as they require knowledge about the scientific domain. To
tackle this challenge, we propose a domain-specific weakly supervised object
detection algorithm that only relies on image-level annotations, which are
significantly easier to acquire. Our method distills the knowledge of a
pre-trained model, on the task of predicting the presence or absence of a virus
in an image, to obtain a set of pseudo-labels that can be used to later train a
state-of-the-art object detection model. To do so, we use an optimization
approach with a shrinking receptive field to extract virus particles directly
without specific network architectures. Through a set of extensive studies, we
show how the proposed pseudo-labels are easier to obtain, and, more
importantly, are able to outperform other existing weak labeling methods, and
even ground truth labels, in cases where the time to obtain the annotation is
limited.

</details>


### [70] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
*Jingchao Xie,Oussema Dhaouadi,Weirong Chen,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoProU-VO的新方法，通过跨帧不确定性传播改进视觉里程计，显著提升了动态场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 动态物体和遮挡会导致传统无监督视觉里程计方法在静态场景假设下失效，因此需要一种更鲁棒的不确定性建模方法。

Method: 提出CoProU-VO，结合目标帧和参考帧的不确定性，利用概率公式进行跨帧传播，基于视觉Transformer同时学习深度、不确定性和相机位姿。

Result: 在KITTI和nuScenes数据集上表现优于现有方法，尤其在高速公路场景中表现突出。

Conclusion: 跨帧不确定性传播显著提升了视觉里程计在动态场景中的鲁棒性和准确性。

Abstract: Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and
augmented reality, with unsupervised approaches eliminating the need for
expensive ground-truth labels. However, these methods struggle when dynamic
objects violate the static scene assumption, leading to erroneous pose
estimations. We tackle this problem by uncertainty modeling, which is a
commonly used technique that creates robust masks to filter out dynamic objects
and occlusions without requiring explicit motion segmentation. Traditional
uncertainty modeling considers only single-frame information, overlooking the
uncertainties across consecutive frames. Our key insight is that uncertainty
must be propagated and combined across temporal frames to effectively identify
unreliable regions, particularly in dynamic scenes. To address this challenge,
we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end
approach that combines target frame uncertainty with projected reference frame
uncertainty using a principled probabilistic formulation. Built upon vision
transformer backbones, our model simultaneously learns depth, uncertainty
estimation, and camera poses. Consequently, experiments on the KITTI and
nuScenes datasets demonstrate significant improvements over previous
unsupervised monocular end-to-end two-frame-based methods and exhibit strong
performance in challenging highway scenes where other approaches often fail.
Additionally, comprehensive ablation studies validate the effectiveness of
cross-frame uncertainty propagation.

</details>


### [71] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
*Marc Hölle,Walter Kellermann,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 论文提出了一种基于不确定性感知的似然比估计方法，用于区分语义分割模型中的已知和未知像素特征，显著降低了误报率。


<details>
  <summary>Details</summary>
Motivation: 现实自动驾驶场景中，语义分割模型常因误分类未知物体而失败，现有方法在复杂场景中表现不佳。

Method: 采用证据分类器结合似然比测试，显式考虑不确定性，输出概率分布而非点估计。

Result: 在五个基准数据集上，误报率降至2.5%，平均精度达90.91%，计算开销可忽略。

Conclusion: 通过显式建模不确定性，该方法有效提升了未知物体检测性能。

Abstract: Semantic segmentation models trained on known object classes often fail in
real-world autonomous driving scenarios by confidently misclassifying unknown
objects. While pixel-wise out-of-distribution detection can identify unknown
objects, existing methods struggle in complex scenes where rare object classes
are often confused with truly unknown objects. We introduce an
uncertainty-aware likelihood ratio estimation method that addresses these
limitations. Our approach uses an evidential classifier within a likelihood
ratio test to distinguish between known and unknown pixel features from a
semantic segmentation model, while explicitly accounting for uncertainty.
Instead of producing point estimates, our method outputs probability
distributions that capture uncertainty from both rare training examples and
imperfect synthetic outliers. We show that by incorporating uncertainty in this
way, outlier exposure can be leveraged more effectively. Evaluated on five
standard benchmark datasets, our method achieves the lowest average false
positive rate (2.5%) among state-of-the-art while maintaining high average
precision (90.91%) and incurring only negligible computational overhead. Code
is available at https://github.com/glasbruch/ULRE.

</details>


### [72] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
*Yihe Tian,Kwan Man Cheng,Zhengbo Zhang,Tao Zhang,Suju Li,Dongmei Yan,Bing Xu*

Main category: cs.CV

TL;DR: 提出了一种新的夜间灯光（NTL）重建框架EVAL，解决了现有方法低估光强和结构缺失的问题，将数据记录扩展到1986年，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有NTL数据时间覆盖有限（始于2012年），且存在光强低估和结构缺失问题，限制了长期时间序列研究。

Method: 采用两阶段重建框架：构建阶段使用分层融合解码器（HFD）提高初始重建保真度；细化阶段利用双特征精炼器（DFR）结合高分辨率不透水面掩模增强细节。

Result: 开发的EVAL产品将数据记录扩展到1986年，R²从0.68提升至0.80，RMSE从1.27降至0.99，具有优异的时间一致性和社会经济参数相关性。

Conclusion: EVAL为研究社区提供了可靠的长期分析资源，公开可用。

Abstract: Artificial Night-Time Light (NTL) remote sensing is a vital proxy for
quantifying the intensity and spatial distribution of human activities.
Although the NPP-VIIRS sensor provides high-quality NTL observations, its
temporal coverage, which begins in 2012, restricts long-term time-series
studies that extend to earlier periods. Despite the progress in extending
VIIRS-like NTL time-series, current methods still suffer from two significant
shortcomings: the underestimation of light intensity and the structural
omission. To overcome these limitations, we propose a novel reconstruction
framework consisting of a two-stage process: construction and refinement. The
construction stage features a Hierarchical Fusion Decoder (HFD) designed to
enhance the fidelity of the initial reconstruction. The refinement stage
employs a Dual Feature Refiner (DFR), which leverages high-resolution
impervious surface masks to guide and enhance fine-grained structural details.
Based on this framework, we developed the Extended VIIRS-like Artificial
Nighttime Light (EVAL) product for China, extending the standard data record
backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL
significantly outperforms existing state-of-the-art products, boosting the
$\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99.
Furthermore, EVAL exhibits excellent temporal consistency and maintains a high
correlation with socioeconomic parameters, confirming its reliability for
long-term analysis. The resulting EVAL dataset provides a valuable new resource
for the research community and is publicly available at
https://doi.org/10.11888/HumanNat.tpdc.302930.

</details>


### [73] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.CV

TL;DR: Wukong是一个基于Transformer的NSFW检测框架，利用扩散模型早期去噪步骤的中间输出，显著提升了检测效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有外部保障方法（文本过滤器和图像过滤器）存在效率低或易受攻击的问题，需要一种更高效的NSFW检测方法。

Method: 利用扩散模型早期去噪步骤的语义布局和U-Net的预训练交叉注意力参数，提出Wukong框架。

Result: Wukong在效率和准确性上显著优于文本过滤器，与图像过滤器相当。

Conclusion: Wukong为T2I生成中的NSFW内容检测提供了一种高效且准确的解决方案。

Abstract: Text-to-Image (T2I) generation is a popular AI-generated content (AIGC)
technology enabling diverse and creative image synthesis. However, some outputs
may contain Not Safe For Work (NSFW) content (e.g., violence), violating
community guidelines. Detecting NSFW content efficiently and accurately, known
as external safeguarding, is essential. Existing external safeguards fall into
two types: text filters, which analyze user prompts but overlook T2I
model-specific variations and are prone to adversarial attacks; and image
filters, which analyze final generated images but are computationally costly
and introduce latency. Diffusion models, the foundation of modern T2I systems
like Stable Diffusion, generate images through iterative denoising using a
U-Net architecture with ResNet and Transformer blocks. We observe that: (1)
early denoising steps define the semantic layout of the image, and (2)
cross-attention layers in U-Net are crucial for aligning text and image
regions. Based on these insights, we propose Wukong, a transformer-based NSFW
detection framework that leverages intermediate outputs from early denoising
steps and reuses U-Net's pre-trained cross-attention parameters. Wukong
operates within the diffusion process, enabling early detection without waiting
for full image generation. We also introduce a new dataset containing prompts,
seeds, and image-specific NSFW labels, and evaluate Wukong on this and two
public benchmarks. Results show that Wukong significantly outperforms
text-based safeguards and achieves comparable accuracy of image filters, while
offering much greater efficiency.

</details>


### [74] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
*Jiajun Le,Jiayi Ma*

Main category: cs.CV

TL;DR: GeoMoE利用混合专家模型（MoE）处理两视图几何中的异质运动模式，通过概率先导分解和双路径校正器提升运动场建模，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 复杂场景中的运动场具有多样性和异质性，现有方法缺乏针对性建模策略，导致估计结果偏离真实结构。

Method: 提出GeoMoE框架，包括概率先导分解策略和MoE增强的双路径校正器，分别用于分解运动场和针对性建模。

Result: 在相对位姿和单应性估计任务中表现优于现有方法，并展现出强泛化能力。

Conclusion: GeoMoE通过分治策略有效处理异质运动模式，为两视图几何提供了高效解决方案。

Abstract: Recent progress in two-view geometry increasingly emphasizes enforcing
smoothness and global consistency priors when estimating motion fields between
pairs of images. However, in complex real-world scenes, characterized by
extreme viewpoint and scale changes as well as pronounced depth
discontinuities, the motion field often exhibits diverse and heterogeneous
motion patterns. Most existing methods lack targeted modeling strategies and
fail to explicitly account for this variability, resulting in estimated motion
fields that diverge from their true underlying structure and distribution. We
observe that Mixture-of-Experts (MoE) can assign dedicated experts to motion
sub-fields, enabling a divide-and-conquer strategy for heterogeneous motion
patterns. Building on this insight, we re-architect motion field modeling in
two-view geometry with GeoMoE, a streamlined framework. Specifically, we first
devise a Probabilistic Prior-Guided Decomposition strategy that exploits inlier
probability signals to perform a structure-aware decomposition of the motion
field into heterogeneous sub-fields, sharply curbing outlier-induced bias.
Next, we introduce an MoE-Enhanced Bi-Path Rectifier that enhances each
sub-field along spatial-context and channel-semantic paths and routes it to a
customized expert for targeted modeling, thereby decoupling heterogeneous
motion regimes, suppressing cross-sub-field interference and representational
entanglement, and yielding fine-grained motion-field rectification. With this
minimalist design, GeoMoE outperforms prior state-of-the-art methods in
relative pose and homography estimation and shows strong generalization. The
source code and pre-trained models are available at
https://github.com/JiajunLe/GeoMoE.

</details>


### [75] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi*

Main category: cs.CV

TL;DR: 论文探讨了人脸识别系统在无约束环境下面临的挑战，并提出了一种针对人脸检测的攻击方法（Face Generation Attacks），首次展示了针对坐标回归任务的Landmark Shift Attack，同时提供了缓解措施。


<details>
  <summary>Details</summary>
Motivation: 研究人脸识别系统在复杂环境（如光线、姿态变化）下的脆弱性，特别是针对人脸检测模块的攻击。

Method: 提出Face Generation Attacks和Landmark Shift Attack，攻击人脸检测的坐标回归任务。

Result: 展示了攻击的有效性，证明了人脸检测模块的漏洞。

Conclusion: 提供了针对这些漏洞的缓解措施，强调了系统安全性改进的必要性。

Abstract: Face Recognition Systems that operate in unconstrained environments capture
images under varying conditions,such as inconsistent lighting, or diverse face
poses. These challenges require including a Face Detection module that
regresses bounding boxes and landmark coordinates for proper Face Alignment.
This paper shows the effectiveness of Object Generation Attacks on Face
Detection, dubbed Face Generation Attacks, and demonstrates for the first time
a Landmark Shift Attack that backdoors the coordinate regression task performed
by face detectors. We then offer mitigations against these vulnerabilities.

</details>


### [76] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
*Junzhe Lu,Jing Lin,Hongkun Dou,Ailing Zeng,Yue Deng,Xian Liu,Zhongang Cai,Lei Yang,Yulun Zhang,Haoqian Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: DPoser-X是一种基于扩散模型的3D全身人体姿态先验模型，通过变分扩散采样解决姿态任务，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 构建一个多功能且鲁棒的全身人体姿态先验模型具有挑战性，主要由于人体姿态的复杂性和高质量数据集的稀缺。

Method: 提出扩散模型DPoser及其扩展DPoser-X，采用截断时间步调度和掩码训练机制，结合全身和局部数据集。

Result: 在身体、手、脸和全身姿态建模的多个基准测试中表现优于现有方法。

Conclusion: DPoser-X为全身人体姿态先验建模设立了新标准。

Abstract: We present DPoser-X, a diffusion-based prior model for 3D whole-body human
poses. Building a versatile and robust full-body human pose prior remains
challenging due to the inherent complexity of articulated human poses and the
scarcity of high-quality whole-body pose datasets. To address these
limitations, we introduce a Diffusion model as body Pose prior (DPoser) and
extend it to DPoser-X for expressive whole-body human pose modeling. Our
approach unifies various pose-centric tasks as inverse problems, solving them
through variational diffusion sampling. To enhance performance on downstream
applications, we introduce a novel truncated timestep scheduling method
specifically designed for pose data characteristics. We also propose a masked
training mechanism that effectively combines whole-body and part-specific
datasets, enabling our model to capture interdependencies between body parts
while avoiding overfitting to specific actions. Extensive experiments
demonstrate DPoser-X's robustness and versatility across multiple benchmarks
for body, hand, face, and full-body pose modeling. Our model consistently
outperforms state-of-the-art alternatives, establishing a new benchmark for
whole-body human pose prior modeling.

</details>


### [77] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
*Prerana Ramkumar*

Main category: cs.CV

TL;DR: SU-ESRGAN是一种针对卫星图像的超分辨率框架，结合了ESRGAN、DeepLabv3分割损失和蒙特卡洛丢弃，以生成像素级不确定性地图，提升语义一致性和可信度。


<details>
  <summary>Details</summary>
Motivation: GANs在超分辨率任务中缺乏语义一致性和像素级置信度，限制了其在遥感关键应用中的可信度。

Method: 提出SU-ESRGAN框架，整合ESRGAN、DeepLabv3分割损失和蒙特卡洛丢弃，生成不确定性地图。

Result: 在PSNR、SSIM和LPIPS指标上与基线ESRGAN相当，适用于无人机或卫星系统。

Conclusion: SU-ESRGAN在跨域应用中表现良好，强调了领域感知训练的重要性。

Abstract: Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.

</details>


### [78] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
*Luisa Gallée,Catharina Silvia Lisson,Christoph Gerhard Lisson,Daniela Drees,Felix Weig,Daniel Vogele,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: 论文提出了一种通过生成模型合成属性标注数据的方法，以解决医学图像中属性标注数据稀缺的问题，从而提升可解释模型的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像诊断中，可解释的分类模型能增强临床医生的信任和使用性。然而，由于缺乏大规模属性标注数据集，这类模型的采用受到限制。

Method: 采用增强的扩散模型（Diffusion Model）进行属性条件化生成，仅需20个标注样本，生成合成数据用于训练可解释模型。

Result: 实验表明，合成数据显著提升了属性预测和目标预测的准确性，分别提高了13.4%和1.8%。

Conclusion: 合成数据能有效克服数据集限制，增强可解释模型在医学图像分析中的应用潜力。

Abstract: Classification models that provide human-interpretable explanations enhance
clinicians' trust and usability in medical image diagnosis. One research focus
is the integration and prediction of pathology-related visual attributes used
by radiologists alongside the diagnosis, aligning AI decision-making with
clinical reasoning. Radiologists use attributes like shape and texture as
established diagnostic criteria and mirroring these in AI decision-making both
enhances transparency and enables explicit validation of model outputs.
However, the adoption of such models is limited by the scarcity of large-scale
medical image datasets annotated with these attributes. To address this
challenge, we propose synthesizing attribute-annotated data using a generative
model. We enhance the Diffusion Model with attribute conditioning and train it
using only 20 attribute-labeled lung nodule samples from the LIDC-IDRI dataset.
Incorporating its generated images into the training of an explainable model
boosts performance, increasing attribute prediction accuracy by 13.4% and
target prediction accuracy by 1.8% compared to training with only the small
real attribute-annotated dataset. This work highlights the potential of
synthetic data to overcome dataset limitations, enhancing the applicability of
explainable models in medical image analysis.

</details>


### [79] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
*Junhao Zheng,Jiahao Sun,Chenhao Lin,Zhengyu Zhao,Chen Ma,Chong Zhang,Cong Wang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 论文提出了首个针对目标检测器补丁攻击的防御基准，通过大规模数据集和全面分析揭示了现有防御方法的不足，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有防御评估缺乏统一框架，导致对防御方法的评估不一致且不完整。

Method: 重新评估11种代表性防御方法，构建包含2种攻击目标、13种补丁攻击、11种目标检测器和4种指标的基准，并创建大规模对抗补丁数据集。

Result: 发现自然补丁防御的难点在于数据分布而非高频特征；攻击目标的平均精度与防御性能高度一致；自适应攻击能显著绕过现有防御。

Conclusion: 研究为补丁攻击/防御的评估和设计提供了指导，数据集和代码已开源。

Abstract: Developing reliable defenses against patch attacks on object detectors has
attracted increasing interest. However, we identify that existing defense
evaluations lack a unified and comprehensive framework, resulting in
inconsistent and incomplete assessments of current methods. To address this
issue, we revisit 11 representative defenses and present the first patch
defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object
detectors, and 4 diverse metrics. This leads to the large-scale adversarial
patch dataset with 94 types of patches and 94,000 images. Our comprehensive
analyses reveal new insights: (1) The difficulty in defending against
naturalistic patches lies in the data distribution, rather than the commonly
believed high frequencies. Our new dataset with diverse patch distributions can
be used to improve existing defenses by 15.09% AP@0.5. (2) The average
precision of the attacked object, rather than the commonly pursued patch
detection accuracy, shows high consistency with defense performance. (3)
Adaptive attacks can substantially bypass existing defenses, and defenses with
complex/stochastic models or universal patch properties are relatively robust.
We hope that our analyses will serve as guidance on properly evaluating patch
attacks/defenses and advancing their design. Code and dataset are available at
https://github.com/Gandolfczjh/APDE, where we will keep integrating new
attacks/defenses.

</details>


### [80] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
*Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于预训练深度特征的图像去雾方法，通过RGB-D融合模块提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法受限于特定架构设计，难以适应不同场景的需求。

Method: 利用预训练的深度特征，设计了一个即插即用的RGB-D融合模块。

Result: 实验表明该方法在多个基准测试中表现优异，且具有广泛适用性。

Conclusion: 预训练深度特征在图像去雾中具有显著一致性，RGB-D融合模块有效提升了方法的泛化能力。

Abstract: Image dehazing remains a challenging problem due to the spatially varying
nature of haze in real-world scenes. While existing methods have demonstrated
the promise of large-scale pretrained models for image dehazing, their
architecture-specific designs hinder adaptability across diverse scenarios with
different accuracy and efficiency requirements. In this work, we systematically
investigate the generalization capability of pretrained depth
representations-learned from millions of diverse images-for image dehazing. Our
empirical analysis reveals that the learned deep depth features maintain
remarkable consistency across varying haze levels. Building on this insight, we
propose a plug-and-play RGB-D fusion module that seamlessly integrates with
diverse dehazing architectures. Extensive experiments across multiple
benchmarks validate both the effectiveness and broad applicability of our
approach.

</details>


### [81] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
*Chende Zheng,Ruiqi suo,Chenhao Lin,Zhengyu Zhao,Le Yang,Shuai Liu,Minghui Yang,Cong Wang,Chao Shen*

Main category: cs.CV

TL;DR: 论文提出了一种基于二阶动力学分析的免费训练检测方法D3，用于识别AI生成视频中的时间伪影，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法对合成视频中时间伪影的探索不足，导致检测效果有限。

Method: 通过牛顿力学下的二阶动力学分析建立理论框架，并设计Second-order Central Difference特征，提出D3方法。

Result: D3在4个开源数据集上表现优异，例如在GenVideo上比之前最佳方法提升10.39%的平均精度。

Conclusion: D3具有高效的计算性能和鲁棒性，为合成视频检测提供了新思路。

Abstract: The evolution of video generation techniques, such as Sora, has made it
increasingly easy to produce high-fidelity AI-generated videos, raising public
concern over the dissemination of synthetic content. However, existing
detection methodologies remain limited by their insufficient exploration of
temporal artifacts in synthetic videos. To bridge this gap, we establish a
theoretical framework through second-order dynamical analysis under Newtonian
mechanics, subsequently extending the Second-order Central Difference features
tailored for temporal artifact detection. Building on this theoretical
foundation, we reveal a fundamental divergence in second-order feature
distributions between real and AI-generated videos. Concretely, we propose
Detection by Difference of Differences (D3), a novel training-free detection
method that leverages the above second-order temporal discrepancies. We
validate the superiority of our D3 on 4 open-source datasets (Gen-Video,
VideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,
D3 outperforms the previous best method by 10.39% (absolute) mean Average
Precision. Additional experiments on time cost and post-processing operations
demonstrate D3's exceptional computational efficiency and strong robust
performance. Our code is available at https://github.com/Zig-HS/D3.

</details>


### [82] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
*Jiale Li,Mingrui Wu,Zixiang Jin,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 该论文首次系统研究了多图像多模态大语言模型中的幻觉问题，提出了MIHBench基准，并设计了一种动态注意力平衡机制以减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单图像场景中的幻觉问题，而多图像场景中的幻觉尚未充分探索，因此需要填补这一研究空白。

Method: 提出了MIHBench基准，包含三个核心任务，用于评估多图像中的对象相关幻觉，并设计了一种动态注意力平衡机制。

Result: 实验表明，动态注意力平衡机制能有效减少多图像场景中的幻觉，并提升语义整合和推理稳定性。

Conclusion: 该研究为多图像多模态大语言模型的幻觉问题提供了系统解决方案，并验证了动态注意力平衡机制的有效性。

Abstract: Despite growing interest in hallucination in Multimodal Large Language
Models, existing studies primarily focus on single-image settings, leaving
hallucination in multi-image scenarios largely unexplored. To address this gap,
we conduct the first systematic study of hallucinations in multi-image MLLMs
and propose MIHBench, a benchmark specifically tailored for evaluating
object-related hallucinations across multiple images. MIHBench comprises three
core tasks: Multi-Image Object Existence Hallucination, Multi-Image Object
Count Hallucination, and Object Identity Consistency Hallucination, targeting
semantic understanding across object existence, quantity reasoning, and
cross-view identity consistency. Through extensive evaluation, we identify key
factors associated with the occurrence of multi-image hallucinations,
including: a progressive relationship between the number of image inputs and
the likelihood of hallucination occurrences; a strong correlation between
single-image hallucination tendencies and those observed in multi-image
contexts; and the influence of same-object image ratios and the positional
placement of negative samples within image sequences on the occurrence of
object identity consistency hallucination. To address these challenges, we
propose a Dynamic Attention Balancing mechanism that adjusts inter-image
attention distributions while preserving the overall visual attention
proportion. Experiments across multiple state-of-the-art MLLMs demonstrate that
our method effectively reduces hallucination occurrences and enhances semantic
integration and reasoning stability in multi-image scenarios.

</details>


### [83] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
*Guanning Zeng,Xiang Zhang,Zirui Wang,Haiyang Xu,Zeyuan Chen,Bingnan Li,Zhuowen Tu*

Main category: cs.CV

TL;DR: YOLO-Count 是一个可微分的开放词汇对象计数模型，解决了通用计数问题，并为文本到图像生成提供精确的数量控制。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇计数与文本到图像生成控制之间的差距，同时应对对象大小和空间分布的变化。

Method: 提出 'cardinality' 映射作为回归目标，结合表示对齐和强弱监督混合方案，采用完全可微分架构。

Result: 在实验中表现出最先进的计数准确性，并为文本到图像系统提供稳健的数量控制。

Conclusion: YOLO-Count 在开放词汇计数和生成控制方面具有显著优势。

Abstract: We propose YOLO-Count, a differentiable open-vocabulary object counting model
that tackles both general counting challenges and enables precise quantity
control for text-to-image (T2I) generation. A core contribution is the
'cardinality' map, a novel regression target that accounts for variations in
object size and spatial distribution. Leveraging representation alignment and a
hybrid strong-weak supervision scheme, YOLO-Count bridges the gap between
open-vocabulary counting and T2I generation control. Its fully differentiable
architecture facilitates gradient-based optimization, enabling accurate object
count estimation and fine-grained guidance for generative models. Extensive
experiments demonstrate that YOLO-Count achieves state-of-the-art counting
accuracy while providing robust and effective quantity control for T2I systems.

</details>


### [84] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
*Adwait Chandorkar,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级骨干网络Dense Backbone，用于3D目标检测，显著降低了计算成本，同时保持了高检测精度。


<details>
  <summary>Details</summary>
Motivation: 当前3D目标检测方法多依赖复杂骨干网络（如VGG或ResNet），增加了模型复杂度，而轻量级骨干网络在3D领域研究较少。

Method: 设计了Dense Backbone，结合高处理速度、轻量架构和鲁棒检测精度，并适配了多种先进3D检测器（如PillarNet）。

Result: DensePillarNet在nuScenes测试集上减少了29%参数和28%延迟，仅损失2%检测精度。

Conclusion: Dense Backbone的即插即用设计使其易于集成到现有架构中，为3D目标检测提供了高效解决方案。

Abstract: Recent advancements in LiDAR-based 3D object detection have significantly
accelerated progress toward the realization of fully autonomous driving in
real-world environments. Despite achieving high detection performance, most of
the approaches still rely on a VGG-based or ResNet-based backbone for feature
exploration, which increases the model complexity. Lightweight backbone design
is well-explored for 2D object detection, but research on 3D object detection
still remains limited. In this work, we introduce Dense Backbone, a lightweight
backbone that combines the benefits of high processing speed, lightweight
architecture, and robust detection accuracy. We adapt multiple SoTA 3d object
detectors, such as PillarNet, with our backbone and show that with our
backbone, these models retain most of their detection capability at a
significantly reduced computational cost. To our knowledge, this is the first
dense-layer-based backbone tailored specifically for 3D object detection from
point cloud data. DensePillarNet, our adaptation of PillarNet, achieves a 29%
reduction in model parameters and a 28% reduction in latency with just a 2%
drop in detection accuracy on the nuScenes test set. Furthermore, Dense
Backbone's plug-and-play design allows straightforward integration into
existing architectures, requiring no modifications to other network components.

</details>


### [85] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
*Regine Hartwig,Dominik Muhle,Riccardo Marin,Daniel Cremers*

Main category: cs.CV

TL;DR: GECO提出了一种基于最优传输的训练框架，生成几何一致的特征，显著提升了语义对应任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督视觉基础模型能捕捉语义对应，但缺乏对3D几何的感知。GECO旨在填补这一空白。

Method: 采用最优传输框架进行训练，支持超越关键点的监督，适用于遮挡和去遮挡情况。

Result: GECO在PFPascal、APK和CUB上实现了最先进的性能，PCK分别提升了6.0%、6.2%和4.1%，运行速度达30 fps。

Conclusion: PCK不足以全面评估几何质量，GECO提出了新指标，为几何感知特征学习提供了新见解。

Abstract: Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/

</details>


### [86] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
*Laura Pedrouzo-Rodriguez,Pedro Delgado-DeRobles,Luis F. Gomez,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CV

TL;DR: 论文探讨了在虚拟化身中通过面部运动模式进行身份验证的可行性，提出了一种轻量级图卷积网络架构，实验表明其有效性。


<details>
  <summary>Details</summary>
Motivation: 虚拟化身在通信中带来沉浸感，但也存在冒充风险，需要可靠的生物特征验证方法。

Method: 使用GAGAvatar生成真实与冒充化身视频数据集，提出基于面部标志的时空图卷积网络架构。

Result: 实验显示面部运动模式可实现身份验证，AUC值接近80%。

Conclusion: 面部运动模式可作为有效生物特征，呼吁加强虚拟化身通信中的行为生物特征防御。

Abstract: Photorealistic talking-head avatars are becoming increasingly common in
virtual meetings, gaming, and social platforms. These avatars allow for more
immersive communication, but they also introduce serious security risks. One
emerging threat is impersonation: an attacker can steal a user's
avatar-preserving their appearance and voice-making it nearly impossible to
detect its fraudulent usage by sight or sound alone. In this paper, we explore
the challenge of biometric verification in such avatar-mediated scenarios. Our
main question is whether an individual's facial motion patterns can serve as
reliable behavioral biometrics to verify their identity when the avatar's
visual appearance is a facsimile of its owner. To answer this question, we
introduce a new dataset of realistic avatar videos created using a
state-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and
impostor avatar videos. We also propose a lightweight, explainable
spatio-temporal Graph Convolutional Network architecture with temporal
attention pooling, that uses only facial landmarks to model dynamic facial
gestures. Experimental results demonstrate that facial motion cues enable
meaningful identity verification with AUC values approaching 80%. The proposed
benchmark and biometric system are available for the research community in
order to bring attention to the urgent need for more advanced behavioral
biometric defenses in avatar-based communication systems.

</details>


### [87] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
*Irene Iele,Francesco Di Feola,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 提出了一种基于测试时适应（TTA）的动态调整框架，用于医学图像转换任务，以解决分布外样本的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像转换在处理分布外样本时性能下降，需要一种动态适应方法。

Method: 引入重建模块量化域偏移，并通过动态适应块选择性调整预训练模型的内部特征。

Result: 在低剂量CT去噪和T1到T2 MRI转换任务中表现优于基线模型和现有TTA方法。

Conclusion: 动态样本特定调整是提高模型在真实场景中鲁棒性的有效途径。

Abstract: Image-to-image translation has emerged as a powerful technique in medical
imaging, enabling tasks such as image denoising and cross-modality conversion.
However, it suffers from limitations in handling out-of-distribution samples
without causing performance degradation. To address this limitation, we propose
a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the
translation process based on the characteristics of each test sample. Our
method introduces a Reconstruction Module to quantify the domain shift and a
Dynamic Adaptation Block that selectively modifies the internal features of a
pretrained translation model to mitigate the shift without compromising the
performance on in-distribution samples that do not require adaptation. We
evaluate our approach on two medical image-to-image translation tasks: low-dose
CT denoising and T1 to T2 MRI translation, showing consistent improvements over
both the baseline translation model without TTA and prior TTA methods. Our
analysis highlights the limitations of the state-of-the-art that uniformly
apply the adaptation to both out-of-distribution and in-distribution samples,
demonstrating that dynamic, sample-specific adjustment offers a promising path
to improve model resilience in real-world scenarios. The code is available at:
https://github.com/cosbidev/Sample-Aware_TTA.

</details>


### [88] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
*Zihan Wang,Samira Ebrahimi Kahou,Narges Armanfard*

Main category: cs.CV

TL;DR: PILOT框架通过双分支提示学习和无标签测试时适应策略，解决了零样本异常检测在领域偏移下的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法在领域偏移下表现不佳，因其训练数据有限且泛化能力不足。

Method: PILOT采用双分支提示学习机制动态整合可学习提示与语义属性，并结合无标签测试时适应策略更新参数。

Result: 在13个工业和医学基准测试中，PILOT在领域偏移下的异常检测和定位性能达到最优。

Conclusion: PILOT通过创新设计显著提升了零样本异常检测的泛化能力。

Abstract: Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects
in unseen categories by relying solely on generalizable features rather than
requiring any labeled examples of anomalies. However, existing ZSAD methods,
whether using fixed or learned prompts, struggle under domain shifts because
their training data are derived from limited training domains and fail to
generalize to new distributions. In this paper, we introduce PILOT, a framework
designed to overcome these challenges through two key innovations: (1) a novel
dual-branch prompt learning mechanism that dynamically integrates a pool of
learnable prompts with structured semantic attributes, enabling the model to
adaptively weight the most relevant anomaly cues for each input image; and (2)
a label-free test-time adaptation strategy that updates the learnable prompt
parameters using high-confidence pseudo-labels from unlabeled test data.
Extensive experiments on 13 industrial and medical benchmarks demonstrate that
PILOT achieves state-of-the-art performance in both anomaly detection and
localization under domain shift.

</details>


### [89] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
*Alexander Nikitas Dimopoulos,Joseph Grasso*

Main category: cs.CV

TL;DR: 研究分析了异构标记点云数据集在公共安全应用中的语义分割性能，发现几何大的物体分割效果较好，而小物体识别率较低，需标准化标注协议和改进标记技术。


<details>
  <summary>Details</summary>
Motivation: 研究异构标记点云数据集在公共安全应用中的语义分割性能，以解决数据统一性和小物体检测的挑战。

Method: 采用分级标注方案和KPConv架构，通过IoU指标评估性能。

Result: 几何大的物体（如楼梯、窗户）分割效果较好，小物体识别率较低，性能受类别不平衡和几何区分度影响。

Conclusion: 公共安全领域的可靠点云语义分割需要标准化标注协议和改进标记技术，以应对数据异构性和小物体检测问题。

Abstract: This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [90] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
*Tong Nie,Jian Sun,Wei Ma*

Main category: cs.LG

TL;DR: 提出了一种基于物理定律的Transformer结构（ScaleSTF），用于高效预测大规模城市网络中的时空动态，解决了现有模型在效能与效率之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 城市网络系统涉及复杂且未知的规则，现有模型（如图神经网络）在计算效率和预测性能之间存在矛盾，难以应用于大规模网络。

Method: 通过物理定律指导模型设计，提出了一种基于Transformer的神经扩散方案，其注意力层由低维嵌入诱导，具有线性复杂度。

Result: 在交通流量、太阳能发电和智能电表等大规模城市系统中验证了ScaleSTF的先进性能和卓越的可扩展性。

Conclusion: ScaleSTF为大规模城市网络的动态预测提供了新的视角，兼具高效性和可解释性。

Abstract: Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.

</details>


### [91] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
*Kaustav Chatterjee,Joshua Q. Li,Fatemeh Ansari,Masud Rana Munna,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 研究提出了一种结合LSTM和Transformer的混合深度学习框架，用于高效测量HRGC剖面，提升安全性。


<details>
  <summary>Details</summary>
Motivation: 传统HRGC剖面测量方法成本高、耗时长且存在安全隐患，需开发更高效的技术。

Method: 利用配备IMU和GPS的测试车辆收集数据，结合工业标准行走剖面仪获取真实数据，开发了三种深度学习模型进行比较。

Result: 模型2和3表现最佳，能生成2D/3D HRGC剖面，显著提升测量效率和准确性。

Conclusion: 混合深度学习框架为HRGC剖面测量提供了快速、准确的解决方案，有助于提升公路和铁路安全性。

Abstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.

</details>


### [92] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 结合贝叶斯机制检测与条件神经过程，提出R-NP模型用于德国市场24小时电价预测，并通过多标准评估优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决电价预测中因市场机制变化导致的预测不准确问题，提升预测模型在电池存储优化中的实用性。

Method: 使用DS-HDP-HMM检测电价机制，每个机制由独立的条件神经过程（CNP）建模，最终预测为机制加权混合。

Result: R-NP在多标准评估中表现最均衡，优于DNN和LEAR模型。

Conclusion: R-NP模型在电价预测和实际应用中表现最优，尤其在多机制市场中具有显著优势。

Abstract: This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.

</details>


### [93] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: DevFT是一种资源高效的联邦微调方法，通过分阶段的子模型优化和知识转移，显著提升了LLM的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决联邦微调在边缘设备上资源密集的问题，同时保持数据隐私。

Method: 采用分阶段的子模型优化，通过知识转移和层分组/融合技术构建高效模型。

Result: 在多个基准测试中，DevFT实现了更快的收敛速度、更低的通信开销和更高的性能。

Conclusion: DevFT是一种高效且兼容现有方法的联邦微调解决方案。

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [94] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Alberto Termine,Mateja Jamnik,Giuseppe Marra*

Main category: cs.LG

TL;DR: 论文提出了一种新的可解释性定义，解决了现有定义不具操作性的问题，并提供了设计可解释模型的蓝图和开源库。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性定义缺乏操作性，无法指导用户设计通用、可靠且稳健的可解释模型，导致研究问题不明确。

Method: 提出了一种通用且简单的可解释性新定义，并基于此设计了可解释模型的蓝图和开源库。

Result: 新定义揭示了设计可解释模型所需的基础属性、假设、原则、数据结构和架构特征。

Conclusion: 论文通过新定义和工具，为可解释性研究提供了明确的方向和实用支持。

Abstract: We argue that existing definitions of interpretability are not actionable in
that they fail to inform users about general, sound, and robust interpretable
model design. This makes current interpretability research fundamentally
ill-posed. To address this issue, we propose a definition of interpretability
that is general, simple, and subsumes existing informal notions within the
interpretable AI community. We show that our definition is actionable, as it
directly reveals the foundational properties, underlying assumptions,
principles, data structures, and architectural features necessary for designing
interpretable models. Building on this, we propose a general blueprint for
designing interpretable models and introduce the first open-sourced library
with native support for interpretable data structures and processes.

</details>


### [95] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
*Nhut Truong,Uri Hasson*

Main category: cs.LG

TL;DR: 比较了两种空间约束（权重相似性和激活相似性）对地形卷积神经网络的影响，发现权重相似性在鲁棒性、输入敏感性和功能定位方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 探讨不同地形约束对神经网络学习表示的影响，填补系统性研究的空白。

Method: 比较权重相似性（WS）和激活相似性（AS）约束下的地形卷积神经网络，评估分类准确性、鲁棒性和表示空间组织。

Result: WS在噪声鲁棒性、输入敏感性和功能定位方面优于AS和标准CNN，并影响了网络表示几何。

Conclusion: 权重相似性约束在端到端训练中产生更鲁棒的表示，对生物物理启发模型的特征学习和功能组织有影响。

Abstract: Topographic neural networks are computational models that can simulate the
spatial and functional organization of the brain. Topographic constraints in
neural networks can be implemented in multiple ways, with potentially different
impacts on the representations learned by the network. The impact of such
different implementations has not been systematically examined. To this end,
here we compare topographic convolutional neural networks trained with two
spatial constraints: Weight Similarity (WS), which pushes neighboring units to
develop similar incoming weights, and Activation Similarity (AS), which
enforces similarity in unit activations. We evaluate the resulting models on
classification accuracy, robustness to weight perturbations and input
degradation, and the spatial organization of learned representations. Compared
to both AS and standard CNNs, WS provided three main advantages: i) improved
robustness to noise, also showing higher accuracy under weight corruption; ii)
greater input sensitivity, reflected in higher activation variance; and iii)
stronger functional localization, with units showing similar activations
positioned at closer distances. In addition, WS produced differences in
orientation tuning, symmetry sensitivity, and eccentricity profiles of units,
indicating an influence of this spatial constraint on the representational
geometry of the network. Our findings suggest that during end-to-end training,
WS constraints produce more robust representations than AS or non-topographic
CNNs. These findings also suggest that weight-based spatial constraints can
shape feature learning and functional organization in biophysical inspired
models.

</details>


### [96] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
*Ruo Yu Tao,Kaicheng Guo,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: 论文提出了一个用于评估强化学习算法在部分可观测性下性能的基准框架POBAX，强调覆盖多种部分可观测形式和环境的内存可改进性。


<details>
  <summary>Details</summary>
Motivation: 现有的部分可观测性基准过于简单，无法反映真实场景中的复杂部分可观测性，如视觉遮挡或未知对手意图。

Method: 提出了一个基准框架POBAX，包含多样化的部分可观测环境，并确保这些环境具有内存可改进性。

Result: POBAX框架提供了多种任务（如定位、视觉控制、游戏等），这些任务均需要难以学习的内存功能。

Conclusion: POBAX为部分可观测性研究提供了全面的基准和工具，支持快速评估和GPU扩展实验。

Abstract: Mitigating partial observability is a necessary but challenging task for
general reinforcement learning algorithms. To improve an algorithm's ability to
mitigate partial observability, researchers need comprehensive benchmarks to
gauge progress. Most algorithms tackling partial observability are only
evaluated on benchmarks with simple forms of state aliasing, such as feature
masking and Gaussian noise. Such benchmarks do not represent the many forms of
partial observability seen in real domains, like visual occlusion or unknown
opponent intent. We argue that a partially observable benchmark should have two
key properties. The first is coverage in its forms of partial observability, to
ensure an algorithm's generalizability. The second is a large gap between the
performance of a agents with more or less state information, all other factors
roughly equal. This gap implies that an environment is memory improvable: where
performance gains in a domain are from an algorithm's ability to cope with
partial observability as opposed to other factors. We introduce best-practice
guidelines for empirically benchmarking reinforcement learning under partial
observability, as well as the open-source library POBAX: Partially Observable
Benchmarks in JAX. We characterize the types of partial observability present
in various environments and select representative environments for our
benchmark. These environments include localization and mapping, visual control,
games, and more. Additionally, we show that these tasks are all memory
improvable and require hard-to-learn memory functions, providing a concrete
signal for partial observability research. This framework includes recommended
hyperparameters as well as algorithm implementations for fast, out-of-the-box
evaluation, as well as highly performant environments implemented in JAX for
GPU-scalable experimentation.

</details>


### [97] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
*Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin*

Main category: cs.LG

TL;DR: TriP-LLM是一种基于大语言模型的无监督时间序列异常检测框架，通过三分支设计整合局部和全局特征，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和智能制造的普及，时间序列数据的规模和复杂性增加，传统统计方法难以应对，需要更高效的解决方案。

Method: TriP-LLM采用三分支设计（分块、选择和全局）将时间序列编码为分块标记，利用预训练的大语言模型处理，并通过轻量级解码器重构输入以计算异常分数。

Result: 实验表明，TriP-LLM在多个公共数据集上优于现有方法，且内存消耗更低。

Conclusion: TriP-LLM展示了LLM在时间序列异常检测中的潜力，适合资源受限的环境。

Abstract: Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git

</details>


### [98] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
*Imen Mahmoud,Andrei Velichko*

Main category: cs.LG

TL;DR: 该研究提出了一种结合LightGBM回归模型和遗传算法优化的新方法，评估COVID-19相关指标对比特币回报预测的贡献。结果显示，疫情指标显著提升了预测准确性，尤其是疫苗接种数据。


<details>
  <summary>Details</summary>
Motivation: 研究旨在确定疫情相关健康数据是否能显著提升比特币回报预测的准确性，为投资者和政策制定者提供更精确的市场不确定性指标。

Method: 使用LightGBM回归模型和遗传算法优化，对比包含与不包含COVID-19特征的预测模型，并通过统计方法评估性能。

Result: COVID-19指标显著提升了模型性能（R2提高40%，RMSE降低2%），疫苗接种数据是最重要的预测因子。

Conclusion: 该方法通过整合公共卫生信号扩展了金融分析工具，为系统性危机期间的市场不确定性提供了更精细的指标。

Abstract: This study proposes a novel methodological framework integrating a LightGBM
regression model and genetic algorithm (GA) optimization to systematically
evaluate the contribution of COVID-19-related indicators to Bitcoin return
prediction. The primary objective was not merely to forecast Bitcoin returns
but rather to determine whether including pandemic-related health data
significantly enhances prediction accuracy. A comprehensive dataset comprising
daily Bitcoin returns and COVID-19 metrics (vaccination rates,
hospitalizations, testing statistics) was constructed. Predictive models,
trained with and without COVID-19 features, were optimized using GA over 31
independent runs, allowing robust statistical assessment. Performance metrics
(R2, RMSE, MAE) were statistically compared through distribution overlaps and
Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified
individual feature contributions. Results indicate that COVID-19 indicators
significantly improved model performance, particularly in capturing extreme
market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly
significant statistically). Among COVID-19 features, vaccination metrics,
especially the 75th percentile of fully vaccinated individuals, emerged as
dominant predictors. The proposed methodology extends existing financial
analytics tools by incorporating public health signals, providing investors and
policymakers with refined indicators to navigate market uncertainty during
systemic crises.

</details>


### [99] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
*Ashkan Shakarami,Yousef Yeganeh,Azade Farshad,Lorenzo Nicole,Stefano Ghidoni,Nassir Navab*

Main category: cs.LG

TL;DR: 提出了一种基于材料科学中结构疲劳概念的弹性学习范式，通过动态调整优化行为提升神经网络的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 受材料科学中临时（弹性）和永久（塑性）变形概念的启发，旨在解决神经网络在优化过程中遇到的停滞问题。

Method: 提出了塑性变形优化器，通过内部应力信号检测训练停滞，并注入自适应噪声以逃离尖锐极小值。

Result: 在六种架构、四种优化器和七个视觉基准测试中验证了方法的鲁棒性和泛化能力。

Conclusion: 该方法能够有效提升模型在复杂优化环境中的性能，且计算开销小。

Abstract: This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.

</details>


### [100] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
*Young-ho Cho,Hao Zhu,Duehee Lee,Ross Baldick*

Main category: cs.LG

TL;DR: 论文提出了一种结合广义动态因子模型（GDFM）和生成对抗网络（GAN）的方法，用于合成分布式风电场的长期风能场景，以更好地捕捉时空相关性、波形特征和统计特性。


<details>
  <summary>Details</summary>
Motivation: 资源充足性研究需要准确的风能场景合成，现有方法（如GDFM和GAN单独使用）无法同时满足时空相关性和波形模仿的需求。

Method: 结合GDFM和GAN的优势，利用GAN提取动态因子并作为GDFM的滤波器，以同时捕捉时空和频率相关性。

Result: 在澳大利亚风能数据上的测试表明，该方法在合成风能场景时性能优于其他替代方案，更接近实际风能的统计特性。

Conclusion: GDFM与GAN的结合方法在风能场景合成中表现出色，为资源充足性研究提供了更可靠的输入。

Abstract: For conducting resource adequacy studies, we synthesize multiple long-term
wind power scenarios of distributed wind farms simultaneously by using the
spatio-temporal features: spatial and temporal correlation, waveforms, marginal
and ramp rates distributions of waveform, power spectral densities, and
statistical characteristics. Generating the spatial correlation in scenarios
requires the design of common factors for neighboring wind farms and
antithetical factors for distant wind farms. The generalized dynamic factor
model (GDFM) can extract the common factors through cross spectral density
analysis, but it cannot closely imitate waveforms. The GAN can synthesize
plausible samples representing the temporal correlation by verifying samples
through a fake sample discriminator. To combine the advantages of GDFM and GAN,
we use the GAN to provide a filter that extracts dynamic factors with temporal
information from the observation data, and we then apply this filter in the
GDFM to represent both spatial and frequency correlations of plausible
waveforms. Numerical tests on the combination of GDFM and GAN have demonstrated
performance improvements over competing alternatives in synthesizing wind power
scenarios from Australia, better realizing plausible statistical
characteristics of actual wind power compared to alternatives such as the GDFM
with a filter synthesized from distributions of actual dynamic filters and the
GAN with direct synthesis without dynamic factors.

</details>


### [101] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
*Md. Ehsanul Haque,S. M. Jahidul Islam,Shakil Mia,Rumana Sharmin,Ashikuzzaman,Md Samir Morshed,Md. Tahmidul Huque*

Main category: cs.LG

TL;DR: StackLiverNet是一种可解释的堆叠集成模型，用于肝病检测，通过高级数据预处理和特征选择提高性能，测试准确率达99.89%。


<details>
  <summary>Details</summary>
Motivation: 现有肝病分类模型存在高误分类率、解释性差等问题，需改进。

Method: 采用随机欠采样处理类别不平衡，结合超参数优化的基分类器和LightGBM元模型。

Result: 测试准确率99.89%，Cohen Kappa 0.9974，AUC 0.9993，训练和推理速度快。

Conclusion: StackLiverNet性能优异，适合临床实践，并通过LIME和SHAP提供解释性。

Abstract: Liver diseases are a serious health concern in the world, which requires
precise and timely diagnosis to enhance the survival chances of patients. The
current literature implemented numerous machine learning and deep learning
models to classify liver diseases, but most of them had some issues like high
misclassification error, poor interpretability, prohibitive computational
expense, and lack of good preprocessing strategies. In order to address these
drawbacks, we introduced StackLiverNet in this study; an interpretable stacked
ensemble model tailored to the liver disease detection task. The framework uses
advanced data preprocessing and feature selection technique to increase model
robustness and predictive ability. Random undersampling is performed to deal
with class imbalance and make the training balanced. StackLiverNet is an
ensemble of several hyperparameter-optimized base classifiers, whose
complementary advantages are used through a LightGBM meta-model. The provided
model demonstrates excellent performance, with the testing accuracy of 99.89%,
Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and
efficient training and inference speeds that are amenable to clinical practice
(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local
Interpretable Model-Agnostic Explanations (LIME) are applied to generate
transparent explanations of individual predictions, revealing high
concentrations of Alkaline Phosphatase and moderate SGOT as important
observations of liver disease. Also, SHAP was used to rank features by their
global contribution to predictions, while the Morris method confirmed the most
influential features through sensitivity analysis.

</details>


### [102] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 论文提出了一种新的神经网络层变换方法，通过结构化线性算子和残差校正组件，提升学习稳定性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当代神经网络缺乏结构保障，导致学习不稳定和可解释性差，需要改进。

Method: 将层变换分解为结构化线性算子和残差校正组件，优化信号传播和训练动态。

Result: 实验表明，该方法改善了梯度条件、降低扰动敏感性，并增强层间鲁棒性。

Conclusion: 该方法为更稳定的神经网络架构奠定了基础，兼顾表达能力和透明度。

Abstract: Despite their impressive performance, contemporary neural networks often lack
structural safeguards that promote stable learning and interpretable behavior.
In this work, we introduce a reformulation of layer-level transformations that
departs from the standard unconstrained affine paradigm. Each transformation is
decomposed into a structured linear operator and a residual corrective
component, enabling more disciplined signal propagation and improved training
dynamics. Our formulation encourages internal consistency and supports stable
information flow across depth, while remaining fully compatible with standard
learning objectives and backpropagation. Through a series of synthetic and
real-world experiments, we demonstrate that models constructed with these
structured transformations exhibit improved gradient conditioning, reduced
sensitivity to perturbations, and layer-wise robustness. We further show that
these benefits persist across architectural scales and training regimes. This
study serves as a foundation for a more principled class of neural
architectures that prioritize stability and transparency-offering new tools for
reasoning about learning behavior without sacrificing expressive power.

</details>


### [103] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
*Christopher Harvey,Sumaiya Shomaji,Zijun Yao,Amit Noheria*

Main category: cs.LG

TL;DR: 该研究通过探索特征生成方法（如PCA和Autoencoders）简化ECG数据，并引入三种新型VAE变体（SAE、A beta-VAE、C beta-VAE），以提升信号重建和下游预测任务的效果。A beta-VAE在信号重建上表现最佳，SAE编码结合传统特征提升了LVEF预测性能。


<details>
  <summary>Details</summary>
Motivation: ECG信号复杂且个体差异大，难以在深度学习模型中有效利用，尤其是在小规模数据集上。研究旨在通过特征生成方法简化数据并提升预测性能。

Method: 使用PCA和Autoencoders（包括三种新型VAE变体）简化ECG数据，并结合LGBM进行下游预测任务。

Result: A beta-VAE将信号重建误差降至15.7+/-3.2 muV；SAE编码结合传统特征在LVEF预测中达到0.901 AUROC，接近CNN模型但计算资源需求更低。

Conclusion: 新型VAE编码不仅简化了ECG数据，还为小规模标注数据场景下的深度学习应用提供了实用解决方案。

Abstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for
cardiac assessment. Despite its standardized format and small file size, the
high complexity and inter-individual variability of ECG signals (typically a
60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep
learning models, especially when only small training datasets are available.
This study addresses these challenges by exploring feature generation methods
from representative beat ECGs, focusing on Principal Component Analysis (PCA)
and Autoencoders to reduce data complexity. We introduce three novel
Variational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed
beta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their
effectiveness in maintaining signal fidelity and enhancing downstream
prediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE
achieved superior signal reconstruction, reducing the mean absolute error (MAE)
to 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE
encodings, when combined with traditional ECG summary features, improved the
prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an
holdout test set area under the receiver operating characteristic curve (AUROC)
of 0.901 with a LGBM classifier. This performance nearly matches the 0.909
AUROC of state-of-the-art CNN model but requires significantly less
computational resources. Further, the ECG feature extraction-LGBM pipeline
avoids overfitting and retains predictive performance when trained with less
data. Our findings demonstrate that these VAE encodings are not only effective
in simplifying ECG data but also provide a practical solution for applying deep
learning in contexts with limited-scale labeled training data.

</details>


### [104] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
*Mohit Gupta,Debjit Bhowmick,Rhys Newbury,Meead Saberi,Shirui Pan,Ben Beck*

Main category: cs.LG

TL;DR: INSPIRE-GNN是一种结合强化学习和图神经网络的框架，用于优化自行车流量传感器布局并提高稀疏数据环境下的流量估计精度。


<details>
  <summary>Details</summary>
Motivation: 解决城市自行车流量数据稀疏性问题，为可持续交通规划提供准确数据支持。

Method: 结合图卷积网络（GCN）、图注意力网络（GAT）和深度Q网络（DQN）的强化学习代理，优化传感器布局。

Result: 在墨尔本自行车网络中，INSPIRE-GNN显著提升了流量估计精度，优于传统启发式方法和其他机器学习模型。

Conclusion: 该框架为交通规划者提供了优化传感器网络和提升数据可靠性的有效工具。

Abstract: Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.

</details>


### [105] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 提出了一种基于权重而非激活的新方法，用于理解和监控微调后的LLMs，无需与训练数据分布相似的数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于激活的解释方法需要与训练数据分布相似的数据，而实际中训练数据往往不可得，限制了检测和防御新威胁（如后门）的能力。

Method: 通过分析微调模型与基础模型权重差异的顶部奇异向量，识别新行为，并通过余弦相似度监控这些行为。

Result: 在后门模型中阻止了100%攻击（假阳性率<1.2%），在遗忘模型中检测遗忘主题准确率达95.42%，并能恢复“遗忘”信息。

Conclusion: 该方法在监控和审计微调LLMs方面具有潜力，可应用于商业模型分析。

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [106] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
*Fupei Guo,Hao Zheng,Xiang Zhang,Li Chen,Yue Wang,Songyang Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于扩散的语义通信框架DiSC-Med，用于高效且鲁棒的医学图像传输。


<details>
  <summary>Details</summary>
Motivation: 人工智能和无线通信技术的发展推动了远程医疗的需求，但如何在有限带宽和噪声信道中高效传输医学数据成为关键挑战。

Method: 开发了医学增强的压缩和去噪模块，以提升带宽效率和鲁棒性，通过语义信息捕获实现高效重建。

Result: 在真实医学数据集上的实验验证了DiSC-Med的优越性能，展示了其在远程医疗中的潜力。

Conclusion: DiSC-Med框架在噪声信道下实现了高效且鲁棒的医学图像传输，为远程医疗应用提供了可行方案。

Abstract: The rapid development of artificial intelligence has driven smart health with
next-generation wireless communication technologies, stimulating exciting
applications in remote diagnosis and intervention. To enable a timely and
effective response for remote healthcare, efficient transmission of medical
data through noisy channels with limited bandwidth emerges as a critical
challenge. In this work, we propose a novel diffusion-based semantic
communication framework, namely DiSC-Med, for the medical image transmission,
where medical-enhanced compression and denoising blocks are developed for
bandwidth efficiency and robustness, respectively. Unlike conventional
pixel-wise communication framework, our proposed DiSC-Med is able to capture
the key semantic information and achieve superior reconstruction performance
with ultra-high bandwidth efficiency against noisy channels. Extensive
experiments on real-world medical datasets validate the effectiveness of our
framework, demonstrating its potential for robust and efficient telehealth
applications.

</details>


### [107] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 论文提出将回归问题转化为强化学习问题，通过自定义奖励信号和RL算法实现灵活的目标定义和学习。


<details>
  <summary>Details</summary>
Motivation: 传统回归方法受限于预定义的可微损失函数，难以处理非对称成本或复杂目标。

Method: 将模型预测视为动作，基于预测误差定义奖励信号，使用Actor-Critic算法，并结合优先经验回放、增加网络容量和位置编码。

Result: RL框架成功解决了回归问题，并在目标定义和学习过程中表现出更高的灵活性。

Conclusion: 强化学习为回归问题提供了新的解决范式，尤其在处理复杂目标时更具优势。

Abstract: Standard regression techniques, while powerful, are often constrained by
predefined, differentiable loss functions such as mean squared error. These
functions may not fully capture the desired behavior of a system, especially
when dealing with asymmetric costs or complex, non-differentiable objectives.
In this paper, we explore an alternative paradigm: framing regression as a
Reinforcement Learning (RL) problem. We demonstrate this by treating a model's
prediction as an action and defining a custom reward signal based on the
prediction error, and we can leverage powerful RL algorithms to perform
function approximation. Through a progressive case study of learning a noisy
sine wave, we illustrate the development of an Actor-Critic agent, iteratively
enhancing it with Prioritized Experience Replay, increased network capacity,
and positional encoding to enable a capable RL agent for this regression task.
Our results show that the RL framework not only successfully solves the
regression problem but also offers enhanced flexibility in defining objectives
and guiding the learning process.

</details>


### [108] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
*Adam Block,Cyril Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种改进的指数移动平均方法（BEMA），用于减少语言模型微调中的训练不稳定性，同时消除传统EMA引入的偏差。


<details>
  <summary>Details</summary>
Motivation: 传统EMA方法虽然能减少训练中的随机性，但会引入旧权重的偏差，导致优化滞后。BEMA旨在保留EMA的方差减少优势，同时消除偏差。

Method: 提出BEMA方法，通过理论模型证明其优于传统EMA和普通训练，并在实验中验证其效果。

Result: BEMA在多个标准语言模型基准测试中显著提高了收敛速度和最终性能。

Conclusion: BEMA是一种实用且理论支持的方法，可提高微调的稳定性和效率。

Abstract: Stochasticity in language model fine-tuning, often caused by the small batch
sizes typically used in this regime, can destabilize training by introducing
large oscillations in generation quality. A popular approach to mitigating this
instability is to take an Exponential moving average (EMA) of weights
throughout training. While EMA reduces stochasticity, thereby smoothing
training, the introduction of bias from old iterates often creates a lag in
optimization relative to vanilla training. In this work, we propose the
Bias-Corrected Exponential Moving Average (BEMA), a simple and practical
augmentation of EMA that retains variance-reduction benefits while eliminating
bias. BEMA is motivated by a simple theoretical model wherein we demonstrate
provable acceleration of BEMA over both a standard EMA and vanilla training.
Through an extensive suite of experiments on Language Models, we show that BEMA
leads to significantly improved convergence rates and final performance over
both EMA and vanilla training in a variety of standard LM benchmarks, making
BEMA a practical and theoretically motivated intervention for more stable and
efficient fine-tuning.

</details>


### [109] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
*Mehdi Ben Ayed,Fei Feng,Jay Adams,Vishwakarma Singh,Kritarth Anand,Jiajing Xu*

Main category: cs.LG

TL;DR: RecoMind是一个基于模拟器的强化学习框架，用于优化网络规模的会话目标，显著提升用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统依赖监督学习，难以优化长期目标（如会话参与度），而强化学习在超大规模动作空间和工程复杂性上面临挑战。

Method: RecoMind利用现有推荐模型构建模拟环境，并通过定制探索策略高效探索超大规模动作空间，简化RL策略的训练与部署。

Result: 离线模拟和在线A/B测试显示，RecoMind训练的RL策略显著优于传统监督学习方法，会话用户满意度提升明显。

Conclusion: RecoMind为网络规模推荐系统提供了一种系统化、可扩展的RL嵌入方法，展示了优化会话用户满意度的巨大潜力。

Abstract: Existing web-scale recommendation systems commonly use supervised learning
methods that prioritize immediate user feedback. Although reinforcement
learning (RL) offers a solution to optimize longer-term goals, such as
in-session engagement, applying it at web scale is challenging due to the
extremely large action space and engineering complexity. In this paper, we
introduce RecoMind, a simulator-based RL framework designed for the effective
optimization of session-based goals at web-scale. RecoMind leverages existing
recommendation models to establish a simulation environment and to bootstrap
the RL policy to optimize immediate user interactions from the outset. This
method integrates well with existing industry pipelines, simplifying the
training and deployment of RL policies. Additionally, RecoMind introduces a
custom exploration strategy to efficiently explore web-scale action spaces with
hundreds of millions of items. We evaluated RecoMind through extensive offline
simulations and online A/B testing on a video streaming platform. Both methods
showed that the RL policy trained using RecoMind significantly outperforms
traditional supervised learning recommendation approaches in in-session user
satisfaction. In online A/B tests, the RL policy increased videos watched for
more than 10 seconds by 15.81\% and improved session depth by 4.71\% for
sessions with at least 10 interactions. As a result, RecoMind presents a
systematic and scalable approach for embedding RL into web-scale recommendation
systems, showing great promise for optimizing session-based user satisfaction.

</details>


### [110] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
*Ecem Bozkurt,Antonio Ortega*

Main category: cs.LG

TL;DR: 提出一种两阶段框架，利用几何信息在标签噪声下实现鲁棒分类，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 在标签噪声存在的情况下，现有方法（如kNN）利用局部几何信息表现良好，但仍有改进空间。

Method: 采用两阶段流程：可靠性估计和可靠性加权推断，引入非负核（NNK）邻域构建。

Result: 在CIFAR-10和DermaMNIST上，方法在多种噪声条件下表现优于标准kNN和自适应邻域基线。

Conclusion: 通过几何信息和可靠性加权推断，显著提升了标签噪声下的分类鲁棒性。

Abstract: Foundation models (FMs) pretrained on large datasets have become fundamental
for various downstream machine learning tasks, in particular in scenarios where
obtaining perfectly labeled data is prohibitively expensive. In this paper, we
assume an FM has to be fine-tuned with noisy data and present a two-stage
framework to ensure robust classification in the presence of label noise
without model retraining. Recent work has shown that simple k-nearest neighbor
(kNN) approaches using an embedding derived from an FM can achieve good
performance even in the presence of severe label noise. Our work is motivated
by the fact that these methods make use of local geometry. In this paper,
following a similar two-stage procedure, reliability estimation followed by
reliability-weighted inference, we show that improved performance can be
achieved by introducing geometry information. For a given instance, our
proposed inference uses a local neighborhood of training data, obtained using
the non-negative kernel (NNK) neighborhood construction. We propose several
methods for reliability estimation that can rely less on distance and local
neighborhood as the label noise increases. Our evaluation on CIFAR-10 and
DermaMNIST shows that our methods improve robustness across various noise
conditions, surpassing standard K-NN approaches and recent
adaptive-neighborhood baselines.

</details>


### [111] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: KRAdapter是一种新型PEFT算法，通过Khatri-Rao乘积生成权重更新，解决了LoRA在近似高有效秩矩阵时的局限性，并在大规模模型上表现优异。


<details>
  <summary>Details</summary>
Motivation: LoRA在多模态和大语言模型中存在局限性，尤其是在处理高有效秩矩阵时表现不佳。

Method: 提出KRAdapter算法，利用Khatri-Rao乘积生成权重更新，以解决高有效秩矩阵的近似问题。

Result: KRAdapter在1B参数的视觉语言模型和8B参数的大语言模型上表现优于LoRA，尤其是在未见过的常识推理任务中。

Conclusion: KRAdapter在保持LoRA计算和内存效率的同时，提供了更强大的性能，是高效微调大规模模型的实用替代方案。

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [112] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
*Jerry Huang,Peng Lu,Qiuhao Zeng*

Main category: cs.LG

TL;DR: 研究探讨了指令调优对大型语言模型（LLM）置信度校准的影响，并提出标签平滑作为解决方案，同时解决了内存占用问题。


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优提升了LLM的交互能力，但其对模型置信度校准的影响尚未充分研究。

Method: 分析了开源LLM的校准退化现象，提出标签平滑作为解决方案，并设计定制内核以减少内存消耗。

Result: 标签平滑能有效维持校准，但在大型词汇LLM中效果受限；理论及实验验证了过自信与模型规模的关系。

Conclusion: 标签平滑是维持LLM校准的有效方法，定制内核解决了内存问题，为实际应用提供了可行方案。

Abstract: Recent advances in natural language processing (NLP) have opened up greater
opportunities to enable fine-tuned large language models (LLMs) to behave as
more powerful interactive agents through improved instruction-following
ability. However, understanding how this impacts confidence calibration for
reliable model output has not been researched in full. In this work, we examine
various open-sourced LLMs, identifying significant calibration degradation
after instruction tuning in each. Seeking a practical solution, we look towards
label smoothing, which has been shown as an effective method to regularize for
overconfident predictions but has yet to be widely adopted in the supervised
fine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing
is sufficient to maintain calibration throughout the SFT process. However,
settings remain where the effectiveness of smoothing is severely diminished, in
particular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to
stem from the ability to become over-confident, which has a direct relationship
with the hidden size and vocabulary size, and justify this theoretically and
experimentally. Finally, we address an outstanding issue regarding the memory
footprint of the cross-entropy loss computation in the label smoothed loss
setting, designing a customized kernel to dramatically reduce memory
consumption without sacrificing speed or performance in comparison to existing
solutions for non-smoothed losses.

</details>


### [113] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
*Robin Schmucker,Nimish Pachapurkar,Shanmuga Bala,Miral Shah,Tom Mitchell*

Main category: cs.LG

TL;DR: 在线辅导系统通过多臂老虎机框架优化学生反馈，提升学习效果，并探索个性化反馈的潜力。


<details>
  <summary>Details</summary>
Motivation: 通过数据驱动的方法优化学生反馈，提升学习效果和练习表现。

Method: 使用多臂老虎机（MAB）框架和离线策略评估，分析43,000个辅助动作，并设计算法选择适合的训练目标。进一步探索上下文老虎机（CB）策略的个性化效果。

Result: MAB策略显著改善学生表现，但CB策略的个性化效果有限，改进空间不大。

Conclusion: 数据驱动的反馈优化系统已大规模应用，未来可进一步探索个性化反馈的潜力。

Abstract: We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.

</details>


### [114] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
*Mohsen Zaker Esteghamati*

Main category: cs.LG

TL;DR: 本研究提出了一种将基于性能的抗震设计视为逆工程问题的方法，通过可解释的机器学习模型直接映射设计变量与性能指标，解决了传统方法的计算效率问题。该方法应用于钢和混凝土框架结构，优化了构件截面属性以最小化地震损失。


<details>
  <summary>Details</summary>
Motivation: 传统基于性能的抗震设计方法计算效率低下，本研究旨在通过机器学习模型直接映射设计变量与性能指标，提高设计效率。

Method: 采用可解释的机器学习模型作为评估函数，结合遗传优化算法解决逆工程问题，应用于钢和混凝土框架结构的优化设计。

Result: 机器学习模型表现出高准确性（R2>90%），优化算法能够识别构件属性的最优值，符合工程原理。

Conclusion: 该方法显著提高了抗震设计的计算效率，并在多样化的建筑类型和地震条件下表现出高准确性。

Abstract: This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.

</details>


### [115] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
*Tianyin Liao,Ziwei Zhang,Yufei Sun,Chunyu Hu,Jianxin Li*

Main category: cs.LG

TL;DR: GOODFormer是一种基于图不变学习的Transformer模型，旨在解决图数据分布偏移下的泛化问题，通过分离不变与可变子图、动态编码和不变学习模块提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有图Transformer在分布偏移下泛化能力不足，图不变学习虽有望解决此问题，但其注意力机制和编码设计仍具挑战。

Method: 提出GOODFormer，包括熵引导不变子图解耦器、动态子图编码器和不变学习模块，联合优化以捕获不变关系。

Result: 在基准数据集上，GOODFormer在分布偏移下优于现有方法。

Conclusion: GOODFormer通过不变学习有效提升图Transformer的泛化能力，为分布偏移问题提供了解决方案。

Abstract: Graph Transformers (GTs) have demonstrated great effectiveness across various
graph analytical tasks. However, the existing GTs focus on training and testing
graph data originated from the same distribution, but fail to generalize under
distribution shifts. Graph invariant learning, aiming to capture generalizable
graph structural patterns with labels under distribution shifts, is potentially
a promising solution, but how to design attention mechanisms and positional and
structural encodings (PSEs) based on graph invariant learning principles
remains challenging. To solve these challenges, we introduce Graph
Out-Of-Distribution generalized Transformer (GOODFormer), aiming to learn
generalized graph representations by capturing invariant relationships between
predictive graph structures and labels through jointly optimizing three
modules. Specifically, we first develop a GT-based entropy-guided invariant
subgraph disentangler to separate invariant and variant subgraphs while
preserving the sharpness of the attention function. Next, we design an evolving
subgraph positional and structural encoder to effectively and efficiently
capture the encoding information of dynamically changing subgraphs during
training. Finally, we propose an invariant learning module utilizing subgraph
node representations and encodings to derive generalizable graph
representations that can to unseen graphs. We also provide theoretical
justifications for our method. Extensive experiments on benchmark datasets
demonstrate the superiority of our method over state-of-the-art baselines under
distribution shifts.

</details>


### [116] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
*Yongquan Qu,Matthieu Blanke,Sara Shamekh,Pierre Gentine*

Main category: cs.LG

TL;DR: PnP-DA是一种数据同化方法，通过结合轻量级梯度更新和预训练生成先验，减少地球系统建模中的误差累积，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 地球系统建模中的误差累积问题需要解决，传统方法的高斯假设不适用于混沌动力系统。

Method: PnP-DA交替使用梯度分析更新和预训练生成先验，避免复杂神经网络的反向传播。

Result: 在混沌测试中，PnP-DA显著降低了预测误差，优于传统变分方法。

Conclusion: PnP-DA通过放松统计假设和利用历史数据，提供了一种高效的数据同化解决方案。

Abstract: Earth system modeling presents a fundamental challenge in scientific
computing: capturing complex, multiscale nonlinear dynamics in computationally
efficient models while minimizing forecast errors caused by necessary
simplifications. Even the most powerful AI- or physics-based forecast system
suffer from gradual error accumulation. Data assimilation (DA) aims to mitigate
these errors by optimally blending (noisy) observations with prior model
forecasts, but conventional variational methods often assume Gaussian error
statistics that fail to capture the true, non-Gaussian behavior of chaotic
dynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates
(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance
misfit on new observations) with (2) a single forward pass through a pretrained
generative prior conditioned on the background forecast via a conditional
Wasserstein coupling. This strategy relaxes restrictive statistical assumptions
and leverages rich historical data without requiring an explicit regularization
functional, and it also avoids the need to backpropagate gradients through the
complex neural network that encodes the prior during assimilation cycles.
Experiments on standard chaotic testbeds demonstrate that this strategy
consistently reduces forecast errors across a range of observation sparsities
and noise levels, outperforming classical variational methods.

</details>


### [117] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
*George Wang,Garrett Baker,Andrew Gordon,Daniel Murfet*

Main category: cs.LG

TL;DR: 论文提出了一种基于UMAP和敏感性分析的胚胎学方法，用于可视化语言模型的内部结构发展，揭示了新的网络机制。


<details>
  <summary>Details</summary>
Motivation: 理解语言模型内部计算结构的形成是深度学习科学的核心问题，但现有的敏感性分析工具尚未充分发挥其潜力。

Method: 采用UMAP技术对敏感性矩阵进行分析，可视化模型在训练过程中的结构发展。

Result: 可视化结果揭示了明确的“身体计划”，包括已知特征（如感应电路）和新发现的结构（如用于计数空格标记的“间距鳍”）。

Conclusion: 敏感性分析不仅能验证模型，还能发现新机制，为研究复杂神经网络的发育原理提供了全面视角。

Abstract: Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.

</details>


### [118] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: BOOD框架利用扩散模型生成高质量的OOD特征和图像，显著提升OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决在潜在空间中提取有效OOD特征的挑战，并生成与人类兼容的异常图像。

Method: BOOD通过学习文本条件潜在特征空间，选择接近决策边界的ID特征并扰动生成OOD特征，再用扩散模型解码为图像。

Result: 在CIFAR-100数据集上，BOOD显著优于现有方法，FPR95降低29.64%，AUROC提升7.27%。

Conclusion: BOOD提供了一种高效的OOD特征生成策略，显著提升了OOD检测性能。

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training
data based on latent space features has proven effective in enhancing
out-of-distribution (OOD) detection performance. However, extracting effective
features outside the in-distribution (ID) boundary in latent space remains
challenging due to the difficulty of identifying decision boundaries between
classes. This paper proposes a novel framework called Boundary-based
Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD
features and generates human-compatible outlier images using diffusion models.
BOOD first learns a text-conditioned latent feature space from the ID dataset,
selects ID features closest to the decision boundary, and perturbs them to
cross the decision boundary to form OOD features. These synthetic OOD features
are then decoded into images in pixel space by a diffusion model. Compared to
previous works, BOOD provides a more training efficient strategy for
synthesizing informative OOD features, facilitating clearer distinctions
between ID and OOD data. Extensive experimental results on common benchmarks
demonstrate that BOOD surpasses the state-of-the-art method significantly,
achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%
improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


### [119] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
*Yoonhyuk Choi,Jiho Choi,Chong-Kwon Kim*

Main category: cs.LG

TL;DR: SGPC是一种结合了细胞鞘消息传递的新方法，通过最优传输提升、方差减少扩散和PAC-Bayes谱正则化，解决了GNN中的过平滑问题，并在异质图上表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决GNN中过平滑问题，特别是在异质图上，现有鞘神经网络方法泛化性和可扩展性不足。

Method: 提出SGPC，结合细胞鞘消息传递、最优传输提升、方差减少扩散和PAC-Bayes谱正则化。

Result: 在九种基准测试中优于现有方法，并提供未见过节点的置信区间。

Conclusion: SGPC在性能和理论保证上均优于现有方法，具有高效性和可扩展性。

Abstract: Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct
node features, particularly on heterophilic graphs where adjacent nodes often
have dissimilar labels. Although sheaf neural networks partially mitigate this
problem, they typically rely on static or heavily parameterized sheaf
structures that hinder generalization and scalability. Existing sheaf-based
models either predefine restriction maps or introduce excessive complexity, yet
fail to provide rigorous stability guarantees. In this paper, we introduce a
novel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified
architecture that combines cellular-sheaf message passing with several
mechanisms, including optimal transport-based lifting, variance-reduced
diffusion, and PAC-Bayes spectral regularization for robust semi-supervised
node classification. We establish performance bounds theoretically and
demonstrate that the resulting bound-aware objective can be achieved via
end-to-end training in linear computational complexity. Experiments on nine
homophilic and heterophilic benchmarks show that SGPC outperforms
state-of-the-art spectral and sheaf-based GNNs while providing certified
confidence intervals on unseen nodes.

</details>


### [120] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
*Chanyoung Yoon,Sangbong Yoo,Soobin Yim,Chansoo Kim,Yun Jang*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习的新框架OID-PPO，用于优化住宅室内设计，解决了现有方法在计算效率和数据稀缺方面的不足。


<details>
  <summary>Details</summary>
Motivation: 住宅室内设计对居住满意度至关重要，但现有方法因计算成本高、数据稀缺或设计原则融入不足而受限。

Method: 采用Proximal Policy Optimization（PPO）强化学习框架，结合专家定义的功能和视觉准则，通过对角高斯策略实现连续灵活的家具布局。

Result: 实验表明，OID-PPO在布局质量和计算效率上显著优于现有方法，并通过消融研究验证了设计准则的重要性。

Conclusion: OID-PPO为室内设计提供了一种高效且灵活的解决方案，成功整合了设计原则并优化了布局效果。

Abstract: Designing residential interiors strongly impacts occupant satisfaction but
remains challenging due to unstructured spatial layouts, high computational
demands, and reliance on expert knowledge. Existing methods based on
optimization or deep learning are either computationally expensive or
constrained by data scarcity. Reinforcement learning (RL) approaches often
limit furniture placement to discrete positions and fail to incorporate design
principles adequately. We propose OID-PPO, a novel RL framework for Optimal
Interior Design using Proximal Policy Optimization, which integrates
expert-defined functional and visual guidelines into a structured reward
function. OID-PPO utilizes a diagonal Gaussian policy for continuous and
flexible furniture placement, effectively exploring latent environmental
dynamics under partial observability. Experiments conducted across diverse room
shapes and furniture configurations demonstrate that OID-PPO significantly
outperforms state-of-the-art methods in terms of layout quality and
computational efficiency. Ablation studies further demonstrate the impact of
structured guideline integration and reveal the distinct contributions of
individual design constraints.

</details>


### [121] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
*Lijun Zhang,Wenhao Yang,Guanghui Wang,Wei Jiang,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种具有双重适应性的通用算法框架，用于在线学习中最小化自适应遗憾，适用于多种凸函数类型和动态环境。


<details>
  <summary>Details</summary>
Motivation: 现有算法缺乏通用性，只能处理单一类型的凸函数且需要先验参数知识，限制了实际应用。

Method: 提出了一种基于元专家框架的双重自适应算法，动态创建多个专家并通过元算法聚合，结合睡眠专家技术捕捉环境变化。

Result: 理论分析表明，该算法能同时最小化多种凸函数的自适应遗憾，并允许函数类型在轮次间切换。

Conclusion: 该框架可扩展到在线复合优化，为复合函数的自适应遗憾最小化提供了通用解决方案。

Abstract: To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters,
which hinders their application in real-world scenarios. To address this
limitation, this paper investigates universal algorithms with dual adaptivity,
which automatically adapt to the property of functions (convex, exponentially
concave, or strongly convex), as well as the nature of environments (stationary
or changing). Specifically, we propose a meta-expert framework for dual
adaptive algorithms, where multiple experts are created dynamically and
aggregated by a meta-algorithm. The meta-algorithm is required to yield a
second-order bound, which can accommodate unknown function types. We further
incorporate the technique of sleeping experts to capture the changing
environments. For the construction of experts, we introduce two strategies
(increasing the number of experts or enhancing the capabilities of experts) to
achieve universality. Theoretical analysis shows that our algorithms are able
to minimize the adaptive regret for multiple types of convex functions
simultaneously, and also allow the type of functions to switch between rounds.
Moreover, we extend our meta-expert framework to online composite optimization,
and develop a universal algorithm for minimizing the adaptive regret of
composite functions.

</details>


### [122] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
*Antonis Klironomos,Baifan Zhou,Zhipeng Tan,Zhuoxun Zheng,Mohamed H. Gad-Elrab,Heiko Paulheim,Evgeny Kharlamov*

Main category: cs.LG

TL;DR: ExeKGLib是一个Python库，带有图形界面，帮助非机器学习专家构建ML管道，利用知识图谱简化ML知识。


<details>
  <summary>Details</summary>
Motivation: 解决领域专家缺乏ML专业知识但需要ML分析的问题。

Method: 通过知识图谱编码ML知识，提供图形界面简化管道构建。

Result: 展示了ExeKGLib的实际用例，证明其可用性和实用性。

Conclusion: ExeKGLib为非ML专家提供了高效、透明的ML管道构建工具。

Abstract: Nowadays machine learning (ML) practitioners have access to numerous ML
libraries available online. Such libraries can be used to create ML pipelines
that consist of a series of steps where each step may invoke up to several ML
libraries that are used for various data-driven analytical tasks. Development
of high-quality ML pipelines is non-trivial; it requires training, ML
expertise, and careful development of each step. At the same time, domain
experts in science and engineering may not possess such ML expertise and
training while they are in pressing need of ML-based analytics. In this paper,
we present our ExeKGLib, a Python library enhanced with a graphical interface
layer that allows users with minimal ML knowledge to build ML pipelines. This
is achieved by relying on knowledge graphs that encode ML knowledge in simple
terms accessible to non-ML experts. ExeKGLib also allows improving the
transparency and reusability of the built ML workflows and ensures that they
are executable. We show the usability and usefulness of ExeKGLib by presenting
real use cases.

</details>


### [123] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
*Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han*

Main category: cs.LG

TL;DR: Co-Reward是一种新型强化学习框架，通过对比语义类比问题的一致性作为奖励基础，提升语言模型的推理能力，避免了依赖人工标注和自奖励信号的崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR依赖人工标注和自奖励信号崩溃的问题，提升语言模型的推理能力。

Method: 构建语义相似的未标注问题对，通过投票生成代理标签，利用对比一致性构建奖励机制。

Result: 在多个推理基准测试和LLM系列上表现优于其他自奖励基线，部分任务甚至超越人工标注奖励。

Conclusion: Co-Reward通过自监督奖励机制有效提升了语言模型的推理能力，避免了崩溃问题。

Abstract: Although reinforcement learning with verifiable rewards (RLVR) shows promise
in improving the reasoning ability of large language models (LLMs), the scaling
up dilemma remains due to the reliance on human annotated labels especially for
complex tasks. Recent alternatives that explore various self-reward signals
exhibit the eliciting potential of LLM reasoning, but suffer from the
non-negligible collapse issue. Inspired by the success of self-supervised
learning, we propose \textit{Co-Reward}, a novel RL framework that leverages
contrastive agreement across semantically analogical questions as a reward
basis. Specifically, we construct a similar question for each training sample
(without labels) and synthesize their individual surrogate labels through a
simple rollout voting, and then the reward is constructed by cross-referring
the labels of each question pair to enforce the internal reasoning consistency
across analogical inputs. Intuitively, such a self-supervised reward-shaping
mechanism increases the difficulty of learning collapse into a trivial
solution, and promotes stable reasoning elicitation and improvement through
expanding the input sample variants. Empirically, Co-Reward achieves superior
performance compared to other self-reward baselines on multiple reasoning
benchmarks and LLM series, and reaches or even surpasses ground-truth (GT)
labeled reward, with improvements of up to $+6.8\%$ on MATH500 over GT reward
on Llama-3.2-3B-Instruct. Our code is publicly available at
https://github.com/tmlr-group/Co-Reward.

</details>


### [124] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
*Yue Yang,Yuxiang Lin,Ying Zhang,Zihan Su,Chang Chuan Goh,Tangtangfang Fang,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 研究提出ResE-BiLSTM模型，用于贷款违约预测，优于五种基线模型，并通过SHAP分析解释模型依赖的特征。


<details>
  <summary>Details</summary>
Motivation: 贷款违约预测对信用风险管理至关重要，机器学习方法能有效检测财务异常。

Method: 使用滑动窗口技术和ResE-BiLSTM模型，在Freddie Mac数据集上评估，并与LSTM、BiLSTM、GRU、CNN、RNN等基线模型对比。

Result: ResE-BiLSTM在准确性、精确度、召回率、F1和AUC等指标上表现最优。

Conclusion: ResE-BiLSTM模型具有实际应用价值，适用于现实场景。

Abstract: Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.

</details>


### [125] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: 论文提出了一种名为ctdGAN的条件生成对抗网络，用于解决表格数据中的类别不平衡问题，通过空间分区和概率采样策略生成高质量样本。


<details>
  <summary>Details</summary>
Motivation: 表格数据中的类别不平衡问题严重影响机器学习性能，现有GAN方法未考虑输入样本的向量子空间，导致生成数据位置随意且条件采样效果不佳。

Method: ctdGAN通过空间分区为输入样本分配聚类标签，利用概率采样策略和新损失函数生成样本，同时引入聚类缩放技术。

Result: 在14个不平衡数据集上的实验表明，ctdGAN能生成高保真样本并显著提升分类准确率。

Conclusion: ctdGAN通过改进生成策略和损失函数，有效解决了表格数据中的类别不平衡问题，生成样本质量高且分类性能优越。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>


### [126] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
*Yiming Xu,Jiarun Chen,Zhen Peng,Zihan Chen,Qika Lin,Lan Ma,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: CoLL框架结合LLMs和GNNs，通过多LLM协作和GNN门控机制，提升文本属性图的异常检测性能，平均AP提升13.37%。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法忽视文本模态的互补价值，且浅层文本编码可能丢失异常相关语义。LLMs虽具语义理解优势，但难以编码图的高阶结构信息。

Method: 提出CoLL框架，结合多LLM协作的证据增强生成和GNN门控机制，融合文本特征与拓扑信息。

Result: 实验显示CoLL平均AP提升13.37%，优于现有方法。

Conclusion: CoLL为LLMs在图异常检测中的应用开辟新途径，展示了文本与拓扑信息融合的潜力。

Abstract: The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.

</details>


### [127] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
*Yiming Xu,Xu Hua,Zhen Peng,Bin Shi,Jiarun Chen,Xingbo Fu,Song Wang,Bo Dong*

Main category: cs.LG

TL;DR: 论文提出了一种名为CMUCL的端到端文本属性图异常检测方法，通过跨模态和多尺度一致性联合训练文本和图编码器，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本属性图（TAGs）异常检测中，文本编码与图域异常检测目标分离，导致提取的文本特征难以聚焦于异常检测相关信息，限制了检测能力。

Method: 提出CMUCL方法，同时建模文本和图结构数据，利用跨模态和单模态多尺度一致性联合训练编码器，并基于不一致性挖掘设计异常评分器。

Result: 在8个新发布的数据集上，CMUCL平均准确率（AP）比次优方法提升了11.13%。

Conclusion: CMUCL通过整合文本和图拓扑数据，显著提升了文本属性图异常检测的性能，为未来研究提供了新的基准数据集。

Abstract: The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.

</details>


### [128] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
*Sifan Yang,Yuanyu Wan,Lijun Zhang*

Main category: cs.LG

TL;DR: 论文研究了在线非子模优化问题，提出了两种算法DBGD-NF和改进版，分别优化了延迟反馈和随机反馈的联合效应，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法对延迟敏感且未解耦延迟与随机反馈的联合效应，限制了性能。

Method: 提出DBGD-NF算法和改进版，分别利用平均延迟和分块更新机制优化性能。

Result: DBGD-NF实现了O(n¯d^1/3T^2/3)的遗憾界，改进版进一步优化为O(n(T^2/3 + √dT))。

Conclusion: 新算法在延迟和随机反馈处理上优于现有方法，实验验证了其有效性。

Abstract: We investigate the online nonsubmodular optimization with delayed feedback in
the bandit setting, where the loss function is $\alpha$-weakly DR-submodular
and $\beta$-weakly DR-supermodular. Previous work has established an
$(\alpha,\beta)$-regret bound of $\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is
the dimensionality and $d$ is the maximum delay. However, its regret bound
relies on the maximum delay and is thus sensitive to irregular delays.
Additionally, it couples the effects of delays and bandit feedback as its bound
is the product of the delay term and the $\mathcal{O}(nT^{2/3})$ regret bound
in the bandit setting without delayed feedback. In this paper, we develop two
algorithms to address these limitations, respectively. Firstly, we propose a
novel method, namely DBGD-NF, which employs the one-point gradient estimator
and utilizes all the available estimated gradients in each round to update the
decision. It achieves a better $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ regret
bound, which is relevant to the average delay $\bar{d} =
\frac{1}{T}\sum_{t=1}^T d_t\leq d$. Secondly, we extend DBGD-NF by employing a
blocking update mechanism to decouple the joint effect of the delays and bandit
feedback, which enjoys an $\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$ regret bound.
When $d = \mathcal{O}(T^{1/3})$, our regret bound matches the
$\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.
Compared to our first $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ bound, it is more
advantageous when the maximum delay $d = o(\bar{d}^{2/3}T^{1/3})$. Finally, we
conduct experiments on structured sparse learning to demonstrate the
superiority of our methods.

</details>


### [129] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
*Judy X Yang*

Main category: cs.LG

TL;DR: 提出了一种两阶段框架，用于增强Cuprite矿区矿物检测，通过SNR阈值和Savitzky-Golay滤波降噪，再结合KMeans和NNLS提高解混精度。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱成像中弱矿物信号被噪声和冗余波段掩盖的问题。

Method: 两阶段方法：1. SNR阈值和Savitzky-Golay滤波降噪；2. KMeans聚类和NNLS解混。

Result: 实验表明，该方法提高了弱矿物区域的检测精度和解混准确性。

Conclusion: 两阶段策略为地质高光谱应用提供了实用且可重复的解决方案。

Abstract: Hyperspectral imaging offers detailed spectral information for mineral
mapping; however, weak mineral signatures are often masked by noisy and
redundant bands, limiting detection performance. To address this, we propose a
two-stage integrated framework for enhanced mineral detection in the Cuprite
mining district. In the first stage, we compute the signal-to-noise ratio (SNR)
for each spectral band and apply a phase-locked thresholding technique to
discard low-SNR bands, effectively removing redundancy and suppressing
background noise. Savitzky-Golay filtering is then employed for spectral
smoothing, serving a dual role first to stabilize trends during band selection,
and second to preserve fine-grained spectral features during preprocessing. In
the second stage, the refined HSI data is reintroduced into the model, where
KMeans clustering is used to extract 12 endmember spectra (W1 custom), followed
by non negative least squares (NNLS) for abundance unmixing. The resulting
endmembers are quantitatively compared with laboratory spectra (W1 raw) using
cosine similarity and RMSE metrics. Experimental results confirm that our
proposed pipeline improves unmixing accuracy and enhances the detection of weak
mineral zones. This two-pass strategy demonstrates a practical and reproducible
solution for spectral dimensionality reduction and unmixing in geological HSI
applications.

</details>


### [130] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
*Marlen Neubert,Patrick Reiser,Frauke Gräter,Pascal Friederich*

Main category: cs.LG

TL;DR: 论文探讨了氢原子转移（HAT）反应的机制，提出了一种基于机器学习的方法，通过生成大量数据并比较不同神经网络架构，最终选择MACE模型进行高精度模拟。


<details>
  <summary>Details</summary>
Motivation: HAT反应在生物过程中至关重要，但其机制尚不完全清楚。传统方法难以在生物尺度上实现量子化学精度，机器学习提供了一种替代方案。

Method: 通过半经验方法和DFT生成HAT配置数据集，并比较三种图神经网络架构（SchNet、Allegro和MACE）的性能。

Result: MACE在能量、力和反应势垒预测上表现最佳，平均绝对误差为1.13 kcal/mol，适用于大规模胶原蛋白模拟。

Conclusion: 该方法可推广至其他生物分子系统，为复杂环境中的化学反应提供量子级精度的模拟。

Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.

</details>


### [131] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
*Thorben Werner,Lars Schmidt-Thieme,Vijaya Krishna Yalavarthi*

Main category: cs.LG

TL;DR: 本文研究了在低数据场景下，数据增强（DA）、半监督学习（SSL）和主动学习（AL）的效果，发现AL效率最低，但结合DA和SSL后仍能提升性能。


<details>
  <summary>Details</summary>
Motivation: 探讨AL在实际应用中未被广泛使用的原因，并研究如何通过DA和SSL提升低数据场景下的性能。

Method: 比较DA、SSL和AL在低数据场景下的效果，并分析其组合效果。

Result: AL单独效果较差（提升1-4%），但结合DA和SSL后仍有提升空间。DA和SSL组合可提升60%。

Conclusion: AL应作为DA和SSL后的补充手段，而非主要解决方案。

Abstract: Even though Active Learning (AL) is widely studied, it is rarely applied in
contexts outside its own scientific literature. We posit that the reason for
this is AL's high computational cost coupled with the comparatively small lifts
it is typically able to generate in scenarios with few labeled points. In this
work we study the impact of different methods to combat this low data scenario,
namely data augmentation (DA), semi-supervised learning (SSL) and AL. We find
that AL is by far the least efficient method of solving the low data problem,
generating a lift of only 1-4\% over random sampling, while DA and SSL methods
can generate up to 60\% lift in combination with random sampling. However, when
AL is combined with strong DA and SSL techniques, it surprisingly is still able
to provide improvements. Based on these results, we frame AL not as a method to
combat missing labels, but as the final building block to squeeze the last bits
of performance out of data after appropriate DA and SSL methods as been
applied.

</details>


### [132] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
*Mukesh Kumar Sahu,Pinki Roy*

Main category: cs.LG

TL;DR: 提出了一种基于相似性的自建图模型（SBSCGM）和混合图神经网络（HybridGraphMedGNN），用于预测ICU患者的死亡风险和关键性评分，性能优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统模型难以利用电子健康记录（EHR）中的关系结构，且孤立处理患者数据，无法动态捕捉患者间的相似性。

Method: SBSCGM通过混合相似性度量动态构建患者相似图，HybridGraphMedGNN结合GCN、GraphSAGE和GAT层学习患者表示。

Result: 在MIMIC-III数据集上，模型AUC-ROC达到0.94，优于基线模型和单一GNN模型，并提供可解释性。

Conclusion: 该框架为ICU风险预测提供了可扩展且可解释的解决方案，有望支持临床决策。

Abstract: Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.

</details>


### [133] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
*Paul Tresson,Pierre Le Coz,Hadrien Tulet,Anthony Malkassian,Maxime Réjou Méchain*

Main category: cs.LG

TL;DR: IAMAP是一个用户友好的QGIS插件，旨在解决深度学习在遥感应用中的三大挑战：大数据需求、高计算资源和强编码能力。它利用自监督学习策略，为非AI专家提供高效、节能的深度学习工具。


<details>
  <summary>Details</summary>
Motivation: 深度学习在遥感领域的应用受限于大数据需求、高计算资源和编码能力，限制了非专家的使用。IAMAP旨在通过简化流程和降低技术门槛，推动深度学习的普及。

Method: IAMAP基于自监督学习的预训练模型（基础模型），提供特征提取、降维、聚类、相似性映射和模型验证等功能，无需GPU或大量标注数据。

Result: IAMAP为非专家提供了高效、节能的深度学习工具，支持零样本或少样本场景，简化了遥感图像分析流程。

Conclusion: IAMAP通过降低技术门槛和资源需求，推动了深度学习在遥感领域的民主化应用。

Abstract: Remote sensing has entered a new era with the rapid development of artificial
intelligence approaches. However, the implementation of deep learning has
largely remained restricted to specialists and has been impractical because it
often requires (i) large reference datasets for model training and validation;
(ii) substantial computing resources; and (iii) strong coding skills. Here, we
introduce IAMAP, a user-friendly QGIS plugin that addresses these three
challenges in an easy yet flexible way. IAMAP builds on recent advancements in
self-supervised learning strategies, which now provide robust feature
extractors, often referred to as foundation models. These generalist models can
often be reliably used in few-shot or zero-shot scenarios (i.e., with little to
no fine-tuning). IAMAP's interface allows users to streamline several key steps
in remote sensing image analysis: (i) extracting image features using a wide
range of deep learning architectures; (ii) reducing dimensionality with
built-in algorithms; (iii) performing clustering on features or their reduced
representations; (iv) generating feature similarity maps; and (v) calibrating
and validating supervised machine learning models for prediction. By enabling
non-AI specialists to leverage the high-quality features provided by recent
deep learning approaches without requiring GPU capacity or extensive reference
datasets, IAMAP contributes to the democratization of computationally efficient
and energy-conscious deep learning methods.

</details>


### [134] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
*Xiong Xiong,Zhuo Zhang,Rongchun Hu,Chen Gao,Zichen Deng*

Main category: cs.LG

TL;DR: SV-SNN是一种新型神经网络框架，通过分离变量和自适应谱方法解决高频振荡PDE问题，显著提升精度并减少参数和训练时间。


<details>
  <summary>Details</summary>
Motivation: 传统PINN存在谱偏差问题，难以捕捉高频解成分，限制了在高频振荡PDE中的应用。

Method: SV-SNN结合变量分离和自适应谱方法，包括分解多元函数为单变量乘积、自适应傅里叶谱特征和基于SVD的理论框架。

Result: 在多个基准问题上，SV-SNN精度提升1-3个数量级，参数减少90%以上，训练时间减少60%。

Conclusion: SV-SNN有效解决了神经PDE求解中的谱偏差问题，具有显著优势。

Abstract: Solving high-frequency oscillatory partial differential equations (PDEs) is a
critical challenge in scientific computing, with applications in fluid
mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional
physics-informed neural networks (PINNs) suffer from spectral bias, limiting
their ability to capture high-frequency solution components. We introduce
Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that
addresses these limitations by integrating separation of variables with
adaptive spectral methods. Our approach features three key innovations: (1)
decomposition of multivariate functions into univariate function products,
enabling independent spatial and temporal networks; (2) adaptive Fourier
spectral features with learnable frequency parameters for high-frequency
capture; and (3) theoretical framework based on singular value decomposition to
quantify spectral bias. Comprehensive evaluation on benchmark problems
including Heat equation, Helmholtz equation, Poisson equations and
Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of
magnitude improvement in accuracy while reducing parameter count by over 90\%
and training time by 60\%. These results establish SV-SNN as an effective
solution to the spectral bias problem in neural PDE solving. The implementation
will be made publicly available upon acceptance at
https://github.com/xgxgnpu/SV-SNN.

</details>


### [135] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
*Changning Wu,Gao Wu,Rongyao Cai,Yong Liu,Kexin Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于KAN的自适应频率选择学习架构（KFS），通过频域能量分布选择主导频率，解决多尺度时间序列预测中的噪声干扰和异质信息分布问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列在不同尺度上存在噪声干扰和异质信息分布，导致多尺度表示不理想。

Method: 结合Kolmogorov-Arnold Networks（KAN）和Parseval定理，设计了KFS架构，包括FreK模块（频域主导频率选择）、时间戳嵌入对齐和特征混合模块。

Result: 在多个真实时间序列数据集上，KFS表现出最先进的性能。

Conclusion: KFS是一种简单而有效的架构，能够解决多尺度时间序列预测中的噪声干扰和复杂模式建模问题。

Abstract: Multi-scale decomposition architectures have emerged as predominant
methodologies in time series forecasting. However, real-world time series
exhibit noise interference across different scales, while heterogeneous
information distribution among frequency components at varying scales leads to
suboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks
(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency
Selection learning architecture (KFS) to address these challenges. This
framework tackles prediction challenges stemming from cross-scale noise
interference and complex pattern modeling through its FreK module, which
performs energy-distribution-based dominant frequency selection in the spectral
domain. Simultaneously, KAN enables sophisticated pattern representation while
timestamp embedding alignment synchronizes temporal representations across
scales. The feature mixing module then fuses scale-specific patterns with
aligned temporal features. Extensive experiments across multiple real-world
time series datasets demonstrate that KT achieves state-of-the-art performance
as a simple yet effective architecture.

</details>


### [136] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
*Alessandro Palmas*

Main category: cs.LG

TL;DR: 论文研究了低成本自杀式无人机群对现代防御系统的威胁，提出了一种基于强化学习的决策方法，通过高保真模拟环境优化拦截优先级，显著降低了平均损害并提高了防御效率。


<details>
  <summary>Details</summary>
Motivation: 低成本自杀式无人机群的威胁日益增长，需要快速且战略性的决策来优化拦截优先级，传统方法难以应对这一挑战。

Method: 采用强化学习在高保真模拟环境中训练决策代理，代理基于状态特征（如位置、类别和效应器状态）选择拦截目标。

Result: 强化学习策略在数百次模拟攻击场景中表现优于手工规则基线，平均损害更低，防御效率更高。

Conclusion: 研究表明强化学习可作为防御架构的战略层，提升系统韧性，同时兼容现有控制系统。

Abstract: The growing threat of low-cost kamikaze drone swarms poses a critical
challenge to modern defense systems demanding rapid and strategic
decision-making to prioritize interceptions across multiple effectors and
high-value target zones. In this work, we present a case study demonstrating
the practical advantages of reinforcement learning in addressing this
challenge. We introduce a high-fidelity simulation environment that captures
realistic operational constraints, within which a decision-level reinforcement
learning agent learns to coordinate multiple effectors for optimal interception
prioritization. Operating in a discrete action space, the agent selects which
drone to engage per effector based on observed state features such as
positions, classes, and effector status. We evaluate the learned policy against
a handcrafted rule-based baseline across hundreds of simulated attack
scenarios. The reinforcement learning based policy consistently achieves lower
average damage and higher defensive efficiency in protecting critical zones.
This case study highlights the potential of reinforcement learning as a
strategic layer within defense architectures, enhancing resilience without
displacing existing control systems. All code and simulation assets are
publicly released for full reproducibility, and a video demonstration
illustrates the policy's qualitative behavior.

</details>


### [137] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
*Albert Matveev,Sanmitra Ghosh,Aamal Hussain,James-Michael Leahy,Michalis Michaelides*

Main category: cs.LG

TL;DR: DINOZAUR是一种基于扩散的神经算子参数化方法，解决了FNO的过参数化和不确定性量化问题，性能优越且高效。


<details>
  <summary>Details</summary>
Motivation: FNO存在可扩展性挑战和缺乏原生不确定性量化，限制了其在科学和工程应用中的可靠性。

Method: DINOZAUR用维度无关的扩散乘子替代FNO中的密集张量乘子，并通过贝叶斯方法定义时间参数的先验，实现不确定性量化。

Result: 在多个PDE基准测试中表现优异，同时提供高效的不确定性量化。

Conclusion: DINOZAUR在减少参数和内存占用的同时，保持了预测性能，并提供了可靠的不确定性估计。

Abstract: Operator learning is a powerful paradigm for solving partial differential
equations, with Fourier Neural Operators serving as a widely adopted
foundation. However, FNOs face significant scalability challenges due to
overparameterization and offer no native uncertainty quantification -- a key
requirement for reliable scientific and engineering applications. Instead,
neural operators rely on post hoc UQ methods that ignore geometric inductive
biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator
parametrization with uncertainty quantification. Inspired by the structure of
the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a
dimensionality-independent diffusion multiplier that has a single learnable
time parameter per channel, drastically reducing parameter count and memory
footprint without compromising predictive performance. By defining priors over
those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield
spatially correlated outputs and calibrated uncertainty estimates. Our method
achieves competitive or superior performance across several PDE benchmarks
while providing efficient uncertainty quantification.

</details>


### [138] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
*Sihang Zeng,Lucas Jing Liu,Jun Wen,Meliha Yetisgen,Ruth Etzioni,Gang Luo*

Main category: cs.LG

TL;DR: TrajSurv利用神经控制微分方程从纵向电子健康记录中学习连续潜在轨迹，通过对比学习对齐潜在状态与患者状态，并通过两步解释过程透明地关联临床进展与生存结果。


<details>
  <summary>Details</summary>
Motivation: 解决纵向电子健康记录中不规则采样数据的连续临床进展建模问题，并透明地将其与生存结果关联。

Method: 使用神经控制微分方程（NCDE）提取连续时间潜在状态，通过时间感知对比学习对齐潜在状态空间，并采用两步解释过程（向量场和聚类）关联临床进展与生存结果。

Result: 在MIMIC-III和eICU数据集上，TrajSurv表现出竞争性准确性和优于现有深度学习的透明度。

Conclusion: TrajSurv为临床决策提供了可信赖的生存预测，具有高准确性和透明度。

Abstract: Trustworthy survival prediction is essential for clinical decision making.
Longitudinal electronic health records (EHRs) provide a uniquely powerful
opportunity for the prediction. However, it is challenging to accurately model
the continuous clinical progression of patients underlying the irregularly
sampled clinical features and to transparently link the progression to survival
outcomes. To address these challenges, we develop TrajSurv, a model that learns
continuous latent trajectories from longitudinal EHR data for trustworthy
survival prediction. TrajSurv employs a neural controlled differential equation
(NCDE) to extract continuous-time latent states from the irregularly sampled
data, forming continuous latent trajectories. To ensure the latent trajectories
reflect the clinical progression, TrajSurv aligns the latent state space with
patient state space through a time-aware contrastive learning approach. To
transparently link clinical progression to the survival outcome, TrajSurv uses
latent trajectories in a two-step divide-and-conquer interpretation process.
First, it explains how the changes in clinical features translate into the
latent trajectory's evolution using a learned vector field. Second, it clusters
these latent trajectories to identify key clinical progression patterns
associated with different survival outcomes. Evaluations on two real-world
medical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and
superior transparency over existing deep learning methods.

</details>


### [139] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
*Jialun Zheng,Jie Liu,Jiannong Cao,Xiao Wang,Hanchen Yang,Yankai Chen,Philip S. Yu*

Main category: cs.LG

TL;DR: 提出了一种动态原型（DP）的动态图异常检测（DGAD）模型，用于捕捉跨域和域内演化的异常模式，并在多个真实数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有通用图异常检测（GAD）模型在静态图上表现良好，但在动态图上难以捕捉演化的异常模式，且新领域缺乏标记数据。

Method: 通过动态原型提取演化的正常和异常模式，存储在内存缓冲区中，并选择性更新；使用异常评分器比较新数据与原型，结合置信度伪标记进行自监督适应。

Result: 在十个不同领域的真实数据集上实现了最先进的性能。

Conclusion: DP-DGAD能有效捕捉动态图中的跨域和域内异常模式，适用于新领域且无需大量标记数据。

Abstract: Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.

</details>


### [140] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 比较多种AI模型（传统机器学习和深度学习）在分类临床笔记为焦虑和适应障碍诊断中的表现，发现超参数调优显著提升模型性能，而过采样技术影响有限。


<details>
  <summary>Details</summary>
Motivation: 研究AI模型在心理健康诊断中的分类性能，以支持临床决策。

Method: 比较多种机器学习（如随机森林、XGBoost）和深度学习模型（如DistilBERT、SciBERT），并评估过采样技术和超参数调优的效果。

Result: 超参数调优显著提升模型性能，过采样技术仅对BERT模型有轻微正面影响。决策树和XGBoost在机器学习中表现最佳（96%准确率），DistilBERT和SciBERT在深度学习中同样达到96%。

Conclusion: 超参数调优对模型性能至关重要，为AI辅助心理健康诊断提供了实用指导。

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


### [141] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
*Haozhe Tian,Pietro Ferraro,Robert Shorten,Mahdi Jalili,Homayoun Hamedmoghadam*

Main category: cs.LG

TL;DR: 论文提出了一种无需手工特征的消息传递图神经网络框架MIND，用于解决NP难的网络拆解问题，并在大规模真实网络上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖手工特征，增加了计算成本并引入偏差，因此需要一种更高效、更通用的方法。

Method: 引入注意力机制和消息迭代配置文件，利用合成网络生成多样化训练集，构建消息传递框架。

Result: MIND模型在大型真实网络上表现优于现有方法，具有高效性和泛化能力。

Conclusion: MIND不仅适用于网络拆解问题，还可推广到其他复杂网络问题。

Abstract: The application of message-passing Graph Neural Networks has been a
breakthrough for important network science problems. However, the competitive
performance often relies on using handcrafted structural features as inputs,
which increases computational cost and introduces bias into the otherwise
purely data-driven network representations. Here, we eliminate the need for
handcrafted features by introducing an attention mechanism and utilizing
message-iteration profiles, in addition to an effective algorithmic approach to
generate a structurally diverse training set of small synthetic networks.
Thereby, we build an expressive message-passing framework and use it to
efficiently solve the NP-hard problem of Network Dismantling, virtually
equivalent to vital node identification, with significant real-world
applications. Trained solely on diversified synthetic networks, our proposed
model -- MIND: Message Iteration Network Dismantler -- generalizes to large,
unseen real networks with millions of nodes, outperforming state-of-the-art
network dismantling methods. Increased efficiency and generalizability of the
proposed model can be leveraged beyond dismantling in a range of complex
network problems.

</details>


### [142] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
*Yannik Schnitzer,Alessandro Abate,David Parker*

Main category: cs.LG

TL;DR: 论文提出了一种基于分解状态空间表示的方法，用于解决和学习鲁棒马尔可夫决策过程（r-MDPs），提高了样本效率并生成更有效的鲁棒策略。


<details>
  <summary>Details</summary>
Motivation: 传统的r-MDPs学习方法需要大量样本交互，而分解状态空间表示可以更好地利用系统组件之间的独立性，从而提高效率。

Method: 通过将非凸优化问题重新表述为可处理的线性规划问题，并直接学习分解模型表示。

Result: 实验结果表明，利用分解结构可以在样本效率上实现维度增益，生成比现有方法更有效的鲁棒策略和更严格的性能保证。

Conclusion: 分解状态空间表示是解决和学习r-MDPs的有效方法，显著提升了样本效率和策略性能。

Abstract: Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling
epistemic uncertainty about transition dynamics. Learning r-MDPs from
interactions with an unknown environment enables the synthesis of robust
policies with provable (PAC) guarantees on performance, but this can require a
large number of sample interactions. We propose novel methods for solving and
learning r-MDPs based on factored state-space representations that leverage the
independence between model uncertainty across system components. Although
policy synthesis for factored r-MDPs leads to hard, non-convex optimisation
problems, we show how to reformulate these into tractable linear programs.
Building on these, we also propose methods to learn factored model
representations directly. Our experimental results show that exploiting
factored structure can yield dimensional gains in sample efficiency, producing
more effective robust policies with tighter performance guarantees than
state-of-the-art methods.

</details>


### [143] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
*Dien Nguyen,Diego Perez-Liebana,Simon Lucas*

Main category: cs.LG

TL;DR: JSON-Bag模型通过JSON描述的游戏轨迹进行通用表示，使用Jensen-Shannon距离作为度量标准，在多个游戏任务中表现优于手工特征基线，并展示了样本高效性和自动特征提取能力。


<details>
  <summary>Details</summary>
Motivation: 提出一种通用方法来表示和分类游戏轨迹，避免手工特征设计的局限性。

Method: 使用JSON-Bag模型对游戏轨迹进行令牌化，并应用Jensen-Shannon距离和原型最近邻搜索进行评估。

Result: 在多数任务中优于手工特征基线，且样本高效，自动特征提取显著提升低效任务准确率。

Conclusion: JSON-Bag模型是一种有效的通用游戏轨迹表示方法，且与代理策略距离高度相关。

Abstract: We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically
represent game trajectories by tokenizing their JSON descriptions and apply
Jensen-Shannon distance (JSD) as distance metric for them. Using a
prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of
JSON-Bag with JSD on six tabletop games -- \textit{7 Wonders},
\textit{Dominion}, \textit{Sea Salt and Paper}, \textit{Can't Stop},
\textit{Connect4}, \textit{Dots and boxes} -- each over three game trajectory
classification tasks: classifying the playing agents, game parameters, or game
seeds that were used to generate the trajectories.
  Our approach outperforms a baseline using hand-crafted features in the
majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag
prototype to represent game trajectory classes is also sample efficient.
Additionally, we demonstrate JSON-Bag ability for automatic feature extraction
by treating tokens as individual features to be used in Random Forest to solve
the tasks above, which significantly improves accuracy on underperforming
tasks. Finally, we show that, across all six games, the JSD between JSON-Bag
prototypes of agent classes highly correlates with the distances between
agents' policies.

</details>


### [144] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
*Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu*

Main category: cs.LG

TL;DR: NeGPR是一种针对带噪声标签的图级域自适应框架，通过双分支预训练和嵌套伪标签细化机制，显著提升域自适应性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中源标签常含噪声，影响图域自适应性能，需解决噪声标签下的特征对齐问题。

Method: NeGPR通过双分支（语义和拓扑）预训练减少噪声影响，嵌套细化机制实现跨域学习，并引入噪声感知正则化。

Result: 在严重标签噪声下，NeGPR性能优于现有方法，准确率提升高达12.7%。

Conclusion: NeGPR有效解决了噪声标签下的图域自适应问题，具有鲁棒性和实用性。

Abstract: Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.

</details>


### [145] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
*Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko*

Main category: cs.LG

TL;DR: MOSTLY AI SDK是一个开源工具包，用于生成高质量的合成表格数据，解决数据隐私和访问问题。


<details>
  <summary>Details</summary>
Motivation: 由于隐私、专有利益和伦理问题，高质量数据的访问受限，合成数据成为解决方案。

Method: 基于TabularARGN自回归框架，集成差分隐私、公平性生成和自动化质量保证。

Result: SDK在速度和可用性上表现优异，支持多种数据类型和复杂数据集。

Conclusion: SDK实用性强，已快速部署，促进数据民主化。

Abstract: Machine learning development critically depends on access to high-quality
data. However, increasing restrictions due to privacy, proprietary interests,
and ethical concerns have created significant barriers to data accessibility.
Synthetic data offers a viable solution by enabling safe, broad data usage
without compromising sensitive information. This paper presents the MOSTLY AI
Synthetic Data Software Development Kit (SDK), an open-source toolkit designed
specifically for synthesizing high-quality tabular data. The SDK integrates
robust features such as differential privacy guarantees, fairness-aware data
generation, and automated quality assurance into a flexible and accessible
Python interface. Leveraging the TabularARGN autoregressive framework, the SDK
supports diverse data types and complex multi-table and sequential datasets,
delivering competitive performance with notable improvements in speed and
usability. Currently deployed both as a cloud service and locally installable
software, the SDK has seen rapid adoption, highlighting its practicality in
addressing real-world data bottlenecks and promoting widespread data
democratization.

</details>


### [146] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 提出了一种基于多保真度分层采样和自适应机器学习元模型的方法，用于高效估计小失效概率，显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂非线性有限元模型中计算小失效概率时仍需要大量模型评估，计算成本高。

Method: 结合分层采样生成高保真数据集训练深度学习元模型，作为低保真模型，并通过自适应训练平衡精度与计算需求。

Result: 应用于高层钢结构建筑，能准确估计非线性响应的超越概率曲线，计算成本显著降低。

Conclusion: 该方法在多保真度框架下有效估计小失效概率，计算效率优于单保真度方法。

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


### [147] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
*Yaxin Ma,Benjamin Colburn,Jose C. Principe*

Main category: cs.LG

TL;DR: 提出一种基于特征空间密度的单确定性模型方法，用于量化分布偏移和OOD检测，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯神经网络和深度集成方法计算和存储成本高，需更高效的不确定性量化方法。

Method: 利用核密度估计的信息势场近似训练集特征空间密度，通过比较测试样本特征判断分布偏移。

Result: 在2D合成数据集和OOD检测任务中表现优于基线模型。

Conclusion: 单确定性模型方法能高效量化不确定性，适用于分布偏移和OOD检测。

Abstract: Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.

</details>


### [148] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: 提出了一种结合扩散模型和去噪自编码器的新框架DDAE，用于表格数据异常检测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 表格数据异常检测面临特征交互复杂和异常样本稀缺的挑战，现有方法如去噪自编码器和扩散模型各有局限。

Method: DDAE整合了扩散模型的噪声调度和对比学习，改进了编码过程。

Result: 在57个数据集上测试，DDAE在半监督和无监督设置中表现优异，PR-AUC和ROC-AUC显著提升。

Conclusion: 噪声策略对表格异常检测至关重要，不同噪声水平适用于不同训练设置。

Abstract: Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.

</details>


### [149] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
*Antonio Tudisco,Andrea Marchesin,Maurizio Zamboni,Mariagrazia Graziano,Giovanna Turvani*

Main category: cs.LG

TL;DR: 该论文研究了量子机器学习中变分量子电路（VQC）的性能差异，比较了振幅编码和角度编码模型在不同旋转门下的分类表现。


<details>
  <summary>Details</summary>
Motivation: 量子计算和机器学习的结合引发了量子机器学习（QML）的关注，其中变分量子电路（VQC）是一种常用模型。研究旨在探索不同编码方式和旋转门对模型性能的影响。

Method: 通过振幅编码和角度编码两种模型，结合不同旋转门，在Wine和Diabetes数据集上训练并评估分类性能。

Result: 在相同拓扑结构下，最佳和最差模型的准确率差异为10%至30%，最大可达41%。旋转门的选择显著影响分类性能。

Conclusion: 编码方式是VQC模型的重要超参数，旋转门的选择对模型性能有显著影响。

Abstract: Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.

</details>


### [150] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
*Bushra Akter,Md Biplob Hosen,Sabbir Ahmed,Mehrin Anannya,Md. Farhad Hossain*

Main category: cs.LG

TL;DR: 研究探讨了影响学生CGPA的多变量因素，通过文献综述和在线调查构建因果图，利用回归和分类模型分析数据，开发了基于Web的应用帮助学生优化学术表现。


<details>
  <summary>Details</summary>
Motivation: 学术表现受多种因素影响，研究旨在识别这些因素并开发策略优化学生CGPA。

Method: 通过文献综述构建因果图，进行在线调查收集数据，使用回归和分类模型分析，并开发Web应用。

Result: Ridge回归预测准确（MAE=0.12，MSE=0.023），随机森林分类表现优异（F1-score接近完美，准确率98.68%）。

Conclusion: 研究成功识别关键因素并开发工具帮助学生提升学术表现。

Abstract: Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.

</details>


### [151] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
*Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo*

Main category: cs.LG

TL;DR: Adacc是一个结合自适应压缩和激活检查点的内存管理框架，旨在减少GPU内存占用并加速大型语言模型训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练中，内存重计算会带来高达30%的开销，影响效率。

Method: Adacc包含三个模块：层特定压缩算法、基于MILP的最优调度策略和自适应策略演化机制。

Result: 实验显示，Adacc比现有框架加速1.01x至1.37x，同时保持模型精度。

Conclusion: Adacc有效降低了内存占用并提升了训练效率，适用于大型语言模型训练。

Abstract: Training large language models often employs recomputation to alleviate
memory pressure, which can introduce up to 30% overhead in real-world
scenarios. In this paper, we propose Adacc, a novel memory management framework
that combines adaptive compression and activation checkpointing to reduce the
GPU memory footprint. It comprises three modules: (1) We design layer-specific
compression algorithms that account for outliers in LLM tensors, instead of
directly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We
propose an optimal scheduling policy that employs MILP to determine the best
memory optimization for each tensor. (3) To accommodate changes in training
tensors, we introduce an adaptive policy evolution mechanism that adjusts the
policy during training to enhance throughput. Experimental results show that
Adacc can accelerate the LLM training by 1.01x to 1.37x compared to
state-of-the-art frameworks, while maintaining comparable model accuracy to the
Baseline.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [152] [Strategic Communication and Language Bias in Multi-Agent LLM Coordination](https://arxiv.org/abs/2508.00032)
*Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.MA

TL;DR: 研究探讨了在多智能体场景中，允许智能体沟通是否会放大语言对合作行为的影响。实验表明，沟通显著影响行为，但其效果因语言、个性和游戏结构而异。


<details>
  <summary>Details</summary>
Motivation: 在多智能体场景中，协调至关重要，但语言框架可能影响合作行为。研究旨在探索沟通是否会放大这种语言驱动效应。

Method: 利用FAIRGAME框架，模拟一次性及重复游戏，比较不同语言和模型（GPT-4o和Llama 4 Maverick）在有/无沟通条件下的行为。

Result: 沟通显著影响智能体行为，但效果因语言、个性和游戏结构而异，表明沟通既能促进协调，也可能强化偏见。

Conclusion: 沟通在多智能体协调中具有双重作用，既能促进合作，也可能加剧语言和个性带来的偏见。

Abstract: Large Language Model (LLM)-based agents are increasingly deployed in
multi-agent scenarios where coordination is crucial but not always assured.
Previous studies indicate that the language used to frame strategic scenarios
can influence cooperative behavior. This paper explores whether allowing agents
to communicate amplifies these language-driven effects. Leveraging the FAIRGAME
framework, we simulate one-shot and repeated games across different languages
and models, both with and without communication. Our experiments, conducted
with two advanced LLMs, GPT-4o and Llama 4 Maverick, reveal that communication
significantly influences agent behavior, though its impact varies by language,
personality, and game structure. These findings underscore the dual role of
communication in fostering coordination and reinforcing biases.

</details>


### [153] [WMAS: A Multi-Agent System Towards Intelligent and Customized Wireless Networks](https://arxiv.org/abs/2508.00280)
*Jingchen Peng,Dingli Yuan,Boxiang Ren,Jie Fan,Hao Wu,Lu Yang*

Main category: cs.MA

TL;DR: 提出了一种无线多智能体系统（WMAS），通过有向无环图建模和强化学习优化，实现高效协作处理用户任务。


<details>
  <summary>Details</summary>
Motivation: AI智能体的快速发展为智能化和定制化无线网络提供了可能，但多智能体协作存在故障和无限循环风险。

Method: 将有向无环图建模为多智能体对话拓扑，并使用强化学习优化其邻接矩阵。

Result: 仿真显示WMAS在任务性能和对话开销上优于现有系统。

Conclusion: WMAS能提升未来无线网络的智能化潜力。

Abstract: The fast development of Artificial Intelligence (AI) agents provides a
promising way for the realization of intelligent and customized wireless
networks. In this paper, we propose a Wireless Multi-Agent System (WMAS), which
can provide intelligent and customized services for different user equipment
(UEs). Note that orchestrating multiple agents carries the risk of malfunction,
and multi-agent conversations may fall into infinite loops. It is thus crucial
to design a conversation topology for WMAS that enables agents to complete UE
task requests with high accuracy and low conversation overhead. To address this
issue, we model the multi-agent conversation topology as a directed acyclic
graph and propose a reinforcement learning-based algorithm to optimize the
adjacency matrix of this graph. As such, WMAS is capable of generating and
self-optimizing multi-agent conversation topologies, enabling agents to
effectively and collaboratively handle a variety of task requests from UEs.
Simulation results across various task types demonstrate that WMAS can achieve
higher task performance and lower conversation overhead compared to existing
multi-agent systems. These results validate the potential of WMAS to enhance
the intelligence of future wireless networks.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [154] [Occlusion-robust Stylization for Drawing-based 3D Animation](https://arxiv.org/abs/2508.00398)
*Sunjae Yoon,Gwanhyeong Koo,Younghwan Lee,Ji Woo Hong,Chang D. Yoo*

Main category: cs.GR

TL;DR: 论文提出了一种用于基于绘图的3D动画的遮挡鲁棒风格化框架（OSF），解决了现有方法在遮挡情况下风格质量下降的问题。


<details>
  <summary>Details</summary>
Motivation: 基于绘图的3D动画需要保留艺术家的独特风格（如粗糙轮廓和笔画模式），但现有方法在遮挡情况下会导致风格质量下降（如轮廓闪烁和笔画模糊）。

Method: 提出OSF框架，利用光流提供遮挡鲁棒的边缘引导，确保风格一致性，同时采用单阶段方法提升效率。

Result: OSF在遮挡情况下保持风格一致性，推理速度提升2.4倍，内存减少2.1倍。

Conclusion: OSF有效解决了风格化网络在遮挡情况下的性能下降问题，并显著提升了效率。

Abstract: 3D animation aims to generate a 3D animated video from an input image and a
target 3D motion sequence. Recent advances in image-to-3D models enable the
creation of animations directly from user-hand drawings. Distinguished from
conventional 3D animation, drawing-based 3D animation is crucial to preserve
artist's unique style properties, such as rough contours and distinct stroke
patterns. However, recent methods still exhibit quality deterioration in style
properties, especially under occlusions caused by overlapping body parts,
leading to contour flickering and stroke blurring. This occurs due to a
`stylization pose gap' between training and inference in stylization networks
designed to preserve drawing styles in drawing-based 3D animation systems. The
stylization pose gap denotes that input target poses used to train the
stylization network are always in occlusion-free poses, while target poses
encountered in an inference include diverse occlusions under dynamic motions.
To this end, we propose Occlusion-robust Stylization Framework (OSF) for
drawing-based 3D animation. We found that while employing object's edge can be
effective input prior for guiding stylization, it becomes notably inaccurate
when occlusions occur at inference. Thus, our proposed OSF provides
occlusion-robust edge guidance for stylization network using optical flow,
ensuring a consistent stylization even under occlusions. Furthermore, OSF
operates in a single run instead of the previous two-stage method, achieving
2.4x faster inference and 2.1x less memory.

</details>


### [155] [CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data](https://arxiv.org/abs/2508.00424)
*Kresimir Matkovic,Rainer Splechtna,Denis Gracanin,Helwig Hauser*

Main category: cs.GR

TL;DR: CrossSet是一种新颖的方法，用于联合研究两个集合类型维度及其相互作用，通过多尺度交互式可视化分析实现。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅支持单个集合类型维度的研究，而CrossSet旨在填补联合分析两个集合类型维度及其交互的空白。

Method: 采用分层矩阵布局联合可视化两个集合类型维度，支持从概览到细节的多尺度探索。

Result: CrossSet在多个应用场景中验证了其有效性和效率，能够详细分析单维度、维度间交互及具体元素关系。

Conclusion: CrossSet为集合类型数据的交互式可视化分析提供了高效的多尺度解决方案。

Abstract: The interactive visual analysis of set-typed data, i.e., data with attributes
that are of type set, is a rewarding area of research and applications.
Valuable prior work has contributed solutions that enable the study of such
data with individual set-typed dimensions. In this paper, we present CrossSet,
a novel method for the joint study of two set-typed dimensions and their
interplay. Based on a task analysis, we describe a new, multi-scale approach to
the interactive visual exploration and analysis of such data. Two set-typed
data dimensions are jointly visualized using a hierarchical matrix layout,
enabling the analysis of the interactions between two set-typed attributes at
several levels, in addition to the analysis of individual such dimensions.
CrossSet is anchored at a compact, large-scale overview that is complemented by
drill-down opportunities to study the relations between and within the
set-typed dimensions, enabling an interactive visual multi-scale exploration
and analysis of bivariate set-typed data. Such an interactive approach makes it
possible to study single set-typed dimensions in detail, to gain an overview of
the interaction and association between two such dimensions, to refine one of
the dimensions to gain additional details at several levels, and to drill down
to the specific interactions of individual set-elements from the set-typed
dimensions. To demonstrate the effectiveness and efficiency of CrossSet, we
have evaluated the new method in the context of several application scenarios.

</details>


### [156] [Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation](https://arxiv.org/abs/2508.00428)
*Nan Xiang,Tianyi Liang,Haiwen Huang,Shiqi Jiang,Hao Huang,Yifei Huang,Liangyu Chen,Changbo Wang,Chenhui Li*

Main category: cs.GR

TL;DR: Sel3DCraft是一个用于文本到3D生成的视觉提示工程系统，通过双分支结构、多视图评分和视觉分析套件提升生成效果。


<details>
  <summary>Details</summary>
Motivation: 解决文本到3D生成中盲目试错导致结果不可预测的问题，提升生成过程的效率和可控性。

Method: 采用双分支结构结合检索与生成，多视图混合评分方法，以及视觉分析套件。

Result: Sel3DCraft在测试和用户研究中表现优于其他系统，支持设计师的创造力。

Conclusion: Sel3DCraft通过视觉提示工程显著改善了文本到3D生成的效率和效果。

Abstract: Text-to-3D (T23D) generation has transformed digital content creation, yet
remains bottlenecked by blind trial-and-error prompting processes that yield
unpredictable results. While visual prompt engineering has advanced in
text-to-image domains, its application to 3D generation presents unique
challenges requiring multi-view consistency evaluation and spatial
understanding. We present Sel3DCraft, a visual prompt engineering system for
T23D that transforms unstructured exploration into a guided visual process. Our
approach introduces three key innovations: a dual-branch structure combining
retrieval and generation for diverse candidate exploration; a multi-view hybrid
scoring approach that leverages MLLMs with innovative high-level metrics to
assess 3D models with human-expert consistency; and a prompt-driven visual
analytics suite that enables intuitive defect identification and refinement.
Extensive testing and user studies demonstrate that Sel3DCraft surpasses other
T23D systems in supporting creativity for designers.

</details>


### [157] [SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation](https://arxiv.org/abs/2508.00782)
*Kien T. Pham,Yingqing He,Yazhou Xing,Qifeng Chen,Long Chen*

Main category: cs.GR

TL;DR: 论文提出SpA2V框架，利用音频中的空间听觉线索生成语义和空间对齐的视频，分为音频引导的视频规划和布局基础的视频生成两阶段。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注语义信息，忽略了声音的空间属性（如位置和运动方向），而人类能自然识别这些信息。SpA2V旨在填补这一空白。

Method: 1) 音频引导的视频规划：利用MLLM从音频中提取空间和语义线索，构建视频场景布局（VSL）；2) 布局基础的视频生成：将VSL作为条件输入预训练扩散模型，实现无训练的视频生成。

Result: 实验表明，SpA2V能生成与输入音频在语义和空间上高度对齐的逼真视频。

Conclusion: SpA2V通过利用空间听觉线索，显著提升了音频驱动视频生成的质量和准确性。

Abstract: Audio-driven video generation aims to synthesize realistic videos that align
with input audio recordings, akin to the human ability to visualize scenes from
auditory input. However, existing approaches predominantly focus on exploring
semantic information, such as the classes of sounding sources present in the
audio, limiting their ability to generate videos with accurate content and
spatial composition. In contrast, we humans can not only naturally identify the
semantic categories of sounding sources but also determine their deeply encoded
spatial attributes, including locations and movement directions. This useful
information can be elucidated by considering specific spatial indicators
derived from the inherent physical properties of sound, such as loudness or
frequency. As prior methods largely ignore this factor, we present SpA2V, the
first framework explicitly exploits these spatial auditory cues from audios to
generate videos with high semantic and spatial correspondence. SpA2V decomposes
the generation process into two stages: 1) Audio-guided Video Planning: We
meticulously adapt a state-of-the-art MLLM for a novel task of harnessing
spatial and semantic cues from input audio to construct Video Scene Layouts
(VSLs). This serves as an intermediate representation to bridge the gap between
the audio and video modalities. 2) Layout-grounded Video Generation: We develop
an efficient and effective approach to seamlessly integrate VSLs as conditional
guidance into pre-trained diffusion models, enabling VSL-grounded video
generation in a training-free manner. Extensive experiments demonstrate that
SpA2V excels in generating realistic videos with semantic and spatial alignment
to the input audios.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [158] [Advancing Speech Quality Assessment Through Scientific Challenges and Open-source Activities](https://arxiv.org/abs/2508.00317)
*Wen-Chin Huang*

Main category: cs.SD

TL;DR: 本文回顾了语音质量评估（SQA）的最新挑战和开源工具，强调了这些活动对推动SQA和语音生成AI发展的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的兴起，开发能反映人类感知的自动SQA方法变得至关重要。

Method: 回顾了近年来的挑战和开源实现，分析了其对SQA和语音生成AI的促进作用。

Result: 研究表明，开源活动和科学挑战推动了SQA领域的进步。

Conclusion: 维护这些活动对SQA和语音生成AI的发展至关重要。

Abstract: Speech quality assessment (SQA) refers to the evaluation of speech quality,
and developing an accurate automatic SQA method that reflects human perception
has become increasingly important, in order to keep up with the generative AI
boom. In recent years, SQA has progressed to a point that researchers started
to faithfully use automatic SQA in research papers as a rigorous measurement of
goodness for speech generation systems. We believe that the scientific
challenges and open-source activities of late have stimulated the growth in
this field. In this paper, we review recent challenges as well as open-source
implementations and toolkits for SQA, and highlight the importance of
maintaining such activities to facilitate the development of not only SQA
itself but also generative AI for speech.

</details>


### [159] [AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation](https://arxiv.org/abs/2508.00733)
*Le Wang,Jun Wang,Feng Deng,Chen Zhang,Kun Gai,Di Zhang*

Main category: cs.SD

TL;DR: AudioGen-Omni是一个基于多模态扩散变换器（MMDit）的统一方法，能够生成与输入视频同步的高保真音频、语音和歌曲。


<details>
  <summary>Details</summary>
Motivation: 解决多模态音频生成任务中的语义对齐和跨模态条件问题，提升生成质量和效率。

Method: 采用联合训练范式，结合大规模视频-文本-音频数据，使用统一的歌词-转录编码器和PAAPI增强的注意力机制。

Result: 在文本到音频/语音/歌曲任务中取得最佳性能，生成时间短（1.91秒生成8秒音频）。

Conclusion: AudioGen-Omni通过多模态联合训练和高效架构设计，显著提升了音频生成的质量和通用性。

Abstract: We present AudioGen-Omni - a unified approach based on multimodal diffusion
transformers (MMDit), capable of generating high-fidelity audio, speech, and
songs coherently synchronized with the input video. AudioGen-Omni introduces a
novel joint training paradigm that seamlessly integrates large-scale
video-text-audio corpora, enabling a model capable of generating semantically
rich, acoustically diverse audio conditioned on multimodal inputs and adaptable
to a wide range of audio generation tasks. AudioGen-Omni employs a unified
lyrics-transcription encoder that encodes graphemes and phonemes from both sung
and spoken inputs into dense frame-level representations. Dense frame-level
representations are fused using an AdaLN-based joint attention mechanism
enhanced with phase-aligned anisotropic positional infusion (PAAPI), wherein
RoPE is selectively applied to temporally structured modalities to ensure
precise and robust cross-modal alignment. By unfreezing all modalities and
masking missing inputs, AudioGen-Omni mitigates the semantic constraints of
text-frozen paradigms, enabling effective cross-modal conditioning. This joint
training approach enhances audio quality, semantic alignment, and lip-sync
accuracy, while also achieving state-of-the-art results on
Text-to-Audio/Speech/Song tasks. With an inference time of 1.91 seconds for 8
seconds of audio, it offers substantial improvements in both efficiency and
generality.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [160] [Computation of Approximately Stable Committees in Approval-based Elections](https://arxiv.org/abs/2508.00130)
*Drew Gao,Yihang Sun,Jan Vondrák*

Main category: cs.GT

TL;DR: 论文研究了基于批准的委员会选举模型中的近似稳定性问题，证明了3.65-近似稳定委员会的存在性及其算法计算。


<details>
  <summary>Details</summary>
Motivation: 研究委员会选举中如何更好地代表选民偏好，特别是通过近似稳定性这一标准。

Method: 基于Lindahl均衡和强瑞利分布的采样方法。

Result: 证明了3.65-近似稳定委员会的存在性，并提供了算法计算的方法。

Conclusion: 通过Lindahl均衡和强瑞利分布，成功解决了委员会选举中的近似稳定性问题。

Abstract: Approval-based committee selection is a model of significant interest in
social choice theory. In this model, we have a set of voters $\mathcal{V}$, a
set of candidates $\mathcal{C}$, and each voter has a set $A_v \subset
\mathcal{C}$ of approved candidates. For any committee size $K$, the goal is to
choose $K$ candidates to represent the voters' preferences. We study a
criterion known as \emph{approximate stability}, where a committee is
$\lambda$-approximately-stable if there is no other committee $T$ preferred by
at least $\frac{\lambda|T|}{k} |\mathcal{V}| $ voters. We prove that a
$3.65$-approximately stable committee always exists and can be computed
algorithmically in this setting. Our approach is based on finding a Lindahl
equilibrium and sampling from a strongly Rayleigh distribution associated with
it.

</details>


### [161] [On the Equivalence of the Graph-Structural and Optimization-Based Characterizations of Popular Matchings](https://arxiv.org/abs/2508.00349)
*Yuga Kanaya,Kenjiro Takazawa*

Main category: cs.GT

TL;DR: 本文研究了三种偏好匹配问题，通过图结构特征和优化特征的联系，揭示了它们之间的等价性。


<details>
  <summary>Details</summary>
Motivation: 研究偏好匹配问题中的Condorcet胜者模型，解决如何高效确定匹配的流行性问题。

Method: 通过图结构特征和最大权重匹配的优化特征，分析三种偏好匹配问题。

Result: 证明了两种特征之间的直接联系，揭示了它们的等价性及对偶最优解的新解释。

Conclusion: 本文通过统一两种特征，深化了对偏好匹配问题的理解，为算法设计提供了新视角。

Abstract: Popular matchings provide a model of matching under preferences in which a
solution corresponds to a Condorcet winner in voting systems. In a bipartite
graph in which the vertices have preferences over their neighbours, a matching
is defined to be popular if it does not lose in a majority vote against any
matching. In this paper, we study the following three primary problems: only
the vertices on one side have preferences; a generalization of this problem
allowing ties in the preferences; and the vertices on both sides have
preferences. A principal issue in the algorithmic aspects of popular matchings
is how to determine the popularity of a matching, because it requires
exponential time if the definition is simply applied. In the literature, we
have the following two types of characterizations: a graph-structural
characterization; and an optimization-based characterization described by
maximum-weight matchings. The graph-structural characterizations are
specifically designed for each problem and provide a combinatorial structure of
the popular matchings. The optimization-based characterizations work in the
same manner for all problems, while they do not reveal the structure of the
popular matchings. A main contribution of this paper is to provide a direct
connection of the above two types of characterizations for all of the three
problems. Specifically, we prove that each characterization can be derived from
the other, without relying on the fact that they characterize popular
matchings. Our proofs offer a comprehensive understanding of the equivalence of
the two types of characterizations, and suggest a new interpretation of the
graph-structural characterization in terms of the dual optimal solution for the
maximum-weight matching problem.

</details>


### [162] [Justified Representation: From Hare to Droop](https://arxiv.org/abs/2508.00811)
*Matthew M. Casey,Edith Elkind*

Main category: cs.GT

TL;DR: 本文系统研究了基于Droop配额的JR风格公理及其满足的投票规则，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 研究多赢家投票中比例代表性的公理，特别是基于Droop配额的JR风格公理，以扩展可满足的比例公理边界。

Method: 对每个标准JR公理（如JR、PJR、EJR等），识别或修改投票规则以满足其Droop版本，并进行实验验证。

Result: 发现Droop配额下的公理更难满足，但通过规则修改仍可实现，实验显示Droop JR/EJR+比标准版本更严格。

Conclusion: Droop配额下的JR风格公理扩展了比例代表性的理论边界，为多赢家投票提供了更严格的标准。

Abstract: The study of proportionality in multiwinner voting with approval ballots has
received much attention in recent years. Typically, proportionality is captured
by variants of the Justified Representation axiom, which say that cohesive
groups of at least $\ell\cdot\frac{n}{k}$ voters (where $n$ is the total number
of voters and $k$ is the desired number of winners) deserve $\ell$
representatives. The quantity $\frac{n}{k}$ is known as the Hare quota in the
social choice literature. Another -- more demanding -- choice of quota is the
Droop quota, defined as $\lfloor\frac{n}{k+1}\rfloor+1$. This quota is often
used in multiwinner voting with ranked ballots: in algorithms such as Single
Transferable Voting, and in proportionality axioms, such as Droop's
Proportionality Criterion. A few authors have considered it in the context of
approval ballots, but the existing analysis is far from comprehensive. The
contribution of our work is a systematic study of JR-style axioms (and voting
rules that satisfy them) defined using the Droop quota instead of the Hare
quota. For each of the standard JR axioms (namely, JR, PJR, EJR, FPJR, FJR,
PJR+ and EJR+), we identify a voting rule that satisfies the Droop version of
this axiom. In some cases, it suffices to consider known rules (modifying the
corresponding Hare proof, sometimes quite substantially), and in other cases it
is necessary to modify the rules from prior work. Each axiom is more difficult
to satisfy when defined using the Droop quota, so our results expand the
frontier of satisfiable proportionality axioms. We complement our theoretical
results with an experimental study, showing that for many probabilistic models
of voter approvals, Droop JR/EJR+ are considerably more demanding than standard
(Hare) JR/EJR+.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [163] [Reinitializing weights vs units for maintaining plasticity in neural networks](https://arxiv.org/abs/2508.00212)
*J. Fernando Hernandez-Garcia,Shibhansh Dohare,Jun Luo,Rich S. Sutton*

Main category: cs.NE

TL;DR: 论文比较了两种防止神经网络丧失可塑性的方法：重新初始化单元与重新初始化权重，并提出了一种新的选择性权重重新初始化算法。实验表明，权重重新初始化在小规模网络或包含层归一化的网络中更有效。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在长时间训练非平稳数据时丧失可塑性的问题，设计持续学习系统。

Method: 提出选择性权重重新初始化算法，并与持续反向传播和ReDo两种单元重新初始化方法进行比较。

Result: 权重重新初始化在小规模网络或包含层归一化的网络中更有效，而在大规模无层归一化网络中与单元重新初始化效果相当。

Conclusion: 权重重新初始化在更广泛的情况下能有效维持网络的可塑性。

Abstract: Loss of plasticity is a phenomenon in which a neural network loses its
ability to learn when trained for an extended time on non-stationary data. It
is a crucial problem to overcome when designing systems that learn continually.
An effective technique for preventing loss of plasticity is reinitializing
parts of the network. In this paper, we compare two different reinitialization
schemes: reinitializing units vs reinitializing weights. We propose a new
algorithm, which we name \textit{selective weight reinitialization}, for
reinitializing the least useful weights in a network. We compare our algorithm
to continual backpropagation and ReDo, two previously proposed algorithms that
reinitialize units in the network. Through our experiments in continual
supervised learning problems, we identify two settings when reinitializing
weights is more effective at maintaining plasticity than reinitializing units:
(1) when the network has a small number of units and (2) when the network
includes layer normalization. Conversely, reinitializing weights and units are
equally effective at maintaining plasticity when the network is of sufficient
size and does not include layer normalization. We found that reinitializing
weights maintains plasticity in a wider variety of settings than reinitializing
units.

</details>


### [164] [Sequential, Parallel and Consecutive Hybrid Evolutionary-Swarm Optimization Metaheuristics](https://arxiv.org/abs/2508.00229)
*Piotr Urbańczyk,Aleksandra Urbańczyk,Magdalena Król,Leszek Rutkowski,Marek Kisiel-Dorohinicki*

Main category: cs.NE

TL;DR: 本文探索了结合PSO和GA的混合进化-群体元启发式算法，并在基准函数上测试，结果显示混合方法在高维搜索空间中表现更优。同时，提出了一种新的连续混合PSO-GA算法，通过信息传递机制确保连续性。


<details>
  <summary>Details</summary>
Motivation: 研究混合进化-群体元启发式算法的性能，尤其是PSO和GA的结合方式，以提升在高维搜索空间中的收敛性和一致性。

Method: 设计了顺序、并行和连续的PSO-GA混合方法，并在多种基准函数上测试。提出了一种新的连续混合算法，通过修改GA的变异算子继承PSO的速度和个人最优信息。

Result: 实验结果表明，混合方法在高维搜索空间中具有更优的收敛性和一致性。

Conclusion: 混合PSO-GA算法在高维优化问题中表现优异，新提出的连续混合算法通过信息传递机制进一步提升了性能。

Abstract: The goal of this paper is twofold. First, it explores hybrid
evolutionary-swarm metaheuristics that combine the features of PSO and GA in a
sequential, parallel and consecutive manner in comparison with their standard
basic form: Genetic Algorithm and Particle Swarm Optimization. The algorithms
were tested on a set of benchmark functions, including Ackley, Griewank, Levy,
Michalewicz, Rastrigin, Schwefel, and Shifted Rotated Weierstrass, across
multiple dimensions. The experimental results demonstrate that the hybrid
approaches achieve superior convergence and consistency, especially in
higher-dimensional search spaces. The second goal of this paper is to introduce
a novel consecutive hybrid PSO-GA evolutionary algorithm that ensures
continuity between PSO and GA steps through explicit information transfer
mechanisms, specifically by modifying GA's variation operators to inherit
velocity and personal best information.

</details>


### [165] [Evolutionary Generative Optimization: Towards Fully Data-Driven Evolutionary Optimization via Generative Learning](https://arxiv.org/abs/2508.00380)
*Kebin Sun,Tao Jiang,Ran Cheng,Yaochu Jin,Kay Chen Tan*

Main category: cs.NE

TL;DR: EvoGO是一个基于生成学习的数据驱动进化算法框架，通过三个阶段实现优化，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动进化算法依赖手工启发式，限制了通用性和自动化。

Method: EvoGO分为数据准备、模型训练和种群生成三个阶段，利用生成模型替代传统繁殖操作。

Result: 在多个任务中，EvoGO仅需10代即可收敛，且性能优于传统方法。

Conclusion: EvoGO展示了数据驱动进化算法的潜力，具有高效和通用性。

Abstract: Recent advances in data-driven evolutionary algorithms (EAs) have
demonstrated the potential of leveraging data to improve optimization accuracy
and adaptability. Nevertheless, most existing approaches remain dependent on
handcrafted heuristics, which limits their generality and automation. To
address this challenge, we propose Evolutionary Generative Optimization
(EvoGO), a fully data-driven framework empowered by generative learning. EvoGO
streamlines the evolutionary optimization process into three stages: data
preparation, model training, and population generation. The data preparation
stage constructs a pairwise dataset to enrich training diversity without
incurring additional evaluation costs. During model training, a tailored
generative model learns to transform inferior solutions into superior ones. In
the population generation stage, EvoGO replaces traditional reproduction
operators with a scalable and parallelizable generative mechanism. Extensive
experiments on numerical benchmarks, classical control problems, and
high-dimensional robotic tasks demonstrate that EvoGO consistently converges
within merely 10 generations and significantly outperforms a wide spectrum of
optimization approaches, including traditional EAs, Bayesian optimization, and
reinforcement learning based methods. Source code will be made publicly
available.

</details>


### [166] [STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers](https://arxiv.org/abs/2508.00387)
*Zeqi Zheng,Zizheng Zhu,Yingchao Yu,Yanchen Huang,Changze Lv,Junfeng Tang,Zhaofei Yu,Yaochu Jin*

Main category: cs.NE

TL;DR: 论文提出了一种轻量级的浅层时间反馈（STF）模块，用于提升基于Transformer的脉冲神经网络（SNNs）的性能，解决了现有深度反馈设计的高成本和低效率问题。


<details>
  <summary>Details</summary>
Motivation: 由于脉冲序列的二进制特性，基于Transformer的SNNs性能远低于浮点人工神经网络（ANNs）。现有深度反馈设计虽然能提升性能，但成本高且效率低。

Method: 提出了浅层时间反馈（STF）模块，包括时空位置嵌入（TSPE）和时间反馈（TF），用于编码层，轻量且即插即用。

Result: 实验表明，STF在多种Transformer-based SNN骨干网络上显著提升了性能，增强了脉冲模式的多样性，并在对抗鲁棒性和时间敏感性上表现优异。

Conclusion: STF是一种高效的新型脉冲编码方案，适用于静态场景，具有广泛的应用潜力。

Abstract: Transformer-based Spiking Neural Networks (SNNs) suffer from a great
performance gap compared to floating-point Artificial Neural Networks (ANNs)
due to the binary nature of spike trains. Recent efforts have introduced
deep-level feedback loops to transmit high-level semantic information to narrow
this gap. However, these designs often span multiple deep layers, resulting in
costly feature transformations, higher parameter overhead, increased energy
consumption, and longer inference latency. To address this issue, we propose
Shallow-level Temporal Feedback (STF), a lightweight plug-and-play module for
the encoding layer, which consists of Temporal-Spatial Position Embedding
(TSPE) and Temporal Feedback (TF).Extensive experiments show that STF
consistently improves performance across various Transformer-based SNN
backbones on static datasets, including CIFAR-10, CIFAR-100, and ImageNet-1K,
under different spike timestep settings. Further analysis reveals that STF
enhances the diversity of the spike patterns, which is key to performance gain.
Moreover, evaluations on adversarial robustness and temporal sensitivity
confirm that STF outperforms direct coding and its variants, highlighting its
potential as a new spike encoding scheme for static scenarios. Our code will be
released upon acceptance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [167] [XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation](https://arxiv.org/abs/2508.00097)
*Zhigen Zhao,Liuchuan Yu,Ke Jing,Ning Yang*

Main category: cs.RO

TL;DR: XRoboToolkit是一个基于OpenXR标准的跨平台扩展现实机器人遥操作框架，解决了当前数据收集方法的可扩展性和质量问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器人演示数据收集方法存在可扩展性差、设置复杂和数据质量低的问题，需要一种更高效的解决方案。

Method: 提出XRoboToolkit框架，支持低延迟立体视觉反馈、基于优化的逆运动学，并整合多种跟踪模态。

Result: 框架在精确操作任务中表现优异，且训练出的VLA模型展现出鲁棒的自主动能。

Conclusion: XRoboToolkit为高质量机器人演示数据收集提供了高效、可扩展的解决方案。

Abstract: The rapid advancement of Vision-Language-Action models has created an urgent
need for large-scale, high-quality robot demonstration datasets. Although
teleoperation is the predominant method for data collection, current approaches
suffer from limited scalability, complex setup procedures, and suboptimal data
quality. This paper presents XRoboToolkit, a cross-platform framework for
extended reality based robot teleoperation built on the OpenXR standard. The
system features low-latency stereoscopic visual feedback, optimization-based
inverse kinematics, and support for diverse tracking modalities including head,
controller, hand, and auxiliary motion trackers. XRoboToolkit's modular
architecture enables seamless integration across robotic platforms and
simulation environments, spanning precision manipulators, mobile robots, and
dexterous hands. We demonstrate the framework's effectiveness through precision
manipulation tasks and validate data quality by training VLA models that
exhibit robust autonomous performance.

</details>


### [168] [CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System](https://arxiv.org/abs/2508.00162)
*Noboru Myers,Obin Kwon,Sankalp Yamsani,Joohyung Kim*

Main category: cs.RO

TL;DR: CHILD是一个紧凑可重构的遥操作系统，支持人形机器人的关节级控制，提升任务多样性。


<details>
  <summary>Details</summary>
Motivation: 现有研究很少支持人形机器人的全身关节级遥操作，限制了任务多样性。

Method: 提出CHILD系统，支持关节映射和自适应力反馈，适用于人形机器人和双臂系统。

Result: 验证了系统在人形机器人和双臂系统中的运动操作和全身控制能力。

Conclusion: CHILD系统提升了遥操作的多样性和安全性，并开源硬件设计以促进可访问性和可重复性。

Abstract: Recent advances in teleoperation have demonstrated robots performing complex
manipulation tasks. However, existing works rarely support whole-body
joint-level teleoperation for humanoid robots, limiting the diversity of tasks
that can be accomplished. This work presents Controller for Humanoid Imitation
and Live Demonstration (CHILD), a compact reconfigurable teleoperation system
that enables joint level control over humanoid robots. CHILD fits within a
standard baby carrier, allowing the operator control over all four limbs, and
supports both direct joint mapping for full-body control and loco-manipulation.
Adaptive force feedback is incorporated to enhance operator experience and
prevent unsafe joint movements. We validate the capabilities of this system by
conducting loco-manipulation and full-body control examples on a humanoid robot
and multiple dual-arm systems. Lastly, we open-source the design of the
hardware promoting accessibility and reproducibility. Additional details and
open-source information are available at our project website:
https://uiuckimlab.github.io/CHILD-pages.

</details>


### [169] [Topology-Inspired Morphological Descriptor for Soft Continuum Robots](https://arxiv.org/abs/2508.00258)
*Zhiwei Wu,Siyi Wei,Jiahao Luo,Jinhui Zhang*

Main category: cs.RO

TL;DR: 提出一种基于拓扑学的形态描述符，结合伪刚体模型和莫尔斯理论，用于软连续机器人的形态定量表征、分类与控制。


<details>
  <summary>Details</summary>
Motivation: 提升软连续机器人在医疗应用（如微创手术和血管内介入）中的精确性和适应性。

Method: 结合伪刚体模型和莫尔斯理论，通过计算方向投影的临界点实现形态离散表示，并用于形态分类与控制。

Result: 提出了一种统一的形态描述、分类与控制框架，能够生成具有目标拓扑特征的平衡形状。

Conclusion: 该框架为软连续机器人的形态分析提供了新方法，有望在医疗领域发挥重要作用。

Abstract: This paper presents a topology-inspired morphological descriptor for soft
continuum robots by combining a pseudo-rigid-body (PRB) model with Morse theory
to achieve a quantitative characterization of robot morphologies. By counting
critical points of directional projections, the proposed descriptor enables a
discrete representation of multimodal configurations and facilitates
morphological classification. Furthermore, we apply the descriptor to
morphology control by formulating the target configuration as an optimization
problem to compute actuation parameters that generate equilibrium shapes with
desired topological features. The proposed framework provides a unified
methodology for quantitative morphology description, classification, and
control of soft continuum robots, with the potential to enhance their precision
and adaptability in medical applications such as minimally invasive surgery and
endovascular interventions.

</details>


### [170] [UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents](https://arxiv.org/abs/2508.00288)
*Jianqiang Xiao,Yuexuan Sun,Yixin Shao,Boxi Gan,Rongqiang Liu,Yanjing Wu,Weili Gua,Xiang Deng*

Main category: cs.RO

TL;DR: UAV-ON是一个针对空中智能体的大规模目标导航基准，旨在解决现有视觉与语言导航（VLN）依赖详细指令的局限性，通过语义目标驱动导航。


<details>
  <summary>Details</summary>
Motivation: 现有空中导航研究多依赖VLN范式，限制了其扩展性和自主性。UAV-ON通过语义目标导航填补这一空白。

Method: 提出UAV-ON基准，包含14个高保真环境和1270个标注目标对象，支持语义目标导航。实现AOA等基线方法，结合指令语义与自我中心观测。

Result: 基线方法在UAV-ON中表现不佳，突显了空中导航与语义目标结合的挑战。

Conclusion: UAV-ON旨在推动复杂环境中基于语义目标的无人机自主性研究。

Abstract: Aerial navigation is a fundamental yet underexplored capability in embodied
intelligence, enabling agents to operate in large-scale, unstructured
environments where traditional navigation paradigms fall short. However, most
existing research follows the Vision-and-Language Navigation (VLN) paradigm,
which heavily depends on sequential linguistic instructions, limiting its
scalability and autonomy. To address this gap, we introduce UAV-ON, a benchmark
for large-scale Object Goal Navigation (ObjectNav) by aerial agents in
open-world environments, where agents operate based on high-level semantic
goals without relying on detailed instructional guidance as in VLN. UAV-ON
comprises 14 high-fidelity Unreal Engine environments with diverse semantic
regions and complex spatial layouts, covering urban, natural, and mixed-use
settings. It defines 1270 annotated target objects, each characterized by an
instance-level instruction that encodes category, physical footprint, and
visual descriptors, allowing grounded reasoning. These instructions serve as
semantic goals, introducing realistic ambiguity and complex reasoning
challenges for aerial agents. To evaluate the benchmark, we implement several
baseline methods, including Aerial ObjectNav Agent (AOA), a modular policy that
integrates instruction semantics with egocentric observations for long-horizon,
goal-directed exploration. Empirical results show that all baselines struggle
in this setting, highlighting the compounded challenges of aerial navigation
and semantic goal grounding. UAV-ON aims to advance research on scalable UAV
autonomy driven by semantic goal descriptions in complex real-world
environments.

</details>


### [171] [TopoDiffuser: A Diffusion-Based Multimodal Trajectory Prediction Model with Topometric Maps](https://arxiv.org/abs/2508.00303)
*Zehui Xu,Junhui Wang,Yongliang Shi,Chao Gao,Guyue Zhou*

Main category: cs.RO

TL;DR: TopoDiffuser是一种基于扩散模型的多模态轨迹预测框架，通过结合拓扑地图生成准确、多样且符合道路规则的未来运动预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在轨迹预测中难以同时满足准确性和道路几何一致性，TopoDiffuser旨在通过融合拓扑地图信息解决这一问题。

Method: 利用扩散模型在去噪过程中嵌入拓扑地图的结构信息，结合LiDAR观测、历史运动和路径信息的多模态编码器生成BEV表示。

Result: 在KITTI基准测试中表现优于现有方法，同时保持几何一致性。消融实验验证了各输入模态和去噪步骤的贡献。

Conclusion: TopoDiffuser通过融合拓扑地图实现了高精度和多样化的轨迹预测，代码已开源。

Abstract: This paper introduces TopoDiffuser, a diffusion-based framework for
multimodal trajectory prediction that incorporates topometric maps to generate
accurate, diverse, and road-compliant future motion forecasts. By embedding
structural cues from topometric maps into the denoising process of a
conditional diffusion model, the proposed approach enables trajectory
generation that naturally adheres to road geometry without relying on explicit
constraints. A multimodal conditioning encoder fuses LiDAR observations,
historical motion, and route information into a unified bird's-eye-view (BEV)
representation. Extensive experiments on the KITTI benchmark demonstrate that
TopoDiffuser outperforms state-of-the-art methods, while maintaining strong
geometric consistency. Ablation studies further validate the contribution of
each input modality, as well as the impact of denoising steps and the number of
trajectory samples. To support future research, we publicly release our code at
https://github.com/EI-Nav/TopoDiffuser.

</details>


### [172] [Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging](https://arxiv.org/abs/2508.00354)
*Tianshuang Qiu,Zehan Ma,Karim El-Refai,Hiya Shah,Chung Min Kim,Justin Kerr,Ken Goldberg*

Main category: cs.RO

TL;DR: Omni-Scan是一种利用双机械臂机器人抓取和旋转物体，结合多模型处理生成高质量3D高斯溅射模型的流程，用于全方位物体建模和缺陷检测。


<details>
  <summary>Details</summary>
Motivation: 传统3D物体扫描方法受限于设备工作空间，需要多相机阵列或激光扫描仪。Omni-Scan旨在通过机器人抓取和旋转物体，结合计算机视觉技术，实现高效且高质量的3D建模。

Method: 使用双机械臂机器人抓取物体并旋转，结合DepthAnything、Segment Anything和RAFT光流模型去除背景和夹持器遮挡，改进3DGS训练流程以支持拼接数据集。

Result: Omni-Scan在12种工业和家用物体上实现了83%的平均缺陷检测准确率。

Conclusion: Omni-Scan提供了一种高效且高质量的3D建模方法，适用于工业缺陷检测等应用。

Abstract: 3D Gaussian Splats (3DGSs) are 3D object models derived from multi-view
images. Such "digital twins" are useful for simulations, virtual reality,
marketing, robot policy fine-tuning, and part inspection. 3D object scanning
usually requires multi-camera arrays, precise laser scanners, or robot
wrist-mounted cameras, which have restricted workspaces. We propose Omni-Scan,
a pipeline for producing high-quality 3D Gaussian Splat models using a
bi-manual robot that grasps an object with one gripper and rotates the object
with respect to a stationary camera. The object is then re-grasped by a second
gripper to expose surfaces that were occluded by the first gripper. We present
the Omni-Scan robot pipeline using DepthAny-thing, Segment Anything, as well as
RAFT optical flow models to identify and isolate objects held by a robot
gripper while removing the gripper and the background. We then modify the 3DGS
training pipeline to support concatenated datasets with gripper occlusion,
producing an omni-directional (360 degree view) model of the object. We apply
Omni-Scan to part defect inspection, finding that it can identify visual or
geometric defects in 12 different industrial and household objects with an
average accuracy of 83%. Interactive videos of Omni-Scan 3DGS models can be
found at https://berkeleyautomation.github.io/omni-scan/

</details>


### [173] [TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots](https://arxiv.org/abs/2508.00355)
*Zhenghan Chen,Haocheng Xu,Haodong Zhang,Liang Zhang,He Li,Dongqi Wang,Jiyu Yu,Yifei Yang,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种新颖的时间优化策略（TOP），用于训练人形机器人的站立操控控制模型，同时确保平衡、精确性和时间效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时满足高维上半身关节的精确控制和快速运动时的鲁棒性，因此需要一种新方法。

Method: 结合运动先验、变分自编码器（VAE）和解耦控制（上半身PD控制器和下半身RL控制器），并通过TOP方法优化时间轨迹。

Result: 仿真和实际实验验证了该方法在稳定和精确完成站立操控任务上的优越性。

Conclusion: TOP方法有效解决了快速上半身运动带来的平衡问题，提升了整体性能。

Abstract: Humanoid robots have the potential capability to perform a diverse range of
manipulation tasks, but this is based on a robust and precise standing
controller. Existing methods are either ill-suited to precisely control
high-dimensional upper-body joints, or difficult to ensure both robustness and
accuracy, especially when upper-body motions are fast. This paper proposes a
novel time optimization policy (TOP), to train a standing manipulation control
model that ensures balance, precision, and time efficiency simultaneously, with
the idea of adjusting the time trajectory of upper-body motions but not only
strengthening the disturbance resistance of the lower-body. Our approach
consists of three parts. Firstly, we utilize motion prior to represent
upper-body motions to enhance the coordination ability between the upper and
lower-body by training a variational autoencoder (VAE). Then we decouple the
whole-body control into an upper-body PD controller for precision and a
lower-body RL controller to enhance robust stability. Finally, we train TOP
method in conjunction with the decoupled controller and VAE to reduce the
balance burden resulting from fast upper-body motions that would destabilize
the robot and exceed the capabilities of the lower-body RL policy. The
effectiveness of the proposed approach is evaluated via both simulation and
real world experiments, which demonstrate the superiority on standing
manipulation tasks stably and accurately. The project page can be found at
https://anonymous.4open.science/w/top-258F/.

</details>


### [174] [A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot](https://arxiv.org/abs/2508.00362)
*Zhenghan Chen,Haodong Zhang,Dongqi Wang,Jiyu Yu,Haocheng Xu,Yue Wang,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种新颖的全身运动模仿框架，用于全尺寸人形机器人，通过接触感知的全身运动重定向和非线性质心模型预测控制器实现高精度模仿与平衡。


<details>
  <summary>Details</summary>
Motivation: 人形机器人模仿人类运动时，由于运动学和动力学差异，难以同时保证模仿精度与平衡。

Method: 采用接触感知的全身运动重定向生成初始轨迹，结合非线性质心模型预测控制器实时维持平衡与抗干扰。

Result: 实验验证了该方法在仿真和真实机器人中均能高精度模仿多种人类运动。

Conclusion: 所提框架有效解决了人形机器人运动模仿中的精度与平衡问题。

Abstract: Motion imitation is a pivotal and effective approach for humanoid robots to
achieve a more diverse range of complex and expressive movements, making their
performances more human-like. However, the significant differences in
kinematics and dynamics between humanoid robots and humans present a major
challenge in accurately imitating motion while maintaining balance. In this
paper, we propose a novel whole-body motion imitation framework for a full-size
humanoid robot. The proposed method employs contact-aware whole-body motion
retargeting to mimic human motion and provide initial values for reference
trajectories, and the non-linear centroidal model predictive controller ensures
the motion accuracy while maintaining balance and overcoming external
disturbances in real time. The assistance of the whole-body controller allows
for more precise torque control. Experiments have been conducted to imitate a
variety of human motions both in simulation and in a real-world humanoid robot.
These experiments demonstrate the capability of performing with accuracy and
adaptability, which validates the effectiveness of our approach.

</details>


### [175] [On Learning Closed-Loop Probabilistic Multi-Agent Simulator](https://arxiv.org/abs/2508.00384)
*Juanwu Lu,Rohit Gupta,Ahmadreza Moradipari,Kyungtae Han,Ruqi Zhang,Ziran Wang*

Main category: cs.RO

TL;DR: NIVA是一个基于分层贝叶斯模型的概率框架，用于多智能体交通模拟，支持闭环、观察条件模拟，并在Waymo数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆的快速部署，需要构建更真实、可扩展的多智能体交通模拟器以高效评估性能。

Method: NIVA采用分层贝叶斯模型，通过自回归采样从潜在的高斯混合分布中生成交互式模拟场景。

Result: 在Waymo Open Motion数据集上，NIVA表现优于现有方法，并能灵活控制意图和驾驶风格。

Conclusion: NIVA为多智能体模拟提供了一种统一且高效的框架，兼具性能和控制灵活性。

Abstract: The rapid iteration of autonomous vehicle (AV) deployments leads to
increasing needs for building realistic and scalable multi-agent traffic
simulators for efficient evaluation. Recent advances in this area focus on
closed-loop simulators that enable generating diverse and interactive
scenarios. This paper introduces Neural Interactive Agents (NIVA), a
probabilistic framework for multi-agent simulation driven by a hierarchical
Bayesian model that enables closed-loop, observation-conditioned simulation
through autoregressive sampling from a latent, finite mixture of Gaussian
distributions. We demonstrate how NIVA unifies preexisting sequence-to-sequence
trajectory prediction models and emerging closed-loop simulation models trained
on Next-token Prediction (NTP) from a Bayesian inference perspective.
Experiments on the Waymo Open Motion Dataset demonstrate that NIVA attains
competitive performance compared to the existing method while providing
embellishing control over intentions and driving styles.

</details>


### [176] [SubCDM: Collective Decision-Making with a Swarm Subset](https://arxiv.org/abs/2508.00467)
*Samratul Fuady,Danesh Tarapore,Mohammad D. Soorati*

Main category: cs.RO

TL;DR: 提出了一种基于子集的集体决策方法（SubCDM），通过动态构建子集减少资源消耗，同时保持决策准确性。


<details>
  <summary>Details</summary>
Motivation: 现有集体决策方法需要所有机器人参与，资源消耗大且无法同时执行其他任务。

Method: 动态构建子集，仅依赖局部信息，自适应确定子集大小以适应不同决策难度。

Result: 仿真实验显示，SubCDM在减少机器人参与数量的同时，保持了与全群决策相当的准确性。

Conclusion: SubCDM是一种资源高效的集体决策方法，适用于机器人群体。

Abstract: Collective decision-making is a key function of autonomous robot swarms,
enabling them to reach a consensus on actions based on environmental features.
Existing strategies require the participation of all robots in the
decision-making process, which is resource-intensive and prevents the swarm
from allocating the robots to any other tasks. We propose Subset-Based
Collective Decision-Making (SubCDM), which enables decisions using only a swarm
subset. The construction of the subset is dynamic and decentralized, relying
solely on local information. Our method allows the swarm to adaptively
determine the size of the subset for accurate decision-making, depending on the
difficulty of reaching a consensus. Simulation results using one hundred robots
show that our approach achieves accuracy comparable to using the entire swarm
while reducing the number of robots required to perform collective
decision-making, making it a resource-efficient solution for collective
decision-making in swarm robotics.

</details>


### [177] [HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning](https://arxiv.org/abs/2508.00491)
*Carlo Alessi,Federico Vasile,Federico Ceola,Giulia Pasquale,Nicolò Boccardo,Lorenzo Natale*

Main category: cs.RO

TL;DR: 论文提出了一种基于模仿学习的假手控制方法HannesImitationPolicy，通过扩散策略预测手腕方向和手部闭合动作，成功实现了在非结构化环境中的物体抓取。


<details>
  <summary>Details</summary>
Motivation: 减少假手用户的认知负担，通过模仿学习提升假手的灵活性和适应性，使其能在更多无约束场景中操作。

Method: 使用HannesImitationDataset中的抓取演示数据训练扩散策略，预测手腕方向和手部闭合动作。

Result: 实验表明，该方法在多样物体和条件下成功抓取，并在非结构化场景中优于基于分割的视觉伺服控制器。

Conclusion: 模仿学习为假手控制提供了新思路，HannesImitationPolicy在非结构化环境中表现出色，未来可进一步扩展应用场景。

Abstract: Recent advancements in control of prosthetic hands have focused on increasing
autonomy through the use of cameras and other sensory inputs. These systems aim
to reduce the cognitive load on the user by automatically controlling certain
degrees of freedom. In robotics, imitation learning has emerged as a promising
approach for learning grasping and complex manipulation tasks while simplifying
data collection. Its application to the control of prosthetic hands remains,
however, largely unexplored. Bridging this gap could enhance dexterity
restoration and enable prosthetic devices to operate in more unconstrained
scenarios, where tasks are learned from demonstrations rather than relying on
manually annotated sequences. To this end, we present HannesImitationPolicy, an
imitation learning-based method to control the Hannes prosthetic hand, enabling
object grasping in unstructured environments. Moreover, we introduce the
HannesImitationDataset comprising grasping demonstrations in table, shelf, and
human-to-prosthesis handover scenarios. We leverage such data to train a single
diffusion policy and deploy it on the prosthetic hand to predict the wrist
orientation and hand closure for grasping. Experimental evaluation demonstrates
successful grasps across diverse objects and conditions. Finally, we show that
the policy outperforms a segmentation-based visual servo controller in
unstructured scenarios. Additional material is provided on our project page:
https://hsp-iit.github.io/HannesImitation

</details>


### [178] [OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery](https://arxiv.org/abs/2508.00580)
*Raul Castilla-Arquillo,Carlos Perez-del-Pulgar,Levin Gerdes,Alfonso Garcia-Cerezo,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: OmniUnet是一种基于Transformer的神经网络架构，用于RGB-D-T图像语义分割，支持火星探测中的多模态地形感知。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，机器人导航需要多模态感知系统以确保安全。火星探测中，热成像对评估地形安全性尤为重要。

Method: 开发了OmniUnet网络架构和定制多模态传感器外壳，在西班牙半沙漠地区收集RGB-D-T数据集，并进行监督训练。

Result: 模型像素准确率达80.37%，推理时间673毫秒，适合在资源受限设备上部署。

Conclusion: OmniUnet在多模态地形感知中表现优异，公开了软件和数据集以支持未来研究。

Abstract: Robot navigation in unstructured environments requires multimodal perception
systems that can support safe navigation. Multimodality enables the integration
of complementary information collected by different sensors. However, this
information must be processed by machine learning algorithms specifically
designed to leverage heterogeneous data. Furthermore, it is necessary to
identify which sensor modalities are most informative for navigation in the
target environment. In Martian exploration, thermal imagery has proven valuable
for assessing terrain safety due to differences in thermal behaviour between
soil types. This work presents OmniUnet, a transformer-based neural network
architecture for semantic segmentation using RGB, depth, and thermal (RGB-D-T)
imagery. A custom multimodal sensor housing was developed using 3D printing and
mounted on the Martian Rover Testbed for Autonomy (MaRTA) to collect a
multimodal dataset in the Bardenas semi-desert in northern Spain. This location
serves as a representative environment of the Martian surface, featuring
terrain types such as sand, bedrock, and compact soil. A subset of this dataset
was manually labeled to support supervised training of the network. The model
was evaluated both quantitatively and qualitatively, achieving a pixel accuracy
of 80.37% and demonstrating strong performance in segmenting complex
unstructured terrain. Inference tests yielded an average prediction time of 673
ms on a resource-constrained computer (Jetson Orin Nano), confirming its
suitability for on-robot deployment. The software implementation of the network
and the labeled dataset have been made publicly available to support future
research in multimodal terrain perception for planetary robotics.

</details>


### [179] [A control scheme for collaborative object transportation between a human and a quadruped robot using the MIGHTY suction cup](https://arxiv.org/abs/2508.00584)
*Konstantinos Plotas,Emmanouil Papadakis,Drosakis Drosakis,Panos Trahanias,Dimitrios Papageorgiou*

Main category: cs.RO

TL;DR: 提出了一种基于导纳控制的四足机器人与人类协作运输物体的控制方案，结合可变阻尼和屏障人工势能，确保物体不脱落。


<details>
  <summary>Details</summary>
Motivation: 提高人类在协作运输中的可控性并减少其努力，同时确保物体与吸盘不分离。

Method: 采用导纳控制框架，引入可变阻尼和基于屏障人工势能的附加控制信号。

Result: 控制方案被证明是被动的，并通过实验验证了其性能。

Conclusion: 提出的控制方案有效提升了协作运输的效率和安全性。

Abstract: In this work, a control scheme for human-robot collaborative object
transportation is proposed, considering a quadruped robot equipped with the
MIGHTY suction cup that serves both as a gripper for holding the object and a
force/torque sensor. The proposed control scheme is based on the notion of
admittance control, and incorporates a variable damping term aiming towards
increasing the controllability of the human and, at the same time, decreasing
her/his effort. Furthermore, to ensure that the object is not detached from the
suction cup during the collaboration, an additional control signal is proposed,
which is based on a barrier artificial potential. The proposed control scheme
is proven to be passive and its performance is demonstrated through
experimental evaluations conducted using the Unitree Go1 robot equipped with
the MIGHTY suction cup.

</details>


### [180] [OpenScout v1.1 mobile robot: a case study on open hardware continuation](https://arxiv.org/abs/2508.00625)
*Bartosz Krawczyk,Ahmed Elbary,Robbie Cato,Jagdish Patil,Kaung Myat,Anyeh Ndi-Tah,Nivetha Sakthivel,Mark Crampton,Gautham Das,Charles Fox*

Main category: cs.RO

TL;DR: OpenScout v1.1是一款开源硬件移动机器人，优化了计算硬件、ROS2接口和Gazebo模拟，并提供了案例研究。


<details>
  <summary>Details</summary>
Motivation: 为研究和工业提供更简化、更经济且更强大的开源硬件移动机器人解决方案。

Method: 通过改进硬件设计、增加ROS2接口和Gazebo模拟功能，并进行案例研究。

Result: 实现了更高效、更经济的机器人平台，并提供了完整的模拟支持。

Conclusion: OpenScout v1.1为开源硬件机器人研究提供了实用且可扩展的解决方案。

Abstract: OpenScout is an Open Source Hardware (OSH) mobile robot for research and
industry. It is extended to v1.1 which includes simplified, cheaper and more
powerful onboard compute hardware; a simulated ROS2 interface; and a Gazebo
simulation. Changes, their rationale, project methodology, and results are
reported as an OSH case study.

</details>


### [181] [Towards Data-Driven Adaptive Exoskeleton Assistance for Post-stroke Gait](https://arxiv.org/abs/2508.00691)
*Fabian C. Weigend,Dabin K. Choe,Santiago Canete,Conor J. Walsh*

Main category: cs.RO

TL;DR: 数据驱动方法用于外骨骼控制，首次在卒中后步态中实现自适应踝关节助力。


<details>
  <summary>Details</summary>
Motivation: 解决卒中后步态障碍患者外骨骼控制的挑战，如数据稀缺和步态异质性。

Method: 使用多任务时间卷积网络（TCN）结合IMU数据，预训练健康步态数据并应用于卒中后步态。

Result: 模型在四名卒中参与者中表现良好（R²=0.74±0.13），并在实时控制中验证可行性。

Conclusion: 数据驱动方法为卒中后外骨骼控制提供了可行路径，未来可扩展至社区应用。

Abstract: Recent work has shown that exoskeletons controlled through data-driven
methods can dynamically adapt assistance to various tasks for healthy young
adults. However, applying these methods to populations with neuromotor gait
deficits, such as post-stroke hemiparesis, is challenging. This is due not only
to high population heterogeneity and gait variability but also to a lack of
post-stroke gait datasets to train accurate models. Despite these challenges,
data-driven methods offer a promising avenue for control, potentially allowing
exoskeletons to function safely and effectively in unstructured community
settings. This work presents a first step towards enabling adaptive
plantarflexion and dorsiflexion assistance from data-driven torque estimation
during post-stroke walking. We trained a multi-task Temporal Convolutional
Network (TCN) using collected data from four post-stroke participants walking
on a treadmill ($R^2$ of $0.74 \pm 0.13$). The model uses data from three
inertial measurement units (IMU) and was pretrained on healthy walking data
from 6 participants. We implemented a wearable prototype for our ankle torque
estimation approach for exoskeleton control and demonstrated the viability of
real-time sensing, estimation, and actuation with one post-stroke participant.

</details>


### [182] [On-Device Diffusion Transformer Policy for Efficient Robot Manipulation](https://arxiv.org/abs/2508.00697)
*Yiming Wu,Huan Wang,Zhenghao Chen,Jianxin Pang,Dong Xu*

Main category: cs.RO

TL;DR: LightDP是一个专为移动设备设计的框架，通过压缩去噪模块和减少采样步骤，加速Diffusion Policies的实时部署。


<details>
  <summary>Details</summary>
Motivation: Diffusion Policies在机器人操作任务中表现优异，但在资源受限的移动平台上应用受限，主要由于计算效率低和内存占用大。

Method: LightDP采用网络压缩和采样步骤减少策略，包括统一的剪枝和再训练流程，并结合一致性蒸馏技术。

Result: 实验表明，LightDP在移动设备上实现实时动作预测，性能与现有Diffusion Policies相当。

Conclusion: LightDP为资源受限环境中基于扩散的策略的实际部署迈出了重要一步。

Abstract: Diffusion Policies have significantly advanced robotic manipulation tasks via
imitation learning, but their application on resource-constrained mobile
platforms remains challenging due to computational inefficiency and extensive
memory footprint. In this paper, we propose LightDP, a novel framework
specifically designed to accelerate Diffusion Policies for real-time deployment
on mobile devices. LightDP addresses the computational bottleneck through two
core strategies: network compression of the denoising modules and reduction of
the required sampling steps. We first conduct an extensive computational
analysis on existing Diffusion Policy architectures, identifying the denoising
network as the primary contributor to latency. To overcome performance
degradation typically associated with conventional pruning methods, we
introduce a unified pruning and retraining pipeline, optimizing the model's
post-pruning recoverability explicitly. Furthermore, we combine pruning
techniques with consistency distillation to effectively reduce sampling steps
while maintaining action prediction accuracy. Experimental evaluations on the
standard datasets, \ie, PushT, Robomimic, CALVIN, and LIBERO, demonstrate that
LightDP achieves real-time action prediction on mobile devices with competitive
performance, marking an important step toward practical deployment of
diffusion-based policies in resource-limited environments. Extensive real-world
experiments also show the proposed LightDP can achieve performance comparable
to state-of-the-art Diffusion Policies.

</details>


### [183] [Video Generators are Robot Policies](https://arxiv.org/abs/2508.00795)
*Junbang Liang,Pavel Tokmakov,Ruoshi Liu,Sruthi Sudhakar,Paarth Shah,Rares Ambrus,Carl Vondrick*

Main category: cs.RO

TL;DR: 论文提出了一种名为Video Policy的模块化框架，通过视频生成作为机器人策略学习的代理，解决了感知和行为分布变化下的泛化问题以及人类演示数据规模的限制。


<details>
  <summary>Details</summary>
Motivation: 当前视觉运动策略在泛化和数据效率方面存在局限，尤其是在感知或行为分布变化时表现不佳，且依赖大量人类演示数据。

Method: 提出Video Policy框架，结合视频和动作生成，端到端训练，利用视频生成模型提取策略。

Result: 方法在仿真和现实世界中均表现出对未见物体、背景和任务的强泛化能力，且样本效率显著提高。

Conclusion: 通过大规模视频生成模型，该方法在数据效率和性能上优于传统行为克隆，为机器人策略学习提供了更可扩展的解决方案。

Abstract: Despite tremendous progress in dexterous manipulation, current visuomotor
policies remain fundamentally limited by two challenges: they struggle to
generalize under perceptual or behavioral distribution shifts, and their
performance is constrained by the size of human demonstration data. In this
paper, we use video generation as a proxy for robot policy learning to address
both limitations simultaneously. We propose Video Policy, a modular framework
that combines video and action generation that can be trained end-to-end. Our
results demonstrate that learning to generate videos of robot behavior allows
for the extraction of policies with minimal demonstration data, significantly
improving robustness and sample efficiency. Our method shows strong
generalization to unseen objects, backgrounds, and tasks, both in simulation
and the real world. We further highlight that task success is closely tied to
the generated video, with action-free video data providing critical benefits
for generalizing to novel tasks. By leveraging large-scale video generative
models, we achieve superior performance compared to traditional behavior
cloning, paving the way for more scalable and data-efficient robot policy
learning.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [184] [ReVise: A Human-AI Interface for Incremental Algorithmic Recourse](https://arxiv.org/abs/2508.00002)
*Kaustav Bhattacharjee,Jun Yuan,Aritra Dasgupta*

Main category: cs.HC

TL;DR: 论文提出了一种可视化分析工作流，帮助数据主体在算法决策中规划增量补救路径，避免误导性步骤。


<details>
  <summary>Details</summary>
Motivation: 人工智能在招聘、金融等领域的黑箱决策引发担忧，数据主体需要理解如何通过调整特征获得更有利的结果，但现有方法忽视了增量步骤和现实约束。

Method: 开发了一个交互式可视化界面，结合专家意见，支持数据主体探索补救路径并做出明智决策。

Result: 通过真实数据集和12名研究生的观察研究，验证了该方法的有效性。

Conclusion: 该方法能帮助数据主体选择适合的补救路径，弥补了现有方法的不足。

Abstract: The recent adoption of artificial intelligence in socio-technical systems
raises concerns about the black-box nature of the resulting decisions in fields
such as hiring, finance, admissions, etc. If data subjects -- such as job
applicants, loan applicants, and students -- receive an unfavorable outcome,
they may be interested in algorithmic recourse, which involves updating certain
features to yield a more favorable result when re-evaluated by algorithmic
decision-making. Unfortunately, when individuals do not fully understand the
incremental steps needed to change their circumstances, they risk following
misguided paths that can lead to significant, long-term adverse consequences.
Existing recourse approaches focus exclusively on the final recourse goal but
neglect the possible incremental steps to reach the goal with real-life
constraints, user preferences, and model artifacts. To address this gap, we
formulate a visual analytic workflow for incremental recourse planning in
collaboration with AI/ML experts and contribute an interactive visualization
interface that helps data subjects efficiently navigate the recourse
alternatives and make an informed decision. We present a usage scenario and
subjective feedback from observational studies with twelve graduate students
using a real-world dataset, which demonstrates that our approach can be
instrumental for data subjects in choosing a suitable recourse path.

</details>


### [185] [A Mixed User-Centered Approach to Enable Augmented Intelligence in Intelligent Tutoring Systems: The Case of MathAIde app](https://arxiv.org/abs/2508.00103)
*Guilherme Guerino,Luiz Rodrigues,Luana Bianchiniand Mariana Alves,Marcelo Marinho,Thomaz Veloso,Valmir Macario,Diego Dermeval,Thales Vieira,Ig Bittencourt,Seiji Isotani*

Main category: cs.HC

TL;DR: 论文探讨了AI在教育中的应用（AIED）及其挑战，提出增强智能（AuI）解决方案，并通过MathAIde系统验证其有效性。


<details>
  <summary>Details</summary>
Motivation: AIED旨在提升学习体验，但面临教师参与、AI工具可靠性和资源可及性等挑战。

Method: 研究设计并评估了MathAIde系统，结合计算机视觉和AI，通过用户调研、原型设计和实地测试验证。

Result: 研究提出了教师为中心的AuI设计方法，提高了AIED系统的实用性和采纳潜力。

Conclusion: 用户中心设计方法能有效提升AIED系统的实用性，尤其在资源有限环境中。

Abstract: Integrating Artificial Intelligence in Education (AIED) aims to enhance
learning experiences through technologies like Intelligent Tutoring Systems
(ITS), offering personalized learning, increased engagement, and improved
retention rates. However, AIED faces three main challenges: the critical role
of teachers in the design process, the limitations and reliability of AI tools,
and the accessibility of technological resources. Augmented Intelligence (AuI)
addresses these challenges by enhancing human capabilities rather than
replacing them, allowing systems to suggest solutions. In contrast, humans
provide final assessments, thus improving AI over time. In this sense, this
study focuses on designing, developing, and evaluating MathAIde, an ITS that
corrects mathematics exercises using computer vision and AI and provides
feedback based on photos of student work. The methodology included
brainstorming sessions with potential users, high-fidelity prototyping, A/B
testing, and a case study involving real-world classroom environments for
teachers and students. Our research identified several design possibilities for
implementing AuI in ITSs, emphasizing a balance between user needs and
technological feasibility. Prioritization and validation through prototyping
and testing highlighted the importance of efficiency metrics, ultimately
leading to a solution that offers pre-defined remediation alternatives for
teachers. Real-world deployment demonstrated the usefulness of the proposed
solution. Our research contributes to the literature by providing a usable,
teacher-centered design approach that involves teachers in all design phases.
As a practical implication, we highlight that the user-centered design approach
increases the usefulness and adoption potential of AIED systems, especially in
resource-limited environments.

</details>


### [186] [DeformTune: A Deformable XAI Music Prototype for Non-Musicians](https://arxiv.org/abs/2508.00160)
*Ziqing Xu,Nick Bryan-Kinns*

Main category: cs.HC

TL;DR: DeformTune是一个结合可变形触控界面与MeasureVAE模型的AI音乐生成系统，旨在为非音乐专业人士提供更直观的音乐创作体验。初步研究表明，用户面临控制映射不清晰等问题，提出了增强AI可解释性的设计机会。


<details>
  <summary>Details</summary>
Motivation: 现有AI音乐生成工具依赖文本提示或复杂界面，非专业人士难以使用。DeformTune旨在通过触控界面和直观交互降低使用门槛。

Method: 结合可变形触控界面与MeasureVAE模型，进行11名非音乐专业人士的初步用户体验研究。

Result: 用户反馈显示控制映射不清晰、表达范围有限等问题，提出了多模态反馈和渐进式交互支持等改进方向。

Conclusion: DeformTune为AI音乐系统的可解释性和易用性提供了早期设计启示，有助于为非专业人士赋能。

Abstract: Many existing AI music generation tools rely on text prompts, complex
interfaces, or instrument-like controls, which may require musical or technical
knowledge that non-musicians do not possess. This paper introduces DeformTune,
a prototype system that combines a tactile deformable interface with the
MeasureVAE model to explore more intuitive, embodied, and explainable AI
interaction. We conducted a preliminary study with 11 adult participants
without formal musical training to investigate their experience with
AI-assisted music creation. Thematic analysis of their feedback revealed
recurring challenge--including unclear control mappings, limited expressive
range, and the need for guidance throughout use. We discuss several design
opportunities for enhancing explainability of AI, including multimodal feedback
and progressive interaction support. These findings contribute early insights
toward making AI music systems more explainable and empowering for novice
users.

</details>


### [187] [Decoupling Data and Tooling in Interactive Visualization](https://arxiv.org/abs/2508.00107)
*Jan Simson*

Main category: cs.HC

TL;DR: 提出了一种模块化方法，将数据整理与加载功能从可视化组件中分离，以减少开发冗余并提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 当前可视化工具缺乏对数据转换或整理的支持，导致开发效率低、用户体验差。

Method: 采用模块化架构，分离数据整理与可视化功能，并通过原型验证可行性。

Result: 展示了模块化方法的可行性，并提出了未来研究方向。

Conclusion: 模块化方法有望提升工具开发效率和用户体验，需社区反馈以进一步完善。

Abstract: Interactive data visualization is a major part of modern exploratory data
analysis, with web-based technologies enabling a rich ecosystem of both
specialized and general tools. However, current visualization tools often lack
support for transformation or wrangling of data and are forced to re-implement
their own solutions to load and ingest data. This redundancy creates
substantial development overhead for tool creators, steeper learning curves for
users who must master different data handling interfaces across tools and a
degraded user experience as data handling is usually seen as an after-thought.
  We propose a modular approach that separates data wrangling and loading
capabilities from visualization components. This architecture allows
visualization tools to concentrate on their core strengths while providing the
opportunity to develop a unified, powerful interface for data handling. An
additional benefit of this approach is that it allows for multiple tools to
exist and be used side by side. We demonstrate the feasibility of this approach
by building an early prototype using web technologies to encapsulate
visualization tools and manage data flow between them.
  We discuss future research directions, including downstream integrations with
other tooling, such as IDEs, literate programming notebooks and applications,
as well as incorporation of new technologies for efficient data
transformations. We seek input from the community to better understand the
requirements towards this approach.

</details>


### [188] [Your Model Is Unfair, Are You Even Aware? Inverse Relationship Between Comprehension and Trust in Explainability Visualizations of Biased ML Models](https://arxiv.org/abs/2508.00140)
*Zhanna Kaufman,Madeline Endres,Cindy Xiong Bearfield,Yuriy Brun*

Main category: cs.HC

TL;DR: 研究探讨了ML模型解释可视化对非专家用户理解、偏见感知和信任的影响，发现理解与信任呈反比关系，偏见感知是中介因素。


<details>
  <summary>Details</summary>
Motivation: ML系统中的偏见行为普遍存在，影响用户信任，不同背景的用户对同一系统的看法和信任度不同，因此模型解释方式至关重要。

Method: 调查了五种最先进的可视化工具（LIME、SHAP、CP、Anchors和ELI5），通过用户研究评估其设计特性对理解、偏见感知和信任的影响。

Result: 发现理解与信任呈反比关系，偏见感知是中介因素；通过调整可视化设计或模型公平性，可以显著提高信任。

Conclusion: 研究揭示了理解与信任的关系，并系统探讨了可视化在促进负责任ML应用中的作用。

Abstract: Systems relying on ML have become ubiquitous, but so has biased behavior
within them. Research shows that bias significantly affects stakeholders' trust
in systems and how they use them. Further, stakeholders of different
backgrounds view and trust the same systems differently. Thus, how ML models'
behavior is explained plays a key role in comprehension and trust. We survey
explainability visualizations, creating a taxonomy of design characteristics.
We conduct user studies to evaluate five state-of-the-art visualization tools
(LIME, SHAP, CP, Anchors, and ELI5) for model explainability, measuring how
taxonomy characteristics affect comprehension, bias perception, and trust for
non-expert ML users. Surprisingly, we find an inverse relationship between
comprehension and trust: the better users understand the models, the less they
trust them. We investigate the cause and find that this relationship is
strongly mediated by bias perception: more comprehensible visualizations
increase people's perception of bias, and increased bias perception reduces
trust. We confirm this relationship is causal: Manipulating explainability
visualizations to control comprehension, bias perception, and trust, we show
that visualization design can significantly (p < 0.001) increase comprehension,
increase perceived bias, and reduce trust. Conversely, reducing perceived model
bias, either by improving model fairness or by adjusting visualization design,
significantly increases trust even when comprehension remains high. Our work
advances understanding of how comprehension affects trust and systematically
investigates visualization's role in facilitating responsible ML applications.

</details>


### [189] [The SPACE of AI: Real-World Lessons on AI's Impact on Developers](https://arxiv.org/abs/2508.00178)
*Brian Houck,Travis Lowdermilk,Cody Beyer,Steven Clarke,Ben Hanrahan*

Main category: cs.HC

TL;DR: AI工具在软件开发中广泛使用，提升生产力但对协作影响有限，团队支持是关键。


<details>
  <summary>Details</summary>
Motivation: 研究AI工具对开发者生产力与体验的真实影响。

Method: 混合方法研究，包括500多名开发者的调查、访谈和观察。

Result: AI提升效率和满意度，但对协作影响较小，团队支持至关重要。

Conclusion: AI增强而非替代开发者，团队文化和支持结构对有效整合至关重要。

Abstract: As artificial intelligence (AI) tools become increasingly embedded in
software development workflows, questions persist about their true impact on
developer productivity and experience. This paper presents findings from a
mixed-methods study examining how developers perceive AI's influence across the
dimensions of the SPACE framework: Satisfaction, Performance, Activity,
Collaboration and Efficiency. Drawing on survey responses from over 500
developers and qualitative insights from interviews and observational studies,
we find that AI is broadly adopted and widely seen as enhancing productivity,
particularly for routine tasks. However, the benefits vary, depending on task
complexity, individual usage patterns, and team-level adoption. Developers
report increased efficiency and satisfaction, with less evidence of impact on
collaboration. Organizational support and peer learning play key roles in
maximizing AI's value. These findings suggest that AI is augmenting developers
rather than replacing them, and that effective integration depends as much on
team culture and support structures as on the tools themselves. We conclude
with practical recommendations for teams, organizations and researchers seeking
to harness AI's potential in software engineering.

</details>


### [190] [HandOver: Enabling Precise Selection & Manipulation of 3D Objects with Mouse and Hand Tracking](https://arxiv.org/abs/2508.00211)
*Esen K. Tütüncü,Mar Gonzalez-Franco,Eric J. Gonzalez*

Main category: cs.HC

TL;DR: HandOver是一种XR交互技术，结合鼠标的精确选择和手部追踪的灵活操作，提升任务表现和用户舒适度。


<details>
  <summary>Details</summary>
Motivation: 传统鼠标输入精确但缺乏表达力，手部追踪灵活但不够精确。HandOver旨在结合两者的优势。

Method: 使用鼠标驱动深度感知3D光标进行精确选择，通过手部悬停过渡到直接3D操作。与两种射线技术（Ray和Ray+Hand）在3D任务中对比。

Result: HandOver在所有距离下任务错误率更低，交互人体工学更优（RULA和NASA-TLX评估）。

Conclusion: 结合传统精确输入和手部追踪的灵活性，HandOver提升了XR交互的用户舒适度和任务表现。

Abstract: We present HandOver, an extended reality (XR) interaction technique designed
to unify the precision of traditional mouse input for object selection with the
expressiveness of hand-tracking for object manipulation. With HandOver, the
mouse is used to drive a depth-aware 3D cursor enabling precise and restful
targeting -by hovering their hand over the mouse, the user can then seamlessly
transition into direct 3D manipulation of the target object. In a formal user
study, we compare HandOver against two raybased techniques: traditional
raycasting (Ray) and a hybrid method (Ray+Hand) in a 3D docking task. Results
show HandOver yields lower task errors across all distances, and moreover
improves interaction ergonomics as highlighted by a RULA posture analysis and
self-reported measures (NASA-TLX). These findings illustrate the benefits of
blending traditional precise input devices with the expressive gestural inputs
afforded by hand-tracking in XR, leading to improved user comfort and task
performance. This blended paradigm yields a unified workflow allowing users to
leverage the best of each input modality as they interact in immersive
environments.

</details>


### [191] [Correcting Misperceptions at a Glance: Using Data Visualizations to Reduce Political Sectarianism](https://arxiv.org/abs/2508.00233)
*Douglas Markant,Subham Sah,Alireza Karduni,Milad Rogha,My Thai,Wenwen Dou*

Main category: cs.HC

TL;DR: 研究发现，通过数据可视化纠正对政治对手的误解可以减少极端主义支持，但可视化方式（如平均值、区间或完整分布）会影响纠正效果。


<details>
  <summary>Details</summary>
Motivation: 政治派系对立部分源于对对手的误解，纠正这些误解可能减少极端主义支持。

Method: 实验比较了不同数据可视化方式（平均值、区间、完整分布）对纠正效果的影响。

Result: 平均值和完整分布可视化纠正效果最强，区间效果较弱；完整分布组回忆最准确。

Conclusion: 数据可视化可纠正误解，但可视化方式对效果有显著影响。

Abstract: Political sectarianism is fueled in part by misperceptions of political
opponents: People commonly overestimate the support for extreme policies among
members of the other party. Research suggests that correcting partisan
misperceptions by informing people about the actual views of outparty members
may reduce one's own expressed support for political extremism, including
partisan violence and anti-democratic actions. The present study investigated
how correction effects depend on different representations of outparty views
communicated through data visualizations. We conducted an experiment with U.S.
based participants from Prolific (N=239 Democrats, N=244 Republicans).
Participants made predictions about support for political violence and
undemocratic practices among members of their political outparty. They were
then presented with data from an earlier survey on the actual views of outparty
members. Some participants viewed only the average response (Mean-Only
condition), while other groups were shown visual representations of the range
of views from 75% of the outparty (Mean+Interval condition) or the full
distribution of responses (Mean+Points condition). Compared to a control group
that was not informed about outparty views, we observed the strongest
correction effects among participants in the Mean-only and Mean+Points
condition, while correction effects were weaker in the Mean+Interval condition.
In addition, participants who observed the full distribution of out-party views
(Mean+Points condition) were most accurate at later recalling the degree of
support among the outparty. Our findings suggest that data visualizations can
be an important tool for correcting pervasive distortions in beliefs about
other groups. However, the way in which variability in outparty views is
visualized can significantly shape how people interpret and respond to
corrective information.

</details>


### [192] [What's Behind the Magic? Audiences Seek Artistic Value in Generative AI's Contributions to a Live Dance Performance](https://arxiv.org/abs/2508.00239)
*Jacqueline Elise Bruen,Myounghoon Jeon*

Main category: cs.HC

TL;DR: 研究发现，当观众不知道作品使用了生成式人工智能（GenAI）时，更容易认可其艺术价值。


<details>
  <summary>Details</summary>
Motivation: 探讨人们对AI创作艺术作品的看法分歧，以及社会背景和用户理解对技术解释的影响。

Method: 开发了两个版本的舞蹈表演（使用或不使用GenAI），并在观众观看前后调查其感知。共有39名参与者。

Result: 观众在不知情的情况下更倾向于认可GenAI作品的艺术价值。

Conclusion: 强调社会背景和用户理解在技术解释中的重要性，呼吁进一步讨论以弥合理解差距。

Abstract: With the development of generative artificial intelligence (GenAI) tools to
create art, stakeholders cannot come to an agreement on the value of these
works. In this study we uncovered the mixed opinions surrounding art made by
AI. We developed two versions of a dance performance augmented by technology
either with or without GenAI. For each version we informed audiences of the
performance's development either before or after a survey on their perceptions
of the performance. There were thirty-nine participants (13 males, 26 female)
divided between the four performances. Results demonstrated that individuals
were more inclined to attribute artistic merit to works made by GenAI when they
were unaware of its use. We present this case study as a call to address the
importance of utilizing the social context and the users' interpretations of
GenAI in shaping a technical explanation, leading to a greater discussion that
can bridge gaps in understanding.

</details>


### [193] [TofuML: A Spatio-Physical Interactive Machine Learning Device for Interactive Exploration of Machine Learning for Novices](https://arxiv.org/abs/2508.00252)
*Wataru Kawabe,Hiroto Fukuda,Akihisa Shitara,Yuri Nakao,Yusuke Sugano*

Main category: cs.HC

TL;DR: TofuML是一个交互式系统，通过物理和空间界面帮助非专家用户更直观地学习机器学习概念，提升用户参与度。


<details>
  <summary>Details</summary>
Motivation: 让非专家用户更容易接触和理解机器学习概念，降低学习门槛。

Method: 使用小型设备和纸质垫作为物理界面，通过直观的互动方式训练和评估声音分类模型。

Result: TofuML比GUI版本更能提升用户参与度，帮助用户更轻松地提供训练数据，并激发他们对ML应用的创意。

Conclusion: TofuML为设计面向广泛用户的交互式ML系统提供了有价值的参考。

Abstract: We introduce TofuML, an interactive system designed to make machine learning
(ML) concepts more accessible and engaging for non-expert users. Unlike
conventional GUI-based systems, TofuML employs a physical and spatial interface
consisting of a small device and a paper mat, allowing users to train and
evaluate sound classification models through intuitive, toy-like interactions.
Through two user studies -- a comparative study against a GUI-based version and
a public event deployment -- we investigated how TofuML impacts users'
engagement in the ML model creation process, their ability to provide
appropriate training data, and their conception of potential applications. Our
results indicated that TofuML enhanced user engagement compared to a GUI while
lowering barriers for non-experts to engage with ML. Users demonstrated
creativity in conceiving diverse ML applications, revealing opportunities to
optimize between conceptual understanding and user engagement. These findings
contribute to developing interactive ML systems/frameworks designed for a wide
range of users.

</details>


### [194] [MetaExplainer: A Framework to Generate Multi-Type User-Centered Explanations for AI Systems](https://arxiv.org/abs/2508.00300)
*Shruthi Chari,Oshani Seneviratne,Prithwish Chakraborty,Pablo Meyer,Deborah L. McGuinness*

Main category: cs.HC

TL;DR: MetaExplainer是一个神经符号框架，通过三阶段流程生成用户为中心的解释，提升AI系统的可解释性和信任度。


<details>
  <summary>Details</summary>
Motivation: 解决模型提供的解释与用户需求之间的差距。

Method: 三阶段流程：问题分解、模型解释生成、自然语言合成，利用Explanation Ontology指导语言模型和解释方法。

Result: 高绩效表现：59.06% F1-score（问题重构）、70%忠实度（模型解释）、67%上下文利用（语言合成）。

Conclusion: MetaExplainer是一个多功能工具，适用于多种领域，提升AI解释性。

Abstract: Explanations are crucial for building trustworthy AI systems, but a gap often
exists between the explanations provided by models and those needed by users.
To address this gap, we introduce MetaExplainer, a neuro-symbolic framework
designed to generate user-centered explanations. Our approach employs a
three-stage process: first, we decompose user questions into machine-readable
formats using state-of-the-art large language models (LLM); second, we delegate
the task of generating system recommendations to model explainer methods; and
finally, we synthesize natural language explanations that summarize the
explainer outputs. Throughout this process, we utilize an Explanation Ontology
to guide the language models and explainer methods. By leveraging LLMs and a
structured approach to explanation generation, MetaExplainer aims to enhance
the interpretability and trustworthiness of AI systems across various
applications, providing users with tailored, question-driven explanations that
better meet their needs. Comprehensive evaluations of MetaExplainer demonstrate
a step towards evaluating and utilizing current state-of-the-art explanation
frameworks. Our results show high performance across all stages, with a 59.06%
F1-score in question reframing, 70% faithfulness in model explanations, and 67%
context-utilization in natural language synthesis. User studies corroborate
these findings, highlighting the creativity and comprehensiveness of generated
explanations. Tested on the Diabetes (PIMA Indian) tabular dataset,
MetaExplainer supports diverse explanation types, including Contrastive,
Counterfactual, Rationale, Case-Based, and Data explanations. The framework's
versatility and traceability from using ontology to guide LLMs suggest broad
applicability beyond the tested scenarios, positioning MetaExplainer as a
promising tool for enhancing AI explainability across various domains.

</details>


### [195] [Evaluating the Efficacy of Large Language Models for Generating Fine-Grained Visual Privacy Policies in Homes](https://arxiv.org/abs/2508.00321)
*Shuning Zhang,Ying Ma,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: 论文探讨了在智能家居环境中利用大语言模型（LLM）实现动态隐私控制的可行性，提出了一种基于多维数据分类和上下文推理的框架，并在模拟环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 智能家居中视觉传感器的普及带来了隐私挑战，现有隐私控制方法静态且粗粒度，无法适应动态和社交复杂的家庭环境。

Method: 提出一个框架，通过多维数据分类（数据敏感性、空间上下文、社交存在）结合LLM实时推理，实现细粒度隐私规则（如选择性对象模糊）。

Result: 在模拟家庭环境中，基于LLM的引擎在机器评估中得分为3.99/5，人类评估中得分为4.00/5，验证了方法的可行性。

Conclusion: LLM可用于动态隐私控制，适应复杂家庭环境，未来可进一步优化模型性能。

Abstract: The proliferation of visual sensors in smart home environments, particularly
through wearable devices like smart glasses, introduces profound privacy
challenges. Existing privacy controls are often static and coarse-grained,
failing to accommodate the dynamic and socially nuanced nature of home
environments. This paper investigates the viability of using Large Language
Models (LLMs) as the core of a dynamic and adaptive privacy policy engine. We
propose a conceptual framework where visual data is classified using a
multi-dimensional schema that considers data sensitivity, spatial context, and
social presence. An LLM then reasons over this contextual information to
enforce fine-grained privacy rules, such as selective object obfuscation, in
real-time. Through a comparative evaluation of state-of-the-art Vision Language
Models (including GPT-4o and the Qwen-VL series) in simulated home settings ,
our findings show the feasibility of this approach. The LLM-based engine
achieved a top machine-evaluated appropriateness score of 3.99 out of 5, and
the policies generated by the models received a top human-evaluated score of
4.00 out of 5.

</details>


### [196] [From Patient Burdens to User Agency: Designing for Real-Time Protection Support in Online Health Consultations](https://arxiv.org/abs/2508.00328)
*Shuning Zhang,Ying Ma,Yongquan `Owen' Hu,Ting Dang,Hong Jia,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: 论文研究了在线医疗咨询平台的隐私风险，提出了一种名为SafeShare的交互技术，通过本地化LLM实时匿名化咨询内容，平衡了实用性与隐私保护。


<details>
  <summary>Details</summary>
Motivation: 在线医疗咨询平台虽然方便，但存在严重的隐私风险，削弱了用户信任。研究旨在了解用户对隐私的感知与期望，并解决用户匿名需求与平台现实之间的脱节问题。

Method: 通过半结构化访谈了解用户需求，开发了SafeShare技术，利用本地化LLM实时匿名化咨询内容，并通过技术评估验证其效果。

Result: SafeShare的PII检测模块在三个数据集上表现出色，在IMCS21数据集上使用Qwen3-4B模型达到了89.64%的准确率。

Conclusion: SafeShare有效解决了用户隐私需求与平台现实之间的脱节问题，为在线医疗咨询平台提供了一种可行的隐私保护方案。

Abstract: Online medical consultation platforms, while convenient, are undermined by
significant privacy risks that erode user trust. We first conducted in-depth
semi-structured interviews with 12 users to understand their perceptions of
security and privacy landscapes on online medical consultation platforms, as
well as their practices, challenges and expectation. Our analysis reveals a
critical disconnect between users' desires for anonymity and control, and
platform realities that offload the responsibility of ``privacy labor''. To
bridge this gap, we present SafeShare, an interaction technique that leverages
localized LLM to redact consultations in real-time. SafeShare balances utility
and privacy through selectively anonymize private information. A technical
evaluation of SafeShare's core PII detection module on 3 dataset demonstrates
high efficacy, achieving 89.64\% accuracy with Qwen3-4B on IMCS21 dataset.

</details>


### [197] [HateBuffer: Safeguarding Content Moderators' Mental Well-Being through Hate Speech Content Modification](https://arxiv.org/abs/2508.00439)
*Subin Park,Jeonghyun Kim,Jeanne Choi,Joseph Seering,Uichin Lee,Sung-Ju Lee*

Main category: cs.HC

TL;DR: HateBuffer是一种工具，旨在通过匿名化仇恨言论目标、改写冒犯性表达来保护内容审核员的心理健康，但实验显示其对情绪和疲劳无显著改善，但提高了审核准确性和用户感知的保护效果。


<details>
  <summary>Details</summary>
Motivation: 在线平台中仇恨言论对内容审核员的心理健康构成威胁，需要工具减轻其负担。

Method: 设计HateBuffer工具，进行用户研究（80人参与模拟审核任务和访谈）。

Result: 使用HateBuffer后，参与者对仇恨言论严重性评分降低，但情绪和疲劳无改善；审核准确性和用户感知保护效果提升。

Conclusion: HateBuffer虽未直接改善心理健康，但展示了文本修改技术在健康内容审核环境中的潜力。

Abstract: Hate speech remains a persistent and unresolved challenge in online
platforms. Content moderators, working on the front lines to review
user-generated content and shield viewers from hate speech, often find
themselves unprotected from the mental burden as they continuously engage with
offensive language. To safeguard moderators' mental well-being, we designed
HateBuffer, which anonymizes targets of hate speech, paraphrases offensive
expressions into less offensive forms, and shows the original expressions when
moderators opt to see them. Our user study with 80 participants consisted of a
simulated hate speech moderation task set on a fictional news platform,
followed by semi-structured interviews. Although participants rated the hate
severity of comments lower while using HateBuffer, contrary to our
expectations, they did not experience improved emotion or reduced fatigue
compared with the control group. In interviews, however, participants described
HateBuffer as an effective buffer against emotional contagion and the
normalization of biased opinions in hate speech. Notably, HateBuffer did not
compromise moderation accuracy and even contributed to a slight increase in
recall. We explore possible explanations for the discrepancy between the
perceived benefits of HateBuffer and its measured impact on mental well-being.
We also underscore the promise of text-based content modification techniques as
tools for a healthier content moderation environment.

</details>


### [198] [Pull Requests From The Classroom: Co-Developing Curriculum And Code](https://arxiv.org/abs/2508.00646)
*Dennis Zyska,Ilia Kuznetsov,Florian Müller,Iryna Gurevych*

Main category: cs.HC

TL;DR: 教育技术与教师教学目标常不匹配，本文通过一个科学写作课程的案例研究，探讨了课程与技术的协同开发，发现协同开发虽能提升软件功能与课程目标的匹配度，但也暴露了可用性和基础设施问题。


<details>
  <summary>Details</summary>
Motivation: 教育技术与教师教学目标的不匹配导致教学效果受损，因此需要探索如何通过协同开发解决这一问题。

Method: 通过一个大学科学写作课程的案例研究，迭代开发了一个定制化的同行反馈系统，支持注释、反馈交换和修订。

Result: 协同开发增强了软件功能与课程目标的匹配度，但也揭示了可用性不足和基础设施问题。

Conclusion: 需要加强教学团队与技术团队的协作，以更好地实现技术与教学目标的匹配。

Abstract: Educational technologies often misalign with instructors' pedagogical goals,
forcing adaptations that compromise teaching efficacy. In this paper, we
present a case study on the co-development of curriculum and technology in the
context of a university course on scientific writing. Specifically, we examine
how a custom-built peer feedback system was iteratively developed alongside the
course to support annotation, feedback exchange, and revision. Results show
that while co-development fostered stronger alignment between software features
and course goals, it also exposed usability limitations and
infrastructure-related frustrations, emphasizing the need for closer
coordination between teaching and technical teams.

</details>


### [199] [The Manipulative Power of Voice Characteristics: Investigating Deceptive Patterns in Mandarin Chinese Female Synthetic Speech](https://arxiv.org/abs/2508.00652)
*Shuning Zhang,Han Chen,Yabo Wang,Yiqun Xu,Jiaqi Bai,Yuanyuan Wu,Shixuan Li,Xin Yi,Chunhui Wang,Hewu Li*

Main category: cs.HC

TL;DR: 研究首次系统调查了中文普通话中基于语音特征的黑暗模式，发现语音特性和场景显著影响用户行为，为伦理设计提供了依据。


<details>
  <summary>Details</summary>
Motivation: 探索语音交互中通过语音特征操纵用户的黑暗模式，填补非英语语言背景下的研究空白。

Method: 通过操纵五种语音特征和三种强度，在不同场景（购物与问答）中评估效果，并进行初步和主要研究。

Result: 语音特征和场景显著影响用户行为（最高达+2027.6%），用户感知和人口统计学因素起中介作用。

Conclusion: 研究揭示了语音特征对用户行为的影响，为语音交互的伦理设计提供了重要见解。

Abstract: Pervasive voice interaction enables deceptive patterns through subtle voice
characteristics, yet empirical investigation into this manipulation lags
behind, especially within major non-English language contexts. Addressing this
gap, our study presents the first systematic investigation into voice
characteristic-based dark patterns employing female synthetic voices in
Mandarin Chinese. This focus is crucial given the prevalence of female personas
in commercial assistants and the prosodic significance in the Chinese language.
Guided by the conceptual framework identifying key influencing factors, we
systematically evaluate effectiveness variations by manipulating voice
characteristics (five characteristics, three intensities) across different
scenarios (shopping vs. question-answering) with different commercial aims. A
preliminary study (N=24) validated the experimental materials and the main
study (N=36) revealed significant behavioral manipulation (up to +2027.6%).
Crucially, the analysis showed that effectiveness varied significantly with
voice characteristics and scenario, mediated by user perception (of tone,
intonation, timbre) and user demographics (individual preferences, though
limited demographic impact). These interconnected findings offer evidence-based
insights for ethical design.

</details>


### [200] [Why Do Decision Makers (Not) Use AI? A Cross-Domain Analysis of Factors Impacting AI Adoption](https://arxiv.org/abs/2508.00723)
*Rebecca Yu,Valerie Chen,Ameet Talwalkar,Hoda Heidari*

Main category: cs.HC

TL;DR: 研究探讨了人类决策者如何与AI系统互动，重点分析了决策者自愿选择使用AI工具（即决策者采纳）的关键因素，并提出了一个AI采纳框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI在各领域的广泛应用，需要评估人类决策者如何与AI系统互动，尤其是理解决策者自愿使用AI工具的条件。

Method: 通过访谈医学、法律、新闻和公共部门的专家，分析当前AI用例和采纳观念，提取关键因素并转化为AI采纳框架。

Result: 研究发现决策者背景、对AI的认知、决策后果及对其他利益相关者的影响是影响AI采纳的关键因素，并通过跨领域案例研究验证了这些因素的解释力。

Conclusion: 研究为支持负责任且情境感知的AI部署提供了实用指导，强调了从决策者角度出发的重要性。

Abstract: Growing excitement around deploying AI across various domains calls for a
careful assessment of how human decision-makers interact with AI-powered
systems. In particular, it is essential to understand when decision-makers
voluntarily choose to consult AI tools, which we term decision-maker adoption.
We interviewed experts across four domains -- medicine, law, journalism, and
the public sector -- to explore current AI use cases and perceptions of
adoption. From these interviews, we identify key factors that shape
decision-maker adoption of AI tools: the decision-maker's background,
perceptions of the AI, consequences for the decision-maker, and perceived
implications for other stakeholders. We translate these factors into an AI
adoption sheet to analyze how decision-makers approach adoption choices through
comparative, cross-domain case studies, highlighting how our factors help
explain inter-domain differences in adoption. Our findings offer practical
guidance for supporting the responsible and context-aware deployment of AI by
better accounting for the decision-maker's perspective.

</details>


### [201] [How LLMs are Shaping the Future of Virtual Reality](https://arxiv.org/abs/2508.00737)
*Süeda Özkaya,Santiago Berrezueta-Guzman,Stefan Wagner*

Main category: cs.HC

TL;DR: 本文综述了大型语言模型（LLMs）在虚拟现实（VR）游戏中的应用，探讨了其在叙事生成、NPC互动等方面的变革，并指出了实时性能、伦理风险等挑战。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs与VR的融合如何提升沉浸式、智能化的数字体验设计。

Method: 分析了2018至2025年间62项同行评审研究，总结了LLMs在VR中的关键应用领域和挑战。

Result: LLMs显著提升了VR环境的真实感、创造力和用户参与度，但需解决实时性能、伦理等问题。

Conclusion: 未来研究方向包括多模态AI、情感计算等，以推动智能和包容性VR系统的负责任发展。

Abstract: The integration of Large Language Models (LLMs) into Virtual Reality (VR)
games marks a paradigm shift in the design of immersive, adaptive, and
intelligent digital experiences. This paper presents a comprehensive review of
recent research at the intersection of LLMs and VR, examining how these models
are transforming narrative generation, non-player character (NPC) interactions,
accessibility, personalization, and game mastering. Drawing from an analysis of
62 peer reviewed studies published between 2018 and 2025, we identify key
application domains ranging from emotionally intelligent NPCs and procedurally
generated storytelling to AI-driven adaptive systems and inclusive gameplay
interfaces. We also address the major challenges facing this convergence,
including real-time performance constraints, memory limitations, ethical risks,
and scalability barriers. Our findings highlight that while LLMs significantly
enhance realism, creativity, and user engagement in VR environments, their
effective deployment requires robust design strategies that integrate
multimodal interaction, hybrid AI architectures, and ethical safeguards. The
paper concludes by outlining future research directions in multimodal AI,
affective computing, reinforcement learning, and open-source development,
aiming to guide the responsible advancement of intelligent and inclusive VR
systems.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [202] [Data-Driven Motion Planning for Uncertain Nonlinear Systems](https://arxiv.org/abs/2508.00154)
*Babak Esmaeili,Hamidreza Modares,Stefano Di Cairano*

Main category: eess.SY

TL;DR: 提出了一种基于数据驱动的非线性系统运动规划框架，通过构建重叠不变多面体序列实现安全路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖系统动力学模型，而本文方法仅需数据即可计算安全区域并设计状态反馈控制器，适用于复杂非线性系统。

Method: 围绕随机采样的路径点构建凸可行区域，通过数据驱动的线性矩阵不等式问题学习椭球不变集及其局部状态反馈增益，并用多面体近似其凸包。

Result: 仿真验证了该方法在复杂非线性系统中实现安全、动态可行路径的有效性。

Conclusion: 该方法无需系统动力学模型，仅依赖数据即可实现安全运动规划，适用于复杂非线性系统。

Abstract: This paper proposes a data-driven motion-planning framework for nonlinear
systems that constructs a sequence of overlapping invariant polytopes. Around
each randomly sampled waypoint, the algorithm identifies a convex admissible
region and solves data-driven linear-matrix-inequality problems to learn
several ellipsoidal invariant sets together with their local state-feedback
gains. The convex hull of these ellipsoids, still invariant under a
piece-wise-affine controller obtained by interpolating the gains, is then
approximated by a polytope. Safe transitions between nodes are ensured by
verifying the intersection of consecutive convex-hull polytopes and introducing
an intermediate node for a smooth transition. Control gains are interpolated in
real time via simplex-based interpolation, keeping the state inside the
invariant polytopes throughout the motion. Unlike traditional approaches that
rely on system dynamics models, our method requires only data to compute safe
regions and design state-feedback controllers. The approach is validated
through simulations, demonstrating the effectiveness of the proposed method in
achieving safe, dynamically feasible paths for complex nonlinear systems.

</details>


### [203] [Integrating Opinion Dynamics into Safety Control for Decentralized Airplane Encounter Resolution](https://arxiv.org/abs/2508.00156)
*Shuhao Qi,Zhiqi Tang,Zhiyong Sun,Sofie Haesaert*

Main category: eess.SY

TL;DR: 论文提出将生物启发的非线性意见动力学整合到飞机安全控制框架中，以解决空中交通拥堵中的冲突问题，确保安全和无阻塞的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着空域日益拥堵，分散式冲突解决方法变得至关重要。现有的安全控制器虽能防止危险碰撞，但无法保证快速解决冲突，导致飞机长时间受阻。

Method: 通过将生物启发的非线性意见动力学引入安全控制框架，实现协作决策和无通信依赖的快速安全协调。

Result: 大量仿真结果表明，该方法显著提高了飞行效率和安全性。

Conclusion: 研究为飞机自主控制器的设计提供了实用见解。

Abstract: As the airspace becomes increasingly congested, decentralized conflict
resolution methods for airplane encounters have become essential. While
decentralized safety controllers can prevent dangerous midair collisions, they
do not always ensure prompt conflict resolution. As a result, airplane progress
may be blocked for extended periods in certain situations. To address this
blocking phenomenon, this paper proposes integrating bio-inspired nonlinear
opinion dynamics into the airplane safety control framework, thereby
guaranteeing both safety and blocking-free resolution. In particular, opinion
dynamics enable the safety controller to achieve collaborative decision-making
for blocking resolution and facilitate rapid, safe coordination without relying
on communication or preset rules. Extensive simulation results validate the
improved flight efficiency and safety guarantees. This study provides practical
insights into the design of autonomous controllers for airplanes.

</details>


### [204] [Adaptive Compensation of Nonlinear Friction in Mechanical Systems Without Velocity Measurement](https://arxiv.org/abs/2508.00175)
*Jose Guadalupe Romero,Romeo Ortega,Leyan Fang,Alexey Bobtsov*

Main category: eess.SY

TL;DR: 提出了一种不依赖速度测量的全局收敛跟踪控制器，用于补偿机械系统中的静摩擦和库仑摩擦。


<details>
  <summary>Details</summary>
Motivation: 摩擦是机械系统中普遍存在的现象，现有补偿方法依赖速度测量和复杂数学模型，限制了实际应用。

Method: 采用基于浸入和不变性的自适应速度观测器进行摩擦补偿。

Result: 首次实现了全局收敛的摩擦补偿方案，并通过仿真验证了其在LuGre模型中的有效性。

Conclusion: 该方法解决了传统摩擦补偿的局限性，为无需速度测量的控制提供了新思路。

Abstract: Friction is an unavoidable phenomenon that exists in all mechanical systems
incorporating parts with relative motion. It is well-known that friction is a
serious impediment for precise servo control, hence the interest to devise a
procedure to compensate for it -- a subject that has been studied by many
researchers for many years. The vast majority of friction compensation schemes
reported in the literature rely on the availability of velocity measurements,
an information that is hard to obtain. A second limitation of the existing
procedures is that they rely on mathematical models of friction that contain
several unknown parameters, some of them entering nonlinearly in the dynamic
equations. In this paper we propose a globally convergent tracking controller
for a mechanical system perturbed by static and Coulomb friction, which is a
reliable mathematical model of the friction phenomenon, that does not rely one
measurement of velocity. The key component is an immersion and invariance-based
adaptive speed observer, used for the friction compensation. To the best of our
knowledge, this is the first globally convergent solution to this challenging
problem. We also present simulation results of the application of our observer
for systems affected by friction, which is described by the more advanced LuGre
model.

</details>


### [205] [Optimal Messaging Strategy for Incentivizing Agents in Dynamic Systems](https://arxiv.org/abs/2508.00188)
*Renyan Sun,Ashutosh Nayyar*

Main category: eess.SY

TL;DR: 论文研究了设计者通过选择性信息披露影响代理行为的动态系统，提出了一种基于逆向归纳法和线性规划的最优策略计算方法。


<details>
  <summary>Details</summary>
Motivation: 设计者希望通过信息控制和直接行动激励代理遵循特定策略，以最大化自身收益。

Method: 采用逆向归纳算法和线性规划，计算设计者的最优信息传递和行动策略。

Result: 在特定信息结构假设下，证明了最优策略的可计算性。

Conclusion: 该方法为设计者在动态系统中激励代理行为提供了有效工具。

Abstract: We consider a finite-horizon discrete-time dynamic system jointly controlled
by a designer and one or more agents, where the designer can influence the
agents' actions through selective information disclosure. At each time step,
the designer sends a message to the agent(s) from a prespecified message space.
The designer may also take an action that directly influences system dynamics
and rewards. Each agent uses its received message (and its own information) to
choose its action. We are interested in the setting where the designer would
like to incentivize each agent to play a specific strategy. We consider a
notion of incentive compatibility that is based on sequential rationality at
each realization of the common information between the designer and the
agent(s). Our objective is to find a messaging and action strategy for the
designer that maximizes its total expected reward while incentivizing each
agent to follow a prespecified strategy. Under certain assumptions on the
information structure of the problem, we show that an optimal designer strategy
can be computed using a backward inductive algorithm that solves a family of
linear programs.

</details>


### [206] [Neural Co-state Projection Regulator: A Model-free Paradigm for Real-time Optimal Control with Input Constraints](https://arxiv.org/abs/2508.00283)
*Lihan Lian,Uduak Inyang-Udoh*

Main category: eess.SY

TL;DR: 论文提出了一种基于神经网络的共态投影调节器（NCPR），用于解决非线性控制系统的优化问题，具有更好的泛化性和采样效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统强化学习方法在样本效率、奖励设计和泛化性方面的不足，尤其是在输入约束下的表现。

Method: 结合Pontryagin最小原则，使用神经网络预测共态轨迹，并通过轻量级二次规划实时计算控制动作。

Result: 在单轮模型机器人跟踪和摆锤摆动任务中，NCPR表现出优于强化学习的泛化性和采样效率。

Conclusion: NCPR为模型无关的优化控制提供了一种高效且泛化性强的解决方案。

Abstract: Learning-based approaches, notably Reinforcement Learning (RL), have shown
promise for solving optimal control tasks without explicit system models.
However, these approaches are often sample-inefficient, sensitive to reward
design and hyperparameters, and prone to poor generalization, especially under
input constraints. To address these challenges, we introduce the neural
co-state projection regulator (NCPR), a model-free learning-based optimal
control framework that is grounded in Pontryagin's Minimum Principle (PMP) and
capable of solving quadratic regulator problems in nonlinear control-affine
systems with input constraints. In this framework, a neural network (NN) is
trained in a self-supervised setting to take the current state of the system as
input and predict a finite-horizon trajectory of projected co-states (i.e., the
co-state weighted by the system's input gain). Subsequently, only the first
element of the NN's prediction is extracted to solve a lightweight quadratic
program (QP). This workflow is executed in a feedback control setting, allowing
real-time computation of control actions that satisfy both input constraints
and first-order optimality conditions.
  We test the proposed learning-based model-free quadratic regulator on (1) a
unicycle model robot reference tracking problem and (2) a pendulum swing-up
task. For comparison, reinforcement learning is used on both tasks; and for
context, a model-based controller is used in the unicycle model example. Our
method demonstrates superior generalizability in terms of both unseen system
states and varying input constraints, and also shows improved sampling
efficiency.

</details>


### [207] [Low-dimensional observer design for stable linear systems by model reduction](https://arxiv.org/abs/2508.00609)
*M. F. Shakib,M. Khalil,R. Postoyan*

Main category: eess.SY

TL;DR: 本文提出了一种针对稳定、单输入单输出连续时间线性时不变系统的低维观测器设计方法，通过模型降阶技术实现状态估计。


<details>
  <summary>Details</summary>
Motivation: 针对高维系统状态估计的复杂性，提出一种基于降阶模型的低维观测器设计方法，以简化计算并保持估计精度。

Method: 利用矩匹配技术进行模型降阶，基于降阶模型设计低维观测器，实现对原系统状态的估计。

Result: 观测器在特定输入类下实现精确渐近状态重构，对一般输入具有指数输入-状态稳定性，保证估计误差有界。数值仿真验证了方法的有效性。

Conclusion: 该方法通过降阶模型设计低维观测器，有效简化了状态估计问题，同时保证了估计精度和稳定性。

Abstract: This paper presents a low-dimensional observer design for stable,
single-input single-output, continuous-time linear time-invariant (LTI)
systems. Leveraging the model reduction by moment matching technique, we
approximate the system with a reduced-order model. Based on this reduced-order
model, we design a low-dimensional observer that estimates the states of the
original system. We show that this observer establishes exact asymptotic state
reconstruction for a given class of inputs tied to the observer's dimension.
Furthermore, we establish an exponential input-to-state stability property for
generic inputs, ensuring a bounded estimation error. Numerical simulations
confirm the effectiveness of the approach for a benchmark model reduction
problem.

</details>


### [208] [Cyber-Physical Co-Simulation of Load Frequency Control under Load-Altering Attacks](https://arxiv.org/abs/2508.00637)
*Michał Forystek,Andrew D. Syrmakesis,Alkistis Kontou,Panos Kotsampopoulos,Nikos D. Hatziargyriou,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 论文提出了一种开源协同仿真环境，用于分析电力网格中的动态负载改变攻击（DLAAs）对负载频率控制（LFC）和低频减载（UFLS）的影响。


<details>
  <summary>Details</summary>
Motivation: 随着信息通信技术（ICT）设备在电力网格中的集成，电网面临新的网络威胁，尤其是动态负载改变攻击（DLAAs）对电网稳定性的威胁。

Method: 开发了一个开源协同仿真环境，模拟电力网格及其通信网络，并实现电网保护机制。

Result: 该环境能够全面分析DLAAs在LFC和UFLS场景中的影响。

Conclusion: 该研究为电力网格网络安全研究提供了重要工具，有助于理解和应对DLAAs等新型网络威胁。

Abstract: Integrating Information and Communications Technology (ICT) devices into the
power grid brings many benefits. However, it also exposes the grid to new
potential cyber threats. Many control and protection mechanisms, such as Load
Frequency Control (LFC), responsible for maintaining nominal frequency during
load fluctuations and Under Frequency Load Shedding (UFLS) disconnecting
portion of the load during an emergency, are dependent on information exchange
through the communication network. The recently emerging Load Altering Attacks
(LAAs) utilize a botnet of high-wattage devices to introduce load fluctuation.
In their dynamic form (DLAAs), they manipulate the load in response to live
grid frequency measurements for increased efficiency, posing a notable threat
to grid stability. Recognizing the importance of communication networks in
power grid cyber security research, this paper presents an open-source
co-simulation environment that models the power grid with the corresponding
communication network, implementing grid protective mechanisms. This setup
allows the comprehensive analysis of the attacks in concrete LFC and UFLS
scenarios.

</details>


### [209] [Petri Net Modeling and Deadlock-Free Scheduling of Attachable Heterogeneous AGV Systems](https://arxiv.org/abs/2508.00724)
*Boyu Li,Zhengchen Li,Weimin Wu,Mengchu Zhou*

Main category: eess.SY

TL;DR: 本文研究了由可附着异构自动导引车（AGV）组成的物料运输系统中的新调度问题，提出了一种基于Petri网的建模和优化方法，以确保无死锁的高效调度。


<details>
  <summary>Details</summary>
Motivation: 随着自动化和灵活性需求的增加，异构AGV的广泛应用带来了新的调度挑战，尤其是在可附着AGV的协作中容易引发死锁问题。

Method: 引入Petri网建模AGV调度，提出基于Petri网理论的触发驱动解码方法，并结合死锁检测与预防策略。开发了一种基于Petri网的元启发式算法，嵌入自适应大邻域搜索框架。

Result: 通过真实工业数据的数值实验验证了算法的有效性，优于工程实践中的调度策略、精确求解器和四种先进元启发式算法。

Conclusion: 提出的方法不仅解决了可附着异构AGV调度中的死锁问题，还显著提升了计算效率和调度性能。

Abstract: The increasing demand for automation and flexibility drives the widespread
adoption of heterogeneous automated guided vehicles (AGVs). This work intends
to investigate a new scheduling problem in a material transportation system
consisting of attachable heterogeneous AGVs, namely carriers and shuttles. They
can flexibly attach to and detach from each other to cooperatively execute
complex transportation tasks. While such collaboration enhances operational
efficiency, the attachment-induced synchronization and interdependence render
the scheduling coupled and susceptible to deadlock. To tackle this challenge,
Petri nets are introduced to model AGV schedules, well describing the
concurrent and sequential task execution and carrier-shuttle synchronization.
Based on Petri net theory, a firing-driven decoding method is proposed, along
with deadlock detection and prevention strategies to ensure deadlock-free
schedules. Furthermore, a Petri net-based metaheuristic is developed in an
adaptive large neighborhood search framework and incorporates an effective
acceleration method to enhance computational efficiency. Finally, numerical
experiments using real-world industrial data validate the effectiveness of the
proposed algorithm against the scheduling policy applied in engineering
practice, an exact solver, and four state-of-the-art metaheuristics. A
sensitivity analysis is also conducted to provide managerial insights.

</details>


### [210] [Learning to optimize with guarantees: a complete characterization of linearly convergent algorithms](https://arxiv.org/abs/2508.00775)
*Andrea Martin,Ian R. Manchester,Luca Furieri*

Main category: eess.SY

TL;DR: 论文提出了一种方法，通过改进线性收敛算法的平均性能，同时保留其最坏情况下的收敛保证，适用于特定目标问题集。


<details>
  <summary>Details</summary>
Motivation: 在高风险工程应用中，优化算法需要具备最坏情况下的理论保证，但为最坏情况设计通常会牺牲实际常见问题实例的性能。

Method: 从基线线性收敛算法出发，推导出所有且仅能保持其收敛性质的修改规则，适用于非光滑复合优化问题。

Result: 该方法在解决迭代预算紧张的优化问题时表现出色，如应用于病态线性方程组和线性系统的模型预测控制。

Conclusion: 研究提供了一种增强现有算法性能的方法，同时不损害其理论保证，适用于多种优化问题。

Abstract: In high-stakes engineering applications, optimization algorithms must come
with provable worst-case guarantees over a mathematically defined class of
problems. Designing for the worst case, however, inevitably sacrifices
performance on the specific problem instances that often occur in practice. We
address the problem of augmenting a given linearly convergent algorithm to
improve its average-case performance on a restricted set of target problems -
for example, tailoring an off-the-shelf solver for model predictive control
(MPC) for an application to a specific dynamical system - while preserving its
worst-case guarantees across the entire problem class. Toward this goal, we
characterize the class of algorithms that achieve linear convergence for
classes of nonsmooth composite optimization problems. In particular, starting
from a baseline linearly convergent algorithm, we derive all - and only - the
modifications to its update rule that maintain its convergence properties. Our
results apply to augmenting legacy algorithms such as gradient descent for
nonconvex, gradient-dominated functions; Nesterov's accelerated method for
strongly convex functions; and projected methods for optimization over
polyhedral feasibility sets. We showcase effectiveness of the approach on
solving optimization problems with tight iteration budgets in application to
ill-conditioned systems of linear equations and MPC for linear systems.

</details>
