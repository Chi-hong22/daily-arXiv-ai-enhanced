<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 156]
- [eess.SY](#eess.SY) [Total: 25]
- [cs.HC](#cs.HC) [Total: 20]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.RO](#cs.RO) [Total: 47]
- [cs.LG](#cs.LG) [Total: 110]
- [cs.SD](#cs.SD) [Total: 11]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.NE](#cs.NE) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: 提出基于深度学习的实时吸烟检测系统，用于消防出口区域的CCTV监控，在多种环境下实现高性能检测，并在边缘设备上验证了实时处理能力。


<details>
  <summary>Details</summary>
Motivation: 由于消防安全的关键要求，需要开发能够实时检测吸烟行为的监控系统，特别是在光线条件较差的消防出口区域。

Method: 使用包含8,124张图像的数据集，评估了YOLOv8、YOLOv11和YOLOv12三种先进目标检测模型，并基于YOLOv8开发了针对监控场景优化的自定义模型，在多种边缘设备上进行多线程性能评估。

Result: 提出的模型表现最佳，召回率达到78.90%，mAP@50达到83.70%，在Jetson Xavier NX设备上处理速度为52-97毫秒/推理，满足实时性要求。

Conclusion: 该系统为公共安全监控和自动合规监管提供了一个强大且适应性强的平台，特别适用于时间敏感的操作场景。

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [2] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 该论文提出了一种仅使用程序化数据训练表征模型的方法，通过视觉记忆（参考图像嵌入数据库）在视觉相似性、分类和语义分割任务上实现强性能，无需额外训练，同时保持与真实世界图像的完全隔离。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉记忆方法无法完全隔离真实世界图像的问题，探索仅使用程序化数据训练模型的可能性，同时保持与真实数据训练模型相当的性能。

Method: 使用纯程序化数据训练表征模型，构建显式的视觉记忆数据库（参考图像嵌入），在推理时通过检索记忆库来完成各种视觉任务，无需对下游任务进行额外训练。

Result: 在多个基准测试中表现优异：NIGHTS视觉相似性仅差1%；CUB200和Flowers102细粒度分类分别超越8%和15%；ImageNet-1K分类差距在10%以内；COCO零样本分割R²差距在10%以内。

Conclusion: 程序化数据模型能够实现与真实数据模型相近的性能，但同一物体不同部分的表征存在差异，导致记忆检索错误，这是性能差距的主要原因。

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [3] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 本文首次系统评估了四种眼科基础模型（RETFound、VisionFM、RetiZero、DINORET）在眼科疾病和全身性疾病预测任务中的表现，并提出了两种融合策略。结果显示DINORET和RetiZero表现最佳，RetiZero在外部数据集上泛化能力更强，门控融合策略在部分疾病预测中有改进。


<details>
  <summary>Details</summary>
Motivation: 虽然基础模型在医学图像分析中显示出巨大潜力，但眼科领域缺乏对现有基础模型的系统性评估，不清楚哪种模型表现最好、在不同任务中的表现如何，以及模型融合是否能带来改进。

Method: 提出了FusionFM评估框架，对四种最先进的基础模型进行标准化评估，涵盖青光眼、糖尿病视网膜病变、年龄相关性黄斑变性等眼科疾病，以及糖尿病和高血压等全身性疾病的视网膜图像预测。采用两种融合方法整合不同模型，使用AUC和F1指标进行评估。

Result: DINORET和RetiZero在眼科和全身性疾病任务中表现最优，RetiZero在外部数据集上表现出更强的泛化能力。门控融合策略在青光眼、AMD和高血压预测中提供了适度改进。但预测全身性疾病（特别是外部队列中的高血压）仍然具有挑战性。

Conclusion: 研究提供了基于证据的眼科基础模型评估，展示了模型融合的益处，并指出了增强临床适用性的策略，为未来眼科AI模型的发展提供了重要参考。

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [4] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF是一个统一的多模态深度学习框架，能够通过点云和多视角图像的融合编码来重建多个牙颌面硬组织，解决了现有单模态方法的局限性，在几何精度、结构完整性和空间准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 牙颌面硬组织缺损严重影响患者的生理功能、面部美观和心理健康，但当前深度学习模型仅限于单组织场景和特定模态的成像输入，导致泛化性差，需要在解剖保真度、计算效率和跨组织适应性之间进行权衡。

Method: 提出了UniDCF框架，通过点云和多视角图像的多模态融合编码，利用每种模态的互补优势，并引入基于分数的去噪模块来细化表面平滑度。构建了最大的多模态数据集，包含6,609名患者的口内扫描、CBCT和CT数据，共54,555个标注实例。

Result: 评估表明UniDCF在几何精度、结构完整性和空间准确性方面优于现有最先进方法。临床模拟显示UniDCF将重建设计时间减少了99%，临床医生接受率超过94%。

Conclusion: UniDCF能够实现快速、自动化、高保真度的重建，支持个性化和精确的修复治疗，简化临床工作流程，并改善患者治疗效果。

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [5] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5是Ovis2的升级版本，专注于原生分辨率视觉感知和强大多模态推理能力。它采用原生分辨率视觉Transformer处理图像，避免固定分辨率分块带来的质量下降，并通过反思机制增强推理能力。模型经过五阶段课程训练，在OpenCompass多模态排行榜上取得78.3分，在40B参数以下开源MLLM中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 为了解决固定分辨率图像处理导致的细节丢失问题，以及提升多模态模型的推理能力，特别是在处理视觉密集内容（如复杂图表）时需要同时保持精细细节和全局布局的完整性。

Method: 采用原生分辨率视觉Transformer处理可变分辨率图像；引入反思机制（包括自检和修订）作为可选的"思考模式"；通过五阶段课程训练（基础视觉和多模态预训练、大规模指令调优、DPO和GRPO对齐与推理增强）；使用多模态数据打包和混合并行技术提升训练效率。

Result: Ovis2.5-9B在OpenCompass多模态排行榜上平均得分78.3，相比前代Ovis2-8B有显著提升，在40B参数以下开源MLLM中达到最先进水平；Ovis2.5-2B得分73.9，在其规模级别建立新的SOTA；在STEM基准测试、接地任务和视频任务上表现领先，在复杂图表分析方面达到开源SOTA。

Conclusion: Ovis2.5通过原生分辨率处理和反思推理机制，在多模态理解和推理能力方面取得了显著进步，特别是在处理视觉密集内容时表现出色。模型在保持高性能的同时提供了不同规模的选择，适合资源受限的端侧部署场景。

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [6] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: VideoAVE是首个公开的视频到文本电商属性值提取数据集，覆盖14个领域和172个属性，包含224k训练数据和25k评估数据，通过CLIP-MoE过滤系统确保数据质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有AVE数据集缺乏视频支持、属性覆盖不足和公开可用性的问题，填补视频到文本电商属性值提取的研究空白。

Method: 提出CLIP-based Mixture of Experts过滤系统(CLIP-MoE)来移除不匹配的视频-产品对，构建高质量数据集，并建立综合基准评估最先进的视频视觉语言模型。

Result: 视频到文本AVE仍然是一个具有挑战性的问题，特别是在开放设置下，现有模型在利用有效时序信息方面仍有改进空间。

Conclusion: VideoAVE为视频属性值提取研究提供了重要资源，展示了该领域的挑战性，并为开发更先进的视觉语言模型指明了方向。

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [7] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 研究表明仅使用二阶几何特征（平面曲率大小、曲率符号和梯度方向）就能驱动多层感知机实现手写字符识别，在MNIST数字上达到97%准确率，在EMNIST字母上达到89%准确率。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以不使用卷积神经网络，仅通过二阶几何特征就能实现有效的手写字符识别，提供一种可解释的替代方案。

Method: 使用手工设计的三个特征图（曲率大小、曲率符号和梯度方向）作为输入，构建基于曲率-方向的多层感知机分类器。

Result: 在MNIST数字数据集上达到97%准确率，在EMNIST字母数据集上达到89%准确率，证明了曲率特征的有效性。

Conclusion: 曲率基础的表征对于手写字符图像具有强大的判别能力，深度学习优势可以通过可解释的手工设计特征实现。

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [8] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 本文提出双管齐下的方法来改进多模态仇恨内容检测：通过提示优化框架提升模型性能，以及通过多模态数据增强管道生成反事实中性meme来减少虚假相关性


<details>
  <summary>Details</summary>
Motivation: 现代网络充斥着多模态内容，仇恨meme检测面临挑战，因为有害意图往往通过文本和图像的微妙互动以幽默或讽刺形式呈现。现有视觉语言模型缺乏细粒度监督支持且容易受到隐式仇恨言论影响

Method: 1) 提示优化框架：系统变化提示结构、监督粒度和训练模态；2) 多模态数据增强管道：使用多智能体LLM-VLM设置生成2,479个反事实中性meme，通过隔离和重写仇恨模态

Result: 结构化提示即使在小型模型中也提高了鲁棒性，InternVL2在二元和缩放设置中均获得最佳F1分数。数据增强管道成功减少了虚假相关性并提高了分类器泛化能力

Conclusion: 提示结构和数据组成与模型大小同等重要，针对性增强可以支持更可信和上下文敏感的仇恨检测，为构建合成数据训练鲁棒公平的视觉语言模型提供了新方向

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [9] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 该论文研究了高斯曲率在3D表面建模中的作用，发现它提供了稀疏紧凑的表面描述，可作为几何先验改进3D重建，并可能作为立体视觉方法的无监督度量指标。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的计算机视觉方法缺乏显式的3D几何模型，无法直接分析、跨模态迁移或进行受控实验。研究者希望探索高斯曲率这一不变量在3D建模中的价值。

Method: 使用Middlebury立体数据集进行研究，分析高斯曲率在3D表面建模中的多个作用：作为稀疏紧凑描述符、隐含在现有方法中、作为几何先验、以及作为无监督度量指标。

Result: 研究发现高斯曲率能够提供稀疏而紧凑的3D表面描述；现有最先进的单目和立体方法似乎隐含地考虑了高斯曲率；高斯曲率可作为几何先验来改进3D表面重建；可能作为立体方法的无监督度量指标。

Conclusion: 高斯曲率在3D表面建模中具有重要价值，可以作为显式几何模型来弥补纯数据驱动方法的不足，为3D重建提供可分析、可迁移和可控制的几何基础。

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [10] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 本研究系统评估了多种图像到图转换方法对GNN图级异常检测的影响，发现颜色特征表现最佳，结合形状和纹理特征可进一步提升性能，在皮肤镜图像上取得了有竞争力的检测效果。


<details>
  <summary>Details</summary>
Motivation: 虽然GNN已广泛应用于图像衍生图的机器学习任务，但缺乏对图像到图转换方法在GNN图级异常检测中有效性的系统比较研究。

Method: 系统评估多种分割方案、边构建策略以及基于颜色、纹理和形状描述符的节点特征集，使用最先进的GLAD模型在皮肤镜图像上进行广泛实验，涵盖无监督、弱监督和全监督三种模式。

Result: 颜色描述符单独使用时性能最佳，结合形状和纹理特征能持续提升检测效果。最佳无监督配置达到0.805 AUC-ROC，弱监督提升至0.872，全监督达到0.914 AUC-ROC。

Conclusion: 图像到图转换方法对GNN图级异常检测性能有显著影响，多特征融合能有效提升检测效果，且无需依赖预训练骨干网络即可达到与图像方法相当的性能。

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [11] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: 这篇综述论文系统性地分类和评估了基于Transformer的架构在无人机系统中的应用，包括注意力机制、CNN-Transformer混合模型、强化学习Transformers和大语言模型，提供了统一的分类法、比较分析和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型的快速发展，无人机系统的感知、决策和自主性得到了显著提升，需要系统地梳理和评估这些新兴技术在无人机领域的应用现状和发展趋势。

Method: 采用系统性综述方法，对基于Transformer的无人机模型进行统一分类，包括注意力机制、混合架构、强化学习应用和大语言模型集成，通过结构化表格和性能基准进行比较分析。

Result: 构建了Transformer在无人机应用中的统一分类体系，识别了在精准农业、自主导航等新兴应用中的进展，总结了关键数据集、仿真器和评估指标，并揭示了计算效率和实时部署方面的挑战。

Conclusion: 该综述为研究人员和从业者提供了Transformer驱动无人机技术的全面指南，指出了当前研究的空白和未来发展方向，特别是在计算优化和实际部署方面需要进一步突破。

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [12] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: ComplicitSplat是一种针对3D高斯溅射(3DGS)的黑盒攻击方法，通过利用标准3DGS着色技术创建视角特异性伪装，在特定视角下嵌入对抗性内容，无需访问模型架构或权重。


<details>
  <summary>Details</summary>
Motivation: 随着3DGS在安全关键任务中的快速应用，需要研究攻击者如何篡改图像造成危害，暴露3DGS在自主导航等关键应用中的安全风险。

Method: 利用标准3DGS着色方法创建视角特异性伪装，使颜色和纹理随视角变化，在特定视角下嵌入对抗性内容，实现黑盒攻击。

Result: 实验表明ComplicitSplat能成功攻击多种流行检测器（单阶段、多阶段和基于transformer的模型），在真实物体捕获和合成场景中均有效。

Conclusion: 这是首个针对下游目标检测器的3DGS黑盒攻击，揭示了自主导航等关键机器人系统应用中的新型安全风险。

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [13] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 本文评估了医学影像基础模型在图像质量变化下的标签效率，发现图像质量分布及微调-测试不匹配显著影响模型性能，高质量图像对微调至关重要，质量分布一致性决定了预训练模型的优势。


<details>
  <summary>Details</summary>
Motivation: 研究医学影像基础模型在真实世界图像质量变化情况下的标签效率表现，探索图像质量分布对模型泛化能力的影响。

Method: 使用ProFound（前列腺MRI领域专用视觉基础模型），系统性地改变微调和测试集中高/低质量图像比例，评估不同下游任务（自动放射学报告和前列腺癌检测）的性能。

Result: 图像质量分布不匹配导致下游性能显著差异；微调集中足够高质量图像对保持强性能至关重要；质量比例一致时，微调所需标注数据远少于从头训练；缺乏高质量微调数据时，预训练模型可能不如非预训练模型。

Conclusion: 需要评估和对齐微调与部署的质量分布，为特定下游任务制定微调数据质量标准，量化图像质量以充分实现基础模型的数据和计算效率优势。

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [14] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: AdaRing是一个基于跨层张量环分解的视觉语言微调框架，通过整合多样化适配器实现超轻量参数高效适应，在减少90%训练参数的同时达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有适配器方法存在两个主要限制：1）由于忽略跨层冗余而导致压缩率有限；2）同质适配器的表示能力有限。需要解决这些限制以实现更高效的视觉语言模型微调。

Method: 提出基于跨层张量环分解（TRD）的框架，利用张量级低秩性将适配器表示为层共享张量核心和层特定切片，并通过泛化感知微调指导多样化秩驱动适配器协作。

Result: 实验表明AdaRing在减少平均训练参数90%的同时，达到了最先进的性能表现。

Conclusion: AdaRing框架成功解决了现有适配器方法的局限性，通过跨层张量分解和多样化适配器协作，实现了超轻量且高性能的视觉语言模型参数高效适应。

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [15] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: 提出EVTP-IV方法，通过视觉token剪枝在保持精度的同时实现5倍视频任务和3.5倍图像任务加速


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在指令视觉分割任务中推理成本过高，特别是视频任务，需要降低计算开销

Method: 基于k-center算法整合空间信息选择紧凑且空间代表性的token子集，提供信息论分析支持

Result: 仅使用20%的token即可达到相当精度，视频任务加速5倍，图像任务加速3.5倍，优于现有剪枝方法

Conclusion: 提出的视觉token剪枝方法能有效加速指令视觉分割任务，在保持性能的同时显著提升效率

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [16] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: 提出了基于纯CNN的大核调制网络（LKMN），通过增强部分大核块和交叉门前馈网络，在保持低延迟的同时实现非局部特征提取，在轻量级超分辨率任务中达到了性能与效率的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限场景下图像超分辨率的需求，传统CNN缺乏非局部特征捕获能力，而Transformer推理速度慢，需要一种既能保持低延迟又能进行非局部建模的轻量级模型。

Method: LKMN包含两个核心组件：增强部分大核块（EPLKB）使用通道混洗增强通道间交互，结合通道注意力机制，在部分通道上应用大核条带卷积进行非局部特征提取；交叉门前馈网络（CGFN）通过可学习缩放因子动态调整输入、局部和非局部特征之间的差异，采用交叉门策略调制和融合这些特征。

Result: 在Manga109数据集上4倍超分辨率任务中，LKMN-L比DAT-light提升0.23 dB PSNR，推理速度快约4.8倍，超越了现有最先进的轻量级超分辨率模型。

Conclusion: LKMN成功实现了纯CNN架构下的非局部特征建模，在保持低延迟的同时显著提升了超分辨率性能，为资源受限场景提供了高效的解决方案。

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [17] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: 使用仅包含水平和垂直Sobel导数作为输入的MLP网络，在MNIST和EMNIST Letters数据集上分别达到98%和92%的准确率，接近CNN性能但更简单透明


<details>
  <summary>Details</summary>
Motivation: 探索一阶边缘图是否足以驱动全连接MLP进行手写字符识别，作为CNN的替代方案

Method: 仅使用水平和垂直Sobel导数作为输入，训练全连接多层感知机(MLP)网络

Result: 在MNIST数字上达到98%准确率，在EMNIST字母上达到92%准确率，接近CNN性能但内存占用更小、特征更透明

Conclusion: 手写字符图像中的类判别信息大部分已被一阶梯度捕获，边缘感知MLP是HCR的一个有吸引力的选择

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [18] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: 提出了在线视频定位新任务OVG-HQ，支持文本、图像、视频片段等多模态查询，解决了传统视频定位在流媒体和视觉查询场景的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统视频定位任务在处理流媒体视频和使用视觉线索的查询时存在不足，需要开发能够在线处理混合模态查询的新方法。

Method: 提出OVG-HQ-Unify统一框架，包含参数记忆块(PMB)来保留历史知识，以及跨模态蒸馏策略来平衡不同模态的学习。构建了QVHighlights-Unify数据集并设计了在线评估指标。

Result: 实验表明OVG-HQ-Unify优于现有模型，为在线混合模态视频定位提供了有效解决方案。

Conclusion: 该工作填补了在线视频定位领域的空白，提出的框架和方法能够有效处理混合模态查询，在准确性和效率方面都表现出色。

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [19] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl是一个轻量级非侵入式插件，通过检测-抑制范式来防止文本到图像模型生成有害内容，在保持安全性和保真度方面优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有安全方法（如提示重写或模型微调）在安全性和保真度之间存在权衡，基于定位的方法依赖显式概念替换可能导致语义不协调

Method: 采用检测-抑制范式，首先精确定位不安全内容，然后抑制有害语义而非硬性替换，使用DPO训练策略利用图像级偏好数据训练模块

Result: 在安全有效性和保真度保持方面显著优于最先进方法

Conclusion: 解耦的基于抑制的控制是构建更负责任生成模型的高效且可扩展方向

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [20] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: TimeSenCLIP是一个轻量级框架，通过利用单个像素的时序和光谱信息进行土地利用分类，减少了对大空间瓦片和文本监督的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在遥感应用中面临两个关键挑战：依赖大空间瓦片增加计算成本，以及依赖文本监督但文本数据往往不易获得。

Method: 利用Sentinel-2影像的光谱和时序信息，通过与地理标记的地面照片进行跨视角学习，最小化基于标题训练的需求，同时保持卫星和地面视角之间的语义对齐。

Result: 证明了单个像素输入结合时序和光谱线索足以进行专题制图，为大规模遥感应用提供了可扩展且高效的替代方案。

Conclusion: 该方法在LUCAS和Sen4Map数据集上进行了评估，包括土地利用、作物类型和生态系统类型分类任务，展示了其有效性。

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [21] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: 该研究探讨了使用GAN生成的合成MRI数据增强脑肿瘤分割训练的效果，发现混合数据集（40%真实+60%合成数据）能改善肿瘤边界分割，但肿瘤核心区域的分割精度仍有待提升。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤手动分割面临肿瘤异质性、标注数据稀缺和类别不平衡等挑战，合成数据有望通过增加数据集多样性来缓解这些问题。

Method: 使用预训练GAN模型生成合成MRI数据，结合BraTS 2020真实数据，构建不同比例的混合数据集训练U-Net分割网络，并进行定量和定性评估。

Result: 混合训练模型与纯真实数据训练模型在整体定量性能（Dice系数、IoU等）上相当，但40%真实+60%合成数据的混合数据集在肿瘤边界分割方面表现更好，肿瘤核心区域的分割精度仍然较低。

Conclusion: 合成数据作为脑肿瘤分割的数据增强策略是可行的，但需要更大规模实验、保持体积数据一致性并解决类别不平衡问题。

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [22] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 这篇论文是关于深度学习点云去噪方法的综述，系统总结了该领域的关键挑战、主要贡献，并提出了针对去噪任务的分类法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的点云数据存在各种模态和强度的噪声，点云去噪作为预处理步骤对下游任务性能提升至关重要。尽管深度学习点云去噪方法在性能上已超越传统方法，但目前缺乏对该领域发展的系统性综述。

Method: 将点云去噪制定为一个两步过程：异常值去除和表面噪声恢复，涵盖大多数点云去噪场景和需求。通过比较方法的相似性、差异性和各自优势，提出专门针对去噪任务的分类法。

Result: 提出了一个全面的深度学习点云去噪方法综述框架，系统总结了现有方法的主要贡献，并建立了适合去噪任务的分类体系。

Conclusion: 论文填补了深度学习点云去噪领域缺乏系统性综述的空白，为后续研究提供了重要参考，并讨论了研究局限性和未来发展方向。

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [23] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: RealTalk是一个新颖的情感说话头生成框架，通过VAE生成3D面部关键点，结合情感标签嵌入和NeRF技术，实现了高情感准确性、增强的情感可控性和鲁棒的身份保持。


<details>
  <summary>Details</summary>
Motivation: 当前方法在唇同步和图像质量方面表现出色，但在生成准确可控的情感表情同时保持主体身份方面存在不足，这限制了人工智能社交智能的发展。

Method: 使用变分自编码器(VAE)从驱动音频生成3D面部关键点，通过ResNet-based关键点变形模型(LDM)结合情感标签嵌入生成情感关键点，最后利用三平面注意力Neural Radiance Field(NeRF)合成高度真实的情感说话头。

Result: 大量实验表明，RealTalk在情感准确性、可控性和身份保持方面优于现有方法。

Conclusion: RealTalk框架推动了社交智能AI系统的发展，在情感说话头合成领域取得了显著进展。

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [24] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose是一个无需重新训练的6D姿态跟踪框架，通过视觉惯性里程计、深度信息2D跟踪器和VIO引导的卡尔曼滤波器，在相机和物体快速移动场景中实现鲁棒的实时6D姿态跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要适用于静态或准静态场景，当相机和物体都快速移动时性能显著下降，需要解决快速运动场景下的6D姿态跟踪鲁棒性问题。

Method: 提出三个协同组件：1）视觉惯性里程计补偿相机运动引起的ROI偏移；2）深度信息2D跟踪器校正大物体平移引起的ROI偏差；3）VIO引导的卡尔曼滤波器预测物体旋转并生成候选姿态进行分层细化。

Result: 在仿真和真实世界实验中证明方法的有效性，实现了对快速移动相机和物体的实时鲁棒6D姿态跟踪。

Conclusion: 该方法通过闭环系统确保精确的姿态初始化和跟踪，解决了快速运动场景下的6D姿态跟踪挑战。

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [25] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 该论文提出了一种基于知识蒸馏的点云多尺度特征近似方法，通过单邻域近似多尺度特征，并结合可迁移特征嵌入机制来降低计算成本，同时保持目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 多尺度特征对点云目标检测至关重要，但传统方法需要多次邻域搜索和尺度感知层，计算成本高，不利于轻量化模型和计算资源有限的研究。

Method: 基于知识蒸馏从单邻域近似多尺度特征，设计可迁移特征嵌入机制（使用类别感知统计量），并引入中心加权交并比来缓解中心偏移带来的不对齐问题。

Result: 在公开数据集上的大量实验证明了该方法的有效性，能够显著节省计算成本。

Conclusion: 该方法通过单邻域近似和可迁移特征机制成功实现了高效的点云目标检测，在保持性能的同时大幅降低了计算复杂度。

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [26] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: UniUGG是首个统一理解和生成3D模态的框架，使用LLM处理文本和3D表示，通过空间解码器和潜在扩散模型生成高质量3D内容，支持空间VQA任务和3D场景生成。


<details>
  <summary>Details</summary>
Motivation: 尽管近期统一架构在图像理解和生成方面取得显著进展，但3D任务的整合仍然具有挑战性且未被充分探索，需要开发能够同时处理3D理解和生成的统一框架。

Method: 提出UniUGG框架，使用LLM理解和解码句子与3D表示；核心是空间解码器利用潜在扩散模型生成高质量3D表示；提出几何语义学习策略预训练视觉编码器，联合捕获输入的语义和几何线索。

Result: 大量实验结果表明该方法在视觉表示、空间理解和3D生成方面具有优越性。

Conclusion: UniUGG成功实现了3D模态的统一理解和生成，通过创新的空间解码器和几何语义学习策略，在多个任务上表现出色，为3D多模态处理提供了有效解决方案。

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [27] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: SAMDWICH是一个针对视频对象分割的moment-aware框架，通过引入时间标注和选择性监督来解决语义对齐问题，在MeViS基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频对象分割方法存在语义错位问题，主要原因是训练时对所有可见对象进行无差别采样和监督，而不考虑它们与文本查询的实际相关性。

Method: 提出了SAMDWICH框架，包含：1）新标注的MeViS-M数据集，手动标注对象被表达式引用的时间片段；2）Moment-guided Dual-path Propagation（MDP）传播策略；3）Object-level Selective Supervision（OSS）对象级过滤策略。

Result: 在具有挑战性的MeViS基准测试中实现了最先进的性能，特别是在涉及多样化表达式的复杂场景中表现优异。

Conclusion: 通过引入时间感知的监督和选择性训练策略，SAMDWICH有效解决了视频对象分割中的语义对齐问题，显著提升了语言条件学习的效果。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [28] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: PEdger++是一个协作学习框架，通过在异构架构、不同训练时刻和参数采样之间进行交叉信息融合，实现在降低计算成本和模型大小的同时提高边缘检测精度。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习边缘检测方法在资源受限设备上部署时面临的高计算成本问题，平衡高精度与低计算复杂度。

Method: 提出协作学习框架PEdger++，利用异构架构、多样化训练时刻和多重参数采样的交叉信息来增强学习效果，从集成角度提升性能。

Result: 在BSDS500、NYUD和Multicue数据集上的实验表明，该方法在定量和定性评估上都优于现有方法，并提供多个不同计算需求的模型版本。

Conclusion: PEdger++通过协作学习有效解决了边缘检测中精度与计算效率的平衡问题，具有很好的适应性和实用性。

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [29] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: 提出了一个新颖的多分辨率多模态微表情数据集，使用同步RGB和事件相机在可变光照条件下录制，展示了事件相机在微表情识别和帧重建方面的优势


<details>
  <summary>Details</summary>
Motivation: 微表情分析在人机交互和驾驶员监控系统中有重要应用，但仅依赖RGB相机难以准确捕捉细微快速的面部运动，事件相机提供了微秒级精度、高动态范围和低延迟的替代方案

Method: 创建了同步RGB和事件相机的多模态数据集，使用脉冲神经网络进行动作单元分类，使用条件变分自编码器进行帧重建

Result: 事件数据在动作单元分类中达到51.23%准确率（RGB仅为23.12%），帧重建达到SSIM=0.8513和PSNR=26.89dB的高质量结果

Conclusion: 事件数据在微表情识别和帧重建方面表现出色，证明了事件相机在微表情分析中的潜力和优势

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [30] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON是首个基于生成式多模态大语言模型的产品表示学习模型，通过引导式专家混合模块、核心语义区域检测和负采样策略，解决了产品图像-文本多对一对齐问题，并在多个下游任务中展现了优秀的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有判别式双流架构难以建模产品多图像与文本之间的多对一对应关系，而生成式MLLMs在提升产品表示学习方面具有巨大潜力，但面临缺乏多模态建模模块、产品图像背景噪声干扰以及标准评估基准缺失等挑战。

Method: 提出MOON模型：(1)使用引导式专家混合(MoE)模块进行多模态和特定方面的针对性建模；(2)有效检测产品图像中的核心语义区域以减少背景噪声干扰；(3)引入专门的负采样策略增加负样本的难度和多样性。

Result: 模型在自建的大规模多模态基准MBE和公共数据集上均表现出竞争力的零样本性能，在跨模态检索、产品分类和属性预测等各种下游任务中展现出强大的泛化能力。

Conclusion: MOON通过创新的多模态建模方法有效解决了产品表示学习中的关键挑战，案例研究和可视化结果证明了其在产品理解方面的有效性，为基于生成式MLLM的产品表示学习提供了新的解决方案。

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [31] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: InstDrive是一个实例感知的3D高斯泼溅框架，专门用于动态驾驶场景的交互式重建，首次在动态开放世界驾驶场景中实现3D实例分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法将背景元素统一为单一表示，阻碍了实例级理解和灵活场景编辑；现有方法主要针对室内场景，不适用于室外驾驶场景；需要避免复杂的预处理和优化流程。

Method: 使用SAM生成的掩码作为伪真值，通过对比损失和伪监督目标指导2D特征学习；在3D层面引入正则化隐式编码实例身份，通过体素损失强制一致性；使用轻量级静态码本桥接连续特征和离散身份。

Result: 定量和定性实验证明了InstDrive的有效性，首次在动态开放世界驾驶场景中实现3D实例分割。

Conclusion: InstDrive提供了一个有效的实例感知3D重建框架，解决了动态驾驶场景中实例分割的挑战，无需复杂预处理即可实现连续特征到离散身份的映射。

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [32] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: WiseLVAM是一个全自动的左心室线性测量框架，通过结合B模式图像的结构感知和AMM模式的运动感知，自动放置虚拟扫描线并执行测量，提高临床应用的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统自动化方法直接从B模式图像估计地标点进行左心室测量，但即使预测点沿心室壁有微小偏移也会导致显著测量误差，降低临床可靠性。需要开发更精确的全自动测量方法。

Method: 提出轮廓感知的扫描线放置方法：使用弱监督B模式地标检测器估计左心室轮廓，通过推断左心室长轴和基底水平来放置扫描线。然后基于生成的解剖运动模式(AMM)图像自动预测地标点进行测量。

Result: WiseLVAM框架结合了B模式图像的结构感知和AMM模式的运动感知，增强了测量的鲁棒性和准确性，为常规临床应用提供了实用解决方案。

Conclusion: 该研究开发了一种全自动且可手动调整的左心室线性测量框架，通过自动扫描线放置和AMM模式测量，显著提高了测量的准确性和临床适用性。

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [33] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU是一个结合频域特征提取和量子检索增强生成的医学视觉问答模型，在VQA-RAD数据集上表现优异，特别擅长处理需要图像-文本推理的复杂临床问题


<details>
  <summary>Details</summary>
Motivation: 解决需要同时理解图像和文本的临床难题是医疗AI的主要挑战，现有模型在处理复杂医学视觉问答时存在准确性和可解释性不足的问题

Method: 使用快速傅里叶变换将医学图像和文本特征转换到频域以提取更有意义的信息并过滤噪声，结合量子检索增强生成技术从外部知识源获取医学事实，通过量子相似度技术进行信息检索和融合

Result: 在VQA-RAD数据集上评估显示，Q-FSRU超越了之前的模型，特别是在需要图像-文本推理的复杂病例上表现突出

Conclusion: 频域和量子信息的结合提高了模型性能和可解释性，为构建智能、清晰且有用的医生AI工具提供了有前景的方法

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [34] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG是一个基于视频检索增强的运动生成框架，通过从大规模视频数据库中检索相关2D人体运动信号来解决运动大语言模型的数据稀缺问题，显著提升了仅基于文本输入的运动生成性能。


<details>
  <summary>Details</summary>
Motivation: 运动大语言模型由于标注数据有限而面临严重的域外/词汇外问题，需要利用大规模野外视频数据库来增强3D运动生成能力。

Method: 设计了Gemini Motion Video Retriever机制进行有效的运动中心视频检索，以及Motion-centric Dual-alignment DPO Trainer来缓解检索结果不佳导致的错误传播问题。

Result: 实验结果表明，VimoRAG显著提升了仅基于文本输入的运动大语言模型的性能。

Conclusion: VimoRAG框架通过视频检索增强的方式有效解决了运动生成中的数据稀缺问题，为运动大语言模型提供了新的性能提升途径。

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [35] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: 自动化对识检测器性能评估的AutoEval框架，通过预测一致性和可靠性(PCR)指标来估计检测性能，无需手动标注真实标签


<details>
  <summary>Details</summary>
Motivation: 解决对识检测器在实际应用中性能评估依赖成本高昂的手动标注问题

Method: 提出PCR指标，聚合测量NMS前后框的空间一致性和保留框的可靠性，构建包含不同严重程度图像腐化的元数据集

Result: PCR比现有AutoEval方法提供更准确的性能估计，构建的元数据集覆盖更广泛的检测性能范围

Conclusion: 该框架能够有效地自动评估对识检测器性能，减少对手动标注的依赖

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [36] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: DiffGEBD是一个基于扩散模型的通用事件边界检测方法，通过生成式视角解决事件边界检测问题，能够产生多样化的合理边界预测。


<details>
  <summary>Details</summary>
Motivation: 传统的事件边界检测方法主要关注确定性预测，忽略了事件边界的主观性和解决方案的多样性。

Method: 提出扩散模型DiffGEBD，通过时间自相似性编码相邻帧间的相关变化，然后以编码特征为条件迭代地将随机噪声解码为合理的事件边界，使用无分类器引导控制多样性。

Result: 在Kinetics-GEBD和TAPOS两个标准基准测试中表现出色，能够生成多样且合理的事件边界。

Conclusion: 扩散模型为事件边界检测提供了有效的生成式解决方案，能够处理该任务的主观性和多样性特点。

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [37] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: 提出基于多阶段卷积神经网络的集成方法，通过配对高低精度激光扫描仪数据，建立统计关系来校正低端设备的系统误差，显著提升测量精度


<details>
  <summary>Details</summary>
Motivation: 解决高低端激光扫描仪在粗糙室内环境中的位置误差问题，使低端设备无需硬件改造就能达到接近高端设备的测量精度

Method: 使用高精度扫描仪作为参考，配对相同环境下的低精度扫描仪数据，建立测量差异与空间分布的统计关系，结合传统几何处理和神经网络精炼的校正框架

Result: 在粗糙室内数据集上，均方误差降低超过70%，峰值信噪比提升约6分贝

Conclusion: 该方法成功将系统误差量化转化为监督学习问题，使低端设备能够达到接近高端设备的测量不确定性水平

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [38] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: 提出了一个理论框架来分析扩散模型中的量化误差传播，并基于此设计了时间步感知的累积误差补偿方案，显著提升了低精度扩散模型的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然图像合成质量优异，但其迭代去噪过程计算密集，部署困难。后训练量化(PTQ)可以加速采样，但迭代特性导致量化误差在生成过程中逐步累积，影响输出质量。

Method: 开发了一个理论框架，数学化地建模扩散模型中的误差传播，推导每步量化误差传播方程，并首次建立了累积误差的闭式解。基于此理论，提出了时间步感知的累积误差补偿方案。

Result: 在多个图像数据集上的广泛实验表明，该补偿策略有效缓解了误差传播，显著提升了现有PTQ方法，在低精度扩散模型上达到了最先进的性能。

Conclusion: 通过理论分析和误差补偿方案，成功解决了扩散模型量化过程中的误差累积问题，为低精度扩散模型的实际部署提供了有效解决方案。

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [39] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med是一个针对有限3D医学数据（如CT扫描和放射学报告）设计的视觉语言预训练框架，通过自监督学习和新颖的TriBERT语言编码器，在仅使用38,875个扫描-报告对的情况下实现了优异的跨模态性能。


<details>
  <summary>Details</summary>
Motivation: 医学领域中体积模态（如CT扫描）与文本的配对数据收集困难且耗时，限制了视觉语言模型在下游任务中的性能表现。

Method: 提出VELVET-Med框架，包含：1）将单模态自监督学习融入VLP框架；2）设计TriBERT语言编码器学习多级文本语义；3）采用分层对比学习捕获多级视觉语言对应关系。

Result: 仅使用38,875个数据对，在3D分割、跨模态检索、视觉问答和报告生成等多个下游任务中实现了最先进的性能。

Conclusion: 该方法通过有效的预训练目标和模型架构设计，在有限数据条件下成功挖掘了体积医学图像和临床叙述中的丰富空间和语义关系，增强了编码器的泛化能力。

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [40] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: Simple o3是一个端到端的多模态思维链框架，通过动态视觉工具交互和"观察-推理-行动"循环，显著提升了多模态大语言模型的视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在长思维链推理方面能力不足，需要探索类似人类"图像思考"的迭代视觉转换和语言推理方法。

Method: 提出监督微调框架，集成裁剪、缩放、重用等动态工具交互，构建TWI-Tools-146K数据集，采用"观察-推理-行动"循环生成高质量视觉语言推理链。

Result: 在多个基准测试中表现优异，超越现有方法。重用和放大原图显著改善视觉推理，基于精确视觉定位的图像裁剪使模型能有效关注关键区域。

Conclusion: Simple o3建立了强大且计算高效的多模态推理范式，首次深入分析了不同交错推理策略对模型性能的影响，为多模态推理提供了新思路。

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [41] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit是一个两阶段的虚拟试穿方法，通过先变形服装再合成的方式，在保持服装细节的同时实现高质量的试穿效果


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的免变形方法虽然提升了感知质量，但无法很好地保留服装的精细细节（如logo和印刷文字），这对品牌完整性和用户信任至关重要

Method: 采用两阶段混合管道：第一阶段通过学习的流场将目标服装变形对齐到人体图像；第二阶段通过保真度保持的试穿模块，使用保留区域输入和修复掩码来合成最终输出，只重新生成必要区域

Result: 广泛的定性结果显示DualFit实现了视觉上无缝的试穿效果，同时忠实地保持了高频服装细节，在重建准确性和感知真实性之间取得了有效平衡

Conclusion: DualFil通过结合变形和合成的方法，成功解决了现有方法在保留服装精细细节方面的局限性，为虚拟试穿技术提供了更好的解决方案

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [42] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef是一个三层次量化感知防御框架，通过特征不对齐惩罚、梯度感知差异惩罚和联合量化感知训练，有效降低QNN中基于补丁的对抗攻击在未知量化位宽间的可迁移性，攻击成功率降低40%以上。


<details>
  <summary>Details</summary>
Motivation: 量化神经网络(QNNs)虽然在计算和内存效率上表现优异，但对基于补丁的对抗攻击防御有限，现有方法要么过拟合于固定量化设置，要么无法解决跨位宽泛化漏洞。

Method: TriQDef包含三个核心组件：1)特征不对齐惩罚(FDP)通过惩罚中间表示的感知相似性来强制语义不一致；2)梯度感知差异惩罚(GPDP)通过边缘IoU和HOG余弦度量最小化结构性和方向性一致性；3)联合量化感知训练协议在多量化级别共享权重训练方案中统一这些惩罚。

Result: 在CIFAR-10和ImageNet上的广泛实验表明，TriQDef在未见过的补丁和量化组合上将攻击成功率(ASR)降低了40%以上，同时保持了高清洁准确率。

Conclusion: 研究强调了破坏语义和感知梯度对齐对于减轻QNN中补丁可迁移性的重要性，TriQDef框架有效解决了跨位宽对抗攻击转移问题。

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [43] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 提出一种针对视觉语言模型的微调方法，在保持预训练模型通用能力的同时实现细粒度领域适应，解决了灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 大规模对比预训练的视觉语言模型在细粒度开放集视觉检索任务中表现不佳，需要领域特定微调，但传统微调会导致灾难性遗忘，丧失模型的通用视觉和跨模态能力。

Method: 受持续学习启发，系统分析标准正则化技术，提出高效组合策略；同时关注验证集设计和超参数调优等关键方面，确保可复现性和跨数据集泛化能力。

Result: 在细粒度和粗粒度图像-图像、图像-文本检索基准测试中表现优异，无需使用文本数据或原始文本编码器即可保持视觉-文本对齐。

Conclusion: 该方法在领域适应和知识保持之间取得了最佳平衡，为视觉语言模型的细粒度微调提供了有效解决方案。

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [44] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: KP-INR是一种用于心脏电影MRI重建的双分支隐式神经表示方法，通过在k空间中处理位置嵌入和局部多尺度特征表示，实现了更好的重建性能


<details>
  <summary>Details</summary>
Motivation: 现有INR方法主要关注基于坐标的位置嵌入，而忽略了目标点及其邻域上下文特征表示的重要性，限制了重建质量

Method: 提出KP-INR双分支网络：一个分支处理k空间坐标的位置嵌入，另一个分支学习该坐标处的局部多尺度k空间特征表示，通过跨分支交互近似目标k空间值

Result: 在CMRxRecon2024数据集上的实验证实，KP-INR相比基线模型具有更好的性能表现

Conclusion: KP-INR方法在心脏电影MRI重建领域展现出潜力，通过同时利用位置信息和局部特征表示，能够有效处理具有挑战性的笛卡尔k空间数据

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [45] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: 提出了FB-Mem方法，通过图像分割量化扩散模型中的记忆化现象，发现记忆化比之前认为的更普遍，现有缓解方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法只能识别完全相同的记忆化，无法量化小区域的部分记忆化，也无法捕捉超越特定提示-图像对的记忆化模式。

Method: 提出基于分割的FB-Mem度量方法，对生成图像中的记忆化区域进行分类和量化，并使用聚类方法进行更强的缓解。

Result: 发现记忆化现象更普遍：单个生成可能关联多个相似训练图像；现有缓解方法无法消除局部记忆化，特别是在前景区域。

Conclusion: 建立了有效测量扩散模型记忆化的框架，证明了当前缓解方法的不足，提出了基于聚类的更强缓解方法。

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [46] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse是一个基于提示的RF信号模拟框架，通过语言引导生成室内场景和人体运动，使用相位相干射线追踪模拟真实RF信号，解决了RF数据采集难题。


<details>
  <summary>Details</summary>
Motivation: 解决在动态多样的室内环境中采集高质量RF数据的挑战，提供隐私保护的替代视觉感知方案。

Method: 结合语言引导的4D世界生成器（包含状态感知因果变换器用于人体运动生成）和相位相干射线追踪模拟器，从生成的室内场景中模拟真实RF信号。

Result: 实验证明在条件人体运动生成方面有效，相位相干性成功应用于波束成形和呼吸监测。在ML高分辨率成像和人类活动识别案例中，首次实现RF成像数据生成，在数据有限和充足场景下均获得性能提升。

Conclusion: WaveVerse提供了一个可扩展的RF信号模拟框架，能够生成高质量的RF数据，为RF感知任务提供了有效的解决方案。

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [47] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 提出了一种统一的、核和特征无关的特征提升方法，通过稀疏线性逆问题求解，在凸损失下可证明全局最优误差上界，结合Tikhonov指导和后提升聚合正则化策略，在开放词汇3D分割基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决多视图图像中丰富通用属性到3D基元的最优分配问题，处理多视图图像的不一致性问题，提升3D场景理解中特征提升的质量和效率。

Method: 将特征提升问题形式化为稀疏线性逆问题，可高效闭式求解；引入Tikhonov指导（通过软对角优势确保数值稳定性）和后提升聚合（通过特征聚类过滤噪声输入）两种互补正则化策略。

Result: 在开放词汇3D分割基准上实现了最先进的性能，优于基于训练、分组和启发式前向的基线方法，且能在几分钟内生成提升后的特征。

Conclusion: 该方法提供了一种高效、可证明最优的特征提升解决方案，通过正则化策略有效处理多视图不一致性和噪声，显著提升了3D场景理解的性能。

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [48] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: 基于深度学习的YOLOv11优化模型，用于棉花病害检测，通过C2PSA模块、动态类别加权和改进数据增强技术，显著提升了小目标检测精度和田间环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决棉花病害检测中的三个关键挑战：早期斑点检测精度低（5mm²以下斑点漏检率35%）、田间环境下性能下降（准确率下降25%）以及多病害场景错误率高（34.7%）。

Method: 采用C2PSA模块增强小目标特征提取，动态类别加权处理样本不平衡，Mosaic-MixUp缩放改进数据增强技术，基于YOLOv11进行深度优化。

Result: 在4,078张图像数据集上测试结果：mAP50达到0.820（提升8.0%），mAP50-95达到0.705（提升10.5%），推理速度158 FPS，移动端部署实现实时病害监测。

Conclusion: 提出的优化方法有效解决了棉花病害检测的关键问题，实现了高精度、高效率的实时监测系统，为农业精准防治提供了可行的技术方案。

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [49] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 提出了一种结合生成网络和物理神经模拟的生成神经物理框架，用于快速、高保真的3D超声计算机断层扫描，克服了强散射环境下的计算瓶颈，实现了肌肉骨骼组织的准确定量成像。


<details>
  <summary>Details</summary>
Motivation: 传统基于射线的重建方法在肌肉骨骼成像中存在局限性，无法处理强散射问题，限制了超声计算机断层扫描（USCT）在该领域的应用。

Method: 开发了生成神经物理框架，通过从少量跨模态图像中学习超声波传播的紧凑代理模型，将波动建模的准确性与深度学习的效率和稳定性相结合。

Result: 在合成和体内数据（乳房、手臂、腿部）上，在10分钟内重建了组织参数的3D图谱，对肌肉和骨骼的生物力学特性具有敏感性，分辨率与MRI相当。

Conclusion: 该方法克服了强散射状态下的计算瓶颈，推动了USCT向肌肉骨骼疾病常规临床评估的发展。

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [50] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 本文提出了一个新的天气扩展显著目标检测数据集WXSOD，包含14,945张带有天气噪声的RGB图像，并设计了天气感知特征聚合网络WFANet，在复杂天气条件下显著提升了显著目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测方法在自然场景中表现良好，但缺乏针对天气噪声影响的研究，主要原因是缺少带有像素级标注的天气噪声数据集。

Method: 构建了WXSOD数据集（包含合成和真实测试集），提出了WFANet网络，采用双分支架构：天气预测分支挖掘天气相关特征，显著性检测分支融合语义特征和天气特征进行检测。

Result: 与17种SOD方法对比，WFANet在WXSOD数据集上取得了优越性能，验证了方法的有效性。

Conclusion: WXSOD数据集填补了天气噪声SOD研究的空白，WFANet网络通过天气特征融合有效提升了复杂天气条件下的检测性能，为相关研究提供了基准和工具。

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [51] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: 提出SCTR框架，通过超像素分割和不对称低秩张量分解，解决了传统低秩张量表示在空间变化和网格约束方面的局限性，在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统低秩张量表示方法存在两个关键局限：假设整体数据低秩（在空间变化显著的实际场景中不成立）和局限于离散网格数据。需要一种更灵活连续的建模方法。

Method: 使用超像素作为基本建模单元，提出不对称低秩张量分解(ALTF)，其中超像素特定因子矩阵由共享神经网络和专用头参数化，分离全局模式学习和局部适应。

Result: 在多个基准数据集上，SCTR相比现有LRTR方法在多光谱图像、视频和彩色图像上实现了3-5 dB的PSNR提升。

Conclusion: SCTR框架通过超像素引导和连续建模，有效克服了传统方法的局限性，在保持模型效率的同时提供了更好的适应性和表达能力。

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [52] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: 提出了视觉动作提示(VAP)，一种统一的动作表示方法，通过将动作渲染为视觉骨架来平衡动作精度和跨域动态迁移能力，解决了动作驱动视频生成中的精度-泛化权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有动作驱动视频生成方法面临精度与泛化性的权衡：文本、原始动作或粗糙掩码方法泛化性好但精度不足，而智能体中心动作信号精度高但缺乏跨域迁移能力。

Method: 将动作渲染为精确的视觉提示（选择视觉骨架作为通用表示），构建从人-物交互和灵巧机器人操作数据中提取骨架的流程，通过轻量级微调将视觉骨架集成到预训练视频生成模型中。

Result: 在EgoVid、RT-1和DROID数据集上的实验证明了该方法的有效性，能够实现复杂交互的精确动作控制同时保持跨域动态学习能力。

Conclusion: 视觉动作提示提供了一种平衡动作精度和动态迁移能力的统一表示，为解决复杂高自由度交互的动作到视频生成问题提供了有效方案。

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [53] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 该论文提出了区域级上下文感知多模态理解(RCMU)任务，开发了RCVIT训练方法、RCMU数据集和RC&P-Bench基准测试，并在Qwen2-VL模型上实现了优秀的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM研究主要关注通用视觉理解，忽略了整合对象相关文本上下文的能力，需要开发区域级上下文感知多模态理解能力。

Method: 提出Region-level Context-aware Visual Instruction Tuning (RCVIT)方法，将对象信息和边界框坐标整合到模型输入中，使模型能够关联视觉内容和文本信息。

Result: 通过在Qwen2-VL模型上进行RCVIT训练得到的RC-Qwen2-VL模型，在多个RCMU任务上表现出色，并在多模态RAG和个性化对话中成功应用。

Conclusion: 该研究填补了MLLM在区域级上下文感知理解方面的空白，提出的方法、数据集和基准测试为多模态理解提供了新的解决方案和评估标准。

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [54] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5在多模态空间智能方面取得显著进展但仍未达到人类水平，研究通过8个基准测试和超过10亿token的成本评估发现，尽管GPT-5展现前所未有的空间理解能力，但在复杂空间推理任务中仍存在明显短板。


<details>
  <summary>Details</summary>
Motivation: 多模态模型在空间理解和推理方面仍存在显著局限性，而空间智能是实现通用人工智能的基础能力。随着GPT-5的发布，需要评估当前最先进模型在空间智能路径上的位置。

Method: 提出统一的空间任务分类法，在8个关键基准测试上评估最先进的专有和开源模型，总成本超过10亿token，并进行定性评估。

Result: GPT-5展现出前所未有的空间智能强度，但仍未达到人类在各种任务中的表现；识别出多模态模型更具挑战性的空间智能问题；专有模型在最困难问题上没有决定性优势。

Conclusion: 尽管GPT-5在空间智能方面取得重大进步，但多模态模型在人类直觉性空间场景中仍存在系统性失败，距离真正的空间智能还有差距。

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [55] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: 提出SNNSIR，一种完全基于脉冲驱动的脉冲神经网络，用于立体图像恢复，通过脉冲残差基本块、立体卷积调制和立体交叉注意力模块，在保持竞争性恢复性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的混合SNN-ANN模型仍然依赖浮点矩阵除法或指数运算，与SNN的二进制和事件驱动特性不兼容。需要开发完全基于脉冲驱动的架构来实现低功耗和硬件友好的计算。

Method: 1. 引入轻量级脉冲残差基本块(SRBB)增强信息流；2. 提出脉冲立体卷积调制(SSCM)模块，通过元素乘法实现简化非线性；3. 设计脉冲立体交叉注意力(SSCA)模块，实现跨视图的双向特征交互。

Result: 在多种立体图像恢复任务（雨纹去除、雨滴去除、低光增强和超分辨率）上的实验表明，该模型在保持竞争性恢复性能的同时显著降低了计算开销。

Conclusion: 该方法展示了在实时、低功耗立体视觉应用中的潜力，为完全基于脉冲驱动的立体图像恢复提供了有效解决方案。

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [56] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种针对自动驾驶平台的动态可适应语义分割网络，通过三层控制机制和贝叶斯优化来实现硬件约束下的模型定制和性能优化。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶平台面临多样化的驾驶场景，每个场景都有不同的硬件资源和精度要求。由于嵌入式设备的计算限制，在目标平台部署时需要考虑计算成本。

Method: 采用三层控制机制（宽度乘数、分类器深度、分类器核）实现动态适应性，并利用贝叶斯优化和代理建模在有限计算预算下高效探索超参数空间。

Result: 实现了针对特定自动驾驶任务的替代配置，最大化计算能力和模型精度，优化硬件利用率。

Conclusion: 该方法能够根据自动驾驶硬件的计算能力和特定场景定制语义分割网络，通过任务特定的学习适应实现更好的资源分配和性能表现。

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [57] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: 本文提出CLAIR方法，通过CLIP置信度评分精炼噪声伪标签，设计多对比损失和跨域映射函数，在弱监督零样本跨域图像检索任务中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型基础模型能够轻松为大量未标注数据生成伪标签，无监督零样本跨域图像检索变得不再重要，因此转向研究使用CLIP等大型基础模型生成噪声伪标签的弱监督零样本跨域图像检索。

Method: 提出CLAIR方法：1）使用CLIP文本和图像特征的相似度计算置信度来精炼噪声伪标签；2）设计实例间和簇间对比损失编码到类感知潜在空间；3）设计域间对比损失缓解域差异；4）学习闭式跨域映射函数，仅使用CLIP文本嵌入将图像特征从一个域投影到另一个域；5）引入可学习提示增强零样本泛化能力。

Result: 在TUBerlin、Sketchy、Quickdraw和DomainNet零样本数据集上的大量实验表明，CLAIR相比现有最先进方法持续表现出优越性能。

Conclusion: CLAIR方法通过精炼噪声伪标签、多对比学习和跨域映射，有效解决了弱监督零样本跨域图像检索问题，在多个数据集上取得了state-of-the-art的性能。

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [58] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: 通过边缘感知分数、长轴分割策略和抗过拟合技术完善了3DGS的密化管道，在不增加计算开销的情况下提升了渲染质量和重建效果


<details>
  <summary>Details</summary>
Motivation: 3D高斯扩散技术的密化策略导致重建质量不佳，需要从密化时机、密化方式和抗过拟合等多个角度进行全面改进

Method: 提出边缘感知分数选择候选高斯元素，长轴分割策略减少几何失真，以及恢复感知剪枝、多步更新和增长控制等抗过拟合技术

Result: 方法在不增加训练或推理开销的情况下，使用更少的高斯元素实现了独创性能的渲染保真度

Conclusion: 该研究通过系统性的密化管道优化，显著提升了3D高斯扩散技术的重建质量，为实时渲染领域提供了有效的改进方案

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [59] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 提出基于神经细胞自动机(NCA)的弱监督分割方法NCA-WSS，利用NCA分类过程中的特征图生成分割掩码，无需分割标签重新训练，在三个白细胞显微镜数据集上显著优于现有弱监督方法。


<details>
  <summary>Details</summary>
Motivation: 白细胞检测和分割是医学诊断的关键步骤，但获取大量标注数据耗时且昂贵，需要开发弱监督方法来减少标注需求。

Method: 使用神经细胞自动机(NCA)进行分类，利用其生成的特征图直接提取分割掩码，无需额外的分割标签训练。

Result: 在三个白细胞显微镜数据集上评估，NCA-WSS方法显著优于现有的弱监督分割方法。

Conclusion: NCA在弱监督框架下同时实现分类和分割的潜力，为医学图像分析提供了可扩展且高效的解决方案。

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [60] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 将注意力池化机制与神经细胞自动机(NCA)结合，在保持参数效率和可解释性的同时，显著提升了显微镜图像分类性能


<details>
  <summary>Details</summary>
Motivation: 神经细胞自动机(NCA)在图像分类中具有鲁棒性和可解释性优势，但性能与大型复杂架构存在差距，需要提升特征提取能力

Method: 集成注意力池化机制到NCA中，通过关注信息最丰富的区域来增强特征提取，提高分类准确性

Result: 在8个不同的显微镜图像数据集上评估，显著优于现有NCA方法，同时保持参数效率；相比传统轻量级CNN和ViT架构，性能更好且参数数量显著更低

Conclusion: 基于NCA的模型具有作为可解释图像分类替代方案的潜力，注意力池化的集成有效提升了性能

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [61] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: DoppDrive是一种基于多普勒效应的雷达点云时间聚合方法，通过径向位移和动态聚合持续时间来增强点云密度并减少散射，显著提升雷达目标检测性能


<details>
  <summary>Details</summary>
Motivation: 雷达在自动驾驶中具有长距离检测优势，但点云稀疏性（尤其在远距离）影响检测精度。现有时间聚合方法会引入动态物体散射，降低检测性能

Method: 提出Doppler-Driven时间聚合方法：1）根据动态多普勒分量对历史帧点进行径向位移以消除径向散射；2）基于多普勒和角度为每个点分配独特的聚合持续时间以减少切向散射

Result: DoppDrive作为检测前的点云密度增强步骤，与任何检测器兼容，在各种检测器和数据集上显著提升了目标检测性能

Conclusion: 该方法有效解决了雷达点云稀疏性问题，通过多普勒信息驱动的智能聚合策略，在增强点云密度的同时最小化散射噪声，为雷达目标检测提供了有效的预处理方案

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [62] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: 提出了一种基于几何感知学习的框架，用于从单视角RGB视频中联合移除HMD遮挡并重建完整的3D面部几何


<details>
  <summary>Details</summary>
Motivation: 头戴显示器(HMD)会遮挡用户上半部分面部，影响外部视频录制和社交XR应用中的面部表情和视线交流，需要解决HMD遮挡问题

Method: 集成GAN-based视频修复网络，通过密集面部关键点和单张无遮挡参考帧引导修复缺失面部区域；使用SynergyNet-based模块从修复后的帧回归3DMM参数；在整个流程中加入密集关键点优化

Result: 能够成功从RGB面部视频中移除HMD，保持面部身份和真实感，生成逼真的3D面部几何输出；在不同关键点密度下保持鲁棒性

Conclusion: 该框架有效解决了HMD遮挡问题，为社交XR应用提供了高质量的面部重建解决方案

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [63] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 提出基于语义差异感知的伪造检测器SDD，通过重建学习在细粒度视觉层面对齐伪造空间和语义概念空间，在标准图像伪造数据集上取得优异效果


<details>
  <summary>Details</summary>
Motivation: 随着图像生成技术的快速发展，需要强大的伪造检测来确保数字媒体的可信度。现有方法中伪造空间与语义概念空间的不对齐问题限制了检测性能

Method: 提出语义差异感知检测器(SDD)：1) 语义标记采样模块利用预训练视觉语言模型的概念知识缓解空间偏移；2) 概念级伪造差异学习模块通过视觉重建范式增强视觉语义概念与伪造痕迹的交互；3) 低级伪造特征增强模块整合学习到的概念级差异来最小化冗余信息

Result: 在两个标准图像伪造数据集上的实验表明，SDD相比现有方法取得了更优异的结果

Conclusion: 该方法通过有效对齐伪造空间和语义概念空间，显著提升了图像伪造检测性能，为解决伪造检测中的空间不对齐问题提供了有效解决方案

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [64] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat是一个即插即用的任务驱动特征增强模块，专门针对水下目标检测任务设计，通过端到端训练的多尺度特征增强网络显著提升检测精度，同时保持实时处理速度。


<details>
  <summary>Details</summary>
Motivation: 水下环境的严重图像退化会影响目标检测模型的性能，传统的图像增强方法通常没有针对下游检测任务进行优化，需要一种专门的任务驱动特征增强方法。

Method: 提出AquaFeat模块，集成多尺度特征增强网络，与检测器的损失函数进行端到端训练，确保增强过程明确指导以优化与检测任务最相关的特征。

Result: 在YOLOv8m上集成AquaFeat，在挑战性水下数据集上达到最先进的精度(0.877)和召回率(0.624)，以及竞争力的mAP分数(mAP@0.5为0.677，mAP@[0.5:0.95]为0.421)，处理速度为46.5 FPS。

Conclusion: AquaFeat提供了一种有效且计算效率高的解决方案，适用于海洋生态系统监测和基础设施检查等实际应用，在保持实用处理速度的同时实现了精度提升。

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [65] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: 提出了MBMamba网络，通过内存缓冲机制和Ising启发的正则化损失来解决Mamba架构在图像去模糊中的局部像素遗忘和通道冗余问题，在不改变原架构的情况下提升了性能。


<details>
  <summary>Details</summary>
Motivation: Mamba架构在图像去模糊中采用flatten-and-scan策略会导致局部像素遗忘和通道冗余，现有方法通过修改扫描策略或加入局部特征模块会增加计算复杂度，影响实时性能。

Method: 设计内存缓冲机制保存历史信息用于后续融合，可靠建模相邻特征间的相关性；引入Ising启发的正则化损失模拟物理系统像素间"相互吸引"的能量最小化，保持图像结构和一致性。

Result: 在广泛使用的基准测试中优于最先进的方法。

Conclusion: MBMamba网络在不改变原始Mamba架构的情况下，通过内存缓冲和物理启发的正则化有效解决了图像去模糊中的信息保留和结构保持问题。

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [66] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: 提出EgoLoc方法，通过零样本方式在自我中心视频中定位手-物体接触和分离的时间戳，无需目标掩码和动词-名词分类，实现了泛化性强的时序交互定位。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注交互动作的行为范式（如何交互），但对手与目标物体接触和分离的关键时刻（何时交互）这一更精细的问题研究不足，这对混合现实和机器人运动规划至关重要。

Method: 提出EgoLoc方法：1）引入手动力学引导采样生成高质量视觉提示；2）利用视觉语言模型识别接触/分离属性并定位特定时间戳；3）提供闭环反馈进行进一步细化

Result: 在公共数据集和新基准上的综合实验表明，EgoLoc在自我中心视频中实现了合理的时序交互定位，并能有效促进自我中心视觉和机器人操作任务中的多个下游应用。

Conclusion: EgoLoc消除了对物体掩码和动词-名词分类的需求，实现了可泛化的零样本实现，为时序交互定位问题提供了有效解决方案。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [67] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 提出了一种通过数据增强和扩散模型生成合成数据的方法，来提升视觉离线强化学习的泛化能力，无需修改现有算法


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在视觉数据上面临泛化困难，因为视觉数据包含噪声、干扰和伪相关性，且训练数据多样性不足容易导致过拟合

Method: 两步法：先对原始离线数据进行增强以增加多样性，然后用扩散模型在潜在空间生成额外的合成训练数据

Result: 在连续动作空间(Visual D4RL)和离散动作空间(Procgen)上都显著提升了泛化性能，减少了泛化差距，同时保持计算效率

Conclusion: 该方法为通过生成合成数据训练更具泛化能力的智能体提供了有前景的方向

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [68] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer是一个用于病理图像生存分析的可解释图-Transformer框架，能够同时捕获肿瘤微环境特征和空间依赖关系，在预测准确性和可解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以平衡长程空间关系与局部上下文依赖性的建模，且缺乏内在可解释性，限制了临床实用性。

Method: 提出Interpretable Pathology Graph-Transformer (IPGPhormer)框架，在组织和细胞层面提供可解释性，无需事后手动标注。

Result: 在四个公共基准数据集上的综合评估表明，IPGPhormer在预测准确性和可解释性方面均优于最先进方法。

Conclusion: IPGPhormer为癌症预后评估提供了一个有前景的工具，为病理学中更可靠和可解释的决策支持系统铺平了道路。

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [69] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: 提出ViT-EnsembleAttack方法，通过对抗性增强ViT模型来提升集成攻击的迁移性，在ViT上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有集成攻击研究主要关注集成权重优化或集成路径，忽略了通过增强集成模型本身来提升对抗迁移性，特别是ViT模型的集成攻击研究较少

Method: 对每个ViT代理模型采用三种对抗增强策略：多头丢弃、注意力分数缩放和MLP特征混合，使用贝叶斯优化优化参数，并引入自动重加权和步长放大模块

Result: 实验表明ViT-EnsembleAttack显著提升了ViT集成攻击的对抗迁移性，大幅超越现有方法

Conclusion: 通过对抗性增强集成模型可以有效提升对抗攻击的迁移性，特别是在ViT模型上取得了显著效果

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [70] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT是一个通过大语言模型分解复杂文本指令来提升文生图模型性能的框架，在LongBench-T2I基准测试中显著改善了文本和构图等挑战性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前文生图模型在处理复杂长文本指令时存在困难，经常无法准确渲染细节、空间关系和特定约束，需要一种方法来提升对复杂指令的理解和执行能力。

Method: DeCoT框架分为两个核心阶段：1）复杂指令分解和语义增强 - 使用LLM将原始指令分解为结构化语义单元并澄清歧义；2）多阶段提示集成和自适应生成 - 将这些单元转换为分层或优化的单一提示以适应现有T2I模型。

Result: 在LongBench-T2I数据集上的实验表明，DeCoT显著提升了主流T2I模型的性能，特别是在"文本"和"构图"等挑战性方面。与Infinity-8B集成时平均得分3.52，优于基线3.44。人工评估也证实了感知质量和指令保真度的提升。

Conclusion: DeCoT有效弥合了高级用户意图与T2I模型需求之间的差距，实现了更忠实和准确的图像生成，证明了LLM提示在增强T2I模型性能中的关键作用。

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [71] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: FedCSAP是一个联邦学习框架，通过利用CLIP视觉编码器的多尺度特征和客户端特定风格指标，生成上下文感知的提示词，提升跨模态模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖最终层特征，无法充分利用分散客户端数据中的多尺度视觉线索和领域特定风格变化，需要一种能够整合丰富视觉细节和文本上下文的方法。

Method: 利用CLIP视觉编码器的低、中、高层特征，结合客户端批量统计信息提取的风格指标，生成独特且非冗余的上下文感知提示词，在联邦学习框架下进行本地训练和全局聚合。

Result: 在多个图像分类数据集上的实验表明，FedCSAP在准确性和整体泛化能力方面优于现有的联邦提示学习方法。

Conclusion: FedCSAP通过整合多尺度视觉特征和客户端风格信息，有效提升了联邦提示学习的性能，能够很好地处理非独立同分布类分布和多样化领域特定风格。

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [72] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR是一种无需微调的推理时策略，通过多角度生成描述、智能整合上下文和深度推理三阶段，显著提升大视觉语言模型在复杂视觉推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在需要深度上下文理解、多角度分析或精细细节识别的复杂视觉推理任务中表现有限，主要受限于单次图像编码和提示的局限性。

Method: 三阶段方法：1) 从多个角度生成N个多样互补的描述或初步推理路径；2) 智能整合这些描述与原始问题构建上下文增强提示；3) 使用增强提示指导最终深度推理和答案生成。无需微调模型参数。

Result: 在GQA、VQA-CP v2和ScienceQA等挑战性VQA数据集上 consistently超越基线方法，定量结果显示准确率显著提升，特别是在需要强上下文理解的任务上。人工评估确认生成答案的连贯性和完整性得到改善。

Conclusion: 利用大视觉语言模型固有的生成能力来丰富输入上下文，可以有效释放其在复杂多模态任务中的潜在推理能力，MPCAR方法证明了这种策略的有效性。

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [73] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD是一个专为自动驾驶设计的视觉语言框架，通过引入初步场景交互和专家适配器，显著提升了现有VLM在驾驶推理任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在车载多视角图像和场景推理文本上微调VLM，但缺乏自动驾驶所需的整体细致场景识别和强大空间感知能力，特别是在复杂情况下

Method: 提出LMAD框架，模拟现代端到端驾驶范式，包含全面场景理解和任务专业化结构。引入初步场景交互和专门专家适配器，在相同驾驶任务结构中更好地对齐VLM与自动驾驶场景

Result: 在DriveLM和nuScenes-QA数据集上的大量实验表明，LMAD显著提升了现有VLM在驾驶推理任务上的性能

Conclusion: LMAD为可解释自动驾驶设立了新标准，完全兼容现有VLM，并能无缝集成到规划导向的驾驶系统中

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [74] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 提出了S5框架，首个用于遥感半监督语义分割的可扩展解决方案，通过大规模无标签数据和MoE微调方法，在多个遥感基准测试中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有半监督语义分割研究依赖小规模数据集和模型，限制了实际应用潜力，需要利用大量未标注的遥感数据来提升性能

Method: 构建RS4P-1M数据集（整合熵过滤和多样性扩展策略），预训练不同规模的遥感基础模型，采用基于Mixture-of-Experts的多数据集微调方法

Result: 在土地覆盖分割和目标检测任务上显著提升性能，在所有基准测试中达到state-of-the-art水平

Conclusion: 证明了扩展半监督学习在遥感应用中的可行性，为充分利用地球观测数据提供了有效框架

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [75] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: SRMA-Mamba是一个基于Mamba架构的新型网络，专门用于MRI体积数据的肝硬化解剖结构空间关系建模，通过整合空间解剖Mamba模块和空间反向注意力模块，实现了高效的3D病理肝脏分割。


<details>
  <summary>Details</summary>
Motivation: 肝硬化在慢性肝病预后中起关键作用，早期检测和及时干预对降低死亡率至关重要。现有方法未能充分利用体积MRI数据中的空间解剖细节，限制了临床效果和可解释性。

Method: 提出SRMA-Mamba网络，集成空间解剖Mamba模块(SABMamba)在肝硬化组织内进行选择性Mamba扫描，结合矢状面、冠状面和轴面的解剖信息构建全局空间上下文表示；引入空间反向注意力模块(SRMA)利用粗分割图和分层编码特征逐步细化肝硬化细节。

Result: 大量实验表明SRMA-Mamba超越了最先进的方法，在3D病理肝脏分割方面提供了卓越的性能。

Conclusion: SRMA-Mamba通过有效建模MRI体积中的复杂解剖结构空间关系，为肝硬化早期检测提供了高效的3D分割解决方案，具有重要的临床应用价值。

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [76] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN是一个文本到动态全景场景生成框架，通过双分支生成模型和几何对齐重建模型，实现了360度沉浸式动态场景的生成，解决了现有方法只能生成静态或窄视角动态场景的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着VR/AR技术的快速发展，对高质量沉浸式动态场景的需求日益增长，但现有生成方法主要集中于静态场景或窄视角动态场景，无法提供真正的360度沉浸体验。

Method: 提出双分支生成模型（全景分支和透视分支）进行全景视频生成，通过双向交叉注意力机制实现信息交换；基于3D高斯泼溅的几何对齐重建模型，利用度量深度图对齐时空点云，确保几何一致性和时间连贯性。

Result: 大量实验证明了所提设计的有效性，TiP4GEN在生成视觉吸引人且运动连贯的动态全景场景方面表现出优越性。

Conclusion: TiP4GEN框架成功实现了从文本生成高质量360度沉浸式动态场景，为VR/AR应用提供了有效的解决方案。

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [77] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 通过比较生物和人工视觉系统对视觉幻觉的响应，揭示两者在构建视觉现实方面的关键差异，发现AI既有类似人类的幻觉效应，也有独特的像素级敏感性和幻觉现象


<details>
  <summary>Details</summary>
Motivation: 理解生物与人工视觉系统在感知机制上的差异，为开发更鲁棒、可解释且与人类对齐的AI视觉系统提供指导

Method: 系统比较人类和AI对经典视觉幻觉（颜色、大小、形状、运动）的响应，分析AI特有的幻觉现象

Result: 发现AI会产生类似人类的幻觉效应（通过针对性训练或模式识别副产品），同时识别出AI特有的幻觉（像素级敏感性、幻觉现象），揭示了人类感知不可见的AI特定感知脆弱性

Conclusion: 这些发现为未来视觉系统研究提供见解，有助于保留对人类有益的感知偏差，同时避免损害信任和安全性的扭曲

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [78] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: 该论文发现现有VQA-NLE系统存在解释不一致和理解不足的问题，提出了基于图像扰动的新攻击策略和基于外部知识的缓解方法，揭示了当前系统的安全可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉问答自然语言解释系统存在黑盒模型透明度不足的问题，会产生不一致的解释和缺乏真正理解的结论，暴露了推理流程或解释生成机制的弱点。

Method: 利用现有的对抗性问题扰动策略，并提出新颖的最小化图像修改策略来诱导矛盾或虚假输出，同时引入基于外部知识的缓解方法来增强模型鲁棒性。

Result: 在两个标准基准和两个广泛使用的VQA-NLE模型上进行广泛评估，证明了攻击方法的有效性和基于知识的防御潜力。

Conclusion: 研究揭示了当前VQA-NLE系统在安全性和可靠性方面存在的紧迫问题，知识驱动的防御方法具有改善系统鲁棒性的潜力。

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [79] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT是一个基于视觉语言大模型的新型框架，通过模拟放射科医生的思维链过程，实现胸部X光片的智能诊断和可解释报告生成，在保持竞争力的诊断准确率的同时提供高质量的可解释性。


<details>
  <summary>Details</summary>
Motivation: 胸部X光影像诊断需要丰富临床经验且存在观察者间差异，虽然深度学习模型诊断准确率高，但其黑盒特性阻碍了在高风险医疗环境中的临床应用。

Method: 提出X-Ray-CoT框架，首先提取多模态特征和视觉概念，然后使用基于LLM的组件配合结构化思维链提示策略进行推理，生成详细自然语言诊断报告。

Result: 在CORDA数据集上评估，疾病诊断的平衡准确率达到80.52%，F1分数78.65%，略优于现有黑盒模型，并能生成高质量的可解释报告。

Conclusion: 该研究代表了医学影像领域向可信赖和临床可操作AI系统迈出的重要一步，消融研究证实了多模态融合和思维链推理对于构建稳健透明医疗AI的必要性。

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [80] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA是一种新的多模态学习方法，无需对齐预训练，通过将文本嵌入映射到视觉表示空间而非传统视觉到文本的映射，在推理密集型任务上表现优异，计算需求减少45%。


<details>
  <summary>Details</summary>
Motivation: 挑战传统多模态学习需要昂贵对齐预训练的假设，探索更高效的多模态融合方式，减少对大规模图像-文本对齐数据集的依赖。

Method: 提出逆向映射方法，将文本嵌入映射到连续视觉表示空间，在transformer中间层进行融合，通过注意力机制中的选择性加性组件实现动态集成。

Result: 在9个多模态基准测试中显示性能权衡：推理和认知任务显著提升（MM-VET: +0.2%, VizWiz: +1.8%, ScienceQA: +0.2%, 认知推理: +27.2%），但感知任务下降（名人识别: -49.5%, OCR: -21.3%）。

Conclusion: 首次实证证明对齐预训练对有效多模态学习并非必要，特别是复杂推理任务；建立新范式可行性，计算需求减少45%，为保留模态特定特征的高效多模态架构开辟新方向。

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [81] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: 基于细调视觉-语言模型联盟和理解大语言模型的决策支持系统，实现自动化H-反射电机图形分析和诊断，提高神经肌诊断的准确性和标准化程度


<details>
  <summary>Details</summary>
Motivation: 传统H-反射EMG波形分析存在变异性和解释偏差，影响可靠性和标准化，需要自动化解决方案

Method: 使用多个细调VLM模型联盟，基于波形图像和临床数据进行特征提取和预测，通过共识算法聚合诊断结果，然后由专门理解LLM精炼，构建结合提示工程和自动理解流程的端到端平台

Result: 混合系统实现了高精度、一致性和可解释的H-反射评估，显著提升了神经肌诊断的自动化和标准化水平

Conclusion: 这是首次将细调VLM聚合与理解LLM集成用于图像基H-反射分析，为下一代AI辅助神经肌评估和运动员监测平台奠定了基础

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [82] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 该研究提出了一种结合CNN、Transformer和卷积Kolmogorov-Arnold网络(CKAN)的混合模型，用于皮肤癌分类任务，在多个数据集上取得了优异的性能表现。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌分类是医学图像分析中的关键任务，需要精确区分恶性和非恶性病变以实现早期诊断和治疗。传统方法在特征表示和模型鲁棒性方面存在局限。

Method: 采用顺序和并行混合的CNN-Transformer架构，结合卷积Kolmogorov-Arnold网络(CKAN)进行非线性特征融合。使用迁移学习和大量数据增强技术，CNN提取局部空间特征，Transformer建模全局依赖关系。

Result: 在HAM10000数据集上达到92.81%准确率和92.47% F1分数，PAD-UFES数据集上达到97.83%准确率和97.83% F1分数，BCN20000数据集上达到91.17%准确率和91.79% F1分数，展现了优异的分类性能和泛化能力。

Conclusion: 混合CNN-Transformer架构能有效捕获空间和上下文特征，CKAN的集成通过可学习激活函数增强了特征融合能力，证明了特征表示和模型设计在医学图像分类中的重要性。

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [83] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: RAIS-DR是一个用于糖尿病视网膜病变筛查的负责任AI系统，在本地数据集上相比FDA批准的EyeArt系统，F1分数提高5-12%，准确率提高6-19%，特异性提高10-20%，并在人口统计亚组中表现出公平性能。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是工作年龄人群视力丧失的主要原因，早期检测可降低95%的视力丧失风险，但视网膜专家短缺和及时检查困难阻碍了检测。AI模型虽然提供解决方案，但低质量数据和偏见导致临床采用受阻。

Method: 开发RAIS-DR负责任AI系统，在整个AI生命周期中整合伦理原则，包括高效的卷积模型进行预处理、质量评估和三个专门的DR分类模型。在1,046名患者的本地数据集上评估，与FDA批准的EyeArt系统进行比较。

Result: RAIS-DR表现出显著改进：F1分数提高5-12%，准确率提高6-19%，特异性提高10-20%。公平性指标如差异影响和均等机会差异显示在人口统计亚组中的公平性能。

Conclusion: RAIS-DR是一个强大且符合伦理的DR筛查解决方案，有潜力减少医疗保健差异，代码和权重已公开提供。

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [84] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: LangVision-LoRA-NAS是一个结合神经架构搜索和LoRA的新框架，通过动态搜索最优LoRA秩配置来优化视觉语言模型，在提高性能的同时降低微调成本。


<details>
  <summary>Details</summary>
Motivation: 当前LoRA实现使用固定秩，限制了在不同任务中的灵活性和效率，需要一种能够根据具体多模态任务动态优化秩配置的方法。

Method: 集成神经架构搜索(NAS)与LoRA，动态搜索最优LoRA秩配置，针对特定多模态任务平衡性能和计算效率。

Result: 在多个数据集上使用LLaMA-3.2-11B模型进行广泛实验，显示出模型性能显著提升，同时降低了微调成本。

Conclusion: LangVision-LoRA-NAS框架通过动态秩优化，为视觉语言模型的高效微调提供了有效的解决方案，在性能和效率之间取得了良好平衡。

Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [85] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 使用交叉视角变换器(CVT)将相机图像映射到鸟瞰图(BEV)的三个通道：道路、车道标记和规划轨迹，在模拟器中进行城市驾驶感知研究


<details>
  <summary>Details</summary>
Motivation: 鸟瞰图(BEV)为自动驾驶感知提供了结构化的自上而下抽象表示，需要研究如何从相机输入有效映射到BEV地图

Method: 使用交叉视角变换器(CVT)，在模拟器中训练模型将相机图像映射到BEV的三个通道，研究不同相机布局和损失函数(L1和focal损失)的影响

Result: 在仅使用一个城镇训练数据的情况下，采用L1损失的四相机CVT模型在新城镇测试中表现最鲁棒

Conclusion: 交叉视角变换器在将相机输入映射到相对准确的BEV地图方面显示出良好潜力

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [86] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo是一种基于协同训练的多模态个性化表情识别方法，通过选择相关源主体并利用多模态互补信息进行主体特异性适应，在BioVid和StressID数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多源域适应方法往往忽视多模态信息或将多个源域混合为单一域，限制了主体多样性，无法明确捕捉独特的主体特异性特征。

Method: 基于协同训练的多模态主体特异性选择和适应方法，选择与目标相关的源主体，使用主导模态生成伪标签进行类感知学习，并结合类无关损失从置信度较低的目标样本中学习，对齐各模态的源特征并仅组合置信的目标特征。

Result: 在具有挑战性的多模态表情识别数据集BioVid和StressID上，MuSACo能够优于无监督域适应（混合）和最先进的多源域适应方法。

Conclusion: MuSACo通过有效利用多模态和多源域信息，成功解决了个性化表情识别中的主体特异性适应问题，在数字健康等情感计算应用中具有重要价值。

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [87] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: REVEAL框架利用视觉语言模型的语义对齐能力，将图像伪造检测构建为提示驱动的视觉推理任务，通过整体场景评估和区域异常检测两种方法实现跨域泛化。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展使得视觉伪造检测和解释变得更加困难，现有方法在跨域泛化方面存在挑战，需要既能检测伪造又能提供推理和定位的鲁棒框架。

Method: 提出REVEAL框架，采用两种方法：(1)整体场景级评估：基于图像的物理、语义、透视和整体真实性；(2)区域异常检测：将图像分割成多个区域并分别分析。

Result: 在不同领域数据集（Photoshop、DeepFake和AIGC编辑）上进行实验，与竞争基线比较并分析模型提供的推理能力。

Conclusion: 基于视觉语言模型的提示驱动方法能够有效解决图像伪造检测的跨域泛化问题，提供可解释的检测结果。

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [88] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: 提出SFAC算法，仅需两张图像即可实现老照片着色，通过特征对齐和结构保持机制解决域差距问题


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法需要大规模数据集，但老照片着色缺乏真实标签且存在域差距问题，需要小样本解决方案

Method: 基于CNN的SFAC算法，使用特征分布对齐损失建立语义对应，结合特征级感知约束和像素级金字塔结构保持机制

Result: 实验证明该方法在老照片着色任务中有效，通过定性和定量指标验证

Conclusion: SFAC算法成功解决了老照片着色的域差距问题，仅需少量样本即可实现高质量着色

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [89] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: 提出了USDRL框架，一个基于骨架的动作理解基础模型，通过Transformer编码器、多粒度特征解相关和多视角一致性训练，在25个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作理解方法缺乏可扩展性和泛化能力，没有能够适应广泛动作理解任务的基础模型。

Method: USDRL框架包含：1）Transformer密集时空编码器（DSTE）学习时空特征；2）多粒度特征解相关（MG-FD）减少维度冗余；3）多视角一致性训练（MPCT）进行自监督学习。

Result: 在9个骨架动作理解任务的25个基准测试中，方法显著优于当前最先进方法。

Conclusion: 该工作拓宽了骨架动作理解的研究范围，鼓励更多关注密集预测任务。

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [90] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 提出了MCOUT方法，在联合潜在空间中进行连续推理，替代传统的语言链式思维，显著提升多模态推理性能


<details>
  <summary>Details</summary>
Motivation: 传统语言模型推理方法（如Chain-of-Thought）在多模态环境中效果不佳，难以动态对齐音频、视觉和文本信息，需要探索新的推理范式

Method: 提出Multimodal Chain of Continuous Thought (MCOUT)，在联合潜在空间中进行连续推理，使用连续隐藏向量表示推理状态。开发两个变体：MCOUT-Base重用语言模型最后隐藏状态进行迭代推理，MCOUT-Multi集成多模态潜在注意力增强跨模态对齐

Result: 在MMMU、ScienceQA和MMStar等基准测试中，MCOUT一致提升多模态推理性能，准确率最高提升8.23%，BLEU分数最高提升8.27%

Conclusion: 潜在连续推理是推进大型多模态模型超越语言绑定CoT的有前景方向，为类人反射式多模态推理提供了可扩展框架

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [91] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD是一个基于扩散模型的新型端到端自动驾驶框架，通过并行生成驾驶决策序列显著降低延迟，支持双向推理和渐进式生成，在nuScenes数据集上表现优于现有自回归VLM方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的自回归架构存在推理延迟高、无法双向推理的问题，不适合动态安全关键环境，需要新的解决方案。

Method: 采用掩码扩散模型实现并行生成整个驾驶决策序列，支持双向推理和渐进式易先生成策略。

Result: 在nuScenes数据集上，ViLaD在规划精度和推理速度方面均优于最先进的自回归VLM基线，接近零失败率，并在真实自动驾驶车辆上验证了实用性。

Conclusion: ViLaD框架代表了自动驾驶领域的范式转变，通过扩散模型解决了自回归架构的局限性，为实际应用提供了有效可靠的解决方案。

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [92] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: 该研究构建了首个大规模UGC图像视觉失真评估指令调优数据集ViDA-UGC，包含11K图像和细粒度质量标注，通过CoT框架指导GPT-4o生成质量描述，显著提升了多模态大语言模型的图像质量分析能力。


<details>
  <summary>Details</summary>
Motivation: 当前可解释图像质量评估方法存在两个主要问题：对用户生成内容(UGC)和AI生成内容(AIGC)使用相同的失真标准进行评估，以及缺乏详细的图像质量分析和修复指导能力。

Method: 通过失真导向的流程构建ViDA-UGC数据集，包含人工标注和思维链(CoT)评估框架，指导GPT-4o识别和分析UGC失真模式，生成详细质量描述。从数据集中精选476张图像和6,149个问答对构建评估基准ViDA-UGC-Bench。

Result: 实验结果表明，ViDA-UGC数据集和CoT框架有效提升了多种基础MLLM在ViDA-UGC-Bench和Q-Bench上的图像质量分析能力，甚至超越了GPT-4o的表现。

Conclusion: 该研究为UGC图像质量评估提供了首个大规模指令调优数据集和评估基准，通过CoT框架成功提升了MLLM的图像质量分析能力，为图像质量监控和修复指导提供了有效解决方案。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [93] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: 提出了OpenMoCap模型和CMU-Occlu数据集，解决光学运动捕捉中大规模标记遮挡问题，通过射线追踪模拟真实遮挡模式，采用标记-关节链推理机制实现鲁棒运动捕捉。


<details>
  <summary>Details</summary>
Motivation: 当前光学运动捕捉系统在现实应用中的大规模标记遮挡情况下性能严重下降，主要原因是缺乏反映真实遮挡模式的训练数据集和捕获标记间长程依赖关系的训练策略。

Method: 引入CMU-Occlu数据集使用射线追踪技术模拟真实遮挡模式；提出OpenMoCap模型，采用标记-关节链推理机制，同时优化和构建标记与关节之间的深度约束。

Result: 大量对比实验表明OpenMoCap在各种场景下始终优于竞争方法，CMU-Occlu数据集为鲁棒运动求解的未来研究打开了大门。

Conclusion: OpenMoCap模型和CMU-Occlu数据集有效解决了运动捕捉中的遮挡问题，模型已集成到MoSen MoCap系统中实际部署，代码已开源。

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [94] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES是一种基于小波的通用视觉基元表示方法，通过小波的空间-频率局部化优势，能够同时捕捉低频和高频信息，并提供快速渲染。


<details>
  <summary>Details</summary>
Motivation: 现有视觉表示方法往往依赖频率指导或复杂神经网络解码，导致频谱损失或渲染速度慢，需要一种既能保持高质量又能快速渲染的通用视觉表示方法。

Method: 基于小波的空间-频率局部化优势构建WIPES表示，开发基于小波的可微分光栅化器实现快速视觉渲染。

Result: 在2D图像表示、5D静态和6D动态新视角合成等视觉任务中，WIPES相比基于INR的方法具有更高的渲染质量和更快的推理速度，在渲染质量上优于基于高斯的方法。

Conclusion: WIPES作为一种视觉基元表示，能够有效平衡渲染质量和速度，为多维视觉信号表示提供了新的解决方案。

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [95] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: 提出了首个可解释的创意评估与选择范式Creative4U，基于多模态大语言模型，通过Reason-to-Select RFT训练方法，在构建的CreativePair数据集上实现准确的创意图像评估和选择。


<details>
  <summary>Details</summary>
Motivation: 电商平台创意图像对用户体验和广告收入至关重要，但现有方法主要关注创意排名，无法满足可解释创意选择的需求。AIGC技术让广告主能低成本生产大量创意图像，但缺乏有效的质量评估方法。

Method: 基于多模态大语言模型，将创意评估和选择转化为自然语言生成任务。构建CreativePair数据集（8k标注图像对），提出Creative4U模型，采用Reason-to-Select RFT训练方法（包括CoT-SFT监督微调和GRPO强化学习）。

Result: 离线和在线实验证明了方法的有效性，模型能够准确评估和选择创意图像，同时考虑用户兴趣偏好。

Conclusion: 该研究为创意图像评估和选择提供了首个可解释的解决方案，通过多模态大语言模型和创新的训练方法，在电商广告场景中展现出良好的应用前景。

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [96] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: 提出了一种名为Context Transfer的新颖云边协作范式，将延迟的LVLM输出作为历史上下文来指导SVLM的实时推理，设计了SpotVLM框架来提升视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有云边协作方法无法适应云延迟波动，且未能充分利用延迟但准确的LVLM响应，需要新的协作策略来满足实时应用的快速可靠响应需求。

Method: 提出了Context Transfer范式，将大型视觉语言模型(LVLM)的延迟输出作为历史上下文，为小型视觉语言模型(SVLM)提供实时指导。设计了SpotVLM框架，包含上下文替换和视觉聚焦模块来优化历史文本输入和增强视觉定位一致性。

Result: 在四个数据集上的三个实时视觉任务上进行了广泛实验，证明了所提框架的有效性。

Conclusion: 这种新范式为未来VLM系统中更有效和延迟感知的协作策略奠定了基础。

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [97] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: 提出了一种两阶段后验均值整流流（PMRF）管道，用于从非对比输入合成体积对比增强脑部MRI，以替代传统钆剂增强扫描。


<details>
  <summary>Details</summary>
Motivation: 传统对比增强MRI需要使用钆剂，这会增加成本、扫描时间，带来环境问题，并对患者有潜在风险。需要开发无需对比剂的替代方案。

Method: 两阶段方法：首先使用基于patch的3D U-Net预测体素级后验均值（最小化MSE），然后通过时间条件3D整流流进行细化，以在不影响结构保真度的情况下加入真实纹理。

Result: 在360个测试样本上，最佳细化输出达到轴向FID 12.46和KID 0.007（比后验均值降低约68.7%），同时保持低体积MSE 0.057（比后验均值高约27%）。

Conclusion: 该方法能够真实地恢复病变边缘和血管细节，有效解决了感知-失真权衡问题，适合临床部署。

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [98] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: 本文提出BEE方法，通过多级一致性正则化和互补锚点重放机制，在持续测试时适应中平衡探索新域和利用历史知识的能力


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法存在两个主要问题：1）深层预测调整对浅层特征域偏移效率低下，导致探索缓慢；2）单一模型在探索新域时会遗忘历史知识，无法有效利用相似域的处理经验

Method: 采用均值教师框架，提出多级一致性正则化(MCR)损失对齐师生模型中间特征加速适应，以及互补锚点重放(CAR)机制重用历史检查点恢复多样化域知识

Result: 在多个基准测试中显著优于最先进方法

Conclusion: BEE方法有效解决了CTTA中探索与利用的平衡问题，通过特征级对齐和知识重放机制实现了快速适应和知识保持

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [99] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd是一个从大场景视频中重建数百人3D姿态、位置和形状的首个框架，采用粗到细的群体引导运动优化策略，结合VAE运动先验和异步运动一致性损失，解决了遮挡和时间不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法从静态图像重建3D人群存在时间不一致性和遮挡问题，需要开发能够从视频中重建动态人群的鲁棒方法。

Method: 提出粗到细的群体引导运动优化策略，结合VAE运动先验和段级群体引导优化，利用异步运动一致性损失(AMC)让未遮挡运动段指导遮挡段的恢复。

Result: 实验结果表明该方法在大场景动态人群重建任务中达到state-of-the-art性能，并贡献了VirtualCrowd虚拟基准数据集。

Conclusion: DyCrowd框架能够有效处理大场景视频中的动态人群重建，解决了遮挡和时间一致性问题，为相关应用提供了有力工具。

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [100] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 提出了一种两阶段的人体去遮挡方法，先通过扩散模型和关节热图完成遮挡掩码重建，再利用文本特征和Stable Diffusion进行RGB外观重建，有效解决了严重遮挡下的人体结构恢复问题。


<details>
  <summary>Details</summary>
Motivation: 人类能够利用先验知识和可见线索推断被遮挡物体的缺失部分，但让深度学习模型准确预测被遮挡区域仍然具有挑战性。现有基于扩散的去遮挡方法在潜在空间转换时会导致可见区域的像素级退化。

Method: 两阶段方法：1) 掩码补全阶段使用基于扩散的人体先验和遮挡关节热图提供身体结构表示；2) RGB补全阶段使用重建的amodal掩码作为条件输入，结合VQA模型提取的人类特定文本特征，通过微调的Stable Diffusion进行RGB重建。

Result: 方法在严重遮挡下有效重建人体外观，在掩码和RGB补全方面均优于现有方法。生成的去遮挡图像能够提升下游任务（如2D姿态估计和3D人体重建）的性能。

Conclusion: 该方法通过分解任务和结合多种先验信息，成功解决了人体去遮挡问题，为人体中心的下游任务提供了高质量的输入数据。

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [101] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: 本文研究使用CLIP视觉语言模型预测Wölfflin的五项艺术风格原则，发现预训练CLIP无法直接捕捉这些细微风格特征，通过微调后提出的WP-CLIP模型能有效预测艺术风格原则并泛化到不同艺术风格。


<details>
  <summary>Details</summary>
Motivation: 现有指标无法有效预测Wölfflin的五项艺术风格原则，而视觉语言模型在评估抽象图像属性方面展现出潜力，因此研究CLIP是否能理解和预测这些艺术风格原则。

Method: 在真实艺术图像的标注数据集上微调CLIP模型，为每项Wölfflin原则预测评分，提出WP-CLIP模型。

Result: WP-CLIP在GAN生成绘画和Pandora-18K艺术数据集上表现出色，能够泛化到不同的艺术风格。

Conclusion: 视觉语言模型在自动化艺术分析方面具有巨大潜力，微调后的CLIP模型能够有效预测复杂的艺术风格原则。

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [102] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: 该论文提出了Vision-G1模型，通过构建包含46个数据源、8个维度的综合视觉推理数据集，并采用基于影响函数的数据选择和难度过滤策略，使用多轮RL训练实现最先进的视觉推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的训练主要集中在数学和逻辑推理等有限任务上，导致模型难以泛化到更广泛的领域，且缺乏可验证的奖励数据和跨领域数据整合的挑战。

Method: 构建包含8个维度（信息图、数学、空间、跨图像、图形用户界面、医学、常识和通用科学）的综合数据集，采用基于影响函数的数据选择和难度过滤策略，使用多轮强化学习配合数据课程进行训练。

Result: Vision-G1模型在各种视觉推理基准测试中达到最先进性能，超越同类规模的VLM模型甚至GPT-4o和Gemini-1.5 Flash等专有模型。

Conclusion: 通过构建全面的多领域数据集和创新的训练策略，成功提升了视觉语言模型的泛化推理能力，证明了跨领域数据整合的有效性。

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [103] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV是一个创新的多无人机协同3D检测框架，通过实例感知的BEV表示学习和对比学习，在保持低分辨率输入的同时实现了优异的精度-计算权衡


<details>
  <summary>Details</summary>
Motivation: 多无人机协同3D检测虽然能提供多视角观测和更好的覆盖范围，但在资源受限的无人机平台上计算负担重，现有方法对所有BEV网格平等处理效率低下

Method: 提出Box-Guided Refinement Module (BG-RM)仅精炼前景实例相关的BEV网格，使用2D监督和空间细分；Instance-Background Contrastive Learning (IBCL)在BEV空间通过对比学习增强前景和背景特征的可区分性

Result: 在Air-Co-Pred数据集上的大量实验表明，AdaBEV在不同模型尺度上都实现了优越的精度-计算权衡，在低分辨率下优于其他最先进方法，接近上限性能

Conclusion: AdaBEV通过自适应实例感知BEV表示学习，有效解决了多无人机协同3D检测中的计算效率问题，为资源受限平台提供了实用的解决方案

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [104] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: TTA-DAME方法通过源域数据增强、域鉴别器和专门域检测器来处理测试时适应中的动态域偏移问题，特别是在驾驶场景中的天气变化，通过多检测器和NMS整合提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决测试时适应(TTA)中模型需要动态适应变化目标域的挑战，特别是在真实驾驶场景中频繁发生的天气域偏移问题。

Method: 利用源域数据增强到目标域，引入域鉴别器和专门域检测器来缓解剧烈域偏移（如白天到夜间），训练多个检测器并通过非极大值抑制(NMS)整合预测结果。

Result: 在SHIFT基准测试上显示出显著性能提升，验证了方法的有效性。

Conclusion: 提出的TTA-DAME方法能够有效处理动态域偏移问题，特别是在驾驶场景的天气变化适应方面表现优异。

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [105] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: 本文提出了多级知识蒸馏(MLKD)和动态自监督损失(SSL)两个组件，用于解决类增量重复学习(CIR)场景下的稳定性与可塑性平衡问题，在CVPR CLVISION挑战赛中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 传统的类增量学习假设每个任务都包含新类别，而CIR场景更现实地考虑了类别重复出现的情况，并且可以利用互联网等外部来源的大量未标注数据。

Method: 1. 多级知识蒸馏(MLKD)：从多个先前模型的不同层面（特征和logits）提取知识；2. 动态自监督损失(SSL)：利用未标注数据加速新类学习，通过动态权重保持对主要任务的关注。

Result: 所提出的两个组件显著提升了CIR设置下的性能表现，在CVPR第5届CLVISION挑战赛中获得了第二名。

Conclusion: 该方法通过有效利用未标注数据和多角度知识蒸馏，成功解决了CIR场景下的稳定性-可塑性权衡问题，为现实世界的增量学习应用提供了有效解决方案。

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [106] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: 本文研究了自动驾驶车辆不同相机传感器配置导致的跨传感器域差距问题，提出了CamShift数据集来模拟这种差距，并发现基于稠密BEV表示的模型最鲁棒，同时提出了基于神经渲染的数据驱动传感器适配管道来缓解性能下降。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆因车型限制而有不同的相机传感器配置，导致在一种配置上训练的感知模型在其他配置上性能下降，需要解决这种跨传感器域差距问题。

Method: 创建CamShift数据集模拟紧凑型车和SUV的传感器差距，评估不同3D目标检测器的性能，并提出基于神经渲染的传感器适配管道来转换数据集以匹配不同传感器配置。

Result: 发现基于稠密BEV表示和反向投影的模型（如BEVFormer）对传感器配置变化最鲁棒，提出的传感器适配方法显著提升了所有检测器的性能，大幅缓解了跨传感器域差距。

Conclusion: 不同传感器配置确实会导致显著的性能下降，但通过合适的模型架构和数据驱动的传感器适配方法可以有效缓解这一问题，提高数据在不同车辆间的复用性。

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [107] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: GenAI驱动的新闻多样性导致多级漂移，显著降低现有LVLM多模态虚假信息检测系统的鲁棒性，性能平均下降14.8%且推理不稳定


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具带来的新闻内容多样性对多模态虚假信息检测构成新挑战，需要系统研究其对检测系统鲁棒性的影响

Method: 构建DriftBench大规模基准数据集（16,000个新闻实例，6种多样化类别），设计三个评估任务：真实性验证鲁棒性、对抗性证据污染敏感性、推理一致性分析

Result: 六个最先进的LVLM检测器性能显著下降（平均F1下降14.8%），推理轨迹不稳定，在对抗性证据注入下表现更差

Conclusion: 现有MMD系统存在根本性脆弱性，在GenAI时代迫切需要更具弹性的方法

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [108] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 基于CNN深度学习的手语实时翻译系统，通过摄像头捕捉手势并转换为文本和语音输出，帮助听障人士实现无障碍沟通


<details>
  <summary>Details</summary>
Motivation: 解决听障人士在日常交流中面临的语言障碍问题，提升他们的社交参与度和自主性

Method: 使用卷积神经网络(CNN)在Sign Language MNIST数据集上训练，实时通过摄像头捕捉手势并进行分类识别

Result: 系统实现了高准确率的手势识别和实时翻译功能，虽然存在一定延迟但性能稳定可靠

Conclusion: 该系统为听障人士提供了一个实用、易用的辅助沟通工具，有效促进了他们在不同社交场景中的融入

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [109] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 提出Dual Contrastive Denoising Score框架，利用文本到图像扩散模型的生成先验，通过双对比损失实现真实图像编辑，既能灵活修改内容又能保持结构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在编辑真实图像时面临两个挑战：用户难以准确描述图像细节的文本提示，以及编辑过程中经常意外改变不需要修改的区域。

Method: 在潜在扩散模型中引入双对比损失，利用自注意力层的中间表示空间信息，无需依赖辅助网络，实现零样本图像到图像转换。

Result: 通过大量实验证明，该方法在真实图像编辑方面优于现有方法，同时保持直接使用预训练文本到图像扩散模型的能力。

Conclusion: 该方法成功解决了真实图像编辑中的关键问题，实现了内容修改灵活性和结构保持的平衡，为扩散模型在图像编辑领域的应用提供了有效解决方案。

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [110] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 本文分析了稀疏视角下3D高斯泼溅(3DGS)的外观伪影问题，发现高斯之间的过度纠缠(co-adaptation)是主要原因，提出了量化指标CA和两种轻量级解决方案。


<details>
  <summary>Details</summary>
Motivation: 3DGS在密集视角下表现优异，但在稀疏视角下会出现外观伪影。本文旨在探究这些伪影的根源并找到解决方案。

Method: 提出了Co-Adaptation Score (CA)指标来量化高斯纠缠程度，并设计了两种轻量级策略：随机高斯丢弃和透明度乘性噪声注入。

Result: 分析表明高斯纠缠程度随训练视角增加而自然缓解，提出的两种策略在各种方法和基准测试中都验证了有效性。

Conclusion: 对co-adaptation效应的深入理解将为稀疏视角3DGS提供更全面的认识，所提出的轻量级解决方案具有即插即用的优势。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [111] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 提出FDIKP网络，通过频率域表示增强核估计的结构可识别性，采用双分支逆核预测策略提高估计精度，引入位置自适应卷积增强解卷积适应性，使用双域尺度循环模块逐步提升去模糊质量


<details>
  <summary>Details</summary>
Motivation: 单图像散焦去模糊的关键挑战是准确建模空间变化的模糊核，现有方法在严重模糊区域性能下降，因为局部高频细节缺失

Method: 频率驱动的逆核预测网络(FDIKP)，包含双分支逆核预测策略、位置自适应卷积(PAC)和双域尺度循环模块(DSRM)

Result: 在广泛实验中表现优于现有方法

Conclusion: 该方法通过频率域表示和创新的网络设计，有效解决了散焦去模糊中核估计的挑战，提升了去模糊质量

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [112] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为DCSCR的少样本图像集分类方法，结合传统方法和深度学习，通过深度特征提取、全局特征学习和类特定协同表示度量学习模块，同时学习帧级和概念级特征表示以及集合间距离相似性。


<details>
  <summary>Details</summary>
Motivation: 解决现有传统方法忽略特征学习、深度方法在度量集合距离时无法自适应调整特征的问题，提升少样本图像集分类性能。

Method: DCSCR网络包含三个模块：全卷积深度特征提取器、全局特征学习模块、基于类特定协同表示的度量学习模块，使用新的CSCR对比损失函数。

Result: 在多个知名少样本图像集分类数据集上的实验表明，该方法相比现有最先进算法具有更好的性能。

Conclusion: DCSCR方法有效解决了图像集分类中的特征学习和距离度量问题，在少样本场景下表现出优越性能。

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [113] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 提出基于Mamba的双尺度融合和双路径扫描网络，通过选择性传播上下文信息来有效去除阴影，在阴影去除基准测试中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 阴影去除需要利用非阴影区域的丰富信息进行指导，但阴影区域与正常光照区域的变换差异很大，需要有效整合非局部上下文线索和自适应建模区域特定变换

Method: 提出双尺度融合Mamba块(DFMB)融合原始特征和低分辨率特征增强多尺度表示，双路径Mamba组(DPMG)通过水平扫描捕获全局特征并采用掩码感知自适应扫描策略

Result: 在阴影去除基准测试中显著优于现有最先进方法

Conclusion: 该方法通过选择性上下文传播和自适应区域建模，有效解决了阴影去除中变换差异大的挑战

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [114] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA是一个基于深度学习的框架，用于在急性缺血性卒中机械取栓术中分类数字减影血管造影图像的关键属性，提高下游图像质量控制和分割性能。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉模型在机械取栓术中辅助应用时，图像质量差会严重影响性能，需要自动化的图像质量评估工具来支持临床工作流程优化。

Method: 使用预训练的ResNet骨干网络进行微调，训练九个独立的分类器来预测图像属性（如对比剂存在、投影角度、运动伪影严重程度等），基于1758张标注的荧光透视最小强度投影图像。

Result: 模型在所有标签上都表现出色，ROC-AUC范围为0.91-0.98，精确度范围为0.70-1.00。在分割任务中，过滤低质量图像后分割成功率从42%提升到69%。

Conclusion: CLAIRE-DSA作为自动化工具在急性缺血性卒中患者的DSA序列中准确分类图像属性方面显示出强大潜力，支持临床和研究应用中的图像标注和质量控制。

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [115] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: 提出了ICAF框架解决CdZnTe半导体图像标注难题，通过组内一致性增强处理多视图到单一GT的映射关系，在仅使用2%标注数据下达到70.6% mIoU


<details>
  <summary>Details</summary>
Motivation: CdZnTe半导体图像标注困难，低对比度缺陷边界需要多视图交叉参考，传统半监督分割方法的一对一关系限制导致误差积累和确认偏差

Method: 提出Intra-group Consistency Augmentation Framework (ICAF)，包含Intra-group View Sampling (IVS)建立组基线，Pseudo-label Correction Network (PCN)增强一致性表示，包含View Augmentation Module (VAM)合成边界感知视图和View Correction Module (VCM)进行信息交互

Result: 在CdZnTe数据集上使用DeepLabV3+和ResNet-101骨干网络，仅用2%组标注数据就达到70.6% mIoU

Conclusion: ICAF框架有效解决了CdZnTe材料的多视图标注问题，通过组内一致性增强显著提升了低对比度区域的标注精度

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [116] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: SocialTrack是一个针对无人机视角下多目标跟踪的框架，通过多尺度特征增强、速度自适应卡尔曼滤波、群体运动补偿和时空记忆预测等技术，显著提升了复杂城市交通环境中小目标的跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机多目标跟踪在智能交通系统中具有重要应用价值，但复杂视角下的小目标尺度变化、遮挡、非线性交叉运动和运动模糊等问题严重影响了跟踪稳定性。

Method: 提出SocialTrack框架，包含：1）多尺度特征增强的小目标检测器；2）速度自适应立方卡尔曼滤波（VACKF）用于轨迹预测；3）群体运动补偿策略（GMCS）建模社会群体运动先验；4）时空记忆预测（STMP）利用历史轨迹信息预测未来状态。

Result: 在UAVDT和MOT17数据集上的实验表明，SocialTrack在多个关键指标上优于现有SOTA方法，特别是在MOTA和IDF1等核心性能指标上有显著提升。

Conclusion: SocialTrack框架具有优异的鲁棒性和适应性，且高度模块化和兼容，可与现有跟踪器无缝集成以进一步提升性能。

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [117] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: 提出了一种基于多风格图像的潜在扩散模型风格迁移方法，通过图像提示适配器和去噪过程中的统计特征对齐，在交叉注意力和自注意力层进行干预，实现了最先进的风格化效果。


<details>
  <summary>Details</summary>
Motivation: 现有风格迁移方法存在风格匹配不准确、可用风格图像数量有限、内容与风格纠缠等问题，需要解决这些关键问题来提升风格迁移质量。

Method: 利用多风格图像更好地表示风格特征并防止内容泄露，设计结合图像提示适配器和去噪过程中统计特征对齐的方法，在去噪UNet的交叉注意力和自注意力层进行干预，使用聚类从大量风格样本注意力值中提取代表性特征集。

Result: 实验证明该方法在风格化任务上取得了最先进的成果。

Conclusion: 通过多风格图像和统计特征对齐的联合使用，有效解决了现有风格迁移方法的局限性，实现了高质量的图像风格迁移。

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [118] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 使用深度学习分析谷歌街景图像，开发全球预测模型来估算自行车和摩托车的交通模式份额，在185个城市中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 交通方式影响健康，但全球范围内自行车和摩托车行为的比较数据稀缺，需要高效的数据采集方法来补充传统调查数据。

Method: 使用YOLOv4模型在谷歌街景图像中检测自行车和摩托车，采用beta回归模型建立城市级别的模式份额预测模型，控制人口密度变量。

Result: 模型预测精度较高，摩托车检测相关性0.78，自行车检测相关性0.51，R²值分别为0.614和0.612，中位绝对误差分别为1.3%和1.4%。

Conclusion: 计算机视觉结合街景图像能有效捕捉交通模式活动，为传统数据源提供有价值的补充，特别是在缺乏最新模式份额数据的城市中。

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [119] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 使用计算机视觉方法对食双星光变曲线进行分类，通过预训练的ResNet50和ViT模型在合成数据集上进行微调，采用极坐标和hexbin可视化新方法，在主要分类任务上取得高准确率（>96%），但在星斑检测任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 开发自动化方法对大规模巡天数据中的食双星进行形态分类，解决传统人工分类效率低下的问题，同时探索星斑检测的可能性。

Method: 使用预训练的卷积神经网络（ResNet50）和视觉变换器（ViT）模型，在合成光变曲线图像上进行微调；创新性地将相位折叠光变曲线转换为极坐标并结合hexbin可视化；采用分层分类方法：第一阶段分类分离和过接系统，第二阶段检测星斑存在与否。

Result: 主要二元分类在验证数据上达到>96%的准确率，在OGLE、DEBCat和WUMaCat观测数据测试中表现强劲（>94%，TESS数据达100%）；但星斑自动检测任务表现很差，显示模型在识别细微光度特征方面存在显著局限性。

Conclusion: 计算机视觉在大规模巡天食双星形态分类方面具有巨大潜力，但需要进一步研究开发鲁棒的自动化星斑检测方法。

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [120] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: 提出了一种新的图像生成方法NVG，通过将图像分解为结构化序列，从全局布局到细节逐步细化生成，在ImageNet上实现了优于VAR系列的FID指标


<details>
  <summary>Details</summary>
Motivation: 传统图像生成方法缺乏对生成过程的细粒度控制，需要一种能够分层级、结构化生成图像的新框架

Method: 将图像分解为共享空间分辨率但不同视觉粒度的序列，使用Next Visual Granularity框架从空图像开始逐步细化生成

Result: 在ImageNet数据集上，NVG模型相比VAR系列在FID指标上有明显提升（3.30->3.03, 2.57->2.44, 2.09->2.06），展现出良好的扩展性

Conclusion: NVG框架提供了一种分层级的图像生成方法，实现了对生成过程的细粒度控制，在多个粒度级别上表现出优越性能

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [121] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: CVPR 2025事件视觉研讨会举办的时空实例分割挑战赛概述，包含任务定义、数据集、挑战细节和排名前5团队的方法总结


<details>
  <summary>Details</summary>
Motivation: 推动事件相机和灰度相机数据融合的时空实例分割技术发展，为计算机视觉社区提供标准化评估基准

Method: 基于时空对齐的事件相机和灰度相机数据，预测像素级分割掩码，使用标准化数据集和评估指标进行竞赛

Result: 提供了挑战赛的完整结果和排名，展示了前5名团队的创新方法，相关代码和资源已开源

Conclusion: 该挑战赛成功推动了多模态时空分割技术的发展，为事件视觉领域建立了重要的基准测试平台

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [122] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA是一个基于深度学习的海底图像恢复模型，通过双频增强自注意力机制同时优化空间和频率信息，有效解决水下图像退化问题。


<details>
  <summary>Details</summary>
Motivation: 水下环境的光线散射、吸收和浑浊问题导致图像质量下降，颜色失真，严重影响海洋生物多样性监测、生态评估和自主探索的准确性。

Method: 提出DEEP-SEA模型，采用双频增强自注意力空间和频率调制器，自适应地在频域中细化特征表示，同时保持空间信息以更好地保护结构完整性。

Result: 在EUVP和LSUI数据集上的实验表明，该模型在恢复精细图像细节和结构一致性方面优于现有最先进方法。

Conclusion: DEEP-SEA通过有效缓解水下视觉退化，有望提高水下监测平台的可靠性，实现更准确的生态观测、物种识别和自主导航。

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [123] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 提出MMPDA框架解决跨域多模态欺骗检测中的域偏移问题，通过渐进式域适应方法在特征和决策层面进行对齐，在MMDD挑战赛中获得第二名


<details>
  <summary>Details</summary>
Motivation: 针对多模态欺骗检测中源域和目标域之间的域偏移问题，需要开发有效的跨域适应方法来提升模型在目标域的性能

Method: 多源多模态渐进式域适应(MMPDA)框架，通过逐步在特征和决策层面对齐源域和目标域，实现跨多模态数据集的域偏移桥接

Result: 在竞赛第二阶段达到60.43%准确率和56.99% F1分数，F1分数比第一名高5.59%，准确率比第三名高6.75%

Conclusion: MMPDA框架有效解决了多模态欺骗检测中的跨域适应问题，在MMDD挑战赛中表现出色，证明了渐进式域适应方法的有效性

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [124] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 提出CoMuCo方法，通过多视图协作优化增强视觉语言模型在跨域少样本任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在自然图像上表现良好，但在与自然图像差异较大的跨域任务中效果有限，需要改进跨域适应能力

Method: 使用两个功能互补的专家模块提取多视图特征，结合基于先验知识的一致性约束和信息几何共识机制来增强特征学习的鲁棒性

Result: 在现有和新提出的跨域少样本基准测试中，CoMuCo方法始终优于当前最先进的方法

Conclusion: CoMuCo策略有效提升了视觉语言模型在跨域少样本任务中的性能，为解决域差异问题提供了新思路

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [125] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: MPS-Tuning是一种新颖的视觉语言模型微调方法，通过保持语义流形的几何结构并增强类别可分性来提升少样本图像分类性能


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型微调方法往往忽略数据分布的几何结构，可能导致整体语义表示的扭曲，需要一种能够保持流形结构的方法

Method: 将特征空间中的数据分布视为语义流形，通过对齐微调前后的Gram矩阵来保持流形的宏观和微观拓扑结构，同时优化图像和文本模态的特征对相似性来增强类别可分性

Result: 大量实验表明MPS-Tuning显著提升了模型性能，同时有效保持了语义流形的结构

Conclusion: MPS-Tuning通过几何结构约束和类别可分性增强，为视觉语言模型的微调提供了一种有效的方法，在保持语义流形结构的同时提升了分类性能

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [126] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: S^2-Guidance是一种新的扩散模型引导方法，通过随机块丢弃构建子网络来改进Classifier-free Guidance的次优预测，在文本到图像和文本到视频生成任务中表现优于CFG和其他先进方法。


<details>
  <summary>Details</summary>
Motivation: 发现Classifier-free Guidance（CFG）在扩散模型中会产生次优预测，导致语义不连贯和低质量输出，需要改进这种引导策略。

Method: 提出S^2-Guidance方法，在前向过程中使用随机块丢弃来构建随机子网络，引导模型远离低质量预测，朝向高质量输出。

Result: 在文本到图像和文本到视频生成任务上的大量实验表明，S^2-Guidance始终超越CFG和其他先进引导策略，提供卓越性能。

Conclusion: S^2-Guidance通过利用模型自身的子网络有效改进CFG的局限性，为扩散模型提供了更高质量的引导方法。

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [127] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: ONG是一种基于非负矩阵分解的一次性剪枝方法，通过梯度掩码机制在训练过程中严格保持目标稀疏度，在CIFAR数据集上实现了与现有方法相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络规模庞大导致部署困难，现有剪枝方法存在迭代过程复杂、标准专业化、训练中难以有效保持稀疏度等问题，需要一种简单有效的一次性剪枝方案。

Method: 提出ONG方法：1）使用非负矩阵分解(NMF)识别重要权重结构进行一次性初始剪枝；2）采用精确的梯度掩码机制确保只更新未剪枝权重，严格保持目标稀疏度；3）在BIMP框架中集成评估。

Result: 在CIFAR-10和CIFAR-100数据集上，使用ResNet56、ResNet34和ResNet18网络，ONG在不同稀疏度水平下都能达到与现有稳定稀疏化方法相当或更优的性能，同时保持剪枝后的结构完整性。

Conclusion: ONG提供了一种简单有效的一次性剪枝解决方案，能够精确控制目标稀疏度，在训练过程中严格保持稀疏结构，为深度神经网络的高效部署提供了有前景的方法。

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [128] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow是一个基于临床报告生成3D CT体积的0.5B参数潜在流匹配变换器模型，通过自回归方式生成连贯的CT切片序列，在时间一致性、图像多样性和文本-图像对齐方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 通过临床报告生成整个CT体积可以加速医学研究，实现数据增强、隐私保护合成，同时减少对患者数据的监管限制，同时保留诊断信号。

Method: 使用FLUX的A-VAE定义潜在空间，CT-Clip文本编码器编码临床报告，采用自定义自回归方法生成连贯的CT体积，首先生成第一个切片序列，然后基于先前生成的序列和文本预测后续序列。

Result: 在FID、FVD、IS分数和CLIP分数等指标上，CTFlow在时间一致性、图像多样性和文本-图像对齐方面均优于最先进的CT生成模型。

Conclusion: CTFlow展示了基于临床报告生成高质量3D CT体积的能力，为医学影像生成提供了有效的解决方案，具有重要的研究和临床应用价值。

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [129] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: CMF-IOU是一个多阶段跨模态融合的3D检测框架，通过深度补全网络生成伪点云统一LiDAR和相机信息表示，采用双边跨视图增强3D骨干网络编码点云，并引入迭代体素-点感知细粒度池化模块和IoU联合预测分支，在多个数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态3D检测方法多为单阶段或部分融合，导致特征提取不足和性能不佳，需要解决3D空间信息与2D语义信息的对齐挑战。

Method: 1) 深度补全网络将像素信息投影到3D空间生成伪点云；2) 双边跨视图增强3D骨干网络(S2D分支和ResVC分支)编码点云；3) 迭代体素-点感知细粒度池化模块捕获空间和纹理信息；4) IoU联合预测分支进行精确边界框优化。

Result: 在KITTI、nuScenes和Waymo数据集上的大量实验表明该方法具有优越性能。

Conclusion: CMF-IOU框架通过多阶段跨模态融合有效解决了3D检测中的信息对齐问题，实现了优异的检测性能。

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [130] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 7Bench是首个同时评估布局引导文本到图像生成中语义和空间对齐的基准测试，包含7个挑战性场景的文本-布局对，并提出了包含布局对齐分数的评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试只评估文本对齐，而忽略了布局对齐，无法全面评估模型的空间保真度，这在合成数据生成等应用中至关重要。

Method: 构建包含7个挑战性场景的文本-布局对数据集，提出结合布局对齐分数的评估协议，用于评估多个最先进的扩散模型。

Result: 评估揭示了不同模型在各种对齐任务中的优势和局限性，为布局引导生成模型的性能提供了全面分析。

Conclusion: 7Bench填补了布局对齐评估的空白，为布局引导文本到图像生成模型的开发和评估提供了重要基准工具。

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [131] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: HiAD是一个针对高分辨率图像异常检测的双分支框架，通过多尺度特征融合和检测器池策略，在有限计算资源下有效检测不同大小的异常区域。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测方法主要针对低分辨率场景，高分辨率图像下采样会导致细粒度信息丢失，现有方法在检测精度和效率上难以满足工业实际需求。

Method: 采用双分支架构整合多尺度异常线索，使用多分辨率特征融合策略处理细粒度纹理变化，并通过检测器池和分配策略自适应分配检测器。

Result: 在MVTec-HD、VisA-HD和RealIAD-HD等高分辨率基准测试中表现出优越性能。

Conclusion: HiAD框架能够有效解决高分辨率图像异常检测的挑战，在保持检测性能的同时控制计算成本，适用于工业应用场景。

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [132] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG是一个两阶段训练的ViT增量学习框架，通过特征增强和知识蒸馏技术同时提升编码器和解码器的泛化能力，有效缓解灾难性遗忘问题，在小内存场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有增量学习方法大多只关注编码器或解码器中的一个组件，限制了缓解灾难性遗忘的效果，特别是在小内存场景下表现更差。需要同时提升编码器和解码器的泛化能力。

Method: 采用两阶段训练框架：1）通过特征增强训练集成编码器学习泛化表示，增强解码器泛化能力并平衡分类器；2）使用平衡知识蒸馏和特征知识蒸馏策略压缩集成编码器，开发新的泛化编码器。

Result: 在三个基准数据集上的大量实验显示SEDEG具有优越性能，消融研究证实了各组件有效性。

Conclusion: SEDEG通过同时提升编码器和解码器的泛化能力，有效解决了增量学习中的灾难性遗忘问题，特别是在小内存场景下表现突出。

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [133] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: 提出了一种基于U-Net架构的自动化框架，用于猕猴示踪数据中的纤维束分割，通过大块尺寸、前景感知采样和半监督预训练，显著提高了稀疏束检测能力并降低了误报率。


<details>
  <summary>Details</summary>
Motivation: 解剖示踪研究对验证和改进扩散MRI纤维束成像至关重要，但手动标注纤维束的过程劳动密集，现有自动化方法常遗漏稀疏束或需要复杂后处理，限制了大规模数据分析。

Method: 采用U-Net架构，结合大块尺寸、前景感知采样策略和半监督预训练方法，实现了对独立切片的自动化纤维束分割。

Result: 相比最先进方法，稀疏束检测提高了20%以上，错误发现率降低了40%，消除了将末端误标为束的常见错误。

Conclusion: 该框架将促进解剖示踪数据的大规模自动化分析，为验证和优化dMRI纤维束成像方法生成更多真实数据。

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [134] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen是一个端到端的视频重光照框架，基于大规模视频生成模型，通过文本描述控制光照和背景，在保持前景一致性的同时实现和谐的视频重光照效果。


<details>
  <summary>Details</summary>
Motivation: 视频重光照是一个具有挑战性但有价值的任务，需要在替换视频背景的同时相应地调整前景的光照并进行和谐融合。现有方法缺乏高质量的多光照条件配对视频数据，且难以保持前景属性的一致性和时间帧间的光照一致性。

Method: 构建混合现实和合成视频的大规模数据集；使用3D渲染引擎生成合成视频对，采用HDR光照模拟补充真实视频；设计联合训练课程，注入域感知适配器解耦重光照和域外观分布的学习。

Result: 实验结果表明，Lumen能够有效地将输入编辑为具有一致光照和严格前景保持的电影级重光照视频，在前景保持和视频一致性评估方面优于现有方法。

Conclusion: Lumen框架通过大规模混合数据集和域感知适配器设计，成功实现了高质量的视频重光照，在保持前景一致性和时间连续性方面表现出色，为视频编辑提供了有效的解决方案。

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [135] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: MaskSem是一种新颖的语义引导掩码方法，通过Grad-CAM指导关节掩码和混合高阶运动重建目标，提升了自监督骨架动作识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督骨架动作识别方法主要关注有限关节集和低阶运动模式，限制了模型对复杂运动模式的理解能力。

Method: 提出语义引导掩码方法MaskSem，利用基于相对运动的Grad-CAM指导关节掩码选择；使用混合高阶运动（速度和加速度）作为重建目标，学习多阶运动模式。

Result: 在NTU60、NTU120和PKU-MMD数据集上的实验表明，MaskSem结合普通transformer能够提升骨架动作识别性能。

Conclusion: 该方法提供了更全面的动态运动过程描述，增强了模型对运动模式的理解，更适合人机交互应用。

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [136] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: ARMed是一个新颖的强化学习框架，通过结合文本正确性和自适应语义奖励来解决医学开放性问题回答中的奖励崩溃问题，在多个医学VQA基准测试中显著提升了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的强化微调方法主要针对封闭式医学视觉问答，而开放式医学VQA更符合临床实践但研究不足。基于模型的语义奖励存在奖励崩溃问题，即语义差异显著的响应获得相似分数。

Method: ARMed首先通过监督微调在思维链数据中融入领域知识，然后应用强化学习结合文本正确性和自适应语义奖励来提升推理质量。

Result: 在六个医学VQA基准测试中，ARMed在域内任务上提升32.64%，在域外基准上提升11.65%，显著提高了准确性和泛化能力。

Conclusion: 研究强调了奖励可区分性在医学强化学习中的关键作用，以及语义引导奖励在实现稳健且具有临床意义的多模态推理方面的潜力。

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [137] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: DLaBella29团队在MICCAI 2025 ToothFairy3挑战赛中提出基于3D SegResNet架构的深度学习管道，用于CBCT图像的多类别牙齿分割，平均Dice得分为0.87


<details>
  <summary>Details</summary>
Motivation: CBCT在牙科诊断和治疗规划中具有重要价值，自动化牙齿结构分割可帮助识别病理（如牙髓或根尖周病变）并促进头颈癌患者的放射治疗规划

Method: 使用MONAI Auto3DSeg框架和3D SegResNet架构，采用5折交叉验证训练，关键预处理包括图像重采样到0.6mm各向同性分辨率和强度裁剪，采用两阶段分割策略：第一阶段使用Multi-Label STAPLE集成融合，第二阶段对下颌骨进行紧密裁剪以分割较小的神经结构

Result: 在ToothFairy3挑战赛的样本外验证集上获得了0.87的平均Dice分数

Conclusion: 该方法展示了自动化牙齿分割在改善放射肿瘤学患者护理方面的相关性和应用价值

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [138] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: GazeDETR是一个新颖的端到端架构，使用两个解耦的解码器分别处理头部定位和视线预测任务，在多个数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端视线目标检测模型使用单一解码器同时定位头部和预测视线，导致表示纠缠。需要解耦这两个任务以获得更好的性能。

Method: 提出GazeDETR架构，包含两个独立的解码器：一个用于头部定位（利用局部信息），一个用于视线预测（结合局部和全局信息），通过相干注意力场有效利用信息。

Result: 在GazeFollow、VideoAttentionTarget和ChildPlay数据集上取得了最先进的成果，显著优于现有的端到端模型。

Conclusion: 解耦的架构设计能够为头部定位和视线预测任务学习独特的表示，证明了该方法在视线通信量化方面的有效性。

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [139] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: 通过分析视频温度变换器的注意力矩阵特征，发现其存在异质性稀疏模式，提出Compact Attention框架，通过自适应分块、变长窗口和自动配置搜索，实现1.6~2.5倍注意力计算加速，保持相当的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制的计算需求给变换器基于视频生成带来严重挑战，特别是在生成超长序列时。现有的因子化注意力和固定稀疏模式方法无法充分利用视频数据中的内在时空冗余性。

Method: 提出Compact Attention加速框架，包括：1)自适应分块策略，通过动态分组近似多样化的空间交互模式；2)时间变化窗口，根据帧间距离调整稀疏程度；3)自动化配置搜索算法，在保留关键注意力通道的同时优化稀疏模式。

Result: 在单GPU环境下实现了注意力计算1.6~2.5倍的加速，同时保持了与全注意力基线相当的视觉质量。

Conclusion: 该工作提供了一种基于结构化稀疏利用的原理性方法，用于开启高效的长形式视频生成。

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [140] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 提出了一种无需标注数据的零样本神经架构搜索代理方法，通过奇异值分解和网络输出外曲率来评估网络架构的收敛性、泛化性和表达能力


<details>
  <summary>Details</summary>
Motivation: 现有零样本NAS代理方法通常需要标注数据，且主要关注收敛性/泛化性或表达能力中的单一属性，无法在真实无标签场景下全面评估架构性能

Method: 利用神经网络层特征的奇异值分解(SVD)和网络输出的外曲率，设计了一个简化的调和平均数作为代理指标，仅需单个无标签数据样本即可计算

Result: 在多个基准测试(NAS-Bench-101、NAS-Bench-201、TransNAS-Bench-101-micro)和搜索空间(DARTS、AutoFormer)上表现出优越性能，且计算高效

Conclusion: 该方法成功解决了零样本NAS中需要标注数据的问题，同时综合考量了网络架构的收敛性、泛化性和表达能力，为实际应用提供了有效的无标签评估方案

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [141] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 本文对多模态视觉目标跟踪(MMVOT)进行了全面综述，涵盖六种MMVOT任务，分析了多模态数据收集、对齐、标注的挑战，并对现有方法进行分类和评估。


<details>
  <summary>Details</summary>
Motivation: 智慧城市发展产生了海量多模态数据，需要从多模态分析的角度研究视觉目标跟踪这一关键任务，探讨多模态跟踪是否总是优于单模态跟踪。

Method: 从数据收集、模态对齐和标注、模型设计、评估四个关键方面分析MMVOT，将现有方法按处理可见光(RGB)和辅助模态(X)的方式进行分类，涵盖热红外、深度、事件、近红外、语言、声纳等多种模态。

Result: 综述了338篇参考文献，首次分析了现有MMVOT数据集中目标类别的分布，发现其明显的长尾性质和动物类别的缺乏。

Conclusion: 多模态跟踪并不总是保证优于单模态跟踪，需要明确在何种情况下应用多模态跟踪是有益的，为未来研究提供了重要指导。

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [142] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: 本文通过实证研究发现，增强特征多样性可以显著改善开放集识别和持续学习性能，促进新类检测和旧知识保留


<details>
  <summary>Details</summary>
Motivation: 虽然现有方法启发式地促进特征多样性来解决开放集识别和持续学习问题，但很少有研究直接探讨特征多样性在这些任务中的具体作用

Method: 通过实证研究分析特征多样性对开放集识别和持续学习的影响，提供经验证据

Result: 增强特征多样性可以改善开放集样本识别，同时促进持续学习中旧数据的保留和新数据的整合

Conclusion: 特征多样性在开放集识别和持续学习中扮演重要角色，这一发现可为这两个领域的实践方法和理论理解提供新的研究灵感

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [143] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: SlimComm是一个通信高效的协作感知框架，通过整合4D雷达多普勒信息和查询驱动的稀疏方案，在保持精度的同时将带宽降低90%


<details>
  <summary>Details</summary>
Motivation: 解决协作感知中密集BEV特征图传输对车载通信带宽的挑战，克服遮挡和传感器范围限制

Method: 构建运动中心动态地图区分动静物体，生成参考查询和探索查询，通过多尺度门控可变形注意力交换和融合查询特定BEV特征

Result: 在OPV2V-R和Adver-City-R数据集上验证，带宽比全图共享降低90%，在不同交通密度和遮挡情况下性能匹配或超越现有基线

Conclusion: SlimComm成功实现了通信效率与感知精度的平衡，为CAV协作感知提供了实用的解决方案

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [144] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 通过视线指导的对比学习和区域感知报告生成框架，结合眼动数据显著提升肺部X光疾病分类和报告生成的性能和可解释性


<details>
  <summary>Details</summary>
Motivation: 利用攻强的眼动数据（MIMIC-Eye数据集）来提升肺部X光的疾病分类精度和报告生成质量，通过模拟攻强的视觉注意力机制来改善医疗图像分析

Method: 两阶段多模态框架：第一阶段使用视线指导的对比学习进行疾病分类，结合多项眼动注意力损失函数；第二阶段通过模块化报告生成流程，提取信心度加权的诊断关键词并映射到解剖区域

Result: 结果显示注意力F1分数从0.597提升到0.631（+5.70%），AUC从0.821提升到0.849（+3.41%），同时改善了精度和召回率，报告质量在临床关键词召回率和ROUGE重叠指标上都有提升

Conclusion: 集成眼动数据能够同时提升疾病分类性能和医疗报告生成的可解释性，证明了视线指导的注意力监督在医学图像分析中的效果性

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [145] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game 2.0是一个实时交互式世界模型，通过少步自回归扩散生成高质量长视频，速度达到25FPS，解决了现有双向注意力模型实时性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有交互式世界模型依赖双向注意力和冗长推理步骤，严重限制了实时性能，难以模拟需要基于历史上下文和当前动作即时更新结果的真实世界动态。

Method: 包含三个关键组件：(1)基于Unreal Engine和GTA5的可扩展数据生产管道，产生约1200小时带交互标注的视频数据；(2)动作注入模块，支持帧级鼠标键盘输入作为交互条件；(3)基于因果架构的少步蒸馏，实现实时流式视频生成。

Result: 能够以25FPS的超快速度生成跨多样化场景的高质量分钟级视频。

Conclusion: Matrix-Game 2.0展示了作为交互式世界模型的潜力，通过开源模型权重和代码库推动交互式世界建模研究发展。

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [146] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: EgoTwin是一个联合生成第一人称视频和人体运动的扩散变换器框架，解决了视角对齐和因果交互两个关键挑战，通过头部中心运动表示和网络启发式交互机制实现视频与运动的同步生成。


<details>
  <summary>Details</summary>
Motivation: 虽然外中心视频合成取得了很大进展，但第一人称视频生成仍然很少被探索，需要同时建模第一人称视角内容和穿戴者身体运动引起的相机运动模式。

Method: 提出EgoTwin框架，基于扩散变换器架构，引入头部中心运动表示将人体运动锚定到头部关节，并采用网络启发式交互机制在注意力操作中显式捕捉视频与运动之间的因果交互。

Result: 通过收集大规模真实世界的同步文本-视频-运动三元组数据集，并设计新的评估指标来验证视频-运动一致性，实验证明了EgoTwin框架的有效性。

Conclusion: EgoTwin成功解决了第一人称视频和人体运动联合生成的关键挑战，为这一新兴领域提供了有效的解决方案和评估基准。

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [147] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR是一个分层特征适应框架，通过参数高效的适配器解决多中心心脏MRI重建中的域偏移问题，在CMRxRecon2025数据集上表现出优异的跨中心泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习心脏MRI重建在多个临床中心部署时面临显著的域偏移挑战，不同扫描仪配置和成像协议导致性能下降。

Method: 提出分层特征适应框架：协议级适配器处理序列特定特征，中心级适配器处理扫描仪相关变化，基于变分展开骨干网络，通用适配器通过随机训练实现未见中心的泛化，使用多尺度SSIM损失和频域增强进行优化。

Result: 在CMRxRecon2025数据集（5+中心、10+扫描仪、9种模态）上的综合评估显示，该方法在保持重建质量的同时实现了优异的跨中心泛化性能。

Conclusion: HierAdaptMR通过分层适配器设计有效解决了多中心心脏MRI重建的域偏移问题，为临床部署提供了实用的解决方案。

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [148] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 提出了一种新颖的多尺度扫描可视化技术，通过语义分割和视觉语言模型识别需要扩展图像覆盖的重要物体，生成球形代理来指导用户扫描，以改善3D高斯溅射等视图合成算法的输入图像采集质量。


<details>
  <summary>Details</summary>
Motivation: 现有的视图合成算法（如3D高斯溅射）在渲染质量和速度方面已取得很大进展，但如何帮助人类收集高质量的输入图像这一问题却被忽视。高质量的视图合成需要均匀密集的视图采样，而人类操作者往往匆忙、缺乏耐心或不理解场景结构和摄影过程，难以满足这一要求。

Method: 提出多尺度扫描的定位可视化技术：1）利用语义分割和类别识别识别需要扩展图像覆盖的重要物体；2）通过视觉语言模型对物体进行排名；3）为高排名物体生成球形代理来指导用户扫描过程。

Result: 在真实场景中相比传统视图采样策略展现出优越性能，能够更好地捕捉视角相关的材质特性。

Conclusion: 该方法通过智能识别重要物体并提供可视化指导，有效解决了人类操作者在图像采集过程中的挑战，为高质量视图合成提供了更好的输入数据采集方案。

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [149] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: 本文提出了Odo方法，一个基于扩散模型的端到端人体形状编辑方法，通过引入大规模数据集和结合ControlNet技术，实现了真实且直观的人体重塑。


<details>
  <summary>Details</summary>
Motivation: 当前人体形状编辑方法依赖3D可变形模型或图像变形，存在身体比例不真实、纹理扭曲和背景不一致等问题，且缺乏大规模公开数据集进行训练和评估。

Method: 提出Odo方法，结合冻结的UNet保留输入图像的细粒度外观和背景细节，使用ControlNet通过目标SMPL深度图引导形状变换。基于新构建的18,573张图像的大规模数据集进行训练。

Result: 方法在顶点重建误差上达到7.5mm，显著优于基线方法的13.6mm，能够产生真实的结果并准确匹配目标形状。

Conclusion: Odo方法通过大规模数据集和创新的扩散模型架构，有效解决了人体形状编辑中的现实性问题，为可控人体形状变换提供了新的解决方案。

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [150] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: 使用Stable Diffusion生成合成真实ID卡图像来提升演示攻击检测系统的泛化能力，解决了真实样本稀缺和数据限制问题


<details>
  <summary>Details</summary>
Motivation: 当前ID卡演示攻击检测系统面临真实样本数量有限和攻击手段多样化的挑战，现有方法主要关注生成攻击样本而忽略了真实样本的稀缺性问题

Method: 提出使用Stable Diffusion生成合成真实ID卡图像的方法，通过在从头训练的系统以及商业解决方案中评估生成图像的效果

Result: 生成的合成图像被PAD系统识别为真实样本，对检测性能和数据限制产生了积极影响

Conclusion: 该方法首次通过生成合成真实样本来改善PAD系统的泛化能力，为解决真实样本稀缺问题提供了有效途径

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [151] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 提出了Chessboard RSVQA数据集和Checkmate模型，通过细粒度视觉推理和可解释性设计，解决遥感视觉问答中的偏见和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 当前RSVQA模型缺乏可解释性，存在数据集偏见和捷径学习问题，需要开发更透明和可信的决策系统。

Method: 创建包含3,123,253个问题的Chessboard数据集，答案分布均衡且与图像单元格关联；开发Checkmate模型，能够识别与决策最相关的图像单元格。

Result: 通过多种模型架构的广泛实验，证明该方法提高了RSVQA系统的透明度和可信度。

Conclusion: 提出的数据集和模型有效解决了RSVQA中的偏见和可解释性问题，支持更可信的决策制定。

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [152] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: 提出DMS方法，利用扩散模型生成新视角图像来补充遮挡区域，提升自监督立体匹配和单目深度估计性能


<details>
  <summary>Details</summary>
Motivation: 自监督方法在立体匹配和深度估计中面临遮挡区域对应像素缺失的问题，导致光度重建存在模糊性

Method: 微调Stable Diffusion模型，沿极线方向生成三个新视角图像（左-左、右-右、中间视图），补充遮挡像素实现显式光度重建

Result: 在多个基准数据集上达到最先进性能，异常值减少高达35%

Conclusion: DMS是一种即插即用的模型无关方法，仅需未标注的立体图像对，能有效提升自监督立体视觉任务的性能

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [153] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: 本研究比较了RT-DETR-Large和RT-DETR-Extra-Large两种模型在沙滩垃圾检测中的性能，发现RT-DETR-X精度略高但计算成本显著，RT-DETR-L在速度和精度间取得更好平衡，更适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 海岸污染是全球性环境问题，需要可扩展的自动化监测解决方案。本研究旨在探索最先进的端到端目标检测模型RT-DETR在沙滩垃圾自动检测和计数中的应用效果。

Method: 使用公开可用的海岸垃圾数据集，对RT-DETR-Large和RT-DETR-Extra-Large两种变体模型进行严格的比较分析，评估其检测精度和推理时间。

Result: RT-DETR-X模型达到mAP@50为0.816，mAP@50-95为0.612，略优于RT-DETR-L的0.810和0.606。但RT-DETR-L推理时间仅20.1ms，显著快于RT-DETR-X的34.5ms。

Conclusion: RT-DETR-L模型在处理速度和检测精度之间提供了更好的平衡，是更实用和高效的实时现场部署解决方案，为基于Transformer的先进检测器在环境保护中的应用提供了重要见解。

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [154] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion是一个无需训练的框架，通过在源骨架和目标骨架之间建立稀疏骨骼对应关系，实现不同拓扑结构角色之间的动画迁移。


<details>
  <summary>Details</summary>
Motivation: 解决不同骨骼拓扑结构角色间动画迁移的挑战，当前缺乏大规模配对运动数据集限制了数据驱动方法的发展。

Method: 提出训练免费的Motion2Motion框架，仅需目标骨架上的一个或几个示例运动，通过建立源骨架和目标骨架之间的稀疏骨骼对应关系来实现动画迁移。

Result: 在相似骨架和跨物种骨架迁移场景中都实现了高效可靠的性能，成功集成到下游应用和用户界面中。

Conclusion: Motion2Motion框架具有工业应用潜力，为解决不同拓扑结构角色间的动画迁移问题提供了有效解决方案。

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [155] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse是一个新颖的3D场景重建框架，通过融合多视角扫描数据来重建交互式高斯场景，解决了物体遮挡和传感器覆盖限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景重建方法存在多阶段流程复杂、需要密集扫描、容易出错且难以扩展的问题，特别是在处理物体遮挡和有限传感器覆盖时效果不佳。

Method: 提出IGFuse框架，构建分割感知的高斯场，通过双向光度和语义一致性约束，引入伪中间场景状态进行统一对齐，并采用协作共剪枝策略来优化几何结构。

Result: 实验验证表明该方法对新场景配置具有很强的泛化能力，能够实现高保真渲染和物体级场景操作，无需密集观测或复杂流程。

Conclusion: IGFuse为真实世界3D重建和真实到仿真的转换提供了有效的解决方案，在多个扫描中通过自然物体重排来揭示被遮挡区域。

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [156] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX是首个从单张图像生成4D（动态3D）场景表示的端到端前馈框架，通过微调预训练视频扩散模型实现高效图像到4D生成


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖计算密集型优化或需要多帧视频输入的问题，提供高效的图像到4D生成方案

Method: 1)构建大规模4DNeX-10M数据集 2)引入统一6D视频表示联合建模RGB和XYZ序列 3)提出适配策略将视频扩散模型重用于4D建模

Result: 生成高质量动态点云支持新视角视频合成，在效率和泛化性方面优于现有4D生成方法

Conclusion: 为图像到4D建模提供可扩展解决方案，为生成式4D世界模型模拟动态场景演化奠定基础

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [157] [Matrix Control Barrier Functions](https://arxiv.org/abs/2508.11795)
*Pio Ong,Yicheng Xu,Ryan M. Bena,Faryar Jabbari,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本文通过将标量控制屏障函数推广到矩阵值函数，提出了矩阵控制屏障函数框架，能够处理由矩阵不等式定义的更丰富安全集，包括非光滑集合，并通过半定规划构建连续的安全滤波器。


<details>
  <summary>Details</summary>
Motivation: 传统标量控制屏障函数难以描述复杂的安全集，特别是非光滑集合和基于布尔逻辑的安全约束（如析取OR操作），需要更强大的数学框架来处理这类问题。

Method: 提出矩阵控制屏障函数，将安全集定义为矩阵不等式（半定和不定），通过半定规划构建安全滤波器，证明其连续性，并特别解决了布尔控制屏障函数中析取操作的连续性问题。

Result: 理论证明了矩阵控制屏障函数安全滤波器的连续性，在无人机网络连接维护和非光滑障碍物避障应用中，通过仿真和硬件实验验证了框架的有效性。

Conclusion: 矩阵控制屏障函数框架扩展了传统方法，能够处理更广泛的安全集类型，特别是非光滑集合和布尔逻辑约束，为复杂安全控制问题提供了有效的解决方案。

Abstract: This paper generalizes the control barrier function framework by replacing
scalar-valued functions with matrix-valued ones. Specifically, we develop
barrier conditions for safe sets defined by matrix inequalities -- both
semidefinite and indefinite. Matrix inequalities can be used to describe a
richer class of safe sets, including nonsmooth ones. The safety filters
constructed from our proposed matrix control barrier functions via semidefinite
programming (CBF-SDP) are shown to be continuous. Our matrix formulation
naturally provides a continuous safety filter for Boolean-based control barrier
functions, notably for disjunctions (OR), without relaxing the safe set. We
illustrate the effectiveness of the proposed framework with applications in
drone network connectivity maintenance and nonsmooth obstacle avoidance, both
in simulations and hardware experiments.

</details>


### [158] [Control of a commercial vehicle by a tetraplegic human using a bimanual brain-computer interface](https://arxiv.org/abs/2508.11805)
*Xinyun Zou,Jorge Gamez,Meghna Menon,Phillip Ring,Chadwick Boulay,Likhith Chitneni,Jackson Brennecke,Shana R. Melby,Gracy Kureel,Kelsie Pejsa,Emily R. Rosario,Ausaf A. Bari,Aniruddh Ravindran,Tyson Aflalo,Spencer S. Kellis,Dimitar Filev,Florian Solzbacher,Richard A. Andersen*

Main category: eess.SY

TL;DR: 研究人员开发了一种双脑机接口系统，让四肢瘫痪患者能够通过脑信号控制车辆在模拟和真实环境中驾驶，表现与健康人相当，展示了BCI技术在恢复独立性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 脑机接口技术主要局限于实验室环境，缺乏实际应用。本研究旨在开发实用的BCI系统，帮助四肢瘫痪患者恢复驾驶能力，提升其独立性和生活质量。

Method: 在瘫痪患者的后顶叶皮层和运动皮层手部区域植入皮质内BCI电极，开发双脑机接口系统，使用光标控制速度和转向，点击控制刹车，实现双手光标-点击控制模式。

Result: 四肢瘫痪患者的反应速度和精确度至少与健康对照组相当，能够熟练驾驶模拟车辆，并成功远程操控真实车辆（福特野马Mach-E），系统安全可行。

Conclusion: 这项首创的可植入BCI应用展示了BCI技术的多功能性和创新潜力，为神经系统严重损伤患者恢复独立性提供了有前景的解决方案。

Abstract: Brain-computer interfaces (BCIs) read neural signals directly from the brain
to infer motor planning and execution. However, the implementation of this
technology has been largely limited to laboratory settings, with few real-world
applications. We developed a bimanual BCI system to drive a vehicle in both
simulated and real-world environments. We demonstrate that an individual with
tetraplegia, implanted with intracortical BCI electrodes in the posterior
parietal cortex (PPC) and the hand knob region of the motor cortex (MC), reacts
at least as fast and precisely as motor intact participants, and drives a
simulated vehicle as proficiently as the same control group. This BCI
participant, living in California, could also remotely drive a Ford Mustang
Mach-E vehicle in Michigan. Our first teledriving task relied on cursor control
for speed and steering in a closed urban test facility. However, the final BCI
system added click control for full-stop braking and thus enabled bimanual
cursor-and-click control for both simulated driving through a virtual town with
traffic and teledriving through an obstacle course without traffic in the real
world. We also demonstrate the safety and feasibility of BCI-controlled
driving. This first-of-its-kind implantable BCI application not only highlights
the versatility and innovative potentials of BCIs but also illuminates the
promising future for the development of life-changing solutions to restore
independence to those who suffer catastrophic neurological injury.

</details>


### [159] [Co-Investment with Payoff-Sharing Mechanism for Cooperative Decision-Making in Network Design Games](https://arxiv.org/abs/2508.12059)
*Mingjia He,Andrea Censi,Emilio Frazzoli,Gioele Zardini*

Main category: eess.SY

TL;DR: 该论文提出了一个结合非合作和合作博弈理论的框架，通过子网络设计游戏和共同投资机制来优化网络系统性能，使自私的运营商和用户都能受益。


<details>
  <summary>Details</summary>
Motivation: 网络系统中自私的运营商决策可能导致用户和整体系统的次优结果，需要探索能够同时使运营商和用户受益的合作机制。

Method: 使用博弈论框架，包含非合作阶段的子网络设计游戏和合作阶段的共同投资与收益分享机制，并在Sioux Falls网络和苏黎世、温特图尔的真实公共交通网络中进行案例研究。

Result: 评估了环境可持续性、社会福利和经济效率的影响，证明了该框架在改善相互依赖的网络系统性能方面的有效性。

Conclusion: 提出的框架为改善相互依赖的网络系统提供了基础，通过促进自私运营商之间的战略合作来实现系统优化。

Abstract: Network-based systems are inherently interconnected, with the design and
performance of subnetworks being interdependent. However, the decisions of
self-interested operators may lead to suboptimal outcomes for users and the
overall system. This paper explores cooperative mechanisms that can
simultaneously benefit both operators and users. We address this challenge
using a game-theoretical framework that integrates both non-cooperative and
cooperative game theory. In the non-cooperative stage, we propose a network
design game in which subnetwork decision-makers strategically design local
infrastructures. In the cooperative stage, co-investment with payoff-sharing
mechanism is developed to enlarge collective benefits and fairly distribute
them. To demonstrate the effectiveness of our framework, we conduct case
studies on the Sioux Falls network and real-world public transport networks in
Zurich and Winterthur, Switzerland. Our evaluation considers impacts on
environmental sustainability, social welfare, and economic efficiency. The
proposed framework provides a foundation for improving interdependent networked
systems by enabling strategic cooperation among self-interested operators.

</details>


### [160] [Feedback Linearization for Replicator Dynamics: A Control Framework for Evolutionary Game Convergence](https://arxiv.org/abs/2508.12583)
*Adil Faisal*

Main category: eess.SY

TL;DR: 将反馈线性化首次应用于复制动态，使非收敛进化博弈系统具有全局渐近稳定性保证


<details>
  <summary>Details</summary>
Motivation: 传统复制动态在处理非收敛进化博弈时缺乏稳定性保证，需要一种控制理论方法来确保系统收敛

Method: 采用反馈线性化技术，通过非线性变换将复制动态系统转化为线性系统，从而实现对进化博弈动态的控制

Result: 成功实现了对非收敛进化博弈系统的控制，获得了全局渐近稳定性的理论保证

Conclusion: 反馈线性化为进化博弈理论提供了有效的控制工具，能够确保复杂博弈动态的收敛性

Abstract: This paper demonstrates the first application of feedback linearization to
replicator dynamics, driving the evolution of non-convergent evolutionary games
to systems with guaranteed global asymptotic stability.

</details>


### [161] [Design of MIMO Lur'e oscillators via dominant system theory with application in multi-agent rhythm synchronization](https://arxiv.org/abs/2508.12141)
*Yu Kawano,Fulvio Forni*

Main category: eess.SY

TL;DR: 提出了一个用于Lur'e振荡器动态输出反馈控制的新设计框架，扩展了主导系统理论并引入了分离原理，应用于多智能体系统的节奏同步。


<details>
  <summary>Details</summary>
Motivation: 解决多输入多输出设置中Lur'e振荡的动态输出反馈控制器设计问题，特别是针对状态依赖速率的情况，旨在通过线性矩阵不等式条件实现控制合成。

Method: 首先扩展主导系统理论到状态依赖速率，推导基于线性矩阵不等式的条件；然后引入Lur'e振荡器设计的分离原理，允许状态反馈振荡器和观测器的独立设计。

Result: 提出的控制合成方法在多智能体系统的节奏同步中得到验证，展示了如何将稳定的异构线性智能体网络驱动到相位锁定的节律行为。

Conclusion: 该框架为Lur'e振荡器的动态输出反馈控制提供了有效的设计方法，特别适用于多智能体系统的同步控制应用。

Abstract: This paper presents a new design framework for dynamic output-feedback
controllers for Lur'e oscillation in a multiple-input multiple-output setting.
We first revisit and extend dominant system theory to state-dependent rates,
with the goal of deriving conditions based on linear matrix inequalities. Then,
we introduce a separation principle for Lur'e oscillator design, which allows
for the independent design of a state-feedback oscillator and an observer. Our
proposed control synthesis is demonstrated through the rhythm synchronization
in multi-agent systems, illustrating how networks of stable, heterogeneous
linear agents can be driven into phase-locked rhythmic behavior.

</details>


### [162] [Euclidean Approach to Green-Wave Theory Applied to Traffic Signal Networks](https://arxiv.org/abs/2508.12146)
*Melvin H. Friedman,Brian L. Mark,Nathan H. Gartner*

Main category: eess.SY

TL;DR: 提出了一种基于欧几里得几何原理的绿波理论，用于实现任意长度信号化主干道的连续交通流，通过道路-旅行者反馈设备协调信号，提高交通效率和减少污染。


<details>
  <summary>Details</summary>
Motivation: 传统信号协调方案在信号数量增加时容易失效，长绿波能够节省旅行时间和燃料、减少污染和交通事故，需要一种能够处理任意长度主干道协调的理论方法。

Method: 基于欧几里得几何原理建立理论框架，定义RGW道路、绿箭头、实节点、虚节点等概念，使用几何推理推导绿箭头长度限制和运动规律，通过RGW-SIM仿真模型验证信号配时效果。

Result: 理论推导出绿箭头长度存在最大值且受离散长度限制，绿箭头运动规律表明现有主干道可转换为RGW道路，仿真验证了信号配时方案的有效性。

Conclusion: 该绿波理论为长信号化主干道提供了有效的协调方法，能够实现连续交通流，提高交通效率并减少环境影响，具有实际应用价值。

Abstract: Travel on long arterials with signalized intersections can be inefficient if
not coordinated properly. As the number of signals increases, coordination
becomes more challenging and traditional progression schemes tend to break
down. Long progressions save travel time and fuel, reduce pollution and traffic
accidents by providing a smoother flow of traffic. This paper introduces a
green-wave theory that can be applied to a network of intersecting arterial
roads. It enables uninterrupted flow on arbitrary long signalized arterials
using a Road-to-Traveler-Feedback Device. The approach is modelled after
Euclid. We define concepts such as RGW-roads (roads where vehicles traveling at
the recommended speed make all traffic signals), green-arrows (representing
vehicle platoons), real nodes (representing signalized intersections where
RGW-roads intersect) and virtual nodes, green-wave speed, blocks, etc. - the
analogue of Euclid's postulates. We then use geometric reasoning to deduce
results: green-arrow lengths have a maximum value, are restricted to discrete
lengths, and green-arrow laws of motion imply that select existing arterial
roads can be converted to RGW-roads. The signal timings and offsets that are
produced have been shown to be effective using a simulation model developed
previously called RGW-SIM.

</details>


### [163] [A layered smart sensing platform for physiologically informed human-exoskeleton interaction](https://arxiv.org/abs/2508.12157)
*Chenyu Tang,Yu Zhu,Josée Mallah,Wentian Yi,Luyao Jin,Zibo Zhang,Shengbo Wang,Muzi Xu,Ming Shen,Calvin Kalun Or,Shuo Gao,Shaoping Bai,Luigi G. Occhipinti*

Main category: eess.SY

TL;DR: 这篇论文提出了一种软质轻型智能腿套，通过多模态感知技术实现对血液、肌肉和皮肤的全面监测，为外骨骼提供个性化的实时辅助控制、优化用户苦继和伤害风险预警。


<details>
  <summary>Details</summary>
Motivation: 可穿戴外骨骼在实际环境中的应用受限于感知系统无法完整捐捕用户的生理和生物力学状态，需要一种轻量、多模态的感知方案来支持下一代人机交互。

Method: 设计了一种软质轻型智能腿套，集成了组织基表面电图（sEMG）电极、超敏感组织应变传感器和惯性测量单元（IMUs）。每种感知模态目标不同的生理层次：IMUs跟踪关节运动学，sEMG监测肌肉激活，应变传感器检测皮肤变形。

Result: 系统在未见过的用户上验证了：(1) 踏关节石矩估计准确（RMSE = 0.13 Nm/kg），(2) 代谢趋势实时分类准确度达97.1%，(3) 伤害风险检测在100毫秒内完成（回归率为0.96）。感知器和电子元件总重小于20克。

Conclusion: 这项工作展示了一种轻型多模态感知架构，为下一代人机外骨骼交互提供了智能、响应式和个性化的可穿戴机器人解决方案，具有扩展到更广泛外骨骼应用的潜力。

Abstract: Wearable exoskeletons offer transformative potential to assist mobility
across diverse user groups with reduced muscle strength or other forms of
impaired mobility. Yet, their deployment beyond laboratory settings remains
constrained by sensing systems able to fully capture users' physiological and
biomechanical states in real time. We introduce a soft, lightweight smart leg
sleeve with anatomically inspired layered multimodal sensing, integrating
textile-based surface electromyography (sEMG) electrodes, ultrasensitive
textile strain sensors, and inertial measurement units (IMUs). Each sensing
modality targets a distinct physiological layer: IMUs track joint kinematics at
the skeletal level, sEMG monitors muscle activation at the muscular level, and
strain sensors detect skin deformation at the cutaneous level. Together, these
sensors provide real-time perception to support three core objectives:
controlling personalized assistance, optimizing user effort, and safeguarding
against injury risks. The system is skin-conformal, mechanically compliant, and
seamlessly integrated with a custom exoskeleton (<20 g total sensor and
electronics weight). We demonstrate: (1) accurate ankle joint moment estimation
(RMSE = 0.13 Nm/kg), (2) real-time classification of metabolic trends (accuracy
= 97.1%), and (3) injury risk detection within 100 ms (recall = 0.96), all
validated on unseen users using a leave-one-subject-out protocol. This work
demonstrates a lightweight, multimodal sensing architecture for next-generation
human-exoskeleton interaction in controlled and semi-structured walking
scenarios, with potential for scaling to broader exoskeleton applications
towards intelligent, responsive, and personalized wearable robotics.

</details>


### [164] [Monotone Neural Control Barrier Certificates](https://arxiv.org/abs/2508.12178)
*Alireza Nadali,Ashutosh Trivedi,Majid Zamani,Saber Jafarpour*

Main category: eess.SY

TL;DR: 提出了一种神经符号框架，利用单调性结构特性，通过单调神经网络合成屏障证书，实现高维单调动力系统的安全控制器合成与验证，仅需线性样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法通常将动力学视为黑盒模型，依赖密集状态空间离散化或Lipschitz过近似，导致指数级样本复杂度。单调性作为现实系统中普遍存在的结构特性，可以简化学习和验证过程。

Method: 结合神经网络的表达能力和符号推理的严谨性，使用单调神经网络架构（嵌入单调性约束）通过梯度优化合成屏障证书。利用序保持特性将验证简化为局部边界检查，将高维问题转化为低维可处理问题。

Result: 在三个大规模基准测试（1000维高速公路交通模型、50维城市交通网络、13000维电网）上验证了方法的可扩展性和有效性。

Conclusion: 该框架实现了从仿真数据直接进行可扩展的形式化验证，在统一的神经符号框架内桥接了黑盒学习和形式化保证。

Abstract: This work presents a neurosymbolic framework for synthesizing and verifying
safety controllers in high-dimensional monotone dynamical systems using only
linear sample complexity, without requiring explicit models or conservative
Lipschitz bounds. The approach combines the expressiveness of neural networks
with the rigor of symbolic reasoning via barrier certificates, functional
analogs of inductive invariants that formally guarantee safety. Prior
data-driven methods often treat dynamics as black-box models, relying on dense
state-space discretization or Lipschitz overapproximations, leading to
exponential sample complexity. In contrast, monotonicity -- a pervasive
structural property in many real-world systems -- provides a symbolic scaffold
that simplifies both learning and verification. Exploiting order preservation
reduces verification to localized boundary checks, transforming a
high-dimensional problem into a tractable, low-dimensional one. Barrier
certificates are synthesized using monotone neural networks -- architectures
with embedded monotonicity constraints -- trained via gradient-based
optimization guided by barrier conditions. This enables scalable, formally
sound verification directly from simulation data, bridging black-box learning
and formal guarantees within a unified neurosymbolic framework. Empirical
results on three large-scale benchmarks -- a 1,000-dimensional freeway traffic
model, a 50-dimensional urban traffic network, and a 13,000-dimensional power
grid -- demonstrate the scalability and effectiveness of the approach in
real-world, safety-critical systems.

</details>


### [165] [Understanding the Fundamental Trade-Off Between Age of Information and Throughput in Unreliable Wireless Networks](https://arxiv.org/abs/2508.12185)
*Lin Wang,I-Hong Hou*

Main category: eess.SY

TL;DR: 本文提出了无线网络中吞吐量与信息新鲜度(AoI)的基本权衡框架，定义了吞吐量-AoI容量区域，并设计了低复杂度调度策略来优化这两个关键性能指标


<details>
  <summary>Details</summary>
Motivation: 解决多设备无线网络中状态更新传输的复杂性问题，由于随机传输成功带来的挑战，需要系统性地优化吞吐量和信息新鲜度的权衡

Method: 提出吞吐量-AoI容量区域概念，使用包含均值和时域方差的二阶近似方法，推导出容量区域的外界和紧内界，并设计简单低复杂度的调度策略

Result: 理论分析建立了吞吐量与AoI的权衡框架，仿真验证表明所提策略在各种实际网络优化场景中显著优于传统方法

Conclusion: 建立了一个系统化、理论基础的框架，用于实际无线通信场景中吞吐量和信息新鲜度的联合优化，证明了方法的有效性和鲁棒性

Abstract: This paper characterizes the fundamental trade-off between throughput and Age
of Information (AoI) in wireless networks where multiple devices transmit
status updates to a central base station over unreliable channels. To address
the complexity introduced by stochastic transmission successes, we propose the
throughput-AoI capacity region, which defines all feasible throughput-AoI pairs
achievable under any scheduling policy. Using a second-order approximation that
incorporates both mean and temporal variance, we derive an outer bound and a
tight inner bound for the throughput-AoI capacity region. Furthermore, we
propose a simple and low complexity scheduling policy and prove that it
achieves every interior point within the tight inner bound. This establishes a
systematic and theoretically grounded framework for the joint optimization of
throughput and information freshness in practical wireless communication
scenarios.
  To validate our theoretical framework and demonstrate the utility of the
throughput-AoI capacity region, extensive simulations are implemented.
Simulation results demonstrate that our proposed policy significantly
outperforms conventional methods across various practical network optimization
scenarios. The findings highlight our approach's effectiveness in optimizing
both throughput and AoI, underscoring its applicability and robustness in
practical wireless networks.

</details>


### [166] [Adaptive Control with Set-Point Tracking and Linear-like Closed-loop Behavior](https://arxiv.org/abs/2508.12225)
*Mohamad T. Shahab*

Main category: eess.SY

TL;DR: 本文提出了一种针对参数未知离散时间系统的自适应控制方法，通过辅助系统参数估计和极点配置控制律，实现了线性化的闭环性能和有界增益保证。


<details>
  <summary>Details</summary>
Motivation: 解决离散时间系统中未知参数（属于凸紧不确定集）的设定点跟踪问题，传统方法难以保证闭环系统性能。

Method: 采用辅助系统参数估计方法，结合基于极点配置的控制律设计自适应控制器。

Result: 证明了控制器能提供理想的线性化闭环行为：初始条件指数衰减、外生输入线性卷积有界、参数估计更新常数平方根相关的常数项有界，系统具有有界增益，且在常值扰动下实现渐近跟踪。

Conclusion: 所提出的自适应控制方法能有效处理参数不确定性，保证系统稳定性和跟踪性能，为离散时间不确定系统控制提供了理论保证。

Abstract: In this paper, we consider the problem of set-point tracking for a
discrete-time plant with unknown plant parameters belonging to a convex and
compact uncertainty set. We carry out parameter estimation for an associated
auxiliary plant, and a pole-placement-based control law is employed. We prove
that this adaptive controller provides desirable linear-like closed-loop
behavior which guarantees a bound consisting of: exponential decay with respect
to the initial condition, a linear-like convolution bound with respect to the
exogenous inputs, and a constant scaled by the square root of the constant in
the denominator of the parameter estimator update law. This implies that the
system has a bounded gain. Moreover, asymptotic tracking is also proven when
the disturbance is constant.

</details>


### [167] [Design and Analysis of Curved Electrode Configurations for Enhanced Sensitivity in 1-Axis MEMS Accelerometers](https://arxiv.org/abs/2508.12249)
*Adhinarayan Naembin Ashok,Adarsh Ganesan*

Main category: eess.SY

TL;DR: 本文通过分析和仿真研究了六种弯曲电极几何形状对MEMS电容式加速度计灵敏度的增强效果，发现双凸电极能最大程度提高灵敏度，且无需改变器件体积或质量块尺寸。


<details>
  <summary>Details</summary>
Motivation: 提高MEMS电容式加速度计的灵敏度，同时保持器件尺寸不变，为高分辨率惯性传感提供解决方案。

Method: 推导了六种不同固定电极轮廓（双凸、双凹、凹凸、凸凹、平凸和平凹）与平面可动电极之间的电容表达式，并使用COMSOL Multiphysics进行有限元仿真验证。

Result: 仿真结果与解析结果偏差小于7%，双凸弯曲电极灵敏度提升最大且随弧长单调增加，凹凸和凸凹配置还引入了输出电压极性反转。

Conclusion: 弯曲电极几何形状能有效增强MEMS加速度计灵敏度，双凸电极性能最优，为高精度惯性传感器设计提供了新的灵活性。

Abstract: This paper presents a comprehensive analytical and simulation-based study of
curved electrode geometries for enhancing the sensitivity of MEMS capacitive
accelerometers. Expressions for the capacitance between a planar movable
electrode and six distinct fixed electrode profiles (biconvex, biconcave,
concavo-convex, convexo-concave, plano-convex, and plano-concave) are derived,
enabling direct calculation of differential gain and sensitivity as functions
of electrode curvature and gap displacement. These analytical models are then
rigorously validated using finite element simulations performed using COMSOL
Multiphysics under identical bias and boundary conditions. The simulation
results demonstrate agreement with the analytical results with a deviation of
less than 7% in all configurations. The results also reveal that biconvex
curved electrodes yield the greatest sensitivity improvement over the planar
electrodes, with sensitivity monotonically increasing with arc length, while
concave and plano-concave designs exhibit reduced performance. The
concavo-convex and convexo-concave configurations furthermore introduce
polarity inversion in the output voltage, offering additional design
flexibility. Importantly, these sensitivity enhancements are achieved without
any change in the overall volumetric dimensions of the device or the proofmass
dimensions of the module for achieving higher-resolution inertial sensing.

</details>


### [168] [Efficient and accurate solution of wind-integrated optimal power flow based on enhanced second-order cone relaxation with rolling cutting plane technique](https://arxiv.org/abs/2508.12351)
*Zhaojun Ruan,Botao Gao,Libao Shi*

Main category: eess.SY

TL;DR: 提出了一种基于增强二阶锥松弛和滚动切割平面技术的风电并网最优潮流解决方案框架，通过高斯混合模型精确建模风电成本，并采用热启动策略提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 大规模风电并网带来的不确定性给电力系统优化运行带来挑战，需要有效处理风电功率预测误差成本并保证AC潮流方程的精确求解。

Method: 使用高斯混合模型建模风电成本，采用二阶锥松弛结合二阶泰勒展开进行凸近似，设计基于滚动切割平面技术的热启动策略减少松弛误差。

Result: 在不同案例研究中验证了所提框架的有效性和效率，并分析了风电成本的影响，证明了该方法的实际应用价值。

Conclusion: 该解决方案框架能够有效处理风电不确定性，提高最优潮流问题的求解精度和计算效率，具有重要的工程应用意义。

Abstract: The integration of large-scale renewable energy sources, such as wind power,
poses significant challenges for the optimal operation of power systems owing
to their inherent uncertainties. This paper proposes a solution framework for
wind-integrated optimal power flow (OPF) that leverages an enhanced
second-order cone relaxation (SOCR), supported by a rolling cutting plane
technique. Initially, the wind generation cost, arising from discrepancies
between scheduled and actual wind power outputs, is meticulously modeled using
a Gaussian mixture model based on historical wind power data. This modelled
wind generation cost is subsequently incorporated into the objective function
of the conventional OPF problem. To achieve the efficient and accurate solution
for the wind-integrated OPF, effectively managing the constraints associated
with AC power flow equations is essential. In this regard, a SOCR, combined
with a second-order Taylor series expansion, is employed to facilitate the
convex approximation of the AC power flow equations. Additionally, a warm-start
strategy, grounded in a proposed rolling cutting plane technique, is devised to
reduce relaxation errors and enhance computational efficiency. Finally, the
effectiveness and efficiency of the proposed solution framework are
demonstrated across various case studies. Specifically, the influence of wind
power cost is also examined, further highlighting the practical implications of
the proposed solution framework.

</details>


### [169] [Data-driven quantification and visualization of resilience metrics of power distribution system](https://arxiv.org/abs/2508.12408)
*Dingwei Wang,Salish Maharjan,Junyuan Zheng,Liming Liu,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 基于历史停电记录和气象数据的数据驱动方法，使用停电次数和恢复时间两个指标来量化配电网对极端天气的韧性


<details>
  <summary>Details</summary>
Motivation: 需要量化评估配电网在极端天气事件中的韧性，为电网规划和运营提供数据支持

Method: 三阶段框架：1）从停电记录中提取停电事件；2）基于NOAA气象传感器位置划分天气区域；3）为每个天气区域建立停电脆弱性和恢复时间的数据驱动模型

Result: 使用美国印第安纳波利斯配电网20年超过16万条停电记录进行验证，能够量化不同强度极端天气下的韧性指标

Conclusion: 提出的数据驱动方法能够有效评估配电网对极端天气的韧性，为电网韧性提升提供量化依据

Abstract: This paper presents a data-driven approach for quantifying the resilience of
distribution power grids to extreme weather events using two key metrics: (a)
the number of outages and (b) restoration time. The method leverages historical
outage records maintained by power utilities and weather measurements collected
by the National Oceanic and Atmospheric Administration (NOAA) to evaluate
resilience across a utility's service territory. The proposed framework
consists of three stages. First, outage events are systematically extracted
from the outage records by temporally and spatially aggregating coincident
component outages. In the second stage, weather zones across the service
territory are delineated using a Voronoi polygon approach, based on the
locations of NOAA weather sensors. Finally, data-driven models for outage
fragility and restoration time are developed for each weather zone. These
models enable the quantification and visualization of resilience metrics under
varying intensities of extreme weather events. The proposed method is
demonstrated using real-world data from a US distribution utility, located in
Indianapolis, focused on wind- and precipitation-related events. The dataset
spans two decades and includes over 160,000 outage records.

</details>


### [170] [A One-Class Explainable AI Framework for Identification of Non-Stationary Concurrent False Data Injections in Nuclear Reactor Signals](https://arxiv.org/abs/2508.12428)
*Zachery Dahm,Vasileios Theos,Konstantinos Vasili,William Richards,Konstantinos Gkouliaras,Stylianos Chatzidakis*

Main category: eess.SY

TL;DR: 提出了一种可解释AI框架，用于检测核反应堆信号中的非平稳并发重放攻击，仅需少量训练数据即可实现高精度检测和攻击源识别


<details>
  <summary>Details</summary>
Motivation: 下一代先进核反应堆系统从模拟向全数字化仪表控制转型，需要强大机制来防范数据完整性威胁。传统线性时不变状态估计器和基于统计阈值的故障检测器容易被虚假数据注入绕过，且真实训练数据有限，使得区分威胁与预期过程异常具有挑战性

Method: 采用可解释AI框架，结合递归神经网络和残差分析，使用改进的SHAP算法和基于规则的关联分析。递归神经网络仅使用正常操作数据训练，残差分析引入自适应窗口技术提高检测精度

Result: 在普渡大学核反应堆真实数据集上验证，检测虚假数据注入准确率超过0.93，误报率低于0.01，能够区分预期过程异常并识别伪造信号来源

Conclusion: 该框架成功解决了核反应堆系统中虚假数据注入检测的挑战，为数字化核反应堆系统的安全防护提供了有效解决方案

Abstract: The transition of next generation advanced nuclear reactor systems from
analog to fully digital instrumentation and control will necessitate robust
mechanisms to safeguard against potential data integrity threats. One challenge
is the real-time characterization of false data injections, which can mask
sensor signals and potentially disrupt reactor control systems. While
significant progress has been made in anomaly detection within reactor systems,
potential false data injections have been shown to bypass conventional linear
time-invariant state estimators and failure detectors based on statistical
thresholds. The dynamic, nonlinear, multi-variate nature of sensor signals,
combined with inherent noise and limited availability of real-world training
data, makes the characterization of such threats and more importantly their
differentiation from anticipated process anomalies particularly challenging. In
this paper, we present an eXplainable AI (XAI) framework for identifying
non-stationary concurrent replay attacks in nuclear reactor signals with
minimal training data. The proposed framework leverages progress on recurrent
neural networks and residual analysis coupled with a modified SHAP algorithm
and rule-based correlations. The recurrent neural networks are trained only on
normal operational data while for residual analysis we introduce an adaptive
windowing technique to improve detection accuracy. We successfully benchmarked
this framework on a real-world dataset from Purdue's nuclear reactor (PUR-1).
We were able to detect false data injections with accuracy higher than 0.93 and
less than 0.01 false positives, differentiate from expected process anomalies,
and to identify the origin of the falsified signals.

</details>


### [171] [Sspherical sailing omnidirectional rover (SSailOR): wind tunnel experimental setup and results](https://arxiv.org/abs/2508.12443)
*Aditya Varanwal,Parin Shah,George Carrion,Ashley Ortenburg,Diego Ramirez-Gomez,Chris Vermillion,Andre P. Mazzoleni*

Main category: eess.SY

TL;DR: 本文介绍了球形帆船全向漫游车(SSailOR)在风洞环境中的测试设计、仪器配置和实验程序，这是一种利用风能驱动的自主漫游车系统。


<details>
  <summary>Details</summary>
Motivation: 开发持久可持续的机器人系统，用于行星探索、北极观测和军事监视等应用，通过风能推进实现长时间移动且能耗最小。

Method: 采用球形设计简化机械复杂性并实现全向移动，通过风洞实验验证动态模型，评估不同配置和环境条件下的空气动力学性能，需要协同设计方法。

Result: 实验验证了动态模型的有效性，评估了漫游车在各种条件下的空气动力学性能，为设计优化提供了关键观察结果。

Conclusion: 球形帆船全向漫游车设计展示了风能推进在可持续机器人系统中的潜力，为未来开发提供了重要的设计优化见解和实验基础。

Abstract: This paper presents the design, instrumentation, and experimental procedures
used to test the Spherical Sailing Omnidirectional Rover (SSailOR) in a
controlled wind tunnel environment. The SSailOR is a wind-powered autonomous
rover. This concept is motivated by the growing need for persistent and
sustainable robotic systems in applications such as planetary exploration,
Arctic observation, and military surveillance. SSailOR uses wind propulsion via
onboard sails to enable long-duration mobility with minimal energy consumption.
The spherical design simplifies mechanical complexity while enabling
omnidirectional movement. Experimental tests were conducted to validate dynamic
models and assess the aerodynamic performance of the rover under various
configurations and environmental conditions. As a result, this design requires
a co-design approach. Details of the mechanical structure, sensor integration,
electronics, data acquisition system, and test parameters are presented in this
paper. In addition, key observations are made that are relevant to the design
optimization for further development of the rover.

</details>


### [172] [Techno-Economic Planning of Spatially-Resolved Battery Storage Systems in Renewable-Dominant Grids Under Weather Variability](https://arxiv.org/abs/2508.12526)
*Seyed Ehsan Ahmadi,Elnaz Kabir,Mohammad Fattahi,Mousa Marzband,Dongjun Li*

Main category: eess.SY

TL;DR: 电池储能系统(BSS)通过两阶段随机规划优化部署，可减少34%可再生能源弃电和21%负荷削减，助力纽约州2030能源目标实现，成本与容量呈非线性关系。


<details>
  <summary>Details</summary>
Motivation: 可再生能源占比增加带来的间歇性和波动性挑战，包括负荷削减和系统拥堵问题，需要电池储能系统来平衡电力供需。

Method: 采用两阶段随机规划方法优化电池的位置、容量和类型，第二阶段包含全年每小时运行决策，考虑电池技术全面经济技术特性，使用1980-2019年负荷和天气数据，通过样本平均近似处理不确定性。

Result: BSS可减少34%可再生能源弃电和21%负荷削减，成本与额外容量不呈线性增长，揭示了成本与可再生能源渗透率之间的复杂关系。

Conclusion: 研究为战略部署BSS实现经济高效可靠电力系统提供了宝贵见解，证明了纽约州2030能源目标的可行性。

Abstract: The ongoing energy transition is significantly increasing the share of
renewable energy sources (RES) in power systems; however, their intermittency
and variability pose substantial challenges, including load shedding and system
congestion. This study examines the role of the battery storage system (BSS) in
mitigating these challenges by balancing power supply and demand. We optimize
the location, size, and type of batteries using a two-stage stochastic program,
with the second stage involving hourly operational decisions over an entire
year. Unlike previous research, we incorporate the comprehensive technical and
economic characteristics of battery technologies. The New York State (NYS)
power system, currently undergoing a significant shift towards increased RES
generation, serves as our case study. Using available load and weather data
from 1980-2019, we account for the uncertainty of both load and RES generation
through a sample average approximation approach. Our findings indicate that BSS
can reduce renewable curtailment by 34% and load shedding by 21%, contributing
to a more resilient power system in achieving NYS 2030 energy targets.
Furthermore, the cost of employing BSS for the reduction of load shedding and
RES curtailment does not increase linearly with additional capacity, revealing
a complex relationship between costs and renewable penetration. This study
provides valuable insights for the strategic BSS deployment to achieve a
cost-effective and reliable power system in the energy transition as well as
the feasibility of the NYS 2030 energy targets.

</details>


### [173] [DCT-MARL: A Dynamic Communication Topology-Based MARL Algorithm for Connected Vehicle Platoon Control](https://arxiv.org/abs/2508.12633)
*Yaqi Xu,Yan Shi,Jin Tian,Fanzeng Xia,Shanzhi Chen,Yuming Ge*

Main category: eess.SY

TL;DR: 提出基于动态通信拓扑的多智能体强化学习算法DCT-MARL，用于解决车联网编队控制中的通信延迟和丢包问题，显著提升了编队稳定性和驾驶舒适性。


<details>
  <summary>Details</summary>
Motivation: 随着车联网和自动驾驶技术的发展，车辆编队控制成为提升交通效率和驾驶安全的重要方式。然而现实交通环境中V2V通信存在时变延迟和丢包问题，严重影响控制性能并带来安全风险。

Method: 提出DCT-MARL算法：1）在状态空间中增加历史控制动作和延迟信息以增强对通信延迟的鲁棒性；2）引入多门控通信机制，根据智能体间相关性和当前通信状态动态调整通信拓扑结构来缓解丢包影响。

Result: 仿真结果表明，DCT-MARL算法在编队稳定性和驾驶舒适性方面显著优于现有最先进方法，验证了其优越的鲁棒性和有效性。

Conclusion: 该研究提出的动态通信拓扑多智能体强化学习方法有效解决了车联网编队控制中的通信质量问题，为实际交通环境中的可靠编队控制提供了有效解决方案。

Abstract: With the rapid advancement of vehicular communication and autonomous driving
technologies, connected vehicle platoon has emerged as a promising approach to
improve traffic efficiency and driving safety. Reliable Vehicle-to-Vehicle
(V2V) communication is critical to achieving efficient cooperative control.
However, in real-world traffic environments, V2V links may suffer from
time-varying delay and packet loss, leading to degraded control performance and
even safety risks. To mitigate the adverse effects of non-ideal communication,
this paper proposes a Dynamic Communication Topology based Multi-Agent
Reinforcement Learning (DCT-MARL) algorithm for robust cooperative platoon
control. Specifically, the state space is augmented with historical control
action and delay to enhance robustness against communication delay. To mitigate
the impact of packet loss, a multi-key gated communication mechanism is
introduced, which dynamically adjusts the communication topology based on the
correlation between agents and their current communication status.Simulation
results demonstrate that the proposed DCT-MARL significantly outperforms
state-of-the-art methods in terms of string stability and driving comfort,
validating its superior robustness and effectiveness.

</details>


### [174] [Stability Analysis of the Newton-Raphson Controller for a Class of Differentially Flat Systems](https://arxiv.org/abs/2508.12694)
*Kaicheng Niu,Yorai Wardi,Chaouki T. Abdallah*

Main category: eess.SY

TL;DR: 本文研究了牛顿-拉夫森控制器在微分平坦非线性系统中的稳定性，证明了输出调节和跟踪控制的稳定性条件，并通过倒立摆和自行车模型的仿真验证了控制效果。


<details>
  <summary>Details</summary>
Motivation: 虽然牛顿-拉夫森控制器在线性系统中的稳定性条件已经建立，但在非线性系统中的稳定性条件尚未探索，特别是对于微分平坦非线性系统的输出调节和跟踪控制问题。

Method: 针对一类微分平坦非线性系统，基于输出预测和牛顿-拉夫森算法，建立了输出调节和跟踪控制的稳定性分析框架，包括可验证的稳定性准则和吸引域度量分析。

Result: 证明了在满足特定稳定性准则时，控制系统在原点邻域内稳定；对于跟踪控制，通过特定参数选择能够驱动输出跟踪外部参考信号；仿真结果显示在倒立摆和自行车模型上分别实现了调节和跟踪控制。

Conclusion: 牛顿-拉夫森控制器在非线性系统中具有良好的稳定性和控制性能，在未来的控制应用中具有潜力。

Abstract: The Newton-Raphson Controller, established on the output prediction and the
Newton-Raphson algorithm, is shown to be effective in a variety of control
applications. Although the stability condition of the controller for linear
systems has already been established, such condition for nonlinear systems
remains unexplored. In this paper, we study the stability of the Newton-Raphson
controller for a class of differentially flat nonlinear systems in the context
of output regulation and tracking control. For output regulation, we prove that
the controlled system is stable within a neighborhood of the origin if the
corresponding flat system and output predictor satisfy a verifiable stability
criterion. A semi-quantitative analysis is conducted to determine the measure
of the domain of attraction. For tracking control, we prove that the controller
is capable of driving the outputs to the external reference signals using a
specific selection of controller parameters. Simulation results show that the
controller achieves regulation and tracking respectively on the inverted
pendulum and the kinematic bicycle, suggesting a potential in future control
applications.

</details>


### [175] [Deadline-Aware Bandwidth Allocation for Semantic Generative Communication with Diffusion Models](https://arxiv.org/abs/2508.12701)
*Jinhyuk Choi,Jihong Park,Seungeun Oh,Seong-Lyun Kim*

Main category: eess.SY

TL;DR: 提出基于语义截止时间的带宽分配方案，在语义生成通信框架中通过优化语义信息和文本描述的传输时机来提升图像修复性能


<details>
  <summary>Details</summary>
Motivation: RAN网络需要同时考虑网络效率和AI性能，特别是在支持语义生成通信的图像修复应用时，需要确保语义信息在关键时间点传输以保证生成质量

Method: 在语义生成通信框架中，发现语义截止时间（语义信息需要注入的最小时间），并基于此设计带宽分配方案，确保每种语义信息在对应的语义截止时间内传输

Result: 实验结果表明，相比不考虑语义截止时间的传统方案，所提方案在给定带宽下获得了更高的PSNR生成性能

Conclusion: 语义截止时间是语义生成通信中的重要概念，基于此的带宽分配方案能有效平衡带宽效率和生成性能，为AI应用服务提供更好的RAN支持

Abstract: The importance of Radio Access Network (RAN) in support Artificial
Intelligence (AI) application services has grown significantly, underscoring
the need for an integrated approach that considers not only network efficiency
but also AI performance. In this paper we focus on a semantic generative
communication (SGC) framework for image inpainting application. Specifically,
the transmitter sends semantic information, i.e., semantic masks and textual
descriptions, while the receiver utilizes a conditional diffusion model on a
base image, using them as conditioning data to produce the intended image. In
this framework, we propose a bandwidth allocation scheme designed to maximize
bandwidth efficiency while ensuring generation performance. This approach is
based on our finding of a Semantic Deadline--the minimum time that conditioning
data is required to be injected to meet a given performance threshold--within
the multi-modal SGC framework. Given this observation, the proposed scheme
allocates limited bandwidth so that each semantic information can be
transmitted within the corresponding semantic deadline. Experimental results
corroborate that the proposed bandwidth allocation scheme achieves higher
generation performance in terms of PSNR for a given bandwidth compared to
traditional schemes that do not account for semantic deadlines.

</details>


### [176] [On the Gaussian Limit of the Output of IIR Filters](https://arxiv.org/abs/2508.12705)
*Yashaswini Murthy,Bassam Bamieh,R. Srikant*

Main category: eess.SY

TL;DR: 本文研究了稳定线性时不变系统在非高斯随机输入下的输出渐近分布，证明了在特定条件下输出会收敛到高斯分布，为低通LTI系统输出近似高斯的普遍观察提供了严格理论基础。


<details>
  <summary>Details</summary>
Motivation: 受随机描述函数方法中长期启发式观察的驱动，旨在严格表征非高斯输入下LTI系统输出何时会变得近似高斯，为工程实践中广泛观察到的现象提供数学证明。

Method: 使用Wasserstein-1距离作为非高斯性的量化度量，通过Stein方法推导输出与标准正态分布之间距离的上界，这些上界显式依赖于系统的脉冲响应和输入过程的依赖结构。

Result: 当系统主导极点接近稳定性边界且输入满足独立性、正相关性或足够相关性衰减条件时，输出以O(1/√t)速率收敛到标准正态分布。同时提供了收敛失败的反例来验证假设的必要性。

Conclusion: 研究结果为低通LTI系统输出倾向于近似高斯分布的普遍观察提供了严格的数学基础，建立了系统特性与输出高斯化之间的定量关系。

Abstract: We study the asymptotic distribution of the output of a stable Linear
Time-Invariant (LTI) system driven by a non-Gaussian stochastic input.
Motivated by longstanding heuristics in the stochastic describing function
method, we rigorously characterize when the output process becomes
approximately Gaussian, even when the input is not. Using the Wasserstein-1
distance as a quantitative measure of non-Gaussianity, we derive upper bounds
on the distance between the appropriately scaled output and a standard normal
distribution. These bounds are obtained via Stein's method and depend
explicitly on the system's impulse response and the dependence structure of the
input process. We show that when the dominant pole of the system approaches the
edge of stability and the input satisfies one of the following conditions: (i)
independence, (ii) positive correlation with a real and positive dominant pole,
or (iii) sufficient correlation decay, the output converges to a standard
normal distribution at rate $O(1/\sqrt{t})$. We also present counterexamples
where convergence fails, thereby motivating the stated assumptions. Our results
provide a rigorous foundation for the widespread observation that outputs of
low-pass LTI systems tend to be approximately Gaussian.

</details>


### [177] [A Hierarchical Surrogate Model for Efficient Multi-Task Parameter Learning in Closed-Loop Contro](https://arxiv.org/abs/2508.12738)
*Sebastian Hirt,Lukas Theiner,Maik Pfefferkorn,Rolf Findeisen*

Main category: eess.SY

TL;DR: 提出分层贝叶斯优化框架，利用控制问题的结构知识提高控制器参数学习的效率和适应性


<details>
  <summary>Details</summary>
Motivation: 解决控制器在不同闭环任务中需要重复调参的问题，提高数据效率和适应性

Method: 构建分层高斯过程代理模型，利用已知的闭环状态演化结构和成本函数闭式表达式

Result: 相比黑盒贝叶斯优化方法，在样本效率和适应性方面都有显著提升

Conclusion: 该框架在保持次线性遗憾保证的同时，实现了多任务学习和知识迁移

Abstract: Many control problems require repeated tuning and adaptation of controllers
across distinct closed-loop tasks, where data efficiency and adaptability are
critical. We propose a hierarchical Bayesian optimization (BO) framework that
is tailored to efficient controller parameter learning in sequential
decision-making and control scenarios for distinct tasks. Instead of treating
the closed-loop cost as a black-box, our method exploits structural knowledge
of the underlying problem, consisting of a dynamical system, a control law, and
an associated closed-loop cost function. We construct a hierarchical surrogate
model using Gaussian processes that capture the closed-loop state evolution
under different parameterizations, while the task-specific weighting and
accumulation into the closed-loop cost are computed exactly via known
closed-form expressions. This allows knowledge transfer and enhanced data
efficiency between different closed-loop tasks. The proposed framework retains
sublinear regret guarantees on par with standard black-box BO, while enabling
multi-task or transfer learning. Simulation experiments with model predictive
control demonstrate substantial benefits in both sample efficiency and
adaptability when compared to purely black-box BO approaches.

</details>


### [178] [PFD or PDF: Rethinking the Probability of Failure in Mitigation Safety Functions](https://arxiv.org/abs/2508.12814)
*Hamid Jahanian*

Main category: eess.SY

TL;DR: 本文认为PFD不适用于缓解型安全功能的可靠性度量，提出了基于概率密度函数和预期失效程度的替代方法


<details>
  <summary>Details</summary>
Motivation: 传统SIL分配主要关注预防性安全功能，对缓解型安全功能的可靠性度量方法存在不足，PFD作为度量指标不适用于缓解型安全功能

Method: 提出使用概率密度函数(PDF)和预期失效程度作为关键指标的新方法，提供了详细的数学公式支持

Result: 通过案例研究展示了新方法的实际应用效果

Conclusion: 对于缓解型安全功能，PFD不是合适的可靠性度量指标，基于PDF和预期失效程度的方法提供了更合适的替代方案

Abstract: SIL (Safety Integrity Level) allocation plays a crucial role in defining the
design requirements for Safety Functions (SFs) within high-risk industries. SIL
is typically determined based on the estimated Probability of Failure on Demand
(PFD), which must remain within permissible limits to manage risk effectively.
Extensive research has been conducted on determining target PFD and SIL, with a
stronger emphasis on preventive SFs than on mitigation SFs. In this paper, we
address a rather conceptual issue: we argue that PFD is not an appropriate
reliability measure for mitigation SFs to begin with, and we propose an
alternative approach that leverages the Probability Density Function (PDF) and
the expected degree of failure as key metrics. The principles underlying this
approach are explained and supported by detailed mathematical formulations.
Furthermore, the practical application of this new methodology is illustrated
through case studies.

</details>


### [179] [Grid Edge Intelligence-Assisted Model Predictive Framework for Black Start of Distribution Systems with Inverter-Based Resources](https://arxiv.org/abs/2508.12937)
*Junyuan Zheng,Salish Maharjan,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 提出基于电网边缘智能的预测性黑启动框架，利用用户侧分布式能源的灵活性，通过频率约束和同步开关实现安全快速的配电网恢复。


<details>
  <summary>Details</summary>
Motivation: 现有黑启动策略忽视了大量用户侧分布式能源，且缺乏对频率安全和同步约束的考虑，需要开发更全面的恢复框架。

Method: 开发预测模型估计多时段灵活性范围，引入频率约束黑启动策略（包括频率最低点、频率变化率和准稳态频率约束），采用同步开关加速负载恢复。

Result: 在改进的IEEE 123节点测试系统中验证了框架有效性，通过不同电网边缘智能渗透率场景对比证明了其优势。

Conclusion: 该框架仅需通信灵活性范围和调度信号，无需交换详细资产信息，实现了安全、快速且保护隐私的配电网黑启动恢复。

Abstract: The growing proliferation of distributed energy resources (DERs) is
significantly enhancing the resilience and reliability of distribution systems.
However, a substantial portion of behind-the-meter (BTM) DERs is often
overlooked during black start (BS) and restoration processes. Existing BS
strategies that utilize grid-forming (GFM) battery energy storage systems
(BESS) frequently ignore critical frequency security and synchronization
constraints. To address these limitations, this paper proposes a predictive
framework for bottom-up BS that leverages the flexibility of BTM DERs through
Grid Edge Intelligence (GEI). A predictive model is developed for GEI to
estimate multi-period flexibility ranges and track dispatch signals from the
utility. A frequency-constrained BS strategy is then introduced, explicitly
incorporating constraints on frequency nadir, rate-of-change-of-frequency
(RoCoF), and quasi-steady-state (QSS) frequency. The framework also includes
synchronizing switches to enable faster and more secure load restoration.
Notably, it requires GEI devices to communicate only their flexibility ranges
and the utility to send dispatch signals without exchanging detailed asset
information. The proposed framework is validated using a modified IEEE 123-bus
test system, and the impact of GEI is demonstrated by comparing results across
various GEI penetration scenarios.

</details>


### [180] [Revisiting Functional Derivatives in Multi-object Tracking](https://arxiv.org/abs/2508.12982)
*Jan Krejčí,Ondřej Straka,Petr Girg,Jiří Benedikt*

Main category: eess.SY

TL;DR: 本文对概率生成泛函(PGFL)中的泛函导数进行了严谨的数学定义和性质分析，解决了传统定义中依赖狄拉克δ函数的复杂性和启发式问题。


<details>
  <summary>Details</summary>
Motivation: PGFL是多目标跟踪中的有效工具，但传统泛函导数定义过于复杂且依赖狄拉克δ函数，缺乏数学严谨性，需要建立更清晰的定义框架。

Method: 比较不同泛函导数定义，探索其关系和应用含义，提出基于严格数学的泛函导数新定义，揭示并讨论其关键性质。

Result: 建立了严谨的泛函导数数学定义，提供了更清晰的理论基础，为PGFL在多目标跟踪中的应用提供了更可靠的数学工具。

Conclusion: 提出的严谨泛函导数定义解决了传统方法的复杂性问题，为概率生成泛函在多目标跟踪算法中的推导提供了更精确和可靠的数学基础。

Abstract: Probability generating functionals (PGFLs) are efficient and powerful tools
for tracking independent objects in clutter. It was shown that PGFLs could be
used for the elegant derivation of practical multi-object tracking algorithms,
e.g., the probability hypothesis density (PHD) filter. However, derivations
using PGFLs use the so-called functional derivatives whose definitions usually
appear too complicated or heuristic, involving Dirac delta ``functions''. This
paper begins by comparing different definitions of functional derivatives and
exploring their relationships and implications for practical applications. It
then proposes a rigorous definition of the functional derivative, utilizing
straightforward yet precise mathematics for clarity. Key properties of the
functional derivative are revealed and discussed.

</details>


### [181] [Exploiting Convexity of Neural Networks in Dynamic Operating Envelope Optimization for Distributed Energy Resources](https://arxiv.org/abs/2508.13090)
*Hongyi Li,Liming Liu,Yunyi Li,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 该论文提出了一种基于输入凸神经网络(ICNN)的动态运行边界(DOE)优化方法，通过ICNN的凸性特性将非凸的电力流约束转化为凸优化问题，显著提高了计算效率和求解质量。


<details>
  <summary>Details</summary>
Motivation: 分布式能源资源(DERs)的普及给配电系统运行带来了机遇和挑战。由于电力流方程的非凸特性，DOE优化面临求解精度和计算效率的权衡问题。

Method: 首先建立DOE优化模型，考虑多种运行约束；提出约束嵌入方法，用训练好的ICNN模型替代非凸电力流约束；进一步提出线性松弛方法加速优化，并理论证明其紧致性。

Result: 数值案例研究表明，所提出的ICNN方法在求解质量和求解时间方面均优于其他基准方法。

Conclusion: 基于ICNN的DOE优化方法有效解决了非凸电力流约束带来的计算挑战，为配电系统中DERs的高效运行提供了可行的解决方案。

Abstract: The increasing penetration of distributed energy resources (DERs) brings
opportunities and challenges to the operation of distribution systems. To
ensure network integrity, dynamic operating envelopes (DOEs) are issued by
utilities to DERs as their time-varying export/import power limits. Due to the
non-convex nature of power flow equations, the optimization of DOEs faces a
dilemma of solution accuracy and computation efficiency. To bridge this gap, in
this paper, we facilitate DOE optimization by exploiting the convexity of input
convex neural networks (ICNNs). A DOE optimization model is first presented,
comprehensively considering multiple operational constraints. We propose a
constraint embedding method that allows us to replace the non-convex power flow
constraints with trained ICNN models and convexify the problem. To further
speed up DOE optimization, we propose a linear relaxation of the ICNN-based DOE
optimization problem, for which the tightness is theoretically proven. The
effectiveness of the proposed method is validated with numerical case studies.
Results show that the proposed ICNN-based method outperforms other benchmark
methods in optimizing DOEs in terms of both solution quality and solution time.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [182] [FairVizARD: A Visualization System for Assessing Multi-Party Fairness of Ride-Sharing Matching Algorithms](https://arxiv.org/abs/2508.11770)
*Ashwin Kumar,Sanket Shah,Meghna Lowalekar,Pradeep Varakantham,Alvitta Ottley,William Yeoh*

Main category: cs.HC

TL;DR: FairVizARD是一个可视化系统，通过动画和图表帮助用户评估网约车匹配算法的公平性，支持大规模数据分析并扩展用户对公平性的理解。


<details>
  <summary>Details</summary>
Motivation: 网约车匹配算法中不同利益相关方（乘客、司机、平台）的公平性往往存在冲突，需要一种有效的方法来评估和平衡这些公平性需求。

Method: 开发了FairVizARD可视化系统，使用动画展示时空信息，通过图表呈现聚合数据，采用高效技术处理大规模信息，并在真实出租车数据集上进行实验。

Result: 通过用户研究和专家访谈证明，FairVizARD不仅能有效评估匹配算法的公平性，还能帮助用户扩展对公平性的概念理解。

Conclusion: FairVizARD为网约车匹配算法的公平性评估提供了一个实用的可视化工具，特别适合现实世界的大规模应用场景。

Abstract: There is growing interest in algorithms that match passengers with drivers in
ride-sharing problems and their fairness for the different parties involved
(passengers, drivers, and ride-sharing companies). Researchers have proposed
various fairness metrics for matching algorithms, but it is often unclear how
one should balance the various parties' fairness, given that they are often in
conflict. We present FairVizARD, a visualization-based system that aids users
in evaluating the fairness of ride-sharing matching algorithms. FairVizARD
presents the algorithms' results by visualizing relevant spatio-temporal
information using animation and aggregated information in charts. FairVizARD
also employs efficient techniques for visualizing a large amount of information
in a user friendly manner, which makes it suitable for real-world settings. We
conduct our experiments on a real-world large-scale taxi dataset and, through
user studies and an expert interview, we show how users can use FairVizARD not
only to evaluate the fairness of matching algorithms but also to expand on
their notions of fairness.

</details>


### [183] [XR-First Design for Productivity: A Conceptual Framework for Enabling Efficient Task Switching in XR](https://arxiv.org/abs/2508.11778)
*Matt Gottsacker,Yahya Hmaiti,Mykola Maslych,Gerd Bruder,Joseph J. LaViola Jr.,Gregory F. Welch*

Main category: cs.HC

TL;DR: 本文提出了XR环境中高效上下文切换的新范式，旨在解决当前XR应用在知识工作中存在的窗口隐喻不足和沉浸式应用隔离问题。


<details>
  <summary>Details</summary>
Motivation: 当前XR头显在知识工作中存在两个主要问题：窗口式界面无法充分表达丰富的空间信息，沉浸式应用之间相互隔离需要完全退出才能切换，这影响了工作效率和用户体验。

Method: 提出了一个以XR为中心、以用户为中心的上下文切换新范式愿景，通过设计新的界面和交互方式来支持快速、无缝的应用切换。

Result: 提出了一个指导未来XR上下文和任务切换界面研究和开发的框架性愿景。

Conclusion: 需要开发新的XR界面范式来支持高效的知识工作流程，打破当前沉浸式应用之间的隔离状态，实现更自然的上下文切换体验。

Abstract: A core component of completing tasks efficiently in computer-supported
knowledge work is the ability for users to rapidly switch their focus (and
interaction) across different applications using various shortcuts and
gestures. This feature set has been explored in research, and several modern
consumer extended reality (XR) headsets now support loading multiple
applications windows at once. However, many XR applications that are useful for
knowledge work involve rich spatial information, which window-based metaphors
do not sufficiently represent nor afford appropriate interaction. In modern XR
headsets, such immersive applications run as siloed experiences, requiring the
user to fully exit one before starting another. We present a vision for
achieving an XR-first, user-centric paradigm for efficient context switching in
XR to encourage and guide future research and development of XR context- and
task-switching interfaces.

</details>


### [184] [Behavioral and Symbolic Fillers as Delay Mitigation for Embodied Conversational Agents in Virtual Reality](https://arxiv.org/abs/2508.11781)
*Denmar Mojan Gonzales,Snehanjali Kalamkar,Sophie Jörg,Jens Grubert*

Main category: cs.HC

TL;DR: 研究虚拟现实中对话代理响应延迟时使用填充行为（如对话和手势填充）相比符号指示器（进度条）能显著改善用户体验、感知响应时间、存在感和自然度


<details>
  <summary>Details</summary>
Motivation: 虚拟现实中与对话代理交互时，由于大语言模型计算导致的响应延迟会造成不自然和令人沮丧的交互体验，需要寻找有效的填充策略来缓解这种负面影响

Method: 在24名参与者的组内研究中，比较了四种延迟处理策略：多模态行为填充（对话+手势）、基础空闲动作、嵌入式符号指示器（徽章进度条）和外部符号指示器（思考气泡进度条）

Result: 行为填充显著改善了感知响应时间、存在感的三个子维度、拟人化和自然度；符号指示器导致参与者更多避开面部注视，但未带来更积极的代理印象或存在感提升；大多数参与者（83.3%）偏好行为填充

Conclusion: 多模态行为填充是处理虚拟现实对话代理响应延迟的最有效策略，能显著提升用户体验和交互质量，而符号指示器效果有限且不受用户青睐

Abstract: When communicating with embodied conversational agents (ECAs) in virtual
reality, there might be delays in the responses of the agents lasting several
seconds, for example, due to more extensive computations of the answers when
large language models are used. Such delays might lead to unnatural or
frustrating interactions. In this paper, we investigate filler types to
mitigate these effects and lead to a more positive experience and perception of
the agent. In a within-subject study, we asked 24 participants to communicate
with ECAs in virtual reality, comparing four strategies displayed during the
delays: a multimodal behavioral filler consisting of conversational and
gestural fillers, a base condition with only idle motions, and two symbolic
indicators with progress bars, one embedded as a badge on the agent, the other
one external and visualized as a thinking bubble. Our results indicate that the
behavioral filler improved perceived response time, three subscales of
presence, humanlikeness, and naturalness. Participants looked away from the
face more often when symbolic indicators were displayed, but the visualizations
did not lead to a more positive impression of the agent or to increased
presence. The majority of participants preferred the behavioral fillers, only
12.5% and 4.2% favored the symbolic embedded and external conditions,
respectively.

</details>


### [185] [Two Sides to Every Story: Exploring Hybrid Design Teams' Perceptions of Psychological Safety on Slack](https://arxiv.org/abs/2508.11788)
*Marjan Naghshbandi,Sharon Ferguson,Alison Olechowski*

Main category: cs.HC

TL;DR: 该研究通过混合方法分析混合工作环境中工程团队的心理学安全感，识别了5个主要方面、4个线上/线下差异，并开发了15个Slack平台上的心理学安全指标，为未来自动化测量提供基础。


<details>
  <summary>Details</summary>
Motivation: 混合工作模式的独特挑战可能损害团队协作和动态，但通过有针对性的策略和工具可以促进混合团队的蓬勃发展。研究旨在了解心理学安全感在创新团队中的表现，为未来支持措施提供依据。

Method: 采用混合研究方法，通过对6个混合工程设计顶点团队的访谈，分析他们在Slack平台和面对面互动中心理学安全感指标的不同表现，并基于访谈洞察设计Slack平台的心理学安全指标。

Result: 识别了混合团队心理学安全感的5个主要方面，发现了4个Slack平台与面对面互动在心理学安全感表现上的差异，开发了15个基于Slack的心理学安全指标，为即时通讯平台的自动化心理学安全测量奠定了基础。

Conclusion: 研究提出了3个设计启示和示例设计，说明即时通讯平台如何支持心理学安全的混合团队，并为混合团队提供了支持人际风险承担和建立相互尊重的最佳实践。

Abstract: While the unique challenges of hybrid work can compromise collaboration and
team dynamics, hybrid teams can thrive with well-informed strategies and tools
that nurture interpersonal engagements. To inform future supports, we pursue a
mixed-methods study of hybrid engineering design capstone teams' Psychological
Safety (PS) (i.e., their climate of interpersonal risk-taking and mutual
respect) to understand how the construct manifests in teams engaged in
innovation. Using interviews, we study six teams' perceptions of PS indicators
and how they present differently on Slack (when compared to in-person
interactions). We then leverage the interview insights to design Slack-based PS
indicators. We present five broad facets of PS in hybrid teams, four perceived
differences of PS on Slack compared to in-person, and 15 Slack-based, PS
indicators--the groundwork for future automated PS measurement on
instant-messaging platforms. These insights produce three design implications
and illustrative design examples for ways instant-messaging platforms can
support Psychologically Safe hybrid teams, and best practices for hybrid teams
to support interpersonal risk-taking and build mutual respect.

</details>


### [186] [RPKT: Learning What You Don't -- Know Recursive Prerequisite Knowledge Tracing in Conversational AI Tutors for Personalized Learning](https://arxiv.org/abs/2508.11892)
*Jinwen Tang,Qiming Guo,Zhicheng Tang*

Main category: cs.HC

TL;DR: 提出基于大语言模型的递归先修知识追踪系统(RPKT)，通过动态发现学习者未知的知识缺口来解决"未知的未知"问题，无需预定义知识图谱即可实现真正的自适应学习


<details>
  <summary>Details</summary>
Motivation: 教育系统通常假设学习者能够识别自己的知识缺口，但研究表明学生难以识别自己不知道需要学习的内容，即"未知的未知"问题

Method: 使用大语言模型进行智能先修知识提取，实现递归实时追踪直到找到学习者的实际知识边界，采用二元评估界面降低认知负荷，基于识别的知识缺口提供个性化学习路径

Result: 在计算机科学领域的演示表明，系统能够发现多层级嵌套的先修依赖关系，识别跨领域的数学基础，无需预建课程即可生成分层学习序列

Conclusion: 该方法通过实现跨任何学术领域的真正自适应学习，在推进个性化教育技术方面展现出巨大潜力

Abstract: Educational systems often assume learners can identify their knowledge gaps,
yet research consistently shows that students struggle to recognize what they
don't know they need to learn-the "unknown unknowns" problem. This paper
presents a novel Recursive Prerequisite Knowledge Tracing (RPKT) system that
addresses this challenge through dynamic prerequisite discovery using large
language models. Unlike existing adaptive learning systems that rely on
pre-defined knowledge graphs, our approach recursively traces prerequisite
concepts in real-time until reaching a learner's actual knowledge boundary. The
system employs LLMs for intelligent prerequisite extraction, implements binary
assessment interfaces for cognitive load reduction, and provides personalized
learning paths based on identified knowledge gaps. Demonstration across
computer science domains shows the system can discover multiple nested levels
of prerequisite dependencies, identify cross-domain mathematical foundations,
and generate hierarchical learning sequences without requiring pre-built
curricula. Our approach shows great potential for advancing personalized
education technology by enabling truly adaptive learning across any academic
domain.

</details>


### [187] [Playing telephone with generative models: "verification disability," "compelled reliance," and accessibility in data visualization](https://arxiv.org/abs/2508.12192)
*Frank Elavsky,Cindy Xiong Bearfield*

Main category: cs.HC

TL;DR: 本文探讨了生成模型在数据可视化可访问性中产生的偏见问题，特别是针对视障用户使用AI生成图表描述时的风险


<details>
  <summary>Details</summary>
Motivation: 随着生成模型在数据可视化可访问性领域的应用日益增多，作者担心这些模型可能会产生偏见，而视障用户无法验证模型输出的准确性，导致被迫依赖而非真正信任

Method: 通过模型间的"传话游戏"实验，观察模型在解释和重新解释数据可视化时产生的偏见，分析模型失败对视障用户的特别影响

Result: 研究发现AI生成的可视化描述存在严重的偏见问题，模型失败对视障用户的影响尤为严重，因为用户无法验证输出准确性

Conclusion: 为技术开发者、残障用户和研究人员提出了三个方向的建议：技术开发者需要构建更可靠的模型辅助界面，用户需要谨慎使用模型，研究人员应关注偏见、可访问性和可视化的交叉问题

Abstract: This paper is a collaborative piece between two worlds of expertise in the
field of data visualization: accessibility and bias. In particular, the rise of
generative models playing a role in accessibility is a worrying trend for data
visualization. These models are increasingly used to help author visualizations
as well as generate descriptions of existing visualizations for people who are
blind, low vision, or use assistive technologies such as screen readers.
Sighted human-to-human bias has already been established as an area of concern
for theory, research, and design in data visualization. But what happens when
someone is unable to verify the model output or adequately interrogate
algorithmic bias, such as a context where a blind person asks a model to
describe a chart for them? In such scenarios, trust from the user is not
earned, rather reliance is compelled by the model-to-human relationship. In
this work, we explored the dangers of AI-generated descriptions for
accessibility, playing a game of telephone between models, observing bias
production in model interpretation, and re-interpretation of a data
visualization. We unpack ways that model failure in visualization is especially
problematic for users with visual impairments, and suggest directions forward
for three distinct readers of this piece: technologists who build
model-assisted interfaces for end users, users with disabilities leveraging
models for their own purposes, and researchers concerned with bias,
accessibility, or visualization.

</details>


### [188] [iTrace: Click-Based Gaze Visualization on the Apple Vision Pro](https://arxiv.org/abs/2508.12268)
*Esra Mehmedova,Santiago Berrezueta-Guzman,Stefan Wagner*

Main category: cs.HC

TL;DR: iTrace是一个在Apple Vision Pro上通过点击手势提取用户注视数据的系统，能够生成动态热力图来分析个人和群体的注意力模式，在保持91%精确度的同时克服了设备隐私限制。


<details>
  <summary>Details</summary>
Motivation: Apple Vision Pro虽然具备精确的眼动追踪能力，但由于隐私限制无法直接获取连续的用户注视数据，这限制了眼动分析应用的发展。

Method: 开发了基于客户端-服务器架构的iTrace系统，使用捏合手势、停留控制和游戏控制器等点击方式来提取注视坐标，并将其转换为视频和空间眼动追踪的动态热力图。

Result: 8BitDo控制器实现了14.22次点击/秒的数据收集率，远高于停留控制的0.45次点击/秒，能够生成更密集的热力图可视化。系统达到91%的注视精确度，揭示了讲座视频中的集中注意力和问题解决任务中的广泛扫描等不同注意力模式。

Conclusion: iTrace在教育内容参与、环境设计评估、营销分析和临床认知评估等领域具有广泛应用潜力，但建议开发者仅在研究环境中使用。

Abstract: The Apple Vision Pro is equipped with accurate eye-tracking capabilities, yet
the privacy restrictions on the device prevent direct access to continuous user
gaze data. This study introduces iTrace, a novel application that overcomes
these limitations through click-based gaze extraction techniques, including
manual methods like a pinch gesture, and automatic approaches utilizing dwell
control or a gaming controller. We developed a system with a client-server
architecture that captures the gaze coordinates and transforms them into
dynamic heatmaps for video and spatial eye tracking. The system can generate
individual and averaged heatmaps, enabling analysis of personal and collective
attention patterns.
  To demonstrate its effectiveness and evaluate the usability and performance,
a study was conducted with two groups of 10 participants, each testing
different clicking methods. The 8BitDo controller achieved higher average data
collection rates at 14.22 clicks/s compared to 0.45 clicks/s with dwell
control, enabling significantly denser heatmap visualizations. The resulting
heatmaps reveal distinct attention patterns, including concentrated focus in
lecture videos and broader scanning during problem-solving tasks. By allowing
dynamic attention visualization while maintaining a high gaze precision of 91
%, iTrace demonstrates strong potential for a wide range of applications in
educational content engagement, environmental design evaluation, marketing
analysis, and clinical cognitive assessment. Despite the current gaze data
restrictions on the Apple Vision Pro, we encourage developers to use iTrace
only in research settings.

</details>


### [189] [Sketchar: Supporting Character Design and Illustration Prototyping Using Generative AI](https://arxiv.org/abs/2508.12333)
*Long Ling,Xinyi Chen,Ruoyu Wen,Toby Jia-Jun Li,Ray LC*

Main category: cs.HC

TL;DR: Sketchar是一个生成式AI工具，帮助游戏设计师通过概念输入快速生成角色原型图像，改善与插画师的跨学科协作沟通。


<details>
  <summary>Details</summary>
Motivation: 解决游戏角色设计中设计师和插画师因背景差异导致的沟通挑战，特别是设计师缺乏艺术能力的问题。

Method: 开发Sketchar生成式AI工具，允许设计师基于概念输入生成角色图像原型，并进行混合方法研究评估工具效果。

Result: Sketchar生成的参考图像促进了设计细节的完善，能融入实际工作流程，无艺术背景的设计师认为该工作流程更具表达性和价值。

Conclusion: 生成式AI有潜力增强游戏行业的跨学科协作，使设计师能够超越自身专业限制进行交互。

Abstract: Character design in games involves interdisciplinary collaborations,
typically between designers who create the narrative content, and illustrators
who realize the design vision. However, traditional workflows face challenges
in communication due to the differing backgrounds of illustrators and
designers, the latter with limited artistic abilities. To overcome these
challenges, we created Sketchar, a Generative AI (GenAI) tool that allows
designers to prototype game characters and generate images based on conceptual
input, providing visual outcomes that can give immediate feedback and enhance
communication with illustrators' next step in the design cycle. We conducted a
mixed-method study to evaluate the interaction between game designers and
Sketchar. We showed that the reference images generated in co-creating with
Sketchar fostered refinement of design details and can be incorporated into
real-world workflows. Moreover, designers without artistic backgrounds found
the Sketchar workflow to be more expressive and worthwhile. This research
demonstrates the potential of GenAI in enhancing interdisciplinary
collaboration in the game industry, enabling designers to interact beyond their
own limited expertise.

</details>


### [190] [System-driven Interactive Design Support for Cloud Architecture: A Qualitative User Experience Study with Novice Engineers](https://arxiv.org/abs/2508.12385)
*Ryosuke Kohita,Akira Kasuga*

Main category: cs.HC

TL;DR: 本研究定性分析60名新手工程师使用系统驱动的云设计支持工具的经验，发现结构化指导能有效帮助新手进行架构设计，特别是在知识经验不足的任务中。系统支持还能通过模拟比较选项来加深对云设计原则的理解。


<details>
  <summary>Details</summary>
Motivation: 云架构设计对新手工程师具有挑战性，需要澄清模糊需求并处理复杂权衡。虽然AI工具提供了更多选择，但系统驱动的方法可能特别有效，能够为新手提供明确指导和分步信息管理。

Method: 定性研究60名新手工程师使用系统驱动的云设计支持工具的体验，分析他们在设计过程中的表现和反馈。

Result: 结构化系统指导帮助新手更有效地参与架构设计，特别是在知识经验差距最大的任务中。参与者发现创建初始架构更容易，无需自己编写提示。模拟比较多个架构选项的能力加深了对云设计原则和权衡的理解。

Conclusion: 系统驱动的云设计支持工具具有教育价值，但需要改进信息交付的适应性、系统输出验证机制，以及与基础设施即代码生成和部署指导等工作流程的更好集成。

Abstract: Cloud architecture design presents significant challenges due to the
necessity of clarifying ambiguous requirements and systematically addressing
complex trade-offs, especially for novice engineers with limited cloud
experience. While recent advances in the use of AI tools have broadened
available options, system-driven approaches that offer explicit guidance and
step-by-step information management may be especially effective in supporting
novices during the design process. This study qualitatively examines the
experiences of 60 novice engineers using such a system-driven cloud design
support tool. The findings indicate that structured and proactive system
guidance helps novices engage more effectively in architectural design,
especially when addressing tasks where knowledge and experience gaps are most
critical. For example, participants found it easier to create initial
architectures and did not need to craft prompts themselves. In addition,
participants reported that the ability to simulate and compare multiple
architecture options enabled them to deepen their understanding of cloud design
principles and trade-offs, demonstrating the educational value of system-driven
support. The study also identifies areas for improvement, including more
adaptive information delivery tailored to user expertise, mechanisms for
validating system outputs, and better integration with implementation workflows
such as infrastructure-as-code generation and deployment guidance. Addressing
these aspects can further enhance the educational and practical value of
system-driven support tools for cloud architecture design.

</details>


### [191] [When motivation can be more than a message: designing agents to boost physical activity](https://arxiv.org/abs/2508.12388)
*Alessandro Silacci,Maurizio Caon,Mauro Cherubini*

Main category: cs.HC

TL;DR: 本研究探讨虚拟代理作为共同参与者而非教练的角色，通过访谈分析发现用户重视真实努力表现，模糊的活动水平会削弱信任和动机，提出了促进共同体验的设计方向。


<details>
  <summary>Details</summary>
Motivation: 传统虚拟代理在体育活动干预中主要作为教练角色，缺乏关系深度。本研究探索让虚拟代理被视为共同参与者，与用户一起付出努力的可能性。

Method: 通过对12名参与者的半结构化访谈进行主题分析，研究用户如何在社会比较情境中解释和评估代理的努力程度。

Result: 研究发现参与者重视社交功能但要求真实努力表现，模糊或不可信的活动水平会破坏信任和动机，用户对虚拟代理持怀疑态度除非能看到明显努力或基于可理解的人类基准。

Conclusion: 提出了促进共同体验的设计方向，包括行为线索、叙事基础和个性化表现，这些见解有助于设计更具吸引力、社会共鸣的虚拟代理来支持共同体验的体育活动。

Abstract: Virtual agents are commonly used in physical activity interventions to
support behavior change, often taking the role of coaches that deliver
encouragement and feedback. While effective for compliance, this role typically
lacks relational depth. This pilot study explores how such agents might be
perceived not just as instructors, but as co-participants: entities that appear
to exert effort alongside users. Drawing on thematic analysis of
semi-structured interviews with 12 participants from a prior physical activity
intervention, we examine how users interpret and evaluate agent effort in
social comparison contexts. Our findings reveal a recurring tension between
perceived performance and authenticity. Participants valued social features
when they believed others were genuinely trying. In contrast, ambiguous or
implausible activity levels undermined trust and motivation. Many participants
expressed skepticism toward virtual agents unless their actions reflected
visible effort or were grounded in relatable human benchmarks. Based on these
insights, we propose early design directions for fostering co-experienced
exertion in agents, including behavioral cues, narrative grounding, and
personalized performance. These insights contribute to the design of more
engaging, socially resonant agents capable of supporting co-experienced
physical activity.

</details>


### [192] [fCrit: A Visual Explanation System for Furniture Design Creative Support](https://arxiv.org/abs/2508.12416)
*Vuong Nguyen,Gabriel Vigliensoni*

Main category: cs.HC

TL;DR: fCrit是一个基于对话的AI系统，专注于家具设计批评，强调可解释性，采用多智能体架构和结构化设计知识库，支持根据用户设计语言和认知框架定制解释。


<details>
  <summary>Details</summary>
Motivation: 在艺术领域的可解释性不仅需要让AI推理透明，还需要适应用户思考和谈论设计的方式，推动以人为中心的解释性AI在创意实践中的应用。

Method: 基于反思学习和形式分析，采用多智能体架构，利用结构化设计知识库，通过对话方式为家具设计提供批评，并根据用户的设计语言和认知框架定制解释。

Result: 开发了fCrit系统，能够支持情境化、对话式和视觉基础的AI辅助，为创意实践提供领域特定的可解释AI方法。

Conclusion: 这项工作推进了以人为中心的解释性AI在创意领域的应用，特别是在家具设计批评方面，通过适应性的解释机制增强了AI与用户的互动效果。

Abstract: We introduce fCrit, a dialogue-based AI system designed to critique furniture
design with a focus on explainability. Grounded in reflective learning and
formal analysis, fCrit employs a multi-agent architecture informed by a
structured design knowledge base. We argue that explainability in the arts
should not only make AI reasoning transparent but also adapt to the ways users
think and talk about their designs. We demonstrate how fCrit supports this
process by tailoring explanations to users' design language and cognitive
framing. This work contributes to Human-Centered Explainable AI (HCXAI) in
creative practice, advancing domain-specific methods for situated, dialogic,
and visually grounded AI support.

</details>


### [193] [Say It, See It: A Systematic Evaluation on Speech-Based 3D Content Generation Methods in Augmented Reality](https://arxiv.org/abs/2508.12498)
*Yanming Xiu,Joshua Chilukuri,Shunav Sen,Maria Gorlatova*

Main category: cs.HC

TL;DR: 本文提出模块化边缘辅助架构，比较文本直接生成3D和文本-图像-3D两种路径的性能。研究发现文本-图像-3D路径质量更高但速度较慢，而直接文本到3D路径速度更快但质量较低。用户更看重生成质量而非延迟。


<details>
  <summary>Details</summary>
Motivation: 随着AR应用对3D内容需求的增长，需要替代手动创建资产的生成管道。通过自然输入（如语音）驱动的生成管道可以提供更便捷的3D内容创建方式。

Method: 设计模块化边缘辅助架构，支持文本直接到3D和文本-图像到3D两种路径。通过IRB批准的用户研究（11名参与者），评估4个代表性管道在3个对象提示下的6个感知和可用性指标。

Result: 文本-图像到3D管道生成质量更高：最佳管道（FLUX图像生成+Trellis 3D生成）平均满意度4.55/5，意图对齐度4.82/5。直接文本到3D管道速度更快：最快的Shap-E约20秒完成生成。感知质量对用户满意度影响大于延迟。

Conclusion: 用户更愿意容忍较长的生成时间来获得符合期望的输出质量。研究为实际AR部署中当前3D生成方法的权衡提供了实用见解，建议根据应用场景需求在质量和速度之间做出选择。

Abstract: As augmented reality (AR) applications increasingly require 3D content,
generative pipelines driven by natural input such as speech offer an
alternative to manual asset creation. In this work, we design a modular,
edge-assisted architecture that supports both direct text-to-3D and
text-image-to-3D pathways, enabling interchangeable integration of
state-of-the-art components and systematic comparison of their performance in
AR settings. Using this architecture, we implement and evaluate four
representative pipelines through an IRB-approved user study with 11
participants, assessing six perceptual and usability metrics across three
object prompts. Overall, text-image-to-3D pipelines deliver higher generation
quality: the best-performing pipeline, which used FLUX for image generation and
Trellis for 3D generation, achieved an average satisfaction score of 4.55 out
of 5 and an intent alignment score of 4.82 out of 5. In contrast, direct
text-to-3D pipelines excel in speed, with the fastest, Shap-E, completing
generation in about 20 seconds. Our results suggest that perceptual quality has
a greater impact on user satisfaction than latency, with users tolerating
longer generation times when output quality aligns with expectations. We
complement subjective ratings with system-level metrics and visual analysis,
providing practical insights into the trade-offs of current 3D generation
methods for real-world AR deployment.

</details>


### [194] [Organization Matters: A Qualitative Study of Organizational Dynamics in Red Teaming Practices For Generative AI](https://arxiv.org/abs/2508.12504)
*Bixuan Ren,EunJeong Cheon,Jianghui Li*

Main category: cs.HC

TL;DR: 本文通过定性分析发现，组织因素（如边缘化红队成员、组织阻力等）阻碍了GenAI红队测试的有效性，建议将用户研究和红队测试嵌入整个开发周期。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注技术层面，但实际应用中组织因素严重影响红队测试效果，需要识别和解决这些组织障碍。

Method: 对来自不同组织的15名红队成员进行半结构化访谈的定性分析。

Result: 发现了脆弱红队成员被边缘化、AI风险在部署后才显现、缺乏以用户为中心的方法等挑战，这些问题源于组织阻力、惯性和平庸等组织动态。

Conclusion: 需要通过用户研究和将红队测试整合到GenAI系统全开发周期来缓解组织动态问题，提高红队测试效果。

Abstract: The rapid integration of generative artificial intelligence (GenAI) across
diverse fields underscores the critical need for red teaming efforts to
proactively identify and mitigate associated risks. While previous research
primarily addresses technical aspects, this paper highlights organizational
factors that hinder the effectiveness of red teaming in real-world settings.
Through qualitative analysis of 15 semi-structured interviews with red teamers
from various organizations, we uncover challenges such as the marginalization
of vulnerable red teamers, the invisibility of nuanced AI risks to vulnerable
users until post-deployment, and a lack of user-centered red teaming
approaches. These issues often arise from underlying organizational dynamics,
including organizational resistance, organizational inertia, and organizational
mediocracy. To mitigate these dynamics, we discuss the implications of user
research for red teaming and the importance of embedding red teaming throughout
the entire development cycle of GenAI systems.

</details>


### [195] [Towards Adaptive External Communication in Autonomous Vehicles: A Conceptual Design Framework](https://arxiv.org/abs/2508.12518)
*Tram Thi Minh Tran,Judy Kay,Stewart Worrall,Marius Hoggenmueller,Callum Parker,Xinyan Yu,Julie Stephany Berrio Perez,Mao Shan,Martin Tomitsch*

Main category: cs.HC

TL;DR: 提出一个用于自适应外部人机界面(eHMIs)的概念设计框架，通过三层结构(输入、处理、输出)实现动态通信调整，解决可扩展性和包容性问题。


<details>
  <summary>Details</summary>
Motivation: 现有eHMIs大多是反应式的，缺乏对道路参与者变化和情境转换的适应性，无法满足可扩展性和包容性需求。

Method: 基于信息物理系统理论，采用理论引导抽象和专家讨论方法，开发包含输入层(系统检测)、处理层(系统决策)和输出层(系统通信)的三层框架。

Result: 建立了一个系统化的设计框架，帮助研究者和设计者系统思考自适应eHMIs，提供结构化工具来设计、分析和评估自适应通信策略。

Conclusion: 该框架能够解决eHMI研究中的长期限制，同时提出了新的伦理和技术考量，为自适应通信系统的发展提供了理论基础。

Abstract: External Human-Machine Interfaces (eHMIs) are key to facilitating interaction
between autonomous vehicles and external road actors, yet most remain reactive
and do not account for scalability and inclusivity. This paper introduces a
conceptual design framework for adaptive eHMIs-interfaces that dynamically
adjust communication as road actors vary and context shifts. Using the
cyber-physical system as a structuring lens, the framework comprises three
layers: Input (what the system detects), Processing (how the system decides),
and Output (how the system communicates). Developed through theory-led
abstraction and expert discussion, the framework helps researchers and
designers think systematically about adaptive eHMIs and provides a structured
tool to design, analyse, and assess adaptive communication strategies. We show
how such systems may resolve longstanding limitations in eHMI research while
raising new ethical and technical considerations.

</details>


### [196] [The Future of Tech Labor: How Workers are Organizing and Transforming the Computing Industry](https://arxiv.org/abs/2508.12579)
*Cella M. Sum,Anna Konvicka,Mona Wang,Sarah E. Fox*

Main category: cs.HC

TL;DR: 通过对44名美国科技工作者组织者的访谈，研究发现科技行业工作者面临碎片化、不稳定的工作环境，尽管组织困难，他们通过社区建设和政治意识提升来建立更强大的劳工运动。


<details>
  <summary>Details</summary>
Motivation: 了解科技行业劳动力日益不稳定的背景下，科技工作者通过集体行动改善工作条件和抗议不道德实践的组织动机、策略和挑战。

Method: 访谈44名美国科技工作者组织者，包括工程师、产品经理、客服专员、QA分析师、物流工人、零工工人和工会组织者。

Result: 研究发现科技工作者面临碎片化、不稳定的工作环境，导致权力分散和组织困难，但组织者通过社区建设和政治意识提升来建立更强大的劳工运动基础。

Conclusion: 研究呼吁CSCW社区与科技工作者建立团结，支持他们通过组织努力实质性改变行业现状的运动。

Abstract: The tech industry's shifting landscape and the growing precarity of its labor
force have spurred unionization efforts among tech workers. These workers turn
to collective action to improve their working conditions and to protest
unethical practices within their workplaces. To better understand this
movement, we interviewed 44 U.S.-based tech worker-organizers to examine their
motivations, strategies, challenges, and future visions for labor organizing.
These workers included engineers, product managers, customer support
specialists, QA analysts, logistics workers, gig workers, and union staff
organizers. Our findings reveal that, contrary to popular narratives of
prestige and privilege within the tech industry, tech workers face fragmented
and unstable work environments which contribute to their disempowerment and
hinder their organizing efforts. Despite these difficulties, organizers are
laying the groundwork for a more resilient tech worker movement through
community building and expanding political consciousness. By situating these
dynamics within broader structural and ideological forces, we identify ways for
the CSCW community to build solidarity with tech workers who are materially
transforming our field through their organizing efforts.

</details>


### [197] [Using AI for User Representation: An Analysis of 83 Persona Prompts](https://arxiv.org/abs/2508.13047)
*Joni Salminen,Danial Amin,Bernard Jansen*

Main category: cs.HC

TL;DR: 对83个LLM生成用户画像提示的分析显示，当前研究主要生成单一、简短的文本格式画像，缺乏传统丰富画像的深度，且多使用结构化输出格式和动态变量插入。


<details>
  <summary>Details</summary>
Motivation: 分析当前研究中如何使用大型语言模型生成用户画像提示，了解其特点、局限性和与传统画像方法的差异。

Method: 分析了来自27篇研究文章的83个画像提示，考察了生成方式、格式要求、属性类型、提示数量等关键特征。

Result: 发现提示主要生成单一画像，偏好简短描述，文本和数字是最常见属性格式，74%的提示使用动态变量，超过一半要求结构化输出。

Conclusion: 计算化画像的兴起改变了用户表示方式，需要关注其与传统丰富画像方法的差异以及对用户理解的影响。

Abstract: We analyzed 83 persona prompts from 27 research articles that used large
language models (LLMs) to generate user personas. Findings show that the
prompts predominantly generate single personas. Several prompts express a
desire for short or concise persona descriptions, which deviates from the
tradition of creating rich, informative, and rounded persona profiles. Text is
the most common format for generated persona attributes, followed by numbers.
Text and numbers are often generated together, and demographic attributes are
included in nearly all generated personas. Researchers use up to 12 prompts in
a single study, though most research uses a small number of prompts. Comparison
and testing multiple LLMs is rare. More than half of the prompts require the
persona output in a structured format, such as JSON, and 74% of the prompts
insert data or dynamic variables. We discuss the implications of increased use
of computational personas for user representation.

</details>


### [198] [Ashes or Breath: Exploring Moral Dilemmas of Life and Cultural Legacy through Mixed Reality Gaming](https://arxiv.org/abs/2508.13074)
*Black Sun,Ge Kacy Fu,Shichao Guo*

Main category: cs.HC

TL;DR: 开发了一款名为《灰烬或呼吸》的混合现实游戏，通过头戴显示器让玩家在博物馆火灾中面临道德困境：拯救活猫还是无价文物，旨在通过沉浸式体验提升道德教育的情绪参与和反思深度。


<details>
  <summary>Details</summary>
Motivation: 传统道德困境教学方法使用抽象、脱离实体的场景，限制了情感参与和反思深度。为了解决这个问题，研究者开发了混合现实游戏来创造更具情感投入的道德困境体验。

Method: 采用迭代式、以价值为中心的设计过程，开发了基于头戴显示器的混合现实游戏。游戏通过具身互动和空间沉浸来增强情感投入，玩家面临不可逆转的情感化选择，并在反思室中体验叙事后果。

Result: 初步评估表明，通过混合现实头戴显示器将道德困境嵌入日常环境，能够强化同理心、加深内省，并促使用户重新思考道德假设。

Conclusion: 这项工作为人机交互领域的道德体验学习做出了贡献，将增强现实定位为不仅是交互媒介，更是道德遭遇的舞台。

Abstract: Traditional approaches to teaching moral dilemmas often rely on abstract,
disembodied scenarios that limit emotional engagement and reflective depth. To
address this gap, we developed \textit{Ashes or Breath}, a Mixed Reality game
delivered via head-mounted displays(MR-HMDs). This places players in an ethical
crisis: they must save a living cat or a priceless cultural artifact during a
museum fire. Designed through an iterative, values-centered process, the
experience leverages embodied interaction and spatial immersion to heighten
emotional stakes and provoke ethical reflection. Players face irreversible,
emotionally charged choices followed by narrative consequences in a reflective
room, exploring diverse perspectives and societal implications. Preliminary
evaluations suggest that embedding moral dilemmas into everyday environments
via MR-HMDs intensifies empathy, deepens introspection, and encourages users to
reconsider their moral assumptions. This work contributes to ethics-based
experiential learning in HCI, positioning augmented reality not merely as a
medium of interaction but as a stage for ethical encounter.

</details>


### [199] [At the Speed of the Heart: Evaluating Physiologically-Adaptive Visualizations for Supporting Engagement in Biking Exergaming in Virtual Reality](https://arxiv.org/abs/2508.13095)
*Oliver Hein,Sandra Wackerl,Changkun Ou,Florian Alt,Francesco Chiossi*

Main category: cs.HC

TL;DR: VR骑行模拟器通过实时心率监测和NPC视觉反馈，动态调整运动强度以保持用户处于目标心率区间，提高锻炼效果和安全性


<details>
  <summary>Details</summary>
Motivation: 现有健身游戏难以保持用户在安全有效的运动强度区间，穿戴设备收集的生理数据很少用于实时调整或促进用户反思

Method: 设计并评估基于心率区间动态调整的VR骑行模拟器，通过用户研究比较8种视觉反馈设计，最终采用NPC游戏化元素实现生理自适应系统

Result: 实验室研究(N=18)显示系统能帮助用户维持目标心率区间，主观运动强度、享受度和动机评分在不同条件下基本保持不变

Conclusion: 通过NPC视觉反馈实现实时生理自适应可以改善健身游戏中的锻炼调节效果

Abstract: Many exergames face challenges in keeping users within safe and effective
intensity levels during exercise. Meanwhile, although wearable devices
continuously collect physiological data, this information is seldom leveraged
for real-time adaptation or to encourage user reflection. We designed and
evaluated a VR cycling simulator that dynamically adapts based on users' heart
rate zones. First, we conducted a user study (N=50) comparing eight
visualization designs to enhance engagement and exertion control, finding that
gamified elements like non-player characters (NPCs) were promising for feedback
delivery. Based on these findings, we implemented a physiology-adaptive
exergame that adjusts visual feedback to keep users within their target heart
rate zones. A lab study (N=18) showed that our system has potential to help
users maintain their target heart rate zones. Subjective ratings of exertion,
enjoyment, and motivation remained largely unchanged between conditions. Our
findings suggest that real-time physiological adaptation through NPC
visualizations can improve workout regulation in exergaming.

</details>


### [200] [Choosing the Right Engine in the Virtual Reality Landscape](https://arxiv.org/abs/2508.13116)
*Santiago Berrezueta-Guzman,Stefan Wagner*

Main category: cs.HC

TL;DR: 对Unreal Engine和Unity在VR开发中的综合对比分析，包括渲染性能、开发工作流和AI增强技术的影响评估


<details>
  <summary>Details</summary>
Motivation: VR开发严重依赖游戏引擎，Unreal Engine和Unity作为行业主导引擎各有优势，需要系统比较其能力差异和适用场景

Method: 通过实证评估和大型VR项目的实际案例研究，对比分析两个引擎的渲染保真度、计算效率、跨平台兼容性和开发工作流程

Result: 研究结果突出了关键选择因素，为基于项目特定需求选择最合适引擎提供了实用见解，并评估了DLSS和LLM等AI技术对VR工作流的影响

Conclusion: 通过将引擎能力与技术创意需求对齐，开发者可以克服性能瓶颈、增强沉浸感并优化开发流程，为VR开发者提供数据驱动的决策参考

Abstract: Virtual reality (VR) development relies on game engines to provide real-time
rendering, physics simulation, and interaction systems. Among the most widely
used game engines, Unreal Engine and Unity dominate the industry, offering
distinct advantages in graphics rendering, performance optimization, usability,
resource requirements, and scalability. This study presents a comprehensive
comparative analysis of both engines, evaluating their capabilities and
trade-offs through empirical assessments and real-world case studies of
large-scale VR projects. The findings highlight key factors such as rendering
fidelity, computational efficiency, cross-platform compatibility, and
development workflows. These provide practical insights for selecting the most
suitable engine based on project-specific needs. Furthermore, emerging trends
in artificial intelligence (AI)-driven enhancements, including Deep Learning
Super Sampling (DLSS) and large language models (LLMs), are explored to assess
their impact on VR development workflows. By aligning engine capabilities with
technical and creative requirements, developers can overcome performance
bottlenecks, enhance immersion, and streamline optimization techniques.
  This study serves as a valuable resource for VR developers, researchers, and
industry professionals, offering data-driven recommendations to navigate the
evolving landscape of VR technology.

</details>


### [201] [Human Digital Twin: Data, Models, Applications, and Challenges](https://arxiv.org/abs/2508.13138)
*Rong Pan,Hongyue Sun,Xiaoyu Chen,Giulia Pedrielli,Jiapeng Huang*

Main category: cs.HC

TL;DR: 本文综述了人类数字孪生（HDT）的建模方法，重点关注统计和机器学习技术，包括异常检测和故障预测的最新进展，并讨论了数据集成、计算方法以及在精准医疗中部署HDT的伦理、技术和监管挑战。


<details>
  <summary>Details</summary>
Motivation: 人类数字孪生作为动态、数据驱动的个体虚拟表示，通过整合多模态数据来模拟、监测和预测健康轨迹，为个性化诊断、治疗规划和异常检测提供了新的可能性。

Method: 回顾当前HDT建模方法，重点关注统计和机器学习技术，包括异常检测和故障预测的最新进展，分析数据集成和计算方法。

Result: 系统梳理了HDT技术发展现状，总结了各种建模方法的优缺点，识别了关键的技术挑战和应用潜力。

Conclusion: HDT在精准医疗领域具有巨大潜力，但面临着数据集成、计算方法以及伦理、技术和监管等多方面的挑战，需要进一步研究和发展。

Abstract: Human digital twins (HDTs) are dynamic, data-driven virtual representations
of individuals, continuously updated with multimodal data to simulate, monitor,
and predict health trajectories. By integrating clinical, physiological,
behavioral, and environmental inputs, HDTs enable personalized diagnostics,
treatment planning, and anomaly detection. This paper reviews current
approaches to HDT modeling, with a focus on statistical and machine learning
techniques, including recent advances in anomaly detection and failure
prediction. It also discusses data integration, computational methods, and
ethical, technological, and regulatory challenges in deploying HDTs for
precision healthcare.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [202] [Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.11706)
*Zhuofan Xu,Benedikt Bollig,Matthias Függer,Thomas Nowak,Vincent Le Dréau*

Main category: cs.MA

TL;DR: 提出CPE学习框架，使用集中式策略和置换等变架构GLPE网络，解决CTDE范式中分散策略性能不足和集中式方法扩展性差的问题，在多个合作基准测试中显著提升性能


<details>
  <summary>Details</summary>
Motivation: CTDE范式在MARL中广泛应用，但分散策略在部分可观测环境下性能较差，而完全集中式方法在智能体数量增加时面临扩展性挑战

Method: 提出Centralized Permutation Equivariant (CPE)学习框架，采用完全集中式策略，使用新颖的Global-Local Permutation Equivariant (GLPE)网络架构，该架构轻量、可扩展且易于实现

Result: CPE能与价值分解和actor-critic方法无缝集成，在MPE、SMAC和RWARE等合作基准测试中显著提升标准CTDE算法的性能，达到最先进RWARE实现的性能水平

Conclusion: CPE框架通过置换等变架构有效解决了集中式训练与执行的挑战，提供了高性能且可扩展的多智能体强化学习解决方案

Abstract: The Centralized Training with Decentralized Execution (CTDE) paradigm has
gained significant attention in multi-agent reinforcement learning (MARL) and
is the foundation of many recent algorithms. However, decentralized policies
operate under partial observability and often yield suboptimal performance
compared to centralized policies, while fully centralized approaches typically
face scalability challenges as the number of agents increases.
  We propose Centralized Permutation Equivariant (CPE) learning, a centralized
training and execution framework that employs a fully centralized policy to
overcome these limitations. Our approach leverages a novel permutation
equivariant architecture, Global-Local Permutation Equivariant (GLPE) networks,
that is lightweight, scalable, and easy to implement. Experiments show that CPE
integrates seamlessly with both value decomposition and actor-critic methods,
substantially improving the performance of standard CTDE algorithms across
cooperative benchmarks including MPE, SMAC, and RWARE, and matching the
performance of state-of-the-art RWARE implementations.

</details>


### [203] [SafeSieve: From Heuristics to Experience in Progressive Pruning for LLM-based Multi-Agent Communication](https://arxiv.org/abs/2508.11733)
*Ruijia Zhang,Xinyan Zhao,Ruixiang Wang,Sigen Chen,Guibin Zhang,An Zhang,Kun Wang,Qingsong Wen*

Main category: cs.MA

TL;DR: SafeSieve是一种渐进式自适应多智能体剪枝算法，通过双机制动态优化智能体间通信，在减少12.4%-27.8%令牌使用的同时保持94.01%的平均准确率


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的多智能体系统中存在的冗余通信和过高令牌开销问题，现有方法通常将任务前后优化分离，缺乏统一策略

Method: 结合初始LLM语义评估和累积性能反馈的双机制，采用0-extension聚类保持结构连贯的智能体组同时消除无效链接

Result: 在多个基准测试中实现94.01%平均准确率，令牌使用减少12.4%-27.8%，在提示注入攻击下仅下降1.23%准确率，异构设置中降低13.3%部署成本

Conclusion: SafeSieve为实际多智能体系统提供了一个鲁棒、高效且可扩展的框架

Abstract: LLM-based multi-agent systems exhibit strong collaborative capabilities but
often suffer from redundant communication and excessive token overhead.
Existing methods typically enhance efficiency through pretrained GNNs or greedy
algorithms, but often isolate pre- and post-task optimization, lacking a
unified strategy. To this end, we present SafeSieve, a progressive and adaptive
multi-agent pruning algorithm that dynamically refines the inter-agent
communication through a novel dual-mechanism. SafeSieve integrates initial
LLM-based semantic evaluation with accumulated performance feedback, enabling a
smooth transition from heuristic initialization to experience-driven
refinement. Unlike existing greedy Top-k pruning methods, SafeSieve employs
0-extension clustering to preserve structurally coherent agent groups while
eliminating ineffective links. Experiments across benchmarks (SVAMP, HumanEval,
etc.) showcase that SafeSieve achieves 94.01% average accuracy while reducing
token usage by 12.4%-27.8%. Results further demonstrate robustness under prompt
injection attacks (1.23% average accuracy drop). In heterogeneous settings,
SafeSieve reduces deployment costs by 13.3% while maintaining performance.
These results establish SafeSieve as a robust, efficient, and scalable
framework for practical multi-agent systems. Our code can be found in
https://anonymous.4open.science/r/SafeSieve-D8F2FFUN.

</details>


### [204] [A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond](https://arxiv.org/abs/2508.11957)
*Xiaodong Qu,Andrews Damoah,Joshua Sherwood,Peiyan Liu,Christian Shun Jin,Lulu Chen,Minjie Shen,Nawwaf Aleisa,Zeyuan Hou,Chenyu Zhang,Lifu Gao,Yanshu Li,Qikai Yang,Qun Wang,Cristabelle De Souza*

Main category: cs.MA

TL;DR: 本文综述了AI智能体从基于规则的专家系统到学习驱动的自主系统的演进，探讨了架构原则、核心组件和新兴范式，并讨论了伦理安全挑战和研究方向。


<details>
  <summary>Details</summary>
Motivation: 设计和部署能够无缝集成认知、规划和交互的统一AI智能体仍然是一个重大挑战，需要系统性地审视当前技术现状和发展趋势。

Method: 系统性地审视AI智能体的架构原则、基础组件和新兴范式，综合认知科学启发模型、分层强化学习框架和大语言模型推理的见解。

Result: 总结了当代AI智能体技术的主要突破、持续挑战，为下一代系统提供了技术路线图。

Conclusion: 需要推动AI智能体系统向更鲁棒、自适应和可信赖的自主智能方向发展，同时重视伦理安全和可解释性问题。

Abstract: Artificial Intelligence (AI) agents have rapidly evolved from specialized,
rule-based programs to versatile, learning-driven autonomous systems capable of
perception, reasoning, and action in complex environments. The explosion of
data, advances in deep learning, reinforcement learning, and multi-agent
coordination have accelerated this transformation. Yet, designing and deploying
unified AI agents that seamlessly integrate cognition, planning, and
interaction remains a grand challenge. In this review, we systematically
examine the architectural principles, foundational components, and emergent
paradigms that define the landscape of contemporary AI agents. We synthesize
insights from cognitive science-inspired models, hierarchical reinforcement
learning frameworks, and large language model-based reasoning. Moreover, we
discuss the pressing ethical, safety, and interpretability concerns associated
with deploying these agents in real-world scenarios. By highlighting major
breakthroughs, persistent challenges, and promising research directions, this
review aims to guide the next generation of AI agent systems toward more
robust, adaptable, and trustworthy autonomous intelligence.

</details>


### [205] [Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems](https://arxiv.org/abs/2508.12314)
*Chiranjit Mitra*

Main category: cs.MA

TL;DR: 将Kuramoto同步理论应用于多智能体AI系统，通过耦合振荡器模型描述异构AI代理的集体动力学，建立了思维链提示与同步现象的联系，为可扩展、自适应、可解释的多智能体系统提供数学基础。


<details>
  <summary>Details</summary>
Motivation: 弥合同步理论与多智能体AI系统之间的跨学科鸿沟，为异构AI代理在复杂任务执行中的集体行为提供统一的数学框架，实现人类式迭代问题求解与群体智能的融合。

Method: 将AI代理建模为具有相位和振幅动力学的耦合振荡器，引入序参数量化协调和同步程度，通过全连接和确定性无标度网络进行广泛模拟，分析耦合强度、代理多样性和网络拓扑对集体行为的影响。

Result: 增强的耦合促进了异构代理能力下的鲁棒同步，反映了真实的协作AI场景，验证了模型在捕捉代理专业化、影响力和通信方面的有效性。

Conclusion: 该物理信息方法为设计、分析和优化可扩展、自适应、可解释的多智能体AI系统建立了严格的数学基础，为未来整合学习动力学和自适应网络架构以增强系统韧性和效率奠定了基础。

Abstract: We present a novel interdisciplinary framework that bridges synchronization
theory and multi-agent AI systems by adapting the Kuramoto model to describe
the collective dynamics of heterogeneous AI agents engaged in complex task
execution. By representing AI agents as coupled oscillators with both phase and
amplitude dynamics, our model captures essential aspects of agent
specialization, influence, and communication within networked systems. We
introduce an order parameter to quantify the degree of coordination and
synchronization, providing insights into how coupling strength, agent
diversity, and network topology impact emergent collective behavior.
Furthermore, we formalize a detailed correspondence between Chain-of-Thought
prompting in AI reasoning and synchronization phenomena, unifying human-like
iterative problem solving with emergent group intelligence. Through extensive
simulations on all-to-all and deterministic scale-free networks, we demonstrate
that increased coupling promotes robust synchronization despite heterogeneous
agent capabilities, reflecting realistic collaborative AI scenarios. Our
physics-informed approach establishes a rigorous mathematical foundation for
designing, analyzing, and optimizing scalable, adaptive, and interpretable
multi-agent AI systems. This work opens pathways for principled orchestration
of agentic AI and lays the groundwork for future incorporation of learning
dynamics and adaptive network architectures to further enhance system
resilience and efficiency.

</details>


### [206] [A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications](https://arxiv.org/abs/2508.12683)
*David J. Moore*

Main category: cs.MA

TL;DR: 提出了一个五维度的分层多智能体系统分类法，包括控制层次、信息流、角色任务委派、时间分层和通信结构，旨在为不同HMAS设计提供比较框架。


<details>
  <summary>Details</summary>
Motivation: 分层多智能体系统虽然能简化协调，但会引入不明显的权衡，需要系统化的分类框架来理解和比较不同方法。

Method: 构建了一个多维分类法，连接具体协调机制（如合同网协议、分层强化学习），并通过工业案例（电网、油田运营）进行验证。

Result: 分类法统一了HMAS的结构、时间和通信维度，展示了分层结构能在保持局部自治的同时实现全局效率。

Conclusion: 提出了首个统一HMAS多维度设计的分类框架，指出了可解释性、大规模扩展和基于学习智能体集成等开放挑战。

Abstract: Hierarchical multi-agent systems (HMAS) organize collections of agents into
layered structures that help manage complexity and scale. These hierarchies can
simplify coordination, but they also can introduce trade-offs that are not
always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along
five axes: control hierarchy, information flow, role and task delegation,
temporal layering, and communication structure. The intent is not to prescribe
a single "best" design but to provide a lens for comparing different
approaches.
  Rather than treating these dimensions in isolation, the taxonomy is connected
to concrete coordination mechanisms - from the long-standing contract-net
protocol for task allocation to more recent work in hierarchical reinforcement
learning. Industrial contexts illustrate the framework, including power grids
and oilfield operations, where agents at production, maintenance, and supply
levels coordinate to diagnose well issues or balance energy demand. These cases
suggest that hierarchical structures may achieve global efficiency while
preserving local autonomy, though the balance is delicate.
  The paper closes by identifying open challenges: making hierarchical
decisions explainable to human operators, scaling to very large agent
populations, and assessing whether learning-based agents such as large language
models can be safely integrated into layered frameworks. This paper presents
what appears to be the first taxonomy that unifies structural, temporal, and
communication dimensions of hierarchical MAS into a single design framework,
bridging classical coordination mechanisms with modern reinforcement learning
and large language model agents.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [207] [RefAdGen: High-Fidelity Advertising Image Generation](https://arxiv.org/abs/2508.11695)
*Yiyun Chen,Weikai Yang*

Main category: cs.GR

TL;DR: 提出了RefAdGen框架，通过解耦设计和注意力融合模块解决AIGC广告图像生成中的保真度-效率困境，在大型数据集AdProd-100K上实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有AIGC技术在广告图像生成中要么需要大量微调才能达到高保真度，要么难以在不同产品间保持保真度，限制了在电商和营销行业的实际应用

Method: 构建AdProd-100K大规模数据集，采用双重数据增强策略；提出RefAdGen生成框架，通过产品掩码注入实现精确空间控制，使用注意力融合模块集成产品特征

Result: RefAdGen实现了最先进的性能，对未见过的产品和具有挑战性的真实世界图像都能保持高保真度和出色的视觉效果

Conclusion: 该框架为传统工作流程提供了可扩展且成本效益高的替代方案，解决了现有方法的保真度-效率困境

Abstract: The rapid advancement of Artificial Intelligence Generated Content (AIGC)
techniques has unlocked opportunities in generating diverse and compelling
advertising images based on referenced product images and textual scene
descriptions. This capability substantially reduces human labor and production
costs in traditional marketing workflows. However, existing AIGC techniques
either demand extensive fine-tuning for each referenced image to achieve high
fidelity, or they struggle to maintain fidelity across diverse products, making
them impractical for e-commerce and marketing industries. To tackle this
limitation, we first construct AdProd-100K, a large-scale advertising image
generation dataset. A key innovation in its construction is our dual data
augmentation strategy, which fosters robust, 3D-aware representations crucial
for realistic and high-fidelity image synthesis. Leveraging this dataset, we
propose RefAdGen, a generation framework that achieves high fidelity through a
decoupled design. The framework enforces precise spatial control by injecting a
product mask at the U-Net input, and employs an efficient Attention Fusion
Module (AFM) to integrate product features. This design effectively resolves
the fidelity-efficiency dilemma present in existing methods. Extensive
experiments demonstrate that RefAdGen achieves state-of-the-art performance,
showcasing robust generalization by maintaining high fidelity and remarkable
visual results for both unseen products and challenging real-world, in-the-wild
images. This offers a scalable and cost-effective alternative to traditional
workflows. Code and datasets are publicly available at
https://github.com/Anonymous-Name-139/RefAdgen.

</details>


### [208] [Substepping the Material Point Method](https://arxiv.org/abs/2508.11722)
*Chenfanfu Jiang*

Main category: cs.GR

TL;DR: 提出一种将显式MPM积分器包装成伪隐式积分器的简单算法，通过子步长实现大时间步长推进


<details>
  <summary>Details</summary>
Motivation: 显式时间积分在MPM中常用，但有时需要大时间步长（如与其他大步长求解器耦合、施加约束或多物理场求解时）

Method: 使用子步长技术包装显式MPM积分器，将其转换为伪隐式积分器，实现大时间步长推进

Result: 开发了一个即插即用的算法，能够有效处理大时间步长情况

Conclusion: 该方法为MPM提供了处理大时间步长需求的简单有效解决方案

Abstract: Many Material Point Method implementations favor explicit time integration.
However large time steps are often desirable for special reasons - for example,
for partitioned coupling with another large-step solver, or for imposing
constraints, projections, or multiphysics solves. We present a simple,
plug-and-play algorithm that advances MPM with a large time step using
substeps, effectively wrapping an explicit MPM integrator into a
pseudo-implicit one.

</details>


### [209] [Mesh Processing Non-Meshes via Neural Displacement Fields](https://arxiv.org/abs/2508.12179)
*Yuta Noma,Zhecheng Wang,Chenxi Liu,Karan Singh,Alec Jacobson*

Main category: cs.GR

TL;DR: 提出了一种紧凑的神经场方法，能够在不同表面表示之间进行几何处理，避免了传统网格处理管道需要昂贵网格化或传输大体积网格的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的网格处理管道成熟，但难以适应新型非网格表面表示（具有快速渲染和小文件尺寸优势），需要昂贵的网格化或传输大体积网格，这削弱了其在流式应用中的核心优势。

Method: 给定输入表面，该方法学习从粗网格近似到表面的神经映射。完整表示仅几百KB，适合轻量传输。支持流形和Delaunay网格快速提取进行内在形状分析，并压缩标量场以高效传输昂贵的预计算结果。

Result: 该方法实现了快速、紧凑且准确的几何处理，为交互式几何处理开辟了新可能性。完整表示仅需几百KB，大大减少了传输负担。

Conclusion: 提出的紧凑神经场方法成功解决了不同表面表示间的几何处理难题，实现了轻量级传输和高效处理，为流式应用和交互式几何处理提供了实用解决方案。

Abstract: Mesh processing pipelines are mature, but adapting them to newer non-mesh
surface representations -- which enable fast rendering with compact file size
-- requires costly meshing or transmitting bulky meshes, negating their core
benefits for streaming applications.
  We present a compact neural field that enables common geometry processing
tasks across diverse surface representations. Given an input surface, our
method learns a neural map from its coarse mesh approximation to the surface.
The full representation totals only a few hundred kilobytes, making it ideal
for lightweight transmission. Our method enables fast extraction of manifold
and Delaunay meshes for intrinsic shape analysis, and compresses scalar fields
for efficient delivery of costly precomputed results. Experiments and
applications show that our fast, compact, and accurate approach opens up new
possibilities for interactive geometry processing.

</details>


### [210] [Express4D: Expressive, Friendly, and Extensible 4D Facial Motion Generation Benchmark](https://arxiv.org/abs/2508.12438)
*Yaron Aloni,Rotem Shalev-Arkushin,Yonatan Shafir,Guy Tevet,Ohad Fried,Amit Haim Bermano*

Main category: cs.GR

TL;DR: 提出了Express4D数据集，用于细粒度文本驱动的面部表情生成，使用消费级设备和LLM生成的标注，训练了两个基线模型并评估性能


<details>
  <summary>Details</summary>
Motivation: 现有面部表情生成数据集要么是语音驱动的，要么仅限于粗糙的情感标签，缺乏细粒度控制的表达性描述，且采集设备昂贵复杂

Method: 使用消费级设备采集面部运动序列，采用LLM生成自然语言指令进行语义标注，数据格式为ARKit blendshape，训练了两个基线模型

Result: 训练模型能够学习有意义的文本到表情运动生成，捕捉两种模态之间的多对多映射关系

Conclusion: Express4D数据集提供了可绑定、富含表现力的动作和标签，为未来基准测试提供了基础，数据集、代码和视频示例已公开

Abstract: Dynamic facial expression generation from natural language is a crucial task
in Computer Graphics, with applications in Animation, Virtual Avatars, and
Human-Computer Interaction. However, current generative models suffer from
datasets that are either speech-driven or limited to coarse emotion labels,
lacking the nuanced, expressive descriptions needed for fine-grained control,
and were captured using elaborate and expensive equipment. We hence present a
new dataset of facial motion sequences featuring nuanced performances and
semantic annotation. The data is easily collected using commodity equipment and
LLM-generated natural language instructions, in the popular ARKit blendshape
format. This provides riggable motion, rich with expressive performances and
labels. We accordingly train two baseline models, and evaluate their
performance for future benchmarking. Using our Express4D dataset, the trained
models can learn meaningful text-to-expression motion generation and capture
the many-to-many mapping of the two modalities. The dataset, code, and video
examples are available on our webpage: https://jaron1990.github.io/Express4D/

</details>


### [211] [MixCache: Mixture-of-Cache for Video Diffusion Transformer Acceleration](https://arxiv.org/abs/2508.12691)
*Yuanxin Wei,Lansong Diao,Bujiao Chen,Shenggan Cheng,Zhengping Qian,Wenyuan Yu,Nong Xiao,Wei Lin,Jiangsu Du*

Main category: cs.GR

TL;DR: MixCache是一个无需训练的缓存框架，通过多粒度缓存策略和智能触发机制，显著提升视频DiT模型的推理速度，在保持生成质量的同时实现近2倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的视频DiT模型虽然能生成高质量视频，但多步迭代去噪过程计算成本高、推理延迟大。现有缓存方法仅限于单粒度策略，无法灵活平衡生成质量和推理速度。

Method: 提出MixCache框架：1）区分不同缓存策略的干扰和边界；2）上下文感知缓存触发策略确定何时启用缓存；3）自适应混合缓存决策策略动态选择最优缓存粒度

Result: 在多个模型上的实验表明，MixCache能显著加速视频生成（Wan 14B模型1.94倍加速，HunyuanVideo模型1.97倍加速），同时在生成质量和推理效率方面优于基线方法

Conclusion: MixCache通过创新的多粒度缓存策略，有效解决了视频DiT模型推理效率问题，在保持高质量生成的同时实现了显著的性能提升

Abstract: Leveraging the Transformer architecture and the diffusion process, video DiT
models have emerged as a dominant approach for high-quality video generation.
However, their multi-step iterative denoising process incurs high computational
cost and inference latency. Caching, a widely adopted optimization method in
DiT models, leverages the redundancy in the diffusion process to skip
computations in different granularities (e.g., step, cfg, block). Nevertheless,
existing caching methods are limited to single-granularity strategies,
struggling to balance generation quality and inference speed in a flexible
manner. In this work, we propose MixCache, a training-free caching-based
framework for efficient video DiT inference. It first distinguishes the
interference and boundary between different caching strategies, and then
introduces a context-aware cache triggering strategy to determine when caching
should be enabled, along with an adaptive hybrid cache decision strategy for
dynamically selecting the optimal caching granularity. Extensive experiments on
diverse models demonstrate that, MixCache can significantly accelerate video
generation (e.g., 1.94$\times$ speedup on Wan 14B, 1.97$\times$ speedup on
HunyuanVideo) while delivering both superior generation quality and inference
efficiency compared to baseline methods.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [212] [Using Natural Language for Human-Robot Collaboration in the Real World](https://arxiv.org/abs/2508.11759)
*Peter Lindes,Kaoutar Skiker*

Main category: cs.RO

TL;DR: 本文探讨如何利用大语言模型(LLMs)提升机器人的自然语言理解能力，使其能与人类在物理世界中更好地协作，提出了集成LLMs与物理机器人的方法框架，并通过ChatGPT进行了概念验证实验。


<details>
  <summary>Details</summary>
Motivation: 实现自主机器人能与人类使用自然语言协作完成复杂物理任务的愿景，解决传统交互式任务学习系统语言理解能力有限的问题，利用LLMs的强大语言能力提升机器人的语言交互水平。

Method: 提出以认知智能体为核心控制物理机器人，与人类和LLM交互并积累情境知识的AI系统框架。针对机器人理解自然语言的三个具体挑战，使用ChatGPT进行了简单的概念验证实验。

Result: 通过概念验证实验展示了LLMs在提升机器人语言理解能力方面的潜力，证明了该方法框架的可行性。

Conclusion: 需要进一步研究将简单的概念验证实验转化为可操作的集成系统，使LLM辅助的语言理解成为能与人类语言协作的机器人助手的重要组成部分。

Abstract: We have a vision of a day when autonomous robots can collaborate with humans
as assistants in performing complex tasks in the physical world. This vision
includes that the robots will have the ability to communicate with their human
collaborators using language that is natural to the humans. Traditional
Interactive Task Learning (ITL) systems have some of this ability, but the
language they can understand is very limited. The advent of large language
models (LLMs) provides an opportunity to greatly improve the language
understanding of robots, yet integrating the language abilities of LLMs with
robots that operate in the real physical world is a challenging problem.
  In this chapter we first review briefly a few commercial robot products that
work closely with humans, and discuss how they could be much better
collaborators with robust language abilities. We then explore how an AI system
with a cognitive agent that controls a physical robot at its core, interacts
with both a human and an LLM, and accumulates situational knowledge through its
experiences, can be a possible approach to reach that vision. We focus on three
specific challenges of having the robot understand natural language, and
present a simple proof-of-concept experiment using ChatGPT for each. Finally,
we discuss what it will take to turn these simple experiments into an
operational system where LLM-assisted language understanding is a part of an
integrated robotic assistant that uses language to collaborate with humans.

</details>


### [213] [Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots](https://arxiv.org/abs/2508.11802)
*Luigi Penco,Beomyeong Park,Stefan Fasano,Nehar Poddar,Stephen McCrory,Nicholas Kitchel,Tomasz Bialek,Dexton Anderson,Duncan Calvert,Robert Griffin*

Main category: cs.RO

TL;DR: 提出了一种实时步态重定向方法，通过预测用户脚步并适配机器人动力学，实现人机运动同步，同时自动适应不平坦地形


<details>
  <summary>Details</summary>
Motivation: 解决高速任务中人机运动同步的挑战，特别是在用户平坦环境与机器人不平坦地形不匹配的情况下

Method: 重定向用户脚步到机器人脚步位置，预测用户脚步以最小化延迟，持续适配步态估计以匹配用户参考，自主调整机器人脚步适应地形

Result: 在Nadia人形机器人上实验验证了系统的有效性

Conclusion: 该方法能够实现实时人机步态同步，确保机器人平衡稳定性，并成功处理环境不匹配问题

Abstract: Achieving seamless synchronization between user and robot motion in
teleoperation, particularly during high-speed tasks, remains a significant
challenge. In this work, we propose a novel approach for transferring stepping
motions from the user to the robot in real-time. Instead of directly
replicating user foot poses, we retarget user steps to robot footstep
locations, allowing the robot to utilize its own dynamics for locomotion,
ensuring better balance and stability. Our method anticipates user footsteps to
minimize delays between when the user initiates and completes a step and when
the robot does it. The step estimates are continuously adapted to converge with
the measured user references. Additionally, the system autonomously adjusts the
robot's steps to account for its surrounding terrain, overcoming challenges
posed by environmental mismatches between the user's flat-ground setup and the
robot's uneven terrain. Experimental results on the humanoid robot Nadia
demonstrate the effectiveness of the proposed system.

</details>


### [214] [LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2508.11849)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: LocoMamba是一个基于Mamba选择性状态空间模型的视觉驱动跨模态DRL框架，通过近线性时间序列建模实现高效训练，在复杂环境中表现出优越的性能和泛化能力


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法在长序列建模中的计算效率低、内存占用大以及对长距离依赖关系捕捉不足的问题，需要开发一个能够高效处理视觉和本体感知信息的强化学习框架

Method: 1) 使用MLP嵌入本体感知状态，CNN处理深度图像生成紧凑token；2) 堆叠Mamba层通过选择性扫描融合token，实现近线性时间建模；3) 使用PPO算法在随机化地形和外观下进行端到端策略训练，采用障碍密度课程和状态中心奖励

Result: 在具有静态/移动障碍和不平地形的模拟环境中，相比SOTA基线方法获得更高回报和成功率，碰撞更少，对未见地形和障碍密度有更强泛化能力，训练效率更高

Conclusion: LocoMamba框架通过选择性状态空间模型有效解决了长序列建模的效率问题，在机器人导航任务中展现出卓越的性能和实用性

Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on
selective state-space models, specifically leveraging Mamba, that achieves
near-linear-time sequence modeling, effectively captures long-range
dependencies, and enables efficient training with longer sequences. First, we
embed proprioceptive states with a multilayer perceptron and patchify depth
images with a lightweight convolutional neural network, producing compact
tokens that improve state representation. Second, stacked Mamba layers fuse
these tokens via near-linear-time selective scanning, reducing latency and
memory footprint, remaining robust to token length and image resolution, and
providing an inductive bias that mitigates overfitting. Third, we train the
policy end-to-end with Proximal Policy Optimization under terrain and
appearance randomization and an obstacle-density curriculum, using a compact
state-centric reward that balances progress, smoothness, and safety. We
evaluate our method in challenging simulated environments with static and
moving obstacles as well as uneven terrain. Compared with state-of-the-art
baselines, our method achieves higher returns and success rates with fewer
collisions, exhibits stronger generalization to unseen terrains and obstacle
densities, and improves training efficiency by converging in fewer updates
under the same compute budget.

</details>


### [215] [Data Shift of Object Detection in Autonomous Driving](https://arxiv.org/abs/2508.11868)
*Lida Xu*

Main category: cs.RO

TL;DR: 本文研究了自动驾驶目标检测中的数据偏移问题，提出了基于CycleGAN数据增强和YOLOv5框架的优化方法，在BDD100K数据集上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在自动驾驶环境感知中发挥关键作用，但其性能严重依赖于训练和测试数据满足独立同分布假设，而现实应用中由于季节变化、天气波动等因素导致的数据分布动态变化会造成数据偏移问题。

Method: 系统分析数据偏移问题的复杂性和多样性表现，综述数据偏移检测方法并运用偏移检测分析技术进行数据集分类和平衡，构建目标检测模型，集成CycleGAN数据增强技术与YOLOv5框架进行模型优化。

Result: 在BDD100K数据集上的实验结果表明，该方法相比基线模型取得了更优越的性能表现。

Conclusion: 通过有效处理数据偏移问题，结合先进的数据增强技术和目标检测框架，可以显著提升自动驾驶系统在复杂环境下的目标检测性能。

Abstract: With the widespread adoption of machine learning technologies in autonomous
driving systems, their role in addressing complex environmental perception
challenges has become increasingly crucial. However, existing machine learning
models exhibit significant vulnerability, as their performance critically
depends on the fundamental assumption that training and testing data satisfy
the independent and identically distributed condition, which is difficult to
guarantee in real-world applications. Dynamic variations in data distribution
caused by seasonal changes, weather fluctuations lead to data shift problems in
autonomous driving systems. This study investigates the data shift problem in
autonomous driving object detection tasks, systematically analyzing its
complexity and diverse manifestations. We conduct a comprehensive review of
data shift detection methods and employ shift detection analysis techniques to
perform dataset categorization and balancing. Building upon this foundation, we
construct an object detection model. To validate our approach, we optimize the
model by integrating CycleGAN-based data augmentation techniques with the
YOLOv5 framework. Experimental results demonstrate that our method achieves
superior performance compared to baseline models on the BDD100K dataset.

</details>


### [216] [Bioinspired underwater soft robots: from biology to robotics and back](https://arxiv.org/abs/2508.11883)
*Lei Li,Boyang Qin,Wenzhuo Gao,Yanyu Li,Yiyuan Zhang,Bo Wang,Shihan Kong,Jian Wang,Dekui He,Junzhi Yu*

Main category: cs.RO

TL;DR: 本文提出了一个双向的生物启发软体机器人框架，不仅用生物学指导机器人设计，还利用机器人作为实验工具来验证生物学假设和进化理论。


<details>
  <summary>Details</summary>
Motivation: 海洋中大量未探索区域和多样化的软体海洋生物激发了仿生水下软体机器人的研究兴趣。现有研究主要是单向的（生物学指导机器人），缺乏从机器人到生物学的反馈机制。

Method: 提出整体性双向框架，整合生物学原理、机器人实现和生物学验证。软体机器人作为实验工具来探测生物功能并测试进化假设。引入"生物通用启发机器人"范式，超越物种特异性模仿，识别跨物种的趋同原理。

Result: 软体机器人凭借其固有的柔顺性，在非结构化环境中优于刚性系统，支持海洋探索、操作和医疗应用。机器人可以反馈验证生物学理论和进化假设。

Conclusion: 通过统一生物学和工程学，软体机器人能够推进海洋探索并深化科学发现，但在材料鲁棒性、驱动效率、自主性和智能方面仍存在挑战。

Abstract: The ocean vast unexplored regions and diverse soft-bodied marine organisms
have spurred interest in bio-inspired underwater soft robotics. Recent advances
have enabled new capabilities in underwater movement, sensing, and interaction.
However, these efforts are largely unidirectional, with biology guiding
robotics while insights from robotics rarely feed back into biology. Here we
propose a holistic, bidirectional framework that integrates biological
principles, robotic implementation, and biological validation. We show that
soft robots can serve as experimental tools to probe biological functions and
even test evolutionary hypotheses. Their inherent compliance also allows them
to outperform rigid systems in unstructured environments, supporting
applications in marine exploration, manipulation, and medicine. Looking
forward, we introduce bio-universal-inspired robotics, a paradigm that
transcends species-specific mimicry by identifying convergent principles across
species to inspire more adaptable designs. Despite rapid progress, challenges
persist in material robustness, actuation efficiency, autonomy, and
intelligence. By uniting biology and engineering, soft robots can advance ocean
exploration and deepen scientific discovery.

</details>


### [217] [From Screen to Stage: Kid Cosmo, A Life-Like, Torque-Controlled Humanoid for Entertainment Robotics](https://arxiv.org/abs/2508.11884)
*Havel Liu,Mingzhang Zhu,Arturo Moises Flores Alvarez,Yuan Hung Lo,Conrad Ku,Federico Parres,Justin Quan,Colin Togashi,Aditya Navghare,Quanyou Wang,Dennis W. Hong*

Main category: cs.RO

TL;DR: Kid Cosmo是一个儿童尺寸的娱乐人形机器人平台，专为稳健运动和拟人动作生成而设计，模仿了Netflix电影《电子国度》中的角色形象。


<details>
  <summary>Details</summary>
Motivation: 探索人形机器人在娱乐领域的潜力，解决娱乐机器人设计中视觉外观与功能性的平衡问题，这类机器人需要同时具备角色体现和技术功能性。

Method: 开发了1.45米高、25公斤重的儿童尺寸人形机器人，配备28个自由度，主要使用本体感受执行器，实现扭矩控制行走和逼真动作生成。

Result: 通过全球展示验证了系统的可行性，展示了在同时进行上下半身运动时的稳定性，证明了性能导向人形机器人的可行性。

Conclusion: Kid Cosmo平台成功展示了娱乐人形机器人既能实现角色体现又能保持技术功能性的设计理念，为娱乐机器人领域提供了有价值的参考。

Abstract: Humanoid robots represent the cutting edge of robotics research, yet their
potential in entertainment remains largely unexplored. Entertainment as a field
prioritizes visuals and form, a principle that contrasts with the purely
functional designs of most contemporary humanoid robots. Designing
entertainment humanoid robots capable of fluid movement presents a number of
unique challenges. In this paper, we present Kid Cosmo, a research platform
designed for robust locomotion and life-like motion generation while imitating
the look and mannerisms of its namesake character from Netflix's movie The
Electric State. Kid Cosmo is a child-sized humanoid robot, standing 1.45 m tall
and weighing 25 kg. It contains 28 degrees of freedom and primarily uses
proprioceptive actuators, enabling torque-control walking and lifelike motion
generation. Following worldwide showcases as part of the movie's press tour, we
present the system architecture, challenges of a functional entertainment robot
and unique solutions, and our initial findings on stability during simultaneous
upper and lower body movement. We demonstrate the viability of
performance-oriented humanoid robots that prioritize both character embodiment
and technical functionality.

</details>


### [218] [Contact-Rich and Deformable Foot Modeling for Locomotion Control of the Human Musculoskeletal System](https://arxiv.org/abs/2508.11885)
*Haixin Gong,Chen Zhang,Yanan Sui*

Main category: cs.RO

TL;DR: 开发了一个包含丰富接触点和可变形足部的新型肌肉骨骼模型，通过两阶段策略训练实现了更自然的人类行走模拟，相比传统刚性模型在运动学、动力学和步态稳定性方面均有提升。


<details>
  <summary>Details</summary>
Motivation: 现有肌肉骨骼模型通常过度简化足地接触力学，限制了准确模拟人类步态动力学的能力，需要开发更精确的接触界面模型。

Method: 构建了接触丰富且可变形的人类足部模型，集成到完整肌肉骨骼系统中，采用两阶段策略训练来学习自然行走模式，克服多点接触和可变形材料建模的控制挑战。

Result: 相比传统刚性肌肉骨骼模型，在运动学、动力学和步态稳定性指标上均有改进，验证实验证实模拟结果与真实人体生物力学测量数据高度吻合。

Conclusion: 这项工作推进了人类肌肉骨骼系统的接触丰富界面建模，建立了可扩展到需要精确足地交互控制的人形机器人应用的稳健框架。

Abstract: The human foot serves as the critical interface between the body and
environment during locomotion. Existing musculoskeletal models typically
oversimplify foot-ground contact mechanics, limiting their ability to
accurately simulate human gait dynamics. We developed a novel contact-rich and
deformable model of the human foot integrated within a complete musculoskeletal
system that captures the complex biomechanical interactions during walking. To
overcome the control challenges inherent in modeling multi-point contacts and
deformable material, we developed a two-stage policy training strategy to learn
natural walking patterns for this interface-enhanced model. Comparative
analysis between our approach and conventional rigid musculoskeletal models
demonstrated improvements in kinematic, kinetic, and gait stability metrics.
Validation against human subject data confirmed that our simulation closely
reproduced real-world biomechanical measurements. This work advances
contact-rich interface modeling for human musculoskeletal systems and
establishes a robust framework that can be extended to humanoid robotics
applications requiring precise foot-ground interaction control.

</details>


### [219] [Saliency-Based Attention Shifting: A Framework for Improving Driver Situational Awareness of Out-of-Label Hazards](https://arxiv.org/abs/2508.11887)
*Yousra Shleibik,Jordan Sinclair,Kerstin Haring*

Main category: cs.RO

TL;DR: 论文探讨了在自动驾驶系统中通过视觉和听觉线索的注意力重定向技术，以提升驾驶员在接管过程中的情境感知能力，减少目标固着现象。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术向更高水平发展，需要在无法识别场景对象时进行人工干预，因此需要集成系统来支持人类决策，确保平稳接管操作并避免碰撞。

Method: 提出了一个结合实时视线追踪、上下文感知显著性分析和同步视听警报的概念框架，用于主动识别潜在危险并增强人机协作。

Result: 通过注意力重定向技术帮助驾驶员保持对突发危险的关注，减少目标固着，提升半自动驾驶场景中的安全性。

Conclusion: 集成的注意力重定向框架能够有效增强情境感知，促进人类与自动驾驶系统之间的有效协作，降低接管过程中的风险。

Abstract: The advent of autonomous driving systems promises to transform transportation
by enhancing safety, efficiency, and comfort. As these technologies evolve
toward higher levels of autonomy, the need for integrated systems that
seamlessly support human involvement in decision-making becomes increasingly
critical. Certain scenarios necessitate human involvement, including those
where the vehicle is unable to identify an object or element in the scene, and
as such cannot take independent action. Therefore, situational awareness is
essential to mitigate potential risks during a takeover, where a driver must
assume control and autonomy from the vehicle. The need for driver attention is
important to avoid collisions with external agents and ensure a smooth
transition during takeover operations. This paper explores the integration of
attention redirection techniques, such as gaze manipulation through targeted
visual and auditory cues, to help drivers maintain focus on emerging hazards
and reduce target fixation in semi-autonomous driving scenarios. We propose a
conceptual framework that combines real-time gaze tracking, context-aware
saliency analysis, and synchronized visual and auditory alerts to enhance
situational awareness, proactively address potential hazards, and foster
effective collaboration between humans and autonomous systems.

</details>


### [220] [Integrating Symbolic RL Planning into a BDI-based Autonomous UAV Framework: System Integration and SIL Validation](https://arxiv.org/abs/2508.11890)
*Sangwoo Jeon,Juchul Shin,YeonJe Cho,Gyeong-Tae Kim,Seongwoo Kim*

Main category: cs.RO

TL;DR: AMAD-SRL框架将符号强化学习集成到无人机多智能体架构中，通过PDDL整合领域知识，在软件在环环境中验证了75%的任务效率提升


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的无人机自主系统在动态复杂环境中适应性不足，需要结合符号规划和强化学习来提高决策可靠性和安全性

Method: 提出AMAD-SRL框架，扩展AMAD认知多智能体架构，集成符号强化学习(SRL)和PDDL规划语言，在软件在环环境中验证

Result: 模块集成稳定，BDI驱动和符号RL规划阶段转换成功，任务效率相比覆盖基线提升约75%（旅行距离减少）

Conclusion: 为处理复杂无人机任务建立了坚实基础，讨论了进一步改进和验证的方向

Abstract: Modern autonomous drone missions increasingly require software frameworks
capable of seamlessly integrating structured symbolic planning with adaptive
reinforcement learning (RL). Although traditional rule-based architectures
offer robust structured reasoning for drone autonomy, their capabilities fall
short in dynamically complex operational environments that require adaptive
symbolic planning. Symbolic RL (SRL), using the Planning Domain Definition
Language (PDDL), explicitly integrates domain-specific knowledge and
operational constraints, significantly improving the reliability and safety of
unmanned aerial vehicle (UAV) decision making. In this study, we propose the
AMAD-SRL framework, an extended and refined version of the Autonomous Mission
Agents for Drones (AMAD) cognitive multi-agent architecture, enhanced with
symbolic reinforcement learning for dynamic mission planning and execution. We
validated our framework in a Software-in-the-Loop (SIL) environment structured
identically to an intended Hardware-In-the-Loop Simulation (HILS) platform,
ensuring seamless transition to real hardware. Experimental results demonstrate
stable integration and interoperability of modules, successful transitions
between BDI-driven and symbolic RL-driven planning phases, and consistent
mission performance. Specifically, we evaluate a target acquisition scenario in
which the UAV plans a surveillance path followed by a dynamic reentry path to
secure the target while avoiding threat zones. In this SIL evaluation, mission
efficiency improved by approximately 75% over a coverage-based baseline,
measured by travel distance reduction. This study establishes a robust
foundation for handling complex UAV missions and discusses directions for
further enhancement and validation.

</details>


### [221] [OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation](https://arxiv.org/abs/2508.11898)
*Jilei Mao,Jiarui Guan,Yingjuan Tang,Qirui Hu,Zhihang Li,Junjie Yu,Yongjie Mao,Yunzhe Sun,Shuang Liu,Xiaozhu Ju*

Main category: cs.RO

TL;DR: OmniD是一个多视角融合框架，通过可变形注意力机制将多视角图像合成为统一的鸟瞰图表示，解决了视觉运动策略在分布外泛化和多视角信息融合方面的难题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉运动策略容易过拟合训练数据（如固定相机位置和背景），在分布外场景表现不佳，且难以有效融合多视角信息生成3D表示。

Method: 提出Omni-Vision Diffusion Policy (OmniD)框架，使用基于可变形注意力的Omni-Feature Generator (OFG)选择性提取任务相关特征，抑制视角特定噪声和背景干扰，合成统一的鸟瞰图表示。

Result: 在分布内、分布外和少样本实验中分别比最佳基线模型平均提升11%、17%和84%。

Conclusion: OmniD通过有效的多视角融合和特征选择机制，显著提升了视觉运动策略的泛化能力和性能表现。

Abstract: The visuomotor policy can easily overfit to its training datasets, such as
fixed camera positions and backgrounds. This overfitting makes the policy
perform well in the in-distribution scenarios but underperform in the
out-of-distribution generalization. Additionally, the existing methods also
have difficulty fusing multi-view information to generate an effective 3D
representation. To tackle these issues, we propose Omni-Vision Diffusion Policy
(OmniD), a multi-view fusion framework that synthesizes image observations into
a unified bird's-eye view (BEV) representation. We introduce a deformable
attention-based Omni-Feature Generator (OFG) to selectively abstract
task-relevant features while suppressing view-specific noise and background
distractions. OmniD achieves 11\%, 17\%, and 84\% average improvement over the
best baseline model for in-distribution, out-of-distribution, and few-shot
experiments, respectively. Training code and simulation benchmark are
available: https://github.com/1mather/omnid.git

</details>


### [222] [Control of Legged Robots using Model Predictive Optimized Path Integral](https://arxiv.org/abs/2508.11917)
*Hossein Keshavarz,Alejandro Ramirez-Serrano,Majid Khadiv*

Main category: cs.RO

TL;DR: 本文提出MPOPI算法，结合MPPI、交叉熵和协方差矩阵自适应方法，为腿式机器人实现实时全身运动控制，相比传统MPPI算法具有更好的样本效率和运动性能。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在复杂非结构化环境中具有独特优势，但现有技术尚未达到自然系统的水平。采样预测控制器显示出良好前景，需要提高样本效率和实时控制能力。

Method: 采用模型预测路径积分(MPPI)与交叉熵(CE)和协方差矩阵自适应(CMA)方法相结合的策略，开发了MPOPI算法来生成实时全身运动控制。

Result: 仿真实验表明MPOPI算法样本效率更高，能用更少样本获得优越的运动效果，可作为随时控制策略，每次迭代都能提升运动能力。

Conclusion: MPOPI算法成功整合了MPPI、CE和CMA的优势，为腿式机器人在多场景下的实时运动控制提供了有效的解决方案，显著提升了运动性能和样本效率。

Abstract: Legged robots possess a unique ability to traverse rough terrains and
navigate cluttered environments, making them well-suited for complex,
real-world unstructured scenarios. However, such robots have not yet achieved
the same level as seen in natural systems. Recently, sampling-based predictive
controllers have demonstrated particularly promising results. This paper
investigates a sampling-based model predictive strategy combining model
predictive path integral (MPPI) with cross-entropy (CE) and covariance matrix
adaptation (CMA) methods to generate real-time whole-body motions for legged
robots across multiple scenarios. The results show that combining the benefits
of MPPI, CE and CMA, namely using model predictive optimized path integral
(MPOPI), demonstrates greater sample efficiency, enabling robots to attain
superior locomotion results using fewer samples when compared to typical MPPI
algorithms. Extensive simulation experiments in multiple scenarios on a
quadruped robot show that MPOPI can be used as an anytime control strategy,
increasing locomotion capabilities at each iteration.

</details>


### [223] [ExploreVLM: Closed-Loop Robot Exploration Task Planning with Vision-Language Models](https://arxiv.org/abs/2508.11918)
*Zhichen Lou,Kechun Xu,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了ExploreVLM框架，通过视觉语言模型实现闭环任务规划，结合逐步反馈机制和对象中心空间关系图，显著提升了机器人在动态环境中的探索和任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的方法在交互探索、精确感知和实时计划调整方面存在不足，需要开发能够适应动态环境的新型任务规划框架。

Method: 采用双阶段任务规划器（带自反思机制）、对象中心空间关系图提供结构化场景表示、执行验证器实现闭环控制，支持实时计划调整和交互探索。

Result: 在真实世界实验中显著优于最先进基线方法，特别是在探索中心任务中表现突出，消融研究验证了反思规划器和结构化感知的关键作用。

Conclusion: ExploreVLM框架通过闭环任务规划和结构化感知实现了鲁棒高效的任务执行，为具身智能在动态环境中的应用提供了有效解决方案。

Abstract: The advancement of embodied intelligence is accelerating the integration of
robots into daily life as human assistants. This evolution requires robots to
not only interpret high-level instructions and plan tasks but also perceive and
adapt within dynamic environments. Vision-Language Models (VLMs) present a
promising solution by combining visual understanding and language reasoning.
However, existing VLM-based methods struggle with interactive exploration,
accurate perception, and real-time plan adaptation. To address these
challenges, we propose ExploreVLM, a novel closed-loop task planning framework
powered by Vision-Language Models (VLMs). The framework is built around a
step-wise feedback mechanism that enables real-time plan adjustment and
supports interactive exploration. At its core is a dual-stage task planner with
self-reflection, enhanced by an object-centric spatial relation graph that
provides structured, language-grounded scene representations to guide
perception and planning. An execution validator supports the closed loop by
verifying each action and triggering re-planning. Extensive real-world
experiments demonstrate that ExploreVLM significantly outperforms
state-of-the-art baselines, particularly in exploration-centric tasks. Ablation
studies further validate the critical role of the reflective planner and
structured perception in achieving robust and efficient task execution.

</details>


### [224] [No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain](https://arxiv.org/abs/2508.11929)
*Mohitvishnu S. Gadde,Pranay Dugar,Ashish Malik,Alan Fern*

Main category: cs.RO

TL;DR: 提出了一个基于视觉的全向双足运动学习框架，通过结合盲控制器和教师策略来训练视觉学生策略，避免了昂贵的全向深度图像渲染成本，实现了高效的全向地形适应运动。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中实现有效的双足运动需要全向地形感知和能够处理这种输入的控制器，但传统模拟到真实的强化学习方法由于全向深度图像渲染计算成本高而不实用。

Method: 结合鲁棒的盲控制器和教师策略来监督基于视觉的学生策略，使用噪声增强的地形数据进行训练以避免RL期间的渲染成本，并引入数据增强技术加速监督训练。

Result: 在仿真和真实世界测试中验证了框架的有效性，展示了全向运动能力，对多样化地形具有良好的适应性，训练速度比传统方法快10倍。

Conclusion: 这是首个基于视觉的全向双足运动演示，展示了在不依赖昂贵渲染的情况下实现全向地形适应的可行性，为动态环境中的双足机器人运动提供了有效解决方案。

Abstract: Effective bipedal locomotion in dynamic environments, such as cluttered
indoor spaces or uneven terrain, requires agile and adaptive movement in all
directions. This necessitates omnidirectional terrain sensing and a controller
capable of processing such input. We present a learning framework for
vision-based omnidirectional bipedal locomotion, enabling seamless movement
using depth images. A key challenge is the high computational cost of rendering
omnidirectional depth images in simulation, making traditional sim-to-real
reinforcement learning (RL) impractical. Our method combines a robust blind
controller with a teacher policy that supervises a vision-based student policy,
trained on noise-augmented terrain data to avoid rendering costs during RL and
ensure robustness. We also introduce a data augmentation technique for
supervised student training, accelerating training by up to 10 times compared
to conventional methods. Our framework is validated through simulation and
real-world tests, demonstrating effective omnidirectional locomotion with
minimal reliance on expensive rendering. This is, to the best of our knowledge,
the first demonstration of vision-based omnidirectional bipedal locomotion,
showcasing its adaptability to diverse terrains.

</details>


### [225] [Toward General Physical Intelligence for Resilient Agile Manufacturing Automation](https://arxiv.org/abs/2508.11960)
*Sandeep Kanta,Mehrdad Tavassoli,Varun Teja Chirkuri,Venkata Akhil Kumar,Santhi Bharath Punati,Praveen Damacharla,Sunny Katyara*

Main category: cs.RO

TL;DR: 这篇综述论文系统性地调查了视觉语言动作(VLA)模型在通用物理智能(GPI)背景下的最新进展，通过结构化消融研究评估了主要实现的工业部署准备度，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 敏捷和以人为本的制造需要具备情境推理能力和在非结构化环境中安全交互的弹性机器人解决方案。虽然GPI概念已在文献中提出，但其在当代敏捷制造过程中的实际应用和演进角色尚未得到充分探索。

Method: 通过系统性文献综述，对VLA模型在GPI背景下的最新进展进行调研，对领先实现进行全面的比较分析，并通过结构化消融研究评估其工业部署准备度。

Result: 分析将最先进技术组织为五个主题支柱：多感官表示学习、仿真到现实迁移、规划与控制、不确定性和安全措施、基准测试。

Conclusion: 文章阐明了开放的研究挑战，并提出了将GPI更好地集成到符合工业5.0标准的下一代工业生态系统中的发展方向。

Abstract: Agile and human-centric manufacturing stipulates resilient robotic solutions
capable of contextual reasoning and safe interaction in unstructured
environments. Foundation models particularly the Vision Language Action (VLA)
models have emerged to fuse multimodal perception, reasoning and physically
grounded action across varied embodiments into unified representation, termed
as General Physical Intelligence (GPI). While GPI has already been described in
the literature but its practical application and evolving role in contemporary
agile manufacturing processes have yet to be duly explored. To bridge this gap,
this practical review systematically surveys recent advancements in VLA models
within GPI context, performs comprehensive comparative analysis of leading
implementations and evaluates their readiness for industrial deployment through
structured ablation study. Our analysis has organized state-of-the-art into
five thematic pillars including multisensory representation learning, sim2real
transfer, planning and control, uncertainty and safety measures and
benchmarking. Finally, we articulate open research challenges and propose
directions to better integrate GPI into next-generation industrial ecosystems
in line with Industry 5.0.

</details>


### [226] [Fully Spiking Actor-Critic Neural Network for Robotic Manipulation](https://arxiv.org/abs/2508.12038)
*Liwen Zhang,Heng Deng,Guanghui Sun*

Main category: cs.RO

TL;DR: 提出基于全脉冲神经网络的混合课程强化学习框架，用于9自由度机械臂的目标抓取任务，通过简化网络结构、集成时间进度分区课程策略和能耗建模，在资源受限环境下实现高性能和能效。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统人工神经网络在机器人控制中的高能耗和延迟问题，利用脉冲神经网络的高推理速度、低能耗和生物合理性优势，开发适用于资源受限环境的强化学习框架。

Method: 采用简化结构的全脉冲神经网络（仅输入输出层），集成时间进度分区课程策略与PPO算法，引入能耗建模框架比较SNN与ANN能耗，采用动态两阶段奖励调整机制和优化观测空间。

Result: 在Isaac Gym仿真平台实验中，该方法在真实物理约束下表现出优越性能，与传统PPO和ANN基线相比，验证了在动态机器人操作任务中的可扩展性和能源效率。

Conclusion: 提出的混合课程强化学习框架成功地将脉冲神经网络应用于复杂机器人控制任务，显著降低了能耗和延迟，为资源受限环境下的机器人应用提供了有效解决方案。

Abstract: This study proposes a hybrid curriculum reinforcement learning (CRL)
framework based on a fully spiking neural network (SNN) for 9-degree-of-freedom
robotic arms performing target reaching and grasping tasks. To reduce network
complexity and inference latency, the SNN architecture is simplified to include
only an input and an output layer, which shows strong potential for
resource-constrained environments. Building on the advantages of SNNs-high
inference speed, low energy consumption, and spike-based biological
plausibility, a temporal progress-partitioned curriculum strategy is integrated
with the Proximal Policy Optimization (PPO) algorithm. Meanwhile, an energy
consumption modeling framework is introduced to quantitatively compare the
theoretical energy consumption between SNNs and conventional Artificial Neural
Networks (ANNs). A dynamic two-stage reward adjustment mechanism and optimized
observation space further improve learning efficiency and policy accuracy.
Experiments on the Isaac Gym simulation platform demonstrate that the proposed
method achieves superior performance under realistic physical constraints.
Comparative evaluations with conventional PPO and ANN baselines validate the
scalability and energy efficiency of the proposed approach in dynamic robotic
manipulation tasks.

</details>


### [227] [Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs](https://arxiv.org/abs/2508.12043)
*Fei Lin,Tengchao Zhang,Qinghua Ni,Jun Huang,Siji Ma,Yonglin Tian,Yisheng Lv,Naiqi Wu*

Main category: cs.RO

TL;DR: 本文探索了LLM驱动的无人机群在带宽受限条件下实现自主语义压缩通信的可行性，通过构建四种复杂度的2D仿真场景，评估了9种主流LLM的语义压缩性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在无人机系统中的快速应用虽然提升了语义理解和自主任务执行能力，但有限的通信带宽和高频交互需求对群内语义信息传输构成了严峻挑战。

Method: 构建了四种不同环境复杂度的2D仿真场景，设计了系统提示与任务指令提示相结合的通信-执行流水线，系统评估了9种主流LLM在不同场景下的语义压缩性能，并通过环境复杂度和群规模的消融实验分析其适应性和稳定性。

Result: 实验结果表明，基于LLM的无人机群有潜力在带宽受限和多跳链路条件下实现高效的协作通信。

Conclusion: LLM驱动的无人机群能够通过语义压缩有效减少通信负载，同时保持关键任务语义，为解决带宽约束下的群协作通信问题提供了可行方案。

Abstract: The rapid adoption of Large Language Models (LLMs) in unmanned systems has
significantly enhanced the semantic understanding and autonomous task execution
capabilities of Unmanned Aerial Vehicle (UAV) swarms. However, limited
communication bandwidth and the need for high-frequency interactions pose
severe challenges to semantic information transmission within the swarm. This
paper explores the feasibility of LLM-driven UAV swarms for autonomous semantic
compression communication, aiming to reduce communication load while preserving
critical task semantics. To this end, we construct four types of 2D simulation
scenarios with different levels of environmental complexity and design a
communication-execution pipeline that integrates system prompts with task
instruction prompts. On this basis, we systematically evaluate the semantic
compression performance of nine mainstream LLMs in different scenarios and
analyze their adaptability and stability through ablation studies on
environmental complexity and swarm size. Experimental results demonstrate that
LLM-based UAV swarms have the potential to achieve efficient collaborative
communication under bandwidth-constrained and multi-hop link conditions.

</details>


### [228] [OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments](https://arxiv.org/abs/2508.12071)
*Amy Phung,Richard Camilli*

Main category: cs.RO

TL;DR: OASIS是一种实时水下3D重建方法，通过光学相机和声纳传感器融合，结合体素雕刻技术，实现非结构化水下工作空间的实时三维重建


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注离线重建，而实时空间感知对于自主和有人驾驶水下车辆操作至关重要

Method: 采用"手眼"配置，利用机器人机械臂的灵活性在短基线上捕获多个工作空间视图，将光学图像与体素雕刻技术相结合

Result: 通过水箱实验验证，展示了定性和定量结果，突显了其在水下操作任务中的实用性

Conclusion: OASIS方法实现了实时水下3D场景重建，为水下操作任务提供了有效的空间感知解决方案

Abstract: High resolution underwater 3D scene reconstruction is crucial for various
applications, including construction, infrastructure maintenance, monitoring,
exploration, and scientific investigation. Prior work has leveraged the
complementary sensing modalities of imaging sonars and optical cameras for
opti-acoustic 3D scene reconstruction, demonstrating improved results over
methods which rely solely on either sensor. However, while most existing
approaches focus on offline reconstruction, real-time spatial awareness is
essential for both autonomous and piloted underwater vehicle operations. This
paper presents OASIS, an opti-acoustic fusion method that integrates data from
optical images with voxel carving techniques to achieve real-time 3D
reconstruction unstructured underwater workspaces. Our approach utilizes an
"eye-in-hand" configuration, which leverages the dexterity of robotic
manipulator arms to capture multiple workspace views across a short baseline.
We validate OASIS through tank-based experiments and present qualitative and
quantitative results that highlight its utility for underwater manipulation
tasks.

</details>


### [229] [Into the Wild: When Robots Are Not Welcome](https://arxiv.org/abs/2508.12075)
*Shaul Ashkenazi,Gabriel Skantze,Jane Stuart-Smith,Mary Ellen Foster*

Main category: cs.RO

TL;DR: 论文报告了在两个公共场所部署社交机器人的失败经历，但最终通过与工作人员建立信任关系成功完成了部署研究


<details>
  <summary>Details</summary>
Motivation: 研究社交机器人在公共场所部署时面临的技术挑战、用户意外反应以及利益相关者反对的问题

Method: 在两个不同公共场所（学生服务中心和难民/寻求庇护者服务中心）部署社交机器人，记录遇到的困难和改进过程

Result: 虽然最初遭遇失败，但通过与工作人员建立信任关系，最终成功部署机器人并完成研究

Conclusion: 社交机器人在公共场所的成功部署不仅取决于技术因素，更重要的是与利益相关者建立信任关系

Abstract: Social robots are increasingly being deployed in public spaces, where they
face not only technological difficulties and unexpected user utterances, but
also objections from stakeholders who may not be comfortable with introducing a
robot into those spaces. We describe our difficulties with deploying a social
robot in two different public settings: 1) Student services center; 2) Refugees
and asylum seekers drop-in service. Although this is a failure report, in each
use case we eventually managed to earn the trust of the staff and form a
relationship with them, allowing us to deploy our robot and conduct our
studies.

</details>


### [230] [Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing](https://arxiv.org/abs/2508.12166)
*Gokul Puthumanaillam,Aditya Penumarti,Manav Vora,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla,Jane Shin,Melkior Ornik*

Main category: cs.RO

TL;DR: B-COD是一种基于扩散模型的信念空间规划器，通过单次前向传播生成轨迹和定位误差代理，结合强化学习在线选择最小传感器子集，在保证定位精度的同时显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 解决机器人如何在映射环境中为特定任务选择最小传感器子集的问题，避免持续开启所有传感器造成的能源浪费，同时维持足够的状态不确定性来完成任务。

Method: 提出信念条件单步扩散模型(B-COD)，通过显式条件化位姿信念栅格和传感器掩码，利用去噪轨迹的扩散作为校准的定位误差代理，结合软演员-评论家算法在线选择传感器。

Result: 在无人水面车辆实时海洋试验中，B-COD在匹配全开传感器基线性能的同时，显著降低了传感能耗消耗。

Conclusion: B-COD首次实现了在10毫秒内生成轨迹和定位误差代理，消除了外部协方差传播需求，为节能的传感器管理提供了有效解决方案。

Abstract: Robots equipped with rich sensor suites can localize reliably in
partially-observable environments, but powering every sensor continuously is
wasteful and often infeasible. Belief-space planners address this by
propagating pose-belief covariance through analytic models and switching
sensors heuristically--a brittle, runtime-expensive approach. Data-driven
approaches--including diffusion models--learn multi-modal trajectories from
demonstrations, but presuppose an accurate, always-on state estimate. We
address the largely open problem: for a given task in a mapped environment,
which \textit{minimal sensor subset} must be active at each location to
maintain state uncertainty \textit{just low enough} to complete the task? Our
key insight is that when a diffusion planner is explicitly conditioned on a
pose-belief raster and a sensor mask, the spread of its denoising trajectories
yields a calibrated, differentiable proxy for the expected localisation error.
Building on this insight, we present Belief-Conditioned One-Step Diffusion
(B-COD), the first planner that, in a 10 ms forward pass, returns a
short-horizon trajectory, per-waypoint aleatoric variances, and a proxy for
localisation error--eliminating external covariance rollouts. We show that this
single proxy suffices for a soft-actor-critic to choose sensors online,
optimising energy while bounding pose-covariance growth. We deploy B-COD in
real-time marine trials on an unmanned surface vehicle and show that it reduces
sensing energy consumption while matching the goal-reach performance of an
always-on baseline.

</details>


### [231] [Energy Efficiency in Robotics Software: A Systematic Literature Review (2020-2024)](https://arxiv.org/abs/2508.12170)
*Aryan Gupta*

Main category: cs.RO

TL;DR: 对2020-2024年机器人软件层面能效方法的系统文献综述，涵盖79项研究，分析了应用领域、能耗模型、主要能耗组件、软件技术家族和能耗-质量权衡。


<details>
  <summary>Details</summary>
Motivation: 更新和扩展2020年前的证据，为机器人软件能效研究提供全面的现状分析，解决现有研究中报告不一致和可比性有限的问题。

Method: 采用自动化但经过审核的流程，结合Google Scholar种子搜索、前后向滚雪球法和大语言模型辅助筛选与数据提取，10%人工审核，最终分析79项同行评审研究。

Result: 工业设置主导(31.6%)，电机/执行器是主要能耗源(68.4%)，运动轨迹优化是最常用技术(69.6%)，仿真评估仍最常见(51.9%)，报告存在异质性。

Conclusion: 提出了最小报告清单，强调跨层设计和量化非性能权衡的机会，提供了包含代码、提示和冻结数据集的复制包。

Abstract: This study presents a systematic literature review of software-level
approaches to energy efficiency in robotics published from 2020 through 2024,
updating and extending pre-2020 evidence. An automated-but-audited pipeline
combined Google Scholar seeding, backward/forward snowballing, and
large-language-model (LLM) assistance for screening and data extraction, with
~10% human audits at each automated step and consensus-with-tie-breaks for
full-text decisions. The final corpus comprises 79 peer-reviewed studies
analyzed across application domain, metrics, evaluation type, energy models,
major energy consumers, software technique families, and energy-quality
trade-offs. Industrial settings dominate (31.6%) followed by exploration
(25.3%). Motors/actuators are identified as the primary consumer in 68.4% of
studies, with computing/controllers a distant second (13.9%). Simulation-only
evaluations remain most common (51.9%), though hybrid evaluations are frequent
(25.3%). Representational (physics-grounded) energy models predominate (87.3%).
Motion and trajectory optimization is the leading technique family (69.6%),
often paired with learning/prediction (40.5%) and computation
allocation/scheduling (26.6%); power management/idle control (11.4%) and
communication/data efficiency (3.8%) are comparatively underexplored. Reporting
is heterogeneous: composite objectives that include energy are most common,
while task-normalized and performance-per-energy metrics appear less often,
limiting cross-paper comparability. The review offers a minimal reporting
checklist (e.g., total energy and average power plus a task-normalized metric
and clear baselines) and highlights opportunities in cross-layer designs and in
quantifying non-performance trade-offs (accuracy, stability). A replication
package with code, prompts, and frozen datasets accompanies the review.

</details>


### [232] [Humanoid Motion Scripting with Postural Synergies](https://arxiv.org/abs/2508.12184)
*Rhea Malhotra,William Chong,Catie Cuan,Oussama Khatib*

Main category: cs.RO

TL;DR: SynSculptor是一个基于姿态协同的无训练人类运动生成框架，通过PCA提取主要运动模式，结合运动-语言变换器实现人形机器人的类人运动编辑和生成。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人运动生成中参考运动收集分析困难、新运动合成复杂以及运动映射到机器人的挑战。

Method: 收集3+小时运动捕捉数据，使用实时操作空间控制器在仿真机器人上模仿人类运动，通过PCA提取速度轨迹的主要姿态协同，构建风格条件协同库，结合运动-语言变换器进行运动适应。

Result: 开发了基于足部滑动比、总动量和动能偏差的运动平滑度评估指标，生成的运动与参考运动进行比较验证。

Conclusion: SynSculptor框架成功实现了基于姿态协同的无训练人类运动生成，为人形机器人的类人运动编辑提供了有效解决方案。

Abstract: Generating sequences of human-like motions for humanoid robots presents
challenges in collecting and analyzing reference human motions, synthesizing
new motions based on these reference motions, and mapping the generated motion
onto humanoid robots. To address these issues, we introduce SynSculptor, a
humanoid motion analysis and editing framework that leverages postural
synergies for training-free human-like motion scripting. To analyze human
motion, we collect 3+ hours of motion capture data across 20 individuals where
a real-time operational space controller mimics human motion on a simulated
humanoid robot. The major postural synergies are extracted using principal
component analysis (PCA) for velocity trajectories segmented by changes in
robot momentum, constructing a style-conditioned synergy library for free-space
motion generation. To evaluate generated motions using the synergy library, the
foot-sliding ratio and proposed metrics for motion smoothness involving total
momentum and kinetic energy deviations are computed for each generated motion,
and compared with reference motions. Finally, we leverage the synergies with a
motion-language transformer, where the humanoid, during execution of motion
tasks with its end-effectors, adapts its posture based on the chosen synergy.
Supplementary material, code, and videos are available at
https://rhea-mal.github.io/humanoidsynergies.io.

</details>


### [233] [Self-Guided Action Diffusion](https://arxiv.org/abs/2508.12189)
*Rhea Malhotra,Yuejiang Liu,Chelsea Finn*

Main category: cs.RO

TL;DR: 自我导向行为激测方法，通过在每个激测步骤基于前期决策导向建议分布，提高了双向解码的效率，在低计算成本下实现近优性能。


<details>
  <summary>Details</summary>
Motivation: 现有的双向解码方法虽然能够提高模型的一致性和反应性，但随着行为样本多样性的增加，计算成本迅速增长，导致推理效率低下。

Method: 提出自我导向行为激测方法，在每个激测步骤中，基于之前的决策来导向建议分布，从而减少计算开销。

Result: 在模拟任务中实现了近优性能，推理成本微乎其微。在样本预算紧张的情况下，在具有挑战性的动态任务上比现有方法成功率提高了70%。

Conclusion: 自我导向方法有效地解决了双向解码的计算效率问题，在保持性能的同时显著降低了推理成本，为激测基于的机器人策略提供了更高效的解决方案。

Abstract: Recent works have shown the promise of inference-time search over action
samples for improving generative robot policies. In particular, optimizing
cross-chunk coherence via bidirectional decoding has proven effective in
boosting the consistency and reactivity of diffusion policies. However, this
approach remains computationally expensive as the diversity of sampled actions
grows. In this paper, we introduce self-guided action diffusion, a more
efficient variant of bidirectional decoding tailored for diffusion-based
policies. At the core of our method is to guide the proposal distribution at
each diffusion step based on the prior decision. Experiments in simulation
tasks show that the proposed self-guidance enables near-optimal performance at
negligible inference cost. Notably, under a tight sampling budget, our method
achieves up to 70% higher success rates than existing counterparts on
challenging dynamic tasks. See project website at
https://rhea-mal.github.io/selfgad.github.io.

</details>


### [234] [Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search](https://arxiv.org/abs/2508.12211)
*Cyrus Neary,Omar G. Younis,Artur Kuramshin,Ozgur Aslan,Glen Berseth*

Main category: cs.RO

TL;DR: VLAPS是一个将基于模型的搜索嵌入预训练VLA模型推理过程的新框架，通过结合蒙特卡洛树搜索和环境模型，显著提升机器人在语言指定任务中的性能表现


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言-动作(VLA)模型在零样本部署到分布外场景时经常产生脆弱行为或不安全故障，需要改进其推理过程以提高鲁棒性和性能

Method: 提出VLAPS框架，将修改后的蒙特卡洛树搜索(MCTS)算法与VLA策略相结合，使用环境模型进行搜索，并利用VLA策略定义的动作先验来引导搜索过程

Result: 在所有实验中，VLAPS显著优于仅使用VLA的基线方法，在语言指定任务上的成功率最高提升了67个百分点

Conclusion: VLAPS提供了一个原则性框架，可以控制VLA模型的测试时计算、利用机器人环境的先验知识，并将成熟的规划和强化学习技术集成到VLA推理过程中

Abstract: Pre-trained vision-language-action (VLA) models offer a promising foundation
for generalist robot policies, but often produce brittle behaviours or unsafe
failures when deployed zero-shot in out-of-distribution scenarios. We present
Vision-Language-Action Planning & Search (VLAPS) -- a novel framework and
accompanying algorithms that embed model-based search into the inference
procedure of pre-trained VLA policies to improve their performance on robotic
tasks. Specifically, our method biases a modified Monte Carlo Tree Search
(MCTS) algorithm -- run using a model of the target environment -- using action
priors defined by the VLA policy. By using VLA-derived abstractions and priors
in model-based search, VLAPS efficiently explores language-conditioned robotics
tasks whose search spaces would otherwise be intractably large. Conversely, by
integrating model-based search with the VLA policy's inference procedure, VLAPS
yields behaviours that are more performant than those obtained by directly
following the VLA policy's action predictions. VLAPS offers a principled
framework to: i) control test-time compute in VLA models, ii) leverage a priori
knowledge of the robotic environment, and iii) integrate established planning
and reinforcement learning techniques into the VLA inference process. Across
all experiments, VLAPS significantly outperforms VLA-only baselines on
language-specified tasks that would otherwise be intractable for uninformed
search algorithms, increasing success rates by as much as 67 percentage points.

</details>


### [235] [Deformation of the panoramic sphere into an ellipsoid to induce self-motion in telepresence users](https://arxiv.org/abs/2508.12925)
*Eetu Laukka,Evan G. Center,Timo Ojala,Steven M. LaValle,Matti Pouke*

Main category: cs.RO

TL;DR: 通过光流创造自我运动幻觉来应对移动亲临机器人的高延迟问题，但在500ms延迟下未显著提升性能，反而可能增加VR舔逆感


<details>
  <summary>Details</summary>
Motivation: 解决使用360度摄像头的移动亲临机器人系统存在的高延迟问题，提升用户在延迟期间的控制体验

Method: 利用光流技术为用户创造自我运动的幻觉，在实际视频流到达前填补延迟期

Result: 在500ms延迟情况下，该方法对任务完成时间和碰撞数量没有显著改善，但可能会增加虚拟现实舔逆感

Conclusion: 该方法需要进一步调整和优化才能成为可行的解决方案

Abstract: Mobile telepresence robots allow users to feel present and explore remote
environments using technology. Traditionally, these systems are implemented
using a camera onboard a mobile robot that can be controlled. Although
high-immersion technologies, such as 360-degree cameras, can increase
situational awareness and presence, they also introduce significant challenges.
Additional processing and bandwidth requirements often result in latencies of
up to seconds. The current delay with a 360-degree camera streaming over the
internet makes real-time control of these systems difficult. Working with
high-latency systems requires some form of assistance to the users.
  This study presents a novel way to utilize optical flow to create an illusion
of self-motion to the user during the latency period between user sending
motion commands to the robot and seeing the actual motion through the
360-camera stream. We find no significant benefit of using the self-motion
illusion to performance or accuracy of controlling a telepresence robot with a
latency of 500 ms, as measured by the task completion time and collisions into
objects. Some evidence is shown that the method might increase virtual reality
(VR) sickness, as measured by the simulator sickness questionnaire (SSQ). We
conclude that further adjustments are necessary in order to render the method
viable.

</details>


### [236] [Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids](https://arxiv.org/abs/2508.12252)
*Kaizhe Hu,Haochen Shi,Yao He,Weizhuo Wang,C. Karen Liu,Shuran Song*

Main category: cs.RO

TL;DR: 提出了Robot-Trains-Robot (RTR)框架，通过机械臂教师主动指导人形机器人学生，实现高效的长时真实世界人形机器人训练，最小化人工干预


<details>
  <summary>Details</summary>
Motivation: 解决仿真到真实世界强化学习中的安全、奖励设计和学习效率等挑战，突破人形机器人直接进行真实世界RL训练的局限性

Method: RTR框架提供保护、学习调度、奖励、扰动、故障检测和自动重置功能；提出优化动态编码潜在变量的RL管道来促进和稳定仿真到真实的迁移

Result: 在两个具有挑战性的真实世界人形机器人任务中验证：精确速度跟踪的行走策略微调，以及从零开始学习人形摆动任务

Conclusion: RTR系统展示了实现真实世界人形机器人学习的有前景能力，为人形机器人的实际应用提供了新的训练范式

Abstract: Simulation-based reinforcement learning (RL) has significantly advanced
humanoid locomotion tasks, yet direct real-world RL from scratch or adapting
from pretrained policies remains rare, limiting the full potential of humanoid
robots. Real-world learning, despite being crucial for overcoming the
sim-to-real gap, faces substantial challenges related to safety, reward design,
and learning efficiency. To address these limitations, we propose
Robot-Trains-Robot (RTR), a novel framework where a robotic arm teacher
actively supports and guides a humanoid robot student. The RTR system provides
protection, learning schedule, reward, perturbation, failure detection, and
automatic resets. It enables efficient long-term real-world humanoid training
with minimal human intervention. Furthermore, we propose a novel RL pipeline
that facilitates and stabilizes sim-to-real transfer by optimizing a single
dynamics-encoded latent variable in the real world. We validate our method
through two challenging real-world humanoid tasks: fine-tuning a walking policy
for precise speed tracking and learning a humanoid swing-up task from scratch,
illustrating the promising capabilities of real-world humanoid learning
realized by RTR-style systems. See https://robot-trains-robot.github.io/ for
more info.

</details>


### [237] [Insights from Interviews with Teachers and Students on the Use of a Social Robot in Computer Science Class in Sixth Grade](https://arxiv.org/abs/2508.12946)
*Ann-Sophie Schenk,Stefan Schiffer,Heqiu Song*

Main category: cs.RO

TL;DR: 研究通过访谈探讨教师和学生对在六年级计算机科学课堂中使用社交机器人的需求和潜在应用，发现双方都持开放态度但需求存在差异，导致复杂的设计挑战。


<details>
  <summary>Details</summary>
Motivation: 了解教师和学习者对社交机器人在计算机科学课堂中的使用需求和应用潜力，特别关注两个群体对机器人应具备功能的看法。

Method: 通过对教师和学生进行访谈，收集关于社交机器人在六年级计算机科学课堂中使用需求和应用场景的第一手见解。

Result: 教师和学生都对在课堂中使用机器人持非常开放的态度，但两个群体的需求存在部分异质性。

Conclusion: 研究揭示了社交机器人在教育环境中应用的复杂性，不同用户群体的需求差异带来了设计挑战，需要在后续工作中进一步探讨解决方案。

Abstract: In this paper we report on first insights from interviews with teachers and
students on using social robots in computer science class in sixth grade. Our
focus is on learning about requirements and potential applications. We are
particularly interested in getting both perspectives, the teachers' and the
learners' view on how robots could be used and what features they should or
should not have. Results show that teachers as well as students are very open
to robots in the classroom. However, requirements are partially quite
heterogeneous among the groups. This leads to complex design challenges which
we discuss at the end of this paper.

</details>


### [238] [Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments](https://arxiv.org/abs/2508.12274)
*Jian Zhao,Yunlong Lian,Andy M Tyrrell,Michael Gienger,Jihong Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种适用于紧身衣物穿着的双手协作穿衣策略，通过建立球面坐标系并使用GMM/GMR进行模仿学习，解决了单手机器人无法完成紧身衣物穿着的问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器人辅助穿衣研究主要关注宽松衣物，对紧身衣物的研究较少。单手机器人由于袖窿较小和刚性减弱特性，往往无法成功完成紧身衣物的穿着任务。

Method: 建立穿衣球面坐标系，以方位角作为双手操作的任务相关特征，采用高斯混合模型(GMM)和高斯混合回归(GMR)进行双手穿衣轨迹的模仿学习。

Result: 通过多种实验验证了所提方法的有效性，能够生成适应不同人体手臂姿势的穿衣策略。

Conclusion: 提出的双手穿衣策略成功解决了紧身衣物穿着难题，为机器人辅助穿衣领域提供了新的解决方案。

Abstract: Robot-assisted dressing is a popular but challenging topic in the field of
robotic manipulation, offering significant potential to improve the quality of
life for individuals with mobility limitations. Currently, the majority of
research on robot-assisted dressing focuses on how to put on loose-fitting
clothing, with little attention paid to tight garments. For the former, since
the armscye is larger, a single robotic arm can usually complete the dressing
task successfully. However, for the latter, dressing with a single robotic arm
often fails due to the narrower armscye and the property of diminishing
rigidity in the armscye, which eventually causes the armscye to get stuck. This
paper proposes a bimanual dressing strategy suitable for dressing tight-fitting
clothing. To facilitate the encoding of dressing trajectories that adapt to
different human arm postures, a spherical coordinate system for dressing is
established. We uses the azimuthal angle of the spherical coordinate system as
a task-relevant feature for bimanual manipulation. Based on this new
coordinate, we employ Gaussian Mixture Model (GMM) and Gaussian Mixture
Regression (GMR) for imitation learning of bimanual dressing trajectories,
generating dressing strategies that adapt to different human arm postures. The
effectiveness of the proposed method is validated through various experiments.

</details>


### [239] [A robust and compliant robotic assembly control strategy for batch precision assembly task with uncertain fit types and fit amounts](https://arxiv.org/abs/2508.12296)
*Bin Wang,Jiwen Zhang,Song Wang,Dan Wu*

Main category: cs.RO

TL;DR: 提出了一种基于力-视觉融合控制器驱动的强化学习方法(FVFC-MTRL)和多任务强化学习训练方法，用于机器人批量精密装配任务中处理不确定配合类型和配合量的鲁棒控制策略构建。


<details>
  <summary>Details</summary>
Motivation: 在精密工业应用中，机器人执行批量精密装配任务时，由于加工误差导致销孔配合类型（间隙配合或过盈配合）和配合量存在不确定性，需要开发鲁棒的顺应控制策略。

Method: 将批量精密装配任务分解为多个确定性子任务，使用力-视觉融合控制器驱动的强化学习方法和多任务强化学习训练方法联合学习多个顺应控制策略，然后通过多教师策略蒸馏方法整合为统一的鲁棒控制策略。

Result: 实验证明该方法成功构建了适用于不同配合类型和配合量的鲁棒控制策略，多任务强化学习框架显著提高了训练效率，最终的控制策略在力顺应性和成功率方面优于现有方法。

Conclusion: 该方法有效解决了批量精密装配中配合不确定性的问题，通过多任务学习和策略蒸馏实现了高效、鲁棒的装配控制策略。

Abstract: In some high-precision industrial applications, robots are deployed to
perform precision assembly tasks on mass batches of manufactured pegs and
holes. If the peg and hole are designed with transition fit, machining errors
may lead to either a clearance or an interference fit for a specific pair of
components, with uncertain fit amounts. This paper focuses on the robotic batch
precision assembly task involving components with uncertain fit types and fit
amounts, and proposes an efficient methodology to construct the robust and
compliant assembly control strategy. Specifically, the batch precision assembly
task is decomposed into multiple deterministic subtasks, and a force-vision
fusion controller-driven reinforcement learning method and a multi-task
reinforcement learning training method (FVFC-MTRL) are proposed to jointly
learn multiple compliance control strategies for these subtasks. Subsequently,
the multi-teacher policy distillation approach is designed to integrate
multiple trained strategies into a unified student network, thereby
establishing a robust control strategy. Real-world experiments demonstrate that
the proposed method successfully constructs the robust control strategy for
high-precision assembly task with different fit types and fit amounts.
Moreover, the MTRL framework significantly improves training efficiency, and
the final developed control strategy achieves superior force compliance and
higher success rate compared with many existing methods.

</details>


### [240] [Implementation and evaluation of a prediction algorithm for an autonomous vehicle](https://arxiv.org/abs/2508.12312)
*Marco Leon Rapp*

Main category: cs.RO

TL;DR: 提出了一种用于自动驾驶车辆的轨迹预测算法，使用动态自行车模型，通过扩展卡尔曼滤波器实现，每5毫秒预测一次轨迹，精度比运动学模型高82.6%。


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶车辆开发高精度的实时轨迹预测算法，解决在高速情况下运动学模型精度不足的问题。

Method: 比较运动学和动态自行车模型，通过实验确定车辆参数（质量、重心、转动惯量、侧偏刚度），引入光学位置跟踪测量侧偏刚度的新方法，将动态模型集成到扩展卡尔曼滤波器中，并用C++在ROS节点中实现。

Result: 动态模型在高速时表现出更高的精度，整个测试过程中位置偏差仅为每米1.25厘米，比运动学模型精确82.6%。

Conclusion: 动态自行车模型结合扩展卡尔曼滤波器能够为自动驾驶车辆提供高精度的实时轨迹预测，特别是在高速行驶条件下。

Abstract: This paper presents a prediction algorithm that estimates the vehicle
trajectory every five milliseconds for an autonomous vehicle. A kinematic and a
dynamic bicycle model are compared, with the dynamic model exhibiting superior
accuracy at higher speeds. Vehicle parameters such as mass, center of gravity,
moment of inertia, and cornering stiffness are determined experimentally. For
cornering stiffness, a novel measurement procedure using optical position
tracking is introduced. The model is incorporated into an extended Kalman
filter and implemented in a ROS node in C++. The algorithm achieves a
positional deviation of only 1.25 cm per meter over the entire test drive and
is up to 82.6% more precise than the kinematic model.

</details>


### [241] [Semi-Infinite Programming for Collision-Avoidance in Optimal and Model Predictive Control](https://arxiv.org/abs/2508.12335)
*Yunfan Gao,Florian Messerer,Niels van Duijkeren,Rashmi Dabir,Moritz Diehl*

Main category: cs.RO

TL;DR: 提出了一种基于半无限规划的最优控制和模型预测控制碰撞避免方法，通过局部约简和外部主动集方法处理无限约束，支持鲁棒碰撞避免和3D应用


<details>
  <summary>Details</summary>
Motivation: 解决在最优控制和模型预测控制中处理大量环境点与机器人多边形表示之间的碰撞避免问题，传统方法难以高效处理无限约束条件

Method: 将环境表示为大量点，机器人表示为填充多边形的并集，通过局部约简和外部主动集方法迭代识别最近点障碍物，确定距离最小化器，求解有限约束子问题

Result: 实现了20Hz实时运行的控制器，能够在狭窄空间中实现快速无碰撞导航，并在仿真中展示了3D碰撞避免应用

Conclusion: 该方法有效解决了半无限规划最优控制问题，为机器人导航提供了高效的碰撞避免解决方案，支持不确定性和3D场景

Abstract: This paper presents a novel approach for collision avoidance in optimal and
model predictive control, in which the environment is represented by a large
number of points and the robot as a union of padded polygons. The conditions
that none of the points shall collide with the robot can be written in terms of
an infinite number of constraints per obstacle point. We show that the
resulting semi-infinite programming (SIP) optimal control problem (OCP) can be
efficiently tackled through a combination of two methods: local reduction and
an external active-set method. Specifically, this involves iteratively
identifying the closest point obstacles, determining the lower-level distance
minimizer among all feasible robot shape parameters, and solving the
upper-level finitely-constrained subproblems.
  In addition, this paper addresses robust collision avoidance in the presence
of ellipsoidal state uncertainties. Enforcing constraint satisfaction over all
possible uncertainty realizations extends the dimension of constraint
infiniteness. The infinitely many constraints arising from translational
uncertainty are handled by local reduction together with the robot shape
parameterization, while rotational uncertainty is addressed via a backoff
reformulation.
  A controller implemented based on the proposed method is demonstrated on a
real-world robot running at 20Hz, enabling fast and collision-free navigation
in tight spaces. An application to 3D collision avoidance is also demonstrated
in simulation.

</details>


### [242] [PUB: A Plasma-Propelled Ultra-Quiet Blimp with Two-DOF Vector Thrusting](https://arxiv.org/abs/2508.12395)
*Zihan Wang*

Main category: cs.RO

TL;DR: 等离子推进超静音飞艇(PUB)采用等离子矢量推进技术实现无机械螺旋桨的超静音飞行，通过氦气升力平台和四层环状不对称电容器产生离子风推力，具备全包线飞行能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种无机械噪音、结构简单且高机动性的空中机器人，适用于噪音敏感、封闭和近空间应用场景。

Method: 使用氦气升力平台提供持久续航，四层环状不对称电容器产生离子风推力，模块化推进单元可灵活配置，二自由度头部实现推力矢量控制，采用闭环滑移控制方案保证稳定机动。

Result: 飞行实验验证了包括起飞、爬升、悬停、下降和平稳着陆在内的全包线飞行能力，证明了等离子矢量推进的可行性、自由度矢量控制的有效性和控制系统的稳定性。

Conclusion: PUB凭借其低声学特征、结构简单性和高机动性，非常适合噪音敏感、封闭和近空间应用。

Abstract: This study presents the design and control of a Plasma-propelled
Ultra-silence Blimp (PUB), a novel aerial robot employing plasma vector
propulsion for ultra-quiet flight without mechanical propellers. The system
utilizes a helium-lift platform for extended endurance and a four-layer ring
asymmetric capacitor to generate ionic wind thrust. The modular propulsion
units allow flexible configuration to meet mission-specific requirements, while
a two-degree-of-freedom (DOF) head enables thrust vector control. A closed-loop
slip control scheme is implemented for stable maneuvering. Flight experiments
demonstrate full-envelope capability, including take-off, climb, hover,
descent, and smooth landing, confirming the feasibility of plasma vector
propulsion, the effectiveness of DOF vector control, and the stability of the
control system. Owing to its low acoustic signature, structural simplicity, and
high maneuverability, PUB is well suited for noise-sensitive, enclosed, and
near-space applications.

</details>


### [243] [SIGN: Safety-Aware Image-Goal Navigation for Autonomous Drones via Reinforcement Learning](https://arxiv.org/abs/2508.12394)
*Zichen Yan,Rui Huang,Lei He,Shao Guo,Lin Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于视觉强化学习的无人机图像目标导航框架，通过辅助任务增强视觉表示能力，实现端到端的速度控制导航，无需外部定位，并集成了深度安全模块进行实时避障。


<details>
  <summary>Details</summary>
Motivation: 现有图像目标导航研究主要针对地面机器人，无人机导航面临高频率反馈控制和全局定位的挑战，需要开发新的sim-to-real框架来解决这些问题。

Method: 使用视觉强化学习训练策略，通过图像扰动和未来转移预测等辅助任务增强视觉骨干网络，采用端到端速度控制，集成深度安全模块进行实时避障。

Result: 实现了无人机的自主探索、避障和图像目标寻找等综合导航行为，无需显式全局建图，能够安全地在杂乱环境中导航。

Conclusion: 该框架成功解决了无人机图像目标导航的挑战，提供了一个完整的sim-to-real解决方案，支持多种导航行为，具有实际应用价值。

Abstract: Image-goal navigation (ImageNav) tasks a robot with autonomously exploring an
unknown environment and reaching a location that visually matches a given
target image. While prior works primarily study ImageNav for ground robots,
enabling this capability for autonomous drones is substantially more
challenging due to their need for high-frequency feedback control and global
localization for stable flight. In this paper, we propose a novel sim-to-real
framework that leverages visual reinforcement learning (RL) to achieve ImageNav
for drones. To enhance visual representation ability, our approach trains the
vision backbone with auxiliary tasks, including image perturbations and future
transition prediction, which results in more effective policy training. The
proposed algorithm enables end-to-end ImageNav with direct velocity control,
eliminating the need for external localization. Furthermore, we integrate a
depth-based safety module for real-time obstacle avoidance, allowing the drone
to safely navigate in cluttered environments. Unlike most existing drone
navigation methods that focus solely on reference tracking or obstacle
avoidance, our framework supports comprehensive navigation
behaviors--autonomous exploration, obstacle avoidance, and image-goal
seeking--without requiring explicit global mapping. Code and model checkpoints
will be released upon acceptance.

</details>


### [244] [MCTR: Midpoint Corrected Triangulation for Autonomous Racing via Digital Twin Simulation in CARLA](https://arxiv.org/abs/2508.12729)
*Junhao Ye,Cheng Hu,Yiqin Wang,Weizhan Huang,Nicolas Baumann,Jie He,Meixun Qu,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: 提出了MCTR算法，通过曲率校正移动平均提高轨迹平滑度，并在CARLA模拟器中实现数字孪生系统来验证3D LiDAR感知下的算法鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有DTR算法使用外接圆进行轨迹生成导致路径不够平滑，性能下降；F1TENTH模拟器缺乏3D LiDAR感知支持，限制了真实测试效果

Method: 基于Curvature Corrected Moving Average改进轨迹平滑度，在CARLA模拟器中构建数字孪生系统进行3D LiDAR感知验证

Result: 算法在仿真和真实车辆实验中得到了充分验证

Conclusion: MCTR算法有效解决了轨迹平滑度和3D LiDAR感知验证的问题，提升了自动驾驶赛车性能

Abstract: In autonomous racing, reactive controllers eliminate the computational burden
of the full See-Think-Act autonomy stack by directly mapping sensor inputs to
control actions. This bypasses the need for explicit localization and
trajectory planning. A widely adopted baseline in this category is the
Follow-The-Gap method, which performs trajectory planning using LiDAR data.
Building on FTG, the Delaunay Triangulation-based Racing algorithm introduces
further enhancements. However, DTR's use of circumcircles for trajectory
generation often results in insufficiently smooth paths, ultimately degrading
performance. Additionally, the commonly used F1TENTH-simulator for autonomous
racing competitions lacks support for 3D LiDAR perception, limiting its
effectiveness in realistic testing. To address these challenges, this work
proposes the MCTR algorithm. MCTR improves trajectory smoothness through the
use of Curvature Corrected Moving Average and implements a digital twin system
within the CARLA simulator to validate the algorithm's robustness under 3D
LiDAR perception. The proposed algorithm has been thoroughly validated through
both simulation and real-world vehicle experiments.

</details>


### [245] [Tactile Gesture Recognition with Built-in Joint Sensors for Industrial Robots](https://arxiv.org/abs/2508.12435)
*Deqing Song,Weimin Yang,Maryam Rezayati,Hans Wernher van de Venn*

Main category: cs.RO

TL;DR: 本文探索仅使用机器人内置关节传感器的深度学习手势识别方法，无需外部传感器，通过评估不同CNN架构和数据集，发现基于频谱图的数据表示显著提高准确率，在Franka Emika机器人上实现了超过95%的接触检测和手势分类准确率。


<details>
  <summary>Details</summary>
Motivation: 在人类机器人协作(HRC)领域，虽然基于视觉或机器人皮肤的手势识别是活跃研究方向，但本研究旨在探索仅利用机器人内置关节传感器的深度学习方法，消除对外部传感器的需求，以开发更经济、可扩展的HRC解决方案。

Method: 评估了多种卷积神经网络(CNN)架构，收集了两个数据集研究数据表示和模型架构对识别准确率的影响，特别比较了基于频谱图的表示方法，并在Franka Emika Research机器人上实现了STFT2DCNN和STT3DCNN两种方法。

Result: 频谱图表示显著提高了识别准确率，而模型架构的影响较小；在测试对新机器人姿态的泛化能力时，基于频谱图的模型表现更好；两种方法在接触检测和手势分类上都达到了超过95%的准确率。

Conclusion: 研究证明了无需外部传感器的触觉识别的可行性，推动了向成本效益高、可扩展的HRC解决方案的进一步研究，频谱图表示在基于关节传感器的手势识别中具有重要价值。

Abstract: While gesture recognition using vision or robot skins is an active research
area in Human-Robot Collaboration (HRC), this paper explores deep learning
methods relying solely on a robot's built-in joint sensors, eliminating the
need for external sensors. We evaluated various convolutional neural network
(CNN) architectures and collected two datasets to study the impact of data
representation and model architecture on the recognition accuracy. Our results
show that spectrogram-based representations significantly improve accuracy,
while model architecture plays a smaller role. We also tested generalization to
new robot poses, where spectrogram-based models performed better. Implemented
on a Franka Emika Research robot, two of our methods, STFT2DCNN and STT3DCNN,
achieved over 95% accuracy in contact detection and gesture classification.
These findings demonstrate the feasibility of external-sensor-free tactile
recognition and promote further research toward cost-effective, scalable
solutions for HRC.

</details>


### [246] [Manipulate-to-Navigate: Reinforcement Learning with Visual Affordances and Manipulability Priors](https://arxiv.org/abs/2508.13151)
*Yuying Zhang,Joni Pajarinen*

Main category: cs.RO

TL;DR: 提出基于强化学习的方法解决移动机器人在动态环境中的'操纵导航'问题，通过结合可操纵性先验和可供性地图来选择有效的操纵动作，为后续导航清理障碍


<details>
  <summary>Details</summary>
Motivation: 传统方法将导航和操纵作为独立任务处理，在需要先清除障碍物才能导航的动态环境中经常失败，需要主动与环境交互来清理移动路径

Method: 结合可操纵性先验（关注高可操纵性的身体位置）和可供性地图（选择高质量操纵动作），使用强化学习学习促进后续导航的操纵策略

Result: 在两个新的操纵导航仿真任务（Reach和Door）中表现有效，成功将学习策略迁移到真实Boston Dynamics Spot机器人上执行Reach任务

Conclusion: 该方法使机器人能够有效与动态环境交互并穿越，通过关注可行且有意义的动作减少不必要的探索，提高学习效率

Abstract: Mobile manipulation in dynamic environments is challenging due to movable
obstacles blocking the robot's path. Traditional methods, which treat
navigation and manipulation as separate tasks, often fail in such
'manipulate-to-navigate' scenarios, as obstacles must be removed before
navigation. In these cases, active interaction with the environment is required
to clear obstacles while ensuring sufficient space for movement. To address the
manipulate-to-navigate problem, we propose a reinforcement learning-based
approach for learning manipulation actions that facilitate subsequent
navigation. Our method combines manipulability priors to focus the robot on
high manipulability body positions with affordance maps for selecting
high-quality manipulation actions. By focusing on feasible and meaningful
actions, our approach reduces unnecessary exploration and allows the robot to
learn manipulation strategies more effectively. We present two new
manipulate-to-navigate simulation tasks called Reach and Door with the Boston
Dynamics Spot robot. The first task tests whether the robot can select a good
hand position in the target area such that the robot base can move effectively
forward while keeping the end effector position fixed. The second task requires
the robot to move a door aside in order to clear the navigation path. Both of
these tasks need first manipulation and then navigating the base forward.
Results show that our method allows a robot to effectively interact with and
traverse dynamic environments. Finally, we transfer the learned policy to a
real Boston Dynamics Spot robot, which successfully performs the Reach task.

</details>


### [247] [Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation](https://arxiv.org/abs/2508.12439)
*Sunyu Wang,Arjun S. Lakshmipathy,Jean Oh,Nancy S. Pollard*

Main category: cs.RO

TL;DR: 本文提出了一种基于测地线追踪的积分方案，用于在网格上直接进行滚滑接触的一阶时间积分，扩展了滚滑接触建模到流形网格，实现了对物体真实几何的高保真离散表示的灵巧操作推理。


<details>
  <summary>Details</summary>
Motivation: 现有的滚滑接触研究主要关注具有可微分参数化的连续形状，而本文旨在将滚滑接触建模扩展到流形网格，使灵巧操作能够基于物体真实几何的高保真离散表示进行推理。

Method: 提出基于测地线追踪的积分方案，在网格上直接进行滚滑接触的一阶时间积分；使用最小二乘优化器规划多指机器人手的灵巧运动，通过最小化接触滑动和旋转来维持最稳定的瞬时抓取。

Result: 在仿真中对五个物体进行灵巧操作规划，与基于碰撞检测和基于原始形状的基线方法相比，本文方法在准确性和精度方面表现最佳，即使在粗糙网格上也是如此。

Conclusion: 该方法为网格表面接触建模提供了准确和精确的解决方案，未来工作将考虑整合多个接触和接触力，以实现更准确和鲁棒的网格表面接触建模。

Abstract: Reasoning about rolling and sliding contact, or roll-slide contact for short,
is critical for dexterous manipulation tasks that involve intricate geometries.
But existing works on roll-slide contact mostly focus on continuous shapes with
differentiable parametrizations. This work extends roll-slide contact modeling
to manifold meshes. Specifically, we present an integration scheme based on
geodesic tracing to first-order time-integrate roll-slide contact directly on
meshes, enabling dexterous manipulation to reason over high-fidelity discrete
representations of an object's true geometry. Using our method, we planned
dexterous motions of a multi-finger robotic hand manipulating five objects
in-hand in simulation. The planning was achieved with a least-squares optimizer
that strives to maintain the most stable instantaneous grasp by minimizing
contact sliding and spinning. Then, we evaluated our method against a baseline
using collision detection and a baseline using primitive shapes. The results
show that our method performed the best in accuracy and precision, even for
coarse meshes. We conclude with a future work discussion on incorporating
multiple contacts and contact forces to achieve accurate and robust mesh-based
surface contact modeling.

</details>


### [248] [Autonomous Oil Spill Response Through Liquid Neural Trajectory Modeling and Coordinated Marine Robotics](https://arxiv.org/abs/2508.12456)
*Hadas C. Kuzmenko,David Ehevich,Oren Gal*

Main category: cs.RO

TL;DR: 这项研究提出了一种结合多自主港海机器人群与液体时间常数神经网络的集成框架，用于油漆澄渊的实时预测和动态响应，在Deepwater Horizon漆潮中达到了23%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 海洋油漆澄渊造成严重环境和经济风险，需要准确的实时轨迹预测和协调减少影响，但因风、流、温度等多因素交互而极其复杂。

Method: 采用MOOS-IvP平台的多自主机器人群系统结合Liquid Time-Constant神经网络(LTCNs)，将适应性机器学习与自主海洋机器人技术融合，实现实时预测、动态跟踪和快速响应。

Result: 在Deepwater Horizon漆潮数据验证中，LTC-RK4模型达到了0.96的空间准确度，超过LSTM方法23%，显著提升了预测精度、灵活性和操作可扩展性。

Conclusion: 这项研究通过先进神经建模与自主协调机器人技术的结合，大大提高了油漆澄渊管理的预测准确性和响应协调能力，推动了可持续自主油漆管理和环境保护技术的发展。

Abstract: Marine oil spills pose grave environmental and economic risks, threatening
marine ecosystems, coastlines, and dependent industries. Predicting and
managing oil spill trajectories is highly complex, due to the interplay of
physical, chemical, and environmental factors such as wind, currents, and
temperature, which makes timely and effective response challenging. Accurate
real-time trajectory forecasting and coordinated mitigation are vital for
minimizing the impact of these disasters. This study introduces an integrated
framework combining a multi-agent swarm robotics system built on the MOOS-IvP
platform with Liquid Time-Constant Neural Networks (LTCNs). The proposed system
fuses adaptive machine learning with autonomous marine robotics, enabling
real-time prediction, dynamic tracking, and rapid response to evolving oil
spills. By leveraging LTCNs--well-suited for modeling complex, time-dependent
processes--the framework achieves real-time, high-accuracy forecasts of spill
movement. Swarm intelligence enables decentralized, scalable, and resilient
decision-making among robot agents, enhancing collective monitoring and
containment efforts. Our approach was validated using data from the Deepwater
Horizon spill, where the LTC-RK4 model achieved 0.96 spatial accuracy,
surpassing LSTM approaches by 23%. The integration of advanced neural modeling
with autonomous, coordinated robotics demonstrates substantial improvements in
prediction precision, flexibility, and operational scalability. Ultimately,
this research advances the state-of-the-art for sustainable, autonomous oil
spill management and environmental protection by enhancing both trajectory
prediction and response coordination.

</details>


### [249] [Mechanical Automation with Vision: A Design for Rubik's Cube Solver](https://arxiv.org/abs/2508.12469)
*Abhinav Chalise,Nimesh Gopal Pradhan,Nishan Khanal,Prashant Raj Bista,Dinesh Baniya Kshatri*

Main category: cs.RO

TL;DR: 开发了一个基于三台步进电机、微控制器和YOLO检测模型的魔方自动求解系统，通过Kociemba算法求解，平均求解时间约2.2分钟


<details>
  <summary>Details</summary>
Motivation: 构建一个能够自动检测和求解魔方的完整系统，结合硬件控制和软件界面，实现高效的魔方求解自动化

Method: 使用三个步进电机进行物理操作，微控制器控制硬件，YOLOv8模型实时检测魔方状态，Unity开发GUI界面，采用Kociemba算法生成求解步骤

Result: YOLOv8模型达到高精度检测（精度0.98443，召回率0.98419），系统平均求解时间约为2.2分钟

Conclusion: 成功开发了一个集成了硬件控制、实时视觉检测和算法求解的完整魔方自动求解系统，实现了较好的性能和用户体验

Abstract: The core mechanical system is built around three stepper motors for physical
manipulation, a microcontroller for hardware control, a camera and YOLO
detection model for real-time cube state detection. A significant software
component is the development of a user-friendly graphical user interface (GUI)
designed in Unity. The initial state after detection from real-time YOLOv8
model (Precision 0.98443, Recall 0.98419, Box Loss 0.42051, Class Loss 0.2611)
is virtualized on GUI. To get the solution, the system employs the Kociemba's
algorithm while physical manipulation with a single degree of freedom is done
by combination of stepper motors' interaction with the cube achieving the
average solving time of ~2.2 minutes.

</details>


### [250] [PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions](https://arxiv.org/abs/2508.12554)
*Hamza El-Kebir*

Main category: cs.RO

TL;DR: PROD是一种通过触觉交互重建可变形物体形状和力学特性的新方法，使用弹性静力学SDF从力和位姿测量中恢复未变形形状和材料刚度


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖纯几何或视觉数据，无法准确估计软材料的静态和动态响应，需要整合触觉交互信息来改进可变形物体重建

Method: 将物体变形建模为弹性静力学过程，推导控制泊松方程，从稀疏的位姿和力测量中估计SDF，结合稳态弹性动力学假设恢复未变形SDF

Result: PROD能够处理位姿误差、非垂直力施加和曲率误差，在模拟软体交互中表现出鲁棒性，可准确估计材料刚度

Conclusion: 该方法为机器人操作、医学成像和触觉反馈系统等应用中的可变形物体重建提供了强大工具

Abstract: We introduce PROD (Palpative Reconstruction of Deformables), a novel method
for reconstructing the shape and mechanical properties of deformable objects
using elastostatic signed distance functions (SDFs). Unlike traditional
approaches that rely on purely geometric or visual data, PROD integrates
palpative interaction -- measured through force-controlled surface probing --
to estimate both the static and dynamic response of soft materials. We model
the deformation of an object as an elastostatic process and derive a governing
Poisson equation for estimating its SDF from a sparse set of pose and force
measurements. By incorporating steady-state elastodynamic assumptions, we show
that the undeformed SDF can be recovered from deformed observations with
provable convergence. Our approach also enables the estimation of material
stiffness by analyzing displacement responses to varying force inputs. We
demonstrate the robustness of PROD in handling pose errors, non-normal force
application, and curvature errors in simulated soft body interactions. These
capabilities make PROD a powerful tool for reconstructing deformable objects in
applications ranging from robotic manipulation to medical imaging and haptic
feedback systems.

</details>


### [251] [Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems](https://arxiv.org/abs/2508.12564)
*Jiayao Mai,Xiuyuan Lu,Kuan Dai,Shaojie Shen,Yi Zhou*

Main category: cs.RO

TL;DR: 提出了一种基于运动的时空标定框架，用于事件相机多传感器系统，无需专用标定目标，通过角速度估计和两步优化实现高精度标定


<details>
  <summary>Details</summary>
Motivation: 事件相机具有微秒级延迟特性，但与其他传感器的外参标定研究不足，需要一种无需标定目标的灵活标定方法

Method: 使用事件相机和其他传感器的旋转运动估计，通过法向流观测估计角速度，采用CCA初始化时间偏移和旋转外参，然后通过SO(3)连续时间参数化进行联合非线性优化

Result: 在公开和自采集数据集上的广泛评估显示，该方法达到与基于目标方法相当的标定精度，比纯CCA方法更稳定，具有高精度、鲁棒性和灵活性

Conclusion: 提出的运动基时空标定框架有效解决了事件相机多传感器系统的标定问题，无需标定目标，性能优异，代码已开源

Abstract: Event cameras generate asynchronous signals in response to pixel-level
brightness changes, offering a sensing paradigm with theoretically
microsecond-scale latency that can significantly enhance the performance of
multi-sensor systems. Extrinsic calibration is a critical prerequisite for
effective sensor fusion; however, the configuration that involves event cameras
remains an understudied topic. In this paper, we propose a motion-based
temporal and rotational calibration framework tailored for event-centric
multi-sensor systems, eliminating the need for dedicated calibration targets.
Our method uses as input the rotational motion estimates obtained from event
cameras and other heterogeneous sensors, respectively. Different from
conventional approaches that rely on event-to-frame conversion, our method
efficiently estimates angular velocity from normal flow observations, which are
derived from the spatio-temporal profile of event data. The overall calibration
pipeline adopts a two-step approach: it first initializes the temporal offset
and rotational extrinsics by exploiting kinematic correlations in the spirit of
Canonical Correlation Analysis (CCA), and then refines both temporal and
rotational parameters through a joint non-linear optimization using a
continuous-time parametrization in SO(3). Extensive evaluations on both
publicly available and self-collected datasets validate that the proposed
method achieves calibration accuracy comparable to target-based methods, while
exhibiting superior stability over purely CCA-based methods, and highlighting
its precision, robustness and flexibility. To facilitate future research, our
implementation will be made open-source. Code:
https://github.com/NAIL-HNU/EvMultiCalib.

</details>


### [252] [Adaptive Model-Predictive Control of a Soft Continuum Robot Using a Physics-Informed Neural Network Based on Cosserat Rod Theory](https://arxiv.org/abs/2508.12681)
*Johann Licher,Max Bartholdt,Henrik Krauss,Tim-Lukas Habich,Thomas Seel,Moritz Schappler*

Main category: cs.RO

TL;DR: 基于域解耦物理信息神经网络(DD-PINN)的实时非线性模型预测控制框架，对软连续体机器人实现了高精度动态跟踪控制，计算速度提升44000倍


<details>
  <summary>Details</summary>
Motivation: 软连续体机器人的动态控制具有广阔应用前景，但准确动态模型的高计算要求以及现有数据驱动方法缺乏适应性和完整形状描述能力，限制了其应用

Method: 提出基于域解耦物理信息神经网络(DD-PINN)的方法，作为动态Cosserat杆模型的代理模型，并在无味Kalman滤波器中用于估计模型状态和弯曲顺度，实现70Hz频率的非线性进化模型预测控制

Result: 在仿真中实现了精确的动态轨迹跟踪，端效器位置误差低于3mm(2.3%活动长度)；在实际实验中达到相似精度，加速度达到3.55m/s²

Conclusion: 该框架为软连续体机器人提供了一种高效、实时的动态控制方案，解决了传统模型计算复杂性高和现有方法适应性不足的问题，在伪真和实际环境中都表现出良好的控制效果

Abstract: Dynamic control of soft continuum robots (SCRs) holds great potential for
expanding their applications, but remains a challenging problem due to the high
computational demands of accurate dynamic models. While data-driven approaches
like Koopman-operator-based methods have been proposed, they typically lack
adaptability and cannot capture the full robot shape, limiting their
applicability. This work introduces a real-time-capable nonlinear
model-predictive control (MPC) framework for SCRs based on a domain-decoupled
physics-informed neural network (DD-PINN) with adaptable bending stiffness. The
DD-PINN serves as a surrogate for the dynamic Cosserat rod model with a
speed-up factor of 44000. It is also used within an unscented Kalman filter for
estimating the model states and bending compliance from end-effector position
measurements. We implement a nonlinear evolutionary MPC running at 70 Hz on the
GPU. In simulation, it demonstrates accurate tracking of dynamic trajectories
and setpoint control with end-effector position errors below 3 mm (2.3% of the
actuator's length). In real-world experiments, the controller achieves similar
accuracy and accelerations up to 3.55 m/s2.

</details>


### [253] [RoboRetriever: Single-Camera Robot Object Retrieval via Active and Interactive Perception with Dynamic Scene Graph](https://arxiv.org/abs/2508.12916)
*Hecheng Wang,Jiankun Ren,Jia Yu,Lizhe Qi,Yunquan Sun*

Main category: cs.RO

TL;DR: RoboRetriever是一个使用单个腕戴式RGB-D相机和自然语言指令进行物体检索的机器人框架，通过动态层次场景图和主动感知实现复杂环境中的物体定位


<details>
  <summary>Details</summary>
Motivation: 人类能够轻松在杂乱、部分可见环境中检索物体，而现有机器人系统依赖多摄像头设置，成本高且适应性差，需要开发单摄像头解决方案

Method: 构建动态层次场景图编码物体语义、几何和关系；监督模块推理任务指令；集成主动感知、交互感知和操作；使用视觉提示方案确定6-DoF相机位姿

Result: 在多样化真实世界物体检索任务中表现出色，包括有人干预的场景，在杂乱环境中仅使用一个RGB-D相机就展现出强大的适应性和鲁棒性

Conclusion: RoboRetriever框架证明了使用单个腕戴相机即可实现复杂环境中的物体检索，为低成本、高适应性机器人系统提供了可行方案

Abstract: Humans effortlessly retrieve objects in cluttered, partially observable
environments by combining visual reasoning, active viewpoint adjustment, and
physical interaction-with only a single pair of eyes. In contrast, most
existing robotic systems rely on carefully positioned fixed or multi-camera
setups with complete scene visibility, which limits adaptability and incurs
high hardware costs. We present \textbf{RoboRetriever}, a novel framework for
real-world object retrieval that operates using only a \textbf{single}
wrist-mounted RGB-D camera and free-form natural language instructions.
RoboRetriever grounds visual observations to build and update a \textbf{dynamic
hierarchical scene graph} that encodes object semantics, geometry, and
inter-object relations over time. The supervisor module reasons over this
memory and task instruction to infer the target object and coordinate an
integrated action module combining \textbf{active perception},
\textbf{interactive perception}, and \textbf{manipulation}. To enable
task-aware scene-grounded active perception, we introduce a novel visual
prompting scheme that leverages large reasoning vision-language models to
determine 6-DoF camera poses aligned with the semantic task goal and geometry
scene context. We evaluate RoboRetriever on diverse real-world object retrieval
tasks, including scenarios with human intervention, demonstrating strong
adaptability and robustness in cluttered scenes with only one RGB-D camera.

</details>


### [254] [Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion](https://arxiv.org/abs/2508.12928)
*Victor Dhédin,Haizhou Zhao,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出基于MCTS和全身轨迹优化的完整流程，用于在复杂环境中同时进行接触序列和接触面选择，能够快速找到多样化动态一致的运动规划，并成功转移到真实四足机器人上。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人需要在高度受限环境中进行敏捷运动，但规划这类运动需要解决包含连续和离散决策变量的复杂优化问题，现有方法难以有效处理。

Method: 使用蒙特卡洛树搜索(MCTS)和全身轨迹优化(TO)相结合的方法，同时优化接触序列和接触面选择，处理复杂的多接触运动规划问题。

Result: 通过大量仿真实验证明，该框架能够快速找到多样化的动态一致运动规划，成功转移到真实四足机器人上，并能处理高度复杂的非周期性人形机器人运动。

Conclusion: 这是首个使用四足机器人全身动力学同时进行接触序列和接触面选择的非周期性多接触运动规划演示，为解决复杂环境中的腿式机器人运动规划提供了有效解决方案。

Abstract: Legged robots have the potential to traverse highly constrained environments
with agile maneuvers. However, planning such motions requires solving a highly
challenging optimization problem with a mixture of continuous and discrete
decision variables. In this paper, we present a full pipeline based on
Monte-Carlo tree search (MCTS) and whole-body trajectory optimization (TO) to
perform simultaneous contact sequence and patch selection on highly challenging
environments. Through extensive simulation experiments, we show that our
framework can quickly find a diverse set of dynamically consistent plans. We
experimentally show that these plans are transferable to a real quadruped
robot. We further show that the same framework can find highly complex acyclic
humanoid maneuvers. To the best of our knowledge, this is the first
demonstration of simultaneous contact sequence and patch selection for acyclic
multi-contact locomotion using the whole-body dynamics of a quadruped.

</details>


### [255] [Scaling Whole-body Multi-contact Manipulation with Contact Optimization](https://arxiv.org/abs/2508.12980)
*Victor Levé,João Moura,Sachiya Fujita,Tamon Miyake,Steve Tonneau,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 通过提出新的表面表示方法和成本设计，实现了人形机器人全身操纵规划的高效优化，规划时间提升77%，解决了现有方法无法处理的问题


<details>
  <summary>Details</summary>
Motivation: 日常任务需要使用全身操纵物体，但现有的人形机器人规划方法主要依赖离散采样，在处理连续接触表面时缺乏可扩展性

Method: 提出(i)能够进行闭式计算近似点的机器人和物体表面表示方法，(ii)有效指导全身操纵规划的成本设计

Result: 规划时间比现有最佳方法提升77%，能解决现有方法无法处理的问题，并在真实硬件上通过人形机器人操纵箱子进行了验证

Conclusion: 该框架通过连续表面表示和梯度优化方法，有效解决了全身操纵规划中的可扩展性问题，为人形机器人自主操作提供了新的解决方案

Abstract: Daily tasks require us to use our whole body to manipulate objects, for
instance when our hands are unavailable. We consider the issue of providing
humanoid robots with the ability to autonomously perform similar whole-body
manipulation tasks. In this context, the infinite possibilities for where and
how contact can occur on the robot and object surfaces hinder the scalability
of existing planning methods, which predominantly rely on discrete sampling.
Given the continuous nature of contact surfaces, gradient-based optimization
offers a more suitable approach for finding solutions. However, a key remaining
challenge is the lack of an efficient representation of robot surfaces. In this
work, we propose (i) a representation of robot and object surfaces that enables
closed-form computation of proximity points, and (ii) a cost design that
effectively guides whole-body manipulation planning. Our experiments
demonstrate that the proposed framework can solve problems unaddressed by
existing methods, and achieves a 77% improvement in planning time over the
state of the art. We also validate the suitability of our approach on real
hardware through the whole-body manipulation of boxes by a humanoid robot.

</details>


### [256] [BOW: Bayesian Optimization over Windows for Motion Planning in Complex Environments](https://arxiv.org/abs/2508.13052)
*Sourav Raxit,Abdullah Al Redwan Newaz,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: BOW Planner是一个基于约束贝叶斯优化的可扩展运动规划算法，通过关注可达速度规划窗口和高效采样控制输入，有效处理运动学约束和高维目标函数，在复杂环境中实现快速安全的轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在处理速度、加速度等运动学约束时存在困难，特别是在复杂环境中难以同时满足高维目标函数和严格安全约束的需求。

Method: 采用约束贝叶斯优化(CBO)方法，专注于可达速度规划窗口，通过高效采样控制输入来管理高维目标函数和安全约束，实现最小化采样下的快速轨迹生成。

Result: 理论分析证明算法渐近收敛到接近最优解，在杂乱和受限环境中的广泛评估显示计算时间、轨迹长度和解算时间相比现有技术有显著改进。

Conclusion: BOW Planner在实际机器人系统中成功部署，展现出卓越的采样效率、安全感知优化和快速规划能力，已成为开源工具包，对机器人应用发展具有重要价值。

Abstract: This paper introduces the BOW Planner, a scalable motion planning algorithm
designed to navigate robots through complex environments using constrained
Bayesian optimization (CBO). Unlike traditional methods, which often struggle
with kinodynamic constraints such as velocity and acceleration limits, the BOW
Planner excels by concentrating on a planning window of reachable velocities
and employing CBO to sample control inputs efficiently. This approach enables
the planner to manage high-dimensional objective functions and stringent safety
constraints with minimal sampling, ensuring rapid and secure trajectory
generation. Theoretical analysis confirms the algorithm's asymptotic
convergence to near-optimal solutions, while extensive evaluations in cluttered
and constrained settings reveal substantial improvements in computation times,
trajectory lengths, and solution times compared to existing techniques.
Successfully deployed across various real-world robotic systems, the BOW
Planner demonstrates its practical significance through exceptional sample
efficiency, safety-aware optimization, and rapid planning capabilities, making
it a valuable tool for advancing robotic applications. The BOW Planner is
released as an open-source package and videos of real-world and simulated
experiments are available at https://bow-web.github.io.

</details>


### [257] [Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](https://arxiv.org/abs/2508.13073)
*Rui Shao,Wei Li,Lingsen Zhang,Renshan Zhang,Zhiyang Liu,Ran Chen,Liqiang Nie*

Main category: cs.RO

TL;DR: 这是一份关于基于大型视觉-语言模型的视觉-语言-动作模型在机器人操控领域的系统性调研报告，包含了架构分析、技术集成、特征综述和未来方向


<details>
  <summary>Details</summary>
Motivation: 传统规则基础方法在非结构化环境中缺乏扩展性和通用性，VLA模型成为了变革性的解决方案，需要系统性的评估和整合

Method: 提出了两种主要架构范式：单一架构模型（包含单系统和双系统设计）和层次架构模型（通过可解释的中间表示明确解耦规划与执行）

Result: 完成了对大型VLM基础VLA模型的深入考察，包括与加强学习、无训练优化、从人类视频学习等领域的集成，并综合了架构特征、操作优势以及支持发展的数据集和测试标准

Conclusion: 该调研报告整合了最新进展，解决了现有分类中的不一致性，减轻了研究分散性，并通过系统性整合大型VLM与机器人操控交叉研究填补了关键空白

Abstract: Robotic manipulation, a key frontier in robotics and embodied AI, requires
precise motor control and multimodal understanding, yet traditional rule-based
methods fail to scale or generalize in unstructured, novel environments. In
recent years, Vision-Language-Action (VLA) models, built upon Large
Vision-Language Models (VLMs) pretrained on vast image-text datasets, have
emerged as a transformative paradigm. This survey provides the first
systematic, taxonomy-oriented review of large VLM-based VLA models for robotic
manipulation. We begin by clearly defining large VLM-based VLA models and
delineating two principal architectural paradigms: (1) monolithic models,
encompassing single-system and dual-system designs with differing levels of
integration; and (2) hierarchical models, which explicitly decouple planning
from execution via interpretable intermediate representations. Building on this
foundation, we present an in-depth examination of large VLM-based VLA models:
(1) integration with advanced domains, including reinforcement learning,
training-free optimization, learning from human videos, and world model
integration; (2) synthesis of distinctive characteristics, consolidating
architectural traits, operational strengths, and the datasets and benchmarks
that support their development; (3) identification of promising directions,
including memory mechanisms, 4D perception, efficient adaptation, multi-agent
cooperation, and other emerging capabilities. This survey consolidates recent
advances to resolve inconsistencies in existing taxonomies, mitigate research
fragmentation, and fill a critical gap through the systematic integration of
studies at the intersection of large VLMs and robotic manipulation. We provide
a regularly updated project page to document ongoing progress:
https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.

</details>


### [258] [Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy](https://arxiv.org/abs/2508.13103)
*Tianyi Zhang,Haonan Duan,Haoran Hao,Yu Qiao,Jifeng Dai,Zhi Hou*

Main category: cs.RO

TL;DR: OC-VLA框架通过将动作预测直接建立在相机观测空间中，解决了VLA模型在观察和动作空间不一致的问题，提高了模型对相机视角变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: VLA模型由于观察空间和动作空间之间的固有差异，在泛化到真实世界环境时经常遇到挑战。虽然训练数据来自不同的相机视角，但模型通常在机器人基坐标系中预测末端执行器位姿，导致空间不一致。

Method: 引入观察中心的VLA（OC-VLA）框架，利用相机外参标定矩阵将末端执行器位姿从机器人基坐标系转换到相机坐标系，从而统一不同视角的预测目标。这是一个轻量级、即插即用的策略。

Result: 在模拟和真实世界机器人操作任务上的综合评估表明，OC-VLA加速了收敛，提高了任务成功率，并改善了跨视角泛化能力。

Conclusion: OC-VLA框架通过统一观察和动作空间，显著提高了VLA模型对相机视角变化的适应性和鲁棒性，且与现有VLA架构兼容，无需重大修改。

Abstract: Vision-Language-Action (VLA) models frequently encounter challenges in
generalizing to real-world environments due to inherent discrepancies between
observation and action spaces. Although training data are collected from
diverse camera perspectives, the models typically predict end-effector poses
within the robot base coordinate frame, resulting in spatial inconsistencies.
To mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA)
framework, which grounds action predictions directly in the camera observation
space. Leveraging the camera's extrinsic calibration matrix, OC-VLA transforms
end-effector poses from the robot base coordinate system into the camera
coordinate system, thereby unifying prediction targets across heterogeneous
viewpoints. This lightweight, plug-and-play strategy ensures robust alignment
between perception and action, substantially improving model resilience to
camera viewpoint variations. The proposed approach is readily compatible with
existing VLA architectures, requiring no substantial modifications.
Comprehensive evaluations on both simulated and real-world robotic manipulation
tasks demonstrate that OC-VLA accelerates convergence, enhances task success
rates, and improves cross-view generalization. The code will be publicly
available.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [259] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: SamKV是首个针对多上下文KV缓存进行注意力稀疏化的方法，通过考虑其他上下文的互补信息来稀疏化单个上下文，并局部重新计算稀疏化信息，在RAG场景中将序列长度压缩至15%且不损失精度。


<details>
  <summary>Details</summary>
Motivation: 解决RAG场景中多上下文KV缓存的内存开销问题，现有方法无法有效处理缺乏跨上下文注意力的多上下文KV缓存，要么需要保留全部KV缓存，要么会因缺少跨注意力而导致精度损失。

Method: SamKV方法在稀疏化一个上下文时考虑其他上下文的互补信息，然后局部重新计算稀疏化信息，实现多上下文KV缓存的有效压缩。

Result: 实验表明该方法能将序列长度压缩至15%，相比完全重新计算的基线方法没有精度损失，显著提升了多上下文RAG场景的吞吐量。

Conclusion: SamKV成功解决了多上下文KV缓存的高效压缩问题，为RAG场景中的长序列推理提供了有效的解决方案，在保持精度的同时大幅提升了推理效率。

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


### [260] [Assessing Representation Stability for Transformer Models](https://arxiv.org/abs/2508.11667)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.LG

TL;DR: 提出了Representation Stability (RS)框架，通过测量重要词汇被遮蔽时嵌入表示的变化来检测对抗性文本攻击，无需重新训练模型，在多个数据集和攻击类型上达到88%以上的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗文本攻击防御方法通常是针对特定攻击的或需要昂贵的模型重新训练，需要一个模型无关的检测框架来识别对抗样本。

Method: RS框架首先使用重要性启发式对词汇进行排序，然后测量对遮蔽前k个关键词的嵌入敏感性，最后使用BiLSTM检测器处理结果模式。使用梯度排序优于注意力和随机选择方法。

Result: 在三个数据集、三种攻击类型和两个受害者模型上，RS实现了超过88%的检测准确率，计算成本较低。梯度排序在扰动识别质量方面表现最佳，识别质量与词级攻击的检测性能相关。

Conclusion: RS框架无需重新训练就能很好地泛化到未见过的数据集、攻击和模型，为对抗性文本检测提供了一个实用的解决方案。

Abstract: Adversarial text attacks remain a persistent threat to transformer models,
yet existing defenses are typically attack-specific or require costly model
retraining. We introduce Representation Stability (RS), a model-agnostic
detection framework that identifies adversarial examples by measuring how
embedding representations change when important words are masked. RS first
ranks words using importance heuristics, then measures embedding sensitivity to
masking top-k critical words, and processes the resulting patterns with a
BiLSTM detector. Experiments show that adversarially perturbed words exhibit
disproportionately high masking sensitivity compared to naturally important
words. Across three datasets, three attack types, and two victim models, RS
achieves over 88% detection accuracy and demonstrates competitive performance
compared to existing state-of-the-art methods, often at lower computational
cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure
perturbation identification quality, we reveal that gradient-based ranking
outperforms attention and random selection approaches, with identification
quality correlating with detection performance for word-level attacks. RS also
generalizes well to unseen datasets, attacks, and models without retraining,
providing a practical solution for adversarial text detection.

</details>


### [261] [Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset](https://arxiv.org/abs/2508.11669)
*Wentao Li,Yonghu He,Kun Gao,Qing Liu,Yali Zheng*

Main category: cs.LG

TL;DR: 该研究提出了一种轻量级神经网络sInvResUNet和协作学习方案KDCL_sInvResUNet，用于从心电图和光电容积脉搏波信号中重建动脉血压波形，在嵌入式设备上实现实时监测。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在嵌入式系统部署时面临计算负载和性能问题，需要开发轻量级但高效的模型用于实时无创血压监测。

Method: 提出sInvResUNet轻量网络和KDCL_sInvResUNet协作学习方案，参数量仅0.89M，计算量0.02 GFLOPS，在大规模围手术期数据集上进行主体独立验证。

Result: 在嵌入式设备上实现8.49毫秒推理时间，平均绝对误差10.06 mmHg，皮尔逊相关系数0.88，性能略优于大型模型，但模型在不同人群和心血管条件下表现存在显著差异。

Conclusion: 该研究为实时无创血压监测奠定了基础，但深度学习模型在广泛人群中的泛化能力有限，需要进一步改进。

Abstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient
management in critical care and perioperative settings, providing continuous
assessment of cardiovascular hemodynamics with minimal risks. Numerous deep
learning models have developed to reconstruct ABP waveform from noninvasively
acquired physiological signals such as electrocardiogram and
photoplethysmogram. However, limited research has addressed the issue of model
performance and computational load for deployment on embedded systems. The
study introduces a lightweight sInvResUNet, along with a collaborative learning
scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a
computational load of 0.02 GFLOPS, real-time ABP estimation was successfully
achieved on embedded devices with an inference time of just 8.49 milliseconds
for a 10-second output. We performed subject-independent validation in a
large-scale and heterogeneous perioperative dataset containing 1,257,141 data
segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and
31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better
performance compared to large models, with a mean absolute error of 10.06 mmHg
and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these
promising results, all deep learning models showed significant performance
variations across different demographic and cardiovascular conditions,
highlighting their limited ability to generalize across such a broad and
diverse population. This study lays a foundation work for real-time,
unobtrusive ABP monitoring in real-world perioperative settings, providing
baseline for future advancements in this area.

</details>


### [262] [Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning](https://arxiv.org/abs/2508.11673)
*Haojie Zhang,Yixiong Liang,Hulin Kuang,Lihui Cen,Zhe Qu,Yigang Cen,Min Zeng,Shichao Kan*

Main category: cs.LG

TL;DR: 提出MSLoRA-CR方法解决多模态生物医学图像增量学习问题，通过模态特定LoRA模块和对比正则化实现知识保留和跨模态知识迁移


<details>
  <summary>Details</summary>
Motivation: 生物医学领域需要处理多种模态和任务，但为每个模态单独训练模型成本过高，需要统一的增量学习方法来降低推理成本

Method: 基于大型视觉语言模型，冻结预训练参数，为每个新模态增量添加模态特定的LoRA模块，并引入对比正则化来增强模态内知识共享和模态间知识区分

Result: 在生物医学图像增量学习实验中，MSLoRA-CR相比为每个模态单独训练模型和通用增量学习方法表现更好，整体性能提升1.88%，同时保持计算效率

Conclusion: MSLoRA-CR有效解决了多模态生物医学图像增量学习的两个核心挑战，在性能和效率方面均优于现有方法

Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for
handling diverse tasks and modalities in the biomedical domain, as training
separate models for each modality or task significantly increases inference
costs. Existing incremental learning methods focus on task expansion within a
single modality, whereas MBIIL seeks to train a unified model incrementally
across modalities. The MBIIL faces two challenges: I) How to preserve
previously learned knowledge during incremental updates? II) How to effectively
leverage knowledge acquired from existing modalities to support new modalities?
To address these challenges, we propose MSLoRA-CR, a method that fine-tunes
Modality-Specific LoRA modules while incorporating Contrastive Regularization
to enhance intra-modality knowledge sharing and promote inter-modality
knowledge differentiation. Our approach builds upon a large vision-language
model (LVLM), keeping the pretrained model frozen while incrementally adapting
new LoRA modules for each modality or task. Experiments on the incremental
learning of biomedical images demonstrate that MSLoRA-CR outperforms both the
state-of-the-art (SOTA) approach of training separate models for each modality
and the general incremental learning method (incrementally fine-tuning LoRA).
Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance
compared to unconstrained incremental learning methods while maintaining
computational efficiency. Our code is publicly available at
https://github.com/VentusAislant/MSLoRA_CR.

</details>


### [263] [Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems](https://arxiv.org/abs/2508.11679)
*Shaodi Feng,Zhuoyi Lin,Jianan Zhou,Cong Zhang,Jingwen Li,Kuan-Wen Chen,Senthilnath Jayavelu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 提出了一种终身学习框架来解决车辆路径问题(VRP)，通过Transformer网络和跨上下文自注意力机制，使神经网络求解器能够适应不同场景的VRP问题。


<details>
  <summary>Details</summary>
Motivation: 现有的神经网络求解器大多在单一上下文环境中训练，限制了其在多样化实际场景中的应用能力，需要提升求解器的通用性和适应性。

Method: 使用Transformer作为主干网络，提出跨上下文自注意力机制来传递知识，并开发动态上下文调度器通过跨上下文经验回放来回顾已学习的策略。

Result: 在合成和基准测试实例上(问题规模达18k)取得了优异性能，在大多数VRP问题上超越了其他神经网络求解器。

Conclusion: 该终身学习框架能够有效发现适用于不同上下文VRP问题的策略，显著提升了神经网络求解器的通用性和实用性。

Abstract: Deep learning has been extensively explored to solve vehicle routing problems
(VRPs), which yields a range of data-driven neural solvers with promising
outcomes. However, most neural solvers are trained to tackle VRP instances in a
relatively monotonous context, e.g., simplifying VRPs by using Euclidean
distance between nodes and adhering to a single problem size, which harms their
off-the-shelf application in different scenarios. To enhance their versatility,
this paper presents a novel lifelong learning framework that incrementally
trains a neural solver to manage VRPs in distinct contexts. Specifically, we
propose a lifelong learner (LL), exploiting a Transformer network as the
backbone, to solve a series of VRPs. The inter-context self-attention mechanism
is proposed within LL to transfer the knowledge obtained from solving preceding
VRPs into the succeeding ones. On top of that, we develop a dynamic context
scheduler (DCS), employing the cross-context experience replay to further
facilitate LL looking back on the attained policies of solving preceding VRPs.
Extensive results on synthetic and benchmark instances (problem sizes up to
18k) show that our LL is capable of discovering effective policies for tackling
generic VRPs in varying contexts, which outperforms other neural solvers and
achieves the best performance for most VRPs.

</details>


### [264] [Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics](https://arxiv.org/abs/2508.11680)
*Aditya Akella,Jonathan Farah*

Main category: cs.LG

TL;DR: 本研究评估了时间序列基础模型TimesFM在预测美国人口变化方面的性能，与传统方法相比，TimesFM在86.67%的测试案例中取得了最低的均方误差，特别是在历史数据稀疏的少数族裔人口预测方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 人口变化受到全球化、经济状况、地缘政治事件和环境因素等多重影响，准确的人口预测对于城市规划、医疗保健和经济政策等领域的决策至关重要。

Method: 使用美国人口普查局和联邦储备经济数据(FRED)的数据集，将时间序列基础模型TimesFM与LSTM网络、ARIMA和线性回归等传统基线方法进行比较评估。

Result: 在六个不同人口特征的州的实验中，TimesFM在86.67%的测试案例中取得了最低的均方误差，对历史数据稀疏的少数族裔人口预测表现尤为突出。

Conclusion: 预训练的基础模型有潜力增强人口分析能力，为主动政策干预提供信息支持，且无需大量任务特定的微调。

Abstract: Demographic shifts, influenced by globalization, economic conditions,
geopolitical events, and environmental factors, pose significant challenges for
policymakers and researchers. Accurate demographic forecasting is essential for
informed decision-making in areas such as urban planning, healthcare, and
economic policy. This study explores the application of time series foundation
models to predict demographic changes in the United States using datasets from
the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate
the performance of the Time Series Foundation Model (TimesFM) against
traditional baselines including Long Short-Term Memory (LSTM) networks,
Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our
experiments across six demographically diverse states demonstrate that TimesFM
achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with
particularly strong performance on minority populations with sparse historical
data. These findings highlight the potential of pre-trained foundation models
to enhance demographic analysis and inform proactive policy interventions
without requiring extensive task-specific fine-tuning.

</details>


### [265] [From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data](https://arxiv.org/abs/2508.11723)
*Qian Cao,Jielin Chen,Junchao Zhao,Rudi Stouffs*

Main category: cs.LG

TL;DR: 提出了一个数据驱动的站点规划布局指标（SPLI）系统，整合多源异构数据和经验知识，通过五个维度量化城市空间布局模式，提高功能分类准确性并支持自动化城市空间分析。


<details>
  <summary>Details</summary>
Motivation: 传统站点规划依赖经验判断和单一数据源，难以系统量化多功能布局。需要数据驱动框架来整合多源数据，提供结构化的城市空间信息分析。

Method: 开发SPLI系统，整合OSM、POI、建筑形态、土地利用和卫星影像等多源数据。通过五个维度分析：建筑功能分层分类、空间组织模式量化、功能多样性指标、基本服务可达性、土地利用强度评估。使用RGNN和GNN等深度学习技术处理数据缺失问题。

Result: 实验表明SPLI系统提高了功能分类的准确性，为自动化、数据驱动的城市空间分析提供了标准化基础。

Conclusion: SPLI系统成功整合了经验知识和多源数据，提供了系统化的城市空间布局量化方法，支持更科学的数据驱动城市规划决策。

Abstract: The spatial layout of urban sites shapes land-use efficiency and spatial
organization. Traditional site planning often relies on experiential judgment
and single-source data, limiting systematic quantification of multifunctional
layouts. We propose a Site Planning Layout Indicator (SPLI) system, a
data-driven framework integrating empirical knowledge with heterogeneous
multi-source data to produce structured urban spatial information. The SPLI
supports multimodal spatial data systems for analytics, inference, and
retrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building
morphology, land use, and satellite imagery. It extends conventional metrics
through five dimensions: (1) Hierarchical Building Function Classification,
refining empirical systems into clear hierarchies; (2) Spatial Organization,
quantifying seven layout patterns (e.g., symmetrical, concentric,
axial-oriented); (3) Functional Diversity, transforming qualitative assessments
into measurable indicators using Functional Ratio (FR) and Simpson Index (SI);
(4) Accessibility to Essential Services, integrating facility distribution and
transport networks for comprehensive accessibility metrics; and (5) Land Use
Intensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to
assess utilization efficiency. Data gaps are addressed through deep learning,
including Relational Graph Neural Networks (RGNN) and Graph Neural Networks
(GNN). Experiments show the SPLI improves functional classification accuracy
and provides a standardized basis for automated, data-driven urban spatial
analytics.

</details>


### [266] [Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks](https://arxiv.org/abs/2508.11727)
*Songyao Jin,Biwei Huang*

Main category: cs.LG

TL;DR: 本文提出了一个两阶段迭代算法，用于在存在潜在子过程的情况下识别多元霍克斯过程中的因果结构，通过离散时间模型表示和路径条件保证可识别性。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统通常只有部分被观测，存在潜在子过程对因果结构发现构成重大挑战，现有方法主要关注观测子过程间的因果结构。

Method: 将连续时间事件序列表示为离散时间模型，建立识别潜在子过程和因果影响的充要条件，提出交替推断已发现子过程间因果关系和发现新潜在子过程的两阶段迭代算法。

Result: 在合成和真实数据集上的实验表明，该方法在存在潜在子过程的情况下能有效恢复因果结构。

Conclusion: 通过离散时间模型表示和路径条件指导的迭代算法，能够成功识别包含潜在子过程的多元霍克斯过程的因果结构。

Abstract: Multivariate Hawkes process provides a powerful framework for modeling
temporal dependencies and event-driven interactions in complex systems. While
existing methods primarily focus on uncovering causal structures among observed
subprocesses, real-world systems are often only partially observed, with latent
subprocesses posing significant challenges. In this paper, we show that
continuous-time event sequences can be represented by a discrete-time model as
the time interval shrinks, and we leverage this insight to establish necessary
and sufficient conditions for identifying latent subprocesses and the causal
influences. Accordingly, we propose a two-phase iterative algorithm that
alternates between inferring causal relationships among discovered subprocesses
and uncovering new latent subprocesses, guided by path-based conditions that
guarantee identifiability. Experiments on both synthetic and real-world
datasets show that our method effectively recovers causal structures despite
the presence of latent subprocesses.

</details>


### [267] [BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification](https://arxiv.org/abs/2508.11732)
*Xiangxiang Cui,Min Zhao,Dongmei Zhi,Shile Qi,Vince D Calhoun,Jing Sui*

Main category: cs.LG

TL;DR: 提出了一种受大脑启发的特征融合框架BRIEF，通过改进的神经网络连接搜索策略和Transformer多特征融合模块，自动优化网络架构，在精神分裂症和自闭症分类任务上相比21个先进模型有2.2%-12.1%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在fMRI分类中存在网络架构确定依赖经验、特征融合简单（主要是拼接）缺乏相互学习的问题，受人类大脑通过学习更新神经连接机制的启发。

Method: 提取4种fMRI时间表征（时间序列、静态/动态功能连接、多尺度分散熵），构建4个编码器，使用改进Q-learning动态优化神经网络连接搜索，通过Transformer融合特征向量，并嵌入注意力模块提高可解释性。

Result: 在精神分裂症（SZ, n=1100）和自闭症（ASD, n=1550）分类任务中，相比21个先进算法有2.2%-12.1%的显著提升，AUC分别达到91.5%和78.4%。

Conclusion: 这是首次将受大脑启发的强化学习策略用于优化fMRI精神障碍分类，显示出识别精确神经影像生物标志物的巨大潜力。

Abstract: Existing deep learning models for functional MRI-based classification have
limitations in network architecture determination (relying on experience) and
feature space fusion (mostly simple concatenation, lacking mutual learning).
Inspired by the human brain's mechanism of updating neural connections through
learning and decision-making, we proposed a novel BRain-Inspired feature Fusion
(BRIEF) framework, which is able to optimize network architecture automatically
by incorporating an improved neural network connection search (NCS) strategy
and a Transformer-based multi-feature fusion module. Specifically, we first
extracted 4 types of fMRI temporal representations, i.e., time series (TCs),
static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion
entropy (MsDE), to construct four encoders. Within each encoder, we employed a
modified Q-learning to dynamically optimize the NCS to extract high-level
feature vectors, where the NCS is formulated as a Markov Decision Process.
Then, all feature vectors were fused via a Transformer, leveraging both
stable/time-varying connections and multi-scale dependencies across different
brain regions to achieve the final classification. Additionally, an attention
module was embedded to improve interpretability. The classification performance
of our proposed BRIEF was compared with 21 state-of-the-art models by
discriminating two mental disorders from healthy controls: schizophrenia (SZ,
n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated
significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching
an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is
the first attempt to incorporate a brain-inspired, reinforcement learning
strategy to optimize fMRI-based mental disorder classification, showing
significant potential for identifying precise neuroimaging biomarkers.

</details>


### [268] [Scalable Geospatial Data Generation Using AlphaEarth Foundations Model](https://arxiv.org/abs/2508.11739)
*Luc Houriez,Sebastian Pilarski,Behzad Vahedi,Ali Ahmadalipour,Teo Honda Scully,Nicholas Aflitto,David Andre,Caroline Jaffe,Martha Wedner,Rich Mazzola,Josh Jeffery,Ben Messinger,Sage McGinley-Smith,Sarah Russell*

Main category: cs.LG

TL;DR: 利用Google DeepMind的AlphaEarth Foundations (AEF)全球地理空间表示，通过基础模型（如随机森林和逻辑回归）将美国LANDFIRE植被类型数据集扩展到加拿大，在两个粒度级别上分别达到81%和73%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 高质量的地理空间标注数据集通常局限于特定地理区域，无法覆盖全球范围，这限制了从这些数据中提取洞察和理解的潜力。

Method: 利用AEF作为信息密集的全球地理空间表示，使用随机森林和逻辑回归等基础模型，将美国LANDFIRE的现有植被类型(EVT)数据集扩展到加拿大，在两个粒度级别(EvtPhys-13类和EvtGp-80类)上进行评估。

Result: 在EvtPhys级别上，模型预测与地面实况相符。在美国和加拿大的验证集上，分类准确率分别达到81%和73%，尽管存在一些局限性。

Conclusion: 即使使用基础模型，利用AEF全球表示也能有效扩展地理空间标注数据集的地理覆盖范围，为全球尺度的地理空间分析提供了可行的方法。

Abstract: High-quality labeled geospatial datasets are essential for extracting
insights and understanding our planet. Unfortunately, these datasets often do
not span the entire globe and are limited to certain geographic regions where
data was collected. Google DeepMind's recently released AlphaEarth Foundations
(AEF) provides an information-dense global geospatial representation designed
to serve as a useful input across a wide gamut of tasks. In this article we
propose and evaluate a methodology which leverages AEF to extend geospatial
labeled datasets beyond their initial geographic regions. We show that even
basic models like random forests or logistic regression can be used to
accomplish this task. We investigate a case study of extending LANDFIRE's
Existing Vegetation Type (EVT) dataset beyond the USA into Canada at two levels
of granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for
EvtPhys, model predictions align with ground truth. Trained models achieve 81%
and 73% classification accuracy on EvtPhys validation sets in the USA and
Canada, despite discussed limitations.

</details>


### [269] [Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data](https://arxiv.org/abs/2508.11794)
*Hemanth Macharla,Mayukha Pal*

Main category: cs.LG

TL;DR: Fed-Meta-Align是一个四阶段联邦学习框架，通过在公共数据集上预训练基础模型，然后进行序列元初始化来学习异构感知的初始化，再通过并行联邦学习阶段使用双重标准聚合机制，最后进行设备端个性化，显著提高了IoT设备在非IID数据下的故障分类准确率。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限IoT设备在异构环境中实时故障分类的挑战，特别是标准联邦学习在非IID数据下容易导致模型发散的问题。

Method: 四阶段框架：1）在公共数据集上训练基础模型；2）序列元初始化阶段在IoT设备子集上顺序训练；3）并行联邦学习阶段使用基于本地性能和余弦相似度的双重标准聚合；4）设备端个性化阶段。

Result: 在异构IoT设备上平均测试准确率达到91.27%，比个性化FedAvg和FedProx分别高出3.87%和3.37%（在电气和机械故障数据集上）。

Conclusion: 这种多阶段的序列初始化和自适应聚合方法为在多样化TinyML网络上部署高性能智能提供了稳健的途径。

Abstract: Real-time fault classification in resource-constrained Internet of Things
(IoT) devices is critical for industrial safety, yet training robust models in
such heterogeneous environments remains a significant challenge. Standard
Federated Learning (FL) often fails in the presence of non-IID data, leading to
model divergence. This paper introduces Fed-Meta-Align, a novel four-phase
framework designed to overcome these limitations through a sophisticated
initialization and training pipeline. Our process begins by training a
foundational model on a general public dataset to establish a competent
starting point. This model then undergoes a serial meta-initialization phase,
where it sequentially trains on a subset of IOT Device data to learn a
heterogeneity-aware initialization that is already situated in a favorable
region of the loss landscape. This informed model is subsequently refined in a
parallel FL phase, which utilizes a dual-criterion aggregation mechanism that
weights for IOT devices updates based on both local performance and cosine
similarity alignment. Finally, an on-device personalization phase adapts the
converged global model into a specialized expert for each IOT Device.
Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average
test accuracy of 91.27% across heterogeneous IOT devices, outperforming
personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and
mechanical fault datasets, respectively. This multi-stage approach of sequenced
initialization and adaptive aggregation provides a robust pathway for deploying
high-performance intelligence on diverse TinyML networks.

</details>


### [270] [Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes](https://arxiv.org/abs/2508.11800)
*Michael Bereket,Jure Leskovec*

Main category: cs.LG

TL;DR: 本文研究了在具有随机结果的验证性领域中，不同RL方法对语言模型概率预测校准性的影响，发现GRPO会导致过度自信的预测，而PPO和RLOO能产生良好校准的模型。


<details>
  <summary>Details</summary>
Motivation: 研究当前RL方法在具有随机结果的验证性领域（如科学实验）中优化语言模型的有效性，特别是在概率预测校准性方面的问题。

Method: 通过合成数据和真实生物实验应用，比较Group Relative Policy Optimization (GRPO)、Proximal Policy Optimization (PPO)和REINFORCE Leave-One-Out (RLOO)等方法的表现。

Result: GRPO导致二元随机结果的过度自信概率预测，而PPO和RLOO产生良好校准的模型。移除GRPO中的组标准化可以修复其校准问题。

Conclusion: 研究结果反对在GRPO中使用标准标准化，为RL在确定性领域之外的语言模型推理应用铺平了道路。

Abstract: Reinforcement learning (RL) has proven remarkably effective at improving the
accuracy of language models in verifiable and deterministic domains like
mathematics. Here, we examine if current RL methods are also effective at
optimizing language models in verifiable domains with stochastic outcomes, like
scientific experiments. Through applications to synthetic data and real-world
biological experiments, we demonstrate that Group Relative Policy Optimization
(GRPO) induces overconfident probability predictions for binary stochastic
outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out
(RLOO) yield well-calibrated models. We show that removing group standard
normalization in GRPO fixes its miscalibration and provide a theoretical
explanation for why normalization causes overconfidence. Our results provide
new evidence against the use of standard normalization in GRPO and help pave
the way for applications of RL for reasoning language models beyond
deterministic domains.

</details>


### [271] [FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation](https://arxiv.org/abs/2508.11810)
*Nitish Nagesh,Salar Shakibhamedan,Mahdi Bagheri,Ziyu Wang,Nima TaheriNejad,Axel Jantsch,Amir M. Rahmani*

Main category: cs.LG

TL;DR: FairTabGen是一个基于大语言模型的公平性感知表格数据生成框架，通过整合反事实和因果公平性定义，在保持数据效用的同时显著提升公平性指标


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感和数据稀缺的环境中生成合成表格数据时，需要同时提高反事实和因果公平性，同时保持高数据效用

Method: 使用上下文学习、提示优化和公平性感知数据策管，将多种公平性定义整合到生成和评估流程中

Result: 在多个数据集上优于最先进的GAN和LLM方法，公平性指标提升达10%，同时保持统计效用，仅需不到20%的原始数据

Conclusion: 该方法为生成公平且有用的合成表格数据提供了一种原则性和实用的方法

Abstract: Generating synthetic data is crucial in privacy-sensitive, data-scarce
settings, especially for tabular datasets widely used in real-world
applications. A key challenge is improving counterfactual and causal fairness,
while preserving high utility. We present FairTabGen, a fairness-aware large
language model-based framework for tabular synthetic data generation. We
integrate multiple fairness definitions including counterfactual and causal
fairness into both its generation and evaluation pipelines. We use in-context
learning, prompt refinement, and fairness-aware data curation to balance
fairness and utility. Across diverse datasets, our method outperforms
state-of-the-art GAN-based and LLM-based methods, achieving up to 10%
improvements on fairness metrics such as demographic parity and path-specific
causal effects while retaining statistical utility. Remarkably, it achieves
these gains using less than 20% of the original data, highlighting its
efficiency in low-data regimes. These results demonstrate a principled and
practical approach for generating fair and useful synthetic tabular data.

</details>


### [272] [Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.11876)
*Hoang-Thang Ta,Duy-Quy Thai,Phuong-Linh Tran-Thi*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: For years, many neural networks have been developed based on the
Kolmogorov-Arnold Representation Theorem (KART), which was created to address
Hilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks
(KANs) have attracted attention from the research community, stimulating the
use of polynomial functions such as B-splines and RBFs. However, these
functions are not fully supported by GPU devices and are still considered less
popular. In this paper, we propose the use of fast computational functions,
such as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as
basis components in Kolmogorov-Arnold Networks (KANs). By integrating these
function combinations into the network structure, we aim to enhance
computational efficiency. Experimental results show that these combinations
maintain competitive performance while offering potential improvements in
training time and generalization.

</details>


### [273] [PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression](https://arxiv.org/abs/2508.11880)
*Yuto Omae*

Main category: cs.LG

TL;DR: 提出了PCA-Grad-CAM和SVM-Grad-CAM方法，用于在CNN的PCA和SVM层中可视化注意力区域，解决了传统Grad-CAM无法直接应用于这些层的问题。


<details>
  <summary>Details</summary>
Motivation: 当训练样本有限时，在CNN中集成PCA层和/或SVM分类器可以提高分类性能，但传统Grad-CAM无法直接应用于这些层，需要开发新的可视化方法来构建白盒方法。

Method: 提出了PCA-Grad-CAM和SVM-Grad-CAM方法，通过求解从最后一个卷积层到PCA和/或SVM层的闭式雅可比矩阵来完成可视化。

Result: 在多个主要数据集上展示了可视化结果，证明了方法的有效性。

Conclusion: 提出的方法能够有效可视化PCA和SVM层的注意力区域，为开发白盒CNN方法提供了重要工具。

Abstract: Convolutional Neural Networks (CNNs) are an effective approach for
classification tasks, particularly when the training dataset is large. Although
CNNs have long been considered a black-box classification method, they can be
used as a white-box method through visualization techniques such as Grad-CAM.
When training samples are limited, incorporating a Principal Component Analysis
(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can
effectively improve classification performance. However, traditional Grad-CAM
cannot be directly applied to PCA and/or SVM layers. It is important to
generate attention regions for PCA and/or SVM layers in CNNs to facilitate the
development of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a
method for visualizing attention regions in PCA feature vectors, and
``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM
classifier layer. To complete our methods analytically, it is necessary to
solve the closed-form Jacobian consisting of partial derivatives from the last
convolutional layer to the PCA and/or SVM layers. In this paper, we present the
exact closed-form Jacobian and the visualization results of our methods applied
to several major datasets.

</details>


### [274] [ENA: Efficient N-dimensional Attention](https://arxiv.org/abs/2508.11921)
*Yibo Zhong*

Main category: cs.LG

TL;DR: 本文提出了一种结合线性循环和高维滑动窗口注意力的混合架构ENA，用于高效建模超长高维数据，相比Transformer更高效。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理长序列高维数据时效率不足，需要更高效的架构来建模这类数据。

Method: 研究了扫描策略和注意力混合架构两种扩展线性循环模型的方法，最终提出结合线性循环和高维滑动窗口注意力的ENA架构。

Result: 实验表明扫描策略效果有限，而注意力混合模型表现良好，其中瓦片式高维滑动窗口注意力在理论和实践中都高效。

Conclusion: ENA架构通过线性循环压缩全局信息和滑动窗口注意力强化局部建模，为超长高维数据建模提供了有前景的实用解决方案。

Abstract: Efficient modeling of long sequences of high-order data requires a more
efficient architecture than Transformer. In this paper, we investigate two key
aspects of extending linear recurrent models, especially those originally
designed for language modeling, to high-order data (1D to ND): scanning
strategies and attention-hybrid architectures. Empirical results suggest that
scanning provides limited benefits, while attention-hybrid models yield
promising results. Focusing on the latter, we further evaluate types of
attention and find that tiled high-order sliding window attention (SWA) is
efficient in both theory and practice. We term the resulting hybrid
architecture of linear recurrence and high-order SWA as Efficient N-dimensional
Attention (ENA). We then conduct several experiments to demonstrate its
effectiveness. The intuition behind ENA is that linear recurrence compresses
global information into a state, while SWA complements it by enforcing strict
local modeling. Together, they form a simple framework that offers a promising
and practical solution for ultra-long high-order data modeling.

</details>


### [275] [Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting](https://arxiv.org/abs/2508.11923)
*Yan Wu,Lihong Pei,Yukai Han,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 提出了SDSTM框架，通过尺度解耦的时空建模解决交通排放长期预测中的级联误差放大问题，利用多尺度可预测性差异进行特征分解和融合，在西安二环道路级排放数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统时空图模型在交通排放长期预测中由于多尺度时空纠缠导致级联误差放大，需要新的建模方法来提高长期预测准确性

Method: 基于Koopman提升算子的双流特征分解策略，将尺度耦合的时空动力系统提升到无限维线性空间，通过门控小波分解界定可预测性边界，并构建包含交叉项损失的双流独立性约束融合机制

Result: 在西安二环道路级交通排放数据集上的大量实验表明，所提模型达到了最先进的性能

Conclusion: SDSTM框架通过尺度解耦和动态融合机制有效解决了交通排放长期预测中的误差放大问题，显著提升了预测精度

Abstract: Long-term traffic emission forecasting is crucial for the comprehensive
management of urban air pollution. Traditional forecasting methods typically
construct spatiotemporal graph models by mining spatiotemporal dependencies to
predict emissions. However, due to the multi-scale entanglement of traffic
emissions across time and space, these spatiotemporal graph modeling method
tend to suffer from cascading error amplification during long-term inference.
To address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling
(SDSTM) framework for long-term traffic emission forecasting. It leverages the
predictability differences across multiple scales to decompose and fuse
features at different scales, while constraining them to remain independent yet
complementary. Specifically, the model first introduces a dual-stream feature
decomposition strategy based on the Koopman lifting operator. It lifts the
scale-coupled spatiotemporal dynamical system into an infinite-dimensional
linear space via Koopman operator, and delineates the predictability boundary
using gated wavelet decomposition. Then a novel fusion mechanism is
constructed, incorporating a dual-stream independence constraint based on
cross-term loss to dynamically refine the dual-stream prediction results,
suppress mutual interference, and enhance the accuracy of long-term traffic
emission prediction. Extensive experiments conducted on a road-level traffic
emission dataset within Xi'an's Second Ring Road demonstrate that the proposed
model achieves state-of-the-art performance.

</details>


### [276] [An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction](https://arxiv.org/abs/2508.11931)
*Tim van Erven,Jack Mayo,Julia Olkhovskaya,Chen-Yu Wei*

Main category: cs.LG

TL;DR: 提出了一个高效的线性上下文bandit算法，处理对抗性损失和随机动作集，实现了多项式时间内的√T级别遗憾


<details>
  <summary>Details</summary>
Motivation: 解决Liu等人(2023)提出的开放性问题：是否能在多项式时间内获得与动作数量无关的poly(d)√T遗憾，特别是在组合bandit场景中

Method: 将随机动作集的对抗性线性上下文bandit问题转化为具有固定动作集的误设鲁棒对抗性线性bandit问题，无需上下文分布知识或模拟器

Result: 算法达到Õ(min{d²√T, √d³TlogK})遗憾，运行时间为poly(d,C,T)，在模拟器可用时可改进为Õ(d√L*)遗憾

Conclusion: 首次在多项式时间内为组合bandit实现poly(d)√T遗憾，解决了重要的开放性问题，为对抗性损失和随机动作集场景提供了高效解决方案

Abstract: We present an efficient algorithm for linear contextual bandits with
adversarial losses and stochastic action sets. Our approach reduces this
setting to misspecification-robust adversarial linear bandits with fixed action
sets. Without knowledge of the context distribution or access to a context
simulator, the algorithm achieves $\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log
K}\})$ regret and runs in $\text{poly}(d,C,T)$ time, where $d$ is the feature
dimension, $C$ is an upper bound on the number of linear constraints defining
the action set in each round, $K$ is an upper bound on the number of actions in
each round, and $T$ is number of rounds. This resolves the open question by Liu
et al. (2023) on whether one can obtain $\text{poly}(d)\sqrt{T}$ regret in
polynomial time independent of the number of actions. For the important class
of combinatorial bandits with adversarial losses and stochastic action sets
where the action sets can be described by a polynomial number of linear
constraints, our algorithm is the first to achieve $\text{poly}(d)\sqrt{T}$
regret in polynomial time, while no prior algorithm achieves even $o(T)$ regret
in polynomial time to our knowledge. When a simulator is available, the regret
bound can be improved to $\tilde{O}(d\sqrt{L^\star})$, where $L^\star$ is the
cumulative loss of the best policy.

</details>


### [277] [M3OOD: Automatic Selection of Multimodal OOD Detectors](https://arxiv.org/abs/2508.11936)
*Yuehan Qin,Li Li,Defu Cao,Tiankai Yang,Yue Zhao*

Main category: cs.LG

TL;DR: M3OOD是一个基于元学习的多模态OOD检测器选择框架，通过历史模型行为学习来自动选择最适合不同分布偏移的异常检测模型


<details>
  <summary>Details</summary>
Motivation: 解决多模态环境下OOD检测模型选择难题，由于OOD检测的无监督特性和新数据评估成本高，需要自动化的模型选择方法

Method: 结合多模态嵌入和手工设计的元特征来表示数据集特征，利用元学习从历史多模态基准性能中学习，为新数据分布偏移推荐合适的检测器

Result: 在12个测试场景中持续优于10个竞争基线方法，且计算开销最小

Conclusion: M3OOD框架有效解决了多模态OOD检测器选择问题，通过元学习方法实现了对新分布偏移的快速适应

Abstract: Out-of-distribution (OOD) robustness is a critical challenge for modern
machine learning systems, particularly as they increasingly operate in
multimodal settings involving inputs like video, audio, and sensor data.
Currently, many OOD detection methods have been proposed, each with different
designs targeting various distribution shifts. A single OOD detector may not
prevail across all the scenarios; therefore, how can we automatically select an
ideal OOD detection model for different distribution shifts? Due to the
inherent unsupervised nature of the OOD detection task, it is difficult to
predict model performance and find a universally Best model. Also,
systematically comparing models on the new unseen data is costly or even
impractical. To address this challenge, we introduce M3OOD, a
meta-learning-based framework for OOD detector selection in multimodal
settings. Meta learning offers a solution by learning from historical model
behaviors, enabling rapid adaptation to new data distribution shifts with
minimal supervision. Our approach combines multimodal embeddings with
handcrafted meta-features that capture distributional and cross-modal
characteristics to represent datasets. By leveraging historical performance
across diverse multimodal benchmarks, M3OOD can recommend suitable detectors
for a new data distribution shift. Experimental evaluation demonstrates that
M3OOD consistently outperforms 10 competitive baselines across 12 test
scenarios with minimal computational overhead.

</details>


### [278] [Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware](https://arxiv.org/abs/2508.11940)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Yixiang Zhang,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.LG

TL;DR: 提出了一种基于直通估计器(STE)框架的噪声感知训练方法，通过前向噪声模拟与后向梯度计算的解耦，解决了模拟存内计算(CIM)硬件中复杂噪声建模的难题。


<details>
  <summary>Details</summary>
Motivation: 模拟存内计算架构虽然能显著提升神经网络推理的能效，但面临复杂的硬件诱发噪声挑战。现有的噪声感知训练方法依赖于理想化且可微分的噪声模型，无法准确捕捉模拟CIM硬件的完整复杂性。

Method: 借鉴量化中的直通估计器(STE)框架，将前向噪声模拟与后向梯度计算解耦，使得能够在训练中使用更准确但计算上难以处理的噪声模型。

Result: 实验表明该方法在图像分类上实现5.3%的准确率提升，文本生成中困惑度降低0.72，训练时间加速2.2倍，峰值内存使用降低37.9%。

Conclusion: 扩展的STE框架为模拟CIM系统提供了有效的噪声感知训练解决方案，在保持计算可行性和优化稳定性的同时，显著提升了模型性能。

Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy
efficiency gains for neural network inference, but suffer from complex
hardware-induced noise that poses major challenges for deployment. While
noise-aware training methods have been proposed to address this issue, they
typically rely on idealized and differentiable noise models that fail to
capture the full complexity of analog CIM hardware variations. Motivated by the
Straight-Through Estimator (STE) framework in quantization, we decouple forward
noise simulation from backward gradient computation, enabling noise-aware
training with more accurate but computationally intractable noise modeling in
analog CIM systems. We provide theoretical analysis demonstrating that our
approach preserves essential gradient directional information while maintaining
computational tractability and optimization stability. Extensive experiments
show that our extended STE framework achieves up to 5.3% accuracy improvement
on image classification, 0.72 perplexity reduction on text generation,
2.2$\times$ speedup in training time, and 37.9% lower peak memory usage
compared to standard noise-aware training methods.

</details>


### [279] [Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/abs/2508.11943)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yan Wang*

Main category: cs.LG

TL;DR: 该研究提出了CFF方法，结合反事实和事实解释来为标记时间点过程模型提供最小且合理的解释子集，解决了直接使用单一解释方法导致不合理解释的问题。


<details>
  <summary>Details</summary>
Motivation: 神经网络标记时间点过程模型在高风险应用中广泛使用，但其输出的可信度存在担忧，需要找到能够保持预测准确性的最小历史事件子集作为合理解释。

Method: 提出CFF方法，结合反事实解释和事实解释，通过精心设计的技术来解决MTPP的解释问题，识别最小且合理的解释子集。

Result: 实验证明CFF在解释质量和处理效率方面优于基线方法，具有正确性和优越性。

Conclusion: 将反事实和事实解释相结合的方法能够为MTPP模型提供更合理和有效的解释，提高了模型输出的可信度。

Abstract: Neural network-based Marked Temporal Point Process (MTPP) models have been
widely adopted to model event sequences in high-stakes applications, raising
concerns about the trustworthiness of outputs from these models. This study
focuses on Explanation for MTPP, aiming to identify the minimal and rational
explanation, that is, the minimum subset of events in history, based on which
the prediction accuracy of MTPP matches that based on full history to a great
extent and better than that based on the complement of the subset. This study
finds that directly defining Explanation for MTPP as counterfactual explanation
or factual explanation can result in irrational explanations. To address this
issue, we define Explanation for MTPP as a combination of counterfactual
explanation and factual explanation. This study proposes Counterfactual and
Factual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of
deliberately designed techniques. Experiments demonstrate the correctness and
superiority of CFF over baselines regarding explanation quality and processing
efficiency.

</details>


### [280] [Set-Valued Transformer Network for High-Emission Mobile Source Identification](https://arxiv.org/abs/2508.11976)
*Yunning Cao,Lihong Pei,Jian Guo,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 提出Set-Valued Transformer Network (SVTN)模型解决高排放车辆识别中的长尾分布问题，通过transformer提取时间相似性特征和集合值识别算法进行概率建模，在合肥柴油车监测数据上实现9.5%的漏检率降低


<details>
  <summary>Details</summary>
Motivation: 实际监测数据中高排放状态数据比例显著低于正常排放状态，呈现长尾分布特征，严重阻碍了排放状态识别中判别性特征的提取。车辆排放状态的高度非线性和缺乏先验知识也给识别模型构建带来挑战

Method: 使用transformer测量微行程条件变化的时间相似性，将高维排放数据映射到低维特征空间；采用集合值识别算法对特征向量与标签关系进行概率建模，为分类算法提供准确度量标准

Result: 在合肥市2020年柴油车监测数据上的实验表明，相比基于transformer的基线方法，该方法将高排放车辆的漏检率降低了9.5%

Conclusion: SVTN模型能够全面学习高排放样本的判别性特征，显著提升高排放移动污染源的准确识别能力

Abstract: Identifying high-emission vehicles is a crucial step in regulating urban
pollution levels and formulating traffic emission reduction strategies.
However, in practical monitoring data, the proportion of high-emission state
data is significantly lower compared to normal emission states. This
characteristic long-tailed distribution severely impedes the extraction of
discriminative features for emission state identification during data mining.
Furthermore, the highly nonlinear nature of vehicle emission states and the
lack of relevant prior knowledge also pose significant challenges to the
construction of identification models.To address the aforementioned issues, we
propose a Set-Valued Transformer Network (SVTN) to achieve comprehensive
learning of discriminative features from high-emission samples, thereby
enhancing detection accuracy. Specifically, this model first employs the
transformer to measure the temporal similarity of micro-trip condition
variations, thus constructing a mapping rule that projects the original
high-dimensional emission data into a low-dimensional feature space. Next, a
set-valued identification algorithm is used to probabilistically model the
relationship between the generated feature vectors and their labels, providing
an accurate metric criterion for the classification algorithm. To validate the
effectiveness of our proposed approach, we conducted extensive experiments on
the diesel vehicle monitoring data of Hefei city in 2020. The results
demonstrate that our method achieves a 9.5\% reduction in the missed detection
rate for high-emission vehicles compared to the transformer-based baseline,
highlighting its superior capability in accurately identifying high-emission
mobile pollution sources.

</details>


### [281] [Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models](https://arxiv.org/abs/2508.11985)
*Zhanhao Cao,Clement Truong,Andrew Lizarraga*

Main category: cs.LG

TL;DR: LoRA模块可以通过简单加法组合，无需额外训练即可实现多领域适配，性能接近合并数据训练模型


<details>
  <summary>Details</summary>
Motivation: 基于叠加原理假设，独立训练的LoRA模块在不相交领域上近似正交，可以通过加法组合

Method: 使用GPT-2 Small (117M)模型，LoRA秩为4，alpha=64，在数学、医学、金融三个QA领域训练独立适配器，然后通过简单加法组合不同领域的LoRA模块

Result: 数学+医学组合相对合并数据微调困惑度改善-9.10%，数学+金融+4.54%，金融+医学+27.56%。LoRA增量之间的RMS余弦相似度与困惑度变化呈正相关线性关系

Conclusion: 朴素加法方法无需额外训练，秒级应用，性能与合并数据训练模型相当，同时揭示了高阶组合中干扰出现的条件

Abstract: Recent advances in large language models are driven by scale, while
parameter-efficient fine-tuning (PEFT) enables updating only a small fraction
of parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the
product of two small matrices, which makes them natural building blocks that
can be composed. Motivated by the superposition principle, we hypothesize that
independently trained LoRA modules on disjoint domains are approximately
orthogonal and can be combined by simple addition. Using GPT-2 Small (117M)
with LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,
medicine, finance). In pairwise tests, adding Math+Medicine adapters improves
perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance
and Finance+Medicine change by +4.54% and +27.56%, respectively. Across
combinations, the RMS cosine similarity between LoRA deltas correlates
positively and approximately linearly with the change in perplexity. Naive
summation requires no additional training, can be applied in seconds, and
achieves performance comparable to models trained on merged data, while
clarifying when interference appears in higher-order compositions.

</details>


### [282] [Universal Learning of Nonlinear Dynamics](https://arxiv.org/abs/2508.11990)
*Evan Dogariu,Anand Brahmbhatt,Elad Hazan*

Main category: cs.LG

TL;DR: 提出了一种基于谱滤波的算法，用于学习具有有限个边际稳定模式的非线性动力系统，通过在线凸优化技术实现了预测误差的消失。


<details>
  <summary>Details</summary>
Motivation: 解决学习未知非线性动力系统的基本问题，特别是针对具有边际稳定模式的系统，这类系统在控制理论中具有重要意义但学习难度较大。

Method: 基于谱滤波技术，通过系统的谱表示构建从过去观测到未来预测的映射，并开发了新的谱滤波算法来处理线性动力系统，该算法能够处理非对称动态和噪声校正。

Result: 证明了对于任何具有有限个边际稳定模式的非线性动力系统，该算法能够实现预测误差的消失，学习速率由新的可学习性量化控制理论概念决定。

Conclusion: 该方法显著推广了原始谱滤波算法，能够处理更一般的噪声和边际稳定系统，在非线性动力系统学习领域具有重要理论价值和独立意义。

Abstract: We study the fundamental problem of learning a marginally stable unknown
nonlinear dynamical system. We describe an algorithm for this problem, based on
the technique of spectral filtering, which learns a mapping from past
observations to the next based on a spectral representation of the system.
Using techniques from online convex optimization, we prove vanishing prediction
error for any nonlinear dynamical system that has finitely many marginally
stable modes, with rates governed by a novel quantitative control-theoretic
notion of learnability. The main technical component of our method is a new
spectral filtering algorithm for linear dynamical systems, which incorporates
past observations and applies to general noisy and marginally stable systems.
This significantly generalizes the original spectral filtering algorithm to
both asymmetric dynamics as well as incorporating noise correction, and is of
independent interest.

</details>


### [283] [FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing](https://arxiv.org/abs/2508.12021)
*You Hak Lee,Xiaofan Yu,Quanling Zhao,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: FedUHD是基于超维计算的首个无监督联邦学习框架，通过轻量级HDC方案解决了传统神经网络方法在计算、通信和噪声鲁棒性方面的挑战，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决无监督联邦学习中的三个关键挑战：非独立同分布数据、边缘设备的高计算通信成本、通信噪声脆弱性。传统基于神经网络的方法存在计算和通信开销大的问题。

Method: 提出基于超维计算(HDC)的FedUHD框架：客户端使用kNN聚类超向量移除方法处理非iid数据异常值；服务器端采用加权HDC聚合技术平衡非iid数据分布。

Result: 相比最先进的神经网络方法，FedUHD实现了173.6倍训练加速、612.7倍能效提升、271倍通信成本降低、平均15.50%精度提升，并展现出优异的噪声鲁棒性。

Conclusion: HDC为基础的无监督联邦学习框架FedUHD在性能、效率和鲁棒性方面显著优于传统神经网络方法，为边缘设备上的隐私保护机器学习提供了实用解决方案。

Abstract: Unsupervised federated learning (UFL) has gained attention as a
privacy-preserving, decentralized machine learning approach that eliminates the
need for labor-intensive data labeling. However, UFL faces several challenges
in practical applications: (1) non-independent and identically distributed
(non-iid) data distribution across devices, (2) expensive computational and
communication costs at the edge, and (3) vulnerability to communication noise.
Previous UFL approaches have relied on deep neural networks (NN), which
introduce substantial overhead in both computation and communication. In this
paper, we propose FedUHD, the first UFL framework based on Hyperdimensional
Computing (HDC). HDC is a brain-inspired computing scheme with lightweight
training and inference operations, much smaller model size, and robustness to
communication noise. FedUHD introduces two novel HDC-based designs to improve
UFL performance. On the client side, a kNN-based cluster hypervector removal
method addresses non-iid data samples by eliminating detrimental outliers. On
the server side, a weighted HDC aggregation technique balances the non-iid data
distribution across clients. Our experiments demonstrate that FedUHD achieves
up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in
training, up to 271x lower communication cost, and 15.50% higher accuracy on
average across diverse settings, along with superior robustness to various
types of noise compared to state-of-the-art NN-based UFL approaches.

</details>


### [284] [Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates](https://arxiv.org/abs/2508.13088)
*Xiaohan Wang,Zhimin Li,Joshua A. Levine,Matthew Berger*

Main category: cs.LG

TL;DR: 该论文提出了一种基于神经代理模型的参数分布可视化方法，用于解决科学模拟中的逆问题，通过密度估计建模代理误差，并开发交互式界面来分析特征驱动的参数空间。


<details>
  <summary>Details</summary>
Motivation: 传统基于代理模型的逆问题解决方案主要关注找到少量匹配参数，而忽略了可能参数的更广泛分布。本文旨在建模和可视化能够产生特定输出特征的可能输入参数分布。

Method: 通过密度估计建模代理模型的近似误差，结合输入和输出空间的接近度来报告高密度区域。将密度估计作为参数先验信念，与特征似然结合，高效采样生成目标输出特征的合理参数配置。

Result: 开发了可视化界面，在三个模拟数据集上执行特征驱动的参数空间分析，证明了解决方案的实用性。

Conclusion: 该方法能够有效解决高维参数空间中逆问题的挑战，提供对可能参数分布的全面可视化分析，源代码已公开。

Abstract: Recently, neural surrogate models have emerged as a compelling alternative to
traditional simulation workflows. This is accomplished by modeling the
underlying function of scientific simulations, removing the need to run
expensive simulations. Beyond just mapping from input parameter to output,
surrogates have also been shown useful for inverse problems: output to input
parameters. Inverse problems can be understood as search, where we aim to find
parameters whose surrogate outputs contain a specified feature. Yet finding
these parameters can be costly, especially for high-dimensional parameter
spaces. Thus, existing surrogate-based solutions primarily focus on finding a
small set of matching parameters, in the process overlooking the broader
picture of plausible parameters. Our work aims to model and visualize the
distribution of possible input parameters that produce a given output feature.
To achieve this goal, we aim to address two challenges: (1) the approximation
error inherent in the surrogate model and (2) forming the parameter
distribution in an interactive manner. We model error via density estimation,
reporting high density only if a given parameter configuration is close to
training parameters, measured both over the input and output space. Our density
estimate is used to form a prior belief on parameters, and when combined with a
likelihood on features, gives us an efficient way to sample plausible parameter
configurations that generate a target output feature. We demonstrate the
usability of our solution through a visualization interface by performing
feature-driven parameter analysis over the input parameter space of three
simulation datasets. Source code is available at
https://github.com/matthewberger/seeing-the-many

</details>


### [285] [Fairness Regularization in Federated Learning](https://arxiv.org/abs/2508.12042)
*Zahra Kharaghani,Ali Dadras,Tommy Löfstedt*

Main category: cs.LG

TL;DR: 该论文研究了联邦学习中的性能公平性问题，提出了FairGrad和FairGrad*两种梯度方差正则化方法，在异构数据环境下能同时提升公平性和整体模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据异构性可能导致某些客户端对全局模型产生不成比例的影响，造成性能差异。现有公平性方法在异构数据环境下的有效性尚不明确，不同方法之间的关系也缺乏深入理解。

Method: 研究专注于性能公平性方法，特别评估了显式正则化客户端损失的公平性方法。提出了FairGrad（近似）和FairGrad*（精确）两种梯度方差正则化变体，用于实现性能公平性。

Result: 从理论上解释了所研究公平性方法之间的联系，实证表明FairGrad和FairGrad*在异构数据设置中能同时改善公平性和整体模型性能。

Conclusion: 提出的梯度方差正则化方法为联邦学习中的性能公平性问题提供了有效解决方案，在保持隐私保护的同时实现了更好的公平性和模型性能。

Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine
learning that enables collaborative training across decentralized data sources
without exchanging raw data. This approach not only addresses privacy concerns
but also allows access to overall substantially larger and potentially more
diverse datasets, without the need for centralized storage or hardware
resources. However, heterogeneity in client data may cause certain clients to
have disproportionate impacts on the global model, leading to disparities in
the clients' performances. Fairness, therefore, becomes a crucial concern in FL
and can be addressed in various ways. However, the effectiveness of existing
fairness-aware methods, particularly in heterogeneous data settings, remains
unclear, and the relationships between different approaches are not well
understood. In this work, we focus on performance equitable fairness, which
aims to minimize differences in performance across clients. We restrict our
study to fairness-aware methods that explicitly regularize client losses,
evaluating both existing and newly proposed approaches. We identify and
theoretically explain connections between the investigated fairness methods,
and empirically show that FairGrad (approximate) and FairGrad* (exact) (two
variants of a gradient variance regularization method introduced here for
performance equitable fairness) improve both fairness and overall model
performance in heterogeneous data settings.

</details>


### [286] [VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks](https://arxiv.org/abs/2508.12061)
*Daria Diatlova,Nikita Balagansky,Alexander Varlamov,Egor Spirin*

Main category: cs.LG

TL;DR: VARAN是一个动态层聚合框架，通过输入相关的权重分配和专门化的探测头，为每个输入自适应地选择最相关的特征层，解决了传统静态聚合方法的信息瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统的自监督语音模型微调中，使用最终层或加权求和的层聚合方法存在信息瓶颈问题，且对所有数据样本采用静态的特征权重分配，无法根据输入内容动态调整。

Method: 采用层专门化的探测头和输入相关的权重分配机制，VARAN框架能够根据每个输入的具体内容自适应地优先选择不同层的特征，特别结合LoRA微调技术使用。

Result: 在自动语音识别和语音情感识别任务上的评估表明，VARAN表现出优越的性能，特别是在使用LoRA微调技术时效果更加显著。

Conclusion: 该框架成功解决了在保持层特定信息和实现灵活特征利用之间的权衡问题，推进了自监督语音表示的高效适应。

Abstract: Conventional methods for aggregating layers in fine-tuned self-supervised
speech models, such as using the final layer or weighted sum, suffer from
information bottlenecks and static feature weighting for all dataset examples.
We propose VARAN, a framework that dynamically tailors layer aggregation to
individual inputs. By employing layer-specialized probing heads and
data-dependent weighting, VARAN adaptively prioritizes layer's features based
on input. Evaluations on automatic speech recognition and speech emotion
recognition tasks demonstrate VARAN's superior performance, particularly when
using the LoRA fine-tuning technique. The framework resolves the trade-off
between preserving layer-specific information and enabling flexible feature
utilization, advancing efficient adaptation of self-supervised speech
representations.

</details>


### [287] [Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks](https://arxiv.org/abs/2508.12079)
*Ningzhe Shi,Yiqing Zhou,Ling Liu,Jinglin Shi,Yihao Wu,Haiwei Shi,Hanxiao Yu*

Main category: cs.LG

TL;DR: 本文提出了一种用于ISAC-AIGC网络的内容准确性和质量感知服务评估指标(CAQA)，并开发了LPDRL-F算法来解决三维资源分配问题，显著提升了平均CAQA性能。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC服务假设输入数据准确，只关注内容生成质量，但在ISAC-AIGC网络中，内容生成基于不准确的感知数据，且AIGC模型本身存在生成误差，需要新的评估指标和资源优化方法。

Method: 提出CAQA评估指标，并设计LP引导的深度强化学习算法(LPDRL-F)，通过LP指导和动作过滤器将三维解空间转换为二维，降低复杂度同时提升DRL学习性能。

Result: 相比现有DRL和生成扩散模型算法，LPDRL-F收敛速度快60%以上，找到更好的资源分配方案，平均CAQA提升超过14%；相比仅关注CGQ的方案，平均CAQA提升超过50%。

Conclusion: CAQA指标能有效评估ISAC-AIGC服务质量，LPDRL-F算法能高效解决三维资源分配问题，显著提升系统性能，为ISAC-AIGC网络的实际部署提供了重要技术支撑。

Abstract: Integrated sensing and communication (ISAC) can enhance artificial
intelligence-generated content (AIGC) networks by providing efficient sensing
and transmission. Existing AIGC services usually assume that the accuracy of
the generated content can be ensured, given accurate input data and prompt,
thus only the content generation quality (CGQ) is concerned. However, it is not
applicable in ISAC-based AIGC networks, where content generation is based on
inaccurate sensed data. Moreover, the AIGC model itself introduces generation
errors, which depend on the number of generating steps (i.e., computing
resources). To assess the quality of experience of ISAC-based AIGC services, we
propose a content accuracy and quality aware service assessment metric (CAQA).
Since allocating more resources to sensing and generating improves content
accuracy but may reduce communication quality, and vice versa, this
sensing-generating (computing)-communication three-dimensional resource
tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all
users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution
space that grows exponentially with users. To solve the CAQA-AIGC problem with
low complexity, a linear programming (LP) guided deep reinforcement learning
(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the
LP-guided approach and the action filter, LPDRL-F can transform the original
three-dimensional solution space to two dimensions, reducing complexity while
improving the learning performance of DRL. Simulations show that compared to
existing DRL and generative diffusion model algorithms without LP, LPDRL-F
converges faster by over 60% and finds better resource allocation solutions,
improving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an
improvement in AvgCAQA of more than 50% compared to existing schemes focusing
solely on CGQ.

</details>


### [288] [Generative Medical Event Models Improve with Scale](https://arxiv.org/abs/2508.12104)
*Shane Waxler,Paul Blazek,Davis White,Daniel Sneider,Kevin Chung,Mani Nagarathnam,Patrick Williams,Hank Voeller,Karen Wong,Matthew Swanhorst,Sheng Zhang,Naoto Usuyama,Cliff Wong,Tristan Naumann,Hoifung Poon,Andrew Loza,Daniella Meeker,Seth Hain,Rahul Shah*

Main category: cs.LG

TL;DR: CoMET是基于160亿次就诊、3亿患者记录的医疗事件数据训练的生成式基础模型，通过自回归生成医疗事件来模拟患者健康时间线，在78个医疗任务中无需微调即可超越或匹配专用监督模型。


<details>
  <summary>Details</summary>
Motivation: 实现规模化个性化医疗需要从纵向患者旅程中提取洞察，基础模型预训练在大规模医疗事件数据上是扩展真实世界证据生成和泛化到多样化下游任务的有前景方向。

Method: 使用Epic Cosmos数据集（163亿次就诊、3亿患者记录）训练CoMET模型家族，采用仅解码器Transformer架构，预训练118百万患者的1150亿离散医疗事件，进行最大规模的医疗数据缩放定律研究。

Result: CoMET在诊断预测、疾病预后和医疗运营等78个真实世界任务中，无需任务特定微调或少量样本，普遍优于或匹配专用监督模型，预测能力随模型规模和预训练规模持续提升。

Conclusion: 生成式医疗事件基础模型CoMET能有效捕捉复杂临床动态，为支持临床决策、简化医疗运营和改善患者结局提供可扩展和可泛化的框架。

Abstract: Realizing personalized medicine at scale calls for methods that distill
insights from longitudinal patient journeys, which can be viewed as a sequence
of medical events. Foundation models pretrained on large-scale medical event
data represent a promising direction for scaling real-world evidence generation
and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with
medical events from de-identified longitudinal health records for 16.3 billion
encounters over 300 million unique patient records from 310 health systems, we
introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of
decoder-only transformer models pretrained on 118 million patients representing
115 billion discrete medical events (151 billion tokens). We present the
largest scaling-law study for medical event data, establishing a methodology
for pretraining and revealing power-law scaling relationships for compute,
tokens, and model size. Based on this, we pretrained a series of
compute-optimal models with up to 1 billion parameters. Conditioned on a
patient's real-world history, CoMET autoregressively generates the next medical
event, simulating patient health timelines. We studied 78 real-world tasks,
including diagnosis prediction, disease prognosis, and healthcare operations.
Remarkably for a foundation model with generic pretraining and simulation-based
inference, CoMET generally outperformed or matched task-specific supervised
models on these tasks, without requiring task-specific fine-tuning or few-shot
examples. CoMET's predictive power consistently improves as the model and
pretraining scale. Our results show that CoMET, a generative medical event
foundation model, can effectively capture complex clinical dynamics, providing
an extensible and generalizable framework to support clinical decision-making,
streamline healthcare operations, and improve patient outcomes.

</details>


### [289] [BUILDA: A Thermal Building Data Generation Framework for Transfer Learning](https://arxiv.org/abs/2508.12703)
*Thomas Krug,Fabian Raisch,Dominik Aimer,Markus Wirnsberger,Ferdinand Sigg,Benjamin Schäfer,Benjamin Tischler*

Main category: cs.LG

TL;DR: BuilDa是一个建筑热力学数据生成框架，无需深厚建筑模拟知识即可生成大量高质量合成数据，用于迁移学习研究


<details>
  <summary>Details</summary>
Motivation: 当前缺乏足够质量和数量的建筑热数据来支持迁移学习研究，现有数据生成方法需要专业知识且无法满足需求

Method: 使用单区域Modelica模型导出为FMU并在Python中模拟，构建数据生成框架

Result: 成功生成数据并用于迁移学习模型的预训练和微调

Conclusion: BuilDa框架能够有效解决建筑热数据缺乏问题，为迁移学习研究提供必要的数据支持

Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal
dynamics. Therefore, many new TL research areas emerge in the field, such as
selecting the right source model for TL. However, these research directions
require massive amounts of thermal building data which is lacking presently.
Neither public datasets nor existing data generators meet the needs of TL
research in terms of data quality and quantity. Moreover, existing data
generation approaches typically require expert knowledge in building
simulation. We present BuilDa, a thermal building data generation framework for
producing synthetic data of adequate quality and quantity for TL research. The
framework does not require profound building simulation knowledge to generate
large volumes of data. BuilDa uses a single-zone Modelica model that is
exported as a Functional Mock-up Unit (FMU) and simulated in Python. We
demonstrate BuilDa by generating data and utilizing it for pretraining and
fine-tuning TL models.

</details>


### [290] [DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections](https://arxiv.org/abs/2508.12116)
*Haebin Shin,Lei Ji,Xiao Liu,Zhiwei Yu,Qi Chen,Yeyun Gong*

Main category: cs.LG

TL;DR: DynamixSFT是一种动态自动化指令调优数据集混合优化方法，通过多臂老虎机框架和先验缩放玻尔兹曼探索来动态平衡数据集采样概率，在Tulu-v2-mixture上实现了2.2%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着指令调优数据集的不断涌现，如何在训练过程中动态平衡和优化这些数据集的混合比例成为一个关键挑战。

Method: 将问题建模为多臂老虎机框架，提出先验缩放玻尔兹曼探索方法，使用轻量级1步前瞻奖励来更新采样概率，保持原始数据集比例的软锚定。

Result: 在包含16个指令调优数据集的Tulu-v2-mixture集合上，DynamixSFT在10个基准测试中实现了高达2.2%的性能改进。

Conclusion: 该方法能够有效动态优化指令调优数据集的混合比例，同时保持数据集的多样性和覆盖范围，为数据集混合优化提供了新的解决方案。

Abstract: As numerous instruction-tuning datasets continue to emerge during the
post-training stage, dynamically balancing and optimizing their mixtures has
become a critical challenge. To address this, we propose DynamixSFT, a dynamic
and automated method for instruction-tuning dataset mixture optimization. We
formulate the problem as a multi-armed bandit setup and introduce a
Prior-scaled Boltzmann Exploration that softly anchors the updated sampling
distribution to the original dataset proportions, thereby preserving the
inherent diversity and coverage of the collection. Sampling probabilities are
updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the
dataset contributes to improving the model's performance at its current state.
When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning
datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10
benchmarks. Furthermore, we provide a comprehensive analysis and visualizations
to offer deeper insights into the adaptive dynamics of our method.

</details>


### [291] [Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks](https://arxiv.org/abs/2508.12121)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 门控机制在RNN中通过耦合状态空间时间尺度和参数空间动力学，在固定学习率下隐式产生自适应学习率行为，起到数据驱动预处理器的作用。


<details>
  <summary>Details</summary>
Motivation: 研究门控RNN如何在固定全局学习率训练下，通过门控机制隐式实现自适应学习率调整，揭示门控对梯度传播和参数更新的系统影响。

Method: 推导泄漏积分器和门控RNN的精确雅可比矩阵，获得一阶展开分析门控如何重塑梯度传播、调节有效步长并引入参数更新各向异性。

Result: 门控不仅控制隐藏状态记忆保留，还作为数据驱动预处理器适应参数空间优化轨迹，与学习率调度、动量和Adam等方法存在形式类比。数值实验验证了微扰分析的有效性。

Conclusion: 提供了统一的动力学系统视角，解释了门控如何耦合状态演化与参数更新，说明门控架构在实践中实现鲁棒可训练性和稳定性的原因。

Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly
induce adaptive learning-rate behavior, even when training is carried out with
a fixed, global learning rate. This effect arises from the coupling between
state-space time scales--parametrized by the gates--and parameter-space
dynamics during gradient descent. By deriving exact Jacobians for
leaky-integrator and gated RNNs, we obtain a first-order expansion that makes
explicit how constant, scalar, and multi-dimensional gates reshape gradient
propagation, modulate effective step sizes, and introduce anisotropy in
parameter updates. These findings reveal that gates not only control memory
retention in the hidden states, but also act as data-driven preconditioners
that adapt optimization trajectories in parameter space. We further draw formal
analogies with learning-rate schedules, momentum, and adaptive methods such as
Adam, showing that these optimization behaviors emerge naturally from gating.
Numerical experiments confirm the validity of our perturbative analysis,
supporting the view that gate-induced corrections remain small while exerting
systematic effects on training dynamics. Overall, this work provides a unified
dynamical-systems perspective on how gating couples state evolution with
parameter updates, explaining why gated architectures achieve robust
trainability and stability in practice.

</details>


### [292] [DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy](https://arxiv.org/abs/2508.12145)
*Frederik L. Dennig,Daniel A. Keim*

Main category: cs.LG

TL;DR: DE-VAE是一种基于微分熵的不确定性感知变分自编码器，用于改进参数化和可逆投影，在处理分布外样本时表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自编码器方法在处理数据空间或嵌入空间的分布外样本时表现不佳，需要一种能够分析嵌入不确定性的改进方法。

Method: 使用微分熵的变分自编码器，学习从原始空间到2D空间的映射及其逆映射，基于固定投影进行训练。

Result: 在四个知名数据集上的定量和定性评估显示，DE-VAE在保持与其他AE方法相当精度的同时，能够分析嵌入不确定性。

Conclusion: DE-VAE能够创建准确且可逆的参数化投影，同时提供嵌入不确定性的分析能力，在处理分布外样本方面优于基线方法。

Abstract: Recently, autoencoders (AEs) have gained interest for creating parametric and
invertible projections of multidimensional data. Parametric projections make it
possible to embed new, unseen samples without recalculating the entire
projection, while invertible projections allow the synthesis of new data
instances. However, existing methods perform poorly when dealing with
out-of-distribution samples in either the data or embedding space. Thus, we
propose DE-VAE, an uncertainty-aware variational AE using differential entropy
(DE) to improve the learned parametric and invertible projections. Given a
fixed projection, we train DE-VAE to learn a mapping into 2D space and an
inverse mapping back to the original space. We conduct quantitative and
qualitative evaluations on four well-known datasets, using UMAP and t-SNE as
baseline projection methods. Our findings show that DE-VAE can create
parametric and inverse projections with comparable accuracy to other current
AE-based approaches while enabling the analysis of embedding uncertainty.

</details>


### [293] [AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis](https://arxiv.org/abs/2508.12162)
*J. M. I. H. Jayakody,A. M. H. H. Alahakoon,C. R. M. Perera,R. M. L. C. Srimal,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.LG

TL;DR: 提出了一种名为AICRN的新型深度学习架构，用于回归关键ECG参数，通过空间和通道注意力机制提高ECG分析的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统ECG分析存在人为错误导致注意力不集中的问题，需要开发能够快速准确检测心脏事件的自动化系统，提高心脏疾病诊断的精确度和预测能力。

Method: 使用注意力集成卷积残差网络(AICRN)，结合空间和通道注意力机制来处理ECG特征的类型和空间位置，采用卷积残差网络解决梯度消失和爆炸问题。

Result: AICRN模型在参数回归方面优于现有模型，具有更高的精确度，能够减少手动分析工作量。

Conclusion: 深度学习可以在ECG分析的可解释性和精确性方面发挥关键作用，为心脏监测和管理开辟新的临床应用。

Abstract: The paradigm of electrocardiogram (ECG) analysis has evolved into real-time
digital analysis, facilitated by artificial intelligence (AI) and machine
learning (ML), which has improved the diagnostic precision and predictive
capacity of cardiac diseases. This work proposes a novel deep learning (DL)
architecture called the attention-integrated convolutional residual network
(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,
the QRS duration, the heart rate, the peak amplitude of the R wave, and the
amplitude of the T wave for interpretable ECG analysis. Our architecture is
specially designed with spatial and channel attention-related mechanisms to
address the type and spatial location of the ECG features for regression. The
models employ a convolutional residual network to address vanishing and
exploding gradient problems. The designed system addresses traditional analysis
challenges, such as loss of focus due to human errors, and facilitates the fast
and easy detection of cardiac events, thereby reducing the manual efforts
required to solve analysis tasks. AICRN models outperform existing models in
parameter regression with higher precision. This work demonstrates that DL can
play a crucial role in the interpretability and precision of ECG analysis,
opening up new clinical applications for cardiac monitoring and management.

</details>


### [294] [ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression](https://arxiv.org/abs/2508.12212)
*Chuanliu Fan,Zicheng Ma,Jun Gao,Nan Yu,Jun Zhang,Ziqiang Cao,Yi Qin Gao,Guohong Fu*

Main category: cs.LG

TL;DR: ProtTeX-CC是一个轻量级的两阶段压缩框架，通过联合嵌入压缩和自压缩模块，将蛋白质输入长度减少约93.68%，在少样本设置下显著提升ProtTeX模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决ProtTeX模型在处理多模态蛋白质信息时的两个主要限制：序列和结构标记的连接导致蛋白质长度加倍并破坏模态间对齐；受限于训练语料和上下文窗口，无法进行上下文学习。

Method: 两阶段压缩框架：1）联合嵌入压缩机制在残基级别融合序列和结构表示，将输入长度减半；2）自压缩模块将完整演示聚合到最后几个语言标记的潜在空间中，大幅压缩演示长度。

Result: 在16-shot设置下实现约93.68%的总提示长度压缩比。蛋白质功能预测实验中，域内基准性能提升2%，域外数据集性能提升11%。

Conclusion: ProtTeX-CC通过轻量级压缩框架有效解决了多模态蛋白质建模的长度和上下文学习问题，显著提升了模型性能，且仅需少量额外参数。

Abstract: Recent advances in protein large language models, such as ProtTeX, represent
both side-chain amino acids and backbone structure as discrete token sequences
of residue length. While this design enables unified modeling of multimodal
protein information, it suffers from two major limitations: (1) The
concatenation of sequence and structure tokens approximately doubles the
protein length and breaks the intrinsic residue-level alignment between
modalities. (2) Constrained by the training corpus and limited context window,
ProtTeX is typically trained on single-protein inputs, rendering it
incompatible with in-context learning (ICL) and thus limiting its
generalization capability. To address these issues, we propose ProtTeX-CC, a
lightweight two-stage compression framework designed to enhance ProtTeX under
few-shot settings. We first design a joint embedding compression mechanism that
fuses sequence and structure representations at the residue level, effectively
reducing the protein input length by half without sacrificing performance. Then
we propose a self-compression module that aggregates each full demonstration
into the latent space of the last few linguistic tokens, reducing the average
demonstration length from 751 tokens to less than 16 tokens. Compared to the
original ProtTeX, our self-compression approach achieves a compression ratio of
approximately 93.68% in the total prompt length under the 16-shot setting.
Without modifying the backbone model, ProtTeX-CC introduces only a small number
of additional parameters through PEFT-based tuning in the joint embedding
compression stage and a single trainable projection layer in the
self-compression stage. Extensive experiments on protein function prediction
show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and
generalizes well to the out-of-domain dataset with a performance gain of 11%.

</details>


### [295] [Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models](https://arxiv.org/abs/2508.12220)
*Abdullah X*

Main category: cs.LG

TL;DR: 该论文提出了一个针对大语言模型遗忘权（GDPR第17条）的系统化解决方案，通过记录训练过程的确定性重放来实现精确的数据删除，同时提供了多种互补路径来满足延迟和可用性要求。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型如何实现"被遗忘权"（GDPR要求），将遗忘问题转化为可复现的系统工程问题，确保模型能够精确删除特定数据而不影响其他数据。

Method: 将训练过程视为确定性程序，记录每个微批次的元数据（ID哈希、RNG种子、学习率值、优化器步数计数器等），在确定性内核下重放训练过程并过滤要遗忘的数据，实现与仅在保留集上训练相同的参数结果。

Result: 在满足前提条件的受控运行中，证明了模型和优化器状态的字节级一致性，验证了该方法的精确性，并报告了存储/延迟预算。

Conclusion: 提出的方法为大规模语言模型实现数据遗忘权提供了可行的系统化解决方案，通过确定性重放和多种互补技术路径，能够在保证精确性的同时满足实际部署的延迟和可用性要求。

Abstract: We study the right to be forgotten (GDPR Art. 17) for large language models
and frame unlearning as a reproducible systems problem. Our approach treats
training as a deterministic program and logs a minimal per-microbatch record
(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and
accumulation boundary). Under a pinned stack and deterministic kernels,
replaying the training tail while filtering only the forget closure yields the
same parameters as training on the retain set (bit-identical in the training
dtype) when preconditions hold. To meet latency and availability constraints,
we add complementary paths: (i) exact reverts of recent steps via
micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion
when the base is frozen, and (iii) a curvature-guided anti-update followed by a
short retain-tune, audit-gated with escalation to exact replay. We report
storage/latency budgets and a toy artifact validating mechanics; in a
controlled run that satisfies the preconditions we demonstrate byte-identical
equality of model and optimizer states.

</details>


### [296] [Distribution Matching via Generalized Consistency Models](https://arxiv.org/abs/2508.12222)
*Sagar Shrestha,Rajesh Shrestha,Tri Nguyen,Subash Timilsina*

Main category: cs.LG

TL;DR: 提出了一种基于一致性模型的分布匹配新方法，结合了连续归一化流模型的简单目标函数和GAN的灵活性，解决了GAN训练中的双级优化和模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 生成模型在分布匹配任务中发挥重要作用，但GAN存在训练困难、双级min-max优化和模式崩溃等问题，需要更稳定有效的替代方法。

Method: 受连续归一化流(CNF)中一致性模型的启发，提出新的分布匹配方法，继承了CNF的直接范数最小化目标，同时保持类似GAN的约束适应性。

Result: 通过理论验证和合成/真实数据集实验证明了该方法的性能表现。

Conclusion: 该方法为分布匹配任务提供了更稳定有效的解决方案，结合了CNF和GAN的优势。

Abstract: Recent advancement in generative models have demonstrated remarkable
performance across various data modalities. Beyond their typical use in data
synthesis, these models play a crucial role in distribution matching tasks such
as latent variable modeling, domain translation, and domain adaptation.
Generative Adversarial Networks (GANs) have emerged as the preferred method of
distribution matching due to their efficacy in handling high-dimensional data
and their flexibility in accommodating various constraints. However, GANs often
encounter challenge in training due to their bi-level min-max optimization
objective and susceptibility to mode collapse. In this work, we propose a novel
approach for distribution matching inspired by the consistency models employed
in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF
models, such as having a straight forward norm minimization objective, while
remaining adaptable to different constraints similar to GANs. We provide
theoretical validation of our proposed objective and demonstrate its
performance through experiments on synthetic and real-world datasets.

</details>


### [297] [Communication-Efficient Distributed Asynchronous ADMM](https://arxiv.org/abs/2508.12233)
*Sagar Shrestha*

Main category: cs.LG

TL;DR: 提出在异步ADMM中引入粗粒度量化来减少通信开销，适用于大规模联邦学习和分布式优化


<details>
  <summary>Details</summary>
Motivation: 分布式优化和联邦学习中，异步ADMM虽然具有优势，但通信成本可能成为瓶颈，特别是在节点通信预算有限或数据量巨大时

Method: 在异步交替方向乘子法(ADMM)中引入粗粒度量化技术，对需要交换的数据进行量化处理以减少通信量

Result: 通过实验验证了该方法在多个分布式学习任务（包括神经网络）中的收敛性

Conclusion: 粗粒度量化是减少异步ADMM通信开销的有效方法，适用于大规模联邦学习和分布式优化应用

Abstract: In distributed optimization and federated learning, asynchronous alternating
direction method of multipliers (ADMM) serves as an attractive option for
large-scale optimization, data privacy, straggler nodes and variety of
objective functions. However, communication costs can become a major bottleneck
when the nodes have limited communication budgets or when the data to be
communicated is prohibitively large. In this work, we propose introducing
coarse quantization to the data to be exchanged in aynchronous ADMM so as to
reduce communication overhead for large-scale federated learning and
distributed optimization applications. We experimentally verify the convergence
of the proposed method for several distributed learning tasks, including neural
networks.

</details>


### [298] [CC-Time: Cross-Model and Cross-Modality Time Series Forecasting](https://arxiv.org/abs/2508.12235)
*Peng Chen,Yihang Wang,Yang Shu,Yunyao Cheng,Kai Zhao,Zhongwen Rao,Lujia Pan,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CC-Time是一个结合预训练语言模型和时间序列模型的跨模态跨模型学习方法，通过文本描述和时间序列数据的联合建模，在时间序列预测任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练语言模型的时间序列预测方法未能充分发挥语言模型的强大序列建模能力，预测精度不够理想。为了解决这个问题，研究者希望探索语言模型在时间序列预测中的潜力，包括能够建模哪些时间序列特征，以及是否单独使用语言模型就足够。

Method: 提出CC-Time方法，包含两个核心部分：1）跨模态学习，通过时间序列序列和对应文本描述联合建模时间依赖性和通道相关性；2）跨模型融合块，自适应整合语言模型和时间序列模型的知识，形成更全面的时间序列模式建模。

Result: 在9个真实世界数据集上的大量实验表明，CC-Time在完整数据训练和少样本学习情况下都达到了最先进的预测精度。

Conclusion: CC-Time通过跨模态和跨模型学习有效提升了预训练语言模型在时间序列预测中的性能，证明了结合语言模型和时间序列专业模型的优势。

Abstract: With the success of pre-trained language models (PLMs) in various application
fields beyond natural language processing, language models have raised emerging
attention in the field of time series forecasting (TSF) and have shown great
prospects. However, current PLM-based TSF methods still fail to achieve
satisfactory prediction accuracy matching the strong sequential modeling power
of language models. To address this issue, we propose Cross-Model and
Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We
explore the potential of PLMs for time series forecasting from two aspects: 1)
what time series features could be modeled by PLMs, and 2) whether relying
solely on PLMs is sufficient for building time series models. In the first
aspect, CC-Time incorporates cross-modality learning to model temporal
dependency and channel correlations in the language model from both time series
sequences and their corresponding text descriptions. In the second aspect,
CC-Time further proposes the cross-model fusion block to adaptively integrate
knowledge from the PLMs and time series model to form a more comprehensive
modeling of time series patterns. Extensive experiments on nine real-world
datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy
in both full-data training and few-shot learning situations.

</details>


### [299] [DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning](https://arxiv.org/abs/2508.12244)
*Fan Li,Xiaoyang Wang,Wenjie Zhang,Ying Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: 提出了DHG-Bench，这是第一个深度超图学习的综合基准测试，包含20个数据集和16种最先进的超图神经网络算法，在统一的数据处理和实验协议下进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有的超图神经网络方法缺乏全面的基准测试，导致在数据集覆盖、算法性能评估和实验可比性方面存在障碍，阻碍了对深度超图学习进展的理解。

Method: 构建了包含20个多样化数据集的综合基准，涵盖节点级、边级和图级任务，整合了16种最先进的HNN算法，采用一致的数据处理和实验协议，从效果、效率、鲁棒性和公平性四个维度系统评估算法特性。

Result: 广泛的实验揭示了现有算法的优势和固有局限性，为未来研究提供了有价值的见解和方向。

Conclusion: DHG-Bench填补了深度超图学习领域基准测试的空白，通过系统化的评估框架促进了该领域的可重复研究和未来发展。

Abstract: Although conventional deep graph models have achieved great success in
relational learning, their focus on pairwise relationships limits their
capacity to learn pervasive higher-order interactions in real-world complex
systems, which can be naturally modeled as hypergraphs. To tackle this,
hypergraph neural networks (HNNs), the dominant approach in deep hypergraph
learning (DHGL), has garnered substantial attention in recent years. Despite
the proposal of numerous HNN methods, there is no comprehensive benchmark for
HNNs, which creates a great obstacle to understanding the progress of DHGL in
several aspects: (i) insufficient coverage of datasets, algorithms, and tasks;
(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent
dataset usage, preprocessing, and experimental setups that hinder
comparability. To fill the gap, we introduce DHG-Bench, the first comprehensive
benchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets
spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art
HNN algorithms, under consistent data processing and experimental protocols.
Our benchmark systematically investigates the characteristics of HNNs in terms
of four dimensions: effectiveness, efficiency, robustness, and fairness.
Further, to facilitate reproducible research, we have developed an easy-to-use
library for training and evaluating different HNN methods. Extensive
experiments conducted with DHG-Bench reveal both the strengths and inherent
limitations of existing algorithms, offering valuable insights and directions
for future research. The code is publicly available at:
https://github.com/Coco-Hut/DHG-Bench.

</details>


### [300] [STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction](https://arxiv.org/abs/2508.12247)
*Haolong Chen,Liang Zhang,Zhengyuan Xin,Guangxu Zhu*

Main category: cs.LG

TL;DR: 提出了STM2和STM3模型，通过多尺度Mamba架构和自适应图因果卷积网络，有效解决长时空依赖学习中的多尺度信息提取和建模难题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以高效学习复杂的长期时空依赖关系，特别是在多尺度信息提取和跨节点多尺度时间信息建模方面存在挑战。

Method: STM2采用多尺度Mamba架构捕获多尺度信息，结合自适应图因果卷积网络学习复杂时空依赖；STM3进一步引入混合专家架构，包含更稳定的路由策略和因果对比学习策略。

Result: 在真实世界基准测试中表现出优越性能，在长期时空时间序列预测方面达到最先进水平。

Conclusion: 提出的STM2/STM3模型能够有效解决长期时空依赖学习中的多尺度挑战，通过创新的架构设计实现了更好的模式解耦和路由平滑性。

Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet
existing deep learning methods struggle with learning complex long-term
spatio-temporal dependencies efficiently. The long-term spatio-temporal
dependency learning brings two new challenges: 1) The long-term temporal
sequence includes multiscale information naturally which is hard to extract
efficiently; 2) The multiscale temporal information from different nodes is
highly correlated and hard to model. To address these challenges, we propose an
efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale
\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture
the multiscale information efficiently and simultaneously, and an adaptive
graph causal convolution network to learn the complex multiscale
spatio-temporal dependency. STM2 includes hierarchical information aggregation
for different-scale information that guarantees their distinguishability. To
capture diverse temporal dynamics across all spatial nodes more efficiently, we
further propose an enhanced version termed
\textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of
\textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special
Mixture-of-Experts architecture, including a more stable routing strategy and a
causal contrastive learning strategy to enhance the scale distinguishability.
We prove that STM3 has much better routing smoothness and guarantees the
pattern disentanglement for each expert successfully. Extensive experiments on
real-world benchmarks demonstrate STM2/STM3's superior performance, achieving
state-of-the-art results in long-term spatio-temporal time-series prediction.

</details>


### [301] [Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset](https://arxiv.org/abs/2508.12253)
*Manish Shukla*

Main category: cs.LG

TL;DR: 提出一个统一框架，使用LIME和SHAP解释时间序列预测，结合梯度提升树和ARIMA模型，通过滞后特征和季节性编码来解释预测方差。


<details>
  <summary>Details</summary>
Motivation: 传统ARIMA模型可解释但难以处理非线性，而树模型如XGBoost准确但缺乏可解释性，需要一种方法既能保持高精度又能提供模型解释。

Method: 将单变量时间序列转换为无泄漏的监督学习问题，训练梯度提升树和ARIMA基线模型，然后应用LIME和SHAP进行事后可解释性分析。

Result: 在Air Passengers数据集上的案例研究表明，少量滞后特征（特别是12个月滞后）和季节性编码能够解释大部分预测方差。

Conclusion: 提出了应用LIME和SHAP到时间序列的方法论，提供了理论阐述、实证评估和实践指南，为时间序列预测提供了可解释的解决方案。

Abstract: Time-series forecasting underpins critical decisions across aviation, energy,
retail and health. Classical autoregressive integrated moving average (ARIMA)
models offer interpretability via coefficients but struggle with
nonlinearities, whereas tree-based machine-learning models such as XGBoost
deliver high accuracy but are often opaque. This paper presents a unified
framework for interpreting time-series forecasts using local interpretable
model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We
convert a univariate series into a leakage-free supervised learning problem,
train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc
explainability. Using the Air Passengers dataset as a case study, we show that
a small set of lagged features -- particularly the twelve-month lag -- and
seasonal encodings explain most forecast variance. We contribute: (i) a
methodology for applying LIME and SHAP to time series without violating
chronology; (ii) theoretical exposition of the underlying algorithms; (iii)
empirical evaluation with extensive analysis; and (iv) guidelines for
practitioners.

</details>


### [302] [L-SR1: Learned Symmetric-Rank-One Preconditioning](https://arxiv.org/abs/2508.12270)
*Gal Lifshitz,Shahar Zuler,Ori Fouks,Dan Raviv*

Main category: cs.LG

TL;DR: 提出了一种新颖的学习型二阶优化器，通过可训练预处理单元增强经典SR1算法，在单目人体网格恢复任务中优于现有学习方法


<details>
  <summary>Details</summary>
Motivation: 端到端深度学习依赖大数据集且泛化性差，传统优化方法计算高效但收敛慢，学习型二阶优化方法研究不足

Method: 引入可训练预处理单元生成数据驱动向量，构建满足割线约束的正半定秩一矩阵，通过学习投影对齐约束

Result: 在分析实验和单目人体网格恢复任务中表现优异，超越现有学习优化方法，具有轻量化和无需标注数据的特点

Conclusion: 该方法提供了强大的泛化能力，适合集成到更广泛的优化框架中，为学习型二阶优化开辟了新方向

Abstract: End-to-end deep learning has achieved impressive results but remains limited
by its reliance on large labeled datasets, poor generalization to unseen
scenarios, and growing computational demands. In contrast, classical
optimization methods are data-efficient and lightweight but often suffer from
slow convergence. While learned optimizers offer a promising fusion of both
worlds, most focus on first-order methods, leaving learned second-order
approaches largely unexplored.
  We propose a novel learned second-order optimizer that introduces a trainable
preconditioning unit to enhance the classical Symmetric-Rank-One (SR1)
algorithm. This unit generates data-driven vectors used to construct positive
semi-definite rank-one matrices, aligned with the secant constraint via a
learned projection. Our method is evaluated through analytic experiments and on
the real-world task of Monocular Human Mesh Recovery (HMR), where it
outperforms existing learned optimization-based approaches. Featuring a
lightweight model and requiring no annotated data or fine-tuning, our approach
offers strong generalization and is well-suited for integration into broader
optimization-based frameworks.

</details>


### [303] [CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision](https://arxiv.org/abs/2508.12278)
*Siyue Xie,Da Sun Handason Tam,Wing Cheong Lau*

Main category: cs.LG

TL;DR: CRoC是一个用于图异常检测的简单有效框架，通过上下文重构和对比学习，在有限标签数据下显著提升GNN性能


<details>
  <summary>Details</summary>
Motivation: 解决图异常检测中标签数据稀缺、异常样本稀少且可能伪装的问题，利用类别不平衡特性来改进GNN训练

Method: 通过重构节点上下文构建增强图，保持交互模式但重组节点属性；分别编码异质关系并整合到消息传递过程；结合对比学习范式利用未标记数据

Result: 在7个真实GAD数据集上测试，相比基线GNN提升高达14% AUC，在有限标签设置下优于最先进方法

Conclusion: CRoC框架有效解决了GAD中的标签稀缺问题，通过上下文重构和对比学习实现了更好的异常检测性能

Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various
graph-related tasks, with their effectiveness in analyzing graph-structured
data. However, training robust GNNs often demands abundant labeled data, which
is a critical bottleneck in real-world applications. This limitation severely
impedes progress in Graph Anomaly Detection (GAD), where anomalies are
inherently rare, costly to label, and may actively camouflage their patterns to
evade detection. To address these problems, we propose Context Refactoring
Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by
jointly leveraging limited labeled and abundant unlabeled data. Different from
previous works, CRoC exploits the class imbalance inherent in GAD to refactor
the context of each node, which builds augmented graphs by recomposing the
attributes of nodes while preserving their interaction patterns. Furthermore,
CRoC encodes heterogeneous relations separately and integrates them into the
message-passing process, enhancing the model's capacity to capture complex
interaction semantics. These operations preserve node semantics while
encouraging robustness to adversarial camouflage, enabling GNNs to uncover
intricate anomalous cases. In the training stage, CRoC is further integrated
with the contrastive learning paradigm. This allows GNNs to effectively harness
unlabeled data during joint training, producing richer, more discriminative
node embeddings. CRoC is evaluated on seven real-world GAD datasets with
varying scales. Extensive experiments demonstrate that CRoC achieves up to 14%
AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods
under limited-label settings.

</details>


### [304] [Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings](https://arxiv.org/abs/2508.12327)
*Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 分析了Lion优化器的收敛性能，包括标准版本、方差缩减版本、分布式版本以及通信高效的分布式变体，并给出了各自的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 研究Lion优化器的理论收敛性质，特别是在分布式设置下的性能表现，旨在提高优化算法的效率和通信效率。

Method: 通过理论分析建立Lion优化器的收敛速率，引入方差缩减技术改进收敛性能，并设计通信高效的分布式变体使用符号压缩技术。

Result: 标准Lion收敛速率为O(d^{1/2}T^{-1/4})，方差缩减版本为O(d^{1/2}T^{-1/3})；分布式版本分别为O(d^{1/2}(nT)^{-1/4})和O(d^{1/2}(nT)^{-1/3})；通信高效变体达到O(max{d^{1/4}/T^{1/4}, d^{1/10}/(n^{1/5}T^{1/5})})和O(d^{1/4}/T^{1/4})。

Conclusion: Lion优化器具有良好的收敛性能，方差缩减和通信高效技术能显著提升收敛速率，特别是在分布式环境下表现优异。

Abstract: In this paper, we analyze the convergence properties of the Lion optimizer.
First, we establish that the Lion optimizer attains a convergence rate of
$\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes
the problem dimension and $T$ is the iteration number. To further improve this
rate, we introduce the Lion optimizer with variance reduction, resulting in an
enhanced convergence rate of $\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in
distributed settings, where the standard and variance reduced version of the
distributed Lion can obtain the convergence rates of
$\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with
$n$ denoting the number of nodes. Furthermore, we investigate a
communication-efficient variant of the distributed Lion that ensures sign
compression in both communication directions. By employing the unbiased sign
operations, the proposed Lion variant and its variance reduction counterpart,
achieve convergence rates of $\mathcal{O}\left( \max
\left\{\frac{d^{1/4}}{T^{1/4}}, \frac{d^{1/10}}{n^{1/5}T^{1/5}} \right\}
\right)$ and $\mathcal{O}\left( \frac{d^{1/4}}{T^{1/4}} \right)$, respectively.

</details>


### [305] [Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2508.12361)
*Xun Su,Jianming Huang,Yang Yusen,Zhongxi Fang,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 该论文针对扩散模型中的推理时缩放问题，提出了Funnel Schedule和Adaptive Temperature两种策略来解决探索-利用困境，在保持NFE不变的情况下显著提升了样本质量。


<details>
  <summary>Details</summary>
Motivation: 当前SMC方法在扩散模型应用中面临早期噪声样本难以准确评估但改进潜力大，而后期样本可可靠评估但基本不可逆的困境，需要解决这种探索-利用权衡问题。

Method: 提出了两种策略：1）Funnel Schedule - 逐步减少维护的粒子数量；2）Adaptive Temperature - 降低早期阶段奖励的影响权重。这些方法针对扩散模型的生成动力学和相变行为进行了专门设计。

Result: 在多个基准测试和最先进的文本到图像扩散模型上的实验结果表明，该方法优于之前的基线方法，显著提升了样本质量。

Conclusion: 通过从搜索算法角度出发设计的简单而有效的方法，成功解决了扩散模型中推理时缩放的探索-利用困境，在不增加噪声函数评估次数的情况下实现了更好的性能。

Abstract: Inference-time scaling has achieved remarkable success in language models,
yet its adaptation to diffusion models remains underexplored. We observe that
the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems
from globally fitting the The reward-tilted distribution, which inherently
preserves diversity during multi-modal search. However, current applications of
SMC to diffusion models face a fundamental dilemma: early-stage noise samples
offer high potential for improvement but are difficult to evaluate accurately,
whereas late-stage samples can be reliably assessed but are largely
irreversible. To address this exploration-exploitation trade-off, we approach
the problem from the perspective of the search algorithm and propose two
strategies: Funnel Schedule and Adaptive Temperature. These simple yet
effective methods are tailored to the unique generation dynamics and
phase-transition behavior of diffusion models. By progressively reducing the
number of maintained particles and down-weighting the influence of early-stage
rewards, our methods significantly enhance sample quality without increasing
the total number of Noise Function Evaluations. Experimental results on
multiple benchmarks and state-of-the-art text-to-image diffusion models
demonstrate that our approach outperforms previous baselines.

</details>


### [306] [Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification](https://arxiv.org/abs/2508.12418)
*Rachael DeVries,Casper Christensen,Marie Lisandra Zepeda Mendoza,Ole Winther*

Main category: cs.LG

TL;DR: 提出了Bi-Axial Transformer (BAT)模型，通过同时关注临床变量和时间轴两个维度来处理电子健康记录数据，在脓毒症预测任务上达到最先进性能，并对数据缺失具有更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录(EHRs)数据日益复杂，包含更大数据集、更长的时间序列和多模态集成。传统的Transformer模型在处理EHR分类时受到数据表示的限制，无法有效处理数据稀疏性和信息缺失问题。

Method: 开发了Bi-Axial Transformer (BAT)模型，该模型同时关注临床变量轴和时间点轴两个维度，学习更丰富的数据关系，解决数据稀疏性难题。

Result: BAT在脓毒症预测任务上达到最先进性能，在死亡率分类任务上与顶级方法竞争力相当。相比其他Transformer模型，BAT对数据缺失具有更强的鲁棒性，并能学习可用于迁移学习的独特传感器嵌入。

Conclusion: BAT模型通过双轴注意力机制有效处理EHR数据的复杂性和稀疏性，为EHR分析提供了新的解决方案，同时重新实现了基线模型以便复现和未来基准测试。

Abstract: Electronic Health Records (EHRs), the digital representation of a patient's
medical history, are a valuable resource for epidemiological and clinical
research. They are also becoming increasingly complex, with recent trends
indicating larger datasets, longer time series, and multi-modal integrations.
Transformers, which have rapidly gained popularity due to their success in
natural language processing and other domains, are well-suited to address these
challenges due to their ability to model long-range dependencies and process
data in parallel. But their application to EHR classification remains limited
by data representations, which can reduce performance or fail to capture
informative missingness. In this paper, we present the Bi-Axial Transformer
(BAT), which attends to both the clinical variable and time point axes of EHR
data to learn richer data relationships and address the difficulties of data
sparsity. BAT achieves state-of-the-art performance on sepsis prediction and is
competitive to top methods for mortality classification. In comparison to other
transformers, BAT demonstrates increased robustness to data missingness, and
learns unique sensor embeddings which can be used in transfer learning.
Baseline models, which were previously located across multiple repositories or
utilized deprecated libraries, were re-implemented with PyTorch and made
available for reproduction and future benchmarking.

</details>


### [307] [Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features](https://arxiv.org/abs/2508.12440)
*Ahmet Bilal Arıkan,Şener Özönder,Mustafa Taha Koçyiğit,Hüseyin Oktay Altun,H. Kübra Küçükkartal,Murat Arslanoğlu,Fatih Çağırankaya,Berk Ayvaz*

Main category: cs.LG

TL;DR: 提出了一个从2D工程图纸自动估算制造成本的机器学习框架，通过提取200多个几何和统计特征，使用梯度提升决策树模型实现约10%的平均绝对百分比误差，并提供成本驱动因素的可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 传统制造报价流程需要大量人工工艺规划，过程劳动密集且耗时，需要一种自动化、可扩展的成本估算解决方案来缩短报价周期并提供一致透明的成本评估。

Method: 从13,684个汽车悬架和转向部件DWG图纸中提取约200个几何和统计描述符，使用XGBoost、CatBoost和LightGBM等梯度提升决策树模型进行训练，并结合SHAP等可解释性工具分析成本驱动因素。

Result: 模型在24个产品组中实现了接近10%的平均绝对百分比误差，表现出良好的可扩展性，超越了特定部件的启发式方法，能够识别旋转维度最大值、圆弧统计和发散度量等关键几何设计驱动因素。

Conclusion: 该端到端CAD到成本管道缩短了报价交付时间，确保跨部件系列的一致透明成本评估，为工业4.0制造环境中实时、ERP集成的决策支持提供了可部署的路径。

Abstract: We present an integrated machine learning framework that transforms how
manufacturing cost is estimated from 2D engineering drawings. Unlike
traditional quotation workflows that require labor-intensive process planning,
our approach about 200 geometric and statistical descriptors directly from
13,684 DWG drawings of automotive suspension and steering parts spanning 24
product groups. Gradient-boosted decision tree models (XGBoost, CatBoost,
LightGBM) trained on these features achieve nearly 10% mean absolute percentage
error across groups, demonstrating robust scalability beyond part-specific
heuristics. By coupling cost prediction with explainability tools such as SHAP,
the framework identifies geometric design drivers including rotated dimension
maxima, arc statistics and divergence metrics, offering actionable insights for
cost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead
times, ensures consistent and transparent cost assessments across part families
and provides a deployable pathway toward real-time, ERP-integrated decision
support in Industry 4.0 manufacturing environments.

</details>


### [308] [Local Cluster Cardinality Estimation for Adaptive Mean Shift](https://arxiv.org/abs/2508.12450)
*Étienne Pepin*

Main category: cs.LG

TL;DR: 提出了一种自适应均值漂移算法，通过局部距离分布估计聚类基数，动态调整带宽和核半径阈值，在变尺度数据集上表现优异


<details>
  <summary>Details</summary>
Motivation: 传统KDE方法只能提供聚类局部区域信息，无法处理具有变化局部尺度和聚类基数的数据集，需要开发能够自适应调整参数的方法

Method: 利用点到所有其他点的局部距离分布，通过识别距离分布密度中的局部最小值来估计局部聚类基数，基于基数估计计算整个聚类的局部参数，在均值漂移执行过程中自适应调整带宽和核半径阈值

Result: 该算法在原始数据集上优于最近提出的自适应均值漂移方法，在更广泛的聚类基准测试中表现出竞争力

Conclusion: 基于局部距离分布的自适应参数调整方法能有效处理变尺度聚类问题，提高了均值漂移算法在复杂数据集上的性能

Abstract: This article presents an adaptive mean shift algorithm designed for datasets
with varying local scale and cluster cardinality. Local distance distributions,
from a point to all others, are used to estimate the cardinality of the local
cluster by identifying a local minimum in the density of the distance
distribution. Based on these cardinality estimates, local cluster parameters
are then computed for the entire cluster in contrast to KDE-based methods,
which provide insight only into localized regions of the cluster. During the
mean shift execution, the cluster cardinality estimate is used to adaptively
adjust the bandwidth and the mean shift kernel radius threshold. Our algorithm
outperformed a recently proposed adaptive mean shift method on its original
dataset and demonstrated competitive performance on a broader clustering
benchmark.

</details>


### [309] [Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX](https://arxiv.org/abs/2508.12485)
*Aayush Gupta,Arpit Bhayani*

Main category: cs.LG

TL;DR: Cold-RL是一个基于强化学习的缓存淘汰策略，通过深度Q网络替代NGINX中的LRU算法，在严格微秒级时延预算下显著提升缓存命中率


<details>
  <summary>Details</summary>
Motivation: 传统LRU缓存淘汰策略对对象大小不敏感，在周期性突发流量和混合对象大小场景下容易出现抖动问题，需要更智能的淘汰机制

Method: 使用双决斗深度Q网络作为ONNX侧车服务，每次淘汰时从K个最近最少使用对象中提取6个轻量级特征，在500微秒超时内决策淘汰对象，离线通过NGINX访问日志在缓存模拟器中训练

Result: 在25MB缓存下命中率从0.1436提升至0.3538（146%提升），100MB时从0.7530提升至0.8675（15%提升），400MB时与传统方法相当（约0.918），推理增加不到2%CPU开销，95%分位淘汰时延在预算内

Conclusion: 这是首个集成到NGINX中具有严格SLO的强化学习淘汰策略，在严格时延约束下显著提升了缓存性能

Abstract: Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.

</details>


### [310] [Cost-Aware Contrastive Routing for LLMs](https://arxiv.org/abs/2508.12491)
*Reza Shirkavand,Shangqian Gao,Peiran Yu,Heng Huang*

Main category: cs.LG

TL;DR: CSCR是一个轻量级框架，通过将提示和模型映射到共享嵌入空间，实现快速、成本敏感的LLM路由选择，在多个基准测试中比基线方法提升25%的准确率-成本权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视提示特定上下文、依赖昂贵的模型分析、假设固定专家集或使用低效的试错策略，需要更高效的成本感知路由方案。

Method: 使用紧凑的logit足迹（开源模型）和困惑度指纹（黑盒API）映射到共享嵌入空间，通过对比编码器训练选择最便宜准确的专家，推理时通过FAISS索引进行k-NN查找。

Result: 在多个基准测试中 consistently优于基线方法，准确率-成本权衡提升达25%，对未见过的LLM和分布外提示具有鲁棒泛化能力。

Conclusion: CSCR提供了一个高效、轻量级的成本感知路由框架，支持动态专家池变化，实现微秒级延迟，无需重新训练。

Abstract: We study cost-aware routing for large language models across diverse and
dynamic pools of models. Existing approaches often overlook prompt-specific
context, rely on expensive model profiling, assume a fixed set of experts, or
use inefficient trial-and-error strategies. We introduce Cost-Spectrum
Contrastive Routing (CSCR), a lightweight framework that maps both prompts and
models into a shared embedding space to enable fast, cost-sensitive selection.
CSCR uses compact, fast-to-compute logit footprints for open-source models and
perplexity fingerprints for black-box APIs. A contrastive encoder is trained to
favor the cheapest accurate expert within adaptive cost bands. At inference
time, routing reduces to a single k-NN lookup via a FAISS index, requiring no
retraining when the expert pool changes and enabling microsecond latency.
Across multiple benchmarks, CSCR consistently outperforms baselines, improving
the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen
LLMs and out-of-distribution prompts.

</details>


### [311] [Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference](https://arxiv.org/abs/2508.12511)
*Denis Blessing,Julius Berner,Lorenz Richter,Carles Domingo-Enrich,Yuanqi Du,Arash Vahdat,Gerhard Neumann*

Main category: cs.LG

TL;DR: 提出了一种基于信任区域的几何退火方法，用于解决随机最优控制问题，通过逐步逼近目标路径空间测度来改进性能


<details>
  <summary>Details</summary>
Motivation: 解决随机最优控制问题中，当目标测度与先验测度差异较大时，基于梯度的优化方法面临挑战

Method: 通过迭代求解包含信任区域的约束问题，采用几何退火策略从先验测度逐步逼近目标测度，信任区域提供了选择退火路径时间步长的原则性方法

Result: 在多个最优控制应用中显著提升性能，包括基于扩散的采样、转移路径采样和扩散模型微调等任务

Conclusion: 基于信任区域的几何退火方法为解决随机最优控制问题提供了一种系统性的有效方法

Abstract: Solving stochastic optimal control problems with quadratic control costs can
be viewed as approximating a target path space measure, e.g. via gradient-based
optimization. In practice, however, this optimization is challenging in
particular if the target measure differs substantially from the prior. In this
work, we therefore approach the problem by iteratively solving constrained
problems incorporating trust regions that aim for approaching the target
measure gradually in a systematic way. It turns out that this trust region
based strategy can be understood as a geometric annealing from the prior to the
target measure, where, however, the incorporated trust regions lead to a
principled and educated way of choosing the time steps in the annealing path.
We demonstrate in multiple optimal control applications that our novel method
can improve performance significantly, including tasks in diffusion-based
sampling, transition path sampling, and fine-tuning of diffusion models.

</details>


### [312] [Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning](https://arxiv.org/abs/2508.12524)
*Joseph Suárez,Kyoung Whan Choe,David Bloomin,Jianming Gao,Yunkun Li,Yao Feng,Saidinesh Pola,Kun Zhang,Yonghui Zhu,Nikhil Pinnaparaju,Hao Xiang Li,Nishaanth Kanna,Daniel Scott,Ryan Sullivan,Rose S. Shuman,Lucas de Alcântara,Herbie Bradley,Kirsty You,Bo Wu,Yuhao Jiang,Qimai Li,Jiaxin Chen,Louis Castricato,Xiaolong Zhu,Phillip Isola*

Main category: cs.LG

TL;DR: NeurIPS 2023 Neural MMO竞赛吸引了200多名参与者，参赛者训练的目标条件策略能够泛化到训练中未见过的任务、地图和对手。最佳解决方案在单张4090 GPU上训练8小时后，得分比基线高4倍。所有相关资源都已开源。


<details>
  <summary>Details</summary>
Motivation: 举办NeurIPS 2023 Neural MMO竞赛，旨在推动目标条件策略在复杂多智能体环境中的泛化能力研究，测试策略在未见过的任务、地图和对手上的表现。

Method: 竞赛参与者训练目标条件策略，这些策略需要泛化到训练期间未见过的任务、地图和对手。使用单张4090 GPU进行8小时训练。

Result: 竞赛吸引了200多名参与者提交方案，最佳解决方案在8小时训练后得分比基线高4倍，展示了出色的泛化性能。

Conclusion: Neural MMO竞赛成功展示了目标条件策略在复杂环境中的强大泛化能力，开源所有资源（包括基线策略权重、顶级提交的训练代码）将促进该领域进一步研究。

Abstract: We present the results of the NeurIPS 2023 Neural MMO Competition, which
attracted over 200 participants and submissions. Participants trained
goal-conditional policies that generalize to tasks, maps, and opponents never
seen during training. The top solution achieved a score 4x higher than our
baseline within 8 hours of training on a single 4090 GPU. We open-source
everything relating to Neural MMO and the competition under the MIT license,
including the policy weights and training code for our baseline and for the top
submissions.

</details>


### [313] [Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs](https://arxiv.org/abs/2508.12530)
*Hyunsoo Song,Seungwhan Kim,Seungkyu Lee*

Main category: cs.LG

TL;DR: 提出Latent Reconstruction(LR)损失函数来解决VAE中的后验坍塌问题，无需特定网络架构约束，在多个数据集上验证有效性


<details>
  <summary>Details</summary>
Motivation: 变分自编码器(VAE)存在后验坍塌问题，导致生成样本多样性不足。现有方法需要在重建和正则化之间权衡，或要求网络架构的结构性约束

Method: 定义了局部后验坍塌概念，基于单射函数和复合函数的数学性质提出Latent Reconstruction(LR)损失函数，无需特定架构限制

Result: 在MNIST、fashionMNIST、Omniglot、CelebA和FFHQ等多个数据集上实验验证了该方法能有效控制后验坍塌

Conclusion: LR损失函数提供了一种无需架构约束的后验坍塌控制方法，提高了VAE生成样本的多样性

Abstract: Variational autoencoders (VAEs), one of the most widely used generative
models, are known to suffer from posterior collapse, a phenomenon that reduces
the diversity of generated samples. To avoid posterior collapse, many prior
works have tried to control the influence of regularization loss. However, the
trade-off between reconstruction and regularization is not satisfactory. For
this reason, several methods have been proposed to guarantee latent
identifiability, which is the key to avoiding posterior collapse. However, they
require structural constraints on the network architecture. For further
clarification, we define local posterior collapse to reflect the importance of
individual sample points in the data space and to relax the network constraint.
Then, we propose Latent Reconstruction(LR) loss, which is inspired by
mathematical properties of injective and composite functions, to control
posterior collapse without restriction to a specific architecture. We
experimentally evaluate our approach, which controls posterior collapse on
varied datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.

</details>


### [314] [Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](https://arxiv.org/abs/2508.12531)
*Minseon Kim,Jin Myung Kwak,Lama Alssum,Bernard Ghanem,Philip Torr,David Krueger,Fazl Barez,Adel Bibi*

Main category: cs.LG

TL;DR: 通过优化训练超参数和EMA动量技术，可以在微调语言模型时保持安全性而无需额外安全措施


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，证明微调语言模型不一定损害安全性，而是优化选择不当导致安全问题

Method: 系统测试关键训练超参数（学习率、批量大小、梯度步数），提出参数空间的指数移动平均动量技术

Result: 将不安全响应从16%降至约5%，在多个数据集上优于需要额外安全数据的方法

Conclusion: 微调过程中的安全问题可以通过适当的优化策略避免，无需专门干预即可保持模型性能和安全性

Abstract: Fine-tuning language models is commonly believed to inevitably harm their
safety, i.e., refusing to respond to harmful user requests, even when using
harmless datasets, thus requiring additional safety measures. We challenge this
belief through systematic testing, showing that poor optimization choices,
rather than inherent trade-offs, often cause safety problems, measured as
harmful responses to adversarial prompts. By properly selecting key training
hyper-parameters, e.g., learning rate, batch size, and gradient steps, we
reduce unsafe model responses from 16\% to approximately 5\%, as measured by
keyword matching, while maintaining utility performance. Based on this
observation, we propose a simple exponential moving average (EMA) momentum
technique in parameter space that preserves safety performance by creating a
stable optimization path and retains the original pre-trained model's safety
properties. Our experiments on the Llama families across multiple datasets
(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can
largely be avoided without specialized interventions, outperforming existing
approaches that require additional safety data while offering practical
guidelines for maintaining both model performance and safety during adaptation.

</details>


### [315] [Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction](https://arxiv.org/abs/2508.12533)
*Qinwen Ge,Roza G. Bayrak,Anwar Said,Catie Chang,Xenofon Koutsoukos,Tyler Derr*

Main category: cs.LG

TL;DR: 本文从数据为中心的角度系统性地定义和评估了脑图构建的设计空间，通过优化信号处理、拓扑提取和图特征化三个阶段的数据决策，显著提升了脑图分类性能


<details>
  <summary>Details</summary>
Motivation: 当前脑图构建流程过于僵化，忽视了数据层面的关键选择，需要从数据为中心的角度重新审视脑图构建过程

Method: 将脑图构建分为三个设计阶段：时间信号处理、拓扑提取和图特征化，系统评估现有技术的不同组合对下游性能的影响

Result: 在HCP1200和ABIDE数据集上，经过精心设计的数据中心配置相比标准流程显著提高了分类准确率

Conclusion: 上游数据决策对图神经影像学至关重要，需要系统性地探索数据中心设计空间

Abstract: The construction of brain graphs from functional Magnetic Resonance Imaging
(fMRI) data plays a crucial role in enabling graph machine learning for
neuroimaging. However, current practices often rely on rigid pipelines that
overlook critical data-centric choices in how brain graphs are constructed. In
this work, we adopt a Data-Centric AI perspective and systematically define and
benchmark a data-centric design space for brain graph construction,
constrasting with primarily model-centric prior work. We organize this design
space into three stages: temporal signal processing, topology extraction, and
graph featurization. Our contributions lie less in novel components and more in
evaluating how combinations of existing and modified techniques influence
downstream performance. Specifically, we study high-amplitude BOLD signal
filtering, sparsification and unification strategies for connectivity,
alternative correlation metrics, and multi-view node and edge features, such as
incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets
show that thoughtful data-centric configurations consistently improve
classification accuracy over standard pipelines. These findings highlight the
critical role of upstream data decisions and underscore the importance of
systematically exploring the data-centric design space for graph-based
neuroimaging. Our code is available at
https://github.com/GeQinwen/DataCentricBrainGraphs.

</details>


### [316] [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551)
*Hongyu Lin,Yuchen Li,Haoran Luo,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: OS-R1是一个基于规则强化学习的Linux内核调优框架，通过将内核配置空间抽象为RL环境，利用LLM进行高效探索和准确配置修改，在实验中比启发式调优性能提升5.6%


<details>
  <summary>Details</summary>
Motivation: 现有Linux内核调优方法在效率、可扩展性和泛化性方面存在挑战，需要更智能和自动化的解决方案

Method: 提出基于规则强化学习的代理框架，将内核配置抽象为RL环境，设计定制奖励函数增强LLM的推理标准化和配置准确性，采用两阶段训练过程加速收敛

Result: 实验结果显示OS-R1显著优于现有基线方法，性能提升达5.6%，保持高数据效率，且在不同实际应用中具有良好适应性

Conclusion: OS-R1框架展示了在实际多样化环境中部署的潜力，为Linux内核自动调优提供了有效的解决方案

Abstract: Linux kernel tuning is essential for optimizing operating system (OS)
performance. However, existing methods often face challenges in terms of
efficiency, scalability, and generalization. This paper introduces OS-R1, an
agentic Linux kernel tuning framework powered by rule-based reinforcement
learning (RL). By abstracting the kernel configuration space as an RL
environment, OS-R1 facilitates efficient exploration by large language models
(LLMs) and ensures accurate configuration modifications. Additionally, custom
reward functions are designed to enhance reasoning standardization,
configuration modification accuracy, and system performance awareness of the
LLMs. Furthermore, we propose a two-phase training process that accelerates
convergence and minimizes retraining across diverse tuning scenarios.
Experimental results show that OS-R1 significantly outperforms existing
baseline methods, achieving up to 5.6% performance improvement over heuristic
tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across
various real-world applications, demonstrating its potential for practical
deployment in diverse environments. Our dataset and code are publicly available
at https://github.com/LHY-24/OS-R1.

</details>


### [317] [Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](https://arxiv.org/abs/2508.12555)
*Junpeng Wang,Yuzhong Chen,Menghai Pan,Chin-Chia Michael Yeh,Mahashweta Das*

Main category: cs.LG

TL;DR: 提出了一种可视化分析系统，用于帮助ML科学家更好地审查和调整基于LLM的编码代理的行为，支持代码级、流程级和LLM级的比较分析。


<details>
  <summary>Details</summary>
Motivation: 当前手动检查编码代理输出的方式效率低下，难以追踪代码演进、比较编码迭代和识别改进机会，需要更有效的分析工具。

Method: 开发了一个可视化分析系统，专注于AIDE框架，支持三个层次的分析：代码级分析（调试和代码精炼）、流程级分析（不同解决方案探索过程对比）和LLM级分析（不同LLM的编码行为差异）。

Result: 通过Kaggle竞赛案例研究，展示了系统如何提供对迭代编码过程的宝贵洞察，帮助科学家更有效地进行调试和提示工程。

Conclusion: 该系统为ML科学家提供了结构化理解编码代理行为的能力，显著提升了编码代理行为的审查和优化效率。

Abstract: Coding agents powered by large language models (LLMs) have gained traction
for automating code generation through iterative problem-solving with minimal
human involvement. Despite the emergence of various frameworks, e.g.,
LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review
and adjust the agents' coding process. The current approach of manually
inspecting individual outputs is inefficient, making it difficult to track code
evolution, compare coding iterations, and identify improvement opportunities.
To address this challenge, we introduce a visual analytics system designed to
enhance the examination of coding agent behaviors. Focusing on the AIDE
framework, our system supports comparative analysis across three levels: (1)
Code-Level Analysis, which reveals how the agent debugs and refines its code
over iterations; (2) Process-Level Analysis, which contrasts different
solution-seeking processes explored by the agent; and (3) LLM-Level Analysis,
which highlights variations in coding behavior across different LLMs. By
integrating these perspectives, our system enables ML scientists to gain a
structured understanding of agent behaviors, facilitating more effective
debugging and prompt engineering. Through case studies using coding agents to
tackle popular Kaggle competitions, we demonstrate how our system provides
valuable insights into the iterative coding process.

</details>


### [318] [Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition](https://arxiv.org/abs/2508.12565)
*Luke Li*

Main category: cs.LG

TL;DR: 基于VMD分解和LSTM的融合时间序列预测模型，通过滑动窗口和变分模态分解提升金融时间序列预测精度和稳定性


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的非稳定性和复杂性导致传统预测模型效果不佳，需要通过信号分解技术提升模型的适应能力

Method: 采用滑动窗口构建数据集，使用VMD技术将金融时间序列分解为平滑子分量，然后输入LSTM深度学习模型进行预测

Result: 与直接使用原始时间序列的LSTM模型相比，VMD处理后的模型显示出更好的预测性能和更高的稳定性

Conclusion: VMD分解技术能够有效提升金融时间序列预测模型的效果，为复杂金融数据的预测提供了一种有效的处理方法

Abstract: To address the complexity of financial time series, this paper proposes a
forecasting model combining sliding window and variational mode decomposition
(VMD) methods. Historical stock prices and relevant market indicators are used
to construct datasets. VMD decomposes non-stationary financial time series into
smoother subcomponents, improving model adaptability. The decomposed data is
then input into a deep learning model for prediction. The study compares the
forecasting effects of an LSTM model trained on VMD-processed sequences with
those using raw time series, demonstrating better performance and stability.

</details>


### [319] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于度量-辛括号形式的多尺度系统粗粒化机器学习框架，能够保持热力学定律、动量守恒和涨落-耗散平衡，并通过自监督学习识别涌现的结构变量。


<details>
  <summary>Details</summary>
Motivation: 多尺度系统模拟困难，粗粒化过程中信息熵损失导致涌现物理现象具有耗散性、历史依赖性和随机性，需要新的机器学习方法来准确捕获这些特性。

Method: 使用度量-辛括号形式主义构建框架，确保热力学第一、第二定律、动量守恒和涨落-耗散平衡的离散保持，采用自监督学习策略识别熵状态变量。

Result: 在基准系统和两个挑战性示例（星形聚合物粗粒化和胶体悬浮液高速视频分析）上验证了方法的有效性，成功保持了非平衡统计特性。

Conclusion: 该框架为粒子系统的大规模推理提供了开源实现（PyTorch和LAMMPS），能够扩展到多样化的粒子系统，有效解决了多尺度系统粗粒化建模的关键挑战。

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


### [320] [Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM](https://arxiv.org/abs/2508.12575)
*Zohra Yagoub,Hafida Bouziane*

Main category: cs.LG

TL;DR: 本研究利用预训练蛋白质大语言模型提取序列上下文特征，结合双向LSTM和GRU网络来预测肽和蛋白质中的淀粉样蛋白形成区域，取得了84.5%的交叉验证准确率和83%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 淀粉样蛋白形成预测是生物信息学的重要研究方向，现有方法主要基于进化模式和氨基酸个体特性，而基于序列信息的特征显示出很高的预测性能，因此探索大语言模型在此领域的应用潜力。

Method: 使用预训练蛋白质大语言模型提取蛋白质序列的上下文特征，然后采用双向LSTM和GRU神经网络架构来预测淀粉样蛋白形成区域。

Result: 在10折交叉验证中达到84.5%的准确率，在测试数据集上达到83%的准确率，表现出具有竞争力的性能。

Conclusion: 研究结果表明大语言模型在提高淀粉样蛋白预测准确性方面具有巨大潜力，为蛋白质功能预测提供了新的技术路径。

Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal
point of ongoing bioinformatics. The crucial step in this field is to apply
advanced computational methodologies. Many recent approaches to predicting
amyloidogenicity within proteins are highly based on evolutionary motifs and
the individual properties of amino acids. It is becoming increasingly evident
that the sequence information-based features show high predictive performance.
Consequently, our study evaluated the contextual features of protein sequences
obtained from a pretrained protein large language model leveraging
bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and
protein sequences. Our method achieved an accuracy of 84.5% on 10-fold
cross-validation and an accuracy of 83% in the test dataset. Our results
demonstrate competitive performance, highlighting the potential of LLMs in
enhancing the accuracy of amyloid prediction.

</details>


### [321] [Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg](https://arxiv.org/abs/2508.12576)
*Like Jian,Dong Liu*

Main category: cs.LG

TL;DR: 论文证明在联邦学习中，随着神经网络宽度增加，数据异质性的影响会减小，当宽度趋于无穷时完全消失，此时FedAvg能达到与集中式学习相同的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中由于客户端数据非独立同分布带来的数据异质性挑战，提高全局模型在异构本地数据分布上的泛化能力。

Method: 分析过参数化FedAvg与梯度下降的收敛性，理论证明网络宽度增加对数据异质性影响的减弱效应，并在无限宽度下证明FedAvg等同于线性模型。

Result: 理论分析和大量实验表明，随着网络宽度增加，数据异质性影响减小，无限宽度时FedAvg能达到与集中式学习相同的泛化性能。

Conclusion: 增加神经网络宽度可以有效缓解联邦学习中的数据异质性问题，在无限宽度极限下FedAvg能够实现与集中式学习相当的泛化性能。

Abstract: Federated learning (FL) enables decentralized clients to train a model
collaboratively without sharing local data. A key distinction between FL and
centralized learning is that clients' data are non-independent and identically
distributed, which poses significant challenges in training a global model that
generalizes well across heterogeneous local data distributions. In this paper,
we analyze the convergence of overparameterized FedAvg with gradient descent
(GD). We prove that the impact of data heterogeneity diminishes as the width of
neural networks increases, ultimately vanishing when the width approaches
infinity. In the infinite-width regime, we further prove that both the global
and local models in FedAvg behave as linear models, and that FedAvg achieves
the same generalization performance as centralized learning with the same
number of GD iterations. Extensive experiments validate our theoretical
findings across various network architectures, loss functions, and optimization
methods.

</details>


### [322] [Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding](https://arxiv.org/abs/2508.12590)
*Jihoon Park,Seungeun Oh,Seong-Lyun Kim*

Main category: cs.LG

TL;DR: 提出了一种基于token级过滤的混合语言模型推理方法，通过认知不确定性和注意力重要性评估，只上传信息丰富的token，显著降低了能耗和通信成本。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境中设备端LLM推理的需求，现有混合语言模型研究主要关注准确性和延迟，但忽视了通信和能源效率问题。

Method: 采用token级过滤机制，结合认知不确定性和基于注意力的重要性评估，选择性地只上传信息丰富的token到云端LLM进行处理。

Result: 实验显示相比标准HLM节省40.7%能耗，BERT Score达到87.5%，token吞吐量0.37 tokens/秒；相比U-HLM基线，BERTScore从85.8%提升到87.0%，能耗节省从31.6%提升到43.6%，吞吐量从0.36提升到0.40。

Conclusion: 该方法能够在带宽受限的边缘环境中实现能源高效且准确的LLM部署，为资源受限设备上的大语言模型推理提供了实用解决方案。

Abstract: To address the growing demand for on-device LLM inference in
resource-constrained environments, hybrid language models (HLM) have emerged,
combining lightweight local models with powerful cloud-based LLMs. Recent
studies on HLM have primarily focused on improving accuracy and latency, while
often overlooking communication and energy efficiency. We propose a token-level
filtering mechanism for an energy-efficient importance- and uncertainty-aware
HLM inference that leverages both epistemic uncertainty and attention-based
importance. Our method opportunistically uploads only informative tokens,
reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and
LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and
token throughput of 0.37 tokens/sec while saving the energy consumption by
40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM
baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings
from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an
energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge
environments.

</details>


### [323] [Physics-informed deep operator network for traffic state estimation](https://arxiv.org/abs/2508.12593)
*Zhihao Li,Ting Wang,Guojian Zou,Ruofei Wang,Ye Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息的深度算子网络(PI-DeepONet)框架来解决交通状态估计问题，相比传统PINNs方法，该框架将交通流守恒定律直接整合到算子学习过程中，在NGSIM数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 交通状态估计需要从有限的噪声测量中求解高维时空偏微分方程，传统物理信息神经网络(PINNs)逐点强制PDE约束存在局限性，需要更有效的物理约束学习方法。

Method: 采用物理信息深度算子网络框架，将TSE重新表述为算子学习问题，训练参数化神经算子从稀疏输入数据映射到完整时空交通状态场，直接整合交通流守恒模型和基本图到算子学习过程中。

Result: 在NGSIM数据集上的实验表明，该方法优于最先进的基线方法，分析揭示了最优函数生成策略和分支网络复杂性的见解，证明了所提框架的鲁棒性和有效性。

Conclusion: PI-DeepONet框架通过将物理约束直接整合到算子学习中，能够确保物理一致性同时捕捉拥堵传播、空间相关性和时间演化，为交通状态估计提供了有效的解决方案。

Abstract: Traffic state estimation (TSE) fundamentally involves solving
high-dimensional spatiotemporal partial differential equations (PDEs) governing
traffic flow dynamics from limited, noisy measurements. While Physics-Informed
Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a
physics-informed deep operator network (PI-DeepONet) framework that
reformulates TSE as an operator learning problem. Our approach trains a
parameterized neural operator that maps sparse input data to the full
spatiotemporal traffic state field, governed by the traffic flow conservation
law. Crucially, unlike PINNs that enforce PDE constraints point-wise,
PI-DeepONet integrates traffic flow conservation model and the fundamental
diagram directly into the operator learning process, ensuring physical
consistency while capturing congestion propagation, spatial correlations, and
temporal evolution. Experiments on the NGSIM dataset demonstrate superior
performance over state-of-the-art baselines. Further analysis reveals insights
into optimal function generation strategies and branch network complexity.
Additionally, the impact of input function generation methods and the number of
functions on model performance is explored, highlighting the robustness and
efficacy of proposed framework.

</details>


### [324] [FLARE: Fast Low-rank Attention Routing Engine](https://arxiv.org/abs/2508.12594)
*Vedant Puri,Aditya Joglekar,Kevin Ferguson,Yu-hsuan Chen,Yongjie Jessica Zhang,Levent Burak Kara*

Main category: cs.LG

TL;DR: FLARE是一种线性复杂度的自注意力机制，通过固定长度的潜在序列路由注意力，解决了传统自注意力二次复杂度在大规模非结构化网格上的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统自注意力机制的二次计算复杂度限制了其在大规模非结构化网格上的应用和可扩展性，需要开发更高效的注意力机制。

Method: 通过可学习的查询令牌将输入序列投影到固定长度的潜在序列（M << N），在瓶颈序列中路由注意力，学习低秩形式的注意力，实现O(NM)的计算成本。

Result: FLARE不仅能够扩展到前所未有的问题规模，而且在各种基准测试中相比最先进的神经PDE代理模型提供了更优越的准确性。

Conclusion: FLARE通过低秩注意力路由机制成功实现了线性复杂度的自注意力，为大规模非结构化网格处理提供了高效解决方案，并发布了新的增材制造数据集促进进一步研究。

Abstract: The quadratic complexity of self-attention limits its applicability and
scalability on large unstructured meshes. We introduce Fast Low-rank Attention
Routing Engine (FLARE), a linear complexity self-attention mechanism that
routes attention through fixed-length latent sequences. Each attention head
performs global communication among $N$ tokens by projecting the input sequence
onto a fixed length latent sequence of $M \ll N$ tokens using learnable query
tokens. By routing attention through a bottleneck sequence, FLARE learns a
low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only
scales to unprecedented problem sizes, but also delivers superior accuracy
compared to state-of-the-art neural PDE surrogates across diverse benchmarks.
We also release a new additive manufacturing dataset to spur further research.
Our code is available at https://github.com/vpuri3/FLARE.py.

</details>


### [325] [Constructing Invariant and Equivariant Operations by Symmetric Tensor Network](https://arxiv.org/abs/2508.12596)
*Meng Zhang,Chao Wang,Hao Zhang,Shaojun Dong,Lixin He*

Main category: cs.LG

TL;DR: 提出了一种系统性的方法来构建有效的不变和等变操作，能够处理不同秩的笛卡尔张量和不同类型的球面张量，并利用对称张量网络的图形表示简化证明和构造过程。


<details>
  <summary>Details</summary>
Motivation: 设计包含对称性的神经网络对于几何深度学习至关重要，核心是开发不变和等变操作，需要系统的方法来处理不同类型的张量输入输出。

Method: 使用对称张量网络的图形表示方法，系统构建不变和等变操作，支持不同秩的笛卡尔张量和不同类型的球面张量。

Result: 成功开发了系统性的构建方法，简化了不变和等变函数的证明和构造过程，并应用于几何图神经网络和材料本构律学习的等变机器学习模型。

Conclusion: 该方法为几何深度学习提供了一种有效的工具，能够系统性地构建不变和等变操作，在多个应用领域展示了实用价值。

Abstract: Design of neural networks that incorporate symmetry is crucial for geometric
deep learning. Central to this effort is the development of invariant and
equivariant operations. This works presents a systematic method for
constructing valid invariant and equivariant operations. It can handle inputs
and outputs in the form of Cartesian tensors with different rank, as well as
spherical tensors with different types. In addition, our method features a
graphical representation utilizing the symmetric tensor network, which
simplifies both the proofs and constructions related to invariant and
equivariant functions. We also apply this approach to design the equivariant
interaction message for the geometry graph neural network, and equivariant
machine learning model to learn the constitutive law of materials.

</details>


### [326] [A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators](https://arxiv.org/abs/2508.12602)
*Hansol Lim,Jongseong Brad Choi,Jee Won Lee,Haeseong Jeoung,Minkyu Han*

Main category: cs.LG

TL;DR: 提出了一种基于傅里叶神经算子和可微分物理模块的混合代理模型，用于电动汽车参数估计和能耗预测，仅需速度和加速度输入即可输出多种物理参数，在真实数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统电动汽车能耗模型需要大量参数且缺乏适应性，需要开发能够从简单传感器数据中自动学习物理参数并准确预测能耗的智能模型。

Method: 结合谱参数算子（基于傅里叶神经算子）和可微分物理模块的混合架构，通过速度和加速度输入估计电机效率、再生制动效率、空气阻力等参数，并直接计算电池功率。

Result: 在特斯拉Model 3、Model S和起亚EV9真实数据上测试，平均绝对误差分别为0.2kW（约高速牵引功率的1%）和0.8kW，具有良好的泛化能力。

Conclusion: 该框架具有可解释性，能泛化到未见条件和采样率，适用于路径优化、生态路由、车载诊断和健康预测管理等实际应用。

Abstract: We present a hybrid surrogate model for electric vehicle parameter estimation
and power consumption. We combine our novel architecture Spectral Parameter
Operator built on a Fourier Neural Operator backbone for global context and a
differentiable physics module in the forward pass. From speed and acceleration
alone, it outputs time-varying motor and regenerative braking efficiencies, as
well as aerodynamic drag, rolling resistance, effective mass, and auxiliary
power. These parameters drive a physics-embedded estimate of battery power,
eliminating any separate physics-residual loss. The modular design lets
representations converge to physically meaningful parameters that reflect the
current state and condition of the vehicle. We evaluate on real-world logs from
a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean
absolute error of 0.2kW (about 1% of average traction power at highway speeds)
for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is
interpretable, and it generalizes well to unseen conditions, and sampling
rates, making it practical for path optimization, eco-routing, on-board
diagnostics, and prognostics health management.

</details>


### [327] [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](https://arxiv.org/abs/2508.12604)
*Yuyang Xu,Yi Cheng,Haochao Ying,Zhuoyun Du,Renjun Hu,Xing Shi,Wei Lin,Jian Wu*

Main category: cs.LG

TL;DR: SSPO是一种无需辅助模型或人工标注的RL过程监督框架，通过模型自身生成的步骤偏好信号来优化推理过程，解决LLM推理中的错误累积和过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 现有后训练方法（如带CoT推理的RL）计算开销大，错误答案部分源于冗长推理过程缺乏自我修正，导致错误在多步骤中累积。

Method: 提出Self-traced Step-wise Preference Optimization (SSPO)，可插拔的RL过程监督框架，利用模型自身生成的步骤级偏好信号进行细粒度优化，实现推理压缩。

Result: 实验表明SSPO生成的推理序列既准确又简洁，有效缓解过度思考行为，在不同领域和语言中不损害模型性能。

Conclusion: SSPO提供了一种高效的无监督方法来解决LLM推理过程中的错误累积问题，显著提升推理效率和质量。

Abstract: Test-time scaling has proven effective in further enhancing the performance
of pretrained Large Language Models (LLMs). However, mainstream post-training
methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)
reasoning) often incur substantial computational overhead due to auxiliary
models and overthinking. In this paper, we empirically reveal that the
incorrect answers partially stem from verbose reasoning processes lacking
correct self-fix, where errors accumulate across multiple reasoning steps. To
this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a
pluggable RL process supervision framework that enables fine-grained
optimization of each reasoning step. Specifically, SSPO requires neither
auxiliary models nor stepwise manual annotations. Instead, it leverages
step-wise preference signals generated by the model itself to guide the
optimization process for reasoning compression. Experiments demonstrate that
the generated reasoning sequences from SSPO are both accurate and succinct,
effectively mitigating overthinking behaviors without compromising model
performance across diverse domains and languages.

</details>


### [328] [How can we trust opaque systems? Criteria for robust explanations in XAI](https://arxiv.org/abs/2508.12623)
*Florian J. Boge,Annika Schuster*

Main category: cs.LG

TL;DR: 该论文提出了可解释人工智能(XAI)的可信度标准，包括解释鲁棒性(ER)和解释方法鲁棒性(EMR)，为建立对深度学习算法的信任提供框架。


<details>
  <summary>Details</summary>
Motivation: 深度学习算法虽然预测准确但内部工作机制不透明，现有XAI方法在性能方面存在疑虑，需要建立可信的解释标准。

Method: 提出并形式化解释鲁棒性(ER)和解释方法鲁棒性(EMR)的标准，开发评估XAI方法可信度的理论框架。

Result: 建立了评估XAI方法可信度的双重标准体系，指出单一方法的鲁棒性不足以确保解释的可信度。

Conclusion: 需要同时满足ER和EMR标准才能确保XAI解释的可信性，为未来研究提供了理论框架和应用方向。

Abstract: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in
scientific research. However, the price we pay for their impressively accurate
predictions is significant: their inner workings are notoriously opaque - it is
unknown to laypeople and researchers alike what features of the data a DL
system focuses on and how it ultimately succeeds in predicting correct outputs.
A necessary criterion for trustworthy explanations is that they should reflect
the relevant processes the algorithms' predictions are based on. The field of
eXplainable Artificial Intelligence (XAI) presents promising methods to create
such explanations. But recent reviews about their performance offer reasons for
skepticism. As we will argue, a good criterion for trustworthiness is
explanatory robustness: different XAI methods produce the same explanations in
comparable contexts. However, in some instances, all methods may give the same,
but still wrong, explanation. We therefore argue that in addition to
explanatory robustness (ER), a prior requirement of explanation method
robustness (EMR) has to be fulfilled by every XAI method. Conversely, the
robustness of an individual method is in itself insufficient for
trustworthiness. In what follows, we develop and formalize criteria for ER as
well as EMR, providing a framework for explaining and establishing trust in DL
algorithms. We also highlight interesting application cases and outline
directions for future work.

</details>


### [329] [FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation](https://arxiv.org/abs/2508.12629)
*Ian Dunn,David R. Koes*

Main category: cs.LG

TL;DR: FlowMol3是一个开源的多模态流匹配模型，通过三种架构无关的技术（自条件、假原子和训练时几何失真）显著提升了全原子小分子生成性能，实现了近100%的分子有效性，并大幅减少了参数数量。


<details>
  <summary>Details</summary>
Motivation: 开发能够生成具有所需属性的真实分子的生成模型，以加速化学发现。现有方法在同时采样分子拓扑和3D结构方面仍有改进空间。

Method: 基于流匹配框架，采用图神经网络架构，引入三种新技术：自条件（self-conditioning）、假原子（fake atoms）和训练时几何失真（train-time geometry distortion）。这些技术不改变基础架构但显著提升性能。

Result: 实现了近100%的药物类分子有效性，更准确地复现训练数据的功能基团组成和几何结构，参数量比可比方法少一个数量级。

Conclusion: 这些简单可迁移的技术能够缓解基于传输的生成模型的普遍病理问题，在推理过程中检测和纠正分布漂移，为扩散和流基分子生成模型提供了改进稳定性和质量的策略。

Abstract: A generative model capable of sampling realistic molecules with desired
properties could accelerate chemical discovery across a wide range of
applications. Toward this goal, significant effort has focused on developing
models that jointly sample molecular topology and 3D structure. We present
FlowMol3, an open-source, multi-modal flow matching model that advances the
state of the art for all-atom, small-molecule generation. Its substantial
performance gains over previous FlowMol versions are achieved without changes
to the graph neural network architecture or the underlying flow matching
formulation. Instead, FlowMol3's improvements arise from three
architecture-agnostic techniques that incur negligible computational cost:
self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3
achieves nearly 100% molecular validity for drug-like molecules with explicit
hydrogens, more accurately reproduces the functional group composition and
geometry of its training data, and does so with an order of magnitude fewer
learnable parameters than comparable methods. We hypothesize that these
techniques mitigate a general pathology affecting transport-based generative
models, enabling detection and correction of distribution drift during
inference. Our results highlight simple, transferable strategies for improving
the stability and quality of diffusion- and flow-based molecular generative
models.

</details>


### [330] [Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery](https://arxiv.org/abs/2508.12650)
*Jiyeon Kang,Songseong Kim,Chanhui Lee,Doyeong Hwang,Joanie Hayoun Chung,Yunkyung Ko,Sumin Lee,Sungwoong Kim,Sungbin Lim*

Main category: cs.LG

TL;DR: 提出了Score-informed Neural Operator (SciNO)方法，通过稳定近似Hessian对角线和保持结构信息来解决现有因果排序方法在计算效率和数值稳定性方面的问题，显著提升了因果发现性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于排序的因果发现方法需要准确估计对数密度的Hessian对角线，但传统方法计算昂贵且内存密集，而DiffAN方法虽然解决了计算问题但仍存在数值不稳定性。

Method: 提出了Score-informed Neural Operator (SciNO)，这是一种在平滑函数空间中的概率生成模型，能够稳定近似Hessian对角线并在分数建模过程中保持结构信息。

Result: 实验结果显示，SciNO在合成图上平均减少42.7%的排序差异，在真实数据集上减少31.5%，同时保持内存效率和可扩展性。

Conclusion: SciNO方法有效解决了现有因果排序方法的计算和稳定性问题，提出的概率控制算法还能增强LLMs的因果推理能力，无需额外微调或提示工程。

Abstract: Ordering-based approaches to causal discovery identify topological orders of
causal graphs, providing scalable alternatives to combinatorial search methods.
Under the Additive Noise Model (ANM) assumption, recent causal ordering methods
based on score matching require an accurate estimation of the Hessian diagonal
of the log-densities. However, previous approaches mainly use Stein gradient
estimators, which are computationally expensive and memory-intensive. Although
DiffAN addresses these limitations by substituting kernel-based estimates with
diffusion models, it remains numerically unstable due to the second-order
derivatives of score models. To alleviate these problems, we propose
Score-informed Neural Operator (SciNO), a probabilistic generative model in
smooth function spaces designed to stably approximate the Hessian diagonal and
to preserve structural information during the score modeling. Empirical results
show that SciNO reduces order divergence by 42.7% on synthetic graphs and by
31.5% on real-world datasets on average compared to DiffAN, while maintaining
memory efficiency and scalability. Furthermore, we propose a probabilistic
control algorithm for causal reasoning with autoregressive models that
integrates SciNO's probability estimates with autoregressive model priors,
enabling reliable data-driven causal ordering informed by semantic information.
Consequently, the proposed method enhances causal reasoning abilities of LLMs
without additional fine-tuning or prompt engineering.

</details>


### [331] [Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering](https://arxiv.org/abs/2508.12672)
*Emmanouil Kritharakis,Dusan Jakovetic,Antonios Makris,Konstantinos Tserpes*

Main category: cs.LG

TL;DR: 提出了一种在联邦学习中抵御拜占庭攻击的新方法，只需要服务器和一个诚实客户端即可有效工作，无需预先知道恶意客户端数量，在多种攻击策略下显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临拜占庭攻击威胁，现有方法通常需要知道恶意客户端数量或依赖多数诚实客户端。本文旨在开发更实用的防御机制，在只有服务器和一个诚实客户端的情况下也能有效工作。

Method: 利用服务器拥有的可信侧数据集，结合至少一个诚实客户端，设计了一种新的联邦学习算法。该方法不需要预先知道恶意客户端数量，通过理论分析确保在有强拜占庭攻击时的有界最优性差距。

Result: 在MNIST、FMNIST和CIFAR-10数据集上的实验表明，该方法在标签翻转、符号翻转和高斯噪声添加等多种攻击策略下，显著优于Mean、Trimmed Mean、Median、Krum和Multi-Krum等标准及鲁棒联邦学习基线方法。

Conclusion: 所提出的方法为联邦学习提供了更强的拜占庭攻击鲁棒性，只需要最少的安全假设（服务器和一个诚实客户端），在实际部署中具有重要应用价值。

Abstract: Federated Learning (FL) enables collaborative model training across multiple
clients without sharing private data. We consider FL scenarios wherein FL
clients are subject to adversarial (Byzantine) attacks, while the FL server is
trusted (honest) and has a trustworthy side dataset. This may correspond to,
e.g., cases where the server possesses trusted data prior to federation, or to
the presence of a trusted client that temporarily assumes the server role. Our
approach requires only two honest participants, i.e., the server and one
client, to function effectively, without prior knowledge of the number of
malicious clients. Theoretical analysis demonstrates bounded optimality gaps
even under strong Byzantine attacks. Experimental results show that our
algorithm significantly outperforms standard and robust FL baselines such as
Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack
strategies including label flipping, sign flipping, and Gaussian noise addition
across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.

</details>


### [332] [Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach](https://arxiv.org/abs/2508.12673)
*Yuhao Zhou,Jindi Lv,Yuxin Tian,Dan Si,Qing Ye,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperFedZero是一个新颖的联邦学习方法，通过超网络动态生成专门化模型来解决非参与客户端的数据分布偏移问题，在保持低开销的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在处理数据异构性方面取得进展，但无法泛化到具有域内分布偏移和资源约束的非参与客户端，需要新的解决方案。

Method: 使用基于分布感知嵌入的超网络动态生成专门化模型，采用NoisyEmbed增强的提取器和平衡惩罚来防止特征坍塌，分块生成适配模型。

Result: 在多个数据集和模型上的实验显示，HyperFedZero性能显著优于竞争方法，计算、存储和通信开销极小，消融研究验证了各组件的必要性。

Conclusion: HyperFedZero通过分布感知的归纳偏置和动态模型生成，有效解决了非参与客户端的泛化问题，为联邦学习中的数据异构性挑战提供了实用解决方案。

Abstract: Federated Learning (FL) has emerged as a promising paradigm for
privacy-preserving collaborative learning, yet data heterogeneity remains a
critical challenge. While existing methods achieve progress in addressing data
heterogeneity for participating clients, they fail to generalize to
non-participating clients with in-domain distribution shifts and resource
constraints. To mitigate this issue, we present HyperFedZero, a novel method
that dynamically generates specialized models via a hypernetwork conditioned on
distribution-aware embeddings. Our approach explicitly incorporates
distribution-aware inductive biases into the model's forward pass, extracting
robust distribution embeddings using a NoisyEmbed-enhanced extractor with a
Balancing Penalty, effectively preventing feature collapse. The hypernetwork
then leverages these embeddings to generate specialized models chunk-by-chunk
for non-participating clients, ensuring adaptability to their unique data
distributions. Extensive experiments on multiple datasets and models
demonstrate HyperFedZero's remarkable performance, surpassing competing methods
consistently with minimal computational, storage, and communication overhead.
Moreover, ablation studies and visualizations further validate the necessity of
each component, confirming meaningful adaptations and validating the
effectiveness of HyperFedZero.

</details>


### [333] [Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs](https://arxiv.org/abs/2508.12712)
*Seyed Mahdi Haji Seyed Hossein,Alireza Hosseini,Soheil Hajian Manesh,Amirali Shahriary*

Main category: cs.LG

TL;DR: 本研究提出了一个去中心化的联邦学习框架，专门用于车辆网络中的交通标志检测，通过不共享原始数据实现协作模型训练，在模拟环境中验证了多种配置的性能。


<details>
  <summary>Details</summary>
Motivation: 联网和自动驾驶车辆每天产生大量传感器数据，集中式机器学习方法在感知任务中面临严重的隐私和通信挑战，需要开发隐私保护的分布式学习方案。

Method: 采用联邦学习框架，将交通标志类别分配到不同车辆进行专门的本地训练，使用轻量级目标检测器，通过Flower框架在模拟环境中聚合模型参数（包括FedProx、FedAdam和FedAVG算法），评估不同服务器轮次、本地周期、客户端参与比例和数据分布配置。

Result: 实验显示：服务器轮次从2增加到20时准确率从低于0.1提升到超过0.8；适中的本地周期（8-10）提供约0.67的最佳效率；更高的客户端参与比例将泛化能力提升至0.83；FedProx在处理异构性方面优于其他聚合器；非独立同分布数据性能低于独立同分布；训练时长主要与轮次数而非聚合策略相关。

Conclusion: 这种联邦学习方法可为现实世界车辆部署提供可扩展的隐私保护解决方案，有望指导未来鲁棒聚合和通信优化的集成，推动智能交通系统发展。

Abstract: Connected and automated vehicles generate vast amounts of sensor data daily,
raising significant privacy and communication challenges for centralized
machine learning approaches in perception tasks. This study presents a
decentralized, federated learning framework tailored for traffic sign detection
in vehicular networks to enable collaborative model training without sharing
raw data. The framework partitioned traffic sign classes across vehicles for
specialized local training using lightweight object detectors, aggregated model
parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated
environment with the Flower framework, and evaluated multiple configurations
including varying server rounds, local epochs, client participation fractions,
and data distributions. Experiments demonstrated that increasing server rounds
from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs
(8-10) provided optimal efficiency with accuracies around 0.67, higher client
participation fractions enhanced generalization up to 0.83, FedProx
outperformed other aggregators in handling heterogeneity, non-IID data
distributions reduced performance compared to IID, and training duration
primarily scaled with the number of rounds rather than aggregation strategy. We
conclude that this federated approach may offer a scalable, privacy-preserving
solution for real-world vehicular deployments, potentially guiding future
integrations of robust aggregation and communication optimizations to advance
intelligent transportation systems.

</details>


### [334] [FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment](https://arxiv.org/abs/2508.12727)
*Manning Zhu,Songtao Guo,Pengzhan Zhou,Yansong Ning,Chang Han,Dewen Qiao*

Main category: cs.LG

TL;DR: FedSODA是一个资源高效的联邦微调框架，通过层剪枝和蒸馏对齐技术，在保持模型性能的同时显著降低通信、存储和计算需求。


<details>
  <summary>Details</summary>
Motivation: 解决联邦微调中资源受限客户端面临的全模型微调计算和内存需求过高的问题，实现隐私保护下的领域自适应。

Method: 提出相似性组剪枝(SGP)模块剪枝冗余层保留关键层，引入协调蒸馏对齐(ODA)模块减少子模型与全模型梯度差异，结合QLoRA技术量化子模型并微调轻量适配器。

Result: 平均减少70.6%通信开销，降低75.6%存储使用，提升3.1%任务准确率，在多个开源LLM和下游任务上验证有效性。

Conclusion: FedSODA为资源受限环境下的实用联邦微调应用提供了高效解决方案，显著降低了资源需求同时保持甚至提升模型性能。

Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently
emerged as a promising solution to enable domain-specific adaptation while
preserving data privacy. Despite its benefits, FFT on resource-constrained
clients relies on the high computational and memory demands of full-model
fine-tuning, which limits the potential advancement. This paper presents
FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs
without accessing or storing the full model. Specifically, we first propose a
similarity group pruning (SGP) module, which prunes redundant layers from the
full LLM while retaining the most critical layers to preserve the model
performance. Moreover, we introduce an orchestrated distillation alignment
(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM
during FFT. Through the use of the QLoRA, clients only need to deploy quantized
sub-LLMs and fine-tune lightweight adapters, significantly reducing local
resource requirements. We conduct extensive experiments on three open-source
LLMs across a variety of downstream tasks. The experimental results demonstrate
that FedSODA reduces communication overhead by an average of 70.6%, decreases
storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly
suitable for practical FFT applications under resource constraints.

</details>


### [335] [FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models](https://arxiv.org/abs/2508.12740)
*Beomseok Seo,Kichang Lee,JaeYeon Park*

Main category: cs.LG

TL;DR: FedUNet是一个轻量级、架构无关的联邦学习框架，通过在每个客户端骨干网络上附加U-Net风格的加性模块，仅共享紧凑的瓶颈层来实现高效知识传输，解决了异构模型架构下的联邦学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法大多假设客户端模型架构相同，限制了在异构现实环境中的适用性。需要开发能够处理不同模型架构的联邦学习框架。

Method: 提出FedUNet框架，为每个客户端骨干网络附加U-Net启发的加性模块，仅共享U-Net的紧凑瓶颈层。利用编码器-解码器设计和跳跃连接捕获低层和高层特征，提取客户端不变表示。

Result: 在VGG变体上的实验显示，FedUNet达到93.11%准确率，轻量版达到92.68%准确率，仅需0.89MB的低通信开销。

Conclusion: FedUNet成功实现了异构模型架构下的高效联邦学习，通过U-Net加性模块设计在保持低通信成本的同时实现了高性能。

Abstract: Federated learning (FL) enables decentralized model training without sharing
local data. However, most existing methods assume identical model architectures
across clients, limiting their applicability in heterogeneous real-world
environments. To address this, we propose FedUNet, a lightweight and
architecture-agnostic FL framework that attaches a U-Net-inspired additive
module to each client's backbone. By sharing only the compact bottleneck of the
U-Net, FedUNet enables efficient knowledge transfer without structural
alignment. The encoder-decoder design and skip connections in the U-Net help
capture both low-level and high-level features, facilitating the extraction of
clientinvariant representations. This enables cooperative learning between the
backbone and the additive module with minimal communication cost. Experiment
with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in
compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low
communication overhead.

</details>


### [336] [A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks](https://arxiv.org/abs/2508.12741)
*Manuela Imbriani,Gina Belmonte,Mieke Massink,Alessandro Tofani,Vincenzo Ciancia*

Main category: cs.LG

TL;DR: 本文提出了一个评估神经网络空间推理能力的基准框架，重点关注连通性和距离关系等形态学属性，通过合成数据集测试发现神经网络在基本几何和拓扑理解任务中存在系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 系统评估神经网络的空间推理能力，特别是在形态学属性方面的表现，为临床应用中改进空间理解提供基础。

Method: 利用VoxLogicA空间模型检查器生成迷宫连通性问题和空间距离计算任务两类合成数据集，采用完整机器学习流程包括数据生成、标准化训练、推理执行和综合评估。

Result: 初步实验结果显示神经网络在空间推理能力方面存在显著挑战，在基本几何和拓扑理解任务中出现系统性失败。

Conclusion: 该框架提供了可重复的实验协议，有助于识别具体限制，这些限制可通过神经网络与符号推理方法相结合的混合方法来解决，为改进临床应用中的空间理解奠定基础。

Abstract: This paper presents preliminary results in the definition of a comprehensive
benchmark framework designed to systematically evaluate spatial reasoning
capabilities in neural networks, with a particular focus on morphological
properties such as connectivity and distance relationships. The framework is
currently being used to study the capabilities of nnU-Net, exploiting the
spatial model checker VoxLogicA to generate two distinct categories of
synthetic datasets: maze connectivity problems for topological analysis and
spatial distance computation tasks for geometric understanding. Each category
is evaluated across multiple resolutions to assess scalability and
generalization properties. The automated pipeline encompasses a complete
machine learning workflow including: synthetic dataset generation, standardized
training with cross-validation, inference execution, and comprehensive
evaluation using Dice coefficient and IoU (Intersection over Union) metrics.
Preliminary experimental results demonstrate significant challenges in neural
network spatial reasoning capabilities, revealing systematic failures in basic
geometric and topological understanding tasks. The framework provides a
reproducible experimental protocol, enabling researchers to identify specific
limitations. Such limitations could be addressed through hybrid approaches
combining neural networks with symbolic reasoning methods for improved spatial
understanding in clinical applications, establishing a foundation for ongoing
research into neural network spatial reasoning limitations and potential
solutions.

</details>


### [337] [Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning](https://arxiv.org/abs/2508.12758)
*Sowmini Devi Veeramachaneni,Ramamurthy Garimella*

Main category: cs.LG

TL;DR: 提出了约束质心聚类(CCC)方法，通过限制簇中心与最远点距离来控制簇的扩散，在保持可解释性的同时实现更紧凑的聚类效果


<details>
  <summary>Details</summary>
Motivation: 传统质心聚类方法缺乏对簇扩散程度的控制，需要一种能够约束簇内最大距离的聚类方法，以满足传感器网络、协作机器人等应用中对结构化聚类的需求

Method: 采用拉格朗日公式推导出闭式解，在经典质心聚类基础上增加最大距离约束，控制簇的径向扩散同时保持角度结构

Result: 在合成环形数据上的实验表明，CCC在环向熵、扇区熵和联合熵等指标上优于K-means和GMM，能够减少径向扩散并保持角度结构

Conclusion: CCC方法通过约束最大距离实现了更紧凑的聚类，适用于需要扩散控制的结构化聚类应用场景，具有良好的可解释性和实用性

Abstract: This paper presents Constrained Centroid Clustering (CCC), a method that
extends classical centroid-based clustering by enforcing a constraint on the
maximum distance between the cluster center and the farthest point in the
cluster. Using a Lagrangian formulation, we derive a closed-form solution that
maintains interpretability while controlling cluster spread. To evaluate CCC,
we conduct experiments on synthetic circular data with radial symmetry and
uniform angular distribution. Using ring-wise, sector-wise, and joint entropy
as evaluation metrics, we show that CCC achieves more compact clusters by
reducing radial spread while preserving angular structure, outperforming
standard methods such as K-means and GMM. The proposed approach is suitable for
applications requiring structured clustering with spread control, including
sensor networks, collaborative robotics, and interpretable pattern analysis.

</details>


### [338] [Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach](https://arxiv.org/abs/2508.12764)
*Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro*

Main category: cs.LG

TL;DR: 提出了一种基于极限学习机(ELM)的短期能源预测新方法，使用多输入多输出架构预测多种能源的产量，在1小时预测范围内表现出色，nRMSE达到17.9%(太阳能)和5.1%(热能)，R²>0.98。


<details>
  <summary>Details</summary>
Motivation: 为了解决能源预测中的非平稳性和季节性变化问题，需要开发一种能够动态适应波动、计算效率高且适用于实时应用的预测方法。

Method: 使用极端学习机(ELM)结合滑动窗口技术和循环时间编码，采用多输入多输出(MIMO)架构处理多种能源数据(太阳能、风能、水电、热能、生物能源和进口电力)。

Result: 模型显著优于基于持续性的预测方法，特别是在太阳能和热能预测方面表现优异。在1小时预测范围内，nRMSE分别为17.9%和5.1%，R²>0.98，并能保持高精度预测达5小时。

Conclusion: ELM模型提供闭式解，计算需求低，适合实时应用和在线学习，且方法具有高度适应性，可根据当地资源可用性、电网特性和市场结构进行调整。

Abstract: A novel methodology for short-term energy forecasting using an Extreme
Learning Machine ($\mathtt{ELM}$) is proposed. Using six years of hourly data
collected in Corsica (France) from multiple energy sources (solar, wind, hydro,
thermal, bioenergy, and imported electricity), our approach predicts both
individual energy outputs and total production (\cyr{including imports, which
closely follow energy demand, modulo losses)} through a Multi-Input
Multi-Output ($\mathtt{MIMO}$) architecture. To address non-stationarity and
seasonal variability, sliding window techniques and cyclic time encoding are
incorporated, enabling dynamic adaptation to fluctuations. The $\mathtt{ELM}$
model significantly outperforms persistence-based forecasting, particularly for
solar and thermal energy, achieving an $\mathtt{nRMSE}$ of $17.9\%$ and
$5.1\%$, respectively, with $\mathtt{R^2} > 0.98$ (1-hour horizon). The model
maintains high accuracy up to five hours ahead, beyond which renewable energy
sources become increasingly volatile. While $\mathtt{MIMO}$ provides marginal
gains over Single-Input Single-Output ($\mathtt{SISO}$) architectures and
offers key advantages over deep learning methods such as $\mathtt{LSTM}$, it
provides a closed-form solution with lower computational demands, making it
well-suited for real-time applications, including online learning. Beyond
predictive accuracy, the proposed methodology is adaptable to various contexts
and datasets, as it can be tuned to local constraints such as resource
availability, grid characteristics, and market structures.

</details>


### [339] [Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling](https://arxiv.org/abs/2508.12773)
*Jiadong Chen,Xiao He,Hengyu Ye,Fuxin Jiang,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: 提出E3Former在线集成模型用于服务器负载预测，相比单模型方法平均降低10%预测误差，已在字节跳动IHPA平台部署，支持60万+CPU核心的预测自动扩缩容，资源利用率降低40%以上。


<details>
  <summary>Details</summary>
Motivation: 现有预测模型难以快速适应在线工作负载流的动态变化，且难以捕捉细粒度高频预测任务带来的复杂周期性，需要更准确和鲁棒的预测方法。

Method: 提出E3Former在线集成模型，通过多个子网络的协同预测能力来克服单模型方法的局限性，在计算开销最小化的前提下实现高精度预测。

Result: 在线预测任务中平均降低10%预测误差，在真实在线系统的预测自动扩缩容测试中验证有效性，已部署支持30+应用稳定运行。

Conclusion: E3Former集成模型在服务器负载预测方面表现出色，能够显著提升预测精度和系统资源利用率，已在生产环境中成功应用。

Abstract: In the swiftly evolving domain of cloud computing, the advent of serverless
systems underscores the crucial need for predictive auto-scaling systems. This
necessity arises to ensure optimal resource allocation and maintain operational
efficiency in inherently volatile environments. At the core of a predictive
auto-scaling system is the workload forecasting model. Existing forecasting
models struggle to quickly adapt to the dynamics in online workload streams and
have difficulty capturing the complex periodicity brought by fine-grained,
high-frequency forecasting tasks. Addressing this, we propose a novel online
ensemble model, E3Former, for online workload forecasting in large-scale
predictive auto-scaling. Our model synergizes the predictive capabilities of
multiple subnetworks to surmount the limitations of single-model approaches,
thus ensuring superior accuracy and robustness. Remarkably, it accomplishes
this with a minimal increase in computational overhead, adhering to the lean
operational ethos of serverless systems. Through extensive experimentation on
real-world workload datasets, we establish the efficacy of our ensemble model.
In online forecasting tasks, the proposed method reduces forecast error by an
average of 10%, and its effectiveness is further demonstrated through a
predictive auto-scaling test in the real-life online system. Currently, our
method has been deployed within ByteDance's Intelligent Horizontal Pod
Auto-scaling (IHPA) platform, which supports the stable operation of over 30
applications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The
predictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis
of essentially ensuring service quality, the predictive auto-scaling system can
reduce resource utilization by over 40%.

</details>


### [340] [Randomized PCA Forest for Outlier Detection](https://arxiv.org/abs/2508.12776)
*Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek*

Main category: cs.LG

TL;DR: 提出基于随机PCA的新型无监督异常检测方法，在多个数据集上优于经典和最先进方法，具有高泛化能力和计算效率


<details>
  <summary>Details</summary>
Motivation: 受随机PCA森林在近似K近邻搜索中的性能启发，开发基于随机PCA森林的无监督异常检测方法

Method: 利用随机PCA森林进行异常检测，通过随机化PCA技术构建检测模型

Result: 实验结果显示该方法在多个数据集上优于经典和最新方法，其余数据集上表现竞争力强

Conclusion: 该方法具有高泛化能力和计算效率，是无监督异常检测的良好选择

Abstract: We propose a novel unsupervised outlier detection method based on Randomized
Principal Component Analysis (PCA). Inspired by the performance of Randomized
PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a
novel unsupervised outlier detection method that utilizes RPCA Forest for
outlier detection. Experimental results showcase the superiority of the
proposed approach compared to the classical and state-of-the-art methods in
performing the outlier detection task on several datasets while performing
competitively on the rest. The extensive analysis of the proposed method
reflects it high generalization power and its computational efficiency,
highlighting it as a good choice for unsupervised outlier detection.

</details>


### [341] [Wavy Transformer](https://arxiv.org/abs/2508.12787)
*Satoshi Noguchi,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: Wavy Transformer通过引入基于二阶波动动力学的新型注意力层来解决Transformer中的过平滑问题，在NLP和CV任务中提升性能且无需额外超参数调优


<details>
  <summary>Details</summary>
Motivation: 深度Transformer模型存在过平滑问题，即token表示在连续transformer块中收敛到相似值。本文从图神经扩散的物理视角解释此问题，并提出基于波动动力学的解决方案

Method: 建立注意力层与完全图上图神经扩散的等价关系，提出基于二阶波动动力学的新型注意力层，设计保持物理状态-速度关系的FFN和归一化层

Result: 在多种NLP和CV任务的Transformer模型上验证，Wavy Transformer以最小额外参数显著提升性能，且无需额外超参数调优

Conclusion: 从物理动力学角度成功解决Transformer过平滑问题，提出的Wavy Transformer架构有效且实用

Abstract: Transformers have achieved remarkable success across natural language
processing (NLP) and computer vision (CV). However, deep transformer models
often suffer from an over-smoothing issue, in which token representations
converge to similar values as they pass through successive transformer blocks.
In this paper, we establish an equivalence between the hidden-state dynamics
induced by stacked attention layers and graph neural diffusion on a complete
graph. From this perspective, over-smoothing can be interpreted as a
consequence of the dissipative nature of the underlying diffusion dynamics.
Motivated by this physical interpretation, we propose Wavy Transformer, which
consists of a novel attention layer based on second-order wavy dynamics. We
also introduce a feed-forward network and a normalization layer designed to
preserve the physical state-velocity relationship under the chain rule, thereby
extending the transformer architecture. We further validate our proposed
techniques on various transformer models for NLP and CV tasks. The results
consistently demonstrate that Wavy Transformer improves performance with
minimal additional parameters and no extra hyperparameter tuning.

</details>


### [342] [Bridging Human and LLM Judgments: Understanding and Narrowing the Gap](https://arxiv.org/abs/2508.12792)
*Felipe Maia Polo,Xinhe Wang,Mikhail Yurochkin,Gongjun Xu,Moulinath Banerjee,Yuekai Sun*

Main category: cs.LG

TL;DR: Bridge是一个统一的统计框架，通过建模人类和LLM评估之间的系统差异，将LLM评分转化为更接近人类偏好的评估结果


<details>
  <summary>Details</summary>
Motivation: LLM作为评估者时与人类判断存在系统性偏差，需要一种方法来弥合这种差距并提高评估的准确性

Method: 建立潜在人类偏好评分模型，将LLM偏差建模为协变量的线性变换，提供高效的拟合算法和统计推断保证

Result: 在6个LLM评估者和两个基准测试上，Bridge实现了与人类评分更高的一致性（准确率、校准和KL散度），并揭示了系统性的人机差距

Conclusion: Bridge提供了一个简单而原则性的框架，可以精炼LLM评分并表征人类与LLM之间的系统性差异，为大规模模型评估提供了可靠的工具

Abstract: Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

</details>


### [343] [A Shift in Perspective on Causality in Domain Generalization](https://arxiv.org/abs/2508.12798)
*Damian Machlanski,Stephanie Riley,Edward Moroshko,Kurt Butler,Panagiotis Dimitrakopoulos,Thomas Melistas,Akchunya Chanchal,Steven McDonagh,Ricardo Silva,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 本文重新审视因果建模在AI泛化中的作用，挑战了现有领域泛化基准的结论，提出了更细致的因果理论观点。


<details>
  <summary>Details</summary>
Motivation: 近期领域泛化基准研究对因果建模能够带来稳健AI泛化的承诺提出了挑战，需要重新审视因果性与泛化之间的关系。

Method: 通过理论分析和文献综述，调和因果建模与领域泛化文献中的表面矛盾，提出更细致的理论框架。

Result: 建立了更全面的因果性在泛化中作用的观点，提供了交互式演示来展示研究成果。

Conclusion: 因果建模在AI泛化中仍然具有重要价值，但需要更细致的理论框架来理解其作用机制。

Abstract: The promise that causal modelling can lead to robust AI generalization has
been challenged in recent work on domain generalization (DG) benchmarks. We
revisit the claims of the causality and DG literature, reconciling apparent
contradictions and advocating for a more nuanced theory of the role of
causality in generalization. We also provide an interactive demo at
https://chai-uk.github.io/ukairs25-causal-predictors/.

</details>


### [344] [Maximum Score Routing For Mixture-of-Experts](https://arxiv.org/abs/2508.12801)
*Bowen Dong,Yilong Fan,Yutao Sun,Zhenyu Li,Tengyu Pan,Xun Zhou,Jianyong Wang*

Main category: cs.LG

TL;DR: MaxScore是一种新的MoE路由范式，通过建模为最小成本最大流问题并集成SoftTopk算子，解决了传统MoE网络中专家容量约束导致的令牌丢弃和硬件效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE网络中的专家容量约束会导致容量饱和时的令牌丢弃和未充分利用专家的填充问题，而移除容量约束又会损害负载平衡和计算效率。

Method: 提出Maximum Score Routing (MaxScore)，将路由建模为最小成本最大流问题，集成SoftTopk算子，避免了迭代重路由和最优传输公式的根本限制。

Result: 在相同FLOPs下，相比有约束和无约束基线，实现了更低的训练损失和更高的评估分数。

Conclusion: MaxScore解决了MoE路由中的关键问题，提供了更好的性能和效率平衡。

Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically
allocate input tokens to top-k experts through differentiable sparse
transformations, enabling scalable model capacity while preserving
computational efficiency. Traditional MoE networks impose an expert capacity
constraint to ensure GPU-friendly computation. However, this leads to token
dropping when capacity is saturated and results in low hardware efficiency due
to padding in underutilized experts. Removing the capacity constraint, in turn,
compromises load balancing and computational efficiency. To address these
issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE
routing paradigm that models routing as a minimum-cost maximum-flow problem and
integrates a SoftTopk operator. MaxScore resolves the fundamental limitations
of iterative rerouting and optimal transport formulations, achieving lower
training losses and higher evaluation scores at equivalent FLOPs compared to
both constrained and unconstrained baselines. Implementation details and
experimental configurations can be obtained from
$\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.

</details>


### [345] [Learning to Steer: Input-dependent Steering for Multimodal LLMs](https://arxiv.org/abs/2508.12815)
*Jayneel Parekh,Pegah Khayatan,Mustafa Shukor,Arnaud Dapogny,Alasdair Newson,Matthieu Cord*

Main category: cs.LG

TL;DR: 本文提出L2S方法，通过训练小型辅助模块预测输入特定的转向向量，实现多模态大语言模型的细粒度控制，在减少幻觉和增强安全性方面优于静态基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的转向技术（如均值转向）使用单一转向向量，无法处理依赖具体输入的期望行为，如安全回答需要根据问题内容动态调整策略。

Method: 采用对比输入特定提示计算输入特定的线性偏移，训练小型辅助模块来预测转向向量，实现细粒度的输入相关控制。

Result: L2S方法有效减少了多模态大语言模型的幻觉现象，增强了模型的安全性表现，超越了其他静态基线方法。

Conclusion: 输入特定的细粒度转向控制是多模态大语言模型后处理指导的有效方法，通过学习预测转向向量可以实现更精准的行为控制。

Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

</details>


### [346] [Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG](https://arxiv.org/abs/2508.12833)
*Kichang Lee,Songkuk Kim,JaeYeon Park,JeongGil Ko*

Main category: cs.LG

TL;DR: 这篇论文通过实验研究探讨了设备上机器学习中的存储问题，发现简单的数据删除或压缩策略都是次优的，而根据数据样本对压缩的敏感性进行适应性压缩更为有效。


<details>
  <summary>Details</summary>
Motivation: 设备上机器学习在持续数据收集场景中遇到存储空间有限的挑战，需要在数据数量和质量之间寻找平衡。

Method: 进行了存储感知学习的实证研究，重点分析了压缩技术在数据数量与质量之间的权衡关系，对比了简单数据删除和统一压缩策略的效果。

Result: 研究发现不同数据样本对压缩的敏感性存在异质性，证明根据样本特征进行适应性压缩的策略是可行且更为优化的。

Conclusion: 该研究系统性地定义了存储感知学习这一被忽视的挑战，为开发新一代存储感知学习系统奠定了基础，提供了有价值的见解。

Abstract: On-device machine learning is often constrained by limited storage,
particularly in continuous data collection scenarios. This paper presents an
empirical study on storage-aware learning, focusing on the trade-off between
data quantity and quality via compression. We demonstrate that naive
strategies, such as uniform data dropping or one-size-fits-all compression, are
suboptimal. Our findings further reveal that data samples exhibit varying
sensitivities to compression, supporting the feasibility of a sample-wise
adaptive compression strategy. These insights provide a foundation for
developing a new class of storage-aware learning systems. The primary
contribution of this work is the systematic characterization of this
under-explored challenge, offering valuable insights that advance the
understanding of storage-aware learning.

</details>


### [347] [Learning In-context $\pmb{n}$-grams with Transformers: Sub-$\pmb{n}$-grams Are Near-stationary Points](https://arxiv.org/abs/2508.12837)
*Aditya Varre,Gizem Yüce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 该论文研究了Transformer模型在上下文学习中的损失景观，发现子n-gram模型是总体交叉熵损失的近似驻点，这解释了训练中观察到的平台期和阶段性学习现象。


<details>
  <summary>Details</summary>
Motivation: 受到训练过程中观察到的长时间平台期和阶段性进展的启发，研究Transformer模型在上下文下一个token预测任务中的损失景观特性。

Method: 研究在交叉熵损失下学习上下文n-gram语言模型，建立了参数配置成为驻点的充分条件，构建了简化transformer模型的k-gram估计器参数配置集。

Result: 在无限序列长度和参数范数极限下，这些解的总体损失梯度消失，表明子n-gram是总体交叉熵损失的近似驻点。数值实验支持了n-gram学习动力学的离散转换特性。

Conclusion: 子n-gram作为近似驻点的特性为广泛观察到的阶段性学习动力学和涌现相变现象提供了理论解释，揭示了transformer模型训练动态的重要特征。

Abstract: Motivated by empirical observations of prolonged plateaus and stage-wise
progression during training, we investigate the loss landscape of transformer
models trained on in-context next-token prediction tasks. In particular, we
focus on learning in-context $n$-gram language models under cross-entropy loss,
and establish a sufficient condition for parameter configurations to be
stationary points. We then construct a set of parameter configurations for a
simplified transformer model that represent $k$-gram estimators (for $k \leq
n$), and show that the gradient of the population loss at these solutions
vanishes in the limit of infinite sequence length and parameter norm. This
reveals a key property of the loss landscape: {sub-$n$-grams are
near-stationary points of the population cross-entropy loss}, offering
theoretical insight into widely observed phenomena such as stage-wise learning
dynamics and emergent phase transitions. These insights are further supported
by numerical experiments that illustrate the learning dynamics of $n$-grams,
characterized by discrete transitions between near-stationary solutions.

</details>


### [348] [HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2508.12839)
*Tiancheng Zhang,Cheng Zhang,Shuren Liu,Xiaofei Wang,Shaoyuan Huang,Wenyu Wang*

Main category: cs.LG

TL;DR: HRS框架通过混合数值和图像表示来预测云边平台中的极端负载动态，结合调度感知损失函数，显著降低SLA违规率63.1%和利润损失32.3%


<details>
  <summary>Details</summary>
Motivation: 解决流媒体服务中网络负载的高度时变和突发性挑战，避免现有方法在峰值期间要么导致SLA违规，要么采用保守的过度配置策略增加资源支出

Method: 提出HRS混合表示框架，整合数值和图像表示来捕捉极端负载动态；引入调度感知损失(SAL)来捕捉预测误差的不对称影响

Result: 在四个真实数据集上的实验表明，HRS持续优于十个基线方法，达到最先进性能，SLA违规率降低63.1%，总利润损失减少32.3%

Conclusion: HRS框架通过混合表示和调度感知损失有效解决了云边平台负载预测的困境，在保持服务质量的同时优化了资源利用效率

Abstract: With the rapid proliferation of streaming services, network load exhibits
highly time-varying and bursty behavior, posing serious challenges for
maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms
(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS
and profitability, accurate load forecasting remains challenging under traffic
surges. Existing methods either minimize mean absolute error, resulting in
underprovisioning and potential Service Level Agreement (SLA) violations during
peak periods, or adopt conservative overprovisioning strategies, which mitigate
SLA risks at the expense of increased resource expenditure. To address this
dilemma, we propose HRS, a hybrid representation framework with scheduling
awareness that integrates numerical and image-based representations to better
capture extreme load dynamics. We further introduce a Scheduling-Aware Loss
(SAL) that captures the asymmetric impact of prediction errors, guiding
predictions that better support scheduling decisions. Extensive experiments on
four real-world datasets demonstrate that HRS consistently outperforms ten
baselines and achieves state-of-the-art performance, reducing SLA violation
rates by 63.1% and total profit loss by 32.3%.

</details>


### [349] [One-Class Intrusion Detection with Dynamic Graphs](https://arxiv.org/abs/2508.12885)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: 提出TGN-SVDD方法，结合动态图建模和深度异常检测，用于网络入侵检测，在真实数据上表现优于多个基线方法


<details>
  <summary>Details</summary>
Motivation: 随着全球数字化发展，网络安全日益重要。机器学习入侵检测面临检测新型未知网络事件、处理时序数据和网络通信图结构等挑战

Method: TGN-SVDD方法，基于现代动态图建模和深度异常检测技术

Result: 在真实入侵检测数据上表现出优于多个基线方法的性能

Conclusion: 该方法为网络入侵检测提供了有效的解决方案，并建议了更具挑战性的数据变体

Abstract: With the growing digitalization all over the globe, the relevance of network
security becomes increasingly important. Machine learning-based intrusion
detection constitutes a promising approach for improving security, but it bears
several challenges. These include the requirement to detect novel and unseen
network events, as well as specific data properties, such as events over time
together with the inherent graph structure of network communication. In this
work, we propose a novel intrusion detection method, TGN-SVDD, which builds
upon modern dynamic graph modelling and deep anomaly detection. We demonstrate
its superiority over several baselines for realistic intrusion detection data
and suggest a more challenging variant of the latter.

</details>


### [350] [TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML](https://arxiv.org/abs/2508.12905)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: TCUQ是一种用于流式TinyML的单次通过、无标签不确定性监测器，通过轻量级信号将短期时间一致性转换为校准风险分数，具有O(W)环形缓冲区和O(1)每步更新。


<details>
  <summary>Details</summary>
Motivation: 为了解决TinyML设备上资源受限环境下实时不确定性监测的问题，传统方法如早期退出和深度集成需要额外计算和内存，无法在资源有限的微控制器上有效运行。

Method: 使用短期时间一致性捕获技术，通过轻量级信号处理后验和特征，结合流式符合校准层将风险分数转换为预算化的接受/弃权规则，无需在线标签或额外前向传播。

Result: 在微控制器上，TCUQ比早期退出和深度集成减少约50-60%的占用空间和30-45%的延迟，在分布内流损坏情况下提高3-7个AUPRC点的准确率下降检测，达到0.86 AUPRC和0.92 AUROC。

Conclusion: 时间一致性结合流式符合校准为TinyML设备上的监测提供了实用且资源高效的基础方案。

Abstract: We introduce TCUQ, a single pass, label free uncertainty monitor for
streaming TinyML that converts short horizon temporal consistency captured via
lightweight signals on posteriors and features into a calibrated risk score
with an O(W ) ring buffer and O(1) per step updates. A streaming conformal
layer turns this score into a budgeted accept/abstain rule, yielding calibrated
behavior without online labels or extra forward passes. On microcontrollers,
TCUQ fits comfortably on kilobyte scale devices and reduces footprint and
latency versus early exit and deep ensembles (typically about 50 to 60% smaller
and about 30 to 45% faster), while methods of similar accuracy often run out of
memory. Under corrupted in distribution streams, TCUQ improves accuracy drop
detection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high
severities; for failure detection it attains up to 0.92 AUROC. These results
show that temporal consistency, coupled with streaming conformal calibration,
provides a practical and resource efficient foundation for on device monitoring
in TinyML.

</details>


### [351] [SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy](https://arxiv.org/abs/2508.12906)
*Boran Zhao,Haiming Zhai,Zihang Yuan,Hetian Liu,Tian Xia,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: SparseMap是一个基于进化策略的稀疏张量加速器优化框架，通过联合优化映射策略和稀疏策略来解决设计空间组合爆炸问题，相比现有方法能够找到更优的设计方案。


<details>
  <summary>Details</summary>
Motivation: 稀疏张量代数在机器学习和大数据中的需求日益增长，但现有手动设计的加速器局限于特定场景，且设计空间巨大（可达O(10^41)），传统优化方法效率低下，需要一种能同时优化映射策略和稀疏策略的统一框架。

Method: 提出基于进化策略的SparseMap框架，构建包含映射策略和稀疏策略的综合设计空间，通过改进遗传编码和进化算子来高效探索巨大且多样化的设计空间。

Result: 与先前工作和经典优化方法进行定量比较，证明SparseMap能够持续找到更优的解决方案。

Conclusion: SparseMap成功解决了稀疏张量加速器设计中映射策略和稀疏策略联合优化的挑战，为自动化设计提供了有效的解决方案。

Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and
big data has driven the development of various sparse tensor accelerators.
However, most existing manually designed accelerators are limited to specific
scenarios, and it's time-consuming and challenging to adjust a large number of
design factors when scenarios change. Therefore, automating the design of SpTA
accelerators is crucial. Nevertheless, previous works focus solely on either
mapping (i.e., tiling communication and computation in space and time) or
sparse strategy (i.e., bypassing zero elements for efficiency), leading to
suboptimal designs due to the lack of comprehensive consideration of both. A
unified framework that jointly optimizes both is urgently needed. However,
integrating mapping and sparse strategies leads to a combinatorial explosion in
the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times
64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space
renders most conventional optimization methods (e.g., particle swarm
optimization, reinforcement learning and Monte Carlo tree search) inefficient.
To address this challenge, we propose an evolution strategy-based sparse tensor
accelerator optimization framework, called SparseMap. SparseMap constructing a
more comprehensive design space with the consideration of both mapping and
sparse strategy. We introduce a series of enhancements to genetic encoding and
evolutionary operators, enabling SparseMap to efficiently explore the vast and
diverse design space. We quantitatively compare SparseMap with prior works and
classical optimization methods, demonstrating that SparseMap consistently finds
superior solutions.

</details>


### [352] [SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML](https://arxiv.org/abs/2508.12907)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: SNAP-UQ是一种面向TinyML的单次前向传播、无需标签的不确定性量化方法，通过深度方向的下层激活预测来估计风险，显著减少了存储和延迟开销。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法（如早退机制和深度集成）在TinyML设备上资源消耗过大，需要多次前向传播或额外退出点，不适合资源受限的微控制器部署。

Method: 使用int8量化的小型预测头来预测下一层的统计特征，通过轻量级单调映射器将预测差异转换为可操作的风险分数，无需时间缓冲、辅助退出点或重复前向传播。

Result: 在视觉和音频任务上，相比早退机制和深度集成方法，SNAP-UQ减少了40-60%的存储开销和25-35%的延迟，在数据损坏流中提高了AUPRC指标，并保持了约0.9的AUROC故障检测性能。

Conclusion: 基于层间动态的不确定性量化为TinyML设备上的实时监测提供了实用且资源高效的解决方案，适合在资源受限的边缘设备上部署。

Abstract: We introduce \textbf{SNAP-UQ}, a single-pass, label-free uncertainty method
for TinyML that estimates risk from \emph{depth-wise next-activation
prediction}: tiny int8 heads forecast the statistics of the next layer from a
compressed view of the previous one, and a lightweight monotone mapper turns
the resulting surprisal into an actionable score. The design requires no
temporal buffers, auxiliary exits, or repeated forward passes, and adds only a
few tens of kilobytes to MCU deployments. Across vision and audio backbones,
SNAP-UQ consistently reduces flash and latency relative to early-exit and deep
ensembles (typically $\sim$40--60\% smaller and $\sim$25--35\% faster), with
competing methods of similar accuracy often exceeding memory limits. In
corrupted streams it improves accuracy-drop detection by several AUPRC points
and maintains strong failure detection (AUROC $\approx$0.9) in a single pass.
Grounding uncertainty in layer-to-layer dynamics yields a practical,
resource-efficient basis for on-device monitoring in TinyML.

</details>


### [353] [Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning](https://arxiv.org/abs/2508.12978)
*Yue Xia,Tayyebeh Jahani-Nezhad,Rawad Bitar*

Main category: cs.LG

TL;DR: Fed-DPRoC是一个新颖的联邦学习框架，同时确保差分隐私、拜占庭鲁棒性和通信效率，通过RobAJoL方法结合JL变换压缩和鲁棒聚合实现。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法难以同时保证差分隐私、拜占庭鲁棒性和通信效率，需要一种能够同时满足这三个关键需求的解决方案。

Method: 提出robust-compatible压缩概念，使用Johnson-Lindenstrauss变换进行压缩，结合鲁棒聚合方法RobAJoL，理论证明JL变换与鲁棒平均的兼容性。

Result: 在CIFAR-10和Fashion MNIST数据集上的实验验证了理论主张，RobAJoL在不同拜占庭攻击下在鲁棒性和效用方面优于现有方法。

Conclusion: Fed-DPRoC框架成功实现了同时保证差分隐私、拜占庭鲁棒性和通信效率的目标，RobAJoL方法在理论和实验上都表现出优越性能。

Abstract: We propose Fed-DPRoC, a novel federated learning framework that
simultaneously ensures differential privacy (DP), Byzantine robustness, and
communication efficiency. We introduce the concept of robust-compatible
compression, which enables users to compress DP-protected updates while
maintaining the robustness of the aggregation rule. We instantiate our
framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for
compression with robust averaging for robust aggregation. We theoretically
prove the compatibility of JL transform with robust averaging and show that
RobAJoL preserves robustness guarantees, ensures DP, and reduces communication
cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims
and demonstrate that RobAJoL outperforms existing methods in terms of
robustness and utility under different Byzantine attacks.

</details>


### [354] [SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression](https://arxiv.org/abs/2508.12984)
*Zehang Lin,Zheng Lin,Miao Yang,Jianhao Huang,Yuxin Zhang,Zihan Fang,Xia Du,Zhe Chen,Shunzhi Zhu,Wei Ni*

Main category: cs.LG

TL;DR: SL-ACC是一个通信高效的拆分学习框架，通过自适应通道重要性识别和通道分组压缩来减少传输数据量，同时保持训练精度。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络复杂度增加，拆分学习中过多的传输数据成为主要瓶颈，限制了在资源受限设备上的分布式机器学习部署。

Method: 提出SL-ACC框架，包含自适应通道重要性识别（使用香农熵评估通道贡献）和通道分组压缩（基于熵值进行分组自适应压缩）。

Result: 在多个数据集上的实验验证，SL-ACC比现有基准方法用更少时间达到目标精度。

Conclusion: SL-ACC有效解决了拆分学习中的通信瓶颈问题，在保持精度的同时显著减少了训练时间。

Abstract: The increasing complexity of neural networks poses a significant barrier to
the deployment of distributed machine learning (ML) on resource-constrained
devices, such as federated learning (FL). Split learning (SL) offers a
promising solution by offloading the primary computing load from edge devices
to a server via model partitioning. However, as the number of participating
devices increases, the transmission of excessive smashed data (i.e.,
activations and gradients) becomes a major bottleneck for SL, slowing down the
model training. To tackle this challenge, we propose a communication-efficient
SL framework, named SL-ACC, which comprises two key components: adaptive
channel importance identification (ACII) and channel grouping compression
(CGC). ACII first identifies the contribution of each channel in the smashed
data to model training using Shannon entropy. Following this, CGC groups the
channels based on their entropy and performs group-wise adaptive compression to
shrink the transmission volume without compromising training accuracy.
Extensive experiments across various datasets validate that our proposed SL-ACC
framework takes considerably less time to achieve a target accuracy than
state-of-the-art benchmarks.

</details>


### [355] [Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian](https://arxiv.org/abs/2508.12993)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: 图卷积网络(GCN)性能与图的代数连通性(Fiedler值)密切相关，Fiedler值可作为GCN性能的有效预测指标，相似Fiedler值的图具有类似结构特性，便于迁移学习。


<details>
  <summary>Details</summary>
Motivation: 解决GCN层数堆叠性能不稳定问题，寻找能够预测GCN性能的图结构指标，为超参数选择和迁移学习提供理论依据。

Method: 通过理论和实验分析，在合成图和真实图数据(Cora、CiteSeer、Polblogs)上验证Fiedler值与GCN性能的关系，探索多种Fiedler值聚合方法。

Result: 实证表明图的Fiedler值是GCN性能的良好预测指标，相似Fiedler值的图具有类似结构特性，可使用相同滤波器和超参数获得相近结果。

Conclusion: 代数连通性(Fiedler值)是预测GCN性能的有效指标，为图神经网络的理论分析和实践应用提供了重要见解，特别是在迁移学习场景中。

Abstract: A common observation in the Graph Convolutional Network (GCN) literature is
that stacking GCN layers may or may not result in better performance on tasks
like node classification and edge prediction. We have found empirically that a
graph's algebraic connectivity, which is known as the Fiedler value, is a good
predictor of GCN performance. Intuitively, graphs with similar Fiedler values
have analogous structural properties, suggesting that the same filters and
hyperparameters may yield similar results when used with GCNs, and that
transfer learning may be more effective between graphs with similar algebraic
connectivity. We explore this theoretically and empirically with experiments on
synthetic and real graph data, including the Cora, CiteSeer and Polblogs
datasets. We explore multiple ways of aggregating the Fiedler value for
connected components in the graphs to arrive at a value for the entire graph,
and show that it can be used to predict GCN performance. We also present
theoretical arguments as to why the Fiedler value is a good predictor.

</details>


### [356] [Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair](https://arxiv.org/abs/2508.12996)
*Stavros C. Kassinos*

Main category: cs.LG

TL;DR: Kourkoutas-Beta是一种Adam风格的优化器，通过动态调整beta2参数来处理梯度尖峰问题，在物理驱动的PDE代理模型和PINNs中显著提升训练稳定性和性能


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在物理问题中训练时由于边界条件变化导致的梯度尖峰和不稳定损失问题，特别是在数据驱动的PDE代理模型和物理信息神经网络中

Method: 将Adam的固定beta2参数替换为基于梯度范数比率的层级动态值，使用sunspike比率（当前梯度范数除以历史EMA）来控制beta2在[0,1)区间动态调整

Result: 在Heat2D Transformer、Heat3D PINN、MLX合成任务和small-enwik8字符级Transformer上测试，相比固定beta2的Adam显著提升稳定性和最终损失，在small-enwik8上比特率降低38-58%

Conclusion: Kourkoutas-Beta保持Adam的收敛保证同时提升梯度尖峰下的鲁棒性，计算开销与Adam相当，可作为即插即用的优化器替代方案

Abstract: Transformer neural networks are increasingly used for physics-based problems.
In data-driven PDE surrogates, training samples from varying boundary and
initial conditions can cause erratic losses and spiky gradients; in
physics-informed neural networks (PINNs), stiff composite losses amplify this
effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed
second-moment discount beta2 is replaced by a layer-wise dynamic value driven
by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an
exponential moving average (EMA) of past norms, squashed to the interval [0,1).
Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.
Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio),
adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',
``exact'). With all features off and bias_correction=``none'', the method is
exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D
PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with
jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB
of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss
versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about
38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller
variance. The method remains drop-in, with runtime overhead comparable to Adam
in testbeds A-C and within single-digit percent in testbed D. It preserves
Adam-style convergence guarantees while improving robustness under spiky
gradients.

</details>


### [357] [Fairness-Aware Multi-view Evidential Learning with Adaptive Prior](https://arxiv.org/abs/2508.12997)
*Haishun Chen,Cai Xu,Jinlong Yu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.LG

TL;DR: FAML方法通过自适应先验、公平性约束和意见对齐机制，解决多视图证据学习中的偏见问题，实现更平衡的证据分配和更可靠的不确定性估计


<details>
  <summary>Details</summary>
Motivation: 传统多视图证据学习方法假设视图特定证据学习是可靠的，但实践中证据学习过程存在偏见，样本倾向于为数据丰富的类别分配更多证据，导致不确定性估计不可靠

Method: 提出FAML框架：1）基于训练轨迹的自适应先验作为正则化策略；2）基于类别证据方差的公平性约束；3）多视图融合阶段的意见对齐机制

Result: 在5个真实世界多视图数据集上的实验表明，FAML实现了更平衡的证据分配，在预测性能和不确定性估计可靠性方面均优于最先进方法

Conclusion: FAML有效解决了多视图证据学习中的偏见问题，通过综合的校准和约束机制提升了模型的公平性和可靠性

Abstract: Multi-view evidential learning aims to integrate information from multiple
views to improve prediction performance and provide trustworthy uncertainty
esitimation. Most previous methods assume that view-specific evidence learning
is naturally reliable. However, in practice, the evidence learning process
tends to be biased. Through empirical analysis on real-world data, we reveal
that samples tend to be assigned more evidence to support data-rich classes,
thereby leading to unreliable uncertainty estimation in predictions. This
motivates us to delve into a new Biased Evidential Multi-view Learning (BEML)
problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning
(FAML). FAML first introduces an adaptive prior based on training trajectory,
which acts as a regularization strategy to flexibly calibrate the biased
evidence learning process. Furthermore, we explicitly incorporate a fairness
constraint based on class-wise evidence variance to promote balanced evidence
allocation. In the multi-view fusion stage, we propose an opinion alignment
mechanism to mitigate view-specific bias across views, thereby encouraging the
integration of consistent and mutually supportive evidence. Extensive
experiments on five real-world multi-view datasets demonstrate that FAML
achieves more balanced evidence allocation and improves both prediction
performance and the reliability of uncertainty estimation compared to
state-of-the-art methods.

</details>


### [358] [Monte Carlo Functional Regularisation for Continual Learning](https://arxiv.org/abs/2508.13006)
*Pengcheng Hao,Menghao Waiyan William Zhu,Ercan Engin Kuruoglu*

Main category: cs.LG

TL;DR: 提出MCFRCL框架，通过蒙特卡洛采样和统计矩方法改进功能正则化持续学习，在准确性和效率上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有功能正则化持续学习方法存在计算成本高和线性近似误差大的问题，需要更有效的解决方案

Method: 使用蒙特卡洛采样近似模型预测分布，利用三种连续分布通过矩方法捕捉统计特征，结合Wasserstein距离和KL距离构建正则化函数

Result: 在MNIST和CIFAR数据集上评估，结果显示在预测准确性和训练效率方面优于多个基准方法

Conclusion: MCFRCL框架通过蒙特卡洛采样和统计矩方法有效解决了功能正则化持续学习的高计算成本和近似误差问题

Abstract: Continual learning (CL) is crucial for the adaptation of neural network
models to new environments. Although outperforming weight-space regularisation
approaches, the functional regularisation-based CL methods suffer from high
computational costs and large linear approximation errors. In this work, we
present a new functional regularisation CL framework, called MCFRCL, which
approximates model prediction distributions by Monte Carlo (MC) sampling.
Moreover, three continuous distributions are leveraged to capture the
statistical characteristics of the MC samples via moment-based methods.
Additionally, both the Wasserstein distance and the Kullback-Leibler (KL)
distance are employed to construct the regularisation function. The proposed
MCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR
datasets, with simulation results highlighting its effectiveness in both
prediction accuracy and training efficiency.

</details>


### [359] [Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control](https://arxiv.org/abs/2508.13018)
*Iam Kim de S. Hermont,Andre R. Flores,Rodrigo C. de Lamare*

Main category: cs.LG

TL;DR: 提出一种针对脉冲噪声的鲁棒自适应滤波算法FXHEKM，用于主动噪声控制，在α稳定噪声环境下表现优于现有算法


<details>
  <summary>Details</summary>
Motivation: 解决主动噪声控制应用中存在脉冲噪声时传统算法性能下降的问题

Method: 开发了滤波-x双曲正切指数广义核M估计函数(FXHEKM)鲁棒自适应算法，进行了统计分析和计算成本研究

Result: 数值结果显示FXHEKM算法在α稳定噪声等加性干扰信号消除方面表现高效，优于竞争算法

Conclusion: FXHEKM算法在脉冲噪声环境下具有优异的噪声消除性能，为主动噪声控制提供了有效的解决方案

Abstract: In this work, we propose a robust adaptive filtering approach for active
noise control applications in the presence of impulsive noise. In particular,
we develop the filtered-x hyperbolic tangent exponential generalized Kernel
M-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis
of the proposed FXHEKM algorithm is carried out along with a study of its
computational cost. {In order to evaluate the proposed FXHEKM algorithm, the
mean-square error (MSE) and the average noise reduction (ANR) performance
metrics have been adopted.} Numerical results show the efficiency of the
proposed FXHEKM algorithm to cancel the presence of the additive spurious
signals, such as \textbf{$\alpha$}-stable noises against competing algorithms.

</details>


### [360] [The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](https://arxiv.org/abs/2508.13030)
*Bipin Chhetri,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 本研究利用BERT和HAN模型对网络攻击后果进行多标签分类，BERT在准确率、精确率和召回率方面显著优于传统深度学习模型


<details>
  <summary>Details</summary>
Motivation: 网络攻击日益复杂，需要自动化方法来分析攻击描述并预测后果，以帮助网络安全专业人员及时采取行动和分配资源

Method: 使用NLP和深度学习技术，特别是BERT模型和分层注意力网络(HAN)，对MITRE CWE数据库中的文本描述进行分析，将攻击后果分为五大类别进行多标签分类

Result: BERT模型达到0.972的整体准确率，远高于传统CNN和LSTM模型；HAN在特定网络安全标签上优于基线模型，但BERT在精确率和召回率方面表现更一致

Conclusion: BERT模型更适合预测网络攻击后果，在网络安全威胁建模中具有更好的应用前景

Abstract: Cyberattacks are increasing, and securing against such threats is costing
industries billions of dollars annually. Threat Modeling, that is,
comprehending the consequences of these attacks, can provide critical support
to cybersecurity professionals, enabling them to take timely action and
allocate resources that could be used elsewhere. Cybersecurity is heavily
dependent on threat modeling, as it assists security experts in assessing and
mitigating risks related to identifying vulnerabilities and threats. Recently,
there has been a pressing need for automated methods to assess attack
descriptions and forecast the future consequences of the increasing complexity
of cyberattacks. This study examines how Natural Language Processing (NLP) and
deep learning can be applied to analyze the potential impact of cyberattacks by
leveraging textual descriptions from the MITRE Common Weakness Enumeration
(CWE) database. We emphasize classifying attack consequences into five
principal categories: Availability, Access Control, Confidentiality, Integrity,
and Other. This paper investigates the use of Bidirectional Encoder
Representations from Transformers (BERT) in combination with Hierarchical
Attention Networks (HANs) for Multi-label classification, evaluating their
performance in comparison with conventional CNN and LSTM-based models.
Experimental findings show that BERT achieves an overall accuracy of $0.972$,
far higher than conventional deep learning models in multi-label
classification. HAN outperforms baseline forms of CNN and LSTM-based models on
specific cybersecurity labels. However, BERT consistently achieves better
precision and recall, making it more suitable for predicting the consequences
of a cyberattack.

</details>


### [361] [Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data](https://arxiv.org/abs/2508.13040)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: 提出一种利用分离数据源估计模型公平性的方法，当完整数据不可访问时，通过联合分布估计来计算公平性指标的可行范围


<details>
  <summary>Details</summary>
Motivation: AI系统公平性测试面临数据获取挑战，由于法律隐私限制，人口统计数据往往分散在不同来源，需要解决在不访问完整数据的情况下评估公平性的问题

Method: 利用内部预测属性数据集和外部人口统计数据，估计可行的联合分布集合，然后计算可能的公平性指标范围

Result: 通过模拟和真实实验证明，该方法能够得出公平性指标的有意义边界，并获得真实指标的可靠估计

Conclusion: 该方法为现实世界中数据访问受限的场景提供了一种实用有效的公平性测试解决方案

Abstract: Ensuring fairness in AI systems is critical, especially in high-stakes
domains such as lending, hiring, and healthcare. This urgency is reflected in
emerging global regulations that mandate fairness assessments and independent
bias audits. However, procuring the necessary complete data for fairness
testing remains a significant challenge. In industry settings, legal and
privacy concerns restrict the collection of demographic data required to assess
group disparities, and auditors face practical and cultural challenges in
gaining access to data. In practice, data relevant for fairness testing is
often split across separate sources: internal datasets held by institutions
with predictive attributes, and external public datasets such as census data
containing protected attributes, each providing only partial, marginal
information. Our work seeks to leverage such available separate data to
estimate model fairness when complete data is inaccessible. We propose
utilising the available separate data to estimate a set of feasible joint
distributions and then compute the set plausible fairness metrics. Through
simulation and real experiments, we demonstrate that we can derive meaningful
bounds on fairness metrics and obtain reliable estimates of the true metric.
Our results demonstrate that this approach can serve as a practical and
effective solution for fairness testing in real-world settings where access to
complete data is restricted.

</details>


### [362] [Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models](https://arxiv.org/abs/2508.13057)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: 该研究比较了两种自定义评估函数FMAE和HEF在多元时间序列预测中的表现，发现HEF在全局指标上表现更好，适合战略规划；FMAE在局部指标和计算效率上更有优势，适合运营效率场景。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列建模面临数据复杂性、不确定性和频繁制度转换等挑战，传统评估指标存在偏差且限制泛化能力，需要开发更有效的评估方法来优化预测模型。

Method: 使用三种优化器（网格搜索、PSO、Optuna）在不同数据分割比例（91:9、80:20、70:30）下进行实验，比较FMAE（聚焦平均绝对误差）和HEF（分层评估函数）在拟合度、相对准确性、鲁棒性和计算效率方面的表现。

Result: HEF在全局指标（R2、相对准确性、RMSE、RMSSE）上始终优于FMAE，增强了模型鲁棒性和解释力；FMAE在局部指标（MAE、MASE）和执行时间上更有优势。

Conclusion: 研究揭示了方法论的权衡：HEF适合战略规划，FMAE更适合运营效率场景，提出了一个可复现的框架用于动态环境中预测模型的优化。

Abstract: Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.

</details>


### [363] [Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network](https://arxiv.org/abs/2508.13099)
*Mingyu Kim,Daniel Stilwell,Jorge Jimenez*

Main category: cs.LG

TL;DR: 提出基于海底声学传感器网络和LGCP的海上空间异常检测框架，通过二阶概率近似和动态传感器部署提高异常分类和检测性能


<details>
  <summary>Details</summary>
Motivation: 解决海上环境中空间异常检测的挑战，传统方法仅考虑均值信息，需要更准确的概率估计和实时检测能力

Method: 使用对数高斯Cox过程建模目标到达，建立正常和异常过程的混合模型，提出包含均值和方差的二阶概率近似方法，结合动态传感器部署策略

Result: 在弗吉尼亚州诺福克真实船舶交通数据上验证，数值结果表明方法在分类性能和异常检测方面优于仅使用均值的方法

Conclusion: 提出的二阶概率近似框架通过更完整的统计信息利用和动态传感器部署，显著提升了海上空间异常检测的准确性和实时性

Abstract: This paper presents a framework for classifying and detecting spatial
commission outliers in maritime environments using seabed acoustic sensor
networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as
a mixture of normal and outlier processes, we estimate the probability that a
newly observed event is an outlier. We propose a second-order approximation of
this probability that incorporates both the mean and variance of the normal
intensity function, providing improved classification accuracy compared to
mean-only approaches. We analytically show that our method yields a tighter
bound to the true probability using Jensen's inequality. To enhance detection,
we integrate a real-time, near-optimal sensor placement strategy that
dynamically adjusts sensor locations based on the evolving outlier intensity.
The proposed framework is validated using real ship traffic data near Norfolk,
Virginia, where numerical results demonstrate the effectiveness of our approach
in improving both classification performance and outlier detection through
sensor deployment.

</details>


### [364] [A Perfectly Truthful Calibration Measure](https://arxiv.org/abs/2508.13100)
*Jason Hartline,Lunjia Hu,Yifan Wu*

Main category: cs.LG

TL;DR: 本文设计了一个在批量设置中完全真实的校准度量——平均双箱校准误差(ATB)，解决了现有校准度量在有限样本上激励预测器说谎的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的校准度量在有限样本评估时会激励预测器说谎以显得更校准，缺乏真实性。虽然已有研究构建了近似真实的校准度量，但在批量设置中尚未存在完全真实的校准度量。

Method: 设计了平均双箱校准误差(ATB)，这是一个简单高效的计算方法。还提出了构建真实度量的一般方法，证明了ATB的真实性，并能构造其他真实校准度量如分位数分箱l_2-ECE。

Result: ATB不仅完全真实，还具有合理性、完备性、连续性，且与平滑校准误差(smCal)和校准距离(distCal)存在二次关系。ATB实现了更快的估计算法和更简单的实现，改进了校准测试问题的运行时间和简洁性。

Conclusion: ATB是第一个在批量设置中完全真实的校准度量，解决了校准评估中的真实性问题，为可靠的概率解释提供了保障。

Abstract: Calibration requires that predictions are conditionally unbiased and,
therefore, reliably interpretable as probabilities. Calibration measures
quantify how far a predictor is from perfect calibration. As introduced by
Haghtalab et al. (2024), a calibration measure is truthful if it is minimized
in expectation when a predictor outputs the ground-truth probabilities.
Although predicting the true probabilities guarantees perfect calibration, in
reality, when calibration is evaluated on a finite sample, predicting the truth
is not guaranteed to minimize any known calibration measure. All known
calibration measures incentivize predictors to lie in order to appear more
calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et
al. (2024) and Qiao and Zhao (2025) to construct approximately truthful
calibration measures in the sequential prediction setting, but no perfectly
truthful calibration measure was known to exist even in the more basic batch
setting.
  We design a perfectly truthful calibration measure in the batch setting:
averaged two-bin calibration error (ATB). In addition to being truthful, ATB is
sound, complete, continuous, and quadratically related to two existing
calibration measures: the smooth calibration error (smCal) and the (lower)
distance to calibration (distCal). The simplicity in our definition of ATB
makes it efficient and straightforward to compute. ATB allows faster estimation
algorithms with significantly easier implementations than smCal and distCal,
achieving improved running time and simplicity for the calibration testing
problem studied by Hu et al. (2024). We also introduce a general recipe for
constructing truthful measures, which proves the truthfulness of ATB as a
special case and allows us to construct other truthful calibration measures
such as quantile-binned l_2-ECE.

</details>


### [365] [Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry](https://arxiv.org/abs/2508.13111)
*Michael Mayr,Georgios C. Chasparis*

Main category: cs.LG

TL;DR: 提出了CGPT模型，通过因果图引导的成对Transformer架构，解决了多维时间序列建模中通道依赖与通道独立的权衡问题，实现了更好的预测精度和维度无关的适应性。


<details>
  <summary>Details</summary>
Motivation: 工业系统中多维时间序列建模存在核心权衡：通道依赖模型能捕捉特定跨变量动态但缺乏鲁棒性，通道独立模型具有通用性但无法建模系统级预测回归任务所需的关键交互。

Method: CGPT架构整合已知因果图作为归纳偏置，采用成对建模范式将多维数据分解为成对关系，使用通道无关的可学习层，在成对级别强制通道依赖信息流，在跨成对关系中实现通道独立式泛化。

Result: 在合成和真实工业数据集的长时期和单步预测任务上，CGPT显著优于通道独立和通道依赖基线模型，在预测精度上表现出色，同时保持与端到端训练的通道依赖模型相竞争的性能。

Conclusion: CGPT通过因果引导的成对建模方法成功解决了多维时间序列建模的权衡问题，实现了复杂系统动态的解耦，确保了可扩展性和任意变量适应性。

Abstract: Foundational modelling of multi-dimensional time-series data in industrial
systems presents a central trade-off: channel-dependent (CD) models capture
specific cross-variable dynamics but lack robustness and adaptability as model
layers are commonly bound to the data dimensionality of the tackled use-case,
while channel-independent (CI) models offer generality at the cost of modelling
the explicit interactions crucial for system-level predictive regression tasks.
To resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a
novel architecture that integrates a known causal graph as an inductive bias.
The core of CGPT is built around a pairwise modeling paradigm, tackling the
CD/CI conflict by decomposing the multidimensional data into pairs. The model
uses channel-agnostic learnable layers where all parameter dimensions are
independent of the number of variables. CGPT enforces a CD information flow at
the pair-level and CI-like generalization across pairs. This approach
disentangles complex system dynamics and results in a highly flexible
architecture that ensures scalability and any-variate adaptability. We validate
CGPT on a suite of synthetic and real-world industrial datasets on long-term
and one-step forecasting tasks designed to simulate common industrial
complexities. Results demonstrate that CGPT significantly outperforms both CI
and CD baselines in predictive accuracy and shows competitive performance with
end-to-end trained CD models while remaining agnostic to the problem
dimensionality.

</details>


### [366] [Contrastive Representations for Temporal Reasoning](https://arxiv.org/abs/2508.13113)
*Alicja Ziarko,Michal Bortkiewicz,Michal Zawalski,Benjamin Eysenbach,Piotr Milos*

Main category: cs.LG

TL;DR: CRTR方法通过负采样方案消除伪特征，在复杂时序结构领域（如Sokoban和魔方）实现强时序推理能力，首次仅通过学习表征高效解决任意魔方状态。


<details>
  <summary>Details</summary>
Motivation: 传统AI中感知和规划分离，本研究探索能否从同时捕获感知和时序结构的表征中自然涌现时序推理能力，解决标准时序对比学习依赖伪特征的问题。

Method: 提出组合时序推理表征（CRTR），采用负采样方案可证明地移除伪特征，促进时序推理，不依赖外部搜索算法。

Result: 在Sokoban和魔方等复杂时序结构领域表现强劲，魔方任务中学习到的表征能泛化到所有初始状态，比BestFS使用更少搜索步骤（但解决方案更长）。

Conclusion: CRTR是首个仅通过学习表征就能高效解决任意魔方状态的方法，证明了从统一表征中涌现时序推理的可行性。

Abstract: In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.

</details>


### [367] [Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]](https://arxiv.org/abs/2508.13135)
*Yueyang Liu,Lance Kennedy,Ruochen Kong,Joon-Seok Kim,Andreas Züfle*

Main category: cs.LG

TL;DR: 该论文研究了如何通过机器学习模型预测个体在未来几天和几周的完整移动轨迹，重点分析了不同模型架构、训练策略和数据采样方法对预测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注人类轨迹的微观方面（如短期轨迹或下一个位置预测），而忽视了宏观层面的移动模式和生活规律。本文旨在探索如何利用历史数据训练模型来预测个体的完整长期轨迹。

Method: 采用LSTM和Transformer架构，结合语义信息（如星期几）和用户特定历史信息，使用用户语义聚类和分层采样来缓解数据不平衡问题，并比较了小批量随机梯度优化的效果。

Result: 研究表明显式包含语义信息和用户特定历史信息能显著提升预测性能；用户采样可能导致数据偏斜和预测精度损失；小批量随机梯度优化在数据有限时能改善模型表现。

Conclusion: 通过结合语义信息、采用适当的数据采样策略和优化方法，可以有效提升人类移动轨迹的长期预测准确性，特别是在处理数据不平衡和隐私限制的情况下。

Abstract: Individual-level human mobility prediction has emerged as a significant topic
of research with applications in infectious disease monitoring, child, and
elderly care. Existing studies predominantly focus on the microscopic aspects
of human trajectories: such as predicting short-term trajectories or the next
location visited, while offering limited attention to macro-level mobility
patterns and the corresponding life routines. In this paper, we focus on an
underexplored problem in human mobility prediction: determining the best
practices to train a machine learning model using historical data to forecast
an individuals complete trajectory over the next days and weeks. In this
experiment paper, we undertake a comprehensive experimental analysis of diverse
models, parameter configurations, and training strategies, accompanied by an
in-depth examination of the statistical distribution inherent in human mobility
patterns. Our empirical evaluations encompass both Long Short-Term Memory and
Transformer-based architectures, and further investigate how incorporating
individual life patterns can enhance the effectiveness of the prediction. We
show that explicitly including semantic information such as day-of-the-week and
user-specific historical information can help the model better understand
individual patterns of life and improve predictions. Moreover, since the
absence of explicit user information is often missing due to user privacy, we
show that the sampling of users may exacerbate data skewness and result in a
substantial loss in predictive accuracy. To mitigate data imbalance and
preserve diversity, we apply user semantic clustering with stratified sampling
to ensure that the sampled dataset remains representative. Our results further
show that small-batch stochastic gradient optimization improves model
performance, especially when human mobility training data is limited.

</details>


### [368] [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)
*Haoyu He,Katrin Renz,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: 提出MDPO方法解决扩散语言模型训练与推理阶段的结构差异问题，通过强化学习优化去噪轨迹，在更少梯度更新下达到SOTA性能，并改进重掩码策略RCR进一步提升效果


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型存在训练与推理阶段的结构差异：训练时随机掩码，推理时逐步揭示序列结构，这种差异导致次优性能但被先前工作忽视

Method: 将学习有效去噪轨迹建模为序列决策问题，提出Masked Diffusion Policy Optimization (MDPO)方法，利用扩散的马尔可夫性质，在推理使用的渐进精炼调度下显式训练模型

Result: MDPO以60倍更少的梯度更新匹配先前SOTA性能，在相同权重更新次数下在MATH500和Countdown上分别平均提升9.6%和54.2%。改进的重掩码策略RCR作为即插即用推理替代方案进一步提升性能

Conclusion: 研究揭示了MDLMs预训练与推理间差异的巨大潜力，MDPO和RCR方法有效解决了这一长期被忽视的问题

Abstract: Diffusion language models, as a promising alternative to traditional
autoregressive (AR) models, enable faster generation and richer conditioning on
bidirectional context. However, they suffer from a key discrepancy between
training and inference: during inference, MDLMs progressively reveal the
structure of the generated sequence by producing fewer and fewer masked tokens,
whereas this structure is ignored in training as tokens are masked at random.
Although this discrepancy between training and inference can lead to suboptimal
performance, it has been largely overlooked by previous works, leaving closing
this gap between the two stages an open problem. To address this, we frame the
problem of learning effective denoising trajectories as a sequential
decision-making problem and use the resulting framework to apply reinforcement
learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to
exploit the Markov property diffusion possesses and explicitly train the model
under the same progressive refining schedule used at inference. MDPO matches
the performance of the previous state-of-the-art (SOTA) method with 60x fewer
gradient updates, while achieving average improvements of 9.6% on MATH500 and
54.2% on Countdown over SOTA when trained within the same number of weight
updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in
inference replacement to overcome the limitation that the model cannot refine
tokens flexibly. This simple yet effective training-free strategy, what we
refer to as RCR, consistently improves performance and yields additional gains
when combined with MDPO. Our findings establish great potential for
investigating the discrepancy between pre-training and inference of MDLMs.
Code: https://github.com/autonomousvision/mdpo. Project Page:
https://cli212.github.io/MDPO/.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [369] [Prediction of Spotify Chart Success Using Audio and Streaming Features](https://arxiv.org/abs/2508.11632)
*Ian Jacob Cabansag,Paul Ntegeka*

Main category: cs.SD

TL;DR: 使用Spotify数据和机器学习模型预测歌曲排行榜成功，树基模型表现最佳，仅音频特征也具有预测能力


<details>
  <summary>Details</summary>
Motivation: 理解影响歌曲在Spotify排行榜早期上升的因素，为音乐营销、投资决策和艺术方向提供指导

Method: 使用2024年美国Top 200 Spotify每日排行榜数据，构建包含14,639首歌曲的数据集，采用逻辑回归、K近邻、随机森林和XGBoost四种模型进行训练和评估

Result: 树基模型表现最优，随机森林和XGBoost的宏观F1分数接近0.95，准确率约97%。即使排除流媒体数量和排名历史，仅基于音频属性的模型仍保持预测能力

Conclusion: 音频特征建模在A&R发掘、播放列表优化和热门预测方面具有潜力，可在歌曲达到临界质量之前进行预测

Abstract: Spotify's streaming charts offer a real-time lens into music popularity,
driving discovery, playlists, and even revenue potential. Understanding what
influences a song's rise in ranks on these charts-especially early on-can guide
marketing efforts, investment decisions, and even artistic direction. In this
project, we developed a classification pipeline to predict a song's chart
success based on its musical characteristics and early engagement data. Using
all 2024 U.S. Top 200 Spotify Daily Charts and the Spotify Web API, we built a
dataset containing both metadata and audio features for 14,639 unique songs.
  The project was structured in two phases. First, we benchmarked four models:
Logistic Regression, K Nearest Neighbors, Random Forest, and XGBoost-using a
standard train-test split. In the second phase, we incorporated
cross-validation, hyperparameter tuning, and detailed class-level evaluation to
ensure robustness. Tree-based models consistently outperformed the rest, with
Random Forest and XGBoost achieving macro F1-scores near 0.95 and accuracy
around 97%.
  Even when stream count and rank history were excluded, models trained solely
on audio attributes retained predictive power. These findings validate the
potential of audio-based modeling in A&R scouting, playlist optimization, and
hit forecasting-long before a track reaches critical mass.

</details>


### [370] [Audio Flamingo Sound-CoT Technical Report: Improving Chain-of-Thought Reasoning in Sound Understanding](https://arxiv.org/abs/2508.11818)
*Zhifeng Kong,Arushi Goel,Joao Felipe Santos,Sreyan Ghosh,Rafael Valle,Wei Ping,Bryan Catanzaro*

Main category: cs.SD

TL;DR: 本文探索了思维链推理在音频语言模型中的应用，提出了AF-Reasoning-Eval评测基准和AF-CoT-Train训练数据集，通过在Audio Flamingo系列模型上进行微调，显著提升了音频理解能力。


<details>
  <summary>Details</summary>
Motivation: 思维链推理在大型语言模型和视觉语言模型中已显示出显著改进，但在音频语言模型中的潜力尚未被充分探索，本文旨在填补这一空白。

Method: 提出了AF-Reasoning-Eval评测基准用于评估声音推理能力，开发了自动流水线将现有音频问答和分类数据转换为显式推理链，构建了包含124万个样本的AF-CoT-Train训练数据集，并在Audio Flamingo系列模型上进行微调。

Result: 在多个推理基准测试中观察到显著改进，验证了思维链微调在高级声音理解方面的有效性。

Conclusion: 思维链微调对音频语言模型的推理能力有显著提升作用，为音频理解领域的发展提供了有效方法。

Abstract: Chain-of-thought reasoning has demonstrated significant improvements in large
language models and vision language models, yet its potential for audio
language models remains largely unexplored. In this technical report, we take a
preliminary step towards closing this gap. For better assessment of sound
reasoning, we propose AF-Reasoning-Eval, a benchmark targeting common-sense
reasoning and the ability to discriminate among closely related choices. To
prepare training corpus for sound reasoning abilities, we propose automatic
pipelines that transform existing audio question answering and classification
data into explicit reasoning chains, yielding AF-CoT-Train with 1.24M samples.
We study the effect of finetuning Audio Flamingo series on AF-CoT-Train and
observe considerable improvements on several reasoning benchmarks, validating
the effectiveness of chain-of-thought finetuning on advanced sound
understanding.

</details>


### [371] [What Matters for Bioacoustic Encoding](https://arxiv.org/abs/2508.11845)
*Marius Miron,David Robinson,Milad Alizadeh,Ellen Gilsenan-McMahon,Gagan Narula,Olivier Pietquin,Matthieu Geist,Emmanuel Chemla,Maddie Cusimano,Felix Effenberger,Masato Hagiwara,Benjamin Hoffman,Sara Keen,Diane Kim,Jane Lawton,Jen-Yu Liu,Aza Raskin*

Main category: cs.SD

TL;DR: 本文提出了一个大规模生物声学编码器的实证研究，通过自监督预训练和监督后训练相结合的方法，在26个数据集上实现了最先进的性能，强调了数据多样性和规模的重要性。


<details>
  <summary>Details</summary>
Motivation: 生物声学研究面临标注数据有限的问题，需要通用的生物声学编码器来提取有用表征。现有方法通常局限于特定物种（如鸟类）、单一模型架构或训练范式，且评估任务和数据集有限。

Method: 采用自监督预训练结合监督后训练的方法，使用混合生物声学+通用音频语料库进行训练。研究涵盖了训练数据多样性和规模、模型架构和训练方案、评估任务和数据集广度等方面。

Result: 在26个数据集上（包括物种分类、检测、个体识别和声学库发现等任务）实现了最先进的性能，证明了该方法在分布内和分布外数据上的强大表现。

Conclusion: 自监督预训练后接监督后训练是最有效的方法，数据多样性在两个阶段都至关重要。研究为未来更多数据或更好架构的出现提供了扩展基础，并将发布模型检查点以支持后续研究。

Abstract: Bioacoustics, the study of sounds produced by living organisms, plays a vital
role in conservation, biodiversity monitoring, and behavioral studies. Many
tasks in this field, such as species, individual, and behavior classification
and detection, are well-suited to machine learning. However, they often suffer
from limited annotated data, highlighting the need for a general-purpose
bioacoustic encoder capable of extracting useful representations for diverse
downstream tasks. Such encoders have been proposed before, but are often
limited in scope due to a focus on a narrow range of species (typically birds),
and a reliance on a single model architecture or training paradigm. Moreover,
they are usually evaluated on a small set of tasks and datasets. In this work,
we present a large-scale empirical study that covers aspects of bioacoustics
that are relevant to research but have previously been scarcely considered:
training data diversity and scale, model architectures and training recipes,
and the breadth of evaluation tasks and datasets. We obtain encoders that are
state-of-the-art on the existing and proposed benchmarks. We also identify what
matters for training these encoders, such that this work can be extended when
more data are available or better architectures are proposed. Specifically,
across 26 datasets with tasks including species classification, detection,
individual ID, and vocal repertoire discovery, we find self-supervised
pre-training followed by supervised post-training on a mixed bioacoustics +
general-audio corpus yields the strongest in- and out-of-distribution
performance. We show the importance of data diversity in both stages. To
support ongoing research and application, we will release the model
checkpoints.

</details>


### [372] [Towards Automatic Evaluation and High-Quality Pseudo-Parallel Dataset Construction for Audio Editing: A Human-in-the-Loop Method](https://arxiv.org/abs/2508.11966)
*Yuhang Jia,Hui Wang,Xin Nie,Yujie Guo,Lianru Gao,Yong Qin*

Main category: cs.SD

TL;DR: 提出了AuditScore数据集和AuditEval模型，用于音频编辑任务的主观评估和自动评分，解决了该领域缺乏高质量基准数据集和评估指标的问题。


<details>
  <summary>Details</summary>
Motivation: 音频编辑任务缺乏高质量基准数据集和全面评估指标，这严重制约了音频编辑质量的评估和任务本身的改进。

Method: 1) 构建包含6300+样本的AuditScore主观评估数据集；2) 基于该数据集训练AuditEval自动评分模型；3) 利用AuditEval筛选合成编辑对，构建高质量伪并行数据集。

Result: 建立了首个音频编辑主观评估数据集，开发了首个音频编辑自动评分模型，验证了专家知识引导的过滤策略在提升数据质量方面的有效性。

Conclusion: 该方法为音频编辑任务提供了可靠的评估框架和高质量数据集，同时揭示了单纯依赖客观指标的局限性，推动了音频编辑领域的发展。

Abstract: Audio editing aims to manipulate audio content based on textual descriptions,
supporting tasks such as adding, removing, or replacing audio events. Despite
recent progress, the lack of high-quality benchmark datasets and comprehensive
evaluation metrics remains a major challenge for both assessing audio editing
quality and improving the task itself. In this work, we propose a novel
approach for audio editing task by incorporating expert knowledge into both the
evaluation and dataset construction processes: 1) First, we establish
AuditScore, the first comprehensive dataset for subjective evaluation of audio
editing, consisting of over 6,300 edited samples generated from 7
representative audio editing frameworks and 23 system configurations. Each
sample is annotated by professional raters on three key aspects of audio
editing quality: overall Quality, Relevance to editing intent, and Faithfulness
to original features. 2) Based on this dataset, we train AuditEval, the first
model designed for automatic MOS-style scoring tailored to audio editing tasks.
AuditEval addresses the critical lack of objective evaluation metrics and the
prohibitive cost of subjective assessment in this field. 3) We further leverage
AuditEval to evaluate and filter a large amount of synthetically mixed editing
pairs, constructing a high-quality pseudo-parallel dataset by selecting the
most plausible samples. Objective experiments validate the effectiveness of our
expert-informed filtering strategy in yielding higher-quality data, while also
revealing the limitations of relying solely on objective metrics. The dataset,
codes and tools can be found at: https://github.com/NKU-HLT/AuditEval.

</details>


### [373] [Optimizing Neural Architectures for Hindi Speech Separation and Enhancement in Noisy Environments](https://arxiv.org/abs/2508.12009)
*Arnav Ramamoorthy*

Main category: cs.SD

TL;DR: 基于DEMUCS模型的印地语语音分离与增强方法，通过U-Net和LSTM层优化，在嘈杂环境下显著提升语音清晰度，并探索了边缘设备量化部署方案。


<details>
  <summary>Details</summary>
Motivation: 解决印地语语音分离和增强在边缘设备上的挑战，克服传统方法的局限性，为印度语境下的语音处理提供定制化AI解决方案。

Method: 使用改进的DEMUCS模型架构，结合U-Net和LSTM层进行微调，在40万条印地语语音片段数据集上训练，并采用ESC-50和MS-SNSD进行数据增强以模拟多样化声学环境。

Result: 在PESQ和STOI评估指标上表现出优越性能，特别是在极端噪声条件下。通过量化技术成功降低了计算需求，适合TWS耳机等资源受限设备部署。

Conclusion: 研究表明定制化AI算法在印度语境语音处理中的有效性，为边缘设备架构优化提供了未来发展方向。

Abstract: This paper addresses the challenges of Hindi speech separation and
enhancement using advanced neural network architectures, with a focus on edge
devices. We propose a refined approach leveraging the DEMUCS model to overcome
limitations of traditional methods, achieving substantial improvements in
speech clarity and intelligibility. The model is fine-tuned with U-Net and LSTM
layers, trained on a dataset of 400,000 Hindi speech clips augmented with
ESC-50 and MS-SNSD for diverse acoustic environments. Evaluation using PESQ and
STOI metrics shows superior performance, particularly under extreme noise
conditions. To ensure deployment on resource-constrained devices like TWS
earbuds, we explore quantization techniques to reduce computational
requirements. This research highlights the effectiveness of customized AI
algorithms for speech processing in Indian contexts and suggests future
directions for optimizing edge-based architectures.

</details>


### [374] [Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection](https://arxiv.org/abs/2508.12230)
*Bing Han,Anbai Jiang,Xinhu Zheng,Wei-Qiang Zhang,Jia Liu,Pingyi Fan,Yanmin Qian*

Main category: cs.SD

TL;DR: 该论文提出了一种基于自监督预训练模型的机器异常声音检测方法，通过LoRA微调、机器感知组适配器和动态聚类对比学习来提升泛化性能，在多个基准测试中取得显著改进


<details>
  <summary>Details</summary>
Motivation: 机器异常声音检测(ASD)在数据收集和复杂声学环境下面临泛化性能受限的问题，受大型预训练模型在其他领域成功的启发，希望利用音频预训练模型来提升ASD性能

Method: 使用自监督预训练模型，采用全连接低秩适应(LoRA)进行微调，提出机器感知组适配器模块来捕获不同机器间的差异，设计基于向量量化和双层次对比学习的动态聚类目标函数

Result: 在DCASE 2020-2024所有基准数据集上的实验结果表明，新方法取得了显著改进，证明了所提策略的有效性

Conclusion: 预训练模型对ASD任务具有重要价值，即使预训练数据与目标任务存在不一致性；提出的LoRA微调、机器感知适配器和动态聚类对比学习方法能有效提升ASD系统的泛化性能

Abstract: Machine anomalous sound detection (ASD) is a valuable technique across
various applications. However, its generalization performance is often limited
due to challenges in data collection and the complexity of acoustic
environments. Inspired by the success of large pre-trained models in numerous
fields, this paper introduces a robust ASD model that leverages self-supervised
pre-trained models trained on large-scale speech and audio datasets. Although
there are inconsistencies between the pre-training datasets and the ASD task,
our findings indicate that pre-training still provides substantial benefits for
ASD. To mitigate overfitting and retain learned knowledge when fine-tuning with
limited data, we explore Fully-Connected Low-Rank Adaptation (LoRA) as an
alternative to full fine-tuning. Additionally, we propose a Machine-aware Group
Adapter module, which enables the model to capture differences between various
machines within a unified framework, thereby enhancing the generalization
performance of ASD systems. To address the challenge of missing attribute
labels, we design a novel objective function that dynamically clusters
unattributed data using vector quantization and optimizes through a dual-level
contrastive learning loss. The proposed methods are evaluated on all benchmark
datasets, including the DCASE 2020-2024 five ASD challenges, and the
experimental results show significant improvements of our new approach and
demonstrate the effectiveness of our proposed strategies.

</details>


### [375] [HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization](https://arxiv.org/abs/2508.12292)
*Hyebin Ahn,Kangwook Jang,Hoirin Kim*

Main category: cs.SD

TL;DR: HuBERT-VIC是一个噪声鲁棒的语音基础模型，通过方差、不变性和协方差正则化目标来调整噪声语音表示，在噪声环境下相比基线模型有显著性能提升


<details>
  <summary>Details</summary>
Motivation: 大多数语音基础模型主要在干净数据上训练，在噪声环境下性能会下降，需要解决噪声鲁棒性问题

Method: 提出HuBERT-VIC模型，采用方差、不变性和协方差正则化(VICReg)目标来调整噪声语音表示的统计特性，捕捉多样化的声学特征

Result: 在LibriSpeech测试集上，相比在噪声语音上预训练的基线模型，test-clean相对提升23.3%，test-other相对提升13.2%

Conclusion: VICReg正则化目标能有效提升语音基础模型在噪声环境下的泛化能力和鲁棒性

Abstract: Noise robustness in speech foundation models (SFMs) has been a critical
challenge, as most models are primarily trained on clean data and experience
performance degradation when the models are exposed to noisy speech. To address
this issue, we propose HuBERT-VIC, a noise-robust SFM with variance,
in-variance, and covariance regularization (VICReg) objectives. These
objectives adjust the statistics of noisy speech representations, enabling the
model to capture diverse acoustic characteristics and improving the
generalization ability across different types of noise. When applied to HuBERT,
our model shows relative performance improvements of 23.3% on LibriSpeech
test-clean and 13.2% on test-other, compared to the baseline model pre-trained
on noisy speech.

</details>


### [376] [Cross-Modal Knowledge Distillation with Multi-Level Data Augmentation for Low-Resource Audio-Visual Sound Event Localization and Detection](https://arxiv.org/abs/2508.12334)
*Qing Wang,Ya Jiang,Hang Chen,Sabato Marco Siniscalchi,Jun Du,Jianqing Gao*

Main category: cs.SD

TL;DR: 提出跨模态知识蒸馏框架结合多级数据增强，用于低资源音频-视觉声音事件定位与检测，通过音频教师模型向AV学生模型传递知识，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 解决低资源条件下音频-视觉声音事件定位与检测的性能瓶颈问题，利用知识蒸馏技术从音频模型向多模态模型传递知识

Method: 使用音频SELD模型作为教师，通过输出响应和中间特征表示向AV学生模型进行跨模态知识蒸馏，结合多层级特征混合的数据增强和SELD任务定制的损失函数

Result: 在DCASE 2023和2024数据集上相对基线提升22%~36%的整体指标，达到或超过在大数据集上训练的教师模型性能，超越现有最先进方法

Conclusion: 跨模态知识蒸馏结合多级数据增强能有效提升低资源AV SELD性能，证明了从单模态向多模态知识转移的有效性

Abstract: This work presents a cross-modal knowledge distillation (CMKD) framework
combined with multi-level data augmentation for low-resource audio-visual (AV)
sound event localization and detection (SELD). An audio-only SELD model acts as
the teacher, transferring knowledge to an AV student model through both output
responses and intermediate feature representations. To enhance learning, data
augmentation is applied by mixing features randomly selected from multiple
network layers and associated loss functions tailored to the SELD task.
Extensive experiments on the DCASE 2023 and 2024 SELD datasets show that the
proposed method significantly improves AV SELD performance, yielding relative
gains of 22%~36% in the overall metric over the baseline. Notably, our approach
achieves results comparable to or better than teacher models trained on much
larger datasets, surpassing state-of-the-art methods on both DCASE 2023 and
2024 SELD tasks.

</details>


### [377] [Exploring the Feasibility of LLMs for Automated Music Emotion Annotation](https://arxiv.org/abs/2508.12626)
*Meng Yang,Jon McCormack,Maria Teresa Llano,Wanchao Su*

Main category: cs.SD

TL;DR: 本研究探讨使用GPT-4o进行音乐情感标注的可行性，在古典钢琴MIDI数据集上与人类专家标注进行对比评估，发现GPT标注虽不及人类准确但具有成本效益优势


<details>
  <summary>Details</summary>
Motivation: 当前音乐情感标注主要依赖人工标注，资源消耗大且限制了标注数据规模，需要探索自动化标注的可行性

Method: 使用GPT-4o对GiantMIDI-Piano古典钢琴数据集进行四象限效价-唤醒度情感标注，并与三位人类专家标注进行对比，采用标准准确率、加权准确率、标注者间一致性指标和分布相似性等多维度评估

Result: GPT的标注性能在整体准确率上低于人类专家，对特定情感状态的分类不够细致，但其标注变异性仍在专家自然分歧范围内

Conclusion: GPT标注虽然目前相对人类表现存在不足，但其成本效益和高效率使其成为音乐情感标注的有前景的可扩展替代方案

Abstract: Current approaches to music emotion annotation remain heavily reliant on
manual labelling, a process that imposes significant resource and labour
burdens, severely limiting the scale of available annotated data. This study
examines the feasibility and reliability of employing a large language model
(GPT-4o) for music emotion annotation. In this study, we annotated
GiantMIDI-Piano, a classical MIDI piano music dataset, in a four-quadrant
valence-arousal framework using GPT-4o, and compared against annotations
provided by three human experts. We conducted extensive evaluations to assess
the performance and reliability of GPT-generated music emotion annotations,
including standard accuracy, weighted accuracy that accounts for inter-expert
agreement, inter-annotator agreement metrics, and distributional similarity of
the generated labels.
  While GPT's annotation performance fell short of human experts in overall
accuracy and exhibited less nuance in categorizing specific emotional states,
inter-rater reliability metrics indicate that GPT's variability remains within
the range of natural disagreement among experts. These findings underscore both
the limitations and potential of GPT-based annotation: despite its current
shortcomings relative to human performance, its cost-effectiveness and
efficiency render it a promising scalable alternative for music emotion
annotation.

</details>


### [378] [MATPAC++: Enhanced Masked Latent Prediction for Self-Supervised Audio Representation Learning](https://arxiv.org/abs/2508.12709)
*Aurian Quelennec,Pierre Chouteau,Geoffroy Peeters,Slim Essid*

Main category: cs.SD

TL;DR: 该论文提出MATPAC++，在MATPAC自监督学习系统中集成多选择学习(MCL)来处理音频预测的模糊性，在AudioSet微调和多个下游任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码潜在预测自监督学习方法忽略了预测器模块在处理多声源音频内容模糊性方面的重要性，需要改进预测质量。

Method: 在MATPAC系统基础上集成多选择学习(MCL)，改进其预测和无监督分类任务，显式建模预测模糊性。

Result: 在AudioSet微调和多个下游任务上达到最先进性能，在音乐数据上训练时效率显著提升且性能最优。

Conclusion: MCL能有效处理音频预测的模糊性问题，提升表示学习质量，在通用音频和音乐领域都表现出色。

Abstract: Masked latent prediction has emerged as a leading paradigm in self-supervised
learning (SSL), especially for general audio and music representation learning.
While recent methods have demonstrated strong performance, the role of the
predictor module used at the output of such SSL systems remains mainly
overlooked, despite being crucial for solving the pretext task at hand. In
particular, this module should be able to deal with the ambiguity inherent in
audio content, especially when it is composed of multiple sound sources. This
work proposes a novel enhancement: integrating Multiple Choice Learning (MCL)
to explicitly model prediction ambiguity and improve representation quality. We
build on top of the recently proposed MATPAC system, improving its prediction
and unsupervised classification pretext tasks with MCL. We extensively evaluate
our method, MATPAC++, through both linear probing across multiple downstream
tasks and fine-tuning on AudioSet, employing a unified protocol that enables
rigorous and fair comparisons with state-of-the-art SSL approaches. Results
show that our proposal achieves state-of-the-art when fine-tuned on AudioSet
and overall state-of-the-art scores on downstream tasks. Additionally, we
examine domain specialisation by training exclusively on music data, where our
model achieves state-of-the-art performance with significantly improved
efficiency.

</details>


### [379] [FoleySpace: Vision-Aligned Binaural Spatial Audio Generation](https://arxiv.org/abs/2508.12918)
*Lei Zhao,Rujin Chen,Chi Zhang,Xiao-Lei Zhang,Xuelong Li*

Main category: cs.SD

TL;DR: FoleySpace是一个视频到双耳音频生成框架，通过视觉信息引导生成具有空间一致性的沉浸式立体声，解决了现有单声道音频缺乏空间感知的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频技术主要关注单声道音频生成，缺乏空间感知能力，而能够提供更强沉浸感的双耳空间音频生成技术研究不足。

Method: 提出声音源估计方法确定视频帧中的声源2D坐标和深度，通过坐标映射机制转换为3D轨迹，结合预训练V2A模型生成的单声道音频，作为扩散模型的输入条件来生成空间一致的双耳音频。

Result: 实验结果表明，该方法在空间感知一致性方面优于现有方法，有效提升了音视频体验的沉浸质量。

Conclusion: FoleySpace框架成功实现了视频到双耳音频的生成，通过视觉引导的空间音频合成技术显著增强了音频的空间感知和沉浸感。

Abstract: Recently, with the advancement of AIGC, deep learning-based video-to-audio
(V2A) technology has garnered significant attention. However, existing research
mostly focuses on mono audio generation that lacks spatial perception, while
the exploration of binaural spatial audio generation technologies, which can
provide a stronger sense of immersion, remains insufficient. To solve this
problem, we propose FoleySpace, a framework for video-to-binaural audio
generation that produces immersive and spatially consistent stereo sound guided
by visual information. Specifically, we develop a sound source estimation
method to determine the sound source 2D coordinates and depth in each video
frame, and then employ a coordinate mapping mechanism to convert the 2D source
positions into a 3D trajectory. This 3D trajectory, together with the monaural
audio generated by a pre-trained V2A model, serves as a conditioning input for
a diffusion model to generate spatially consistent binaural audio. To support
the generation of dynamic sound fields, we constructed a training dataset based
on recorded Head-Related Impulse Responses that includes various sound source
movement scenarios. Experimental results demonstrate that the proposed method
outperforms existing approaches in spatial perception consistency, effectively
enhancing the immersive quality of the audio-visual experience.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [380] [Discovering Expert-Level Nash Equilibrium Algorithms with Large Language Models](https://arxiv.org/abs/2508.11874)
*Hanyu Li,Dongchen Li,Xiaotie Deng*

Main category: cs.GT

TL;DR: LegoNE框架通过将算法转换为约束优化问题，自动推导和证明算法性能保证，使AI能在数小时内重新发现人类15年才完成的双人博弈最优算法，并发现超越人类设计的三玩家博弈新算法。


<details>
  <summary>Details</summary>
Motivation: 传统算法性能证明需要大量易错的人工努力，而AI虽然能解决具体问题实例，但自动化发现具有可证明保证的通用算法仍面临重大障碍，需要将算法设计的创造性过程与形式化分析的严谨过程相结合。

Method: 提出LegoNE框架，将用简单Python类语言编写的算法自动转换为约束优化问题，通过求解该问题来推导和证明算法的近似边界。

Result: 使用LegoNE，大语言模型在数小时内重新发现了双人博弈的最先进算法（人类耗时15年），并为三玩家博弈发现了超越所有现有人类设计算法的新算法。

Conclusion: 这项工作展示了理论科学中新的人机协作范式：人类在更高抽象层次进行推理，使用符号压缩搜索空间，AI在其中探索，实现两者单独都无法完成的成就。

Abstract: Algorithm design and analysis is a cornerstone of computer science, but it
confronts a major challenge. Proving an algorithm's performance guarantee
across all inputs has traditionally required extensive and often error-prone
human effort. While AI has shown great success in finding solutions to specific
problem instances, automating the discovery of general algorithms with such
provable guarantees has remained a significant barrier. This challenge stems
from the difficulty of integrating the creative process of algorithm design
with the rigorous process of formal analysis. To address this gap, we propose
LegoNE, a framework that tightly fuses these two processes for the fundamental
and notoriously difficult problem of computing approximate Nash equilibria.
LegoNE automatically translates any algorithm written by a simple Python-like
language into a constrained optimization problem. Solving this problem derives
and proves the algorithm's approximation bound. Using LegoNE, a
state-of-the-art large language model rediscovered the state-of-the-art
algorithm for two-player games within hours, a feat that had taken human
researchers 15 years to achieve. For three-player games, the model discovered a
novel algorithm surpassing all existing human-designed ones. This work
demonstrates a new human-machine collaborative paradigm for theoretical
science: humans reason at a higher-abstract level, using symbols to compress
the search space, and AI explores within it, achieving what neither could
alone.

</details>


### [381] [Computing Approximately Proportional Allocations of Indivisible Goods: Beyond Additive and Monotone Valuations](https://arxiv.org/abs/2508.12453)
*Martin Jupakkal Andersen,Ioannis Caragiannis,Anders Bo Ipsen,Alexander Søltoft*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Although approximate notions of envy-freeness-such as envy-freeness up to one
good (EF1)-have been extensively studied for indivisible goods, the seemingly
simpler fairness concept of proportionality up to one good (PROP1) has received
far less attention. For additive valuations, every EF1 allocation is PROP1, and
well-known algorithms such as Round-Robin and Envy-Cycle Elimination compute
such allocations in polynomial time. PROP1 is also compatible with Pareto
efficiency, as maximum Nash welfare allocations are EF1 and hence PROP1.
  We ask whether these favorable properties extend to non-additive valuations.
We study a broad class of allocation instances with {\em satiating goods},
where agents have non-negative valuation functions that need not be monotone,
allowing for negative marginal values. We present the following results:
  - EF1 implies PROP1 for submodular valuations over satiating goods, ensuring
existence and efficient computation via Envy-Cycle Elimination for monotone
submodular valuations;
  - Round-robin computes a partial PROP1 allocation after the second-to-last
round for satiating submodular goods and a complete PROP1 for monotone
submodular valuations;
  - PROP1 allocations for satiating subadditive goods can be computed in
polynomial-time;
  - Maximum Nash welfare allocations are PROP1 for monotone submodular goods,
revealing yet another facet of their ``unreasonable fairness.''

</details>


### [382] [Group Fair Matchings using Convex Cost Functions](https://arxiv.org/abs/2508.12549)
*Atasi Panda,Harsh Sharma,Anand Louis,Prajakta Nimbhorkar*

Main category: cs.GT

TL;DR: 提出一个多项式时间近似算法，用于解决带有组公平性约束的平台物品分配问题，通过凸成本函数替代硬约束来实现柔性公平性权衡


<details>
  <summary>Details</summary>
Motivation: 传统公平性约束（如限制支配和少数群体保护）采用硬边界限制，缺乏灵活性。需要一种能够通过成本惩罚来平衡平台总体成本和组特定成本的柔性方法

Method: 基于线性规划和网络流技术，设计多项式时间近似算法来处理凸成本函数和效用约束的组合优化问题

Result: 开发了高效的近似算法，提供理论保证，并在特殊情况下（效用均匀）提供精确算法，证明了任意组交集情况下问题的困难性

Conclusion: 提出的凸成本框架为组公平性提供了更灵活的建模方式，近似算法在实际应用中具有可行性和有效性

Abstract: We consider the problem of assigning items to platforms where each item has a
utility associated with each of the platforms to which it can be assigned. Each
platform has a soft constraint over the total number of items it serves,
modeled via a convex cost function. Additionally, items are partitioned into
groups, and each platform also incurs group-specific convex cost over the
number of items from each group that can be assigned to the platform. These
costs promote group fairness by penalizing imbalances, yielding a soft
variation of fairness notions introduced in prior work, such as Restricted
Dominance and Minority protection. Restricted Dominance enforces upper bounds
on group representation, while Minority protection enforces lower bounds. Our
approach replaces such hard constraints with cost-based penalties, allowing
more flexible trade-offs. Our model also captures Nash Social Welfare kind of
objective.
  The cost of an assignment is the sum of the values of all the cost functions
across all the groups and platforms. The objective is to find an assignment
that minimizes the cost while achieving a total utility that is at least a
user-specified threshold. The main challenge lies in balancing the overall
platform cost with group-specific costs, both governed by convex functions,
while meeting the utility constraint. We present an efficient polynomial-time
approximation algorithm, supported by theoretical guarantees and experimental
evaluation. Our algorithm is based on techniques involving linear programming
and network flows. We also provide an exact algorithm for a special case with
uniform utilities and establish the hardness of the general problem when the
groups can intersect arbitrarily.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [383] [Toward Practical Equilibrium Propagation: Brain-inspired Recurrent Neural Network with Feedback Regulation and Residual Connections](https://arxiv.org/abs/2508.11659)
*Zhuo Liu,Tao Chen*

Main category: cs.NE

TL;DR: 提出了一种生物启发的反馈调节残差循环神经网络(FRE-RNN)，在平衡传播(EP)框架中大幅降低了计算成本和训练时间，性能可与反向传播相媲美。


<details>
  <summary>Details</summary>
Motivation: 平衡传播(EP)是一种生物可信的学习框架，但现有实现存在不稳定性和计算成本过高的问题，限制了其在大规模网络中的应用。

Method: 设计反馈调节机制降低谱半径实现快速收敛，采用脑启发的残差连接拓扑结构缓解深度RNN中的梯度消失问题。

Result: 计算成本和训练时间降低了数量级，在基准任务中达到与反向传播相当的性能。

Conclusion: 该方法显著增强了EP在大规模网络中的适用性和实用性，为物理神经网络中的原位学习实现提供了指导。

Abstract: Brain-like intelligent systems need brain-like learning methods. Equilibrium
Propagation (EP) is a biologically plausible learning framework with strong
potential for brain-inspired computing hardware. However, existing
im-plementations of EP suffer from instability and prohibi-tively high
computational costs. Inspired by the structure and dynamics of the brain, we
propose a biologically plau-sible Feedback-regulated REsidual recurrent neural
network (FRE-RNN) and study its learning performance in EP framework. Feedback
regulation enables rapid convergence by reducing the spectral radius. The
improvement in con-vergence property reduces the computational cost and
train-ing time of EP by orders of magnitude, delivering perfor-mance on par
with backpropagation (BP) in benchmark tasks. Meanwhile, residual connections
with brain-inspired topologies help alleviate the vanishing gradient problem
that arises when feedback pathways are weak in deep RNNs. Our approach
substantially enhances the applicabil-ity and practicality of EP in large-scale
networks that un-derpin artificial intelligence. The techniques developed here
also offer guidance to implementing in-situ learning in physical neural
networks.

</details>


### [384] [Learning Internal Biological Neuron Parameters and Complexity-Based Encoding for Improved Spiking Neural Networks Performance](https://arxiv.org/abs/2508.11674)
*Zofia Rudnicka,Janusz Szczepanski,Agnieszka Pregowska*

Main category: cs.NE

TL;DR: 本研究提出用概率元神经元替代传统感知器神经元，结合Lempel-Ziv复杂度构建新型SNN分类框架，在多种学习算法下分类效率最高提升11%


<details>
  <summary>Details</summary>
Motivation: 传统SNN神经元模型存在局限性，需要更生物启发的神经元模型来提高分类准确率，同时现有方法未能有效处理时空神经数据的分类问题

Method: 提出概率元神经元模型替代传统LIF神经元，结合Lempel-Ziv复杂度构建分类框架，使用反向传播、STDP和Tempotron等学习算法，采用泊松过程模拟神经元放电

Result: 实验结果显示，根据训练方法的不同，分类器效率最高可提升11.00%，证明学习额外神经元参数的优势

Conclusion: 概率元神经元模型和LZC-SNN结合框架能有效提升SNN分类性能，为时空神经数据分类提供了高效可解释的新方法

Abstract: This study introduces a novel approach by replacing the traditional
perceptron neuron model with a biologically inspired probabilistic meta neuron,
where the internal neuron parameters are jointly learned, leading to improved
classification accuracy of spiking neural networks (SNNs). To validate this
innovation, we implement and compare two SNN architectures: one based on
standard leaky integrate-and-fire (LIF) neurons and another utilizing the
proposed probabilistic meta neuron model. As a second key contribution, we
present a new biologically inspired classification framework that uniquely
integrates SNNs with Lempel-Ziv complexity (LZC) a measure closely related to
entropy rate. By combining the temporal precision and biological plausibility
of SNNs with the capacity of LZC to capture structural regularity, the proposed
approach enables efficient and interpretable classification of spatiotemporal
neural data, an aspect not addressed in existing works. We consider learning
algorithms such as backpropagation, spike-timing-dependent plasticity (STDP),
and the Tempotron learning rule. To explore neural dynamics, we use Poisson
processes to model neuronal spike trains, a well-established method for
simulating the stochastic firing behavior of biological neurons. Our results
reveal that depending on the training method, the classifier's efficiency can
improve by up to 11.00%, highlighting the advantage of learning additional
neuron parameters beyond the traditional focus on weighted inputs alone.

</details>


### [385] [Adaptive Spiking with Plasticity for Energy Aware Neuromorphic Systems](https://arxiv.org/abs/2508.11689)
*Eduardo Calle-Ortiz,Hui Guan,Deepak Ganesan,Phuc Nguyen*

Main category: cs.NE

TL;DR: ASPEN是一种新型的神经形态系统能量感知技术，通过随机扰动神经元阈值来减少脉冲活动，从而显著降低能量消耗，同时保持与最先进方法相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 探索神经形态计算在可穿戴设备中的可行性，开发自适应脉冲技术以实现能量感知计算，这对于始终在线应用中的资源受限设备具有变革性意义。

Method: 利用训练期间对神经元阈值的随机扰动，不仅增强网络在不同阈值下的鲁棒性，还作为正则化器提高泛化能力、减少脉冲活动，并实现无需复杂重新训练或剪枝的能量控制。

Result: 在神经形态仿真器和硬件上的评估显示，ASPEN显著减少了脉冲计数和能量消耗，同时保持了与最先进方法相当的准确性。

Conclusion: ASPEN提供了一种轻量级且可扩展的动态能量控制技术，无需重新配置整个模型，为超低功耗可穿戴设备的发展开辟了新途径。

Abstract: This paper presents ASPEN, a novel energy-aware technique for neuromorphic
systems that could unleash the future of intelligent, always-on,
ultra-low-power, and low-burden wearables. Our main research objectives are to
explore the feasibility of neuromorphic computing for wearables, identify open
research directions, and demonstrate the feasibility of developing an adaptive
spiking technique for energy-aware computation, which can be game-changing for
resource-constrained devices in always-on applications. As neuromorphic
computing systems operate based on spike events, their energy consumption is
closely related to spiking activity, i.e., each spike incurs computational and
power costs; consequently, minimizing the number of spikes is a critical
strategy for operating under constrained energy budgets. To support this goal,
ASPEN utilizes stochastic perturbations to the neuronal threshold during
training to not only enhance the network's robustness across varying
thresholds, which can be controlled at inference time, but also act as a
regularizer that improves generalization, reduces spiking activity, and enables
energy control without the need for complex retraining or pruning. More
specifically, ASPEN adaptively adjusts intrinsic neuronal parameters as a
lightweight and scalable technique for dynamic energy control without
reconfiguring the entire model. Our evaluation on neuromorphic emulator and
hardware shows that ASPEN significantly reduces spike counts and energy
consumption while maintaining accuracy comparable to state-of-the-art methods.

</details>


### [386] [Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming](https://arxiv.org/abs/2508.11703)
*Vasileios Saketos,Sebastian Kaltenbach,Sergey Litvinov,Petros Koumoutsakos*

Main category: cs.NE

TL;DR: 本文研究通过结合笛卡尔遗传编程(CGP)和大语言模型(LLM)的自动化进化过程来发现卡尔曼滤波算法，在满足和不满足卡尔曼最优性假设的情况下都能找到优秀解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统算法发现依赖人类智慧和大量实验，研究探索是否可以通过自动化的数据驱动进化过程来发现重要的科学计算算法。

Method: 使用笛卡尔遗传编程(CGP)和大语言模型(LLM)相结合的框架，在卡尔曼最优性假设成立和违反的不同条件下进行算法发现。

Result: 当卡尔曼最优性假设成立时，框架收敛到接近最优解；当假设违反时，进化出可解释的替代方案，性能优于卡尔曼滤波器。

Conclusion: 结合进化算法和生成模型进行可解释的数据驱动计算模块合成，是科学计算中算法发现的有效方法。

Abstract: Algorithmic discovery has traditionally relied on human ingenuity and
extensive experimentation. Here we investigate whether a prominent scientific
computing algorithm, the Kalman Filter, can be discovered through an automated,
data-driven, evolutionary process that relies on Cartesian Genetic Programming
(CGP) and Large Language Models (LLM). We evaluate the contributions of both
modalities (CGP and LLM) in discovering the Kalman filter under varying
conditions. Our results demonstrate that our framework of CGP and LLM-assisted
evolution converges to near-optimal solutions when Kalman optimality
assumptions hold. When these assumptions are violated, our framework evolves
interpretable alternatives that outperform the Kalman filter. These results
demonstrate that combining evolutionary algorithms and generative models for
interpretable, data-driven synthesis of simple computational modules is a
potent approach for algorithmic discovery in scientific computing.

</details>


### [387] [LLM4CMO: Large Language Model-aided Algorithm Design for Constrained Multiobjective Optimization](https://arxiv.org/abs/2508.11871)
*Zhen-Song Chen,Hong-Wei Ding,Xian-Jia Wang,Witold Pedrycz*

Main category: cs.NE

TL;DR: 提出LLM4CMO算法，利用大语言模型辅助设计双种群两阶段约束多目标优化算法，在基准测试和实际问题中优于11种先进基线算法


<details>
  <summary>Details</summary>
Motivation: 现有双种群两阶段算法在约束多目标优化中表现良好但设计复杂，大语言模型为算法设计提供新机会但整合应用不足

Method: 采用双种群两阶段框架：第一阶段识别约束和非约束Pareto前沿，第二阶段使用混合算子、epsilon约束处理、分类策略和动态资源分配进行优化，核心模块通过提示模板工程和LLM-人类交互设计

Result: 在6个基准测试套件和10个实际CMOP问题上优于11种先进基线算法，消融研究验证了LLM辅助模块化设计的有效性

Conclusion: LLM可以作为复杂进化优化算法开发的高效协同设计者

Abstract: Constrained multi-objective optimization problems (CMOPs) frequently arise in
real-world applications where multiple conflicting objectives must be optimized
under complex constraints. Existing dual-population two-stage algorithms have
shown promise by leveraging infeasible solutions to improve solution quality.
However, designing high-performing constrained multi-objective evolutionary
algorithms (CMOEAs) remains a challenging task due to the intricacy of
algorithmic components. Meanwhile, large language models (LLMs) offer new
opportunities for assisting with algorithm design; however, their effective
integration into such tasks remains underexplored. To address this gap, we
propose LLM4CMO, a novel CMOEA based on a dual-population, two-stage framework.
In Stage 1, the algorithm identifies both the constrained Pareto front (CPF)
and the unconstrained Pareto front (UPF). In Stage 2, it performs targeted
optimization using a combination of hybrid operators (HOps), an epsilon-based
constraint-handling method, and a classification-based UPF-CPF relationship
strategy, along with a dynamic resource allocation (DRA) mechanism. To reduce
design complexity, the core modules, including HOps, epsilon decay function,
and DRA, are decoupled and designed through prompt template engineering and
LLM-human interaction. Experimental results on six benchmark test suites and
ten real-world CMOPs demonstrate that LLM4CMO outperforms eleven
state-of-the-art baseline algorithms. Ablation studies further validate the
effectiveness of the LLM-aided modular design. These findings offer preliminary
evidence that LLMs can serve as efficient co-designers in the development of
complex evolutionary optimization algorithms. The code associated with this
article is available at https://anonymous.4open.science/r/LLM4CMO971.

</details>


### [388] [Improving MSA Estimation through Adaptive Weight Vectors in MOEA/D](https://arxiv.org/abs/2508.12133)
*Saem Hasan,Muhammad Ali Nayeem,M. Sohel Rahman*

Main category: cs.NE

TL;DR: MOEA/D-ADF是一种改进的多目标优化算法，结合PMAO形成PMAO++框架，通过生成多样化的比对-树对集合，显著提升了系统发育推断的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 准确的系统发育推断严重依赖于多序列比对的质量，但最优比对对于许多序列在计算上难以处理且对评分选择敏感，需要开发更有效的比对方法。

Method: 提出MOEA/D-ADF算法，基于适应度方差自适应调整子问题权重向量，改进探索-开发权衡。将MOEA/D-ADF与PMAO结合形成PMAO++，使用PMAO生成的解作为种子，通过30个权重向量演化种群，产生多样化的比对-树对集合。

Result: PMAO++在大多数基准案例上优于原始PMAO，在17个BAliBASE数据集中12个实现了更好的假阴性率，产生了多个零假阴性率的最佳树实例。生成的丰富比对-树对集合特别有利于下游汇总方法。

Conclusion: PMAO++在序列系统发育分析中展现出明显优势，未来工作将探索参数调优、更大基准测试套件以及与汇总树管道的更紧密集成，以进一步增强生物序列研究的适用性。

Abstract: Accurate phylogenetic inference from biological sequences depends critically
on the quality of multiple sequence alignments, yet optimal alignment for many
sequences is computationally intractable and sensitive to scoring choices. In
this work we introduce MOEA/D-ADF, a novel variant of MOEA/D that adaptively
adjusts subproblem weight vectors based on fitness variance to improve the
exploration-exploitation trade-off. We combine MOEA/D-ADF with PMAO (PASTA with
many application-aware optimization criteria) to form PMAO++, where
PMAO-generated solutions are used to seed MOEA/D-ADF, which then evolves a
population using 30 weight vectors to produce a diverse ensemble of
alignment-tree pairs. PMAO++ outperforms the original PMAO on a majority of
benchmark cases, achieving better false-negative (FN) rates on 12 of 17
BAliBASE-derived datasets and producing superior best-case trees, including
several instances with zero FN rate. Beyond improving single best alignments,
the rich set of alignment-tree pairs produced by PMAO++ is especially valuable
for downstream summary methods (for example, consensus and summary-tree
approaches), allowing more robust phylogenetic inference by integrating signal
across multiple plausible alignments and trees. Certain dataset features, such
as large terminal N/C extensions found in the RV40 group, remain challenging,
but overall PMAO++ demonstrates clear advantages for sequence-based
phylogenetic analysis. Future work will explore parameter tuning, larger
benchmark suites, and tighter integration with summary-tree pipelines to
further enhance applicability for biological sequence studies.

</details>


### [389] [A Self-Ensemble Inspired Approach for Effective Training of Binary-Weight Spiking Neural Networks](https://arxiv.org/abs/2508.12609)
*Qingyan Meng,Mingqing Xiao,Zhengyu Ma,Huihui Zhou,Yonghong Tian,Zhouchen Lin*

Main category: cs.NE

TL;DR: 本文提出了一种将脉冲神经网络(SNN)训练视为带噪声注入的二元激活神经网络自集成训练的新视角，并基于此开发了SEI-BWSNN方法，在低延迟下实现了高性能的二元权重SNN训练。


<details>
  <summary>Details</summary>
Motivation: SNN和BNN都面临不可微函数的训练挑战，但这两个领域之间的深层联系以及训练技术如何相互受益尚未得到系统研究。特别是二元权重SNN的训练更加困难。

Method: 通过分析反向传播过程，将前馈SNN训练视为带噪声注入的二元激活神经网络的自集成训练。提出了SEI-BWSNN方法，利用多短路结构和基于知识蒸馏的训练技术来改进(二元权重)SNN的训练。

Result: 在Transformer架构中二值化FFN层，仅用2个时间步就在ImageNet上达到了82.52%的准确率，证明了方法的有效性和二元权重SNN的潜力。

Conclusion: 该研究为SNN训练提供了新的理论视角，提出的SEI-BWSNN方法成功解决了二元权重SNN的训练难题，在低延迟下实现了高性能，展示了二元权重SNN的实际应用潜力。

Abstract: Spiking Neural Networks (SNNs) are a promising approach to low-power
applications on neuromorphic hardware due to their energy efficiency. However,
training SNNs is challenging because of the non-differentiable spike generation
function. To address this issue, the commonly used approach is to adopt the
backpropagation through time framework, while assigning the gradient of the
non-differentiable function with some surrogates. Similarly, Binary Neural
Networks (BNNs) also face the non-differentiability problem and rely on
approximating gradients. However, the deep relationship between these two
fields and how their training techniques can benefit each other has not been
systematically researched. Furthermore, training binary-weight SNNs is even
more difficult. In this work, we present a novel perspective on the dynamics of
SNNs and their close connection to BNNs through an analysis of the
backpropagation process. We demonstrate that training a feedforward SNN can be
viewed as training a self-ensemble of a binary-activation neural network with
noise injection. Drawing from this new understanding of SNN dynamics, we
introduce the Self-Ensemble Inspired training method for (Binary-Weight) SNNs
(SEI-BWSNN), which achieves high-performance results with low latency even for
the case of the 1-bit weights. Specifically, we leverage a structure of
multiple shortcuts and a knowledge distillation-based training technique to
improve the training of (binary-weight) SNNs. Notably, by binarizing FFN layers
in a Transformer architecture, our approach achieves 82.52% accuracy on
ImageNet with only 2 time steps, indicating the effectiveness of our
methodology and the potential of binary-weight SNNs.

</details>


### [390] [IzhiRISC-V -- a RISC-V-based Processor with Custom ISA Extension for Spiking Neuron Networks Processing with Izhikevich Neurons](https://arxiv.org/abs/2508.12846)
*Wiktor J. Szczerek,Artur Podobas*

Main category: cs.NE

TL;DR: 提出基于RISC-V的IzhiRISC-V处理器，通过自定义神经形态ISA扩展来解决SNN在通用硬件上效率低下的问题


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络在通用硬件（如RISC-V处理器）上运行时，由于需要重复使用基本指令更新所有神经元，导致能效优势被低效代码所抵消

Method: 引入自定义ISA扩展，包含神经形态指令用于脉冲神经元更新，并在现有ALU基础上实现定制硬件扩展

Result: 开发了支持自定义神经形态ISA扩展的RISC-V兼容处理器IzhiRISC-V

Conclusion: 这是实现基于RISC-V的大规模神经形态系统的第一步，为高效SNN处理提供了硬件解决方案

Abstract: Spiking Neural Network processing promises to provide high energy efficiency
due to the sparsity of the spiking events. However, when realized on
general-purpose hardware -- such as a RISC-V processor -- this promise can be
undermined and overshadowed by the inefficient code, stemming from repeated
usage of basic instructions for updating all the neurons in the network. One of
the possible solutions to this issue is the introduction of a custom ISA
extension with neuromorphic instructions for spiking neuron updating, and
realizing those instructions in bespoke hardware expansion to the existing ALU.
In this paper, we present the first step towards realizing a large-scale system
based on the RISC-V-compliant processor called IzhiRISC-V, supporting the
custom neuromorphic ISA extension.

</details>
