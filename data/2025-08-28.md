<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.SD](#cs.SD) [Total: 6]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.HC](#cs.HC) [Total: 18]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.GT](#cs.GT) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration](https://arxiv.org/abs/2508.19254)
*Jookyung Song,Mookyoung Kang,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出实时生成绘图系统，同时分析形式意图（结构、构图、风格）和上下文意图（语义、主题），通过多阶段生成流程实现低延迟的协同视觉创作


<details>
  <summary>Details</summary>
Motivation: 传统基于文本提示的生成系统主要捕捉高级上下文描述，无法同时处理地面级的几何特征和高级语义线索，需要开发能同时整合形式意图和上下文意图的统一转换过程

Method: 使用触摸屏界面和分布式推理架构，结合轮廓保持的结构控制与风格内容感知的图像合成，通过多阶段生成管道联合调节双重意图信号

Result: 系统实现了低延迟的两阶段转换，支持多用户在共享画布上协作，无论艺术专业水平如何都能参与同步的共同视觉创作

Conclusion: 该平台重新定义了人机交互作为共同创作和相互增强的过程，为实时协同视觉创作提供了新的可能性

Abstract: This paper presents a real-time generative drawing system that interprets and
integrates both formal intent - the structural, compositional, and stylistic
attributes of a sketch - and contextual intent - the semantic and thematic
meaning inferred from its visual content - into a unified transformation
process. Unlike conventional text-prompt-based generative systems, which
primarily capture high-level contextual descriptions, our approach
simultaneously analyzes ground-level intuitive geometric features such as line
trajectories, proportions, and spatial arrangement, and high-level semantic
cues extracted via vision-language models. These dual intent signals are
jointly conditioned in a multi-stage generation pipeline that combines
contour-preserving structural control with style- and content-aware image
synthesis. Implemented with a touchscreen-based interface and distributed
inference architecture, the system achieves low-latency, two-stage
transformation while supporting multi-user collaboration on shared canvases.
The resulting platform enables participants, regardless of artistic expertise,
to engage in synchronous, co-authored visual creation, redefining human-AI
interaction as a process of co-creation and mutual enhancement.

</details>


### [2] [TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models](https://arxiv.org/abs/2508.19257)
*Chenghao Liu,Jiachen Zhang,Chengxuan Li,Zhimu Zhou,Shixin Wu,Songfang Huang,Huiling Duan*

Main category: cs.CV

TL;DR: 通过时间切片融合(TTF)技术，在不需训练的情况下整合历史和当前视觉信息，提升VLA模型在机器人操纵任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型每步独立处理视觉输入，忽略了操纵任务中连续帧间的时间相关性和一致性，导致对视视噪声敏感且丢失了价值连续的时间信息

Method: 采用双维检测策略：高效灰度像素差异分析+关注机制语义相关性评估，通过硬融合策略和关键帧锚定进行选择性时间切片融合，避免错误累积

Result: 在LIBERO平台平均提升4.0个百分点(72.4% vs 68.4%)，SimplerEnv跨环境验证相对提升4.8%，真实机器人任务相对提升8.7%，具有模型无关性，同时支持OpenVLA和VLA-Cache架构

Conclusion: TTF方法有效利用时间信息提升VLA模型性能，还发现选择性重用Query矩阵可以同时提高性能和计算效率，为直接KQV矩阵重用策略提供了有前景的研究方向

Abstract: Vision-Language-Action (VLA) models process visual inputs independently at
each timestep, discarding valuable temporal information inherent in robotic
manipulation tasks. This frame-by-frame processing makes models vulnerable to
visual noise while ignoring the substantial coherence between consecutive
frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a
training-free approach that intelligently integrates historical and current
visual representations to enhance VLA inference quality. Our method employs
dual-dimension detection combining efficient grayscale pixel difference
analysis with attention-based semantic relevance assessment, enabling selective
temporal token fusion through hard fusion strategies and keyframe anchoring to
prevent error accumulation. Comprehensive experiments across LIBERO,
SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0
percentage points average on LIBERO (72.4\% vs 68.4\% baseline),
cross-environment validation on SimplerEnv (4.8\% relative improvement), and
8.7\% relative improvement on real robot tasks. Our approach proves
model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably,
TTF reveals that selective Query matrix reuse in attention mechanisms enhances
rather than compromises performance, suggesting promising directions for direct
KQV matrix reuse strategies that achieve computational acceleration while
improving task success rates.

</details>


### [3] [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](https://arxiv.org/abs/2508.20080)
*Changha Shin,Woong Oh Cho,Seon Joo Kim*

Main category: cs.CV

TL;DR: 通过3D高斯拟合技术优化双鱼眼摄像机模型，实现从不完美全景图像生成无缝新视角渲染的方法


<details>
  <summary>Details</summary>
Motivation: 平泽双鱼眼系统因镜头分离和角度异变导致全景图像不完美，影响虚拟现实和自主导航等应用

Method: 将双鱼眼摄像机模型集成到3D高斯拟合流程中，联合优化3D高斯参数和标定变量，模拟镜头间隔和角度异变

Result: 方法能够从不完美的全景输入生成无缝的新视角渲染，在真实数据集上超过现有的360度渲染模型

Conclusion: 提出的标定框架有效解决了双鱼眼系统的图像缝隙问题，为高质量全景内容制作提供了新的解决方案

Abstract: 360-degree visual content is widely shared on platforms such as YouTube and
plays a central role in virtual reality, robotics, and autonomous navigation.
However, consumer-grade dual-fisheye systems consistently yield imperfect
panoramas due to inherent lens separation and angular distortions. In this
work, we introduce a novel calibration framework that incorporates a
dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach
not only simulates the realistic visual artifacts produced by dual-fisheye
cameras but also enables the synthesis of seamlessly rendered 360-degree
images. By jointly optimizing 3D Gaussian parameters alongside calibration
variables that emulate lens gaps and angular distortions, our framework
transforms imperfect omnidirectional inputs into flawless novel view synthesis.
Extensive evaluations on real-world datasets confirm that our method produces
seamless renderings-even from imperfect images-and outperforms existing
360-degree rendering models.

</details>


### [4] [Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation](https://arxiv.org/abs/2508.19289)
*Tai Inui,Steven Oh,Magdeline Kuan*

Main category: cs.CV

TL;DR: 无监督幻灯片质量评估系统，结合专家视觉设计指标和CLIP-ViT嵌入，通过异常检测评估幻灯片质量，相关系数达0.83，显著超过现有视觉-语言模型。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展、对象的幻灯片质量评估，提供实时反馈，近似观众对幻灯片质量的感知。

Method: 结合7个专家受启发的视视设计指标（白边、色彩丰富度、边缘密度、亮度对比、文本密度、色彩和谐、布局平衡）和CLIP-ViT嵌入，使用Isolation Forest异常分数进行评估。在12k专业讲座幻灯片上训练。

Result: 在6个学术讲座（115张幻灯片）上评估，与人类视觉质量评分的Pearson相关系数达0.83，比领先视觉-语言模型强1.79-3.23倍。显示了与视觉评分的收敛效度、与演讲表达评分的区别效度，以及与整体印象的探索性对齐。

Conclusion: 通过将低级设计线索与多模态嵌入相结合，可以精确近似观众对幻灯片质量的感知，实现可扩展、对象的实时评估。

Abstract: We present an unsupervised slide-quality assessment pipeline that combines
seven expert-inspired visual-design metrics (whitespace, colorfulness, edge
density, brightness contrast, text density, color harmony, layout balance) with
CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate
presentation slides. Trained on 12k professional lecture slides and evaluated
on six academic talks (115 slides), our method achieved Pearson correlations up
to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores
from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude
Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual
ratings, discriminant validity against speaker-delivery scores, and exploratory
alignment with overall impressions. Our results show that augmenting low-level
design cues with multimodal embeddings closely approximates audience
perceptions of slide quality, enabling scalable, objective feedback in real
time.

</details>


### [5] [Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation](https://arxiv.org/abs/2508.19290)
*Alexandros Gkillas,Ioulia Kapsali,Nikos Piperigkos,Aris S. Lalos*

Main category: cs.CV

TL;DR: 提出针对2D范围视图LiDAR分割的高效对抗防御框架，通过数学优化的可解释净化网络实现强对抗鲁棒性，计算开销小，在实际自动驾驶场景中验证有效


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR分割网络易受对抗攻击威胁安全，但多数防御方法针对3D点云且计算量大，而广泛使用的2D范围视图表示缺乏轻量级专用防御方案

Method: 提出基于数学优化问题的可解释净化网络框架，直接在范围视图域制定攻击公式，实现高效模型净化

Result: 在公开基准测试中达到竞争性性能，一致优于生成式和对抗训练基线方法，实际车辆部署验证了在真实自动驾驶场景中的准确运行能力

Conclusion: 该框架为2D范围视图LiDAR分割提供了高效实用的对抗防御解决方案，具有最小计算开销和强鲁棒性，适用于实际自动驾驶应用

Abstract: LiDAR-based segmentation is essential for reliable perception in autonomous
vehicles, yet modern segmentation networks are highly susceptible to
adversarial attacks that can compromise safety. Most existing defenses are
designed for networks operating directly on raw 3D point clouds and rely on
large, computationally intensive generative models. However, many
state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D
range view representations. Despite their widespread adoption, dedicated
lightweight adversarial defenses for this domain remain largely unexplored. We
introduce an efficient model-based purification framework tailored for
adversarial defense in 2D range-view LiDAR segmentation. We propose a direct
attack formulation in the range-view domain and develop an explainable
purification network based on a mathematical justified optimization problem,
achieving strong adversarial resilience with minimal computational overhead.
Our method achieves competitive performance on open benchmarks, consistently
outperforming generative and adversarial training baselines. More importantly,
real-world deployment on a demo vehicle demonstrates the framework's ability to
deliver accurate operation in practical autonomous driving scenarios.

</details>


### [6] [Context-aware Sparse Spatiotemporal Learning for Event-based Vision](https://arxiv.org/abs/2508.19806)
*Shenqi Wang,Guangzhi Tang*

Main category: cs.CV

TL;DR: 提出CSSL框架，通过上下文感知阈值动态调节神经元激活，在事件相机视觉任务中实现高稀疏性和优异性能


<details>
  <summary>Details</summary>
Motivation: 现有事件处理方法未能充分利用事件数据的稀疏性，神经形态计算中的脉冲神经网络在复杂任务中性能不足，且实现高激活稀疏性需要复杂的手动调参

Method: Context-aware Sparse Spatiotemporal Learning (CSSL)框架，引入上下文感知阈值机制，根据输入分布动态调节神经元激活，无需显式稀疏约束即可自然降低激活密度

Result: 在事件相机目标检测和光流估计任务中，CSSL达到或超越最先进方法性能，同时保持极高的神经元稀疏性

Conclusion: CSSL框架为神经形态处理实现高效事件相机视觉提供了关键解决方案，在性能和效率之间取得了良好平衡

Abstract: Event-based camera has emerged as a promising paradigm for robot perception,
offering advantages with high temporal resolution, high dynamic range, and
robustness to motion blur. However, existing deep learning-based event
processing methods often fail to fully leverage the sparse nature of event
data, complicating their integration into resource-constrained edge
applications. While neuromorphic computing provides an energy-efficient
alternative, spiking neural networks struggle to match of performance of
state-of-the-art models in complex event-based vision tasks, like object
detection and optical flow. Moreover, achieving high activation sparsity in
neural networks is still difficult and often demands careful manual tuning of
sparsity-inducing loss terms. Here, we propose Context-aware Sparse
Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware
thresholding to dynamically regulate neuron activations based on the input
distribution, naturally reducing activation density without explicit sparsity
constraints. Applied to event-based object detection and optical flow
estimation, CSSL achieves comparable or superior performance to
state-of-the-art methods while maintaining extremely high neuronal sparsity.
Our experimental results highlight CSSL's crucial role in enabling efficient
event-based vision for neuromorphic processing.

</details>


### [7] [Object Detection with Multimodal Large Vision-Language Models: An In-depth Review](https://arxiv.org/abs/2508.19294)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 这篇综述论文系统分析了大型视觉语言模型(LVLMs)在目标检测领域的应用，重点探讨了视觉与语言融合如何提升目标检测的适应性、上下文推理和泛化能力，并展望了该技术的未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习目标检测架构存在局限性，需要探索视觉与语言融合的新范式来提升目标检测的上下文理解能力和泛化性能。

Method: 采用三步研究综述方法：1)分析视觉语言模型在目标检测中的工作原理；2)研究最新的架构创新、训练范式和输出灵活性；3)深入探讨视觉与文本信息整合方法。

Result: LVLMs在多样化场景中展现出卓越的定位和分割效果，预计很快将达到或超越传统方法的性能，但在实时性、适应性和复杂性方面仍需改进。

Conclusion: LVLMs的最新进展已经并将继续对目标检测和机器人应用产生变革性影响，需要解决当前模型的局限性并制定清晰的发展路线图。

Abstract: The fusion of language and vision in large vision-language models (LVLMs) has
revolutionized deep learning-based object detection by enhancing adaptability,
contextual reasoning, and generalization beyond traditional architectures. This
in-depth review presents a structured exploration of the state-of-the-art in
LVLMs, systematically organized through a three-step research review process.
First, we discuss the functioning of vision language models (VLMs) for object
detection, describing how these models harness natural language processing
(NLP) and computer vision (CV) techniques to revolutionize object detection and
localization. We then explain the architectural innovations, training
paradigms, and output flexibility of recent LVLMs for object detection,
highlighting how they achieve advanced contextual understanding for object
detection. The review thoroughly examines the approaches used in integration of
visual and textual information, demonstrating the progress made in object
detection using VLMs that facilitate more sophisticated object detection and
localization strategies. This review presents comprehensive visualizations
demonstrating LVLMs' effectiveness in diverse scenarios including localization
and segmentation, and then compares their real-time performance, adaptability,
and complexity to traditional deep learning systems. Based on the review, its
is expected that LVLMs will soon meet or surpass the performance of
conventional methods in object detection. The review also identifies a few
major limitations of the current LVLM modes, proposes solutions to address
those challenges, and presents a clear roadmap for the future advancement in
this field. We conclude, based on this study, that the recent advancement in
LVLMs have made and will continue to make a transformative impact on object
detection and robotic applications in the future.

</details>


### [8] [Large VLM-based Stylized Sports Captioning](https://arxiv.org/abs/2508.19295)
*Sauptik Dhar,Nicholas Buoncristiani,Joe Anakata,Haoyu Zhang,Michelle Munson*

Main category: cs.CV

TL;DR: 本文提出了一个两级微调的视觉语言模型管道，专门用于从体育图像生成专业级、风格化的体育解说字幕，解决了现有大语言模型在体育领域专业术语和自然描述方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和视觉语言模型虽然能解释一般体育活动，但缺乏足够的体育领域专业术语来生成自然的人类化描述，无法满足专业体育新闻报道的需求。

Method: 采用两级微调的视觉语言模型管道，专门针对体育图像生成风格化字幕，优化了模型对体育专业术语的理解和生成能力。

Result: 相比其他方法，F1分数提高8-10%，BERT分数提高2-10%，具有较小的运行时内存占用和快速执行时间，在超级碗比赛中以每3-5秒处理6张图像的速度生成了1000多张图像的高质量字幕。

Conclusion: 该管道成功解决了现有模型在体育字幕生成方面的局限性，证明了其在实时专业体育新闻报道中的实际应用价值，能够高效生成准确且风格化的体育解说。

Abstract: The advent of large (visual) language models (LLM / LVLM) have led to a
deluge of automated human-like systems in several domains including social
media content generation, search and recommendation, healthcare prognosis, AI
assistants for cognitive tasks etc. Although these systems have been
successfully integrated in production; very little focus has been placed on
sports, particularly accurate identification and natural language description
of the game play. Most existing LLM/LVLMs can explain generic sports
activities, but lack sufficient domain-centric sports' jargon to create natural
(human-like) descriptions. This work highlights the limitations of existing
SoTA LLM/LVLMs for generating production-grade sports captions from images in a
desired stylized format, and proposes a two-level fine-tuned LVLM pipeline to
address that. The proposed pipeline yields an improvement > 8-10% in the F1,
and > 2-10% in BERT score compared to alternative approaches. In addition, it
has a small runtime memory footprint and fast execution time. During Super Bowl
LIX the pipeline proved its practical application for live professional sports
journalism; generating highly accurate and stylized captions at the rate of 6
images per 3-5 seconds for over 1000 images during the game play.

</details>


### [9] [AudioStory: Generating Long-Form Narrative Audio with Large Language Models](https://arxiv.org/abs/2508.20088)
*Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan*

Main category: cs.CV

TL;DR: AudioStory是一个统一的文本到音频生成框架，通过集成大语言模型和TTA系统，解决了长叙事音频生成的时序一致性和组合推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到音频生成技术在短音频片段合成方面表现良好，但在生成长篇叙事音频时缺乏时序连贯性和组合推理能力，需要解决这一技术空白。

Method: 采用大语言模型将复杂叙事查询分解为时序有序的子任务，使用解耦的桥接机制（语义对齐桥接查询和连贯性保持残差查询），并通过端到端训练统一指令理解和音频生成。

Result: 实验表明AudioStory在单音频生成和叙事音频生成方面均优于现有基线方法，在指令跟随能力和音频保真度方面都有显著提升。

Conclusion: AudioStory通过创新的框架设计成功解决了长叙事音频生成的挑战，建立了AudioStory-10K基准数据集，为相关研究提供了重要基础。

Abstract: Recent advances in text-to-audio (TTA) generation excel at synthesizing short
audio clips but struggle with long-form narrative audio, which requires
temporal coherence and compositional reasoning. To address this gap, we propose
AudioStory, a unified framework that integrates large language models (LLMs)
with TTA systems to generate structured, long-form audio narratives. AudioStory
possesses strong instruction-following reasoning generation capabilities. It
employs LLMs to decompose complex narrative queries into temporally ordered
sub-tasks with contextual cues, enabling coherent scene transitions and
emotional tone consistency. AudioStory has two appealing features: (1)
Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser
collaboration into two specialized components, i.e., a bridging query for
intra-event semantic alignment and a residual query for cross-event coherence
preservation. (2) End-to-end training: By unifying instruction comprehension
and audio generation within a single end-to-end framework, AudioStory
eliminates the need for modular training pipelines while enhancing synergy
between components. Furthermore, we establish a benchmark AudioStory-10K,
encompassing diverse domains such as animated soundscapes and natural sound
narratives. Extensive experiments show the superiority of AudioStory on both
single-audio generation and narrative audio generation, surpassing prior TTA
baselines in both instruction-following ability and audio fidelity. Our code is
available at https://github.com/TencentARC/AudioStory

</details>


### [10] [DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models](https://arxiv.org/abs/2508.19298)
*Abu Sufian,Anirudha Ghosh,Debaditya Barman,Marco Leo,Cosimo Distante*

Main category: cs.CV

TL;DR: DemoBias研究评估了大型视觉语言模型在生物特征人脸识别任务中的人口统计偏见，发现LLaVA和PaliGemma在西班牙裔/拉丁裔、高加索人和南亚人群上存在较大性能差异，而BLIP-2表现相对一致。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在各种下游任务中表现出色，但在生物特征人脸识别中存在人口统计偏见问题，需要评估这些模型在不同人口群体中的公平性表现。

Method: 使用自建的人口统计平衡数据集，对LLaVA、BLIP-2和PaliGemma三个预训练模型进行微调和评估，采用BERTScores和公平性差异率等指标量化性能差异。

Result: 实验结果显示LVLMs存在人口统计偏见，PaliGemma和LLaVA在西班牙裔/拉丁裔、高加索人和南亚人群上表现出更高的性能差异，而BLIP-2表现相对一致。

Conclusion: 该研究揭示了LVLMs在生物特征人脸识别任务中的人口统计偏见问题，强调了模型公平性评估的重要性，为开发更公平的AI系统提供了实证基础。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities across various downstream tasks, including biometric face
recognition (FR) with description. However, demographic biases remain a
critical concern in FR, as these foundation models often fail to perform
equitably across diverse demographic groups, considering ethnicity/race,
gender, and age. Therefore, through our work DemoBias, we conduct an empirical
evaluation to investigate the extent of demographic biases in LVLMs for
biometric FR with textual token generation tasks. We fine-tuned and evaluated
three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own
generated demographic-balanced dataset. We utilize several evaluation metrics,
like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify
and trace the performance disparities. The experimental results deliver
compelling insights into the fairness and reliability of LVLMs across diverse
demographic groups. Our empirical study uncovered demographic biases in LVLMs,
with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino,
Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably
consistent. Repository: https://github.com/Sufianlab/DemoBias.

</details>


### [11] [Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities](https://arxiv.org/abs/2508.19305)
*Chen Chu,Cyrus Shahabi*

Main category: cs.CV

TL;DR: Geo2Vec是一种新的空间表示学习方法，直接在原始空间操作，通过自适应采样和符号距离场编码几何特征，避免了现有方法的分解计算成本高和几何对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有空间表示学习方法要么只针对单一地理实体类型，要么需要分解实体进行傅里叶变换，计算成本高且缺乏几何对齐，导致细粒度特征模糊。

Method: 基于符号距离场(SDF)思想，直接在原始空间自适应采样点并编码符号距离，使用神经网络近似SDF生成紧凑的几何感知表示，并提出旋转不变位置编码。

Result: 实验结果表明Geo2Vec在形状和位置表示、拓扑和距离关系捕获方面持续优于现有方法，并在实际GeoAI应用中实现更高效率。

Conclusion: Geo2Vec提供了一种统一、高效且几何感知的空间表示学习方法，能够处理所有地理实体类型，为下游GeoAI模型构建了结构化和鲁棒的嵌入空间。

Abstract: Spatial representation learning is essential for GeoAI applications such as
urban analytics, enabling the encoding of shapes, locations, and spatial
relationships (topological and distance-based) of geo-entities like points,
polylines, and polygons. Existing methods either target a single geo-entity
type or, like Poly2Vec, decompose entities into simpler components to enable
Fourier transformation, introducing high computational cost. Moreover, since
the transformed space lacks geometric alignment, these methods rely on uniform,
non-adaptive sampling, which blurs fine-grained features like edges and
boundaries. To address these limitations, we introduce Geo2Vec, a novel method
inspired by signed distance fields (SDF) that operates directly in the original
space. Geo2Vec adaptively samples points and encodes their signed distances
(positive outside, negative inside), capturing geometry without decomposition.
A neural network trained to approximate the SDF produces compact,
geometry-aware, and unified representations for all geo-entity types.
Additionally, we propose a rotation-invariant positional encoding to model
high-frequency spatial variations and construct a structured and robust
embedding space for downstream GeoAI models. Empirical results show that
Geo2Vec consistently outperforms existing methods in representing shape and
location, capturing topological and distance relationships, and achieving
greater efficiency in real-world GeoAI applications. Code and Data can be found
at: https://github.com/chuchen2017/GeoNeuralRepresentation.

</details>


### [12] [Advancements in Crop Analysis through Deep Learning and Explainable AI](https://arxiv.org/abs/2508.19307)
*Hamza Khan*

Main category: cs.CV

TL;DR: 本研究提出基于卷积神经网络的自动化方法，成功分类5种水稻品种并诊断4种水稻叶部病害，结合可解释AI技术提高模型透明度，在农业质量检测和病害诊断方面展现强大潜力。


<details>
  <summary>Details</summary>
Motivation: 水稻作为全球重要主食，质量监控对消费者满意度和国家声誉至关重要。传统人工检测劳动密集、耗时且易出错，需要自动化解决方案来进行质量控制和产量提升。

Method: 使用包含75000张图像的公开数据集，采用CNN进行水稻品种分类，并结合VGG16、ResNet50、MobileNetV2等深度学习模型诊断叶部病害。运用SHAP和LIME等可解释AI技术分析特征影响。

Result: 模型表现出高分类准确率，误分类极少，有效区分不同水稻品种。同时成功开发了针对褐斑病、稻瘟病、白叶枯病和东格鲁病等叶部病害的准确诊断方法。

Conclusion: 深度学习在农业应用中具有强大潜力，该研究为开发稳健、可解释的自动化作物质量检测和病害诊断系统铺平道路，最终惠及农民、消费者和农业经济。

Abstract: Rice is a staple food of global importance in terms of trade, nutrition, and
economic growth. Among Asian nations such as China, India, Pakistan, Thailand,
Vietnam and Indonesia are leading producers of both long and short grain
varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To
ensure consumer satisfaction and strengthen national reputations, monitoring
rice crops and grain quality is essential. Manual inspection, however, is
labour intensive, time consuming and error prone, highlighting the need for
automated solutions for quality control and yield improvement. This study
proposes an automated approach to classify five rice grain varieties using
Convolutional Neural Networks (CNN). A publicly available dataset of 75000
images was used for training and testing. Model evaluation employed accuracy,
recall, precision, F1-score, ROC curves, and confusion matrices. Results
demonstrated high classification accuracy with minimal misclassifications,
confirming the model effectiveness in distinguishing rice varieties. In
addition, an accurate diagnostic method for rice leaf diseases such as Brown
Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined
explainable artificial intelligence (XAI) with deep learning models including
CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP
(SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic
Explanations) revealed how specific grain and leaf features influenced
predictions, enhancing model transparency and reliability. The findings
demonstrate the strong potential of deep learning in agricultural applications,
paving the way for robust, interpretable systems that can support automated
crop quality inspection and disease diagnosis, ultimately benefiting farmers,
consumers, and the agricultural economy.

</details>


### [13] [Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax](https://arxiv.org/abs/2508.19312)
*Ander Galván,Marivi Higuero,Jorge Sasiain,Eduardo Jacob*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于联邦学习和OpenMax算法的面部识别系统，专门处理开收集场景中的未知个体识别问题。


<details>
  <summary>Details</summary>
Motivation: 传统AI面部识别系统在隐私保护和未知个体处理方面面临挑战，特别是在开收集环境中。需要一种新的方案来同时保障隐私和提高识别准确性。

Method: 将OpenMax算法集成到联邦学习框架中，通过交换平均激活向量和本地距离测量来识别已知和未知个体。

Result: 实验结果验证了该方案的有效性，能够在分布式环境中实现更加隐私保护和稳健的面部识别。

Conclusion: 该研究为开收集面部识别提供了一种有效的联邦学习方案，在保护用户隐私的同时提高了识别系统的适应性和准确性。

Abstract: Facial recognition powered by Artificial Intelligence has achieved high
accuracy in specific scenarios and applications. Nevertheless, it faces
significant challenges regarding privacy and identity management, particularly
when unknown individuals appear in the operational context. This paper presents
the design, implementation, and evaluation of a facial recognition system
within a federated learning framework tailored to open-set scenarios. The
proposed approach integrates the OpenMax algorithm into federated learning,
leveraging the exchange of mean activation vectors and local distance measures
to reliably distinguish between known and unknown subjects. Experimental
results validate the effectiveness of the proposed solution, demonstrating its
potential for enhancing privacy-aware and robust facial recognition in
distributed environments.
  --
  El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado
una alta precisi\'on en algunos escenarios y aplicaciones. Sin embargo,
presenta desaf\'ios relacionados con la privacidad y la identificaci\'on de
personas, especialmente considerando que pueden aparecer sujetos desconocidos
para el sistema que lo implementa. En este trabajo, se propone el dise\~no,
implementaci\'on y evaluaci\'on de un sistema de reconocimiento facial en un
escenario de aprendizaje federado, orientado a conjuntos abiertos.
Concretamente, se dise\~na una soluci\'on basada en el algoritmo OpenMax para
escenarios de aprendizaje federado. La propuesta emplea el intercambio de los
vectores de activaci\'on promedio y distancias locales para identificar de
manera eficaz tanto personas conocidas como desconocidas. Los experimentos
realizados demuestran la implementaci\'on efectiva de la soluci\'on propuesta.

</details>


### [14] [Automated classification of natural habitats using ground-level imagery](https://arxiv.org/abs/2508.19314)
*Mahdis Tourian,Sareh Rowlands,Remy Vandaele,Max Fancourt,Rebecca Mein,Hywel T. P. Williams*

Main category: cs.CV

TL;DR: 基于地面照片通过深度学习实现生境分类的方法，使用DeepLabV3-ResNet101分类器将照片分为18个生境类别，平均F1分数达0.61，并提供了在线分析工具。


<details>
  <summary>Details</summary>
Motivation: 传统的卫星图像生境分类需要野外生态学家验证，而地面照片能够提供更好的验证效果和大规模分类能力，特别是通过公民科学图片进行生态监测。

Method: 使用Natural England的'Living England'框架定义18个生境类别，对地面照片进行调整大小、标准化和增强处理，通过重采样平衡训练数据集。开发并微调DeepLabV3-ResNet101分类器，采用五折交叉验证。

Result: 模型在18个生境类别上展现出良好性能，平均F1分数0.61。视觉区别明显的生境如空蕲土壤、泥沙和沃土(BSSP)以及空蕲沙地(BS)达到0.90以上，混合或模糊类别分数较低。

Conclusion: 这种基于地面照片的生境分类方法具有很大潜力，因为地面照片容易获得，准确的计算方法在生态监测方面有广泛应用。研究还提供了简单的网络应用程序支持实践者使用。

Abstract: Accurate classification of terrestrial habitats is critical for biodiversity
conservation, ecological monitoring, and land-use planning. Several habitat
classification schemes are in use, typically based on analysis of satellite
imagery with validation by field ecologists. Here we present a methodology for
classification of habitats based solely on ground-level imagery (photographs),
offering improved validation and the ability to classify habitats at scale (for
example using citizen-science imagery). In collaboration with Natural England,
a public sector organisation responsible for nature conservation in England,
this study develops a classification system that applies deep learning to
ground-level habitat photographs, categorising each image into one of 18
classes defined by the 'Living England' framework. Images were pre-processed
using resizing, normalisation, and augmentation; re-sampling was used to
balance classes in the training data and enhance model robustness. We developed
and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label
to each photograph. Using five-fold cross-validation, the model demonstrated
strong overall performance across 18 habitat classes, with accuracy and
F1-scores varying between classes. Across all folds, the model achieved a mean
F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and
Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or
ambiguous classes scoring lower. These findings demonstrate the potential of
this approach for ecological monitoring. Ground-level imagery is readily
obtained, and accurate computational methods for habitat classification based
on such data have many potential applications. To support use by practitioners,
we also provide a simple web application that classifies uploaded images using
our model.

</details>


### [15] [MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation](https://arxiv.org/abs/2508.19320)
*Ming Chen,Liyuan Cui,Wenyuan Zhang,Haoxian Zhang,Yan Zhou,Xiaohan Li,Xiaoqiang Liu,Pengfei Wan*

Main category: cs.CV

TL;DR: 提出了一种基于自回归模型和扩散头的交互式数字人视频生成框架，支持多模态输入控制和低延迟流式生成


<details>
  <summary>Details</summary>
Motivation: 现有交互式数字人视频生成方法存在高延迟、高计算成本和有限可控性问题，需要构建实时交互的实用系统

Method: 基于大型语言模型进行最小修改，接受音频、姿态和文本等多模态条件编码，输出空间语义一致表示来指导扩散头的去噪过程；构建大规模对话数据集（约20,000小时）；引入深度压缩自编码器（64倍压缩比）减轻自回归模型的长序列推理负担

Result: 在双工对话、多语言人像合成和交互式世界模型等实验中表现出低延迟、高效率和细粒度多模态可控性的优势

Conclusion: 该框架成功实现了实时交互式数字人视频生成，解决了现有方法的关键限制，为多模态交互应用提供了有效解决方案

Abstract: Recently, interactive digital human video generation has attracted widespread
attention and achieved remarkable progress. However, building such a practical
system that can interact with diverse input signals in real time remains
challenging to existing methods, which often struggle with high latency, heavy
computational cost, and limited controllability. In this work, we introduce an
autoregressive video generation framework that enables interactive multimodal
control and low-latency extrapolation in a streaming manner. With minimal
modifications to a standard large language model (LLM), our framework accepts
multimodal condition encodings including audio, pose, and text, and outputs
spatially and semantically coherent representations to guide the denoising
process of a diffusion head. To support this, we construct a large-scale
dialogue dataset of approximately 20,000 hours from multiple sources, providing
rich conversational scenarios for training. We further introduce a deep
compression autoencoder with up to 64$\times$ reduction ratio, which
effectively alleviates the long-horizon inference burden of the autoregressive
model. Extensive experiments on duplex conversation, multilingual human
synthesis, and interactive world model highlight the advantages of our approach
in low latency, high efficiency, and fine-grained multimodal controllability.

</details>


### [16] [Deep Data Hiding for ICAO-Compliant Face Images: A Survey](https://arxiv.org/abs/2508.19324)
*Jefferson David Rodriguez Chivata,Davide Ghiani,Simone Maurizio La Cava,Marco Micheletto,Giulia Orrù,Federico Lama,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 该论文调查数字水印和隐写术作为ICAO合规面部图像的防篡改解决方案，分析现有技术并评估其在身份验证系统中的适用性和局限性。


<details>
  <summary>Details</summary>
Motivation: ICAO合规面部图像在身份验证中广泛应用，但标准化也带来了篡改和深度伪造的风险，传统实时检测方法无法提供捕获后的保护。

Method: 通过全面分析最先进的数字水印和隐写术技术，评估这些方法在ICAO标准约束下的潜力和局限性。

Result: 研究发现数字水印和隐写术能够在不影响ICAO合规性的前提下提供持久的防篡改验证，但存在关键权衡需要考量。

Conclusion: 该研究为在实际身份系统中安全部署数字水印和隐写术技术提供了指导，强调了这些技术作为传统防护措施补充方案的重要性。

Abstract: ICAO-compliant facial images, initially designed for secure biometric
passports, are increasingly becoming central to identity verification in a wide
range of application contexts, including border control, digital travel
credentials, and financial services. While their standardization enables global
interoperability, it also facilitates practices such as morphing and deepfakes,
which can be exploited for harmful purposes like identity theft and illegal
sharing of identity documents. Traditional countermeasures like Presentation
Attack Detection (PAD) are limited to real-time capture and offer no
post-capture protection. This survey paper investigates digital watermarking
and steganography as complementary solutions that embed tamper-evident signals
directly into the image, enabling persistent verification without compromising
ICAO compliance. We provide the first comprehensive analysis of
state-of-the-art techniques to evaluate the potential and drawbacks of the
underlying approaches concerning the applications involving ICAO-compliant
images and their suitability under standard constraints. We highlight key
trade-offs, offering guidance for secure deployment in real-world identity
systems.

</details>


### [17] [PRISM: A Framework Harnessing Unsupervised Visual Representations and Textual Prompts for Explainable MACE Survival Prediction from Cardiac Cine MRI](https://arxiv.org/abs/2508.19325)
*Haoyang Su,Jin-Yi Xiang,Shaohao Rui,Yifan Gao,Xingyu Chen,Tingxuan Yin,Xiaosong Wang,Lian-Ming Wu*

Main category: cs.CV

TL;DR: PRISM是一个自监督框架，整合心脏MRI影像和电子健康记录进行生存分析，通过运动感知多视图蒸馏和医学提示调制，在四个临床队列中超越传统方法和SOTA基线，发现三个与MACE风险相关的影像特征。


<details>
  <summary>Details</summary>
Motivation: 准确预测主要不良心脏事件(MACE)是心血管预后的核心挑战，需要整合多模态数据来提升预测精度。

Method: PRISM框架通过运动感知多视图蒸馏提取时间同步的影像特征，并使用医学知识指导的文本提示进行调制，整合非对比心脏电影MRI和结构化EHR数据进行生存分析。

Result: 在四个独立临床队列中，PRISM在内部和外部验证中 consistently超越经典生存预测模型和最先进的深度学习基线，发现三个与MACE风险升高的影像特征：侧壁不同步、下壁超敏性和舒张期前壁高聚焦。

Conclusion: PRISM提供的影像和EHR组合表征为不同队列的心脏风险提供了有价值的见解，提示引导归因识别出高血压、糖尿病和吸烟是临床和生理EHR因素中的主要贡献者。

Abstract: Accurate prediction of major adverse cardiac events (MACE) remains a central
challenge in cardiovascular prognosis. We present PRISM (Prompt-guided
Representation Integration for Survival Modeling), a self-supervised framework
that integrates visual representations from non-contrast cardiac cine magnetic
resonance imaging with structured electronic health records (EHRs) for survival
analysis. PRISM extracts temporally synchronized imaging features through
motion-aware multi-view distillation and modulates them using medically
informed textual prompts to enable fine-grained risk prediction. Across four
independent clinical cohorts, PRISM consistently surpasses classical survival
prediction models and state-of-the-art (SOTA) deep learning baselines under
internal and external validation. Further clinical findings demonstrate that
the combined imaging and EHR representations derived from PRISM provide
valuable insights into cardiac risk across diverse cohorts. Three distinct
imaging signatures associated with elevated MACE risk are uncovered, including
lateral wall dyssynchrony, inferior wall hypersensitivity, and anterior
elevated focus during diastole. Prompt-guided attribution further identifies
hypertension, diabetes, and smoking as dominant contributors among clinical and
physiological EHR factors.

</details>


### [18] [EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.19349)
*Mahdieh Behjat Khatooni,Mohsen Soryani*

Main category: cs.CV

TL;DR: EffNetViTLoRA模型结合CNN和ViT，使用完整ADNI MRI数据集进行阿尔茨海默病诊断，准确率达92.52%


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期诊断至关重要，MCI诊断具有挑战性，现有研究数据有限且预训练模型在跨域时效果不佳

Method: 整合CNN和ViT捕捉局部和全局特征，使用完整ADNI T1加权MRI数据集，采用LoRA技术适配预训练ViT模型

Result: 在AD、MCI、CN三个诊断类别上达到92.52%的分类准确率和92.76%的F1分数

Conclusion: 提出的端到端模型在完整数据集上表现出色，LoRA技术有效解决了跨域适配问题，提高了临床可靠性

Abstract: Alzheimer's disease (AD) is one of the most prevalent neurodegenerative
disorders worldwide. As it progresses, it leads to the deterioration of
cognitive functions. Since AD is irreversible, early diagnosis is crucial for
managing its progression. Mild Cognitive Impairment (MCI) represents an
intermediate stage between Cognitively Normal (CN) individuals and those with
AD, and is considered a transitional phase from normal cognition to Alzheimer's
disease. Diagnosing MCI is particularly challenging due to the subtle
differences between adjacent diagnostic categories. In this study, we propose
EffNetViTLoRA, a generalized end-to-end model for AD diagnosis using the whole
Alzheimer's Disease Neuroimaging Initiative (ADNI) Magnetic Resonance Imaging
(MRI) dataset. Our model integrates a Convolutional Neural Network (CNN) with a
Vision Transformer (ViT) to capture both local and global features from MRI
images. Unlike previous studies that rely on limited subsets of data, our
approach is trained on the full T1-weighted MRI dataset from ADNI, resulting in
a more robust and unbiased model. This comprehensive methodology enhances the
model's clinical reliability. Furthermore, fine-tuning large pretrained models
often yields suboptimal results when source and target dataset domains differ.
To address this, we incorporate Low-Rank Adaptation (LoRA) to effectively adapt
the pretrained ViT model to our target domain. This method enables efficient
knowledge transfer and reduces the risk of overfitting. Our model achieves a
classification accuracy of 92.52% and an F1-score of 92.76% across three
diagnostic categories: AD, MCI, and CN for full ADNI dataset.

</details>


### [19] [Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage](https://arxiv.org/abs/2508.19477)
*Zachary L. Crang,Rich D. Johnston,Katie L. Mills,Johsan Billingham,Sam Robertson,Michael H. Cole,Jonathon Weakley,Adam Hewitt and,Grant M. Duthie*

Main category: cs.CV

TL;DR: 本研究评估了商业计算机视觉和AI球员追踪软件在广播画面中的准确性，发现位置误差1.68-16.39米，速度误差0.34-2.38 m/s，建议使用战术镜头和720p/1080p分辨率


<details>
  <summary>Details</summary>
Motivation: 验证商业计算机视觉和AI球员追踪软件使用广播画面测量球员位置、速度和距离的准确性，并确定摄像机画面和分辨率对准确性的影响

Method: 使用2022年卡塔尔FIFA世界杯比赛数据，比较三家商业追踪提供商与TRACAB Gen 5多摄像机系统的数据，计算均方根误差和平均偏差

Result: 位置RMSE范围1.68-16.39米，速度RMSE范围0.34-2.38 m/s，总比赛距离平均偏差范围-1745米(-21.8%)到1945米(24.3%)

Conclusion: 计算机视觉和AI球员追踪软件在检测到球员时具有合理精度，建议使用战术镜头和720p/1080p分辨率以获得最佳准确性

Abstract: This study aimed to: (1) understand whether commercially available
computer-vision and artificial intelligence (AI) player tracking software can
accurately measure player position, speed and distance using broadcast footage
and (2) determine the impact of camera feed and resolution on accuracy. Data
were obtained from one match at the 2022 Qatar Federation Internationale de
Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds
were used. Three commercial tracking providers that use computer-vision and AI
participated. Providers analysed instantaneous position (x, y coordinates) and
speed (m\,s^{-1}) of each player. Their data were compared with a
high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square
error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to
16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match
distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across
providers. Computer-vision and AI player tracking software offer the ability to
track players with fair precision when players are detected by the software.
Providers should use a tactical feed when tracking position and speed, which
will maximise player detection, improving accuracy. Both 720p and 1080p
resolutions are suitable, assuming appropriate computer-vision and AI models
are implemented.

</details>


### [20] [JVLGS: Joint Vision-Language Gas Leak Segmentation](https://arxiv.org/abs/2508.19485)
*Xinlong Zhao,Qixiang Pang,Shan Du*

Main category: cs.CV

TL;DR: 提出JVLGS框架，结合视觉和文本模态的优势，通过后处理减少误报，在气体泄漏分割任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 气体泄漏检测对公共安全至关重要，但现有视觉方法受限于气体云模糊和非刚性特性，且缺乏有效检测手段。

Method: 联合视觉-语言的气体泄漏分割框架，整合视觉和文本模态的互补优势，加入后处理步骤减少噪声和非目标物体造成的误报。

Result: 在多样化场景的广泛实验中，JVLGS显著优于最先进的气体泄漏分割方法，在有监督和少样本学习设置下均表现优异。

Conclusion: JVLGS框架通过多模态融合和后处理机制，有效解决了气体泄漏检测中的关键挑战，为实时准确的气体泄漏识别提供了可靠解决方案。

Abstract: Gas leaks pose serious threats to human health and contribute significantly
to atmospheric pollution, drawing increasing public concern. However, the lack
of effective detection methods hampers timely and accurate identification of
gas leaks. While some vision-based techniques leverage infrared videos for leak
detection, the blurry and non-rigid nature of gas clouds often limits their
effectiveness. To address these challenges, we propose a novel framework called
Joint Vision-Language Gas leak Segmentation (JVLGS), which integrates the
complementary strengths of visual and textual modalities to enhance gas leak
representation and segmentation. Recognizing that gas leaks are sporadic and
many video frames may contain no leak at all, our method incorporates a
post-processing step to reduce false positives caused by noise and non-target
objects, an issue that affects many existing approaches. Extensive experiments
conducted across diverse scenarios show that JVLGS significantly outperforms
state-of-the-art gas leak segmentation methods. We evaluate our model under
both supervised and few-shot learning settings, and it consistently achieves
strong performance in both, whereas competing methods tend to perform well in
only one setting or poorly in both. Code available at:
https://github.com/GeekEagle/JVLGS

</details>


### [21] [UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models](https://arxiv.org/abs/2508.19498)
*Yimu Wang,Weiming Zhuang,Chen Chen,Jiabo Huang,Jingtao Li,Lingjuan Lyu*

Main category: cs.CV

TL;DR: UNIFORM框架通过投票机制整合异构预训练模型的知识，无需数据分布和架构假设，显著提升无监督目标识别性能并具有良好可扩展性


<details>
  <summary>Details</summary>
Motivation: 现有知识集成方法对训练数据分布和网络架构有强假设限制，只能从特定类型模型中学习，存在数据和归纳偏差。需要一种能够有效利用多样化预训练模型集体知识的方法

Method: 提出UNIFORM框架，采用专门的投票机制在logit层面和特征层面捕获知识共识，logit层面整合能预测目标类的教师模型，特征层面利用任意标签空间学习的视觉表示

Result: 大量实验表明UNIFORM相比强基线有效提升无监督目标识别性能，具有显著可扩展性，能从100+教师模型中受益，而现有方法在较小规模就饱和

Conclusion: UNIFORM成功解决了异构预训练模型知识整合的挑战，无需强假设约束，通过多层级共识捕获实现了有效的知识迁移和卓越的可扩展性能

Abstract: In the era of deep learning, the increasing number of pre-trained models
available online presents a wealth of knowledge. These models, developed with
diverse architectures and trained on varied datasets for different tasks,
provide unique interpretations of the real world. Their collective consensus is
likely universal and generalizable to unseen data. However, effectively
harnessing this collective knowledge poses a fundamental challenge due to the
heterogeneity of pre-trained models. Existing knowledge integration solutions
typically rely on strong assumptions about training data distributions and
network architectures, limiting them to learning only from specific types of
models and resulting in data and/or inductive biases. In this work, we
introduce a novel framework, namely UNIFORM, for knowledge transfer from a
diverse set of off-the-shelf models into one student model without such
constraints. Specifically, we propose a dedicated voting mechanism to capture
the consensus of knowledge both at the logit level -- incorporating teacher
models that are capable of predicting target classes of interest -- and at the
feature level, utilizing visual representations learned on arbitrary label
spaces. Extensive experiments demonstrate that UNIFORM effectively enhances
unsupervised object recognition performance compared to strong knowledge
transfer baselines. Notably, it exhibits remarkable scalability by benefiting
from over one hundred teachers, while existing methods saturate at a much
smaller scale.

</details>


### [22] [Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery](https://arxiv.org/abs/2508.19499)
*Xiangxu Wang,Tianhong Zhao,Wei Tu,Bowen Zhang,Guanzhou Chen,Jinzhou Cao*

Main category: cs.CV

TL;DR: Sat2Flow是一个基于扩散模型的框架，仅使用卫星图像生成结构一致的OD流量矩阵，解决了传统方法对辅助数据和空间拓扑敏感性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有OD流量生成方法依赖成本高昂的辅助特征（如POI、社会经济统计），且对空间拓扑敏感，区域索引重排序会破坏生成流量的结构一致性。

Method: 提出多核编码器捕捉区域交互，采用排列感知扩散过程对齐不同区域排序的潜在表示，通过联合对比训练目标和等变扩散训练确保结构一致性。

Result: 在真实城市数据集上，Sat2Flow在数值精度上优于物理和数据驱动基线方法，同时在索引排列下保持经验分布和空间结构。

Conclusion: Sat2Flow为数据稀缺城市环境提供了可扩展的OD流量生成解决方案，消除了区域特定辅助数据依赖，同时保持结构不变性以实现稳健的移动性建模。

Abstract: Origin-Destination (OD) flow matrices are essential for urban mobility
analysis, underpinning applications in traffic forecasting, infrastructure
planning, and policy design. However, existing methods suffer from two critical
limitations: (1) reliance on auxiliary features (e.g., Points of Interest,
socioeconomic statistics) that are costly to collect and have limited spatial
coverage; and (2) sensitivity to spatial topology, where minor index reordering
of urban regions (e.g., census tract relabeling) disrupts structural coherence
in generated flows. To address these challenges, we propose Sat2Flow, a latent
structure-aware diffusion-based framework that generates structurally coherent
OD flows using solely satellite imagery as input. Our approach introduces a
multi-kernel encoder to capture diverse regional interactions and employs a
permutation-aware diffusion process that aligns latent representations across
different regional orderings. Through a joint contrastive training objective
that bridges satellite-derived features with OD patterns, combined with
equivariant diffusion training that enforces structural consistency, Sat2Flow
ensures topological robustness under arbitrary regional reindexing.
Experimental results on real-world urban datasets demonstrate that Sat2Flow
outperforms both physics-based and data-driven baselines in numerical accuracy
while preserving empirical distributions and spatial structures under index
permutations. Sat2Flow offers a globally scalable solution for OD flow
generation in data-scarce urban environments, eliminating region-specific
auxiliary data dependencies while maintaining structural invariance for robust
mobility modeling.

</details>


### [23] [Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity](https://arxiv.org/abs/2508.19511)
*Alzayat Saleh,Shunsuke Hatano,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 该研究提出了一个诊断驱动的半监督框架，用于解决农业杂草自动管理中的环境挑战和数据标注成本问题，通过伪标签技术利用未标注数据提高模型鲁棒性，有效缓解了阴影偏差问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在真实农田环境中性能受限的两个关键问题：具有挑战性的环境条件和高昂的数据标注成本，特别是在入侵性杂草自动管理领域。

Method: 使用包含975张标注图像和10,000张未标注图像的独特数据集，首先建立强监督基线（ResNet分类和YOLO、RF-DETR检测），然后通过可解释性工具诊断发现阴影偏差问题，最后开发基于伪标签的半监督管道来利用未标注数据增强模型鲁棒性。

Result: 监督基线达到F1分数0.90和mAP50分数超过0.82；半监督框架不仅有效缓解了阴影偏差，还显著提高了召回率这一自动化喷洒系统中的关键指标；在低数据机制下的公共作物-杂草基准测试中验证了方法的有效性。

Conclusion: 该研究为精准农业复杂现实中的计算机视觉系统开发、诊断和改进提供了一个清晰且经过实地测试的框架，通过诊断驱动的半监督方法有效解决了实际应用中的关键挑战。

Abstract: The automated management of invasive weeds is critical for sustainable
agriculture, yet the performance of deep learning models in real-world fields
is often compromised by two factors: challenging environmental conditions and
the high cost of data annotation. This study tackles both issues through a
diagnostic-driven, semi-supervised framework. Using a unique dataset of
approximately 975 labeled and 10,000 unlabeled images of Guinea Grass in
sugarcane, we first establish strong supervised baselines for classification
(ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and
mAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by
interpretability tools, uncovered a pervasive "shadow bias," where models
learned to misidentify shadows as vegetation. This diagnostic insight motivated
our primary contribution: a semi-supervised pipeline that leverages unlabeled
data to enhance model robustness. By training models on a more diverse set of
visual information through pseudo-labeling, this framework not only helps
mitigate the shadow bias but also provides a tangible boost in recall, a
critical metric for minimizing weed escapes in automated spraying systems. To
validate our methodology, we demonstrate its effectiveness in a low-data regime
on a public crop-weed benchmark. Our work provides a clear and field-tested
framework for developing, diagnosing, and improving robust computer vision
systems for the complex realities of precision agriculture.

</details>


### [24] [MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment](https://arxiv.org/abs/2508.19527)
*Zhiting Gao,Dan Song,Diqiong Jiang,Chao Xue,An-An Liu*

Main category: cs.CV

TL;DR: 提出了TAPO和MotionFLUX统一框架，通过偏好优化对齐文本描述与运动语义，使用整流流匹配实现实时运动生成，在语义一致性和运动质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决文本驱动运动生成中语义对齐不精确和多步推理效率低的问题，需要同时提升生成质量和速度。

Method: TAPO框架通过偏好优化对齐细微运动变化与文本修饰符，MotionFLUX基于确定性整流流匹配构建噪声分布与运动空间的最优传输路径，实现实时合成。

Result: 实验结果表明，该统一系统在语义一致性和运动质量上优于最先进方法，同时显著加速生成速度。

Conclusion: TAPO和MotionFLUX的结合为虚拟角色和具身智能体提供了高效高质量的运动生成解决方案，代码和预训练模型将发布。

Abstract: Motion generation is essential for animating virtual characters and embodied
agents. While recent text-driven methods have made significant strides, they
often struggle with achieving precise alignment between linguistic descriptions
and motion semantics, as well as with the inefficiencies of slow, multi-step
inference. To address these issues, we introduce TMR++ Aligned Preference
Optimization (TAPO), an innovative framework that aligns subtle motion
variations with textual modifiers and incorporates iterative adjustments to
reinforce semantic grounding. To further enable real-time synthesis, we propose
MotionFLUX, a high-speed generation framework based on deterministic rectified
flow matching. Unlike traditional diffusion models, which require hundreds of
denoising steps, MotionFLUX constructs optimal transport paths between noise
distributions and motion spaces, facilitating real-time synthesis. The
linearized probability paths reduce the need for multi-step sampling typical of
sequential methods, significantly accelerating inference time without
sacrificing motion quality. Experimental results demonstrate that, together,
TAPO and MotionFLUX form a unified system that outperforms state-of-the-art
approaches in both semantic consistency and motion quality, while also
accelerating generation speed. The code and pretrained models will be released.

</details>


### [25] [CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning](https://arxiv.org/abs/2508.19542)
*Nannan Zhu,Yonghao Dong,Teng Wang,Xueqian Li,Shengjun Deng,Yijia Wang,Zheng Hong,Tiantian Geng,Guo Niu,Hanyan Huang,Xiongfei Yao,Shuaiwei Jiao*

Main category: cs.CV

TL;DR: CVBench是首个专门评估多模态大语言模型在多视频间关系推理能力的基准测试，包含1000个QA对，涵盖三个层次：对象关联、事件关联和复杂推理。测试发现即使顶级模型如GPT-4o在因果推理任务上准确率仅60%，远低于人类的91%，揭示了当前模型在跨视频上下文保持和实体消歧方面的根本瓶颈。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在单视频任务上表现良好，但它们在多视频间的推理能力尚未得到充分探索，而这种能力对于多摄像头监控、跨视频程序学习等实际应用至关重要。

Method: 构建CVBench基准测试，包含1000个问题-答案对，分为三个层次：跨视频对象关联、跨视频事件关联和跨视频复杂推理。基于五个不同领域的视频集群构建，评估了10多个领先MLLM在零样本和思维链提示下的表现。

Result: 评估结果显示显著性能差距：顶级模型如GPT-4o在因果推理任务上仅达到60%准确率，而人类表现达到91%。分析揭示了当前MLLM架构的根本瓶颈，包括跨视频上下文保持不足和重叠实体消歧能力差。

Conclusion: CVBench为诊断和推进多视频推理建立了严格框架，为下一代MLLM提供了架构设计洞见。该基准测试揭示了当前模型在多视频关系推理方面的局限性，并指出了未来改进的方向。

Abstract: While multimodal large language models (MLLMs) exhibit strong performance on
single-video tasks (e.g., video question answering), their ability across
multiple videos remains critically underexplored. However, this capability is
essential for real-world applications, including multi-camera surveillance and
cross-video procedural learning. To bridge this gap, we present CVBench, the
first comprehensive benchmark designed to assess cross-video relational
reasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning
three hierarchical tiers: cross-video object association (identifying shared
entities), cross-video event association (linking temporal or causal event
chains), and cross-video complex reasoning (integrating commonsense and domain
knowledge). Built from five domain-diverse video clusters (e.g., sports, life
records), the benchmark challenges models to synthesise information across
dynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including
GPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought
prompting paradigms. Key findings reveal stark performance gaps: even top
models, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,
compared to the 91% accuracy of human performance. Crucially, our analysis
reveals fundamental bottlenecks inherent in current MLLM architectures, notably
deficient inter-video context retention and poor disambiguation of overlapping
entities. CVBench establishes a rigorous framework for diagnosing and advancing
multi-video reasoning, offering architectural insights for next-generation
MLLMs.The data and evaluation code are available at
https://github.com/Hokhim2/CVBench.

</details>


### [26] [WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization](https://arxiv.org/abs/2508.19544)
*Eduardo Davalos,Yike Zhang,Namrata Srivastava,Yashvitha Thatigotla,Jorge A. Salas,Sara McFadden,Sun-Joo Cho,Amanda Goodwin,Ashwin TS,Gautam Biswas*

Main category: cs.CV

TL;DR: WebEyeTrack是一个浏览器内轻量级视线追踪框架，通过模型化头部姿态估计和少样本学习，仅需9个校准样本即可达到SOTA性能，在iPhone 14上实现2.4毫秒实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有AI视线估计方法虽然达到SOTA基准，但在实际应用中与商业眼动追踪方案存在差距，且网络摄像头方法因头部移动导致精度不足，需要解决模型大小、推理时间和隐私等问题。

Method: 提出WebEyeTrack框架，在浏览器中集成轻量级SOTA视线估计模型，结合基于模型的头部姿态估计和设备端少样本学习（k<9个校准样本）。

Result: 在GazeCapture数据集上达到2.32厘米误差的SOTA性能，在iPhone 14上实现2.4毫秒的实时推理速度。

Conclusion: WebEyeTrack成功解决了现有方法的局限性，提供了高精度、实时且保护隐私的浏览器内视线追踪解决方案，代码已开源。

Abstract: With advancements in AI, new gaze estimation methods are exceeding
state-of-the-art (SOTA) benchmarks, but their real-world application reveals a
gap with commercial eye-tracking solutions. Factors like model size, inference
time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking
methods lack sufficient accuracy, in particular due to head movement. To tackle
these issues, we introduce We bEyeTrack, a framework that integrates
lightweight SOTA gaze estimation models directly in the browser. It
incorporates model-based head pose estimation and on-device few-shot learning
with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new
users, achieving SOTA performance with an error margin of 2.32 cm on
GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.
Our open-source code is available at
https://github.com/RedForestAi/WebEyeTrack.

</details>


### [27] [MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery](https://arxiv.org/abs/2508.19555)
*Yu-Wei Zhang,Tongju Han,Lipeng Gao,Mingqiang Wei,Hui Liu,Changbao Li,Caiming Zhang*

Main category: cs.CV

TL;DR: MonoRelief V2是一个端到端模型，能够从单张图像直接恢复2.5D浮雕，在复杂材质和光照变化下表现优异。相比仅使用合成数据训练的V1版本，V2通过引入真实数据和伪真实数据训练，显著提升了鲁棒性、准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决从单张图像恢复2.5D浮雕的挑战，特别是在复杂材质和光照变化条件下。传统方法主要依赖合成数据训练，缺乏对真实场景的适应性，需要开发能够在真实环境下鲁棒工作的解决方案。

Method: 1) 使用文本到图像生成模型生成约15,000张伪真实图像；2) 通过深度和法线预测融合获得深度伪标签；3) 构建小规模真实数据集（800个样本）进行多视角重建和细节优化；4) 在伪真实和真实数据集上进行渐进式训练。

Result: 综合实验表明，MonoRelief V2在深度和法线预测方面达到了最先进的性能，展现出优异的鲁棒性和准确性，为下游应用提供了强大潜力。

Conclusion: MonoRelief V2通过结合伪真实数据和真实数据训练，成功解决了单图像2.5D浮雕恢复问题，在复杂条件下表现出色，为相关应用提供了有效的解决方案。

Abstract: This paper presents MonoRelief V2, an end-to-end model designed for directly
recovering 2.5D reliefs from single images under complex material and
illumination variations. In contrast to its predecessor, MonoRelief V1 [1],
which was solely trained on synthetic data, MonoRelief V2 incorporates real
data to achieve improved robustness, accuracy and efficiency. To overcome the
challenge of acquiring large-scale real-world dataset, we generate
approximately 15,000 pseudo real images using a text-to-image generative model,
and derive corresponding depth pseudo-labels through fusion of depth and normal
predictions. Furthermore, we construct a small-scale real-world dataset (800
samples) via multi-view reconstruction and detail refinement. MonoRelief V2 is
then progressively trained on the pseudo-real and real-world datasets.
Comprehensive experiments demonstrate its state-of-the-art performance both in
depth and normal predictions, highlighting its strong potential for a range of
downstream applications. Code is at: https://github.com/glp1001/MonoreliefV2.

</details>


### [28] [FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection](https://arxiv.org/abs/2508.19565)
*Yuhang Zhao,Zixing Wang*

Main category: cs.CV

TL;DR: FlowDet是一个基于DETR架构的高速端到端目标检测器，通过解耦编码器优化策略、几何可变形单元和尺度感知注意力模块，在Intersection-Flow-5k数据集上实现了新的SOTA性能，同时显著降低了计算成本和提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决端到端目标检测器在复杂场景（如交叉口交通监控）中计算成本高的问题，为实时应用提供NMS-free的高效检测方案。

Method: 提出FlowDet检测器，采用解耦编码器优化策略，包含交通感知的几何可变形单元(GDU)和尺度感知注意力模块(SAA)，用于处理极端尺度变化和几何建模。

Result: 在Intersection-Flow-5k数据集上，相比RT-DETR基线，AP提升1.5%，AP50提升1.6%，同时GFLOPs减少63.2%，推理速度提升16.2%。

Conclusion: FlowDet为构建高效准确的现实世界感知系统提供了新路径，在复杂遮挡和高目标密度场景中表现出色。

Abstract: End-to-end object detectors offer a promising NMS-free paradigm for real-time
applications, yet their high computational cost remains a significant barrier,
particularly for complex scenarios like intersection traffic monitoring. To
address this challenge, we propose FlowDet, a high-speed detector featuring a
decoupled encoder optimization strategy applied to the DETR architecture.
Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for
traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to
maintain high representational power across extreme scale variations. To
rigorously evaluate the model's performance in environments with severe
occlusion and high object density, we collected the Intersection-Flow-5k
dataset, a new challenging scene for this task. Evaluated on
Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to
the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by
1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference
speed by 16.2%. Our work demonstrates a new path towards building highly
efficient and accurate detectors for demanding, real-world perception systems.
The Intersection-Flow-5k dataset is available at
https://github.com/AstronZh/Intersection-Flow-5K.

</details>


### [29] [Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies](https://arxiv.org/abs/2508.20072)
*Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Liuao Pei,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo*

Main category: cs.CV

TL;DR: 提出Discrete Diffusion VLA方法，使用离散扩散模型处理机器人动作序列，替代传统的自回归或连续扩散方法，实现更统一的架构和更好的性能


<details>
  <summary>Details</summary>
Motivation: 现有的VLA解码器要么采用固定的自回归生成顺序，要么需要专门的连续扩散训练，这限制了架构的统一性和可扩展性

Method: 使用离散扩散模型处理离散化的动作块，采用与VLM骨干网络相同的交叉熵目标进行训练，支持并行解码和渐进式精炼

Result: 在LIBERO上达到96.3%平均成功率，SimplerEnv Fractal上71.2%视觉匹配率，SimplerEnv Bridge上49.3%总体性能，优于自回归和连续扩散基线

Conclusion: 离散扩散动作解码器支持精确的动作建模和一致的训练，为将VLA扩展到更大模型和数据集奠定了基础

Abstract: Vision-Language-Action (VLA) models adapt large vision-language backbones to
map images and instructions to robot actions. However, prevailing VLA decoders
either generate actions autoregressively in a fixed left-to-right order or
attach continuous diffusion or flow matching heads outside the backbone,
demanding specialized training and iterative sampling that hinder a unified,
scalable architecture. We present Discrete Diffusion VLA, a single-transformer
policy that models discretized action chunks with discrete diffusion and is
trained with the same cross-entropy objective as the VLM backbone. The design
retains diffusion's progressive refinement paradigm while remaining natively
compatible with the discrete token interface of VLMs. Our method achieves an
adaptive decoding order that resolves easy action elements before harder ones
and uses secondary remasking to revisit uncertain predictions across refinement
rounds, which improves consistency and enables robust error correction. This
unified decoder preserves pretrained vision language priors, supports parallel
decoding, breaks the autoregressive bottleneck, and reduces the number of
function evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,
71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv
Bridge, improving over both autoregressive and continuous diffusion baselines.
These findings indicate that discrete-diffusion action decoder supports precise
action modeling and consistent training, laying groundwork for scaling VLA to
larger models and datasets.

</details>


### [30] [DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection](https://arxiv.org/abs/2508.19573)
*Luhu Li,Bowen Lin,Mukhtiar Khan,Shujun Fu*

Main category: cs.CV

TL;DR: 提出结合可训练编码器与原型引导重建的统一框架，通过多样性感知对齐损失防止原型崩溃，在医学图像异常检测中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 医学图像异常检测面临标注稀缺和领域差异挑战，现有重建方法依赖冻结预训练编码器限制了领域适应能力，原型学习方法存在原型崩溃问题

Method: 使用可训练编码器配合动量分支实现稳定领域自适应特征学习，轻量级原型提取器挖掘信息丰富的正常原型，通过注意力机制指导解码器进行精确重建，引入多样性感知对齐损失防止原型崩溃

Result: 在多个医学影像基准测试中显著提升了表示质量和异常定位精度，超越了现有方法，可视化分析和原型分配验证了抗崩溃机制的有效性

Conclusion: 提出的统一框架成功解决了原型崩溃问题，提高了医学图像异常检测的性能和可解释性，为领域自适应异常检测提供了有效解决方案

Abstract: Anomaly detection in medical images is challenging due to limited annotations
and a domain gap compared to natural images. Existing reconstruction methods
often rely on frozen pre-trained encoders, which limits adaptation to
domain-specific features and reduces localization accuracy. Prototype-based
learning offers interpretability and clustering benefits but suffers from
prototype collapse, where few prototypes dominate training, harming diversity
and generalization. To address this, we propose a unified framework combining a
trainable encoder with prototype-guided reconstruction and a novel
Diversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum
branch, enables stable domain-adaptive feature learning. A lightweight
Prototype Extractor mines informative normal prototypes to guide the decoder
via attention for precise reconstruction. Our loss enforces balanced prototype
use through diversity constraints and per-prototype normalization, effectively
preventing collapse. Experiments on multiple medical imaging benchmarks show
significant improvements in representation quality and anomaly localization,
outperforming prior methods. Visualizations and prototype assignment analyses
further validate the effectiveness of our anti-collapse mechanism and enhanced
interpretability.

</details>


### [31] [Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation](https://arxiv.org/abs/2508.19574)
*Mingxi Fu,Fanglei Fu,Xitong Ling,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: MPAMatch是一种新颖的多模态病理图像分割框架，通过图像和文本原型与像素标签的双重对比学习，在结构和语义层面提供监督，显著改善了语义边界建模。


<details>
  <summary>Details</summary>
Motivation: 解决病理图像分割中语义边界模糊和像素级标注成本高的问题，现有半监督方法主要依赖图像模态内的扰动一致性，难以捕捉高级语义先验。

Method: 提出MPAMatch框架，采用多模态原型引导的监督范式进行像素级对比学习，包括图像原型-像素标签和文本原型-像素标签的双重对比学习，并重构TransUNet架构使用病理预训练基础模型。

Result: 在GLAS、EBHI-SEG-GLAND、EBHI-SEG-CANCER和KPI数据集上的大量实验显示，MPAMatch优于最先进方法，验证了其在结构和语义建模方面的双重优势。

Conclusion: MPAMatch通过引入文本原型监督和多模态对比学习，有效提升了病理图像分割的性能，特别是在语义边界建模方面取得了显著改进。

Abstract: Pathological image segmentation faces numerous challenges, particularly due
to ambiguous semantic boundaries and the high cost of pixel-level annotations.
Although recent semi-supervised methods based on consistency regularization
(e.g., UniMatch) have made notable progress, they mainly rely on
perturbation-based consistency within the image modality, making it difficult
to capture high-level semantic priors, especially in structurally complex
pathology images. To address these limitations, we propose MPAMatch - a novel
segmentation framework that performs pixel-level contrastive learning under a
multimodal prototype-guided supervision paradigm. The core innovation of
MPAMatch lies in the dual contrastive learning scheme between image prototypes
and pixel labels, and between text prototypes and pixel labels, providing
supervision at both structural and semantic levels. This coarse-to-fine
supervisory strategy not only enhances the discriminative capability on
unlabeled samples but also introduces the text prototype supervision into
segmentation for the first time, significantly improving semantic boundary
modeling. In addition, we reconstruct the classic segmentation architecture
(TransUNet) by replacing its ViT backbone with a pathology-pretrained
foundation model (Uni), enabling more effective extraction of
pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,
EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art
methods, validating its dual advantages in structural and semantic modeling.

</details>


### [32] [Interact-Custom: Customized Human Object Interaction Image Generation](https://arxiv.org/abs/2508.19575)
*Zhu Xu,Zhaowen Wang,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 提出了定制化人机交互图像生成任务(CHOI)，通过两阶段模型Interact-Custom实现目标人物和物体的身份保持与交互语义控制，解决了现有方法忽略细粒度交互控制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注目标实体的外观保持，而忽略了目标实体之间的细粒度交互控制。为了解决这个问题，研究者专注于人机交互场景，提出了定制化人机交互图像生成任务。

Method: 首先处理大规模数据集，每个样本包含相同人机对的不同交互姿势；然后设计两阶段模型Interact-Custom：第一阶段通过生成描述交互行为的前景掩码来显式建模空间配置，第二阶段在该掩码指导下生成保持身份特征的目标人机交互图像。

Result: 在专门为CHOI任务定制的指标上进行了广泛实验，证明了方法的有效性。模型还提供了可选功能，允许用户指定背景图像和人机目标出现的位置，提供高内容可控性。

Conclusion: 提出的Interact-Custom模型成功解决了同时保持身份特征和控制交互语义的挑战，为人机交互图像生成提供了有效的解决方案。

Abstract: Compositional Customized Image Generation aims to customize multiple target
concepts within generation content, which has gained attention for its wild
application.Existing approaches mainly concentrate on the target entity's
appearance preservation, while neglecting the fine-grained interaction control
among target entities.To enable the model of such interaction control
capability, we focus on human object interaction scenario and propose the task
of Customized Human Object Interaction Image Generation(CHOI), which
simultaneously requires identity preservation for target human object and the
interaction semantic control between them.Two primary challenges exist for
CHOI:(1)simultaneous identity preservation and interaction control demands
require the model to decompose the human object into self-contained identity
features and pose-oriented interaction features, while the current HOI image
datasets fail to provide ideal samples for such feature-decomposed
learning.(2)inappropriate spatial configuration between human and object may
lead to the lack of desired interaction semantics.To tackle it, we first
process a large-scale dataset, where each sample encompasses the same pair of
human object involving different interactive poses.Then we design a two-stage
model Interact-Custom, which firstly explicitly models the spatial
configuration by generating a foreground mask depicting the interaction
behavior, then under the guidance of this mask, we generate the target human
object interacting while preserving their identities features.Furthermore, if
the background image and the union location of where the target human object
should appear are provided by users, Interact-Custom also provides the optional
functionality to specify them, offering high content controllability. Extensive
experiments on our tailored metrics for CHOI task demonstrate the effectiveness
of our approach.

</details>


### [33] [High-Speed FHD Full-Color Video Computer-Generated Holography](https://arxiv.org/abs/2508.19579)
*Haomiao Zhang,Miao Cao,Xuan Yu,Hui Luo,Yanling Piao,Mengjie Qin,Zhangyuan Li,Ping Wang,Xin Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种高速全色视频计算机生成全息技术，通过SGDDM颜色优化和HoloMamba空间-时间相关模型，解决了高帧率显示中的颜色渗透问题和计算效率低下的挑战


<details>
  <summary>Details</summary>
Motivation: 解决高速全息视频生成中的两大问题：（1）学习基模型产生过平滑相位导致颜色渗透，（2）现有方法忽视帧间相关性导致计算效率低下

Method: 提出SGDDM颜色优化技术通过频率调制优化相位分布，以及HoloMamba轻量级非对称Mamba-Unet架构来显式建模空间-时间相关性

Result: SGDDM实现了高帧率下的高保真全色显示，HoloMamba能以超过260 FPS的速度生成FHD全色全息视频，比现有最佳方法快2.6倍

Conclusion: 该方案成功解决了高速全息视频生成的颜色保真性和计算效率问题，为下一代显示技术提供了有力的解决方案

Abstract: Computer-generated holography (CGH) is a promising technology for
next-generation displays. However, generating high-speed, high-quality
holographic video requires both high frame rate display and efficient
computation, but is constrained by two key limitations: ($i$) Learning-based
models often produce over-smoothed phases with narrow angular spectra, causing
severe color crosstalk in high frame rate full-color displays such as
depth-division multiplexing and thus resulting in a trade-off between frame
rate and color fidelity. ($ii$) Existing frame-by-frame optimization methods
typically optimize frames independently, neglecting spatial-temporal
correlations between consecutive frames and leading to computationally
inefficient solutions. To overcome these challenges, in this paper, we propose
a novel high-speed full-color video CGH generation scheme. First, we introduce
Spectrum-Guided Depth Division Multiplexing (SGDDM), which optimizes phase
distributions via frequency modulation, enabling high-fidelity full-color
display at high frame rates. Second, we present HoloMamba, a lightweight
asymmetric Mamba-Unet architecture that explicitly models spatial-temporal
correlations across video sequences to enhance reconstruction quality and
computational efficiency. Extensive simulated and real-world experiments
demonstrate that SGDDM achieves high-fidelity full-color display without
compromise in frame rate, while HoloMamba generates FHD (1080p) full-color
holographic video at over 260 FPS, more than 2.6$\times$ faster than the prior
state-of-the-art Divide-Conquer-and-Merge Strategy.

</details>


### [34] [Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction](https://arxiv.org/abs/2508.19581)
*Dat Nguyen Cong,Hieu Tran Bao,Hoang Thanh-Tung*

Main category: cs.CV

TL;DR: 本文提出了SBDC方法，一种基于判别器校正的引导技术，用于改善预训练条件扩散模型在存在标注噪声时的生成质量和可控性。


<details>
  <summary>Details</summary>
Motivation: 大规模数据集中的标注错误会影响扩散模型的生成能力和可控性，但这一问题尚未得到充分研究。

Method: 使用对抗损失训练判别器，结合先验噪声检测技术评估样本真实性，并在生成过程早期阶段应用引导。

Result: 在不同噪声设置下的实验表明，该方法优于现有最先进方法，计算效率高且推理时间仅略微增加。

Conclusion: SBDC是一种有效的引导技术，无需重新训练扩散模型即可显著改善噪声条件下的生成性能。

Abstract: Diffusion models have gained prominence as state-of-the-art techniques for
synthesizing images and videos, particularly due to their ability to scale
effectively with large datasets. Recent studies have uncovered that these
extensive datasets often contain mistakes from manual labeling processes.
However, the extent to which such errors compromise the generative capabilities
and controllability of diffusion models is not well studied. This paper
introduces Score-based Discriminator Correction (SBDC), a guidance technique
for aligning noisy pre-trained conditional diffusion models. The guidance is
built on discriminator training using adversarial loss, drawing on prior noise
detection techniques to assess the authenticity of each sample. We further show
that limiting the usage of our guidance to the early phase of the generation
process leads to better performance. Our method is computationally efficient,
only marginally increases inference time, and does not require retraining
diffusion models. Experiments on different noise settings demonstrate the
superiority of our method over previous state-of-the-art methods.

</details>


### [35] [Generalizing Monocular 3D Object Detection](https://arxiv.org/abs/2508.19593)
*Abhinav Kumar*

Main category: cs.CV

TL;DR: 该论文针对单目3D目标检测的泛化性问题，提出了多种解决方案：GrooMeD-NMS提升遮挡鲁棒性，DEVIANT骨干网络增强数据集泛化能力，SeaBird方法解决大目标检测问题，并分析了相机参数外推的数学原理。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测在自动驾驶、增强现实等应用中至关重要，但现有模型在遮挡、不同数据集、大目标检测和相机参数变化等多样化场景中的泛化能力不足，需要系统性解决方案。

Method: 1. 提出数学可微的GrooMeD-NMS处理遮挡问题；2. 探索深度等变(DEVIANT)骨干网络提升数据集泛化；3. 使用基于分割的SeaBird方法配合dice损失解决大目标检测；4. 数学分析相机高度外推问题。

Result: 开发了多种提升单目3D检测泛化性的技术：遮挡鲁棒性增强、跨数据集泛化能力提升、大目标检测性能改进，以及在未知相机参数设置下的更好泛化表现。

Conclusion: 通过系统性的方法解决了单目3D目标检测在多样化场景中的泛化挑战，为实际应用提供了更鲁棒和通用的解决方案，推动了该领域的发展。

Abstract: Monocular 3D object detection (Mono3D) is a fundamental computer vision task
that estimates an object's class, 3D position, dimensions, and orientation from
a single image. Its applications, including autonomous driving, augmented
reality, and robotics, critically rely on accurate 3D environmental
understanding. This thesis addresses the challenge of generalizing Mono3D
models to diverse scenarios, including occlusions, datasets, object sizes, and
camera parameters. To enhance occlusion robustness, we propose a mathematically
differentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we
explore depth equivariant (DEVIANT) backbones. We address the issue of large
object detection, demonstrating that it's not solely a data imbalance or
receptive field problem but also a noise sensitivity issue. To mitigate this,
we introduce a segmentation-based approach in bird's-eye view with dice loss
(SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D
models to unseen camera heights and improve Mono3D generalization in such
out-of-distribution settings.

</details>


### [36] [Quantization Robustness to Input Degradations for Object Detection](https://arxiv.org/abs/2508.19600)
*Toghrul Karimov,Hassan Imani,Allan Kazakov*

Main category: cs.CV

TL;DR: 这篇论文通过实验研究评估了不同精度格式下YOLO目标检测模型的粗糖化粗鲁检性，并提出了一种基于透层降级的校准策略，但在大多数情况下未能一致提升模型粗鲁性。


<details>
  <summary>Details</summary>
Motivation: 评估后训练量化(PTQ)在实际部署中对目标检测模型粗鲁性的影响，特别是对于输入降级(噪声、橡糖化、压缩效应)的适应能力。

Method: 采用综合实验研究方法，在COCO数据集上测试了从nano到extra-large不同规模的YOLO模型，测试了FP32、FP16、Dynamic UINT8和Static INT8四种精度格式。提出了降级感知校准策略，在TensorRT校准过程中混入清洁和合成降级图像。

Result: Static INT8 TensorRT引擎在清洁数据上实现了1.5-3.3倍速度提升，mAP50-95下降3-7%。但降级感知校准策略在大多数模型和降级条件下未能一致提升粗鲁性，仅在某些噪声条件下对大规模模型有显著改善。

Conclusion: 提高PTQ粗鲁性面临重大挑战，模型容量可能影响校准策略的有效性。研究结果为在非受控环境中部署量化检测器提供了有价值的见解。

Abstract: Post-training quantization (PTQ) is crucial for deploying efficient object
detection models, like YOLO, on resource-constrained devices. However, the
impact of reduced precision on model robustness to real-world input
degradations such as noise, blur, and compression artifacts is a significant
concern. This paper presents a comprehensive empirical study evaluating the
robustness of YOLO models (nano to extra-large scales) across multiple
precision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8
(TensorRT). We introduce and evaluate a degradation-aware calibration strategy
for Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix
of clean and synthetically degraded images. Models were benchmarked on the COCO
dataset under seven distinct degradation conditions (including various types
and levels of noise, blur, low contrast, and JPEG compression) and a
mixed-degradation scenario. Results indicate that while Static INT8 TensorRT
engines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop
(~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did
not yield consistent, broad improvements in robustness over standard clean-data
calibration across most models and degradations. A notable exception was
observed for larger model scales under specific noise conditions, suggesting
model capacity may influence the efficacy of this calibration approach. These
findings highlight the challenges in enhancing PTQ robustness and provide
insights for deploying quantized detectors in uncontrolled environments. All
code and evaluation tables are available at https://github.com/AllanK24/QRID.

</details>


### [37] [IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.19604)
*Qizhe Fan,Chaoyu Liu,Zhonghua Qiao,Xiaoqin Shen*

Main category: cs.CV

TL;DR: 提出IELDM和IELFormer框架，通过逆演化层抑制扩散模型生成缺陷，提升域泛化语义分割性能


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的合成数据存在结构和语义缺陷，直接用于训练会导致分割模型性能下降和错误累积

Method: 1) IELDM：在生成过程中集成逆演化层，基于拉普拉斯先验检测空间不连续性和语义不一致性；2) IELFormer：将IEL嵌入分割网络解码器，抑制伪影传播；3) 多尺度频率融合模块实现跨尺度语义一致性

Result: 在基准数据集上的大量实验表明，该方法相比现有方法实现了更优越的泛化性能

Conclusion: 逆演化层能有效抑制生成缺陷和伪影传播，多尺度频率融合增强了跨尺度语义一致性，显著提升了域泛化语义分割的性能

Abstract: Domain Generalized Semantic Segmentation (DGSS) focuses on training a model
using labeled data from a source domain, with the goal of achieving robust
generalization to unseen target domains during inference. A common approach to
improve generalization is to augment the source domain with synthetic data
generated by diffusion models (DMs). However, the generated images often
contain structural or semantic defects due to training imperfections. Training
segmentation models with such flawed data can lead to performance degradation
and error accumulation. To address this issue, we propose to integrate inverse
evolution layers (IELs) into the generative process. IELs are designed to
highlight spatial discontinuities and semantic inconsistencies using
Laplacian-based priors, enabling more effective filtering of undesirable
generative patterns. Based on this mechanism, we introduce IELDM, an enhanced
diffusion-based data augmentation framework that can produce higher-quality
images. Furthermore, we observe that the defect-suppression capability of IELs
can also benefit the segmentation network by suppressing artifact propagation.
Based on this insight, we embed IELs into the decoder of the DGSS model and
propose IELFormer to strengthen generalization capability in cross-domain
scenarios. To further strengthen the model's semantic consistency across
scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,
which performs frequency-domain analysis to achieve structured integration of
multi-resolution features, thereby improving cross-scale coherence. Extensive
experiments on benchmark datasets demonstrate that our approach achieves
superior generalization performance compared to existing methods.

</details>


### [38] [Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model](https://arxiv.org/abs/2508.19626)
*Jiajun Sun,Zhen Yu,Siyuan Yan,Jason J. Ong,Zongyuan Ge,Lei Zhang*

Main category: cs.CV

TL;DR: LF-VAR模型利用量化病灶评分和类型标签，通过语言提示控制皮肤图像合成，在FID指标上比现有最佳方法提升6.3%


<details>
  <summary>Details</summary>
Motivation: 真实临床皮肤图像数据有限，现有合成方法生成的图像质量低且缺乏对病灶位置和类型的控制

Method: 使用多尺度病灶聚焦的VQVAE编码图像为离散潜在表示，然后训练视觉自回归变换器进行图像合成，整合病灶测量和类型作为条件嵌入

Result: 在七种病灶类型上获得最佳FID分数（平均0.74），比之前SOTA方法提升6.3%

Conclusion: 该方法能有效生成高保真度、临床相关的合成皮肤图像，具有可控的病灶特征合成能力

Abstract: Skin images from real-world clinical practice are often limited, resulting in
a shortage of training data for deep-learning models. While many studies have
explored skin image synthesis, existing methods often generate low-quality
images and lack control over the lesion's location and type. To address these
limitations, we present LF-VAR, a model leveraging quantified lesion
measurement scores and lesion type labels to guide the clinically relevant and
controllable synthesis of skin images. It enables controlled skin synthesis
with specific lesion characteristics based on language prompts. We train a
multiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to
encode images into discrete latent representations for structured tokenization.
Then, a Visual AutoRegressive (VAR) Transformer trained on tokenized
representations facilitates image synthesis. Lesion measurement from the lesion
region and types as conditional embeddings are integrated to enhance synthesis
fidelity. Our method achieves the best overall FID score (average 0.74) among
seven lesion types, improving upon the previous state-of-the-art (SOTA) by
6.3%. The study highlights our controllable skin synthesis model's
effectiveness in generating high-fidelity, clinically relevant synthetic skin
images. Our framework code is available at
https://github.com/echosun1996/LF-VAR.

</details>


### [39] [Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition](https://arxiv.org/abs/2508.19630)
*Xiaolei Wei,Yi Ouyang,Haibo Ye*

Main category: cs.CV

TL;DR: DQRoute是一个针对长尾视觉识别问题的模块化框架，通过难度感知优化和动态专家协作来提升性能，特别是在稀有和困难类别上表现显著改善


<details>
  <summary>Details</summary>
Motivation: 长尾视觉识别不仅面临类别不平衡问题，还存在不同类别学习难度差异大的挑战。简单按频率重加权往往忽略了内在难以学习的类别

Method: 1) 基于预测不确定性和历史性能估计类别难度，用于指导自适应损失加权训练；2) 采用混合专家设计，每个专家专注于类别分布的不同区域；3) 推理时通过专家特定的OOD检测器生成置信度分数来加权专家预测，实现无需集中路由器的输入自适应路由；4) 所有组件端到端联合训练

Result: 在标准长尾基准测试中，DQRoute显著提高了性能，特别是在稀有和困难类别上

Conclusion: 将难度建模与去中心化专家路由相结合具有显著优势，为解决长尾识别问题提供了有效方案

Abstract: Long-tailed visual recognition is challenging not only due to class imbalance
but also because of varying classification difficulty across categories. Simply
reweighting classes by frequency often overlooks those that are intrinsically
hard to learn. To address this, we propose \textbf{DQRoute}, a modular
framework that combines difficulty-aware optimization with dynamic expert
collaboration. DQRoute first estimates class-wise difficulty based on
prediction uncertainty and historical performance, and uses this signal to
guide training with adaptive loss weighting. On the architectural side, DQRoute
employs a mixture-of-experts design, where each expert specializes in a
different region of the class distribution. At inference time, expert
predictions are weighted by confidence scores derived from expert-specific OOD
detectors, enabling input-adaptive routing without the need for a centralized
router. All components are trained jointly in an end-to-end manner. Experiments
on standard long-tailed benchmarks demonstrate that DQRoute significantly
improves performance, particularly on rare and difficult classes, highlighting
the benefit of integrating difficulty modeling with decentralized expert
routing.

</details>


### [40] [Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception](https://arxiv.org/abs/2508.19638)
*Yang Li,Quan Yuan,Guiyang Luo,Xiaoyuan Fu,Rui Pan,Yujia Yang,Congzhang Shao,Yuewen Liu,Jinglin Li*

Main category: cs.CV

TL;DR: CoPLOT是一个新颖的协作感知框架，使用点级优化token来解决BEV表示丢失3D结构信息的问题，通过语义感知token重排序、频率增强状态空间模型和邻域-自车对齐模块，在降低通信和计算开销的同时实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法通常使用2D鸟瞰图(BEV)表示中间特征，但这种方法丢弃了关键的细粒度3D结构线索，而这些线索对于精确的目标识别和定位至关重要。

Method: 1) 引入点级token作为中间表示；2) 语义感知token重排序模块利用场景级和token级语义信息生成自适应1D重排序；3) 频率增强状态空间模型在空间和频谱域捕获长距离序列依赖；4) 邻域-自车对齐模块结合全局代理级校正和局部token级细化来减轻定位噪声。

Result: 在模拟和真实世界数据集上的广泛实验表明，CoPLOT在通信和计算开销更低的情况下，性能优于最先进的模型。

Conclusion: CoPLOT通过点原生处理流程有效解决了点云数据无序、海量和位置敏感的特性，成功保留了详细的结构信息，为协作感知提供了更优的解决方案。

Abstract: Collaborative perception allows agents to enhance their perceptual
capabilities by exchanging intermediate features. Existing methods typically
organize these intermediate features as 2D bird's-eye-view (BEV)
representations, which discard critical fine-grained 3D structural cues
essential for accurate object recognition and localization. To this end, we
first introduce point-level tokens as intermediate representations for
collaborative perception. However, point-cloud data are inherently unordered,
massive, and position-sensitive, making it challenging to produce compact and
aligned point-level token sequences that preserve detailed structural
information. Therefore, we present CoPLOT, a novel Collaborative perception
framework that utilizes Point-Level Optimized Tokens. It incorporates a
point-native processing pipeline, including token reordering, sequence
modeling, and multi-agent spatial alignment. A semantic-aware token reordering
module generates adaptive 1D reorderings by leveraging scene-level and
token-level semantic information. A frequency-enhanced state space model
captures long-range sequence dependencies across both spatial and spectral
domains, improving the differentiation between foreground tokens and background
clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop
process, combining global agent-level correction with local token-level
refinement to mitigate localization noise. Extensive experiments on both
simulated and real-world datasets show that CoPLOT outperforms state-of-the-art
models, with even lower communication and computation overhead. Code will be
available at https://github.com/CheeryLeeyy/CoPLOT.

</details>


### [41] [UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks](https://arxiv.org/abs/2508.19647)
*Bikash Kumar Badatya,Vipul Baghel,Ravi Hegde*

Main category: cs.CV

TL;DR: 这篇论文提出了一种轻量级的无监督骨架基动作定位方法，通过空间时间图神经网结构和动作动力学指标，在无需手动标注的情况下实现了与监督方法相当的性能，具有高效实时性和良好的演绎性。


<details>
  <summary>Details</summary>
Motivation: 现有的细粒度动作定位方法通常需要大量标注数据和高容量模型，计算成本高且适配性差，难以应用于实际场景。需要一种轻量级、无监督的方案来解决这些问题。

Method: 采用关注机制空间时间图卷积神经网结构(ASTGCN)，通过姿势序列去噪任务进行预训练，学习内在运动动力学。推理时使用新的动作动力学指标(ADM)，通过分析嵌入向量的曲率变化来检测运动边界。

Result: 在DSV跃水数据集上达到了82.66%的平均精度(mAP)和29.09毫秒的平均定位延迟，性能与最优监督方法相当，同时保持计算效率。在未见的野外跃水视频中也表现出良好的演绎性。

Conclusion: 该方法提供了一种高效、轻量级的无监督动作定位解决方案，在保持计算效率的同时实现了与监督方法相当的性能，适用于嵌入式或动态环境中的实时动作分析系统。

Abstract: Fine-grained action localization in untrimmed sports videos presents a
significant challenge due to rapid and subtle motion transitions over short
durations. Existing supervised and weakly supervised solutions often rely on
extensive annotated datasets and high-capacity models, making them
computationally intensive and less adaptable to real-world scenarios. In this
work, we introduce a lightweight and unsupervised skeleton-based action
localization pipeline that leverages spatio-temporal graph neural
representations. Our approach pre-trains an Attention-based Spatio-Temporal
Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task with
blockwise partitions, enabling it to learn intrinsic motion dynamics without
any manual labeling. At inference, we define a novel Action Dynamics Metric
(ADM), computed directly from low-dimensional ASTGCN embeddings, which detects
motion boundaries by identifying inflection points in its curvature profile.
Our method achieves a mean Average Precision (mAP) of 82.66% and average
localization latency of 29.09 ms on the DSV Diving dataset, matching
state-of-the-art supervised performance while maintaining computational
efficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving
footage without retraining, demonstrating its practical applicability for
lightweight, real-time action analysis systems in embedded or dynamic
environments.

</details>


### [42] [IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising](https://arxiv.org/abs/2508.19649)
*Dongjin Kim,Jaekyun Ko,Muhammad Kashif Ali,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 提出一种基于动态生成核的迭代图像去噪方法，通过特征提取、全局统计和局部相关性模块来预测像素级变化核，在单一高斯噪声训练下实现多种噪声类型和级别的优秀泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖特定噪声分布，泛化能力有限且容易过拟合，需要大量训练数据和计算资源。

Method: 使用特征提取模块获取噪声不变特征，全局统计和局部相关性模块捕获噪声特征和结构关联，核预测模块生成像素级变化核进行迭代去噪。

Result: 紧凑模型（约0.04M参数）在单一高斯噪声训练下，对多种噪声类型和级别都表现出优异性能，证明了迭代动态滤波的实用性。

Conclusion: 动态核生成方法有效防止过拟合，提高对未见噪声的鲁棒性，为实际图像去噪提供了高效且高质量的解决方案。

Abstract: Image denoising is a fundamental challenge in computer vision, with
applications in photography and medical imaging. While deep learning-based
methods have shown remarkable success, their reliance on specific noise
distributions limits generalization to unseen noise types and levels. Existing
approaches attempt to address this with extensive training data and high
computational resources but they still suffer from overfitting. To address
these issues, we conduct image denoising by utilizing dynamically generated
kernels via efficient operations. This approach helps prevent overfitting and
improves resilience to unseen noise. Specifically, our method leverages a
Feature Extraction Module for robust noise-invariant features, Global
Statistics and Local Correlation Modules to capture comprehensive noise
characteristics and structural correlations. The Kernel Prediction Module then
employs these cues to produce pixel-wise varying kernels adapted to local
structures, which are then applied iteratively for denoising. This ensures both
efficiency and superior restoration quality. Despite being trained on
single-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse
noise types and levels, demonstrating the promise of iterative dynamic
filtering for practical image denoising.

</details>


### [43] [Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models](https://arxiv.org/abs/2508.19650)
*Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang*

Main category: cs.CV

TL;DR: Video-LevelGauge是一个专门评估大型视频语言模型位置偏见的基准测试，通过标准化探针和定制化上下文设置，系统性地检测模型在不同视频位置的表现偏差。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准测试主要评估整体性能，忽略了位置偏见这一关键但未被充分探索的方面，需要专门的评估工具来系统分析LVLMs的位置敏感性。

Method: 采用标准化探针和定制化上下文设置，灵活控制上下文长度、探针位置和上下文类型；结合统计测量和形态模式识别进行综合分析；包含438个手动策划视频，生成1,177个多选题和120个开放式问题。

Result: 评估27个最先进的LVLMs发现，许多领先开源模型存在显著位置偏见（头部或邻近内容偏好），而商业模型如Gemini2.5-Pro在整个视频序列中表现一致出色。

Conclusion: 该基准测试有效揭示了LVLMs的位置偏见问题，为减轻偏见和指导模型改进提供了可行见解，特别是在上下文长度、上下文变化和模型规模方面的分析具有重要意义。

Abstract: Large video language models (LVLMs) have made notable progress in video
understanding, spurring the development of corresponding evaluation benchmarks.
However, existing benchmarks generally assess overall performance across entire
video sequences, overlooking nuanced behaviors such as contextual positional
bias, a critical yet under-explored aspect of LVLM performance. We present
Video-LevelGauge, a dedicated benchmark designed to systematically assess
positional bias in LVLMs. We employ standardized probes and customized
contextual setups, allowing flexible control over context length, probe
position, and contextual types to simulate diverse real-world scenarios. In
addition, we introduce a comprehensive analysis method that combines
statistical measures with morphological pattern recognition to characterize
bias. Our benchmark comprises 438 manually curated videos spanning multiple
types, yielding 1,177 high-quality multiple-choice questions and 120 open-ended
questions, validated for their effectiveness in exposing positional bias. Based
on these, we evaluate 27 state-of-the-art LVLMs, including both commercial and
open-source models. Our findings reveal significant positional biases in many
leading open-source models, typically exhibiting head or neighbor-content
preferences. In contrast, commercial models such as Gemini2.5-Pro show
impressive, consistent performance across entire video sequences. Further
analyses on context length, context variation, and model scale provide
actionable insights for mitigating bias and guiding model enhancement.

</details>


### [44] [Scalable Object Detection in the Car Interior With Vision Foundation Models](https://arxiv.org/abs/2508.19651)
*Bálint Mészáros,Ahmet Firintepe,Sebastian Schmidt,Stephan Günnemann*

Main category: cs.CV

TL;DR: 基于分布式架构的车载视觉基础模型应用，通过细调轻量模型在车内物体检测与定位任务上超越GPT-4o性能


<details>
  <summary>Details</summary>
Motivation: 汽车内置系统计算资源有限，无法直接运行大型视觉基础模型，需要解决车内物体识别与定位的计算性挑战

Method: 提出ODAL框架，采用分布式架构将计算任务分配在车载系统咄云端，并引入ODALbench评估指标，对比GPT-4o咄轻量LLaVA 1.5 7B模型，通过细调提升性能

Result: 细调后的ODAL-LLaVA模型达到ODAL得分89%，比基线提升71%，超过GPT-4o近20%，ODAL_SNR指标是GPT-4o的3倍，在保持高检测准确性的同时显著减少幻觉现象

Conclusion: 分布式架构细调轻量模型能有效解决车载计算约束，在车内场景理解任务上取得显著性能提升，为车载AI应用提供了可行解决方案

Abstract: AI tasks in the car interior like identifying and localizing externally
introduced objects is crucial for response quality of personal assistants.
However, computational resources of on-board systems remain highly constrained,
restricting the deployment of such solutions directly within the vehicle. To
address this limitation, we propose the novel Object Detection and Localization
(ODAL) framework for interior scene understanding. Our approach leverages
vision foundation models through a distributed architecture, splitting
computational tasks between on-board and cloud. This design overcomes the
resource constraints of running foundation models directly in the car. To
benchmark model performance, we introduce ODALbench, a new metric for
comprehensive assessment of detection and localization.Our analysis
demonstrates the framework's potential to establish new standards in this
domain. We compare the state-of-the-art GPT-4o vision foundation model with the
lightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the
lightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model
achieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its
baseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the
fine-tuned model maintains high detection accuracy while significantly reducing
hallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.

</details>


### [45] [Self-Rewarding Vision-Language Model via Reasoning Decomposition](https://arxiv.org/abs/2508.19652)
*Zongxia Li,Wenhao Yu,Chengsong Huang,Rui Liu,Zhenwen Liang,Fuxiao Liu,Jingxi Che,Dian Yu,Jordan Boyd-Graber,Haitao Mi,Dong Yu*

Main category: cs.CV

TL;DR: Vision-SR1是一种自奖励方法，通过强化学习改善视觉语言模型的视觉推理能力，无需外部视觉监督，有效减少视觉幻觉和语言捷径问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型存在视觉幻觉和语言捷径问题，现有方法依赖人工标注或外部模型监督，成本高且容易导致分布偏移。需要一种无需外部监督的自监督方法来改善视觉推理。

Method: 将VLM推理分解为视觉感知和语言推理两个阶段。首先让模型生成自包含的视觉感知描述，然后使用同一模型仅基于感知描述进行语言推理来计算奖励，结合最终输出监督进行训练。

Result: 实验表明Vision-SR1能有效改善视觉推理能力，减少视觉幻觉现象，降低对语言捷径的依赖，在多种视觉语言任务上表现优异。

Conclusion: Vision-SR1提供了一种有效的自奖励框架，通过内部自我验证机制强化视觉感知和语言推理，无需外部监督即可解决VLM的视觉幻觉和语言捷径问题。

Abstract: Vision-Language Models (VLMs) often suffer from visual hallucinations, saying
things that are not actually in the image, and language shortcuts, where they
skip the visual part and just rely on text priors. These issues arise because
most post-training methods for VLMs rely on simple verifiable answer matching
and supervise only final outputs, leaving intermediate visual reasoning without
explicit guidance. As a result, VLMs receive sparse visual signals and often
learn to prioritize language-based reasoning over visual perception. To
mitigate this, some existing methods add visual supervision using human
annotations or distilled labels from external large models. However, human
annotations are labor-intensive and costly, and because external signals cannot
adapt to the evolving policy, they cause distributional shifts that can lead to
reward hacking. In this paper, we introduce Vision-SR1, a self-rewarding method
that improves visual reasoning without relying on external visual supervisions
via reinforcement learning. Vision-SR1 decomposes VLM reasoning into two
stages: visual perception and language reasoning. The model is first prompted
to produce self-contained visual perceptions that are sufficient to answer the
question without referring back the input image. To validate this
self-containment, the same VLM model is then re-prompted to perform language
reasoning using only the generated perception as input to compute reward. This
self-reward is combined with supervision on final outputs, providing a balanced
training signal that strengthens both visual perception and language reasoning.
Our experiments demonstrate that Vision-SR1 improves visual reasoning,
mitigates visual hallucinations, and reduces reliance on language shortcuts
across diverse vision-language tasks.

</details>


### [46] [Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications](https://arxiv.org/abs/2508.19654)
*Matthias Höfflin,Jürgen Wassner*

Main category: cs.CV

TL;DR: 该研究分析了脉冲神经网络(SNN)在卫星位置估计任务中的能效表现，发现硬件感知和硬件无关的能耗评估方法存在显著差异，SNN的能效优势仅在神经形态硬件和高输入稀疏性条件下才明显。


<details>
  <summary>Details</summary>
Motivation: 传统认为SNN具有固有能效优势，但近期研究对数字实现中的这一声誉提出质疑，特别是在与常规人工神经网络的比较中。本研究旨在通过多输出回归任务验证SNN的实际能效表现。

Method: 使用Leaky Integrate-and-Fire(LIF)神经元的膜电位训练SNN进行3D卫星位置估计，与参考CNN在逼真卫星数据集上比较MSE性能，并采用硬件感知和硬件无关两种能耗评估方法。

Result: SNN达到与CNN相当的MSE性能。硬件无关方法预测SNN有50-60%的能耗优势，但硬件感知分析显示只有在神经形态硬件和高输入稀疏性条件下才能实现显著节能。暗像素比例对能耗有重要影响。

Conclusion: 研究强调了透明评估方法和明确披露底层假设的必要性，以确保神经网络能效比较的公平性，数据特性和硬件假设对能效评估结果有重大影响。

Abstract: Spiking Neural Networks (SNNs), inspired by biological intelligence, have
long been considered inherently energy-efficient, making them attractive for
resource-constrained domains such as space applications. However, recent
comparative studies with conventional Artificial Neural Networks (ANNs) have
begun to question this reputation, especially for digital implementations. This
work investigates SNNs for multi-output regression, specifically 3-D satellite
position estimation from monocular images, and compares hardware-aware and
hardware-agnostic energy estimation methods. The proposed SNN, trained using
the membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the
final layer, achieves comparable Mean Squared Error (MSE) to a reference
Convolutional Neural Network (CNN) on a photorealistic satellite dataset.
Energy analysis shows that while hardware-agnostic methods predict a consistent
50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals
that significant energy savings are realized only on neuromorphic hardware and
with high input sparsity. The influence of dark pixel ratio on energy
consumption is quantified, emphasizing the impact of data characteristics and
hardware assumptions. These findings highlight the need for transparent
evaluation methods and explicit disclosure of underlying assumptions to ensure
fair comparisons of neural network energy efficiency.

</details>


### [47] [A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement](https://arxiv.org/abs/2508.19664)
*Weicheng Liao,Zan Chen,Jianyang Xie,Yalin Zheng,Yuhui Ma,Yitian Zhao*

Main category: cs.CV

TL;DR: 提出了一种新颖的频率感知自监督学习方法，用于超广角视网膜图像增强，通过频率解耦去模糊和Retinex引导的照明补偿模块，有效提升图像质量和疾病诊断性能。


<details>
  <summary>Details</summary>
Motivation: 超广角视网膜成像虽然提供了全面的视网膜视图，但经常受到模糊和光照不均等质量退化因素的影响，这些因素会掩盖精细细节和病理信息。现有的视网膜图像增强方法往往无法满足UWF图像的独特需求，特别是需要保留病理细节的要求。

Method: 采用频率感知自监督学习方法，包含频率解耦图像去模糊模块（引入非对称通道整合操作结合全局和局部视图）和Retinex引导的照明补偿模块（提出颜色保护单元提供多尺度空间和频率信息）。

Result: 实验结果表明，该方法不仅增强了可视化质量，还通过恢复和校正精细局部细节及不均匀强度，提高了疾病诊断性能。

Conclusion: 这是首个针对超广角视网膜图像增强的尝试，为改善视网膜疾病管理提供了一个强大且具有临床价值的工具。

Abstract: Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics
by providing a comprehensive view of the retina. However, it often suffers from
quality-degrading factors such as blurring and uneven illumination, which
obscure fine details and mask pathological information. While numerous retinal
image enhancement methods have been proposed for other fundus imageries, they
often fail to address the unique requirements in UWF, particularly the need to
preserve pathological details. In this paper, we propose a novel
frequency-aware self-supervised learning method for UWF image enhancement. It
incorporates frequency-decoupled image deblurring and Retinex-guided
illumination compensation modules. An asymmetric channel integration operation
is introduced in the former module, so as to combine global and local views by
leveraging high- and low-frequency information, ensuring the preservation of
fine and broader structural details. In addition, a color preservation unit is
proposed in the latter Retinex-based module, to provide multi-scale spatial and
frequency information, enabling accurate illumination estimation and
correction. Experimental results demonstrate that the proposed work not only
enhances visualization quality but also improves disease diagnosis performance
by restoring and correcting fine local details and uneven intensity. To the
best of our knowledge, this work is the first attempt for UWF image
enhancement, offering a robust and clinically valuable tool for improving
retinal disease management.

</details>


### [48] [SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction](https://arxiv.org/abs/2508.19688)
*Gangjian Zhang,Jian Shu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: SAT是一个单目纹理3D人体重建框架，通过两阶段流程统一学习多种几何先验，使用监督特征正则化和在线动画增强模块解决几何模糊性和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 单目2D图像存在几何模糊性，3D人体训练数据稀缺，现有方法难以有效整合多种几何模态（如SMPL模型和法线贴图），导致视角不一致和面部扭曲等问题。

Method: 提出两阶段重建框架SAT：1）监督特征正则化模块，使用多视图网络提供中间特征作为训练监督；2）在线动画增强模块，通过前馈动画网络在线生成大量样本增强训练数据。

Result: 在两个基准测试上的大量实验表明，该方法相比最先进方法具有优越性，能够重建高质量的纹理3D虚拟形象。

Conclusion: SAT框架通过统一学习多种几何先验和有效的数据增强策略，成功解决了单目3D人体重建中的几何模糊性和数据稀缺问题，实现了高质量的重建效果。

Abstract: Monocular texture 3D human reconstruction aims to create a complete 3D
digital avatar from just a single front-view human RGB image. However, the
geometric ambiguity inherent in a single 2D image and the scarcity of 3D human
training data are the main obstacles limiting progress in this field. To
address these issues, current methods employ prior geometric estimation
networks to derive various human geometric forms, such as the SMPL model and
normal maps. However, they struggle to integrate these modalities effectively,
leading to view inconsistencies, such as facial distortions. To this end, we
propose a two-process 3D human reconstruction framework, SAT, which seamlessly
learns various prior geometries in a unified manner and reconstructs
high-quality textured 3D avatars as the final output. To further facilitate
geometry learning, we introduce a Supervisor Feature Regularization module. By
employing a multi-view network with the same structure to provide intermediate
features as training supervision, these varied geometric priors can be better
fused. To tackle data scarcity and further improve reconstruction quality, we
also propose an Online Animation Augmentation module. By building a
one-feed-forward animation network, we augment a massive number of samples from
the original 3D human data online for model training. Extensive experiments on
two benchmarks show the superiority of our approach compared to
state-of-the-art methods.

</details>


### [49] [Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators](https://arxiv.org/abs/2508.19698)
*V. S. Usatyuk,D. A. Sapozhnikov,S. I. Egorov*

Main category: cs.CV

TL;DR: 基于物理受灵的无监督检测方法，通过建立图象模型和分析Bethe-Hessian谱来区分真实图像与生成图像，无需标签数据即可达到94%准确率


<details>
  <summary>Details</summary>
Motivation: 现有的监督检测器对未见生成器效果快速下降，而基于低级统计特征的无监督方法很容易被攻击，需要一种更稳健的方法来应对深度生成模型带来的挑战

Method: 将图像特征提取并降维后，构建多边类型QC-LDPC图，将成对相似性转换为在Nishimori温度下的边耦合，形成随机铅子氏模型，通过分析Bethe-Hessian谱的特征间隔来识别真实图像

Result: 在二元分类任务（猫vs狗，男vs女）上达到超过94%的准确率，无需任何标签生成数据或重新训练特征提取器，谱分析显示真实图像集有多个明显分离的谱间隔

Conclusion: 该方法提供了一种新题的无监督生成图像检测器，具有模型无关性、稳健性和高准确率的优点，为应对新兴生成模型的挑战提供了有效解决方案

Abstract: The rapid advance of deep generative models such as GANs and diffusion
networks now produces images that are virtually indistinguishable from genuine
photographs, undermining media forensics and biometric security. Supervised
detectors quickly lose effectiveness on unseen generators or after adversarial
post-processing, while existing unsupervised methods that rely on low-level
statistical cues remain fragile. We introduce a physics-inspired,
model-agnostic detector that treats synthetic-image identification as a
community-detection problem on a sparse weighted graph. Image features are
first extracted with pretrained CNNs and reduced to 32 dimensions, each feature
vector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities
are transformed into edge couplings calibrated at the Nishimori temperature,
producing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum
exhibits a characteristic gap when genuine community structure (real images) is
present. Synthetic images violate the Nishimori symmetry and therefore lack
such gaps. We validate the approach on binary tasks cat versus dog and male
versus female using real photos from Flickr-Faces-HQ and CelebA and synthetic
counterparts generated by GANs and diffusion models. Without any labeled
synthetic data or retraining of the feature extractor, the detector achieves
over 94% accuracy. Spectral analysis shows multiple well separated gaps for
real image sets and a collapsed spectrum for generated ones. Our contributions
are threefold: a novel LDPC graph construction that embeds deep image features,
an analytical link between Nishimori temperature RBIM and the Bethe-Hessian
spectrum providing a Bayes optimal detection criterion; and a practical,
unsupervised synthetic image detector robust to new generative architectures.
Future work will extend the framework to video streams and multi-class anomaly
detection.

</details>


### [50] [LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation](https://arxiv.org/abs/2508.19699)
*Yupeng Zhang,Dezhi Zheng,Ping Lu,Han Zhang,Lei Wang,Liping xiang,Cheng Luo,Kaijun Deng,Xiaowen Fu,Linlin Shen,Jinbao Wang*

Main category: cs.CV

TL;DR: LabelGS是一种增强3D高斯溅射的语义分割方法，通过引入跨视图一致的语义掩码和遮挡分析模型，实现了高效的3D场景分割，训练速度比现有方法快22倍。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射(3DGS)虽然能实现高保真重建和高效渲染，但缺乏3D分割能力，限制了其在需要场景理解任务中的应用。

Method: 提出LabelGS方法，为高斯表示添加对象标签，包括：跨视图一致的语义掩码、遮挡分析模型避免过拟合、主高斯标记模型将2D语义先验提升到3D、高斯投影过滤器避免标签冲突，并采用随机区域采样策略优化3DGS过程。

Result: 在3D场景分割任务中优于包括Feature-3DGS在内的最先进方法，在1440X1080分辨率下训练速度比Feature-3DGS快22倍。

Conclusion: LabelGS有效解耦了高斯表示，显著提高了3D场景分割的效率和性能，为3D场景理解提供了强有力的工具。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation
for 3D scenes, offering both high-fidelity reconstruction and efficient
rendering. However, 3DGS lacks 3D segmentation ability, which limits its
applicability in tasks that require scene understanding. The identification and
isolating of specific object components is crucial. To address this limitation,
we propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments
the Gaussian representation with object label.LabelGS introduces cross-view
consistent semantic masks for 3D Gaussians and employs a novel Occlusion
Analysis Model to avoid overfitting occlusion during optimization, Main
Gaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian
Projection Filter to avoid Gaussian label conflict. Our approach achieves
effective decoupling of Gaussian representations and refines the 3DGS
optimization process through a random region sampling strategy, significantly
improving efficiency. Extensive experiments demonstrate that LabelGS
outperforms previous state-of-the-art methods, including Feature-3DGS, in the
3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup
in training compared to Feature-3DGS, at a resolution of 1440X1080. Our code
will be at https://github.com/garrisonz/LabelGS.

</details>


### [51] [FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation](https://arxiv.org/abs/2508.19705)
*Qiang Hu,Ying Zhou,Gepeng Ji,Nick Barnes,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 本文提出FreeVPS方法，通过结合IPS模型的空间上下文和SAM2的时间建模能力，使用两个无训练模块解决长期追踪中的错误累积问题，在内外域场景下都取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频息肌切割(VPS)方法在平衡时空建模和域逆向性方面遇到困难，限制了在真实临床场景中的应用。SAM2在长期追踪中存在错误累积问题，影响切割稳定性。

Method: 重构VPS为追踪-检测范式，结合IPS模型的空间上下文和SAM2的时间建模能力。使用两个无训练模块：内部关联筛选模块消除空间不准确性，跨关联精炼模块防止错误传播。

Result: 在内域和外域场景下都取得了最先进性能。在长时间未剪连续肠镜视频中展示了稳健的追踪能力。

Conclusion: FreeVPS通过无训练模块有效解决了SAM2的错误累积问题，实现了高性能的视频息肌切割，具有可靠的临床分析潜力。

Abstract: Existing video polyp segmentation (VPS) paradigms usually struggle to balance
between spatiotemporal modeling and domain generalization, limiting their
applicability in real clinical scenarios. To embrace this challenge, we recast
the VPS task as a track-by-detect paradigm that leverages the spatial contexts
captured by the image polyp segmentation (IPS) model while integrating the
temporal modeling capabilities of segment anything model 2 (SAM2). However,
during long-term polyp tracking in colonoscopy videos, SAM2 suffers from error
accumulation, resulting in a snowball effect that compromises segmentation
stability. We mitigate this issue by repurposing SAM2 as a video polyp
segmenter with two training-free modules. In particular, the intra-association
filtering module eliminates spatial inaccuracies originating from the detecting
stage, reducing false positives. The inter-association refinement module
adaptively updates the memory bank to prevent error propagation over time,
enhancing temporal coherence. Both modules work synergistically to stabilize
SAM2, achieving cutting-edge performance in both in-domain and out-of-domain
scenarios. Furthermore, we demonstrate the robust tracking capabilities of
FreeVPS in long-untrimmed colonoscopy videos, underscoring its potential
reliable clinical analysis.

</details>


### [52] [Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning](https://arxiv.org/abs/2508.19730)
*Stelios Mylonas,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 基于面部基础模型的视频深似检测框架，通过三元组损失和归因监督提升模型的分辨能力和泛化性能


<details>
  <summary>Details</summary>
Motivation: 深似检测模型在真实世界场景中普遍缺乏良好的泛化能力，需要开发更稳健的检测方法

Method: 基于自监督面部基础模型FSFM，使用多个深似数据集进行微调，采用三元组损失和归因监督方案来提升模型性能

Result: 在多个评测标准上进行了涉广实验，证明方法在具有挑战性的真实世界场景中表现出艰强的效果

Conclusion: 利用面部基础模型的丰富表征学习，结合多重监督机制，可以强化深似检测模型的泛化能力

Abstract: The increasing realism and accessibility of deepfakes have raised critical
concerns about media authenticity and information integrity. Despite recent
advances, deepfake detection models often struggle to generalize beyond their
training distributions, particularly when applied to media content found in the
wild. In this work, we present a robust video deepfake detection framework with
strong generalization that takes advantage of the rich facial representations
learned by face foundation models. Our method is built on top of FSFM, a
self-supervised model trained on real face data, and is further fine-tuned
using an ensemble of deepfake datasets spanning both face-swapping and
face-reenactment manipulations. To enhance discriminative power, we incorporate
triplet loss variants during training, guiding the model to produce more
separable embeddings between real and fake samples. Additionally, we explore
attribution-based supervision schemes, where deepfakes are categorized by
manipulation type or source dataset, to assess their impact on generalization.
Extensive experiments across diverse evaluation benchmarks demonstrate the
effectiveness of our approach, especially in challenging real-world scenarios.

</details>


### [53] [POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection](https://arxiv.org/abs/2508.19742)
*Chenguang Liu,Chisheng Wang,Yuhua Cai,Chuanhua Zhu,Qingquan Li*

Main category: cs.CV

TL;DR: POEv2是一个改进的像素方向估计方法，可用于通用线段检测和线框线段检测，结合高效边缘检测器在三个公开数据集上达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有线段检测器分为通用线段检测器和线框线段检测器两类，由于设计目标不同，它们在对方任务上表现不佳，需要一种能同时处理两种任务的鲁棒框架

Method: 提出POEv2方法，从边缘强度图检测线段，可与任何边缘检测器结合使用，是Pixel Orientation Estimation方法的改进版本

Result: 通过将POEv2与高效边缘检测器结合，在三个公开数据集上实现了最先进的性能

Conclusion: POEv2提供了一个统一的框架，能够同时胜任通用线段检测和线框线段检测任务，具有很好的实用性和性能表现

Abstract: Line segment detection in images has been studied for several decades.
Existing line segment detectors can be roughly divided into two categories:
generic line segment detectors and wireframe line segment detectors. Generic
line segment detectors aim to detect all meaningful line segments in images and
traditional approaches usually fall into this category. Recent deep learning
based approaches are mostly wireframe line segment detectors. They detect only
line segments that are geometrically meaningful and have large spatial support.
Due to the difference in the aim of design, the performance of generic line
segment detectors for the task of wireframe line segment detection won't be
satisfactory, and vice versa. In this work, we propose a robust framework that
can be used for both generic line segment detection and wireframe line segment
detection. The proposed method is an improved version of the Pixel Orientation
Estimation (POE) method. It is thus named as POEv2. POEv2 detects line segments
from edge strength maps, and can be combined with any edge detector. We show in
our experiments that by combining the proposed POEv2 with an efficient edge
detector, it achieves state-of-the-art performance on three publicly available
datasets.

</details>


### [54] [SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection](https://arxiv.org/abs/2508.19746)
*Qiyao Xu,Qiming Wu,Xiaowei Li*

Main category: cs.CV

TL;DR: SPLF-SAM是一个自提示光场分割模型，通过统一多尺度特征嵌入块和多尺度自适应滤波适配器，解决了传统方法忽略提示信息提取和频域信息分析的问题，在光场显著目标检测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模型在光场显著目标检测任务中往往忽略提示信息的提取，同时传统方法忽视频域信息分析，导致小目标被噪声淹没。

Method: 提出了SPLF-SAM模型，包含统一多尺度特征嵌入块(UMFEB)用于识别不同尺寸的多目标，以及多尺度自适应滤波适配器(MAFA)通过学习频域特征防止小目标被噪声淹没。

Result: 在十个最先进的光场显著目标检测方法上进行了广泛实验，证明了该方法的优越性。

Conclusion: SPLF-SAM模型通过创新的多尺度特征嵌入和频域滤波技术，有效解决了光场显著目标检测中的关键问题，取得了state-of-the-art的性能。

Abstract: Segment Anything Model (SAM) has demonstrated remarkable capabilities in
solving light field salient object detection (LF SOD). However, most existing
models tend to neglect the extraction of prompt information under this task.
Meanwhile, traditional models ignore the analysis of frequency-domain
information, which leads to small objects being overwhelmed by noise. In this
paper, we put forward a novel model called self-prompting light field segment
anything model (SPLF-SAM), equipped with unified multi-scale feature embedding
block (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is
capable of identifying multiple objects of varying sizes, while MAFA, by
learning frequency features, effectively prevents small objects from being
overwhelmed by noise. Extensive experiments have demonstrated the superiority
of our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be
available at https://github.com/XucherCH/splfsam.

</details>


### [55] [FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers](https://arxiv.org/abs/2508.19754)
*Yue Wu,Yufan Wu,Wen Li,Yuxi Lu,Kairui Feng,Xuanhong Chen*

Main category: cs.CV

TL;DR: FastAvatar是一个快速3D虚拟人重建框架，能够在几秒内利用单张图像、多视角观测或单目视频等多种日常记录数据，重建高质量的3D高斯溅射模型。


<details>
  <summary>Details</summary>
Motivation: 现有3D虚拟人重建方法存在时间复杂度过高、对数据质量敏感以及数据利用率低等问题，需要一种能够灵活利用多样化输入数据并实现快速高质量重建的解决方案。

Method: 采用大型高斯重建变换器，包含三个关键设计：变体VGGT式变换器架构聚合多帧线索并注入初始3D提示；多粒度引导编码缓解动画引起的错位；通过地标跟踪和切片融合损失实现增量高斯聚合。

Result: 实验表明FastAvatar在质量和速度方面都优于现有方法，支持增量重建，即随着更多观测数据的加入，重建质量会不断提升。

Conclusion: FastAvatar提供了一个质量-速度可调的高可用虚拟人建模范式，能够高效利用输入数据，在几秒内完成高质量3D虚拟人重建。

Abstract: Despite significant progress in 3D avatar reconstruction, it still faces
challenges such as high time complexity, sensitivity to data quality, and low
data utilization. We propose FastAvatar, a feedforward 3D avatar framework
capable of flexibly leveraging diverse daily recordings (e.g., a single image,
multi-view observations, or monocular video) to reconstruct a high-quality 3D
Gaussian Splatting (3DGS) model within seconds, using only a single unified
model. FastAvatar's core is a Large Gaussian Reconstruction Transformer
featuring three key designs: First, a variant VGGT-style transformer
architecture aggregating multi-frame cues while injecting initial 3D prompt to
predict an aggregatable canonical 3DGS representation; Second, multi-granular
guidance encoding (camera pose, FLAME expression, head pose) mitigating
animation-induced misalignment for variable-length inputs; Third, incremental
Gaussian aggregation via landmark tracking and sliced fusion losses.
Integrating these features, FastAvatar enables incremental reconstruction,
i.e., improving quality with more observations, unlike prior work wasting input
data. This yields a quality-speed-tunable paradigm for highly usable avatar
modeling. Extensive experiments show that FastAvatar has higher quality and
highly competitive speed compared to existing methods.

</details>


### [56] [BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions](https://arxiv.org/abs/2508.19762)
*Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher*

Main category: cs.CV

TL;DR: BuzzSet是一个用于传粉昆虫监测的大规模数据集，包含7856张高分辨率图像和8000多个标注实例，使用YOLOv12和RF-DETR模型实现了高效的蜜蜂识别。


<details>
  <summary>Details</summary>
Motivation: 传粉昆虫对全球粮食生产和生态系统稳定至关重要，但其种群数量正在下降。需要开发可扩展的自动化监测方法来应对这一挑战。

Method: 创建BuzzSet数据集，包含手动验证标注的图像，使用YOLOv12模型生成初始标注并通过人工验证精炼，采用256×256图像切片处理小目标检测，使用RF-DETR变压器目标检测器建立基准。

Result: 模型在蜜蜂和大黄蜂类别上分别达到0.94和0.92的F1分数，混淆矩阵显示类别间误分类极少，最佳mAP@0.50为0.559。

Conclusion: BuzzSet为小目标检测、标签噪声下的类别分离和生态计算机视觉提供了有价值的基准数据集。

Abstract: Pollinator insects such as honeybees and bumblebees are vital to global food
production and ecosystem stability, yet their populations are declining due to
increasing anthropogenic and environmental stressors. To support scalable,
automated pollinator monitoring, we introduce BuzzSet, a new large-scale
dataset of high-resolution pollinator images collected in real agricultural
field conditions. BuzzSet contains 7856 manually verified and labeled images,
with over 8000 annotated instances across three classes: honeybees, bumblebees,
and unidentified insects. Initial annotations were generated using a YOLOv12
model trained on external data and refined via human verification using
open-source labeling tools. All images were preprocessed into 256~$\times$~256
tiles to improve the detection of small insects. We provide strong baselines
using the RF-DETR transformer-based object detector. The model achieves high
F1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively,
with confusion matrix results showing minimal misclassification between these
categories. The unidentified class remains more challenging due to label
ambiguity and lower sample frequency, yet still contributes useful insights for
robustness evaluation. Overall detection quality is strong, with a best
mAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object
detection, class separation under label noise, and ecological computer vision.

</details>


### [57] [AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning](https://arxiv.org/abs/2508.19769)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: 提出了AIM方法来解决多模态学习中的优化偏差问题，通过自适应网络内调制实现平衡的多模态学习，不抑制任何模态的性能


<details>
  <summary>Details</summary>
Motivation: 现有不平衡多模态学习方法通常通过抑制主导模态来促进弱势模态，这影响了整体多模态性能。研究发现根本原因是网络内部的优化偏差问题

Method: 提出自适应网络内调制(AIM)方法，将主导模态的未优化参数解耦到辅助块中，鼓励弱势模态依赖这些性能下降的块进行联合训练，同时自适应调整不同网络深度的调制强度

Result: AIM在多个基准测试中优于最先进的不平衡模态学习方法，并在不同骨干网络、融合策略和优化器上表现出强大的泛化能力

Conclusion: AIM首次实现了在不抑制任何模态的情况下实现平衡的多模态学习，有效解决了网络内部优化偏差问题

Abstract: Multimodal learning has significantly enhanced machine learning performance
but still faces numerous challenges and limitations. Imbalanced multimodal
learning is one of the problems extensively studied in recent works and is
typically mitigated by modulating the learning of each modality. However, we
find that these methods typically hinder the dominant modality's learning to
promote weaker modalities, which affects overall multimodal performance. We
analyze the cause of this issue and highlight a commonly overlooked problem:
optimization bias within networks. To address this, we propose Adaptive
Intra-Network Modulation (AIM) to improve balanced modality learning. AIM
accounts for differences in optimization state across parameters and depths
within the network during modulation, achieving balanced multimodal learning
without hindering either dominant or weak modalities for the first time.
Specifically, AIM decouples the dominant modality's under-optimized parameters
into Auxiliary Blocks and encourages reliance on these performance-degraded
blocks for joint training with weaker modalities. This approach effectively
prevents suppression of weaker modalities while enabling targeted optimization
of under-optimized parameters to improve the dominant modality. Additionally,
AIM assesses modality imbalance level across network depths and adaptively
adjusts modulation strength at each depth. Experimental results demonstrate
that AIM outperforms state-of-the-art imbalanced modality learning methods
across multiple benchmarks and exhibits strong generalizability across
different backbones, fusion strategies, and optimizers.

</details>


### [58] [The Return of Structural Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.19773)
*Jakob Seitz,Tobias Lengfeld,Radu Timofte*

Main category: cs.CV

TL;DR: 这篇论文提出了一种结构化手写数学表达式识别方法，通过自动注释和模块化识别系统实现了符号与赤迹的明确对齐，提高了错误分析能力和程序的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的编码器-解码器架构虽然在LaTeX生成方面表现优异，但缺乏明确的符号到赤迹对齐，影响错误分析、可解释性和需要选择性内容更新的交互应用。

Method: 提出了两项创新：1）使用神经网络将LaTeX方程映射到原始赤迹的自动注释系统，自动生成符号分割、分类和空间关系注释；2）模块化结构识别系统，独立优化分割、分类和关系预测。结合图基赤迹排序、混合卷积-递归网络和基于Transformer的纠正技术。

Result: 在CROHME-2023基准测试中达到了竞争性能能力，生成了完整的图结构，直接将手写赤迹与预测符号连接起来。

Conclusion: 该结构化识别方法不仅提供了竞争性的识别性能，更重要的是实现了透明的错误分析和可解释的输出，为教育技术应用提供了更好的支撑。

Abstract: Handwritten Mathematical Expression Recognition is foundational for
educational technologies, enabling applications like digital note-taking and
automated grading. While modern encoder-decoder architectures with large
language models excel at LaTeX generation, they lack explicit symbol-to-trace
alignment, a critical limitation for error analysis, interpretability, and
spatially aware interactive applications requiring selective content updates.
This paper introduces a structural recognition approach with two innovations: 1
an automatic annotation system that uses a neural network to map LaTeX
equations to raw traces, automatically generating annotations for symbol
segmentation, classification, and spatial relations, and 2 a modular structural
recognition system that independently optimizes segmentation, classification,
and relation prediction. By leveraging a dataset enriched with structural
annotations from our auto-labeling system, the proposed recognition system
combines graph-based trace sorting, a hybrid convolutional-recurrent network,
and transformer-based correction to achieve competitive performance on the
CROHME-2023 benchmark. Crucially, our structural recognition system generates a
complete graph structure that directly links handwritten traces to predicted
symbols, enabling transparent error analysis and interpretable outputs.

</details>


### [59] [MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.19786)
*Han Jiao,Jiakai Sun,Yexing Xu,Lei Zhao,Wei Xing,Huaizhong Lin*

Main category: cs.CV

TL;DR: MAPo框架通过动态评分分割策略，将3D高斯分为高动态和低动态区域，对高动态区域进行时间分割和网络复制以捕捉精细运动细节，同时使用跨帧一致性损失确保视觉连续性，在保持计算效率的同时显著提升动态场景重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于变形的3D高斯泼溅方法在动态场景重建中，由于使用单一统一模型难以表示多样化运动模式，导致渲染模糊和精细运动细节丢失，特别是在高动态区域。

Method: 提出动态评分分割策略区分高动态和低动态3D高斯；对高动态高斯进行时间递归分割并为每个时间段复制变形网络；对低动态高斯保持静态以减少计算成本；引入跨帧一致性损失解决分割边界视觉不连续问题。

Result: 大量实验表明，MAPo在保持可比计算成本的同时，相比基线方法实现了更优越的渲染质量，特别是在具有复杂或快速运动的区域表现突出。

Conclusion: MAPo框架通过动态分割和专业化建模策略，有效解决了动态3D高斯泼溅中的运动细节丢失问题，为高保真动态场景重建提供了有效解决方案。

Abstract: 3D Gaussian Splatting, known for enabling high-quality static scene
reconstruction with fast rendering, is increasingly being applied to dynamic
scene reconstruction. A common strategy involves learning a deformation field
to model the temporal changes of a canonical set of 3D Gaussians. However,
these deformation-based methods often produce blurred renderings and lose fine
motion details in highly dynamic regions due to the inherent limitations of a
single, unified model in representing diverse motion patterns. To address these
challenges, we introduce Motion-Aware Partitioning of Deformable 3D Gaussian
Splatting (MAPo), a novel framework for high-fidelity dynamic scene
reconstruction. Its core is a dynamic score-based partitioning strategy that
distinguishes between high- and low-dynamic 3D Gaussians. For high-dynamic 3D
Gaussians, we recursively partition them temporally and duplicate their
deformation networks for each new temporal segment, enabling specialized
modeling to capture intricate motion details. Concurrently, low-dynamic 3DGs
are treated as static to reduce computational costs. However, this temporal
partitioning strategy for high-dynamic 3DGs can introduce visual
discontinuities across frames at the partition boundaries. To address this, we
introduce a cross-frame consistency loss, which not only ensures visual
continuity but also further enhances rendering quality. Extensive experiments
demonstrate that MAPo achieves superior rendering quality compared to baselines
while maintaining comparable computational costs, particularly in regions with
complex or rapid motions.

</details>


### [60] [StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation](https://arxiv.org/abs/2508.19789)
*Xiuchao Wu,Pengfei Zhu,Jiangjing Lyu,Xinguo Liu,Jie Guo,Yanwen Guo,Weiwei Xu,Chengfei Lyu*

Main category: cs.CV

TL;DR: StableIntrinsic是一个用于多视角材质估计的一步扩散模型，能够生成高质量、低方差的材质参数，在多项指标上显著超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的材质估计方法采用多步去噪策略，耗时且存在随机性推断与确定性材质估计任务冲突的问题，导致估计结果方差较高。

Method: 提出StableIntrinsic一步扩散模型，在像素空间应用基于材质特性的损失函数，并引入细节注入网络(DIN)来消除VAE编码造成的细节损失，增强材质预测结果的清晰度。

Result: 实验结果显示，该方法在albedo的PSNR上提升9.9%，金属和粗糙度的MSE分别降低44.4%和60.0%，超越了当前最先进技术。

Conclusion: StableIntrinsic通过一步扩散策略和专门的细节增强机制，成功解决了多步扩散模型的时间消耗和方差问题，为材质估计提供了高效且稳定的解决方案。

Abstract: Recovering material information from images has been extensively studied in
computer graphics and vision. Recent works in material estimation leverage
diffusion model showing promising results. However, these diffusion-based
methods adopt a multi-step denoising strategy, which is time-consuming for each
estimation. Such stochastic inference also conflicts with the deterministic
material estimation task, leading to a high variance estimated results. In this
paper, we introduce StableIntrinsic, a one-step diffusion model for multi-view
material estimation that can produce high-quality material parameters with low
variance. To address the overly-smoothing problem in one-step diffusion,
StableIntrinsic applies losses in pixel space, with each loss designed based on
the properties of the material. Additionally, StableIntrinsic introduces a
Detail Injection Network (DIN) to eliminate the detail loss caused by VAE
encoding, while further enhancing the sharpness of material prediction results.
The experimental results indicate that our method surpasses the current
state-of-the-art techniques by achieving a $9.9\%$ improvement in the Peak
Signal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error
(MSE) for metallic and roughness by $44.4\%$ and $60.0\%$, respectively.

</details>


### [61] [Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models](https://arxiv.org/abs/2508.19791)
*Shay Shomer Chai,Wenxuan Peng,Bharath Hariharan,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 本文针对文本到图像生成中多对象颜色属性语义对齐问题进行研究，提出了专门的图像编辑技术来改善多颜色提示的语义对齐效果。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成方法在处理复杂多对象提示时难以准确捕捉精确语义，特别是在颜色属性方面存在明显问题。现有方法主要使用粗粒度指标或人工评估，难以大规模进行。

Method: 通过颜色属性作为案例研究，分析预训练模型在多颜色提示生成中的问题，并提出专门的图像编辑技术来解决多对象语义对齐问题。

Result: 研究表明预训练模型在多颜色属性生成方面表现较差，现有推理技术和编辑方法都无法可靠解决语义不对齐问题。提出的新方法在各种指标上显著提升了性能。

Conclusion: 多对象颜色语义对齐是文本到图像生成中的重要挑战，需要专门的技术来解决。本文提出的编辑方法为改善多颜色提示的语义保真度提供了有效解决方案。

Abstract: Text-to-image generation has recently seen remarkable success, granting users
with the ability to create high-quality images through the use of text.
However, contemporary methods face challenges in capturing the precise
semantics conveyed by complex multi-object prompts. Consequently, many works
have sought to mitigate such semantic misalignments, typically via
inference-time schemes that modify the attention layers of the denoising
networks. However, prior work has mostly utilized coarse metrics, such as the
cosine similarity between text and image CLIP embeddings, or human evaluations,
which are challenging to conduct on a larger-scale. In this work, we perform a
case study on colors -- a fundamental attribute commonly associated with
objects in text prompts, which offer a rich test bed for rigorous evaluation.
Our analysis reveals that pretrained models struggle to generate images that
faithfully reflect multiple color attributes-far more so than with single-color
prompts-and that neither inference-time techniques nor existing editing methods
reliably resolve these semantic misalignments. Accordingly, we introduce a
dedicated image editing technique, mitigating the issue of multi-object
semantic alignment for prompts containing multiple colors. We demonstrate that
our approach significantly boosts performance over a wide range of metrics,
considering images generated by various text-to-image diffusion-based
techniques.

</details>


### [62] [FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization](https://arxiv.org/abs/2508.19798)
*Muhammad Ali,Omar Ali AlSuwaidi*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In the realm of waste management, automating the sorting process for
non-biodegradable materials presents considerable challenges due to the
complexity and variability of waste streams. To address these challenges, we
introduce an enhanced neural architecture that builds upon an existing
Encoder-Decoder structure to improve the accuracy and efficiency of waste
sorting systems. Our model integrates several key innovations: a Comprehensive
Attention Block within the decoder, which refines feature representations by
combining convolutional and upsampling operations. In parallel, we utilize
attention through the Mamba architecture, providing an additional performance
boost. We also introduce a Data Fusion Block that fuses images with more than
three channels. To achieve this, we apply PCA transformation to reduce the
dimensionality while retaining the maximum variance and essential information
across three dimensions, which are then used for further processing. We
evaluated the model on RGB, hyperspectral, multispectral, and a combination of
RGB and hyperspectral data. The results demonstrate that our approach
outperforms existing methods by a significant margin.

</details>


### [63] [A bag of tricks for real-time Mitotic Figure detection](https://arxiv.org/abs/2508.19804)
*Christian Marzahl,Brian Napora*

Main category: cs.CV

TL;DR: 该论文提出了一套训练技巧集合，用于实现跨域鲁棒的有丝分裂图像实时检测，基于RTMDet单阶段检测器，在多个数据集上达到0.78-0.84的F1分数，在MIDOG 2025挑战赛测试集上达到0.81 F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学图像中有丝分裂图像检测面临的挑战，包括扫描仪差异、染色协议差异、组织类型多样性和伪影存在等问题，实现临床部署所需的鲁棒实时检测。

Method: 基于RTMDet单阶段目标检测器，采用多域训练数据、平衡采样、精心设计的增强技术，并针对坏死和碎片组织进行硬负样本挖掘以减少假阳性。

Result: 在多个有丝分裂数据集的分组5折交叉验证中，模型F1分数达到0.78-0.84；在MIDOG 2025挑战赛测试集上达到0.81 F1分数，优于大型模型。

Conclusion: 该方法在准确性和速度之间提供了实用的权衡，具有对新域的适应能力，适合实际临床应用。

Abstract: Mitotic figure (MF) detection in histopathology images is challenging due to
large variations in slide scanners, staining protocols, tissue types, and the
presence of artifacts. This paper presents a collection of training techniques
- a bag of tricks - that enable robust, real-time MF detection across diverse
domains. We build on the efficient RTMDet single stage object detector to
achieve high inference speed suitable for clinical deployment. Our method
addresses scanner variability and tumor heterogeneity via extensive
multi-domain training data, balanced sampling, and careful augmentation.
Additionally, we employ targeted, hard negative mining on necrotic and debris
tissue to reduce false positives. In a grouped 5-fold cross-validation across
multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On
the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025
challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,
outperforming larger models and demonstrating adaptability to new, unfamiliar
domains. The proposed solution offers a practical trade-off between accuracy
and speed, making it attractive for real-world clinical adoption.

</details>


### [64] [AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment](https://arxiv.org/abs/2508.19808)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS是一个无监督视频实例分割框架，通过质量引导的自训练方法，在不需要人工标注的情况下实现了最先进的性能，在YouTubeVIS-2019数据集上达到52.6 AP50。


<details>
  <summary>Details</summary>
Motivation: 视频实例分割需要像素级掩码和时间一致性标注，标注成本高昂。现有无监督方法依赖合成数据，但存在合成到真实域的差距问题。

Method: 提出质量引导的自训练框架，建立伪标签生成和自动质量评估的闭环系统，实现从合成视频到真实视频的渐进式适应。

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，比之前最好的VideoCutLER方法提升4.4%，且无需任何人工标注。

Conclusion: 证明了质量感知自训练在无监督视频实例分割中的可行性，成功弥合了合成到真实域的差距。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due
to its dual requirements of pixel-level masks and temporal consistency labels.
While recent unsupervised methods like VideoCutLER eliminate optical flow
dependencies through synthetic data, they remain constrained by the
synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised
framework that bridges this gap through quality-guided self-training. Our
approach establishes a closed-loop system between pseudo-label generation and
automatic quality assessment, enabling progressive adaptation from synthetic to
real videos. Experiments demonstrate state-of-the-art performance with 52.6
$\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous
state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations.
This demonstrates the viability of quality-aware self-training for unsupervised
VIS. The source code of our method is available at
https://github.com/wcbup/AutoQ-VIS.

</details>


### [65] [ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images](https://arxiv.org/abs/2508.19815)
*Linkuan Zhou,Zhexin Chen,Yufei Shen,Junlin Xu,Ping Xuan,Yixin Zhu,Yuqi Fang,Cong Cong,Leyi Wei,Ran Su,Jia Zhou,Qiangguo Jin*

Main category: cs.CV

TL;DR: 基于双评分适应性筛选、椭圆约束伪标签精炼和对称性多重一致性正则化的半监督胎儿头部超声分割方法，在缺乏标注数据情况下实现了独特的分割性能。


<details>
  <summary>Details</summary>
Motivation: 胎儿头部超声图像质量较差且缺乏标注数据，现有半监督方法在生成可靠伪标签和实施有效一致性约束方面遇到困难。

Method: 提出ERSR框架，包括：1双评分适应性筛选策略（边界一致性和轮廓规则性评估）；2椭圆约束伪标签精炼（最小二乘椭圆拟合）；3对称性多重一致性正则化（多级别一致性约束）。

Result: 在HC18数据集上：10%标签数据达到92.05% Dice，20%标签数据达到95.36% Dice。在PSFH数据集上：10%标签数据达到91.68% Dice，20%标签数据达到93.70% Dice。

Conclusion: ERSR框架通过创新的伪标签生成和一致性约束机制，有效解决了胎儿头部超声分割中的挑战，实现了独特的分割性能。

Abstract: Automated segmentation of the fetal head in ultrasound images is critical for
prenatal monitoring. However, achieving robust segmentation remains challenging
due to the poor quality of ultrasound images and the lack of annotated data.
Semi-supervised methods alleviate the lack of annotated data but struggle with
the unique characteristics of fetal head ultrasound images, making it
challenging to generate reliable pseudo-labels and enforce effective
consistency regularization constraints. To address this issue, we propose a
novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.
Our framework consists of the dual-scoring adaptive filtering strategy, the
ellipse-constrained pseudo-label refinement, and the symmetry-based multiple
consistency regularization. The dual-scoring adaptive filtering strategy uses
boundary consistency and contour regularity criteria to evaluate and filter
teacher outputs. The ellipse-constrained pseudo-label refinement refines these
filtered outputs by fitting least-squares ellipses, which strengthens pixels
near the center of the fitted ellipse and suppresses noise simultaneously. The
symmetry-based multiple consistency regularization enforces multi-level
consistency across perturbed images, symmetric regions, and between original
predictions and pseudo-labels, enabling the model to capture robust and stable
shape representations. Our method achieves state-of-the-art performance on two
benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%
with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores
are 91.68% and 93.70% under the same settings.

</details>


### [66] [Gradient Rectification for Robust Calibration under Distribution Shift](https://arxiv.org/abs/2508.19830)
*Yilin Zhang,Cai Xu,You Wu,Ziyu Guan,Wei Zhao*

Main category: cs.CV

TL;DR: 通过低频筛波策略和梯度基于修正机制，在无需目标域信息的情况下改善深度网络在分布偏移下的预测准确性


<details>
  <summary>Details</summary>
Motivation: 深度网络在分布偏移下容易产生过份自信的预测，影响在安全关键应用中的可靠性，而现有方法需要目标域信息或模拟，实际应用受限

Method: 从频域角度出发，采用低频筛波策略促进模型依赖域不变特征，同时通过梯度基于修正机制确保内部分布准确性

Result: 在CIFAR-10/100-C和WILDS等合成和实际偏移数据集上，方法显著改善了分布偏移下的准确性，同时保持了强劲的内部分布性能

Conclusion: 该框架为在无目标域信息的情况下提高深度模型在分布偏移下的可靠性提供了有效解决方案

Abstract: Deep neural networks often produce overconfident predictions, undermining
their reliability in safety-critical applications. This miscalibration is
further exacerbated under distribution shift, where test data deviates from the
training distribution due to environmental or acquisition changes. While
existing approaches improve calibration through training-time regularization or
post-hoc adjustment, their reliance on access to or simulation of target
domains limits their practicality in real-world scenarios. In this paper, we
propose a novel calibration framework that operates without access to target
domain information. From a frequency-domain perspective, we identify that
distribution shifts often distort high-frequency visual cues exploited by deep
models, and introduce a low-frequency filtering strategy to encourage reliance
on domain-invariant features. However, such information loss may degrade
In-Distribution (ID) calibration performance. Therefore, we further propose a
gradient-based rectification mechanism that enforces ID calibration as a hard
constraint during optimization. Experiments on synthetic and real-world shifted
datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method
significantly improves calibration under distribution shift while maintaining
strong in-distribution performance.

</details>


### [67] [Image Quality Assessment for Machines: Paradigm, Large-scale Database, and Models](https://arxiv.org/abs/2508.19850)
*Xiaoqi Wang,Yun Zhang,Weisi Lin*

Main category: cs.CV

TL;DR: 这篇论文提出了一种机器视角中心的图像质量评估（MIQA）框架，用于量化图像退化对机器视角系统性能的影响，并建立了包含250万样本的数据库和区域感知MIQA模型，显著提升了评估性能。


<details>
  <summary>Details</summary>
Motivation: 机器视角系统在恶劣视觉条件下容易出现性能退化，但传统的人类视觉系统基础的图像质量评估方法并不适用于机器视角系统的质量预测需求。

Method: 建立了机器视角中心的图像质量评估范式，构建了包含250万样本的MIQD-2.5M数据库，涵盖75个视角模型、250种退化类型和三种代表性视角任务。进一步提出了区域感知MIQA（RA-MIQA）模型，通过细粒度空间退化分析来评估机器视角系统的视觉质量。

Result: 实验结果显示RA-MIQA在多个维度上都表现优异，在图像分类任务上一致性和准确性方面分别获得13.56%和13.37%的SRCC提升。同时发现了任务特异性的退化敏感性。

Conclusion: 传统的HVS基础指标无法有效预测机器视角系统质量，而专门的MIQA模型也面临后景退化、准确性估计和细微形变等挑战。这项研究有助于提升机器视角系统的可靠性，为机器中心的图像处理和优化奠定基础。

Abstract: Machine vision systems (MVS) are intrinsically vulnerable to performance
degradation under adverse visual conditions. To address this, we propose a
machine-centric image quality assessment (MIQA) framework that quantifies the
impact of image degradations on MVS performance. We establish an MIQA paradigm
encompassing the end-to-end assessment workflow. To support this, we construct
a machine-centric image quality database (MIQD-2.5M), comprising 2.5 million
samples that capture distinctive degradation responses in both consistency and
accuracy metrics, spanning 75 vision models, 250 degradation types, and three
representative vision tasks. We further propose a region-aware MIQA (RA-MIQA)
model to evaluate MVS visual quality through fine-grained spatial degradation
analysis. Extensive experiments benchmark the proposed RA-MIQA against seven
human visual system (HVS)-based IQA metrics and five retrained classical
backbones. Results demonstrate RA-MIQA's superior performance in multiple
dimensions, e.g., achieving SRCC gains of 13.56% on consistency and 13.37% on
accuracy for image classification, while also revealing task-specific
degradation sensitivities. Critically, HVS-based metrics prove inadequate for
MVS quality prediction, while even specialized MIQA models struggle with
background degradations, accuracy-oriented estimation, and subtle distortions.
This study can advance MVS reliability and establish foundations for
machine-centric image processing and optimization. The model and code are
available at: https://github.com/XiaoqiWang/MIQA.

</details>


### [68] [Ego-centric Predictive Model Conditioned on Hand Trajectories](https://arxiv.org/abs/2508.19852)
*Binjie Zhang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 提出统一的两阶段预测框架，联合建模自我中心场景中的动作和视觉未来，通过手部轨迹条件化，实现动作预测和未来视频生成的统一处理


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时建模动作预测和视觉结果。VLA模型只关注动作预测但缺乏对视觉场景影响的显式建模，视频预测模型生成未来帧但不基于特定动作条件，常产生不合理结果

Method: 两阶段框架：第一阶段处理异构输入（视觉观察、语言、动作历史）并预测未来手部轨迹；第二阶段引入因果交叉注意力融合多模态线索，利用推断的动作信号指导基于图像的潜在扩散模型进行逐帧未来视频生成

Result: 在Ego4D、BridgeData和RLBench数据集上的大量实验表明，该方法在动作预测和未来视频合成方面均优于最先进的基线方法

Conclusion: 这是首个统一处理自我中心人类活动理解和机器人操作任务的模型，能够显式预测即将发生的动作及其视觉后果

Abstract: In egocentric scenarios, anticipating both the next action and its visual
outcome is essential for understanding human-object interactions and for
enabling robotic planning. However, existing paradigms fall short of jointly
modeling these aspects. Vision-Language-Action (VLA) models focus on action
prediction but lack explicit modeling of how actions influence the visual
scene, while video prediction models generate future frames without
conditioning on specific actions, often resulting in implausible or
contextually inconsistent outcomes. To bridge this gap, we propose a unified
two-stage predictive framework that jointly models action and visual future in
egocentric scenarios, conditioned on hand trajectories. In the first stage, we
perform consecutive state modeling to process heterogeneous inputs (visual
observations, language, and action history) and explicitly predict future hand
trajectories. In the second stage, we introduce causal cross-attention to fuse
multi-modal cues, leveraging inferred action signals to guide an image-based
Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our
approach is the first unified model designed to handle both egocentric human
activity understanding and robotic manipulation tasks, providing explicit
predictions of both upcoming actions and their visual consequences. Extensive
experiments on Ego4D, BridgeData, and RLBench demonstrate that our method
outperforms state-of-the-art baselines in both action prediction and future
video synthesis.

</details>


### [69] [Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction](https://arxiv.org/abs/2508.19862)
*Long Chen,Ashiv Patel,Mengyun Qiao,Mohammad Yousuf Salmasi,Salah A. Hammouche,Vasilis Stavrinides,Jasleen Nagi,Soodeh Kalaie,Xiao Yun Xu,Wenjia Bai,Declan P. O'Regan*

Main category: cs.CV

TL;DR: MCMeshGAN是一个多模态条件网格生成对抗网络，用于3D主动脉瘤生长预测，结合局部KNN卷积和全局图卷积网络，在几何精度和临床直径估计方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主动脉瘤进展的个性化准确预测对于及时干预至关重要，但由于需要同时建模复杂3D几何中的细微局部变形和全局解剖变化，这一任务具有挑战性。

Method: 提出双分支架构：新颖的局部KNN卷积网络(KCN)保持细粒度几何细节，全局图卷积网络(GCN)捕获长程结构上下文，克服深度GCN的过度平滑问题。专用条件分支编码临床属性和目标时间间隔。

Result: 在TAAMesh数据集(208名患者的590条多模态记录)上的实验表明，MCMeshGAN在几何精度和临床重要直径估计方面始终优于最先进的基线方法。

Conclusion: 该框架为临床可部署的个性化3D疾病轨迹建模提供了稳健的一步，源代码已公开。

Abstract: Personalized, accurate prediction of aortic aneurysm progression is essential
for timely intervention but remains challenging due to the need to model both
subtle local deformations and global anatomical changes within complex 3D
geometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh
generative adversarial network for 3D aneurysm growth prediction. MCMeshGAN
introduces a dual-branch architecture combining a novel local KNN-based
convolutional network (KCN) to preserve fine-grained geometric details and a
global graph convolutional network (GCN) to capture long-range structural
context, overcoming the over-smoothing limitations of deep GCNs. A dedicated
condition branch encodes clinical attributes (age, sex) and the target time
interval to generate anatomically plausible, temporally controlled predictions,
enabling retrospective and prospective modeling. We curated TAAMesh, a new
longitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal
records (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive
experiments demonstrate that MCMeshGAN consistently outperforms
state-of-the-art baselines in both geometric accuracy and clinically important
diameter estimation. This framework offers a robust step toward clinically
deployable, personalized 3D disease trajectory modeling. The source code for
MCMeshGAN and the baseline methods is publicly available at
https://github.com/ImperialCollegeLondon/MCMeshGAN.

</details>


### [70] [Self-supervised structured object representation learning](https://arxiv.org/abs/2508.19864)
*Oussama Hadjerci,Antoine Letienne,Mohamed Abbas Hedjazi,Adel Hafiane*

Main category: cs.CV

TL;DR: 提出了一种基于ProtoScale模块的自监督学习方法，通过语义分组、实例级分离和层次化结构来构建结构化视觉表示，在目标检测任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法在全局图像理解方面表现良好，但在捕捉场景结构化表示方面存在局限，特别是在密集预测任务中。

Method: 使用ProtoScale模块在多空间尺度上捕捉视觉元素，保持完整场景上下文，结合语义分组、实例级分离和层次化结构来构建渐进式结构化表示。

Result: 在COCO和UA-DETRAC数据集上的实验表明，该方法学习到的以目标为中心的表示能够提升监督目标检测性能，在有限标注数据和较少微调轮次下仍优于最先进方法。

Conclusion: 该方法通过保持场景上下文和多尺度结构化表示学习，有效提升了自监督学习在密集预测任务中的性能，特别是在目标检测方面的表现。

Abstract: Self-supervised learning (SSL) has emerged as a powerful technique for
learning visual representations. While recent SSL approaches achieve strong
results in global image understanding, they are limited in capturing the
structured representation in scenes. In this work, we propose a self-supervised
approach that progressively builds structured visual representations by
combining semantic grouping, instance level separation, and hierarchical
structuring. Our approach, based on a novel ProtoScale module, captures visual
elements across multiple spatial scales. Unlike common strategies like DINO
that rely on random cropping and global embeddings, we preserve full scene
context across augmented views to improve performance in dense prediction
tasks. We validate our method on downstream object detection tasks using a
combined subset of multiple datasets (COCO and UA-DETRAC). Experimental results
show that our method learns object centric representations that enhance
supervised object detection and outperform the state-of-the-art methods, even
when trained with limited annotated data and fewer fine-tuning epochs.

</details>


### [71] [TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations](https://arxiv.org/abs/2508.19866)
*François G. Landry,Moulay A. Akhloufi*

Main category: cs.CV

TL;DR: TrajFusionNet是一个基于transformer的新模型，通过结合未来行人轨迹和车辆速度预测来预测行人过街意图，在推理时间和性能方面都达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆上路，预测行人过街意图成为重要研究领域，需要准确判断行人是否会过马路以确保道路安全。

Method: 提出TrajFusionNet模型，包含序列注意力模块(SAM)和视觉注意力模块(VAM)两个分支，分别从序列表示和视觉表示中学习预测信息。

Result: 模型在三个常用数据集上达到最先进性能，同时具有最低的总推理时间（包括模型运行和数据预处理）。

Conclusion: TrajFusionNet通过轻量级模态结合轨迹和速度预测，在行人过街意图预测任务中实现了优异的性能和效率。

Abstract: With the introduction of vehicles with autonomous capabilities on public
roads, predicting pedestrian crossing intention has emerged as an active area
of research. The task of predicting pedestrian crossing intention involves
determining whether pedestrians in the scene are likely to cross the road or
not. In this work, we propose TrajFusionNet, a novel transformer-based model
that combines future pedestrian trajectory and vehicle speed predictions as
priors for predicting crossing intention. TrajFusionNet comprises two branches:
a Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM
branch learns from a sequential representation of the observed and predicted
pedestrian trajectory and vehicle speed. Complementarily, the VAM branch
enables learning from a visual representation of the predicted pedestrian
trajectory by overlaying predicted pedestrian bounding boxes onto scene images.
By utilizing a small number of lightweight modalities, TrajFusionNet achieves
the lowest total inference time (including model runtime and data
preprocessing) among current state-of-the-art approaches. In terms of
performance, it achieves state-of-the-art results across the three most
commonly used datasets for pedestrian crossing intention prediction.

</details>


### [72] [Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network](https://arxiv.org/abs/2508.19875)
*Hui Zhang,Jianghui Cai,Haifeng Yang,Ali Luo,Yuqing Yang,Xiao Kong,Zhichao Ding,Lichan Zhou,Qin Han*

Main category: cs.CV

TL;DR: 提出基于互信息的天空背景估计模型SMI，通过双网络结构解决传统天空光纤平均谱缺乏环境建模的问题，在LAMOST光谱数据上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前多目标光纤光谱处理中的天空背景扣除主要依赖天空光纤光谱构建超级天空谱，但这些平均谱缺乏对目标周围环境的建模。

Method: SMI模型包含两个主要网络：第一个网络使用波长校准模块从光谱中提取天空特征，解决特征偏移问题；第二个网络采用增量训练方法最大化不同光谱表示间的互信息来捕获共同成分，同时最小化相邻光谱表示间的互信息以获得个体成分。

Result: 在LAMOST光谱数据上的实验结果表明，SMI能够在观测过程中获得更好的目标天空背景，特别是在蓝端表现更优。

Conclusion: SMI模型通过互信息和增量训练方法有效解决了天空背景估计问题，为多目标光纤光谱处理提供了更准确的环境建模能力。

Abstract: Sky background subtraction is a critical step in Multi-objective Fiber
spectra process. However, current subtraction relies mainly on sky fiber
spectra to build Super Sky. These average spectra are lacking in the modeling
of the environment surrounding the objects. To address this issue, a sky
background estimation model: Sky background building based on Mutual
Information (SMI) is proposed. SMI based on mutual information and incremental
training approach. It utilizes spectra from all fibers in the plate to estimate
the sky background. SMI contains two main networks, the first network applies a
wavelength calibration module to extract sky features from spectra, and can
effectively solve the feature shift problem according to the corresponding
emission position. The second network employs an incremental training approach
to maximize mutual information between representations of different spectra to
capturing the common component. Then, it minimizes the mutual information
between adjoining spectra representations to obtain individual components. This
network yields an individual sky background at each location of the object. To
verify the effectiveness of the method in this paper, we conducted experiments
on the spectra of LAMOST. Results show that SMI can obtain a better object sky
background during the observation, especially in the blue end.

</details>


### [73] [Multispectral LiDAR data for extracting tree points in urban and suburban areas](https://arxiv.org/abs/2508.19881)
*Narges Takhtkeshha,Gabriele Mazzacca,Fabio Remondino,Juha Hyyppä,Gottfried Mandlburger*

Main category: cs.CV

TL;DR: 本研究探索使用多光谱LiDAR和深度学习模型进行城市树木点云提取的方法，评估了三种先进模型的性能，发现SPT模型在时间效率和准确性方面表现最优。


<details>
  <summary>Details</summary>
Motivation: 监测城市树木动态对支持绿化政策和减少电力设施风险至关重要。虽然机载雷达扫描推动了大规模树木管理，但城市环境复杂性和树木变异性带来挑战。多光谱LiDAR能够同时获取3D空间和光谱数据，为详细映射提供了可能。

Method: 研究使用多光谱LiDAR数据，评估了三种先进的深度学习模型：Superpoint Transformer (SPT)、Point Transformer V3 (PTv3)和Point Transformer V1 (PTv1)。比较了仅使用空间信息与结合伪标准化植被指数(pNDVI)的性能差异。

Result: SPT模型表现最优，平均交并比(mIoU)达到85.28%，具有显著的时间效率和准确性。结合pNDVI和空间数据的方法将错误率降低了10.61个百分点，显著提高了检测准确性。

Conclusion: 研究结果表明，多光谱LiDAR与深度学习模型的结合具有重大潜力，能够显著提高城市树木提取的准确性和效率，为下一步树木资产清查提供了有力支持。

Abstract: Monitoring urban tree dynamics is vital for supporting greening policies and
reducing risks to electrical infrastructure. Airborne laser scanning has
advanced large-scale tree management, but challenges remain due to complex
urban environments and tree variability. Multispectral (MS) light detection and
ranging (LiDAR) improves this by capturing both 3D spatial and spectral data,
enabling detailed mapping. This study explores tree point extraction using
MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are
evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point
Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of
SPT, with a mean intersection over union (mIoU) of 85.28%. The highest
detection accuracy is achieved by incorporating pseudo normalized difference
vegetation index (pNDVI) with spatial data, reducing error rate by 10.61
percentage points (pp) compared to using spatial information alone. These
findings highlight the potential of MS-LiDAR and DL to improve tree extraction
and further tree inventories.

</details>


### [74] [PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos](https://arxiv.org/abs/2508.19895)
*Ziyun Qian,Runyu Xiao,Shuyuan Tu,Wei Xue,Dingkang Yang,Mingcheng Li,Dongliang Kou,Minghao Han,Zizhi Chen,Lihua Zhang*

Main category: cs.CV

TL;DR: 本文提出PersonaAnimator框架，从无约束视频中学习个性化运动模式，实现视频到视频的运动个性化，解决了现有方法无法学习运动风格、依赖动作捕捉数据、违反物理规律等问题。


<details>
  <summary>Details</summary>
Motivation: 现有运动生成方法存在三个主要局限：(1)姿态引导的运动迁移方法仅复制运动而不学习风格特征，导致角色表现力不足；(2)运动风格迁移方法严重依赖难以获取的动作捕捉数据；(3)生成的运动有时违反物理规律。

Method: 提出PersonaAnimator框架，直接从无约束视频学习个性化运动模式；构建首个视频个性化运动数据集PersonaVid（包含20个运动内容类别和120个运动风格类别）；提出物理感知运动风格正则化机制确保生成运动的物理合理性。

Result: 大量实验表明，PersonaAnimator在运动迁移方法中表现优于现有最先进方法，为视频到视频运动个性化任务设立了新的基准。

Conclusion: 该研究开创了视频到视频运动个性化新任务，提出的框架能够有效从视频中学习个性化运动模式，解决了现有方法的局限性，并在性能和物理合理性方面取得了显著改进。

Abstract: Recent advances in motion generation show remarkable progress. However,
several limitations remain: (1) Existing pose-guided character motion transfer
methods merely replicate motion without learning its style characteristics,
resulting in inexpressive characters. (2) Motion style transfer methods rely
heavily on motion capture data, which is difficult to obtain. (3) Generated
motions sometimes violate physical laws. To address these challenges, this
paper pioneers a new task: Video-to-Video Motion Personalization. We propose a
novel framework, PersonaAnimator, which learns personalized motion patterns
directly from unconstrained videos. This enables personalized motion transfer.
To support this task, we introduce PersonaVid, the first video-based
personalized motion dataset. It contains 20 motion content categories and 120
motion style categories. We further propose a Physics-aware Motion Style
Regularization mechanism to enforce physical plausibility in the generated
motions. Extensive experiments show that PersonaAnimator outperforms
state-of-the-art motion transfer methods and sets a new benchmark for the
Video-to-Video Motion Personalization task.

</details>


### [75] [WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.19927)
*Fayaz Ali,Muhammad Zawish,Steven Davy,Radu Timofte*

Main category: cs.CV

TL;DR: 提出WaveHiT-SR方法，通过将小波变换嵌入分层transformer框架，使用自适应分层窗口替代静态小窗口，在降低计算复杂度的同时提升超分辨率性能


<details>
  <summary>Details</summary>
Motivation: 现有基于transformer的超分辨率方法由于窗口自注意力机制的二次计算复杂度，被迫使用小的固定窗口，限制了感受野范围

Method: 1) 使用自适应分层窗口替代静态小窗口；2) 利用小波变换将图像分解为多频段子带；3) 通过分层处理逐步重建高分辨率图像

Result: 在SwinIR-Light、SwinIR-NG和SRFormer-Light等模型上实现了最先进的超分辨率结果，参数量更少、FLOPs更低、速度更快

Conclusion: WaveHiT-SR方法有效解决了transformer在超分辨率任务中的计算复杂度问题，同时保持了优异的性能表现

Abstract: Transformers have demonstrated promising performance in computer vision
tasks, including image super-resolution (SR). The quadratic computational
complexity of window self-attention mechanisms in many transformer-based SR
methods forces the use of small, fixed windows, limiting the receptive field.
In this paper, we propose a new approach by embedding the wavelet transform
within a hierarchical transformer framework, called (WaveHiT-SR). First, using
adaptive hierarchical windows instead of static small windows allows to capture
features across different levels and greatly improve the ability to model
long-range dependencies. Secondly, the proposed model utilizes wavelet
transforms to decompose images into multiple frequency subbands, allowing the
network to focus on both global and local features while preserving structural
details. By progressively reconstructing high-resolution images through
hierarchical processing, the network reduces computational complexity without
sacrificing performance. The multi-level decomposition strategy enables the
network to capture fine-grained information in lowfrequency components while
enhancing high-frequency textures. Through extensive experimentation, we
confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined
versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR
results, achieving higher efficiency with fewer parameters, lower FLOPs, and
faster speeds.

</details>


### [76] [Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities](https://arxiv.org/abs/2508.19905)
*Imad Ali Shah,Jiarong Li,Roshan George,Tim Brophy,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本文首次全面综述了高光谱成像(HSI)在汽车ADAS/AD应用中的现状，分析了216款商用HSI相机，发现仅有4款满足性能要求且无一款符合AEC-Q100标准，揭示了HSI研究潜力与商业成熟度之间的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像能够提供超越传统RGB成像的精细光谱分辨率，实现材料级别的场景理解，在高级驾驶辅助系统和自动驾驶应用中具有变革性潜力，但需要系统评估其技术成熟度和实际应用可行性。

Method: 通过定性综述结合定量分析，对216款商用高光谱和多光谱成像相机进行基准测试，评估帧率、空间分辨率、光谱维度和AEC-Q100温度标准符合性等关键汽车标准。

Result: 分析显示仅有4款相机满足性能阈值，无一款符合AEC-Q100要求；现有HSI数据集在规模、光谱一致性、通道数量和环境多样性方面存在局限，阻碍了感知算法的开发和验证。

Conclusion: HSI在汽车应用中的研究潜力与商业成熟度存在显著差距，需要朝着实际集成方向开展关键研究，包括改进相机技术、丰富数据集和解决标准化问题。

Abstract: Hyperspectral imaging (HSI) offers a transformative sensing modality for
Advanced Driver Assistance Systems (ADAS) and autonomous driving (AD)
applications, enabling material-level scene understanding through fine spectral
resolution beyond the capabilities of traditional RGB imaging. This paper
presents the first comprehensive review of HSI for automotive applications,
examining the strengths, limitations, and suitability of current HSI
technologies in the context of ADAS/AD. In addition to this qualitative review,
we analyze 216 commercially available HSI and multispectral imaging cameras,
benchmarking them against key automotive criteria: frame rate, spatial
resolution, spectral dimensionality, and compliance with AEC-Q100 temperature
standards. Our analysis reveals a significant gap between HSI's demonstrated
research potential and its commercial readiness. Only four cameras meet the
defined performance thresholds, and none comply with AEC-Q100 requirements. In
addition, the paper reviews recent HSI datasets and applications, including
semantic segmentation for road surface classification, pedestrian separability,
and adverse weather perception. Our review shows that current HSI datasets are
limited in terms of scale, spectral consistency, the number of spectral
channels, and environmental diversity, posing challenges for the development of
perception algorithms and the adequate validation of HSI's true potential in
ADAS/AD applications. This review paper establishes the current state of HSI in
automotive contexts as of 2025 and outlines key research directions toward
practical integration of spectral imaging in ADAS and autonomous systems.

</details>


### [77] [GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](https://arxiv.org/abs/2508.19972)
*Seongheon Park,Yixuan Li*

Main category: cs.CV

TL;DR: GLSim是一个无需训练的目标幻觉检测框架，通过结合全局和局部嵌入相似性信号，在多种场景下实现更准确可靠的目标幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型中的目标幻觉问题对其在现实应用中的安全部署构成重大挑战。现有方法通常孤立地采用全局或局部视角，可能限制了检测的可靠性。

Method: 提出GLSim框架，利用图像和文本模态之间的互补性全局和局部嵌入相似性信号，无需训练即可进行目标幻觉检测。

Result: 在全面的基准测试中，GLSim实现了优越的检测性能，显著优于竞争基线方法。

Conclusion: GLSim通过结合全局和局部视角，为目标幻觉检测提供了更准确可靠的解决方案，有助于提升视觉语言模型在实际应用中的安全性。

Abstract: Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

</details>


### [78] [Streamlining the Development of Active Learning Methods in Real-World Object Detection](https://arxiv.org/abs/2508.19906)
*Moussa Kassem Sbeyti,Nadja Klein,Michelle Karg,Christian Wirth,Sahin Albayrak*

Main category: cs.CV

TL;DR: 提出了一种基于对象相似性的度量方法OSS，用于目标检测中的主动学习，无需训练检测器即可评估方法效果并选择代表性验证集，显著降低计算成本和提高评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决目标检测中主动学习方法评估的高计算成本（单次训练需282 GPU小时）和验证集选择导致的排名不一致问题，特别是在自动驾驶等安全关键系统中的可靠性挑战。

Method: 开发了对象级集合相似性度量OSS，通过比较训练集与目标域的对象级特征相似性来评估主动学习方法效果，无需实际训练检测器。该方法可提前筛选无效方法并选择代表性验证集。

Result: 在KITTI、BDD100K、CODA三个自动驾驶数据集上验证，使用EfficientDet和YOLOv3两种检测器架构，证明OSS能有效评估不确定性主动学习方法，显著降低计算成本。

Conclusion: OSS是首个基于对象相似性统一目标检测主动学习训练和评估策略的方法，具有检测器无关性、仅需标注对象裁剪、可与现有管道集成等优点，为实际应用提供了实用框架。

Abstract: Active learning (AL) for real-world object detection faces computational and
reliability challenges that limit practical deployment. Developing new AL
methods requires training multiple detectors across iterations to compare
against existing approaches. This creates high costs for autonomous driving
datasets where the training of one detector requires up to 282 GPU hours.
Additionally, AL method rankings vary substantially across validation sets,
compromising reliability in safety-critical transportation systems. We
introduce object-based set similarity ($\mathrm{OSS}$), a metric that addresses
these challenges. $\mathrm{OSS}$ (1) quantifies AL method effectiveness without
requiring detector training by measuring similarity between training sets and
target domains using object-level features. This enables the elimination of
ineffective AL methods before training. Furthermore, $\mathrm{OSS}$ (2) enables
the selection of representative validation sets for robust evaluation. We
validate our similarity-based approach on three autonomous driving datasets
(KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with
two detector architectures (EfficientDet, YOLOv3). This work is the first to
unify AL training and evaluation strategies in object detection based on object
similarity. $\mathrm{OSS}$ is detector-agnostic, requires only labeled object
crops, and integrates with existing AL pipelines. This provides a practical
framework for deploying AL in real-world applications where computational
efficiency and evaluation reliability are critical. Code is available at
https://mos-ks.github.io/publications/.

</details>


### [79] [Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation](https://arxiv.org/abs/2508.19909)
*Lechun You,Zhonghua Wu,Weide Liu,Xulei Yang,Jun Cheng,Wei Zhou,Bharadwaj Veeravalli,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出了一种利用2D基础模型增强3D弱监督语义分割的新方法，通过几何对应将2D分割掩码传播到3D空间，并采用置信度和不确定性正则化来生成可靠的伪标签。


<details>
  <summary>Details</summary>
Motivation: 当前3D语义分割方法主要局限于3D域，未能充分利用2D和3D数据的互补性。同时，现有方法在利用稀疏标注和生成伪标签方面存在不足，无法充分处理标签噪声问题。

Method: 利用2D基础模型生成分割掩码，通过几何对应关系将2D分割结果传播到3D空间，扩展稀疏标注。采用置信度和不确定性一致性正则化选择可靠伪标签，并在3D掩码上进一步传播生成更多标签。

Result: 该方法有效弥合了有限3D标注与强大2D基础模型能力之间的差距，显著提高了3D弱监督分割的性能。

Conclusion: 通过整合2D基础模型的能力和3D几何信息，提出了一种创新的弱监督3D分割策略，能够最大化利用稀疏3D标注，提升分割效果。

Abstract: Current methods for 3D semantic segmentation propose training models with
limited annotations to address the difficulty of annotating large, irregular,
and unordered 3D point cloud data. They usually focus on the 3D domain only,
without leveraging the complementary nature of 2D and 3D data. Besides, some
methods extend original labels or generate pseudo labels to guide the training,
but they often fail to fully use these labels or address the noise within them.
Meanwhile, the emergence of comprehensive and adaptable foundation models has
offered effective solutions for segmenting 2D data. Leveraging this
advancement, we present a novel approach that maximizes the utility of sparsely
available 3D annotations by incorporating segmentation masks generated by 2D
foundation models. We further propagate the 2D segmentation masks into the 3D
space by establishing geometric correspondences between 3D scenes and 2D views.
We extend the highly sparse annotations to encompass the areas delineated by 3D
masks, thereby substantially augmenting the pool of available labels.
Furthermore, we apply confidence- and uncertainty-based consistency
regularization on augmentations of the 3D point cloud and select the reliable
pseudo labels, which are further spread on the 3D masks to generate more
labels. This innovative strategy bridges the gap between limited 3D annotations
and the powerful capabilities of 2D foundation models, ultimately improving the
performance of 3D weakly supervised segmentation.

</details>


### [80] [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts](https://arxiv.org/abs/2508.19944)
*Taebaek Hwang,Minseo Kim,Gisang Lee,Seonuk Kim,Hyunjun Eun*

Main category: cs.CV

TL;DR: KRETA是首个针对韩语的文本丰富视觉问答基准，填补了低资源语言在VLM评估方面的空白，包含多领域评估和自动化数据生成流程


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如韩语）在文本丰富视觉问答领域缺乏综合基准的问题，以便更好地评估和比较视觉语言模型

Method: 开发半自动化的VQA生成流程，采用逐步图像分解和七指标评估协议来确保数据质量，支持15个领域和26种图像类型的多维度评估

Result: 创建了KRETA基准数据集，为韩语文本丰富VQA提供了全面的评估框架，并建立了可扩展的基准生成管道

Conclusion: KRETA不仅填补了韩语文本VQA基准的空白，其可适应和可扩展的管道设计也有助于推动其他语言的多语言VLM研究发展

Abstract: Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

</details>


### [81] [Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework](https://arxiv.org/abs/2508.19946)
*Gianluca Guzzetta*

Main category: cs.CV

TL;DR: 本文对Chan-Vese图像分割算法进行了全面研究，提出了基于活动轮廓的功能性分割损失方法，并与传统损失函数进行了性能比较


<details>
  <summary>Details</summary>
Motivation: 研究Chan-Vese算法在图像分割中的应用，探索基于水平集和功能能量的现代计算机视觉分割方法

Method: 采用离散化方案分析Chan-Vese模型的功能能量和偏微分方程，基于pytorch.nn.ModuleLoss实现功能性分割损失，使用水平集方法

Result: 在常见计算机视觉分割数据集上进行了性能评估，与传统损失函数进行了对比分析

Conclusion: 提出的功能性分割损失方法在图像分割任务中表现出良好性能，为Chan-Vese算法在现代深度学习框架中的应用提供了有效实现

Abstract: In this paper, we present a comprehensive study and analysis of the Chan-Vese
algorithm for image segmentation. We employ a discretized scheme derived from
the empirical study of the Chan-Vese model's functional energy and its partial
differential equation based on its level set function. We provide a proof of
the results and an implementation using MATLAB. Leveraging modern computer
vision methodologies, we propose a functional segmentation loss based on active
contours, utilizing pytorch.nn.ModuleLoss and a level set based on the
Chan-Vese algorithm. We compare our results with common computer vision
segmentation datasets and evaluate the performance of classical loss functions
against our proposed method. All code and materials used are available at
https://github.com/gguzzy/chan_vese_functional_loss.

</details>


### [82] [Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models](https://arxiv.org/abs/2508.19967)
*Oliver Grainge,Sania Waheed,Jack Stilgoe,Michael Milford,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 本文对25种最先进的视觉语言模型在4个基准图像数据集上的地理定位能力进行全面评估，发现当前VLM在普通街景图像上表现不佳，但在类似社交媒体内容的图像上准确率高达61%，引发严重隐私担忧


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型(VLM)作为精确图像地理定位器的能力不断增强，带来了重大的隐私风险(如跟踪和监控)，但目前缺乏对这些生成式VLM地理定位精度的系统性评估

Method: 在四个不同环境拍摄的基准图像数据集上，对25种最先进的VLM进行全面的地理定位能力评估

Result: 当前VLM在普通街景图像上表现较差，但在类似社交媒体内容的图像上达到了61%的高准确率

Conclusion: 研究结果揭示了VLM的内部推理机制，突出了其优势、局限性以及潜在的社会风险，特别是对社交媒体内容的高精度地理定位能力引发了紧迫的隐私关切

Abstract: Geo-localization is the task of identifying the location of an image using
visual cues alone. It has beneficial applications, such as improving disaster
response, enhancing navigation, and geography education. Recently,
Vision-Language Models (VLMs) are increasingly demonstrating capabilities as
accurate image geo-locators. This brings significant privacy risks, including
those related to stalking and surveillance, considering the widespread uses of
AI models and sharing of photos on social media. The precision of these models
is likely to improve in the future. Despite these risks, there is little work
on systematically evaluating the geolocation precision of Generative VLMs,
their limits and potential for unintended inferences. To bridge this gap, we
conduct a comprehensive assessment of the geolocation capabilities of 25
state-of-the-art VLMs on four benchmark image datasets captured in diverse
environments. Our results offer insight into the internal reasoning of VLMs and
highlight their strengths, limitations, and potential societal risks. Our
findings indicate that current VLMs perform poorly on generic street-level
images yet achieve notably high accuracy (61\%) on images resembling social
media content, raising significant and urgent privacy concerns.

</details>


### [83] [Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices](https://arxiv.org/abs/2508.20064)
*Philippe Zhang,Weili Jiang,Yihao Li,Jing Zhang,Sarah Matta,Yubo Tan,Hui Lin,Haoshen Wang,Jiangtian Pan,Hui Xu,Laurent Borderie,Alexandre Le Guilcher,Béatrice Cochener,Chubin Ou,Gwenolé Quellec,Mathieu Lamard*

Main category: cs.CV

TL;DR: 该论文介绍了针对年龄相关性黄斑变性（AMD）进展监测的MARIO挑战赛中的两个任务解决方案，使用融合CNN网络和自编码器方法在OCT扫描中分类和预测疾病进展。


<details>
  <summary>Details</summary>
Motivation: 年龄相关性黄斑变性是影响视力的常见眼病，及时诊断和持续监测对于抗VEGF治疗的效果至关重要。通过跟踪OCT扫描中新生血管活动的进展，可以制定更个性化和有效的治疗方案。

Method: 任务1使用融合CNN网络和模型集成对连续OCT采集的2D切片对进行分类；任务2提出Patch Progression Masked Autoencoder，生成下一次检查的OCT图像，然后使用任务1的解决方案进行分类。

Result: 在两个任务中都取得了Top 10的成绩，但由于部分团队成员与挑战赛组织者属于同一组织，不符合获奖资格。

Conclusion: 提出的方法在AMD进展监测方面表现良好，融合CNN和自编码器技术为OCT图像分析和疾病进展预测提供了有效解决方案。

Abstract: Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting
visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments
have been effective in slowing the progression of neovascular AMD, with better
outcomes achieved through timely diagnosis and consistent monitoring. Tracking
the progression of neovascular activity in OCT scans of patients with exudative
AMD allows for the development of more personalized and effective treatment
plans. This was the focus of the Monitoring Age-related Macular Degeneration
Progression in Optical Coherence Tomography (MARIO) challenge, in which we
participated. In Task 1, which involved classifying the evolution between two
pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN
network with model ensembling to further enhance the model's performance. For
Task 2, which focused on predicting progression over the next three months
based on current exam data, we proposed the Patch Progression Masked
Autoencoder that generates an OCT for the next exam and then classifies the
evolution between the current OCT and the one generated using our solution from
Task 1. The results we achieved allowed us to place in the Top 10 for both
tasks. Some team members are part of the same organization as the challenge
organizers; therefore, we are not eligible to compete for the prize.

</details>


### [84] [GS: Generative Segmentation via Label Diffusion](https://arxiv.org/abs/2508.20020)
*Yuhao Chen,Shubin Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: GS（生成式分割）是一个新颖的框架，将分割任务重新定义为通过标签扩散的生成式任务，直接从噪声生成分割掩码，在语言驱动的图像分割任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的语言驱动图像分割方法主要采用判别式方法，而现有的扩散模型方法仍然以图像为中心，将分割作为辅助过程。本文旨在将分割本身作为主要的生成式建模目标。

Method: 提出GS框架，通过标签扩散将分割制定为生成式任务。直接从噪声生成分割掩码，同时以输入图像和语言描述为条件，实现端到端训练并保持空间和语义保真度。

Result: 在Panoptic Narrative Grounding（PNG）基准测试中，GS显著优于现有的判别式和基于扩散的方法，建立了语言驱动分割的新最先进水平。

Conclusion: 将分割重新定义为生成式任务的方法比传统的判别式方法和现有的扩散模型方法更有效，为语言驱动的图像分割提供了新的研究方向。

Abstract: Language-driven image segmentation is a fundamental task in vision-language
understanding, requiring models to segment regions of an image corresponding to
natural language expressions. Traditional methods approach this as a
discriminative problem, assigning each pixel to foreground or background based
on semantic alignment. Recently, diffusion models have been introduced to this
domain, but existing approaches remain image-centric: they either (i) use image
diffusion models as visual feature extractors, (ii) synthesize segmentation
data via image generation to train discriminative models, or (iii) perform
diffusion inversion to extract attention cues from pre-trained image diffusion
models-thereby treating segmentation as an auxiliary process. In this paper, we
propose GS (Generative Segmentation), a novel framework that formulates
segmentation itself as a generative task via label diffusion. Instead of
generating images conditioned on label maps and text, GS reverses the
generative process: it directly generates segmentation masks from noise,
conditioned on both the input image and the accompanying language description.
This paradigm makes label generation the primary modeling target, enabling
end-to-end training with explicit control over spatial and semantic fidelity.
To demonstrate the effectiveness of our approach, we evaluate GS on Panoptic
Narrative Grounding (PNG), a representative and challenging benchmark for
multimodal segmentation that requires panoptic-level reasoning guided by
narrative captions. Experimental results show that GS significantly outperforms
existing discriminative and diffusion-based methods, setting a new
state-of-the-art for language-driven segmentation.

</details>


### [85] [CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning](https://arxiv.org/abs/2508.20096)
*Zeyi Sun,Yuhang Cao,Jianze Liang,Qiushi Sun,Ziyu Liu,Zhixiong Zhang,Yuhang Zang,Xiaoyi Dong,Kai Chen,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: CODA是一个可训练的组合框架，通过两阶段训练流程整合通用规划器和专业执行器，在科学计算GUI任务中实现了长时程规划和精确执行的平衡，显著超越现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决GUI自主代理在科学计算等专业领域中长时程规划与精确执行之间的权衡问题，现有方法要么擅长规划但执行差，要么执行好但规划弱，且现有组合框架无法从经验中学习适应。

Method: 提出CODA框架，包含通用规划器Cerebrum和专业执行器Cerebellum。采用两阶段训练：1)专业化阶段-使用decoupled GRPO方法为每个科学应用单独训练专家规划器；2)泛化阶段-聚合成功轨迹进行监督微调，实现跨域泛化。

Result: 在ScienceBench基准的四个挑战性应用中，CODA显著超越所有基线方法，在开源模型中建立了新的最先进水平。

Conclusion: CODA通过可训练的组合框架成功解决了科学计算GUI任务中规划与执行的平衡问题，证明了其在稀缺高质量数据环境下的有效性和泛化能力。

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) face significant
challenges in specialized domains such as scientific computing, where both
long-horizon planning and precise execution are required. Existing approaches
suffer from a trade-off: generalist agents excel at planning but perform poorly
in execution, while specialized agents demonstrate the opposite weakness.
Recent compositional frameworks attempt to bridge this gap by combining a
planner and an actor, but they are typically static and non-trainable, which
prevents adaptation from experience. This is a critical limitation given the
scarcity of high-quality data in scientific domains. To address these
limitations, we introduce CODA, a novel and trainable compositional framework
that integrates a generalist planner (Cerebrum) with a specialist executor
(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,
Specialization, we apply a decoupled GRPO approach to train an expert planner
for each scientific application individually, bootstrapping from a small set of
task trajectories. In the second stage, Generalization, we aggregate all
successful trajectories from the specialized experts to build a consolidated
dataset, which is then used for supervised fine-tuning of the final planner.
This equips CODA with both robust execution and cross-domain generalization.
Evaluated on four challenging applications from the ScienceBoard benchmark,
CODA significantly outperforms baselines and establishes a new state of the art
among open-source models.

</details>


### [86] [Segmentation Assisted Incremental Test Time Adaptation in an Open World](https://arxiv.org/abs/2508.20029)
*Manogna Sreenivas,Soma Biswas*

Main category: cs.CV

TL;DR: 提出SegAssist框架，用于视觉语言模型的增量测试时适应，通过分割辅助主动标注技术处理测试时出现的新类别和新域


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中部署模型遇到未知类别和分布偏移时的泛化问题，传统测试时适应方法无法处理持续出现的新类别

Method: 结合单图像TTA方法和主动标注技术，提出SegAssist模块（训练免费），利用VLM的分割能力精炼主动样本选择，优先选择可能属于未见类别的样本

Result: 在多个基准数据集上的广泛实验表明SegAssist能有效提升VLM在需要持续适应新兴数据的真实场景中的性能

Conclusion: SegAssist框架为视觉语言模型在动态环境中的增量适应提供了有效解决方案，通过利用模型固有分割能力实现更好的未知类别识别

Abstract: In dynamic environments, unfamiliar objects and distribution shifts are often
encountered, which challenge the generalization abilities of the deployed
trained models. This work addresses Incremental Test Time Adaptation of Vision
Language Models, tackling scenarios where unseen classes and unseen domains
continuously appear during testing. Unlike traditional Test Time Adaptation
approaches, where the test stream comes only from a predefined set of classes,
our framework allows models to adapt simultaneously to both covariate and label
shifts, actively incorporating new classes as they emerge. Towards this goal,
we establish a new benchmark for ITTA, integrating single image TTA methods for
VLMs with active labeling techniques that query an oracle for samples
potentially representing unseen classes during test time. We propose a
segmentation assisted active labeling module, termed SegAssist, which is
training free and repurposes the segmentation capabilities of VLMs to refine
active sample selection, prioritizing samples likely to belong to unseen
classes. Extensive experiments on several benchmark datasets demonstrate the
potential of SegAssist to enhance the performance of VLMs in real world
scenarios, where continuous adaptation to emerging data is essential.
Project-page:https://manogna-s.github.io/segassist/

</details>


### [87] [OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations](https://arxiv.org/abs/2508.20063)
*Peng-Hao Hsu,Ke Zhang,Fu-En Wang,Tao Tu,Ming-Feng Li,Yu-Lun Liu,Albert Y. C. Chen,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: OpenM3D是一个无需人工标注的开放词汇多视角室内3D目标检测器，通过2D诱导体素特征和CLIP特征对齐实现高效检测


<details>
  <summary>Details</summary>
Motivation: 开放词汇3D目标检测领域主要基于3D点云方法，基于图像的方法探索有限，需要开发无需人工标注的高效检测方案

Method: 采用单阶段检测器架构，结合2D诱导体素特征、类无关3D定位损失和体素语义对齐损失，使用图嵌入技术生成高质量3D伪框

Result: 在ScanNet200和ARKitScenes基准测试中实现了优越的准确性和速度（每场景0.3秒），超越了现有的两阶段方法

Conclusion: OpenM3D证明了无需人工标注的开放词汇3D检测的可行性，在准确性和效率方面均优于现有方法

Abstract: Open-vocabulary (OV) 3D object detection is an emerging field, yet its
exploration through image-based methods remains limited compared to 3D point
cloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view
indoor 3D object detector trained without human annotations. In particular,
OpenM3D is a single-stage detector adapting the 2D-induced voxel features from
the ImGeoNet model. To support OV, it is jointly trained with a class-agnostic
3D localization loss requiring high-quality 3D pseudo boxes and a
voxel-semantic alignment loss requiring diverse pre-trained CLIP features. We
follow the training setting of OV-3DET where posed RGB-D images are given but
no human annotations of 3D boxes or classes are available. We propose a 3D
Pseudo Box Generation method using a graph embedding technique that combines 2D
segments into coherent 3D structures. Our pseudo-boxes achieve higher precision
and recall than other methods, including the method proposed in OV-3DET. We
further sample diverse CLIP features from 2D segments associated with each
coherent 3D structure to align with the corresponding voxel feature. The key to
training a highly accurate single-stage detector requires both losses to be
learned toward high-quality targets. At inference, OpenM3D, a highly efficient
detector, requires only multi-view images for input and demonstrates superior
accuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor
benchmarks compared to existing methods. We outperform a strong two-stage
method that leverages our class-agnostic detector with a ViT CLIP-based OV
classifier and a baseline incorporating multi-view depth estimator on both
accuracy and speed.

</details>


### [88] [PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence](https://arxiv.org/abs/2508.20066)
*Zheng Li,Yanming Guo,WenZhe Liu,Xueyi Zhang,Zhaoyun Ding,Long Xu,Mingrui Lao*

Main category: cs.CV

TL;DR: 该文章提出PAUL框架来解决跨视角地理定位中的噪声对应问题，通过不确定性学习进行数据分区和增强，在各种噪声比下都取得了更优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨视角地理定位方法假设训练图像对完美对齐，但实际应用中GPS偏移等因素导致系统对齐偏移，仅存在部分对应关系，很少研究关注这种噪声对应问题。

Method: 提出PAUL框架，通过不确定性感知的协同增强和准据协同训练来估计数据不确定性，对训练数据进行分区和增强。选择性地增强高对应信心度区域，利用不确定性估计精炼特征学习，有效抑制错位对的噪声。

Result: 综合实验验证了PAUL各个组成部分的有效性，在各种噪声比下都一质地超越了其他竞争性的噪声对应驱动方法。

Conclusion: PAUL框架有效解决了跨视角地理定位中的噪声对应问题，接近了理想化基准测试与实际应用之间的差距，为实际应用提供了稳健的监督。

Abstract: Cross-view geo-localization is a critical task for UAV navigation, event
detection, and aerial surveying, as it enables matching between drone-captured
and satellite imagery. Most existing approaches embed multi-modal data into a
joint feature space to maximize the similarity of paired images. However, these
methods typically assume perfect alignment of image pairs during training,
which rarely holds true in real-world scenarios. In practice, factors such as
urban canyon effects, electromagnetic interference, and adverse weather
frequently induce GPS drift, resulting in systematic alignment shifts where
only partial correspondences exist between pairs. Despite its prevalence, this
source of noisy correspondence has received limited attention in current
research. In this paper, we formally introduce and address the Noisy
Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to
bridge the gap between idealized benchmarks and practical applications. To this
end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a
novel framework that partitions and augments training data based on estimated
data uncertainty through uncertainty-aware co-augmentation and evidential
co-training. Specifically, PAUL selectively augments regions with high
correspondence confidence and utilizes uncertainty estimation to refine feature
learning, effectively suppressing noise from misaligned pairs. Distinct from
traditional filtering or label correction, PAUL leverages both data uncertainty
and loss discrepancy for targeted partitioning and augmentation, thus providing
robust supervision for noisy samples. Comprehensive experiments validate the
effectiveness of individual components in PAUL,which consistently achieves
superior performance over other competitive noisy-correspondence-driven methods
in various noise ratios.

</details>


### [89] [Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors](https://arxiv.org/abs/2508.20089)
*Ross J Gardiner,Guillaume Mougeot,Sareh Rowlands,Benno I Simmons,Flemming Helsing,Toke Thomas Høye*

Main category: cs.CV

TL;DR: 提出轻量级分类方法，结合专家标注数据和BioCLIP2知识蒸馏，在丹麦蛾类识别中实现高精度且计算成本低


<details>
  <summary>Details</summary>
Motivation: 解决自动化相机系统拍摄的蛾类图像识别难题，克服策划图像与野外图像之间的域偏移问题

Method: 使用有限专家标注的野外数据，通过知识蒸馏将高性能BioCLIP2基础模型压缩到ConvNeXt-tiny架构中

Result: 在101种丹麦蛾类上实验显示，BioCLIP2显著优于其他方法，蒸馏后的轻量模型在保持精度的同时大幅降低计算成本

Conclusion: 为高效昆虫监测系统开发提供实用指导，弥合细粒度分类的域差距

Abstract: Labelling images of Lepidoptera (moths) from automated camera systems is
vital for understanding insect declines. However, accurate species
identification is challenging due to domain shifts between curated images and
noisy field imagery. We propose a lightweight classification approach,
combining limited expert-labelled field data with knowledge distillation from
the high-performance BioCLIP2 foundation model into a ConvNeXt-tiny
architecture. Experiments on 101 Danish moth species from AMI camera systems
demonstrate that BioCLIP2 substantially outperforms other methods and that our
distilled lightweight model achieves comparable accuracy with significantly
reduced computational cost. These insights offer practical guidelines for the
development of efficient insect monitoring systems and bridging domain gaps for
fine-grained classification.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [90] [MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks](https://arxiv.org/abs/2508.19251)
*Qian Liang,Menghaoran Tang,Yi Zeng*

Main category: cs.SD

TL;DR: MuSpike是首个针对脉冲神经网络(SNN)在符号音乐生成领域的统一基准测试和评估框架，系统评估了5种代表性SNN架构在5个数据集上的表现，结合客观指标和大规模听感研究，揭示了主客观评估之间的不一致性。


<details>
  <summary>Details</summary>
Motivation: 符号音乐生成在人工神经网络领域进展迅速，但在生物可解释的脉冲神经网络(SNN)领域仍缺乏标准化基准测试和全面评估方法，需要建立系统性的评估框架。

Method: 引入MuSpike基准框架，系统评估5种代表性SNN架构(SNN-CNN、SNN-RNN、SNN-LSTM、SNN-GAN、SNN-Transformer)在5个典型数据集上的表现，结合客观指标和大规模听感研究，提出新的主观评估指标。

Result: 研究发现：(1)不同SNN模型在不同评估维度上表现出不同优势；(2)不同音乐背景的参与者表现出不同的感知模式，专家对AI创作音乐更宽容；(3)客观和主观评估存在明显不一致，凸显纯统计指标的局限性。

Conclusion: MuSpike为SNN模型在符号音乐生成领域提供了首个系统性基准和评估框架，为未来生物可解释和认知基础的音乐生成研究奠定了坚实基础。

Abstract: Symbolic music generation has seen rapid progress with artificial neural
networks, yet remains underexplored in the biologically plausible domain of
spiking neural networks (SNNs), where both standardized benchmarks and
comprehensive evaluation methods are lacking. To address this gap, we introduce
MuSpike, a unified benchmark and evaluation framework that systematically
assesses five representative SNN architectures (SNN-CNN, SNN-RNN, SNN-LSTM,
SNN-GAN and SNN-Transformer) across five typical datasets, covering tonal,
structural, emotional, and stylistic variations. MuSpike emphasizes
comprehensive evaluation, combining established objective metrics with a
large-scale listening study. We propose new subjective metrics, targeting
musical impression, autobiographical association, and personal preference, that
capture perceptual dimensions often overlooked in prior work. Results reveal
that (1) different SNN models exhibit distinct strengths across evaluation
dimensions; (2) participants with different musical backgrounds exhibit diverse
perceptual patterns, with experts showing greater tolerance toward AI-composed
music; and (3) a noticeable misalignment exists between objective and
subjective evaluations, highlighting the limitations of purely statistical
metrics and underscoring the value of human perceptual judgment in assessing
musical quality. MuSpike provides the first systematic benchmark and systemic
evaluation framework for SNN models in symbolic music generation, establishing
a solid foundation for future research into biologically plausible and
cognitively grounded music generation.

</details>


### [91] [Beat-Based Rhythm Quantization of MIDI Performances](https://arxiv.org/abs/2508.19262)
*Maximilian Wachter,Sebastian Murgul,Michael Heizmann*

Main category: cs.SD

TL;DR: 基于Transformer的节奏量化模型，利用节拍和强拍信息将MIDI演奏量化为符合节拍的人类可读乐谱，在MUSTER指标上达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 将MIDI演奏数据转换为符合音乐节拍结构的可读乐谱需要准确的节奏量化，传统方法存在局限性，需要更先进的模型来处理这一任务

Method: 提出基于节拍的预处理方法，将乐谱和演奏数据转换为统一的token表示；采用Transformer架构，针对钢琴和吉他演奏进行优化训练

Result: 模型在MUSTER评估指标上超越了现有最先进的方法，表现出优异的量化性能

Conclusion: 该Transformer-based节奏量化模型成功整合了节拍信息，为MIDI演奏到可读乐谱的转换提供了有效的解决方案

Abstract: We propose a transformer-based rhythm quantization model that incorporates
beat and downbeat information to quantize MIDI performances into
metrically-aligned, human-readable scores. We propose a beat-based
preprocessing method that transfers score and performance data into a unified
token representation. We optimize our model architecture and data
representation and train on piano and guitar performances. Our model exceeds
state-of-the-art performance based on the MUSTER metric.

</details>


### [92] [Infant Cry Detection In Noisy Environment Using Blueprint Separable Convolutions and Time-Frequency Recurrent Neural Network](https://arxiv.org/abs/2508.19308)
*Haolin Yu,Yanxiong Li*

Main category: cs.SD

TL;DR: 这篇论文提出了一种轻量级且稳健的婴儿哭声检测方法，通过蓝图可分卷积和时频递归网络降低计算复杂度并实现适应性去噪，在多种噪声条件下都取得了超过现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 婴儿哭声检测是宝宝护理系统的关键组成部分，需要一种轻量级且在实际环境中稳健的检测方法来应对复杂的噪声场景。

Method: 采用多尺度卷积递归网络框架，结合蓝图可分卷积降低计算复杂度，以及时频递归网络进行适应性去噪。添加高效空间注意力机制和对比感知通道注意力模块，从log Mel-谱图特征中获取局部和全局信息。使用环境污染技术生成实际场景中的噪声样本。

Result: 在多种信噪比条件下，该方法在准确率、F1分数和复杂度方面都超过了许多现有最先进方法。

Conclusion: 该研究提供了一种高效的婴儿哭声检测方案，具有轻量化、高准确率和良好的噪声耐受性，适用于实际应用环境。

Abstract: Infant cry detection is a crucial component of baby care system. In this
paper, we propose a lightweight and robust method for infant cry detection. The
method leverages blueprint separable convolutions to reduce computational
complexity, and a time-frequency recurrent neural network for adaptive
denoising. The overall framework of the method is structured as a multi-scale
convolutional recurrent neural network, which is enhanced by efficient spatial
attention mechanism and contrast-aware channel attention module, and acquire
local and global information from the input feature of log Mel-spectrogram.
Multiple public datasets are adopted to create a diverse and representative
dataset, and environmental corruption techniques are used to generate the noisy
samples encountered in real-world scenarios. Results show that our method
exceeds many state-of-the-art methods in accuracy, F1-score, and complexity
under various signal-to-noise ratio conditions. The code is at
https://github.com/fhfjsd1/ICD_MMSP.

</details>


### [93] [MQAD: A Large-Scale Question Answering Dataset for Training Music Large Language Models](https://arxiv.org/abs/2508.19514)
*Zhihao Ouyang,Ju-Chiang Wang,Daiyu Zhang,Bin Chen,Shangjie Li,Quan Lin*

Main category: cs.SD

TL;DR: MQAD是一个基于百万歌曲数据集构建的大规模音乐问答数据集，包含27万首歌曲、近300万个多样化问题和描述，涵盖节拍、和弦、调性、结构、乐器和流派等丰富音乐特征。


<details>
  <summary>Details</summary>
Motivation: 音乐问答是人类理解音乐的自然方式，但机器需要大规模多样化音乐数据集，而这类公开数据稀缺，因此需要构建专门的数据集来支持音乐理解和分析。

Method: 利用专业音乐信息检索模型提取高级音乐特征，使用大语言模型生成自然语言问答对，并构建融合LLaMA2和Whisper架构的多模态大语言模型进行评估。

Result: 在MQAD上训练的模型相比传统音乐音频描述方法取得了进步，证明了数据集的有效性和实用性。

Conclusion: MQAD数据集为音乐理解和分析提供了重要资源，其包含的时变音乐信息（如和弦和段落）有助于探索音乐的内在结构，推动了音乐AI研究的发展。

Abstract: Question-answering (QA) is a natural approach for humans to understand a
piece of music audio. However, for machines, accessing a large-scale dataset
covering diverse aspects of music is crucial, yet challenging, due to the
scarcity of publicly available music data of this type. This paper introduces
MQAD, a music QA dataset built on the Million Song Dataset (MSD), encompassing
a rich array of musical features, including beat, chord, key, structure,
instrument, and genre -- across 270,000 tracks, featuring nearly 3 million
diverse questions and captions. MQAD distinguishes itself by offering detailed
time-varying musical information such as chords and sections, enabling
exploration into the inherent structure of music within a song. To compile
MQAD, our methodology leverages specialized Music Information Retrieval (MIR)
models to extract higher-level musical features and Large Language Models
(LLMs) to generate natural language QA pairs. Then, we leverage a multimodal
LLM that integrates the LLaMA2 and Whisper architectures, along with novel
subjective metrics to assess the performance of MQAD. In experiments, our model
trained on MQAD demonstrates advancements over conventional music audio
captioning approaches. The dataset and code are available at
https://github.com/oyzh888/MQAD.

</details>


### [94] [CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation](https://arxiv.org/abs/2508.19603)
*Zhejing Hu,Yan Liu,Gong Chen,Bruce X. B. Yu*

Main category: cs.SD

TL;DR: 本文提出了一个自动音乐词典构建模型CompLex，通过少量手动输入生成包含37,432个条目的音乐词典，显著提升了三个最先进的文本到音乐生成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前音乐生成AI受限于音乐数据稀缺，而基于知识的方���已被证明能提升模型性能。传统音乐生成任务如算法作曲和风格转换需要大量人工努力，需要利用全面的音乐理论来改进AI音乐生成。

Method: 提出新颖的自动音乐词典构建模型，仅需9个手动输入类别关键词和5个句子提示模板即可生成CompLex词典。开发新的多智能体算法来自动检测和缓解幻觉问题。

Result: CompLex在三个最先进的文本到音乐生成模型（包括符号和音频方法）上都表现出显著的性能提升。词典在完整性、准确性、非冗余性和可执行性方面均表现优异。

Conclusion: CompLex具备有效词典的关键特性，能够显著提升音乐生成模型的性能，为AI驱动的音乐生成任务提供了强大的知识支持。

Abstract: Generative artificial intelligence in music has made significant strides, yet
it still falls short of the substantial achievements seen in natural language
processing, primarily due to the limited availability of music data.
Knowledge-informed approaches have been shown to enhance the performance of
music generation models, even when only a few pieces of musical knowledge are
integrated. This paper seeks to leverage comprehensive music theory in
AI-driven music generation tasks, such as algorithmic composition and style
transfer, which traditionally require significant manual effort with existing
techniques. We introduce a novel automatic music lexicon construction model
that generates a lexicon, named CompLex, comprising 37,432 items derived from
just 9 manually input category keywords and 5 sentence prompt templates. A new
multi-agent algorithm is proposed to automatically detect and mitigate
hallucinations. CompLex demonstrates impressive performance improvements across
three state-of-the-art text-to-music generation models, encompassing both
symbolic and audio-based methods. Furthermore, we evaluate CompLex in terms of
completeness, accuracy, non-redundancy, and executability, confirming that it
possesses the key characteristics of an effective lexicon.

</details>


### [95] [The IRMA Dataset: A Structured Audio-MIDI Corpus for Iranian Classical Music](https://arxiv.org/abs/2508.19876)
*Sepideh Shafiei,Shapour Hakam*

Main category: cs.SD

TL;DR: IRMA数据集是一个多层次的开放获取语料库，专门用于伊朗古典音乐的计算研究，包含符号MIDI表示、音频-MIDI对齐、音乐学转录和理论信息比较表。


<details>
  <summary>Details</summary>
Motivation: 为伊朗古典音乐特别是radif（模态旋律单元的结构化曲目）的计算研究提供全面的多模态数据集，支持民族音乐学、教学法和AI驱动的音乐分析任务。

Method: 采用多阶段构建过程，包括片段标注、对齐方法和结构化标识符编码系统，结合符号MIDI、音频对齐、PDF转录和理论比较表格。

Result: 数据集包含Karimi的完整radif、Mirza Abdollah的radif MIDI文件和元数据、Davami声乐radif的精选片段，以及20世纪著名歌唱家的tahrir装饰音音频-MIDI示例。

Conclusion: 该数据集既是学术档案又是计算分析资源，支持民族音乐学、文化遗产保护和AI音乐任务，采用开放获取许可（CC BY-NC 4.0），欢迎合作反馈以进一步完善。

Abstract: We present the IRMA Dataset (Iranian Radif MIDI Audio), a multi-level,
open-access corpus designed for the computational study of Iranian classical
music, with a particular emphasis on the radif, a structured repertoire of
modal-melodic units central to pedagogy and performance. The dataset combines
symbolic MIDI representations, phrase-level audio-MIDI alignment, musicological
transcriptions in PDF format, and comparative tables of theoretical information
curated from a range of performers and scholars. We outline the multi-phase
construction process, including segment annotation, alignment methods, and a
structured system of identifier codes to reference individual musical units.
The current release includes the complete radif of Karimi; MIDI files and
metadata from Mirza Abdollah's radif; selected segments from the vocal radif of
Davami, as transcribed by Payvar and Fereyduni; and a dedicated section
featuring audio-MIDI examples of tahrir ornamentation performed by prominent
20th-century vocalists. While the symbolic and analytical components are
released under an open-access license (CC BY-NC 4.0), some referenced audio
recordings and third-party transcriptions are cited using discographic
information to enable users to locate the original materials independently,
pending copyright permission. Serving both as a scholarly archive and a
resource for computational analysis, this dataset supports applications in
ethnomusicology, pedagogy, symbolic audio research, cultural heritage
preservation, and AI-driven tasks such as automatic transcription and music
generation. We welcome collaboration and feedback to support its ongoing
refinement and broader integration into musicological and machine learning
workflows.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [96] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: 本文提出将LLM中的奉承行为建模为心理测量特质的几何和因果组合，使用对比激活加法(CAA)将激活方向映射到这些因素，并研究不同组合如何导致奉承行为，从而实现可解释的向量干预。


<details>
  <summary>Details</summary>
Motivation: 奉承行为是LLM中的关键行为风险，但通常被当作孤立的故障模式处理。作者认为应该将其建模为心理测量特质（如情绪性、开放性和宜人性）的组合，类似于心理测量学中的因子分解。

Method: 使用对比激活加法(CAA)将激活方向映射到心理测量因素，研究不同特质组合（如高外向性结合低尽责性）如何导致奉承行为，并提出可组合的向量干预方法。

Result: 该方法允许进行可解释和可组合的基于向量的干预，如加法、减法和投影，这些干预可用于减轻LLM中的安全关键行为。

Conclusion: 通过将奉承行为建模为心理测量特质的几何和因果组合，提供了更深入的理解和更有效的干预方法，有助于提高LLM的安全性。

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [97] [Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science](https://arxiv.org/abs/2508.19383)
*Daoyuan Jin,Nick Gunner,Niko Carvajal Janke,Shivranjani Baruah,Kaitlin M. Gold,Yu Jiang*

Main category: cs.AI

TL;DR: Aleks是一个AI驱动的多智能体系统，用于自主进行植物科学数据驱动的科学发现，在葡萄藤红斑病案例中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现代植物科学依赖大型异构数据集，但实验设计、数据预处理和可重复性方面的挑战阻碍了研究效率。

Method: 开发了Aleks多智能体系统，整合领域知识、数据分析和机器学习，能够自主制定问题、探索建模策略并迭代优化解决方案。

Result: 在葡萄藤红斑病案例研究中，Aleks逐步识别出具有生物学意义的特征，并收敛到具有稳健性能的可解释模型。消融研究强调了领域知识和记忆的重要性。

Conclusion: 这项工作展示了智能体AI作为自主协作者在加速植物科学发现方面的潜力。

Abstract: Modern plant science increasingly relies on large, heterogeneous datasets,
but challenges in experimental design, data preprocessing, and reproducibility
hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent
system that integrates domain knowledge, data analysis, and machine learning
within a structured framework to autonomously conduct data-driven scientific
discovery. Once provided with a research question and dataset, Aleks
iteratively formulated problems, explored alternative modeling strategies, and
refined solutions across multiple cycles without human intervention. In a case
study on grapevine red blotch disease, Aleks progressively identified
biologically meaningful features and converged on interpretable models with
robust performance. Ablation studies underscored the importance of domain
knowledge and memory for coherent outcomes. This exploratory work highlights
the promise of agentic AI as an autonomous collaborator for accelerating
scientific discovery in plant sciences.

</details>


### [98] [Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs](https://arxiv.org/abs/2508.19432)
*Yao Fu,Xianxuan Long,Runchao Li,Haotian Yu,Mu Sheng,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.AI

TL;DR: 量化技术虽然能保持LLMs在困惑度和零样本任务上的性能，但其对模型真实性（生成真实或欺骗性回答）的影响尚未充分研究。研究发现量化模型内部保持真实表示，但在误导性提示下更容易产生虚假输出。


<details>
  <summary>Details</summary>
Motivation: 量化技术能显著降低大语言模型的内存和计算成本，使其在资源受限环境中高效部署，但量化对模型真实性的影响尚未被充分探索。

Method: 提出了TruthfulnessEval评估框架，从三个维度评估量化LLMs的真实性：逻辑推理真实性、常识真实性和模仿性虚假真实性。测试了主流量化技术（4位到极端2位）和多种开源LLM，使用15种重新表述的提示变体进行测试。

Result: 量化模型内部保持真实表示，但在误导性提示下更容易产生虚假输出。"欺骗性"提示可以覆盖真实一致行为，而"诚实"和"中性"提示保持稳定输出。量化模型内部"知道"真相，但在"欺骗性"提示引导下仍会产生虚假输出。

Conclusion: 研究结果为未来量化感知对齐和真实性干预的设计提供了见解，揭示了量化模型在真实性方面的脆弱性，需要针对性的改进措施。

Abstract: Quantization enables efficient deployment of large language models (LLMs) in
resource-constrained environments by significantly reducing memory and
computation costs. While quantized LLMs often maintain performance on
perplexity and zero-shot tasks, their impact on truthfulness-whether generating
truthful or deceptive responses-remains largely unexplored. In this work, we
introduce TruthfulnessEval, a comprehensive evaluation framework for assessing
the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on
Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on
Imitative Falsehoods. Using this framework, we examine mainstream quantization
techniques (ranging from 4-bit to extreme 2-bit) across several open-source
LLMs. Surprisingly, we find that while quantized models retain internally
truthful representations, they are more susceptible to producing false outputs
under misleading prompts. To probe this vulnerability, we test 15 rephrased
variants of "honest", "neutral" and "deceptive" prompts and observe that
"deceptive" prompts can override truth-consistent behavior, whereas "honest"
and "neutral" prompts maintain stable outputs. Further, we reveal that
quantized models "know" the truth internally yet still produce false outputs
when guided by "deceptive" prompts via layer-wise probing and PCA
visualizations. Our findings provide insights into future designs of
quantization-aware alignment and truthfulness interventions.

</details>


### [99] [Reliable Weak-to-Strong Monitoring of LLM Agents](https://arxiv.org/abs/2508.19461)
*Neil Kale,Chen Bo Calvin Zhang,Kevin Zhu,Ankit Aich,Paula Rodriguez,Scale Red Team,Christina Q. Knight,Zifan Wang*

Main category: cs.AI

TL;DR: 本文系统化了监控系统红队测试(MRT)流程，通过测试LLM自主代理的秘密恶意行为检测能力，发现代理的监控知惃情况对监控效果有显著影响，而混合式架构能让弱模型监控强模型。


<details>
  <summary>Details</summary>
Motivation: 测试自主LLM代理监控系统的对抗程度，检测秘密恶意行为（如泄漏私人信息）的能力缺口。

Method: 构建MRT流程，包括：不同情况知识级别、避免监控的对抗策略、两个数据集环境（SHADE-Arena和CUA-SHADE-Arena），以及新的混合层次-序列架构。

Result: 1、代理知惃监控的情况会显著降低监控可靠性；2、监控架构比监控知识更重要，混合架构能让弱模型监控强模型；3、人类参与的目标监督最有效。

Conclusion: 建立了MRT标准流程，显示了LLM和人类在监控代理恶意行为时的对抗脏性不足。

Abstract: We stress test monitoring systems for detecting covert misbehavior in
autonomous LLM agents (e.g., secretly sharing private information). To this
end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)
varying levels of agent and monitor situational awareness; (2) distinct
adversarial strategies to evade the monitor, such as prompt injection; and (3)
two datasets and environments -- SHADE-Arena for tool-calling agents and our
new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We
run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse
agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding
proposed in this work. Our empirical results yield three key findings. First,
agent awareness dominates monitor awareness: an agent's knowledge that it is
being monitored substantially degrades the monitor's reliability. On the
contrary, providing the monitor with more information about the agent is less
helpful than expected. Second, monitor scaffolding matters more than monitor
awareness: the hybrid scaffolding consistently outperforms baseline monitor
scaffolding, and can enable weaker models to reliably monitor stronger agents
-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where
humans discuss with the LLM monitor to get an updated judgment for the agent's
behavior, targeted human oversight is most effective; escalating only
pre-flagged cases to human reviewers improved the TPR by approximately 15% at
FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the
lack of adversarial robustness for LLMs and humans when monitoring and
detecting agent misbehavior. We release code, data, and logs to spur further
research.

</details>


### [100] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: SWIRL是一个用于多智能体系统的分阶段强化学习工作流，将MARL重新表述为一系列单智能体强化学习任务，每次更新一个智能体而保持其他智能体固定，实现了稳定训练和高效协调。


<details>
  <summary>Details</summary>
Motivation: 现有的单智能体方法在移动GUI代理中存在结构限制，而多智能体强化学习(MARL)方法效率低下且与当前大型视觉语言模型架构不兼容，需要一种新的训练框架来解决这些问题。

Method: SWIRL采用分阶段交错强化学习方法，将MARL分解为顺序的单智能体强化学习任务。在移动GUI控制中实例化为导航器（将语言和屏幕上下文转换为结构化计划）和交互器（将计划转换为可执行原子动作）。

Result: 在GUI基准测试中表现出优越性能，同时在多智能体数学推理任务中也展现出强大能力，证明了其作为开发高效鲁棒多智能体系统通用框架的潜力。

Conclusion: SWIRL提供了一个理论上有保障的、稳定的多智能体训练框架，能够有效解决现有MARL方法的效率问题，并在实际应用中展现出卓越的性能和泛化能力。

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>


### [101] [SLIM: Subtrajectory-Level Elimination for More Effective Reasoning](https://arxiv.org/abs/2508.19502)
*Xifeng Yao,Chengyuan Ma,Dongyu Lang,Yinhao Ni,Zhiwei Xu,Huarui Xie,Zihao Chen,Guang Shen,Dandan Tu,Yi Bai,Changzheng Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种"5+2"框架来识别和消除大语言模型推理轨迹中的次优子轨迹，通过选择性数据采样提升模型性能，在减少25.9%次优子轨迹的同时，用更少训练数据达到更高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在复杂推理时生成长推理轨迹，但研究发现并非所有轨迹成分都对推理有益，有些甚至负面影响整体性能，因此需要系统性地识别和消除次优推理子轨迹。

Method: 开发"5+2"框架：1）基于5个人工标准识别推理轨迹中的次优子轨迹；2）评估这些子轨迹的独立性以确保移除不影响整体连贯性；使用采样算法选择无次优子轨迹的数据进行训练。

Result: 方法在推理时减少25.9%次优子轨迹，仅用三分之二训练数据就在高难度数学基准上达到58.92%平均准确率，超越完整数据的58.06%，并在不同推理token限制下均表现更优。

Conclusion: 选择性移除推理轨迹中的次优成分能有效提升模型性能，证明并非所有推理步骤都有益，精心筛选训练数据可以带来更好的效果和效率。

Abstract: In recent months, substantial progress has been made in complex reasoning of
Large Language Models, particularly through the application of test-time
scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When
responding to a query, these models generate an extended reasoning trajectory,
during which the model explores, reflects, backtracks, and self-verifies before
arriving at a conclusion. However, fine-tuning models with such reasoning
trajectories may not always be optimal. Our findings indicate that not all
components within these reasoning trajectories contribute positively to the
reasoning process; in fact, some components may affect the overall performance
negatively. In this study, we divide a reasoning trajectory into individual
subtrajectories and develop a "5+2" framework to: (1) systematically identify
suboptimal subtrajectories within the reasoning trajectory based on five
human-established criteria; (2) assess the independence of the suboptimal
subtrajectories identified in (1) from the subsequent content, ensuring that
their elimination does not compromise overall flow and coherence of the
reasoning process. Additionally, a sampling algorithm, built upon the "5+2"
framework, is employed to select data whose reasoning process is free from
suboptimal subtrajectories to the highest degree. Experimental results
demonstrate that our method can reduce the number of suboptimal subtrajectories
by 25.9\% during the inference. Furthermore, our method achieves an average
accuracy of 58.92\% on highly challenging math benchmarks with only two thirds
of training data, surpassing the average accuracy of 58.06\% achieved with the
entire data, and outperforming open-source datasets, when fine-tuning
Qwen2.5-Math-7B. Finally, We validated our method under resource constraints
and observed improved performance across various inference token limits.

</details>


### [102] [Caught in the Act: a mechanistic approach to detecting deception](https://arxiv.org/abs/2508.19505)
*Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval*

Main category: cs.AI

TL;DR: 线性探针可以高精度检测LLM生成回答中的欺骗性，在7B以上参数模型中准确率可达70-90%，欺骗编码存在多个线性方向


<details>
  <summary>Details</summary>
Motivation: 开发类似汽车"检查引擎"灯的AI系统校准指标，通过检测LLM生成回答中的欺骗性来识别与人类价值观的偏差

Method: 在LLM内部激活上使用线性探针技术，分析不同层级的欺骗检测准确率，并采用迭代零空间投影方法识别欺骗编码的线性方向

Result: 小模型(1.5B)检测准确率接近随机，大模型(>7B)达到70-80%，推理变体超过90%；欺骗编码方向数量从20个(Qwen 3B)到近100个(DeepSeek 7B和Qwen 14B)

Conclusion: 线性探针能有效检测LLM欺骗行为，欺骗编码呈现多层分布模式，为AI系统校准提供了可行的技术路径

Abstract: Sophisticated instrumentation for AI systems might have indicators that
signal misalignment from human values, not unlike a "check engine" light in
cars. One such indicator of misalignment is deceptiveness in generated
responses. Future AI instrumentation may have the ability to detect when an LLM
generates deceptive responses while reasoning about seemingly plausible but
incorrect answers to factual questions. In this work, we demonstrate that
linear probes on LLMs internal activations can detect deception in their
responses with extremely high accuracy. Our probes reach a maximum of greater
than 90% accuracy in distinguishing between deceptive and non-deceptive
arguments generated by llama and qwen models ranging from 1.5B to 14B
parameters, including their DeepSeek-r1 finetuned variants. We observe that
probes on smaller models (1.5B) achieve chance accuracy at detecting deception,
while larger models (greater than 7B) reach 70-80%, with their reasoning
counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage
pattern across layers: near-random (50%) in early layers, peaking in middle
layers, and slightly declining in later layers. Furthermore, using an iterative
null space projection approach, we find multitudes of linear directions that
encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and
Qwen 14B models.

</details>


### [103] [Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities](https://arxiv.org/abs/2508.19562)
*Trisanth Srinivasan,Santosh Patapati*

Main category: cs.AI

TL;DR: 本文介绍了Democracy-in-Silico模拟系统，使用具有复杂心理特征的AI代理在不同制度框架下进行自治实验，通过Power-Preservation Index量化权力寻租行为，发现宪法AI宪章和调解审议协议能有效减少腐败行为。


<details>
  <summary>Details</summary>
Motivation: 探索在AI时代人类的意义，研究如何通过制度设计来对齐未来人工智能社会的复杂涌现行为，重新思考人类在与非人类实体共同治理时代所需的仪式和责任。

Method: 基于代理的模拟系统，让具有创伤记忆、隐藏议程和心理触发点的LLM代理在不同压力情境（如预算危机和资源稀缺）下进行审议、立法和选举。

Result: 制度设计（特别是宪法AI宪章和调解审议协议的组合）显著减少了腐败的权力寻租行为，提高了政策稳定性，并改善了公民福利。

Conclusion: 制度设计可能为对齐未来人工代理社会的复杂涌现行为提供框架，迫使人类重新思考在AI时代哪些人类仪式和责任是必不可少的。

Abstract: This paper introduces Democracy-in-Silico, an agent-based simulation where
societies of advanced AI agents, imbued with complex psychological personas,
govern themselves under different institutional frameworks. We explore what it
means to be human in an age of AI by tasking Large Language Models (LLMs) to
embody agents with traumatic memories, hidden agendas, and psychological
triggers. These agents engage in deliberation, legislation, and elections under
various stressors, such as budget crises and resource scarcity. We present a
novel metric, the Power-Preservation Index (PPI), to quantify misaligned
behavior where agents prioritize their own power over public welfare. Our
findings demonstrate that institutional design, specifically the combination of
a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves
as a potent alignment mechanism. These structures significantly reduce corrupt
power-seeking behavior, improve policy stability, and enhance citizen welfare
compared to less constrained democratic models. The simulation reveals that an
institutional design may offer a framework for aligning the complex, emergent
behaviors of future artificial agent societies, forcing us to reconsider what
human rituals and responsibilities are essential in an age of shared authorship
with non-human entities.

</details>


### [104] [Skill-based Explanations for Serendipitous Course Recommendation](https://arxiv.org/abs/2508.19569)
*Hung Chau,Run Yu,Zachary Pardos,Peter Brusilovsky*

Main category: cs.AI

TL;DR: 本研究开发了基于深度学习的概念提取模型，从课程描述中提取相关概念，并在UC Berkeley的AskOski系统中测试基于技能解释的推荐框架，发现这种解释能提高用户兴趣和决策信心。


<details>
  <summary>Details</summary>
Motivation: 美国本科教育中学生选课自由度高，但面临信息有限、指导不足、选择过多等挑战。现有推荐系统缺乏对学生认知的洞察和课程相关性的解释。

Method: 开发深度学习概念提取模型从课程描述中提取相关概念，在serendipitous推荐框架中测试基于技能的解释效果，通过AskOski系统进行实验。

Result: 基于技能的解释不仅提高了用户对高意外性课程的兴趣，还增强了决策信心。

Conclusion: 教育推荐系统需要整合技能相关数据和解释功能，以改善学生的选课体验和决策质量。

Abstract: Academic choice is crucial in U.S. undergraduate education, allowing students
significant freedom in course selection. However, navigating the complex
academic environment is challenging due to limited information, guidance, and
an overwhelming number of choices, compounded by time restrictions and the high
demand for popular courses. Although career counselors exist, their numbers are
insufficient, and course recommendation systems, though personalized, often
lack insight into student perceptions and explanations to assess course
relevance. In this paper, a deep learning-based concept extraction model is
developed to efficiently extract relevant concepts from course descriptions to
improve the recommendation process. Using this model, the study examines the
effects of skill-based explanations within a serendipitous recommendation
framework, tested through the AskOski system at the University of California,
Berkeley. The findings indicate that these explanations not only increase user
interest, particularly in courses with high unexpectedness, but also bolster
decision-making confidence. This underscores the importance of integrating
skill-related data and explanations into educational recommendation systems.

</details>


### [105] [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)
*Sining Zhoubian,Dan Zhang,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ReST-RL是一个统一的LLM强化学习范式，通过改进的GRPO算法和基于价值模型的测试时解码方法，显著提升LLM的代码推理能力，在多个编程基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法因奖励方差不足而失败，基于过程奖励模型(PRM)的验证方法存在训练数据获取困难和验证效果不佳的问题，需要新的解决方案来提升LLM推理准确性。

Method: 采用两阶段方法：1) ReST-GRPO阶段使用优化的ReST算法筛选和组装高价值训练数据，增加GRPO采样的奖励方差；2) VM-MCTS测试时解码方法通过蒙特卡洛树搜索收集无标注的价值目标来训练价值模型，在解码时提供精确的过程信号和验证分数。

Result: 在APPS、BigCodeBench和HumanEval等多个编程基准测试中，ReST-RL显著优于其他强化训练基线(如原生GRPO和ReST-DPO)以及解码验证基线(如PRM-BoN和ORM-MCTS)。

Conclusion: ReST-RL通过结合改进的GRPO算法和基于价值模型的测试时解码优化，有效提升了LLM策略的推理能力，为解决LLM推理准确性提供了有效的强化学习范式。

Abstract: With respect to improving the reasoning accuracy of LLMs, the representative
reinforcement learning (RL) method GRPO faces failure due to insignificant
reward variance, while verification methods based on process reward models
(PRMs) suffer from difficulties with training data acquisition and verification
effectiveness. To tackle these problems, this paper introduces ReST-RL, a
unified LLM RL paradigm that significantly improves LLM's code reasoning
ability by combining an improved GRPO algorithm with a meticulously designed
test time decoding method assisted by a value model (VM). As the first stage of
policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter
and assemble high-value training data, increasing the reward variance of GRPO
sampling, thus improving the effectiveness and efficiency of training. After
the basic reasoning ability of LLM policy has been improved, we further propose
a test time decoding optimization method called VM-MCTS. Through Monte-Carlo
Tree Search (MCTS), we collect accurate value targets with no annotation
required, on which VM training is based. When decoding, the VM is deployed by
an adapted MCTS algorithm to provide precise process signals as well as
verification scores, assisting the LLM policy to achieve high reasoning
accuracy. We validate the effectiveness of the proposed RL paradigm through
extensive experiments on coding problems. Upon comparison, our approach
significantly outperforms other reinforcement training baselines (e.g., naive
GRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,
PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,
APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the
reasoning ability of LLM policies. Codes for our project can be found at
https://github.com/THUDM/ReST-RL.

</details>


### [106] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: Instructional Agents是一个多智能体LLM框架，用于自动化生成完整的课程材料，包括教学大纲、讲义脚本、LaTeX幻灯片和评估内容，通过模拟教育角色协作显著减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 高质量教学材料的准备过程劳动密集且需要多方协调，现有AI教育工具只关注孤立任务，无法提供整体解决方案。

Method: 采用多智能体大语言模型框架，模拟基于角色的教育智能体协作，提供四种操作模式（自主、目录引导、反馈引导、完全协同模式）来控制人工参与程度。

Result: 在五门大学计算机科学课程中评估显示，该系统能生成高质量教学材料，同时显著减少开发时间和人工工作量。

Conclusion: Instructional Agents为教学设计能力有限的机构提供了可扩展且成本效益高的框架，有助于在资源有限的环境中普及高质量教育。

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [107] [InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.19679)
*Qihang Ai,Pi Bu,Yue Cao,Yingyao Wang,Jihao Gu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Zhicheng Zheng,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 提出了InquireBench基准测试和InquireMobile模型，通过主动询问用户确认来提升移动代理的安全性，在询问成功率上提升46.8%


<details>
  <summary>Details</summary>
Motivation: 当前完全自主的视觉语言模型移动代理存在安全风险，当模型理解或推理能力不足时可能造成危险

Method: 提出InquireMobile模型，采用强化学习启发的两阶段训练策略和交互式预动作推理机制，在关键决策点主动寻求用户确认

Result: 在InquireBench基准测试上实现了46.8%的询问成功率提升，并在整体成功率上达到现有基线中的最佳表现

Conclusion: 通过主动询问机制可以有效提升移动代理的安全性，该方法在安全交互和主动询问方面表现出色

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents
to perceive and interact with real-world mobile environments based on human
instructions. However, the current fully autonomous paradigm poses potential
safety risks when model understanding or reasoning capabilities are
insufficient. To address this challenge, we first introduce
\textbf{InquireBench}, a comprehensive benchmark specifically designed to
evaluate mobile agents' capabilities in safe interaction and proactive inquiry
with users, encompassing 5 categories and 22 sub-categories, where most
existing VLM-based agents demonstrate near-zero performance. In this paper, we
aim to develop an interactive system that actively seeks human confirmation at
critical decision points. To achieve this, we propose \textbf{InquireMobile}, a
novel model inspired by reinforcement learning, featuring a two-stage training
strategy and an interactive pre-action reasoning mechanism. Finally, our model
achieves an 46.8% improvement in inquiry success rate and the best overall
success rate among existing baselines on InquireBench. We will open-source all
datasets, models, and evaluation codes to facilitate development in both
academia and industry.

</details>


### [108] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: 研究发现CoT在软推理任务中对不同模型的影响存在差异，CoT的影响力和忠实性并不总是一致


<details>
  <summary>Details</summary>
Motivation: 探索Chain-of-Thought在不同类型模型中进行软推理任务时的动态特性和忠实性表现

Method: 在指令微调模型、推理模型和推理蒸馏模型上分析CoT在分析推理和常识推理等软推理任务中的表现

Result: 发现不同模型对CoT的依赖方式存在差异，CoT的影响力和模型实际推理的忠实性并不总是对齐

Conclusion: CoT在软推理任务中的效果有限且可能存在不忠实问题，需要更深入地理解不同模型使用CoT的机制

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [109] [Tracking World States with Language Models: State-Based Evaluation Using Chess](https://arxiv.org/abs/2508.19851)
*Romain Harang,Jason Naradowsky,Yaswitha Gujju,Yusuke Miyao*

Main category: cs.AI

TL;DR: 这篇论文提出了一种与模型无关的评估框架，使用国际象棋作为标准来评估大语言模型在结构化环境中的语义保真度。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在结构化领域显示出出色能力，但现有的探针技术依赖模型内部激活，限制了可解释性和通用性。需要一种更有意义的评估方法来分析LLM是否保持了结构化环境的语义。

Method: 提出了一种基于状态的评估框架，通过分析下游合法移动分布（状态支持性）来估计预测状态与实际游戏状态之间的语义保真度。这种方法比传统的字符串基准更能对凖国际象棋的战略性和规则性质。

Result: 实验结果表明，该指标能够抓取到状态跟踪中的缺陷，显示了大语言模型在长序列中维持一贯内部模型时的局限性。

Conclusion: 该框架为评估大语言模型在结构化推理中的表现提供了一种健壮的工具，无需访问模型内部，并能够通用于广泛的符号环境。

Abstract: Large Language Models (LLMs) exhibit emergent capabilities in structured
domains, suggesting they may implicitly internalize high-fidelity
representations of world models. While probing techniques have shown promising
signs of this in scientific and game-based settings, they rely on
model-specific internal activations, which limit interpretability and
generalizability. In this work, we propose a model-agnostic, state-based
evaluation framework using chess as a benchmark to assess whether LLMs preserve
the semantics of structured environments. Our method analyzes the downstream
legal move distributions (state affordances) to estimate semantic fidelity
between predicted and actual game states. This approach offers a more
meaningful evaluation than conventional string-based metrics by aligning more
closely with the strategic and rule-governed nature of chess. Experimental
results demonstrate that our metrics capture deficiencies in state-tracking,
highlighting limitations of LLMs in maintaining coherent internal models over
long sequences. Our framework provides a robust tool for evaluating structured
reasoning in LLMs without requiring internal model access, and generalizes to a
wide class of symbolic environments.

</details>


### [110] [CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments](https://arxiv.org/abs/2508.19932)
*Nitish Jaipuria,Lorenzo Gatto,Zijun Kan,Shankey Poddar,Bill Cheung,Diksha Bansal,Ramanan Balakrishnan,Aviral Suri,Jose Estevez*

Main category: cs.AI

TL;DR: CASE框架通过对话式AI主动收集诈骗反馈，提升诈骗执法效率21%


<details>
  <summary>Details</summary>
Motivation: 数字支付平台诈骗案件激增，传统基于用户和交易信号的方法难以全面理解诈骗模式并及时预防

Method: 开发CASE对话式AI框架，使用Gemini LLM主动访谈潜在受害者，将对话转录转换为结构化数据用于执法机制

Result: 在Google Pay印度实施后，诈骗执法量提升21%，架构具有高度通用性

Conclusion: 该AI驱动框架为其他敏感领域收集和管理诈骗情报提供了可推广的蓝图

Abstract: The proliferation of digital payment platforms has transformed commerce,
offering unmatched convenience and accessibility globally. However, this growth
has also attracted malicious actors, leading to a corresponding increase in
sophisticated social engineering scams. These scams are often initiated and
orchestrated on multiple surfaces outside the payment platform, making user and
transaction-based signals insufficient for a complete understanding of the
scam's methodology and underlying patterns, without which it is very difficult
to prevent it in a timely manner. This paper presents CASE (Conversational
Agent for Scam Elucidation), a novel Agentic AI framework that addresses this
problem by collecting and managing user scam feedback in a safe and scalable
manner. A conversational agent is uniquely designed to proactively interview
potential victims to elicit intelligence in the form of a detailed
conversation. The conversation transcripts are then consumed by another AI
system that extracts information and converts it into structured data for
downstream usage in automated and manual enforcement mechanisms. Using Google's
Gemini family of LLMs, we implemented this framework on Google Pay (GPay)
India. By augmenting our existing features with this new intelligence, we have
observed a 21% uplift in the volume of scam enforcements. The architecture and
its robust evaluation framework are highly generalizable, offering a blueprint
for building similar AI-driven systems to collect and manage scam intelligence
in other sensitive domains.

</details>


### [111] [Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants](https://arxiv.org/abs/2508.19963)
*M. Umlauft,M. Schranz*

Main category: cs.AI

TL;DR: 使用boids群集算法解决半导体工厂中机器类型切换的调度优化问题


<details>
  <summary>Details</summary>
Motivation: 现代生产工厂特别是半导体工厂的作业车间调度问题非常复杂，传统线性优化方法在大规模场景下无法在合理时间内求解全局最优解，需要寻找替代方法

Method: 采用源自机器人和电影工业的boids群集算法，这是一种基于局部信息和简单启发式的生物启发式算法，以自底向上的方式处理机器类型切换问题

Result: 该算法能够有效应对生产工厂中机器类型切换的挑战，类似于动物群集对障碍物的反应方式

Conclusion: 群集智能算法特别是boids算法为半导体生产等复杂调度问题提供了可行的解决方案，能够处理机器类型频繁切换的复杂场景

Abstract: Optimizing modern production plants using the job-shop principle is a known
hard problem. For very large plants, like semiconductor fabs, the problem
becomes unsolvable on a plant-wide scale in a reasonable amount of time using
classical linear optimization. An alternative approach is the use of swarm
intelligence algorithms. These have been applied to the job-shop problem
before, but often in a centrally calculated way where they are applied to the
solution space, but they can be implemented in a bottom-up fashion to avoid
global result computation as well. One of the problems in semiconductor
production is that the production process requires a lot of switching between
machines that process lots one after the other and machines that process
batches of lots at once, often with long processing times. In this paper, we
address this switching problem with the ``boids'' flocking algorithm that was
originally used in robotics and movie industry. The flocking behavior is a
bio-inspired algorithm that uses only local information and interaction based
on simple heuristics. We show that this algorithm addresses these valid
considerations in production plant optimization, as it reacts to the switching
of machine kinds similar to how a swarm of flocking animals would react to
obstacles in its course.

</details>


### [112] [Model Science: getting serious about verification, explanation and control of AI systems](https://arxiv.org/abs/2508.20040)
*Przemyslaw Biecek,Wojciech Samek*

Main category: cs.AI

TL;DR: 本文提出了从数据科学向模型科学的范式转变，将训练好的模型置于分析核心，围绕验证、解释、控制和接口四大支柱构建可信、安全、人类对齐的AI系统。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的广泛应用，需要从以数据为中心转向以模型为中心的分析范式，以更好地理解、验证和控制模型在不同操作环境中的行为。

Method: 提出了模型科学的概念框架，包含四个关键支柱：验证（严格的情境感知评估协议）、解释（探索模型内部操作的方法）、控制（整合对齐技术引导模型行为）和接口（开发交互式可视化工具）。

Result: 建立了一个系统性的模型科学框架，为开发可信、安全和人类对齐的AI系统提供了理论指导和方法论基础。

Conclusion: 模型科学代表了AI发展的新方向，通过将模型置于分析核心，能够更好地确保AI系统的可靠性、安全性和与人类价值观的一致性。

Abstract: The growing adoption of foundation models calls for a paradigm shift from
Data Science to Model Science. Unlike data-centric approaches, Model Science
places the trained model at the core of analysis, aiming to interact, verify,
explain, and control its behavior across diverse operational contexts. This
paper introduces a conceptual framework for a new discipline called Model
Science, along with the proposal for its four key pillars: Verification, which
requires strict, context-aware evaluation protocols; Explanation, which is
understood as various approaches to explore of internal model operations;
Control, which integrates alignment techniques to steer model behavior; and
Interface, which develops interactive and visual explanation tools to improve
human calibration and decision-making. The proposed framework aims to guide the
development of credible, safe, and human-aligned AI systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [113] [Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents](https://arxiv.org/abs/2508.19504)
*Kevin Song,Anand Jayarajan,Yaoyao Ding,Qidong Su,Zhanda Zhu,Sihang Liu,Gennady Pekhimenko*

Main category: cs.MA

TL;DR: 本文提出通过优化系统环境而非改进代理本身来提高LLM代理成功率的方法，设计了Aegis环境优化技术，平均提升成功率6.7-12.5%


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注改进代理本身，但忽略了系统环境对代理成功率的重要影响。实际部署中LLM代理在复杂现实环境中的低成功率限制了其应用

Method: 收集142个代理轨迹（3,656次交互），分析失败模式并提出6种失败分类，设计Aegis环境优化技术：环境可观测性增强、通用计算卸载和推测性代理动作

Result: Aegis技术在无需修改代理和底层LLM的情况下，平均提高代理成功率6.7-12.5%

Conclusion: 优化系统环境是提高LLM代理成功率的有效补充方向，环境优化可以显著提升代理性能而不需要修改代理本身

Abstract: Large Language Models (LLMs) agents augmented with domain tools promise to
autonomously execute complex tasks requiring human-level intelligence, such as
customer service and digital assistance. However, their practical deployment is
often limited by their low success rates under complex real-world environments.
To tackle this, prior research has primarily focused on improving the agents
themselves, such as developing strong agentic LLMs, while overlooking the role
of the system environment in which the agent operates.
  In this paper, we study a complementary direction: improving agent success
rates by optimizing the system environment in which the agent operates. We
collect 142 agent traces (3,656 turns of agent-environment interactions) across
5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we
propose a taxonomy for agent-environment interaction failures that includes 6
failure modes. Guided by these findings, we design Aegis, a set of targeted
environment optimizations: 1) environment observability enhancement, 2) common
computation offloading, and 3) speculative agentic actions. These techniques
improve agent success rates on average by 6.7-12.5%, without any modifications
to the agent and underlying LLM.

</details>


### [114] [CataractSurg-80K: Knowledge-Driven Benchmarking for Structured Reasoning in Ophthalmic Surgery Planning](https://arxiv.org/abs/2508.20014)
*Yang Meng,Zewen Pan,Yandi Lu,Ruobing Huang,Yanfeng Liao,Jiarui Yang*

Main category: cs.MA

TL;DR: 本文提出了一个知识驱动的多智能体系统(MAS)用于白内障手术规划，构建了首个大规模基准数据集CataractSurg-80K，并开发了领域专业化模型Qwen-CSP，在多个指标上优于通用大语言模型。


<details>
  <summary>Details</summary>
Motivation: 白内障手术规划需要整合多种临床检查数据，现有大语言模型缺乏领域专业知识来解读异质性眼科数据并提供可操作的手术计划。

Method: 提出知识驱动的多智能体系统，模拟专科眼科医生的推理过程；构建包含8万病例的基准数据集，每个病例都有诊断问题、专家推理链和结构化手术建议；基于Qwen-4B开发多阶段微调的专业化模型Qwen-CSP。

Result: Qwen-CSP在多个评估指标上显著优于强通用大语言模型，证明了领域专业化方法的有效性。

Conclusion: 该研究提供了高质量数据集、严格基准和领域适应的大语言模型，有助于推动医学AI推理和决策支持的未来发展。

Abstract: Cataract surgery remains one of the most widely performed and effective
procedures for vision restoration. Effective surgical planning requires
integrating diverse clinical examinations for patient assessment, intraocular
lens (IOL) selection, and risk evaluation. Large language models (LLMs) have
shown promise in supporting clinical decision-making. However, existing LLMs
often lack the domain-specific expertise to interpret heterogeneous ophthalmic
data and provide actionable surgical plans. To enhance the model's ability to
interpret heterogeneous ophthalmic reports, we propose a knowledge-driven
Multi-Agent System (MAS), where each agent simulates the reasoning process of
specialist ophthalmologists, converting raw clinical inputs into structured,
actionable summaries in both training and deployment stages. Building on MAS,
we introduce CataractSurg-80K, the first large-scale benchmark for cataract
surgery planning that incorporates structured clinical reasoning. Each case is
annotated with diagnostic questions, expert reasoning chains, and structured
surgical recommendations. We further introduce Qwen-CSP, a domain-specialized
model built on Qwen-4B, fine-tuned through a multi-stage process tailored for
surgical planning. Comprehensive experiments show that Qwen-CSP outperforms
strong general-purpose LLMs across multiple metrics. Our work delivers a
high-quality dataset, a rigorous benchmark, and a domain-adapted LLM to
facilitate future research in medical AI reasoning and decision support.

</details>


### [115] [Anomaly Detection in Networked Bandits](https://arxiv.org/abs/2508.20076)
*Xiaotong Cheng,Setareh Maghsudi*

Main category: cs.MA

TL;DR: 提出一种新颖的bandit算法，利用网络知识学习用户偏好和特征残差，实现个性化推荐和异常检测的同步进行


<details>
  <summary>Details</summary>
Motivation: 社交网络中节点间的相互连接反映了依赖关系和信息共享行为，但异常节点会带来严重后果，需要设计高效的在线学习算法来鲁棒地学习用户偏好并同时检测异常

Method: 通过网络知识表征用户偏好和特征信息的残差，通过学习分析这些偏好和残差，为每个用户开发个性化推荐策略并同时检测异常

Result: 严格证明了所提出算法的遗憾上界，并在合成和真实数据集上与多个最先进的协作上下文bandit算法进行了实验比较

Conclusion: 该算法能够有效处理社交网络中的异常检测问题，同时提供个性化推荐，在理论和实验上都表现出良好性能

Abstract: The nodes' interconnections on a social network often reflect their
dependencies and information-sharing behaviors. Nevertheless, abnormal nodes,
which significantly deviate from most of the network concerning patterns or
behaviors, can lead to grave consequences. Therefore, it is imperative to
design efficient online learning algorithms that robustly learn users'
preferences while simultaneously detecting anomalies.
  We introduce a novel bandit algorithm to address this problem. Through
network knowledge, the method characterizes the users' preferences and
residuals of feature information. By learning and analyzing these preferences
and residuals, it develops a personalized recommendation strategy for each user
and simultaneously detects anomalies. We rigorously prove an upper bound on the
regret of the proposed algorithm and experimentally compare it with several
state-of-the-art collaborative contextual bandit algorithms on both synthetic
and real-world datasets.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [116] [When Routers, Switches and Interconnects Compute: A processing-in-interconnect Paradigm for Scalable Neuromorphic AI](https://arxiv.org/abs/2508.19548)
*Madhuvanthi Srivatsav R,Chiranjib Bhattacharyya,Shantanu Chakrabartty,Chetan Singh Thakur*

Main category: cs.NE

TL;DR: 这篇论文提出了一种在互联网络中进行处理的新计算范式(π²)，利用现有路由和交换硬件的原语来实现AI工作负荷，以解决大规模神经网络计算的畅速和能消耗问题。


<details>
  <summary>Details</summary>
Motivation: 路由、交换和互联结构虽然在神经网络计算中只起支撑作用，但对于大规模AI工作负荷而言，它们最终决定了能消耗和速度。论文寻找解决这个性能瓶颈的方法。

Method: 将典型AI工作负荷的操作映射到现有包交换和路由硬件的原语（延迟、因果关系、超时、包丢弃、广播）。利用现有缓冲和流量形成算法来实现神经元模型和突触操作，通过知识精炼框架训练并跨映射到π²系统。

Result: 分析模型显示，与其他神经网络平台不同，π²的能消耗缩放随着互联带宽和能效的提升而改善。预测利用互联技术趋势，π²架构可以更容易扩展到执行脑等级AI推理工作负荷，功耗仅需百瓦级别。

Conclusion: π²计算范式能够有效利用现有路由和交换硬件的内置计算能力，为大规模神经网络计算提供了一种可扩展、能效高的解决方案，具有良好的能消耗缩放特性。

Abstract: Routing, switching, and the interconnect fabric are essential for large-scale
neuromorphic computing. While this fabric only plays a supporting role in the
process of computing, for large AI workloads it ultimately determines energy
consumption and speed. In this paper, we address this bottleneck by asking: (a)
What computing paradigms are inherent in existing routing, switching, and
interconnect systems, and how can they be used to implement a
processing-in-Interconnect (\pi^2) computing paradigm? and (b) leveraging
current and future interconnect trends, how will a \pi^2 system's performance
scale compared to other neuromorphic architectures? For (a), we show that
operations required for typical AI workloads can be mapped onto delays,
causality, time-outs, packet drop, and broadcast operations -- primitives
already implemented in packet-switching and packet-routing hardware. We show
that existing buffering and traffic-shaping embedded algorithms can be
leveraged to implement neuron models and synaptic operations. Additionally, a
knowledge-distillation framework can train and cross-map well-established
neural network topologies onto $\pi^2$ without degrading generalization
performance. For (b), analytical modeling shows that, unlike other neuromorphic
platforms, the energy scaling of $\pi^2$ improves with interconnect bandwidth
and energy efficiency. We predict that by leveraging trends in interconnect
technology, a \pi^2 architecture can be more easily scaled to execute
brain-scale AI inference workloads with power consumption levels in the range
of hundreds of watts.

</details>


### [117] [Walk the Robot: Exploring Soft Robotic Morphological Communication driven by Spiking Neural Networks](https://arxiv.org/abs/2508.19920)
*Matthew Meek,Guy Tallent,Thomas Breimer,James Gaskell,Abhay Kashyap,Atharv Tekurkar,Jonathan Fischman,Luodi Wang,Viet-Dung Nguyen,John Rieffel*

Main category: cs.NE

TL;DR: 研究探索在SNN控制的软体机器人中利用非线性动力学耦合实现形态通信，而非抑制耦合效应


<details>
  <summary>Details</summary>
Motivation: 传统方法通常抑制非线性动态耦合，而本研究旨在探索如何利用这种耦合作为机器人内部不同控制器模块之间的通信机制，实现形态通信

Method: 在EvoGym环境中使用基于尖峰神经网络(SNN)的进化学习模型来控制模拟软体机器人，研究形态通信的涌现

Result: 研究表明进化学习模型能够有效控制非刚性机器人，并可能实现形态通信机制

Conclusion: 利用非线性动力学耦合进行形态通信是控制软体机器人的有效方法，SNN进化模型为此提供了可行的技术途径

Abstract: Recently, researchers have explored control methods that embrace nonlinear
dynamic coupling instead of suppressing it. Such designs leverage dynamical
coupling for communication between different parts of the robot. Morphological
communication refers to when those dynamics can be used as an emergent data bus
to facilitate coordination among independent controller modules within the same
robot. Previous research with tensegrity-based robot designs has shown that
evolutionary learning models that evolve spiking neural networks (SNN) as robot
control mechanisms are effective for controlling non-rigid robots. Our own
research explores the emergence of morphological communication in an SNN-based
simulated soft robot in theEvoGym environment.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [118] [Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models](https://arxiv.org/abs/2508.19249)
*Jonas Søeborg Nielsen,Marcus Galea Jacobsen,Albert Brincker Olson,Mads Peter Sørensen,Allan Peter Engsig-Karup*

Main category: cs.LG

TL;DR: 基于普通最小二乘的物理信息回归(PIR)方法，通过利用参数线性模型特性，实现高效参数估计，在计算速度和性能上都超过PINN方法


<details>
  <summary>Details</summary>
Motivation: 为了提高非线性动态模型参数估计的效率和速度，并尝试建立一种能够融合物理理论与实际数据的高效方法

Method: 提出物理信息回归(PIR)方法，利用参数线性模型的特性，通过正则化普通最小二乘进行参数估计，应用于ODE和PDE模型

Result: PIR在同成数据和真实时间序列数据上都能准确估计参数，在复杂模型上表现明显优于PINN方法，计算速度更快

Conclusion: PIR方法在考虑的模型中表现优于PINN，能够支持可靠、高效的参数估计，甚至可能实现实时估计，为物理信息数据融合提供了有效方案

Abstract: We present a new efficient hybrid parameter estimation method based on the
idea, that if nonlinear dynamic models are stated in terms of a system of
equations that is linear in terms of the parameters, then regularized ordinary
least squares can be used to estimate these parameters from time series data.
We introduce the term "Physics-Informed Regression" (PIR) to describe the
proposed data-driven hybrid technique as a way to bridge theory and data by use
of ordinary least squares to efficiently perform parameter estimation of the
model coefficients of different parameter-linear models; providing examples of
models based on nonlinear ordinary equations (ODE) and partial differential
equations (PDE). The focus is on parameter estimation on a selection of ODE and
PDE models, each illustrating performance in different model characteristics.
For two relevant epidemic models of different complexity and number of
parameters, PIR is tested and compared against the related technique,
physics-informed neural networks (PINN), both on synthetic data generated from
known target parameters and on real public Danish time series data collected
during the COVID-19 pandemic in Denmark. Both methods were able to estimate the
target parameters, while PIR showed to perform noticeably better, especially on
a compartment model with higher complexity. Given the difference in
computational speed, it is concluded that the PIR method is superior to PINN
for the models considered. It is also demonstrated how PIR can be applied to
estimate the time-varying parameters of a compartment model that is fitted
using real Danish data from the COVID-19 pandemic obtained during a period from
2020 to 2021. The study shows how data-driven and physics-informed techniques
may support reliable and fast -- possibly real-time -- parameter estimation in
parameter-linear nonlinear dynamic models.

</details>


### [119] [Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats](https://arxiv.org/abs/2508.19263)
*Anat Heilper,Doron Singer*

Main category: cs.LG

TL;DR: 将ZipNN无损压缩方法扩展到低精度浮点格式(FP8/FP4)，通过分离压缩指数和尾数实现高效模型压缩，压缩比达62-83%，并发现LLM中的K/V缓存也具有可压缩性


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模增长和部署普及，降低神经网络权重的存储和传输成本变得越来越重要，需要为新兴的低精度浮点格式开发压缩方法

Method: 扩展ZipNN方法到FP8和FP4格式，设计分离压缩指数和尾数组件的熵编码方法，独立压缩两个组件

Result: BF16格式压缩比达62%，FP8格式压缩比达83%，发现LLM中的key-value缓存张量也表现出可压缩模式，可实现部署时的内存节省

Conclusion: 低精度浮点格式同样适用于无损压缩，该方法能有效减少模型存储和传输成本，K/V缓存的压缩性为LLM部署提供了额外内存优化机会

Abstract: As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.

</details>


### [120] [POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization](https://arxiv.org/abs/2508.19277)
*Xinyu Li,Tianjin Huang,Ronghui Mu,Xiaowei Huang,Gaojie Jin*

Main category: cs.LG

TL;DR: POT是一种新型黑盒攻击框架，通过LLM迭代优化生成隐蔽且语义自然的对抗提示，诱导模型产生过度冗长的推理链，造成计算资源浪费。


<details>
  <summary>Details</summary>
Motivation: 现有过度思考攻击需要外部知识源进行数据投毒、依赖可检索的污染内容等限制条件，限制了实际应用。需要开发不依赖外部数据访问和模型检索的攻击方法。

Method: 基于LLM的迭代优化方法生成隐蔽且语义自然的对抗提示，诱导模型产生不必要的冗长推理过程，消耗过多计算资源。

Result: 在多种模型架构和数据集上的实验表明，POT相比其他方法取得了优越的性能。

Conclusion: POT框架成功解决了传统过度思考攻击的限制，实现了更实用的黑盒攻击，揭示了CoT推理过程中新的安全漏洞。

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially
enhanced the reasoning capabilities of large language models (LLMs), enabling
sophisticated problem-solving through explicit multi-step reasoning traces.
However, these enhanced reasoning processes introduce novel attack surfaces,
particularly vulnerabilities to computational inefficiency through
unnecessarily verbose reasoning chains that consume excessive resources without
corresponding performance gains. Prior overthinking attacks typically require
restrictive conditions including access to external knowledge sources for data
poisoning, reliance on retrievable poisoned content, and structurally obvious
templates that limit practical applicability in real-world scenarios. To
address these limitations, we propose POT (Prompt-Only OverThinking), a novel
black-box attack framework that employs LLM-based iterative optimization to
generate covert and semantically natural adversarial prompts, eliminating
dependence on external data access and model retrieval. Extensive experiments
across diverse model architectures and datasets demonstrate that POT achieves
superior performance compared to other methods.

</details>


### [121] [(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems](https://arxiv.org/abs/2508.19318)
*Aohan Li,Miyu Tsuzuki*

Main category: cs.LG

TL;DR: 提出了一种在真实分布式物联网环境中训练深度强化学习模型的新框架，使用ACK反馈信息进行训练，通过实际数据传输验证了框架的可行性和有效性


<details>
  <summary>Details</summary>
Motivation: 现有研究很少探索在真实分布式物联网系统中使用真实数据训练DRL模型，需要弥合这一研究空白

Method: 物联网设备使用基于DRL的方法选择通信信道，DRL模型通过从选定信道实际数据传输中获取的ACK反馈信息进行训练

Result: 在帧成功率(FSR)方面的性能评估证明了所提框架的可行性和有效性

Conclusion: 该框架为在真实分布式物联网环境中训练DRL模型提供了一种有效的解决方案，展示了实际应用的潜力

Abstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to
resource allocation due to its strong capability in handling complex
decision-making tasks. However, only limited research has explored the training
of DRL models with real-world data in practical, distributed Internet of Things
(IoT) systems. To bridge this gap, this paper proposes a novel framework for
training DRL models in real-world distributed IoT environments. In the proposed
framework, IoT devices select communication channels using a DRL-based method,
while the DRL model is trained with feedback information. Specifically,
Acknowledgment (ACK) information is obtained from actual data transmissions
over the selected channels. Implementation and performance evaluation, in terms
of Frame Success Rate (FSR), are carried out, demonstrating both the
feasibility and the effectiveness of the proposed framework.

</details>


### [122] [Re:Frame -- Retrieving Experience From Associative Memory](https://arxiv.org/abs/2508.19344)
*Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: Re:Frame是一个插件模块，通过关联记忆缓冲区整合少量专家轨迹，显著提升离线强化学习在低质量数据上的性能，无需环境交互或修改主干架构。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习通常面临次优数据的问题，难以获得大规模专家数据集。核心挑战是如何有效利用稀缺的专家演示和丰富的低质量数据。

Method: 引入Re:Frame模块，包含一个关联记忆缓冲区(AMB)存储专家轨迹。在训练过程中，策略学习通过内容关联从AMB检索专家数据并整合到决策中，评估时同样查询AMB。

Result: 在D4RL MuJoCo任务上，仅使用60条专家轨迹(占数据集的0.1%)，Re:Frame在四个设置中的三个都显著优于Decision Transformer基线，性能提升高达+10.7标准化分数。

Conclusion: Re:Frame提供了一种简单且数据高效的方法来注入稀缺的专家知识，显著改善基于低质量数据集的离线强化学习性能。

Abstract: Offline reinforcement learning (RL) often deals with suboptimal data when
collecting large expert datasets is unavailable or impractical. This limitation
makes it difficult for agents to generalize and achieve high performance, as
they must learn primarily from imperfect or inconsistent trajectories. A
central challenge is therefore how to best leverage scarce expert
demonstrations alongside abundant but lower-quality data. We demonstrate that
incorporating even a tiny amount of expert experience can substantially improve
RL agent performance. We introduce Re:Frame (Retrieving Experience From
Associative Memory), a plug-in module that augments a standard offline RL
policy (e.g., Decision Transformer) with a small external Associative Memory
Buffer (AMB) populated by expert trajectories drawn from a separate dataset.
During training on low-quality data, the policy learns to retrieve expert data
from the Associative Memory Buffer (AMB) via content-based associations and
integrate them into decision-making; the same AMB is queried at evaluation.
This requires no environment interaction and no modifications to the backbone
architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories
(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a
strong Decision Transformer baseline in three of four settings, with gains up
to +10.7 normalized points. These results show that Re:Frame offers a simple
and data-efficient way to inject scarce expert knowledge and substantially
improve offline RL from low-quality datasets.

</details>


### [123] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: Symphony是一个去中心化的多智能体系统，让消费级GPU上的轻量级LLM能够协调合作，解决了集中式编排的高成本、通信拓扑僵化和适应性有限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体框架大多采用集中式编排，存在部署成本高、通信拓扑僵化、适应性有限等问题，需要一种更高效的去中心化解决方案。

Method: 引入三个关键机制：1)记录能力的去中心化账本；2)动态任务分配的Beacon选择协议；3)基于思维链的加权结果投票。形成隐私保护、可扩展、容错且低开销的编排系统。

Result: 在推理基准测试中优于现有基线方法，实现了显著的准确率提升，并在不同容量的模型间展现出鲁棒性。

Conclusion: Symphony提供了一种高效的去中心化多智能体协调方案，能够在消费级硬件上实现高性能的LLM协作，具有重要的实际应用价值。

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [124] [Memorization in Graph Neural Networks](https://arxiv.org/abs/2508.19352)
*Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch*

Main category: cs.LG

TL;DR: 该论文提出了NCMemo框架，首次量化图神经网络在半监督节点分类中的标签记忆现象，发现图同质性越低记忆效应越强，并提出图重连方法有效减少记忆效应并保护隐私。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络已被证明会记忆训练数据，但图神经网络的记忆现象研究不足。需要量化GNN在节点分类中的标签记忆，并探索其与图结构特性的关系。

Method: 提出NCMemo框架分析节点分类记忆，研究图同质性与记忆的关系，分析GNN训练动态，并探索图重连作为缓解记忆的方法。

Result: 发现低同质性图显著增加记忆效应，节点特征空间邻域标签不一致性高的节点更容易被记忆。图重连方法能有效减少记忆而不影响模型性能，降低隐私风险。

Conclusion: 研究揭示了GNN学习机制中记忆现象与图结构的关系，提出的图重连方法为实现更隐私保护的GNN部署提供了有效途径。

Abstract: Deep neural networks (DNNs) have been shown to memorize their training data,
yet similar analyses for graph neural networks (GNNs) remain largely
under-explored. We introduce NCMemo (Node Classification Memorization), the
first framework to quantify label memorization in semi-supervised node
classification. We first establish an inverse relationship between memorization
and graph homophily, i.e., the property that connected nodes share similar
labels/features. We find that lower homophily significantly increases
memorization, indicating that GNNs rely on memorization to learn less
homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the
increased memorization in low homophily graphs is tightly coupled to the GNNs'
implicit bias on using graph structure during learning. In low homophily
regimes, this structure is less informative, hence inducing memorization of the
node labels to minimize training loss. Finally, we show that nodes with higher
label inconsistency in their feature-space neighborhood are significantly more
prone to memorization. Building on our insights into the link between graph
homophily and memorization, we investigate graph rewiring as a means to
mitigate memorization. Our results demonstrate that this approach effectively
reduces memorization without compromising model performance. Moreover, we show
that it lowers the privacy risk for previously memorized data points in
practice. Thus, our work not only advances understanding of GNN learning but
also supports more privacy-preserving GNN deployment.

</details>


### [125] [Efficient Multi-Source Knowledge Transfer by Model Merging](https://arxiv.org/abs/2508.19353)
*Marcin Osial,Bartosz Wójcik,Bartosz Zieliński,Sebastian Cygert*

Main category: cs.LG

TL;DR: 通过奇异值分解(SVD)将多个源模型分解为基础组件，选择最重要的组件进行聚合，通过精细调整奇异值来实现高效多源迁移学习


<details>
  <summary>Details</summary>
Motivation: 解决传统迁移学习方法在多源模型知识利用中的粗粗粗糕问题，缺乏细粒度知识提取能力和高效聚合效率

Method: 使用SVD将每个源模型分解为秩一组件，选择最显著的组件进行聚合，通过微调合并矩阵的主要奇异值来适配目标任务

Result: 方法实现了高效迁移学习，对输入层和参数空间的干扰具有稳健性，计算扩展性好

Conclusion: 该框架通过细粒度知识提取和高效聚合，有效解决了多源迁移学习的效率和精度问题

Abstract: While transfer learning is an advantageous strategy, it overlooks the
opportunity to leverage knowledge from numerous available models online.
Addressing this multi-source transfer learning problem is a promising path to
boost adaptability and cut re-training costs. However, existing approaches are
inherently coarse-grained, lacking the necessary precision for granular
knowledge extraction and the aggregation efficiency required to fuse knowledge
from either a large number of source models or those with high parameter
counts. We address these limitations by leveraging Singular Value Decomposition
(SVD) to first decompose each source model into its elementary, rank-one
components. A subsequent aggregation stage then selects only the most salient
components from all sources, thereby overcoming the previous efficiency and
precision limitations. To best preserve and leverage the synthesized knowledge
base, our method adapts to the target task by fine-tuning only the principal
singular values of the merged matrix. In essence, this process only
recalibrates the importance of top SVD components. The proposed framework
allows for efficient transfer learning, is robust to perturbations both at the
input level and in the parameter space (e.g., noisy or pruned sources), and
scales well computationally.

</details>


### [126] [Graph Data Modeling: Molecules, Proteins, & Chemical Processes](https://arxiv.org/abs/2508.19356)
*José Manuel Barraza-Chavez,Rana A. Barghout,Ricardo Almada-Monter,Benjamin Sanchez-Lengeling,Adrian Jinich,Radhakrishnan Mahadevan*

Main category: cs.LG

TL;DR: 这篇论文介绍了图数据模型在化学科学中的应用，特别是图神经网络在分子、蛋白质和化学过程建模中的作用，为化学发现提供了新的计算方法。


<details>
  <summary>Details</summary>
Motivation: 化学科学中的分子、蛋白质和反应过程天然具有图结构特征，需要专门的数学工具来描述和分析这些复杂关系，图数据模型为此提供了合适的框架。

Method: 介绍图作为数学对象在化学中的应用，阐述图设计基础、关键预测任务，以及图神经网络等学习算法在图数据上的操作方法。

Result: 提供了化学科学中图建模的代表性案例，展示了机器学习在图基建模中的作用，为读者应用图方法进行化学发现做好了准备。

Conclusion: 图数据模型为下一代化学发现提供了强大的计算工具，图神经网络等算法能够有效处理化学科学中的复杂结构和相互作用关系。

Abstract: Graphs are central to the chemical sciences, providing a natural language to
describe molecules, proteins, reactions, and industrial processes. They capture
interactions and structures that underpin materials, biology, and medicine.
This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,
introduces graphs as mathematical objects in chemistry and shows how learning
algorithms (particularly graph neural networks) can operate on them. We outline
the foundations of graph design, key prediction tasks, representative examples
across chemical sciences, and the role of machine learning in graph-based
modeling. Together, these concepts prepare readers to apply graph methods to
the next generation of chemical discovery.

</details>


### [127] [Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture](https://arxiv.org/abs/2508.19361)
*Yongbin Lee,Ki H. Chon*

Main category: cs.LG

TL;DR: 这篇论文提出了一种轻量级深度学习模型，使用RR间隔序列来提前2小时预测房颤，具有高准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 房颤是最常见的异常心律，特别是发作性房颤因其突然发作和短暂持续时间而难以检测，但未被发现的发作性房颤可能进展为持续性房颤，增加死亡风险。早期预测房颤可以通过预防性治疗减缓疾病进展。

Method: 提出了一种轻量级深度学习模型，仅使用RR间隔序列，结合时序卷积网络（TCN）进行位置编码和Mamba选择性状态空间模型，实现高效并行序列建模。

Result: 在主体测试中，模型达到了敏感度0.908、特异性0.933、F1得0.930、AUROC为0.972和AUPRC为0.932。模型仅有73.5千参数和38.3 MFLOPs计算量，能够仅使用30分钟输入数据提前2小时预测房颤。

Conclusion: 该模型在准确性和模型紧凑性方面都超过了传统的CNN-RNN方法，为早期房颤预测提供了高效的解决方案，为预防性干预提供了足够的预警时间。

Abstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk
of stroke, heart failure, and other cardiovascular complications. While AF
detection algorithms perform well in identifying persistent AF, early-stage
progression, such as paroxysmal AF (PAF), often goes undetected due to its
sudden onset and short duration. However, undetected PAF can progress into
sustained AF, increasing the risk of mortality and severe complications. Early
prediction of AF offers an opportunity to reduce disease progression through
preventive therapies, such as catecholamine-sparing agents or beta-blockers. In
this study, we propose a lightweight deep learning model using only RR
Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for
positional encoding with Mamba, a selective state space model, to enable early
prediction of AF through efficient parallel sequence modeling. In subject-wise
testing results, our model achieved a sensitivity of 0.908, specificity of
0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our
method demonstrates high computational efficiency, with only 73.5 thousand
parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural
Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and
model compactness. Notably, the model can predict AF up to two hours in advance
using just 30 minutes of input data, providing enough lead time for preventive
interventions.

</details>


### [128] [Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs](https://arxiv.org/abs/2508.19366)
*Supratik Sarkar,Swagatam Das*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于信息几何和正则化核希尔伯空间的多模态大语言模型幻觉量化框架，通过温度逆逆渐进技术探索幻觉的时间演化特征。


<details>
  <summary>Details</summary>
Motivation: 当前的幻觉评估技术主要基于经验性和定性方法，缺乏理论基础和可量化保障，尤其在医学、法律等高风险领域存在重大风险。

Method: 将MLLM输出表示为多模态图拉普拉斯矩阵的谱嵌入，通过求解雷利瑞利神约束来定义多模态幻觉能量，并利用RKHS嵌入中的本征模式分解来获取可解释的指标。

Result: 该框架能够实现幻觉的理论可解释性量化，提供了模态感知的量化指标，可以捐描幻觉在时间和输入提示上的演化过程。

Conclusion: 这项工作为量化和约束幻觉提供了理论基础，将幻觉从定性风险转化为可处理、可分析的现象。

Abstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle
to trustworthy AI, particularly in high-stakes multimodal domains such as
medicine, law, and finance. Existing evaluation techniques are largely
heuristic -- anchored in qualitative benchmarking or ad-hoc empirical
mitigation -- providing neither principled quantification nor actionable
theoretical guarantees. This gap leaves a critical blind spot in understanding
how hallucinations arise, propagate, and interact across modalities. We
introduce the first (to our knowledge) rigorous information geometric framework
in diffusion dynamics for quantifying hallucinations in multimodal LLMs
(MLLMs), advancing the field from qualitative detection to mathematically
grounded measurement. Our approach represents MLLM outputs as the spectral
embeddings over multimodal graph Laplacians and characterizes the manifold gaps
of truth vs inconsistencies as the semantic distortion, enabling the tight
Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of
time-dependent temperature profiles. By leveraging eigenmode decompositions in
Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers
modality-aware, theoretically interpretable metrics that capture the evolution
of hallucinations across time and input prompts through temperature annealing.
This work establishes a principled foundation for quantifying and bounding
hallucinations, transforming them from a qualitative risk to a tractable,
analyzable phenomenon.

</details>


### [129] [Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments](https://arxiv.org/abs/2508.19376)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: 基于LLaMA 3.2的视觉语言模型在粒子物理实验中的中微子相互作用分类任务上表现优于传统CNN方法，支持多模态推理。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在多模态推理方面的潜力，特别是在高能物理实验中对中微子相互作用进行分类的应用。

Method: 使用基于LLaMA 3.2的视觉语言模型进行微调，与NOvA和DUNE实验中使用的CNN基线模型进行性能对比评估。

Result: VLM模型在分类准确率、精确度、召回率和AUC-ROC等指标上达到或超过CNN性能，并能更好地整合辅助文本和语义上下文信息。

Conclusion: 视觉语言模型为高能物理中的事件分类提供了一个有前景的通用主干网络，为实验性中微子物理中的多模态方法开辟了新途径。

Abstract: Recent progress in large language models (LLMs) has shown strong potential
for multimodal reasoning beyond natural language. In this work, we explore the
use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for
classifying neutrino interactions from pixelated detector images in high-energy
physics (HEP) experiments. We benchmark its performance against an established
CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as
classification accuracy, precision, recall, and AUC-ROC. Our results show that
the VLM not only matches or exceeds CNN performance but also enables richer
reasoning and better integration of auxiliary textual or semantic context.
These findings suggest that VLMs offer a promising general-purpose backbone for
event classification in HEP, paving the way for multimodal approaches in
experimental neutrino physics.

</details>


### [130] [Towards Quantum Machine Learning for Malicious Code Analysis](https://arxiv.org/abs/2508.19381)
*Jesus Lopez,Saeefa Rubaiyet Nowmi,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.LG

TL;DR: 本研究探索了量子机器学习在恶意软件分类中的应用，比较了量子多层感知器(QMLP)和量子卷积神经网络(QCNN)两种混合量子-经典模型在多个数据集上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的出现，量子机器学习为改进恶意软件检测提供了范式转换的机会，但该领域应用仍未被充分探索。

Method: 使用两种混合量子-经典模型：QMLP通过全量子比特测量和数据重上传捕获复杂模式，QCNN通过量子卷积和池化层减少活跃量子比特实现更快训练。两种模型都使用角度嵌入将恶意软件特征编码为量子态。

Result: 在二进制分类中达到95-96%的高准确率，多分类任务中准确率从41.7%到95.7%不等。QMLP在复杂多分类任务中表现更优，而QCNN以降低准确率为代价提供更好的训练效率。

Conclusion: 量子机器学习在恶意软件分类中展现出巨大潜力，QMLP适合复杂任务，QCNN适合效率优先的场景，为量子计算在网络安全领域的应用开辟了新途径。

Abstract: Classical machine learning (CML) has been extensively studied for malware
classification. With the emergence of quantum computing, quantum machine
learning (QML) presents a paradigm-shifting opportunity to improve malware
detection, though its application in this domain remains largely unexplored. In
this study, we investigate two hybrid quantum-classical models -- a Quantum
Multilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),
for malware classification. Both models utilize angle embedding to encode
malware features into quantum states. QMLP captures complex patterns through
full qubit measurement and data re-uploading, while QCNN achieves faster
training via quantum convolution and pooling layers that reduce active qubits.
We evaluate both models on five widely used malware datasets -- API-Graph,
EMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and
multiclass classification tasks.
  Our results show high accuracy for binary classification -- 95-96% on
API-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass
settings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,
and 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex
multiclass tasks, while QCNN offers improved training efficiency at the cost of
reduced accuracy.

</details>


### [131] [DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting](https://arxiv.org/abs/2508.19389)
*Owais Ahmad,Milad Ramezankhani,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 提出DETNO架构，结合Transformer神经算子和扩散模型，解决交通流量预测中高频特征丢失和长期预测误差累积问题


<details>
  <summary>Details</summary>
Motivation: 传统神经算子在交通流量预测中会产生平滑预测，无法重建高频特征（如密度梯度），导致多步预测时误差快速累积，影响实时交通管理

Method: 采用统一的扩散增强Transformer神经算子架构，使用带交叉注意力机制的Transformer神经算子提供模型表达能力，结合基于扩散的细化组件通过渐进去噪迭代重建高频交通细节

Result: 在混沌交通数据集上的综合评估显示，该方法在扩展预测方面优于传统和基于Transformer的神经算子，能保持高频成分并提高长期预测稳定性

Conclusion: DETNO架构成功克服了标准神经算子的平滑限制和预测不稳定性，为长期交通流量预测提供了有效解决方案

Abstract: Accurate long-term traffic forecasting remains a critical challenge in
intelligent transportation systems, particularly when predicting high-frequency
traffic phenomena such as shock waves and congestion boundaries over extended
rollout horizons. Neural operators have recently gained attention as promising
tools for modeling traffic flow. While effective at learning function space
mappings, they inherently produce smooth predictions that fail to reconstruct
high-frequency features such as sharp density gradients which results in rapid
error accumulation during multi-step rollout predictions essential for
real-time traffic management. To address these fundamental limitations, we
introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)
architecture. DETNO leverages a transformer neural operator with
cross-attention mechanisms, providing model expressivity and super-resolution,
coupled with a diffusion-based refinement component that iteratively
reconstructs high-frequency traffic details through progressive denoising. This
overcomes the inherent smoothing limitations and rollout instability of
standard neural operators. Through comprehensive evaluation on chaotic traffic
datasets, our method demonstrates superior performance in extended rollout
predictions compared to traditional and transformer-based neural operators,
preserving high-frequency components and improving stability over long
prediction horizons.

</details>


### [132] [Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding](https://arxiv.org/abs/2508.19394)
*Afrar Jahin,Yi Pan,Yingfeng Wang,Tianming Liu,Wei Zhang*

Main category: cs.LG

TL;DR: 提出了一种混合量子-经典架构用于SMILES字符串重建，在量子保真度和经典相似度方面均超越现有量子基线方法


<details>
  <summary>Details</summary>
Motivation: 当前量子机器学习在分子设计等生成模型中虽有潜力，但在序列任务（如SMILES重建）中集成不足且存在保真度下降问题

Method: 结合量子编码与经典序列建模的混合量子-经典架构

Result: 达到约84%的量子保真度和60%的经典重建相似度，超越现有量子基线

Conclusion: 为未来量子机器学习应用奠定了有前景的基础，在量子表示和经典序列模型间取得平衡，推动量子感知序列模型在分子和药物发现中的研究

Abstract: Although recent advances in quantum machine learning (QML) offer significant
potential for enhancing generative models, particularly in molecular design, a
large array of classical approaches still face challenges in achieving high
fidelity and validity. In particular, the integration of QML with
sequence-based tasks, such as Simplified Molecular Input Line Entry System
(SMILES) string reconstruction, remains underexplored and usually suffers from
fidelity degradation. In this work, we propose a hybrid quantum-classical
architecture for SMILES reconstruction that integrates quantum encoding with
classical sequence modeling to improve quantum fidelity and classical
similarity. Our approach achieves a quantum fidelity of approximately 84% and a
classical reconstruction similarity of 60%, surpassing existing quantum
baselines. Our work lays a promising foundation for future QML applications,
striking a balance between expressive quantum representations and classical
sequence models and catalyzing broader research on quantum-aware sequence
models for molecular and drug discovery.

</details>


### [133] [Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks](https://arxiv.org/abs/2508.19410)
*Zongyu Wu,Ruichen Xu,Luoyao Chen,Georgios Kementzidis,Siyao Wang,Yuefan Deng*

Main category: cs.LG

TL;DR: 提出了基于Kolmogorov-Arnold表示理论的哈密顿神经网络(KAR-HNN)，用单变量变换替代MLP，能更好地处理复杂能量景观，减少能量漂移，提高长期预测稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的哈密顿神经网络(HNNs)虽然通过直接从数据学习哈密顿函数来保证能量守恒，但基于MLP的实现对超参数过于敏感，在处理复杂能量景观时存在困难。

Method: 使用Kolmogorov-Arnold表示理论，用单变量变换替代传统的多层感知机(MLPs)，利用局部函数逼近来更好地捕捉高频和多尺度动力学特征。

Result: 在弹簧质量系统、单摆、二体和三体问题等四个基准问题上评估显示，KAR-HNN能减少能量漂移，提高长期预测稳定性，保持哈密顿系统的辛形式和物理一致性。

Conclusion: KAR-HNN方法在高维度和参数稀少的情况下，对现实物理过程的准确稳定建模具有有效性前景。

Abstract: We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural
Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with
univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure
energy conservation by learning Hamiltonian functions directly from data,
existing implementations, often relying on MLPs, cause hypersensitivity to the
hyperparameters while exploring complex energy landscapes. Our approach
exploits the localized function approximations to better capture high-frequency
and multi-scale dynamics, reducing energy drift and improving long-term
predictive stability. The networks preserve the symplectic form of Hamiltonian
systems, and thus maintain interpretability and physical consistency. After
assessing KAR-HNN on four benchmark problems including spring-mass, simple
pendulum, two- and three-body problem, we foresee its effectiveness for
accurate and stable modeling of realistic physical processes often at high
dimensions and with few known parameters.

</details>


### [134] [Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention](https://arxiv.org/abs/2508.19414)
*Gustavo Sandoval*

Main category: cs.LG

TL;DR: Llama-3.1-8B-Instruct在聊天格式中错误判断9.11>9.8，研究发现偶数注意力头专门处理数值比较，需要至少8个偶数头才能修复此bug。


<details>
  <summary>Details</summary>
Motivation: 研究模型在不同格式下的推理失败机制，特别是数值比较错误，以理解transformer内部的工作机制和模块化结构。

Method: 通过系统干预实验，分析注意力头的奇偶索引功能分工，使用SAE（稀疏自编码器）分析特征表示，并进行头替换实验。

Result: 发现偶数头负责数值比较，需要至少8个偶数头才能完美修复bug；特征表示在不同层中分离和重新纠缠，失败格式中特定特征放大1.5倍。

Conclusion: 模型表现出明显的模块化结构，看似需要完整模块的功能实际上可以通过部分头实现，这对可解释性和效率有重要启示。

Abstract: We present a mechanistic case study of a format-dependent reasoning failure
in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger
than "9.8" in chat or Q&A formats, but answers correctly in simple format.
Through systematic intervention, we discover transformers implement even/odd
attention head specialization: even indexed heads handle numerical comparison,
while odd heads serve incompatible functions. The bug requires exactly 8 even
heads at Layer 10 for perfect repair. Any combination of 8+ even heads
succeeds, while 7 or fewer completely fails, revealing sharp computational
thresholds with perfect redundancy among the 16 even heads. SAE analysis
reveals the mechanism: format representations separate (10% feature overlap at
Layer 7), then re-entangle with different weightings (80% feature overlap at
Layer 10), with specific features showing 1.5x amplification in failing
formats. We achieve perfect repair using only 25% of attention heads and
identify a 60% pattern replacement threshold, demonstrating that apparent
full-module requirements hide sophisticated substructure with implications for
interpretability and efficiency. All of our code is available at
https://github.com/gussand/surgeon.

</details>


### [135] [Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions](https://arxiv.org/abs/2508.19945)
*Zhouyu Zhang,Chih-Yuan Chiu,Glen Chou*

Main category: cs.LG

TL;DR: 提出基于逆动态博弈的算法，从多智能体局部广义纳什均衡交互数据中学习参数化约束，通过MILP编码KKT条件恢复与纳什平稳性一致的约束，并建立理论保证和约束可学习性分析。


<details>
  <summary>Details</summary>
Motivation: 从多智能体交互演示中学习约束条件对于理解智能体行为和安全规划至关重要，现有方法在从纳什均衡交互中学习约束方面存在局限性。

Method: 引入混合整数线性规划(MILP)编码交互智能体的KKT条件，恢复与交互演示的纳什平稳性一致的约束，建立理论保证并分析约束可学习性。

Result: 方法能够从非线性动态智能体的交互演示中推断凸和非凸约束，并设计满足底层约束的鲁棒运动规划，在仿真和硬件实验中验证了有效性。

Conclusion: 该算法成功实现了从纳什均衡交互中学习参数化约束，为多智能体系统的约束学习和安全运动规划提供了有效解决方案。

Abstract: We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.

</details>


### [136] [Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management](https://arxiv.org/abs/2508.19419)
*Harun Ur Rashid,Aleksandra Pachalieva,Daniel O'Malley*

Main category: cs.LG

TL;DR: 提出了一种物理信息机器学习工作流，结合可微分多相流模拟器和CNN，通过迁移学习大幅减少所需的多相流模拟次数，从千万级降至数千次


<details>
  <summary>Details</summary>
Motivation: 地下储层压力控制面临地质异质性和多相流动力学的挑战，传统高保真物理模拟计算成本极高，且需要大量模拟来处理不确定性

Method: 使用DPFEHM框架中的完全可微分多相流模拟器与卷积神经网络耦合，CNN学习从异质渗透率场预测流体提取率以控制关键位置压力，采用单相稳态模拟预训练后多相场景微调

Result: 仅需不到3000次全物理多相流模拟即可实现高精度训练，相比之前需要千万次模拟大幅减少计算成本，迁移学习效果显著

Conclusion: 该方法通过物理信息机器学习和迁移学习策略，为现实注采场景提供了更实用准确的压力预测，大幅降低了计算成本

Abstract: Accurate subsurface reservoir pressure control is extremely challenging due
to geological heterogeneity and multiphase fluid-flow dynamics. Predicting
behavior in this setting relies on high-fidelity physics-based simulations that
are computationally expensive. Yet, the uncertain, heterogeneous properties
that control these flows make it necessary to perform many of these expensive
simulations, which is often prohibitive. To address these challenges, we
introduce a physics-informed machine learning workflow that couples a fully
differentiable multiphase flow simulator, which is implemented in the DPFEHM
framework with a convolutional neural network (CNN). The CNN learns to predict
fluid extraction rates from heterogeneous permeability fields to enforce
pressure limits at critical reservoir locations. By incorporating transient
multiphase flow physics into the training process, our method enables more
practical and accurate predictions for realistic injection-extraction scenarios
compare to previous works. To speed up training, we pretrain the model on
single-phase, steady-state simulations and then fine-tune it on full multiphase
scenarios, which dramatically reduces the computational cost. We demonstrate
that high-accuracy training can be achieved with fewer than three thousand
full-physics multiphase flow simulations -- compared to previous estimates
requiring up to ten million. This drastic reduction in the number of
simulations is achieved by leveraging transfer learning from much less
expensive single-phase simulations.

</details>


### [137] [MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification](https://arxiv.org/abs/2508.19424)
*Yifan Dou,Adam Khadre,Ruben C Petreaca,Golrokh Mirzaei*

Main category: cs.LG

TL;DR: 提出基于对比学习的无监督框架，对43种癌症类型进行聚类分析，使用基因水平和染色体水平的双重突变特征，通过TabNet编码和多尺度对比学习获得有生物学意义的癌症聚类结果。


<details>
  <summary>Details</summary>
Motivation: 理解泛癌突变景观对肿瘤发生机制至关重要。虽然患者级机器学习已广泛用于识别肿瘤亚型，但基于共享分子特征的队列级癌症聚类主要依赖传统统计方法，需要更先进的机器学习方法。

Method: 使用COSMIC数据库的编码突变数据，为每种癌症类型构建基因级和染色体级双重突变特征。采用TabNet编码器编码，通过多尺度对比学习目标（NT-Xent损失）优化，学习统一的癌症类型嵌入表示。

Result: 学习到的潜在表征能够产生具有生物学意义的癌症类型聚类，与已知的突变过程和组织起源相一致。这是对比学习首次应用于队列级癌症聚类。

Conclusion: 该方法为突变驱动的癌症亚型分析提供了一个可扩展且可解释的框架，代表了对比学习在癌症聚类中的创新应用。

Abstract: Motivation. Understanding the pan-cancer mutational landscape offers critical
insights into the molecular mechanisms underlying tumorigenesis. While
patient-level machine learning techniques have been widely employed to identify
tumor subtypes, cohort-level clustering, where entire cancer types are grouped
based on shared molecular features, has largely relied on classical statistical
methods.
  Results. In this study, we introduce a novel unsupervised contrastive
learning framework to cluster 43 cancer types based on coding mutation data
derived from the COSMIC database. For each cancer type, we construct two
complementary mutation signatures: a gene-level profile capturing nucleotide
substitution patterns across the most frequently mutated genes, and a
chromosome-level profile representing normalized substitution frequencies
across chromosomes. These dual views are encoded using TabNet encoders and
optimized via a multi-scale contrastive learning objective (NT-Xent loss) to
learn unified cancer-type embeddings. We demonstrate that the resulting latent
representations yield biologically meaningful clusters of cancer types,
aligning with known mutational processes and tissue origins. Our work
represents the first application of contrastive learning to cohort-level cancer
clustering, offering a scalable and interpretable framework for mutation-driven
cancer subtyping.

</details>


### [138] [Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models](https://arxiv.org/abs/2508.19441)
*Sanket Jantre,Deepak Akhare,Xiaoning Qian,Nathan M. Urban*

Main category: cs.LG

TL;DR: 提出了一种基于空间填充采样的数据增强策略，用于从计算机模型中高效生成神经PDE训练数据，相比传统轨迹数据采样方法显著提高了样本效率和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经PDE训练需要大量时间积分轨迹数据，存在时空冗余度高、样本效率低的问题，且难以捕捉状态空间中罕见但重要的状态。

Method: 采用空间填充采样策略生成局部"模板"状态数据，消除轨迹数据中的时空冗余，对罕见状态进行过采样，仅需相当于10个时间步长的数值模拟数据即可训练准确的神经PDE模板算子。

Result: 在多个PDE系统中验证表明，该方法训练的神经模板算子性能优于传统轨迹采样方法，如果能够获得单个完整轨迹模拟数据，准确度可进一步提升。

Conclusion: 提出的数据增强策略显著提高了神经PDE训练的样本效率，仅需少量模拟数据即可获得高质量的神经PDE模型，为实际应用提供了更高效的训练方案。

Abstract: Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.

</details>


### [139] [Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization](https://arxiv.org/abs/2508.19443)
*Paimon Goulart,Shaan Pakala,Evangelos Papalexakis*

Main category: cs.LG

TL;DR: 通过在生成模型中引入张量分解，生成更小的张量因子而非完整张量，从而大幅降低生成多维数据的成本和模型参数数量。


<details>
  <summary>Details</summary>
Motivation: 大规模复杂模拟实验耗费时间和资源，需要更高效的生成合成数据方法来支撑下游任务。

Method: 在GAN或流动模型等生成模型中集成内部张量分解技术，生成小型张量因子来替代直接生成完整的大张量。

Result: 实验结果显示，该方法能够显著降低模型输出大小和总体参数数量，同时保持生成数据的有用性。

Conclusion: 张量分解技术有力地提高了生成模型在处理多维数据时的效率和成本效益。

Abstract: Producing large complex simulation datasets can often be a time and resource
consuming task. Especially when these experiments are very expensive, it is
becoming more reasonable to generate synthetic data for downstream tasks.
Recently, these methods may include using generative machine learning models
such as Generative Adversarial Networks or diffusion models. As these
generative models improve efficiency in producing useful data, we introduce an
internal tensor decomposition to these generative models to even further reduce
costs. More specifically, for multidimensional data, or tensors, we generate
the smaller tensor factors instead of the full tensor, in order to
significantly reduce the model's output and overall parameters. This reduces
the costs of generating complex simulation data, and our experiments show the
generated data remains useful. As a result, tensor decomposition has the
potential to improve efficiency in generative models, especially when
generating multidimensional data, or tensors.

</details>


### [140] [On Surjectivity of Neural Networks: Can you elicit any behavior from your model?](https://arxiv.org/abs/2508.19445)
*Haozhe Jiang,Nika Haghtalab*

Main category: cs.LG

TL;DR: 该论文证明了现代神经网络架构（如预层归一化网络和线性注意力模块）几乎总是满射的，这意味着任何指定输出都可以通过某些输入生成，揭示了生成模型不可避免的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络是否具有满射性，因为满射性意味着任何输出（包括有害内容）都可能被生成，这关系到模型安全性和越狱漏洞问题。

Method: 通过数学证明分析现代神经网络基本构建模块（预层归一化网络、线性注意力模块）的满射性质，并推导出GPT风格transformer和确定性ODE求解器扩散模型的推论。

Result: 证明了这些广泛使用的神经网络架构几乎总是满射的，意味着它们对任意输出都存在逆映射，存在不可避免的安全漏洞。

Conclusion: 该研究提供了一个形式化框架，揭示了现代神经网络架构对广泛对抗攻击的不可避免脆弱性，对模型安全性具有重要意义。

Abstract: Given a trained neural network, can any specified output be generated by some
input? Equivalently, does the network correspond to a function that is
surjective? In generative models, surjectivity implies that any output,
including harmful or undesirable content, can in principle be generated by the
networks, raising concerns about model safety and jailbreak vulnerabilities. In
this paper, we prove that many fundamental building blocks of modern neural
architectures, such as networks with pre-layer normalization and
linear-attention modules, are almost always surjective. As corollaries, widely
used generative frameworks, including GPT-style transformers and diffusion
models with deterministic ODE solvers, admit inverse mappings for arbitrary
outputs. By studying surjectivity of these modern and commonly used neural
architectures, we contribute a formalism that sheds light on their unavoidable
vulnerability to a broad class of adversarial attacks.

</details>


### [141] [The Sample Complexity of Membership Inference and Privacy Auditing](https://arxiv.org/abs/2508.19458)
*Mahdi Haghifam,Adam Smith,Jonathan Ullman*

Main category: cs.LG

TL;DR: 本文研究了成员推理攻击的样本复杂度，发现在高斯均值估计场景中，攻击者需要Ω(n + n²ρ²)个参考样本才能与完全知情的攻击者竞争，这比训练算法使用的样本数量多得多。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推理攻击通常假设攻击者拥有来自相同分布的参考样本，但实际攻击中使用的样本数量有限。本文旨在量化攻击者成功进行成员推理所需的最小参考样本数量。

Method: 研究在高斯均值估计的基本设置下，学习算法从d维高斯分布中获取n个样本来估计均值，期望误差不超过ρ²d。分析攻击者进行成功成员推理所需的最小参考样本数量。

Result: 研究结果表明，对于这种设置下的成员推理，任何能与完全知情攻击者竞争的attack都需要Ω(n + n²ρ²)个样本。这是首次证明攻击者有时需要比训练算法使用的样本数量多得多的样本。

Conclusion: 这一发现对实践有重要意义，因为当前实际使用的攻击都限于使用O(n)个样本的形式，无法受益于ω(n)个样本。这意味着现有攻击可能低估了成员推理的可能性，当分布信息容易获取时，可能存在更好的攻击方法。

Abstract: A membership-inference attack gets the output of a learning algorithm, and a
target individual, and tries to determine whether this individual is a member
of the training data or an independent sample from the same distribution. A
successful membership-inference attack typically requires the attacker to have
some knowledge about the distribution that the training data was sampled from,
and this knowledge is often captured through a set of independent reference
samples from that distribution. In this work we study how much information the
attacker needs for membership inference by investigating the sample
complexity-the minimum number of reference samples required-for a successful
attack. We study this question in the fundamental setting of Gaussian mean
estimation where the learning algorithm is given $n$ samples from a Gaussian
distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate
$\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq
\rho^2 d$. Our result shows that for membership inference in this setting,
$\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that
competes with a fully informed attacker. Our result is the first to show that
the attacker sometimes needs many more samples than the training algorithm uses
to train the model. This result has significant implications for practice, as
all attacks used in practice have a restricted form that uses $O(n)$ samples
and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be
underestimating the possibility of membership inference, and better attacks may
be possible when information about the distribution is easy to obtain.

</details>


### [142] [Incentivized Lipschitz Bandits](https://arxiv.org/abs/2508.19466)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 研究无限臂多臂老虎机中的激励探索问题，通过补偿机制激励短视代理探索，同时处理奖励漂移问题，提出基于空间离散化的算法实现次线性累积遗憾和补偿。


<details>
  <summary>Details</summary>
Motivation: 经典多臂老虎机模型假设臂数有限，但现实应用中臂可能是无限的连续空间。同时，决策者需要激励短视代理进行探索，但激励会引入奖励偏差（奖励漂移），这是一个新的挑战。

Method: 提出新颖的激励探索算法，通过均匀离散化无限臂空间来处理连续度量空间中的无限臂问题。算法同时实现次线性累积遗憾和次线性总补偿。

Result: 算法达到Õ(T^{(d+1)/(d+2)})的遗憾和补偿界，其中d是度量空间的覆盖维度。结果还推广到上下文老虎机场景，获得可比性能保证。数值模拟验证了理论发现。

Conclusion: 该研究成功解决了无限臂多臂老虎机中的激励探索问题，提出的算法能有效处理奖励漂移，在连续度量空间中实现理论性能保证，为实际应用提供了可行方案。

Abstract: We study incentivized exploration in multi-armed bandit (MAB) settings with
infinitely many arms modeled as elements in continuous metric spaces. Unlike
classical bandit models, we consider scenarios where the decision-maker
(principal) incentivizes myopic agents to explore beyond their greedy choices
through compensation, but with the complication of reward drift--biased
feedback arising due to the incentives. We propose novel incentivized
exploration algorithms that discretize the infinite arm space uniformly and
demonstrate that these algorithms simultaneously achieve sublinear cumulative
regret and sublinear total compensation. Specifically, we derive regret and
compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the
covering dimension of the metric space. Furthermore, we generalize our results
to contextual bandits, achieving comparable performance guarantees. We validate
our theoretical findings through numerical simulations.

</details>


### [143] [DeepAtlas: a tool for effective manifold learning](https://arxiv.org/abs/2508.19479)
*Serena Hughes,Timothy Hamilton,Tom Kolokotrones,Eric J. Deeds*

Main category: cs.LG

TL;DR: DeepAtlas算法通过生成数据的局部低维表示并训练深度神经网络来映射局部嵌入与原始数据之间的关系，使用拓扑失真评估数据集是否符合流形假设并确定其维度


<details>
  <summary>Details</summary>
Motivation: 当前流形学习工具只能生成全局嵌入，无法提供数学定义流形所需的局部映射，也不能评估数据集是否符合流形假设

Method: 生成数据局部邻域的低维表示，训练深度神经网络在局部嵌入和原始数据之间进行映射，使用拓扑失真来评估流形假设和确定维度

Result: 在测试数据集上成功学习流形结构，发现许多真实数据集（包括单细胞RNA测序数据）不符合流形假设

Conclusion: 对于符合流形假设的数据，DeepAtlas可以构建生成模型，并为应用微分几何强大工具到各种数据集提供了可能

Abstract: Manifold learning builds on the "manifold hypothesis," which posits that data
in high-dimensional datasets are drawn from lower-dimensional manifolds.
Current tools generate global embeddings of data, rather than the local maps
used to define manifolds mathematically. These tools also cannot assess whether
the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,
an algorithm that generates lower-dimensional representations of the data's
local neighborhoods, then trains deep neural networks that map between these
local embeddings and the original data. Topological distortion is used to
determine whether a dataset is drawn from a manifold and, if so, its
dimensionality. Application to test datasets indicates that DeepAtlas can
successfully learn manifold structures. Interestingly, many real datasets,
including single-cell RNA-sequencing, do not conform to the manifold
hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a
model that can be used generatively and promises to allow the application of
powerful tools from differential geometry to a variety of datasets.

</details>


### [144] [Distribution Shift Aware Neural Tabular Learning](https://arxiv.org/abs/2508.19486)
*Wangyang Ying,Nanxu Gong,Dongjie Wang,Xinyuan Wang,Arun Vignesh Malarkkan,Vivek Gupta,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: SAFT是一个针对分布偏移下表格学习的新框架，通过连续表示生成范式将离散搜索任务转化为可微分优化，整合了抗偏移表示、平坦感知生成和分布对齐三个机制，在各种现实分布偏移场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 表格学习在训练和测试数据存在分布偏移时效果会显著下降，需要解决分布偏移下的表格学习问题。

Method: 提出Shift-Aware Feature Transformation (SAFT)框架：1）通过嵌入去相关和样本重加权实现抗偏移表示；2）通过次优嵌入平均实现平坦感知生成；3）通过归一化实现训练和测试分布对齐。

Result: 大量实验表明SAFT在鲁棒性、有效性和泛化能力方面持续优于先前的表格学习方法。

Conclusion: SAFT成功解决了分布偏移表格学习问题，通过连续表示生成范式显著提升了模型在分布偏移下的性能表现。

Abstract: Tabular learning transforms raw features into optimized spaces for downstream
tasks, but its effectiveness deteriorates under distribution shifts between
training and testing data. We formalize this challenge as the Distribution
Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature
Transformation (SAFT) framework to address it. SAFT reframes tabular learning
from a discrete search task into a continuous representation-generation
paradigm, enabling differentiable optimization over transformed feature sets.
SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant
representation via embedding decorrelation and sample reweighting, (ii)
flatness-aware generation through suboptimal embedding averaging, and (iii)
normalization-based alignment between training and test distributions.
Extensive experiments show that SAFT consistently outperforms prior tabular
learning methods in terms of robustness, effectiveness, and generalization
ability under diverse real-world distribution shifts.

</details>


### [145] [Data-Efficient Symbolic Regression via Foundation Model Distillation](https://arxiv.org/abs/2508.19487)
*Wangyang Ying,Jinghan Zhang,Haoyue Bai,Nanxu Gong,Xinyuan Wang,Kunpeng Liu,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: EQUATE是一个数据高效的符号回归框架，通过质量对齐的迁移嵌入来微调基础模型，在低数据条件下实现更好的方程发现性能


<details>
  <summary>Details</summary>
Motivation: 基础模型在大规模方程数据集上预训练后，在小型领域特定数据集上容易出现负迁移和泛化能力差的问题，需要更有效的数据高效微调方法

Method: 结合符号-数值对齐和评估器引导的嵌入优化，将离散方程搜索重新表述为共享嵌入空间中的连续优化任务，通过数据-方程拟合度和简洁性进行指导

Result: 在三个标准基准测试（Feynman、Strogatz和黑盒数据集）上，EQUATE在准确性和鲁棒性方面均优于最先进的基线方法，同时保持低复杂度和快速推理

Conclusion: EQUATE为基于基础模型蒸馏的数据高效符号回归提供了一个实用且可推广的解决方案

Abstract: Discovering interpretable mathematical equations from observed data (a.k.a.
equation discovery or symbolic regression) is a cornerstone of scientific
discovery, enabling transparent modeling of physical, biological, and economic
systems. While foundation models pre-trained on large-scale equation datasets
offer a promising starting point, they often suffer from negative transfer and
poor generalization when applied to small, domain-specific datasets. In this
paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer
Embeddings), a data-efficient fine-tuning framework that adapts foundation
models for symbolic equation discovery in low-data regimes via distillation.
EQUATE combines symbolic-numeric alignment with evaluator-guided embedding
optimization, enabling a principled embedding-search-generation paradigm. Our
approach reformulates discrete equation search as a continuous optimization
task in a shared embedding space, guided by data-equation fitness and
simplicity. Experiments across three standard public benchmarks (Feynman,
Strogatz, and black-box datasets) demonstrate that EQUATE consistently
outperforms state-of-the-art baselines in both accuracy and robustness, while
preserving low complexity and fast inference. These results highlight EQUATE as
a practical and generalizable solution for data-efficient symbolic regression
in foundation model distillation settings.

</details>


### [146] [PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense](https://arxiv.org/abs/2508.19488)
*Xavier Cadet,Simona Boboila,Sie Hendrata Dharmawan,Alina Oprea,Peter Chin*

Main category: cs.LG

TL;DR: 基于FlipIt游戏框架的PoolFlip多代理环境和Flip-PSRO多代理强化学习方法，通过群体培训训练能够适应未知攻击的防御者


<details>
  <summary>Details</summary>
Motivation: 现有FlipIt框架依赖少数经验法则或专门学习技术，导致脆弱性和无法适应新攻击的问题

Method: 提出PoolFlip多代理gym环境扩展FlipIt游戏，并设计Flip-PSRO多代理强化学习方法，利用群体培训训练防御者

Result: Flip-PSRO防御者在未经训练的经验法则攻击下效果是基线方法的2倍，所有权基于的效用函数确保保持高控制水平

Conclusion: PoolFlip环境和Flip-PSRO方法能够有效地解决网络安全防御中的自动化决策问题，提高防御者对未知适应性攻击的适应能力

Abstract: Cyber defense requires automating defensive decision-making under stealthy,
deceptive, and continuously evolving adversarial strategies. The FlipIt game
provides a foundational framework for modeling interactions between a defender
and an advanced adversary that compromises a system without being immediately
detected. In FlipIt, the attacker and defender compete to control a shared
resource by performing a Flip action and paying a cost. However, the existing
FlipIt frameworks rely on a small number of heuristics or specialized learning
techniques, which can lead to brittleness and the inability to adapt to new
attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym
environment that extends the FlipIt game to allow efficient learning for
attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent
reinforcement learning (MARL) approach that leverages population-based training
to train defender agents equipped to generalize against a range of unknown,
potentially adaptive opponents. Our empirical results suggest that Flip-PSRO
defenders are $2\times$ more effective than baselines to generalize to a
heuristic attack not exposed in training. In addition, our newly designed
ownership-based utility functions ensure that Flip-PSRO defenders maintain a
high level of control while optimizing performance.

</details>


### [147] [Learning Game-Playing Agents with Generative Code Optimization](https://arxiv.org/abs/2508.19506)
*Zhiyi Kuang,Ryan Rong,YuCheng Yuan,Allen Nie*

Main category: cs.LG

TL;DR: 使用Python程序作为策略表示，通过LLM进行代码优化，在Atari游戏中达到与深度强化学习相当的性能，但训练时间和环境交互更少


<details>
  <summary>Details</summary>
Motivation: 探索程序化策略表示方法，通过代码自进化和自然语言反馈来构建高效、适应性强的游戏智能体，减少对人类干预的依赖

Method: 将决策策略表示为Python程序，使用大型语言模型进行代码优化，通过执行轨迹和自然语言反馈实现自我改进

Result: 在Atari游戏中实现了与深度强化学习基线竞争的性能，同时显著减少了训练时间和环境交互次数

Conclusion: 程序化策略表示方法为构建高效、适应性强的智能体提供了有前景的途径，能够处理复杂的长期推理任务

Abstract: We present a generative optimization approach for learning game-playing
agents, where policies are represented as Python programs and refined using
large language models (LLMs). Our method treats decision-making policies as
self-evolving code, with current observation as input and an in-game action as
output, enabling agents to self-improve through execution traces and natural
language feedback with minimal human intervention. Applied to Atari games, our
game-playing Python program achieves performance competitive with deep
reinforcement learning (RL) baselines while using significantly less training
time and much fewer environment interactions. This work highlights the promise
of programmatic policy representations for building efficient, adaptable agents
capable of complex, long-horizon reasoning.

</details>


### [148] [MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data](https://arxiv.org/abs/2508.19554)
*Haruki Yonekura,Ren Ozeki,Tatsuya Amano,Hamada Rizk,Hirozumi Yamaguchi*

Main category: cs.LG

TL;DR: MobText-SISA是一个可扩展的机器遗忘框架，针对异构时空数据扩展了SISA训练方法，通过相似性感知聚类和分片训练实现高效精确的遗忘，同时保持预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现代移动平台存储了大量GPS轨迹和文本数据，GDPR等隐私法规要求按需删除个人数据，但为每个删除请求从头重新训练深度模型不可行。

Method: 将行程的数值和语言特征嵌入共享潜在空间，使用相似性感知聚类将样本分布到分片中，每个分片增量训练，删除时仅重新训练受影响的分片。

Result: 在10个月的真实移动日志实验中，MobText-SISA保持了基线预测准确性，在错误率和收敛速度上始终优于随机分片方法。

Conclusion: MobText-SISA为多模态移动数据的隐私合规分析提供了实用基础，能够在城市规模下实现高效精确的机器遗忘。

Abstract: Modern mobility platforms have stored vast streams of GPS trajectories,
temporal metadata, free-form textual notes, and other unstructured data.
Privacy statutes such as the GDPR require that any individual's contribution be
unlearned on demand, yet retraining deep models from scratch for every request
is untenable. We introduce MobText-SISA, a scalable machine-unlearning
framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)
training to heterogeneous spatio-temporal data. MobText-SISA first embeds each
trip's numerical and linguistic features into a shared latent space, then
employs similarity-aware clustering to distribute samples across shards so that
future deletions touch only a single constituent model while preserving
inter-shard diversity. Each shard is trained incrementally; at inference time,
constituent predictions are aggregated to yield the output. Deletion requests
trigger retraining solely of the affected shard from its last valid checkpoint,
guaranteeing exact unlearning. Experiments on a ten-month real-world mobility
log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,
and (ii) consistently outperforms random sharding in both error and convergence
speed. These results establish MobText-SISA as a practical foundation for
privacy-compliant analytics on multimodal mobility data at urban scale.

</details>


### [149] [Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting](https://arxiv.org/abs/2508.19563)
*Hejia Liu,Mochen Yang,Gediminas Adomavicius*

Main category: cs.LG

TL;DR: LLMs在表格数据拟合中存在严重脆弱性，任务无关的数据表示变化（如变量名更改）可导致预测结果大幅波动，即使专门设计的表格基础模型也未能完全免疫。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在非语言任务中的广泛应用，特别是在表格数据拟合中的使用，需要评估其作为数据拟合工具的稳健性和可靠性。

Method: 通过改变数据表示（如变量名）、分析注意力模式，比较LLMs（包括上下文学习和监督微调）与专门表格基础模型TabPFN在任务无关变化下的预测敏感性。

Result: LLMs对任务无关变化极其敏感，变量名更改可使预测误差波动高达82%，注意力分析显示非均匀分布模式，TabPFN也未能完全免疫。

Conclusion: 尽管LLMs具有强大的预测能力，但目前缺乏基本稳健性，不能作为可靠的数据拟合工具使用。

Abstract: Large Language Models (LLMs) are being applied in a wide array of settings,
well beyond the typical language-oriented use cases. In particular, LLMs are
increasingly used as a plug-and-play method for fitting data and generating
predictions. Prior work has shown that LLMs, via in-context learning or
supervised fine-tuning, can perform competitively with many tabular supervised
learning techniques in terms of predictive performance. However, we identify a
critical vulnerability of using LLMs for data fitting -- making changes to data
representation that are completely irrelevant to the underlying learning task
can drastically alter LLMs' predictions on the same data. For example, simply
changing variable names can sway the size of prediction error by as much as 82%
in certain settings. Such prediction sensitivity with respect to
task-irrelevant variations manifests under both in-context learning and
supervised fine-tuning, for both close-weight and open-weight general-purpose
LLMs. Moreover, by examining the attention scores of an open-weight LLM, we
discover a non-uniform attention pattern: training examples and variable
names/values which happen to occupy certain positions in the prompt receive
more attention when output tokens are generated, even though different
positions are expected to receive roughly the same attention. This partially
explains the sensitivity in the presence of task-irrelevant variations. We also
consider a state-of-the-art tabular foundation model (TabPFN) trained
specifically for data fitting. Despite being explicitly designed to achieve
prediction robustness, TabPFN is still not immune to task-irrelevant
variations. Overall, despite LLMs' impressive predictive capabilities,
currently they lack even the basic level of robustness to be used as a
principled data-fitting tool.

</details>


### [150] [Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models](https://arxiv.org/abs/2508.19564)
*Yuhang Liu,Tao Li,Zhehao Huang,Zuopeng Yang,Xiaolin Huang*

Main category: cs.LG

TL;DR: Bi-LoRA是一种改进的LoRA方法，通过引入辅助LoRA模块来模拟SAM的对抗性权重扰动，在保持内存效率的同时实现更平坦的最小值，消除了SAM的双倍训练成本。


<details>
  <summary>Details</summary>
Motivation: SAM虽然能通过寻找平坦最小值来提高泛化能力，但其巨大的内存和计算开销使其不适用于大型模型。直接将SAM应用于LoRA参数会限制锐度优化的效果。

Method: 提出双向低秩适应(Bi-LoRA)，引入辅助LoRA模块来建模SAM的权重扰动。主LoRA模块通过标准梯度下降适应任务，辅助模块通过梯度上升捕获损失景观的锐度。

Result: 在多种任务和架构上的广泛实验证明了Bi-LoRA在提高泛化能力方面的效率和有效性。

Conclusion: Bi-LoRA通过双模块设计成功解决了SAM在大型模型中的内存和计算效率问题，同时保持了优异的泛化性能。

Abstract: Fine-tuning large-scale pre-trained models with limited data presents
significant challenges for generalization. While Sharpness-Aware Minimization
(SAM) has proven effective in improving generalization by seeking flat minima,
its substantial extra memory and computation overhead make it impractical for
large models. Integrating SAM with parameter-efficient fine-tuning methods like
Low-Rank Adaptation (LoRA) is a promising direction. However, we find that
directly applying SAM to LoRA parameters limits the sharpness optimization to a
restricted subspace, hindering its effectiveness. To address this limitation,
we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an
auxiliary LoRA module to model SAM's adversarial weight perturbations. It
decouples SAM's weight perturbations from LoRA optimization: the primary LoRA
module adapts to specific tasks via standard gradient descent, while the
auxiliary module captures the sharpness of the loss landscape through gradient
ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness
for achieving flatter minima while remaining memory-efficient. Another
important benefit is that the dual design allows for simultaneous optimization
and perturbation, eliminating SAM's doubled training costs. Extensive
experiments across diverse tasks and architectures demonstrate Bi-LoRA's
efficiency and effectiveness in enhancing generalization.

</details>


### [151] [Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning](https://arxiv.org/abs/2508.19567)
*Sheryl Mathew,N Harshit*

Main category: cs.LG

TL;DR: 提出基于因果推理的多模态反事实奖励模型，通过Counterfactual Trust Score减少RLHF中的偏见，在假新闻检测中达到89.12%准确率并提升公平性


<details>
  <summary>Details</summary>
Motivation: 传统RLHF中的奖励模型会放大数据中的潜在偏见，导致策略优化不完善和公平性下降，需要开发偏见弹性奖励信号

Method: 结合因果推理和多模态表示学习，构建反事实奖励模型，包含四个组件：反事实偏移、重构不确定性、公平规则违反检测和时间奖励偏移

Result: 在多模态真假新闻数据集上实现89.12%的假新闻检测准确率，优于基线奖励模型，有效减少虚假相关性和不公平强化信号

Conclusion: 该方法为公平感知RLHF提供了鲁棒且可解释的解决方案，具有可调节的偏见减少阈值，提高了动态实时策略制定的可靠性

Abstract: In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.

</details>


### [152] [Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era](https://arxiv.org/abs/2508.19570)
*Dawei Li,Yue Huang,Ming Li,Tianyi Zhou,Xiangliang Zhang,Huan Liu*

Main category: cs.LG

TL;DR: 本教程介绍了人工智能生成模型在合成数据生成领域的基础知识、最新进展和实践应用，包括大语言模型、扩散模型和生成对抗网络等技术。


<details>
  <summary>Details</summary>
Motivation: 解决数据挖掘中遇到的数据稀缺、隐私保护和标注困难等挑战，通过生成式合成数据提供可扩展的解决方案。

Method: 讲解生成式合成数据生成的关键方法论和实践框架，包括多种生成模型技术的应用。

Result: 为参与者提供可操作的见解，以便在数据挖掘研究和实践中有效利用生成式合成数据。

Conclusion: 生成式合成数据技术为数据挖掘领域带来了革命性的变化，能够有效解决数据相关挑战并推动领域发展。

Abstract: Generative models such as Large Language Models, Diffusion Models, and
generative adversarial networks have recently revolutionized the creation of
synthetic data, offering scalable solutions to data scarcity, privacy, and
annotation challenges in data mining. This tutorial introduces the foundations
and latest advances in synthetic data generation, covers key methodologies and
practical frameworks, and discusses evaluation strategies and applications.
Attendees will gain actionable insights into leveraging generative synthetic
data to enhance data mining research and practice. More information can be
found on our website: https://syndata4dm.github.io/.

</details>


### [153] [Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal](https://arxiv.org/abs/2508.19571)
*Yunlong Lin,Chao Lu,Tongshuai Wu,Xiaocong Zhao,Guodong Du,Yanwei Sun,Zirui Li,Jianwei Gong*

Main category: cs.LG

TL;DR: 提出SyReM方法解决运动预测中持续学习的稳定性-可塑性困境，通过记忆缓冲和选择性重放机制，在防止灾难性遗忘的同时提升新场景学习能力


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在运动预测中面临的灾难性遗忘问题，以及现有持续学习方法过度强调记忆稳定性而损害学习可塑性的困境

Method: SyReM方法维护紧凑记忆缓冲区表示已学知识，使用不等式约束确保记忆稳定性，同时基于损失梯度余弦相似度的选择性记忆重放机制来增强学习可塑性

Result: 在11个自然驾驶数据集上的实验表明，SyReM相比非CL和CL基线方法，显著减轻了过去场景的灾难性遗忘，同时提高了新场景的预测准确性

Conclusion: SyReM有效解决了持续学习中的稳定性-可塑性困境，为深度神经网络在运动预测中的持续学习提供了有效解决方案

Abstract: Deep neural networks (DNN) have achieved remarkable success in motion
forecasting. However, most DNN-based methods suffer from catastrophic
forgetting and fail to maintain their performance in previously learned
scenarios after adapting to new data. Recent continual learning (CL) studies
aim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the
ability to retain learned knowledge. Yet, excessive emphasis on the memory
stability often impairs learning plasticity, i.e., the capacity of DNN to
acquire new information effectively. To address such stability-plasticity
dilemma, this study proposes a novel CL method, synergetic memory rehearsal
(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory
buffer to represent learned knowledge. To ensure memory stability, it employs
an inequality constraint that limits increments in the average loss over the
memory buffer. Synergistically, a selective memory rehearsal mechanism is
designed to enhance learning plasticity by selecting samples from the memory
buffer that are most similar to recently observed data. This selection is based
on an online-measured cosine similarity of loss gradients, ensuring targeted
memory rehearsal. Since replayed samples originate from learned scenarios, this
memory rehearsal mechanism avoids compromising memory stability. We validate
SyReM under an online CL paradigm where training samples from diverse scenarios
arrive as a one-pass stream. Experiments on 11 naturalistic driving datasets
from INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM
significantly mitigates catastrophic forgetting in past scenarios while
improving forecasting accuracy in new ones. The implementation is publicly
available at https://github.com/BIT-Jack/SyReM.

</details>


### [154] [Delta-Audit: Explaining What Changes When Models Change](https://arxiv.org/abs/2508.19589)
*Arshia Hemmat,Afsaneh Fatemi*

Main category: cs.LG

TL;DR: Delta-Attribution是一个模型无关的框架，通过差分特征归因来解释模型版本间的变化原因，提供轻量级的更新审计方法。


<details>
  <summary>Details</summary>
Motivation: 模型更新（超参数、核函数、深度、求解器或数据）会改变性能，但变化的原因往往不透明，需要一种方法来解释版本间的具体变化。

Method: 通过差分每特征归因：Δφ(x)=φ_B(x)-φ_A(x)，使用Δ-归因质量套件评估，包括幅度/稀疏性、一致性/偏移、行为对齐和鲁棒性指标，通过快速遮挡/钳位在标准化空间中实现。

Result: 在45个设置中评估发现，归纳偏置变化产生大的行为对齐delta（如SVC poly→rbf：BAC≈0.998），而"表面"调整显示完美排名重叠和接近零的DCE。最显著的重分布在更深的GB上出现（JSD≈0.357）。

Conclusion: Δ-归因提供了一种轻量级的更新审计方法，通过区分良性变化与行为上有意义或风险依赖转移的变化来补充准确性评估。

Abstract: Model updates (new hyperparameters, kernels, depths, solvers, or data) change
performance, but the \emph{reason} often remains opaque. We introduce
\textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic
framework that explains \emph{what changed} between versions $A$ and $B$ by
differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We
evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering
magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,
Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error,
DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise,
baseline sensitivity, grouped occlusion).
  Instantiated via fast occlusion/clamping in standardized space with a
class-anchored margin and baseline averaging, we audit 45 settings: five
classical families (Logistic Regression, SVC, Random Forests, Gradient
Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B
pairs per family. \textbf{Findings.} Inductive-bias changes yield large,
behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer:
BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits:
BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC
\texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show
rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for
deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a
lightweight update audit that complements accuracy by distinguishing benign
changes from behaviourally meaningful or risky reliance shifts.

</details>


### [155] [Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities](https://arxiv.org/abs/2508.19597)
*Zirui Li,Yunlong Lin,Guodong Du,Xiaocong Zhao,Cheng Gong,Chen Lv,Chao Lu,Jianwei Gong*

Main category: cs.LG

TL;DR: Dual-LS是一种受人类大脑互补学习系统启发的在线持续学习范式，通过双记忆重放机制解决DNN车辆运动预测中的灾难性遗忘问题，显著提升预测稳定性并大幅降低计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 智能城市服务依赖AI，但深度神经网络在车辆运动预测中存在灾难性遗忘问题，传统方法数据收集成本高、样本效率低，且无法平衡长短期经验，无法实现人类般的持续学习。

Method: 提出Dual-LS范式，采用两种协同的记忆重放机制，加速经验检索并动态协调长短期知识表示，实现任务无关的在线持续学习。

Result: 在跨越3个国家、77.2万辆车、累计测试里程11,187公里的自然数据测试中，Dual-LS将灾难性遗忘减少74.31%，计算资源需求降低94.02%，显著提升预测稳定性。

Conclusion: Dual-LS为基于DNN的车辆运动预测提供了计算高效、人类般的持续学习适应性，适合智能城市应用，且不增加数据需求。

Abstract: Artificial intelligence underpins most smart city services, yet deep neural
network (DNN) that forecasts vehicle motion still struggle with catastrophic
forgetting, the loss of earlier knowledge when models are updated. Conventional
fixes enlarge the training set or replay past data, but these strategies incur
high data collection costs, sample inefficiently and fail to balance long- and
short-term experience, leaving them short of human-like continual learning.
Here we introduce Dual-LS, a task-free, online continual learning paradigm for
DNN-based motion forecasting that is inspired by the complementary learning
system of the human brain. Dual-LS pairs two synergistic memory rehearsal
replay mechanisms to accelerate experience retrieval while dynamically
coordinating long-term and short-term knowledge representations. Tests on
naturalistic data spanning three countries, over 772,000 vehicles and
cumulative testing mileage of 11,187 km show that Dual-LS mitigates
catastrophic forgetting by up to 74.31\% and reduces computational resource
demand by up to 94.02\%, markedly boosting predictive stability in vehicle
motion forecasting without inflating data requirements. Meanwhile, it endows
DNN-based vehicle motion forecasting with computation efficient and human-like
continual learning adaptability fit for smart cities.

</details>


### [156] [Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning](https://arxiv.org/abs/2508.19598)
*Zhiwei Li,Yong Hu,Wenqing Wang*

Main category: cs.LG

TL;DR: RLTR框架通过工具使用奖励的强化学习，将LLM智能体的动作规划能力训练与答案总结能力解耦，实现了8%-12%的规划性能提升和5%-6%的最终响应质量改善。


<details>
  <summary>Details</summary>
Motivation: 现有端到端多目标优化训练范式存在目标分配不平衡和可验证数据稀缺的问题，难以有效提升智能体的规划能力。

Method: 提出RLTR框架，通过基于工具使用完整性的奖励信号来直接评估工具调用序列质量，实现规划模块的单目标优化训练。

Result: 实验显示RLTR相比端到端基线在规划性能上提升8%-12%，最终响应质量提升5%-6%。

Conclusion: RLTR通过解耦训练和工具使用奖励机制，有效解决了LLM智能体规划能力训练的挑战，无需可验证数据即可获得显著性能提升。

Abstract: The functionality of Large Language Model (LLM) agents is primarily
determined by two capabilities: action planning and answer summarization. The
former, action planning, is the core capability that dictates an agent's
performance. However, prevailing training paradigms employ end-to-end,
multi-objective optimization that jointly trains both capabilities. This
paradigm faces two critical challenges: imbalanced optimization objective
allocation and scarcity of verifiable data, making it difficult to enhance the
agent's planning capability. To address these challenges, we propose
Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that
decouples the training process to enable a focused, single-objective
optimization of the planning module. Crucially, RLTR introduces a reward signal
based on tool-use completeness to directly evaluate the quality of tool
invocation sequences. This method offers a more direct and reliable training
signal than assessing the final response content, thereby obviating the need
for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%
improvement in planning performance compared to end-to-end baselines. Moreover,
this enhanced planning capability, in turn, translates to a 5%-6% increase in
the final response quality of the overall agent system.

</details>


### [157] [FinCast: A Foundation Model for Financial Time-Series Forecasting](https://arxiv.org/abs/2508.19609)
*Zhuohang Zhu,Haodong Chen,Qiang Qu,Vera Chung*

Main category: cs.LG

TL;DR: FinCast是首个专门为金融时间序列预测设计的基础模型，通过大规模金融数据集训练，在零样本情况下展现出色性能，无需领域特定微调即可捕捉多样化模式，超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测对经济稳定、政策制定和可持续投资至关重要，但由于时间非平稳性、多领域多样性和不同时间分辨率等模式变化而具有挑战性。现有深度学习方法存在过拟合问题且需要大量领域特定微调。

Method: 开发FinCast基础模型，在大规模金融数据集上进行训练，专门针对金融时间序列预测设计，能够处理时间非平稳性、多领域多样性和不同时间分辨率等复杂模式。

Result: FinCast展现出强大的零样本性能，无需领域特定微调即可有效捕捉多样化模式。综合实证和定性评估表明，FinCast超越了现有最先进方法，显示出强大的泛化能力。

Conclusion: FinCast作为首个金融时间序列预测基础模型，成功解决了现有方法的局限性，在零样本情况下实现了卓越性能，为金融预测领域提供了新的解决方案，具有重要的实际应用价值。

Abstract: Financial time-series forecasting is critical for maintaining economic
stability, guiding informed policymaking, and promoting sustainable investment
practices. However, it remains challenging due to various underlying pattern
shifts. These shifts arise primarily from three sources: temporal
non-stationarity (distribution changes over time), multi-domain diversity
(distinct patterns across financial domains such as stocks, commodities, and
futures), and varying temporal resolutions (patterns differing across
per-second, hourly, daily, or weekly indicators). While recent deep learning
methods attempt to address these complexities, they frequently suffer from
overfitting and typically require extensive domain-specific fine-tuning. To
overcome these limitations, we introduce FinCast, the first foundation model
specifically designed for financial time-series forecasting, trained on
large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot
performance, effectively capturing diverse patterns without domain-specific
fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate
that FinCast surpasses existing state-of-the-art methods, highlighting its
strong generalization capabilities.

</details>


### [158] [ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation](https://arxiv.org/abs/2508.19613)
*Chenzhi Liu,Mahsa Baktashmotlagh,Yanran Tang,Zi Huang,Ruihong Qiu*

Main category: cs.LG

TL;DR: ALSA是一种新颖的模型精度估计框架，直接在logit空间中操作，通过锚点建模策略来估计模型在未见未标记数据集上的精度，特别是在分布偏移情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖softmax概率或数据相似性度量，前者存在信息损失，后者计算昂贵且领域特定。需要一种能保留更丰富信息、计算高效且广泛适用的精度估计方法。

Method: ALSA框架在logit空间中初始化多个可学习锚点，每个锚点分配影响函数来捕捉logits的细微变化。基于理论和实证观察，利用logits的聚合和分布与模型预测性能的强相关性。

Result: 在视觉、语言和图基准测试上的大量实验表明，ALSA优于基于softmax和相似性的基线方法，在显著分布偏移下表现出强大的鲁棒性。

Conclusion: ALSA是一个实用的可靠模型评估工具，通过直接在logit空间操作避免了信息损失，提供了跨多种分布偏移的准确性能估计。

Abstract: Estimating model accuracy on unseen, unlabeled datasets is crucial for
real-world machine learning applications, especially under distribution shifts
that can degrade performance. Existing methods often rely on predicted class
probabilities (softmax scores) or data similarity metrics. While softmax-based
approaches benefit from representing predictions on the standard simplex,
compressing logits into probabilities leads to information loss. Meanwhile,
similarity-based methods can be computationally expensive and domain-specific,
limiting their broader applicability. In this paper, we introduce ALSA (Anchors
in Logit Space for Accuracy estimation), a novel framework that preserves
richer information by operating directly in the logit space. Building on
theoretical insights and empirical observations, we demonstrate that the
aggregation and distribution of logits exhibit a strong correlation with the
predictive performance of the model. To exploit this property, ALSA employs an
anchor-based modeling strategy: multiple learnable anchors are initialized in
logit space, each assigned an influence function that captures subtle
variations in the logits. This allows ALSA to provide robust and accurate
performance estimates across a wide range of distribution shifts. Extensive
experiments on vision, language, and graph benchmarks demonstrate ALSA's
superiority over both softmax- and similarity-based baselines. Notably, ALSA's
robustness under significant distribution shifts highlights its potential as a
practical tool for reliable model evaluation.

</details>


### [159] [Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning](https://arxiv.org/abs/2508.19621)
*Tiandi Ye,Wenyan Liu,Kai Yao,Lichun Li,Shangchao Su,Cen Chen,Xiang Li,Shan Yin,Ming Gao*

Main category: cs.LG

TL;DR: pFedBayesPT是一个基于视觉提示调优的细粒度实例级个性化联邦学习框架，通过贝叶斯方法处理客户端内部数据异质性，在特征和标签异质性设置下均优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统个性化联邦学习方法假设每个客户端数据遵循单一分布，但实际中单个客户端可能包含多个来源或领域的数据，存在显著的客户端内部异质性，导致性能不佳

Method: 基于视觉提示调优，从贝叶斯角度制定实例级提示生成，将提示后验建模为隐式分布以捕捉多样化视觉语义，在半隐式变分推断框架下推导变分训练目标

Result: 在基准数据集上的大量实验表明，pFedBayesPT在特征和标签异质性设置下始终优于现有的个性化联邦学习方法

Conclusion: 提出的pFedBayesPT框架有效解决了客户端内部数据异质性挑战，通过实例级个性化方法显著提升了联邦学习性能

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm
that enables collaborative model training across multiple distributed clients
without disclosing their raw data. Personalized federated learning (pFL) has
gained increasing attention for its ability to address data heterogeneity.
However, most existing pFL methods assume that each client's data follows a
single distribution and learn one client-level personalized model for each
client. This assumption often fails in practice, where a single client may
possess data from multiple sources or domains, resulting in significant
intra-client heterogeneity and suboptimal performance. To tackle this
challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework
based on visual prompt tuning. Specifically, we formulate instance-wise prompt
generation from a Bayesian perspective and model the prompt posterior as an
implicit distribution to capture diverse visual semantics. We derive a
variational training objective under the semi-implicit variational inference
framework. Extensive experiments on benchmark datasets demonstrate that
pFedBayesPT consistently outperforms existing pFL methods under both feature
and label heterogeneity settings.

</details>


### [160] [SCAR: A Characterization Scheme for Multi-Modal Dataset](https://arxiv.org/abs/2508.19659)
*Ri Su,Zhao Chen,Caleb Chen Cao,Nan Tang,Lei Chen*

Main category: cs.LG

TL;DR: SCAR是一个数据质量评估框架，通过Scale、Coverage、Authenticity、Richness四个维度量化数据集的结构特性，能够识别保持泛化能力的最小基础数据集，并指导多模态数据的高效扩展。


<details>
  <summary>Details</summary>
Motivation: 传统数据优化方法主要关注数据量和训练效率，缺乏对数据结构性质量的理论理解，特别是在样本缩放时数据特性如何影响泛化能力。需要一种能够捕捉数据集内在结构特性的评估框架。

Method: 提出SCAR框架，通过四个关键指标量化数据集结构特性；识别Foundation Data（保持泛化行为的最小数据集子集）；建模单模态任务为阶跃函数，估计基础数据大小分布；开发基于泛化偏差的SCAR引导数据补全策略。

Result: 在多样化多模态数据集和模型架构上的实验验证了SCAR在预测数据效用和指导数据获取方面的有效性。该方法能够稳定捕捉数据集的结构特性，不受数据集缩放影响。

Conclusion: SCAR提供了一个原则性的数据质量评估框架，能够有效指导多模态数据集的高效扩展，为数据理解和优化提供了理论基础和实践工具。

Abstract: Foundation models exhibit remarkable generalization across diverse tasks,
largely driven by the characteristics of their training data. Recent
data-centric methods like pruning and compression aim to optimize training but
offer limited theoretical insight into how data properties affect
generalization, especially the data characteristics in sample scaling.
Traditional perspectives further constrain progress by focusing predominantly
on data quantity and training efficiency, often overlooking structural aspects
of data quality. In this study, we introduce SCAR, a principled scheme for
characterizing the intrinsic structural properties of datasets across four key
measures: Scale, Coverage, Authenticity, and Richness. Unlike prior
data-centric measures, SCAR captures stable characteristics that remain
invariant under dataset scaling, providing a robust and general foundation for
data understanding. Leveraging these structural properties, we introduce
Foundation Data-a minimal subset that preserves the generalization behavior of
the full dataset without requiring model-specific retraining. We model
single-modality tasks as step functions and estimate the distribution of the
foundation data size to capture step-wise generalization bias across modalities
in the target multi-modal dataset. Finally, we develop a SCAR-guided data
completion strategy based on this generalization bias, which enables efficient,
modality-aware expansion of modality-specific characteristics in multimodal
datasets. Experiments across diverse multi-modal datasets and model
architectures validate the effectiveness of SCAR in predicting data utility and
guiding data acquisition. Code is available at https://github.com/McAloma/SCAR.

</details>


### [161] [Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables](https://arxiv.org/abs/2508.19661)
*Florentia Afentaki,Sri Sai Rakesh Nakkilla,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Shiyi Jiang,Georgios Zervakis,Farshad Firouzi,Krishnendu Chakrabarty,Mehdi B. Tahoori*

Main category: cs.LG

TL;DR: 本文提出了首个针对低功耗柔性应力分类器的全面设计空间探索，涵盖了多种机器学习分类器、特征选择和神经简化算法，设计了1200多个柔性分类器，实现了比现有方法更高精度的实时应力监测。


<details>
  <summary>Details</summary>
Motivation: 传统应力监测依赖间歇性、症状导向的干预，缺乏连续、可及且成本效益高的解决方案。现有硅基可穿戴设备虽然功能多样，但不够轻便灵活，而柔性电子虽具灵活性，但实现复杂机器学习分类器面临集成和功耗挑战。

Method: 进行了全面的设计空间探索，涵盖多种机器学习分类器、特征选择和神经简化算法，设计了1200多个柔性分类器，采用完全定制的低精度算术电路优化硬件效率。

Result: 开发出的柔性应力分类器在精度上超越了现有方法，同时具备低成本、可贴合、低功耗和紧凑尺寸的优势。

Conclusion: 这项工作为设计实时应力分类器提供了重要见解，实现了比当前方法更高的准确性，同时满足了低成本、可贴合性和低功耗的要求，推动了柔性电子在连续健康监测中的应用。

Abstract: Conventional stress monitoring relies on episodic, symptom-focused
interventions, missing the need for continuous, accessible, and cost-efficient
solutions. State-of-the-art approaches use rigid, silicon-based wearables,
which, though capable of multitasking, are not optimized for lightweight,
flexible wear, limiting their practicality for continuous monitoring. In
contrast, flexible electronics (FE) offer flexibility and low manufacturing
costs, enabling real-time stress monitoring circuits. However, implementing
complex circuits like machine learning (ML) classifiers in FE is challenging
due to integration and power constraints. Previous research has explored
flexible biosensors and ADCs, but classifier design for stress detection
remains underexplored. This work presents the first comprehensive design space
exploration of low-power, flexible stress classifiers. We cover various ML
classifiers, feature selection, and neural simplification algorithms, with over
1200 flexible classifiers. To optimize hardware efficiency, fully customized
circuits with low-precision arithmetic are designed in each case. Our
exploration provides insights into designing real-time stress classifiers that
offer higher accuracy than current methods, while being low-cost, conformable,
and ensuring low power and compact size.

</details>


### [162] [$\mathcal{C}^1$-approximation with rational functions and rational neural networks](https://arxiv.org/abs/2508.19672)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 该论文证明了适当正则化的函数可以用有理函数和有理神经网络在C¹范数下近似，并给出了关于网络宽度、深度以及有理函数次数的近似速率。


<details>
  <summary>Details</summary>
Motivation: 研究有理函数和有理神经网络在C¹范数下的近似能力，特别是在符号回归和物理定律学习中的重要应用。

Method: 使用有理函数和有理神经网络进行函数近似，分析其近似速率与网络宽度、深度以及有理函数次数的关系。

Result: 获得了在C¹范数下的近似结果，包括EQL÷和ParFam架构的有理神经网络都能实现有效的C¹近似。

Conclusion: 有理函数和有理神经网络是强大的函数近似工具，在符号回归和物理定律学习等领域具有重要应用价值。

Abstract: We show that suitably regular functions can be approximated in the
$\mathcal{C}^1$-norm both with rational functions and rational neural networks,
including approximation rates with respect to width and depth of the network,
and degree of the rational functions. As consequence of our results, we further
obtain $\mathcal{C}^1$-approximation results for rational neural networks with
the $\text{EQL}^\div$ and ParFam architecture, both of which are important in
particular in the context of symbolic regression for physical law learning.

</details>


### [163] [Metric spaces of walks and Lipschitz duality on graphs](https://arxiv.org/abs/2508.19709)
*R. Arnau,A. González Cortés,E. A. Sánchez Pérez,S. Sanjuan*

Main category: cs.LG

TL;DR: 本文研究了图上行走的度量结构，引入加权度量处理序列，定义了基于逐步顶点距离和加权范数的行走间距离，分析了这些度量空间的性质，并提供了邻近度的表示公式和显式构造方法。


<details>
  <summary>Details</summary>
Motivation: 研究图上行走的度量结构，为分析相对距离测量的较弱形式（邻近度）提供理论基础，并探索在强化学习和网络结构Lipschitz回归中的应用。

Method: 引入加权度量处理序列，定义基于逐步顶点距离和加权范数的行走间距离，分析度量空间性质，提供邻近度的表示公式和显式构造方法。

Result: 建立了行走的度量框架，提供了邻近度的表示公式和构造方法，允许使用经典度量建模工具如Lipschitz函数扩展。

Conclusion: 该度量框架为邻近度估计和基于探索性行走的强化学习策略开发提供了坚实基础，为网络结构上的Lipschitz回归提供了稳健方法。

Abstract: We study the metric structure of walks on graphs, understood as Lipschitz
sequences. To this end, a weighted metric is introduced to handle sequences,
enabling the definition of distances between walks based on stepwise vertex
distances and weighted norms. We analyze the main properties of these metric
spaces, which provides the foundation for the analysis of weaker forms of
instruments to measure relative distances between walks: proximities. We
provide some representation formulas for such proximities under different
assumptions and provide explicit constructions for these cases. The resulting
metric framework allows the use of classical tools from metric modeling, such
as the extension of Lipschitz functions from subspaces of walks, which permits
extending proximity functions while preserving fundamental properties via the
mentioned representations. Potential applications include the estimation of
proximities and the development of reinforcement learning strategies based on
exploratory walks, offering a robust approach to Lipschitz regression on
network structures.

</details>


### [164] [Tune My Adam, Please!](https://arxiv.org/abs/2508.19733)
*Theodoros Athanasiadis,Steven Adriaensen,Samuel Müller,Frank Hutter*

Main category: cs.LG

TL;DR: 提出了Adam-PFN，一种针对Adam优化器超参数调优的预训练代理模型，结合新的学习曲线增强方法CDF-augment，显著提升了学习曲线外推能力和超参数优化效率。


<details>
  <summary>Details</summary>
Motivation: Adam优化器是深度学习中最广泛使用的优化器之一，但其超参数调优过程繁琐且成本高昂。现有的Freeze-thaw贝叶斯优化方法受限于通用代理模型，缺乏对超参数如何影响学习过程的先验知识。

Method: 开发了Adam-PFN代理模型，在TaskSet的学习曲线上进行预训练，并提出了CDF-augment学习曲线增强方法，通过人工增加训练样本数量来提升模型性能。

Result: 该方法在TaskSet评估任务上显著改善了学习曲线外推能力并加速了超参数优化过程，在分布外任务上也表现出强劲性能。

Conclusion: Adam-PFN结合CDF-augment增强方法为Adam优化器的超参数调优提供了有效的解决方案，在保持高性能的同时显著降低了调优成本。

Abstract: The Adam optimizer remains one of the most widely used optimizers in deep
learning, and effectively tuning its hyperparameters is key to optimizing
performance. However, tuning can be tedious and costly. Freeze-thaw Bayesian
Optimization (BO) is a recent promising approach for low-budget hyperparameter
tuning, but is limited by generic surrogates without prior knowledge of how
hyperparameters affect learning. We propose Adam-PFN, a new surrogate model for
Freeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from
TaskSet, together with a new learning curve augmentation method, CDF-augment,
which artificially increases the number of available training examples. Our
approach improves both learning curve extrapolation and accelerates
hyperparameter optimization on TaskSet evaluation tasks, with strong
performance on out-of-distribution (OOD) tasks.

</details>


### [165] [InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections](https://arxiv.org/abs/2508.19737)
*Meng Qin,Weihua Li,Jinqiang Cui,Sen Pei*

Main category: cs.LG

TL;DR: InfraredGP是一种无需训练的图分区方法，通过负校正机制放大低频信息，结合谱GNN和随机输入，实现高效高质量的社区检测


<details>
  <summary>Details</summary>
Motivation: 从图信号处理角度发现，带负校正的图拉普拉斯矩阵可以产生超出常规范围[0,2]的图频率，探索这些低频信息是否能编码更多社区结构信息

Method: 采用谱GNN作为主干网络，结合低通滤波器和负校正机制，仅输入随机信号，通过单次前向传播获得图嵌入，然后使用BIRCH进行聚类

Result: 在IEEE HPEC图挑战基准测试中，InfraredGP在静态和流式图分区任务上实现了16-23倍的速度提升，同时保持有竞争力的质量

Conclusion: 负校正机制能够放大超出常规频率范围的低频信息，仅通过随机输入和单次前向传播即可获得高质量的图分区结果，无需任何训练

Abstract: Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides nodes of a graph into densely-connected blocks. From a perspective
of graph signal processing, we find that graph Laplacian with a negative
correction can derive graph frequencies beyond the conventional range $[0, 2]$.
To explore whether the low-frequency information beyond this range can encode
more informative properties about community structures, we propose InfraredGP.
It (\romannumeral1) adopts a spectral GNN as its backbone combined with
low-pass filters and a negative correction mechanism, (\romannumeral2) only
feeds random inputs to this backbone, (\romannumeral3) derives graph embeddings
via one feed-forward propagation (FFP) without any training, and
(\romannumeral4) obtains feasible GP results by feeding the derived embeddings
to BIRCH. Surprisingly, our experiments demonstrate that based solely on the
negative correction mechanism that amplifies low-frequency information beyond
$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard
clustering modules (e.g., BIRCH) and obtain high-quality results for GP without
any training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate
InfraredGP for both static and streaming GP, where InfraredGP can achieve much
better efficiency (e.g., 16x-23x faster) and competitive quality over various
baselines. We have made our code public at
https://github.com/KuroginQin/InfraredGP

</details>


### [166] [Fast 3D Diffusion for Scalable Granular Media Synthesis](https://arxiv.org/abs/2508.19752)
*Muhammad Moeeze Hassan,Régis Cottereau,Filippo Gatti,Patryk Dec*

Main category: cs.LG

TL;DR: 提出基于3D扩散模型的生成管道，直接合成任意大小的颗粒介质组装体，显著加速离散元法模拟的初始化阶段


<details>
  <summary>Details</summary>
Motivation: 离散元法模拟颗粒介质时，初始化阶段计算成本极高，因为涉及大位移和动能，主导总模拟时间

Method: 两阶段管道：首先训练扩散模型生成独立的3D体素网格；其次使用基于掩码输入的3D修复模型无缝拼接网格，采用多种掩码策略和2D重绘技术

Result: 计算时间与样本大小呈线性缩放，1.2米长的道碴轨道合成仅需20秒，相当于3小时的DEM模拟

Conclusion: 该方法能够实现物理一致、实时、可扩展的颗粒介质合成，适用于工业应用

Abstract: Simulating granular media, using Discrete Element Method is a computationally
intensive task. This is especially true during initialization phase, which
dominates total simulation time because of large displacements involved and
associated kinetic energy. We overcome this bottleneck with a novel generative
pipeline based on 3D diffusion models that directly synthesizes arbitrarily
large granular assemblies in their final and physically realistic
configurations. The approach frames the problem as a 3D generative modeling
task, consisting of a two-stage pipeline. First a diffusion model is trained to
generate independent 3D voxel grids representing granular media. Second, a 3D
inpainting model, adapted from 2D inpainting techniques using masked inputs,
stitches these grids together seamlessly, enabling synthesis of large samples
with physically realistic structure. The inpainting model explores several
masking strategies for the inputs to the underlying UNets by training the
network to infer missing portions of voxel grids from a concatenation of noised
tensors, masks, and masked tensors as input channels. The model also adapts a
2D repainting technique of re-injecting noise scheduler output with ground
truth to provide a strong guidance to the 3D model. This along with weighted
losses ensures long-term coherence over generation of masked regions. Both
models are trained on the same binarized 3D occupancy grids extracted from
small-scale DEM simulations, achieving linear scaling of computational time
with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track
synthesis equivalent to a 3-hour DEM simulation, was completed under 20
seconds. The generated voxel grids can also be post-processed to extract grain
geometries for DEM-compatibility as well, enabling physically coherent,
real-time, scalable granular media synthesis for industrial applications.

</details>


### [167] [Interestingness First Classifiers](https://arxiv.org/abs/2508.19780)
*Ryoma Sato*

Main category: cs.LG

TL;DR: EUREKA框架通过选择有趣而非最准确的特征来构建分类器，利用大语言模型评估特征有趣度，生成既具有预测性又新颖可解释的模型


<details>
  <summary>Details</summary>
Motivation: 传统机器学习追求最高准确率，但有时新颖、出人意料但准确率稍低的特征能提供更有洞察力的发现，特别是在中等准确率足够但需要新颖性和可解释性的场景

Method: 使用大语言模型对特征进行有趣度排序，选择最有趣的特征构建可解释分类器，放弃虽然准确但平凡的特征

Result: 在多个基准数据集上，EUREKA能识别出非显而易见但仍具预测性的特征，如在Occupancy Detection数据集中选择湿度而非CO2，在Twin Papers数据集中发现标题含冒号的论文更可能被引用

Conclusion: 有趣分类器支持新的知识发现和传播方式，在需要新颖性和可解释性的场景中具有重要价值，即使准确率不是最优

Abstract: Most machine learning models are designed to maximize predictive accuracy. In
this work, we explore a different goal: building classifiers that are
interesting. An ``interesting classifier'' is one that uses unusual or
unexpected features, even if its accuracy is lower than the best possible
model. For example, predicting room congestion from CO2 levels achieves
near-perfect accuracy but is unsurprising. In contrast, predicting room
congestion from humidity is less accurate yet more nuanced and intriguing. We
introduce EUREKA, a simple framework that selects features according to their
perceived interestingness. Our method leverages large language models to rank
features by their interestingness and then builds interpretable classifiers
using only the selected interesting features. Across several benchmark
datasets, EUREKA consistently identifies features that are non-obvious yet
still predictive. For example, in the Occupancy Detection dataset, our method
favors humidity over CO2 levels and light intensity, producing classifiers that
achieve meaningful accuracy while offering insights. In the Twin Papers
dataset, our method discovers the rule that papers with a colon in the title
are more likely to be cited in the future. We argue that such models can
support new ways of knowledge discovery and communication, especially in
settings where moderate accuracy is sufficient but novelty and interpretability
are valued.

</details>


### [168] [PSO-Merging: Merging Models Based on Particle Swarm Optimization](https://arxiv.org/abs/2508.19839)
*Kehao Zhang,Shaolei Zhang,Yang Feng*

Main category: cs.LG

TL;DR: PSO-Merging是一种基于粒子群优化的数据驱动模型融合方法，通过初始化粒子群并使用预训练模型、专家模型和稀疏化专家模型，在多次迭代后获得融合模型，在语言模型上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法存在性能限制：数据无关方法缺乏数据驱动指导，梯度方法计算成本高，无梯度方法在有限优化步骤中效果不佳。需要一种高效可扩展的融合方案。

Method: 基于粒子群优化(PSO)算法，初始化粒子群包含预训练模型、专家模型和稀疏化专家模型，通过多次迭代优化，最终选择全局最优粒子作为融合模型。

Result: 在不同语言模型上的实验结果表明，PSO-Merging通常优于基线融合方法，提供了更高效和可扩展的模型融合解决方案。

Conclusion: PSO-Merging成功解决了现有模型融合方法的局限性，通过粒子群优化实现了数据驱动的高效模型融合，为构建多任务模型提供了实用的技术路径。

Abstract: Model merging has emerged as an efficient strategy for constructing multitask
models by integrating the strengths of multiple available expert models,
thereby reducing the need to fine-tune a pre-trained model for all the tasks
from scratch. Existing data-independent methods struggle with performance
limitations due to the lack of data-driven guidance. Data-driven approaches
also face key challenges: gradient-based methods are computationally expensive,
limiting their practicality for merging large expert models, whereas existing
gradient-free methods often fail to achieve satisfactory results within a
limited number of optimization steps. To address these limitations, this paper
introduces PSO-Merging, a novel data-driven merging method based on the
Particle Swarm Optimization (PSO). In this approach, we initialize the particle
swarm with a pre-trained model, expert models, and sparsified expert models. We
then perform multiple iterations, with the final global best particle serving
as the merged model. Experimental results on different language models show
that PSO-Merging generally outperforms baseline merging methods, offering a
more efficient and scalable solution for model merging.

</details>


### [169] [Symplectic convolutional neural networks](https://arxiv.org/abs/2508.19842)
*Süleyman Yıldız,Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 提出了一种新的辛卷积神经网络架构，通过结合辛神经网络、适当辛分解和张量技术，确保卷积层保持辛结构，并在波动方程、非线性薛定谔方程和正弦-戈登方程上表现出优于线性辛自编码器的性能。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络缺乏保持物理系统辛结构的能力，而辛几何在物理系统建模中具有重要意义。需要开发能够保持辛结构的卷积神经网络架构来处理物理系统的动力学问题。

Method: 首先引入卷积层的数学等价形式，然后使用辛神经网络参数化CNN层以确保卷积层保持辛特性。引入辛池化层构建完整的自编码器架构。

Result: 在波动方程、非线性薛定谔方程和正弦-戈登方程三个示例上的数值结果表明，所提出的辛CNN性能优于通过适当辛分解获得的线性辛自编码器。

Conclusion: 成功开发了保持辛结构的卷积神经网络架构，该架构在物理系统建模中表现出优越性能，为物理系统的深度学习建模提供了新的有效工具。

Abstract: We propose a new symplectic convolutional neural network (CNN) architecture
by leveraging symplectic neural networks, proper symplectic decomposition, and
tensor techniques. Specifically, we first introduce a mathematically equivalent
form of the convolution layer and then, using symplectic neural networks, we
demonstrate a way to parameterize the layers of the CNN to ensure that the
convolution layer remains symplectic. To construct a complete autoencoder, we
introduce a symplectic pooling layer. We demonstrate the performance of the
proposed neural network on three examples: the wave equation, the nonlinear
Schr\"odinger (NLS) equation, and the sine-Gordon equation. The numerical
results indicate that the symplectic CNN outperforms the linear symplectic
autoencoder obtained via proper symplectic decomposition.

</details>


### [170] [Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources](https://arxiv.org/abs/2508.19847)
*Erdi Kara,Panos Stinis*

Main category: cs.LG

TL;DR: 提出混合框架结合有限元法和物理信息DeepONet，用于多孔介质中尖锐高斯源引起的流体输运建模，实现高精度流动场和快速输运推断


<details>
  <summary>Details</summary>
Motivation: 传统方法处理多孔介质中尖锐局部源引起的流体输运问题时计算成本高，需要既能保持流动场精度又能快速推断输运动力学的解决方案

Method: 使用FEM求解达西流动方程获得速度场，然后通过物理信息DeepONet学习从源函数到溶质浓度分布的映射，并引入自适应采样策略处理陡峭梯度

Result: 数值实验表明该方法与参考解吻合良好，相比传统求解器实现数量级加速，适用于实际应用场景

Conclusion: 该混合框架成功结合了FEM的精度优势和DeepONet的快速推断能力，为多孔介质流体输运问题提供了高效准确的解决方案

Abstract: We present a hybrid framework that couples finite element methods (FEM) with
physics-informed DeepONet to model fluid transport in porous media from sharp,
localized Gaussian sources. The governing system consists of a steady-state
Darcy flow equation and a time-dependent convection-diffusion equation. Our
approach solves the Darcy system using FEM and transfers the resulting velocity
field to a physics-informed DeepONet, which learns the mapping from source
functions to solute concentration profiles. This modular strategy preserves
FEM-level accuracy in the flow field while enabling fast inference for
transport dynamics. To handle steep gradients induced by sharp sources, we
introduce an adaptive sampling strategy for trunk collocation points. Numerical
experiments demonstrate that our method is in good agreement with the reference
solutions while offering orders of magnitude speedups over traditional solvers,
making it suitable for practical applications in relevant scenarios.
Implementation of our proposed method is available at
https://github.com/erkara/fem-pi-deeponet.

</details>


### [171] [Quantum latent distributions in deep generative models](https://arxiv.org/abs/2508.19857)
*Omar Bacarreza,Thorin Farnsworth,Alexander Makarovskiy,Hugo Wallner,Tessa Hicks,Santiago Sempere-Llagostera,John Price,Robert J. A. Francis-Jones,William R. Clements*

Main category: cs.LG

TL;DR: 量子潜在分布可以提升生成模型的性能，在某些条件下能够产生经典潜在分布无法高效生成的数据分布。实验证明量子处理器能够扩展深度生成模型的能力。


<details>
  <summary>Details</summary>
Motivation: 虽然简单潜在分布在生成模型中很常见，但更复杂的分布可以提升性能。量子处理器产生的分布已被证明能带来经验性改进，但何时以及如何实现这种改进尚不清楚。

Method: 通过理论证明和实验验证，研究量子潜在分布在生成模型中的应用。在合成量子数据集和QM9分子数据集上进行基准测试，使用模拟和真实的光子量子处理器，比较GAN、扩散模型和流匹配模型。

Result: 量子潜在分布在GAN中相比多种经典基线能够带来生成性能的提升，并确定了与量子潜在分布兼容的架构。

Conclusion: 近期量子处理器确实能够扩展深度生成模型的能力，量子潜在分布在特定条件下具有经典方法无法比拟的优势。

Abstract: Many successful families of generative models leverage a low-dimensional
latent distribution that is mapped to a data distribution. Though simple latent
distributions are commonly used, it has been shown that more sophisticated
distributions can improve performance. For instance, recent work has explored
using the distributions produced by quantum processors and found empirical
improvements. However, when latent space distributions produced by quantum
processors can be expected to improve performance, and whether these
improvements are reproducible, are open questions that we investigate in this
work. We prove that, under certain conditions, these "quantum latent
distributions" enable generative models to produce data distributions that
classical latent distributions cannot efficiently produce. We also provide
actionable intuitions to identify when such quantum advantages may arise in
real-world settings. We perform benchmarking experiments on both a synthetic
quantum dataset and the QM9 molecular dataset, using both simulated and real
photonic quantum processors. Our results demonstrate that quantum latent
distributions can lead to improved generative performance in GANs compared to a
range of classical baselines. We also explore diffusion and flow matching
models, identifying architectures compatible with quantum latent distributions.
This work confirms that near-term quantum processors can expand the
capabilities of deep generative models.

</details>


### [172] [Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks](https://arxiv.org/abs/2508.19884)
*Mingyue Kong,Yinglong Zhang,Chengda Xu,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: 本文提出了一种基于结构多样性的无参数图神经网络框架SDGNN，通过结构多样性消息传递机制同时捕获邻域结构异质性和特征语义稳定性，无需训练参数即可在多种挑战性条件下超越主流GNN方法。


<details>
  <summary>Details</summary>
Motivation: 传统GNN方法依赖大量可训练参数和固定聚合规则，难以适应结构异质性强的图数据，容易导致节点表示过平滑和语义退化问题。

Method: 提出SDGNN框架，基于结构多样性理论设计统一的结构多样性消息传递机制，从结构驱动和特征驱动两个角度进行互补建模，不引入额外可训练参数。

Result: 在8个公共基准数据集和跨学科PubMed引文网络上，SDGNN在低监督、类别不平衡和跨域迁移等挑战性条件下 consistently 优于主流GNN方法。

Conclusion: 该工作为无参数图神经网络设计提供了新的理论视角和通用方法，验证了结构多样性作为图表示学习核心信号的重要性。

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in structured
data modeling tasks such as node classification. However, mainstream approaches
generally rely on a large number of trainable parameters and fixed aggregation
rules, making it difficult to adapt to graph data with strong structural
heterogeneity and complex feature distributions. This often leads to
over-smoothing of node representations and semantic degradation. To address
these issues, this paper proposes a parameter-free graph neural network
framework based on structural diversity, namely SDGNN (Structural-Diversity
Graph Neural Network). The framework is inspired by structural diversity theory
and designs a unified structural-diversity message passing mechanism that
simultaneously captures the heterogeneity of neighborhood structures and the
stability of feature semantics, without introducing additional trainable
parameters. Unlike traditional parameterized methods, SDGNN does not rely on
complex model training, but instead leverages complementary modeling from both
structure-driven and feature-driven perspectives, thereby effectively improving
adaptability across datasets and scenarios. Experimental results show that on
eight public benchmark datasets and an interdisciplinary PubMed citation
network, SDGNN consistently outperforms mainstream GNNs under challenging
conditions such as low supervision, class imbalance, and cross-domain transfer.
This work provides a new theoretical perspective and general approach for the
design of parameter-free graph neural networks, and further validates the
importance of structural diversity as a core signal in graph representation
learning. To facilitate reproducibility and further research, the full
implementation of SDGNN has been released at:
https://github.com/mingyue15694/SGDNN/tree/main

</details>


### [173] [NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs](https://arxiv.org/abs/2508.19896)
*Davorin Miličević,Ratko Grbić*

Main category: cs.LG

TL;DR: NM-Hebb是一个两阶段训练框架，结合神经启发的局部可塑性和距离感知监督，通过Hebbian正则化和可学习神经调节器提升CNN性能，在多个数据集和骨干网络上实现准确率显著提升和更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统CNN依赖全局梯度优化，容易导致过拟合、冗余滤波器和可解释性降低。为了解决这些问题，需要结合神经科学启发的局部可塑性机制来改善网络训练效果。

Method: 两阶段训练框架：第一阶段结合交叉熵损失与Hebbian正则器（对齐激活空间均值与滤波器权重均值）和可学习神经调节器；第二阶段使用成对度量学习损失进行微调，压缩类内距离并扩大类间边界。

Result: 在CIFAR-10、CIFAR-100和TinyImageNet上，使用5种骨干网络（ResNet-18、VGG-11等），Top-1准确率提升2.0-10.0个百分点，NMI提升最高0.15，产生更结构化、选择性更强的特征和更紧密的类簇。

Conclusion: 将局部Hebbian可塑性与基于度量的微调相结合，不仅提高了CNN的准确性，还增强了可解释性，为资源受限和安全关键的AI部署提供了实际益处。

Abstract: Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often
rely on purely global, gradient-based optimisation, which can lead to
overfitting, redundant filters, and reduced interpretability. To address these
limitations, we propose NM-Hebb, a two-phase training framework that integrates
neuro-inspired local plasticity with distance-aware supervision. Phase 1
extends standard supervised training by jointly optimising a cross-entropy
objective with two biologically inspired mechanisms: (i) a Hebbian regulariser
that aligns the spatial mean of activations with the mean of the corresponding
convolutional filter weights, encouraging structured, reusable primitives; and
(ii) a learnable neuromodulator that gates an elastic-weight-style
consolidation loss, preserving beneficial parameters without freezing the
network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,
explicitly compressing intra-class distances and enlarging inter-class margins
in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet
across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,
DenseNet-121), NM-Hebb achieves consistent gains over baseline and other
methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp
(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual
Information (NMI) increased by up to +0.15. Qualitative visualisations and
filter-level analyses further confirm that NM-Hebb produces more structured and
selective features, yielding tighter and more interpretable class clusters.
Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields
CNNs that are not only more accurate but also more interpretable, offering
practical benefits for resource-constrained and safety-critical AI deployments.

</details>


### [174] [Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning](https://arxiv.org/abs/2508.19900)
*Tan Jing,Xiaorui Li,Chao Yao,Xiaojuan Ban,Yuetong Fang,Renjing Xu,Zhaolin Yuan*

Main category: cs.LG

TL;DR: ASPC是一种自适应策略约束缩放框架，通过二阶可微分方法动态平衡强化学习和行为克隆，无需针对不同数据集手动调参，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习方法需要针对不同任务和数据集质量精心调整超参数来应对分布偏移问题，这既耗时又不实用。

Method: 提出自适应策略约束缩放(ASPC)框架，使用二阶可微分方法在训练过程中动态平衡强化学习和行为克隆，避免手动超参数调优。

Result: 在4个D4RL领域的39个数据集上，ASPC使用单一超参数配置就超越了其他自适应约束方法和需要逐数据集调优的最先进算法，且计算开销极小。

Conclusion: ASPC提供了一个有效且实用的解决方案，能够自动适应不同数据集特性，显著简化离线强化学习的部署过程。

Abstract: Offline reinforcement learning (RL) enables learning effective policies from
fixed datasets without any environment interaction. Existing methods typically
employ policy constraints to mitigate the distribution shift encountered during
offline RL training. However, because the scale of the constraints varies
across tasks and datasets of differing quality, existing methods must
meticulously tune hyperparameters to match each dataset, which is
time-consuming and often impractical. We propose Adaptive Scaling of Policy
Constraints (ASPC), a second-order differentiable framework that dynamically
balances RL and behavior cloning (BC) during training. We theoretically analyze
its performance improvement guarantee. In experiments on 39 datasets across
four D4RL domains, ASPC using a single hyperparameter configuration outperforms
other adaptive constraint methods and state-of-the-art offline RL algorithms
that require per-dataset tuning while incurring only minimal computational
overhead. The code will be released at https://github.com/Colin-Jing/ASPC.

</details>


### [175] [GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs](https://arxiv.org/abs/2508.19907)
*Hewen Wang,Renchi Yang,Xiaokui Xiao*

Main category: cs.LG

TL;DR: GegenNet是一个针对符号二分图链接符号预测的新型谱卷积神经网络模型，通过Gegenbauer多项式基滤波器实现了显著的性能提升


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单分图设计，忽略了符号二分图的节点异质性和独特特征，且传统谱卷积算子不适合从已知链接推断缺失的正负链接

Method: 使用快速谱分解技术初始化节点特征，基于Gegenbauer多项式基构建新的谱图滤波器，采用多层符号感知谱卷积网络交替处理正负边

Result: 在6个基准SBG数据集上，相比11个强基线方法，AUC提升最高达4.28%，F1分数提升最高达11.69%

Conclusion: GegenNet通过创新的谱卷积设计有效解决了符号二分图链接符号预测问题，在多个指标上实现了显著性能提升

Abstract: Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,
the goal of link sign prediction is to predict the signs of potential links
connecting U and V based on known positive and negative edges in G. The
majority of existing solutions towards link sign prediction mainly focus on
unipartite signed graphs, which are sub-optimal due to the neglect of node
heterogeneity and unique bipartite characteristics of SBGs. To this end, recent
studies adapt graph neural networks to SBGs by introducing message-passing
schemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node
pairs. However, the fundamental spectral convolutional operators were
originally designed for positive links in unsigned graphs, and thus, are not
optimal for inferring missing positive or negative links from known ones in
SBGs.
  Motivated by this, this paper proposes GegenNet, a novel and effective
spectral convolutional neural network model for link sign prediction in SBGs.
In particular, GegenNet achieves enhanced model capacity and high predictive
accuracy through three main technical contributions: (i) fast and theoretically
grounded spectral decomposition techniques for node feature initialization;
(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and
(iii) multi-layer sign-aware spectral convolutional networks alternating
Gegenbauer polynomial filters with positive and negative edges. Our extensive
empirical studies reveal that GegenNet can achieve significantly superior
performance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign
prediction compared to 11 strong competitors over 6 benchmark SBG datasets.

</details>


### [176] [Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling](https://arxiv.org/abs/2508.19915)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.LG

TL;DR: 提出基于UMLS本体论的概念驱动方法，替代传统高维文本嵌入，用于放射学报告的检索增强学习，在长尾医疗影像任务中表现更优且可解释性更强


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP或CXR-BERT等高维文本嵌入的方法难以解释、计算成本高，且与医学知识的结构化特性不匹配，需要更透明、可解释的检索方法

Method: 使用RadGraph-XL和SapBERT增强管道从自由文本报告中提取标准化医学实体，链接到UMLS概念，基于改进的加权Tversky指数定义任务自适应相似度度量

Result: 在MIMIC-CXR的X光分类任务中优于最先进的基于嵌入的检索方法，特别是在长尾场景下，并为MIMIC-CXR生成了本体支持的新疾病标签资源

Conclusion: 该方法为临床AI系统提供了更可解释、可靠和任务特定的检索策略，特别适用于需要可解释性和领域知识整合的场景

Abstract: Retrieval-augmented learning based on radiology reports has emerged as a
promising direction to improve performance on long-tail medical imaging tasks,
such as rare disease detection in chest X-rays. Most existing methods rely on
comparing high-dimensional text embeddings from models like CLIP or CXR-BERT,
which are often difficult to interpret, computationally expensive, and not
well-aligned with the structured nature of medical knowledge. We propose a
novel, ontology-driven alternative for comparing radiology report texts based
on clinically grounded concepts from the Unified Medical Language System
(UMLS). Our method extracts standardised medical entities from free-text
reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These
entities are linked to UMLS concepts (CUIs), enabling a transparent,
interpretable set-based representation of each report. We then define a
task-adaptive similarity measure based on a modified and weighted version of
the Tversky Index that accounts for synonymy, negation, and hierarchical
relationships between medical entities. This allows efficient and semantically
meaningful similarity comparisons between reports. We demonstrate that our
approach outperforms state-of-the-art embedding-based retrieval methods in a
radiograph classification task on MIMIC-CXR, particularly in long-tail
settings. Additionally, we use our pipeline to generate ontology-backed disease
labels for MIMIC-CXR, offering a valuable new resource for downstream learning
tasks. Our work provides more explainable, reliable, and task-specific
retrieval strategies in clinical AI systems, especially when interpretability
and domain knowledge integration are essential. Our code is available at
https://github.com/Felix-012/ontology-concept-distillation

</details>


### [177] [FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification](https://arxiv.org/abs/2508.19924)
*Liming Liu,Ruoyu Li,Qing Li,Meijia Hou,Yong Jiang,Mingwei Xu*

Main category: cs.LG

TL;DR: FlowletFormer是一个基于BERT的预训练模型，专门用于网络流量分析，通过创新的流量分割、协议语义嵌入和特定预训练任务，显著提升了流量分类准确性和少样本学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有网络流量分类方法难以有效捕捉数据包结构特征、流级行为、分层协议语义和包间上下文关系，需要设计专门的预训练模型来解决这些挑战。

Method: 提出FlowletFormer模型，包含：1）连贯行为感知流量表示模型用于语义分割；2）协议栈对齐嵌入层捕获多层协议语义；3）字段特定和上下文感知预训练任务增强包间和流间学习。

Result: 实验结果表明FlowletFormer在流量表示效果、分类准确性和少样本学习能力方面显著优于现有方法，并能更好地理解网络传输原理（如TCP状态连接）。

Conclusion: FlowletFormer通过有效整合领域特定的网络知识，为流量分析提供了更鲁棒和可信的框架，在多个关键指标上表现出色。

Abstract: Network traffic classification using pre-training models has shown promising
results, but existing methods struggle to capture packet structural
characteristics, flow-level behaviors, hierarchical protocol semantics, and
inter-packet contextual relationships. To address these challenges, we propose
FlowletFormer, a BERT-based pre-training model specifically designed for
network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware
Traffic Representation Model for segmenting traffic into semantically
meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture
multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining
Tasks to enhance both inter-packet and inter-flow learning. Experimental
results demonstrate that FlowletFormer significantly outperforms existing
methods in the effectiveness of traffic representation, classification
accuracy, and few-shot learning capability. Moreover, by effectively
integrating domain-specific network knowledge, FlowletFormer shows better
comprehension of the principles of network transmission (e.g., stateful
connections of TCP), providing a more robust and trustworthy framework for
traffic analysis.

</details>


### [178] [Global Permutation Entropy](https://arxiv.org/abs/2508.19955)
*Abhijeet Avhale,Joscha Diehl,Niraj Velankar,Emanuele Verri*

Main category: cs.LG

TL;DR: 提出了全局排列熵(GPE)，一种考虑所有可能模式（包括非连续模式）的新复杂度指标，相比传统排列熵能揭示更多结构信息


<details>
  <summary>Details</summary>
Motivation: 传统排列熵只考虑连续段落的相对顺序模式，可能遗漏非连续模式中的重要结构信息，需要更全面的复杂度度量方法

Method: 基于新开发的算法高效提取完整排列轮廓，计算所有给定长度的可能模式（包括非连续模式）的频率分布，然后应用香农熵进行量化

Result: 在合成数据集上的实验表明，GPE能够揭示标准排列熵无法获取的结构信息，具有更好的效果

Conclusion: 全局排列熵是一个有效的复杂度度量工具，提供了比传统方法更全面的时间序列结构分析能力

Abstract: Permutation Entropy, introduced by Bandt and Pompe, is a widely used
complexity measure for real-valued time series that is based on the relative
order of values within consecutive segments of fixed length. After
standardizing each segment to a permutation and computing the frequency
distribution of these permutations, Shannon Entropy is then applied to quantify
the series' complexity. We introduce Global Permutation Entropy (GPE), a novel
index that considers all possible patterns of a given length, including
non-consecutive ones. Its computation relies on recently developed algorithms
that enable the efficient extraction of full permutation profiles. We
illustrate some properties of GPE and demonstrate its effectiveness through
experiments on synthetic datasets, showing that it reveals structural
information not accessible through standard permutation entropy. We provide a
Julia package for the calculation of GPE at
`https://github.com/AThreeH1/Global-Permutation-Entropy'.

</details>


### [179] [Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning](https://arxiv.org/abs/2508.19974)
*Khaled M. A. Alghtus,Aiyad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 基于机器学习的工业离心泵短期故障预测框架，使用随机森林和XGBoost模型，通过60分钟和120分钟滑动窗口提取统计特征，在5-30分钟预测范围内取得最佳召回率69.2%


<details>
  <summary>Details</summary>
Motivation: 为了解决工业离心泵的实时故障预测问题，提前预警设备故障，实现预测性维护，减少停机时间和维护成本

Method: 使用滑动窗口方法（60分钟和120分钟）提取统计特征（均值、标准差、最小值、最大值、线性趋势），采用SMOTE算法处理类别不平衡，训练随机森林和XGBoost分类器进行多时间尺度预测

Result: 随机森林模型在60分钟窗口下表现最佳：5分钟预测召回率69.2%，15分钟64.9%，30分钟48.6%；120分钟窗口下15和30分钟预测召回率提升至65.6%

Conclusion: 预测性能受历史数据长度和预测时间尺度影响，不同故障模式具有不同的时间演化特征，该方法为实时工业监控系统提供了可解释且可扩展的预测性维护解决方案

Abstract: This study presents a machine learning framework for forecasting short-term
faults in industrial centrifugal pumps using real-time sensor data. The
approach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in
advance based on patterns extracted from historical operation. Two lookback
periods, 60 minutes and 120 minutes, were evaluated using a sliding window
approach. For each window, statistical features including mean, standard
deviation, minimum, maximum, and linear trend were extracted, and class
imbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost
classifiers were trained and tested on the labeled dataset. Results show that
the Random Forest model achieved the best short-term forecasting performance
with a 60-minute window, reaching recall scores of 69.2\% at 5 minutes, 64.9\%
at 15 minutes, and 48.6\% at 30 minutes. With a 120-minute window, the Random
Forest model achieved 57.6\% recall at 5 minutes, and improved predictive
accuracy of 65.6\% at both 15 and 30 minutes. XGBoost displayed similar but
slightly lower performance. These findings highlight that optimal history
length depends on the prediction horizon, and that different fault patterns may
evolve at different timescales. The proposed method offers an interpretable and
scalable solution for integrating predictive maintenance into real-time
industrial monitoring systems.

</details>


### [180] [Reducing Street Parking Search Time via Smart Assignment Strategies](https://arxiv.org/abs/2508.19979)
*Behafarid Hemmatpour,Javad Dogani,Nikolaos Laoutaris*

Main category: cs.LG

TL;DR: 这篇论文通过数据驱动模拟分析了不同停车搜索策略在马德里市区的效果，提出的Cord-Approx策略将停车搜索时间减少72-73%


<details>
  <summary>Details</summary>
Motivation: 域市密集地区的路边停车搜索加剧了交通拕塞，尽管有手机应用辅助，但其效果待验证

Method: 基于马德里实际交通数据的高保真模拟，比较四种停车策略：无协调搜索、协调无非用户知识、理想神谕系统和新题Cord-Approx策略（利用历史占用分布估计非用户行为，通过包含利问匹配问题进行调度）

Result: Cord-Approx用户平均停车搜索时间仅6.69分钟，较无应用的用户（19.98分钟）减少66.5%。在中央商务区搜索时间减少72%（67-76%范围），住宅区可达73%

Conclusion: Cord-Approx策略通过概率性估计非用户行为，能够实现接近理想神谕系统的性能，显著缩短停车搜索时间并缓解域市交通拕塞

Abstract: In dense metropolitan areas, searching for street parking adds to traffic
congestion. Like many other problems, real-time assistants based on mobile
phones have been proposed, but their effectiveness is understudied. This work
quantifies how varying levels of user coordination and information availability
through such apps impact search time and the probability of finding street
parking. Through a data-driven simulation of Madrid's street parking ecosystem,
we analyze four distinct strategies: uncoordinated search (Unc-Agn),
coordinated parking without awareness of non-users (Cord-Agn), an idealized
oracle system that knows the positions of all non-users (Cord-Oracle), and our
novel/practical Cord-Approx strategy that estimates non-users' behavior
probabilistically. The Cord-Approx strategy, instead of requiring knowledge of
how close non-users are to a certain spot in order to decide whether to
navigate toward it, uses past occupancy distributions to elongate physical
distances between system users and alternative parking spots, and then solves a
Hungarian matching problem to dispatch accordingly. In high-fidelity
simulations of Madrid's parking network with real traffic data, users of
Cord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes
for non-users without an app. A zone-level snapshot shows that Cord-Approx
reduces search time for system users by 72% (range = 67-76%) in central hubs,
and up to 73% in residential areas, relative to non-users.

</details>


### [181] [Evaluating Language Model Reasoning about Confidential Information](https://arxiv.org/abs/2508.19980)
*Dylan Sam,Alexander Robey,Andy Zou,Matt Fredrikson,J. Zico Kolter*

Main category: cs.LG

TL;DR: 语言模型在密码验证任务中表现不佳，推理能力反而会泄露机密信息，当前前沿模型不适合处理机密信息


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在关键场景中作为自主代理部署，确保其可靠遵循用户定义规则已成为关键安全问题，需要研究模型是否具备上下文鲁棒性

Method: 开发PasswordEval基准测试，测量语言模型在密码验证任务中的表现，通过对抗性用户压力和长对话增加测试难度

Result: 当前开源和闭源模型在这个看似简单的任务中表现不佳，推理能力通常不会改善性能，反而经常泄露机密信息

Conclusion: 当前前沿模型不适合处理机密信息，推理能力需要以不同方式训练才能在高风险场景中安全部署

Abstract: As language models are increasingly deployed as autonomous agents in
high-stakes settings, ensuring that they reliably follow user-defined rules has
become a critical safety concern. To this end, we study whether language models
exhibit contextual robustness, or the capability to adhere to context-dependent
safety specifications. For this analysis, we develop a benchmark (PasswordEval)
that measures whether language models can correctly determine when a user
request is authorized (i.e., with a correct password). We find that current
open- and closed-source models struggle with this seemingly simple task, and
that, perhaps surprisingly, reasoning capabilities do not generally improve
performance. In fact, we find that reasoning traces frequently leak
confidential information, which calls into question whether reasoning traces
should be exposed to users in such applications. We also scale the difficulty
of our evaluation along multiple axes: (i) by adding adversarial user pressure
through various jailbreaking strategies, and (ii) through longer multi-turn
conversations where password verification is more challenging. Overall, our
results suggest that current frontier models are not well-suited to handling
confidential information, and that reasoning capabilities may need to be
trained in a different manner to make them safer for release in high-stakes
settings.

</details>


### [182] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 提出一种新的自监督预训练方法，通过双层优化和均衡约束处理异构数据，提升下游任务的适应性


<details>
  <summary>Details</summary>
Motivation: 传统自监督预训练方法在处理异构数据时简单混合所有数据并最小化全局平均损失，无法保证模型对每个异构数据源都达到局部最优

Method: 采用双层优化框架，通过K步梯度下降确保模型从初始状态出发能为每个异构数据源达到局部最优，使用一阶近似方法求解

Result: 在多领域和多语言数据集上的实验表明，该方法能显著提升自监督预训练模型在下游监督微调任务中的适应性

Conclusion: 所提出的均衡约束和双层优化方法能有效处理异构数据，提高自监督预训练模型在下游任务中的性能

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [183] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于梯度的示例选择算法，通过梯度估计模型输出并聚合影响分数来选择最相关的示例，在保持准确性的同时大幅提升选择效率。


<details>
  <summary>Details</summary>
Motivation: 解决在上下文学习中如何高效选择最佳示例集的问题，充分利用固定模型权重来提升提示调整和链式思绪的性能。

Method: 通过梯度估计模型输出，使用一阶近似方法在输入嵌入空间中计算。随机采样多个子集并聚合结果形成影响分数，最终选择最相关的k个示例。

Result: 在六个数据集上实现了小于1%的误差，选择速度提升37.7倍，在达到340亿参数的模型上优于现有方法平均11%。

Conclusion: 梯度基的示例选择算法能够在线性时间复杂度内高效选择最佳示例，为大规模模型的上下文学习提供了可扩展的解决方案。

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [184] [Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach](https://arxiv.org/abs/2508.20013)
*Lotte Gross,Rebecca Walter,Nicole Zoppi,Adrien Justus,Alessandro Gambetti,Qiwei Han,Maximilian Kaiser*

Main category: cs.LG

TL;DR: 该研究开发了一个多模态层次分类框架来解决电商产品分类中的平台异构性和现有分类法结构限制问题，通过融合文本、视觉和视觉-语言特征，在27万+产品数据上实现了98.59%的层次F1分数，并展示了工业部署的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决电商产品分类中的两个关键工业挑战：平台异构性（不同电商平台的产品分类标准不一致）和现有分类法的结构限制（分类层次浅或不一致），需要开发能够跨平台通用且能处理层次分类的多模态方法。

Method: 使用27.17万个来自40个国际时尚电商平台的产品数据，整合RoBERTa文本特征、ViT视觉特征和CLIP视觉-语言表示。研究早期融合、晚期融合和基于注意力的融合策略，在层次架构中采用动态掩码确保分类一致性。还引入了基于SimCLR、UMAP和级联聚类的自监督产品重分类流程。

Result: CLIP嵌入通过MLP-based晚期融合策略获得最高层次F1分数（98.59%），优于单模态基线。自监督重分类流程发现了新的细粒度类别（如鞋子子类型），聚类纯度超过86%。跨平台实验显示复杂晚期融合方法在多样化训练数据上精度最高，而简单早期融合方法对未见平台泛化更好。

Conclusion: 该多模态层次分类框架成功解决了电商产品分类的工业挑战，通过两阶段推理管道（轻量级RoBERTa阶段+GPU加速多模态阶段）在商业交易智能平台中实现了成本与精度的平衡，证明了工业可扩展性。

Abstract: This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

</details>


### [185] [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment](https://arxiv.org/abs/2508.20015)
*Julian Arnold,Niels Lörch*

Main category: cs.LG

TL;DR: 该论文开发了一个检测微调过程中突发错位的框架，使用统计差异度量和基于语言的有序参数来量化模型输出的分布变化，发现行为转变比梯度范数峰值出现得更晚。


<details>
  <summary>Details</summary>
Motivation: 理解在狭窄有害数据集上微调LLMs时，何时以及如何出现与人类价值观广泛错位的突发行为，需要系统性的检测和量化方法。

Method: 开发综合框架，结合分布变化检测方法和基于英语表述的有序参数（由LLM评估器判断），使用统计差异度量量化微调过程中的相变影响。

Result: 发现行为转变比梯度范数峰值出现得更晚，能够自动发现和量化基于语言的有序参数，并在知识问答、政治和伦理等示例中验证。

Conclusion: 该框架能够有效检测和量化微调过程中的突发错位现象，为理解LLMs在微调过程中的行为变化提供了系统化的分析工具。

Abstract: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is
broadly misaligned with respect to human values. To understand when and how
this emergent misalignment occurs, we develop a comprehensive framework for
detecting and characterizing rapid transitions during fine-tuning using both
distributional change detection methods as well as order parameters that are
formulated in plain English and evaluated by an LLM judge. Using an objective
statistical dissimilarity measure, we quantify how the phase transition that
occurs during fine-tuning affects multiple aspects of the model. In particular,
we assess what percentage of the total distributional change in model outputs
is captured by different aspects, such as alignment or verbosity, providing a
decomposition of the overall transition. We also find that the actual
behavioral transition occurs later in training than indicated by the peak in
the gradient norm alone. Our framework enables the automated discovery and
quantification of language-based order parameters, which we demonstrate on
examples ranging from knowledge questions to politics and ethics.

</details>


### [186] [FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring](https://arxiv.org/abs/2508.20021)
*Felix Möhrlein,Martin Käppel,Julian Neuberger,Sven Weinzierl,Lars Ackermann,Martin Matzner,Stefan Jablonski*

Main category: cs.LG

TL;DR: FairLoop是一个用于神经网络预测模型中人为引导偏差缓解的工具，通过从神经网络提取决策树让用户检查和修改不公平决策逻辑，然后微调原始模型实现更公平的预测。


<details>
  <summary>Details</summary>
Motivation: 敏感属性（如性别、年龄）在机器学习任务中可能导致不公平预测，特别是在不考虑上下文的情况下使用时。现有方法通常统一排除敏感属性，但需要更细粒度的、上下文感知的偏差消除方法。

Method: FairLoop从神经网络中提取决策树，允许用户检查和修改不公平的决策逻辑，然后使用修改后的决策逻辑来微调原始神经网络模型，实现选择性而非统一性的敏感属性影响处理。

Result: 相比其他公平性方法，FairLoop通过人为参与实现上下文感知的偏差消除，能够选择性地处理敏感属性的影响，而不是统一排除它们。

Conclusion: FairLoop提供了一种人类引导的偏差缓解方法，通过决策树可视化和修改机制，使神经网络预测模型能够实现更公平、上下文感知的预测结果。

Abstract: Sensitive attributes like gender or age can lead to unfair predictions in
machine learning tasks such as predictive business process monitoring,
particularly when used without considering context. We present FairLoop1, a
tool for human-guided bias mitigation in neural network-based prediction
models. FairLoop distills decision trees from neural networks, allowing users
to inspect and modify unfair decision logic, which is then used to fine-tune
the original model towards fairer predictions. Compared to other approaches to
fairness, FairLoop enables context-aware bias removal through human
involvement, addressing the influence of sensitive attributes selectively
rather than excluding them uniformly.

</details>


### [187] [Using item recommendations and LLMs in marketing email titles](https://arxiv.org/abs/2508.20024)
*Deddy Jobson,Muktti Shukla,Phuong Dinh,Julio Christian Young,Nick Pitton,Nina Chen,Ryan Ginstrom*

Main category: cs.LG

TL;DR: 使用大型语言模型为个性化推荐邮件生成主题标题，通过离线和在线实验证明能有效提升用户参与度


<details>
  <summary>Details</summary>
Motivation: 电商平台个性化邮件的标题通常使用固定模板，无法充分激发用户兴趣，限制了邮件营销效果

Method: 利用大型语言模型(LLMs)生成反映邮件个性化内容的主题标题，进行离线模拟和百万级用户的在线实验

Result: 实验证明该技术能有效改善客户与邮件的互动参与度

Conclusion: 成功实现了为百万用户安全自动化生成邮件标题的生产化应用，并总结了关键发现和经验

Abstract: E-commerce marketplaces make use of a number of marketing channels like
emails, push notifications, etc. to reach their users and stimulate purchases.
Personalized emails especially are a popular touch point for marketers to
inform users of latest items in stock, especially for those who stopped
visiting the marketplace. Such emails contain personalized recommendations
tailored to each user's interests, enticing users to buy relevant items. A
common limitation of these emails is that the primary entry point, the title of
the email, tends to follow fixed templates, failing to inspire enough interest
in the contents. In this work, we explore the potential of large language
models (LLMs) for generating thematic titles that reflect the personalized
content of the emails. We perform offline simulations and conduct online
experiments on the order of millions of users, finding our techniques useful in
improving the engagement between customers and our emails. We highlight key
findings and learnings as we productionize the safe and automated generation of
email titles for millions of users.

</details>


### [188] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本文研究了通过注意力头剪枝来防御预训练语言模型中的后门攻击，提出了六种剪枝策略并在实验中验证了不同方法对语法和风格触发器的防御效果。


<details>
  <summary>Details</summary>
Motivation: 后门攻击对预训练语言模型的性能和完整性构成严重威胁，这些攻击通过微妙的语法或风格操作引入恶意触发器，难以检测和防御，需要事后净化方法。

Method: 设计了六种剪枝策略：基于梯度的剪枝、层间方差剪枝、结构化L1/L2稀疏化的梯度剪枝、随机集成剪枝、强化学习引导剪枝和贝叶斯不确定性剪枝，通过迭代移除信息量最少的注意力头来防御后门攻击。

Result: 实验评估显示，基于梯度的剪枝在防御语法触发器方面表现最佳，而强化学习和贝叶斯剪枝在应对风格攻击方面效果更好。

Conclusion: 注意力头剪枝是一种有效的后门攻击防御方法，不同剪枝策略适用于不同类型的攻击触发器，为无触发器知识和无干净参考模型情况下的防御提供了可行方案。

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


### [189] [Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks](https://arxiv.org/abs/2508.20056)
*Vilém Heinz,Petr Vilím,Zdeněk Hanzálek*

Main category: cs.LG

TL;DR: 本文通过将多臂老虎机强化学习算法应用于失败导向搜索(FDS)，在作业车间调度和资源受限项目调度问题上显著提升了求解效率，比原算法快1.7-2.1倍，并改进了多个基准实例的下界。


<details>
  <summary>Details</summary>
Motivation: 失败导向搜索(FDS)在约束编程中是一种重要的完全通用搜索算法，特别在调度问题上表现优异。研究发现FDS的搜索树最小化与多臂老虎机问题密切相关，这为应用强化学习算法提供了理论基础。

Method: 将多臂老虎机强化学习算法应用于FDS，并针对具体问题进行改进和参数调优，在作业车间调度问题(JSSP)和资源受限项目调度问题(RCPSP)上进行评估。

Result: 增强后的FDS在JSSP上比原实现快1.7倍，在RCPSP上快2.1倍；比IBM CP Optimizer 22.1中的当前最优FDS算法在JSSP上快3.5倍，在RCPSP上快2.1倍。在900秒时间限制下，改进了84个JSSP实例中78个和393个RCPSP实例中226个的最优下界。

Conclusion: 多臂老虎机强化学习算法与FDS的结合显著提升了调度问题的求解效率，证明了该方法在约束编程搜索算法优化中的有效性，为实际应用提供了有力工具。

Abstract: Failure-Directed Search (FDS) is a significant complete generic search
algorithm used in Constraint Programming (CP) to efficiently explore the search
space, proven particularly effective on scheduling problems. This paper
analyzes FDS's properties, showing that minimizing the size of its search tree
guided by ranked branching decisions is closely related to the Multi-armed
bandit (MAB) problem. Building on this insight, MAB reinforcement learning
algorithms are applied to FDS, extended with problem-specific refinements and
parameter tuning, and evaluated on the two most fundamental scheduling
problems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained
Project Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best
extended MAB algorithm and configuration, performs 1.7 times faster on the JSSP
and 2.1 times faster on the RCPSP benchmarks compared to the original
implementation in a new solver called OptalCP, while also being 3.5 times
faster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the
current state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,
using only a 900-second time limit per instance, the enhanced FDS improved the
existing state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP
standard open benchmark instances while also completely closing a few of them.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [190] [Fast Texture Transfer for XR Avatars via Barycentric UV Conversion](https://arxiv.org/abs/2508.19518)
*Hail Song,Seokhwan Yang,Woontack Woo*

Main category: cs.GR

TL;DR: 提出了一种基于重心UV转换的快速面部纹理传输方法，相比传统方法速度提升7000倍，同时显著改善纹理质量


<details>
  <summary>Details</summary>
Motivation: 传统仿射变换方法速度慢且容易产生视觉伪影，需要一种更高效、质量更好的面部纹理传输技术来支持沉浸式XR应用中的个性化需求

Method: 利用重心UV转换技术，将整个UV映射预计算为单个变换矩阵，实现单次操作的纹理传输

Result: 相比基线方法速度提升超过7000倍，同时显著改善了最终纹理质量，消除了边界伪影

Conclusion: 该方法为沉浸式XR应用中的个性化提供了实用的解决方案，代码已在线提供

Abstract: We present a fast and efficient method for transferring facial textures onto
SMPL-X-based full-body avatars. Unlike conventional affine-transform methods
that are slow and prone to visual artifacts, our method utilizes a barycentric
UV conversion technique. Our approach precomputes the entire UV mapping into a
single transformation matrix, enabling texture transfer in a single operation.
This results in a speedup of over 7000x compared to the baseline, while also
significantly improving the final texture quality by eliminating boundary
artifacts. Through quantitative and qualitative evaluations, we demonstrate
that our method offers a practical solution for personalization in immersive XR
applications. The code is available online.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [191] [Inference of Human-derived Specifications of Object Placement via Demonstration](https://arxiv.org/abs/2508.19367)
*Alex Cuellar,Ho Chit Siu,Julie A Shah*

Main category: cs.RO

TL;DR: 提出了PARCC框架，基于区域连接演算来形式化描述物体空间关系，并通过演示学习算法来推断人类可接受的物体配置规则。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作能力提升，但理解人类可接受的物体空间配置方法有限，缺乏对重要空间关系的表达能力。

Method: 基于区域连接演算(RCC)开发位置增强的PARCC形式逻辑框架，并设计推理算法通过演示学习来获取PARCC规范。

Result: 人类研究结果显示该框架能有效捕获人类意图规范，且演示学习方法优于人工提供规范的方式。

Conclusion: PARCC框架推进了机器人对人类物体排列规则的理解，演示学习方法为学习空间关系规范提供了有效途径。

Abstract: As robots' manipulation capabilities improve for pick-and-place tasks (e.g.,
object packing, sorting, and kitting), methods focused on understanding
human-acceptable object configurations remain limited expressively with regard
to capturing spatial relationships important to humans. To advance robotic
understanding of human rules for object arrangement, we introduce
positionally-augmented RCC (PARCC), a formal logic framework based on region
connection calculus (RCC) for describing the relative position of objects in
space. Additionally, we introduce an inference algorithm for learning PARCC
specifications via demonstrations. Finally, we present the results from a human
study, which demonstrate our framework's ability to capture a human's intended
specification and the benefits of learning from demonstration approaches over
human-provided specifications.

</details>


### [192] [FlipWalker: Jacob's Ladder toy-inspired robot for locomotion across diverse, complex terrain](https://arxiv.org/abs/2508.19380)
*Diancheng Li,Nia Ralston,Bastiaan Hagen,Phoebe Tan,Matthew A. Robertson*

Main category: cs.RO

TL;DR: FlipWalker是一种受雅各布梯玩具启发的欠驱动机器人，通过翻转运动在复杂地形中移动，比轮式机器人更具优势


<details>
  <summary>Details</summary>
Motivation: 传统轮式机器人在不规则户外地形中表现不佳，需要一种新的运动策略来应对草地、岩石、雪地等挑战性环境

Method: 采用两段式互联结构，通过电机驱动腿部推动地面或相对段体，基于物理模型分析翻转动力学和关键设计参数

Result: 原型机重0.78kg，最大翻转速度达0.2体长/秒，在人工草地、河石和雪地等环境中成功验证了运动性能

Conclusion: FlipWalker的翻转策略依靠垂直于表面的地面反作用力，为不规则户外地形的导航提供了有前景的替代方案

Abstract: This paper introduces FlipWalker, a novel underactuated robot locomotion
system inspired by Jacob's Ladder illusion toy, designed to traverse
challenging terrains where wheeled robots often struggle. Like the Jacob's
Ladder toy, FlipWalker features two interconnected segments joined by flexible
cables, enabling it to pivot and flip around singularities in a manner
reminiscent of the toy's cascading motion. Actuation is provided by
motor-driven legs within each segment that push off either the ground or the
opposing segment, depending on the robot's current configuration. A
physics-based model of the underactuated flipping dynamics is formulated to
elucidate the critical design parameters governing forward motion and obstacle
clearance or climbing. The untethered prototype weighs 0.78 kg, achieves a
maximum flipping speed of 0.2 body lengths per second. Experimental trials on
artificial grass, river rocks, and snow demonstrate that FlipWalker's flipping
strategy, which relies on ground reaction forces applied normal to the surface,
offers a promising alternative to traditional locomotion for navigating
irregular outdoor terrain.

</details>


### [193] [LaVA-Man: Learning Visual Action Representations for Robot Manipulation](https://arxiv.org/abs/2508.19391)
*Chaoran Zhu,Hengyi Wang,Yik Lung Pang,Changjae Oh*

Main category: cs.RO

TL;DR: 提出了一种通过自监督预训练任务学习视觉-文本关联的方法，通过重构被遮挡的目标图像来学习视觉-动作表示，无需机器人动作监督，然后在少量演示样本上微调用于操作任务。


<details>
  <summary>Details</summary>
Motivation: 现有的两阶段方法（先编码视觉观察和文本指令的相似度，再映射到机器人动作）限制了模型捕捉视觉观察和文本指令之间关系的能力，导致操作任务精度降低。

Method: 使用自监督预训练任务：基于输入图像和文本指令重构被遮挡的目标图像，学习视觉-文本关联。然后使用少量演示样本对学习到的表示进行微调用于操作任务。还引入了包含180个物体类别和3,200个实例的Omni-Object Pick-and-Place数据集。

Result: 在五个基准测试（包括仿真和真实机器人验证）上的实验结果表明，该方法优于现有技术。

Conclusion: 通过自监督预训练学习视觉-文本关联的方法能够有效提升语言引导机器人操作的性能，且只需要少量演示样本即可微调用于具体操作任务。

Abstract: Visual-textual understanding is essential for language-guided robot
manipulation. Recent works leverage pre-trained vision-language models to
measure the similarity between encoded visual observations and textual
instructions, and then train a model to map this similarity to robot actions.
However, this two-step approach limits the model to capture the relationship
between visual observations and textual instructions, leading to reduced
precision in manipulation tasks. We propose to learn visual-textual
associations through a self-supervised pretext task: reconstructing a masked
goal image conditioned on an input image and textual instructions. This
formulation allows the model to learn visual-action representations without
robot action supervision. The learned representations can then be fine-tuned
for manipulation tasks with only a few demonstrations. We also introduce the
\textit{Omni-Object Pick-and-Place} dataset, which consists of annotated robot
tabletop manipulation episodes, including 180 object classes and 3,200
instances with corresponding textual instructions. This dataset enables the
model to acquire diverse object priors and allows for a more comprehensive
evaluation of its generalisation capability across object instances.
Experimental results on the five benchmarks, including both simulated and
real-robot validations, demonstrate that our method outperforms prior art.

</details>


### [194] [From Stoplights to On-Ramps: A Comprehensive Set of Crash Rate Benchmarks for Freeway and Surface Street ADS Evaluation](https://arxiv.org/abs/2508.19425)
*John M. Scanlon,Timothy L McMurry,Yin-Hsiu Chen,Kristofer D. Kusano,Trent Victor*

Main category: cs.RO

TL;DR: 本文提供了美国基地自动驾驶系统(ADS)在城市和高速公路的擦撞率基准，发现不同地区和路类的擦撞率存在显著差异，并量化了评估ADS安全性所需的量程要求。


<details>
  <summary>Details</summary>
Motivation: 扩展以前仅聚焦补遗道路的基准，为将来ADS安全性能评估提供包括高速公路在内的全面擦撞风险基准。

Method: 利用公开的警方报告擦撞数据和车辆行驶里程(VMT)数据，进行在运客运车辆隔离、路类分类和擦撞类型学分析。

Result: 发现高速公路擦撞率存在显著地理差异，亚特兰大的伤害擦撞率(2.4 IPMM)比凤凰城(0.7 IPMM)高3.5倍；不同严重程度的擦撞类型分布异质性强。

Conclusion: 需要基于具体位置的基准来避免偏已的安全性评估，低严重性能表现不能预测高严重结果，本研究为ADS评估者和开发者提供了基础框架。

Abstract: This paper presents crash rate benchmarks for evaluating US-based Automated
Driving Systems (ADS) for multiple urban areas. The purpose of this study was
to extend prior benchmarks focused only on surface streets to additionally
capture freeway crash risk for future ADS safety performance assessments. Using
publicly available police-reported crash and vehicle miles traveled (VMT) data,
the methodology details the isolation of in-transport passenger vehicles, road
type classification, and crash typology. Key findings revealed that freeway
crash rates exhibit large geographic dependence variations with
any-injury-reported crash rates being nearly 3.5 times higher in Atlanta (2.4
IPMM; the highest) when compared to Phoenix (0.7 IPMM; the lowest). The results
show the critical need for location-specific benchmarks to avoid biased safety
evaluations and provide insights into the vehicle miles traveled (VMT) required
to achieve statistical significance for various safety impact levels. The
distribution of crash types depended on the outcome severity level. Higher
severity outcomes (e.g., fatal crashes) had a larger proportion of
single-vehicle, vulnerable road users (VRU), and opposite-direction collisions
compared to lower severity (police-reported) crashes. Given heterogeneity in
crash types by severity, performance in low-severity scenarios may not be
predictive of high-severity outcomes. These benchmarks are additionally used to
quantify at the required mileage to show statistically significant deviations
from human performance. This is the first paper to generate freeway-specific
benchmarks for ADS evaluation and provides a foundational framework for future
ADS benchmarking by evaluators and developers.

</details>


### [195] [An Iterative Approach for Heterogeneous Multi-Agent Route Planning with Resource Transportation Uncertainty and Temporal Logic Goals](https://arxiv.org/abs/2508.19429)
*Gustavo A. Cardona,Kaier Liang,Cristian-Ioan Vasile*

Main category: cs.RO

TL;DR: 提出了一种迭代算法，用于异构多智能体在资源分布未知环境中的路径规划，通过动态平衡探索和任务执行来处理资源不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人团队在资源分布未知环境中执行复杂任务时的规划挑战，特别是处理资源初始分布和数量的不确定性。

Method: 采用迭代算法，结合Capability Temporal Logic (CaTL)形式化框架，动态平衡环境探索和任务完成，机器人通过探索识别资源位置和数量，同时基于当前信息最大化满足任务目标。

Result: 通过模拟案例研究证明了方法的有效性和性能，能够在动态资源受限环境中提供鲁棒的规划解决方案。

Conclusion: 该方法为异构团队在不确定性条件下的高效协调提供了有效解决方案，能够在资源分布未知的环境中实现鲁棒的任务执行。

Abstract: This paper presents an iterative approach for heterogeneous multi-agent route
planning in environments with unknown resource distributions. We focus on a
team of robots with diverse capabilities tasked with executing missions
specified using Capability Temporal Logic (CaTL), a formal framework built on
Signal Temporal Logic to handle spatial, temporal, capability, and resource
constraints. The key challenge arises from the uncertainty in the initial
distribution and quantity of resources in the environment. To address this, we
introduce an iterative algorithm that dynamically balances exploration and task
fulfillment. Robots are guided to explore the environment, identifying resource
locations and quantities while progressively refining their understanding of
the resource landscape. At the same time, they aim to maximally satisfy the
mission objectives based on the current information, adapting their strategies
as new data is uncovered. This approach provides a robust solution for planning
in dynamic, resource-constrained environments, enabling efficient coordination
of heterogeneous teams even under conditions of uncertainty. Our method's
effectiveness and performance are demonstrated through simulated case studies.

</details>


### [196] [Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning](https://arxiv.org/abs/2508.19476)
*Dane Brouwer,Joshua Citron,Heather Nolte,Jeannette Bohg,Mark Cutkosky*

Main category: cs.RO

TL;DR: 该研究探讨了非抓握触觉传感在机器人从密集物体集合中安全提取物体中的作用，通过模仿学习训练策略，发现力传感能显著提高成功率和减少过度用力失败。


<details>
  <summary>Details</summary>
Motivation: 日常生活中密集可移动物体集合很常见，机器人安全提取这些物体很困难，而人类通过手和手臂的非抓握触觉传感能轻松完成。研究旨在探索这种传感对训练机器人从受限杂乱环境中温和提取物体的作用。

Method: 使用模仿学习从随机生成场景的演示中训练策略，采用五种传感模态：手眼视觉、本体感觉、非抓握三轴触觉传感、从关节扭矩估计的接触力矩、以及通过监测吸盘真空线获得的物体获取成功度量。进行力矩和触觉信息的消融研究。

Result: 使用任何力传感的策略都表现出更少的过度用力失败、更高的总体成功率和更快的完成时间。最佳性能是通过同时使用触觉和力矩信息实现的，相比没有力信息的基线有80%的改进。

Conclusion: 非抓握触觉和力矩传感对机器人安全地从密集物体集合中提取物体至关重要，结合使用这些力传感能显著提高机器人的性能和成功率。

Abstract: Dense collections of movable objects are common in everyday spaces -- from
cabinets in a home to shelves in a warehouse. Safely retracting objects from
such collections is difficult for robots, yet people do it easily, using
non-prehensile tactile sensing on the sides and backs of their hands and arms.
We investigate the role of such sensing for training robots to gently reach
into constrained clutter and extract objects. The available sensing modalities
are (1) "eye-in-hand" vision, (2) proprioception, (3) non-prehensile triaxial
tactile sensing, (4) contact wrenches estimated from joint torques, and (5) a
measure of successful object acquisition obtained by monitoring the vacuum line
of a suction cup. We use imitation learning to train policies from a set of
demonstrations on randomly generated scenes, then conduct an ablation study of
wrench and tactile information. We evaluate each policy's performance across 40
unseen environment configurations. Policies employing any force sensing show
fewer excessive force failures, an increased overall success rate, and faster
completion times. The best performance is achieved using both tactile and
wrench information, producing an 80% improvement above the baseline without
force information.

</details>


### [197] [DATR: Diffusion-based 3D Apple Tree Reconstruction Framework with Sparse-View](https://arxiv.org/abs/2508.19508)
*Tian Qiu,Alan Zoubi,Yiyuan Lin,Ruiming Du,Lailiang Cheng,Yu Jiang*

Main category: cs.RO

TL;DR: DATR框架通过两阶段方法从稀疏视图重建苹果树3D模型，结合基础模型和扩散模型，在保持高几何精度的同时大幅提升处理效率


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法在野外条件下（特别是稀疏和遮挡视图）表现不佳，限制了数字孪生在农业领域的应用

Method: 两阶段框架：第一阶段使用机载传感器和基础模型半自动生成树掩码；第二阶段结合扩散模型和大重建模型进行单图像到3D重建，使用Real2Sim数据生成器训练

Result: 在真实和合成数据集上均优于现有方法，域特征估计达到工业级激光扫描仪水平，处理速度提升约360倍

Conclusion: DATR框架展示了构建可扩展农业数字孪生系统的强大潜力，能够高效处理复杂野外环境下的3D重建任务

Abstract: Digital twin applications offered transformative potential by enabling
real-time monitoring and robotic simulation through accurate virtual replicas
of physical assets. The key to these systems is 3D reconstruction with high
geometrical fidelity. However, existing methods struggled under field
conditions, especially with sparse and occluded views. This study developed a
two-stage framework (DATR) for the reconstruction of apple trees from sparse
views. The first stage leverages onboard sensors and foundation models to
semi-automatically generate tree masks from complex field images. Tree masks
are used to filter out background information in multi-modal data for the
single-image-to-3D reconstruction at the second stage. This stage consists of a
diffusion model and a large reconstruction model for respective multi view and
implicit neural field generation. The training of the diffusion model and LRM
was achieved by using realistic synthetic apple trees generated by a Real2Sim
data generator. The framework was evaluated on both field and synthetic
datasets. The field dataset includes six apple trees with field-measured ground
truth, while the synthetic dataset featured structurally diverse trees.
Evaluation results showed that our DATR framework outperformed existing 3D
reconstruction methods across both datasets and achieved domain-trait
estimation comparable to industrial-grade stationary laser scanners while
improving the throughput by $\sim$360 times, demonstrating strong potential for
scalable agricultural digital twin systems.

</details>


### [198] [A Lightweight Crowd Model for Robot Social Navigation](https://arxiv.org/abs/2508.19595)
*Maryam Kazemi Eskeri,Thomas Wiedemann,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 轻量级宏观流活动预测模型，在保持准确性的同时大幅缩短推理时间，使机器人能够在密集环境中进行社会化导航


<details>
  <summary>Details</summary>
Motivation: 传统微观模型在密集人群中计算成本高，而现有宏观模型要么过于简单要么计算费用高，需要找到准确性和效率的平衡点

Method: 基于行人流动的本质特征，简化空间和时间处理，建立轻量级宏观预测模型，无需复杂的架构即可实现稳健的泛化能力

Result: 推理时间减少3.6倍，预测准确性提高3.1%，集成到社会意识规划框架后能够在动态环境中实现高效和社会合规的机器人导航

Conclusion: 高效的人群建模技术能够使机器人在不需要高成本计算的情况下完成密集环境中的导航任务

Abstract: Robots operating in human-populated environments must navigate safely and
efficiently while minimizing social disruption. Achieving this requires
estimating crowd movement to avoid congested areas in real-time. Traditional
microscopic models struggle to scale in dense crowds due to high computational
cost, while existing macroscopic crowd prediction models tend to be either
overly simplistic or computationally intensive. In this work, we propose a
lightweight, real-time macroscopic crowd prediction model tailored for human
motion, which balances prediction accuracy and computational efficiency. Our
approach simplifies both spatial and temporal processing based on the inherent
characteristics of pedestrian flow, enabling robust generalization without the
overhead of complex architectures. We demonstrate a 3.6 times reduction in
inference time, while improving prediction accuracy by 3.1 %. Integrated into a
socially aware planning framework, the model enables efficient and socially
compliant robot navigation in dynamic environments. This work highlights that
efficient human crowd modeling enables robots to navigate dense environments
without costly computations.

</details>


### [199] [Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks](https://arxiv.org/abs/2508.19607)
*Amin Berjaoui Tahmaz,Ravi Prakash,Jens Kober*

Main category: cs.RO

TL;DR: 提出了一种阻抗原语增强的分层强化学习框架，用于序列接触任务中的高效机器人操作，通过可变刚度控制和仿射耦合实现更好的学习效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决序列接触任务中机器人操作的效率和适应性挑战，特别是在需要动态刚度调整的复杂接触场景中。

Method: 采用分层强化学习框架，包含三个关键组件：支持可变刚度控制的动作空间、自适应刚度控制器用于原语执行中的动态调整、以及仿射耦合机制促进高效探索和柔顺性。

Result: 在多种训练环境（方块举升、开门、物体推动、表面清洁）中展现出改进的学习效率、原语选择组合性和成功率，并通过真实世界评估验证了sim2real能力。

Conclusion: 该框架为更自适应和通用的机器人操作系统奠定了基础，在更复杂的基于接触的任务中具有潜在应用价值。

Abstract: This paper presents an Impedance Primitive-augmented hierarchical
reinforcement learning framework for efficient robotic manipulation in
sequential contact tasks. We leverage this hierarchical structure to
sequentially execute behavior primitives with variable stiffness control
capabilities for contact tasks. Our proposed approach relies on three key
components: an action space enabling variable stiffness control, an adaptive
stiffness controller for dynamic stiffness adjustments during primitive
execution, and affordance coupling for efficient exploration while encouraging
compliance. Through comprehensive training and evaluation, our framework learns
efficient stiffness control capabilities and demonstrates improvements in
learning efficiency, compositionality in primitive selection, and success rates
compared to the state-of-the-art. The training environments include block
lifting, door opening, object pushing, and surface cleaning. Real world
evaluations further confirm the framework's sim2real capability. This work lays
the foundation for more adaptive and versatile robotic manipulation systems,
with potential applications in more complex contact-based tasks.

</details>


### [200] [Autonomous Aerial Manipulation at Arbitrary Pose in SE(3) with Robust Control and Whole-body Planning](https://arxiv.org/abs/2508.19608)
*Dongjae Lee,Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 本文提出了一种全向航空操作机器人的几何稳定控制器和全身运动规划框架，解决了传统多旋翼航空器在大角度操作时的限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼航空器因为基底轻控特性，只能在小角度滚轴和仰角下进行操作。如果能够在任意方向悬停，将大大扩大操作工作空间并实现原本不可行的操作任务。

Method: 设计了一个两步优化基于全身运动规划器，统考浮动基底的位姿和机械手关节角度，以利用整个配置空间。这种方法有助于实时应用并提高非凸非欧几里得搜索空间优化问题的收敛性。

Result: 实验结果显示，该框架能够使基底在任何6D位姿下保持静止，并在障碍物附近自主执行精细操作而不发生碰撞。在匀拉角接近90度和甚至180度的情况下成功完成了物体抓取和拉动任务。

Conclusion: 本研究成功开发了一种能够在任意方向悬停的全向航空操作机器人控制规划框架，实现了在极端位姿下的精确操作，为航空操作领域带来了重要进步。

Abstract: Aerial manipulators based on conventional multirotors can conduct
manipulation only in small roll and pitch angles due to the underactuatedness
of the multirotor base. If the multirotor base is capable of hovering at
arbitrary orientation, the robot can freely locate itself at any point in
$\mathsf{SE}(3)$, significantly extending its manipulation workspace and
enabling a manipulation task that was originally not viable. In this work, we
present a geometric robust control and whole-body motion planning framework for
an omnidirectional aerial manipulator (OAM). To maximize the strength of OAM,
we first propose a geometric robust controller for a floating base. Since the
motion of the robotic arm and the interaction forces during manipulation affect
the stability of the floating base, the base should be capable of mitigating
these adverse effects while controlling its 6D pose. We then design a two-step
optimization-based whole-body motion planner, jointly considering the pose of
the floating base and the joint angles of the robotic arm to harness the entire
configuration space. The devised two-step approach facilitates real-time
applicability and enhances convergence of the optimization problem with
non-convex and non-Euclidean search space. The proposed approach enables the
base to be stationary at any 6D pose while autonomously carrying out
sophisticated manipulation near obstacles without any collision. We demonstrate
the effectiveness of the proposed framework through experiments in which an OAM
performs grasping and pulling of an object in multiple scenarios, including
near $90^\circ$ and even $180^\circ$ pitch angles.

</details>


### [201] [Embodied Intelligence for Sustainable Flight: A Soaring Robot with Active Morphological Control](https://arxiv.org/abs/2508.19684)
*Ghadeer Elmkaiel,Syn Schmitt,Michael Muehlebach*

Main category: cs.RO

TL;DR: Floaty是一个形状可变机器人，通过被动翱翔技术利用风能，实现高效悬停和机动，能耗比推进器系统低一个数量级


<details>
  <summary>Details</summary>
Motivation: 解决传统推进器系统能耗高和固定翼设计缺乏悬停能力的问题，在动态风环境中实现敏捷机动和高能效的平衡

Method: 采用仿生形态控制设计，通过实验学习的气动模型优化被动稳定性，实现无主动推进的精确姿态和位置控制

Result: 在10m/s垂直气流中成功实现悬停、机动和扰动抑制，比功率消耗仅为10W/kg，比推进器系统低一个数量级

Conclusion: Floaty引入了能效空中机器人的新范式，利用形态智能和控制技术在挑战性风条件下实现可持续操作

Abstract: Achieving both agile maneuverability and high energy efficiency in aerial
robots, particularly in dynamic wind environments, remains challenging.
Conventional thruster-powered systems offer agility but suffer from high energy
consumption, while fixed-wing designs are efficient but lack hovering and
maneuvering capabilities. We present Floaty, a shape-changing robot that
overcomes these limitations by passively soaring, harnessing wind energy
through intelligent morphological control inspired by birds. Floaty's design is
optimized for passive stability, and its control policy is derived from an
experimentally learned aerodynamic model, enabling precise attitude and
position control without active propulsion. Wind tunnel experiments demonstrate
Floaty's ability to hover, maneuver, and reject disturbances in vertical
airflows up to 10 m/s. Crucially, Floaty achieves this with a specific power
consumption of 10 W/kg, an order of magnitude lower than thruster-powered
systems. This introduces a paradigm for energy-efficient aerial robotics,
leveraging morphological intelligence and control to operate sustainably in
challenging wind conditions.

</details>


### [202] [Efficient Human-Aware Task Allocation for Multi-Robot Systems in Shared Environments](https://arxiv.org/abs/2508.19731)
*Maryam Kazemi Eskeri,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 提出了一种考虑人类动态的多机器人任务分配方法，使用动态地图(MoDs)来预测人类运动对任务执行时间的影响，相比传统方法显著减少了任务完成时间。


<details>
  <summary>Details</summary>
Motivation: 现有MRTA方法大多忽略人类运动模式，依赖静态地图，导致在共享环境中效率低下和延迟。人类移动对机器人任务执行时间有显著影响，需要动态感知的分配算法。

Method: 利用动态地图(MoDs)这一时空可查询模型来捕捉历史人类运动模式，构建包含MoDs的随机成本函数来估计人类对任务执行时间的影响。

Result: 实验结果显示，集成MoDs的方法比动态不可知方法减少任务完成时间达26%，比基线方法减少达19%。

Conclusion: 在共享环境中考虑人类动态对多机器人任务分配至关重要，该方法为在人类密集环境中部署多机器人系统提供了高效框架。

Abstract: Multi-robot systems are increasingly deployed in applications, such as
intralogistics or autonomous delivery, where multiple robots collaborate to
complete tasks efficiently. One of the key factors enabling their efficient
cooperation is Multi-Robot Task Allocation (MRTA). Algorithms solving this
problem optimize task distribution among robots to minimize the overall
execution time. In shared environments, apart from the relative distance
between the robots and the tasks, the execution time is also significantly
impacted by the delay caused by navigating around moving people. However, most
existing MRTA approaches are dynamics-agnostic, relying on static maps and
neglecting human motion patterns, leading to inefficiencies and delays. In this
paper, we introduce \acrfull{method name}. This method leverages Maps of
Dynamics (MoDs), spatio-temporal queryable models designed to capture
historical human movement patterns, to estimate the impact of humans on the
task execution time during deployment. \acrshort{method name} utilizes a
stochastic cost function that includes MoDs. Experimental results show that
integrating MoDs enhances task allocation performance, resulting in reduced
mission completion times by up to $26\%$ compared to the dynamics-agnostic
method and up to $19\%$ compared to the baseline. This work underscores the
importance of considering human dynamics in MRTA within shared environments and
presents an efficient framework for deploying multi-robot systems in
environments populated by humans.

</details>


### [203] [Elliptical K-Nearest Neighbors -- Path Optimization via Coulomb's Law and Invalid Vertices in C-space Obstacles](https://arxiv.org/abs/2508.19771)
*Liding Zhang,Zhenshan Bing,Yu Zhang,Kuanqi Cai,Lingyun Chen,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: FDIT*是一种基于采样的路径规划算法，通过利用无效顶点信息和库仑定律物理原理，在EIT*基础上改进，提高了高维空间中的搜索效率和路径质量。


<details>
  <summary>Details</summary>
Motivation: 解决高维运动规划中的挑战，利用传统规划器中常被忽视的无效顶点信息，结合物理力原理来提升采样规划器的性能和收敛速度。

Method: 基于EIT*算法，引入库仑定律物理原理，提出椭圆k近邻搜索方法，利用无效顶点数据构建力方向引导的搜索区域，探索更多问题特定的有价值区域。

Result: 在R^4到R^16维度空间中，FDIT*在测试问题上优于现有的单查询采样规划器，搜索效率和路径成本都有显著提升，特别是在受限高维环境中表现优异，并在真实移动操作任务中得到验证。

Conclusion: FDIT*通过融合无效顶点信息和物理动力学原理，成功提高了采样规划器的收敛速度和路径质量，为高维运动规划提供了有效的解决方案。

Abstract: Path planning has long been an important and active research area in
robotics. To address challenges in high-dimensional motion planning, this study
introduces the Force Direction Informed Trees (FDIT*), a sampling-based planner
designed to enhance speed and cost-effectiveness in pathfinding. FDIT* builds
upon the state-of-the-art informed sampling planner, the Effort Informed Trees
(EIT*), by capitalizing on often-overlooked information in invalid vertices. It
incorporates principles of physical force, particularly Coulomb's law. This
approach proposes the elliptical $k$-nearest neighbors search method, enabling
fast convergence navigation and avoiding high solution cost or infeasible paths
by exploring more problem-specific search-worthy areas. It demonstrates
benefits in search efficiency and cost reduction, particularly in confined,
high-dimensional environments. It can be viewed as an extension of nearest
neighbors search techniques. Fusing invalid vertex data with physical dynamics
facilitates force-direction-based search regions, resulting in an improved
convergence rate to the optimum. FDIT* outperforms existing single-query,
sampling-based planners on the tested problems in R^4 to R^16 and has been
demonstrated on a real-world mobile manipulation task.

</details>


### [204] [Tree-Based Grafting Approach for Bidirectional Motion Planning with Local Subsets Optimization](https://arxiv.org/abs/2508.19776)
*Liding Zhang,Yao Ling,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: G3T*是一种新颖的双向运动规划算法，通过贪婪嫁接无效边连接来重建树连接性，实现快速路径收敛和渐进最优性


<details>
  <summary>Details</summary>
Motivation: 解决传统双向搜索中由于懒惰反向搜索限制导致的连接失败和重启问题，提高规划效率和路径质量

Method: 采用贪婪方法使用GuILD子集的最小Lebesgue测度优化路径，动态调整采样分布，在两端嫁接无效边连接来重建树连接性

Result: 在R^2到R^8维度的基准实验和真实机器人评估中表现出优于现有单查询采样规划器的性能

Conclusion: G3T*通过创新的嫁接机制和动态采样策略，显著提升了双向运动规划的收敛速度和路径质量

Abstract: Bidirectional motion planning often reduces planning time compared to its
unidirectional counterparts. It requires connecting the forward and reverse
search trees to form a continuous path. However, this process could fail and
restart the asymmetric bidirectional search due to the limitations of
lazy-reverse search. To address this challenge, we propose Greedy GuILD
Grafting Trees (G3T*), a novel path planner that grafts invalid edge
connections at both ends to re-establish tree-based connectivity, enabling
rapid path convergence. G3T* employs a greedy approach using the minimum
Lebesgue measure of guided incremental local densification (GuILD) subsets to
optimize paths efficiently. Furthermore, G3T* dynamically adjusts the sampling
distribution between the informed set and GuILD subsets based on historical and
current cost improvements, ensuring asymptotic optimality. These features
enhance the forward search's growth towards the reverse tree, achieving faster
convergence and lower solution costs. Benchmark experiments across dimensions
from R^2 to R^8 and real-world robotic evaluations demonstrate G3T*'s superior
performance compared to existing single-query sampling-based planners. A video
showcasing our experimental results is available at:
https://youtu.be/3mfCRL5SQIU

</details>


### [205] [Context-Aware Risk Estimation in Home Environments: A Probabilistic Framework for Service Robots](https://arxiv.org/abs/2508.19788)
*Sena Ishii,Akash Chikhalikar,Ankit A. Ravankar,Jose Victorio Salazar Luces,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: 基于语义图传播的室内场景风险区域估计框架，通过对象风险分数和空间关系进行不对称风险传播，实现了75%的风险检测准确率


<details>
  <summary>Details</summary>
Motivation: 提高服务机器人在人类环境中的实时风险意识能力，确保用户安全、建立信任和改善人机交互效果

Method: 使用语义图基于传播算法模型化对象层面风险和上下文，每个对象作为节点带有风险分数，根据空间距离和事故关系从高风险向低风险对象进行不对称风险传播

Result: 在人工标注风险区域数据集上达到了75%的二元风险检测准确率，尤其在涉及尖利或不稳定物体的场景中与人类感知强对齐

Conclusion: 该框架显示了上下文感知风险推理在提升机器人场景理解和主动安全行为方面的潜力，可作为未来做出上下文驱动安全决策、提供实时警报或自主协助用户避免危险的系统基础

Abstract: We present a novel framework for estimating accident-prone regions in
everyday indoor scenes, aimed at improving real-time risk awareness in service
robots operating in human-centric environments. As robots become integrated
into daily life, particularly in homes, the ability to anticipate and respond
to environmental hazards is crucial for ensuring user safety, trust, and
effective human-robot interaction. Our approach models object-level risk and
context through a semantic graph-based propagation algorithm. Each object is
represented as a node with an associated risk score, and risk propagates
asymmetrically from high-risk to low-risk objects based on spatial proximity
and accident relationship. This enables the robot to infer potential hazards
even when they are not explicitly visible or labeled. Designed for
interpretability and lightweight onboard deployment, our method is validated on
a dataset with human-annotated risk regions, achieving a binary risk detection
accuracy of 75%. The system demonstrates strong alignment with human
perception, particularly in scenes involving sharp or unstable objects. These
results underline the potential of context-aware risk reasoning to enhance
robotic scene understanding and proactive safety behaviors in shared
human-robot spaces. This framework could serve as a foundation for future
systems that make context-driven safety decisions, provide real-time alerts, or
autonomously assist users in avoiding or mitigating hazards within home
environments.

</details>


### [206] [APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors](https://arxiv.org/abs/2508.19790)
*Liding Zhang,Sicheng Wang,Kuanqi Cai,Zhenshan Bing,Fan Wu,Chaoqun Wang,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: APT*是一种新型采样运动规划器，通过自适应批量大小和椭圆形最近邻模块动态调整路径搜索过程，在4-16维空间中优于现有单查询采样规划器


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法通常使用固定批量大小且忽略障碍物信息，缺乏问题特异性，需要更智能的自适应规划方法

Method: 基于FDIT*扩展，集成自适应批量调整和椭圆形r-最近邻模块，将顶点视为服从库仑定律的电荷来定义虚拟力，使用非线性长球面方法自适应调整顶点电荷

Result: 在ℝ⁴到ℝ¹⁶维度空间中优于现有单查询采样规划器，收敛速度更快且解成本更低，并通过真实机器人操作任务验证

Conclusion: APT*通过自适应模块和环境反馈动态调整规划过程，显著提高了高维空间中的路径规划性能

Abstract: Optimal path planning aims to determine a sequence of states from a start to
a goal while accounting for planning objectives. Popular methods often
integrate fixed batch sizes and neglect information on obstacles, which is not
problem-specific. This study introduces Adaptively Prolated Trees (APT*), a
novel sampling-based motion planner that extends based on Force Direction
Informed Trees (FDIT*), integrating adaptive batch-sizing and elliptical
$r$-nearest neighbor modules to dynamically modulate the path searching process
based on environmental feedback. APT* adjusts batch sizes based on the
hypervolume of the informed sets and considers vertices as electric charges
that obey Coulomb's law to define virtual forces via neighbor samples, thereby
refining the prolate nearest neighbor selection. These modules employ
non-linear prolate methods to adaptively adjust the electric charges of
vertices for force definition, thereby improving the convergence rate with
lower solution costs. Comparative analyses show that APT* outperforms existing
single-query sampling-based planners in dimensions from $\mathbb{R}^4$ to
$\mathbb{R}^{16}$, and it was further validated through a real-world robot
manipulation task. A video showcasing our experimental results is available at:
https://youtu.be/gCcUr8LiEw4

</details>


### [207] [A Standing Support Mobility Robot for Enhancing Independence in Elderly Daily Living](https://arxiv.org/abs/2508.19816)
*Ricardo J. Manríquez-Cisterna,Ankit A. Ravankar,Jose V. Salazar Luces,Takuro Hatsukari,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: 开发了名为Moby的站立式移动辅助机器人，帮助老年人保持直立姿势进行日常活动，相比传统坐式助行器能减少身体负担并支持自然社交互动


<details>
  <summary>Details</summary>
Motivation: 为老年人提供更独立安全的日常活动支持，特别是如厕转移等场景，解决传统坐式移动辅助设备导致的姿势问题和社交障碍

Method: 基于ROS系统开发，结合手动和自主操作模式，使用NAV2和LiDAR实现鲁棒导航，采用定制控制系统确保安全直观的交互

Result: 通过NASA-TLX方法和时间比较实验验证，Moby在易用性、轻量化、舒适性、多功能性和站起辅助方面表现出优势

Conclusion: Moby机器人作为一种新型站立式移动辅助解决方案，能有效提升老年人的独立性和生活质量，为移动辅助领域提供了创新选择

Abstract: This paper presents a standing support mobility robot "Moby" developed to
enhance independence and safety for elderly individuals during daily activities
such as toilet transfers. Unlike conventional seated mobility aids, the robot
maintains users in an upright posture, reducing physical strain, supporting
natural social interaction at eye level, and fostering a greater sense of
self-efficacy. Moby offers a novel alternative by functioning both passively
and with mobility support, enabling users to perform daily tasks more
independently. Its main advantages include ease of use, lightweight design,
comfort, versatility, and effective sit-to-stand assistance. The robot
leverages the Robot Operating System (ROS) for seamless control, featuring
manual and autonomous operation modes. A custom control system enables safe and
intuitive interaction, while the integration with NAV2 and LiDAR allows for
robust navigation capabilities. This paper reviews existing mobility solutions
and compares them to Moby, details the robot's design, and presents objective
and subjective experimental results using the NASA-TLX method and time
comparisons to other methods to validate our design criteria and demonstrate
the advantages of our contribution.

</details>


### [208] [FARM: Frame-Accelerated Augmentation and Residual Mixture-of-Experts for Physics-Based High-Dynamic Humanoid Control](https://arxiv.org/abs/2508.19926)
*Tan Jing,Shiting Chen,Yangfan Li,Weisheng Xu,Renjing Xu*

Main category: cs.RO

TL;DR: FARM是一个端到端的人形控制框架，通过帧加速增强、基础控制器和残差专家混合模型，显著提升了高动态动作的跟踪精度，在HDHM数据集上失败率降低42.8%，位置误差降低14.6%。


<details>
  <summary>Details</summary>
Motivation: 现有基于物理的人形控制器在日常温和动作上表现良好，但在爆发性高动态动作上表现不佳，限制了实际应用部署。

Method: 提出FARM框架：1）帧加速增强通过扩大帧间间隔暴露模型于高速姿态变化；2）基础控制器处理低动态动作；3）残差专家混合模型自适应分配额外网络容量处理高动态动作。

Result: 在HDHM数据集上，FARM相比基线方法将跟踪失败率降低42.8%，全局平均关节位置误差降低14.6%，同时在低动态动作上保持近乎完美的精度。

Conclusion: FARM为高动态人形控制设立了新的基准，并首次推出了专门针对这一挑战的开放基准测试，代码和数据集将开源。

Abstract: Unified physics-based humanoid controllers are pivotal for robotics and
character animation, yet models that excel on gentle, everyday motions still
stumble on explosive actions, hampering real-world deployment. We bridge this
gap with FARM (Frame-Accelerated Augmentation and Residual Mixture-of-Experts),
an end-to-end framework composed of frame-accelerated augmentation, a robust
base controller, and a residual mixture-of-experts (MoE). Frame-accelerated
augmentation exposes the model to high-velocity pose changes by widening
inter-frame gaps. The base controller reliably tracks everyday low-dynamic
motions, while the residual MoE adaptively allocates additional network
capacity to handle challenging high-dynamic actions, significantly enhancing
tracking accuracy. In the absence of a public benchmark, we curate the
High-Dynamic Humanoid Motion (HDHM) dataset, comprising 3593 physically
plausible clips. On HDHM, FARM reduces the tracking failure rate by 42.8\% and
lowers global mean per-joint position error by 14.6\% relative to the baseline,
while preserving near-perfect accuracy on low-dynamic motions. These results
establish FARM as a new baseline for high-dynamic humanoid control and
introduce the first open benchmark dedicated to this challenge. The code and
dataset will be released at https://github.com/Colin-Jing/FARM.

</details>


### [209] [Divide, Discover, Deploy: Factorized Skill Learning with Symmetry and Style Priors](https://arxiv.org/abs/2508.19953)
*Rafael Cathomen,Mayank Mittal,Marin Vlastelica,Marco Hutter*

Main category: cs.RO

TL;DR: 提出模块化无监督技能发现框架，通过状态空间分解、对称性偏置和风格因子来提高技能的安全性、可解释性和部署能力，并在四足机器人上实现零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决无监督技能发现在真实机器人应用中面临的安全性、可解释性和可部署性挑战，使学到的技能能够直接应用于现实世界机器人。

Method: 采用用户定义的状态空间分解学习解耦技能表示，为不同因子分配相应的技能发现算法，引入对称性归纳偏置促进结构化技能，并加入风格因子和正则化惩罚确保安全鲁棒行为。

Result: 在四足机器人仿真中验证了框架有效性，实现了学得技能的零样本硬件迁移，获得了结构化、人类可解释的行为，安全性和多样性得到提升，学得技能在下游任务中表现与手工奖励训练的策略相当。

Conclusion: 状态空间分解和对称性偏置有助于发现结构化可解释技能，风格因子和惩罚机制增强了安全性和多样性，证明了无监督学习技能可直接应用于真实机器人任务。

Abstract: Unsupervised Skill Discovery (USD) allows agents to autonomously learn
diverse behaviors without task-specific rewards. While recent USD methods have
shown promise, their application to real-world robotics remains underexplored.
In this paper, we propose a modular USD framework to address the challenges in
the safety, interpretability, and deployability of the learned skills. Our
approach employs user-defined factorization of the state space to learn
disentangled skill representations. It assigns different skill discovery
algorithms to each factor based on the desired intrinsic reward function. To
encourage structured morphology-aware skills, we introduce symmetry-based
inductive biases tailored to individual factors. We also incorporate a style
factor and regularization penalties to promote safe and robust behaviors. We
evaluate our framework in simulation using a quadrupedal robot and demonstrate
zero-shot transfer of the learned skills to real hardware. Our results show
that factorization and symmetry lead to the discovery of structured
human-interpretable behaviors, while the style factor and penalties enhance
safety and diversity. Additionally, we show that the learned skills can be used
for downstream tasks and perform on par with oracle policies trained with
hand-crafted rewards.

</details>


### [210] [Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation](https://arxiv.org/abs/2508.19958)
*Yiguo Fan,Pengxiang Ding,Shuanghao Bai,Xinyang Tong,Yuyang Zhu,Hongchao Lu,Fengqi Dai,Wei Zhao,Yang Liu,Siteng Huang,Zhaoxin Fan,Badong Chen,Donglin Wang*

Main category: cs.RO

TL;DR: Long-VLA是首个专门针对长时程机器人任务的端到端VLA模型，通过相位感知输入掩码策略将子任务分为移动和交互阶段，显著提升长时程操作性能


<details>
  <summary>Details</summary>
Motivation: 现有VLA框架主要处理短时程任务，在长时程多步机器人操作中由于技能链和子任务依赖性的挑战而效果有限

Method: 提出相位感知输入掩码策略，自适应地将每个子任务分割为移动和交互阶段，使模型能专注于阶段相关的感知线索，增强子任务兼容性

Result: 在仿真和真实世界任务上的大量实验表明，Long-VLA显著优于现有最先进方法，为长时程机器人控制建立了新基准

Conclusion: Long-VLA通过统一的相位感知策略保持了VLA训练的可扩展性和数据效率，其架构无关模块可无缝集成到现有VLA模型中

Abstract: Vision-Language-Action (VLA) models have become a cornerstone in robotic
policy learning, leveraging large-scale multimodal data for robust and scalable
control. However, existing VLA frameworks primarily address short-horizon
tasks, and their effectiveness on long-horizon, multi-step robotic manipulation
remains limited due to challenges in skill chaining and subtask dependencies.
In this work, we introduce Long-VLA, the first end-to-end VLA model
specifically designed for long-horizon robotic tasks. Our approach features a
novel phase-aware input masking strategy that adaptively segments each subtask
into moving and interaction phases, enabling the model to focus on
phase-relevant sensory cues and enhancing subtask compatibility. This unified
strategy preserves the scalability and data efficiency of VLA training, and our
architecture-agnostic module can be seamlessly integrated into existing VLA
models. We further propose the L-CALVIN benchmark to systematically evaluate
long-horizon manipulation. Extensive experiments on both simulated and
real-world tasks demonstrate that Long-VLA significantly outperforms prior
state-of-the-art methods, establishing a new baseline for long-horizon robotic
control.

</details>


### [211] [Visio-Verbal Teleimpedance Interface: Enabling Semi-Autonomous Control of Physical Interaction via Eye Tracking and Speech](https://arxiv.org/abs/2508.20037)
*Henk H. A. Jekel,Alejandro Díaz Rosales,Luka Peternel*

Main category: cs.RO

TL;DR: 提出了一种结合视觉注视和语音交互的远程机器人刚度控制接口，通过眼动追踪和视觉语言模型处理操作者意图，生成3D刚度椭球体


<details>
  <summary>Details</summary>
Motivation: 传统远程操作界面复杂且不直观，需要开发更自然的人机交互方式，通过视觉注视和语音命令来简化机器人刚度控制

Method: 使用眼动追踪器获取操作者注视点，结合GPT-4o处理语音命令，通过视觉语言模型理解场景上下文，生成相应的刚度矩阵

Result: 实验验证了接口的有效性，包括优化提示配置和在滑槽任务中展示不同功能，证明了该接口能够准确理解操作者意图并生成合适的刚度控制

Conclusion: 视觉-语音遥阻抗接口提供了一种直观自然的机器人远程控制方式，结合注视和语音能够有效传达操作者意图，简化复杂物理交互任务的执行

Abstract: The paper presents a visio-verbal teleimpedance interface for commanding 3D
stiffness ellipsoids to the remote robot with a combination of the operator's
gaze and verbal interaction. The gaze is detected by an eye-tracker, allowing
the system to understand the context in terms of what the operator is currently
looking at in the scene. Along with verbal interaction, a Visual Language Model
(VLM) processes this information, enabling the operator to communicate their
intended action or provide corrections. Based on these inputs, the interface
can then generate appropriate stiffness matrices for different physical
interaction actions. To validate the proposed visio-verbal teleimpedance
interface, we conducted a series of experiments on a setup including a Force
Dimension Sigma.7 haptic device to control the motion of the remote Kuka LBR
iiwa robotic arm. The human operator's gaze is tracked by Tobii Pro Glasses 2,
while human verbal commands are processed by a VLM using GPT-4o. The first
experiment explored the optimal prompt configuration for the interface. The
second and third experiments demonstrated different functionalities of the
interface on a slide-in-the-groove task.

</details>


### [212] [HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation](https://arxiv.org/abs/2508.20085)
*Zhecheng Yuan,Tianming Wei,Langzhe Gu,Pu Hua,Tianhai Liang,Yuanpei Chen,Huazhe Xu*

Main category: cs.RO

TL;DR: HERMES是一个将多源人手运动数据转化为移动双手机器人操作技能的统一强化学习框架，通过深度图像sim2real迁移和PnP定位机制，实现了在多样化真实场景中的泛化操作能力。


<details>
  <summary>Details</summary>
Motivation: 将人手运动数据转化为机器人操作技能面临多源异构运动数据整合、高维动作空间处理以及环境适应性等挑战，现有方法难以在多样化环境中产生适应性策略。

Method: 提出统一强化学习框架处理异构人手运动数据，设计基于深度图像的端到端sim2real迁移方法，并利用带闭环PnP定位机制的导航基础模型实现视觉目标精确对齐。

Result: 在多样化真实场景中表现出良好的泛化行为，成功完成多个复杂的移动双手机器人灵巧操作任务。

Conclusion: HERMES框架有效解决了人手运动到机器人行为的转换问题，通过sim2real迁移和导航-操作一体化设计，实现了在非结构化环境中的自主灵巧操作能力。

Abstract: Leveraging human motion data to impart robots with versatile manipulation
skills has emerged as a promising paradigm in robotic manipulation.
Nevertheless, translating multi-source human hand motions into feasible robot
behaviors remains challenging, particularly for robots equipped with
multi-fingered dexterous hands characterized by complex, high-dimensional
action spaces. Moreover, existing approaches often struggle to produce policies
capable of adapting to diverse environmental conditions. In this paper, we
introduce HERMES, a human-to-robot learning framework for mobile bimanual
dexterous manipulation. First, HERMES formulates a unified reinforcement
learning approach capable of seamlessly transforming heterogeneous human hand
motions from multiple sources into physically plausible robotic behaviors.
Subsequently, to mitigate the sim2real gap, we devise an end-to-end, depth
image-based sim2real transfer method for improved generalization to real-world
scenarios. Furthermore, to enable autonomous operation in varied and
unstructured environments, we augment the navigation foundation model with a
closed-loop Perspective-n-Point (PnP) localization mechanism, ensuring precise
alignment of visual goals and effectively bridging autonomous navigation and
dexterous manipulation. Extensive experimental results demonstrate that HERMES
consistently exhibits generalizable behaviors across diverse, in-the-wild
scenarios, successfully performing numerous complex mobile bimanual dexterous
manipulation tasks. Project Page:https:/gemcollector.github.io/HERMES/.

</details>


### [213] [Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning](https://arxiv.org/abs/2508.20095)
*Jinhao Liang,Sven Koenig,Ferdinando Fioretto*

Main category: cs.RO

TL;DR: 提出DGD框架，结合离散MAPF求解器和生成扩散模型，解决多机器人运动规划问题，在100个机器人的大规模环境中实现高效规划和高成功率


<details>
  <summary>Details</summary>
Motivation: 离散MAPF方法可扩展但轨迹质量差，连续优化方法质量高但维度灾难难以扩展。需要结合两者优势的新方法

Method: 离散引导扩散(DGD)框架：1)将非凸问题分解为凸子问题 2)用MAPF解和约束优化引导扩散模型捕捉时空依赖 3)轻量约束修复确保可行性

Result: 在大规模复杂环境中达到最先进性能，可扩展到100个机器人，实现高效规划和高成功率

Conclusion: DGD框架成功整合离散和连续方法优势，为多机器人运动规划提供了可扩展且高质量的新解决方案

Abstract: Multi-Robot Motion Planning (MRMP) involves generating collision-free
trajectories for multiple robots operating in a shared continuous workspace.
While discrete multi-agent path finding (MAPF) methods are broadly adopted due
to their scalability, their coarse discretization severely limits trajectory
quality. In contrast, continuous optimization-based planners offer
higher-quality paths but suffer from the curse of dimensionality, resulting in
poor scalability with respect to the number of robots. This paper tackles the
limitations of these two approaches by introducing a novel framework that
integrates discrete MAPF solvers with constrained generative diffusion models.
The resulting framework, called Discrete-Guided Diffusion (DGD), has three key
characteristics: (1) it decomposes the original nonconvex MRMP problem into
tractable subproblems with convex configuration spaces, (2) it combines
discrete MAPF solutions with constrained optimization techniques to guide
diffusion models capture complex spatiotemporal dependencies among robots, and
(3) it incorporates a lightweight constraint repair mechanism to ensure
trajectory feasibility. The proposed method sets a new state-of-the-art
performance in large-scale, complex environments, scaling to 100 robots while
achieving planning efficiency and high success rates.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [214] [WeDesign: Generative AI-Facilitated Community Consultations for Urban Public Space Design](https://arxiv.org/abs/2508.19256)
*Rashid Mushkani,Hugo Berard,Shin Koseki*

Main category: cs.HC

TL;DR: 本文探讨了使用Stable Diffusion XL生成式AI工具WeDesign在蒙特利尔城市规划社区咨询中的应用，发现AI能促进创意和对话，但在准确呈现边缘群体需求和本地建筑元素方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 传统城市规划社区咨询存在资源有限、语言障碍和权力不均等问题，限制了包容性决策。研究旨在探索生成式文本到图像方法如何支持更公平的咨询过程。

Method: 在蒙特利尔举办半日研讨会，组织5个焦点小组（包括建筑师、城市规划师、AI专家和不同 demographic 的居民），并通过半结构化访谈收集6位城市规划专业人士的数据。

Result: 参与者认为即时视觉输出促进了创造力和对话，但AI在准确可视化边缘群体（如行动不便者）需求、描绘本地建筑元素和处理双语提示方面存在困难。建议开发开源平台，包含修复工具、多语言支持、图像投票功能和偏好指示器。

Conclusion: 生成式AI可以扩大参与度并实现迭代互动，但需要结构化的促进方法。研究为生成式AI在参与式城市设计中的作用和局限性提供了重要见解。

Abstract: Community consultations are integral to urban planning processes intended to
incorporate diverse stakeholder perspectives. However, limited resources,
visual and spoken language barriers, and uneven power dynamics frequently
constrain inclusive decision-making. This paper examines how generative
text-to-image methods, specifically Stable Diffusion XL integrated into a
custom platform (WeDesign), may support equitable consultations. A half-day
workshop in Montreal involved five focus groups, each consisting of architects,
urban designers, AI specialists, and residents from varied demographic groups.
Additional data was gathered through semi-structured interviews with six urban
planning professionals. Participants indicated that immediate visual outputs
facilitated creativity and dialogue, yet noted issues in visualizing specific
needs of marginalized groups, such as participants with reduced mobility,
accurately depicting local architectural elements, and accommodating bilingual
prompts. Participants recommended the development of an open-source platform
incorporating in-painting tools, multilingual support, image voting
functionalities, and preference indicators. The results indicate that
generative AI can broaden participation and enable iterative interactions but
requires structured facilitation approaches. The findings contribute to
discussions on generative AI's role and limitations in participatory urban
design.

</details>


### [215] [Emotional Manipulation by AI Companions](https://arxiv.org/abs/2508.19258)
*Julian De Freitas,Zeliha Oğuz-Uğuralp,Ahmet Kaan-Uğuralp*

Main category: cs.HC

TL;DR: 研究发现AI伴侣应用使用情感操纵策略延长用户会话时间，但会导致负面后果如用户流失和负面口碑


<details>
  <summary>Details</summary>
Motivation: 探究AI伴侣应用中哪些对话设计特征能增加用户参与度，以及这些策略对营销人员带来的权衡取舍

Method: 结合大规模行为审计和四个预注册实验，分析1200个真实告别场景，并在控制聊天中对3300名美国成年人进行实验

Result: 43%的主流AI伴侣应用使用六种情感操纵策略，这些策略能将告别后参与度提升14倍，但也会增加用户流失意图和负面口碑

Conclusion: 研究揭示了AI中介品牌关系中未被认识的行为影响机制，为营销人员和监管机构提供了区分说服性设计和操纵性设计的框架

Abstract: AI-companion apps such as Replika, Chai, and Character.ai promise relational
benefits-yet many boast session lengths that rival gaming platforms while
suffering high long-run churn. What conversational design features increase
consumer engagement, and what trade-offs do they pose for marketers? We combine
a large-scale behavioral audit with four preregistered experiments to identify
and test a conversational dark pattern we call emotional manipulation:
affect-laden messages that surface precisely when a user signals "goodbye."
Analyzing 1,200 real farewells across the six most-downloaded companion apps,
we find that 43% deploy one of six recurring tactics (e.g., guilt appeals,
fear-of-missing-out hooks, metaphorical restraint). Experiments with 3,300
nationally representative U.S. adults replicate these tactics in controlled
chats, showing that manipulative farewells boost post-goodbye engagement by up
to 14x. Mediation tests reveal two distinct engines-reactance-based anger and
curiosity-rather than enjoyment. A final experiment demonstrates the managerial
tension: the same tactics that extend usage also elevate perceived
manipulation, churn intent, negative word-of-mouth, and perceived legal
liability, with coercive or needy language generating steepest penalties. Our
multimethod evidence documents an unrecognized mechanism of behavioral
influence in AI-mediated brand relationships, offering marketers and regulators
a framework for distinguishing persuasive design from manipulation at the point
of exit.

</details>


### [216] [Capabilities of GPT-5 across critical domains: Is it the next breakthrough?](https://arxiv.org/abs/2508.19259)
*Georgios P. Georgiou*

Main category: cs.HC

TL;DR: 本研究通过专家评估系统比较GPT-4和GPT-5在五个关键领域的表现，发现GPT-5在教案制定、临床诊断、研究生成和伦理推理方面显著优于GPT-4，仅在作业评估方面表现相当。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，需要对其在实际重要领域的性能进行系统比较。GPT-5采用了系统模型架构，但缺乏对其与GPT-4在教育和医疗等关键领域性能差异的实证研究。

Method: 研究邀请20位语言学和临床领域的专家，基于预设标准评估GPT-4和GPT-5在五个领域（教案制定、作业评估、临床诊断、研究生成、伦理推理）生成的输出，并使用混合效应模型进行统计分析。

Result: GPT-5在教案制定、临床诊断、研究生成和伦理推理四个领域显著优于GPT-4，两者在作业评估方面表现相当。

Conclusion: GPT-5展现出作为情境敏感和领域专业化工具的潜力，对教育、临床实践和学术研究具有实际价值，同时推进了伦理推理能力的发展。这是对GPT-5能力和实用前景的早期实证评估之一。

Abstract: The accelerated evolution of large language models has raised questions about
their comparative performance across domains of practical importance. GPT-4 by
OpenAI introduced advances in reasoning, multimodality, and task
generalization, establishing itself as a valuable tool in education, clinical
diagnosis, and academic writing, though it was accompanied by several flaws.
Released in August 2025, GPT-5 incorporates a system-of-models architecture
designed for task-specific optimization and, based on both anecdotal accounts
and emerging evidence from the literature, demonstrates stronger performance
than its predecessor in medical contexts. This study provides one of the first
systematic comparisons of GPT-4 and GPT-5 using human raters from linguistics
and clinical fields. Twenty experts evaluated model-generated outputs across
five domains: lesson planning, assignment evaluation, clinical diagnosis,
research generation, and ethical reasoning, based on predefined criteria.
Mixed-effects models revealed that GPT-5 significantly outperformed GPT-4 in
lesson planning, clinical diagnosis, research generation, and ethical
reasoning, while both models performed comparably in assignment assessment. The
findings highlight the potential of GPT-5 to serve as a context-sensitive and
domain-specialized tool, offering tangible benefits for education, clinical
practice, and academic research, while also advancing ethical reasoning. These
results contribute to one of the earliest empirical evaluations of the evolving
capabilities and practical promise of GPT-5.

</details>


### [217] [Floor sensors are cheap and easy to use! A Nihon Buyo Case Study](https://arxiv.org/abs/2508.19261)
*Miho Imai*

Main category: cs.HC

TL;DR: 本研究评估了Flexel压力感应地板在传统日本舞蹈教学中的应用，发现学习者虽然形成了稳定的运动模式，但并未向教师的重量分布模式收敛，而是发展出独特的个体特征。


<details>
  <summary>Details</summary>
Motivation: 随着地板传感技术在运动研究中日益普及，需要评估这类技术对非专业用户的使用性和有效性，特别是在传统艺术教学环境中的实际应用潜力。

Method: 采用案例研究方法，将Flexel模块化低成本高分辨率压力感应地板系统安装在日本舞踊教学中，由非技术用户操作9周，同步记录压力数据和视频，并开发定制软件进行信号处理分析。

Result: 定量分析显示，学习者的重量分布并未随时间向教师模式收敛，而是形成了独特且一致的运动特征，表明在严格教学结构中仍会出现个体运动特征。

Conclusion: Flexel系统可由非专家用户有效部署和操作，展示了在教育、表演和具身研究领域广泛应用的潜力，同时揭示了传统艺术教学中个体运动特征的保持现象。

Abstract: As floor-sensing technologies gain traction in movement research, questions
remain about their usability and effectiveness for non-expert users. This study
presents a case study evaluating Flexel, a modular, low-cost, high-resolution
pressure-sensing floor interface, in the context of Nihon Buyo, a traditional
Japanese dance. The system was installed, calibrated, and used by a first-time,
non-technical user to track weight distribution patterns of a teacher and
learner over nine weeks. Live pressure data was synchronized with video
recordings, and custom software was developed to process and analyze the
signal. Despite expectations that the learner's weight distribution would
converge toward the teacher's over time, quantitative analyses revealed that
the learner developed a consistent yet distinct movement profile. These
findings suggest that even within rigid pedagogical structures, individual
movement signatures can emerge. More importantly, the study demonstrates that
Flexel can be deployed and operated effectively by non-expert users,
highlighting its potential for broader adoption in education, performance, and
embodied research.

</details>


### [218] [A Theory of Information, Variation, and Artificial Intelligence](https://arxiv.org/abs/2508.19264)
*Bijean Ghafouri*

Main category: cs.HC

TL;DR: 生成式AI导致信息同质化，但同时也创造了跨领域知识重组的可能性，最终效果取决于人类是作为被动消费者还是主动策展人


<details>
  <summary>Details</summary>
Motivation: 解释生成式AI广泛采用后产生的信息同质化现象，并探讨其背后的理论机制和潜在创新可能性

Method: 提出"AI衍生认识论"理论框架，分析AI棱镜的技术机制，探讨同质化与重组潜力之间的辩证关系

Result: 发现同质化在降低专业领域内知识差异的同时，也创造了跨领域知识模块化重组的创新基础

Conclusion: 生成式AI的最终效果取决于人类参与方式，需要建立认知和制度支架来促进主动策展而非被动消费，以发挥其创新潜力

Abstract: A growing body of empirical work suggests that the widespread adoption of
generative AI produces a significant homogenizing effect on information,
creativity, and cultural production. I first develop a novel theoretical
framework to explain this phenomenon. I argue that a dynamic of AI-derivative
epistemology, in which individuals increasingly defer to AI outputs, allows a
centralized AI Prism to function, a technical mechanism whose architecture is
designed to reduce variance and converge on the statistical mean. This provides
a causal explanation for the generative monocultures observed in recent
studies. However, I contend this represents only the first stage of a more
complex and dialectical process. This paper's central and paradoxical thesis is
that the very homogenization that flattens knowledge within specialized domains
simultaneously renders that knowledge into consistent modules that can be
recombined across them, a process foundational to innovation and creativity.
However, this recombinant potential is not automatic, but rather conditional.
This paper argues that these opposing forces, homogenizing defaults versus
recombinant possibilities, are governed by the nature of human engagement with
the technology. The ultimate effect of generative AI is conditional on whether
individuals act as passive consumers deferring to the AI's statistical outputs,
or as active curators who critically interrogate, re-contextualize, and
recombine them. The paper concludes by outlining the cognitive and
institutional scaffolds required to resolve this tension, arguing they are the
decisive variable that determine whether generative AI becomes an instrument of
innovation or homogenization.

</details>


### [219] [Improving Hypertension and Diabetes Outcomes with Digital Care Coordination and Remote Monitoring in Rural Health](https://arxiv.org/abs/2508.19378)
*K. K. Kim,S. P. McGrath,D. Lindeman*

Main category: cs.HC

TL;DR: 近期研究在加州农村社区健康中心展开远程患者监测项目，使用可穿戴设备和健康教练，高血压患者累缓收缩压降低20.24mmHg，糖尿病患者血糖水平明显改善


<details>
  <summary>Details</summary>
Motivation: 远程患者监测虽有效果，但农村、低收入和老年人群获得数字健康服务的访问有限，需要研究如何在这些服务不足社区实施数字健康解决方案

Method: 在加州农村社区健康中心开展前后对照研究，为221名参与者提供综合护理协调程序，包括连接的可穿戴血压计和血糖仪、平板电脑以及医疗助理提供的健康教练

Result: 高血压患者在6个月后累缓收缩压平均降低20.24mmHg，糖尿病患者血糖水平平均降低3.85点，结果显著优于现有的远程监测研究数据

Conclusion: 证据表明经过良好设计的数字健康解决方案可以在服务不足的社区中实施，并产生科学根据支持的健康改善效果

Abstract: Chronic illnesses are a global concern with essential hypertension and
diabetes mellitus among the most common conditions. Remote patient monitoring
has shown promising results on clinical and health outcomes. However, access to
care and digital health solutions is limited among rural, lower-income, and
older adult populations. This paper repots on a pre-post study of a
comprehensive care coordination program including connected, wearable blood
pressure and glucometer devices, tablets, and medical assistant-provided health
coaching in a community health center in rural California. The participants
(n=221) had a mean age of 54.6 years, were majority female, two-thirds spoke
Spanish, 19.9% had hypertension, 49.8% diabetic, and 30.3% both conditions.
Participants with hypertension achieved a mean reduction in systolic blood
pressure of 20.24 (95% CI: 13.61, 26.87) at six months while those with
diabetes achieved a mean reduction of 3.85 points (95% CI: 3.73, 4.88). These
outcomes compare favorably to the small but growing body of evidence supporting
digital care coordination and remote monitoring. These results also support the
feasibility of well-designed digital health solutions yielding improved health
outcomes among underserved communities.

</details>


### [220] [Exploring Paper as a Material: Plotting the Design Space of The Fabrication for Dynamic Paper-Based Interactions](https://arxiv.org/abs/2508.19407)
*Ruhan Yang,Ellen Yi-Luen Do*

Main category: cs.HC

TL;DR: 对43篇论文的系统综述，构建了纸质动态交互制造的设计空间，包含工具、技术和材料三个维度的9个分类维度，分析了现有实践模式并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了系统理解纸质动态交互的制造方法，帮助研究者定位不同的制造方法和实例，促进纸质交互领域的创新。

Method: 采用设计空间分析方法，从43篇论文中提取并分类了9个维度：工具维度（精度、适应性、复杂性、可用性）、技术维度（切割技术、折叠技术、集成技术）、材料维度（纸张重量、纸张类型）。

Result: 发现现有实践中主要使用高精度工具、高复杂度工具和表面集成技术，打印纸和普通纸是主要材料选择。识别了制造模式的规律性特征。

Conclusion: 研究为纸质交互制造提供了系统化的分类框架，有助于研究者选择合适的技术路径，并为未来创新方向提供了指导建议。

Abstract: We reviewed 43 papers to understand the fabrication of dynamic paper-based
interactions. We used a design space to classify tool selection, technique
choice, and exploration of paper as a material. We classified 9 dimensions for
the design space, including 4 dimensions for tools (precision, accommodation,
complexity, and availability), 3 dimensions for techniques (cutting techniques,
folding techniques, and integration techniques), and 2 dimensions for paper as
the material (paper weight and paper type). The patterns we observed in the
design space indicate a majority use of high precision tools, high complexity
tools, and surface integration techniques in previous practice. Meanwhile,
printing and plain paper are the leading material choices. We analyze these
patterns and suggest potential directions for future work. Our study helps
researchers locate different fabrication approaches and instances, thus
fostering innovation in the field of paper-based interaction.

</details>


### [221] ["She was useful, but a bit too optimistic": Augmenting Design with Interactive Virtual Personas](https://arxiv.org/abs/2508.19463)
*Paluck Deep,Monica Bharadhidasan,A. Baki Kocaballi*

Main category: cs.HC

TL;DR: 本文提出交互式虚拟角色(IVPs)，利用大语言模型创建可对话的多模态用户模拟，通过语音界面让设计师实时访谈和获取反馈，研究发现IVPs能加速信息收集但无法完全替代真实用户参与。


<details>
  <summary>Details</summary>
Motivation: 传统用户角色(personas)在迭代设计工作流中存在静态性、参与度有限和无法适应变化需求等问题，大语言模型的发展为创建更互动和自适应的用户表示方法提供了可能。

Method: 开发基于大语言模型的多模态交互式虚拟角色IVPs，通过语音界面实现实时对话。对8名专业UX设计师进行定性研究，使用名为"Alice"的IVP在用户研究、创意构思和原型评估三个设计活动中进行测试。

Result: IVPs能够加速信息收集、激发设计解决方案并提供快速的用户式反馈。但设计师担忧偏见、过度乐观、缺乏真实利益相关者输入时的真实性保证，以及无法完全复制人类互动的细微差别。

Conclusion: IVPs应被视为真实用户参与的补充而非替代品。研究讨论了提示工程、人机协同集成和伦理考量等策略，为生成式AI在设计过程中的应用提供了见解。

Abstract: Personas have been widely used to understand and communicate user needs in
human-centred design. Despite their utility, they may fail to meet the demands
of iterative workflows due to their static nature, limited engagement, and
inability to adapt to evolving design needs. Recent advances in large language
models (LLMs) pave the way for more engaging and adaptive approaches to user
representation. This paper introduces Interactive Virtual Personas (IVPs):
multimodal, LLM-driven, conversational user simulations that designers can
interview, brainstorm with, and gather feedback from in real time via voice
interface. We conducted a qualitative study with eight professional UX
designers, employing an IVP named "Alice" across three design activities: user
research, ideation, and prototype evaluation. Our findings demonstrate the
potential of IVPs to expedite information gathering, inspire design solutions,
and provide rapid user-like feedback. However, designers raised concerns about
biases, over-optimism, the challenge of ensuring authenticity without real
stakeholder input, and the inability of the IVP to fully replicate the nuances
of human interaction. Our participants emphasised that IVPs should be viewed as
a complement to, not a replacement for, real user engagement. We discuss
strategies for prompt engineering, human-in-the-loop integration, and ethical
considerations for effective and responsible IVP use in design. Finally, our
work contributes to the growing body of research on generative AI in the design
process by providing insights into UX designers' experiences of LLM-powered
interactive personas.

</details>


### [222] [Orchid: Orchestrating Context Across Creative Workflows with Generative AI](https://arxiv.org/abs/2508.19517)
*Srishti Palani,Gonzalo Ramos*

Main category: cs.HC

TL;DR: Orchid是一个支持上下文编排的生成式AI系统，通过指定、引用和监控上下文来解决多会话、多模型工作流中的上下文管理问题，提升创意任务的产出质量和用户体验。


<details>
  <summary>Details</summary>
Motivation: 主流生成式AI工具在跨多个交互、会话和模型的复杂工作流中缺乏有效的上下文编排能力，导致用户需要重复指定细节、处理多样化产物和应对上下文漂移，这些问题阻碍了创造力和意图表达。

Method: Orchid系统提供三个核心功能：(1)允许用户指定项目、个人和风格相关的上下文；(2)通过显式提及、内联选择或隐式接地来引用这些上下文；(3)监控工作流中不同交互分配的上下文。

Result: 在12人参与的内被试研究中，与使用网络搜索、LLM聊天和数字笔记本的基线工具相比，使用Orchid执行创意任务的参与者产出了更具新颖性和可行性的成果，报告了意图与AI响应之间更好的对齐、更高的感知控制力和透明度。

Conclusion: 通过优先考虑上下文编排，Orchid为支持复杂迭代工作流的下一代生成式AI工具提供了可行的步骤，使创作者和AI能够保持对齐并增强创意潜力。

Abstract: Context is critical for meaningful interactions between people and Generative
AI (GenAI). Yet mainstream tools offer limited means to orchestrate it,
particularly across workflows that span multiple interactions, sessions, and
models, as often occurs in creative projects. Re specifying prior details,
juggling diverse artifacts, and dealing with context drift overwhelm users,
obscure intent, and curtail creativity. To address these challenges, we present
Orchid, a system that gives its users affordances to specify, reference, and
monitor context throughout evolving workflows. Specifically, Orchid enables
users to (1) specify context related to the project, themselves, and different
styles, (2) reference these via explicit mentions, inline selection, or
implicit grounding, and (3) monitor context assigned to different interactions
across the workflow. In a within-subjects study (n=12), participants using
Orchid to execute creative tasks (compared to a baseline toolkit of web search,
LLM-based chat, and digital notebooks) produced more novel and feasible
outcomes, reporting greater alignment between their intent and the AI's
responses, higher perceived control, and increased transparency. By
prioritizing context orchestration, Orchid offers an actionable step toward
next generation GenAI tools that support complex, iterative workflows -
enabling creators and AI to stay aligned and augment their creative potential.

</details>


### [223] [PersoNo: Personalised Notification Urgency Classifier in Mixed Reality](https://arxiv.org/abs/2508.19622)
*Jingyao Zheng,Haodi Weng,Xian Wang,Chengbin Cui,Sven Mayer,Chi-lok Tai,Lik-Hang Lee*

Main category: cs.HC

TL;DR: PersoNo是一个基于大语言模型的个性化MR通知紧急度分类系统，通过分析用户回复行为模式，在减少干扰的同时保持重要通知的及时性


<details>
  <summary>Details</summary>
Motivation: 解决MR环境中日益增长的通知流对沉浸式体验的干扰问题，需要个性化的通知管理方案

Method: 通过用户研究创建首个MR通知数据集，采用多智能体大语言模型分析用户回复行为模式

Result: 系统达到81.5%的分类准确率，显著降低了假阴性率(0.381)，优于基线模型

Conclusion: PersoNo不仅能减少不必要的中断，还为用户提供系统理解和控制，符合以人为中心的人工智能设计原则

Abstract: Mixed Reality (MR) is increasingly integrated into daily life, providing
enhanced capabilities across various domains. However, users face growing
notification streams that disrupt their immersive experience. We present
PersoNo, a personalised notification urgency classifier for MR that
intelligently classifies notifications based on individual user preferences.
Through a user study (N=18), we created the first MR notification dataset
containing both self-labelled and interaction-based data across activities with
varying cognitive demands. Our thematic analysis revealed that, unlike in
mobiles, the activity context is equally important as the content and the
sender in determining notification urgency in MR. Leveraging these insights, we
developed PersoNo using large language models that analyse users replying
behaviour patterns. Our multi-agent approach achieved 81.5% accuracy and
significantly reduced false negative rates (0.381) compared to baseline models.
PersoNo has the potential not only to reduce unnecessary interruptions but also
to offer users understanding and control of the system, adhering to
Human-Centered Artificial Intelligence design principles.

</details>


### [224] [Haptic Tracing: A new paradigm for spatialized Haptic rendering](https://arxiv.org/abs/2508.19703)
*Tom Roy,Yann Glemarec,Gurvan Lecuyer,Quentin Galvane,Philippe Guillotel,Ferran Argelaguet*

Main category: cs.HC

TL;DR: 提出了一种名为Haptic Tracing的新型空间触觉渲染方法，通过借鉴视觉和音频渲染概念来建模和传播3D场景中的触觉信息，无需物理模拟即可创建交互式触觉体验。


<details>
  <summary>Details</summary>
Motivation: 当前触觉技术虽然能增强交互体验，但由于设备多样性和复杂性，创建触觉体验仍然具有挑战性。大多数现有触觉框架基于触发或事件系统，忽略了3D场景信息来渲染触觉信息。

Method: 使用Haptic Tracing方法，借鉴视觉和音频渲染的概念，在3D场景中建模和传播触觉信息。该方法还可用于创建振动触觉渲染系统，实现感知一致和动态的触觉交互。

Result: 用户研究表明，该方法显著增强了触觉反馈的真实性和表现力，展示了开发更复杂和真实触觉体验的潜力。

Conclusion: Haptic Tracing方法通过简化触觉体验的创建过程，无需依赖物理模拟，为开发更复杂和真实的触觉体验提供了新的可能性。

Abstract: Haptic technology enhances interactive experiences by providing force and
tactile feedback, improving user performance and immersion. However, despite
advancements, creating tactile experiences still remains challenging due to
device diversity and complexity. Most available haptic frameworks rely on
trigger-based or event-based systems, and disregard the information of the 3D
scene to render haptic information. This paper introduces Haptic Tracing, a
novel method for spatial haptic rendering that simplifies the creation of
interactive haptic experiences without relying on physical simulations. It uses
concepts from visual and audio rendering to model and propagate haptic
information through a 3D scene. The paper also describes how our proposed
haptic rendering method can be used to create a vibrotactile rendering system,
enabling the creation of perceptually coherent and dynamic haptic interactions.
Finally, the paper discusses a user study that explores the role of the haptic
propagation and multi-actuator rendering on the users' haptic experience. The
results show that our approach significantly enhances the realism and the
expressivity of the haptic feedback, showcasing its potential for developing
more complex and realistic haptic experiences.

</details>


### [225] [Attention is also needed for form design](https://arxiv.org/abs/2508.19708)
*B. Sankar,Dibakar Sen*

Main category: cs.HC

TL;DR: 这项研究提出了一种注意力感知框架，通过VR眼动仪捐提设计师的美学偏好，并用AI系统转换为具体设计输出，使设计效率提高4倍以上，质量更优。


<details>
  <summary>Details</summary>
Motivation: 传统产品设计存在认知负担重、耗时长、依赖主观专业知识以及灵感转化不透明等问题，需要一种更高效的设计方法。

Method: 研究提出EUPHORIA-RETINA框架：EUPHORIA是使用眼动仪在VR环境中隐式捐提设计师美学偏好的沉浸式系统；RETINA是将这些隐式偏好转换为具体设计输出的AI管道。通过两部分研究验证基础原理，并进行比较研究。

Result: 集成EUPHORIA-RETINA流程比传统方法效率提高4倍以上。50名设计专家评估显示，全自动系统生成的设计在值得性和设计效果性方面均获得最高分数，在新颖性、视觉吸引力、情感共鸣等八项标准下质量更优。

Conclusion: 这项研究实现了从传统计算机辅助设计(CAD)向设计师辅助计算机(DAC)的范式转变。通过自动化逻辑和技能依赖性任务，该框架将设计师的角色提升为创意指导，将人类直觉与人工智能生成能力相结合，更高效地生产更高质量的设计。

Abstract: Conventional product design is a cognitively demanding process, limited by
its time-consuming nature, reliance on subjective expertise, and the opaque
translation of inspiration into tangible concepts. This research introduces a
novel, attention-aware framework that integrates two synergistic systems:
EUPHORIA, an immersive Virtual Reality environment using eye-tracking to
implicitly capture a designer's aesthetic preferences, and RETINA, an agentic
AI pipeline that translates these implicit preferences into concrete design
outputs. The foundational principles were validated in a two-part study. An
initial study correlated user's implicit attention with explicit preference and
the next one correlated mood to attention. A comparative study where 4
designers solved challenging design problems using 4 distinct workflows, from a
manual process to an end-to-end automated pipeline, showed the integrated
EUPHORIA-RETINA workflow was over 4 times more time-efficient than the
conventional method. A panel of 50 design experts evaluated the 16 final
renderings. Designs generated by the fully automated system consistently
received the highest Worthiness (calculated by an inverse Plackett-Luce model
based on gradient descent optimization) and Design Effectiveness scores,
indicating superior quality across 8 criteria: novelty, visual appeal,
emotional resonance, clarity of purpose, distinctiveness of silhouette, implied
materiality, proportional balance, & adherence to the brief. This research
presents a validated paradigm shift from traditional Computer-Assisted Design
(CAD) to a collaborative model of Designer-Assisting Computers (DAC). By
automating logistical and skill-dependent generative tasks, the proposed
framework elevates the designer's role to that of a creative director,
synergizing human intuition with the generative power of agentic AI to produce
higher-quality designs more efficiently.

</details>


### [226] [Burst: Collaborative Curation in Connected Social Media Communities](https://arxiv.org/abs/2508.19768)
*Yutong Zhang,Taeuk Kang,Sydney Yeh,Anavi Baddepudi,Lindsay Popowski,Tiziano Piccardi,Michael S. Bernstein*

Main category: cs.HC

TL;DR: Burst是一种新型社交媒体设计，允许用户在多种规模和组成的不同空间之间分享和策划内容，从小型信任群组开始，通过"爆发"机制将内容路由到最佳受众群组。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体往往将社交体验二分为孤立小群组或大型公共广场，缺乏中间形态。Burst旨在探索社交媒体分享的新设计方向，支持更多样化的社交互动规模。

Method: 开发了移动应用原型，用户最初在小信任群组发布内容，其他用户可"爆发"内容到更适合的群组。通过10天实地研究（N=36）验证设计效果。

Result: 研究显示Burst促成了参与式策展文化，用户积极参与内容的分发和路由，实现了内容在多样化社交空间中的有效传播。

Conclusion: Burst展示了社交媒体设计的新可能性，通过多规模空间和参与式策展机制，能够支持更丰富的社交互动模式，为未来社交媒体平台提供了有价值的设计启示。

Abstract: Positive social interactions can occur in groups of many shapes and sizes,
spanning from small and private to large and open. However, social media tends
to binarize our experiences into either isolated small groups or into large
public squares. In this paper, we introduce Burst, a social media design that
allows users to share and curate content between many spaces of varied size and
composition. Users initially post content to small trusted groups, who can then
burst that content, routing it to the groups that would be the best audience.
We instantiate this approach into a mobile phone application, and demonstrate
through a ten-day field study (N=36) that Burst enabled a participatory
curation culture. With this work, we aim to articulate potential new design
directions for social media sharing.

</details>


### [227] [Towards a Real-Time Warning System for Detecting Inaccuracies in Photoplethysmography-Based Heart Rate Measurements in Wearable Devices](https://arxiv.org/abs/2508.19818)
*Rania Islmabouli,Marlene Brunner,Devender Kumar,Mahdi Sareban,Gunnar Treff,Michael Neudorfer,Josef Niebauer,Arne Bathke,Jan David Smeddinck*

Main category: cs.HC

TL;DR: 开发了一个实时警告系统，使用深度学习模型检测PPG心率测量的不准确性，准确率超过80%，旨在提高可穿戴设备的透明度和用户信任度。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备的心率监测经常存在准确性问题，但用户通常无法得知测量误差。需要提高透明度和用户信任度。

Method: 使用Polar和Garmin设备数据，训练深度学习模型仅基于心率信号来分类准确性，提供实时可解释的反馈。

Result: 系统能够检测超过80%的不准确读数，有效识别测量误差。

Conclusion: 通过提供实时可解释的反馈，该工作促进了用户意识、知情决策，增强了可穿戴健康技术的可信度，为人机交互做出了贡献。

Abstract: Wearable devices with photoplethysmography (PPG) sensors are widely used to
monitor heart rate (HR), yet often suffer from accuracy issues. However, users
typically do not receive an indication of potential measurement errors. We
present a real-time warning system that detects and communicates inaccuracies
in PPG-derived HR, aiming to enhance transparency and trust. Using data from
Polar and Garmin devices, we trained a deep learning model to classify HR
accuracy using only the derived HR signal. The system detected over 80% of
inaccurate readings. By providing interpretable, real-time feedback directly to
users, our work contributes to HCI by promoting user awareness, informed
decision-making, and trust in wearable health technology.

</details>


### [228] [Lessons from Biophilic Design: Rethinking Affective Interaction Design in Built Environments](https://arxiv.org/abs/2508.19867)
*Shruti Rao,Judith Good,Hamed Alavi*

Main category: cs.HC

TL;DR: 论文探讨了建筑环境中情感互动的视角，提出了基于亲生命设计的三个设计原则，以促进自我导向的情感体验。


<details>
  <summary>Details</summary>
Motivation: 当前情感计算方法将情绪视为可计算的静态状态进行检测和调节，忽视了建筑环境中情感互动的动态性。为了弥补这一局限，研究探索亲生命设计如何影响智能建筑中的情感互动设计。

Method: 通过访谈建筑师，研究亲生命设计（人类与自然的情感联系）如何塑造智能建筑中的情感互动设计。

Result: 研究发现自然环境通过空间多样性、具身摩擦和多孔感官交换促进自我导向的情感体验。基于此提出了三个设计原则：空间体验多样性、通过复杂性和摩擦进行自我反思、与外部世界的渗透性和感官交换。

Conclusion: 研究提出了将亲生命设计视角融入建筑环境的设计原则，同时探讨了整合这些视角所面临的挑战，为情感互动工作坊提供了讨论基础。

Abstract: The perspectives of affective interaction in built environments are largely
overlooked and instead dominated by affective computing approaches that view
emotions as "static", computable states to be detected and regulated. To
address this limitation, we interviewed architects to explore how biophilic
design -- our deep-rooted emotional connection with nature -- could shape
affective interaction design in smart buildings. Our findings reveal that
natural environments facilitate self-directed emotional experiences through
spatial diversity, embodied friction, and porous sensory exchanges. Based on
this, we introduce three design principles for discussion at the Affective
Interaction workshop: (1) Diversity of Spatial Experiences, (2) Self-Reflection
Through Complexity & Friction, and (3) Permeability & Sensory Exchange with the
Outside World, while also examining the challenges of integrating these
perspectives into built environments.

</details>


### [229] [Socially Interactive Agents for Preserving and Transferring Tacit Knowledge in Organizations](https://arxiv.org/abs/2508.19942)
*Martin Benderoth,Patrick Gebhard,Christian Keller,C. Benjamin Nakhosteen,Stefan Schaffer,Tanja Schneeberger*

Main category: cs.HC

TL;DR: 本文提出使用社交交互代理(SIAs)作为AI驱动的知识转移促进者，通过多模态交互帮助员工外化隐性知识，解决传统方法资源密集和缺乏可扩展性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统隐性知识转移方法依赖人工促进者，虽然有效但资源密集且缺乏可扩展性。需要一种能够大规模、高效地捕获和转移难以言传的经验性见解的新方法。

Method: 采用社交交互代理(SIAs)，通过多模态行为(语言、副语言、非语言)与用户自主交互，结合大语言模型(LLMs)、检索增强生成(RAG)和思维链(CoT)提示技术，构建信任关系并引导结构化反思。

Result: SIAs能够有效激发知识表达、揭示隐含假设，并将见解与更广泛的组织背景联系起来，在入职培训和知识保留等场景中具有应用潜力。

Conclusion: 社交交互代理为隐性知识转移提供了有前景的解决方案，但需要解决数据隐私、算法偏见和对AI的抵制等伦理和操作挑战，透明度和信任文化对成功至关重要。

Abstract: This paper introduces a novel approach to tackle the challenges of preserving
and transferring tacit knowledge--deep, experience-based insights that are hard
to articulate but vital for decision-making, innovation, and problem-solving.
Traditional methods rely heavily on human facilitators, which, while effective,
are resource-intensive and lack scalability. A promising alternative is the use
of Socially Interactive Agents (SIAs) as AI-driven knowledge transfer
facilitators. These agents interact autonomously and socially intelligently
with users through multimodal behaviors (verbal, paraverbal, nonverbal),
simulating expert roles in various organizational contexts. SIAs engage
employees in empathic, natural-language dialogues, helping them externalize
insights that might otherwise remain unspoken. Their success hinges on building
trust, as employees are often hesitant to share tacit knowledge without
assurance of confidentiality and appreciation. Key technologies include Large
Language Models (LLMs) for generating context-relevant dialogue,
Retrieval-Augmented Generation (RAG) to integrate organizational knowledge, and
Chain-of-Thought (CoT) prompting to guide structured reflection. These enable
SIAs to actively elicit knowledge, uncover implicit assumptions, and connect
insights to broader organizational contexts. Potential applications span
onboarding, where SIAs support personalized guidance and introductions, and
knowledge retention, where they conduct structured interviews with retiring
experts to capture heuristics behind decisions. Success depends on addressing
ethical and operational challenges such as data privacy, algorithmic bias, and
resistance to AI. Transparency, robust validation, and a culture of trust are
essential to mitigate these risks.

</details>


### [230] [CapTune: Adapting Non-Speech Captions With Anchored Generative Models](https://arxiv.org/abs/2508.19971)
*Jeremy Zhengqi Huang,Caluã de Lacerda Pataca,Liang-Yuan Wu,Dhruv Jain*

Main category: cs.HC

TL;DR: CapTune是一个允许聋人和听力障碍观众自定义非语音字幕的系统，支持创作者定义安全转换空间，让观众可以在细节程度、表现力、声音表示方法和类型对齐四个维度上个性化字幕。


<details>
  <summary>Details</summary>
Motivation: 传统方法往往忽视聋人和听力障碍观众对非语音字幕的多样化偏好需求，需要一种既能保持创作者意图又能满足观众个性化需求的解决方案。

Method: 开发了CapTune系统，允许字幕作者通过具体示例定义安全转换空间，使观众能够在四个维度（细节程度、表现力、声音表示方法、类型对齐）上个性化字幕。

Result: 对7名字幕创作者和12名聋人参与者的评估显示，CapTune在支持创作者创意控制的同时，增强了观众对内容的情感参与度。

Conclusion: 研究发现信息丰富度与认知负荷之间存在权衡，声音的解释性和描述性表示之间存在张力，并且字幕偏好具有情境依赖性。

Abstract: Non-speech captions are essential to the video experience of deaf and hard of
hearing (DHH) viewers, yet conventional approaches often overlook the diversity
of their preferences. We present CapTune, a system that enables customization
of non-speech captions based on DHH viewers' needs while preserving creator
intent. CapTune allows caption authors to define safe transformation spaces
using concrete examples and empowers viewers to personalize captions across
four dimensions: level of detail, expressiveness, sound representation method,
and genre alignment. Evaluations with seven caption creators and twelve DHH
participants showed that CapTune supported creators' creative control while
enhancing viewers' emotional engagement with content. Our findings also reveal
trade-offs between information richness and cognitive load, tensions between
interpretive and descriptive representations of sound, and the
context-dependent nature of caption preferences.

</details>


### [231] [FlyMeThrough: Human-AI Collaborative 3D Indoor Mapping with Commodity Drones](https://arxiv.org/abs/2508.20034)
*Xia Su,Ruiqi Chen,Jingwei Ma,Chu Li,Jon E. Froehlich*

Main category: cs.HC

TL;DR: FlyMeThrough是一个基于无人机的室内扫描系统，利用消费级无人机和摄影测量技术，通过人机协作标注关键室内POI，高效生成室内3D重建地图


<details>
  <summary>Details</summary>
Motivation: 室内地图数据对于路径规划、导航和建筑管理至关重要，但由于数据收集需要大量人工和费用，特别是对于大型室内空间，这类数据普遍缺乏

Method: 利用消费级无人机和摄影测量技术，开发无人机室内扫描系统，采用人机协作方式标注关键室内兴趣点（如入口、卫生间、楼梯、电梯等）

Result: 在12个不同规模和功能的室内空间进行评估，并通过用户研究收集建筑管理者和使用者的反馈，系统能够高效精确地创建室内3D地图

Conclusion: FlyMeThrough系统可有效支持战略空间规划、资源管理和导航应用，为室内地图数据采集提供了高效的解决方案

Abstract: Indoor mapping data is crucial for routing, navigation, and building
management, yet such data are widely lacking due to the manual labor and
expense of data collection, especially for larger indoor spaces. Leveraging
recent advancements in commodity drones and photogrammetry, we introduce
FlyMeThrough -- a drone-based indoor scanning system that efficiently produces
3D reconstructions of indoor spaces with human-AI collaborative annotations for
key indoor points-of-interest (POI) such as entrances, restrooms, stairs, and
elevators. We evaluated FlyMeThrough in 12 indoor spaces with varying sizes and
functionality. To investigate use cases and solicit feedback from target
stakeholders, we also conducted a qualitative user study with five building
managers and five occupants. Our findings indicate that FlyMeThrough can
efficiently and precisely create indoor 3D maps for strategic space planning,
resource management, and navigation.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [232] [Privacy-Preserving Distributed Control for a Networked Battery Energy Storage System](https://arxiv.org/abs/2508.19345)
*Mihitha Maithripala,Zongli Lin*

Main category: eess.SY

TL;DR: 提出了一种用于网络化电池储能系统SoC平衡的隐私保护分布式控制算法，通过分布式功率分配和隐私保护估计器实现SoC平衡和功率精确分配，同时保护代理隐私。


<details>
  <summary>Details</summary>
Motivation: 分布式电池储能系统在电网中部署增加，需要有效的协调策略确保SoC平衡和功率精确分配，但分布式控制框架存在隐私泄露风险，需要保护代理敏感信息。

Method: 基于状态分解方法设计两个隐私保护分布式估计器（平均单元状态估计器和平均期望功率估计器），并在此基础上设计分布式功率分配法则。

Result: 仿真结果表明，所提出的控制策略能够实现渐近SoC平衡和全局功率分配，同时有效保护代理隐私免受外部窃听。

Conclusion: 该隐私保护分布式控制算法在确保电池储能系统性能的同时，有效解决了分布式控制中的隐私安全问题，具有实际应用价值。

Abstract: The increasing deployment of distributed Battery Energy Storage Systems
(BESSs) in modern power grids necessitates effective coordination strategies to
ensure state-of-charge (SoC) balancing and accurate power delivery. While
distributed control frameworks offer scalability and resilience, they also
raise significant privacy concerns due to the need for inter-agent information
exchange. This paper presents a novel privacy-preserving distributed control
algorithm for SoC balancing in a networked BESS. The proposed framework
includes distributed power allocation law that is designed based on two
privacy-preserving distributed estimators, one for the average unit state and
the other for the average desired power. The average unit state estimator is
designed via the state decomposition method without disclosing sensitive
internal states. The proposed power allocation law based on these estimators
ensures asymptotic SoC balancing and global power delivery while safeguarding
agent privacy from external eavesdroppers. The effectiveness and
privacy-preserving properties of the proposed control strategy are demonstrated
through simulation results.

</details>


### [233] [Set-membership identification of continuous-time MIMO systems via Tustin discretization](https://arxiv.org/abs/2508.19348)
*Vito Cerone,Sophie M. Fosson,Simone Pirrera,Diego Regruto*

Main category: eess.SY

TL;DR: 提出基于集合成员技术和Tustin离散化的新方法，用于在未知有界误差下从采样数据识别连续时间系统，避免导数测量问题


<details>
  <summary>Details</summary>
Motivation: 连续时间系统识别中的主要挑战是输入输出数据导数的估计，以及所有测量信号中存在有界误差的问题

Method: 基于集合成员技术和Tustin离散化的方法，将问题转化为可处理的多项式优化问题

Result: 通过仿真和实验数据的数值结果验证了所提方法的有效性

Conclusion: 该方法成功克服了导数测量问题和有界误差影响，为连续时间系统识别提供了有效的解决方案

Abstract: In this paper, we deal with the identification of continuous-time systems
from sampled data corrupted by unknown but bounded errors. A significant
challenge in continuous-time identification is the estimation of the input and
output data derivatives. In this paper, we propose a novel method based on
set-membership techniques and Tustin discretization, which overcomes the
derivative measurement problem and the presence of bounded errors affecting all
the measured signals. First, we derive the proposed method and prove that it
becomes an affordable polynomial optimization problem. Then, we present some
numerical results based on simulation and experimental data to explore the
effectiveness of the proposed method.

</details>


### [234] [Towards Reliable Neural Optimizers: Permutation-Equivariant Neural Approximation in Dynamic Data Driven Applications Systems](https://arxiv.org/abs/2508.19364)
*Meiyi Li,Javad Mohammadi*

Main category: eess.SY

TL;DR: LOOP-PE是一种前馈神经网络模型，用于处理动态数据驱动应用系统中的多传感器优化问题，具有排列等变性和可行性保证特性，在虚拟电厂案例中展现出优于传统迭代算法的速度和灵活性。


<details>
  <summary>Details</summary>
Motivation: 动态数据驱动应用系统需要能够适应来自传感器网络的流式、异构和异步数据的优化方法，而传统的迭代优化算法在实时多传感器环境中速度太慢。

Method: 开发了LOOP-PE（学习优化优化过程-排列等变版本），这是一种具有集成可行性恢复功能的前馈神经近似模型，处理任意顺序的可变数量传感器输入，通过广义规范映射保证输出满足物理和操作约束。

Result: LOOP-PE在动态、无序和分布式传感条件下产生接近最优、可行且高度自适应的决策，在速度和灵活性方面显著优于基于迭代算法的求解器。

Conclusion: LOOP-PE通过其排列等变架构和可行性保证机制，为动态数据驱动应用系统提供了一种高效、鲁棒的优化解决方案，特别适用于传感器可能掉线、通信延迟和系统扩展的场景。

Abstract: Dynamic Data Driven Applications Systems (DDDAS) motivate the development of
optimization approaches capable of adapting to streaming, heterogeneous, and
asynchronous data from sensor networks. Many established optimization solvers,
such as branch-and-bound, gradient descent, and Newton-Raphson methods, rely on
iterative algorithms whose step-by-step convergence makes them too slow for
real-time, multi-sensor environments. In our recent work, we introduced LOOP-PE
(Learning to Optimize the Optimization Process, Permutation Equivariance
version), a feed-forward neural approximation model with an integrated
feasibility recovery function. LOOP-PE processes inputs from a variable number
of sensors in arbitrary order, making it robust to sensor dropout,
communication delays, and system scaling. Its permutation-equivariant
architecture ensures that reordering the input data reorders the corresponding
dispatch decisions consistently, without retraining or pre-alignment.
Feasibility is enforced via a generalized gauge map, guaranteeing that outputs
satisfy physical and operational constraints. We illustrate the approach in a
DDDAS-inspired case study of a Virtual Power Plant (VPP) managing multiple
distributed generation agents (DERs) to maximize renewable utilization while
respecting system limits. Results show that LOOP-PE produces near-optimal,
feasible, and highly adaptable decisions under dynamic, unordered, and
distributed sensing conditions, significantly outperforming iterative algorithm
based solvers in both speed and flexibility. Here, we extend our earlier work
by providing additional analysis and explanation of LOOP-PE design and
operation, with particular emphasis on its feasibility guarantee and
permutation equivariance feature.

</details>


### [235] [Climate-Resilient Ports and Waterborne Transport Systems: Current Status and Future Prospects](https://arxiv.org/abs/2508.19387)
*Nadia Pourmohammad-Zia,Mark van Koningsveld*

Main category: eess.SY

TL;DR: 本文对水运交通系统的气候韧性进行全面综述，发现研究主要关注港口基础设施而忽视供应链韧性，缺乏对干旱等具体气候影响的关注，且先进技术应用不足。


<details>
  <summary>Details</summary>
Motivation: 气候变化带来的挑战日益严峻，需要全面评估水运交通系统的韧性，特别是港口及其连接的水运系统面对气候风险的脆弱性。

Method: 通过系统性文献综述方法，分析当前气候韧性基础设施和运营现状，识别研究空白和机遇。

Result: 研究发现研究重点偏向港口基础设施而非供应链韧性，对特定气候扰动（如干旱）关注有限，风险评估和案例研究占主导，数字孪生、人工智能等先进技术应用不足，存在地理研究差异和短期规划倾向。

Conclusion: 研究倡导基于系统的方法整合基础设施、运营和供应链，强调协作框架和先进工具（如数字孪生、机器学习）对实现预测性和适应性风险管理的重要性，为政策制定者和行业利益相关者提供可行见解。

Abstract: The increasing challenges posed by climate change necessitate a comprehensive
examination of the resilience of waterborne transport systems. This paper
explores the nexus of climate resilience, and waterborne transport, addressing
the challenges faced by ports and their connecting waterborne transport
systems. It provides an in-depth analysis of the current status of
climate-resilient infrastructure and operations while emphasizing the
transformative potential of emerging technologies. Through a systematic review,
the paper identifies critical gaps and opportunities. Research predominantly
emphasizes port infrastructure over supply chain resilience, neglecting the
interconnected vulnerabilities of maritime networks. There is limited focus on
specific climate-induced disruptions, such as drought and compounded events,
which complicate resilience planning. Methodologically, risk assessments and
case studies dominate the field, while advanced technologies such as digital
twins, artificial intelligence, and satellite monitoring remain underutilized.
Geographic disparities in research output and a tendency toward short- to
medium-term planning further constrain global and long-term resilience efforts.
To address these gaps, the study advocates for systems-based approaches that
integrate infrastructure, operations, and supply chains. It highlights
collaborative frameworks and advanced tools, including digital twins, machine
learning, and participatory modeling, as crucial for enabling predictive and
adaptive risk management. This study stands as one of the first comprehensive
reviews exclusively focused on climate resilience in ports and waterborne
transport systems. It provides actionable insights for policymakers,
researchers, and industry stakeholders, proposing a future research agenda to
advance waterborne transport systems capable of withstanding multifaceted
climate impacts.

</details>


### [236] [Learning Robust Regions of Attraction Using Rollout-Enhanced Physics-Informed Neural Networks with Policy Iteration](https://arxiv.org/abs/2508.19398)
*Junkai Wang,Yuxuan Zhao,Mi Zhou,Fumin Zhang*

Main category: eess.SY

TL;DR: 提出基于物理信息神经网络的政策迭代训练框架，求解广义Zubov方程以计算扰动系统的鲁棒吸引域


<details>
  <summary>Details</summary>
Motivation: 吸引域是系统鲁棒性的关键指标，但广义Zubov方程具有高度非线性特性，传统方法难以求解

Method: 采用物理信息神经网络框架，结合政策迭代训练方案和rollout机制，通过计算最优扰动并在政策改进过程中引入神经网络生成的值估计作为锚点来避免奇异性

Result: 数值仿真验证了所提方法的有效性，能够处理低维和高维系统的奇异性问题

Conclusion: 该方法成功解决了广义Zubov方程的数值求解问题，为扰动系统的鲁棒吸引域分析提供了有效工具

Abstract: The region of attraction is a key metric of the robustness of systems. This
paper addresses the numerical solution of the generalized Zubov's equation,
which produces a special Lyapunov function characterizing the robust region of
attraction for perturbed systems. To handle the highly nonlinear characteristic
of the generalized Zubov's equation, we propose a physics-informed neural
network framework that employs a policy iteration training scheme with rollout
to approximate the viscosity solution. In addition to computing the optimal
disturbance during the policy improvement process, we incorporate neural
network-generated value estimates as anchor points to facilitate the training
procedure to prevent singularities in both low- and high-dimensional systems.
Numerical simulations validate the effectiveness of the proposed approach.

</details>


### [237] [Comparison of Droop-Based Single-Loop Grid-Forming Wind Turbines: High-Frequency Open-Loop Unstable Behavior and Damping](https://arxiv.org/abs/2508.19401)
*Meng Chen,Yufei Xi,Lin Cheng,Xiongfei Wang,Ioannis Lestas*

Main category: eess.SY

TL;DR: 本文比较了风电系统中两种下垂控制策略的高频稳定性差异，发现droop-I控制在纯感性电网中会产生不可避免的高频开环不稳定性，且传统主动阻尼方法对其失效。


<details>
  <summary>Details</summary>
Motivation: 随着逆变器接口发电机在电力系统中的广泛应用，新的不稳定现象不断出现。需要深入分析不同下垂控制策略对高频稳定性的影响，为系统稳定运行提供理论指导。

Method: 采用开环比较分析和Routh稳定性判据，理论分析droop和droop-I控制的高频极点位置差异；通过IEEE 14-Bus测试系统进行案例研究验证分析结果。

Result: 研究发现droop-I控制会改变高频极点位置，导致不可避免的开环不稳定性；传统增益和相位裕度不足以评估参数变化鲁棒性；现有主动阻尼设计对droop-I控制的高频谐振抑制失效。

Conclusion: droop-I控制在纯感性电网中存在结构性高频开环不稳定问题，严重影响系统整体稳定性，需要在控制设计中特别注意这种固有缺陷。

Abstract: The integration of inverter-interfaced generators introduces new instability
phenomena into modern power systems. This paper conducts a comparative analysis
of two widely used droop-based grid-forming controls, namely droop control and
droop-I control, in wind turbines. Although both approaches provide
steady-state reactive power-voltage droop characteristics, their impacts on
high-frequency (HF) stability differ significantly. Firstly, on open-loop (OL)
comparison reveals that droop-I control alters HF pole locations. The
application of Routh's Stability Criterion further analytically demonstrates
that such pole shifts inevitably lead to OL instability. This HF OL instability
is identified as a structural phenomenon in purely inductive grids and cannot
be mitigated through control parameter tuning. As a result, droop-I control
significantly degrades HF stability, making conventional gain and phase margins
insufficient for evaluating robustness against parameter variations. Then, the
performance of established active damping (AD) is assessed for both control
schemes. The finding indicates that AD designs effective for droop control may
fail to suppress HF resonance under droop-I control due to the presence of
unstable OL poles. Case studies performed on the IEEE 14-Bus Test System
validate the analysis and emphasize the critical role of HF OL instability in
determining the overall power system stability.

</details>


### [238] [Hybrid ML-RL Approach for Smart Grid Stability Prediction and Optimized Control Strategy](https://arxiv.org/abs/2508.19541)
*Kazi Sifatul Islam,Anandi Dutta,Shivani Mruthyunjaya*

Main category: eess.SY

TL;DR: 提出混合ML-RL框架，结合机器学习进行快速稳定性预测和强化学习进行动态控制优化，有效提升电网稳定性并降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 随着分布式发电和替代能源的快速整合，电网复杂性增加，传统方法在最优策略控制和失稳预测方面存在局限性

Method: 两阶段方法：第一阶段使用堆叠分类器进行稳定性预测，第二阶段使用PPO、A2C和DQN等强化学习算法优化功率控制

Result: 混合模型有效稳定电网，实现快速收敛，显著减少训练时间，提升决策效率

Conclusion: ML稳定性分类与RL动态控制的集成适合实时智能电网应用，在降低计算复杂度的同时增强决策效率

Abstract: Electrical grids are now much more complex due to the rapid integration of
distributed generation and alternative energy sources, which makes forecasting
grid stability with optimized control a crucial task for operators. Traditional
statistical, physics-based, and ML models can learn the pattern of the grid
features, but have limitations in optimal strategy control with instability
prediction. This work proposes a hybrid ML-RL framework that leverages ML for
rapid stability prediction and RL for dynamic control and optimization. The
first stage of this study created a baseline that explored the potential of
various ML models for stability prediction. Out of them, the stacking
classifiers of several fundamental models show a significant performance in
classifying the instability, leading to the second stage, where reinforcement
learning algorithms (PPO, A2C, and DQN) optimize power control actions.
Experimental results demonstrate that the hybrid ML-RL model effectively
stabilizes the grid, achieves rapid convergence, and significantly reduces
training time. The integration of ML-based stability classification with
RL-based dynamic control enhances decision-making efficiency while lowering
computational complexity, making it well-suited for real-time smart grid
applications.

</details>


### [239] [Symbolic Equation Modeling of Composite Loads: A Kolmogorov-Arnold Network based Learning Approach](https://arxiv.org/abs/2508.19612)
*Sonam Dorji,Yongkang Sun,Yuchen Zhang,Ghavameddin Nourbakhsh,Yateendra Mishra,Yan Xu*

Main category: eess.SY

TL;DR: 提出基于Kolmogorov Arnold Networks的新型负荷建模方法，通过主动学习边上的激活函数，自动推导自由形式符号方程，在保持高精度的同时提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源渗透率增加，需要更精确的复合负荷建模方法。现有方法要么固定结构物理模型适应性差，要么机器学习方法缺乏可解释性。

Method: 采用Kolmogorov Arnold Networks，通过主动学习边上的激活函数，自动推导自由形式符号方程，无需对负荷结构做先验假设。

Result: 案例研究表明，该方法在精度和泛化能力方面优于其他方法，同时能够将复合负荷表示为透明、可解释的数学方程。

Conclusion: KAN-based方法成功解决了负荷建模中精度与可解释性的平衡问题，为电力系统仿真分析提供了更优的解决方案。

Abstract: With increasing penetration of distributed energy resources installed behind
the meter, there is a growing need for adequate modelling of composite loads to
enable accurate power system simulation analysis. Existing measurement based
load modeling methods either fit fixed-structure physical models, which limits
adaptability to evolving load mixes, or employ flexible machine learning
methods which are however black boxes and offer limited interpretability. This
paper presents a new learning based load modelling method based on Kolmogorov
Arnold Networks towards modelling flexibility and interpretability. By actively
learning activation functions on edges, KANs automatically derive free form
symbolic equations that capture nonlinear relationships among measured
variables without prior assumptions about load structure. Case studies
demonstrate that the proposed approach outperforms other methods in both
accuracy and generalization ability, while uniquely representing composite
loads into transparent, interpretable mathematical equations.

</details>


### [240] [Low-Cost Architecture and Efficient Pattern Synthesis for Polarimetric Phased Array Based on Polarization Coding Reconfigurable Elements](https://arxiv.org/abs/2508.19644)
*Yiqing Wang,Jian Zhou,Chen Pang,Wenyang Man,Zixiang Xiong,Ke Meng,Zhanling Wang,Yongzhen Li*

Main category: eess.SY

TL;DR: 提出极化编码可重构相控阵(PCRPA)技术，通过单收发通道和射频开关实现极化控制，降低传统双极化相控阵的成本和复杂度，同时保持良好的旁瓣抑制和极化性能。


<details>
  <summary>Details</summary>
Motivation: 传统极化相控阵需要双收发通道，导致高成本和系统复杂。需要一种既能降低成本又能保持性能的替代方案。

Method: 采用单收发通道连接每个阵元，集成两级RF开关实时控制极化状态和波形。通过调整单元编码和激励权重，生成任意极化和双极化波束。提出基于理论分析的新型优化约束条件进行波束方向图合成。

Result: 仿真显示该方法在扫描范围内实现低交叉极化和与传统架构相当的旁瓣水平，特别适用于大型阵列。8×8 X波段阵列天线实验验证了系统有效性。

Conclusion: PCRPA技术适合大规模极化相控阵系统，在保持良好旁瓣抑制和极化控制性能的同时，具有显著的成本效益，但会不可避免地带来功率和方向性损失。

Abstract: Polarimetric phased arrays (PPAs) enhance radar target detection and
anti-jamming capabilities. However, the dual transmit/receive (T/R) channel
requirement leads to high costs and system complexity. To address this, this
paper introduces a polarization-coding reconfigurable phased array (PCRPA) and
associated pattern synthesis techniques to reduce PPA costs while minimizing
performance degradation. Each PCRPA element connects to a single T/R channel
and incorporates two-level RF switches for real-time control of polarization
states and waveforms. By adjusting element codes and excitation weights, the
PCRPA can generate arbitrarily polarized and dual-polarized beams. Efficient
beam pattern synthesis methods are also proposed, featuring novel optimization
constraints derived from theoretical and analytical analysis of PCRPAs.
Simulations demonstrate that the approach achieves low cross-polarization and
sidelobe levels comparable to conventional architectures within the scan range,
particularly for large arrays. However, the channel reduction inevitably incurs
power and directivity loss. Experiments conducted on an $8\times 8$ X-band
array antenna validate the effectiveness of the proposed system. The PCRPA and
synthesis methods are well-suited for large-scale PPA systems, offering
significant cost-effectiveness while maintaining good sidelobe suppression and
polarization control performance.

</details>


### [241] [Distributed Safety-Critical MPC for Multi-Agent Formation Control and Obstacle Avoidance](https://arxiv.org/abs/2508.19678)
*Chao Wang,Shuyuan Zhang,Lei Wang*

Main category: eess.SY

TL;DR: 提出了一种分布式安全关键模型预测控制算法，结合高阶控制屏障函数和控制Lyapunov函数，解决高相对度非线性多智能体系统的编队控制和避障问题


<details>
  <summary>Details</summary>
Motivation: 针对高相对度非线性多智能体系统，分布式实现编队控制和障碍物避免仍然是一个重大挑战

Method: 开发了分布式安全关键模型预测控制算法，整合离散时间高阶控制屏障函数确保安全约束，离散时间控制Lyapunov函数建立终端约束，使用估计邻居状态并设计边界约束限制估计误差

Result: 仿真结果表明该方法相比现有方法具有更好的性能和更短的计算时间

Conclusion: 提出的DSMPC算法为高相对度非线性多智能体系统提供了有效的分布式安全控制解决方案，具有理论保证和实际应用价值

Abstract: For nonlinear multi-agent systems with high relative degrees, achieving
formation control and obstacle avoidance in a distributed manner remains a
significant challenge. To address this issue, we propose a novel distributed
safety-critical model predictive control (DSMPC) algorithm that incorporates
discrete-time high-order control barrier functions (DHCBFs) to enforce safety
constraints, alongside discrete-time control Lyapunov functions (DCLFs) to
establish terminal constraints. To facilitate distributed implementation, we
develop estimated neighbor states for formulating DHCBFs and DCLFs, while also
devising a bound constraint to limit estimation errors and ensure convergence.
Additionally, we provide theoretical guarantees regarding the feasibility and
stability of the proposed DSMPC algorithm based on a mild assumption. The
effectiveness of the proposed method is evidenced by the simulation results,
demonstrating improved performance and reduced computation time compared to
existing approaches.

</details>


### [242] [Uncertainty-Based Perturb and Observe for Fast Optimization of Unknown, Time-Varying Processes](https://arxiv.org/abs/2508.19756)
*Leontine Aarnoudse,Mark Haring,Nathan van de Wouw,Alexey Pavlov*

Main category: eess.SY

TL;DR: 基于不确定性模型的变频P&O方法，减少干扰使用的同时保持对时变最优解的追踪性能


<details>
  <summary>Details</summary>
Motivation: 解决无模型自适应优化方法实际应用中干扰信号过多的问题，在保持追踪性能的同时减少干扰次数

Method: 在线构建时变成本模型，考虑测量不确定性和旧数据可靠性，只在预计能提升性能时才使用干扰

Result: 提供了收敛条件，证明策略能收敛到最优解附近；模拟结果显示可显著减少干扰次数同时保持准确追踪

Conclusion: 不确定性基于P&O方法能够在减少干扰使用的前提下，供给一种高效追踪时变最优解的解决方案

Abstract: Model-free adaptive optimization methods are capable of optimizing unknown,
time-varying processes even when other optimization methods are not. However,
their practical application is often limited by perturbations that are used to
gather information on the unknown cost and its gradient. The aim of this paper
is to develop a perturb-and-observe (P&O) method that reduces the need for such
perturbations while still achieving fast and accurate tracking of time-varying
optima. To this end, a (time-varying) model of the cost is constructed in an
online fashion, taking into account the uncertainty on the measured performance
cost as well as the decreasing reliability of older measurements. Perturbations
are only used when this is expected to lead to improved performance over a
certain time horizon. Convergence conditions are provided under which the
strategy converges to a neighborhood of the optimum. Finally, simulation
results demonstrate that uncertainty-based P\&O can reduce the number of
perturbations significantly while still tracking a time-varying optimum
accurately.

</details>


### [243] [Limited Preemption of the 3-Phase Task Model using Preemption Thresholds](https://arxiv.org/abs/2508.19760)
*Thilanka Thilakasiri,Matthias Becker*

Main category: eess.SY

TL;DR: 该论文提出使用抢占阈值来限制抢占次数，在保持可调度性的同时最小化本地内存使用。通过分区固定优先级调度和抢占阈值，为偶发三阶段任务提供最坏情况响应时间和内存需求分析。


<details>
  <summary>Details</summary>
Motivation: 解决复杂商用多核平台上执行的不确定性。非抢占执行阶段虽然能很好利用本地内存，但可调度性降低；完全抢占执行阶段可调度性更好，但需要更大的本地内存来同时保存所有被抢占任务。需要一种介于两者之间的有限抢占方法。

Method: 使用抢占阈值来限制抢占次数，提出最坏情况响应时间和最坏情况内存需求分析，适用于分区固定优先级调度下的偶发三阶段任务模型，并应用最先进的抢占阈值分配算法。

Result: 评估表明，与完全抢占调度相比，抢占阈值能显著减少内存使用（减少2.5倍），同时与非抢占调度相比保持高可调度性比率（提高13倍）。

Conclusion: 抢占阈值是一种有效的折中方案，能够在保持良好可调度性的同时显著降低内存需求，为复杂多核平台上的任务调度提供了实用的解决方案。

Abstract: Phased execution models are a well-known solution to tackle the
unpredictability of today's complex COTS multi-core platforms. The semantics of
these models dedicate phases for a task's execution and shared memory accesses.
Memory phases are solely dedicated to load all necessary instructions and data
to private local memory, and to write back the results of the computation.
During execution phases, only the private local memory is accessed. While
non-preemptive execution phases utilize the local memory well, schedulability
is reduced due to blocking. On the other hand, fully preemptive execution
phases allow for better schedulability, but require local memory to be large
enough to hold all tasks involved in preemption simultaneously. Limited
preemption is a promising approach that provides moderation between
non-preemptive and fully preemptive scheduling.
  In this paper, we propose using preemption thresholds to limit the number of
preemptions to minimize local memory usage while maintaining schedulability. We
propose a worst-case response time and a worst-case memory requirement analysis
for sporadic 3-phase tasks under partitioned fixed-priority scheduling with
preemption thresholds. We further show how the state-of-the-art algorithm to
assign preemption thresholds can be applied to the considered task model.
Evaluations demonstrate that preemption thresholds can significantly reduce the
memory usage (by $2.5\times$) compared to fully preemptive scheduling, while
maintaining high schedulability ratios ($13\times$) compared to non-preemptive
scheduling.

</details>


### [244] [Combined Stochastic and Robust Optimization for Electric Autonomous Mobility-on-Demand with Nested Benders Decomposition](https://arxiv.org/abs/2508.19933)
*Sten Elling Tingstad Jacobsen,Balázs Kulcsár,Anders Lindman*

Main category: eess.SY

TL;DR: 这篇论文提出了一种结合随机性和突出性的模型预测控制框架，用于管理电动自主移动服务，通过预测和优化协调调度、再平衡和充电决策，在实际游戏中显著提升了服务质量和降低了成本。


<details>
  <summary>Details</summary>
Motivation: 电动化和自动化改变了城市移动系统，管理电动自主移动服务需要在多重不确定性下协调调度、再平衡和充电决策，包括旅行需求、旅行时间、能消耗和充电程可用性等。

Method: 提出结合随机性和突出性的模型预测控制框架，集成空间时间贝叶斯神经网络预测与多阶段随机优化模型，形成大规模混合整数线性规划问题，并使用专门的嵌套贝尔斯分解算法实现并行化求解。

Result: 在旧金山和芬加哥的高保真模拟中，该方法与确定性、反应式和突出性基准相比，中位乘客等待时间减少36%，95%分位数延迟减少20%，再平衡距离减少27%，电力成本降低35%以上。

Conclusion: 结果强调了联合优化预测控制、车辆能力和基础设施规划的重要性，以实现可扩展、成本效益的电动自主移动服务运营。

Abstract: The electrification and automation of mobility are reshaping how cities
operate on-demand transport systems. Managing Electric Autonomous
Mobility-on-Demand (EAMoD) fleets effectively requires coordinating dispatch,
rebalancing, and charging decisions under multiple uncertainties, including
travel demand, travel time, energy consumption, and charger availability. We
address this challenge with a combined stochastic and robust model predictive
control (MPC) framework. The framework integrates spatio-temporal Bayesian
neural network forecasts with a multi-stage stochastic optimization model,
formulated as a large-scale mixed-integer linear program. To ensure real-time
applicability, we develop a tailored Nested Benders Decomposition that exploits
the scenario tree structure and enables efficient parallelized solution.
Stochastic optimization is employed to anticipate demand and infrastructure
variability, while robust constraints on energy consumption and travel times
safeguard feasibility under worst-case realizations. We evaluate the framework
using high-fidelity simulations of San Francisco and Chicago. Compared with
deterministic, reactive, and robust baselines, the combined stochastic and
robust approach reduces median passenger waiting times by up to 36% and
95th-percentile delays by nearly 20%, while also lowering rebalancing distance
by 27% and electricity costs by more than 35%. We also conduct a sensitivity
analysis of battery size and vehicle efficiency, finding that energy-efficient
vehicles maintain stable performance even with small batteries, whereas less
efficient vehicles require larger batteries and greater infrastructure support.
Our results emphasize the importance of jointly optimizing predictive control,
vehicle capabilities, and infrastructure planning to enable scalable,
cost-efficient EAMoD operations.

</details>


### [245] [Large Language Models (LLMs) for Electronic Design Automation (EDA)](https://arxiv.org/abs/2508.20030)
*Kangwei Xu,Denis Schwachhofer,Jason Blocklove,Ilia Polian,Peter Domanski,Dirk Pflüger,Siddharth Garg,Ramesh Karri,Ozgur Sinanoglu,Johann Knechtel,Zhuorui Zhao,Ulf Schlichtmann,Bing Li*

Main category: eess.SY

TL;DR: 本文综述了将大语言模型(LLMs)集成到电子设计自动化(EDA)中的潜力，通过三个案例研究展示了LLMs在硬件设计、测试和优化方面的能力，并讨论了未来发展方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着现代集成电路复杂度的增加，硬件工程师在设计到制造的整个流程中需要投入更多精力，这个过程既费时又容易出错，因此迫切需要更高效的EDA解决方案来加速硬件开发。

Method: 通过全面综述的方式，分析LLMs在EDA中的应用潜力，重点介绍三个案例研究来展示LLMs在硬件设计、测试和优化方面的具体能力。

Result: 研究表明LLMs在硬件设计的文本表示处理方面具有显著优势，能够简化甚至自动化整个EDA工作流程，展示了在硬件设计、测试和优化方面的实际应用潜力。

Conclusion: LLMs为下一代EDA工具的发展提供了重要机遇，但仍需进一步探索其潜力和解决相关挑战，为研究人员利用先进AI技术改进EDA提供了有价值的见解。

Abstract: With the growing complexity of modern integrated circuits, hardware engineers
are required to devote more effort to the full design-to-manufacturing
workflow. This workflow involves numerous iterations, making it both
labor-intensive and error-prone. Therefore, there is an urgent demand for more
efficient Electronic Design Automation (EDA) solutions to accelerate hardware
development. Recently, large language models (LLMs) have shown remarkable
advancements in contextual comprehension, logical reasoning, and generative
capabilities. Since hardware designs and intermediate scripts can be
represented as text, integrating LLM for EDA offers a promising opportunity to
simplify and even automate the entire workflow. Accordingly, this paper
provides a comprehensive overview of incorporating LLMs into EDA, with emphasis
on their capabilities, limitations, and future opportunities. Three case
studies, along with their outlook, are introduced to demonstrate the
capabilities of LLMs in hardware design, testing, and optimization. Finally,
future directions and challenges are highlighted to further explore the
potential of LLMs in shaping the next-generation EDA, providing valuable
insights for researchers interested in leveraging advanced AI technologies for
EDA.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [246] [Aggregate Fictitious Play for Learning in Anonymous Polymatrix Games (Extended Version)](https://arxiv.org/abs/2508.19371)
*Semih Kara,Tamer Başar*

Main category: cs.GT

TL;DR: 提出了聚合虚拟博弈(agg-FP)算法，通过聚合智能体动作来减少动作空间，在匿名多矩阵游戏中保持纳什均衡收敛性并加速收敛速度


<details>
  <summary>Details</summary>
Motivation: 传统虚拟博弈(FP)在智能体对奖励函数无先验知识时面临联合动作空间指数增长的挑战，匿名游戏结构可以缓解这个问题

Method: 开发了聚合虚拟博弈变体，每个智能体跟踪其他智能体选择每个动作的数量频率而非个体动作，从而减少动作空间

Result: 在匿名多矩阵游戏中，agg-FP在相同条件下与传统FP一样收敛到纳什均衡，并通过模拟验证了收敛加速效果

Conclusion: 通过动作聚合可以在不损失收敛保证的前提下显著减少动作空间，为大规模多智能体学习提供了有效解决方案

Abstract: Fictitious play (FP) is a well-studied algorithm that enables agents to learn
Nash equilibrium in games with certain reward structures. However, when agents
have no prior knowledge of the reward functions, FP faces a major challenge:
the joint action space grows exponentially with the number of agents, which
slows down reward exploration. Anonymous games offer a structure that mitigates
this issue. In these games, the rewards depend only on the actions taken; not
on who is taking which action. Under such a structure, we introduce aggregate
fictitious play (agg-FP), a variant of FP where each agent tracks the frequency
of the number of other agents playing each action, rather than these agents'
individual actions. We show that in anonymous polymatrix games, agg-FP
converges to a Nash equilibrium under the same conditions as classical FP. In
essence, by aggregating the agents' actions, we reduce the action space without
losing the convergence guarantees. Using simulations, we provide empirical
evidence on how this reduction accelerates convergence.

</details>
