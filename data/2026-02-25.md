<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Global Prior Meets Local Consistency: Dual-Memory Augmented Vision-Language-Action Model for Efficient Robotic Manipulation](https://arxiv.org/abs/2602.20200)
*Zaijing Li,Bing Hu,Rui Shao,Gongwei Chen,Dongmei Jiang,Pengwei Xie,Jianye Hao,Liqiang Nie*

Main category: cs.RO

TL;DR: OptimusVLA是一个具有全局先验记忆和局部一致性记忆的双记忆VLA框架，通过任务级先验替代高斯噪声减少推理步骤，并通过历史动作序列建模增强时间一致性，在多个机器人操作基准上显著提升性能和推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前分层视觉-语言-动作（VLA）模型在机器人操作中存在两个主要瓶颈：1）推理效率低，各向同性噪声先验与目标动作分布之间存在显著分布差距，导致去噪步骤增多和不可行样本增加；2）鲁棒性差，现有策略仅基于当前观测，忽略了历史序列约束，缺乏任务进度意识和时间一致性。

Method: 提出OptimusVLA双记忆VLA框架，包含全局先验记忆（GPM）和局部一致性记忆（LCM）。GPM从语义相似轨迹中检索任务级先验替代高斯噪声，缩短生成路径并减少函数评估次数。LCM动态建模已执行的动作序列以推断任务进度，并注入学习到的一致性约束来增强轨迹的时间连贯性和平滑性。

Result: 在三个仿真基准测试中：LIBERO上达到98.6%平均成功率，CALVIN上比pi_0提升13.5%，RoboTwin 2.0 Hard上达到38%平均成功率。真实世界评估中，在泛化和长时程任务套件上表现最佳，分别超越pi_0 42.9%和52.4%，同时实现2.9倍推理加速。

Conclusion: OptimusVLA通过引入双记忆机制有效解决了VLA模型在动作生成过程中的效率和鲁棒性问题，在仿真和真实世界机器人操作任务中均展现出优越性能，为分层VLA模型的发展提供了新方向。

Abstract: Hierarchical Vision-Language-Action (VLA) models have rapidly become a dominant paradigm for robotic manipulation. It typically comprising a Vision-Language backbone for perception and understanding, together with a generative policy for action generation. However, its performance is increasingly bottlenecked by the action generation proceess. (i) Low inference efficiency. A pronounced distributional gap between isotropic noise priors and target action distributions, which increases denoising steps and the incidence of infeasible samples. (ii) Poor robustness. Existing policies condition solely on the current observation, neglecting the constraint of history sequence and thus lacking awareness of task progress and temporal consistency. To address these issues, we introduce OptimusVLA, a dual-memory VLA framework with Global Prior Memory (GPM) and Local Consistency Memory (LCM). GPM replaces Gaussian noise with task-level priors retrieved from semantically similar trajectories, thereby shortening the generative path and reducing the umber of function evaluations (NFE). LCM dynamically models executed action sequence to infer task progress and injects a learned consistency constraint that enforces temporal coherence and smoothness of trajectory. Across three simulation benchmarks, OptimusVLA consistently outperforms strong baselines: it achieves 98.6% average success rate on LIBERO, improves over pi_0 by 13.5% on CALVIN, and attains 38% average success rate on RoboTwin 2.0 Hard. In Real-World evaluation, OptimusVLA ranks best on Generalization and Long-horizon suites, surpassing pi_0 by 42.9% and 52.4%, respectively, while delivering 2.9x inference speedup.

</details>


### [2] [Sample-Efficient Learning with Online Expert Correction for Autonomous Catheter Steering in Endovascular Bifurcation Navigation](https://arxiv.org/abs/2602.20216)
*Hao Wang,Tianliang Yao,Bo Lu,Zhiqiang Pei,Liu Dong,Lei Ma,Peng Qi*

Main category: cs.RO

TL;DR: 提出结合在线专家校正的样本高效强化学习框架，用于血管分叉导航中的自主导管操控，相比基线方法训练收敛更快且定位误差更小。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助血管内介入治疗能安全远程操控导管，减少辐射暴露。传统强化学习方法存在奖励稀疏、依赖静态血管模型的问题，样本效率低且难以适应术中变化。

Method: 提出包含三个关键组件的框架：(1)基于分割的姿态估计模块提供实时状态反馈；(2)模糊控制器进行分叉感知方向调整；(3)结合专家先验的结构化奖励生成器指导策略学习。通过在线专家校正减少探索低效性。

Result: 在透明血管模型机器人平台上验证，仅需123个训练周期即可收敛（比基线SAC算法减少25.9%），平均位置误差降至基线的83.8%。

Conclusion: 样本高效强化学习结合在线专家校正能实现可靠准确的导管操控，特别是在血管分叉等解剖结构复杂的场景中，这对血管内导航至关重要。

Abstract: Robot-assisted endovascular intervention offers a safe and effective solution for remote catheter manipulation, reducing radiation exposure while enabling precise navigation. Reinforcement learning (RL) has recently emerged as a promising approach for autonomous catheter steering; however, conventional methods suffer from sparse reward design and reliance on static vascular models, limiting their sample efficiency and generalization to intraoperative variations. To overcome these challenges, this paper introduces a sample-efficient RL framework with online expert correction for autonomous catheter steering in endovascular bifurcation navigation. The proposed framework integrates three key components: (1) A segmentation-based pose estimation module for accurate real-time state feedback, (2) A fuzzy controller for bifurcation-aware orientation adjustment, and (3) A structured reward generator incorporating expert priors to guide policy learning. By leveraging online expert correction, the framework reduces exploration inefficiency and enhances policy robustness in complex vascular structures. Experimental validation on a robotic platform using a transparent vascular phantom demonstrates that the proposed approach achieves convergence in 123 training episodes -- a 25.9% reduction compared to the baseline Soft Actor-Critic (SAC) algorithm -- while reducing average positional error to 83.8% of the baseline. These results indicate that combining sample-efficient RL with online expert correction enables reliable and accurate catheter steering, particularly in anatomically challenging bifurcation scenarios critical for endovascular navigation.

</details>


### [3] [An Approach to Combining Video and Speech with Large Language Models in Human-Robot Interaction](https://arxiv.org/abs/2602.20219)
*Guanting Shen,Zi Tian*

Main category: cs.RO

TL;DR: 提出一种结合视觉语言模型、语音处理和模糊逻辑的多模态人机交互框架，用于控制Dobot机械臂，通过语音命令实现物体操作，在消费级硬件上达到75%的命令执行准确率。


<details>
  <summary>Details</summary>
Motivation: 准确理解人类意图是人机交互的核心挑战，也是实现更自然、直观的人机协作的关键要求。当前需要更精确和自适应的机器人控制方法。

Method: 采用多模态HRI框架，结合Florence-2进行物体检测、Llama 3.1进行自然语言理解、Whisper进行语音识别，并集成模糊逻辑实现精确的自适应控制。

Result: 在消费级硬件上的实验评估显示，系统实现了75%的命令执行准确率，证明了系统的鲁棒性和适应性。

Conclusion: 该架构为未来HRI研究提供了灵活可扩展的基础，通过紧密耦合的语音和视觉语言处理，为实现更复杂自然的人机协作提供了实用路径。

Abstract: Interpreting human intent accurately is a central challenge in human-robot interaction (HRI) and a key requirement for achieving more natural and intuitive collaboration between humans and machines. This work presents a novel multimodal HRI framework that combines advanced vision-language models, speech processing, and fuzzy logic to enable precise and adaptive control of a Dobot Magician robotic arm. The proposed system integrates Florence-2 for object detection, Llama 3.1 for natural language understanding, and Whisper for speech recognition, providing users with a seamless and intuitive interface for object manipulation through spoken commands. By jointly addressing scene perception and action planning, the approach enhances the reliability of command interpretation and execution. Experimental evaluations conducted on consumer-grade hardware demonstrate a command execution accuracy of 75\%, highlighting both the robustness and adaptability of the system. Beyond its current performance, the proposed architecture serves as a flexible and extensible foundation for future HRI research, offering a practical pathway toward more sophisticated and natural human-robot collaboration through tightly coupled speech and vision-language processing.

</details>


### [4] [What Matters for Simulation to Online Reinforcement Learning on Real Robots](https://arxiv.org/abs/2602.20220)
*Yarden As,Dhruva Tirumala,René Zurbrügg,Chenhao Li,Stelian Coros,Andreas Krause,Markus Wulfmeier*

Main category: cs.RO

TL;DR: 本文通过100次真实机器人实验，系统研究了在线强化学习在物理机器人上的关键设计选择，发现一些常用默认设置有害，而一组稳健的设计选择能实现稳定学习


<details>
  <summary>Details</summary>
Motivation: 研究在线强化学习在物理机器人上成功应用的具体设计选择，填补了先前工作中通常隐含的设计决策缺乏系统性实证研究的空白

Method: 在三种不同的机器人平台上进行100次真实世界训练，系统性地消融分析算法、系统和实验决策，这些决策在先前工作中通常被隐含处理

Result: 发现一些广泛使用的默认设置可能有害，而一组在标准强化学习实践中稳健且易于采用的设计选择能在不同任务和硬件上实现稳定学习

Conclusion: 这是首次对此类设计选择进行大规模实证研究，使从业者能够以更低的工程努力部署在线强化学习

Abstract: We investigate what specific design choices enable successful online reinforcement learning (RL) on physical robots. Across 100 real-world training runs on three distinct robotic platforms, we systematically ablate algorithmic, systems, and experimental decisions that are typically left implicit in prior work. We find that some widely used defaults can be harmful, while a set of robust, readily adopted design choices within standard RL practice yield stable learning across tasks and hardware. These results provide the first large-sample empirical study of such design choices, enabling practitioners to deploy online RL with lower engineering effort.

</details>


### [5] [FACTO: Function-space Adaptive Constrained Trajectory Optimization for Robotic Manipulators](https://arxiv.org/abs/2602.20225)
*Yichang Feng,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: FACTO是一种用于单臂和多臂机械臂轨迹优化的新算法，通过在系数空间直接优化，使用正交基函数参数化轨迹，采用自适应约束更新策略，在约束场景下相比现有方法有更好的解质量和可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的轨迹优化方法在单臂和多臂机械臂的约束场景中，解的质量和可行性有待提升，特别是在处理非线性约束和轨迹范围约束方面存在挑战。

Method: FACTO使用正交基函数线性组合参数化轨迹，在系数空间直接优化；采用高斯-牛顿近似和指数移动平均处理非线性；使用系数空间映射处理轨迹范围约束；在活动约束的零空间中使用Levenberg-Marquardt算法进行自适应约束更新。

Result: 与优化型规划器（CHOMP、TrajOpt、GPMP2）和采样型规划器（RRT-Connect、RRT*、PRM）相比，FACTO在约束单臂和多臂场景中表现出更好的解质量和可行性；在Franka机器人上的实验验证了部署的可行性。

Conclusion: FACTO是一种有效的轨迹优化算法，特别适用于约束单臂和多臂机械臂场景，能够产生高质量且可行的轨迹，具有实际部署的潜力。

Abstract: This paper introduces Function-space Adaptive Constrained Trajectory Optimization (FACTO), a new trajectory optimization algorithm for both single- and multi-arm manipulators. Trajectory representations are parameterized as linear combinations of orthogonal basis functions, and optimization is performed directly in the coefficient space. The constrained problem formulation consists of both an objective functional and a finite-dimensional objective defined over truncated coefficients. To address nonlinearity, FACTO uses a Gauss-Newton approximation with exponential moving averaging, yielding a smoothed quadratic subproblem. Trajectory-wide constraints are addressed using coefficient-space mappings, and an adaptive constrained update using the Levenberg-Marquardt algorithm is performed in the null space of active constraints. Comparisons with optimization-based planners (CHOMP, TrajOpt, GPMP2) and sampling-based planners (RRT-Connect, RRT*, PRM) show the improved solution quality and feasibility, especially in constrained single- and multi-arm scenarios. The experimental evaluation of FACTO on Franka robots verifies the feasibility of deployment.

</details>


### [6] [UniLACT: Depth-Aware RGB Latent Action Learning for Vision-Language-Action Models](https://arxiv.org/abs/2602.20231)
*Manish Kumar Govind,Dominick Reilly,Pu Wang,Srijan Das*

Main category: cs.RO

TL;DR: UniLACT模型通过深度感知的潜在动作表示预训练，解决了仅基于RGB的潜在动作缺乏3D几何结构的问题，在机器人操作任务中表现优于RGB基线。


<details>
  <summary>Details</summary>
Motivation: 从无标签视频学习的潜在动作表示缺乏明确的3D几何结构，这对于精确和接触丰富的机器人操作至关重要。仅基于RGB观察的潜在动作主要编码外观驱动的动态，限制了在复杂操作任务中的表现。

Method: 提出了UniLACT模型，通过深度感知的潜在预训练结合几何结构。同时开发了UniLARN框架，基于逆动力学和前向动力学目标学习RGB和深度的共享嵌入空间，并显式建模跨模态交互，生成模态特定和统一的潜在动作表示作为伪标签。

Result: 在仿真和真实世界环境中的广泛实验表明，深度感知的统一潜在动作表示有效。UniLACT在域内和域外预训练机制下，以及在已见和未见操作任务中，始终优于基于RGB的潜在动作基线。

Conclusion: 通过深度感知的潜在动作表示预训练，可以显著提升视觉-语言-动作模型在机器人操作任务中的性能，特别是对于需要精确空间感知的接触丰富操作。

Abstract: Latent action representations learned from unlabeled videos have recently emerged as a promising paradigm for pretraining vision-language-action (VLA) models without explicit robot action supervision. However, latent actions derived solely from RGB observations primarily encode appearance-driven dynamics and lack explicit 3D geometric structure, which is essential for precise and contact-rich manipulation. To address this limitation, we introduce UniLACT, a transformer-based VLA model that incorporates geometric structure through depth-aware latent pretraining, enabling downstream policies to inherit stronger spatial priors. To facilitate this process, we propose UniLARN, a unified latent action learning framework based on inverse and forward dynamics objectives that learns a shared embedding space for RGB and depth while explicitly modeling their cross-modal interactions. This formulation produces modality-specific and unified latent action representations that serve as pseudo-labels for the depth-aware pretraining of UniLACT. Extensive experiments in both simulation and real-world settings demonstrate the effectiveness of depth-aware unified latent action representations. UniLACT consistently outperforms RGB-based latent action baselines under in-domain and out-of-domain pretraining regimes, as well as on both seen and unseen manipulation tasks.

</details>


### [7] [Smoothly Differentiable and Efficiently Vectorizable Contact Manifold Generation](https://arxiv.org/abs/2602.20304)
*Onur Beker,Andreas René Geist,Anselm Paulus,Nico Gürtler,Ji Shi,Sylvain Calinon,Georg Martius*

Main category: cs.RO

TL;DR: 提出了一种用于刚体动力学接触模拟的新框架，旨在实现快速、可向量化和可微分，通过平滑解析有符号距离基元和创新的可微分边-边碰撞检测来解决现有方法的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有可微分模拟框架在接触流形生成方面存在瓶颈，传统机器人模拟器的相关程序在设计时未充分考虑向量化和可微分性，导致效率低下且不可微分。

Method: 提出了一种新框架，采用平滑解析有符号距离基元实现顶点-面碰撞检测，并开发了新颖的可微分边-边碰撞检测方法，能够提供有符号距离和接触法向量。

Result: 通过教学实验评估并与Mujoco XLA框架的碰撞检测进行基准测试，观察到显著的速度提升。

Conclusion: 该框架在机器人刚体动力学接触模拟中实现了快速、可向量化和可微分的特性，平衡了传统方法的效率与可微分性需求。

Abstract: Simulating rigid-body dynamics with contact in a fast, massively vectorizable, and smoothly differentiable manner is highly desirable in robotics. An important bottleneck faced by existing differentiable simulation frameworks is contact manifold generation: representing the volume of intersection between two colliding geometries via a discrete set of properly distributed contact points. A major factor contributing to this bottleneck is that the related routines of commonly used robotics simulators were not designed with vectorization and differentiability as a primary concern, and thus rely on logic and control flow that hinder these goals. We instead propose a framework designed from the ground up with these goals in mind, by trying to strike a middle ground between: i) convex primitive based approaches used by common robotics simulators (efficient but not differentiable), and ii) mollified vertex-face and edge-edge unsigned distance-based approaches used by barrier methods (differentiable but inefficient). Concretely, we propose: i) a representative set of smooth analytical signed distance primitives to implement vertex-face collisions, and ii) a novel differentiable edge-edge collision routine that can provide signed distances and signed contact normals. The proposed framework is evaluated via a set of didactic experiments and benchmarked against the collision detection routine of the well-established Mujoco XLA framework, where we observe a significant speedup. Supplementary videos can be found at https://github.com/bekeronur/contax, where a reference implementation in JAX will also be made available at the conclusion of the review process.

</details>


### [8] [Learning Physical Principles from Interaction: Self-Evolving Planning via Test-Time Memory](https://arxiv.org/abs/2602.20323)
*Haoyang Li,Yang You,Hao Su,Leonidas Guibas*

Main category: cs.RO

TL;DR: PhysMem框架让视觉语言模型机器人规划器通过交互学习物理原理，无需更新模型参数，通过验证假设而非直接应用经验来适应变化的物理条件。


<details>
  <summary>Details</summary>
Motivation: 可靠的物体操作需要理解随物体和环境变化的物理属性。虽然视觉语言模型规划器能在一般意义上推理摩擦和稳定性，但无法预测特定物体在特定表面的具体行为，需要直接经验。

Method: PhysMem是一个记忆框架，系统记录交互经验，生成候选假设，通过有针对性的交互验证假设，然后将验证后的知识提升为指导未来决策。核心设计是"验证优先于应用"原则。

Result: 在受控的砖块插入任务中，基于原则的抽象方法达到76%成功率，而直接经验检索只有23%。真实世界实验在30分钟部署会话中显示持续改进，在三个真实世界操作任务和四个VLM骨干的模拟基准测试中表现良好。

Conclusion: PhysMem框架使VLM机器人规划器能够在测试时通过交互学习物理原理，通过验证假设而非直接应用经验来适应变化的物理条件，显著提高了操作任务的性能。

Abstract: Reliable object manipulation requires understanding physical properties that vary across objects and environments. Vision-language model (VLM) planners can reason about friction and stability in general terms; however, they often cannot predict how a specific ball will roll on a particular surface or which stone will provide a stable foundation without direct experience. We present PhysMem, a memory framework that enables VLM robot planners to learn physical principles from interaction at test time, without updating model parameters. The system records experiences, generates candidate hypotheses, and verifies them through targeted interaction before promoting validated knowledge to guide future decisions. A central design choice is verification before application: the system tests hypotheses against new observations rather than applying retrieved experience directly, reducing rigid reliance on prior experience when physical conditions change. We evaluate PhysMem on three real-world manipulation tasks and simulation benchmarks across four VLM backbones. On a controlled brick insertion task, principled abstraction achieves 76% success compared to 23% for direct experience retrieval, and real-world experiments show consistent improvement over 30-minute deployment sessions.

</details>


### [9] [Energy-Based Injury Protection Database: Including Shearing Contact Thresholds for Hand and Finger Using Porcine Surrogates](https://arxiv.org/abs/2602.20362)
*Robin Jeanne Kirschner,Anna Huber,Carina M. Micheler,Dirk Müller,Nader Rajaei,Rainer Burgkart,Sami Haddadin*

Main category: cs.RO

TL;DR: 该研究扩展了机器人碰撞安全数据集，通过包含剪切接触场景，建立了首个基于能量的伤害保护数据库，为开发有效的能量限制控制器提供基础。


<details>
  <summary>Details</summary>
Motivation: 当前机器人碰撞安全研究主要依赖EN ISO 10218-2:2025的钝器冲击数据，但该数据集不涵盖边缘或尖锐碰撞。在受限环境和未来人形机器人系统中，接触不可避免，需要更全面的安全验证数据集。

Method: 研究扩展了先前数据集，包括无约束碰撞中的剪切接触场景，重新评估所有先前猪替代物数据，建立跨几何形状和接触类型的能量阈值。

Result: 发现碰撞角度显著影响伤害结果，无约束剪切接触比垂直碰撞造成更少伤害。建立了首个基于能量的伤害保护数据库。

Conclusion: 通过建立全面的能量阈值数据库，能够开发有意义的能量限制控制器，确保在各种现实碰撞事件中的安全性。

Abstract: While robotics research continues to propose strategies for collision avoidance in human-robot interaction, the reality of constrained environments and future humanoid systems makes contact inevitable. To mitigate injury risks, energy-constraining control approaches are commonly used, often relying on safety thresholds derived from blunt impact data in EN ISO 10218-2:2025. However, this dataset does not extend to edged or pointed collisions. Without scalable, clinically grounded datasets covering diverse contact scenarios, safety validation remains limited. Previous studies have laid the groundwork by assessing surrogate-based velocity and mass limits across various geometries, focusing on perpendicular impacts. This study expands those datasets by including shearing contact scenarios in unconstrained collisions, revealing that collision angle significantly affects injury outcomes. Notably, unconstrained shearing contacts result in fewer injuries than perpendicular ones. By reevaluating all prior porcine surrogate data, we establish energy thresholds across geometries and contact types, forming the first energy-based Injury Protection Database. This enables the development of meaningful energy-limiting controllers that ensure safety across a wide range of realistic collision events.

</details>


### [10] [Generalizing from References using a Multi-Task Reference and Goal-Driven RL Framework](https://arxiv.org/abs/2602.20375)
*Jiashun Wang,M. Eva Mungai,He Li,Jean Pierre Sleiman,Jessica Hodgins,Farbod Farshidian*

Main category: cs.RO

TL;DR: 提出统一的多任务强化学习框架，将参考运动作为行为塑造的先验而非部署约束，通过联合优化模仿任务和泛化任务，使策略既能学习人类运动技能又能适应新目标


<details>
  <summary>Details</summary>
Motivation: 现有方法存在权衡：基于参考跟踪的策略在演示数据集外往往脆弱，而纯任务驱动的强化学习虽能实现适应性但牺牲运动质量。需要弥合这一差距，使策略既自然又鲁棒

Method: 提出统一多任务RL框架，训练单一目标条件策略同时完成两个任务：(1)参考引导的模仿任务，参考轨迹定义密集模仿奖励但不作为策略输入；(2)目标条件泛化任务，目标独立于参考采样，奖励仅反映任务成功。通过共享观察和动作空间的联合优化，无需对抗目标、显式轨迹跟踪、相位变量或参考相关推理

Result: 在基于箱子的跑酷场景中评估，控制器能够超越参考分布进行泛化，同时保持运动自然性。展示了通过组合多个学习技能生成长时程行为，在复杂场景中体现策略灵活性

Conclusion: 该方法通过将参考运动作为行为先验而非约束，成功弥合了运动质量和适应性之间的差距，使策略既能从密集参考监督中获取结构化的人类运动技能，又能适应新目标和初始条件

Abstract: Learning agile humanoid behaviors from human motion offers a powerful route to natural, coordinated control, but existing approaches face a persistent trade-off: reference-tracking policies are often brittle outside the demonstration dataset, while purely task-driven Reinforcement Learning (RL) can achieve adaptability at the cost of motion quality. We introduce a unified multi-task RL framework that bridges this gap by treating reference motion as a prior for behavioral shaping rather than a deployment-time constraint. A single goal-conditioned policy is trained jointly on two tasks that share the same observation and action spaces, but differ in their initialization schemes, command spaces, and reward structures: (i) a reference-guided imitation task in which reference trajectories define dense imitation rewards but are not provided as policy inputs, and (ii) a goal-conditioned generalization task in which goals are sampled independently of any reference and where rewards reflect only task success. By co-optimizing these objectives within a shared formulation, the policy acquires structured, human-like motor skills from dense reference supervision while learning to adapt these skills to novel goals and initial conditions. This is achieved without adversarial objectives, explicit trajectory tracking, phase variables, or reference-dependent inference. We evaluate the method on a challenging box-based parkour playground that demands diverse athletic behaviors (e.g., jumping and climbing), and show that the learned controller transfers beyond the reference distribution while preserving motion naturalness. Finally, we demonstrate long-horizon behavior generation by composing multiple learned skills, illustrating the flexibility of the learned polices in complex scenarios.

</details>


### [11] [Grasp to Act: Dexterous Grasping for Tool Use in Dynamic Settings](https://arxiv.org/abs/2602.20466)
*Harsh Gupta,Mohammad Amin Mirzaee,Wenzhen Yuan*

Main category: cs.RO

TL;DR: 提出Grasp-to-Act混合系统，结合基于物理的抓取优化和强化学习抓取适应，在动态工具使用任务中实现零样本仿真到真实迁移的稳健抓取。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对静态几何稳定性优化抓取，但在涉及冲击、扭矩和持续阻力等动态力的真实工具使用场景中容易失效，需要能够适应动态接触条件的稳健抓取方法。

Method: 结合基于物理的抓取优化和基于强化学习的抓取适应，通过人类演示信息合成稳健抓取配置，并使用自适应控制器残差地发出关节修正以防止手内滑动，同时跟踪物体轨迹。

Result: 在五个动态工具使用任务（锤击、锯切、切割、搅拌、舀取）中实现零样本仿真到真实迁移，在16自由度灵巧手的仿真和真实硬件试验中，减少平移和旋转手内滑动，获得最高任务完成率。

Conclusion: Grasp-to-Act方法在动态、接触丰富的条件下实现了稳定的功能性抓取，显著优于基线方法，为解决真实世界工具使用中的动态抓取问题提供了有效解决方案。

Abstract: Achieving robust grasping with dexterous hands remains challenging, especially when manipulation involves dynamic forces such as impacts, torques, and continuous resistance--situations common in real-world tool use. Existing methods largely optimize grasps for static geometric stability and often fail once external forces arise during manipulation. We present Grasp-to-Act, a hybrid system that combines physics-based grasp optimization with reinforcement-learning-based grasp adaptation to maintain stable grasps throughout functional manipulation tasks. Our method synthesizes robust grasp configurations informed by human demonstrations and employs an adaptive controller that residually issues joint corrections to prevent in-hand slip while tracking the object trajectory. Grasp-to-Act enables robust zero-shot sim-to-real transfer across five dynamic tool-use tasks--hammering, sawing, cutting, stirring, and scooping--consistently outperforming baselines. Across simulation and real-world hardware trials with a 16-DoF dexterous hand, our method reduces translational and rotational in-hand slip and achieves the highest task completion rates, demonstrating stable functional grasps under dynamic, contact-rich conditions.

</details>


### [12] [Strategy-Supervised Autonomous Laparoscopic Camera Control via Event-Driven Graph Mining](https://arxiv.org/abs/2602.20500)
*Keyu Zhou,Peisen Xu,Yahao Wu,Jiming Chen,Gaofeng Li,Shunlei Li*

Main category: cs.RO

TL;DR: 提出基于策略的自主腹腔镜相机控制框架，结合高层视觉语言推理与低层闭环控制，通过事件图挖掘可重用策略原语，在离体实验中显著优于初级外科医生。


<details>
  <summary>Details</summary>
Motivation: 自主腹腔镜相机控制需要在快速工具-组织交互下保持稳定安全的手术视野，同时保持对外科医生的可解释性。现有方法难以同时满足稳定性、安全性和可解释性要求。

Method: 提出策略基础框架：离线阶段将原始手术视频解析为相机相关时间事件（交互、工作距离偏差、视野质量下降），构建属性事件图，挖掘可重用相机操作策略原语；在线阶段使用微调视觉语言模型处理实时腹腔镜视野，预测主导策略和离散图像运动指令，由IBVS-RCM控制器在严格安全约束下执行，可选语音输入支持人机交互。

Result: 事件解析实现可靠时间定位（F1分数0.86），挖掘策略与专家解释语义对齐强（聚类纯度0.81）。在硅胶模型和猪组织离体实验中，系统在标准化相机操作评估中优于初级外科医生，视野中心误差减少35.26%，图像抖动减少62.33%，同时保持平滑运动和稳定工作距离调节。

Conclusion: 提出的策略基础框架成功实现了稳定、安全且可解释的自主腹腔镜相机控制，通过结合高层语义推理和低层闭环控制，显著提升了相机操作性能，为手术机器人自主化提供了有效解决方案。

Abstract: Autonomous laparoscopic camera control must maintain a stable and safe surgical view under rapid tool-tissue interactions while remaining interpretable to surgeons. We present a strategy-grounded framework that couples high-level vision-language inference with low-level closed-loop control. Offline, raw surgical videos are parsed into camera-relevant temporal events (e.g., interaction, working-distance deviation, and view-quality degradation) and structured as attributed event graphs. Mining these graphs yields a compact set of reusable camera-handling strategy primitives, which provide structured supervision for learning. Online, a fine-tuned Vision-Language Model (VLM) processes the live laparoscopic view to predict the dominant strategy and discrete image-based motion commands, executed by an IBVS-RCM controller under strict safety constraints; optional speech input enables intuitive human-in-the-loop conditioning. On a surgeon-annotated dataset, event parsing achieves reliable temporal localization (F1-score 0.86), and the mined strategies show strong semantic alignment with expert interpretation (cluster purity 0.81). Extensive ex vivo experiments on silicone phantoms and porcine tissues demonstrate that the proposed system outperforms junior surgeons in standardized camera-handling evaluations, reducing field-of-view centering error by 35.26% and image shaking by 62.33%, while preserving smooth motion and stable working-distance regulation.

</details>


### [13] [BFA++: Hierarchical Best-Feature-Aware Token Prune for Multi-View Vision Language Action Model](https://arxiv.org/abs/2602.20566)
*Haosheng Li,Weixin Mao,Zihan Lan,Hongwei Xiong,Hongan Wang,Chenyang Si,Ziwei Liu,Xiaoming Deng,Hua Chen*

Main category: cs.RO

TL;DR: BFA++是一个专为VLA模型设计的动态token剪枝框架，通过分层剪枝策略提高计算效率，在保持操作成功率的同时实现1.5-1.8倍加速。


<details>
  <summary>Details</summary>
Motivation: VLA模型在多视角输入时产生大量视觉token，对实时机器人操作构成挑战。现有token剪枝技术直接应用于VLA模型会导致性能下降，因为它们忽略了不同视角间的关系以及机器人操作的动态和任务特定特性。

Method: 提出BFA++动态token剪枝框架，采用分层剪枝策略，包含两个层次的重要性预测器：视图内预测器突出每张图像中任务相关区域以抑制空间噪声，视图间预测器识别不同操作阶段的关键相机视角以减少跨视角冗余。

Result: 在RoboTwin基准测试和真实世界机器人任务中，BFA++始终优于现有方法。在π0和RDT模型上，成功率提高约10%，分别实现1.8倍和1.5倍加速。

Conclusion: 上下文敏感和任务感知的token剪枝比完整视觉处理更有效，能够在真实世界机器人系统中实现更快的推理和更高的操作准确性。

Abstract: Vision-Language-Action (VLA) models have achieved significant breakthroughs by leveraging Large Vision Language Models (VLMs) to jointly interpret instructions and visual inputs. However, the substantial increase in visual tokens, particularly from multi-view inputs, poses serious challenges to real-time robotic manipulation. Existing acceleration techniques for VLMs, such as token pruning, often result in degraded performance when directly applied to VLA models, as they overlook the relationships between different views and fail to account for the dynamic and task-specific characteristics of robotic operation. To address this, we propose BFA++, a dynamic token pruning framework designed specifically for VLA models. BFA++ introduces a hierarchical pruning strategy guided by two-level importance predictors: an intra-view predictor highlights task-relevant regions within each image to suppress spatial noise, while an inter-view predictor identifies critical camera views throughout different manipulation phases to reduce cross-view redundancy. This design enables efficient token selection while preserving essential visual cues, resulting in improved computational efficiency and higher manipulation success rates. Evaluations on the RoboTwin benchmark and real-world robotic tasks demonstrate that BFA++ consistently outperforms existing methods. BFA++ improves the success rate by about 10% on both the π0 and RDT models, achieving speedup of 1.8X and 1.5X, respectively. Our results highlight that context-sensitive and task-aware token pruning serves as a more effective strategy than full visual processing, enabling faster inference and improved manipulation accuracy in real-world robotic systems.

</details>


### [14] [Acoustic Feedback for Closed-Loop Force Control in Robotic Grinding](https://arxiv.org/abs/2602.20596)
*Zongyuan Zhang,Christopher Lehnert,Will N. Browne,Jonathan M. Roberts*

Main category: cs.RO

TL;DR: 本文提出了一种低成本声学反馈机器人磨削系统（AFRG），使用接触式麦克风替代昂贵的力传感器，通过音频信号实时估计磨削力并实现闭环控制。


<details>
  <summary>Details</summary>
Motivation: 人类进行磨削任务时依赖声学反馈判断工具与工件的接触状态，而现有机器人磨削系统主要依赖昂贵的力传感器，难以适应不同磨削工具。音频传感器成本低且易于安装，但相关声学信息在机器人磨削中被忽视。

Method: AFRG系统使用接触式麦克风采集音频信号，从音频中实时估计磨削力，并实现磨削过程的闭环力控制。系统仅依赖低成本麦克风作为传感模态，无需传统力传感器。

Result: 与传统力传感方法相比，AFRG在不同磨削盘条件下的一致性提高了4倍。系统使用的麦克风成本约为传统力传感器的1/200，提供了经济高效的机器人磨削解决方案。

Conclusion: AFRG系统证明了使用低成本音频传感器替代昂贵力传感器的可行性，为机器人磨削提供了易于部署、成本效益高的解决方案，显著提高了不同磨削条件下的操作一致性。

Abstract: Acoustic feedback is a critical indicator for assessing the contact condition between the tool and the workpiece when humans perform grinding tasks with rotary tools. In contrast, robotic grinding systems typically rely on force sensing, with acoustic information largely ignored. This reliance on force sensors is costly and difficult to adapt to different grinding tools, whereas audio sensors (microphones) are low-cost and can be mounted on any medium that conducts grinding sound.
  This paper introduces a low-cost Acoustic Feedback Robotic Grinding System (AFRG) that captures audio signals with a contact microphone, estimates grinding force from the audio in real time, and enables closed-loop force control of the grinding process. Compared with conventional force-sensing approaches, AFRG achieves a 4-fold improvement in consistency across different grinding disc conditions. AFRG relies solely on a low-cost microphone, which is approximately 200-fold cheaper than conventional force sensors, as the sensing modality, providing an easily deployable, cost-effective robotic grinding solution.

</details>


### [15] [Robot Local Planner: A Periodic Sampling-Based Motion Planner with Minimal Waypoints for Home Environments](https://arxiv.org/abs/2602.20645)
*Keisuke Takeshita,Takahiro Yamazaki,Tomohiro Ono,Takashi Yamamoto*

Main category: cs.RO

TL;DR: 提出了一种用于家庭环境的周期性采样全身轨迹规划方法RLP，能够在运动中识别环境并规划动作，实现快速安全的操作任务。


<details>
  <summary>Details</summary>
Motivation: 开发能够在家庭环境中快速安全执行操作任务的系统，需要在运动中识别周围环境并规划动作，同时保证计算效率、运动最优性和安全性。

Method: 提出周期性采样全身轨迹规划方法RLP，利用家庭环境特征提高计算效率，通过最小化路径点规划安全轨迹，周期性执行轨迹规划选择更优运动，并采用对基座位置误差鲁棒的逆运动学。

Result: RLP在运动规划时间、运动持续时间和鲁棒性方面优于现有方法，在整理任务中实现了高成功率和短操作时间。

Conclusion: RLP方法在家庭环境中具有高效性、最优性和鲁棒性，能够实现快速安全的操作任务，具有实际可行性。

Abstract: The objective of this study is to enable fast and safe manipulation tasks in home environments. Specifically, we aim to develop a system that can recognize its surroundings and identify target objects while in motion, enabling it to plan and execute actions accordingly. We propose a periodic sampling-based whole-body trajectory planning method, called the "Robot Local Planner (RLP)." This method leverages unique features of home environments to enhance computational efficiency, motion optimality, and robustness against recognition and control errors, all while ensuring safety. The RLP minimizes computation time by planning with minimal waypoints and generating safe trajectories. Furthermore, overall motion optimality is improved by periodically executing trajectory planning to select more optimal motions. This approach incorporates inverse kinematics that are robust to base position errors, further enhancing robustness. Evaluation experiments demonstrated that the RLP outperformed existing methods in terms of motion planning time, motion duration, and robustness, confirming its effectiveness in home environments. Moreover, application experiments using a tidy-up task achieved high success rates and short operation times, thereby underscoring its practical feasibility.

</details>


### [16] [IG-RFT: An Interaction-Guided RL Framework for VLA Models in Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2602.20715)
*Zhian Su,Weijie Kong,Haonan Dong,Huixu Dong*

Main category: cs.RO

TL;DR: IG-RFT：一种用于基于流的VLA模型的交互引导强化微调系统，通过IG-AWR算法和混合密集奖励函数解决VLA模型在真实世界长时程任务中的泛化问题


<details>
  <summary>Details</summary>
Motivation: VLA模型在真实世界长时程复杂任务中泛化能力不足，存在分布偏移和高质量演示稀缺的问题，而传统强化学习在真实世界VLA微调中存在探索效率、训练稳定性和样本成本等挑战

Method: 提出IG-RFT系统，包含：1）IG-AWR算法，根据机器人交互状态动态调节探索强度；2）混合密集奖励函数，整合轨迹级和子任务级奖励；3）三阶段RL系统（SFT、离线RL、人在回路RL）

Result: 在四个具有挑战性的长时程任务上进行真实世界实验，IG-RFT平均成功率85.0%，显著优于SFT（18.8%）和标准离线RL基线（40.0%），消融研究证实了IG-AWR和混合奖励塑形的关键贡献

Conclusion: 建立并验证了一种用于真实世界机器人操作的VLA模型强化微调系统，为解决VLA模型在复杂真实世界任务中的泛化问题提供了有效方案

Abstract: Vision-Language-Action (VLA) models have demonstrated significant potential for generalist robotic policies; however, they struggle to generalize to long-horizon complex tasks in novel real-world domains due to distribution shifts and the scarcity of high-quality demonstrations. Although reinforcement learning (RL) offers a promising avenue for policy improvement, applying it to real-world VLA fine-tuning faces challenges regarding exploration efficiency, training stability, and sample cost. To address these issues, we propose IG-RFT, a novel Interaction-Guided Reinforced Fine-Tuning system designed for flow-based VLA models. Firstly, to facilitate effective policy optimization, we introduce Interaction-Guided Advantage Weighted Regression (IG-AWR), an RL algorithm that dynamically modulates exploration intensity based on the robot's interaction status. Furthermore, to address the limitations of sparse or task-specific rewards, we design a novel hybrid dense reward function that integrates the trajectory-level reward and the subtask-level reward. Finally, we construct a three-stage RL system comprising SFT, Offline RL, and Human-in-the-Loop RL for fine-tuning VLA models. Extensive real-world experiments on four challenging long-horizon tasks demonstrate that IG-RFT achieves an average success rate of 85.0%, significantly outperforming SFT (18.8%) and standard Offline RL baselines (40.0%). Ablation studies confirm the critical contributions of IG-AWR and hybrid reward shaping. In summary, our work establishes and validates a novel reinforced fine-tuning system for VLA models in real-world robotic manipulation.

</details>


### [17] [Visual Cooperative Drone Tracking for Open-Path Gas Measurements](https://arxiv.org/abs/2602.20768)
*Marius Schaab,Alisha Kiefer,Thomas Wiedemann,Patrick Hinsen,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 本文提出了一种用于开放路径激光吸收光谱测量的机器人系统，使用地面云台传感器和无人机携带反射器，实现自主跟踪和气体测量


<details>
  <summary>Details</summary>
Motivation: 开放路径可调谐二极管激光吸收光谱技术能有效测量气体浓度，但需要专用反射面，这使得自动化空间采样过程具有挑战性

Method: 开发了由地面云台单元（配备传感器和变焦相机）和携带反射器的小型无人机组成的机器人系统，通过视觉跟踪无人机上的LED标记并结合GNSS位置信息来对准激光束

Result: 室外实验验证了系统性能，成功实现自主跟踪和有效CO2测量，距离达60米，并能测量CO2羽流而不受无人机推进系统干扰

Conclusion: 该系统克服了传统开放路径测量的反射面限制，实现了自动化气体测量，相比飞行原位传感器具有优越性

Abstract: Open-path Tunable Diode Laser Absorption Spectroscopy offers an effective method for measuring, mapping, and monitoring gas concentrations, such as leaking CO2 or methane. Compared to spatial sampling of gas distributions using in-situ sensors, open-path sensors in combination with gas tomography algorithms can cover large outdoor environments faster in a non-invasive way. However, the requirement of a dedicated reflection surface for the open-path laser makes automating the spatial sampling process challenging. This publication presents a robotic system for collecting open-path measurements, making use of a sensor mounted on a ground-based pan-tilt unit and a small drone carrying a reflector. By means of a zoom camera, the ground unit visually tracks red LED markers mounted on the drone and aligns the sensor's laser beam with the reflector. Incorporating GNSS position information provided by the drone's flight controller further improves the tracking approach. Outdoor experiments validated the system's performance, demonstrating successful autonomous tracking and valid CO2 measurements at distances up to 60 meters. Furthermore, the system successfully measured a CO2 plume without interference from the drone's propulsion system, demonstrating its superiority compared to flying in-situ sensors.

</details>


### [18] [KCFRC: Kinematic Collision-Aware Foothold Reachability Criteria for Legged Locomotion](https://arxiv.org/abs/2602.20850)
*Lei Ye,Haibo Gao,Huaiguang Yang,Peng Xu,Haoyu Wang,Tie Liu,Junqi Shan,Zongquan Deng,Liang Ding*

Main category: cs.RO

TL;DR: 本文提出KCFRC算法，用于高效分析足式机器人的落脚点可达性，能在2ms内完成900个潜在落脚点的可达性验证，显著提升机器人在复杂环境中的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 足式机器人在复杂环境中导航面临重大挑战，需要精确的实时决策来选择落脚点和规划接触。现有方法主要基于地形几何或运动学选择落脚点，但缺乏高效验证无碰撞摆动轨迹存在性的方法，这是当前研究的关键空白。

Method: 首先正式定义落脚点可达性问题并建立可达性的充分条件。基于此条件开发KCFRC算法，使机器人能够实时验证落脚点的可达性。该方法特别适用于受限空间中的接触规划。

Result: 实验结果显示KCFRC具有显著的时间效率，单腿在900个潜在落脚点上完成可达性检查的平均时间仅为2ms。该算法还能加速轨迹优化，在受限空间的接触规划中表现尤为突出。

Conclusion: KCFRC算法填补了足式机器人落脚点可达性验证的关键空白，通过高效的实时验证能力，显著提升了足式机器人在挑战性环境中的适应性和鲁棒性，特别是在受限空间中的导航能力。

Abstract: Legged robots face significant challenges in navigating complex environments, as they require precise real-time decisions for foothold selection and contact planning. While existing research has explored methods to select footholds based on terrain geometry or kinematics, a critical gap remains: few existing methods efficiently validate the existence of a non-collision swing trajectory. This paper addresses this gap by introducing KCFRC, a novel approach for efficient foothold reachability analysis. We first formally define the foothold reachability problem and establish a sufficient condition for foothold reachability. Based on this condition, we develop the KCFRC algorithm, which enables robots to validate foothold reachability in real time. Our experimental results demonstrate that KCFRC achieves remarkable time efficiency, completing foothold reachability checks for a single leg across 900 potential footholds in an average of 2 ms. Furthermore, we show that KCFRC can accelerate trajectory optimization and is particularly beneficial for contact planning in confined spaces, enhancing the adaptability and robustness of legged robots in challenging environments.

</details>


### [19] [GeCo-SRT: Geometry-aware Continual Adaptation for Robotic Cross-Task Sim-to-Real Transfer](https://arxiv.org/abs/2602.20871)
*Wenbo Yu,Wenke Xia,Weitao Zhang,Di Hu*

Main category: cs.RO

TL;DR: GeCo-SRT提出了一种几何感知的持续适应方法，通过积累跨任务的知识来桥接仿真到现实的差距，相比基线平均性能提升52%，新任务适应仅需1/6数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法将每次仿真到现实的转移视为独立任务，需要重复昂贵的调优，浪费了先前的转移经验。需要超越这种孤立的方法，建立持续跨任务的仿真到现实转移范式。

Method: GeCo-SRT方法包含两个核心模块：1）几何感知的专家混合模块，动态激活专家专门处理不同的几何知识来桥接观测差距；2）几何专家引导的优先经验回放模块，优先从未充分利用的专家中采样，刷新专门知识以对抗遗忘。

Result: 该方法相比基线实现了52%的平均性能提升，并且在新任务适应中表现出显著的数据效率，仅需1/6的数据量。

Conclusion: GeCo-SRT通过利用局部几何特征中的领域不变和任务不变知识作为可转移基础，实现了高效、低成本的跨任务仿真到现实转移，为持续知识积累提供了新思路。

Abstract: Bridging the sim-to-real gap is important for applying low-cost simulation data to real-world robotic systems. However, previous methods are severely limited by treating each transfer as an isolated endeavor, demanding repeated, costly tuning and wasting prior transfer experience.To move beyond isolated sim-to-real, we build a continual cross-task sim-to-real transfer paradigm centered on knowledge accumulation across iterative transfers, thereby enabling effective and efficient adaptation to novel tasks. Thus, we propose GeCo-SRT, a geometry-aware continual adaptation method. It utilizes domain-invariant and task-invariant knowledge from local geometric features as a transferable foundation to accelerate adaptation during subsequent sim-to-real transfers. This method starts with a geometry-aware mixture-of-experts module, which dynamically activates experts to specialize in distinct geometric knowledge to bridge observation sim-to-real gap. Further, the geometry-expert-guided prioritized experience replay module preferentially samples from underutilized experts, refreshing specialized knowledge to combat forgetting and maintain robust cross-task performance. Leveraging knowledge accumulated during iterative transfer, GeCo-SRT method not only achieves 52% average performance improvement over the baseline, but also demonstrates significant data efficiency for new task adaptation with only 1/6 data.We hope this work inspires approaches for efficient, low-cost cross-task sim-to-real transfer.

</details>


### [20] [Task-oriented grasping for dexterous robots using postural synergies and reinforcement learning](https://arxiv.org/abs/2602.20915)
*Dimitrios Dimou,José Santos-Victor,Plinio Moreno*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习的任务导向抓取方法，结合人类抓取偏好数据，使仿人机器人能够考虑下游任务约束进行多物体抓取。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏端到端的解决方案，无法在抓取多个物体时考虑下游任务的约束。需要让仿人机器人的抓取行为符合人类社交规范并满足任务特定目标。

Method: 1. 从ContactPose数据集中提取人类抓取偏好；2. 基于变分自编码器(VAE)训练手部协同模型来模仿人类抓取动作；3. 使用强化学习训练能够考虑任务特定抓取后意图的智能体。

Result: 开发出能够考虑任务特定约束进行多物体抓取的智能体，结合人类抓取行为的数据驱动洞察和强化学习的探索学习能力。

Conclusion: 通过结合人类抓取行为数据和强化学习，可以开发出具有上下文感知操作能力的仿人机器人，促进在人类中心环境中的协作。

Abstract: In this paper, we address the problem of task-oriented grasping for humanoid robots, emphasizing the need to align with human social norms and task-specific objectives. Existing methods, employ a variety of open-loop and closed-loop approaches but lack an end-to-end solution that can grasp several objects while taking into account the downstream task's constraints. Our proposed approach employs reinforcement learning to enhance task-oriented grasping, prioritizing the post-grasp intention of the agent. We extract human grasp preferences from the ContactPose dataset, and train a hand synergy model based on the Variational Autoencoder (VAE) to imitate the participant's grasping actions. Based on this data, we train an agent able to grasp multiple objects while taking into account distinct post-grasp intentions that are task-specific. By combining data-driven insights from human grasping behavior with learning by exploration provided by reinforcement learning, we can develop humanoid robots capable of context-aware manipulation actions, facilitating collaboration in human-centered environments.

</details>


### [21] [Computer-Aided Design of Rational Motions for 4R and 6R Spatial Mechanism Synthesis](https://arxiv.org/abs/2602.20920)
*Daniel Huczala,Severinas Zube,Martin Pfurner,Johannes Siegele,Frank C. Park*

Main category: cs.RO

TL;DR: 提出基于三次四元数贝塞尔曲线的新插值方案，用于生成有理运动，并实现空间六杆机构的合成


<details>
  <summary>Details</summary>
Motivation: 为单环有理连杆机构设计提供几何方法，使机构能够执行规定的空间任务，支持工程实践应用

Method: 基于现有有理运动合成方法，引入基于三次四元数贝塞尔曲线的七个3D点插值方案，实现运动分解和空间六杆机构合成

Result: 开发了开源CAD工具，实现了该方法及其他方法，提供运动生成和机构合成的快速可视化评估

Conclusion: 提出的几何方法和CAD工具为有理连杆机构设计提供了有效的工程实践支持

Abstract: This paper focuses on geometric methods for generating rational motions used in the design of single-loop rational linkages, 1-degree-of-freedom mechanisms that can execute prescribed spatial tasks. Building on established rational motion synthesis methods, we introduce a new interpolation scheme for seven 3D points based on cubic quaternionic Bezier curves. The resulting motion admits factorization, i.e. the synthesis of a spatial six-bar mechanism whose tool frame passes the specified seven points. To support engineering practice, we provide open-source CAD tools that implement also the other methods and provide fast visual evaluation of motion generation and mechanism synthesis.

</details>


### [22] [ParkDiffusion++: Ego Intention Conditioned Joint Multi-Agent Trajectory Prediction for Automated Parking using Diffusion Models](https://arxiv.org/abs/2602.20923)
*Jiarong Wei,Anna Rehr,Christian Feist,Abhinav Valada*

Main category: cs.RO

TL;DR: ParkDiffusion++：用于自动泊车的联合多模态自我意图预测和多智能体轨迹预测方法，通过自我意图标记化、条件联合预测、安全引导去噪和反事实知识蒸馏提升性能。


<details>
  <summary>Details</summary>
Motivation: 自动泊车是高级驾驶辅助系统的挑战性领域，需要鲁棒的场景理解和交互推理。现有方法通常将自我意图预测和周围智能体响应预测这两个相互依赖的问题孤立处理，无法有效支持"假设"决策。

Method: 1. 自我意图标记器：从智能体历史和矢量化地图折线预测离散的终点意图集合；2. 自我意图条件联合预测：为每个可能的自我意图生成周围智能体的社会一致性预测；3. 轻量级安全引导去噪器：在训练期间使用不同约束细化联合场景；4. 反事实知识蒸馏：通过冻结的安全引导去噪器精炼的EMA教师模型提供伪目标，捕捉智能体对替代自我意图的反应。

Result: 在Dragon Lake Parking (DLP)数据集和Intersections Drone (inD)数据集上实现了最先进的性能。定性"假设"可视化显示其他智能体对不同自我意图做出适当反应。

Conclusion: ParkDiffusion++通过联合学习多模态自我意图预测和自我条件多智能体联合轨迹预测，有效解决了自动泊车中的场景理解和交互推理挑战，支持更好的"假设"决策。

Abstract: Automated parking is a challenging operational domain for advanced driver assistance systems, requiring robust scene understanding and interaction reasoning. The key challenge is twofold: (i) predict multiple plausible ego intentions according to context and (ii) for each intention, predict the joint responses of surrounding agents, enabling effective what-if decision-making. However, existing methods often fall short, typically treating these interdependent problems in isolation. We propose ParkDiffusion++, which jointly learns a multi-modal ego intention predictor and an ego-conditioned multi-agent joint trajectory predictor for automated parking. Our approach makes several key contributions. First, we introduce an ego intention tokenizer that predicts a small set of discrete endpoint intentions from agent histories and vectorized map polylines. Second, we perform ego-intention-conditioned joint prediction, yielding socially consistent predictions of the surrounding agents for each possible ego intention. Third, we employ a lightweight safety-guided denoiser with different constraints to refine joint scenes during training, thus improving accuracy and safety. Fourth, we propose counterfactual knowledge distillation, where an EMA teacher refined by a frozen safety-guided denoiser provides pseudo-targets that capture how agents react to alternative ego intentions. Extensive evaluations demonstrate that ParkDiffusion++ achieves state-of-the-art performance on the Dragon Lake Parking (DLP) dataset and the Intersections Drone (inD) dataset. Importantly, qualitative what-if visualizations show that other agents react appropriately to different ego intentions.

</details>


### [23] [LST-SLAM: A Stereo Thermal SLAM System for Kilometer-Scale Dynamic Environments](https://arxiv.org/abs/2602.20925)
*Zeyu Jiang,Kuan Xu,Changhao Chen*

Main category: cs.RO

TL;DR: LST-SLAM：一种新颖的大规模立体热成像SLAM系统，通过自监督热特征学习、立体双级运动跟踪和几何位姿优化，在复杂动态场景中实现鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 热成像相机在挑战性光照和天气条件下具有强大的机器人感知潜力，但热成像SLAM由于特征提取不可靠、运动跟踪不稳定、全局位姿和地图构建不一致等问题，特别是在动态大规模室外环境中仍然困难。

Method: 结合自监督热特征学习、立体双级运动跟踪和几何位姿优化；引入语义-几何混合约束抑制缺乏强帧间几何一致性的潜在动态特征；开发用于闭环检测的在线增量词袋模型，并结合全局位姿优化减少累积漂移。

Result: 在千米级动态热成像数据集上的广泛实验表明，LST-SLAM在鲁棒性和准确性方面显著优于最近的代表性SLAM系统（包括AirSLAM和DROID-SLAM）。

Conclusion: LST-SLAM系统有效解决了热成像SLAM在复杂动态环境中的挑战，通过创新的特征学习、运动跟踪和优化方法，实现了大规模室外场景下的鲁棒性能。

Abstract: Thermal cameras offer strong potential for robot perception under challenging illumination and weather conditions. However, thermal Simultaneous Localization and Mapping (SLAM) remains difficult due to unreliable feature extraction, unstable motion tracking, and inconsistent global pose and map construction, particularly in dynamic large-scale outdoor environments. To address these challenges, we propose LST-SLAM, a novel large-scale stereo thermal SLAM system that achieves robust performance in complex, dynamic scenes. Our approach combines self-supervised thermal feature learning, stereo dual-level motion tracking, and geometric pose optimization. We also introduce a semantic-geometric hybrid constraint that suppresses potentially dynamic features lacking strong inter-frame geometric consistency. Furthermore, we develop an online incremental bag-of-words model for loop closure detection, coupled with global pose optimization to mitigate accumulated drift. Extensive experiments on kilometer-scale dynamic thermal datasets show that LST-SLAM significantly outperforms recent representative SLAM systems, including AirSLAM and DROID-SLAM, in both robustness and accuracy.

</details>


### [24] [EKF-Based Depth Camera and Deep Learning Fusion for UAV-Person Distance Estimation and Following in SAR Operations](https://arxiv.org/abs/2602.20958)
*Luka Šiktar,Branimir Ćaran,Bojan Šekoranja,Marko Švaco*

Main category: cs.RO

TL;DR: 该论文提出了一种用于无人机搜救任务中人体跟踪跟随的深度相机与单目相机融合距离估计系统，通过YOLO-pose和扩展卡尔曼滤波实现实时距离测量，在室内测试中平均误差降低15.3%。


<details>
  <summary>Details</summary>
Motivation: 搜救任务需要快速响应，无人机配备视觉系统可以辅助人类搜索任务。关键安全需求是在真实条件下准确估计相机与目标对象之间的距离，这需要通过融合多种图像模态来实现。

Method: 提出融合深度相机测量和单目相机到人体距离估计的系统。使用YOLO-pose进行深度相机数据过滤和单目相机距离估计，通过扩展卡尔曼滤波算法实时融合深度信息。系统估计深度相机与人体关键点之间的距离，以保持无人机与人体目标的安全距离。

Result: 系统提供了准确的估计距离，已通过运动捕捉地面真实数据验证。在室内实时测试中，在三个测试场景中将距离估计的平均误差、均方根误差和标准差降低了15.3%。

Conclusion: 该研究提出了一种基于深度学习的无人机视觉系统，通过融合深度相机和单目相机信息，实现了在搜救任务中对人体目标的准确距离估计和跟踪跟随，提高了无人机操作的安全性。

Abstract: Search and rescue (SAR) operations require rapid responses to save lives or property. Unmanned Aerial Vehicles (UAVs) equipped with vision-based systems support these missions through prior terrain investigation or real-time assistance during the mission itself. Vision-based UAV frameworks aid human search tasks by detecting and recognizing specific individuals, then tracking and following them while maintaining a safe distance. A key safety requirement for UAV following is the accurate estimation of the distance between camera and target object under real-world conditions, achieved by fusing multiple image modalities. UAVs with deep learning-based vision systems offer a new approach to the planning and execution of SAR operations. As part of the system for automatic people detection and face recognition using deep learning, in this paper we present the fusion of depth camera measurements and monocular camera-to-body distance estimation for robust tracking and following. Deep learning-based filtering of depth camera data and estimation of camera-to-body distance from a monocular camera are achieved with YOLO-pose, enabling real-time fusion of depth information using the Extended Kalman Filter (EKF) algorithm. The proposed subsystem, designed for use in drones, estimates and measures the distance between the depth camera and the human body keypoints, to maintain the safe distance between the drone and the human target. Our system provides an accurate estimated distance, which has been validated against motion capture ground truth data. The system has been tested in real time indoors, where it reduces the average errors, root mean square error (RMSE) and standard deviations of distance estimation up to 15,3\% in three tested scenarios.

</details>


### [25] [A Robotic Testing Platform for Pipelined Discovery of Resilient Soft Actuators](https://arxiv.org/abs/2602.20963)
*Ang,Li,Alexander Yin,Alexander White,Sahib Sandhu,Matthew Francoeur,Victor Jimenez-Santiago,Van Remenar,Codrin Tugui,Mihai Duduta*

Main category: cs.RO

TL;DR: 提出了一种基于测试机器人的优化流程，用于扫描线性介电弹性体驱动器（DEA）的寿命，通过参数优化将运行寿命提高100%，并成功应用于四足机器人


<details>
  <summary>Details</summary>
Motivation: 线性介电弹性体驱动器在高电场下的短寿命限制了其在机器人领域的广泛应用，传统方法难以系统扫描高维参数空间

Method: 开发了新型测试机器人，集成了机电性能测量、可编程电压输入和多通道测试能力，用于扫描Elastosil基线性驱动器在不同参数（电压幅值、频率、电极材料浓度、电连接填料）下的寿命

Result: 通过参数优化，在边界工作条件下将运行寿命提高达100%，最终产品在模块化可扩展四足行走机器人上表现出良好的承载能力（>100%无缆体重，>700%执行器总重）

Conclusion: 这是首次将自动驾驶实验室方法引入机器人执行器设计，为DEA的优化和应用提供了系统化解决方案

Abstract: Short lifetime under high electrical fields hinders the widespread robotic application of linear dielectric elastomer actuators (DEAs). Systematic scanning is difficult due to time-consuming per-sample testing and the high-dimensional parameter space affecting performance. To address this, we propose an optimization pipeline enabled by a novel testing robot capable of scanning DEA lifetime. The robot integrates electro-mechanical property measurement, programmable voltage input, and multi-channel testing capacity. Using it, we scanned the lifetime of Elastosil-based linear actuators across parameters including input voltage magnitude, frequency, electrode material concentration, and electrical connection filler. The optimal parameter combinations improved operational lifetime under boundary operating conditions by up to 100% and were subsequently scaled up to achieve higher force and displacement output. The final product demonstrated resilience on a modular, scalable quadruped walking robot with payload carrying capacity (>100% of its untethered body weight, and >700% of combined actuator weight). This work is the first to introduce a self-driving lab approach into robotic actuator design.

</details>


### [26] [Surface-based Manipulation Using Tunable Compliant Porous-Elastic Soft Sensing](https://arxiv.org/abs/2602.21028)
*Gayatri Indukumar,Muhammad Awais,Diana Cafiso,Matteo Lo Preti,Lucia Beccai*

Main category: cs.RO

TL;DR: COPESS软体机器人平台通过可调晶格层同时调控机械柔顺性和传感性能，实现自适应物体操作和局部化感知


<details>
  <summary>Details</summary>
Motivation: 现有表面操作系统缺乏处理各种物体所需的柔顺性和触觉反馈，需要能够进行轻柔精确操作的软体机器人平台

Method: 设计集成电感传感器的COPESS系统，采用可调晶格层同时调节机械柔顺性和传感性能，通过调整晶格几何形状来定制刚度和传感器响应

Result: 实验表明，仅通过调整晶格密度（7%到20%），就能显著改变灵敏度和操作力范围（分别约-23倍和9倍）

Conclusion: 该方法为创建自适应传感表面提供了蓝图，实现了机械和感官特性的协同优化，支持被动但可编程的精细操作

Abstract: There is a growing need for soft robotic platforms that perform gentle, precise handling of a wide variety of objects. Existing surface-based manipulation systems, however, lack the compliance and tactile feedback needed for delicate handling. This work introduces the COmpliant Porous-Elastic Soft Sensing (COPESS) integrated with inductive sensors for adaptive object manipulation and localised sensing. The design features a tunable lattice layer that simultaneously modulates mechanical compliance and sensing performance. By adjusting lattice geometry, both stiffness and sensor response can be tailored to handle objects with varying mechanical properties. Experiments demonstrate that by easily adjusting one parameter, the lattice density, from 7 % to 20 %, it is possible to significantly alter the sensitivity and operational force range (about -23x and 9x, respectively). This approach establishes a blueprint for creating adaptive, sensorized surfaces where mechanical and sensory properties are co-optimized, enabling passive, yet programmable, delicate manipulation.

</details>


### [27] [Cooperative-Competitive Team Play of Real-World Craft Robots](https://arxiv.org/abs/2602.21119)
*Rui Zhao,Xihui Li,Yizheng Zhang,Yuzhen Liu,Zhong Zhang,Yufeng Zhang,Cheng Zhou,Zhengyou Zhang,Lei Han*

Main category: cs.RO

TL;DR: 该论文提出一个用于多智能体机器人深度强化学习的综合系统，包含仿真、分布式学习框架和物理机器人组件，并引入OODSI方法缓解仿真到现实的迁移问题，在实验中提升了20%的性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体深度强化学习在游戏智能体方面取得进展，但如何高效训练集体机器人并将学习策略迁移到现实应用仍是开放研究问题。需要解决多智能体仿真到现实迁移的挑战。

Method: 1. 开发综合机器人系统，包括仿真、分布式学习框架和物理机器人组件；2. 提出并评估用于高效训练合作和竞争策略的强化学习技术；3. 引入OODSI（分布外状态初始化）方法缓解仿真到现实的差距。

Result: OODSI方法将仿真到现实的性能提升了20%。通过多机器人汽车竞争游戏和现实环境中的合作任务实验，验证了方法的有效性。

Conclusion: 该研究提出了一个完整的多智能体机器人强化学习平台和OODSI方法，有效解决了仿真到现实的迁移问题，为多机器人系统的实际应用提供了可行方案。

Abstract: Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications remain open research questions. In this work, we first develop a comprehensive robotic system, including simulation, distributed learning framework, and physical robot components. We then propose and evaluate reinforcement learning techniques designed for efficient training of cooperative and competitive policies on this platform. To address the challenges of multi-agent sim-to-real transfer, we introduce Out of Distribution State Initialization (OODSI) to mitigate the impact of the sim-to-real gap. In the experiments, OODSI improves the Sim2Real performance by 20%. We demonstrate the effectiveness of our approach through experiments with a multi-robot car competitive game and a cooperative task in real-world settings.

</details>


### [28] [A Micro-Macro Model of Encounter-Driven Information Diffusion in Robot Swarms](https://arxiv.org/abs/2602.21148)
*Davis S. Catherman,Carlo Pinciroli*

Main category: cs.RO

TL;DR: 本文提出了"相遇驱动信息扩散"(EDID)问题，研究机器人在仅能通过相遇交换信息且无法安排会面的情况下的信息传播模型


<details>
  <summary>Details</summary>
Motivation: 研究机器人在无法安排会面、只能随机相遇的情况下如何进行信息传播，为设计存储和路由算法提供理论基础

Method: 提出双层模型：微观模型基于"平均自由程"概念的推广，宏观模型捕捉信息扩散的全局动态，并通过机器人模拟验证模型

Result: 通过大量机器人模拟验证了模型的有效性，考虑了群体规模、通信范围、环境大小和不同随机运动机制等因素

Conclusion: 该模型为EDID问题提供了理论基础，并讨论了模型参数对最佳信息扩散算法设计的影响

Abstract: In this paper, we propose the problem of Encounter-Driven Information Diffusion (EDID). In EDID, robots are allowed to exchange information only upon meeting. Crucially, EDID assumes that the robots are not allowed to schedule their meetings. As such, the robots have no means to anticipate when, where, and who they will meet. As a step towards the design of storage and routing algorithms for EDID, in this paper we propose a model of information diffusion that captures the essential dynamics of EDID. The model is derived from first principles and is composed of two levels: a micro model, based on a generalization of the concept of `mean free path'; and a macro model, which captures the global dynamics of information diffusion. We validate the model through extensive robot simulations, in which we consider swarm size, communication range, environment size, and different random motion regimes. We conclude the paper with a discussion of the implications of this model on the algorithms that best support information diffusion according to the parameters of interest.

</details>


### [29] [HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.21157)
*Quanxin Shou,Fangqi Zhu,Shawn Chen,Puxin Yan,Zhengyang Yan,Yikun Miao,Xiaoyi Pang,Zicong Hong,Ruikai Shi,Hao Huang,Jie Zhang,Song Guo*

Main category: cs.RO

TL;DR: HALO是一个统一的视觉-语言-动作模型，通过具身多模态思维链推理，结合文本任务推理、视觉子目标预测和动作预测，在机器人操作任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在长视野或分布外场景中表现不佳，缺乏明确的多模态推理机制和动作对世界演变的预测能力。虽然已有工作引入文本思维链或视觉子目标预测，但仍缺乏统一的人类式推理框架来整合文本推理、视觉预见和动作预测。

Method: 提出HALO模型，通过具身多模态思维链推理实现文本任务推理、视觉子目标预测和动作预测的序列化过程。采用混合Transformer架构，将语义推理、视觉预见和动作预测解耦为专门专家，同时支持跨专家协作。开发自动化流水线合成训练数据，并设计精心调制的训练方案。

Result: HALO在模拟和真实环境中均取得优越性能，在RoboTwin基准上比基线策略pi_0提升34.1%。训练方案和EM-CoT设计的所有组件都有助于提高任务成功率。在激进未见环境随机化下，HALO展现出强大的泛化能力。

Conclusion: HALO通过统一的具身多模态思维链推理框架，有效解决了现有VLA模型在复杂场景中的局限性，为机器人操作任务提供了更强大的推理和泛化能力。

Abstract: Vision-Language-Action (VLA) models have shown strong performance in robotic manipulation, but often struggle in long-horizon or out-of-distribution scenarios due to the lack of explicit mechanisms for multimodal reasoning and anticipating how the world will evolve under action. Recent works introduce textual chain-of-thought or visual subgoal prediction within VLA models to reason, but still fail to offer a unified human-like reasoning framework for joint textual reasoning, visual foresight, and action prediction. To this end, we propose HALO, a unified VLA model that enables embodied multimodal chain-of-thought (EM-CoT) reasoning through a sequential process of textual task reasoning, visual subgoal prediction for fine-grained guidance, and EM-CoT-augmented action prediction. We instantiate HALO with a Mixture-of-Transformers (MoT) architecture that decouples semantic reasoning, visual foresight, and action prediction into specialized experts while allowing seamless cross-expert collaboration. To enable HALO learning at scale, we introduce an automated pipeline to synthesize EM-CoT training data along with a carefully crafted training recipe. Extensive experiments demonstrate that: (1) HALO achieves superior performance in both simulated and real-world environments, surpassing baseline policy pi_0 by 34.1% on RoboTwin benchmark; (2) all proposed components of the training recipe and EM-CoT design help improve task success rate; and (3) HALO exhibits strong generalization capabilities under aggressive unseen environmental randomization with our proposed EM-CoT reasoning.

</details>


### [30] [ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking](https://arxiv.org/abs/2602.21161)
*Guangming Wang,Qizhen Ying,Yixiong Jing,Olaf Wysocki,Brian Sheil*

Main category: cs.RO

TL;DR: 本文提出ActionReasoning框架，利用LLM进行显式动作推理，为机器人操作生成物理一致、先验引导的决策，在砖块堆叠任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统依赖定制规划器，在受限环境中有效但缺乏泛化能力，限制了具身AI和通用机器人的可扩展性。现有的VLA方法试图从大规模数据中学习策略，但物理世界的连续动作空间远超语言令牌的表征能力，仅靠数据扩展难以实现通用机器人智能。

Method: 提出ActionReasoning框架，利用LLM中已有的物理先验和现实世界知识，通过多智能体架构进行结构化。在砖块堆叠案例中，将准确测量的环境状态序列化，输入多智能体LLM框架生成物理感知的动作计划。

Result: 实验表明，提出的多智能体LLM框架能够实现稳定的砖块放置，同时将工作重心从低级的领域特定编码转移到高级的工具调用和提示工程，展示了其更广泛泛化的潜力。

Conclusion: 这项工作通过将物理推理与LLM集成，为机器人操作中感知与执行的桥接提供了一种有前景的方法，有望促进更通用的机器人智能发展。

Abstract: Classical robotic systems typically rely on custom planners designed for constrained environments. While effective in restricted settings, these systems lack generalization capabilities, limiting the scalability of embodied AI and general-purpose robots. Recent data-driven Vision-Language-Action (VLA) approaches aim to learn policies from large-scale simulation and real-world data. However, the continuous action space of the physical world significantly exceeds the representational capacity of linguistic tokens, making it unclear if scaling data alone can yield general robotic intelligence. To address this gap, we propose ActionReasoning, an LLM-driven framework that performs explicit action reasoning to produce physics-consistent, prior-guided decisions for robotic manipulation. ActionReasoning leverages the physical priors and real-world knowledge already encoded in Large Language Models (LLMs) and structures them within a multi-agent architecture. We instantiate this framework on a tractable case study of brick stacking, where the environment states are assumed to be already accurately measured. The environmental states are then serialized and passed to a multi-agent LLM framework that generates physics-aware action plans. The experiments demonstrate that the proposed multi-agent LLM framework enables stable brick placement while shifting effort from low-level domain-specific coding to high-level tool invocation and prompting, highlighting its potential for broader generalization. This work introduces a promising approach to bridging perception and execution in robotic manipulation by integrating physical reasoning with LLMs.

</details>


### [31] [Efficient Hierarchical Any-Angle Path Planning on Multi-Resolution 3D Grids](https://arxiv.org/abs/2602.21174)
*Victor Reijgwart,Cesar Cadena,Roland Siegwart,Lionel Ott*

Main category: cs.RO

TL;DR: 提出一种基于多分辨率体素地图的任意角度路径规划方法，结合了任意角度规划的最优性和完备性，同时利用多分辨率表示克服搜索方法的计算可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法存在局限性：采样法和轨迹优化法未充分利用体素地图的显式连通性信息，基于搜索的方法（如A*）在大规模高分辨率地图中存在可扩展性问题。需要一种既能保持任意角度规划最优性和完备性，又能高效处理大规模环境的方法

Method: 提出一种基于多分辨率体素地图的任意角度路径规划框架，通过利用层次化、多分辨率的体素表示来捕获环境的占用和连通性信息，将任意角度规划的最优性和完备性与多分辨率表示的计算效率相结合

Result: 在真实和合成环境中的大量实验表明，该方法在解质量和速度方面均表现出色，甚至优于基于采样的方法。该方法能够高效处理大规模高分辨率地图，同时保持路径的最优性

Conclusion: 该方法成功地将任意角度规划的最优性和完备性与多分辨率表示的计算效率相结合，为大规模复杂环境中的路径规划提供了高效解决方案。框架已开源供机器人学和规划社区使用

Abstract: Hierarchical, multi-resolution volumetric mapping approaches are widely used to represent large and complex environments as they can efficiently capture their occupancy and connectivity information. Yet widely used path planning methods such as sampling and trajectory optimization do not exploit this explicit connectivity information, and search-based methods such as A* suffer from scalability issues in large-scale high-resolution maps. In many applications, Euclidean shortest paths form the underpinning of the navigation system. For such applications, any-angle planning methods, which find optimal paths by connecting corners of obstacles with straight-line segments, provide a simple and efficient solution. In this paper, we present a method that has the optimality and completeness properties of any-angle planners while overcoming computational tractability issues common to search-based methods by exploiting multi-resolution representations. Extensive experiments on real and synthetic environments demonstrate the proposed approach's solution quality and speed, outperforming even sampling-based methods. The framework is open-sourced to allow the robotics and planning community to build on our research.

</details>


### [32] [Squint: Fast Visual Reinforcement Learning for Sim-to-Real Robotics](https://arxiv.org/abs/2602.21203)
*Abdulaziz Almuzairee,Henrik I. Christensen*

Main category: cs.RO

TL;DR: Squint是一种视觉强化学习方法，通过并行仿真、分布评论家、分辨率压缩等技术，在单GPU上15分钟内训练出可迁移到真实机器人的策略。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习对机器人应用很有吸引力但成本高昂：离策略方法样本效率高但训练慢；同策略方法可并行化但浪费样本。现有方法在基于状态的控制中已实现快速训练，但扩展到视觉输入仍面临高维图像带来的训练动态复杂、存储和编码开销大的挑战。

Method: Squint是一种视觉软演员评论家方法，采用并行仿真、分布评论家、分辨率压缩（squinting）、层归一化、优化的更新数据比以及优化实现。在ManiSkill3的SO-101任务集（8个操作任务）上进行评估，该任务集包含大量领域随机化。

Result: 在单RTX 3090 GPU上训练15分钟，大多数任务在6分钟内收敛。实现了从仿真到真实SO-101机器人的迁移，训练速度超过现有视觉离策略和同策略方法。

Conclusion: Squint通过技术创新解决了视觉强化学习的训练效率问题，实现了快速训练和仿真到真实迁移，为机器人视觉控制提供了高效的解决方案。

Abstract: Visual reinforcement learning is appealing for robotics but expensive -- off-policy methods are sample-efficient yet slow; on-policy methods parallelize well but waste samples. Recent work has shown that off-policy methods can train faster than on-policy methods in wall-clock time for state-based control. Extending this to vision remains challenging, where high-dimensional input images complicate training dynamics and introduce substantial storage and encoding overhead. To address these challenges, we introduce Squint, a visual Soft Actor Critic method that achieves faster wall-clock training than prior visual off-policy and on-policy methods. Squint achieves this via parallel simulation, a distributional critic, resolution squinting, layer normalization, a tuned update-to-data ratio, and an optimized implementation. We evaluate on the SO-101 Task Set, a new suite of eight manipulation tasks in ManiSkill3 with heavy domain randomization, and demonstrate sim-to-real transfer to a real SO-101 robot. We train policies for 15 minutes on a single RTX 3090 GPU, with most tasks converging in under 6 minutes.

</details>
