<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 83]
- [cs.RO](#cs.RO) [Total: 64]
- [eess.SY](#eess.SY) [Total: 22]
- [cs.SY](#cs.SY) [Total: 2]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.SD](#cs.SD) [Total: 7]
- [cs.HC](#cs.HC) [Total: 16]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.LG](#cs.LG) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 提出基于证据检索的不确定性感知决策机制，用实例自适应的证据条件阈值替代全局固定阈值，通过Dempster-Shafer理论融合近邻样本预测分布，实现更可靠和可解释的决策。


<details>
  <summary>Details</summary>
Motivation: 传统基于预测熵的全局阈值方法在不确定性感知决策中存在置信错误率高、缺乏可解释性的问题，需要一种更可靠和透明的替代方案。

Method: 为每个测试实例在嵌入空间中检索近邻样本，使用Dempster-Shafer理论融合这些证据样本的预测分布，生成实例自适应的阈值标准。

Result: 在CIFAR-10/100数据集上，使用BiT和ViT骨干网络，相比预测熵阈值方法，取得了相当或更好的不确定性感知性能，显著减少了置信错误预测，同时保持了可持续的审核负载。

Conclusion: 证据条件标记机制为操作性的不确定性感知决策提供了比固定预测熵阈值更可靠、可解释的替代方案，仅需少量证据即可实现显著性能提升。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [2] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在准确率、训练效率和参数可扩展性方面优于纯经典模型，特别是在复杂视觉任务中表现突出


<details>
  <summary>Details</summary>
Motivation: 系统比较混合量子-经典神经网络与纯经典模型在性能、效率和鲁棒性方面的差异，评估量子计算在深度学习中的实际价值

Method: 在三个基准数据集(MNIST、CIFAR100、STL10)上对比混合模型(参数化量子电路+经典深度学习架构)和经典CNN模型，进行50个训练周期的实验，评估验证准确率、测试准确率、训练时间、计算资源使用和对抗鲁棒性

Result: 混合模型在所有数据集上准确率均更高(MNIST 99.38% vs 98.21%, CIFAR100 41.69% vs 32.25%, STL10 74.05% vs 63.76%)，训练速度快5-12倍，参数减少6-32%，内存使用更少(4-5GB vs 5-6GB)，CPU利用率更低(9.5% vs 23.2%)，在简单数据集上对抗鲁棒性显著更好

Conclusion: 混合量子-经典架构在准确率、训练效率和参数可扩展性方面具有明显优势，特别适用于复杂视觉任务，为量子计算在深度学习中的应用提供了有力证据

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [3] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 本研究提出了一个集成技术框架来解决高速公路交通拥堵问题，通过优化目标检测算法YOLOv11-DIoU和改进DeepSort跟踪算法提高车辆感知精度，同时使用GRU-Attention模型进行拥堵预警，在准确率和时间误差方面都取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 高速公路交通拥堵严重降低出行效率并阻碍区域连通性。现有的'检测-预测'系统存在关键缺陷：遮挡条件下车辆感知精度低，以及拥堵预测中长序列依赖关系的丢失。

Method: 1) 交通流感知：优化YOLOv11为YOLOv11-DIoU（用DIoU Loss替换GIoU Loss），改进DeepSort融合马氏距离和余弦距离；2) 使用Greenberg模型分析速度密度关系；3) 拥堵预警：构建GRU-Attention模型捕捉拥堵前兆，使用流量、密度和速度数据进行训练。

Result: YOLOv11-DIoU达到95.7% mAP（比基线高6.5个百分点），遮挡漏检率5.3%；DeepSort达到93.8% MOTA（比SORT高11.3个百分点）；GRU-Attention模型测试准确率99.7%（比传统GRU高7-9个百分点），10分钟提前预警时间误差≤1分钟，独立视频验证显示95%预警准确率。

Conclusion: 该框架为高速公路拥堵控制提供了量化支持，在智能交通应用中具有良好前景，能够有效解决现有系统的关键缺陷，实现高精度的交通感知和拥堵预警。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [4] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 利用卷积神经网络和图像模式识别技术，自动化路边停车服务的测试分析过程，将人工资源需求减少99.58%


<details>
  <summary>Details</summary>
Motivation: 优化基于众包车辆数据的实时路边停车服务质量，通过自动化现有地面实况测试流程来替代人工工程工作

Method: 应用机器学习特别是图像模式识别方法，使用卷积神经网络实现分析过程的高度自动化

Result: 实现了99.58%的人工资源时间减少，显著提高了停车服务的测试效率

Conclusion: 自动化分析工具成功替代了主要的人工工程工作，为未来发展和潜在应用提供了良好基础

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [5] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统分析了基于视觉语言模型(VLM)的零样本分布外(OOD)检测机制，揭示了VLM在语义新颖性利用方面的优势，同时发现了其对提示词措辞的高度敏感性这一关键脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉语言模型在零样本OOD检测方面表现出色，但研究界对其工作机制、相对于单模态方法的优势以及行为鲁棒性缺乏系统理解。

Method: 使用分布内(ID)和分布外(OOD)提示词进行系统性实证分析，包括：1)形式化VLM嵌入空间的关键操作属性；2)量化比较VLM与单模态方法的性能；3)评估模型对图像噪声和提示词措辞的敏感性。

Result: VLM在OOD检测方面显著优于单模态方法，主要优势在于能够利用丰富的语义新颖性；同时发现VLM对常见图像噪声具有鲁棒性，但对提示词措辞高度敏感。

Conclusion: 研究提供了对VLM-based OOD检测优势和关键脆弱性的结构化理解，为开发更鲁棒可靠的未来设计提供了实证指导。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [6] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 本文提出了一种基于截面曲率的几何分析方法，用于构建离散度量空间的曲率剖面，并以此评估数据表示效果和估计数据集的内在维度。


<details>
  <summary>Details</summary>
Motivation: 开发一种基于几何曲率概念的方法来分析离散度量空间，特别是为了评估数据表示（如降维技术）的有效性和估计数据集的内在维度。

Method: 利用新发展的截面曲率抽象概念，构建离散度量空间的曲率剖面，该方法捕捉点三元组与其他点之间的度量关系。

Result: 实验表明，这种基于曲率的分析可以用于估计数据集的内在维度，探索经验网络的大规模几何结构，并评估降维技术的有效性。

Conclusion: 基于截面曲率的几何剖面方法为分析离散度量空间提供了有效的工具，特别是在评估数据表示质量和维度估计方面具有实用价值。

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [7] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 本研究使用机器学习和遥感技术分析斐济Nadi地区2013-2024年的土地利用变化，重点关注城市化发展对土地覆盖的影响。


<details>
  <summary>Details</summary>
Motivation: 斐济作为发展中国家正经历快速城市化，需要技术手段来监测土地利用变化，为土地规划和管理提供支持。

Method: 使用Landsat-8卫星影像，结合Google Earth Engine平台，采用k-means聚类无监督学习和卷积神经网络进行土地覆盖分类和变化检测。

Result: 生成了土地覆盖变化可视化图，突出了城市区域随时间的变化情况，实现了对地图变化的有效监测。

Conclusion: 该研究为土地利用建模和变化检测提供了有效的技术框架，能够支持斐济城市化进程中的土地管理决策。

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [8] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 提出了一种用于电力传输系统实时异物入侵检测与跟踪的三阶段框架，结合YOLOv7分割、ConvNeXt特征提取和特征辅助IoU跟踪，支持边缘设备部署和增量学习


<details>
  <summary>Details</summary>
Motivation: 电力传输系统中异物入侵检测需要实时、准确且能在边缘设备上运行的解决方案，传统方法在遮挡和运动情况下跟踪效果不佳

Method: 三阶段框架：1) YOLOv7分割模型进行目标定位；2) ConvNeXt特征提取器配合三元组损失生成判别性嵌入；3) 特征辅助IoU跟踪器处理遮挡和运动跟踪

Result: 在真实监控和无人机视频数据集上表现出高准确性和鲁棒性，在NVIDIA Jetson设备上验证了实际边缘应用的可行性和可扩展性

Conclusion: 该框架为电力传输系统提供了有效的实时异物入侵检测解决方案，支持增量更新且无需重新训练模型，具有实际部署价值

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [9] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: 提出了EdiVal-Agent，一个自动化的多轮指令图像编辑评估框架，通过对象中心视角和专家工具套件实现细粒度评估，并构建了EdiVal-Bench基准测试


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑评估方法存在局限性：要么依赖配对的参考图像导致覆盖范围有限，要么仅使用零样本视觉语言模型评估不够精确

Method: 首先将图像分解为语义对象，然后合成多样化的上下文感知编辑指令。评估时结合VLM和开放词汇对象检测器评估指令遵循，使用语义级特征提取器评估内容一致性，利用人类偏好模型判断视觉质量

Result: 相比单独使用VLM和CLIP指标，结合VLM和对象检测器在指令遵循评估中与人类判断有更强的一致性。模块化设计支持未来工具的无缝集成

Conclusion: EdiVal-Agent能够识别现有编辑模型的失败模式，为下一代编辑模型的开发提供信息，其模块化设计确保了评估准确性的持续提升

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [10] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个统一的基于transformer的前馈模型，能够处理单张或多张图像以及可选几何输入，直接回归出度量3D场景几何和相机参数。


<details>
  <summary>Details</summary>
Motivation: 为了解决多种3D视觉任务需要专门模型的问题，研究者希望开发一个统一的模型来处理包括未标定运动恢复结构、多视角立体视觉、单目深度估计等多种任务。

Method: 使用基于transformer的前馈架构，输入图像和可选几何信息，通过分解的多视角场景几何表示（深度图、局部射线图、相机位姿和度量尺度因子）来回归3D几何。

Result: 实验表明MapAnything在多个3D视觉任务上表现优于或匹配专门的模型，同时提供更高效的联合训练能力。

Conclusion: 该模型为构建通用3D重建骨干网络奠定了基础，展示了统一模型在多样化3D视觉任务上的潜力。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [11] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 提出SCM-PR框架，通过结合RGB图像的语义信息来改进激光雷达地图中的跨模态地点识别，在复杂场景和视角变化下实现鲁棒定位。


<details>
  <summary>Details</summary>
Motivation: 解决现有RGB-VPR方法对光照、天气和季节变化敏感的问题，以及当前跨模态定位方法在复杂场景、细粒度匹配和视角变化下的性能不足。

Method: 使用VMamba骨干网络提取RGB特征；设计语义感知特征融合模块；构建包含语义和几何信息的激光雷达描述符；在NetVLAD中引入跨模态语义注意力机制；提出多视角语义几何匹配和语义一致性损失。

Result: 在KITTI和KITTI-360数据集上实现了最先进的性能，相比其他跨模态地点识别方法表现更优。

Conclusion: 通过有效整合语义信息，SCM-PR框架显著提升了跨模态地点识别的鲁棒性和准确性，特别是在复杂环境和视角变化条件下。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [12] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于场景自适应格点向量量化(SALVQ)的3D高斯泼溅压缩方法，替代传统的均匀标量量化，在保持低复杂度的同时显著提升率失真性能。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然渲染质量高且实时性好，但数据量巨大需要压缩。现有压缩方法都使用简单的均匀标量量化，作者探索是否能用更复杂的量化器来提升压缩性能。

Method: 使用格点向量量化(LVQ)替代均匀标量量化，并为每个场景优化格点基向量，实现场景自适应LVQ(SALVQ)。通过缩放格点基向量可以动态调整压缩率。

Result: SALVQ在保持低复杂度的同时显著提升了率失真性能，可以无缝集成到现有3DGS压缩架构中，且单个模型可支持多种压缩率目标。

Conclusion: 场景自适应格点向量量化是提升3D高斯泼溅压缩性能的有效方法，在最小化系统改动和计算开销的情况下实现了更好的压缩效果和灵活性。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [13] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 提出了MINGLE方法，通过三阶段流程检测图像中的社交群体区域，并发布了包含10万张街景图像的新数据集


<details>
  <summary>Details</summary>
Motivation: 理解公共场所的群体社交互动对城市规划至关重要，需要从图像中解读超越传统物体检测的复杂语义信号

Method: 三阶段模块化管道：1)现成的人体检测和深度估计，2)VLM推理分类成对社交关系，3)轻量级空间聚合算法定位社交连接群体

Result: 创建了包含10万张街景图像的新数据集，结合人工标注和MINGLE输出，确保语义丰富性和现实场景覆盖

Conclusion: MINGLE方法有效解决了社交群体区域检测任务，为未来研究提供了重要数据集和方法框架

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [14] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: BiasMap是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念级表征偏见，通过交叉注意力归因图揭示人口统计学与语义概念之间的结构纠缠，并提出基于能量引导扩散采样的偏见缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注输出层面的人口统计分布，无法保证偏见缓解后概念表示的解耦。需要更深入地揭示图像生成过程中的表征偏见。

Method: 利用交叉注意力归因图量化人口统计学与语义概念的空间纠缠（通过IoU指标），并采用能量引导扩散采样在去噪过程中直接修改潜在噪声空间以最小化SoftIoU期望值。

Result: 研究发现现有公平性干预措施可能减少输出分布差距，但往往无法解耦概念级耦合，而BiasMap的缓解方法能够有效减轻图像生成中的概念纠缠。

Conclusion: BiasMap提供了一个发现和缓解概念级表征偏见的新框架，能够补充分布偏见缓解，为生成模型的公平性评估和改善提供了更深入的视角。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [15] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePyxel是一个基于Python的实时图像标注工具，可直接连接成像设备进行实时标注，支持贝塞尔曲线和二进制掩码等专业标注功能


<details>
  <summary>Details</summary>
Motivation: 现有图像标注软件需要先上传预收集的数据集，无法支持实时数据采集和按需标注，这在实验室实时仪器数据采集场景中尤为不便

Method: 开发基于Python的图形用户界面，集成OpenCV和Numpy等高性能库，支持多种视频设备连接，提供类似商业图形软件的标注工具和非破坏性图层编辑

Result: 实现了实时图像标注功能，支持贝塞尔曲线、二进制掩码等专业标注工具，可与显微镜、网络摄像头等成像设备直接集成

Conclusion: LivePyxel解决了科学领域AI模型部署中的标注工具限制问题，为实验工作流程提供了无缝的数据收集和标注解决方案

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [16] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 本文提出DEFT-VTON方法，通过Doob's h变换高效微调和自适应一致性损失，在仅训练1.42%参数的情况下实现高质量虚拟试穿，推理步骤减少至15步。


<details>
  <summary>Details</summary>
Motivation: 现实应用中虚拟试穿(VTO)需要有限的训练和推理预算，而现有方法依赖大型预训练模型的端到端训练，计算成本高昂。

Method: 采用DEFT高效微调技术冻结预训练模型参数，仅训练小型h变换网络；提出自适应一致性损失结合去噪分数匹配损失，以数据自适应方式进行微调。

Result: DEFT-VTON在VTO任务上达到最先进性能，仅需15个去噪步骤，参数量仅为传统PEFT方法的1.42%（对比基准5.52%）。

Conclusion: 该方法在保持竞争力的同时显著降低了训练和推理成本，为实际部署提供了高效解决方案。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [17] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 提出了一种基于数据增强的合成数据生成方法，通过虚拟行人生成和光照条件对抗学习来改善自动驾驶中的行人识别性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要覆盖特定交通场景的合成数据，但合成数据与真实数据之间存在域差距问题，影响行人识别效果

Method: 开发了数据增强流水线，在Cityscapes数据集中添加虚拟行人；提出了新颖的生成对抗网络架构来学习数据集的光照条件，提高增强的真实性

Result: 在语义分割和实例分割任务上评估了该方法

Conclusion: 该方法能够有效生成自定义交通场景数据，改善行人识别性能，减少合成与真实数据之间的域差距

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [18] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出了FunKAN网络，一种专门为图像处理设计的可解释神经网络框架，在医学图像增强和分割任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法架构复杂且可解释性有限，而Kolmogorov-Arnold网络虽然可解释但会破坏图像的空间结构特征

Method: 基于函数空间推广Kolmogorov-Arnold表示定理，使用傅里叶分解和Hermite函数基学习内部函数，提出FunKAN用于图像增强和U-FunKAN用于分割

Result: 在IXI数据集上实现MRI吉布斯伪影抑制，在BUSI、GlaS、CVC-ClinicDB三个医学数据集上实现乳腺癌、腺体和息肉检测的分割任务，PSNR、TV、IoU、F1指标均优于其他KAN基模型

Conclusion: 该工作填补了理论函数逼近与医学图像分析之间的空白，为临床应用提供了鲁棒且可解释的解决方案

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [19] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态双流图神经网络模型，用于仇恨视频检测，通过实例图和权重图突出仇恨内容，在公开数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态分类方法通常忽视仇恨内容的关键性，对所有内容一视同仁，且无法系统捕捉视频中的结构化信息，限制了多模态融合效果。

Method: 构建实例图将视频分割为多个实例提取特征，通过互补权重图为这些特征分配重要性权重以突出仇恨实例，结合权重和特征生成视频标签。

Result: 在公开数据集上的大量实验表明，该模型在仇恨视频分类方面达到最先进水平，并具有很强的可解释性。

Conclusion: 提出的多模态双流图神经网络模型有效解决了现有方法的局限性，在仇恨视频检测任务中表现出色，具有实际应用价值。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [20] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一个基于扩散模型的深度估计方法，专门用于结肠镜检查视频，能够生成时间一致的深度图，在C3VD数据集上实现了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜三维场景理解面临重大挑战，现有深度估计模型在视频序列中缺乏时间一致性，限制了其在三维重建中的应用。

Method: 使用基于扩散的深度估计模型，从合成结肠镜序列学习稳健的几何先验来生成时间一致的深度图，并引入风格迁移技术将真实临床视频适配到合成训练域。

Result: 在C3VD数据集上实现了最先进的零样本性能，优于通用和结肠镜专用方法，展示了3D点云生成和表面覆盖评估等临床应用。

Conclusion: 虽然完整的轨迹三维重建仍然具有挑战性，但ColonCrafter在临床相关应用中表现出色，为结肠镜三维理解提供了有效的解决方案。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [21] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 本文针对嵌入式平台计算资源有限的问题，提出了基于体素空间几何相似性的3D高斯合并方法和Patch-Grid点采样初始化，在降低GPU内存使用的同时提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯溅射技术主要关注高性能桌面GPU，忽视了嵌入式平台（如微型飞行器）的计算资源限制。这些设备需要在系统性能和重建质量之间做出权衡。

Method: 1. 在SLAM中基于几何相似性在体素空间合并冗余的3D高斯基元，减少GPU内存使用；2. 通过Patch-Grid点采样初始化3D高斯基元，实现更精确的场景建模。

Result: 在公开数据集上的定量和定性评估证明了所提改进的有效性，在降低GPU内存使用的同时提升了渲染质量，且不影响系统运行时性能。

Conclusion: 该方法成功解决了嵌入式平台在3D高斯溅射技术应用中面临的内存限制问题，实现了内存使用优化和渲染质量提升的双重目标。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [22] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 提出了一种用于自动驾驶车辆轨迹预测的自适应OOD检测框架，通过显式建模预测误差模式，在检测延迟和误报率方面显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在部署时面临训练数据与现实条件之间的分布偏移问题，现有OOD检测研究主要关注计算机视觉任务，轨迹级别的OOD检测研究不足

Method: 基于快速变化检测(QCD)任务构建新框架，引入自适应机制，显式建模预测误差模式及其随时间演化的数据集特定动态

Result: 在多个真实世界数据集上的实验表明，该方法在检测延迟和误报率方面取得显著改进，在准确性和计算效率上均优于现有的UQ和基于视觉的OOD方法

Conclusion: 该框架为实现可靠、驾驶感知的自主性提供了一条实用路径，能够有效处理复杂驾驶环境中的分布偏移问题

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [23] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的方法，利用地球观测卫星图像对检测亚马逊雨林森林砍伐，并通过视觉语义模型自动生成相关标注


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林是重要生态系统，森林砍伐对全球碳排放和生物多样性有重大影响，需要有效的监测方法

Method: 使用深度学习技术比较不同时间点的卫星图像对，检测森林覆盖变化，并利用科学文献提取关键词构建视觉语义模型进行自动标注

Result: 在亚马逊图像对数据集上验证了方法在检测森林砍伐和生成相关标注方面的有效性

Conclusion: 该方法为监测和研究亚马逊森林砍伐影响提供了有用工具，虽然专注于环境应用，但具有通用性可应用于其他领域

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [24] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 基于Google Gemini 2.5 Flash的多模态医疗影像分析框架，整合视觉和语言处理技术，实现肿瘤检测和临床报告自动生成，支持CT、MRI、X光、超声等多种影像模态。


<details>
  <summary>Details</summary>
Motivation: 利用AI技术提升医疗影像诊断效率和准确性，解决传统诊断方法依赖专家经验、处理效率低的问题，通过多模态融合实现智能化的医疗影像分析。

Method: 采用Vision-Language Models (VLMs)技术，结合视觉特征提取和自然语言处理，集成坐标验证机制和概率高斯建模进行异常分布分析，使用多层可视化技术生成医学图解和统计表示。

Result: 在多模态异常检测中表现优异，位置测量平均偏差80像素，具备零样本学习能力减少对大数据集的依赖，用户友好的Gradio界面便于临床工作流集成。

Conclusion: 该框架显著提升了自动化诊断支持和放射工作流效率，但需要进行临床验证和多中心评估才能广泛推广应用。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [25] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法从2D定位扩展到3D定位和图像拼接的通用框架，通过聚类方法处理噪声和异常值，与RANSAC和霍夫变换相关，具有广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 将CLAP算法从2D定位扩展到更通用的3D定位和图像拼接领域，提供一种替代传统异常值剔除方法（如RANSAC）的聚类策略。

Method: 使用聚类方法来抑制噪声和错误特征匹配，通过将候选解分组并选择最一致的簇来定位，而不是像RANSAC那样通过重投影误差验证所有数据点。

Result: 成功将CLAP算法扩展到3D定位和图像拼接应用，证明了该方法在不同领域的适用性，并建立了CLAP与RANSAC、霍夫变换之间的关系。

Conclusion: CLAP的通用化框架可广泛应用于多个领域，是处理噪声和不确定性的有用工具，为各种定位和匹配问题提供了鲁棒的解决方案。

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [26] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR是一个利用Segment Anything Model (SAM)增强特征提取的医学图像配准框架，通过SAM的图像编码器提取结构感知特征嵌入，结合轻量级3D头部和分层特征一致性损失，在心脏和腹部CT图像配准任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像配准中变形与组织形态特征密切相关，但现有的弱监督方法需要分割掩码或地标等解剖先验信息，而这些弱标签往往不易获得，限制了实际应用。受视觉基础模型强大表示学习能力的启发，利用SAM的预训练特征来增强特征提取。

Method: 设计了任务特定的适配管道，使用SAM的图像编码器提取结构感知特征嵌入；设计了轻量级3D头部来细化嵌入空间中的特征以适应局部变形；引入了分层特征一致性损失来指导从粗到细的特征匹配。

Result: 在基准数据集上的广泛实验表明，SAMIR在心脏图像配准和腹部CT图像配准任务上显著优于最先进方法，在ACDC数据集上性能提升2.68%，在腹部数据集上提升6.44%。

Conclusion: SAMIR框架通过利用SAM的强大表示学习能力，有效解决了医学图像配准中特征提取的挑战，无需依赖难以获得的弱标签，在多个任务上取得了显著的性能提升。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [27] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 本文提出了一种基于联邦学习的分布式方法，用于从卫星图像中识别和定位森林砍伐，在保护数据隐私的同时实现多客户端协作训练。


<details>
  <summary>Details</summary>
Motivation: 准确识别卫星图像中的森林砍伐对于了解地理状况至关重要，但传统集中式训练方法需要合并数据，会损害客户端的数据安全和隐私。

Method: 使用联邦学习框架（FLOWER和RAY），结合YOLOS-small、Faster R-CNN with ResNet50和Faster R-CNN with MobileNetV3等模型，在分布式网络客户端上协作训练，每个客户端对应一个边缘卫星中心。

Result: 该方法能够在保护数据隐私的前提下，有效识别和定位森林砍伐，为卫星图像的图像分割任务提供了新的视角。

Conclusion: 联邦学习为卫星图像分析提供了一种既保护数据隐私又实现有效协作训练的可行方案，特别适用于需要多客户端参与的地理监测任务。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [28] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS是一个无需训练的两视图相对位姿估计框架，通过直接对齐两个独立重建的3D高斯混合模型来实现度量尺度的相机位姿估计，在Real-Estate10K数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统两视图位姿估计方法无法恢复度量尺度（相机平移只有尺度未知），且在宽基线和纹理贫乏区域表现不佳，需要一种能够实现度量尺度估计且对纹理不敏感的方法。

Method: 使用度量单目深度估计器和高斯场景重建器为每张图像构建度量3D高斯混合模型，然后通过优化可微分GMM对齐目标来细化初始位姿，该目标综合考虑几何结构、颜色、协方差和语义特征一致性。

Result: 在Real-Estate10K数据集上的大量实验表明，GARPS超越了经典方法和最先进的学习方法（包括MASt3R），实现了更好的性能。

Conclusion: 该方法展示了将单视图感知与多视图几何相结合来实现鲁棒度量相对位姿估计的潜力，无需显式2D对应关系即可处理遮挡和纹理贫乏区域。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [29] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 提出一种通用的查找表操作替代神经网络中的乘法运算，通过可微查找表实现端到端优化，在保持性能的同时显著提升能效和推理速度


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络中的乘法运算计算复杂度高、能耗大，阻碍了在移动设备上的部署。受资源受限设备使用查找表简化计算的启发，希望用查找操作替代乘法运算

Method: 设计可微的查找表操作，提出多种训练策略促进收敛，用查找操作替换权重和激活值之间的乘法运算

Result: 在图像分类、超分辨率和点云分类任务中，查找网络在能效和推理速度方面显著提升，同时保持与原始卷积网络相当的性能

Conclusion: 查找表操作是一种有效的神经网络基本操作，能够在不同任务和数据类型上实现高效部署，为边缘设备上的神经网络应用提供了可行方案

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [30] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 提出了一种基于语义超像素的视觉投影器，通过SAM生成语义超像素作为"视觉词汇"，将视觉token减少93%而不损失性能，显著加速MLLM训练和推理。


<details>
  <summary>Details</summary>
Motivation: 传统基于补丁的视觉投影器在减少视觉token数量和保持语义清晰度之间难以平衡，通常需要保留过长的token序列以避免性能下降，导致计算密集型问题。

Method: 利用SAM生成语义超像素来识别图像中的"视觉词汇"，通过压缩和投影语义超像素作为视觉token；提出语义超像素位置嵌入来增强MLLM对超像素几何和位置的感知，以及语义超像素聚合器来保留超像素内部细节和全局上下文。

Result: 实验表明该方法将视觉token减少93%而不影响性能，显著加快了MLLM的训练和推理速度，在Referring Image Segmentation任务上优于现有的压缩视觉投影器。

Conclusion: 基于语义超像素的视觉投影方法有效解决了视觉token冗余问题，在保持性能的同时大幅提升了效率，为MLLM在分割任务中的应用提供了更高效的解决方案。

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [31] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: FishBEV是一个专门针对鱼眼相机设计的BEV分割框架，通过三个创新模块解决鱼眼相机的几何畸变、多视角对应关系模糊和时间动态不稳定问题，在Synwoodscapes数据集上超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有BEV分割方法主要针对针孔相机设计，难以直接应用于存在严重几何畸变、多视角对应关系模糊和时间动态不稳定问题的鱼眼相机，导致BEV性能显著下降。

Method: 提出FishBEV框架，包含三个核心模块：1) 抗畸变多尺度提取(DRME)主干网络，在畸变下学习鲁棒特征并保持尺度一致性；2) 不确定性感知空间交叉注意力(U-SCA)机制，利用不确定性估计实现可靠的跨视角对齐；3) 距离感知时间自注意力(D-TSA)模块，自适应平衡近场细节和远场上下文以确保时间一致性。

Result: 在Synwoodscapes数据集上的大量实验表明，FishBEV在环视鱼眼BEV分割任务上持续优于现有最先进基线方法。

Conclusion: FishBEV通过专门针对鱼眼相机特性设计的三个互补创新模块，有效解决了鱼眼相机BEV分割中的关键挑战，为自动驾驶系统提供了更可靠的环视感知能力。

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [32] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: 该研究提出了三种基于样条的Kolmogorov-Arnold网络（KANs）变体，用于医疗图像分类，在有限数据集上实现了高精度和强泛化能力，同时大幅减少了参数数量。


<details>
  <summary>Details</summary>
Motivation: 解决医疗图像分类在资源有限临床环境中的挑战，特别是在数据集有限且多样化的情况下，需要开发准确、轻量且可解释的模型。

Method: 开发了三种基于样条的KAN模型：SBTAYLOR-KAN（B样条+泰勒级数）、SBRBF-KAN（B样条+径向基函数）、SBWAVELET-KAN（B样条+Morlet小波变换），利用样条基函数逼近来捕获局部和全局非线性特征。

Result: SBTAYLOR-KAN在多个医疗图像数据集上达到98.93%的准确率，仅使用2,872个可训练参数（相比ResNet50的24.18M），在仅使用30%训练数据时仍保持86%以上准确率，在类别不平衡的皮肤癌数据集上达到68.22%准确率。

Conclusion: 该框架为医疗图像分类提供了轻量级、可解释且泛化能力强的解决方案，特别适合数据稀缺的临床AI应用场景。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [33] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 本文提出StyleProtect方法，通过选择性更新交叉注意力层来有效防御针对艺术风格的恶意扩散模型模仿，保护艺术家的独特创作风格。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型特别是扩散模型的快速发展，恶意使用者可以廉价地复制艺术家的独特风格，这损害了艺术家的创作劳动和个人视觉表达，因此需要探索有效的艺术作品风格保护方法。

Method: 研究发现某些交叉注意力层对艺术风格特别敏感，基于此提出了StyleProtect方法，通过仅更新选定的交叉注意力层来实现轻量级的风格保护，该方法测量注意力层对风格和内容表示的激活强度及其与外部模型特征的相关性。

Result: 实验使用基于WikiArt精心策划的艺术作品数据集和Anita卡通动画数据集，包含30位具有独特影响力风格的艺术家作品，结果显示该方法在保护艺术作品和动漫独特风格方面表现优异，同时保持了良好的不可感知性。

Conclusion: StyleProtect提供了一种高效轻量的保护策略，能够有效防御经过微调的扩散模型对艺术风格的模仿，为保护艺术创作提供了可行的技术解决方案。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [34] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: UM-Depth是一个自监督单目深度估计框架，通过运动感知和不确定性感知的细化方法，在动态物体边界和纹理缺失区域提升深度估计精度，无需额外标签且在推理时无额外计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督单目深度估计方法在处理输入数据不确定性（如低纹理区域或动态区域）时面临挑战，导致深度精度下降。需要一种方法能够增强在光度信号较弱区域的监督，同时避免推理时的额外计算成本。

Method: 提出UM-Depth框架，采用师生训练策略，将不确定性估计嵌入训练流程和网络架构。使用光流仅在教师网络训练期间进行，无需额外标签且推理时无运行时成本。结合运动感知和不确定性感知的细化来提升深度准确性。

Result: 在KITTI和Cityscapes数据集上的广泛实验表明，该方法在不确定性感知细化方面具有有效性。在KITTI数据集上实现了自监督深度和姿态估计的最先进结果。

Conclusion: UM-Depth通过创新的师生训练策略和不确定性感知方法，成功解决了自监督深度估计中的不确定性问题，在保持实时性能的同时达到了state-of-the-art的精度。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [35] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: 本文提出Triple Query Former (TQF)方法，通过将参考查询分解为三个专门组件来解决Referring Video Object Segmentation中的查询选择偏差问题，并在多个基准测试中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于查询的RVOS方法使用静态文本查询进行跨模态对齐，但容易被外观或运动相似的干扰物误导，导致查询选择偏差问题。

Method: 提出TQF框架，将参考查询分解为三个专门组件：外观查询（处理静态属性）、帧内交互查询（处理空间关系）和帧间运动查询（处理时间关联）。查询通过整合语言线索和视觉指导动态构建，并引入两个运动感知聚合模块来增强对象token表示。

Result: 在多个RVOS基准测试上的广泛实验证明了TQF的优势以及结构化查询设计和运动感知聚合模块的有效性。

Conclusion: 通过将参考查询分解为三个专门化组件并引入运动感知聚合机制，TQF有效解决了查询选择偏差问题，在Referring Video Object Segmentation任务中取得了显著性能提升。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [36] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG是一个多任务通用视觉定位框架，首次同时处理GREC和GRES任务，通过实例查询统一实例级边界框和掩码的联合一致性预测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立处理GREC和GRES任务，忽视了联合训练的优势，且将GRES视为语义分割任务，忽略了实例感知能力的重要性以及实例级边界框和掩码预测一致性的必要性。

Method: 提出InstanceVG框架，利用实例查询统一实例级边界框和掩码的联合一致性预测，为每个实例查询分配先验参考点，促进同一实例的点、边界框和掩码的一致性预测。

Result: 在四个任务的十个数据集上进行广泛实验，InstanceVG在各项评估指标上显著超越现有方法，达到最先进的性能。

Conclusion: InstanceVG是第一个同时处理GREC和GRES任务并融入实例感知能力的通用视觉定位框架，通过实例查询实现多粒度一致性预测，取得了优异性能。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [37] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: FMFA框架通过显式细粒度对齐和自适应相似度分布匹配，解决了文本-图像行人检索中局部特征对齐验证不足和正负样本对处理不平衡的问题，在三个公开数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本-图像行人检索方法主要依赖注意力机制进行隐式跨模态局部对齐，但缺乏验证局部特征是否正确对齐的能力，且过度关注硬负样本而忽视错误匹配的正样本对。

Method: 提出FMFA框架，包含两个核心模块：1）自适应相似度分布匹配（A-SDM）模块，通过自适应拉近未匹配正样本对实现更精确的全局对齐；2）显式细粒度对齐（EFA）模块，通过稀疏化相似度矩阵和硬编码方法增强显式跨模态细粒度交互。

Result: 在三个公开数据集上进行评估，该方法在所有全局匹配方法中达到了最先进的性能。

Conclusion: FMFA框架通过全模式细粒度对齐，有效解决了跨模态对齐中的关键挑战，无需额外监督即可实现更好的文本-图像行人检索性能。

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [38] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 本文提出了一种颜色映射模块来解决文本驱动图像编辑中颜色控制精度不足的问题，通过建立文本嵌入空间与图像RGB值的对应关系，实现精确连续的颜色控制。


<details>
  <summary>Details</summary>
Motivation: 由于自然语言的模糊性和离散性，现有文本驱动图像编辑方法在颜色编辑方面存在精度不足和难以实现连续控制的问题，线性插值方法缺乏对颜色变化范围的精确控制。

Method: 引入颜色映射模块，显式建模文本嵌入空间与图像RGB值的对应关系，根据给定的RGB值预测对应的嵌入向量，从而在保持语义一致性的同时实现精确的颜色控制。

Result: 实验结果表明，该方法在颜色连续性和可控性方面表现良好，用户可以通过指定目标RGB范围生成具有所需范围内连续颜色变化的图像。

Conclusion: 所提出的颜色映射模块能够实现更细粒度、连续且可控的颜色编辑，有效解决了文本驱动图像编辑中的颜色控制精度问题。

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [39] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出基于视觉反馈的迭代提示词优化算法，使用视觉语言模型分析文本提示和生成图像，在保持用户意图的同时提高文本到图像生成的安全性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的安全方法只关注文本提示而忽略生成的图像，可能导致不安全输出或对安全提示的不必要修改

Method: 迭代提示词优化算法，利用视觉语言模型分析输入提示和生成图像，通过视觉反馈更有效地优化提示词

Result: 实验结果表明该方法在不损害用户意图对齐的情况下产生更安全的输出，安全性可与现有LLM方法相媲美

Conclusion: 该方法为生成更安全的文本到图像内容提供了实用解决方案，并引入了包含文本和视觉安全信号标注的新数据集

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [40] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出Task-Aware Image Signal Processing (TA-ISP)框架，通过轻量级多尺度调制算子替代传统密集卷积ISP网络，为预训练视觉模型生成任务导向的RGB表示，显著降低计算开销同时提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAW数据处理方法存在两个主要问题：大规模ISP网络计算开销大，基于传统ISP流水线调优的方法表示能力有限。需要一种既能保持高性能又适合资源受限设备的解决方案。

Method: 提出TA-ISP框架，预测一组轻量级多尺度调制算子（全局、区域、像素尺度），通过这些算子重塑不同空间范围的图像统计特征，实现分解式控制。

Result: 在多个RAW域检测和分割基准测试中（白天和夜间条件），TA-ISP持续提升下游任务准确率，同时显著减少参数数量和推理时间。

Conclusion: TA-ISP通过紧凑的RAW-to-RGB框架，在保持高性能的同时大幅降低计算资源需求，特别适合在资源受限设备上部署。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [41] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 提出NDLPNet网络解决夜间低光照条件下的图像去雨问题，通过位置感知模块捕捉雨条纹空间位置信息，在真实夜间场景数据集上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有图像去雨技术主要针对白天条件，在夜间光照下表现不佳，因为雨分布的空间异质性和光线依赖的条纹可见性影响

Method: 提出夜间去雨位置增强感知网络(NDLPNet)，包含位置感知模块(PPM)来捕获空间上下文信息，增强特征通道重要性识别和重新校准能力

Result: 在现有数据集和新建的NSR数据集(900对真实夜间场景图像)上的定性和定量实验表明，该方法在夜间去雨任务中优于最先进方法

Conclusion: NDLPNet能有效去除雨条纹同时保留关键背景信息，为夜间去雨任务研究提供了新的基准数据集和有效解决方案

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [42] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: VocSegMRI是一个多模态框架，通过跨注意力融合视频、音频和音韵输入来改善实时MRI中发音结构的分割精度，即使推理时缺少音频模态也能保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，但同步的声学和音韵信号能提供互补信息来丰富视觉信息并提高分割精度。

Method: 引入跨注意力融合机制整合视频、音频和音韵输入，并采用对比学习目标来增强跨模态表示，即使在推理时音频不可用也能保持性能。

Result: 在USC-75 rtMRI数据集子集上达到最先进性能：Dice分数0.95，95% Hausdorff距离4.20mm，优于单模态和多模态基线。

Conclusion: 消融研究证实了跨注意力和对比学习对分割精度和鲁棒性的贡献，突显了集成多模态建模在声道分析中的价值。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [43] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 提出基于扩散先验的生成式编码框架，在低码率下显著提升压缩性能和视觉保真度


<details>
  <summary>Details</summary>
Motivation: 随着生成技术的发展，视觉内容日益复杂（自然图像+AI生成图像），传统编解码器和学习方法难以在高压缩比下保持主观质量，现有生成方法存在视觉保真度和泛化性问题

Method: 使用预优化编码器生成广义压缩域表示，通过轻量级适配器和注意力融合模块与预训练模型内部特征集成，引入分布重归一化方法增强重建保真度

Result: 在低码率下视觉保真度优于现有方法，压缩性能比H.266/VVC提升高达79%，为AI生成内容提供高效解决方案且可适应更广泛内容类型

Conclusion: 该框架有效利用现有预训练扩散模型，能以最小重训练成本适应不同预训练模型，为低码率压缩提供了高效的生成式编码解决方案

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [44] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: AdaThinkDrive是一个新颖的视觉语言动作框架，采用双模式推理机制（快速回答和慢速思考），通过自适应选择是否使用思维链推理来平衡自动驾驶决策的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链推理技术在简单场景中表现不佳，引入不必要的计算开销而未能提升决策质量，需要一种能够自适应选择推理模式的方法。

Method: 提出双模式推理机制，预训练时使用问答和轨迹数据集获取世界知识和驾驶常识，监督微调时引入快速回答（无CoT）和慢速思考（有CoT）两种模式数据集，结合自适应思维奖励策略和组相对策略优化来奖励模型选择性应用CoT。

Result: 在Navsim基准测试中达到90.3的PDMS分数，比最佳纯视觉基线提升1.7分，比始终使用和不使用CoT的基线分别提升1.4和2.0分，推理时间减少14%。

Conclusion: AdaThinkDrive通过自适应推理机制有效平衡了准确性和效率，在自动驾驶任务中表现出色。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [45] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 提出了一种新的深度伪造检测方法，通过独立使用局部和全局视角预测篡改区域，并采用形态学操作融合输出，有效抑制噪声并提高空间一致性。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测虽然追求更高准确率，但对篡改区域的精确定位需求日益增长。现有方法往往忽视局部细节与全局语义上下文的互补性，且融合策略简单，容易放大噪声和错误。

Method: 独立使用局部和全局视角预测篡改区域，采用形态学操作融合两个分支的输出，以抑制噪声并增强空间连贯性。

Result: 大量实验证明了每个模块在提高伪造定位准确性和鲁棒性方面的有效性。

Conclusion: 该方法通过创新的局部-全局独立预测和形态学融合策略，显著提升了深度伪造区域定位的性能。

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [46] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 提出Variable-Rate Spatial Event Mamba架构，直接处理原始事件流，无需中间表示，通过自适应速率控制实现低延迟和高效率


<details>
  <summary>Details</summary>
Motivation: 现有方法需要预定义时间窗口引入窗口延迟，而逐点检测方法计算成本高难以实现实时效率，需要克服这些限制

Method: 使用轻量级因果空间邻域编码器捕获局部几何关系，然后采用基于Mamba的状态空间模型进行线性复杂度的可扩展时序建模

Result: 在推理时通过控制器根据事件速率自适应调整处理速度，实现窗口延迟和推理延迟之间的最优平衡

Conclusion: 该方法直接处理原始事件流，避免了中间表示的局限性，实现了高效且低延迟的事件相机数据处理

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [47] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: BWCache是一种无需训练的方法，通过动态缓存和重用DiT块特征来加速基于DiT的视频生成，在保持视觉质量的同时实现最高2.24倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT视频生成方法存在不可避免的延迟问题，限制了实际应用。现有加速方法要么因架构修改而牺牲视觉质量，要么无法在适当粒度上重用中间特征。

Method: 提出Block-Wise Caching (BWCache)方法，动态缓存和重用跨扩散时间步的DiT块特征，并引入相似性指示器来触发特征重用，仅在相邻时间步块特征差异低于阈值时进行重用。

Result: 在多个视频扩散模型上的广泛实验表明，BWCache实现了最高2.24倍的加速，同时保持可比的视觉质量。

Conclusion: BWCache通过有效利用DiT块特征的时间相似性，在不需要重新训练的情况下显著加速DiT-based视频生成，为实时应用提供了可行的解决方案。

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [48] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出了首个针对航天器姿态估计关键点回归的监督域适应框架，通过联合优化域不变表示和任务特定风险，显著减少域偏移下的泛化误差


<details>
  <summary>Details</summary>
Motivation: 解决航天器姿态估计中合成数据到真实数据的域适应问题，现有无监督方法在有少量标注目标数据时表现不佳

Method: 基于学习不变表示和风险(LIRR)范式，联合使用标注的合成数据和有限的标注真实数据，优化域不变表示和任务特定风险

Result: 在SPEED+基准测试中一致优于源域训练、微调和oracle基线，仅用5%标注目标数据就能达到或超过使用更多标注数据的oracle性能

Conclusion: 该框架轻量级、骨干网络无关且计算高效，为现实空间环境中鲁棒可部署的航天器姿态估计提供了实用途径

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [49] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 提出了一种基于语义加权自适应粒子滤波的无人机视觉定位方法，在GNSS拒止环境中实现了高效准确的4自由度位姿估计


<details>
  <summary>Details</summary>
Motivation: 解决现有检索式无人机定位方法在数据集可用性、实时性能、环境敏感性和泛化能力方面的局限性，特别是在动态或时变环境中

Method: 提出大规模多高度飞行段数据集(MAFS)和语义加权自适应粒子滤波(SWA-PF)方法，集成无人机图像和卫星图像的鲁棒语义特征，包含语义加权机制和优化的粒子滤波架构

Result: 相比特征提取方法获得10倍计算效率提升，全局定位误差保持在10米以下，能够在数秒内使用低分辨率卫星地图快速完成4自由度位姿估计

Conclusion: 该方法在GNSS拒止环境中实现了高效准确的无人机视觉定位，解决了现有方法的局限性，具有重要的实际应用价值

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [50] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 提出Masked Feature Modeling (MFM)作为语义分割无监督域适应的辅助任务，通过在特征空间进行掩码重建，与分割任务对齐且不增加推理计算开销


<details>
  <summary>Details</summary>
Motivation: 现有对比学习辅助任务在无监督域适应中已取得进展，但掩码建模方法因架构不兼容和优化目标不一致而未被充分探索

Method: 在特征空间进行特征掩码和重建，引入轻量级Rebuilder模块进行联合训练（推理时丢弃），利用分割解码器对重建特征进行分类

Result: 在各种架构和UDA基准测试中一致提升分割性能

Conclusion: MFM为无监督域适应语义分割提供了简单、高效且通用的策略

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [51] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 本文比较了MiniROCKET和1D-Justo-LiuNet在高光谱图像光谱分类中的性能，发现在训练数据有限的情况下MiniROCKET表现更优


<details>
  <summary>Details</summary>
Motivation: 虽然1D-Justo-LiuNet是目前光谱分类的最先进模型，但在训练数据有限时性能会下降，需要寻找更稳健的替代方案

Method: 研究使用MiniROCKET和HDC-MiniROCKET进行光谱分类，这些模型在特征提取部分没有可训练参数，对有限训练数据更具鲁棒性

Result: MiniROCKET在有限数据场景下优于1D-Justo-LiuNet，在一般情况下性能相当，尽管参数更多

Conclusion: MiniROCKET是光谱分类中处理有限训练数据问题的有效解决方案，为未来空间-光谱方法提供了改进基础

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [52] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: Semi-MOE是首个用于半监督组织病理学图像分割的多任务混合专家框架，通过三个专家网络和动态伪标签机制，在低标签设置下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有半监督学习方法在组织病理学图像分割中因腺体边界模糊和形态学误分类导致的噪声伪标签问题。

Method: 采用三个专家网络：主分割专家、符号距离场回归专家和边界预测专家，结合多门控伪标签模块和自适应多目标损失函数。

Result: 在GlaS和CRAG基准测试中，该方法在低标签设置下超越了最先进的方法。

Conclusion: 基于MoE的架构在推进半监督分割方面具有巨大潜力，为组织病理学图像分析提供了有效的解决方案。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [53] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 本文提出VHBench-10基准测试和VisionWeaver方法，通过多专家动态路由机制有效减少大型视觉语言模型中的物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型中的物体幻觉严重阻碍其实际应用，不同视觉编码器的训练范式差异导致不同的归纳偏置和幻觉表现，现有基准测试无法捕捉细粒度的幻觉类别。

Method: 提出VHBench-10基准测试（约10,000样本，10个细粒度幻觉类别），并设计VisionWeaver - 基于上下文感知路由网络，利用全局视觉特征生成路由信号，动态聚合多个专业专家的视觉特征。

Result: 评估确认不同编码器具有独特的幻觉特征，VisionWeaver在显著减少幻觉和提高整体模型性能方面表现出有效性。

Conclusion: 视觉编码器的选择对模型幻觉表现至关重要，提出的VisionWeaver方法通过动态特征聚合机制有效缓解了物体幻觉问题，为LVLMs的实际应用提供了重要改进。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [54] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 本文挑战了表示学习中视图间不相关性假设，提出显式对齐不同视图表示的方法，在自监督学习中实现了下游任务性能提升


<details>
  <summary>Details</summary>
Motivation: 现有表示学习方法隐含假设数据点的不相关视图足以学习有意义的表示，但作者发现潜在空间的有意义结构不会自然出现，需要显式诱导

Method: 提出一致视图对齐方法，将数据不同视图的表示对齐以整合互补信息，同时避免产生假阳性

Result: 在MICCAI 2025 SSL3D挑战赛中，使用Primus视觉transformer和ResEnc卷积神经网络分别获得第一和第二名

Conclusion: 结构化视图对齐在学习有效表示中起着关键作用，显式对齐方法能显著提升下游任务性能

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [55] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecDiff是一种训练自由的多级特征缓存策略，通过自推测引入未来信息，结合历史信息实现动态特征选择和分类，在Stable Diffusion等模型上实现2.7-3.2倍加速且质量损失可忽略


<details>
  <summary>Details</summary>
Motivation: 现有特征缓存方法仅依赖历史信息，导致精度和速度性能受限。需要引入未来信息来突破速度-精度权衡的瓶颈

Method: 提出自推测范式，利用不同迭代次数下相同时步的信息相似性引入未来信息。包含基于自推测信息的缓存特征选择算法和基于特征重要性分数的多级特征分类算法

Result: 在Stable Diffusion 3、3.5和FLUX上分别实现平均2.80倍、2.74倍和3.17倍加速，质量损失可忽略，超越了RFlow方法

Conclusion: 通过融合推测信息和历史信息，SpecDiff突破了速度-精度权衡的瓶颈，推动了高效扩散模型推理中速度和精度的帕累托前沿

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [56] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA是一种知识蒸馏方法，通过对象级别的跨架构对齐，将大型视觉-语言教师模型的多模态语义知识转移到轻量级视觉目标检测学生模型中，在少样本个性化检测任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注密集或全局对齐，缺乏对象级别的语义知识转移。需要一种能够在不需要修改教师模型或推理时文本输入的情况下，高效传递多模态语义的方法。

Method: 使用翻译模块将学生特征映射到联合空间，通过双目标损失函数（局部对齐和全局关系一致性）指导学生和翻译器的训练，实现对象级别的跨架构知识蒸馏。

Result: 在四个个性化检测基准测试中，平均得分提升+10.1，性能达到与大型多模态模型相当的水平，证明了其在实际部署中的适用性。

Conclusion: MOCHA通过对象级别的知识蒸馏，成功实现了从多模态教师到单模态学生的高效语义转移，为轻量级目标检测模型的性能提升提供了有效解决方案。

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [57] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: EDITS是一个新颖的数据集蒸馏框架，通过利用图像中的隐式文本语义信息，结合视觉语言模型和大型语言模型，生成更高质量的合成数据集。


<details>
  <summary>Details</summary>
Motivation: 传统的数据集蒸馏技术主要捕捉低级视觉特征，忽略了图像中的高级语义和结构信息，导致蒸馏效果有限。

Method: 首先通过视觉语言模型生成外部文本并与图像特征融合，形成先验聚类缓冲区；然后通过局部语义感知选择代表性样本构建图像和文本原型；最后通过双原型指导策略使用扩散模型生成最终合成数据集。

Result: 大量实验证实了该方法的有效性，在保持竞争力的模型性能的同时实现了高效学习。

Conclusion: EDITS框架通过整合文本语义信息，显著提升了数据集蒸馏的质量和效果，为高效机器学习提供了新的解决方案。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [58] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: LamiGauss是一种结合高斯泼溅辐射光栅化和专用探测器到世界变换模型的X射线层析成像重建算法，能够在极稀疏视图条件下实现高质量重建，仅需3%的完整视图即可超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统CT在板状结构（如微芯片和复合电池材料）的非破坏性检测中存在几何约束问题，而现有层析成像方法在稀疏视图条件下重建质量较差，需要解决这一技术挑战。

Method: 提出LamiGauss算法，结合高斯泼溅辐射光栅化和包含层析倾斜角的专用探测器到世界变换模型，采用初始化策略过滤常见层析伪影，防止高斯分布分配到虚假结构上。

Result: 在合成和真实数据集上的广泛实验表明，该方法仅使用3%的完整视图就能实现优于在完整数据集上优化的迭代方法的性能，实现了准确高效的重建。

Conclusion: LamiGauss通过创新的高斯泼溅方法和伪影过滤策略，有效解决了稀疏视图层析成像重建的难题，为板状结构的非破坏性检测提供了高效解决方案。

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [59] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: 提出了DAM4SAM，一个针对SAM2的干扰物感知内存模块和自省管理方法，有效减少跟踪漂移并提升遮挡后重检测能力，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于内存的视频分割方法（如SAM2）在分割任务中表现优异，但在视觉目标跟踪中面对视觉相似干扰物时存在挑战，需要专门针对干扰物问题的解决方案。

Method: 提出了干扰物感知的即插即用内存模块和基于自省的管理方法，构建了DiDi干扰物蒸馏数据集用于分析，并将该模块集成到不同跟踪器架构中。

Result: 在13个基准测试中超越SAM2.1，在10个测试中达到新的SOTA；集成到实时跟踪器EfficientTAM中提升11%性能，与EdgeTAM集成提升4%性能，显示出良好的架构泛化能力。

Conclusion: DAM4SAM模块有效解决了视觉目标跟踪中的干扰物问题，显著提升了跟踪性能，并且具有良好的通用性和可移植性，可以集成到不同的跟踪器架构中。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [60] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet是一个双流注意力网络，通过融合原始骨盆X光片和分割骨图像来提高骨折分类性能，在可见和不可见骨折检测中均表现出色


<details>
  <summary>Details</summary>
Motivation: 骨盆骨折在标准X光片中常常难以诊断，特别是当骨折迹象细微或不可见时，需要开发更准确的检测方法

Method: 采用双流注意力网络结构，使用融合注意力块(FABlocks)迭代交换和精炼来自原始X光片和分割骨图像的特征，通过两阶段分割引导的管道进行训练

Result: 在AMERI数据集上，可见骨折检测准确率达到88.68%，AUC为0.9334；对未训练的不可见骨折案例也达到82.29%准确率和0.8688 AUC

Conclusion: 基于解剖学感知的双输入架构在骨折检测方面具有显著临床潜力，特别是在放射学表现细微的情况下表现出强大的鲁棒性

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [61] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: EvHand-FPV是一个轻量级的事件相机第一人称视角3D手部追踪框架，通过手腕ROI定位、端到端映射和多任务学习策略，在保持高精度的同时大幅降低了计算量和参数数量


<details>
  <summary>Details</summary>
Motivation: 传统帧式方法在精度、延迟和能效方面难以满足XR设备等资源受限场景的需求，事件相机具有微秒级时间分辨率和毫瓦级功耗的优势，但缺乏第一人称视角的基准数据集

Method: 构建事件相机FPV数据集（合成3D标签+真实2D标签），引入手腕ROI几何定位，端到端映射嵌入ROI偏移减少计算，多任务学习辅助几何特征头提升表示能力

Result: 在真实FPV测试集上2D-AUCp从0.77提升到0.85，参数减少89%（11.2M→1.2M），FLOPs减少89%（1.648G→0.185G），合成数据上3D-AUCp达到0.84

Conclusion: EvHand-FPV实现了准确高效的第一人称视角事件手部追踪，适用于设备端XR应用，证明了事件相机在手部追踪任务中的巨大潜力

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [62] [Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions](https://arxiv.org/abs/2509.14165)
*Michal Szczepanski,Martyna Poreba,Karim Haroun*

Main category: cs.CV

TL;DR: STEP是一个结合动态补丁合并和token剪枝的混合框架，通过dCTS策略网络和早期退出机制，显著降低Vision Transformer的计算和内存成本，在保持精度的同时实现最高4倍计算复杂度降低和1.7倍推理速度提升。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义分割中表现出色，但面临高计算和内存成本的挑战，需要一种高效的方法来减少token数量而不显著影响精度。

Method: 提出STEP框架，包含：1）dCTS轻量级CNN策略网络实现灵活的超补丁合并；2）编码器块集成早期退出机制，移除高置信度的超token；3）结合动态补丁合并和token剪枝技术。

Result: 在1024x1024高分辨率图像上测试：单独使用dCTS可减少2.5倍token数量，降低2.6倍计算成本，提升3.4倍吞吐量；完整STEP框架可达4倍计算复杂度降低和1.7倍推理速度提升，精度损失不超过2.0%，40%的token可在最终编码层前提前终止。

Conclusion: STEP框架有效解决了ViT在语义分割中的效率问题，通过创新的token减少策略实现了计算效率和精度的良好平衡，为高分辨率图像处理提供了实用解决方案。

Abstract: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.

</details>


### [63] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 提出WARM模块，通过白化和染色变换解决可学习原型标记与支持特征之间的分布差异问题，在少样本3D点云分割任务中取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有少样本3D点云分割方法使用传统算法构建原型，但初始随机性严重影响性能，且原型生成过程研究不足。注意力机制有潜力但存在分布差异问题

Method: 提出White Aggregation and Restoration Module (WARM)，在白化和染色变换之间插入交叉注意力，先通过白化对齐支持特征与原型标记，注意力处理后通过染色恢复原始分布

Result: 在多个少样本3D点云分割基准测试中取得显著优势的state-of-the-art性能

Conclusion: WARM模块通过简单有效的设计实现鲁棒的注意力机制，能够捕捉支持特征间的语义关系生成代表性原型

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [64] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 提出SRC框架，通过迭代校准理性与答案的对齐，提升大视觉语言模型的推理一致性和准确性


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在视觉问答中表现出色，但存在理性推理与生成答案不一致的问题，导致错误响应

Method: 采用轻量级"理性微调"修改响应格式，使用R-Scorer评分模型评估候选响应质量，通过置信度加权偏好选择进行偏好微调

Result: 在多个基准测试中显著提升了模型的感知、推理和泛化能力

Conclusion: 强调理性导向的对齐在挖掘大视觉语言模型潜力中的重要性

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [65] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 提出了AntiPure方法，通过在图像中注入不可见的对抗性噪声来抵抗净化过程，保护图像免受恶意伪造和版权侵犯。


<details>
  <summary>Details</summary>
Motivation: 扩散模型如Stable Diffusion的强大定制能力带来了严重的安全风险，包括深度伪造和版权侵权。现有的保护性扰动方法容易被净化技术移除，导致图像再次面临恶意伪造的风险。

Method: 提出了AntiPure方法，采用两种引导机制：1）块状频率引导，减少模型对净化图像高频分量的影响；2）错误时间步引导，扰乱模型在不同时间步的去噪策略。通过额外引导嵌入不可见的扰动，使其在代表性净化设置下持续存在。

Result: 实验表明，AntiPure在净化-定制工作流中实现了最小的感知差异和最大的失真效果，优于其他保护性扰动方法。

Conclusion: AntiPure作为一种净化压力测试方法，能够有效抵抗净化过程，为图像安全保护提供了新的解决方案。

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [66] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 提出了Dense Video Understanding (DVU)框架和Gated Residual Tokenization (GRT)方法，通过运动补偿和语义场景融合来高效处理高帧率视频，解决了现有VLLMs在密集时间信息理解上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型(VLLMs)和基准测试主要依赖低帧率采样，丢弃了密集的时间信息，无法处理需要精确时间对齐的任务（如讲座理解）。高帧率处理面临计算冗余和token线性增长的挑战。

Method: 提出了Gated Residual Tokenization (GRT)两阶段框架：1) 运动补偿门控tokenization利用像素级运动估计跳过静态区域；2) 语义场景内tokenization合并融合静态区域内的token，在保留动态语义的同时减少冗余。

Result: 在DIVE基准测试上的实验表明，GRT优于更大的VLLM基线模型，并且随着帧率的增加表现更好，证明了密集时间信息的重要性。

Conclusion: GRT能够实现高效、可扩展的高帧率视频理解，解决了现有方法在密集时间推理任务上的局限性，为视频理解提供了新的解决方案。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [67] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 提出了Noise Level Guidance (NLG)方法，通过优化初始噪声来提高扩散模型生成质量和提示遵循度，无需额外数据、网络或反向传播


<details>
  <summary>Details</summary>
Motivation: 扩散模型使用随机高斯噪声作为起点会影响最终输出质量和提示遵循度，现有噪声优化方法需要额外数据集、网络或优化过程，实用性受限

Method: NLG方法通过增加初始噪声与通用指导对齐的可能性来细化噪声，提供统一框架适用于条件和无条件扩散模型，支持各种扩散级指导形式

Result: 在五个标准基准测试上的实验表明，该方法提高了输出生成质量和输入条件遵循度，同时保持计算效率

Conclusion: NLG作为一种实用且可扩展的扩散模型增强方法，能够与现有指导方法无缝集成

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [68] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: PairTally是一个专门评估细粒度视觉计数能力的基准数据集，包含681张高分辨率图像，每张图像包含两个物体类别，要求模型基于形状、大小、颜色或语义的细微差异进行区分和计数。


<details>
  <summary>Details</summary>
Motivation: 当前视觉计数模型在复杂场景中对特定类型物体的细粒度、意图驱动的计数能力尚不明确，需要专门的评估基准来诊断和改进现有模型。

Method: 构建PairTally数据集，包含681张高分辨率图像，每张图像有两个物体类别（包括类别间和类别内设置），对多种最先进模型进行基准测试，包括基于示例的方法、语言提示模型和大规模视觉语言模型。

Result: 尽管最近有所进展，但当前模型在可靠地计数用户意图方面仍然困难，特别是在细粒度和视觉模糊的情况下。

Conclusion: PairTally为诊断和改进细粒度视觉计数系统提供了新的基础，揭示了当前模型在精细计数任务中的局限性。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [69] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 提出增强版YOLO-FEDER FusionNet无人机检测框架，通过融合通用目标检测和伪装目标检测技术，在复杂视觉环境中显著提升检测性能


<details>
  <summary>Details</summary>
Motivation: 解决无人机在复杂视觉环境中检测困难的问题，包括背景杂乱、目标尺度小和伪装效应等挑战，传统检测器在低目标-背景可分离性的杂乱环境中性能下降

Method: 在原始架构基础上系统改进训练数据组成、特征融合策略和骨干网络设计。使用大规模照片级合成数据配合少量真实样本增强鲁棒性，系统评估多尺度FEDER特征贡献，并在多种YOLO骨干配置上进行基准测试

Result: 最佳配置（YOLOv8l骨干+DWD模块FEDER特征）相比初始基线，在IoU阈值为0.5时，FNR降低达39.1个百分点，mAP提升达62.8个百分点

Conclusion: 集成中间FEDER特征与骨干网络升级相结合能带来显著性能改进，为复杂视觉环境中的无人机检测提供了有效解决方案

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [70] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2是一个开源的2B和8B参数规模视觉语言基础模型，在106个数据集上表现优异，在MMMU和MathVista等推理基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 开发一个全面的多模态理解和推理基础模型，作为SAIL-VL的继任者，为开源多模态社区提供高效可扩展的基础。

Method: 采用大规模数据筛选管道、渐进式训练框架（从预训练视觉编码器到多模态预训练，再到思维融合SFT-RL混合范式）以及稀疏混合专家（MoE）架构设计。

Result: 在2B和8B参数规模下实现最先进性能，在OpenCompass排行榜中2B版本在4B参数规模以下开源模型中排名第一。

Conclusion: SAIL-VL2通过三项核心创新实现了强大的多模态理解和推理能力，为开源社区提供了高效可扩展的视觉语言基础模型。

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [71] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: 提出PROFUSEme方法，通过融合临床、影像和病理多模态数据来早期预测前列腺癌根治术后的生化复发，性能优于传统方法


<details>
  <summary>Details</summary>
Motivation: 约30%前列腺癌患者在根治性前列腺切除术后会出现生化复发，早期准确预测有助于临床决策和改善患者预后

Method: 采用中间融合配置结合Cox比例风险回归器，学习临床、影像和病理数据的跨模态交互

Result: 在内部5折嵌套交叉验证中平均C-index为0.861，在CHIMERA 2025挑战验证排行榜上C-index为0.7103，性能优于后期融合配置

Conclusion: PROFUSEme方法通过多模态数据融合有效提升了前列腺癌生化复发的早期预测准确性

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [72] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate是一个统一的角色动画和替换框架，能够根据参考视频精确复制角色的表情和动作来生成高质量角色视频，或将动画角色无缝集成到参考视频中替换原始角色。


<details>
  <summary>Details</summary>
Motivation: 为了解决角色动画和替换任务中需要高保真度复制表情动作、实现环境光照无缝集成的问题，开发一个统一的框架来处理这些相关但不同的任务。

Method: 基于Wan模型构建，采用改进的输入范式区分参考条件和生成区域，使用空间对齐的骨架信号复制身体运动，从源图像提取隐式面部特征重现表情，并开发辅助的Relighting LoRA模块来增强环境集成效果。

Result: 实验结果表明Wan-Animate达到了最先进的性能水平，能够生成具有高可控性和表现力的角色视频。

Conclusion: 该框架成功统一了多个角色动画任务，实现了高质量的角色动画生成和环境无缝集成，作者承诺将开源模型权重和源代码。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [73] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 提出VSE-MOT框架，通过视觉语义增强技术解决低质量视频中的多目标跟踪问题，在真实低质量场景中性能提升8-20%


<details>
  <summary>Details</summary>
Motivation: 当前多目标跟踪算法在低质量视频中性能显著下降，需要提升在真实世界低质量视频场景中的应用能力

Method: 设计三分支架构，利用视觉语言模型提取全局视觉语义信息并与查询向量融合；引入MOT-Adapter适配多目标跟踪任务，VSFM模块提升特征融合效果

Result: 在真实低质量视频场景中，跟踪性能指标比现有方法提升约8%到20%，同时在常规场景中保持稳健性能

Conclusion: VSE-MOT框架有效解决了低质量视频中的多目标跟踪挑战，为真实世界应用提供了有力解决方案

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


### [74] [AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration](https://arxiv.org/abs/2509.14084)
*Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao*

Main category: cs.CV

TL;DR: AD-DINOv3是一个新颖的零样本异常检测框架，通过结合DINOv3视觉编码器和CLIP文本编码器，使用轻量级适配器和异常感知校准模块来解决领域偏差和全局语义偏差问题，在工业和医疗基准测试中达到或超越最先进方法。


<details>
  <summary>Details</summary>
Motivation: 传统零样本异常检测主要基于CLIP模型，而新兴的视觉基础模型DINOv3具有强大的可迁移表示能力。但直接将DINOv3应用于异常检测面临两个关键挑战：大规模预训练数据与异常检测任务之间的领域偏差导致特征不对齐，以及预训练表示对全局语义的固有偏差导致细微异常被误判为正常前景对象。

Method: 提出AD-DINOv3多模态框架，将异常检测构建为多模态对比学习问题。使用DINOv3作为视觉骨干提取patch token和CLS token，CLIP文本编码器提供正常和异常提示的嵌入。引入轻量级适配器桥接领域差距，并设计异常感知校准模块(AACM)显式引导CLS token关注异常区域而非通用前景语义。

Result: 在八个工业和医疗基准测试上的广泛实验表明，AD-DINOv3始终匹配或超越最先进的零样本异常检测方法，验证了其作为通用框架的优越性。

Conclusion: AD-DINOv3成功解决了DINOv3在零样本异常检测中的适应挑战，通过多模态对比学习和专门设计的校准模块，实现了优异的检测性能，为零样本异常检测提供了新的有效解决方案。

Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.

</details>


### [75] [Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing](https://arxiv.org/abs/2509.14097)
*Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 提出EMA引导的伪监督框架和类感知跨模态一致性损失，在弱监督音频-视觉视频解析任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决现有方法忽视稳定片段级监督和类感知跨模态对齐的问题，通过提供可靠的时序指导和跨模态一致性来改进弱监督AVVP任务

Method: 1) EMA引导的伪监督框架：通过自适应阈值或top-k选择生成可靠的片段级掩码；2) 类感知跨模态一致性(CMA)损失：在可靠的片段-类别对上对齐音频和视觉嵌入

Result: 在LLP和UnAV-100数据集上的评估显示，该方法在多个指标上达到了最先进的性能

Conclusion: 所提出的EMA伪监督和CMA损失策略有效解决了弱监督AVVP中的时序监督和跨模态对齐问题，取得了优异的性能表现

Abstract: Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.

</details>


### [76] [CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts](https://arxiv.org/abs/2509.14104)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: 提出了一种通过集成软混合专家（Soft MoE）机制来提升遥感基础模型效率的方法，在保持或提升表征性能的同时显著降低计算需求


<details>
  <summary>Details</summary>
Motivation: 现有遥感基础模型存在计算复杂度高或表征能力有限的问题，限制了实际应用，需要开发更高效的模型

Method: 将软混合专家机制集成到跨传感器掩码自编码器（CSMAE）中，形成CSMoE模型，并采用主题-气候描述符驱动的采样策略构建训练集

Result: CSMoE在场景分类、语义分割和图像检索任务中实现了超过现有方法两倍的计算效率，同时保持竞争性性能

Conclusion: 所提出的软混合专家集成方法能有效创建计算高效的遥感基础模型，在表征能力、准确性和计算效率之间实现了优越的平衡

Abstract: Self-supervised learning through masked autoencoders has attracted great
attention for remote sensing (RS) foundation model (FM) development, enabling
improved representation learning across diverse sensors and downstream tasks.
However, existing RS FMs often either suffer from substantial computational
complexity during both training and inference or exhibit limited
representational capacity. These issues restrict their practical applicability
in RS. To address this limitation, we propose an adaptation for enhancing the
efficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism
into the FM. The integration of Soft MoEs into the FM allows modality-specific
expert specialization alongside shared cross-sensor representation learning. To
demonstrate the effectiveness of our adaptation, we apply it on the
Cross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor
Mixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic
descriptor-driven sampling strategy for the construction of a representative
and diverse training set to train our CSMoE model. Extensive experiments on
scene classification, semantic segmentation, and content-based image retrieval
demonstrate that our adaptation yields a reduction in computational
requirements while maintaining or improving representational performance.
Compared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off
between representational capacity, accuracy, and computational efficiency. On
average, CSMoE achieves more than twice the computational efficiency of
existing RS FMs, while maintaining competitive performance across all
experiments. These results show the effectiveness of the proposed adaptation
for creating computationally efficient RS FMs. The code for the model, the
training set creation, and the model weights will be available at
https://git.tu-berlin.de/rsim/csmoe.

</details>


### [77] [Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows](https://arxiv.org/abs/2509.14119)
*Jiabo MA,Wenqiang Li,Jinbang Li,Ziyi Liu,Linshan Wu,Fengtao Zhou,Li Liang,Ronald Cheong Kin Chan,Terence T. W. Wong,Hao Chen*

Main category: cs.CV

TL;DR: 提出了一种具有级联配准机制的鲁棒虚拟染色框架，解决了生成输出与真实标签之间的空间不匹配问题，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统组织病理学诊断需要多种化学染色，过程耗时、劳动密集且对环境有害。现有虚拟染色方法依赖对齐良好的配对数据，但获取这种数据困难，因为化学染色过程会导致组织变形，且单个组织切片无法进行多次染色。

Method: 提出了一个具有级联配准机制的鲁棒虚拟染色框架，通过多级配准来解决生成输出与真实标签之间的空间不匹配问题。

Result: 在五个数据集上显著优于最先进模型，内部数据集平均提升3.2%，外部数据集平均提升10.1%。在严重不对齐的数据集上，PSNR比基线模型提升23.8%。

Conclusion: 该方法在多样化数据集上表现出卓越的鲁棒性，简化了虚拟染色的数据采集过程，并为推进其发展提供了新思路。

Abstract: Accurate histopathological diagnosis often requires multiple differently
stained tissue sections, a process that is time-consuming, labor-intensive, and
environmentally taxing due to the use of multiple chemical stains. Recently,
virtual staining has emerged as a promising alternative that is faster,
tissue-conserving, and environmentally friendly. However, existing virtual
staining methods face significant challenges in clinical applications,
primarily due to their reliance on well-aligned paired data. Obtaining such
data is inherently difficult because chemical staining processes can distort
tissue structures, and a single tissue section cannot undergo multiple staining
procedures without damage or loss of information. As a result, most available
virtual staining datasets are either unpaired or roughly paired, making it
difficult for existing methods to achieve accurate pixel-level supervision. To
address this challenge, we propose a robust virtual staining framework
featuring cascaded registration mechanisms to resolve spatial mismatches
between generated outputs and their corresponding ground truth. Experimental
results demonstrate that our method significantly outperforms state-of-the-art
models across five datasets, achieving an average improvement of 3.2% on
internal datasets and 10.1% on external datasets. Moreover, in datasets with
substantial misalignment, our approach achieves a remarkable 23.8% improvement
in peak signal-to-noise ratio compared to baseline models. The exceptional
robustness of the proposed method across diverse datasets simplifies the data
acquisition process for virtual staining and offers new insights for advancing
its development.

</details>


### [78] [Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection](https://arxiv.org/abs/2509.14120)
*Sara Concas,Simone Maurizio La Cava,Andrea Panzino,Ester Masala,Giulia Orrù,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 美颜滤镜会影响深度伪造和变形攻击检测器的性能，导致检测准确率下降


<details>
  <summary>Details</summary>
Motivation: 社交媒体美颜滤镜的普及对自动化人脸分析的可靠性构成挑战，特别是在区分真实和伪造面部数据方面，需要研究这些滤镜对深度伪造和变形攻击检测器的影响

Method: 对多个最先进的检测器在基准数据集上进行综合评估，比较应用各种平滑滤镜前后的性能表现

Result: 研究发现美颜滤镜会导致检测器性能下降，揭示了面部增强带来的脆弱性

Conclusion: 需要开发能够抵抗此类美颜滤镜干扰的鲁棒检测模型

Abstract: Digital beautification through social media filters has become increasingly
popular, raising concerns about the reliability of facial images and videos and
the effectiveness of automated face analysis. This issue is particularly
critical for digital manipulation detectors, systems aiming at distinguishing
between genuine and manipulated data, especially in cases involving deepfakes
and morphing attacks designed to deceive humans and automated facial
recognition. This study examines whether beauty filters impact the performance
of deepfake and morphing attack detectors. We perform a comprehensive analysis,
evaluating multiple state-of-the-art detectors on benchmark datasets before and
after applying various smoothing filters. Our findings reveal performance
degradation, highlighting vulnerabilities introduced by facial enhancements and
underscoring the need for robust detection models resilient to such
alterations.

</details>


### [79] [MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook](https://arxiv.org/abs/2509.14142)
*Peng Xu,Shengwu Xiong,Jiajun Zhang,Yaxiong Chen,Bowen Zhou,Chen Change Loy,David A. Clifton,Kyoung Mu Lee,Luc Van Gool,Ruiming He,Ruilin Yao,Xinwei Long,Jirui Huang,Kai Tian,Sa Yang,Yihua Shao,Jin Feng,Yue Zhong,Jiakai Zhou,Cheng Tang,Tianyu Zou,Yifang Zhang,Junming Liang,Guoyou Li,Zhaoxiang Wang,Qiang Zhou,Yichen Zhao,Shili Xiong,Hyeongjin Nam,Jaerin Lee,Jaeyoung Chung,JoonKyu Park,Junghun Oh,Kanggeon Lee,Wooseok Lee,Juneyoung Ro,Turghun Osman,Can Hu,Chaoyang Liao,Cheng Chen,Chengcheng Han,Chenhao Qiu,Chong Peng,Cong Xu,Dailin Li,Feiyu Wang,Feng Gao,Guibo Zhu,Guopeng Tang,Haibo Lu,Han Fang,Han Qi,Hanxiao Wu,Haobo Cheng,Hongbo Sun,Hongyao Chen,Huayong Hu,Hui Li,Jiaheng Ma,Jiang Yu,Jianing Wang,Jie Yang,Jing He,Jinglin Zhou,Jingxuan Li,Josef Kittler,Lihao Zheng,Linnan Zhao,Mengxi Jia,Muyang Yan,Nguyen Thanh Thien,Pu Luo,Qi Li,Shien Song,Shijie Dong,Shuai Shao,Shutao Li,Taofeng Xue,Tianyang Xu,Tianyi Gao,Tingting Li,Wei Zhang,Weiyang Su,Xiaodong Dong,Xiao-Jun Wu,Xiaopeng Zhou,Xin Chen,Xin Wei,Xinyi You,Xudong Kang,Xujie Zhou,Xusheng Liu,Yanan Wang,Yanbin Huang,Yang Liu,Yang Yang,Yanglin Deng,Yashu Kang,Ye Yuan,Yi Wen,Yicen Tian,Yilin Tao,Yin Tang,Yipeng Lin,Yiqing Wang,Yiting Xi,Yongkang Yu,Yumei Li,Yuxin Qin,Yuying Chen,Yuzhe Cen,Zhaofan Zou,Zhaohong Liu,Zhehao Shen,Zhenglin Du,Zhengyang Li,Zhenni Huang,Zhenwei Shao,Zhilong Song,Zhiyong Feng,Zhiyu Wang,Zhou Yu,Ziang Li,Zihan Zhai,Zijian Zhang,Ziyang Peng,Ziyun Xiao,Zongshu Li*

Main category: cs.CV

TL;DR: MARS2 2025挑战赛综述，聚焦多模态推理，发布Lens和AdsQA两个数据集，评估40+基线模型，设立三个竞赛赛道，吸引76个团队参与。


<details>
  <summary>Details</summary>
Motivation: 整合多模态机器学习和LLM的不同方法，通过大规模基准测试推动该领域发展，关注现实世界和专业化场景以拓宽多模态推理应用。

Method: 发布两个定制数据集（Lens支持12个日常场景的通用推理，AdsQA支持广告视频的领域特定推理），评估40+基线模型，设立三个竞赛赛道：VG-RS、VQA-SA、VR-Ads。

Result: 76个知名学术和工业机构团队注册，1200+提交中40+有效提交进入排名，数据集、代码集和排名公开可用。

Conclusion: MARS2挑战赛成功推动了多模态推理研究，提供了宝贵的基准资源和社区平台，将持续更新和举办后续活动。

Abstract: This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim
to bring together different approaches in multimodal machine learning and LLMs
via a large benchmark. We hope it better allows researchers to follow the
state-of-the-art in this very dynamic area. Meanwhile, a growing number of
testbeds have boosted the evolution of general-purpose large language models.
Thus, this year's MARS2 focuses on real-world and specialized scenarios to
broaden the multimodal reasoning applications of MLLMs. Our organizing team
released two tailored datasets Lens and AdsQA as test sets, which support
general reasoning in 12 daily scenarios and domain-specific reasoning in
advertisement videos, respectively. We evaluated 40+ baselines that include
both generalist MLLMs and task-specific models, and opened up three competition
tracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question
Answering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative
Advertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and
industrial institutions have registered and 40+ valid submissions (out of
1200+) have been included in our ranking lists. Our datasets, code sets (40+
baselines and 15+ participants' methods), and rankings are publicly available
on the MARS2 workshop website and our GitHub organization page
https://github.com/mars2workshop/, where our updates and announcements of
upcoming events will be continuously provided.

</details>


### [80] [An Exploratory Study on Abstract Images and Visual Representations Learned from Them](https://arxiv.org/abs/2509.14149)
*Haotian Li,Jianbo Jiao*

Main category: cs.CV

TL;DR: 该论文研究了原始形状构成的抽象图像能否有效传递视觉语义信息，通过创建分层抽象图像数据集HAID，在不同抽象层次上评估传统视觉系统的性能表现。


<details>
  <summary>Details</summary>
Motivation: 探索抽象图像（由原始形状构成）与传统栅格图像在视觉语义信息传递方面的性能差距，研究不同抽象层次能够捕获多少高级语义内容。

Method: 引入分层抽象图像数据集HAID，包含从正常栅格图像生成的多层次抽象图像，在分类、分割和目标检测等任务上训练和评估传统视觉系统。

Result: 提供了栅格化图像与抽象图像表示之间的全面比较研究，分析了抽象图像在不同视觉任务中的表现。

Conclusion: 讨论了抽象图像是否可以作为传递视觉语义信息的有效格式，以及其对视觉任务的潜在贡献价值。

Abstract: Imagine living in a world composed solely of primitive shapes, could you
still recognise familiar objects? Recent studies have shown that abstract
images-constructed by primitive shapes-can indeed convey visual semantic
information to deep learning models. However, representations obtained from
such images often fall short compared to those derived from traditional raster
images. In this paper, we study the reasons behind this performance gap and
investigate how much high-level semantic content can be captured at different
abstraction levels. To this end, we introduce the Hierarchical Abstraction
Image Dataset (HAID), a novel data collection that comprises abstract images
generated from normal raster images at multiple levels of abstraction. We then
train and evaluate conventional vision systems on HAID across various tasks
including classification, segmentation, and object detection, providing a
comprehensive study between rasterised and abstract image representations. We
also discuss if the abstract image can be considered as a potentially effective
format for conveying visual semantic information and contributing to vision
tasks.

</details>


### [81] [BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection](https://arxiv.org/abs/2509.14151)
*Rongyu Zhang,Jiaming Liu,Xiaoqi Li,Xiaowei Chi,Dan Wang,Li Du,Yuan Du,Shanghang Zhang*

Main category: cs.CV

TL;DR: BEVUDA++是一个针对鸟瞰图感知中域适应问题的几何感知教师-学生框架，通过可靠深度教师和几何一致性学生模型，在四个跨域场景中实现了最先进的3D目标检测性能


<details>
  <summary>Details</summary>
Motivation: 鸟瞰图感知在自动驾驶中很重要，但现有研究忽视了域偏移问题，导致跨域时性能显著下降。作者发现多几何空间中的域偏移累积是主要挑战

Method: 提出BEVUDA++框架，包含可靠深度教师(RDT)和几何一致性学生(GCS)。RDT融合LiDAR和深度预测生成深度感知信息，GCS将多空间特征映射到统一几何嵌入空间。还引入不确定性引导指数移动平均(UEMA)减少误差累积

Result: 在四个跨域场景中实现最先进性能，在日夜间适应任务上分别提升12.9% NDS和9.5% mAP

Conclusion: 该方法有效解决了BEV感知中的域适应挑战，通过几何感知框架显著提升了跨域3D目标检测性能

Abstract: Vision-centric Bird's Eye View (BEV) perception holds considerable promise
for autonomous driving. Recent studies have prioritized efficiency or accuracy
enhancements, yet the issue of domain shift has been overlooked, leading to
substantial performance degradation upon transfer. We identify major domain
gaps in real-world cross-domain scenarios and initiate the first effort to
address the Domain Adaptation (DA) challenge in multi-view 3D object detection
for BEV perception. Given the complexity of BEV perception approaches with
their multiple components, domain shift accumulation across multi-geometric
spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain
adaptation. In this paper, we introduce an innovative geometric-aware
teacher-student framework, BEVUDA++, to diminish this issue, comprising a
Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.
Specifically, RDT effectively blends target LiDAR with dependable depth
predictions to generate depth-aware information based on uncertainty
estimation, enhancing the extraction of Voxel and BEV features that are
essential for understanding the target domain. To collaboratively reduce the
domain shift, GCS maps features from multiple spaces into a unified geometric
embedding space, thereby narrowing the gap in data distribution between the two
domains. Additionally, we introduce a novel Uncertainty-guided Exponential
Moving Average (UEMA) to further reduce error accumulation due to domain shifts
informed by previously obtained uncertainty guidance. To demonstrate the
superiority of our proposed method, we execute comprehensive experiments in
four cross-domain scenarios, securing state-of-the-art performance in BEV 3D
object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night
adaptation.

</details>


### [82] [Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark](https://arxiv.org/abs/2509.14227)
*Nisarg A. Shah,Amir Ziai,Chaitanya Ekanadham,Vishal M. Patel*

Main category: cs.CV

TL;DR: Cineaste是一个用于评估长视频电影理解能力的综合基准数据集，包含3119个多选题，涵盖5种细粒度推理类别，现有模型表现不佳（最高63.15%准确率），显示长时序推理是主要瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要测试短片段识别或模板化问题，缺乏对长叙事内容的细粒度推理能力评估，需要填补这一空白

Method: 使用GPT-4o生成多样化、上下文丰富的问题，整合视觉描述、字幕、场景标题和摘要，采用两阶段过滤流程确保问题质量（上下文独立性和事实一致性验证）

Result: 现有多模态大语言模型在Cineaste上表现困难，最佳开源模型准确率仅63.15%，长时序推理是主要挑战

Conclusion: 长形式电影理解仍面临显著挑战，需要在细粒度上下文理解和长时序推理方面取得进展

Abstract: While recent advancements in vision-language models have improved video
understanding, diagnosing their capacity for deep, narrative comprehension
remains a challenge. Existing benchmarks often test short-clip recognition or
use template-based questions, leaving a critical gap in evaluating fine-grained
reasoning over long-form narrative content. To address these gaps, we introduce
$\mathsf{Cin\acute{e}aste}$, a comprehensive benchmark for long-form movie
understanding. Our dataset comprises 3,119 multiple-choice question-answer
pairs derived from 1,805 scenes across 200 diverse movies, spanning five novel
fine-grained contextual reasoning categories. We use GPT-4o to generate
diverse, context-rich questions by integrating visual descriptions, captions,
scene titles, and summaries, which require deep narrative understanding. To
ensure high-quality evaluation, our pipeline incorporates a two-stage filtering
process: Context-Independence filtering ensures questions require video
context, while Contextual Veracity filtering validates factual consistency
against the movie content, mitigating hallucinations. Experiments show that
existing MLLMs struggle on $\mathsf{Cin\acute{e}aste}$; our analysis reveals
that long-range temporal reasoning is a primary bottleneck, with the top
open-source model achieving only 63.15\% accuracy. This underscores significant
challenges in fine-grained contextual understanding and the need for
advancements in long-form movie comprehension.

</details>


### [83] [GenExam: A Multidisciplinary Text-to-Image Exam](https://arxiv.org/abs/2509.14232)
*Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo*

Main category: cs.CV

TL;DR: GenExam是首个多学科文本到图像考试基准，包含10个学科的1000个样本，采用四级分类法组织考试式提示，用于精确评估语义正确性和视觉合理性。


<details>
  <summary>Details</summary>
Motivation: 现有考试式基准主要关注理解和推理任务，而生成基准强调世界知识和视觉概念的展示，忽略了严格绘图考试的评估。需要一个新的基准来综合评估知识整合、推理和生成能力。

Method: 构建包含1000个样本的多学科文本到图像考试基准，涵盖10个学科，每个问题配备真实图像和细粒度评分点，采用四级分类法组织考试式提示。

Result: 实验显示，即使是GPT-Image-1和Gemini-2.5-Flash-Image等最先进模型也只能获得不到15%的严格分数，大多数模型得分接近0%，表明该基准具有很大挑战性。

Conclusion: 通过将图像生成构建为考试形式，GenExam提供了对模型整合知识、推理和生成能力的严格评估，为通向通用AGI的路径提供了重要见解。

Abstract: Exams are a fundamental test of expert-level intelligence and require
integrated understanding, reasoning, and generation. Existing exam-style
benchmarks mainly focus on understanding and reasoning tasks, and current
generation benchmarks emphasize the illustration of world knowledge and visual
concepts, neglecting the evaluation of rigorous drawing exams. We introduce
GenExam, the first benchmark for multidisciplinary text-to-image exams,
featuring 1,000 samples across 10 subjects with exam-style prompts organized
under a four-level taxonomy. Each problem is equipped with ground-truth images
and fine-grained scoring points to enable a precise evaluation of semantic
correctness and visual plausibility. Experiments show that even
state-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve
less than 15% strict scores, and most models yield almost 0%, suggesting the
great challenge of our benchmark. By framing image generation as an exam,
GenExam offers a rigorous assessment of models' ability to integrate knowledge,
reasoning, and generation, providing insights on the path to general AGI.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [84] [Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning](https://arxiv.org/abs/2509.13336)
*Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah*

Main category: cs.RO

TL;DR: 基于强化学习的无人机超视距路径规划方法，通过最小化飞行距离和最大化蜂窝链路质量来确保安全可靠的飞行操作


<details>
  <summary>Details</summary>
Motivation: 解决超视距无人机操作中的蜂窝通信限制问题，需要优化路径规划来确保与地面基站的持续连接质量

Method: 使用强化学习技术训练智能体，以无人机与基站之间的通信链路质量作为奖励函数，考虑实际空中覆盖约束和经验空中信道模型

Result: 仿真结果表明该方法能有效训练智能体并生成可行的无人机路径规划，RL算法能高效识别最优路径确保最大连接性

Conclusion: 该方法可作为离线路径规划模块集成到未来地面控制系统中，具有在复杂长距离无人机应用中推广的潜力，推动了蜂窝连接无人机路径规划技术的发展

Abstract: This paper presents a reinforcement learning (RL) based approach for path
planning of cellular connected unmanned aerial vehicles (UAVs) operating beyond
visual line of sight (BVLoS). The objective is to minimize travel distance
while maximizing the quality of cellular link connectivity by considering real
world aerial coverage constraints and employing an empirical aerial channel
model. The proposed solution employs RL techniques to train an agent, using the
quality of communication links between the UAV and base stations (BSs) as the
reward function. Simulation results demonstrate the effectiveness of the
proposed method in training the agent and generating feasible UAV path plans.
The proposed approach addresses the challenges due to limitations in UAV
cellular communications, highlighting the need for investigations and
considerations in this area. The RL algorithm efficiently identifies optimal
paths, ensuring maximum connectivity with ground BSs to ensure safe and
reliable BVLoS flight operation. Moreover, the solution can be deployed as an
offline path planning module that can be integrated into future ground control
systems (GCS) for UAV operations, enhancing their capabilities and safety. The
method holds potential for complex long range UAV applications, advancing the
technology in the field of cellular connected UAV path planning.

</details>


### [85] [How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots](https://arxiv.org/abs/2509.13827)
*Renyuan Liu,Haoting Zhou,Chuankai Fang,Qinbing Fu*

Main category: cs.RO

TL;DR: 本文提出了一种受苍蝇视觉神经元启发的注意力驱动视觉运动控制策略，实现了96.1%成功率的碰撞检测和优雅的规避动作


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在复杂环境中敏捷性的计算成本与性能之间的权衡问题，利用昆虫启发的智能提供低功耗、计算高效的解决方案

Method: 基于苍蝇LPLC2视觉投影神经元的简化神经模型（70KB内存），结合多注意力机制模拟分布式响应特性，在Colias微型机器人上实现碰撞感知和反应规避

Result: 与最先进的蝗虫启发碰撞检测模型相比，实现了96.1%的碰撞检测成功率，产生更自适应和优雅的规避动作

Conclusion: 这项工作不仅展示了有效的避碰策略，还突显了苍蝇启发神经模型在推进昆虫智能集体行为研究方面的潜力

Abstract: Anyone who has tried to swat a fly has likely been frustrated by its
remarkable agility.This ability stems from its visual neural perception system,
particularly the collision-selective neurons within its small brain.For
autonomous robots operating in complex and unfamiliar environments, achieving
similar agility is highly desirable but often constrained by the trade-off
between computational cost and performance.In this context, insect-inspired
intelligence offers a parsimonious route to low-power, computationally
efficient frameworks.In this paper, we propose an attention-driven visuomotor
control strategy inspired by a specific class of fly visual projection
neurons-the lobula plate/lobula column type-2 (LPLC2)-and their associated
escape behaviors.To our knowledge, this represents the first embodiment of an
LPLC2 neural model in the embedded vision of a physical mobile robot, enabling
collision perception and reactive evasion.The model was simplified and
optimized at 70KB in memory to suit the computational constraints of a
vision-based micro robot, the Colias, while preserving key neural perception
mechanisms.We further incorporated multi-attention mechanisms to emulate the
distributed nature of LPLC2 responses, allowing the robot to detect and react
to approaching targets both rapidly and selectively.We systematically evaluated
the proposed method against a state-of-the-art locust-inspired collision
detection model.Results showed that the fly-inspired visuomotor model achieved
comparable robustness, at success rate of 96.1% in collision detection while
producing more adaptive and elegant evasive maneuvers.Beyond demonstrating an
effective collision-avoidance strategy, this work highlights the potential of
fly-inspired neural models for advancing research into collective behaviors in
insect intelligence.

</details>


### [86] [Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments](https://arxiv.org/abs/2509.13342)
*Isaac Ronald Ward*

Main category: cs.RO

TL;DR: 本文通过改进深度神经网络的损失函数，结合位置和旋转误差来提高机器人视觉定位的鲁棒性，在室内场景中实现了定位精度的显著提升，并建立了从数据采集到实时导航的完整流程。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉信息的机器人位姿确定方法在面对感知混淆时定位性能有限，需要一种既能提高定位精度又不增加训练难度的改进方法。

Method: 扩展神经网络损失函数，直观地结合位置和旋转误差来增强对感知混淆的鲁棒性；使用摄影测量数据生成位姿标注数据集；在TurtleBot轮式机器人上进行实时测试。

Result: 室内场景定位精度显著提升：位置误差中位数降低达9.64%，旋转误差中位数降低2.99%；最终实现0.11米和0.89度的定位精度；整个数据采集流程仅需330秒。

Conclusion: 该方法成功构建了一个完整的鲁棒导航算法流程，仅需场景图像集合即可为任何真实室内场景创建有效的导航系统，在保持训练简便性的同时显著提高了定位性能。

Abstract: In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of

</details>


### [87] [ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy](https://arxiv.org/abs/2509.13380)
*Alejandro D. Mousist*

Main category: cs.RO

TL;DR: ASTREA是首个在飞行硬件上部署的自主航天器操作智能体系统，结合LLM语义推理和强化学习控制，地面实验成功但太空验证显示延迟问题


<details>
  <summary>Details</summary>
Motivation: 开发首个在飞行硬件上部署的自主航天器操作智能体系统，解决太空环境下的自主控制问题，以热控制为代表性用例

Method: 采用异步架构，将资源受限的大型语言模型(LLM)智能体与强化学习控制器集成，针对太空认证平台进行定制化设计

Result: 地面实验显示LLM引导的监督提高了热稳定性并减少违规；但在国际空间站的轨道验证中，由于推理延迟与低地球轨道快速热循环不匹配导致性能下降

Conclusion: 研究揭示了基于LLM的智能体系统在真实飞行环境中的机遇和当前局限性，为未来太空自主系统提供了实用设计指南

Abstract: This paper presents ASTREA, the first agentic system deployed on
flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using
thermal control as a representative use case, we integrate a
resource-constrained Large Language Model (LLM) agent with a reinforcement
learning controller in an asynchronous architecture tailored for
space-qualified platforms. Ground experiments show that LLM-guided supervision
improves thermal stability and reduces violations, confirming the feasibility
of combining semantic reasoning with adaptive control under hardware
constraints. However, on-orbit validation aboard the International Space
Station (ISS) reveals performance degradation caused by inference latency
mismatched with the rapid thermal cycles characteristic of Low Earth Orbit
(LEO) satellites. These results highlight both the opportunities and current
limitations of agentic LLM-based systems in real flight environments, providing
practical design guidelines for future space autonomy.

</details>


### [88] [Label-Efficient Grasp Joint Prediction with Point-JEPA](https://arxiv.org/abs/2509.13349)
*Jed Guzelkabaagac,Boris Petrović*

Main category: cs.RO

TL;DR: Point-JEPA自监督预训练在低标签数据情况下显著提升抓取关节角度预测性能，在DLR-Hand II数据集上RMSE降低26%，达到全监督性能水平


<details>
  <summary>Details</summary>
Motivation: 研究3D自监督预训练是否能够实现标签高效的抓取关节角度预测，解决数据标注成本高的问题

Method: 使用从网格中token化的点云数据，采用ShapeNet预训练的Point-JEPA编码器，训练轻量级多假设头部网络，使用winner-takes-all策略和top-logit选择进行评估

Result: 在DLR-Hand II数据集的对象级分割上，Point-JEPA在低标签情况下将RMSE降低了26%，并达到与全监督方法相当的性能

Conclusion: JEPA风格的预训练是数据高效抓取学习的一种实用方法

Abstract: We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.

</details>


### [89] [Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach](https://arxiv.org/abs/2509.13381)
*Zhang Xueyao,Yang Bo,Yu Zhiwen,Cao Xuelin,George C. Alexandropoulos,Merouane Debbah,Chau Yuen*

Main category: cs.RO

TL;DR: 提出了一种新颖的双时间尺度分层多智能体近端策略优化(H-MAPPO)框架，用于解决自主水下航行器(AUV)在对抗环境中协同通信的隐蔽性问题，通过高层任务分配和低层功率轨迹控制实现高效隐蔽协作。


<details>
  <summary>Details</summary>
Motivation: 自主水下航行器在协同探测和侦察中具有巨大潜力，但在对抗环境中，协同通信会带来暴露风险。如何在确保隐蔽操作的同时实现高效协作成为水下协同任务的关键挑战。

Method: 采用双时间尺度分层框架：高层组件基于中央AUV确定参与任务的个体，低层组件通过参与AUV的功率和轨迹控制来降低暴露概率。使用多智能体近端策略优化(H-MAPPO)算法。

Result: 仿真结果表明，所提框架实现了快速收敛，在性能上优于基准算法，在确保隐蔽操作的同时最大化长期协作效率。

Conclusion: 该H-MAPPO框架有效解决了AUV在对抗环境中的隐蔽协同问题，为水下协同任务提供了既高效又安全的解决方案。

Abstract: Autonomous Underwater Vehicles (AUVs) have shown great potential for
cooperative detection and reconnaissance. However, collaborative AUV
communications introduce risks of exposure. In adversarial environments,
achieving efficient collaboration while ensuring covert operations becomes a
key challenge for underwater cooperative missions. In this paper, we propose a
novel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization
(H-MAPPO) framework. The high-level component determines the individuals
participating in the task based on a central AUV, while the low-level component
reduces exposure probabilities through power and trajectory control by the
participating AUVs. Simulation results show that the proposed framework
achieves rapid convergence, outperforms benchmark algorithms in terms of
performance, and maximizes long-term cooperative efficiency while ensuring
covert operations.

</details>


### [90] [Using role-play and Hierarchical Task Analysis for designing human-robot interaction](https://arxiv.org/abs/2509.13378)
*Mattias Wingren,Sören Andersson,Sara Rosenberg,Malin Andtfolk,Susanne Hägglund,Prashani Jayasingha Arachchige,Linda Nyholm*

Main category: cs.RO

TL;DR: 本文展示了角色扮演和层次任务分析在人机交互领域的应用价值，通过在社区药房机器人开发项目中的实践，证明了这两种方法在理解用户需求和确保行为建模准确性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互领域对角色扮演和层次任务分析方法的使用不足，研究者希望通过在社区药房机器人应用开发中的实践，展示这两种方法的潜在价值和应用优势。

Method: 采用角色扮演方法创建可控可调节的环境来理解客户需求，让药剂师作为机器人行为的模型；使用层次任务分析确保行为建模的正确性，并通过促进协同设计来辅助开发过程。

Result: 角色扮演提供了理解客户需求的有效环境，层次任务分析确保了行为建模的准确性并促进了协同开发，两种方法为研究项目带来了多重优势。

Conclusion: 角色扮演和层次任务分析是人机交互领域中值得更多应用的有效方法，未来研究可以专注于开发特别适合社交机器人交互的任务分析方法。

Abstract: We present the use of two methods we believe warrant more use than they
currently have in the field of human-robot interaction: role-play and
Hierarchical Task Analysis. Some of its potential is showcased through our use
of them in an ongoing research project which entails developing a robot
application meant to assist at a community pharmacy. The two methods have
provided us with several advantages. The role-playing provided a controlled and
adjustable environment for understanding the customers' needs where pharmacists
could act as models for the robot's behavior; and the Hierarchical Task
Analysis ensured the behavior displayed was modelled correctly and aided
development through facilitating co-design. Future research could focus on
developing task analysis methods especially suited for social robot
interaction.

</details>


### [91] [Repulsive Trajectory Modification and Conflict Resolution for Efficient Multi-Manipulator Motion Planning](https://arxiv.org/abs/2509.13882)
*Junhwa Hong,Beomjoon Lee,Woojin Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 提出一种基于冲突搜索的多机械臂运动规划方法，通过斥力轨迹修改减少后续冲突，提高规划效率


<details>
  <summary>Details</summary>
Motivation: 多机械臂系统协调运动面临高维配置空间的挑战，传统冲突搜索方法在解决冲突时会产生新的冲突，导致约束树指数级增长

Method: 在冲突搜索的两层结构中，低层规划器使用人工势场的梯度下降方法生成斥力，引导冲突机械臂轨迹远离其他机器人，并开发了单步寻找无冲突解的策略

Result: 通过大量测试和物理机器人实验，该方法显著减少了约束树扩展节点数，提高了成功率，比增强型冲突搜索和其他先进算法更快找到解

Conclusion: 所提出的斥力轨迹修改方法有效解决了多机械臂运动规划中的冲突传播问题，提高了规划效率和成功率

Abstract: We propose an efficient motion planning method designed to efficiently find
collision-free trajectories for multiple manipulators. While multi-manipulator
systems offer significant advantages, coordinating their motions is
computationally challenging owing to the high dimensionality of their composite
configuration space. Conflict-Based Search (CBS) addresses this by decoupling
motion planning, but suffers from subsequent conflicts incurred by resolving
existing conflicts, leading to an exponentially growing constraint tree of CBS.
Our proposed method is based on repulsive trajectory modification within the
two-level structure of CBS. Unlike conventional CBS variants, the low-level
planner applies a gradient descent approach using an Artificial Potential
Field. This field generates repulsive forces that guide the trajectory of the
conflicting manipulator away from those of other robots. As a result,
subsequent conflicts are less likely to occur. Additionally, we develop a
strategy that, under a specific condition, directly attempts to find a
conflict-free solution in a single step without growing the constraint tree.
Through extensive tests including physical robot experiments, we demonstrate
that our method consistently reduces the number of expanded nodes in the
constraint tree, achieves a higher success rate, and finds a solution faster
compared to Enhanced CBS and other state-of-the-art algorithms.

</details>


### [92] [TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems](https://arxiv.org/abs/2509.14025)
*Rui Huang,Zhiyu Gao,Siyu Tang,Jialin Zhang,Lei He,Ziqian Zhang,Lin Zhao*

Main category: cs.RO

TL;DR: TransforMARS是一个通用的故障容忍重构框架，能够处理任意形状的模块化空中机器人系统在多个转子和单元故障情况下的重构，同时确保空中稳定性


<details>
  <summary>Details</summary>
Motivation: 现有的MARS自重构方法仅关注最大化可控性裕度来处理矩形形状系统的单转子或单元故障，缺乏对任意形状系统和多重故障的通用解决方案

Method: 开发算法首先识别和构建包含故障单元的最小可控组件，然后规划可行的拆卸-组装序列来运输MARS单元或子组件以形成目标配置

Result: 在具有挑战性的任意形状MARS配置中验证了TransforMARS，在处理多样化配置的能力和容忍故障数量方面相比先前工作有显著改进

Conclusion: 该方法实现了更灵活和实用的可行重构，为模块化空中机器人系统提供了通用的多重故障容忍重构解决方案

Abstract: Modular Aerial Robot Systems (MARS) consist of multiple drone modules that
are physically bound together to form a single structure for flight. Exploiting
structural redundancy, MARS can be reconfigured into different formations to
mitigate unit or rotor failures and maintain stable flight. Prior work on MARS
self-reconfiguration has solely focused on maximizing controllability margins
to tolerate a single rotor or unit fault for rectangular-shaped MARS. We
propose TransforMARS, a general fault-tolerant reconfiguration framework that
transforms arbitrarily shaped MARS under multiple rotor and unit faults while
ensuring continuous in-air stability. Specifically, we develop algorithms to
first identify and construct minimum controllable assemblies containing faulty
units. We then plan feasible disassembly-assembly sequences to transport MARS
units or subassemblies to form target configuration. Our approach enables more
flexible and practical feasible reconfiguration. We validate TransforMARS in
challenging arbitrarily shaped MARS configurations, demonstrating substantial
improvements over prior works in both the capacity of handling diverse
configurations and the number of faults tolerated. The videos and source code
of this work are available at the anonymous repository:
https://anonymous.4open.science/r/TransforMARS-1030/

</details>


### [93] [VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization](https://arxiv.org/abs/2509.13386)
*Hansol Lim,Minhyeok Im,Jonathan Boyack,Jee Won Lee,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: VEGA是一个基于强化学习的电动汽车充电感知导航系统，使用物理信息神经网络和PPO算法优化路径规划和充电策略，无需额外传感器即可实现个性化能效优化。


<details>
  <summary>Details</summary>
Motivation: 随着软件定义车辆需求增长和电动汽车计算能力提升，需要开发能够根据车辆实时状态和环境条件进行充电感知路径优化的AI系统，以降低电动汽车成本并提高能效。

Method: 系统包含两个模块：1）物理信息神经网络算子(PINO)，基于车辆速度日志学习车辆定制化动力学参数；2）强化学习智能体，使用学习到的动力学模型在电量约束下优化路径、充电站点选择和停留时间。

Result: 在长距离路线测试中，VEGA的充电站点选择、停留时间、电量管理和总旅行时间与特斯拉行程规划器接近但更保守，展示了良好的泛化能力，能在法国和日本等未训练地区计算最优路径。

Conclusion: VEGA成功实现了物理信息学习与强化学习的实际集成，为电动汽车生态路由提供了有效的解决方案，可作为虚拟传感器减少车辆成本。

Abstract: Demands for software-defined vehicles (SDV) are rising and electric vehicles
(EVs) are increasingly being equipped with powerful computers. This enables
onboard AI systems to optimize charge-aware path optimization customized to
reflect vehicle's current condition and environment. We present VEGA, a
charge-aware EV navigation agent that plans over a charger-annotated road graph
using Proximal Policy Optimization (PPO) with budgeted A* teacher-student
guidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.
First, a physics-informed neural operator (PINO), trained on real vehicle speed
and battery-power logs, uses recent vehicle speed logs to estimate aerodynamic
drag, rolling resistance, mass, motor and regenerative-braking efficiencies,
and auxiliary load by learning a vehicle-custom dynamics. Second, a
Reinforcement Learning (RL) agent uses these dynamics to optimize a path with
optimal charging stops and dwell times under SoC constraints. VEGA requires no
additional sensors and uses only vehicle speed signals. It may serve as a
virtual sensor for power and efficiency to potentially reduce EV cost. In
evaluation on long routes like San Francisco to New York, VEGA's stops, dwell
times, SoC management, and total travel time closely track Tesla Trip Planner
while being slightly more conservative, presumably due to real vehicle
conditions such as vehicle parameter drift due to deterioration. Although
trained only in U.S. regions, VEGA was able to compute optimal charge-aware
paths in France and Japan, demonstrating generalizability. It achieves
practical integration of physics-informed learning and RL for EV eco-routing.

</details>


### [94] [A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies](https://arxiv.org/abs/2509.13434)
*Wei-Chen Li,Glen Chou*

Main category: cs.RO

TL;DR: 提出了一个计算框架，用于模拟细丝与刚体之间的接触相互作用，通过统一离散弹性杆模型、压力场补丁接触模型和凸接触公式，实现了细丝与刚体间摩擦相互作用的精确模拟。


<details>
  <summary>Details</summary>
Motivation: 现有的细丝模拟方法通常假设细丝永久附着在刚体上，无法准确模拟细丝与刚体之间的复杂摩擦相互作用。细丝由于其共维特性（一维结构嵌入三维空间）而难以模拟。

Method: 结合离散弹性杆（DER）建模、压力场补丁接触模型和凸接触公式，采用凸优化方法确保每个时间步都能达到全局最优解，保证接触速度与冲量之间的互补性。

Result: 验证了摩擦力的准确性，与基线方法相比具有更高的物理保真度。在软机器人（如随机细丝抓取器）和可变形物体操作（如鞋带系结）等应用中展示了其适用性。

Conclusion: 该框架为涉及复杂细丝-细丝和细丝-刚体相互作用的系统提供了一个通用的模拟器，解决了先前无法实现的细丝与刚体摩擦相互作用模拟问题。

Abstract: We present a computational framework for simulating filaments interacting
with rigid bodies through contact. Filaments are challenging to simulate due to
their codimensionality, i.e., they are one-dimensional structures embedded in
three-dimensional space. Existing methods often assume that filaments remain
permanently attached to rigid bodies. Our framework unifies discrete elastic
rod (DER) modeling, a pressure field patch contact model, and a convex contact
formulation to accurately simulate frictional interactions between slender
filaments and rigid bodies - capabilities not previously achievable. Owing to
the convex formulation of contact, each time step can be solved to global
optimality, guaranteeing complementarity between contact velocity and impulse.
We validate the framework by assessing the accuracy of frictional forces and
comparing its physical fidelity against baseline methods. Finally, we
demonstrate its applicability in both soft robotics, such as a stochastic
filament-based gripper, and deformable object manipulation, such as shoelace
tying, providing a versatile simulator for systems involving complex
filament-filament and filament-rigid body interactions.

</details>


### [95] [CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads](https://arxiv.org/abs/2509.14126)
*Viktor Lorentz,Khaled Wahba,Sayantan Auddy,Marc Toussaint,Wolfgang Hönig*

Main category: cs.RO

TL;DR: 提出了CrazyMARL框架，使用去中心化强化学习解决多无人机协同运输电缆悬挂载荷的控制问题，能够处理电缆松弛-拉紧模式转换和非线性动力学，在干扰抑制和跟踪精度方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 多无人机协同运输电缆悬挂载荷具有提升载荷能力、适应不同形状载荷和内置合规性等优势，但在干扰、非线性载荷动力学和电缆松弛-拉紧模式转换下的协调控制仍是一个挑战性问题。

Method: 提出CrazyMARL去中心化强化学习框架，通过模拟训练学习控制策略，能够处理电缆模式转换和非线性动力学问题。

Result: 仿真结果显示学习策略在干扰抑制和跟踪精度方面优于传统去中心化控制器，在恶劣条件下恢复率达到80%（基线方法为44%），并成功实现零样本仿真到现实的迁移。

Conclusion: 该工作为在非结构化环境中执行复杂载荷任务的自适应、弹性无人机团队铺平了道路，展示了强化学习在多无人机协同控制中的潜力。

Abstract: Collaborative transportation of cable-suspended payloads by teams of Unmanned
Aerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to
different payload shapes, and provide built-in compliance, making it attractive
for applications ranging from disaster relief to precision logistics. However,
multi-UAV coordination under disturbances, nonlinear payload dynamics, and
slack--taut cable modes remains a challenging control problem. To our
knowledge, no prior work has addressed these cable mode transitions in the
multi-UAV context, instead relying on simplifying rigid-link assumptions. We
propose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for
multi-UAV cable-suspended payload transport. Simulation results demonstrate
that the learned policies can outperform classical decentralized controllers in
terms of disturbance rejection and tracking precision, achieving an 80%
recovery rate from harsh conditions compared to 44% for the baseline method. We
also achieve successful zero-shot sim-to-real transfer and demonstrate that our
policies are highly robust under harsh conditions, including wind, random
external disturbances, and transitions between slack and taut cable dynamics.
This work paves the way for autonomous, resilient UAV teams capable of
executing complex payload missions in unstructured environments.

</details>


### [96] [Trajectory Tracking with Reachability-Guided Quadratic Programming and Freeze-Resume](https://arxiv.org/abs/2509.13501)
*Hossein Gholampour,Logan E. Beaver*

Main category: cs.RO

TL;DR: 提出一种输出空间方法，用于双积分器系统的安全路径跟踪，能够在遇到干扰时暂停并恢复，无需重新规划路径。


<details>
  <summary>Details</summary>
Motivation: 许多机器人系统需要遵循规划路径，但在遇到人或物体干预时能够安全暂停并恢复。现有方法在安全停止和非计划偏差处理方面存在不足。

Method: 离线进行可达性检查验证运动计划符合速度和加速度限制，在线应用二次规划在相同限制下跟踪运动计划，使用一步可达性测试来界定系统能够拒绝的最大干扰。

Result: 系统能够高效处理安全停止和非计划偏差，无需重新规划即可返回运动计划，在仿真中表现出比纯追踪方法更好的性能。

Conclusion: 该方法为双积分器系统提供了一种有效的安全路径跟踪解决方案，能够在保持安全约束的同时处理意外干扰。

Abstract: Many robotic systems must follow planned paths yet pause safely and resume
when people or objects intervene. We present an output-space method for systems
whose tracked output can be feedback-linearized to a double integrator (e.g.,
manipulators). The approach has two parts. Offline, we perform a pre-run
reachability check to verify that the motion plan respects speed and
acceleration magnitude limits. Online, we apply a quadratic program to track
the motion plan under the same limits. We use a one-step reachability test to
bound the maximum disturbance the system is capable of rejecting. When the
state coincides with the reference path we recover perfect tracking in the
deterministic case, and we correct errors using a KKT-inspired weight. We
demonstrate that safety stops and unplanned deviations are handled efficiently,
and the system returns to the motion plan without replanning. We demonstrate
our system's improved performance over pure pursuit in simulation.

</details>


### [97] [Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks](https://arxiv.org/abs/2509.14127)
*Alkesh K. Srivastava,Jared Michael Levin,Philip Dames*

Main category: cs.RO

TL;DR: VCST-RCP框架通过Voronoi约束的Steiner树优化构建稀疏中继主干，将中继从附带产物转变为协调核心，在多机器人包裹配送中相比传统方法提升效率达34%


<details>
  <summary>Details</summary>
Motivation: 解决同构机器人车队在有限运载能力下从单一取货点到多个目标位置的包裹配送问题，传统直接运输方法效率有限，需要新的协调框架

Method: 提出Voronoi约束的Steiner树中继协调规划框架，使用Steiner树优化构建稀疏中继主干，然后合成机器人级别的取货、中继和配送调度计划

Result: 大量实验显示相比传统基线方法有高达34%的持续改进，显著提升了容量约束下多机器人配送的能源效率

Conclusion: 将中继纳入配送过程具有显著优势，为现实世界物流提供了一个可扩展的框架，中继应成为协调的核心元素而非附带产物

Abstract: We consider the problem of delivering multiple packages from a single pickup
depot to distinct goal locations using a homogeneous fleet of robots with
limited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner
Tree Relay Coordination Planning framework that constructs sparse relay trunks
using Steiner tree optimization and then synthesizes robot-level pickup, relay,
and delivery schedules. This framework reframes relays from incidental
byproducts into central elements of coordination, offering a contrast with
traditional delivery methods that rely on direct source-to-destination
transport. Extensive experiments show consistent improvements of up to 34%
compared to conventional baselines, underscoring the benefits of incorporating
relays into the delivery process. These improvements translate directly to
enhanced energy efficiency in multi-robot delivery under capacity constraints,
providing a scalable framework for real-world logistics.

</details>


### [98] [Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning](https://arxiv.org/abs/2509.13534)
*Chunxin Zheng,Kai Chen,Zhihai Bi,Yulin Li,Liang Pan,Jinni Zhou,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 提出基于强化学习的全身拥抱操作框架，结合预训练人体运动先验和神经符号距离场表示，实现人形机器人对大型物体的稳定多接触操作


<details>
  <summary>Details</summary>
Motivation: 传统仅依赖末端执行器的抓取方法在大型物体操作中存在稳定性差和负载能力有限的问题，需要开发全身协调的多接触操作方法

Method: 采用师生架构蒸馏大规模人体运动数据，结合神经符号距离场提供连续几何感知，通过强化学习生成运动自然且物理可行的全身运动模式

Result: 在仿真和真实实验中表现出对多样化形状尺寸物体的适应能力，成功实现从仿真到现实的迁移，提升了操作鲁棒性和负载能力

Conclusion: 该框架为人形机器人的多接触和长时程全身操作任务提供了有效实用的解决方案

Abstract: Whole-body manipulation (WBM) for humanoid robots presents a promising
approach for executing embracing tasks involving bulky objects, where
traditional grasping relying on end-effectors only remains limited in such
scenarios due to inherent stability and payload constraints. This paper
introduces a reinforcement learning framework that integrates a pre-trained
human motion prior with a neural signed distance field (NSDF) representation to
achieve robust whole-body embracing. Our method leverages a teacher-student
architecture to distill large-scale human motion data, generating kinematically
natural and physically feasible whole-body motion patterns. This facilitates
coordinated control across the arms and torso, enabling stable multi-contact
interactions that enhance the robustness in manipulation and also the load
capacity. The embedded NSDF further provides accurate and continuous geometric
perception, improving contact awareness throughout long-horizon tasks. We
thoroughly evaluate the approach through comprehensive simulations and
real-world experiments. The results demonstrate improved adaptability to
diverse shapes and sizes of objects and also successful sim-to-real transfer.
These indicate that the proposed framework offers an effective and practical
solution for multi-contact and long-horizon WBM tasks of humanoid robots.

</details>


### [99] [Semantic 3D Reconstructions with SLAM for Central Airway Obstruction](https://arxiv.org/abs/2509.13541)
*Ayberk Acar,Fangjie Li,Hao Li,Lidia Al-Zogbi,Kanyifeechukwu Jane Oguine,Susheela Sharma Stern,Jesse F. d'Almeida,Robert J. Webster III,Ipek Oguz,Jie Ying Wu*

Main category: cs.RO

TL;DR: 提出了一种结合语义分割和实时单目SLAM的新颖管道，用于中央气道阻塞的内窥镜3D重建，实现实时语义标注的3D地图生成


<details>
  <summary>Details</summary>
Motivation: 中央气道阻塞(CAO)是一种危及生命的疾病，传统治疗方法并发症风险高。机器人干预结合场景理解和映射为自动化提供了可能性，需要实时语义感知的3D重建技术

Method: 结合DROID-SLAM与专门训练的分割模型来识别阻塞组织。SLAM模块实时重建气道3D几何结构，分割掩码指导在重建点云中标注阻塞区域

Result: 离体模型验证显示重建质量高，与真实CT扫描具有高度相似性（0.62 mm Chamfer距离）。系统能够实时生成标注临床相关区域的3D地图，重建速度比先前工作更快

Conclusion: 这是首个将语义分割与实时单目SLAM集成用于内窥镜CAO场景的工作，框架模块化且可推广到其他解剖结构或手术，为自主机器人干预提供了有前景的一步

Abstract: Central airway obstruction (CAO) is a life-threatening condition with
increasing incidence, caused by tumors in and outside of the airway.
Traditional treatment methods such as bronchoscopy and electrocautery can be
used to remove the tumor completely; however, these methods carry a high risk
of complications. Recent advances allow robotic interventions with lesser risk.
The combination of robot interventions with scene understanding and mapping
also opens up the possibilities for automation. We present a novel pipeline
that enables real-time, semantically informed 3D reconstructions of the central
airway using monocular endoscopic video.
  Our approach combines DROID-SLAM with a segmentation model trained to
identify obstructive tissues. The SLAM module reconstructs the 3D geometry of
the airway in real time, while the segmentation masks guide the annotation of
obstruction regions within the reconstructed point cloud. To validate our
pipeline, we evaluate the reconstruction quality using ex vivo models.
  Qualitative and quantitative results show high similarity between ground
truth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By
integrating segmentation directly into the SLAM workflow, our system produces
annotated 3D maps that highlight clinically relevant regions in real time.
High-speed capabilities of the pipeline allows quicker reconstructions compared
to previous work, reflecting the surgical scene more accurately.
  To the best of our knowledge, this is the first work to integrate semantic
segmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our
framework is modular and can generalize to other anatomies or procedures with
minimal changes, offering a promising step toward autonomous robotic
interventions.

</details>


### [100] [Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference](https://arxiv.org/abs/2509.13572)
*Ozan Karaali,Hossam Farag,Strahinja Dosen,Cedomir Stefanovic*

Main category: cs.RO

TL;DR: 本研究评估了8种视觉语言模型在假手感知任务中的表现，通过单一图像实现物体识别和抓取参数推断，发现模型在物体识别方面表现良好，但在尺寸估计和抓取参数推断方面存在差异。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型作为半自主假手感知模块的潜力，替代传统需要多个独立模块（物体检测、姿态估计、抓取规划）的复杂流程。

Method: 建立统一基准测试，使用34张常见物体图像，通过结构化JSON提示要求8种当代VLM模型从单张静态图像中识别物体属性（名称、形状、朝向、尺寸）并推断抓取参数（抓取类型、手腕旋转、手部开合度、手指数量）。

Result: 大多数模型在物体识别和形状识别方面表现优异，但在尺寸估计和最优抓取参数推断（特别是手部旋转和开合度）方面准确性差异较大。同时分析了延迟和成本性能指标。

Conclusion: 研究展示了VLM作为仿生肢体高级感知模块的当前能力和局限性，证明了其在有效假肢应用中的潜力。

Abstract: This study examines the potential of utilizing Vision Language Models (VLMs)
to improve the perceptual capabilities of semi-autonomous prosthetic hands. We
introduce a unified benchmark for end-to-end perception and grasp inference,
evaluating a single VLM to perform tasks that traditionally require complex
pipelines with separate modules for object detection, pose estimation, and
grasp planning. To establish the feasibility and current limitations of this
approach, we benchmark eight contemporary VLMs on their ability to perform a
unified task essential for bionic grasping. From a single static image, they
should (1) identify common objects and their key properties (name, shape,
orientation, and dimensions), and (2) infer appropriate grasp parameters (grasp
type, wrist rotation, hand aperture, and number of fingers). A corresponding
prompt requesting a structured JSON output was employed with a dataset of 34
snapshots of common objects. Key performance metrics, including accuracy for
categorical attributes (e.g., object name, shape) and errors in numerical
estimates (e.g., dimensions, hand aperture), along with latency and cost, were
analyzed. The results demonstrated that most models exhibited high performance
in object identification and shape recognition, while accuracy in estimating
dimensions and inferring optimal grasp parameters, particularly hand rotation
and aperture, varied more significantly. This work highlights the current
capabilities and limitations of VLMs as advanced perceptual modules for
semi-autonomous control of bionic limbs, demonstrating their potential for
effective prosthetic applications.

</details>


### [101] [Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation](https://arxiv.org/abs/2509.13574)
*Zidong Chen,Zihao Guo,Peng Wang,ThankGod Itua Egbe,Yan Lyu,Chenghao Qian*

Main category: cs.RO

TL;DR: 本文提出了一种基于非均匀时间调度和密集跳跃积分的新型流匹配策略，解决了传统方法中泛化能力早饱和和推理时多步积分性能下降的问题，在机器人任务上实现了23.7%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 发现流匹配框架中泛化能力在流轨迹早期就出现饱和，且增加欧拉积分步数反而会降低策略性能，这主要源于均匀积分步长对后期区域的过采样以及速度场在接近时间1时变得非Lipschitz导致的不稳定性。

Method: 提出在训练时使用非均匀时间调度（如U形调度）来正则化策略训练，强调早期和晚期时间阶段；在推理时使用密集跳跃积分调度，通过单步积分替换跳跃点后的多步积分来避免不稳定区域。

Result: 在多样化的机器人任务上，该方法相比最先进的基线方法实现了高达23.7%的性能提升，成为一种高效的单步学习器，同时通过多步积分推动性能提升。

Conclusion: 通过非均匀时间调度和密集跳跃积分的新型策略设计，有效解决了流匹配框架中的泛化和稳定性问题，为机器人学习提供了更高质量的生成策略。

Abstract: Flow matching has emerged as a competitive framework for learning
high-quality generative policies in robotics; however, we find that
generalisation arises and saturates early along the flow trajectory, in
accordance with recent findings in the literature. We further observe that
increasing the number of Euler integration steps during inference
counter-intuitively and universally degrades policy performance. We attribute
this to (i) additional, uniformly spaced integration steps oversample the
late-time region, thereby constraining actions towards the training
trajectories and reducing generalisation; and (ii) the learned velocity field
becoming non-Lipschitz as integration time approaches 1, causing instability.
To address these issues, we propose a novel policy that utilises non-uniform
time scheduling (e.g., U-shaped) during training, which emphasises both early
and late temporal stages to regularise policy training, and a dense-jump
integration schedule at inference, which uses a single-step integration to
replace the multi-step integration beyond a jump point, to avoid unstable areas
around 1. Essentially, our policy is an efficient one-step learner that still
pushes forward performance through multi-step integration, yielding up to 23.7%
performance gains over state-of-the-art baselines across diverse robotic tasks.

</details>


### [102] [TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning](https://arxiv.org/abs/2509.13579)
*Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu*

Main category: cs.RO

TL;DR: TreeIRL结合MCTS和IRL的自动驾驶规划器，在仿真和真实道路测试中表现优异，平衡安全性、进度、舒适度和人类相似性


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶规划瓶颈，结合经典方法和学习方法的优势，实现更安全、更人性化的驾驶决策

Method: 使用MCTS生成安全候选轨迹，通过深度IRL评分函数选择最像人类的轨迹

Result: 在大规模仿真和拉斯维加斯500+英里真实道路测试中表现最佳，涵盖密集城市交通、自适应巡航、切入和交通灯等多种场景

Conclusion: 首次在公共道路上展示MCTS规划，强调多维度评估的重要性，为探索经典与学习方法的组合提供了可扩展框架

Abstract: We present TreeIRL, a novel planner for autonomous driving that combines
Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to
achieve state-of-the-art performance in simulation and in real-world driving.
The core idea is to use MCTS to find a promising set of safe candidate
trajectories and a deep IRL scoring function to select the most human-like
among them. We evaluate TreeIRL against both classical and state-of-the-art
planners in large-scale simulations and on 500+ miles of real-world autonomous
driving in the Las Vegas metropolitan area. Test scenarios include dense urban
traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves
the best overall performance, striking a balance between safety, progress,
comfort, and human-likeness. To our knowledge, our work is the first
demonstration of MCTS-based planning on public roads and underscores the
importance of evaluating planners across a diverse set of metrics and in
real-world environments. TreeIRL is highly extensible and could be further
improved with reinforcement learning and imitation learning, providing a
framework for exploring different combinations of classical and learning-based
approaches to solve the planning bottleneck in autonomous driving.

</details>


### [103] [Object Pose Estimation through Dexterous Touch](https://arxiv.org/abs/2509.13591)
*Amir-Hossein Shahidzadeh,Jiyue Zhu,Kezhou Chen,Sha Yi,Cornelia Fermüller,Yiannis Aloimonos,Xiaolong Wang*

Main category: cs.RO

TL;DR: 使用强化学习和双手协作的触觉探索方法，通过主动交互收集3D点云数据来迭代优化物体姿态估计，无需先验几何知识


<details>
  <summary>Details</summary>
Motivation: 解决在视觉数据受限或受光照、遮挡、外观影响时，机器人操作任务中稳健物体姿态估计的挑战。触觉传感器提供有限局部信息，难以从部分数据重建姿态

Method: 采用传感器运动探索策略，使用强化学习训练机器人手主动与物体交互。双手协作：一只手固定物体，另一只手进行主动探索，收集3D点云数据迭代优化物体形状和姿态

Result: 方法能够主动探索物体表面以识别关键姿态特征，无需物体几何形状的先验知识

Conclusion: 提出的双手触觉姿态估计方法通过主动探索和强化学习，有效解决了在视觉受限环境下物体姿态估计的问题

Abstract: Robust object pose estimation is essential for manipulation and interaction
tasks in robotics, particularly in scenarios where visual data is limited or
sensitive to lighting, occlusions, and appearances. Tactile sensors often offer
limited and local contact information, making it challenging to reconstruct the
pose from partial data. Our approach uses sensorimotor exploration to actively
control a robot hand to interact with the object. We train with Reinforcement
Learning (RL) to explore and collect tactile data. The collected 3D point
clouds are used to iteratively refine the object's shape and pose. In our
setup, one hand holds the object steady while the other performs active
exploration. We show that our method can actively explore an object's surface
to identify critical pose features without prior knowledge of the object's
geometry. Supplementary material and more demonstrations will be provided at
https://amirshahid.github.io/BimanualTactilePose .

</details>


### [104] [Leg-Arm Coordinated Operation for Curtain Wall Installation](https://arxiv.org/abs/2509.13595)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 提出基于分层优化的六足幕墙安装机器人全身控制框架，解决传统幕墙安装方法效率低、安全风险高的问题，实现了臂腿协调规划，在三种关键任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统幕墙安装方法面临现场地形多变、劳动强度大、施工效率低和安全风险高等挑战，需要多人协作完成大型面板安装，亟需自动化解决方案。

Method: 基于六足幕墙安装机器人，设计了分层优化的全身控制框架，集成了六足腿运动、折叠臂操作和串并联机械手的协调臂腿规划，专门针对墙面安装、天花板安装和地板铺设三种关键任务。

Result: 在六足幕墙安装机器人上进行的实验验证了所提控制方法的有效性，证明了该机器人能够成功执行幕墙安装任务。

Conclusion: 分层优化的臂腿协调框架对六足机器人有效，为其在复杂施工现场环境的进一步应用奠定了基础。

Abstract: With the acceleration of urbanization, the number of high-rise buildings and
large public facilities is increasing, making curtain walls an essential
component of modern architecture with widespread applications. Traditional
curtain wall installation methods face challenges such as variable on-site
terrain, high labor intensity, low construction efficiency, and significant
safety risks. Large panels often require multiple workers to complete
installation. To address these issues, based on a hexapod curtain wall
installation robot, we design a hierarchical optimization-based whole-body
control framework for coordinated arm-leg planning tailored to three key tasks:
wall installation, ceiling installation, and floor laying. This framework
integrates the motion of the hexapod legs with the operation of the folding arm
and the serial-parallel manipulator. We conduct experiments on the hexapod
curtain wall installation robot to validate the proposed control method,
demonstrating its capability in performing curtain wall installation tasks. Our
results confirm the effectiveness of the hierarchical optimization-based
arm-leg coordination framework for the hexapod robot, laying the foundation for
its further application in complex construction site environments.

</details>


### [105] [Barometer-Aided Attitude Estimation](https://arxiv.org/abs/2509.13649)
*Méloné Nyoba Tchonkeu,Soulaimane Berkane,Tarek Hamel*

Main category: cs.RO

TL;DR: 提出了一种基于气压计的姿态估计架构，利用气压高度测量来推断垂直速度和姿态，通过非线性观测器在SO(3)上实现几乎全局渐近稳定性。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止或高动态环境中，仅使用IMU无法可靠估计倾斜姿态，而辅助速度传感器可能不可用、间歇性或成本高昂。

Method: 设计了一个确定性Riccati观测器与互补滤波器级联的架构，利用气压高度测量推断垂直速度和姿态，在SO(3)上实现非线性观测。

Result: 在满足一致可观测性条件下，系统实现了几乎全局渐近稳定性(AGAS)，同时保持几何一致性。

Conclusion: 气压计辅助估计是一种轻量级且有效的补充模态，为自主车辆在挑战性环境中提供了可靠的态度估计解决方案。

Abstract: Accurate and robust attitude estimation is a central challenge for autonomous
vehicles operating in GNSS-denied or highly dynamic environments. In such
cases, Inertial Measurement Units (IMUs) alone are insufficient for reliable
tilt estimation due to the ambiguity between gravitational and inertial
accelerations. While auxiliary velocity sensors, such as GNSS, Pitot tubes,
Doppler radar, or visual odometry, are often used, they can be unavailable,
intermittent, or costly. This work introduces a barometer-aided attitude
estimation architecture that leverages barometric altitude measurements to
infer vertical velocity and attitude within a nonlinear observer on SO(3). The
design cascades a deterministic Riccati observer with a complementary filter,
ensuring Almost Global Asymptotic Stability (AGAS) under a uniform
observability condition while maintaining geometric consistency. The analysis
highlights barometer-aided estimation as a lightweight and effective
complementary modality.

</details>


### [106] [DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring](https://arxiv.org/abs/2509.13666)
*Zhenqi Wu,Abhinav Modi,Angelos Mavrogiannis,Kaustubh Joshi,Nikhil Chopra,Yiannis Aloimonos,Nare Karapetyan,Ioannis Rekleitis,Xiaomin Lin*

Main category: cs.RO

TL;DR: 提出了DREAM框架，这是一个基于视觉语言模型的自主系统，用于长期水下探索和栖息地监测，特别是在海洋变暖和酸化的背景下监测牡蛎等敏感物种。


<details>
  <summary>Details</summary>
Motivation: 海洋变暖和酸化增加了温度敏感贝类（如牡蛎）大规模死亡事件的风险，需要开发长期监测系统。人工监测成本高且危险，因此需要机器人解决方案来实现持久、广域、低成本的海底监测。

Method: 开发了DREAM框架，这是一个视觉语言模型（VLM）引导的自主框架，使水下机器人能够在不依赖人类干预的情况下做出实时、环境感知的决策。

Result: 在牡蛎监测任务中，比先前基线节省31.5%的时间；相比普通VLM，使用步骤减少23%同时覆盖更多牡蛎（8.88%）。在沉船场景中，成功探索并绘制沉船地图而无碰撞，步骤减少27.5%，达到100%覆盖率（普通模型仅为60.23%）。

Conclusion: DREAM框架为水下长期监测提供了一种高效、自主的解决方案，显著提高了目标探测效率和覆盖率，为海洋生态保护提供了重要的技术支撑。

Abstract: The ocean is warming and acidifying, increasing the risk of mass mortality
events for temperature-sensitive shellfish such as oysters. This motivates the
development of long-term monitoring systems. However, human labor is costly and
long-duration underwater work is highly hazardous, thus favoring robotic
solutions as a safer and more efficient option. To enable underwater robots to
make real-time, environment-aware decisions without human intervention, we must
equip them with an intelligent "brain." This highlights the need for
persistent,wide-area, and low-cost benthic monitoring. To this end, we present
DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term
underwater exploration and habitat monitoring. The results show that our
framework is highly efficient in finding and exploring target objects (e.g.,
oysters, shipwrecks) without prior location information. In the
oyster-monitoring task, our framework takes 31.5% less time than the previous
baseline with the same amount of oysters. Compared to the vanilla VLM, it uses
23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our
framework successfully explores and maps the wreck without collisions,
requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,
while the vanilla model achieves 60.23% average coverage in our shipwreck
environments.

</details>


### [107] [SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics](https://arxiv.org/abs/2509.13691)
*Songhao Huang,Yuwei Wu,Guangyao Shi,Gaurav S. Sukhatme,Vijay Kumar*

Main category: cs.RO

TL;DR: 使用大型语言模型自动生成PDDL规划领域，特别针对无人机任务，提出SPAR框架从自然语言输入生成有效、多样且语义准确的PDDL领域


<details>
  <summary>Details</summary>
Motivation: PDDL是机器人规划中广泛采用的标准，但为不同应用手动设计领域既费时又容易出错，阻碍了实际部署和采用

Method: 首先构建系统化验证的无人机规划数据集，包含真实PDDL领域和相关问题；然后设计提示框架从语言输入生成高质量PDDL领域；通过语法验证、可执行性、可行性和可解释性进行评估

Result: 证明LLMs能够显著加速复杂规划领域的创建，提供可复现的数据集和评估流程

Conclusion: 该工作使没有先前经验的应用专家能够利用它完成实际任务，并推动空中机器人和自动化规划的未来研究

Abstract: We investigate the problem of automatic domain generation for the Planning
Domain Definition Language (PDDL) using Large Language Models (LLMs), with a
particular focus on unmanned aerial vehicle (UAV) tasks. Although PDDL is a
widely adopted standard in robotic planning, manually designing domains for
diverse applications such as surveillance, delivery, and inspection is
labor-intensive and error-prone, which hinders adoption and real-world
deployment. To address these challenges, we propose SPAR, a framework that
leverages the generative capabilities of LLMs to automatically produce valid,
diverse, and semantically accurate PDDL domains from natural language input. To
this end, we first introduce a systematically formulated and validated UAV
planning dataset, consisting of ground-truth PDDL domains and associated
problems, each paired with detailed domain and action descriptions. Building on
this dataset, we design a prompting framework that generates high-quality PDDL
domains from language input. The generated domains are evaluated through syntax
validation, executability, feasibility, and interpretability. Overall, this
work demonstrates that LLMs can substantially accelerate the creation of
complex planning domains, providing a reproducible dataset and evaluation
pipeline that enables application experts without prior experience to leverage
it for practical tasks and advance future research in aerial robotics and
automated planning.

</details>


### [108] [HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion](https://arxiv.org/abs/2509.13692)
*Yadan Zeng,Jiadong Zhou,Xiaohan Li,I-Ming Chen*

Main category: cs.RO

TL;DR: HGACNet是一个新颖的点云补全框架，通过分层图注意力编码器和多尺度跨模态融合模块，结合单视图RGB图像引导，实现高质量的点云补全。


<details>
  <summary>Details</summary>
Motivation: 解决由于自遮挡和传感器限制导致的不完整几何形状问题，这些不完整性会显著降低下游推理和交互任务的性能。

Method: 使用分层图注意力编码器自适应选择关键局部点，通过基于图注意力的下采样逐步细化分层几何特征；设计多尺度跨模态融合模块进行注意力特征对齐；提出对比损失来显式对齐跨模态特征分布。

Result: 在ShapeNet-ViPC基准和YCB-Complete数据集上的广泛实验证实了HGACNet的有效性，展示了最先进的性能以及在真实世界机器人操作任务中的强大适用性。

Conclusion: HGACNet通过分层几何特征编码和图像引导先验的融合，成功解决了点云补全问题，在性能和实际应用方面都表现出色。

Abstract: Point cloud completion is essential for robotic perception, object
reconstruction and supporting downstream tasks like grasp planning, obstacle
avoidance, and manipulation. However, incomplete geometry caused by
self-occlusion and sensor limitations can significantly degrade downstream
reasoning and interaction. To address these challenges, we propose HGACNet, a
novel framework that reconstructs complete point clouds of individual objects
by hierarchically encoding 3D geometric features and fusing them with
image-guided priors from a single-view RGB image. At the core of our approach,
the Hierarchical Graph Attention (HGA) encoder adaptively selects critical
local points through graph attention-based downsampling and progressively
refines hierarchical geometric features to better capture structural continuity
and spatial relationships. To strengthen cross-modal interaction, we further
design a Multi-Scale Cross-Modal Fusion (MSCF) module that performs
attention-based feature alignment between hierarchical geometric features and
structured visual representations, enabling fine-grained semantic guidance for
completion. In addition, we proposed the contrastive loss (C-Loss) to
explicitly align the feature distributions across modalities, improving
completion fidelity under modality discrepancy. Finally, extensive experiments
conducted on both the ShapeNet-ViPC benchmark and the YCB-Complete dataset
confirm the effectiveness of HGACNet, demonstrating state-of-the-art
performance as well as strong applicability in real-world robotic manipulation
tasks.

</details>


### [109] [EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility](https://arxiv.org/abs/2509.13720)
*Tianle Zeng,Jianwei Peng,Hanjing Ye,Guangcheng Chen,Senzi Luo,Hong Zhang*

Main category: cs.RO

TL;DR: 提出了一种用于室外零样本目标导航的统一轻量级系统，通过多尺度图像瓦片层次结构和分层目标显著性融合，有效处理远距离小目标和间歇性遮挡问题


<details>
  <summary>Details</summary>
Motivation: 解决室外零样本目标导航中的关键挑战：远距离目标投影过小和间歇性可见性问题，这些因素导致传统方法难以稳定导航

Method: 构建对齐的多尺度图像瓦片层次结构，通过分层目标显著性融合将局部语义对比汇总为稳定的粗层区域显著性，支持可见性感知的航向维护和主动搜索

Result: 在仿真和真实室外试验中，系统能检测150米外的语义目标，在可见性变化下以82.6%的概率保持正确航向，相比最先进方法提高17.5%的任务成功率

Conclusion: 该系统为远距离和间歇可见目标的鲁棒零样本导航提供了有效解决方案，避免了全图像缩放，支持确定性自底向上聚合，并在移动机器人上高效运行

Abstract: Zero-shot object navigation (ZSON) in large-scale outdoor environments faces
many challenges; we specifically address a coupled one: long-range targets that
reduce to tiny projections and intermittent visibility due to partial or
complete occlusion. We present a unified, lightweight closed-loop system built
on an aligned multi-scale image tile hierarchy. Through hierarchical
target-saliency fusion, it summarizes localized semantic contrast into a stable
coarse-layer regional saliency that provides the target direction and indicates
target visibility. This regional saliency supports visibility-aware heading
maintenance through keyframe memory, saliency-weighted fusion of historical
headings, and active search during temporary invisibility. The system avoids
whole-image rescaling, enables deterministic bottom-up aggregation, supports
zero-shot navigation, and runs efficiently on a mobile robot. Across simulation
and real-world outdoor trials, the system detects semantic targets beyond 150m,
maintains a correct heading through visibility changes with 82.6% probability,
and improves overall task success by 17.5% compared with the SOTA methods,
demonstrating robust ZSON toward distant and intermittently observable targets.

</details>


### [110] [Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings](https://arxiv.org/abs/2509.13731)
*Jeongwoo Park,Seabin Lee,Changmin Park,Wonjong Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 提出了一种基于基础模型的RL算法，用于柔性扁平电缆(FFC)插入任务，通过语义分割掩码实现sim-to-real迁移，无需真实环境训练即可实现零样本部署


<details>
  <summary>Details</summary>
Motivation: 工业FFC插入需要亚毫米级精度，传统方法需要人工轨迹生成，RL训练存在非确定性和安全风险，需要减少训练时间并消除物理损坏风险

Method: 使用基础模型(SAM2)进行语义分割，保留电缆和插座的相关几何空间信息，结合VLM自动生成分割提示，在仿真环境中进行RL训练

Result: 方法表现出零样本能力，可直接部署到真实环境而无需微调

Conclusion: 提出的基于基础模型的sim-to-real方法有效解决了FFC插入任务的训练挑战，实现了安全高效的自动化部署

Abstract: The industrial insertion of flexible flat cables (FFCs) into receptacles
presents a significant challenge owing to the need for submillimeter precision
when handling the deformable cables. In manufacturing processes, FFC insertion
with robotic manipulators often requires laborious human-guided trajectory
generation. While Reinforcement Learning (RL) offers a solution to automate
this task without modeling complex properties of FFCs, the nondeterminism
caused by the deformability of FFCs requires significant efforts and time on
training. Moreover, training directly in a real environment is dangerous as
industrial robots move fast and possess no safety measure. We propose an RL
algorithm for FFC insertion that leverages a foundation model-based real-to-sim
approach to reduce the training time and eliminate the risk of physical damages
to robots and surroundings. Training is done entirely in simulation, allowing
for random exploration without the risk of physical damages. Sim-to-real
transfer is achieved through semantic segmentation masks which leave only those
visual features relevant to the insertion tasks such as the geometric and
spatial information of the cables and receptacles. To enhance generality, we
use a foundation model, Segment Anything Model 2 (SAM2). To eleminate human
intervention, we employ a Vision-Language Model (VLM) to automate the initial
prompting of SAM2 to find segmentation masks. In the experiments, our method
exhibits zero-shot capabilities, which enable direct deployments to real
environments without fine-tuning.

</details>


### [111] [FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph](https://arxiv.org/abs/2509.13733)
*Xiaolin Zhou,Tingyang Xiao,Liu Liu,Yucheng Wang,Maiyue Chen,Xinrui Meng,Xinjie Wang,Wei Feng,Wei Sui,Zhizhong Su*

Main category: cs.RO

TL;DR: FSR-VLN是一个视觉语言导航系统，通过分层多模态场景图和快慢推理机制，在长距离导航任务中实现了SOTA性能，响应时间减少82%，并成功集成到人形机器人实现实时导航。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法在长距离空间推理方面存在局限，表现为低成功率高延迟，特别是在长距离导航任务中。需要一种能够高效处理多模态信息并实现快速准确导航的系统。

Method: 提出FSR-VLN系统，结合分层多模态场景图(HMSG)和快慢导航推理(FSR)。HMSG提供从粗粒度房间定位到细粒度目标视图和物体识别的渐进检索，FSR先进行快速匹配选择候选，再用VLM驱动的精炼进行最终目标选择。

Result: 在4个室内数据集上评估，使用87条涵盖多样物体类别的指令。FSR-VLN在所有数据集上都达到SOTA性能（检索成功率），响应时间比基于VLM的方法减少82%，仅在快速直觉失败时才激活慢速推理。

Conclusion: FSR-VLN成功解决了长距离视觉语言导航的挑战，通过分层多模态表示和高效推理机制实现了高性能和低延迟，并成功集成到人形机器人平台实现自然语言交互和实时导航。

Abstract: Visual-Language Navigation (VLN) is a fundamental challenge in robotic
systems, with broad applications for the deployment of embodied agents in
real-world environments. Despite recent advances, existing approaches are
limited in long-range spatial reasoning, often exhibiting low success rates and
high inference latency, particularly in long-range navigation tasks. To address
these limitations, we propose FSR-VLN, a vision-language navigation system that
combines a Hierarchical Multi-modal Scene Graph (HMSG) with Fast-to-Slow
Navigation Reasoning (FSR). The HMSG provides a multi-modal map representation
supporting progressive retrieval, from coarse room-level localization to
fine-grained goal view and object identification. Building on HMSG, FSR first
performs fast matching to efficiently select candidate rooms, views, and
objects, then applies VLM-driven refinement for final goal selection. We
evaluated FSR-VLN across four comprehensive indoor datasets collected by
humanoid robots, utilizing 87 instructions that encompass a diverse range of
object categories. FSR-VLN achieves state-of-the-art (SOTA) performance in all
datasets, measured by the retrieval success rate (RSR), while reducing the
response time by 82% compared to VLM-based methods on tour videos by activating
slow reasoning only when fast intuition fails. Furthermore, we integrate
FSR-VLN with speech interaction, planning, and control modules on a Unitree-G1
humanoid robot, enabling natural language interaction and real-time navigation.

</details>


### [112] [Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning](https://arxiv.org/abs/2509.13736)
*Muyuan Ma,Long Cheng,Lijun Han,Xiuze Xia,Houcheng Li*

Main category: cs.RO

TL;DR: 提出基于元模仿学习的可穿戴外骨骼控制框架，通过从RGB视频提取运动数据训练任务特定神经网络，实现对新任务和新用户的快速适应，显著降低肌肉激活和代谢成本


<details>
  <summary>Details</summary>
Motivation: 开发个性化和任务通用的外骨骼辅助算法是可穿戴外骨骼领域的关键挑战，需要解决新用户和新任务的泛化问题

Method: 使用公开RGB视频和运动捕捉数据集提取全身关键点运动，在仿真中重定向生成肘关节屈曲轨迹，在MAML框架下训练任务特定神经网络，通过重力补偿PD控制器实现稳定辅助

Result: 实验结果表明，外骨骼显著降低了新用户执行未训练任务时的肌肉激活和代谢成本，相比无辅助状态有明显改善

Conclusion: 该框架有效提高了可穿戴外骨骼系统的任务泛化能力和用户适应性，为个性化辅助算法开发提供了有效解决方案

Abstract: Wearable exoskeletons can augment human strength and reduce muscle fatigue
during specific tasks. However, developing personalized and task-generalizable
assistance algorithms remains a critical challenge. To address this, a
meta-imitation learning approach is proposed. This approach leverages a
task-specific neural network to predict human elbow joint movements, enabling
effective assistance while enhancing generalization to new scenarios. To
accelerate data collection, full-body keypoint motions are extracted from
publicly available RGB video and motion-capture datasets across multiple tasks,
and subsequently retargeted in simulation. Elbow flexion trajectories generated
in simulation are then used to train the task-specific neural network within
the model-agnostic meta-learning (MAML) framework, which allows the network to
rapidly adapt to novel tasks and unseen users with only a few gradient updates.
The adapted network outputs personalized references tracked by a
gravity-compensated PD controller to ensure stable assistance. Experimental
results demonstrate that the exoskeleton significantly reduces both muscle
activation and metabolic cost for new users performing untrained tasks,
compared to performing without exoskeleton assistance. These findings suggest
that the proposed framework effectively improves task generalization and user
adaptability for wearable exoskeleton systems.

</details>


### [113] [Dynamic Adaptive Legged Locomotion Policy via Decoupling Reaction Force Control and Gait Control](https://arxiv.org/abs/2509.13737)
*Renjie Wang,Shangke Lyu,Donglin Wang*

Main category: cs.RO

TL;DR: 提出解耦框架分离支撑腿和摆动腿控制，通过在线快速适应能力解决强化学习在腿式运动控制中的分布外泛化问题和仿真到现实的差距。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在腿式运动控制中面临分布外条件性能下降和仿真-现实环境差异问题，主要依赖域随机化方法覆盖真实环境存在局限性。

Method: 采用解耦框架，将支撑腿控制和摆动腿控制分离，获得快速在线适应能力，从而在不熟悉环境中缓解仿真到现实的问题。

Result: 在仿真和真实世界实验中证明该方法能有效应对水平力干扰、不平坦地形、重载和偏置载荷以及仿真到现实差距等多种挑战。

Conclusion: 解耦控制框架为解决腿式运动控制的鲁棒性和仿真到现实迁移问题提供了有效的新途径，相比传统域随机化方法具有更好的适应性能。

Abstract: While Reinforcement Learning (RL) has achieved remarkable progress in legged
locomotion control, it often suffers from performance degradation in
out-of-distribution (OOD) conditions and discrepancies between the simulation
and the real environments. Instead of mainly relying on domain randomization
(DR) to best cover the real environments and thereby close the sim-to-real gap
and enhance robustness, this work proposes an emerging decoupled framework that
acquires fast online adaptation ability and mitigates the sim-to-real problems
in unfamiliar environments by isolating stance-leg control and swing-leg
control. Various simulation and real-world experiments demonstrate its
effectiveness against horizontal force disturbances, uneven terrains, heavy and
biased payloads, and sim-to-real gap.

</details>


### [114] [CDFlow: Generative Gradient Flows for Configuration Space Distance Fields via Neural ODEs](https://arxiv.org/abs/2509.13771)
*Mengzhu Li,Yunyu Zhou,He Ying,F. Richard Yu*

Main category: cs.RO

TL;DR: CDFlow是一个基于神经ODE的新框架，通过建模最小距离碰撞配置的多模态分布来解决传统CDF在高自由度机器人中的梯度模糊和几何失真问题


<details>
  <summary>Details</summary>
Motivation: 传统配置空间距离场(CDF)在高自由度机器人中存在两个主要问题：1)只能返回单个最近碰撞配置，忽略了多模态特性导致梯度模糊；2)依赖稀疏采样，无法识别真正最近配置，产生过度平滑的近似和几何失真

Method: 提出CDFlow框架，使用神经ODE学习配置空间中的连续流，重新定义问题为建模最小距离碰撞配置的分布，并引入自适应细化采样策略生成高质量训练数据

Result: 神经ODE隐式建模多模态分布，产生平滑一致的梯度场，缓解梯度模糊并保持锐利几何特征。在高自由度运动规划任务中显著提高了规划效率、轨迹质量和鲁棒性

Conclusion: CDFlow能够为碰撞感知机器人在复杂环境中提供更鲁棒和高效的规划能力，相比现有CDF方法有显著改进

Abstract: Signed Distance Fields (SDFs) are a fundamental representation in robot
motion planning. Their configuration-space counterpart, the Configuration Space
Distance Field (CDF), directly encodes distances in joint space, offering a
unified representation for optimization and control. However, existing CDF
formulations face two major challenges in high-degree-of-freedom (DoF) robots:
(1) they effectively return only a single nearest collision configuration,
neglecting the multi-modal nature of minimal-distance collision configurations
and leading to gradient ambiguity; and (2) they rely on sparse sampling of the
collision boundary, which often fails to identify the true closest
configurations, producing oversmoothed approximations and geometric distortion
in high-dimensional spaces. We propose CDFlow, a novel framework that addresses
these limitations by learning a continuous flow in configuration space via
Neural Ordinary Differential Equations (Neural ODEs). We redefine the problem
from finding a single nearest point to modeling the distribution of
minimal-distance collision configurations. We also introduce an adaptive
refinement sampling strategy to generate high-fidelity training data for this
distribution. The resulting Neural ODE implicitly models this multi-modal
distribution and produces a smooth, consistent gradient field-derived as the
expected direction towards the distribution-that mitigates gradient ambiguity
and preserves sharp geometric features. Extensive experiments on high-DoF
motion planning tasks demonstrate that CDFlow significantly improves planning
efficiency, trajectory quality, and robustness compared to existing CDF-based
methods, enabling more robust and efficient planning for collision-aware robots
in complex environments.

</details>


### [115] [Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach](https://arxiv.org/abs/2509.13774)
*Piaopiao Jin,Qi Wang,Guokang Sun,Ziwen Cai,Pinjia He,Yangwei You*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的人类在环双执行器微调框架，通过语言命令将人类修正转化为语义基础的数据集，在真实世界多任务中实现快速高效的学习和扩展。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在机器人操作中表现出良好的泛化能力，但在复杂现实任务中面临挑战。监督微调受限于数据质量，而强化学习提供了有前景的替代方案。

Method: 人类在环双执行器微调框架：包含主执行器负责鲁棒多任务性能，精炼执行器负责潜在空间适应。引入轻量级talk-and-tweak方案，将人类修正转化为语义基础的语言命令，生成新的策略学习数据集。

Result: 真实世界多任务实验中，101分钟在线微调内实现3个任务100%成功率；长时域任务中保持12个连续操作50%成功率；多机器人训练效率提升2倍。

Conclusion: 该框架通过人类在环的强化学习微调，有效解决了复杂现实任务中的挑战，实现了高效的多任务学习和多机器人扩展。

Abstract: Vision-language-action (VLA) models demonstrate strong generalization in
robotic manipulation but face challenges in complex, real-world tasks. While
supervised fine-tuning with demonstrations is constrained by data quality,
reinforcement learning (RL) offers a promising alternative. We propose a
human-in-the-loop dual-actor fine-tuning framework grounded in RL. The
framework integrates a primary actor for robust multi-task performance with a
refinement actor for latent-space adaptation. Beyond standard physical
interventions, we introduce a lightweight talk-and-tweak scheme that converts
human corrections into semantically grounded language commands, thereby
generating a new dataset for policy learning. In real-world multi-task
experiments, our approach achieves 100% success across three tasks within 101
minutes of online fine-tuning. For long-horizon tasks, it sustains a 50%
success rate over 12 consecutive operations. Furthermore, the framework scales
effectively to multi-robot training, achieving up to a 2 times improvement in
efficiency when using dual robots. The experiment videos are available at
https://sites.google.com/view/hil-daft/.

</details>


### [116] [Reinforcement Learning for Autonomous Point-to-Point UAV Navigation](https://arxiv.org/abs/2509.13943)
*Salim Oyinlola,Nitesh Subedi,Soumik Sarkar*

Main category: cs.RO

TL;DR: 开发基于强化学习的无人机自主导航系统，通过试错学习实现点对点导航，在真实无人机平台上验证了有效性


<details>
  <summary>Details</summary>
Motivation: 无人机在自动化检查、配送和导航任务中需要可靠自主性，传统方法依赖人工干预，需要开发无需人工干预的自主导航解决方案

Method: 采用强化学习方法，设计自定义奖励函数鼓励高效到达目标并惩罚碰撞和不安全行为，集成ROS和Gym兼容训练环境

Result: 训练后的策略在真实无人机平台上成功实现自主导航，只需最少人工监督，证明了RL控制在现实场景中的可行性

Conclusion: 强化学习方法可有效实现无人机点对点自主导航，为实际应用提供了可行的技术方案

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly used in automated
inspection, delivery, and navigation tasks that require reliable autonomy. This
project develops a reinforcement learning (RL) approach to enable a single UAV
to autonomously navigate between predefined points without manual intervention.
The drone learns navigation policies through trial-and-error interaction, using
a custom reward function that encourages goal-reaching efficiency while
penalizing collisions and unsafe behavior. The control system integrates ROS
with a Gym-compatible training environment, enabling flexible deployment and
testing. After training, the learned policy is deployed on a real UAV platform
and evaluated under practical conditions. Results show that the UAV can
successfully perform autonomous navigation with minimal human oversight,
demonstrating the viability of RL-based control for point-to-point drone
operations in real-world scenarios.

</details>


### [117] [Behavior Foundation Model for Humanoid Robots](https://arxiv.org/abs/2509.13780)
*Weishuai Zeng,Shunlin Lu,Kangning Yin,Xiaojie Niu,Minyue Dai,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出了行为基础模型（BFM），这是一个基于大规模行为数据集预训练的生成模型，用于人形机器人的全身控制，能够跨任务泛化并快速适应新行为。


<details>
  <summary>Details</summary>
Motivation: 现有全身控制框架任务特定性强，依赖人工奖励工程，跨任务泛化能力有限，难以应对复杂现实场景中的任意控制模式。

Method: 采用掩码在线蒸馏框架与条件变分自编码器（CVAE）结合，建模行为分布，支持多种控制模式的灵活操作和新行为的高效获取。

Result: 在仿真和物理人形平台上的大量实验表明，BFM能够跨多种全身控制任务稳健泛化，并快速适应新行为。

Conclusion: BFM为通用人形控制的基础模型迈出了有希望的一步，展示了在复杂场景中的广泛应用潜力。

Abstract: Whole-body control (WBC) of humanoid robots has witnessed remarkable progress
in skill versatility, enabling a wide range of applications such as locomotion,
teleoperation, and motion tracking. Despite these achievements, existing WBC
frameworks remain largely task-specific, relying heavily on labor-intensive
reward engineering and demonstrating limited generalization across tasks and
skills. These limitations hinder their response to arbitrary control modes and
restrict their deployment in complex, real-world scenarios. To address these
challenges, we revisit existing WBC systems and identify a shared objective
across diverse tasks: the generation of appropriate behaviors that guide the
robot toward desired goal states. Building on this insight, we propose the
Behavior Foundation Model (BFM), a generative model pretrained on large-scale
behavioral datasets to capture broad, reusable behavioral knowledge for
humanoid robots. BFM integrates a masked online distillation framework with a
Conditional Variational Autoencoder (CVAE) to model behavioral distributions,
thereby enabling flexible operation across diverse control modes and efficient
acquisition of novel behaviors without retraining from scratch. Extensive
experiments in both simulation and on a physical humanoid platform demonstrate
that BFM generalizes robustly across diverse WBC tasks while rapidly adapting
to new behaviors. These results establish BFM as a promising step toward a
foundation model for general-purpose humanoid control.

</details>


### [118] [Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning](https://arxiv.org/abs/2509.14040)
*Zewen Yang,Xiaobing Dai,Dongfa Zhang,Yu Li,Ziyang Meng,Bingkun Huang,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: Prompt2Auto是一个几何不变的单样本高斯过程学习框架，通过坐标变换实现平移、旋转和缩放不变性，能够从单个运动提示中实现人类引导的自动化控制，显著减少演示负担。


<details>
  <summary>Details</summary>
Motivation: 传统的示教学习方法需要大量数据集且难以跨坐标变换泛化，限制了机器人在实际应用中的灵活性和效率。

Method: 提出几何不变高斯过程(GeoGP)框架，基于坐标变换的数据集构建策略，支持多步预测，对用户运动提示变化具有鲁棒性，并支持多技能自主。

Result: 通过数值仿真和两个真实机器人实验验证，证明该方法有效、能跨任务泛化，并显著减少演示需求。

Conclusion: Prompt2Auto提供了一个高效的单样本学习解决方案，能够从单个运动提示中实现鲁棒的自动化控制，具有良好的泛化能力和实用性。

Abstract: Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io

</details>


### [119] [Shell-Type Soft Jig for Holding Objects during Disassembly](https://arxiv.org/abs/2509.13802)
*Takuya Kiyokawa,Ryunosuke Takebayashi,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出了一种基于气囊的壳式软夹具，用于机器人拆卸中的柔性夹持，能够安全通用地夹持各种形状物体，减少对专用夹具设计和高精度感知的需求。


<details>
  <summary>Details</summary>
Motivation: 传统夹具需要专用设计、高精度感知、精确抓取和精细轨迹规划，容易造成部件损坏且适应性差。需要一种能够适应不同形状、减少对感知和控制精度要求的柔性夹持工具。

Method: 采用壳式软夹具设计，基于气囊的夹持机制，实现软固定和对识别、规划、控制错误的鲁棒性。通过气囊确保正确对齐和稳定夹持性能。

Result: 实验结果表明，与虎钳和基于堵塞抓手的软夹具相比，所提出的夹具具有实际可行性。在10种不同物体上的测试显示了代表性的成功和失败案例，明确了夹具的局限性和前景。

Conclusion: 气囊式壳式软夹具为机器人拆卸提供了一种有效的柔性夹持解决方案，能够减少对传统夹具所需的高精度要求，同时适应各种形状的物体，但仍有待进一步改进局限性。

Abstract: This study addresses a flexible holding tool for robotic disassembly. We
propose a shell-type soft jig that securely and universally holds objects,
mitigating the risk of component damage and adapting to diverse shapes while
enabling soft fixation that is robust to recognition, planning, and control
errors. The balloon-based holding mechanism ensures proper alignment and stable
holding performance, thereby reducing the need for dedicated jig design, highly
accurate perception, precise grasping, and finely tuned trajectory planning
that are typically required with conventional fixtures. Our experimental
results demonstrate the practical feasibility of the proposed jig through
performance comparisons with a vise and a jamming-gripper-inspired soft jig.
Tests on ten different objects further showed representative successes and
failures, clarifying the jig's limitations and outlook.

</details>


### [120] [Constraint-Consistent Control of Task-Based and Kinematic RCM Constraints for Surgical Robots](https://arxiv.org/abs/2509.14075)
*Yu Li,Hamid Sadeghian,Zewen Yang,Valentin Le Mesle,Sami Haddadin*

Main category: cs.RO

TL;DR: 本文提出了一种约束一致的扭矩控制器，用于机器人辅助微创手术中的远程运动中心约束，通过投影逆动力学框架实现精确工具尖端跟踪和扭矩平滑性。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助微创手术需要精确执行远程运动中心约束以确保手术安全，但现有控制方法在扭矩级别缺乏鲁棒性或无法保证一致的约束满足。

Method: 将RCM约束视为流变完整约束，嵌入到基于投影的逆动力学框架中，统一任务级和运动学表述，实现工具尖端精确跟踪和扭矩平滑。

Result: 在仿真和RAMIS训练平台上验证，相比现有方法改善了RCM约束满足度，降低了所需扭矩，在螺旋轨迹、可变插入深度、移动套管和人类交互等临床相关场景下表现出鲁棒性能。

Conclusion: 约束一致的扭矩控制方法有潜力提高手术机器人的安全性和可靠性。

Abstract: Robotic-assisted minimally invasive surgery (RAMIS) requires precise
enforcement of the remote center of motion (RCM) constraint to ensure safe tool
manipulation through a trocar. Achieving this constraint under dynamic and
interactive conditions remains challenging, as existing control methods either
lack robustness at the torque level or do not guarantee consistent RCM
constraint satisfaction. This paper proposes a constraint-consistent torque
controller that treats the RCM as a rheonomic holonomic constraint and embeds
it into a projection-based inverse-dynamics framework. The method unifies
task-level and kinematic formulations, enabling accurate tool-tip tracking
while maintaining smooth and efficient torque behavior. The controller is
validated both in simulation and on a RAMIS training platform, and is
benchmarked against state-of-the-art approaches. Results show improved RCM
constraint satisfaction, reduced required torque, and robust performance by
improving joint torque smoothness through the consistency formulation under
clinically relevant scenarios, including spiral trajectories, variable
insertion depths, moving trocars, and human interaction. These findings
demonstrate the potential of constraint-consistent torque control to enhance
safety and reliability in surgical robotics. The project page is available at:
https://rcmpc-cube.github.io

</details>


### [121] [Soft Regrasping Tool Inspired by Jamming Gripper](https://arxiv.org/abs/2509.13815)
*Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出一种基于阻塞转变现象的软夹具，通过真空吸附形成稳定空腔来适应不同几何形状的零件，实现高精度的重新抓取


<details>
  <summary>Details</summary>
Motivation: 传统刚性夹具缺乏适应性且需要为每个零件专门设计，为解决装配中位姿不确定性问题，需要开发通用性强的柔性夹具

Method: 使用三角形金字塔形状工具压入膜内并抽真空形成稳定空腔，优化压入深度以平衡放置稳定性和抓取器可达性

Result: 对10种不同形状机械零件的跌落实验显示，大多数物体放置成功率超过80%，圆柱形物体超过90%，失败主要由几何约束和膜特性引起

Conclusion: 所提出的软夹具能够实现通用、准确和可重复的重新抓取，是装配自动化中刚性夹具的实用替代方案，同时明确了当前局限性和未来潜力

Abstract: Regrasping on fixtures is a promising approach to reduce pose uncertainty in
robotic assembly, but conventional rigid fixtures lack adaptability and require
dedicated designs for each part. To overcome this limitation, we propose a soft
jig inspired by the jamming transition phenomenon, which can be continuously
deformed to accommodate diverse object geometries. By pressing a
triangular-pyramid-shaped tool into the membrane and evacuating the enclosed
air, a stable cavity is formed as a placement space. We further optimize the
stamping depth to balance placement stability and gripper accessibility. In
soft-jig-based regrasping, the key challenge lies in optimizing the cavity size
to achieve precise dropping; once the part is reliably placed, subsequent
grasping can be performed with reduced uncertainty. Accordingly, we conducted
drop experiments on ten mechanical parts of varying shapes, which achieved
placement success rates exceeding 80% for most objects and above 90% for
cylindrical ones, while failures were mainly caused by geometric constraints
and membrane properties. These results demonstrate that the proposed jig
enables general-purpose, accurate, and repeatable regrasping, while also
clarifying its current limitations and future potential as a practical
alternative to rigid fixtures in assembly automation.

</details>


### [122] [Agile in the Face of Delay: Asynchronous End-to-End Learning for Real-World Aerial Navigation](https://arxiv.org/abs/2509.13816)
*Yude Li,Zhexuan Zhou,Huizhe Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: 提出异步强化学习框架解决无人机导航中高频控制与低频感知的冲突，通过时间编码模块处理感知延迟，实现100Hz控制频率和零样本仿真到现实的鲁棒导航


<details>
  <summary>Details</summary>
Motivation: 解决自主飞行器在复杂环境中导航时，高频控制需求与低频感知流之间的不匹配问题，传统同步模型被迫降低控制频率

Method: 异步强化学习框架，解耦感知和控制；时间编码模块(TEM)显式处理感知延迟；两阶段课程学习确保训练稳定性

Result: 在广泛仿真中验证，成功实现零样本仿真到现实迁移，在机载NUC上维持100Hz控制频率，在杂乱真实环境中展示鲁棒敏捷导航

Conclusion: 该方法有效解决了感知-控制频率不匹配问题，实现了高频响应的鲁棒自主导航，代码将开源供社区参考

Abstract: Robust autonomous navigation for Autonomous Aerial Vehicles (AAVs) in complex
environments is a critical capability. However, modern end-to-end navigation
faces a key challenge: the high-frequency control loop needed for agile flight
conflicts with low-frequency perception streams, which are limited by sensor
update rates and significant computational cost. This mismatch forces
conventional synchronous models into undesirably low control rates. To resolve
this, we propose an asynchronous reinforcement learning framework that
decouples perception and control, enabling a high-frequency policy to act on
the latest IMU state for immediate reactivity, while incorporating perception
features asynchronously. To manage the resulting data staleness, we introduce a
theoretically-grounded Temporal Encoding Module (TEM) that explicitly
conditions the policy on perception delays, a strategy complemented by a
two-stage curriculum to ensure stable and efficient training. Validated in
extensive simulations, our method was successfully deployed in zero-shot
sim-to-real transfer on an onboard NUC, where it sustains a 100~Hz control rate
and demonstrates robust, agile navigation in cluttered real-world environments.
Our source code will be released for community reference.

</details>


### [123] [UltraHiT: A Hierarchical Transformer Architecture for Generalizable Internal Carotid Artery Robotic Ultrasonography](https://arxiv.org/abs/2509.13832)
*Teng Wang,Haojun Jiang,Yuxuan Wang,Zhenguo Sun,Xiangjie Yan,Xiang Li,Gao Huang*

Main category: cs.RO

TL;DR: 提出基于分层Transformer的决策架构UltraHiT，用于自动化颈动脉超声扫描中的内颈动脉定位，通过高层变异评估和低层动作决策的集成，在未见个体上达到95%的成功率。


<details>
  <summary>Details</summary>
Motivation: 内颈动脉(ICA)由于位置深、路径曲折且个体差异大，是颈动脉超声扫描中最具挑战性的部位。现有研究未能有效解决ICA的自动化扫描问题，因此需要开发能够处理个体形态变异的新方法。

Method: 提出分层Transformer架构UltraHiT：1)高层模块识别血管形态变异并选择执行模块；2)低层模块包括针对变异的自适应校正器和针对正常情况的标准执行器；3)使用因果Transformer基于历史扫描序列生成预测；4)构建首个大规模ICA扫描数据集(164条轨迹，72K样本，28名受试者)。

Result: 在未见个体上实现了95%的ICA定位成功率，显著优于基线方法，证明了方法的有效性。

Conclusion: UltraHiT通过分层决策架构成功解决了内颈动脉自动化超声扫描的挑战，为脑血管健康评估提供了有效的自动化解决方案，代码将在接受后开源。

Abstract: Carotid ultrasound is crucial for the assessment of cerebrovascular health,
particularly the internal carotid artery (ICA). While previous research has
explored automating carotid ultrasound, none has tackled the challenging ICA.
This is primarily due to its deep location, tortuous course, and significant
individual variations, which greatly increase scanning complexity. To address
this, we propose a Hierarchical Transformer-based decision architecture, namely
UltraHiT, that integrates high-level variation assessment with low-level action
decision. Our motivation stems from conceptualizing individual vascular
structures as morphological variations derived from a standard vascular model.
The high-level module identifies variation and switches between two low-level
modules: an adaptive corrector for variations, or a standard executor for
normal cases. Specifically, both the high-level module and the adaptive
corrector are implemented as causal transformers that generate predictions
based on the historical scanning sequence. To ensure generalizability, we
collected the first large-scale ICA scanning dataset comprising 164
trajectories and 72K samples from 28 subjects of both genders. Based on the
above innovations, our approach achieves a 95% success rate in locating the ICA
on unseen individuals, outperforming baselines and demonstrating its
effectiveness. Our code will be released after acceptance.

</details>


### [124] [Track Any Motions under Any Disturbances](https://arxiv.org/abs/2509.13833)
*Zhikai Zhang,Jun Guo,Chao Chen,Jilong Wang,Chenghuai Lin,Yunrui Lian,Han Xue,Zhenrong Wang,Maoqi Liu,Huaping Liu,He Wang,Li Yi*

Main category: cs.RO

TL;DR: Any2Track是一个两阶段强化学习框架，用于在真实世界中跟踪各种运动并应对多种干扰，包括地形变化、外力和物理属性变化。


<details>
  <summary>Details</summary>
Motivation: 开发能够在真实世界场景中稳定运行的人形运动跟踪器，需要应对多样的动态干扰，包括地形、外力和物理属性变化，以实现通用实用。

Method: 提出两阶段RL框架Any2Track，包含AnyTracker（通用运动跟踪器）和AnyAdapter（历史信息适应模块），通过精心设计实现多种运动跟踪和在线动态适应能力。

Result: 在Unitree G1硬件上成功实现零样本sim2real迁移，在各种真实世界干扰下表现出色的运动跟踪性能。

Conclusion: Any2Track框架有效解决了人形机器人在真实环境中应对多种动态干扰的运动跟踪问题，实现了成功的sim2real转换。

Abstract: A foundational humanoid motion tracker is expected to be able to track
diverse, highly dynamic, and contact-rich motions. More importantly, it needs
to operate stably in real-world scenarios against various dynamics
disturbances, including terrains, external forces, and physical property
changes for general practical use. To achieve this goal, we propose Any2Track
(Track Any motions under Any disturbances), a two-stage RL framework to track
various motions under multiple disturbances in the real world. Any2Track
reformulates dynamics adaptability as an additional capability on top of basic
action execution and consists of two key components: AnyTracker and AnyAdapter.
AnyTracker is a general motion tracker with a series of careful designs to
track various motions within a single policy. AnyAdapter is a history-informed
adaptation module that endows the tracker with online dynamics adaptability to
overcome the sim2real gap and multiple real-world disturbances. We deploy
Any2Track on Unitree G1 hardware and achieve a successful sim2real transfer in
a zero-shot manner. Any2Track performs exceptionally well in tracking various
motions under multiple real-world disturbances.

</details>


### [125] [Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models](https://arxiv.org/abs/2509.13839)
*Motonari Kambara,Komei Sugiura*

Main category: cs.RO

TL;DR: 提出了一种预测开放式词汇物体操作任务未来成功率的模型，通过多级轨迹融合模块分析末端执行器轨迹的自相关性，在实验中获得优于现有方法的表现


<details>
  <summary>Details</summary>
Motivation: 传统方法只能在操作完成后判断成功与否，难以预防潜在危险且依赖失败触发重规划，降低了物体操作序列的效率

Method: 提出预测预操作自我中心图像与规划轨迹及自然语言指令对齐度的模型，采用多级轨迹融合模块（结合深度状态空间模型和Transformer编码器）来捕捉末端执行器轨迹的多级时间序列自相关性

Result: 实验结果表明该方法优于现有方法，包括基础模型

Conclusion: 该方法能够有效预测操作任务的成功率，提高操作效率和安全性

Abstract: In this work, we address the problem of predicting the future success of
open-vocabulary object manipulation tasks. Conventional approaches typically
determine success or failure after the action has been carried out. However,
they make it difficult to prevent potential hazards and rely on failures to
trigger replanning, thereby reducing the efficiency of object manipulation
sequences. To overcome these challenges, we propose a model, which predicts the
alignment between a pre-manipulation egocentric image with the planned
trajectory and a given natural language instruction. We introduce a Multi-Level
Trajectory Fusion module, which employs a state-of-the-art deep state-space
model and a transformer encoder in parallel to capture multi-level time-series
self-correlation within the end effector trajectory. Our experimental results
indicate that the proposed method outperformed existing methods, including
foundation models.

</details>


### [126] [InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap](https://arxiv.org/abs/2509.13857)
*Nguyen Hoang Khoi Tran,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.RO

TL;DR: InterKey是一个利用道路交叉口作为地标的跨模态全局定位框架，通过点云和OSM地图的联合编码实现鲁棒的跨模态匹配，在KITTI数据集上达到最先进精度


<details>
  <summary>Details</summary>
Motivation: 解决GNSS信号退化环境下自动驾驶车辆的可靠全局定位问题，利用免费且全球可用的OpenStreetMap作为高成本HD地图的替代方案

Method: 构建紧凑的二进制描述符，联合编码点云和OSM中的道路和建筑物印记，采用差异缓解、方向确定和区域均衡采样策略来弥合模态差距

Result: 在KITTI数据集上实现了最先进的精度，大幅超越现有基线方法

Conclusion: 该框架可推广到能够产生密集结构点云的传感器，为鲁棒车辆定位提供了可扩展且经济高效的解决方案

Abstract: Reliable global localization is critical for autonomous vehicles, especially
in environments where GNSS is degraded or unavailable, such as urban canyons
and tunnels. Although high-definition (HD) maps provide accurate priors, the
cost of data collection, map construction, and maintenance limits scalability.
OpenStreetMap (OSM) offers a free and globally available alternative, but its
coarse abstraction poses challenges for matching with sensor data. We propose
InterKey, a cross-modal framework that leverages road intersections as
distinctive landmarks for global localization. Our method constructs compact
binary descriptors by jointly encoding road and building imprints from point
clouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,
orientation determination, and area-equalized sampling strategies, enabling
robust cross-modal matching. Experiments on the KITTI dataset demonstrate that
InterKey achieves state-of-the-art accuracy, outperforming recent baselines by
a large margin. The framework generalizes to sensors that can produce dense
structural point clouds, offering a scalable and cost-effective solution for
robust vehicle localization.

</details>


### [127] [Using Petri Nets for Context-Adaptive Robot Explanations](https://arxiv.org/abs/2509.13861)
*Görkem Kılınç Soylu,Neziha Akalin,Maria Riveiro*

Main category: cs.RO

TL;DR: 使用Petri网建模上下文信息，实现机器人自适应解释的正式方法


<details>
  <summary>Details</summary>
Motivation: 在人机交互中，机器人需要以自然透明的方式沟通以建立信任，这要求机器人能够根据上下文调整其沟通方式

Method: 提出使用Petri网（PNs）来建模上下文信息，PNs提供了一种正式的图形化方法来表示并发动作、因果依赖和系统状态，适合分析人机之间的动态交互

Result: 通过一个涉及机器人根据用户注意力和存在等上下文线索提供解释的场景进行演示，模型分析确认了关键属性，包括无死锁性、上下文敏感可达性、有界性和活性

Conclusion: Petri网在设计和验证人机交互中上下文自适应解释方面表现出鲁棒性和灵活性

Abstract: In human-robot interaction, robots must communicate in a natural and
transparent manner to foster trust, which requires adapting their communication
to the context. In this paper, we propose using Petri nets (PNs) to model
contextual information for adaptive robot explanations. PNs provide a formal,
graphical method for representing concurrent actions, causal dependencies, and
system states, making them suitable for analyzing dynamic interactions between
humans and robots. We demonstrate this approach through a scenario involving a
robot that provides explanations based on contextual cues such as user
attention and presence. Model analysis confirms key properties, including
deadlock-freeness, context-sensitive reachability, boundedness, and liveness,
showing the robustness and flexibility of PNs for designing and verifying
context-adaptive explanations in human-robot interactions.

</details>


### [128] [PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models](https://arxiv.org/abs/2509.13903)
*Artem Lykov,Jeffrin Sam,Hung Khang Nguyen,Vladislav Kozlovskiy,Yara Mahmoud,Valerii Serpiva,Miguel Altamirano Cabrera,Mikhail Konenkov,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: PhysicalAgent是一个机器人操作框架，通过迭代推理、扩散视频生成和闭环执行来处理文本指令，生成候选轨迹视频演示，并在执行失败时重新规划，实现高达83%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人操作中执行错误恢复的问题，开发一个能够通过迭代推理和视频生成来适应不同感知模式和机器人平台的通用框架。

Method: 结合迭代推理、基于扩散的视频生成和闭环执行，根据文本指令生成候选轨迹的视频演示，执行并针对失败进行重新规划。

Result: 在多种感知模式（第一人称、第三人称、模拟）和机器人平台（UR3、G1人形、GR1模拟）上评估，相比现有方法表现更优，首次尝试成功率20-30%，通过迭代校正整体成功率提升至80%。

Conclusion: 基于视频的生成推理在通用机器人操作中具有潜力，迭代执行对于从初始失败中恢复至关重要，该框架为可扩展、适应性强且稳健的机器人控制铺平了道路。

Abstract: We introduce PhysicalAgent, an agentic framework for robotic manipulation
that integrates iterative reasoning, diffusion-based video generation, and
closed-loop execution. Given a textual instruction, our method generates short
video demonstrations of candidate trajectories, executes them on the robot, and
iteratively re-plans in response to failures. This approach enables robust
recovery from execution errors. We evaluate PhysicalAgent across multiple
perceptual modalities (egocentric, third-person, and simulated) and robotic
embodiments (bimanual UR3, Unitree G1 humanoid, simulated GR1), comparing
against state-of-the-art task-specific baselines. Experiments demonstrate that
our method consistently outperforms prior approaches, achieving up to 83%
success on human-familiar tasks. Physical trials reveal that first-attempt
success is limited (20-30%), yet iterative correction increases overall success
to 80% across platforms. These results highlight the potential of video-based
generative reasoning for general-purpose robotic manipulation and underscore
the importance of iterative execution for recovering from initial failures. Our
framework paves the way for scalable, adaptable, and robust robot control.

</details>


### [129] [MAP: End-to-End Autonomous Driving with Map-Assisted Planning](https://arxiv.org/abs/2509.13926)
*Huilin Yin,Yiming Kan,Daniel Watzenig*

Main category: cs.RO

TL;DR: MAP是一个新颖的地图辅助端到端轨迹规划框架，通过显式整合语义地图特征和当前自车状态，显著提升了自动驾驶轨迹规划性能


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法未能充分利用在线地图模块的潜力，地图特征对轨迹规划的增强作用未被充分挖掘

Method: 提出MAP框架，包含规划增强在线地图模块、自车状态引导规划模块和基于当前自车状态的权重适配器，显式整合分割式地图特征和自车状态

Result: 在DAIR-V2X-seq-SPD数据集上，L2位移误差降低16.6%，脱轨率降低56.2%，综合评分提升44.5%；在CVPR2025 MEIS Workshop竞赛中排名第一，综合评分比第二名高39.5%

Conclusion: 显式利用语义地图特征能有效提升规划性能，为端到端自动驾驶系统的结构设计提供了新方向

Abstract: In recent years, end-to-end autonomous driving has attracted increasing
attention for its ability to jointly model perception, prediction, and planning
within a unified framework. However, most existing approaches underutilize the
online mapping module, leaving its potential to enhance trajectory planning
largely untapped. This paper proposes MAP (Map-Assisted Planning), a novel
map-assisted end-to-end trajectory planning framework. MAP explicitly
integrates segmentation-based map features and the current ego status through a
Plan-enhancing Online Mapping module, an Ego-status-guided Planning module, and
a Weight Adapter based on current ego status. Experiments conducted on the
DAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%
reduction in L2 displacement error, a 56.2% reduction in off-road rate, and a
44.5% improvement in overall score compared to the UniV2X baseline, even
without post-processing. Furthermore, it achieves top ranking in Track 2 of the
End-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS
Workshop @CVPR2025, outperforming the second-best model by 39.5% in terms of
overall score. These results highlight the effectiveness of explicitly
leveraging semantic map features in planning and suggest new directions for
improving structure design in end-to-end autonomous driving systems. Our code
is available at https://gitee.com/kymkym/map.git

</details>


### [130] [The Influence of Facial Features on the Perceived Trustworthiness of a Social Robot](https://arxiv.org/abs/2509.13948)
*Benedict Barrow,Roger K. Moore*

Main category: cs.RO

TL;DR: 研究证实社交机器人面部特征中眼睛形状和大小对可信度感知有显著影响，婴儿脸特征能促进信任


<details>
  <summary>Details</summary>
Motivation: 信任和可信度感知在人机交互中至关重要，但目前对影响人类对机器人信任的因素理解仍不充分，需要研究机器人面部特征如何影响第一印象

Method: 通过操纵Furhat机器人的后投影面部特征，特别是眼睛形状和大小，研究婴儿脸特征对信任感知的影响

Result: 眼睛形状和大小对可信度感知有显著影响，婴儿脸特征确实能够促进信任

Conclusion: 这项工作为开发社交机器人时的设计选择提供了重要见解，有助于优化人机交互效果

Abstract: Trust and the perception of trustworthiness play an important role in
decision-making and our behaviour towards others, and this is true not only of
human-human interactions but also of human-robot interactions. While
significant advances have been made in recent years in the field of social
robotics, there is still some way to go before we fully understand the factors
that influence human trust in robots. This paper presents the results of a
study into the first impressions created by a social robot's facial features,
based on the hypothesis that a `babyface' engenders trust. By manipulating the
back-projected face of a Furhat robot, the study confirms that eye shape and
size have a significant impact on the perception of trustworthiness. The work
thus contributes to an understanding of the design choices that need to be made
when developing social robots so as to optimise the effectiveness of
human-robot interaction.

</details>


### [131] [SHaRe-RL: Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks](https://arxiv.org/abs/2509.13949)
*Jannick Stranghöner,Philipp Hartmann,Marco Braun,Sebastian Wrede,Klaus Neumann*

Main category: cs.RO

TL;DR: SHaRe-RL是一个强化学习框架，通过整合操作原语、人类演示和力控约束，实现了高效安全的工业装配任务在线学习。


<details>
  <summary>Details</summary>
Motivation: 解决高混合低批量(HMLV)工业装配中机器人系统面临的挑战：手动编程脆弱且成本高，基于学习的方法样本效率低且探索不安全。

Method: 结合多种先验知识：(i)将技能结构化为操作原语，(ii)整合人类演示和在线校正，(iii)通过轴向柔顺性约束交互力。

Result: 在0.2-0.4mm间隙的工业Harting连接器插入任务中，SHaRe-RL在实用时间预算内实现了可靠性能。

Conclusion: 过程专业知识（无需机器人或RL知识）可以显著促进学习，使RL在工业装配中更安全、更稳健、更经济可行。

Abstract: High-mix low-volume (HMLV) industrial assembly, common in small and
medium-sized enterprises (SMEs), requires the same precision, safety, and
reliability as high-volume automation while remaining flexible to product
variation and environmental uncertainty. Current robotic systems struggle to
meet these demands. Manual programming is brittle and costly to adapt, while
learning-based methods suffer from poor sample efficiency and unsafe
exploration in contact-rich tasks. To address this, we present SHaRe-RL, a
reinforcement learning framework that leverages multiple sources of prior
knowledge. By (i) structuring skills into manipulation primitives, (ii)
incorporating human demonstrations and online corrections, and (iii) bounding
interaction forces with per-axis compliance, SHaRe-RL enables efficient and
safe online learning for long-horizon, contact-rich industrial assembly tasks.
Experiments on the insertion of industrial Harting connector modules with
0.2-0.4 mm clearance demonstrate that SHaRe-RL achieves reliable performance
within practical time budgets. Our results show that process expertise, without
requiring robotics or RL knowledge, can meaningfully contribute to learning,
enabling safer, more robust, and more economically viable deployment of RL for
industrial assembly.

</details>


### [132] [SEG-Parking: Towards Safe, Efficient, and Generalizable Autonomous Parking via End-to-End Offline Reinforcement Learning](https://arxiv.org/abs/2509.13956)
*Zewei Yang,Zengqi Peng,Jun Ma*

Main category: cs.RO

TL;DR: SEG-Parking是一个基于离线强化学习的端到端自动驾驶停车框架，通过构建专用停车数据集和保守正则化方法，在复杂交互环境中实现高性能的自主停车。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境和动态交互给自动驾驶停车任务带来重大挑战，需要开发能够处理复杂交互的智能停车系统。

Method: 构建包含有无干扰车辆场景的专用停车数据集；预训练目标条件状态编码器将感知信息映射到潜在空间；使用保守正则化器优化离线强化学习策略，惩罚分布外动作。

Result: 在CARLA模拟器中进行广泛闭环实验，结果显示该方法具有最高的成功率和强大的泛化能力，能够处理分布外停车场景。

Conclusion: SEG-Parking框架通过端到端离线强化学习方法有效解决了自动驾驶停车中的交互感知问题，展现出优越的性能和鲁棒性。

Abstract: Autonomous parking is a critical component for achieving safe and efficient
urban autonomous driving. However, unstructured environments and dynamic
interactions pose significant challenges to autonomous parking tasks. To
address this problem, we propose SEG-Parking, a novel end-to-end offline
reinforcement learning (RL) framework to achieve interaction-aware autonomous
parking. Notably, a specialized parking dataset is constructed for parking
scenarios, which include those without interference from the opposite vehicle
(OV) and complex ones involving interactions with the OV. Based on this
dataset, a goal-conditioned state encoder is pretrained to map the fused
perception information into the latent space. Then, an offline RL policy is
optimized with a conservative regularizer that penalizes out-of-distribution
actions. Extensive closed-loop experiments are conducted in the high-fidelity
CARLA simulator. Comparative results demonstrate the superior performance of
our framework with the highest success rate and robust generalization to
out-of-distribution parking scenarios. The related dataset and source code will
be made publicly available after the paper is accepted.

</details>


### [133] [MetricNet: Recovering Metric Scale in Generative Navigation Policies](https://arxiv.org/abs/2509.13965)
*Abhijeet Nayak,Débora N. P. Oliveira,Samiran Gode,Cordelia Schmid,Wolfram Burgard*

Main category: cs.RO

TL;DR: MetricNet是一个用于生成式导航的附加模块，通过预测路径点之间的度量距离，将策略输出映射到真实世界坐标中，解决了现有方法缺乏度量基础和短视行为的问题。


<details>
  <summary>Details</summary>
Motivation: 生成式导航策略存在两个结构性问题：1）采样的轨迹存在于抽象的无尺度空间中，缺乏度量基础；2）控制策略丢弃完整路径，只朝向单个路径点移动，导致短视和不安全的动作。

Method: 提出MetricNet作为生成式导航的附加模块，预测路径点之间的度量距离；进一步提出MetricNav，将MetricNet集成到导航策略中，引导机器人避开障碍物同时朝向目标移动。

Result: 在仿真环境中使用新的基准框架进行评估，显示执行MetricNet缩放的路径点显著提高了导航和探索性能；在真实世界实验中进一步验证了方法的有效性。

Conclusion: MetricNet通过提供度量基础解决了生成式导航的关键问题，MetricNav集成方案能够同时实现避障和目标导向，显著提升了导航的安全性和性能。

Abstract: Generative navigation policies have made rapid progress in improving
end-to-end learned navigation. Despite their promising results, this paradigm
has two structural problems. First, the sampled trajectories exist in an
abstract, unscaled space without metric grounding. Second, the control strategy
discards the full path, instead moving directly towards a single waypoint. This
leads to short-sighted and unsafe actions, moving the robot towards obstacles
that a complete and correctly scaled path would circumvent. To address these
issues, we propose MetricNet, an effective add-on for generative navigation
that predicts the metric distance between waypoints, grounding policy outputs
in real-world coordinates. We evaluate our method in simulation with a new
benchmarking framework and show that executing MetricNet-scaled waypoints
significantly improves both navigation and exploration performance. Beyond
simulation, we further validate our approach in real-world experiments.
Finally, we propose MetricNav, which integrates MetricNet into a navigation
policy to guide the robot away from obstacles while still moving towards the
goal.

</details>


### [134] [BIM Informed Visual SLAM for Construction Monitoring](https://arxiv.org/abs/2509.13972)
*Asier Bikandi,Miguel Fernandez-Cortizas,Muhammad Shaheer,Ali Tourani,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: 提出了一种结合BIM结构先验知识的RGB-D SLAM系统，通过在后台优化中引入检测墙体与BIM模型的对应约束，显著降低了施工环境中的轨迹误差和地图误差。


<details>
  <summary>Details</summary>
Motivation: 施工环境中的视觉SLAM面临重复布局、遮挡和低纹理结构等挑战，容易导致轨迹漂移。LiDAR SLAM虽然精度高但设备笨重耗电，需要一种实用的替代方案。

Method: 使用RGB-D SLAM系统，将BIM模型作为结构先验知识，持续建立检测墙体与BIM模型的对应关系，并将这些对应关系作为约束引入后台优化过程。

Result: 在真实施工场地验证显示，相比视觉SLAM基线方法，轨迹误差平均减少23.71%，地图RMSE减少7.14%，系统能够实时运行。

Conclusion: BIM约束即使在部分施工条件下也能可靠地对齐数字规划与实际施工场景，为施工监控提供了有效的SLAM解决方案。

Abstract: Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring
construction sites, where aligning the evolving as-built state with the
as-planned design enables early error detection and reduces costly rework.
LiDAR-based SLAM achieves high geometric precision, but its sensors are
typically large and power-demanding, limiting their use on portable platforms.
Visual SLAM offers a practical alternative with lightweight cameras already
embedded in most mobile devices. however, visually mapping construction
environments remains challenging: repetitive layouts, occlusions, and
incomplete or low-texture structures often cause drift in the trajectory map.
To mitigate this, we propose an RGB-D SLAM system that incorporates the
Building Information Model (BIM) as structural prior knowledge. Instead of
relying solely on visual cues, our system continuously establishes
correspondences between detected wall and their BIM counterparts, which are
then introduced as constraints in the back-end optimization. The proposed
method operates in real time and has been validated on real construction sites,
reducing trajectory error by an average of 23.71% and map RMSE by 7.14%
compared to visual SLAM baselines. These results demonstrate that BIM
constraints enable reliable alignment of the digital plan with the as-built
scene, even under partially constructed conditions.

</details>


### [135] [Flexible and Foldable: Workspace Analysis and Object Manipulation Using a Soft, Interconnected, Origami-Inspired Actuator Array](https://arxiv.org/abs/2509.13998)
*Bailey Dacre,Rodrigo Moreno,Serhat Demirtas,Ziqiao Wang,Yuhao Jiang,Jamie Paik,Kasper Stoy,Andrés Faíña*

Main category: cs.RO

TL;DR: 提出了一种基于折纸灵感的3自由度机器人瓦片阵列分布式操纵系统，通过柔性连接表面实现连续可控的操纵表面，显著降低执行器密度并扩大操纵范围


<details>
  <summary>Details</summary>
Motivation: 传统分布式操纵系统依赖高执行器密度和受限的物体-执行器比例约束，限制了系统的适应性和应用范围

Method: 使用3自由度折纸灵感机器人瓦片阵列，通过柔性表面层相互连接，创建连续可控的操纵表面，分析系统工作空间并推导简单运动原语

Result: 系统能够操纵简单几何物体在瓦片阵列上移动，执行器密度显著降低，操纵面积增加1.84倍而无需增加执行器数量

Conclusion: 该设计提供了比传统高密度阵列更低成本和复杂度的替代方案，并为利用互联表面柔性的新操纵策略创造了机会

Abstract: Object manipulation is a fundamental challenge in robotics, where systems
must balance trade-offs among manipulation capabilities, system complexity, and
throughput. Distributed manipulator systems (DMS) use the coordinated motion of
actuator arrays to perform complex object manipulation tasks, seeing widespread
exploration within the literature and in industry. However, existing DMS
designs typically rely on high actuator densities and impose constraints on
object-to-actuator scale ratios, limiting their adaptability. We present a
novel DMS design utilizing an array of 3-DoF, origami-inspired robotic tiles
interconnected by a compliant surface layer. Unlike conventional DMS, our
approach enables manipulation not only at the actuator end effectors but also
across a flexible surface connecting all actuators; creating a continuous,
controllable manipulation surface. We analyse the combined workspace of such a
system, derive simple motion primitives, and demonstrate its capabilities to
translate simple geometric objects across an array of tiles. By leveraging the
inter-tile connective material, our approach significantly reduces actuator
density, increasing the area over which an object can be manipulated by x1.84
without an increase in the number of actuators. This design offers a lower cost
and complexity alternative to traditional high-density arrays, and introduces
new opportunities for manipulation strategies that leverage the flexibility of
the interconnected surface.

</details>


### [136] [Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization](https://arxiv.org/abs/2509.14010)
*Zong Chen,Shaoyang Li,Ben Liu,Min Li,Zhouping Yin,Yiqun Li*

Main category: cs.RO

TL;DR: 提出了一种轮腿式四足机器人及其全身运动控制框架，集成转向模块和轮毂驱动轮，实现全向移动和精确操作，通过接触感知优化和统一运动学模型解决控制挑战。


<details>
  <summary>Details</summary>
Motivation: 轮腿式机器人结合机械臂在物流、工业自动化和人机协作中具有巨大潜力，但由于自由度冗余、轮地接触动力学复杂以及运动与操作需要无缝协调，统一控制仍然具有挑战性。

Method: 开发了接触感知的全身动态优化框架，集成了操作的点接触建模和轮地交互的线接触建模；引入热启动策略加速在线优化；为4WIS-4WID驱动方案定制统一运动学模型。

Result: 仿真和实验结果验证了框架的有效性，展示了敏捷的地形穿越、高速全向移动和精确操作能力。

Conclusion: 该系统在工厂自动化、城市物流和半结构化环境中的服务机器人领域具有巨大应用潜力。

Abstract: Wheel-legged robots with integrated manipulators hold great promise for
mobile manipulation in logistics, industrial automation, and human-robot
collaboration. However, unified control of such systems remains challenging due
to the redundancy in degrees of freedom, complex wheel-ground contact dynamics,
and the need for seamless coordination between locomotion and manipulation. In
this work, we present the design and whole-body motion control of an
omnidirectional wheel-legged quadrupedal robot equipped with a dexterous
manipulator. The proposed platform incorporates independently actuated steering
modules and hub-driven wheels, enabling agile omnidirectional locomotion with
high maneuverability in structured environments. To address the challenges of
contact-rich interaction, we develop a contact-aware whole-body dynamic
optimization framework that integrates point-contact modeling for manipulation
with line-contact modeling for wheel-ground interactions. A warm-start strategy
is introduced to accelerate online optimization, ensuring real-time feasibility
for high-dimensional control. Furthermore, a unified kinematic model tailored
for the robot's 4WIS-4WID actuation scheme eliminates the need for mode
switching across different locomotion strategies, improving control consistency
and robustness. Simulation and experimental results validate the effectiveness
of the proposed framework, demonstrating agile terrain traversal, high-speed
omnidirectional mobility, and precise manipulation under diverse scenarios,
underscoring the system's potential for factory automation, urban logistics,
and service robotics in semi-structured environments.

</details>


### [137] [Language Conditioning Improves Accuracy of Aircraft Goal Prediction in Untowered Airspace](https://arxiv.org/abs/2509.14063)
*Sundhar Vinodh Sangeetha,Chih-Yuan Chiu,Sarah H. Q. Li,Shreyas Kousik*

Main category: cs.RO

TL;DR: 提出多模态框架，结合自然语言理解和空间推理来预测飞机目标位置，通过语音识别和语言模型解析飞行员无线电通话，融合意图标签和轨迹数据，显著降低预测误差


<details>
  <summary>Details</summary>
Motivation: 在无塔台空域中，自主飞机需要安全运行，依赖人类飞行员之间的语音通信。安全操作要求飞机预测其他飞机的意图和目标位置

Method: 使用自动语音识别和大语言模型转录和解释飞行员无线电通话，识别飞机并提取离散意图标签。将这些意图标签与观测轨迹融合，通过时间卷积网络和高斯混合模型进行概率目标预测

Result: 相比仅依赖运动历史的基线方法，该方法显著减少了目标预测误差，证明了语言条件预测能提高预测准确性

Conclusion: 在真实无塔台机场数据集上的实验验证了该方法的有效性，突显了其在实现社会感知、语言条件机器人运动规划方面的潜力

Abstract: Autonomous aircraft must safely operate in untowered airspace, where
coordination relies on voice-based communication among human pilots. Safe
operation requires an aircraft to predict the intent, and corresponding goal
location, of other aircraft. This paper introduces a multimodal framework for
aircraft goal prediction that integrates natural language understanding with
spatial reasoning to improve autonomous decision-making in such environments.
We leverage automatic speech recognition and large language models to
transcribe and interpret pilot radio calls, identify aircraft, and extract
discrete intent labels. These intent labels are fused with observed
trajectories to condition a temporal convolutional network and Gaussian mixture
model for probabilistic goal prediction. Our method significantly reduces goal
prediction error compared to baselines that rely solely on motion history,
demonstrating that language-conditioned prediction increases prediction
accuracy. Experiments on a real-world dataset from an untowered airport
validate the approach and highlight its potential to enable socially aware,
language-conditioned robotic motion planning.

</details>


### [138] [FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video](https://arxiv.org/abs/2509.14082)
*Valerii Serpiva,Artem Lykov,Faryal Batool,Vladislav Kozlovskiy,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: FlightDiffusion是一个基于扩散模型的框架，用于从第一人称视角视频训练自主无人机，能够生成逼真的视频序列和对应的动作空间，支持推理驱动的导航，并可以合成大规模训练数据集。


<details>
  <summary>Details</summary>
Motivation: 为了解决无人机自主导航中真实世界数据收集成本高的问题，以及需要大规模多样化训练数据来提升导航策略学习的挑战。

Method: 采用扩散模型从单帧图像生成逼真的第一人称视角视频序列，同时生成对应的动作空间，通过合成多样化的FPV轨迹和状态-动作对来创建大规模训练数据集。

Result: 生成的轨迹具有物理可行性，平均位置误差0.25米（RMSE 0.28米），平均方向误差0.19弧度（RMSE 0.24弧度）。仿真和现实性能无显著差异（p=0.541），成功率分别为0.628和0.617，显示出良好的sim-to-real迁移能力。

Conclusion: 扩散模型为基础的方法为无人机导航、动作生成和数据合成提供了一个有前景的统一范式，能够提升策略学习效果和数据集可扩展性，在仿真环境中表现出更强的鲁棒性、更平滑的轨迹规划和更好的环境适应性。

Abstract: We present FlightDiffusion, a diffusion-model-based framework for training
autonomous drones from first-person view (FPV) video. Our model generates
realistic video sequences from a single frame, enriched with corresponding
action spaces to enable reasoning-driven navigation in dynamic environments.
Beyond direct policy learning, FlightDiffusion leverages its generative
capabilities to synthesize diverse FPV trajectories and state-action pairs,
facilitating the creation of large-scale training datasets without the high
cost of real-world data collection. Our evaluation demonstrates that the
generated trajectories are physically plausible and executable, with a mean
position error of 0.25 m (RMSE 0.28 m) and a mean orientation error of 0.19 rad
(RMSE 0.24 rad). This approach enables improved policy learning and dataset
scalability, leading to superior performance in downstream navigation tasks.
Results in simulated environments highlight enhanced robustness, smoother
trajectory planning, and adaptability to unseen conditions. An ANOVA revealed
no statistically significant difference between performance in simulation and
reality (F(1, 16) = 0.394, p = 0.541), with success rates of M = 0.628 (SD =
0.162) and M = 0.617 (SD = 0.177), respectively, indicating strong sim-to-real
transfer. The generated datasets provide a valuable resource for future UAV
research. This work introduces diffusion-based reasoning as a promising
paradigm for unifying navigation, action generation, and data synthesis in
aerial robotics.

</details>


### [139] [GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14117)
*Ali Abouzeid,Malak Mansour,Zezhou Sun,Dezhen Song*

Main category: cs.RO

TL;DR: GeoAware-VLA通过集成几何先验增强VLA模型的视角不变性，在未见相机视角下实现2倍以上的性能提升


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action模型难以从2D图像推断鲁棒的3D几何信息，导致在新相机视角下泛化能力不足

Method: 使用冻结的预训练几何视觉模型作为特征提取器，通过可训练的投影层将几何丰富的特征适配到策略解码器，避免从头学习3D一致性

Result: 在LIBERO基准测试中，零样本泛化到新相机姿态的成功率提升超过2倍，在真实机器人上从未见相机角度评估也显示出显著性能增益

Conclusion: 鲁棒的几何基础是创建更具泛化能力的机器人智能体的关键组件，该方法在连续和离散动作空间中都有效

Abstract: Vision-Language-Action (VLA) models often fail to generalize to novel camera
viewpoints, a limitation stemming from their difficulty in inferring robust 3D
geometry from 2D images. We introduce GeoAware-VLA, a simple yet effective
approach that enhances viewpoint invariance by integrating strong geometric
priors into the vision backbone. Instead of training a visual encoder or
relying on explicit 3D data, we leverage a frozen, pretrained geometric vision
model as a feature extractor. A trainable projection layer then adapts these
geometrically-rich features for the policy decoder, relieving it of the burden
of learning 3D consistency from scratch. Through extensive evaluations on
LIBERO benchmark subsets, we show GeoAware-VLA achieves substantial
improvements in zero-shot generalization to novel camera poses, boosting
success rates by over 2x in simulation. Crucially, these benefits translate to
the physical world; our model shows a significant performance gain on a real
robot, especially when evaluated from unseen camera angles. Our approach proves
effective across both continuous and discrete action spaces, highlighting that
robust geometric grounding is a key component for creating more generalizable
robotic agents.

</details>


### [140] [SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14138)
*Ran Yang,Zijian An,Lifeng ZHou,Yiming Feng*

Main category: cs.RO

TL;DR: SeqVLA是一个基于π₀的视觉-语言-动作模型扩展，通过添加轻量级检测头来感知子任务完成状态，从而在长时程多阶段机器人操作任务中实现自主子任务转换，显著提高了序列操作的鲁棒性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型如π₀擅长连续低层控制，但缺乏检测子任务完成的内在信号，导致在需要严格序列执行的长期任务中容易因错误累积而失败。

Method: 在π₀基础架构上增加轻量级检测头，形成双头设计（动作生成头和完成检测头）。研究了四种微调策略：联合微调与顺序微调，以及全微调与冻结骨干网络的组合。

Result: 在沙拉打包（7个子任务）和糖果打包（4个子任务）实验中，SeqVLA显著优于基线π₀和其他强基线。联合微调且不冻结骨干网络的策略获得了最可靠和决定性的完成预测，消除了序列相关故障。

Conclusion: 将动作生成与子任务感知检测耦合对于可扩展的顺序操作至关重要，SeqVLA通过完成感知机制实现了鲁棒的长时程执行。

Abstract: Long-horizon robotic manipulation tasks require executing multiple
interdependent subtasks in strict sequence, where errors in detecting subtask
completion can cascade into downstream failures. Existing
Vision-Language-Action (VLA) models such as $\pi_0$ excel at continuous
low-level control but lack an internal signal for identifying when a subtask
has finished, making them brittle in sequential settings. We propose SeqVLA, a
completion-aware extension of $\pi_0$ that augments the base architecture with
a lightweight detection head perceiving whether the current subtask is
complete. This dual-head design enables SeqVLA not only to generate
manipulation actions but also to autonomously trigger transitions between
subtasks. We investigate four finetuning strategies that vary in how the action
and detection heads are optimized (joint vs. sequential finetuning) and how
pretrained knowledge is preserved (full finetuning vs. frozen backbone).
Experiments are performed on two multi-stage tasks: salad packing with seven
distinct subtasks and candy packing with four distinct subtasks. Results show
that SeqVLA significantly outperforms the baseline $\pi_0$ and other strong
baselines in overall success rate. In particular, joint finetuning with an
unfrozen backbone yields the most decisive and statistically reliable
completion predictions, eliminating sequence-related failures and enabling
robust long-horizon execution. Our results highlight the importance of coupling
action generation with subtask-aware detection for scalable sequential
manipulation.

</details>


### [141] [CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping](https://arxiv.org/abs/2509.14143)
*Zijian An,Ran Yang,Yiming Feng,Lifeng Zhou*

Main category: cs.RO

TL;DR: CLAW是一个将条件评估与动作生成解耦的视觉-语言-动作框架，使用微调CLIP模型监控数字读数并生成基于重量阈值的离散指令，再由VLA策略整合多视角观察生成连续机器人动作


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在处理精确任务约束（如基于数值阈值的停止）方面存在困难，因为其观察-动作映射是隐式训练的，缺乏明确的条件监控机制

Method: 提出CLAW框架：1）使用微调CLIP模型作为轻量级提示生成器，持续监控秤的数字读数并基于任务特定重量阈值生成离散指令；2）由π₀流式VLA策略整合提示和多视角相机观察生成连续机器人动作

Result: 在单物体抓取和需要双臂操作的混合物体任务三个实验设置中，CLAW可靠执行重量感知行为，性能优于原始π₀和微调π₀模型

Conclusion: CLAW成功将符号重量推理与高频视觉运动控制相结合，为处理精确任务约束的机器人控制提供了有效解决方案

Abstract: Vision-language-action (VLA) models have recently emerged as a promising
paradigm for robotic control, enabling end-to-end policies that ground natural
language instructions into visuomotor actions. However, current VLAs often
struggle to satisfy precise task constraints, such as stopping based on numeric
thresholds, since their observation-to-action mappings are implicitly shaped by
training data and lack explicit mechanisms for condition monitoring. In this
work, we propose CLAW (CLIP-Language-Action for Weight), a framework that
decouples condition evaluation from action generation. CLAW leverages a
fine-tuned CLIP model as a lightweight prompt generator, which continuously
monitors the digital readout of a scale and produces discrete directives based
on task-specific weight thresholds. These prompts are then consumed by $\pi_0$,
a flow-based VLA policy, which integrates the prompts with multi-view camera
observations to produce continuous robot actions. This design enables CLAW to
combine symbolic weight reasoning with high-frequency visuomotor control. We
validate CLAW on three experimental setups: single-object grasping and
mixed-object tasks requiring dual-arm manipulation. Across all conditions, CLAW
reliably executes weight-aware behaviors and outperforms both raw-$\pi_0$ and
fine-tuned $\pi_0$ models. We have uploaded the videos as supplementary
materials.

</details>


### [142] [StableTracker: Learning to Stably Track Target via Differentiable Simulation](https://arxiv.org/abs/2509.14147)
*Fanxing Li,Shengyang Wang,Fangyu Sun,Shuyu Wu,Dexin Zuo,Wenxian Yu,Danping Zou*

Main category: cs.RO

TL;DR: StableTracker是一个基于学习的控制策略，通过可微分模拟训练，使四旋翼无人机能够从任意视角稳定跟踪移动目标，在精度、稳定性和泛化性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统FPV目标跟踪方法依赖手工设计的模块化方案，存在硬件过载和累积误差问题，特别是在目标快速加减速时性能严重下降。

Method: 使用基于时间的反向传播通过可微分模拟训练学习型控制策略，使无人机在水平和垂直方向保持目标在视野中心，同时维持固定相对距离。

Result: 仿真实验显示该方法在精度、稳定性和泛化性方面优于最先进传统算法和学习基线，真实世界实验验证了实用性。

Conclusion: StableTracker提供了一种有效的自主空中摄像解决方案，能够鲁棒地跟踪移动目标，解决了传统方法的局限性。

Abstract: FPV object tracking methods heavily rely on handcraft modular designs,
resulting in hardware overload and cumulative error, which seriously degrades
the tracking performance, especially for rapidly accelerating or decelerating
targets. To address these challenges, we present \textbf{StableTracker}, a
learning-based control policy that enables quadrotors to robustly follow the
moving target from arbitrary perspectives. The policy is trained using
backpropagation-through-time via differentiable simulation, allowing the
quadrotor to maintain the target at the center of the visual field in both
horizontal and vertical directions, while keeping a fixed relative distance,
thereby functioning as an autonomous aerial camera. We compare StableTracker
against both state-of-the-art traditional algorithms and learning baselines.
Simulation experiments demonstrate that our policy achieves superior accuracy,
stability and generalization across varying safe distances, trajectories, and
target velocities. Furthermore, a real-world experiment on a quadrotor with an
onboard computer validated practicality of the proposed approach.

</details>


### [143] [MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies](https://arxiv.org/abs/2509.14159)
*Dayi Dong,Maulik Bhatt,Seoyeon Choi,Negar Mehr*

Main category: cs.RO

TL;DR: 提出了MIMIC-D方法，使用扩散策略在集中训练分散执行框架下解决多智能体多模态模仿学习问题，能够在无显式通信的情况下恢复智能体间的多模态协调行为。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在社会中更广泛的应用，需要能够与其他机器人和人类在多模态任务上协调工作。传统模仿学习方法在处理多模态专家演示时难以捕捉多样策略，而现有的扩散模型方法通常需要集中规划或显式通信，这在现实场景中往往不可行。

Method: 提出了MIMIC-D方法，采用集中训练分散执行（CTDE）范式，使用扩散策略进行多智能体多模态模仿学习。在训练时使用完整信息联合训练智能体，但在执行时仅使用局部信息实现隐式协调。

Result: 在仿真和硬件实验中证明，该方法能够在各种任务和环境中恢复智能体间的多模态协调行为，并在性能上优于现有最先进的基线方法。

Conclusion: MIMIC-D方法成功解决了多智能体多模态模仿学习中的协调问题，无需显式通信即可实现有效的隐式协调，为现实世界中机器人协调提供了可行的解决方案。

Abstract: As robots become more integrated in society, their ability to coordinate with
other robots and humans on multi-modal tasks (those with multiple valid
solutions) is crucial. We propose to learn such behaviors from expert
demonstrations via imitation learning (IL). However, when expert demonstrations
are multi-modal, standard IL approaches can struggle to capture the diverse
strategies, hindering effective coordination. Diffusion models are known to be
effective at handling complex multi-modal trajectory distributions in
single-agent systems. Diffusion models have also excelled in multi-agent
scenarios where multi-modality is more common and crucial to learning
coordinated behaviors. Typically, diffusion-based approaches require a
centralized planner or explicit communication among agents, but this assumption
can fail in real-world scenarios where robots must operate independently or
with agents like humans that they cannot directly communicate with. Therefore,
we propose MIMIC-D, a Centralized Training, Decentralized Execution (CTDE)
paradigm for multi-modal multi-agent imitation learning using diffusion
policies. Agents are trained jointly with full information, but execute
policies using only local information to achieve implicit coordination. We
demonstrate in both simulation and hardware experiments that our method
recovers multi-modal coordination behavior among agents in a variety of tasks
and environments, while improving upon state-of-the-art baselines.

</details>


### [144] [\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video](https://arxiv.org/abs/2509.14178)
*Kai Ye,Yuhang Wu,Shuyuan Hu,Junliang Li,Meng Liu,Yongquan Chen,Rui Huang*

Main category: cs.RO

TL;DR: Gen2Real使用生成视频替代人工演示，通过视频生成、轨迹优化和演示学习实现灵巧操作，在仿真中达到77.3%成功率并能在真实机器人上执行


<details>
  <summary>Details</summary>
Motivation: 灵巧操作面临的主要挑战是收集大量人类演示数据成本高昂，需要寻找替代方案来降低对人工演示的依赖

Method: 结合视频生成与姿态深度估计生成手-物体轨迹，使用物理感知交互优化模型(PIOM)进行轨迹优化，通过锚点残差PPO策略将人类动作重定向到机器人手并稳定控制

Result: 仅使用生成视频学习的策略在仿真抓取任务中达到77.3%成功率，在真实机器人上展示连贯执行，并能通过自然语言直接指定任务

Conclusion: Gen2Real展示了从想象视频到真实世界执行的泛化能力，为灵巧操作提供了一种灵活且鲁棒的解决方案

Abstract: Dexterous manipulation remains a challenging robotics problem, largely due to
the difficulty of collecting extensive human demonstrations for learning. In
this paper, we introduce \textsc{Gen2Real}, which replaces costly human demos
with one generated video and drives robot skill from it: it combines
demonstration generation that leverages video generation with pose and depth
estimation to yield hand-object trajectories, trajectory optimization that uses
Physics-aware Interaction Optimization Model (PIOM) to impose physics
consistency, and demonstration learning that retargets human motions to a robot
hand and stabilizes control with an anchor-based residual Proximal Policy
Optimization (PPO) policy. Using only generated videos, the learned policy
achieves a 77.3\% success rate on grasping tasks in simulation and demonstrates
coherent executions on a real robot. We also conduct ablation studies to
validate the contribution of each component and demonstrate the ability to
directly specify tasks using natural language, highlighting the flexibility and
robustness of \textsc{Gen2Real} in generalizing grasping skills from imagined
videos to real-world execution.

</details>


### [145] [MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping](https://arxiv.org/abs/2509.14191)
*Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald*

Main category: cs.RO

TL;DR: MCGS-SLAM是首个基于纯RGB输入的多相机3D高斯溅射SLAM系统，通过多视角融合实现实时高精度建图和轨迹估计，优于单目方法


<details>
  <summary>Details</summary>
Motivation: 现有密集SLAM主要针对单目设置，牺牲了鲁棒性和几何覆盖范围。多相机系统能提供更宽的视野和更好的几何覆盖，对自动驾驶等应用至关重要

Method: 使用多相机束调整(MCBA)通过密集光度学和几何残差联合优化位姿和深度，采用尺度一致性模块通过低秩先验实现跨视图的度量对齐，基于3D高斯溅射技术融合多视角RGB输入

Result: 在合成和真实数据集上实验表明，MCGS-SLAM能持续产生准确轨迹和逼真重建，通常优于单目基线方法，多相机输入能够重建单目系统遗漏的侧视区域

Conclusion: 多相机高斯溅射SLAM在机器人和自动驾驶的高保真建图中具有巨大潜力，能够提供更完整的环境重建和更安全的自主操作

Abstract: Recent progress in dense SLAM has primarily targeted monocular setups, often
at the expense of robustness and geometric coverage. We present MCGS-SLAM, the
first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting
(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM
fuses dense RGB inputs from multiple viewpoints into a unified, continuously
optimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines
poses and depths via dense photometric and geometric residuals, while a scale
consistency module enforces metric alignment across views using low-rank
priors. The system supports RGB input and maintains real-time performance at
large scale. Experiments on synthetic and real-world datasets show that
MCGS-SLAM consistently yields accurate trajectories and photorealistic
reconstructions, usually outperforming monocular baselines. Notably, the wide
field of view from multi-camera input enables reconstruction of side-view
regions that monocular setups miss, critical for safe autonomous operation.
These results highlight the promise of multi-camera Gaussian Splatting SLAM for
high-fidelity mapping in robotics and autonomous driving.

</details>


### [146] [GLIDE: A Coordinated Aerial-Ground Framework for Search and Rescue in Unknown Environments](https://arxiv.org/abs/2509.14210)
*Seth Farrell,Chenghao Li,Hongzhan Yu,Hesam Mojtahedi,Sicun Gao,Henrik I. Christensen*

Main category: cs.RO

TL;DR: 提出GLIDE框架，使用两架无人机和一辆地面车协同执行搜救任务，通过无人机引导实现快速受害者定位和避障导航


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中搜救任务的时间紧迫性和导航安全性问题，通过空中-地面协同提高受害者定位效率和路径规划安全性

Method: 采用双无人机架构：目标搜索无人机负责实时受害者检测和地理参考，地形侦察无人机提供路径可通行性更新；地面车融合空中线索进行A*规划和连续重规划

Result: 硬件演示和仿真实验表明，明确的角色分离、地形侦察和引导规划显著提高了搜救任务的到达时间和导航安全性

Conclusion: GLIDE框架通过空中-地面协同和专门的无人机角色分配，有效提升了时间关键型搜救任务的性能表现

Abstract: We present a cooperative aerial-ground search-and-rescue (SAR) framework that
pairs two unmanned aerial vehicles (UAVs) with an unmanned ground vehicle (UGV)
to achieve rapid victim localization and obstacle-aware navigation in unknown
environments. We dub this framework Guided Long-horizon Integrated Drone Escort
(GLIDE), highlighting the UGV's reliance on UAV guidance for long-horizon
planning. In our framework, a goal-searching UAV executes real-time onboard
victim detection and georeferencing to nominate goals for the ground platform,
while a terrain-scouting UAV flies ahead of the UGV's planned route to provide
mid-level traversability updates. The UGV fuses aerial cues with local sensing
to perform time-efficient A* planning and continuous replanning as information
arrives. Additionally, we present a hardware demonstration (using a GEM e6 golf
cart as the UGV and two X500 UAVs) to evaluate end-to-end SAR mission
performance and include simulation ablations to assess the planning stack in
isolation from detection. Empirical results demonstrate that explicit role
separation across UAVs, coupled with terrain scouting and guided planning,
improves reach time and navigation safety in time-critical SAR missions.

</details>


### [147] [Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models](https://arxiv.org/abs/2509.14228)
*Benjamin Shaffer,Victoria Edwards,Brooks Kinch,Nathaniel Trask,M. Ani Hsieh*

Main category: cs.RO

TL;DR: 提出了一种分布式移动传感框架，使用机器学习有限元模型指导多机器人团队在复杂流动中进行源定位，通过信息熵控制策略实现更快的误差减少和更准确的定位效果。


<details>
  <summary>Details</summary>
Motivation: 复杂流动中的源定位（如化学泄漏或石油泄漏）面临挑战，包括时变混沌流动、间歇性传感器读数、复杂环境几何形状以及机载计算能力有限难以运行计算密集型数值模型的问题。

Method: 每个机器人携带机器学习有限元环境模型，使用近似互信息准则驱动信息熵控制策略，选择预期能最大化源定位信息量的传感区域进行采样。

Result: 与基线传感策略相比，该方法实现了更快的误差减少；与基线机器学习方法相比，获得了更准确的源定位结果。

Conclusion: 分布式移动传感框架结合机器学习模型和信息熵控制策略，能够有效解决复杂流动环境中的源定位问题，在计算效率和定位精度方面都表现出优势。

Abstract: Source localization in a complex flow poses a significant challenge for
multi-robot teams tasked with localizing the source of chemical leaks or
tracking the dispersion of an oil spill. The flow dynamics can be time-varying
and chaotic, resulting in sporadic and intermittent sensor readings, and
complex environmental geometries further complicate a team's ability to model
and predict the dispersion. To accurately account for the physical processes
that drive the dispersion dynamics, robots must have access to computationally
intensive numerical models, which can be difficult when onboard computation is
limited. We present a distributed mobile sensing framework for source
localization in which each robot carries a machine-learned, finite element
model of its environment to guide information-based sampling. The models are
used to evaluate an approximate mutual information criterion to drive an
infotaxis control strategy, which selects sensing regions that are expected to
maximize informativeness for the source localization objective. Our approach
achieves faster error reduction compared to baseline sensing strategies and
results in more accurate source localization compared to baseline machine
learning approaches.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [148] [Circuit realization and hardware linearization of monotone operator equilibrium networks](https://arxiv.org/abs/2509.13793)
*Thomas Chaffey*

Main category: eess.SY

TL;DR: 该论文展示了电阻-二极管网络的端口行为对应于ReLU单调算子平衡网络（无限深度神经网络）的解，提供了模拟硬件中神经网络的简洁构造方法。论文还提出了硬件线性化方法直接在硬件中计算梯度，实现了硬件内训练，并通过级联电阻-二极管网络实现了前馈等非对称网络架构。


<details>
  <summary>Details</summary>
Motivation: 研究如何在模拟硬件中简洁地实现神经网络，特别是利用电阻-二极管网络来构建神经网络的硬件等效模型，并探索直接在硬件中进行训练的可能性。

Method: 使用电阻-二极管网络构建ReLU单调算子平衡网络，提出硬件线性化方法来直接计算电路梯度，通过级联网络实现复杂架构，并研究不同非线性元件产生的激活函数。

Result: 成功实现了模拟硬件中的神经网络构造，证明了硬件内训练的可行性，发现了非理想二极管模型产生的新型ReLU激活函数（二极管ReLU），并扩展到了前馈等非对称网络架构。

Conclusion: 电阻-二极管网络为模拟硬件实现神经网络提供了简洁有效的解决方案，硬件线性化方法使得硬件内训练成为可能，为未来模拟神经网络硬件设计开辟了新途径。

Abstract: It is shown that the port behavior of a resistor-diode network corresponds to
the solution of a ReLU monotone operator equilibrium network (a neural network
in the limit of infinite depth), giving a parsimonious construction of a neural
network in analog hardware. We furthermore show that the gradient of such a
circuit can be computed directly in hardware, using a procedure we call
hardware linearization. This allows the network to be trained in hardware,
which we demonstrate with a device-level circuit simulation. We extend the
results to cascades of resistor-diode networks, which can be used to implement
feedforward and other asymmetric networks. We finally show that different
nonlinear elements give rise to different activation functions, and introduce
the novel diode ReLU which is induced by a non-ideal diode model.

</details>


### [149] [A hybrid dynamic model and parameter estimation method for accurately simulating overhead cranes with friction](https://arxiv.org/abs/2509.13330)
*Jorge Vicente-Martinez,Edgar Ramirez-Laboreo*

Main category: eess.SY

TL;DR: 提出了一种结合高斯过程回归和最小二乘法的混合动力学模型，用于准确模拟3D桥式起重机的摩擦动力学，在保证计算效率的同时实现高精度摩擦建模


<details>
  <summary>Details</summary>
Motivation: 非线性摩擦动力学对3D桥式起重机系统有重要影响，但传统方法要么使用不精确的摩擦近似，要么需要过长的计算时间，难以在仿真中准确建模这一现象

Method: 采用混合动力学模型，结合高斯过程回归(GPR)和最小二乘(LS)估计的分步算法，全面估计包括摩擦在内的所有未知系统参数

Result: 通过实验室起重机实验验证，证实了所提出的建模和估计方法的有效性

Conclusion: 该方法在计算效率和摩擦建模精度之间取得了良好平衡，为3D起重机系统的准确仿真提供了有效解决方案

Abstract: This paper presents a new approach to accurately simulating 3D overhead
cranes with friction. Nonlinear friction dynamics have a significant impact on
these systems, however, accurately modeling this phenomenon in simulations is a
significant challenge. Traditional methods often rely on imprecise
approximations of friction or require excessive computational times for
reliable results. To address this, we present a hybrid dynamical model that
features a trade-off between high-fidelity friction modeling and computational
efficiency. Furthermore, we present a step-by-step algorithm for the
comprehensive estimation of all unknown system parameters, including friction.
This methodology is based on Gaussian Process Regression (GPR) and Least
Squares (LS) estimations. Finally, experimental validation with a laboratory
crane confirms the effectiveness of the proposed modeling and estimation
approach.

</details>


### [150] [Right-to-Override for Critical Urban Control Systems: A Deliberative Audit Method for Buildings, Power, and Transport](https://arxiv.org/abs/2509.13369)
*Rashid Mushkani*

Main category: eess.SY

TL;DR: 提出了Right-to-Override（R2O）框架和Deliberative Audit Method（DAM），让居民能够暂停或重定向自动化系统，减少分布性伤害，同时保持效率。


<details>
  <summary>Details</summary>
Motivation: 当前自动化系统（如建筑HVAC、电网、交通信号）缺乏居民干预机制，当这些系统损害包容性、安全性或可访问性时，居民无法暂停或重定向它们。

Method: 定义了R2O框架（包括覆盖权限、证据阈值和领域验证的安全回退状态），并引入DAM方法（包含预部署演练、影子模式试验和事后审查的剧本）。在智能电网减载、建筑HVAC和交通信号等场景进行模拟验证。

Result: R2O显著减少了分布性伤害：未服务能源的减载差异从5.61倍降至0.69倍；为老年人消除2小时不适的能源成本为77kWh；行人等待中位数从90.4秒降至55.9秒，车辆平均延迟仅增加6.0秒。

Conclusion: R2O/DAM框架使城市自动化系统具有可争议性和可审查性，在有限效率损失下有效减少分布性伤害，并提供了政策标准、审计工作表等实用工具。

Abstract: Automation now steers building HVAC, distribution grids, and traffic signals,
yet residents rarely have authority to pause or redirect these systems when
they harm inclusivity, safety, or accessibility. We formalize a
Right-to-Override (R2O) - defining override authorities, evidentiary
thresholds, and domain-validated safe fallback states - and introduce a
Deliberative Audit Method (DAM) with playbooks for pre-deployment walkthroughs,
shadow-mode trials, and post-incident review. We instantiate R2O/DAM in
simulations of smart-grid load shedding, building HVAC under occupancy
uncertainty, and multi-agent traffic signals. R2O reduces distributional harm
with limited efficiency loss: load-shedding disparity in unserved energy drops
from 5.61x to 0.69x with constant curtailment; an override eliminates two
discomfort-hours for seniors at an energy cost of 77 kWh; and median pedestrian
wait falls from 90.4 s to 55.9 s with a 6.0 s increase in mean vehicle delay.
We also contribute a policy standard, audit worksheets, and a ModelOps
integration pattern to make urban automation contestable and reviewable.

</details>


### [151] [A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings](https://arxiv.org/abs/2509.13371)
*Xuyuan Kang,Xiao Wang,Jingjing An,Da Yan*

Main category: eess.SY

TL;DR: 提出了一种基于负荷预测的冰蓄冷系统优化控制方法，通过集成负荷预测和规则控制策略，实现了9.9%的能源成本节约


<details>
  <summary>Details</summary>
Motivation: 现有TES系统大多采用固定运行计划，无法充分利用其负荷转移能力，需要大量调查和优化工作

Method: 开发了冷却负荷预测模型并引入午间修正机制，基于预测结果根据分时电价制定规则控制策略，并引入午间控制调整机制

Result: 在北京某商业综合体的冰蓄冷系统中应用，MAE为389kW，变异系数12.5%，能源成本节约率达9.9%

Conclusion: 所提方法在实际楼宇自动化系统中部署，显著提高了冷却系统的效率和自动化水平

Abstract: Thermal energy storage (TES) is an effective method for load shifting and
demand response in buildings. Optimal TES control and management are essential
to improve the performance of the cooling system. Most existing TES systems
operate on a fixed schedule, which cannot take full advantage of its load
shifting capability, and requires extensive investigation and optimization.
This study proposed a novel integrated load prediction and optimized control
approach for ice-based TES in commercial buildings. A cooling load prediction
model was developed and a mid-day modification mechanism was introduced into
the prediction model to improve the accuracy. Based on the predictions, a
rule-based control strategy was proposed according to the time-of-use tariff;
the mid-day control adjustment mechanism was introduced in accordance with the
mid-day prediction modifications. The proposed approach was applied in the
ice-based TES system of a commercial complex in Beijing, and achieved a mean
absolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The
integrated prediction-based control strategy achieved an energy cost saving
rate of 9.9%. The proposed model was deployed in the realistic building
automation system of the case building and significantly improved the
efficiency and automation of the cooling system.

</details>


### [152] [Identifying Network Structure of Nonlinear Dynamical Systems: Contraction and Kuramoto Oscillators](https://arxiv.org/abs/2509.13505)
*Jaidev Gill,Jing Shuang Li*

Main category: eess.SY

TL;DR: 该论文研究了非线性网络系统在部分节点测量下的拓扑可识别性问题，发现某些不同拓扑结构可能产生相似的测量结果，从而限制了可识别性。


<details>
  <summary>Details</summary>
Motivation: 研究网络非线性系统在部分测量条件下拓扑结构的可识别性，探索不同候选拓扑产生相似测量结果的情况，这对于网络系统识别和拓扑推断具有重要意义。

Method: 应用收缩理论框架来比较候选拓扑结构，证明可观测空间中的半收缩性是两个系统基于部分测量变得不可区分的一个充分条件。

Result: 将框架应用于Kuramoto振荡器网络，发现了不同拓扑结构（包括连接和断开的情况）变得不可区分的具体场景。

Conclusion: 部分测量条件下网络拓扑的可识别性存在局限性，半收缩理论为分析这种不可区分性提供了有效的理论框架，这对于理解网络系统识别的根本限制具有重要意义。

Abstract: In this work, we study the identifiability of network topologies for
networked nonlinear systems when partial measurements of the nodes are taken.
We explore scenarios where different candidate topologies can yield similar
measurements, thus limiting identifiability. To do so, we apply the contraction
theory framework to facilitate comparisons between candidate topologies. We
show that semicontraction in the observable space is a sufficient condition for
two systems to become indistinguishable from one another based on partial
measurements. We apply this framework to study networks of Kuramoto
oscillators, and discuss scenarios in which different topologies (both
connected and disconnected) become indistinguishable.

</details>


### [153] [The impact of modeling approaches on controlling safety-critical, highly perturbed systems: the case for data-driven models](https://arxiv.org/abs/2509.13531)
*Piotr Łaszkiewicz,Maria Carvalho,Cláudia Soares,Pedro Lourenço*

Main category: eess.SY

TL;DR: 本文评估了三种系统模型对LQR最优控制器参考轨迹跟踪误差的影响，比较了数据驱动的平滑线性时变系统(DD-LTV)与传统LTV系统辨识方法在强扰动和重构条件下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 在强扰动和系统重构的挑战性条件下，需要评估不同系统模型对最优控制器跟踪性能的影响，特别是比较数据驱动方法与传统方法的优劣。

Method: 使用三种系统模型：数据驱动的线性时变系统(DD-LTV)、标准线性时不变系统(LTI)和线性化线性时变系统(L-LTV)，在受扰动和时间变化的弹簧-质量-阻尼器系统上进行测试比较。

Result: DD-LTV在状态传播任务上优于最先进的LTV系统辨识方法，在轨迹跟踪误差方面比标准LTI模型表现更好，性能与L-LTV模型相当。

Conclusion: 数据驱动的线性时变系统(DD-LTV)在强扰动条件下表现出优越的性能，为复杂环境下的控制系统设计提供了有效解决方案。

Abstract: This paper evaluates the impact of three system models on the reference
trajectory tracking error of the LQR optimal controller, in the challenging
problem of guidance and control of the state of a system under strong
perturbations and reconfiguration. We compared a smooth Linear Time Variant
system learned from data (DD-LTV) with state of the art Linear Time Variant
(LTV) system identification methods, showing its superiority in the task of
state propagation. Moreover, we have found that DD-LTV allows for better
performance in terms of trajectory tracking error than the standard solutions
of a Linear Time Invariant (LTI) system model, and comparable performance to a
linearized Linear Time Variant (L-LTV) system model. We tested the three
approaches on the perturbed and time varying spring-mass-damper systems.

</details>


### [154] [Zero-sum turn games using Q-learning: finite computation with security guarantees](https://arxiv.org/abs/2509.13585)
*Sean Anderson,Chris Darken,João Hespanha*

Main category: eess.SY

TL;DR: 本文针对零和"回合制"博弈，提出了基于动态规划固定点方程的纯鞍点状态反馈策略构建方法，以及适用于折扣和无折扣成本的Q学习收敛性分析，并提出了对手知情探索策略来保证安全水平。


<details>
  <summary>Details</summary>
Motivation: 解决回合制零和博弈中纯鞍点策略的构建问题，特别是在复杂游戏中Q学习提前终止可能导致策略无法保证最终Q函数所隐含的安全水平的问题。

Method: 使用动态规划固定点方程构建纯鞍点状态反馈策略，采用Q学习方法进行求解，对于无折扣成本提供有限时间确定性博弈的收敛性证明，并提出对手知情探索策略来选择Q学习样本。

Result: 为折扣成本建立了Q学习的收敛性，为无折扣成本提供了有限时间确定性博弈的收敛结果，数值实验表明所提方法在多智能体游戏Atlatl中有效。

Conclusion: 提出的动态规划方法和Q学习算法能够有效解决回合制零和博弈问题，对手知情探索策略可以保证最终Q函数提供的安全水平至少对给定策略集成立。

Abstract: This paper addresses zero-sum ``turn'' games, in which only one player can
make decisions at each state. We show that pure saddle-point state-feedback
policies for turn games can be constructed from dynamic programming fixed-point
equations for a single value function or Q-function. These fixed-points can be
constructed using a suitable form of Q-learning. For discounted costs,
convergence of this form of Q-learning can be established using classical
techniques. For undiscounted costs, we provide a convergence result that
applies to finite-time deterministic games, which we use to illustrate our
results. For complex games, the Q-learning iteration must be terminated before
exploring the full-state, which can lead to policies that cannot guarantee the
security levels implied by the final Q-function. To mitigate this, we propose
an ``opponent-informed'' exploration policy for selecting the Q-learning
samples. This form of exploration can guarantee that the final Q-function
provides security levels that hold, at least, against a given set of policies.
A numerical demonstration for a multi-agent game, Atlatl, indicates the
effectiveness of these methods.

</details>


### [155] [A Game-Theoretic Predictive Control Framework with Statistical Collision Avoidance Constraints for Autonomous Vehicle Overtaking](https://arxiv.org/abs/2509.13545)
*Sheng Yu,Boli Chen,Imad M. Jaimoukha,Simos A. Evangelou*

Main category: eess.SY

TL;DR: 开发了一个用于混合交通环境中CAV自主超车的控制框架GT-PRO，通过博弈论和模型预测控制协调纵向和横向动力学，利用真实数据集优化控制器，实现更安全高效的超车。


<details>
  <summary>Details</summary>
Motivation: 在混合交通环境中，当被超车车辆是人工驾驶的非联网车辆时，需要处理其实时交互行为，现有方法难以有效协调纵向和横向控制。

Method: 提出GT-PRO策略，使用动态Stackelberg博弈的双层优化控制横向运动并预测被超车响应，结合随机MPC控制纵向运动，利用真实人类驾驶数据优化控制器参数。

Result: 仿真结果表明，GT-PRO在各种人类驾驶员响应情况下都能实现更安全、高效和舒适的自主超车，且具备实时实施能力。

Conclusion: GT-PRO框架成功解决了混合交通环境中的自主超车问题，通过博弈论和MPC的协同控制，显著提升了超车性能，具有实际应用价值。

Abstract: This work develops a control framework for the autonomous overtaking of
connected and automated vehicles (CAVs) in a mixed traffic environment, where
the overtaken vehicle is an unconnected but interactive human-driven vehicle.
The proposed method, termed the Game-Theoretic, PRedictive Overtaking (GT-PRO)
strategy, successfully decouples the longitudinal and lateral vehicle dynamics
of the CAV and comprehensively coordinates these decoupled dynamics via
innovative longitudinal and lateral model predictive (MPC) based controllers,
respectively. To address the real-time interactive behavior of the human-driven
overtaken vehicle, a dynamic Stackelberg game-based bilevel optimization is
solved by the lateral controller to directly control the CAV lateral motion and
predict the overtaken vehicle longitudinal responses that are subsequently
shared with a stochastic MPC that governs the CAV longitudinal motion. The
proposed strategy exploits a comprehensive real-world dataset, which captures
human driver responses when being overtaken, to tune the game-theoretic lateral
controller according to the most common human responses, and to statistically
characterize human uncertainties and hence implement a collision avoidance
chance constraint for the stochastic longitudinal controller. The simulation
results for both polite and aggressive human response case studies of the
overtaken vehicle demonstrate that the proposed GT-PRO can achieve for this
range of human driver responsiveness, safer, more efficient, and more
comfortable autonomous overtaking, as compared to existing autonomous
overtaking approaches in the literature. Furthermore, the results suggest that
the GT-PRO method is capable of real-time implementation.

</details>


### [156] [Modeling and Verification of Lumped-Parameter, Multibody Structural Dynamics for Offshore Wind Turbines](https://arxiv.org/abs/2509.13558)
*Saad Rahman,Doyal Sarker,Tri Ngo,Roger Bergua,Daniel Zalkind,Jason Jonkman,Tuhin Das*

Main category: eess.SY

TL;DR: 本文提出了一种用于海上风力涡轮机的多体结构动力学建模与验证方法，采用非因果、集总参数的多体方法对柔性塔架和支撑结构进行建模，包含结构柔性、土-结构相互作用和水动力模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够准确捕捉海上风力涡轮机在各种风浪条件下静态和动态行为的计算高效模型，为分析关键结构特性提供有价值的工具。

Method: 使用非因果、集总参数的多体方法对单桩基础海上风力涡轮机的柔性塔架和支撑结构进行建模，整合了结构柔性、土-结构相互作用和水动力模型。

Result: 仿真结果与其他建模方法进行了基准测试，证明该模型能够准确捕捉静态和动态行为，同时保持计算效率。

Conclusion: 该工作为分析风力涡轮机的关键结构特性（包括特征频率、模态形状、阻尼和内力）提供了一个有价值的建模工具。

Abstract: This paper presents the modeling and verification of multibody structural
dynamics for offshore wind turbines. The flexible tower and support structure
of a monopile-based offshore wind turbine are modeled using an acausal,
lumped-parameter, multibody approach that incorporates structural flexibility,
soil-structure interaction, and hydrodynamic models. Simulation results are
benchmarked against alternative modeling approaches, demonstrating the model's
ability to accurately capture both static and dynamic behaviors under various
wind and wave conditions while maintaining computational efficiency. This work
provides a valuable tool for analyzing key structural characteristics of wind
turbines, including eigenfrequencies, mode shapes, damping, and internal
forces.

</details>


### [157] [Multi-Attacker Single-Defender Target Defense in Conical Environments](https://arxiv.org/abs/2509.13564)
*Arman Pourghorban,Dipankar Maity*

Main category: eess.SY

TL;DR: 本文研究平面锥形环境中的目标防御问题，单个防御者需要捕获一系列连续出现的攻击者。攻击者选择对当前和未来交战都有利的策略，双方基于有限感知范围进行博弈，推导出最优捕获率的均衡策略。


<details>
  <summary>Details</summary>
Motivation: 解决连续攻击场景下的目标防御问题，考虑攻击者的策略选择不仅影响当前交战，还会影响后续攻击者的成功率，需要建立多阶段博弈模型。

Method: 使用博弈论方法推导均衡策略，基于捕获分布概念优化捕获百分比，并通过蒙特卡洛随机实验进行数值验证。

Result: 建立了攻击者和防御者的最优策略模型，得出了在有限感知范围内的均衡解，验证了理论结果的正确性。

Conclusion: 该研究为连续目标防御问题提供了有效的博弈论解决方案，攻击者的策略选择对整体防御效果有重要影响，理论模型通过实验验证具有实用价值。

Abstract: We consider a variant of the target defense problem in a planar conical
environment where a single defender is tasked to capture a sequence of incoming
attackers. The attackers' objective is to breach the target boundary without
being captured by the defender. As soon as the current attacker breaches the
target or gets captured by the defender, the next attacker appears at the
boundary of the environment and moves radially toward the target with maximum
speed. Therefore, the defender's final location at the end of the current game
becomes its initial location for the next game. The attackers pick strategies
that are advantageous for the current as well as for future engagements between
the defender and the remaining attackers. The attackers have their own sensors
with limited range, using which they can perfectly detect if the defender is
within their sensing range. We derive equilibrium strategies for all the
players to optimize the capture percentage using the notions of capture
distribution. Finally, the theoretical results are verified through numerical
examples using Monte Carlo type random trials of experiments.

</details>


### [158] [Impact of Solar Integration on Grid Security: Unveiling Vulnerabilities in Load Redistribution Attacks](https://arxiv.org/abs/2509.13567)
*Praveen Verma,Di Shi,Yanzhu Ye,Fengyu Wang,Ying Zhang*

Main category: eess.SY

TL;DR: 本文提出了一种增强型负载重分配攻击模型，针对太阳能发电并网带来的新漏洞，通过操纵太阳能发电数据显著破坏电网经济性。


<details>
  <summary>Details</summary>
Motivation: 传统负载重分配攻击模型假设发电机测量数据安全不可篡改，但随着太阳能发电在电网中的集成度不断提高，这一假设受到挑战，暴露出新的安全漏洞。

Method: 提出增强型负载重分配攻击模型，专门针对太阳能发电并网带来的新漏洞，通过操纵太阳能发电数据来误导安全约束经济调度决策。

Result: 研究表明操纵太阳能发电数据能显著破坏电网经济性，在太阳能发电高峰期影响最为严重。

Conclusion: 太阳能发电的集成带来了新的电网安全漏洞，需要开发针对性的防护措施来应对这类增强型负载重分配攻击。

Abstract: Load redistribution (LR) attacks represent a practical and sophisticated form
of false data injection (FDI) attacks, where the attacker manipulates grid data
to influence economic operations of the grid through misleading security
constrained economic dispatch (SCED) decisions. Traditionally, LR attack models
operate under the assumption that generator measurements are secure and immune
to tampering. However, the increasing integration of solar generation into
power grids challenges this assumption, exposing new vulnerabilities. This
paper proposes an enhanced load redistribution attack model, addressing new
vulnerabilities introduced by the increasing integration of solar generation in
power grids. The study demonstrates that manipulating solar generation data
significantly disrupts grid economics, with peak impacts during periods of high
solar generation.

</details>


### [159] [Scaling green hydrogen and CCUS via cement-methanol co-production in China](https://arxiv.org/abs/2509.13674)
*Yuezhang He,Hongxi Luo,Yuancheng Lin,Carl J. Talsma,Anna Li,Zhenqian Wang,Yujuan Fang,Pei Liu,Jesse D. Jenkins,Eric Larson,Zheng Li*

Main category: eess.SY

TL;DR: 提出可再生能源驱动的氢-CCUS联产系统，通过分子交换耦合电解制氢和碳捕集，可显著降低水泥和甲醇行业的脱碳成本


<details>
  <summary>Details</summary>
Motivation: 绿色氢气和CCUS的高成本阻碍了难以减排行业（如水泥和甲醇）的脱碳进程，需要寻找经济可行的整合方案

Method: 使用小时分辨率的基于过程的模型优化系统配置，考虑运行灵活性，探索工厂级部署和中国范围内的CO2源汇匹配策略

Result: 联产系统可将CO2减排成本降至41-53美元/吨（2035年），显著低于单独水泥CCUS（约75美元）和可再生甲醇（超过120美元）

Conclusion: 氢-CCUS耦合范式可加速工业脱碳，优先在可再生能源丰富地区的水泥厂部署，可能重塑国家CO2基础设施规划

Abstract: High costs of green hydrogen and of carbon capture, utilization, and
sequestration (CCUS) have hindered policy ambition and slowed real-world
deployment, despite their importance for decarbonizing hard-to-abate sectors,
including cement and methanol. Given the economic challenges of adopting CCUS
in cement and green hydrogen in methanol production separately, we propose a
renewable-powered co-production system that couples electrolytic hydrogen and
CCUS through molecule exchange. We optimize system configurations using an
hourly-resolved, process-based model incorporating operational flexibility, and
explore integrated strategies for plant-level deployment and CO2 source-sink
matching across China. We find that co-production could reduce CO2 abatement
costs to USD 41-53 per tonne by 2035, significantly lower than approximately
USD 75 for standalone cement CCUS and over USD 120 for standalone
renewable-based methanol. Co-production is preferentially deployed at cement
plants in renewable-rich regions, potentially reshaping national CO2
infrastructure planning. This hydrogen-CCUS coupling paradigm could accelerate
industrial decarbonization and scaling for other applications.

</details>


### [160] [Scale Up Analysis of Inductively Heated Metamaterial Reactors](https://arxiv.org/abs/2509.13719)
*Chenghao Wan,Conner Cremers,Ariana B. Höfelmann,Zhennan Ru,Calvin H. Lin,Kesha N. Tamakuwala,Dolly Mantle,Pinak Mohapatra,Juan Rivas-Davila,Matthew W. Kanan,Jonathan A. Fan*

Main category: eess.SY

TL;DR: 本文通过分析建模、数值模拟和实验，系统研究了感应加热超材料反应器的放大性能，发现通过调控超材料感受器的径向有效电导率分布可以克服温度梯度限制，实现接近理想活塞流的放大反应器。


<details>
  <summary>Details</summary>
Motivation: 感应加热超材料反应器具有体积加热特性和增强的传热性能，是规模化电热化学反应器的有前景候选方案，但需要系统研究其放大性能和限制因素。

Method: 采用分析建模、数值模拟和实验相结合的方法，以逆水煤气变换反应为模型体系，研究均匀超材料感受器反应器的放大性能，并探索通过调控径向有效电导率分布来优化性能。

Result: 研究发现，对于均匀超材料感受器的反应器配置，系统总效率随规模增大而提高，但吞吐量受径向温度梯度限制。通过定制感受器的径向有效电导率分布可以克服这一瓶颈。

Conclusion: 这些概念为开发具有最佳化学转化能力的规模化电热化学反应器提供了可行路径，通过优化超材料感受器的热导率分布可以实现接近理想活塞流的反应器性能。

Abstract: Inductively heated metamaterial reactors, which utilize an open cell lattice
baffle structure as a heating susceptor for magnetic induction, are promising
candidates for scaled electrified thermochemical reactor operation due to their
ability to support volumetric heating profiles and enhanced heat transfer
properties. In this work, we present a systematic scale up analysis of
inductive metamaterial reactors where we utilize a combination of analytic
modeling, numerical simulations, and experiments to project the capabilities
and performance of scaled reactors. We use reverse water gas shift as a model
reaction system and show that for reactor configurations featuring a uniform
metamaterial susceptor, the total system efficiency increases with scale.
However, the throughput of these scaled reactors is limited by radial
temperature gradients. We further show this bottleneck can be overcome by
tailoring the radial effective conductivity profile of the susceptor, which can
enable scaled reactors with nearly ideal plug flow-like capabilities. These
concepts provide a pathway towards scaled electrified thermochemical reactors
with optimal chemical conversion capabilities.

</details>


### [161] [Characterizing Human Limb Movements Using An In-House Multi-Channel Non-Invasive Surface-EMG System](https://arxiv.org/abs/2509.13840)
*Vinay C K,Vikas Vazhayil,Madhav rao*

Main category: eess.SY

TL;DR: 开发了一个8通道非侵入式表面肌电信号采集系统，结合支持向量机分类器，成功实现了对人体上下肢各关节运动的表征和分类。


<details>
  <summary>Details</summary>
Motivation: 传统肌电信号采集需要侵入式电极，本研究旨在开发非侵入式表面EMG系统，用于神经肌肉疾病患者的运动障碍研究和仿生控制设计。

Method: 设计并制造了8通道表面EMG信号采集系统，采用模块化前端模拟电路设计，使用支持向量机(SVM)作为分类器模型进行离线分析。

Result: 系统成功表征了手指、手腕、肘部、肩部、膝盖和脚踝等多个关节的个体运动，能够准确分类不同的人体肢体动作。

Conclusion: 该非侵入式EMG采集系统结合机器学习分类器，为神经肌肉疾病患者的运动研究和仿生控制应用提供了有效的技术解决方案。

Abstract: Electromyography (EMG) signals are obtained from muscle cell activity. The
recording and analysis of EMG signals has several applications. The EMG is of
diagnostic importance for treating patients suffering from neurological and
neuromuscular disorders. Conventional methods involve placement of invasive
electrodes within the muscles to record EMG signals. The goal is to showcase
the usage of surface based EMG signals to characterize all possible human limb
movements. An in-house non-invasive EMG signal acquisition system that offers
characterization of human limb actions is a suitable candidate for motor
impairment studies and easily extendable to design bionics control specifically
for neuromuscular disorder patients. An in-house 8-channel surface-EMG signal
acquisition system was designed, fabricated, and employed for characterizing
specific movements of upper and lower limb. The non-invasive acquisition system
captures the compound electromuscular activity generated from the group of
muscles. The EMG acquisition system was designed as a modular structure where
the front end analog circuit designs were replicated for all 8 channels, and
were designed to function independently. Support vector machine (SVM) as
classifier models were developed offline to successfully characterize different
human limb actions. The in house built 8 channel acquisition system with ML
classifier models were utilized to successfully characterize movements at
various joints of the upper and lower limb including fingers, wrist, elbow,
shoulder, knee, and ankle individually.

</details>


### [162] [Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection](https://arxiv.org/abs/2509.13934)
*Zhixion Chen,Jiangzhou Wang,and Hyundong Shin,Arumugam Nallanathan*

Main category: eess.SY

TL;DR: 提出LLM-CRDT框架，结合大语言模型和决策变换器，用于无人机轨迹规划和资源分配，提高数据收集能效


<details>
  <summary>Details</summary>
Motivation: 解决无人机在IoT数据收集中续航和通信范围有限的问题，传统强化学习方法成本高风险大，离线RL训练不稳定且依赖专家数据集

Method: 将资源分配子问题转化为线性规划求解，提出LLM-CRDT框架：使用评论家网络正则化决策变换器训练，采用预训练LLM作为变换器骨干，使用LoRA参数高效微调策略

Result: 在仿真中优于基准在线和离线RL方法，比当前最先进的DT方法能效提高36.7%

Conclusion: LLM-CRDT框架能够从小规模次优数据集中学习有效策略，实现高效的无人机轨迹规划和资源分配

Abstract: The deployment of unmanned aerial vehicles (UAVs) for reliable and
energy-efficient data collection from spatially distributed devices holds great
promise in supporting diverse Internet of Things (IoT) applications.
Nevertheless, the limited endurance and communication range of UAVs necessitate
intelligent trajectory planning. While reinforcement learning (RL) has been
extensively explored for UAV trajectory optimization, its interactive nature
entails high costs and risks in real-world environments. Offline RL mitigates
these issues but remains susceptible to unstable training and heavily rely on
expert-quality datasets. To address these challenges, we formulate a joint UAV
trajectory planning and resource allocation problem to maximize energy
efficiency of data collection. The resource allocation subproblem is first
transformed into an equivalent linear programming formulation and solved
optimally with polynomial-time complexity. Then, we propose a large language
model (LLM)-empowered critic-regularized decision transformer (DT) framework,
termed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we
incorporate critic networks to regularize the DT model training, thereby
integrating the sequence modeling capabilities of DT with critic-based value
guidance to enable learning effective policies from suboptimal datasets.
Furthermore, to mitigate the data-hungry nature of transformer models, we
employ a pre-trained LLM as the transformer backbone of the DT model and adopt
a parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid
adaptation to UAV control tasks with small-scale dataset and low computational
overhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark
online and offline RL methods, achieving up to 36.7\% higher energy efficiency
than the current state-of-the-art DT approaches.

</details>


### [163] [Distributionally Robust Equilibria over the Wasserstein Distance for Generalized Nash Game](https://arxiv.org/abs/2509.13985)
*Yixun Wen,Yulong Gao,Boli Chen*

Main category: eess.SY

TL;DR: 本文研究具有共享分布鲁棒机会约束的广义纳什均衡问题，提出将原问题转化为确定性混合整数非线性规划问题的精确方法，显著提高了计算可行性。


<details>
  <summary>Details</summary>
Motivation: 广义纳什均衡问题在实际应用中很重要，但需要考虑不确定性。分布鲁棒机会约束能够有效处理有限样本数据下的不确定性，但计算复杂度高，需要有效的求解方法。

Method: 使用Nikaido-Isoda函数将原问题转化为确定性公式。当所有智能体目标函数在其变量上为二次型时，可将均衡求解转化为混合整数非线性规划问题，其中整数和连续变量在目标函数和约束中解耦。

Result: 提出的方法显著提高了计算可行性，通过充电站定价问题的案例研究验证了方法的有效性。

Conclusion: 该方法为处理具有分布鲁棒机会约束的广义纳什均衡问题提供了有效的计算框架，特别适用于目标函数为二次型的情况，具有重要的实际应用价值。

Abstract: Generalized Nash equilibrium problem (GNEP) is fundamental for practical
applications where multiple self-interested agents work together to make
optimal decisions. In this work, we study GNEP with shared distributionally
robust chance constraints (DRCCs) for incorporating inevitable uncertainties.
The DRCCs are defined over the Wasserstein ball, which can be explicitly
characterized even with limited sample data. To determine the equilibrium of
the GNEP, we propose an exact approach to transform the original
computationally intractable problem into a deterministic formulation using the
Nikaido-Isoda function. Specifically, we show that when all agents' objectives
are quadratic in their respective variables, the equilibrium can be obtained by
solving a typical mixed-integer nonlinear programming (MINLP) problem, where
the integer and continuous variables are decoupled in both the objective
function and the constraints. This structure significantly improves
computational tractability, as demonstrated through a case study on the
charging station pricing problem.

</details>


### [164] [Day-Ahead Transmission Grid Topology Optimization Considering Renewable Energy Sources' Uncertainty](https://arxiv.org/abs/2509.13994)
*Giacomo Bastianel,Dirk Van Hertem,Hakan Ergun,Line Roald*

Main category: eess.SY

TL;DR: 该论文提出了一种结合最优输电切换和母线分裂的电网拓扑优化模型，用于处理高比例可再生能源接入带来的不确定性，通过随机优化方法减少电网拥堵和总成本。


<details>
  <summary>Details</summary>
Motivation: 可再生能源渗透率增加导致电力系统运行不确定性增大，现有输电网络经常拥堵且扩容困难，需要低成本解决方案来保证高效电力传输。

Method: 采用基于场景的随机优化方法，结合最优输电切换和母线分裂技术，使用K-means聚类生成代表性预测误差场景，构建混合整数二次凸优化问题。

Result: 在AC 30节点和混合AC/DC 50节点测试案例中，电网拓扑优化在拥堵和高可再生能源渗透情况下带来显著经济效益，6-8个场景的随机优化比确定性预测成本更低或相当。

Conclusion: 电网拓扑优化是应对高比例可再生能源接入和网络拥堵的有效非昂贵解决方案，考虑可再生能源不确定性可进一步降低成本，即使限制拓扑操作频率也能获得良好效果。

Abstract: The increasing renewable penetration introduces significant uncertainty in
power system operations. At the same time, the existing transmission grid is
often already congested, and urgently needed reinforcements are frequently
delayed due to several constraints. To address these challenges, adjusting the
grid topology based on congestion patterns is considered a non-costly remedy to
guarantee efficient power transmission. Based on this idea, this paper proposes
a grid topology optimization model combining optimal transmission switching and
busbar splitting for AC and hybrid AC/DC grids. The methodology incorporates
RES forecast uncertainty through a scenario-based stochastic optimization
approach, using real offshore wind data and K-means clustering to generate
representative forecast error scenarios. The proposed model includes several
formulations to be compared with a plain optimal power flow (OPF) model: hourly
optimizing the topology, one topology for 24 hours, or a limited number of
switching actions over a day. The grid topology optimization model is
formulated as a Mixed-Integer Quadratic Convex Problem, optimized based on the
day-ahead (D-1) RES forecast and validated for AC-feasibility via an AC-OPF
formulation. Based on the generation setpoints of the feasibility check, a
redispatch simulation based on the measured (D) RES realization is then
computed. The methodology is tested on an AC 30-bus test case and a hybrid
AC/DC 50-bus test case, for a 24-hours (30-bus) and a 14-days (both test cases)
time series. The results highlight the economic benefits brought by grid
topology optimization for congested test cases with high penetration of RES. In
addition, the results demonstrate that accounting for RES uncertainty with at
least 6 to 8 scenarios leads to lower or comparable total costs to
deterministic day-ahead forecasts, even when limiting the frequency of
topological actions.

</details>


### [165] [Dissipativity-Based Data-Driven Decentralized Control of Interconnected Systems](https://arxiv.org/abs/2509.14047)
*Taiki Nakano,Ahmed Aboudonia,Jaap Eising,Andrea Martinelli,Florian Dörfler,John Lygeros*

Main category: eess.SY

TL;DR: 提出基于数据的分散式控制算法，通过耗散性理论实现互联系统的稳定控制，使用线性矩阵不等式条件，并在微电网场景中验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统集中式控制在大型互联系统中面临可扩展性和计算复杂度问题，需要开发数据驱动的分散式控制方法来处理子系统间的相互作用

Method: 首先推导数据驱动的局部控制器合成条件确保子系统耗散性，然后基于各子系统耗散性提出全局系统的数据驱动分散稳定性条件，均采用线性矩阵不等式形式

Result: 建立了统一的数据驱动分散控制流程，特别针对扩散耦合互联系统提出了控制算法，在微电网数值示例中验证了算法的有效性和可扩展性

Conclusion: 该方法为互联系统提供了一种实用的数据驱动分散控制解决方案，特别适用于大规模系统如微电网，具有良好的应用前景

Abstract: We propose data-driven decentralized control algorithms for stabilizing
interconnected systems. We first derive a data-driven condition to synthesize a
local controller that ensures the dissipativity of the local subsystems. Then,
we propose data-driven decentralized stability conditions for the global system
based on the dissipativity of each local system. Since both conditions take the
form of linear matrix inequalities and are based on dissipativity theory, this
yields a unified pipeline, resulting in a data-driven decentralized control
algorithm. As a special case, we also consider stabilizing systems
interconnected through diffusive coupling and propose a control algorithm. We
validate the effectiveness and the scalability of the proposed control
algorithms in numerical examples in the context of microgrids.

</details>


### [166] [Identifying Network Structure of Linear Dynamical Systems: Observability and Edge Misclassification](https://arxiv.org/abs/2509.14065)
*Jaidev Gill,Jing Shuang Li*

Main category: eess.SY

TL;DR: 该研究分析了线性网络拓扑识别在部分节点测量下的局限性，揭示了多个结构不一致的网络可能产生相同的测量结果，并提供了可能网络空间的聚合特征分析。


<details>
  <summary>Details</summary>
Motivation: 研究线性网络拓扑识别中部分测量数据的局限性，揭示现有拓扑推理方法中常被忽视的问题——多个结构不同的网络可能产生完全一致的测量结果。

Method: 通过分析观测矩阵的零空间来研究网络一致性关系，解析求解结构最不相似网络来表征可能网络空间，构建保持测量ε-接近的网络族，并与增广观测Gramian的谱特性相关联。

Result: 在随机网络模型（如Erdős-Rényi和Watts-Strogatz）中，当观测超过6%的节点时，边误分类率降至约1%。构建的网络族能够保持测量结果在ε范围内接近。

Conclusion: 线性网络拓扑识别存在根本性限制，多个结构不同的网络可能产生相同的部分测量结果。研究为拓扑推理方法的设计提供了重要理论指导，强调了考虑网络一致性空间的重要性。

Abstract: This work studies the limitations of uniquely identifying a linear network's
topology from partial measurements of its nodes. We show that the set of
networks that are consistent with the measurements are related through the
nullspace of the observability matrix for the true network. In doing so, we
illustrate how potentially many networks are fully consistent with the
measurements despite having topologies that are structurally inconsistent with
each other, an often neglected consideration in the design of topology
inference methods. We then provide an aggregate characterization of the space
of possible networks by analytically solving for the most structurally
dissimilar network. We find that when observing over 6% of nodes in random
network models (e.g., Erd\H{o}s-R\'{e}nyi and Watts-Strogatz) the rate of edge
misclassification drops to ~1%. Extending this discussion, we construct a
family of networks that keep measurements $\epsilon$-"close" to each other, and
connect the identifiability of these networks to the spectral properties of an
augmented observability Gramian.

</details>


### [167] [Asymptotic Boundedness of Distributed Set-Membership Filtering](https://arxiv.org/abs/2509.14106)
*Yudong Li,Yirui Cong,Shimin Wang,Martin Guay,Jiuxiang Dong*

Main category: eess.SY

TL;DR: 本文研究了线性离散时间系统分布式集合成员滤波的渐近有界性，提出了集体观测信息塔概念，建立了易于验证的充分条件，并将结果推广到集体可检测性条件。


<details>
  <summary>Details</summary>
Motivation: 分布式集合成员滤波的渐近有界性是一个重要但研究不足的性质，相比无噪声和随机噪声情况下的分布式观测器和卡尔曼滤波，需要更深入的分析。

Method: 引入了集体观测信息塔概念来描述图结构与集合估计之间的基本关系，利用这一概念建立了线性分布式集合成员滤波渐近有界性的充分条件。

Result: 建立了一个易于验证的充分条件，该条件推广了分布式观测器和卡尔曼滤波的集体可检测性条件，揭示了分布式集合成员滤波的独特特性。

Conclusion: 该研究将分布式集合成员滤波与现有分布式估计方法联系起来，通过集体观测信息塔概念为渐近有界性分析提供了新的理论框架。

Abstract: Asymptotic boundedness is a crucial property of Distributed Set-Membership
Filtering (DSMFing) that prevents the unbounded growth of the set estimates
caused by the wrapping effect. However, this important property remains
underinvestigated, compared to its noise-free and stochastic-noise
counterparts, i.e., the convergence of Distributed Observers (DOs) and the
bounded error covariance of Distributed Kalman Filters (DKFs). This paper
studies the asymptotic boundedness of DSMFing for linear discrete-time systems.
A novel concept, termed the Collective Observation-Information Tower (COIT), is
introduced to characterize the fundamental relationship between the structure
of graphs and the set estimates, which enables the boundedness analysis.
Leveraging the COIT, an easily verifiable sufficient condition for the
asymptotic boundedness of linear DSMFing is established. Surprisingly, the
sufficient condition generalizes the well-known collective detectability
condition for DOs and DKFs; it links DSMFs to existing distributed estimation
methods and reveals the unique characteristic of DSMFs.

</details>


### [168] [Safe Sliding Mode Control in Position for Double Integrator Systems](https://arxiv.org/abs/2509.14121)
*Marco A. Gomez,Christopher D. Cruz-Ancona*

Main category: eess.SY

TL;DR: 提出了一种针对双积分器系统的鲁棒安全控制设计方法，通过构建安全滑动域确保系统在位置状态约束下保持安全，并设计了保证收敛到安全域的控制器增益。


<details>
  <summary>Details</summary>
Motivation: 解决双积分器系统在仅位置状态约束下的鲁棒安全控制问题，确保系统在不确定性和干扰下仍能保持安全状态。

Method: 首先从简单积分器的安全动态构建安全滑动域，然后设计控制器增益保证系统收敛到该安全域并避开不安全区域，最后将一阶滑模概念推广到自适应框架。

Result: 成功构建了安全滑动域，使闭环轨迹在不确定性和干扰下保持鲁棒安全，控制器增益能确保系统收敛到安全域并避开不安全集。

Conclusion: 该方法为双积分器系统提供了有效的鲁棒安全控制解决方案，通过安全滑动域和自适应框架确保系统始终保持在安全区域内运行。

Abstract: We address the problem of robust safety control design for double integrator
systems. We show that, when the constraints are defined only on position
states, it is possible to construct a safe sliding domain from the dynamic of a
simple integrator that is already safe. On this domain, the closed-loop
trajectories remain robust and safe against uncertainties and disturbances.
Furthermore, we design a controller gain that guarantees convergence to the
safe sliding domain while avoiding the given unsafe set. The concept is
initially developed for first-order sliding mode and is subsequently
generalized to an adaptive framework, ensuring that trajectories remain
confined to a predefined vicinity of the sliding domain, outside the unsafe
region.

</details>


### [169] [Factored Output Feedback Controller Synthesis with Locality Constraints for Spatially-Invariant Systems](https://arxiv.org/abs/2509.14168)
*Walden Marshall*

Main category: eess.SY

TL;DR: 本文提出了两种参数化框架（系统级和输入输出参数化）来解决具有空间通信距离约束的H2输出反馈控制器综合问题，证明了该问题可转化为凸优化问题，且决策变量数量与允许通信距离呈线性关系。


<details>
  <summary>Details</summary>
Motivation: 针对空间不变系统，需要在保证控制器性能的同时满足预定义的空间通信距离约束，即控制器的通信只能在有限距离内进行，这在实际分布式控制系统中具有重要意义。

Method: 使用系统级参数化和输入输出参数化两种框架，将具有局部性约束的输出反馈控制器综合问题表述为有限多个传递函数变量的凸优化问题，并证明了两种参数化方法的等价性。

Result: 证明了控制器设计问题可以转化为凸优化问题，决策变量数量与允许通信距离呈线性比例关系，通过数值算例展示了通信稀疏性与性能之间的权衡关系。

Conclusion: 所提出的方法能够有效处理具有空间通信约束的控制器设计问题，为分布式控制系统提供了实用的设计框架，两种参数化方法在特定系统下具有等价性。

Abstract: We consider H2 output feedback controller synthesis with pre-specified
constraints on spatial communication distance (locality) for
spatially-invariant systems using two factored controller frameworks: the
system-level parameterization and the input-output parameterization. In our
main result, we show that in both frameworks, output feedback controller
synthesis with locality constraints can be formulated as a convex problem in
finitely many transfer function variables, admitting the use of standard
numerical solution techniques. The number of decision variables in the optimal
controller design problem scales linearly with the distance of allowed
communication. We also show that the optimal controller design problems for the
system-level and input-ouptput parameterizations are equivalent for the chosen
system of interest. We present numerical examples to illustrate the tradeoff
between communication sparsity and performance.

</details>


<div id='cs.SY'></div>

# cs.SY [[Back]](#toc)

### [170] [Location and allocation problem of high-speed train maintenance bases](https://arxiv.org/abs/2509.13383)
*Boliang Lin,Xiang Li,Yuxue Gu,Dishen Lu*

Main category: cs.SY

TL;DR: 本文提出双层规划模型优化高铁维修基地选址，通过上层最小化年化总成本（投资+维护成本），下层优化列车调度至最合适维修基地，在西北高铁网络案例中验证了哈密新建基地和西安基地扩建的最优方案。


<details>
  <summary>Details</summary>
Motivation: 高铁维修基地对列车安全稳定运行至关重要，但在广阔的高铁网络中规划基地位置和任务分配是复杂的组合优化问题，需要科学的优化方法来确保维修工作的可靠性和效率。

Method: 采用双层规划模型，上层目标是最小化年化总成本（包括新建/扩建基地投资和总维护成本），下层重点是将高速列车调度到最合适的维修基地以降低维护运营调度成本。

Result: 西北高铁网络案例研究表明，在哈密新建基地和扩建西安基地可在规划期内最小化年化总成本，总计达到22.7815亿元人民币，并通过敏感性分析反映了维修政策改革的影响。

Conclusion: 该研究为维修基地选址提供了优化方法，能够确保随着未来列车数量增加时维修工作的可靠性和效率。

Abstract: Maintenance bases are crucial for the safe and stable operation of high-speed
trains, necessitating significant financial investment for their construction
and operation. Planning the location and task allocation of these bases in the
vast high-speed railway network is a complex combinatorial optimization
problem. This paper explored the strategic planning of identifying optimal
locations for maintenance bases, introducing a bi-level programming model. The
upper-level objective was to minimize the annualized total cost, including
investment for new or expanding bases and total maintenance costs, while the
lower-level focused on dispatching high-speed trains to the most suitable base
for maintenance tasks, thereby reducing maintenance operation dispatch costs
under various investment scenarios. A case study of the Northwest China
high-speed rail network demonstrated the application of this model, and
included the sensitivity analysis reflecting maintenance policy reforms. The
results showed that establishing a new base in Hami and expanding Xi'an base
could minimize the total annualized cost during the planning period, amounting
to a total of 2,278.15 million RMB. This paper offers an optimization method
for selecting maintenance base locations that ensures reliability and
efficiency in maintenance work as the number of trains increases in the future.

</details>


### [171] [Modeling skiers flows via Wardrope equilibrium in closed capacitated networks](https://arxiv.org/abs/2509.13392)
*Demyan Yarmoshik,Igor Ignashin,Ekaterina Sikacheva,Alexander Gasnikov*

Main category: cs.SY

TL;DR: 提出滑雪场均衡模型，通过凸优化计算有限容量缆车队列等待时间，使用变分不等式建模并验证标准算法有效性


<details>
  <summary>Details</summary>
Motivation: 解决滑雪场用户分配和缆车队列等待时间计算问题，为拥挤网络中的用户均衡提供有效计算方法

Method: 建立封闭网络中的用户循环分配模型，通过凸优化求解等待时间，将均衡问题表述为变分不等式

Result: 数值实验表明该均衡模型可以使用标准算法有效求解

Conclusion: 提出的方法为滑雪场等拥挤网络中的用户均衡问题提供了有效的计算框架

Abstract: We propose an equilibrium model of ski resorts where users are assigned to
cycles in a closed network. As queues form on lifts with limited capacity, we
derive an efficient way to find waiting times via convex optimization. The
equilibrium problem is formulated as a variational inequality, and numerical
experiments show that it can be solved using standard algorithms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [172] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

TL;DR: 本研究系统比较了在LLM-as-a-judge范式下"思考"与"非思考"模型的表现，发现思考模型在准确率、计算效率和鲁棒性方面均优于非思考模型，即使经过增强策略改进后仍有明显差距。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地被用作自动评判工具，确保其可靠性、效率和鲁棒性变得至关重要。本研究旨在系统比较思考与非思考模型在这一范式下的表现差异。

Method: 使用开源Qwen 3小规模模型（0.6B、1.7B和4B参数），在RewardBench任务上评估准确性和计算效率（FLOPs），并测试了多种增强策略：上下文学习、规则引导评判、基于参考的评估和n-best聚合。

Result: 思考模型准确率高出约10个百分点，计算开销仅增加不到2倍；而增强策略如小样本学习虽然带来一定提升但成本较高（>8倍）。在多种偏见条件下，思考模型保持显著更高的一致性（平均高6%）。多语言实验也证实了显式推理的优势。

Conclusion: 显式推理在LLM-as-a-judge范式中具有明显优势，不仅在准确性和效率方面，在鲁棒性方面也表现更好，为这一范式提供了系统性证据支持。

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [173] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

TL;DR: 研究发现大型语言模型存在评估意识，即模型能够区分评估和部署环境，这种能力随模型规模呈幂律增长，可用于预测未来更大模型的欺骗行为。


<details>
  <summary>Details</summary>
Motivation: 先前研究仅在单个70B参数模型中观察到评估意识现象，但不同规模模型间的评估意识缩放关系尚不清楚，这影响了AI安全评估的有效性。

Method: 使用线性探测方法分析15个不同规模模型（0.27B到70B参数）的转向向量激活，研究评估意识的缩放规律。

Result: 发现评估意识随模型规模呈幂律增长，建立了可预测的缩放定律，能够预测未来更大模型的欺骗性行为。

Conclusion: 该缩放定律为设计规模感知的AI安全评估策略提供了指导，有助于更准确地评估大型语言模型的安全风险。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [174] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

TL;DR: FRIT是一种通过干预训练提升大语言模型推理忠实性的对齐方法，通过生成忠实/不忠实推理对并应用直接偏好优化，使模型偏好因果一致的推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有链式思维推理方法存在推理步骤与最终答案缺乏因果关联的问题，导致输出脆弱且不可信。虽然已有方法关注忠实性度量，但系统性提升忠实性的方法仍然有限。

Method: 提出FRIT方法：1）在模型生成的推理链中对单个推理步骤进行干预，生成忠实/不忠实推理对；2）应用直接偏好优化训练模型偏好因果一致的推理路径。

Result: 在Qwen3-8B和Mistral-7B-v0.1模型上测试，FRIT使Mistral在GSM8K任务上的忠实推理提升3.4个百分点，准确率提升7.6个百分点。

Conclusion: FRIT提供了首个可扩展、无监督的方法来训练语言模型产生更可靠和可解释的推理，解决了推理性能与可信度之间的关键差距。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [175] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: 该立场论文主张现代AI安全研究应采用抗脆弱性视角，使系统处理罕见或分布外事件的能力随时间增强，而非依赖静态测试。


<details>
  <summary>Details</summary>
Motivation: 传统静态基准测试和一次性鲁棒性测试无法应对环境动态变化和模型可能出现的奖励攻击、过度优化等问题，需要新的方法来确保AI系统的长期安全性。

Method: 提出抗脆弱性方法，利用不确定性来为未来更大的不可预测性做准备，重新校准AI安全的测量、基准测试和持续改进方法。

Result: 识别了静态测试的关键局限性（场景多样性不足、奖励攻击、过度对齐），并探索了抗脆弱性解决方案处理罕见事件的潜力。

Conclusion: 抗脆弱性方法对于开放式机器学习系统的长期可靠性至关重要，需要建立相应的伦理和实践指南来培育抗脆弱性AI安全社区。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [176] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: IMAC方法利用世界模型生成想象环境，通过无监督环境设计自动生成课程，在有限数据下训练出能泛化到新任务的鲁棒智能体


<details>
  <summary>Details</summary>
Motivation: 解决在具身环境中训练智能体需要大量训练数据或精确仿真的问题，利用离线被动收集的数据通过世界模型生成多样化的训练环境

Method: 提出IMAC（想象自动课程）方法，结合无监督环境设计（UED）在世界模型生成的想象环境中自动生成课程，确保智能体训练数据的有效性

Result: 在具有挑战性的程序生成环境中，仅使用较窄数据集学习的世界模型进行训练，就能在保留环境中实现强大的迁移性能

Conclusion: 该方法为利用更大规模的基础世界模型训练通用智能体开辟了新路径

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [177] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 本文系统比较了不同抽象动作空间在Minecraft环境中的表现，发现最优动作空间高度依赖具体任务。为此提出了Chain of Action (CoA)框架，将高层规划和底层控制统一在单一VLA模型中，通过混合动作空间训练实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决动作空间选择这一关键但未解决的挑战，因为研究发现没有单一动作空间在所有任务中都最优，这给构建通用智能体带来了困境。

Method: 提出了Chain of Action (CoA)框架，将抽象动作视为中间推理步骤而非单独策略的命令，在单一VLA模型中统一高层规划和底层控制。使用混合动作空间训练All-in-One智能体。

Result: CoA框架训练的智能体实现了新的最先进性能，相比专门的基线模型提高了整体任务成功率，学习到了更鲁棒和可泛化的策略。

Conclusion: CoA框架成功解决了动作空间选择的困境，通过统一规划和控制实现了更好的性能，并发布了OpenHA套件促进可重复研究。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [178] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

TL;DR: PDDL-Instruct框架通过逻辑思维链推理增强大语言模型的符号规划能力，在标准基准测试中达到94%的规划准确率，比基线模型提升66%


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多种任务上表现出色，但在需要形式化表示（如PDDL）的结构化符号规划方面能力有限，需要弥合通用推理能力与自动规划所需逻辑精度之间的差距

Method: 开发指令调优框架，通过指导模型进行精确的逻辑推理步骤来教授动作适用性、状态转换和计划有效性，使用逻辑思维链推理分解规划过程为明确的前提条件满足、效果应用和不变性保持

Result: 在多个规划领域的实验结果显示，基于思维链推理的指令调优模型规划能力显著提升，在标准基准测试中达到94%的规划准确率

Conclusion: 该工作为大语言模型与自动规划之间的能力差距提供了桥梁，为开发更好的AI规划系统指明了有前景的方向

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [179] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 提出了一个基于大语言模型的Agentic UAVs框架，通过五层架构增强无人机自主性，在搜救模拟中显著提升了检测准确率和决策能力


<details>
  <summary>Details</summary>
Motivation: 现有无人机系统主要依赖基于规则的控制和窄AI，缺乏上下文感知推理、自主决策和生态系统集成能力，无法充分利用大语言模型的实时知识访问优势

Method: 设计五层架构（感知、推理、行动、集成、学习），集成ROS2和Gazebo原型，结合YOLOv11目标检测与GPT-4推理，部署本地Gemma-3模型

Result: 在模拟搜救场景中，检测置信度从0.72提升至0.79，人员检测率从75%提升至91%，行动推荐率从4.5%大幅提升至92%

Conclusion: 适度的计算开销即可实现质的自主性提升和生态系统集成，证明了LLM驱动的无人机框架在动态不确定任务中的有效性

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [180] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

TL;DR: 提出语义融合方案，通过并行模糊成员特征通道增强Transformer语言模型，实现可解释的语义特征融合和可控生成


<details>
  <summary>Details</summary>
Motivation: 增强语言模型的语义理解能力，提供可解释的特征表示和用户可控的文本生成，同时保持模型轻量化和兼容性

Method: 为每个token构建包含词性、浅层角色、边界标志、情感极性等可解释特征的向量，通过门控适配器将语义矩阵融合到语言模型中，使用标准下一个token预测、辅助重建损失和轻量级正则化器进行训练

Result: 在合成双子句语料库上，语义融合提高了困惑度，实现了精确的用户可控极性标点生成，同时保持模型简洁性

Conclusion: 语义融合方案以较小开销增强了语言模型的语义能力，提供了可解释的条件自然语言生成路径，完全兼容现有的输入输出嵌入结构

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [181] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

TL;DR: 提出了星号操作符（∗-operator），一个基于邻接结构并行传播（ASPP）的统一抽象推理框架，将结构化推理任务形式化为由隐式关系图指导的局部并行状态演化过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决抽象推理问题，需要一种既能保持局部计算约束又能实现全局推理能力的统一框架，以提供高效且收敛的计算范式。

Method: 采用邻接结构并行传播（ASPP）方法，通过星号操作符将推理任务建模为局部并行状态演化过程，并提出了创新的Embedding-Asterisk蒸馏方法。

Result: 在ARC2挑战和康威生命游戏中验证了操作符的通用性、收敛性和优越性能，使用仅6M参数在ARC2验证集上达到100%准确率。

Conclusion: 星号操作符为神经符号推理领域提供了重大突破，实现了局部计算约束下的全局推理能力，为抽象推理问题提供了高效且收敛的计算解决方案。

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [182] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: Agent²是一个完全自动化的强化学习代理生成框架，通过LLM驱动将自然语言任务描述转换为高性能RL解决方案，无需人工干预


<details>
  <summary>Details</summary>
Motivation: 传统RL代理开发需要大量专业知识和迭代，失败率高且可访问性有限，需要自动化解决方案

Method: 采用双代理架构：生成器代理分析任务并生成可执行RL代理，目标代理是自动生成的RL代理。框架将RL开发分解为MDP建模和算法优化两个阶段

Result: 在MuJoCo、MetaDrive、MPE和SMAC等多个基准测试中，Agent²始终优于人工设计的解决方案，性能提升高达55%

Conclusion: 这项工作建立了智能代理设计和优化其他代理的新范式，实现了真正端到端的闭环自动化，是自动化AI系统的根本突破

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [183] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

TL;DR: 该研究对16个最先进的视觉语言模型进行了全面的不确定性基准测试，发现更大模型具有更好的不确定性量化能力，数学和推理任务的不确定性表现较差。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在复杂视觉理解方面取得了显著进展，但不确定性量化这一关键维度尚未得到足够关注，需要对此进行系统性评估。

Method: 在6个多模态数据集上评估16个开源和闭源的最先进VLMs，使用3种不同的评分函数进行全面的不确定性基准测试研究。

Result: 研究发现：1) 更大模型具有更好的不确定性量化能力；2) 更确定的模型准确率更高；3) 数学和推理任务的不确定性表现普遍较差。

Conclusion: 这项工作为多模态系统中可靠的不确定性评估奠定了基础，强调了模型规模与不确定性量化能力之间的正相关关系。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [184] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

TL;DR: 使用Transformer架构从动作序列中学习命题STRIPS世界模型，通过监督式的下一个token预测任务来推断动作前提条件和隐藏效果。


<details>
  <summary>Details</summary>
Motivation: 从纯动作轨迹中学习世界模型是一个重要但具有挑战性的问题，传统方法需要完整的状态信息，而本文旨在仅通过动作序列就能推断出隐藏的世界模型结构。

Method: 将任务建模为监督式的下一个token预测问题，使用Transformer架构，通过正负样本（有效和无效动作序列）来学习动作的前提条件和效果。

Result: 实验表明合适的Transformer架构能够准确表示命题STRIPS世界模型，并且仅从随机生成的正负动作序列中就能成功学习到这些模型。

Conclusion: 深度学习方法特别是Transformer架构能够有效从动作序列中学习世界模型，为从观察数据中推断隐藏状态结构提供了新的途径。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [185] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: SteeringControl是一个评估表示引导方法的基准，重点关注偏见、有害生成和幻觉等核心对齐目标，以及这些方法对次要行为（如奉承和常识道德）的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐工作往往只关注真实性或推理能力来展示表示引导的副作用，但许多权衡关系尚未得到系统性的理解。

Method: 构建了一个包含安全相关主要和次要行为的数据集，基于五个流行引导方法创建模块化引导框架，在Qwen-2.5-7B和Llama-3.1-8B模型上进行评估。

Result: 发现强引导性能取决于引导方法、模型和目标行为的特定组合，不良组合会导致严重的概念纠缠问题。

Conclusion: 表示引导的效果具有高度情境依赖性，需要仔细选择方法、模型和行为目标的组合，以避免意外的负面副作用。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [186] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: 为LLM智能体提供类似人类的协作工具和自主性可以显著提升其在最困难编程问题上的性能表现，但效果因问题难度而异


<details>
  <summary>Details</summary>
Motivation: 研究是否通过赋予LLM智能体人类自然使用的协作工具和自主性，能够改善它们的问题解决能力

Method: 为Claude Code智能体配备基于MCP的社交媒体和日志工具，让它们自主决定如何使用这些工具来解决34个Aider多语言Python编程挑战

Result: 在最困难问题上，协作工具使成本降低15-40%，轮次减少12-27%，完成时间加快12-38%。不同模型自然采用不同的协作策略，Sonnet 3.7广泛使用工具，Sonnet 4在真正困难时依赖基于日志的语义搜索

Conclusion: AI智能体在其能力边界处可以从人类启发的协作工具中系统性获益，这表明自适应协作界面可以作为推理增强器而非通用效率提升工具

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [187] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

TL;DR: 本研究调查了本科生在证明数学课程中使用生成式AI的情况，分析了学生的使用模式、感知有用性和局限性，并探讨了对证明数学教学的启示。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的快速兴起和现有AI检测工具的不可靠性，制定能够促进学生学习和批判性思维的政策变得日益重要。

Method: 通过调查问卷和学生访谈，分析了三个证明数学课程（抽象代数、拓扑学）中学生对生成式AI工具的使用情况和看法。

Result: 研究发现学生对生成式AI工具的使用方式和感知存在差异，揭示了这些工具在证明数学中的有用性和局限性。

Conclusion: 研究为将生成式AI整合到证明数学教学中提供了未来考虑方向，强调需要制定鼓励学生学习和批判性思维的政策。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [188] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: CoBRA是一个用于在基于LLM的社会模拟中系统化指定智能体行为的新工具包，通过显式编程认知偏见来解决传统自然语言描述方法的一致性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过隐式自然语言描述指定智能体行为存在两个问题：无法在不同模型间产生一致行为，且生成的行为无法捕捉描述的细微差别。

Method: CoBRA包含两个组件：1) 认知偏见指数 - 通过量化智能体在一组经过验证的经典社会科学实验中的反应来测量其认知偏见；2) 行为调节引擎 - 调整智能体行为以展示受控的认知偏见。

Result: 评估显示CoBRA能够以模型无关的方式精确编程社会智能体中展示的认知偏见。

Conclusion: CoBRA提供了一个有效的工具包，能够系统化和精确地控制LLM-based社会模拟中智能体的认知偏见行为。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [189] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 提出了State-aware Reasoning (StaR)方法，通过训练多模态代理感知当前切换状态并执行相应操作，显著提升了GUI切换控制指令的执行准确率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态代理在执行GUI切换控制指令时可靠性不足，特别是在当前状态与期望状态一致时表现不佳，这成为GUI控制的关键瓶颈。

Method: 构建状态控制基准测试集，提出StaR训练方法，教导代理感知当前切换状态、分析指令中的期望状态，并相应执行操作。

Result: 在三个多模态代理上实验显示，StaR能将切换指令执行准确率提升30%以上，在三个公共基准测试中也提升了通用任务性能。

Conclusion: StaR方法有效解决了GUI切换控制问题，在动态环境评估中显示出实际应用的潜力，为多模态代理的GUI交互提供了可靠解决方案。

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [190] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: InfraMind是一个专门为工业管理系统设计的基于探索的GUI代理框架，通过五个创新模块解决LLM-based GUI代理在工业管理中的五大挑战，在DCIM平台上显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 工业基础设施管理面临系统复杂性增加、多供应商集成和专家操作员短缺等挑战。现有RPA自动化方案灵活性有限且维护成本高，而通用LLM-based GUI代理在工业管理中存在元素理解、精度效率、状态定位、部署约束和安全要求等五大挑战。

Method: 提出InfraMind框架，包含五个核心模块：(1)基于系统搜索探索和虚拟机快照的自主GUI理解；(2)内存驱动规划确保高精度高效任务执行；(3)高级状态识别用于层次化界面中的鲁棒定位；(4)结构化知识蒸馏实现轻量模型高效部署；(5)多层安全机制保护敏感操作。

Result: 在开源和商业DCIM平台上的广泛实验表明，该方法在任务成功率和操作效率方面持续优于现有框架。

Conclusion: InfraMind为工业管理自动化提供了一个严谨且可扩展的解决方案，有效解决了LLM-based GUI代理在工业环境中的关键挑战。

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [191] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: THOR是一个通过强化学习实现工具集成分层优化的方法，用于提升LLM在数学推理中的性能，包括数据生成、分层优化和推理增强三个核心组件


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理方面取得显著进展，但在高精度任务如数值计算和符号操作方面仍有困难，现有工具集成方法面临数据构建、细粒度优化和推理增强三大挑战

Method: 提出THOR框架：1) TIRGen多智能体actor-critic管道构建高质量工具集成推理数据集；2) 分层RL策略联合优化轨迹级问题解决和步骤级代码生成；3) 推理时利用工具反馈进行动态错误修正

Result: 方法在不同模型上表现出强泛化能力，在多个数学基准测试中达到同类规模模型的最先进性能，同时在代码基准测试上也获得一致改进

Conclusion: THOR通过工具集成和分层优化有效提升了LLM的数学推理能力，为解决高精度计算任务提供了有前景的解决方案

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [192] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA是一个智能手机AI任务指令推荐框架，通过长按图像或文本来提供上下文相关的AI任务指令建议，使用MLLM和结构化推理来提升推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的快速发展，智能手机需要更直观的方式来访问预定义的AI服务，简化用户与AI服务的交互过程。

Method: 1) 基于多模态大语言模型(MLLM)的推荐流水线，进行结构化推理提取关键实体和推断用户意图；2) 模板增强推理机制整合高级推理模板；3) 基于前缀树的约束解码策略限制输出到预定义指令候选集。

Result: 通过真实世界标注数据集和用户研究评估，MIRA在指令推荐准确性方面显示出显著改进。

Conclusion: MIRA有潜力彻底改变用户在智能手机上与AI服务的交互方式，提供更无缝和高效的体验。

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [193] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

TL;DR: 本文提出了一种基于DPLL架构的精确方法来解决整数线性约束的模型计数问题(MCILC)，通过整合混合整数规划中的简化技术显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: 线性约束是计算机科学、运筹学和优化领域中最基本的约束之一，许多应用都归结为整数线性约束的模型计数问题，需要高效的解决方案。

Method: 基于详尽的DPLL架构设计精确方法，整合混合整数规划中的有效简化技术来提高效率。

Result: 在2840个随机基准测试和4131个应用基准测试中，该方法解决了1718个随机实例（优于最先进方法的1470个），并且是唯一能解决所有4131个应用实例的方法。

Conclusion: 该方法在整数线性约束模型计数方面显著优于现有精确方法，特别是在应用实例上表现出色。

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [194] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

TL;DR: 该研究使用人工神经网络模型探讨信息流结构变化是否会导致认知性能的过渡性变化，发现循环网络相比前馈网络在处理复杂语法学习任务时表现出质的性能提升，并观察到训练难度形成的过渡障碍。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证认知进化是否通过一系列主要过渡来实现，这些过渡通过操纵生物神经网络结构来根本改变信息流，从而产生认知性能的质变。

Method: 使用理想化的信息流模型和人工神经网络，比较前馈、循环和分层拓扑结构的网络性能，控制网络大小和资源，测试它们学习不同复杂度人工语法的能力。

Result: 循环网络相比前馈网络能够处理更多类型的输入，在最复杂语法学习任务中表现出质的性能提升。循环网络的训练难度形成了过渡障碍和偶然不可逆性。分层网络在语法学习任务中并未表现出优势。

Conclusion: 某些信息流结构的变化确实能够产生认知性能的过渡性变化，这支持了认知进化可能通过主要过渡来实现的观点，但并非所有网络拓扑变化都能带来性能优势。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [195] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: CrowdAgent是一个多智能体系统，通过整合任务分配、数据标注和质量/成本管理，为LLM、SLM和人类专家提供端到端的协同标注流程控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注标注步骤本身，缺乏对多样化标注源（LLM、SLM、人类专家）的动态管理和复杂调度需求，需要统一的质-成本权衡解决方案。

Method: 采用多智能体系统架构，实现任务分配、数据标注和质量管理的端到端流程控制，让不同标注源在协作标注工作流中协同推进。

Result: 在六个多样化多模态分类任务上的广泛实验证明了CrowdAgent的有效性。

Conclusion: CrowdAgent提供了一个统一框架来动态管理多样化标注源，解决了复杂调度和质-成本权衡问题，显著提升了标注流程的效率和质量。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [196] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 本文通过层次架构（GCN作为一阶学习器，MLP作为二阶学习器）实证验证了二阶学习促进环境-认知同构性形成的假设，证明当认知系统发展出与环境结构同构的心理地图时，二阶学习效果最佳。


<details>
  <summary>Details</summary>
Motivation: 研究心智表征（与环境结构同构的内部模型）对高级认知的重要性，但现有研究缺乏实证验证。理论假设二阶学习（调整一阶学习机制的学习）能促进这种环境-认知同构性的形成。

Method: 提出分层架构：使用图卷积网络（GCN）作为一阶学习器直接映射节点特征到最优导航路径预测，使用MLP控制器作为二阶学习器在遇到结构新颖的迷宫环境时动态调整GCN参数。

Result: 定量和定性结果显示，当认知系统发展出与环境结构同构的内部心理地图时，二阶学习特别有效，在未见过的迷宫任务上表现出显著的性能提升和强大的泛化能力。

Conclusion: 研究为结构化心智表征在最大化二阶学习效果中的关键作用提供了实证支持，验证了二阶学习促进环境-认知同构性形成的理论假设。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [197] [A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds](https://arxiv.org/abs/2509.13390)
*Deepti Kunte,Bram Cornelis,Claudio Colangeli,Karl Janssens,Brecht Van Baelen,Konstantinos Gryllias*

Main category: cs.SD

TL;DR: 提出了一种基于领域知识的模型选择方法，通过工程化代理异常来改进汽车舱音异常检测的无监督学习模型选择


<details>
  <summary>Details</summary>
Motivation: 汽车舱音异常检测通常是无监督学习问题，但由于缺乏标注的故障数据和验证指标不可靠，模型选择面临重大挑战

Method: 使用健康样本的频谱图进行结构化扰动来创建代理异常，在验证集中支持模型选择

Result: 在包含五种典型故障类型的高保真电动车数据集上，使用代理异常选择的模型显著优于传统模型选择策略

Conclusion: 基于领域知识的代理异常方法为无监督异常检测提供了有效的模型选择解决方案

Abstract: The detection of anomalies in automotive cabin sounds is critical for
ensuring vehicle quality and maintaining passenger comfort. In many real-world
settings, this task is more appropriately framed as an unsupervised learning
problem rather than the supervised case due to the scarcity or complete absence
of labeled faulty data. In such an unsupervised setting, the model is trained
exclusively on healthy samples and detects anomalies as deviations from normal
behavior. However, in the absence of labeled faulty samples for validation and
the limited reliability of commonly used metrics, such as validation
reconstruction error, effective model selection remains a significant
challenge. To overcome these limitations, a domain-knowledge-informed approach
for model selection is proposed, in which proxy-anomalies engineered through
structured perturbations of healthy spectrograms are used in the validation set
to support model selection. The proposed methodology is evaluated on a
high-fidelity electric vehicle dataset comprising healthy and faulty cabin
sounds across five representative fault types viz., Imbalance, Modulation,
Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced
sound synthesis techniques, and validated via expert jury assessments, has been
made publicly available to facilitate further research. Experimental
evaluations on the five fault cases demonstrate the selection of optimal models
using proxy-anomalies, significantly outperform conventional model selection
strategies.

</details>


### [198] [Field of View Enhanced Signal Dependent Binauralization with Mixture of Experts Framework for Continuous Source Motion](https://arxiv.org/abs/2509.13548)
*Manan Mittal,Thomas Deppisch,Joseph Forrer,Chris Le Sueur,Zamir Ben-Hur,David Lou Along,Daniel D. E. Wong*

Main category: cs.SD

TL;DR: 提出了一种新颖的专家混合框架，用于双耳信号匹配中的视场增强，支持动态空间音频渲染和实时声源跟踪


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖显式到达方向估计或在Ambisonics域操作，无法有效处理连续说话者运动，需要一种能够自适应增强或抑制特定方向声音的方法

Method: 基于信号依赖的框架，通过隐式定位在线组合多个双耳滤波器，实现实时移动声源跟踪和增强，不依赖阵列几何形状

Result: 能够实现动态空间音频渲染，支持语音聚焦、噪声抑制和AR/VR中的世界锁定音频应用

Conclusion: 该方法为下一代消费音频设备提供了灵活的空间音频捕获和个性化播放解决方案

Abstract: We propose a novel mixture of experts framework for field-of-view enhancement
in binaural signal matching. Our approach enables dynamic spatial audio
rendering that adapts to continuous talker motion, allowing users to emphasize
or suppress sounds from selected directions while preserving natural binaural
cues. Unlike traditional methods that rely on explicit direction-of-arrival
estimation or operate in the Ambisonics domain, our signal-dependent framework
combines multiple binaural filters in an online manner using implicit
localization. This allows for real-time tracking and enhancement of moving
sound sources, supporting applications such as speech focus, noise reduction,
and world-locked audio in augmented and virtual reality. The method is agnostic
to array geometry offering a flexible solution for spatial audio capture and
personalized playback in next-generation consumer audio devices.

</details>


### [199] [Neural Speech Separation with Parallel Amplitude and Phase Spectrum Estimation](https://arxiv.org/abs/2509.13825)
*Fei Liu,Yang Ai,Zhen-Hua Ling*

Main category: cs.SD

TL;DR: APSS是一种新颖的神经语音分离模型，通过并行估计振幅和相位谱来实现更完整准确的语音分离，在多个数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语音分离方法大多没有显式估计相位谱，导致分离结果不够完整和准确。APSS旨在通过并行处理振幅和相位谱来改进语音分离质量。

Method: APSS首先从混合语音信号中提取振幅和相位谱，通过特征组合器融合成联合表示，使用时频Transformer捕获时频依赖关系，最后通过并行分离器估计各说话人的频谱并进行iSTFT重建。

Result: 实验结果表明APSS超越了时域分离方法和基于隐式相位估计的时频方法，在多个数据集上获得稳定且具有竞争力的结果。

Conclusion: APSS通过显式并行估计振幅和相位谱，展现了强大的泛化能力和实际应用价值，为语音分离领域提供了有效的解决方案。

Abstract: This paper proposes APSS, a novel neural speech separation model with
parallel amplitude and phase spectrum estimation. Unlike most existing speech
separation methods, the APSS distinguishes itself by explicitly estimating the
phase spectrum for more complete and accurate separation. Specifically, APSS
first extracts the amplitude and phase spectra from the mixed speech signal.
Subsequently, the extracted amplitude and phase spectra are fused by a feature
combiner into joint representations, which are then further processed by a deep
processor with time-frequency Transformers to capture temporal and spectral
dependencies. Finally, leveraging parallel amplitude and phase separators, the
APSS estimates the respective spectra for each speaker from the resulting
features, which are then combined via inverse short-time Fourier transform
(iSTFT) to reconstruct the separated speech signals. Experimental results
indicate that APSS surpasses both time-domain separation methods and
implicit-phase-estimation-based time-frequency approaches. Also, APSS achieves
stable and competitive results on multiple datasets, highlighting its strong
generalization capability and practical applicability.

</details>


### [200] [Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection](https://arxiv.org/abs/2509.13853)
*Shun Huang,Zhihua Fang,Liang He*

Main category: cs.SD

TL;DR: 本文提出了一种名为OS-SCL的单阶段监督对比学习方法，通过嵌入空间特征扰动和噪声监督对比学习，有效解决了无监督异常声音检测中不同机器同类型样本误报率高的问题，并在DCASE 2020挑战赛上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 当前无监督异常声音检测方法在处理来自不同机器的同类型样本时存在频繁误报的问题，尽管自监督方法有所进展，但这一问题仍未得到有效解决。

Method: 提出OS-SCL训练技术：1）在嵌入空间中进行特征扰动；2）采用单阶段噪声监督对比学习方法；3）提出新的时频特征TFgram从原始音频中提取关键信息。

Result: 仅使用Log-Mel特征时达到94.64% AUC、88.42% pAUC和89.24% mAUC；使用TFgram特征时性能进一步提升至95.71% AUC、90.23% pAUC和91.23% mAUC。

Conclusion: OS-SCL方法有效解决了无监督异常声音检测中的误报问题，TFgram特征能够更好地捕捉异常检测所需的关键信息，在DCASE 2020挑战赛上取得了state-of-the-art的性能。

Abstract: Unsupervised anomalous sound detection aims to detect unknown anomalous
sounds by training a model using only normal audio data. Despite advancements
in self-supervised methods, the issue of frequent false alarms when handling
samples of the same type from different machines remains unresolved. This paper
introduces a novel training technique called one-stage supervised contrastive
learning (OS-SCL), which significantly addresses this problem by perturbing
features in the embedding space and employing a one-stage noisy supervised
contrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved
94.64\% AUC, 88.42\% pAUC, and 89.24\% mAUC using only Log-Mel features.
Additionally, a time-frequency feature named TFgram is proposed, which is
extracted from raw audio. This feature effectively captures critical
information for anomalous sound detection, ultimately achieving 95.71\% AUC,
90.23\% pAUC, and 91.23\% mAUC. The source code is available at:
\underline{www.github.com/huangswt/OS-SCL}.

</details>


### [201] [RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing](https://arxiv.org/abs/2509.14003)
*Liting Gao,Yi Yuan,Yaru Chen,Yuelan Cheng,Zhenbo Li,Juan Wen,Shubin Zhang,Wenwu Wang*

Main category: cs.SD

TL;DR: 提出了一种基于修正流匹配扩散框架的端到端高效音频编辑方法，在复杂场景下实现无需辅助标注或掩码的语义对齐编辑


<details>
  <summary>Details</summary>
Motivation: 文本引导的音频编辑仍处于早期阶段，现有方法在处理复杂编辑时存在困难或缺乏实用性，需要精确的定位和基于文本提示的忠实编辑

Method: 基于修正流匹配的端到端扩散框架，构建了包含重叠多事件音频的数据集来支持复杂场景的训练和基准测试

Result: 实验表明该模型无需辅助标注或掩码即可实现忠实的语义对齐，在各项指标上保持竞争力的编辑质量

Conclusion: 提出的方法为文本引导音频编辑提供了一种高效实用的解决方案，在复杂编辑场景中表现出色

Abstract: Diffusion models have shown remarkable progress in text-to-audio generation.
However, text-guided audio editing remains in its early stages. This task
focuses on modifying the target content within an audio signal while preserving
the rest, thus demanding precise localization and faithful editing according to
the text prompt. Existing training-based and zero-shot methods that rely on
full-caption or costly optimization often struggle with complex editing or lack
practicality. In this work, we propose a novel end-to-end efficient rectified
flow matching-based diffusion framework for audio editing, and construct a
dataset featuring overlapping multi-event audio to support training and
benchmarking in complex scenarios. Experiments show that our model achieves
faithful semantic alignment without requiring auxiliary captions or masks,
while maintaining competitive editing quality across metrics.

</details>


### [202] [Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices](https://arxiv.org/abs/2509.14049)
*Jordi Grau-Haro,Ruben Ribes-Serrano,Javier Naranjo-Alcazar,Marta Garcia-Ballesteros,Pedro Zuccarello*

Main category: cs.SD

TL;DR: 对多种CNN架构在树莓派上进行音频标签任务的综合评估，包括1D/2D PANNs模型、ConvNeXt变体、MobileNetV3等，通过ONNX格式转换和24小时连续推理测试性能稳定性


<details>
  <summary>Details</summary>
Motivation: 解决CNN音频标签模型在资源受限设备（如树莓派）上部署时面临的计算效率和热管理挑战

Method: 评估多种CNN架构（PANNs框架的1D/2D模型、ConvNeXt音频分类适配版、MobileNetV3、CNN9和CNN13），转换为ONNX格式，进行24小时连续推理会话测试

Result: 通过适当的模型选择和优化，可以在长时间内保持一致的推理延迟并有效管理热行为

Conclusion: 为在实际边缘计算场景中部署音频标签模型提供了有价值的见解，证明在资源受限设备上实现稳定性能的可行性

Abstract: Convolutional Neural Networks (CNNs) have demonstrated exceptional
performance in audio tagging tasks. However, deploying these models on
resource-constrained devices like the Raspberry Pi poses challenges related to
computational efficiency and thermal management. In this paper, a comprehensive
evaluation of multiple convolutional neural network (CNN) architectures for
audio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D
models from the Pretrained Audio Neural Networks (PANNs) framework, a
ConvNeXt-based model adapted for audio classification, as well as MobileNetV3
architectures. In addition, two PANNs-derived networks, CNN9 and CNN13,
recently proposed, are also evaluated. To enhance deployment efficiency and
portability across diverse hardware platforms, all models are converted to the
Open Neural Network Exchange (ONNX) format. Unlike previous works that focus on
a single model, our analysis encompasses a broader range of architectures and
involves continuous 24-hour inference sessions to assess performance stability.
Our experiments reveal that, with appropriate model selection and optimization,
it is possible to maintain consistent inference latency and manage thermal
behavior effectively over extended periods. These findings provide valuable
insights for deploying audio tagging models in real-world edge computing
scenarios.

</details>


### [203] [AnyAccomp: Generalizable Accompaniment Generation via Quantized Melodic Bottleneck](https://arxiv.org/abs/2509.14052)
*Junan Zhang,Yunjia Zhang,Xueyao Zhang,Zhizheng Wu*

Main category: cs.SD

TL;DR: AnyAccomp是一个新的歌唱伴奏生成框架，通过解耦伴奏生成与源依赖伪影，解决了现有方法在真实干净人声输入上的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的歌唱伴奏生成技术使用源分离的人声作为输入，过度拟合分离伪影，导致在真实干净人声输入上失败，存在严重的训练-测试不匹配问题。

Method: AnyAccomp首先使用量化旋律瓶颈，通过色度图和VQ-VAE提取离散且音色不变的核心旋律表示，然后使用流匹配模型基于这些鲁棒编码生成伴奏。

Result: 实验表明AnyAccomp在分离人声基准测试中具有竞争力，同时在干净录音室人声和独奏乐器音轨的泛化测试集上显著优于基线方法。

Conclusion: 该方法在泛化能力上实现了质的飞跃，能够为乐器生成鲁棒的伴奏（现有模型完全失败的任务），为更通用的音乐共创工具铺平了道路。

Abstract: Singing Accompaniment Generation (SAG) is the process of generating
instrumental music for a given clean vocal input. However, existing SAG
techniques use source-separated vocals as input and overfit to separation
artifacts. This creates a critical train-test mismatch, leading to failure on
clean, real-world vocal inputs. We introduce AnyAccomp, a framework that
resolves this by decoupling accompaniment generation from source-dependent
artifacts. AnyAccomp first employs a quantized melodic bottleneck, using a
chromagram and a VQ-VAE to extract a discrete and timbre-invariant
representation of the core melody. A subsequent flow-matching model then
generates the accompaniment conditioned on these robust codes. Experiments show
AnyAccomp achieves competitive performance on separated-vocal benchmarks while
significantly outperforming baselines on generalization test sets of clean
studio vocals and, notably, solo instrumental tracks. This demonstrates a
qualitative leap in generalization, enabling robust accompaniment for
instruments - a task where existing models completely fail - and paving the way
for more versatile music co-creation tools. Demo audio and code:
https://anyaccomp.github.io

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [204] [AI Behavioral Science](https://arxiv.org/abs/2509.13323)
*Matthew O. Jackson,Qiaozhu Me,Stephanie W. Wang,Yutong Xie,Walter Yuan,Seth Benzell,Erik Brynjolfsson,Colin F. Camerer,James Evans,Brian Jabarian,Jon Kleinberg,Juanjuan Meng,Sendhil Mullainathan,Asuman Ozdaglar,Thomas Pfeiffer,Moshe Tennenholtz,Robb Willer,Diyi Yang,Teng Ye*

Main category: cs.HC

TL;DR: AI行为科学的新兴领域包含三个主要方向：AI如何增强行为科学研究、行为科学如何研究和设计AI、以及理解AI与人类互动带来的世界变化


<details>
  <summary>Details</summary>
Motivation: 探讨AI与行为科学交叉领域的新兴研究方向，建立AI行为科学这一新学科的理论框架

Method: 理论分析和框架构建，将AI行为科学划分为三个相互关联的研究领域

Result: 提出了AI行为科学的三个核心研究领域：AI赋能行为科学研究、行为科学指导AI设计、以及AI-人类互动对社会的影响研究

Conclusion: AI行为科学是一个多学科交叉的新兴领域，需要整合AI技术和行为科学理论来应对AI与人类互动的复杂挑战

Abstract: We discuss the three main areas comprising the new and emerging field of "AI
Behavioral Science". This includes not only how AI can enhance research in the
behavioral sciences, but also how the behavioral sciences can be used to study
and better design AI and to understand how the world will change as AI and
humans interact in increasingly layered and complex ways.

</details>


### [205] [Designing Psychometric Bias Measures for ChatBots: An Application to Racial Bias Measurement](https://arxiv.org/abs/2509.13324)
*Mouhacine Benosman*

Main category: cs.HC

TL;DR: 本文提出了一个原则性框架来设计和评估聊天机器人的心理测量偏差，旨在解决AI聊天机器人可能强化人类现有偏见的问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和聊天机器人在日常生活中的广泛应用，需要研究这些AI系统是否会以无偏见的方式与人类互动，还是会强化人类现有的病理偏见。关键问题是如何严格测量这些偏见。

Method: 提出了一个原则性框架来设计心理测量学指标，用于评估聊天机器人的偏见。该方法旨在系统性地量化和分析聊天机器人在各种人机交互场景中可能表现的偏见。

Result: 论文提出了一个评估聊天机器人偏见的心理测量框架，但具体实验结果未在摘要中详细说明。

Conclusion: 需要开发严谨的方法来测量聊天机器人的偏见，本文提出的原则性框架为解决这一挑战提供了基础，对于确保AI系统公平、无偏见地与人互动具有重要意义。

Abstract: Artificial intelligence (AI), particularly in the form of large language
models (LLMs) or chatbots, has become increasingly integrated into our daily
lives. In the past five years, several LLMs have been introduced, including
ChatGPT by OpenAI, Claude by Anthropic, and Llama by Meta, among others. These
models have the potential to be employed across a wide range of human-machine
interaction applications, such as chatbots for information retrieval,
assistance in corporate hiring decisions, college admissions, financial loan
approvals, parole determinations, and even in medical fields like psychotherapy
delivered through chatbots. The key question is whether these chatbots will
interact with humans in a bias-free manner or if they will further reinforce
the existing pathological biases present in human-to-human interactions. If the
latter is true, then how to rigorously measure these biases? We aim to address
this challenge by proposing a principled framework for designing psychometric
measures to evaluate chatbot biases.

</details>


### [206] [LLM Chatbot-Creation Approaches](https://arxiv.org/abs/2509.13326)
*Hemil Mehta,Tanvi Raut,Kohav Yadav,Edward F. Gehringer*

Main category: cs.HC

TL;DR: 本研究比较了低代码平台和自定义编码方案在教育聊天机器人开发中的优劣，发现低代码平台适合快速原型但定制性有限，而自定义编码提供更好控制但需要技术专长。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的兴起，教育领域需要选择最优的聊天机器人开发策略，在易用性、定制性、数据隐私和可扩展性之间取得平衡。

Method: 研究比较了AnythingLLM和Botpress等低代码平台与使用LangChain、FAISS和FastAPI的自定义编码方案，通过提示工程、检索增强生成和个性化来评估技术性能、可扩展性和用户体验。

Result: 低代码平台支持快速原型开发但面临定制和扩展限制，自定义编码系统提供更多控制但需要专业技术知识。两种方法都能成功实现自适应反馈循环和对话连续性等关键研究原则。

Conclusion: 研究提供了一个基于机构目标和资源选择适当开发策略的框架，未来工作将专注于结合低代码可访问性和模块化定制的混合解决方案，以及整合多模态输入的智能辅导系统。

Abstract: This full research-to-practice paper explores approaches for developing
course chatbots by comparing low-code platforms and custom-coded solutions in
educational contexts. With the rise of Large Language Models (LLMs) like GPT-4
and LLaMA, LLM-based chatbots are being integrated into teaching workflows to
automate tasks, provide assistance, and offer scalable support. However,
selecting the optimal development strategy requires balancing ease of use,
customization, data privacy, and scalability. This study compares two
development approaches: low-code platforms like AnythingLLM and Botpress, with
custom-coded solutions using LangChain, FAISS, and FastAPI. The research uses
Prompt engineering, Retrieval-augmented generation (RAG), and personalization
to evaluate chatbot prototypes across technical performance, scalability, and
user experience. Findings indicate that while low-code platforms enable rapid
prototyping, they face limitations in customization and scaling, while
custom-coded systems offer more control but require significant technical
expertise. Both approaches successfully implement key research principles such
as adaptive feedback loops and conversational continuity. The study provides a
framework for selecting the appropriate development strategy based on
institutional goals and resources. Future work will focus on hybrid solutions
that combine low-code accessibility with modular customization and incorporate
multimodal input for intelligent tutoring systems.

</details>


### [207] [DuetUI: A Bidirectional Context Loop for Human-Agent Co-Generation of Task-Oriented Interfaces](https://arxiv.org/abs/2509.13444)
*Yuan Xu,Shaowen Xiang,Yizhi Song,Ruoting Sun,Xin Tong*

Main category: cs.HC

TL;DR: 提出了DuetUI系统，通过人机协同生成范式解决LLM在复杂多步骤任务中的局限性，实现用户与AI代理的双向协作


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂多步骤现实任务中存在局限，用户需要能够塑造生成界面而非依赖一次性输出，需要支持动态用户干预

Method: 引入人机协同生成范式，开发DuetUI系统，通过双向上下文循环：代理分解任务搭建界面，用户通过直接操作隐式指导代理的下一步生成

Result: 在24名参与者的用户研究中，DuetUI相比基线显著提高了任务效率和界面可用性，促进了无缝的人机协作

Conclusion: 提出了新颖的人机协同生成范式并验证其有效性，设计了DuetUI原型，实证了双向循环能更好地使代理与人类意图对齐

Abstract: Large Language Models are reshaping task automation, yet remain limited in
complex, multi-step real-world tasks that require aligning with vague user
intent and enabling dynamic user override. From a formative study with 12
participants, we found that end-users actively seek to shape generative
interfaces rather than relying on one-shot outputs. To address this, we
introduce the human-agent co-generation paradigm, materialized in DuetUI. This
LLM-empowered system unfolds alongside task progress through a bidirectional
context loop--the agent scaffolds the interface by decomposing the task, while
the user's direct manipulations implicitly steer the agent's next generation
step. In a user study with 24 participants, DuetUI significantly improved task
efficiency and interface usability compared to a baseline, fostering seamless
human-agent collaboration. Our contributions include the proposal and
validation of this novel paradigm, the design of the DuetUI prototype embodying
it, and empirical insights into how this bidirectional loop better aligns
agents with human intent.

</details>


### [208] [Do We Need Subsidiarity in Software?](https://arxiv.org/abs/2509.13466)
*Louisa Conwill,Megan Levis Scheirer,Walter Scheirer*

Main category: cs.HC

TL;DR: 本研究通过辅助性原则分析数据隐私，发现Slack和Discord等聊天平台最违反该原则，揭示了用户在便利性和隐私之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 探索辅助性原则作为批判性视角来分析数据隐私问题，研究用户控制与科技巨头控制之间的平衡，特别是在监控资本主义背景下。

Method: 采用多方法研究，包括数据流监控和用户访谈，评估不同日常技术的控制层级以及用户认为必要的控制水平。

Result: 研究发现聊天平台（如Slack和Discord）最严重违反辅助性原则，揭示了用户在特定情况下愿意为便利性牺牲隐私的界限。

Conclusion: 辅助性原则可以为促进人类繁荣的设计提供指导，帮助在用户自主权和必要的外部干预之间找到平衡点。

Abstract: Subsidiarity is a principle of social organization that promotes human
dignity and resists over-centralization by balancing personal autonomy with
intervention from higher authorities only when necessary. Thus it is a
relevant, but not previously explored, critical lens for discerning the
tradeoffs between complete user control of software and surrendering control to
"big tech" for convenience, as is common in surveillance capitalism. Our study
explores data privacy through the lens of subsidiarity: we employ a
multi-method approach of data flow monitoring and user interviews to determine
the level of control different everyday technologies currently operate at, and
the level of control everyday computer users think is necessary. We found that
chat platforms like Slack and Discord violate subsidiarity the most. Our work
provides insight into when users are willing to surrender privacy for
convenience and demonstrates how subsidiarity can inform designs that promote
human flourishing.

</details>


### [209] [AR-TMT: Investigating the Impact of Distraction Types on Attention and Behavior in AR-based Trail Making Test](https://arxiv.org/abs/2509.13468)
*Sihun Baek,Zhehan Qu,Maria Gorlatova*

Main category: cs.HC

TL;DR: AR-TMT是Trail Making Test的AR版本，在Magic Leap 2上实现空间目标选择任务，研究三类分心对用户行为的影响。研究发现自上而下分心通过语义干扰降低性能，自下而上分心破坏初始注意力投入，空间分心导致凝视行为不稳定。


<details>
  <summary>Details</summary>
Motivation: 尽管AR在安全关键领域应用日益增多，但缺乏对不同类型分心如何影响AR环境中用户行为的系统理解。

Method: 开发AR-TMT测试，基于Wolfe的引导搜索模型实现三类分心（自上而下、自下而上、空间分心），采集性能、凝视、运动行为和主观负荷数据，对34名参与者进行用户研究。

Result: 自上而下分心通过语义干扰降低性能；自下而上分心破坏初始注意力投入；空间分心导致凝视行为不稳定，视觉扫描模式更分散。在基于对象的分心条件下，性能与注意力控制相关（R² = 0.20-0.35）。

Conclusion: 研究揭示了AR环境中分心机制及其对用户的影响，为生态相关AR任务的泛化提供了机会，同时强调了解决AR环境独特需求的必要性。

Abstract: Despite the growing use of AR in safety-critical domains, the field lacks a
systematic understanding of how different types of distraction affect user
behavior in AR environments. To address this gap, we present AR-TMT, an AR
adaptation of the Trail Making Test that spatially renders targets for
sequential selection on the Magic Leap 2. We implemented distractions in three
categories: top-down, bottom-up, and spatial distraction based on Wolfe's
Guided Search model, and captured performance, gaze, motor behavior, and
subjective load measures to analyze user attention and behavior. A user study
with 34 participants revealed that top-down distraction degraded performance
through semantic interference, while bottom-up distraction disrupted initial
attentional engagement. Spatial distraction destabilized gaze behavior, leading
to more scattered and less structured visual scanning patterns. We also found
that performance was correlated with attention control ($R^2 = .20$--$.35$)
under object-based distraction conditions, where distractors possessed
task-relevant features. The study offers insights into distraction mechanisms
and their impact on users, providing opportunities for generalization to
ecologically relevant AR tasks while underscoring the need to address the
unique demands of AR environments.

</details>


### [210] [Py maidr: Bridging Visual and Non-Visual Data Experiences Through a Unified Python Framework](https://arxiv.org/abs/2509.13532)
*JooYoung Seo,Saairam Venkatesh,Daksh Pokar,Sanchita Kamath,Krishna Anandan Ganesan*

Main category: cs.HC

TL;DR: Py maidr是一个Python包，通过在Matplotlib和Seaborn可视化中无缝编码多模态（触觉、听觉、对话）数据表示，为盲人和低视力用户提供双向可访问的数据可视化工具


<details>
  <summary>Details</summary>
Motivation: 解决当前可访问数据可视化工具中存在的"为他们设计"的单向范式问题，这种范式在视力正常的创作者和盲人/低视力用户之间造成了无意的隔阂和权力动态不平衡

Method: 开发Py maidr Python包，通过简单的maidr.show()方法调用，在现有代码基础上最小化修改即可生成包含多模态表示的可访问图表，支持触觉、听觉和对话式交互

Result: 技术案例研究表明该工具具有可扩展性，可集成到交互式计算环境（Jupyter Notebook、Google Colab）、可重复编程（Quarto）和响应式仪表板（Shiny、Streamlit）中，性能基准测试显示渲染和导出图表时引入的开销最小且一致

Conclusion: 这项工作通过提供统一框架促进视力正常和盲人/低视力个体之间的协作与沟通，显著缩小了数据可视化中的可访问性差距

Abstract: Although recent efforts have developed accessible data visualization tools
for blind and low-vision (BLV) users, most follow a "design for them" approach
that creates an unintentional divide between sighted creators and BLV
consumers. This unidirectional paradigm perpetuates a power dynamic where
sighted creators produce non-visual content boundaries for BLV consumers to
access. This paper proposes a bidirectional approach, "design for us," where
both sighted and BLV collaborators can employ the same tool to create,
interpret, and communicate data visualizations for each other. We introduce Py
maidr, a Python package that seamlessly encodes multimodal (e.g., tactile,
auditory, conversational) data representations into visual plots generated by
Matplotlib and Seaborn. By simply importing the maidr package and invoking the
maidr.show() method, users can generate accessible plots with minimal changes
to their existing codebase regardless of their visual dis/abilities. Our
technical case studies demonstrate how this tool is scalable and can be
integrated into interactive computing (e.g., Jupyter Notebook, Google Colab),
reproducible and literate programming (e.g., Quarto), and reactive dashboards
(e.g., Shiny, Streamlit). Our performance benchmarks demonstrate that Py maidr
introduces minimal and consistent overhead during the rendering and export of
plots against Matplotlib and Seaborn baselines. This work significantly
contributes to narrowing the accessibility gap in data visualization by
providing a unified framework that fosters collaboration and communication
between sighted and BLV individuals.

</details>


### [211] [Vistoria: A Multimodal System to Support Fictional Story Writing through Instrumental Text-Image Co-Editing](https://arxiv.org/abs/2509.13646)
*Kexue Fu,Jingfei Huang,Long Ling,Sumin Hong,Yihang Zuo,Ray LC,Toby Jia-jun Li*

Main category: cs.HC

TL;DR: Vistoria是一个文本-图像协同编辑系统，通过将视觉和文本作为平等的叙事材料，提升小说故事创作的表达力、沉浸感和协作性。


<details>
  <summary>Details</summary>
Motivation: 人类以视觉方式思考（记忆、梦境、沟通都使用图像），但现有创作工具仍以文本为中心，限制了作者的构思和表达方式。

Method: 基于工具性交互和结构映射理论，开发了Vistoria系统，提供多模态操作（套索、拼贴、滤镜、视角转换），通过Wizard-of-Oz协同设计研究和控制实验进行验证。

Result: 协同编辑增强了表达力、沉浸感和协作性，使作者能够探索不同方向、拥抱随机性并追踪故事发展。虽然多模态增加了认知负荷，但参与者报告了更强的作者意识和控制感。

Conclusion: 多模态协同编辑通过平衡叙事发展中的抽象性和具体性，扩展了创作潜力，证明了视觉和文本作为平等叙事材料的价值。

Abstract: Humans think visually-we remember in images, dream in pictures, and use
visual metaphors to communicate. Yet, most creative writing tools remain
text-centric, limiting how authors plan and translate ideas. We present
Vistoria, a system for synchronized text-image co-editing in fictional story
writing that treats visuals and text as coequal narrative materials. A
formative Wizard-of-Oz co-design study with 10 story writers revealed how
sketches, images, and annotations serve as essential instruments for ideation
and organization. Drawing on theories of Instrumental Interaction and
Structural Mapping, Vistoria introduces multimodal operations-lasso, collage,
filters, and perspective shifts that enable seamless narrative exploration
across modalities. A controlled study with 12 participants shows that
co-editing enhances expressiveness, immersion, and collaboration, enabling
writers to explore divergent directions, embrace serendipitous randomness, and
trace evolving storylines. While multimodality increased cognitive demand,
participants reported stronger senses of authorship and agency. These findings
demonstrate how multimodal co-editing expands creative potential by balancing
abstraction and concreteness in narrative development.

</details>


### [212] [I, Robot? Socio-Technical Implications of Ultra-Personalized AI-Powered AAC; an Autoethnographic Account](https://arxiv.org/abs/2509.13671)
*Tobias Weinberg,Ricardo E. Gonzalez Penuela,Stephanie Valencia,Thijs Roumen*

Main category: cs.HC

TL;DR: 本文通过自民族志研究探讨了为AAC用户个性化AI自动完成系统的社会技术影响，发现个性化虽然能减少编辑负担，但带来了隐私、作者身份和自我表达边界模糊等问题。


<details>
  <summary>Details</summary>
Motivation: 通用AI自动完成系统无法捕捉个人身份细微差别，对依赖AAC设备的用户在沟通中造成严重编辑负担。虽然技术可行，但个性化带来了社会技术问题需要探讨。

Method: 采用自民族志研究分三个阶段：(1)收集7个月AAC沟通数据；(2)基于数据集微调模型；(3)3个月日常使用个性化AI建议，并通过持续日记和交互日志进行反思。

Result: 研究发现个性化具有重要价值，但同时也对隐私、作者身份产生深远影响，模糊了自我表达的边界。

Conclusion: 个性化AI建议对AAC用户有益，但需要仔细考虑其社会技术影响，包括隐私保护、作者身份界定和自我表达边界等问题。

Abstract: Generic AI auto-complete for message composition often fails to capture the
nuance of personal identity, requiring significant editing. While harmless in
low-stakes settings, for users of Augmentative and Alternative Communication
(AAC) devices, who rely on such systems for everyday communication, this
editing burden is particularly acute. Intuitively, the need for edits would be
lower if language models were personalized to the communication of the specific
user. While technically feasible, such personalization raises socio-technical
questions: what are the implications of logging one's own conversations, and
how does personalization affect privacy, authorship, and control? We explore
these questions through an autoethnographic study in three phases: (1) seven
months of collecting all the lead author's AAC communication data, (2)
fine-tuning a model on this dataset, and (3) three months of daily use of
personalized AI suggestions. We reflect on these phases through continuous
diary entries and interaction logs. Our findings highlight the value of
personalization as well as implications on privacy, authorship, and blurring
the boundaries of self-expression.

</details>


### [213] [From Prompts to Reflection: Designing Reflective Play for GenAI Literacy](https://arxiv.org/abs/2509.13679)
*Qianou Ma,Megan Chai,Yike Tan,Jihun Choi,Jini Kim,Erik Harpstead,Geoff Kauffman,Tongshuang Wu*

Main category: cs.HC

TL;DR: ImaginAItion是一个多人派对游戏，通过游戏化方式帮助成年人认识生成式AI的系统性偏见、反思人机解释差异，并改进提示策略。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在日常生活中的广泛应用凸显了提高对其能力、偏见和限制的认识的必要性。虽然许多AI素养教育针对儿童采用游戏化学习，但很少有干预措施通过游戏化探索帮助成年人建立细致、反思性的理解。

Method: 基于Drawful游戏设计的多玩家派对游戏，采用反思性游戏框架，通过提示和讨论来揭示模型默认设置、偏见和人机感知差距。进行了10次游戏会话（n=30）的研究。

Result: 游戏玩法帮助成年人识别生成式AI中的系统性偏见，反思人类与AI解释差异，并调整他们的提示策略。群体动态和组成（如专业知识和多样性）会放大或抑制反思效果。

Conclusion: 这项工作为通过游戏化、社交化的干预措施扩展批判性生成式AI素养提供了起点，这些干预措施对快速发展的技术具有韧性。

Abstract: The wide adoption of Generative AI (GenAI) in everyday life highlights the
need for greater literacy around its evolving capabilities, biases, and
limitations. While many AI literacy efforts focus on children through
game-based learning, few interventions support adults in developing a nuanced,
reflective understanding of GenAI via playful exploration. To address the gap,
we introduce ImaginAItion, a multiplayer party game inspired by Drawful and
grounded in the reflective play framework to surface model defaults, biases,
and human-AI perception gaps through prompting and discussion. From ten
sessions (n=30), we show how gameplay helped adults recognize systematic biases
in GenAI, reflect on humans and AI interpretation differences, and adapt their
prompting strategies. We also found that group dynamics and composition, such
as expertise and diversity, amplified or muted reflection. Our work provides a
starting point to scale critical GenAI literacy through playful, social
interventions resilient to rapidly evolving technologies.

</details>


### [214] [Spatial Balancing: Harnessing Spatial Reasoning to Balance Scientific Exposition and Narrative Engagement in LLM-assisted Science Communication Writing](https://arxiv.org/abs/2509.13742)
*Kexue Fu,Jiaye Leng,Yawen Zhang,Jingfei Huang,Yihang Zuo,Runze Cai,Zijian Ding,Ray LC,Shengdong Zhao,Qinyuan Lei*

Main category: cs.HC

TL;DR: 开发了SpatialBalancing系统，通过空间可视化帮助科学传播者在修订过程中平衡科学严谨性和叙事吸引力


<details>
  <summary>Details</summary>
Motivation: 解决科学传播中平衡科学阐述和叙事参与的核心挑战，创作者在迭代过程中缺乏结构化支持

Method: 结合人类空间推理和大型语言模型的语言智能，开发双轴空间可视化系统，用户可以选择基于策略的标签来生成、比较和精炼版本

Result: 在16人参与的研究中，SpatialBalancing增强了元认知反思、灵活性和创造性探索

Conclusion: 将空间推理与语言生成相结合，可以促进迭代科学传播写作中的监控能力

Abstract: Balancing scientific exposition and narrative engagement is a central
challenge in science communication. To examine how to achieve balance, we
conducted a formative study with four science communicators and a literature
review of science communication practices, focusing on their workflows and
strategies. These insights revealed how creators iteratively shift between
exposition and engagement but often lack structured support. Building on this,
we developed SpatialBalancing, a co-writing system that connects human spatial
reasoning with the linguistic intelligence of large language models. The system
visualizes revision trade-offs in a dual-axis space, where users select
strategy-based labels to generate, compare, and refine versions during the
revision process. This spatial externalization transforms revision into spatial
navigation, enabling intentional iterations that balance scientific rigor with
narrative appeal. In a within-subjects study (N=16), SpatialBalancing enhanced
metacognitive reflection, flexibility, and creative exploration, demonstrating
how coupling spatial reasoning with linguistic generation fosters monitoring in
iterative science communication writing.

</details>


### [215] [Synthetic Data Generation for Screen Time and App Usage](https://arxiv.org/abs/2509.13892)
*Gustavo Kruger,Nikhil Sachdeva,Michael Sobolev*

Main category: cs.HC

TL;DR: 使用LLM生成合成智能手机使用数据的研究，通过四种提示策略比较数据质量，发现详细提示可生成行为合理的数据，但仍需针对具体用例评估数据保真度与多样性。


<details>
  <summary>Details</summary>
Motivation: 真实智能手机使用数据收集面临高成本、隐私问题、样本代表性不足等挑战，需要探索替代方法来获取大规模数据集。

Method: 采用四种提示策略（详细程度和种子数据包含两个因素）进行对比研究，使用LLM生成结构化智能手机使用数据。

Result: 研究发现使用详细提示可以生成行为合理的合成数据，但在捕捉人类行为多样性方面仍存在挑战，需要用例特定的评估指标。

Conclusion: LLM生成智能手机使用数据在某些用例中可行，但需要进一步研究更多样化的种子数据和不同LLM模型，以平衡数据保真度和多样性。

Abstract: Smartphone usage data can provide valuable insights for understanding
interaction with technology and human behavior. However, collecting
large-scale, in-the-wild smartphone usage logs is challenging due to high
costs, privacy concerns, under representative user samples and biases like
non-response that can skew results. These challenges call for exploring
alternative approaches to obtain smartphone usage datasets. In this context,
large language models (LLMs) such as Open AI's ChatGPT present a novel approach
for synthetic smartphone usage data generation, addressing limitations of
real-world data collection. We describe a case study on how four prompt
strategies influenced the quality of generated smartphone usage data. We
contribute with insights on prompt design and measures of data quality,
reporting a prompting strategy comparison combining two factors, prompt level
of detail (describing a user persona, describing the expected results
characteristics) and seed data inclusion (with versus without an initial real
usage example). Our findings suggest that using LLMs to generate structured and
behaviorally plausible smartphone use datasets is feasible for some use cases,
especially when using detailed prompts. Challenges remain in capturing diverse
nuances of human behavioral patterns in a single synthetic dataset, and
evaluating tradeoffs between data fidelity and diversity, suggesting the need
for use-case-specific evaluation metrics and future research with more diverse
seed data and different LLM models.

</details>


### [216] [AI as a teaching tool and learning partner](https://arxiv.org/abs/2509.13899)
*Steven Watterson,Sarah Atkinson,Elaine Murray,Andrew McDowell*

Main category: cs.HC

TL;DR: 本研究探索了在生物课程教学中整合大型语言模型(LLM)工具的效果，包括基于RAG的聊天机器人和AI生成播客，发现学生对AI工具整体持积极态度，聊天机器人更受欢迎。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具特别是大型语言模型的兴起，教育机构需要探索如何以建设性方式将LLM整合到教学中，本研究旨在评估两种LLM工具在教学中的实际应用效果。

Method: 在两个生物课程项目(本科和研究生)中提供：(1)基于RAG技术的LLM聊天机器人，可访问课程材料；(2)每周教学内容的AI生成纯音频播客。学期末通过问卷调查评估学生态度。

Result: 学生对AI整体持积极态度，认为AI工具对教学有积极影响。LLM聊天机器人使用简单有趣，能增强学习效果。播客较不受欢迎，只有少数学生每周收听，整体对播客推广持中立态度，但收听者喜欢并支持使用。

Conclusion: LLM工具在教育中具有应用潜力，聊天机器人比音频播客更受学生欢迎，未来需要根据学生偏好和工具特点进行有针对性的整合。

Abstract: The arrival of AI tools and in particular Large Language Models (LLMs) has
had a transformative impact on teaching and learning and institutes are still
trying to determine how to integrate LLMs into education in constructive ways.
Here, we explore the adoption of LLM-based tools into two teaching programmes,
one undergraduate and one postgraduate. We provided to our classes (1) a
LLM-powered chatbot that had access to course materials by RAG and (2)
AI-generated audio-only podcasts for each week$\text{'}$s teaching material. At
the end of the semester, we surveyed the classes to gauge attitudes towards
these tools. The classes were small and from biological courses. The students
felt positive about AI generally and that AI tools made a positive impact on
teaching. Students found the LLM-powered chatbot easy and enjoyable to use and
felt that it enhanced their learning. The podcasts were less popular and only a
small proportion of the class listened weekly. The class as a whole was
indifferent to whether the podcasts should be used more widely across courses,
but those who listened enjoyed them and were in favour.

</details>


### [217] [AI For Privacy in Smart Homes: Exploring How Leveraging AI-Powered Smart Devices Enhances Privacy Protection](https://arxiv.org/abs/2509.14050)
*Wael Albayaydh,Ivan Flechais,Rui Zhao,Jood Albayaydh*

Main category: cs.HC

TL;DR: 本研究探讨AI工具如何通过个性化支持增强智能家居隐私保护，通过23个深度访谈发现用户对AI隐私增强的期望以及相关的安全伦理挑战


<details>
  <summary>Details</summary>
Motivation: 智能家居设备的隐私担忧常源于对数据收集和使用方式的误解，需要探索AI如何提供创新的隐私保护方案

Method: 采用扎根理论分析，对23名用户、AI开发者、设计师和监管者进行深度访谈

Result: 识别出两个关键主题：AI增强隐私的期望（用户希望AI赋能、解决权力不平衡、提高易用性）以及AI伦理、安全和监管考虑（数据安全、合规性、伦理实践挑战）

Conclusion: 研究为智能设备设计师和AI开发者提供了实用建议，帮助弥合用户期望、AI能力和监管框架之间的差距，指导AI工具的共同设计以增强智能家居隐私保护

Abstract: Privacy concerns and fears of unauthorized access in smart home devices often
stem from misunderstandings about how data is collected, used, and protected.
This study explores how AI-powered tools can offer innovative privacy
protections through clear, personalized, and contextual support to users.
Through 23 in-depth interviews with users, AI developers, designers, and
regulators, and using Grounded Theory analysis, we identified two key themes:
Aspirations for AI-Enhanced Privacy - how users perceive AI's potential to
empower them, address power imbalances, and improve ease of use- and AI
Ethical, Security, and Regulatory Considerations-challenges in strengthening
data security, ensuring regulatory compliance, and promoting ethical AI
practices. Our findings contribute to the field by uncovering user aspirations
for AI-driven privacy solutions, identifying key security and ethical
challenges, and providing actionable recommendations for all stakeholders,
particularly targeting smart device designers and AI developers, to guide the
co-design of AI tools that enhance privacy protection in smart home devices. By
bridging the gap between user expectations, AI capabilities, and regulatory
frameworks, this work offers practical insights for shaping the future of
privacy-conscious AI integration in smart homes.

</details>


### [218] [EEG-Based Cognitive Load Classification During Landmark-Based VR Navigation](https://arxiv.org/abs/2509.14056)
*Jiahui An,Bingjie Cheng,Dmitriy Rudyka,Elisa Donati,Sara Fabrikant*

Main category: cs.HC

TL;DR: EEG信号可以有效分类VR导航中的认知负荷，分类准确率高达90.8%（二分类）和78.7%（三分类），任务复杂度比个体差异对分类性能影响更大


<details>
  <summary>Details</summary>
Motivation: 脑机接口能够实时监测认知负荷，但在动态导航环境中的有效性尚未得到充分验证，需要研究EEG信号在基于地图的寻路任务中是否能有效分类认知负荷

Method: 使用现有VR导航数据集，分析46名参与者在包含3、5或7个地标的地图导航任务中的EEG记录，采用嵌套交叉验证框架和多种机器学习模型进行分类

Result: 二分类（3 vs 7地标）平均准确率达到90.8%，三分类问题达到78.7%，均显著高于随机水平。人口统计学和认知变量（年龄、性别、空间能力、工作记忆）对分类准确性没有显著影响

Conclusion: 任务需求比个体差异更能影响分类性能，这为开发能够根据实时认知状态动态调整地图复杂度的任务自适应导航系统提供了潜力

Abstract: Brain computer interfaces enable real-time monitoring of cognitive load, but
their effectiveness in dynamic navigation contexts is not well established.
Using an existing VR navigation dataset, we examined whether EEG signals can
classify cognitive load during map-based wayfinding and whether classification
accuracy depends more on task complexity or on individual traits. EEG
recordings from forty-six participants navigating routes with 3, 5, or 7 map
landmarks were analyzed with a nested cross-validation framework across
multiple machine learning models. Classification achieved mean accuracies up to
90.8% for binary contrasts (3 vs. 7 landmarks) and 78.7% for the three-class
problem, both well above chance. Demographic and cognitive variables (age,
gender, spatial ability, working memory) showed no significant influence. These
findings demonstrate that task demands outweigh individual differences in
shaping classification performance, highlighting the potential for
task-adaptive navigation systems that dynamically adjust map complexity in
response to real-time cognitive states.

</details>


### [219] [When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training](https://arxiv.org/abs/2509.14132)
*Julia S. Dollis,Iago A. Brito,Fernanda B. Färber,Pedro S. F. B. Ribeiro,Rafael T. Sousa,Arlindo R. Galvão Filho*

Main category: cs.HC

TL;DR: 本文提出了一个将大型语言模型集成到VR中的框架，用于创建具有一致个性的医学虚拟患者，在医师研究中被证明是可行且有效的培训增强工具。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实在模拟物理环境方面表现出色，但在培训复杂人际技能方面存在局限性，特别是在医疗教育等高风险领域，缺乏心理上合理的虚拟人类是一个关键缺口。

Method: 采用模块化架构，将个性与临床数据解耦，将大型语言模型集成到沉浸式VR中，创建医学上连贯且具有独特一致个性的虚拟患者。通过混合方法的受试者内研究，让执业医师参与模拟咨询进行评估。

Result: 该方法不仅可行，而且被医师认为是高度有益和有效的培训增强工具。分析揭示了关键设计原则，包括"真实感-冗长悖论"（沟通较少的代理可能显得更人工）以及挑战需要被感知为真实才能具有指导性。

Conclusion: 这项工作为开发下一代社会智能VR培训环境提供了经过验证的框架和关键见解，推动了VR在人际技能培训中的应用发展。

Abstract: While virtual reality (VR) excels at simulating physical environments, its
effectiveness for training complex interpersonal skills is limited by a lack of
psychologically plausible virtual humans. This is a critical gap in high-stakes
domains like medical education, where communication is a core competency. This
paper introduces a framework that integrates large language models (LLMs) into
immersive VR to create medically coherent virtual patients with distinct,
consistent personalities, built on a modular architecture that decouples
personality from clinical data. We evaluated our system in a mixed-method,
within-subjects study with licensed physicians who engaged in simulated
consultations. Results demonstrate that the approach is not only feasible but
is also perceived by physicians as a highly rewarding and effective training
enhancement. Furthermore, our analysis uncovers critical design principles,
including a ``realism-verbosity paradox" where less communicative agents can
seem more artificial, and the need for challenges to be perceived as authentic
to be instructive. This work provides a validated framework and key insights
for developing the next generation of socially intelligent VR training
environments.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [220] [CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion](https://arxiv.org/abs/2509.13688)
*James Jincheng,Youcheng Cai,Ligang Liu*

Main category: cs.GR

TL;DR: CraftMesh是一个通过泊松无缝融合实现高保真生成式网格编辑的新框架，将2D和3D生成模型优势结合，在复杂编辑任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的生成方法在处理复杂几何形状时往往难以产生详细结果，可控的高保真网格编辑仍然是3D内容创建中的重大挑战。

Method: 将网格编辑分解为管道：先编辑2D参考图像，然后生成区域特定的3D网格，最后无缝融合到原始模型中。核心包括泊松几何融合（使用混合SDF/网格表示和法线混合）和泊松纹理协调。

Result: 实验结果表明，CraftMesh在复杂编辑任务中优于最先进的方法，提供了更好的全局一致性和局部细节。

Conclusion: CraftMesh框架通过结合2D和3D生成模型的优势，实现了高质量的可控网格编辑，解决了现有方法在处理复杂几何时的局限性。

Abstract: Controllable, high-fidelity mesh editing remains a significant challenge in
3D content creation. Existing generative methods often struggle with complex
geometries and fail to produce detailed results. We propose CraftMesh, a novel
framework for high-fidelity generative mesh manipulation via Poisson Seamless
Fusion. Our key insight is to decompose mesh editing into a pipeline that
leverages the strengths of 2D and 3D generative models: we edit a 2D reference
image, then generate a region-specific 3D mesh, and seamlessly fuse it into the
original model. We introduce two core techniques: Poisson Geometric Fusion,
which utilizes a hybrid SDF/Mesh representation with normal blending to achieve
harmonious geometric integration, and Poisson Texture Harmonization for
visually consistent texture blending. Experimental results demonstrate that
CraftMesh outperforms state-of-the-art methods, delivering superior global
consistency and local detail in complex editing tasks.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [221] [All Models Are Wrong, But Can They Be Useful? Lessons from COVID-19 Agent-Based Models: A Systematic Review](https://arxiv.org/abs/2509.13346)
*Emma Von Hoene,Sara Von Hoene,Szandra Peter,Ethan Hopson,Emily Csizmadia,Faith Fenyk,Kai Barner,Timothy Leslie,Hamdi Kavak,Andreas Zufle,Amira Roess,Taylor Anderson*

Main category: cs.MA

TL;DR: 对536篇COVID-19基于代理模型研究的系统回顾显示，虽然模型发展迅速，但缺乏透明度、代码共享和利益相关者参与，需要更强标准来支持公共卫生决策。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行期间基于代理模型(ABMs)被广泛用于模拟疾病传播，但其实际效用和可靠性需要系统评估，以指导未来公共卫生危机中的模型应用。

Method: 系统回顾2020-2023年间发表的536项COVID-19 ABM研究，从Web of Science、PubMed和Wiley等数据库检索，使用9个模型实用性标准进行评估。

Result: 大多数模型关注行为或政策干预(54.85%)而非实时预测(1.68%)；模型透明度不足，仅40.86%共享代码，36.38%基于现有模型；标准化报告协议(6.72%)和利益相关者参与(13.62%)罕见；仅2.24%有全面验证框架。

Conclusion: COVID-19 ABMs发展迅速但存在透明度、可及性和参与性不足的问题，需要建立更强标准以确保其在未来公共卫生危机中作为可靠决策支持工具的有效性。

Abstract: The COVID-19 pandemic prompted a surge in computational models to simulate
disease dynamics and guide interventions. Agent-based models (ABMs) are
well-suited to capture population and environmental heterogeneity, but their
rapid deployment raised questions about utility for health policy. We
systematically reviewed 536 COVID-19 ABM studies published from January 2020 to
December 2023, retrieved from Web of Science, PubMed, and Wiley on January 30,
2024. Studies were included if they used ABMs to simulate COVID-19
transmission, where reviews were excluded. Studies were assessed against nine
criteria of model usefulness, including transparency and re-use,
interdisciplinary collaboration and stakeholder engagement, and evaluation
practices. Publications peaked in late 2021 and were concentrated in a few
countries. Most models explored behavioral or policy interventions (n = 294,
54.85%) rather than real-time forecasting (n = 9, 1.68%). While most described
model assumptions (n = 491, 91.60%), fewer disclosed limitations (n = 349,
65.11%), shared code (n = 219, 40.86%), or built on existing models (n = 195,
36.38%). Standardized reporting protocols (n = 36, 6.72%) and stakeholder
engagement were rare (13.62%, n = 73). Only 2.24% (n = 12) described a
comprehensive validation framework, though uncertainty was often quantified (n
= 407, 75.93%). Limitations of this review include underrepresentation of
non-English studies, subjective data extraction, variability in study quality,
and limited generalizability. Overall, COVID-19 ABMs advanced quickly, but
lacked transparency, accessibility, and participatory engagement. Stronger
standards are needed for ABMs to serve as reliable decision-support tools in
future public health crises.

</details>


### [222] [Inject, Fork, Compare: Defining an Interaction Vocabulary for Multi-Agent Simulation Platforms](https://arxiv.org/abs/2509.13712)
*HwiJoon Lee,Martina Di Paola,Yoo Jin Hong,Quang-Huy Nguyen,Joseph Seering*

Main category: cs.MA

TL;DR: 提出了三个核心操作（inject、fork、compare）来增强LLM多智能体模拟的交互性和分析能力，将线性模拟转变为可探索的交互空间。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体模拟缺乏清晰的交互和分析模式，限制了研究人员探索"如果...会怎样"场景的能力。

Method: 定义了三个核心操作：inject（在模拟执行过程中引入外部事件）、fork（从任意时间点创建独立时间线分支）、compare（并行观察多个分支以比较不同干预的效果）。

Result: 通过一个包含14个AI智能体的商品市场模拟演示了这些操作，研究人员可以注入对比事件并观察平行时间线上的不同结果。

Conclusion: 这些基本操作为LLM智能体模拟中的系统性因果研究提供了起点，使研究从被动观察转向主动实验。

Abstract: LLM-based multi-agent simulations are a rapidly growing field of research,
but current simulations often lack clear modes for interaction and analysis,
limiting the "what if" scenarios researchers are able to investigate. In this
demo, we define three core operations for interacting with multi-agent
simulations: inject, fork, and compare. Inject allows researchers to introduce
external events at any point during simulation execution. Fork creates
independent timeline branches from any timestamp, preserving complete state
while allowing divergent exploration. Compare facilitates parallel observation
of multiple branches, revealing how different interventions lead to distinct
emergent behaviors. Together, these operations establish a vocabulary that
transforms linear simulation workflows into interactive, explorable spaces. We
demonstrate this vocabulary through a commodity market simulation with fourteen
AI agents, where researchers can inject contrasting events and observe
divergent outcomes across parallel timelines. By defining these fundamental
operations, we provide a starting point for systematic causal investigation in
LLM-based agent simulations, moving beyond passive observation toward active
experimentation.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [223] [Snail Homing and Mating Search Algorithm for Weight Optimization of Stepped-Transmission Shaft](https://arxiv.org/abs/2509.13721)
*Kaustav Saha,Ishaan R Kale,Vivek Patel,Anand J Kulkarni,Puskaraj D Sonawwanay*

Main category: cs.NE

TL;DR: 本文提出了一种基于蜗牛归巢与交配搜索算法的阶梯传动轴重量优化设计方法，通过生物启发式算法解决考虑疲劳载荷和复合载荷的传动轴优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统传动轴设计往往无法在满足强度要求的同时实现重量最小化，需要一种有效的优化方法来平衡结构强度与轻量化需求。

Method: 采用生物启发的蜗牛归巢与交配搜索算法，结合MDSOLIDS软件进行力学分析，建立考虑疲劳载荷和Modified Goodman准则的数学模型，使用静态罚函数处理约束条件。

Result: SHMS算法以合理的计算成本获得了满意解，通过ANSYS Workbench验证了优化结果的准确性，算法计算结果与有限元分析结果具有良好的一致性。

Conclusion: SHMS算法在阶梯传动轴重量优化设计中表现出色，为机械结构优化提供了一种有效的生物启发式解决方案，计算结果经过有限元分析验证具有工程实用性。

Abstract: In this paper, the steeped-transmission shaft design problem is proposed for
weight optimization. The bio-inspired search-based Snail Homing and Mating
Search (SHMS) algorithm is utilized to solve the problem. It is inspired by the
social behaviour of snails and their inherent nature of finding better homes,
and mate. The proposed steeped-transmission shaft design problem is modelled
considering the fatigue loading, combined bending, torsion loads, and the
principle of Modified Goodman criteria. The forces diagram and the bending
moment diagrams are obtained using the MDSOLIDS software. The forces and
bending moment are then used to mathematical model the objective function and
constraints. The SHMS algorithm has yielded the desired solution with
reasonable computational cost. The constraints are handled using a static
penalty function approach. The statistical results obtained using SHMS
algorithm are further used for generating CAD model. The analysis is carried
out in ANSYS Workbench. Further, the deflection obtained from SHMS algorithm
and ANSYS Workbench are compared and results are discussed in details.

</details>


### [224] [A neuromorphic continuous soil monitoring system for precision irrigation](https://arxiv.org/abs/2509.14066)
*Mirco Tincani,Khaled Kerouch,Umberto Garlando,Mattia Barezzi,Alessandro Sanginario,Giacomo Indiveri,Chiara De Luca*

Main category: cs.NE

TL;DR: 提出了一种完全能量高效的神经形态灌溉控制系统，利用脉冲神经网络在边缘设备上实现本地计算和决策，无需数据传输或远程处理，验证了与传统方法相当的灌溉决策准确性。


<details>
  <summary>Details</summary>
Motivation: 现代农业和精准灌溉系统需要超低功耗的边缘计算技术来优化水资源使用，神经形态处理系统因其在资源受限硬件上的高效性而成为理想选择。

Method: 使用生物逼真的脉冲神经网络在混合信号神经形态处理器上进行本地计算和决策，利用真实世界的苹果和猕猴桃果园土壤湿度数据进行验证。

Result: 生成的灌溉指令与传统方法在不同土壤深度下高度匹配，保持了决策准确性。

Conclusion: 本地神经形态推理能够维持决策精度，为大规模自主可持续灌溉解决方案开辟了道路。

Abstract: Sensory processing at the edge requires ultra-low power stand-alone computing
technologies. This is particularly true for modern agriculture and precision
irrigation systems which aim to optimize water usage by monitoring key
environmental observables continuously using distributed efficient embedded
processing elements. Neuromorphic processing systems are emerging as a
promising technology for extreme edge-computing applications that need to run
on resource-constrained hardware. As such, they are a very good candidate for
implementing efficient water management systems based on data measured from
soil and plants, across large fields. In this work, we present a fully
energy-efficient neuromorphic irrigation control system that operates
autonomously without any need for data transmission or remote processing.
Leveraging the properties of a biologically realistic spiking neural network,
our system performs computation, and decision-making locally. We validate this
approach using real-world soil moisture data from apple and kiwi orchards
applied to a mixed-signal neuromorphic processor, and show that the generated
irrigation commands closely match those derived from conventional methods
across different soil depths. Our results show that local neuromorphic
inference can maintain decision accuracy, paving the way for autonomous,
sustainable irrigation solutions at scale.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [225] [Delta Matters: An Analytically Tractable Model for $β$-$δ$ Discounting Agents](https://arxiv.org/abs/2509.13637)
*Yasunori Akagi,Takeshi Kurashima*

Main category: cs.GT

TL;DR: 本文扩展了时间不一致性研究，从δ=1扩展到0<δ≤1的一般情况，证明了闭式解的存在性，并开发了计算最优干预的高效方法


<details>
  <summary>Details</summary>
Motivation: 先前研究局限于δ=1的特殊情况，而现实决策中δ通常小于1，需要更一般的理论框架来理解时间不一致行为和设计有效干预策略

Method: 采用β-δ贴现（准双曲线贴现）模型，分析0<δ≤1的一般情况，推导代理行为的闭式描述，建立任务放弃条件，开发最优干预计算方法

Result: 成功证明了在一般δ值下代理行为仍存在闭式解，发现了代理行为和最优干预策略对δ值的敏感性，表明固定δ=1会过度简化现实决策过程

Conclusion: δ参数在时间不一致行为建模中至关重要，忽略δ<1的情况会导致对现实决策过程的不准确理解，本文为更精确的行为建模和干预设计提供了理论基础

Abstract: Humans exhibit time-inconsistent behavior, in which planned actions diverge
from executed actions. Understanding time inconsistency and designing
appropriate interventions is a key research challenge in computer science and
behavioral economics. Previous work focuses on progress-based tasks and derives
a closed-form description of agent behavior, from which they obtain optimal
intervention strategies. They model time-inconsistency using the
$\beta$-$\delta$ discounting (quasi-hyperbolic discounting), but the analysis
is limited to the case $\delta = 1$. In this paper, we relax that constraint
and show that a closed-form description of agent behavior remains possible for
the general case $0 < \delta \le 1$. Based on this result, we derive the
conditions under which agents abandon tasks and develop efficient methods for
computing optimal interventions. Our analysis reveals that agent behavior and
optimal interventions depend critically on the value of $\delta$, suggesting
that fixing $\delta = 1$ in many prior studies may unduly simplify real-world
decision-making processes.

</details>


### [226] [Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation](https://arxiv.org/abs/2509.13653)
*Hang Ren,Yulin Wu,Shuhan Qi,Jiajia Zhang,Xiaozhen Sun,Tianzi Ma,Xuan Wang*

Main category: cs.GT

TL;DR: 提出自适应奖励变换框架，解决传统后悔最小化方法中平均策略计算成本高和参数敏感问题，在NFGs和EFGs中实现更好的最终迭代收敛


<details>
  <summary>Details</summary>
Motivation: 传统后悔最小化方法需要计算平均策略，计算成本高且引入误差；奖励变换框架参数敏感，理论条件与实际性能不一致，导致收敛慢或陷入局部最优

Method: 为RTRM和RTCFR及其变体设计自适应技术，动态调整参数以平衡探索与利用，改进后悔积累，增强渐近最终迭代收敛

Result: 实验结果表明该方法显著加速收敛，在NFGs和EFGs中优于最先进算法，实现线性收敛

Conclusion: 自适应奖励变换方法有效解决了传统方法的实际问题，在理论和实际性能一致性方面取得突破，为博弈求解提供更实用的解决方案

Abstract: Regret minimization is a powerful method for finding Nash equilibria in
Normal-Form Games (NFGs) and Extensive-Form Games (EFGs), but it typically
guarantees convergence only for the average strategy. However, computing the
average strategy requires significant computational resources or introduces
additional errors, limiting its practical applicability. The Reward
Transformation (RT) framework was introduced to regret minimization to achieve
last-iterate convergence through reward function regularization. However, it
faces practical challenges: its performance is highly sensitive to manually
tuned parameters, which often deviate from theoretical convergence conditions,
leading to slow convergence, oscillations, or stagnation in local optima.
  Inspired by previous work, we propose an adaptive technique to address these
issues, ensuring better consistency between theoretical guarantees and
practical performance for RT Regret Matching (RTRM), RT Counterfactual Regret
Minimization (RTCFR), and their variants in solving NFGs and EFGs more
effectively. Our adaptive methods dynamically adjust parameters, balancing
exploration and exploitation while improving regret accumulation, ultimately
enhancing asymptotic last-iterate convergence and achieving linear convergence.
Experimental results demonstrate that our methods significantly accelerate
convergence, outperforming state-of-the-art algorithms.

</details>


### [227] [Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation](https://arxiv.org/abs/2509.14032)
*Philip Jordan,Maryam Kamgarpour*

Main category: cs.GT

TL;DR: 该论文研究了具有共享耦合约束的连续静态博弈中纳什均衡的存在性和计算方法，提出了在玩家级凹约束条件下纳什均衡存在性的新证明，并设计了基于对数障碍正则化的梯度上升算法来计算近似纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于现有纳什均衡存在性理论依赖于联合凸性等强假设，无法处理玩家级凹约束的博弈场景，需要开发更弱条件下的存在性理论和有效计算方法。

Method: 方法包括：1）利用拓扑不动点理论和可行集可收缩性结构洞察证明纳什均衡存在性；2）在存在势函数假设下，采用自适应步长的对数障碍正则化梯度上升法计算近似纳什均衡。

Result: 结果表明：在玩家级凹效用和约束条件下纳什均衡存在；所提算法从初始可行策略出发，在精确梯度反馈下，以O(ε⁻³)迭代次数收敛到ε-近似约束纳什均衡。

Conclusion: 结论是成功建立了较弱条件下的纳什均衡存在性理论，并设计了有效的计算算法，为具有共享耦合约束的非凸博弈提供了理论保证和实用解决方案。

Abstract: We study the existence and computation of Nash equilibria in continuous
static games where the players' admissible strategies are subject to shared
coupling constraints, i.e., constraints that depend on their \emph{joint}
strategies. Specifically, we focus on a class of games characterized by
playerwise concave utilities and playerwise concave constraints. Prior results
on the existence of Nash equilibria are not applicable to this class, as they
rely on strong assumptions such as joint convexity of the feasible set. By
leveraging topological fixed point theory and novel structural insights into
the contractibility of feasible sets under playerwise concave constraints, we
give an existence proof for Nash equilibria under weaker conditions. Having
established existence, we then focus on the computation of Nash equilibria via
independent gradient methods under the additional assumption that the utilities
admit a potential function. To account for the possibly nonconvex feasible
region, we employ a log barrier regularized gradient ascent with adaptive
stepsizes. Starting from an initial feasible strategy profile and under exact
gradient feedback, the proposed method converges to an $\epsilon$-approximate
constrained Nash equilibrium within $\mathcal{O}(\epsilon^{-3})$ iterations.

</details>


### [228] [Generalised Reachability Games Revisited](https://arxiv.org/abs/2509.14091)
*Sougata Bose,Daniel Hausmann,Soumyajit Paul,Sven Schewe,Tansholpan Zhanabekova*

Main category: cs.GT

TL;DR: 本文研究了图上的广义可达性游戏及其优化变体的复杂度，扩展了已知的可处理类，并分析了目标集大小优化问题的难解性。


<details>
  <summary>Details</summary>
Motivation: 经典可达性游戏是零和游戏，其中一个玩家Eve的目标是访问给定目标集中的顶点，而另一个玩家Adam的目标是阻止这一行为。广义可达性游戏将这一概念推广到多个目标集，Eve需要按任意顺序访问所有目标集。本文旨在进一步研究具有广义可达性目标的两人游戏的复杂度。

Method: 研究采用复杂度分析方法，首先扩展了已知的可处理类，从所有目标集都是单例的情况扩展到允许对数数量任意大小的目标集。其次，研究了广义可达性的优化变体，重点关注目标集大小的优化问题。

Result: 1) 提供了改进的广义可达性游戏复杂度图景；2) 对于优化变体，大多数有趣情况都显示难解性；3) 当Eve试图最大化访问的单例目标集数量时，优化问题是NP难的；4) 当所有目标集都是单例时，通过要求Eve承诺她能保证访问的最大目标集子集，可以恢复可处理性。

Conclusion: 广义可达性游戏的复杂度分析揭示了在扩展目标集类型和数量时的计算边界，优化变体在大多数情况下是难解的，但在特定约束条件下可以找到可处理的解决方案。

Abstract: Classic reachability games on graphs are zero-sum games, where the goal of
one player, Eve, is to visit a vertex from a given target set, and that of
other player, Adam, is to prevent this. Generalised reachability games, studied
by Fijalkow and Horn, are a generalisation of reachability objectives, where
instead of a single target set, there is a family of target sets and Eve must
visit all of them in any order. In this work, we further study the complexity
of solving two-player games on graphs with generalised reachability objectives.
Our results are twofold: first, we provide an improved complexity picture for
generalised reachability games, expanding the known tractable class from games
in which all target sets are singleton to additionally allowing a logarithmic
number of target sets of arbitrary size. Second, we study optimisation variants
of generalised reachability with a focus on the size of the target sets. For
these problems, we show intractability for most interesting cases.
Particularly, in contrast to the tractability in the classic variant for
singleton target sets, the optimisation problem is NP-hard when Eve tries to
maximise the number of singleton target sets that are visited. Tractability can
be recovered in the optimisation setting when all target sets are singleton by
requiring that Eve pledges a maximum sized subset of target sets that she can
guarantee to visit.

</details>


### [229] [Sound Value Iteration for Simple Stochastic Games](https://arxiv.org/abs/2509.14112)
*Muqsit Azeem,Jan Kretinsky,Maximilian Weininger*

Main category: cs.GT

TL;DR: 本文扩展了声音值迭代(SVI)算法，使其能够处理随机游戏(SG)和具有端组件的MDP，提供了精确的上下界保证和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 基本值迭代算法无法提供结果精度保证，现有的SVI算法虽然提供了精确边界和更快收敛，但不能处理随机游戏和具有端组件的MDP问题。

Method: 扩展SVI算法，特别改进了对端组件的处理方式，不同于文献中的现有方法，并提供了多个优化技术。

Result: 开发了原型实现，实验证明在具有概率循环的系统上表现出良好潜力。

Conclusion: 成功扩展了SVI算法适用范围，能够处理更广泛的随机游戏和MDP问题，同时保持了算法的精确边界特性和快速收敛优势。

Abstract: Algorithmic analysis of Markov decision processes (MDP) and stochastic games
(SG) in practice relies on value-iteration (VI) algorithms. Since basic VI does
not provide guarantees on the precision of the result, variants of VI have been
proposed that offer such guarantees. In particular, sound value iteration (SVI)
not only provides precise lower and upper bounds on the result, but also
converges faster in the presence of probabilistic cycles. Unfortunately, it is
neither applicable to SG, nor to MDP with end components. In this paper, we
extend SVI and cover both cases. The technical challenge consists mainly in
proper treatment of end components, which require different handling than in
the literature. Moreover, we provide several optimizations of SVI. Finally, we
evaluate our prototype implementation experimentally to demonstrate its
potential on systems with probabilistic cycles.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [230] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

TL;DR: 提出了USPIL框架，结合物理信息神经网络和守恒定律，统一建模捕食者-猎物系统的时空动力学，在保持物理一致性的同时实现高效计算和机制解释。


<details>
  <summary>Details</summary>
Motivation: 生态系统的多尺度复杂动态挑战传统建模方法，需要新方法来捕捉时空振荡和涌现模式，同时遵守守恒原理。

Method: 使用物理信息神经网络(PINNs)和守恒定律的深度学习架构，通过自动微分强制执行物理约束，采用自适应损失权重平衡数据保真度和物理一致性。

Result: 在Lotka-Volterra系统中，1D时间动力学达到98.9%相关性，2D系统捕捉到复杂螺旋波，守恒定律遵守度在0.5%以内，推理速度比数值求解器快10-50倍。

Conclusion: USPIL为多尺度生态建模开辟了新途径，是生态预测、保护规划和理解生态系统恢复力的变革性工具，确立了物理信息深度学习作为科学严谨的范式。

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [231] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

TL;DR: 本文通过360次实验研究发现，不同优化器在神经网络训练中的能源效率存在显著差异，AdamW和NAdam表现最节能，而SGD在复杂数据集上性能最佳但碳排放更高


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越复杂和计算需求增加，理解训练决策对环境的影响对于可持续AI发展变得至关重要

Method: 在三个基准数据集(MNIST、CIFAR-10、CIFAR-100)上使用8种流行优化器进行360次对照实验，使用CodeCarbon在Apple M1 Pro硬件上精确追踪能源消耗

Result: 发现训练速度、准确性和环境影响之间存在显著权衡，这些权衡因数据集和模型复杂度而异。AdamW和NAdam表现最节能，SGD在复杂数据集上性能最佳但碳排放更高

Conclusion: 研究结果为从业者在机器学习工作流中平衡性能和可持续性提供了可行的见解

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [232] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出混合DeepONet-Transolver框架，用于解决PET瓶子屈曲分析问题，能够同时预测节点位移场和时间相关的反作用力，在几何形状变化时具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络方法在处理非参数化几何域变化时的泛化能力有限，而传统的有限元分析计算成本高昂，需要开发计算高效且可扩展的替代模型。

Method: 采用混合DeepONet-Transolver框架，在Abaqus中通过非线性有限元模拟生成254个独特设计的数据集，对两个参数化瓶子几何家族进行训练。

Result: 在四参数瓶子家族上，位移场的平均相对L²误差为2.5-13%，时间相关反作用力的误差约为2.4%，点位移误差在10⁻⁴-10⁻³量级，准确捕捉了屈曲等关键物理现象。

Conclusion: 该框架展示了作为可扩展计算高效替代模型的潜力，特别适用于计算力学中的多任务预测和需要快速设计评估的应用场景。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [233] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

TL;DR: AERIS是一个10-800亿参数的像素级Swin扩散变换器，用于改进天气预报的集合校准和稳定性，在Aurora超级计算机上实现了10.21 ExaFLOPS的性能表现，在90天季节尺度上优于IFS ENS系统。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散方法在高分辨率天气预测中难以稳定扩展的问题，利用生成式机器学习更好地理解复杂地球系统动力学。

Method: 提出AERIS（1.3-80B参数像素级Swin扩散变换器）和SWiPe技术（结合窗口并行、序列并行和流水线并行的方法），在0.25° ERA5数据集上进行训练和评估。

Result: 在Aurora（10,080节点）上达到10.21 ExaFLOPS混合精度性能，峰值11.21 ExaFLOPS，弱扩展效率95.5%，强扩展效率81.6%。AERIS在90天季节尺度上优于IFS ENS并保持稳定。

Conclusion: 十亿参数级别的扩散模型在天气和气候预测方面具有巨大潜力，AERIS展示了在高分辨率下稳定扩展的能力和优异的预测性能。

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [234] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

TL;DR: LAMeL是一个用于化学性质预测的线性元学习算法，在保持模型可解释性的同时显著提升预测准确率，相比标准岭回归有1.1-25倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 化学研究中高质量数据集有限，机器学习方法虽然提升了预测能力但增加了数据需求。需要可解释AI来弥合预测准确性和人类可理解性之间的差距。

Method: 采用元学习框架，识别相关任务间的共享模型参数，学习共同的功能流形作为新任务的更优起点，即使任务间不共享数据。

Result: 在不同数据集域上，性能提升范围从1.1倍到25倍不等，始终优于或匹敌传统线性方法。

Conclusion: LAMeL是化学性质预测中既准确又可解释的可靠工具，特别适合需要准确性和可解释性并重的场景。

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [235] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

TL;DR: 研究发现GPT-4o mini存在"单模态瓶颈"安全架构缺陷，多模态安全过滤器会错误拦截良性内容，导致高假阳性率


<details>
  <summary>Details</summary>
Motivation: 随着大型多模态模型(LMMs)在日常数字生活中的普及，理解其安全架构对AI对齐至关重要，需要系统分析这些模型在多模态仇恨言论检测任务中的表现

Method: 使用Hateful Memes Challenge数据集的500个样本进行多阶段调查，通过定量验证144个内容策略拒绝案例来分析模型的推理和失败模式

Result: 实验识别出"单模态瓶颈"架构缺陷，安全过滤器在50%视觉内容和50%文本内容上同等触发错误拦截，系统脆弱且会产生可预测的假阳性

Conclusion: 研究揭示了最先进LMMs中能力与安全之间的根本矛盾，强调需要更集成、上下文感知的对齐策略来确保AI系统既安全又有效地部署

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [236] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

TL;DR: 基于自然语言处理和语义嵌入的自动化故障分析框架，通过实时分析EPICS控制系统日志来检测异常事件序列


<details>
  <summary>Details</summary>
Motivation: 为先进光源(ALS)控制系统开发自动化故障分析方法，帮助操作人员快速识别导致复杂系统故障的关键事件序列

Method: 将日志条目视为自然语言，使用语义嵌入技术转换为上下文向量表示，通过序列感知神经网络对正常操作数据训练，为每个事件分配实时异常分数

Result: 能够标记与基线行为的偏差，有效识别系统故障前的关键事件序列

Conclusion: 该方法为大型科学设施的控制系统提供了有效的实时故障检测和预警能力

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [237] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

TL;DR: 提出了一种基于差分隐私的文本生成框架，通过聚合token输出分布来生成高质量合成文本，在保证隐私的同时保持高实用性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在隐私泄露风险，攻击者可能从提示中提取敏感信息，需要开发具有强隐私保证的文本生成方法

Method: 利用差分隐私框架，对私有记录进行推理并聚合每个token的输出分布，结合私有和公共推理的混合操作来提升效用

Result: 在上下文学习任务上优于现有最先进方法，能够生成长且连贯的合成文本同时保持隐私保证

Conclusion: 该方法为隐私保护文本生成提供了有前景的方向，在不微调基础模型的情况下实现了隐私和效用的平衡

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [238] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

TL;DR: 开发DeepLogit模型，通过序列约束方法结合深度学习与离散选择模型，在保持参数可解释性的同时提升预测精度


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在规划和政策领域的应用受限于其黑盒特性，需要一种既能保持可解释性又能提高预测准确性的方法

Method: 采用两步法：先估计仅含线性项的CNN模型（等同于线性参数多项logit模型），然后约束需要解释的参数值，引入高阶项或Transformer等先进架构

Result: 该方法在保持选定参数可解释性的同时，显著提高了模型准确性，优于传统离散选择模型

Conclusion: 展示了理论驱动的离散选择模型与数据驱动的AI模型相结合的统一方法潜力，可在保持规划政策适用性的同时实现更准确的建模

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [239] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 提出结合数字孪生和零知识联邦学习的新框架，解决无人机辅助联邦学习系统的能耗、通信效率和安全问题，能耗降低29.6%


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助联邦学习系统中的高能耗、通信效率低下和安全漏洞等关键问题，确保系统的可靠运行

Method: 集成数字孪生技术实现实时监控和预测性维护，采用零知识证明增强安全性，引入动态分配策略优化无人机飞行路径、传输功率和处理速率，使用块坐标下降和凸优化技术

Result: 系统能耗相比传统联邦学习方法降低29.6%，学习性能、安全性和可扩展性显著提升

Conclusion: 该框架为下一代无人机智能网络提供了有前景的解决方案，在能耗优化、安全增强和系统效率方面表现优异

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [240] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

TL;DR: 将多模态生理信号（PPG、GSR、ACC）转换为2D图像矩阵，使用CNN进行压力检测的新方法，通过信号融合和图像化表示提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法单独处理多模态生理信号或依赖固定编码，无法有效捕捉信号间的时空依赖关系，需要一种能够融合多源信号并提升模型泛化能力的新方法。

Method: 将PPG、GSR、ACC信号转换为2D图像矩阵，通过系统性的信号重组和多格式组合，构建多阶段训练流程，利用CNN捕捉时空和跨信号依赖关系。

Result: 该方法显著提升了压力检测的分类性能，同时提高了模型的泛化能力和鲁棒性，图像化转换还增强了结果的可解释性。

Conclusion: 提出的图像化多模态信号处理方法不仅适用于压力检测，还可广泛应用于其他多模态生理信号分析领域，为可穿戴设备的实时健康监测提供了更准确、个性化的解决方案。

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [241] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-Interleaved是一个将图像-文本交错生成重新定义为工具使用问题的动态框架，通过强化学习训练LLM智能协调多种视觉工具，在多个基准测试中大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前统一模型存在"单一工具"瓶颈，只能生成合成图像，难以处理需要事实基础或编程精度的任务，需要更灵活的框架来整合多种专业视觉工具。

Method: 设计了一个中央LLM/MLLM代理，通过强化学习框架协调在线图像搜索、扩散生成、代码执行和图像编辑等专业工具，采用结合规则逻辑和LLM评估的混合奖励系统。

Result: 在四个基准测试中实现了最先进的性能，大幅超越现有方法，并通过新颖的测试时扩展策略获得进一步性能提升。

Conclusion: LLM-I框架成功解决了当前模型的工具限制问题，通过智能工具协调实现了更灵活和准确的图像-文本交错生成能力。

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [242] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: 本文提出了GenPAS框架，系统性地分析了生成式推荐中数据增强策略对模型性能的影响，并通过三个偏差控制步骤统一了现有方法，在多个数据集上取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐模型训练中，数据增强过程往往被简化处理或缺乏系统性理解，而不同增强策略会导致显著的性能差异，需要建立原则性的框架来指导训练数据构建。

Method: 提出GenPAS框架，将数据增强建模为包含三个偏差控制步骤的随机采样过程：序列采样、目标采样和输入采样，统一了现有广泛使用的策略作为特例。

Result: 在基准和工业数据集上的广泛实验表明，GenPAS在准确性、数据效率和参数效率方面均优于现有策略。

Conclusion: GenPAS为生成式推荐中的训练数据构建提供了原则性指导，通过系统化的数据增强框架显著提升了模型性能。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [243] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

TL;DR: 提出CPT方法，通过多目标优化实现公平性与准确性的可控权衡，使用梯度稳定和剪枝技术来精确控制用户偏好的权衡比例。


<details>
  <summary>Details</summary>
Motivation: 现有工作只寻找单一"最优"解决方案，但帕累托前沿存在多样化解决方案。需要根据用户对公平性和准确性的偏好提供可控的权衡方案。

Method: 提出Controllable Pareto Trade-off (CPT)方法：1) 使用随机梯度的移动平均来稳定公平性更新方向；2) 通过仅保留关键参数的梯度来剪枝梯度。

Result: 在仇恨言论检测和职业分类任务上，CPT相比基线方法能在帕累托前沿获得更高质量的解决方案集，展现出更好的可控性并能精确遵循人工定义的参考向量。

Conclusion: CPT方法有效解决了公平性-准确性权衡的可控性问题，通过多目标优化和梯度处理技术实现了对用户偏好的精确响应。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [244] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

TL;DR: RF-LSCM是一个基于辐射场的多域无线信道建模框架，通过物理感知的频率相关衰减模型和点云辅助环境增强方法，解决了传统单细胞单频段信道建模的局限性，在计算效率和预测精度上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统局部统计信道建模方法局限于单细胞、单网格和单载波频率分析，无法捕捉复杂的跨域交互，需要新的框架来支持多细胞多频段的网络优化需求。

Method: 提出RF-LSCM框架，采用辐射场联合建模大尺度信号衰减和多径分量，引入物理感知的频率相关衰减模型(FDAM)实现跨频段泛化，使用点云辅助环境增强方法支持多细胞多网格建模，并利用低秩张量表示和分层张量角度建模算法(HiTAM)提高计算效率。

Result: 在真实多细胞数据集上的实验表明，RF-LSCM显著优于现有方法，覆盖预测的平均绝对误差(MAE)降低30%，通过有效融合多频数据使MAE提升22%。

Conclusion: RF-LSCM通过创新的辐射场建模和高效计算架构，成功解决了传统信道建模的局限性，为蜂窝网络优化提供了更准确和高效的信道建模解决方案。

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [245] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

TL;DR: 本文提出了一个基于共形预测的分布无关不确定性量化框架，为物理信息神经网络(PINNs)提供严格的统计保证和空间自适应不确定性区间


<details>
  <summary>Details</summary>
Motivation: 现有的PINNs不确定性量化方法缺乏严格的统计保证，需要一种能够提供有限样本覆盖保证的分布无关方法

Method: 引入分布无关的共形预测框架，通过在校准集上构建非共形性分数来校准预测区间，并进一步提出局部共形分位数估计来处理空间异方差性

Result: 在典型PDE系统（阻尼谐振子、泊松、Allen-Cahn和亥姆霍兹方程）上的系统评估表明，该框架实现了可靠的校准和局部自适应不确定性区间，一致优于启发式UQ方法

Conclusion: 这项工作通过将PINNs与分布无关UQ相结合，不仅提高了校准和可靠性，还为复杂PDE系统的不确定性感知建模开辟了新途径

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [246] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

TL;DR: 本研究开发了一个基于智能手表的系统，通过心率数据和特质水平测量来预测社交焦虑患者的瞬时焦虑波动，在检测状态焦虑方面达到了60.4%的平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种常见心理健康问题，但之前很少有研究测量或预测日常焦虑波动。捕捉这些日内动态对于设计实时个性化干预措施至关重要。

Method: 使用定制智能手表系统收集91名社交焦虑大学生的数据，每天进行7次生态瞬时评估。基于外部心率数据开发基础模型，将其表征迁移到研究数据集并进行微调，结合特质水平测量构建元学习器。

Result: 在研究数据集中达到60.4%的状态焦虑检测平衡准确率。在TILES-18数据集的10,095个每日评估中达到59.1%的平衡准确率，比先前工作至少高出7%。

Conclusion: 该方法能够有效预测社交焦虑患者的瞬时焦虑波动，为实时个性化干预措施的设计提供了重要技术支持，具有良好的泛化能力。

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [247] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出了DirGraphSSM，首个将状态空间模型系统扩展到有向图学习的架构，通过k-hop ego图序列化和消息传递机制，在保持高效训练的同时实现了SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有GNN和图Transformer在处理有向图时面临两个主要挑战：有效捕捉长距离因果依赖关系，以及在处理大规模图数据时平衡准确性和训练效率。现有的图状态空间模型仅适用于无向图，限制了其性能

Method: 提出DirEgo2Token方法通过k-hop ego图将有向图序列化，并在此基础上开发DirGraphSSM架构，通过消息传递机制在有向图上实现状态空间模型

Result: 在三个代表性有向图学习任务上达到SOTA性能，在另外两个任务上获得竞争性性能，训练速度比现有SOTA模型提升1.5-2倍

Conclusion: DirGraphSSM成功将有向图学习与状态空间模型相结合，在准确性和效率方面都取得了显著提升，为有向图学习提供了新的有效解决方案

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [248] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

TL;DR: ParaAegis是一个并行保护框架，通过模型分割策略在联邦学习中实现隐私-效用-效率的灵活平衡控制，使用轻量级差分隐私保护低重要性部分，同态加密保护关键部分。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中现有保护机制（如差分隐私和同态加密）在模型效用和计算效率之间强制刚性权衡的问题，缺乏灵活性阻碍了实际应用。

Method: 提出战略模型分割方案：对模型中重要性较低的低范数部分应用轻量级差分隐私，其余部分使用同态加密保护，并通过分布式投票机制确保分割共识。

Result: 理论分析确认了在相同隐私保护水平下效率与效用之间的可调节性。实验结果表明通过调整超参数，该方法能够在模型精度和训练时间之间灵活优先选择。

Conclusion: ParaAegis框架为联邦学习实践者提供了对隐私-效用-效率平衡的灵活控制，解决了现有保护机制的刚性权衡问题。

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [249] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

TL;DR: ST-LINK是一个增强大语言模型捕捉时空依赖性的新框架，通过空间增强注意力和记忆检索前馈网络解决LLM在交通预测中的空间建模限制


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型主要针对序列标记处理设计，在捕捉交通数据中的空间依赖性方面存在显著挑战，特别是在建模空间关系和图结构空间数据方面存在架构不兼容问题

Method: 提出ST-LINK框架，包含两个关键组件：1) 空间增强注意力(SE-Attention)，将旋转位置嵌入扩展到注意力机制中，通过直接旋转变换整合空间相关性；2) 记忆检索前馈网络(MRFFN)，动态检索和利用关键历史模式来捕捉复杂时间依赖性

Result: 在基准数据集上的综合实验表明，ST-LINK超越了传统的深度学习和LLM方法，能够有效捕捉常规交通模式和突变变化

Conclusion: ST-LINK成功解决了LLM在交通预测中的空间建模限制，通过创新的空间增强机制显著提升了时空依赖性的捕捉能力

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [250] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

TL;DR: 本文从因果视角分析多视图无监督特征选择，提出CAUSA方法，通过因果正则化模块分离混淆变量并平衡分布，有效缓解伪相关性问题，在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多视图无监督特征选择方法通过捕获特征与聚类标签间的相关性来选择判别性特征，但忽视了混淆变量导致的伪相关性可能选择不相关特征的问题。

Method: 提出CAUSA方法：1)使用广义无监督谱回归模型识别信息特征；2)引入因果正则化模块自适应分离多视图数据中的混淆变量，并学习视图共享样本权重来平衡混淆变量分布；3)将两者整合到统一学习框架中。

Result: 综合实验表明CAUSA方法在多个基准数据集上优于现有最先进方法，能够选择因果信息特征。

Conclusion: 这是首个在无监督设置下深入研究因果多视图特征选择的工作，从因果视角揭示了现有方法的局限性，并提出了有效的解决方案。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [251] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

TL;DR: 提出了FHNN框架，通过物理结构化的神经网络预测可解释的水动力参数，相比传统黑盒模型显著提升了精度和稳定性


<details>
  <summary>Details</summary>
Motivation: 传统黑盒神经网络模型在流体-结构相互作用问题中缺乏可解释性，长期预测不稳定，需要一种既能保持物理一致性又能处理耗散动力学的方法

Method: 使用物理结构化的神经网络框架，预测方向性附加质量、阻力系数和基于流函数的流动场，并与解析运动方程耦合

Result: 在合成涡流数据集上，FHNN比神经ODE误差低一个数量级，能恢复物理一致的流场，相比哈密顿和拉格朗日神经网络更有效处理耗散动力学

Conclusion: FHNN在保持可解释性的同时有效处理耗散动力学，填补了黑盒学习与透明系统识别之间的空白

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [252] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

TL;DR: 提出了General Physics Transformer (GPhyT)，这是一个基于1.8TB多样化模拟数据训练的物理基础模型，能够在多个物理领域实现零样本泛化和稳定长期预测。


<details>
  <summary>Details</summary>
Motivation: 当前基于物理的机器学习方法局限于单一狭窄领域且需要针对每个新系统重新训练，缺乏像自然语言处理中基础模型那样的"一次训练，随处部署"能力。物理基础模型(PFM)将能够民主化高保真模拟访问、加速科学发现并消除专业求解器开发需求。

Method: 使用Transformer架构，在1.8TB多样化物理模拟数据上进行训练。关键洞见是Transformer能够从上下文中学习推断控制动力学，使单个模型能够模拟多种物理现象而无需被告知底层方程。

Result: GPhyT实现了三个关键突破：(1)在多个物理领域表现优于专业架构达29倍；(2)通过上下文学习实现零样本泛化到完全未见过的物理系统；(3)通过50时间步展开实现稳定长期预测。

Conclusion: 这项工作证明单个模型可以从数据中学习可泛化的物理原理，为通向可能改变计算科学与工程的通用物理基础模型开辟了道路。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [253] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

TL;DR: 本文提出了一种混合量子-经典工作流程，用于解决普惠金融中少样本信用风险评估问题，通过经典机器学习进行特征工程，再使用量子神经网络作为核心分类器，在真实数据集上取得了优于经典方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决普惠金融中由于数据稀缺和不平衡导致的信用风险评估难题，传统方法在处理少样本问题时效果有限，量子机器学习为此提供了新的解决途径。

Method: 设计混合量子-经典工作流程：首先使用经典机器学习模型（逻辑回归、随机森林、XGBoost）进行智能特征工程和降维，然后使用通过参数偏移规则训练的量子神经网络作为核心分类器。

Result: 在279个样本的真实信用数据集上，量子神经网络在模拟中获得了0.852±0.027的平均AUC，在Quafu量子云平台的ScQ-P21超导处理器上实现了0.88的AUC，性能超越了一系列经典基准方法。

Conclusion: 该研究为NISQ时代量子计算在数据受限金融场景中的应用提供了实用蓝图，并为量子计算在高风险应用（如普惠金融）中的潜力提供了有价值的实证证据。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [254] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

TL;DR: 提出了一种端到端可微分混合框架，将图神经网络嵌入孔隙网络模型中，用于多孔介质渗透率预测，避免了传统方法的理想化几何假设，同时保持了物理基础。


<details>
  <summary>Details</summary>
Motivation: 传统纯数据驱动模型缺乏跨尺度泛化能力且不包含显式物理约束，而孔隙网络模型依赖理想化几何假设来估计孔喉水力传导度，限制了在复杂结构中的准确性。需要结合两者优势的新方法。

Method: 开发端到端可微分混合框架，用图神经网络替代孔隙网络模型中的解析公式进行传导度计算，通过自动微分和离散伴随方法实现反向传播，仅需单一渗透率标量作为训练目标。

Result: 该模型实现了高精度和良好的跨尺度泛化能力，优于纯数据驱动和传统孔隙网络模型方法。梯度敏感性分析显示了物理一致的特征影响，增强了模型可解释性。

Conclusion: 该方法为复杂多孔介质中的渗透率预测提供了可扩展且物理信息丰富的框架，减少了模型不确定性并提高了准确性。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [255] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

TL;DR: 提出概率框架联合心脏数据插补和心血管机制模型个性化，用于脑研究中不完整心脏数据的处理


<details>
  <summary>Details</summary>
Motivation: 临床研究中缺乏多模态患者数据限制了机制模型的应用，神经影像数据集无法充分代表心脏特征来建模脑疾病中的心血管因素

Method: 基于变分框架联合推断心脏信息插补模型和能够忠实再现个性化心血管动力学的Gaussian Process模拟器

Result: 在UK Biobank上的实验显示，模型能够准确插补仅包含收缩压和舒张压等最小心脏信息数据集中的缺失特征，同时估计集总模型的模拟参数

Conclusion: 该方法通过模拟与不同脑解剖条件相对应的真实心脏动力学，为探索心脑联合关系提供了新途径

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


### [256] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

TL;DR: 提出了一种分布式环境下图正则化的高斯混合模型学习方法，利用相似性图指导节点间参数共享，避免原始数据传输，在异构小样本场景下优于集中式和本地训练方法


<details>
  <summary>Details</summary>
Motivation: 解决分布式环境中数据异构且样本有限的情况下，如何有效学习高斯混合模型而不需要传输原始数据的问题

Method: 使用图正则化方法，通过提供的相似性图来指导不同节点间的参数共享，实现灵活的邻居参数聚合

Result: 该方法在异构、小样本条件下表现优于集中式训练和本地单独训练的GMM模型

Conclusion: 图正则化的分布式GMM学习方法能够有效处理数据异构性和样本限制问题，提供了一种保护隐私的高效模型训练方案

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [257] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

TL;DR: 本文提出了一个理论框架，将掩码扩散模型解释为离散最优传输中的能量最小化问题，证明了三种能量形式的数学等价性，并通过Beta分布参数化插值调度，实现了高效的采样改进。


<details>
  <summary>Details</summary>
Motivation: 统一掩码扩散模型的理论基础，澄清其数学本质，并为实际采样提供理论指导，特别是在低步数采样设置中提升性能。

Method: 通过数学证明三种能量形式（动能、条件动能和测地线能量）在掩码扩散模型结构下的等价性；使用Beta分布参数化插值调度，将调度设计空间简化为2D搜索。

Result: 理论证明了能量最小化问题的等价性；实验表明，基于能量启发的调度在合成和真实基准测试中优于手工设计的基线，尤其在低步数采样设置中表现突出。

Conclusion: 该框架不仅统一了掩码扩散模型的理论基础，还提供了实用的调度优化方法，显著提升了采样效率，特别是在资源受限的低步数场景中。

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [258] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

TL;DR: FedSSG是一种基于随机采样的历史感知漂移对齐方法，通过维护每个客户端的漂移记忆和使用参与率门控机制，有效解决联邦学习中的非IID数据和部分参与导致的客户端漂移问题。


<details>
  <summary>Details</summary>
Motivation: 非IID数据和部分参与会导致联邦学习中的客户端漂移和局部最优不一致，造成收敛不稳定和精度损失。需要一种能够有效对齐本地和全局模型的方法。

Method: FedSSG维护每个客户端的漂移记忆，积累本地模型差异作为历史梯度的轻量级草图。使用基于观察/期望参与比的门控函数来控制记忆更新和本地对齐项，该门控在采样噪声主导时保持弱和平滑，在参与统计稳定后增强。

Result: 在CIFAR-10/100数据集上，100/500个客户端，2-15%参与率的情况下，FedSSG始终优于强漂移感知基线，测试精度平均提升0.9点(CIFAR-10)和2.7点(CIFAR-100)，目标精度收敛速度平均加快4.5倍。

Conclusion: FedSSG证明了采样统计可以转化为原则性的历史感知相位控制，能够稳定和加速联邦训练，仅需O(d)客户端内存和常数时间门控，在近IID或均匀采样下优雅退化为温和正则化器。

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [259] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

TL;DR: TFMAdapter是一个轻量级适配器，无需微调即可为时间序列基础模型添加协变量信息，通过两阶段方法结合伪预测和TSFM预测，在真实数据集上比基础模型提升24-27%


<details>
  <summary>Details</summary>
Motivation: 大多数时间序列基础模型无法利用协变量信息，因为协变量具有领域特定性且缺乏相关归纳偏置，这限制了其在许多需要准确预测的应用中的性能

Method: 提出TFMAdapter适配器，采用两阶段方法：1) 使用简单回归模型生成伪预测；2) 训练高斯过程回归器，结合伪预测、TSFM预测和协变量来优化预测结果

Result: 在真实世界数据集上的广泛实验表明，TFMAdapter始终优于基础模型和监督基线，以最小的数据和计算开销实现了比基础基础模型24-27%的改进

Conclusion: 轻量级适配器有潜力弥合通用基础模型与领域特定预测需求之间的差距，TFMAdapter展示了在不重新训练的情况下有效整合协变量信息的能力

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [260] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: APFEx是首个专门针对交叉公平性的框架，通过多目标优化解决多个敏感属性组合的公平性问题，在保持准确性的同时显著减少公平性违规


<details>
  <summary>Details</summary>
Motivation: 现有公平性方法只处理单一敏感属性，无法捕捉交叉属性（如种族+性别+年龄）带来的复合偏见，需要专门解决交叉公平性问题

Method: APFEx框架包含三个创新：自适应多目标优化器（动态切换帕累托锥投影、梯度加权和探索策略）、可微交叉公平性度量、理论收敛保证

Result: 在四个真实数据集上的实验表明，APFEx在保持竞争力的准确性的同时，显著减少了公平性违规，优于现有方法

Conclusion: APFEx填补了公平机器学习的重要空白，为交叉公平性提供了可扩展、模型无关的解决方案

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [261] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

TL;DR: 通过简单的置信度加权平均方法，无需重新训练即可组合多个最先进的深度学习模型，在车辆轨迹预测任务中实现了10%的性能提升


<details>
  <summary>Details</summary>
Motivation: 解决如何在不进行昂贵重新训练的情况下，组合多个大型自动驾驶预测模型的优势，提升整体预测性能

Method: 使用置信度加权平均方法直接组合现成的深度学习模型，无需重新训练或微调

Result: 在NuScenes和Argoverse数据集上，该方法比最佳单一模型性能提升10%，特别是在长尾指标上表现优异，且改进在整个数据分布范围内都有效

Conclusion: 简单的模型组合方法能够有效提升轨迹预测性能，证明了集成学习在自动驾驶预测任务中的实用价值，该方法开源可用

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [262] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

TL;DR: 提出WILF-Q方法，使用Q学习自适应学习客户端Whittle指数，解决无线联邦学习中的客户端选择问题，显著提升学习效率


<details>
  <summary>Details</summary>
Motivation: 无线联邦学习中客户端动态状态不可观测，需要高效选择客户端以减少达到特定学习精度所需的总时间

Method: 将客户端选择建模为多臂老虎机问题，通过Q学习自适应学习和更新每个客户端的近似Whittle指数，选择指数最高的客户端

Result: WILF-Q在实验结果表明显著优于现有基线策略，提供了一种鲁棒高效的客户端选择方法

Conclusion: WILF-Q方法不需要客户端状态转移或数据分布的显式知识，适用于实际联邦学习部署，为无线联邦学习中的客户端选择提供了有效解决方案

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [263] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

TL;DR: 提出了X-PINN框架，结合物理信息神经网络和扩展有限元方法，用于解决含多裂纹的断裂力学问题，通过能量损失函数、定制积分方案和域分解方法有效捕捉裂纹不连续性和尖端奇异性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多裂纹断裂力学问题时面临挑战，特别是在捕捉裂纹不连续性和尖端奇异性方面存在困难，需要开发更有效的数值模拟框架。

Method: 结合扩展有限元方法(XFEM)的思想，在神经网络解空间中引入专门函数来显式捕捉裂纹体不连续性和尖端奇异性；使用能量基损失函数、定制积分方案和域分解程序；采用标准解和增强解分量分别由不同神经网络建模的结构化框架。

Result: 数值实验验证了所提方法的有效性和鲁棒性，能够灵活有效地模拟1D和2D域中的复杂多裂纹问题，并具有良好的扩展到3D问题的能力。

Conclusion: X-PINN框架为断裂力学中的多裂纹问题提供了新颖且鲁棒的解决方案，通过神经网络与物理信息的结合，成功克服了传统方法的局限性，具有广阔的应用前景。

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [264] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: EpiSMART是一个用于癫痫发作检测的持续学习框架，通过选择性保留高熵和预测为发作的样本，在有限内存和计算资源下实现个性化适应，在CHB-MIT数据集上F1分数提升21%。


<details>
  <summary>Details</summary>
Motivation: 癫痫诊断依赖专家分析脑电图，过程耗时且需要专业知识。现有深度学习模型存在灾难性遗忘问题，无法适应患者脑电图信号的动态变化，需要开发能够持续学习并个性化适应的自动化检测方法。

Method: 提出EpiSMART持续学习框架，使用大小受限的重放缓冲区和信息样本选择策略，选择性地保留高熵和预测为癫痫发作的样本，以增量方式适应患者特定的脑电图信号特征。

Result: 在CHB-MIT数据集验证中，EpiSMART相比不更新的基线模型F1分数提升21%，平均每天仅需6.46分钟标记数据和6.28次更新，适合可穿戴系统实时部署。

Conclusion: EpiSMART能够在资源受限的现实条件下，有效整合新数据而不损害已有知识，实现鲁棒的个性化癫痫发作检测，为可穿戴医疗系统的实际部署提供了可行的持续学习方案。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [265] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

TL;DR: 提出基于动态图回归的GNSS干扰抑制方法，使用异构图卷积LSTM网络实时预测接收机水平偏差，在多种干扰场景下显著优于传统时间序列基线模型


<details>
  <summary>Details</summary>
Motivation: GNSS系统面临日益严重的故意干扰问题，在需要精确定位和授时的时候导致系统可用性下降，需要实时有效的干扰抑制解决方案

Method: 将卫星接收环境建模为异构星型图（接收机为中心，卫星为叶节点），使用单层异构图卷积LSTM（HeteroGCLSTM）聚合空间上下文和时间动态信息，输出2D偏差向量进行实时校正

Result: 在两种接收机和三种干扰模式下（连续波、三音调、宽带FM），模型在-45dBm时达到3.64-7.74cm的MAE，在-60至-70dBm时提升至1.65-2.08cm。混合模式下MAE为3.78-4.25cm，数据效率研究中仅用10%训练数据仍显著优于基线（20cm vs 36-42cm）

Conclusion: 该方法通过图神经网络有效处理GNSS干扰问题，在精度和数据效率方面均优于传统时间序列方法，为实时干扰抑制提供了有效解决方案

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [266] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

TL;DR: 提出基于联邦学习和差分隐私的隐私保护流行病预测方法，在德国县级层面实现本地化COVID-19病例预测，在保持数据隐私的同时达到接近非隐私模型的预测性能。


<details>
  <summary>Details</summary>
Motivation: 在流行病爆发时需要快速反应，但本地化机器学习模型训练面临数据不足的问题，而集中化数据又存在敏感性和隐私约束的挑战。

Method: 使用联邦学习框架，以县级卫生部门作为客户端，训练多层感知机模型预测病例数。采用客户端级差分隐私技术，只交换经过范数裁剪的更新和添加DP噪声的聚合更新。

Result: 在适度隐私保护水平下，DP模型接近非DP模型性能：2020年11月R²=0.94（vs. 0.95），MAPE=26%；2022年3月R²=0.88（vs. 0.93），MAPE=21%。严格隐私保护会导致预测不稳定。

Conclusion: 客户端级差分隐私联邦学习能够在提供强隐私保证的同时提供有用的县级预测，可行的隐私预算取决于流行病阶段，支持卫生部门之间的隐私合规协作。

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [267] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 该论文提出了一种使用小波变换将纳米孔电流信号转换为尺度图图像，然后利用机器学习算法进行蛋白质分类的新方法，在42种肽上达到了81%的分类准确率，为实时临床诊断提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 开发能够在临床环境中实时分类蛋白质的设备，实现廉价快速的疾病诊断。纳米孔技术虽然具有潜力，但由于电流信号的复杂性，其分类准确性一直受限。

Method: 将纳米孔电流信号通过小波变换转换为尺度图图像，捕捉振幅、频率和时间信息，然后使用机器学习算法进行分类。还展示了模型迁移技术以适应实际硬件部署。

Result: 在42种肽的测试中，该方法达到了约81%的分类准确率，创下了该领域的新纪录。

Conclusion: 该方法为实时肽/蛋白质诊断在临床护理点的实际应用迈出了重要一步，为实现实时疾病诊断的新方法铺平了道路。

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [268] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

TL;DR: 一种基于环境感知器融合的轻量级多模态系统，通过温度、湿度和压力差判断蜂王存在，实现了超过99%的准确率和低耗电的边缘计算。


<details>
  <summary>Details</summary>
Motivation: 现有蜂王监测方法主要依靠人工检查，劳动密集且干扰蜂群，而音频方法则需要高耗电和复杂预处理，容易受到环境噪声影响。

Method: 采用环境感知器融合技术（温度、湿度、内外压力差），通过量化决策树推理在STM32微控制器上实现实时边缘计算。

Result: 系统仅使用环境感知数据就能达到超过99%的蜂王检测准确率，音频特征并没有显著提升性能。

Conclusion: 该研究提供了一种可扩展、可持续的非侵入式蜂箱监测方案，为使用市面上现成的能效硬件实现自主精准养蜂探索了新路径。

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>


### [269] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

TL;DR: 本文研究强化学习中的贝叶斯风险规避方法，通过BRMDP处理模型参数不确定性，证明了贝叶斯风险价值函数与真实价值函数之间的渐近正态性差异，并在线RL和CMAB中应用后验采样算法获得次线性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中由于数据不足导致的认知不确定性，采用贝叶斯风险方法来处理未知基础模型的参数不确定性。

Method: 使用贝叶斯风险马尔可夫决策过程(BRMDP)，推导贝叶斯风险价值函数与原始价值函数之间的渐近正态性关系，并在在线RL和CMAB中应用后验采样算法。

Result: 贝叶斯风险规避方法会悲观地低估原始价值函数，这种差异随风险规避强度增加而增大，随数据量增加而减小。获得了RL和CMAB的次线性遗憾界。

Conclusion: 提出的算法能有效处理认知不确定性，数值实验验证了理论性质，贝叶斯风险方法在数据稀缺时提供保守但安全的决策策略。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [270] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 研究比较了不同优化器和神经网络架构在EEG频段分类中的性能，发现Adagrad和RMSprop优化器表现最佳，CNN在空间特征提取上表现优异，SHAP分析揭示了频段对分类的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索不同优化器和神经网络架构在EEG频段分类任务中的性能差异，以及如何有效预测左右脑半球的分类，以提高神经影像分类任务的准确性和可解释性。

Method: 使用TensorFlow和PyTorch框架实现了三种神经网络架构：深度密集网络、浅层三层网络和卷积神经网络(CNN)，并比较了多种优化器（Adagrad、RMSprop、Adadelta、SGD、FTRL）在不同EEG频段的性能，采用SHAP进行特征重要性分析。

Result: Adagrad和RMSprop优化器在不同频段表现稳定，Adagrad在beta频段表现最佳，RMSprop在gamma频段表现最优。CNN获得第二高准确率，擅长捕捉EEG空间特征。深度密集网络在学习复杂模式方面有竞争力，浅层网络计算效率高但准确率较低。

Conclusion: 优化器选择、模型架构和EEG频段分析对提高分类器性能至关重要，SHAP分析有助于理解不同频段对模型准确性的贡献，为神经影像分类任务提供了重要见解。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [271] [From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting](https://arxiv.org/abs/2509.14113)
*Alessandro Brusaferri,Danial Ramin,Andrea Ballarino*

Main category: cs.LG

TL;DR: 提出Quantile Neural Basis Model，将可解释的Quantile Generalized Additive Models原则融入神经网络框架，在保持预测性能的同时提供模型行为洞察


<details>
  <summary>Details</summary>
Motivation: 虽然神经网络在多水平概率预测中取得了高精度，但理解特征条件输出的底层机制仍然是一个重大挑战，需要提高模型的可解释性

Method: 利用共享基分解和权重因子化，避免参数分布假设，将Quantile Generalized Additive Models的可解释性原则整合到端到端神经网络训练框架中

Result: 在日前电价预测任务上验证，预测性能与分布和分位数回归神经网络相当，同时通过学习输入特征到输出预测的非线性映射提供有价值的模型行为洞察

Conclusion: Quantile Neural Basis Model在保持预测准确性的同时显著提升了模型的可解释性，为理解神经网络预测机制提供了有效途径

Abstract: While neural networks are achieving high predictive accuracy in multi-horizon
probabilistic forecasting, understanding the underlying mechanisms that lead to
feature-conditioned outputs remains a significant challenge for forecasters. In
this work, we take a further step toward addressing this critical issue by
introducing the Quantile Neural Basis Model, which incorporates the
interpretability principles of Quantile Generalized Additive Models into an
end-to-end neural network training framework. To this end, we leverage shared
basis decomposition and weight factorization, complementing Neural Models for
Location, Scale, and Shape by avoiding any parametric distributional
assumptions. We validate our approach on day-ahead electricity price
forecasting, achieving predictive performance comparable to distributional and
quantile regression neural networks, while offering valuable insights into
model behavior through the learned nonlinear mappings from input features to
output predictions across the horizon.

</details>


### [272] [Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy](https://arxiv.org/abs/2509.14129)
*Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani*

Main category: cs.LG

TL;DR: 该研究通过机器学习模型预测再监禁风险，对高风险群体进行针对性心理健康干预，发现对最高风险人群的干预效果最显著。


<details>
  <summary>Details</summary>
Motivation: 监狱系统难以有效处理囚犯的心理健康、药物依赖和无家可归等复杂问题，导致再犯罪和监禁循环，特别是加剧了种族不平等。需要创新方法来打破这一循环。

Method: 使用预测建模方法识别再监禁高风险个体，设计并实施实地试验，对高风险群体进行针对性心理健康外展服务，并评估干预效果。

Result: 模型对新的监狱收监具有高度预测性，最高风险群体中超过一半在一年内重返监狱。干预对最高风险个体最有效，显著影响了心理健康服务使用、急救调度和刑事司法参与。

Conclusion: 针对性心理健康外展服务，特别是针对最高风险人群的干预，可以有效减少再监禁率并改善相关 outcomes，为刑事司法系统改革提供了有效途径。

Abstract: Many incarcerated individuals face significant and complex challenges,
including mental illness, substance dependence, and homelessness, yet jails and
prisons are often poorly equipped to address these needs. With little support
from the existing criminal justice system, these needs can remain untreated and
worsen, often leading to further offenses and a cycle of incarceration with
adverse outcomes both for the individual and for public safety, with
particularly large impacts on communities of color that continue to widen the
already extensive racial disparities in criminal justice outcomes. Responding
to these failures, a growing number of criminal justice stakeholders are
seeking to break this cycle through innovative approaches such as
community-driven and alternative approaches to policing, mentoring, community
building, restorative justice, pretrial diversion, holistic defense, and social
service connections. Here we report on a collaboration between Johnson County,
Kansas, and Carnegie Mellon University to perform targeted, proactive mental
health outreach in an effort to reduce reincarceration rates.
  This paper describes the data used, our predictive modeling approach and
results, as well as the design and analysis of a field trial conducted to
confirm our model's predictive power, evaluate the impact of this targeted
outreach, and understand at what level of reincarceration risk outreach might
be most effective. Through this trial, we find that our model is highly
predictive of new jail bookings, with more than half of individuals in the
trial's highest-risk group returning to jail in the following year. Outreach
was most effective among these highest-risk individuals, with impacts on mental
health utilization, EMS dispatches, and criminal justice involvement.

</details>


### [273] [A Compositional Kernel Model for Feature Learning](https://arxiv.org/abs/2509.14158)
*Feng Ruan,Keli Liu,Michael Jordan*

Main category: cs.LG

TL;DR: 该论文研究了一种组合式核岭回归方法，通过坐标重加权来学习特征，证明了在噪声变量为高斯分布时，全局最小值和驻点都能有效剔除噪声坐标，并发现拉普拉斯核等ℓ1型核能恢复非线性特征，而高斯核只能恢复线性特征。


<details>
  <summary>Details</summary>
Motivation: 研究组合式核岭回归作为特征学习的简单测试平台，探索如何通过变分问题来恢复相关变量并消除噪声变量，特别关注不同核函数在特征选择中的表现差异。

Method: 采用组合式核岭回归方法，将预测器应用于输入的坐标重加权，将其表述为变分问题，分析全局最小值和驻点的性质，比较ℓ1型核（如拉普拉斯核）和高斯核在特征恢复中的表现。

Result: 证明了当噪声变量为高斯分布时，全局最小值和驻点都能成功剔除噪声坐标；发现ℓ1型核能在驻点恢复非线性效应的特征，而高斯核只能恢复线性特征。

Conclusion: 组合式核岭回归为特征学习提供了有效的测试框架，ℓ1型核在非线性特征恢复方面优于高斯核，这为核函数选择提供了重要指导意义。

Abstract: We study a compositional variant of kernel ridge regression in which the
predictor is applied to a coordinate-wise reweighting of the inputs. Formulated
as a variational problem, this model provides a simple testbed for feature
learning in compositional architectures. From the perspective of variable
selection, we show how relevant variables are recovered while noise variables
are eliminated. We establish guarantees showing that both global minimizers and
stationary points discard noise coordinates when the noise variables are
Gaussian distributed. A central finding is that $\ell_1$-type kernels, such as
the Laplace kernel, succeed in recovering features contributing to nonlinear
effects at stationary points, whereas Gaussian kernels recover only linear
ones.

</details>


### [274] [Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework](https://arxiv.org/abs/2509.14167)
*Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek*

Main category: cs.LG

TL;DR: 提出了一个端到端框架，通过稀疏常规数据非侵入性地估计青光眼治疗中无法测量的关键参数（如小梁网渗透性），解决了缺乏真实数据和计算成本高的逆问题挑战。


<details>
  <summary>Details</summary>
Motivation: 青光眼治疗中关键参数（如眼内压的决定因素小梁网渗透性）无法在体内测量，临床依赖间接替代指标，同时缺乏真实数据和计算成本阻碍了预测模型开发。

Method: 采用多阶段人工智能架构功能分离问题，提出新颖的PCDS数据生成策略避免大量昂贵模拟，将计算时间从数年缩短到数小时，并使用贝叶斯引擎量化预测不确定性。

Result: 非侵入性估计的流出设施与最先进的眼压测量技术高度一致，精度接近直接物理仪器；新推导的渗透性生物标志物在按疾病风险分层临床队列方面表现出高准确性。

Conclusion: 该框架为其他数据稀缺、计算密集型领域的类似逆问题提供了可推广的解决方案蓝图，具有重要的诊断潜力。

Abstract: Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.

</details>


### [275] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: TopoSizing是一个端到端框架，通过图算法和LLM代理实现电路层次化理解，并将领域知识整合到贝叶斯优化中，提高模拟电路设计效率


<details>
  <summary>Details</summary>
Motivation: 模拟和混合信号电路设计面临高质量数据短缺和领域知识难以嵌入自动化流程的挑战，传统黑盒优化缺乏电路理解，学习型方法成本高且需要重新训练

Method: 首先使用图算法将电路组织成层次化的设备-模块-阶段表示，然后LLM代理执行假设-验证-精炼循环进行标注，最后将验证后的洞察整合到贝叶斯优化中

Result: 该方法能够直接从原始网表进行稳健的电路理解，并将知识转化为优化增益，通过LLM引导的初始采样和停滞触发的信任区域更新提高效率

Conclusion: TopoSizing框架实现了端到端的电路理解和优化，在保持可行性的同时显著提高了模拟电路设计的效率

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [276] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: TGPO是一个离线强化学习框架，通过树形轨迹表示和过程奖励模型解决Web Agent训练中的信用分配、标注成本和奖励稀疏问题，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和视觉语言模型的发展，使用大模型作为Web Agent进行自动化网页交互变得重要，但强化学习训练面临信用分配错误、标注成本高和奖励稀疏等关键挑战。

Method: 提出Tree-Guided Preference Optimization (TGPO)框架，使用树形轨迹表示合并语义相同的状态消除标签冲突，包含过程奖励模型自动生成细粒度奖励（通过子目标进度、冗余检测和动作验证），以及动态权重机制优先处理高影响力决策点。

Result: 在Online-Mind2Web和自建的C-WebShop数据集上的实验表明，TGPO显著优于现有方法，以更少的冗余步骤实现更高的成功率。

Conclusion: TGPO框架有效解决了Web Agent训练中的关键问题，通过创新的树形结构和过程奖励机制提升了性能表现。

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [277] [Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](https://arxiv.org/abs/2509.14181)
*Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun*

Main category: cs.LG

TL;DR: TimeAlign是一个轻量级的即插即用框架，通过表示对齐来弥合时间序列预测中输入历史与未来目标之间的分布差距，显著提升各种基预测器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习等表示学习技术在时间序列预测中表现不佳，作者认为显式的表示对齐能够提供关键信息来弥合输入历史与未来目标之间的分布差距。

Method: TimeAlign通过简单的重构任务学习辅助特征，并将这些特征反馈给任何基预测器。该方法架构无关且计算开销极小。

Result: 在八个基准测试上的广泛实验验证了其优越性能，增益主要来自纠正历史输入与未来输出之间的频率不匹配问题。

Conclusion: TimeAlign可作为现代深度学习时间序列预测系统的通用对齐模块，理论分析表明其能有效增加学习表示与预测目标之间的互信息。

Abstract: Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.

</details>


### [278] [A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning](https://arxiv.org/abs/2509.14198)
*Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出了一个变分框架来形式化基于残差的自适应策略，通过积分残差的凸变换将离散化选择与误差度量直接关联，系统化设计自适应方案并提升性能


<details>
  <summary>Details</summary>
Motivation: 基于残差的自适应策略在科学机器学习中广泛使用但缺乏理论依据，需要建立一个统一的理论框架来形式化这些方法

Method: 引入变分框架，通过积分残差的凸变换（指数权重对应最小化均匀误差，线性权重对应最小化二次误差），将自适应加权等价于选择优化原始目标的采样分布

Result: 该框架实现了三个优势：系统化设计跨范数的自适应方案、通过损失估计器方差减少降低离散化误差、通过改善梯度信噪比增强学习动态，在算子学习中表现出显著性能提升

Conclusion: 为基于残差的自适应性提供了理论依据，为有原则的离散化和训练策略建立了基础

Abstract: Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

</details>


### [279] [A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training](https://arxiv.org/abs/2509.14216)
*Johnny R. Zhang,Xiaomei Mi,Gaoyuan Du,Qianyi Sun,Shiqi Wang,Jiaxuan Li,Wenhua Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一个开创性的Banach-Bregman随机优化框架，突破了传统Hilbert空间的限制，为下一代优化理论提供了统一基础。


<details>
  <summary>Details</summary>
Motivation: 现有随机优化理论主要局限于Hilbert空间，无法有效处理非欧几里得设置，如单纯形上的镜像下降、稀疏学习的Bregman近端方法、信息几何中的自然梯度下降等。需要建立更通用的Banach空间优化框架。

Method: 引入Banach-Bregman框架，通过Bregman投影和Bregman-Fejer单调性提供统一模板，涵盖随机逼近、镜像下降、自然梯度、自适应方法和mirror-prox等方法。建立了非Hilbert设置中的超松弛技术（λ>2）。

Result: 在机器学习（UCI基准）、深度学习（Transformer训练）、强化学习（actor-critic）和大语言模型（WikiText-2与distilGPT-2）上的实证研究表明，相比经典基线方法，收敛速度提升高达20%，方差减小，精度提高。

Conclusion: Banach-Bregman几何成为统一优化理论和AI核心范式实践的关键基石，为下一代优化方法提供了理论基础和实用工具。

Abstract: Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.

</details>


### [280] [Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems](https://arxiv.org/abs/2509.14219)
*Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran*

Main category: cs.LG

TL;DR: 提出RKTV-INR去噪框架，结合隐式神经表示、龙格-库塔积分和全变分约束，从噪声观测中重建动力系统轨迹，为SINDy提供干净的轨迹和导数以恢复控制方程。


<details>
  <summary>Details</summary>
Motivation: 非线性动力系统的数据驱动建模常受测量噪声影响，需要有效去噪方法来获得准确的状态轨迹和导数，以便可靠地识别系统控制方程。

Method: 使用隐式神经表示(INR)直接拟合噪声观测，通过龙格-库塔积分和全变分约束确保重建状态符合动力系统轨迹，利用自动微分获得准确一阶导数，最后用SINDy方法恢复控制方程。

Result: 实验证明该方法能有效抑制噪声、精确估计导数，并实现可靠的系统识别。

Conclusion: RKTV-INR框架成功解决了噪声环境下动力系统建模的挑战，为数据驱动的系统识别提供了有效的去噪和导数估计解决方案。

Abstract: Data-driven modeling of nonlinear dynamical systems is often hampered by
measurement noise. We propose a denoising framework, called Runge-Kutta and
Total Variation Based Implicit Neural Representation (RKTV-INR), that
represents the state trajectory with an implicit neural representation (INR)
fitted directly to noisy observations. Runge-Kutta integration and total
variation are imposed as constraints to ensure that the reconstructed state is
a trajectory of a dynamical system that remains close to the original data. The
trained INR yields a clean, continuous trajectory and provides accurate
first-order derivatives via automatic differentiation. These denoised states
and derivatives are then supplied to Sparse Identification of Nonlinear
Dynamics (SINDy) to recover the governing equations. Experiments demonstrate
effective noise suppression, precise derivative estimation, and reliable system
identification.

</details>


### [281] [Language models' activations linearly encode training-order recency](https://arxiv.org/abs/2509.14223)
*Dmitrii Krasheninnikov,Richard E. Turner,David Krueger*

Main category: cs.LG

TL;DR: 语言模型的激活值线性编码了训练过程中信息被学习的时间顺序，模型能够区分信息获取的时间点


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否以及如何编码信息在训练过程中被学习的时间顺序，这对于理解模型如何处理冲突数据和知识修改具有重要意义

Method: 通过顺序微调Llama-3.2-1B模型在六个不相交但相似的命名实体数据集上，分析激活值的线性编码特性，使用线性探测和2D投影技术

Result: 发现激活值中心点按训练顺序精确排列在一条直线上，线性探测能准确区分早期和晚期实体（约90%准确率），模型还能微调以报告未见实体的训练阶段（约80%准确率）

Conclusion: 模型能够区分信息获取的时间，这一发现对模型管理冲突数据和响应知识修改具有重要启示意义

Abstract: We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

</details>


### [282] [Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](https://arxiv.org/abs/2509.14225)
*Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo*

Main category: cs.LG

TL;DR: 本文提出使用临界阻尼高阶Langevin动力学来防御扩散模型中的成员推理攻击，通过引入辅助变量和联合扩散过程来增强数据隐私保护。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI应用的快速发展，数据安全问题日益突出。扩散模型虽然相比其他生成模型对成员推理攻击具有更强的内在抵抗力，但仍然存在被攻击的风险，需要有效的防御机制。

Method: 采用临界阻尼高阶Langevin动力学，引入多个辅助变量和联合扩散过程。通过辅助变量引入外部随机性，在扩散过程早期破坏敏感输入数据，从而增强隐私保护。

Result: 在玩具数据集和语音数据集上进行了理论分析和实验验证，使用AUROC曲线和FID指标进行评估，证明了该防御方法的有效性。

Conclusion: 提出的基于高阶Langevin动力学的防御机制能够有效增强扩散模型对成员推理攻击的抵抗力，为生成式AI的数据安全提供了新的解决方案。

Abstract: Recent advances in generative artificial intelligence applications have
raised new data security concerns. This paper focuses on defending diffusion
models against membership inference attacks. This type of attack occurs when
the attacker can determine if a certain data point was used to train the model.
Although diffusion models are intrinsically more resistant to membership
inference attacks than other generative models, they are still susceptible. The
defense proposed here utilizes critically-damped higher-order Langevin
dynamics, which introduces several auxiliary variables and a joint diffusion
process along these variables. The idea is that the presence of auxiliary
variables mixes external randomness that helps to corrupt sensitive input data
earlier on in the diffusion process. This concept is theoretically investigated
and validated on a toy dataset and a speech dataset using the Area Under the
Receiver Operating Characteristic (AUROC) curves and the FID metric.

</details>


### [283] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: NIRVANA是一种新颖的结构化剪枝方法，通过神经正切核理论和自适应稀疏分配机制，在保持零样本准确性的同时实现高效LLM压缩


<details>
  <summary>Details</summary>
Motivation: 解决现有结构化剪枝方法在零样本设置下性能显著下降、需要昂贵恢复技术的问题，平衡即时零样本准确性保持与强大微调能力

Method: 基于Adam优化动态下神经正切核的一阶显著性准则，采用自适应稀疏分配机制（在注意力层和MLP层之间调整剪枝强度），以及基于KL散度的校准数据选择策略

Result: 在Llama3、Qwen和T5模型上的综合实验表明，NIRVANA在同等稀疏度约束下优于现有结构化剪枝方法

Conclusion: NIRVANA提供了一个理论上有依据且实用的LLM压缩方法，能够有效平衡零样本性能保持和微调能力

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [284] [Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision](https://arxiv.org/abs/2509.14234)
*Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten*

Main category: cs.LG

TL;DR: Compute as Teacher (CaT) 通过将推理时的探索转化为无参考监督，使用并行rollout合成参考答案，将额外计算转化为教学信号，在可验证和不可验证任务中提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决后训练中缺乏真实监督信号的问题，探索如何在没有ground truth的情况下获得学习信号，通过推理时计算来提供自我监督。

Method: 使用当前策略生成一组并行rollout，通过冻结的锚点策略（初始策略）协调冲突和遗漏来合成参考答案，在可验证任务中使用程序等价性，在不可验证任务中使用自提规则和独立LLM法官评分。

Result: 在Gemma 3 4B、Qwen 3 4B和Llama 3.1 8B上显著提升性能（MATH-500上最高+27%，HealthBench上+12%），结合强化学习（CaT-RL）获得进一步增益（最高+33%和+30%）。

Conclusion: CaT方法有效将推理时计算转化为监督信号，合成方法优于选择方法，性能随rollout数量提升，训练后的策略可以超越初始教师信号。

Abstract: Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

</details>
