<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]
- [cs.CV](#cs.CV) [Total: 48]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.HC](#cs.HC) [Total: 10]
- [cs.LG](#cs.LG) [Total: 74]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.SY](#eess.SY) [Total: 8]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Evolutionary Gait Reconfiguration in Damaged Legged Robots](https://arxiv.org/abs/2506.19968)
*Sahand Farghdani,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种无需训练的快速损伤恢复算法，用于多足机器人在部分或完全失去功能腿时恢复运动。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂任务中易受腿部物理损伤影响，影响任务完成和任务成功率。

Method: 通过生成新步态序列稳定运动，并利用差分进化算法优化步态配置，以最大化前进并减少身体旋转和侧移。

Result: 算法在24自由度六足机器人上成功在一小时内恢复运动，表现出高效性和对结构损伤的鲁棒性。

Conclusion: 该算法为多足机器人提供了一种快速、无需训练的损伤恢复解决方案。

Abstract: Multi-legged robots deployed in complex missions are susceptible to physical
damage in their legs, impairing task performance and potentially compromising
mission success. This letter presents a rapid, training-free damage recovery
algorithm for legged robots subject to partial or complete loss of functional
legs. The proposed method first stabilizes locomotion by generating a new gait
sequence and subsequently optimally reconfigures leg gaits via a developed
differential evolution algorithm to maximize forward progression while
minimizing body rotation and lateral drift. The algorithm successfully restores
locomotion in a 24-degree-of-freedom hexapod within one hour, demonstrating
both high efficiency and robustness to structural damage.

</details>


### [2] [Robust Embodied Self-Identification of Morphology in Damaged Multi-Legged Robots](https://arxiv.org/abs/2506.19984)
*Sahand Farghdani,Mili Patel,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种基于低成本IMU的自建模与损伤识别算法，帮助多足机器人自主适应腿部损伤。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂任务中易受腿部损伤影响性能，需自主适应能力。

Method: 引入FFT滤波器处理时间不一致信号，通过比较机器人与模型的身体方向检测损伤，更新模型并集成到控制系统。

Result: 在崎岖地形实验中验证了算法的鲁棒性和计算效率。

Conclusion: 该方法能有效识别损伤并自主适应，提升多足机器人的可靠性。

Abstract: Multi-legged robots (MLRs) are vulnerable to leg damage during complex
missions, which can impair their performance. This paper presents a
self-modeling and damage identification algorithm that enables autonomous
adaptation to partial or complete leg loss using only data from a low-cost IMU.
A novel FFT-based filter is introduced to address time-inconsistent signals,
improving damage detection by comparing body orientation between the robot and
its model. The proposed method identifies damaged legs and updates the robot's
model for integration into its control system. Experiments on uneven terrain
validate its robustness and computational efficiency.

</details>


### [3] [Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion](https://arxiv.org/abs/2506.20036)
*Jeremiah Coholich,Muhammad Ali Murtaza,Seth Hutchinson,Zsolt Kira*

Main category: cs.RO

TL;DR: 提出了一种新颖的分层强化学习框架，用于四足机器人在复杂地形上的运动。该方法通过高层策略选择目标，低层策略执行，无需额外训练，表现优于端到端方法。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在复杂地形上的运动问题，提高运动效率和安全性。

Method: 采用两层分层结构，高层策略通过在线优化选择目标，低层策略使用actor-critic算法执行。

Result: 在多种复杂地形上表现优于端到端方法，奖励更高且碰撞更少。

Conclusion: 分层强化学习框架在复杂地形运动任务中具有显著优势。

Abstract: We propose a novel hierarchical reinforcement learning framework for
quadruped locomotion over challenging terrain. Our approach incorporates a
two-layer hierarchy in which a high-level policy (HLP) selects optimal goals
for a low-level policy (LLP). The LLP is trained using an on-policy
actor-critic RL algorithm and is given footstep placements as goals. We propose
an HLP that does not require any additional training or environment samples and
instead operates via an online optimization process over the learned value
function of the LLP. We demonstrate the benefits of this framework by comparing
it with an end-to-end reinforcement learning (RL) approach. We observe
improvements in its ability to achieve higher rewards with fewer collisions
across an array of different terrains, including terrains more difficult than
any encountered during training.

</details>


### [4] [Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception](https://arxiv.org/abs/2506.20045)
*Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai*

Main category: cs.RO

TL;DR: 提出一种轻量级深度网络方法，用于预测基于图像姿态估计的抓取是否成功，并通过模拟抓取生成训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有深度物体姿态估计器过于自信，缺乏不确定性量化，导致抓取任务失败风险高。

Method: 通过真实图像姿态估计和模拟抓取生成训练数据，训练网络预测抓取成功概率。

Result: 网络能从多样化的物体数据中学习，联合训练效果优于单独训练。

Conclusion: 该方法能有效减少抓取任务失败，且多样化数据有助于提升模型性能。

Abstract: Deep object pose estimators are notoriously overconfident. A grasping agent
that both estimates the 6-DoF pose of a target object and predicts the
uncertainty of its own estimate could avoid task failure by choosing not to act
under high uncertainty. Even though object pose estimation improves and
uncertainty quantification research continues to make strides, few studies have
connected them to the downstream task of robotic grasping. We propose a method
for training lightweight, deep networks to predict whether a grasp guided by an
image-based pose estimate will succeed before that grasp is attempted. We
generate training data for our networks via object pose estimation on real
images and simulated grasping. We also find that, despite high object
variability in grasping trials, networks benefit from training on all objects
jointly, suggesting that a diverse variety of objects can nevertheless
contribute to the same goal.

</details>


### [5] [Robust Robotic Exploration and Mapping Using Generative Occupancy Map Synthesis](https://arxiv.org/abs/2506.20049)
*Lorin Achey,Alec Reed,Brendan Crowe,Bradley Hayes,Christoffer Heckman*

Main category: cs.RO

TL;DR: 提出了一种基于生成式占用映射的机器人探索新方法，通过SceneSense扩散模型预测3D占用图，显著提升了地图质量和可通行性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人探索中部分观测导致的地图质量不足问题，提升地图的完整性和实用性。

Method: 使用SceneSense扩散模型预测3D占用图，并实时融合到运行中的占用图中。

Result: 实验显示，SceneSense显著提升了地图质量（FID改进24.44%近机器人，75.59%远距离），并改善了探索的稳健性和可通行时间。

Conclusion: SceneSense增强的地图为机器人探索提供了更一致和可靠的结果，优于仅依赖传感器测量的地图。

Abstract: We present a novel approach for enhancing robotic exploration by using
generative occupancy mapping. We introduce SceneSense, a diffusion model
designed and trained for predicting 3D occupancy maps given partial
observations. Our proposed approach probabilistically fuses these predictions
into a running occupancy map in real-time, resulting in significant
improvements in map quality and traversability. We implement SceneSense onboard
a quadruped robot and validate its performance with real-world experiments to
demonstrate the effectiveness of the model. In these experiments, we show that
occupancy maps enhanced with SceneSense predictions better represent our fully
observed ground truth data (24.44% FID improvement around the robot and 75.59%
improvement at range). We additionally show that integrating
SceneSense-enhanced maps into our robotic exploration stack as a "drop-in" map
improvement, utilizing an existing off-the-shelf planner, results in
improvements in robustness and traversability time. Finally we show results of
full exploration evaluations with our proposed system in two dissimilar
environments and find that locally enhanced maps provide more consistent
exploration results than maps constructed only from direct sensor measurements.

</details>


### [6] [PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models](https://arxiv.org/abs/2506.20097)
*Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason*

Main category: cs.RO

TL;DR: PSALM-V是一种自主神经符号学习系统，能够在视觉环境中通过交互推断符号动作语义（如前置和后置条件），无需专家定义动作，利用LLM生成启发式计划和候选语义。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖文本领域或不现实的假设（如预定义问题文件或完全可观察性），而PSALM-V旨在动态推断PDDL问题文件和动作语义，适用于部分可观察和多智能体环境。

Method: PSALM-V通过分析执行结果和合成可能的错误解释，动态推断PDDL问题文件和动作语义，迭代生成和执行计划，同时维护动作语义的树状信念。

Result: 在ALFRED任务中，PSALM-V将计划成功率从37%提升至74%；在RTFM和Overcooked-AI中提高了步骤效率；在机器人BlocksWorld任务中成功推断出PDDL条件。

Conclusion: PSALM-V在部分可观察和多智能体环境中表现出色，能够有效推断符号动作语义，提升任务完成效率。

Abstract: We propose PSALM-V, the first autonomous neuro-symbolic learning system able
to induce symbolic action semantics (i.e., pre- and post-conditions) in visual
environments through interaction. PSALM-V bootstraps reliable symbolic planning
without expert action definitions, using LLMs to generate heuristic plans and
candidate symbolic semantics. Previous work has explored using large language
models to generate action semantics for Planning Domain Definition Language
(PDDL)-based symbolic planners. However, these approaches have primarily
focused on text-based domains or relied on unrealistic assumptions, such as
access to a predefined problem file, full observability, or explicit error
messages. By contrast, PSALM-V dynamically infers PDDL problem files and domain
action semantics by analyzing execution outcomes and synthesizing possible
error explanations. The system iteratively generates and executes plans while
maintaining a tree-structured belief over possible action semantics for each
action, iteratively refining these beliefs until a goal state is reached.
Simulated experiments of task completion in ALFRED demonstrate that PSALM-V
increases the plan success rate from 37% (Claude-3.7) to 74% in partially
observed setups. Results on two 2D game environments, RTFM and Overcooked-AI,
show that PSALM-V improves step efficiency and succeeds in domain induction in
multi-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions
for real-world robot BlocksWorld tasks, despite low-level manipulation failures
from the robot.

</details>


### [7] [Personalized Mental State Evaluation in Human-Robot Interaction using Federated Learning](https://arxiv.org/abs/2506.20212)
*Andrea Bussolan,Oliver Avram,Andrea Pignata,Gianvito Urgese,Stefano Baraldo,Anna Valente*

Main category: cs.RO

TL;DR: 论文提出了一种基于联邦学习的框架，用于在工业5.0环境中实现个性化心理状态评估，同时保护用户隐私。通过多模态生理信号预测操作员压力水平，优化人机协作。


<details>
  <summary>Details</summary>
Motivation: 工业5.0强调工人福祉与大规模定制，需要机器人根据人类心理状态调整行为以提高协作流畅性和安全性。

Method: 整合联邦学习（FL）和多模态生理信号（EEG、ECG、EDA、EMG、呼吸）构建模型，实现分布式设备端训练，保护隐私并提升个性化。

Result: FL方法在压力预测准确性上与集中式训练相当，同时增强个性化，优化人机交互。

Conclusion: 该框架推动了隐私保护的适应性机器人技术，提升智能制造业中的劳动力福祉。

Abstract: With the advent of Industry 5.0, manufacturers are increasingly prioritizing
worker well-being alongside mass customization. Stress-aware Human-Robot
Collaboration (HRC) plays a crucial role in this paradigm, where robots must
adapt their behavior to human mental states to improve collaboration fluency
and safety. This paper presents a novel framework that integrates Federated
Learning (FL) to enable personalized mental state evaluation while preserving
user privacy. By leveraging physiological signals, including EEG, ECG, EDA,
EMG, and respiration, a multimodal model predicts an operator's stress level,
facilitating real-time robot adaptation. The FL-based approach allows
distributed on-device training, ensuring data confidentiality while improving
model generalization and individual customization. Results demonstrate that the
deployment of an FL approach results in a global model with performance in
stress prediction accuracy comparable to a centralized training approach.
Moreover, FL allows for enhancing personalization, thereby optimizing
human-robot interaction in industrial settings, while preserving data privacy.
The proposed framework advances privacy-preserving, adaptive robotics to
enhance workforce well-being in smart manufacturing.

</details>


### [8] [Generating and Customizing Robotic Arm Trajectories using Neural Networks](https://arxiv.org/abs/2506.20259)
*Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Igor Farkaš*

Main category: cs.RO

TL;DR: 提出了一种神经网络方法，用于生成和定制机械臂的轨迹，确保精度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 为了提高机械臂在与人交互时的动作可预测性，特别是在认知机器人实验场景中。

Method: 通过神经网络计算机械臂的正向运动学，并结合关节角度生成器，训练在人工数据集上开发的另一神经网络。

Result: 机械臂能够执行精确的线性运动，动作质量在形状和精度上得到评估。

Conclusion: 该方法成功生成了可定制形状并适应不同场景的精确轨迹。

Abstract: We introduce a neural network approach for generating and customizing the
trajectory of a robotic arm, that guarantees precision and repeatability. To
highlight the potential of this novel method, we describe the design and
implementation of the technique and show its application in an experimental
setting of cognitive robotics. In this scenario, the NICO robot was
characterized by the ability to point to specific points in space with precise
linear movements, increasing the predictability of the robotic action during
its interaction with humans. To achieve this goal, the neural network computes
the forward kinematics of the robot arm. By integrating it with a generator of
joint angles, another neural network was developed and trained on an artificial
dataset created from suitable start and end poses of the robotic arm. Through
the computation of angular velocities, the robot was characterized by its
ability to perform the movement, and the quality of its action was evaluated in
terms of shape and accuracy. Thanks to its broad applicability, our approach
successfully generates precise trajectories that could be customized in their
shape and adapted to different settings.

</details>


### [9] [Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue](https://arxiv.org/abs/2506.20268)
*Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme*

Main category: cs.RO

TL;DR: 研究评估机器学习模型在检测人机对话中的沟通错误效果，发现即使使用先进模型，识别准确率仅略高于随机猜测，揭示了用户反馈不足的根本问题。


<details>
  <summary>Details</summary>
Motivation: 人机交互中检测沟通错误对维持用户参与和信任至关重要，但机器人难以通过非语言反馈识别错误。

Method: 使用包含240段人机对话的多模态数据集，引入四种对话失败类型，评估计算机视觉模型的性能。

Result: 模型在识别沟通错误时表现不佳，仅略优于随机猜测，但在情感表达更丰富的数据集中能成功识别困惑状态。

Conclusion: 研究揭示了识别机器人沟通错误的根本限制：用户即使感知到错误，也常未反馈给机器人，这有助于改进人机对话设计。

Abstract: Detecting miscommunication in human-robot interaction is a critical function
for maintaining user engagement and trust. While humans effortlessly detect
communication errors in conversations through both verbal and non-verbal cues,
robots face significant challenges in interpreting non-verbal feedback, despite
advances in computer vision for recognizing affective expressions. This
research evaluates the effectiveness of machine learning models in detecting
miscommunications in robot dialogue. Using a multi-modal dataset of 240
human-robot conversations, where four distinct types of conversational failures
were systematically introduced, we assess the performance of state-of-the-art
computer vision models. After each conversational turn, users provided feedback
on whether they perceived an error, enabling an analysis of the models' ability
to accurately detect robot mistakes. Despite using state-of-the-art models, the
performance barely exceeds random chance in identifying miscommunication, while
on a dataset with more expressive emotional content, they successfully
identified confused states. To explore the underlying cause, we asked human
raters to do the same. They could also only identify around half of the induced
miscommunications, similarly to our model. These results uncover a fundamental
limitation in identifying robot miscommunications in dialogue: even when users
perceive the induced miscommunication as such, they often do not communicate
this to their robotic conversation partner. This knowledge can shape
expectations of the performance of computer vision models and can help
researchers to design better human-robot conversations by deliberately
eliciting feedback where needed.

</details>


### [10] [Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles](https://arxiv.org/abs/2506.20311)
*Jingwen Wei*

Main category: cs.RO

TL;DR: 论文探讨了无人机在复杂3D环境中的实时安全导航方法，特别针对森林火灾救援任务，提出了2D和3D导航策略，并整合了无人机与地面无人车的协同控制。


<details>
  <summary>Details</summary>
Motivation: 无人机在灾害救援中的应用尚未充分探索，尤其是在自主导航方面。研究旨在提升救援效率和安全性。

Method: 分阶段设计导航算法：从2D融合导航策略到3D反应式导航策略，最后整合无人机与地面无人车的协同控制。

Result: 提出了有效的导航和控制模型，并通过数学和仿真验证了其可行性。

Conclusion: 研究为无人机在自然灾害救援中的实际应用提供了学术和实践价值。

Abstract: The growing use of mobile robots in sectors such as automotive, agriculture,
and rescue operations reflects progress in robotics and autonomy. In unmanned
aerial vehicles (UAVs), most research emphasizes visual SLAM, sensor fusion,
and path planning. However, applying UAVs to search and rescue missions in
disaster zones remains underexplored, especially for autonomous navigation.
  This report develops methods for real-time and secure UAV maneuvering in
complex 3D environments, crucial during forest fires. Building upon past
research, it focuses on designing navigation algorithms for unfamiliar and
hazardous environments, aiming to improve rescue efficiency and safety through
UAV-based early warning and rapid response.
  The work unfolds in phases. First, a 2D fusion navigation strategy is
explored, initially for mobile robots, enabling safe movement in dynamic
settings. This sets the stage for advanced features such as adaptive obstacle
handling and decision-making enhancements. Next, a novel 3D reactive navigation
strategy is introduced for collision-free movement in forest fire simulations,
addressing the unique challenges of UAV operations in such scenarios.
  Finally, the report proposes a unified control approach that integrates UAVs
and unmanned ground vehicles (UGVs) for coordinated rescue missions in forest
environments. Each phase presents challenges, proposes control models, and
validates them with mathematical and simulation-based evidence. The study
offers practical value and academic insights for improving the role of UAVs in
natural disaster rescue operations.

</details>


### [11] [Near Time-Optimal Hybrid Motion Planning for Timber Cranes](https://arxiv.org/abs/2506.20314)
*Marc-Philip Ecker,Bernhard Bischof,Minh Nhat Vu,Christoph Fröhlich,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 本文提出了一种针对液压驱动木材起重机的新型时间最优、无碰撞混合运动规划方法，改进了VP-STO算法并开发了新的碰撞成本公式。


<details>
  <summary>Details</summary>
Motivation: 解决液压驱动木材起重机在运动规划中面临的独特挑战，如液压驱动约束和被动关节问题，这些问题现有方法很少涉及。

Method: 增强VP-STO算法以包含泵流量约束，并开发新的碰撞成本公式；结合梯度局部规划器形成混合运动规划。

Result: 验证了增强VP-STO作为全局规划器的有效性，优于RRT*算法。

Conclusion: 混合运动规划方法在时间最优性和无碰撞性上表现优异，适用于复杂机械系统。

Abstract: Efficient, collision-free motion planning is essential for automating
large-scale manipulators like timber cranes. They come with unique challenges
such as hydraulic actuation constraints and passive joints-factors that are
seldom addressed by current motion planning methods. This paper introduces a
novel approach for time-optimal, collision-free hybrid motion planning for a
hydraulically actuated timber crane with passive joints. We enhance the
via-point-based stochastic trajectory optimization (VP-STO) algorithm to
include pump flow rate constraints and develop a novel collision cost
formulation to improve robustness. The effectiveness of the enhanced VP-STO as
an optimal single-query global planner is validated by comparison with an
informed RRT* algorithm using a time-optimal path parameterization (TOPP). The
overall hybrid motion planning is formed by combination with a gradient-based
local planner that is designed to follow the global planner's reference and to
systematically consider the passive joint dynamics for both collision avoidance
and sway damping.

</details>


### [12] [Building Forest Inventories with Autonomous Legged Robots -- System, Lessons, and Challenges Ahead](https://arxiv.org/abs/2506.20315)
*Matías Mattamala,Nived Chebrolu,Jonas Frey,Leonard Freißmuth,Haedam Oh,Benoit Casseau,Marco Hutter,Maurice Fallon*

Main category: cs.RO

TL;DR: 本文介绍了一种基于四足机器人的自主森林调查系统，展示了其在自然环境中导航和测绘的能力，并总结了相关挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现代四足机器人具有强大的鲁棒性和移动性，适合在复杂的自然环境中执行任务，如森林调查。本文旨在开发一种自主系统，用于森林树冠下的测绘和树木特征估计。

Method: 提出了一种完整的导航系统架构，包括状态估计、任务规划、树木检测和特征估计。系统在三个欧洲国家的森林中进行了为期一年半的实地测试。

Result: ANYmal机器人能够在30分钟内完成1公顷森林的测绘，树木直径（DBH）的测量精度达到2厘米。

Conclusion: 总结了硬件成熟度、状态估计限制、森林导航问题等五个关键挑战，并提出了未来研究方向，为四足机器人在自然环境中的应用提供了新思路。

Abstract: Legged robots are increasingly being adopted in industries such as oil, gas,
mining, nuclear, and agriculture. However, new challenges exist when moving
into natural, less-structured environments, such as forestry applications. This
paper presents a prototype system for autonomous, under-canopy forest inventory
with legged platforms. Motivated by the robustness and mobility of modern
legged robots, we introduce a system architecture which enabled a quadruped
platform to autonomously navigate and map forest plots. Our solution involves a
complete navigation stack for state estimation, mission planning, and tree
detection and trait estimation. We report the performance of the system from
trials executed over one and a half years in forests in three European
countries. Our results with the ANYmal robot demonstrate that we can survey
plots up to 1 ha plot under 30 min, while also identifying trees with typical
DBH accuracy of 2cm. The findings of this project are presented as five lessons
and challenges. Particularly, we discuss the maturity of hardware development,
state estimation limitations, open problems in forest navigation, future
avenues for robotic forest inventory, and more general challenges to assess
autonomous systems. By sharing these lessons and challenges, we offer insight
and new directions for future research on legged robots, navigation systems,
and applications in natural environments. Additional videos can be found in
https://dynamic.robots.ox.ac.uk/projects/legged-robots

</details>


### [13] [Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation](https://arxiv.org/abs/2506.20320)
*Malte Probst,Raphael Wenzel,Tim Puphal,Monica Dasi,Nico A. Steinhardt,Sango Matsuzaki,Misa Komuro*

Main category: cs.RO

TL;DR: 论文提出了一种分解轨迹规划的方法，结合冲突避免和协作碰撞避免，通过Probabilistic Gap Planner（PGP）提升社交机器人导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有规划器仅关注短期交互，难以在复杂场景中选择长期策略，如寻找人群中的间隙或通道。

Method: 将轨迹规划分解为冲突避免（宏观轨迹）和协作碰撞避免（微观交互），提出PGP作为冲突避免规划器。

Result: 在模拟实验中，PGP结合现有CCA规划器显著提升了性能，如增加空间、减少紧张和碰撞，但路径略长。

Conclusion: PGP方法有效提升了社交机器人导航的长期策略能力，适用于实时机器人平台。

Abstract: In Social Robot Navigation, autonomous agents need to resolve many sequential
interactions with other agents. State-of-the art planners can efficiently
resolve the next, imminent interaction cooperatively and do not focus on longer
planning horizons. This makes it hard to maneuver scenarios where the agent
needs to select a good strategy to find gaps or channels in the crowd. We
propose to decompose trajectory planning into two separate steps: Conflict
avoidance for finding good, macroscopic trajectories, and cooperative collision
avoidance (CCA) for resolving the next interaction optimally. We propose the
Probabilistic Gap Planner (PGP) as a conflict avoidance planner. PGP modifies
an established probabilistic collision risk model to include a general
assumption of cooperativity. PGP biases the short-term CCA planner to head
towards gaps in the crowd. In extensive simulations with crowds of varying
density, we show that using PGP in addition to state-of-the-art CCA planners
improves the agents' performance: On average, agents keep more space to others,
create less tension, and cause fewer collisions. This typically comes at the
expense of slightly longer paths. PGP runs in real-time on WaPOCHI mobile robot
by Honda R&D.

</details>


### [14] [PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks](https://arxiv.org/abs/2506.20343)
*Kento Kawaharazuka,Takahiro Hattori,Keita Yoneda,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种基于物理信息神经网络（PINN）的方法，用于学习肌肉骨骼人形机器人的身体模式，即使数据量有限也能实现高精度学习。


<details>
  <summary>Details</summary>
Motivation: 肌肉骨骼人形机器人的身体结构复杂，肌肉路径常偏离几何模型，传统方法依赖大量实际数据，数据收集耗时且学习困难。

Method: 结合实际机器人数据和物理规律（扭矩与肌肉张力关系），利用PINN方法学习身体模式。

Result: 在仿真和实际机器人中验证了方法的有效性和特点。

Conclusion: 该方法在数据有限情况下仍能高效学习，为肌肉骨骼人形机器人的身体模式学习提供了新思路。

Abstract: Musculoskeletal humanoids are robots that closely mimic the human
musculoskeletal system, offering various advantages such as variable stiffness
control, redundancy, and flexibility. However, their body structure is complex,
and muscle paths often significantly deviate from geometric models. To address
this, numerous studies have been conducted to learn body schema, particularly
the relationships among joint angles, muscle tension, and muscle length. These
studies typically rely solely on data collected from the actual robot, but this
data collection process is labor-intensive, and learning becomes difficult when
the amount of data is limited. Therefore, in this study, we propose a method
that applies the concept of Physics-Informed Neural Networks (PINNs) to the
learning of body schema in musculoskeletal humanoids, enabling high-accuracy
learning even with a small amount of data. By utilizing not only data obtained
from the actual robot but also the physical laws governing the relationship
between torque and muscle tension under the assumption of correct joint
structure, more efficient learning becomes possible. We apply the proposed
method to both simulation and an actual musculoskeletal humanoid and discuss
its effectiveness and characteristics.

</details>


### [15] [CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition](https://arxiv.org/abs/2506.20373)
*Joerg Deigmoeller,Stephan Hasler,Nakul Agarwal,Daniel Tanneberg,Anna Belardinelli,Reza Ghoddoosian,Chao Wang,Felix Ocker,Fan Zhang,Behzad Dariush,Michael Gienger*

Main category: cs.RO

TL;DR: CARMA是一个用于人机群体交互中情境感知的系统，通过唯一标识实体并组织成行动者-对象-动作三元组，实现协作中的角色区分和多行动者感知。


<details>
  <summary>Details</summary>
Motivation: 在群体协作中，机器人需要情境感知能力以正确识别和跟踪行动者、对象及其交互，确保协作的有效性。

Method: CARMA通过唯一标识物理实体并将其组织成行动者-对象-动作三元组，实现情境感知。

Result: 实验表明，CARMA能可靠生成准确的三元组，为时空推理和协作决策提供基础。

Conclusion: CARMA为协作场景中的情境感知提供了结构化且鲁棒的解决方案。

Abstract: We introduce CARMA, a system for situational grounding in human-robot group
interactions. Effective collaboration in such group settings requires
situational awareness based on a consistent representation of present persons
and objects coupled with an episodic abstraction of events regarding actors and
manipulated objects. This calls for a clear and consistent assignment of
instances, ensuring that robots correctly recognize and track actors, objects,
and their interactions over time. To achieve this, CARMA uniquely identifies
physical instances of such entities in the real world and organizes them into
grounded triplets of actors, objects, and actions.
  To validate our approach, we conducted three experiments, where multiple
humans and a robot interact: collaborative pouring, handovers, and sorting.
These scenarios allow the assessment of the system's capabilities as to role
distinction, multi-actor awareness, and consistent instance identification. Our
experiments demonstrate that the system can reliably generate accurate
actor-action-object triplets, providing a structured and robust foundation for
applications requiring spatiotemporal reasoning and situated decision-making in
collaborative settings.

</details>


### [16] [Enhanced Robotic Navigation in Deformable Environments using Learning from Demonstration and Dynamic Modulation](https://arxiv.org/abs/2506.20376)
*Lingyun Chen,Xinrui Zhao,Marcos P. S. Campanha,Alexander Wegener,Abdeldjallil Naceri,Abdalla Swikir,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种结合学习演示（LfD）和动态系统（DS）的新方法，用于机器人在包含可变形障碍物的环境中导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在复杂环境中导航时，区分可变形和不可变形障碍物的需求，以实现安全灵活的轨迹规划。

Method: 在DS框架中引入动态调制矩阵，实时区分可变形和不可变形区域，并结合LfD进行自适应导航。

Result: 通过仿真和机器人实验验证了方法的有效性，能够灵活导航并控制轨迹和速度。

Conclusion: 该方法在可变形环境中实现了安全、可靠的导航，同时保持了动态适应性和轨迹一致性。

Abstract: This paper presents a novel approach for robot navigation in environments
containing deformable obstacles. By integrating Learning from Demonstration
(LfD) with Dynamical Systems (DS), we enable adaptive and efficient navigation
in complex environments where obstacles consist of both soft and hard regions.
We introduce a dynamic modulation matrix within the DS framework, allowing the
system to distinguish between traversable soft regions and impassable hard
areas in real-time, ensuring safe and flexible trajectory planning. We validate
our method through extensive simulations and robot experiments, demonstrating
its ability to navigate deformable environments. Additionally, the approach
provides control over both trajectory and velocity when interacting with
deformable objects, including at intersections, while maintaining adherence to
the original DS trajectory and dynamically adapting to obstacles for smooth and
reliable navigation.

</details>


### [17] [SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning](https://arxiv.org/abs/2506.20394)
*Mimo Shirasaka,Yuya Ikeda,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: 论文提出SPARK框架，用于在线更新语义信息并整合到场景图中，以提升机器人在动态环境中的任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 通用服务机器人需要在线更新几何和语义信息，但语义信息的在线更新尚未充分研究。

Method: 基于离线场景图表示，提出SPARK框架，从环境线索中提取语义信息并更新场景图。

Result: SPARK框架能增强机器人在动态环境中的任务执行能力，适应非常规空间线索（如手势）。

Conclusion: 在线语义信息更新和场景图表示对机器人任务规划至关重要。

Abstract: The ability to update information acquired through various means online
during task execution is crucial for a general-purpose service robot. This
information includes geometric and semantic data. While SLAM handles geometric
updates on 2D maps or 3D point clouds, online updates of semantic information
remain unexplored. We attribute the challenge to the online scene graph
representation, for its utility and scalability. Building on previous works
regarding offline scene graph representations, we study online graph
representations of semantic information in this work. We introduce SPARK:
Spatial Perception and Robot Knowledge Integration. This framework extracts
semantic information from environment-embedded cues and updates the scene graph
accordingly, which is then used for subsequent task planning. We demonstrate
that graph representations of spatial relationships enhance the robot system's
ability to perform tasks in dynamic environments and adapt to unconventional
spatial cues, like gestures.

</details>


### [18] [Multimodal Behaviour Trees for Robotic Laboratory Task Automation](https://arxiv.org/abs/2506.20399)
*Hatem Fakhruldeen,Arvind Raveendran Nambiar,Satheeshkumar Veeramani,Bonilkumar Vijaykumar Tailor,Hadi Beyzaee Juneghani,Gabriella Pizzuto,Andrew Ian Cooper*

Main category: cs.RO

TL;DR: 论文提出了一种基于行为树和多模态感知的新方法，用于提高实验室机器人在执行任务（如样品瓶封盖和实验室架插入）时的可靠性和安全性。实验结果显示高成功率和强错误检测能力。


<details>
  <summary>Details</summary>
Motivation: 实验室机器人虽然能高效完成重复性任务，但其可靠性问题可能导致安全隐患（如毒物泄漏）。需要一种方法确保任务执行的准确性。

Method: 采用行为树结合多模态感知的方法，自动化任务执行并验证其成功完成。

Result: 实验显示样品瓶封盖成功率为88%，实验室架插入成功率为92%，且具备强错误检测能力。

Conclusion: 该方法证明了其鲁棒性和可靠性，为下一代机器人化学家的研发奠定了基础。

Abstract: Laboratory robotics offer the capability to conduct experiments with a high
degree of precision and reproducibility, with the potential to transform
scientific research. Trivial and repeatable tasks; e.g., sample transportation
for analysis and vial capping are well-suited for robots; if done successfully
and reliably, chemists could contribute their efforts towards more critical
research activities. Currently, robots can perform these tasks faster than
chemists, but how reliable are they? Improper capping could result in human
exposure to toxic chemicals which could be fatal. To ensure that robots perform
these tasks as accurately as humans, sensory feedback is required to assess the
progress of task execution. To address this, we propose a novel methodology
based on behaviour trees with multimodal perception. Along with automating
robotic tasks, this methodology also verifies the successful execution of the
task, a fundamental requirement in safety-critical environments. The
experimental evaluation was conducted on two lab tasks: sample vial capping and
laboratory rack insertion. The results show high success rate, i.e., 88% for
capping and 92% for insertion, along with strong error detection capabilities.
This ultimately proves the robustness and reliability of our approach and that
using multimodal behaviour trees should pave the way towards the next
generation of robotic chemists.

</details>


### [19] [Learn to Position -- A Novel Meta Method for Robotic Positioning](https://arxiv.org/abs/2506.20445)
*Dongkun Wang,Junkai Zhao,Yunfei Teng,Jieyang Peng,Wenjing Xue,Xiaoming Tao*

Main category: cs.RO

TL;DR: 提出了一种无需视觉、模型无关的元方法，通过交互反馈补偿机器人定位误差，提高定位精度，并具备学习和适应能力。


<details>
  <summary>Details</summary>
Motivation: 机器人绝对定位精度至关重要，但误差来源复杂且随机，视觉方法易受遮挡或光照影响，需更鲁棒的解决方案。

Method: 采用基于交互反馈的元方法，无需依赖视觉，具备自学习和自适应能力，可加速定位过程。

Result: 实证研究验证了方法的有效性，已在电子元件装配线中实现应用。

Conclusion: 该方法显著提升了机器人定位精度，具备适应性和学习能力，适用于复杂环境。

Abstract: Absolute positioning accuracy is a vital specification for robots. Achieving
high position precision can be challenging due to the presence of various
sources of errors. Meanwhile, accurately depicting these errors is difficult
due to their stochastic nature. Vision-based methods are commonly integrated to
guide robotic positioning, but their performance can be highly impacted by
inevitable occlusions or adverse lighting conditions. Drawing on the
aforementioned considerations, a vision-free, model-agnostic meta-method for
compensating robotic position errors is proposed, which maximizes the
probability of accurate robotic position via interactive feedback. Meanwhile,
the proposed method endows the robot with the capability to learn and adapt to
various position errors, which is inspired by the human's instinct for grasping
under uncertainties. Furthermore, it is a self-learning and self-adaptive
method able to accelerate the robotic positioning process as more examples are
incorporated and learned. Empirical studies validate the effectiveness of the
proposed method. As of the writing of this paper, the proposed meta search
method has already been implemented in a robotic-based assembly line for
odd-form electronic components.

</details>


### [20] [A Review of Personalisation in Human-Robot Collaboration and Future Perspectives Towards Industry 5.0](https://arxiv.org/abs/2506.20447)
*James Fant-Male,Roel Pieters*

Main category: cs.RO

TL;DR: 本文综述了从工业4.0到工业5.0的转变，强调以人为中心的工作环境，并探讨了人机协作（HRC）在个性化适应方面的最新进展。


<details>
  <summary>Details</summary>
Motivation: 工业5.0的核心是实现以人为中心的技术应用，关注社会福祉和个性化交互，但目前缺乏统一的研究方法。

Method: 通过综述近期研究，分析个性化HRC的关键趋势，包括个人因素、工作单元设计、交互设计及自适应任务完成。

Result: 研究发现个性化HRC的研究趋势增长，但缺乏一致性，并提出了未来发展的伦理和监管问题。

Conclusion: 未来的个性化HRC发展需关注伦理和监管框架，以确保技术的人本主义实现。

Abstract: The shift in research focus from Industry 4.0 to Industry 5.0 (I5.0) promises
a human-centric workplace, with social and well-being values at the centre of
technological implementation. Human-Robot Collaboration (HRC) is a core aspect
of I5.0 development, with an increase in adaptive and personalised interactions
and behaviours. This review investigates recent advancements towards
personalised HRC, where user-centric adaption is key. There is a growing trend
for adaptable HRC research, however there lacks a consistent and unified
approach. The review highlights key research trends on which personal factors
are considered, workcell and interaction design, and adaptive task completion.
This raises various key considerations for future developments, particularly
around the ethical and regulatory development of personalised systems, which
are discussed in detail.

</details>


### [21] [EANS: Reducing Energy Consumption for UAV with an Environmental Adaptive Navigation Strategy](https://arxiv.org/abs/2506.20485)
*Tian Liu,Han Liu,Boyang Li,Long Chen,Kai Huang*

Main category: cs.RO

TL;DR: 该论文提出了一种动态调整无人机导航策略的方法，通过分析其动态特性和时间特性，以减少能耗。实验显示，该方法在任务时间和能耗上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 无人机（UAVS）受限于机载能源，现有导航策略在动态场景中效率低下，需解决任务管道依赖、环境-策略关联和参数选择等挑战。

Method: 提出动态调整导航策略的方法，分析无人机的动态特性和自主导航管道的时间特性，以响应环境变化。

Result: 通过硬件在环（HIL）仿真和真实实验，显示任务时间提升3.2倍和2.6倍，能耗降低2.4倍和1.6倍。

Conclusion: 动态调整导航策略能有效减少无人机能耗，提升任务效率。

Abstract: Unmanned Aerial Vehicles (UAVS) are limited by the onboard energy. Refinement
of the navigation strategy directly affects both the flight velocity and the
trajectory based on the adjustment of key parameters in the UAVS pipeline, thus
reducing energy consumption. However, existing techniques tend to adopt static
and conservative strategies in dynamic scenarios, leading to inefficient energy
reduction. Dynamically adjusting the navigation strategy requires overcoming
the challenges including the task pipeline interdependencies, the
environmental-strategy correlations, and the selecting parameters. To solve the
aforementioned problems, this paper proposes a method to dynamically adjust the
navigation strategy of the UAVS by analyzing its dynamic characteristics and
the temporal characteristics of the autonomous navigation pipeline, thereby
reducing UAVS energy consumption in response to environmental changes. We
compare our method with the baseline through hardware-in-the-loop (HIL)
simulation and real-world experiments, showing our method 3.2X and 2.6X
improvements in mission time, 2.4X and 1.6X improvements in energy,
respectively.

</details>


### [22] [Behavior Foundation Model: Towards Next-Generation Whole-Body Control System of Humanoid Robots](https://arxiv.org/abs/2506.20487)
*Mingqi Yuan,Tao Yu,Wenqi Ge,Xiuyong Yao,Dapeng Li,Huijiang Wang,Jiayu Chen,Xin Jin,Bo Li,Hua Chen,Wei Zhang,Wenjun Zeng*

Main category: cs.RO

TL;DR: 本文综述了行为基础模型（BFMs）在人形机器人全身控制（WBC）中的应用，探讨了其发展、应用、局限性和未来机会。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人全身控制中的复杂动态、欠驱动和多样化任务需求问题，减少学习控制器的重复训练成本。

Method: 利用大规模预训练的行为基础模型（BFMs）学习可重用的原始技能和行为先验，支持零样本或快速适应下游任务。

Result: BFMs为可扩展和通用的人形机器人智能提供了关键方法，并总结了相关论文和项目资源。

Conclusion: BFMs是人形机器人智能的重要研究方向，未来需解决实际应用中的挑战。

Abstract: Humanoid robots are drawing significant attention as versatile platforms for
complex motor control, human-robot interaction, and general-purpose physical
intelligence. However, achieving efficient whole-body control (WBC) in
humanoids remains a fundamental challenge due to sophisticated dynamics,
underactuation, and diverse task requirements. While learning-based controllers
have shown promise for complex tasks, their reliance on labor-intensive and
costly retraining for new scenarios limits real-world applicability. To address
these limitations, behavior(al) foundation models (BFMs) have emerged as a new
paradigm that leverages large-scale pretraining to learn reusable primitive
skills and behavioral priors, enabling zero-shot or rapid adaptation to a wide
range of downstream tasks. In this paper, we present a comprehensive overview
of BFMs for humanoid WBC, tracing their development across diverse pre-training
pipelines. Furthermore, we discuss real-world applications, current
limitations, urgent challenges, and future opportunities, positioning BFMs as a
key approach toward scalable and general-purpose humanoid intelligence.
Finally, we provide a curated and long-term list of BFM papers and projects to
facilitate more subsequent research, which is available at
https://github.com/yuanmingqi/awesome-bfm-papers.

</details>


### [23] [Critical Anatomy-Preserving & Terrain-Augmenting Navigation (CAPTAiN): Application to Laminectomy Surgical Education](https://arxiv.org/abs/2506.20496)
*Jonathan Wang,Hisashi Ishida,David Usevitch,Kesavan Venkatesh,Yi Wang,Mehran Armand,Rachel Bronheim,Amit Jain,Adnan Munawar*

Main category: cs.RO

TL;DR: CAPTAiN系统通过分层彩色体素引导，显著提高了椎板切除术的完成率并降低认知负荷，使新手表现接近高级学员。


<details>
  <summary>Details</summary>
Motivation: 椎板切除术风险高，意外撕裂率达11.3%，且缺乏辅助工具，患者解剖结构差异进一步增加了学习难度。

Method: 开发CAPTAiN导航系统，通过虚拟椎板切除术评估其效果，比较标准无导航方法。

Result: CAPTAiN显著提高目标解剖结构完成率（87.99% vs. 74.42%），降低认知负荷，缩小经验差距。

Conclusion: CAPTAiN有潜力优化手术执行并支持技能发展，适用于多种外科和钻孔手术。

Abstract: Surgical training remains a crucial milestone in modern medicine, with
procedures such as laminectomy exemplifying the high risks involved.
Laminectomy drilling requires precise manual control to mill bony tissue while
preserving spinal segment integrity and avoiding breaches in the dura: the
protective membrane surrounding the spinal cord. Despite unintended tears
occurring in up to 11.3% of cases, no assistive tools are currently utilized to
reduce this risk. Variability in patient anatomy further complicates learning
for novice surgeons. This study introduces CAPTAiN, a critical
anatomy-preserving and terrain-augmenting navigation system that provides
layered, color-coded voxel guidance to enhance anatomical awareness during
spinal drilling. CAPTAiN was evaluated against a standard non-navigated
approach through 110 virtual laminectomies performed by 11 orthopedic residents
and medical students. CAPTAiN significantly improved surgical completion rates
of target anatomy (87.99% vs. 74.42%) and reduced cognitive load across
multiple NASA-TLX domains. It also minimized performance gaps across experience
levels, enabling novices to perform on par with advanced trainees. These
findings highlight CAPTAiN's potential to optimize surgical execution and
support skill development across experience levels. Beyond laminectomy, it
demonstrates potential for broader applications across various surgical and
drilling procedures, including those in neurosurgery, otolaryngology, and other
medical fields.

</details>


### [24] [Leveraging Correlation Across Test Platforms for Variance-Reduced Metric Estimation](https://arxiv.org/abs/2506.20553)
*Rachel Luo,Heng Yang,Michael Watson,Apoorva Sharma,Sushant Veer,Edward Schmerling,Marco Pavone*

Main category: cs.RO

TL;DR: 提出了一种基于控制变量的通用估计框架，通过利用模拟和现实世界数据的配对，减少蒙特卡洛估计的方差，从而显著降低现实世界测试的样本需求。


<details>
  <summary>Details</summary>
Motivation: 学习型机器人系统需要大量验证以确保可靠性，但现实世界测试成本高昂且数据不足。

Method: 利用配对数据（如模拟与现实观测）和控制变量方法，通过廉价辅助测量（如模拟输出）优化现实世界样本的估计。

Result: 理论分析和实验（自动驾驶和四足机器人）表明，该方法显著提高了样本效率，实现了高概率性能边界。

Conclusion: 该技术可降低现实世界测试负担，使机器人系统的实验评估更高效和经济。

Abstract: Learning-based robotic systems demand rigorous validation to assure reliable
performance, but extensive real-world testing is often prohibitively expensive,
and if conducted may still yield insufficient data for high-confidence
guarantees. In this work, we introduce a general estimation framework that
leverages paired data across test platforms, e.g., paired simulation and
real-world observations, to achieve better estimates of real-world metrics via
the method of control variates. By incorporating cheap and abundant auxiliary
measurements (for example, simulator outputs) as control variates for costly
real-world samples, our method provably reduces the variance of Monte Carlo
estimates and thus requires significantly fewer real-world samples to attain a
specified confidence bound on the mean performance. We provide theoretical
analysis characterizing the variance and sample-efficiency improvement, and
demonstrate empirically in autonomous driving and quadruped robotics settings
that our approach achieves high-probability bounds with markedly improved
sample efficiency. Our technique can lower the real-world testing burden for
validating the performance of the stack, thereby enabling more efficient and
cost-effective experimental evaluation of robotic systems.

</details>


### [25] [HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction](https://arxiv.org/abs/2506.20566)
*Zhonghao Shi,Enyu Zhao,Nathaniel Dennler,Jingzhen Wang,Xinyang Xu,Kaleen Shrestha,Mengxue Fu,Daniel Seita,Maja Matarić*

Main category: cs.RO

TL;DR: HRIBench是一个用于评估视觉语言模型（VLMs）在人类感知任务中性能和延迟权衡的基准测试，涵盖五个关键领域。研究发现当前VLMs在实时部署中仍存在性能与延迟的不足。


<details>
  <summary>Details</summary>
Motivation: 研究实时人类感知在HRI中的重要性，以及VLMs在性能和延迟方面的局限性。

Method: 构建HRIBench基准测试，包含1000个VQA问题，覆盖五个关键领域，并对11种VLMs进行全面评估。

Result: 当前VLMs在核心感知能力上表现不足，且性能和延迟权衡不理想。

Conclusion: 未来需开发更小、低延迟的VLMs以提升实时HRI性能。

Abstract: Real-time human perception is crucial for effective human-robot interaction
(HRI). Large vision-language models (VLMs) offer promising generalizable
perceptual capabilities but often suffer from high latency, which negatively
impacts user experience and limits VLM applicability in real-world scenarios.
To systematically study VLM capabilities in human perception for HRI and
performance-latency trade-offs, we introduce HRIBench, a visual
question-answering (VQA) benchmark designed to evaluate VLMs across a diverse
set of human perceptual tasks critical for HRI. HRIBench covers five key
domains: (1) non-verbal cue understanding, (2) verbal instruction
understanding, (3) human-robot object relationship understanding, (4) social
navigation, and (5) person identification. To construct HRIBench, we collected
data from real-world HRI environments to curate questions for non-verbal cue
understanding, and leveraged publicly available datasets for the remaining four
domains. We curated 200 VQA questions for each domain, resulting in a total of
1000 questions for HRIBench. We then conducted a comprehensive evaluation of
both state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench.
Our results show that, despite their generalizability, current VLMs still
struggle with core perceptual capabilities essential for HRI. Moreover, none of
the models within our experiments demonstrated a satisfactory
performance-latency trade-off suitable for real-time deployment, underscoring
the need for future research on developing smaller, low-latency VLMs with
improved human perception capabilities. HRIBench and our results can be found
in this Github repository: https://github.com/interaction-lab/HRIBench.

</details>


### [26] [Communication-Aware Map Compression for Online Path-Planning: A Rate-Distortion Approach](https://arxiv.org/abs/2506.20579)
*Ali Reza Pedram,Evangelos Psomiadis,Dipankar Maity,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 论文提出了一种在未知环境中协作导航的方法，通过压缩地图表示和优化通信成本来支持路径规划。


<details>
  <summary>Details</summary>
Motivation: 解决在带宽限制下，如何高效传输地图信息以支持协作导航的问题。

Method: 引入比特率度量，将压缩设计问题建模为率失真优化问题，采用反向注水法求解。

Result: 仿真结果表明，该方法能在低带宽下生成任务相关的地图压缩表示。

Conclusion: 提出的方法能高效、实时地支持协作导航，减少通信开销。

Abstract: This paper addresses the problem of collaborative navigation in an unknown
environment, where two robots, referred to in the sequel as the Seeker and the
Supporter, traverse the space simultaneously. The Supporter assists the Seeker
by transmitting a compressed representation of its local map under bandwidth
constraints to support the Seeker's path-planning task. We introduce a bit-rate
metric based on the expected binary codeword length to quantify communication
cost. Using this metric, we formulate the compression design problem as a
rate-distortion optimization problem that determines when to communicate, which
regions of the map should be included in the compressed representation, and at
what resolution (i.e., quantization level) they should be encoded. Our
formulation allows different map regions to be encoded at varying quantization
levels based on their relevance to the Seeker's path-planning task. We
demonstrate that the resulting optimization problem is convex, and admits a
closed-form solution known in the information theory literature as reverse
water-filling, enabling efficient, low-computation, and real-time
implementation. Additionally, we show that the Seeker can infer the compression
decisions of the Supporter independently, requiring only the encoded map
content and not the encoding policy itself to be transmitted, thereby reducing
communication overhead. Simulation results indicate that our method effectively
constructs compressed, task-relevant map representations, both in content and
resolution, that guide the Seeker's planning decisions even under tight
bandwidth limitations.

</details>


### [27] [A Computationally Aware Multi Objective Framework for Camera LiDAR Calibration](https://arxiv.org/abs/2506.20636)
*Venkat Karramreddy,Rangarajan Ramanujam*

Main category: cs.RO

TL;DR: 提出了一种多目标优化框架，用于联合优化LiDAR与相机的外参校准的几何对齐误差和计算成本。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶系统中LiDAR与相机校准的可靠性和效率。

Method: 使用NSGA-II进化算法优化6-DoF变换和点采样率，探索校准精度与计算成本的权衡。

Result: 在KITTI数据集上验证，性能优于现有方法，具有可解释性和可调性。

Conclusion: 该框架为资源受限条件下的校准提供了可扩展且透明的方法，适用于长期自动驾驶系统。

Abstract: Accurate extrinsic calibration between LiDAR and camera sensors is important
for reliable perception in autonomous systems. In this paper, we present a
novel multi-objective optimization framework that jointly minimizes the
geometric alignment error and computational cost associated with camera-LiDAR
calibration. We optimize two objectives: (1) error between projected LiDAR
points and ground-truth image edges, and (2) a composite metric for
computational cost reflecting runtime and resource usage. Using the NSGA-II
\cite{deb2002nsga2} evolutionary algorithm, we explore the parameter space
defined by 6-DoF transformations and point sampling rates, yielding a
well-characterized Pareto frontier that exposes trade-offs between calibration
fidelity and resource efficiency. Evaluations are conducted on the KITTI
dataset using its ground-truth extrinsic parameters for validation, with
results verified through both multi-objective and constrained single-objective
baselines. Compared to existing gradient-based and learned calibration methods,
our approach demonstrates interpretable, tunable performance with lower
deployment overhead. Pareto-optimal configurations are further analyzed for
parameter sensitivity and innovation insights. A preference-based
decision-making strategy selects solutions from the Pareto knee region to suit
the constraints of the embedded system. The robustness of calibration is tested
across variable edge-intensity weighting schemes, highlighting optimal balance
points. Although real-time deployment on embedded platforms is deferred to
future work, this framework establishes a scalable and transparent method for
calibration under realistic misalignment and resource-limited conditions,
critical for long-term autonomy, particularly in SAE L3+ vehicles receiving OTA
updates.

</details>


### [28] [DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy](https://arxiv.org/abs/2506.20668)
*Sungjae Park,Homanga Bharadhwaj,Shubham Tulsiani*

Main category: cs.RO

TL;DR: DemoDiffusion是一种简单且可扩展的方法，通过模仿单个人类演示使机器人能在自然环境中完成任务。结合运动学重定向和预训练的扩散策略，优化机器人轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决机器人模仿人类演示时轨迹不匹配的问题，避免在线强化学习或配对数据的需求。

Method: 1. 通过运动学重定向将人类手部运动转换为机器人轨迹；2. 使用预训练的扩散策略优化轨迹，使其更符合机器人动作分布。

Result: 在仿真和现实实验中，DemoDiffusion优于基础策略和重定向轨迹，能完成预训练策略失败的任务。

Conclusion: DemoDiffusion通过结合人类演示和扩散策略，实现了高效且鲁棒的机器人任务适应。

Abstract: We propose DemoDiffusion, a simple and scalable method for enabling robots to
perform manipulation tasks in natural environments by imitating a single human
demonstration. Our approach is based on two key insights. First, the hand
motion in a human demonstration provides a useful prior for the robot's
end-effector trajectory, which we can convert into a rough open-loop robot
motion trajectory via kinematic retargeting. Second, while this retargeted
motion captures the overall structure of the task, it may not align well with
plausible robot actions in-context. To address this, we leverage a pre-trained
generalist diffusion policy to modify the trajectory, ensuring it both follows
the human motion and remains within the distribution of plausible robot
actions. Our approach avoids the need for online reinforcement learning or
paired human-robot data, enabling robust adaptation to new tasks and scenes
with minimal manual effort. Experiments in both simulation and real-world
settings show that DemoDiffusion outperforms both the base policy and the
retargeted trajectory, enabling the robot to succeed even on tasks where the
pre-trained generalist policy fails entirely. Project page:
https://demodiffusion.github.io/

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [29] [Computer Vision based Automated Quantification of Agricultural Sprayers Boom Displacement](https://arxiv.org/abs/2506.19939)
*Aryan Singh Dalal,Sidharth Rai,Rahul Singh,Treman Singh Kaloya,Rahul Harsha Cheppally,Ajay Sharda*

Main category: cs.CV

TL;DR: 开发了一种基于计算机视觉的系统，用于量化农业喷雾器喷杆的运动，以提高喷雾应用的准确性。


<details>
  <summary>Details</summary>
Motivation: 喷雾喷杆的不稳定性是喷雾应用误差的主要因素之一，但目前缺乏对其运动量的定量了解，难以系统改进设计或控制系统。

Method: 使用YOLO V7、V8和V11神经网络模型实时跟踪喷杆边缘目标，并结合倾角传感器验证模型输出。

Result: 模型检测目标的准确率超过90%，距离估计与传感器数据误差在0.026米内。

Conclusion: 该系统能有效量化喷杆运动，为喷杆设计改进和控制系统优化提供数据支持。

Abstract: Application rate errors when using self-propelled agricultural sprayers for
agricultural production remain a concern. Among other factors, spray boom
instability is one of the major contributors to application errors. Spray
booms' width of 38m, combined with 30 kph driving speeds, varying terrain, and
machine dynamics when maneuvering complex field boundaries, make controls of
these booms very complex. However, there is no quantitative knowledge on the
extent of boom movement to systematically develop a solution that might include
boom designs and responsive boom control systems. Therefore, this study was
conducted to develop an automated computer vision system to quantify the boom
movement of various agricultural sprayers. A computer vision system was
developed to track a target on the edge of the sprayer boom in real time. YOLO
V7, V8, and V11 neural network models were trained to track the boom's
movements in field operations to quantify effective displacement in the
vertical and transverse directions. An inclinometer sensor was mounted on the
boom to capture boom angles and validate the neural network model output. The
results showed that the model could detect the target with more than 90 percent
accuracy, and distance estimates of the target on the boom were within 0.026 m
of the inclinometer sensor data. This system can quantify the boom movement on
the current sprayer and potentially on any other sprayer with minor
modifications. The data can be used to make design improvements to make sprayer
booms more stable and achieve greater application accuracy.

</details>


### [30] [EBC-ZIP: Improving Blockwise Crowd Counting with Zero-Inflated Poisson Regression](https://arxiv.org/abs/2506.19955)
*Yiming Ma,Victor Sanchez,Tanaya Guha*

Main category: cs.CV

TL;DR: 论文提出EBC-ZIP框架，通过零膨胀泊松回归改进人群计数中的密度图估计，解决数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视地面真实密度图的极端稀疏性，导致模型在稀疏区域表现不佳。

Method: 采用零膨胀泊松回归（ZIP）替代传统回归损失，结合增强块分类（EBC）框架。

Result: 在四个基准测试中，EBC-ZIP表现优于EBC，达到最先进水平。

Conclusion: EBC-ZIP通过更合理的概率损失，提升了人群计数的准确性和稳定性。

Abstract: Density map estimation has become the mainstream paradigm in crowd counting.
However, most existing methods overlook the extreme sparsity of ground-truth
density maps. In real-world crowd scenes, the vast majority of spatial regions
(often over 95%) contain no people, leading to heavily imbalanced count
distributions. Ignoring this imbalance can bias models toward overestimating
dense regions and underperforming in sparse areas. Furthermore, most loss
functions used in density estimation are majorly based on MSE and implicitly
assume Gaussian distributions, which are ill-suited for modeling discrete,
non-negative count data. In this paper, we propose EBC-ZIP, a crowd counting
framework that models the spatial distribution of counts using a Zero-Inflated
Poisson (ZIP) regression formulation. Our approach replaces the traditional
regression loss with the negative log-likelihood of the ZIP distribution,
enabling better handling of zero-heavy distributions while preserving count
accuracy. Built upon the recently proposed Enhanced Block Classification (EBC)
framework, EBC-ZIP inherits EBC's advantages in preserving the discreteness of
targets and ensuring training stability, while further improving performance
through a more principled probabilistic loss. We also evaluate EBC-ZIP with
backbones of varying computational complexity to assess its scalability.
Extensive experiments on four crowd counting benchmarks demonstrate that
EBC-ZIP consistently outperforms EBC and achieves state-of-the-art results.

</details>


### [31] [ToSA: Token Merging with Spatial Awareness](https://arxiv.org/abs/2506.20066)
*Hsiang-Wei Huang,Wenhao Chai,Kuang-Ming Chen,Cheng-Yen Yang,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: ToSA是一种结合语义和空间信息的新颖令牌合并方法，通过深度图像生成伪空间令牌，优化视觉Transformer的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有令牌合并方法主要依赖视觉令牌的特征相似性，忽略了空间信息在早期层中的潜力。

Method: 提出ToSA，利用深度图像生成伪空间令牌，结合语义和空间信息指导令牌合并。

Result: ToSA在多个视觉和具身问答基准上优于现有方法，同时显著减少ViT运行时间。

Conclusion: ToSA是一种高效的ViT加速解决方案，代码将开源。

Abstract: Token merging has emerged as an effective strategy to accelerate Vision
Transformers (ViT) by reducing computational costs. However, existing methods
primarily rely on the visual token's feature similarity for token merging,
overlooking the potential of integrating spatial information, which can serve
as a reliable criterion for token merging in the early layers of ViT, where the
visual tokens only possess weak visual information. In this paper, we propose
ToSA, a novel token merging method that combines both semantic and spatial
awareness to guide the token merging process. ToSA leverages the depth image as
input to generate pseudo spatial tokens, which serve as auxiliary spatial
information for the visual token merging process. With the introduced spatial
awareness, ToSA achieves a more informed merging strategy that better preserves
critical scene structure. Experimental results demonstrate that ToSA
outperforms previous token merging methods across multiple benchmarks on visual
and embodied question answering while largely reducing the runtime of the ViT,
making it an efficient solution for ViT acceleration. The code will be
available at: https://github.com/hsiangwei0903/ToSA

</details>


### [32] [BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos](https://arxiv.org/abs/2506.20103)
*Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文提出BrokenVideos数据集，用于AI生成视频中视觉伪影的像素级定位，填补了现有基准的空白。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成视频存在视觉伪影问题，但缺乏针对伪影定位的全面基准数据集。

Method: 构建BrokenVideos数据集，包含3,254个AI生成视频，标注像素级伪影区域，并通过人工验证。

Result: 实验表明，基于BrokenVideos训练的模型能显著提升伪影定位能力。

Conclusion: BrokenVideos为生成视频模型的伪影定位研究提供了关键基准。

Abstract: Recent advances in deep generative models have led to significant progress in
video generation, yet the fidelity of AI-generated videos remains limited.
Synthesized content often exhibits visual artifacts such as temporally
inconsistent motion, physically implausible trajectories, unnatural object
deformations, and local blurring that undermine realism and user trust.
Accurate detection and spatial localization of these artifacts are crucial for
both automated quality control and for guiding the development of improved
generative models. However, the research community currently lacks a
comprehensive benchmark specifically designed for artifact localization in AI
generated videos. Existing datasets either restrict themselves to video or
frame level detection or lack the fine-grained spatial annotations necessary
for evaluating localization methods. To address this gap, we introduce
BrokenVideos, a benchmark dataset of 3,254 AI-generated videos with
meticulously annotated, pixel-level masks highlighting regions of visual
corruption. Each annotation is validated through detailed human inspection to
ensure high quality ground truth. Our experiments show that training state of
the art artifact detection models and multi modal large language models (MLLMs)
on BrokenVideos significantly improves their ability to localize corrupted
regions. Through extensive evaluation, we demonstrate that BrokenVideos
establishes a critical foundation for benchmarking and advancing research on
artifact localization in generative video models. The dataset is available at:
https://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.

</details>


### [33] [From 2D to 3D Cognition: A Brief Survey of General World Models](https://arxiv.org/abs/2506.20134)
*Ningwei Xie,Zizi Tian,Lei Yang,Xiao-Ping Zhang,Meng Guo,Jie Li*

Main category: cs.CV

TL;DR: 该论文综述了从2D感知到3D认知的世界模型发展，重点分析了3D表示和世界知识整合的技术驱动，并探讨了3D世界建模的核心能力及其实际应用。


<details>
  <summary>Details</summary>
Motivation: 当前3D认知世界模型领域缺乏系统性分析，需要明确新兴技术的分类及其在推动3D认知中的作用。

Method: 提出概念框架，系统回顾从2D感知到3D认知的过渡，分析3D表示和世界知识整合的技术驱动，并剖析3D世界建模的三大核心能力。

Result: 总结了3D世界模型在物理场景生成、空间推理和交互方面的能力，并探讨了其在具体应用中的部署。

Conclusion: 指出了数据、建模和部署中的挑战，并提出了未来发展方向，以推动更鲁棒和通用的3D世界模型。

Abstract: World models have garnered increasing attention in the development of
artificial general intelligence (AGI), serving as computational frameworks for
learning representations of the external world and forecasting future states.
While early efforts focused on 2D visual perception and simulation, recent
3D-aware generative world models have demonstrated the ability to synthesize
geometrically consistent, interactive 3D environments, marking a shift toward
3D spatial cognition. Despite rapid progress, the field lacks systematic
analysis to categorize emerging techniques and clarify their roles in advancing
3D cognitive world models. This survey addresses this need by introducing a
conceptual framework, providing a structured and forward-looking review of
world models transitioning from 2D perception to 3D cognition. Within this
framework, we highlight two key technological drivers, particularly advances in
3D representations and the incorporation of world knowledge, as fundamental
pillars. Building on these, we dissect three core cognitive capabilities that
underpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning,
and 3D spatial interaction. We further examine the deployment of these
capabilities in real-world applications, including embodied AI, autonomous
driving, digital twin, and gaming/VR. Finally, we identify challenges across
data, modeling, and deployment, and outline future directions for advancing
more robust and generalizable 3D world models.

</details>


### [34] [EAR: Erasing Concepts from Unified Autoregressive Models](https://arxiv.org/abs/2506.20151)
*Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为EAR的微调方法，用于在自回归模型中实现有效且保留生成质量的概念擦除，并引入了WGA和TLM策略以及新的评估基准ECGVF。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在视觉理解和图像生成任务中表现优异，但如何在保持生成质量的同时去除不想要的概念仍是一个挑战。

Method: 提出了EAR方法，结合WGA策略和TLM策略，并设计了ECGVF基准用于评估。

Result: 实验表明，EAR在概念擦除效果和模型效用保留方面均有显著提升。

Conclusion: EAR方法在自回归模型中实现了高效的概念擦除，同时保持了生成质量。

Abstract: Autoregressive (AR) models have achieved unified and strong performance
across both visual understanding and image generation tasks. However, removing
undesired concepts from AR models while maintaining overall generation quality
remains an open challenge. In this paper, we propose Erasure Autoregressive
Model (EAR), a fine-tuning method for effective and utility-preserving concept
erasure in AR models. Specifically, we introduce Windowed Gradient Accumulation
(WGA) strategy to align patch-level decoding with erasure objectives, and
Thresholded Loss Masking (TLM) strategy to protect content unrelated to the
target concept during fine-tuning. Furthermore, we propose a novel benchmark,
Erase Concept Generator and Visual Filter (ECGVF), aim at provide a more
rigorous and comprehensive foundation for evaluating concept erasure in AR
models. Specifically, we first employ structured templates across diverse large
language models (LLMs) to pre-generate a large-scale corpus of
target-replacement concept prompt pairs. Subsequently, we generate images from
these prompts and subject them to rigorous filtering via a visual classifier to
ensure concept fidelity and alignment. Extensive experimental results conducted
on the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR
achieves marked improvements in both erasure effectiveness and model utility
preservation. Code is available at: https://github.com/immc-lab/ear/

</details>


### [35] [Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration](https://arxiv.org/abs/2506.20152)
*Deepak Ghimire,Kilho Lee,Seong-heum Kim*

Main category: cs.CV

TL;DR: 本文提出了一种高效的损失感知自动选择结构化剪枝标准（LAASP）方法，用于压缩和加速深度神经网络。该方法采用边训练边剪枝的策略，自动选择剪枝标准和层，并通过短暂重训练减少精度损失。实验表明，该方法在减少计算量的同时显著提升了模型精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统剪枝方法需要分阶段进行（训练、剪枝、微调）的问题，并减少手动调整剪枝率的工作量，本文提出了一种更高效的剪枝方法。

Method: 提出了一种边训练边剪枝的方法，自动从候选标准中选择剪枝标准和层，并通过网络损失指导选择。每减少一定计算量后短暂重训练以缓解精度下降。

Result: 在CIFAR-10数据集上，ResNet56和ResNet110模型的top-1精度显著提升，同时计算量减少52%。在ImageNet数据集上，ResNet50的计算量减少42%以上，top-5精度仅下降0.33%。

Conclusion: LAASP方法在减少计算量的同时保持了模型精度，适用于资源受限的边缘设备部署。

Abstract: Structured pruning is a well-established technique for compressing neural
networks, making it suitable for deployment in resource-limited edge devices.
This paper presents an efficient Loss-Aware Automatic Selection of Structured
Pruning Criteria (LAASP) for slimming and accelerating deep neural networks.
The majority of pruning methodologies employ a sequential process consisting of
three stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed
pruning technique adopts a pruning-while-training approach that eliminates the
first stage and integrates the second and third stages into a single cycle. The
automatic selection of magnitude or similarity-based filter pruning criteria
from a specified pool of criteria and the specific pruning layer at each
pruning iteration is guided by the network's overall loss on a small subset of
the training data. To mitigate the abrupt accuracy drop due to pruning, the
network is retrained briefly after each reduction of a predefined number of
floating-point operations (FLOPs). The optimal pruning rates for each layer in
the network are automatically determined, eliminating the need for manual
allocation of fixed or variable pruning rates for each layer. Experiments on
the VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets
demonstrate the effectiveness of the proposed method. In particular, the
ResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the
top-1 accuracy compared to state-of-the-art methods while reducing the network
FLOPs by 52\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces
FLOPs by more than 42\% with a negligible 0.33\% drop in top-5 accuracy. The
source code of this paper is publicly available online -
https://github.com/ghimiredhikura/laasp.

</details>


### [36] [Towards Efficient Exemplar Based Image Editing with Multimodal VLMs](https://arxiv.org/abs/2506.20155)
*Avadhoot Jadhav,Ashutosh Srivastava,Abhinav Java,Silky Singh,Tarun Ram Menta,Surgan Jandial,Balaji Krishnamurthy*

Main category: cs.CV

TL;DR: 论文提出了一种基于示例对的图像编辑方法，利用预训练的文本到图像扩散模型和多模态VLMs，无需优化即可实现高效编辑。


<details>
  <summary>Details</summary>
Motivation: 仅通过文本描述难以捕捉所有类型的图像编辑需求，而示例对能更直观地表达模糊的编辑意图。

Method: 利用预训练的文本到图像扩散模型和多模态VLMs，构建端到端的优化免费管道。

Result: 实验表明，该方法在多种编辑类型上优于基线方法，且速度快约4倍。

Conclusion: 该方法为示例驱动的图像编辑提供了一种高效且无需优化的解决方案。

Abstract: Text-to-Image Diffusion models have enabled a wide array of image editing
applications. However, capturing all types of edits through text alone can be
challenging and cumbersome. The ambiguous nature of certain image edits is
better expressed through an exemplar pair, i.e., a pair of images depicting an
image before and after an edit respectively. In this work, we tackle
exemplar-based image editing -- the task of transferring an edit from an
exemplar pair to a content image(s), by leveraging pretrained text-to-image
diffusion models and multimodal VLMs. Even though our end-to-end pipeline is
optimization-free, our experiments demonstrate that it still outperforms
baselines on multiple types of edits while being ~4x faster.

</details>


### [37] [Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2506.20168)
*Zhentao He,Can Zhang,Ziheng Wu,Zhenghao Chen,Yufei Zhan,Yifan Li,Zhao Zhang,Xian Wang,Minghui Qiu*

Main category: cs.CV

TL;DR: 论文提出KIE-HVQA基准评估OCR在退化文档理解中的幻觉问题，并引入GRPO框架以减少幻觉内容。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉退化场景下表现不佳，容易产生幻觉内容，需改进。

Method: 提出KIE-HVQA基准和GRPO框架，结合视觉不确定性和拒绝回答机制。

Result: 7B参数模型在KIE-HVQA上比GPT-4o提升22%的幻觉减少准确率，标准任务无显著下降。

Conclusion: GRPO框架有效减少幻觉，提升模型在退化视觉条件下的鲁棒性。

Abstract: Recent advancements in multimodal large language models have enhanced
document understanding by integrating textual and visual information. However,
existing models exhibit incompleteness within their paradigm in real-world
scenarios, particularly under visual degradation. In such conditions, the
current response paradigm often fails to adequately perceive visual degradation
and ambiguity, leading to overreliance on linguistic priors or misaligned
visual-textual reasoning. This difficulty in recognizing uncertainty frequently
results in the generation of hallucinatory content, especially when a precise
answer is not feasible. To better demonstrate and analyze this phenomenon and
problem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR
hallucination in degraded document understanding. This dataset includes test
samples spanning identity cards and invoices, with simulated real-world
degradations for OCR reliability. This setup allows for evaluating models'
capacity, under degraded input, to distinguish reliable visual information and
answer accordingly, thereby highlighting the challenge of avoiding
hallucination on uncertain data. To achieve vision-faithful reasoning and
thereby avoid the aforementioned issues, we further introduce a GRPO-based
framework featuring a novel reward mechanism. By incorporating a self-awareness
of visual uncertainty and an analysis method that initiates refusal to answer
to increase task difficulty within our supervised fine-tuning and reinforcement
learning framework, we successfully mitigated hallucinations in ambiguous
regions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model
achieves a 22\% absolute improvement in hallucination-free accuracy over GPT-4o
on KIE-HVQA and there is no significant performance drop in standard tasks,
highlighting both effectiveness and robustness.

</details>


### [38] [Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition](https://arxiv.org/abs/2506.20174)
*Man Duc Chuc*

Main category: cs.CV

TL;DR: 研究探讨了结合预训练基础模型提升地球观测任务性能的可行性，发现特征级集成小模型可媲美或超越大模型，且更高效。


<details>
  <summary>Details</summary>
Motivation: 探索利用现有预训练模型而非从头训练大模型，以提升地球观测任务的性能和效率。

Method: 通过GEO-Bench基准测试，评估Prithvi、Hiera和DOFA等模型在11个数据集上的表现，采用特征级集成和知识蒸馏技术。

Result: 特征级集成小模型性能可媲美或超越大模型，同时减少训练时间和计算资源。知识蒸馏能将集成优势转移到更紧凑模型中。

Conclusion: 结合预训练模型和知识蒸馏为地球观测任务提供了高效且实用的解决方案。

Abstract: Foundation models are rapidly transforming Earth Observation data mining by
enabling generalizable and scalable solutions for key tasks such as scene
classification and semantic segmentation. While most efforts in the geospatial
domain have focused on developing large models trained from scratch using
massive Earth Observation datasets, an alternative strategy that remains
underexplored is the reuse and combination of existing pretrained models. In
this study, we investigate whether foundation models pretrained on remote
sensing and general vision datasets can be effectively combined to improve
performance across a diverse set of key Earth Observation tasks. Using the
GEO-Bench benchmark, we evaluate several prominent models, including Prithvi,
Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions,
sensor modalities, and task types. The results show that feature-level
ensembling of smaller pretrained models can match or exceed the performance of
much larger models, while requiring less training time and computational
resources. Moreover, the study highlights the potential of applying knowledge
distillation to transfer the strengths of ensembles into more compact models,
offering a practical path for deploying foundation models in real-world Earth
Observation applications.

</details>


### [39] [Progressive Alignment Degradation Learning for Pansharpening](https://arxiv.org/abs/2506.20179)
*Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu*

Main category: cs.CV

TL;DR: 论文提出了一种新的渐进对齐退化模块（PADM）和HFreqdiff方法，用于改进深度学习全色锐化模型的泛化能力，显著提升了图像的空间清晰度和质量。


<details>
  <summary>Details</summary>
Motivation: 传统Wald协议生成的合成数据无法准确模拟真实世界的退化模式，限制了深度学习全色锐化模型的泛化能力。

Method: 提出PADM模块，通过两个子网络（PAlignNet和PDegradeNet）的相互迭代自适应学习退化过程；引入HFreqdiff方法，结合CFB和BACM模块进行高频细节提取和反向过程学习。

Result: 实验和消融研究表明，该方法在空间清晰度和图像质量上优于现有技术。

Conclusion: PADM和HFreqdiff有效解决了传统方法的局限性，显著提升了全色锐化模型的性能。

Abstract: Deep learning-based pansharpening has been shown to effectively generate
high-resolution multispectral (HRMS) images. To create supervised ground-truth
HRMS images, synthetic data generated using the Wald protocol is commonly
employed. This protocol assumes that networks trained on artificial
low-resolution data will perform equally well on high-resolution data. However,
well-trained models typically exhibit a trade-off in performance between
reduced-resolution and full-resolution datasets. In this paper, we delve into
the Wald protocol and find that its inaccurate approximation of real-world
degradation patterns limits the generalization of deep pansharpening models. To
address this issue, we propose the Progressive Alignment Degradation Module
(PADM), which uses mutual iteration between two sub-networks, PAlignNet and
PDegradeNet, to adaptively learn accurate degradation processes without relying
on predefined operators. Building on this, we introduce HFreqdiff, which embeds
high-frequency details into a diffusion framework and incorporates CFB and BACM
modules for frequency-selective detail extraction and precise reverse process
learning. These innovations enable effective integration of high-resolution
panchromatic and multispectral images, significantly enhancing spatial
sharpness and quality. Experiments and ablation studies demonstrate the
proposed method's superior performance compared to state-of-the-art techniques.

</details>


### [40] [UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.20214)
*Yanzhe Chen,Huasong Zhong,Yan Li,Zhenheng Yang*

Main category: cs.CV

TL;DR: UniCode²提出了一种级联码本框架，用于大规模、语义对齐且稳定的视觉标记化，解决了现有方法在词汇量小或训练不稳定上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于码本的方法要么词汇量小（约16K条目），缺乏细粒度语义，要么盲目扩展导致标记利用率低和训练不稳定。

Method: 通过聚类数百万SigLIP序列嵌入，构建了一个50万条目的码本，采用级联设计：冻结码本锚定嵌入空间，可训练码本细化任务特定语义。

Result: UniCode²在多样化基准测试中表现优异，验证了在不牺牲稳定性、语义或模块性的情况下扩展视觉标记空间的可行性。

Conclusion: UniCode²通过级联码本框架，实现了视觉标记化的大规模、语义对齐和稳定性，为多模态大语言模型提供了高效解决方案。

Abstract: Unified multimodal large language models (MLLMs) have shown promise in
jointly advancing multimodal understanding and generation, with visual
codebooks discretizing images into tokens for autoregressive modeling. Existing
codebook-based methods either rely on small vocabularies (~16K entries) that
lack fine-grained semantics or naively scale up, resulting in low token
utilization and unstable training. We propose UniCode$^2$, a cascaded codebook
framework enabling large-scale, semantically aligned, and stable visual
tokenization. By clustering millions of SigLIP sequence embeddings, we build a
500K-entry codebook that preserves vision-language alignment while expanding
capacity. Stability is ensured via a cascaded design: a frozen codebook anchors
the embedding space, and a trainable codebook refines task-specific semantics.
This decoupling promotes high utilization and robust learning. Moreover, the
alignment of our visual tokens with textual semantics enables seamless
integration with pretrained diffusion decoders, supporting high-quality visual
synthesis with minimal adaptation. UniCode^2 delivers strong performance across
diverse benchmarks, demonstrating the viability of scaling visual token spaces
without sacrificing stability, semantics, or modularity.

</details>


### [41] [Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission](https://arxiv.org/abs/2506.20222)
*Pujing Yang,Guangyi Zhang,Yunlong Cai,Lei Yu,Guanding Yu*

Main category: cs.CV

TL;DR: 提出了一种联合事件和图像（E-I）传输框架，通过贝叶斯建模和信息瓶颈方法消除冗余，优化带宽利用，同时实现实时去模糊。


<details>
  <summary>Details</summary>
Motivation: 混合系统中事件相机和RGB相机传输大量数据存在冗余和带宽挑战，需高效重建和去模糊。

Method: 采用贝叶斯建模和信息瓶颈方法，分离共享和领域特定信息，动态分配传输带宽。

Result: 仿真结果表明，方案在重建质量和去模糊性能上优于传统系统。

Conclusion: 提出的E-I传输框架有效优化带宽利用，提升重建和去模糊性能。

Abstract: Event cameras asynchronously capture pixel-level intensity changes with
extremely low latency. They are increasingly used in conjunction with RGB
cameras for a wide range of vision-related applications. However, a major
challenge in these hybrid systems lies in the transmission of the large volume
of triggered events and RGB images. To address this, we propose a transmission
scheme that retains efficient reconstruction performance of both sources while
accomplishing real-time deblurring in parallel. Conventional RGB cameras and
event cameras typically capture the same scene in different ways, often
resulting in significant redundant information across their outputs. To address
this, we develop a joint event and image (E-I) transmission framework to
eliminate redundancy and thereby optimize channel bandwidth utilization. Our
approach employs Bayesian modeling and the information bottleneck method to
disentangle the shared and domain-specific information within the E-I inputs.
This disentangled information bottleneck framework ensures both the compactness
and informativeness of extracted shared and domain-specific information.
Moreover, it adaptively allocates transmission bandwidth based on scene
dynamics, i.e., more symbols are allocated to events for dynamic details or to
images for static information. Simulation results demonstrate that the proposed
scheme not only achieves superior reconstruction quality compared to
conventional systems but also delivers enhanced deblurring performance.

</details>


### [42] [Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement](https://arxiv.org/abs/2506.20254)
*Kun Yuan,Tingxuan Chen,Shi Li,Joel L. Lavanchy,Christian Heiliger,Ege Özsoy,Yiming Huang,Long Bai,Nassir Navab,Vinkle Srivastav,Hongliang Ren,Nicolas Padoy*

Main category: cs.CV

TL;DR: SPA是一个轻量级框架，通过少量标注和自然语言定义，实现跨机构和跨手术的通用工作流理解。


<details>
  <summary>Details</summary>
Motivation: 手术工作流的复杂性和多样性导致通用模型开发困难，现有基础模型在零样本性能上受限于领域偏移。

Method: SPA利用少样本空间适应、扩散建模和动态测试时适应，实现多模态嵌入对齐和时间一致性。

Result: SPA在少样本手术阶段识别中表现优异，甚至超过全样本模型。

Conclusion: SPA为医院提供了一种快速定制手术阶段识别模型的轻量级解决方案。

Abstract: The complexity and diversity of surgical workflows, driven by heterogeneous
operating room settings, institutional protocols, and anatomical variability,
present a significant challenge in developing generalizable models for
cross-institutional and cross-procedural surgical understanding. While recent
surgical foundation models pretrained on large-scale vision-language data offer
promising transferability, their zero-shot performance remains constrained by
domain shifts, limiting their utility in unseen surgical environments. To
address this, we introduce Surgical Phase Anywhere (SPA), a lightweight
framework for versatile surgical workflow understanding that adapts foundation
models to institutional settings with minimal annotation. SPA leverages
few-shot spatial adaptation to align multi-modal embeddings with
institution-specific surgical scenes and phases. It also ensures temporal
consistency through diffusion modeling, which encodes task-graph priors derived
from institutional procedure protocols. Finally, SPA employs dynamic test-time
adaptation, exploiting the mutual agreement between multi-modal phase
prediction streams to adapt the model to a given test video in a
self-supervised manner, enhancing the reliability under test-time distribution
shifts. SPA is a lightweight adaptation framework, allowing hospitals to
rapidly customize phase recognition models by defining phases in natural
language text, annotating a few images with the phase labels, and providing a
task graph defining phase transitions. The experimental results show that the
SPA framework achieves state-of-the-art performance in few-shot surgical phase
recognition across multiple institutions and procedures, even outperforming
full-shot models with 32-shot labeled data. Code is available at
https://github.com/CAMMA-public/SPA

</details>


### [43] [A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features](https://arxiv.org/abs/2506.20255)
*Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal*

Main category: cs.CV

TL;DR: 提出一种结合离线图像和在线笔画数据的端到端网络，通过早期融合提升手写识别准确率，实验显示优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 手写识别通常仅利用单一模态（图像或笔画轨迹），而结合两者可提供互补信息，提升性能。

Method: 设计一个端到端网络，将离线图像和在线笔画数据在共享潜在空间早期融合，使用视觉标记和轻量级Transformer嵌入数据，并通过可学习查询增强上下文。

Result: 在IAMOn-DB和VNOn-DB数据集上达到最优准确率，比之前方法提升1%。

Conclusion: 早期融合多模态数据能有效提升手写识别性能，且具有更强的书写独立性。

Abstract: We posit that handwriting recognition benefits from complementary cues
carried by the rasterized complex glyph and the pen's trajectory, yet most
systems exploit only one modality. We introduce an end-to-end network that
performs early fusion of offline images and online stroke data within a shared
latent space. A patch encoder converts the grayscale crop into fixed-length
visual tokens, while a lightweight transformer embeds the $(x, y, \text{pen})$
sequence. Learnable latent queries attend jointly to both token streams,
yielding context-enhanced stroke embeddings that are pooled and decoded under a
cross-entropy loss objective. Because integration occurs before any high-level
classification, temporal cues reinforce each other during representation
learning, producing stronger writer independence. Comprehensive experiments on
IAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art
accuracy, exceeding previous bests by up to 1\%. Our study also shows
adaptation of this pipeline with gesturification on the ISI-Air dataset. Our
code can be found here.

</details>


### [44] [Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification](https://arxiv.org/abs/2506.20263)
*Ning Luo,Meiyin Hu,Huan Wan,Yanyan Yang,Zhuohang Jiang,Xin Wei*

Main category: cs.CV

TL;DR: HMDRN提出了一种结合双层次特征重建和掩码增强的少样本细粒度图像分类方法，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在少样本细粒度图像分类中存在空间信息丢失、局部特征错位、层次特征利用不足等问题，HMDRN旨在解决这些局限性。

Method: HMDRN通过双层次特征重建与融合模块及掩码增强的自重建模块，平衡高层语义与中层结构信息，并增强对判别区域的关注。

Result: 在三个细粒度数据集上，HMDRN优于现有方法，并通过消融实验验证了各模块的有效性。

Conclusion: HMDRN通过双层次重建和掩码增强，显著提升了细粒度分类性能，减少了类内差异。

Abstract: Few-shot fine-grained image classification (FS-FGIC) presents a significant
challenge, requiring models to distinguish visually similar subclasses with
limited labeled examples. Existing methods have critical limitations:
metric-based methods lose spatial information and misalign local features,
while reconstruction-based methods fail to utilize hierarchical feature
information and lack mechanisms to focus on discriminative regions. We propose
the Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which
integrates dual-layer feature reconstruction with mask-enhanced feature
processing to improve fine-grained classification. HMDRN incorporates a
dual-layer feature reconstruction and fusion module that leverages
complementary visual information from different network hierarchies. Through
learnable fusion weights, the model balances high-level semantic
representations from the last layer with mid-level structural details from the
penultimate layer. Additionally, we design a spatial binary mask-enhanced
transformer self-reconstruction module that processes query features through
adaptive thresholding while maintaining complete support features, enhancing
focus on discriminative regions while filtering background noise. Extensive
experiments on three challenging fine-grained datasets demonstrate that HMDRN
consistently outperforms state-of-the-art methods across Conv-4 and ResNet-12
backbone architectures. Comprehensive ablation studies validate the
effectiveness of each proposed component, revealing that dual-layer
reconstruction enhances inter-class discrimination while mask-enhanced
transformation reduces intra-class variations. Visualization results provide
evidence of HMDRN's superior feature reconstruction capabilities.

</details>


### [45] [Forensic Study of Paintings Through the Comparison of Fabrics](https://arxiv.org/abs/2506.20272)
*Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的纺织品相似性评估方法，用于艺术品中画布的鉴定与保护。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖线密度图匹配，无法适用于不连续的画布。

Method: 设计并训练了一个Siamese深度学习模型，通过图像对比较特征表示，并提出相似性估计方法。

Result: 在Museo Nacional del Prado的画布上验证了方法的可行性和准确性。

Conclusion: 该方法为艺术品分析提供了新途径。

Abstract: The study of canvas fabrics in works of art is a crucial tool for
authentication, attribution and conservation. Traditional methods are based on
thread density map matching, which cannot be applied when canvases do not come
from contiguous positions on a roll. This paper presents a novel approach based
on deep learning to assess the similarity of textiles. We introduce an
automatic tool that evaluates the similarity between canvases without relying
on thread density maps. A Siamese deep learning model is designed and trained
to compare pairs of images by exploiting the feature representations learned
from the scans. In addition, a similarity estimation method is proposed,
aggregating predictions from multiple pairs of cloth samples to provide a
robust similarity score. Our approach is applied to canvases from the Museo
Nacional del Prado, corroborating the hypothesis that plain weave canvases,
widely used in painting, can be effectively compared even when their thread
densities are similar. The results demonstrate the feasibility and accuracy of
the proposed method, opening new avenues for the analysis of masterpieces.

</details>


### [46] [From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios](https://arxiv.org/abs/2506.20279)
*Changliang Xia,Chengyou Jia,Zhuohang Dang,Minnan Luo*

Main category: cs.CV

TL;DR: 论文提出了DenseWorld基准和DenseDiT方法，用于解决密集预测任务在真实场景中的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有密集预测方法在理想条件下表现良好，但在真实场景中泛化能力有限且数据稀缺。

Method: 提出DenseDiT，利用生成模型的视觉先验，通过参数复用和轻量级分支实现多尺度上下文自适应集成。

Result: 在DenseWorld基准上，现有方法表现不佳，而DenseDiT仅需0.01%的训练数据即取得优越结果。

Conclusion: DenseDiT在真实场景中具有显著实用价值，且资源高效。

Abstract: Dense prediction tasks hold significant importance of computer vision, aiming
to learn pixel-wise annotated label for an input image. Despite advances in
this field, existing methods primarily focus on idealized conditions, with
limited generalization to real-world scenarios and facing the challenging
scarcity of real-world data. To systematically study this problem, we first
introduce DenseWorld, a benchmark spanning a broad set of 25 dense prediction
tasks that correspond to urgent real-world applications, featuring unified
evaluation across tasks. Then, we propose DenseDiT, which maximally exploits
generative models' visual priors to perform diverse real-world dense prediction
tasks through a unified strategy. DenseDiT combines a parameter-reuse mechanism
and two lightweight branches that adaptively integrate multi-scale context,
working with less than 0.1% additional parameters. Evaluations on DenseWorld
reveal significant performance drops in existing general and specialized
baselines, highlighting their limited real-world generalization. In contrast,
DenseDiT achieves superior results using less than 0.01% training data of
baselines, underscoring its practical value for real-world deployment. Our
data, and checkpoints and codes are available at
https://xcltql666.github.io/DenseDiTProj

</details>


### [47] [Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion](https://arxiv.org/abs/2506.20293)
*Kunjing Yang,Libin Zheng,Minru Bai,Ting Lu,Leyuan Fang*

Main category: cs.CV

TL;DR: 提出了一种基于光谱域的未配准高光谱图像（HSI）和多光谱图像（MSI）融合方法，通过轻量级光谱先验学习网络（SPL）和盲稀疏融合（BSF）方法，解决了传统空间变换配准的不足，提高了效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过空间变换配准HSI和MSI，但由于分辨率差异大，效果不佳且耗时。因此，从光谱域解决配准问题成为新的研究方向。

Method: 1. 开发SPL网络提取HSI光谱特征并增强MSI光谱分辨率；2. 通过子空间表示和循环训练策略提高配准HSI的光谱精度；3. 提出BSF方法，利用群稀疏正则化等效促进图像低秩性；4. 使用PAO算法求解BSF模型。

Result: 实验验证了该方法在配准和融合中的有效性，并展示了其在分类性能提升上的优势。

Conclusion: 该方法从光谱域解决配准问题，显著提高了效率和精度，同时避免了传统方法的计算复杂性。

Abstract: The blind fusion of unregistered hyperspectral images (HSIs) and
multispectral images (MSIs) has attracted growing attention recently. To
address the registration challenge, most existing methods employ spatial
transformations on the HSI to achieve alignment with the MSI. However, due to
the substantial differences in spatial resolution of the images, the
performance of these methods is often unsatisfactory. Moreover, the
registration process tends to be time-consuming when dealing with large-sized
images in remote sensing. To address these issues, we propose tackling the
registration problem from the spectral domain. Initially, a lightweight
Spectral Prior Learning (SPL) network is developed to extract spectral features
from the HSI and enhance the spectral resolution of the MSI. Following this,
the obtained image undergoes spatial downsampling to produce the registered
HSI. In this process, subspace representation and cyclic training strategy are
employed to improve spectral accuracy of the registered HSI obtained. Next, we
propose a blind sparse fusion (BSF) method, which utilizes group sparsity
regularization to equivalently promote the low-rankness of the image. This
approach not only circumvents the need for rank estimation, but also reduces
computational complexity. Then, we employ the Proximal Alternating Optimization
(PAO) algorithm to solve the BSF model, and present its convergence analysis.
Finally, extensive numerical experiments on simulated and real datasets are
conducted to verify the effectiveness of our method in registration and fusion.
We also demonstrate its efficacy in enhancing classification performance.

</details>


### [48] [Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations](https://arxiv.org/abs/2506.20294)
*Shunqi Mao,Wei Guo,Chaoyi Zhang,Weidong Cai*

Main category: cs.CV

TL;DR: 提出了一种名为Ctrl-Z Sampling的新采样策略，用于在条件生成中检测和逃离局部最优解，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在条件生成中容易陷入局部最优解，导致全局不一致或条件不匹配。现有方法通过强化指导信号或调整初始噪声分布来缓解，但效果有限。

Method: Ctrl-Z Sampling通过奖励模型识别局部最优解，注入噪声并回退到更早状态以逃离，动态交替前向优化和后向探索。

Result: 实验表明，Ctrl-Z Sampling显著提升了生成质量，仅增加约7.6倍的函数评估次数。

Conclusion: Ctrl-Z Sampling是一种模型无关的方法，可有效提升扩散模型的生成质量。

Abstract: Diffusion models have shown strong performance in conditional generation by
progressively denoising Gaussian noise toward a target data distribution. This
denoising process can be interpreted as a form of hill climbing in a learned
latent space, where the model iteratively refines the sample toward regions of
higher probability. However, diffusion models often converge to local optima
that are locally visually coherent yet globally inconsistent or conditionally
misaligned, due to latent space complexity and suboptimal initialization. Prior
efforts attempted to address this by strengthening guidance signals or
manipulating the initial noise distribution. We introduce Controlled Random
Zigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy designed to detect
and escape such local maxima during conditional generation. The method first
identifies potential local maxima using a reward model. Upon detection, it
injects noise and reverts to a previous, noisier state to escape the current
optimization plateau. The reward model then evaluates candidate trajectories,
accepting only those that offer improvement, while progressively deeper retreat
enables stronger escapes when nearby alternatives fail. This controlled random
zigzag process allows dynamic alternation between forward refinement and
backward exploration, enhancing both alignment and visual quality in the
generated outputs. The proposed Ctrl-Z Sampling is model-agnostic and
compatible with existing diffusion frameworks. Experimental results show that
Ctrl-Z Sampling substantially improves generation quality with only around 7.6X
increase in function evaluations.

</details>


### [49] [TDiR: Transformer based Diffusion for Image Restoration Tasks](https://arxiv.org/abs/2506.20302)
*Abbas Anwar,Mohammad Shullar,Ali Arshad Nasir,Mudassir Masood,Saeed Anwar*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的扩散模型，用于图像恢复任务，在多个质量指标上优于现有深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 解决图像在恶劣环境下捕获时出现的噪声、色偏、模糊和光散射等问题，提升图像质量以支持下游任务。

Method: 开发了一种结合Transformer的扩散模型，用于图像恢复任务，并在公开数据集上评估其性能。

Result: 该模型在图像增强、去噪和去雨任务中表现优于现有方法。

Conclusion: 扩散模型与Transformer结合能有效提升图像质量，扩展其在高保真视觉数据任务中的应用。

Abstract: Images captured in challenging environments often experience various forms of
degradation, including noise, color cast, blur, and light scattering. These
effects significantly reduce image quality, hindering their applicability in
downstream tasks such as object detection, mapping, and classification. Our
transformer-based diffusion model was developed to address image restoration
tasks, aiming to improve the quality of degraded images. This model was
evaluated against existing deep learning methodologies across multiple quality
metrics for underwater image enhancement, denoising, and deraining on publicly
available datasets. Our findings demonstrate that the diffusion model, combined
with transformers, surpasses current methods in performance. The results of our
model highlight the efficacy of diffusion models and transformers in improving
the quality of degraded images, consequently expanding their utility in
downstream tasks that require high-fidelity visual data.

</details>


### [50] [Radiomic fingerprints for knee MR images assessment](https://arxiv.org/abs/2506.20306)
*Yaxi Chen,Simin Ni,Shaheer U. Saeed,Aleksandra Ivanova,Rikin Hargunani,Jie Huang,Chaozong Liu,Yipeng Hu*

Main category: cs.CV

TL;DR: 提出了一种动态构建放射组学特征的框架（指纹），通过深度学习模型为每位患者选择个性化特征，提升了诊断准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有放射组学方法使用固定特征集，无法充分代表个体病理变化，导致性能受限。本文旨在通过个性化特征选择提升泛化能力和可解释性。

Method: 提出放射组学指纹框架，动态为每位患者选择特征，结合低维逻辑回归进行分类。

Result: 在多种膝关节诊断任务中表现优于或媲美端到端深度学习模型，同时保持了可解释性。

Conclusion: 个性化放射组学特征选择不仅能提升诊断性能，还能提供临床洞见和潜在生物标志物发现。

Abstract: Accurate interpretation of knee MRI scans relies on expert clinical judgment,
often with high variability and limited scalability. Existing radiomic
approaches use a fixed set of radiomic features (the signature), selected at
the population level and applied uniformly to all patients. While
interpretable, these signatures are often too constrained to represent
individual pathological variations. As a result, conventional radiomic-based
approaches are found to be limited in performance, compared with recent
end-to-end deep learning (DL) alternatives without using interpretable radiomic
features. We argue that the individual-agnostic nature in current radiomic
selection is not central to its intepretability, but is responsible for the
poor generalization in our application. Here, we propose a novel radiomic
fingerprint framework, in which a radiomic feature set (the fingerprint) is
dynamically constructed for each patient, selected by a DL model. Unlike the
existing radiomic signatures, our fingerprints are derived on a per-patient
basis by predicting the feature relevance in a large radiomic feature pool, and
selecting only those that are predictive of clinical conditions for individual
patients. The radiomic-selecting model is trained simultaneously with a
low-dimensional (considered relatively explainable) logistic regression for
downstream classification. We validate our methods across multiple diagnostic
tasks including general knee abnormalities, anterior cruciate ligament (ACL)
tears, and meniscus tears, demonstrating comparable or superior diagnostic
accuracy relative to state-of-the-art end-to-end DL models. More importantly,
we show that the interpretability inherent in our approach facilitates
meaningful clinical insights and potential biomarker discovery, with detailed
discussion, quantitative and qualitative analysis of real-world clinical cases
to evidence these advantages.

</details>


### [51] [On the Burstiness of Faces in Set](https://arxiv.org/abs/2506.20312)
*Jiong Wang*

Main category: cs.CV

TL;DR: 论文研究了集合人脸识别中的突发性现象，提出检测和抑制突发性人脸的方法，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 突发性现象在集合人脸识别中普遍存在，导致训练和评估性能下降，需解决这一问题以提高模型泛化能力。

Method: 提出基于Quickshift++、特征自相似性和广义最大池化的三种策略检测突发性人脸，并在训练和评估阶段调整采样比例或贡献。

Result: 实验证明突发性现象广泛存在，抑制突发性显著提升了识别性能。

Conclusion: 通过检测和抑制突发性人脸，有效提升了集合人脸识别的性能。

Abstract: Burstiness, a phenomenon observed in text and image retrieval, refers to that
particular elements appear more times in a set than a statistically independent
model assumes. We argue that in the context of set-based face recognition
(SFR), burstiness exists widely and degrades the performance in two aspects:
Firstly, the bursty faces, where faces with particular attributes %exist
frequently in a face set, dominate the training instances and dominate the
training face sets and lead to poor generalization ability to unconstrained
scenarios. Secondly, the bursty faces %dominating the evaluation sets interfere
with the similarity comparison in set verification and identification when
evaluation. To detect the bursty faces in a set, we propose three strategies
based on Quickshift++, feature self-similarity, and generalized max-pooling
(GMP). We apply the burst detection results on training and evaluation stages
to enhance the sampling ratios or contributions of the infrequent faces. When
evaluation, we additionally propose the quality-aware GMP that enables
awareness of the face quality and robustness to the low-quality faces for the
original GMP. We give illustrations and extensive experiments on the SFR
benchmarks to demonstrate that burstiness is widespread and suppressing
burstiness considerably improves the recognition performance.

</details>


### [52] [From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents](https://arxiv.org/abs/2506.20326)
*Sergio Torres Aguilar*

Main category: cs.CV

TL;DR: 论文评估了五种目标检测架构在三个历史文档数据集上的表现，发现Transformer模型在结构化布局中表现优异，而CNN-OBB模型在复杂文档中更具优势。


<details>
  <summary>Details</summary>
Motivation: 历史文档布局复杂，自动化处理需要鲁棒的文档布局分析（DLA），因此需要评估不同模型在多样化数据集上的表现。

Method: 比较了两种Transformer模型（Co-DETR、Grounding DINO）和三种YOLO变体（AABB、OBB、YOLO-World）在三个数据集（e-NDP、CATMuS、HORAE）上的性能。

Result: Co-DETR在e-NDP上表现最佳（0.752 mAP），而YOLOv11x-OBB在更复杂的CATMuS和HORAE上显著优于其他模型（0.564和0.568）。

Conclusion: Transformer模型适合结构化布局，而CNN-OBB模型更适合复杂文档；OBB是准确建模历史文档非笛卡尔特性的关键。

Abstract: Robust Document Layout Analysis (DLA) is critical for the automated
processing and understanding of historical documents with complex page
organizations. This paper benchmarks five state-of-the-art object detection
architectures on three annotated datasets representing a spectrum of
codicological complexity: The e-NDP, a corpus of Parisian medieval registers
(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval
and modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated
books of hours (ca.13th-16th centuries). We evaluate two Transformer-based
models (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and
YOLO-World). Our findings reveal significant performance variations dependent
on model architecture, data set characteristics, and bounding box
representation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results
(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on
the more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB
significantly outperforms all other models (0.564 and 0.568, respectively).
This study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)
is not a minor refinement but a fundamental requirement for accurately modeling
the non-Cartesian nature of historical manuscripts. We conclude that a key
trade-off exists between the global context awareness of Transformers, ideal
for structured layouts, and the superior generalization of CNN-OBB models for
visually diverse and complex documents.

</details>


### [53] [Feature Hallucination for Self-supervised Action Recognition](https://arxiv.org/abs/2506.20342)
*Lei Wang,Piotr Koniusz*

Main category: cs.CV

TL;DR: 提出了一种深度翻译动作识别框架，通过联合预测动作概念和辅助特征提升识别精度，并引入两种领域特定描述符（ODF和SDF）以增强特征表示。


<details>
  <summary>Details</summary>
Motivation: 视频中的人类动作理解需要高层次的语义推理和多模态特征的有效整合，而现有方法在特征表示和计算效率上存在不足。

Method: 框架通过幻觉流推断缺失线索，整合对象检测特征（ODF）和显著性检测特征（SDF），并结合多种辅助模态（如光流、骨架数据等），同时采用不确定性建模和鲁棒损失函数。

Result: 在Kinetics-400、Kinetics-600和Something-Something V2等多个基准测试中实现了最先进的性能。

Conclusion: 该框架通过多模态自监督学习有效捕捉细粒度动作动态，展示了其在动作识别任务中的优越性。

Abstract: Understanding human actions in videos requires more than raw pixel analysis;
it relies on high-level semantic reasoning and effective integration of
multimodal features. We propose a deep translational action recognition
framework that enhances recognition accuracy by jointly predicting action
concepts and auxiliary features from RGB video frames. At test time,
hallucination streams infer missing cues, enriching feature representations
without increasing computational overhead. To focus on action-relevant regions
beyond raw pixels, we introduce two novel domain-specific descriptors. Object
Detection Features (ODF) aggregate outputs from multiple object detectors to
capture contextual cues, while Saliency Detection Features (SDF) highlight
spatial and intensity patterns crucial for action recognition. Our framework
seamlessly integrates these descriptors with auxiliary modalities such as
optical flow, Improved Dense Trajectories, skeleton data, and audio cues. It
remains compatible with state-of-the-art architectures, including I3D,
AssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE
V2 and InternVideo2. To handle uncertainty in auxiliary features, we
incorporate aleatoric uncertainty modeling in the hallucination step and
introduce a robust loss function to mitigate feature noise. Our multimodal
self-supervised action recognition framework achieves state-of-the-art
performance on multiple benchmarks, including Kinetics-400, Kinetics-600, and
Something-Something V2, demonstrating its effectiveness in capturing
fine-grained action dynamics.

</details>


### [54] [InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking](https://arxiv.org/abs/2506.20370)
*Abdullah All Tanvir,Xin Zhong*

Main category: cs.CV

TL;DR: 提出了一种基于失真不变特征学习的深度学习框架，用于鲁棒图像零水印技术，保持原图不变并通过特征空间优化学习参考签名。


<details>
  <summary>Details</summary>
Motivation: 解决传统水印技术对图像内容修改的依赖问题，同时提高对多种失真的鲁棒性。

Method: 框架包含两个模块：1）通过噪声对抗学习训练特征提取器，生成对失真不变且语义丰富的特征；2）设计基于学习的多比特零水印方案，将特征投影到可训练的参考码上以匹配目标二进制消息。

Result: 在多种图像数据集和失真条件下，方法在特征稳定性和水印恢复方面达到最先进的鲁棒性。

Conclusion: 该框架在泛化能力和鲁棒性上优于现有自监督和深度水印技术。

Abstract: This paper introduces a novel deep learning framework for robust image
zero-watermarking based on distortion-invariant feature learning. As a
zero-watermarking scheme, our method leaves the original image unaltered and
learns a reference signature through optimization in the feature space. The
proposed framework consists of two key modules. In the first module, a feature
extractor is trained via noise-adversarial learning to generate representations
that are both invariant to distortions and semantically expressive. This is
achieved by combining adversarial supervision against a distortion
discriminator and a reconstruction constraint to retain image content. In the
second module, we design a learning-based multibit zero-watermarking scheme
where the trained invariant features are projected onto a set of trainable
reference codes optimized to match a target binary message. Extensive
experiments on diverse image datasets and a wide range of distortions show that
our method achieves state-of-the-art robustness in both feature stability and
watermark recovery. Comparative evaluations against existing self-supervised
and deep watermarking techniques further highlight the superiority of our
framework in generalization and robustness.

</details>


### [55] [Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking](https://arxiv.org/abs/2506.20381)
*Ben Kang,Xin Chen,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: HiT和DyHiT是高效的视觉跟踪模型，通过Bridge Module和动态路由技术，在保持高性能的同时提升速度，适用于资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 解决基于Transformer的视觉跟踪器在资源受限设备上速度慢的问题。

Method: HiT采用Bridge Module和双图像位置编码；DyHiT通过动态路由分类场景并选择计算路径。

Result: HiT在NVIDIA Jetson AGX上达61 fps，AUC 64.6%；DyHiT达111 fps，AUC 62.4%。

Conclusion: HiT和DyHiT在速度和性能上取得平衡，动态路由方法还能加速其他高性能跟踪器。

Abstract: Transformer-based visual trackers have demonstrated significant advancements
due to their powerful modeling capabilities. However, their practicality is
limited on resource-constrained devices because of their slow processing
speeds. To address this challenge, we present HiT, a novel family of efficient
tracking models that achieve high performance while maintaining fast operation
across various devices. The core innovation of HiT lies in its Bridge Module,
which connects lightweight transformers to the tracking framework, enhancing
feature representation quality. Additionally, we introduce a dual-image
position encoding approach to effectively encode spatial information. HiT
achieves an impressive speed of 61 frames per second (fps) on the NVIDIA Jetson
AGX platform, alongside a competitive AUC of 64.6% on the LaSOT benchmark,
outperforming all previous efficient trackers.Building on HiT, we propose
DyHiT, an efficient dynamic tracker that flexibly adapts to scene complexity by
selecting routes with varying computational requirements. DyHiT uses search
area features extracted by the backbone network and inputs them into an
efficient dynamic router to classify tracking scenarios. Based on the
classification, DyHiT applies a divide-and-conquer strategy, selecting
appropriate routes to achieve a superior trade-off between accuracy and speed.
The fastest version of DyHiT achieves 111 fps on NVIDIA Jetson AGX while
maintaining an AUC of 62.4% on LaSOT.Furthermore, we introduce a training-free
acceleration method based on the dynamic routing architecture of DyHiT. This
method significantly improves the execution speed of various high-performance
trackers without sacrificing accuracy. For instance, our acceleration method
enables the state-of-the-art tracker SeqTrack-B256 to achieve a 2.68 times
speedup on an NVIDIA GeForce RTX 2080 Ti GPU while maintaining the same AUC of
69.9% on the LaSOT.

</details>


### [56] [A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management](https://arxiv.org/abs/2506.20388)
*Shen Tan,Xin Zhang,Liangxiu Han,Huaguo Huang,Han Wang*

Main category: cs.CV

TL;DR: 提出了一种基于大型视觉基础模型（LVFM）的新方法，用于高分辨率冠层高度图（CHM）生成，以低成本准确监测人工林地上生物量（AGB）。


<details>
  <summary>Details</summary>
Motivation: 传统激光雷达方法成本高，而基于RGB图像的深度学习方法难以准确提取冠层高度特征，因此需要一种更高效、低成本的方法。

Method: 开发了一种结合特征提取器、自监督特征增强模块和高度估计器的新模型，使用1米分辨率的Google Earth图像进行测试。

Result: 模型在北京市房山区的测试中表现优于现有方法，平均绝对误差为0.09米，均方根误差为0.24米，与激光雷达CHM的相关系数为0.78。

Conclusion: 该方法为评估碳汇提供了可扩展的工具，适用于人工林和天然林。

Abstract: Accurate, cost-effective monitoring of plantation aboveground biomass (AGB)
is crucial for supporting local livelihoods and carbon sequestration
initiatives like the China Certified Emission Reduction (CCER) program.
High-resolution canopy height maps (CHMs) are essential for this, but standard
lidar-based methods are expensive. While deep learning with RGB imagery offers
an alternative, accurately extracting canopy height features remains
challenging. To address this, we developed a novel model for high-resolution
CHM generation using a Large Vision Foundation Model (LVFM). Our model
integrates a feature extractor, a self-supervised feature enhancement module to
preserve spatial details, and a height estimator. Tested in Beijing's Fangshan
District using 1-meter Google Earth imagery, our model outperformed existing
methods, including conventional CNNs. It achieved a mean absolute error of 0.09
m, a root mean square error of 0.24 m, and a correlation of 0.78 against
lidar-based CHMs. The resulting CHMs enabled over 90% success in individual
tree detection, high accuracy in AGB estimation, and effective tracking of
plantation growth, demonstrating strong generalization to non-training areas.
This approach presents a promising, scalable tool for evaluating carbon
sequestration in both plantations and natural forests.

</details>


### [57] [Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation](https://arxiv.org/abs/2506.20449)
*Changlu Guo,Anders Nymark Christensen,Morten Rieger Hannemose*

Main category: cs.CV

TL;DR: Med-Art是一个针对有限数据医学图像生成的框架，利用视觉语言模型生成医学图像的视觉描述，并通过改进的扩散模型实现高性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像生成面临数据集小和医学文本数据稀缺的挑战，需要一种适应有限数据的解决方案。

Method: Med-Art结合视觉语言模型和预训练的PixArt-α扩散模型，提出混合级扩散微调（HLDF）方法，解决颜色过饱和等问题。

Result: 在两个医学图像数据集上，Med-Art在FID、KID和下游分类性能上达到最先进水平。

Conclusion: Med-Art为有限数据下的医学图像生成提供了高效解决方案，具有实际应用潜力。

Abstract: Text-to-image generative models have achieved remarkable breakthroughs in
recent years. However, their application in medical image generation still
faces significant challenges, including small dataset sizes, and scarcity of
medical textual data. To address these challenges, we propose Med-Art, a
framework specifically designed for medical image generation with limited data.
Med-Art leverages vision-language models to generate visual descriptions of
medical images which overcomes the scarcity of applicable medical textual data.
Med-Art adapts a large-scale pre-trained text-to-image model, PixArt-$\alpha$,
based on the Diffusion Transformer (DiT), achieving high performance under
limited data. Furthermore, we propose an innovative Hybrid-Level Diffusion
Fine-tuning (HLDF) method, which enables pixel-level losses, effectively
addressing issues such as overly saturated colors. We achieve state-of-the-art
performance on two medical image datasets, measured by FID, KID, and downstream
classification performance.

</details>


### [58] [Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos](https://arxiv.org/abs/2506.20550)
*Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell*

Main category: cs.CV

TL;DR: 提出了一种简单有效的多帧输入策略，利用时间信息提升YOLO检测器在视频中的性能，同时保持轻量化和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有单帧检测模型忽略视频中的时间信息，而复杂的时间模块增加计算负担。

Method: 堆叠连续帧作为输入，仅监督目标帧输出，保留YOLO架构的轻量化和实时性。

Result: 在MOT20Det和BOAT360数据集上验证，提升了检测鲁棒性，缩小了轻量与重量级网络的差距。

Conclusion: 方法简单高效，适用于实际场景，并贡献了BOAT360数据集支持未来研究。

Abstract: Modern image-based object detection models, such as YOLOv7, primarily process
individual frames independently, thus ignoring valuable temporal context
naturally present in videos. Meanwhile, existing video-based detection methods
often introduce complex temporal modules, significantly increasing model size
and computational complexity. In practical applications such as surveillance
and autonomous driving, transient challenges including motion blur, occlusions,
and abrupt appearance changes can severely degrade single-frame detection
performance. To address these issues, we propose a straightforward yet highly
effective strategy: stacking multiple consecutive frames as input to a
YOLO-based detector while supervising only the output corresponding to a single
target frame. This approach leverages temporal information with minimal
modifications to existing architectures, preserving simplicity, computational
efficiency, and real-time inference capability. Extensive experiments on the
challenging MOT20Det and our BOAT360 datasets demonstrate that our method
improves detection robustness, especially for lightweight models, effectively
narrowing the gap between compact and heavy detection networks. Additionally,
we contribute the BOAT360 benchmark dataset, comprising annotated fisheye video
sequences captured from a boat, to support future research in multi-frame video
object detection in challenging real-world scenarios.

</details>


### [59] [HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling](https://arxiv.org/abs/2506.20452)
*Tobias Vontobel,Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber*

Main category: cs.CV

TL;DR: HiWave是一种无需训练的零样本方法，通过两阶段流程（基础图像生成和基于小波的细节增强模块）显著提升超高分辨率图像合成的视觉保真度和结构一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有零样本生成技术在超高分辨率图像合成中常见的伪影问题（如物体重复和空间不连贯）。

Method: 1. 使用预训练模型生成基础图像；2. 通过DDIM反演和小波域细节增强模块，保留低频结构并增强高频细节。

Result: 在Stable Diffusion XL上的评估显示，HiWave有效减少了伪影，用户研究中80%以上优于现有方法。

Conclusion: HiWave无需重新训练或修改架构，即可实现高质量的超高分辨率图像合成。

Abstract: Diffusion models have emerged as the leading approach for image synthesis,
demonstrating exceptional photorealism and diversity. However, training
diffusion models at high resolutions remains computationally prohibitive, and
existing zero-shot generation techniques for synthesizing images beyond
training resolutions often produce artifacts, including object duplication and
spatial incoherence. In this paper, we introduce HiWave, a training-free,
zero-shot approach that substantially enhances visual fidelity and structural
coherence in ultra-high-resolution image synthesis using pretrained diffusion
models. Our method employs a two-stage pipeline: generating a base image from
the pretrained model followed by a patch-wise DDIM inversion step and a novel
wavelet-based detail enhancer module. Specifically, we first utilize inversion
methods to derive initial noise vectors that preserve global coherence from the
base image. Subsequently, during sampling, our wavelet-domain detail enhancer
retains low-frequency components from the base image to ensure structural
consistency, while selectively guiding high-frequency components to enrich fine
details and textures. Extensive evaluations using Stable Diffusion XL
demonstrate that HiWave effectively mitigates common visual artifacts seen in
prior methods, achieving superior perceptual quality. A user study confirmed
HiWave's performance, where it was preferred over the state-of-the-art
alternative in more than 80% of comparisons, highlighting its effectiveness for
high-quality, ultra-high-resolution image synthesis without requiring
retraining or architectural modifications.

</details>


### [60] [Learning-Based Distance Estimation for 360° Single-Sensor Setups](https://arxiv.org/abs/2506.20586)
*Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell*

Main category: cs.CV

TL;DR: 提出一种基于神经网络的单目360度鱼眼相机距离估计方法，优于传统几何方法。


<details>
  <summary>Details</summary>
Motivation: 解决全向成像中传统几何方法因镜头畸变和环境变化导致的距离估计不准确问题。

Method: 使用神经网络直接从原始全向输入中学习并推断物体距离，无需精确镜头标定。

Result: 在三个360度数据集上验证，学习模型在准确性和鲁棒性上优于传统几何方法和其他学习基线。

Conclusion: 深度学习在全向距离估计中具有潜力，适用于低成本机器人、自主导航和监控应用。

Abstract: Accurate distance estimation is a fundamental challenge in robotic
perception, particularly in omnidirectional imaging, where traditional
geometric methods struggle with lens distortions and environmental variability.
In this work, we propose a neural network-based approach for monocular distance
estimation using a single 360{\deg} fisheye lens camera. Unlike classical
trigonometric techniques that rely on precise lens calibration, our method
directly learns and infers the distance of objects from raw omnidirectional
inputs, offering greater robustness and adaptability across diverse conditions.
We evaluate our approach on three 360{\deg} datasets (LOAF, ULM360, and a newly
captured dataset Boat360), each representing distinct environmental and sensor
setups. Our experimental results demonstrate that the proposed learning-based
model outperforms traditional geometry-based methods and other learning
baselines in both accuracy and robustness. These findings highlight the
potential of deep learning for real-time omnidirectional distance estimation,
making our approach particularly well-suited for low-cost applications in
robotics, autonomous navigation, and surveillance.

</details>


### [61] [A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners](https://arxiv.org/abs/2506.20464)
*Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval*

Main category: cs.CV

TL;DR: 论文提出了一种名为DeepBolt的两阶段深度学习架构，用于在复杂3D点云中自动高效识别岩锚，解决了传统方法在噪声、环境变化和复杂结构下的不足。


<details>
  <summary>Details</summary>
Motivation: 地下矿井中岩锚的频繁评估对维持岩体稳定性和减少风险至关重要，但手动检测因光线不足和耗时性而困难，自动化检测成为必要。

Method: 采用两阶段深度学习架构DeepBolt，专门针对严重类别不平衡问题，优化岩锚在3D点云中的识别。

Result: DeepBolt在岩锚点交并比（IoU）上比现有语义分割模型提升42.5%，分类精度和召回率分别达到96.41%和96.96%。

Conclusion: DeepBolt在复杂地下环境中表现出高效性和鲁棒性，为岩锚自动化检测提供了可靠解决方案。

Abstract: Rock bolts are crucial components of the subterranean support systems in
underground mines that provide adequate structural reinforcement to the rock
mass to prevent unforeseen hazards like rockfalls. This makes frequent
assessments of such bolts critical for maintaining rock mass stability and
minimising risks in underground mining operations. Where manual surveying of
rock bolts is challenging due to the low light conditions in the underground
mines and the time-intensive nature of the process, automated detection of rock
bolts serves as a plausible solution. To that end, this study focuses on the
automatic identification of rock bolts within medium to large-scale 3D point
clouds obtained from underground mines using mobile laser scanners. Existing
techniques for automated rock bolt identification primarily rely on feature
engineering and traditional machine learning approaches. However, such
techniques lack robustness as these point clouds present several challenges due
to data noise, varying environments, and complex surrounding structures.
Moreover, the target rock bolts are extremely small objects within large-scale
point clouds and are often partially obscured due to the application of
reinforcement shotcrete. Addressing these challenges, this paper proposes an
approach termed DeepBolt, which employs a novel two-stage deep learning
architecture specifically designed for handling severe class imbalance for the
automatic and efficient identification of rock bolts in complex 3D point
clouds. The proposed method surpasses state-of-the-art semantic segmentation
models by up to 42.5% in Intersection over Union (IoU) for rock bolt points.
Additionally, it outperforms existing rock bolt identification techniques,
achieving a 96.41% precision and 96.96% recall in classifying rock bolts,
demonstrating its robustness and effectiveness in complex underground
environments.

</details>


### [62] [AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns](https://arxiv.org/abs/2506.20522)
*Chathura Wimalasiri,Piumal Rathnayake,Shamod Wijerathne,Sumudu Rasnayaka,Dhanushka Leuke Bandara,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.CV

TL;DR: 提出了一种基于AI的深度学习框架，用于自动检测和量化牙槽骨流失及其模式，通过结合YOLOv8和Keypoint R-CNN模型实现高精度评估。


<details>
  <summary>Details</summary>
Motivation: 牙周炎严重影响口腔健康和生活质量，准确评估骨流失的严重程度和模式对诊断和治疗计划至关重要。

Method: 结合YOLOv8检测牙齿，Keypoint R-CNN识别解剖标志，YOLOv8x-seg模型分割骨水平和牙齿掩膜，通过几何分析确定骨流失模式。

Result: 在1000张放射线照片上评估，骨流失严重程度检测的组内相关系数达0.80，骨流失模式分类准确率为87%。

Conclusion: 该自动化系统为牙周评估提供了快速、客观且可重复的工具，有望改善早期诊断和个性化治疗计划。

Abstract: Periodontitis, a chronic inflammatory disease causing alveolar bone loss,
significantly affects oral health and quality of life. Accurate assessment of
bone loss severity and pattern is critical for diagnosis and treatment
planning. In this study, we propose a novel AI-based deep learning framework to
automatically detect and quantify alveolar bone loss and its patterns using
intraoral periapical (IOPA) radiographs. Our method combines YOLOv8 for tooth
detection with Keypoint R-CNN models to identify anatomical landmarks, enabling
precise calculation of bone loss severity. Additionally, YOLOv8x-seg models
segment bone levels and tooth masks to determine bone loss patterns (horizontal
vs. angular) via geometric analysis. Evaluated on a large, expertly annotated
dataset of 1000 radiographs, our approach achieved high accuracy in detecting
bone loss severity (intra-class correlation coefficient up to 0.80) and bone
loss pattern classification (accuracy 87%). This automated system offers a
rapid, objective, and reproducible tool for periodontal assessment, reducing
reliance on subjective manual evaluation. By integrating AI into dental
radiographic analysis, our framework has the potential to improve early
diagnosis and personalized treatment planning for periodontitis, ultimately
enhancing patient care and clinical outcomes.

</details>


### [63] [Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks](https://arxiv.org/abs/2506.20548)
*Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: PLADA是一个新型框架，通过处理压缩图像的块效应和利用配对与非配对数据，显著提升了在线社交网络中的深度伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法忽视了压缩引入的块效应，且主要依赖原始图像，难以应对实际场景中的挑战。

Method: PLADA包含两个核心模块：块效应消除器（B2E）和开放数据聚合（ODA），分别处理块效应和利用多种数据。

Result: 在26个数据集上的实验表明，PLADA在深度伪造检测中表现优异，尤其在压缩和有限配对数据情况下优于现有方法。

Conclusion: PLADA不仅提升了检测性能，还首次将块效应作为关键因素引入深度伪造检测，为开放场景提供了鲁棒解决方案。

Abstract: With the rapid advancement of deep learning, particularly through generative
adversarial networks (GANs) and diffusion models (DMs), AI-generated images, or
``deepfakes", have become nearly indistinguishable from real ones. These images
are widely shared across Online Social Networks (OSNs), raising concerns about
their misuse. Existing deepfake detection methods overlook the ``block effects"
introduced by compression in OSNs, which obscure deepfake artifacts, and
primarily focus on raw images, rarely encountered in real-world scenarios. To
address these challenges, we propose PLADA (Pay Less Attention to Deceptive
Artifacts), a novel framework designed to tackle the lack of paired data and
the ineffective use of compressed images. PLADA consists of two core modules:
Block Effect Eraser (B2E), which uses a dual-stage attention mechanism to
handle block effects, and Open Data Aggregation (ODA), which processes both
paired and unpaired data to improve detection. Extensive experiments across 26
datasets demonstrate that PLADA achieves a remarkable balance in deepfake
detection, outperforming SoTA methods in detecting deepfakes on OSNs, even with
limited paired data and compression. More importantly, this work introduces the
``block effect" as a critical factor in deepfake detection, providing a robust
solution for open-world scenarios. Our code is available at
https://github.com/ManyiLee/PLADA.

</details>


### [64] [AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.20563)
*Lei Zhu,Jun Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.CV

TL;DR: 提出了一种对抗性掩码图像建模方法，用于半监督医学图像分割，通过增强监督信号和减少域差距，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: Transformer在医学图像分割中表现优异，但需要大量标注数据，限制了其在半监督学习中的应用。现有方法难以有效利用有限标注数据训练Transformer。

Method: 提出对抗性掩码图像建模方法，通过构建掩码域并利用原始标签和伪标签增强监督信号，同时设计对抗训练损失以减少域差距。

Result: 在三个公开医学图像分割数据集上显著优于现有方法。

Conclusion: 该方法有效解决了半监督学习中Transformer训练不足的问题，提升了分割性能。

Abstract: Vision Transformer has recently gained tremendous popularity in medical image
segmentation task due to its superior capability in capturing long-range
dependencies. However, transformer requires a large amount of labeled data to
be effective, which hinders its applicability in annotation scarce
semi-supervised learning scenario where only limited labeled data is available.
State-of-the-art semi-supervised learning methods propose combinatorial
CNN-Transformer learning to cross teach a transformer with a convolutional
neural network, which achieves promising results. However, it remains a
challenging task to effectively train the transformer with limited labeled
data. In this paper, we propose an adversarial masked image modeling method to
fully unleash the potential of transformer for semi-supervised medical image
segmentation. The key challenge in semi-supervised learning with transformer
lies in the lack of sufficient supervision signal. To this end, we propose to
construct an auxiliary masked domain from original domain with masked image
modeling and train the transformer to predict the entire segmentation mask with
masked inputs to increase supervision signal. We leverage the original labels
from labeled data and pseudo-labels from unlabeled data to learn the masked
domain. To further benefit the original domain from masked domain, we provide a
theoretical analysis of our method from a multi-domain learning perspective and
devise a novel adversarial training loss to reduce the domain gap between the
original and masked domain, which boosts semi-supervised learning performance.
We also extend adversarial masked image modeling to CNN network. Extensive
experiments on three public medical image segmentation datasets demonstrate the
effectiveness of our method, where our method outperforms existing methods
significantly. Our code is publicly available at
https://github.com/zlheui/AdvMIM.

</details>


### [65] [Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization](https://arxiv.org/abs/2506.20567)
*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan*

Main category: cs.CV

TL;DR: 提出了一种基于分割与摘要（DaS）的密集视频字幕框架，通过两阶段LSTM和分层注意力机制生成描述性句子。


<details>
  <summary>Details</summary>
Motivation: 解决未修剪长视频中密集事件描述的挑战，通过分割视频并利用视觉特征辅助句子摘要。

Method: 1. 将视频分割为事件提案，提取视觉特征；2. 使用现有方法生成句子；3. 两阶段LSTM（编码器和解码器）结合分层注意力机制进行摘要。

Result: 在ActivityNet Captions数据集上验证了DaS框架的有效性。

Conclusion: DaS框架通过视觉辅助的句子摘要，显著提升了密集视频字幕生成的性能。

Abstract: In this work, we propose a division-and-summarization (DaS) framework for
dense video captioning. After partitioning each untrimmed long video as
multiple event proposals, where each event proposal consists of a set of short
video segments, we extract visual feature (e.g., C3D feature) from each segment
and use the existing image/video captioning approach to generate one sentence
description for this segment. Considering that the generated sentences contain
rich semantic descriptions about the whole event proposal, we formulate the
dense video captioning task as a visual cue aided sentence summarization
problem and propose a new two stage Long Short Term Memory (LSTM) approach
equipped with a new hierarchical attention mechanism to summarize all generated
sentences as one descriptive sentence with the aid of visual features.
Specifically, the first-stage LSTM network takes all semantic words from the
generated sentences and the visual features from all segments within one event
proposal as the input, and acts as the encoder to effectively summarize both
semantic and visual information related to this event proposal. The
second-stage LSTM network takes the output from the first-stage LSTM network
and the visual features from all video segments within one event proposal as
the input, and acts as the decoder to generate one descriptive sentence for
this event proposal. Our comprehensive experiments on the ActivityNet Captions
dataset demonstrate the effectiveness of our newly proposed DaS framework for
dense video captioning.

</details>


### [66] [Causal Representation Learning with Observational Grouping for CXR Classification](https://arxiv.org/abs/2506.20582)
*Rajat Rasal,Avinash Kori,Ben Glocker*

Main category: cs.CV

TL;DR: 通过分组观测学习可识别的因果表示，提升胸部X光疾病分类的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在医学影像中，识别数据生成过程中的真实因果关系可以提升任务特定潜在特征的泛化性和鲁棒性。

Method: 提出一种端到端框架，通过分组观测学习可识别的因果表示，并在种族、性别和成像视角上强制不变性。

Result: 实验表明，这种因果表示在多个分类任务中提升了泛化性和鲁棒性。

Conclusion: 分组观测学习可识别的因果表示在医学影像分类中具有潜力。

Abstract: Identifiable causal representation learning seeks to uncover the true causal
relationships underlying a data generation process. In medical imaging, this
presents opportunities to improve the generalisability and robustness of
task-specific latent features. This work introduces the concept of grouping
observations to learn identifiable representations for disease classification
in chest X-rays via an end-to-end framework. Our experiments demonstrate that
these causal representations improve generalisability and robustness across
multiple classification tasks when grouping is used to enforce invariance w.r.t
race, sex, and imaging views.

</details>


### [67] [Dense Video Captioning using Graph-based Sentence Summarization](https://arxiv.org/abs/2506.20583)
*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种基于图的分割与总结（GPaS）框架，用于密集视频字幕生成，通过分割事件提案为更短的片段并总结描述信息，解决了现有方法在场景变化时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有密集视频字幕生成方法未充分探索事件提案内的场景演变，导致在场景和对象变化时表现不佳。

Method: 提出GPaS框架，分为分割和总结两阶段。总结阶段通过图卷积网络（GCN）和长短时记忆网络（LSTM）结合，利用语义词关系生成描述。

Result: 在ActivityNet Captions和YouCook II数据集上，方法优于现有技术。

Conclusion: GPaS框架通过细粒度分割和语义关系建模，显著提升了密集视频字幕生成的性能。

Abstract: Recently, dense video captioning has made attractive progress in detecting
and captioning all events in a long untrimmed video. Despite promising results
were achieved, most existing methods do not sufficiently explore the scene
evolution within an event temporal proposal for captioning, and therefore
perform less satisfactorily when the scenes and objects change over a
relatively long proposal. To address this problem, we propose a graph-based
partition-and-summarization (GPaS) framework for dense video captioning within
two stages. For the ``partition" stage, a whole event proposal is split into
short video segments for captioning at a finer level. For the ``summarization"
stage, the generated sentences carrying rich description information for each
segment are summarized into one sentence to describe the whole event. We
particularly focus on the ``summarization" stage, and propose a framework that
effectively exploits the relationship between semantic words for summarization.
We achieve this goal by treating semantic words as nodes in a graph and
learning their interactions by coupling Graph Convolutional Network (GCN) and
Long Short Term Memory (LSTM), with the aid of visual cues. Two schemes of
GCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN
and LSTM. The effectiveness of our approach is demonstrated via an extensive
comparison with the state-of-the-arts methods on the two benchmarks ActivityNet
Captions dataset and YouCook II dataset.

</details>


### [68] [TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness](https://arxiv.org/abs/2506.20588)
*Pritam Mishra,Coloma Ballester,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: 提出了一种自监督视频摘要模型，无需注意力机制或复杂架构，在SUMME和TVSUM数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 视频内容日益普及，但现有方法依赖监督标注或计算昂贵的注意力模型，限制了跨域适用性。

Method: 采用马尔可夫过程驱动的损失指标和两阶段自监督学习范式，避免使用注意力、RNN或Transformer。

Result: 在SUMME和TVSUM数据集上达到最先进性能，优于所有无监督方法，媲美监督模型。

Conclusion: 展示了高效、无需标注的架构潜力，挑战了对复杂架构的依赖，推动了通用视频摘要技术的发展。

Abstract: The increasing ubiquity of video content and the corresponding demand for
efficient access to meaningful information have elevated video summarization
and video highlights as a vital research area. However, many state-of-the-art
methods depend heavily either on supervised annotations or on attention-based
models, which are computationally expensive and brittle in the face of
distribution shifts that hinder cross-domain applicability across datasets. We
introduce a pioneering self-supervised video summarization model that captures
both spatial and temporal dependencies without the overhead of attention, RNNs,
or transformers. Our framework integrates a novel set of Markov process-driven
loss metrics and a two-stage self supervised learning paradigm that ensures
both performance and efficiency. Our approach achieves state-of-the-art
performance on the SUMME and TVSUM datasets, outperforming all existing
unsupervised methods. It also rivals the best supervised models, demonstrating
the potential for efficient, annotation-free architectures. This paves the way
for more generalizable video summarization techniques and challenges the
prevailing reliance on complex architectures.

</details>


### [69] [WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration](https://arxiv.org/abs/2506.20590)
*Chaojun Ni,Jie Li,Haoyun Li,Hengyu Liu,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Boyuan Wang,Chenxin Li,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: WonderFree是一种交互式3D场景生成模型，解决了现有方法在视角探索自由度和渲染质量上的限制，通过WorldRestorer和ConsistView技术提升了新视角质量和跨视角一致性。


<details>
  <summary>Details</summary>
Motivation: 当前3D生成方法在探索自由度和新视角渲染质量上存在限制，特别是在未探索区域的渲染效果较差。

Method: 提出WonderFree模型，包含WorldRestorer（消除新视角的视觉伪影）和ConsistView（确保跨视角一致性）两个关键技术。

Result: 实验表明，WonderFree显著提升了渲染质量和全局一致性，用户偏好率达77.20%。

Conclusion: WonderFree为3D场景生成提供了更自由和沉浸式的探索体验，代码和模型将公开。

Abstract: Interactive 3D scene generation from a single image has gained significant
attention due to its potential to create immersive virtual worlds. However, a
key challenge in current 3D generation methods is the limited explorability,
which cannot render high-quality images during larger maneuvers beyond the
original viewpoint, particularly when attempting to move forward into unseen
areas. To address this challenge, we propose WonderFree, the first model that
enables users to interactively generate 3D worlds with the freedom to explore
from arbitrary angles and directions. Specifically, we decouple this challenge
into two key subproblems: novel view quality, which addresses visual artifacts
and floating issues in novel views, and cross-view consistency, which ensures
spatial consistency across different viewpoints. To enhance rendering quality
in novel views, we introduce WorldRestorer, a data-driven video restoration
model designed to eliminate floaters and artifacts. In addition, a data
collection pipeline is presented to automatically gather training data for
WorldRestorer, ensuring it can handle scenes with varying styles needed for 3D
scene generation. Furthermore, to improve cross-view consistency, we propose
ConsistView, a multi-view joint restoration mechanism that simultaneously
restores multiple perspectives while maintaining spatiotemporal coherence.
Experimental results demonstrate that WonderFree not only enhances rendering
quality across diverse viewpoints but also significantly improves global
coherence and consistency. These improvements are confirmed by CLIP-based
metrics and a user study showing a 77.20% preference for WonderFree over
WonderWorld enabling a seamless and immersive 3D exploration experience. The
code, model, and data will be publicly available.

</details>


### [70] [SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection](https://arxiv.org/abs/2506.20599)
*Ji Qi,Xinchang Zhang,Dingqi Ye,Yongjia Ruan,Xin Guo,Shaowen Wang,Haifeng Li*

Main category: cs.CV

TL;DR: SFNet是一种新型的伪造检测框架，通过结合空间和频域特征来识别多样化的遥感图像伪造内容，显著提升了检测准确率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的快速发展导致伪造遥感图像（RSI）难以检测，可能引发错误情报和虚假信息。现有方法依赖单一视觉特征，难以应对多样化的伪造内容。

Method: SFNet采用两个独立的特征提取器分别捕获空间和频域特征，并通过域特征映射模块和混合域特征细化模块（CBAM注意力）对齐和融合多域特征。

Result: 在三个数据集上的实验表明，SFNet比现有最先进方法的准确率提高了4%-15.18%，并展现出强大的泛化能力。

Conclusion: SFNet通过多域特征融合有效提升了伪造检测的准确性和泛化能力，为遥感图像伪造检测提供了新思路。

Abstract: The rapid advancement of generative artificial intelligence is producing fake
remote sensing imagery (RSI) that is increasingly difficult to detect,
potentially leading to erroneous intelligence, fake news, and even conspiracy
theories. Existing forgery detection methods typically rely on single visual
features to capture predefined artifacts, such as spatial-domain cues to detect
forged objects like roads or buildings in RSI, or frequency-domain features to
identify artifacts from up-sampling operations in adversarial generative
networks (GANs). However, the nature of artifacts can significantly differ
depending on geographic terrain, land cover types, or specific features within
the RSI. Moreover, these complex artifacts evolve as generative models become
more sophisticated. In short, over-reliance on a single visual cue makes
existing forgery detectors struggle to generalize across diverse remote sensing
data. This paper proposed a novel forgery detection framework called SFNet,
designed to identify fake images in diverse remote sensing data by leveraging
spatial and frequency domain features. Specifically, to obtain rich and
comprehensive visual information, SFNet employs two independent feature
extractors to capture spatial and frequency domain features from input RSIs. To
fully utilize the complementary domain features, the domain feature mapping
module and the hybrid domain feature refinement module(CBAM attention) of SFNet
are designed to successively align and fuse the multi-domain features while
suppressing redundant information. Experiments on three datasets show that
SFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art
RS forgery detection methods and exhibits robust generalization capabilities.
The code is available at https://github.com/GeoX-Lab/RSTI/tree/main/SFNet.

</details>


### [71] [Video Perception Models for 3D Scene Synthesis](https://arxiv.org/abs/2506.20601)
*Rui Huang,Guangyao Zhai,Zuria Bauer,Marc Pollefeys,Federico Tombari,Leonidas Guibas,Gao Huang,Francis Engelmann*

Main category: cs.CV

TL;DR: VIPScene利用视频生成模型的3D物理世界常识知识，实现高真实性和结构一致性的3D场景合成。


<details>
  <summary>Details</summary>
Motivation: 传统3D场景合成需专家知识且手动操作繁琐，自动化可广泛应用于建筑设计、机器人仿真等领域。现有方法（如LLMs或图像生成模型）在3D空间推理或多视角一致性上存在局限。

Method: VIPScene结合文本和图像提示，整合视频生成、3D重建和开放词汇感知模型，实现语义和几何分析。引入FPVScore评估连贯性和合理性。

Result: 实验表明VIPScene显著优于现有方法，且能泛化至多样场景。

Conclusion: VIPScene为3D场景合成提供了高真实性和一致性的解决方案，代码将开源。

Abstract: Traditionally, 3D scene synthesis requires expert knowledge and significant
manual effort. Automating this process could greatly benefit fields such as
architectural design, robotics simulation, virtual reality, and gaming. Recent
approaches to 3D scene synthesis often rely on the commonsense reasoning of
large language models (LLMs) or strong visual priors of modern image generation
models. However, current LLMs demonstrate limited 3D spatial reasoning ability,
which restricts their ability to generate realistic and coherent 3D scenes.
Meanwhile, image generation-based methods often suffer from constraints in
viewpoint selection and multi-view inconsistencies. In this work, we present
Video Perception models for 3D Scene synthesis (VIPScene), a novel framework
that exploits the encoded commonsense knowledge of the 3D physical world in
video generation models to ensure coherent scene layouts and consistent object
placements across views. VIPScene accepts both text and image prompts and
seamlessly integrates video generation, feedforward 3D reconstruction, and
open-vocabulary perception models to semantically and geometrically analyze
each object in a scene. This enables flexible scene synthesis with high realism
and structural consistency. For more precise analysis, we further introduce
First-Person View Score (FPVScore) for coherence and plausibility evaluation,
utilizing continuous first-person perspective to capitalize on the reasoning
ability of multimodal large language models. Extensive experiments show that
VIPScene significantly outperforms existing methods and generalizes well across
diverse scenarios. The code will be released.

</details>


### [72] [Shape2Animal: Creative Animal Generation from Natural Silhouettes](https://arxiv.org/abs/2506.20616)
*Quoc-Duy Tran,Anh-Tuan Vo,Dinh-Khoi Vo,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: Shape2Animal框架通过重新解释自然物体轮廓（如云、石头或火焰）为动物形态，模拟人类的pareidolia现象。


<details>
  <summary>Details</summary>
Motivation: 模仿人类在模糊刺激中感知有意义模式的能力，探索视觉创意应用。

Method: 使用开放词汇分割提取物体轮廓，结合视觉语言模型生成动物概念，利用文本到图像扩散模型合成动物图像并融入原场景。

Result: 在多样化真实输入上验证了框架的鲁棒性和创意潜力。

Conclusion: Shape2Animal为视觉叙事、教育内容、数字艺术和交互媒体设计提供了新机会。

Abstract: Humans possess a unique ability to perceive meaningful patterns in ambiguous
stimuli, a cognitive phenomenon known as pareidolia. This paper introduces
Shape2Animal framework to mimics this imaginative capacity by reinterpreting
natural object silhouettes, such as clouds, stones, or flames, as plausible
animal forms. Our automated framework first performs open-vocabulary
segmentation to extract object silhouette and interprets semantically
appropriate animal concepts using vision-language models. It then synthesizes
an animal image that conforms to the input shape, leveraging text-to-image
diffusion model and seamlessly blends it into the original scene to generate
visually coherent and spatially consistent compositions. We evaluated
Shape2Animal on a diverse set of real-world inputs, demonstrating its
robustness and creative potential. Our Shape2Animal can offer new opportunities
for visual storytelling, educational content, digital art, and interactive
media design. Our project page is here: https://shape2image.github.io

</details>


### [73] [Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects](https://arxiv.org/abs/2506.20638)
*Clément Forray,Pauline Delporte,Nicolas Delaygue,Florence Genin,Dawa Derksen*

Main category: cs.CV

TL;DR: 利用NeRF技术从模拟图像中重建非合作空间物体的3D模型，重点优化相机姿态，实验表明逐帧训练效果最佳。


<details>
  <summary>Details</summary>
Motivation: 提升对地球轨道物体的状态和行为的了解，支持空间态势感知（SSA）应用，如碎片清除和异常检测。

Method: 采用NeRF进行3D重建，联合优化相机姿态，通过正则化限制姿态变化范围。

Result: 实验显示逐帧训练能实现最准确的3D重建。

Conclusion: NeRF结合相机姿态优化在空间物体3D重建中具有潜力，尤其在受限条件下。

Abstract: Obtaining a better knowledge of the current state and behavior of objects
orbiting Earth has proven to be essential for a range of applications such as
active debris removal, in-orbit maintenance, or anomaly detection. 3D models
represent a valuable source of information in the field of Space Situational
Awareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to
perform 3D reconstruction of non-cooperative space objects from simulated
images. This scenario is challenging for NeRF models due to unusual camera
characteristics and environmental conditions : mono-chromatic images, unknown
object orientation, limited viewing angles, absence of diffuse lighting etc. In
this work we focus primarly on the joint optimization of camera poses alongside
the NeRF. Our experimental results show that the most accurate 3D
reconstruction is achieved when training with successive images one-by-one. We
estimate camera poses by optimizing an uniform rotation and use regularization
to prevent successive poses from being too far apart.

</details>


### [74] [Disentangled representations of microscopy images](https://arxiv.org/abs/2506.20649)
*Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone*

Main category: cs.CV

TL;DR: 提出了一种解耦表示学习方法（DRL），用于提高显微镜图像分类模型的可解释性，并在三个不同领域的显微镜图像数据集上验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 显微镜图像分析在诊断、合成工程和环境监测等领域至关重要，但深度学习模型的可解释性仍是一个挑战。

Method: 采用解耦表示学习方法（DRL），通过从合成数据中学习表示并迁移到真实数据，以提高模型的可解释性。

Result: 在浮游生物、酵母液泡和人类细胞三个显微镜图像数据集上，DRL框架在准确性和可解释性之间取得了良好平衡。

Conclusion: DRL方法为显微镜图像分类提供了一种兼具高准确性和可解释性的解决方案。

Abstract: Microscopy image analysis is fundamental for different applications, from
diagnosis to synthetic engineering and environmental monitoring. Modern
acquisition systems have granted the possibility to acquire an escalating
amount of images, requiring a consequent development of a large collection of
deep learning-based automatic image analysis methods. Although deep neural
networks have demonstrated great performance in this field, interpretability,
an essential requirement for microscopy image analysis, remains an open
challenge.
  This work proposes a Disentangled Representation Learning (DRL) methodology
to enhance model interpretability for microscopy image classification.
Exploiting benchmark datasets from three different microscopic image domains
(plankton, yeast vacuoles, and human cells), we show how a DRL framework, based
on transferring a representation learnt from synthetic data, can provide a good
trade-off between accuracy and interpretability in this domain.

</details>


### [75] [MMSearch-R1: Incentivizing LMMs to Search](https://arxiv.org/abs/2506.20670)
*Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu*

Main category: cs.CV

TL;DR: MMSearch-R1是一个基于强化学习的端到端框架，用于优化大型多模态模型在真实互联网环境中的多轮搜索行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如RAG和提示工程搜索代理）依赖固定流程，导致搜索效率低下或过度搜索，无法满足动态复杂的真实世界信息需求。

Method: 提出MMSearch-R1框架，结合图像和文本搜索工具，通过基于结果的奖励和搜索惩罚机制指导模型决策。训练时使用半自动收集的多模态搜索VQA数据集。

Result: 在知识密集和信息寻求VQA任务中，MMSearch-R1优于同规模RAG基线，并减少30%以上的搜索调用，性能接近更大RAG模型。

Conclusion: MMSearch-R1为多模态搜索研究提供了高效、按需的解决方案，并揭示了关键经验以推动未来研究。

Abstract: Robust deployment of large multimodal models (LMMs) in real-world scenarios
requires access to external knowledge sources, given the complexity and dynamic
nature of real-world information. Existing approaches such as
retrieval-augmented generation (RAG) and prompt engineered search agents rely
on rigid pipelines, often leading to inefficient or excessive search behaviors.
We present MMSearch-R1, the first end-to-end reinforcement learning framework
that enables LMMs to perform on-demand, multi-turn search in real-world
Internet environments. Our framework integrates both image and text search
tools, allowing the model to reason about when and how to invoke them guided by
an outcome-based reward with a search penalty. To support training, We collect
a multimodal search VQA dataset through a semi-automated pipeline that covers
diverse visual and textual knowledge needs and curate a search-balanced subset
with both search-required and search-free samples, which proves essential for
shaping efficient and on-demand search behavior. Extensive experiments on
knowledge-intensive and info-seeking VQA tasks show that our model not only
outperforms RAG-based baselines of the same model size, but also matches the
performance of a larger RAG-based model while reducing search calls by over
30%. We further analyze key empirical findings to offer actionable insights for
advancing research in multimodal search.

</details>


### [76] [IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals](https://arxiv.org/abs/2506.20671)
*Markus Gross,Aya Fahmy,Danit Niwattananan,Dominik Muhle,Rui Song,Daniel Cremers,Henri Meeß*

Main category: cs.CV

TL;DR: IPFormer提出了一种基于视觉的3D全景场景补全方法，通过动态实例提案提升场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在测试时静态查询的局限性，以及视觉模态在全景场景补全中的探索不足。

Method: 利用图像上下文动态初始化实例提案，并通过注意力机制编码和解码优化语义实例-体素关系。

Result: 在PQ$^\dagger$和PQ-All指标上超越现有方法，运行时间减少14倍以上，动态提案带来显著性能提升。

Conclusion: IPFormer通过动态实例提案，为视觉模态的全景场景补全提供了创新解决方案。

Abstract: Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointly
learning scene geometry and semantics, enabling downstream applications such as
navigation in mobile robotics. The recent generalization to Panoptic Scene
Completion (PSC) advances the SSC domain by integrating instance-level
information, thereby enhancing object-level sensitivity in scene understanding.
While PSC was introduced using LiDAR modality, methods based on camera images
remain largely unexplored. Moreover, recent Transformer-based SSC approaches
utilize a fixed set of learned queries to reconstruct objects within the scene
volume. Although these queries are typically updated with image context during
training, they remain static at test time, limiting their ability to
dynamically adapt specifically to the observed scene. To overcome these
limitations, we propose IPFormer, the first approach that leverages
context-adaptive instance proposals at train and test time to address
vision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptively
initializes these queries as panoptic instance proposals derived from image
context and further refines them through attention-based encoding and decoding
to reason about semantic instance-voxel relationships. Experimental results
show that our approach surpasses state-of-the-art methods in overall panoptic
metrics PQ$^\dagger$ and PQ-All, matches performance in individual metrics, and
achieves a runtime reduction exceeding 14$\times$. Furthermore, our ablation
studies reveal that dynamically deriving instance proposals from image context,
as opposed to random initialization, leads to a 3.62% increase in PQ-All and a
remarkable average improvement of 18.65% in combined Thing-metrics. These
results highlight our introduction of context-adaptive instance proposals as a
pioneering effort in addressing vision-based 3D Panoptic Scene Completion.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [77] [RaRa Clipper: A Clipper for Gaussian Splatting Based on Ray Tracer and Rasterizer](https://arxiv.org/abs/2506.20202)
*Da Li,Donggang Jia,Yousef Rajeh,Dominik Engel,Ivan Viola*

Main category: cs.GR

TL;DR: 提出了一种结合光栅化和光线追踪的混合渲染框架，用于高效且高保真地裁剪高斯泼溅数据。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅技术的进步催生了大量基于此表示的数据集，但因其体积特性，精确高效的裁剪仍是一个未解决的挑战。

Method: 采用RaRa策略，先通过光栅化快速识别被裁剪平面相交的高斯，再通过光线追踪计算部分遮挡的衰减权重，以准确估计其对最终图像的贡献。

Result: 在多种数据集上验证了方法的有效性，用户研究表明其在感知质量和定量性能上均表现优异。

Conclusion: 该方法在保持实时渲染性能和高保真度的同时，实现了视觉上更优的裁剪效果。

Abstract: With the advancement of Gaussian Splatting techniques, a growing number of
datasets based on this representation have been developed. However, performing
accurate and efficient clipping for Gaussian Splatting remains a challenging
and unresolved problem, primarily due to the volumetric nature of Gaussian
primitives, which makes hard clipping incapable of precisely localizing their
pixel-level contributions. In this paper, we propose a hybrid rendering
framework that combines rasterization and ray tracing to achieve efficient and
high-fidelity clipping of Gaussian Splatting data. At the core of our method is
the RaRa strategy, which first leverages rasterization to quickly identify
Gaussians intersected by the clipping plane, followed by ray tracing to compute
attenuation weights based on their partial occlusion. These weights are then
used to accurately estimate each Gaussian's contribution to the final image,
enabling smooth and continuous clipping effects. We validate our approach on
diverse datasets, including general Gaussians, hair strand Gaussians, and
multi-layer Gaussians, and conduct user studies to evaluate both perceptual
quality and quantitative performance. Experimental results demonstrate that our
method delivers visually superior results while maintaining real-time rendering
performance and preserving high fidelity in the unclipped regions.

</details>


### [78] [X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis](https://arxiv.org/abs/2506.20267)
*Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger*

Main category: cs.GR

TL;DR: 论文提出了一种可解释的表面视觉变换器（X-SiT），用于基于可解释的皮层特征进行医学图像分析，并在阿尔茨海默病和额颞叶痴呆检测中表现出色。


<details>
  <summary>Details</summary>
Motivation: 3D体积数据的复杂性和难以可视化促使研究者开发更易理解的皮层表面渲染方法，以支持临床决策。

Method: X-SiT结合了原型表面补丁解码器，通过案例推理和空间对应的皮层原型进行分类。

Result: X-SiT在阿尔茨海默病和额颞叶痴呆检测中达到最新水平，并提供与已知疾病模式一致的原型。

Conclusion: X-SiT首次实现了基于可解释特征的神经网络预测，为医学图像分析提供了新的工具。

Abstract: Interpretable models are crucial for supporting clinical decision-making,
driving advances in their development and application for medical images.
However, the nature of 3D volumetric data makes it inherently challenging to
visualize and interpret intricate and complex structures like the cerebral
cortex. Cortical surface renderings, on the other hand, provide a more
accessible and understandable 3D representation of brain anatomy, facilitating
visualization and interactive exploration. Motivated by this advantage and the
widespread use of surface data for studying neurological disorders, we present
the eXplainable Surface Vision Transformer (X-SiT). This is the first
inherently interpretable neural network that offers human-understandable
predictions based on interpretable cortical features. As part of X-SiT, we
introduce a prototypical surface patch decoder for classifying surface patch
embeddings, incorporating case-based reasoning with spatially corresponding
cortical prototypes. The results demonstrate state-of-the-art performance in
detecting Alzheimer's disease and frontotemporal dementia while additionally
providing informative prototypes that align with known disease patterns and
reveal classification errors.

</details>


### [79] [DreamAnywhere: Object-Centric Panoramic 3D Scene Generation](https://arxiv.org/abs/2506.20367)
*Edoardo Alberto Dominici,Jozef Hladky,Floor Verhoeven,Lukas Radl,Thomas Deixelberger,Stefan Ainetter,Philipp Drescher,Stefan Hauswiesner,Arno Coomans,Giacomo Nazzaro,Konstantinos Vardis,Markus Steinberger*

Main category: cs.GR

TL;DR: DreamAnywhere是一个模块化系统，用于快速生成和原型化3D场景，解决了现有方法在视觉保真度、场景理解和多环境适应性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D场景生成方法存在仅面向正面、视觉保真度低、场景理解有限且仅适用于特定环境的问题。

Method: 系统通过合成360度全景图像，分解为背景和对象，通过混合修复构建完整3D表示，并将对象掩码提升为详细3D对象。

Result: 在新型视图合成一致性和图像质量上显著优于现有方法，用户研究显示其技术稳健性和实用性。

Conclusion: DreamAnywhere为低成本电影制作等场景提供了高效的原型设计和编辑工具，具有高度可定制性。

Abstract: Recent advances in text-to-3D scene generation have demonstrated significant
potential to transform content creation across multiple industries. Although
the research community has made impressive progress in addressing the
challenges of this complex task, existing methods often generate environments
that are only front-facing, lack visual fidelity, exhibit limited scene
understanding, and are typically fine-tuned for either indoor or outdoor
settings. In this work, we address these issues and propose DreamAnywhere, a
modular system for the fast generation and prototyping of 3D scenes. Our system
synthesizes a 360{\deg} panoramic image from text, decomposes it into
background and objects, constructs a complete 3D representation through hybrid
inpainting, and lifts object masks to detailed 3D objects that are placed in
the virtual environment. DreamAnywhere supports immersive navigation and
intuitive object-level editing, making it ideal for scene exploration, visual
mock-ups, and rapid prototyping -- all with minimal manual modeling. These
features make our system particularly suitable for low-budget movie production,
enabling quick iteration on scene layout and visual tone without the overhead
of traditional 3D workflows. Our modular pipeline is highly customizable as it
allows components to be replaced independently. Compared to current
state-of-the-art text and image-based 3D scene generation approaches,
DreamAnywhere shows significant improvements in coherence in novel view
synthesis and achieves competitive image quality, demonstrating its
effectiveness across diverse and challenging scenarios. A comprehensive user
study demonstrates a clear preference for our method over existing approaches,
validating both its technical robustness and practical usefulness.

</details>


### [80] [EditP23: 3D Editing via Propagation of Image Prompts to Multi-View](https://arxiv.org/abs/2506.20652)
*Roi Bar-On,Dana Cohen-Bar,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: EditP23是一种无需掩码的3D编辑方法，通过2D图像编辑传播到多视角表示，实现3D一致性编辑。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖文本提示或显式空间掩码，EditP23通过原始视图和用户编辑后的图像对实现直观编辑，简化流程。

Method: 利用预训练多视角扩散模型的潜在空间，通过图像对引导编辑感知流，实现跨视角一致性编辑。

Result: 在多种对象类别和编辑场景中表现出色，保持原始对象结构和外观的高保真度，无需手动掩码。

Conclusion: EditP23提供了一种高效、直观的3D编辑方法，无需优化或掩码，适用于广泛的应用场景。

Abstract: We present EditP23, a method for mask-free 3D editing that propagates 2D
image edits to multi-view representations in a 3D-consistent manner. In
contrast to traditional approaches that rely on text-based prompting or
explicit spatial masks, EditP23 enables intuitive edits by conditioning on a
pair of images: an original view and its user-edited counterpart. These image
prompts are used to guide an edit-aware flow in the latent space of a
pre-trained multi-view diffusion model, allowing the edit to be coherently
propagated across views. Our method operates in a feed-forward manner, without
optimization, and preserves the identity of the original object, in both
structure and appearance. We demonstrate its effectiveness across a range of
object categories and editing scenarios, achieving high fidelity to the source
while requiring no manual masks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [81] [Polynomial-Time Approximation Schemes via Utility Alignment: Unit-Demand Pricing and More](https://arxiv.org/abs/2506.20030)
*Robin Bowers,Marius Garbea,Emmanouil Pountourakis,Samuel Taggart*

Main category: cs.GT

TL;DR: 本文提出了多项式时间近似方案（PTAS），解决了多个NP难随机优化问题，包括定价、分类优化和委托选择问题，并引入“效用对齐”作为关键技术。


<details>
  <summary>Details</summary>
Motivation: 解决机制设计和运筹学中的NP难随机优化问题，提升现有算法的性能。

Method: 提出“效用对齐”概念，通过优化代理效用高的情景来简化算法设计。

Result: 改进了单位需求定价、分类优化和委托选择的近似算法，填补了部分问题的空白。

Conclusion: 效用对齐是一个广泛适用的技术，能够简化复杂优化问题的求解。

Abstract: This paper derives polynomial-time approximation schemes for several NP-hard
stochastic optimization problems from the algorithmic mechanism design and
operations research literatures. The problems we consider involve a principal
or seller optimizing with respect to a subsequent choice by an agent or buyer.
These include posted pricing for a unit-demand buyer with independent values
(Chawla et al., 2007, Cai and Daskalakis, 2011), assortment optimization with
independent utilities (Talluri and van Ryzin, 2004), and delegated choice
(Khodabakhsh et al., 2024). Our results advance the state of the art for each
of these problems. For unit-demand pricing with discrete distributions, our
multiplicative PTAS improves on the additive PTAS of Cai and Daskalakis, and we
additionally give a PTAS for the unbounded regular case, improving on the
latter paper's QPTAS. For assortment optimization, no constant approximation
was previously known. For delegated choice, we improve on both the
$3$-approximation for the case with no outside option and the
super-constant-approximation with an outside option.
  A key technical insight driving our results is an economically meaningful
property we term utility alignment. Informally, a problem is utility aligned
if, at optimality, the principal derives most of their utility from
realizations where the agent's utility is also high. Utility alignment allows
the algorithm designer to focus on maximizing performance on realizations with
high agent utility, which is often an algorithmically simpler task. We prove
utility alignment results for all the problems mentioned above, including
strong results for unit-demand pricing and delegation, as well as a weaker but
very broad guarantee that holds for many other problems under very mild
conditions.

</details>


### [82] [Exact and approximate maximin share allocations in multi-graphs](https://arxiv.org/abs/2506.20317)
*George Christodoulou,Symeon Mastrakoulis*

Main category: cs.GT

TL;DR: 研究在图形估值模型下不可分割物品的最大最小份额（MMS）分配问题，探讨了不同估值类型下的正负结果。


<details>
  <summary>Details</summary>
Motivation: 探索图形估值模型中MMS和PMMS公平分配的可行性和近似解。

Method: 基于图形模型，分析边对应物品、顶点对应代理的分配问题，研究加性、XOS和次加性估值。

Result: 提出了MMS和PMMS公平分配的正负结果，展示了不同估值类型下的近似解。

Conclusion: 图形估值模型为MMS和PMMS公平分配提供了新的研究视角，但结果因估值类型而异。

Abstract: We study the problem of (approximate) maximin share (MMS) allocation of
indivisible items among a set of agents. We focus on the graphical valuation
model, previously studied by Christodolou, Fiat, Koutsoupias, and Sgouritsa
("Fair allocation in graphs", EC 2023), where the input is given by a graph
where edges correspond to items, and vertices correspond to agents. An edge may
have non-zero marginal value only for its incident vertices. We study additive,
XOS and subadditive valuations and we present positive and negative results for
(approximate) MMS fairness, and also for (approximate) pair-wise maximin share
(PMMS) fairness.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [83] [Refining Participatory Design for AAC Users](https://arxiv.org/abs/2506.19995)
*Blade Frisch,Keith Vertanen*

Main category: cs.HC

TL;DR: 探讨如何通过改进参与式设计方法，使高科技辅助沟通系统（AAC）的设计更包容用户需求。


<details>
  <summary>Details</summary>
Motivation: AAC系统设计需用户参与，但现有方法可能不够包容，需改进以提升可访问性。

Method: 提出两阶段设计流程，并根据用户反馈优化其可访问性。

Result: 计划通过用户反馈进一步优化设计流程。

Conclusion: 改进参与式设计方法有望提升AAC系统的用户包容性。

Abstract: Augmentative and alternative communication (AAC) is a field of research and
practice that works with people who have a communication disability. One form
AAC can take is a high-tech tool, such as a software-based communication
system. Like all user interfaces, these systems must be designed and it is
critical to include AAC users in the design process for their systems. A
participatory design approach can include AAC users in the design process, but
modifications may be necessary to make these methods more accessible. We
present a two-part design process we are investigating for improving the
participatory design for high-tech AAC systems. We discuss our plans to refine
the accessibility of this process based on participant feedback.

</details>


### [84] ["I'm Petting the Laptop, Which Has You Inside It": Reflecting on Lived Experiences of Online Friendship](https://arxiv.org/abs/2506.20055)
*Seraphina Yong,Ashlee Milton,Evan Suma Rosenberg,Stevie Chancellor,Svetlana Yarosh*

Main category: cs.HC

TL;DR: 研究探讨了在线友谊的独特挑战与策略，包括现实圈子的污名化、与在线社区的矛盾关系，以及通信技术的反理论重新利用。


<details>
  <summary>Details</summary>
Motivation: 理解在线友谊的动态及其在心理健康和关系维护中的作用，填补平台无关研究的空白。

Method: 对25个长期在线友谊的生活经历访谈进行活动基础分析。

Result: 揭示了在线友谊的独特挑战与策略，并重新定义了在线社交空间中的强弱关系。

Conclusion: 研究为HCI和社交界面设计提供了新视角，强调技术中介关系的时间稳定性，并呼吁对在线朋友作为边缘化群体的关注。

Abstract: Online(-only) friendships have become increasingly common in daily lives
post-COVID despite debates around their mental health benefits and equivalence
to ''real'' relationships. Previous research has reflected a need to understand
how online friends engage beyond individual platforms, and the lack of
platform-agnostic inquiry limits our ability to fully understand the dynamics
of online friendship. We employed an activity-grounded analysis of 25
interviews on lived experiences of close online friendship spanning multiple
years. Our findings present unique challenges and strategies in online
friendships, such as stigma from real-life circles, an ambivalent relationship
with online communities, and counter-theoretical reappropriations of
communication technology. This study contributes to HCI research in online
communities and social interface design by refocusing prior impressions of
strong vs. weak-ties in online social spaces and foregrounding time-stable
interactions in design for relationship maintenance through technology. Our
work also promotes critical reflection on biased perspectives towards
technology-mediated practices and consideration of online friends as an
invisible marginalized community.

</details>


### [85] [Beyond Autocomplete: Designing CopilotLens Towards Transparent and Explainable AI Coding Agents](https://arxiv.org/abs/2506.20062)
*Runlong Ye,Zeling Zhang,Boushra Almazroua,Michael Liut*

Main category: cs.HC

TL;DR: CopilotLens是一个交互式框架，通过透明化AI代码助手的决策过程，提升开发者对代码建议的理解和信任。


<details>
  <summary>Details</summary>
Motivation: 当前AI代码助手缺乏解释性，开发者难以理解其决策逻辑，影响了信任和效率。

Method: CopilotLens作为解释层，通过动态两级界面展示AI的“思考过程”，包括高层计划和代码库上下文。

Result: CopilotLens提供了一个透明化框架，促进开发者对AI建议的深入理解和信任。

Conclusion: CopilotLens为未来代码助手设计提供了新方向，强调推理的清晰性而非速度，优化人机协作。

Abstract: AI-powered code assistants are widely used to generate code completions,
significantly boosting developer productivity. However, these tools typically
present suggestions without explaining their rationale, leaving their
decision-making process inscrutable. This opacity hinders developers' ability
to critically evaluate the output, form accurate mental models, and build
calibrated trust in the system. To address this, we introduce CopilotLens, a
novel interactive framework that reframes code completion from a simple
suggestion into a transparent, explainable event. CopilotLens operates as an
explanation layer that reveals the AI agent's "thought process" through a
dynamic two-level interface, surfacing everything from its reconstructed
high-level plans to the specific codebase context influencing the code. This
paper presents the design and rationale of CopilotLens, offering a concrete
framework for building future agentic code assistants that prioritize clarity
of reasoning over speed of suggestion, thereby fostering deeper comprehension
and more robust human-AI collaboration.

</details>


### [86] [From Conversation to Orchestration: HCI Challenges and Opportunities in Interactive Multi-Agentic Systems](https://arxiv.org/abs/2506.20091)
*Sarah Schömbs,Yan Zhang,Jorge Goncalves,Wafa Johal*

Main category: cs.HC

TL;DR: 论文探讨了多智能体系统的架构和关键特性，从人机交互（HCI）的角度分析了其机会、风险和挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（如AutoGen、OpenAI Swarm）的出现为用户提供了与多个专业AI代理交互的新范式，但HCI领域尚未充分研究其潜在影响。

Method: 通过分析现有工具和框架，识别多智能体系统的核心挑战（如协调和冲突解决），并结合案例提出设计考虑和研究机会。

Result: 研究总结了多智能体系统在人机交互中的主要挑战，并提供了未来研究的指导方向。

Conclusion: 论文为多智能体系统的用户中心设计奠定了基础，并提出了一个以HCI为重点的研究议程。

Abstract: Recent advances in multi-agentic systems (e.g. AutoGen, OpenAI Swarm) allow
users to interact with a group of specialised AI agents rather than a single
general-purpose agent. Despite the promise of this new paradigm, the HCI
community has yet to fully examine the opportunities, risks, and user-centred
challenges it introduces. We contribute to research on multi-agentic systems by
exploring their architectures and key features through a human-centred lens.
While literature and use cases remain limited, we build on existing tools and
frameworks available to developers to identify a set of overarching challenges,
e.g. orchestration and conflict resolution, that can guide future research in
HCI. We illustrate these challenges through examples, offer potential design
considerations, and provide research opportunities to spark interdisciplinary
conversation. Our work lays the groundwork for future exploration and offers a
research agenda focused on user-centred design in multi-agentic systems.

</details>


### [87] [Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype](https://arxiv.org/abs/2506.20156)
*Xuefei Hou,Xizhao Tan*

Main category: cs.HC

TL;DR: 论文提出了一种名为“Insight Recall”的新范式，通过上下文触发的个人过去见解检索来支持自我调节学习（SRL），并开发了原型系统Irec。


<details>
  <summary>Details</summary>
Motivation: 现有数字工具在支持元认知反思方面不足，如Spaced Repetition Systems（SRS）缺乏上下文，Personal Knowledge Management（PKM）工具维护成本高。

Method: 采用Just-in-Time Adaptive Intervention（JITAI）框架，构建动态知识图谱和混合检索引擎，结合LLM进行深度相似性评估，并设计了人机协作的知识图谱构建流程。

Result: 开发了Irec系统，能够及时提供相关见解，并支持用户通过“引导探究”模块与专家LLM进行对话。

Conclusion: 论文提供了增强元认知和自我调节学习的理论框架和系统平台，为下一代智能学习系统设计奠定了基础。

Abstract: The core challenge in learning has shifted from knowledge acquisition to
effective Self-Regulated Learning (SRL): planning, monitoring, and reflecting
on one's learning. Existing digital tools, however, inadequately support
metacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized
review, overlooking the role of context, while Personal Knowledge Management
(PKM) tools require high manual maintenance.
  To address these challenges, this paper introduces "Insight Recall," a novel
paradigm that conceptualizes the context-triggered retrieval of personal past
insights as a metacognitive scaffold to promote SRL. We formalize this paradigm
using the Just-in-Time Adaptive Intervention (JITAI) framework and implement a
prototype system, Irec, to demonstrate its feasibility. At its core, Irec uses
a dynamic knowledge graph of the user's learning history. When a user faces a
new problem, a hybrid retrieval engine recalls relevant personal "insights."
Subsequently, a large language model (LLM) performs a deep similarity
assessment to filter and present the most relevant scaffold in a just-in-time
manner. To reduce cognitive load, Irec features a human-in-the-loop pipeline
for LLM-based knowledge graph construction. We also propose an optional "Guided
Inquiry" module, where users can engage in a Socratic dialogue with an expert
LLM, using the current problem and recalled insights as context. The
contribution of this paper is a solid theoretical framework and a usable system
platform for designing next-generation intelligent learning systems that
enhance metacognition and self-regulation.

</details>


### [88] [User Understanding of Privacy Permissions in Mobile Augmented Reality: Perceptions and Misconceptions](https://arxiv.org/abs/2506.20207)
*Viktorija Paneva,Verena Winterhalter,Franziska Augustinowski,Florian Alt*

Main category: cs.HC

TL;DR: 研究分析了移动AR应用中用户对隐私权限的误解，提出了改进隐私机制的设计建议。


<details>
  <summary>Details</summary>
Motivation: 移动AR应用依赖多种传感器数据，但用户对隐私权限的理解不足，导致隐私风险。

Method: 通过分析现有应用和120名参与者的在线调查，研究用户对权限的理解。

Result: 发现用户对权限与AR功能的关系存在误解，如位置权限与物理距离测量的混淆。

Conclusion: 提出了改进隐私机制的设计建议，如上下文解释和更清晰的权限标签。

Abstract: Mobile Augmented Reality (AR) applications leverage various sensors to
provide immersive user experiences. However, their reliance on diverse data
sources introduces significant privacy challenges. This paper investigates user
perceptions and understanding of privacy permissions in mobile AR apps through
an analysis of existing applications and an online survey of 120 participants.
Findings reveal common misconceptions, including confusion about how
permissions relate to specific AR functionalities (e.g., location and
measurement of physical distances), and misinterpretations of permission labels
(e.g., conflating camera and gallery access). We identify a set of actionable
implications for designing more usable and transparent privacy mechanisms
tailored to mobile AR technologies, including contextual explanations, modular
permission requests, and clearer permission labels. These findings offer
actionable guidance for developers, researchers, and policymakers working to
enhance privacy frameworks in mobile AR.

</details>


### [89] [A Literature Review on Simulation in Conversational Recommender Systems](https://arxiv.org/abs/2506.20291)
*Haoran Zhang,Xin Zhao,Jinze Chen,Junpeng Guo*

Main category: cs.HC

TL;DR: 本文综述了对话推荐系统（CRSs）的研究现状，提出了一个分类框架，分析了模拟方法在解决CRSs挑战中的关键作用，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 对话推荐系统（CRSs）通过多轮对话提供个性化推荐，但其研究面临数据集偏差、模拟方法灵活性不足等挑战。本文旨在系统总结现有研究并提出未来方向。

Method: 通过构建分类框架，将相关文献分为数据集构建、算法设计、系统评估和实证研究四类，并分析模拟方法的应用。

Result: 模拟方法（如基于LLM的方法）在数据生成、算法优化和系统评估中发挥重要作用，但仍存在数据集偏差和语义空间差距等问题。

Conclusion: 模拟方法对CRSs研究具有重要潜力，未来需解决现有挑战并进一步探索其应用。

Abstract: Conversational Recommender Systems (CRSs) have garnered attention as a novel
approach to delivering personalized recommendations through multi-turn
dialogues. This review developed a taxonomy framework to systematically
categorize relevant publications into four groups: dataset construction,
algorithm design, system evaluation, and empirical studies, providing a
comprehensive analysis of simulation methods in CRSs research. Our analysis
reveals that simulation methods play a key role in tackling CRSs' main
challenges. For example, LLM-based simulation methods have been used to create
conversational recommendation data, enhance CRSs algorithms, and evaluate CRSs.
Despite several challenges, such as dataset bias, the limited output
flexibility of LLM-based simulations, and the gap between text semantic space
and behavioral semantics, persist due to the complexity in Human-Computer
Interaction (HCI) of CRSs, simulation methods hold significant potential for
advancing CRS research. This review offers a thorough summary of the current
research landscape in this domain and identifies promising directions for
future inquiry.

</details>


### [90] [The Role of Partisan Culture in Mental Health Language Online](https://arxiv.org/abs/2506.20377)
*Sachin R. Pendse,Ben Rochford,Neha Kumar,Munmun De Choudhury*

Main category: cs.HC

TL;DR: 研究发现，美国共和党和民主党用户在在线心理健康支持社区中表达痛苦的方式受党派文化影响。


<details>
  <summary>Details</summary>
Motivation: 探讨党派文化如何影响在线支持社区中用户表达痛苦的方式。

Method: 通过大规模观察性研究，使用因果推断和自然语言处理技术分析匹配的党派用户数据。

Result: 党派文化确实影响痛苦表达，强调了在设计在线支持平台时需考虑党派文化差异。

Conclusion: 研究强调了在设计在线支持社区平台时考虑党派文化差异的重要性。

Abstract: The impact of culture on how people express distress in online support
communities is increasingly a topic of interest within Computer Supported
Cooperative Work (CSCW) and Human-Computer Interaction (HCI). In the United
States, distinct cultures have emerged from each of the two dominant political
parties, forming a primary lens by which people navigate online and offline
worlds. We examine whether partisan culture may play a role in how U.S.
Republican and Democrat users of online mental health support communities
express distress. We present a large-scale observational study of 2,184,356
posts from 8,916 statistically matched Republican, Democrat, and unaffiliated
online support community members. We utilize methods from causal inference to
statistically match partisan users along covariates that correspond with
demographic attributes and platform use, in order to create comparable cohorts
for analysis. We then leverage methods from natural language processing to
understand how partisan expressions of distress compare between these sets of
closely matched opposing partisans, and between closely matched partisans and
typical support community members. Our data spans January 2013 to December
2022, a period of both rising political polarization and mental health
concerns. We find that partisan culture does play into expressions of distress,
underscoring the importance of considering partisan cultural differences in the
design of online support community platforms.

</details>


### [91] [Analyzing Security and Privacy Challenges in Generative AI Usage Guidelines for Higher Education](https://arxiv.org/abs/2506.20463)
*Bei Yi Ng,Jiarui Li,Xinyuan Tong,Kevin Ye,Gauthami Yenne,Varun Chandrasekaran,Jingjie Li*

Main category: cs.HC

TL;DR: 论文探讨了高等教育中生成式人工智能（GenAI）的隐私与安全问题，分析了多国大学的政策，提出了针对学术环境的保护措施。


<details>
  <summary>Details</summary>
Motivation: 随着GenAI在高等教育中的普及，隐私与安全问题日益突出，需要制定专门的政策以保护用户数据。

Method: 通过定性分析12个国家大学的GenAI使用指南，研究隐私与安全维度的挑战与机遇。

Result: 研究发现，学术机构需定制化的GenAI保护措施，以平衡技术创新与隐私安全。

Conclusion: 高等教育机构应制定专门政策，确保GenAI的隐私与安全，同时兼顾学术价值。

Abstract: Educators and learners worldwide are embracing the rise of Generative
Artificial Intelligence (GenAI) as it reshapes higher education. However, GenAI
also raises significant privacy and security concerns, as models and
privacy-sensitive user data, such as student records, may be misused by service
providers. Unfortunately, end-users often have little awareness of or control
over how these models operate. To address these concerns, universities are
developing institutional policies to guide GenAI use while safeguarding
security and privacy. This work examines these emerging policies and
guidelines, with a particular focus on the often-overlooked privacy and
security dimensions of GenAI integration in higher education, alongside other
academic values. Through a qualitative analysis of GenAI usage guidelines from
universities across 12 countries, we identify key challenges and opportunities
institutions face in providing effective privacy and security protections,
including the need for GenAI safeguards tailored specifically to the academic
context.

</details>


### [92] [AI in the Writing Process: How Purposeful AI Support Fosters Student Writing](https://arxiv.org/abs/2506.20595)
*Momin N. Siddiqui,Roy Pea,Hari Subramonyam*

Main category: cs.HC

TL;DR: 研究表明，集成式AI写作工具比聊天式LLM更能提升学生的写作自主性和知识转化深度。


<details>
  <summary>Details</summary>
Motivation: 探讨AI写作支持工具对学生写作自主性和知识转化深度的影响。

Method: 通过随机对照试验，比较聊天式LLM、集成式AI写作工具和标准写作界面的效果。

Result: 集成式AI写作工具显著提升学生的写作自主性和知识转化深度。

Conclusion: 针对性设计的AI写作支持工具有助于学生保持写作自主性并提升内容参与度。

Abstract: The ubiquity of technologies like ChatGPT has raised concerns about their
impact on student writing, particularly regarding reduced learner agency and
superficial engagement with content. While standalone chat-based LLMs often
produce suboptimal writing outcomes, evidence suggests that purposefully
designed AI writing support tools can enhance the writing process. This paper
investigates how different AI support approaches affect writers' sense of
agency and depth of knowledge transformation. Through a randomized control
trial with 90 undergraduate students, we compare three conditions: (1) a
chat-based LLM writing assistant, (2) an integrated AI writing tool to support
diverse subprocesses, and (3) a standard writing interface (control). Our
findings demonstrate that, among AI-supported conditions, students using the
integrated AI writing tool exhibited greater agency over their writing process
and engaged in deeper knowledge transformation overall. These results suggest
that thoughtfully designed AI writing support targeting specific aspects of the
writing process can help students maintain ownership of their work while
facilitating improved engagement with content.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [93] [Neuromorphic Wireless Split Computing with Resonate-and-Fire Neurons](https://arxiv.org/abs/2506.20015)
*Dengyu Wu,Jiechen Chen,H. Vincent Poor,Bipin Rajendran,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 该论文提出了一种基于共振放电（RF）神经元的无线分体计算架构，用于高效处理具有丰富频谱特征的流式信号，显著降低了计算和传输能耗。


<details>
  <summary>Details</summary>
Motivation: 传统漏电积分放电（LIF）神经元无法有效捕捉流式信号的频谱特征，而无线边缘应用（如无线传感和音频识别）需要高效的实时处理。

Method: 采用具有振荡动态的RF神经元直接处理时域信号，避免昂贵的频谱预处理，并通过可调谐频率提取时间局部化频谱特征。

Result: 实验表明，RF-SNN架构在音频分类和调制分类任务中与传统LIF-SNN和ANN精度相当，但显著降低了脉冲率和总能耗。

Conclusion: RF神经元在无线分体计算中表现出高效能，适用于边缘设备的实时信号处理。

Abstract: Neuromorphic computing offers an energy-efficient alternative to conventional
deep learning accelerators for real-time time-series processing. However, many
edge applications, such as wireless sensing and audio recognition, generate
streaming signals with rich spectral features that are not effectively captured
by conventional leaky integrate-and-fire (LIF) spiking neurons. This paper
investigates a wireless split computing architecture that employs
resonate-and-fire (RF) neurons with oscillatory dynamics to process time-domain
signals directly, eliminating the need for costly spectral pre-processing. By
resonating at tunable frequencies, RF neurons extract time-localized spectral
features while maintaining low spiking activity. This temporal sparsity
translates into significant savings in both computation and transmission
energy. Assuming an OFDM-based analog wireless interface for spike
transmission, we present a complete system design and evaluate its performance
on audio classification and modulation classification tasks. Experimental
results show that the proposed RF-SNN architecture achieves comparable accuracy
to conventional LIF-SNNs and ANNs, while substantially reducing spike rates and
total energy consumption during inference and communication.

</details>


### [94] [Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track](https://arxiv.org/abs/2506.19882)
*Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho*

Main category: cs.LG

TL;DR: 该立场论文主张机器学习会议应设立专门的“反驳与批评”轨道，以促进研究的自我修正。


<details>
  <summary>Details</summary>
Motivation: 机器学习研究快速发展导致错误研究被接受，缺乏系统修正机制。

Method: 提出设立“反驳与批评”轨道，讨论其设计、评审原则及潜在问题。

Result: 通过高声誉平台支持批判性研究，推动研究生态自我修正。

Conclusion: 机器学习会议应建立官方机制以促进研究的自我修正。

Abstract: Science progresses by iteratively advancing and correcting humanity's
understanding of the world. In machine learning (ML) research, rapid
advancements have led to an explosion of publications, but have also led to
misleading, incorrect, flawed or perhaps even fraudulent studies being accepted
and sometimes highlighted at ML conferences due to the fallibility of peer
review. While such mistakes are understandable, ML conferences do not offer
robust processes to help the field systematically correct when such errors are
made.This position paper argues that ML conferences should establish a
dedicated "Refutations and Critiques" (R & C) Track. This R & C Track would
provide a high-profile, reputable platform to support vital research that
critically challenges prior research, thereby fostering a dynamic
self-correcting research ecosystem. We discuss key considerations including
track design, review principles, potential pitfalls, and provide an
illustrative example submission concerning a recent ICLR 2025 Oral. We conclude
that ML conferences should create official, reputable mechanisms to help ML
research self-correct.

</details>


### [95] [STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning](https://arxiv.org/abs/2506.19883)
*Zhuqing Liu,Chaosheng Dong,Michinari Momma,Simone Shao,Shaoyuan Xu,Yan Gao,Haibo Yang,Jia Liu*

Main category: cs.LG

TL;DR: 提出了一种名为STIMULUS的新算法，用于解决多目标优化问题，通过递归框架改进收敛性能和样本复杂度，并进一步提出带动量项的STIMULUS-M和自适应批处理的STIMULUS+/STIMULUS-M+。


<details>
  <summary>Details</summary>
Motivation: 多目标优化（MOO）在机器学习和工程中应用广泛，但现有方法收敛速度和样本复杂度表现不佳，需要改进。

Method: STIMULUS采用递归框架更新随机梯度估计，STIMULUS-M加入动量项，STIMULUS+/STIMULUS-M+引入自适应批处理以减少全梯度评估需求。

Result: 在非凸和强凸设置下分别达到$O(1/T)$和$O(\exp{-\mu T})$的收敛速率，样本复杂度达到当前最优水平。

Conclusion: STIMULUS及其变体在多目标优化中表现出色，显著提升了收敛性能和样本效率。

Abstract: Recently, multi-objective optimization (MOO) has gained attention for its
broad applications in ML, operations research, and engineering. However, MOO
algorithm design remains in its infancy and many existing MOO methods suffer
from unsatisfactory convergence rate and sample complexity performance. To
address this challenge, in this paper, we propose an algorithm called STIMULUS(
stochastic path-integrated multi-gradient recursive e\ulstimator), a new and
robust approach for solving MOO problems. Different from the traditional
methods, STIMULUS introduces a simple yet powerful recursive framework for
updating stochastic gradient estimates to improve convergence performance with
low sample complexity. In addition, we introduce an enhanced version of
STIMULUS, termed STIMULUS-M, which incorporates a momentum term to further
expedite convergence. We establish $O(1/T)$ convergence rates of the proposed
methods for non-convex settings and $O (\exp{-\mu T})$ for strongly convex
settings, where $T$ is the total number of iteration rounds. Additionally, we
achieve the state-of-the-art $O \left(n+\sqrt{n}\epsilon^{-1}\right)$ sample
complexities for non-convex settings and $O\left(n+ \sqrt{n} \ln
({\mu/\epsilon})\right)$ for strongly convex settings, where $\epsilon>0$ is a
desired stationarity error. Moreover, to alleviate the periodic full gradient
evaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced
versions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their
theoretical analysis.

</details>


### [96] [FlightKooba: A Fast Interpretable FTP Model](https://arxiv.org/abs/2506.19885)
*Jing Lu,Xuan Wu,Yizhun Tian,Songhan Fan,Yali Fang*

Main category: cs.LG

TL;DR: 论文提出FlightKooba框架，结合HIPPO方法、Koopman理论和状态空间方程，显著提升飞行轨迹预测的效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前基于Koopman理论的飞行轨迹预测模型效率低、可解释性差且计算量大，亟需改进。

Method: FlightKooba直接通过数据构建Koopman算子，减少可训练参数，降低计算复杂度。

Result: 实验显示FlightKooba在时间和内存消耗上表现优异，训练时间接近Mamba模块，内存减少50%以上，参数数量减少十倍。

Conclusion: FlightKooba为Koopman算子的快速计算提供了新方法，为时间序列预测与控制的结合开辟了新途径。

Abstract: The Koopman theory is a powerful and effective modeling tool for converting
nonlinear systems into linear representations, and flight trajectory prediction
(FTP) is a complex nonlinear system. However, current models applying the
Koopman theory to FTP tasks are not very effective, model interpretability is
indeed an issue, and the Koopman operators are computationally intensive,
resulting in long training times. To address this issue, this paper proposes a
new modeling and control framework based on the HIPPO method, the Koopman
theory, and state space equations from cybernetics: FlightKooba. Inspired by
the idea of structural state space equations, FlightKooba directly constructs
the Koopman operators from data. This makes the framework highly interpretable
and significantly reduces the number of trainable parameters in the module,
thereby greatly reducing training time. Experiments have demonstrated the
superiority of the FlightKooba modeling method in terms of time and memory
consumption (training time comparable to the Mamba module without using
CUDA-level acceleration; memory reduced by more than 50% on most datasets, with
a tenfold reduction in the number of parameters), essentially completing the
FTP task. It provides a new method for the fast computation of the Koopman
operators, opening up new possibilities for the combination of time series
forecasting and control.

</details>


### [97] [Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction](https://arxiv.org/abs/2506.19890)
*Ziru Zhang,Jiadong Yu,Danny H. K. Tsang*

Main category: cs.LG

TL;DR: 论文提出了一种结合自适应关键帧提取和因果感知强化学习的智能框架，以优化多用户VR交互中的QoE。通过新QoE度量和PS-CDDPG算法，显著降低了延迟并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在优化多用户VR交互的QoE时，忽视了带宽、CPU频率与用户感知之间的因果关系，限制了QoE的提升。

Method: 提出PS-CDDPG算法，结合DDPG和因果推理，优化关键帧比率、带宽和计算资源。

Result: 实验表明，该框架显著降低延迟，提升QoE，并保持公平性。

Conclusion: 该框架在多用户VR交互中实现了更优的QoE优化效果。

Abstract: The optimization of quality of experience (QoE) in multi-user virtual reality
(VR) interactions demands a delicate balance between ultra-low latency,
high-fidelity motion synchronization, and equitable resource allocation. While
adaptive keyframe extraction mitigates transmission overhead, existing
approaches often overlook the causal relationships among allocated bandwidth,
CPU frequency, and user perception, limiting QoE gains. This paper proposes an
intelligent framework to maximize QoE by integrating adaptive keyframe
extraction with causal-aware reinforcement learning (RL). First, a novel QoE
metric is formulated using the Weber-Fechner Law, combining perceptual
sensitivity, attention-driven priorities, and motion reconstruction accuracy.
The QoE optimization problem is then modeled as a mixed integer programming
(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational
resources under horizon-fairness constraints. We propose Partial State Causal
Deep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep
Deterministic Policy Gradient (DDPG) method with causal influence detection. By
leveraging causal information regarding how QoE is influenced and determined by
various actions, we explore actions guided by weights calculated from causal
inference (CI), which in turn improves training efficiency. Experiments
conducted with the CMU Motion Capture Database demonstrate that our framework
significantly reduces interactive latency, enhances QoE, and maintains
fairness, achieving superior performance compared to benchmark methods.

</details>


### [98] [Orthogonal Soft Pruning for Efficient Class Unlearning](https://arxiv.org/abs/2506.19891)
*Qinghui Gong,Xue Yang,Xiaohu Tang*

Main category: cs.LG

TL;DR: 提出了一种基于正交卷积核正则化的类感知软剪枝框架，实现快速精准的机器遗忘，满足隐私法规要求。


<details>
  <summary>Details</summary>
Motivation: 现有方法在遗忘速度和预测准确性之间存在权衡，计算开销大或性能下降明显。

Method: 利用正交卷积核正则化，通过激活差异分析识别类特定通道，实现快速遗忘。

Result: 在多架构和数据集上验证了快速执行、完全遗忘目标类、保留数据准确性损失最小。

Conclusion: 该框架为MLaaS场景提供了高效、实时的机器遗忘解决方案。

Abstract: Machine unlearning aims to selectively remove class-specific knowledge from
pretrained neural networks to satisfy privacy regulations such as the GDPR.
Existing methods typically face a trade-off between unlearning speed and
preservation of predictive accuracy, often incurring either high computational
overhead or significant performance degradation on retained classes. In this
paper, we propose a novel class-aware soft pruning framework leveraging
orthogonal convolutional kernel regularization to achieve rapid and precise
forgetting with millisecond-level response times. By enforcing orthogonality
constraints during training, our method decorrelates convolutional filters and
disentangles feature representations, while efficiently identifying
class-specific channels through activation difference analysis. Extensive
evaluations across multiple architectures and datasets demonstrate stable
pruning with near-instant execution, complete forgetting of targeted classes,
and minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100,
and TinyImageNet confirm that our approach substantially reduces membership
inference attack risks and accelerates unlearning by orders of magnitude
compared to state-of-the-art baselines. This framework provides an efficient,
practical solution for real-time machine unlearning in Machine Learning as a
Service (MLaaS) scenarios.

</details>


### [99] [Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks](https://arxiv.org/abs/2506.19893)
*Jingzhi Hu,Geoffrey Ye Li*

Main category: cs.LG

TL;DR: 论文提出DeKA-g算法，通过知识蒸馏和自适应传输优化生成语义通信（GSC）系统，显著提升边缘生成图像与云端生成图像的对齐效率。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容（AIGC）的激增，从云端向边缘和移动用户传输内容导致网络流量剧增。生成语义通信（GSC）通过传输紧凑信息（如提示文本和潜在表示）提供解决方案，但知识对齐问题仍具挑战性。

Method: 提出DeKA-g算法，包含元词辅助知识蒸馏（MAKD）和可变速率分组信噪比适应（VGSA）两种方法，通过低秩矩阵蒸馏云端生成知识并适应无线信道条件。

Result: DeKA-g将边缘与云端生成图像对齐效率提升44%，压缩率适应效率提高116%，低信噪比条件下性能提升28%。

Conclusion: DeKA-g有效解决了GSC系统中的知识对齐问题，显著提升了传输效率和适应性。

Abstract: Due to the surging amount of AI-generated content (AIGC), its provisioning to
edges and mobile users from the cloud incurs substantial traffic on networks.
Generative semantic communication (GSC) offers a promising solution by
transmitting highly compact information, i.e., prompt text and latent
representations, instead of high-dimensional AIGC data. However, GSC relies on
the alignment between the knowledge in the cloud generative AI (GAI) and that
possessed by the edges and users, and between the knowledge for wireless
transmission and that of actual channels, which remains challenging. In this
paper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm
for GSC systems. The core idea is to distill the generation knowledge from the
cloud-GAI into low-rank matrices, which can be incorporated by the edge and
used to adapt the transmission knowledge to diverse wireless channel
conditions. DeKA-g comprises two novel methods: metaword-aided knowledge
distillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD,
an optimized metaword is employed to enhance the efficiency of knowledge
distillation, while VGSA enables efficient adaptation to diverse compression
rates and SNR ranges. From simulation results, DeKA-g improves the alignment
between the edge-generated images and the cloud-generated ones by 44%.
Moreover, it adapts to compression rates with 116% higher efficiency than the
baseline and enhances the performance in low-SNR conditions by 28%.

</details>


### [100] [Explaining deep neural network models for electricity price forecasting with XAI](https://arxiv.org/abs/2506.19894)
*Antoine Pesenti,Aidan OSullivan*

Main category: cs.LG

TL;DR: 使用深度神经网络（DNN）预测电力市场价格，并结合可解释人工智能（XAI）方法（如SHAP和Gradient）分析价格驱动因素，以增强对电力市场的理解。


<details>
  <summary>Details</summary>
Motivation: 电力市场复杂且依赖性强，传统计量经济学方法（白盒模型）预测能力有限，而DNN虽强大但缺乏可解释性。本文旨在结合DNN的预测能力和XAI的可解释性，揭示市场价格动态的驱动因素。

Method: 采用DNN进行价格预测，并应用XAI方法（如SHAP和Gradient）及可视化技术（如热图）分析五个电力市场中各特征的行为和贡献。提出SSHAP值和SSHAP线以增强高维表格模型的复杂表示。

Result: 通过DNN和XAI方法的结合，成功预测了电力市场价格，并揭示了驱动价格动态的关键因素。

Conclusion: 本文展示了DNN与XAI结合在电力市场分析中的潜力，为理解复杂市场机制提供了新工具。

Abstract: Electricity markets are highly complex, involving lots of interactions and
complex dependencies that make it hard to understand the inner workings of the
market and what is driving prices. Econometric methods have been developed for
this, white-box models, however, they are not as powerful as deep neural
network models (DNN). In this paper, we use a DNN to forecast the price and
then use XAI methods to understand the factors driving the price dynamics in
the market. The objective is to increase our understanding of how different
electricity markets work. To do that, we apply explainable methods such as SHAP
and Gradient, combined with visual techniques like heatmaps (saliency maps) to
analyse the behaviour and contributions of various features across five
electricity markets. We introduce the novel concepts of SSHAP values and SSHAP
lines to enhance the complex representation of high-dimensional tabular models.

</details>


### [101] [A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers](https://arxiv.org/abs/2506.19895)
*Miguel N. Font,José L. Jorro-Aragoneses,Carlos M. Alaíz*

Main category: cs.LG

TL;DR: 提出了一种新的后处理框架，通过检索训练案例测量神经网络决策的不确定性，并提出了两种新指标：决策变化和层不确定性。


<details>
  <summary>Details</summary>
Motivation: 神经网络在高风险领域（如医疗诊断或自动驾驶）中可能返回错误决策，因此需要有效的不确定性测量方法以减少错误。

Method: 基于每层与查询激活向量相似的训练案例，提出决策变化和层不确定性两种新指标。

Result: 在CIFAR-10和MNIST数据集上验证，新指标优于基于softmax的置信度方法。

Conclusion: 新框架和指标能有效提升不确定性估计，尤其在复杂分类任务中表现更优。

Abstract: Neural Networks have high accuracy in solving problems where it is difficult
to detect patterns or create a logical model. However, these algorithms
sometimes return wrong solutions, which become problematic in high-risk domains
like medical diagnosis or autonomous driving. One strategy to detect and
mitigate these errors is the measurement of the uncertainty over neural network
decisions. In this paper, we present a novel post-hoc framework for measuring
the uncertainty of a decision based on retrieved training cases that have a
similar activation vector to the query for each layer. Based on these retrieved
cases, we propose two new metrics: Decision Change and Layer Uncertainty, which
capture changes in nearest-neighbor class distributions across layers. We
evaluated our approach in a classification model for two datasets: CIFAR-10 and
MNIST. The results show that these metrics enhance uncertainty estimation,
especially in challenging classification tasks, outperforming softmax-based
confidence.

</details>


### [102] [A Comparative Analysis of Reinforcement Learning and Conventional Deep Learning Approaches for Bearing Fault Diagnosis](https://arxiv.org/abs/2506.19929)
*Efe Çakır,Patrick Dumond*

Main category: cs.LG

TL;DR: 该论文探讨了强化学习（特别是DQN）在轴承故障诊断中的应用，发现其在适应性上优于传统监督学习，但计算需求较高。


<details>
  <summary>Details</summary>
Motivation: 轴承故障可能导致严重的运营中断和维护成本，传统方法依赖大量标记数据且适应性不足。

Method: 使用深度Q网络（DQN）进行轴承故障分类，优化奖励结构以提高适应性。

Result: RL模型在受控条件下与传统方法性能相当，但在适应性上表现更优，计算需求较高。

Conclusion: 强化学习有潜力补充传统方法，为自适应诊断框架提供新方向。

Abstract: Bearing faults in rotating machinery can lead to significant operational
disruptions and maintenance costs. Modern methods for bearing fault diagnosis
rely heavily on vibration analysis and machine learning techniques, which often
require extensive labeled data and may not adapt well to dynamic environments.
This study explores the feasibility of reinforcement learning (RL),
specifically Deep Q-Networks (DQNs), for bearing fault classification tasks in
machine condition monitoring to enhance the accuracy and adaptability of
bearing fault diagnosis. The results demonstrate that while RL models developed
in this study can match the performance of traditional supervised learning
models under controlled conditions, they excel in adaptability when equipped
with optimized reward structures. However, their computational demands
highlight areas for further improvement. These findings demonstrate RL's
potential to complement traditional methods, paving the way for adaptive
diagnostic frameworks.

</details>


### [103] [Causal discovery in deterministic discrete LTI-DAE systems](https://arxiv.org/abs/2506.20169)
*Bala Rajesh Konkathi,Arun K. Tangirala*

Main category: cs.LG

TL;DR: 提出了一种名为PoV的方法，用于在LTI-DAE系统中发现因果关系，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法处理带有代数关系的动态系统，而许多实际系统存在反馈控制或守恒定律，导致混合因果系统。

Method: PoV方法通过DIPCA确定代数关系数、动态关系数和约束矩阵，再通过条件数识别最小因果驱动子集。

Result: PoV方法在LTI-DAE系统中有效，且适用于纯动态系统。

Conclusion: PoV方法在因果发现中具有优越性，适用于更广泛的系统类型。

Abstract: Discovering pure causes or driver variables in deterministic LTI systems is
of vital importance in the data-driven reconstruction of causal networks. A
recent work by Kathari and Tangirala, proposed in 2022, formulated the causal
discovery method as a constraint identification problem. The constraints are
identified using a dynamic iterative PCA (DIPCA)-based approach for dynamical
systems corrupted with Gaussian measurement errors. The DIPCA-based method
works efficiently for dynamical systems devoid of any algebraic relations.
However, several dynamical systems operate under feedback control and/or are
coupled with conservation laws, leading to differential-algebraic (DAE) or
mixed causal systems. In this work, a method, namely the partition of variables
(PoV), for causal discovery in LTI-DAE systems is proposed. This method is
superior to the method that was presented by Kathari and Tangirala (2022), as
PoV also works for pure dynamical systems, which are devoid of algebraic
equations. The proposed method identifies the causal drivers up to a minimal
subset. PoV deploys DIPCA to first determine the number of algebraic relations
($n_a$), the number of dynamical relations ($n_d$) and the constraint matrix.
Subsequently, the subsets are identified through an admissible partitioning of
the constraint matrix by finding the condition number of it. Case studies are
presented to demonstrate the effectiveness of the proposed method.

</details>


### [104] [Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture](https://arxiv.org/abs/2506.19935)
*Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma*

Main category: cs.LG

TL;DR: 该研究在解码器框架下评估掩码扩散模型（MDM），公平比较MDM与自回归（AR）范式，并探讨架构影响。


<details>
  <summary>Details</summary>
Motivation: 比较AR和MDM范式时，架构差异导致不公平对比，研究旨在区分范式与架构的影响。

Method: 在解码器框架下评估MDM，将其视为任意顺序自回归（AO-AR），并分析架构差异。

Result: 解码器MDM在生成速度上显著提升（约25倍），且困惑度与编码器MDM相当。

Conclusion: 研究分离了范式与架构的影响，为未来模型设计提供了见解。

Abstract: Large language models (LLMs) predominantly use autoregressive (AR)
approaches, but masked diffusion models (MDMs) are emerging as viable
alternatives. A key challenge in comparing AR and MDM paradigms is their
typical architectural difference: AR models are often decoder-only, while MDMs
have largely been encoder-only. This practice of changing both the modeling
paradigm and architecture simultaneously makes direct comparisons unfair, as
it's hard to distinguish whether observed differences stem from the paradigm
itself or the architectural shift. This research evaluates MDMs within a
decoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or
AO-AR) and standard AR paradigms. Our investigation suggests that the standard
AO-AR objective, which averages over all token permutations, may benefit from
refinement, as many permutations appear less informative compared to the
language's inherent left-to-right structure. (2) Investigate architectural
influences (decoder-only vs. encoder-only) within MDMs. We demonstrate that
while encoder-only MDMs model a simpler conditional probability space,
decoder-only MDMs can achieve dramatic generation speedups ($\sim25\times$) and
comparable perplexity with temperature annealing despite modeling a vastly
larger space, highlighting key trade-offs. This work thus decouples core
paradigm differences from architectural influences, offering insights for
future model design. Code is available at https://github.com/scxue/AO-GPT-MDM.

</details>


### [105] [The Most Important Features in Generalized Additive Models Might Be Groups of Features](https://arxiv.org/abs/2506.19937)
*Tomas M. Bosschieter,Luis Franca,Jessica Wolk,Yiyuan Wu,Bella Mehta,Joseph Dehoney,Orsolya Kiss,Fiona C. Baker,Qingyu Zhao,Rich Caruana,Kilian M. Pohl*

Main category: cs.LG

TL;DR: 本文提出了一种高效、无需重新训练模型的方法，用于评估广义加性模型（GAMs）中特征组的重要性，适用于高维数据，并在多模态数据集中展示了其优势。


<details>
  <summary>Details</summary>
Motivation: 现有方法常忽略特征组的联合信号，导致遗漏重要预测信息，尤其是在多模态数据集中。

Method: 提出了一种无需重新训练模型、支持事后定义和重叠特征组的方法，并与统计学中的解释变异概念平行。

Result: 在合成实验和两个实际案例（抑郁症症状识别和髋关节置换术后健康因素分析）中验证了方法的有效性。

Conclusion: 分析特征组重要性比单特征分析更全面准确，尤其在医学领域。

Abstract: While analyzing the importance of features has become ubiquitous in
interpretable machine learning, the joint signal from a group of related
features is sometimes overlooked or inadvertently excluded. Neglecting the
joint signal could bypass a critical insight: in many instances, the most
significant predictors are not isolated features, but rather the combined
effect of groups of features. This can be especially problematic for datasets
that contain natural groupings of features, including multimodal datasets. This
paper introduces a novel approach to determine the importance of a group of
features for Generalized Additive Models (GAMs) that is efficient, requires no
model retraining, allows defining groups posthoc, permits overlapping groups,
and remains meaningful in high-dimensional settings. Moreover, this definition
offers a parallel with explained variation in statistics. We showcase
properties of our method on three synthetic experiments that illustrate the
behavior of group importance across various data regimes. We then demonstrate
the importance of groups of features in identifying depressive symptoms from a
multimodal neuroscience dataset, and study the importance of social
determinants of health after total hip arthroplasty. These two case studies
reveal that analyzing group importance offers a more accurate, holistic view of
the medical issues compared to a single-feature analysis.

</details>


### [106] [HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization](https://arxiv.org/abs/2506.19992)
*Gabor Petnehazi,Bernadett Aradi*

Main category: cs.LG

TL;DR: HERCULES是一种新型分层k-means聚类算法，支持多种数据类型，并利用LLM生成语义丰富的聚类标题和描述，提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 复杂数据集的快速增长需要既能有效分组数据又能提供人类可理解洞察的工具。

Method: HERCULES通过递归应用k-means聚类构建层次结构，并利用LLM生成聚类标题和描述，支持两种表示模式（直接模式和描述模式）。

Result: 算法能够从复杂数据集中提取有意义的分层知识，并提供交互式可视化工具。

Conclusion: HERCULES展示了从复杂数据中提取层次化知识的潜力，增强了聚类的可解释性。

Abstract: The explosive growth of complex datasets across various modalities
necessitates advanced analytical tools that not only group data effectively but
also provide human-understandable insights into the discovered structures. We
introduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using
LLMs for Efficient Summarization), a novel algorithm and Python package
designed for hierarchical k-means clustering of diverse data types, including
text, images, and numeric data (processed one modality per run). HERCULES
constructs a cluster hierarchy by recursively applying k-means clustering,
starting from individual data points at level 0. A key innovation is its deep
integration of Large Language Models (LLMs) to generate semantically rich
titles and descriptions for clusters at each level of the hierarchy,
significantly enhancing interpretability. The algorithm supports two main
representation modes: `direct' mode, which clusters based on original data
embeddings or scaled numeric features, and `description' mode, which clusters
based on embeddings derived from LLM-generated summaries. Users can provide a
`topic\_seed' to guide LLM-generated summaries towards specific themes. An
interactive visualization tool facilitates thorough analysis and understanding
of the clustering results. We demonstrate HERCULES's capabilities and discuss
its potential for extracting meaningful, hierarchical knowledge from complex
datasets.

</details>


### [107] [Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation](https://arxiv.org/abs/2506.20525)
*Christian Internò,Andrea Castellani,Sebastian Schmitt,Fabio Stella,Barbara Hammer*

Main category: cs.LG

TL;DR: 论文提出了一种合成工业数据集SIDED和一种数据增强方法AMDA，用于解决工业非侵入式负载监测（NILM）中的数据稀缺和隐私问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 工业NILM面临高质量数据集稀缺和工业能耗模式复杂多变的问题，同时需解决数据隐私问题。

Method: 使用数字孪生模拟生成开源数据集SIDED，并提出AMDA方法，通过智能调整电器功率贡献来增强模型泛化能力。

Result: 实验显示，使用AMDA增强数据的NILM模型在复杂工业电器（如热电联产系统）的能耗分解中表现优异，归一化分解误差为0.093，优于未增强（0.451）和随机增强（0.290）的模型。

Conclusion: AMDA有效对齐训练和测试数据分布，提升模型泛化能力，为工业NILM提供了实用解决方案。

Abstract: Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of
high-quality datasets and the complex variability of industrial energy
consumption patterns. To address data scarcity and privacy issues, we introduce
the Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an
open-source dataset generated using Digital Twin simulations. SIDED includes
three types of industrial facilities across three different geographic
locations, capturing diverse appliance behaviors, weather conditions, and load
profiles. We also propose the Appliance-Modulated Data Augmentation (AMDA)
method, a computationally efficient technique that enhances NILM model
generalization by intelligently scaling appliance power contributions based on
their relative impact. We show in experiments that NILM models trained with
AMDA-augmented data significantly improve the disaggregation of energy
consumption of complex industrial appliances like combined heat and power
systems. Specifically, in our out-of-sample scenarios, models trained with AMDA
achieved a Normalized Disaggregation Error of 0.093, outperforming models
trained without data augmentation (0.451) and those trained with random data
augmentation (0.290). Data distribution analyses confirm that AMDA effectively
aligns training and test data distributions, enhancing model generalization.

</details>


### [108] [TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design](https://arxiv.org/abs/2506.19997)
*Geonwoo Cho,Jaegyun Im,Jihwan Lee,Hojun Yi,Sejin Kim,Sundong Kim*

Main category: cs.LG

TL;DR: 论文提出TRACED方法，通过结合转移预测误差和共学习性改进UED框架，提升零样本泛化能力并减少环境交互需求。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习代理在未见环境中的泛化问题，改进现有UED框架的遗憾近似方法。

Method: 引入转移预测误差作为遗憾近似的额外项，并提出轻量级共学习性指标，结合两者形成TRACED方法。

Result: 实验表明TRACED在多个基准测试中提升零样本泛化能力，且环境交互需求减少至基线的一半。

Conclusion: 改进的遗憾近似和任务关系建模可高效设计UED课程，提升样本效率。

Abstract: Generalizing deep reinforcement learning agents to unseen environments
remains a significant challenge. One promising solution is Unsupervised
Environment Design (UED), a co-evolutionary framework in which a teacher
adaptively generates tasks with high learning potential, while a student learns
a robust policy from this evolving curriculum. Existing UED methods typically
measure learning potential via regret, the gap between optimal and current
performance, approximated solely by value-function loss. Building on these
approaches, we introduce the transition prediction error as an additional term
in our regret approximation. To capture how training on one task affects
performance on others, we further propose a lightweight metric called
co-learnability. By combining these two measures, we present Transition-aware
Regret Approximation with Co-learnability for Environment Design (TRACED).
Empirical evaluations show that TRACED yields curricula that improve zero-shot
generalization across multiple benchmarks while requiring up to 2x fewer
environment interactions than strong baselines. Ablation studies confirm that
the transition prediction error drives rapid complexity ramp-up and that
co-learnability delivers additional gains when paired with the transition
prediction error. These results demonstrate how refined regret approximation
and explicit modeling of task relationships can be leveraged for
sample-efficient curriculum design in UED.

</details>


### [109] [New Insights on Unfolding and Fine-tuning Quantum Federated Learning](https://arxiv.org/abs/2506.20016)
*Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 提出了一种基于深度展开的新方法，解决量子联邦学习中客户端异构性问题，通过动态优化超参数实现90%准确率，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 客户端异构性严重影响了量子联邦学习的性能，需要一种能够动态适应不同客户端训练行为的方法。

Method: 利用深度展开技术，使客户端能够自主优化学习率和正则化因子等超参数，动态适应异构环境。

Result: 在IBM量子硬件和Qiskit Aer模拟器上实现约90%的准确率，显著优于传统方法的55%。

Conclusion: 该方法通过自适应的优化步骤解决了传统量子联邦学习的核心限制，适用于医疗和基因组研究等复杂场景。

Abstract: Client heterogeneity poses significant challenges to the performance of
Quantum Federated Learning (QFL). To overcome these limitations, we propose a
new approach leveraging deep unfolding, which enables clients to autonomously
optimize hyperparameters, such as learning rates and regularization factors,
based on their specific training behavior. This dynamic adaptation mitigates
overfitting and ensures robust optimization in highly heterogeneous
environments where standard aggregation methods often fail. Our framework
achieves approximately 90% accuracy, significantly outperforming traditional
methods, which typically yield around 55% accuracy, as demonstrated through
real-time training on IBM quantum hardware and Qiskit Aer simulators. By
developing self adaptive fine tuning, the proposed method proves particularly
effective in critical applications such as gene expression analysis and cancer
detection, enhancing diagnostic precision and predictive modeling within
quantum systems. Our results are attributed to convergence-aware, learnable
optimization steps intrinsic to the deep unfolded framework, which maintains
the generalization. Hence, this study addresses the core limitations of
conventional QFL, streamlining its applicability to any complex challenges such
as healthcare and genomic research.

</details>


### [110] [DIM-SUM: Dynamic IMputation for Smart Utility Management](https://arxiv.org/abs/2506.20023)
*Ryan Hildebrant,Rahul Bhope,Sharad Mehrotra,Christopher Tull,Nalini Venkatasubramanian*

Main category: cs.LG

TL;DR: DIM-SUM是一个预处理框架，通过模式聚类和自适应掩码策略，有效处理真实缺失数据模式，提升时间序列插值模型的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列插值模型使用人工掩码模拟缺失数据，无法应对现实世界中复杂、异构的缺失模式。

Method: 结合模式聚类和自适应掩码策略，并提供理论学习保证，以处理真实数据中的多样化缺失模式。

Result: 在加州水务、电力数据集和基准测试中，DIM-SUM性能优于传统方法，达到相似精度但处理时间和训练数据更少；与大型预训练模型相比，精度提高2倍且推理时间显著减少。

Conclusion: DIM-SUM能有效弥合人工掩码训练数据与真实缺失模式之间的差距，为实际应用提供高效解决方案。

Abstract: Time series imputation models have traditionally been developed using
complete datasets with artificial masking patterns to simulate missing values.
However, in real-world infrastructure monitoring, practitioners often encounter
datasets where large amounts of data are missing and follow complex,
heterogeneous patterns. We introduce DIM-SUM, a preprocessing framework for
training robust imputation models that bridges the gap between artificially
masked training data and real missing patterns. DIM-SUM combines pattern
clustering and adaptive masking strategies with theoretical learning guarantees
to handle diverse missing patterns actually observed in the data. Through
extensive experiments on over 2 billion readings from California water
districts, electricity datasets, and benchmarks, we demonstrate that DIM-SUM
outperforms traditional methods by reaching similar accuracy with lower
processing time and significantly less training data. When compared against a
large pre-trained model, DIM-SUM averages 2x higher accuracy with significantly
less inference time.

</details>


### [111] [Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting](https://arxiv.org/abs/2506.20024)
*Salva Rühling Cachay,Miika Aittala,Karsten Kreis,Noah Brenowitz,Arash Vahdat,Morteza Mardani,Rose Yu*

Main category: cs.LG

TL;DR: ERDM框架将滚动预测结构与高性能扩散模型结合，解决了高维混沌系统中时间依赖性和不确定性增长的问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在高维混沌系统中难以建模复杂时间依赖性和不确定性增长，滚动扩散框架与高性能扩散技术的结合仍具挑战性。

Method: 提出ERDM框架，结合EDM的核心组件（噪声调度、网络预处理、Heun采样器），并引入新的损失加权方案、预训练初始化策略和混合序列架构。

Result: 在2D Navier-Stokes模拟和ERA5全球天气预报中，ERDM表现优于基线扩散模型。

Conclusion: ERDM为扩散模型序列生成问题提供了灵活且强大的通用框架，尤其适用于不确定性增长显著的场景。

Abstract: Diffusion models are a powerful tool for probabilistic forecasting, yet most
applications in high-dimensional chaotic systems predict future snapshots
one-by-one. This common approach struggles to model complex temporal
dependencies and fails to explicitly account for the progressive growth of
uncertainty inherent to such systems. While rolling diffusion frameworks, which
apply increasing noise to forecasts at longer lead times, have been proposed to
address this, their integration with state-of-the-art, high-fidelity diffusion
techniques remains a significant challenge. We tackle this problem by
introducing Elucidated Rolling Diffusion Models (ERDM), the first framework to
successfully unify a rolling forecast structure with the principled, performant
design of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM
components-its noise schedule, network preconditioning, and Heun sampler-to the
rolling forecast setting. The success of this integration is driven by three
key contributions: (i) a novel loss weighting scheme that focuses model
capacity on the mid-range forecast horizons where determinism gives way to
stochasticity; (ii) an efficient initialization strategy using a pre-trained
EDM for the initial window; and (iii) a bespoke hybrid sequence architecture
for robust spatiotemporal feature extraction under progressive denoising. On 2D
Navier-Stokes simulations and ERA5 global weather forecasting at 1.5^\circ
resolution, ERDM consistently outperforms key diffusion-based baselines,
including conditional autoregressive EDM. ERDM offers a flexible and powerful
general framework for tackling diffusion-based sequence generation problems
where modeling escalating uncertainty is paramount. Code is available at:
https://github.com/salvaRC/erdm

</details>


### [112] [Thumb on the Scale: Optimal Loss Weighting in Last Layer Retraining](https://arxiv.org/abs/2506.20025)
*Nathan Stromberg,Christos Thrampoulidis,Lalitha Sankar*

Main category: cs.LG

TL;DR: 论文探讨了在中间参数化情况下损失加权对模型性能的影响，发现其仍有效但需考虑模型的相对过参数化。


<details>
  <summary>Details</summary>
Motivation: 研究机器学习模型在训练数据偏差下的表现，特别是在中间参数化情况下损失加权的有效性。

Method: 通过理论和实践分析，研究了最后一层重训练（LLR）机制中损失加权的作用。

Result: 发现损失加权在中间参数化情况下仍然有效，但需考虑模型的相对过参数化。

Conclusion: 损失加权在中间参数化情况下仍是一种有效策略，但需调整以考虑模型的具体参数化程度。

Abstract: While machine learning models become more capable in discriminative tasks at
scale, their ability to overcome biases introduced by training data has come
under increasing scrutiny. Previous results suggest that there are two extremes
of parameterization with very different behaviors: the population
(underparameterized) setting where loss weighting is optimal and the separable
overparameterized setting where loss weighting is ineffective at ensuring equal
performance across classes. This work explores the regime of last layer
retraining (LLR) in which the unseen limited (retraining) data is frequently
inseparable and the model proportionately sized, falling between the two
aforementioned extremes. We show, in theory and practice, that loss weighting
is still effective in this regime, but that these weights \emph{must} take into
account the relative overparameterization of the model.

</details>


### [113] [Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning](https://arxiv.org/abs/2506.20031)
*Prithvi Poddar,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury*

Main category: cs.LG

TL;DR: 提出了一种生成多样化行动方案（COA）的理论框架和计算方法，用于多代理任务分配，结合遗传算法和图神经网络优化任务分配和序列。


<details>
  <summary>Details</summary>
Motivation: 多代理任务（如灾害响应、军事任务）需要多样化的行动方案以适应环境变化和代理能力差异。

Method: 使用图抽象表示任务空间和COA池，遗传算法优化任务分配，图神经网络优化任务序列。

Result: 模拟测试显示性能显著优于随机基线，任务序列接近最优，20个COA规划时间约50分钟。

Conclusion: 框架有效生成多样化COA，适用于复杂多代理任务场景。

Abstract: Operations in disaster response, search \& rescue, and military missions that
involve multiple agents demand automated processes to support the planning of
the courses of action (COA). Moreover, traverse-affecting changes in the
environment (rain, snow, blockades, etc.) may impact the expected performance
of a COA, making it desirable to have a pool of COAs that are diverse in task
distributions across agents. Further, variations in agent capabilities, which
could be human crews and/or autonomous systems, present practical opportunities
and computational challenges to the planning process. This paper presents a new
theoretical formulation and computational framework to generate such diverse
pools of COAs for operations with soft variations in agent-task compatibility.
Key to the problem formulation is a graph abstraction of the task space and the
pool of COAs itself to quantify its diversity. Formulating the COAs as a
centralized multi-robot task allocation problem, a genetic algorithm is used
for (order-ignoring) allocations of tasks to each agent that jointly maximize
diversity within the COA pool and overall compatibility of the agent-task
mappings. A graph neural network is trained using a policy gradient approach to
then perform single agent task sequencing in each COA, which maximizes
completion rates adaptive to task features. Our tests of the COA generation
process in a simulated environment demonstrate significant performance gain
over a random walk baseline, small optimality gap in task sequencing, and
execution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 task
operations.

</details>


### [114] [Verifiable Unlearning on Edge](https://arxiv.org/abs/2506.20037)
*Mohammad M Maheri,Alex Davidson,Hamed Haddadi*

Main category: cs.LG

TL;DR: 论文提出了一种基于零知识证明（zk-SNARKs）的验证框架，用于确保边缘设备在个性化模型中正确执行数据遗忘操作，同时保护隐私。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备在个性化模型中执行数据遗忘时可能面临的版权侵权、偏见或监管要求问题，确保操作的完整性和隐私保护。

Method: 开发了与高效zk-SNARK证明生成兼容的数据遗忘算法，适用于资源受限的边缘环境，同时保留个性化增强功能。

Result: 验证了该框架的实用性和有效性，实现了可验证的数据遗忘，且对个性化性能影响极小。

Conclusion: 该方法为边缘设备提供了可验证、隐私保护且高效的数据遗忘解决方案。

Abstract: Machine learning providers commonly distribute global models to edge devices,
which subsequently personalize these models using local data. However, issues
such as copyright infringements, biases, or regulatory requirements may require
the verifiable removal of certain data samples across all edge devices.
Ensuring that edge devices correctly execute such unlearning operations is
critical to maintaining integrity.
  In this work, we introduce a verification framework leveraging zero-knowledge
proofs, specifically zk-SNARKs, to confirm data unlearning on personalized
edge-device models without compromising privacy. We have developed algorithms
explicitly designed to facilitate unlearning operations that are compatible
with efficient zk-SNARK proof generation, ensuring minimal computational and
memory overhead suitable for constrained edge environments. Furthermore, our
approach carefully preserves personalized enhancements on edge devices,
maintaining model performance post-unlearning.
  Our results affirm the practicality and effectiveness of this verification
framework, demonstrating verifiable unlearning with minimal degradation in
personalization-induced performance improvements. Our methodology ensures
verifiable, privacy-preserving, and effective machine unlearning across edge
devices.

</details>


### [115] [Cross-Layer Discrete Concept Discovery for Interpreting Language Models](https://arxiv.org/abs/2506.20040)
*Ankur Garg,Xuemin Yu,Hassan Sajjad,Samira Ebrahimi Kahou*

Main category: cs.LG

TL;DR: 提出了一种名为CLVQVAE的框架，通过向量量化技术跨层映射神经表示，将冗余特征压缩为紧凑的概念向量，以解决现有方法在分析Transformer层间特征演化时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单层神经表示，忽略了跨层特征的叠加和冗余，导致对特征演化的理解不足。

Method: 采用向量量化技术，结合top-k温度采样和EMA码本更新，以及基于方向相似性的k-means++初始化，以生成紧凑且可解释的概念向量。

Result: 提出的框架能够有效压缩冗余特征，生成更具语义一致性的概念向量。

Conclusion: CLVQVAE为跨层特征分析提供了一种新方法，有助于更深入地理解Transformer模型中的特征演化。

Abstract: Uncovering emergent concepts across transformer layers remains a significant
challenge because the residual stream linearly mixes and duplicates
information, obscuring how features evolve within large language models.
Current research efforts primarily inspect neural representations at single
layers, thereby overlooking this cross-layer superposition and the redundancy
it introduces. These representations are typically either analyzed directly for
activation patterns or passed to probing classifiers that map them to a limited
set of predefined concepts. To address these limitations, we propose
\gls{clvqvae}, a framework that uses vector quantization to map representations
across layers and in the process collapse duplicated residual-stream features
into compact, interpretable concept vectors. Our approach uniquely combines
top-$k$ temperature-based sampling during quantization with EMA codebook
updates, providing controlled exploration of the discrete latent space while
maintaining code-book diversity. We further enhance the framework with
scaled-spherical k-means++ for codebook initialization, which clusters by
directional similarity rather than magnitude, better aligning with semantic
structure in word embedding space.

</details>


### [116] [LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification](https://arxiv.org/abs/2506.20041)
*Soheil Abadifard,Fazli Can*

Main category: cs.LG

TL;DR: 本文提出了一种名为LSH-DynED的新方法，通过结合局部敏感哈希与随机超平面投影（LSH-RHP）和动态集成多样化（DynED）框架，解决了多类别不平衡数据流分类的挑战。该方法通过LSH-RHP对多数类进行欠采样，提供平衡的训练集，并在实验中表现优于15种现有方法。


<details>
  <summary>Details</summary>
Motivation: 多类别不平衡数据流的分类问题在机器学习中具有挑战性，尤其是动态不平衡比的处理。现有研究主要集中在二分类问题，而多类别问题研究较少。

Method: 提出LSH-DynED方法，将LSH-RHP集成到DynED框架中，通过欠采样多数类来平衡训练集。

Result: 在23个真实世界和10个半合成数据集上的实验表明，LSH-DynED在Kappa和mG-Mean指标上优于其他15种方法，尤其在大规模、高维数据中表现优异。

Conclusion: LSH-DynED是一种高效、鲁棒的方法，适用于多类别不平衡非平稳数据流分类，并为未来研究提供了方向。

Abstract: The classification of imbalanced data streams, which have unequal class
distributions, is a key difficulty in machine learning, especially when dealing
with multiple classes. While binary imbalanced data stream classification tasks
have received considerable attention, only a few studies have focused on
multi-class imbalanced data streams. Effectively managing the dynamic imbalance
ratio is a key challenge in this domain. This study introduces a novel, robust,
and resilient approach to address these challenges by integrating Locality
Sensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic
Ensemble Diversification (DynED) framework. To the best of our knowledge, we
present the first application of LSH-RHP for undersampling in the context of
imbalanced non-stationary data streams. The proposed method undersamples the
majority classes by utilizing LSH-RHP, provides a balanced training set, and
improves the ensemble's prediction performance. We conduct comprehensive
experiments on 23 real-world and ten semi-synthetic datasets and compare
LSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED
outperforms other approaches in terms of both Kappa and mG-Mean effectiveness
measures, demonstrating its capability in dealing with multi-class imbalanced
non-stationary data streams. Notably, LSH-DynED performs well in large-scale,
high-dimensional datasets with considerable class imbalances and demonstrates
adaptation and robustness in real-world circumstances. To motivate our design,
we review existing methods for imbalanced data streams, outline key challenges,
and offer guidance for future work. For the reproducibility of our results, we
have made our implementation available on GitHub.

</details>


### [117] [GNN's Uncertainty Quantification using Self-Distillation](https://arxiv.org/abs/2506.20046)
*Hirad Daneshvar,Reza Samavi*

Main category: cs.LG

TL;DR: 提出了一种基于知识蒸馏的新方法，用于高效且精确地量化图神经网络（GNN）的预测不确定性，解决了传统贝叶斯和集成方法计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中，量化GNN的预测不确定性对可信度至关重要，但现有方法（如贝叶斯和集成方法）计算成本高且无法充分捕捉模型多样性。

Method: 采用自蒸馏技术，同一网络同时作为教师和学生模型，避免了独立训练多个网络的需求，并开发了一种新的不确定性度量方法。

Result: 实验结果表明，该方法在MIMIC-IV和Enzymes数据集上能有效捕捉预测不确定性，性能与MC Dropout和集成方法相当。

Conclusion: 提出的方法在计算效率和不确定性量化精度上优于传统方法，适用于临床环境中的GNN应用。

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in the
healthcare domain. However, what remained challenging is quantifying the
predictive uncertainty of GNNs, which is an important aspect of trustworthiness
in clinical settings. While Bayesian and ensemble methods can be used to
quantify uncertainty, they are computationally expensive. Additionally, the
disagreement metric used by ensemble methods to compute uncertainty cannot
capture the diversity of models in an ensemble network. In this paper, we
propose a novel method, based on knowledge distillation, to quantify GNNs'
uncertainty more efficiently and with higher precision. We apply
self-distillation, where the same network serves as both the teacher and
student models, thereby avoiding the need to train several networks
independently. To ensure the impact of self-distillation, we develop an
uncertainty metric that captures the diverse nature of the network by assigning
different weights to each GNN classifier. We experimentally evaluate the
precision, performance, and ability of our approach in distinguishing
out-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The
evaluation results demonstrate that the proposed method can effectively capture
the predictive uncertainty of the model while having performance similar to
that of the MC Dropout and ensemble methods. The code is publicly available at
https://github.com/tailabTMU/UQ_GNN.

</details>


### [118] [Universal pre-training by iterated random computation](https://arxiv.org/abs/2506.20057)
*Peter Bloem*

Main category: cs.LG

TL;DR: 研究使用随机生成数据预训练模型的理论和实证效果，证明其能实现零样本学习和泛化提升。


<details>
  <summary>Details</summary>
Motivation: 探索随机生成数据预训练的理论基础，验证其在未见数据上的有效性。

Method: 从算法复杂性角度理论分析，实证验证预训练模型在零样本学习和泛化中的表现。

Result: 预训练模型在多种数据集上实现零样本学习，且性能随规模提升；微调后收敛更快、泛化更好。

Conclusion: 随机生成数据预训练具有理论和实际价值，能提升模型性能。

Abstract: We investigate the use of randomly generated data for the sake of
pre-training a model. We justify this approach theoretically from the
perspective of algorithmic complexity, building on recent research that shows
that sequence models can be trained to approximate Solomonoff induction. We
derive similar, but complementary theoretical results. We show empirically that
synthetically generated data can be used to pre-train a model before the data
is seen. We replicate earlier results that models trained this way show
zero-shot in-context learning across a variety of datasets, and that this
performance improves with scale. We extend earlier results to real-world data,
and show that finetuning a model after pre-training offers faster convergence
and better generalization.

</details>


### [119] [Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models](https://arxiv.org/abs/2506.20061)
*Zhicheng Zhang,Ziyan Wang,Yali Du,Fei Fang*

Main category: cs.LG

TL;DR: 利用大型语言模型（LLM）自动生成开放式指令，通过重新标注失败轨迹来提升强化学习中的指令跟随能力。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中依赖人工标注指令数据集和稀疏奖励学习困难的问题。

Method: 利用LLM从已收集的代理轨迹中生成开放式指令，重新标注失败轨迹以丰富训练数据。

Result: 在Craftax环境中，样本效率、指令覆盖率和策略性能均优于现有基线。

Conclusion: LLM引导的开放式指令重新标注能有效提升指令跟随强化学习的效果。

Abstract: Developing effective instruction-following policies in reinforcement learning
remains challenging due to the reliance on extensive human-labeled instruction
datasets and the difficulty of learning from sparse rewards. In this paper, we
propose a novel approach that leverages the capabilities of large language
models (LLMs) to automatically generate open-ended instructions retrospectively
from previously collected agent trajectories. Our core idea is to employ LLMs
to relabel unsuccessful trajectories by identifying meaningful subtasks the
agent has implicitly accomplished, thereby enriching the agent's training data
and substantially alleviating reliance on human annotations. Through this
open-ended instruction relabeling, we efficiently learn a unified
instruction-following policy capable of handling diverse tasks within a single
policy. We empirically evaluate our proposed method in the challenging Craftax
environment, demonstrating clear improvements in sample efficiency, instruction
coverage, and overall policy performance compared to state-of-the-art
baselines. Our results highlight the effectiveness of utilizing LLM-guided
open-ended instruction relabeling to enhance instruction-following
reinforcement learning.

</details>


### [120] [Supervised Coupled Matrix-Tensor Factorization (SCMTF) for Computational Phenotyping of Patient Reported Outcomes in Ulcerative Colitis](https://arxiv.org/abs/2506.20065)
*Cristian Minoccheri,Sophia Tesic,Kayvan Najarian,Ryan Stidham*

Main category: cs.LG

TL;DR: 论文提出了一种新型的监督耦合矩阵-张量分解（SCMTF）方法，用于整合患者报告结果（PROs）和实验室数据，预测溃疡性结肠炎（UC）患者的药物持续性。该方法首次将张量分解应用于UC领域和PRO数据，并展示了其在处理高缺失数据中的有效性。


<details>
  <summary>Details</summary>
Motivation: 患者报告的症状（PROs）通常噪声大、主观性强且数据稀疏，传统方法常忽略这些数据。本文旨在利用PROs数据，通过计算表型分析预测UC患者的药物持续性。

Method: 采用监督耦合矩阵-张量分解（SCMTF）方法，整合时间序列的PROs和实验室数据以及静态特征，结合深度学习框架处理缺失数据。

Result: 最佳模型在测试集上预测8个月和20个月后药物变化的AUC分别为0.853和0.803，并提取了可解释的表型。

Conclusion: 研究表明，低秩矩阵和张量分解方法可成功应用于UC领域和高缺失PRO数据，PROs中包含传统方法忽略的有用信息。

Abstract: Phenotyping is the process of distinguishing groups of patients to identify
different types of disease progression. A recent trend employs low-rank matrix
and tensor factorization methods for their capability of dealing with
multi-modal, heterogeneous, and missing data. Symptom quantification is crucial
for understanding patient experiences in inflammatory bowel disease, especially
in conditions such as ulcerative colitis (UC). However, patient-reported
symptoms are typically noisy, subjective, and significantly more sparse than
other data types. For this reason, they are usually not included in phenotyping
and other machine learning methods. This paper explores the application of
computational phenotyping to leverage Patient-Reported Outcomes (PROs) using a
novel supervised coupled matrix-tensor factorization (SCMTF) method, which
integrates temporal PROs and temporal labs with static features to predict
medication persistence in ulcerative colitis. This is the first tensor-based
method that is both supervised and coupled, it is the first application to the
UC domain, and the first application to PROs. We use a deep learning framework
that makes the model flexible and easy to train. The proposed method allows us
to handle the large amount of missing data in the PROs. The best model predicts
changes in medication 8 and 20 months in the future with AUCs of 0.853 and
0.803 on the test set respectively. We derive interpretable phenotypes
consisting of static features and temporal features (including their temporal
patterns). We show that low-rank matrix and tensor based phenotyping can be
successfully applied to the UC domain and to highly missing PRO data. We
identify phenotypes useful to predict medication persistence - these phenotypes
include several symptom variables, showing that PROs contain relevant
infromation that is usually discarded.

</details>


### [121] [A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression](https://arxiv.org/abs/2506.20090)
*Ainaz Jamshidi,Dongchan Kim,Muhammad Arif*

Main category: cs.LG

TL;DR: 本文综述了预测性维护（PdM）中回归与分类方法的比较，强调其在设备故障预测中的优势与挑战，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 预测性维护对工业运营至关重要，但缺乏回归与分类方法的系统比较研究，本文旨在填补这一空白。

Method: 通过综合分析近期文献，比较回归（提供剩余使用寿命估计）和分类（预测故障概率）方法在PdM中的应用。

Result: 研究揭示了回归与分类方法的优缺点，以及数据不平衡、高维特征等挑战，同时指出混合方法和AI系统的趋势。

Conclusion: 本文为研究者和从业者提供了PdM方法的全面视角，并建议未来研究关注公开数据集和开源工具的开发。

Abstract: Predictive maintenance (PdM) has become a crucial element of modern
industrial practice. PdM plays a significant role in operational dependability
and cost management by decreasing unforeseen downtime and optimizing asset life
cycle management. Machine learning and deep learning have enabled more precise
forecasts of equipment failure and remaining useful life (RUL). Although many
studies have been conducted on PdM, there has not yet been a standalone
comparative study between regression- and classification-based approaches. In
this review, we look across a range of PdM methodologies, while focusing more
strongly on the comparative use of classification and regression methods in
prognostics. While regression-based methods typically provide estimates of RUL,
classification-based methods present a forecast of the probability of failure
across defined time intervals. Through a comprehensive analysis of recent
literature, we highlight key advancements, challenges-such as data imbalance
and high-dimensional feature spaces-and emerging trends, including hybrid
approaches and AI-enabled prognostic systems. This review aims to provide
researchers and practitioners with an awareness of the strengths and
compromises of various PdM methods and to help identify future research and
build more robust, directed adaptive maintenance systems. Future work may
include a systematic review of practical aspects such as public datasets,
benchmarking platforms, and open-source tools to support the advancement of PdM
research.

</details>


### [122] [MEL: Multi-level Ensemble Learning for Resource-Constrained Environments](https://arxiv.org/abs/2506.20094)
*Krishna Praneet Gudipaty,Walid A. Hanafy,Kaan Ozkara,Qianlin Liang,Jesse Milzman,Prashant Shenoy,Suhas Diggavi*

Main category: cs.LG

TL;DR: 论文提出了一种名为MEL的多级集成学习框架，用于在边缘计算环境中实现低延迟、高准确性的容错推理。


<details>
  <summary>Details</summary>
Motivation: 边缘计算环境资源有限且易发生故障，传统容错方法（如云故障转移或压缩备份）通常牺牲延迟或准确性，无法满足关键边缘推理服务的需求。

Method: MEL通过同时训练多个轻量级备份模型，这些模型能够协作运行或在故障时独立运行，并通过多目标优化问题确保模型多样性和独立性能。

Result: 实验表明，MEL在视觉、语言和音频数据集上表现接近原始架构，同时提供容错能力和部署灵活性。集成模型大小仅为原模型的40%，在故障情况下仍保持95.6%的准确率。

Conclusion: MEL为边缘推理提供了一种高效、灵活的容错解决方案，平衡了性能与资源限制。

Abstract: AI inference at the edge is becoming increasingly common for low-latency
services. However, edge environments are power- and resource-constrained, and
susceptible to failures. Conventional failure resilience approaches, such as
cloud failover or compressed backups, often compromise latency or accuracy,
limiting their effectiveness for critical edge inference services. In this
paper, we propose Multi-Level Ensemble Learning (MEL), a new framework for
resilient edge inference that simultaneously trains multiple lightweight backup
models capable of operating collaboratively, refining each other when multiple
servers are available, and independently under failures while maintaining good
accuracy. Specifically, we formulate our approach as a multi-objective
optimization problem with a loss formulation that inherently encourages
diversity among individual models to promote mutually refining representations,
while ensuring each model maintains good standalone performance. Empirical
evaluations across vision, language, and audio datasets show that MEL provides
performance comparable to original architectures while also providing fault
tolerance and deployment flexibility across edge platforms. Our results show
that our ensemble model, sized at 40\% of the original model, achieves similar
performance, while preserving 95.6\% of ensemble accuracy in the case of
failures when trained using MEL.

</details>


### [123] [High-Resolution Live Fuel Moisture Content (LFMC) Maps for Wildfire Risk from Multimodal Earth Observation Data](https://arxiv.org/abs/2506.20132)
*Patrick Alan Johnson,Gabriel Tseng,Yawen Zhang,Heather Heward,Virginia Sjahli,Favyen Bastani,Joseph Redmon,Patrick Beukema*

Main category: cs.LG

TL;DR: 利用预训练的多模态地球观测模型生成大范围、空间完整的LFMC地图，显著降低RMSE，并开发自动化管道快速生成美国范围内的LFMC地图。


<details>
  <summary>Details</summary>
Motivation: 地面LFMC样本采集成本高且更新稀疏，需要高效、低成本的监测方法以支持野火研究和应急响应。

Method: 采用预训练的多模态地球观测模型，生成大范围、空间完整的LFMC地图，并通过自动化管道实现快速更新。

Result: 相比随机初始化模型，RMSE降低20%，并在受野火影响的地区验证了有效性。

Conclusion: 该方法为野火风险监测提供了高效、低成本的解决方案，适用于大范围应用。

Abstract: Wildfires are increasing in intensity and severity at an alarming rate.
Recent advances in AI and publicly available satellite data enable monitoring
critical wildfire risk factors globally, at high resolution and low latency.
Live Fuel Moisture Content (LFMC) is a critical wildfire risk factor and is
valuable for both wildfire research and operational response. However,
ground-based LFMC samples are both labor intensive and costly to acquire,
resulting in sparse and infrequent updates. In this work, we explore the use of
a pretrained, highly-multimodal earth-observation model for generating
large-scale spatially complete (wall-to-wall) LFMC maps. Our approach achieves
significant improvements over previous methods using randomly initialized
models (20 reduction in RMSE). We provide an automated pipeline that enables
rapid generation of these LFMC maps across the United States, and demonstrate
its effectiveness in two regions recently impacted by wildfire (Eaton and
Palisades).

</details>


### [124] [Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks](https://arxiv.org/abs/2506.20181)
*Ronald Katende*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息神经网络和反事实扰动的PDE因果结构发现框架，通过功能干预量化算子级必要性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法如残差最小化或稀疏回归在PDE因果结构发现中存在局限性，需要更精确和可解释的方法。

Method: 引入因果敏感性指数和结构偏差度量，结合神经代理模型，通过功能干预评估候选微分算子的影响。

Result: 理论和实验验证了方法在噪声、冗余和数据稀缺下的有效性，优于标准PINNs和DeepONets。

Conclusion: 该框架将PDE因果发现定位为基于结构因果模型和变分残差分析的可解释推理任务。

Abstract: We develop a principled framework for discovering causal structure in partial
differential equations (PDEs) using physics-informed neural networks and
counterfactual perturbations. Unlike classical residual minimization or sparse
regression methods, our approach quantifies operator-level necessity through
functional interventions on the governing dynamics. We introduce causal
sensitivity indices and structural deviation metrics to assess the influence of
candidate differential operators within neural surrogates. Theoretically, we
prove exact recovery of the causal operator support under restricted isometry
or mutual coherence conditions, with residual bounds guaranteeing
identifiability. Empirically, we validate the framework on both synthetic and
real-world datasets across climate dynamics, tumor diffusion, and ocean flows.
Our method consistently recovers governing operators even under noise,
redundancy, and data scarcity, outperforming standard PINNs and DeepONets in
structural fidelity. This work positions causal PDE discovery as a tractable
and interpretable inference task grounded in structural causal models and
variational residual analysis.

</details>


### [125] [DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs](https://arxiv.org/abs/2506.20194)
*Ruokai Yin,Yuhang Li,Donghyun Lee,Priyadarshini Panda*

Main category: cs.LG

TL;DR: DuoGPT提出了一种结合权重剪枝和激活稀疏性的双稀疏框架，通过动态结构化权重稀疏性优化LLM部署，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）因高内存和计算成本难以部署，现有剪枝方法未充分利用运行时激活稀疏性。

Method: 将激活稀疏性重新解释为动态结构化权重稀疏性，结合非结构化权重剪枝构建双稀疏（spMspV）工作负载，并通过激活感知校准和密集模型输出残差校正保持精度。

Result: 在LLaMA-2和LLaMA-3上，DuoGPT在1.39倍加速下比基线密集模型准确率提升高达9.17%。

Conclusion: DuoGPT通过双稀疏框架和GPU优化，显著提升了LLM的部署效率和性能。

Abstract: Large language models (LLMs) deliver strong performance but are difficult to
deploy due to high memory and compute costs. While pruning reduces these
demands, most methods ignore activation sparsity observed at runtime. We
reinterpret activation sparsity as dynamic structured weight sparsity and
propose DuoGPT, a unified framework that constructs dual-sparse (spMspV)
workloads by combining unstructured weight pruning with activation sparsity. To
preserve accuracy, we extend the Optimal Brain Compression (OBC) framework with
activation-aware calibration and introduce output residuals from the dense
model as correction terms. We further optimize the solution for efficient GPU
execution, enabling scalability to billion-parameter LLMs. Evaluations on
LLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured
pruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\times$
compared to the baseline dense model.

</details>


### [126] [Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach](https://arxiv.org/abs/2506.20197)
*Clément L. Canonne,Yash Pote,Uddalok Sarkar*

Main category: cs.LG

TL;DR: 论文提出了一种名为Anubis的零样本归属工具，通过假设检验将代码归属问题转化为分布测试问题，利用LLM的样本和密度估计实现高效归属。


<details>
  <summary>Details</summary>
Motivation: 随着大量代码由大型语言模型生成，如何准确归属代码来源成为一个重要问题。论文旨在解决这一问题，利用假设检验技术提供可靠的归属方法。

Method: 提出Anubis工具，将归属问题视为分布测试问题，结合LLM的样本和密度估计，避免维度灾难。

Result: 实验表明，Anubis在区分不同LLM（如DeepSeek-Coder、CodeGemma和Stable-Code）时，仅需约2000个样本即可达到高AUROC（≥0.9）。

Conclusion: Anubis是一种高效的零样本归属工具，适用于代码来源归属问题，具有实际应用潜力。

Abstract: A growing fraction of all code is sampled from Large Language Models (LLMs).
We investigate the problem of attributing code generated by language models
using hypothesis testing to leverage established techniques and guarantees.
Given a set of samples $S$ and a suspect model $\mathcal{L}^*$, our goal is to
assess the likelihood of $S$ originating from $\mathcal{L}^*$. Due to the curse
of dimensionality, this is intractable when only samples from the LLM are
given: to circumvent this, we use both samples and density estimates from the
LLM, a form of access commonly available.
  We introduce $\mathsf{Anubis}$, a zero-shot attribution tool that frames
attribution as a distribution testing problem. Our experiments on a benchmark
of code samples show that $\mathsf{Anubis}$ achieves high AUROC scores (
$\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and
Stable-Code using only $\approx 2000$ samples.

</details>


### [127] [Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets](https://arxiv.org/abs/2506.20204)
*Eduardo Gutierrez Maestro,Hadi Banaee,Amy Loutfi*

Main category: cs.LG

TL;DR: 该研究提出了一种数据驱动的方法（APS）来检测情感计算中受启动效应影响的数据点，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 情感计算中启动效应的模糊性挑战尚未从数据层面充分探索，可能导致模型误分类。

Method: 提出Affective Priming Score (APS)方法，量化数据点受启动效应影响的程度，并在SEED和SEED-VII数据集上验证。

Result: 使用去启动效应的数据序列显著降低了模型的误分类率。

Conclusion: 该研究通过数据层面的启动效应识别与缓解，提升了模型鲁棒性，为情感计算数据集的设计与收集提供了新见解。

Abstract: Affective priming exemplifies the challenge of ambiguity in affective
computing. While the community has largely addressed this issue from a
label-based perspective, identifying data points in the sequence affected by
the priming effect, the impact of priming on data itself, particularly in
physiological signals, remains underexplored. Data affected by priming can lead
to misclassifications when used in learning models. This study proposes the
Affective Priming Score (APS), a data-driven method to detect data points
influenced by the priming effect. The APS assigns a score to each data point,
quantifying the extent to which it is affected by priming. To validate this
method, we apply it to the SEED and SEED-VII datasets, which contain sufficient
transitions between emotional events to exhibit priming effects. We train
models with the same configuration using both the original data and
priming-free sequences. The misclassification rate is significantly reduced
when using priming-free sequences compared to the original data. This work
contributes to the broader challenge of ambiguity by identifying and mitigating
priming effects at the data level, enhancing model robustness, and offering
valuable insights for the design and collection of affective computing
datasets.

</details>


### [128] [Directed Link Prediction using GNN with Local and Global Feature Fusion](https://arxiv.org/abs/2506.20235)
*Yuyang Zhang,Xu Shen,Yu Xie,Ka-Chun Wong,Weidun Xie,Chengbin Peng*

Main category: cs.LG

TL;DR: 提出了一种融合特征嵌入与社区信息的图神经网络框架，用于有向链接预测，并通过实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决有向图中链接预测问题，通过结合特征嵌入与社区信息提升性能。

Method: 提出新型GNN框架，融合特征嵌入与社区信息，并将输入图转化为有向线图以增强信息聚合。

Result: 在多个基准数据集上，使用不同比例的训练数据时，性能优于现有方法。

Conclusion: 融合特征嵌入与社区信息的GNN框架能有效提升有向链接预测的性能。

Abstract: Link prediction is a classical problem in graph analysis with many practical
applications. For directed graphs, recently developed deep learning approaches
typically analyze node similarities through contrastive learning and aggregate
neighborhood information through graph convolutions. In this work, we propose a
novel graph neural network (GNN) framework to fuse feature embedding with
community information. We theoretically demonstrate that such hybrid features
can improve the performance of directed link prediction. To utilize such
features efficiently, we also propose an approach to transform input graphs
into directed line graphs so that nodes in the transformed graph can aggregate
more information during graph convolutions. Experiments on benchmark datasets
show that our approach outperforms the state-of-the-art in most cases when 30%,
40%, 50%, and 60% of the connected links are used as training data,
respectively.

</details>


### [129] [FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data](https://arxiv.org/abs/2506.20245)
*Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu*

Main category: cs.LG

TL;DR: 论文提出了一种名为FedBKD的无数据蒸馏框架，通过生成对抗网络（GAN）合成数据，实现全局和局部模型之间的双向知识蒸馏，解决了联邦学习中非独立同分布数据的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中非独立同分布数据的问题，同时避免引入公共数据集导致的数据泄漏风险。

Method: 使用GAN生成合成数据，局部模型作为判别器，冻结其参数，通过双向蒸馏实现全局和局部模型的知识交互。

Result: 在4个基准测试中，FedBKD在不同非独立同分布设置下均达到最优性能。

Conclusion: FedBKD能够同时提升全局和局部模型的性能，且无需依赖公共数据集，降低了数据泄漏风险。

Abstract: Federated learning (FL) is a decentralized collaborative machine learning
(ML) technique. It provides a solution to the issues of isolated data islands
and data privacy leakage in industrial ML practices. One major challenge in FL
is handling the non-identical and independent distributed (non-IID) data.
Current solutions either focus on constructing an all-powerful global model, or
customizing personalized local models. Few of them can provide both a
well-generalized global model and well-performed local models at the same time.
Additionally, many FL solutions to the non-IID problem are benefited from
introducing public datasets. However, this will also increase the risk of data
leakage. To tackle the problems, we propose a novel data-free distillation
framework, Federated Bidirectional Knowledge Distillation (FedBKD).
Specifically, we train Generative Adversarial Networks (GAN) for synthetic
data. During the GAN training, local models serve as discriminators and their
parameters are frozen. The synthetic data is then used for bidirectional
distillation between global and local models to achieve knowledge interactions
so that performances for both sides are improved. We conduct extensive
experiments on 4 benchmarks under different non-IID settings. The results show
that FedBKD achieves SOTA performances in every case.

</details>


### [130] [Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models](https://arxiv.org/abs/2506.20251)
*Kejia Chen,Jiawen Zhang,Jiacong Hu,Yu Wang,Jian Lou,Zunlei Feng,Mingli Song*

Main category: cs.LG

TL;DR: 该论文研究了量化大型语言模型（LLMs）对安全性的影响，并提出了一种量化感知的安全补丁框架Q-resafe，以恢复量化LLMs的安全性。


<details>
  <summary>Details</summary>
Motivation: 量化LLMs在资源受限环境中部署具有重要意义，但现有研究表明量化可能损害其安全能力，因此需要系统性安全评估和缓解策略。

Method: 通过主流量化技术和多样化校准数据集进行安全性评估，并提出Q-resafe框架以恢复安全性。

Result: 实验表明Q-resafe成功将量化LLMs的安全性恢复到量化前水平。

Conclusion: Q-resafe是一种有效的解决方案，能够在保持实用性的同时恢复量化LLMs的安全性。

Abstract: Quantized large language models (LLMs) have gained increasing attention and
significance for enabling deployment in resource-constrained environments.
However, emerging studies on a few calibration dataset-free quantization
methods suggest that quantization may compromise the safety capabilities of
LLMs, underscoring the urgent need for systematic safety evaluations and
effective mitigation strategies. In this paper, we present comprehensive safety
evaluations across various mainstream quantization techniques and diverse
calibration datasets, utilizing widely accepted safety benchmarks. To address
the identified safety vulnerabilities, we propose a quantization-aware safety
patching framework, Q-resafe, to efficiently restore the safety capabilities of
quantized LLMs while minimizing any adverse impact on utility. Extensive
experimental results demonstrate that Q-resafe successfully re-aligns the
safety of quantized LLMs with their pre-quantization counterparts, even under
challenging evaluation scenarios. Project page is available at:
https://github.com/Thecommonirin/Qresafe.

</details>


### [131] [Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios](https://arxiv.org/abs/2506.20253)
*Ben Gerhards,Nikita Popkov,Annekatrin König,Marcel Arpogaus,Bastian Schäfermeier,Leonie Riedl,Stephan Vogt,Philip Hehlert*

Main category: cs.LG

TL;DR: 该论文比较了四种数据驱动方法（WGAN、DDPM、HMM、MABF）在生成用于长期电力消费预测的高保真合成时间序列数据方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于短期电力消费预测，而长期个体消费预测被忽视，且缺乏高保真合成数据用于系统规划等应用。

Method: 评估了四种方法（WGAN、DDPM、HMM、MABF）在复制电力消费时间动态、长程依赖和概率转移方面的能力。

Result: 比较分析揭示了各方法的优缺点，为能源相关任务（如状态估计）选择合适方法提供了依据。

Conclusion: 研究框架提升了合成电力消费数据的准确性和隐私保护能力，适用于实际应用。

Abstract: Forecasting attracts a lot of research attention in the electricity value
chain. However, most studies concentrate on short-term forecasting of
generation or consumption with a focus on systems and less on individual
consumers. Even more neglected is the topic of long-term forecasting of
individual power consumption.
  Here, we provide an in-depth comparative evaluation of data-driven methods
for generating synthetic time series data tailored to energy consumption
long-term forecasting. High-fidelity synthetic data is crucial for a wide range
of applications, including state estimations in energy systems or power grid
planning. In this study, we assess and compare the performance of multiple
state-of-the-art but less common techniques: a hybrid Wasserstein Generative
Adversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM),
Hidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial
normalizing Flows (MABF). We analyze the ability of each method to replicate
the temporal dynamics, long-range dependencies, and probabilistic transitions
characteristic of individual energy consumption profiles. Our comparative
evaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and
MABF aiding in selecting the most suitable approach for state estimations and
other energy-related tasks. Our generation and analysis framework aims to
enhance the accuracy and reliability of synthetic power consumption data while
generating data that fulfills criteria like anonymisation - preserving privacy
concerns mitigating risks of specific profiling of single customers. This study
utilizes an open-source dataset from households in Germany with 15min time
resolution. The generated synthetic power profiles can readily be used in
applications like state estimations or consumption forecasting.

</details>


### [132] [Argumentative Ensembling for Robust Recourse under Model Multiplicity](https://arxiv.org/abs/2506.20260)
*Junqi Jiang,Antonio Rago,Francesco Leofante,Francesca Toni*

Main category: cs.LG

TL;DR: 论文提出了一种名为“recourse-aware ensembling (RAE)”的方法，用于解决机器学习中模型多样性（MM）下反事实解释（CEs）的鲁棒性问题。通过计算论证方法，确保CEs在多模型下的有效性。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，模型多样性（MM）导致不同模型对同一输入可能产生不同的预测和反事实解释（CEs），这使得CEs的鲁棒性成为问题。

Method: 提出了一种基于计算论证的集成方法，通过显式表示模型与CEs之间的冲突，并利用论证语义解决冲突，确保CEs的鲁棒性。

Result: 理论分析表明，该方法在四种论证语义下均表现良好；实证研究验证了其满足六种理想性质。

Conclusion: 该方法有效解决了MM下CEs的鲁棒性问题，并支持对模型的偏好定制。

Abstract: In machine learning, it is common to obtain multiple equally performing
models for the same prediction task, e.g., when training neural networks with
different random seeds. Model multiplicity (MM) is the situation which arises
when these competing models differ in their predictions for the same input, for
which ensembling is often employed to determine an aggregation of the outputs.
Providing recourse recommendations via counterfactual explanations (CEs) under
MM thus becomes complex, since the CE may not be valid across all models, i.e.,
the CEs are not robust under MM. In this work, we formalise the problem of
providing recourse under MM, which we name recourse-aware ensembling (RAE). We
propose the idea that under MM, CEs for each individual model should be
considered alongside their predictions so that the aggregated prediction and
recourse are decided in tandem. Centred around this intuition, we introduce six
desirable properties for solutions to this problem. For solving RAE, we propose
a novel argumentative ensembling method which guarantees the robustness of CEs
under MM. Specifically, our method leverages computational argumentation to
explicitly represent the conflicts between models and counterfactuals regarding
prediction results and CE validity. It then uses argumentation semantics to
resolve the conflicts and obtain the final solution, in a manner which is
parametric to the chosen semantics. Our method also allows for the
specification of preferences over the models under MM, allowing further
customisation of the ensemble. In a comprehensive theoretical analysis, we
characterise the behaviour of argumentative ensembling with four different
argumentation semantics. We then empirically demonstrate the effectiveness of
our approach in satisfying desirable properties with eight instantiations of
our method. (Abstract is shortened for arXiv.)

</details>


### [133] [Distilling A Universal Expert from Clustered Federated Learning](https://arxiv.org/abs/2506.20285)
*Zeqi Leng,Chunxu Zhang,Guodong Long,Riting Xia,Bo Yang*

Main category: cs.LG

TL;DR: 本文提出了一种新的联邦学习框架，通过从多个集群知识中蒸馏出一个通用专家模型，解决了非独立同分布数据问题，并平衡了个性化和共享知识。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了集群间的共享信息，这些信息对所有联邦学习参与者具有通用价值。

Method: 框架分为三步：本地模型训练、集群特定模型聚合和通用专家蒸馏。

Result: 实验结果表明，该方法在各种场景下表现优异，能更有效地处理模型异构性。

Conclusion: 该方法通过平衡个性化和共享知识，推动了集群联邦学习的发展。

Abstract: Clustered Federated Learning (CFL) addresses the challenges posed by non-IID
data by training multiple group- or cluster-specific expert models. However,
existing methods often overlook the shared information across clusters, which
represents the generalizable knowledge valuable to all participants in the
Federated Learning (FL) system. To overcome this limitation, this paper
introduces a novel FL framework that distills a universal expert model from the
knowledge of multiple clusters. This universal expert captures globally shared
information across all clients and is subsequently distributed to each client
as the initialization for the next round of model training. The proposed FL
framework operates in three iterative steps: (1) local model training at each
client, (2) cluster-specific model aggregation, and (3) universal expert
distillation. This three-step learning paradigm ensures the preservation of
fine-grained non-IID characteristics while effectively incorporating shared
knowledge across clusters. Compared to traditional gradient-based aggregation
methods, the distillation-based model aggregation introduces greater
flexibility in handling model heterogeneity and reduces conflicts among
cluster-specific experts. Extensive experimental results demonstrate the
superior performance of the proposed method across various scenarios,
highlighting its potential to advance the state of CFL by balancing
personalized and shared knowledge more effectively.

</details>


### [134] [Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding](https://arxiv.org/abs/2506.20305)
*Kazuki Yoda,Kazuhiko Kawamoto,Hiroshi Kera*

Main category: cs.LG

TL;DR: 本文研究了基于学习的QR码解码，发现Transformer模型能够通过学习嵌入文本结构成功解码QR码，甚至超越理论纠错限制。


<details>
  <summary>Details</summary>
Motivation: 探索中等输入敏感性的学习函数，特别是在QR码解码中的应用。

Method: 使用Transformer模型进行QR码解码实验，分析其对数据位和纠错位的关注。

Result: Transformer模型能够超越理论纠错限制解码QR码，并能从英语训练数据泛化到其他语言和随机字符串。

Conclusion: Transformer模型在QR码解码中表现出独特的机制，不同于标准QR码阅读器。

Abstract: The hardness of learning a function that attains a target task relates to its
input-sensitivity. For example, image classification tasks are
input-insensitive as minor corruptions should not affect the classification
results, whereas arithmetic and symbolic computation, which have been recently
attracting interest, are highly input-sensitive as each input variable connects
to the computation results. This study presents the first learning-based Quick
Response (QR) code decoding and investigates learning functions of medium
sensitivity. Our experiments reveal that Transformers can successfully decode
QR codes, even beyond the theoretical error-correction limit, by learning the
structure of embedded texts. They generalize from English-rich training data to
other languages and even random strings. Moreover, we observe that the
Transformer-based QR decoder focuses on data bits while ignoring
error-correction bits, suggesting a decoding mechanism distinct from standard
QR code readers.

</details>


### [135] [Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration](https://arxiv.org/abs/2506.20307)
*Heyang Zhao,Xingrui Yu,David M. Bossens,Ivor W. Tsang,Quanquan Gu*

Main category: cs.LG

TL;DR: 提出了一种新的模仿学习算法ILDE，通过双重探索（乐观策略优化和好奇心驱动探索）提高样本效率并实现超越专家性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在有限演示下难以准确学习专家策略，且需探索环境以实现超越专家性能。

Method: ILDE算法结合乐观策略优化（奖励高不确定性状态-动作对）和好奇心驱动探索（偏离演示轨迹的状态）。

Result: 在Atari和MuJoCo任务中，ILDE在样本效率上优于现有算法，且用更少演示实现超越专家性能。

Conclusion: ILDE是一种不确定性正则化的策略优化方法，理论证明其遗憾增长为次线性。

Abstract: Imitation learning is a central problem in reinforcement learning where the
goal is to learn a policy that mimics the expert's behavior. In practice, it is
often challenging to learn the expert policy from a limited number of
demonstrations accurately due to the complexity of the state space. Moreover,
it is essential to explore the environment and collect data to achieve
beyond-expert performance. To overcome these challenges, we propose a novel
imitation learning algorithm called Imitation Learning with Double Exploration
(ILDE), which implements exploration in two aspects: (1) optimistic policy
optimization via an exploration bonus that rewards state-action pairs with high
uncertainty to potentially improve the convergence to the expert policy, and
(2) curiosity-driven exploration of the states that deviate from the
demonstration trajectories to potentially yield beyond-expert performance.
Empirically, we demonstrate that ILDE outperforms the state-of-the-art
imitation learning algorithms in terms of sample efficiency and achieves
beyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations
than in previous work. We also provide a theoretical justification of ILDE as
an uncertainty-regularized policy optimization method with optimistic
exploration, leading to a regret growing sublinearly in the number of episodes.

</details>


### [136] [Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach](https://arxiv.org/abs/2506.20323)
*Saundarya Subramaniam,Shalini Majumdar,Shantanu Nadar,Kaustubh Kulkarni*

Main category: cs.LG

TL;DR: 开发了一种基于AI的作物病害检测系统，比较了多种深度学习模型在迁移学习中的效果，验证准确率达95.76%。


<details>
  <summary>Details</summary>
Motivation: 帮助资源有限的农村农民通过AI技术改善作物健康管理，推动可持续农业。

Method: 使用EfficientNet、ResNet101、MobileNetV2和自定义CNN模型进行迁移学习比较。

Result: 系统验证准确率达95.76%，证明了迁移学习在农业中的潜力。

Conclusion: AI驱动的病害检测系统可有效支持农村农业实践，提升可持续性。

Abstract: This research presents the development of an Artificial Intelligence (AI) -
driven crop disease detection system designed to assist farmers in rural areas
with limited resources. We aim to compare different deep learning models for a
comparative analysis, focusing on their efficacy in transfer learning. By
leveraging deep learning models, including EfficientNet, ResNet101,
MobileNetV2, and our custom CNN, which achieved a validation accuracy of
95.76%, the system effectively classifies plant diseases. This research
demonstrates the potential of transfer learning in reshaping agricultural
practices, improving crop health management, and supporting sustainable farming
in rural environments.

</details>


### [137] [Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning](https://arxiv.org/abs/2506.20324)
*Torben Berndt,Benjamin Walker,Tiexin Qin,Jan Stühmer,Andrey Kormilitzin*

Main category: cs.LG

TL;DR: 论文提出了一种基于置换等变性的神经图控制微分方程（Permutation Equivariant Neural Graph CDEs），通过减少参数数量提升训练效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 动态图的复杂时序动态需要高效且泛化能力强的模型。

Method: 将Graph Neural CDEs扩展到置换等变函数空间，减少参数数量。

Result: 在模拟动态系统和真实任务中表现优异，尤其在插值和外推场景。

Conclusion: 置换等变神经图CDEs在保持表达能力的同时提升了效率和泛化能力。

Abstract: Dynamic graphs exhibit complex temporal dynamics due to the interplay between
evolving node features and changing network structures. Recently, Graph Neural
Controlled Differential Equations (Graph Neural CDEs) successfully adapted
Neural CDEs from paths on Euclidean domains to paths on graph domains. Building
on this foundation, we introduce Permutation Equivariant Neural Graph CDEs,
which project Graph Neural CDEs onto permutation equivariant function spaces.
This significantly reduces the model's parameter count without compromising
representational power, resulting in more efficient training and improved
generalisation. We empirically demonstrate the advantages of our approach
through experiments on simulated dynamical systems and real-world tasks,
showing improved performance in both interpolation and extrapolation scenarios.

</details>


### [138] [Producer-Fairness in Sequential Bundle Recommendation](https://arxiv.org/abs/2506.20329)
*Alexandre Rio,Marta Soare,Sihem Amer-Yahia*

Main category: cs.LG

TL;DR: 论文研究了顺序捆绑推荐中的公平性问题，提出了一种结合生产者公平性和捆绑质量的实时解决方案，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中需要确保不同商品组在推荐会话中获得公平的曝光机会，同时保持捆绑推荐的高质量。

Method: 提出了精确解决方案（适用于小规模问题）和三种启发式方法（质量优先、公平优先和自适应平衡）。

Result: 在三个真实数据集上的实验表明，这些方法能在不牺牲捆绑质量的前提下实现公平推荐。

Conclusion: 研究为顺序捆绑推荐中的公平性问题提供了实用的解决方案，并展示了不同方法在不同场景下的适用性。

Abstract: We address fairness in the context of sequential bundle recommendation, where
users are served in turn with sets of relevant and compatible items. Motivated
by real-world scenarios, we formalize producer-fairness, that seeks to achieve
desired exposure of different item groups across users in a recommendation
session. Our formulation combines naturally with building high quality bundles.
Our problem is solved in real time as users arrive. We propose an exact
solution that caters to small instances of our problem. We then examine two
heuristics, quality-first and fairness-first, and an adaptive variant that
determines on-the-fly the right balance between bundle fairness and quality.
Our experiments on three real-world datasets underscore the strengths and
limitations of each solution and demonstrate their efficacy in providing fair
bundle recommendations without compromising bundle quality.

</details>


### [139] [On the ability of Deep Neural Networks to Learn Granger Causality in Multi-Variate Time Series Data](https://arxiv.org/abs/2506.20347)
*Malik Shahid Sultan,Hernando Ombao*

Main category: cs.LG

TL;DR: 论文提出了一种基于深度学习的Granger因果关系（GC）估计新方法，通过模型不确定性和残差分布揭示GC结构，无需显式稀疏回归。


<details>
  <summary>Details</summary>
Motivation: 传统线性VAR模型在GC估计中受限于假设，而现有DNN方法将GC视为变量选择问题，未能充分利用预测能力。

Method: 利用深度神经网络联合建模时间序列，通过比较模型不确定性和残差分布（是否丢弃特定时间序列）来揭示GC结构。

Result: 研究表明，经过良好正则化的模型可以从数据中学习真实的GC结构，无需显式稀疏回归。

Conclusion: 深度学习方法可以更自然地捕捉GC结构，为GC估计提供了新视角。

Abstract: Granger Causality (GC) offers an elegant statistical framework to study the
association between multivariate time series data. Linear Vector Autoregressive
models (VAR) though have nice interpretation properties but have limited
practical application due to underlying assumptions on the kind of associations
that can be captured by these models. Numerous attempts have already been made
in the literature that exploit the functional approximation power of Deep
Neural Networks (DNNs) for the task of GC estimation. These methods however
treat GC as a variable selection problem. We present a novel paradigm for
approaching GC. We present this idea that GC is essentially linked with
prediction and if a deep learning model is used to model the time series
collectively or jointly, a well regularized model may learn the true granger
causal structure from the data, given that there is enough training data. We
propose to uncover the learned GC structure by comparing the model uncertainty
or distribution of the residuals when the past of everything is used as
compared to the one where a specific time series component is dropped from the
model. We also compare the effect of input layer dropout on the ability of a
neural network to learn granger causality from the data. We show that a well
regularized model infact can learn the true GC structure from the data without
explicitly adding terms in the loss function that guide the model to select
variables or perform sparse regression.

</details>


### [140] [DipSVD: Dual-importance Protected SVD for Efficient LLM Compression](https://arxiv.org/abs/2506.20353)
*Xuan Ding,Rui Sun,Yunjian Zhang,Xiu Yan,Yueqi Zhou,Kaihao Huang,Suzhong Fu,Chuanlong Xie,Yao Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种双级重要性保护机制（DipSVD），通过局部和全局重要性保护，优化SVD压缩方法，显著提升压缩模型的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的计算需求和部署成本不断增加，现有SVD压缩方法忽视矩阵关键组件的保护，导致压缩模型性能下降。

Method: 提出双级重要性保护机制：局部保护通过通道加权数据白化保留关键奇异向量；全局保护通过启发式或优化方法分配压缩负担。

Result: DipSVD在多个基准测试中优于现有SVD压缩方法，尤其在高压缩比下表现更优。

Conclusion: DipSVD通过保护关键组件，显著提升了SVD压缩方法的性能，适用于高压缩比场景。

Abstract: The ever-increasing computational demands and deployment costs of large
language models (LLMs) have spurred numerous compressing methods. Compared to
quantization and unstructured pruning, SVD compression offers superior hardware
compatibility and theoretical guarantees. However, existing SVD-based methods
focus on the overall discrepancy between the original and compressed matrices
while overlooking the protection of critical components within the matrix,
which leads to inferior performance in the compressed models. This paper
proposes a dual-level importance protection mechanism to enhance SVD-based
compression methods: (1) local importance protection: preserving the most
critical singular vectors within each weight matrix through channel-weighted
data whitening; and (2) global importance protection: enabling less important
layers to bear a greater portion of the compression burden through either a
heuristic or optimization-based approach, thereby minimizing the impact of
compression on critical layers. Extensive experiments demonstrate that DipSVD
outperforms existing SVD-based compression approaches across multiple
benchmarks, achieving superior model performance especially at high model
compression ratios.

</details>


### [141] [A foundation model with multi-variate parallel attention to generate neuronal activity](https://arxiv.org/abs/2506.20354)
*Francesco Carzaniga,Michael Hersche,Abu Sebastian,Kaspar Schindler,Abbas Rahimi*

Main category: cs.LG

TL;DR: 提出了一种多变量并行注意力机制（MVPA）和MVPFormer模型，用于处理多变量时间序列数据，特别是在iEEG领域，解决了通道配置异构性问题。


<details>
  <summary>Details</summary>
Motivation: 解决多变量时间序列数据中通道配置异构性对深度神经网络的挑战，特别是在临床iEEG领域。

Method: 引入MVPA机制，分离内容、时间和空间注意力，构建MVPFormer模型，并发布SWEC iEEG数据集。

Result: MVPFormer在多个数据集上表现优异，达到专家级癫痫检测性能，并在标准时间序列任务上匹配或超越现有模型。

Conclusion: MVPA是一种通用的异构时间序列注意力机制，MVPFormer是首个开源、开放权重的iEEG基础模型，具有先进的临床性能。

Abstract: Learning from multi-variate time-series with heterogeneous channel
configurations remains a fundamental challenge for deep neural networks (DNNs),
particularly in clinical domains such as intracranial electroencephalography
(iEEG), where channel setups vary widely across subjects. In this work, we
introduce multi-variate parallel attention (MVPA), a novel self-attention
mechanism that disentangles content, temporal, and spatial attention, enabling
flexible, generalizable, and efficient modeling of time-series data with
varying channel counts and configurations. We use MVPA to build MVPFormer, a
generative foundation model for human electrophysiology, trained to predict the
evolution of iEEG signals across diverse subjects. To support this and future
effort by the community, we release the SWEC iEEG dataset, the largest publicly
available iEEG dataset to date, comprising nearly 10,000 hours of recordings
from heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong
generalization across subjects, demonstrating expert-level performance in
seizure detection and outperforming state-of-the-art Transformer baselines on
our SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard
time-series forecasting and classification tasks, where it matches or exceeds
existing attention-based models. Together, our contributions establish MVPA as
a general-purpose attention mechanism for heterogeneous time-series and
MVPFormer as the first open-source, open-weights, and open-data iEEG foundation
model with state-of-the-art clinical performance. The code is available at
https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG
dataset is available at
https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.

</details>


### [142] [Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach](https://arxiv.org/abs/2506.20359)
*Chanuka Don Samarasinghage,Dhruv Gulabani*

Main category: cs.LG

TL;DR: 论文提出了一种基于分类学的特征选择方法，用于解决轨迹分析中的高维特征爆炸问题，提高模型效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 轨迹分析中高维特征导致模型效率降低和可解释性下降，需要一种有效的特征选择方法。

Method: 提出基于分类学的特征选择方法，将特征分为几何和运动学两类，并进一步细分为曲率、凹陷、速度和加速度。

Result: 分类学方法在预测性能上表现优异，显著减少特征选择时间，并提供了对数据集敏感性的洞察。

Conclusion: 分类学方法能降低维度、提高可解释性，为轨迹数据集研究提供方法论框架，推动可解释人工智能发展。

Abstract: Trajectory analysis is not only about obtaining movement data, but it is also
of paramount importance in understanding the pattern in which an object moves
through space and time, as well as in predicting its next move. Due to the
significant interest in the area, data collection has improved substantially,
resulting in a large number of features becoming available for training and
predicting models. However, this introduces a high-dimensionality-induced
feature explosion problem, which reduces the efficiency and interpretability of
the data, thereby reducing the accuracy of machine learning models. To overcome
this issue, feature selection has become one of the most prevalent tools. Thus,
the objective of this paper was to introduce a taxonomy-based feature selection
method that categorizes features based on their internal structure. This
approach classifies the data into geometric and kinematic features, further
categorizing them into curvature, indentation, speed, and acceleration. The
comparative analysis indicated that a taxonomy-based approach consistently
achieved comparable or superior predictive performance. Furthermore, due to the
taxonomic grouping, which reduces combinatorial space, the time taken to select
features was drastically reduced. The taxonomy was also used to gain insights
into what feature sets each dataset was more sensitive to. Overall, this study
provides robust evidence that a taxonomy-based feature selection method can add
a layer of interpretability, reduce dimensionality and computational
complexity, and contribute to high-level decision-making. It serves as a step
toward providing a methodological framework for researchers and practitioners
dealing with trajectory datasets and contributing to the broader field of
explainable artificial intelligence.

</details>


### [143] [Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations](https://arxiv.org/abs/2506.20362)
*Lorenzo Bini,Stephane Marchand-Maillet*

Main category: cs.LG

TL;DR: LaplaceGNN是一种无需负采样的自监督图学习框架，通过谱自举技术实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 传统图学习方法依赖负采样或手工增强，效率低且复杂。LaplaceGNN旨在简化流程并提升性能。

Method: 结合拉普拉斯信号和谱增强，采用对抗性自举训练方案，实现正对齐学习。

Result: 在多个基准数据集上优于现有自监督图学习方法。

Conclusion: LaplaceGNN为高效学习图表示提供了新方向。

Abstract: We present LaplaceGNN, a novel self-supervised graph learning framework that
bypasses the need for negative sampling by leveraging spectral bootstrapping
techniques. Our method integrates Laplacian-based signals into the learning
process, allowing the model to effectively capture rich structural
representations without relying on contrastive objectives or handcrafted
augmentations. By focusing on positive alignment, LaplaceGNN achieves linear
scaling while offering a simpler, more efficient, self-supervised alternative
for graph neural networks, applicable across diverse domains. Our contributions
are twofold: we precompute spectral augmentations through max-min
centrality-guided optimization, enabling rich structural supervision without
relying on handcrafted augmentations, then we integrate an adversarial
bootstrapped training scheme that further strengthens feature learning and
robustness. Our extensive experiments on different benchmark datasets show that
LaplaceGNN achieves superior performance compared to state-of-the-art
self-supervised graph methods, offering a promising direction for efficiently
learning expressive graph representations.

</details>


### [144] [MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations](https://arxiv.org/abs/2506.20100)
*Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve*

Main category: cs.LG

TL;DR: MIRAGE是一个用于多模态专家级推理和决策的新基准，专注于农业领域，结合自然用户查询、专家回答和图像上下文，评估模型的推理、澄清策略和长文本生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准通常依赖明确输入和封闭分类，无法满足真实世界中复杂、开放场景的需求。MIRAGE旨在填补这一空白，提供高保真度的评估工具。

Method: 基于35,000+真实用户-专家交互数据，通过多步骤流程构建，涵盖作物健康、害虫诊断和管理场景，包含7,000+生物实体。

Result: MIRAGE成为视觉语言模型中分类最多样化的基准之一，支持开放世界场景和罕见实体处理。

Conclusion: MIRAGE为知识密集型领域的多模态模型提供了更真实的评估环境，推动了复杂推理和交互能力的研究。

Abstract: We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning
and decision-making in consultative interaction settings. Designed for the
agriculture domain, MIRAGE captures the full complexity of expert consultations
by combining natural user queries, expert-authored responses, and image-based
context, offering a high-fidelity benchmark for evaluating models on grounded
reasoning, clarification strategies, and long-form generation in a real-world,
knowledge-intensive domain. Grounded in over 35,000 real user-expert
interactions and curated through a carefully designed multi-step pipeline,
MIRAGE spans diverse crop health, pest diagnosis, and crop management
scenarios. The benchmark includes more than 7,000 unique biological entities,
covering plant species, pests, and diseases, making it one of the most
taxonomically diverse benchmarks available for vision-language models, grounded
in the real world. Unlike existing benchmarks that rely on well-specified user
inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich
scenarios with open-world settings, requiring models to infer latent knowledge
gaps, handle rare entities, and either proactively guide the interaction or
respond. Project Page: https://mirage-benchmark.github.io

</details>


### [145] [TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis](https://arxiv.org/abs/2506.20380)
*Zhengpeng Feng,Sadiq Jaffer,Jovana Knezevic,Silja Sormunen,Robin Young,Madeline Lisaius,Markus Immitzer,James Ball,Clement Atzberger,David A. Coomes,Anil Madhavapeddy,Andrew Blake,Srinivasan Keshav*

Main category: cs.LG

TL;DR: TESSERA是一种新型遥感基础模型，通过自监督学习从卫星时间序列数据生成全球10米尺度的稳健表示，结合光学和SAR数据，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 卫星遥感在气候建模、碳核算等领域有广泛应用，但需要高性能、高分辨率的表示方法。

Method: TESSERA使用两个并行Transformer编码器分别处理Sentinel-1 SAR和Sentinel-2 MSI数据，通过MLP融合生成全球表示。

Result: TESSERA在五项任务中表现优于传统遥感基线和领先的地理空间基础模型。

Conclusion: TESSERA为高分辨率遥感表示提供了开源解决方案，性能领先。

Abstract: Satellite remote sensing (RS) enables a wide array of downstream Earth
observation (EO) applications, including climate modeling, carbon accounting,
and strategies for conservation and sustainable land use. We present TESSERA, a
novel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning
(SSL) to generate global, robust representations at 10m scale from pixel-level
satellite time series data. TESSERA combines information from only optical and
SAR data streams using two parallel Transformer-based encoders: one dedicated
to Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected
spectral bands) to create representations that are then fused using a
multilayer perceptron (MLP), resulting in a global representation map covering
the years 2017 to 2024. Our precomputed representations set a new
state-of-the-art performance benchmark and our open-source approach
democratizes access to high-performance, high-resolution representations. We
benchmark the performance of TESSERA in five diverse tasks, comparing our work
with state-of-the-art task-specific models and other foundation models. Our
results show that TESSERA outperforms both traditional RS baselines and the
leading geospatial foundation models in these diverse downstream tasks.

</details>


### [146] [Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning](https://arxiv.org/abs/2506.20413)
*Mohammad Mahdi Maheri,Denys Herasymuk,Hamed Haddadi*

Main category: cs.LG

TL;DR: P4是一种针对资源受限物联网设备的个性化学习方法，通过去中心化算法确保隐私和抗攻击性，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: AI在IoT中的广泛应用需要高效、隐私保护的个性化学习方法，但去中心化环境下的知识转移、隐私保护和抗攻击性仍是挑战。

Method: P4采用轻量级去中心化算法，通过差分隐私知识蒸馏在协作组内共同训练模型，确保隐私和抗攻击性。

Result: P4在多种异构和攻击场景下比现有方法准确率高5%至30%，并能容忍30%的恶意客户端。

Conclusion: P4为资源受限设备提供了一种高效、隐私保护且抗攻击的个性化学习解决方案。

Abstract: The growing adoption of Artificial Intelligence (AI) in Internet of Things
(IoT) ecosystems has intensified the need for personalized learning methods
that can operate efficiently and privately across heterogeneous,
resource-constrained devices. However, enabling effective personalized learning
in decentralized settings introduces several challenges, including efficient
knowledge transfer between clients, protection of data privacy, and resilience
against poisoning attacks. In this paper, we address these challenges by
developing P4 (Personalized, Private, Peer-to-Peer) -- a method designed to
deliver personalized models for resource-constrained IoT devices while ensuring
differential privacy and robustness against poisoning attacks. Our solution
employs a lightweight, fully decentralized algorithm to privately detect client
similarity and form collaborative groups. Within each group, clients leverage
differentially private knowledge distillation to co-train their models,
maintaining high accuracy while ensuring robustness to the presence of
malicious clients. We evaluate P4 on popular benchmark datasets using both
linear and CNN-based architectures across various heterogeneity settings and
attack scenarios. Experimental results show that P4 achieves 5% to 30% higher
accuracy than leading differentially private peer-to-peer approaches and
maintains robustness with up to 30% malicious clients. Additionally, we
demonstrate its practicality by deploying it on resource-constrained devices,
where collaborative training between two clients adds only ~7 seconds of
overhead.

</details>


### [147] [Off-Policy Evaluation and Learning for the Future under Non-Stationarity](https://arxiv.org/abs/2506.20417)
*Tatsuhiro Shimizu,Kazuki Kawamura,Takanori Muroi,Yusuke Narita,Kei Tateno,Takuma Udagawa,Yuta Saito*

Main category: cs.LG

TL;DR: 论文提出了一种名为OPFV的新估计器，用于在非平稳环境中准确估计和优化未来策略价值，利用时间序列数据中的结构信息，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在非平稳环境中（如电子商务推荐系统），现有方法因假设平稳性或依赖限制性奖励建模假设而产生显著偏差，无法准确估计未来策略价值。

Method: 提出OPFV估计器，通过新型重要性加权利用时间序列数据中的结构（如季节性、周效应等），并扩展为策略梯度方法以优化未来策略。

Result: 理论分析表明OPFV在特定条件下具有低偏差，实验结果显示其在非平稳环境中显著优于现有方法。

Conclusion: OPFV为未来策略评估和学习提供了有效工具，尤其在非平稳环境中表现优异。

Abstract: We study the novel problem of future off-policy evaluation (F-OPE) and
learning (F-OPL) for estimating and optimizing the future value of policies in
non-stationary environments, where distributions vary over time. In e-commerce
recommendations, for instance, our goal is often to estimate and optimize the
policy value for the upcoming month using data collected by an old policy in
the previous month. A critical challenge is that data related to the future
environment is not observed in the historical data. Existing methods assume
stationarity or depend on restrictive reward-modeling assumptions, leading to
significant bias. To address these limitations, we propose a novel estimator
named \textit{\textbf{O}ff-\textbf{P}olicy Estimator for the \textbf{F}uture
\textbf{V}alue (\textbf{\textit{OPFV}})}, designed for accurately estimating
policy values at any future time point. The key feature of OPFV is its ability
to leverage the useful structure within time-series data. While future data
might not be present in the historical log, we can leverage, for example,
seasonal, weekly, or holiday effects that are consistent in both the historical
and future data. Our estimator is the first to exploit these time-related
structures via a new type of importance weighting, enabling effective F-OPE.
Theoretical analysis identifies the conditions under which OPFV becomes
low-bias. In addition, we extend our estimator to develop a new policy-gradient
method to proactively learn a good future policy using only historical data.
Empirical results show that our methods substantially outperform existing
methods in estimating and optimizing the future policy value under
non-stationarity for various experimental setups.

</details>


### [148] [Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation](https://arxiv.org/abs/2506.20431)
*Xing Ma*

Main category: cs.LG

TL;DR: 提出了一种名为KDIA的知识蒸馏策略，针对大规模客户端中仅部分参与训练的联邦学习场景，通过教师-学生不平等聚合和生成IID数据特征，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中因客户端标签倾斜、数据量倾斜等异构性问题导致的性能下降，特别是在大规模客户端中仅部分参与训练的挑战性场景。

Method: 采用教师-学生不平等聚合（KDIA），学生模型为参与客户端的平均聚合，教师模型为基于参与频率、参与次数和数据量比例的加权聚合；结合本地自知识蒸馏和服务器生成IID数据特征辅助训练。

Result: 在CIFAR-10/100/CINIC-10数据集及多种异构设置下，KDIA能以更少训练轮次获得更高准确率，且在严重异构性下改进更显著。

Conclusion: KDIA是一种高效的联邦学习策略，特别适用于大规模客户端中部分参与的场景，能有效利用所有客户端知识提升模型性能。

Abstract: Federated learning aims to train a global model in a distributed environment
that is close to the performance of centralized training. However, issues such
as client label skew, data quantity skew, and other heterogeneity problems
severely degrade the model's performance. Most existing methods overlook the
scenario where only a small portion of clients participate in training within a
large-scale client setting, whereas our experiments show that this scenario
presents a more challenging federated learning task. Therefore, we propose a
Knowledge Distillation with teacher-student Inequitable Aggregation (KDIA)
strategy tailored to address the federated learning setting mentioned above,
which can effectively leverage knowledge from all clients. In KDIA, the student
model is the average aggregation of the participating clients, while the
teacher model is formed by a weighted aggregation of all clients based on three
frequencies: participation intervals, participation counts, and data volume
proportions. During local training, self-knowledge distillation is performed.
Additionally, we utilize a generator trained on the server to generate
approximately independent and identically distributed (IID) data features
locally for auxiliary training. We conduct extensive experiments on the
CIFAR-10/100/CINIC-10 datasets and various heterogeneous settings to evaluate
KDIA. The results show that KDIA can achieve better accuracy with fewer rounds
of training, and the improvement is more significant under severe
heterogeneity.

</details>


### [149] [Méthode de quadrature pour les PINNs fondée théoriquement sur la hessienne des résiduels](https://arxiv.org/abs/2506.20441)
*Antoine Caradot,Rémi Emonet,Amaury Habrard,Abdel-Rahim Mezidi,Marc Sebban*

Main category: cs.LG

TL;DR: 本文提出了一种基于Hessian矩阵的积分方法，用于优化PINNs中配点的选择。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs中配点均匀采样，效率不高，需改进配点选择方法以提高求解精度。

Method: 提出基于Hessian矩阵的积分方法，用于指导PINNs训练过程中配点的选择。

Result: 新方法能更高效地选择配点，提升PINNs的求解性能。

Conclusion: 基于Hessian的积分方法为PINNs配点选择提供了新思路，具有潜在应用价值。

Abstract: Physics-informed Neural Networks (PINNs) have emerged as an efficient way to
learn surrogate neural solvers of PDEs by embedding the physical model in the
loss function and minimizing its residuals using automatic differentiation at
so-called collocation points. Originally uniformly sampled, the choice of the
latter has been the subject of recent advances leading to adaptive sampling
refinements. In this paper, we propose a new quadrature method for
approximating definite integrals based on the hessian of the considered
function, and that we leverage to guide the selection of the collocation points
during the training process of PINNs.

</details>


### [150] [Automatic Demonstration Selection for LLM-based Tabular Data Classification](https://arxiv.org/abs/2506.20451)
*Shuchu Han,Wolfgang Bruckner*

Main category: cs.LG

TL;DR: 提出一种基于谱图理论的算法，自动选择适合表格数据分类的上下文学习演示数量。


<details>
  <summary>Details</summary>
Motivation: 解决在表格数据分类中如何确定上下文学习演示数量的挑战。

Method: 结合数据分布、用户选择的提示模板和特定大语言模型，利用谱图理论量化演示相似性，构建相似图并通过拉普拉斯矩阵特征值分析确定最小演示数量。

Result: 实验验证了该方法在多样数据集和大语言模型上优于传统随机选择算法。

Conclusion: 该算法能有效确定上下文学习中的演示数量，提升分类性能。

Abstract: A fundamental question in applying In-Context Learning (ICL) for tabular data
classification is how to determine the ideal number of demonstrations in the
prompt. This work addresses this challenge by presenting an algorithm to
automatically select a reasonable number of required demonstrations. Our method
distinguishes itself by integrating not only the tabular data's distribution
but also the user's selected prompt template and the specific Large Language
Model (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed
algorithm defines a novel metric to quantify the similarities between different
demonstrations. We then construct a similarity graph and analyze the
eigenvalues of its Laplacian to derive the minimum number of demonstrations
capable of representing the data within the LLM's intrinsic representation
space. We validate the efficacy of our approach through experiments comparing
its performance against conventional random selection algorithms on diverse
datasets and LLMs.

</details>


### [151] [Counterfactual Influence as a Distributional Quantity](https://arxiv.org/abs/2506.20481)
*Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye*

Main category: cs.LG

TL;DR: 研究探讨了机器学习模型记忆训练数据的机制，指出仅依赖自影响（self-influence）会低估记忆化风险，需考虑完整影响分布。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型记忆训练数据引发隐私和泛化问题，现有研究多关注自影响，但忽略了其他样本（如重复样本）的影响。

Method: 通过计算训练样本间的完整影响分布，分析其对记忆化的作用，并在小语言模型和CIFAR-10图像分类任务中验证。

Result: 发现仅关注自影响会低估风险，重复样本显著降低自影响但仍可被提取；影响分布能揭示重复样本的存在。

Conclusion: 记忆化是训练数据间复杂互动的结果，完整影响分布比自影响更能准确捕捉其机制。

Abstract: Machine learning models are known to memorize samples from their training
data, raising concerns around privacy and generalization. Counterfactual
self-influence is a popular metric to study memorization, quantifying how the
model's prediction for a sample changes depending on the sample's inclusion in
the training dataset. However, recent work has shown memorization to be
affected by factors beyond self-influence, with other training samples, in
particular (near-)duplicates, having a large impact. We here study memorization
treating counterfactual influence as a distributional quantity, taking into
account how all training samples influence how a sample is memorized. For a
small language model, we compute the full influence distribution of training
samples on each other and analyze its properties. We find that solely looking
at self-influence can severely underestimate tangible risks associated with
memorization: the presence of (near-)duplicates seriously reduces
self-influence, while we find these samples to be (near-)extractable. We
observe similar patterns for image classification, where simply looking at the
influence distributions reveals the presence of near-duplicates in CIFAR-10.
Our findings highlight that memorization stems from complex interactions across
training data and is better captured by the full influence distribution than by
self-influence alone.

</details>


### [152] [Multimodal Representation Learning and Fusion](https://arxiv.org/abs/2506.20494)
*Qihang Jin,Enze Ge,Yuhang Xie,Hongying Luo,Junhao Song,Ziqian Bi,Chia Xin Liang,Jibin Guan,Joe Yeong,Junfeng Hao*

Main category: cs.LG

TL;DR: 多模态学习是人工智能中快速发展的领域，通过结合图像、文本和音频等信息，帮助机器理解复杂事物，提升解释、推理和决策能力。


<details>
  <summary>Details</summary>
Motivation: 多模态学习旨在利用不同模态的优势，构建更强、更丰富的内部表示，以应对现实世界的复杂性。

Method: 核心方法包括表示学习、对齐方法和融合策略，同时探索无监督或半监督学习、AutoML工具等新方法。

Result: 尽管取得进展，但仍需解决数据格式差异、输入缺失和对抗攻击等问题。

Conclusion: 多模态学习有望推动计算机视觉、自然语言处理等领域发展，未来或能构建更接近人类理解的AI系统。

Abstract: Multi-modal learning is a fast growing area in artificial intelligence. It
tries to help machines understand complex things by combining information from
different sources, like images, text, and audio. By using the strengths of each
modality, multi-modal learning allows AI systems to build stronger and richer
internal representations. These help machines better interpretation, reasoning,
and making decisions in real-life situations. This field includes core
techniques such as representation learning (to get shared features from
different data types), alignment methods (to match information across
modalities), and fusion strategies (to combine them by deep learning models).
Although there has been good progress, some major problems still remain. Like
dealing with different data formats, missing or incomplete inputs, and
defending against adversarial attacks. Researchers now are exploring new
methods, such as unsupervised or semi-supervised learning, AutoML tools, to
make models more efficient and easier to scale. And also more attention on
designing better evaluation metrics or building shared benchmarks, make it
easier to compare model performance across tasks and domains. As the field
continues to grow, multi-modal learning is expected to improve many areas:
computer vision, natural language processing, speech recognition, and
healthcare. In the future, it may help to build AI systems that can understand
the world in a way more like humans, flexible, context aware, and able to deal
with real-world complexity.

</details>


### [153] [Collaborative Batch Size Optimization for Federated Learning](https://arxiv.org/abs/2506.20511)
*Arno Geimer,Karthick Panner Selvam,Beltran Fiz Pontiveros*

Main category: cs.LG

TL;DR: 论文提出了一种通过贪婪随机搜索优化联邦学习中本地批量大小的方法，以提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的参与者可能因硬件配置不当而影响训练效果，本文旨在通过优化本地批量大小解决这一问题。

Method: 利用联邦学习的并行处理特性，采用贪婪随机搜索优化本地批量大小。

Result: 相比默认参数设置，该方法提高了收敛速度，且性能接近本地参数优化的情况。

Conclusion: 优化本地批量大小是提升联邦学习训练效率的有效方法。

Abstract: Federated Learning (FL) is a decentralized collaborative Machine Learning
framework for training models without collecting data in a centralized
location. It has seen application across various disciplines, from helping
medical diagnoses in hospitals to detecting fraud in financial transactions. In
this paper, we focus on improving the local training process through hardware
usage optimization. While participants in a federation might share the hardware
they are training on, since there is no information exchange between them,
their training process can be hindered by an improper training configuration.
Taking advantage of the parallel processing inherent to Federated Learning, we
use a greedy randomized search to optimize local batch sizes for the best
training settings across all participants. Our results show that against
default parameter settings, our method improves convergence speed while staying
nearly on par with the case where local parameters are optimized.

</details>


### [154] [WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning](https://arxiv.org/abs/2506.20518)
*Arno Geimer,Beltran Fiz Pontiveros,Radu State*

Main category: cs.LG

TL;DR: 本文提出了一种基于去中心化金融（DeFi）和自动化做市商（AMM）的新型联邦学习激励机制框架，旨在解决现有激励方案的局限性。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，激励机制对参与者至关重要，但现有的分配框架研究不足，限制了其灵活性和可扩展性。

Method: 提出了一种利用DeFi平台和AMM的框架，通过客户端特定代币作为投资工具，优化奖励分配。

Result: 该框架为参与者提供了更灵活的奖励分配系统，并允许第三方投资联邦学习过程。

Conclusion: 该框架为联邦学习的激励机制提供了创新解决方案，增强了其灵活性和可扩展性。

Abstract: Federated Learning (FL) is a collaborative machine learning paradigm which
allows participants to collectively train a model while training data remains
private. This paradigm is especially beneficial for sectors like finance, where
data privacy, security and model performance are paramount. FL has been
extensively studied in the years following its introduction, leading to, among
others, better performing collaboration techniques, ways to defend against
other clients trying to attack the model, and contribution assessment methods.
An important element in for-profit Federated Learning is the development of
incentive methods to determine the allocation and distribution of rewards for
participants. While numerous methods for allocation have been proposed and
thoroughly explored, distribution frameworks remain relatively understudied. In
this paper, we propose a novel framework which introduces client-specific
tokens as investment vehicles within the FL ecosystem. Our framework aims to
address the limitations of existing incentive schemes by leveraging a
decentralized finance (DeFi) platform and automated market makers (AMMs) to
create a more flexible and scalable reward distribution system for
participants, and a mechanism for third parties to invest in the federation
learning process.

</details>


### [155] [Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards](https://arxiv.org/abs/2506.20520)
*Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos*

Main category: cs.LG

TL;DR: 论文研究了介于离策略强化学习和监督微调之间的算法，通过分析简单的离策略REINFORCE算法，探讨了基线V对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 离策略方法在实现简单性和数据效率上优于同策略方法，但性能常不理想。本文旨在探索中间范围的算法，以优化性能。

Method: 分析了一种简单的离策略REINFORCE算法，其中优势定义为A=r-V，并通过理论分析和实验验证其效果。

Result: 理论分析表明，当基线V低于预期奖励时，算法具有策略改进保证。实验验证了离策略更新更应关注正向奖励。

Conclusion: 离策略更新应更注重正向奖励，而非负向信号，这一发现为优化强化学习对齐大语言模型提供了新思路。

Abstract: Reinforcement learning (RL) is increasingly used to align large language
models (LLMs). Off-policy methods offer greater implementation simplicity and
data efficiency than on-policy techniques, but often result in suboptimal
performance. In this work, we study the intermediate range of algorithms
between off-policy RL and supervised fine-tuning by analyzing a simple
off-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with
$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$
emphasizes high-reward samples, while raising it penalizes low-reward ones more
heavily. We first provide a theoretical analysis of this off-policy REINFORCE
algorithm, showing that when the baseline $V$ lower-bounds the expected reward,
the algorithm enjoys a policy improvement guarantee. Our analysis reveals that
while on-policy updates can safely leverage both positive and negative signals,
off-policy updates benefit from focusing more on positive rewards than on
negative ones. We validate our findings experimentally in a controlled
stochastic bandit setting and through fine-tuning state-of-the-art LLMs on
reasoning tasks.

</details>


### [156] [Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion](https://arxiv.org/abs/2506.20537)
*R. Sharma,M. Raissi,Y. B. Guo*

Main category: cs.LG

TL;DR: 提出了一种名为FEA-PINN的高效建模框架，用于加速激光粉末床熔融（LPBF）过程中的热场预测，同时保持FEA的精度。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法（如FEA）计算成本高，阻碍了LPBF过程的高效模拟。

Method: 结合FEA和物理信息神经网络（PINN），开发动态材料更新策略以捕捉相变行为，并通过校正FEA模拟减少误差漂移。

Result: FEA-PINN在保持与FEA相同精度的同时，显著降低了计算成本。

Conclusion: FEA-PINN框架为LPBF过程的高效模拟提供了可行方案，具有推广潜力。

Abstract: Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process
prediction due to the lasting issue of high computation cost using traditional
numerical methods such as finite element analysis (FEA). This study presents an
efficient modeling framework termed FEA-Regulated Physics-Informed Neural
Network (FEA-PINN) to accelerate the thermal field prediction in a LPBF process
while maintaining the FEA accuracy. A novel dynamic material updating strategy
is developed to capture the dynamic phase change of powder-liquid-solid in the
PINN model. The PINN model incorporates temperature-dependent material
properties and phase change behavior using the apparent heat capacity method.
While the PINN model demonstrates high accuracy with a small training data and
enables generalization of new process parameters via transfer learning, it
faces the challenge of high computation cost in time-dependent problems due to
the residual accumulation. To overcome this issue, the FEA-PINN framework
integrates corrective FEA simulations during inference to enforce physical
consistency and reduce error drift. A comparative analysis shows that FEA-PINN
achieves equivalent accuracy to FEA while significantly reducing computational
cost. The framework has been validated using the benchmark FEA data and
demonstrated through single-track scanning in LPBF.

</details>


### [157] [Demonstration of effective UCB-based routing in skill-based queues on real-world data](https://arxiv.org/abs/2506.20543)
*Sanne van Kempen,Jaron Sanders,Fiona Sloothaak,Maarten G. Wolf*

Main category: cs.LG

TL;DR: 本文研究了基于技能的排队系统（如数据中心、云计算网络和服务系统）的最优控制，通过真实数据集验证了一种强化学习算法在客户路由中的实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索如何在实际环境中高效实现强化学习算法以优化客户路由，并提升系统性能。

Method: 方法包括使用真实数据集进行案例研究，引入新的启发式路由规则以减少延迟，并优化多目标（如收益最大化、服务器负载公平性和客户等待时间减少）。

Result: 实验表明，该算法能高效学习并适应动态环境，优于静态基准策略，同时能平衡性能权衡。

Conclusion: 结论是该算法具有实际应用潜力，但需注意参数调优和估计误差的敏感性。

Abstract: This paper is about optimally controlling skill-based queueing systems such
as data centers, cloud computing networks, and service systems. By means of a
case study using a real-world data set, we investigate the practical
implementation of a recently developed reinforcement learning algorithm for
optimal customer routing. Our experiments show that the algorithm efficiently
learns and adapts to changing environments and outperforms static benchmark
policies, indicating its potential for live implementation. We also augment the
real-world applicability of this algorithm by introducing a new heuristic
routing rule to reduce delays. Moreover, we show that the algorithm can
optimize for multiple objectives: next to payoff maximization, secondary
objectives such as server load fairness and customer waiting time reduction can
be incorporated. Tuning parameters are used for balancing inherent performance
trade--offs. Lastly, we investigate the sensitivity to estimation errors and
parameter tuning, providing valuable insights for implementing adaptive routing
algorithms in complex real-world queueing systems.

</details>


### [158] [Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2506.20574)
*Laura Boggia,Rafael Teixeira de Lima,Bogdan Malaescu*

Main category: cs.LG

TL;DR: 本文研究了基于Transformer的多变量时间序列异常检测方法，重点分析了iTransformer架构的应用及其性能影响因素，并提出了异常标签提取和评估方法。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列异常检测在多个领域至关重要，但由于异常未知性和时间序列维度间的复杂依赖关系，准确检测异常具有挑战性。

Method: 采用iTransformer架构，研究了窗口大小、步长和模型维度等参数对性能的影响，并探讨了异常标签提取方法和评估指标。

Result: 分析了异常数据对训练的影响，评估了替代损失函数的有效性，并对多种Transformer模型在不同数据集上进行了全面比较。

Conclusion: iTransformer在多变量时间序列异常检测中表现出潜力，参数选择和异常标签处理对性能有显著影响。

Abstract: Anomaly detection in multivariate time series is an important problem across
various fields such as healthcare, financial services, manufacturing or physics
detector monitoring. Accurately identifying when unexpected errors or faults
occur is essential, yet challenging, due to the unknown nature of anomalies and
the complex interdependencies between time series dimensions. In this paper, we
investigate transformer-based approaches for time series anomaly detection,
focusing on the recently proposed iTransformer architecture. Our contributions
are fourfold: (i) we explore the application of the iTransformer to time series
anomaly detection, and analyse the influence of key parameters such as window
size, step size, and model dimensions on performance; (ii) we examine methods
for extracting anomaly labels from multidimensional anomaly scores and discuss
appropriate evaluation metrics for such labels; (iii) we study the impact of
anomalous data present during training and assess the effectiveness of
alternative loss functions in mitigating their influence; and (iv) we present a
comprehensive comparison of several transformer-based models across a diverse
set of datasets for time series anomaly detection.

</details>


### [159] [Exploring Graph-Transformer Out-of-Distribution Generalization Abilities](https://arxiv.org/abs/2506.20575)
*Itay Niv,Neta Rabin*

Main category: cs.LG

TL;DR: 该论文探讨了图神经网络在分布外（OOD）泛化中的表现，重点比较了图变换器（GT）和混合GT-MPNN架构与传统MPNNs的效果，并提出了一种新的后训练分析方法。


<details>
  <summary>Details</summary>
Motivation: 现实场景中训练和测试数据分布通常不一致，而现有图学习方法大多假设分布相同。论文旨在探索GT和混合架构在OOD泛化中的潜力。

Method: 系统评估GT和混合GT-MPNN在OOD设置下的表现，并对比MPNNs。同时提出一种新的后训练分析方法，分析ID和OOD数据的聚类结构。

Result: GT和混合GT-MPNN在OOD泛化中表现优于MPNNs，且无需专门域泛化算法。后训练分析方法提供了对泛化能力的深入见解。

Conclusion: 图变换器在现实图学习中具有潜力，为OOD泛化研究提供了新方向。

Abstract: Deep learning on graphs has shown remarkable success across numerous
applications, including social networks, bio-physics, traffic networks, and
recommendation systems. Regardless of their successes, current methods
frequently depend on the assumption that training and testing data share the
same distribution, a condition rarely met in real-world scenarios. While
graph-transformer (GT) backbones have recently outperformed traditional
message-passing neural networks (MPNNs) in multiple in-distribution (ID)
benchmarks, their effectiveness under distribution shifts remains largely
unexplored.
  In this work, we address the challenge of out-of-distribution (OOD)
generalization for graph neural networks, with a special focus on the impact of
backbone architecture. We systematically evaluate GT and hybrid backbones in
OOD settings and compare them to MPNNs. To do so, we adapt several leading
domain generalization (DG) algorithms to work with GTs and assess their
performance on a benchmark designed to test a variety of distribution shifts.
Our results reveal that GT and hybrid GT-MPNN backbones consistently
demonstrate stronger generalization ability compared to MPNNs, even without
specialized DG algorithms.
  Additionally, we propose a novel post-training analysis approach that
compares the clustering structure of the entire ID and OOD test datasets,
specifically examining domain alignment and class separation. Demonstrating its
model-agnostic design, this approach not only provided meaningful insights into
GT and MPNN backbones. It also shows promise for broader applicability to DG
problems beyond graph learning, offering a deeper perspective on generalization
abilities that goes beyond standard accuracy metrics. Together, our findings
highlight the promise of graph-transformers for robust, real-world graph
learning and set a new direction for future research in OOD generalization.

</details>


### [160] [The kernel of graph indices for vector search](https://arxiv.org/abs/2506.20584)
*Mariano Tepper,Ted Willke*

Main category: cs.LG

TL;DR: 论文提出了一种基于机器学习的图索引方法（SVG），适用于度量和非度量向量空间，并引入SVG-L0以限制出度。


<details>
  <summary>Details</summary>
Motivation: 传统图索引的导航保证仅适用于欧几里得空间，而机器学习可以扩展其适用范围。

Method: 利用核方法建立图连接性，提出SVG和SVG-L0（带稀疏约束）。

Result: SVG-L0具有自调优特性，避免了启发式方法，并保持计算复杂度可控。

Conclusion: SVG为图索引提供了新的理论基础，并展示了传统方法的特例化。

Abstract: The most popular graph indices for vector search use principles from
computational geometry to build the graph. Hence, their formal graph
navigability guarantees are only valid in Euclidean space. In this work, we
show that machine learning can be used to build graph indices for vector search
in metric and non-metric vector spaces (e.g., for inner product similarity).
From this novel perspective, we introduce the Support Vector Graph (SVG), a new
type of graph index that leverages kernel methods to establish the graph
connectivity and that comes with formal navigability guarantees valid in metric
and non-metric vector spaces. In addition, we interpret the most popular graph
indices, including HNSW and DiskANN, as particular specializations of SVG and
show that new indices can be derived from the principles behind this
specialization. Finally, we propose SVG-L0 that incorporates an $\ell_0$
sparsity constraint into the SVG kernel method to build graphs with a bounded
out-degree. This yields a principled way of implementing this practical
requirement, in contrast to the traditional heuristic of simply truncating the
out edges of each node. Additionally, we show that SVG-L0 has a self-tuning
property that avoids the heuristic of using a set of candidates to find the
out-edges of each node and that keeps its computational complexity in check.

</details>


### [161] [H-FEX: A Symbolic Learning Method for Hamiltonian Systems](https://arxiv.org/abs/2506.20607)
*Jasen Lai,Senwei Liang,Chunmei Wang*

Main category: cs.LG

TL;DR: H-FEX是一种符号学习方法，用于从观测数据中学习哈密顿系统的控制方程，能有效捕捉复杂相互作用并保持能量守恒。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法难以准确捕捉复杂哈密顿函数并保持能量守恒，因此需要一种更有效的方法。

Method: 提出H-FEX方法，通过引入新型交互节点来捕捉复杂相互作用项。

Result: 实验表明H-FEX能准确恢复复杂系统的哈密顿函数，并长期保持能量守恒。

Conclusion: H-FEX是发现复杂动力系统闭式表达的有力框架。

Abstract: Hamiltonian systems describe a broad class of dynamical systems governed by
Hamiltonian functions, which encode the total energy and dictate the evolution
of the system. Data-driven approaches, such as symbolic regression and neural
network-based methods, provide a means to learn the governing equations of
dynamical systems directly from observational data of Hamiltonian systems.
However, these methods often struggle to accurately capture complex Hamiltonian
functions while preserving energy conservation. To overcome this limitation, we
propose the Finite Expression Method for learning Hamiltonian Systems (H-FEX),
a symbolic learning method that introduces novel interaction nodes designed to
capture intricate interaction terms effectively. Our experiments, including
those on highly stiff dynamical systems, demonstrate that H-FEX can recover
Hamiltonian functions of complex systems that accurately capture system
dynamics and preserve energy over long time horizons. These findings highlight
the potential of H-FEX as a powerful framework for discovering closed-form
expressions of complex dynamical systems.

</details>


### [162] [Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning](https://arxiv.org/abs/2506.20623)
*Fariba Jangjoo,Matteo Marsili,Yasser Roudi*

Main category: cs.LG

TL;DR: 闭环学习是通过从模型自身生成的数据中反复估计模型的过程。研究表明，最大似然估计会导致参数收敛到放大初始偏差的状态，但可以通过数据污染、最大后验估计或正则化避免。


<details>
  <summary>Details</summary>
Motivation: 研究闭环学习在指数族模型中的动态行为，探索其潜在问题及解决方案。

Method: 推导参数动态方程，分析最大似然估计的性质，并提出数据污染、最大后验估计和正则化等方法。

Result: 最大似然估计会导致参数收敛到吸收状态，放大初始偏差；但通过干预可避免这一结果。

Conclusion: 闭环学习的动态行为对参数化敏感，需通过适当方法避免偏差放大。

Abstract: Closed-loop learning is the process of repeatedly estimating a model from
data generated from the model itself. It is receiving great attention due to
the possibility that large neural network models may, in the future, be
primarily trained with data generated by artificial neural networks themselves.
We study this process for models that belong to exponential families, deriving
equations of motions that govern the dynamics of the parameters. We show that
maximum likelihood estimation of the parameters endows sufficient statistics
with the martingale property and that as a result the process converges to
absorbing states that amplify initial biases present in the data. However, we
show that this outcome may be prevented by polluting the data with an
infinitesimal fraction of data points generated from a fixed model, by relying
on maximum a posteriori estimation or by introducing regularisation.
Furthermore, we show that the asymptotic behavior of the dynamics is not
reparametrisation invariant.

</details>


### [163] [PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models](https://arxiv.org/abs/2506.20629)
*Soufiane Hayou,Nikhil Ghosh,Bin Yu*

Main category: cs.LG

TL;DR: PLoP是一种轻量级方法，通过自动识别LoRA适配器的最佳放置位置，显著提升了模型微调性能。


<details>
  <summary>Details</summary>
Motivation: 研究LoRA适配器放置策略的优化问题，以提升大型模型在特定任务上的微调效率。

Method: 提出PLoP方法，通过理论分析自动确定LoRA适配器的最佳放置位置。

Result: PLoP在监督微调和强化学习任务中表现优于或至少与常用策略相当。

Conclusion: PLoP为LoRA适配器放置提供了一种高效且自动化的解决方案。

Abstract: Low-Rank Adaptation (LoRA) is a widely used finetuning method for large
models. Its small memory footprint allows practitioners to adapt large models
to specific tasks at a fraction of the cost of full finetuning. Different
modifications have been proposed to enhance its efficiency by, for example,
setting the learning rate, the rank, and the initialization. Another
improvement axis is adapter placement strategy: when using LoRA, practitioners
usually pick module types to adapt with LoRA, such as Query and Key modules.
Few works have studied the problem of adapter placement, with nonconclusive
results: original LoRA paper suggested placing adapters in attention modules,
while other works suggested placing them in the MLP modules. Through an
intuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a
lightweight method that allows automatic identification of module types where
LoRA adapters should be placed, given a pretrained model and a finetuning task.
We demonstrate that PLoP consistently outperforms, and in the worst case
competes, with commonly used placement strategies through comprehensive
experiments on supervised finetuning and reinforcement learning for reasoning.

</details>


### [164] [Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices](https://arxiv.org/abs/2506.20644)
*Hangyu Li,Hongyue Wu,Guodong Fan,Zhen Zhang,Shizhan Chen,Zhiyong Feng*

Main category: cs.LG

TL;DR: 提出了一种名为FedEDS的新联邦学习方案，通过加密数据共享解决边缘设备上的网络拓扑、物理距离和数据异构性问题。


<details>
  <summary>Details</summary>
Motivation: 当前研究忽视了网络拓扑、物理距离和数据异构性对边缘设备的影响，导致延迟增加和模型性能下降。

Method: FedEDS利用客户端模型和模型的随机层训练数据加密器，生成加密数据并与其他客户端共享，结合本地私有数据和共享加密数据训练模型。

Result: 实验证明FedEDS能加速联邦学习收敛速度，减轻数据异构性的负面影响。

Conclusion: FedEDS适用于需要快速收敛的边缘设备应用服务，有效提升模型性能。

Abstract: As privacy protection gains increasing importance, more models are being
trained on edge devices and subsequently merged into the central server through
Federated Learning (FL). However, current research overlooks the impact of
network topology, physical distance, and data heterogeneity on edge devices,
leading to issues such as increased latency and degraded model performance. To
address these issues, we propose a new federated learning scheme on edge
devices that called Federated Learning with Encrypted Data Sharing(FedEDS).
FedEDS uses the client model and the model's stochastic layer to train the data
encryptor. The data encryptor generates encrypted data and shares it with other
clients. The client uses the corresponding client's stochastic layer and
encrypted data to train and adjust the local model. FedEDS uses the client's
local private data and encrypted shared data from other clients to train the
model. This approach accelerates the convergence speed of federated learning
training and mitigates the negative impact of data heterogeneity, making it
suitable for application services deployed on edge devices requiring rapid
convergence. Experiments results show the efficacy of FedEDS in promoting model
performance.

</details>


### [165] [Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer](https://arxiv.org/abs/2506.20650)
*Anqi Mao,Mehryar Mohri,Yutao Zhong*

Main category: cs.LG

TL;DR: 该论文提出新的代理损失函数和高效算法，解决多专家学习中的延迟分配问题，并提供了理论保证和实验验证。


<details>
  <summary>Details</summary>
Motivation: 解决在多专家系统中平衡准确性和计算成本的挑战，特别是在自然语言生成等领域。

Method: 引入新的代理损失函数和算法，分别针对单阶段和两阶段学习场景，提供理论一致性保证。

Result: 提出了可实现H一致性的损失函数，并在实验中验证了其优于现有基线。

Conclusion: 论文为多专家学习中的延迟分配问题提供了有效的解决方案和理论支持。

Abstract: The problem of learning to defer with multiple experts consists of optimally
assigning input instances to experts, balancing the trade-off between their
accuracy and computational cost. This is a critical challenge in natural
language generation, but also in other fields such as image processing, and
medical diagnostics. Recent studies have proposed surrogate loss functions to
optimize deferral, but challenges remain in ensuring their consistency
properties. This paper introduces novel surrogate loss functions and efficient
algorithms with strong theoretical learning guarantees. We address open
questions regarding realizable $H$-consistency, $H$-consistency bounds, and
Bayes-consistency for both single-stage (jointly learning predictor and
deferral function) and two-stage (learning only the deferral function with a
fixed expert) learning scenarios. For single-stage deferral, we introduce a
family of new realizable $H$-consistent surrogate losses and further prove
$H$-consistency for a selected member. For two-stage deferral, we derive new
surrogate losses that achieve realizable $H$-consistency, $H$-consistency
bounds, and Bayes-consistency for the two-expert scenario and, under natural
assumptions, multiple-expert scenario. Additionally, we provide enhanced
theoretical guarantees under low-noise assumptions for both scenarios. Finally,
we report the results of experiments using our proposed surrogate losses,
comparing their performance against existing baselines.

</details>


### [166] [Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning](https://arxiv.org/abs/2506.20651)
*Fei Wang,Baochun Li*

Main category: cs.LG

TL;DR: 论文分析了联邦学习中恶意梯度泄漏攻击的局限性，提出了一种轻量级客户端检测机制。


<details>
  <summary>Details</summary>
Motivation: 研究恶意服务器通过操纵全局模型获取客户端敏感信息的风险，探讨攻击的实际限制和防御可行性。

Method: 从防御者角度分析攻击的有效性与隐蔽性，提出基于监控的客户端检测机制。

Result: 发现攻击在现实联邦学习环境中难以同时高效和隐蔽，检测机制可有效防御。

Conclusion: 恶意梯度泄漏攻击实际威胁有限，轻量级防御机制可行且易于部署。

Abstract: Recent work has shown that gradient updates in federated learning (FL) can
unintentionally reveal sensitive information about a client's local data. This
risk becomes significantly greater when a malicious server manipulates the
global model to provoke information-rich updates from clients. In this paper,
we adopt a defender's perspective to provide the first comprehensive analysis
of malicious gradient leakage attacks and the model manipulation techniques
that enable them. Our investigation reveals a core trade-off: these attacks
cannot be both highly effective in reconstructing private data and sufficiently
stealthy to evade detection -- especially in realistic FL settings that
incorporate common normalization techniques and federated averaging.
  Building on this insight, we argue that malicious gradient leakage attacks,
while theoretically concerning, are inherently limited in practice and often
detectable through basic monitoring. As a complementary contribution, we
propose a simple, lightweight, and broadly applicable client-side detection
mechanism that flags suspicious model updates before local training begins,
despite the fact that such detection may not be strictly necessary in realistic
FL settings. This mechanism further underscores the feasibility of defending
against these attacks with minimal overhead, offering a deployable safeguard
for privacy-conscious federated learning systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [167] [Learning Bilateral Team Formation in Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.20039)
*Koorosh Moslemi,Chi-Guhn Lee*

Main category: cs.MA

TL;DR: 论文提出了一种动态多智能体系统中双边团队形成的框架，填补了现有研究中动态群体双边分组选择的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单边分组、预定义团队或固定群体设置，而动态群体中的双边分组选择影响尚未充分探索。

Method: 引入了一个学习双边团队形成的框架，分析了算法特性对策略性能和泛化的影响。

Result: 在广泛采用的多智能体场景中验证了方法的竞争力，多数情况下表现出改进的泛化能力。

Conclusion: 该框架为动态多智能体系统中的双边团队形成提供了新见解，展示了其在性能和泛化方面的潜力。

Abstract: Team formation and the dynamics of team-based learning have drawn significant
interest in the context of Multi-Agent Reinforcement Learning (MARL). However,
existing studies primarily focus on unilateral groupings, predefined teams, or
fixed-population settings, leaving the effects of algorithmic bilateral
grouping choices in dynamic populations underexplored. To address this gap, we
introduce a framework for learning two-sided team formation in dynamic
multi-agent systems. Through this study, we gain insight into what algorithmic
properties in bilateral team formation influence policy performance and
generalization. We validate our approach using widely adopted multi-agent
scenarios, demonstrating competitive performance and improved generalization in
most scenarios.

</details>


### [168] [A Visualization Framework for Exploring Multi-Agent-Based Simulations Case Study of an Electric Vehicle Home Charging Ecosystem](https://arxiv.org/abs/2506.20400)
*Kristoffer Christensen,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.MA

TL;DR: 该论文提出了一种基于Python的模块化仪表盘框架，用于分析和解释多智能体电动汽车充电模拟中的复杂数据。


<details>
  <summary>Details</summary>
Motivation: 多智能体电动汽车充电模拟生成的数据复杂且随机，难以通过静态后处理检测和解释系统级事件。

Method: 开发了一个基于Dash by Plotly的仪表盘框架，包含三个协调视图（系统概览、系统分析和消费者分析），提供高分辨率可视化工具。

Result: 案例研究表明，该框架能快速识别和解释异常，如变压器过载和充电失败。

Conclusion: 该框架为研究人员和电网运营商提供了可操作的见解，并适用于其他分布式能源系统。

Abstract: Multi-agent-based simulations (MABS) of electric vehicle (EV) home charging
ecosystems generate large, complex, and stochastic time-series datasets that
capture interactions between households, grid infrastructure, and energy
markets. These interactions can lead to unexpected system-level events, such as
transformer overloads or consumer dissatisfaction, that are difficult to detect
and explain through static post-processing. This paper presents a modular,
Python-based dashboard framework, built using Dash by Plotly, that enables
efficient, multi-level exploration and root-cause analysis of emergent behavior
in MABS outputs. The system features three coordinated views (System Overview,
System Analysis, and Consumer Analysis), each offering high-resolution
visualizations such as time-series plots, spatial heatmaps, and agent-specific
drill-down tools. A case study simulating full EV adoption with smart charging
in a Danish residential network demonstrates how the dashboard supports rapid
identification and contextual explanation of anomalies, including clustered
transformer overloads and time-dependent charging failures. The framework
facilitates actionable insight generation for researchers and distribution
system operators, and its architecture is adaptable to other distributed energy
resources and complex energy systems.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [169] [Higher-Order Neuromorphic Ising Machines -- Autoencoders and Fowler-Nordheim Annealers are all you need for Scalability](https://arxiv.org/abs/2506.19964)
*Faiek Ahsan,Saptarshi Maiti,Zihao Chen,Jakob Kaiser,Ankita Nandi,Madhuvanthi Srivatsav,Johannes Schemmel,Andreas G. Andreou,Jason Eshraghian,Chetan Singh Thakur,Shantanu Chakrabartty*

Main category: cs.NE

TL;DR: 提出了一种高阶神经形态Ising机，通过异步自编码器架构直接操作Ising子句而非自旋，实现了优于二次化架构的可扩展性、高质量解和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决高阶Ising问题中二次化方法带来的资源复杂性问题，同时提升解的质量和求解速度。

Method: 采用异步自编码器架构，利用Fowler-Nordheim量子隧穿退火动态采样自旋潜在空间，直接处理高阶Ising子句。

Result: 在MAX-CUT和MAX-SAT等基准问题上，相比二阶模型，高阶模型在更短时间内提供更高质量的解。

Conclusion: 自编码器和Fowler-Nordheim退火器足以实现任意阶神经形态Ising机的可靠性和可扩展性。

Abstract: We report a higher-order neuromorphic Ising machine that exhibits superior
scalability compared to architectures based on quadratization, while also
achieving state-of-the-art quality and reliability in solutions with
competitive time-to-solution metrics. At the core of the proposed machine is an
asynchronous autoencoder architecture that captures higher-order interactions
by directly manipulating Ising clauses instead of Ising spins, thereby
maintaining resource complexity independent of interaction order. Asymptotic
convergence to the Ising ground state is ensured by sampling the autoencoder
latent space defined by the spins, based on the annealing dynamics of the
Fowler-Nordheim quantum mechanical tunneling. To demonstrate the advantages of
the proposed higher-order neuromorphic Ising machine, we systematically solved
benchmark combinatorial optimization problems such as MAX-CUT and MAX-SAT,
comparing the results to those obtained using a second-order Ising machine
employing the same annealing process. Our findings indicate that the proposed
architecture consistently provides higher quality solutions in shorter time
frames compared to the second-order model across multiple runs. Additionally,
we show that the techniques based on the sparsity of the interconnection
matrix, such as graph coloring, can be effectively applied to higher-order
neuromorphic Ising machines, enhancing the solution quality and the
time-to-solution. The time-to-solution can be further improved through hardware
co-design, as demonstrated in this paper using a field-programmable gate array
(FPGA). The results presented in this paper provide further evidence that
autoencoders and Fowler-Nordheim annealers are sufficient to achieve
reliability and scaling of any-order neuromorphic Ising machines.

</details>


### [170] [Surrogate-Assisted Evolution for Efficient Multi-branch Connection Design in Deep Neural Networks](https://arxiv.org/abs/2506.20469)
*Fergal Stapleton,Daniel García Núñez,Yanan Sun,Edgar Galván*

Main category: cs.NE

TL;DR: 论文提出了一种基于线性遗传编程（LGP）的新方法NeuroLGP-MB，用于自动设计多分支连接的深度神经网络（DNN），并通过代理辅助进化算法优化架构。


<details>
  <summary>Details</summary>
Motivation: 现有的多分支DNN虽然能提升特征提取能力，但训练成本高且架构优化复杂。

Method: 使用线性遗传编程（LGP）编码多分支连接，结合代理辅助进化算法（EA）高效设计DNN，并引入语义增强的代理模型。

Result: 提出的NeuroLGP-MB方法能够高效设计高性能DNN架构，且代理模型优于基线模型。

Conclusion: NeuroLGP-MB为复杂DNN的自动设计提供了高效解决方案，代理辅助EA的扩展应用显著提升了性能。

Abstract: State-of-the-art Deep Neural Networks (DNNs) often incorporate multi-branch
connections, enabling multi-scale feature extraction and enhancing the capture
of diverse features. This design improves network capacity and generalisation
to unseen data. However, training such DNNs can be computationally expensive.
The challenge is further exacerbated by the complexity of identifying optimal
network architectures. To address this, we leverage Evolutionary Algorithms
(EAs) to automatically discover high-performing architectures, a process
commonly known as neuroevolution. We introduce a novel approach based on Linear
Genetic Programming (LGP) to encode multi-branch (MB) connections within DNNs,
referred to as NeuroLGP-MB. To efficiently design the DNNs, we use
surrogate-assisted EAs. While their application in simple artificial neural
networks has been influential, we scale their use from dozens or hundreds of
sample points to thousands, aligning with the demands of complex DNNs by
incorporating a semantic-based approach in our surrogate-assisted EA.
Furthermore, we introduce a more advanced surrogate model that outperforms
baseline, computationally expensive, and simpler surrogate models.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [171] [Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot Recordings](https://arxiv.org/abs/2506.20609)
*Ankit Shah,Rita Singh,Bhiksha Raj,Alexander Hauptmann*

Main category: cs.SD

TL;DR: 研究提出了一种基于声学分析的枪声检测与分类方法，利用机器学习框架（如SVM和CNN）从低成本设备（如手机）中识别枪声并分类枪支类型。


<details>
  <summary>Details</summary>
Motivation: 枪击事件频发威胁公共安全，现有商业系统成本高昂，需低成本替代方案。

Method: 通过分析枪声的声学特征（如枪口爆炸和冲击波），使用SVM和CNN进行枪声检测与分类。

Result: CNN在干净数据上表现优于SVM（mAP 0.58 vs. 0.39），但网络数据质量影响性能（mAP 0.35）。

Conclusion: 研究目标是开发低成本、高精度的实时系统，为执法机构提供关键信息。

Abstract: The escalating rates of gun-related violence and mass shootings represent a
significant threat to public safety. Timely and accurate information for law
enforcement agencies is crucial in mitigating these incidents. Current
commercial gunshot detection systems, while effective, often come with
prohibitive costs. This research explores a cost-effective alternative by
leveraging acoustic analysis of gunshot recordings, potentially obtainable from
ubiquitous devices like cell phones, to not only detect gunshots but also
classify the type of firearm used. This paper details a study on deciphering
gun type hierarchies using a curated dataset of 3459 recordings. We investigate
the fundamental acoustic characteristics of gunshots, including muzzle blasts
and shockwaves, which vary based on firearm type, ammunition, and shooting
direction. We propose and evaluate machine learning frameworks, including
Support Vector Machines (SVMs) as a baseline and a more advanced Convolutional
Neural Network (CNN) architecture for joint gunshot detection and gun type
classification. Results indicate that our deep learning approach achieves a
mean average precision (mAP) of 0.58 on clean labeled data, outperforming the
SVM baseline (mAP 0.39). Challenges related to data quality, environmental
noise, and the generalization capabilities when using noisy web-sourced data
(mAP 0.35) are also discussed. The long-term vision is to develop a highly
accurate, real-time system deployable on common recording devices,
significantly reducing detection costs and providing critical intelligence to
first responders.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [172] [Recursive-ARX for Grid-Edge Fault Detection](https://arxiv.org/abs/2506.20011)
*Soufiane El Yaagoubi,Keith Moffat,Eduardo Prieto Araujo,Florian Dörfler*

Main category: eess.SY

TL;DR: 论文提出使用实时系统辨识（rARX）方法进行电网故障检测，适用于逆变器无法提供大故障电流的现代电网。


<details>
  <summary>Details</summary>
Motivation: 未来电网中逆变器无法提供大故障电流，且分布式资源可能从电网边缘供电，需要新的故障检测方法。

Method: 采用递归ARX（rARX）系统辨识方法，在并网逆变器上实现实时故障检测。

Result: 实验表明rARX能快速检测大故障，并区分高阻抗故障与大负载增加。

Conclusion: rARX电网边缘故障检测是提高现代电网可靠性和安全性的有前景的研究方向。

Abstract: Future electrical grids will require new ways to identify faults as inverters
are not capable of supplying large fault currents to support existing fault
detection methods and because distributed resources may feed faults from the
edge of the grid. This paper proposes the use of real-time system
identification for online power-system fault detection. Specifically, we
implement Recursive ARX (rARX) system identification on a grid-connected
inverter. Experiments demonstrate that the proposed rARX method is able to both
detect large faults quickly, and distinguish between high-impedance faults and
large load increases. These results indicate that rARX grid-edge fault
detection is a promising research direction for improving the reliability and
safety of modern electric grids.

</details>


### [173] [A Data-Driven Approach for Topology Correction in Low Voltage Networks with DERs](https://arxiv.org/abs/2506.20238)
*Dong Liu,Sander Timmerman,Yu Xiang,Peter Palensky,Pedro P. Vergara*

Main category: eess.SY

TL;DR: 论文提出了一种基于数据驱动的低压配电网拓扑识别与校正方法，结合时间智能电表数据选择策略，旨在修正过时记录并识别遗漏记录。


<details>
  <summary>Details</summary>
Motivation: 解决低压配电网中拓扑记录过时或遗漏的问题，同时减少隐私问题和测量负担。

Method: 仅依赖电压幅值测量，通过监督学习算法识别开关状态，改进的层次聚类算法确定用户-馈线连接和相位标签，结合时间智能电表数据选择策略。

Result: 在荷兰的真实低压配电网和不完整电表数据集上验证了方法的可行性和鲁棒性，时间选择策略有效减轻了光伏系统对相位识别的影响。

Conclusion: 校正后的拓扑提高了网络可观测性，支持负载平衡和光伏消纳。

Abstract: This paper introduces a data-driven topology identification and correction
approach for low-voltage distribution networks (LVDNs) combined with a
time-based smart meter data selection strategy, aiming to correct outdated
recordings and identify the missed recordings. The proposed approach solely
relies on voltage magnitude measurements, releasing privacy concerns and
measurement burdens. It enables the distribution system operators to identify
switch states through supervised learning algorithms, as well as determine
user-feeder connections and phase labels of customers by a modified
Hierarchical Clustering algorithm. To address the similarity among smart meter
(SM) data caused by distributed photovoltaic (PV) systems, a time-based SM data
selection strategy is combined with the proposed correlation analysis. The
feasibility and robustness of the proposed approach are validated using
modified real-world LVDNs and multiple incomplete SM datasets collected from
customers in the Netherlands. The results demonstrate that the time-based SM
data selection strategy effectively mitigates their impact on phase
identification, and the corrected topology not only improves network
observability but also supports network operators in load balancing and PV
consumption.

</details>


### [174] [Cooperative Sensing and Communication Beamforming Design for Low-Altitude Economy](https://arxiv.org/abs/2506.20244)
*Fangzhi Li,Zhichu Ren,Cunhua Pan,Hong Ren,Jing Jin,Qixing Wang,Jiangzhou Wang*

Main category: eess.SY

TL;DR: 本文提出了一种用于空地网络的协作式集成感知与通信（ISAC）框架，通过优化波束成形、接收滤波和无人机轨迹，实现高精度感知和高速通信。


<details>
  <summary>Details</summary>
Motivation: 为低空经济提供高精度感知和高速通信能力，解决空地网络中感知与通信的协同问题。

Method: 采用协作波束成形技术，联合优化波束成形、接收滤波和无人机轨迹，使用半定松弛（SDR）和逐次凸近似（SCA）解决非凸问题。

Result: 仿真结果表明，联合设计在保证感知鲁棒性的同时提高了通信吞吐量，感知SINR阈值和无人机高度对轨迹设计有显著影响。

Conclusion: 自适应部署策略在实际应用中至关重要，联合优化设计能够有效提升空地网络的性能。

Abstract: To empower the low-altitude economy with high-accuracy sensing and high-rate
communication, this paper proposes a cooperative integrated sensing and
communication (ISAC) framework for aerial-ground networks. In the proposed
system, the ground base stations (BSs) cooperatively serve the unmanned aerial
vehicles (UAVs), which are equipped for either joint communication and sensing
or sensing-only operations. The BSs employ coordinated beamforming to
simultaneously transmit communication and sensing signals, while the UAVs
execute their missions. To maximize the weighted sum rate under the sensing
signal-to-interference-plus-noise ratio (SINR) constraints, we jointly optimize
the transmit beamforming, receive filtering, and UAV trajectory. The resulting
non-convex problem is solved using an alternating optimization framework
incorporating semidefinite relaxation (SDR) and successive convex approximation
(SCA). Simulation results demonstrate that the proposed joint design achieves
higher communication throughput while ensuring required sensing robustness.
Additionally, the sensing SINR threshold and the UAV altitude have a
significant impact on the trajectory design, highlighting the necessity of
adaptive deployment strategies in practical applications.

</details>


### [175] [Analyzing the Impact of Strategic Bidding on the Reserve Capacity via a Bi-Level Model](https://arxiv.org/abs/2506.20493)
*Yun Xu,Yunxiao Bai,Yunyong Zhang,Peng Wang,Xuelin Wang,Jiqun Guo,Kaijun Xie,Rusheng Zhao*

Main category: eess.SY

TL;DR: 论文研究了可再生能源整合背景下，电力公司通过策略性报价影响市场储备容量和电力成本的问题。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源的普及，电力系统需要足够的储备容量来维持平衡，但电力公司可能通过策略性报价牟利，影响储备和市场效率。

Method: 采用双层模型，上层模拟策略性公司最大化利润，下层模拟系统运营商基于报价的市场清算，并采用连续储备容量计算方法。

Result: 研究表明，在不完全竞争市场中，更多机组被激励运行以增加储备，但部分机组仅为利润运行，导致消费者电力成本上升。

Conclusion: 市场设计需平衡储备充足性和经济效率，以应对策略性报价行为。

Abstract: The growing integration of renewable energy sources necessitates adequate
reserve capacity to maintain power balance. However, in market clearing, power
companies with flexible resources may submit strategic bids to maximize
profits, potentially compromising system reserves. This paper examines the
effects of such strategic behavior by modeling the market as a bi-level
problem. The upper level represents a strategic company aiming to maximize
profit, while the lower level simulates the system operator clearing the market
based on submitted offers. To enable duality-based solution methods, we
approximate unit commitments with a continuous reserve capacity calculation.
Case studies indicate that, in an imperfectly competitive market, more units
are incentivized to operate,enhancing system reserves. However, some units go
online mainly for profit, ultimately raising electricity costs for consumers.
These findings highlight the importance of market design in managing the
trade-off between reserve adequacy and economic efficiency in the presence of
strategic bidding behavior.

</details>


### [176] [Recurrent neural network-based robust control systems with closed-loop regional incremental ISS and application to MPC design](https://arxiv.org/abs/2506.20334)
*Daniele Ravasio,Marcello Farina,Alessio La Bella,Andrea Ballarino*

Main category: eess.SY

TL;DR: 论文研究了基于一类递归神经网络的输出反馈方案设计，提出了一种基于线性矩阵不等式的观测器和静态状态反馈控制器设计方法，并引入非线性模型预测控制器以增强性能。


<details>
  <summary>Details</summary>
Motivation: 针对递归神经网络系统的输出反馈设计问题，解决在存在干扰和状态估计不确定性时的跟踪和鲁棒性问题。

Method: 提出基于线性矩阵不等式的观测器和静态状态反馈控制器设计方法，并引入基于区域的增量输入-状态稳定性（ISS）和管式非线性模型预测控制器（NMPC）。

Result: 理论结果表明，所提方案能够保证收敛性和递归可行性，并扩大吸引域。数值仿真验证了方法的有效性。

Conclusion: 论文提出的方法在递归神经网络系统中实现了鲁棒输出反馈控制，并通过NMPC进一步提升了性能。

Abstract: This paper investigates the design of output-feedback schemes for systems
described by a class of recurrent neural networks. We propose a procedure based
on linear matrix inequalities for designing an observer and a static
state-feedback controller. The algorithm leverages global and regional
incremental input-to-state stability (incremental ISS) and enables the tracking
of constant setpoints, ensuring robustness to disturbances and state estimation
uncertainty. To address the potential limitations of regional incremental ISS,
we introduce an alternative scheme in which the static law is replaced with a
tube-based nonlinear model predictive controller (NMPC) that exploits regional
incremental ISS properties. We show that these conditions enable the
formulation of a robust NMPC law with guarantees of convergence and recursive
feasibility, leading to an enlarged region of attraction. Theoretical results
are validated through numerical simulations on the pH-neutralisation process
benchmark, demonstrating the effectiveness of the proposed schemes.

</details>


### [177] [Learning-based safety lifting monitoring system for cranes on construction sites](https://arxiv.org/abs/2506.20475)
*Hao Chen,Yu Hin Ng,Ching-Wei Chang,Haobo Liang,Yanke Wang*

Main category: eess.SY

TL;DR: 论文提出了一种基于学习方法的自动化安全吊装监控算法，用于减少模块化集成建筑（MiC）吊装中的安全风险，通过2D和3D检测技术实现实时预警。


<details>
  <summary>Details</summary>
Motivation: 模块化集成建筑（MiC）吊装因其重量和体积大，存在较高的安全风险，可能导致事故或对工人造成伤害。研究旨在通过自动化技术提升吊装过程的安全性和效率。

Method: 设计了基于学习方法的自动化监控算法流程，包括2D目标检测模型训练和点云信息融合，实现MiC和工人的3D定位，并自动触发警报。

Result: 算法在MiC和工人检测上的平均距离误差分别为1.5640米和0.7824米，系统在真实工地上成功实现了安全风险监控和预警功能。

Conclusion: 该系统能够有效减少人工干预，提升MiC吊装过程的安全性和效率，具有实际应用潜力。

Abstract: Lifting on construction sites, as a frequent operation, works still with
safety risks, especially for modular integrated construction (MiC) lifting due
to its large weight and size, probably leading to accidents, causing damage to
the modules, or more critically, posing safety hazards to on-site workers.
Aiming to reduce the safety risks in lifting scenarios, we design an automated
safe lifting monitoring algorithm pipeline based on learning-based methods, and
deploy it on construction sites. This work is potentially to increase the
safety and efficiency of MiC lifting process via automation technologies. A
dataset is created consisting of 1007 image-point cloud pairs (37 MiC
liftings). Advanced object detection models are trained for automated
two-dimensional (2D) detection of MiCs and humans. Fusing the 2D detection
results with the point cloud information allows accurate determination of the
three-dimensional (3D) positions of MiCs and humans. The system is designed to
automatically trigger alarms that notify individuals in the MiC lifting danger
zone, while providing the crane operator with real-time lifting information and
early warnings. The monitoring process minimizes the human intervention and no
or less signal men are required on real sites assisted by our system. A
quantitative analysis is conducted to evaluate the effectiveness of the
algorithmic pipeline. The pipeline shows promising results in MiC and human
perception with the mean distance error of 1.5640 m and 0.7824 m respectively.
Furthermore, the developed system successfully executes safety risk monitoring
and alarm functionalities during the MiC lifting process with limited manual
work on real construction sites.

</details>


### [178] [Task Allocation of UAVs for Monitoring Missions via Hardware-in-the-Loop Simulation and Experimental Validation](https://arxiv.org/abs/2506.20626)
*Hamza Chakraa,François Guérin,Edouard Leclercq,Dimitri Lefebvre*

Main category: eess.SY

TL;DR: 该研究提出了一种结合遗传算法和2-Opt局部搜索的方法，优化无人机在工业监测任务中的任务分配，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在工业监测任务中的任务分配优化问题，以提高效率和实用性。

Method: 结合遗传算法（GA）和2-Opt局部搜索技术，并通过硬件在环（HIL）模拟器进行验证。

Result: 优化成本与实际电池消耗和飞行时间高度相关，验证了方法的实用性。

Conclusion: 提出的方法在实际场景中有效，优化成本与真实数据一致。

Abstract: This study addresses the optimisation of task allocation for Unmanned Aerial
Vehicles (UAVs) within industrial monitoring missions. The proposed methodology
integrates a Genetic Algorithms (GA) with a 2-Opt local search technique to
obtain a high-quality solution. Our approach was experimentally validated in an
industrial zone to demonstrate its efficacy in real-world scenarios. Also, a
Hardware-in-the-loop (HIL) simulator for the UAVs team is introduced. Moreover,
insights about the correlation between the theoretical cost function and the
actual battery consumption and time of flight are deeply analysed. Results show
that the considered costs for the optimisation part of the problem closely
correlate with real-world data, confirming the practicality of the proposed
approach.

</details>


### [179] [Identifiability and Maximum Likelihood Estimation for System Identification of Networks of Dynamical Systems](https://arxiv.org/abs/2506.20628)
*Anders Hansson,João Victor Galvão da Mata,Martin S. Andersen*

Main category: eess.SY

TL;DR: 研究了动态系统网络直接识别的可识别性和最大似然估计，提出了基于Gröbner基的必要和充分条件，并证明该方法比现有预测误差方法更一致和高效。


<details>
  <summary>Details</summary>
Motivation: 探索动态系统网络识别的可识别性和高效估计方法，以解决现有预测误差方法的局限性。

Method: 利用Gröbner基分析网络可识别性，提出无需预测器的最大似然估计方法。

Result: 证明了最大似然方法的优越性（一致性和高效性），并扩展了其适用范围。

Conclusion: 该方法在动态系统网络识别中具有高效性和广泛适用性，为相关领域提供了新工具。

Abstract: In this paper we investigate identifiability and maximum likelihood
estimation for direct system identification of networks of dynamical systems.
We provide necessary and sufficient conditions for network identifiability in
terms of Gr\"obner bases. We show that the maximum likelihood approach is both
consistent and efficient, which is in contrast to existing prediction error
approaches. Moreover, our approach has wider applicability, i.e., it is
applicable whenever network identifiability holds. Finally, we show that we can
formulate the maximum likelihood problem without the use of a predictor, which
is the key to numerically being able to solve it efficiently.

</details>
