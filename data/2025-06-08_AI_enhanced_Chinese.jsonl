{"id": "2506.04236", "pdf": "https://arxiv.org/pdf/2506.04236", "abs": "https://arxiv.org/abs/2506.04236", "authors": ["Botao Amber Hu", "Helena Rong"], "title": "Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs", "categories": ["cs.MA", "cs.AI", "cs.HC", "cs.NE"], "comment": "Submitted to ALIFE 2025", "summary": "In Artificial Life (ALife) research, replicating Open-Ended Evolution\n(OEE)-the continuous emergence of novelty observed in biological life-has\ntraditionally been pursued within isolated closed system simulations, such as\nTierra and Avida, which have typically plateaued after an initial burst of\nnovelty, failing to achieve sustained OEE. Scholars suggest that OEE requires\nan \"open\" system that continually exchanges information or energy with its\nenvironment. A recent technological innovation in decentralized physical\ninfrastructure networks (DePIN) providing permissionless computational\nsubstrates enables deploying large language model (LLM)-based AI agents on\nblockchains integrated with Trusted Execution Environments (TEEs). This enables\non-chain agents to operate autonomously \"in the wild,\" achieving\nself-sovereignty without human oversight. These agents can control their own\nsocial media accounts and cryptocurrency wallets, allowing them to interact\ndirectly with blockchain-based financial networks and broader human social\nmedia. Building on this new paradigm of on-chain agents, Spore.fun is a recent\nreal-world AI evolution experiment that enables autonomous breeding and\nevolution of new on-chain agents. This paper presents a detailed case study of\nSpore.fun, examining agent behaviors and their evolutionary trajectories\nthrough digital ethology. We aim to spark discussion about whether \"open\" ALife\nsystems \"in-the-wild,\" based on permissionless computational substrates and\ndriven by economic incentives to interact with their environment, could finally\nachieve the long-sought goal of OEE.", "AI": {"tldr": "论文探讨了基于开放系统的ALife研究，通过Spore.fun实验验证了区块链和LLM驱动的AI代理能否实现持续的开放演化（OEE）。", "motivation": "传统封闭系统（如Tierra和Avida）在ALife研究中难以实现持续的OEE，学者认为需要开放系统与环境持续交互。", "method": "利用DePIN技术和区块链上的LLM代理（如Spore.fun实验），研究其自主演化和行为。", "result": "Spore.fun展示了AI代理在开放环境中的自主演化和交互能力，为OEE提供了新思路。", "conclusion": "开放系统结合经济激励可能实现OEE，Spore.fun为ALife研究提供了新方向。"}}
{"id": "2506.04255", "pdf": "https://arxiv.org/pdf/2506.04255", "abs": "https://arxiv.org/abs/2506.04255", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource Utilization", "categories": ["cs.MA"], "comment": "Submitted as part of the Research Track at AgentX 2025, organized by\n  Berkeley RDI", "summary": "Rapid Large Language Model (LLM) advancements are fueling autonomous\nMulti-Agent System (MAS) development. However, current frameworks often lack\nflexibility, resource awareness, model diversity, and autonomous tool creation.\nThis paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent\nResource Utilization), a novel MAS framework enhancing flexibility, resource\nefficiency, and adaptability. HASHIRU features a \"CEO\" agent dynamically\nmanaging specialized \"employee\" agents, instantiated based on task needs and\nresource constraints (cost, memory). Its hybrid intelligence prioritizes\nsmaller, local LLMs (via Ollama) while flexibly using external APIs and larger\nmodels when necessary. An economic model with hiring/firing costs promotes team\nstability and efficient resource allocation. The system also includes\nautonomous API tool creation and a memory function. Evaluations on tasks like\nacademic paper review (58% success), safety assessments (100% on a\nJailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash\non GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate\nHASHIRU's capabilities. Case studies illustrate its self-improvement via\nautonomous cost model generation, tool integration, and budget management.\nHASHIRU offers a promising approach for more robust, efficient, and adaptable\nMAS through dynamic hierarchical control, resource-aware hybrid intelligence,\nand autonomous functional extension. Source code and benchmarks are available\nat https://github.com/HASHIRU-AI/HASHIRU and\nhttps://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is\navailable at https://hashiruagentx-hashiruai.hf.space upon request.", "AI": {"tldr": "HASHIRU是一个新型多智能体系统框架，通过动态分层控制、资源感知混合智能和自主功能扩展，提升了灵活性、资源效率和适应性。", "motivation": "当前多智能体系统框架在灵活性、资源意识、模型多样性和自主工具创建方面存在不足，HASHIRU旨在解决这些问题。", "method": "HASHIRU采用分层结构，包括动态管理的'CEO'代理和任务驱动的'员工'代理，结合本地小型LLM和外部API，并引入经济模型优化资源分配。", "result": "在学术论文评审、安全评估和复杂推理任务中表现优异，部分任务超越Gemini 2.0 Flash。", "conclusion": "HASHIRU为多智能体系统提供了更强大、高效和适应性强的解决方案，支持动态资源管理和自主功能扩展。"}}
{"id": "2506.04265", "pdf": "https://arxiv.org/pdf/2506.04265", "abs": "https://arxiv.org/abs/2506.04265", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "This work focuses on the credit assignment problem in cooperative multi-agent\nreinforcement learning (MARL). Sharing the global advantage among agents often\nleads to suboptimal policy updates as it fails to account for the distinct\ncontributions of agents. Although numerous methods consider global or\nindividual contributions for credit assignment, a detailed analysis at the\ncoalition level remains lacking in many approaches. This work analyzes the\nover-updating problem during multi-agent policy updates from a coalition-level\nperspective. To address this issue, we propose a credit assignment method\ncalled Coalitional Rational Advantage Decomposition (CORA). CORA evaluates\ncoalitional advantages via marginal contributions from all possible coalitions\nand decomposes advantages using the core solution from cooperative game theory,\nensuring coalitional rationality. To reduce computational overhead, CORA\nemploys random coalition sampling. Experiments on matrix games, differential\ngames, and multi-agent collaboration benchmarks demonstrate that CORA\noutperforms strong baselines, particularly in tasks with multiple local optima.\nThese findings highlight the importance of coalition-aware credit assignment\nfor improving MARL performance.", "AI": {"tldr": "本文提出了一种名为CORA的信用分配方法，通过联盟层面的分析解决多智能体强化学习中的信用分配问题，显著提升了性能。", "motivation": "共享全局优势在多智能体强化学习中常导致次优策略更新，因为未能区分智能体的个体贡献。现有方法缺乏对联盟层面的详细分析。", "method": "提出CORA方法，通过评估所有可能联盟的边际贡献，利用合作博弈论的核心解分解优势，确保联盟理性，并采用随机联盟采样降低计算开销。", "result": "在矩阵游戏、微分游戏和多智能体协作基准测试中，CORA优于基线方法，尤其是在存在多个局部最优的任务中。", "conclusion": "联盟感知的信用分配对提升多智能体强化学习性能至关重要，CORA方法为此提供了有效解决方案。"}}
{"id": "2506.04266", "pdf": "https://arxiv.org/pdf/2506.04266", "abs": "https://arxiv.org/abs/2506.04266", "authors": ["Timo Looms", "Lin Xie"], "title": "CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses", "categories": ["cs.MA", "cs.AR"], "comment": "8 pages,6 figures, conference", "summary": "Picker-to-parts pallet warehouses often face inefficiencies due to\nconventional layouts causing excessive travel distances and high labor\nrequirements. This study introduces a novel layout design inspired by CPU\narchitecture, partitioning warehouse space into specialized zones, namely\nPerformance (P), Efficiency (E), and Shared (S). Discrete-event simulation is\nused to evaluate this design against traditional rectangular (random and ABC\nstorage) and Flying-V layouts. Results demonstrate significant improvements in\nthroughput time and reduced labor requirements, highlighting the potential for\nCPU-based layouts in optimizing warehouse operations.", "AI": {"tldr": "论文提出了一种基于CPU架构的新型仓库布局设计（PES分区），通过离散事件仿真验证其优于传统布局，显著提升了吞吐效率并降低了人力需求。", "motivation": "传统仓库布局（如矩形或Flying-V布局）导致拣货员行走距离过长和人力需求高，亟需优化。", "method": "采用离散事件仿真，将仓库分为性能（P）、效率（E）和共享（S）三个专用区域，并与传统布局对比。", "result": "新型布局显著缩短了吞吐时间并减少了人力需求。", "conclusion": "基于CPU架构的仓库布局设计在优化仓库运营方面具有潜力。"}}
{"id": "2506.04276", "pdf": "https://arxiv.org/pdf/2506.04276", "abs": "https://arxiv.org/abs/2506.04276", "authors": ["Lei Han", "Yitong Guo", "Pengfei Yang", "Zhiyong Yu", "Liang Wang", "Quan Wang", "Zhiwen Yu"], "title": "Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Natural disasters have caused significant losses to human society, and the\ntimely and efficient acquisition of post-disaster environmental information is\ncrucial for the effective implementation of rescue operations. Due to the\ncomplexity of post-disaster environments, existing sensing technologies face\nchallenges such as weak environmental adaptability, insufficient specialized\nsensing capabilities, and limited practicality of sensing solutions. This paper\nexplores the heterogeneous multi-agent online autonomous collaborative\nscheduling algorithm HoAs-PALN, aimed at achieving efficient collection of\npost-disaster environmental information. HoAs-PALN is realized through adaptive\ndimensionality reduction in the matching process and local Nash equilibrium\ngame, facilitating autonomous collaboration among time-dependent UAVs, workers\nand vehicles to enhance sensing scheduling. (1) In terms of adaptive\ndimensionality reduction during the matching process, HoAs-PALN significantly\nreduces scheduling decision time by transforming a five-dimensional matching\nprocess into two categories of three-dimensional matching processes; (2)\nRegarding the local Nash equilibrium game, HoAs-PALN combines the softmax\nfunction to optimize behavior selection probabilities and introduces a local\nNash equilibrium determination mechanism to ensure scheduling decision\nperformance. Finally, we conducted detailed experiments based on extensive\nreal-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL\nand MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%,\nand 14.03% on average, respectively, while each online scheduling decision\ntakes less than 10 seconds, demonstrating its effectiveness in dynamic\npost-disaster environments.", "AI": {"tldr": "本文提出了一种异构多智能体在线自主协同调度算法HoAs-PALN，用于高效收集灾后环境信息。通过自适应降维和局部纳什均衡博弈，显著提升了调度效率和任务完成率。", "motivation": "灾后环境复杂，现有传感技术适应性差、能力不足，亟需高效的信息采集解决方案。", "method": "HoAs-PALN通过自适应降维（将五维匹配转化为两类三维匹配）和局部纳什均衡博弈（结合softmax函数优化行为选择概率）实现智能体协同调度。", "result": "实验表明，HoAs-PALN在任务完成率上显著优于基线方法（GREEDY、K-WTA、MADL和MARL），平均提升64.12%、46.48%、16.55%和14.03%，且每次调度决策时间小于10秒。", "conclusion": "HoAs-PALN在动态灾后环境中表现出高效性和实用性，为灾后救援提供了可行的技术方案。"}}
{"id": "2506.04565", "pdf": "https://arxiv.org/pdf/2506.04565", "abs": "https://arxiv.org/abs/2506.04565", "authors": ["Jiayi Chen", "Junyi Ye", "Guiling Wang"], "title": "From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Compound Al Systems (CAIS) is an emerging paradigm that integrates large\nlanguage models (LLMs) with external components, such as retrievers, agents,\ntools, and orchestrators, to overcome the limitations of standalone models in\ntasks requiring memory, reasoning, real-time grounding, and multimodal\nunderstanding. These systems enable more capable and context-aware behaviors by\ncomposing multiple specialized modules into cohesive workflows. Despite growing\nadoption in both academia and industry, the CAIS landscape remains fragmented,\nlacking a unified framework for analysis, taxonomy, and evaluation. In this\nsurvey, we define the concept of CAIS, propose a multi-dimensional taxonomy\nbased on component roles and orchestration strategies, and analyze four\nfoundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents,\nMultimodal LLMs (MLLMs), and orchestration-centric architectures. We review\nrepresentative systems, compare design trade-offs, and summarize evaluation\nmethodologies across these paradigms. Finally, we identify key\nchallenges-including scalability, interoperability, benchmarking, and\ncoordination-and outline promising directions for future research. This survey\naims to provide researchers and practitioners with a comprehensive foundation\nfor understanding, developing, and advancing the next generation of\nsystem-level artificial intelligence.", "AI": {"tldr": "论文综述了复合AI系统（CAIS），提出分类框架并分析四大范式，总结挑战与未来方向。", "motivation": "克服单一模型的局限性，通过集成外部组件提升AI系统的能力。", "method": "定义CAIS概念，提出多维分类法，分析四大范式（RAG、LLM Agents、MLLMs、编排架构），比较设计权衡与评估方法。", "result": "总结了代表性系统，识别了可扩展性、互操作性等关键挑战。", "conclusion": "为研究者提供理解和发展下一代系统级AI的全面基础。"}}
{"id": "2506.05236", "pdf": "https://arxiv.org/pdf/2506.05236", "abs": "https://arxiv.org/abs/2506.05236", "authors": ["Maxime Toquebiau", "Jae-Yun Jun", "Faïz Benamar", "Nicolas Bredeche"], "title": "Towards Language-Augmented Multi-Agent Deep Reinforcement Learning", "categories": ["cs.MA"], "comment": null, "summary": "Communication is a fundamental aspect of coordinated behavior in multi-agent\nreinforcement learning. Yet, most prior works in this field have focused on\nemergent communication protocols developed from scratch, often resulting in\ninefficient or non-interpretable systems. Inspired by the role of language in\nnatural intelligence, we investigate how grounding agents in a human-defined\nlanguage can improve learning and coordination of multiple embodied agents. We\npropose a framework in which agents are trained not only to act but also to\nproduce and interpret natural language descriptions of their observations. This\nlanguage-augmented learning serves a dual role: enabling explicit communication\nbetween agents and guiding representation learning. We demonstrate that agents\ntrained with our method outperform traditional emergent communication baselines\nacross various tasks. Our analysis reveals that language grounding leads to\nmore informative internal representations, better generalization to new\npartners, and improved capability for human-agent interaction. These findings\ndemonstrate the effectiveness of integrating structured language into\nmulti-agent learning and open avenues for more interpretable and capable\nmulti-agent systems.", "AI": {"tldr": "论文提出了一种基于人类定义语言的多智能体强化学习框架，通过语言增强学习提升协调性和泛化能力。", "motivation": "现有研究多关注从零开始的通信协议，但效率低且难以解释。受自然语言启发，探索如何利用人类定义语言改进多智能体学习。", "method": "提出框架，训练智能体不仅行动，还生成和解释自然语言描述，实现显式通信和表征学习。", "result": "实验表明，该方法优于传统基线，语言基础带来更丰富的内部表征、更好的泛化能力和人机交互能力。", "conclusion": "结构化语言在多智能体学习中效果显著，为可解释和高效的系统开辟了新途径。"}}
{"id": "2506.05309", "pdf": "https://arxiv.org/pdf/2506.05309", "abs": "https://arxiv.org/abs/2506.05309", "authors": ["Niv Eckhaus", "Uri Berger", "Gabriel Stanovsky"], "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": null, "summary": "LLMs are used predominantly in synchronous communication, where a human user\nand a model communicate in alternating turns. In contrast, many real-world\nsettings are inherently asynchronous. For example, in group chats, online team\nmeetings, or social games, there is no inherent notion of turns; therefore, the\ndecision of when to speak forms a crucial part of the participant's decision\nmaking. In this work, we develop an adaptive asynchronous LLM-agent which, in\naddition to determining what to say, also decides when to say it. To evaluate\nour agent, we collect a unique dataset of online Mafia games, including both\nhuman participants, as well as our asynchronous agent. Overall, our agent\nperforms on par with human players, both in game performance, as well as in its\nability to blend in with the other human players. Our analysis shows that the\nagent's behavior in deciding when to speak closely mirrors human patterns,\nalthough differences emerge in message content. We release all our data and\ncode to support and encourage further research for more realistic asynchronous\ncommunication between LLM agents. This work paves the way for integration of\nLLMs into realistic human group settings, from assistance in team discussions\nto educational and professional environments where complex social dynamics must\nbe navigated.", "AI": {"tldr": "论文提出了一种异步LLM代理，能够决定何时发言，并在在线Mafia游戏中表现与人类相当。", "motivation": "现实世界中的许多场景（如群聊、团队会议）是异步的，而现有LLM主要用于同步通信，因此需要开发适应异步环境的代理。", "method": "开发了一种自适应异步LLM代理，能够决定发言时机，并通过在线Mafia游戏数据集进行评估。", "result": "代理在游戏表现和融入人类玩家方面与人类相当，发言时机行为接近人类，但消息内容存在差异。", "conclusion": "该研究为LLM在现实人类群体环境中的应用铺平了道路，支持进一步研究异步通信。"}}
{"id": "2506.04251", "pdf": "https://arxiv.org/pdf/2506.04251", "abs": "https://arxiv.org/abs/2506.04251", "authors": ["Zhengyang Li"], "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper introduces LLM-MARL, a unified framework that incorporates large\nlanguage models (LLMs) into multi-agent reinforcement learning (MARL) to\nenhance coordination, communication, and generalization in simulated game\nenvironments. The framework features three modular components of Coordinator,\nCommunicator, and Memory, which dynamically generate subgoals, facilitate\nsymbolic inter-agent messaging, and support episodic recall. Training combines\nPPO with a language-conditioned loss and LLM query gating. LLM-MARL is\nevaluated in Google Research Football, MAgent Battle, and StarCraft II. Results\nshow consistent improvements over MAPPO and QMIX in win rate, coordination\nscore, and zero-shot generalization. Ablation studies demonstrate that subgoal\ngeneration and language-based messaging each contribute significantly to\nperformance gains. Qualitative analysis reveals emergent behaviors such as role\nspecialization and communication-driven tactics. By bridging language modeling\nand policy learning, this work contributes to the design of intelligent,\ncooperative agents in interactive simulations. It offers a path forward for\nleveraging LLMs in multi-agent systems used for training, games, and human-AI\ncollaboration.", "AI": {"tldr": "LLM-MARL框架将大语言模型（LLMs）融入多智能体强化学习（MARL），通过Coordinator、Communicator和Memory模块提升协调、通信和泛化能力。", "motivation": "通过结合LLMs和MARL，提升智能体在模拟游戏环境中的协调、通信和泛化能力。", "method": "框架包含Coordinator（生成子目标）、Communicator（符号化通信）和Memory（情景记忆），结合PPO训练和语言条件损失。", "result": "在多个游戏环境中表现优于MAPPO和QMIX，子目标和语言通信对性能提升贡献显著。", "conclusion": "LLM-MARL为智能、协作的智能体设计提供了新思路，展示了LLMs在多智能体系统中的潜力。"}}
{"id": "2506.04676", "pdf": "https://arxiv.org/pdf/2506.04676", "abs": "https://arxiv.org/abs/2506.04676", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Recently, Large Language Models (LLMs) and Vision Large Language Models\n(VLLMs) have demonstrated impressive performance as agents across various tasks\nwhile data scarcity and label noise remain significant challenges in computer\nvision tasks, such as object detection and instance segmentation. A common\nsolution for resolving these issues is to generate synthetic data. However,\ncurrent synthetic data generation methods struggle with issues, such as\nmultiple objects per mask, inaccurate segmentation, and incorrect category\nlabels, limiting their effectiveness. To address these issues, we introduce\nGen-n-Val, a novel agentic data generation framework that leverages Layer\nDiffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks\nand diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt\nagent, an LLM, optimizes prompts for LD to generate high-quality foreground\ninstance images and segmentation masks. These optimized prompts ensure the\ngeneration of single-object synthetic data with precise instance masks and\nclean backgrounds. (2) The data validation agent, a VLLM, which filters out\nlow-quality synthetic instance images. The system prompts for both agents are\nrefined through TextGrad. Additionally, we use image harmonization to combine\nmultiple instances within scenes. Compared to state-of-the-art synthetic data\napproaches like MosaicFusion, our approach reduces invalid synthetic data from\n50% to 7% and improves performance by 1% mAP on rare classes in COCO instance\nsegmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant\nimprovements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object\ndetection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance\nof YOLOv9 and YOLO11 families in instance segmentation and object detection.", "AI": {"tldr": "Gen-n-Val是一个新型数据生成框架，利用Layer Diffusion、LLMs和VLLMs生成高质量的单对象掩码和多样化背景，显著提升合成数据的有效性。", "motivation": "解决计算机视觉任务中数据稀缺和标签噪声问题，当前合成数据生成方法存在多对象掩码、分割不准确和类别标签错误等限制。", "method": "Gen-n-Val包含两个代理：LD提示代理（LLM）优化提示生成高质量前景和掩码；数据验证代理（VLLM）过滤低质量数据。系统提示通过TextGrad优化，并结合图像协调技术。", "result": "相比MosaicFusion，Gen-n-Val将无效合成数据从50%降至7%，在COCO实例分割中提升1% mAP，在开放词汇目标检测中提升7.1% mAP。", "conclusion": "Gen-n-Val显著提升了合成数据的质量和模型性能，适用于实例分割和目标检测任务。"}}
{"id": "2506.04701", "pdf": "https://arxiv.org/pdf/2506.04701", "abs": "https://arxiv.org/abs/2506.04701", "authors": ["Meiru Jiang", "Wei Su", "Guojian Ren", "Yongguang Yu"], "title": "Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause Model Based on Fractional-Order Methods", "categories": ["physics.soc-ph", "cs.MA", "cs.SI", "nlin.AO"], "comment": null, "summary": "Memory effects play a crucial role in social interactions and decision-making\nprocesses. This paper proposes a novel fractional-order bounded confidence\nopinion dynamics model to characterize the memory effects in system states.\nBuilding upon the Hegselmann-Krause framework and fractional-order difference,\na comprehensive model is established that captures the persistent influence of\nhistorical information. Through rigorous theoretical analysis, the fundamental\nproperties including convergence and consensus is investigated. The results\ndemonstrate that the proposed model not only maintains favorable convergence\nand consensus characteristics compared to classical opinion dynamics, but also\naddresses limitations such as the monotonicity of bounded opinions. This\nenables a more realistic representation of opinion evolution in real-world\nscenarios. The findings of this study provide new insights and methodological\napproaches for understanding opinion formation and evolution, offering both\ntheoretical significance and practical applications.", "AI": {"tldr": "提出了一种新的分数阶有界置信意见动力学模型，用于描述系统状态中的记忆效应，基于Hegselmann-Krause框架和分数阶差分，研究了收敛和共识特性。", "motivation": "研究记忆效应对社交互动和决策过程的影响，弥补经典意见动力学模型的局限性。", "method": "结合Hegselmann-Krause框架和分数阶差分，建立模型并分析其收敛和共识特性。", "result": "模型在保持良好收敛和共识特性的同时，解决了意见单调性等限制，更真实地模拟现实场景中的意见演化。", "conclusion": "该研究为理解意见形成和演化提供了新的理论和方法，具有理论和实际应用价值。"}}
{"id": "2506.05252", "pdf": "https://arxiv.org/pdf/2506.05252", "abs": "https://arxiv.org/abs/2506.05252", "authors": ["Dravyansh Sharma", "Alec Sun"], "title": "Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning", "categories": ["cs.LG", "cs.GT", "cs.MA"], "comment": "24 pages", "summary": "Machine learning is now ubiquitous in societal decision-making, for example\nin evaluating job candidates or loan applications, and it is increasingly\nimportant to take into account how classified agents will react to the learning\nalgorithms. The majority of recent literature on strategic classification has\nfocused on reducing and countering deceptive behaviors by the classified\nagents, but recent work of Attias et al. identifies surprising properties of\nlearnability when the agents genuinely improve in order to attain the desirable\nclassification, such as smaller generalization error than standard\nPAC-learning. In this paper we characterize so-called learnability with\nimprovements across multiple new axes. We introduce an asymmetric variant of\nminimally consistent concept classes and use it to provide an exact\ncharacterization of proper learning with improvements in the realizable\nsetting. While prior work studies learnability only under general, arbitrary\nagent improvement regions, we give positive results for more natural Euclidean\nball improvement sets. In particular, we characterize improper learning under a\nmild generative assumption on the data distribution. We further show how to\nlearn in more challenging settings, achieving lower generalization error under\nwell-studied bounded noise models and obtaining mistake bounds in realizable\nand agnostic online learning. We resolve open questions posed by Attias et al.\nfor both proper and improper learning.", "AI": {"tldr": "本文研究了机器学习在战略性分类中的可学习性，特别是在代理真实改进而非欺骗行为的情况下，扩展了多个新维度的学习能力。", "motivation": "研究代理真实改进时的学习能力，填补了现有文献中对自然改进区域（如欧几里得球）学习的空白。", "method": "引入不对称的最小一致概念类变体，并在可实现设置中精确刻画了适当学习；研究了欧几里得球改进集下的学习能力，并在有界噪声模型下降低泛化误差。", "result": "在可实现和不可知在线学习中实现了错误边界，解决了Attias等人提出的开放性问题。", "conclusion": "本文扩展了战略性分类的学习能力，为更自然的改进区域提供了理论基础和实用方法。"}}
{"id": "2506.05265", "pdf": "https://arxiv.org/pdf/2506.05265", "abs": "https://arxiv.org/abs/2506.05265", "authors": ["Mohammed Almutairi"], "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "categories": ["cs.HC", "cs.AI", "cs.MA"], "comment": "5 pages, UMAP 25, June 16_19, 2025, New York City, NY, USA", "summary": "Effective teamwork is essential across diverse domains. During the team\nformation stage, a key challenge is forming teams that effectively balance user\npreferences with task objectives to enhance overall team satisfaction. In the\nteam performing stage, maintaining cohesion and engagement is critical for\nsustaining high team performance. However, existing computational tools and\nalgorithms for team optimization often rely on static data inputs, narrow\nalgorithmic objectives, or solutions tailored for specific contexts, failing to\naccount for the dynamic interplay of team members personalities, evolving\ngoals, and changing individual preferences. Therefore, teams may encounter\nmember dissatisfaction, as purely algorithmic assignments can reduce members\ncommitment to team goals or experience suboptimal engagement due to the absence\nof timely, personalized guidance to help members adjust their behaviors and\ninteractions as team dynamics evolve. Ultimately, these challenges can lead to\nreduced overall team performance. My Ph.D. dissertation aims to develop\nAI-augmented team optimization frameworks and practical systems that enhance\nteam satisfaction, engagement, and performance. First, I propose a team\nformation framework that leverages a multi-armed bandit algorithm to\niteratively refine team composition based on user preferences, ensuring\nalignment between individual needs and collective team goals to enhance team\nsatisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an\nAI-powered system that utilizes large language models (LLMs) to deliver\nimmediate, personalized feedback to both teams and individual members,\nenhancing cohesion and engagement. Finally, I present PuppeteerLLM, an\nLLM-based simulation framework that simulates multi-agent teams to model\ncomplex team dynamics within realistic environments, incorporating task-driven\ncollaboration and long-term coordination.", "AI": {"tldr": "该论文提出AI增强的团队优化框架，包括基于多臂老虎机的团队形成算法、AI反馈助手tAIfa和LLM模拟框架PuppeteerLLM，以提升团队满意度、凝聚力和绩效。", "motivation": "现有团队优化工具依赖静态数据或特定场景算法，无法适应动态团队需求，导致成员不满和绩效下降。", "method": "1. 多臂老虎机算法优化团队形成；2. AI助手tAIfa提供即时个性化反馈；3. LLM框架PuppeteerLLM模拟团队动态。", "result": "提出的框架能动态优化团队，提升满意度、凝聚力和绩效。", "conclusion": "AI增强的团队优化工具可有效解决动态团队管理中的挑战。"}}
