{"id": "2506.19964", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2506.19964", "abs": "https://arxiv.org/abs/2506.19964", "authors": ["Faiek Ahsan", "Saptarshi Maiti", "Zihao Chen", "Jakob Kaiser", "Ankita Nandi", "Madhuvanthi Srivatsav", "Johannes Schemmel", "Andreas G. Andreou", "Jason Eshraghian", "Chetan Singh Thakur", "Shantanu Chakrabartty"], "title": "Higher-Order Neuromorphic Ising Machines -- Autoencoders and Fowler-Nordheim Annealers are all you need for Scalability", "comment": null, "summary": "We report a higher-order neuromorphic Ising machine that exhibits superior\nscalability compared to architectures based on quadratization, while also\nachieving state-of-the-art quality and reliability in solutions with\ncompetitive time-to-solution metrics. At the core of the proposed machine is an\nasynchronous autoencoder architecture that captures higher-order interactions\nby directly manipulating Ising clauses instead of Ising spins, thereby\nmaintaining resource complexity independent of interaction order. Asymptotic\nconvergence to the Ising ground state is ensured by sampling the autoencoder\nlatent space defined by the spins, based on the annealing dynamics of the\nFowler-Nordheim quantum mechanical tunneling. To demonstrate the advantages of\nthe proposed higher-order neuromorphic Ising machine, we systematically solved\nbenchmark combinatorial optimization problems such as MAX-CUT and MAX-SAT,\ncomparing the results to those obtained using a second-order Ising machine\nemploying the same annealing process. Our findings indicate that the proposed\narchitecture consistently provides higher quality solutions in shorter time\nframes compared to the second-order model across multiple runs. Additionally,\nwe show that the techniques based on the sparsity of the interconnection\nmatrix, such as graph coloring, can be effectively applied to higher-order\nneuromorphic Ising machines, enhancing the solution quality and the\ntime-to-solution. The time-to-solution can be further improved through hardware\nco-design, as demonstrated in this paper using a field-programmable gate array\n(FPGA). The results presented in this paper provide further evidence that\nautoencoders and Fowler-Nordheim annealers are sufficient to achieve\nreliability and scaling of any-order neuromorphic Ising machines.", "AI": {"tldr": "提出了一种高阶神经形态Ising机，通过异步自编码器架构直接操作Ising子句而非自旋，实现了优于二次化架构的可扩展性、高质量解和可靠性。", "motivation": "解决高阶Ising问题中二次化方法带来的资源复杂性问题，同时提升解的质量和求解速度。", "method": "采用异步自编码器架构，利用Fowler-Nordheim量子隧穿退火动态采样自旋潜在空间，直接处理高阶Ising子句。", "result": "在MAX-CUT和MAX-SAT等基准问题上，相比二阶模型，高阶模型在更短时间内提供更高质量的解。", "conclusion": "自编码器和Fowler-Nordheim退火器足以实现任意阶神经形态Ising机的可靠性和可扩展性。"}}
{"id": "2506.20469", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2506.20469", "abs": "https://arxiv.org/abs/2506.20469", "authors": ["Fergal Stapleton", "Daniel García Núñez", "Yanan Sun", "Edgar Galván"], "title": "Surrogate-Assisted Evolution for Efficient Multi-branch Connection Design in Deep Neural Networks", "comment": "GECCO '25 Companion: Proceedings of the Companion Conference on\n  Genetic and Evolutionary Computation (2025)", "summary": "State-of-the-art Deep Neural Networks (DNNs) often incorporate multi-branch\nconnections, enabling multi-scale feature extraction and enhancing the capture\nof diverse features. This design improves network capacity and generalisation\nto unseen data. However, training such DNNs can be computationally expensive.\nThe challenge is further exacerbated by the complexity of identifying optimal\nnetwork architectures. To address this, we leverage Evolutionary Algorithms\n(EAs) to automatically discover high-performing architectures, a process\ncommonly known as neuroevolution. We introduce a novel approach based on Linear\nGenetic Programming (LGP) to encode multi-branch (MB) connections within DNNs,\nreferred to as NeuroLGP-MB. To efficiently design the DNNs, we use\nsurrogate-assisted EAs. While their application in simple artificial neural\nnetworks has been influential, we scale their use from dozens or hundreds of\nsample points to thousands, aligning with the demands of complex DNNs by\nincorporating a semantic-based approach in our surrogate-assisted EA.\nFurthermore, we introduce a more advanced surrogate model that outperforms\nbaseline, computationally expensive, and simpler surrogate models.", "AI": {"tldr": "论文提出了一种基于线性遗传编程（LGP）的新方法NeuroLGP-MB，用于自动设计多分支连接的深度神经网络（DNN），并通过代理辅助进化算法优化架构。", "motivation": "现有的多分支DNN虽然能提升特征提取能力，但训练成本高且架构优化复杂。", "method": "使用线性遗传编程（LGP）编码多分支连接，结合代理辅助进化算法（EA）高效设计DNN，并引入语义增强的代理模型。", "result": "提出的NeuroLGP-MB方法能够高效设计高性能DNN架构，且代理模型优于基线模型。", "conclusion": "NeuroLGP-MB为复杂DNN的自动设计提供了高效解决方案，代理辅助EA的扩展应用显著提升了性能。"}}
{"id": "2506.20015", "categories": ["cs.LG", "cs.IT", "cs.NE", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.20015", "abs": "https://arxiv.org/abs/2506.20015", "authors": ["Dengyu Wu", "Jiechen Chen", "H. Vincent Poor", "Bipin Rajendran", "Osvaldo Simeone"], "title": "Neuromorphic Wireless Split Computing with Resonate-and-Fire Neurons", "comment": null, "summary": "Neuromorphic computing offers an energy-efficient alternative to conventional\ndeep learning accelerators for real-time time-series processing. However, many\nedge applications, such as wireless sensing and audio recognition, generate\nstreaming signals with rich spectral features that are not effectively captured\nby conventional leaky integrate-and-fire (LIF) spiking neurons. This paper\ninvestigates a wireless split computing architecture that employs\nresonate-and-fire (RF) neurons with oscillatory dynamics to process time-domain\nsignals directly, eliminating the need for costly spectral pre-processing. By\nresonating at tunable frequencies, RF neurons extract time-localized spectral\nfeatures while maintaining low spiking activity. This temporal sparsity\ntranslates into significant savings in both computation and transmission\nenergy. Assuming an OFDM-based analog wireless interface for spike\ntransmission, we present a complete system design and evaluate its performance\non audio classification and modulation classification tasks. Experimental\nresults show that the proposed RF-SNN architecture achieves comparable accuracy\nto conventional LIF-SNNs and ANNs, while substantially reducing spike rates and\ntotal energy consumption during inference and communication.", "AI": {"tldr": "该论文提出了一种基于共振放电（RF）神经元的无线分体计算架构，用于高效处理具有丰富频谱特征的流式信号，显著降低了计算和传输能耗。", "motivation": "传统漏电积分放电（LIF）神经元无法有效捕捉流式信号的频谱特征，而无线边缘应用（如无线传感和音频识别）需要高效的实时处理。", "method": "采用具有振荡动态的RF神经元直接处理时域信号，避免昂贵的频谱预处理，并通过可调谐频率提取时间局部化频谱特征。", "result": "实验表明，RF-SNN架构在音频分类和调制分类任务中与传统LIF-SNN和ANN精度相当，但显著降低了脉冲率和总能耗。", "conclusion": "RF神经元在无线分体计算中表现出高效能，适用于边缘设备的实时信号处理。"}}
{"id": "2506.19939", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19939", "abs": "https://arxiv.org/abs/2506.19939", "authors": ["Aryan Singh Dalal", "Sidharth Rai", "Rahul Singh", "Treman Singh Kaloya", "Rahul Harsha Cheppally", "Ajay Sharda"], "title": "Computer Vision based Automated Quantification of Agricultural Sprayers Boom Displacement", "comment": "Under publication process for COMPAG", "summary": "Application rate errors when using self-propelled agricultural sprayers for\nagricultural production remain a concern. Among other factors, spray boom\ninstability is one of the major contributors to application errors. Spray\nbooms' width of 38m, combined with 30 kph driving speeds, varying terrain, and\nmachine dynamics when maneuvering complex field boundaries, make controls of\nthese booms very complex. However, there is no quantitative knowledge on the\nextent of boom movement to systematically develop a solution that might include\nboom designs and responsive boom control systems. Therefore, this study was\nconducted to develop an automated computer vision system to quantify the boom\nmovement of various agricultural sprayers. A computer vision system was\ndeveloped to track a target on the edge of the sprayer boom in real time. YOLO\nV7, V8, and V11 neural network models were trained to track the boom's\nmovements in field operations to quantify effective displacement in the\nvertical and transverse directions. An inclinometer sensor was mounted on the\nboom to capture boom angles and validate the neural network model output. The\nresults showed that the model could detect the target with more than 90 percent\naccuracy, and distance estimates of the target on the boom were within 0.026 m\nof the inclinometer sensor data. This system can quantify the boom movement on\nthe current sprayer and potentially on any other sprayer with minor\nmodifications. The data can be used to make design improvements to make sprayer\nbooms more stable and achieve greater application accuracy.", "AI": {"tldr": "开发了一种基于计算机视觉的系统，用于量化农业喷雾器喷杆的运动，以提高喷雾应用的准确性。", "motivation": "喷雾喷杆的不稳定性是喷雾应用误差的主要因素之一，但目前缺乏对其运动量的定量了解，难以系统改进设计或控制系统。", "method": "使用YOLO V7、V8和V11神经网络模型实时跟踪喷杆边缘目标，并结合倾角传感器验证模型输出。", "result": "模型检测目标的准确率超过90%，距离估计与传感器数据误差在0.026米内。", "conclusion": "该系统能有效量化喷杆运动，为喷杆设计改进和控制系统优化提供数据支持。"}}
{"id": "2506.19995", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.19995", "abs": "https://arxiv.org/abs/2506.19995", "authors": ["Blade Frisch", "Keith Vertanen"], "title": "Refining Participatory Design for AAC Users", "comment": null, "summary": "Augmentative and alternative communication (AAC) is a field of research and\npractice that works with people who have a communication disability. One form\nAAC can take is a high-tech tool, such as a software-based communication\nsystem. Like all user interfaces, these systems must be designed and it is\ncritical to include AAC users in the design process for their systems. A\nparticipatory design approach can include AAC users in the design process, but\nmodifications may be necessary to make these methods more accessible. We\npresent a two-part design process we are investigating for improving the\nparticipatory design for high-tech AAC systems. We discuss our plans to refine\nthe accessibility of this process based on participant feedback.", "AI": {"tldr": "探讨如何通过改进参与式设计方法，使高科技辅助沟通系统（AAC）的设计更包容用户需求。", "motivation": "AAC系统设计需用户参与，但现有方法可能不够包容，需改进以提升可访问性。", "method": "提出两阶段设计流程，并根据用户反馈优化其可访问性。", "result": "计划通过用户反馈进一步优化设计流程。", "conclusion": "改进参与式设计方法有望提升AAC系统的用户包容性。"}}
{"id": "2506.20039", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20039", "abs": "https://arxiv.org/abs/2506.20039", "authors": ["Koorosh Moslemi", "Chi-Guhn Lee"], "title": "Learning Bilateral Team Formation in Cooperative Multi-Agent Reinforcement Learning", "comment": "Accepted to the 2nd Coordination and Cooperation in Multi-Agent\n  Reinforcement Learning (CoCoMARL) Workshop at RLC 2025", "summary": "Team formation and the dynamics of team-based learning have drawn significant\ninterest in the context of Multi-Agent Reinforcement Learning (MARL). However,\nexisting studies primarily focus on unilateral groupings, predefined teams, or\nfixed-population settings, leaving the effects of algorithmic bilateral\ngrouping choices in dynamic populations underexplored. To address this gap, we\nintroduce a framework for learning two-sided team formation in dynamic\nmulti-agent systems. Through this study, we gain insight into what algorithmic\nproperties in bilateral team formation influence policy performance and\ngeneralization. We validate our approach using widely adopted multi-agent\nscenarios, demonstrating competitive performance and improved generalization in\nmost scenarios.", "AI": {"tldr": "论文提出了一种动态多智能体系统中双边团队形成的框架，填补了现有研究中动态群体双边分组选择的空白。", "motivation": "现有研究主要关注单边分组、预定义团队或固定群体设置，而动态群体中的双边分组选择影响尚未充分探索。", "method": "引入了一个学习双边团队形成的框架，分析了算法特性对策略性能和泛化的影响。", "result": "在广泛采用的多智能体场景中验证了方法的竞争力，多数情况下表现出改进的泛化能力。", "conclusion": "该框架为动态多智能体系统中的双边团队形成提供了新见解，展示了其在性能和泛化方面的潜力。"}}
{"id": "2506.20609", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.20609", "abs": "https://arxiv.org/abs/2506.20609", "authors": ["Ankit Shah", "Rita Singh", "Bhiksha Raj", "Alexander Hauptmann"], "title": "Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot Recordings", "comment": "4 pages + 1 References", "summary": "The escalating rates of gun-related violence and mass shootings represent a\nsignificant threat to public safety. Timely and accurate information for law\nenforcement agencies is crucial in mitigating these incidents. Current\ncommercial gunshot detection systems, while effective, often come with\nprohibitive costs. This research explores a cost-effective alternative by\nleveraging acoustic analysis of gunshot recordings, potentially obtainable from\nubiquitous devices like cell phones, to not only detect gunshots but also\nclassify the type of firearm used. This paper details a study on deciphering\ngun type hierarchies using a curated dataset of 3459 recordings. We investigate\nthe fundamental acoustic characteristics of gunshots, including muzzle blasts\nand shockwaves, which vary based on firearm type, ammunition, and shooting\ndirection. We propose and evaluate machine learning frameworks, including\nSupport Vector Machines (SVMs) as a baseline and a more advanced Convolutional\nNeural Network (CNN) architecture for joint gunshot detection and gun type\nclassification. Results indicate that our deep learning approach achieves a\nmean average precision (mAP) of 0.58 on clean labeled data, outperforming the\nSVM baseline (mAP 0.39). Challenges related to data quality, environmental\nnoise, and the generalization capabilities when using noisy web-sourced data\n(mAP 0.35) are also discussed. The long-term vision is to develop a highly\naccurate, real-time system deployable on common recording devices,\nsignificantly reducing detection costs and providing critical intelligence to\nfirst responders.", "AI": {"tldr": "研究提出了一种基于声学分析的枪声检测与分类方法，利用机器学习框架（如SVM和CNN）从低成本设备（如手机）中识别枪声并分类枪支类型。", "motivation": "枪击事件频发威胁公共安全，现有商业系统成本高昂，需低成本替代方案。", "method": "通过分析枪声的声学特征（如枪口爆炸和冲击波），使用SVM和CNN进行枪声检测与分类。", "result": "CNN在干净数据上表现优于SVM（mAP 0.58 vs. 0.39），但网络数据质量影响性能（mAP 0.35）。", "conclusion": "研究目标是开发低成本、高精度的实时系统，为执法机构提供关键信息。"}}
{"id": "2506.20030", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2506.20030", "abs": "https://arxiv.org/abs/2506.20030", "authors": ["Robin Bowers", "Marius Garbea", "Emmanouil Pountourakis", "Samuel Taggart"], "title": "Polynomial-Time Approximation Schemes via Utility Alignment: Unit-Demand Pricing and More", "comment": null, "summary": "This paper derives polynomial-time approximation schemes for several NP-hard\nstochastic optimization problems from the algorithmic mechanism design and\noperations research literatures. The problems we consider involve a principal\nor seller optimizing with respect to a subsequent choice by an agent or buyer.\nThese include posted pricing for a unit-demand buyer with independent values\n(Chawla et al., 2007, Cai and Daskalakis, 2011), assortment optimization with\nindependent utilities (Talluri and van Ryzin, 2004), and delegated choice\n(Khodabakhsh et al., 2024). Our results advance the state of the art for each\nof these problems. For unit-demand pricing with discrete distributions, our\nmultiplicative PTAS improves on the additive PTAS of Cai and Daskalakis, and we\nadditionally give a PTAS for the unbounded regular case, improving on the\nlatter paper's QPTAS. For assortment optimization, no constant approximation\nwas previously known. For delegated choice, we improve on both the\n$3$-approximation for the case with no outside option and the\nsuper-constant-approximation with an outside option.\n  A key technical insight driving our results is an economically meaningful\nproperty we term utility alignment. Informally, a problem is utility aligned\nif, at optimality, the principal derives most of their utility from\nrealizations where the agent's utility is also high. Utility alignment allows\nthe algorithm designer to focus on maximizing performance on realizations with\nhigh agent utility, which is often an algorithmically simpler task. We prove\nutility alignment results for all the problems mentioned above, including\nstrong results for unit-demand pricing and delegation, as well as a weaker but\nvery broad guarantee that holds for many other problems under very mild\nconditions.", "AI": {"tldr": "本文提出了多项式时间近似方案（PTAS），解决了多个NP难随机优化问题，包括定价、分类优化和委托选择问题，并引入“效用对齐”作为关键技术。", "motivation": "解决机制设计和运筹学中的NP难随机优化问题，提升现有算法的性能。", "method": "提出“效用对齐”概念，通过优化代理效用高的情景来简化算法设计。", "result": "改进了单位需求定价、分类优化和委托选择的近似算法，填补了部分问题的空白。", "conclusion": "效用对齐是一个广泛适用的技术，能够简化复杂优化问题的求解。"}}
{"id": "2506.19968", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.19968", "abs": "https://arxiv.org/abs/2506.19968", "authors": ["Sahand Farghdani", "Robin Chhabra"], "title": "Evolutionary Gait Reconfiguration in Damaged Legged Robots", "comment": null, "summary": "Multi-legged robots deployed in complex missions are susceptible to physical\ndamage in their legs, impairing task performance and potentially compromising\nmission success. This letter presents a rapid, training-free damage recovery\nalgorithm for legged robots subject to partial or complete loss of functional\nlegs. The proposed method first stabilizes locomotion by generating a new gait\nsequence and subsequently optimally reconfigures leg gaits via a developed\ndifferential evolution algorithm to maximize forward progression while\nminimizing body rotation and lateral drift. The algorithm successfully restores\nlocomotion in a 24-degree-of-freedom hexapod within one hour, demonstrating\nboth high efficiency and robustness to structural damage.", "AI": {"tldr": "提出了一种无需训练的快速损伤恢复算法，用于多足机器人在部分或完全失去功能腿时恢复运动。", "motivation": "多足机器人在复杂任务中易受腿部物理损伤影响，影响任务完成和任务成功率。", "method": "通过生成新步态序列稳定运动，并利用差分进化算法优化步态配置，以最大化前进并减少身体旋转和侧移。", "result": "算法在24自由度六足机器人上成功在一小时内恢复运动，表现出高效性和对结构损伤的鲁棒性。", "conclusion": "该算法为多足机器人提供了一种快速、无需训练的损伤恢复解决方案。"}}
{"id": "2506.19882", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.19882", "abs": "https://arxiv.org/abs/2506.19882", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "Yegor Denisov-Blanch", "Brando Miranda", "Matthias Gerstgrasser", "Susan Zhang", "Andreas Haupt", "Isha Gupta", "Elyas Obbad", "Jesse Dodge", "Jessica Zosa Forde", "Koustuv Sinha", "Francesco Orabona", "Sanmi Koyejo", "David Donoho"], "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track", "comment": null, "summary": "Science progresses by iteratively advancing and correcting humanity's\nunderstanding of the world. In machine learning (ML) research, rapid\nadvancements have led to an explosion of publications, but have also led to\nmisleading, incorrect, flawed or perhaps even fraudulent studies being accepted\nand sometimes highlighted at ML conferences due to the fallibility of peer\nreview. While such mistakes are understandable, ML conferences do not offer\nrobust processes to help the field systematically correct when such errors are\nmade.This position paper argues that ML conferences should establish a\ndedicated \"Refutations and Critiques\" (R & C) Track. This R & C Track would\nprovide a high-profile, reputable platform to support vital research that\ncritically challenges prior research, thereby fostering a dynamic\nself-correcting research ecosystem. We discuss key considerations including\ntrack design, review principles, potential pitfalls, and provide an\nillustrative example submission concerning a recent ICLR 2025 Oral. We conclude\nthat ML conferences should create official, reputable mechanisms to help ML\nresearch self-correct.", "AI": {"tldr": "该立场论文主张机器学习会议应设立专门的“反驳与批评”轨道，以促进研究的自我修正。", "motivation": "机器学习研究快速发展导致错误研究被接受，缺乏系统修正机制。", "method": "提出设立“反驳与批评”轨道，讨论其设计、评审原则及潜在问题。", "result": "通过高声誉平台支持批判性研究，推动研究生态自我修正。", "conclusion": "机器学习会议应建立官方机制以促进研究的自我修正。"}}
{"id": "2506.20202", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2506.20202", "abs": "https://arxiv.org/abs/2506.20202", "authors": ["Da Li", "Donggang Jia", "Yousef Rajeh", "Dominik Engel", "Ivan Viola"], "title": "RaRa Clipper: A Clipper for Gaussian Splatting Based on Ray Tracer and Rasterizer", "comment": null, "summary": "With the advancement of Gaussian Splatting techniques, a growing number of\ndatasets based on this representation have been developed. However, performing\naccurate and efficient clipping for Gaussian Splatting remains a challenging\nand unresolved problem, primarily due to the volumetric nature of Gaussian\nprimitives, which makes hard clipping incapable of precisely localizing their\npixel-level contributions. In this paper, we propose a hybrid rendering\nframework that combines rasterization and ray tracing to achieve efficient and\nhigh-fidelity clipping of Gaussian Splatting data. At the core of our method is\nthe RaRa strategy, which first leverages rasterization to quickly identify\nGaussians intersected by the clipping plane, followed by ray tracing to compute\nattenuation weights based on their partial occlusion. These weights are then\nused to accurately estimate each Gaussian's contribution to the final image,\nenabling smooth and continuous clipping effects. We validate our approach on\ndiverse datasets, including general Gaussians, hair strand Gaussians, and\nmulti-layer Gaussians, and conduct user studies to evaluate both perceptual\nquality and quantitative performance. Experimental results demonstrate that our\nmethod delivers visually superior results while maintaining real-time rendering\nperformance and preserving high fidelity in the unclipped regions.", "AI": {"tldr": "提出了一种结合光栅化和光线追踪的混合渲染框架，用于高效且高保真地裁剪高斯泼溅数据。", "motivation": "高斯泼溅技术的进步催生了大量基于此表示的数据集，但因其体积特性，精确高效的裁剪仍是一个未解决的挑战。", "method": "采用RaRa策略，先通过光栅化快速识别被裁剪平面相交的高斯，再通过光线追踪计算部分遮挡的衰减权重，以准确估计其对最终图像的贡献。", "result": "在多种数据集上验证了方法的有效性，用户研究表明其在感知质量和定量性能上均表现优异。", "conclusion": "该方法在保持实时渲染性能和高保真度的同时，实现了视觉上更优的裁剪效果。"}}
{"id": "2506.20011", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2506.20011", "abs": "https://arxiv.org/abs/2506.20011", "authors": ["Soufiane El Yaagoubi", "Keith Moffat", "Eduardo Prieto Araujo", "Florian Dörfler"], "title": "Recursive-ARX for Grid-Edge Fault Detection", "comment": "6 pages, 9 figures, to be presented at IEEE PowerTech 2025 (Kiel,\n  Germany)", "summary": "Future electrical grids will require new ways to identify faults as inverters\nare not capable of supplying large fault currents to support existing fault\ndetection methods and because distributed resources may feed faults from the\nedge of the grid. This paper proposes the use of real-time system\nidentification for online power-system fault detection. Specifically, we\nimplement Recursive ARX (rARX) system identification on a grid-connected\ninverter. Experiments demonstrate that the proposed rARX method is able to both\ndetect large faults quickly, and distinguish between high-impedance faults and\nlarge load increases. These results indicate that rARX grid-edge fault\ndetection is a promising research direction for improving the reliability and\nsafety of modern electric grids.", "AI": {"tldr": "论文提出使用实时系统辨识（rARX）方法进行电网故障检测，适用于逆变器无法提供大故障电流的现代电网。", "motivation": "未来电网中逆变器无法提供大故障电流，且分布式资源可能从电网边缘供电，需要新的故障检测方法。", "method": "采用递归ARX（rARX）系统辨识方法，在并网逆变器上实现实时故障检测。", "result": "实验表明rARX能快速检测大故障，并区分高阻抗故障与大负载增加。", "conclusion": "rARX电网边缘故障检测是提高现代电网可靠性和安全性的有前景的研究方向。"}}
{"id": "2506.19955", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19955", "abs": "https://arxiv.org/abs/2506.19955", "authors": ["Yiming Ma", "Victor Sanchez", "Tanaya Guha"], "title": "EBC-ZIP: Improving Blockwise Crowd Counting with Zero-Inflated Poisson Regression", "comment": null, "summary": "Density map estimation has become the mainstream paradigm in crowd counting.\nHowever, most existing methods overlook the extreme sparsity of ground-truth\ndensity maps. In real-world crowd scenes, the vast majority of spatial regions\n(often over 95%) contain no people, leading to heavily imbalanced count\ndistributions. Ignoring this imbalance can bias models toward overestimating\ndense regions and underperforming in sparse areas. Furthermore, most loss\nfunctions used in density estimation are majorly based on MSE and implicitly\nassume Gaussian distributions, which are ill-suited for modeling discrete,\nnon-negative count data. In this paper, we propose EBC-ZIP, a crowd counting\nframework that models the spatial distribution of counts using a Zero-Inflated\nPoisson (ZIP) regression formulation. Our approach replaces the traditional\nregression loss with the negative log-likelihood of the ZIP distribution,\nenabling better handling of zero-heavy distributions while preserving count\naccuracy. Built upon the recently proposed Enhanced Block Classification (EBC)\nframework, EBC-ZIP inherits EBC's advantages in preserving the discreteness of\ntargets and ensuring training stability, while further improving performance\nthrough a more principled probabilistic loss. We also evaluate EBC-ZIP with\nbackbones of varying computational complexity to assess its scalability.\nExtensive experiments on four crowd counting benchmarks demonstrate that\nEBC-ZIP consistently outperforms EBC and achieves state-of-the-art results.", "AI": {"tldr": "论文提出EBC-ZIP框架，通过零膨胀泊松回归改进人群计数中的密度图估计，解决数据稀疏性问题。", "motivation": "现有方法忽视地面真实密度图的极端稀疏性，导致模型在稀疏区域表现不佳。", "method": "采用零膨胀泊松回归（ZIP）替代传统回归损失，结合增强块分类（EBC）框架。", "result": "在四个基准测试中，EBC-ZIP表现优于EBC，达到最先进水平。", "conclusion": "EBC-ZIP通过更合理的概率损失，提升了人群计数的准确性和稳定性。"}}
{"id": "2506.20055", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.20055", "abs": "https://arxiv.org/abs/2506.20055", "authors": ["Seraphina Yong", "Ashlee Milton", "Evan Suma Rosenberg", "Stevie Chancellor", "Svetlana Yarosh"], "title": "\"I'm Petting the Laptop, Which Has You Inside It\": Reflecting on Lived Experiences of Online Friendship", "comment": "CSCW 2025, 29 article pages, 5 pages of references, 3 figures", "summary": "Online(-only) friendships have become increasingly common in daily lives\npost-COVID despite debates around their mental health benefits and equivalence\nto ''real'' relationships. Previous research has reflected a need to understand\nhow online friends engage beyond individual platforms, and the lack of\nplatform-agnostic inquiry limits our ability to fully understand the dynamics\nof online friendship. We employed an activity-grounded analysis of 25\ninterviews on lived experiences of close online friendship spanning multiple\nyears. Our findings present unique challenges and strategies in online\nfriendships, such as stigma from real-life circles, an ambivalent relationship\nwith online communities, and counter-theoretical reappropriations of\ncommunication technology. This study contributes to HCI research in online\ncommunities and social interface design by refocusing prior impressions of\nstrong vs. weak-ties in online social spaces and foregrounding time-stable\ninteractions in design for relationship maintenance through technology. Our\nwork also promotes critical reflection on biased perspectives towards\ntechnology-mediated practices and consideration of online friends as an\ninvisible marginalized community.", "AI": {"tldr": "研究探讨了在线友谊的独特挑战与策略，包括现实圈子的污名化、与在线社区的矛盾关系，以及通信技术的反理论重新利用。", "motivation": "理解在线友谊的动态及其在心理健康和关系维护中的作用，填补平台无关研究的空白。", "method": "对25个长期在线友谊的生活经历访谈进行活动基础分析。", "result": "揭示了在线友谊的独特挑战与策略，并重新定义了在线社交空间中的强弱关系。", "conclusion": "研究为HCI和社交界面设计提供了新视角，强调技术中介关系的时间稳定性，并呼吁对在线朋友作为边缘化群体的关注。"}}
{"id": "2506.20400", "categories": ["cs.MA", "cs.CE", "cs.HC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.20400", "abs": "https://arxiv.org/abs/2506.20400", "authors": ["Kristoffer Christensen", "Bo Nørregaard Jørgensen", "Zheng Grace Ma"], "title": "A Visualization Framework for Exploring Multi-Agent-Based Simulations Case Study of an Electric Vehicle Home Charging Ecosystem", "comment": null, "summary": "Multi-agent-based simulations (MABS) of electric vehicle (EV) home charging\necosystems generate large, complex, and stochastic time-series datasets that\ncapture interactions between households, grid infrastructure, and energy\nmarkets. These interactions can lead to unexpected system-level events, such as\ntransformer overloads or consumer dissatisfaction, that are difficult to detect\nand explain through static post-processing. This paper presents a modular,\nPython-based dashboard framework, built using Dash by Plotly, that enables\nefficient, multi-level exploration and root-cause analysis of emergent behavior\nin MABS outputs. The system features three coordinated views (System Overview,\nSystem Analysis, and Consumer Analysis), each offering high-resolution\nvisualizations such as time-series plots, spatial heatmaps, and agent-specific\ndrill-down tools. A case study simulating full EV adoption with smart charging\nin a Danish residential network demonstrates how the dashboard supports rapid\nidentification and contextual explanation of anomalies, including clustered\ntransformer overloads and time-dependent charging failures. The framework\nfacilitates actionable insight generation for researchers and distribution\nsystem operators, and its architecture is adaptable to other distributed energy\nresources and complex energy systems.", "AI": {"tldr": "该论文提出了一种基于Python的模块化仪表盘框架，用于分析和解释多智能体电动汽车充电模拟中的复杂数据。", "motivation": "多智能体电动汽车充电模拟生成的数据复杂且随机，难以通过静态后处理检测和解释系统级事件。", "method": "开发了一个基于Dash by Plotly的仪表盘框架，包含三个协调视图（系统概览、系统分析和消费者分析），提供高分辨率可视化工具。", "result": "案例研究表明，该框架能快速识别和解释异常，如变压器过载和充电失败。", "conclusion": "该框架为研究人员和电网运营商提供了可操作的见解，并适用于其他分布式能源系统。"}}
{"id": "2506.20317", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2506.20317", "abs": "https://arxiv.org/abs/2506.20317", "authors": ["George Christodoulou", "Symeon Mastrakoulis"], "title": "Exact and approximate maximin share allocations in multi-graphs", "comment": null, "summary": "We study the problem of (approximate) maximin share (MMS) allocation of\nindivisible items among a set of agents. We focus on the graphical valuation\nmodel, previously studied by Christodolou, Fiat, Koutsoupias, and Sgouritsa\n(\"Fair allocation in graphs\", EC 2023), where the input is given by a graph\nwhere edges correspond to items, and vertices correspond to agents. An edge may\nhave non-zero marginal value only for its incident vertices. We study additive,\nXOS and subadditive valuations and we present positive and negative results for\n(approximate) MMS fairness, and also for (approximate) pair-wise maximin share\n(PMMS) fairness.", "AI": {"tldr": "研究在图形估值模型下不可分割物品的最大最小份额（MMS）分配问题，探讨了不同估值类型下的正负结果。", "motivation": "探索图形估值模型中MMS和PMMS公平分配的可行性和近似解。", "method": "基于图形模型，分析边对应物品、顶点对应代理的分配问题，研究加性、XOS和次加性估值。", "result": "提出了MMS和PMMS公平分配的正负结果，展示了不同估值类型下的近似解。", "conclusion": "图形估值模型为MMS和PMMS公平分配提供了新的研究视角，但结果因估值类型而异。"}}
{"id": "2506.19984", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.19984", "abs": "https://arxiv.org/abs/2506.19984", "authors": ["Sahand Farghdani", "Mili Patel", "Robin Chhabra"], "title": "Robust Embodied Self-Identification of Morphology in Damaged Multi-Legged Robots", "comment": null, "summary": "Multi-legged robots (MLRs) are vulnerable to leg damage during complex\nmissions, which can impair their performance. This paper presents a\nself-modeling and damage identification algorithm that enables autonomous\nadaptation to partial or complete leg loss using only data from a low-cost IMU.\nA novel FFT-based filter is introduced to address time-inconsistent signals,\nimproving damage detection by comparing body orientation between the robot and\nits model. The proposed method identifies damaged legs and updates the robot's\nmodel for integration into its control system. Experiments on uneven terrain\nvalidate its robustness and computational efficiency.", "AI": {"tldr": "提出了一种基于低成本IMU的自建模与损伤识别算法，帮助多足机器人自主适应腿部损伤。", "motivation": "多足机器人在复杂任务中易受腿部损伤影响性能，需自主适应能力。", "method": "引入FFT滤波器处理时间不一致信号，通过比较机器人与模型的身体方向检测损伤，更新模型并集成到控制系统。", "result": "在崎岖地形实验中验证了算法的鲁棒性和计算效率。", "conclusion": "该方法能有效识别损伤并自主适应，提升多足机器人的可靠性。"}}
{"id": "2506.19883", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19883", "abs": "https://arxiv.org/abs/2506.19883", "authors": ["Zhuqing Liu", "Chaosheng Dong", "Michinari Momma", "Simone Shao", "Shaoyuan Xu", "Yan Gao", "Haibo Yang", "Jia Liu"], "title": "STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning", "comment": null, "summary": "Recently, multi-objective optimization (MOO) has gained attention for its\nbroad applications in ML, operations research, and engineering. However, MOO\nalgorithm design remains in its infancy and many existing MOO methods suffer\nfrom unsatisfactory convergence rate and sample complexity performance. To\naddress this challenge, in this paper, we propose an algorithm called STIMULUS(\nstochastic path-integrated multi-gradient recursive e\\ulstimator), a new and\nrobust approach for solving MOO problems. Different from the traditional\nmethods, STIMULUS introduces a simple yet powerful recursive framework for\nupdating stochastic gradient estimates to improve convergence performance with\nlow sample complexity. In addition, we introduce an enhanced version of\nSTIMULUS, termed STIMULUS-M, which incorporates a momentum term to further\nexpedite convergence. We establish $O(1/T)$ convergence rates of the proposed\nmethods for non-convex settings and $O (\\exp{-\\mu T})$ for strongly convex\nsettings, where $T$ is the total number of iteration rounds. Additionally, we\nachieve the state-of-the-art $O \\left(n+\\sqrt{n}\\epsilon^{-1}\\right)$ sample\ncomplexities for non-convex settings and $O\\left(n+ \\sqrt{n} \\ln\n({\\mu/\\epsilon})\\right)$ for strongly convex settings, where $\\epsilon>0$ is a\ndesired stationarity error. Moreover, to alleviate the periodic full gradient\nevaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced\nversions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their\ntheoretical analysis.", "AI": {"tldr": "提出了一种名为STIMULUS的新算法，用于解决多目标优化问题，通过递归框架改进收敛性能和样本复杂度，并进一步提出带动量项的STIMULUS-M和自适应批处理的STIMULUS+/STIMULUS-M+。", "motivation": "多目标优化（MOO）在机器学习和工程中应用广泛，但现有方法收敛速度和样本复杂度表现不佳，需要改进。", "method": "STIMULUS采用递归框架更新随机梯度估计，STIMULUS-M加入动量项，STIMULUS+/STIMULUS-M+引入自适应批处理以减少全梯度评估需求。", "result": "在非凸和强凸设置下分别达到$O(1/T)$和$O(\\exp{-\\mu T})$的收敛速率，样本复杂度达到当前最优水平。", "conclusion": "STIMULUS及其变体在多目标优化中表现出色，显著提升了收敛性能和样本效率。"}}
{"id": "2506.20267", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20267", "abs": "https://arxiv.org/abs/2506.20267", "authors": ["Fabian Bongratz", "Tom Nuno Wolf", "Jaume Gual Ramon", "Christian Wachinger"], "title": "X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis", "comment": "MICCAI 2025", "summary": "Interpretable models are crucial for supporting clinical decision-making,\ndriving advances in their development and application for medical images.\nHowever, the nature of 3D volumetric data makes it inherently challenging to\nvisualize and interpret intricate and complex structures like the cerebral\ncortex. Cortical surface renderings, on the other hand, provide a more\naccessible and understandable 3D representation of brain anatomy, facilitating\nvisualization and interactive exploration. Motivated by this advantage and the\nwidespread use of surface data for studying neurological disorders, we present\nthe eXplainable Surface Vision Transformer (X-SiT). This is the first\ninherently interpretable neural network that offers human-understandable\npredictions based on interpretable cortical features. As part of X-SiT, we\nintroduce a prototypical surface patch decoder for classifying surface patch\nembeddings, incorporating case-based reasoning with spatially corresponding\ncortical prototypes. The results demonstrate state-of-the-art performance in\ndetecting Alzheimer's disease and frontotemporal dementia while additionally\nproviding informative prototypes that align with known disease patterns and\nreveal classification errors.", "AI": {"tldr": "论文提出了一种可解释的表面视觉变换器（X-SiT），用于基于可解释的皮层特征进行医学图像分析，并在阿尔茨海默病和额颞叶痴呆检测中表现出色。", "motivation": "3D体积数据的复杂性和难以可视化促使研究者开发更易理解的皮层表面渲染方法，以支持临床决策。", "method": "X-SiT结合了原型表面补丁解码器，通过案例推理和空间对应的皮层原型进行分类。", "result": "X-SiT在阿尔茨海默病和额颞叶痴呆检测中达到最新水平，并提供与已知疾病模式一致的原型。", "conclusion": "X-SiT首次实现了基于可解释特征的神经网络预测，为医学图像分析提供了新的工具。"}}
{"id": "2506.20238", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2506.20238", "abs": "https://arxiv.org/abs/2506.20238", "authors": ["Dong Liu", "Sander Timmerman", "Yu Xiang", "Peter Palensky", "Pedro P. Vergara"], "title": "A Data-Driven Approach for Topology Correction in Low Voltage Networks with DERs", "comment": null, "summary": "This paper introduces a data-driven topology identification and correction\napproach for low-voltage distribution networks (LVDNs) combined with a\ntime-based smart meter data selection strategy, aiming to correct outdated\nrecordings and identify the missed recordings. The proposed approach solely\nrelies on voltage magnitude measurements, releasing privacy concerns and\nmeasurement burdens. It enables the distribution system operators to identify\nswitch states through supervised learning algorithms, as well as determine\nuser-feeder connections and phase labels of customers by a modified\nHierarchical Clustering algorithm. To address the similarity among smart meter\n(SM) data caused by distributed photovoltaic (PV) systems, a time-based SM data\nselection strategy is combined with the proposed correlation analysis. The\nfeasibility and robustness of the proposed approach are validated using\nmodified real-world LVDNs and multiple incomplete SM datasets collected from\ncustomers in the Netherlands. The results demonstrate that the time-based SM\ndata selection strategy effectively mitigates their impact on phase\nidentification, and the corrected topology not only improves network\nobservability but also supports network operators in load balancing and PV\nconsumption.", "AI": {"tldr": "论文提出了一种基于数据驱动的低压配电网拓扑识别与校正方法，结合时间智能电表数据选择策略，旨在修正过时记录并识别遗漏记录。", "motivation": "解决低压配电网中拓扑记录过时或遗漏的问题，同时减少隐私问题和测量负担。", "method": "仅依赖电压幅值测量，通过监督学习算法识别开关状态，改进的层次聚类算法确定用户-馈线连接和相位标签，结合时间智能电表数据选择策略。", "result": "在荷兰的真实低压配电网和不完整电表数据集上验证了方法的可行性和鲁棒性，时间选择策略有效减轻了光伏系统对相位识别的影响。", "conclusion": "校正后的拓扑提高了网络可观测性，支持负载平衡和光伏消纳。"}}
{"id": "2506.20066", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20066", "abs": "https://arxiv.org/abs/2506.20066", "authors": ["Hsiang-Wei Huang", "Wenhao Chai", "Kuang-Ming Chen", "Cheng-Yen Yang", "Jenq-Neng Hwang"], "title": "ToSA: Token Merging with Spatial Awareness", "comment": "Accepted by IROS 2025", "summary": "Token merging has emerged as an effective strategy to accelerate Vision\nTransformers (ViT) by reducing computational costs. However, existing methods\nprimarily rely on the visual token's feature similarity for token merging,\noverlooking the potential of integrating spatial information, which can serve\nas a reliable criterion for token merging in the early layers of ViT, where the\nvisual tokens only possess weak visual information. In this paper, we propose\nToSA, a novel token merging method that combines both semantic and spatial\nawareness to guide the token merging process. ToSA leverages the depth image as\ninput to generate pseudo spatial tokens, which serve as auxiliary spatial\ninformation for the visual token merging process. With the introduced spatial\nawareness, ToSA achieves a more informed merging strategy that better preserves\ncritical scene structure. Experimental results demonstrate that ToSA\noutperforms previous token merging methods across multiple benchmarks on visual\nand embodied question answering while largely reducing the runtime of the ViT,\nmaking it an efficient solution for ViT acceleration. The code will be\navailable at: https://github.com/hsiangwei0903/ToSA", "AI": {"tldr": "ToSA是一种结合语义和空间信息的新颖令牌合并方法，通过深度图像生成伪空间令牌，优化视觉Transformer的加速效果。", "motivation": "现有令牌合并方法主要依赖视觉令牌的特征相似性，忽略了空间信息在早期层中的潜力。", "method": "提出ToSA，利用深度图像生成伪空间令牌，结合语义和空间信息指导令牌合并。", "result": "ToSA在多个视觉和具身问答基准上优于现有方法，同时显著减少ViT运行时间。", "conclusion": "ToSA是一种高效的ViT加速解决方案，代码将开源。"}}
{"id": "2506.20062", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20062", "abs": "https://arxiv.org/abs/2506.20062", "authors": ["Runlong Ye", "Zeling Zhang", "Boushra Almazroua", "Michael Liut"], "title": "Beyond Autocomplete: Designing CopilotLens Towards Transparent and Explainable AI Coding Agents", "comment": null, "summary": "AI-powered code assistants are widely used to generate code completions,\nsignificantly boosting developer productivity. However, these tools typically\npresent suggestions without explaining their rationale, leaving their\ndecision-making process inscrutable. This opacity hinders developers' ability\nto critically evaluate the output, form accurate mental models, and build\ncalibrated trust in the system. To address this, we introduce CopilotLens, a\nnovel interactive framework that reframes code completion from a simple\nsuggestion into a transparent, explainable event. CopilotLens operates as an\nexplanation layer that reveals the AI agent's \"thought process\" through a\ndynamic two-level interface, surfacing everything from its reconstructed\nhigh-level plans to the specific codebase context influencing the code. This\npaper presents the design and rationale of CopilotLens, offering a concrete\nframework for building future agentic code assistants that prioritize clarity\nof reasoning over speed of suggestion, thereby fostering deeper comprehension\nand more robust human-AI collaboration.", "AI": {"tldr": "CopilotLens是一个交互式框架，通过透明化AI代码助手的决策过程，提升开发者对代码建议的理解和信任。", "motivation": "当前AI代码助手缺乏解释性，开发者难以理解其决策逻辑，影响了信任和效率。", "method": "CopilotLens作为解释层，通过动态两级界面展示AI的“思考过程”，包括高层计划和代码库上下文。", "result": "CopilotLens提供了一个透明化框架，促进开发者对AI建议的深入理解和信任。", "conclusion": "CopilotLens为未来代码助手设计提供了新方向，强调推理的清晰性而非速度，优化人机协作。"}}
{"id": "2506.20036", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20036", "abs": "https://arxiv.org/abs/2506.20036", "authors": ["Jeremiah Coholich", "Muhammad Ali Murtaza", "Seth Hutchinson", "Zsolt Kira"], "title": "Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion", "comment": null, "summary": "We propose a novel hierarchical reinforcement learning framework for\nquadruped locomotion over challenging terrain. Our approach incorporates a\ntwo-layer hierarchy in which a high-level policy (HLP) selects optimal goals\nfor a low-level policy (LLP). The LLP is trained using an on-policy\nactor-critic RL algorithm and is given footstep placements as goals. We propose\nan HLP that does not require any additional training or environment samples and\ninstead operates via an online optimization process over the learned value\nfunction of the LLP. We demonstrate the benefits of this framework by comparing\nit with an end-to-end reinforcement learning (RL) approach. We observe\nimprovements in its ability to achieve higher rewards with fewer collisions\nacross an array of different terrains, including terrains more difficult than\nany encountered during training.", "AI": {"tldr": "提出了一种新颖的分层强化学习框架，用于四足机器人在复杂地形上的运动。该方法通过高层策略选择目标，低层策略执行，无需额外训练，表现优于端到端方法。", "motivation": "解决四足机器人在复杂地形上的运动问题，提高运动效率和安全性。", "method": "采用两层分层结构，高层策略通过在线优化选择目标，低层策略使用actor-critic算法执行。", "result": "在多种复杂地形上表现优于端到端方法，奖励更高且碰撞更少。", "conclusion": "分层强化学习框架在复杂地形运动任务中具有显著优势。"}}
{"id": "2506.19885", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.19885", "abs": "https://arxiv.org/abs/2506.19885", "authors": ["Jing Lu", "Xuan Wu", "Yizhun Tian", "Songhan Fan", "Yali Fang"], "title": "FlightKooba: A Fast Interpretable FTP Model", "comment": "7 figures", "summary": "The Koopman theory is a powerful and effective modeling tool for converting\nnonlinear systems into linear representations, and flight trajectory prediction\n(FTP) is a complex nonlinear system. However, current models applying the\nKoopman theory to FTP tasks are not very effective, model interpretability is\nindeed an issue, and the Koopman operators are computationally intensive,\nresulting in long training times. To address this issue, this paper proposes a\nnew modeling and control framework based on the HIPPO method, the Koopman\ntheory, and state space equations from cybernetics: FlightKooba. Inspired by\nthe idea of structural state space equations, FlightKooba directly constructs\nthe Koopman operators from data. This makes the framework highly interpretable\nand significantly reduces the number of trainable parameters in the module,\nthereby greatly reducing training time. Experiments have demonstrated the\nsuperiority of the FlightKooba modeling method in terms of time and memory\nconsumption (training time comparable to the Mamba module without using\nCUDA-level acceleration; memory reduced by more than 50% on most datasets, with\na tenfold reduction in the number of parameters), essentially completing the\nFTP task. It provides a new method for the fast computation of the Koopman\noperators, opening up new possibilities for the combination of time series\nforecasting and control.", "AI": {"tldr": "论文提出FlightKooba框架，结合HIPPO方法、Koopman理论和状态空间方程，显著提升飞行轨迹预测的效率和可解释性。", "motivation": "当前基于Koopman理论的飞行轨迹预测模型效率低、可解释性差且计算量大，亟需改进。", "method": "FlightKooba直接通过数据构建Koopman算子，减少可训练参数，降低计算复杂度。", "result": "实验显示FlightKooba在时间和内存消耗上表现优异，训练时间接近Mamba模块，内存减少50%以上，参数数量减少十倍。", "conclusion": "FlightKooba为Koopman算子的快速计算提供了新方法，为时间序列预测与控制的结合开辟了新途径。"}}
{"id": "2506.20367", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20367", "abs": "https://arxiv.org/abs/2506.20367", "authors": ["Edoardo Alberto Dominici", "Jozef Hladky", "Floor Verhoeven", "Lukas Radl", "Thomas Deixelberger", "Stefan Ainetter", "Philipp Drescher", "Stefan Hauswiesner", "Arno Coomans", "Giacomo Nazzaro", "Konstantinos Vardis", "Markus Steinberger"], "title": "DreamAnywhere: Object-Centric Panoramic 3D Scene Generation", "comment": null, "summary": "Recent advances in text-to-3D scene generation have demonstrated significant\npotential to transform content creation across multiple industries. Although\nthe research community has made impressive progress in addressing the\nchallenges of this complex task, existing methods often generate environments\nthat are only front-facing, lack visual fidelity, exhibit limited scene\nunderstanding, and are typically fine-tuned for either indoor or outdoor\nsettings. In this work, we address these issues and propose DreamAnywhere, a\nmodular system for the fast generation and prototyping of 3D scenes. Our system\nsynthesizes a 360{\\deg} panoramic image from text, decomposes it into\nbackground and objects, constructs a complete 3D representation through hybrid\ninpainting, and lifts object masks to detailed 3D objects that are placed in\nthe virtual environment. DreamAnywhere supports immersive navigation and\nintuitive object-level editing, making it ideal for scene exploration, visual\nmock-ups, and rapid prototyping -- all with minimal manual modeling. These\nfeatures make our system particularly suitable for low-budget movie production,\nenabling quick iteration on scene layout and visual tone without the overhead\nof traditional 3D workflows. Our modular pipeline is highly customizable as it\nallows components to be replaced independently. Compared to current\nstate-of-the-art text and image-based 3D scene generation approaches,\nDreamAnywhere shows significant improvements in coherence in novel view\nsynthesis and achieves competitive image quality, demonstrating its\neffectiveness across diverse and challenging scenarios. A comprehensive user\nstudy demonstrates a clear preference for our method over existing approaches,\nvalidating both its technical robustness and practical usefulness.", "AI": {"tldr": "DreamAnywhere是一个模块化系统，用于快速生成和原型化3D场景，解决了现有方法在视觉保真度、场景理解和多环境适应性上的不足。", "motivation": "现有文本到3D场景生成方法存在仅面向正面、视觉保真度低、场景理解有限且仅适用于特定环境的问题。", "method": "系统通过合成360度全景图像，分解为背景和对象，通过混合修复构建完整3D表示，并将对象掩码提升为详细3D对象。", "result": "在新型视图合成一致性和图像质量上显著优于现有方法，用户研究显示其技术稳健性和实用性。", "conclusion": "DreamAnywhere为低成本电影制作等场景提供了高效的原型设计和编辑工具，具有高度可定制性。"}}
{"id": "2506.20244", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2506.20244", "abs": "https://arxiv.org/abs/2506.20244", "authors": ["Fangzhi Li", "Zhichu Ren", "Cunhua Pan", "Hong Ren", "Jing Jin", "Qixing Wang", "Jiangzhou Wang"], "title": "Cooperative Sensing and Communication Beamforming Design for Low-Altitude Economy", "comment": null, "summary": "To empower the low-altitude economy with high-accuracy sensing and high-rate\ncommunication, this paper proposes a cooperative integrated sensing and\ncommunication (ISAC) framework for aerial-ground networks. In the proposed\nsystem, the ground base stations (BSs) cooperatively serve the unmanned aerial\nvehicles (UAVs), which are equipped for either joint communication and sensing\nor sensing-only operations. The BSs employ coordinated beamforming to\nsimultaneously transmit communication and sensing signals, while the UAVs\nexecute their missions. To maximize the weighted sum rate under the sensing\nsignal-to-interference-plus-noise ratio (SINR) constraints, we jointly optimize\nthe transmit beamforming, receive filtering, and UAV trajectory. The resulting\nnon-convex problem is solved using an alternating optimization framework\nincorporating semidefinite relaxation (SDR) and successive convex approximation\n(SCA). Simulation results demonstrate that the proposed joint design achieves\nhigher communication throughput while ensuring required sensing robustness.\nAdditionally, the sensing SINR threshold and the UAV altitude have a\nsignificant impact on the trajectory design, highlighting the necessity of\nadaptive deployment strategies in practical applications.", "AI": {"tldr": "本文提出了一种用于空地网络的协作式集成感知与通信（ISAC）框架，通过优化波束成形、接收滤波和无人机轨迹，实现高精度感知和高速通信。", "motivation": "为低空经济提供高精度感知和高速通信能力，解决空地网络中感知与通信的协同问题。", "method": "采用协作波束成形技术，联合优化波束成形、接收滤波和无人机轨迹，使用半定松弛（SDR）和逐次凸近似（SCA）解决非凸问题。", "result": "仿真结果表明，联合设计在保证感知鲁棒性的同时提高了通信吞吐量，感知SINR阈值和无人机高度对轨迹设计有显著影响。", "conclusion": "自适应部署策略在实际应用中至关重要，联合优化设计能够有效提升空地网络的性能。"}}
{"id": "2506.20103", "categories": ["cs.CV", "cs.AI", "I.4"], "pdf": "https://arxiv.org/pdf/2506.20103", "abs": "https://arxiv.org/abs/2506.20103", "authors": ["Jiahao Lin", "Weixuan Peng", "Bojia Zi", "Yifeng Gao", "Xianbiao Qi", "Xingjun Ma", "Yu-Gang Jiang"], "title": "BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos", "comment": "7 page,4 figures,2 tables", "summary": "Recent advances in deep generative models have led to significant progress in\nvideo generation, yet the fidelity of AI-generated videos remains limited.\nSynthesized content often exhibits visual artifacts such as temporally\ninconsistent motion, physically implausible trajectories, unnatural object\ndeformations, and local blurring that undermine realism and user trust.\nAccurate detection and spatial localization of these artifacts are crucial for\nboth automated quality control and for guiding the development of improved\ngenerative models. However, the research community currently lacks a\ncomprehensive benchmark specifically designed for artifact localization in AI\ngenerated videos. Existing datasets either restrict themselves to video or\nframe level detection or lack the fine-grained spatial annotations necessary\nfor evaluating localization methods. To address this gap, we introduce\nBrokenVideos, a benchmark dataset of 3,254 AI-generated videos with\nmeticulously annotated, pixel-level masks highlighting regions of visual\ncorruption. Each annotation is validated through detailed human inspection to\nensure high quality ground truth. Our experiments show that training state of\nthe art artifact detection models and multi modal large language models (MLLMs)\non BrokenVideos significantly improves their ability to localize corrupted\nregions. Through extensive evaluation, we demonstrate that BrokenVideos\nestablishes a critical foundation for benchmarking and advancing research on\nartifact localization in generative video models. The dataset is available at:\nhttps://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.", "AI": {"tldr": "论文提出BrokenVideos数据集，用于AI生成视频中视觉伪影的像素级定位，填补了现有基准的空白。", "motivation": "当前AI生成视频存在视觉伪影问题，但缺乏针对伪影定位的全面基准数据集。", "method": "构建BrokenVideos数据集，包含3,254个AI生成视频，标注像素级伪影区域，并通过人工验证。", "result": "实验表明，基于BrokenVideos训练的模型能显著提升伪影定位能力。", "conclusion": "BrokenVideos为生成视频模型的伪影定位研究提供了关键基准。"}}
{"id": "2506.20091", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.20091", "abs": "https://arxiv.org/abs/2506.20091", "authors": ["Sarah Schömbs", "Yan Zhang", "Jorge Goncalves", "Wafa Johal"], "title": "From Conversation to Orchestration: HCI Challenges and Opportunities in Interactive Multi-Agentic Systems", "comment": null, "summary": "Recent advances in multi-agentic systems (e.g. AutoGen, OpenAI Swarm) allow\nusers to interact with a group of specialised AI agents rather than a single\ngeneral-purpose agent. Despite the promise of this new paradigm, the HCI\ncommunity has yet to fully examine the opportunities, risks, and user-centred\nchallenges it introduces. We contribute to research on multi-agentic systems by\nexploring their architectures and key features through a human-centred lens.\nWhile literature and use cases remain limited, we build on existing tools and\nframeworks available to developers to identify a set of overarching challenges,\ne.g. orchestration and conflict resolution, that can guide future research in\nHCI. We illustrate these challenges through examples, offer potential design\nconsiderations, and provide research opportunities to spark interdisciplinary\nconversation. Our work lays the groundwork for future exploration and offers a\nresearch agenda focused on user-centred design in multi-agentic systems.", "AI": {"tldr": "论文探讨了多智能体系统的架构和关键特性，从人机交互（HCI）的角度分析了其机会、风险和挑战，并提出了未来研究方向。", "motivation": "多智能体系统（如AutoGen、OpenAI Swarm）的出现为用户提供了与多个专业AI代理交互的新范式，但HCI领域尚未充分研究其潜在影响。", "method": "通过分析现有工具和框架，识别多智能体系统的核心挑战（如协调和冲突解决），并结合案例提出设计考虑和研究机会。", "result": "研究总结了多智能体系统在人机交互中的主要挑战，并提供了未来研究的指导方向。", "conclusion": "论文为多智能体系统的用户中心设计奠定了基础，并提出了一个以HCI为重点的研究议程。"}}
{"id": "2506.20493", "categories": ["eess.SY", "cs.GT", "cs.SY"], "pdf": "https://arxiv.org/pdf/2506.20493", "abs": "https://arxiv.org/abs/2506.20493", "authors": ["Yun Xu", "Yunxiao Bai", "Yunyong Zhang", "Peng Wang", "Xuelin Wang", "Jiqun Guo", "Kaijun Xie", "Rusheng Zhao"], "title": "Analyzing the Impact of Strategic Bidding on the Reserve Capacity via a Bi-Level Model", "comment": null, "summary": "The growing integration of renewable energy sources necessitates adequate\nreserve capacity to maintain power balance. However, in market clearing, power\ncompanies with flexible resources may submit strategic bids to maximize\nprofits, potentially compromising system reserves. This paper examines the\neffects of such strategic behavior by modeling the market as a bi-level\nproblem. The upper level represents a strategic company aiming to maximize\nprofit, while the lower level simulates the system operator clearing the market\nbased on submitted offers. To enable duality-based solution methods, we\napproximate unit commitments with a continuous reserve capacity calculation.\nCase studies indicate that, in an imperfectly competitive market, more units\nare incentivized to operate,enhancing system reserves. However, some units go\nonline mainly for profit, ultimately raising electricity costs for consumers.\nThese findings highlight the importance of market design in managing the\ntrade-off between reserve adequacy and economic efficiency in the presence of\nstrategic bidding behavior.", "AI": {"tldr": "论文研究了可再生能源整合背景下，电力公司通过策略性报价影响市场储备容量和电力成本的问题。", "motivation": "随着可再生能源的普及，电力系统需要足够的储备容量来维持平衡，但电力公司可能通过策略性报价牟利，影响储备和市场效率。", "method": "采用双层模型，上层模拟策略性公司最大化利润，下层模拟系统运营商基于报价的市场清算，并采用连续储备容量计算方法。", "result": "研究表明，在不完全竞争市场中，更多机组被激励运行以增加储备，但部分机组仅为利润运行，导致消费者电力成本上升。", "conclusion": "市场设计需平衡储备充足性和经济效率，以应对策略性报价行为。"}}
{"id": "2506.20045", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20045", "abs": "https://arxiv.org/abs/2506.20045", "authors": ["Eric C. Joyce", "Qianwen Zhao", "Nathaniel Burgdorfer", "Long Wang", "Philippos Mordohai"], "title": "Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception", "comment": null, "summary": "Deep object pose estimators are notoriously overconfident. A grasping agent\nthat both estimates the 6-DoF pose of a target object and predicts the\nuncertainty of its own estimate could avoid task failure by choosing not to act\nunder high uncertainty. Even though object pose estimation improves and\nuncertainty quantification research continues to make strides, few studies have\nconnected them to the downstream task of robotic grasping. We propose a method\nfor training lightweight, deep networks to predict whether a grasp guided by an\nimage-based pose estimate will succeed before that grasp is attempted. We\ngenerate training data for our networks via object pose estimation on real\nimages and simulated grasping. We also find that, despite high object\nvariability in grasping trials, networks benefit from training on all objects\njointly, suggesting that a diverse variety of objects can nevertheless\ncontribute to the same goal.", "AI": {"tldr": "提出一种轻量级深度网络方法，用于预测基于图像姿态估计的抓取是否成功，并通过模拟抓取生成训练数据。", "motivation": "现有深度物体姿态估计器过于自信，缺乏不确定性量化，导致抓取任务失败风险高。", "method": "通过真实图像姿态估计和模拟抓取生成训练数据，训练网络预测抓取成功概率。", "result": "网络能从多样化的物体数据中学习，联合训练效果优于单独训练。", "conclusion": "该方法能有效减少抓取任务失败，且多样化数据有助于提升模型性能。"}}
{"id": "2506.19890", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19890", "abs": "https://arxiv.org/abs/2506.19890", "authors": ["Ziru Zhang", "Jiadong Yu", "Danny H. K. Tsang"], "title": "Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction", "comment": null, "summary": "The optimization of quality of experience (QoE) in multi-user virtual reality\n(VR) interactions demands a delicate balance between ultra-low latency,\nhigh-fidelity motion synchronization, and equitable resource allocation. While\nadaptive keyframe extraction mitigates transmission overhead, existing\napproaches often overlook the causal relationships among allocated bandwidth,\nCPU frequency, and user perception, limiting QoE gains. This paper proposes an\nintelligent framework to maximize QoE by integrating adaptive keyframe\nextraction with causal-aware reinforcement learning (RL). First, a novel QoE\nmetric is formulated using the Weber-Fechner Law, combining perceptual\nsensitivity, attention-driven priorities, and motion reconstruction accuracy.\nThe QoE optimization problem is then modeled as a mixed integer programming\n(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational\nresources under horizon-fairness constraints. We propose Partial State Causal\nDeep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep\nDeterministic Policy Gradient (DDPG) method with causal influence detection. By\nleveraging causal information regarding how QoE is influenced and determined by\nvarious actions, we explore actions guided by weights calculated from causal\ninference (CI), which in turn improves training efficiency. Experiments\nconducted with the CMU Motion Capture Database demonstrate that our framework\nsignificantly reduces interactive latency, enhances QoE, and maintains\nfairness, achieving superior performance compared to benchmark methods.", "AI": {"tldr": "论文提出了一种结合自适应关键帧提取和因果感知强化学习的智能框架，以优化多用户VR交互中的QoE。通过新QoE度量和PS-CDDPG算法，显著降低了延迟并提升了性能。", "motivation": "现有方法在优化多用户VR交互的QoE时，忽视了带宽、CPU频率与用户感知之间的因果关系，限制了QoE的提升。", "method": "提出PS-CDDPG算法，结合DDPG和因果推理，优化关键帧比率、带宽和计算资源。", "result": "实验表明，该框架显著降低延迟，提升QoE，并保持公平性。", "conclusion": "该框架在多用户VR交互中实现了更优的QoE优化效果。"}}
{"id": "2506.20652", "categories": ["cs.GR", "cs.CV", "68U05 (Primary), 68T45 (Secondary)", "I.3.7; I.3.8; I.4.9"], "pdf": "https://arxiv.org/pdf/2506.20652", "abs": "https://arxiv.org/abs/2506.20652", "authors": ["Roi Bar-On", "Dana Cohen-Bar", "Daniel Cohen-Or"], "title": "EditP23: 3D Editing via Propagation of Image Prompts to Multi-View", "comment": "Code, supplementary videos, interactive 3D visualizations, and\n  additional results are available at https://editp23.github.io/", "summary": "We present EditP23, a method for mask-free 3D editing that propagates 2D\nimage edits to multi-view representations in a 3D-consistent manner. In\ncontrast to traditional approaches that rely on text-based prompting or\nexplicit spatial masks, EditP23 enables intuitive edits by conditioning on a\npair of images: an original view and its user-edited counterpart. These image\nprompts are used to guide an edit-aware flow in the latent space of a\npre-trained multi-view diffusion model, allowing the edit to be coherently\npropagated across views. Our method operates in a feed-forward manner, without\noptimization, and preserves the identity of the original object, in both\nstructure and appearance. We demonstrate its effectiveness across a range of\nobject categories and editing scenarios, achieving high fidelity to the source\nwhile requiring no manual masks.", "AI": {"tldr": "EditP23是一种无需掩码的3D编辑方法，通过2D图像编辑传播到多视角表示，实现3D一致性编辑。", "motivation": "传统方法依赖文本提示或显式空间掩码，EditP23通过原始视图和用户编辑后的图像对实现直观编辑，简化流程。", "method": "利用预训练多视角扩散模型的潜在空间，通过图像对引导编辑感知流，实现跨视角一致性编辑。", "result": "在多种对象类别和编辑场景中表现出色，保持原始对象结构和外观的高保真度，无需手动掩码。", "conclusion": "EditP23提供了一种高效、直观的3D编辑方法，无需优化或掩码，适用于广泛的应用场景。"}}
{"id": "2506.20334", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2506.20334", "abs": "https://arxiv.org/abs/2506.20334", "authors": ["Daniele Ravasio", "Marcello Farina", "Alessio La Bella", "Andrea Ballarino"], "title": "Recurrent neural network-based robust control systems with closed-loop regional incremental ISS and application to MPC design", "comment": "16 pages, 7 figures, submitted to IEEE Transactions on Automatic\n  Control (under review)", "summary": "This paper investigates the design of output-feedback schemes for systems\ndescribed by a class of recurrent neural networks. We propose a procedure based\non linear matrix inequalities for designing an observer and a static\nstate-feedback controller. The algorithm leverages global and regional\nincremental input-to-state stability (incremental ISS) and enables the tracking\nof constant setpoints, ensuring robustness to disturbances and state estimation\nuncertainty. To address the potential limitations of regional incremental ISS,\nwe introduce an alternative scheme in which the static law is replaced with a\ntube-based nonlinear model predictive controller (NMPC) that exploits regional\nincremental ISS properties. We show that these conditions enable the\nformulation of a robust NMPC law with guarantees of convergence and recursive\nfeasibility, leading to an enlarged region of attraction. Theoretical results\nare validated through numerical simulations on the pH-neutralisation process\nbenchmark, demonstrating the effectiveness of the proposed schemes.", "AI": {"tldr": "论文研究了基于一类递归神经网络的输出反馈方案设计，提出了一种基于线性矩阵不等式的观测器和静态状态反馈控制器设计方法，并引入非线性模型预测控制器以增强性能。", "motivation": "针对递归神经网络系统的输出反馈设计问题，解决在存在干扰和状态估计不确定性时的跟踪和鲁棒性问题。", "method": "提出基于线性矩阵不等式的观测器和静态状态反馈控制器设计方法，并引入基于区域的增量输入-状态稳定性（ISS）和管式非线性模型预测控制器（NMPC）。", "result": "理论结果表明，所提方案能够保证收敛性和递归可行性，并扩大吸引域。数值仿真验证了方法的有效性。", "conclusion": "论文提出的方法在递归神经网络系统中实现了鲁棒输出反馈控制，并通过NMPC进一步提升了性能。"}}
{"id": "2506.20134", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20134", "abs": "https://arxiv.org/abs/2506.20134", "authors": ["Ningwei Xie", "Zizi Tian", "Lei Yang", "Xiao-Ping Zhang", "Meng Guo", "Jie Li"], "title": "From 2D to 3D Cognition: A Brief Survey of General World Models", "comment": null, "summary": "World models have garnered increasing attention in the development of\nartificial general intelligence (AGI), serving as computational frameworks for\nlearning representations of the external world and forecasting future states.\nWhile early efforts focused on 2D visual perception and simulation, recent\n3D-aware generative world models have demonstrated the ability to synthesize\ngeometrically consistent, interactive 3D environments, marking a shift toward\n3D spatial cognition. Despite rapid progress, the field lacks systematic\nanalysis to categorize emerging techniques and clarify their roles in advancing\n3D cognitive world models. This survey addresses this need by introducing a\nconceptual framework, providing a structured and forward-looking review of\nworld models transitioning from 2D perception to 3D cognition. Within this\nframework, we highlight two key technological drivers, particularly advances in\n3D representations and the incorporation of world knowledge, as fundamental\npillars. Building on these, we dissect three core cognitive capabilities that\nunderpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning,\nand 3D spatial interaction. We further examine the deployment of these\ncapabilities in real-world applications, including embodied AI, autonomous\ndriving, digital twin, and gaming/VR. Finally, we identify challenges across\ndata, modeling, and deployment, and outline future directions for advancing\nmore robust and generalizable 3D world models.", "AI": {"tldr": "该论文综述了从2D感知到3D认知的世界模型发展，重点分析了3D表示和世界知识整合的技术驱动，并探讨了3D世界建模的核心能力及其实际应用。", "motivation": "当前3D认知世界模型领域缺乏系统性分析，需要明确新兴技术的分类及其在推动3D认知中的作用。", "method": "提出概念框架，系统回顾从2D感知到3D认知的过渡，分析3D表示和世界知识整合的技术驱动，并剖析3D世界建模的三大核心能力。", "result": "总结了3D世界模型在物理场景生成、空间推理和交互方面的能力，并探讨了其在具体应用中的部署。", "conclusion": "指出了数据、建模和部署中的挑战，并提出了未来发展方向，以推动更鲁棒和通用的3D世界模型。"}}
{"id": "2506.20156", "categories": ["cs.HC", "cs.AI", "cs.IR", "H.5.2; I.2.7; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.20156", "abs": "https://arxiv.org/abs/2506.20156", "authors": ["Xuefei Hou", "Xizhao Tan"], "title": "Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype", "comment": "Version 1 of a work in progress. Finalized system flowcharts, a\n  public GitHub repository with the source code, and a full reproducibility\n  package detailing the prompts, models, and testing guidelines will be\n  provided in v2", "summary": "The core challenge in learning has shifted from knowledge acquisition to\neffective Self-Regulated Learning (SRL): planning, monitoring, and reflecting\non one's learning. Existing digital tools, however, inadequately support\nmetacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized\nreview, overlooking the role of context, while Personal Knowledge Management\n(PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel\nparadigm that conceptualizes the context-triggered retrieval of personal past\ninsights as a metacognitive scaffold to promote SRL. We formalize this paradigm\nusing the Just-in-Time Adaptive Intervention (JITAI) framework and implement a\nprototype system, Irec, to demonstrate its feasibility. At its core, Irec uses\na dynamic knowledge graph of the user's learning history. When a user faces a\nnew problem, a hybrid retrieval engine recalls relevant personal \"insights.\"\nSubsequently, a large language model (LLM) performs a deep similarity\nassessment to filter and present the most relevant scaffold in a just-in-time\nmanner. To reduce cognitive load, Irec features a human-in-the-loop pipeline\nfor LLM-based knowledge graph construction. We also propose an optional \"Guided\nInquiry\" module, where users can engage in a Socratic dialogue with an expert\nLLM, using the current problem and recalled insights as context. The\ncontribution of this paper is a solid theoretical framework and a usable system\nplatform for designing next-generation intelligent learning systems that\nenhance metacognition and self-regulation.", "AI": {"tldr": "论文提出了一种名为“Insight Recall”的新范式，通过上下文触发的个人过去见解检索来支持自我调节学习（SRL），并开发了原型系统Irec。", "motivation": "现有数字工具在支持元认知反思方面不足，如Spaced Repetition Systems（SRS）缺乏上下文，Personal Knowledge Management（PKM）工具维护成本高。", "method": "采用Just-in-Time Adaptive Intervention（JITAI）框架，构建动态知识图谱和混合检索引擎，结合LLM进行深度相似性评估，并设计了人机协作的知识图谱构建流程。", "result": "开发了Irec系统，能够及时提供相关见解，并支持用户通过“引导探究”模块与专家LLM进行对话。", "conclusion": "论文提供了增强元认知和自我调节学习的理论框架和系统平台，为下一代智能学习系统设计奠定了基础。"}}
{"id": "2506.20049", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20049", "abs": "https://arxiv.org/abs/2506.20049", "authors": ["Lorin Achey", "Alec Reed", "Brendan Crowe", "Bradley Hayes", "Christoffer Heckman"], "title": "Robust Robotic Exploration and Mapping Using Generative Occupancy Map Synthesis", "comment": "arXiv admin note: text overlap with arXiv:2409.10681", "summary": "We present a novel approach for enhancing robotic exploration by using\ngenerative occupancy mapping. We introduce SceneSense, a diffusion model\ndesigned and trained for predicting 3D occupancy maps given partial\nobservations. Our proposed approach probabilistically fuses these predictions\ninto a running occupancy map in real-time, resulting in significant\nimprovements in map quality and traversability. We implement SceneSense onboard\na quadruped robot and validate its performance with real-world experiments to\ndemonstrate the effectiveness of the model. In these experiments, we show that\noccupancy maps enhanced with SceneSense predictions better represent our fully\nobserved ground truth data (24.44% FID improvement around the robot and 75.59%\nimprovement at range). We additionally show that integrating\nSceneSense-enhanced maps into our robotic exploration stack as a \"drop-in\" map\nimprovement, utilizing an existing off-the-shelf planner, results in\nimprovements in robustness and traversability time. Finally we show results of\nfull exploration evaluations with our proposed system in two dissimilar\nenvironments and find that locally enhanced maps provide more consistent\nexploration results than maps constructed only from direct sensor measurements.", "AI": {"tldr": "提出了一种基于生成式占用映射的机器人探索新方法，通过SceneSense扩散模型预测3D占用图，显著提升了地图质量和可通行性。", "motivation": "解决机器人探索中部分观测导致的地图质量不足问题，提升地图的完整性和实用性。", "method": "使用SceneSense扩散模型预测3D占用图，并实时融合到运行中的占用图中。", "result": "实验显示，SceneSense显著提升了地图质量（FID改进24.44%近机器人，75.59%远距离），并改善了探索的稳健性和可通行时间。", "conclusion": "SceneSense增强的地图为机器人探索提供了更一致和可靠的结果，优于仅依赖传感器测量的地图。"}}
{"id": "2506.19891", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19891", "abs": "https://arxiv.org/abs/2506.19891", "authors": ["Qinghui Gong", "Xue Yang", "Xiaohu Tang"], "title": "Orthogonal Soft Pruning for Efficient Class Unlearning", "comment": "11 pages,3 figures", "summary": "Machine unlearning aims to selectively remove class-specific knowledge from\npretrained neural networks to satisfy privacy regulations such as the GDPR.\nExisting methods typically face a trade-off between unlearning speed and\npreservation of predictive accuracy, often incurring either high computational\noverhead or significant performance degradation on retained classes. In this\npaper, we propose a novel class-aware soft pruning framework leveraging\northogonal convolutional kernel regularization to achieve rapid and precise\nforgetting with millisecond-level response times. By enforcing orthogonality\nconstraints during training, our method decorrelates convolutional filters and\ndisentangles feature representations, while efficiently identifying\nclass-specific channels through activation difference analysis. Extensive\nevaluations across multiple architectures and datasets demonstrate stable\npruning with near-instant execution, complete forgetting of targeted classes,\nand minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100,\nand TinyImageNet confirm that our approach substantially reduces membership\ninference attack risks and accelerates unlearning by orders of magnitude\ncompared to state-of-the-art baselines. This framework provides an efficient,\npractical solution for real-time machine unlearning in Machine Learning as a\nService (MLaaS) scenarios.", "AI": {"tldr": "提出了一种基于正交卷积核正则化的类感知软剪枝框架，实现快速精准的机器遗忘，满足隐私法规要求。", "motivation": "现有方法在遗忘速度和预测准确性之间存在权衡，计算开销大或性能下降明显。", "method": "利用正交卷积核正则化，通过激活差异分析识别类特定通道，实现快速遗忘。", "result": "在多架构和数据集上验证了快速执行、完全遗忘目标类、保留数据准确性损失最小。", "conclusion": "该框架为MLaaS场景提供了高效、实时的机器遗忘解决方案。"}}
{"id": "2506.20475", "categories": ["eess.SY", "cs.SY", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.20475", "abs": "https://arxiv.org/abs/2506.20475", "authors": ["Hao Chen", "Yu Hin Ng", "Ching-Wei Chang", "Haobo Liang", "Yanke Wang"], "title": "Learning-based safety lifting monitoring system for cranes on construction sites", "comment": "20 pages, 10 figures", "summary": "Lifting on construction sites, as a frequent operation, works still with\nsafety risks, especially for modular integrated construction (MiC) lifting due\nto its large weight and size, probably leading to accidents, causing damage to\nthe modules, or more critically, posing safety hazards to on-site workers.\nAiming to reduce the safety risks in lifting scenarios, we design an automated\nsafe lifting monitoring algorithm pipeline based on learning-based methods, and\ndeploy it on construction sites. This work is potentially to increase the\nsafety and efficiency of MiC lifting process via automation technologies. A\ndataset is created consisting of 1007 image-point cloud pairs (37 MiC\nliftings). Advanced object detection models are trained for automated\ntwo-dimensional (2D) detection of MiCs and humans. Fusing the 2D detection\nresults with the point cloud information allows accurate determination of the\nthree-dimensional (3D) positions of MiCs and humans. The system is designed to\nautomatically trigger alarms that notify individuals in the MiC lifting danger\nzone, while providing the crane operator with real-time lifting information and\nearly warnings. The monitoring process minimizes the human intervention and no\nor less signal men are required on real sites assisted by our system. A\nquantitative analysis is conducted to evaluate the effectiveness of the\nalgorithmic pipeline. The pipeline shows promising results in MiC and human\nperception with the mean distance error of 1.5640 m and 0.7824 m respectively.\nFurthermore, the developed system successfully executes safety risk monitoring\nand alarm functionalities during the MiC lifting process with limited manual\nwork on real construction sites.", "AI": {"tldr": "论文提出了一种基于学习方法的自动化安全吊装监控算法，用于减少模块化集成建筑（MiC）吊装中的安全风险，通过2D和3D检测技术实现实时预警。", "motivation": "模块化集成建筑（MiC）吊装因其重量和体积大，存在较高的安全风险，可能导致事故或对工人造成伤害。研究旨在通过自动化技术提升吊装过程的安全性和效率。", "method": "设计了基于学习方法的自动化监控算法流程，包括2D目标检测模型训练和点云信息融合，实现MiC和工人的3D定位，并自动触发警报。", "result": "算法在MiC和工人检测上的平均距离误差分别为1.5640米和0.7824米，系统在真实工地上成功实现了安全风险监控和预警功能。", "conclusion": "该系统能够有效减少人工干预，提升MiC吊装过程的安全性和效率，具有实际应用潜力。"}}
{"id": "2506.20151", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20151", "abs": "https://arxiv.org/abs/2506.20151", "authors": ["Haipeng Fan", "Shiyuan Zhang", "Baohunesitu", "Zihang Guo", "Huaiwen Zhang"], "title": "EAR: Erasing Concepts from Unified Autoregressive Models", "comment": "11 pages, 7 figures, 1 tables", "summary": "Autoregressive (AR) models have achieved unified and strong performance\nacross both visual understanding and image generation tasks. However, removing\nundesired concepts from AR models while maintaining overall generation quality\nremains an open challenge. In this paper, we propose Erasure Autoregressive\nModel (EAR), a fine-tuning method for effective and utility-preserving concept\nerasure in AR models. Specifically, we introduce Windowed Gradient Accumulation\n(WGA) strategy to align patch-level decoding with erasure objectives, and\nThresholded Loss Masking (TLM) strategy to protect content unrelated to the\ntarget concept during fine-tuning. Furthermore, we propose a novel benchmark,\nErase Concept Generator and Visual Filter (ECGVF), aim at provide a more\nrigorous and comprehensive foundation for evaluating concept erasure in AR\nmodels. Specifically, we first employ structured templates across diverse large\nlanguage models (LLMs) to pre-generate a large-scale corpus of\ntarget-replacement concept prompt pairs. Subsequently, we generate images from\nthese prompts and subject them to rigorous filtering via a visual classifier to\nensure concept fidelity and alignment. Extensive experimental results conducted\non the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR\nachieves marked improvements in both erasure effectiveness and model utility\npreservation. Code is available at: https://github.com/immc-lab/ear/", "AI": {"tldr": "提出了一种名为EAR的微调方法，用于在自回归模型中实现有效且保留生成质量的概念擦除，并引入了WGA和TLM策略以及新的评估基准ECGVF。", "motivation": "自回归模型在视觉理解和图像生成任务中表现优异，但如何在保持生成质量的同时去除不想要的概念仍是一个挑战。", "method": "提出了EAR方法，结合WGA策略和TLM策略，并设计了ECGVF基准用于评估。", "result": "实验表明，EAR在概念擦除效果和模型效用保留方面均有显著提升。", "conclusion": "EAR方法在自回归模型中实现了高效的概念擦除，同时保持了生成质量。"}}
{"id": "2506.20207", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.20207", "abs": "https://arxiv.org/abs/2506.20207", "authors": ["Viktorija Paneva", "Verena Winterhalter", "Franziska Augustinowski", "Florian Alt"], "title": "User Understanding of Privacy Permissions in Mobile Augmented Reality: Perceptions and Misconceptions", "comment": "14 pages, 3 figures. Preprint. Accepted to MobileHCI 2025", "summary": "Mobile Augmented Reality (AR) applications leverage various sensors to\nprovide immersive user experiences. However, their reliance on diverse data\nsources introduces significant privacy challenges. This paper investigates user\nperceptions and understanding of privacy permissions in mobile AR apps through\nan analysis of existing applications and an online survey of 120 participants.\nFindings reveal common misconceptions, including confusion about how\npermissions relate to specific AR functionalities (e.g., location and\nmeasurement of physical distances), and misinterpretations of permission labels\n(e.g., conflating camera and gallery access). We identify a set of actionable\nimplications for designing more usable and transparent privacy mechanisms\ntailored to mobile AR technologies, including contextual explanations, modular\npermission requests, and clearer permission labels. These findings offer\nactionable guidance for developers, researchers, and policymakers working to\nenhance privacy frameworks in mobile AR.", "AI": {"tldr": "研究分析了移动AR应用中用户对隐私权限的误解，提出了改进隐私机制的设计建议。", "motivation": "移动AR应用依赖多种传感器数据，但用户对隐私权限的理解不足，导致隐私风险。", "method": "通过分析现有应用和120名参与者的在线调查，研究用户对权限的理解。", "result": "发现用户对权限与AR功能的关系存在误解，如位置权限与物理距离测量的混淆。", "conclusion": "提出了改进隐私机制的设计建议，如上下文解释和更清晰的权限标签。"}}
{"id": "2506.20097", "categories": ["cs.RO", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20097", "abs": "https://arxiv.org/abs/2506.20097", "authors": ["Wang Bill Zhu", "Miaosen Chai", "Ishika Singh", "Robin Jia", "Jesse Thomason"], "title": "PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models", "comment": null, "summary": "We propose PSALM-V, the first autonomous neuro-symbolic learning system able\nto induce symbolic action semantics (i.e., pre- and post-conditions) in visual\nenvironments through interaction. PSALM-V bootstraps reliable symbolic planning\nwithout expert action definitions, using LLMs to generate heuristic plans and\ncandidate symbolic semantics. Previous work has explored using large language\nmodels to generate action semantics for Planning Domain Definition Language\n(PDDL)-based symbolic planners. However, these approaches have primarily\nfocused on text-based domains or relied on unrealistic assumptions, such as\naccess to a predefined problem file, full observability, or explicit error\nmessages. By contrast, PSALM-V dynamically infers PDDL problem files and domain\naction semantics by analyzing execution outcomes and synthesizing possible\nerror explanations. The system iteratively generates and executes plans while\nmaintaining a tree-structured belief over possible action semantics for each\naction, iteratively refining these beliefs until a goal state is reached.\nSimulated experiments of task completion in ALFRED demonstrate that PSALM-V\nincreases the plan success rate from 37% (Claude-3.7) to 74% in partially\nobserved setups. Results on two 2D game environments, RTFM and Overcooked-AI,\nshow that PSALM-V improves step efficiency and succeeds in domain induction in\nmulti-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions\nfor real-world robot BlocksWorld tasks, despite low-level manipulation failures\nfrom the robot.", "AI": {"tldr": "PSALM-V是一种自主神经符号学习系统，能够在视觉环境中通过交互推断符号动作语义（如前置和后置条件），无需专家定义动作，利用LLM生成启发式计划和候选语义。", "motivation": "现有方法主要依赖文本领域或不现实的假设（如预定义问题文件或完全可观察性），而PSALM-V旨在动态推断PDDL问题文件和动作语义，适用于部分可观察和多智能体环境。", "method": "PSALM-V通过分析执行结果和合成可能的错误解释，动态推断PDDL问题文件和动作语义，迭代生成和执行计划，同时维护动作语义的树状信念。", "result": "在ALFRED任务中，PSALM-V将计划成功率从37%提升至74%；在RTFM和Overcooked-AI中提高了步骤效率；在机器人BlocksWorld任务中成功推断出PDDL条件。", "conclusion": "PSALM-V在部分可观察和多智能体环境中表现出色，能够有效推断符号动作语义，提升任务完成效率。"}}
{"id": "2506.19893", "categories": ["cs.LG", "cs.AI", "cs.IT", "eess.IV", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.19893", "abs": "https://arxiv.org/abs/2506.19893", "authors": ["Jingzhi Hu", "Geoffrey Ye Li"], "title": "Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks", "comment": null, "summary": "Due to the surging amount of AI-generated content (AIGC), its provisioning to\nedges and mobile users from the cloud incurs substantial traffic on networks.\nGenerative semantic communication (GSC) offers a promising solution by\ntransmitting highly compact information, i.e., prompt text and latent\nrepresentations, instead of high-dimensional AIGC data. However, GSC relies on\nthe alignment between the knowledge in the cloud generative AI (GAI) and that\npossessed by the edges and users, and between the knowledge for wireless\ntransmission and that of actual channels, which remains challenging. In this\npaper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm\nfor GSC systems. The core idea is to distill the generation knowledge from the\ncloud-GAI into low-rank matrices, which can be incorporated by the edge and\nused to adapt the transmission knowledge to diverse wireless channel\nconditions. DeKA-g comprises two novel methods: metaword-aided knowledge\ndistillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD,\nan optimized metaword is employed to enhance the efficiency of knowledge\ndistillation, while VGSA enables efficient adaptation to diverse compression\nrates and SNR ranges. From simulation results, DeKA-g improves the alignment\nbetween the edge-generated images and the cloud-generated ones by 44%.\nMoreover, it adapts to compression rates with 116% higher efficiency than the\nbaseline and enhances the performance in low-SNR conditions by 28%.", "AI": {"tldr": "论文提出DeKA-g算法，通过知识蒸馏和自适应传输优化生成语义通信（GSC）系统，显著提升边缘生成图像与云端生成图像的对齐效率。", "motivation": "随着AI生成内容（AIGC）的激增，从云端向边缘和移动用户传输内容导致网络流量剧增。生成语义通信（GSC）通过传输紧凑信息（如提示文本和潜在表示）提供解决方案，但知识对齐问题仍具挑战性。", "method": "提出DeKA-g算法，包含元词辅助知识蒸馏（MAKD）和可变速率分组信噪比适应（VGSA）两种方法，通过低秩矩阵蒸馏云端生成知识并适应无线信道条件。", "result": "DeKA-g将边缘与云端生成图像对齐效率提升44%，压缩率适应效率提高116%，低信噪比条件下性能提升28%。", "conclusion": "DeKA-g有效解决了GSC系统中的知识对齐问题，显著提升了传输效率和适应性。"}}
{"id": "2506.20152", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.20152", "abs": "https://arxiv.org/abs/2506.20152", "authors": ["Deepak Ghimire", "Kilho Lee", "Seong-heum Kim"], "title": "Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration", "comment": null, "summary": "Structured pruning is a well-established technique for compressing neural\nnetworks, making it suitable for deployment in resource-limited edge devices.\nThis paper presents an efficient Loss-Aware Automatic Selection of Structured\nPruning Criteria (LAASP) for slimming and accelerating deep neural networks.\nThe majority of pruning methodologies employ a sequential process consisting of\nthree stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed\npruning technique adopts a pruning-while-training approach that eliminates the\nfirst stage and integrates the second and third stages into a single cycle. The\nautomatic selection of magnitude or similarity-based filter pruning criteria\nfrom a specified pool of criteria and the specific pruning layer at each\npruning iteration is guided by the network's overall loss on a small subset of\nthe training data. To mitigate the abrupt accuracy drop due to pruning, the\nnetwork is retrained briefly after each reduction of a predefined number of\nfloating-point operations (FLOPs). The optimal pruning rates for each layer in\nthe network are automatically determined, eliminating the need for manual\nallocation of fixed or variable pruning rates for each layer. Experiments on\nthe VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets\ndemonstrate the effectiveness of the proposed method. In particular, the\nResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the\ntop-1 accuracy compared to state-of-the-art methods while reducing the network\nFLOPs by 52\\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces\nFLOPs by more than 42\\% with a negligible 0.33\\% drop in top-5 accuracy. The\nsource code of this paper is publicly available online -\nhttps://github.com/ghimiredhikura/laasp.", "AI": {"tldr": "本文提出了一种高效的损失感知自动选择结构化剪枝标准（LAASP）方法，用于压缩和加速深度神经网络。该方法采用边训练边剪枝的策略，自动选择剪枝标准和层，并通过短暂重训练减少精度损失。实验表明，该方法在减少计算量的同时显著提升了模型精度。", "motivation": "为了解决传统剪枝方法需要分阶段进行（训练、剪枝、微调）的问题，并减少手动调整剪枝率的工作量，本文提出了一种更高效的剪枝方法。", "method": "提出了一种边训练边剪枝的方法，自动从候选标准中选择剪枝标准和层，并通过网络损失指导选择。每减少一定计算量后短暂重训练以缓解精度下降。", "result": "在CIFAR-10数据集上，ResNet56和ResNet110模型的top-1精度显著提升，同时计算量减少52%。在ImageNet数据集上，ResNet50的计算量减少42%以上，top-5精度仅下降0.33%。", "conclusion": "LAASP方法在减少计算量的同时保持了模型精度，适用于资源受限的边缘设备部署。"}}
{"id": "2506.20291", "categories": ["cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.20291", "abs": "https://arxiv.org/abs/2506.20291", "authors": ["Haoran Zhang", "Xin Zhao", "Jinze Chen", "Junpeng Guo"], "title": "A Literature Review on Simulation in Conversational Recommender Systems", "comment": "6 pages, 1 figures, accepted as a poster for CSWIM 2025", "summary": "Conversational Recommender Systems (CRSs) have garnered attention as a novel\napproach to delivering personalized recommendations through multi-turn\ndialogues. This review developed a taxonomy framework to systematically\ncategorize relevant publications into four groups: dataset construction,\nalgorithm design, system evaluation, and empirical studies, providing a\ncomprehensive analysis of simulation methods in CRSs research. Our analysis\nreveals that simulation methods play a key role in tackling CRSs' main\nchallenges. For example, LLM-based simulation methods have been used to create\nconversational recommendation data, enhance CRSs algorithms, and evaluate CRSs.\nDespite several challenges, such as dataset bias, the limited output\nflexibility of LLM-based simulations, and the gap between text semantic space\nand behavioral semantics, persist due to the complexity in Human-Computer\nInteraction (HCI) of CRSs, simulation methods hold significant potential for\nadvancing CRS research. This review offers a thorough summary of the current\nresearch landscape in this domain and identifies promising directions for\nfuture inquiry.", "AI": {"tldr": "本文综述了对话推荐系统（CRSs）的研究现状，提出了一个分类框架，分析了模拟方法在解决CRSs挑战中的关键作用，并指出了未来研究方向。", "motivation": "对话推荐系统（CRSs）通过多轮对话提供个性化推荐，但其研究面临数据集偏差、模拟方法灵活性不足等挑战。本文旨在系统总结现有研究并提出未来方向。", "method": "通过构建分类框架，将相关文献分为数据集构建、算法设计、系统评估和实证研究四类，并分析模拟方法的应用。", "result": "模拟方法（如基于LLM的方法）在数据生成、算法优化和系统评估中发挥重要作用，但仍存在数据集偏差和语义空间差距等问题。", "conclusion": "模拟方法对CRSs研究具有重要潜力，未来需解决现有挑战并进一步探索其应用。"}}
{"id": "2506.20212", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.20212", "abs": "https://arxiv.org/abs/2506.20212", "authors": ["Andrea Bussolan", "Oliver Avram", "Andrea Pignata", "Gianvito Urgese", "Stefano Baraldo", "Anna Valente"], "title": "Personalized Mental State Evaluation in Human-Robot Interaction using Federated Learning", "comment": null, "summary": "With the advent of Industry 5.0, manufacturers are increasingly prioritizing\nworker well-being alongside mass customization. Stress-aware Human-Robot\nCollaboration (HRC) plays a crucial role in this paradigm, where robots must\nadapt their behavior to human mental states to improve collaboration fluency\nand safety. This paper presents a novel framework that integrates Federated\nLearning (FL) to enable personalized mental state evaluation while preserving\nuser privacy. By leveraging physiological signals, including EEG, ECG, EDA,\nEMG, and respiration, a multimodal model predicts an operator's stress level,\nfacilitating real-time robot adaptation. The FL-based approach allows\ndistributed on-device training, ensuring data confidentiality while improving\nmodel generalization and individual customization. Results demonstrate that the\ndeployment of an FL approach results in a global model with performance in\nstress prediction accuracy comparable to a centralized training approach.\nMoreover, FL allows for enhancing personalization, thereby optimizing\nhuman-robot interaction in industrial settings, while preserving data privacy.\nThe proposed framework advances privacy-preserving, adaptive robotics to\nenhance workforce well-being in smart manufacturing.", "AI": {"tldr": "论文提出了一种基于联邦学习的框架，用于在工业5.0环境中实现个性化心理状态评估，同时保护用户隐私。通过多模态生理信号预测操作员压力水平，优化人机协作。", "motivation": "工业5.0强调工人福祉与大规模定制，需要机器人根据人类心理状态调整行为以提高协作流畅性和安全性。", "method": "整合联邦学习（FL）和多模态生理信号（EEG、ECG、EDA、EMG、呼吸）构建模型，实现分布式设备端训练，保护隐私并提升个性化。", "result": "FL方法在压力预测准确性上与集中式训练相当，同时增强个性化，优化人机交互。", "conclusion": "该框架推动了隐私保护的适应性机器人技术，提升智能制造业中的劳动力福祉。"}}
{"id": "2506.19894", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.19894", "abs": "https://arxiv.org/abs/2506.19894", "authors": ["Antoine Pesenti", "Aidan OSullivan"], "title": "Explaining deep neural network models for electricity price forecasting with XAI", "comment": null, "summary": "Electricity markets are highly complex, involving lots of interactions and\ncomplex dependencies that make it hard to understand the inner workings of the\nmarket and what is driving prices. Econometric methods have been developed for\nthis, white-box models, however, they are not as powerful as deep neural\nnetwork models (DNN). In this paper, we use a DNN to forecast the price and\nthen use XAI methods to understand the factors driving the price dynamics in\nthe market. The objective is to increase our understanding of how different\nelectricity markets work. To do that, we apply explainable methods such as SHAP\nand Gradient, combined with visual techniques like heatmaps (saliency maps) to\nanalyse the behaviour and contributions of various features across five\nelectricity markets. We introduce the novel concepts of SSHAP values and SSHAP\nlines to enhance the complex representation of high-dimensional tabular models.", "AI": {"tldr": "使用深度神经网络（DNN）预测电力市场价格，并结合可解释人工智能（XAI）方法（如SHAP和Gradient）分析价格驱动因素，以增强对电力市场的理解。", "motivation": "电力市场复杂且依赖性强，传统计量经济学方法（白盒模型）预测能力有限，而DNN虽强大但缺乏可解释性。本文旨在结合DNN的预测能力和XAI的可解释性，揭示市场价格动态的驱动因素。", "method": "采用DNN进行价格预测，并应用XAI方法（如SHAP和Gradient）及可视化技术（如热图）分析五个电力市场中各特征的行为和贡献。提出SSHAP值和SSHAP线以增强高维表格模型的复杂表示。", "result": "通过DNN和XAI方法的结合，成功预测了电力市场价格，并揭示了驱动价格动态的关键因素。", "conclusion": "本文展示了DNN与XAI结合在电力市场分析中的潜力，为理解复杂市场机制提供了新工具。"}}
{"id": "2506.20626", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2506.20626", "abs": "https://arxiv.org/abs/2506.20626", "authors": ["Hamza Chakraa", "François Guérin", "Edouard Leclercq", "Dimitri Lefebvre"], "title": "Task Allocation of UAVs for Monitoring Missions via Hardware-in-the-Loop Simulation and Experimental Validation", "comment": null, "summary": "This study addresses the optimisation of task allocation for Unmanned Aerial\nVehicles (UAVs) within industrial monitoring missions. The proposed methodology\nintegrates a Genetic Algorithms (GA) with a 2-Opt local search technique to\nobtain a high-quality solution. Our approach was experimentally validated in an\nindustrial zone to demonstrate its efficacy in real-world scenarios. Also, a\nHardware-in-the-loop (HIL) simulator for the UAVs team is introduced. Moreover,\ninsights about the correlation between the theoretical cost function and the\nactual battery consumption and time of flight are deeply analysed. Results show\nthat the considered costs for the optimisation part of the problem closely\ncorrelate with real-world data, confirming the practicality of the proposed\napproach.", "AI": {"tldr": "该研究提出了一种结合遗传算法和2-Opt局部搜索的方法，优化无人机在工业监测任务中的任务分配，并通过实验验证其有效性。", "motivation": "解决无人机在工业监测任务中的任务分配优化问题，以提高效率和实用性。", "method": "结合遗传算法（GA）和2-Opt局部搜索技术，并通过硬件在环（HIL）模拟器进行验证。", "result": "优化成本与实际电池消耗和飞行时间高度相关，验证了方法的实用性。", "conclusion": "提出的方法在实际场景中有效，优化成本与真实数据一致。"}}
{"id": "2506.20155", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20155", "abs": "https://arxiv.org/abs/2506.20155", "authors": ["Avadhoot Jadhav", "Ashutosh Srivastava", "Abhinav Java", "Silky Singh", "Tarun Ram Menta", "Surgan Jandial", "Balaji Krishnamurthy"], "title": "Towards Efficient Exemplar Based Image Editing with Multimodal VLMs", "comment": "Accepted at ECCV 2024 (AI4VA Workshop)", "summary": "Text-to-Image Diffusion models have enabled a wide array of image editing\napplications. However, capturing all types of edits through text alone can be\nchallenging and cumbersome. The ambiguous nature of certain image edits is\nbetter expressed through an exemplar pair, i.e., a pair of images depicting an\nimage before and after an edit respectively. In this work, we tackle\nexemplar-based image editing -- the task of transferring an edit from an\nexemplar pair to a content image(s), by leveraging pretrained text-to-image\ndiffusion models and multimodal VLMs. Even though our end-to-end pipeline is\noptimization-free, our experiments demonstrate that it still outperforms\nbaselines on multiple types of edits while being ~4x faster.", "AI": {"tldr": "论文提出了一种基于示例对的图像编辑方法，利用预训练的文本到图像扩散模型和多模态VLMs，无需优化即可实现高效编辑。", "motivation": "仅通过文本描述难以捕捉所有类型的图像编辑需求，而示例对能更直观地表达模糊的编辑意图。", "method": "利用预训练的文本到图像扩散模型和多模态VLMs，构建端到端的优化免费管道。", "result": "实验表明，该方法在多种编辑类型上优于基线方法，且速度快约4倍。", "conclusion": "该方法为示例驱动的图像编辑提供了一种高效且无需优化的解决方案。"}}
{"id": "2506.20377", "categories": ["cs.HC", "cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2506.20377", "abs": "https://arxiv.org/abs/2506.20377", "authors": ["Sachin R. Pendse", "Ben Rochford", "Neha Kumar", "Munmun De Choudhury"], "title": "The Role of Partisan Culture in Mental Health Language Online", "comment": "Accepted to the ACM Conference on Computer-Supported Cooperative Work\n  and Social Computing (CSCW 2025)", "summary": "The impact of culture on how people express distress in online support\ncommunities is increasingly a topic of interest within Computer Supported\nCooperative Work (CSCW) and Human-Computer Interaction (HCI). In the United\nStates, distinct cultures have emerged from each of the two dominant political\nparties, forming a primary lens by which people navigate online and offline\nworlds. We examine whether partisan culture may play a role in how U.S.\nRepublican and Democrat users of online mental health support communities\nexpress distress. We present a large-scale observational study of 2,184,356\nposts from 8,916 statistically matched Republican, Democrat, and unaffiliated\nonline support community members. We utilize methods from causal inference to\nstatistically match partisan users along covariates that correspond with\ndemographic attributes and platform use, in order to create comparable cohorts\nfor analysis. We then leverage methods from natural language processing to\nunderstand how partisan expressions of distress compare between these sets of\nclosely matched opposing partisans, and between closely matched partisans and\ntypical support community members. Our data spans January 2013 to December\n2022, a period of both rising political polarization and mental health\nconcerns. We find that partisan culture does play into expressions of distress,\nunderscoring the importance of considering partisan cultural differences in the\ndesign of online support community platforms.", "AI": {"tldr": "研究发现，美国共和党和民主党用户在在线心理健康支持社区中表达痛苦的方式受党派文化影响。", "motivation": "探讨党派文化如何影响在线支持社区中用户表达痛苦的方式。", "method": "通过大规模观察性研究，使用因果推断和自然语言处理技术分析匹配的党派用户数据。", "result": "党派文化确实影响痛苦表达，强调了在设计在线支持平台时需考虑党派文化差异。", "conclusion": "研究强调了在设计在线支持社区平台时考虑党派文化差异的重要性。"}}
{"id": "2506.20259", "categories": ["cs.RO", "cs.AI", "68T40, 93C85, 70E60", "I.2.9"], "pdf": "https://arxiv.org/pdf/2506.20259", "abs": "https://arxiv.org/abs/2506.20259", "authors": ["Andrej Lúčny", "Matilde Antonj", "Carlo Mazzola", "Hana Hornáčková", "Igor Farkaš"], "title": "Generating and Customizing Robotic Arm Trajectories using Neural Networks", "comment": "The code is released at\n  https://github.com/andylucny/nico2/tree/main/generate", "summary": "We introduce a neural network approach for generating and customizing the\ntrajectory of a robotic arm, that guarantees precision and repeatability. To\nhighlight the potential of this novel method, we describe the design and\nimplementation of the technique and show its application in an experimental\nsetting of cognitive robotics. In this scenario, the NICO robot was\ncharacterized by the ability to point to specific points in space with precise\nlinear movements, increasing the predictability of the robotic action during\nits interaction with humans. To achieve this goal, the neural network computes\nthe forward kinematics of the robot arm. By integrating it with a generator of\njoint angles, another neural network was developed and trained on an artificial\ndataset created from suitable start and end poses of the robotic arm. Through\nthe computation of angular velocities, the robot was characterized by its\nability to perform the movement, and the quality of its action was evaluated in\nterms of shape and accuracy. Thanks to its broad applicability, our approach\nsuccessfully generates precise trajectories that could be customized in their\nshape and adapted to different settings.", "AI": {"tldr": "提出了一种神经网络方法，用于生成和定制机械臂的轨迹，确保精度和可重复性。", "motivation": "为了提高机械臂在与人交互时的动作可预测性，特别是在认知机器人实验场景中。", "method": "通过神经网络计算机械臂的正向运动学，并结合关节角度生成器，训练在人工数据集上开发的另一神经网络。", "result": "机械臂能够执行精确的线性运动，动作质量在形状和精度上得到评估。", "conclusion": "该方法成功生成了可定制形状并适应不同场景的精确轨迹。"}}
{"id": "2506.19895", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19895", "abs": "https://arxiv.org/abs/2506.19895", "authors": ["Miguel N. Font", "José L. Jorro-Aragoneses", "Carlos M. Alaíz"], "title": "A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers", "comment": "This paper has been accepted for presentation at ICANN 2025\n  (International Conference on Artificial Neural Networks) and will appear in\n  the conference proceedings published by Springer Nature in the Lecture Notes\n  in Computer Science (LNCS) series. The final authenticated version will be\n  available on the publisher website", "summary": "Neural Networks have high accuracy in solving problems where it is difficult\nto detect patterns or create a logical model. However, these algorithms\nsometimes return wrong solutions, which become problematic in high-risk domains\nlike medical diagnosis or autonomous driving. One strategy to detect and\nmitigate these errors is the measurement of the uncertainty over neural network\ndecisions. In this paper, we present a novel post-hoc framework for measuring\nthe uncertainty of a decision based on retrieved training cases that have a\nsimilar activation vector to the query for each layer. Based on these retrieved\ncases, we propose two new metrics: Decision Change and Layer Uncertainty, which\ncapture changes in nearest-neighbor class distributions across layers. We\nevaluated our approach in a classification model for two datasets: CIFAR-10 and\nMNIST. The results show that these metrics enhance uncertainty estimation,\nespecially in challenging classification tasks, outperforming softmax-based\nconfidence.", "AI": {"tldr": "提出了一种新的后处理框架，通过检索训练案例测量神经网络决策的不确定性，并提出了两种新指标：决策变化和层不确定性。", "motivation": "神经网络在高风险领域（如医疗诊断或自动驾驶）中可能返回错误决策，因此需要有效的不确定性测量方法以减少错误。", "method": "基于每层与查询激活向量相似的训练案例，提出决策变化和层不确定性两种新指标。", "result": "在CIFAR-10和MNIST数据集上验证，新指标优于基于softmax的置信度方法。", "conclusion": "新框架和指标能有效提升不确定性估计，尤其在复杂分类任务中表现更优。"}}
{"id": "2506.20628", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2506.20628", "abs": "https://arxiv.org/abs/2506.20628", "authors": ["Anders Hansson", "João Victor Galvão da Mata", "Martin S. Andersen"], "title": "Identifiability and Maximum Likelihood Estimation for System Identification of Networks of Dynamical Systems", "comment": "This work has been submitted to the IEEE for possible publication.\n  Submitted to IEEE Transactions on Automatic Control", "summary": "In this paper we investigate identifiability and maximum likelihood\nestimation for direct system identification of networks of dynamical systems.\nWe provide necessary and sufficient conditions for network identifiability in\nterms of Gr\\\"obner bases. We show that the maximum likelihood approach is both\nconsistent and efficient, which is in contrast to existing prediction error\napproaches. Moreover, our approach has wider applicability, i.e., it is\napplicable whenever network identifiability holds. Finally, we show that we can\nformulate the maximum likelihood problem without the use of a predictor, which\nis the key to numerically being able to solve it efficiently.", "AI": {"tldr": "研究了动态系统网络直接识别的可识别性和最大似然估计，提出了基于Gröbner基的必要和充分条件，并证明该方法比现有预测误差方法更一致和高效。", "motivation": "探索动态系统网络识别的可识别性和高效估计方法，以解决现有预测误差方法的局限性。", "method": "利用Gröbner基分析网络可识别性，提出无需预测器的最大似然估计方法。", "result": "证明了最大似然方法的优越性（一致性和高效性），并扩展了其适用范围。", "conclusion": "该方法在动态系统网络识别中具有高效性和广泛适用性，为相关领域提供了新工具。"}}
{"id": "2506.20168", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20168", "abs": "https://arxiv.org/abs/2506.20168", "authors": ["Zhentao He", "Can Zhang", "Ziheng Wu", "Zhenghao Chen", "Yufei Zhan", "Yifan Li", "Zhao Zhang", "Xian Wang", "Minghui Qiu"], "title": "Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models", "comment": null, "summary": "Recent advancements in multimodal large language models have enhanced\ndocument understanding by integrating textual and visual information. However,\nexisting models exhibit incompleteness within their paradigm in real-world\nscenarios, particularly under visual degradation. In such conditions, the\ncurrent response paradigm often fails to adequately perceive visual degradation\nand ambiguity, leading to overreliance on linguistic priors or misaligned\nvisual-textual reasoning. This difficulty in recognizing uncertainty frequently\nresults in the generation of hallucinatory content, especially when a precise\nanswer is not feasible. To better demonstrate and analyze this phenomenon and\nproblem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR\nhallucination in degraded document understanding. This dataset includes test\nsamples spanning identity cards and invoices, with simulated real-world\ndegradations for OCR reliability. This setup allows for evaluating models'\ncapacity, under degraded input, to distinguish reliable visual information and\nanswer accordingly, thereby highlighting the challenge of avoiding\nhallucination on uncertain data. To achieve vision-faithful reasoning and\nthereby avoid the aforementioned issues, we further introduce a GRPO-based\nframework featuring a novel reward mechanism. By incorporating a self-awareness\nof visual uncertainty and an analysis method that initiates refusal to answer\nto increase task difficulty within our supervised fine-tuning and reinforcement\nlearning framework, we successfully mitigated hallucinations in ambiguous\nregions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model\nachieves a 22\\% absolute improvement in hallucination-free accuracy over GPT-4o\non KIE-HVQA and there is no significant performance drop in standard tasks,\nhighlighting both effectiveness and robustness.", "AI": {"tldr": "论文提出KIE-HVQA基准评估OCR在退化文档理解中的幻觉问题，并引入GRPO框架以减少幻觉内容。", "motivation": "现有多模态大语言模型在视觉退化场景下表现不佳，容易产生幻觉内容，需改进。", "method": "提出KIE-HVQA基准和GRPO框架，结合视觉不确定性和拒绝回答机制。", "result": "7B参数模型在KIE-HVQA上比GPT-4o提升22%的幻觉减少准确率，标准任务无显著下降。", "conclusion": "GRPO框架有效减少幻觉，提升模型在退化视觉条件下的鲁棒性。"}}
{"id": "2506.20463", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.20463", "abs": "https://arxiv.org/abs/2506.20463", "authors": ["Bei Yi Ng", "Jiarui Li", "Xinyuan Tong", "Kevin Ye", "Gauthami Yenne", "Varun Chandrasekaran", "Jingjie Li"], "title": "Analyzing Security and Privacy Challenges in Generative AI Usage Guidelines for Higher Education", "comment": null, "summary": "Educators and learners worldwide are embracing the rise of Generative\nArtificial Intelligence (GenAI) as it reshapes higher education. However, GenAI\nalso raises significant privacy and security concerns, as models and\nprivacy-sensitive user data, such as student records, may be misused by service\nproviders. Unfortunately, end-users often have little awareness of or control\nover how these models operate. To address these concerns, universities are\ndeveloping institutional policies to guide GenAI use while safeguarding\nsecurity and privacy. This work examines these emerging policies and\nguidelines, with a particular focus on the often-overlooked privacy and\nsecurity dimensions of GenAI integration in higher education, alongside other\nacademic values. Through a qualitative analysis of GenAI usage guidelines from\nuniversities across 12 countries, we identify key challenges and opportunities\ninstitutions face in providing effective privacy and security protections,\nincluding the need for GenAI safeguards tailored specifically to the academic\ncontext.", "AI": {"tldr": "论文探讨了高等教育中生成式人工智能（GenAI）的隐私与安全问题，分析了多国大学的政策，提出了针对学术环境的保护措施。", "motivation": "随着GenAI在高等教育中的普及，隐私与安全问题日益突出，需要制定专门的政策以保护用户数据。", "method": "通过定性分析12个国家大学的GenAI使用指南，研究隐私与安全维度的挑战与机遇。", "result": "研究发现，学术机构需定制化的GenAI保护措施，以平衡技术创新与隐私安全。", "conclusion": "高等教育机构应制定专门政策，确保GenAI的隐私与安全，同时兼顾学术价值。"}}
{"id": "2506.20268", "categories": ["cs.RO", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.20268", "abs": "https://arxiv.org/abs/2506.20268", "authors": ["Ruben Janssens", "Jens De Bock", "Sofie Labat", "Eva Verhelst", "Veronique Hoste", "Tony Belpaeme"], "title": "Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue", "comment": "Accepted at the 34th IEEE International Conference on Robot and Human\n  Interactive Communication (RO-MAN 2025)", "summary": "Detecting miscommunication in human-robot interaction is a critical function\nfor maintaining user engagement and trust. While humans effortlessly detect\ncommunication errors in conversations through both verbal and non-verbal cues,\nrobots face significant challenges in interpreting non-verbal feedback, despite\nadvances in computer vision for recognizing affective expressions. This\nresearch evaluates the effectiveness of machine learning models in detecting\nmiscommunications in robot dialogue. Using a multi-modal dataset of 240\nhuman-robot conversations, where four distinct types of conversational failures\nwere systematically introduced, we assess the performance of state-of-the-art\ncomputer vision models. After each conversational turn, users provided feedback\non whether they perceived an error, enabling an analysis of the models' ability\nto accurately detect robot mistakes. Despite using state-of-the-art models, the\nperformance barely exceeds random chance in identifying miscommunication, while\non a dataset with more expressive emotional content, they successfully\nidentified confused states. To explore the underlying cause, we asked human\nraters to do the same. They could also only identify around half of the induced\nmiscommunications, similarly to our model. These results uncover a fundamental\nlimitation in identifying robot miscommunications in dialogue: even when users\nperceive the induced miscommunication as such, they often do not communicate\nthis to their robotic conversation partner. This knowledge can shape\nexpectations of the performance of computer vision models and can help\nresearchers to design better human-robot conversations by deliberately\neliciting feedback where needed.", "AI": {"tldr": "研究评估机器学习模型在检测人机对话中的沟通错误效果，发现即使使用先进模型，识别准确率仅略高于随机猜测，揭示了用户反馈不足的根本问题。", "motivation": "人机交互中检测沟通错误对维持用户参与和信任至关重要，但机器人难以通过非语言反馈识别错误。", "method": "使用包含240段人机对话的多模态数据集，引入四种对话失败类型，评估计算机视觉模型的性能。", "result": "模型在识别沟通错误时表现不佳，仅略优于随机猜测，但在情感表达更丰富的数据集中能成功识别困惑状态。", "conclusion": "研究揭示了识别机器人沟通错误的根本限制：用户即使感知到错误，也常未反馈给机器人，这有助于改进人机对话设计。"}}
{"id": "2506.19929", "categories": ["cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2506.19929", "abs": "https://arxiv.org/abs/2506.19929", "authors": ["Efe Çakır", "Patrick Dumond"], "title": "A Comparative Analysis of Reinforcement Learning and Conventional Deep Learning Approaches for Bearing Fault Diagnosis", "comment": "5 pages, 5 figures. To appear in the Proceedings of the Canadian\n  Society for Mechanical Engineering (CSME) Congress 2025", "summary": "Bearing faults in rotating machinery can lead to significant operational\ndisruptions and maintenance costs. Modern methods for bearing fault diagnosis\nrely heavily on vibration analysis and machine learning techniques, which often\nrequire extensive labeled data and may not adapt well to dynamic environments.\nThis study explores the feasibility of reinforcement learning (RL),\nspecifically Deep Q-Networks (DQNs), for bearing fault classification tasks in\nmachine condition monitoring to enhance the accuracy and adaptability of\nbearing fault diagnosis. The results demonstrate that while RL models developed\nin this study can match the performance of traditional supervised learning\nmodels under controlled conditions, they excel in adaptability when equipped\nwith optimized reward structures. However, their computational demands\nhighlight areas for further improvement. These findings demonstrate RL's\npotential to complement traditional methods, paving the way for adaptive\ndiagnostic frameworks.", "AI": {"tldr": "该论文探讨了强化学习（特别是DQN）在轴承故障诊断中的应用，发现其在适应性上优于传统监督学习，但计算需求较高。", "motivation": "轴承故障可能导致严重的运营中断和维护成本，传统方法依赖大量标记数据且适应性不足。", "method": "使用深度Q网络（DQN）进行轴承故障分类，优化奖励结构以提高适应性。", "result": "RL模型在受控条件下与传统方法性能相当，但在适应性上表现更优，计算需求较高。", "conclusion": "强化学习有潜力补充传统方法，为自适应诊断框架提供新方向。"}}
{"id": "2506.20169", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY", "stat.ME"], "pdf": "https://arxiv.org/pdf/2506.20169", "abs": "https://arxiv.org/abs/2506.20169", "authors": ["Bala Rajesh Konkathi", "Arun K. Tangirala"], "title": "Causal discovery in deterministic discrete LTI-DAE systems", "comment": null, "summary": "Discovering pure causes or driver variables in deterministic LTI systems is\nof vital importance in the data-driven reconstruction of causal networks. A\nrecent work by Kathari and Tangirala, proposed in 2022, formulated the causal\ndiscovery method as a constraint identification problem. The constraints are\nidentified using a dynamic iterative PCA (DIPCA)-based approach for dynamical\nsystems corrupted with Gaussian measurement errors. The DIPCA-based method\nworks efficiently for dynamical systems devoid of any algebraic relations.\nHowever, several dynamical systems operate under feedback control and/or are\ncoupled with conservation laws, leading to differential-algebraic (DAE) or\nmixed causal systems. In this work, a method, namely the partition of variables\n(PoV), for causal discovery in LTI-DAE systems is proposed. This method is\nsuperior to the method that was presented by Kathari and Tangirala (2022), as\nPoV also works for pure dynamical systems, which are devoid of algebraic\nequations. The proposed method identifies the causal drivers up to a minimal\nsubset. PoV deploys DIPCA to first determine the number of algebraic relations\n($n_a$), the number of dynamical relations ($n_d$) and the constraint matrix.\nSubsequently, the subsets are identified through an admissible partitioning of\nthe constraint matrix by finding the condition number of it. Case studies are\npresented to demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "提出了一种名为PoV的方法，用于在LTI-DAE系统中发现因果关系，优于现有方法。", "motivation": "现有方法无法处理带有代数关系的动态系统，而许多实际系统存在反馈控制或守恒定律，导致混合因果系统。", "method": "PoV方法通过DIPCA确定代数关系数、动态关系数和约束矩阵，再通过条件数识别最小因果驱动子集。", "result": "PoV方法在LTI-DAE系统中有效，且适用于纯动态系统。", "conclusion": "PoV方法在因果发现中具有优越性，适用于更广泛的系统类型。"}}
{"id": "2506.20174", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20174", "abs": "https://arxiv.org/abs/2506.20174", "authors": ["Man Duc Chuc"], "title": "Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition", "comment": null, "summary": "Foundation models are rapidly transforming Earth Observation data mining by\nenabling generalizable and scalable solutions for key tasks such as scene\nclassification and semantic segmentation. While most efforts in the geospatial\ndomain have focused on developing large models trained from scratch using\nmassive Earth Observation datasets, an alternative strategy that remains\nunderexplored is the reuse and combination of existing pretrained models. In\nthis study, we investigate whether foundation models pretrained on remote\nsensing and general vision datasets can be effectively combined to improve\nperformance across a diverse set of key Earth Observation tasks. Using the\nGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,\nHiera, and DOFA, on eleven datasets covering a range of spatial resolutions,\nsensor modalities, and task types. The results show that feature-level\nensembling of smaller pretrained models can match or exceed the performance of\nmuch larger models, while requiring less training time and computational\nresources. Moreover, the study highlights the potential of applying knowledge\ndistillation to transfer the strengths of ensembles into more compact models,\noffering a practical path for deploying foundation models in real-world Earth\nObservation applications.", "AI": {"tldr": "研究探讨了结合预训练基础模型提升地球观测任务性能的可行性，发现特征级集成小模型可媲美或超越大模型，且更高效。", "motivation": "探索利用现有预训练模型而非从头训练大模型，以提升地球观测任务的性能和效率。", "method": "通过GEO-Bench基准测试，评估Prithvi、Hiera和DOFA等模型在11个数据集上的表现，采用特征级集成和知识蒸馏技术。", "result": "特征级集成小模型性能可媲美或超越大模型，同时减少训练时间和计算资源。知识蒸馏能将集成优势转移到更紧凑模型中。", "conclusion": "结合预训练模型和知识蒸馏为地球观测任务提供了高效且实用的解决方案。"}}
{"id": "2506.20595", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20595", "abs": "https://arxiv.org/abs/2506.20595", "authors": ["Momin N. Siddiqui", "Roy Pea", "Hari Subramonyam"], "title": "AI in the Writing Process: How Purposeful AI Support Fosters Student Writing", "comment": null, "summary": "The ubiquity of technologies like ChatGPT has raised concerns about their\nimpact on student writing, particularly regarding reduced learner agency and\nsuperficial engagement with content. While standalone chat-based LLMs often\nproduce suboptimal writing outcomes, evidence suggests that purposefully\ndesigned AI writing support tools can enhance the writing process. This paper\ninvestigates how different AI support approaches affect writers' sense of\nagency and depth of knowledge transformation. Through a randomized control\ntrial with 90 undergraduate students, we compare three conditions: (1) a\nchat-based LLM writing assistant, (2) an integrated AI writing tool to support\ndiverse subprocesses, and (3) a standard writing interface (control). Our\nfindings demonstrate that, among AI-supported conditions, students using the\nintegrated AI writing tool exhibited greater agency over their writing process\nand engaged in deeper knowledge transformation overall. These results suggest\nthat thoughtfully designed AI writing support targeting specific aspects of the\nwriting process can help students maintain ownership of their work while\nfacilitating improved engagement with content.", "AI": {"tldr": "研究表明，集成式AI写作工具比聊天式LLM更能提升学生的写作自主性和知识转化深度。", "motivation": "探讨AI写作支持工具对学生写作自主性和知识转化深度的影响。", "method": "通过随机对照试验，比较聊天式LLM、集成式AI写作工具和标准写作界面的效果。", "result": "集成式AI写作工具显著提升学生的写作自主性和知识转化深度。", "conclusion": "针对性设计的AI写作支持工具有助于学生保持写作自主性并提升内容参与度。"}}
{"id": "2506.20311", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.20311", "abs": "https://arxiv.org/abs/2506.20311", "authors": ["Jingwen Wei"], "title": "Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles", "comment": null, "summary": "The growing use of mobile robots in sectors such as automotive, agriculture,\nand rescue operations reflects progress in robotics and autonomy. In unmanned\naerial vehicles (UAVs), most research emphasizes visual SLAM, sensor fusion,\nand path planning. However, applying UAVs to search and rescue missions in\ndisaster zones remains underexplored, especially for autonomous navigation.\n  This report develops methods for real-time and secure UAV maneuvering in\ncomplex 3D environments, crucial during forest fires. Building upon past\nresearch, it focuses on designing navigation algorithms for unfamiliar and\nhazardous environments, aiming to improve rescue efficiency and safety through\nUAV-based early warning and rapid response.\n  The work unfolds in phases. First, a 2D fusion navigation strategy is\nexplored, initially for mobile robots, enabling safe movement in dynamic\nsettings. This sets the stage for advanced features such as adaptive obstacle\nhandling and decision-making enhancements. Next, a novel 3D reactive navigation\nstrategy is introduced for collision-free movement in forest fire simulations,\naddressing the unique challenges of UAV operations in such scenarios.\n  Finally, the report proposes a unified control approach that integrates UAVs\nand unmanned ground vehicles (UGVs) for coordinated rescue missions in forest\nenvironments. Each phase presents challenges, proposes control models, and\nvalidates them with mathematical and simulation-based evidence. The study\noffers practical value and academic insights for improving the role of UAVs in\nnatural disaster rescue operations.", "AI": {"tldr": "论文探讨了无人机在复杂3D环境中的实时安全导航方法，特别针对森林火灾救援任务，提出了2D和3D导航策略，并整合了无人机与地面无人车的协同控制。", "motivation": "无人机在灾害救援中的应用尚未充分探索，尤其是在自主导航方面。研究旨在提升救援效率和安全性。", "method": "分阶段设计导航算法：从2D融合导航策略到3D反应式导航策略，最后整合无人机与地面无人车的协同控制。", "result": "提出了有效的导航和控制模型，并通过数学和仿真验证了其可行性。", "conclusion": "研究为无人机在自然灾害救援中的实际应用提供了学术和实践价值。"}}
{"id": "2506.19935", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.19935", "abs": "https://arxiv.org/abs/2506.19935", "authors": ["Shuchen Xue", "Tianyu Xie", "Tianyang Hu", "Zijin Feng", "Jiacheng Sun", "Kenji Kawaguchi", "Zhenguo Li", "Zhi-Ming Ma"], "title": "Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture", "comment": null, "summary": "Large language models (LLMs) predominantly use autoregressive (AR)\napproaches, but masked diffusion models (MDMs) are emerging as viable\nalternatives. A key challenge in comparing AR and MDM paradigms is their\ntypical architectural difference: AR models are often decoder-only, while MDMs\nhave largely been encoder-only. This practice of changing both the modeling\nparadigm and architecture simultaneously makes direct comparisons unfair, as\nit's hard to distinguish whether observed differences stem from the paradigm\nitself or the architectural shift. This research evaluates MDMs within a\ndecoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or\nAO-AR) and standard AR paradigms. Our investigation suggests that the standard\nAO-AR objective, which averages over all token permutations, may benefit from\nrefinement, as many permutations appear less informative compared to the\nlanguage's inherent left-to-right structure. (2) Investigate architectural\ninfluences (decoder-only vs. encoder-only) within MDMs. We demonstrate that\nwhile encoder-only MDMs model a simpler conditional probability space,\ndecoder-only MDMs can achieve dramatic generation speedups ($\\sim25\\times$) and\ncomparable perplexity with temperature annealing despite modeling a vastly\nlarger space, highlighting key trade-offs. This work thus decouples core\nparadigm differences from architectural influences, offering insights for\nfuture model design. Code is available at https://github.com/scxue/AO-GPT-MDM.", "AI": {"tldr": "该研究在解码器框架下评估掩码扩散模型（MDM），公平比较MDM与自回归（AR）范式，并探讨架构影响。", "motivation": "比较AR和MDM范式时，架构差异导致不公平对比，研究旨在区分范式与架构的影响。", "method": "在解码器框架下评估MDM，将其视为任意顺序自回归（AO-AR），并分析架构差异。", "result": "解码器MDM在生成速度上显著提升（约25倍），且困惑度与编码器MDM相当。", "conclusion": "研究分离了范式与架构的影响，为未来模型设计提供了见解。"}}
{"id": "2506.20179", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.20179", "abs": "https://arxiv.org/abs/2506.20179", "authors": ["Enzhe Zhao", "Zhichang Guo", "Yao Li", "Fanghui Song", "Boying Wu"], "title": "Progressive Alignment Degradation Learning for Pansharpening", "comment": "13 pages, 9 figures", "summary": "Deep learning-based pansharpening has been shown to effectively generate\nhigh-resolution multispectral (HRMS) images. To create supervised ground-truth\nHRMS images, synthetic data generated using the Wald protocol is commonly\nemployed. This protocol assumes that networks trained on artificial\nlow-resolution data will perform equally well on high-resolution data. However,\nwell-trained models typically exhibit a trade-off in performance between\nreduced-resolution and full-resolution datasets. In this paper, we delve into\nthe Wald protocol and find that its inaccurate approximation of real-world\ndegradation patterns limits the generalization of deep pansharpening models. To\naddress this issue, we propose the Progressive Alignment Degradation Module\n(PADM), which uses mutual iteration between two sub-networks, PAlignNet and\nPDegradeNet, to adaptively learn accurate degradation processes without relying\non predefined operators. Building on this, we introduce HFreqdiff, which embeds\nhigh-frequency details into a diffusion framework and incorporates CFB and BACM\nmodules for frequency-selective detail extraction and precise reverse process\nlearning. These innovations enable effective integration of high-resolution\npanchromatic and multispectral images, significantly enhancing spatial\nsharpness and quality. Experiments and ablation studies demonstrate the\nproposed method's superior performance compared to state-of-the-art techniques.", "AI": {"tldr": "论文提出了一种新的渐进对齐退化模块（PADM）和HFreqdiff方法，用于改进深度学习全色锐化模型的泛化能力，显著提升了图像的空间清晰度和质量。", "motivation": "传统Wald协议生成的合成数据无法准确模拟真实世界的退化模式，限制了深度学习全色锐化模型的泛化能力。", "method": "提出PADM模块，通过两个子网络（PAlignNet和PDegradeNet）的相互迭代自适应学习退化过程；引入HFreqdiff方法，结合CFB和BACM模块进行高频细节提取和反向过程学习。", "result": "实验和消融研究表明，该方法在空间清晰度和图像质量上优于现有技术。", "conclusion": "PADM和HFreqdiff有效解决了传统方法的局限性，显著提升了全色锐化模型的性能。"}}
{"id": "2506.20314", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20314", "abs": "https://arxiv.org/abs/2506.20314", "authors": ["Marc-Philip Ecker", "Bernhard Bischof", "Minh Nhat Vu", "Christoph Fröhlich", "Tobias Glück", "Wolfgang Kemmetmüller"], "title": "Near Time-Optimal Hybrid Motion Planning for Timber Cranes", "comment": "Accepted at ICRA 2025", "summary": "Efficient, collision-free motion planning is essential for automating\nlarge-scale manipulators like timber cranes. They come with unique challenges\nsuch as hydraulic actuation constraints and passive joints-factors that are\nseldom addressed by current motion planning methods. This paper introduces a\nnovel approach for time-optimal, collision-free hybrid motion planning for a\nhydraulically actuated timber crane with passive joints. We enhance the\nvia-point-based stochastic trajectory optimization (VP-STO) algorithm to\ninclude pump flow rate constraints and develop a novel collision cost\nformulation to improve robustness. The effectiveness of the enhanced VP-STO as\nan optimal single-query global planner is validated by comparison with an\ninformed RRT* algorithm using a time-optimal path parameterization (TOPP). The\noverall hybrid motion planning is formed by combination with a gradient-based\nlocal planner that is designed to follow the global planner's reference and to\nsystematically consider the passive joint dynamics for both collision avoidance\nand sway damping.", "AI": {"tldr": "本文提出了一种针对液压驱动木材起重机的新型时间最优、无碰撞混合运动规划方法，改进了VP-STO算法并开发了新的碰撞成本公式。", "motivation": "解决液压驱动木材起重机在运动规划中面临的独特挑战，如液压驱动约束和被动关节问题，这些问题现有方法很少涉及。", "method": "增强VP-STO算法以包含泵流量约束，并开发新的碰撞成本公式；结合梯度局部规划器形成混合运动规划。", "result": "验证了增强VP-STO作为全局规划器的有效性，优于RRT*算法。", "conclusion": "混合运动规划方法在时间最优性和无碰撞性上表现优异，适用于复杂机械系统。"}}
{"id": "2506.19937", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19937", "abs": "https://arxiv.org/abs/2506.19937", "authors": ["Tomas M. Bosschieter", "Luis Franca", "Jessica Wolk", "Yiyuan Wu", "Bella Mehta", "Joseph Dehoney", "Orsolya Kiss", "Fiona C. Baker", "Qingyu Zhao", "Rich Caruana", "Kilian M. Pohl"], "title": "The Most Important Features in Generalized Additive Models Might Be Groups of Features", "comment": null, "summary": "While analyzing the importance of features has become ubiquitous in\ninterpretable machine learning, the joint signal from a group of related\nfeatures is sometimes overlooked or inadvertently excluded. Neglecting the\njoint signal could bypass a critical insight: in many instances, the most\nsignificant predictors are not isolated features, but rather the combined\neffect of groups of features. This can be especially problematic for datasets\nthat contain natural groupings of features, including multimodal datasets. This\npaper introduces a novel approach to determine the importance of a group of\nfeatures for Generalized Additive Models (GAMs) that is efficient, requires no\nmodel retraining, allows defining groups posthoc, permits overlapping groups,\nand remains meaningful in high-dimensional settings. Moreover, this definition\noffers a parallel with explained variation in statistics. We showcase\nproperties of our method on three synthetic experiments that illustrate the\nbehavior of group importance across various data regimes. We then demonstrate\nthe importance of groups of features in identifying depressive symptoms from a\nmultimodal neuroscience dataset, and study the importance of social\ndeterminants of health after total hip arthroplasty. These two case studies\nreveal that analyzing group importance offers a more accurate, holistic view of\nthe medical issues compared to a single-feature analysis.", "AI": {"tldr": "本文提出了一种高效、无需重新训练模型的方法，用于评估广义加性模型（GAMs）中特征组的重要性，适用于高维数据，并在多模态数据集中展示了其优势。", "motivation": "现有方法常忽略特征组的联合信号，导致遗漏重要预测信息，尤其是在多模态数据集中。", "method": "提出了一种无需重新训练模型、支持事后定义和重叠特征组的方法，并与统计学中的解释变异概念平行。", "result": "在合成实验和两个实际案例（抑郁症症状识别和髋关节置换术后健康因素分析）中验证了方法的有效性。", "conclusion": "分析特征组重要性比单特征分析更全面准确，尤其在医学领域。"}}
{"id": "2506.20214", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.20214", "abs": "https://arxiv.org/abs/2506.20214", "authors": ["Yanzhe Chen", "Huasong Zhong", "Yan Li", "Zhenheng Yang"], "title": "UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation", "comment": "19 pages, 5 figures", "summary": "Unified multimodal large language models (MLLMs) have shown promise in\njointly advancing multimodal understanding and generation, with visual\ncodebooks discretizing images into tokens for autoregressive modeling. Existing\ncodebook-based methods either rely on small vocabularies (~16K entries) that\nlack fine-grained semantics or naively scale up, resulting in low token\nutilization and unstable training. We propose UniCode$^2$, a cascaded codebook\nframework enabling large-scale, semantically aligned, and stable visual\ntokenization. By clustering millions of SigLIP sequence embeddings, we build a\n500K-entry codebook that preserves vision-language alignment while expanding\ncapacity. Stability is ensured via a cascaded design: a frozen codebook anchors\nthe embedding space, and a trainable codebook refines task-specific semantics.\nThis decoupling promotes high utilization and robust learning. Moreover, the\nalignment of our visual tokens with textual semantics enables seamless\nintegration with pretrained diffusion decoders, supporting high-quality visual\nsynthesis with minimal adaptation. UniCode^2 delivers strong performance across\ndiverse benchmarks, demonstrating the viability of scaling visual token spaces\nwithout sacrificing stability, semantics, or modularity.", "AI": {"tldr": "UniCode²提出了一种级联码本框架，用于大规模、语义对齐且稳定的视觉标记化，解决了现有方法在词汇量小或训练不稳定上的问题。", "motivation": "现有基于码本的方法要么词汇量小（约16K条目），缺乏细粒度语义，要么盲目扩展导致标记利用率低和训练不稳定。", "method": "通过聚类数百万SigLIP序列嵌入，构建了一个50万条目的码本，采用级联设计：冻结码本锚定嵌入空间，可训练码本细化任务特定语义。", "result": "UniCode²在多样化基准测试中表现优异，验证了在不牺牲稳定性、语义或模块性的情况下扩展视觉标记空间的可行性。", "conclusion": "UniCode²通过级联码本框架，实现了视觉标记化的大规模、语义对齐和稳定性，为多模态大语言模型提供了高效解决方案。"}}
{"id": "2506.20315", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20315", "abs": "https://arxiv.org/abs/2506.20315", "authors": ["Matías Mattamala", "Nived Chebrolu", "Jonas Frey", "Leonard Freißmuth", "Haedam Oh", "Benoit Casseau", "Marco Hutter", "Maurice Fallon"], "title": "Building Forest Inventories with Autonomous Legged Robots -- System, Lessons, and Challenges Ahead", "comment": "20 pages, 13 figures. Pre-print version of the accepted paper for\n  IEEE Transactions on Field Robotics (T-FR)", "summary": "Legged robots are increasingly being adopted in industries such as oil, gas,\nmining, nuclear, and agriculture. However, new challenges exist when moving\ninto natural, less-structured environments, such as forestry applications. This\npaper presents a prototype system for autonomous, under-canopy forest inventory\nwith legged platforms. Motivated by the robustness and mobility of modern\nlegged robots, we introduce a system architecture which enabled a quadruped\nplatform to autonomously navigate and map forest plots. Our solution involves a\ncomplete navigation stack for state estimation, mission planning, and tree\ndetection and trait estimation. We report the performance of the system from\ntrials executed over one and a half years in forests in three European\ncountries. Our results with the ANYmal robot demonstrate that we can survey\nplots up to 1 ha plot under 30 min, while also identifying trees with typical\nDBH accuracy of 2cm. The findings of this project are presented as five lessons\nand challenges. Particularly, we discuss the maturity of hardware development,\nstate estimation limitations, open problems in forest navigation, future\navenues for robotic forest inventory, and more general challenges to assess\nautonomous systems. By sharing these lessons and challenges, we offer insight\nand new directions for future research on legged robots, navigation systems,\nand applications in natural environments. Additional videos can be found in\nhttps://dynamic.robots.ox.ac.uk/projects/legged-robots", "AI": {"tldr": "本文介绍了一种基于四足机器人的自主森林调查系统，展示了其在自然环境中导航和测绘的能力，并总结了相关挑战和未来研究方向。", "motivation": "现代四足机器人具有强大的鲁棒性和移动性，适合在复杂的自然环境中执行任务，如森林调查。本文旨在开发一种自主系统，用于森林树冠下的测绘和树木特征估计。", "method": "提出了一种完整的导航系统架构，包括状态估计、任务规划、树木检测和特征估计。系统在三个欧洲国家的森林中进行了为期一年半的实地测试。", "result": "ANYmal机器人能够在30分钟内完成1公顷森林的测绘，树木直径（DBH）的测量精度达到2厘米。", "conclusion": "总结了硬件成熟度、状态估计限制、森林导航问题等五个关键挑战，并提出了未来研究方向，为四足机器人在自然环境中的应用提供了新思路。"}}
{"id": "2506.19992", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19992", "abs": "https://arxiv.org/abs/2506.19992", "authors": ["Gabor Petnehazi", "Bernadett Aradi"], "title": "HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization", "comment": null, "summary": "The explosive growth of complex datasets across various modalities\nnecessitates advanced analytical tools that not only group data effectively but\nalso provide human-understandable insights into the discovered structures. We\nintroduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using\nLLMs for Efficient Summarization), a novel algorithm and Python package\ndesigned for hierarchical k-means clustering of diverse data types, including\ntext, images, and numeric data (processed one modality per run). HERCULES\nconstructs a cluster hierarchy by recursively applying k-means clustering,\nstarting from individual data points at level 0. A key innovation is its deep\nintegration of Large Language Models (LLMs) to generate semantically rich\ntitles and descriptions for clusters at each level of the hierarchy,\nsignificantly enhancing interpretability. The algorithm supports two main\nrepresentation modes: `direct' mode, which clusters based on original data\nembeddings or scaled numeric features, and `description' mode, which clusters\nbased on embeddings derived from LLM-generated summaries. Users can provide a\n`topic\\_seed' to guide LLM-generated summaries towards specific themes. An\ninteractive visualization tool facilitates thorough analysis and understanding\nof the clustering results. We demonstrate HERCULES's capabilities and discuss\nits potential for extracting meaningful, hierarchical knowledge from complex\ndatasets.", "AI": {"tldr": "HERCULES是一种新型分层k-means聚类算法，支持多种数据类型，并利用LLM生成语义丰富的聚类标题和描述，提升可解释性。", "motivation": "复杂数据集的快速增长需要既能有效分组数据又能提供人类可理解洞察的工具。", "method": "HERCULES通过递归应用k-means聚类构建层次结构，并利用LLM生成聚类标题和描述，支持两种表示模式（直接模式和描述模式）。", "result": "算法能够从复杂数据集中提取有意义的分层知识，并提供交互式可视化工具。", "conclusion": "HERCULES展示了从复杂数据中提取层次化知识的潜力，增强了聚类的可解释性。"}}
{"id": "2506.20525", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.20525", "abs": "https://arxiv.org/abs/2506.20525", "authors": ["Christian Internò", "Andrea Castellani", "Sebastian Schmitt", "Fabio Stella", "Barbara Hammer"], "title": "Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation", "comment": null, "summary": "Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of\nhigh-quality datasets and the complex variability of industrial energy\nconsumption patterns. To address data scarcity and privacy issues, we introduce\nthe Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an\nopen-source dataset generated using Digital Twin simulations. SIDED includes\nthree types of industrial facilities across three different geographic\nlocations, capturing diverse appliance behaviors, weather conditions, and load\nprofiles. We also propose the Appliance-Modulated Data Augmentation (AMDA)\nmethod, a computationally efficient technique that enhances NILM model\ngeneralization by intelligently scaling appliance power contributions based on\ntheir relative impact. We show in experiments that NILM models trained with\nAMDA-augmented data significantly improve the disaggregation of energy\nconsumption of complex industrial appliances like combined heat and power\nsystems. Specifically, in our out-of-sample scenarios, models trained with AMDA\nachieved a Normalized Disaggregation Error of 0.093, outperforming models\ntrained without data augmentation (0.451) and those trained with random data\naugmentation (0.290). Data distribution analyses confirm that AMDA effectively\naligns training and test data distributions, enhancing model generalization.", "AI": {"tldr": "论文提出了一种合成工业数据集SIDED和一种数据增强方法AMDA，用于解决工业非侵入式负载监测（NILM）中的数据稀缺和隐私问题，显著提升了模型性能。", "motivation": "工业NILM面临高质量数据集稀缺和工业能耗模式复杂多变的问题，同时需解决数据隐私问题。", "method": "使用数字孪生模拟生成开源数据集SIDED，并提出AMDA方法，通过智能调整电器功率贡献来增强模型泛化能力。", "result": "实验显示，使用AMDA增强数据的NILM模型在复杂工业电器（如热电联产系统）的能耗分解中表现优异，归一化分解误差为0.093，优于未增强（0.451）和随机增强（0.290）的模型。", "conclusion": "AMDA有效对齐训练和测试数据分布，提升模型泛化能力，为工业NILM提供了实用解决方案。"}}
{"id": "2506.20222", "categories": ["cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20222", "abs": "https://arxiv.org/abs/2506.20222", "authors": ["Pujing Yang", "Guangyi Zhang", "Yunlong Cai", "Lei Yu", "Guanding Yu"], "title": "Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission", "comment": null, "summary": "Event cameras asynchronously capture pixel-level intensity changes with\nextremely low latency. They are increasingly used in conjunction with RGB\ncameras for a wide range of vision-related applications. However, a major\nchallenge in these hybrid systems lies in the transmission of the large volume\nof triggered events and RGB images. To address this, we propose a transmission\nscheme that retains efficient reconstruction performance of both sources while\naccomplishing real-time deblurring in parallel. Conventional RGB cameras and\nevent cameras typically capture the same scene in different ways, often\nresulting in significant redundant information across their outputs. To address\nthis, we develop a joint event and image (E-I) transmission framework to\neliminate redundancy and thereby optimize channel bandwidth utilization. Our\napproach employs Bayesian modeling and the information bottleneck method to\ndisentangle the shared and domain-specific information within the E-I inputs.\nThis disentangled information bottleneck framework ensures both the compactness\nand informativeness of extracted shared and domain-specific information.\nMoreover, it adaptively allocates transmission bandwidth based on scene\ndynamics, i.e., more symbols are allocated to events for dynamic details or to\nimages for static information. Simulation results demonstrate that the proposed\nscheme not only achieves superior reconstruction quality compared to\nconventional systems but also delivers enhanced deblurring performance.", "AI": {"tldr": "提出了一种联合事件和图像（E-I）传输框架，通过贝叶斯建模和信息瓶颈方法消除冗余，优化带宽利用，同时实现实时去模糊。", "motivation": "混合系统中事件相机和RGB相机传输大量数据存在冗余和带宽挑战，需高效重建和去模糊。", "method": "采用贝叶斯建模和信息瓶颈方法，分离共享和领域特定信息，动态分配传输带宽。", "result": "仿真结果表明，方案在重建质量和去模糊性能上优于传统系统。", "conclusion": "提出的E-I传输框架有效优化带宽利用，提升重建和去模糊性能。"}}
{"id": "2506.20320", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20320", "abs": "https://arxiv.org/abs/2506.20320", "authors": ["Malte Probst", "Raphael Wenzel", "Tim Puphal", "Monica Dasi", "Nico A. Steinhardt", "Sango Matsuzaki", "Misa Komuro"], "title": "Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation", "comment": null, "summary": "In Social Robot Navigation, autonomous agents need to resolve many sequential\ninteractions with other agents. State-of-the art planners can efficiently\nresolve the next, imminent interaction cooperatively and do not focus on longer\nplanning horizons. This makes it hard to maneuver scenarios where the agent\nneeds to select a good strategy to find gaps or channels in the crowd. We\npropose to decompose trajectory planning into two separate steps: Conflict\navoidance for finding good, macroscopic trajectories, and cooperative collision\navoidance (CCA) for resolving the next interaction optimally. We propose the\nProbabilistic Gap Planner (PGP) as a conflict avoidance planner. PGP modifies\nan established probabilistic collision risk model to include a general\nassumption of cooperativity. PGP biases the short-term CCA planner to head\ntowards gaps in the crowd. In extensive simulations with crowds of varying\ndensity, we show that using PGP in addition to state-of-the-art CCA planners\nimproves the agents' performance: On average, agents keep more space to others,\ncreate less tension, and cause fewer collisions. This typically comes at the\nexpense of slightly longer paths. PGP runs in real-time on WaPOCHI mobile robot\nby Honda R&D.", "AI": {"tldr": "论文提出了一种分解轨迹规划的方法，结合冲突避免和协作碰撞避免，通过Probabilistic Gap Planner（PGP）提升社交机器人导航性能。", "motivation": "现有规划器仅关注短期交互，难以在复杂场景中选择长期策略，如寻找人群中的间隙或通道。", "method": "将轨迹规划分解为冲突避免（宏观轨迹）和协作碰撞避免（微观交互），提出PGP作为冲突避免规划器。", "result": "在模拟实验中，PGP结合现有CCA规划器显著提升了性能，如增加空间、减少紧张和碰撞，但路径略长。", "conclusion": "PGP方法有效提升了社交机器人导航的长期策略能力，适用于实时机器人平台。"}}
{"id": "2506.19997", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19997", "abs": "https://arxiv.org/abs/2506.19997", "authors": ["Geonwoo Cho", "Jaegyun Im", "Jihwan Lee", "Hojun Yi", "Sejin Kim", "Sundong Kim"], "title": "TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design", "comment": null, "summary": "Generalizing deep reinforcement learning agents to unseen environments\nremains a significant challenge. One promising solution is Unsupervised\nEnvironment Design (UED), a co-evolutionary framework in which a teacher\nadaptively generates tasks with high learning potential, while a student learns\na robust policy from this evolving curriculum. Existing UED methods typically\nmeasure learning potential via regret, the gap between optimal and current\nperformance, approximated solely by value-function loss. Building on these\napproaches, we introduce the transition prediction error as an additional term\nin our regret approximation. To capture how training on one task affects\nperformance on others, we further propose a lightweight metric called\nco-learnability. By combining these two measures, we present Transition-aware\nRegret Approximation with Co-learnability for Environment Design (TRACED).\nEmpirical evaluations show that TRACED yields curricula that improve zero-shot\ngeneralization across multiple benchmarks while requiring up to 2x fewer\nenvironment interactions than strong baselines. Ablation studies confirm that\nthe transition prediction error drives rapid complexity ramp-up and that\nco-learnability delivers additional gains when paired with the transition\nprediction error. These results demonstrate how refined regret approximation\nand explicit modeling of task relationships can be leveraged for\nsample-efficient curriculum design in UED.", "AI": {"tldr": "论文提出TRACED方法，通过结合转移预测误差和共学习性改进UED框架，提升零样本泛化能力并减少环境交互需求。", "motivation": "解决深度强化学习代理在未见环境中的泛化问题，改进现有UED框架的遗憾近似方法。", "method": "引入转移预测误差作为遗憾近似的额外项，并提出轻量级共学习性指标，结合两者形成TRACED方法。", "result": "实验表明TRACED在多个基准测试中提升零样本泛化能力，且环境交互需求减少至基线的一半。", "conclusion": "改进的遗憾近似和任务关系建模可高效设计UED课程，提升样本效率。"}}
{"id": "2506.20254", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20254", "abs": "https://arxiv.org/abs/2506.20254", "authors": ["Kun Yuan", "Tingxuan Chen", "Shi Li", "Joel L. Lavanchy", "Christian Heiliger", "Ege Özsoy", "Yiming Huang", "Long Bai", "Nassir Navab", "Vinkle Srivastav", "Hongliang Ren", "Nicolas Padoy"], "title": "Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement", "comment": "Accepted by MICCAI 2025", "summary": "The complexity and diversity of surgical workflows, driven by heterogeneous\noperating room settings, institutional protocols, and anatomical variability,\npresent a significant challenge in developing generalizable models for\ncross-institutional and cross-procedural surgical understanding. While recent\nsurgical foundation models pretrained on large-scale vision-language data offer\npromising transferability, their zero-shot performance remains constrained by\ndomain shifts, limiting their utility in unseen surgical environments. To\naddress this, we introduce Surgical Phase Anywhere (SPA), a lightweight\nframework for versatile surgical workflow understanding that adapts foundation\nmodels to institutional settings with minimal annotation. SPA leverages\nfew-shot spatial adaptation to align multi-modal embeddings with\ninstitution-specific surgical scenes and phases. It also ensures temporal\nconsistency through diffusion modeling, which encodes task-graph priors derived\nfrom institutional procedure protocols. Finally, SPA employs dynamic test-time\nadaptation, exploiting the mutual agreement between multi-modal phase\nprediction streams to adapt the model to a given test video in a\nself-supervised manner, enhancing the reliability under test-time distribution\nshifts. SPA is a lightweight adaptation framework, allowing hospitals to\nrapidly customize phase recognition models by defining phases in natural\nlanguage text, annotating a few images with the phase labels, and providing a\ntask graph defining phase transitions. The experimental results show that the\nSPA framework achieves state-of-the-art performance in few-shot surgical phase\nrecognition across multiple institutions and procedures, even outperforming\nfull-shot models with 32-shot labeled data. Code is available at\nhttps://github.com/CAMMA-public/SPA", "AI": {"tldr": "SPA是一个轻量级框架，通过少量标注和自然语言定义，实现跨机构和跨手术的通用工作流理解。", "motivation": "手术工作流的复杂性和多样性导致通用模型开发困难，现有基础模型在零样本性能上受限于领域偏移。", "method": "SPA利用少样本空间适应、扩散建模和动态测试时适应，实现多模态嵌入对齐和时间一致性。", "result": "SPA在少样本手术阶段识别中表现优异，甚至超过全样本模型。", "conclusion": "SPA为医院提供了一种快速定制手术阶段识别模型的轻量级解决方案。"}}
{"id": "2506.20343", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20343", "abs": "https://arxiv.org/abs/2506.20343", "authors": ["Kento Kawaharazuka", "Takahiro Hattori", "Keita Yoneda", "Kei Okada"], "title": "PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks", "comment": "Accepted at IEEE Robotics and Automation Letters", "summary": "Musculoskeletal humanoids are robots that closely mimic the human\nmusculoskeletal system, offering various advantages such as variable stiffness\ncontrol, redundancy, and flexibility. However, their body structure is complex,\nand muscle paths often significantly deviate from geometric models. To address\nthis, numerous studies have been conducted to learn body schema, particularly\nthe relationships among joint angles, muscle tension, and muscle length. These\nstudies typically rely solely on data collected from the actual robot, but this\ndata collection process is labor-intensive, and learning becomes difficult when\nthe amount of data is limited. Therefore, in this study, we propose a method\nthat applies the concept of Physics-Informed Neural Networks (PINNs) to the\nlearning of body schema in musculoskeletal humanoids, enabling high-accuracy\nlearning even with a small amount of data. By utilizing not only data obtained\nfrom the actual robot but also the physical laws governing the relationship\nbetween torque and muscle tension under the assumption of correct joint\nstructure, more efficient learning becomes possible. We apply the proposed\nmethod to both simulation and an actual musculoskeletal humanoid and discuss\nits effectiveness and characteristics.", "AI": {"tldr": "提出了一种基于物理信息神经网络（PINN）的方法，用于学习肌肉骨骼人形机器人的身体模式，即使数据量有限也能实现高精度学习。", "motivation": "肌肉骨骼人形机器人的身体结构复杂，肌肉路径常偏离几何模型，传统方法依赖大量实际数据，数据收集耗时且学习困难。", "method": "结合实际机器人数据和物理规律（扭矩与肌肉张力关系），利用PINN方法学习身体模式。", "result": "在仿真和实际机器人中验证了方法的有效性和特点。", "conclusion": "该方法在数据有限情况下仍能高效学习，为肌肉骨骼人形机器人的身体模式学习提供了新思路。"}}
{"id": "2506.20255", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20255", "abs": "https://arxiv.org/abs/2506.20255", "authors": ["Ayush Lodh", "Ritabrata Chakraborty", "Shivakumara Palaiahnakote", "Umapada Pal"], "title": "A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features", "comment": "15 pages, 7 figures", "summary": "We posit that handwriting recognition benefits from complementary cues\ncarried by the rasterized complex glyph and the pen's trajectory, yet most\nsystems exploit only one modality. We introduce an end-to-end network that\nperforms early fusion of offline images and online stroke data within a shared\nlatent space. A patch encoder converts the grayscale crop into fixed-length\nvisual tokens, while a lightweight transformer embeds the $(x, y, \\text{pen})$\nsequence. Learnable latent queries attend jointly to both token streams,\nyielding context-enhanced stroke embeddings that are pooled and decoded under a\ncross-entropy loss objective. Because integration occurs before any high-level\nclassification, temporal cues reinforce each other during representation\nlearning, producing stronger writer independence. Comprehensive experiments on\nIAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art\naccuracy, exceeding previous bests by up to 1\\%. Our study also shows\nadaptation of this pipeline with gesturification on the ISI-Air dataset. Our\ncode can be found here.", "AI": {"tldr": "提出一种结合离线图像和在线笔画数据的端到端网络，通过早期融合提升手写识别准确率，实验显示优于现有方法。", "motivation": "手写识别通常仅利用单一模态（图像或笔画轨迹），而结合两者可提供互补信息，提升性能。", "method": "设计一个端到端网络，将离线图像和在线笔画数据在共享潜在空间早期融合，使用视觉标记和轻量级Transformer嵌入数据，并通过可学习查询增强上下文。", "result": "在IAMOn-DB和VNOn-DB数据集上达到最优准确率，比之前方法提升1%。", "conclusion": "早期融合多模态数据能有效提升手写识别性能，且具有更强的书写独立性。"}}
{"id": "2506.20373", "categories": ["cs.RO", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.20373", "abs": "https://arxiv.org/abs/2506.20373", "authors": ["Joerg Deigmoeller", "Stephan Hasler", "Nakul Agarwal", "Daniel Tanneberg", "Anna Belardinelli", "Reza Ghoddoosian", "Chao Wang", "Felix Ocker", "Fan Zhang", "Behzad Dariush", "Michael Gienger"], "title": "CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition", "comment": null, "summary": "We introduce CARMA, a system for situational grounding in human-robot group\ninteractions. Effective collaboration in such group settings requires\nsituational awareness based on a consistent representation of present persons\nand objects coupled with an episodic abstraction of events regarding actors and\nmanipulated objects. This calls for a clear and consistent assignment of\ninstances, ensuring that robots correctly recognize and track actors, objects,\nand their interactions over time. To achieve this, CARMA uniquely identifies\nphysical instances of such entities in the real world and organizes them into\ngrounded triplets of actors, objects, and actions.\n  To validate our approach, we conducted three experiments, where multiple\nhumans and a robot interact: collaborative pouring, handovers, and sorting.\nThese scenarios allow the assessment of the system's capabilities as to role\ndistinction, multi-actor awareness, and consistent instance identification. Our\nexperiments demonstrate that the system can reliably generate accurate\nactor-action-object triplets, providing a structured and robust foundation for\napplications requiring spatiotemporal reasoning and situated decision-making in\ncollaborative settings.", "AI": {"tldr": "CARMA是一个用于人机群体交互中情境感知的系统，通过唯一标识实体并组织成行动者-对象-动作三元组，实现协作中的角色区分和多行动者感知。", "motivation": "在群体协作中，机器人需要情境感知能力以正确识别和跟踪行动者、对象及其交互，确保协作的有效性。", "method": "CARMA通过唯一标识物理实体并将其组织成行动者-对象-动作三元组，实现情境感知。", "result": "实验表明，CARMA能可靠生成准确的三元组，为时空推理和协作决策提供基础。", "conclusion": "CARMA为协作场景中的情境感知提供了结构化且鲁棒的解决方案。"}}
{"id": "2506.20016", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20016", "abs": "https://arxiv.org/abs/2506.20016", "authors": ["Shanika Iroshi Nanayakkara", "Shiva Raj Pokhrel"], "title": "New Insights on Unfolding and Fine-tuning Quantum Federated Learning", "comment": "12 pages, 9 figures, 7 Tables, Submitted to IEEE/ACM journal 2025", "summary": "Client heterogeneity poses significant challenges to the performance of\nQuantum Federated Learning (QFL). To overcome these limitations, we propose a\nnew approach leveraging deep unfolding, which enables clients to autonomously\noptimize hyperparameters, such as learning rates and regularization factors,\nbased on their specific training behavior. This dynamic adaptation mitigates\noverfitting and ensures robust optimization in highly heterogeneous\nenvironments where standard aggregation methods often fail. Our framework\nachieves approximately 90% accuracy, significantly outperforming traditional\nmethods, which typically yield around 55% accuracy, as demonstrated through\nreal-time training on IBM quantum hardware and Qiskit Aer simulators. By\ndeveloping self adaptive fine tuning, the proposed method proves particularly\neffective in critical applications such as gene expression analysis and cancer\ndetection, enhancing diagnostic precision and predictive modeling within\nquantum systems. Our results are attributed to convergence-aware, learnable\noptimization steps intrinsic to the deep unfolded framework, which maintains\nthe generalization. Hence, this study addresses the core limitations of\nconventional QFL, streamlining its applicability to any complex challenges such\nas healthcare and genomic research.", "AI": {"tldr": "提出了一种基于深度展开的新方法，解决量子联邦学习中客户端异构性问题，通过动态优化超参数实现90%准确率，显著优于传统方法。", "motivation": "客户端异构性严重影响了量子联邦学习的性能，需要一种能够动态适应不同客户端训练行为的方法。", "method": "利用深度展开技术，使客户端能够自主优化学习率和正则化因子等超参数，动态适应异构环境。", "result": "在IBM量子硬件和Qiskit Aer模拟器上实现约90%的准确率，显著优于传统方法的55%。", "conclusion": "该方法通过自适应的优化步骤解决了传统量子联邦学习的核心限制，适用于医疗和基因组研究等复杂场景。"}}
{"id": "2506.20263", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20263", "abs": "https://arxiv.org/abs/2506.20263", "authors": ["Ning Luo", "Meiyin Hu", "Huan Wan", "Yanyan Yang", "Zhuohang Jiang", "Xin Wei"], "title": "Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification", "comment": null, "summary": "Few-shot fine-grained image classification (FS-FGIC) presents a significant\nchallenge, requiring models to distinguish visually similar subclasses with\nlimited labeled examples. Existing methods have critical limitations:\nmetric-based methods lose spatial information and misalign local features,\nwhile reconstruction-based methods fail to utilize hierarchical feature\ninformation and lack mechanisms to focus on discriminative regions. We propose\nthe Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which\nintegrates dual-layer feature reconstruction with mask-enhanced feature\nprocessing to improve fine-grained classification. HMDRN incorporates a\ndual-layer feature reconstruction and fusion module that leverages\ncomplementary visual information from different network hierarchies. Through\nlearnable fusion weights, the model balances high-level semantic\nrepresentations from the last layer with mid-level structural details from the\npenultimate layer. Additionally, we design a spatial binary mask-enhanced\ntransformer self-reconstruction module that processes query features through\nadaptive thresholding while maintaining complete support features, enhancing\nfocus on discriminative regions while filtering background noise. Extensive\nexperiments on three challenging fine-grained datasets demonstrate that HMDRN\nconsistently outperforms state-of-the-art methods across Conv-4 and ResNet-12\nbackbone architectures. Comprehensive ablation studies validate the\neffectiveness of each proposed component, revealing that dual-layer\nreconstruction enhances inter-class discrimination while mask-enhanced\ntransformation reduces intra-class variations. Visualization results provide\nevidence of HMDRN's superior feature reconstruction capabilities.", "AI": {"tldr": "HMDRN提出了一种结合双层次特征重建和掩码增强的少样本细粒度图像分类方法，显著提升了分类性能。", "motivation": "现有方法在少样本细粒度图像分类中存在空间信息丢失、局部特征错位、层次特征利用不足等问题，HMDRN旨在解决这些局限性。", "method": "HMDRN通过双层次特征重建与融合模块及掩码增强的自重建模块，平衡高层语义与中层结构信息，并增强对判别区域的关注。", "result": "在三个细粒度数据集上，HMDRN优于现有方法，并通过消融实验验证了各模块的有效性。", "conclusion": "HMDRN通过双层次重建和掩码增强，显著提升了细粒度分类性能，减少了类内差异。"}}
{"id": "2506.20376", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20376", "abs": "https://arxiv.org/abs/2506.20376", "authors": ["Lingyun Chen", "Xinrui Zhao", "Marcos P. S. Campanha", "Alexander Wegener", "Abdeldjallil Naceri", "Abdalla Swikir", "Sami Haddadin"], "title": "Enhanced Robotic Navigation in Deformable Environments using Learning from Demonstration and Dynamic Modulation", "comment": "Accepted to IROS 2025", "summary": "This paper presents a novel approach for robot navigation in environments\ncontaining deformable obstacles. By integrating Learning from Demonstration\n(LfD) with Dynamical Systems (DS), we enable adaptive and efficient navigation\nin complex environments where obstacles consist of both soft and hard regions.\nWe introduce a dynamic modulation matrix within the DS framework, allowing the\nsystem to distinguish between traversable soft regions and impassable hard\nareas in real-time, ensuring safe and flexible trajectory planning. We validate\nour method through extensive simulations and robot experiments, demonstrating\nits ability to navigate deformable environments. Additionally, the approach\nprovides control over both trajectory and velocity when interacting with\ndeformable objects, including at intersections, while maintaining adherence to\nthe original DS trajectory and dynamically adapting to obstacles for smooth and\nreliable navigation.", "AI": {"tldr": "提出了一种结合学习演示（LfD）和动态系统（DS）的新方法，用于机器人在包含可变形障碍物的环境中导航。", "motivation": "解决机器人在复杂环境中导航时，区分可变形和不可变形障碍物的需求，以实现安全灵活的轨迹规划。", "method": "在DS框架中引入动态调制矩阵，实时区分可变形和不可变形区域，并结合LfD进行自适应导航。", "result": "通过仿真和机器人实验验证了方法的有效性，能够灵活导航并控制轨迹和速度。", "conclusion": "该方法在可变形环境中实现了安全、可靠的导航，同时保持了动态适应性和轨迹一致性。"}}
{"id": "2506.20023", "categories": ["cs.LG", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.20023", "abs": "https://arxiv.org/abs/2506.20023", "authors": ["Ryan Hildebrant", "Rahul Bhope", "Sharad Mehrotra", "Christopher Tull", "Nalini Venkatasubramanian"], "title": "DIM-SUM: Dynamic IMputation for Smart Utility Management", "comment": null, "summary": "Time series imputation models have traditionally been developed using\ncomplete datasets with artificial masking patterns to simulate missing values.\nHowever, in real-world infrastructure monitoring, practitioners often encounter\ndatasets where large amounts of data are missing and follow complex,\nheterogeneous patterns. We introduce DIM-SUM, a preprocessing framework for\ntraining robust imputation models that bridges the gap between artificially\nmasked training data and real missing patterns. DIM-SUM combines pattern\nclustering and adaptive masking strategies with theoretical learning guarantees\nto handle diverse missing patterns actually observed in the data. Through\nextensive experiments on over 2 billion readings from California water\ndistricts, electricity datasets, and benchmarks, we demonstrate that DIM-SUM\noutperforms traditional methods by reaching similar accuracy with lower\nprocessing time and significantly less training data. When compared against a\nlarge pre-trained model, DIM-SUM averages 2x higher accuracy with significantly\nless inference time.", "AI": {"tldr": "DIM-SUM是一个预处理框架，通过模式聚类和自适应掩码策略，有效处理真实缺失数据模式，提升时间序列插值模型的鲁棒性和效率。", "motivation": "传统时间序列插值模型使用人工掩码模拟缺失数据，无法应对现实世界中复杂、异构的缺失模式。", "method": "结合模式聚类和自适应掩码策略，并提供理论学习保证，以处理真实数据中的多样化缺失模式。", "result": "在加州水务、电力数据集和基准测试中，DIM-SUM性能优于传统方法，达到相似精度但处理时间和训练数据更少；与大型预训练模型相比，精度提高2倍且推理时间显著减少。", "conclusion": "DIM-SUM能有效弥合人工掩码训练数据与真实缺失模式之间的差距，为实际应用提供高效解决方案。"}}
{"id": "2506.20272", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20272", "abs": "https://arxiv.org/abs/2506.20272", "authors": ["Juan José Murillo-Fuentes", "Pablo M. Olmos", "Laura Alba-Carcelén"], "title": "Forensic Study of Paintings Through the Comparison of Fabrics", "comment": null, "summary": "The study of canvas fabrics in works of art is a crucial tool for\nauthentication, attribution and conservation. Traditional methods are based on\nthread density map matching, which cannot be applied when canvases do not come\nfrom contiguous positions on a roll. This paper presents a novel approach based\non deep learning to assess the similarity of textiles. We introduce an\nautomatic tool that evaluates the similarity between canvases without relying\non thread density maps. A Siamese deep learning model is designed and trained\nto compare pairs of images by exploiting the feature representations learned\nfrom the scans. In addition, a similarity estimation method is proposed,\naggregating predictions from multiple pairs of cloth samples to provide a\nrobust similarity score. Our approach is applied to canvases from the Museo\nNacional del Prado, corroborating the hypothesis that plain weave canvases,\nwidely used in painting, can be effectively compared even when their thread\ndensities are similar. The results demonstrate the feasibility and accuracy of\nthe proposed method, opening new avenues for the analysis of masterpieces.", "AI": {"tldr": "提出了一种基于深度学习的纺织品相似性评估方法，用于艺术品中画布的鉴定与保护。", "motivation": "传统方法依赖线密度图匹配，无法适用于不连续的画布。", "method": "设计并训练了一个Siamese深度学习模型，通过图像对比较特征表示，并提出相似性估计方法。", "result": "在Museo Nacional del Prado的画布上验证了方法的可行性和准确性。", "conclusion": "该方法为艺术品分析提供了新途径。"}}
{"id": "2506.20394", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20394", "abs": "https://arxiv.org/abs/2506.20394", "authors": ["Mimo Shirasaka", "Yuya Ikeda", "Tatsuya Matsushima", "Yutaka Matsuo", "Yusuke Iwasawa"], "title": "SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning", "comment": null, "summary": "The ability to update information acquired through various means online\nduring task execution is crucial for a general-purpose service robot. This\ninformation includes geometric and semantic data. While SLAM handles geometric\nupdates on 2D maps or 3D point clouds, online updates of semantic information\nremain unexplored. We attribute the challenge to the online scene graph\nrepresentation, for its utility and scalability. Building on previous works\nregarding offline scene graph representations, we study online graph\nrepresentations of semantic information in this work. We introduce SPARK:\nSpatial Perception and Robot Knowledge Integration. This framework extracts\nsemantic information from environment-embedded cues and updates the scene graph\naccordingly, which is then used for subsequent task planning. We demonstrate\nthat graph representations of spatial relationships enhance the robot system's\nability to perform tasks in dynamic environments and adapt to unconventional\nspatial cues, like gestures.", "AI": {"tldr": "论文提出SPARK框架，用于在线更新语义信息并整合到场景图中，以提升机器人在动态环境中的任务执行能力。", "motivation": "通用服务机器人需要在线更新几何和语义信息，但语义信息的在线更新尚未充分研究。", "method": "基于离线场景图表示，提出SPARK框架，从环境线索中提取语义信息并更新场景图。", "result": "SPARK框架能增强机器人在动态环境中的任务执行能力，适应非常规空间线索（如手势）。", "conclusion": "在线语义信息更新和场景图表示对机器人任务规划至关重要。"}}
{"id": "2506.20024", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.20024", "abs": "https://arxiv.org/abs/2506.20024", "authors": ["Salva Rühling Cachay", "Miika Aittala", "Karsten Kreis", "Noah Brenowitz", "Arash Vahdat", "Morteza Mardani", "Rose Yu"], "title": "Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting", "comment": null, "summary": "Diffusion models are a powerful tool for probabilistic forecasting, yet most\napplications in high-dimensional chaotic systems predict future snapshots\none-by-one. This common approach struggles to model complex temporal\ndependencies and fails to explicitly account for the progressive growth of\nuncertainty inherent to such systems. While rolling diffusion frameworks, which\napply increasing noise to forecasts at longer lead times, have been proposed to\naddress this, their integration with state-of-the-art, high-fidelity diffusion\ntechniques remains a significant challenge. We tackle this problem by\nintroducing Elucidated Rolling Diffusion Models (ERDM), the first framework to\nsuccessfully unify a rolling forecast structure with the principled, performant\ndesign of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM\ncomponents-its noise schedule, network preconditioning, and Heun sampler-to the\nrolling forecast setting. The success of this integration is driven by three\nkey contributions: (i) a novel loss weighting scheme that focuses model\ncapacity on the mid-range forecast horizons where determinism gives way to\nstochasticity; (ii) an efficient initialization strategy using a pre-trained\nEDM for the initial window; and (iii) a bespoke hybrid sequence architecture\nfor robust spatiotemporal feature extraction under progressive denoising. On 2D\nNavier-Stokes simulations and ERA5 global weather forecasting at 1.5^\\circ\nresolution, ERDM consistently outperforms key diffusion-based baselines,\nincluding conditional autoregressive EDM. ERDM offers a flexible and powerful\ngeneral framework for tackling diffusion-based sequence generation problems\nwhere modeling escalating uncertainty is paramount. Code is available at:\nhttps://github.com/salvaRC/erdm", "AI": {"tldr": "ERDM框架将滚动预测结构与高性能扩散模型结合，解决了高维混沌系统中时间依赖性和不确定性增长的问题。", "motivation": "现有扩散模型在高维混沌系统中难以建模复杂时间依赖性和不确定性增长，滚动扩散框架与高性能扩散技术的结合仍具挑战性。", "method": "提出ERDM框架，结合EDM的核心组件（噪声调度、网络预处理、Heun采样器），并引入新的损失加权方案、预训练初始化策略和混合序列架构。", "result": "在2D Navier-Stokes模拟和ERA5全球天气预报中，ERDM表现优于基线扩散模型。", "conclusion": "ERDM为扩散模型序列生成问题提供了灵活且强大的通用框架，尤其适用于不确定性增长显著的场景。"}}
{"id": "2506.20279", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20279", "abs": "https://arxiv.org/abs/2506.20279", "authors": ["Changliang Xia", "Chengyou Jia", "Zhuohang Dang", "Minnan Luo"], "title": "From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios", "comment": null, "summary": "Dense prediction tasks hold significant importance of computer vision, aiming\nto learn pixel-wise annotated label for an input image. Despite advances in\nthis field, existing methods primarily focus on idealized conditions, with\nlimited generalization to real-world scenarios and facing the challenging\nscarcity of real-world data. To systematically study this problem, we first\nintroduce DenseWorld, a benchmark spanning a broad set of 25 dense prediction\ntasks that correspond to urgent real-world applications, featuring unified\nevaluation across tasks. Then, we propose DenseDiT, which maximally exploits\ngenerative models' visual priors to perform diverse real-world dense prediction\ntasks through a unified strategy. DenseDiT combines a parameter-reuse mechanism\nand two lightweight branches that adaptively integrate multi-scale context,\nworking with less than 0.1% additional parameters. Evaluations on DenseWorld\nreveal significant performance drops in existing general and specialized\nbaselines, highlighting their limited real-world generalization. In contrast,\nDenseDiT achieves superior results using less than 0.01% training data of\nbaselines, underscoring its practical value for real-world deployment. Our\ndata, and checkpoints and codes are available at\nhttps://xcltql666.github.io/DenseDiTProj", "AI": {"tldr": "论文提出了DenseWorld基准和DenseDiT方法，用于解决密集预测任务在真实场景中的泛化问题。", "motivation": "现有密集预测方法在理想条件下表现良好，但在真实场景中泛化能力有限且数据稀缺。", "method": "提出DenseDiT，利用生成模型的视觉先验，通过参数复用和轻量级分支实现多尺度上下文自适应集成。", "result": "在DenseWorld基准上，现有方法表现不佳，而DenseDiT仅需0.01%的训练数据即取得优越结果。", "conclusion": "DenseDiT在真实场景中具有显著实用价值，且资源高效。"}}
{"id": "2506.20399", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20399", "abs": "https://arxiv.org/abs/2506.20399", "authors": ["Hatem Fakhruldeen", "Arvind Raveendran Nambiar", "Satheeshkumar Veeramani", "Bonilkumar Vijaykumar Tailor", "Hadi Beyzaee Juneghani", "Gabriella Pizzuto", "Andrew Ian Cooper"], "title": "Multimodal Behaviour Trees for Robotic Laboratory Task Automation", "comment": "7 pages, 5 figures, accepted and presented in ICRA 2025", "summary": "Laboratory robotics offer the capability to conduct experiments with a high\ndegree of precision and reproducibility, with the potential to transform\nscientific research. Trivial and repeatable tasks; e.g., sample transportation\nfor analysis and vial capping are well-suited for robots; if done successfully\nand reliably, chemists could contribute their efforts towards more critical\nresearch activities. Currently, robots can perform these tasks faster than\nchemists, but how reliable are they? Improper capping could result in human\nexposure to toxic chemicals which could be fatal. To ensure that robots perform\nthese tasks as accurately as humans, sensory feedback is required to assess the\nprogress of task execution. To address this, we propose a novel methodology\nbased on behaviour trees with multimodal perception. Along with automating\nrobotic tasks, this methodology also verifies the successful execution of the\ntask, a fundamental requirement in safety-critical environments. The\nexperimental evaluation was conducted on two lab tasks: sample vial capping and\nlaboratory rack insertion. The results show high success rate, i.e., 88% for\ncapping and 92% for insertion, along with strong error detection capabilities.\nThis ultimately proves the robustness and reliability of our approach and that\nusing multimodal behaviour trees should pave the way towards the next\ngeneration of robotic chemists.", "AI": {"tldr": "论文提出了一种基于行为树和多模态感知的新方法，用于提高实验室机器人在执行任务（如样品瓶封盖和实验室架插入）时的可靠性和安全性。实验结果显示高成功率和强错误检测能力。", "motivation": "实验室机器人虽然能高效完成重复性任务，但其可靠性问题可能导致安全隐患（如毒物泄漏）。需要一种方法确保任务执行的准确性。", "method": "采用行为树结合多模态感知的方法，自动化任务执行并验证其成功完成。", "result": "实验显示样品瓶封盖成功率为88%，实验室架插入成功率为92%，且具备强错误检测能力。", "conclusion": "该方法证明了其鲁棒性和可靠性，为下一代机器人化学家的研发奠定了基础。"}}
{"id": "2506.20025", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.20025", "abs": "https://arxiv.org/abs/2506.20025", "authors": ["Nathan Stromberg", "Christos Thrampoulidis", "Lalitha Sankar"], "title": "Thumb on the Scale: Optimal Loss Weighting in Last Layer Retraining", "comment": null, "summary": "While machine learning models become more capable in discriminative tasks at\nscale, their ability to overcome biases introduced by training data has come\nunder increasing scrutiny. Previous results suggest that there are two extremes\nof parameterization with very different behaviors: the population\n(underparameterized) setting where loss weighting is optimal and the separable\noverparameterized setting where loss weighting is ineffective at ensuring equal\nperformance across classes. This work explores the regime of last layer\nretraining (LLR) in which the unseen limited (retraining) data is frequently\ninseparable and the model proportionately sized, falling between the two\naforementioned extremes. We show, in theory and practice, that loss weighting\nis still effective in this regime, but that these weights \\emph{must} take into\naccount the relative overparameterization of the model.", "AI": {"tldr": "论文探讨了在中间参数化情况下损失加权对模型性能的影响，发现其仍有效但需考虑模型的相对过参数化。", "motivation": "研究机器学习模型在训练数据偏差下的表现，特别是在中间参数化情况下损失加权的有效性。", "method": "通过理论和实践分析，研究了最后一层重训练（LLR）机制中损失加权的作用。", "result": "发现损失加权在中间参数化情况下仍然有效，但需考虑模型的相对过参数化。", "conclusion": "损失加权在中间参数化情况下仍是一种有效策略，但需调整以考虑模型的具体参数化程度。"}}
{"id": "2506.20293", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.20293", "abs": "https://arxiv.org/abs/2506.20293", "authors": ["Kunjing Yang", "Libin Zheng", "Minru Bai", "Ting Lu", "Leyuan Fang"], "title": "Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion", "comment": null, "summary": "The blind fusion of unregistered hyperspectral images (HSIs) and\nmultispectral images (MSIs) has attracted growing attention recently. To\naddress the registration challenge, most existing methods employ spatial\ntransformations on the HSI to achieve alignment with the MSI. However, due to\nthe substantial differences in spatial resolution of the images, the\nperformance of these methods is often unsatisfactory. Moreover, the\nregistration process tends to be time-consuming when dealing with large-sized\nimages in remote sensing. To address these issues, we propose tackling the\nregistration problem from the spectral domain. Initially, a lightweight\nSpectral Prior Learning (SPL) network is developed to extract spectral features\nfrom the HSI and enhance the spectral resolution of the MSI. Following this,\nthe obtained image undergoes spatial downsampling to produce the registered\nHSI. In this process, subspace representation and cyclic training strategy are\nemployed to improve spectral accuracy of the registered HSI obtained. Next, we\npropose a blind sparse fusion (BSF) method, which utilizes group sparsity\nregularization to equivalently promote the low-rankness of the image. This\napproach not only circumvents the need for rank estimation, but also reduces\ncomputational complexity. Then, we employ the Proximal Alternating Optimization\n(PAO) algorithm to solve the BSF model, and present its convergence analysis.\nFinally, extensive numerical experiments on simulated and real datasets are\nconducted to verify the effectiveness of our method in registration and fusion.\nWe also demonstrate its efficacy in enhancing classification performance.", "AI": {"tldr": "提出了一种基于光谱域的未配准高光谱图像（HSI）和多光谱图像（MSI）融合方法，通过轻量级光谱先验学习网络（SPL）和盲稀疏融合（BSF）方法，解决了传统空间变换配准的不足，提高了效率和精度。", "motivation": "现有方法通过空间变换配准HSI和MSI，但由于分辨率差异大，效果不佳且耗时。因此，从光谱域解决配准问题成为新的研究方向。", "method": "1. 开发SPL网络提取HSI光谱特征并增强MSI光谱分辨率；2. 通过子空间表示和循环训练策略提高配准HSI的光谱精度；3. 提出BSF方法，利用群稀疏正则化等效促进图像低秩性；4. 使用PAO算法求解BSF模型。", "result": "实验验证了该方法在配准和融合中的有效性，并展示了其在分类性能提升上的优势。", "conclusion": "该方法从光谱域解决配准问题，显著提高了效率和精度，同时避免了传统方法的计算复杂性。"}}
{"id": "2506.20445", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20445", "abs": "https://arxiv.org/abs/2506.20445", "authors": ["Dongkun Wang", "Junkai Zhao", "Yunfei Teng", "Jieyang Peng", "Wenjing Xue", "Xiaoming Tao"], "title": "Learn to Position -- A Novel Meta Method for Robotic Positioning", "comment": null, "summary": "Absolute positioning accuracy is a vital specification for robots. Achieving\nhigh position precision can be challenging due to the presence of various\nsources of errors. Meanwhile, accurately depicting these errors is difficult\ndue to their stochastic nature. Vision-based methods are commonly integrated to\nguide robotic positioning, but their performance can be highly impacted by\ninevitable occlusions or adverse lighting conditions. Drawing on the\naforementioned considerations, a vision-free, model-agnostic meta-method for\ncompensating robotic position errors is proposed, which maximizes the\nprobability of accurate robotic position via interactive feedback. Meanwhile,\nthe proposed method endows the robot with the capability to learn and adapt to\nvarious position errors, which is inspired by the human's instinct for grasping\nunder uncertainties. Furthermore, it is a self-learning and self-adaptive\nmethod able to accelerate the robotic positioning process as more examples are\nincorporated and learned. Empirical studies validate the effectiveness of the\nproposed method. As of the writing of this paper, the proposed meta search\nmethod has already been implemented in a robotic-based assembly line for\nodd-form electronic components.", "AI": {"tldr": "提出了一种无需视觉、模型无关的元方法，通过交互反馈补偿机器人定位误差，提高定位精度，并具备学习和适应能力。", "motivation": "机器人绝对定位精度至关重要，但误差来源复杂且随机，视觉方法易受遮挡或光照影响，需更鲁棒的解决方案。", "method": "采用基于交互反馈的元方法，无需依赖视觉，具备自学习和自适应能力，可加速定位过程。", "result": "实证研究验证了方法的有效性，已在电子元件装配线中实现应用。", "conclusion": "该方法显著提升了机器人定位精度，具备适应性和学习能力，适用于复杂环境。"}}
{"id": "2506.20031", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20031", "abs": "https://arxiv.org/abs/2506.20031", "authors": ["Prithvi Poddar", "Ehsan Tarkesh Esfahani", "Karthik Dantu", "Souma Chowdhury"], "title": "Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning", "comment": null, "summary": "Operations in disaster response, search \\& rescue, and military missions that\ninvolve multiple agents demand automated processes to support the planning of\nthe courses of action (COA). Moreover, traverse-affecting changes in the\nenvironment (rain, snow, blockades, etc.) may impact the expected performance\nof a COA, making it desirable to have a pool of COAs that are diverse in task\ndistributions across agents. Further, variations in agent capabilities, which\ncould be human crews and/or autonomous systems, present practical opportunities\nand computational challenges to the planning process. This paper presents a new\ntheoretical formulation and computational framework to generate such diverse\npools of COAs for operations with soft variations in agent-task compatibility.\nKey to the problem formulation is a graph abstraction of the task space and the\npool of COAs itself to quantify its diversity. Formulating the COAs as a\ncentralized multi-robot task allocation problem, a genetic algorithm is used\nfor (order-ignoring) allocations of tasks to each agent that jointly maximize\ndiversity within the COA pool and overall compatibility of the agent-task\nmappings. A graph neural network is trained using a policy gradient approach to\nthen perform single agent task sequencing in each COA, which maximizes\ncompletion rates adaptive to task features. Our tests of the COA generation\nprocess in a simulated environment demonstrate significant performance gain\nover a random walk baseline, small optimality gap in task sequencing, and\nexecution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 task\noperations.", "AI": {"tldr": "提出了一种生成多样化行动方案（COA）的理论框架和计算方法，用于多代理任务分配，结合遗传算法和图神经网络优化任务分配和序列。", "motivation": "多代理任务（如灾害响应、军事任务）需要多样化的行动方案以适应环境变化和代理能力差异。", "method": "使用图抽象表示任务空间和COA池，遗传算法优化任务分配，图神经网络优化任务序列。", "result": "模拟测试显示性能显著优于随机基线，任务序列接近最优，20个COA规划时间约50分钟。", "conclusion": "框架有效生成多样化COA，适用于复杂多代理任务场景。"}}
{"id": "2506.20294", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20294", "abs": "https://arxiv.org/abs/2506.20294", "authors": ["Shunqi Mao", "Wei Guo", "Chaoyi Zhang", "Weidong Cai"], "title": "Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations", "comment": "10 pages, 3 figures, 2 tables", "summary": "Diffusion models have shown strong performance in conditional generation by\nprogressively denoising Gaussian noise toward a target data distribution. This\ndenoising process can be interpreted as a form of hill climbing in a learned\nlatent space, where the model iteratively refines the sample toward regions of\nhigher probability. However, diffusion models often converge to local optima\nthat are locally visually coherent yet globally inconsistent or conditionally\nmisaligned, due to latent space complexity and suboptimal initialization. Prior\nefforts attempted to address this by strengthening guidance signals or\nmanipulating the initial noise distribution. We introduce Controlled Random\nZigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy designed to detect\nand escape such local maxima during conditional generation. The method first\nidentifies potential local maxima using a reward model. Upon detection, it\ninjects noise and reverts to a previous, noisier state to escape the current\noptimization plateau. The reward model then evaluates candidate trajectories,\naccepting only those that offer improvement, while progressively deeper retreat\nenables stronger escapes when nearby alternatives fail. This controlled random\nzigzag process allows dynamic alternation between forward refinement and\nbackward exploration, enhancing both alignment and visual quality in the\ngenerated outputs. The proposed Ctrl-Z Sampling is model-agnostic and\ncompatible with existing diffusion frameworks. Experimental results show that\nCtrl-Z Sampling substantially improves generation quality with only around 7.6X\nincrease in function evaluations.", "AI": {"tldr": "提出了一种名为Ctrl-Z Sampling的新采样策略，用于在条件生成中检测和逃离局部最优解，提升生成质量。", "motivation": "扩散模型在条件生成中容易陷入局部最优解，导致全局不一致或条件不匹配。现有方法通过强化指导信号或调整初始噪声分布来缓解，但效果有限。", "method": "Ctrl-Z Sampling通过奖励模型识别局部最优解，注入噪声并回退到更早状态以逃离，动态交替前向优化和后向探索。", "result": "实验表明，Ctrl-Z Sampling显著提升了生成质量，仅增加约7.6倍的函数评估次数。", "conclusion": "Ctrl-Z Sampling是一种模型无关的方法，可有效提升扩散模型的生成质量。"}}
{"id": "2506.20447", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20447", "abs": "https://arxiv.org/abs/2506.20447", "authors": ["James Fant-Male", "Roel Pieters"], "title": "A Review of Personalisation in Human-Robot Collaboration and Future Perspectives Towards Industry 5.0", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "The shift in research focus from Industry 4.0 to Industry 5.0 (I5.0) promises\na human-centric workplace, with social and well-being values at the centre of\ntechnological implementation. Human-Robot Collaboration (HRC) is a core aspect\nof I5.0 development, with an increase in adaptive and personalised interactions\nand behaviours. This review investigates recent advancements towards\npersonalised HRC, where user-centric adaption is key. There is a growing trend\nfor adaptable HRC research, however there lacks a consistent and unified\napproach. The review highlights key research trends on which personal factors\nare considered, workcell and interaction design, and adaptive task completion.\nThis raises various key considerations for future developments, particularly\naround the ethical and regulatory development of personalised systems, which\nare discussed in detail.", "AI": {"tldr": "本文综述了从工业4.0到工业5.0的转变，强调以人为中心的工作环境，并探讨了人机协作（HRC）在个性化适应方面的最新进展。", "motivation": "工业5.0的核心是实现以人为中心的技术应用，关注社会福祉和个性化交互，但目前缺乏统一的研究方法。", "method": "通过综述近期研究，分析个性化HRC的关键趋势，包括个人因素、工作单元设计、交互设计及自适应任务完成。", "result": "研究发现个性化HRC的研究趋势增长，但缺乏一致性，并提出了未来发展的伦理和监管问题。", "conclusion": "未来的个性化HRC发展需关注伦理和监管框架，以确保技术的人本主义实现。"}}
{"id": "2506.20037", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20037", "abs": "https://arxiv.org/abs/2506.20037", "authors": ["Mohammad M Maheri", "Alex Davidson", "Hamed Haddadi"], "title": "Verifiable Unlearning on Edge", "comment": "This paper has been accepted to the IEEE European Symposium on\n  Security and Privacy (EuroS&P) 2025", "summary": "Machine learning providers commonly distribute global models to edge devices,\nwhich subsequently personalize these models using local data. However, issues\nsuch as copyright infringements, biases, or regulatory requirements may require\nthe verifiable removal of certain data samples across all edge devices.\nEnsuring that edge devices correctly execute such unlearning operations is\ncritical to maintaining integrity.\n  In this work, we introduce a verification framework leveraging zero-knowledge\nproofs, specifically zk-SNARKs, to confirm data unlearning on personalized\nedge-device models without compromising privacy. We have developed algorithms\nexplicitly designed to facilitate unlearning operations that are compatible\nwith efficient zk-SNARK proof generation, ensuring minimal computational and\nmemory overhead suitable for constrained edge environments. Furthermore, our\napproach carefully preserves personalized enhancements on edge devices,\nmaintaining model performance post-unlearning.\n  Our results affirm the practicality and effectiveness of this verification\nframework, demonstrating verifiable unlearning with minimal degradation in\npersonalization-induced performance improvements. Our methodology ensures\nverifiable, privacy-preserving, and effective machine unlearning across edge\ndevices.", "AI": {"tldr": "论文提出了一种基于零知识证明（zk-SNARKs）的验证框架，用于确保边缘设备在个性化模型中正确执行数据遗忘操作，同时保护隐私。", "motivation": "解决边缘设备在个性化模型中执行数据遗忘时可能面临的版权侵权、偏见或监管要求问题，确保操作的完整性和隐私保护。", "method": "开发了与高效zk-SNARK证明生成兼容的数据遗忘算法，适用于资源受限的边缘环境，同时保留个性化增强功能。", "result": "验证了该框架的实用性和有效性，实现了可验证的数据遗忘，且对个性化性能影响极小。", "conclusion": "该方法为边缘设备提供了可验证、隐私保护且高效的数据遗忘解决方案。"}}
{"id": "2506.20302", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20302", "abs": "https://arxiv.org/abs/2506.20302", "authors": ["Abbas Anwar", "Mohammad Shullar", "Ali Arshad Nasir", "Mudassir Masood", "Saeed Anwar"], "title": "TDiR: Transformer based Diffusion for Image Restoration Tasks", "comment": null, "summary": "Images captured in challenging environments often experience various forms of\ndegradation, including noise, color cast, blur, and light scattering. These\neffects significantly reduce image quality, hindering their applicability in\ndownstream tasks such as object detection, mapping, and classification. Our\ntransformer-based diffusion model was developed to address image restoration\ntasks, aiming to improve the quality of degraded images. This model was\nevaluated against existing deep learning methodologies across multiple quality\nmetrics for underwater image enhancement, denoising, and deraining on publicly\navailable datasets. Our findings demonstrate that the diffusion model, combined\nwith transformers, surpasses current methods in performance. The results of our\nmodel highlight the efficacy of diffusion models and transformers in improving\nthe quality of degraded images, consequently expanding their utility in\ndownstream tasks that require high-fidelity visual data.", "AI": {"tldr": "提出了一种基于Transformer的扩散模型，用于图像恢复任务，在多个质量指标上优于现有深度学习方法。", "motivation": "解决图像在恶劣环境下捕获时出现的噪声、色偏、模糊和光散射等问题，提升图像质量以支持下游任务。", "method": "开发了一种结合Transformer的扩散模型，用于图像恢复任务，并在公开数据集上评估其性能。", "result": "该模型在图像增强、去噪和去雨任务中表现优于现有方法。", "conclusion": "扩散模型与Transformer结合能有效提升图像质量，扩展其在高保真视觉数据任务中的应用。"}}
{"id": "2506.20485", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20485", "abs": "https://arxiv.org/abs/2506.20485", "authors": ["Tian Liu", "Han Liu", "Boyang Li", "Long Chen", "Kai Huang"], "title": "EANS: Reducing Energy Consumption for UAV with an Environmental Adaptive Navigation Strategy", "comment": null, "summary": "Unmanned Aerial Vehicles (UAVS) are limited by the onboard energy. Refinement\nof the navigation strategy directly affects both the flight velocity and the\ntrajectory based on the adjustment of key parameters in the UAVS pipeline, thus\nreducing energy consumption. However, existing techniques tend to adopt static\nand conservative strategies in dynamic scenarios, leading to inefficient energy\nreduction. Dynamically adjusting the navigation strategy requires overcoming\nthe challenges including the task pipeline interdependencies, the\nenvironmental-strategy correlations, and the selecting parameters. To solve the\naforementioned problems, this paper proposes a method to dynamically adjust the\nnavigation strategy of the UAVS by analyzing its dynamic characteristics and\nthe temporal characteristics of the autonomous navigation pipeline, thereby\nreducing UAVS energy consumption in response to environmental changes. We\ncompare our method with the baseline through hardware-in-the-loop (HIL)\nsimulation and real-world experiments, showing our method 3.2X and 2.6X\nimprovements in mission time, 2.4X and 1.6X improvements in energy,\nrespectively.", "AI": {"tldr": "该论文提出了一种动态调整无人机导航策略的方法，通过分析其动态特性和时间特性，以减少能耗。实验显示，该方法在任务时间和能耗上均有显著提升。", "motivation": "无人机（UAVS）受限于机载能源，现有导航策略在动态场景中效率低下，需解决任务管道依赖、环境-策略关联和参数选择等挑战。", "method": "提出动态调整导航策略的方法，分析无人机的动态特性和自主导航管道的时间特性，以响应环境变化。", "result": "通过硬件在环（HIL）仿真和真实实验，显示任务时间提升3.2倍和2.6倍，能耗降低2.4倍和1.6倍。", "conclusion": "动态调整导航策略能有效减少无人机能耗，提升任务效率。"}}
{"id": "2506.20040", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20040", "abs": "https://arxiv.org/abs/2506.20040", "authors": ["Ankur Garg", "Xuemin Yu", "Hassan Sajjad", "Samira Ebrahimi Kahou"], "title": "Cross-Layer Discrete Concept Discovery for Interpreting Language Models", "comment": null, "summary": "Uncovering emergent concepts across transformer layers remains a significant\nchallenge because the residual stream linearly mixes and duplicates\ninformation, obscuring how features evolve within large language models.\nCurrent research efforts primarily inspect neural representations at single\nlayers, thereby overlooking this cross-layer superposition and the redundancy\nit introduces. These representations are typically either analyzed directly for\nactivation patterns or passed to probing classifiers that map them to a limited\nset of predefined concepts. To address these limitations, we propose\n\\gls{clvqvae}, a framework that uses vector quantization to map representations\nacross layers and in the process collapse duplicated residual-stream features\ninto compact, interpretable concept vectors. Our approach uniquely combines\ntop-$k$ temperature-based sampling during quantization with EMA codebook\nupdates, providing controlled exploration of the discrete latent space while\nmaintaining code-book diversity. We further enhance the framework with\nscaled-spherical k-means++ for codebook initialization, which clusters by\ndirectional similarity rather than magnitude, better aligning with semantic\nstructure in word embedding space.", "AI": {"tldr": "提出了一种名为CLVQVAE的框架，通过向量量化技术跨层映射神经表示，将冗余特征压缩为紧凑的概念向量，以解决现有方法在分析Transformer层间特征演化时的局限性。", "motivation": "现有研究主要关注单层神经表示，忽略了跨层特征的叠加和冗余，导致对特征演化的理解不足。", "method": "采用向量量化技术，结合top-k温度采样和EMA码本更新，以及基于方向相似性的k-means++初始化，以生成紧凑且可解释的概念向量。", "result": "提出的框架能够有效压缩冗余特征，生成更具语义一致性的概念向量。", "conclusion": "CLVQVAE为跨层特征分析提供了一种新方法，有助于更深入地理解Transformer模型中的特征演化。"}}
{"id": "2506.20306", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20306", "abs": "https://arxiv.org/abs/2506.20306", "authors": ["Yaxi Chen", "Simin Ni", "Shaheer U. Saeed", "Aleksandra Ivanova", "Rikin Hargunani", "Jie Huang", "Chaozong Liu", "Yipeng Hu"], "title": "Radiomic fingerprints for knee MR images assessment", "comment": null, "summary": "Accurate interpretation of knee MRI scans relies on expert clinical judgment,\noften with high variability and limited scalability. Existing radiomic\napproaches use a fixed set of radiomic features (the signature), selected at\nthe population level and applied uniformly to all patients. While\ninterpretable, these signatures are often too constrained to represent\nindividual pathological variations. As a result, conventional radiomic-based\napproaches are found to be limited in performance, compared with recent\nend-to-end deep learning (DL) alternatives without using interpretable radiomic\nfeatures. We argue that the individual-agnostic nature in current radiomic\nselection is not central to its intepretability, but is responsible for the\npoor generalization in our application. Here, we propose a novel radiomic\nfingerprint framework, in which a radiomic feature set (the fingerprint) is\ndynamically constructed for each patient, selected by a DL model. Unlike the\nexisting radiomic signatures, our fingerprints are derived on a per-patient\nbasis by predicting the feature relevance in a large radiomic feature pool, and\nselecting only those that are predictive of clinical conditions for individual\npatients. The radiomic-selecting model is trained simultaneously with a\nlow-dimensional (considered relatively explainable) logistic regression for\ndownstream classification. We validate our methods across multiple diagnostic\ntasks including general knee abnormalities, anterior cruciate ligament (ACL)\ntears, and meniscus tears, demonstrating comparable or superior diagnostic\naccuracy relative to state-of-the-art end-to-end DL models. More importantly,\nwe show that the interpretability inherent in our approach facilitates\nmeaningful clinical insights and potential biomarker discovery, with detailed\ndiscussion, quantitative and qualitative analysis of real-world clinical cases\nto evidence these advantages.", "AI": {"tldr": "提出了一种动态构建放射组学特征的框架（指纹），通过深度学习模型为每位患者选择个性化特征，提升了诊断准确性和可解释性。", "motivation": "现有放射组学方法使用固定特征集，无法充分代表个体病理变化，导致性能受限。本文旨在通过个性化特征选择提升泛化能力和可解释性。", "method": "提出放射组学指纹框架，动态为每位患者选择特征，结合低维逻辑回归进行分类。", "result": "在多种膝关节诊断任务中表现优于或媲美端到端深度学习模型，同时保持了可解释性。", "conclusion": "个性化放射组学特征选择不仅能提升诊断性能，还能提供临床洞见和潜在生物标志物发现。"}}
{"id": "2506.20487", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20487", "abs": "https://arxiv.org/abs/2506.20487", "authors": ["Mingqi Yuan", "Tao Yu", "Wenqi Ge", "Xiuyong Yao", "Dapeng Li", "Huijiang Wang", "Jiayu Chen", "Xin Jin", "Bo Li", "Hua Chen", "Wei Zhang", "Wenjun Zeng"], "title": "Behavior Foundation Model: Towards Next-Generation Whole-Body Control System of Humanoid Robots", "comment": "19 pages, 8 figures", "summary": "Humanoid robots are drawing significant attention as versatile platforms for\ncomplex motor control, human-robot interaction, and general-purpose physical\nintelligence. However, achieving efficient whole-body control (WBC) in\nhumanoids remains a fundamental challenge due to sophisticated dynamics,\nunderactuation, and diverse task requirements. While learning-based controllers\nhave shown promise for complex tasks, their reliance on labor-intensive and\ncostly retraining for new scenarios limits real-world applicability. To address\nthese limitations, behavior(al) foundation models (BFMs) have emerged as a new\nparadigm that leverages large-scale pretraining to learn reusable primitive\nskills and behavioral priors, enabling zero-shot or rapid adaptation to a wide\nrange of downstream tasks. In this paper, we present a comprehensive overview\nof BFMs for humanoid WBC, tracing their development across diverse pre-training\npipelines. Furthermore, we discuss real-world applications, current\nlimitations, urgent challenges, and future opportunities, positioning BFMs as a\nkey approach toward scalable and general-purpose humanoid intelligence.\nFinally, we provide a curated and long-term list of BFM papers and projects to\nfacilitate more subsequent research, which is available at\nhttps://github.com/yuanmingqi/awesome-bfm-papers.", "AI": {"tldr": "本文综述了行为基础模型（BFMs）在人形机器人全身控制（WBC）中的应用，探讨了其发展、应用、局限性和未来机会。", "motivation": "解决人形机器人全身控制中的复杂动态、欠驱动和多样化任务需求问题，减少学习控制器的重复训练成本。", "method": "利用大规模预训练的行为基础模型（BFMs）学习可重用的原始技能和行为先验，支持零样本或快速适应下游任务。", "result": "BFMs为可扩展和通用的人形机器人智能提供了关键方法，并总结了相关论文和项目资源。", "conclusion": "BFMs是人形机器人智能的重要研究方向，未来需解决实际应用中的挑战。"}}
{"id": "2506.20041", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.20041", "abs": "https://arxiv.org/abs/2506.20041", "authors": ["Soheil Abadifard", "Fazli Can"], "title": "LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification", "comment": null, "summary": "The classification of imbalanced data streams, which have unequal class\ndistributions, is a key difficulty in machine learning, especially when dealing\nwith multiple classes. While binary imbalanced data stream classification tasks\nhave received considerable attention, only a few studies have focused on\nmulti-class imbalanced data streams. Effectively managing the dynamic imbalance\nratio is a key challenge in this domain. This study introduces a novel, robust,\nand resilient approach to address these challenges by integrating Locality\nSensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic\nEnsemble Diversification (DynED) framework. To the best of our knowledge, we\npresent the first application of LSH-RHP for undersampling in the context of\nimbalanced non-stationary data streams. The proposed method undersamples the\nmajority classes by utilizing LSH-RHP, provides a balanced training set, and\nimproves the ensemble's prediction performance. We conduct comprehensive\nexperiments on 23 real-world and ten semi-synthetic datasets and compare\nLSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED\noutperforms other approaches in terms of both Kappa and mG-Mean effectiveness\nmeasures, demonstrating its capability in dealing with multi-class imbalanced\nnon-stationary data streams. Notably, LSH-DynED performs well in large-scale,\nhigh-dimensional datasets with considerable class imbalances and demonstrates\nadaptation and robustness in real-world circumstances. To motivate our design,\nwe review existing methods for imbalanced data streams, outline key challenges,\nand offer guidance for future work. For the reproducibility of our results, we\nhave made our implementation available on GitHub.", "AI": {"tldr": "本文提出了一种名为LSH-DynED的新方法，通过结合局部敏感哈希与随机超平面投影（LSH-RHP）和动态集成多样化（DynED）框架，解决了多类别不平衡数据流分类的挑战。该方法通过LSH-RHP对多数类进行欠采样，提供平衡的训练集，并在实验中表现优于15种现有方法。", "motivation": "多类别不平衡数据流的分类问题在机器学习中具有挑战性，尤其是动态不平衡比的处理。现有研究主要集中在二分类问题，而多类别问题研究较少。", "method": "提出LSH-DynED方法，将LSH-RHP集成到DynED框架中，通过欠采样多数类来平衡训练集。", "result": "在23个真实世界和10个半合成数据集上的实验表明，LSH-DynED在Kappa和mG-Mean指标上优于其他15种方法，尤其在大规模、高维数据中表现优异。", "conclusion": "LSH-DynED是一种高效、鲁棒的方法，适用于多类别不平衡非平稳数据流分类，并为未来研究提供了方向。"}}
{"id": "2506.20312", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20312", "abs": "https://arxiv.org/abs/2506.20312", "authors": ["Jiong Wang"], "title": "On the Burstiness of Faces in Set", "comment": "18 pages, 5 figures", "summary": "Burstiness, a phenomenon observed in text and image retrieval, refers to that\nparticular elements appear more times in a set than a statistically independent\nmodel assumes. We argue that in the context of set-based face recognition\n(SFR), burstiness exists widely and degrades the performance in two aspects:\nFirstly, the bursty faces, where faces with particular attributes %exist\nfrequently in a face set, dominate the training instances and dominate the\ntraining face sets and lead to poor generalization ability to unconstrained\nscenarios. Secondly, the bursty faces %dominating the evaluation sets interfere\nwith the similarity comparison in set verification and identification when\nevaluation. To detect the bursty faces in a set, we propose three strategies\nbased on Quickshift++, feature self-similarity, and generalized max-pooling\n(GMP). We apply the burst detection results on training and evaluation stages\nto enhance the sampling ratios or contributions of the infrequent faces. When\nevaluation, we additionally propose the quality-aware GMP that enables\nawareness of the face quality and robustness to the low-quality faces for the\noriginal GMP. We give illustrations and extensive experiments on the SFR\nbenchmarks to demonstrate that burstiness is widespread and suppressing\nburstiness considerably improves the recognition performance.", "AI": {"tldr": "论文研究了集合人脸识别中的突发性现象，提出检测和抑制突发性人脸的方法，显著提升了识别性能。", "motivation": "突发性现象在集合人脸识别中普遍存在，导致训练和评估性能下降，需解决这一问题以提高模型泛化能力。", "method": "提出基于Quickshift++、特征自相似性和广义最大池化的三种策略检测突发性人脸，并在训练和评估阶段调整采样比例或贡献。", "result": "实验证明突发性现象广泛存在，抑制突发性显著提升了识别性能。", "conclusion": "通过检测和抑制突发性人脸，有效提升了集合人脸识别的性能。"}}
{"id": "2506.20496", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20496", "abs": "https://arxiv.org/abs/2506.20496", "authors": ["Jonathan Wang", "Hisashi Ishida", "David Usevitch", "Kesavan Venkatesh", "Yi Wang", "Mehran Armand", "Rachel Bronheim", "Amit Jain", "Adnan Munawar"], "title": "Critical Anatomy-Preserving & Terrain-Augmenting Navigation (CAPTAiN): Application to Laminectomy Surgical Education", "comment": null, "summary": "Surgical training remains a crucial milestone in modern medicine, with\nprocedures such as laminectomy exemplifying the high risks involved.\nLaminectomy drilling requires precise manual control to mill bony tissue while\npreserving spinal segment integrity and avoiding breaches in the dura: the\nprotective membrane surrounding the spinal cord. Despite unintended tears\noccurring in up to 11.3% of cases, no assistive tools are currently utilized to\nreduce this risk. Variability in patient anatomy further complicates learning\nfor novice surgeons. This study introduces CAPTAiN, a critical\nanatomy-preserving and terrain-augmenting navigation system that provides\nlayered, color-coded voxel guidance to enhance anatomical awareness during\nspinal drilling. CAPTAiN was evaluated against a standard non-navigated\napproach through 110 virtual laminectomies performed by 11 orthopedic residents\nand medical students. CAPTAiN significantly improved surgical completion rates\nof target anatomy (87.99% vs. 74.42%) and reduced cognitive load across\nmultiple NASA-TLX domains. It also minimized performance gaps across experience\nlevels, enabling novices to perform on par with advanced trainees. These\nfindings highlight CAPTAiN's potential to optimize surgical execution and\nsupport skill development across experience levels. Beyond laminectomy, it\ndemonstrates potential for broader applications across various surgical and\ndrilling procedures, including those in neurosurgery, otolaryngology, and other\nmedical fields.", "AI": {"tldr": "CAPTAiN系统通过分层彩色体素引导，显著提高了椎板切除术的完成率并降低认知负荷，使新手表现接近高级学员。", "motivation": "椎板切除术风险高，意外撕裂率达11.3%，且缺乏辅助工具，患者解剖结构差异进一步增加了学习难度。", "method": "开发CAPTAiN导航系统，通过虚拟椎板切除术评估其效果，比较标准无导航方法。", "result": "CAPTAiN显著提高目标解剖结构完成率（87.99% vs. 74.42%），降低认知负荷，缩小经验差距。", "conclusion": "CAPTAiN有潜力优化手术执行并支持技能发展，适用于多种外科和钻孔手术。"}}
{"id": "2506.20046", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20046", "abs": "https://arxiv.org/abs/2506.20046", "authors": ["Hirad Daneshvar", "Reza Samavi"], "title": "GNN's Uncertainty Quantification using Self-Distillation", "comment": "The paper has been accepted in the International Conference on AI in\n  Healthcare (AIiH) 2025 and will appear in the conference proceedings", "summary": "Graph Neural Networks (GNNs) have shown remarkable performance in the\nhealthcare domain. However, what remained challenging is quantifying the\npredictive uncertainty of GNNs, which is an important aspect of trustworthiness\nin clinical settings. While Bayesian and ensemble methods can be used to\nquantify uncertainty, they are computationally expensive. Additionally, the\ndisagreement metric used by ensemble methods to compute uncertainty cannot\ncapture the diversity of models in an ensemble network. In this paper, we\npropose a novel method, based on knowledge distillation, to quantify GNNs'\nuncertainty more efficiently and with higher precision. We apply\nself-distillation, where the same network serves as both the teacher and\nstudent models, thereby avoiding the need to train several networks\nindependently. To ensure the impact of self-distillation, we develop an\nuncertainty metric that captures the diverse nature of the network by assigning\ndifferent weights to each GNN classifier. We experimentally evaluate the\nprecision, performance, and ability of our approach in distinguishing\nout-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The\nevaluation results demonstrate that the proposed method can effectively capture\nthe predictive uncertainty of the model while having performance similar to\nthat of the MC Dropout and ensemble methods. The code is publicly available at\nhttps://github.com/tailabTMU/UQ_GNN.", "AI": {"tldr": "提出了一种基于知识蒸馏的新方法，用于高效且精确地量化图神经网络（GNN）的预测不确定性，解决了传统贝叶斯和集成方法计算成本高的问题。", "motivation": "在临床环境中，量化GNN的预测不确定性对可信度至关重要，但现有方法（如贝叶斯和集成方法）计算成本高且无法充分捕捉模型多样性。", "method": "采用自蒸馏技术，同一网络同时作为教师和学生模型，避免了独立训练多个网络的需求，并开发了一种新的不确定性度量方法。", "result": "实验结果表明，该方法在MIMIC-IV和Enzymes数据集上能有效捕捉预测不确定性，性能与MC Dropout和集成方法相当。", "conclusion": "提出的方法在计算效率和不确定性量化精度上优于传统方法，适用于临床环境中的GNN应用。"}}
{"id": "2506.20326", "categories": ["cs.CV", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.20326", "abs": "https://arxiv.org/abs/2506.20326", "authors": ["Sergio Torres Aguilar"], "title": "From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents", "comment": null, "summary": "Robust Document Layout Analysis (DLA) is critical for the automated\nprocessing and understanding of historical documents with complex page\norganizations. This paper benchmarks five state-of-the-art object detection\narchitectures on three annotated datasets representing a spectrum of\ncodicological complexity: The e-NDP, a corpus of Parisian medieval registers\n(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval\nand modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated\nbooks of hours (ca.13th-16th centuries). We evaluate two Transformer-based\nmodels (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and\nYOLO-World). Our findings reveal significant performance variations dependent\non model architecture, data set characteristics, and bounding box\nrepresentation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results\n(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on\nthe more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB\nsignificantly outperforms all other models (0.564 and 0.568, respectively).\nThis study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)\nis not a minor refinement but a fundamental requirement for accurately modeling\nthe non-Cartesian nature of historical manuscripts. We conclude that a key\ntrade-off exists between the global context awareness of Transformers, ideal\nfor structured layouts, and the superior generalization of CNN-OBB models for\nvisually diverse and complex documents.", "AI": {"tldr": "论文评估了五种目标检测架构在三个历史文档数据集上的表现，发现Transformer模型在结构化布局中表现优异，而CNN-OBB模型在复杂文档中更具优势。", "motivation": "历史文档布局复杂，自动化处理需要鲁棒的文档布局分析（DLA），因此需要评估不同模型在多样化数据集上的表现。", "method": "比较了两种Transformer模型（Co-DETR、Grounding DINO）和三种YOLO变体（AABB、OBB、YOLO-World）在三个数据集（e-NDP、CATMuS、HORAE）上的性能。", "result": "Co-DETR在e-NDP上表现最佳（0.752 mAP），而YOLOv11x-OBB在更复杂的CATMuS和HORAE上显著优于其他模型（0.564和0.568）。", "conclusion": "Transformer模型适合结构化布局，而CNN-OBB模型更适合复杂文档；OBB是准确建模历史文档非笛卡尔特性的关键。"}}
{"id": "2506.20553", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20553", "abs": "https://arxiv.org/abs/2506.20553", "authors": ["Rachel Luo", "Heng Yang", "Michael Watson", "Apoorva Sharma", "Sushant Veer", "Edward Schmerling", "Marco Pavone"], "title": "Leveraging Correlation Across Test Platforms for Variance-Reduced Metric Estimation", "comment": null, "summary": "Learning-based robotic systems demand rigorous validation to assure reliable\nperformance, but extensive real-world testing is often prohibitively expensive,\nand if conducted may still yield insufficient data for high-confidence\nguarantees. In this work, we introduce a general estimation framework that\nleverages paired data across test platforms, e.g., paired simulation and\nreal-world observations, to achieve better estimates of real-world metrics via\nthe method of control variates. By incorporating cheap and abundant auxiliary\nmeasurements (for example, simulator outputs) as control variates for costly\nreal-world samples, our method provably reduces the variance of Monte Carlo\nestimates and thus requires significantly fewer real-world samples to attain a\nspecified confidence bound on the mean performance. We provide theoretical\nanalysis characterizing the variance and sample-efficiency improvement, and\ndemonstrate empirically in autonomous driving and quadruped robotics settings\nthat our approach achieves high-probability bounds with markedly improved\nsample efficiency. Our technique can lower the real-world testing burden for\nvalidating the performance of the stack, thereby enabling more efficient and\ncost-effective experimental evaluation of robotic systems.", "AI": {"tldr": "提出了一种基于控制变量的通用估计框架，通过利用模拟和现实世界数据的配对，减少蒙特卡洛估计的方差，从而显著降低现实世界测试的样本需求。", "motivation": "学习型机器人系统需要大量验证以确保可靠性，但现实世界测试成本高昂且数据不足。", "method": "利用配对数据（如模拟与现实观测）和控制变量方法，通过廉价辅助测量（如模拟输出）优化现实世界样本的估计。", "result": "理论分析和实验（自动驾驶和四足机器人）表明，该方法显著提高了样本效率，实现了高概率性能边界。", "conclusion": "该技术可降低现实世界测试负担，使机器人系统的实验评估更高效和经济。"}}
{"id": "2506.20057", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20057", "abs": "https://arxiv.org/abs/2506.20057", "authors": ["Peter Bloem"], "title": "Universal pre-training by iterated random computation", "comment": null, "summary": "We investigate the use of randomly generated data for the sake of\npre-training a model. We justify this approach theoretically from the\nperspective of algorithmic complexity, building on recent research that shows\nthat sequence models can be trained to approximate Solomonoff induction. We\nderive similar, but complementary theoretical results. We show empirically that\nsynthetically generated data can be used to pre-train a model before the data\nis seen. We replicate earlier results that models trained this way show\nzero-shot in-context learning across a variety of datasets, and that this\nperformance improves with scale. We extend earlier results to real-world data,\nand show that finetuning a model after pre-training offers faster convergence\nand better generalization.", "AI": {"tldr": "研究使用随机生成数据预训练模型的理论和实证效果，证明其能实现零样本学习和泛化提升。", "motivation": "探索随机生成数据预训练的理论基础，验证其在未见数据上的有效性。", "method": "从算法复杂性角度理论分析，实证验证预训练模型在零样本学习和泛化中的表现。", "result": "预训练模型在多种数据集上实现零样本学习，且性能随规模提升；微调后收敛更快、泛化更好。", "conclusion": "随机生成数据预训练具有理论和实际价值，能提升模型性能。"}}
{"id": "2506.20342", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20342", "abs": "https://arxiv.org/abs/2506.20342", "authors": ["Lei Wang", "Piotr Koniusz"], "title": "Feature Hallucination for Self-supervised Action Recognition", "comment": "Accepted for publication in International Journal of Computer Vision\n  (IJCV)", "summary": "Understanding human actions in videos requires more than raw pixel analysis;\nit relies on high-level semantic reasoning and effective integration of\nmultimodal features. We propose a deep translational action recognition\nframework that enhances recognition accuracy by jointly predicting action\nconcepts and auxiliary features from RGB video frames. At test time,\nhallucination streams infer missing cues, enriching feature representations\nwithout increasing computational overhead. To focus on action-relevant regions\nbeyond raw pixels, we introduce two novel domain-specific descriptors. Object\nDetection Features (ODF) aggregate outputs from multiple object detectors to\ncapture contextual cues, while Saliency Detection Features (SDF) highlight\nspatial and intensity patterns crucial for action recognition. Our framework\nseamlessly integrates these descriptors with auxiliary modalities such as\noptical flow, Improved Dense Trajectories, skeleton data, and audio cues. It\nremains compatible with state-of-the-art architectures, including I3D,\nAssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE\nV2 and InternVideo2. To handle uncertainty in auxiliary features, we\nincorporate aleatoric uncertainty modeling in the hallucination step and\nintroduce a robust loss function to mitigate feature noise. Our multimodal\nself-supervised action recognition framework achieves state-of-the-art\nperformance on multiple benchmarks, including Kinetics-400, Kinetics-600, and\nSomething-Something V2, demonstrating its effectiveness in capturing\nfine-grained action dynamics.", "AI": {"tldr": "提出了一种深度翻译动作识别框架，通过联合预测动作概念和辅助特征提升识别精度，并引入两种领域特定描述符（ODF和SDF）以增强特征表示。", "motivation": "视频中的人类动作理解需要高层次的语义推理和多模态特征的有效整合，而现有方法在特征表示和计算效率上存在不足。", "method": "框架通过幻觉流推断缺失线索，整合对象检测特征（ODF）和显著性检测特征（SDF），并结合多种辅助模态（如光流、骨架数据等），同时采用不确定性建模和鲁棒损失函数。", "result": "在Kinetics-400、Kinetics-600和Something-Something V2等多个基准测试中实现了最先进的性能。", "conclusion": "该框架通过多模态自监督学习有效捕捉细粒度动作动态，展示了其在动作识别任务中的优越性。"}}
{"id": "2506.20566", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20566", "abs": "https://arxiv.org/abs/2506.20566", "authors": ["Zhonghao Shi", "Enyu Zhao", "Nathaniel Dennler", "Jingzhen Wang", "Xinyang Xu", "Kaleen Shrestha", "Mengxue Fu", "Daniel Seita", "Maja Matarić"], "title": "HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction", "comment": "Accepted to the 19th International Symposium on Experimental Robotics\n  (ISER 2025)", "summary": "Real-time human perception is crucial for effective human-robot interaction\n(HRI). Large vision-language models (VLMs) offer promising generalizable\nperceptual capabilities but often suffer from high latency, which negatively\nimpacts user experience and limits VLM applicability in real-world scenarios.\nTo systematically study VLM capabilities in human perception for HRI and\nperformance-latency trade-offs, we introduce HRIBench, a visual\nquestion-answering (VQA) benchmark designed to evaluate VLMs across a diverse\nset of human perceptual tasks critical for HRI. HRIBench covers five key\ndomains: (1) non-verbal cue understanding, (2) verbal instruction\nunderstanding, (3) human-robot object relationship understanding, (4) social\nnavigation, and (5) person identification. To construct HRIBench, we collected\ndata from real-world HRI environments to curate questions for non-verbal cue\nunderstanding, and leveraged publicly available datasets for the remaining four\ndomains. We curated 200 VQA questions for each domain, resulting in a total of\n1000 questions for HRIBench. We then conducted a comprehensive evaluation of\nboth state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench.\nOur results show that, despite their generalizability, current VLMs still\nstruggle with core perceptual capabilities essential for HRI. Moreover, none of\nthe models within our experiments demonstrated a satisfactory\nperformance-latency trade-off suitable for real-time deployment, underscoring\nthe need for future research on developing smaller, low-latency VLMs with\nimproved human perception capabilities. HRIBench and our results can be found\nin this Github repository: https://github.com/interaction-lab/HRIBench.", "AI": {"tldr": "HRIBench是一个用于评估视觉语言模型（VLMs）在人类感知任务中性能和延迟权衡的基准测试，涵盖五个关键领域。研究发现当前VLMs在实时部署中仍存在性能与延迟的不足。", "motivation": "研究实时人类感知在HRI中的重要性，以及VLMs在性能和延迟方面的局限性。", "method": "构建HRIBench基准测试，包含1000个VQA问题，覆盖五个关键领域，并对11种VLMs进行全面评估。", "result": "当前VLMs在核心感知能力上表现不足，且性能和延迟权衡不理想。", "conclusion": "未来需开发更小、低延迟的VLMs以提升实时HRI性能。"}}
{"id": "2506.20061", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20061", "abs": "https://arxiv.org/abs/2506.20061", "authors": ["Zhicheng Zhang", "Ziyan Wang", "Yali Du", "Fei Fang"], "title": "Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models", "comment": "Under Review", "summary": "Developing effective instruction-following policies in reinforcement learning\nremains challenging due to the reliance on extensive human-labeled instruction\ndatasets and the difficulty of learning from sparse rewards. In this paper, we\npropose a novel approach that leverages the capabilities of large language\nmodels (LLMs) to automatically generate open-ended instructions retrospectively\nfrom previously collected agent trajectories. Our core idea is to employ LLMs\nto relabel unsuccessful trajectories by identifying meaningful subtasks the\nagent has implicitly accomplished, thereby enriching the agent's training data\nand substantially alleviating reliance on human annotations. Through this\nopen-ended instruction relabeling, we efficiently learn a unified\ninstruction-following policy capable of handling diverse tasks within a single\npolicy. We empirically evaluate our proposed method in the challenging Craftax\nenvironment, demonstrating clear improvements in sample efficiency, instruction\ncoverage, and overall policy performance compared to state-of-the-art\nbaselines. Our results highlight the effectiveness of utilizing LLM-guided\nopen-ended instruction relabeling to enhance instruction-following\nreinforcement learning.", "AI": {"tldr": "利用大型语言模型（LLM）自动生成开放式指令，通过重新标注失败轨迹来提升强化学习中的指令跟随能力。", "motivation": "解决强化学习中依赖人工标注指令数据集和稀疏奖励学习困难的问题。", "method": "利用LLM从已收集的代理轨迹中生成开放式指令，重新标注失败轨迹以丰富训练数据。", "result": "在Craftax环境中，样本效率、指令覆盖率和策略性能均优于现有基线。", "conclusion": "LLM引导的开放式指令重新标注能有效提升指令跟随强化学习的效果。"}}
{"id": "2506.20370", "categories": ["cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.20370", "abs": "https://arxiv.org/abs/2506.20370", "authors": ["Abdullah All Tanvir", "Xin Zhong"], "title": "InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking", "comment": null, "summary": "This paper introduces a novel deep learning framework for robust image\nzero-watermarking based on distortion-invariant feature learning. As a\nzero-watermarking scheme, our method leaves the original image unaltered and\nlearns a reference signature through optimization in the feature space. The\nproposed framework consists of two key modules. In the first module, a feature\nextractor is trained via noise-adversarial learning to generate representations\nthat are both invariant to distortions and semantically expressive. This is\nachieved by combining adversarial supervision against a distortion\ndiscriminator and a reconstruction constraint to retain image content. In the\nsecond module, we design a learning-based multibit zero-watermarking scheme\nwhere the trained invariant features are projected onto a set of trainable\nreference codes optimized to match a target binary message. Extensive\nexperiments on diverse image datasets and a wide range of distortions show that\nour method achieves state-of-the-art robustness in both feature stability and\nwatermark recovery. Comparative evaluations against existing self-supervised\nand deep watermarking techniques further highlight the superiority of our\nframework in generalization and robustness.", "AI": {"tldr": "提出了一种基于失真不变特征学习的深度学习框架，用于鲁棒图像零水印技术，保持原图不变并通过特征空间优化学习参考签名。", "motivation": "解决传统水印技术对图像内容修改的依赖问题，同时提高对多种失真的鲁棒性。", "method": "框架包含两个模块：1）通过噪声对抗学习训练特征提取器，生成对失真不变且语义丰富的特征；2）设计基于学习的多比特零水印方案，将特征投影到可训练的参考码上以匹配目标二进制消息。", "result": "在多种图像数据集和失真条件下，方法在特征稳定性和水印恢复方面达到最先进的鲁棒性。", "conclusion": "该框架在泛化能力和鲁棒性上优于现有自监督和深度水印技术。"}}
{"id": "2506.20579", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20579", "abs": "https://arxiv.org/abs/2506.20579", "authors": ["Ali Reza Pedram", "Evangelos Psomiadis", "Dipankar Maity", "Panagiotis Tsiotras"], "title": "Communication-Aware Map Compression for Online Path-Planning: A Rate-Distortion Approach", "comment": null, "summary": "This paper addresses the problem of collaborative navigation in an unknown\nenvironment, where two robots, referred to in the sequel as the Seeker and the\nSupporter, traverse the space simultaneously. The Supporter assists the Seeker\nby transmitting a compressed representation of its local map under bandwidth\nconstraints to support the Seeker's path-planning task. We introduce a bit-rate\nmetric based on the expected binary codeword length to quantify communication\ncost. Using this metric, we formulate the compression design problem as a\nrate-distortion optimization problem that determines when to communicate, which\nregions of the map should be included in the compressed representation, and at\nwhat resolution (i.e., quantization level) they should be encoded. Our\nformulation allows different map regions to be encoded at varying quantization\nlevels based on their relevance to the Seeker's path-planning task. We\ndemonstrate that the resulting optimization problem is convex, and admits a\nclosed-form solution known in the information theory literature as reverse\nwater-filling, enabling efficient, low-computation, and real-time\nimplementation. Additionally, we show that the Seeker can infer the compression\ndecisions of the Supporter independently, requiring only the encoded map\ncontent and not the encoding policy itself to be transmitted, thereby reducing\ncommunication overhead. Simulation results indicate that our method effectively\nconstructs compressed, task-relevant map representations, both in content and\nresolution, that guide the Seeker's planning decisions even under tight\nbandwidth limitations.", "AI": {"tldr": "论文提出了一种在未知环境中协作导航的方法，通过压缩地图表示和优化通信成本来支持路径规划。", "motivation": "解决在带宽限制下，如何高效传输地图信息以支持协作导航的问题。", "method": "引入比特率度量，将压缩设计问题建模为率失真优化问题，采用反向注水法求解。", "result": "仿真结果表明，该方法能在低带宽下生成任务相关的地图压缩表示。", "conclusion": "提出的方法能高效、实时地支持协作导航，减少通信开销。"}}
{"id": "2506.20065", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2506.20065", "abs": "https://arxiv.org/abs/2506.20065", "authors": ["Cristian Minoccheri", "Sophia Tesic", "Kayvan Najarian", "Ryan Stidham"], "title": "Supervised Coupled Matrix-Tensor Factorization (SCMTF) for Computational Phenotyping of Patient Reported Outcomes in Ulcerative Colitis", "comment": null, "summary": "Phenotyping is the process of distinguishing groups of patients to identify\ndifferent types of disease progression. A recent trend employs low-rank matrix\nand tensor factorization methods for their capability of dealing with\nmulti-modal, heterogeneous, and missing data. Symptom quantification is crucial\nfor understanding patient experiences in inflammatory bowel disease, especially\nin conditions such as ulcerative colitis (UC). However, patient-reported\nsymptoms are typically noisy, subjective, and significantly more sparse than\nother data types. For this reason, they are usually not included in phenotyping\nand other machine learning methods. This paper explores the application of\ncomputational phenotyping to leverage Patient-Reported Outcomes (PROs) using a\nnovel supervised coupled matrix-tensor factorization (SCMTF) method, which\nintegrates temporal PROs and temporal labs with static features to predict\nmedication persistence in ulcerative colitis. This is the first tensor-based\nmethod that is both supervised and coupled, it is the first application to the\nUC domain, and the first application to PROs. We use a deep learning framework\nthat makes the model flexible and easy to train. The proposed method allows us\nto handle the large amount of missing data in the PROs. The best model predicts\nchanges in medication 8 and 20 months in the future with AUCs of 0.853 and\n0.803 on the test set respectively. We derive interpretable phenotypes\nconsisting of static features and temporal features (including their temporal\npatterns). We show that low-rank matrix and tensor based phenotyping can be\nsuccessfully applied to the UC domain and to highly missing PRO data. We\nidentify phenotypes useful to predict medication persistence - these phenotypes\ninclude several symptom variables, showing that PROs contain relevant\ninfromation that is usually discarded.", "AI": {"tldr": "论文提出了一种新型的监督耦合矩阵-张量分解（SCMTF）方法，用于整合患者报告结果（PROs）和实验室数据，预测溃疡性结肠炎（UC）患者的药物持续性。该方法首次将张量分解应用于UC领域和PRO数据，并展示了其在处理高缺失数据中的有效性。", "motivation": "患者报告的症状（PROs）通常噪声大、主观性强且数据稀疏，传统方法常忽略这些数据。本文旨在利用PROs数据，通过计算表型分析预测UC患者的药物持续性。", "method": "采用监督耦合矩阵-张量分解（SCMTF）方法，整合时间序列的PROs和实验室数据以及静态特征，结合深度学习框架处理缺失数据。", "result": "最佳模型在测试集上预测8个月和20个月后药物变化的AUC分别为0.853和0.803，并提取了可解释的表型。", "conclusion": "研究表明，低秩矩阵和张量分解方法可成功应用于UC领域和高缺失PRO数据，PROs中包含传统方法忽略的有用信息。"}}
{"id": "2506.20381", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20381", "abs": "https://arxiv.org/abs/2506.20381", "authors": ["Ben Kang", "Xin Chen", "Jie Zhao", "Chunjuan Bo", "Dong Wang", "Huchuan Lu"], "title": "Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking", "comment": "This paper was accepted by International Journal of Computer\n  Vision(IJCV)", "summary": "Transformer-based visual trackers have demonstrated significant advancements\ndue to their powerful modeling capabilities. However, their practicality is\nlimited on resource-constrained devices because of their slow processing\nspeeds. To address this challenge, we present HiT, a novel family of efficient\ntracking models that achieve high performance while maintaining fast operation\nacross various devices. The core innovation of HiT lies in its Bridge Module,\nwhich connects lightweight transformers to the tracking framework, enhancing\nfeature representation quality. Additionally, we introduce a dual-image\nposition encoding approach to effectively encode spatial information. HiT\nachieves an impressive speed of 61 frames per second (fps) on the NVIDIA Jetson\nAGX platform, alongside a competitive AUC of 64.6% on the LaSOT benchmark,\noutperforming all previous efficient trackers.Building on HiT, we propose\nDyHiT, an efficient dynamic tracker that flexibly adapts to scene complexity by\nselecting routes with varying computational requirements. DyHiT uses search\narea features extracted by the backbone network and inputs them into an\nefficient dynamic router to classify tracking scenarios. Based on the\nclassification, DyHiT applies a divide-and-conquer strategy, selecting\nappropriate routes to achieve a superior trade-off between accuracy and speed.\nThe fastest version of DyHiT achieves 111 fps on NVIDIA Jetson AGX while\nmaintaining an AUC of 62.4% on LaSOT.Furthermore, we introduce a training-free\nacceleration method based on the dynamic routing architecture of DyHiT. This\nmethod significantly improves the execution speed of various high-performance\ntrackers without sacrificing accuracy. For instance, our acceleration method\nenables the state-of-the-art tracker SeqTrack-B256 to achieve a 2.68 times\nspeedup on an NVIDIA GeForce RTX 2080 Ti GPU while maintaining the same AUC of\n69.9% on the LaSOT.", "AI": {"tldr": "HiT和DyHiT是高效的视觉跟踪模型，通过Bridge Module和动态路由技术，在保持高性能的同时提升速度，适用于资源受限设备。", "motivation": "解决基于Transformer的视觉跟踪器在资源受限设备上速度慢的问题。", "method": "HiT采用Bridge Module和双图像位置编码；DyHiT通过动态路由分类场景并选择计算路径。", "result": "HiT在NVIDIA Jetson AGX上达61 fps，AUC 64.6%；DyHiT达111 fps，AUC 62.4%。", "conclusion": "HiT和DyHiT在速度和性能上取得平衡，动态路由方法还能加速其他高性能跟踪器。"}}
{"id": "2506.20636", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20636", "abs": "https://arxiv.org/abs/2506.20636", "authors": ["Venkat Karramreddy", "Rangarajan Ramanujam"], "title": "A Computationally Aware Multi Objective Framework for Camera LiDAR Calibration", "comment": "16 pages, 10 figures", "summary": "Accurate extrinsic calibration between LiDAR and camera sensors is important\nfor reliable perception in autonomous systems. In this paper, we present a\nnovel multi-objective optimization framework that jointly minimizes the\ngeometric alignment error and computational cost associated with camera-LiDAR\ncalibration. We optimize two objectives: (1) error between projected LiDAR\npoints and ground-truth image edges, and (2) a composite metric for\ncomputational cost reflecting runtime and resource usage. Using the NSGA-II\n\\cite{deb2002nsga2} evolutionary algorithm, we explore the parameter space\ndefined by 6-DoF transformations and point sampling rates, yielding a\nwell-characterized Pareto frontier that exposes trade-offs between calibration\nfidelity and resource efficiency. Evaluations are conducted on the KITTI\ndataset using its ground-truth extrinsic parameters for validation, with\nresults verified through both multi-objective and constrained single-objective\nbaselines. Compared to existing gradient-based and learned calibration methods,\nour approach demonstrates interpretable, tunable performance with lower\ndeployment overhead. Pareto-optimal configurations are further analyzed for\nparameter sensitivity and innovation insights. A preference-based\ndecision-making strategy selects solutions from the Pareto knee region to suit\nthe constraints of the embedded system. The robustness of calibration is tested\nacross variable edge-intensity weighting schemes, highlighting optimal balance\npoints. Although real-time deployment on embedded platforms is deferred to\nfuture work, this framework establishes a scalable and transparent method for\ncalibration under realistic misalignment and resource-limited conditions,\ncritical for long-term autonomy, particularly in SAE L3+ vehicles receiving OTA\nupdates.", "AI": {"tldr": "提出了一种多目标优化框架，用于联合优化LiDAR与相机的外参校准的几何对齐误差和计算成本。", "motivation": "提高自动驾驶系统中LiDAR与相机校准的可靠性和效率。", "method": "使用NSGA-II进化算法优化6-DoF变换和点采样率，探索校准精度与计算成本的权衡。", "result": "在KITTI数据集上验证，性能优于现有方法，具有可解释性和可调性。", "conclusion": "该框架为资源受限条件下的校准提供了可扩展且透明的方法，适用于长期自动驾驶系统。"}}
{"id": "2506.20090", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20090", "abs": "https://arxiv.org/abs/2506.20090", "authors": ["Ainaz Jamshidi", "Dongchan Kim", "Muhammad Arif"], "title": "A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression", "comment": "13 pages, 7 figures", "summary": "Predictive maintenance (PdM) has become a crucial element of modern\nindustrial practice. PdM plays a significant role in operational dependability\nand cost management by decreasing unforeseen downtime and optimizing asset life\ncycle management. Machine learning and deep learning have enabled more precise\nforecasts of equipment failure and remaining useful life (RUL). Although many\nstudies have been conducted on PdM, there has not yet been a standalone\ncomparative study between regression- and classification-based approaches. In\nthis review, we look across a range of PdM methodologies, while focusing more\nstrongly on the comparative use of classification and regression methods in\nprognostics. While regression-based methods typically provide estimates of RUL,\nclassification-based methods present a forecast of the probability of failure\nacross defined time intervals. Through a comprehensive analysis of recent\nliterature, we highlight key advancements, challenges-such as data imbalance\nand high-dimensional feature spaces-and emerging trends, including hybrid\napproaches and AI-enabled prognostic systems. This review aims to provide\nresearchers and practitioners with an awareness of the strengths and\ncompromises of various PdM methods and to help identify future research and\nbuild more robust, directed adaptive maintenance systems. Future work may\ninclude a systematic review of practical aspects such as public datasets,\nbenchmarking platforms, and open-source tools to support the advancement of PdM\nresearch.", "AI": {"tldr": "本文综述了预测性维护（PdM）中回归与分类方法的比较，强调其在设备故障预测中的优势与挑战，并探讨了未来研究方向。", "motivation": "预测性维护对工业运营至关重要，但缺乏回归与分类方法的系统比较研究，本文旨在填补这一空白。", "method": "通过综合分析近期文献，比较回归（提供剩余使用寿命估计）和分类（预测故障概率）方法在PdM中的应用。", "result": "研究揭示了回归与分类方法的优缺点，以及数据不平衡、高维特征等挑战，同时指出混合方法和AI系统的趋势。", "conclusion": "本文为研究者和从业者提供了PdM方法的全面视角，并建议未来研究关注公开数据集和开源工具的开发。"}}
{"id": "2506.20388", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20388", "abs": "https://arxiv.org/abs/2506.20388", "authors": ["Shen Tan", "Xin Zhang", "Liangxiu Han", "Huaguo Huang", "Han Wang"], "title": "A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management", "comment": null, "summary": "Accurate, cost-effective monitoring of plantation aboveground biomass (AGB)\nis crucial for supporting local livelihoods and carbon sequestration\ninitiatives like the China Certified Emission Reduction (CCER) program.\nHigh-resolution canopy height maps (CHMs) are essential for this, but standard\nlidar-based methods are expensive. While deep learning with RGB imagery offers\nan alternative, accurately extracting canopy height features remains\nchallenging. To address this, we developed a novel model for high-resolution\nCHM generation using a Large Vision Foundation Model (LVFM). Our model\nintegrates a feature extractor, a self-supervised feature enhancement module to\npreserve spatial details, and a height estimator. Tested in Beijing's Fangshan\nDistrict using 1-meter Google Earth imagery, our model outperformed existing\nmethods, including conventional CNNs. It achieved a mean absolute error of 0.09\nm, a root mean square error of 0.24 m, and a correlation of 0.78 against\nlidar-based CHMs. The resulting CHMs enabled over 90% success in individual\ntree detection, high accuracy in AGB estimation, and effective tracking of\nplantation growth, demonstrating strong generalization to non-training areas.\nThis approach presents a promising, scalable tool for evaluating carbon\nsequestration in both plantations and natural forests.", "AI": {"tldr": "提出了一种基于大型视觉基础模型（LVFM）的新方法，用于高分辨率冠层高度图（CHM）生成，以低成本准确监测人工林地上生物量（AGB）。", "motivation": "传统激光雷达方法成本高，而基于RGB图像的深度学习方法难以准确提取冠层高度特征，因此需要一种更高效、低成本的方法。", "method": "开发了一种结合特征提取器、自监督特征增强模块和高度估计器的新模型，使用1米分辨率的Google Earth图像进行测试。", "result": "模型在北京市房山区的测试中表现优于现有方法，平均绝对误差为0.09米，均方根误差为0.24米，与激光雷达CHM的相关系数为0.78。", "conclusion": "该方法为评估碳汇提供了可扩展的工具，适用于人工林和天然林。"}}
{"id": "2506.20668", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20668", "abs": "https://arxiv.org/abs/2506.20668", "authors": ["Sungjae Park", "Homanga Bharadhwaj", "Shubham Tulsiani"], "title": "DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy", "comment": "Preprint(17 pages). Under Review", "summary": "We propose DemoDiffusion, a simple and scalable method for enabling robots to\nperform manipulation tasks in natural environments by imitating a single human\ndemonstration. Our approach is based on two key insights. First, the hand\nmotion in a human demonstration provides a useful prior for the robot's\nend-effector trajectory, which we can convert into a rough open-loop robot\nmotion trajectory via kinematic retargeting. Second, while this retargeted\nmotion captures the overall structure of the task, it may not align well with\nplausible robot actions in-context. To address this, we leverage a pre-trained\ngeneralist diffusion policy to modify the trajectory, ensuring it both follows\nthe human motion and remains within the distribution of plausible robot\nactions. Our approach avoids the need for online reinforcement learning or\npaired human-robot data, enabling robust adaptation to new tasks and scenes\nwith minimal manual effort. Experiments in both simulation and real-world\nsettings show that DemoDiffusion outperforms both the base policy and the\nretargeted trajectory, enabling the robot to succeed even on tasks where the\npre-trained generalist policy fails entirely. Project page:\nhttps://demodiffusion.github.io/", "AI": {"tldr": "DemoDiffusion是一种简单且可扩展的方法，通过模仿单个人类演示使机器人能在自然环境中完成任务。结合运动学重定向和预训练的扩散策略，优化机器人轨迹。", "motivation": "解决机器人模仿人类演示时轨迹不匹配的问题，避免在线强化学习或配对数据的需求。", "method": "1. 通过运动学重定向将人类手部运动转换为机器人轨迹；2. 使用预训练的扩散策略优化轨迹，使其更符合机器人动作分布。", "result": "在仿真和现实实验中，DemoDiffusion优于基础策略和重定向轨迹，能完成预训练策略失败的任务。", "conclusion": "DemoDiffusion通过结合人类演示和扩散策略，实现了高效且鲁棒的机器人任务适应。"}}
{"id": "2506.20094", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20094", "abs": "https://arxiv.org/abs/2506.20094", "authors": ["Krishna Praneet Gudipaty", "Walid A. Hanafy", "Kaan Ozkara", "Qianlin Liang", "Jesse Milzman", "Prashant Shenoy", "Suhas Diggavi"], "title": "MEL: Multi-level Ensemble Learning for Resource-Constrained Environments", "comment": null, "summary": "AI inference at the edge is becoming increasingly common for low-latency\nservices. However, edge environments are power- and resource-constrained, and\nsusceptible to failures. Conventional failure resilience approaches, such as\ncloud failover or compressed backups, often compromise latency or accuracy,\nlimiting their effectiveness for critical edge inference services. In this\npaper, we propose Multi-Level Ensemble Learning (MEL), a new framework for\nresilient edge inference that simultaneously trains multiple lightweight backup\nmodels capable of operating collaboratively, refining each other when multiple\nservers are available, and independently under failures while maintaining good\naccuracy. Specifically, we formulate our approach as a multi-objective\noptimization problem with a loss formulation that inherently encourages\ndiversity among individual models to promote mutually refining representations,\nwhile ensuring each model maintains good standalone performance. Empirical\nevaluations across vision, language, and audio datasets show that MEL provides\nperformance comparable to original architectures while also providing fault\ntolerance and deployment flexibility across edge platforms. Our results show\nthat our ensemble model, sized at 40\\% of the original model, achieves similar\nperformance, while preserving 95.6\\% of ensemble accuracy in the case of\nfailures when trained using MEL.", "AI": {"tldr": "论文提出了一种名为MEL的多级集成学习框架，用于在边缘计算环境中实现低延迟、高准确性的容错推理。", "motivation": "边缘计算环境资源有限且易发生故障，传统容错方法（如云故障转移或压缩备份）通常牺牲延迟或准确性，无法满足关键边缘推理服务的需求。", "method": "MEL通过同时训练多个轻量级备份模型，这些模型能够协作运行或在故障时独立运行，并通过多目标优化问题确保模型多样性和独立性能。", "result": "实验表明，MEL在视觉、语言和音频数据集上表现接近原始架构，同时提供容错能力和部署灵活性。集成模型大小仅为原模型的40%，在故障情况下仍保持95.6%的准确率。", "conclusion": "MEL为边缘推理提供了一种高效、灵活的容错解决方案，平衡了性能与资源限制。"}}
{"id": "2506.20449", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20449", "abs": "https://arxiv.org/abs/2506.20449", "authors": ["Changlu Guo", "Anders Nymark Christensen", "Morten Rieger Hannemose"], "title": "Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation", "comment": "The project is available at \\url{https://medart-ai.github.io}", "summary": "Text-to-image generative models have achieved remarkable breakthroughs in\nrecent years. However, their application in medical image generation still\nfaces significant challenges, including small dataset sizes, and scarcity of\nmedical textual data. To address these challenges, we propose Med-Art, a\nframework specifically designed for medical image generation with limited data.\nMed-Art leverages vision-language models to generate visual descriptions of\nmedical images which overcomes the scarcity of applicable medical textual data.\nMed-Art adapts a large-scale pre-trained text-to-image model, PixArt-$\\alpha$,\nbased on the Diffusion Transformer (DiT), achieving high performance under\nlimited data. Furthermore, we propose an innovative Hybrid-Level Diffusion\nFine-tuning (HLDF) method, which enables pixel-level losses, effectively\naddressing issues such as overly saturated colors. We achieve state-of-the-art\nperformance on two medical image datasets, measured by FID, KID, and downstream\nclassification performance.", "AI": {"tldr": "Med-Art是一个针对有限数据医学图像生成的框架，利用视觉语言模型生成医学图像的视觉描述，并通过改进的扩散模型实现高性能。", "motivation": "医学图像生成面临数据集小和医学文本数据稀缺的挑战，需要一种适应有限数据的解决方案。", "method": "Med-Art结合视觉语言模型和预训练的PixArt-α扩散模型，提出混合级扩散微调（HLDF）方法，解决颜色过饱和等问题。", "result": "在两个医学图像数据集上，Med-Art在FID、KID和下游分类性能上达到最先进水平。", "conclusion": "Med-Art为有限数据下的医学图像生成提供了高效解决方案，具有实际应用潜力。"}}
{"id": "2506.20550", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20550", "abs": "https://arxiv.org/abs/2506.20550", "authors": ["Yitong Quan", "Benjamin Kiefer", "Martin Messmer", "Andreas Zell"], "title": "Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos", "comment": "Submitted to ECMR 2025", "summary": "Modern image-based object detection models, such as YOLOv7, primarily process\nindividual frames independently, thus ignoring valuable temporal context\nnaturally present in videos. Meanwhile, existing video-based detection methods\noften introduce complex temporal modules, significantly increasing model size\nand computational complexity. In practical applications such as surveillance\nand autonomous driving, transient challenges including motion blur, occlusions,\nand abrupt appearance changes can severely degrade single-frame detection\nperformance. To address these issues, we propose a straightforward yet highly\neffective strategy: stacking multiple consecutive frames as input to a\nYOLO-based detector while supervising only the output corresponding to a single\ntarget frame. This approach leverages temporal information with minimal\nmodifications to existing architectures, preserving simplicity, computational\nefficiency, and real-time inference capability. Extensive experiments on the\nchallenging MOT20Det and our BOAT360 datasets demonstrate that our method\nimproves detection robustness, especially for lightweight models, effectively\nnarrowing the gap between compact and heavy detection networks. Additionally,\nwe contribute the BOAT360 benchmark dataset, comprising annotated fisheye video\nsequences captured from a boat, to support future research in multi-frame video\nobject detection in challenging real-world scenarios.", "AI": {"tldr": "提出了一种简单有效的多帧输入策略，利用时间信息提升YOLO检测器在视频中的性能，同时保持轻量化和实时性。", "motivation": "现有单帧检测模型忽略视频中的时间信息，而复杂的时间模块增加计算负担。", "method": "堆叠连续帧作为输入，仅监督目标帧输出，保留YOLO架构的轻量化和实时性。", "result": "在MOT20Det和BOAT360数据集上验证，提升了检测鲁棒性，缩小了轻量与重量级网络的差距。", "conclusion": "方法简单高效，适用于实际场景，并贡献了BOAT360数据集支持未来研究。"}}
{"id": "2506.20132", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20132", "abs": "https://arxiv.org/abs/2506.20132", "authors": ["Patrick Alan Johnson", "Gabriel Tseng", "Yawen Zhang", "Heather Heward", "Virginia Sjahli", "Favyen Bastani", "Joseph Redmon", "Patrick Beukema"], "title": "High-Resolution Live Fuel Moisture Content (LFMC) Maps for Wildfire Risk from Multimodal Earth Observation Data", "comment": "10 pages, ICML 2025 (TerraBytes)", "summary": "Wildfires are increasing in intensity and severity at an alarming rate.\nRecent advances in AI and publicly available satellite data enable monitoring\ncritical wildfire risk factors globally, at high resolution and low latency.\nLive Fuel Moisture Content (LFMC) is a critical wildfire risk factor and is\nvaluable for both wildfire research and operational response. However,\nground-based LFMC samples are both labor intensive and costly to acquire,\nresulting in sparse and infrequent updates. In this work, we explore the use of\na pretrained, highly-multimodal earth-observation model for generating\nlarge-scale spatially complete (wall-to-wall) LFMC maps. Our approach achieves\nsignificant improvements over previous methods using randomly initialized\nmodels (20 reduction in RMSE). We provide an automated pipeline that enables\nrapid generation of these LFMC maps across the United States, and demonstrate\nits effectiveness in two regions recently impacted by wildfire (Eaton and\nPalisades).", "AI": {"tldr": "利用预训练的多模态地球观测模型生成大范围、空间完整的LFMC地图，显著降低RMSE，并开发自动化管道快速生成美国范围内的LFMC地图。", "motivation": "地面LFMC样本采集成本高且更新稀疏，需要高效、低成本的监测方法以支持野火研究和应急响应。", "method": "采用预训练的多模态地球观测模型，生成大范围、空间完整的LFMC地图，并通过自动化管道实现快速更新。", "result": "相比随机初始化模型，RMSE降低20%，并在受野火影响的地区验证了有效性。", "conclusion": "该方法为野火风险监测提供了高效、低成本的解决方案，适用于大范围应用。"}}
{"id": "2506.20452", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20452", "abs": "https://arxiv.org/abs/2506.20452", "authors": ["Tobias Vontobel", "Seyedmorteza Sadat", "Farnood Salehi", "Romann M. Weber"], "title": "HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling", "comment": null, "summary": "Diffusion models have emerged as the leading approach for image synthesis,\ndemonstrating exceptional photorealism and diversity. However, training\ndiffusion models at high resolutions remains computationally prohibitive, and\nexisting zero-shot generation techniques for synthesizing images beyond\ntraining resolutions often produce artifacts, including object duplication and\nspatial incoherence. In this paper, we introduce HiWave, a training-free,\nzero-shot approach that substantially enhances visual fidelity and structural\ncoherence in ultra-high-resolution image synthesis using pretrained diffusion\nmodels. Our method employs a two-stage pipeline: generating a base image from\nthe pretrained model followed by a patch-wise DDIM inversion step and a novel\nwavelet-based detail enhancer module. Specifically, we first utilize inversion\nmethods to derive initial noise vectors that preserve global coherence from the\nbase image. Subsequently, during sampling, our wavelet-domain detail enhancer\nretains low-frequency components from the base image to ensure structural\nconsistency, while selectively guiding high-frequency components to enrich fine\ndetails and textures. Extensive evaluations using Stable Diffusion XL\ndemonstrate that HiWave effectively mitigates common visual artifacts seen in\nprior methods, achieving superior perceptual quality. A user study confirmed\nHiWave's performance, where it was preferred over the state-of-the-art\nalternative in more than 80% of comparisons, highlighting its effectiveness for\nhigh-quality, ultra-high-resolution image synthesis without requiring\nretraining or architectural modifications.", "AI": {"tldr": "HiWave是一种无需训练的零样本方法，通过两阶段流程（基础图像生成和基于小波的细节增强模块）显著提升超高分辨率图像合成的视觉保真度和结构一致性。", "motivation": "解决现有零样本生成技术在超高分辨率图像合成中常见的伪影问题（如物体重复和空间不连贯）。", "method": "1. 使用预训练模型生成基础图像；2. 通过DDIM反演和小波域细节增强模块，保留低频结构并增强高频细节。", "result": "在Stable Diffusion XL上的评估显示，HiWave有效减少了伪影，用户研究中80%以上优于现有方法。", "conclusion": "HiWave无需重新训练或修改架构，即可实现高质量的超高分辨率图像合成。"}}
{"id": "2506.20586", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.20586", "abs": "https://arxiv.org/abs/2506.20586", "authors": ["Yitong Quan", "Benjamin Kiefer", "Martin Messmer", "Andreas Zell"], "title": "Learning-Based Distance Estimation for 360° Single-Sensor Setups", "comment": "Submitted to ECMR 2025", "summary": "Accurate distance estimation is a fundamental challenge in robotic\nperception, particularly in omnidirectional imaging, where traditional\ngeometric methods struggle with lens distortions and environmental variability.\nIn this work, we propose a neural network-based approach for monocular distance\nestimation using a single 360{\\deg} fisheye lens camera. Unlike classical\ntrigonometric techniques that rely on precise lens calibration, our method\ndirectly learns and infers the distance of objects from raw omnidirectional\ninputs, offering greater robustness and adaptability across diverse conditions.\nWe evaluate our approach on three 360{\\deg} datasets (LOAF, ULM360, and a newly\ncaptured dataset Boat360), each representing distinct environmental and sensor\nsetups. Our experimental results demonstrate that the proposed learning-based\nmodel outperforms traditional geometry-based methods and other learning\nbaselines in both accuracy and robustness. These findings highlight the\npotential of deep learning for real-time omnidirectional distance estimation,\nmaking our approach particularly well-suited for low-cost applications in\nrobotics, autonomous navigation, and surveillance.", "AI": {"tldr": "提出一种基于神经网络的单目360度鱼眼相机距离估计方法，优于传统几何方法。", "motivation": "解决全向成像中传统几何方法因镜头畸变和环境变化导致的距离估计不准确问题。", "method": "使用神经网络直接从原始全向输入中学习并推断物体距离，无需精确镜头标定。", "result": "在三个360度数据集上验证，学习模型在准确性和鲁棒性上优于传统几何方法和其他学习基线。", "conclusion": "深度学习在全向距离估计中具有潜力，适用于低成本机器人、自主导航和监控应用。"}}
{"id": "2506.20464", "categories": ["cs.CV", "I.4.9"], "pdf": "https://arxiv.org/pdf/2506.20464", "abs": "https://arxiv.org/abs/2506.20464", "authors": ["Dibyayan Patra", "Pasindu Ranasinghe", "Bikram Banerjee", "Simit Raval"], "title": "A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners", "comment": null, "summary": "Rock bolts are crucial components of the subterranean support systems in\nunderground mines that provide adequate structural reinforcement to the rock\nmass to prevent unforeseen hazards like rockfalls. This makes frequent\nassessments of such bolts critical for maintaining rock mass stability and\nminimising risks in underground mining operations. Where manual surveying of\nrock bolts is challenging due to the low light conditions in the underground\nmines and the time-intensive nature of the process, automated detection of rock\nbolts serves as a plausible solution. To that end, this study focuses on the\nautomatic identification of rock bolts within medium to large-scale 3D point\nclouds obtained from underground mines using mobile laser scanners. Existing\ntechniques for automated rock bolt identification primarily rely on feature\nengineering and traditional machine learning approaches. However, such\ntechniques lack robustness as these point clouds present several challenges due\nto data noise, varying environments, and complex surrounding structures.\nMoreover, the target rock bolts are extremely small objects within large-scale\npoint clouds and are often partially obscured due to the application of\nreinforcement shotcrete. Addressing these challenges, this paper proposes an\napproach termed DeepBolt, which employs a novel two-stage deep learning\narchitecture specifically designed for handling severe class imbalance for the\nautomatic and efficient identification of rock bolts in complex 3D point\nclouds. The proposed method surpasses state-of-the-art semantic segmentation\nmodels by up to 42.5% in Intersection over Union (IoU) for rock bolt points.\nAdditionally, it outperforms existing rock bolt identification techniques,\nachieving a 96.41% precision and 96.96% recall in classifying rock bolts,\ndemonstrating its robustness and effectiveness in complex underground\nenvironments.", "AI": {"tldr": "论文提出了一种名为DeepBolt的两阶段深度学习架构，用于在复杂3D点云中自动高效识别岩锚，解决了传统方法在噪声、环境变化和复杂结构下的不足。", "motivation": "地下矿井中岩锚的频繁评估对维持岩体稳定性和减少风险至关重要，但手动检测因光线不足和耗时性而困难，自动化检测成为必要。", "method": "采用两阶段深度学习架构DeepBolt，专门针对严重类别不平衡问题，优化岩锚在3D点云中的识别。", "result": "DeepBolt在岩锚点交并比（IoU）上比现有语义分割模型提升42.5%，分类精度和召回率分别达到96.41%和96.96%。", "conclusion": "DeepBolt在复杂地下环境中表现出高效性和鲁棒性，为岩锚自动化检测提供了可靠解决方案。"}}
{"id": "2506.20181", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.20181", "abs": "https://arxiv.org/abs/2506.20181", "authors": ["Ronald Katende"], "title": "Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks", "comment": null, "summary": "We develop a principled framework for discovering causal structure in partial\ndifferential equations (PDEs) using physics-informed neural networks and\ncounterfactual perturbations. Unlike classical residual minimization or sparse\nregression methods, our approach quantifies operator-level necessity through\nfunctional interventions on the governing dynamics. We introduce causal\nsensitivity indices and structural deviation metrics to assess the influence of\ncandidate differential operators within neural surrogates. Theoretically, we\nprove exact recovery of the causal operator support under restricted isometry\nor mutual coherence conditions, with residual bounds guaranteeing\nidentifiability. Empirically, we validate the framework on both synthetic and\nreal-world datasets across climate dynamics, tumor diffusion, and ocean flows.\nOur method consistently recovers governing operators even under noise,\nredundancy, and data scarcity, outperforming standard PINNs and DeepONets in\nstructural fidelity. This work positions causal PDE discovery as a tractable\nand interpretable inference task grounded in structural causal models and\nvariational residual analysis.", "AI": {"tldr": "提出了一种基于物理信息神经网络和反事实扰动的PDE因果结构发现框架，通过功能干预量化算子级必要性，优于传统方法。", "motivation": "传统方法如残差最小化或稀疏回归在PDE因果结构发现中存在局限性，需要更精确和可解释的方法。", "method": "引入因果敏感性指数和结构偏差度量，结合神经代理模型，通过功能干预评估候选微分算子的影响。", "result": "理论和实验验证了方法在噪声、冗余和数据稀缺下的有效性，优于标准PINNs和DeepONets。", "conclusion": "该框架将PDE因果发现定位为基于结构因果模型和变分残差分析的可解释推理任务。"}}
{"id": "2506.20522", "categories": ["cs.CV", "I.5.4; I.4.6; I.4.9; I.4.8; J.3"], "pdf": "https://arxiv.org/pdf/2506.20522", "abs": "https://arxiv.org/abs/2506.20522", "authors": ["Chathura Wimalasiri", "Piumal Rathnayake", "Shamod Wijerathne", "Sumudu Rasnayaka", "Dhanushka Leuke Bandara", "Roshan Ragel", "Vajira Thambawita", "Isuru Nawinne"], "title": "AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns", "comment": "This manuscript is 17 pages with 5 tables and 12 figures. The\n  manuscript is under review at Nature Scientific Reports", "summary": "Periodontitis, a chronic inflammatory disease causing alveolar bone loss,\nsignificantly affects oral health and quality of life. Accurate assessment of\nbone loss severity and pattern is critical for diagnosis and treatment\nplanning. In this study, we propose a novel AI-based deep learning framework to\nautomatically detect and quantify alveolar bone loss and its patterns using\nintraoral periapical (IOPA) radiographs. Our method combines YOLOv8 for tooth\ndetection with Keypoint R-CNN models to identify anatomical landmarks, enabling\nprecise calculation of bone loss severity. Additionally, YOLOv8x-seg models\nsegment bone levels and tooth masks to determine bone loss patterns (horizontal\nvs. angular) via geometric analysis. Evaluated on a large, expertly annotated\ndataset of 1000 radiographs, our approach achieved high accuracy in detecting\nbone loss severity (intra-class correlation coefficient up to 0.80) and bone\nloss pattern classification (accuracy 87%). This automated system offers a\nrapid, objective, and reproducible tool for periodontal assessment, reducing\nreliance on subjective manual evaluation. By integrating AI into dental\nradiographic analysis, our framework has the potential to improve early\ndiagnosis and personalized treatment planning for periodontitis, ultimately\nenhancing patient care and clinical outcomes.", "AI": {"tldr": "提出了一种基于AI的深度学习框架，用于自动检测和量化牙槽骨流失及其模式，通过结合YOLOv8和Keypoint R-CNN模型实现高精度评估。", "motivation": "牙周炎严重影响口腔健康和生活质量，准确评估骨流失的严重程度和模式对诊断和治疗计划至关重要。", "method": "结合YOLOv8检测牙齿，Keypoint R-CNN识别解剖标志，YOLOv8x-seg模型分割骨水平和牙齿掩膜，通过几何分析确定骨流失模式。", "result": "在1000张放射线照片上评估，骨流失严重程度检测的组内相关系数达0.80，骨流失模式分类准确率为87%。", "conclusion": "该自动化系统为牙周评估提供了快速、客观且可重复的工具，有望改善早期诊断和个性化治疗计划。"}}
{"id": "2506.20194", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20194", "abs": "https://arxiv.org/abs/2506.20194", "authors": ["Ruokai Yin", "Yuhang Li", "Donghyun Lee", "Priyadarshini Panda"], "title": "DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs", "comment": null, "summary": "Large language models (LLMs) deliver strong performance but are difficult to\ndeploy due to high memory and compute costs. While pruning reduces these\ndemands, most methods ignore activation sparsity observed at runtime. We\nreinterpret activation sparsity as dynamic structured weight sparsity and\npropose DuoGPT, a unified framework that constructs dual-sparse (spMspV)\nworkloads by combining unstructured weight pruning with activation sparsity. To\npreserve accuracy, we extend the Optimal Brain Compression (OBC) framework with\nactivation-aware calibration and introduce output residuals from the dense\nmodel as correction terms. We further optimize the solution for efficient GPU\nexecution, enabling scalability to billion-parameter LLMs. Evaluations on\nLLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured\npruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\\times$\ncompared to the baseline dense model.", "AI": {"tldr": "DuoGPT提出了一种结合权重剪枝和激活稀疏性的双稀疏框架，通过动态结构化权重稀疏性优化LLM部署，显著提升性能。", "motivation": "大型语言模型（LLM）因高内存和计算成本难以部署，现有剪枝方法未充分利用运行时激活稀疏性。", "method": "将激活稀疏性重新解释为动态结构化权重稀疏性，结合非结构化权重剪枝构建双稀疏（spMspV）工作负载，并通过激活感知校准和密集模型输出残差校正保持精度。", "result": "在LLaMA-2和LLaMA-3上，DuoGPT在1.39倍加速下比基线密集模型准确率提升高达9.17%。", "conclusion": "DuoGPT通过双稀疏框架和GPU优化，显著提升了LLM的部署效率和性能。"}}
{"id": "2506.20548", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.20548", "abs": "https://arxiv.org/abs/2506.20548", "authors": ["Manyi Li", "Renshuai Tao", "Yufan Liu", "Chuangchuang Tan", "Haotong Qin", "Bing Li", "Yunchao Wei", "Yao Zhao"], "title": "Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks", "comment": "20 pages, 10 figures", "summary": "With the rapid advancement of deep learning, particularly through generative\nadversarial networks (GANs) and diffusion models (DMs), AI-generated images, or\n``deepfakes\", have become nearly indistinguishable from real ones. These images\nare widely shared across Online Social Networks (OSNs), raising concerns about\ntheir misuse. Existing deepfake detection methods overlook the ``block effects\"\nintroduced by compression in OSNs, which obscure deepfake artifacts, and\nprimarily focus on raw images, rarely encountered in real-world scenarios. To\naddress these challenges, we propose PLADA (Pay Less Attention to Deceptive\nArtifacts), a novel framework designed to tackle the lack of paired data and\nthe ineffective use of compressed images. PLADA consists of two core modules:\nBlock Effect Eraser (B2E), which uses a dual-stage attention mechanism to\nhandle block effects, and Open Data Aggregation (ODA), which processes both\npaired and unpaired data to improve detection. Extensive experiments across 26\ndatasets demonstrate that PLADA achieves a remarkable balance in deepfake\ndetection, outperforming SoTA methods in detecting deepfakes on OSNs, even with\nlimited paired data and compression. More importantly, this work introduces the\n``block effect\" as a critical factor in deepfake detection, providing a robust\nsolution for open-world scenarios. Our code is available at\nhttps://github.com/ManyiLee/PLADA.", "AI": {"tldr": "PLADA是一个新型框架，通过处理压缩图像的块效应和利用配对与非配对数据，显著提升了在线社交网络中的深度伪造检测性能。", "motivation": "现有深度伪造检测方法忽视了压缩引入的块效应，且主要依赖原始图像，难以应对实际场景中的挑战。", "method": "PLADA包含两个核心模块：块效应消除器（B2E）和开放数据聚合（ODA），分别处理块效应和利用多种数据。", "result": "在26个数据集上的实验表明，PLADA在深度伪造检测中表现优异，尤其在压缩和有限配对数据情况下优于现有方法。", "conclusion": "PLADA不仅提升了检测性能，还首次将块效应作为关键因素引入深度伪造检测，为开放场景提供了鲁棒解决方案。"}}
{"id": "2506.20197", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.20197", "abs": "https://arxiv.org/abs/2506.20197", "authors": ["Clément L. Canonne", "Yash Pote", "Uddalok Sarkar"], "title": "Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach", "comment": "16 pages, 4 figures", "summary": "A growing fraction of all code is sampled from Large Language Models (LLMs).\nWe investigate the problem of attributing code generated by language models\nusing hypothesis testing to leverage established techniques and guarantees.\nGiven a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to\nassess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse\nof dimensionality, this is intractable when only samples from the LLM are\ngiven: to circumvent this, we use both samples and density estimates from the\nLLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames\nattribution as a distribution testing problem. Our experiments on a benchmark\nof code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores (\n$\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and\nStable-Code using only $\\approx 2000$ samples.", "AI": {"tldr": "论文提出了一种名为Anubis的零样本归属工具，通过假设检验将代码归属问题转化为分布测试问题，利用LLM的样本和密度估计实现高效归属。", "motivation": "随着大量代码由大型语言模型生成，如何准确归属代码来源成为一个重要问题。论文旨在解决这一问题，利用假设检验技术提供可靠的归属方法。", "method": "提出Anubis工具，将归属问题视为分布测试问题，结合LLM的样本和密度估计，避免维度灾难。", "result": "实验表明，Anubis在区分不同LLM（如DeepSeek-Coder、CodeGemma和Stable-Code）时，仅需约2000个样本即可达到高AUROC（≥0.9）。", "conclusion": "Anubis是一种高效的零样本归属工具，适用于代码来源归属问题，具有实际应用潜力。"}}
{"id": "2506.20204", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20204", "abs": "https://arxiv.org/abs/2506.20204", "authors": ["Eduardo Gutierrez Maestro", "Hadi Banaee", "Amy Loutfi"], "title": "Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets", "comment": null, "summary": "Affective priming exemplifies the challenge of ambiguity in affective\ncomputing. While the community has largely addressed this issue from a\nlabel-based perspective, identifying data points in the sequence affected by\nthe priming effect, the impact of priming on data itself, particularly in\nphysiological signals, remains underexplored. Data affected by priming can lead\nto misclassifications when used in learning models. This study proposes the\nAffective Priming Score (APS), a data-driven method to detect data points\ninfluenced by the priming effect. The APS assigns a score to each data point,\nquantifying the extent to which it is affected by priming. To validate this\nmethod, we apply it to the SEED and SEED-VII datasets, which contain sufficient\ntransitions between emotional events to exhibit priming effects. We train\nmodels with the same configuration using both the original data and\npriming-free sequences. The misclassification rate is significantly reduced\nwhen using priming-free sequences compared to the original data. This work\ncontributes to the broader challenge of ambiguity by identifying and mitigating\npriming effects at the data level, enhancing model robustness, and offering\nvaluable insights for the design and collection of affective computing\ndatasets.", "AI": {"tldr": "该研究提出了一种数据驱动的方法（APS）来检测情感计算中受启动效应影响的数据点，并通过实验验证其有效性。", "motivation": "情感计算中启动效应的模糊性挑战尚未从数据层面充分探索，可能导致模型误分类。", "method": "提出Affective Priming Score (APS)方法，量化数据点受启动效应影响的程度，并在SEED和SEED-VII数据集上验证。", "result": "使用去启动效应的数据序列显著降低了模型的误分类率。", "conclusion": "该研究通过数据层面的启动效应识别与缓解，提升了模型鲁棒性，为情感计算数据集的设计与收集提供了新见解。"}}
{"id": "2506.20563", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20563", "abs": "https://arxiv.org/abs/2506.20563", "authors": ["Lei Zhu", "Jun Zhou", "Rick Siow Mong Goh", "Yong Liu"], "title": "AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation", "comment": "Accepted to MICCAI 2025", "summary": "Vision Transformer has recently gained tremendous popularity in medical image\nsegmentation task due to its superior capability in capturing long-range\ndependencies. However, transformer requires a large amount of labeled data to\nbe effective, which hinders its applicability in annotation scarce\nsemi-supervised learning scenario where only limited labeled data is available.\nState-of-the-art semi-supervised learning methods propose combinatorial\nCNN-Transformer learning to cross teach a transformer with a convolutional\nneural network, which achieves promising results. However, it remains a\nchallenging task to effectively train the transformer with limited labeled\ndata. In this paper, we propose an adversarial masked image modeling method to\nfully unleash the potential of transformer for semi-supervised medical image\nsegmentation. The key challenge in semi-supervised learning with transformer\nlies in the lack of sufficient supervision signal. To this end, we propose to\nconstruct an auxiliary masked domain from original domain with masked image\nmodeling and train the transformer to predict the entire segmentation mask with\nmasked inputs to increase supervision signal. We leverage the original labels\nfrom labeled data and pseudo-labels from unlabeled data to learn the masked\ndomain. To further benefit the original domain from masked domain, we provide a\ntheoretical analysis of our method from a multi-domain learning perspective and\ndevise a novel adversarial training loss to reduce the domain gap between the\noriginal and masked domain, which boosts semi-supervised learning performance.\nWe also extend adversarial masked image modeling to CNN network. Extensive\nexperiments on three public medical image segmentation datasets demonstrate the\neffectiveness of our method, where our method outperforms existing methods\nsignificantly. Our code is publicly available at\nhttps://github.com/zlheui/AdvMIM.", "AI": {"tldr": "提出了一种对抗性掩码图像建模方法，用于半监督医学图像分割，通过增强监督信号和减少域差距，显著提升性能。", "motivation": "Transformer在医学图像分割中表现优异，但需要大量标注数据，限制了其在半监督学习中的应用。现有方法难以有效利用有限标注数据训练Transformer。", "method": "提出对抗性掩码图像建模方法，通过构建掩码域并利用原始标签和伪标签增强监督信号，同时设计对抗训练损失以减少域差距。", "result": "在三个公开医学图像分割数据集上显著优于现有方法。", "conclusion": "该方法有效解决了半监督学习中Transformer训练不足的问题，提升了分割性能。"}}
{"id": "2506.20235", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20235", "abs": "https://arxiv.org/abs/2506.20235", "authors": ["Yuyang Zhang", "Xu Shen", "Yu Xie", "Ka-Chun Wong", "Weidun Xie", "Chengbin Peng"], "title": "Directed Link Prediction using GNN with Local and Global Feature Fusion", "comment": null, "summary": "Link prediction is a classical problem in graph analysis with many practical\napplications. For directed graphs, recently developed deep learning approaches\ntypically analyze node similarities through contrastive learning and aggregate\nneighborhood information through graph convolutions. In this work, we propose a\nnovel graph neural network (GNN) framework to fuse feature embedding with\ncommunity information. We theoretically demonstrate that such hybrid features\ncan improve the performance of directed link prediction. To utilize such\nfeatures efficiently, we also propose an approach to transform input graphs\ninto directed line graphs so that nodes in the transformed graph can aggregate\nmore information during graph convolutions. Experiments on benchmark datasets\nshow that our approach outperforms the state-of-the-art in most cases when 30%,\n40%, 50%, and 60% of the connected links are used as training data,\nrespectively.", "AI": {"tldr": "提出了一种融合特征嵌入与社区信息的图神经网络框架，用于有向链接预测，并通过实验验证其优于现有方法。", "motivation": "解决有向图中链接预测问题，通过结合特征嵌入与社区信息提升性能。", "method": "提出新型GNN框架，融合特征嵌入与社区信息，并将输入图转化为有向线图以增强信息聚合。", "result": "在多个基准数据集上，使用不同比例的训练数据时，性能优于现有方法。", "conclusion": "融合特征嵌入与社区信息的GNN框架能有效提升有向链接预测的性能。"}}
{"id": "2506.20567", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20567", "abs": "https://arxiv.org/abs/2506.20567", "authors": ["Zhiwang Zhang", "Dong Xu", "Wanli Ouyang", "Chuanqi Tan"], "title": "Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization", "comment": "10 pages", "summary": "In this work, we propose a division-and-summarization (DaS) framework for\ndense video captioning. After partitioning each untrimmed long video as\nmultiple event proposals, where each event proposal consists of a set of short\nvideo segments, we extract visual feature (e.g., C3D feature) from each segment\nand use the existing image/video captioning approach to generate one sentence\ndescription for this segment. Considering that the generated sentences contain\nrich semantic descriptions about the whole event proposal, we formulate the\ndense video captioning task as a visual cue aided sentence summarization\nproblem and propose a new two stage Long Short Term Memory (LSTM) approach\nequipped with a new hierarchical attention mechanism to summarize all generated\nsentences as one descriptive sentence with the aid of visual features.\nSpecifically, the first-stage LSTM network takes all semantic words from the\ngenerated sentences and the visual features from all segments within one event\nproposal as the input, and acts as the encoder to effectively summarize both\nsemantic and visual information related to this event proposal. The\nsecond-stage LSTM network takes the output from the first-stage LSTM network\nand the visual features from all video segments within one event proposal as\nthe input, and acts as the decoder to generate one descriptive sentence for\nthis event proposal. Our comprehensive experiments on the ActivityNet Captions\ndataset demonstrate the effectiveness of our newly proposed DaS framework for\ndense video captioning.", "AI": {"tldr": "提出了一种基于分割与摘要（DaS）的密集视频字幕框架，通过两阶段LSTM和分层注意力机制生成描述性句子。", "motivation": "解决未修剪长视频中密集事件描述的挑战，通过分割视频并利用视觉特征辅助句子摘要。", "method": "1. 将视频分割为事件提案，提取视觉特征；2. 使用现有方法生成句子；3. 两阶段LSTM（编码器和解码器）结合分层注意力机制进行摘要。", "result": "在ActivityNet Captions数据集上验证了DaS框架的有效性。", "conclusion": "DaS框架通过视觉辅助的句子摘要，显著提升了密集视频字幕生成的性能。"}}
{"id": "2506.20245", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20245", "abs": "https://arxiv.org/abs/2506.20245", "authors": ["Yushan Zhao", "Jinyuan He", "Donglai Chen", "Weijie Luo", "Chong Xie", "Ri Zhang", "Yonghong Chen", "Yan Xu"], "title": "FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data", "comment": null, "summary": "Federated learning (FL) is a decentralized collaborative machine learning\n(ML) technique. It provides a solution to the issues of isolated data islands\nand data privacy leakage in industrial ML practices. One major challenge in FL\nis handling the non-identical and independent distributed (non-IID) data.\nCurrent solutions either focus on constructing an all-powerful global model, or\ncustomizing personalized local models. Few of them can provide both a\nwell-generalized global model and well-performed local models at the same time.\nAdditionally, many FL solutions to the non-IID problem are benefited from\nintroducing public datasets. However, this will also increase the risk of data\nleakage. To tackle the problems, we propose a novel data-free distillation\nframework, Federated Bidirectional Knowledge Distillation (FedBKD).\nSpecifically, we train Generative Adversarial Networks (GAN) for synthetic\ndata. During the GAN training, local models serve as discriminators and their\nparameters are frozen. The synthetic data is then used for bidirectional\ndistillation between global and local models to achieve knowledge interactions\nso that performances for both sides are improved. We conduct extensive\nexperiments on 4 benchmarks under different non-IID settings. The results show\nthat FedBKD achieves SOTA performances in every case.", "AI": {"tldr": "论文提出了一种名为FedBKD的无数据蒸馏框架，通过生成对抗网络（GAN）合成数据，实现全局和局部模型之间的双向知识蒸馏，解决了联邦学习中非独立同分布数据的挑战。", "motivation": "解决联邦学习中非独立同分布数据的问题，同时避免引入公共数据集导致的数据泄漏风险。", "method": "使用GAN生成合成数据，局部模型作为判别器，冻结其参数，通过双向蒸馏实现全局和局部模型的知识交互。", "result": "在4个基准测试中，FedBKD在不同非独立同分布设置下均达到最优性能。", "conclusion": "FedBKD能够同时提升全局和局部模型的性能，且无需依赖公共数据集，降低了数据泄漏风险。"}}
{"id": "2506.20582", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20582", "abs": "https://arxiv.org/abs/2506.20582", "authors": ["Rajat Rasal", "Avinash Kori", "Ben Glocker"], "title": "Causal Representation Learning with Observational Grouping for CXR Classification", "comment": null, "summary": "Identifiable causal representation learning seeks to uncover the true causal\nrelationships underlying a data generation process. In medical imaging, this\npresents opportunities to improve the generalisability and robustness of\ntask-specific latent features. This work introduces the concept of grouping\nobservations to learn identifiable representations for disease classification\nin chest X-rays via an end-to-end framework. Our experiments demonstrate that\nthese causal representations improve generalisability and robustness across\nmultiple classification tasks when grouping is used to enforce invariance w.r.t\nrace, sex, and imaging views.", "AI": {"tldr": "通过分组观测学习可识别的因果表示，提升胸部X光疾病分类的泛化性和鲁棒性。", "motivation": "在医学影像中，识别数据生成过程中的真实因果关系可以提升任务特定潜在特征的泛化性和鲁棒性。", "method": "提出一种端到端框架，通过分组观测学习可识别的因果表示，并在种族、性别和成像视角上强制不变性。", "result": "实验表明，这种因果表示在多个分类任务中提升了泛化性和鲁棒性。", "conclusion": "分组观测学习可识别的因果表示在医学影像分类中具有潜力。"}}
{"id": "2506.20251", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20251", "abs": "https://arxiv.org/abs/2506.20251", "authors": ["Kejia Chen", "Jiawen Zhang", "Jiacong Hu", "Yu Wang", "Jian Lou", "Zunlei Feng", "Mingli Song"], "title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models", "comment": "ICML 2025", "summary": "Quantized large language models (LLMs) have gained increasing attention and\nsignificance for enabling deployment in resource-constrained environments.\nHowever, emerging studies on a few calibration dataset-free quantization\nmethods suggest that quantization may compromise the safety capabilities of\nLLMs, underscoring the urgent need for systematic safety evaluations and\neffective mitigation strategies. In this paper, we present comprehensive safety\nevaluations across various mainstream quantization techniques and diverse\ncalibration datasets, utilizing widely accepted safety benchmarks. To address\nthe identified safety vulnerabilities, we propose a quantization-aware safety\npatching framework, Q-resafe, to efficiently restore the safety capabilities of\nquantized LLMs while minimizing any adverse impact on utility. Extensive\nexperimental results demonstrate that Q-resafe successfully re-aligns the\nsafety of quantized LLMs with their pre-quantization counterparts, even under\nchallenging evaluation scenarios. Project page is available at:\nhttps://github.com/Thecommonirin/Qresafe.", "AI": {"tldr": "该论文研究了量化大型语言模型（LLMs）对安全性的影响，并提出了一种量化感知的安全补丁框架Q-resafe，以恢复量化LLMs的安全性。", "motivation": "量化LLMs在资源受限环境中部署具有重要意义，但现有研究表明量化可能损害其安全能力，因此需要系统性安全评估和缓解策略。", "method": "通过主流量化技术和多样化校准数据集进行安全性评估，并提出Q-resafe框架以恢复安全性。", "result": "实验表明Q-resafe成功将量化LLMs的安全性恢复到量化前水平。", "conclusion": "Q-resafe是一种有效的解决方案，能够在保持实用性的同时恢复量化LLMs的安全性。"}}
{"id": "2506.20583", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20583", "abs": "https://arxiv.org/abs/2506.20583", "authors": ["Zhiwang Zhang", "Dong Xu", "Wanli Ouyang", "Luping Zhou"], "title": "Dense Video Captioning using Graph-based Sentence Summarization", "comment": "12 pages", "summary": "Recently, dense video captioning has made attractive progress in detecting\nand captioning all events in a long untrimmed video. Despite promising results\nwere achieved, most existing methods do not sufficiently explore the scene\nevolution within an event temporal proposal for captioning, and therefore\nperform less satisfactorily when the scenes and objects change over a\nrelatively long proposal. To address this problem, we propose a graph-based\npartition-and-summarization (GPaS) framework for dense video captioning within\ntwo stages. For the ``partition\" stage, a whole event proposal is split into\nshort video segments for captioning at a finer level. For the ``summarization\"\nstage, the generated sentences carrying rich description information for each\nsegment are summarized into one sentence to describe the whole event. We\nparticularly focus on the ``summarization\" stage, and propose a framework that\neffectively exploits the relationship between semantic words for summarization.\nWe achieve this goal by treating semantic words as nodes in a graph and\nlearning their interactions by coupling Graph Convolutional Network (GCN) and\nLong Short Term Memory (LSTM), with the aid of visual cues. Two schemes of\nGCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN\nand LSTM. The effectiveness of our approach is demonstrated via an extensive\ncomparison with the state-of-the-arts methods on the two benchmarks ActivityNet\nCaptions dataset and YouCook II dataset.", "AI": {"tldr": "论文提出了一种基于图的分割与总结（GPaS）框架，用于密集视频字幕生成，通过分割事件提案为更短的片段并总结描述信息，解决了现有方法在场景变化时的不足。", "motivation": "现有密集视频字幕生成方法未充分探索事件提案内的场景演变，导致在场景和对象变化时表现不佳。", "method": "提出GPaS框架，分为分割和总结两阶段。总结阶段通过图卷积网络（GCN）和长短时记忆网络（LSTM）结合，利用语义词关系生成描述。", "result": "在ActivityNet Captions和YouCook II数据集上，方法优于现有技术。", "conclusion": "GPaS框架通过细粒度分割和语义关系建模，显著提升了密集视频字幕生成的性能。"}}
{"id": "2506.20253", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20253", "abs": "https://arxiv.org/abs/2506.20253", "authors": ["Ben Gerhards", "Nikita Popkov", "Annekatrin König", "Marcel Arpogaus", "Bastian Schäfermeier", "Leonie Riedl", "Stephan Vogt", "Philip Hehlert"], "title": "Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios", "comment": null, "summary": "Forecasting attracts a lot of research attention in the electricity value\nchain. However, most studies concentrate on short-term forecasting of\ngeneration or consumption with a focus on systems and less on individual\nconsumers. Even more neglected is the topic of long-term forecasting of\nindividual power consumption.\n  Here, we provide an in-depth comparative evaluation of data-driven methods\nfor generating synthetic time series data tailored to energy consumption\nlong-term forecasting. High-fidelity synthetic data is crucial for a wide range\nof applications, including state estimations in energy systems or power grid\nplanning. In this study, we assess and compare the performance of multiple\nstate-of-the-art but less common techniques: a hybrid Wasserstein Generative\nAdversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM),\nHidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial\nnormalizing Flows (MABF). We analyze the ability of each method to replicate\nthe temporal dynamics, long-range dependencies, and probabilistic transitions\ncharacteristic of individual energy consumption profiles. Our comparative\nevaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and\nMABF aiding in selecting the most suitable approach for state estimations and\nother energy-related tasks. Our generation and analysis framework aims to\nenhance the accuracy and reliability of synthetic power consumption data while\ngenerating data that fulfills criteria like anonymisation - preserving privacy\nconcerns mitigating risks of specific profiling of single customers. This study\nutilizes an open-source dataset from households in Germany with 15min time\nresolution. The generated synthetic power profiles can readily be used in\napplications like state estimations or consumption forecasting.", "AI": {"tldr": "该论文比较了四种数据驱动方法（WGAN、DDPM、HMM、MABF）在生成用于长期电力消费预测的高保真合成时间序列数据方面的性能。", "motivation": "现有研究多集中于短期电力消费预测，而长期个体消费预测被忽视，且缺乏高保真合成数据用于系统规划等应用。", "method": "评估了四种方法（WGAN、DDPM、HMM、MABF）在复制电力消费时间动态、长程依赖和概率转移方面的能力。", "result": "比较分析揭示了各方法的优缺点，为能源相关任务（如状态估计）选择合适方法提供了依据。", "conclusion": "研究框架提升了合成电力消费数据的准确性和隐私保护能力，适用于实际应用。"}}
{"id": "2506.20260", "categories": ["cs.LG", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.20260", "abs": "https://arxiv.org/abs/2506.20260", "authors": ["Junqi Jiang", "Antonio Rago", "Francesco Leofante", "Francesca Toni"], "title": "Argumentative Ensembling for Robust Recourse under Model Multiplicity", "comment": "arXiv admin note: substantial text overlap with arXiv:2312.15097", "summary": "In machine learning, it is common to obtain multiple equally performing\nmodels for the same prediction task, e.g., when training neural networks with\ndifferent random seeds. Model multiplicity (MM) is the situation which arises\nwhen these competing models differ in their predictions for the same input, for\nwhich ensembling is often employed to determine an aggregation of the outputs.\nProviding recourse recommendations via counterfactual explanations (CEs) under\nMM thus becomes complex, since the CE may not be valid across all models, i.e.,\nthe CEs are not robust under MM. In this work, we formalise the problem of\nproviding recourse under MM, which we name recourse-aware ensembling (RAE). We\npropose the idea that under MM, CEs for each individual model should be\nconsidered alongside their predictions so that the aggregated prediction and\nrecourse are decided in tandem. Centred around this intuition, we introduce six\ndesirable properties for solutions to this problem. For solving RAE, we propose\na novel argumentative ensembling method which guarantees the robustness of CEs\nunder MM. Specifically, our method leverages computational argumentation to\nexplicitly represent the conflicts between models and counterfactuals regarding\nprediction results and CE validity. It then uses argumentation semantics to\nresolve the conflicts and obtain the final solution, in a manner which is\nparametric to the chosen semantics. Our method also allows for the\nspecification of preferences over the models under MM, allowing further\ncustomisation of the ensemble. In a comprehensive theoretical analysis, we\ncharacterise the behaviour of argumentative ensembling with four different\nargumentation semantics. We then empirically demonstrate the effectiveness of\nour approach in satisfying desirable properties with eight instantiations of\nour method. (Abstract is shortened for arXiv.)", "AI": {"tldr": "论文提出了一种名为“recourse-aware ensembling (RAE)”的方法，用于解决机器学习中模型多样性（MM）下反事实解释（CEs）的鲁棒性问题。通过计算论证方法，确保CEs在多模型下的有效性。", "motivation": "在机器学习中，模型多样性（MM）导致不同模型对同一输入可能产生不同的预测和反事实解释（CEs），这使得CEs的鲁棒性成为问题。", "method": "提出了一种基于计算论证的集成方法，通过显式表示模型与CEs之间的冲突，并利用论证语义解决冲突，确保CEs的鲁棒性。", "result": "理论分析表明，该方法在四种论证语义下均表现良好；实证研究验证了其满足六种理想性质。", "conclusion": "该方法有效解决了MM下CEs的鲁棒性问题，并支持对模型的偏好定制。"}}
{"id": "2506.20588", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20588", "abs": "https://arxiv.org/abs/2506.20588", "authors": ["Pritam Mishra", "Coloma Ballester", "Dimosthenis Karatzas"], "title": "TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness", "comment": null, "summary": "The increasing ubiquity of video content and the corresponding demand for\nefficient access to meaningful information have elevated video summarization\nand video highlights as a vital research area. However, many state-of-the-art\nmethods depend heavily either on supervised annotations or on attention-based\nmodels, which are computationally expensive and brittle in the face of\ndistribution shifts that hinder cross-domain applicability across datasets. We\nintroduce a pioneering self-supervised video summarization model that captures\nboth spatial and temporal dependencies without the overhead of attention, RNNs,\nor transformers. Our framework integrates a novel set of Markov process-driven\nloss metrics and a two-stage self supervised learning paradigm that ensures\nboth performance and efficiency. Our approach achieves state-of-the-art\nperformance on the SUMME and TVSUM datasets, outperforming all existing\nunsupervised methods. It also rivals the best supervised models, demonstrating\nthe potential for efficient, annotation-free architectures. This paves the way\nfor more generalizable video summarization techniques and challenges the\nprevailing reliance on complex architectures.", "AI": {"tldr": "提出了一种自监督视频摘要模型，无需注意力机制或复杂架构，在SUMME和TVSUM数据集上表现优异。", "motivation": "视频内容日益普及，但现有方法依赖监督标注或计算昂贵的注意力模型，限制了跨域适用性。", "method": "采用马尔可夫过程驱动的损失指标和两阶段自监督学习范式，避免使用注意力、RNN或Transformer。", "result": "在SUMME和TVSUM数据集上达到最先进性能，优于所有无监督方法，媲美监督模型。", "conclusion": "展示了高效、无需标注的架构潜力，挑战了对复杂架构的依赖，推动了通用视频摘要技术的发展。"}}
{"id": "2506.20285", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20285", "abs": "https://arxiv.org/abs/2506.20285", "authors": ["Zeqi Leng", "Chunxu Zhang", "Guodong Long", "Riting Xia", "Bo Yang"], "title": "Distilling A Universal Expert from Clustered Federated Learning", "comment": null, "summary": "Clustered Federated Learning (CFL) addresses the challenges posed by non-IID\ndata by training multiple group- or cluster-specific expert models. However,\nexisting methods often overlook the shared information across clusters, which\nrepresents the generalizable knowledge valuable to all participants in the\nFederated Learning (FL) system. To overcome this limitation, this paper\nintroduces a novel FL framework that distills a universal expert model from the\nknowledge of multiple clusters. This universal expert captures globally shared\ninformation across all clients and is subsequently distributed to each client\nas the initialization for the next round of model training. The proposed FL\nframework operates in three iterative steps: (1) local model training at each\nclient, (2) cluster-specific model aggregation, and (3) universal expert\ndistillation. This three-step learning paradigm ensures the preservation of\nfine-grained non-IID characteristics while effectively incorporating shared\nknowledge across clusters. Compared to traditional gradient-based aggregation\nmethods, the distillation-based model aggregation introduces greater\nflexibility in handling model heterogeneity and reduces conflicts among\ncluster-specific experts. Extensive experimental results demonstrate the\nsuperior performance of the proposed method across various scenarios,\nhighlighting its potential to advance the state of CFL by balancing\npersonalized and shared knowledge more effectively.", "AI": {"tldr": "本文提出了一种新的联邦学习框架，通过从多个集群知识中蒸馏出一个通用专家模型，解决了非独立同分布数据问题，并平衡了个性化和共享知识。", "motivation": "现有方法忽视了集群间的共享信息，这些信息对所有联邦学习参与者具有通用价值。", "method": "框架分为三步：本地模型训练、集群特定模型聚合和通用专家蒸馏。", "result": "实验结果表明，该方法在各种场景下表现优异，能更有效地处理模型异构性。", "conclusion": "该方法通过平衡个性化和共享知识，推动了集群联邦学习的发展。"}}
{"id": "2506.20590", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20590", "abs": "https://arxiv.org/abs/2506.20590", "authors": ["Chaojun Ni", "Jie Li", "Haoyun Li", "Hengyu Liu", "Xiaofeng Wang", "Zheng Zhu", "Guosheng Zhao", "Boyuan Wang", "Chenxin Li", "Guan Huang", "Wenjun Mei"], "title": "WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration", "comment": null, "summary": "Interactive 3D scene generation from a single image has gained significant\nattention due to its potential to create immersive virtual worlds. However, a\nkey challenge in current 3D generation methods is the limited explorability,\nwhich cannot render high-quality images during larger maneuvers beyond the\noriginal viewpoint, particularly when attempting to move forward into unseen\nareas. To address this challenge, we propose WonderFree, the first model that\nenables users to interactively generate 3D worlds with the freedom to explore\nfrom arbitrary angles and directions. Specifically, we decouple this challenge\ninto two key subproblems: novel view quality, which addresses visual artifacts\nand floating issues in novel views, and cross-view consistency, which ensures\nspatial consistency across different viewpoints. To enhance rendering quality\nin novel views, we introduce WorldRestorer, a data-driven video restoration\nmodel designed to eliminate floaters and artifacts. In addition, a data\ncollection pipeline is presented to automatically gather training data for\nWorldRestorer, ensuring it can handle scenes with varying styles needed for 3D\nscene generation. Furthermore, to improve cross-view consistency, we propose\nConsistView, a multi-view joint restoration mechanism that simultaneously\nrestores multiple perspectives while maintaining spatiotemporal coherence.\nExperimental results demonstrate that WonderFree not only enhances rendering\nquality across diverse viewpoints but also significantly improves global\ncoherence and consistency. These improvements are confirmed by CLIP-based\nmetrics and a user study showing a 77.20% preference for WonderFree over\nWonderWorld enabling a seamless and immersive 3D exploration experience. The\ncode, model, and data will be publicly available.", "AI": {"tldr": "WonderFree是一种交互式3D场景生成模型，解决了现有方法在视角探索自由度和渲染质量上的限制，通过WorldRestorer和ConsistView技术提升了新视角质量和跨视角一致性。", "motivation": "当前3D生成方法在探索自由度和新视角渲染质量上存在限制，特别是在未探索区域的渲染效果较差。", "method": "提出WonderFree模型，包含WorldRestorer（消除新视角的视觉伪影）和ConsistView（确保跨视角一致性）两个关键技术。", "result": "实验表明，WonderFree显著提升了渲染质量和全局一致性，用户偏好率达77.20%。", "conclusion": "WonderFree为3D场景生成提供了更自由和沉浸式的探索体验，代码和模型将公开。"}}
{"id": "2506.20305", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20305", "abs": "https://arxiv.org/abs/2506.20305", "authors": ["Kazuki Yoda", "Kazuhiko Kawamoto", "Hiroshi Kera"], "title": "Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding", "comment": "17 pages, 13 figures", "summary": "The hardness of learning a function that attains a target task relates to its\ninput-sensitivity. For example, image classification tasks are\ninput-insensitive as minor corruptions should not affect the classification\nresults, whereas arithmetic and symbolic computation, which have been recently\nattracting interest, are highly input-sensitive as each input variable connects\nto the computation results. This study presents the first learning-based Quick\nResponse (QR) code decoding and investigates learning functions of medium\nsensitivity. Our experiments reveal that Transformers can successfully decode\nQR codes, even beyond the theoretical error-correction limit, by learning the\nstructure of embedded texts. They generalize from English-rich training data to\nother languages and even random strings. Moreover, we observe that the\nTransformer-based QR decoder focuses on data bits while ignoring\nerror-correction bits, suggesting a decoding mechanism distinct from standard\nQR code readers.", "AI": {"tldr": "本文研究了基于学习的QR码解码，发现Transformer模型能够通过学习嵌入文本结构成功解码QR码，甚至超越理论纠错限制。", "motivation": "探索中等输入敏感性的学习函数，特别是在QR码解码中的应用。", "method": "使用Transformer模型进行QR码解码实验，分析其对数据位和纠错位的关注。", "result": "Transformer模型能够超越理论纠错限制解码QR码，并能从英语训练数据泛化到其他语言和随机字符串。", "conclusion": "Transformer模型在QR码解码中表现出独特的机制，不同于标准QR码阅读器。"}}
{"id": "2506.20599", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20599", "abs": "https://arxiv.org/abs/2506.20599", "authors": ["Ji Qi", "Xinchang Zhang", "Dingqi Ye", "Yongjia Ruan", "Xin Guo", "Shaowen Wang", "Haifeng Li"], "title": "SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection", "comment": null, "summary": "The rapid advancement of generative artificial intelligence is producing fake\nremote sensing imagery (RSI) that is increasingly difficult to detect,\npotentially leading to erroneous intelligence, fake news, and even conspiracy\ntheories. Existing forgery detection methods typically rely on single visual\nfeatures to capture predefined artifacts, such as spatial-domain cues to detect\nforged objects like roads or buildings in RSI, or frequency-domain features to\nidentify artifacts from up-sampling operations in adversarial generative\nnetworks (GANs). However, the nature of artifacts can significantly differ\ndepending on geographic terrain, land cover types, or specific features within\nthe RSI. Moreover, these complex artifacts evolve as generative models become\nmore sophisticated. In short, over-reliance on a single visual cue makes\nexisting forgery detectors struggle to generalize across diverse remote sensing\ndata. This paper proposed a novel forgery detection framework called SFNet,\ndesigned to identify fake images in diverse remote sensing data by leveraging\nspatial and frequency domain features. Specifically, to obtain rich and\ncomprehensive visual information, SFNet employs two independent feature\nextractors to capture spatial and frequency domain features from input RSIs. To\nfully utilize the complementary domain features, the domain feature mapping\nmodule and the hybrid domain feature refinement module(CBAM attention) of SFNet\nare designed to successively align and fuse the multi-domain features while\nsuppressing redundant information. Experiments on three datasets show that\nSFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art\nRS forgery detection methods and exhibits robust generalization capabilities.\nThe code is available at https://github.com/GeoX-Lab/RSTI/tree/main/SFNet.", "AI": {"tldr": "SFNet是一种新型的伪造检测框架，通过结合空间和频域特征来识别多样化的遥感图像伪造内容，显著提升了检测准确率和泛化能力。", "motivation": "生成式人工智能的快速发展导致伪造遥感图像（RSI）难以检测，可能引发错误情报和虚假信息。现有方法依赖单一视觉特征，难以应对多样化的伪造内容。", "method": "SFNet采用两个独立的特征提取器分别捕获空间和频域特征，并通过域特征映射模块和混合域特征细化模块（CBAM注意力）对齐和融合多域特征。", "result": "在三个数据集上的实验表明，SFNet比现有最先进方法的准确率提高了4%-15.18%，并展现出强大的泛化能力。", "conclusion": "SFNet通过多域特征融合有效提升了伪造检测的准确性和泛化能力，为遥感图像伪造检测提供了新思路。"}}
{"id": "2506.20307", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20307", "abs": "https://arxiv.org/abs/2506.20307", "authors": ["Heyang Zhao", "Xingrui Yu", "David M. Bossens", "Ivor W. Tsang", "Quanquan Gu"], "title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration", "comment": null, "summary": "Imitation learning is a central problem in reinforcement learning where the\ngoal is to learn a policy that mimics the expert's behavior. In practice, it is\noften challenging to learn the expert policy from a limited number of\ndemonstrations accurately due to the complexity of the state space. Moreover,\nit is essential to explore the environment and collect data to achieve\nbeyond-expert performance. To overcome these challenges, we propose a novel\nimitation learning algorithm called Imitation Learning with Double Exploration\n(ILDE), which implements exploration in two aspects: (1) optimistic policy\noptimization via an exploration bonus that rewards state-action pairs with high\nuncertainty to potentially improve the convergence to the expert policy, and\n(2) curiosity-driven exploration of the states that deviate from the\ndemonstration trajectories to potentially yield beyond-expert performance.\nEmpirically, we demonstrate that ILDE outperforms the state-of-the-art\nimitation learning algorithms in terms of sample efficiency and achieves\nbeyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations\nthan in previous work. We also provide a theoretical justification of ILDE as\nan uncertainty-regularized policy optimization method with optimistic\nexploration, leading to a regret growing sublinearly in the number of episodes.", "AI": {"tldr": "提出了一种新的模仿学习算法ILDE，通过双重探索（乐观策略优化和好奇心驱动探索）提高样本效率并实现超越专家性能。", "motivation": "模仿学习在有限演示下难以准确学习专家策略，且需探索环境以实现超越专家性能。", "method": "ILDE算法结合乐观策略优化（奖励高不确定性状态-动作对）和好奇心驱动探索（偏离演示轨迹的状态）。", "result": "在Atari和MuJoCo任务中，ILDE在样本效率上优于现有算法，且用更少演示实现超越专家性能。", "conclusion": "ILDE是一种不确定性正则化的策略优化方法，理论证明其遗憾增长为次线性。"}}
{"id": "2506.20601", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20601", "abs": "https://arxiv.org/abs/2506.20601", "authors": ["Rui Huang", "Guangyao Zhai", "Zuria Bauer", "Marc Pollefeys", "Federico Tombari", "Leonidas Guibas", "Gao Huang", "Francis Engelmann"], "title": "Video Perception Models for 3D Scene Synthesis", "comment": null, "summary": "Traditionally, 3D scene synthesis requires expert knowledge and significant\nmanual effort. Automating this process could greatly benefit fields such as\narchitectural design, robotics simulation, virtual reality, and gaming. Recent\napproaches to 3D scene synthesis often rely on the commonsense reasoning of\nlarge language models (LLMs) or strong visual priors of modern image generation\nmodels. However, current LLMs demonstrate limited 3D spatial reasoning ability,\nwhich restricts their ability to generate realistic and coherent 3D scenes.\nMeanwhile, image generation-based methods often suffer from constraints in\nviewpoint selection and multi-view inconsistencies. In this work, we present\nVideo Perception models for 3D Scene synthesis (VIPScene), a novel framework\nthat exploits the encoded commonsense knowledge of the 3D physical world in\nvideo generation models to ensure coherent scene layouts and consistent object\nplacements across views. VIPScene accepts both text and image prompts and\nseamlessly integrates video generation, feedforward 3D reconstruction, and\nopen-vocabulary perception models to semantically and geometrically analyze\neach object in a scene. This enables flexible scene synthesis with high realism\nand structural consistency. For more precise analysis, we further introduce\nFirst-Person View Score (FPVScore) for coherence and plausibility evaluation,\nutilizing continuous first-person perspective to capitalize on the reasoning\nability of multimodal large language models. Extensive experiments show that\nVIPScene significantly outperforms existing methods and generalizes well across\ndiverse scenarios. The code will be released.", "AI": {"tldr": "VIPScene利用视频生成模型的3D物理世界常识知识，实现高真实性和结构一致性的3D场景合成。", "motivation": "传统3D场景合成需专家知识且手动操作繁琐，自动化可广泛应用于建筑设计、机器人仿真等领域。现有方法（如LLMs或图像生成模型）在3D空间推理或多视角一致性上存在局限。", "method": "VIPScene结合文本和图像提示，整合视频生成、3D重建和开放词汇感知模型，实现语义和几何分析。引入FPVScore评估连贯性和合理性。", "result": "实验表明VIPScene显著优于现有方法，且能泛化至多样场景。", "conclusion": "VIPScene为3D场景合成提供了高真实性和一致性的解决方案，代码将开源。"}}
{"id": "2506.20323", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20323", "abs": "https://arxiv.org/abs/2506.20323", "authors": ["Saundarya Subramaniam", "Shalini Majumdar", "Shantanu Nadar", "Kaustubh Kulkarni"], "title": "Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach", "comment": null, "summary": "This research presents the development of an Artificial Intelligence (AI) -\ndriven crop disease detection system designed to assist farmers in rural areas\nwith limited resources. We aim to compare different deep learning models for a\ncomparative analysis, focusing on their efficacy in transfer learning. By\nleveraging deep learning models, including EfficientNet, ResNet101,\nMobileNetV2, and our custom CNN, which achieved a validation accuracy of\n95.76%, the system effectively classifies plant diseases. This research\ndemonstrates the potential of transfer learning in reshaping agricultural\npractices, improving crop health management, and supporting sustainable farming\nin rural environments.", "AI": {"tldr": "开发了一种基于AI的作物病害检测系统，比较了多种深度学习模型在迁移学习中的效果，验证准确率达95.76%。", "motivation": "帮助资源有限的农村农民通过AI技术改善作物健康管理，推动可持续农业。", "method": "使用EfficientNet、ResNet101、MobileNetV2和自定义CNN模型进行迁移学习比较。", "result": "系统验证准确率达95.76%，证明了迁移学习在农业中的潜力。", "conclusion": "AI驱动的病害检测系统可有效支持农村农业实践，提升可持续性。"}}
{"id": "2506.20616", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20616", "abs": "https://arxiv.org/abs/2506.20616", "authors": ["Quoc-Duy Tran", "Anh-Tuan Vo", "Dinh-Khoi Vo", "Tam V. Nguyen", "Minh-Triet Tran", "Trung-Nghia Le"], "title": "Shape2Animal: Creative Animal Generation from Natural Silhouettes", "comment": null, "summary": "Humans possess a unique ability to perceive meaningful patterns in ambiguous\nstimuli, a cognitive phenomenon known as pareidolia. This paper introduces\nShape2Animal framework to mimics this imaginative capacity by reinterpreting\nnatural object silhouettes, such as clouds, stones, or flames, as plausible\nanimal forms. Our automated framework first performs open-vocabulary\nsegmentation to extract object silhouette and interprets semantically\nappropriate animal concepts using vision-language models. It then synthesizes\nan animal image that conforms to the input shape, leveraging text-to-image\ndiffusion model and seamlessly blends it into the original scene to generate\nvisually coherent and spatially consistent compositions. We evaluated\nShape2Animal on a diverse set of real-world inputs, demonstrating its\nrobustness and creative potential. Our Shape2Animal can offer new opportunities\nfor visual storytelling, educational content, digital art, and interactive\nmedia design. Our project page is here: https://shape2image.github.io", "AI": {"tldr": "Shape2Animal框架通过重新解释自然物体轮廓（如云、石头或火焰）为动物形态，模拟人类的pareidolia现象。", "motivation": "模仿人类在模糊刺激中感知有意义模式的能力，探索视觉创意应用。", "method": "使用开放词汇分割提取物体轮廓，结合视觉语言模型生成动物概念，利用文本到图像扩散模型合成动物图像并融入原场景。", "result": "在多样化真实输入上验证了框架的鲁棒性和创意潜力。", "conclusion": "Shape2Animal为视觉叙事、教育内容、数字艺术和交互媒体设计提供了新机会。"}}
{"id": "2506.20324", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20324", "abs": "https://arxiv.org/abs/2506.20324", "authors": ["Torben Berndt", "Benjamin Walker", "Tiexin Qin", "Jan Stühmer", "Andrey Kormilitzin"], "title": "Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning", "comment": null, "summary": "Dynamic graphs exhibit complex temporal dynamics due to the interplay between\nevolving node features and changing network structures. Recently, Graph Neural\nControlled Differential Equations (Graph Neural CDEs) successfully adapted\nNeural CDEs from paths on Euclidean domains to paths on graph domains. Building\non this foundation, we introduce Permutation Equivariant Neural Graph CDEs,\nwhich project Graph Neural CDEs onto permutation equivariant function spaces.\nThis significantly reduces the model's parameter count without compromising\nrepresentational power, resulting in more efficient training and improved\ngeneralisation. We empirically demonstrate the advantages of our approach\nthrough experiments on simulated dynamical systems and real-world tasks,\nshowing improved performance in both interpolation and extrapolation scenarios.", "AI": {"tldr": "论文提出了一种基于置换等变性的神经图控制微分方程（Permutation Equivariant Neural Graph CDEs），通过减少参数数量提升训练效率和泛化能力。", "motivation": "动态图的复杂时序动态需要高效且泛化能力强的模型。", "method": "将Graph Neural CDEs扩展到置换等变函数空间，减少参数数量。", "result": "在模拟动态系统和真实任务中表现优异，尤其在插值和外推场景。", "conclusion": "置换等变神经图CDEs在保持表达能力的同时提升了效率和泛化能力。"}}
{"id": "2506.20638", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20638", "abs": "https://arxiv.org/abs/2506.20638", "authors": ["Clément Forray", "Pauline Delporte", "Nicolas Delaygue", "Florence Genin", "Dawa Derksen"], "title": "Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects", "comment": "accepted for CVPR 2025 NFBCC workshop", "summary": "Obtaining a better knowledge of the current state and behavior of objects\norbiting Earth has proven to be essential for a range of applications such as\nactive debris removal, in-orbit maintenance, or anomaly detection. 3D models\nrepresent a valuable source of information in the field of Space Situational\nAwareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to\nperform 3D reconstruction of non-cooperative space objects from simulated\nimages. This scenario is challenging for NeRF models due to unusual camera\ncharacteristics and environmental conditions : mono-chromatic images, unknown\nobject orientation, limited viewing angles, absence of diffuse lighting etc. In\nthis work we focus primarly on the joint optimization of camera poses alongside\nthe NeRF. Our experimental results show that the most accurate 3D\nreconstruction is achieved when training with successive images one-by-one. We\nestimate camera poses by optimizing an uniform rotation and use regularization\nto prevent successive poses from being too far apart.", "AI": {"tldr": "利用NeRF技术从模拟图像中重建非合作空间物体的3D模型，重点优化相机姿态，实验表明逐帧训练效果最佳。", "motivation": "提升对地球轨道物体的状态和行为的了解，支持空间态势感知（SSA）应用，如碎片清除和异常检测。", "method": "采用NeRF进行3D重建，联合优化相机姿态，通过正则化限制姿态变化范围。", "result": "实验显示逐帧训练能实现最准确的3D重建。", "conclusion": "NeRF结合相机姿态优化在空间物体3D重建中具有潜力，尤其在受限条件下。"}}
{"id": "2506.20329", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.20329", "abs": "https://arxiv.org/abs/2506.20329", "authors": ["Alexandre Rio", "Marta Soare", "Sihem Amer-Yahia"], "title": "Producer-Fairness in Sequential Bundle Recommendation", "comment": null, "summary": "We address fairness in the context of sequential bundle recommendation, where\nusers are served in turn with sets of relevant and compatible items. Motivated\nby real-world scenarios, we formalize producer-fairness, that seeks to achieve\ndesired exposure of different item groups across users in a recommendation\nsession. Our formulation combines naturally with building high quality bundles.\nOur problem is solved in real time as users arrive. We propose an exact\nsolution that caters to small instances of our problem. We then examine two\nheuristics, quality-first and fairness-first, and an adaptive variant that\ndetermines on-the-fly the right balance between bundle fairness and quality.\nOur experiments on three real-world datasets underscore the strengths and\nlimitations of each solution and demonstrate their efficacy in providing fair\nbundle recommendations without compromising bundle quality.", "AI": {"tldr": "论文研究了顺序捆绑推荐中的公平性问题，提出了一种结合生产者公平性和捆绑质量的实时解决方案，并通过实验验证了其有效性。", "motivation": "现实场景中需要确保不同商品组在推荐会话中获得公平的曝光机会，同时保持捆绑推荐的高质量。", "method": "提出了精确解决方案（适用于小规模问题）和三种启发式方法（质量优先、公平优先和自适应平衡）。", "result": "在三个真实数据集上的实验表明，这些方法能在不牺牲捆绑质量的前提下实现公平推荐。", "conclusion": "研究为顺序捆绑推荐中的公平性问题提供了实用的解决方案，并展示了不同方法在不同场景下的适用性。"}}
{"id": "2506.20649", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20649", "abs": "https://arxiv.org/abs/2506.20649", "authors": ["Jacopo Dapueto", "Vito Paolo Pastore", "Nicoletta Noceti", "Francesca Odone"], "title": "Disentangled representations of microscopy images", "comment": "Published in: International Joint Conference on Neural Networks\n  (IJCNN 2025). Project page:\n  https://github.com/JacopoDapueto/disentangled_microscopy", "summary": "Microscopy image analysis is fundamental for different applications, from\ndiagnosis to synthetic engineering and environmental monitoring. Modern\nacquisition systems have granted the possibility to acquire an escalating\namount of images, requiring a consequent development of a large collection of\ndeep learning-based automatic image analysis methods. Although deep neural\nnetworks have demonstrated great performance in this field, interpretability,\nan essential requirement for microscopy image analysis, remains an open\nchallenge.\n  This work proposes a Disentangled Representation Learning (DRL) methodology\nto enhance model interpretability for microscopy image classification.\nExploiting benchmark datasets from three different microscopic image domains\n(plankton, yeast vacuoles, and human cells), we show how a DRL framework, based\non transferring a representation learnt from synthetic data, can provide a good\ntrade-off between accuracy and interpretability in this domain.", "AI": {"tldr": "提出了一种解耦表示学习方法（DRL），用于提高显微镜图像分类模型的可解释性，并在三个不同领域的显微镜图像数据集上验证了其效果。", "motivation": "显微镜图像分析在诊断、合成工程和环境监测等领域至关重要，但深度学习模型的可解释性仍是一个挑战。", "method": "采用解耦表示学习方法（DRL），通过从合成数据中学习表示并迁移到真实数据，以提高模型的可解释性。", "result": "在浮游生物、酵母液泡和人类细胞三个显微镜图像数据集上，DRL框架在准确性和可解释性之间取得了良好平衡。", "conclusion": "DRL方法为显微镜图像分类提供了一种兼具高准确性和可解释性的解决方案。"}}
{"id": "2506.20347", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.20347", "abs": "https://arxiv.org/abs/2506.20347", "authors": ["Malik Shahid Sultan", "Hernando Ombao"], "title": "On the ability of Deep Neural Networks to Learn Granger Causality in Multi-Variate Time Series Data", "comment": null, "summary": "Granger Causality (GC) offers an elegant statistical framework to study the\nassociation between multivariate time series data. Linear Vector Autoregressive\nmodels (VAR) though have nice interpretation properties but have limited\npractical application due to underlying assumptions on the kind of associations\nthat can be captured by these models. Numerous attempts have already been made\nin the literature that exploit the functional approximation power of Deep\nNeural Networks (DNNs) for the task of GC estimation. These methods however\ntreat GC as a variable selection problem. We present a novel paradigm for\napproaching GC. We present this idea that GC is essentially linked with\nprediction and if a deep learning model is used to model the time series\ncollectively or jointly, a well regularized model may learn the true granger\ncausal structure from the data, given that there is enough training data. We\npropose to uncover the learned GC structure by comparing the model uncertainty\nor distribution of the residuals when the past of everything is used as\ncompared to the one where a specific time series component is dropped from the\nmodel. We also compare the effect of input layer dropout on the ability of a\nneural network to learn granger causality from the data. We show that a well\nregularized model infact can learn the true GC structure from the data without\nexplicitly adding terms in the loss function that guide the model to select\nvariables or perform sparse regression.", "AI": {"tldr": "论文提出了一种基于深度学习的Granger因果关系（GC）估计新方法，通过模型不确定性和残差分布揭示GC结构，无需显式稀疏回归。", "motivation": "传统线性VAR模型在GC估计中受限于假设，而现有DNN方法将GC视为变量选择问题，未能充分利用预测能力。", "method": "利用深度神经网络联合建模时间序列，通过比较模型不确定性和残差分布（是否丢弃特定时间序列）来揭示GC结构。", "result": "研究表明，经过良好正则化的模型可以从数据中学习真实的GC结构，无需显式稀疏回归。", "conclusion": "深度学习方法可以更自然地捕捉GC结构，为GC估计提供了新视角。"}}
{"id": "2506.20670", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20670", "abs": "https://arxiv.org/abs/2506.20670", "authors": ["Jinming Wu", "Zihao Deng", "Wei Li", "Yiding Liu", "Bo You", "Bo Li", "Zejun Ma", "Ziwei Liu"], "title": "MMSearch-R1: Incentivizing LMMs to Search", "comment": "Code: https://github.com/EvolvingLMMs-Lab/multimodal-search-r1", "summary": "Robust deployment of large multimodal models (LMMs) in real-world scenarios\nrequires access to external knowledge sources, given the complexity and dynamic\nnature of real-world information. Existing approaches such as\nretrieval-augmented generation (RAG) and prompt engineered search agents rely\non rigid pipelines, often leading to inefficient or excessive search behaviors.\nWe present MMSearch-R1, the first end-to-end reinforcement learning framework\nthat enables LMMs to perform on-demand, multi-turn search in real-world\nInternet environments. Our framework integrates both image and text search\ntools, allowing the model to reason about when and how to invoke them guided by\nan outcome-based reward with a search penalty. To support training, We collect\na multimodal search VQA dataset through a semi-automated pipeline that covers\ndiverse visual and textual knowledge needs and curate a search-balanced subset\nwith both search-required and search-free samples, which proves essential for\nshaping efficient and on-demand search behavior. Extensive experiments on\nknowledge-intensive and info-seeking VQA tasks show that our model not only\noutperforms RAG-based baselines of the same model size, but also matches the\nperformance of a larger RAG-based model while reducing search calls by over\n30%. We further analyze key empirical findings to offer actionable insights for\nadvancing research in multimodal search.", "AI": {"tldr": "MMSearch-R1是一个基于强化学习的端到端框架，用于优化大型多模态模型在真实互联网环境中的多轮搜索行为。", "motivation": "现有方法（如RAG和提示工程搜索代理）依赖固定流程，导致搜索效率低下或过度搜索，无法满足动态复杂的真实世界信息需求。", "method": "提出MMSearch-R1框架，结合图像和文本搜索工具，通过基于结果的奖励和搜索惩罚机制指导模型决策。训练时使用半自动收集的多模态搜索VQA数据集。", "result": "在知识密集和信息寻求VQA任务中，MMSearch-R1优于同规模RAG基线，并减少30%以上的搜索调用，性能接近更大RAG模型。", "conclusion": "MMSearch-R1为多模态搜索研究提供了高效、按需的解决方案，并揭示了关键经验以推动未来研究。"}}
{"id": "2506.20353", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20353", "abs": "https://arxiv.org/abs/2506.20353", "authors": ["Xuan Ding", "Rui Sun", "Yunjian Zhang", "Xiu Yan", "Yueqi Zhou", "Kaihao Huang", "Suzhong Fu", "Chuanlong Xie", "Yao Zhu"], "title": "DipSVD: Dual-importance Protected SVD for Efficient LLM Compression", "comment": null, "summary": "The ever-increasing computational demands and deployment costs of large\nlanguage models (LLMs) have spurred numerous compressing methods. Compared to\nquantization and unstructured pruning, SVD compression offers superior hardware\ncompatibility and theoretical guarantees. However, existing SVD-based methods\nfocus on the overall discrepancy between the original and compressed matrices\nwhile overlooking the protection of critical components within the matrix,\nwhich leads to inferior performance in the compressed models. This paper\nproposes a dual-level importance protection mechanism to enhance SVD-based\ncompression methods: (1) local importance protection: preserving the most\ncritical singular vectors within each weight matrix through channel-weighted\ndata whitening; and (2) global importance protection: enabling less important\nlayers to bear a greater portion of the compression burden through either a\nheuristic or optimization-based approach, thereby minimizing the impact of\ncompression on critical layers. Extensive experiments demonstrate that DipSVD\noutperforms existing SVD-based compression approaches across multiple\nbenchmarks, achieving superior model performance especially at high model\ncompression ratios.", "AI": {"tldr": "本文提出了一种双级重要性保护机制（DipSVD），通过局部和全局重要性保护，优化SVD压缩方法，显著提升压缩模型的性能。", "motivation": "大型语言模型（LLMs）的计算需求和部署成本不断增加，现有SVD压缩方法忽视矩阵关键组件的保护，导致压缩模型性能下降。", "method": "提出双级重要性保护机制：局部保护通过通道加权数据白化保留关键奇异向量；全局保护通过启发式或优化方法分配压缩负担。", "result": "DipSVD在多个基准测试中优于现有SVD压缩方法，尤其在高压缩比下表现更优。", "conclusion": "DipSVD通过保护关键组件，显著提升了SVD压缩方法的性能，适用于高压缩比场景。"}}
{"id": "2506.20671", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20671", "abs": "https://arxiv.org/abs/2506.20671", "authors": ["Markus Gross", "Aya Fahmy", "Danit Niwattananan", "Dominik Muhle", "Rui Song", "Daniel Cremers", "Henri Meeß"], "title": "IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals", "comment": null, "summary": "Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointly\nlearning scene geometry and semantics, enabling downstream applications such as\nnavigation in mobile robotics. The recent generalization to Panoptic Scene\nCompletion (PSC) advances the SSC domain by integrating instance-level\ninformation, thereby enhancing object-level sensitivity in scene understanding.\nWhile PSC was introduced using LiDAR modality, methods based on camera images\nremain largely unexplored. Moreover, recent Transformer-based SSC approaches\nutilize a fixed set of learned queries to reconstruct objects within the scene\nvolume. Although these queries are typically updated with image context during\ntraining, they remain static at test time, limiting their ability to\ndynamically adapt specifically to the observed scene. To overcome these\nlimitations, we propose IPFormer, the first approach that leverages\ncontext-adaptive instance proposals at train and test time to address\nvision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptively\ninitializes these queries as panoptic instance proposals derived from image\ncontext and further refines them through attention-based encoding and decoding\nto reason about semantic instance-voxel relationships. Experimental results\nshow that our approach surpasses state-of-the-art methods in overall panoptic\nmetrics PQ$^\\dagger$ and PQ-All, matches performance in individual metrics, and\nachieves a runtime reduction exceeding 14$\\times$. Furthermore, our ablation\nstudies reveal that dynamically deriving instance proposals from image context,\nas opposed to random initialization, leads to a 3.62% increase in PQ-All and a\nremarkable average improvement of 18.65% in combined Thing-metrics. These\nresults highlight our introduction of context-adaptive instance proposals as a\npioneering effort in addressing vision-based 3D Panoptic Scene Completion.", "AI": {"tldr": "IPFormer提出了一种基于视觉的3D全景场景补全方法，通过动态实例提案提升场景理解能力。", "motivation": "解决现有方法在测试时静态查询的局限性，以及视觉模态在全景场景补全中的探索不足。", "method": "利用图像上下文动态初始化实例提案，并通过注意力机制编码和解码优化语义实例-体素关系。", "result": "在PQ$^\\dagger$和PQ-All指标上超越现有方法，运行时间减少14倍以上，动态提案带来显著性能提升。", "conclusion": "IPFormer通过动态实例提案，为视觉模态的全景场景补全提供了创新解决方案。"}}
{"id": "2506.20354", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20354", "abs": "https://arxiv.org/abs/2506.20354", "authors": ["Francesco Carzaniga", "Michael Hersche", "Abu Sebastian", "Kaspar Schindler", "Abbas Rahimi"], "title": "A foundation model with multi-variate parallel attention to generate neuronal activity", "comment": "The code is available at\n  https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\n  dataset is available at\n  https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg", "summary": "Learning from multi-variate time-series with heterogeneous channel\nconfigurations remains a fundamental challenge for deep neural networks (DNNs),\nparticularly in clinical domains such as intracranial electroencephalography\n(iEEG), where channel setups vary widely across subjects. In this work, we\nintroduce multi-variate parallel attention (MVPA), a novel self-attention\nmechanism that disentangles content, temporal, and spatial attention, enabling\nflexible, generalizable, and efficient modeling of time-series data with\nvarying channel counts and configurations. We use MVPA to build MVPFormer, a\ngenerative foundation model for human electrophysiology, trained to predict the\nevolution of iEEG signals across diverse subjects. To support this and future\neffort by the community, we release the SWEC iEEG dataset, the largest publicly\navailable iEEG dataset to date, comprising nearly 10,000 hours of recordings\nfrom heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong\ngeneralization across subjects, demonstrating expert-level performance in\nseizure detection and outperforming state-of-the-art Transformer baselines on\nour SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard\ntime-series forecasting and classification tasks, where it matches or exceeds\nexisting attention-based models. Together, our contributions establish MVPA as\na general-purpose attention mechanism for heterogeneous time-series and\nMVPFormer as the first open-source, open-weights, and open-data iEEG foundation\nmodel with state-of-the-art clinical performance. The code is available at\nhttps://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\ndataset is available at\nhttps://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.", "AI": {"tldr": "提出了一种多变量并行注意力机制（MVPA）和MVPFormer模型，用于处理多变量时间序列数据，特别是在iEEG领域，解决了通道配置异构性问题。", "motivation": "解决多变量时间序列数据中通道配置异构性对深度神经网络的挑战，特别是在临床iEEG领域。", "method": "引入MVPA机制，分离内容、时间和空间注意力，构建MVPFormer模型，并发布SWEC iEEG数据集。", "result": "MVPFormer在多个数据集上表现优异，达到专家级癫痫检测性能，并在标准时间序列任务上匹配或超越现有模型。", "conclusion": "MVPA是一种通用的异构时间序列注意力机制，MVPFormer是首个开源、开放权重的iEEG基础模型，具有先进的临床性能。"}}
{"id": "2506.20359", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20359", "abs": "https://arxiv.org/abs/2506.20359", "authors": ["Chanuka Don Samarasinghage", "Dhruv Gulabani"], "title": "Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach", "comment": null, "summary": "Trajectory analysis is not only about obtaining movement data, but it is also\nof paramount importance in understanding the pattern in which an object moves\nthrough space and time, as well as in predicting its next move. Due to the\nsignificant interest in the area, data collection has improved substantially,\nresulting in a large number of features becoming available for training and\npredicting models. However, this introduces a high-dimensionality-induced\nfeature explosion problem, which reduces the efficiency and interpretability of\nthe data, thereby reducing the accuracy of machine learning models. To overcome\nthis issue, feature selection has become one of the most prevalent tools. Thus,\nthe objective of this paper was to introduce a taxonomy-based feature selection\nmethod that categorizes features based on their internal structure. This\napproach classifies the data into geometric and kinematic features, further\ncategorizing them into curvature, indentation, speed, and acceleration. The\ncomparative analysis indicated that a taxonomy-based approach consistently\nachieved comparable or superior predictive performance. Furthermore, due to the\ntaxonomic grouping, which reduces combinatorial space, the time taken to select\nfeatures was drastically reduced. The taxonomy was also used to gain insights\ninto what feature sets each dataset was more sensitive to. Overall, this study\nprovides robust evidence that a taxonomy-based feature selection method can add\na layer of interpretability, reduce dimensionality and computational\ncomplexity, and contribute to high-level decision-making. It serves as a step\ntoward providing a methodological framework for researchers and practitioners\ndealing with trajectory datasets and contributing to the broader field of\nexplainable artificial intelligence.", "AI": {"tldr": "论文提出了一种基于分类学的特征选择方法，用于解决轨迹分析中的高维特征爆炸问题，提高模型效率和可解释性。", "motivation": "轨迹分析中高维特征导致模型效率降低和可解释性下降，需要一种有效的特征选择方法。", "method": "提出基于分类学的特征选择方法，将特征分为几何和运动学两类，并进一步细分为曲率、凹陷、速度和加速度。", "result": "分类学方法在预测性能上表现优异，显著减少特征选择时间，并提供了对数据集敏感性的洞察。", "conclusion": "分类学方法能降低维度、提高可解释性，为轨迹数据集研究提供方法论框架，推动可解释人工智能发展。"}}
{"id": "2506.20362", "categories": ["cs.LG", "cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2506.20362", "abs": "https://arxiv.org/abs/2506.20362", "authors": ["Lorenzo Bini", "Stephane Marchand-Maillet"], "title": "Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations", "comment": "LaplaceGNN is a novel graph learning framework that employs a\n  bootstrapped teacher-student architecture. Its precomputed spectral\n  augmentations and adversarial training enable robust performance,\n  outperforming SOTA methods while scaling linearly", "summary": "We present LaplaceGNN, a novel self-supervised graph learning framework that\nbypasses the need for negative sampling by leveraging spectral bootstrapping\ntechniques. Our method integrates Laplacian-based signals into the learning\nprocess, allowing the model to effectively capture rich structural\nrepresentations without relying on contrastive objectives or handcrafted\naugmentations. By focusing on positive alignment, LaplaceGNN achieves linear\nscaling while offering a simpler, more efficient, self-supervised alternative\nfor graph neural networks, applicable across diverse domains. Our contributions\nare twofold: we precompute spectral augmentations through max-min\ncentrality-guided optimization, enabling rich structural supervision without\nrelying on handcrafted augmentations, then we integrate an adversarial\nbootstrapped training scheme that further strengthens feature learning and\nrobustness. Our extensive experiments on different benchmark datasets show that\nLaplaceGNN achieves superior performance compared to state-of-the-art\nself-supervised graph methods, offering a promising direction for efficiently\nlearning expressive graph representations.", "AI": {"tldr": "LaplaceGNN是一种无需负采样的自监督图学习框架，通过谱自举技术实现高效学习。", "motivation": "传统图学习方法依赖负采样或手工增强，效率低且复杂。LaplaceGNN旨在简化流程并提升性能。", "method": "结合拉普拉斯信号和谱增强，采用对抗性自举训练方案，实现正对齐学习。", "result": "在多个基准数据集上优于现有自监督图学习方法。", "conclusion": "LaplaceGNN为高效学习图表示提供了新方向。"}}
{"id": "2506.20100", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20100", "abs": "https://arxiv.org/abs/2506.20100", "authors": ["Vardhan Dongre", "Chi Gui", "Shubham Garg", "Hooshang Nayyeri", "Gokhan Tur", "Dilek Hakkani-Tür", "Vikram S. Adve"], "title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations", "comment": "66 pages, 32 figures, 23 tables", "summary": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning\nand decision-making in consultative interaction settings. Designed for the\nagriculture domain, MIRAGE captures the full complexity of expert consultations\nby combining natural user queries, expert-authored responses, and image-based\ncontext, offering a high-fidelity benchmark for evaluating models on grounded\nreasoning, clarification strategies, and long-form generation in a real-world,\nknowledge-intensive domain. Grounded in over 35,000 real user-expert\ninteractions and curated through a carefully designed multi-step pipeline,\nMIRAGE spans diverse crop health, pest diagnosis, and crop management\nscenarios. The benchmark includes more than 7,000 unique biological entities,\ncovering plant species, pests, and diseases, making it one of the most\ntaxonomically diverse benchmarks available for vision-language models, grounded\nin the real world. Unlike existing benchmarks that rely on well-specified user\ninputs and closed-set taxonomies, MIRAGE features underspecified, context-rich\nscenarios with open-world settings, requiring models to infer latent knowledge\ngaps, handle rare entities, and either proactively guide the interaction or\nrespond. Project Page: https://mirage-benchmark.github.io", "AI": {"tldr": "MIRAGE是一个用于多模态专家级推理和决策的新基准，专注于农业领域，结合自然用户查询、专家回答和图像上下文，评估模型的推理、澄清策略和长文本生成能力。", "motivation": "现有基准通常依赖明确输入和封闭分类，无法满足真实世界中复杂、开放场景的需求。MIRAGE旨在填补这一空白，提供高保真度的评估工具。", "method": "基于35,000+真实用户-专家交互数据，通过多步骤流程构建，涵盖作物健康、害虫诊断和管理场景，包含7,000+生物实体。", "result": "MIRAGE成为视觉语言模型中分类最多样化的基准之一，支持开放世界场景和罕见实体处理。", "conclusion": "MIRAGE为知识密集型领域的多模态模型提供了更真实的评估环境，推动了复杂推理和交互能力的研究。"}}
{"id": "2506.20380", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20380", "abs": "https://arxiv.org/abs/2506.20380", "authors": ["Zhengpeng Feng", "Sadiq Jaffer", "Jovana Knezevic", "Silja Sormunen", "Robin Young", "Madeline Lisaius", "Markus Immitzer", "James Ball", "Clement Atzberger", "David A. Coomes", "Anil Madhavapeddy", "Andrew Blake", "Srinivasan Keshav"], "title": "TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis", "comment": null, "summary": "Satellite remote sensing (RS) enables a wide array of downstream Earth\nobservation (EO) applications, including climate modeling, carbon accounting,\nand strategies for conservation and sustainable land use. We present TESSERA, a\nnovel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning\n(SSL) to generate global, robust representations at 10m scale from pixel-level\nsatellite time series data. TESSERA combines information from only optical and\nSAR data streams using two parallel Transformer-based encoders: one dedicated\nto Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected\nspectral bands) to create representations that are then fused using a\nmultilayer perceptron (MLP), resulting in a global representation map covering\nthe years 2017 to 2024. Our precomputed representations set a new\nstate-of-the-art performance benchmark and our open-source approach\ndemocratizes access to high-performance, high-resolution representations. We\nbenchmark the performance of TESSERA in five diverse tasks, comparing our work\nwith state-of-the-art task-specific models and other foundation models. Our\nresults show that TESSERA outperforms both traditional RS baselines and the\nleading geospatial foundation models in these diverse downstream tasks.", "AI": {"tldr": "TESSERA是一种新型遥感基础模型，通过自监督学习从卫星时间序列数据生成全球10米尺度的稳健表示，结合光学和SAR数据，性能优于现有模型。", "motivation": "卫星遥感在气候建模、碳核算等领域有广泛应用，但需要高性能、高分辨率的表示方法。", "method": "TESSERA使用两个并行Transformer编码器分别处理Sentinel-1 SAR和Sentinel-2 MSI数据，通过MLP融合生成全球表示。", "result": "TESSERA在五项任务中表现优于传统遥感基线和领先的地理空间基础模型。", "conclusion": "TESSERA为高分辨率遥感表示提供了开源解决方案，性能领先。"}}
{"id": "2506.20413", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20413", "abs": "https://arxiv.org/abs/2506.20413", "authors": ["Mohammad Mahdi Maheri", "Denys Herasymuk", "Hamed Haddadi"], "title": "Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning", "comment": null, "summary": "The growing adoption of Artificial Intelligence (AI) in Internet of Things\n(IoT) ecosystems has intensified the need for personalized learning methods\nthat can operate efficiently and privately across heterogeneous,\nresource-constrained devices. However, enabling effective personalized learning\nin decentralized settings introduces several challenges, including efficient\nknowledge transfer between clients, protection of data privacy, and resilience\nagainst poisoning attacks. In this paper, we address these challenges by\ndeveloping P4 (Personalized, Private, Peer-to-Peer) -- a method designed to\ndeliver personalized models for resource-constrained IoT devices while ensuring\ndifferential privacy and robustness against poisoning attacks. Our solution\nemploys a lightweight, fully decentralized algorithm to privately detect client\nsimilarity and form collaborative groups. Within each group, clients leverage\ndifferentially private knowledge distillation to co-train their models,\nmaintaining high accuracy while ensuring robustness to the presence of\nmalicious clients. We evaluate P4 on popular benchmark datasets using both\nlinear and CNN-based architectures across various heterogeneity settings and\nattack scenarios. Experimental results show that P4 achieves 5% to 30% higher\naccuracy than leading differentially private peer-to-peer approaches and\nmaintains robustness with up to 30% malicious clients. Additionally, we\ndemonstrate its practicality by deploying it on resource-constrained devices,\nwhere collaborative training between two clients adds only ~7 seconds of\noverhead.", "AI": {"tldr": "P4是一种针对资源受限物联网设备的个性化学习方法，通过去中心化算法确保隐私和抗攻击性，实验显示其性能优于现有方法。", "motivation": "AI在IoT中的广泛应用需要高效、隐私保护的个性化学习方法，但去中心化环境下的知识转移、隐私保护和抗攻击性仍是挑战。", "method": "P4采用轻量级去中心化算法，通过差分隐私知识蒸馏在协作组内共同训练模型，确保隐私和抗攻击性。", "result": "P4在多种异构和攻击场景下比现有方法准确率高5%至30%，并能容忍30%的恶意客户端。", "conclusion": "P4为资源受限设备提供了一种高效、隐私保护且抗攻击的个性化学习解决方案。"}}
{"id": "2506.20417", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20417", "abs": "https://arxiv.org/abs/2506.20417", "authors": ["Tatsuhiro Shimizu", "Kazuki Kawamura", "Takanori Muroi", "Yusuke Narita", "Kei Tateno", "Takuma Udagawa", "Yuta Saito"], "title": "Off-Policy Evaluation and Learning for the Future under Non-Stationarity", "comment": null, "summary": "We study the novel problem of future off-policy evaluation (F-OPE) and\nlearning (F-OPL) for estimating and optimizing the future value of policies in\nnon-stationary environments, where distributions vary over time. In e-commerce\nrecommendations, for instance, our goal is often to estimate and optimize the\npolicy value for the upcoming month using data collected by an old policy in\nthe previous month. A critical challenge is that data related to the future\nenvironment is not observed in the historical data. Existing methods assume\nstationarity or depend on restrictive reward-modeling assumptions, leading to\nsignificant bias. To address these limitations, we propose a novel estimator\nnamed \\textit{\\textbf{O}ff-\\textbf{P}olicy Estimator for the \\textbf{F}uture\n\\textbf{V}alue (\\textbf{\\textit{OPFV}})}, designed for accurately estimating\npolicy values at any future time point. The key feature of OPFV is its ability\nto leverage the useful structure within time-series data. While future data\nmight not be present in the historical log, we can leverage, for example,\nseasonal, weekly, or holiday effects that are consistent in both the historical\nand future data. Our estimator is the first to exploit these time-related\nstructures via a new type of importance weighting, enabling effective F-OPE.\nTheoretical analysis identifies the conditions under which OPFV becomes\nlow-bias. In addition, we extend our estimator to develop a new policy-gradient\nmethod to proactively learn a good future policy using only historical data.\nEmpirical results show that our methods substantially outperform existing\nmethods in estimating and optimizing the future policy value under\nnon-stationarity for various experimental setups.", "AI": {"tldr": "论文提出了一种名为OPFV的新估计器，用于在非平稳环境中准确估计和优化未来策略价值，利用时间序列数据中的结构信息，显著优于现有方法。", "motivation": "在非平稳环境中（如电子商务推荐系统），现有方法因假设平稳性或依赖限制性奖励建模假设而产生显著偏差，无法准确估计未来策略价值。", "method": "提出OPFV估计器，通过新型重要性加权利用时间序列数据中的结构（如季节性、周效应等），并扩展为策略梯度方法以优化未来策略。", "result": "理论分析表明OPFV在特定条件下具有低偏差，实验结果显示其在非平稳环境中显著优于现有方法。", "conclusion": "OPFV为未来策略评估和学习提供了有效工具，尤其在非平稳环境中表现优异。"}}
{"id": "2506.20431", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20431", "abs": "https://arxiv.org/abs/2506.20431", "authors": ["Xing Ma"], "title": "Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation", "comment": "33pages,8figures", "summary": "Federated learning aims to train a global model in a distributed environment\nthat is close to the performance of centralized training. However, issues such\nas client label skew, data quantity skew, and other heterogeneity problems\nseverely degrade the model's performance. Most existing methods overlook the\nscenario where only a small portion of clients participate in training within a\nlarge-scale client setting, whereas our experiments show that this scenario\npresents a more challenging federated learning task. Therefore, we propose a\nKnowledge Distillation with teacher-student Inequitable Aggregation (KDIA)\nstrategy tailored to address the federated learning setting mentioned above,\nwhich can effectively leverage knowledge from all clients. In KDIA, the student\nmodel is the average aggregation of the participating clients, while the\nteacher model is formed by a weighted aggregation of all clients based on three\nfrequencies: participation intervals, participation counts, and data volume\nproportions. During local training, self-knowledge distillation is performed.\nAdditionally, we utilize a generator trained on the server to generate\napproximately independent and identically distributed (IID) data features\nlocally for auxiliary training. We conduct extensive experiments on the\nCIFAR-10/100/CINIC-10 datasets and various heterogeneous settings to evaluate\nKDIA. The results show that KDIA can achieve better accuracy with fewer rounds\nof training, and the improvement is more significant under severe\nheterogeneity.", "AI": {"tldr": "提出了一种名为KDIA的知识蒸馏策略，针对大规模客户端中仅部分参与训练的联邦学习场景，通过教师-学生不平等聚合和生成IID数据特征，显著提升了模型性能。", "motivation": "解决联邦学习中因客户端标签倾斜、数据量倾斜等异构性问题导致的性能下降，特别是在大规模客户端中仅部分参与训练的挑战性场景。", "method": "采用教师-学生不平等聚合（KDIA），学生模型为参与客户端的平均聚合，教师模型为基于参与频率、参与次数和数据量比例的加权聚合；结合本地自知识蒸馏和服务器生成IID数据特征辅助训练。", "result": "在CIFAR-10/100/CINIC-10数据集及多种异构设置下，KDIA能以更少训练轮次获得更高准确率，且在严重异构性下改进更显著。", "conclusion": "KDIA是一种高效的联邦学习策略，特别适用于大规模客户端中部分参与的场景，能有效利用所有客户端知识提升模型性能。"}}
{"id": "2506.20441", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20441", "abs": "https://arxiv.org/abs/2506.20441", "authors": ["Antoine Caradot", "Rémi Emonet", "Amaury Habrard", "Abdel-Rahim Mezidi", "Marc Sebban"], "title": "Méthode de quadrature pour les PINNs fondée théoriquement sur la hessienne des résiduels", "comment": "10 pages. In French. Comments are welcome", "summary": "Physics-informed Neural Networks (PINNs) have emerged as an efficient way to\nlearn surrogate neural solvers of PDEs by embedding the physical model in the\nloss function and minimizing its residuals using automatic differentiation at\nso-called collocation points. Originally uniformly sampled, the choice of the\nlatter has been the subject of recent advances leading to adaptive sampling\nrefinements. In this paper, we propose a new quadrature method for\napproximating definite integrals based on the hessian of the considered\nfunction, and that we leverage to guide the selection of the collocation points\nduring the training process of PINNs.", "AI": {"tldr": "本文提出了一种基于Hessian矩阵的积分方法，用于优化PINNs中配点的选择。", "motivation": "传统PINNs中配点均匀采样，效率不高，需改进配点选择方法以提高求解精度。", "method": "提出基于Hessian矩阵的积分方法，用于指导PINNs训练过程中配点的选择。", "result": "新方法能更高效地选择配点，提升PINNs的求解性能。", "conclusion": "基于Hessian的积分方法为PINNs配点选择提供了新思路，具有潜在应用价值。"}}
{"id": "2506.20451", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20451", "abs": "https://arxiv.org/abs/2506.20451", "authors": ["Shuchu Han", "Wolfgang Bruckner"], "title": "Automatic Demonstration Selection for LLM-based Tabular Data Classification", "comment": null, "summary": "A fundamental question in applying In-Context Learning (ICL) for tabular data\nclassification is how to determine the ideal number of demonstrations in the\nprompt. This work addresses this challenge by presenting an algorithm to\nautomatically select a reasonable number of required demonstrations. Our method\ndistinguishes itself by integrating not only the tabular data's distribution\nbut also the user's selected prompt template and the specific Large Language\nModel (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed\nalgorithm defines a novel metric to quantify the similarities between different\ndemonstrations. We then construct a similarity graph and analyze the\neigenvalues of its Laplacian to derive the minimum number of demonstrations\ncapable of representing the data within the LLM's intrinsic representation\nspace. We validate the efficacy of our approach through experiments comparing\nits performance against conventional random selection algorithms on diverse\ndatasets and LLMs.", "AI": {"tldr": "提出一种基于谱图理论的算法，自动选择适合表格数据分类的上下文学习演示数量。", "motivation": "解决在表格数据分类中如何确定上下文学习演示数量的挑战。", "method": "结合数据分布、用户选择的提示模板和特定大语言模型，利用谱图理论量化演示相似性，构建相似图并通过拉普拉斯矩阵特征值分析确定最小演示数量。", "result": "实验验证了该方法在多样数据集和大语言模型上优于传统随机选择算法。", "conclusion": "该算法能有效确定上下文学习中的演示数量，提升分类性能。"}}
{"id": "2506.20481", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20481", "abs": "https://arxiv.org/abs/2506.20481", "authors": ["Matthieu Meeus", "Igor Shilov", "Georgios Kaissis", "Yves-Alexandre de Montjoye"], "title": "Counterfactual Influence as a Distributional Quantity", "comment": "Workshop on The Impact of Memorization on Trustworthy Foundation\n  Models (MemFM) @ ICML 2025", "summary": "Machine learning models are known to memorize samples from their training\ndata, raising concerns around privacy and generalization. Counterfactual\nself-influence is a popular metric to study memorization, quantifying how the\nmodel's prediction for a sample changes depending on the sample's inclusion in\nthe training dataset. However, recent work has shown memorization to be\naffected by factors beyond self-influence, with other training samples, in\nparticular (near-)duplicates, having a large impact. We here study memorization\ntreating counterfactual influence as a distributional quantity, taking into\naccount how all training samples influence how a sample is memorized. For a\nsmall language model, we compute the full influence distribution of training\nsamples on each other and analyze its properties. We find that solely looking\nat self-influence can severely underestimate tangible risks associated with\nmemorization: the presence of (near-)duplicates seriously reduces\nself-influence, while we find these samples to be (near-)extractable. We\nobserve similar patterns for image classification, where simply looking at the\ninfluence distributions reveals the presence of near-duplicates in CIFAR-10.\nOur findings highlight that memorization stems from complex interactions across\ntraining data and is better captured by the full influence distribution than by\nself-influence alone.", "AI": {"tldr": "研究探讨了机器学习模型记忆训练数据的机制，指出仅依赖自影响（self-influence）会低估记忆化风险，需考虑完整影响分布。", "motivation": "机器学习模型记忆训练数据引发隐私和泛化问题，现有研究多关注自影响，但忽略了其他样本（如重复样本）的影响。", "method": "通过计算训练样本间的完整影响分布，分析其对记忆化的作用，并在小语言模型和CIFAR-10图像分类任务中验证。", "result": "发现仅关注自影响会低估风险，重复样本显著降低自影响但仍可被提取；影响分布能揭示重复样本的存在。", "conclusion": "记忆化是训练数据间复杂互动的结果，完整影响分布比自影响更能准确捕捉其机制。"}}
{"id": "2506.20494", "categories": ["cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.20494", "abs": "https://arxiv.org/abs/2506.20494", "authors": ["Qihang Jin", "Enze Ge", "Yuhang Xie", "Hongying Luo", "Junhao Song", "Ziqian Bi", "Chia Xin Liang", "Jibin Guan", "Joe Yeong", "Junfeng Hao"], "title": "Multimodal Representation Learning and Fusion", "comment": null, "summary": "Multi-modal learning is a fast growing area in artificial intelligence. It\ntries to help machines understand complex things by combining information from\ndifferent sources, like images, text, and audio. By using the strengths of each\nmodality, multi-modal learning allows AI systems to build stronger and richer\ninternal representations. These help machines better interpretation, reasoning,\nand making decisions in real-life situations. This field includes core\ntechniques such as representation learning (to get shared features from\ndifferent data types), alignment methods (to match information across\nmodalities), and fusion strategies (to combine them by deep learning models).\nAlthough there has been good progress, some major problems still remain. Like\ndealing with different data formats, missing or incomplete inputs, and\ndefending against adversarial attacks. Researchers now are exploring new\nmethods, such as unsupervised or semi-supervised learning, AutoML tools, to\nmake models more efficient and easier to scale. And also more attention on\ndesigning better evaluation metrics or building shared benchmarks, make it\neasier to compare model performance across tasks and domains. As the field\ncontinues to grow, multi-modal learning is expected to improve many areas:\ncomputer vision, natural language processing, speech recognition, and\nhealthcare. In the future, it may help to build AI systems that can understand\nthe world in a way more like humans, flexible, context aware, and able to deal\nwith real-world complexity.", "AI": {"tldr": "多模态学习是人工智能中快速发展的领域，通过结合图像、文本和音频等信息，帮助机器理解复杂事物，提升解释、推理和决策能力。", "motivation": "多模态学习旨在利用不同模态的优势，构建更强、更丰富的内部表示，以应对现实世界的复杂性。", "method": "核心方法包括表示学习、对齐方法和融合策略，同时探索无监督或半监督学习、AutoML工具等新方法。", "result": "尽管取得进展，但仍需解决数据格式差异、输入缺失和对抗攻击等问题。", "conclusion": "多模态学习有望推动计算机视觉、自然语言处理等领域发展，未来或能构建更接近人类理解的AI系统。"}}
{"id": "2506.20511", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.20511", "abs": "https://arxiv.org/abs/2506.20511", "authors": ["Arno Geimer", "Karthick Panner Selvam", "Beltran Fiz Pontiveros"], "title": "Collaborative Batch Size Optimization for Federated Learning", "comment": null, "summary": "Federated Learning (FL) is a decentralized collaborative Machine Learning\nframework for training models without collecting data in a centralized\nlocation. It has seen application across various disciplines, from helping\nmedical diagnoses in hospitals to detecting fraud in financial transactions. In\nthis paper, we focus on improving the local training process through hardware\nusage optimization. While participants in a federation might share the hardware\nthey are training on, since there is no information exchange between them,\ntheir training process can be hindered by an improper training configuration.\nTaking advantage of the parallel processing inherent to Federated Learning, we\nuse a greedy randomized search to optimize local batch sizes for the best\ntraining settings across all participants. Our results show that against\ndefault parameter settings, our method improves convergence speed while staying\nnearly on par with the case where local parameters are optimized.", "AI": {"tldr": "论文提出了一种通过贪婪随机搜索优化联邦学习中本地批量大小的方法，以提高训练效率。", "motivation": "联邦学习中的参与者可能因硬件配置不当而影响训练效果，本文旨在通过优化本地批量大小解决这一问题。", "method": "利用联邦学习的并行处理特性，采用贪婪随机搜索优化本地批量大小。", "result": "相比默认参数设置，该方法提高了收敛速度，且性能接近本地参数优化的情况。", "conclusion": "优化本地批量大小是提升联邦学习训练效率的有效方法。"}}
{"id": "2506.20518", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20518", "abs": "https://arxiv.org/abs/2506.20518", "authors": ["Arno Geimer", "Beltran Fiz Pontiveros", "Radu State"], "title": "WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning", "comment": null, "summary": "Federated Learning (FL) is a collaborative machine learning paradigm which\nallows participants to collectively train a model while training data remains\nprivate. This paradigm is especially beneficial for sectors like finance, where\ndata privacy, security and model performance are paramount. FL has been\nextensively studied in the years following its introduction, leading to, among\nothers, better performing collaboration techniques, ways to defend against\nother clients trying to attack the model, and contribution assessment methods.\nAn important element in for-profit Federated Learning is the development of\nincentive methods to determine the allocation and distribution of rewards for\nparticipants. While numerous methods for allocation have been proposed and\nthoroughly explored, distribution frameworks remain relatively understudied. In\nthis paper, we propose a novel framework which introduces client-specific\ntokens as investment vehicles within the FL ecosystem. Our framework aims to\naddress the limitations of existing incentive schemes by leveraging a\ndecentralized finance (DeFi) platform and automated market makers (AMMs) to\ncreate a more flexible and scalable reward distribution system for\nparticipants, and a mechanism for third parties to invest in the federation\nlearning process.", "AI": {"tldr": "本文提出了一种基于去中心化金融（DeFi）和自动化做市商（AMM）的新型联邦学习激励机制框架，旨在解决现有激励方案的局限性。", "motivation": "在联邦学习中，激励机制对参与者至关重要，但现有的分配框架研究不足，限制了其灵活性和可扩展性。", "method": "提出了一种利用DeFi平台和AMM的框架，通过客户端特定代币作为投资工具，优化奖励分配。", "result": "该框架为参与者提供了更灵活的奖励分配系统，并允许第三方投资联邦学习过程。", "conclusion": "该框架为联邦学习的激励机制提供了创新解决方案，增强了其灵活性和可扩展性。"}}
{"id": "2506.20520", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20520", "abs": "https://arxiv.org/abs/2506.20520", "authors": ["Charles Arnal", "Gaëtan Narozniak", "Vivien Cabannes", "Yunhao Tang", "Julia Kempe", "Remi Munos"], "title": "Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards", "comment": null, "summary": "Reinforcement learning (RL) is increasingly used to align large language\nmodels (LLMs). Off-policy methods offer greater implementation simplicity and\ndata efficiency than on-policy techniques, but often result in suboptimal\nperformance. In this work, we study the intermediate range of algorithms\nbetween off-policy RL and supervised fine-tuning by analyzing a simple\noff-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with\n$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$\nemphasizes high-reward samples, while raising it penalizes low-reward ones more\nheavily. We first provide a theoretical analysis of this off-policy REINFORCE\nalgorithm, showing that when the baseline $V$ lower-bounds the expected reward,\nthe algorithm enjoys a policy improvement guarantee. Our analysis reveals that\nwhile on-policy updates can safely leverage both positive and negative signals,\noff-policy updates benefit from focusing more on positive rewards than on\nnegative ones. We validate our findings experimentally in a controlled\nstochastic bandit setting and through fine-tuning state-of-the-art LLMs on\nreasoning tasks.", "AI": {"tldr": "论文研究了介于离策略强化学习和监督微调之间的算法，通过分析简单的离策略REINFORCE算法，探讨了基线V对性能的影响。", "motivation": "离策略方法在实现简单性和数据效率上优于同策略方法，但性能常不理想。本文旨在探索中间范围的算法，以优化性能。", "method": "分析了一种简单的离策略REINFORCE算法，其中优势定义为A=r-V，并通过理论分析和实验验证其效果。", "result": "理论分析表明，当基线V低于预期奖励时，算法具有策略改进保证。实验验证了离策略更新更应关注正向奖励。", "conclusion": "离策略更新应更注重正向奖励，而非负向信号，这一发现为优化强化学习对齐大语言模型提供了新思路。"}}
{"id": "2506.20537", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20537", "abs": "https://arxiv.org/abs/2506.20537", "authors": ["R. Sharma", "M. Raissi", "Y. B. Guo"], "title": "Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion", "comment": null, "summary": "Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process\nprediction due to the lasting issue of high computation cost using traditional\nnumerical methods such as finite element analysis (FEA). This study presents an\nefficient modeling framework termed FEA-Regulated Physics-Informed Neural\nNetwork (FEA-PINN) to accelerate the thermal field prediction in a LPBF process\nwhile maintaining the FEA accuracy. A novel dynamic material updating strategy\nis developed to capture the dynamic phase change of powder-liquid-solid in the\nPINN model. The PINN model incorporates temperature-dependent material\nproperties and phase change behavior using the apparent heat capacity method.\nWhile the PINN model demonstrates high accuracy with a small training data and\nenables generalization of new process parameters via transfer learning, it\nfaces the challenge of high computation cost in time-dependent problems due to\nthe residual accumulation. To overcome this issue, the FEA-PINN framework\nintegrates corrective FEA simulations during inference to enforce physical\nconsistency and reduce error drift. A comparative analysis shows that FEA-PINN\nachieves equivalent accuracy to FEA while significantly reducing computational\ncost. The framework has been validated using the benchmark FEA data and\ndemonstrated through single-track scanning in LPBF.", "AI": {"tldr": "提出了一种名为FEA-PINN的高效建模框架，用于加速激光粉末床熔融（LPBF）过程中的热场预测，同时保持FEA的精度。", "motivation": "传统数值方法（如FEA）计算成本高，阻碍了LPBF过程的高效模拟。", "method": "结合FEA和物理信息神经网络（PINN），开发动态材料更新策略以捕捉相变行为，并通过校正FEA模拟减少误差漂移。", "result": "FEA-PINN在保持与FEA相同精度的同时，显著降低了计算成本。", "conclusion": "FEA-PINN框架为LPBF过程的高效模拟提供了可行方案，具有推广潜力。"}}
{"id": "2506.20543", "categories": ["cs.LG", "math.OC", "60K25, 93E35"], "pdf": "https://arxiv.org/pdf/2506.20543", "abs": "https://arxiv.org/abs/2506.20543", "authors": ["Sanne van Kempen", "Jaron Sanders", "Fiona Sloothaak", "Maarten G. Wolf"], "title": "Demonstration of effective UCB-based routing in skill-based queues on real-world data", "comment": null, "summary": "This paper is about optimally controlling skill-based queueing systems such\nas data centers, cloud computing networks, and service systems. By means of a\ncase study using a real-world data set, we investigate the practical\nimplementation of a recently developed reinforcement learning algorithm for\noptimal customer routing. Our experiments show that the algorithm efficiently\nlearns and adapts to changing environments and outperforms static benchmark\npolicies, indicating its potential for live implementation. We also augment the\nreal-world applicability of this algorithm by introducing a new heuristic\nrouting rule to reduce delays. Moreover, we show that the algorithm can\noptimize for multiple objectives: next to payoff maximization, secondary\nobjectives such as server load fairness and customer waiting time reduction can\nbe incorporated. Tuning parameters are used for balancing inherent performance\ntrade--offs. Lastly, we investigate the sensitivity to estimation errors and\nparameter tuning, providing valuable insights for implementing adaptive routing\nalgorithms in complex real-world queueing systems.", "AI": {"tldr": "本文研究了基于技能的排队系统（如数据中心、云计算网络和服务系统）的最优控制，通过真实数据集验证了一种强化学习算法在客户路由中的实际应用效果。", "motivation": "研究动机是探索如何在实际环境中高效实现强化学习算法以优化客户路由，并提升系统性能。", "method": "方法包括使用真实数据集进行案例研究，引入新的启发式路由规则以减少延迟，并优化多目标（如收益最大化、服务器负载公平性和客户等待时间减少）。", "result": "实验表明，该算法能高效学习并适应动态环境，优于静态基准策略，同时能平衡性能权衡。", "conclusion": "结论是该算法具有实际应用潜力，但需注意参数调优和估计误差的敏感性。"}}
{"id": "2506.20574", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2506.20574", "abs": "https://arxiv.org/abs/2506.20574", "authors": ["Laura Boggia", "Rafael Teixeira de Lima", "Bogdan Malaescu"], "title": "Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series", "comment": "Submitted to VLDB 2026 conference, currently under review", "summary": "Anomaly detection in multivariate time series is an important problem across\nvarious fields such as healthcare, financial services, manufacturing or physics\ndetector monitoring. Accurately identifying when unexpected errors or faults\noccur is essential, yet challenging, due to the unknown nature of anomalies and\nthe complex interdependencies between time series dimensions. In this paper, we\ninvestigate transformer-based approaches for time series anomaly detection,\nfocusing on the recently proposed iTransformer architecture. Our contributions\nare fourfold: (i) we explore the application of the iTransformer to time series\nanomaly detection, and analyse the influence of key parameters such as window\nsize, step size, and model dimensions on performance; (ii) we examine methods\nfor extracting anomaly labels from multidimensional anomaly scores and discuss\nappropriate evaluation metrics for such labels; (iii) we study the impact of\nanomalous data present during training and assess the effectiveness of\nalternative loss functions in mitigating their influence; and (iv) we present a\ncomprehensive comparison of several transformer-based models across a diverse\nset of datasets for time series anomaly detection.", "AI": {"tldr": "本文研究了基于Transformer的多变量时间序列异常检测方法，重点分析了iTransformer架构的应用及其性能影响因素，并提出了异常标签提取和评估方法。", "motivation": "多变量时间序列异常检测在多个领域至关重要，但由于异常未知性和时间序列维度间的复杂依赖关系，准确检测异常具有挑战性。", "method": "采用iTransformer架构，研究了窗口大小、步长和模型维度等参数对性能的影响，并探讨了异常标签提取方法和评估指标。", "result": "分析了异常数据对训练的影响，评估了替代损失函数的有效性，并对多种Transformer模型在不同数据集上进行了全面比较。", "conclusion": "iTransformer在多变量时间序列异常检测中表现出潜力，参数选择和异常标签处理对性能有显著影响。"}}
{"id": "2506.20575", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20575", "abs": "https://arxiv.org/abs/2506.20575", "authors": ["Itay Niv", "Neta Rabin"], "title": "Exploring Graph-Transformer Out-of-Distribution Generalization Abilities", "comment": null, "summary": "Deep learning on graphs has shown remarkable success across numerous\napplications, including social networks, bio-physics, traffic networks, and\nrecommendation systems. Regardless of their successes, current methods\nfrequently depend on the assumption that training and testing data share the\nsame distribution, a condition rarely met in real-world scenarios. While\ngraph-transformer (GT) backbones have recently outperformed traditional\nmessage-passing neural networks (MPNNs) in multiple in-distribution (ID)\nbenchmarks, their effectiveness under distribution shifts remains largely\nunexplored.\n  In this work, we address the challenge of out-of-distribution (OOD)\ngeneralization for graph neural networks, with a special focus on the impact of\nbackbone architecture. We systematically evaluate GT and hybrid backbones in\nOOD settings and compare them to MPNNs. To do so, we adapt several leading\ndomain generalization (DG) algorithms to work with GTs and assess their\nperformance on a benchmark designed to test a variety of distribution shifts.\nOur results reveal that GT and hybrid GT-MPNN backbones consistently\ndemonstrate stronger generalization ability compared to MPNNs, even without\nspecialized DG algorithms.\n  Additionally, we propose a novel post-training analysis approach that\ncompares the clustering structure of the entire ID and OOD test datasets,\nspecifically examining domain alignment and class separation. Demonstrating its\nmodel-agnostic design, this approach not only provided meaningful insights into\nGT and MPNN backbones. It also shows promise for broader applicability to DG\nproblems beyond graph learning, offering a deeper perspective on generalization\nabilities that goes beyond standard accuracy metrics. Together, our findings\nhighlight the promise of graph-transformers for robust, real-world graph\nlearning and set a new direction for future research in OOD generalization.", "AI": {"tldr": "该论文探讨了图神经网络在分布外（OOD）泛化中的表现，重点比较了图变换器（GT）和混合GT-MPNN架构与传统MPNNs的效果，并提出了一种新的后训练分析方法。", "motivation": "现实场景中训练和测试数据分布通常不一致，而现有图学习方法大多假设分布相同。论文旨在探索GT和混合架构在OOD泛化中的潜力。", "method": "系统评估GT和混合GT-MPNN在OOD设置下的表现，并对比MPNNs。同时提出一种新的后训练分析方法，分析ID和OOD数据的聚类结构。", "result": "GT和混合GT-MPNN在OOD泛化中表现优于MPNNs，且无需专门域泛化算法。后训练分析方法提供了对泛化能力的深入见解。", "conclusion": "图变换器在现实图学习中具有潜力，为OOD泛化研究提供了新方向。"}}
{"id": "2506.20584", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20584", "abs": "https://arxiv.org/abs/2506.20584", "authors": ["Mariano Tepper", "Ted Willke"], "title": "The kernel of graph indices for vector search", "comment": null, "summary": "The most popular graph indices for vector search use principles from\ncomputational geometry to build the graph. Hence, their formal graph\nnavigability guarantees are only valid in Euclidean space. In this work, we\nshow that machine learning can be used to build graph indices for vector search\nin metric and non-metric vector spaces (e.g., for inner product similarity).\nFrom this novel perspective, we introduce the Support Vector Graph (SVG), a new\ntype of graph index that leverages kernel methods to establish the graph\nconnectivity and that comes with formal navigability guarantees valid in metric\nand non-metric vector spaces. In addition, we interpret the most popular graph\nindices, including HNSW and DiskANN, as particular specializations of SVG and\nshow that new indices can be derived from the principles behind this\nspecialization. Finally, we propose SVG-L0 that incorporates an $\\ell_0$\nsparsity constraint into the SVG kernel method to build graphs with a bounded\nout-degree. This yields a principled way of implementing this practical\nrequirement, in contrast to the traditional heuristic of simply truncating the\nout edges of each node. Additionally, we show that SVG-L0 has a self-tuning\nproperty that avoids the heuristic of using a set of candidates to find the\nout-edges of each node and that keeps its computational complexity in check.", "AI": {"tldr": "论文提出了一种基于机器学习的图索引方法（SVG），适用于度量和非度量向量空间，并引入SVG-L0以限制出度。", "motivation": "传统图索引的导航保证仅适用于欧几里得空间，而机器学习可以扩展其适用范围。", "method": "利用核方法建立图连接性，提出SVG和SVG-L0（带稀疏约束）。", "result": "SVG-L0具有自调优特性，避免了启发式方法，并保持计算复杂度可控。", "conclusion": "SVG为图索引提供了新的理论基础，并展示了传统方法的特例化。"}}
{"id": "2506.20607", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20607", "abs": "https://arxiv.org/abs/2506.20607", "authors": ["Jasen Lai", "Senwei Liang", "Chunmei Wang"], "title": "H-FEX: A Symbolic Learning Method for Hamiltonian Systems", "comment": "16 pages, 7 figures", "summary": "Hamiltonian systems describe a broad class of dynamical systems governed by\nHamiltonian functions, which encode the total energy and dictate the evolution\nof the system. Data-driven approaches, such as symbolic regression and neural\nnetwork-based methods, provide a means to learn the governing equations of\ndynamical systems directly from observational data of Hamiltonian systems.\nHowever, these methods often struggle to accurately capture complex Hamiltonian\nfunctions while preserving energy conservation. To overcome this limitation, we\npropose the Finite Expression Method for learning Hamiltonian Systems (H-FEX),\na symbolic learning method that introduces novel interaction nodes designed to\ncapture intricate interaction terms effectively. Our experiments, including\nthose on highly stiff dynamical systems, demonstrate that H-FEX can recover\nHamiltonian functions of complex systems that accurately capture system\ndynamics and preserve energy over long time horizons. These findings highlight\nthe potential of H-FEX as a powerful framework for discovering closed-form\nexpressions of complex dynamical systems.", "AI": {"tldr": "H-FEX是一种符号学习方法，用于从观测数据中学习哈密顿系统的控制方程，能有效捕捉复杂相互作用并保持能量守恒。", "motivation": "现有数据驱动方法难以准确捕捉复杂哈密顿函数并保持能量守恒，因此需要一种更有效的方法。", "method": "提出H-FEX方法，通过引入新型交互节点来捕捉复杂相互作用项。", "result": "实验表明H-FEX能准确恢复复杂系统的哈密顿函数，并长期保持能量守恒。", "conclusion": "H-FEX是发现复杂动力系统闭式表达的有力框架。"}}
{"id": "2506.20623", "categories": ["cs.LG", "cond-mat.dis-nn", "physics.data-an", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.20623", "abs": "https://arxiv.org/abs/2506.20623", "authors": ["Fariba Jangjoo", "Matteo Marsili", "Yasser Roudi"], "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning", "comment": "13 pages, 2 figures", "summary": "Closed-loop learning is the process of repeatedly estimating a model from\ndata generated from the model itself. It is receiving great attention due to\nthe possibility that large neural network models may, in the future, be\nprimarily trained with data generated by artificial neural networks themselves.\nWe study this process for models that belong to exponential families, deriving\nequations of motions that govern the dynamics of the parameters. We show that\nmaximum likelihood estimation of the parameters endows sufficient statistics\nwith the martingale property and that as a result the process converges to\nabsorbing states that amplify initial biases present in the data. However, we\nshow that this outcome may be prevented by polluting the data with an\ninfinitesimal fraction of data points generated from a fixed model, by relying\non maximum a posteriori estimation or by introducing regularisation.\nFurthermore, we show that the asymptotic behavior of the dynamics is not\nreparametrisation invariant.", "AI": {"tldr": "闭环学习是通过从模型自身生成的数据中反复估计模型的过程。研究表明，最大似然估计会导致参数收敛到放大初始偏差的状态，但可以通过数据污染、最大后验估计或正则化避免。", "motivation": "研究闭环学习在指数族模型中的动态行为，探索其潜在问题及解决方案。", "method": "推导参数动态方程，分析最大似然估计的性质，并提出数据污染、最大后验估计和正则化等方法。", "result": "最大似然估计会导致参数收敛到吸收状态，放大初始偏差；但通过干预可避免这一结果。", "conclusion": "闭环学习的动态行为对参数化敏感，需通过适当方法避免偏差放大。"}}
{"id": "2506.20629", "categories": ["cs.LG", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.20629", "abs": "https://arxiv.org/abs/2506.20629", "authors": ["Soufiane Hayou", "Nikhil Ghosh", "Bin Yu"], "title": "PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models", "comment": "TD,LR: A lightweight module type selection method for LoRA\n  finetuning. PLoP gives precise placements for LoRA adapters for improved\n  performance", "summary": "Low-Rank Adaptation (LoRA) is a widely used finetuning method for large\nmodels. Its small memory footprint allows practitioners to adapt large models\nto specific tasks at a fraction of the cost of full finetuning. Different\nmodifications have been proposed to enhance its efficiency by, for example,\nsetting the learning rate, the rank, and the initialization. Another\nimprovement axis is adapter placement strategy: when using LoRA, practitioners\nusually pick module types to adapt with LoRA, such as Query and Key modules.\nFew works have studied the problem of adapter placement, with nonconclusive\nresults: original LoRA paper suggested placing adapters in attention modules,\nwhile other works suggested placing them in the MLP modules. Through an\nintuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a\nlightweight method that allows automatic identification of module types where\nLoRA adapters should be placed, given a pretrained model and a finetuning task.\nWe demonstrate that PLoP consistently outperforms, and in the worst case\ncompetes, with commonly used placement strategies through comprehensive\nexperiments on supervised finetuning and reinforcement learning for reasoning.", "AI": {"tldr": "PLoP是一种轻量级方法，通过自动识别LoRA适配器的最佳放置位置，显著提升了模型微调性能。", "motivation": "研究LoRA适配器放置策略的优化问题，以提升大型模型在特定任务上的微调效率。", "method": "提出PLoP方法，通过理论分析自动确定LoRA适配器的最佳放置位置。", "result": "PLoP在监督微调和强化学习任务中表现优于或至少与常用策略相当。", "conclusion": "PLoP为LoRA适配器放置提供了一种高效且自动化的解决方案。"}}
{"id": "2506.20644", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20644", "abs": "https://arxiv.org/abs/2506.20644", "authors": ["Hangyu Li", "Hongyue Wu", "Guodong Fan", "Zhen Zhang", "Shizhan Chen", "Zhiyong Feng"], "title": "Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices", "comment": "Accepted by ICWS 2025", "summary": "As privacy protection gains increasing importance, more models are being\ntrained on edge devices and subsequently merged into the central server through\nFederated Learning (FL). However, current research overlooks the impact of\nnetwork topology, physical distance, and data heterogeneity on edge devices,\nleading to issues such as increased latency and degraded model performance. To\naddress these issues, we propose a new federated learning scheme on edge\ndevices that called Federated Learning with Encrypted Data Sharing(FedEDS).\nFedEDS uses the client model and the model's stochastic layer to train the data\nencryptor. The data encryptor generates encrypted data and shares it with other\nclients. The client uses the corresponding client's stochastic layer and\nencrypted data to train and adjust the local model. FedEDS uses the client's\nlocal private data and encrypted shared data from other clients to train the\nmodel. This approach accelerates the convergence speed of federated learning\ntraining and mitigates the negative impact of data heterogeneity, making it\nsuitable for application services deployed on edge devices requiring rapid\nconvergence. Experiments results show the efficacy of FedEDS in promoting model\nperformance.", "AI": {"tldr": "提出了一种名为FedEDS的新联邦学习方案，通过加密数据共享解决边缘设备上的网络拓扑、物理距离和数据异构性问题。", "motivation": "当前研究忽视了网络拓扑、物理距离和数据异构性对边缘设备的影响，导致延迟增加和模型性能下降。", "method": "FedEDS利用客户端模型和模型的随机层训练数据加密器，生成加密数据并与其他客户端共享，结合本地私有数据和共享加密数据训练模型。", "result": "实验证明FedEDS能加速联邦学习收敛速度，减轻数据异构性的负面影响。", "conclusion": "FedEDS适用于需要快速收敛的边缘设备应用服务，有效提升模型性能。"}}
{"id": "2506.20650", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.20650", "abs": "https://arxiv.org/abs/2506.20650", "authors": ["Anqi Mao", "Mehryar Mohri", "Yutao Zhong"], "title": "Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer", "comment": "ICML 2025", "summary": "The problem of learning to defer with multiple experts consists of optimally\nassigning input instances to experts, balancing the trade-off between their\naccuracy and computational cost. This is a critical challenge in natural\nlanguage generation, but also in other fields such as image processing, and\nmedical diagnostics. Recent studies have proposed surrogate loss functions to\noptimize deferral, but challenges remain in ensuring their consistency\nproperties. This paper introduces novel surrogate loss functions and efficient\nalgorithms with strong theoretical learning guarantees. We address open\nquestions regarding realizable $H$-consistency, $H$-consistency bounds, and\nBayes-consistency for both single-stage (jointly learning predictor and\ndeferral function) and two-stage (learning only the deferral function with a\nfixed expert) learning scenarios. For single-stage deferral, we introduce a\nfamily of new realizable $H$-consistent surrogate losses and further prove\n$H$-consistency for a selected member. For two-stage deferral, we derive new\nsurrogate losses that achieve realizable $H$-consistency, $H$-consistency\nbounds, and Bayes-consistency for the two-expert scenario and, under natural\nassumptions, multiple-expert scenario. Additionally, we provide enhanced\ntheoretical guarantees under low-noise assumptions for both scenarios. Finally,\nwe report the results of experiments using our proposed surrogate losses,\ncomparing their performance against existing baselines.", "AI": {"tldr": "该论文提出新的代理损失函数和高效算法，解决多专家学习中的延迟分配问题，并提供了理论保证和实验验证。", "motivation": "解决在多专家系统中平衡准确性和计算成本的挑战，特别是在自然语言生成等领域。", "method": "引入新的代理损失函数和算法，分别针对单阶段和两阶段学习场景，提供理论一致性保证。", "result": "提出了可实现H一致性的损失函数，并在实验中验证了其优于现有基线。", "conclusion": "论文为多专家学习中的延迟分配问题提供了有效的解决方案和理论支持。"}}
{"id": "2506.20651", "categories": ["cs.LG", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.20651", "abs": "https://arxiv.org/abs/2506.20651", "authors": ["Fei Wang", "Baochun Li"], "title": "Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning", "comment": null, "summary": "Recent work has shown that gradient updates in federated learning (FL) can\nunintentionally reveal sensitive information about a client's local data. This\nrisk becomes significantly greater when a malicious server manipulates the\nglobal model to provoke information-rich updates from clients. In this paper,\nwe adopt a defender's perspective to provide the first comprehensive analysis\nof malicious gradient leakage attacks and the model manipulation techniques\nthat enable them. Our investigation reveals a core trade-off: these attacks\ncannot be both highly effective in reconstructing private data and sufficiently\nstealthy to evade detection -- especially in realistic FL settings that\nincorporate common normalization techniques and federated averaging.\n  Building on this insight, we argue that malicious gradient leakage attacks,\nwhile theoretically concerning, are inherently limited in practice and often\ndetectable through basic monitoring. As a complementary contribution, we\npropose a simple, lightweight, and broadly applicable client-side detection\nmechanism that flags suspicious model updates before local training begins,\ndespite the fact that such detection may not be strictly necessary in realistic\nFL settings. This mechanism further underscores the feasibility of defending\nagainst these attacks with minimal overhead, offering a deployable safeguard\nfor privacy-conscious federated learning systems.", "AI": {"tldr": "论文分析了联邦学习中恶意梯度泄漏攻击的局限性，提出了一种轻量级客户端检测机制。", "motivation": "研究恶意服务器通过操纵全局模型获取客户端敏感信息的风险，探讨攻击的实际限制和防御可行性。", "method": "从防御者角度分析攻击的有效性与隐蔽性，提出基于监控的客户端检测机制。", "result": "发现攻击在现实联邦学习环境中难以同时高效和隐蔽，检测机制可有效防御。", "conclusion": "恶意梯度泄漏攻击实际威胁有限，轻量级防御机制可行且易于部署。"}}
