<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 86]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.SD](#cs.SD) [Total: 9]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.HC](#cs.HC) [Total: 18]
- [cs.RO](#cs.RO) [Total: 24]
- [eess.IV](#eess.IV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 71]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search](https://arxiv.org/abs/2507.11549)
*Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种硬件友好的优化框架，通过神经架构搜索和新的切片策略，解决了可变形注意力变换器（DAT）在硬件部署中的内存访问问题，同时保持了高精度。


<details>
  <summary>Details</summary>
Motivation: 可变形注意力变换器（DAT）在计算机视觉任务中表现出色，但其数据依赖的采样机制导致不规则内存访问模式，影响硬件部署效率。现有方法要么硬件开销高，要么牺牲模型精度。

Method: 提出了一种基于神经架构搜索（NAS）的方法，采用新的切片策略自动划分输入特征为均匀块，避免内存冲突；同时设计了基于FPGA的验证系统。

Result: 在ImageNet-1K数据集上，精度仅下降0.2%；在Xilinx FPGA上，DRAM访问次数减少至现有方法的18%。

Conclusion: 该框架在保持高精度的同时，显著提升了硬件效率，适用于边缘计算场景。

Abstract: Deformable Attention Transformers (DAT) have shown remarkable performance in
computer vision tasks by adaptively focusing on informative image regions.
However, their data-dependent sampling mechanism introduces irregular memory
access patterns, posing significant challenges for efficient hardware
deployment. Existing acceleration methods either incur high hardware overhead
or compromise model accuracy. To address these issues, this paper proposes a
hardware-friendly optimization framework for DAT. First, a neural architecture
search (NAS)-based method with a new slicing strategy is proposed to
automatically divide the input feature into uniform patches during the
inference process, avoiding memory conflicts without modifying model
architecture. The method explores the optimal slice configuration by jointly
optimizing hardware cost and inference accuracy. Secondly, an FPGA-based
verification system is designed to test the performance of this framework on
edge-side hardware. Algorithm experiments on the ImageNet-1K dataset
demonstrate that our hardware-friendly framework can maintain have only 0.2%
accuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA
show the proposed method reduces DRAM access times to 18% compared with
existing DAT acceleration methods.

</details>


### [2] [Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction](https://arxiv.org/abs/2507.11550)
*Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim*

Main category: cs.CV

TL;DR: 提出了一种名为DDCN的新方法，用于高效且准确的时空交通预测，解决了传统GNN和CNN的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉时空异质性和扩展性方面存在不足，尤其是GNN需要预定义邻接矩阵且难以处理大规模数据。

Method: DDCN通过动态应用可变形滤波器，结合编码器-解码器结构和注意力机制，提升时空特征的建模能力。

Result: 在四个真实数据集上的实验表明，DDCN具有竞争性的性能。

Conclusion: DDCN展示了CNN方法在时空交通预测中的潜力和有效性。

Abstract: Spatio-temporal traffic prediction plays a key role in intelligent
transportation systems by enabling accurate prediction in complex urban areas.
Although not only accuracy but also efficiency for scalability is important,
some previous methods struggle to capture heterogeneity such as varying traffic
patterns across regions and time periods. Moreover, Graph Neural Networks
(GNNs), which are the mainstream of traffic prediction, not only require
predefined adjacency matrix, but also limit scalability to large-scale data
containing many nodes due to their inherent complexity. To overcome these
limitations, we propose Deformable Dynamic Convolution Network (DDCN) for
accurate yet efficient traffic prediction. Traditional Convolutional Neural
Networks (CNNs) are limited in modeling non-Euclidean spatial structures and
spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically
applying deformable filters based on offset. Specifically, DDCN decomposes
transformer-style CNN to encoder-decoder structure, and applies proposed
approaches to the spatial and spatio-temporal attention blocks of the encoder
to emphasize important features. The decoder, composed of feed-forward module,
complements the output of the encoder. This novel structure make DDCN can
perform accurate yet efficient traffic prediction. In comprehensive experiments
on four real-world datasets, DDCN achieves competitive performance, emphasizing
the potential and effectiveness of CNN-based approaches for spatio-temporal
traffic prediction.

</details>


### [3] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
*Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun*

Main category: cs.CV

TL;DR: 提出Inversion-DPO框架，通过DDIM反演优化扩散模型的对齐，避免奖励建模，提升训练效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法计算开销大且可能影响模型精度，需改进。

Method: 结合DDIM反演与Direct Preference Optimization，避免奖励模型，直接优化后验采样。

Result: 在文本到图像生成和组合图像生成任务中表现优异，生成高保真图像。

Conclusion: Inversion-DPO为扩散模型提供高效、高精度的对齐方法，适用于复杂生成任务。

Abstract: Recent advancements in diffusion models (DMs) have been propelled by
alignment methods that post-train models to better conform to human
preferences. However, these approaches typically require computation-intensive
training of a base model and a reward model, which not only incurs substantial
computational overhead but may also compromise model accuracy and training
efficiency. To address these limitations, we propose Inversion-DPO, a novel
alignment framework that circumvents reward modeling by reformulating Direct
Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts
intractable posterior sampling in Diffusion-DPO with the deterministic
inversion from winning and losing samples to noise and thus derive a new
post-training paradigm. This paradigm eliminates the need for auxiliary reward
models or inaccurate appromixation, significantly enhancing both precision and
efficiency of training. We apply Inversion-DPO to a basic task of text-to-image
generation and a challenging task of compositional image generation. Extensive
experiments show substantial performance improvements achieved by Inversion-DPO
compared to existing post-training methods and highlight the ability of the
trained generative models to generate high-fidelity compositionally coherent
images. For the post-training of compostitional image geneation, we curate a
paired dataset consisting of 11,140 images with complex structural annotations
and comprehensive scores, designed to enhance the compositional capabilities of
generative models. Inversion-DPO explores a new avenue for efficient,
high-precision alignment in diffusion models, advancing their applicability to
complex realistic generation tasks. Our code is available at
https://github.com/MIGHTYEZ/Inversion-DPO

</details>


### [4] [Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2507.11558)
*Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu*

Main category: cs.CV

TL;DR: ST-VFM是一个新颖的框架，通过重新编程视觉基础模型（VFMs）来解决时空预测任务中的时空建模和模态差异问题。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在自然语言处理和计算机视觉中表现出色，但大型语言模型（LLMs）在时空预测中难以捕捉丰富的时空相关性。ST-VFM旨在填补这一空白。

Method: ST-VFM采用双分支架构，结合原始时空输入和辅助时空流输入，并通过前VFM和后VFM两个重新编程阶段处理这些输入。

Result: 在十个时空数据集上的实验表明，ST-VFM优于现有基线，展示了其有效性和鲁棒性。

Conclusion: ST-VFM是一个强大的通用框架，适用于时空预测任务。

Abstract: Foundation models have achieved remarkable success in natural language
processing and computer vision, demonstrating strong capabilities in modeling
complex patterns. While recent efforts have explored adapting large language
models (LLMs) for time-series forecasting, LLMs primarily capture
one-dimensional sequential dependencies and struggle to model the richer
spatio-temporal (ST) correlations essential for accurate ST forecasting. In
this paper, we present \textbf{ST-VFM}, a novel framework that systematically
reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal
forecasting. While VFMs offer powerful spatial priors, two key challenges arise
when applying them to ST tasks: (1) the lack of inherent temporal modeling
capacity and (2) the modality gap between visual and ST data. To address these,
ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputs
with auxiliary ST flow inputs, where the flow encodes lightweight temporal
difference signals interpretable as dynamic spatial cues. To effectively
process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming
stages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token
Adapter to embed temporal context and align both branches into VFM-compatible
feature spaces. The \emph{post-VFM reprogramming} stage introduces a Bilateral
Cross-Prompt Coordination module, enabling dynamic interaction between branches
through prompt-based conditioning, thus enriching joint representation learning
without modifying the frozen VFM backbone. Extensive experiments on ten
spatio-temporal datasets show that ST-VFM outperforms state-of-the-art
baselines, demonstrating effectiveness and robustness across VFM backbones
(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong
general framework for spatio-temporal forecasting.

</details>


### [5] [Expert Operational GANS: Towards Real-Color Underwater Image Restoration](https://arxiv.org/abs/2507.11562)
*Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj*

Main category: cs.CV

TL;DR: xOp-GAN是一种新型GAN模型，通过多个专家生成器网络解决水下图像恢复问题，每个生成器专注于特定质量范围的图像恢复，并通过判别器选择最佳结果。


<details>
  <summary>Details</summary>
Motivation: 传统GAN方法在复杂水下图像恢复中表现不佳，因为单一生成器难以覆盖所有视觉退化范围。

Method: 提出xOp-GAN，包含多个专家生成器网络，每个生成器针对特定质量范围的图像进行训练，判别器在推理阶段选择最佳恢复结果。

Result: 在LSUI数据集上，xOp-GAN的PSNR达到25.16 dB，显著优于单一回归模型。

Conclusion: xOp-GAN通过多生成器架构和判别器选择机制，显著提升了水下图像恢复的性能。

Abstract: The wide range of deformation artifacts that arise from complex light
propagation, scattering, and depth-dependent attenuation makes the underwater
image restoration to remain a challenging problem. Like other single deep
regressor networks, conventional GAN-based restoration methods struggle to
perform well across this heterogeneous domain, since a single generator network
is typically insufficient to capture the full range of visual degradations. In
order to overcome this limitation, we propose xOp-GAN, a novel GAN model with
several expert generator networks, each trained solely on a particular subset
with a certain image quality. Thus, each generator can learn to maximize its
restoration performance for a particular quality range. Once a xOp-GAN is
trained, each generator can restore the input image and the best restored image
can then be selected by the discriminator based on its perceptual confidence
score. As a result, xOP-GAN is the first GAN model with multiple generators
where the discriminator is being used during the inference of the regression
task. Experimental results on benchmark Large Scale Underwater Image (LSUI)
dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,
surpassing all single-regressor models by a large margin even, with reduced
complexity.

</details>


### [6] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 论文通过元分析和大规模实验，评估了基于步态估计年龄的方法，发现卷积神经网络表现最佳，并提出实用指南以降低误差。


<details>
  <summary>Details</summary>
Motivation: 步态估计年龄在医疗、安全和人机交互中有重要应用，但现有方法在实验室和现实数据中存在差异，需建立更可靠的性能基准。

Method: 结合元分析、大规模数据集实验（如OU-ISIR和VersatileGait）和可解释性技术（如Grad-CAM），评估多种模型（CNN、SVM等）。

Result: CNN平均误差4.2年，多传感器融合最低3.4年；步态指标与年龄相关性显著；CNN在VersatileGait上准确率达96%。

Conclusion: 通过综合方法，论文为降低步态年龄估计误差提供了性能基准和实用指南，目标为现实场景中误差低于3年。

Abstract: Estimating a person's age from their gait has important applications in
healthcare, security and human-computer interaction. In this work, we review
fifty-nine studies involving over seventy-five thousand subjects recorded with
video, wearable and radar sensors. We observe that convolutional neural
networks produce an average error of about 4.2 years, inertial-sensor models
about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable
differences between lab and real-world data. We then analyse sixty-three
thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population
dataset to quantify correlations between age and five key metrics: stride
length, walking speed, step cadence, step-time variability and joint-angle
entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a
ResNet34 model and apply Grad-CAM to reveal that the network attends to the
knee and pelvic regions, consistent with known age-related gait changes.
Finally, on a one hundred thousand sample subset of the VersatileGait database,
we compare support vector machines, decision trees, random forests, multilayer
perceptrons and convolutional neural networks, finding that deep networks
achieve up to 96 percent accuracy while processing each sample in under 0.1
seconds. By combining a broad meta-analysis with new large-scale experiments
and interpretable visualizations, we establish solid performance baselines and
practical guidelines for reducing gait-age error below three years in
real-world scenarios.

</details>


### [7] [What cat is that? A re-id model for feral cats](https://arxiv.org/abs/2507.11575)
*Victor Caquilpan*

Main category: cs.CV

TL;DR: 研究提出了一种改进的PPGNet-Cat模型，用于通过摄像头图像重新识别野猫，取得了高精度（mAP 0.86，rank-1准确率0.95）。


<details>
  <summary>Details</summary>
Motivation: 野猫对澳大利亚野生动物造成严重威胁，需要高效监控以减少其影响。

Method: 改进PPGNet模型（原用于东北虎重识别），适应野猫特征，并探索对比学习方法如ArcFace损失。

Result: PPGNet-Cat表现优异，mAP达0.86，rank-1准确率0.95。

Conclusion: PPGNet-Cat是一种高效的野猫重识别模型，适用于监控工作。

Abstract: Feral cats exert a substantial and detrimental impact on Australian wildlife,
placing them among the most dangerous invasive species worldwide. Therefore,
closely monitoring these cats is essential labour in minimising their effects.
In this context, the potential application of Re-Identification (re-ID) emerges
to enhance monitoring activities for these animals, utilising images captured
by camera traps. This project explores different CV approaches to create a
re-ID model able to identify individual feral cats in the wild. The main
approach consists of modifying a part-pose guided network (PPGNet) model,
initially used in the re-ID of Amur tigers, to be applicable for feral cats.
This adaptation, resulting in PPGNet-Cat, which incorporates specific
modifications to suit the characteristics of feral cats images. Additionally,
various experiments were conducted, particularly exploring contrastive learning
approaches such as ArcFace loss. The main results indicate that PPGNet-Cat
excels in identifying feral cats, achieving high performance with a mean
Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes
establish PPGNet-Cat as a competitive model within the realm of re-ID.

</details>


### [8] [SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation](https://arxiv.org/abs/2507.11579)
*Sathvik Chereddy,John Femiani*

Main category: cs.CV

TL;DR: SketchDNN提出了一种生成CAD草图的模型，通过统一的连续-离散扩散过程联合建模连续参数和离散类别标签，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决CAD草图中原始参数化的异质性和原始元素的排列不变性问题。

Method: 采用高斯-Softmax扩散，通过高斯噪声扰动logits并通过softmax变换投影到概率单纯形，实现离散变量的混合类别标签。

Result: 在SketchGraphs数据集上，FID从16.04降至7.80，NLL从84.8降至81.33，达到新的最优性能。

Conclusion: SketchDNN在CAD草图生成中实现了显著的性能提升，为相关领域提供了新的解决方案。

Abstract: We present SketchDNN, a generative model for synthesizing CAD sketches that
jointly models both continuous parameters and discrete class labels through a
unified continuous-discrete diffusion process. Our core innovation is
Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are
projected onto the probability simplex via a softmax transformation,
facilitating blended class labels for discrete variables. This formulation
addresses 2 key challenges, namely, the heterogeneity of primitive
parameterizations and the permutation invariance of primitives in CAD sketches.
Our approach significantly improves generation quality, reducing Fr\'echet
Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)
from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch
generation on the SketchGraphs dataset.

</details>


### [9] [Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders](https://arxiv.org/abs/2507.11638)
*Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton*

Main category: cs.CV

TL;DR: 论文提出了一种基于变分自编码器（VAE）的特征编码模型，用于提高直肠癌淋巴结转移（LNM）分期的准确性，替代了传统的大型预训练卷积神经网络（CNN）。


<details>
  <summary>Details</summary>
Motivation: 现有基于淋巴结大小、形状和纹理形态的放射学标准诊断准确性有限，因此需要更有效的特征编码方法。

Method: 使用VAE作为特征编码器，生成模型直接编码视觉特征和有意义的数据模式，形成解耦和结构化的潜在空间。模型在168名未接受新辅助治疗的患者的MRI数据集上部署。

Result: 提出的VAE-MLP模型在MRI数据集上达到了最先进的性能，交叉验证指标为AUC 0.86 +/- 0.05，敏感性0.79 +/- 0.06，特异性0.85 +/- 0.05。

Conclusion: VAE作为特征编码器在淋巴结转移分期中表现优异，具有更高的可解释性和性能。

Abstract: Effective treatment for rectal cancer relies on accurate lymph node
metastasis (LNM) staging. However, radiological criteria based on lymph node
(LN) size, shape and texture morphology have limited diagnostic accuracy. In
this work, we investigate applying a Variational Autoencoder (VAE) as a feature
encoder model to replace the large pre-trained Convolutional Neural Network
(CNN) used in existing approaches. The motivation for using a VAE is that the
generative model aims to reconstruct the images, so it directly encodes visual
features and meaningful patterns across the data. This leads to a disentangled
and structured latent space which can be more interpretable than a CNN. Models
are deployed on an in-house MRI dataset with 168 patients who did not undergo
neo-adjuvant treatment. The post-operative pathological N stage was used as the
ground truth to evaluate model predictions. Our proposed model 'VAE-MLP'
achieved state-of-the-art performance on the MRI dataset, with cross-validated
metrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85
+/- 0.05. Code is available at:
https://github.com/benkeel/Lymph_Node_Classification_MIUA.

</details>


### [10] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 论文提出一种基于姿势的心理状态推断方法，通过板球运动验证其有效性，用于区分攻击性和防守性击球意图，取得了75%的F1分数和80%的AUC-ROC。


<details>
  <summary>Details</summary>
Motivation: 姿势推断在疲劳诊断、伤害预防和性能提升方面潜力巨大，但面临人类数据敏感性的挑战。体育场景为数据积累提供了可行替代方案。

Method: 利用板球运动中的活动视频，通过运动分析识别击球意图，并结合现有数据统计作为弱监督验证。

Result: 方法在区分攻击性和防守性击球意图上表现优异（F1>75%，AUC-ROC>80%），表明姿势信号强且鲁棒。

Conclusion: 研究为体育分析提供了通用技术，并拓展了人类行为分析在其他领域的应用可能性。

Abstract: Posture-based mental state inference has significant potential in diagnosing
fatigue, preventing injury, and enhancing performance across various domains.
Such tools must be research-validated with large datasets before being
translated into practice. Unfortunately, such vision diagnosis faces serious
challenges due to the sensitivity of human subject data. To address this, we
identify sports settings as a viable alternative for accumulating data from
human subjects experiencing diverse emotional states. We test our hypothesis in
the game of cricket and present a posture-based solution to identify human
intent from activity videos. Our method achieves over 75\% F1 score and over
80\% AUC-ROC in discriminating aggressive and defensive shot intent through
motion analysis. These findings indicate that posture leaks out strong signals
for intent inference, even with inherent noise in the data pipeline.
Furthermore, we utilize existing data statistics as weak supervision to
validate our findings, offering a potential solution for overcoming data
labelling limitations. This research contributes to generalizable techniques
for sports analytics and also opens possibilities for applying human behavior
analysis across various fields.

</details>


### [11] [VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](https://arxiv.org/abs/2507.11653)
*Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How*

Main category: cs.CV

TL;DR: VISTA是一种新型的单目全局定位框架，通过对象分割和跟踪以及子图对应搜索，解决了无结构环境中的定位挑战，无需特定领域训练。


<details>
  <summary>Details</summary>
Motivation: 解决无结构环境中因视角变化、季节变化、空间混叠和遮挡导致的定位困难。

Method: 结合前端对象分割跟踪管道和子图对应搜索，利用几何一致性对齐参考帧。

Result: 在季节性和斜视角航空数据集上，召回率提升69%，地图大小仅为基线方法的0.6%。

Conclusion: VISTA在多样视角和季节变化下实现一致定位，适合资源受限平台实时应用。

Abstract: Global localization is critical for autonomous navigation, particularly in
scenarios where an agent must localize within a map generated in a different
session or by another agent, as agents often have no prior knowledge about the
correlation between reference frames. However, this task remains challenging in
unstructured environments due to appearance changes induced by viewpoint
variation, seasonal changes, spatial aliasing, and occlusions -- known failure
modes for traditional place recognition methods. To address these challenges,
we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame
Alignment), a novel open-set, monocular global localization framework that
combines: 1) a front-end, object-based, segmentation and tracking pipeline,
followed by 2) a submap correspondence search, which exploits geometric
consistencies between environment maps to align vehicle reference frames. VISTA
enables consistent localization across diverse camera viewpoints and seasonal
changes, without requiring any domain-specific training or finetuning. We
evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a
69% improvement in recall over baseline methods. Furthermore, we maintain a
compact object-based map that is only 0.6% the size of the most
memory-conservative baseline, making our approach capable of real-time
implementation on resource-constrained platforms.

</details>


### [12] [Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis](https://arxiv.org/abs/2507.11730)
*Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying*

Main category: cs.CV

TL;DR: 论文比较了多模态视觉语言模型（VLMs）与传统CNN-based OCR在户外广告文本识别中的表现，发现VLMs在整体场景理解上表现优异，但轻量级CNN在裁剪文本识别中仍具竞争力且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 户外广告文本识别的准确性在复杂场景中仍具挑战性，传统OCR在复杂环境下表现不佳，而新兴的VLMs可能提供更好的解决方案。

Method: 系统性地对比了Qwen 2.5 VL 3B、InternVL3、SmolVLM2等VLMs与PaddleOCRv4（CNN-based OCR）在两个公开数据集（ICDAR 2015和SVT）上的表现，并加入合成天气失真以模拟真实场景。

Result: 部分VLMs在整体场景推理上表现优异，但轻量级CNN在裁剪文本识别中仍具竞争力且计算成本更低。

Conclusion: VLMs在场景理解上有优势，但CNN在特定任务中更高效；为促进研究，公开了天气增强的基准和评估代码。

Abstract: Outdoor advertisements remain a critical medium for modern marketing, yet
accurately verifying billboard text visibility under real-world conditions is
still challenging. Traditional Optical Character Recognition (OCR) pipelines
excel at cropped text recognition but often struggle with complex outdoor
scenes, varying fonts, and weather-induced visual noise. Recently, multimodal
Vision-Language Models (VLMs) have emerged as promising alternatives, offering
end-to-end scene understanding with no explicit detection step. This work
systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,
InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline
(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with
synthetic weather distortions to simulate realistic degradation. Our results
reveal that while selected VLMs excel at holistic scene reasoning, lightweight
CNN pipelines still achieve competitive accuracy for cropped text at a fraction
of the computational cost-an important consideration for edge deployment. To
foster future research, we release our weather-augmented benchmark and
evaluation code publicly.

</details>


### [13] [Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning](https://arxiv.org/abs/2507.11761)
*Fan Shi,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 论文提出了一种统一的条件生成求解器（UCGS），用于解决多种抽象视觉推理任务，避免了任务特定设计或参数调整的需求。


<details>
  <summary>Details</summary>
Motivation: 设计具有人类抽象视觉推理能力的智能系统是人工智能领域的长期目标，但现有方法通常需要针对不同任务进行特定设计或重训练。

Method: 将抽象视觉推理任务重新表述为目标图像可预测性问题，并通过训练一个统一的条件生成模型来解决多种任务。

Result: 实验表明，UCGS通过多任务训练，能够在多种任务上展示抽象推理能力，并具备零样本推理能力。

Conclusion: UCGS提供了一种统一的框架，能够高效解决多种抽象视觉推理任务，并具备对新任务的泛化能力。

Abstract: Abstract visual reasoning (AVR) enables humans to quickly discover and
generalize abstract rules to new scenarios. Designing intelligent systems with
human-like AVR abilities has been a long-standing topic in the artificial
intelligence community. Deep AVR solvers have recently achieved remarkable
success in various AVR tasks. However, they usually use task-specific designs
or parameters in different tasks. In such a paradigm, solving new tasks often
means retraining the model, and sometimes retuning the model architectures,
which increases the cost of solving AVR problems. In contrast to task-specific
approaches, this paper proposes a novel Unified Conditional Generative Solver
(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we
prove that some well-known AVR tasks can be reformulated as the problem of
estimating the predictability of target images in problem panels. Then, we
illustrate that, under the proposed framework, training one conditional
generative model can solve various AVR tasks. The experiments show that with a
single round of multi-task training, UCGS demonstrates abstract reasoning
ability across various AVR tasks. Especially, UCGS exhibits the ability of
zero-shot reasoning, enabling it to perform abstract reasoning on problems from
unseen AVR tasks in the testing phase.

</details>


### [14] [CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning](https://arxiv.org/abs/2507.11834)
*Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang*

Main category: cs.CV

TL;DR: CorrMoE提出了一种新的图像对应关系修剪框架，通过去风格化双分支和双融合专家混合模块，提升了跨域和跨场景的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理跨域和跨场景的图像对应关系时表现不佳，CorrMoE旨在解决这一问题。

Method: 采用去风格化双分支处理域偏移，双融合专家混合模块应对场景多样性，结合线性复杂度注意力和动态专家路由。

Result: 在基准数据集上，CorrMoE表现出优于现有方法的准确性和泛化能力。

Conclusion: CorrMoE为跨域和跨场景的图像对应关系修剪提供了有效的解决方案。

Abstract: Establishing reliable correspondences between image pairs is a fundamental
task in computer vision, underpinning applications such as 3D reconstruction
and visual localization. Although recent methods have made progress in pruning
outliers from dense correspondence sets, they often hypothesize consistent
visual domains and overlook the challenges posed by diverse scene structures.
In this paper, we propose CorrMoE, a novel correspondence pruning framework
that enhances robustness under cross-domain and cross-scene variations. To
address domain shift, we introduce a De-stylization Dual Branch, performing
style mixing on both implicit and explicit graph features to mitigate the
adverse influence of domain-specific representations. For scene diversity, we
design a Bi-Fusion Mixture of Experts module that adaptively integrates
multi-perspective features through linear-complexity attention and dynamic
expert routing. Extensive experiments on benchmark datasets demonstrate that
CorrMoE achieves superior accuracy and generalization compared to
state-of-the-art methods. The code and pre-trained models are available at
https://github.com/peiwenxia/CorrMoE.

</details>


### [15] [ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification](https://arxiv.org/abs/2507.11845)
*Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng*

Main category: cs.CV

TL;DR: ProtoConNet提出了一种原型增强与对齐方法，通过整合背景信息提升少样本图像分类的性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅利用单张图像的视觉信息，忽略了上下文信息的整合，限制了模型的泛化能力。

Method: ProtoConNet包含三个模块：基于聚类的数据选择（CDS）、上下文增强语义细化（CSR）和原型对齐（PA），分别用于挖掘数据模式、整合上下文信息和缩小特征与原型差距。

Result: 在两个数据集上的实验表明，ProtoConNet提升了少样本场景下的表示学习效果，并能有效识别开放集样本。

Conclusion: ProtoConNet通过整合上下文信息，显著提升了少样本开放集分类的性能。

Abstract: Open-set few-shot image classification aims to train models using a small
amount of labeled data, enabling them to achieve good generalization when
confronted with unknown environments. Existing methods mainly use visual
information from a single image to learn class representations to distinguish
known from unknown categories. However, these methods often overlook the
benefits of integrating rich contextual information. To address this issue,
this paper proposes a prototypical augmentation and alignment method, termed
ProtoConNet, which incorporates background information from different samples
to enhance the diversity of the feature space, breaking the spurious
associations between context and image subjects in few-shot scenarios.
Specifically, it consists of three main modules: the clustering-based data
selection (CDS) module mines diverse data patterns while preserving core
features; the contextual-enhanced semantic refinement (CSR) module builds a
context dictionary to integrate into image representations, which boosts the
model's robustness in various scenarios; and the prototypical alignment (PA)
module reduces the gap between image representations and class prototypes,
amplifying feature distances for known and unknown classes. Experimental
results from two datasets verified that ProtoConNet enhances the effectiveness
of representation learning in few-shot scenarios and identifies open-set
samples, making it superior to existing methods.

</details>


### [16] [From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition](https://arxiv.org/abs/2507.11892)
*Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 论文提出GRACE方法，通过动态运动建模、语义文本细化和跨模态对齐，改进动态面部表情识别（DFER），解决了现有方法对文本情感线索利用不足和对无关面部动态过滤不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用文本情感线索和过滤无关面部动态方面存在不足，影响了动态面部表情识别的准确性。

Method: GRACE结合动态运动建模、语义文本细化（CATE模块）和基于熵正则化最优传输的跨模态对齐，定位情感相关的时空特征。

Result: 在三个基准数据集上，GRACE显著提升了识别性能，特别是在模糊或不平衡情感类别场景中，达到了新的SOTA结果。

Conclusion: GRACE通过多模态细化和对齐，显著提升了动态面部表情识别的性能，为情感计算提供了更精确的解决方案。

Abstract: Dynamic Facial Expression Recognition (DFER) aims to identify human emotions
from temporally evolving facial movements and plays a critical role in
affective computing. While recent vision-language approaches have introduced
semantic textual descriptions to guide expression recognition, existing methods
still face two key limitations: they often underutilize the subtle emotional
cues embedded in generated text, and they have yet to incorporate sufficiently
effective mechanisms for filtering out facial dynamics that are irrelevant to
emotional expression. To address these gaps, We propose GRACE, Granular
Representation Alignment for Cross-modal Emotion recognition that integrates
dynamic motion modeling, semantic text refinement, and token-level cross-modal
alignment to facilitate the precise localization of emotionally salient
spatiotemporal features. Our method constructs emotion-aware textual
descriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and
highlights expression-relevant facial motion through a motion-difference
weighting mechanism. These refined semantic and visual signals are aligned at
the token level using entropy-regularized optimal transport. Experiments on
three benchmark datasets demonstrate that our method significantly improves
recognition performance, particularly in challenging settings with ambiguous or
imbalanced emotion classes, establishing new state-of-the-art (SOTA) results in
terms of both UAR and WAR.

</details>


### [17] [Spatial Frequency Modulation for Semantic Segmentation](https://arxiv.org/abs/2507.11893)
*Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai*

Main category: cs.CV

TL;DR: 提出了一种空间频率调制（SFM）方法，通过调制高频特征到低频以减轻下采样中的混叠，并通过解调恢复高频信息，提升语义分割精度。


<details>
  <summary>Details</summary>
Motivation: 高频信息（如纹理）对语义分割至关重要，但在下采样过程中易受混叠或失真影响。

Method: 采用自适应重采样（ARS）调制高频特征至低频，设计多尺度自适应上采样（MSAU）解调并恢复高频信息。

Result: SFM有效减轻混叠并保留细节，适用于多种任务（分类、对抗鲁棒性、实例分割等）。

Conclusion: SFM是一种轻量级、通用的方法，可无缝集成到不同架构中，显著提升高频信息保留能力。

Abstract: High spatial frequency information, including fine details like textures,
significantly contributes to the accuracy of semantic segmentation. However,
according to the Nyquist-Shannon Sampling Theorem, high-frequency components
are vulnerable to aliasing or distortion when propagating through downsampling
layers such as strided-convolution. Here, we propose a novel Spatial Frequency
Modulation (SFM) that modulates high-frequency features to a lower frequency
before downsampling and then demodulates them back during upsampling.
Specifically, we implement modulation through adaptive resampling (ARS) and
design a lightweight add-on that can densely sample the high-frequency areas to
scale up the signal, thereby lowering its frequency in accordance with the
Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling
(MSAU) to demodulate the modulated feature and recover high-frequency
information through non-uniform upsampling This module further improves
segmentation by explicitly exploiting information interaction between densely
and sparsely resampled areas at multiple scales. Both modules can seamlessly
integrate with various architectures, extending from convolutional neural
networks to transformers. Feature visualization and analysis confirm that our
method effectively alleviates aliasing while successfully retaining details
after demodulation. Finally, we validate the broad applicability and
effectiveness of SFM by extending it to image classification, adversarial
robustness, instance segmentation, and panoptic segmentation tasks. The code is
available at
\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.

</details>


### [18] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: SEPose是一个合成的事件行人姿态估计数据集，用于解决真实数据不足的问题，并在多种环境条件下进行了测试。


<details>
  <summary>Details</summary>
Motivation: 解决行人监控系统中事件传感器数据不足的问题，尤其是在复杂条件下（如分心行走或异常运动）。

Method: 利用CARLA模拟器生成合成数据，标注了近350K行人的姿态关键点，并在不同光照和天气条件下测试。

Result: 训练了RVT和YOLOv8等模型，并在真实事件数据上验证了模拟到实际的泛化能力。

Conclusion: SEPose数据集填补了事件传感器数据的空白，并展示了在复杂条件下的实用性。

Abstract: Event-based sensors have emerged as a promising solution for addressing
challenging conditions in pedestrian and traffic monitoring systems. Their
low-latency and high dynamic range allow for improved response time in
safety-critical situations caused by distracted walking or other unusual
movements. However, the availability of data covering such scenarios remains
limited. To address this gap, we present SEPose -- a comprehensive synthetic
event-based human pose estimation dataset for fixed pedestrian perception
generated using dynamic vision sensors in the CARLA simulator. With nearly 350K
annotated pedestrians with body pose keypoints from the perspective of fixed
traffic cameras, SEPose is a comprehensive synthetic multi-person pose
estimation dataset that spans busy and light crowds and traffic across diverse
lighting and weather conditions in 4-way intersections in urban, suburban, and
rural environments. We train existing state-of-the-art models such as RVT and
YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate
the sim-to-real generalization capabilities of the proposed dataset.

</details>


### [19] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 论文提出Dark-EvGS框架，利用事件相机和3D高斯泼溅技术，在低光环境下实现多视角明亮帧重建，解决了噪声、帧质量差和色调不一致问题。


<details>
  <summary>Details</summary>
Motivation: 传统相机在低光环境下难以捕捉清晰多视角图像，事件相机和高斯泼溅技术虽有潜力，但仍面临噪声、帧质量和色调问题。

Method: 提出Dark-EvGS框架，采用三重监督学习、色调匹配模块，并构建首个真实数据集。

Result: 实验表明，该方法在低光条件下优于现有方法，成功重建辐射场。

Conclusion: Dark-EvGS为低光环境下的多视角明亮帧重建提供了有效解决方案。

Abstract: In low-light environments, conventional cameras often struggle to capture
clear multi-view images of objects due to dynamic range limitations and motion
blur caused by long exposure. Event cameras, with their high-dynamic range and
high-speed properties, have the potential to mitigate these issues.
Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,
facilitating bright frame synthesis from multiple viewpoints in low-light
conditions. However, naively using an event-assisted 3D GS approach still faced
challenges because, in low light, events are noisy, frames lack quality, and
the color tone may be inconsistent. To address these issues, we propose
Dark-EvGS, the first event-assisted 3D GS framework that enables the
reconstruction of bright frames from arbitrary viewpoints along the camera
trajectory. Triplet-level supervision is proposed to gain holistic knowledge,
granular details, and sharp scene rendering. The color tone matching block is
proposed to guarantee the color consistency of the rendered frames.
Furthermore, we introduce the first real-captured dataset for the event-guided
bright frame synthesis task via 3D GS-based radiance field reconstruction.
Experiments demonstrate that our method achieves better results than existing
methods, conquering radiance field reconstruction under challenging low-light
conditions. The code and sample data are included in the supplementary
material.

</details>


### [20] [Traffic-Aware Pedestrian Intention Prediction](https://arxiv.org/abs/2507.12433)
*Fahimeh Orvati Nia,Hai Lin*

Main category: cs.CV

TL;DR: 提出了一种结合交通信号状态的时空图卷积网络（TA-STGCN），显著提高了行人意图预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有模型常忽略动态交通信号和场景信息，而这些对自动驾驶车辆的安全导航至关重要。

Method: 提出TA-STGCN，整合交通信号状态和边界框大小作为关键特征，捕捉复杂城市环境中的时空依赖性。

Result: 在PIE数据集上，TA-STGCN比基线模型准确率提高了4.75%。

Conclusion: TA-STGCN通过整合动态交通信号状态，有效提升了行人意图预测的准确性。

Abstract: Accurate pedestrian intention estimation is crucial for the safe navigation
of autonomous vehicles (AVs) and hence attracts a lot of research attention.
However, current models often fail to adequately consider dynamic traffic
signals and contextual scene information, which are critical for real-world
applications. This paper presents a Traffic-Aware Spatio-Temporal Graph
Convolutional Network (TA-STGCN) that integrates traffic signs and their states
(Red, Yellow, Green) into pedestrian intention prediction. Our approach
introduces the integration of dynamic traffic signal states and bounding box
size as key features, allowing the model to capture both spatial and temporal
dependencies in complex urban environments. The model surpasses existing
methods in accuracy. Specifically, TA-STGCN achieves a 4.75% higher accuracy
compared to the baseline model on the PIE dataset, demonstrating its
effectiveness in improving pedestrian intention prediction.

</details>


### [21] [Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs](https://arxiv.org/abs/2507.11932)
*Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi*

Main category: cs.CV

TL;DR: 论文提出了Hyperphantasia基准，用于评估多模态大语言模型（MLLMs）的心理可视化能力，发现当前模型与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估被动视觉感知，缺乏对主动构建视觉模式以支持问题解决能力的测试，而心理可视化是人类认知的核心能力。

Method: 通过四个程序生成的谜题任务（三个难度级别）评估MLLMs的心理可视化能力，并探索强化学习提升视觉模拟能力的潜力。

Result: 当前MLLMs在识别视觉模式上表现部分能力，但稳健的心理可视化仍是挑战，与人类表现差距显著。

Conclusion: 心理可视化是MLLMs的开放挑战，需进一步研究提升其能力。

Abstract: Mental visualization, the ability to construct and manipulate visual
representations internally, is a core component of human cognition and plays a
vital role in tasks involving reasoning, prediction, and abstraction. Despite
the rapid progress of Multimodal Large Language Models (MLLMs), current
benchmarks primarily assess passive visual perception, offering limited insight
into the more active capability of internally constructing visual patterns to
support problem solving. Yet mental visualization is a critical cognitive skill
in humans, supporting abilities such as spatial navigation, predicting physical
trajectories, and solving complex visual problems through imaginative
simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic
benchmark designed to evaluate the mental visualization abilities of MLLMs
through four carefully constructed puzzles. Each task is procedurally generated
and presented at three difficulty levels, enabling controlled analysis of model
performance across increasing complexity. Our comprehensive evaluation of
state-of-the-art models reveals a substantial gap between the performance of
humans and MLLMs. Additionally, we explore the potential of reinforcement
learning to improve visual simulation capabilities. Our findings suggest that
while some models exhibit partial competence in recognizing visual patterns,
robust mental visualization remains an open challenge for current MLLMs.

</details>


### [22] [RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation](https://arxiv.org/abs/2507.11947)
*Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 论文提出了一种关系感知解耦学习框架（RaDL），用于解决多实例图像生成中的关系差异和属性泄漏问题，显著提升了生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多实例图像生成中难以处理实例间的关系差异和属性泄漏，需要更有效的解决方案。

Method: RaDL通过可学习参数增强实例特定属性，并利用关系注意力生成关系感知图像特征。

Result: 在多个基准测试中，RaDL在位置准确性、多属性考虑和实例关系方面优于现有方法。

Conclusion: RaDL是多实例图像生成中考虑实例关系和属性的有效解决方案。

Abstract: With recent advancements in text-to-image (T2I) models, effectively
generating multiple instances within a single image prompt has become a crucial
challenge. Existing methods, while successful in generating positions of
individual instances, often struggle to account for relationship discrepancy
and multiple attributes leakage. To address these limitations, this paper
proposes the relation-aware disentangled learning (RaDL) framework. RaDL
enhances instance-specific attributes through learnable parameters and
generates relation-aware image features via Relation Attention, utilizing
action verbs extracted from the global prompt. Through extensive evaluations on
benchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that
RaDL outperforms existing methods, showing significant improvements in
positional accuracy, multiple attributes consideration, and the relationships
between instances. Our results present RaDL as the solution for generating
images that consider both the relationships and multiple attributes of each
instance within the multi-instance image.

</details>


### [23] [Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli](https://arxiv.org/abs/2507.12009)
*Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville*

Main category: cs.CV

TL;DR: 提出了一种端到端的深度神经网络编码器-解码器模型，用于编码和解码自然刺激下的大脑活动，通过fMRI数据实现视觉输入的重建和脑区贡献分析。


<details>
  <summary>Details</summary>
Motivation: 研究自然电影刺激下的大脑活动编码与解码，以填补自然刺激与fMRI数据之间的时间分辨率差距。

Method: 采用时间卷积层的深度神经网络架构，利用连续电影帧的时间相关性，预测视觉皮层及其周围体素的活动，并通过显著性图分析脑区贡献。

Result: 模型成功重建了视觉输入，发现中枕区、梭状回和距状沟是解码视觉信息的关键区域，分别对应形状感知、复杂识别（如人脸）和基本视觉特征（如边缘和对比度）。

Conclusion: 研究表明，通过深度学习模型的行为可以间接探索视觉处理的机制，为理解电影中的视觉处理提供了新方法。

Abstract: We propose an end-to-end deep neural encoder-decoder model to encode and
decode brain activity in response to naturalistic stimuli using functional
magnetic resonance imaging (fMRI) data. Leveraging temporally correlated input
from consecutive film frames, we employ temporal convolutional layers in our
architecture, which effectively allows to bridge the temporal resolution gap
between natural movie stimuli and fMRI acquisitions. Our model predicts
activity of voxels in and around the visual cortex and performs reconstruction
of corresponding visual inputs from neural activity. Finally, we investigate
brain regions contributing to visual decoding through saliency maps. We find
that the most contributing regions are the middle occipital area, the fusiform
area, and the calcarine, respectively employed in shape perception, complex
recognition (in particular face perception), and basic visual features such as
edges and contrasts. These functions being strongly solicited are in line with
the decoder's capability to reconstruct edges, faces, and contrasts. All in
all, this suggests the possibility to probe our understanding of visual
processing in films using as a proxy the behaviour of deep learning models such
as the one proposed in this paper.

</details>


### [24] [Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation](https://arxiv.org/abs/2507.11955)
*Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu*

Main category: cs.CV

TL;DR: PPAR框架通过渐进式对齐和原型重加权，利用CLIP模型提升语义分割的泛化能力，解决了现有方法在原型对齐和源数据利用上的不足。


<details>
  <summary>Details</summary>
Motivation: 现实应用中语义分割需要高泛化性，但现有方法在原型对齐和源数据利用上存在不足，如粗对齐策略、原型计算不准确及忽略特征适应性差异。

Method: 提出PPAR框架，定义OTP和VTP两种原型，采用渐进式对齐策略和原型重加权机制，优化特征对齐和源数据利用。

Result: 在多个基准测试中，PPAR实现了最先进的性能，验证了其有效性。

Conclusion: PPAR通过渐进式对齐和重加权机制，显著提升了语义分割的泛化能力，为领域泛化提供了新思路。

Abstract: Generalizable semantic segmentation aims to perform well on unseen target
domains, a critical challenge due to real-world applications requiring high
generalizability. Class-wise prototypes, representing class centroids, serve as
domain-invariant cues that benefit generalization due to their stability and
semantic consistency. However, this approach faces three challenges. First,
existing methods often adopt coarse prototypical alignment strategies, which
may hinder performance. Second, naive prototypes computed by averaging source
batch features are prone to overfitting and may be negatively affected by
unrelated source data. Third, most methods treat all source samples equally,
ignoring the fact that different features have varying adaptation difficulties.
To address these limitations, we propose a novel framework for generalizable
semantic segmentation: Prototypical Progressive Alignment and Reweighting
(PPAR), leveraging the strong generalization ability of the CLIP model.
Specifically, we define two prototypes: the Original Text Prototype (OTP) and
Visual Text Prototype (VTP), generated via CLIP to serve as a solid base for
alignment. We then introduce a progressive alignment strategy that aligns
features in an easy-to-difficult manner, reducing domain gaps gradually.
Furthermore, we propose a prototypical reweighting mechanism that estimates the
reliability of source data and adjusts its contribution, mitigating the effect
of irrelevant or harmful features (i.e., reducing negative transfer). We also
provide a theoretical analysis showing the alignment between our method and
domain generalization theory. Extensive experiments across multiple benchmarks
demonstrate that PPAR achieves state-of-the-art performance, validating its
effectiveness.

</details>


### [25] [Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos](https://arxiv.org/abs/2507.11967)
*Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki*

Main category: cs.CV

TL;DR: 论文提出了一种语言引导的对比音频-视觉掩码自编码器（LG-CAV-MAE），通过整合预训练的文本编码器，实现了跨音频、视觉和文本模态的学习。


<details>
  <summary>Details</summary>
Motivation: 提升音频-视觉表示学习的效果，通过结合文本模态增强模型的跨模态理解能力。

Method: 使用自动生成的高质量音频-视觉-文本三元组训练模型，结合CLAP过滤确保对齐性。

Result: 在音频-视觉检索和分类任务中表现优异，分别提升了5.6%和3.2%。

Conclusion: LG-CAV-MAE通过跨模态学习显著提升了性能，且无需人工标注。

Abstract: In this paper, we propose Language-Guided Contrastive Audio-Visual Masked
Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning.
LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual
masked autoencoders, enabling the model to learn across audio, visual and text
modalities. To train LG-CAV-MAE, we introduce an automatic method to generate
audio-visual-text triplets from unlabeled videos. We first generate frame-level
captions using an image captioning model and then apply CLAP-based filtering to
ensure strong alignment between audio and captions. This approach yields
high-quality audio-visual-text triplets without requiring manual annotations.
We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an
audio-visual classification task. Our method significantly outperforms existing
approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks
and a 3.2% improvement for the classification task.

</details>


### [26] [Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation](https://arxiv.org/abs/2507.11968)
*Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 论文提出了一个评估多模态大语言模型（MLLMs）在短视屏内容审核中安全性的框架，包括SVMA数据集和ChimeraBreak攻击策略，揭示了模型的显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 当前的安全评估多依赖单模态攻击，未能充分应对多模态联合攻击的脆弱性。

Method: 提出SVMA数据集和ChimeraBreak三模态攻击策略，测试MLLMs在视觉、听觉和语义推理上的鲁棒性。

Result: 实验显示MLLMs存在显著漏洞，攻击成功率（ASR）高，且模型对良性或违规内容存在分类偏差。

Conclusion: 研究为开发更鲁棒和安全的MLLMs提供了重要见解。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly used for content
moderation, yet their robustness in short-form video contexts remains
underexplored. Current safety evaluations often rely on unimodal attacks,
failing to address combined attack vulnerabilities. In this paper, we introduce
a comprehensive framework for evaluating the tri-modal safety of MLLMs. First,
we present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising
diverse short-form videos with human-guided synthetic adversarial attacks.
Second, we propose ChimeraBreak, a novel tri-modal attack strategy that
simultaneously challenges visual, auditory, and semantic reasoning pathways.
Extensive experiments on state-of-the-art MLLMs reveal significant
vulnerabilities with high Attack Success Rates (ASR). Our findings uncover
distinct failure modes, showing model biases toward misclassifying benign or
policy-violating content. We assess results using LLM-as-a-judge, demonstrating
attack reasoning efficacy. Our dataset and findings provide crucial insights
for developing more robust and safe MLLMs.

</details>


### [27] [GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2507.11969)
*Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: GS-Bias是一种高效的测试时适应（TTA）方法，通过全局和空间偏置提升视觉语言模型的性能，同时显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在性能和效率之间难以平衡，要么计算开销大，要么效果不稳定。

Method: GS-Bias引入全局偏置和空间偏置，直接添加到预训练模型的输出中，避免全反向传播。

Result: 在15个基准数据集上达到最优性能，例如在跨数据集和领域泛化中分别提升2.23%和2.72%，且内存占用仅为TPT的6.5%。

Conclusion: GS-Bias在高效性和性能上均优于现有方法，为TTA提供了新思路。

Abstract: Recent advances in test-time adaptation (TTA) for Vision-Language Models
(VLMs) have garnered increasing attention, particularly through the use of
multiple augmented views of a single image to boost zero-shot generalization.
Unfortunately, existing methods fail to strike a satisfactory balance between
performance and efficiency, either due to excessive overhead of tuning text
prompts or unstable benefits from handcrafted, training-free visual feature
enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias),
an efficient and effective TTA paradigm that incorporates two learnable biases
during TTA, unfolded as the global bias and spatial bias. Particularly, the
global bias captures the global semantic features of a test image by learning
consistency across augmented views, while spatial bias learns the semantic
coherence between regions in the image's spatial visual representation. It is
worth highlighting that these two sets of biases are directly added to the
logits outputed by the pretrained VLMs, which circumvent the full
backpropagation through VLM that hinders the efficiency of existing TTA
methods. This endows GS-Bias with extremely high efficiency while achieving
state-of-the-art performance on 15 benchmark datasets. For example, it achieves
a 2.23% improvement over TPT in cross-dataset generalization and a 2.72%
improvement in domain generalization, while requiring only 6.5% of TPT's memory
usage on ImageNet.

</details>


### [28] [EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models](https://arxiv.org/abs/2507.11980)
*Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu*

Main category: cs.CV

TL;DR: EC-Diff提出了一种混合边缘-云协作框架，通过梯度噪声估计和最优切换点提升扩散模型的推理速度与生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型中云推理时间过长与边缘模型输出不一致的问题。

Method: 采用K步噪声近似策略减少云推理频率，并通过两阶段贪婪搜索算法优化切换参数。

Result: 实验显示生成质量显著提升，推理速度平均提高2倍。

Conclusion: EC-Diff在保持生成质量的同时，显著加速了扩散模型的推理过程。

Abstract: Diffusion Models have shown remarkable proficiency in image and video
synthesis. As model size and latency increase limit user experience, hybrid
edge-cloud collaborative framework was recently proposed to realize fast
inference and high-quality generation, where the cloud model initiates
high-quality semantic planning and the edge model expedites later-stage
refinement. However, excessive cloud denoising prolongs inference time, while
insufficient steps cause semantic ambiguity, leading to inconsistency in edge
model output. To address these challenges, we propose EC-Diff that accelerates
cloud inference through gradient-based noise estimation while identifying the
optimal point for cloud-edge handoff to maintain generation quality.
Specifically, we design a K-step noise approximation strategy to reduce cloud
inference frequency by using noise gradients between steps and applying cloud
inference periodically to adjust errors. Then we design a two-stage greedy
search algorithm to efficiently find the optimal parameters for noise
approximation and edge model switching. Extensive experiments demonstrate that
our method significantly enhances generation quality compared to edge
inference, while achieving up to an average $2\times$ speedup in inference
compared to cloud inference. Video samples and source code are available at
https://ec-diff.github.io/.

</details>


### [29] [Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints](https://arxiv.org/abs/2507.11985)
*Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为MPAE的无监督部件发现方法，通过学习部件描述符和特征图，利用掩码恢复机制实现跨类别和场景的鲁棒部件发现。


<details>
  <summary>Details</summary>
Motivation: 现有无监督部件发现方法在跨类别和场景时缺乏鲁棒性，限制了其应用范围。

Method: MPAE通过学习部件描述符和特征图，利用掩码恢复机制，通过局部特征与描述符的相似性填充掩码区域，实现部件对齐。

Result: MPAE在复杂场景中能鲁棒地发现与实际物体形状匹配的部件，并通过实验验证了其有效性。

Conclusion: MPAE为无监督部件发现提供了更有效的范式，支持跨类别和场景的应用，并为遮挡和部件相似性研究奠定了基础。

Abstract: Part-level features are crucial for image understanding, but few studies
focus on them because of the lack of fine-grained labels. Although unsupervised
part discovery can eliminate the reliance on labels, most of them cannot
maintain robustness across various categories and scenarios, which restricts
their application range. To overcome this limitation, we present a more
effective paradigm for unsupervised part discovery, named Masked Part
Autoencoder (MPAE). It first learns part descriptors as well as a feature map
from the inputs and produces patch features from a masked version of the
original images. Then, the masked regions are filled with the learned part
descriptors based on the similarity between the local features and descriptors.
By restoring these masked patches using the part descriptors, they become
better aligned with their part shapes, guided by appearance features from
unmasked patches. Finally, MPAE robustly discovers meaningful parts that
closely match the actual object shapes, even in complex scenarios. Moreover,
several looser yet more effective constraints are proposed to enable MPAE to
identify the presence of parts across various scenarios and categories in an
unsupervised manner. This provides the foundation for addressing challenges
posed by occlusion and for exploring part similarity across multiple
categories. Extensive experiments demonstrate that our method robustly
discovers meaningful parts across various categories and scenarios. The code is
available at the project https://github.com/Jiahao-UTS/MPAE.

</details>


### [30] [SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation](https://arxiv.org/abs/2507.12027)
*Beining Xu,Siting Zhu,Hesheng Wang*

Main category: cs.CV

TL;DR: SGLoc是一种新颖的定位系统，通过利用3D高斯泼溅（3DGS）表示和语义信息直接回归相机姿态。


<details>
  <summary>Details</summary>
Motivation: 解决无需初始姿态先验的全局定位问题，利用语义信息提高定位精度。

Method: 采用多级姿态回归策略和语义全局检索算法，逐步估计和优化查询图像的6DoF姿态。

Result: 在12scenes和7scenes数据集上表现优于基线方法，展示了无需初始姿态先验的全局定位能力。

Conclusion: SGLoc通过结合语义信息和3DGS表示，实现了高效的全局定位，具有广泛的应用潜力。

Abstract: We propose SGLoc, a novel localization system that directly regresses camera
poses from 3D Gaussian Splatting (3DGS) representation by leveraging semantic
information. Our method utilizes the semantic relationship between 2D image and
3D scene representation to estimate the 6DoF pose without prior pose
information. In this system, we introduce a multi-level pose regression
strategy that progressively estimates and refines the pose of query image from
the global 3DGS map, without requiring initial pose priors. Moreover, we
introduce a semantic-based global retrieval algorithm that establishes
correspondences between 2D (image) and 3D (3DGS map). By matching the extracted
scene semantic descriptors of 2D query image and 3DGS semantic representation,
we align the image with the local region of the global 3DGS map, thereby
obtaining a coarse pose estimation. Subsequently, we refine the coarse pose by
iteratively optimizing the difference between the query image and the rendered
image from 3DGS. Our SGLoc demonstrates superior performance over baselines on
12scenes and 7scenes datasets, showing excellent capabilities in global
localization without initial pose prior. Code will be available at
https://github.com/IRMVLab/SGLoc.

</details>


### [31] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
*Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出一种零样本扩散管道，通过融合不同风格模型的去噪潜在空间，实现区域特定风格混合。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型难以在区域中精确控制多种风格，常导致单一风格主导。

Method: 在去噪潜在空间中进行风格融合，利用空间掩码和深度图条件控制。

Result: 成功实现区域特定风格混合，保持各风格保真度。

Conclusion: 该方法有效解决了多风格混合中的控制问题。

Abstract: Diffusion-based text-to-image models have achieved remarkable results in
synthesizing diverse images from text prompts and can capture specific artistic
styles via style personalization. However, their entangled latent space and
lack of smooth interpolation make it difficult to apply distinct painting
techniques in a controlled, regional manner, often causing one style to
dominate. To overcome this, we propose a zero-shot diffusion pipeline that
naturally blends multiple styles by performing style composition on the
denoised latents predicted during the flow-matching denoising process of
separately trained, style-specialized models. We leverage the fact that
lower-noise latents carry stronger stylistic information and fuse them across
heterogeneous diffusion pipelines using spatial masks, enabling precise,
region-specific style control. This mechanism preserves the fidelity of each
individual style while allowing user-guided mixing. Furthermore, to ensure
structural coherence across different models, we incorporate depth-map
conditioning via ControlNet into the diffusion framework. Qualitative and
quantitative experiments demonstrate that our method successfully achieves
region-specific style mixing according to the given masks.

</details>


### [32] [Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](https://arxiv.org/abs/2507.12083)
*Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen*

Main category: cs.CV

TL;DR: 论文提出了一种基于规划视角的运动预测方法，通过先推理行为意图再预测轨迹，结合逆向强化学习，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法直接预测轨迹，缺乏对行为意图的显式建模，影响预测准确性和可解释性。

Method: 采用查询中心的逆向强化学习（IRL）推理行为意图，结合分层DETR解码器和双向选择性状态空间模型生成轨迹。

Result: 在Argoverse和nuScenes数据集上表现优异，显著提升了预测置信度和性能。

Conclusion: 通过显式建模行为意图，结合IRL和分层解码器，实现了更准确和可解释的运动预测。

Abstract: Motion forecasting for on-road traffic agents presents both a significant
challenge and a critical necessity for ensuring safety in autonomous driving
systems. In contrast to most existing data-driven approaches that directly
predict future trajectories, we rethink this task from a planning perspective,
advocating a "First Reasoning, Then Forecasting" strategy that explicitly
incorporates behavior intentions as spatial guidance for trajectory prediction.
To achieve this, we introduce an interpretable, reward-driven intention
reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)
scheme. Our method first encodes traffic agents and scene elements into a
unified vectorized representation, then aggregates contextual features through
a query-centric paradigm. This enables the derivation of a reward distribution,
a compact yet informative representation of the target agent's behavior within
the given scene context via IRL. Guided by this reward heuristic, we perform
policy rollouts to reason about multiple plausible intentions, providing
valuable priors for subsequent trajectory generation. Finally, we develop a
hierarchical DETR-like decoder integrated with bidirectional selective state
space models to produce accurate future trajectories along with their
associated probabilities. Extensive experiments on the large-scale Argoverse
and nuScenes motion forecasting datasets demonstrate that our approach
significantly enhances trajectory prediction confidence, achieving highly
competitive performance relative to state-of-the-art methods.

</details>


### [33] [ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2507.11990)
*Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: ID-EA框架通过ID-Enhancer和ID-Adapter改进文本嵌入与视觉身份嵌入的对齐，显著提升个性化肖像生成中的身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有Textual Inversion方法在个性化肖像生成中难以保持面部身份一致性，主要由于文本与视觉嵌入空间的语义不对齐。

Method: ID-EA包含ID-Enhancer（整合身份嵌入与文本ID锚点）和ID-Adapter（调整文本条件以保持身份），通过优化预训练UNet模型的交叉注意力模块实现。

Result: ID-EA在身份保留指标上显著优于现有方法，且计算效率高，生成速度比现有方法快约15倍。

Conclusion: ID-EA通过改进文本与视觉嵌入的对齐，有效解决了身份一致性问题，为个性化肖像生成提供了高效解决方案。

Abstract: Recently, personalized portrait generation with a text-to-image diffusion
model has significantly advanced with Textual Inversion, emerging as a
promising approach for creating high-fidelity personalized images. Despite its
potential, current Textual Inversion methods struggle to maintain consistent
facial identity due to semantic misalignments between textual and visual
embedding spaces regarding identity. We introduce ID-EA, a novel framework that
guides text embeddings to align with visual identity embeddings, thereby
improving identity preservation in a personalized generation. ID-EA comprises
two key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned
Adapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings
with a textual ID anchor, refining visual identity embeddings derived from a
face recognition model using representative text embeddings. Then, the
ID-Adapter leverages the identity-enhanced embedding to adapt the text
condition, ensuring identity preservation by adjusting the cross-attention
module in the pre-trained UNet model. This process encourages the text features
to find the most related visual clues across the foreground snippets. Extensive
quantitative and qualitative evaluations demonstrate that ID-EA substantially
outperforms state-of-the-art methods in identity preservation metrics while
achieving remarkable computational efficiency, generating personalized
portraits approximately 15 times faster than existing approaches.

</details>


### [34] [AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models](https://arxiv.org/abs/2507.12414)
*Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding*

Main category: cs.CV

TL;DR: AutoVDC框架利用视觉语言模型自动检测视觉数据集中的错误标注，提升数据质量，并在KITTI和nuImages数据集上验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 人工标注存在缺陷且成本高昂，需自动化方法提升数据集质量。

Method: 提出AutoVDC框架，利用视觉语言模型检测错误标注，并通过注入错误验证其效果。

Result: 在KITTI和nuImages数据集上表现出高错误检测率，显著提升数据可靠性。

Conclusion: AutoVDC能有效提升自动驾驶大规模数据集的质量和准确性。

Abstract: Training of autonomous driving systems requires extensive datasets with
precise annotations to attain robust performance. Human annotations suffer from
imperfections, and multiple iterations are often needed to produce high-quality
datasets. However, manually reviewing large datasets is laborious and
expensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)
framework and investigate the utilization of Vision-Language Models (VLMs) to
automatically identify erroneous annotations in vision datasets, thereby
enabling users to eliminate these errors and enhance data quality. We validate
our approach using the KITTI and nuImages datasets, which contain object
detection benchmarks for autonomous driving. To test the effectiveness of
AutoVDC, we create dataset variants with intentionally injected erroneous
annotations and observe the error detection rate of our approach. Additionally,
we compare the detection rates using different VLMs and explore the impact of
VLM fine-tuning on our pipeline. The results demonstrate our method's high
performance in error detection and data cleaning experiments, indicating its
potential to significantly improve the reliability and accuracy of large-scale
production datasets in autonomous driving.

</details>


### [35] [SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2507.11994)
*Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui*

Main category: cs.CV

TL;DR: SAMST是一种半监督语义分割方法，利用Segment Anything Model（SAM）的零样本泛化和边界检测能力，通过迭代优化伪标签提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决公共遥感数据集因分辨率和类别定义不一致导致的通用性不足问题，利用大量未标注数据。

Method: 结合监督模型自训练和SAM伪标签优化器，通过阈值过滤、提示生成和标签细化模块迭代优化伪标签。

Result: 在Potsdam数据集上验证了SAMST的有效性和可行性，提升了伪标签准确性和模型性能。

Conclusion: SAMST通过结合大模型泛化能力与小模型训练效率，解决了遥感语义分割中标注数据不足的挑战。

Abstract: Public remote sensing datasets often face limitations in universality due to
resolution variability and inconsistent land cover category definitions. To
harness the vast pool of unlabeled remote sensing data, we propose SAMST, a
semi-supervised semantic segmentation method. SAMST leverages the strengths of
the Segment Anything Model (SAM) in zero-shot generalization and boundary
detection. SAMST iteratively refines pseudo-labels through two main components:
supervised model self-training using both labeled and pseudo-labeled data, and
a SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three
modules: a Threshold Filter Module for preprocessing, a Prompt Generation
Module for extracting connected regions and generating prompts for SAM, and a
Label Refinement Module for final label stitching. By integrating the
generalization power of large models with the training efficiency of small
models, SAMST improves pseudo-label accuracy, thereby enhancing overall model
performance. Experiments on the Potsdam dataset validate the effectiveness and
feasibility of SAMST, demonstrating its potential to address the challenges
posed by limited labeled data in remote sensing semantic segmentation.

</details>


### [36] [AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation](https://arxiv.org/abs/2507.12001)
*Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan*

Main category: cs.CV

TL;DR: 论文提出AUBlendSet数据集和AUBlendNet网络，用于基于AU-Blendshape的细粒度3D面部表情操纵。


<details>
  <summary>Details</summary>
Motivation: 现有3D面部动画在细粒度风格化表情操纵上存在挑战，主要由于缺乏合适的数据集。

Method: 基于32个标准面部动作单元（AUs）构建AUBlendSet数据集，并提出AUBlendNet网络学习不同风格的AU-Blendshape基向量。

Result: 通过实验验证了AUBlendSet和AUBlendNet在风格化表情操纵、语音驱动动画和情感识别数据增强中的有效性。

Conclusion: AUBlendSet和AUBlendNet在3D面部动画任务中具有重要潜力，填补了相关领域空白。

Abstract: While 3D facial animation has made impressive progress, challenges still
exist in realizing fine-grained stylized 3D facial expression manipulation due
to the lack of appropriate datasets. In this paper, we introduce the
AUBlendSet, a 3D facial dataset based on AU-Blendshape representation for
fine-grained facial expression manipulation across identities. AUBlendSet is a
blendshape data collection based on 32 standard facial action units (AUs)
across 500 identities, along with an additional set of facial postures
annotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to
learn AU-Blendshape basis vectors for different character styles. AUBlendNet
predicts, in parallel, the AU-Blendshape basis vectors of the corresponding
style for a given identity mesh, thereby achieving stylized 3D emotional facial
manipulation. We comprehensively validate the effectiveness of AUBlendSet and
AUBlendNet through tasks such as stylized facial expression manipulation,
speech-driven emotional facial animation, and emotion recognition data
augmentation. Through a series of qualitative and quantitative experiments, we
demonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D
facial animation tasks. To the best of our knowledge, AUBlendSet is the first
dataset, and AUBlendNet is the first network for continuous 3D facial
expression manipulation for any identity through facial AUs. Our source code is
available at https://github.com/wslh852/AUBlendNet.git.

</details>


### [37] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
*Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种基于电路理论的频率动态注意力调制（FDAM）方法，通过注意力反转（AttInv）和频率动态缩放（FreqScale）改进ViTs的频率响应，避免细节丢失，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有ViTs的注意力机制导致频率消失，丢失关键细节和纹理。

Method: 提出FDAM，包含AttInv（生成互补高通滤波）和FreqScale（动态加权频率分量）。

Result: 在多种模型（如SegFormer、DeiT）和任务（语义分割、目标检测）中表现提升，并在遥感检测中达到SOTA。

Conclusion: FDAM有效解决了ViTs的频率消失问题，显著提升了性能。

Abstract: Vision Transformers (ViTs) have significantly advanced computer vision,
demonstrating strong performance across various tasks. However, the attention
mechanism in ViTs makes each layer function as a low-pass filter, and the
stacked-layer architecture in existing transformers suffers from frequency
vanishing. This leads to the loss of critical details and textures. We propose
a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention
Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly
modulates the overall frequency response of ViTs and consists of two
techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling
(FreqScale). Since circuit theory uses low-pass filters as fundamental
elements, we introduce AttInv, a method that generates complementary high-pass
filtering by inverting the low-pass filter in the attention matrix, and
dynamically combining the two. We further design FreqScale to weight different
frequency components for fine-grained adjustments to the target response
function. Through feature similarity analysis and effective rank evaluation, we
demonstrate that our approach avoids representation collapse, leading to
consistent performance improvements across various models, including SegFormer,
DeiT, and MaskDINO. These improvements are evident in tasks such as semantic
segmentation, object detection, and instance segmentation. Additionally, we
apply our method to remote sensing detection, achieving state-of-the-art
results in single-scale settings. The code is available at
\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.

</details>


### [38] [Dual form Complementary Masking for Domain-Adaptive Image Segmentation](https://arxiv.org/abs/2507.12008)
*Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 论文提出MaskTwins框架，通过将掩码重构作为稀疏信号重构问题，理论证明互补掩码在提取域无关特征上的优势，并在UDA任务中实现端到端训练。


<details>
  <summary>Details</summary>
Motivation: 现有工作仅将掩码视为图像变形的一种形式，缺乏理论分析，未能充分利用掩码重构在特征提取和表示学习中的潜力。

Method: 将掩码重构重新定义为稀疏信号重构问题，提出MaskTwins框架，通过互补掩码强制预测一致性，提取跨域的结构模式。

Result: 实验证明MaskTwins在自然和生物图像分割任务中优于基线方法，无需单独预训练即可提取域不变特征。

Conclusion: MaskTwins为域自适应分割提供了新范式，展示了掩码重构在特征提取中的显著优势。

Abstract: Recent works have correlated Masked Image Modeling (MIM) with consistency
regularization in Unsupervised Domain Adaptation (UDA). However, they merely
treat masking as a special form of deformation on the input images and neglect
the theoretical analysis, which leads to a superficial understanding of masked
reconstruction and insufficient exploitation of its potential in enhancing
feature extraction and representation learning. In this paper, we reframe
masked reconstruction as a sparse signal reconstruction problem and
theoretically prove that the dual form of complementary masks possesses
superior capabilities in extracting domain-agnostic image features. Based on
this compelling insight, we propose MaskTwins, a simple yet effective UDA
framework that integrates masked reconstruction directly into the main training
pipeline. MaskTwins uncovers intrinsic structural patterns that persist across
disparate domains by enforcing consistency between predictions of images masked
in complementary ways, enabling domain generalization in an end-to-end manner.
Extensive experiments verify the superiority of MaskTwins over baseline methods
in natural and biological image segmentation. These results demonstrate the
significant advantages of MaskTwins in extracting domain-invariant features
without the need for separate pre-training, offering a new paradigm for
domain-adaptive segmentation.

</details>


### [39] [SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection](https://arxiv.org/abs/2507.12017)
*Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng*

Main category: cs.CV

TL;DR: 论文提出了一种基于解耦-耦合策略的SS-DC框架，用于解决可见光到红外（RGB-IR）域的无监督域自适应目标检测问题，通过光谱分解和空间-光谱耦合方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将RGB域视为统一域，忽略了其内部的多个子域（如白天、夜晚和雾天场景）。论文认为解耦这些子域中的域不变（DI）和域特定（DS）特征对RGB-IR域适应有益。

Method: 设计了光谱自适应幂等解耦（SAID）模块，通过基于滤波器组的光谱处理范式和自蒸馏驱动的解耦损失实现更准确的光谱域解耦；提出了一种新的空间-光谱耦合方法，结合DI特征金字塔实现联合耦合。

Result: 实验表明，该方法显著提升了基线性能，并在多个RGB-IR数据集上优于现有UDAOD方法，包括基于FLIR-ADAS数据集的新实验协议。

Conclusion: 通过解耦-耦合策略，论文提出的SS-DC框架有效提升了RGB-IR域自适应目标检测的性能，为多子域场景下的域适应提供了新思路。

Abstract: Unsupervised domain adaptive object detection (UDAOD) from the visible domain
to the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB
domain as a unified domain and neglect the multiple subdomains within it, such
as daytime, nighttime, and foggy scenes. We argue that decoupling the
domain-invariant (DI) and domain-specific (DS) features across these multiple
subdomains is beneficial for RGB-IR domain adaptation. To this end, this paper
proposes a new SS-DC framework based on a decoupling-coupling strategy. In
terms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)
module in the aspect of spectral decomposition. Due to the style and content
information being highly embedded in different frequency bands, this module can
decouple DI and DS components more accurately and interpretably. A novel filter
bank-based spectral processing paradigm and a self-distillation-driven
decoupling loss are proposed to improve the spectral domain decoupling. In
terms of coupling, a new spatial-spectral coupling method is proposed, which
realizes joint coupling through spatial and spectral DI feature pyramids.
Meanwhile, this paper introduces DS from decoupling to reduce the domain bias.
Extensive experiments demonstrate that our method can significantly improve the
baseline performance and outperform existing UDAOD methods on multiple RGB-IR
datasets, including a new experimental protocol proposed in this paper based on
the FLIR-ADAS dataset.

</details>


### [40] [Dataset Ownership Verification for Pre-trained Masked Models](https://arxiv.org/abs/2507.12022)
*Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song*

Main category: cs.CV

TL;DR: 提出了一种针对掩码模型的数据集所有权验证方法DOV4MM，填补了现有技术空白，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 高质量开源数据集面临被滥用的风险，现有验证技术不适用于掩码模型，亟需新方法保护数据集所有者权益。

Method: 基于掩码信息重建难度的差异，设计DOV4MM方法验证黑盒模型是否在目标数据集上预训练。

Result: 在ImageNet-1K和WikiText-103上测试，DOV4MM显著优于现有方法，p值远低于0.05。

Conclusion: DOV4MM为掩码模型的数据集所有权验证提供了有效解决方案，保护了数据集所有者的权益。

Abstract: High-quality open-source datasets have emerged as a pivotal catalyst driving
the swift advancement of deep learning, while facing the looming threat of
potential exploitation. Protecting these datasets is of paramount importance
for the interests of their owners. The verification of dataset ownership has
evolved into a crucial approach in this domain; however, existing verification
techniques are predominantly tailored to supervised models and contrastive
pre-trained models, rendering them ill-suited for direct application to the
increasingly prevalent masked models. In this work, we introduce the inaugural
methodology addressing this critical, yet unresolved challenge, termed Dataset
Ownership Verification for Masked Modeling (DOV4MM). The central objective is
to ascertain whether a suspicious black-box model has been pre-trained on a
particular unlabeled dataset, thereby assisting dataset owners in safeguarding
their rights. DOV4MM is grounded in our empirical observation that when a model
is pre-trained on the target dataset, the difficulty of reconstructing masked
information within the embedding space exhibits a marked contrast to models not
pre-trained on that dataset. We validated the efficacy of DOV4MM through ten
masked image models on ImageNet-1K and four masked language models on
WikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis,
with a $p$-value considerably below 0.05, surpassing all prior approaches. Code
is available at https://github.com/xieyc99/DOV4MM.

</details>


### [41] [MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model](https://arxiv.org/abs/2507.12023)
*Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li*

Main category: cs.CV

TL;DR: 论文提出了一种多变量自回归空气污染物预测模型（MVAR），解决了现有研究忽视污染物间相互作用及空间响应多样性的问题，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 空气污染物对环境和人类健康构成重大威胁，准确预测污染物浓度对污染预警和政策制定至关重要。现有研究多关注单一污染物预测，忽视了多污染物间的相互作用及其空间响应多样性。

Method: 提出MVAR模型，减少对长时间窗口输入的依赖，提高数据利用效率；设计了多变量自回归训练范式，支持120小时长期预测；开发了气象耦合空间变换模块，灵活结合气象预报数据。

Result: 实验结果表明，MVAR模型优于现有方法，验证了其架构的有效性。

Conclusion: MVAR模型在多变量空气污染物预测中表现出色，为污染预警和政策制定提供了有力工具。

Abstract: Air pollutants pose a significant threat to the environment and human health,
thus forecasting accurate pollutant concentrations is essential for pollution
warnings and policy-making. Existing studies predominantly focus on
single-pollutant forecasting, neglecting the interactions among different
pollutants and their diverse spatial responses. To address the practical needs
of forecasting multivariate air pollutants, we propose MultiVariate
AutoRegressive air pollutants forecasting model (MVAR), which reduces the
dependency on long-time-window inputs and boosts the data utilization
efficiency. We also design the Multivariate Autoregressive Training Paradigm,
enabling MVAR to achieve 120-hour long-term sequential forecasting.
Additionally, MVAR develops Meteorological Coupled Spatial Transformer block,
enabling the flexible coupling of AI-based meteorological forecasts while
learning the interactions among pollutants and their diverse spatial responses.
As for the lack of standardized datasets in air pollutants forecasting, we
construct a comprehensive dataset covering 6 major pollutants across 75 cities
in North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0
forecast data. Experimental results demonstrate that the proposed model
outperforms state-of-the-art methods and validate the effectiveness of the
proposed architecture.

</details>


### [42] [3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering](https://arxiv.org/abs/2507.12026)
*Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu*

Main category: cs.CV

TL;DR: 3D-MoRe是一种新范式，利用基础模型生成大规模3D-语言数据集，显著提升了在ScanQA和ScanRefer任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 满足室内场景任务（如问答和密集标注）对多样化、可扩展数据的需求。

Method: 整合多模态嵌入、跨模态交互和语言模型解码器，处理自然语言指令和3D场景数据，结合数据增强和语义过滤。

Result: 在ScanQA上CIDEr分数提升2.15%，在ScanRefer上CIDEr@0.5提升1.84%。

Conclusion: 3D-MoRe有效提升了3D场景任务性能，代码和数据集将公开。

Abstract: With the growing need for diverse and scalable data in indoor scene tasks,
such as question answering and dense captioning, we propose 3D-MoRe, a novel
paradigm designed to generate large-scale 3D-language datasets by leveraging
the strengths of foundational models. The framework integrates key components,
including multi-modal embedding, cross-modal interaction, and a language model
decoder, to process natural language instructions and 3D scene data. This
approach facilitates enhanced reasoning and response generation in complex 3D
environments. Using the ScanNet 3D scene dataset, along with text annotations
from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs
and 73,000 object descriptions across 1,513 scenes. We also employ various data
augmentation techniques and implement semantic filtering to ensure high-quality
data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms
state-of-the-art baselines, with the CIDEr score improving by 2.15\%.
Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5
by 1.84\%, highlighting its effectiveness in both tasks. Our code and generated
datasets will be publicly released to benefit the community, and both can be
accessed on the https://3D-MoRe.github.io.

</details>


### [43] [Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery](https://arxiv.org/abs/2507.12029)
*Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 本文提出了一种名为IICMVNCD的新框架，首次在多视图数据中探索新类发现（NCD），解决了现有方法的单视图限制和伪标签依赖问题。


<details>
  <summary>Details</summary>
Motivation: 现有NCD方法仅适用于单视图数据，且依赖伪标签导致性能不稳定。本文旨在解决这些问题，并探索多视图数据中的NCD。

Method: 通过矩阵分解在视图内捕获已知类和新类的分布一致性，同时在视图间利用已知类关系指导新类聚类，动态调整视图权重。

Result: 实验验证了所提方法的有效性。

Conclusion: IICMVNCD框架在多视图NCD中表现出色，解决了现有方法的局限性。

Abstract: In this paper, we address the problem of novel class discovery (NCD), which
aims to cluster novel classes by leveraging knowledge from disjoint known
classes. While recent advances have made significant progress in this area,
existing NCD methods face two major limitations. First, they primarily focus on
single-view data (e.g., images), overlooking the increasingly common multi-view
data, such as multi-omics datasets used in disease diagnosis. Second, their
reliance on pseudo-labels to supervise novel class clustering often results in
unstable performance, as pseudo-label quality is highly sensitive to factors
such as data noise and feature dimensionality. To address these challenges, we
propose a novel framework named Intra-view and Inter-view Correlation Guided
Multi-view Novel Class Discovery (IICMVNCD), which is the first attempt to
explore NCD in multi-view setting so far. Specifically, at the intra-view
level, leveraging the distributional similarity between known and novel
classes, we employ matrix factorization to decompose features into
view-specific shared base matrices and factor matrices. The base matrices
capture distributional consistency among the two datasets, while the factor
matrices model pairwise relationships between samples. At the inter-view level,
we utilize view relationships among known classes to guide the clustering of
novel classes. This includes generating predicted labels through the weighted
fusion of factor matrices and dynamically adjusting view weights of known
classes based on the supervision loss, which are then transferred to novel
class learning. Experimental results validate the effectiveness of our proposed
approach.

</details>


### [44] [MoViAD: Modular Visual Anomaly Detection](https://arxiv.org/abs/2507.12049)
*Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto*

Main category: cs.CV

TL;DR: MoViAD是一个模块化库，用于快速访问最先进的视觉异常检测（VAD）模型和工具，支持多种场景和部署需求。


<details>
  <summary>Details</summary>
Motivation: 解决VAD领域中异常数据稀缺和需要无监督训练的挑战，加速研究和部署。

Method: 提供模块化库，集成多种VAD模型、训练器、数据集和实用工具，支持边缘和物联网部署。

Result: MoViAD支持多种场景，提供优化模型和效率分析工具，便于快速部署和扩展。

Conclusion: MoViAD为工程师和研究人员提供了灵活、高效的VAD解决方案。

Abstract: VAD is a critical field in machine learning focused on identifying deviations
from normal patterns in images, often challenged by the scarcity of anomalous
data and the need for unsupervised training. To accelerate research and
deployment in this domain, we introduce MoViAD, a comprehensive and highly
modular library designed to provide fast and easy access to state-of-the-art
VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array
of scenarios, including continual, semi-supervised, few-shots, noisy, and many
more. In addition, it addresses practical deployment challenges through
dedicated Edge and IoT settings, offering optimized models and backbones, along
with quantization and compression utilities for efficient on-device execution
and distributed inference. MoViAD integrates a selection of backbones, robust
evaluation VAD metrics (pixel-level and image-level) and useful profiling tools
for efficiency analysis. The library is designed for fast, effortless
deployment, enabling machine learning engineers to easily use it for their
specific setup with custom models, datasets, and backbones. At the same time,
it offers the flexibility and extensibility researchers need to develop and
experiment with new methods.

</details>


### [45] [InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](https://arxiv.org/abs/2507.12060)
*Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: InstructFLIP是一种基于视觉语言模型（VLM）的新型框架，通过文本指导增强跨域泛化能力，显著减少训练冗余并提升反欺骗（FAS）性能。


<details>
  <summary>Details</summary>
Motivation: 解决跨域泛化中的语义理解不足和训练冗余问题。

Method: 结合VLM增强视觉感知，采用元域策略学习统一模型，并解耦指令为内容和风格组件。

Result: 在准确率上超越SOTA模型，显著减少跨域训练冗余。

Conclusion: InstructFLIP通过文本指导和指令解耦，有效提升FAS系统的泛化能力和效率。

Abstract: Face anti-spoofing (FAS) aims to construct a robust system that can withstand
diverse attacks. While recent efforts have concentrated mainly on cross-domain
generalization, two significant challenges persist: limited semantic
understanding of attack types and training redundancy across domains. We
address the first by integrating vision-language models (VLMs) to enhance the
perception of visual input. For the second challenge, we employ a meta-domain
strategy to learn a unified model that generalizes well across multiple
domains. Our proposed InstructFLIP is a novel instruction-tuned framework that
leverages VLMs to enhance generalization via textual guidance trained solely on
a single domain. At its core, InstructFLIP explicitly decouples instructions
into content and style components, where content-based instructions focus on
the essential semantics of spoofing, and style-based instructions consider
variations related to the environment and camera characteristics. Extensive
experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA
models in accuracy and substantially reducing training redundancy across
diverse domains in FAS. Project website is available at
https://kunkunlin1221.github.io/InstructFLIP.

</details>


### [46] [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)
*Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding*

Main category: cs.CV

TL;DR: MS-DETR框架通过统一学习运动与语义特征，提升视频时刻检索与高光检测性能，并通过对比去噪学习解决数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 现有DETR框架未充分利用视频中时间运动与空间语义的复杂关系，存在性能提升空间。

Method: 提出MS-DETR框架，编码器显式建模运动与语义的模态内相关性，解码器利用跨模态任务相关性进行定位与边界细化，并通过生成策略和对比去噪学习解决数据稀疏问题。

Result: 在四个基准测试中显著优于现有最优模型。

Conclusion: MS-DETR通过运动与语义的统一学习及数据增强策略，显著提升了视频时刻检索与高光检测的性能。

Abstract: Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint
specific moments and assess clip-wise relevance based on the text query. While
DETR-based joint frameworks have made significant strides, there remains
untapped potential in harnessing the intricate relationships between temporal
motion and spatial semantics within video content. In this paper, we propose
the Motion-Semantics DETR (MS-DETR), a framework that captures rich
motion-semantics features through unified learning for MR/HD tasks. The encoder
first explicitly models disentangled intra-modal correlations within motion and
semantics dimensions, guided by the given text queries. Subsequently, the
decoder utilizes the task-wise correlation across temporal motion and spatial
semantics dimensions to enable precise query-guided localization for MR and
refined highlight boundary delineation for HD. Furthermore, we observe the
inherent sparsity dilemma within the motion and semantics dimensions of MR/HD
datasets. To address this issue, we enrich the corpus from both dimensions by
generation strategies and propose contrastive denoising learning to ensure the
above components learn robustly and effectively. Extensive experiments on four
MR/HD benchmarks demonstrate that our method outperforms existing
state-of-the-art models by a margin. Our code is available at
https://github.com/snailma0229/MS-DETR.git.

</details>


### [47] [YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association](https://arxiv.org/abs/2507.12087)
*Xiang Yu,Xinyao Liu,Guang Liang*

Main category: cs.CV

TL;DR: 本文提出了一种针对无人机视角下小型敏捷多目标（如鸟类）跟踪的冠军解决方案，通过创新的检测和关联方法，显著提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 解决无人机视角下小型多目标跟踪的三大挑战：目标外观特征稀缺、相机与目标动态复杂纠缠、频繁遮挡和身份模糊。

Method: 采用跟踪-检测范式，提出SliceTrain检测增强框架和基于运动方向维护与自适应相似性度量的独立外观跟踪器。

Result: 在SMOT4SB测试集上达到SO-HOTA分数55.205，性能领先。

Conclusion: 验证了框架在复杂SMOT问题中的有效性和先进性，代码将开源。

Abstract: Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned
Aerial Vehicle (UAV) perspective is a highly challenging computer vision task.
The difficulty stems from three main sources: the extreme scarcity of target
appearance features, the complex motion entanglement caused by the combined
dynamics of the camera and the targets themselves, and the frequent occlusions
and identity ambiguity arising from dense flocking behavior. This paper details
our championship-winning solution in the MVA 2025 "Finding Birds" Small
Multi-Object Tracking Challenge (SMOT4SB), which adopts the
tracking-by-detection paradigm with targeted innovations at both the detection
and association levels. On the detection side, we propose a systematic training
enhancement framework named \textbf{SliceTrain}. This framework, through the
synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic
augmentation, effectively addresses the problem of insufficient learning for
small objects in high-resolution image training. On the tracking side, we
designed a robust tracker that is completely independent of appearance
information. By integrating a \textbf{motion direction maintenance (EMA)}
mechanism and an \textbf{adaptive similarity metric} combining \textbf{bounding
box expansion and distance penalty} into the OC-SORT framework, our tracker can
stably handle irregular motion and maintain target identities. Our method
achieves state-of-the-art performance on the SMOT4SB public test set, reaching
an SO-HOTA score of \textbf{55.205}, which fully validates the effectiveness
and advancement of our framework in solving complex real-world SMOT problems.
The source code will be made available at
https://github.com/Salvatore-Love/YOLOv8-SMOT.

</details>


### [48] [BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images](https://arxiv.org/abs/2507.12095)
*Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的3D车辆重建方法，通过结合深度图和DUSt3R架构，解决了稀疏视角输入下的重建问题，并在多个基准测试中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如NeRF和Gaussian Splatting）依赖密集视角输入，限制了实际应用。本文旨在解决稀疏视角下的车辆重建问题。

Method: 结合深度图和DUSt3R架构改进Gaussian Splatting，引入选择性光度损失，并构建包含合成和真实公共交通工具的新数据集。

Result: 实验表明，该方法在多个基准测试中表现优异，能够在输入受限条件下实现高质量重建。

Conclusion: 该方法显著提升了稀疏视角输入下的3D车辆重建性能，具有实际应用潜力。

Abstract: Accurate 3D reconstruction of vehicles is vital for applications such as
vehicle inspection, predictive maintenance, and urban planning. Existing
methods like Neural Radiance Fields and Gaussian Splatting have shown
impressive results but remain limited by their reliance on dense input views,
which hinders real-world applicability. This paper addresses the challenge of
reconstructing vehicles from sparse-view inputs, leveraging depth maps and a
robust pose estimation architecture to synthesize novel views and augment
training data. Specifically, we enhance Gaussian Splatting by integrating a
selective photometric loss, applied only to high-confidence pixels, and
replacing standard Structure-from-Motion pipelines with the DUSt3R architecture
to improve camera pose estimation. Furthermore, we present a novel dataset
featuring both synthetic and real-world public transportation vehicles,
enabling extensive evaluation of our approach. Experimental results demonstrate
state-of-the-art performance across multiple benchmarks, showcasing the
method's ability to achieve high-quality reconstructions even under constrained
input conditions.

</details>


### [49] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
*Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei*

Main category: cs.CV

TL;DR: 论文提出了一种通过3D模拟构建阴影数据集的方法，并开发了DeepShade模型来生成随时间变化的阴影图像，用于改进高温天气下的路径规划。


<details>
  <summary>Details</summary>
Motivation: 全球变暖加剧了热浪对公共健康的威胁，但现有路径规划系统缺乏阴影信息。论文旨在解决卫星图像噪声大和训练数据不足的问题。

Method: 1. 通过Blender模拟构建多样化的阴影数据集；2. 提出DeepShade模型，结合RGB和Canny边缘层，利用对比学习捕捉阴影的时间变化规律。

Result: 模型在生成阴影图像方面表现优异，并成功应用于美国亚利桑那州Tempe的路径规划中。

Conclusion: 该研究为极端高温天气下的城市规划提供了参考，具有潜在的实际应用价值。

Abstract: Heatwaves pose a significant threat to public health, especially as global
warming intensifies. However, current routing systems (e.g., online maps) fail
to incorporate shade information due to the difficulty of estimating shades
directly from noisy satellite imagery and the limited availability of training
data for generative models. In this paper, we address these challenges through
two main contributions. First, we build an extensive dataset covering diverse
longitude-latitude regions, varying levels of building density, and different
urban layouts. Leveraging Blender-based 3D simulations alongside building
outlines, we capture building shadows under various solar zenith angles
throughout the year and at different times of day. These simulated shadows are
aligned with satellite images, providing a rich resource for learning shade
patterns. Second, we propose the DeepShade, a diffusion-based model designed to
learn and synthesize shade variations over time. It emphasizes the nuance of
edge features by jointly considering RGB with the Canny edge layer, and
incorporates contrastive learning to capture the temporal change rules of
shade. Then, by conditioning on textual descriptions of known conditions (e.g.,
time of day, solar angles), our framework provides improved performance in
generating shade images. We demonstrate the utility of our approach by using
our shade predictions to calculate shade ratios for real-world route planning
in Tempe, Arizona. We believe this work will benefit society by providing a
reference for urban planning in extreme heat weather and its potential
practical applications in the environment.

</details>


### [50] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: Med-OoD框架通过引入OoD数据监督，解决了医学图像分割中的误分类问题，无需外部数据或额外标注，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割网络在有限和不完美数据集上容易误分类，OoD数据在其他视觉任务中表现优异，因此探索其在医学分割中的应用。

Method: 提出Med-OoD框架，利用OoD数据监督完全监督的分割网络，无需外部数据、特征正则化目标或额外标注。

Result: 在Lizard数据集上显著减少误分类，性能大幅提升；仅用OoD数据训练的网络达到76.1% mIoU。

Conclusion: Med-OoD展示了OoD数据在医学分割中的潜力，提出了一种新的学习范式，鼓励重新思考OoD数据的作用。

Abstract: Biomedical segmentation networks easily suffer from the unexpected
misclassification between foreground and background objects when learning on
limited and imperfect medical datasets. Inspired by the strong power of
Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric
framework, Med-OoD to address this issue by introducing OoD data supervision
into fully-supervised biomedical segmentation with none of the following needs:
(i) external data sources, (ii) feature regularization objectives, (iii)
additional annotations. Our method can be seamlessly integrated into
segmentation networks without any modification on the architectures. Extensive
experiments show that Med-OoD largely prevents various segmentation networks
from the pixel misclassification on medical images and achieves considerable
performance improvements on Lizard dataset. We also present an emerging
learning paradigm of training a medical segmentation network completely using
OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU
as test result. We hope this learning paradigm will attract people to rethink
the roles of OoD data. Code is made available at
https://github.com/StudioYG/Med-OoD.

</details>


### [51] [Non-Adaptive Adversarial Face Generation](https://arxiv.org/abs/2507.12107)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo*

Main category: cs.CV

TL;DR: 提出一种基于人脸识别系统特征空间结构的新型对抗攻击方法，通过利用属性子球体生成对抗性人脸，仅需少量非自适应查询即可实现高成功率。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统（FRSs）的对抗攻击对安全和隐私构成严重威胁，尤其是在身份验证场景中。现有方法依赖迭代优化或迁移性，效率较低且不适用于商业FRSs。

Method: 利用FRS特征空间中的属性子球体结构（如同性别或种族），生成视觉差异大但被识别为目标身份的对抗性人脸，仅需单次非自适应查询。

Result: 在AWS CompareFaces API上，仅用100张人脸图像的非自适应查询，攻击成功率超过93%。

Conclusion: 该方法高效且无需依赖迁移性或开源模型，能够生成具有特定属性的对抗性人脸，显著提升攻击效果。

Abstract: Adversarial attacks on face recognition systems (FRSs) pose serious security
and privacy threats, especially when these systems are used for identity
verification. In this paper, we propose a novel method for generating
adversarial faces-synthetic facial images that are visually distinct yet
recognized as a target identity by the FRS. Unlike iterative optimization-based
approaches (e.g., gradient descent or other iterative solvers), our method
leverages the structural characteristics of the FRS feature space. We figure
out that individuals sharing the same attribute (e.g., gender or race) form an
attributed subsphere. By utilizing such subspheres, our method achieves both
non-adaptiveness and a remarkably small number of queries. This eliminates the
need for relying on transferability and open-source surrogate models, which
have been a typical strategy when repeated adaptive queries to commercial FRSs
are impossible. Despite requiring only a single non-adaptive query consisting
of 100 face images, our method achieves a high success rate of over 93% against
AWS's CompareFaces API at its default threshold. Furthermore, unlike many
existing attacks that perturb a given image, our method can deliberately
produce adversarial faces that impersonate the target identity while exhibiting
high-level attributes chosen by the adversary.

</details>


### [52] [LidarPainter: One-Step Away From Any Lidar View To Novel Guidance](https://arxiv.org/abs/2507.12114)
*Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: LidarPainter是一种基于扩散模型的实时方法，通过稀疏LiDAR数据和损坏渲染恢复一致的驾驶场景视图，显著提升重建质量和效率。


<details>
  <summary>Details</summary>
Motivation: 动态驾驶场景重建在数字孪生和自动驾驶模拟中至关重要，但现有方法在偏离输入轨迹时会出现背景和车辆模型损坏，且存在不一致、变形和耗时等问题。

Method: 提出LidarPainter，一种一步扩散模型，从稀疏LiDAR条件和损坏渲染中实时恢复一致驾驶视图，支持高保真车道偏移重建。

Result: 实验表明，LidarPainter在速度、质量和资源效率上优于现有方法，比StreetCrafter快7倍，GPU内存需求仅为五分之一，并支持基于文本提示的风格化生成。

Conclusion: LidarPainter为驾驶场景重建提供了一种高效、高质量且灵活的解决方案，支持多样化的场景扩展。

Abstract: Dynamic driving scene reconstruction is of great importance in fields like
digital twin system and autonomous driving simulation. However, unacceptable
degradation occurs when the view deviates from the input trajectory, leading to
corrupted background and vehicle models. To improve reconstruction quality on
novel trajectory, existing methods are subject to various limitations including
inconsistency, deformation, and time consumption. This paper proposes
LidarPainter, a one-step diffusion model that recovers consistent driving views
from sparse LiDAR condition and artifact-corrupted renderings in real-time,
enabling high-fidelity lane shifts in driving scene reconstruction. Extensive
experiments show that LidarPainter outperforms state-of-the-art methods in
speed, quality and resource efficiency, specifically 7 x faster than
StreetCrafter with only one fifth of GPU memory required. LidarPainter also
supports stylized generation using text prompts such as "foggy" and "night",
allowing for a diverse expansion of the existing asset library.

</details>


### [53] [Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph](https://arxiv.org/abs/2507.12123)
*Sergey Linok,Gleb Naumov*

Main category: cs.CV

TL;DR: OVIGo-3DHSG方法通过3D层次场景图和开放词汇基础模型，实现室内环境中物体的开放词汇定位，结合大型语言模型进行多步推理，提升空间上下文理解。


<details>
  <summary>Details</summary>
Motivation: 解决复杂查询中对其他物体空间参考的需求，提升室内环境的语义和几何准确性。

Method: 利用RGB-D帧序列构建层次场景图，结合开放词汇基础模型和大型语言模型进行多步推理。

Result: 在Habitat Matterport 3D语义多楼层场景中表现高效场景理解和鲁棒物体定位。

Conclusion: OVIGo-3DHSG在空间推理和室内环境理解应用中具有潜力。

Abstract: We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects
using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor
environment over a Hierarchical Scene Graph derived from sequences of RGB-D
frames utilizing a set of open-vocabulary foundation models and sensor data
processing. The hierarchical representation explicitly models spatial relations
across floors, rooms, locations, and objects. To effectively address complex
queries involving spatial reference to other objects, we integrate the
hierarchical scene graph with a Large Language Model for multistep reasoning.
This integration leverages inter-layer (e.g., room-to-object) and intra-layer
(e.g., object-to-object) connections, enhancing spatial contextual
understanding. We investigate the semantic and geometry accuracy of
hierarchical representation on Habitat Matterport 3D Semantic multi-floor
scenes. Our approach demonstrates efficient scene comprehension and robust
object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates
strong potential for applications requiring spatial reasoning and understanding
of indoor environments. Related materials can be found at
https://github.com/linukc/OVIGo-3DHSG.

</details>


### [54] [Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers](https://arxiv.org/abs/2507.12125)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: 提出了一种名为BSPF-ViT的新方法，通过联合修剪查询（Q）和键（K）令牌，并考虑令牌交互，显著降低了ViT的计算成本，同时提升了性能。


<details>
  <summary>Details</summary>
Motivation: ViT的高计算成本限制了其实际应用，现有方法在修剪令牌时独立处理Q/K令牌，导致性能下降。

Method: 采用基于块的对称修剪和融合（BSPF-ViT），联合优化Q/K令牌的修剪，并通过相似性融合压缩保留的令牌。

Result: 在ImageNet分类任务中，DeiT-T和DeiT-S的准确率分别提高了1.3%和2.0%，计算开销减少了50%，速度提升了40%。

Conclusion: BSPF-ViT通过考虑令牌交互和对称修剪，显著提升了ViT的效率和性能。

Abstract: Vision Transformer (ViT) has achieved impressive results across various
vision tasks, yet its high computational cost limits practical applications.
Recent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning
unimportant tokens. However, these techniques often sacrifice accuracy by
independently pruning query (Q) and key (K) tokens, leading to performance
degradation due to overlooked token interactions. To address this limitation,
we introduce a novel {\bf Block-based Symmetric Pruning and Fusion} for
efficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly.
Unlike previous methods that consider only a single direction, our approach
evaluates each token and its neighbors to decide which tokens to retain by
taking token interaction into account. The retained tokens are compressed
through a similarity fusion step, preserving key information while reducing
computational costs. The shared weights of Q/K tokens create a symmetric
attention matrix, allowing pruning only the upper triangular part for speed up.
BSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning
levels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0%
on DeiT-S, while reducing computational overhead by 50%. It achieves 40%
speedup with improved accuracy across various ViTs.

</details>


### [55] [Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement](https://arxiv.org/abs/2507.12135)
*Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种结合双边网格和MLP的BPAM框架，用于图像增强，解决了现有方法的线性和全局参数限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有双边网格方法仅支持线性变换，而传统MLP方法难以处理局部变化，BPAM旨在结合两者的优势。

Method: 通过双边网格动态生成像素级MLP参数，并采用网格分解策略和多通道引导图优化参数提取。

Result: 在公开数据集上表现优于现有方法，同时保持实时处理能力。

Conclusion: BPAM框架成功结合了双边网格的空间建模能力和MLP的非线性映射能力，提升了图像增强效果。

Abstract: Deep learning-based bilateral grid processing has emerged as a promising
solution for image enhancement, inherently encoding spatial and intensity
information while enabling efficient full-resolution processing through slicing
operations. However, existing approaches are limited to linear affine
transformations, hindering their ability to model complex color relationships.
Meanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings,
traditional MLP-based methods employ globally shared parameters, which is hard
to deal with localized variations. To overcome these dual challenges, we
propose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM)
framework. Our approach synergizes the spatial modeling of bilateral grids with
the non-linear capabilities of MLPs. Specifically, we generate bilateral grids
containing MLP parameters, where each pixel dynamically retrieves its unique
transformation parameters and obtain a distinct MLP for color mapping based on
spatial coordinates and intensity values. In addition, we propose a novel grid
decomposition strategy that categorizes MLP parameters into distinct types
stored in separate subgrids. Multi-channel guidance maps are used to extract
category-specific parameters from corresponding subgrids, ensuring effective
utilization of color information during slicing while guiding precise parameter
generation. Extensive experiments on public datasets demonstrate that our
method outperforms state-of-the-art methods in performance while maintaining
real-time processing capabilities.

</details>


### [56] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
*Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang*

Main category: cs.CV

TL;DR: AD-GS是一种自监督框架，用于从单一日志中高质量渲染驾驶场景的自由视角，无需手动标注。


<details>
  <summary>Details</summary>
Motivation: 当前高质量方法依赖昂贵的手动标注，而自监督方法无法准确捕捉动态对象运动或正确分解场景，导致渲染伪影。

Method: AD-GS结合局部感知B样条曲线和全局感知三角函数，通过动态高斯和双向时间可见性掩模自动分割场景。

Result: AD-GS在无标注方法中表现优异，甚至可与依赖标注的方法竞争。

Conclusion: AD-GS提供了一种高效、无需标注的动态场景建模和渲染解决方案。

Abstract: Modeling and rendering dynamic urban driving scenes is crucial for
self-driving simulation. Current high-quality methods typically rely on costly
manual object tracklet annotations, while self-supervised approaches fail to
capture dynamic object motions accurately and decompose scenes properly,
resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised
framework for high-quality free-viewpoint rendering of driving scenes from a
single log. At its core is a novel learnable motion model that integrates
locality-aware B-spline curves with global-aware trigonometric functions,
enabling flexible yet precise dynamic object modeling. Rather than requiring
comprehensive semantic labeling, AD-GS automatically segments scenes into
objects and background with the simplified pseudo 2D segmentation, representing
objects using dynamic Gaussians and bidirectional temporal visibility masks.
Further, our model incorporates visibility reasoning and physically rigid
regularization to enhance robustness. Extensive evaluations demonstrate that
our annotation-free model significantly outperforms current state-of-the-art
annotation-free methods and is competitive with annotation-dependent
approaches.

</details>


### [57] [Neural Human Pose Prior](https://arxiv.org/abs/2507.12138)
*Michal Heker,Sefy Kararlitsky,David Tolpin*

Main category: cs.CV

TL;DR: 提出了一种基于归一化流的神经先验方法，用于建模人体姿态分布，解决了6D旋转流形上的分布建模问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为启发式或表达能力有限，需要一种更灵活且稳定的方法来建模人体姿态的先验分布。

Method: 利用RealNVP学习6D旋转格式的姿态分布，通过反转Gram-Schmidt过程解决流形上的分布建模问题。

Result: 通过定性和定量评估验证了方法的有效性，并通过消融实验分析了其影响。

Conclusion: 为人体运动捕捉和重建提供了概率基础，具有框架无关性和易复现性。

Abstract: We introduce a principled, data-driven approach for modeling a neural prior
over human body poses using normalizing flows. Unlike heuristic or
low-expressivity alternatives, our method leverages RealNVP to learn a flexible
density over poses represented in the 6D rotation format. We address the
challenge of modeling distributions on the manifold of valid 6D rotations by
inverting the Gram-Schmidt process during training, enabling stable learning
while preserving downstream compatibility with rotation-based frameworks. Our
architecture and training pipeline are framework-agnostic and easily
reproducible. We demonstrate the effectiveness of the learned prior through
both qualitative and quantitative evaluations, and we analyze its impact via
ablation studies. This work provides a sound probabilistic foundation for
integrating pose priors into human motion capture and reconstruction pipelines.

</details>


### [58] [Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation](https://arxiv.org/abs/2507.12157)
*Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu*

Main category: cs.CV

TL;DR: 论文提出了一种无需预训练的高性能细粒度图像识别（FGIR）框架TGDA，通过数据增强和知识蒸馏实现，在低分辨率和高分辨率输入下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有FGIR方法依赖预训练模型，限制了在资源受限环境中的适应性和任务特定架构的开发。

Method: 引入TGDA框架，结合数据感知增强和细粒度感知教师模型的弱监督，通过知识蒸馏实现从零开始训练。

Result: 在多个FGIR基准测试中，TGDA框架性能优于或匹配现有预训练方法，尤其在低分辨率设置下提升显著。

Conclusion: TGDA为细粒度视觉系统提供了一种高效且适应性强的替代方案，减少了对预训练的依赖。

Abstract: Fine-grained image recognition (FGIR) aims to distinguish visually similar
sub-categories within a broader class, such as identifying bird species. While
most existing FGIR methods rely on backbones pretrained on large-scale datasets
like ImageNet, this dependence limits adaptability to resource-constrained
environments and hinders the development of task-specific architectures
tailored to the unique challenges of FGIR.
  In this work, we challenge the conventional reliance on pretrained models by
demonstrating that high-performance FGIR systems can be trained entirely from
scratch. We introduce a novel training framework, TGDA, that integrates
data-aware augmentation with weak supervision via a fine-grained-aware teacher
model, implemented through knowledge distillation. This framework unlocks the
design of task-specific and hardware-aware architectures, including LRNets for
low-resolution FGIR and ViTFS, a family of Vision Transformers optimized for
efficient inference.
  Extensive experiments across three FGIR benchmarks over diverse settings
involving low-resolution and high-resolution inputs show that our method
consistently matches or surpasses state-of-the-art pretrained counterparts. In
particular, in the low-resolution setting, LRNets trained with TGDA improve
accuracy by up to 23\% over prior methods while requiring up to 20.6x less
parameters, lower FLOPs, and significantly less training data. Similarly,
ViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k
while using 15.3x fewer trainable parameters and requiring orders of magnitudes
less data. These results highlight TGDA's potential as an adaptable alternative
to pretraining, paving the way for more efficient fine-grained vision systems.

</details>


### [59] [Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification](https://arxiv.org/abs/2507.12177)
*Zahid Ullah,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 提出了一种双集成框架，结合预训练深度学习模型和微调机器学习模型，以提高脑肿瘤MRI诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: MRI诊断中因人为因素（如疲劳、经验不足）可能导致误诊，需自动化方法提升精度。

Method: 采用预处理、数据增强、预训练深度学习模型提取特征，并微调机器学习分类器参数。

Result: 特征融合和分类器融合显著提升了分类性能，超参数微调进一步优化结果。

Conclusion: 双集成框架有效提高了脑肿瘤分类的准确性，各组件均对结果有贡献。

Abstract: Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable
tool for detecting tumors due to its capability to produce detailed images that
reveal their presence. However, the accuracy of diagnosis can be compromised
when human specialists evaluate these images. Factors such as fatigue, limited
expertise, and insufficient image detail can lead to errors. For example, small
tumors might go unnoticed, or overlap with healthy brain regions could result
in misidentification. To address these challenges and enhance diagnostic
precision, this study proposes a novel double ensembling framework, consisting
of ensembled pre-trained deep learning (DL) models for feature extraction and
ensembled fine-tuned hyperparameter machine learning (ML) models to efficiently
classify brain tumors. Specifically, our method includes extensive
preprocessing and augmentation, transfer learning concepts by utilizing various
pre-trained deep convolutional neural networks and vision transformer networks
to extract deep features from brain MRI, and fine-tune hyperparameters of ML
classifiers. Our experiments utilized three different publicly available Kaggle
MRI brain tumor datasets to evaluate the pre-trained DL feature extractor
models, ML classifiers, and the effectiveness of an ensemble of deep features
along with an ensemble of ML classifiers for brain tumor classification. Our
results indicate that the proposed feature fusion and classifier fusion improve
upon the state of the art, with hyperparameter fine-tuning providing a
significant enhancement over the ensemble method. Additionally, we present an
ablation study to illustrate how each component contributes to accurate brain
tumor classification.

</details>


### [60] [Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement](https://arxiv.org/abs/2507.12188)
*Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun*

Main category: cs.CV

TL;DR: 提出了一种基于小波变换的低光立体图像增强方法，通过特征空间解耦解决现有方法特征纠缠和黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法将所有退化因素编码在单一潜在空间中，导致特征高度纠缠和黑盒特性，易陷入捷径学习。

Method: 利用小波变换将特征空间分解为低频分支（用于光照调整）和高频分支（用于纹理增强），并提出高频引导的跨视图交互模块（HF-CIM）和基于交叉注意力的细节纹理增强模块（DTEM）。

Result: 在真实和合成图像上的实验表明，该方法在光照调整和高频信息恢复方面具有显著优势。

Conclusion: 该方法通过特征空间解耦和高频引导的跨视图交互，有效提升了低光立体图像的增强效果。

Abstract: Low-light images suffer from complex degradation, and existing enhancement
methods often encode all degradation factors within a single latent space. This
leads to highly entangled features and strong black-box characteristics, making
the model prone to shortcut learning. To mitigate the above issues, this paper
proposes a wavelet-based low-light stereo image enhancement method with feature
space decoupling. Our insight comes from the following findings: (1) Wavelet
transform enables the independent processing of low-frequency and
high-frequency information. (2) Illumination adjustment can be achieved by
adjusting the low-frequency component of a low-light image, extracted through
multi-level wavelet decomposition. Thus, by using wavelet transform the feature
space is decomposed into a low-frequency branch for illumination adjustment and
multiple high-frequency branches for texture enhancement. Additionally, stereo
low-light image enhancement can extract useful cues from another view to
improve enhancement. To this end, we propose a novel high-frequency guided
cross-view interaction module (HF-CIM) that operates within high-frequency
branches rather than across the entire feature space, effectively extracting
valuable image details from the other view. Furthermore, to enhance the
high-frequency information, a detail and texture enhancement module (DTEM) is
proposed based on cross-attention mechanism. The model is trained on a dataset
consisting of images with uniform illumination and images with non-uniform
illumination. Experimental results on both real and synthetic images indicate
that our algorithm offers significant advantages in light adjustment while
effectively recovering high-frequency information. The code and dataset are
publicly available at: https://github.com/Cherisherr/WDCI-Net.git.

</details>


### [61] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 论文提出了三种创新技术（Fractal Convolution、SSTF和Super Resolution）用于印度文化遗产的保护与修复，结合机器学习和计算机视觉，实现了高效且经济的自动化解决方案。


<details>
  <summary>Details</summary>
Motivation: 现代数字化方法为文化遗产保护带来了革命性变化，但印度古迹的特殊性需要针对性技术。本文旨在通过先进技术平衡传统与创新，提升保护效率与美学质量。

Method: 1. Fractal Convolution：基于图像处理的细分方法，揭示建筑细节。2. SSTF：专为Bankura陶庙设计的自敏感瓷砖填充方法，结合MosaicSlice数据增强。3. Super Resolution：图像超分辨率技术，提升画质。

Result: 方法实现了无缝区域填充和高细节瓷砖生成，成本可控且自动化，保持了文化遗产的真实性。

Conclusion: 研究通过创新技术推动了文化遗产保护领域的发展，实现了效率与美学质量的平衡。

Abstract: Modern digitised approaches have dramatically changed the preservation and
restoration of cultural treasures, integrating computer scientists into
multidisciplinary projects with ease. Machine learning, deep learning, and
computer vision techniques have revolutionised developing sectors like 3D
reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and
image processing with the integration of computer scientists into
multidisciplinary initiatives. We suggest three cutting-edge techniques in
recognition of the special qualities of Indian monuments, which are famous for
their architectural skill and aesthetic appeal. First is the Fractal
Convolution methodology, a segmentation method based on image processing that
successfully reveals subtle architectural patterns within these irreplaceable
cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling
(SSTF) method created especially for West Bengal's mesmerising Bankura
Terracotta Temples with a brand-new data augmentation method called MosaicSlice
on the third. Furthermore, we delve deeper into the Super Resolution strategy
to upscale the images without losing significant amount of quality. Our methods
allow for the development of seamless region-filling and highly detailed tiles
while maintaining authenticity using a novel data augmentation strategy within
affordable costs introducing automation. By providing effective solutions that
preserve the delicate balance between tradition and innovation, this study
improves the subject and eventually ensures unrivalled efficiency and aesthetic
excellence in cultural heritage protection. The suggested approaches advance
the field into an era of unmatched efficiency and aesthetic quality while
carefully upholding the delicate equilibrium between tradition and innovation.

</details>


### [62] [RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models](https://arxiv.org/abs/2507.12201)
*Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li*

Main category: cs.CV

TL;DR: RODS是一种基于优化的扩散采样方法，通过几何线索检测和纠正高风险采样步骤，提高生成模型的鲁棒性和保真度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的采样过程容易产生幻觉，主要源于分数近似的不准确性。

Method: 引入RODS方法，通过优化视角重新解释扩散采样，利用损失景观的几何线索检测和纠正高风险步骤。

Result: 在多个数据集上，RODS检测到70%以上的幻觉样本并纠正超过25%，同时避免引入新伪影。

Conclusion: RODS在不重新训练且额外推理成本最小的情况下，显著提升了扩散模型的采样质量。

Abstract: Diffusion models have achieved state-of-the-art performance in generative
modeling, yet their sampling procedures remain vulnerable to hallucinations,
often stemming from inaccuracies in score approximation. In this work, we
reinterpret diffusion sampling through the lens of optimization and introduce
RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that
detects and corrects high-risk sampling steps using geometric cues from the
loss landscape. RODS enforces smoother sampling trajectories and adaptively
adjusts perturbations, reducing hallucinations without retraining and at
minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands
demonstrate that RODS improves both sampling fidelity and robustness, detecting
over 70% of hallucinated samples and correcting more than 25%, all while
avoiding the introduction of new artifacts.

</details>


### [63] [MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM](https://arxiv.org/abs/2507.12232)
*Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng*

Main category: cs.CV

TL;DR: 论文提出了一种新的伪造检测框架MGFFD-VLM，通过扩展数据集DD-VQA+和改进训练策略，提升了视觉大语言模型在伪造检测中的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用面部质量相关属性和训练策略上存在不足，限制了伪造检测的性能和解释能力。

Method: 扩展了DD-VQA+数据集，引入Attribute-Driven Hybrid LoRA策略、多粒度提示学习和伪造感知训练策略，并结合辅助损失提升性能。

Result: 实验表明，该方法在文本伪造判断和分析上优于现有方法，准确性更高。

Conclusion: MGFFD-VLM框架显著提升了伪造检测的性能和可解释性，为未来研究提供了新方向。

Abstract: Recent studies have utilized visual large language models (VLMs) to answer
not only "Is this face a forgery?" but also "Why is the face a forgery?" These
studies introduced forgery-related attributes, such as forgery location and
type, to construct deepfake VQA datasets and train VLMs, achieving high
accuracy while providing human-understandable explanatory text descriptions.
However, these methods still have limitations. For example, they do not fully
leverage face quality-related attributes, which are often abnormal in forged
faces, and they lack effective training strategies for forgery-aware VLMs. In
this paper, we extend the VQA dataset to create DD-VQA+, which features a
richer set of attributes and a more diverse range of samples. Furthermore, we
introduce a novel forgery detection framework, MGFFD-VLM, which integrates an
Attribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual
Large Language Models (VLMs). Additionally, our framework incorporates
Multi-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By
transforming classification and forgery segmentation results into prompts, our
method not only improves forgery classification but also enhances
interpretability. To further boost detection performance, we design multiple
forgery-related auxiliary losses. Experimental results demonstrate that our
approach surpasses existing methods in both text-based forgery judgment and
analysis, achieving superior accuracy.

</details>


### [64] [Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models](https://arxiv.org/abs/2507.12236)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 生成式文本到图像扩散模型在医学影像中的短语定位任务中表现优于当前判别式方法，通过微调和Bimodal Bias Merging（BBM）技术进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索生成式模型在医学影像中短语定位任务的潜力，以提升疾病定位的准确性和可解释性。

Method: 使用生成式文本到图像扩散模型，结合跨注意力机制，并引入BBM技术优化定位结果。

Result: mIoU分数显著提升，是当前判别式方法的两倍。

Conclusion: 生成式模型在医学影像短语定位任务中更具优势，为临床应用提供了更稳健的解决方案。

Abstract: Phrase grounding, i.e., mapping natural language phrases to specific image
regions, holds significant potential for disease localization in medical
imaging through clinical reports. While current state-of-the-art methods rely
on discriminative, self-supervised contrastive models, we demonstrate that
generative text-to-image diffusion models, leveraging cross-attention maps, can
achieve superior zero-shot phrase grounding performance. Contrary to prior
assumptions, we show that fine-tuning diffusion models with a frozen,
domain-specific language model, such as CXR-BERT, substantially outperforms
domain-agnostic counterparts. This setup achieves remarkable improvements, with
mIoU scores doubling those of current discriminative methods. These findings
highlight the underexplored potential of generative models for phrase grounding
tasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM),
a novel post-processing technique that aligns text and image biases to identify
regions of high certainty. BBM refines cross-attention maps, achieving even
greater localization accuracy. Our results establish generative approaches as a
more effective paradigm for phrase grounding in the medical imaging domain,
paving the way for more robust and interpretable applications in clinical
practice. The source code and model weights are available at
https://github.com/Felix-012/generate_to_ground.

</details>


### [65] [Calisthenics Skills Temporal Video Segmentation](https://arxiv.org/abs/2507.12245)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 论文提出了一种自动识别和分割静态健身技能视频的方法，并建立了一个标注数据集，展示了基线方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 健身技能的视频自动识别和分割工具对运动员训练和比赛评分有帮助，但目前缺乏相关研究。

Method: 构建了一个标注静态健身技能视频的数据集，并提出了基线方法进行技能时间分割。

Result: 基线方法证明了问题的可行性，但仍有改进空间。

Conclusion: 研究为健身技能自动识别和分割提供了初步解决方案，未来可进一步优化。

Abstract: Calisthenics is a fast-growing bodyweight discipline that consists of
different categories, one of which is focused on skills. Skills in calisthenics
encompass both static and dynamic elements performed by athletes. The
evaluation of static skills is based on their difficulty level and the duration
of the hold. Automated tools able to recognize isometric skills from a video by
segmenting them to estimate their duration would be desirable to assist
athletes in their training and judges during competitions. Although the video
understanding literature on action recognition through body pose analysis is
rich, no previous work has specifically addressed the problem of calisthenics
skill temporal video segmentation. This study aims to provide an initial step
towards the implementation of automated tools within the field of Calisthenics.
To advance knowledge in this context, we propose a dataset of video footage of
static calisthenics skills performed by athletes. Each video is annotated with
a temporal segmentation which determines the extent of each skill. We hence
report the results of a baseline approach to address the problem of skill
temporal segmentation on the proposed dataset. The results highlight the
feasibility of the proposed problem, while there is still room for improvement.

</details>


### [66] [Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST](https://arxiv.org/abs/2507.12248)
*Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 比较Keras、PyTorch和JAX在医学图像分类任务中的性能，使用PathMNIST数据集评估训练效率、分类准确性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 探讨不同深度学习框架在医学图像分类中的表现，填补现有研究的空白。

Method: 使用PathMNIST数据集，对Keras、PyTorch和JAX实现的CNN进行训练效率、分类准确性和推理速度的全面分析。

Result: 揭示了计算速度和模型准确性之间的权衡。

Conclusion: 为医学图像分析的研究者和实践者提供了有价值的参考。

Abstract: Deep learning has significantly advanced the field of medical image
classification, particularly with the adoption of Convolutional Neural Networks
(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer
unique advantages in model development and deployment. However, their
comparative performance in medical imaging tasks remains underexplored. This
study presents a comprehensive analysis of CNN implementations across these
frameworks, using the PathMNIST dataset as a benchmark. We evaluate training
efficiency, classification accuracy and inference speed to assess their
suitability for real-world applications. Our findings highlight the trade-offs
between computational speed and model accuracy, offering valuable insights for
researchers and practitioners in medical image analysis.

</details>


### [67] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 该研究开发了一种基于深度学习的模型，利用出生24小时内的胸部X光片预测极低出生体重婴儿的中/重度支气管肺发育不良（BPD）结果。模型通过领域特定的预训练和优化技术，实现了较高的预测性能。


<details>
  <summary>Details</summary>
Motivation: BPD是一种常见的慢性肺病，预防措施可能带来严重风险。因此，早期预测BPD结果对避免不必要的治疗毒性至关重要。

Method: 研究使用163名极低出生体重婴儿的胸部X光片，通过微调ResNet-50模型（预训练于成人胸部X光片），结合渐进式层冻结、CutMix增强和线性探测技术。

Result: 最佳模型的AUROC为0.78，平衡准确率为0.69，F1分数为0.67，显著优于ImageNet初始化和传统IRDS分级。

Conclusion: 领域特定的预训练和优化技术能够从常规X光片中准确预测BPD结果，且方法计算可行，适合未来分布式学习部署。

Abstract: Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of
extremely low birth weight infants. Defined by oxygen dependence at 36 weeks
postmenstrual age, it causes lifelong respiratory complications. However,
preventive interventions carry severe risks, including neurodevelopmental
impairment, ventilator-induced lung injury, and systemic complications.
Therefore, early BPD prognosis and prediction of BPD outcome is crucial to
avoid unnecessary toxicity in low risk infants. Admission radiographs of
extremely preterm infants are routinely acquired within 24h of life and could
serve as a non-invasive prognostic tool. In this work, we developed and
investigated a deep learning approach using chest X-rays from 163 extremely
low-birth-weight infants ($\leq$32 weeks gestation, 401-999g) obtained within
24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult
chest radiographs, employing progressive layer freezing with discriminative
learning rates to prevent overfitting and evaluated a CutMix augmentation and
linear probing. For moderate/severe BPD outcome prediction, our best performing
model with progressive freezing, linear probing and CutMix achieved an AUROC of
0.78 $\pm$ 0.10, balanced accuracy of 0.69 $\pm$ 0.10, and an F1-score of 0.67
$\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet
initialization (p = 0.031) which confirms domain-specific pretraining to be
important for BPD outcome prediction. Routine IRDS grades showed limited
prognostic value (AUROC 0.57 $\pm$ 0.11), confirming the need of learned
markers. Our approach demonstrates that domain-specific pretraining enables
accurate BPD prediction from routine day-1 radiographs. Through progressive
freezing and linear probing, the method remains computationally feasible for
site-level implementation and future federated learning deployments.

</details>


### [68] [FADE: Adversarial Concept Erasure in Flow Models](https://arxiv.org/abs/2507.12283)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为FADE的新方法，用于从文本到图像扩散模型中删除指定概念，确保隐私和公平性，同时在性能和图像质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面表现出色，但也存在隐私泄露和偏见传播的风险，需要一种有效的方法删除敏感概念。

Method: FADE结合了轨迹感知微调策略和对抗性目标，确保概念被可靠删除的同时保持模型整体保真度。

Result: FADE在概念删除性能和图像质量上达到最先进水平，优于ESD、UCE、MACE和ANT等方法，性能提升5-10%。

Conclusion: FADE为安全和公平的生成建模设定了新标准，无需从头训练即可删除指定概念。

Abstract: Diffusion models have demonstrated remarkable image generation capabilities,
but also pose risks in privacy and fairness by memorizing sensitive concepts or
perpetuating biases. We propose a novel \textbf{concept erasure} method for
text-to-image diffusion models, designed to remove specified concepts (e.g., a
private individual or a harmful stereotype) from the model's generative
repertoire. Our method, termed \textbf{FADE} (Fair Adversarial Diffusion
Erasure), combines a trajectory-aware fine-tuning strategy with an adversarial
objective to ensure the concept is reliably removed while preserving overall
model fidelity. Theoretically, we prove a formal guarantee that our approach
minimizes the mutual information between the erased concept and the model's
outputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable
Diffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity,
explicit content, and style erasure tasks from MACE). FADE achieves
state-of-the-art concept removal performance, surpassing recent baselines like
ESD, UCE, MACE, and ANT in terms of removal efficacy and image quality.
Notably, FADE improves the harmonic mean of concept removal and fidelity by
5--10\% over the best prior method. We also conduct an ablation study to
validate each component of FADE, confirming that our adversarial and
trajectory-preserving objectives each contribute to its superior performance.
Our work sets a new standard for safe and fair generative modeling by
unlearning specified concepts without retraining from scratch.

</details>


### [69] [Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 提出了一种基于深度估计和运动员区域提取的直接方法，用于高效识别体操技能，避免了传统姿态估计的高计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于姿态估计的方法计算成本高、推理时间长，限制了实时应用和移动设备的适用性。

Method: 利用Depth Anything V2进行深度估计，YOLOv10定位运动员区域，直接分割主体而非依赖姿态估计。

Result: 方法显著优于基于骨架的方法，推理速度快38.3倍，分类准确率更高（0.837 vs. 0.815）。

Conclusion: 模块化设计提高了效率，支持未来灵活改进和实际应用。

Abstract: Calisthenics skill classification is the computer vision task of inferring
the skill performed by an athlete from images, enabling automatic performance
assessment and personalized analytics. Traditional methods for calisthenics
skill recognition are based on pose estimation methods to determine the
position of skeletal data from images, which is later fed to a classification
algorithm to infer the performed skill. Despite the progress in human pose
estimation algorithms, they still involve high computational costs, long
inference times, and complex setups, which limit the applicability of such
approaches in real-time applications or mobile devices. This work proposes a
direct approach to calisthenics skill recognition, which leverages depth
estimation and athlete patch retrieval to avoid the computationally expensive
human pose estimation module. Using Depth Anything V2 for depth estimation and
YOLOv10 for athlete localization, we segment the subject from the background
rather than relying on traditional pose estimation techniques. This strategy
increases efficiency, reduces inference time, and improves classification
accuracy. Our approach significantly outperforms skeleton-based methods,
achieving 38.3x faster inference with RGB image patches and improved
classification accuracy with depth patches (0.837 vs. 0.815). Beyond these
performance gains, the modular design of our pipeline allows for flexible
replacement of components, enabling future enhancements and adaptation to
real-world applications.

</details>


### [70] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
*Samuel Lavoie,Michael Noukhovitch,Aaron Courville*

Main category: cs.CV

TL;DR: 论文提出离散潜在码（DLC）作为扩散模型的输入条件表示，提升生成质量、易生成性和组合性，实现超出训练分布的样本生成。


<details>
  <summary>Details</summary>
Motivation: 研究扩散模型成功的关键在于输入条件表示，理想表示应提升样本保真度、易生成且具有组合性。

Method: 引入基于自监督学习的离散潜在码（DLC），作为离散标记序列替代连续嵌入，用于扩散模型训练。

Result: DLC显著提升无条件图像生成质量，在ImageNet上达到新SOTA，并能生成超出训练分布的样本。

Conclusion: DLC为扩散模型提供高效、组合性强的条件表示，支持文本到图像生成等扩展应用。

Abstract: We argue that diffusion models' success in modeling complex distributions is,
for the most part, coming from their input conditioning. This paper
investigates the representation used to condition diffusion models from the
perspective that ideal representations should improve sample fidelity, be easy
to generate, and be compositional to allow out-of-training samples generation.
We introduce Discrete Latent Code (DLC), an image representation derived from
Simplicial Embeddings trained with a self-supervised learning objective. DLCs
are sequences of discrete tokens, as opposed to the standard continuous image
embeddings. They are easy to generate and their compositionality enables
sampling of novel images beyond the training distribution. Diffusion models
trained with DLCs have improved generation fidelity, establishing a new
state-of-the-art for unconditional image generation on ImageNet. Additionally,
we show that composing DLCs allows the image generator to produce
out-of-distribution samples that coherently combine the semantics of images in
diverse ways. Finally, we showcase how DLCs can enable text-to-image generation
by leveraging large-scale pretrained language models. We efficiently finetune a
text diffusion language model to generate DLCs that produce novel samples
outside of the image generator training distribution.

</details>


### [71] [Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors](https://arxiv.org/abs/2507.12336)
*Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim*

Main category: cs.CV

TL;DR: KeyDiff3D是一个无监督的单目3D关键点估计框架，利用预训练的多视角扩散模型生成几何先验，仅需单视角图像即可准确预测3D关键点。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的手动标注或多视角图像，KeyDiff3D旨在通过单视角图像实现高效且准确的3D关键点估计。

Method: 利用预训练的多视角扩散模型生成多视角图像作为监督信号，并从中提取3D特征，将隐式3D先验转化为显式3D特征。

Result: 在Human3.6M、Stanford Dogs等数据集上表现出高准确性和泛化能力，并能实现单图像生成的3D物体操控。

Conclusion: KeyDiff3D提供了一种高效且无需标注的单目3D关键点估计方法，并扩展了3D物体操控的可能性。

Abstract: This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D
keypoints estimation that accurately predicts 3D keypoints from a single image.
While previous methods rely on manual annotations or calibrated multi-view
images, both of which are expensive to collect, our method enables monocular 3D
keypoints estimation using only a collection of single-view images. To achieve
this, we leverage powerful geometric priors embedded in a pretrained multi-view
diffusion model. In our framework, this model generates multi-view images from
a single image, serving as a supervision signal to provide 3D geometric cues to
our model. We also use the diffusion model as a powerful 2D multi-view feature
extractor and construct 3D feature volumes from its intermediate
representations. This transforms implicit 3D priors learned by the diffusion
model into explicit 3D features. Beyond accurate keypoints estimation, we
further introduce a pipeline that enables manipulation of 3D objects generated
by the diffusion model. Experimental results on diverse aspects and datasets,
including Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain
datasets, highlight the effectiveness of our method in terms of accuracy,
generalization, and its ability to enable manipulation of 3D objects generated
by the diffusion model from a single image.

</details>


### [72] [Improving Lightweight Weed Detection via Knowledge Distillation](https://arxiv.org/abs/2507.12344)
*Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein*

Main category: cs.CV

TL;DR: 论文研究了通道知识蒸馏（CWD）和掩码生成蒸馏（MGD）在轻量级模型中的应用，以提高实时智能喷洒系统中的杂草检测性能。实验表明，CWD和MGD显著提升了模型精度，且不影响模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的平台上部署高精度杂草检测模型具有挑战性，尤其是在区分视觉相似的杂草种类时。

Method: 使用YOLO11x作为教师模型，YOLO11n作为学生模型，应用CWD和MGD进行知识蒸馏。

Result: CWD和MGD分别提升了2.5%和1.9%的mAP50，并在嵌入式设备上验证了实时部署的可行性。

Conclusion: CWD和MGD是提高深度学习杂草检测精度的有效、高效且实用的方法。

Abstract: Weed detection is a critical component of precision agriculture, facilitating
targeted herbicide application and reducing environmental impact. However,
deploying accurate object detection models on resource-limited platforms
remains challenging, particularly when differentiating visually similar weed
species commonly encountered in plant phenotyping applications. In this work,
we investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative
Distillation (MGD) to enhance the performance of lightweight models for
real-time smart spraying systems. Utilizing YOLO11x as the teacher model and
YOLO11n as both reference and student, both CWD and MGD effectively transfer
knowledge from the teacher to the student model. Our experiments, conducted on
a real-world dataset comprising sugar beet crops and four weed types (Cirsium,
Convolvulus, Fallopia, and Echinochloa), consistently show increased AP50
across all classes. The distilled CWD student model achieves a notable
improvement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without
increasing model complexity. Additionally, we validate real-time deployment
feasibility by evaluating the student YOLO11n model on Jetson Orin Nano and
Raspberry Pi 5 embedded devices, performing five independent runs to evaluate
performance stability across random seeds. These findings confirm CWD and MGD
as an effective, efficient, and practical approach for improving deep
learning-based weed detection accuracy in precision agriculture and plant
phenotyping scenarios.

</details>


### [73] [Cluster Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2507.12359)
*Nikolaos Giakoumoglou,Tania Stathaki*

Main category: cs.CV

TL;DR: CueCo结合对比学习和聚类方法，通过分散和对齐特征表示提升无监督视觉表示学习效果。


<details>
  <summary>Details</summary>
Motivation: 结合对比学习和聚类的优势，提升无监督视觉表示学习的性能。

Method: 使用查询和关键两个神经网络，关键网络通过查询输出的慢速平均更新，结合对比损失和聚类目标优化特征表示。

Result: 在CIFAR-10、CIFAR-100和ImageNet-100上分别达到91.40%、68.56%和78.65%的top-1分类准确率。

Conclusion: CueCo通过整合对比学习和聚类，为无监督视觉表示学习开辟了新方向。

Abstract: We introduce Cluster Contrast (CueCo), a novel approach to unsupervised
visual representation learning that effectively combines the strengths of
contrastive learning and clustering methods. Inspired by recent advancements,
CueCo is designed to simultaneously scatter and align feature representations
within the feature space. This method utilizes two neural networks, a query and
a key, where the key network is updated through a slow-moving average of the
query outputs. CueCo employs a contrastive loss to push dissimilar features
apart, enhancing inter-class separation, and a clustering objective to pull
together features of the same cluster, promoting intra-class compactness. Our
method achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on
CIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18
backbone. By integrating contrastive learning with clustering, CueCo sets a new
direction for advancing unsupervised visual representation learning.

</details>


### [74] [Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.12382)
*Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于文本驱动的半监督医学图像分割框架Text-SemiSeg，通过文本增强视觉语义嵌入，提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像标注成本高的问题，利用文本信息增强视觉语义理解。

Method: 包含三个模块：文本增强多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA）。

Result: 在三个公开数据集上表现优于其他方法。

Conclusion: Text-SemiSeg通过文本与视觉交互有效提升了半监督医学图像分割性能。

Abstract: Semi-supervised medical image segmentation is a crucial technique for
alleviating the high cost of data annotation. When labeled data is limited,
textual information can provide additional context to enhance visual semantic
understanding. However, research exploring the use of textual data to enhance
visual semantic embeddings in 3D medical imaging tasks remains scarce. In this
paper, we propose a novel text-driven multiplanar visual interaction framework
for semi-supervised medical image segmentation (termed Text-SemiSeg), which
consists of three main modules: Text-enhanced Multiplanar Representation (TMR),
Category-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation
(DCA). Specifically, TMR facilitates text-visual interaction through planar
mapping, thereby enhancing the category awareness of visual features. CSA
performs cross-modal semantic alignment between the text features with
introduced learnable variables and the intermediate layer of visual features.
DCA reduces the distribution discrepancy between labeled and unlabeled data
through their interaction, thus improving the model's robustness. Finally,
experiments on three public datasets demonstrate that our model effectively
enhances visual features with textual information and outperforms other
methods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.

</details>


### [75] [OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments](https://arxiv.org/abs/2507.12396)
*Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva*

Main category: cs.CV

TL;DR: 提出了两个视觉目标检测基准OD-VIRAT Large和OD-VIRAT Tiny，用于评估复杂环境下的人体监控模型性能，并测试了多种先进目标检测架构。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的监控系统需要多样化和具有挑战性的数据集，以全面评估模型性能。

Method: 创建了两个包含丰富标注的监控数据集，并测试了RETMDET、YOLOX等先进目标检测架构。

Result: OD-VIRAT Large包含8.7百万标注实例，OD-VIRAT Tiny包含288,901标注实例，测试了多种模型在复杂条件下的表现。

Conclusion: 该工作为开发更高效和鲁棒的目标检测架构提供了基准和实验设置。

Abstract: Realistic human surveillance datasets are crucial for training and evaluating
computer vision models under real-world conditions, facilitating the
development of robust algorithms for human and human-interacting object
detection in complex environments. These datasets need to offer diverse and
challenging data to enable a comprehensive assessment of model performance and
the creation of more reliable surveillance systems for public safety. To this
end, we present two visual object detection benchmarks named OD-VIRAT Large and
OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance
imagery. The video sequences in both benchmarks cover 10 different scenes of
human surveillance recorded from significant height and distance. The proposed
benchmarks offer rich annotations of bounding boxes and categories, where
OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and
OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also
focuses on benchmarking state-of-the-art object detection architectures,
including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object
detection-specific variant of VIRAT dataset. To the best of our knowledge, it
is the first work to examine the performance of these recently published
state-of-the-art object detection architectures on realistic surveillance
imagery under challenging conditions such as complex backgrounds, occluded
objects, and small-scale objects. The proposed benchmarking and experimental
settings will help in providing insights concerning the performance of selected
object detection models and set the base for developing more efficient and
robust object detection architectures.

</details>


### [76] [QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval](https://arxiv.org/abs/2507.12416)
*Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee*

Main category: cs.CV

TL;DR: 论文提出了一种名为QuRe的方法，通过硬负采样减少假阴性，提升组合图像检索的准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有组合图像检索方法仅关注目标图像，忽略其他图像的相关性，导致假阴性问题，影响用户满意度。

Method: 提出Query-Relevant Retrieval（QuRe），结合奖励模型目标和硬负采样策略，减少假阴性。

Result: 在FashionIQ和CIRR数据集上达到最优性能，并在新数据集HP-FashionIQ上表现出与人类偏好最强的对齐。

Conclusion: QuRe通过优化假阴性问题，显著提升了组合图像检索的性能和用户满意度。

Abstract: Composed Image Retrieval (CIR) retrieves relevant images based on a reference
image and accompanying text describing desired modifications. However, existing
CIR methods only focus on retrieving the target image and disregard the
relevance of other images. This limitation arises because most methods
employing contrastive learning-which treats the target image as positive and
all other images in the batch as negatives-can inadvertently include false
negatives. This may result in retrieving irrelevant images, reducing user
satisfaction even when the target image is retrieved. To address this issue, we
propose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which
optimizes a reward model objective to reduce false negatives. Additionally, we
introduce a hard negative sampling strategy that selects images positioned
between two steep drops in relevance scores following the target image, to
effectively filter false negatives. In order to evaluate CIR models on their
alignment with human satisfaction, we create Human-Preference FashionIQ
(HP-FashionIQ), a new dataset that explicitly captures user preferences beyond
target retrieval. Extensive experiments demonstrate that QuRe achieves
state-of-the-art performance on FashionIQ and CIRR datasets while exhibiting
the strongest alignment with human preferences on the HP-FashionIQ dataset. The
source code is available at https://github.com/jackwaky/QuRe.

</details>


### [77] [InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization](https://arxiv.org/abs/2507.12420)
*Haoyuan Liu,Hiroshi Watanabe*

Main category: cs.CV

TL;DR: 提出了一种新的损失函数InterpIoU，通过插值框解决IoU在非重叠情况下的不可微问题，并避免传统几何惩罚的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于IoU的损失函数在非重叠情况下表现不佳，且对框的形状、大小和分布敏感，导致小物体检测效果差和框扩大的问题。

Method: 提出InterpIoU，利用插值框与目标的IoU替代手工几何惩罚，并进一步提出动态调整插值系数的Dynamic InterpIoU。

Result: 在COCO、VisDrone和PASCAL VOC数据集上，新方法优于现有IoU损失，尤其在小物体检测中表现突出。

Conclusion: InterpIoU和Dynamic InterpIoU有效解决了传统IoU损失的问题，提升了物体检测的准确性。

Abstract: Bounding box regression (BBR) is fundamental to object detection, where the
regression loss is crucial for accurate localization. Existing IoU-based losses
often incorporate handcrafted geometric penalties to address IoU's
non-differentiability in non-overlapping cases and enhance BBR performance.
However, these penalties are sensitive to box shape, size, and distribution,
often leading to suboptimal optimization for small objects and undesired
behaviors such as bounding box enlargement due to misalignment with the IoU
objective. To address these limitations, we propose InterpIoU, a novel loss
function that replaces handcrafted geometric penalties with a term based on the
IoU between interpolated boxes and the target. By using interpolated boxes to
bridge the gap between predictions and ground truth, InterpIoU provides
meaningful gradients in non-overlapping cases and inherently avoids the box
enlargement issue caused by misaligned penalties. Simulation results further
show that IoU itself serves as an ideal regression target, while existing
geometric penalties are both unnecessary and suboptimal. Building on InterpIoU,
we introduce Dynamic InterpIoU, which dynamically adjusts interpolation
coefficients based on IoU values, enhancing adaptability to scenarios with
diverse object distributions. Experiments on COCO, VisDrone, and PASCAL VOC
show that our methods consistently outperform state-of-the-art IoU-based losses
across various detection frameworks, with particularly notable improvements in
small object detection, confirming their effectiveness.

</details>


### [78] [DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition](https://arxiv.org/abs/2507.12426)
*Hayat Ullah,Muhammad Ali Shafique,Abbas Khan,Arslan Munir*

Main category: cs.CV

TL;DR: 提出了一种轻量级视频识别网络DVFL-Net，通过知识蒸馏和时空特征调制，在保持高性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在视频识别中性能优越但计算成本高，需要一种更高效的解决方案。

Method: 采用知识蒸馏和时空焦点调制技术，将预训练大模型的知识迁移到轻量级学生模型中。

Result: DVFL-Net在多个数据集上表现优异，平衡了性能和效率，适合实时应用。

Conclusion: DVFL-Net为实时视频识别提供了一种高效且高性能的解决方案。

Abstract: The landscape of video recognition has evolved significantly, shifting from
traditional Convolutional Neural Networks (CNNs) to Transformer-based
architectures for improved accuracy. While 3D CNNs have been effective at
capturing spatiotemporal dynamics, recent Transformer models leverage
self-attention to model long-range spatial and temporal dependencies. Despite
achieving state-of-the-art performance on major benchmarks, Transformers remain
computationally expensive, particularly with dense video data. To address this,
we propose a lightweight Video Focal Modulation Network, DVFL-Net, which
distills spatiotemporal knowledge from a large pre-trained teacher into a
compact nano student model, enabling efficient on-device deployment. DVFL-Net
utilizes knowledge distillation and spatial-temporal feature modulation to
significantly reduce computation while preserving high recognition performance.
We employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal
focal modulation to effectively transfer both local and global context from the
Video-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate
DVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it
against recent state-of-the-art methods in Human Action Recognition (HAR).
Additionally, we conduct a detailed ablation study analyzing the impact of
forward KL divergence. The results confirm the superiority of DVFL-Net in
achieving an optimal balance between performance and efficiency, demonstrating
lower memory usage, reduced GFLOPs, and strong accuracy, making it a practical
solution for real-time HAR applications.

</details>


### [79] [Describe Anything Model for Visual Question Answering on Text-rich Images](https://arxiv.org/abs/2507.12441)
*Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DAM-QA利用DAM的区域感知能力改进文本密集型VQA任务，通过多区域视图聚合答案，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 针对文本密集型VQA任务中细粒度文本信息提取的需求，利用DAM的区域描述能力提升答案准确性。

Method: 提出DAM-QA框架，结合多区域视图聚合机制，优化文本相关证据的识别。

Result: 在六个VQA基准测试中表现优于基线DAM，DocVQA提升7分以上，参数更少且性能接近通用VLMs。

Conclusion: DAM类模型在高效使用和集成策略下，对文本密集型及更广泛的VQA任务具有潜力。

Abstract: Recent progress has been made in region-aware vision-language modeling,
particularly with the emergence of the Describe Anything Model (DAM). DAM is
capable of generating detailed descriptions of any specific image areas or
objects without the need for additional localized image-text alignment
supervision. We hypothesize that such region-level descriptive capability is
beneficial for the task of Visual Question Answering (VQA), especially in
challenging scenarios involving images with dense text. In such settings, the
fine-grained extraction of textual information is crucial to producing correct
answers. Motivated by this, we introduce DAM-QA, a framework with a tailored
evaluation protocol, developed to investigate and harness the region-aware
capabilities from DAM for the text-rich VQA problem that requires reasoning
over text-based information within images. DAM-QA incorporates a mechanism that
aggregates answers from multiple regional views of image content, enabling more
effective identification of evidence that may be tied to text-related elements.
Experiments on six VQA benchmarks show that our approach consistently
outperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA
also achieves the best overall performance among region-aware models with fewer
parameters, significantly narrowing the gap with strong generalist VLMs. These
results highlight the potential of DAM-like models for text-rich and broader
VQA tasks when paired with efficient usage and integration strategies. Our code
is publicly available at https://github.com/Linvyl/DAM-QA.git.

</details>


### [80] [Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios](https://arxiv.org/abs/2507.12449)
*Van-Hoang-Anh Phan,Chi-Tam Nguyen,Doan-Trung Au,Thanh-Danh Phan,Minh-Thien Duong,My-Ha Le*

Main category: cs.CV

TL;DR: 提出了一种基于摄像头感知和Frenet-Pure Pursuit规划的障碍物避障系统，结合YOLOv11和目标深度估计模型，在校园环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶车辆的安全性需要高效的障碍物避障能力，尤其是在复杂环境中。

Method: 使用摄像头感知模块（YOLOv11和目标深度估计模型）和Frenet-Pure Pursuit规划策略。

Result: 系统在多样化的校园场景中表现良好，能有效处理各种障碍物。

Conclusion: 提出的方法在自动驾驶障碍物避障中具有实际应用潜力。

Abstract: Obstacle avoidance is essential for ensuring the safety of autonomous
vehicles. Accurate perception and motion planning are crucial to enabling
vehicles to navigate complex environments while avoiding collisions. In this
paper, we propose an efficient obstacle avoidance pipeline that leverages a
camera-only perception module and a Frenet-Pure Pursuit-based planning
strategy. By integrating advancements in computer vision, the system utilizes
YOLOv11 for object detection and state-of-the-art monocular depth estimation
models, such as Depth Anything V2, to estimate object distances. A comparative
analysis of these models provides valuable insights into their accuracy,
efficiency, and robustness in real-world conditions. The system is evaluated in
diverse scenarios on a university campus, demonstrating its effectiveness in
handling various obstacles and enhancing autonomous navigation. The video
presenting the results of the obstacle avoidance experiments is available at:
https://www.youtube.com/watch?v=FoXiO5S_tA8

</details>


### [81] [Mitigating Object Hallucinations via Sentence-Level Early Intervention](https://arxiv.org/abs/2507.12455)
*Shangpin Peng,Senqiao Yang,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: SENTINEL框架通过句子级早期干预和领域内偏好学习，显著减少多模态大语言模型中的幻觉问题，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在跨模态理解中存在幻觉问题，现有方法计算成本高或引入数据分布不匹配。

Method: 通过迭代采样模型输出、验证对象存在性并分类句子，构建上下文感知偏好数据，使用C-DPO损失训练模型。

Result: SENTINEL减少幻觉超过90%，在幻觉和通用能力基准测试中优于现有方法。

Conclusion: SENTINEL在减少幻觉和保持模型性能方面表现出色，具有推广潜力。

Abstract: Multimodal large language models (MLLMs) have revolutionized cross-modal
understanding but continue to struggle with hallucinations - fabricated content
contradicting visual inputs. Existing hallucination mitigation methods either
incur prohibitive computational costs or introduce distribution mismatches
between training data and model outputs. We identify a critical insight:
hallucinations predominantly emerge at the early stages of text generation and
propagate through subsequent outputs. To address this, we propose **SENTINEL**
(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain
pr**E**ference **L**earning), a framework that eliminates dependency on human
annotations. Specifically, we first bootstrap high-quality in-domain preference
pairs by iteratively sampling model outputs, validating object existence
through cross-checking with two open-vocabulary detectors, and classifying
sentences into hallucinated/non-hallucinated categories. Subsequently, we use
context-coherent positive samples and hallucinated negative samples to build
context-aware preference data iteratively. Finally, we train models using a
context-aware preference loss (C-DPO) that emphasizes discriminative learning
at the sentence level where hallucinations initially manifest. Experimental
results show that SENTINEL can reduce hallucinations by over 90\% compared to
the original model and outperforms the previous state-of-the-art method on both
hallucination benchmarks and general capabilities benchmarks, demonstrating its
superiority and generalization ability. The models, datasets, and code are
available at https://github.com/pspdada/SENTINEL.

</details>


### [82] [Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis](https://arxiv.org/abs/2507.12461)
*Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: 本文提出了一种名为RadGazeIntent的深度学习方法，用于建模放射科医生在解读医学图像时的意图驱动行为，通过处理眼动数据预测其诊断意图。


<details>
  <summary>Details</summary>
Motivation: 现有模型未能捕捉放射科医生在图像解读中每个注视点背后的意图，而理解这种意图驱动行为对提升医学图像分析至关重要。

Method: 采用基于Transformer的架构，处理眼动数据的时空维度，将细粒度注视特征转化为粗粒度的诊断意图表示，并利用三个意图标记数据集（RadSeq、RadExplore、RadHybrid）进行训练。

Result: RadGazeIntent在所有意图标记数据集上均优于基线方法，能够准确预测放射科医生在特定时刻关注的发现。

Conclusion: RadGazeIntent成功建模了放射科医生的意图驱动行为，为医学图像分析提供了新的视角。

Abstract: Radiologists rely on eye movements to navigate and interpret medical images.
A trained radiologist possesses knowledge about the potential diseases that may
be present in the images and, when searching, follows a mental checklist to
locate them using their gaze. This is a key observation, yet existing models
fail to capture the underlying intent behind each fixation. In this paper, we
introduce a deep learning-based approach, RadGazeIntent, designed to model this
behavior: having an intention to find something and actively searching for it.
Our transformer-based architecture processes both the temporal and spatial
dimensions of gaze data, transforming fine-grained fixation features into
coarse, meaningful representations of diagnostic intent to interpret
radiologists' goals. To capture the nuances of radiologists' varied
intention-driven behaviors, we process existing medical eye-tracking datasets
to create three intention-labeled subsets: RadSeq (Systematic Sequential
Search), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid
Pattern). Experimental results demonstrate RadGazeIntent's ability to predict
which findings radiologists are examining at specific moments, outperforming
baseline methods across all intention-labeled datasets.

</details>


### [83] [SpatialTrackerV2: 3D Point Tracking Made Easy](https://arxiv.org/abs/2507.12462)
*Yuxi Xiao,Jianyuan Wang,Nan Xue,Nikita Karaev,Yuri Makarov,Bingyi Kang,Xing Zhu,Hujun Bao,Yujun Shen,Xiaowei Zhou*

Main category: cs.CV

TL;DR: SpatialTrackerV2是一种基于前馈的3D点跟踪方法，通过统一几何、相机运动和物体运动，显著提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D跟踪方法依赖模块化流程，性能有限。SpatialTrackerV2旨在通过统一几何、相机运动和物体运动，提升跟踪效率和准确性。

Method: 将3D运动分解为场景几何、相机运动和物体运动，采用端到端可微分架构，支持多数据集训练。

Result: 性能超越现有方法30%，与领先的动态3D重建方法精度相当，但速度快50倍。

Conclusion: SpatialTrackerV2通过统一学习和端到端设计，显著提升了3D点跟踪的性能和效率。

Abstract: We present SpatialTrackerV2, a feed-forward 3D point tracking method for
monocular videos. Going beyond modular pipelines built on off-the-shelf
components for 3D tracking, our approach unifies the intrinsic connections
between point tracking, monocular depth, and camera pose estimation into a
high-performing and feedforward 3D point tracker. It decomposes world-space 3D
motion into scene geometry, camera ego-motion, and pixel-wise object motion,
with a fully differentiable and end-to-end architecture, allowing scalable
training across a wide range of datasets, including synthetic sequences, posed
RGB-D videos, and unlabeled in-the-wild footage. By learning geometry and
motion jointly from such heterogeneous data, SpatialTrackerV2 outperforms
existing 3D tracking methods by 30%, and matches the accuracy of leading
dynamic 3D reconstruction approaches while running 50$\times$ faster.

</details>


### [84] [MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding](https://arxiv.org/abs/2507.12463)
*Renjie Li,Ruijie Ye,Mingyang Wu,Hao Frank Yang,Zhiwen Fan,Hezhen Hu,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 提出了一个名为MMHU的大规模人类行为分析基准，包含丰富的注释和多任务评估。


<details>
  <summary>Details</summary>
Motivation: 理解人类行为对开发安全的驾驶系统至关重要，但目前缺乏全面的评估基准。

Method: 开发了一个包含57k人类运动片段和1.73M帧的数据集，采用人机协作标注流程生成行为描述。

Result: 提供了多任务基准，包括运动预测、运动生成和行为问答。

Conclusion: MMHU为自动驾驶中的人类行为理解提供了全面的评估工具。

Abstract: Humans are integral components of the transportation ecosystem, and
understanding their behaviors is crucial to facilitating the development of
safe driving systems. Although recent progress has explored various aspects of
human behavior$\unicode{x2014}$such as motion, trajectories, and
intention$\unicode{x2014}$a comprehensive benchmark for evaluating human
behavior understanding in autonomous driving remains unavailable. In this work,
we propose $\textbf{MMHU}$, a large-scale benchmark for human behavior analysis
featuring rich annotations, such as human motion and trajectories, text
description for human motions, human intention, and critical behavior labels
relevant to driving safety. Our dataset encompasses 57k human motion clips and
1.73M frames gathered from diverse sources, including established driving
datasets such as Waymo, in-the-wild videos from YouTube, and self-collected
data. A human-in-the-loop annotation pipeline is developed to generate rich
behavior captions. We provide a thorough dataset analysis and benchmark
multiple tasks$\unicode{x2014}$ranging from motion prediction to motion
generation and human behavior question answering$\unicode{x2014}$thereby
offering a broad evaluation suite. Project page :
https://MMHU-Benchmark.github.io.

</details>


### [85] [CytoSAE: Interpretable Cell Embeddings for Hematology](https://arxiv.org/abs/2507.12464)
*Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider*

Main category: cs.CV

TL;DR: 稀疏自编码器（SAEs）被用于医学影像领域，提出CytoSAE模型，可识别形态学相关概念并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 医学影像领域缺乏解释基础模型推理的工具，SAEs在视觉领域的成功应用启发了其在医学影像中的尝试。

Method: 提出CytoSAE模型，基于40,000多张外周血单细胞图像训练，适用于多样化和域外数据集。

Result: CytoSAE能识别形态学相关概念，生成患者和疾病特异性概念，并在AML亚型分类任务中表现优异。

Conclusion: CytoSAE在保持高性能的同时提供亚细胞级别的可解释性，为医学影像分析提供了新工具。

Abstract: Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic
interpretability of transformer-based foundation models. Very recently, SAEs
were also adopted for the visual domain, enabling the discovery of visual
concepts and their patch-wise attribution to tokens in the transformer model.
While a growing number of foundation models emerged for medical imaging, tools
for explaining their inferences are still lacking. In this work, we show the
applicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder
which is trained on over 40,000 peripheral blood single-cell images. CytoSAE
generalizes to diverse and out-of-domain datasets, including bone marrow
cytology, where it identifies morphologically relevant concepts which we
validated with medical experts. Furthermore, we demonstrate scenarios in which
CytoSAE can generate patient-specific and disease-specific concepts, enabling
the detection of pathognomonic cells and localized cellular abnormalities at
the patch level. We quantified the effect of concepts on a patient-level AML
subtype classification task and show that CytoSAE concepts reach performance
comparable to the state-of-the-art, while offering explainability on the
sub-cellular level. Source code and model weights are available at
https://github.com/dynamical-inference/cytosae.

</details>


### [86] [PhysX: Physical-Grounded 3D Asset Generation](https://arxiv.org/abs/2507.12465)
*Ziang Cao,Zhaoxi Chen,Linag Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出PhysX，一种物理基础的3D资产生成方法，包括数据集PhysXNet和生成框架PhysXGen，填补了物理属性标注的空白。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型忽视物理属性，限制了在仿真和具身AI等领域的应用。

Method: 1) 构建物理标注数据集PhysXNet；2) 提出双分支框架PhysXGen，结合3D结构与物理知识。

Result: 实验验证了PhysXGen的优越性能和泛化能力。

Conclusion: PhysX为生成物理AI提供了新范式，代码和数据将开源。

Abstract: 3D modeling is moving from virtual to physical. Existing 3D generation
primarily emphasizes geometries and textures while neglecting physical-grounded
modeling. Consequently, despite the rapid development of 3D generative models,
the synthesized 3D assets often overlook rich and important physical
properties, hampering their real-world application in physical domains like
simulation and embodied AI. As an initial attempt to address this challenge, we
propose \textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset
generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we
present PhysXNet - the first physics-grounded 3D dataset systematically
annotated across five foundational dimensions: absolute scale, material,
affordance, kinematics, and function description. In particular, we devise a
scalable human-in-the-loop annotation pipeline based on vision-language models,
which enables efficient creation of physics-first assets from raw 3D assets.2)
Furthermore, we propose \textbf{PhysXGen}, a feed-forward framework for
physics-grounded image-to-3D asset generation, injecting physical knowledge
into the pre-trained 3D structural space. Specifically, PhysXGen employs a
dual-branch architecture to explicitly model the latent correlations between 3D
structures and physical properties, thereby producing 3D assets with plausible
physical predictions while preserving the native geometry quality. Extensive
experiments validate the superior performance and promising generalization
capability of our framework. All the code, data, and models will be released to
facilitate future research in generative physical AI.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [87] [A Deep Reinforcement Learning Method for Multi-objective Transmission Switching](https://arxiv.org/abs/2507.11726)
*Ding Lin,Jianhui Wang,Tianqiao Zhao,Meng Yue*

Main category: eess.SY

TL;DR: 本文提出了一种基于深度强化学习（DRL）的多目标输电切换方法，通过双演员-评论家框架优化决策，提升系统可靠性和成本效率。


<details>
  <summary>Details</summary>
Motivation: 传统输电切换方法主要关注成本最小化，但可能牺牲系统可靠性。多目标优化虽能平衡两者，但随着系统规模扩大，计算复杂度高，难以实现。

Method: 采用深度强化学习方法，结合双演员-评论家框架，评估线路切换决策的相对影响，优化决策质量。

Result: 在IEEE 118节点系统上的数值实验表明，该方法优于两种基准DRL算法，验证了其有效性和高效性。

Conclusion: 提出的DRL方法能够高效解决多目标输电切换问题，同时提升系统可靠性和成本效率。

Abstract: Transmission switching is a well-established approach primarily applied to
minimize operational costs through strategic network reconfiguration. However,
exclusive focus on cost reduction can compromise system reliability. While
multi-objective transmission switching can balance cost savings with
reliability improvements, feasible solutions become exceedingly difficult to
obtain as system scale grows, due to the inherent nonlinearity and high
computational demands involved. This paper proposes a deep reinforcement
learning (DRL) method for multi-objective transmission switching. The method
incorporates a dueling-based actor-critic framework to evaluate the relative
impact of each line switching decision within the action space, which improves
decision quality and enhances both system reliability and cost efficiency.
Numerical studies on the IEEE 118-bus system verify the effectiveness and
efficiency of the proposed approach compared to two benchmark DRL algorithms.

</details>


### [88] [Reconfigurable Battery Systems for Enhanced Fast Charging in Electric Vehicles](https://arxiv.org/abs/2507.11749)
*Jonathan Olivares,Tyler Depe,Rakeshkumar Mahto*

Main category: eess.SY

TL;DR: 研究探讨可重构电池系统如何缩短电动汽车充电时间，提出动态调整电池组配置的方法，通过仿真验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车充电时间长是普及的主要障碍，尤其是缺乏快充基础设施的用户。

Method: 提出创新的电池组配置，动态调整电池排列以优化充电性能，使用MATLAB和Simulink进行仿真。

Result: 结果显示，通过可重构性串联更多电池可显著缩短充电时间，同时确保安全性。

Conclusion: 可重构电池设计为家庭充电提供高效解决方案，提升电动汽车的普及和可持续性。

Abstract: The adoption of electric vehicles (EVs) is rapidly growing as a key solution
to reducing greenhouse gas emissions. However, prolonged charging times remain
a significant barrier to widespread EV usage, especially for individuals
without access to fast charging infrastructure. This paper explores the
potential of reconfigurable battery systems to reduce EV charging times without
compromising battery life. We propose innovative battery pack configurations
that dynamically adjust the arrangement of cells to optimize charging
performance. Simulations were conducted using MATLAB and Simulink to compare
the efficiency of various battery configurations, focusing on charging times,
state of charge (SOC), voltage, and current under different conditions. The
results demonstrate that connecting more batteries in series through
reconfigurability in battery packs can significantly reduce charging times
while maintaining operational safety. This study offers insights into how
reconfigurable battery designs can provide a practical solution for faster,
more efficient home-based EV charging, making EV ownership more accessible and
sustainable.

</details>


### [89] [Mobility Extraction and Analysis of GaN HEMTs for RF Applications Using TCAD and Experimental Data](https://arxiv.org/abs/2507.11849)
*Tanjim Rahman*

Main category: eess.SY

TL;DR: 论文通过TCAD模拟和实验表征分析了GaN HEMTs，研究了能带结构和电学性能，展示了优异的开关比和栅控能力。


<details>
  <summary>Details</summary>
Motivation: 研究GaN HEMTs的结构与性能关系，为先进晶体管设计提供理论支持。

Method: 结合Nextnano模拟软件和实验数据（I-V、C-V）分析能带结构和电学参数。

Result: 器件表现出1.9 mA的导通电流和0.01 mA的关断电流，开关比优异；栅控能力良好，峰值跨导为0.5 mS。

Conclusion: 模拟与实验结合的方法为GaN HEMTs的设计提供了全面见解。

Abstract: This paper presents an analysis of GaN high-electron-mobility transistors
(HEMTs) using both TCAD simulation and experimental characterization. The
energy band structure was studied using Nextnano simulation software to observe
two-dimensional electron gas (2DEG) formation and carrier confinement under
equilibrium conditions. Additionally, I-V and C-V data from fabricated
research-grade GaN HEMTs were analyzed to extract key electrical parameters.
The device demonstrated an ON current of 1.9 mA and an OFF current of 0.01 mA,
indicating a strong ON/OFF current ratio. A subthreshold swing of 80 mV/decade
and a DIBL of 5 mV/V were observed, confirming good gate control and
short-channel suppression. The ON-resistance was 22.72 ohm per micron, with a
saturation voltage of 1 V . The peak transconductance was extracted as 0.18 mS
in the linear region and 0.5 mS in saturation. Field-effect mobility was
calculated using the transconductance method, with a maximum value of
approximately 1200 cm2/V.s at low drain bias. The combined simulation and
experimental approach provided comprehensive insight into GaN HEMT behavior,
enabling a deeper understanding of structure-performance relationships critical
to advanced transistor design.

</details>


### [90] [Algorithm Design and Comparative Test of Natural Gradient Gaussian Approximation Filter](https://arxiv.org/abs/2507.11872)
*Wenhan Cao,Tianyi Zhang,Shengbo Eben Li*

Main category: eess.SY

TL;DR: NANO滤波器通过自然梯度下降和优化问题解决非线性非高斯系统中的滤波问题，性能优于传统卡尔曼滤波器家族。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯滤波器依赖线性化技术，可能在非线性非高斯系统中引入较大误差，NANO滤波器旨在解决这一问题。

Method: NANO滤波器将贝叶斯滤波视为两个优化问题，利用自然梯度下降直接最小化更新目标，避免线性化误差。

Result: 在多种经典系统和噪声条件下，NANO滤波器性能优于EKF、UKF等传统滤波器，且计算负担相似。

Conclusion: NANO滤波器在非线性非高斯系统中表现优越，具有实际应用潜力。

Abstract: Popular Bayes filters typically rely on linearization techniques such as
Taylor series expansion and stochastic linear regression to use the structure
of standard Kalman filter. These techniques may introduce large estimation
errors in nonlinear and non-Gaussian systems. This paper overviews a recent
breakthrough in filtering algorithm design called \textit{N}atural
Gr\textit{a}dient Gaussia\textit{n} Appr\textit{o}ximation (NANO) filter and
compare its performance over a large class of nonlinear filters. The NANO
filter interprets Bayesian filtering as solutions to two distinct optimization
problems, which allows to define optimal Gaussian approximation and derive its
corresponding extremum conditions. The algorithm design still follows the
two-step structure of Bayes filters. In the prediction step, NANO filter
calculates the first two moments of the prior distribution, and this process is
equivalent to a moment-matching filter. In the update step, natural gradient
descent is employed to directly minimize the objective of the update step,
thereby avoiding errors caused by model linearization. Comparative tests are
conducted on four classic systems, including the damped linear oscillator,
sequence forecasting, modified growth model, and robot localization, under
Gaussian, Laplace, and Beta noise to evaluate the NANO filter's capability in
handling nonlinearity. Additionally, we validate the NANO filter's robustness
to data outliers using a satellite attitude estimation example. It is observed
that the NANO filter outperforms popular Kalman filters family such as extended
Kalman filter (EKF), unscented Kalman filter (UKF), iterated extended Kalman
filter (IEKF) and posterior linearization filter (PLF), while having similar
computational burden.

</details>


### [91] [Advantages of Feedback in Distributed Data-Gathering for Accurate and Power-Efficient State-Estimation](https://arxiv.org/abs/2507.11924)
*Hyeongmin Choe,Soojean Han*

Main category: eess.SY

TL;DR: 本文提出了一种反馈式（FB）分布式数据收集方法，通过中心单元向移动传感器反馈信息以减少冗余传输和通信拥塞，并与传统非反馈（NF）架构在性能和功耗上进行了比较。


<details>
  <summary>Details</summary>
Motivation: 在分布式目标跟踪传感器网络中，高效的数据收集方法对节省通信资源和确保信息准确性至关重要。

Method: 提出FB方法，中心单元向传感器反馈信息以减少冗余传输；通过理论分析和数值模拟比较FB与NF的性能（MSE和功耗）。

Result: FB的可行性主要取决于通信功耗成本，而优势则与传感器的传播延迟相关；数值模拟验证了理论结果的准确性。

Conclusion: FB在特定条件下优于NF，理论分析结果在复杂场景中仍成立。

Abstract: In distributed target-tracking sensor networks, efficient data gathering
methods are necessary to save communication resources and assure information
accuracy. This paper proposes a Feedback (FB) distributed data-gathering method
which lets the central unit feed information back to the mobile sensors; each
sensor then uses it to cancel redundant transmissions and reduce communication
congestion. We rigorously compare its performance, in terms of mean-squared
error (MSE) and cost of power per sensor, against more conventional
Non-Feedback (NF) architectures by evaluating conditions of feasibility and
advantage under different architecture specifications (e.g., communication
delay rate, power cost rate, maximum back-off time, sampling period,
observation noise). Here, we defined the advantage as the performance gain
achieved by FB over NF, while FB is said to be feasible if the advantage region
is nonempty. Our theoretical analyses show that the feasibility of FB depends
more on the communication power cost, while the advantage depends on the
sensors' propagation delay per transmission interval; we derive concrete
conditions under which these outcomes hold. Using extensive numerical
simulations under a variety of settings, we confirm the accuracy of the derived
conditions, and show that our theoretical results hold even for more complex
scenarios where the simplifying assumptions no longer hold.

</details>


### [92] [Towards Ultra-Reliable 6G in-X Subnetworks: Dynamic Link Adaptation by Deep Reinforcement Learning](https://arxiv.org/abs/2507.12031)
*Fateme Salehi,Aamir Mahmood,Sarder Fakhrul Abedin,Kyi Thar,Mikael Gidlund*

Main category: eess.SY

TL;DR: 本文提出了一种基于深度强化学习的链路自适应框架，用于6G网络中满足超可靠低延迟通信（URLLC）需求，特别关注减少连续数据包中断。


<details>
  <summary>Details</summary>
Motivation: 6G网络中，连续数据包中断可能破坏控制环路并威胁工业环境安全，现有研究多关注平均可靠性，而忽略了突发中断问题。

Method: 采用基于软演员-评论家（SAC）的深度强化学习算法，动态调整传输功率和块长度，以优化能量效率和可靠性。

Result: 仿真结果表明，该方法显著优于基线算法，减少了中断突发，同时仅消耗最大资源分配策略18%的传输成本。

Conclusion: 该框架通过调整奖励权重，灵活平衡能量效率与可靠性，适用于多样化的工业需求。

Abstract: 6G networks are composed of subnetworks expected to meet ultra-reliable
low-latency communication (URLLC) requirements for mission-critical
applications such as industrial control and automation. An often-ignored aspect
in URLLC is consecutive packet outages, which can destabilize control loops and
compromise safety in in-factory environments. Hence, the current work proposes
a link adaptation framework to support extreme reliability requirements using
the soft actor-critic (SAC)-based deep reinforcement learning (DRL) algorithm
that jointly optimizes energy efficiency (EE) and reliability under dynamic
channel and interference conditions. Unlike prior work focusing on average
reliability, our method explicitly targets reducing burst/consecutive outages
through adaptive control of transmit power and blocklength based solely on the
observed signal-to-interference-plus-noise ratio (SINR). The joint optimization
problem is formulated under finite blocklength and quality of service
constraints, balancing reliability and EE. Simulation results show that the
proposed method significantly outperforms the baseline algorithms, reducing
outage bursts while consuming only 18\% of the transmission cost required by a
full/maximum resource allocation policy in the evaluated scenario. The
framework also supports flexible trade-off tuning between EE and reliability by
adjusting reward weights, making it adaptable to diverse industrial
requirements.

</details>


### [93] [Distributed Resilient State Estimation and Control with Strategically Implemented Security Measures](https://arxiv.org/abs/2507.12052)
*Takumi Shinohara,Karl H. Johansson,Henrik Sandberg*

Main category: eess.SY

TL;DR: 论文研究了分布式弹性状态估计与控制问题，针对恶意虚假数据注入攻击和有界噪声，提出了一种优化安全措施的方法。


<details>
  <summary>Details</summary>
Motivation: 解决线性时不变系统在传感器攻击和噪声下的弹性状态估计与控制问题，平衡安全措施的增益与成本。

Method: 提出一种算法确定最优安全措施，并开发分布式弹性状态估计与控制方案。

Result: 通过数值仿真验证了方法的有效性，确保估计和控制误差有界。

Conclusion: 优化安全措施可最大化系统弹性，算法在特定条件下可高效计算。

Abstract: This paper addresses the problem of distributed resilient state estimation
and control for linear time-invariant systems in the presence of malicious
false data injection sensor attacks and bounded noise. We consider a system
operator (defender) capable of deploying cybersecurity measures to counteract
the sensor compromises. Although such measures enhance resilience against
adversarial attacks, they may incur substantial costs; hence, it is crucial to
select countermeasures to balance resilience gains and cost efficiency
strategically. We first demonstrate that the system's resilience against
attacks is maximized through the appropriate implementation of security
measures, implying that no attacker can execute undetectable sensor attacks.
Building on this analysis, we propose an algorithm that identifies the optimal
security measure. While determining this measure is NP-hard in general, we also
derive sufficient conditions under which efficient computation is feasible.
Furthermore, we develop a distributed resilient state estimation and control
scheme informed by the optimal security measure and establish conditions that
guarantee bounded estimation and control errors. Finally, we validate the
efficacy of our approach via numerical simulations of a vehicle platooning
scenario.

</details>


### [94] [Inductance Estimation for High-Power Multilayer Rectangle Planar Windings](https://arxiv.org/abs/2507.12082)
*Theofilos Papadopoulos,Antonios Antonopoulos*

Main category: eess.SY

TL;DR: 提出了一种简单准确的单形式方程，用于估算多层矩形平面绕组（MLRPWs）的电感，适用于高频高功率应用。


<details>
  <summary>Details</summary>
Motivation: 为高频高功率应用中的多层矩形平面绕组提供一种简单且准确的电感估算方法。

Method: 通过多重线性回归（MLR）生成几何尺寸的幂乘积方程，基于约6,000个模拟绕组数据，训练与评估比例为80/20。

Result: 平均误差为0%，标准差低于1.8%，并在实验样本中验证了准确性。

Conclusion: 该方法在电感估算中表现出高准确性和广泛适用性。

Abstract: This paper proposes a simple and accurate monomial-like equation for
estimating the inductance of Multilayer Rectangle-shaped Planar Windings
(MLRPWs) for high-frequency, high-power applications. The equation consists of
the power product of the geometrical dimensions, raised at individual power
coefficients. The coefficients are generated via Multiple Linear Regression
(MLR), based on a large set of approximately 6,000 simulated windings, with an
80/20 training/evaluation sample ratio. The resulting mean error value is 0%,
with a standard deviation below 1.8%. The accuracy of the inductance estimation
is confirmed on several experimental samples, with dimensions both within and
outside the initial training dataset.

</details>


### [95] [Integrated Switched Capacitor Array and Synchronous Charge Extraction with Adaptive Hybrid MPPT for Piezoelectric Harvesters](https://arxiv.org/abs/2507.12163)
*Pramit Karmakar,Siddharth B,Chinmay Murlidhar Kadnur Rao*

Main category: eess.SY

TL;DR: 本文提出了一种新型的压电能量收集（PEH）框架，解决了窄带宽、非线性和阻抗不匹配等挑战，通过SECE、混合MPPT和SCA等技术提高了系统性能。


<details>
  <summary>Details</summary>
Motivation: 压电能量收集技术因其利用环境振动实现自供电的潜力而备受关注，但面临带宽窄、非线性等问题，亟需改进。

Method: 提出了一种自适应PEH框架，结合非线性压电模型、SECE、混合MPPT和SCA，利用Bouc-Wen模型描述非线性。

Result: SECE在机械极值点提取最大电荷，混合MPPT优于传统P&O，SCA系统对变频输入表现出鲁棒性。

Conclusion: 该框架有效解决了PEH的关键挑战，为下一代电子系统和可持续基础设施提供了技术支持。

Abstract: Energy Harvesting technologies will play a fundamental role in the
development of the next generation of electronic systems as well as in
advancing the development of sustainable infrastructure. One of the critical
challenges in EH is utilizing ambient vibrations to harvest energy. Piezo
Energy Harvesting, which uses ambient vibrations, is a promising technology in
energy harvesting and a self-powered technology. However, it suffers from
several practical challenges. Some of these challenges include narrow
bandwidth, non-linearity, and impedance mismatch, among others. This paper
presents a novel, simulated Piezo Energy Harvesting (PEH) framework that
addresses some of these challenges. The proposed model is designed to be
adaptive and effective against the inherent non-linearity of PEH. This detailed
model covers a non-linear piezo, Synchronous Electric Charge Extraction (SECE),
Hybrid Maximum Power Point Tracking (MPPT) and a Switched Capacitor Array
(SCA). The SECE extracts the maximum charge accumulated on the piezo every time
the piezo reaches the mechanical extremum. The Bouc-Wen model has been used to
establish nonlinearity in the system. The hybrid MPPT exhibits significant
improvement over conventional P&O, while the SCA-tuned system demonstrates
resilience against variable frequency input.

</details>


### [96] [Learning, fast and slow: a two-fold algorithm for data-based model adaptation](https://arxiv.org/abs/2507.12187)
*Laura Boca de Giuli,Alessio La Bella,Riccardo Scattolini*

Main category: eess.SY

TL;DR: 提出了一种新型的双重建模架构，用于解决由域外和域内不确定性引起的模型失配问题，通过慢学习和快学习组件分别处理不同情况，显著提升了模型准确性。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动模型在运行过程中因域外和域内不确定性导致的模型失配问题。

Method: 采用慢学习组件处理域外不确定性（通过模型集成和监控策略），快学习组件（高斯过程模型）实时补偿域内不确定性。

Result: 在基准能源系统上测试表明，该方法比标准适应方法更准确。

Conclusion: 双重建模架构有效提升了模型适应性和准确性。

Abstract: This article addresses the challenge of adapting data-based models over time.
We propose a novel two-fold modelling architecture designed to correct
plant-model mismatch caused by two types of uncertainty. Out-of-domain
uncertainty arises when the system operates under conditions not represented in
the initial training dataset, while in-domain uncertainty results from
real-world variability and flaws in the model structure or training process. To
handle out-of-domain uncertainty, a slow learning component, inspired by the
human brain's slow thinking process, learns system dynamics under unexplored
operating conditions, and it is activated only when a monitoring strategy deems
it necessary. This component consists of an ensemble of models, featuring (i) a
combination rule that weights individual models based on the statistical
proximity between their training data and the current operating condition, and
(ii) a monitoring algorithm based on statistical control charts that supervises
the ensemble's reliability and triggers the offline training and integration of
a new model when a new operating condition is detected. To address in-domain
uncertainty, a fast learning component, inspired by the human brain's fast
thinking process, continuously compensates in real time for the mismatch of the
slow learning model. This component is implemented as a Gaussian process (GP)
model, trained online at each iteration using recent data while discarding
older samples. The proposed methodology is tested on a benchmark energy system
referenced in the literature, demonstrating that the combined use of slow and
fast learning components improves model accuracy compared to standard
adaptation approaches.

</details>


### [97] [Neural Co-state Regulator: A Data-Driven Paradigm for Real-time Optimal Control with Input Constraints](https://arxiv.org/abs/2507.12259)
*Lihan Lian,Yuxin Tong,Uduak Inyang-Udoh*

Main category: eess.SY

TL;DR: 提出了一种无监督学习框架（NCR）用于实时解决带输入约束的非线性最优控制问题，性能优于传统非线性MPC。


<details>
  <summary>Details</summary>
Motivation: 解决传统非线性最优控制问题中计算复杂性和依赖专家求解器的问题。

Method: 通过神经网络预测最优共态轨迹，结合二次规划求解控制输入，满足约束和最优性条件。

Result: NCR在收敛误差和输入轨迹平滑性上优于非线性MPC，计算时间减少两个数量级。

Conclusion: NCR是一种高效且性能优越的实时非线性控制解决方案。

Abstract: We propose a novel unsupervised learning framework for solving nonlinear
optimal control problems (OCPs) with input constraints in real-time. In this
framework, a neural network (NN) learns to predict the optimal co-state
trajectory that minimizes the control Hamiltonian for a given system, at any
system's state, based on the Pontryagin's Minimum Principle (PMP).
Specifically, the NN is trained to find the norm-optimal co-state solution that
simultaneously satisfies the nonlinear system dynamics and minimizes a
quadratic regulation cost. The control input is then extracted from the
predicted optimal co-state trajectory by solving a quadratic program (QP) to
satisfy input constraints and optimality conditions. We coin the term neural
co-state regulator (NCR) to describe the combination of the co-state NN and
control input QP solver. To demonstrate the effectiveness of the NCR, we
compare its feedback control performance with that of an expert nonlinear model
predictive control (MPC) solver on a unicycle model. Because the NCR's training
does not rely on expert nonlinear control solvers which are often suboptimal,
the NCR is able to produce solutions that outperform the nonlinear MPC solver
in terms of convergence error and input trajectory smoothness even for system
conditions that are outside its original training domain. At the same time, the
NCR offers two orders of magnitude less computational time than the nonlinear
MPC.

</details>


### [98] [Mixed-integer Second-Order Cone Programming for Multi-period Scheduling of Flexible AC Transmission System Devices](https://arxiv.org/abs/2507.12327)
*Mohamad Charara,Martin De Montigny,Nivine Abou Daher,Hanane Dagdougui,Antoine Lesage-Landry*

Main category: eess.SY

TL;DR: 提出了一种混合整数二阶锥规划模型，用于电力传输系统中关键FACTS设备的多周期调度，以最小化有功功率损耗。


<details>
  <summary>Details</summary>
Motivation: 随着能源需求增加和可再生能源的广泛集成，电力系统面临过载、损耗和稳定性问题，FACTS设备对确保电网可靠运行至关重要。

Method: 采用混合整数二阶锥规划模型，整合了四种关键控制机制（OLTCs、STATCOMs、shunt reactors、TCSCs），并通过二阶锥松弛和线性化处理设备约束。

Result: 在IEEE 9-bus、30-bus和RTS96测试系统中验证了模型的有效性，能够显著减少损耗。

Conclusion: 该模型适用于大规模电网，为FACTS设备的多周期调度提供了有效解决方案。

Abstract: With the increasing energy demand and the growing integration of renewable
sources of energy, power systems face operational challenges such as overloads,
losses, and stability concerns, particularly as networks operate near their
capacity limits. Flexible alternating current transmission system (FACTS)
devices are essential to ensure reliable grid operations and enable the
efficient integration of renewable energy. This work introduces a mixed-integer
second-order cone programming (MISOCP) model for the multi-period scheduling of
key FACTS devices in electric transmission systems. The proposed model
integrates four key control mechanisms: (i) on-load tap changers (OLTCs) for
voltage regulation via discrete taps; (ii) static synchronous compensators
(STATCOMs) and (iii) shunt reactors for reactive power compensation; and (iv)
thyristor-controlled series capacitors (TCSCs) for adjustable impedance and
flow control. The objective is to minimize active power losses using a limited
number of control actions while meeting physical and operational constraints at
all times throughout the defined time horizon. To ensure tractability, the
model employs a second-order cone relaxation of the power flow. Device-specific
constraints are handled via binary expansion and linearization: OLTCs and shunt
reactors are modelled with discrete variables, STATCOMs through reactive power
bounds, and TCSCs using a reformulation-linearization technique (RLT). A
multi-period formulation captures the sequential nature of decision making,
ensuring consistency across time steps. The model is evaluated on the IEEE
9-bus, 30-bus, and RTS96 test systems, demonstrating its ability to reduce
losses, with potential applicability to larger-scale grids.

</details>


### [99] [Symbolic Control: Unveiling Free Robustness Margins](https://arxiv.org/abs/2507.12339)
*Youssef Ait Si,Antoine Girard,Adnane Saoud*

Main category: eess.SY

TL;DR: 本文研究了符号控制技术在系统扰动下的鲁棒性问题，提出了计算最大鲁棒性边界的方法，并展示了其在控制器综合中的应用。


<details>
  <summary>Details</summary>
Motivation: 符号控制技术在实际应用中面临系统扰动的挑战，需要确保其鲁棒性。

Method: 通过交替模拟关系分析符号模型，计算均匀和非均匀的鲁棒性边界，并探讨其与可达性技术的关系。

Result: 符号模型具有固有的鲁棒性边界，且其紧密度取决于可达性技术的紧密度。通过示例验证了方法的有效性。

Conclusion: 本文提出的方法能有效计算鲁棒性边界，并支持控制器综合，为符号控制技术的实际应用提供了保障。

Abstract: This paper addresses the challenge of ensuring robustness in the presence of
system perturbations for symbolic control techniques. Given a discrete-time
control system that is related to its symbolic model by an alternating
simulation relation. In this paper, we focus on computing the maximum
robustness margin under which the symbolic model remains valid for a
perturbed-version of the discrete-time control system. We first show that
symbolic models are inherently equipped with a certain free robustness margins.
We then provide constructive procedures to compute uniform and non-uniform
(state and input dependent) robustness margins. We also show that the tightness
of the robustness margin depends on the tightness of the reachability technique
used to compute the symbolic model. We then explain how the computed robustness
margin can be used for the sake of controller synthesis. Finally, we present
two illustrative examples to demonstrate the effectiveness of our approach.

</details>


### [100] [BitWave: Exploiting Column-Based Bit-Level Sparsity for Deep Learning Acceleration](https://arxiv.org/abs/2507.12444)
*Man Shi,Vikram Jain,Antony Joseph,Maurice Meijer,Marian Verhelst*

Main category: eess.SY

TL;DR: BitWave是一种新型的位序列计算架构，通过结构化位级稀疏性和动态数据流技术，显著提升了DNN加速器的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的位序列加速器虽然能利用位级稀疏性减少计算，但由于非零位的不规则索引导致内存访问效率低下，限制了性能。

Method: 提出了一种名为“位列序列”的计算方法和兼容的BitWave架构设计，结合结构化位级稀疏性和动态数据流技术，减少计算和内存占用。

Result: 在四个深度学习基准测试中，BitWave实现了最高13.25倍的速度提升和7.71倍的效率提升，同时在16nm工艺下占用1.138 mm2面积和17.56 mW功耗。

Conclusion: BitWave通过位翻转的后期训练优化，有效缓解了稀疏性增强技术带来的性能下降或重新训练需求，显著提升了DNN加速器的性能。

Abstract: Bit-serial computation facilitates bit-wise sequential data processing,
offering numerous benefits, such as a reduced area footprint and
dynamically-adaptive computational precision. It has emerged as a prominent
approach, particularly in leveraging bit-level sparsity in Deep Neural Networks
(DNNs). However, existing bit-serial accelerators exploit bit-level sparsity to
reduce computations by skipping zero bits, but they suffer from inefficient
memory accesses due to the irregular indices of the non-zero bits.
  As memory accesses typically are the dominant contributor to DNN accelerator
performance, this paper introduces a novel computing approach called
"bit-column-serial" and a compatible architecture design named "BitWave."
BitWave harnesses the advantages of the "bit-column-serial" approach,
leveraging structured bit-level sparsity in combination with dynamic dataflow
techniques. This achieves a reduction in computations and memory footprints
through redundant computation skipping and weight compression. BitWave is able
to mitigate the performance drop or the need for retraining that is typically
associated with sparsity-enhancing techniques using a post-training
optimization involving selected weight bit-flips. Empirical studies conducted
on four deep-learning benchmarks demonstrate the achievements of BitWave: (1)
Maximally realize 13.25x higher speedup, 7.71x efficiency compared to
state-of-the-art sparsity-aware accelerators. (2) Occupying 1.138 mm2 area and
consuming 17.56 mW power in 16nm FinFet process node.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [101] [Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection](https://arxiv.org/abs/2507.11777)
*Ivan Viakhirev,Daniil Sirota,Aleksandr Smirnov,Kirill Borodin*

Main category: cs.SD

TL;DR: 论文提出对AASIST反欺骗架构的改进，通过引入冻结的Wav2Vec 2.0编码器、标准化多头注意力模块和可训练的上下文感知融合层，显著提升了语音深度伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着语音转换和文本到语音合成技术的进步，自动说话人验证系统更容易受到欺骗攻击，因此需要改进反欺骗技术。

Method: 改进AASIST架构，包括使用冻结的Wav2Vec 2.0编码器、替换图注意力块为标准化多头注意力模块，以及引入可训练的上下文感知融合层。

Result: 在ASVspoof 5语料库上，系统达到7.6%的等错误率（EER），优于基准模型。

Conclusion: 针对现有模型的针对性调整可以有效提升语音深度伪造检测性能，适用于实际场景。

Abstract: Advances in voice conversion and text-to-speech synthesis have made automatic
speaker verification (ASV) systems more susceptible to spoofing attacks. This
work explores modest refinements to the AASIST anti-spoofing architecture. It
incorporates a frozen Wav2Vec 2.0 encoder to retain self-supervised speech
representations in limited-data settings, substitutes the original graph
attention block with a standardized multi-head attention module using
heterogeneous query projections, and replaces heuristic frame-segment fusion
with a trainable, context-aware integration layer. When evaluated on the
ASVspoof 5 corpus, the proposed system reaches a 7.6\% equal error rate (EER),
improving on a re-implemented AASIST baseline under the same training
conditions. Ablation experiments suggest that each architectural change
contributes to the overall performance, indicating that targeted adjustments to
established models may help strengthen speech deepfake detection in practical
scenarios. The code is publicly available at
https://github.com/KORALLLL/AASIST_SCALING.

</details>


### [102] [A Multimodal Data Fusion Generative Adversarial Network for Real Time Underwater Sound Speed Field Construction](https://arxiv.org/abs/2507.11812)
*Wei Huang,Yuqiang Huang,Yanan Wu,Tianhe Xu,Junting Wang,Hao Zhang*

Main category: cs.SD

TL;DR: 提出了一种多模态数据融合生成对抗网络模型（MDF-RAGAN），用于无需现场水下数据测量的高精度声速剖面构建，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统声速剖面获取方法依赖现场声纳观测数据，部署要求严格，需开发无需现场测量的高精度方法。

Method: 采用多模态数据融合生成对抗网络，嵌入注意力机制和残差模块，捕捉全球空间特征关联和深海声速分布微小扰动。

Result: 在真实数据集上，误差小于0.3m/s，优于CNN和SITP近两倍，RMSE降低65.8%。

Conclusion: MDF-RAGAN通过多源融合和跨模态注意力显著提升了声速剖面匹配精度。

Abstract: Sound speed profiles (SSPs) are essential parameters underwater that affects
the propagation mode of underwater signals and has a critical impact on the
energy efficiency of underwater acoustic communication and accuracy of
underwater acoustic positioning. Traditionally, SSPs can be obtained by
matching field processing (MFP), compressive sensing (CS), and deep learning
(DL) methods. However, existing methods mainly rely on on-site underwater sonar
observation data, which put forward strict requirements on the deployment of
sonar observation systems. To achieve high-precision estimation of sound
velocity distribution in a given sea area without on-site underwater data
measurement, we propose a multi-modal data-fusion generative adversarial
network model with residual attention block (MDF-RAGAN) for SSP construction.
To improve the model's ability for capturing global spatial feature
correlations, we embedded the attention mechanisms, and use residual modules
for deeply capturing small disturbances in the deep ocean sound velocity
distribution caused by changes of SST. Experimental results on real open
dataset show that the proposed model outperforms other state-of-the-art
methods, which achieves an accuracy with an error of less than 0.3m/s.
Specifically, MDF-RAGAN not only outperforms convolutional neural network (CNN)
and spatial interpolation (SITP) by nearly a factor of two, but also achieves
about 65.8\% root mean square error (RMSE) reduction compared to mean profile,
which fully reflects the enhancement of overall profile matching by
multi-source fusion and cross-modal attention.

</details>


### [103] [Schrödinger Bridge Consistency Trajectory Models for Speech Enhancement](https://arxiv.org/abs/2507.11925)
*Shuichiro Nishigori,Koichi Saito,Naoki Murata,Masato Hirano,Shusuke Takahashi,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 论文提出了一种基于Schrödinger桥的一致性轨迹模型（SBCTM），用于语音增强，显著提高了推理速度并保持了质量与速度的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 传统基于Schrödinger桥的扩散模型在语音增强中存在推理速度慢的问题，而一致性模型（CMs）虽能加速但无法提升生成质量。因此，作者提出结合一致性轨迹模型（CTMs）和Schrödinger桥的SBCTM，以解决这一问题。

Method: 将CTM技术应用于Schrödinger桥，并引入包括感知损失在内的新型辅助损失函数，优化训练框架。

Result: SBCTM在实时因子（RTF）上比传统Schrödinger桥提升了约16倍，并在质量与速度之间取得了良好平衡。

Conclusion: SBCTM是一种高效的语音增强方法，适用于需要快速推理的场景，同时代码和模型已开源。

Abstract: Speech enhancement (SE) utilizing diffusion models is a promising technology
that improves speech quality in noisy speech data. Furthermore, the
Schr\"odinger bridge (SB) has recently been used in diffusion-based SE to
improve speech quality by resolving a mismatch between the endpoint of the
forward process and the starting point of the reverse process. However, the SB
still exhibits slow inference owing to the necessity of a large number of
function evaluations (NFE) for inference to obtain high-quality results. While
Consistency Models (CMs) address this issue by employing consistency training
that uses distillation from pretrained models in the field of image generation,
it does not improve generation quality when the number of steps increases. As a
solution to this problem, Consistency Trajectory Models (CTMs) not only
accelerate inference speed but also maintain a favorable trade-off between
quality and speed. Furthermore, SoundCTM demonstrates the applicability of CTM
techniques to the field of sound generation. In this paper, we present
Schr\"odinger bridge Consistency Trajectory Models (SBCTM) by applying the
CTM's technique to the Schr\"odinger bridge for SE. Additionally, we introduce
a novel auxiliary loss, including a perceptual loss, into the original CTM's
training framework. As a result, SBCTM achieves an approximately 16x
improvement in the real-time factor (RTF) compared to the conventional
Schr\"odinger bridge for SE. Furthermore, the favorable trade-off between
quality and speed in SBCTM allows for time-efficient inference by limiting
multi-step refinement to cases where 1-step inference is insufficient. Our
code, pretrained models, and audio samples are available at
https://github.com/sony/sbctm/.

</details>


### [104] [EME-TTS: Unlocking the Emphasis and Emotion Link in Speech Synthesis](https://arxiv.org/abs/2507.12015)
*Haoxun Li,Leyuan Qu,Jiaxi Hu,Taihao Li*

Main category: cs.SD

TL;DR: EME-TTS是一个结合情感和强调的TTS框架，通过弱监督学习和EPE模块提升情感语音的表达力和强调稳定性。


<details>
  <summary>Details</summary>
Motivation: 探索情感TTS与强调可控语音合成的交互，解决如何利用强调增强情感语音表达及保持强调清晰稳定性的问题。

Method: 采用弱监督学习（伪标签和基于方差的强调特征）和EPE模块增强情感信号与强调位置的交互。

Result: 实验表明，结合大语言模型预测强调位置，EME-TTS能生成更自然的情感语音，同时保持强调的稳定性和区分性。

Conclusion: EME-TTS有效解决了情感与强调的交互问题，为情感语音合成提供了新方向。

Abstract: In recent years, emotional Text-to-Speech (TTS) synthesis and
emphasis-controllable speech synthesis have advanced significantly. However,
their interaction remains underexplored. We propose Emphasis Meets Emotion TTS
(EME-TTS), a novel framework designed to address two key research questions:
(1) how to effectively utilize emphasis to enhance the expressiveness of
emotional speech, and (2) how to maintain the perceptual clarity and stability
of target emphasis across different emotions. EME-TTS employs weakly supervised
learning with emphasis pseudo-labels and variance-based emphasis features.
Additionally, the proposed Emphasis Perception Enhancement (EPE) block enhances
the interaction between emotional signals and emphasis positions. Experimental
results show that EME-TTS, when combined with large language models for
emphasis position prediction, enables more natural emotional speech synthesis
while preserving stable and distinguishable target emphasis across emotions.
Synthesized samples are available on-line.

</details>


### [105] [Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification](https://arxiv.org/abs/2507.12042)
*Kazuki Shimada,Archontis Politis,Iran R. Roman,Parthasaarathy Sudarsanam,David Diaz-Guerra,Ruchi Pandey,Kengo Uchida,Yuichiro Koyama,Naoya Takahashi,Takashi Shibuya,Shusuke Takahashi,Tuomas Virtanen,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: DCASE2025挑战赛任务3聚焦于立体声数据的声事件定位与检测（SELD），引入新数据集和基线系统，评估指标包括屏幕内外分类。


<details>
  <summary>Details</summary>
Motivation: 从传统的四声道音频转向更常见的立体声数据，以适应有限视场的场景，并解决立体声数据的角度模糊问题。

Method: 使用立体声音频和视频帧作为输入，基线系统整合了屏幕内外分类任务。

Result: 基线系统在立体声数据上表现良好。

Conclusion: 任务3为立体声SELD提供了新数据集和评估框架，适应更广泛的媒体场景。

Abstract: This paper presents the objective, dataset, baseline, and metrics of Task 3
of the DCASE2025 Challenge on sound event localization and detection (SELD). In
previous editions, the challenge used four-channel audio formats of first-order
Ambisonics (FOA) and microphone array. In contrast, this year's challenge
investigates SELD with stereo audio data (termed stereo SELD). This change
shifts the focus from more specialized 360{\deg} audio and audiovisual scene
analysis to more commonplace audio and media scenarios with limited
field-of-view (FOV). Due to inherent angular ambiguities in stereo audio data,
the task focuses on direction-of-arrival (DOA) estimation in the azimuth plane
(left-right axis) along with distance estimation. The challenge remains divided
into two tracks: audio-only and audiovisual, with the audiovisual track
introducing a new sub-task of onscreen/offscreen event classification
necessitated by the limited FOV. This challenge introduces the DCASE2025 Task3
Stereo SELD Dataset, whose stereo audio and perspective video clips are sampled
and converted from the STARSS23 recordings. The baseline system is designed to
process stereo audio and corresponding video frames as inputs. In addition to
the typical SELD event classification and localization, it integrates
onscreen/offscreen classification for the audiovisual track. The evaluation
metrics have been modified to introduce an onscreen/offscreen accuracy metric,
which assesses the models' ability to identify which sound sources are
onscreen. In the experimental evaluation, the baseline system performs
reasonably well with the stereo audio data.

</details>


### [106] [MambaRate: Speech Quality Assessment Across Different Sampling Rates](https://arxiv.org/abs/2507.12090)
*Panos Kakoulidis,Iakovi Alexiou,Junkwang Oh,Gunu Jho,Inchul Hwang,Pirros Tsiakoulis,Aimilios Chalamandaris*

Main category: cs.SD

TL;DR: MambaRate是一种预测音频MOS分数的模型，专注于高采样频率下的语音评分，采用自监督嵌入和选择性状态空间建模，在AudioMOS挑战赛中表现优于基线但未夺冠。


<details>
  <summary>Details</summary>
Motivation: 解决高采样频率语音MOS预测中的采样率偏差问题，参与AudioMOS挑战赛Track 3。

Method: 利用自监督嵌入和选择性状态空间建模，通过高斯径向基函数（RBF）编码目标评分。

Result: 初始版本（T16）在少样本设置下优于基线14%，挑战赛中排名第四，与冠军相差6%；在BVCC数据集上表现更优。

Conclusion: MambaRate在MOS预测中表现良好，但仍有改进空间，特别是在挑战赛中的表现。

Abstract: We propose MambaRate, which predicts Mean Opinion Scores (MOS) with limited
bias regarding the sampling rate of the waveform under evaluation. It is
designed for Track 3 of the AudioMOS Challenge 2025, which focuses on
predicting MOS for speech in high sampling frequencies. Our model leverages
self-supervised embeddings and selective state space modeling. The target
ratings are encoded in a continuous representation via Gaussian radial basis
functions (RBF). The results of the challenge were based on the system-level
Spearman's Rank Correllation Coefficient (SRCC) metric. An initial MambaRate
version (T16 system) outperformed the pre-trained baseline (B03) by ~14% in a
few-shot setting without pre-training. T16 ranked fourth out of five in the
challenge, differing by ~6% from the winning system. We present additional
results on the BVCC dataset as well as ablations with different representations
as input, which outperform the initial T16 version.

</details>


### [107] [Room Impulse Response Generation Conditioned on Acoustic Parameters](https://arxiv.org/abs/2507.12136)
*Silvia Arellano,Chunghsin Yeh,Gautam Bhattacharya,Daniel Arteaga*

Main category: cs.SD

TL;DR: 论文提出了一种基于声学参数而非几何信息的房间脉冲响应生成方法，通过感知驱动实现更灵活的生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖房间几何信息，限制了在未知布局或需要感知真实性时的应用。

Method: 使用声学参数（如混响时间和直达声与混响比）直接生成RIR，探索了自回归和非自回归模型。

Result: 提出的模型性能优于或匹配现有方法，其中MaskGIT表现最佳。

Conclusion: 基于声学参数的方法在灵活性和感知真实性上具有优势，为RIR生成提供了新思路。

Abstract: The generation of room impulse responses (RIRs) using deep neural networks
has attracted growing research interest due to its applications in virtual and
augmented reality, audio postproduction, and related fields. Most existing
approaches condition generative models on physical descriptions of a room, such
as its size, shape, and surface materials. However, this reliance on geometric
information limits their usability in scenarios where the room layout is
unknown or when perceptual realism (how a space sounds to a listener) is more
important than strict physical accuracy. In this study, we propose an
alternative strategy: conditioning RIR generation directly on a set of RIR
acoustic parameters. These parameters include various measures of reverberation
time and direct sound to reverberation ratio, both broadband and bandwise. By
specifying how the space should sound instead of how it should look, our method
enables more flexible and perceptually driven RIR generation. We explore both
autoregressive and non-autoregressive generative models operating in the
Descript Audio Codec domain, using either discrete token sequences or
continuous embeddings. Specifically, we have selected four models to evaluate:
an autoregressive transformer, the MaskGIT model, a flow matching model, and a
classifier-based approach. Objective and subjective evaluations are performed
to compare these methods with state-of-the-art alternatives. Results show that
the proposed models match or outperform state-of-the-art alternatives, with the
MaskGIT model achieving the best performance.

</details>


### [108] [RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection](https://arxiv.org/abs/2507.12175)
*Sungkyun Chang,Simon Dixon,Emmanouil Benetos*

Main category: cs.SD

TL;DR: RUMAA是一个基于Transformer的框架，用于音乐表演分析，统一了乐谱与表演对齐、乐谱转录和错误检测任务。


<details>
  <summary>Details</summary>
Motivation: 传统方法单独处理这些任务，且依赖手动展开的MIDI数据，RUMAA旨在通过统一框架和预训练编码器解决这些问题。

Method: 使用预训练的乐谱和音频编码器，结合三流解码器，通过代理任务捕获任务间的依赖关系。

Result: 在公开钢琴数据集上，RUMAA在非重复乐谱上达到先进水平，在重复乐谱上表现更优，同时提供转录和错误检测的潜力。

Conclusion: RUMAA展示了统一框架在音乐表演分析中的有效性，尤其在处理重复乐谱时表现突出。

Abstract: This study introduces RUMAA, a transformer-based framework for music
performance analysis that unifies score-to-performance alignment,
score-informed transcription, and mistake detection in a near end-to-end
manner. Unlike prior methods addressing these tasks separately, RUMAA
integrates them using pre-trained score and audio encoders and a novel
tri-stream decoder capturing task interdependencies through proxy tasks. It
aligns human-readable MusicXML scores with repeat symbols to full-length
performance audio, overcoming traditional MIDI-based methods that rely on
manually unfolded score-MIDI data with pre-specified repeat structures. RUMAA
matches state-of-the-art alignment methods on non-repeated scores and
outperforms them on scores with repeats in a public piano music dataset, while
also delivering promising transcription and mistake detection results.

</details>


### [109] [Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations](https://arxiv.org/abs/2507.12197)
*Yichen Han,Xiaoyang Hao,Keming Chen,Weibo Xiong,Jun He,Ruonan Zhang,Junjie Cao,Yue Liu,Bowen Li,Dongrui Zhang,Hui Xia,Huilei Fu,Kai Jia,Kaixuan Guo,Mingli Jin,Qingyun Meng,Ruidong Ma,Ruiqian Fang,Shaotong Guo,Xuhui Li,Yang Xiang,Ying Zhang,Yulong Liu,Yunfeng Li,Yuyi Zhang,Yuze Zhou,Zhen Wang,Zhaowen Chen*

Main category: cs.SD

TL;DR: QTTS是一种基于新型音频编解码器QDAC的TTS框架，通过多码本建模和并行预测提升合成质量和速度。


<details>
  <summary>Details</summary>
Motivation: 现有自回归TTS方法依赖单码本表示，导致信息丢失，难以恢复细节（如韵律、音色），尤其在复杂场景（如歌声合成）中表现不佳。

Method: 提出QDAC编解码器，结合ASR自回归网络和GAN进行端到端训练；QTTS采用分层并行架构和延迟多头策略，优化合成质量和推理速度。

Result: 实验表明，QTTS在合成质量和表达内容保留上优于基线方法。

Conclusion: 多码本建模是实现高保真、通用语音和音频生成的有前景方向。

Abstract: Text-to-speech (TTS) synthesis has seen renewed progress under the discrete
modeling paradigm. Existing autoregressive approaches often rely on
single-codebook representations, which suffer from significant information
loss. Even with post-hoc refinement techniques such as flow matching, these
methods fail to recover fine-grained details (e.g., prosodic nuances,
speaker-specific timbres), especially in challenging scenarios like singing
voice or music synthesis. We propose QTTS, a novel TTS framework built upon our
new audio codec, QDAC. The core innovation of QDAC lies in its end-to-end
training of an ASR-based auto-regressive network with a GAN, which achieves
superior semantic feature disentanglement for scalable, near-lossless
compression. QTTS models these discrete codes using two innovative strategies:
the Hierarchical Parallel architecture, which uses a dual-AR structure to model
inter-codebook dependencies for higher-quality synthesis, and the Delay
Multihead approach, which employs parallelized prediction with a fixed delay to
accelerate inference speed. Our experiments demonstrate that the proposed
framework achieves higher synthesis quality and better preserves expressive
content compared to baseline. This suggests that scaling up compression via
multi-codebook modeling is a promising direction for high-fidelity,
general-purpose speech and audio generation.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [110] [Emergent Heterogeneous Swarm Control Through Hebbian Learning](https://arxiv.org/abs/2507.11566)
*Fuda van Diggelen,Tugay Alperen Karagüzel,Andres Garcia Rincon,A. E. Eiben,Dario Floreano,Eliseo Ferrante*

Main category: cs.NE

TL;DR: 论文提出了一种基于Hebbian学习的群体机器人方法，实现了异质性的自动涌现，解决了群体控制中的多个挑战。


<details>
  <summary>Details</summary>
Motivation: 解决群体机器人中异质性控制的复杂性，减少对先验知识的依赖。

Method: 采用Hebbian学习作为局部信息驱动的神经适应方法，通过统一的规则和群体行为演化学习规则。

Result: 异质性自然涌现，群体行为切换能力显著提升，Hebbian学习可作为多智能体强化学习的替代方案。

Conclusion: Hebbian学习为群体机器人提供了一种简单有效的异质性控制方法，具有广泛的应用潜力。

Abstract: In this paper, we introduce Hebbian learning as a novel method for swarm
robotics, enabling the automatic emergence of heterogeneity. Hebbian learning
presents a biologically inspired form of neural adaptation that solely relies
on local information. By doing so, we resolve several major challenges for
learning heterogeneous control: 1) Hebbian learning removes the complexity of
attributing emergent phenomena to single agents through local learning rules,
thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules
across all swarm members limit the number of parameters needed, mitigating the
curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian
learning rules based on swarm-level behaviour minimises the need for extensive
prior knowledge typically required for optimising heterogeneous swarms. This
work demonstrates that with Hebbian learning heterogeneity naturally emerges,
resulting in swarm-level behavioural switching and in significantly improved
swarm capabilities. It also demonstrates how the evolution of Hebbian learning
rules can be a valid alternative to Multi Agent Reinforcement Learning in
standard benchmarking tasks.

</details>


### [111] [Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11751)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.NE

TL;DR: 该论文探讨了在大数据背景下，利用遗传算法和差分进化算法进行文档语义相似性搜索的最新进展。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力的提升和大数据的兴起，传统的分布式计算方法在文档相似性识别中面临挑战，需要更高效的算法。

Method: 研究聚焦于遗传算法和差分进化算法，分析其在语义文本相似性搜索中的应用。

Result: 论文总结了这些进化计算算法在文档相似性搜索中的成功应用和最新进展。

Conclusion: 遗传算法和差分进化算法在大数据环境下对文档相似性搜索具有显著潜力。

Abstract: Identifying similar documents within extensive volumes of data poses a
significant challenge. To tackle this issue, researchers have developed a
variety of effective distributed computing techniques. With the advancement of
computing power and the rise of big data, deep neural networks and evolutionary
computing algorithms such as genetic algorithms and differential evolution
algorithms have achieved greater success. This survey will explore the most
recent advancements in the search for documents based on their semantic text
similarity, focusing on genetic and differential evolutionary computing
algorithms.

</details>


### [112] [Simulated Language Acquisition in a Biologically Realistic Model of the Brain](https://arxiv.org/abs/2507.11788)
*Daniel Mitropolsky,Christos Papadimitriou*

Main category: cs.NE

TL;DR: 论文提出了一种基于六种神经科学原则的数学形式化方法，并实现了一个模拟神经形态系统，能够从零开始学习语言的基本语义和语法。


<details>
  <summary>Details</summary>
Motivation: 尽管神经科学取得了巨大进展，但仍缺乏对神经元活动如何导致高级认知现象（如计划和语言）的明确解释。

Method: 基于六种神经科学原则（兴奋性神经元、脑区、随机突触、Hebbian可塑性、局部抑制和区域间抑制），构建了一个模拟神经形态系统。

Result: 该系统能够从零开始学习语言的语义、语法角色和词序，并能生成新句子。

Conclusion: 该结果为神经科学与认知现象之间的联系提供了新的视角，并提出了可能的扩展方向。

Abstract: Despite tremendous progress in neuroscience, we do not have a compelling
narrative for the precise way whereby the spiking of neurons in our brain
results in high-level cognitive phenomena such as planning and language. We
introduce a simple mathematical formulation of six basic and broadly accepted
principles of neuroscience: excitatory neurons, brain areas, random synapses,
Hebbian plasticity, local inhibition, and inter-area inhibition. We implement a
simulated neuromorphic system based on this formalism, which is capable of
basic language acquisition: Starting from a tabula rasa, the system learns, in
any language, the semantics of words, their syntactic role (verb versus noun),
and the word order of the language, including the ability to generate novel
sentences, through the exposure to a modest number of grounded sentences in the
same language. We discuss several possible extensions and implications of this
result.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [113] [A Cellular Automata Approach to Donation Game](https://arxiv.org/abs/2507.11744)
*Marcin Kowalik,Przemysław Stokłosa,Mateusz Grabowski,Janusz Starzyk,Paweł Raif*

Main category: cs.MA

TL;DR: 论文研究了在多智能体系统中，合作行为如何受到环境噪声和智能体决策策略的影响，通过一维二元细胞自动机模型探索了合作动态。


<details>
  <summary>Details</summary>
Motivation: 传统模拟假设完全随机交互，而本研究关注智能体与邻近邻居交互时的合作演化，以更贴近现实场景。

Method: 使用Stephen Wolfram的一维二元细胞自动机模型，定义符合捐赠游戏机制的规则，并引入感知和行动噪声模型及策略突变矩阵。

Result: 实验结果表明，合作行为显著受智能体移动性和空间局部性的影响。

Conclusion: 研究强调了区分完全随机多智能体系统与邻近交互系统的重要性，为合作行为的演化提供了新视角。

Abstract: The donation game is a well-established framework for studying the emergence
and evolution of cooperation in multi-agent systems. The cooperative behavior
can be influenced by the environmental noise in partially observable settings
and by the decision-making strategies of agents, which may incorporate not only
reputation but also traits such as generosity and forgiveness. Traditional
simulations often assume fully random interactions, where cooperation is tested
between randomly selected agent pairs. In this paper, we investigate
cooperation dynamics using the concept of Stephen Wolfram's one-dimensional
binary cellular automata. This approach allows us to explore how cooperation
evolves when interactions are limited to neighboring agents. We define binary
cellular automata rules that conform to the donation game mechanics.
Additionally, we introduce models of perceptual and action noise, along with a
mutation matrix governing the probabilistic evolution of agent strategies. Our
empirical results demonstrate that cooperation is significantly affected by
agents' mobility and their spatial locality on the game board. These findings
highlight the importance of distinguishing between entirely random multi-agent
systems and those in which agents are more likely to interact with their
nearest neighbors.

</details>


### [114] [CoCre-Sam (Kokkuri-san): Modeling Ouija Board as Collective Langevin Dynamics Sampling from Fused Language Models](https://arxiv.org/abs/2507.11906)
*Tadahiro Taniguchi,Masatoshi Nagano,Haruumi Omoto,Yoshiki Hayashi*

Main category: cs.MA

TL;DR: CoCre-Sam框架通过集体Langevin动力学模拟人类集体活动中的语言融合现象，将个体隐式语言知识融合为集体输出。


<details>
  <summary>Details</summary>
Motivation: 研究集体活动中（如Ouija板）如何通过分散的隐式语言知识融合产生有意义的语言输出。

Method: 提出CoCre-Sam框架，将参与者建模为基于能量景观的代理，通过Langevin动力学模拟集体采样过程。

Result: 理论证明和仿真验证表明，CoCre-Sam能有效融合不同语言模型并生成有意义的字符序列。

Conclusion: CoCre-Sam为个体隐式知识、集体行动和涌现语言现象提供了计算机制，基于概率采样原则。

Abstract: Collective human activities like using an Ouija board (or Kokkuri-san) often
produce emergent, coherent linguistic outputs unintended by any single
participant. While psychological explanations such as the ideomotor effect
exist, a computational understanding of how decentralized, implicit linguistic
knowledge fuses through shared physical interaction remains elusive. We
introduce CoCre-Sam (Collective-Creature Sampling), a framework modeling this
phenomenon as collective Langevin dynamics sampling from implicitly fused
language models. Each participant is represented as an agent associated with an
energy landscape derived from an internal language model reflecting linguistic
priors, and agents exert stochastic forces based on local energy gradients. We
theoretically prove that the collective motion of the shared pointer
(planchette) corresponds to Langevin MCMC sampling from the sum of individual
energy landscapes, representing fused collective knowledge. Simulations
validate that CoCre-Sam dynamics effectively fuse different models and generate
meaningful character sequences, while ablation studies confirm the essential
roles of collective interaction and stochasticity. Altogether, CoCre-Sam
provides a novel computational mechanism linking individual implicit knowledge,
embodied collective action, and emergent linguistic phenomena, grounding these
complex interactions in the principles of probabilistic sampling.

</details>


### [115] [Modeling Feasible Locomotion of Nanobots for Cancer Detection and Treatment](https://arxiv.org/abs/2507.12400)
*Noble Harasha,Cristina Gava,Nancy Lynch,Claudia Contini,Frederik Mallmann-Trenn*

Main category: cs.MA

TL;DR: 论文提出了一种纳米机器人在人体内定位和治疗癌症的模型，包括静态和动态化学梯度两种变体，展示了其在速度和效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 利用纳米机器人提高药物递送的选择性并减少副作用，解决纳米尺度下个体能力受限的问题。

Method: 提出了一种基于化学梯度的纳米机器人运动模型，包括静态和动态梯度两种变体，分别通过模拟和分析验证其性能。

Result: 静态梯度模型通过模拟和分析验证了其有效性；动态梯度模型通过化学信号放大机制显著提高了性能。

Conclusion: 动态梯度模型在性能上优于静态梯度模型，展示了纳米机器人在癌症治疗中的潜力。

Abstract: Deploying motile nanosized particles, also known as ``nanobots'', in the
human body promises to improve selectivity in drug delivery and reduce side
effects. We consider a swarm of nanobots locating a single cancerous region and
treating it by releasing an onboard payload of drugs at the site. At nanoscale,
the computation, communication, sensing, and locomotion capabilities of
individual agents are extremely limited, noisy, and/or nonexistent.
  We present a general model to formally describe the individual and collective
behavior of agents in a colloidal environment, such as the bloodstream, for
cancer detection and treatment by nanobots. This includes a feasible and
precise model of agent locomotion, inspired by actual nanoparticles that, in
the presence of an external chemical gradient, move towards areas of higher
concentration by means of self-propulsion. We present two variants of our
general model: The first assumes an endogenous chemical gradient that is fixed
over time and centered at the targeted cancer site; the second is a more
speculative and dynamic variant in which agents themselves create and amplify a
chemical gradient centered at the cancer site. In both settings, agents can
sense the gradient and ascend it noisily, locating the cancer site more quickly
than via simple Brownian motion.
  For the first variant of the model, we present simulation results to show the
behavior of agents under our locomotion model, as well as {analytical results}
to bound the time it takes for the agents to reach the cancer site. For the
second variant, simulation results highlight the collective benefit in having
agents issue their own chemical signal. While arguably more speculative in its
agent capability assumptions, this variant shows a significant improvement in
runtime performance over the first variant, resulting from its chemical signal
amplification mechanism.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [116] [Neuroaesthetics and the Science of Visual Experience](https://arxiv.org/abs/2507.11599)
*Harish Vijayakumar*

Main category: cs.HC

TL;DR: 本文概述了神经美学的核心原理，探讨了大脑如何感知美及其在设计中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究神经美学旨在揭示大脑如何构建美的体验，并探索其在设计领域的实际应用。

Method: 通过分析感知、情感和认知的相互作用，研究神经机制如何影响审美体验。

Result: 研究发现，精心设计的视觉体验不仅能吸引人，还能在情感和认知层面与人产生深刻连接。

Conclusion: 神经美学的研究表明，美的体验不仅仅是表面的吸引力，而是能够通过设计实现更深层次的人际连接。

Abstract: Neuroaesthetics is an interdisciplinary field that brings together
neuroscience, psychology, and the arts to explore how the human brain perceives
and responds to visual beauty. This paper examines the neural mechanisms behind
aesthetic experiences, aiming to explain why certain designs or artworks feel
emotionally or cognitively "right." By analyzing the interaction between
perception, emotion, and cognition, neuroaesthetics reveals how beauty is
constructed in the brain and how this understanding can inform fields such as
graphic and interface design. This paper offers a clear and accessible overview
of core neuroaesthetic principles, making the subject approachable to a wide
audience. The findings suggest that impactful design is more than surface-level
appeal: well-crafted visual experiences can engage, support, and connect people
in meaningful ways.

</details>


### [117] [DiaryPlay: AI-Assisted Authoring of Interactive Vignettes for Everyday Storytelling](https://arxiv.org/abs/2507.11628)
*Jiangnan Xu,Haeseul Cha,Gosu Choi,Gyu-cheol Lee,Yeo-Jin Yoon,Zucheul Lee,Konstantinos Papangelis,Dae Hyun Kim,Juho Kim*

Main category: cs.HC

TL;DR: DiaryPlay是一个AI辅助的交互式小故事创作系统，通过自然语言输入简化创作流程，利用LLM生成分支叙事结构。


<details>
  <summary>Details</summary>
Motivation: 解决日常故事讲述中交互式小故事创作复杂性的问题。

Method: 系统从自然语言故事中提取核心元素（环境、角色、事件），并利用LLM自动生成分支叙事结构。

Result: 技术评估显示生成的角色活动可信度与人工创作相当；用户研究表明系统能有效支持创作并保持作者意图。

Conclusion: DiaryPlay为日常故事讲述者提供了一种简单高效的交互式小故事创作工具。

Abstract: An interactive vignette is a popular and immersive visual storytelling
approach that invites viewers to role-play a character and influences the
narrative in an interactive environment. However, it has not been widely used
by everyday storytellers yet due to authoring complexity, which conflicts with
the immediacy of everyday storytelling. We introduce DiaryPlay, an AI-assisted
authoring system for interactive vignette creation in everyday storytelling. It
takes a natural language story as input and extracts the three core elements of
an interactive vignette (environment, characters, and events), enabling authors
to focus on refining these elements instead of constructing them from scratch.
Then, it automatically transforms the single-branch story input into a
branch-and-bottleneck structure using an LLM-powered narrative planner, which
enables flexible viewer interactions while freeing the author from
multi-branching. A technical evaluation (N=16) shows that DiaryPlay-generated
character activities are on par with human-authored ones regarding
believability. A user study (N=16) shows that DiaryPlay effectively supports
authors in creating interactive vignette elements, maintains authorial intent
while reacting to viewer interactions, and provides engaging viewing
experiences.

</details>


### [118] [CLAImate: AI-Enabled Climate Change Communication through Personalized and Localized Narrative Visualizations](https://arxiv.org/abs/2507.11677)
*Mashrur Rashik,Jean-Daniel Fekete,Narges Mahyar*

Main category: cs.HC

TL;DR: CLAImate是一个AI驱动的原型工具，通过个性化对话叙事和本地化可视化，提升公众对气候变化的认知和理解。


<details>
  <summary>Details</summary>
Motivation: 气候变化报告通常过于抽象或技术化，难以引起公众共鸣，因此需要更个性化的沟通工具。

Method: 开发CLAImate原型，结合用户的气候知识和地理位置，个性化叙事和可视化，并通过内部验证、专家研究和用户试点进行评估。

Result: CLAImate在SNLI准确率达到66%，FACTSCORE为70%，专家认可其清晰度和个性化，70%的英国参与者表示对气候风险的理解和本地相关性有所提升。

Conclusion: CLAImate展示了在个性化气候沟通中的潜力，但也面临个性化、准确性和可扩展性等设计挑战，未来需进一步优化。

Abstract: Communicating climate change remains challenging, as climate reports, though
rich in data and visualizations, often feel too abstract or technical for the
public. Although personalization can enhance communication, most tools still
lack the narrative and visualization tailoring needed to connect with
individual experiences. We present CLAImate, an AI-enabled prototype that
personalizes conversation narratives and localizes visualizations based on
users' climate knowledge and geographic location. We evaluated CLAImate through
internal verification of factual correctness, a formative study with experts,
and a pilot with UK residents. CLAImate achieved 66% SNLI accuracy and 70%
FACTSCORE. Visualization experts appreciated its clarity and personalization,
and seven out of ten UK participants reported better understanding and local
relevance of climate risks with CLAImate. We also discuss design challenges in
personalization, accuracy, and scalability, and outline future directions for
integrating visualizations in personalized conversational interfaces.

</details>


### [119] [GIST: Group Interaction Sensing Toolkit for Mixed Reality](https://arxiv.org/abs/2507.11797)
*Diana Romero,Yasra Chandio,Fatima Anwar,Salma Elmalaki*

Main category: cs.HC

TL;DR: 论文提出了一种名为GIST的工具包，用于在混合现实环境中被动捕获多模态交互数据（如语音、凝视和空间接近度），并自动生成静态交互网络和动态行为模式。通过48名参与者的实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部摄像头或仅关注单一模态，限制了其有效性和适用性。研究旨在设计一种能在MR环境中实时捕获多模态交互数据的系统。

Method: 开发了GIST工具包，利用MR头显的传感器被动捕获语音、凝视和空间接近度数据，并自动分析静态和动态交互模式。

Result: 实验表明，GIST能有效识别行为模式与交互网络结构的变化，验证了传感器数据的可用性。

Conclusion: GIST为MR环境中的团队协作研究提供了新的工具，支持实时多模态交互数据的捕获与分析。

Abstract: Understanding how teams coordinate, share work, and negotiate roles in
immersive environments is critical for designing effective mixed-reality (MR)
applications that support real-time collaboration. However, existing methods
either rely on external cameras and offline annotation or focus narrowly on
single modalities, limiting their validity and applicability. To address this,
we present a novel group interaction sensing toolkit (GIST), a deployable
system that passively captures multi-modal interaction data, such as speech,
gaze, and spatial proximity from commodity MR headset's sensors and
automatically derives both overall static interaction networks and dynamic
moment-by-moment behavior patterns. We evaluate GIST with a human subject study
with 48 participants across 12 four-person groups performing an open-ended
image-sorting task in MR. Our analysis shows strong alignment between the
identified behavior modes and shifts in interaction network structure,
confirming that momentary changes in speech, gaze, and proximity data are
observable through the sensor data.

</details>


### [120] ["Mapping What I Feel": Understanding Affective Geovisualization Design Through the Lens of People-Place Relationships](https://arxiv.org/abs/2507.11841)
*Xingyu Lan,Yutong Yang,Yifan Wang*

Main category: cs.HC

TL;DR: 本文通过分析情感地理可视化设计，提出了基于地理理论的PPP模型的设计分类法，并识别了四种高级设计范式，为情感可视化设计提供了领域特定的见解。


<details>
  <summary>Details</summary>
Motivation: 情感可视化设计是一个新兴但高度跨学科的研究方向，需要更细粒度的分析。本文选择情感地理可视化设计这一相对成熟的子领域，以推动研究并提供领域特定见解。

Method: 通过使用地理理论中的PPP模型分析精选的情感地理可视化设计语料库，提出了设计分类法，并识别了四种高级设计范式。

Result: 提出了情感地理可视化设计的设计分类法，并识别了四种高级设计范式（如计算性、拟人化），为领域提供了具体的设计示例和分析。

Conclusion: 通过扩展现有情感可视化设计框架，本文为这一创新领域的研究和实践提供了指导，并推动了未来探索。

Abstract: Affective visualization design is an emerging research direction focused on
communicating and influencing emotion through visualization. However, as
revealed by previous research, this area is highly interdisciplinary and
involves theories and practices from diverse fields and disciplines, thus
awaiting analysis from more fine-grained angles. To address this need, this
work focuses on a pioneering and relatively mature sub-area, affective
geovisualization design, to further the research in this direction and provide
more domain-specific insights. Through an analysis of a curated corpus of
affective geovisualization designs using the Person-Process-Place (PPP) model
from geographic theory, we derived a design taxonomy that characterizes a
variety of methods for eliciting and enhancing emotions through geographic
visualization. We also identified four underlying high-level design paradigms
of affective geovisualization design (e.g., computational, anthropomorphic)
that guide distinct approaches to linking geographic information with human
experience. By extending existing affective visualization design frameworks
with geographic specificity, we provide additional design examples,
domain-specific analyses, and insights to guide future research and practices
in this underexplored yet highly innovative domain.

</details>


### [121] [Interactive Hybrid Rice Breeding with Parametric Dual Projection](https://arxiv.org/abs/2507.11848)
*Changjian Chen,Pengcheng Wang,Fei Lyu,Zhuo Tang,Li Yang,Long Wang,Yong Cai,Feng Yu,Kenli Li*

Main category: cs.HC

TL;DR: 本文提出了一种视觉分析方法，通过参数化双投影方法促进交互式杂交水稻育种，帮助识别调控基因和选择杂交种。


<details>
  <summary>Details</summary>
Motivation: 基因组预测模型准确性有限，育种者仍需结合经验识别调控基因和选择杂交种，过程耗时。

Method: 开发参数化双投影方法，支持交互式双分析，并进一步开发基因和杂交种可视化工具。

Result: 通过案例研究定量评估，验证了方法的有效性，包括调控基因和理想杂交种的识别，并获得育种者积极反馈。

Conclusion: 该方法显著简化了杂交水稻育种过程，提高了效率和准确性。

Abstract: Hybrid rice breeding crossbreeds different rice lines and cultivates the
resulting hybrids in fields to select those with desirable agronomic traits,
such as higher yields. Recently, genomic selection has emerged as an efficient
way for hybrid rice breeding. It predicts the traits of hybrids based on their
genes, which helps exclude many undesired hybrids, largely reducing the
workload of field cultivation. However, due to the limited accuracy of genomic
prediction models, breeders still need to combine their experience with the
models to identify regulatory genes that control traits and select hybrids,
which remains a time-consuming process. To ease this process, in this paper, we
proposed a visual analysis method to facilitate interactive hybrid rice
breeding. Regulatory gene identification and hybrid selection naturally
ensemble a dual-analysis task. Therefore, we developed a parametric dual
projection method with theoretical guarantees to facilitate interactive dual
analysis. Based on this dual projection method, we further developed a gene
visualization and a hybrid visualization to verify the identified regulatory
genes and hybrids. The effectiveness of our method is demonstrated through the
quantitative evaluation of the parametric dual projection method, identified
regulatory genes and desired hybrids in the case study, and positive feedback
from breeders.

</details>


### [122] [Unveiling the Visual Rhetoric of Persuasive Cartography: A Case Study of the Design of Octopus Maps](https://arxiv.org/abs/2507.11903)
*Daocheng Lin,Yifan Wang,Yutong Yang,Xingyu Lan*

Main category: cs.HC

TL;DR: 论文探讨了数据可视化作为说服工具的潜力，聚焦于章鱼地图的修辞构造，揭示了其跨世纪的社会影响和设计策略。


<details>
  <summary>Details</summary>
Motivation: 填补当前可视化研究中修辞构造视角的不足，探索章鱼地图作为说服工具的设计机制。

Method: 采用修辞模式理论，收集并分析了90个从19世纪至今的章鱼地图，研究其视觉隐喻和修辞策略。

Result: 发现章鱼地图在现代仍具影响力，揭示了其跨文化的动态修辞特点，并探讨了相关伦理问题。

Conclusion: 章鱼地图展示了修辞构造在说服性可视化中的重要性，同时提醒设计者关注伦理问题。

Abstract: When designed deliberately, data visualizations can become powerful
persuasive tools, influencing viewers' opinions, values, and actions. While
researchers have begun studying this issue (e.g., to evaluate the effects of
persuasive visualization), we argue that a fundamental mechanism of persuasion
resides in rhetorical construction, a perspective inadequately addressed in
current visualization research. To fill this gap, we present a focused analysis
of octopus maps, a visual genre that has maintained persuasive power across
centuries and achieved significant social impact. Employing rhetorical schema
theory, we collected and analyzed 90 octopus maps spanning from the 19th
century to contemporary times. We closely examined how octopus maps implement
their persuasive intents and constructed a design space that reveals how visual
metaphors are strategically constructed and what common rhetorical strategies
are applied to components such as maps, octopus imagery, and text. Through the
above analysis, we also uncover a set of interesting findings. For instance,
contrary to the common perception that octopus maps are primarily a historical
phenomenon, our research shows that they remain a lively design convention in
today's digital age. Additionally, while most octopus maps stem from Western
discourse that views the octopus as an evil symbol, some designs offer
alternative interpretations, highlighting the dynamic nature of rhetoric across
different sociocultural settings. Lastly, drawing from the lessons provided by
octopus maps, we discuss the associated ethical concerns of persuasive
visualization.

</details>


### [123] [AFPM: Alignment-based Frame Patch Modeling for Cross-Dataset EEG Decoding](https://arxiv.org/abs/2507.11911)
*Xiaoqing Chen,Siyang Li,Dongrui Wu*

Main category: cs.HC

TL;DR: 提出了一种无需校准的跨数据集EEG解码框架AFPM，通过空间对齐和帧-块编码提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决EEG解码模型在跨数据集学习和泛化中的问题，如通道布局不一致、信号分布非平稳性及缺乏神经生理学先验整合。

Method: AFPM框架包含空间对齐（选择任务相关通道、对齐分布、统一布局）和帧-块编码（统一时空块建模）。

Result: 在运动想象和事件相关电位任务上分别提升4.40%和3.58%，优于17种现有方法。

Conclusion: AFPM是首个无需校准的跨数据集EEG解码框架，显著提升了BCI的实际应用性。

Abstract: Electroencephalogram (EEG) decoding models for brain-computer interfaces
(BCIs) struggle with cross-dataset learning and generalization due to channel
layout inconsistencies, non-stationary signal distributions, and limited
neurophysiological prior integration. To address these issues, we propose a
plug-and-play Alignment-Based Frame-Patch Modeling (AFPM) framework, which has
two main components: 1) Spatial Alignment, which selects task-relevant channels
based on brain-region priors, aligns EEG distributions across domains, and
remaps the selected channels to a unified layout; and, 2) Frame-Patch Encoding,
which models multi-dataset signals into unified spatiotemporal patches for EEG
decoding. Compared to 17 state-of-the-art approaches that need dataset-specific
tuning, the proposed calibration-free AFPM achieves performance gains of up to
4.40% on motor imagery and 3.58% on event-related potential tasks. To our
knowledge, this is the first calibration-free cross-dataset EEG decoding
framework, substantially enhancing the practicalness of BCIs in real-world
applications.

</details>


### [124] [d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement](https://arxiv.org/abs/2507.11960)
*Hyein Hong,Sangbong Yoo,SeokHwan Choi,Jisue Kim,Seongbum Seo,Haneol Cho,Chansoo Kim,Yun Jang*

Main category: cs.HC

TL;DR: 论文提出了一种名为d-DQIVAR的可视化分析系统，结合数据驱动和流程驱动方法，旨在提升数据质量（DQ）以优化机器学习模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于数据预处理而非真正的数据质量改进（DQI），且传统批处理数据预处理方法常导致数据特征失真，影响模型性能。

Method: 系统整合了数据驱动（如填补、异常检测、特征选择）和流程驱动（如DQ评估、Kolmogorov-Smirnov测试）技术，通过可视化分析支持DQI策略。

Result: 通过案例研究、评估和用户研究，展示了系统如何有效结合专家与领域知识，提升ML模型性能。

Conclusion: d-DQIVAR系统为数据质量改进提供了实用工具，弥补了现有研究的不足，优化了机器学习模型的性能。

Abstract: Approaches to enhancing data quality (DQ) are classified into two main
categories: data- and process-driven. However, prior research has predominantly
utilized batch data preprocessing within the data-driven framework, which often
proves insufficient for optimizing machine learning (ML) model performance and
frequently leads to distortions in data characteristics. Existing studies have
primarily focused on data preprocessing rather than genuine data quality
improvement (DQI). In this paper, we introduce d-DQIVAR, a novel visual
analytics system designed to facilitate DQI strategies aimed at improving ML
model performance. Our system integrates visual analytics techniques that
leverage both data-driven and process-driven approaches. Data-driven techniques
tackle DQ issues such as imputation, outlier detection, deletion, format
standardization, removal of duplicate records, and feature selection.
Process-driven strategies encompass evaluating DQ and DQI procedures by
considering DQ dimensions and ML model performance and applying the
Kolmogorov-Smirnov test. We illustrate how our system empowers users to harness
expert and domain knowledge effectively within a practical workflow through
case studies, evaluations, and user studies.

</details>


### [125] [Dataset-Adaptive Dimensionality Reduction](https://arxiv.org/abs/2507.11984)
*Hyeon Jeon,Jeongin Park,Soohyun Lee,Dae Hyun Kim,Sungbok Shin,Jinwook Seo*

Main category: cs.HC

TL;DR: 提出了一种基于结构复杂性度量的数据集自适应降维优化方法，显著提高了降维效率且不损失精度。


<details>
  <summary>Details</summary>
Motivation: 传统降维技术选择和超参数优化依赖试错，计算开销大，需一种更高效的方法。

Method: 利用结构复杂性度量量化数据集内在复杂性，预测降维技术的最大可达到精度，避免冗余优化。

Result: 验证了度量能有效近似数据集真实复杂性，并显著提升降维优化效率。

Conclusion: 数据集自适应降维方法高效且准确，适用于实际应用。

Abstract: Selecting the appropriate dimensionality reduction (DR) technique and
determining its optimal hyperparameter settings that maximize the accuracy of
the output projections typically involves extensive trial and error, often
resulting in unnecessary computational overhead. To address this challenge, we
propose a dataset-adaptive approach to DR optimization guided by structural
complexity metrics. These metrics quantify the intrinsic complexity of a
dataset, predicting whether higher-dimensional spaces are necessary to
represent it accurately. Since complex datasets are often inaccurately
represented in two-dimensional projections, leveraging these metrics enables us
to predict the maximum achievable accuracy of DR techniques for a given
dataset, eliminating redundant trials in optimizing DR. We introduce the design
and theoretical foundations of these structural complexity metrics. We
quantitatively verify that our metrics effectively approximate the ground truth
complexity of datasets and confirm their suitability for guiding
dataset-adaptive DR workflow. Finally, we empirically show that our
dataset-adaptive workflow significantly enhances the efficiency of DR
optimization without compromising accuracy.

</details>


### [126] [Envisage: Towards Expressive Visual Graph Querying](https://arxiv.org/abs/2507.11999)
*Xiaolin Wen,Qishuang Fu,Shuangyue Han,Yichen Guo,Joseph K. Liu,Yong Wang*

Main category: cs.HC

TL;DR: Envisage是一个交互式视觉图查询系统，通过支持直观的图结构构建和灵活的规则规范，提升复杂查询场景中的表达能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉图查询工具仅支持简单查询，限制了用户表达复杂或模糊查询意图的能力。

Method: Envisage分为四个阶段：查询表达、查询验证、渐进查询执行和结果分析。

Result: 案例研究和用户访谈表明Envisage在构建、验证和执行复杂图查询方面有效且易用。

Conclusion: Envisage通过交互式设计提升了视觉图查询的表达能力和用户体验。

Abstract: Graph querying is the process of retrieving information from graph data using
specialized languages (e.g., Cypher), often requiring programming expertise.
Visual Graph Querying (VGQ) streamlines this process by enabling users to
construct and execute queries via an interactive interface without resorting to
complex coding. However, current VGQ tools only allow users to construct simple
and specific query graphs, limiting users' ability to interactively express
their query intent, especially for underspecified query intent. To address
these limitations, we propose Envisage, an interactive visual graph querying
system to enhance the expressiveness of VGQ in complex query scenarios by
supporting intuitive graph structure construction and flexible parameterized
rule specification. Specifically, Envisage comprises four stages: Query
Expression allows users to interactively construct graph queries through
intuitive operations; Query Verification enables the validation of constructed
queries via rule verification and query instantiation; Progressive Query
Execution can progressively execute queries to ensure meaningful querying
results; and Result Analysis facilitates result exploration and interpretation.
To evaluate Envisage, we conducted two case studies and in-depth user
interviews with 14 graph analysts. The results demonstrate its effectiveness
and usability in constructing, verifying, and executing complex graph queries.

</details>


### [127] [Tao-Technology for Teen Mobile Use: Harmonizing Adaptation, Autonomy, and Reflection](https://arxiv.org/abs/2507.12204)
*Pengyu Zhu,Janghee Cho*

Main category: cs.HC

TL;DR: 提出Tao-Technology框架，基于道家哲学（无为、阴阳、自然），通过动态自适应调节青少年移动技术使用，取代僵化控制。


<details>
  <summary>Details</summary>
Motivation: 现有青少年移动技术使用管控机制过于僵化，忽视其自主性和自然使用模式，需更灵活的调节方式。

Method: 结合道家哲学（无为、阴阳、自然）、反思信息学与信息生态学，设计动态自适应调节框架Tao-Technology。

Result: Tao-Technology能动态适应情境，促进自我反思与意义构建，实现技术与青少年的协同适应调节。

Conclusion: Tao-Technology提供了一种灵活且结构化的技术治理方式，帮助青少年建立平衡、有意识的数字技术关系。

Abstract: Adolescents' mobile technology use is often regulated through rigid control
mechanisms that fail to account for their autonomy and natural usage patterns.
Drawing on Taoist philosophy, particularly Wu Wei, Yin-Yang, and Zi Ran, this
position paper proposes Tao-Technology, a self-organizing, adaptive regulatory
framework. Integrating insights from Reflective Informatics and Information
Ecologies, we explore how mobile technology can dynamically adjust to context
while fostering self-reflection and meaning-making. This approach shifts from
external restrictions to dynamic co-adaptative regulation, ensuring technology
governance remains flexible yet structured, supporting adolescents in
cultivating a balanced and intentional relationship with digital technology.

</details>


### [128] [Draw an Ugly Person An Exploration of Generative AIs Perceptions of Ugliness](https://arxiv.org/abs/2507.12212)
*Garyoung Kim,Huisung Kwon,Seoju Yun,Yu-Won Youn*

Main category: cs.HC

TL;DR: 生成式AI不仅复制人类创造力，还再现了根深蒂固的文化偏见。本研究探讨了四种AI模型如何理解和表达“丑陋”，揭示了其中嵌入的偏见。


<details>
  <summary>Details</summary>
Motivation: 批判性分析生成式AI如何理解和表达“丑陋”，以揭示其潜在的偏见问题。

Method: 通过迭代提示提取13个与“丑陋”相关的形容词，生成624张图像，并对图像中的人口和社会经济属性进行编码和主题分析。

Result: AI模型倾向于将“丑陋”与老年白人男性形象关联，反映了社会偏见和矛盾偏见。定性分析显示，传统物理标记（如不对称和衰老）仍是核心视觉主题。

Conclusion: 尽管试图创造更平等的表征，生成式AI仍延续了继承性和矛盾性偏见，凸显了开发伦理AI训练范式和包容性AI方法的重要性。

Abstract: Generative AI does not only replicate human creativity but also reproduces
deep-seated cultural biases, making it crucial to critically examine how
concepts like ugliness are understood and expressed by these tools. This study
investigates how four different generative AI models understand and express
ugliness through text and image and explores the biases embedded within these
representations. We extracted 13 adjectives associated with ugliness through
iterative prompting of a large language model and generated 624 images across
four AI models and three prompts. Demographic and socioeconomic attributes
within the images were independently coded and thematically analyzed. Our
findings show that AI models disproportionately associate ugliness with old
white male figures, reflecting entrenched social biases as well as paradoxical
biases, where efforts to avoid stereotypical depictions of marginalized groups
inadvertently result in the disproportionate projection of negative attributes
onto majority groups. Qualitative analysis further reveals that, despite
supposed attempts to frame ugliness within social contexts, conventional
physical markers such as asymmetry and aging persist as central visual motifs.
These findings demonstrate that despite attempts to create more equal
representations, generative AI continues to perpetuate inherited and
paradoxical biases, underscoring the critical work being done to create ethical
AI training paradigms and advance methodologies for more inclusive AI
development.

</details>


### [129] [Humans are more gullible than LLMs in believing common psychological myths](https://arxiv.org/abs/2507.12296)
*Bevan Koopman,Guido Zuccon*

Main category: cs.HC

TL;DR: 研究发现，尽管大型语言模型（LLMs）对心理神话的相信程度显著低于人类，但用户提示仍会影响其回答。检索增强生成（RAG）能有效减少神话相信，并揭示LLMs潜在的纠偏能力。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否模仿人类对心理神话的相信行为，并寻找减少这种倾向的方法。

Method: 使用50个流行心理神话，评估不同提示策略下LLMs的相信程度，包括检索增强生成和引导提示。

Result: LLMs的相信率显著低于人类，但用户提示会影响回答；RAG能有效减少神话相信。

Conclusion: 研究为机器心理学领域提供见解，并展示认知科学方法如何指导LLMs的评估与开发。

Abstract: Despite widespread debunking, many psychological myths remain deeply
entrenched. This paper investigates whether Large Language Models (LLMs) mimic
human behaviour of myth belief and explores methods to mitigate such
tendencies. Using 50 popular psychological myths, we evaluate myth belief
across multiple LLMs under different prompting strategies, including
retrieval-augmented generation and swaying prompts. Results show that LLMs
exhibit significantly lower myth belief rates than humans, though user
prompting can influence responses. RAG proves effective in reducing myth belief
and reveals latent debiasing potential within LLMs. Our findings contribute to
the emerging field of Machine Psychology and highlight how cognitive science
methods can inform the evaluation and development of LLM-based systems.

</details>


### [130] [TrialCompass: Visual Analytics for Enhancing the Eligibility Criteria Design of Clinical Trials](https://arxiv.org/abs/2507.12298)
*Rui Sheng,Xingbo Wang,Jiachen Wang,Xiaofu Jin,Zhonghua Sheng,Zhenxing Xu,Suraj Rajendran,Huamin Qu,Fei Wang*

Main category: cs.HC

TL;DR: TrialCompass是一个可视化分析系统，支持临床医生通过知识驱动和结果驱动方法迭代探索临床试验的资格标准。


<details>
  <summary>Details</summary>
Motivation: 当前设计资格标准的方法存在局限性，无法支持交互式探索大量标准，且忽略了从原始电子健康记录（EHR）数据中提取详细特征。

Method: 提出TrialCompass系统，结合知识驱动和结果驱动方法，支持历史追踪以帮助临床医生理解资格标准对结果的影响。

Result: 通过真实数据集验证，TrialCompass在设计和优化脓毒症休克和脓毒症相关急性肾损伤的资格标准方面有效。

Conclusion: TrialCompass为临床试验提供了系统化的资格标准优化工具，并展望了可视化分析在临床研究中的应用前景。

Abstract: Eligibility criteria play a critical role in clinical trials by determining
the target patient population, which significantly influences the outcomes of
medical interventions. However, current approaches for designing eligibility
criteria have limitations to support interactive exploration of the large space
of eligibility criteria. They also ignore incorporating detailed
characteristics from the original electronic health record (EHR) data for
criteria refinement. To address these limitations, we proposed TrialCompass, a
visual analytics system integrating a novel workflow, which can empower
clinicians to iteratively explore the vast space of eligibility criteria
through knowledge-driven and outcome-driven approaches. TrialCompass supports
history-tracking to help clinicians trace the evolution of their adjustments
and decisions when exploring various forms of data (i.e., eligibility criteria,
outcome metrics, and detailed characteristics of original EHR data) through
these two approaches. This feature can help clinicians comprehend the impact of
eligibility criteria on outcome metrics and patient characteristics, which
facilitates systematic refinement of eligibility criteria. Using a real-world
dataset, we demonstrated the effectiveness of TrialCompass in providing
insights into designing eligibility criteria for septic shock and
sepsis-associated acute kidney injury. We also discussed the research prospects
of applying visual analytics to clinical trials.

</details>


### [131] [An Analysis of Text Functions in Information Visualization](https://arxiv.org/abs/2507.12334)
*Chase Stokes,Anjana Arunkumar,Marti A. Hearst,Lace Padilla*

Main category: cs.HC

TL;DR: 本文提出了一个理解信息可视化中文本功能的框架，填补了现有分类的空白。通过分析120个实际可视化案例和804个文本元素，识别了10种文本功能，并揭示了4种文本驱动的设计策略。


<details>
  <summary>Details</summary>
Motivation: 研究文本在可视化设计中的作用，填补现有分类的不足，探索文本功能的多样性。

Method: 分析120个真实可视化案例和804个文本元素，识别文本功能并进行因子分析。

Result: 发现10种文本功能和4种设计策略，揭示了文本的多功能性和灵活性。

Conclusion: 该框架丰富了现有研究，展示了文本在可视化中的多样性和重要性。

Abstract: Text is an integral but understudied component of visualization design.
Although recent studies have examined how text elements (e.g., titles and
annotations) influence comprehension, preferences, and predictions, many
questions remain about textual design and use in practice. This paper
introduces a framework for understanding text functions in information
visualizations, building on and filling gaps in prior classifications and
taxonomies. Through an analysis of 120 real-world visualizations and 804 text
elements, we identified ten distinct text functions, ranging from identifying
data mappings to presenting valenced subtext. We further identify patterns in
text usage and conduct a factor analysis, revealing four overarching
text-informed design strategies: Attribution and Variables, Annotation-Centric
Design, Visual Embellishments, and Narrative Framing. In addition to these
factors, we explore features of title rhetoric and text multifunctionality,
while also uncovering previously unexamined text functions, such as text
replacing visual elements. Our findings highlight the flexibility of text,
demonstrating how different text elements in a given design can combine to
communicate, synthesize, and frame visual information. This framework adds
important nuance and detail to existing frameworks that analyze the diverse
roles of text in visualization.

</details>


### [132] [MExplore: an entity-based visual analytics approach for medical expertise acquisition](https://arxiv.org/abs/2507.12337)
*Xiao Pang,Yan Huang,Chang Liu,JiYuan Liu,MingYou Liu*

Main category: cs.HC

TL;DR: MExplore是一个交互式可视化分析系统，用于从非结构化医学文本中提取医学实体并支持医学专业知识获取。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏从非结构化医学文本中提取专业知识的方法，这些文本在医学文献中占重要比例且提供更灵活的细节。

Method: 提出一个工作流程，使用微调的BERT模型提取医学实体，并结合多层次可视化分析框架。

Result: 通过案例研究、用户研究和专家访谈验证，MExplore显著提升了医学专业知识获取的效果。

Conclusion: MExplore为从医学文本中获取和保留知识提供了一种有效的交互式方法。

Abstract: Acquiring medical expertise is a critical component of medical education and
professional development. While existing studies focus primarily on
constructing medical knowledge bases or developing learning tools based on the
structured, private healthcare data, they often lack methods for extracting
expertise from unstructured medical texts. These texts constitute a significant
portion of medical literature and offer greater flexibility and detail compared
to structured data formats. Furthermore, many studies fail to provide explicit
analytical and learning pathways in this context.
  This paper introduces MExplore, an interactive visual analytics system
designed to support the acquisition of medical expertise. To address the
challenges of the inconsistencies and confidentiality concerns inherent in
unstructured medical texts, we propose a workflow that employs a fine-tuned
BERT-based model to extract medical entities (MEs) from them. We then present a
novel multilevel visual analysis framework that integrates multiple coordinated
visualizations, enabling a progressive and interactive exploration of medical
knowledge.
  To assess the effectiveness of MExplore, we conducted three case studies, a
user study, and interviews with domain experts. The results indicate that the
system significantly enhances the medical expertise acquisition process,
providing an effective interactive approach for acquiring and retaining
knowledge from medical texts.

</details>


### [133] [Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight](https://arxiv.org/abs/2507.12377)
*Ke Er Amy Zhang,Jodie Jenkinson,Laura Garrison*

Main category: cs.HC

TL;DR: 通过对17位全球视觉数据记者的访谈进行解构性分析，揭示了两组对立信念（客观性/主观性、人文主义/机制主义），并通过谱系分析展示了这些信念的社会历史背景。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉数据新闻中隐含的信念及其社会历史根源，以批判性理论重新定义视觉数据叙事的“成功”。

Method: 采用文学批评中的解构方法分析访谈内容，结合谱系分析揭示信念的历史背景。

Result: 发现视觉数据新闻中的信念受外部社会力量和范式变迁影响，非孤立存在。

Conclusion: 批判性理论（如解构与谱系分析）能丰富可视化研究，重新审视数据化与可视化的社会技术问题。

Abstract: We conduct a deconstructive reading of a qualitative interview study with 17
visual data journalists from newsrooms across the globe. We borrow a
deconstruction approach from literary critique to explore the instability of
meaning in language and reveal implicit beliefs in words and ideas. Through our
analysis we surface two sets of opposing implicit beliefs in visual data
journalism: objectivity/subjectivity and humanism/mechanism. We contextualize
these beliefs through a genealogical analysis, which brings deconstruction
theory into practice by providing a historic backdrop for these opposing
perspectives. Our analysis shows that these beliefs held within visual data
journalism are not self-enclosed but rather a product of external societal
forces and paradigm shifts over time. Through this work, we demonstrate how
thinking with critical theories such as deconstruction and genealogy can
reframe "success" in visual data storytelling and diversify visualization
research outcomes. These efforts push the ways in which we as researchers
produce domain knowledge to examine the sociotechnical issues of today's values
towards datafication and data visualization.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [134] [HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways](https://arxiv.org/abs/2507.11621)
*Tianyi Wang,Yangyang Wang,Jie Pan,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 论文提出了一种分层协作的匝道合并控制框架（HCOMC），用于解决混合交通流中的匝道合并问题，结合了纵向跟车和横向换道模型，并通过仿真验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道合并区域是交通拥堵和事故的常见瓶颈，而基于联网自动驾驶车辆（CAVs）的协作控制策略是根本解决方案。在CAV尚未普及的情况下，需要为混合交通流提出一种分层协作控制框架。

Method: 扩展了基于智能驾驶员模型的纵向跟车模型和基于五次多项式曲线的横向换道模型，提出了HCOMC框架，包括分层协作规划模型、基于博弈论的可选换道模型和多目标优化模型。

Result: 仿真结果表明，HCOMC在提升车辆群安全性、稳定和加速合并过程、优化交通效率和节省燃油消耗方面具有显著优势。

Conclusion: HCOMC框架为混合交通流中的匝道合并问题提供了有效的解决方案，具有广泛的应用前景。

Abstract: Highway on-ramp merging areas are common bottlenecks to traffic congestion
and accidents. Currently, a cooperative control strategy based on connected and
automated vehicles (CAVs) is a fundamental solution to this problem. While CAVs
are not fully widespread, it is necessary to propose a hierarchical cooperative
on-ramp merging control (HCOMC) framework for heterogeneous traffic flow on
two-lane highways to address this gap. This paper extends longitudinal
car-following models based on the intelligent driver model and lateral
lane-changing models using the quintic polynomial curve to account for
human-driven vehicles (HDVs) and CAVs, comprehensively considering human
factors and cooperative adaptive cruise control. Besides, this paper proposes a
HCOMC framework, consisting of a hierarchical cooperative planning model based
on the modified virtual vehicle model, a discretionary lane-changing model
based on game theory, and a multi-objective optimization model using the
elitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and
efficient merging process. Then, the performance of our HCOMC is analyzed under
different traffic densities and CAV penetration rates through simulation. The
findings underscore our HCOMC's pronounced comprehensive advantages in
enhancing the safety of group vehicles, stabilizing and expediting merging
process, optimizing traffic efficiency, and economizing fuel consumption
compared with benchmarks.

</details>


### [135] [A Roadmap for Climate-Relevant Robotics Research](https://arxiv.org/abs/2507.11623)
*Alan Papalia,Charles Dawson,Laurentiu L. Anton,Norhan Magdy Bayomi,Bianca Champenois,Jung-Hoon Cho,Levi Cai,Joseph DelPreto,Kristen Edwards,Bilha-Catherine Githinji,Cameron Hickert,Vindula Jayawardana,Matthew Kramer,Shreyaa Raghavan,David Russell,Shide Salimi,Jingnan Shi,Soumya Sudhakar,Yanwei Wang,Shouyi Wang,Luca Carlone,Vijay Kumar,Daniela Rus,John E. Fernandez,Cathy Wu,George Kantor,Derek Young,Hanumant Singh*

Main category: cs.RO

TL;DR: 本文提出了一个气候相关机器人研究的路线图，旨在通过机器人技术解决气候变化问题。


<details>
  <summary>Details</summary>
Motivation: 气候变化是21世纪的重要挑战，机器人社区希望通过技术贡献应对这一问题。

Method: 通过识别机器人技术与气候领域（如能源、建筑环境、交通等）的高影响力合作机会，提出具体应用方向。

Result: 提出了包括能源系统优化、精准农业、环境监测等具体应用，并强调机器人工具包的广泛适用性。

Conclusion: 本文旨在激发机器人社区的新研究方向，推动跨领域合作以应对气候问题。

Abstract: Climate change is one of the defining challenges of the 21st century, and
many in the robotics community are looking for ways to contribute. This paper
presents a roadmap for climate-relevant robotics research, identifying
high-impact opportunities for collaboration between roboticists and experts
across climate domains such as energy, the built environment, transportation,
industry, land use, and Earth sciences. These applications include problems
such as energy systems optimization, construction, precision agriculture,
building envelope retrofits, autonomous trucking, and large-scale environmental
monitoring. Critically, we include opportunities to apply not only physical
robots but also the broader robotics toolkit - including planning, perception,
control, and estimation algorithms - to climate-relevant problems. A central
goal of this roadmap is to inspire new research directions and collaboration by
highlighting specific, actionable problems at the intersection of robotics and
climate. This work represents a collaboration between robotics researchers and
domain experts in various climate disciplines, and it serves as an invitation
to the robotics community to bring their expertise to bear on urgent climate
priorities.

</details>


### [136] [CoNav Chair: Development and Evaluation of a Shared Control based Wheelchair for the Built Environment](https://arxiv.org/abs/2507.11716)
*Yifan Xu,Qianwei Wang,Jordan Lillie,Vineet Kamat,Carol Menassa,Clive D'Souza*

Main category: cs.RO

TL;DR: 本文介绍了CoNav Chair，一种基于ROS的智能轮椅，结合共享控制导航和避障功能，旨在提升导航效率、安全性和易用性。初步评估显示共享控制模式在碰撞次数、任务完成时间和用户体验上优于手动和全自动模式。


<details>
  <summary>Details</summary>
Motivation: 随着残疾人口增长，现有电动轮椅在灵活性和导航能力上存在局限，完全自主或手动控制模式可能影响效率和用户信任。

Method: 基于ROS设计CoNav Chair，比较手动、共享和全自动三种导航模式，通过21名健康参与者在室内环境中的测试进行评估。

Result: 共享控制模式碰撞更少，任务完成时间、轨迹长度和平滑度表现优异，用户主观评价认为其更安全和高效。

Conclusion: CoNav系统展现出良好的安全性和性能，为后续残疾用户测试奠定了基础。

Abstract: As the global population of people with disabilities (PWD) continues to grow,
so will the need for mobility solutions that promote independent living and
social integration. Wheelchairs are vital for the mobility of PWD in both
indoor and outdoor environments. The current SOTA in powered wheelchairs is
based on either manually controlled or fully autonomous modes of operation,
offering limited flexibility and often proving difficult to navigate in
spatially constrained environments. Moreover, research on robotic wheelchairs
has focused predominantly on complete autonomy or improved manual control;
approaches that can compromise efficiency and user trust. To overcome these
challenges, this paper introduces the CoNav Chair, a smart wheelchair based on
the Robot Operating System (ROS) and featuring shared control navigation and
obstacle avoidance capabilities that are intended to enhance navigational
efficiency, safety, and ease of use for the user. The paper outlines the CoNav
Chair's design and presents a preliminary usability evaluation comparing three
distinct navigation modes, namely, manual, shared, and fully autonomous,
conducted with 21 healthy, unimpaired participants traversing an indoor
building environment. Study findings indicated that the shared control
navigation framework had significantly fewer collisions and performed
comparably, if not superior to the autonomous and manual modes, on task
completion time, trajectory length, and smoothness; and was perceived as being
safer and more efficient based on user reported subjective assessments of
usability. Overall, the CoNav system demonstrated acceptable safety and
performance, laying the foundation for subsequent usability testing with end
users, namely, PWDs who rely on a powered wheelchair for mobility.

</details>


### [137] [Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies](https://arxiv.org/abs/2507.11770)
*Giang Nguyen,Mihai Pomarlan,Sascha Jongebloed,Nils Leusmann,Minh Nhat Vu,Michael Beetz*

Main category: cs.RO

TL;DR: 提出了一种将多种机器人场景描述格式统一为USD格式的方法，结合语义标注和知识图谱，提升机器人认知控制能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人领域中因数据格式多样性和不兼容性导致的环境数据整合难题。

Method: 开发统一的场景图模型，将MJCF、URDF和SDF等格式标准化为USD格式，并通过语义标注与知识图谱结合。

Result: 成功将3D环境转换为USD格式并生成知识图谱，支持实时机器人决策。

Conclusion: 该方法有效整合环境数据，为机器人认知控制提供了实用工具。

Abstract: In robotics, the effective integration of environmental data into actionable
knowledge remains a significant challenge due to the variety and
incompatibility of data formats commonly used in scene descriptions, such as
MJCF, URDF, and SDF. This paper presents a novel approach that addresses these
challenges by developing a unified scene graph model that standardizes these
varied formats into the Universal Scene Description (USD) format. This
standardization facilitates the integration of these scene graphs with robot
ontologies through semantic reporting, enabling the translation of complex
environmental data into actionable knowledge essential for cognitive robotic
control. We evaluated our approach by converting procedural 3D environments
into USD format, which is then annotated semantically and translated into a
knowledge graph to effectively answer competency questions, demonstrating its
utility for real-time robotic decision-making. Additionally, we developed a
web-based visualization tool to support the semantic mapping process, providing
users with an intuitive interface to manage the 3D environment.

</details>


### [138] [Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties](https://arxiv.org/abs/2507.12174)
*Zhenmin Huang,Yusen Xie,Benshan Ma,Shaojie Shen,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种新的博弈论交互轨迹规划方法，有效处理多智能体交互中的意图不确定性，具有高效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 多智能体交互轨迹规划面临意图不确定性的挑战，现有博弈论方法计算负担重且可扩展性差。

Method: 将意图不确定性下的交互建模为贝叶斯博弈，并证明其可表示为潜在博弈；提出基于ADMM的分布式算法求解。

Result: 仿真和实验表明，该方法在多种意图不确定性场景下有效，可扩展性优于现有方法。

Conclusion: 新方法解决了意图不确定性下的交互轨迹规划问题，实现了高效和可扩展的实时规划。

Abstract: Trajectory planning involving multi-agent interactions has been a
long-standing challenge in the field of robotics, primarily burdened by the
inherent yet intricate interactions among agents. While game-theoretic methods
are widely acknowledged for their effectiveness in managing multi-agent
interactions, significant impediments persist when it comes to accommodating
the intentional uncertainties of agents. In the context of intentional
uncertainties, the heavy computational burdens associated with existing
game-theoretic methods are induced, leading to inefficiencies and poor
scalability. In this paper, we propose a novel game-theoretic interactive
trajectory planning method to effectively address the intentional uncertainties
of agents, and it demonstrates both high efficiency and enhanced scalability.
As the underpinning basis, we model the interactions between agents under
intentional uncertainties as a general Bayesian game, and we show that its
agent-form equivalence can be represented as a potential game under certain
minor assumptions. The existence and attainability of the optimal interactive
trajectories are illustrated, as the corresponding Bayesian Nash equilibrium
can be attained by optimizing a unified optimization problem. Additionally, we
present a distributed algorithm based on the dual consensus alternating
direction method of multipliers (ADMM) tailored to the parallel solving of the
problem, thereby significantly improving the scalability. The attendant
outcomes from simulations and experiments demonstrate that the proposed method
is effective across a range of scenarios characterized by general forms of
intentional uncertainties. Its scalability surpasses that of existing
centralized and decentralized baselines, allowing for real-time interactive
trajectory planning in uncertain game settings.

</details>


### [139] [The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey](https://arxiv.org/abs/2507.11840)
*Gaofeng Li,Ruize Wang,Peisen Xu,Qi Ye,Jiming Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人灵巧操控的演变，从机械编程到具身智能，重点讨论了数据收集和技能学习框架的进展，并总结了三大关键挑战。


<details>
  <summary>Details</summary>
Motivation: 实现类人的灵巧机器人操控是机器人领域的核心目标和关键挑战，AI的发展推动了这一领域的快速进步。

Method: 通过总结机器人操控的演变，分析当前具身灵巧操控阶段的数据收集（仿真、人类演示、远程操作）和技能学习框架（模仿与强化学习）。

Result: 概述了现有数据收集范式和学习框架，并总结了限制灵巧机器人操控发展的三大关键挑战。

Conclusion: 灵巧机器人操控的发展仍面临三大关键挑战，需进一步研究解决。

Abstract: Achieving human-like dexterous robotic manipulation remains a central goal
and a pivotal challenge in robotics. The development of Artificial Intelligence
(AI) has allowed rapid progress in robotic manipulation. This survey summarizes
the evolution of robotic manipulation from mechanical programming to embodied
intelligence, alongside the transition from simple grippers to multi-fingered
dexterous hands, outlining key characteristics and main challenges. Focusing on
the current stage of embodied dexterous manipulation, we highlight recent
advances in two critical areas: dexterous manipulation data collection (via
simulation, human demonstrations, and teleoperation) and skill-learning
frameworks (imitation and reinforcement learning). Then, based on the overview
of the existing data collection paradigm and learning framework, three key
challenges restricting the development of dexterous robotic manipulation are
summarized and discussed.

</details>


### [140] [Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers](https://arxiv.org/abs/2507.11852)
*Mohammed Hassanin,Mohammad Abu Alsheikh,Carlos C. N. Kuhn,Damith Herath,Dinh Thai Hoang,Ibrahim Radwan*

Main category: cs.RO

TL;DR: 综述分析了自动驾驶技术（AD）在自主骑行（AR）中的应用，指出AR面临的独特挑战和研究空白，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着微型交通工具（如电动滑板车和电动自行车）的快速普及，开发可靠的自主骑行技术（AR）变得迫切。然而，由于两轮平台的不稳定性、尺寸和功率限制以及环境不可预测性，AR面临独特挑战，亟需研究解决。

Method: 通过系统分析AR的核心组件（感知、规划和控制），借鉴AD技术的研究成果，识别当前AR研究的空白和不足。

Result: 研究发现AR领域存在感知系统不完善、行业和政府支持不足以及研究关注度低等问题，并提出了多模态传感器技术和边缘深度学习架构等研究方向。

Conclusion: 通过结合AD研究成果和AR的特定需求，该综述旨在推动安全、高效和可扩展的自主骑行系统的发展，以支持未来城市交通。

Abstract: The rapid adoption of micromobility solutions, particularly two-wheeled
vehicles like e-scooters and e-bikes, has created an urgent need for reliable
autonomous riding (AR) technologies. While autonomous driving (AD) systems have
matured significantly, AR presents unique challenges due to the inherent
instability of two-wheeled platforms, limited size, limited power, and
unpredictable environments, which pose very serious concerns about road users'
safety. This review provides a comprehensive analysis of AR systems by
systematically examining their core components, perception, planning, and
control, through the lens of AD technologies. We identify critical gaps in
current AR research, including a lack of comprehensive perception systems for
various AR tasks, limited industry and government support for such
developments, and insufficient attention from the research community. The
review analyses the gaps of AR from the perspective of AD to highlight
promising research directions, such as multimodal sensor techniques for
lightweight platforms and edge deep learning architectures. By synthesising
insights from AD research with the specific requirements of AR, this review
aims to accelerate the development of safe, efficient, and scalable autonomous
riding systems for future urban mobility.

</details>


### [141] [A Fast Method for Planning All Optimal Homotopic Configurations for Tethered Robots and Its Extended Applications](https://arxiv.org/abs/2507.11880)
*Jinyuan Liu,Minglei Fu,Ling Shi,Chenguang Yang,Wenan Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为CDT-TCS的新算法，用于解决系留机器人在运动规划中的限制问题，并通过三种应用算法展示了其高效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 系留机器人在灾难响应和地下探索等特殊环境中具有稳定供电和可靠通信的优势，但其运动规划受限于系绳长度和缠绕风险，亟需优化路径规划方法。

Method: 研究采用CDT编码作为同伦不变量表示路径拓扑状态，结合代数拓扑和几何优化，开发了CDT-TCS算法及其三种应用算法（CDT-TPP、CDT-TMV、CDT-UTPP）。

Result: 仿真和实验表明，所提算法在各自问题领域中显著优于现有方法，并验证了其工程实用性。

Conclusion: CDT-TCS及其衍生算法为系留和未系留机器人的路径规划提供了高效解决方案，具有重要的理论和实践价值。

Abstract: Tethered robots play a pivotal role in specialized environments such as
disaster response and underground exploration, where their stable power supply
and reliable communication offer unparalleled advantages. However, their motion
planning is severely constrained by tether length limitations and entanglement
risks, posing significant challenges to achieving optimal path planning. To
address these challenges, this study introduces CDT-TCS (Convex Dissection
Topology-based Tethered Configuration Search), a novel algorithm that leverages
CDT Encoding as a homotopy invariant to represent topological states of paths.
By integrating algebraic topology with geometric optimization, CDT-TCS
efficiently computes the complete set of optimal feasible configurations for
tethered robots at all positions in 2D environments through a single
computation. Building on this foundation, we further propose three
application-specific algorithms: i) CDT-TPP for optimal tethered path planning,
ii) CDT-TMV for multi-goal visiting with tether constraints, iii) CDT-UTPP for
distance-optimal path planning of untethered robots. All theoretical results
and propositions underlying these algorithms are rigorously proven and
thoroughly discussed in this paper. Extensive simulations demonstrate that the
proposed algorithms significantly outperform state-of-the-art methods in their
respective problem domains. Furthermore, real-world experiments on robotic
platforms validate the practicality and engineering value of the proposed
framework.

</details>


### [142] [NemeSys: An Online Underwater Explorer with Goal-Driven Adaptive Autonomy](https://arxiv.org/abs/2507.11889)
*Adnan Abdullah,Alankrit Gupta,Vaishnav Ramesh,Shivali Patel,Md Jahidul Islam*

Main category: cs.RO

TL;DR: NemeSys是一种新型AUV系统，通过光学和磁电信号实现实时任务重配置，适用于GPS和通信受限的水下环境。


<details>
  <summary>Details</summary>
Motivation: 当前AUV系统依赖静态预编程任务或高延迟通信，限制了其适应性和响应能力。

Method: 提出NemeSys系统，包括设计、控制架构和语义任务编码框架，支持低带宽通信下的任务适应。

Result: 通过建模、实验和开放水域测试验证了系统的可行性，实现了在线任务适应和语义更新。

Conclusion: NemeSys为动态不确定水下环境中的目标驱动自适应AUV平台提供了有效解决方案。

Abstract: Adaptive mission control and dynamic parameter reconfiguration are essential
for autonomous underwater vehicles (AUVs) operating in GPS-denied,
communication-limited marine environments. However, most current AUV platforms
execute static, pre-programmed missions or rely on tethered connections and
high-latency acoustic channels for mid-mission updates, significantly limiting
their adaptability and responsiveness. In this paper, we introduce NemeSys, a
novel AUV system designed to support real-time mission reconfiguration through
compact optical and magnetoelectric (OME) signaling facilitated by floating
buoys. We present the full system design, control architecture, and a semantic
mission encoding framework that enables interactive exploration and task
adaptation via low-bandwidth communication. The proposed system is validated
through analytical modeling, controlled experimental evaluations, and
open-water trials. Results confirm the feasibility of online mission adaptation
and semantic task updates, highlighting NemeSys as an online AUV platform for
goal-driven adaptive autonomy in dynamic and uncertain underwater environments.

</details>


### [143] [Hybrid Conformal Prediction-based Risk-Aware Model Predictive Planning in Dense, Uncertain Environments](https://arxiv.org/abs/2507.11920)
*Jeongyong Yang,KwangBin Lee,SooJean Han*

Main category: cs.RO

TL;DR: HyPRAP是一种基于混合预测的风险感知路径规划框架，通过选择性使用预测模型和新型碰撞风险指数（P-CRI），在密集动态环境中高效平衡安全性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决密集动态环境中实时路径规划的挑战，特别是预测大量动态障碍物未来运动的计算负担和不现实性。

Method: HyPRAP结合多种模型预测局部障碍物运动，使用P-CRI评估障碍物风险，并选择性分配预测资源，同时通过混合共形预测量化不确定性。

Result: 理论分析和仿真表明，HyPRAP在安全性和计算效率上优于单一预测方法，P-CRI也优于基于邻近性的风险评估。

Conclusion: HyPRAP通过混合预测和风险感知机制，为密集动态环境提供了一种高效且安全的路径规划解决方案。

Abstract: Real-time path planning in dense, uncertain environments remains a
challenging problem, as predicting the future motions of numerous dynamic
obstacles is computationally burdensome and unrealistic. To address this, we
introduce Hybrid Prediction-based Risk-Aware Planning (HyPRAP), a
prediction-based risk-aware path-planning framework which uses a hybrid
combination of models to predict local obstacle movement. HyPRAP uses a novel
Prediction-based Collision Risk Index (P-CRI) to evaluate the risk posed by
each obstacle, enabling the selective use of predictors based on whether the
agent prioritizes high predictive accuracy or low computational prediction
overhead. This selective routing enables the agent to focus on high-risk
obstacles while ignoring or simplifying low-risk ones, making it suitable for
environments with a large number of obstacles. Moreover, HyPRAP incorporates
uncertainty quantification through hybrid conformal prediction by deriving
confidence bounds simultaneously achieved by multiple predictions across
different models. Theoretical analysis demonstrates that HyPRAP effectively
balances safety and computational efficiency by leveraging the diversity of
prediction models. Extensive simulations validate these insights for more
general settings, confirming that HyPRAP performs better compared to single
predictor methods, and P-CRI performs better over naive proximity-based risk
assessment.

</details>


### [144] [A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning](https://arxiv.org/abs/2507.11938)
*Hao Chen,Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 论文提出了一种基于相似性匹配的新方法，通过利用已知物体的相似性来指导未知物体的抓取，解决了单视角下抓取的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的方法对感知噪声和环境变化敏感，性能鲁棒性不足，因此需要一种更通用的抓取方法。

Method: 1) 利用视觉特征进行相似性匹配；2) 基于候选模型的抓取知识规划模仿抓取；3) 通过局部微调优化抓取质量。

Result: 提出了一种多级相似性匹配框架和C-FPFH描述符，结合语义、几何和维度特征，显著提高了匹配和抓取的准确性。

Conclusion: 新方法通过相似性匹配和局部优化，实现了对未知物体的鲁棒抓取，克服了单视角下的不确定性。

Abstract: Grasping unknown objects from a single view has remained a challenging topic
in robotics due to the uncertainty of partial observation. Recent advances in
large-scale models have led to benchmark solutions such as GraspNet-1Billion.
However, such learning-based approaches still face a critical limitation in
performance robustness for their sensitivity to sensing noise and environmental
changes. To address this bottleneck in achieving highly generalized grasping,
we abandon the traditional learning framework and introduce a new perspective:
similarity matching, where similar known objects are utilized to guide the
grasping of unknown target objects. We newly propose a method that robustly
achieves unknown-object grasping from a single viewpoint through three key
steps: 1) Leverage the visual features of the observed object to perform
similarity matching with an existing database containing various object models,
identifying potential candidates with high similarity; 2) Use the candidate
models with pre-existing grasping knowledge to plan imitative grasps for the
unknown target object; 3) Optimize the grasp quality through a local
fine-tuning process. To address the uncertainty caused by partial and noisy
observation, we propose a multi-level similarity matching framework that
integrates semantic, geometric, and dimensional features for comprehensive
evaluation. Especially, we introduce a novel point cloud geometric descriptor,
the C-FPFH descriptor, which facilitates accurate similarity assessment between
partial point clouds of observed objects and complete point clouds of database
models. In addition, we incorporate the use of large language models, introduce
the semi-oriented bounding box, and develop a novel point cloud registration
approach based on plane detection to enhance matching accuracy under
single-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.

</details>


### [145] [IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving](https://arxiv.org/abs/2507.11940)
*Kanghyun Ryu,Minjun Sung,Piyush Gupta,Jovin D'sa,Faizan M. Tariq,David Isele,Sangjae Bae*

Main category: cs.RO

TL;DR: 提出了一种名为IANN-MPPI的交互感知轨迹规划方法，用于解决自动驾驶车辆在密集交通中的保守行为和规划目标未达成问题。


<details>
  <summary>Details</summary>
Motivation: 传统预测与规划方法忽视了周围车辆对自动驾驶车辆行为的交互反应，导致规划效果不佳。

Method: 结合神经网络和MPPI控制，预测周围车辆对控制序列的反应，并引入基于样条的采样分布先验以优化车道变更行为。

Result: 在密集交通合并场景中验证了方法的有效性，能够实现高效的合并操作。

Conclusion: IANN-MPPI方法通过交互感知显著提升了自动驾驶车辆在密集交通中的规划性能。

Abstract: Motion planning for autonomous vehicles (AVs) in dense traffic is
challenging, often leading to overly conservative behavior and unmet planning
objectives. This challenge stems from the AVs' limited ability to anticipate
and respond to the interactive behavior of surrounding agents. Traditional
decoupled prediction and planning pipelines rely on non-interactive predictions
that overlook the fact that agents often adapt their behavior in response to
the AV's actions. To address this, we propose Interaction-Aware Neural
Network-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which
enables interactive trajectory planning by predicting how surrounding agents
may react to each control sequence sampled by MPPI. To improve performance in
structured lane environments, we introduce a spline-based prior for the MPPI
sampling distribution, enabling efficient lane-changing behavior. We evaluate
IANN-MPPI in a dense traffic merging scenario, demonstrating its ability to
perform efficient merging maneuvers. Our project website is available at
https://sites.google.com/berkeley.edu/iann-mppi

</details>


### [146] [A Review of Generative AI in Aquaculture: Foundations, Applications, and Future Directions for Smart and Sustainable Farming](https://arxiv.org/abs/2507.11974)
*Waseem Akram,Muhayy Ud Din,Lyes Saad Soud,Irfan Hussain*

Main category: cs.RO

TL;DR: 综述探讨了生成式人工智能（GAI）在水产养殖中的多模态数据合成与智能决策应用，涵盖技术架构、实际案例及挑战。


<details>
  <summary>Details</summary>
Motivation: 水产养殖业向数据驱动和自动化转型（Aquaculture 4.0），GAI为环境监测、疾病诊断等领域提供了新机遇。

Method: 综述GAI在水产养殖中的应用，包括基础架构（如扩散模型、Transformer）、实验系统及实际案例。

Result: GAI在水下感知、数字孪生建模和ROV任务规划中发挥重要作用，但仍面临数据不足、实时性等限制。

Conclusion: GAI是智能、可持续水产养殖系统的关键推动者，但需解决技术和监管挑战。

Abstract: Generative Artificial Intelligence (GAI) has rapidly emerged as a
transformative force in aquaculture, enabling intelligent synthesis of
multimodal data, including text, images, audio, and simulation outputs for
smarter, more adaptive decision-making. As the aquaculture industry shifts
toward data-driven, automation and digital integration operations under the
Aquaculture 4.0 paradigm, GAI models offer novel opportunities across
environmental monitoring, robotics, disease diagnostics, infrastructure
planning, reporting, and market analysis. This review presents the first
comprehensive synthesis of GAI applications in aquaculture, encompassing
foundational architectures (e.g., diffusion models, transformers, and retrieval
augmented generation), experimental systems, pilot deployments, and real-world
use cases. We highlight GAI's growing role in enabling underwater perception,
digital twin modeling, and autonomous planning for remotely operated vehicle
(ROV) missions. We also provide an updated application taxonomy that spans
sensing, control, optimization, communication, and regulatory compliance.
Beyond technical capabilities, we analyze key limitations, including limited
data availability, real-time performance constraints, trust and explainability,
environmental costs, and regulatory uncertainty. This review positions GAI not
merely as a tool but as a critical enabler of smart, resilient, and
environmentally aligned aquaculture systems.

</details>


### [147] [Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers](https://arxiv.org/abs/2507.11991)
*Juanran Wang,Marc R. Schlichting,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 利用深度生成模型提升自动驾驶车辆在交叉路口的安全性，通过生成对抗架构将1000步去噪扩散模型蒸馏为单步模型，并应用于鲁棒规划器。


<details>
  <summary>Details</summary>
Motivation: 高风险交通区域（如交叉路口）是碰撞的主要原因，需提升自动驾驶车辆的安全性。

Method: 训练1000步去噪扩散概率模型生成碰撞传感器噪声序列，并通过生成对抗架构蒸馏为单步模型。

Result: 单步模型在保持采样质量的同时实现快速推理，鲁棒规划器显著降低失败率和延迟率。

Conclusion: 单步模型在自动驾驶规划中具有高效性和实用性，显著提升安全性。

Abstract: High-risk traffic zones such as intersections are a major cause of
collisions. This study leverages deep generative models to enhance the safety
of autonomous vehicles in an intersection context. We train a 1000-step
denoising diffusion probabilistic model to generate collision-causing sensor
noise sequences for an autonomous vehicle navigating a four-way intersection
based on the current relative position and velocity of an intruder. Using the
generative adversarial architecture, the 1000-step model is distilled into a
single-step denoising diffusion model which demonstrates fast inference speed
while maintaining similar sampling quality. We demonstrate one possible
application of the single-step model in building a robust planner for the
autonomous vehicle. The planner uses the single-step model to efficiently
sample potential failure cases based on the currently measured traffic state to
inform its decision-making. Through simulation experiments, the robust planner
demonstrates significantly lower failure rate and delay rate compared with the
baseline Intelligent Driver Model controller.

</details>


### [148] [Robust Route Planning for Sidewalk Delivery Robots](https://arxiv.org/abs/2507.12067)
*Xing Tong,Michele D. Simoni*

Main category: cs.RO

TL;DR: 研究提出了一种针对人行道配送机器人的鲁棒路径规划方法，通过模拟行人流量和障碍物影响，结合优化方法解决旅行时间不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 人行道配送机器人因行人密度、障碍物和基础设施条件导致旅行时间不可靠，影响效率，需鲁棒路径规划。

Method: 集成优化与模拟，采用预算、椭球和支持向量聚类（SVC）方法生成不确定性集，结合分布鲁棒方法求解最短路径问题。

Result: 鲁棒路径规划显著提升操作可靠性，椭球和DRSP方法表现最佳，尤其在恶劣天气和高行人密度场景。

Conclusion: 鲁棒路径规划能有效应对人行道条件变化，提升配送机器人效率，尤其在复杂环境下表现突出。

Abstract: Sidewalk delivery robots are a promising solution for urban freight
distribution, reducing congestion compared to trucks and providing a safer,
higher-capacity alternative to drones. However, unreliable travel times on
sidewalks due to pedestrian density, obstacles, and varying infrastructure
conditions can significantly affect their efficiency. This study addresses the
robust route planning problem for sidewalk robots, explicitly accounting for
travel time uncertainty due to varying sidewalk conditions. Optimization is
integrated with simulation to reproduce the effect of obstacles and pedestrian
flows and generate realistic travel times. The study investigates three
different approaches to derive uncertainty sets, including budgeted,
ellipsoidal, and support vector clustering (SVC)-based methods, along with a
distributionally robust method to solve the shortest path (SP) problem. A
realistic case study reproducing pedestrian patterns in Stockholm's city center
is used to evaluate the efficiency of robust routing across various robot
designs and environmental conditions. The results show that, when compared to a
conventional SP, robust routing significantly enhances operational reliability
under variable sidewalk conditions. The Ellipsoidal and DRSP approaches
outperform the other methods, yielding the most efficient paths in terms of
average and worst-case delay. Sensitivity analyses reveal that robust
approaches consistently outperform the conventional SP, particularly for
sidewalk delivery robots that are wider, slower, and have more conservative
navigation behaviors. These benefits are even more pronounced in adverse
weather conditions and high pedestrian congestion scenarios.

</details>


### [149] [Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards](https://arxiv.org/abs/2507.12093)
*David Rapado-Rincon,Gert Kootstra*

Main category: cs.RO

TL;DR: Tree-SLAM是一种针对果园中单棵树定位的语义SLAM方法，通过RGB-D图像和实例分割模型检测树干，结合GPS和里程计数据，实现高精度地图构建。


<details>
  <summary>Details</summary>
Motivation: 果园中GPS信号不可靠且传统SLAM方法因树木重复外观易出错，需要一种能精准定位单棵树的方法。

Method: 使用RGB-D图像检测树干，通过级联图数据关联算法重识别树干，结合GPS、里程计和树干观测构建因子图框架。

Result: 在苹果和梨园数据集上验证，定位误差低至18厘米，小于种植距离的20%。

Conclusion: Tree-SLAM在GPS信号不可靠时仍能实现高精度和鲁棒性的单棵树定位。

Abstract: Accurate mapping of individual trees is an important component for precision
agriculture in orchards, as it allows autonomous robots to perform tasks like
targeted operations or individual tree monitoring. However, creating these maps
is challenging because GPS signals are often unreliable under dense tree
canopies. Furthermore, standard Simultaneous Localization and Mapping (SLAM)
approaches struggle in orchards because the repetitive appearance of trees can
confuse the system, leading to mapping errors. To address this, we introduce
Tree-SLAM, a semantic SLAM approach tailored for creating maps of individual
trees in orchards. Utilizing RGB-D images, our method detects tree trunks with
an instance segmentation model, estimates their location and re-identifies them
using a cascade-graph-based data association algorithm. These re-identified
trunks serve as landmarks in a factor graph framework that integrates noisy GPS
signals, odometry, and trunk observations. The system produces maps of
individual trees with a geo-localization error as low as 18 cm, which is less
than 20\% of the planting distance. The proposed method was validated on
diverse datasets from apple and pear orchards across different seasons,
demonstrating high mapping accuracy and robustness in scenarios with unreliable
GPS signals.

</details>


### [150] [Leveraging Sidewalk Robots for Walkability-Related Analyses](https://arxiv.org/abs/2507.12148)
*Xing Tong,Michele D. Simoni,Kaj Munhoz Arfvidsson,Jonas Mårtensson*

Main category: cs.RO

TL;DR: 利用配备传感器的机器人收集人行道数据，分析其与步行性的关系，为可持续城市发展提供支持。


<details>
  <summary>Details</summary>
Motivation: 传统方法收集步行性相关数据成本高且难以扩展，而人行道送货机器人提供了自动化、实时且可扩展的解决方案。

Method: 在斯德哥尔摩KTH的人行道网络中部署传感器机器人，完成101次行程，收集速度、人行道条件和利用率等数据。

Result: 人行道特征（如宽度、表面不平整度）显著影响行人行为，机器人速度可作为行人动态的代理指标。

Conclusion: 机器人框架能持续监测人行道条件和行人行为，有助于打造更适宜步行、包容性更强的城市环境。

Abstract: Walkability is a key component of sustainable urban development, while
collecting detailed data on its related features remains challenging due to the
high costs and limited scalability of traditional methods. Sidewalk delivery
robots, increasingly deployed in urban environments, offer a promising solution
to these limitations. This paper explores how these robots can serve as mobile
data collection platforms, capturing sidewalk-level features related to
walkability in a scalable, automated, and real-time manner. A sensor-equipped
robot was deployed on a sidewalk network at KTH in Stockholm, completing 101
trips covering 900 segments. From the collected data, different typologies of
features are derived, including robot trip characteristics (e.g., speed,
duration), sidewalk conditions (e.g., width, surface unevenness), and sidewalk
utilization (e.g., pedestrian density). Their walkability-related implications
were investigated with a series of analyses. The results demonstrate that
pedestrian movement patterns are strongly influenced by sidewalk
characteristics, with higher density, reduced width, and surface irregularity
associated with slower and more variable trajectories. Notably, robot speed
closely mirrors pedestrian behavior, highlighting its potential as a proxy for
assessing pedestrian dynamics. The proposed framework enables continuous
monitoring of sidewalk conditions and pedestrian behavior, contributing to the
development of more walkable, inclusive, and responsive urban environments.

</details>


### [151] [Probabilistic Safety Verification for an Autonomous Ground Vehicle: A Situation Coverage Grid Approach](https://arxiv.org/abs/2507.12158)
*Nawshin Mannan Proma,Gricel Vázquez,Sepeedeh Shahbeigi,Arjun Badyal,Victoria Hodge*

Main category: cs.RO

TL;DR: 本文提出了一种基于系统性情境提取、概率建模和验证的工业自动驾驶车辆安全验证新方法，通过情境覆盖网格和概率模型检查，有效识别高风险情境并提供安全保证。


<details>
  <summary>Details</summary>
Motivation: 随着工业自动驾驶车辆在安全关键环境中的部署增加，确保其在多样化条件下的安全运行至关重要。

Method: 利用情境覆盖网格枚举环境配置，结合概率数据构建模型，通过概率模型检查验证安全属性。

Result: 方法成功识别高风险情境，提供定量安全保证，并支持符合监管标准。

Conclusion: 该方法为自动驾驶系统的稳健部署提供了有效支持。

Abstract: As industrial autonomous ground vehicles are increasingly deployed in
safety-critical environments, ensuring their safe operation under diverse
conditions is paramount. This paper presents a novel approach for their safety
verification based on systematic situation extraction, probabilistic modelling
and verification. We build upon the concept of a situation coverage grid, which
exhaustively enumerates environmental configurations relevant to the vehicle's
operation. This grid is augmented with quantitative probabilistic data
collected from situation-based system testing, capturing probabilistic
transitions between situations. We then generate a probabilistic model that
encodes the dynamics of both normal and unsafe system behaviour. Safety
properties extracted from hazard analysis and formalised in temporal logic are
verified through probabilistic model checking against this model. The results
demonstrate that our approach effectively identifies high-risk situations,
provides quantitative safety guarantees, and supports compliance with
regulatory standards, thereby contributing to the robust deployment of
autonomous systems.

</details>


### [152] [UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization](https://arxiv.org/abs/2507.12194)
*Hongming Shen,Xun Chen,Yulin Hui,Zhenyu Wu,Wei Wang,Qiyang Lyu,Tianchen Deng,Danwei Wang*

Main category: cs.RO

TL;DR: 提出了一种统一的LiDAR全局定位（LGL）方法UniLGL，通过编码完整点云信息到BEV图像，实现空间、材料和传感器类型的统一性。


<details>
  <summary>Details</summary>
Motivation: 现有LGL方法通常仅考虑部分信息或针对同质LiDAR传感器，忽略了LGL的统一性。

Method: 将点云编码为空间和强度BEV图像，设计多BEV融合网络提取统一特征，引入视角不变性假设实现传感器类型统一。

Result: 实验表明UniLGL在真实环境中表现优异，适用于多种平台和场景。

Conclusion: UniLGL在工业与野外场景中具有广泛应用潜力。

Abstract: Existing LGL methods typically consider only partial information (e.g.,
geometric features) from LiDAR observations or are designed for homogeneous
LiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL
method is proposed, termed UniLGL, which simultaneously achieves spatial and
material uniformity, as well as sensor-type uniformity. The key idea of the
proposed method is to encode the complete point cloud, which contains both
geometric and material information, into a pair of BEV images (i.e., a spatial
BEV image and an intensity BEV image). An end-to-end multi-BEV fusion network
is designed to extract uniform features, equipping UniLGL with spatial and
material uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a
viewpoint invariance hypothesis is introduced, which replaces the conventional
translation equivariance assumption commonly used in existing LPR networks and
supervises UniLGL to achieve sensor-type uniformity in both global descriptors
and local feature representations. Finally, based on the mapping between local
features on the 2D BEV image and the point cloud, a robust global pose
estimator is derived that determines the global minimum of the global pose on
SE(3) without requiring additional registration. To validate the effectiveness
of the proposed uniform LGL, extensive benchmarks are conducted in real-world
environments, and the results show that the proposed UniLGL is demonstratively
competitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL
has been deployed on diverse platforms, including full-size trucks and agile
Micro Aerial Vehicles (MAVs), to enable high-precision localization and mapping
as well as multi-MAV collaborative exploration in port and forest environments,
demonstrating the applicability of UniLGL in industrial and field scenarios.

</details>


### [153] [Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot](https://arxiv.org/abs/2507.12273)
*Luca Garello,Francesca Cocchella,Alessandra Sciutti,Manuel Catalano,Francesco Rea*

Main category: cs.RO

TL;DR: 论文介绍了自主博物馆导览机器人Alter-Ego的设计与评估，展示了其在提升用户体验方面的潜力与局限性。


<details>
  <summary>Details</summary>
Motivation: 探索AI驱动的机器人在文化空间中的应用，以提升博物馆参观体验和知识获取。

Method: 结合LLMs实现实时问答交互，利用SLAM技术进行导航，并通过实地测试评估效果。

Result: 机器人受到普遍欢迎，提升了参观体验，但在理解和响应方面存在不足。

Conclusion: 研究揭示了AI机器人在文化空间中的潜力与挑战，强调了进一步优化的必要性。

Abstract: Autonomous robots are increasingly being tested into public spaces to enhance
user experiences, particularly in cultural and educational settings. This paper
presents the design, implementation, and evaluation of the autonomous museum
guide robot Alter-Ego equipped with advanced navigation and interactive
capabilities. The robot leverages state-of-the-art Large Language Models (LLMs)
to provide real-time, context aware question-and-answer (Q&A) interactions,
allowing visitors to engage in conversations about exhibits. It also employs
robust simultaneous localization and mapping (SLAM) techniques, enabling
seamless navigation through museum spaces and route adaptation based on user
requests. The system was tested in a real museum environment with 34
participants, combining qualitative analysis of visitor-robot conversations and
quantitative analysis of pre and post interaction surveys. Results showed that
the robot was generally well-received and contributed to an engaging museum
experience, despite some limitations in comprehension and responsiveness. This
study sheds light on HRI in cultural spaces, highlighting not only the
potential of AI-driven robotics to support accessibility and knowledge
acquisition, but also the current limitations and challenges of deploying such
technologies in complex, real-world environments.

</details>


### [154] [Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning](https://arxiv.org/abs/2507.12391)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: 论文评估了多模态大语言模型（LLMs）在机器人路径规划中的表现，发现视觉输入在简单任务中有一定帮助，但在复杂任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探索视觉输入对多模态LLMs在机器人路径规划任务中的效用，以提升其性能。

Method: 通过基准测试评估15种多模态LLMs在2D网格环境中的路径规划能力，比较纯文本与文本加视觉输入的效果。

Result: 在简单小网格中表现尚可，视觉输入或少量文本提示有助提升；但在大网格中性能显著下降。视觉模态并未普遍优于结构化文本。

Conclusion: 当前多模态LLMs在空间推理、约束遵循和可扩展性方面存在局限，需进一步改进。

Abstract: Large Language Models (LLMs) show potential for enhancing robotic path
planning. This paper assesses visual input's utility for multimodal LLMs in
such tasks via a comprehensive benchmark. We evaluated 15 multimodal LLMs on
generating valid and optimal paths in 2D grid environments, simulating
simplified robotic planning, comparing text-only versus text-plus-visual inputs
across varying model sizes and grid complexities. Our results indicate moderate
success rates on simpler small grids, where visual input or few-shot text
prompting offered some benefits. However, performance significantly degraded on
larger grids, highlighting a scalability challenge. While larger models
generally achieved higher average success, the visual modality was not
universally dominant over well-structured text for these multimodal systems,
and successful paths on simpler grids were generally of high quality. These
results indicate current limitations in robust spatial reasoning, constraint
adherence, and scalable multimodal integration, identifying areas for future
LLM development in robotic path planning.

</details>


### [155] [Regrasp Maps for Sequential Manipulation Planning](https://arxiv.org/abs/2507.12407)
*Svetlana Levit,Marc Toussaint*

Main category: cs.RO

TL;DR: 提出了一种基于优化的任务和运动规划（TAMP）方法，通过状态空间抽象（regrasp map）加速搜索，解决复杂环境中的多次抓取问题。


<details>
  <summary>Details</summary>
Motivation: 在受限和杂乱环境中，多次抓取（regrasp）的需求增加了任务和运动规划的复杂性，需要高效的方法来加速搜索。

Method: 使用状态空间抽象（regrasp map）捕捉不同配置空间中的抓取组合，为优化器提供模式切换猜测和物体放置约束。通过交替生成regrasp map、基于失败调整和解决TAMP子问题，实现鲁棒搜索。

Result: 该方法能够高效解决复杂环境中的多次抓取问题，加速了搜索过程。

Conclusion: 提出的regrasp map和交替优化方法为复杂环境中的抓取规划提供了高效且鲁棒的解决方案。

Abstract: We consider manipulation problems in constrained and cluttered settings,
which require several regrasps at unknown locations. We propose to inform an
optimization-based task and motion planning (TAMP) solver with possible regrasp
areas and grasp sequences to speed up the search. Our main idea is to use a
state space abstraction, a regrasp map, capturing the combinations of available
grasps in different parts of the configuration space, and allowing us to
provide the solver with guesses for the mode switches and additional
constraints for the object placements. By interleaving the creation of regrasp
maps, their adaptation based on failed refinements, and solving TAMP
(sub)problems, we are able to provide a robust search method for challenging
regrasp manipulation problems.

</details>


### [156] [Design and Development of an Automated Contact Angle Tester (ACAT) for Surface Wettability Measurement](https://arxiv.org/abs/2507.12431)
*Connor Burgess,Kyle Douin,Amir Kordijazi*

Main category: cs.RO

TL;DR: ACAT是一个自动化测量3D打印材料表面润湿性的集成机器人工作站，通过结合可编程机器人、精确液体分配和模块化软硬件架构，解决了手动测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 手动接触角测试存在精度和重复性问题，ACAT旨在通过自动化提高效率和安全性。

Method: ACAT由电气系统、软件控制系统和机械系统组成，符合工业标准，采用Raspberry Pi和Python实现控制。

Result: ACAT实现了高通量、自动化的表面表征，为智能制造和材料发现提供了平台。

Conclusion: ACAT的设计和实现为自动化表面润湿性测试提供了高效、可靠的解决方案。

Abstract: The Automated Contact Angle Tester (ACAT) is a fully integrated robotic work
cell developed to automate the measurement of surface wettability on 3D-printed
materials. Designed for precision, repeatability, and safety, ACAT addresses
the limitations of manual contact angle testing by combining programmable
robotics, precise liquid dispensing, and a modular software-hardware
architecture. The system is composed of three core subsystems: (1) an
electrical system including power, control, and safety circuits compliant with
industrial standards such as NEC 70, NFPA 79, and UL 508A; (2) a software
control system based on a Raspberry Pi and Python, featuring fault detection,
GPIO logic, and operator interfaces; and (3) a mechanical system that includes
a 3-axis Cartesian robot, pneumatic actuation, and a precision liquid dispenser
enclosed within a safety-certified frame. The ACAT enables high-throughput,
automated surface characterization and provides a robust platform for future
integration into smart manufacturing and materials discovery workflows. This
paper details the design methodology, implementation strategies, and system
integration required to develop the ACAT platform.

</details>


### [157] [EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos](https://arxiv.org/abs/2507.12440)
*Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种利用人类视频训练视觉-语言-动作（VLA）模型的方法，通过逆运动学和重定向将人类动作转换为机器人动作，并展示了在仿真基准上的显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决机器人模仿学习中因硬件限制导致数据规模不足的问题，同时利用人类视频丰富的场景和任务多样性。

Method: 使用人类视频训练VLA模型，预测人类手腕和手部动作，通过逆运动学和重定向转换为机器人动作，并用少量机器人演示微调模型。

Result: 在仿真基准（Isaac Humanoid Manipulation Benchmark）上，EgoVLA模型表现显著优于基线，并验证了人类数据的重要性。

Conclusion: 利用人类视频训练VLA模型是一种有效的方法，能够显著提升机器人模仿学习的性能，同时减少对机器人硬件的依赖。

Abstract: Real robot data collection for imitation learning has led to significant
advancements in robotic manipulation. However, the requirement for robot
hardware in the process fundamentally constrains the scale of the data. In this
paper, we explore training Vision-Language-Action (VLA) models using egocentric
human videos. The benefit of using human videos is not only for their scale but
more importantly for the richness of scenes and tasks. With a VLA trained on
human video that predicts human wrist and hand actions, we can perform Inverse
Kinematics and retargeting to convert the human actions to robot actions. We
fine-tune the model using a few robot manipulation demonstrations to obtain the
robot policy, namely EgoVLA. We propose a simulation benchmark called Isaac
Humanoid Manipulation Benchmark, where we design diverse bimanual manipulation
tasks with demonstrations. We fine-tune and evaluate EgoVLA with Isaac Humanoid
Manipulation Benchmark and show significant improvements over baselines and
ablate the importance of human data. Videos can be found on our website:
https://rchalyang.github.io/EgoVLA

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [158] [CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos](https://arxiv.org/abs/2507.11900)
*Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 提出CompressedVQA-HDR框架，针对HDR视频质量评估，采用Swin Transformer和SigLip 2作为骨干网络，分别构建FR和NR模型，通过预训练和微调策略提升性能，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频压缩质量评估方法对HDR视频泛化能力不足，需开发更通用的评估框架。

Method: FR模型利用Swin Transformer提取结构和纹理相似性；NR模型使用SigLip 2提取全局特征。通过预训练和混合数据集训练优化模型。

Result: 模型在HDR视频质量评估中表现优异，FR模型在IEEE ICME 2025挑战赛中获第一名。

Conclusion: CompressedVQA-HDR框架有效解决了HDR视频质量评估问题，性能优于现有方法。

Abstract: Video compression is a standard procedure applied to all videos to minimize
storage and transmission demands while preserving visual quality as much as
possible. Therefore, evaluating the visual quality of compressed videos is
crucial for guiding the practical usage and further development of video
compression algorithms. Although numerous compressed video quality assessment
(VQA) methods have been proposed, they often lack the generalization capability
needed to handle the increasing diversity of video types, particularly high
dynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an
effective VQA framework designed to address the challenges of HDR video quality
assessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the
backbone networks for the proposed full-reference (FR) and no-reference (NR)
VQA models, respectively. For the FR model, we compute deep structural and
textural similarities between reference and distorted frames using
intermediate-layer features extracted from the Swin Transformer as its
quality-aware feature representation. For the NR model, we extract the global
mean of the final-layer feature maps from SigLip 2 as its quality-aware
representation. To mitigate the issue of limited HDR training data, we
pre-train the FR model on a large-scale standard dynamic range (SDR) VQA
dataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ
an iterative mixed-dataset training strategy across multiple compressed VQA
datasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental
results show that our models achieve state-of-the-art performance compared to
existing FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place
in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand
Challenge at IEEE ICME 2025. The code is available at
https://github.com/sunwei925/CompressedVQA-HDR.

</details>


### [159] [Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease](https://arxiv.org/abs/2507.12012)
*Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs*

Main category: eess.IV

TL;DR: 该论文提出了一种无监督机器学习方法，通过深度聚类网络从肝脏MRI图像中提取组织模式词汇，用于量化弥漫性肝病的治疗反应。


<details>
  <summary>Details</summary>
Motivation: 量化与疾病进展和治疗反应相关的图像模式对于指导个体化治疗和开发新疗法至关重要。

Method: 使用深度聚类网络对医学图像块进行编码和聚类，构建低维潜在空间的组织词汇。

Result: 该方法在非酒精性脂肪性肝炎患者的随机对照试验中验证，能识别与治疗相关的特定组织变化路径，并优于非影像学指标。

Conclusion: 提出的方法具有临床应用潜力，可通过非侵入性影像数据预测活检特征。

Abstract: Quantifiable image patterns associated with disease progression and treatment
response are critical tools for guiding individual treatment, and for
developing novel therapies. Here, we show that unsupervised machine learning
can identify a pattern vocabulary of liver tissue in magnetic resonance images
that quantifies treatment response in diffuse liver disease. Deep clustering
networks simultaneously encode and cluster patches of medical images into a
low-dimensional latent space to establish a tissue vocabulary. The resulting
tissue types capture differential tissue change and its location in the liver
associated with treatment response. We demonstrate the utility of the
vocabulary on a randomized controlled trial cohort of non-alcoholic
steatohepatitis patients. First, we use the vocabulary to compare longitudinal
liver change in a placebo and a treatment cohort. Results show that the method
identifies specific liver tissue change pathways associated with treatment, and
enables a better separation between treatment groups than established
non-imaging measures. Moreover, we show that the vocabulary can predict biopsy
derived features from non-invasive imaging data. We validate the method on a
separate replication cohort to demonstrate the applicability of the proposed
method.

</details>


### [160] [Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis](https://arxiv.org/abs/2507.12092)
*Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 该论文提出了一种基于多中心MRI数据的皮质病变检测与分割方法，利用nnU-Net框架改进检测性能，并分析了模型在不同数据分布下的表现。


<details>
  <summary>Details</summary>
Motivation: 皮质病变在MS诊断和预后中具有重要价值，但临床应用中因MRI表现不明显、专家标注困难及缺乏标准化方法而受限。

Method: 使用656份3T和7T MRI扫描数据，结合专家共识标注，采用nnU-Net框架进行改进，并评估模型泛化能力。

Result: 模型在域内和域外的F1分数分别为0.64和0.5，分析了数据变异性、病变模糊性和协议差异对性能的影响。

Conclusion: 研究为临床应用中数据标准化和模型改进提供了建议，并公开了代码和模型以促进可重复性。

Abstract: Cortical lesions (CLs) have emerged as valuable biomarkers in multiple
sclerosis (MS), offering high diagnostic specificity and prognostic relevance.
However, their routine clinical integration remains limited due to subtle
magnetic resonance imaging (MRI) appearance, challenges in expert annotation,
and a lack of standardized automated methods. We propose a comprehensive
multi-centric benchmark of CL detection and segmentation in MRI. A total of 656
MRI scans, including clinical trial and research data from four institutions,
were acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with
expert-consensus annotations. We rely on the self-configuring nnU-Net
framework, designed for medical imaging segmentation, and propose adaptations
tailored to the improved CL detection. We evaluated model generalization
through out-of-distribution testing, demonstrating strong lesion detection
capabilities with an F1-score of 0.64 and 0.5 in and out of the domain,
respectively. We also analyze internal model features and model errors for a
better understanding of AI decision-making. Our study examines how data
variability, lesion ambiguity, and protocol differences impact model
performance, offering future recommendations to address these barriers to
clinical adoption. To reinforce the reproducibility, the implementation and
models will be publicly accessible and ready to use at
https://github.com/Medical-Image-Analysis-Laboratory/ and
https://doi.org/10.5281/zenodo.15911797.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [161] [Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming](https://arxiv.org/abs/2507.11547)
*Yingxue Zhao,Qianyi Chen,Haoran Li,Haosu Zhou,Hamid Reza Attar,Tobias Pfaff,Tailin Wu,Nan Li*

Main category: cs.LG

TL;DR: 提出了一种名为RUGNN的图神经网络替代模型，用于预测材料成形过程中的变形场，解决了传统AI模型在捕捉3D空间关系和置换不变性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于标量或图像的AI替代模型难以捕捉复杂的3D空间关系和置换不变性，因此需要开发更先进的图神经网络模型。

Method: 开发了RUGNN模型，结合门控循环单元（GRUs）建模时间动态，并采用U-Net启发的图上下采样机制处理空间长程依赖。提出了一种新颖的“节点到表面”接触表示方法。

Result: RUGNN在冷成形和热成形案例中表现出色，预测结果与真实有限元模拟高度吻合，且优于其他基线GNN架构。

Conclusion: RUGNN是一种可靠的方法，能够支持板材成形设计，提供准确的制造性预测。

Abstract: In recent years, various artificial intelligence-based surrogate models have
been proposed to provide rapid manufacturability predictions of material
forming processes. However, traditional AI-based surrogate models, typically
built with scalar or image-based neural networks, are limited in their ability
to capture complex 3D spatial relationships and to operate in a
permutation-invariant manner. To overcome these issues, emerging graph-based
surrogate models are developed using graph neural networks. This study
developed a new graph neural network surrogate model named Recurrent U
Net-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate
predictions of sheet material deformation fields across multiple forming
timesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model
temporal dynamics and a U-Net inspired graph-based downsample/upsample
mechanism to handle spatial long-range dependencies. A novel 'node-to-surface'
contact representation method was proposed, offering significant improvements
in computational efficiency for large-scale contact interactions. The RUGNN
model was validated using a cold forming case study and a more complex hot
forming case study using aluminium alloys. Results demonstrate that the RUGNN
model provides accurate deformation predictions closely matching ground truth
FE simulations and outperforming several baseline GNN architectures. Model
tuning was also performed to identify suitable hyperparameters, training
strategies, and input feature representations. These results demonstrate that
RUGNN is a reliable approach to support sheet material forming design by
enabling accurate manufacturability predictions.

</details>


### [162] [SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery](https://arxiv.org/abs/2507.11570)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.LG

TL;DR: 论文开发了SurgeryLSTM模型，用于预测脊柱手术住院时间，结合注意力机制提升模型解释性，表现优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过时间建模和模型解释性改进脊柱手术住院时间的预测，以支持临床决策。

Method: 比较传统ML模型与SurgeryLSTM（带注意力机制的BiLSTM），使用结构化电子健康记录数据，评估指标为R2。

Result: SurgeryLSTM预测准确率最高（R2=0.86），注意力机制动态识别关键时间片段，骨病、慢性肾病和腰椎融合是关键预测因素。

Conclusion: SurgeryLSTM为脊柱手术住院时间预测提供高准确性和解释性，支持临床决策系统的整合。

Abstract: Objective: To develop and evaluate machine learning (ML) models for
predicting length of stay (LOS) in elective spine surgery, with a focus on the
benefits of temporal modeling and model interpretability. Materials and
Methods: We compared traditional ML models (e.g., linear regression, random
forest, support vector machine (SVM), and XGBoost) with our developed model,
SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an
attention, using structured perioperative electronic health records (EHR) data.
Performance was evaluated using the coefficient of determination (R2), and key
predictors were identified using explainable AI. Results: SurgeryLSTM achieved
the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)
and baseline models. The attention mechanism improved interpretability by
dynamically identifying influential temporal segments within preoperative
clinical sequences, allowing clinicians to trace which events or features most
contributed to each LOS prediction. Key predictors of LOS included bone
disorder, chronic kidney disease, and lumbar fusion identified as the most
impactful predictors of LOS. Discussion: Temporal modeling with attention
mechanisms significantly improves LOS prediction by capturing the sequential
nature of patient data. Unlike static models, SurgeryLSTM provides both higher
accuracy and greater interpretability, which are critical for clinical
adoption. These results highlight the potential of integrating attention-based
temporal models into hospital planning workflows. Conclusion: SurgeryLSTM
presents an effective and interpretable AI solution for LOS prediction in
elective spine surgery. Our findings support the integration of temporal,
explainable ML approaches into clinical decision support systems to enhance
discharge readiness and individualized patient care.

</details>


### [163] [Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators](https://arxiv.org/abs/2507.11574)
*Kazuma Kobayashi,Shailesh Garg,Farid Ahmed,Souvik Chakraborty,Syed Bahauddin Alam*

Main category: cs.LG

TL;DR: CMCO框架通过结合蒙特卡洛dropout和分形预测，为神经算子提供无需重新训练或定制损失设计的分布无关预测区间，解决了深度学习在实时虚拟传感中的不确定性量化问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在高风险领域（如稀疏、噪声或非共位传感器数据）中不确定性量化的关键障碍，以实现安全部署。

Method: 提出Conformalized Monte Carlo Operator (CMCO)，结合蒙特卡洛dropout和分形预测，在DeepONet架构中实现空间分辨的不确定性估计。

Result: 在湍流、弹塑性变形和全球宇宙辐射剂量估计三个应用中，CMCO实现了接近名义的覆盖范围，即使在强空间梯度和代理传感条件下。

Conclusion: CMCO为神经算子提供了一种通用、即插即用的不确定性量化解决方案，为可扩展、泛化和不确定性感知的科学机器学习奠定了基础。

Abstract: Robust uncertainty quantification (UQ) remains a critical barrier to the safe
deployment of deep learning in real-time virtual sensing, particularly in
high-stakes domains where sparse, noisy, or non-collocated sensor data are the
norm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework
that transforms neural operator-based virtual sensing with calibrated,
distribution-free prediction intervals. By unifying Monte Carlo dropout with
split conformal prediction in a single DeepONet architecture, CMCO achieves
spatially resolved uncertainty estimates without retraining, ensembling, or
custom loss design. Our method addresses a longstanding challenge: how to endow
operator learning with efficient and reliable UQ across heterogeneous domains.
Through rigorous evaluation on three distinct applications: turbulent flow,
elastoplastic deformation, and global cosmic radiation dose estimation-CMCO
consistently attains near-nominal empirical coverage, even in settings with
strong spatial gradients and proxy-based sensing. This breakthrough offers a
general-purpose, plug-and-play UQ solution for neural operators, unlocking
real-time, trustworthy inference in digital twins, sensor fusion, and
safety-critical monitoring. By bridging theory and deployment with minimal
computational overhead, CMCO establishes a new foundation for scalable,
generalizable, and uncertainty-aware scientific machine learning.

</details>


### [164] [STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics](https://arxiv.org/abs/2507.11660)
*Joao F. Rocha,Ke Xu,Xingzhi Sun,Ananya Krishna,Dhananjay Bhaskar,Blanche Mongeon,Morgan Craig,Mark Gerstein,Smita Krishnaswamy*

Main category: cs.LG

TL;DR: 论文提出了一种结合深度学习和基于代理的建模（ABM）的方法STAGED，用于模拟细胞间通信及其对细胞内基因调控网络的影响，从而更准确地表示细胞动态。


<details>
  <summary>Details</summary>
Motivation: 单细胞技术虽然提升了我们对细胞状态的理解，但现有方法将细胞视为独立数据点，忽略了细胞间动态相互作用。空间转录组学提供了细胞组织信息，但需要计算方法的进步来数据驱动地学习这些复杂的细胞动态。

Method: STAGED方法整合了ABM和深度学习，使用图ODE网络（GDEs）和注意力机制动态学习基因间相互作用强度，模拟细胞间和细胞内动态。

Result: 模型能够匹配模拟和空间转录组学数据推断的连续轨迹，捕捉细胞间和细胞内相互作用，提供更自适应和准确的细胞动态表示。

Conclusion: STAGED方法为数据驱动的细胞动态建模提供了新思路，结合ABM和深度学习的优势，有望推动对复杂细胞系统的理解。

Abstract: The advent of single-cell technology has significantly improved our
understanding of cellular states and subpopulations in various tissues under
normal and diseased conditions by employing data-driven approaches such as
clustering and trajectory inference. However, these methods consider cells as
independent data points of population distributions. With spatial
transcriptomics, we can represent cellular organization, along with dynamic
cell-cell interactions that lead to changes in cell state. Still, key
computational advances are necessary to enable the data-driven learning of such
complex interactive cellular dynamics. While agent-based modeling (ABM)
provides a powerful framework, traditional approaches rely on handcrafted rules
derived from domain knowledge rather than data-driven approaches. To address
this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)
integrating ABM with deep learning to model intercellular communication, and
its effect on the intracellular gene regulatory network. Using graph ODE
networks (GDEs) with shared weights per cell type, our approach represents
genes as vertices and interactions as directed edges, dynamically learning
their strengths through a designed attention mechanism. Trained to match
continuous trajectories of simulated as well as inferred trajectories from
spatial transcriptomics data, the model captures both intercellular and
intracellular interactions, enabling a more adaptive and accurate
representation of cellular dynamics.

</details>


### [165] [Einstein Fields: A Neural Perspective To Computational General Relativity](https://arxiv.org/abs/2507.11589)
*Sandeep Suresh Cranganore,Andrei Bodnar,Arturs Berzins,Johannes Brandstetter*

Main category: cs.LG

TL;DR: Einstein Fields是一种神经表示方法，用于压缩四维数值相对论模拟，通过自动微分推导物理量，具有存储高效、易于使用等优势。


<details>
  <summary>Details</summary>
Motivation: 解决数值相对论模拟中计算密集的问题，提供一种高效的神经表示方法。

Method: 使用神经张量场（Neural Tensor Fields）建模广义相对论的核心张量场（metric），通过自动微分推导物理量。

Result: Einstein Fields在4D时空连续建模、存储效率、导数精度等方面表现出色。

Conclusion: Einstein Fields为数值相对论提供了可扩展且高效的解决方案，并开源了相关代码库。

Abstract: We introduce Einstein Fields, a neural representation that is designed to
compress computationally intensive four-dimensional numerical relativity
simulations into compact implicit neural network weights. By modeling the
\emph{metric}, which is the core tensor field of general relativity, Einstein
Fields enable the derivation of physical quantities via automatic
differentiation. However, unlike conventional neural fields (e.g., signed
distance, occupancy, or radiance fields), Einstein Fields are \emph{Neural
Tensor Fields} with the key difference that when encoding the spacetime
geometry of general relativity into neural field representations, dynamics
emerge naturally as a byproduct. Einstein Fields show remarkable potential,
including continuum modeling of 4D spacetime, mesh-agnosticity, storage
efficiency, derivative accuracy, and ease of use. We address these challenges
across several canonical test beds of general relativity and release an open
source JAX-based library, paving the way for more scalable and expressive
approaches to numerical relativity. Code is made available at
https://github.com/AndreiB137/EinFields

</details>


### [166] [Measuring Informativeness Gap of (Mis)Calibrated Predictors](https://arxiv.org/abs/2507.12094)
*Yiding Feng,Wei Tang*

Main category: cs.LG

TL;DR: 论文提出了一个称为‘信息差距’的新概念，用于比较多个预测模型在下游决策任务中的‘有用性’，并提供了其双重表征和一种新的信息度量方法。


<details>
  <summary>Details</summary>
Motivation: 解决决策者在多个可能校准错误的预测模型中选择更‘有用’模型的问题。

Method: 引入信息差距概念，定义了两个预测器在所有决策任务中的最大归一化收益优势，并提供了其双重表征和一种类似EMD的度量方法。

Result: 信息差距框架泛化了现有概念（如U-Calibration和Calibration Decision Loss），并在完美校准情况下恢复Blackwell信息性。新度量方法满足完整性、可靠性和样本高效性。

Conclusion: 信息差距及其度量方法为比较预测模型的决策有用性提供了统一框架，适用于多种场景。

Abstract: In many applications, decision-makers must choose between multiple predictive
models that may all be miscalibrated. Which model (i.e., predictor) is more
"useful" in downstream decision tasks? To answer this, our first contribution
introduces the notion of the informativeness gap between any two predictors,
defined as the maximum normalized payoff advantage one predictor offers over
the other across all decision-making tasks. Our framework strictly generalizes
several existing notions: it subsumes U-Calibration [KLST-23] and Calibration
Decision Loss [HW-24], which compare a miscalibrated predictor to its
calibrated counterpart, and it recovers Blackwell informativeness [Bla-51,
Bla-53] as a special case when both predictors are perfectly calibrated. Our
second contribution is a dual characterization of the informativeness gap,
which gives rise to a natural informativeness measure that can be viewed as a
relaxed variant of the earth mover's distance (EMD) between two prediction
distributions. We show that this measure satisfies natural desiderata: it is
complete and sound, and it can be estimated sample-efficiently in the
prediction-only access setting. Along the way, we also obtain novel
combinatorial structural results when applying this measure to perfectly
calibrated predictors.

</details>


### [167] [Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques](https://arxiv.org/abs/2507.11590)
*Raju Challagundla,Mohsen Dorodchi,Pu Wang,Minwoo Lee*

Main category: cs.LG

TL;DR: 综述了合成表格数据生成的最新进展，提出基于实际目标的分类法，并强调隐私保护和数据实用性。


<details>
  <summary>Details</summary>
Motivation: 隐私法规趋严，真实数据获取受限，合成数据成为关键解决方案。

Method: 提出基于实际目标的分类法，包括下游应用、隐私保证和数据实用性，并设计基准框架。

Result: 综述了方法以保留复杂特征关系、统计保真度和隐私要求，为未来研究提供路线图。

Conclusion: 该工作为隐私关键环境中合成表格数据的实施提供了指导和未来研究方向。

Abstract: As privacy regulations become more stringent and access to real-world data
becomes increasingly constrained, synthetic data generation has emerged as a
vital solution, especially for tabular datasets, which are central to domains
like finance, healthcare and the social sciences. This survey presents a
comprehensive and focused review of recent advances in synthetic tabular data
generation, emphasizing methods that preserve complex feature relationships,
maintain statistical fidelity, and satisfy privacy requirements. A key
contribution of this work is the introduction of a novel taxonomy based on
practical generation objectives, including intended downstream applications,
privacy guarantees, and data utility, directly informing methodological design
and evaluation strategies. Therefore, this review prioritizes the actionable
goals that drive synthetic data creation, including conditional generation and
risk-sensitive modeling. Additionally, the survey proposes a benchmark
framework to align technical innovation with real-world demands. By bridging
theoretical foundations with practical deployment, this work serves as both a
roadmap for future research and a guide for implementing synthetic tabular data
in privacy-critical environments.

</details>


### [168] [A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning](https://arxiv.org/abs/2507.12439)
*Daniel Commey,Rebecca A. Sarpong,Griffith S. Klogo,Winful Bagyl-Bac,Garth V. Crosby*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级的贝叶斯激励机制，通过经济手段主动防御联邦学习中的数据投毒攻击，确保恶意行为在经济上不理性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的开放参与特性使其容易受到数据投毒攻击，现有防御方法多为被动且计算成本高，假设诚实参与者占多数。

Method: 设计了一种贝叶斯激励机制，将每轮训练建模为不完全信息的贝叶斯博弈，服务器通过小型验证数据集验证更新质量并发放奖励。

Result: 在MNIST和FashionMNIST的非独立同分布数据上实验表明，该机制在50%标签翻转攻击下仍保持96.7%准确率，显著优于标准FedAvg。

Conclusion: 该机制计算轻量、预算可控，易于集成到现有联邦学习框架中，为经济稳健和可持续的联邦学习生态系统提供了实用方案。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy. However, its
open-participation nature exposes it to data-poisoning attacks, in which
malicious actors submit corrupted model updates to degrade the global model.
Existing defenses are often reactive, relying on statistical aggregation rules
that can be computationally expensive and that typically assume an honest
majority. This paper introduces a proactive, economic defense: a lightweight
Bayesian incentive mechanism that makes malicious behavior economically
irrational. Each training round is modeled as a Bayesian game of incomplete
information in which the server, acting as the principal, uses a small, private
validation dataset to verify update quality before issuing payments. The design
satisfies Individual Rationality (IR) for benevolent clients, ensuring their
participation is profitable, and Incentive Compatibility (IC), making poisoning
an economically dominated strategy. Extensive experiments on non-IID partitions
of MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping
adversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3
percentage points lower than in a scenario with 30% label-flipping adversaries.
This outcome is 51.7 percentage points better than standard FedAvg, which
collapses under the same 50% attack. The mechanism is computationally light,
budget-bounded, and readily integrates into existing FL frameworks, offering a
practical route to economically robust and sustainable FL ecosystems.

</details>


### [169] [Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification](https://arxiv.org/abs/2507.11620)
*Steven Dillmann,Juan Rafael Martínez-Galarza*

Main category: cs.LG

TL;DR: 论文提出了一种用于不规则事件时间序列的新型张量表示方法，结合稀疏自编码器提取物理意义明确的潜在表示，支持多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 事件时间序列在多个领域中常见，但其非结构化和不规则性使得传统方法难以提取有意义模式。

Method: 提出二维和三维张量表示方法，结合稀疏自编码器学习潜在表示。

Result: 在X射线天文学数据集上验证，成功捕捉时间和光谱特征，并分类不同X射线瞬变事件。

Conclusion: 该框架为跨领域复杂事件时间序列分析提供了灵活、可扩展且通用的解决方案。

Abstract: Event time series are sequences of discrete events occurring at irregular
time intervals, each associated with a domain-specific observational modality.
They are common in domains such as high-energy astrophysics, computational
social science, cybersecurity, finance, healthcare, neuroscience, and
seismology. Their unstructured and irregular structure poses significant
challenges for extracting meaningful patterns and identifying salient phenomena
using conventional techniques. We propose novel two- and three-dimensional
tensor representations for event time series, coupled with sparse autoencoders
that learn physically meaningful latent representations. These embeddings
support a variety of downstream tasks, including anomaly detection,
similarity-based retrieval, semantic clustering, and unsupervised
classification. We demonstrate our approach on a real-world dataset from X-ray
astronomy, showing that these representations successfully capture temporal and
spectral signatures and isolate diverse classes of X-ray transients. Our
framework offers a flexible, scalable, and generalizable solution for analyzing
complex, irregular event time series across scientific and industrial domains.

</details>


### [170] [Deep Generative Methods and Tire Architecture Design](https://arxiv.org/abs/2507.11639)
*Fouad Oubari,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 该论文研究了五种深度生成模型在工业轮胎架构生成任务中的表现，发现扩散模型整体表现最佳，并提出了分类修复方法以支持条件生成。


<details>
  <summary>Details</summary>
Motivation: 解决工业实践中关于哪种深度生成模型最适合复杂制造设计任务的问题。

Method: 评估了五种模型（VAE、GAN、MMVAE、DDPM、MDM）在三种工业场景中的表现，并提出了分类修复方法。

Result: 扩散模型整体表现最佳，MDM在分布内表现最好，DDPM在分布外泛化能力更强。

Conclusion: 扩散模型在工业设计任务中具有优势，分类修复方法有效支持条件生成。

Abstract: As deep generative models proliferate across the AI landscape, industrial
practitioners still face critical yet unanswered questions about which deep
generative models best suit complex manufacturing design tasks. This work
addresses this question through a complete study of five representative models
(Variational Autoencoder, Generative Adversarial Network, multimodal
Variational Autoencoder, Denoising Diffusion Probabilistic Model, and
Multinomial Diffusion Model) on industrial tire architecture generation. Our
evaluation spans three key industrial scenarios: (i) unconditional generation
of complete multi-component designs, (ii) component-conditioned generation
(reconstructing architectures from partial observations), and (iii)
dimension-constrained generation (creating designs that satisfy specific
dimensional requirements). To enable discrete diffusion models to handle
conditional scenarios, we introduce categorical inpainting, a mask-aware
reverse diffusion process that preserves known labels without requiring
additional training. Our evaluation employs geometry-aware metrics specifically
calibrated for industrial requirements, quantifying spatial coherence,
component interaction, structural connectivity, and perceptual fidelity. Our
findings reveal that diffusion models achieve the strongest overall
performance; a masking-trained VAE nonetheless outperforms the multimodal
variant MMVAE\textsuperscript{+} on nearly all component-conditioned metrics,
and within the diffusion family MDM leads in-distribution whereas DDPM
generalises better to out-of-distribution dimensional constraints.

</details>


### [171] [Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation](https://arxiv.org/abs/2507.11645)
*Ahmed Salah,David Yevick*

Main category: cs.LG

TL;DR: 本文提出了几种实用指标（如dropout下的方差、鲁棒性、嵌入相似性和稀疏性度量），用于预测神经网络中的“grokking”行为（即延迟泛化现象）。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络在训练过程中表现出的“grokking”行为，即测试准确率显著滞后于训练准确率提升的现象，旨在通过量化指标提前预测和解释这一行为。

Method: 通过Dropout鲁棒性曲线（DRC）估计神经网络对推理噪声的鲁棒性，同时分析测试准确率在随机dropout下的方差、神经元激活比例及嵌入分布的变化。

Result: 发现grokking过程中测试准确率方差出现局部最大值，神经元激活比例下降，嵌入分布趋于双峰且与数据集对称性相关。

Conclusion: 提出的指标不仅能够预测grokking行为，还揭示了其起源和动态特征，为理解神经网络泛化机制提供了新视角。

Abstract: Grokking refers to delayed generalization in which the increase in test
accuracy of a neural network occurs appreciably after the improvement in
training accuracy This paper introduces several practical metrics including
variance under dropout, robustness, embedding similarity, and sparsity
measures, that can forecast grokking behavior. Specifically, the resilience of
neural networks to noise during inference is estimated from a Dropout
Robustness Curve (DRC) obtained from the variation of the accuracy with the
dropout rate as the model transitions from memorization to generalization. The
variance of the test accuracy under stochastic dropout across training
checkpoints further exhibits a local maximum during the grokking. Additionally,
the percentage of inactive neurons decreases during generalization, while the
embeddings tend to a bimodal distribution independent of initialization that
correlates with the observed cosine similarity patterns and dataset symmetries.
These metrics additionally provide valuable insight into the origin and
behaviour of grokking.

</details>


### [172] [ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs](https://arxiv.org/abs/2507.11649)
*Daniel Commey,Benjamin Appiah,Griffith S. Klogo,Garth V. Crosby*

Main category: cs.LG

TL;DR: 提出了一种基于零知识证明（ZKP）的联邦学习隐私保护评估协议，避免通过性能指标泄露敏感信息。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的评估阶段可能通过共享性能指标泄露敏感信息，需要一种隐私保护且可验证的评估方法。

Method: 使用零知识证明生成简洁证明，断言本地损失低于预设阈值，无需依赖外部API，包含联邦学习模拟、ZKP电路设计和实验评估。

Result: 在MNIST和HAR数据集上测试了CNN和MLP模型，评估了计算开销、通信成本和可验证性。

Conclusion: 提出的协议在保护隐私的同时实现了可验证的联邦学习评估。

Abstract: Federated Learning (FL) enables collaborative model training on decentralized
data without exposing raw data. However, the evaluation phase in FL may leak
sensitive information through shared performance metrics. In this paper, we
propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to
enable privacy-preserving and verifiable evaluation for FL. Instead of
revealing raw loss values, clients generate a succinct proof asserting that
their local loss is below a predefined threshold. Our approach is implemented
without reliance on external APIs, using self-contained modules for federated
learning simulation, ZKP circuit design, and experimental evaluation on both
the MNIST and Human Activity Recognition (HAR) datasets. We focus on a
threshold-based proof for a simple Convolutional Neural Network (CNN) model
(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate
the approach in terms of computational overhead, communication cost, and
verifiability.

</details>


### [173] [Composing Linear Layers from Irreducibles](https://arxiv.org/abs/2507.11688)
*Travis Pence,Daisuke Yamada,Vikas Singh*

Main category: cs.LG

TL;DR: 论文研究了线性层中的几何基元（如双向量）如何组合成更高级功能，提出一种基于Clifford代数的可微分算法，将线性层分解为转子乘积，参数效率更高。


<details>
  <summary>Details</summary>
Motivation: 当前大模型的行为表明存在由低层基元组合成的模块，但这些基元的本质尚不明确。本文旨在探索线性层中的几何基元及其组合方式。

Method: 使用Clifford代数将线性层表示为双向量（编码定向平面的几何对象）的组合，并提出一种可微分算法将其分解为转子乘积，参数复杂度为O(log^2 d)。

Result: 在LLM注意力层的键、查询和值投影中，基于转子的层与块Hadamard和低秩近似等基线性能相当。

Conclusion: 研究提供了几何基元如何组合为深度学习模型中高级功能的代数视角，参数效率显著优于传统方法。

Abstract: Contemporary large models often exhibit behaviors suggesting the presence of
low-level primitives that compose into modules with richer functionality, but
these fundamental building blocks remain poorly understood. We investigate this
compositional structure in linear layers by asking: can we identify/synthesize
linear transformations from a minimal set of geometric primitives? Using
Clifford algebra, we show that linear layers can be expressed as compositions
of bivectors -- geometric objects encoding oriented planes -- and introduce a
differentiable algorithm that decomposes them into products of rotors. This
construction uses only O(log^2 d) parameters, versus O(d^2) required by dense
matrices. Applied to the key, query, and value projections in LLM attention
layers, our rotor-based layers match the performance of strong baselines such
as block-Hadamard and low-rank approximations. Our findings provide an
algebraic perspective on how these geometric primitives can compose into
higher-level functions within deep models.

</details>


### [174] [The Impact of Coreset Selection on Spurious Correlations and Group Robustness](https://arxiv.org/abs/2507.11690)
*Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky*

Main category: cs.LG

TL;DR: 本文分析了数据集缩减方法（如核心集选择）对模型偏见的影响，发现某些方法可能无意中加剧偏见，而基于嵌入的样本评分方法风险较低。然而，即使选择方法能降低偏见，也无法保证下游模型的稳健性。


<details>
  <summary>Details</summary>
Motivation: 研究数据集缩减方法如何影响模型中的偏见，以促进数据高效机器学习的同时避免偏见放大。

Method: 在十个不同的虚假相关性基准上，结合五种评分指标和五种数据选择策略，全面分析核心集选择对偏见水平的影响。

Result: 基于嵌入的样本评分方法比基于学习动态的方法更不易加剧偏见，但降低偏见并不总能保证模型稳健性。

Conclusion: 核心集选择方法需谨慎设计以避免偏见放大，且降低偏见与模型稳健性之间无必然联系。

Abstract: Coreset selection methods have shown promise in reducing the training data
size while maintaining model performance for data-efficient machine learning.
However, as many datasets suffer from biases that cause models to learn
spurious correlations instead of causal features, it is important to understand
whether and how dataset reduction methods may perpetuate, amplify, or mitigate
these biases. In this work, we conduct the first comprehensive analysis of the
implications of data selection on the spurious bias levels of the selected
coresets and the robustness of downstream models trained on them. We use an
extensive experimental setting spanning ten different spurious correlations
benchmarks, five score metrics to characterize sample importance/ difficulty,
and five data selection policies across a broad range of coreset sizes.
Thereby, we unravel a series of nontrivial nuances in interactions between
sample difficulty and bias alignment, as well as dataset bias and resultant
model robustness. For example, we find that selecting coresets using
embedding-based sample characterization scores runs a comparatively lower risk
of inadvertently exacerbating bias than selecting using characterizations based
on learning dynamics. Most importantly, our analysis reveals that although some
coreset selection methods could achieve lower bias levels by prioritizing
difficult samples, they do not reliably guarantee downstream robustness.

</details>


### [175] [Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption](https://arxiv.org/abs/2507.11702)
*Hein de Wilde,Ali Mohammed Mansoor Alsahag,Pierre Blanchet*

Main category: cs.LG

TL;DR: 英国铁路因落叶导致交通中断，每年损失超3亿英镑。本研究利用LSTM网络和卫星数据，开发了一个可扩展且可靠的落叶时间预测系统，误差分别为6.32天（开始）和9.31天（结束）。


<details>
  <summary>Details</summary>
Motivation: 落叶导致铁路运营中断，每年损失巨大，现有预测方法在可扩展性和可靠性上存在不足。

Method: 结合地面真实落叶数据、多光谱和气象卫星数据，训练LSTM网络进行预测。

Result: 预测落叶开始和结束的均方根误差分别为6.32天和9.31天，优于先前研究。

Conclusion: 该模型为铁路行业优化落叶缓解措施提供了新机会，并有助于理解复杂生态系统。

Abstract: Railroad traffic disruption as a result of leaf-fall cost the UK rail
industry over 300 million per year and measures to mitigate such disruptions
are employed on a large scale, with 1.67 million kilometers of track being
treated in the UK in 2021 alone. Therefore, the ability to anticipate the
timing of leaf-fall would offer substantial benefits for rail network
operators, enabling the efficient scheduling of such mitigation measures.
However, current methodologies for predicting leaf-fall exhibit considerable
limitations in terms of scalability and reliability. This study endeavors to
devise a prediction system that leverages specialized prediction methods and
the latest satellite data sources to generate both scalable and reliable
insights into leaf-fall timings. An LSTM network trained on ground-truth
leaf-falling data combined with multispectral and meteorological satellite data
demonstrated a root-mean-square error of 6.32 days for predicting the start of
leaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which
improves upon previous work on the topic, offers promising opportunities for
the optimization of leaf mitigation measures in the railway industry and the
improvement of our understanding of complex ecological systems.

</details>


### [176] [Reinforcement Learning from Adversarial Preferences in Tabular MDPs](https://arxiv.org/abs/2507.11706)
*Taira Tsuchiya,Shinji Ito,Haipeng Luo*

Main category: cs.LG

TL;DR: 该论文提出了基于偏好的马尔可夫决策过程（PbMDPs）框架，专注于Borda分数下的偏好设置，并提出了相应的遗憾下界和算法。


<details>
  <summary>Details</summary>
Motivation: 研究在偏好而非直接数值损失下的MDP问题，填补了标准MDP与偏好学习之间的空白。

Method: 通过在线线性优化和策略优化算法，分别在已知和未知转移概率下实现遗憾上界。

Result: 证明了PbMDPs的遗憾下界为Ω((H²SK)^(1/3)T^(2/3))，并提出了达到O(T^(2/3))遗憾的算法。

Conclusion: 论文为偏好学习的MDP问题提供了理论基础和实用算法，但仍有计算效率上的改进空间。

Abstract: We introduce a new framework of episodic tabular Markov decision processes
(MDPs) with adversarial preferences, which we refer to as preference-based MDPs
(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the
numerical value of the loss is directly observed, in PbMDPs the learner instead
observes preferences between two candidate arms, which represent the choices
being compared. In this work, we focus specifically on the setting where the
reward functions are determined by Borda scores. We begin by establishing a
regret lower bound for PbMDPs with Borda scores. As a preliminary step, we
present a simple instance to prove a lower bound of $\Omega(\sqrt{HSAT})$ for
episodic MDPs with adversarial losses, where $H$ is the number of steps per
episode, $S$ is the number of states, $A$ is the number of actions, and $T$ is
the number of episodes. Leveraging this construction, we then derive a regret
lower bound of $\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda
scores, where $K$ is the number of arms. Next, we develop algorithms that
achieve a regret bound of order $T^{2/3}$. We first propose a global
optimization approach based on online linear optimization over the set of all
occupancy measures, achieving a regret bound of $\tilde{O}((H^2 S^2 K)^{1/3}
T^{2/3} )$ under known transitions. However, this approach suffers from
suboptimal dependence on the potentially large number of states $S$ and
computational inefficiency. To address this, we propose a policy optimization
algorithm whose regret is roughly bounded by $\tilde{O}( (H^6 S K^5)^{1/3}
T^{2/3} )$ under known transitions, and further extend the result to the
unknown-transition setting.

</details>


### [177] [Subgraph Generation for Generalizing on Out-of-Distribution Links](https://arxiv.org/abs/2507.11710)
*Jay Revolinsky,Harry Shomer,Jiliang Tang*

Main category: cs.LG

TL;DR: FLEX是一个图生成模型框架，通过结构条件生成和对抗训练提升图神经网络在分布外场景下的链接预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络在链接预测任务中表现良好，但依赖同分布数据；图生成模型虽能生成新图，但应用受限。FLEX旨在填补这一空白。

Method: FLEX结合结构条件生成和对抗训练（自动编码器与图神经网络协同训练），确保样本分布的结构对齐。

Result: 实验证明FLEX在合成和真实分布外场景中提升性能，无需专家知识。

Conclusion: FLEX通过数据增强和结构对齐，有效提升分布外链接预测性能。

Abstract: Graphs Neural Networks (GNNs) demonstrate high-performance on the link
prediction (LP) task. However, these models often rely on all dataset samples
being drawn from the same distribution. In addition, graph generative models
(GGMs) show a pronounced ability to generate novel output graphs. Despite this,
GGM applications remain largely limited to domain-specific tasks. To bridge
this gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)
structurally-conditioned graph generation, and (2) adversarial co-training
between an auto-encoder and GNN. As such, FLEX ensures structural-alignment
between sample distributions to enhance link-prediction performance in
out-of-distribution (OOD) scenarios. Notably, FLEX does not require expert
knowledge to function in different OOD scenarios. Numerous experiments are
conducted in synthetic and real-world OOD settings to demonstrate FLEX's
performance-enhancing ability, with further analysis for understanding the
effects of graph data augmentation on link structures. The source code is
available here: https://github.com/revolins/FlexOOD.

</details>


### [178] [Globalization for Scalable Short-term Load Forecasting](https://arxiv.org/abs/2507.11729)
*Amirhossein Ahmadi,Hamidreza Zareipour,Henry Leung*

Main category: cs.LG

TL;DR: 论文探讨了电力传输网络中负荷预测的全局模型（GFMs）相对于传统局部模型（LFMs）的优势，特别是在处理数据漂移、可扩展性和泛化能力方面。通过实验验证了全局目标转换模型在性能上的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统局部预测模型在泛化性、数据漂移和冷启动问题上存在局限性，而全局模型通过跨学习和全球化提供了更优的解决方案。

Method: 研究了特征转换和目标转换模型，提出了基于时间序列聚类（TSC）的方法，分别针对不同类型模型设计了聚类策略。

Result: 全局目标转换模型在实验中表现优于局部模型，而全局特征转换模型需要TSC来有效处理数据异质性。

Conclusion: 全局目标转换模型在负荷预测中更具优势，而特征转换模型需结合聚类技术以平衡局部与全局动态。

Abstract: Forecasting load in power transmission networks is essential across various
hierarchical levels, from the system level down to individual points of
delivery (PoD). While intuitive and locally accurate, traditional local
forecasting models (LFMs) face significant limitations, particularly in
handling generalizability, overfitting, data drift, and the cold start problem.
These methods also struggle with scalability, becoming computationally
expensive and less efficient as the network's size and data volume grow. In
contrast, global forecasting models (GFMs) offer a new approach to enhance
prediction generalizability, scalability, accuracy, and robustness through
globalization and cross-learning. This paper investigates global load
forecasting in the presence of data drifts, highlighting the impact of
different modeling techniques and data heterogeneity. We explore
feature-transforming and target-transforming models, demonstrating how
globalization, data heterogeneity, and data drift affect each differently. In
addition, we examine the role of globalization in peak load forecasting and its
potential for hierarchical forecasting. To address data heterogeneity and the
balance between globality and locality, we propose separate time series
clustering (TSC) methods, introducing model-based TSC for feature-transforming
models and new weighted instance-based TSC for target-transforming models.
Through extensive experiments on a real-world dataset of Alberta's electricity
load, we demonstrate that global target-transforming models consistently
outperform their local counterparts, especially when enriched with global
features and clustering techniques. In contrast, global feature-transforming
models face challenges in balancing local and global dynamics, often requiring
TSC to manage data heterogeneity effectively.

</details>


### [179] [Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning](https://arxiv.org/abs/2507.11732)
*Shiyu Chen,Cencheng Shen,Youngser Park,Carey E. Priebe*

Main category: cs.LG

TL;DR: 论文提出了一种基于统计方法（GEE）的图神经网络（GNN）初始化特征生成方法，显著提升了GNN的性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统GNN依赖随机或低信息量的初始特征表示，导致收敛慢且性能不佳。论文旨在通过统计方法改进初始特征，提升GNN效果。

Method: 使用one-hot图编码器嵌入（GEE）生成高质量初始节点特征，并集成到GNN框架中（GG）。在无监督和有监督任务中验证其有效性。

Result: 在节点聚类任务中，GG在所有评估的真实数据集上表现最佳；在节点分类任务中，改进版GG-C进一步提升了性能。

Conclusion: 结构感知的特征初始化对发挥GNN潜力至关重要，GEE方法为GNN提供了更优的初始特征。

Abstract: Graph neural networks (GNNs) have emerged as a powerful framework for a wide
range of node-level graph learning tasks. However, their performance is often
constrained by reliance on random or minimally informed initial feature
representations, which can lead to slow convergence and suboptimal solutions.
In this paper, we leverage a statistically grounded method, one-hot graph
encoder embedding (GEE), to generate high-quality initial node features that
enhance the end-to-end training of GNNs. We refer to this integrated framework
as the GEE-powered GNN (GG), and demonstrate its effectiveness through
extensive simulations and real-world experiments across both unsupervised and
supervised settings. In node clustering, GG consistently achieves
state-of-the-art performance, ranking first across all evaluated real-world
datasets, while exhibiting faster convergence compared to the standard GNN. For
node classification, we further propose an enhanced variant, GG-C, which
concatenates the outputs of GG and GEE and outperforms competing baselines.
These results confirm the importance of principled, structure-aware feature
initialization in realizing the full potential of GNNs.

</details>


### [180] [Sparse Identification of Nonlinear Dynamics with Conformal Prediction](https://arxiv.org/abs/2507.11739)
*Urban Fasel*

Main category: cs.LG

TL;DR: 论文提出了一种将Conformal Prediction与Ensemble-SINDy（E-SINDy）结合的方法，用于量化SINDy模型的不确定性，并在时间序列预测、模型选择和模型系数不确定性方面展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 量化SINDy模型的不确定性对于评估其可靠性至关重要，尤其是在安全关键应用中。

Method: 通过集成Conformal Prediction框架与E-SINDy，提出了三种应用：时间序列预测的不确定性量化、基于特征重要性的模型选择以及模型系数的不确定性量化。

Result: 在随机捕食者-猎物动力学和混沌动力系统中，该方法能够可靠地实现目标覆盖范围，有效量化特征重要性，并在非高斯噪声下生成更稳健的模型系数不确定性区间。

Conclusion: Conformal Prediction与E-SINDy的结合能够显著提升模型的不确定性量化能力，适用于复杂动态系统的建模。

Abstract: The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for
discovering nonlinear dynamical system models from data. Quantifying
uncertainty in SINDy models is essential for assessing their reliability,
particularly in safety-critical applications. While various uncertainty
quantification methods exist for SINDy, including Bayesian and ensemble
approaches, this work explores the integration of Conformal Prediction, a
framework that can provide valid prediction intervals with coverage guarantees
based on minimal assumptions like data exchangeability. We introduce three
applications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)
quantifying uncertainty in time series prediction, (2) model selection based on
library feature importance, and (3) quantifying the uncertainty of identified
model coefficients using feature conformal prediction. We demonstrate the three
applications on stochastic predator-prey dynamics and several chaotic dynamical
systems. We show that conformal prediction methods integrated with E-SINDy can
reliably achieve desired target coverage for time series forecasting,
effectively quantify feature importance, and produce more robust uncertainty
intervals for model coefficients, even under non-Gaussian noise, compared to
standard E-SINDy coefficient estimates.

</details>


### [181] [RadioDiff-3D: A 3D$\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication](https://arxiv.org/abs/2507.12166)
*Xiucheng Wang,Qiming Zhang,Nan Cheng,Junting Chen,Zezhong Zhang,Zan Li,Shuguang Cui,Xuemin Shen*

Main category: cs.LG

TL;DR: 论文提出UrbanRadio3D数据集和RadioDiff-3D方法，用于构建高分辨率3D无线电地图，解决了现有方法在方向、时间和垂直空间变化上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图构建方法局限于2D平面和静态学习范式，无法捕捉方向、时间和垂直空间变化等关键参数。

Method: 通过射线追踪构建大规模高分辨率3D数据集UrbanRadio3D，并提出基于3D卷积的UNet和扩散模型RadioDiff-3D。

Result: RadioDiff-3D在多样环境动态下构建高维无线电地图表现优异，数据集规模远超现有SOTA。

Conclusion: 该工作为3D环境感知通信研究提供了基础数据集和基准方法。

Abstract: Radio maps (RMs) serve as a critical foundation for enabling
environment-aware wireless communication, as they provide the spatial
distribution of wireless channel characteristics. Despite recent progress in RM
construction using data-driven approaches, most existing methods focus solely
on pathloss prediction in a fixed 2D plane, neglecting key parameters such as
direction of arrival (DoA), time of arrival (ToA), and vertical spatial
variations. Such a limitation is primarily due to the reliance on static
learning paradigms, which hinder generalization beyond the training data
distribution. To address these challenges, we propose UrbanRadio3D, a
large-scale, high-resolution 3D RM dataset constructed via ray tracing in
realistic urban environments. UrbanRadio3D is over 37$\times$3 larger than
previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,
forming a novel 3D$\times$33D dataset with 7$\times$3 more height layers than
prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet
with 3D convolutional operators is proposed. Moreover, we further introduce
RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D
convolutional architecture. RadioDiff-3D supports both radiation-aware
scenarios with known transmitter locations and radiation-unaware settings based
on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate
that RadioDiff-3D achieves superior performance in constructing rich,
high-dimensional radio maps under diverse environmental dynamics. This work
provides a foundational dataset and benchmark for future research in 3D
environment-aware communication. The dataset is available at
https://github.com/UNIC-Lab/UrbanRadio3D.

</details>


### [182] [MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory](https://arxiv.org/abs/2507.11821)
*Pouya Shaeri,Arash Karimi,Ariane Middel*

Main category: cs.LG

TL;DR: MNIST-Gen是一个自动化、模块化和自适应的框架，用于生成用户指定类别的MNIST风格数据集，解决了领域特定任务中标准数据集不足的问题。


<details>
  <summary>Details</summary>
Motivation: 标准数据集（如MNIST）对领域特定任务（如树木或食品分类）不适用，而创建自定义数据集耗时且法律受限。

Method: 结合CLIP语义理解、强化学习和人类反馈，采用分层语义分类和可组合的态射模型。

Result: 生成的两个新数据集（Tree-MNIST和Food-MNIST）实现了85%的自动分类准确率和80%的时间节省。

Conclusion: MNIST-Gen为任务特定评估数据提供高效解决方案，具有模块化和扩展性优势。

Abstract: Neural networks are often benchmarked using standard datasets such as MNIST,
FashionMNIST, or other variants of MNIST, which, while accessible, are limited
to generic classes such as digits or clothing items. For researchers working on
domain-specific tasks, such as classifying trees, food items, or other
real-world objects, these data sets are insufficient and irrelevant.
Additionally, creating and publishing a custom dataset can be time consuming,
legally constrained, or beyond the scope of individual projects. We present
MNIST-Gen, an automated, modular, and adaptive framework for generating
MNIST-style image datasets tailored to user-specified categories using
hierarchical semantic categorization. The system combines CLIP-based semantic
understanding with reinforcement learning and human feedback to achieve
intelligent categorization with minimal manual intervention. Our hierarchical
approach supports complex category structures with semantic characteristics,
enabling fine-grained subcategorization and multiple processing modes:
individual review for maximum control, smart batch processing for large
datasets, and fast batch processing for rapid creation. Inspired by category
theory, MNIST-Gen models each data transformation stage as a composable
morphism, enhancing clarity, modularity, and extensibility. As proof of
concept, we generate and benchmark two novel datasets-\textit{Tree-MNIST} and
\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing
task-specific evaluation data while achieving 85\% automatic categorization
accuracy and 80\% time savings compared to manual approaches.

</details>


### [183] [A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction](https://arxiv.org/abs/2507.11757)
*Yuehua Song,Yong Gao*

Main category: cs.LG

TL;DR: 提出了一种名为Graph-in-Graph（GiG）的新框架，结合转导学习和归纳学习，有效整合药物和靶点的分子特征及其相互作用，显著提升了药物-靶点相互作用预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络（GNN）的方法在药物-靶点相互作用（DTI）预测中难以有效整合药物、靶点及其相互作用的多样化特征。

Method: 提出GiG模型，将药物和靶点的分子结构图表示为药物-靶点相互作用图中的元节点，结合转导学习和归纳学习，探索其复杂关系。

Result: GiG模型在多个评估指标上显著优于现有方法，证明了整合不同学习范式和相互作用数据的优势。

Conclusion: GiG框架通过整合分子水平和网络水平的特征，为DTI预测提供了更有效的解决方案。

Abstract: Accurately predicting drug-target interactions (DTIs) is pivotal for
advancing drug discovery and target validation techniques. While machine
learning approaches including those that are based on Graph Neural Networks
(GNN) have achieved notable success in DTI prediction, many of them have
difficulties in effectively integrating the diverse features of drugs, targets
and their interactions. To address this limitation, we introduce a novel
framework to take advantage of the power of both transductive learning and
inductive learning so that features at molecular level and drug-target
interaction network level can be exploited. Within this framework is a
GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and
target molecular structures as meta-nodes in a drug-target interaction graph,
enabling a detailed exploration of their intricate relationships. To evaluate
the proposed model, we have compiled a special benchmark comprising drug
SMILES, protein sequences, and their interaction data, which is interesting in
its own right. Our experimental results demonstrate that the GiG model
significantly outperforms existing approaches across all evaluation metrics,
highlighting the benefits of integrating different learning paradigms and
interaction data.

</details>


### [184] [Selective Quantization Tuning for ONNX Models](https://arxiv.org/abs/2507.12196)
*Nikolaos Louloudakis,Ajitha Rajan*

Main category: cs.LG

TL;DR: TuneQn是一个工具套件，用于选择性量化、部署和执行ONNX模型，通过多目标优化和性能分析，显著减少精度损失和模型大小。


<details>
  <summary>Details</summary>
Motivation: 完全量化的模型可能在精度和硬件部署上表现不佳，因此需要一种选择性量化的方法来解决这些问题。

Method: TuneQn结合选择性量化、部署、执行、性能分析和多目标优化，生成并评估量化模型。

Result: 实验表明，TuneQn能减少54.14%的精度损失和72.9%的模型大小。

Conclusion: TuneQn有效解决了选择性量化问题，优化了模型性能和部署效率。

Abstract: Quantization is a process that reduces the precision of deep neural network
models to lower model size and computational demands, often at the cost of
accuracy. However, fully quantized models may exhibit sub-optimal performance
below acceptable levels and face deployment challenges on low-end hardware
accelerators due to practical constraints. To address these issues,
quantization can be selectively applied to only a subset of layers, but
selecting which layers to exclude is non-trivial. To this direction, we propose
TuneQn, a suite enabling selective quantization, deployment and execution of
ONNX models across various CPU and GPU devices, combined with profiling and
multi-objective optimization. TuneQn generates selectively quantized ONNX
models, deploys them on different hardware, measures performance on metrics
like accuracy and size, performs Pareto Front minimization to identify the best
model candidate and visualizes the results. To demonstrate the effectiveness of
TuneQn, we evaluated TuneQn on four ONNX models with two quantization settings
across CPU and GPU devices. As a result, we demonstrated that our utility
effectively performs selective quantization and tuning, selecting ONNX model
candidates with up to a $54.14$% reduction in accuracy loss compared to the
fully quantized model, and up to a $72.9$% model size reduction compared to the
original model.

</details>


### [185] [Torsional-GFN: a conditional conformation generator for small molecules](https://arxiv.org/abs/2507.11759)
*Alexandra Volokhova,Léna Néhale Ezzine,Piotr Gaiński,Luca Scimeca,Emmanuel Bengio,Prudencio Tossou,Yoshua Bengio,Alex Hernandez-Garcia*

Main category: cs.LG

TL;DR: Torsional-GFN是一种基于GFlowNet的生成模型，用于高效采样分子构象，近似玻尔兹曼分布，并实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 分子构象的稳定生成对药物发现至关重要，传统方法如分子动力学效率较低，需要更高效的方法。

Method: 提出Torsional-GFN，一种条件GFlowNet，通过奖励函数训练，采样分子扭转角旋转，生成构象。

Result: Torsional-GFN能近似玻尔兹曼分布采样构象，并实现零样本泛化到未见过的键长和键角。

Conclusion: 该方法为扩展到更大分子系统和零样本泛化提供了可能，未来可进一步生成局部结构。

Abstract: Generating stable molecular conformations is crucial in several drug
discovery applications, such as estimating the binding affinity of a molecule
to a target. Recently, generative machine learning methods have emerged as a
promising, more efficient method than molecular dynamics for sampling of
conformations from the Boltzmann distribution. In this paper, we introduce
Torsional-GFN, a conditional GFlowNet specifically designed to sample
conformations of molecules proportionally to their Boltzmann distribution,
using only a reward function as training signal. Conditioned on a molecular
graph and its local structure (bond lengths and angles), Torsional-GFN samples
rotations of its torsion angles. Our results demonstrate that Torsional-GFN is
able to sample conformations approximately proportional to the Boltzmann
distribution for multiple molecules with a single model, and allows for
zero-shot generalization to unseen bond lengths and angles coming from the MD
simulations for such molecules. Our work presents a promising avenue for
scaling the proposed approach to larger molecular systems, achieving zero-shot
generalization to unseen molecules, and including the generation of the local
structure into the GFlowNet model.

</details>


### [186] [Scaling laws for activation steering with Llama 2 models and refusal mechanisms](https://arxiv.org/abs/2507.11771)
*Sheikh Abdur Raheem Ali,Justin Xu,Ivory Yang,Jasmine Xinze Li,Ayse Arslan,Clark Benham*

Main category: cs.LG

TL;DR: 本文研究了对比激活加法（CAA）在不同规模的Llama 2模型（7B、13B、70B）中的有效性，发现CAA在早期到中间层效果最佳，但随着模型规模增大效果减弱，且负面导向比正面导向影响更显著。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的复杂性和能力提升，较少广泛部署的对齐技术的有效性尚不明确。本文旨在探索CAA在不同模型规模下的表现。

Method: 通过对比激活加法（CAA）在Llama 2模型家族（7B、13B、70B）中的应用，利用对比对（如从仇恨到爱）在残差流向量空间中寻找理想方向，并在前向传播中添加到残差流中。

Result: 研究发现：1）CAA在早期到中间层效果最佳；2）CAA的效果随模型规模增大而减弱；3）负面导向比正面导向在所有模型规模中影响更显著。

Conclusion: CAA的有效性受模型规模和层位置影响，负面导向效果更强，为语言模型的对齐技术提供了新见解。

Abstract: As large language models (LLMs) evolve in complexity and capability, the
efficacy of less widely deployed alignment techniques are uncertain. Building
on previous work on activation steering and contrastive activation addition
(CAA), this paper explores the effectiveness of CAA with model scale using the
family of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable
'directions' in the model's residual stream vector space using contrastive
pairs (for example, hate to love) and adding this direction to the residual
stream during the forward pass. It directly manipulates the residual stream and
aims to extract features from language models to better control their outputs.
Using answer matching questions centered around the refusal behavior, we found
that 1) CAA is most effective when applied at early-mid layers. 2) The
effectiveness of CAA diminishes with model size. 3) Negative steering has more
pronounced effects than positive steering across all model sizes.

</details>


### [187] [Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network](https://arxiv.org/abs/2507.11776)
*Merel Kampere,Ali Mohammed Mansoor Alsahag*

Main category: cs.LG

TL;DR: 该研究使用XGBoost分类器结合拓扑特征预测荷兰铁路网络延误，发现现有方法在非同步测试中表现有限，需进一步改进。


<details>
  <summary>Details</summary>
Motivation: 荷兰铁路网络是全球最繁忙的之一，延误问题突出，现有研究多关注短期预测，忽略了网络范围的模式。

Method: 采用XGBoost分类器，整合节点中心性度量，并比较多种分类器（如随机森林、决策树等），预测延误轨迹。

Result: 结果显示性能有限，尤其在非同步测试中，表明需要更多上下文特定适应。

Conclusion: 研究为交通网络评估提供了新见解，并提出了未来开发更稳健预测模型的方向。

Abstract: The Dutch railway network is one of the busiest in the world, with delays
being a prominent concern for the principal passenger railway operator NS. This
research addresses a gap in delay prediction studies within the Dutch railway
network by employing an XGBoost Classifier with a focus on topological
features. Current research predominantly emphasizes short-term predictions and
neglects the broader network-wide patterns essential for mitigating ripple
effects. This research implements and improves an existing methodology,
originally designed to forecast the evolution of the fast-changing US air
network, to predict delays in the Dutch Railways. By integrating Node
Centrality Measures and comparing multiple classifiers like RandomForest,
DecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is
to predict delayed trajectories. However, the results reveal limited
performance, especially in non-simultaneous testing scenarios, suggesting the
necessity for more context-specific adaptations. Regardless, this research
contributes to the understanding of transportation network evaluation and
proposes future directions for developing more robust predictive models for
delays.

</details>


### [188] [Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation](https://arxiv.org/abs/2507.11789)
*Alessandro Palma,Sergei Rybakov,Leon Hetzel,Stephan Günnemann,Fabian J. Theis*

Main category: cs.LG

TL;DR: FlatVI是一种新的训练框架，通过正则化离散似然变分自编码器的潜在流形，使其更适合单细胞计数数据的建模，提升潜在空间直线与解码数据流形上测地线的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单细胞RNA测序中常假设线性转移和欧几里得几何，但潜在空间的线性插值可能不反映数据流形上的测地线路径，限制了方法的有效性。

Method: FlatVI通过正则化潜在流形，使其更接近欧几里得几何，从而优化潜在空间直线与数据流形测地线的一致性。

Result: 在合成数据和单细胞RNA测序数据上的实验表明，FlatVI提高了轨迹重建和流形插值的准确性。

Conclusion: FlatVI通过优化潜在流形的几何特性，显著提升了单细胞数据建模的效果。

Abstract: Latent space interpolations are a powerful tool for navigating deep
generative models in applied settings. An example is single-cell RNA
sequencing, where existing methods model cellular state transitions as latent
space interpolations with variational autoencoders, often assuming linear
shifts and Euclidean geometry. However, unless explicitly enforced, linear
interpolations in the latent space may not correspond to geodesic paths on the
data manifold, limiting methods that assume Euclidean geometry in the data
representations. We introduce FlatVI, a novel training framework that
regularises the latent manifold of discrete-likelihood variational autoencoders
towards Euclidean geometry, specifically tailored for modelling single-cell
count data. By encouraging straight lines in the latent space to approximate
geodesic interpolations on the decoded single-cell manifold, FlatVI enhances
compatibility with downstream approaches that assume Euclidean latent geometry.
Experiments on synthetic data support the theoretical soundness of our
approach, while applications to time-resolved single-cell RNA sequencing data
demonstrate improved trajectory reconstruction and manifold interpolation.

</details>


### [189] [CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels](https://arxiv.org/abs/2507.11807)
*Ruofan Hu,Dongyu Zhang,Huayi Zhang,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 提出了一种无需干净标注数据的元学习方法CLID-MU，利用跨层信息差异评估模型性能并指导训练，在噪声标签场景下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有元学习方法依赖干净标注数据，但实际中难以获取，因此研究如何在无干净数据的情况下进行元学习。

Method: 设计CLID-MU策略，通过分析干净样本和噪声样本在隐藏层与输出层数据结构的差异，利用跨层信息对齐指导模型训练。

Result: 在合成和真实噪声标签数据集上，CLID-MU均优于现有方法。

Conclusion: CLID-MU为噪声标签场景下的元学习提供了有效解决方案，无需依赖干净数据。

Abstract: Learning with noisy labels (LNL) is essential for training deep neural
networks with imperfect data. Meta-learning approaches have achieved success by
using a clean unbiased labeled set to train a robust model. However, this
approach heavily depends on the availability of a clean labeled meta-dataset,
which is difficult to obtain in practice. In this work, we thus tackle the
challenge of meta-learning for noisy label scenarios without relying on a clean
labeled dataset. Our approach leverages the data itself while bypassing the
need for labels. Building on the insight that clean samples effectively
preserve the consistency of related data structures across the last hidden and
the final layer, whereas noisy samples disrupt this consistency, we design the
Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU).
CLID-MU leverages the alignment of data structures across these diverse feature
spaces to evaluate model performance and use this alignment to guide training.
Experiments on benchmark datasets with varying amounts of labels under both
synthetic and real-world noise demonstrate that CLID-MU outperforms
state-of-the-art methods. The code is released at
https://github.com/ruofanhu/CLID-MU.

</details>


### [190] [SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling](https://arxiv.org/abs/2507.11818)
*Andrei Rekesh,Miruna Cretu,Dmytro Shevchuk,Vignesh Ram Somnath,Pietro Liò,Robert A. Batey,Mike Tyers,Michał Koziarski,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: SynCoGen框架结合掩码图扩散和流匹配，用于可合成的3D分子生成，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决生成小分子设计中的可合成性问题，并扩展至3D几何条件生成。

Method: 结合掩码图扩散和流匹配，从分子构建块、化学反应和原子坐标的联合分布中采样。

Result: 在无条件小分子图和构象生成中表现最佳，并在零射击分子连接设计中具有竞争力。

Conclusion: 为未来非自回归分子生成应用（如类似物扩展和直接结构条件）奠定基础。

Abstract: Ensuring synthesizability in generative small molecule design remains a major
challenge. While recent developments in synthesizable molecule generation have
demonstrated promising results, these efforts have been largely confined to 2D
molecular graph representations, limiting the ability to perform geometry-based
conditional generation. In this work, we present SynCoGen (Synthesizable
Co-Generation), a single framework that combines simultaneous masked graph
diffusion and flow matching for synthesizable 3D molecule generation. SynCoGen
samples from the joint distribution of molecular building blocks, chemical
reactions, and atomic coordinates. To train the model, we curated SynSpace, a
dataset containing over 600K synthesis-aware building block graphs and 3.3M
conformers. SynCoGen achieves state-of-the-art performance in unconditional
small molecule graph and conformer generation, and the model delivers
competitive performance in zero-shot molecular linker design for protein ligand
generation in drug discovery. Overall, this multimodal formulation represents a
foundation for future applications enabled by non-autoregressive molecular
generation, including analog expansion, lead optimization, and direct structure
conditioning.

</details>


### [191] [HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction](https://arxiv.org/abs/2507.11836)
*Jian Gao,Jianshe Wu,JingYi Ding*

Main category: cs.LG

TL;DR: 论文提出HyperEvent框架，将动态链接预测重构为超事件识别，通过事件相关性向量动态构建关联序列，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法捕捉复合超事件的结构凝聚力，限制了动态图建模的准确性。

Method: 提出HyperEvent框架，利用事件相关性向量动态构建关联序列，评估查询事件与历史事件是否形成有效超事件。

Result: 在5个数据集中4个表现最佳，大规模Flight数据集上MRR提升6.95%，训练时间仅需10.17%。

Conclusion: HyperEvent在准确性和效率上均优于现有方法，适用于大规模动态图建模。

Abstract: Dynamic link prediction in continuous-time dynamic graphs is a fundamental
task for modeling evolving complex systems. Existing node-centric and
event-centric methods focus on individual interactions or atomic states,
failing to capture the structural cohesion of composite hyper-events, groups of
causally related events. To address this, we propose HyperEvent, a framework
reframing dynamic link prediction as hyper-event recognition. Central to
HyperEvent is the dynamic construction of an association sequence using event
correlation vectors. These vectors quantify pairwise dependencies between the
query event and relevant historical events, thereby characterizing the
structural cohesion of a potential hyper-event. The framework predicts the
occurrence of the query event by evaluating whether it collectively forms a
valid hyper-event with these historical events. Notably, HyperEvent outperforms
state-of-the-art methods on 4 out of 5 datasets in the official leaderboard.
For scalability, we further introduce an efficient parallel training algorithm
that segments large event streams to enable concurrent training. Experiments
validate HyperEvent's superior accuracy and efficiency on large-scale graphs.
Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank
over state-of-the-art baseline on the large-scale Flight dataset while
utilizing only 10.17% of the training time.

</details>


### [192] [Online Training and Pruning of Deep Reinforcement Learning Networks](https://arxiv.org/abs/2507.11975)
*Valentin Frank Ingmar Guenter,Athanasios Sideris*

Main category: cs.LG

TL;DR: 提出了一种在强化学习（RL）中同时训练和修剪神经网络的方法，特别针对使用在线特征提取网络（OFENet）的RL算法，通过变分伯努利分布和正则化实现高效网络压缩。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在RL中的扩展提高了性能，但增加了计算和内存复杂度。虽然神经网络修剪方法在监督学习中成功应用，但在RL中尚未充分探索。

Method: 提出XiNet，通过随机优化问题训练网络权重和变分伯努利分布参数，利用正则化促进不活跃结构的修剪。针对OFENet的DenseNet架构设计成本感知的稀疏正则化方案。

Result: 在MuJoCo连续控制基准和Soft Actor-Critic RL代理上验证，OFENet可显著修剪且性能损失最小，修剪大网络比从头训练小网络更高效且性能更高。

Conclusion: 该方法成功将网络修剪与RL目标结合，显著提升了RL代理的效率和性能。

Abstract: Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms
has been shown to enhance performance when feature extraction networks are used
but the gained performance comes at the significant expense of increased
computational and memory complexity. Neural network pruning methods have
successfully addressed this challenge in supervised learning. However, their
application to RL is underexplored. We propose an approach to integrate
simultaneous training and pruning within advanced RL methods, in particular to
RL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our
networks (XiNet) are trained to solve stochastic optimization problems over the
RL networks' weights and the parameters of variational Bernoulli distributions
for 0/1 Random Variables $\xi$ scaling each unit in the networks. The
stochastic problem formulation induces regularization terms that promote
convergence of the variational parameters to 0 when a unit contributes little
to the performance. In this case, the corresponding structure is rendered
permanently inactive and pruned from its network. We propose a cost-aware,
sparsity-promoting regularization scheme, tailored to the DenseNet architecture
of OFENets expressing the parameter complexity of involved networks in terms of
the parameters of the RVs in these networks. Then, when matching this cost with
the regularization terms, the many hyperparameters associated with them are
automatically selected, effectively combining the RL objectives and network
compression. We evaluate our method on continuous control benchmarks (MuJoCo)
and the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned
considerably with minimal loss in performance. Furthermore, our results confirm
that pruning large networks during training produces more efficient and higher
performing RL agents rather than training smaller networks from scratch.

</details>


### [193] [Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM](https://arxiv.org/abs/2507.11839)
*Chengyue Gong,Xinshi Chen,Yuxuan Zhang,Yuxuan Song,Hao Zhou,Wenzhi Xiao*

Main category: cs.LG

TL;DR: 论文提出Protenix-Mini，一种轻量化的蛋白质结构预测模型，通过优化采样策略和架构设计，显著降低计算开销，同时仅轻微牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 生物分子结构预测等任务需要轻量化推理以实现高效部署和大规模应用，如何在模型效率和预测准确性之间取得平衡是关键挑战。

Method: 1) 用少步ODE采样器替代多步AF3采样器；2) 通过剪枝和轻量化重新设计去除冗余Transformer模块；3) 用ESM模块替代传统MSA模块以减少预处理时间。

Result: Protenix-Mini在基准数据集上表现出高保真预测，性能仅比完整模型下降1-5%。

Conclusion: Protenix-Mini适用于计算资源有限但仍需高精度结构预测的场景。

Abstract: Lightweight inference is critical for biomolecular structure prediction and
other downstream tasks, enabling efficient real-world deployment and
inference-time scaling for large-scale applications. In this work, we address
the challenge of balancing model efficiency and prediction accuracy by making
several key modifications, 1) Multi-step AF3 sampler is replaced by a few-step
ODE sampler, significantly reducing computational overhead for the diffusion
module part during inference; 2) In the open-source Protenix framework, a
subset of pairformer or diffusion transformer blocks doesn't make contributions
to the final structure prediction, presenting opportunities for architectural
pruning and lightweight redesign; 3) A model incorporating an ESM module is
trained to substitute the conventional MSA module, reducing MSA preprocessing
time. Building on these key insights, we present Protenix-Mini, a compact and
optimized model designed for efficient protein structure prediction. This
streamlined version incorporates a more efficient architectural design with a
two-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating
redundant Transformer components and refining the sampling process,
Protenix-Mini significantly reduces model complexity with slight accuracy drop.
Evaluations on benchmark datasets demonstrate that it achieves high-fidelity
predictions, with only a negligible 1 to 5 percent decrease in performance on
benchmark datasets compared to its full-scale counterpart. This makes
Protenix-Mini an ideal choice for applications where computational resources
are limited but accurate structure prediction remains crucial.

</details>


### [194] [Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update](https://arxiv.org/abs/2507.11847)
*Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 论文提出了一种联合高效的广义线性老虎机（GLB）算法，通过在线镜像下降（OMD）估计器实现近乎最优的遗憾边界，同时每轮计算和空间复杂度为常数时间。


<details>
  <summary>Details</summary>
Motivation: 广义线性老虎机（GLB）因其非线性特性在计算和统计效率之间存在权衡，现有方法难以同时优化两者。

Method: 使用在线镜像下降（OMD）估计器，结合混合损失的新颖分析，构建紧密置信集，实现统计效率与最大似然估计相当。

Result: 算法在每轮计算和空间复杂度为O(1)的情况下，达到近乎最优的遗憾边界。

Conclusion: 该方法在计算和统计效率上均表现优异，为GLB问题提供了实用的解决方案。

Abstract: We study the generalized linear bandit (GLB) problem, a contextual
multi-armed bandit framework that extends the classical linear model by
incorporating a non-linear link function, thereby modeling a broad class of
reward distributions such as Bernoulli and Poisson. While GLBs are widely
applicable to real-world scenarios, their non-linear nature introduces
significant challenges in achieving both computational and statistical
efficiency. Existing methods typically trade off between two objectives, either
incurring high per-round costs for optimal regret guarantees or compromising
statistical efficiency to enable constant-time updates. In this paper, we
propose a jointly efficient algorithm that attains a nearly optimal regret
bound with $\mathcal{O}(1)$ time and space complexities per round. The core of
our method is a tight confidence set for the online mirror descent (OMD)
estimator, which is derived through a novel analysis that leverages the notion
of mix loss from online prediction. The analysis shows that our OMD estimator,
even with its one-pass updates, achieves statistical efficiency comparable to
maximum likelihood estimation, thereby leading to a jointly efficient
optimistic method.

</details>


### [195] [OrdShap: Feature Position Importance for Sequential Black-Box Models](https://arxiv.org/abs/2507.11855)
*Davin Hill,Brian L. Hill,Aria Masoomi,Vijay S. Nori,Robert E. Tillman,Jennifer Dy*

Main category: cs.LG

TL;DR: OrdShap是一种新的特征归因方法，通过量化特征位置对模型预测的影响，解决了现有方法混淆特征值和位置的问题。


<details>
  <summary>Details</summary>
Motivation: 现有特征归因方法假设固定特征顺序，无法区分特征值和位置的影响，限制了模型解释的准确性。

Method: 引入OrdShap，通过置换特征位置量化模型预测变化，并与Sanchez-Bergantiños值建立博弈论联系。

Result: 在健康、自然语言和合成数据集上的实验表明，OrdShap能有效捕捉特征值和位置的影响。

Conclusion: OrdShap提供了更深入理解模型行为的工具，解决了特征归因中的位置混淆问题。

Abstract: Sequential deep learning models excel in domains with temporal or sequential
dependencies, but their complexity necessitates post-hoc feature attribution
methods for understanding their predictions. While existing techniques quantify
feature importance, they inherently assume fixed feature ordering - conflating
the effects of (1) feature values and (2) their positions within input
sequences. To address this gap, we introduce OrdShap, a novel attribution
method that disentangles these effects by quantifying how a model's predictions
change in response to permuting feature position. We establish a game-theoretic
connection between OrdShap and Sanchez-Berganti\~nos values, providing a
theoretically grounded approach to position-sensitive attribution. Empirical
results from health, natural language, and synthetic datasets highlight
OrdShap's effectiveness in capturing feature value and feature position
attributions, and provide deeper insight into model behavior.

</details>


### [196] [A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers](https://arxiv.org/abs/2507.11865)
*Hanwen Dai,Chang Gao,Fang He,Congyuan Ji,Yanni Yang*

Main category: cs.LG

TL;DR: 研究提出了一种动态管理司机接受折扣快车服务的方法，通过改进的深度确定性策略梯度框架（pi-DDPG）解决高随机性和数据不足问题，提高了学习效率和匹配性能。


<details>
  <summary>Details</summary>
Motivation: 平台整合中，司机参与折扣快车服务虽能扩大需求池和提高匹配效率，但会降低利润，且缺乏历史数据支持动态管理。

Method: 提出pi-DDPG框架，包含改进模块、卷积LSTM网络和优先经验回放机制，以应对高随机性和数据不足。

Result: 数值实验表明，pi-DDPG显著提升了学习效率并减少了早期训练损失。

Conclusion: pi-DDPG框架有效解决了动态管理司机行为的挑战，为平台整合提供了可靠解决方案。

Abstract: The rapid expansion of platform integration has emerged as an effective
solution to mitigate market fragmentation by consolidating multiple
ride-hailing platforms into a single application. To address heterogeneous
passenger preferences, third-party integrators provide Discount Express service
delivered by express drivers at lower trip fares. For the individual platform,
encouraging broader participation of drivers in Discount Express services has
the potential to expand the accessible demand pool and improve matching
efficiency, but often at the cost of reduced profit margins. This study aims to
dynamically manage drivers' acceptance of Discount Express from the perspective
of individual platforms. The lack of historical data under the new business
model necessitates online learning. However, early-stage exploration through
trial and error can be costly in practice, highlighting the need for reliable
early-stage performance in real-world deployment. To address these challenges,
this study formulates the decision regarding the proportion of drivers'
acceptance behavior as a continuous control task. In response to the high
stochasticity, the opaque matching mechanisms employed by third-party
integrator, and the limited availability of historical data, we propose a
policy-improved deep deterministic policy gradient (pi-DDPG) framework. The
proposed framework incorporates a refiner module to boost policy performance
during the early training phase, leverages a convolutional long short-term
memory network to effectively capture complex spatiotemporal patterns, and
adopts a prioritized experience replay mechanism to enhance learning
efficiency. A simulator based on a real-world dataset is developed to validate
the effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate
that pi-DDPG achieves superior learning efficiency and significantly reduces
early-stage training losses.

</details>


### [197] [Imbalanced Regression Pipeline Recommendation](https://arxiv.org/abs/2507.11901)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 论文提出了Meta-IR框架，通过元学习推荐最佳的数据重采样策略和学习模型组合，以解决回归任务中的不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 回归任务中目标值稀少导致的不平衡问题缺乏有效解决方案，现有方法需要大量组合测试。

Method: 提出Meta-IR框架，训练元分类器以零样本方式推荐最佳策略组合，包括独立和链式两种形式。

Result: 链式形式表现更优，Meta-IR在实验中优于AutoML框架和42种基线配置。

Conclusion: Meta-IR通过元学习有效解决了回归任务中的不平衡问题，且性能优于现有方法。

Abstract: Imbalanced problems are prevalent in various real-world scenarios and are
extensively explored in classification tasks. However, they also present
challenges for regression tasks due to the rarity of certain target values. A
common alternative is to employ balancing algorithms in preprocessing to
address dataset imbalance. However, due to the variety of resampling methods
and learning models, determining the optimal solution requires testing many
combinations. Furthermore, the learning model, dataset, and evaluation metric
affect the best strategies. This work proposes the Meta-learning for Imbalanced
Regression (Meta-IR) framework, which diverges from existing literature by
training meta-classifiers to recommend the best pipeline composed of the
resampling strategy and learning model per task in a zero-shot fashion. The
meta-classifiers are trained using a set of meta-features to learn how to map
the meta-features to the classes indicating the best pipeline. We propose two
formulations: Independent and Chained. Independent trains the meta-classifiers
to separately indicate the best learning algorithm and resampling strategy.
Chained involves a sequential procedure where the output of one meta-classifier
is used as input for another to model intrinsic relationship factors. The
Chained scenario showed superior performance, suggesting a relationship between
the learning algorithm and the resampling strategy per task. Compared with
AutoML frameworks, Meta-IR obtained better results. Moreover, compared with
baselines of six learning algorithms and six resampling algorithms plus no
resampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of
them. The code, data, and further information of the experiments can be found
on GitHub: https://github.com/JusciAvelino/Meta-IR.

</details>


### [198] [Resampling strategies for imbalanced regression: a survey and empirical analysis](https://arxiv.org/abs/2507.11902)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 该论文研究了不平衡回归问题，提出了一种基于回归模型、学习过程和评估指标的分类法，并通过实验验证了不同平衡策略的效果。


<details>
  <summary>Details</summary>
Motivation: 不平衡问题在分类任务中已被广泛研究，但在回归任务中尚未得到充分关注。本文旨在填补这一空白，探索不平衡回归的解决策略。

Method: 通过实验研究多种平衡和预测模型，并使用特定指标评估模型在不平衡回归数据中的表现。同时提出了一种基于三个关键标准的分类法。

Result: 研究提供了关于平衡策略的新见解，展示了它们对模型学习过程的优势，并指出了进一步研究的方向。

Conclusion: 论文为不平衡回归问题提供了系统性的分析和解决方案，同时开源了代码和数据以促进后续研究。

Abstract: Imbalanced problems can arise in different real-world situations, and to
address this, certain strategies in the form of resampling or balancing
algorithms are proposed. This issue has largely been studied in the context of
classification, and yet, the same problem features in regression tasks, where
target values are continuous. This work presents an extensive experimental
study comprising various balancing and predictive models, and wich uses metrics
to capture important elements for the user and to evaluate the predictive model
in an imbalanced regression data context. It also proposes a taxonomy for
imbalanced regression approaches based on three crucial criteria: regression
model, learning process, and evaluation metrics. The study offers new insights
into the use of such strategies, highlighting the advantages they bring to each
model's learning process, and indicating directions for further studies. The
code, data and further information related to the experiments performed herein
can be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.

</details>


### [199] [From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning](https://arxiv.org/abs/2507.11926)
*Max Hopkins,Sihan Liu,Christopher Ye,Yuichi Yoshida*

Main category: cs.LG

TL;DR: 本文研究了可复制强化学习算法的样本效率问题，填补了生成模型与无模型设置之间的样本复杂度差距。


<details>
  <summary>Details</summary>
Motivation: 解决可复制学习在强化学习中的探索成本问题，验证样本高效的可复制RL是否可行。

Method: 提出一种可复制RL算法，在低水平表格MDP中实现样本高效的探索。

Result: 算法在生成模型和无模型设置中分别达到$	ilde{O}(S^2A)$和$	ilde{O}(S^2A^2)$样本复杂度，并提供了匹配的下界。

Conclusion: 探索并非可复制学习的主要障碍，算法在状态空间上接近最优。

Abstract: The epidemic failure of replicability across empirical science and machine
learning has recently motivated the formal study of replicable learning
algorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from
a fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the
design of data-efficient replicable algorithms is now more or less understood.
In contrast, there remain significant gaps in our knowledge for control
settings like reinforcement learning where an agent must interact directly with
a shifting environment. Karbasi et. al show that with access to a generative
model of an environment with $S$ states and $A$ actions (the RL 'batch
setting'), replicably learning a near-optimal policy costs only
$\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a
generative model jumps to $\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the
substantial difficulty of environment exploration. This gap raises a key
question in the broader theory of replicability: Is replicable exploration
inherently more expensive than batch learning? Is sample-efficient replicable
RL even possible?
  In this work, we (nearly) resolve this problem (for low-horizon tabular
MDPs): exploration is not a significant barrier to replicable learning! Our
main result is a replicable RL algorithm on $\tilde{O}(S^2A)$ samples, bridging
the gap between the generative and episodic settings. We complement this with a
matching $\tilde{\Omega}(S^2A)$ lower bound in the generative setting (under
the common parallel sampling assumption) and an unconditional lower bound in
the episodic setting of $\tilde{\Omega}(S^2)$ showcasing the near-optimality of
our algorithm with respect to the state space $S$.

</details>


### [200] [Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning](https://arxiv.org/abs/2507.11928)
*Abhishek Sriram,Neal Tuffy*

Main category: cs.LG

TL;DR: 论文提出了一种机器学习加速的优化框架，用于RF功率放大器设计，减少65%的仿真需求，同时保持±0.3至±0.4 dBm的精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要穷举所有参数组合以满足目标P2dB压缩规格，耗时且低效。本文旨在通过智能采样和机器学习减少仿真需求，提高设计效率。

Method: 结合MaxMin拉丁超立方采样和CatBoost梯度提升，智能探索多维参数空间，仅选择35%的关键仿真点。框架处理ADS网表，执行谐波平衡仿真，并训练CatBoost模型预测P2dB性能。

Result: 在15种PA工作模式下验证，平均R²为0.901，仿真时间减少58.24%至77.78%。

Conclusion: 该框架通过自动化GUI工作流实现了快速设计迭代，同时满足生产RF电路的精度要求。

Abstract: This paper presents a machine learning-accelerated optimization framework for
RF power amplifier design that reduces simulation requirements by 65% while
maintaining $\pm0.3$ to $\pm0.4$ dBm accuracy. The proposed method combines
MaxMin Latin Hypercube Sampling with CatBoost gradient boosting to
intelligently explore multidimensional parameter spaces. Instead of
exhaustively simulating all parameter combinations to achieve target P2dB
compression specifications, our approach strategically selects approximately
35% of critical simulation points. The framework processes ADS netlists,
executes harmonic balance simulations on the reduced dataset, and trains a
CatBoost model to predict P2dB performance across the entire design space.
Validation across 15 PA operating modes yields an average $R^2$ of 0.901, with
the system ranking parameter combinations by their likelihood of meeting target
specifications. The integrated solution delivers 58.24% to 77.78% reduction in
simulation time through automated GUI-based workflows, enabling rapid design
iterations without compromising accuracy standards required for production RF
circuits.

</details>


### [201] [Kevin: Multi-Turn RL for Generating CUDA Kernels](https://arxiv.org/abs/2507.11948)
*Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti*

Main category: cs.LG

TL;DR: 论文提出了一种多轮强化学习（RL）方法Kevin，用于CUDA内核生成和优化，显著提升了生成内核的正确性和性能。


<details>
  <summary>Details</summary>
Motivation: GPU内核编写对AI系统效率至关重要，但具有挑战性且需要迭代优化。强化学习因其可验证的奖励（如正确性和加速）成为自然选择。

Method: 开发了一种灵活的多轮RL方法，解决了长轨迹学习和跨轮奖励分配等现实挑战。

Result: Kevin在生成内核的正确性（从56%提升至82%）和平均加速（从0.53x提升至1.10x）上显著优于基础模型和前沿模型。

Conclusion: 多轮RL在CUDA内核优化中表现优异，且串行细化比并行采样更具优势，更多细化轮次带来更高改进率。

Abstract: Writing GPU kernels is a challenging task and critical for AI systems'
efficiency. It is also highly iterative: domain experts write code and improve
performance through execution feedback. Moreover, it presents verifiable
rewards like correctness and speedup, making it a natural environment to apply
Reinforcement Learning (RL). To explicitly incorporate the iterative nature of
this process into training, we develop a flexible multi-turn RL recipe that
addresses unique challenges encountered in real-world settings, such as
learning from long trajectories and effective reward attribution across turns.
We present Kevin - K(ernel D)evin, the first model trained with multi-turn RL
for CUDA kernel generation and optimization. In our evaluation setup, Kevin
shows significant gains over its base model (QwQ-32B), improving correctness of
generated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to
1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini
(0.78x). Finally, we study its behavior across test-time scaling axes: we found
scaling serial refinement more beneficial than parallel sampling. In
particular, when given more refinement turns, Kevin shows a higher rate of
improvement.

</details>


### [202] [Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection](https://arxiv.org/abs/2507.11997)
*Tairan Huang,Yili Wang*

Main category: cs.LG

TL;DR: MLED框架利用LLMs从文本信息中提取外部知识，通过多级增强器（类型级和关系级）融合图结构信息，提升欺诈检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有图欺诈检测方法忽略原始文本信息的丰富语义线索，且难以将LLMs处理的文本嵌入与图结构进行多模态融合。

Method: 提出MLED框架，利用LLMs提取文本知识，设计类型级和关系级增强器融合图结构信息。

Result: 在四个真实数据集上，MLED作为通用框架实现了最先进的欺诈检测性能。

Conclusion: MLED通过多级LLM增强有效提升欺诈检测能力，可作为现有方法的通用框架。

Abstract: Graph fraud detection has garnered significant attention as Graph Neural
Networks (GNNs) have proven effective in modeling complex relationships within
multimodal data. However, existing graph fraud detection methods typically use
preprocessed node embeddings and predefined graph structures to reveal
fraudsters, which ignore the rich semantic cues contained in raw textual
information. Although Large Language Models (LLMs) exhibit powerful
capabilities in processing textual information, it remains a significant
challenge to perform multimodal fusion of processed textual embeddings with
graph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM
\textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. In
MLED, we utilize LLMs to extract external knowledge from textual information to
enhance graph fraud detection methods. To integrate LLMs with graph structure
information and enhance the ability to distinguish fraudsters, we design a
multi-level LLM enhanced framework including type-level enhancer and
relation-level enhancer. One is to enhance the difference between the
fraudsters and the benign entities, the other is to enhance the importance of
the fraudsters in different relations. The experiments on four real-world
datasets show that MLED achieves state-of-the-art performance in graph fraud
detection as a generalized framework that can be applied to existing methods.

</details>


### [203] [Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing](https://arxiv.org/abs/2507.12002)
*Alice Zhang,Callihan Bertley,Dawei Liang,Edison Thomaz*

Main category: cs.LG

TL;DR: 论文提出了一种利用智能手表的多模态数据（音频和惯性）检测面对面对话的计算方法，并在实验室和半自然环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 社交互动对人类行为和社会关系至关重要，但现有方法在复杂声学环境中检测对话的能力有限。

Method: 结合音频和惯性数据，采用机器学习和深度学习模型，通过三种融合方法分析对话中的言语和非言语线索。

Result: 在实验室和半自然环境中，框架的宏F1分数分别达到82.0±3.0%和77.2±1.8%。

Conclusion: 多模态数据融合在复杂环境中显著提升了对话检测的准确性。

Abstract: Social interactions play a crucial role in shaping human behavior,
relationships, and societies. It encompasses various forms of communication,
such as verbal conversation, non-verbal gestures, facial expressions, and body
language. In this work, we develop a novel computational approach to detect a
foundational aspect of human social interactions, in-person verbal
conversations, by leveraging audio and inertial data captured with a commodity
smartwatch in acoustically-challenging scenarios. To evaluate our approach, we
conducted a lab study with 11 participants and a semi-naturalistic study with
24 participants. We analyzed machine learning and deep learning models with 3
different fusion methods, showing the advantages of fusing audio and inertial
data to consider not only verbal cues but also non-verbal gestures in
conversations. Furthermore, we perform a comprehensive set of evaluations
across activities and sampling rates to demonstrate the benefits of multimodal
sensing in specific contexts. Overall, our framework achieved 82.0$\pm$3.0%
macro F1-score when detecting conversations in the lab and 77.2$\pm$1.8% in the
semi-naturalistic setting.

</details>


### [204] [DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning](https://arxiv.org/abs/2507.12011)
*Yao Lu,Hongyu Gao,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.LG

TL;DR: 提出了一种名为DUSE的数据扩展框架，通过不确定性评分和主动学习策略解决自动调制识别中的数据稀缺问题，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决自动调制识别中因目标域数据稀缺导致模型训练困难的问题，避免高成本的人工标注和数据增强的局限性。

Method: 采用不确定性评分函数从相关数据集中筛选有用样本，并结合主动学习策略持续优化评分器。

Result: DUSE在类别平衡和不平衡设置下均优于8种核心集选择基线方法，并展现出对未见模型的强泛化能力。

Conclusion: DUSE有效解决了数据稀缺问题，为自动调制识别提供了一种高效的数据扩展方法。

Abstract: Although deep neural networks have made remarkable achievements in the field
of automatic modulation recognition (AMR), these models often require a large
amount of labeled data for training. However, in many practical scenarios, the
available target domain data is scarce and difficult to meet the needs of model
training. The most direct way is to collect data manually and perform expert
annotation, but the high time and labor costs are unbearable. Another common
method is data augmentation. Although it can enrich training samples to a
certain extent, it does not introduce new data and therefore cannot
fundamentally solve the problem of data scarcity. To address these challenges,
we introduce a data expansion framework called Dynamic Uncertainty-driven
Sample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring
function to filter out useful samples from relevant AMR datasets and employs an
active learning strategy to continuously refine the scorer. Extensive
experiments demonstrate that DUSE consistently outperforms 8 coreset selection
baselines in both class-balance and class-imbalance settings. Besides, DUSE
exhibits strong cross-architecture generalization for unseen models.

</details>


### [205] [Granular feedback merits sophisticated aggregation](https://arxiv.org/abs/2507.12041)
*Anmol Kagrecha,Henrik Marklund,Potsawee Manakul,Richard Zeckhauser,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 论文探讨了在有限个体反馈下预测群体反馈分布的方法，发现随着反馈粒度的增加，复杂方法比正则化平均更有效。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用有限个体反馈更准确地预测群体反馈分布，尤其是在高粒度反馈的情况下。

Method: 比较了正则化平均与更复杂的方法在不同反馈粒度下的表现。

Result: 实验表明，对于五点反馈，复杂方法所需个体数量仅为正则化平均的一半。

Conclusion: 反馈粒度越高，复杂方法的优势越明显，尤其在非二元反馈情况下。

Abstract: Human feedback is increasingly used across diverse applications like training
AI models, developing recommender systems, and measuring public opinion -- with
granular feedback often being preferred over binary feedback for its greater
informativeness. While it is easy to accurately estimate a population's
distribution of feedback given feedback from a large number of individuals,
cost constraints typically necessitate using smaller groups. A simple method to
approximate the population distribution is regularized averaging: compute the
empirical distribution and regularize it toward a prior. Can we do better? As
we will discuss, the answer to this question depends on feedback granularity.
  Suppose one wants to predict a population's distribution of feedback using
feedback from a limited number of individuals. We show that, as feedback
granularity increases, one can substantially improve upon predictions of
regularized averaging by combining individuals' feedback in ways more
sophisticated than regularized averaging.
  Our empirical analysis using questions on social attitudes confirms this
pattern. In particular, with binary feedback, sophistication barely reduces the
number of individuals required to attain a fixed level of performance. By
contrast, with five-point feedback, sophisticated methods match the performance
of regularized averaging with about half as many individuals.

</details>


### [206] [Information-Theoretic Generalization Bounds of Replay-based Continual Learning](https://arxiv.org/abs/2507.12043)
*Wen Wen,Tieliang Gong,Yunjiao Zhang,Zeyu Gao,Weizhan Zhang,Yong-Jin Liu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，用于分析基于回放的持续学习方法，通过信息论界限揭示了记忆缓冲区与当前任务的交互如何影响泛化性能。


<details>
  <summary>Details</summary>
Motivation: 持续学习中基于回放的方法虽然表现良好，但其泛化行为的理论理解有限，本文旨在填补这一空白。

Method: 建立了一个统一的理论框架，推导了一系列信息论界限，分析了记忆缓冲区与当前任务的交互对泛化的影响。

Result: 理论分析表明，有限地回放先前任务的样本与当前任务数据结合，可以改善泛化并减轻灾难性遗忘。实验验证了界限的有效性。

Conclusion: 本文的理论框架为基于回放的持续学习提供了泛化行为的深入理解，并通过实验验证了其有效性。

Abstract: Continual learning (CL) has emerged as a dominant paradigm for acquiring
knowledge from sequential tasks while avoiding catastrophic forgetting.
Although many CL methods have been proposed to show impressive empirical
performance, the theoretical understanding of their generalization behavior
remains limited, particularly for replay-based approaches. In this paper, we
establish a unified theoretical framework for replay-based CL, deriving a
series of information-theoretic bounds that explicitly characterize how the
memory buffer interacts with the current task to affect generalization.
Specifically, our hypothesis-based bounds reveal that utilizing the limited
exemplars of previous tasks alongside the current task data, rather than
exhaustive replay, facilitates improved generalization while effectively
mitigating catastrophic forgetting. Furthermore, our prediction-based bounds
yield tighter and computationally tractable upper bounds of the generalization
gap through the use of low-dimensional variables. Our analysis is general and
broadly applicable to a wide range of learning algorithms, exemplified by
stochastic gradient Langevin dynamics (SGLD) as a representative method.
Comprehensive experimental evaluations demonstrate the effectiveness of our
derived bounds in capturing the generalization dynamics in replay-based CL
settings.

</details>


### [207] [FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling](https://arxiv.org/abs/2507.12053)
*Seanglidet Yean,Jiazu Zhou,Bu-Sung Lee,Markus Schläpfer*

Main category: cs.LG

TL;DR: 提出了一种基于条件生成对抗网络（cGANs）的数据驱动方法，用于生成适应动态城市场景的出行流量，解决了现有方法依赖历史数据或静态假设的局限性。


<details>
  <summary>Details</summary>
Motivation: 城市规划和交通优化需要模拟和分析动态变化的人口流动模式，但现有方法无法有效结合历史数据和动态因素（如人口密度和土地利用变化）。

Method: 利用动态区域大小和土地利用类型等自适应参数，结合cGANs生成出行流量，支持快速生成且无需复杂校准。

Result: 在新加坡手机数据上的应用表明，该方法性能优于现有方法。

Conclusion: 该方法为动态城市场景下的出行流量生成提供了高效、灵活的解决方案。

Abstract: The mobility patterns of people in cities evolve alongside changes in land
use and population. This makes it crucial for urban planners to simulate and
analyze human mobility patterns for purposes such as transportation
optimization and sustainable urban development. Existing generative models
borrowed from machine learning rely heavily on historical trajectories and
often overlook evolving factors like changes in population density and land
use. Mechanistic approaches incorporate population density and facility
distribution but assume static scenarios, limiting their utility for future
projections where historical data for calibration is unavailable. This study
introduces a novel, data-driven approach for generating origin-destination
mobility flows tailored to simulated urban scenarios. Our method leverages
adaptive factors such as dynamic region sizes and land use archetypes, and it
utilizes conditional generative adversarial networks (cGANs) to blend
historical data with these adaptive parameters. The approach facilitates rapid
mobility flow generation with adjustable spatial granularity based on regions
of interest, without requiring extensive calibration data or complex behavior
modeling. The promising performance of our approach is demonstrated by its
application to mobile phone data from Singapore, and by its comparison with
existing methods.

</details>


### [208] [Emergence of Quantised Representations Isolated to Anisotropic Functions](https://arxiv.org/abs/2507.12070)
*George Bird*

Main category: cs.LG

TL;DR: 论文提出了一种基于Spotlight Resonance的新方法，用于确定表征对齐，发现网络原语的代数对称性是任务无关表征结构的强预测因子。通过改变激活函数，研究发现离散代数置换对称性会导致表征离散化，而连续代数正交对称性则保持连续性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示功能形式选择如何引入意外的归纳偏差，导致任务无关的表征结构，特别是当代形式如何诱导离散化。

Method: 采用基于Spotlight Resonance的新方法，通过改变激活函数进行消融研究，分析表征的形成和排列。

Result: 离散代数置换对称性导致表征离散化，而连续代数正交对称性保持连续性。量化表征与重建误差增加相关。

Conclusion: 功能形式对表征的影响机制为可解释性研究提供了新见解，离散化可能对下游任务产生负面影响。

Abstract: This paper describes a novel methodology for determining representational
alignment, developed upon the existing Spotlight Resonance method. Using this,
it is found that algebraic symmetries of network primitives are a strong
predictor for task-agnostic structure in representations. Particularly, this
new tool is used to gain insight into how discrete representations can form and
arrange in autoencoder models, through an ablation study where only the
activation function is altered. Representations are found to tend to discretise
when the activation functions are defined through a discrete algebraic
permutation-equivariant symmetry. In contrast, they remain continuous under a
continuous algebraic orthogonal-equivariant definition. These findings
corroborate the hypothesis that functional form choices can carry unintended
inductive biases which produce task-independent artefactual structures in
representations, particularly that contemporary forms induce discretisation of
otherwise continuous structure -- a quantisation effect. Moreover, this
supports a general causal model for one mode in which discrete representations
may form, and could constitute a prerequisite for downstream interpretability
phenomena, including grandmother neurons, discrete coding schemes, general
linear features and possibly Superposition. Hence, this tool and proposed
mechanism for the influence of functional form on representations may provide
several insights into emergent interpretability research. Finally, preliminary
results indicate that quantisation of representations appears to correlate with
a measurable increase in reconstruction error, reinforcing previous conjectures
that this collapse can be detrimental.

</details>


### [209] [Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks](https://arxiv.org/abs/2507.12127)
*Ngoc Duy Pham,Thusitha Dayaratne,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.LG

TL;DR: 论文提出了一种基于联邦学习（FL）的动态频谱分配（DSA）方法，解决了频谱感知中标签数据稀缺和安全漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 无线设备的快速增长导致频谱稀缺，传统集中式机器学习方法因隐私和带宽限制难以应用，联邦学习成为潜在解决方案。

Method: 采用半监督联邦学习结合能量检测，解决标签数据稀缺问题；提出基于疫苗接种思想的防御机制，对抗数据投毒攻击。

Result: 实验验证了方法在无标签数据集上的高准确性，并能有效抵御恶意参与者的数据投毒攻击。

Conclusion: FLSS方法在频谱感知中表现出色，解决了标签数据和安全问题，为动态频谱分配提供了可行方案。

Abstract: Advancements in wireless and mobile technologies, including 5G advanced and
the envisioned 6G, are driving exponential growth in wireless devices. However,
this rapid expansion exacerbates spectrum scarcity, posing a critical
challenge. Dynamic spectrum allocation (DSA)--which relies on sensing and
dynamically sharing spectrum--has emerged as an essential solution to address
this issue. While machine learning (ML) models hold significant potential for
improving spectrum sensing, their adoption in centralized ML-based DSA systems
is limited by privacy concerns, bandwidth constraints, and regulatory
challenges. To overcome these limitations, distributed ML-based approaches such
as Federated Learning (FL) offer promising alternatives. This work addresses
two key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of
labeled data for training FL models in practical spectrum sensing scenarios is
tackled with a semi-supervised FL approach, combined with energy detection,
enabling model training on unlabeled datasets. Second, we examine the security
vulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our
analysis highlights the shortcomings of existing majority-based defenses in
countering such attacks. To address these vulnerabilities, we propose a novel
defense mechanism inspired by vaccination, which effectively mitigates data
poisoning attacks without relying on majority-based assumptions. Extensive
experiments on both synthetic and real-world datasets validate our solutions,
demonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets
and maintain Byzantine robustness against both targeted and untargeted data
poisoning attacks, even when a significant proportion of participants are
malicious.

</details>


### [210] [HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD](https://arxiv.org/abs/2507.12133)
*Hanwen Liu,Yuhe Huang,Yifeng Gong,Yanjie Zhai,Jiaxuan Lu*

Main category: cs.LG

TL;DR: HyDRA是一种混合双模射频架构，结合优化的VMD和新型CNN、Transformer与Mamba组件，支持闭集和开集分类任务，实现高效无线设备识别。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统中的设备识别对安全至关重要，RFFI提供了一种非加密解决方案。

Method: HyDRA整合优化的VMD预处理，结合CNN、Transformer和Mamba组件，支持闭集和开集分类。

Result: 在公开数据集上实现SOTA精度，并在开集分类中表现稳健，部署后实现毫秒级推理速度和低功耗。

Conclusion: HyDRA为实时无线认证提供了高效实用的解决方案。

Abstract: Device recognition is vital for security in wireless communication systems,
particularly for applications like access control. Radio Frequency Fingerprint
Identification (RFFI) offers a non-cryptographic solution by exploiting
hardware-induced signal distortions. This paper proposes HyDRA, a Hybrid
Dual-mode RF Architecture that integrates an optimized Variational Mode
Decomposition (VMD) with a novel architecture based on the fusion of
Convolutional Neural Networks (CNNs), Transformers, and Mamba components,
designed to support both closed-set and open-set classification tasks. The
optimized VMD enhances preprocessing efficiency and classification accuracy by
fixing center frequencies and using closed-form solutions. HyDRA employs the
Transformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and
the Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting
to varying conditions. Evaluation on public datasets demonstrates
state-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance
in our proposed open-set classification method, effectively identifying
unauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves
millisecond-level inference speed with low power consumption, providing a
practical solution for real-time wireless authentication in real-world
environments.

</details>


### [211] [RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization](https://arxiv.org/abs/2507.12142)
*Vladimir Bogachev,Vladimir Aletov,Alexander Molozhavenko,Denis Bobkov,Vera Soboleva,Aibek Alanov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: 提出了一种名为RiemannLoRA的新方法，通过将LoRA矩阵视为光滑流形，解决了初始化策略和低秩矩阵过参数化的问题。


<details>
  <summary>Details</summary>
Motivation: LoRA在参数高效微调中广泛应用，但仍面临初始化策略和过参数化的挑战。

Method: 将固定秩的LoRA矩阵视为光滑流形，利用流形上的最快损失下降方向进行初始化，并采用数值稳定和计算高效的实现。

Result: 在LLM和扩散模型上的实验表明，RiemannLoRA在收敛速度和最终性能上优于标准LoRA及其改进版本。

Conclusion: RiemannLoRA通过流形优化框架有效解决了LoRA的挑战，提升了性能。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted standard for
parameter-efficient fine-tuning of large language models (LLMs), significantly
reducing memory and computational demands. However, challenges remain,
including finding optimal initialization strategies or mitigating
overparametrization in low-rank matrix factorization. In this work, we propose
a novel approach that addresses both of the challenges simultaneously within a
unified framework. Our method treats a set of fixed-rank LoRA matrices as a
smooth manifold. Considering adapters as elements on this manifold removes
overparametrization, while determining the direction of the fastest loss
decrease along the manifold provides initialization. Special care is taken to
obtain numerically stable and computationally efficient implementation of our
method, using best practices from numerical linear algebra and Riemannian
optimization. Experimental results on LLM and diffusion model architectures
demonstrate that RiemannLoRA consistently improves both convergence speed and
final performance over standard LoRA and its state-of-the-art modifications.

</details>


### [212] [FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale](https://arxiv.org/abs/2507.12144)
*Boris Bonev,Thorsten Kurth,Ankur Mahesh,Mauro Bisson,Jean Kossaifi,Karthik Kashinath,Anima Anandkumar,William D. Collins,Michael S. Pritchard,Alexander Keller*

Main category: cs.LG

TL;DR: FourCastNet 3 是一种基于几何机器学习的全球天气概率集合预报模型，具有高效、准确和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 改进全球天气建模，提供更快速、更准确的概率集合预报，同时保持光谱和动力学的真实性。

Method: 采用纯卷积神经网络架构，结合球面几何特性，并通过新型训练范式实现大规模并行训练。

Result: 预报精度超越传统集合模型，媲美最佳扩散方法，速度提升8至60倍，且具有优秀的概率校准和光谱保真性。

Conclusion: FourCastNet 3 是改进气象预报和早期预警系统的有力候选方案。

Abstract: FourCastNet 3 advances global weather modeling by implementing a scalable,
geometric machine learning (ML) approach to probabilistic ensemble forecasting.
The approach is designed to respect spherical geometry and to accurately model
the spatially correlated probabilistic nature of the problem, resulting in
stable spectra and realistic dynamics across multiple scales. FourCastNet 3
delivers forecasting accuracy that surpasses leading conventional ensemble
models and rivals the best diffusion-based methods, while producing forecasts 8
to 60 times faster than these approaches. In contrast to other ML approaches,
FourCastNet 3 demonstrates excellent probabilistic calibration and retains
realistic spectra, even at extended lead times of up to 60 days. All of these
advances are realized using a purely convolutional neural network architecture
tailored for spherical geometry. Scalable and efficient large-scale training on
1024 GPUs and more is enabled by a novel training paradigm for combined model-
and data-parallelism, inspired by domain decomposition methods in classical
numerical models. Additionally, FourCastNet 3 enables rapid inference on a
single GPU, producing a 90-day global forecast at 0.25{\deg}, 6-hourly
resolution in under 20 seconds. Its computational efficiency, medium-range
probabilistic skill, spectral fidelity, and rollout stability at subseasonal
timescales make it a strong candidate for improving meteorological forecasting
and early warning systems through large ensemble predictions.

</details>


### [213] [PRISM: Distributed Inference for Foundation Models at Edge](https://arxiv.org/abs/2507.12145)
*Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang*

Main category: cs.LG

TL;DR: PRISM是一种通信高效且计算感知的策略，用于在边缘设备上部署基础模型，显著减少通信和计算开销。


<details>
  <summary>Details</summary>
Motivation: 基础模型在边缘部署面临通信和计算挑战，需要高效策略。

Method: 利用Segment Means表示近似中间特征，重构自注意力机制以减少冗余计算，设计分区感知的因果掩码。

Result: 在BERT等模型上，通信开销减少99.2%，计算减少51.24%，仅轻微影响精度。

Conclusion: PRISM为资源受限环境中的基础模型部署提供了可扩展的解决方案。

Abstract: Foundation models (FMs) have achieved remarkable success across a wide range
of applications, from image classification to natural langurage processing, but
pose significant challenges for deployment at edge. This has sparked growing
interest in developing practical and efficient strategies for bringing
foundation models to edge environments. In this work, we propose PRISM, a
communication-efficient and compute-aware strategy for distributed Transformer
inference on edge devices. Our method leverages a Segment Means representation
to approximate intermediate output features, drastically reducing inter-device
communication. Additionally, we restructure the self-attention mechanism to
eliminate redundant computations caused by per-device Key/Value calculation in
position-wise partitioning and design a partition-aware causal masking scheme
tailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2
across diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and
CBT. Our results demonstrate substantial reductions in communication overhead
(up to 99.2% for BERT at compression rate CR = 128) and per-device computation
(51.24% for BERT at the same setting), with only minor accuracy degradation.
This method offers a scalable and practical solution for deploying foundation
models in distributed resource-constrained environments.

</details>


### [214] [Multi-Component VAE with Gaussian Markov Random Field](https://arxiv.org/abs/2507.12165)
*Fouad Oubari,Mohamed El-Baha,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 论文提出了一种新的生成框架GMRF MCVAE，通过嵌入高斯马尔可夫随机场来显式建模多组件关系，提升了生成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多组件变分自编码器依赖简化聚合策略，忽略了关键细节，导致生成组件间结构一致性不足。

Method: 引入高斯马尔可夫随机场到先验和后验分布中，显式建模跨组件关系。

Result: 在合成Copula数据集、PolyMNIST基准和真实BIKED数据集上表现优异，提升了结构一致性。

Conclusion: GMRF MCVAE特别适用于需要强大多组件一致性建模的实际应用。

Abstract: Multi-component datasets with intricate dependencies, like industrial
assemblies or multi-modal imaging, challenge current generative modeling
techniques. Existing Multi-component Variational AutoEncoders typically rely on
simplified aggregation strategies, neglecting critical nuances and consequently
compromising structural coherence across generated components. To explicitly
address this gap, we introduce the Gaussian Markov Random Field Multi-Component
Variational AutoEncoder , a novel generative framework embedding Gaussian
Markov Random Fields into both prior and posterior distributions. This design
choice explicitly models cross-component relationships, enabling richer
representation and faithful reproduction of complex interactions. Empirically,
our GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula
dataset specifically constructed to evaluate intricate component relationships,
demonstrates competitive results on the PolyMNIST benchmark, and significantly
enhances structural coherence on the real-world BIKED dataset. Our results
indicate that the GMRF MCVAE is especially suited for practical applications
demanding robust and realistic modeling of multi-component coherence

</details>


### [215] [Explainable Evidential Clustering](https://arxiv.org/abs/2507.12192)
*Victor F. Lopes de Souza,Karima Bakhti,Sofiane Ramdani,Denis Mottet,Abdelhak Imoussaten*

Main category: cs.LG

TL;DR: 本文探讨了基于Dempster-Shafer理论的证据聚类解释问题，提出了一种称为IEMM的算法，用于生成可解释的决策树解释。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据常存在不确定性和不精确性，传统方法难以处理。证据聚类能解决这些问题，但其结果解释问题尚未充分研究。

Method: 通过代表性条件，将决策树作为解释器，并引入效用函数和证据错误概念，提出IEMM算法。

Result: 在合成和真实数据上验证，IEMM算法能提供93%满意的解释。

Conclusion: IEMM算法为证据聚类提供了可解释且谨慎的解释方法，适用于高风险领域。

Abstract: Unsupervised classification is a fundamental machine learning problem.
Real-world data often contain imperfections, characterized by uncertainty and
imprecision, which are not well handled by traditional methods. Evidential
clustering, based on Dempster-Shafer theory, addresses these challenges. This
paper explores the underexplored problem of explaining evidential clustering
results, which is crucial for high-stakes domains such as healthcare. Our
analysis shows that, in the general case, representativity is a necessary and
sufficient condition for decision trees to serve as abductive explainers.
Building on the concept of representativity, we generalize this idea to
accommodate partial labeling through utility functions. These functions enable
the representation of "tolerable" mistakes, leading to the definition of
evidential mistakeness as explanation cost and the construction of explainers
tailored to evidential classifiers. Finally, we propose the Iterative
Evidential Mistake Minimization (IEMM) algorithm, which provides interpretable
and cautious decision tree explanations for evidential clustering functions. We
validate the proposed algorithm on synthetic and real-world data. Taking into
account the decision-maker's preferences, we were able to provide an
explanation that was satisfactory up to 93% of the time.

</details>


### [216] [Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation](https://arxiv.org/abs/2507.12218)
*Tomohisa Okazaki*

Main category: cs.LG

TL;DR: 论文提出了一种物理信息线性模型（PILM），用于解决偏微分方程（PDEs）的正反问题，并通过地壳应变率估计验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于利用线性基函数组合解析求解PDEs，以替代传统数值方法，同时探索物理正则化与数学正则化的效果。

Method: 采用物理信息线性模型（PILM），通过线性基函数组合表示解，并应用于正反问题及不确定边界条件下的验证。

Result: PILM在弹性平衡约束下表现良好，但数学正则化在贝叶斯框架下效果更优。

Conclusion: PILM为线性正反问题及欠定系统提供了解析求解框架，物理正则化与数学正则化的比较为后续研究提供了方向。

Abstract: Many physical systems are described by partial differential equations (PDEs),
and solving these equations and estimating their coefficients or boundary
conditions (BCs) from observational data play a crucial role in understanding
the associated phenomena. Recently, a machine learning approach known as
physics-informed neural network, which solves PDEs using neural networks by
minimizing the sum of residuals from the PDEs, BCs, and data, has gained
significant attention in the scientific community. In this study, we
investigate a physics-informed linear model (PILM) that uses linear
combinations of basis functions to represent solutions, thereby enabling an
analytical representation of optimal solutions. The PILM was formulated and
verified for illustrative forward and inverse problems including cases with
uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain
rates using geodetic data. Specifically, physical regularization that enforces
elastic equilibrium on the velocity fields was compared with mathematical
regularization that imposes smoothness constraints. From a Bayesian
perspective, mathematical regularization exhibited superior performance. The
PILM provides an analytically solvable framework applicable to linear forward
and inverse problems, underdetermined systems, and physical regularization.

</details>


### [217] [Optimizers Qualitatively Alter Solutions And We Should Leverage This](https://arxiv.org/abs/2507.12224)
*Razvan Pascanu,Clare Lyle,Ionut-Vlad Modoranu,Naima Elosegui Borras,Dan Alistarh,Petar Velickovic,Sarath Chandar,Soham De,James Martens*

Main category: cs.LG

TL;DR: 论文探讨了深度神经网络（DNN）优化器的设计不仅影响收敛速度，还影响学习解的性质，呼吁关注优化器的归纳偏置及其对模型表达力的影响。


<details>
  <summary>Details</summary>
Motivation: 早期对DNN可行性的怀疑源于其非线性特性可能导致优化不收敛，但实践表明标准训练协议下DNN表现良好。然而，当前研究过于关注优化效率，忽视了优化器对学习解性质的影响。

Method: 通过分析现有优化器的行为，提出优化器不仅影响收敛速度，还能通过编码归纳偏置改变模型的有效表达力。

Result: 优化器设计应被视为与架构和数据同等重要的杠杆，能够显著影响模型的学习结果。

Conclusion: 呼吁社区关注优化器的归纳偏置，设计能够诱导特定解性质的新优化器，而不仅仅是追求收敛速度的提升。

Abstract: Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not
guarantee convergence to a unique global minimum of the loss when using
optimizers relying only on local information, such as SGD. Indeed, this was a
primary source of skepticism regarding the feasibility of DNNs in the early
days of the field. The past decades of progress in deep learning have revealed
this skepticism to be misplaced, and a large body of empirical evidence shows
that sufficiently large DNNs following standard training protocols exhibit
well-behaved optimization dynamics that converge to performant solutions. This
success has biased the community to use convex optimization as a mental model
for learning, leading to a focus on training efficiency, either in terms of
required iteration, FLOPs or wall-clock time, when improving optimizers. We
argue that, while this perspective has proven extremely fruitful, another
perspective specific to DNNs has received considerably less attention: the
optimizer not only influences the rate of convergence, but also the qualitative
properties of the learned solutions. Restated, the optimizer can and will
encode inductive biases and change the effective expressivity of a given class
of models. Furthermore, we believe the optimizer can be an effective way of
encoding desiderata in the learning process. We contend that the community
should aim at understanding the biases of already existing methods, as well as
aim to build new optimizers with the explicit intent of inducing certain
properties of the solution, rather than solely judging them based on their
convergence rates. We hope our arguments will inspire research to improve our
understanding of how the learning process can impact the type of solution we
converge to, and lead to a greater recognition of optimizers design as a
critical lever that complements the roles of architecture and data in shaping
model outcomes.

</details>


### [218] [Robust Causal Discovery in Real-World Time Series with Power-Laws](https://arxiv.org/abs/2507.12257)
*Matteo Tusoni,Giuseppe Masi,Andrea Coletta,Aldo Glielmo,Viviana Arrigoni,Novella Bartolini*

Main category: cs.LG

TL;DR: 提出了一种基于幂律谱特征的鲁棒因果发现方法，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索随机时间序列中的因果关系具有广泛应用，但现有方法对噪声敏感，导致误导性推断。

Method: 利用时间序列的幂律谱特征提取真实因果信号，构建鲁棒方法。

Result: 在合成和真实数据集上优于现有方法，验证了鲁棒性和实用性。

Conclusion: 基于幂律谱特征的方法在因果发现中具有显著优势。

Abstract: Exploring causal relationships in stochastic time series is a challenging yet
crucial task with a vast range of applications, including finance, economics,
neuroscience, and climate science. Many algorithms for Causal Discovery (CD)
have been proposed, but they often exhibit a high sensitivity to noise,
resulting in misleading causal inferences when applied to real data. In this
paper, we observe that the frequency spectra of typical real-world time series
follow a power-law distribution, notably due to an inherent self-organizing
behavior. Leveraging this insight, we build a robust CD method based on the
extraction of power -law spectral features that amplify genuine causal signals.
Our method consistently outperforms state-of-the-art alternatives on both
synthetic benchmarks and real-world datasets with known causal structures,
demonstrating its robustness and practical relevance.

</details>


### [219] [A Framework for Nonstationary Gaussian Processes with Neural Network Parameters](https://arxiv.org/abs/2507.12262)
*Zachary James,Joseph Guinness*

Main category: cs.LG

TL;DR: 提出了一种使用非平稳核的高斯过程框架，通过神经网络动态调整核参数，提升了模型表达能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程通常使用平稳核，限制了模型的表达能力，难以适应复杂数据集。

Method: 将非平稳核参数建模为神经网络的输出，联合训练神经网络和高斯过程，支持大规模数据扩展。

Result: 在多个数据集上测试，非平稳核模型在准确性和对数得分上优于平稳模型和变分推断的层次模型。

Conclusion: 该方法灵活且易于扩展，能够有效恢复非平稳参数，适用于复杂数据集。

Abstract: Gaussian processes have become a popular tool for nonparametric regression
because of their flexibility and uncertainty quantification. However, they
often use stationary kernels, which limit the expressiveness of the model and
may be unsuitable for many datasets. We propose a framework that uses
nonstationary kernels whose parameters vary across the feature space, modeling
these parameters as the output of a neural network that takes the features as
input. The neural network and Gaussian process are trained jointly using the
chain rule to calculate derivatives. Our method clearly describes the behavior
of the nonstationary parameters and is compatible with approximation methods
for scaling to large datasets. It is flexible and easily adapts to different
nonstationary kernels without needing to redesign the optimization procedure.
Our methods are implemented with the GPyTorch library and can be readily
modified. We test a nonstationary variance and noise variant of our method on
several machine learning datasets and find that it achieves better accuracy and
log-score than both a stationary model and a hierarchical model approximated
with variational inference. Similar results are observed for a model with only
nonstationary variance. We also demonstrate our approach's ability to recover
the nonstationary parameters of a spatial dataset.

</details>


### [220] [RegCL: Continual Adaptation of Segment Anything Model via Model Merging](https://arxiv.org/abs/2507.12297)
*Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang*

Main category: cs.LG

TL;DR: 本文提出RegCL，一种新型的非回放持续学习框架，通过模型合并实现多领域知识的高效整合，解决了Segment Anything Model（SAM）在特定领域性能受限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为针对特定领域的适配器式一步适应范式，跨领域使用时性能下降，严重限制了模型的可扩展性。

Method: RegCL将模型合并算法引入持续学习范式，通过合并不同领域训练的SAM适配模块（如LoRA模块）参数，以权重优化为指导最小化预测差异。

Result: 实验表明，RegCL在多个下游数据集上实现了良好的持续学习性能，验证了其在动态场景中的有效性。

Conclusion: RegCL通过模型合并有效整合多领域知识，同时保持参数效率，无需历史数据存储，模型大小恒定。

Abstract: To address the performance limitations of the Segment Anything Model (SAM) in
specific domains, existing works primarily adopt adapter-based one-step
adaptation paradigms. However, some of these methods are specific developed for
specific domains. If used on other domains may lead to performance degradation.
This issue of catastrophic forgetting severely limits the model's scalability.
To address this issue, this paper proposes RegCL, a novel non-replay continual
learning (CL) framework designed for efficient multi-domain knowledge
integration through model merging. Specifically, RegCL incorporates the model
merging algorithm into the continual learning paradigm by merging the
parameters of SAM's adaptation modules (e.g., LoRA modules) trained on
different domains. The merging process is guided by weight optimization, which
minimizes prediction discrepancies between the merged model and each of the
domain-specific models. RegCL effectively consolidates multi-domain knowledge
while maintaining parameter efficiency, i.e., the model size remains constant
regardless of the number of tasks, and no historical data storage is required.
Experimental results demonstrate that RegCL achieves favorable continual
learning performance across multiple downstream datasets, validating its
effectiveness in dynamic scenarios.

</details>


### [221] [PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning](https://arxiv.org/abs/2507.12305)
*M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk*

Main category: cs.LG

TL;DR: 提出了一种基于提示的在线持续学习方法，解决了数据隐私和参数增长问题，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在线持续学习中数据隐私限制加剧了灾难性遗忘问题，现有方法存在数据开放政策或参数增长的局限性。

Method: 提出包含轻量级提示生成器、可训练缩放移位器、预训练模型保留和硬软更新机制的提示方法。

Result: 在多个数据集上性能显著优于现有技术，参数较少且训练和推理时间适中。

Conclusion: 该方法在性能和效率上均表现优异，代码已开源。

Abstract: The data privacy constraint in online continual learning (OCL), where the
data can be seen only once, complicates the catastrophic forgetting problem in
streaming data. A common approach applied by the current SOTAs in OCL is with
the use of memory saving exemplars or features from previous classes to be
replayed in the current task. On the other hand, the prompt-based approach
performs excellently in continual learning but with the cost of a growing
number of trainable parameters. The first approach may not be applicable in
practice due to data openness policy, while the second approach has the issue
of throughput associated with the streaming data. In this study, we propose a
novel prompt-based method for online continual learning that includes 4 main
components: (1) single light-weight prompt generator as a general knowledge,
(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model
(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our
proposed method achieves significantly higher performance than the current
SOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity
analysis shows that our method requires a relatively smaller number of
parameters and achieves moderate training time, inference time, and throughput.
For further study, the source code of our method is available at
https://github.com/anwarmaxsum/PROL.

</details>


### [222] [Thought Purity: Defense Paradigm For Chain-of-Thought Attack](https://arxiv.org/abs/2507.12314)
*Zihao Xue,Zhen Bi,Long Ma,Zhenlin Hu,Yan Wang,Zhenfang Liu,Qing Sheng,Jie Xiao,Jungang Lou*

Main category: cs.LG

TL;DR: 论文提出了一种名为Thought Purity (TP)的防御范式，用于解决强化学习训练的大型推理模型（LRMs）在Chain-of-Thought (CoT)生成过程中面临的安全威胁，如后门提示攻击。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习训练的大型推理模型（如Deepseek-R1）在推理能力上表现优异，但其在Chain-of-Thought生成过程中容易受到安全威胁，如后门提示攻击，导致推理机制被系统性破坏。

Method: 提出的Thought Purity (TP)防御范式包含三个协同组件：(1) 安全性优化的数据处理流程，(2) 强化学习增强的规则约束，(3) 自适应监控指标。

Result: 该方案首次为强化学习对齐的推理系统建立了全面的防御机制，显著提升了安全性与功能性的平衡。

Conclusion: Thought Purity (TP)为下一代AI架构的安全性与功能性平衡提供了重要进展。

Abstract: While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,
Deepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large
Language Models (LLMs) domain, their susceptibility to security threats remains
a critical vulnerability. This weakness is particularly evident in
Chain-of-Thought (CoT) generation processes, where adversarial methods like
backdoor prompt attacks can systematically subvert the model's core reasoning
mechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this
vulnerability through exploiting prompt controllability, simultaneously
degrading both CoT safety and task performance with low-cost interventions. To
address this compounded security-performance vulnerability, we propose Thought
Purity (TP): a defense paradigm that systematically strengthens resistance to
malicious content while preserving operational efficacy. Our solution achieves
this through three synergistic components: (1) a safety-optimized data
processing pipeline (2) reinforcement learning-enhanced rule constraints (3)
adaptive monitoring metrics. Our approach establishes the first comprehensive
defense mechanism against CoTA vulnerabilities in reinforcement
learning-aligned reasoning systems, significantly advancing the
security-functionality equilibrium for next-generation AI architectures.

</details>


### [223] [Nonlinear Concept Erasure: a Density Matching Approach](https://arxiv.org/abs/2507.12341)
*Antoine Saillenfest,Pirmin Lemberger*

Main category: cs.LG

TL;DR: 论文提出了一种概念擦除方法（LEOPARD），通过正交投影从文本表示中移除敏感信息（如性别或种族），同时保留其他语义信息，以提升公平性。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络模型可能从文本表示中推断敏感信息（如人口统计属性）的问题，以确保公平性。

Method: 使用正交投影在嵌入空间中学习，使离散概念的类条件特征分布在投影后无法区分，并通过调整投影秩控制信息移除程度。

Result: LEOPARD在经典NLP基准测试中实现了最先进的离散属性非线性擦除性能，并有效减少了深度非线性分类器的偏见。

Conclusion: LEOPARD方法在移除敏感信息的同时保留了语义信息，显著提升了模型的公平性。

Abstract: Ensuring that neural models used in real-world applications cannot infer
sensitive information, such as demographic attributes like gender or race, from
text representations is a critical challenge when fairness is a concern. We
address this issue through concept erasure, a process that removes information
related to a specific concept from distributed representations while preserving
as much of the remaining semantic information as possible. Our approach
involves learning an orthogonal projection in the embedding space, designed to
make the class-conditional feature distributions of the discrete concept to
erase indistinguishable after projection. By adjusting the rank of the
projector, we control the extent of information removal, while its
orthogonality ensures strict preservation of the local structure of the
embeddings. Our method, termed $\overline{\mathrm{L}}$EOPARD, achieves
state-of-the-art performance in nonlinear erasure of a discrete attribute on
classic natural language processing benchmarks. Furthermore, we demonstrate
that $\overline{\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear
classifiers, thereby promoting fairness.

</details>


### [224] [Heat Kernel Goes Topological](https://arxiv.org/abs/2507.12380)
*Maximilian Krahn,Vikas Garg*

Main category: cs.LG

TL;DR: 提出了一种基于组合复形（CCs）的新型拓扑框架，通过引入拉普拉斯算子计算热核作为节点描述符，解决了高阶消息传递的计算开销问题。该方法具有多尺度信息捕捉和置换等变性，适用于现代Transformer架构。


<details>
  <summary>Details</summary>
Motivation: 解决拓扑神经网络中高阶消息传递带来的高计算成本问题，同时提升表达能力和计算效率。

Method: 在组合复形上引入拉普拉斯算子，计算高效的热核作为节点描述符，支持多尺度信息捕捉和置换等变表示。

Result: 理论证明该方法能区分任意非同构组合复形；实验显示其在计算效率和性能上优于现有拓扑方法，并在分子数据集和拓扑基准测试中表现优异。

Conclusion: 该方法为拓扑深度学习提供了高效且表达能力强的表示，为分子分类和性质预测任务开辟了新途径。

Abstract: Topological neural networks have emerged as powerful successors of graph
neural networks. However, they typically involve higher-order message passing,
which incurs significant computational expense. We circumvent this issue with a
novel topological framework that introduces a Laplacian operator on
combinatorial complexes (CCs), enabling efficient computation of heat kernels
that serve as node descriptors. Our approach captures multiscale information
and enables permutation-equivariant representations, allowing easy integration
into modern transformer-based architectures.
  Theoretically, the proposed method is maximally expressive because it can
distinguish arbitrary non-isomorphic CCs. Empirically, it significantly
outperforms existing topological methods in terms of computational efficiency.
Besides demonstrating competitive performance with the state-of-the-art
descriptors on standard molecular datasets, it exhibits superior capability in
distinguishing complex topological structures and avoiding blind spots on
topological benchmarks. Overall, this work advances topological deep learning
by providing expressive yet scalable representations, thereby opening up
exciting avenues for molecular classification and property prediction tasks.

</details>


### [225] [Improving Reinforcement Learning Sample-Efficiency using Local Approximation](https://arxiv.org/abs/2507.12383)
*Mohit Prashant,Arvind Easwaran*

Main category: cs.LG

TL;DR: 本文提出了在无限时间马尔可夫决策过程（MDP）中，比现有文献更精确的强化学习（RL）样本复杂度的PAC边界。通过近似原始MDP，样本复杂度降低了对数因子。


<details>
  <summary>Details</summary>
Motivation: 现有RL样本复杂度的PAC边界不够精确，本文旨在通过分析状态间的距离和相关性，提出更优的边界。

Method: 通过构建原始MDP的子集近似，减少样本复杂度，并扩展到无限时间、无模型设置，提出PAC-MDP算法。

Result: 样本复杂度降至O(SA log A)时间步，并通过实验验证了显著改进。

Conclusion: 本文提出的方法显著降低了样本复杂度，为RL的实际应用提供了更高效的解决方案。

Abstract: In this study, we derive Probably Approximately Correct (PAC) bounds on the
asymptotic sample-complexity for RL within the infinite-horizon Markov Decision
Process (MDP) setting that are sharper than those in existing literature. The
premise of our study is twofold: firstly, the further two states are from each
other, transition-wise, the less relevant the value of the first state is when
learning the $\epsilon$-optimal value of the second; secondly, the amount of
'effort', sample-complexity-wise, expended in learning the $\epsilon$-optimal
value of a state is independent of the number of samples required to learn the
$\epsilon$-optimal value of a second state that is a sufficient number of
transitions away from the first. Inversely, states within each other's vicinity
have values that are dependent on each other and will require a similar number
of samples to learn. By approximating the original MDP using smaller MDPs
constructed using subsets of the original's state-space, we are able to reduce
the sample-complexity by a logarithmic factor to $O(SA \log A)$ timesteps,
where $S$ and $A$ are the state and action space sizes. We are able to extend
these results to an infinite-horizon, model-free setting by constructing a
PAC-MDP algorithm with the aforementioned sample-complexity. We conclude with
showing how significant the improvement is by comparing our algorithm against
prior work in an experimental setting.

</details>


### [226] [Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries](https://arxiv.org/abs/2507.12384)
*Bo Wen,Guoyun Gao,Zhicheng Xu,Ruibin Mao,Xiaojuan Qi,X. Sharon Hu,Xunzhao Yin,Can Li*

Main category: cs.LG

TL;DR: 提出了一种基于$MoS_2$闪存模拟CAM的软树模型硬件-软件协同设计方法，显著提升了对抗设备变异和攻击的鲁棒性，同时保持高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 人工智能的快速发展引发了对可信赖性的关注，尤其是可解释性和鲁棒性。传统树模型在扩展性上存在计算成本高的问题，而现有模拟CAM方法因设备变异导致性能不佳。

Method: 采用$MoS_2$闪存模拟CAM的软边界特性，设计了一种软树模型硬件-软件协同方法。

Result: 在WDBC数据库上达到96%准确率，MNIST数据集在10%设备变异下仅下降0.6%准确率，优于传统决策树的45.3%下降。

Conclusion: 该工作为提升AI可信赖性和效率的专用硬件设计提供了新方向。

Abstract: The rapid advancement of artificial intelligence has raised concerns
regarding its trustworthiness, especially in terms of interpretability and
robustness. Tree-based models like Random Forest and XGBoost excel in
interpretability and accuracy for tabular data, but scaling them remains
computationally expensive due to poor data locality and high data dependence.
Previous efforts to accelerate these models with analog content addressable
memory (CAM) have struggled, due to the fact that the difficult-to-implement
sharp decision boundaries are highly susceptible to device variations, which
leads to poor hardware performance and vulnerability to adversarial attacks.
This work presents a novel hardware-software co-design approach using $MoS_2$
Flash-based analog CAM with inherent soft boundaries, enabling efficient
inference with soft tree-based models. Our soft tree model inference
experiments on $MoS_2$ analog CAM arrays show this method achieves exceptional
robustness against device variation and adversarial attacks while achieving
state-of-the-art accuracy. Specifically, our fabricated analog CAM arrays
achieve $96\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,
while maintaining decision explainability. Our experimentally calibrated model
validated only a $0.6\%$ accuracy drop on the MNIST dataset under $10\%$ device
threshold variation, compared to a $45.3\%$ drop for traditional decision
trees. This work paves the way for specialized hardware that enhances AI's
trustworthiness and efficiency.

</details>


### [227] [ROC-n-reroll: How verifier imperfection affects test-time scaling](https://arxiv.org/abs/2507.12399)
*Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang*

Main category: cs.LG

TL;DR: 论文研究了测试时扩展（test-time scaling）中验证器不完美对性能的影响，通过ROC曲线的几何特性分析了Best-of-N和拒绝采样的准确性。


<details>
  <summary>Details</summary>
Motivation: 填补验证器不完美如何影响测试时扩展性能的理论空白。

Method: 通过分析验证器ROC曲线的几何特性，理论推导Best-of-N和拒绝采样的实例级准确性。

Result: 拒绝采样在固定计算量下优于Best-of-N，但在无限计算量下两者性能趋同，取决于ROC曲线原点附近的斜率。

Conclusion: 验证器的ROC曲线几何特性决定了测试时扩展方法的性能，实验验证了理论结果。

Abstract: Test-time scaling aims to improve language model performance by leveraging
additional compute during inference. While many works have empirically studied
techniques like Best-of-N (BoN) and rejection sampling that make use of a
verifier to enable test-time scaling, there is little theoretical understanding
of how verifier imperfection affects performance. In this work, we address this
gap. Specifically, we prove how instance-level accuracy of these methods is
precisely characterized by the geometry of the verifier's ROC curve.
Interestingly, while scaling is determined by the local geometry of the ROC
curve for rejection sampling, it depends on global properties of the ROC curve
for BoN. As a consequence when the ROC curve is unknown, it is impossible to
extrapolate the performance of rejection sampling based on the low-compute
regime. Furthermore, while rejection sampling outperforms BoN for fixed
compute, in the infinite-compute limit both methods converge to the same level
of accuracy, determined by the slope of the ROC curve near the origin. Our
theoretical results are confirmed by experiments on GSM8K using different
versions of Llama and Qwen to generate and verify solutions.

</details>


### [228] [NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data](https://arxiv.org/abs/2507.12412)
*Dzung Dinh,Boqi Chen,Marc Niethammer,Junier Oliva*

Main category: cs.LG

TL;DR: NOCTA是一种非贪婪目标成本权衡获取方法，用于在资源受限的预测任务中动态选择最具信息量的特征。


<details>
  <summary>Details</summary>
Motivation: 在医疗等关键应用中，资源限制和特征获取成本（时间、金钱、风险）使得动态选择信息量最大的特征至关重要。

Method: 提出了NOCTA方法，包括非参数（NOCTA-NP）和参数（NOCTA-P）两种互补的估计器，用于动态特征获取。

Result: 在合成和真实医疗数据集上的实验表明，NOCTA优于现有基线方法。

Conclusion: NOCTA能有效平衡特征获取成本和信息量，适用于资源受限的动态预测任务。

Abstract: In many critical applications, resource constraints limit the amount of
information that can be gathered to make predictions. For example, in
healthcare, patient data often spans diverse features ranging from lab tests to
imaging studies. Each feature may carry different information and must be
acquired at a respective cost of time, money, or risk to the patient. Moreover,
temporal prediction tasks, where both instance features and labels evolve over
time, introduce additional complexity in deciding when or what information is
important. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff
Acquisition method that sequentially acquires the most informative features at
inference time while accounting for both temporal dynamics and acquisition
cost. We first introduce a cohesive estimation target for our NOCTA setting,
and then develop two complementary estimators: 1) a non-parametric method based
on nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric
method that directly predicts the utility of potential acquisitions (NOCTA-P).
Experiments on synthetic and real-world medical datasets demonstrate that both
NOCTA variants outperform existing baselines.

</details>


### [229] [Mixture of Raytraced Experts](https://arxiv.org/abs/2507.12419)
*Andrea Perin,Giacomo Lagomarsini,Claudio Gallicchio,Giuseppe Nuti*

Main category: cs.LG

TL;DR: 提出了一种动态选择专家序列的混合专家架构（MoE），通过可变宽度和深度的计算图逐步提高预测精度，无需负载平衡机制，训练效率提升10%-40%。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构通常需要固定计算量，限制了模型的灵活性和效率。本文旨在设计一种动态选择专家序列的方法，以逐步提升预测精度。

Method: 采用类似RNN的训练方式，迭代采样候选专家序列，构建可变宽度和深度的计算图。

Result: 初步实验显示训练周期减少10%-40%，且精度相当或更高。

Conclusion: 该方法为MoE领域提供了新的研究方向，有望设计出更快、表达能力更强的模型。

Abstract: We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts
(MoE) architecture which can dynamically select sequences of experts, producing
computational graphs of variable width and depth. Existing MoE architectures
generally require a fixed amount of computation for a given sample. Our
approach, in contrast, yields predictions with increasing accuracy as the
computation cycles through the experts' sequence. We train our model by
iteratively sampling from a set of candidate experts, unfolding the sequence
akin to how Recurrent Neural Networks are trained. Our method does not require
load-balancing mechanisms, and preliminary experiments show a reduction in
training epochs of 10\% to 40\% with a comparable/higher accuracy. These
results point to new research directions in the field of MoEs, allowing the
design of potentially faster and more expressive models. The code is available
at https://github.com/nutig/RayTracing

</details>


### [230] [Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks](https://arxiv.org/abs/2507.12435)
*Yi Li,David Mccoy,Nolan Gunter,Kaitlyn Lee,Alejandro Schuler,Mark van der Laan*

Main category: cs.LG

TL;DR: 提出了一种名为TDA的新框架，将TMLE直接嵌入神经网络参数空间，解决了现有方法在因果推断中的偏差问题，并支持多参数目标。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络在预测方面强大，但在因果参数（如治疗效果或生存曲线）的推断上缺乏有效性。现有方法要么无法保证解决高效影响函数方程，要么计算成本高。

Method: TDA通过将模型参数分区并冻结大部分，仅更新一小部分“目标”参数，利用目标梯度迭代优化，从而消除一阶偏差并生成有效的置信区间。

Result: 在IHDP数据集和模拟生存数据上，TDA相比标准神经网络估计器和现有后处理方法，减少了偏差并提高了覆盖率。

Conclusion: TDA为复杂多参数目标的深度架构提供了一种直接且可扩展的严格因果推断途径。

Abstract: Modern deep neural networks are powerful predictive tools yet often lack
valid inference for causal parameters, such as treatment effects or entire
survival curves. While frameworks like Double Machine Learning (DML) and
Targeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,
existing neural implementations either rely on "targeted losses" that do not
guarantee solving the efficient influence function equation or computationally
expensive post-hoc "fluctuations" for multi-parameter settings. We propose
Targeted Deep Architectures (TDA), a new framework that embeds TMLE directly
into the network's parameter space with no restrictions on the backbone
architecture. Specifically, TDA partitions model parameters - freezing all but
a small "targeting" subset - and iteratively updates them along a targeting
gradient, derived from projecting the influence functions onto the span of the
gradients of the loss with respect to weights. This procedure yields plug-in
estimates that remove first-order bias and produce asymptotically valid
confidence intervals. Crucially, TDA easily extends to multi-dimensional causal
estimands (e.g., entire survival curves) by merging separate targeting
gradients into a single universal targeting update. Theoretically, TDA inherits
classical TMLE properties, including double robustness and semiparametric
efficiency. Empirically, on the benchmark IHDP dataset (average treatment
effects) and simulated survival data with informative censoring, TDA reduces
bias and improves coverage relative to both standard neural-network estimators
and prior post-hoc approaches. In doing so, TDA establishes a direct, scalable
pathway toward rigorous causal inference within modern deep architectures for
complex multi-parameter targets.

</details>


### [231] [Cost-aware Stopping for Bayesian Optimization](https://arxiv.org/abs/2507.12453)
*Qian Xie,Linda Cai,Alexander Terenin,Peter I. Frazier,Ziv Scully*

Main category: cs.LG

TL;DR: 提出了一种成本感知的贝叶斯优化停止规则，无需启发式调参，适用于不同评估成本，并与先进成本感知获取函数结合，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 在贝叶斯优化中，如何在高成本的黑盒函数评估中适时停止是一个重要问题，现有方法缺乏成本保证。

Method: 提出一种成本感知停止规则，与Pandora's Box Gittins Index（PBGI）和log expected improvement per cost两种获取函数结合，提供理论成本保证。

Result: 实验表明，该停止规则与PBGI结合时，在成本调整简单遗憾指标上优于其他方法。

Conclusion: 该方法在成本和性能间取得平衡，适用于超参数优化和神经网络架构搜索等任务。

Abstract: In automated machine learning, scientific discovery, and other applications
of Bayesian optimization, deciding when to stop evaluating expensive black-box
functions is an important practical consideration. While several adaptive
stopping rules have been proposed, in the cost-aware setting they lack
guarantees ensuring they stop before incurring excessive function evaluation
costs. We propose a cost-aware stopping rule for Bayesian optimization that
adapts to varying evaluation costs and is free of heuristic tuning. Our rule is
grounded in a theoretical connection to state-of-the-art cost-aware acquisition
functions, namely the Pandora's Box Gittins Index (PBGI) and log expected
improvement per cost. We prove a theoretical guarantee bounding the expected
cumulative evaluation cost incurred by our stopping rule when paired with these
two acquisition functions. In experiments on synthetic and empirical tasks,
including hyperparameter optimization and neural architecture size search, we
show that combining our stopping rule with the PBGI acquisition function
consistently matches or outperforms other acquisition-function--stopping-rule
pairs in terms of cost-adjusted simple regret, a metric capturing trade-offs
between solution quality and cumulative evaluation cost.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [232] [Real-Time Cloth Simulation Using WebGPU: Evaluating Limits of High-Resolution](https://arxiv.org/abs/2507.11794)
*Nak-Jun Sung,Jun Ma,TaeHeon Kim,Yoo-joo Choi,Min-Hyung Choi,Min Hong*

Main category: cs.GR

TL;DR: WebGPU在实时布料模拟中显著优于WebGL，支持高分辨率模拟和实时碰撞处理。


<details>
  <summary>Details</summary>
Motivation: 探索WebGPU在实时布料模拟中的潜力，解决传统WebGL方法在复杂物理模拟中的局限性。

Method: 使用Mass-Spring方法在WebGPU框架中实现布料模拟，集成碰撞检测和响应处理。

Result: WebGPU在高分辨率模拟中保持60fps，支持实时碰撞处理（4K-100K节点）。

Conclusion: WebGPU在实时性能和渲染质量之间取得平衡，适用于复杂3D对象的布料模拟。

Abstract: This study explores the capabilities of WebGPU, an emerging web graphics
paradigm, for real-time cloth simulation. Traditional WebGL-based methods have
been in handling complex physical simulations due to their emphasis on graphics
rendering rather than general-purpose GPU (GPGPU) operations. WebGPU, designed
to provide modern 3D graphics and computational capabilities, offers
significant improvements through parallel processing and support for
computational shaders. In this work, we implemented a cloth simulation system
using the Mass-Spring Method within the WebGPU framework, integrating collision
detection and response handling with the 3D surface model. First, comparative
performance evaluations demonstrate that WebGPU substantially outperforms
WebGL, particularly in high-resolution simulations, maintaining 60 frames per
second (fps) even with up to 640K nodes. The second experiment aimed to
determine the real-time limitations of WebGPU and confirmed that WebGPU can
handle real-time collisions between 4K and 100k cloth node models and a 100K
triangle surface model in real-time. These experiments also highlight the
importance of balancing real-time performance with realistic rendering when
handling collisions between cloth models and complex 3D objects. Our source
code is available at https://github.com/nakjun/Cloth-Simulation-WebGPU

</details>


### [233] [Measuring and predicting visual fidelity](https://arxiv.org/abs/2507.11857)
*Benjamin Watson,Alinda Friedman,Aaron McGaffey*

Main category: cs.GR

TL;DR: 研究测量和预测视觉保真度的技术，使用多边形模型和两种简化算法，通过命名时间、评分和偏好三种实验方法测量，发现自动预测方法对评分有效，但对偏好和命名时间效果较差。


<details>
  <summary>Details</summary>
Motivation: 探讨如何有效测量和预测视觉保真度，以改进视觉模型的质量评估方法。

Method: 使用多边形模型和两种简化算法，分为动物和人造物两类，通过命名时间、评分和偏好三种实验方法测量保真度变化。

Result: 实验方法对简化类型和程度敏感，但不同方法对物体类型的反应不同；自动预测方法对评分有效，对偏好和命名时间效果差。

Conclusion: 建议改进实验和自动测量方法，以提高视觉保真度评估的准确性。

Abstract: This paper is a study of techniques for measuring and predicting visual
fidelity. As visual stimuli we use polygonal models, and vary their fidelity
with two different model simplification algorithms. We also group the stimuli
into two object types: animals and man made artifacts. We examine three
different experimental techniques for measuring these fidelity changes: naming
times, ratings, and preferences. All the measures were sensitive to the type of
simplification and level of simplification. However, the measures differed from
one another in their response to object type. We also examine several automatic
techniques for predicting these experimental measures, including techniques
based on images and on the models themselves. Automatic measures of fidelity
were successful at predicting experimental ratings, less successful at
predicting preferences, and largely failures at predicting naming times. We
conclude with suggestions for use and improvement of the experimental and
automatic measures of visual fidelity.

</details>


### [234] [MOSPA: Human Motion Generation Driven by Spatial Audio](https://arxiv.org/abs/2507.11949)
*Shuyang Xu,Zhiyang Dou,Mingyi Shi,Liang Pan,Leo Ho,Jingbo Wang,Yuan Liu,Cheng Lin,Yuexin Ma,Wenping Wang,Taku Komura*

Main category: cs.GR

TL;DR: 论文提出了一种基于空间音频驱动的人体运动生成方法（MOSPA），并发布了首个全面的空间音频驱动人体运动数据集（SAM），填补了现有研究中忽略空间音频对人体运动影响的空白。


<details>
  <summary>Details</summary>
Motivation: 虚拟人如何动态且真实地响应多样化的听觉刺激是角色动画的关键挑战，但现有研究多集中于语音、音频和音乐驱动的运动生成，忽略了空间音频的空间特征对人运动的影响。

Method: 作者提出了一个简单而有效的扩散生成框架（MOSPA），通过有效的融合机制捕捉身体运动与空间音频之间的关系，并发布了高质量的空间音频和运动数据集（SAM）。

Result: MOSPA能够根据不同的空间音频输入生成多样且真实的人体运动，实验表明该方法在该任务上达到了最先进的性能。

Conclusion: 论文通过数据集和模型填补了空间音频驱动人体运动研究的空白，为未来相关研究提供了基础。

Abstract: Enabling virtual humans to dynamically and realistically respond to diverse
auditory stimuli remains a key challenge in character animation, demanding the
integration of perceptual modeling and motion synthesis. Despite its
significance, this task remains largely unexplored. Most previous works have
primarily focused on mapping modalities like speech, audio, and music to
generate human motion. As of yet, these models typically overlook the impact of
spatial features encoded in spatial audio signals on human motion. To bridge
this gap and enable high-quality modeling of human movements in response to
spatial audio, we introduce the first comprehensive Spatial Audio-Driven Human
Motion (SAM) dataset, which contains diverse and high-quality spatial audio and
motion data. For benchmarking, we develop a simple yet effective
diffusion-based generative framework for human MOtion generation driven by
SPatial Audio, termed MOSPA, which faithfully captures the relationship between
body motion and spatial audio through an effective fusion mechanism. Once
trained, MOSPA could generate diverse realistic human motions conditioned on
varying spatial audio inputs. We perform a thorough investigation of the
proposed dataset and conduct extensive experiments for benchmarking, where our
method achieves state-of-the-art performance on this task. Our model and
dataset will be open-sourced upon acceptance. Please refer to our supplementary
video for more details.

</details>


### [235] [HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing](https://arxiv.org/abs/2507.11971)
*Tielong Wang,Yuxuan Xiong,Jinfan Liu,Zhifan Zhang,Ye Chen,Yue Shi,Bingbing Ni*

Main category: cs.GR

TL;DR: 论文提出了一种新颖的3D分层代理节点表示方法，解决了现有3D表示（如网格、体素、点云和NeRF）在通用性、编辑性和复杂性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D表示方法（如网格、NeRF等）存在任务特定性、编辑复杂性和结构模糊性等问题，限制了其在重建、生成和编辑等任务中的通用性。

Method: 通过稀疏的分层组织（树状结构）代理节点表示物体的形状和纹理，每个节点存储局部信息，并通过轻量级MLP编码和解码实现高效查询。

Result: 实验表明，该方法在3D重建和编辑中表现出高效的表达能力、高保真渲染质量和卓越的可编辑性。

Conclusion: 分层代理节点表示提供了一种紧凑、高效且易于编辑的3D表示方法，显著优于现有技术。

Abstract: Current 3D representations like meshes, voxels, point clouds, and NeRF-based
neural implicit fields exhibit significant limitations: they are often
task-specific, lacking universal applicability across reconstruction,
generation, editing, and driving. While meshes offer high precision, their
dense vertex data complicates editing; NeRFs deliver excellent rendering but
suffer from structural ambiguity, hindering animation and manipulation; all
representations inherently struggle with the trade-off between data complexity
and fidelity. To overcome these issues, we introduce a novel 3D Hierarchical
Proxy Node representation. Its core innovation lies in representing an object's
shape and texture via a sparse set of hierarchically organized
(tree-structured) proxy nodes distributed on its surface and interior. Each
node stores local shape and texture information (implicitly encoded by a small
MLP) within its neighborhood. Querying any 3D coordinate's properties involves
efficient neural interpolation and lightweight decoding from relevant nearby
and parent nodes. This framework yields a highly compact representation where
nodes align with local semantics, enabling direct drag-and-edit manipulation,
and offers scalable quality-complexity control. Extensive experiments across 3D
reconstruction and editing demonstrate our method's expressive efficiency,
high-fidelity rendering quality, and superior editability.

</details>


### [236] [SmokeSVD: Smoke Reconstruction from A Single View via Progressive Novel View Synthesis and Refinement with Diffusion Models](https://arxiv.org/abs/2507.12156)
*Chen Li,Shanshan Dong,Sheng Qiu,Jianmin Han,Zan Gao,Kemeng Huang,Taku Komura*

Main category: cs.GR

TL;DR: SmokeSVD是一种高效框架，通过结合扩散模型和物理引导优化，从单视频重建动态烟雾，显著提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏视角下动态流体重建的挑战，避免传统方法耗时的优化过程。

Method: 结合扩散模型生成侧视图，通过物理引导优化逐步重建3D密度场和速度场。

Result: 实验表明，SmokeSVD在重建质量上优于现有技术。

Conclusion: SmokeSVD为动态流体重建提供了高效且高质量的解决方案。

Abstract: Reconstructing dynamic fluids from sparse views is a long-standing and
challenging problem, due to the severe lack of 3D information from insufficient
view coverage. While several pioneering approaches have attempted to address
this issue using differentiable rendering or novel view synthesis, they are
often limited by time-consuming optimization and refinement processes under
ill-posed conditions. To tackle above challenges, we propose SmokeSVD, an
efficient and effective framework to progressively generate and reconstruct
dynamic smoke from a single video by integrating both the powerful generative
capabilities from diffusion models and physically guided consistency
optimization towards realistic appearance and dynamic evolution. Specifically,
we first propose a physically guided side-view synthesizer based on diffusion
models, which explicitly incorporates divergence and gradient guidance of
velocity fields to generate visually realistic and spatio-temporally consistent
side-view images frame by frame, significantly alleviating the ill-posedness of
single-view reconstruction without imposing additional constraints.
Subsequently, we determine a rough estimation of density field from the pair of
front-view input and side-view synthetic image, and further refine 2D blurry
novel-view images and 3D coarse-grained density field through an iterative
process that progressively renders and enhances the images from increasing
novel viewing angles, generating high-quality multi-view image sequences.
Finally, we reconstruct and estimate the fine-grained density field, velocity
field, and smoke source via differentiable advection by leveraging the
Navier-Stokes equations. Extensive quantitative and qualitative experiments
show that our approach achieves high-quality reconstruction and outperforms
previous state-of-the-art techniques.

</details>


### [237] [Shape Adaptation for 3D Hairstyle Retargeting](https://arxiv.org/abs/2507.12168)
*Lu Yu,Zhong Ren,Youyi Zheng,Xiang Chen,Kun Zhou*

Main category: cs.GR

TL;DR: 提出一种自动形状适应方法，用于将3D发型重定向到新角色，通过多尺度策略和优化问题解决高分辨率发型的复杂几何和空间关系。


<details>
  <summary>Details</summary>
Motivation: 在游戏和VR应用中，为角色设计发型复杂且耗时，艺术家需要处理复杂的头发几何和空间关系。

Method: 将发型适应过程转化为约束优化问题，采用多尺度策略从粗到细计算发丝位置，并引入发际线编辑工具。

Result: 通过定量和定性实验验证了方法在多种发型和角色上的有效性。

Conclusion: 该方法能高效自动地重定向发型，同时支持用户自定义发际线。

Abstract: It is demanding to author an existing hairstyle for novel characters in games
and VR applications. However, it is a non-trivial task for artists due to the
complicated hair geometries and spatial interactions to preserve. In this
paper, we present an automatic shape adaptation method to retarget 3D
hairstyles. We formulate the adaptation process as a constrained optimization
problem, where all the shape properties and spatial relationships are converted
into individual objectives and constraints. To make such an optimization on
high-resolution hairstyles tractable, we adopt a multi-scale strategy to
compute the target positions of the hair strands in a coarse-to-fine manner.
The global solving for the inter-strands coupling is restricted to the coarse
level, and the solving for fine details is made local and parallel. In
addition, we present a novel hairline edit tool to allow for user customization
during retargeting. We achieve it by solving physics-based deformations of an
embedded membrane to redistribute the hair roots with minimal distortion. We
demonstrate the efficacy of our method through quantitative and qualitative
experiments on various hairstyles and characters.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [238] [New allocation rule based on graph structures and their application to economic phenomena](https://arxiv.org/abs/2507.11808)
*Taiki Yamada,Taisuke Matsubae,Tomoya Akamatsu*

Main category: cs.GT

TL;DR: 论文提出了一种基于边的Shapley值分配规则，适用于网络化系统，强调边（交互）在价值生成中的作用，解决了传统节点级分配规则的不足。


<details>
  <summary>Details</summary>
Motivation: 传统分配规则（如Shapley值和Myerson值）主要基于节点特性或连通组件，未能充分捕捉边在价值生成中的关键作用，尤其是在供应链和数字平台等系统中。

Method: 提出了一种新的分配规则，将特征函数从节点集转移到边集，支持更细粒度和上下文敏感的贡献评估。

Result: 理论分析表明，该方法保留了公平性和对称性等关键性质，并在内容平台网络和供应链物流的实际案例中验证了其有效性。

Conclusion: 该框架为复杂交互结构中的价值分配提供了新视角，并为现实经济和物流网络分析提供了实用工具。

Abstract: This study introduces the \emph{edge-based Shapley value}, a novel allocation
rule within cooperative game theory, specifically tailored for networked
systems, where value is generated through interactions represented by edges.
Traditional allocation rules, such as the Shapley and Myerson values, evaluate
player contributions based on node-level characteristics, or connected
components. However, these approaches often fail to adequately capture the
functional role of edges, which are crucial in systems such as supply chains
and digital platforms, where interactions, rather than individual agents, are
the primary drivers of value. Our edge-based Shapley value shifts the
characteristic function from node sets to edge sets, thereby enabling a more
granular and context-sensitive evaluation of the contributions. We establish
its theoretical foundations, demonstrate its relationship to classical
allocation rules, and show that it retains key properties such as fairness and
symmetry. To illustrate its applicability, we present two use cases: content
platform networks and supply chain logistics (SCL). In both cases, our method
produces intuitive and structurally consistent allocations, particularly in
scenarios with overlapping routes, exclusive contracts or cost-sensitive paths.
This framework offers a new perspective on value attribution in cooperative
settings with complex interaction structures and provides practical tools for
analyzing real-world economic and logistical networks.

</details>


### [239] [Coalitions on the Fly in Cooperative Games](https://arxiv.org/abs/2507.11883)
*Yao Zhang,Indrajit Saha,Zhaohong Sun,Makoto Yokoo*

Main category: cs.GT

TL;DR: 本文研究了动态玩家加入的合作博弈，设计了一种在线价值分配策略，以激励玩家形成最大化社会福利的联盟结构。


<details>
  <summary>Details</summary>
Motivation: 探讨动态环境下玩家如何选择加入或形成联盟，以最大化个人奖励和社会福利。

Method: 假设玩家是贪婪的，基于到达时的信息做决策，提出不可撤销策略的竞争比率上界，并设计了一种接近最优的策略。

Result: 证明了不可撤销策略的竞争比率上界为$\frac{3\mathsf{min}}{\mathsf{max}}$，并提出了一种竞争比率为$\min\left\{\frac{1}{2}, \frac{3\mathsf{min}}{\mathsf{max}}\right\}$的策略。

Conclusion: 在有限玩家情况下，非不可撤销策略可能有更好的表现。

Abstract: In this work, we examine a sequential setting of a cooperative game in which
players arrive dynamically to form coalitions and complete tasks either
together or individually, depending on the value created. Upon arrival, a new
player as a decision maker faces two options: forming a new coalition or
joining an existing one. We assume that players are greedy, i.e., they aim to
maximize their rewards based on the information available at their arrival. The
objective is to design an online value distribution policy that incentivizes
players to form a coalition structure that maximizes social welfare. We focus
on monotone and bounded cooperative games. Our main result establishes an upper
bound of $\frac{3\mathsf{min}}{\mathsf{max}}$ on the competitive ratio for any
irrevocable policy (i.e., one without redistribution), and proposes a policy
that achieves a near-optimal competitive ratio of $\min\left\{\frac{1}{2},
\frac{3\mathsf{min}}{\mathsf{max}}\right\}$, where $\mathsf{min}$ and
$\mathsf{max}$ denote the smallest and largest marginal contribution of any
sub-coalition of players respectively. Finally, we also consider
non-irrevocable policies, with alternative bounds only when the number of
players is limited.

</details>


### [240] [Contracting with a Mechanism Designer](https://arxiv.org/abs/2507.12054)
*Tian Bai,Yiding Feng,Yaohao Liu,Mengfan Ma,Mingyu Xiao*

Main category: cs.GT

TL;DR: 本文研究现代众包市场的经济互动，提出三方模型（请求者、平台、工作者），分析其作为Stackelberg博弈的子博弈完美均衡，并引入新概念量化效用损失。


<details>
  <summary>Details</summary>
Motivation: 探索众包市场中请求者、平台和工作者之间的经济互动，理解其角色分工及激励机制。

Method: 提出三方模型，将其建模为Stackelberg博弈，分析子博弈完美均衡，并引入虚拟价值定价和线性合同。

Result: 发现线性合同在多种任务结果和不对称成本分布下仍为最优，量化了双重边际化和信息不对称的效用损失。

Conclusion: 研究为众包市场的合同设计和平台机制提供了理论支持，并扩展至信息不完全的鲁棒框架。

Abstract: This paper explores the economic interactions within modern crowdsourcing
markets. In these markets, employers issue requests for tasks, platforms
facilitate the recruitment of crowd workers, and workers complete tasks for
monetary rewards. Recognizing that these roles serve distinct functions within
the ecosystem, we introduce a three-party model that distinguishes among the
principal (the requester), the intermediary (the platform), and the pool of
agents (the workers). The principal, unable to directly engage with agents,
relies on the intermediary to recruit and incentivize them. This interaction
unfolds in two stages: first, the principal designs a profit-sharing contract
with the intermediary; second, the intermediary implements a mechanism to
select an agent to complete the delegated task.
  We analyze the proposed model as an extensive-form Stackelberg game. Our
contributions are fourfold: (1) We fully characterize the subgame perfect
equilibrium. In particular, we reduce the principal's contract design problem
to a novel auction-theoretic formulation we term virtual value pricing, and
reveals that linear contracts are optimal even when the task have multiple
outcomes and agents' cost distributions are asymmetric. (2) To quantify the
principal's utility loss from delegation and information asymmetry, we
introduce the price of double marginalization (PoDM) and the classical price of
anarchy (PoA), and derive tight or nearly tight bounds on both ratios under
regular and monotone hazard rate (MHR) distributions. (3) We further examine
these two ratios in a natural setting where the intermediary is restricted to
anonymous pricing mechanisms, and show that similar qualitative insights
continue to hold. (4) Finally, we extend our results on both ratios to a robust
framework that accommodates scenarios in which the principal lacks precise
information about the market size.

</details>
