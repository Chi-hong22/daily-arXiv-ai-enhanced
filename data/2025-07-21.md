<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 82]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.LG](#cs.LG) [Total: 52]
- [cs.SD](#cs.SD) [Total: 3]
- [cs.RO](#cs.RO) [Total: 21]
- [eess.SY](#eess.SY) [Total: 16]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.HC](#cs.HC) [Total: 12]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 本文综述了无人机（UAV）航拍图像中的开放词汇目标检测（OVOD），探讨了其核心原理、方法分类、数据集及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统无人机目标检测方法局限于预定义类别，而跨模态文本-图像对齐技术（如CLIP）的出现推动了开放词汇目标检测的发展，提升了无人机在航拍场景中的智能性和自主性。

Method: 通过将OVOD核心原理与无人机视觉特点结合，构建系统分类法，综述现有方法及相关数据集，并分析关键挑战。

Result: 提出了无人机航拍场景中OVOD的系统性综述，明确了当前挑战和开放问题。

Conclusion: 本文为研究者提供了清晰的路线图和参考，促进了这一快速发展领域的创新。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [2] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: EDNIG是一种基于U-Net架构的新型深度学习框架，用于低光图像增强，结合了亮度图和多尺度特征提取，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强问题，通过引入亮度引导和多尺度特征提取，提升模型在复杂光照条件下的表现。

Method: 采用U-Net架构，结合亮度图（BCP）和多尺度特征提取（SPP），使用Swish激活函数和GAN框架优化。

Result: EDNIG在定量指标和视觉质量上优于现有方法，同时模型复杂度较低。

Conclusion: EDNIG是一种高效的低光图像增强方法，适用于实际应用。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [3] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: VLMs在复杂视觉任务中表现出色，但在非局部视觉推理任务中表现不佳，甚至低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 评估VLMs在非局部视觉推理任务中的能力，揭示其核心视觉推理缺陷。

Method: 设计三种非局部视觉任务（比较感知、扫视搜索、平滑视觉搜索），测试主流VLMs的性能。

Result: 主流VLMs在任务中表现差，接近随机准确率，远低于人类水平。

Conclusion: 当前VLMs在非局部视觉推理能力上存在显著不足，需进一步改进。

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [4] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 研究发现，简单的Chain-of-Thought（CoT）提示可能损害视觉语言模型（VLM）的空间推理能力，而基于场景图的多阶段提示（SceneGraph CoT）显著提升准确性。使用Group Relative Policy Optimization（GRPO）微调模型在SAT数据集上表现优于监督微调（SFT），尤其在分布外（OOD）条件下更稳健。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过提示策略和强化学习提升视觉语言模型的空间推理能力及其泛化性。

Method: 评估不同提示策略（如CoT和SceneGraph CoT），并使用GRPO在SAT数据集上微调模型，对比SFT的效果。

Result: SceneGraph CoT显著提升空间推理准确性；GRPO在Pass@1评估中优于SFT，且在OOD条件下表现更稳健。

Conclusion: 强化学习和结构化提示能有效提升VLM的空间推理能力和泛化性，GRPO优于传统SFT方法。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [5] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 利用2D视觉语言模型进行开放词汇3D物体检测，无需人工标注3D标签，通过几何策略推断3D边界框，并在多种输入条件下实现竞争性定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D物体检测数据集受限于狭窄的类别分类和昂贵的人工标注，难以扩展到开放世界场景。2D视觉语言模型具有丰富的语义理解和开放词汇检测能力，可用于解决这一问题。

Method: 使用2D视觉语言检测器生成文本条件提案，通过SAM分割并利用相机几何和LiDAR或单目伪深度反投影到3D。引入基于DBSCAN聚类和旋转卡尺的几何膨胀策略推断3D边界框。构建Pseudo-nuScenes数据集模拟恶劣条件。

Result: 在LiDAR和RGB-D输入等多种设置下实现竞争性定位性能，且无需训练和开放词汇。

Conclusion: 展示了2D基础模型在可扩展3D感知中的潜力，代码和资源已开源。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [6] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种新型多模态多任务网络及训练算法，支持12种模态数据输入，通过共享Transformer架构和跨注意力机制实现统一嵌入空间，并在25个数据集上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态和多任务场景下的数据融合与任务协同问题，提升模型在多种模态数据上的表现。

Method: 使用模态专用分词器、共享Transformer架构和跨注意力机制，提出迭代模态切换预训练策略和成对模态训练算法。

Result: 在25个数据集上实现了最优性能，验证了架构、预训练策略和多任务训练的有效性。

Conclusion: 该方法在多模态和多任务场景中表现出色，为未来研究提供了有效框架。

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [7] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的端到端深度学习框架，用于增强医疗康复中的运动捕捉数据，解决噪声和缺失数据问题，并实时检测异常动作。


<details>
  <summary>Details</summary>
Motivation: 解决运动捕捉数据中的噪声和缺失问题，同时实时监测异常动作以确保患者安全，为远程康复提供可扩展、经济高效的解决方案。

Method: 结合光学运动捕捉和Transformer模型，利用时序序列建模对数据进行去噪和补全。

Result: 在卒中和骨科康复数据集上表现出优异的数据重建和异常检测性能。

Conclusion: 该框架为远程康复提供了高效、经济的解决方案，减少了对现场监督的依赖。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [8] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 提出了一种结合ViT和GNN的创新框架，用于乳腺癌检测，准确率达84.2%，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因，早期检测对提高生存率至关重要。

Method: 整合Vision Transformers（ViT）和Graph Neural Networks（GNN），利用ViT捕捉全局图像特征，GNN建模结构关系。

Result: 在CBIS-DDSM数据集上达到84.2%的准确率，并提供可解释的注意力热图。

Conclusion: 该框架在乳腺癌检测中表现优异，同时提供决策过程的可解释性，有助于临床诊断。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [9] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: Butter是一个新型目标检测框架，通过频率自适应特征一致性增强和渐进式分层特征融合网络，提升了多尺度特征表示能力，显著提高了检测精度并降低了模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有架构（如YOLO和DETR）在多尺度特征一致性和计算效率之间难以平衡，影响了自动驾驶场景中的目标检测效果。

Method: Butter引入了FAFCE组件（通过自适应频率滤波增强特征一致性）和PHFFNet模块（渐进融合多级特征以减少语义鸿沟）。

Result: 在BDD100K、KITTI和Cityscapes数据集上的实验表明，Butter在检测精度和计算效率方面表现优异。

Conclusion: Butter通过分层特征优化和融合，为实时自动驾驶场景提供了一种高精度、高效的目标检测解决方案。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [10] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: ModaRoute是一个基于LLM的多模态视频检索智能路由系统，通过动态选择最优模态，减少计算开销41%，同时保持60.9%的召回率。


<details>
  <summary>Details</summary>
Motivation: 现有密集文本标注方法需要昂贵的离线处理，且会遗漏34%的视觉信息（如场景文本）。

Method: 利用GPT-4.1分析查询意图，动态路由到ASR、OCR或视觉索引，平均每查询使用1.78种模态。

Result: 在180万视频片段上测试，计算开销减少41%，召回率为60.9%。

Conclusion: 智能路由为多模态检索系统提供了实用解决方案，降低了成本并保持了竞争力。

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [11] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 该论文综述了工业缺陷检测领域的最新进展，重点分析了从封闭集到开放集检测方法的转变，并探讨了2D和3D模态下的挑战与趋势。


<details>
  <summary>Details</summary>
Motivation: 传统工业缺陷检测方法难以满足现代制造系统对精度、自动化和可扩展性的需求，而计算机视觉和深度学习的进步为这一领域带来了新的可能性。

Method: 论文通过深入分析封闭集和开放集缺陷检测策略，追踪其近年来的发展，并强调开放集技术的日益重要性。

Result: 研究总结了实际检测环境中的关键挑战，并揭示了新兴趋势，为该领域提供了全面的视角。

Conclusion: 论文为工业缺陷检测领域提供了一个现代且全面的综述，突出了开放集技术的潜力及其未来发展方向。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [12] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 论文探讨了在卫星图像机器学习（SatML）任务中，融合其他地理数据层（如高程模型、传感器数据等）是否能提升模型性能。实验表明，多模态输入显著提高了数据效率和泛化能力，且硬编码融合策略优于学习型方法。


<details>
  <summary>Details</summary>
Motivation: 现有SatML模型主要依赖光学图像输入，而其他地理数据层的潜在价值未被充分探索。研究旨在验证多模态输入对模型性能的提升作用。

Method: 通过扩展SatML基准任务，将额外地理数据层（如高程、温度等）与光学图像结合，构建多模态数据集，用于分类、回归和分割任务。

Result: 实验表明，多模态输入显著提高了模型性能，尤其在数据有限和泛化场景中。硬编码融合策略表现优于学习型方法。

Conclusion: 多模态输入对SatML模型的数据效率和泛化能力有重要价值，硬编码融合策略值得进一步研究。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [13] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 提出了一种基于生成输出分布距离的最小化概念擦除方法，通过端到端优化和神经元掩码技术，在不影响模型性能的情况下有效擦除概念。


<details>
  <summary>Details</summary>
Motivation: 生成模型依赖大规模无标签数据引发安全和版权问题，现有擦除方法过度修改模型影响其效用。

Method: 提出基于生成输出分布距离的擦除目标，通过端到端优化和神经元掩码技术实现。

Result: 在先进流匹配模型上验证，方法能稳健擦除概念且不降低模型性能。

Conclusion: 为更安全、负责任的生成模型提供了新途径。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [14] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 论文提出了一种利用大规模二进制占用数据的方法，通过分解预测过程为二进制和语义占用模块，提升了3D语义占用预测的效果。


<details>
  <summary>Details</summary>
Motivation: 3D语义占用预测需要标注的LiDAR点云，成本高；而二进制占用数据成本低但未被充分利用。

Method: 提出基于二进制占用的框架，分解预测过程为二进制和语义占用模块。

Result: 实验表明，该方法在预训练和自动标注任务中优于现有方法。

Conclusion: 该框架有效提升了3D语义占用预测，且代码已开源。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [15] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 论文提出了一种名为InSyn的Transformer模型，通过显式捕捉多样化的行人交互模式（如同步行走或冲突行为）来提升轨迹预测准确性，并引入SSOS训练策略以减少初始步预测误差。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖相对位置建模行人交互，但忽略了特定交互模式（如配对行走或冲突行为），导致在拥挤场景中预测准确性受限。

Method: 提出InSyn模型，基于Transformer显式捕捉多样化交互模式，并引入SSOS训练策略以减少初始步预测误差。

Result: 在ETH和UCY数据集上，模型显著优于基线方法，尤其是在高密度场景中；SSOS策略将初始步预测误差降低约6.58%。

Conclusion: InSyn模型和SSOS策略有效提升了行人轨迹预测的准确性，特别是在复杂交互场景中。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [16] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: MADI框架通过Masking-Augmented gaussian Diffusion（MAgD）和推理时容量扩展机制，显著提升了扩散模型的可编辑性和可控性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成方面取得了显著成功，但在结构化视觉编辑和组合控制方面仍面临挑战。

Method: 提出MADI框架，包括MAgD（结合去噪和掩码重建的双重训练策略）和基于Pause Tokens的推理时容量扩展机制。

Result: MADI显著提升了扩散模型的可编辑性、组合性和可控性。

Conclusion: MADI为扩散模型在通用上下文生成架构中的集成铺平了道路。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [17] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 该研究提供了一个用于驾驶员 drowsiness 检测的多模态数据集，包含面部、行为、生物特征等信号，总时长 1,400 分钟，记录了驾驶员状态的渐变过程。


<details>
  <summary>Details</summary>
Motivation: 创建更全面的驾驶员 drowsiness 数据集，捕捉生理、行为和驾驶相关信号，弥补现有数据集的不足。

Method: 整合 3D 面部视频、IR 摄像头、后视视频、生物特征信号（心率、皮肤电活动等）和方向盘传感器数据，使用 KSS 量表每 4 分钟自报 drowsiness 水平。

Result: 数据集包含 19 名受试者的 40 分钟连续数据，记录了从清醒到 drowsiness 的渐变状态。

Conclusion: 该数据集为驾驶员 drowsiness 研究提供了更全面的多模态信号支持，未来可公开获取。

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [18] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一种基于扩散的框架，直接从CT/MRI体积生成平滑的主动脉表面，解决了现有方法依赖大量标注数据和手动干预的问题。


<details>
  <summary>Details</summary>
Motivation: 准确的3D主动脉构造对临床诊断、术前规划和CFD模拟至关重要，但现有方法依赖大量标注数据和手动干预，且生成的网格不适合CFD分析。

Method: AortaDiff使用体积引导的条件扩散模型生成主动脉中心线，并自动提取血管轮廓，最终拟合为平滑的3D表面。

Result: 实验表明，AortaDiff即使在训练数据有限的情况下也能有效工作，生成高质量的CFD兼容网格，适用于正常和病理主动脉。

Conclusion: AortaDiff为心血管研究提供了一种端到端的实用解决方案，能够生成高质量的CFD兼容主动脉网格。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [19] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: COREVQA是一个新的视觉语言模型基准测试，专注于视觉蕴涵任务，揭示了现有模型在拥挤场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注视觉问答（VQA），但缺乏对视觉蕴涵能力的评估，尤其是在拥挤场景中。

Method: 提出COREVQA基准，包含5608张图像和合成的真假陈述对，基于CrowdHuman数据集生成。

Result: 顶级视觉语言模型准确率低于80%，其他模型表现更差（39.98%-69.95%），显示模型在拥挤场景中的推理能力不足。

Conclusion: COREVQA揭示了视觉语言模型在视觉蕴涵任务中的关键局限性，尤其是在复杂场景中。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [20] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: IConMark是一种新型的语义水印方法，通过嵌入可解释的概念到AI生成图像中，提高对抗攻击的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和合成媒体的快速发展，区分AI生成图像与真实图像对防止虚假信息和确保数字真实性至关重要。传统水印技术易受对抗攻击影响。

Method: 提出IConMark方法，嵌入有意义语义属性而非噪声或扰动，使其对人类可解释且抗对抗操作。还结合现有水印技术（如StegaStamp和TrustMark）增强鲁棒性。

Result: IConMark及其变体（+TM和+SS）在检测准确性和图像质量上表现优越，AUROC分数分别比最佳基线高10.8%、14.5%和15.9%。

Conclusion: IConMark为可解释水印技术提供了有效解决方案，兼具鲁棒性和可读性，可与其他水印技术结合进一步提升性能。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [21] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: AI系统通过多模型深度学习技术，显著提高了肩部骨折的检测准确率，适用于临床快速筛查。


<details>
  <summary>Details</summary>
Motivation: 肩部骨折在急诊和高流量临床环境中常被漏诊，AI工具可帮助早期检测并减少诊断延误。

Method: 开发了基于10,000张标注肩部X光片的多模型深度学习系统，采用Faster R-CNN、EfficientDet和RF-DETR架构，并结合多种集成技术。

Result: NMW集成方法达到95.5%的准确率和0.9610的F1分数，优于单个模型。

Conclusion: 基于集成的AI系统能可靠检测肩部骨折，适合实时诊断工作流，但仅限于二元骨折检测。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [22] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: Depth3DLane是一种新型双路径框架，通过自监督单目深度估计提供显式结构信息，无需昂贵传感器或额外深度数据，适用于无相机标定的场景。


<details>
  <summary>Details</summary>
Motivation: 解决单目3D车道检测因缺乏显式空间信息而面临的挑战，避免依赖昂贵传感器或大规模真实深度数据，并扩展至无相机标定的场景。

Method: 采用双路径框架：鸟瞰路径提取空间信息，前视路径提取语义信息；结合3D车道锚点采样特征，并预测每帧相机参数以增强稳定性。

Result: 在OpenLane基准数据集上表现优异，且无需真实相机参数即可应用。

Conclusion: Depth3DLane通过自监督深度估计和双路径设计，有效解决了单目3D车道检测的挑战，扩展了应用场景。

Abstract: Monocular 3D lane detection is essential for autonomous driving, but
challenging due to the inherent lack of explicit spatial information.
Multi-modal approaches rely on expensive depth sensors, while methods
incorporating fully-supervised depth networks rely on ground-truth depth data
that is impractical to collect at scale. Additionally, existing methods assume
that camera parameters are available, limiting their applicability in scenarios
like crowdsourced high-definition (HD) lane mapping. To address these
limitations, we propose Depth3DLane, a novel dual-pathway framework that
integrates self-supervised monocular depth estimation to provide explicit
structural information, without the need for expensive sensors or additional
ground-truth depth data. Leveraging a self-supervised depth network to obtain a
point cloud representation of the scene, our bird's-eye view pathway extracts
explicit spatial information, while our front view pathway simultaneously
extracts rich semantic information. Depth3DLane then uses 3D lane anchors to
sample features from both pathways and infer accurate 3D lane geometry.
Furthermore, we extend the framework to predict camera parameters on a
per-frame basis and introduce a theoretically motivated fitting procedure to
enhance stability on a per-segment basis. Extensive experiments demonstrate
that Depth3DLane achieves competitive performance on the OpenLane benchmark
dataset. Furthermore, experimental results show that using learned parameters
instead of ground-truth parameters allows Depth3DLane to be applied in
scenarios where camera calibration is infeasible, unlike previous methods.

</details>


### [23] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 通过结合古老的CORONA卫星影像升级深度学习模型，显著提升了考古遗址自动识别的精度，并发现了四个新遗址。


<details>
  <summary>Details</summary>
Motivation: 利用CORONA影像解决因人为活动导致考古遗址消失的问题，提升AI在考古领域的应用效果。

Method: 基于Bing的卷积网络模型，使用CORONA影像对伊拉克阿布格莱布地区进行重新训练。

Result: 检测精度显著提升（IoU超过85%，总体准确率达90%），并发现四个新遗址。

Conclusion: AI技术与CORONA影像结合是发现已消失考古遗址的有效方法，对考古研究具有重大意义。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [24] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: CaSTFormer是一种因果时空变换器，用于建模驾驶员行为与环境之间的因果关系，提升驾驶意图预测的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 准确预测驾驶意图对提升人机共驾系统的安全性和交互效率至关重要，但现有方法难以建模复杂的时空依赖性和人类驾驶行为的不确定性。

Method: CaSTFormer提出了一种新颖的互易移位融合（RSF）机制、因果模式提取（CPE）模块和特征合成网络（FSN），用于精确建模因果关系和时空依赖性。

Result: 在Brain4Cars数据集上，CaSTFormer实现了最先进的性能，有效捕捉了复杂的因果时空依赖关系。

Conclusion: CaSTFormer显著提升了驾驶意图预测的准确性和透明度，为高级自动驾驶奠定了基础。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [25] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: PhyWorldBench是一个评估视频生成模型物理模拟能力的基准，涵盖从基础物理现象到复杂场景，并引入“反物理”类别。通过人类评估和MLLM方法，对12种模型进行了测试，分析了其在物理一致性上的挑战。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型在物理现象模拟上仍存在不足，需要系统评估其物理一致性。

Method: 设计了PhyWorldBench基准，包括基础物理、复杂场景和反物理类别，结合人类评估和MLLM方法。

Result: 测试了12种模型，发现其在物理一致性上存在显著挑战，并提出了改进建议。

Conclusion: PhyWorldBench为视频生成模型的物理模拟能力提供了系统评估，并指出了未来改进方向。

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [26] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文提出了一种用于摄影测量点云的不确定性量化框架，解决了多视角立体（MVS）阶段的不确定性估计问题。


<details>
  <summary>Details</summary>
Motivation: 摄影测量点云的精度高度依赖场景，而MVS阶段的不确定性估计尚未标准化，本文旨在填补这一空白。

Method: 通过关联误差协方差矩阵，提出一种自校准方法，利用可靠的多视角点回归视差不确定性。

Result: 在多个公开数据集上的实验表明，该方法优于现有方法，实现了高边界率且未高估不确定性。

Conclusion: 该框架为摄影测量过程提供了稳健且可验证的不确定性量化。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [27] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 提出了一种基于3D卷积自编码器的无监督方法，用于从Sentinel-2卫星图像序列中检测甜菜田的压力状态。


<details>
  <summary>Details</summary>
Motivation: 卫星图像时间序列（SITS）数据因其丰富的频谱和时间特性，适合用于农业任务，尤其是甜菜田的压力检测。

Method: 使用3D卷积自编码器提取Sentinel-2图像序列的特征，并结合特定采集日期的时间编码，以更好地捕捉甜菜的生长动态。

Result: 通过下游聚类任务，成功区分了压力田和健康田，且该系统可直接应用于不同年份的数据。

Conclusion: 该方法为甜菜田的压力检测提供了一种实用且易用的工具。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [28] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: SparseC-AFM是一种基于深度学习的模型，能够快速准确地从稀疏的C-AFM扫描数据中重建2D材料的导电性图，显著减少采集时间。


<details>
  <summary>Details</summary>
Motivation: 随着2D材料在纳米电子学中的广泛应用，需要高效的电气表征技术。传统AFM方法速度慢，无法满足大规模生产需求。

Method: 提出SparseC-AFM模型，通过稀疏扫描数据重建高分辨率导电性图，适用于多种扫描模式和实验条件。

Result: 相比传统方法，SparseC-AFM将采集时间减少11倍以上，且预测结果与高分辨率数据电气性能相似。

Conclusion: SparseC-AFM为AI辅助2D材料表征从实验室研究向工业应用迈出了重要一步。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [29] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 提出了一种新的二阶总广义变分（TGV）公式，用于处理三维空间中三角网格的法向量，并将其与现有方法在网格去噪实验中进行了比较。


<details>
  <summary>Details</summary>
Motivation: 扩展离散TGV模型以处理流形值函数（如单位球面上的法向量），并构建适合的有限元空间。

Method: 构建了定制的切向Raviart-Thomas型有限元空间，将TGV公式扩展到流形设置。

Result: 新正则化器在网格去噪实验中表现优于现有方法。

Conclusion: 提出的方法为处理流形值函数提供了有效的正则化工具，并在去噪任务中展示了优越性。

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [30] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: NABLA提出了一种新型的邻域自适应块级注意力机制，用于降低视频扩散变换器中全注意力的计算开销，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 全注意力机制的二次复杂度是视频生成任务中的瓶颈，尤其是在高分辨率和长时视频序列中。

Method: NABLA通过块级注意力和自适应稀疏驱动阈值，动态适应视频扩散变换器中的稀疏模式。

Result: 实验表明，NABLA在训练和推理速度上比基线快2.7倍，且几乎不影响定量指标和视觉质量。

Conclusion: NABLA是一种高效且易于集成的方法，显著提升了视频生成的效率。

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [31] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 提出了一种基于LoRA增强的合成重放框架，通过任务特定的低秩适配器改进Stable Diffusion模型，提升视觉语言模型的持续学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有合成重放方法生成的样本可能因未捕捉领域特定细节而误导微调，导致知识遗忘。

Method: 采用LoRA增强的Stable Diffusion模型，结合两阶段置信度样本选择，优化任务数据生成和蒸馏。

Result: 在MTIL基准测试中表现优于现有合成重放技术，平衡了可塑性、稳定性和零样本能力。

Conclusion: LoRA适配器能有效提升生成器的适应性，支持视觉语言模型的鲁棒持续学习。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [32] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 论文提出了一种名为NoiseSDF2NoiseSDF的方法，用于从噪声点云中学习干净的神经SDF，通过最小化噪声SDF表示之间的MSE损失，显著提高了表面重建质量。


<details>
  <summary>Details</summary>
Motivation: 低质量扫描设备捕获的点云通常包含大量噪声，导致表面重建不准确。受Noise2Noise范式的启发，作者希望将其扩展到3D神经场中。

Method: 提出NoiseSDF2NoiseSDF方法，通过噪声监督直接从噪声点云中学习干净的神经SDF，最小化噪声SDF表示之间的MSE损失。

Result: 在ShapeNet、ABC、Famous和Real数据集上的实验表明，该方法显著提高了从噪声输入中重建表面的质量。

Conclusion: NoiseSDF2NoiseSDF方法有效解决了噪声点云表面重建的问题，为3D神经场的噪声处理提供了新思路。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [33] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的无监督图像去模糊方法，通过从非配对数据中学习空间变化的纹理先验，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 由于获取大量真实的模糊-清晰图像对困难且昂贵，从非配对数据中学习盲图像去模糊更具实用性和前景。现有方法依赖对抗学习，忽略了真实模糊模式的复杂性。

Method: 提出基于扩散模型的框架，包括纹理先验编码器（TPE）和纹理转移变换层（TTformer），利用自适应滤波去除空间变化的模糊。

Result: 在广泛使用的基准测试中表现优于现有技术，提供了有前景的无监督去模糊解决方案。

Conclusion: 该方法通过生成纹理先验和自适应滤波，有效解决了无监督图像去模糊问题，性能优于现有方法。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [34] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的随机采样方法，用于从低分辨率（LR）图像序列中生成高保真超分辨率（SR）图像，显著减少了运行时间并保持了图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有确定性方法生成的SR图像模糊且感知质量差，本文旨在通过扩散模型生成清晰且高保真的SR图像。

Method: 采用随机采样器结合高阶ODE和一步扩散知识蒸馏，提高了扩散模型的效率。

Result: 实验结果表明，该方法将运行时间减少至基线的1.6%，同时保持了基于图像失真和感知质量的SR质量。

Conclusion: 该方法在效率和图像质量之间取得了良好平衡，为SR任务提供了一种有效的解决方案。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [35] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: 论文提出CoTasks框架，通过分解复杂视频问题为四个基础任务，提升视频大语言模型的链式推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型缺乏细粒度对象级理解和链式推理能力，需要结构化标注支持逐步推理。

Method: CoTasks将复杂视频问题分解为帧定位、实体跟踪、时空关系提取等四个基础任务，嵌入中间推理步骤。

Result: 在NeXT-QA基准测试中，LLaVA-video-7B和Qwen2.5-VL-3B模型性能显著提升，尤其在因果、时序和描述性子类别。

Conclusion: CoTasks作为结构化监督框架，有效提升了视频推理的组成能力。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [36] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: 提出了一种结合光流和纹理信息的方法FoELS，用于从移动相机视角分离静态和动态物体，解决了复杂场景中的挑战。


<details>
  <summary>Details</summary>
Motivation: 从移动相机视角分离静态和动态物体对3D重建、自主导航和场景理解至关重要，现有方法主要依赖光流，但在复杂场景中效果不佳。

Method: FoELS通过计算光流的扩展焦点（FoE）并利用其异常值生成初始运动似然，再结合分割先验估计最终运动概率。

Result: 在DAVIS 2016数据集和真实交通视频上的评估表明，该方法在复杂场景中表现优异，达到先进水平。

Conclusion: FoELS通过结合光流和纹理信息，有效解决了复杂场景中动态物体检测的难题。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [37] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon提出了一种高效的混合表示方法，通过空射线省略（ERO）和空区间省略（EIO）策略，显著减少了计算成本，同时保持了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF和SMPL的混合表示方法因变形计算成本高而推理速度慢，EPSilon旨在通过优化采样策略解决这一问题。

Method: EPSilon采用ERO和EIO两种策略，分别省略空射线和空区间，减少无效采样点，从而降低计算成本。

Result: EPSilon仅使用3.9%的采样点，推理速度提升约20倍，训练收敛速度提升4倍，同时保持生成质量。

Conclusion: EPSilon通过高效采样策略，显著提升了混合表示方法的性能，为3D虚拟人生成提供了更高效的解决方案。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [38] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 论文提出了一种新的大规模RGB-事件数据集EvReID，并提出了TriPro-ReID框架，通过行人属性引导的对比学习提升特征学习。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件相机ReID方法在小规模或模拟数据集上训练和评估的问题，提供更真实的数据和评估基准。

Method: 构建EvReID数据集，并提出TriPro-ReID框架，结合RGB和事件流数据，利用行人属性进行对比学习。

Result: 在EvReID和MARS数据集上的实验验证了框架的有效性。

Conclusion: EvReID数据集和TriPro-ReID框架为事件相机ReID研究提供了新的数据和基准。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [39] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: PW-FNet是一种高效图像恢复方法，结合小波和傅里叶变换，减少计算复杂度并提升恢复质量。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气条件会降低图像质量，影响下游任务性能。现有基于Transformer的方法复杂度高，难以实时处理。

Method: 提出PW-FNet，采用金字塔小波多输入多输出结构和傅里叶变换替代自注意力机制。

Result: 在多种图像恢复任务中表现优于现有方法，计算效率和恢复质量均显著提升。

Conclusion: PW-FNet通过小波和傅里叶变换的结合，实现了高效且高质量的图像恢复。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [40] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: 提出MaskHOI，一种基于MAE的预训练框架，通过区域特定掩码比率分配和SDF驱动的多模态学习，提升3D手-物交互任务的姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 解决RGB图像几何模糊性和交互中严重遮挡问题，提升手和物体姿态估计的精度。

Method: 采用MAE的掩码-重建策略，引入区域特定掩码比率分配和SDF驱动的多模态学习机制。

Result: 在实验中显著优于现有方法。

Conclusion: MaskHOI通过几何感知和遮挡鲁棒性学习，有效提升了3D手-物交互任务的姿态估计性能。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [41] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一个统一框架，用于解决V2X协同感知中异构传感器配置带来的挑战，通过分层融合机制和自适应空间分辨率调整，显著提升了感知性能。


<details>
  <summary>Details</summary>
Motivation: 现实中的V2X协同感知系统常因成本限制和部署差异导致传感器配置异构，这给特征融合和感知可靠性带来挑战。

Method: 提出HeCoFuse框架，采用分层融合机制（通道和空间注意力）和自适应空间分辨率调整模块，并结合动态调整融合类型的协同学习策略。

Result: 在TUMTraf-V2X数据集上，HeCoFuse在多种传感器配置下表现优异，3D mAP最高达43.38%，优于基线方法。

Conclusion: HeCoFuse在异构传感器配置下表现出色，成为当前TUM-Traf V2X数据集上的最先进方法。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [42] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于高斯核的运动测量方法，用于高精度结构健康监测，解决了现有视觉方法在亚像素级测量中精度不足或需手动调参的问题。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测需求增长，但现有视觉方法在亚像素级运动测量中精度不足或需复杂调参。

Method: 开发了一种基于高斯核的运动测量方法，结合运动一致性和超分辨率约束以提高精度和鲁棒性。

Result: 数值和实验验证表明，该方法无需定制参数即可实现高精度。

Conclusion: 该方法为结构健康监测提供了一种高效、高精度的运动测量解决方案。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [43] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 本文提出了两种用于多目标跟踪（MOT）算法性能评估的准度量，分别扩展了GOSPA和T-GOSPA度量，具有不对称惩罚和灵活成本设置的特性。


<details>
  <summary>Details</summary>
Motivation: 现有的GOSPA和T-GOSPA度量在多目标跟踪评估中缺乏灵活性，无法根据应用需求调整惩罚成本。

Method: 扩展GOSPA和T-GOSPA度量，引入不对称的定位误差惩罚和灵活的虚假/漏检目标成本。T-GOSPA准度量还增加了轨迹切换成本。

Result: 通过仿真实验，使用T-GOSPA准度量评估了多种贝叶斯MOT算法的性能。

Conclusion: 提出的准度量在MOT评估中更具灵活性，适用于特定应用场景。

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [44] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 提出了一种无需训练的方法PoemTale Diffusion，通过多阶段提示优化和自注意力机制改进，提升诗歌文本到图像的生成效果，并发布了P4I数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在处理复杂、抽象的诗歌语言时表现不佳，导致信息丢失。

Method: 结合多阶段提示优化和自注意力机制改进，生成多张一致性图像以传达诗歌含义。

Result: 通过人类和定量评估验证了方法的有效性，生成图像能更好地捕捉诗歌信息。

Conclusion: PoemTale Diffusion为诗歌到图像生成提供了新视角，并推动了相关研究。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [45] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 提出了一种针对博物馆环境的增强现实流程，通过结合两种预训练深度估计模型（GLPN和Depth-Anything），从单张图像生成精确的3D模型，提升AR体验的沉浸感。


<details>
  <summary>Details</summary>
Motivation: 博物馆希望通过交互式数字内容增强游客参与度，但艺术品的复杂特征（如不规则轮廓和可变纹理）对3D重建提出了挑战。

Method: 整合GLPN（全局场景结构）和Depth-Anything（局部细节重建）两种模型，生成优化的深度图，并将其转换为高质量点云和网格。

Result: 实验结果显示，重建精度和视觉真实感显著提升，系统成为博物馆增强游客参与度的强大工具。

Conclusion: 该方法通过先进神经网络和计算机视觉技术，成功解决了艺术品3D重建的难题，为博物馆提供了高效的AR解决方案。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


### [46] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: 本文分析了StyleGAN生成器的内部机制，探讨了其关键架构和技术，揭示了权重修剪的潜力，并研究了潜在向量的作用，同时指出了技术滥用的伦理问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成图像技术的普及，理解StyleGAN等模型的内部运作机制及其潜在风险变得尤为重要。

Method: 通过PyTorch训练StyleGAN模型，详细分析其架构（如Equalized Learning Rate），并进行权重修剪和潜在向量研究。

Result: 研究发现大量权重可被修剪而不显著影响输出，同时潜在向量对生成图像的外观有重要影响。

Conclusion: StyleGAN的精确控制能力具有学术价值，但也可能被恶意利用，引发严重的伦理和安全问题。

Abstract: In today's digital age, concerns about the dangers of AI-generated images are
increasingly common. One powerful tool in this domain is StyleGAN (style-based
generative adversarial networks), a generative adversarial network capable of
producing highly realistic synthetic faces. To gain a deeper understanding of
how such a model operates, this work focuses on analyzing the inner workings of
StyleGAN's generator component. Key architectural elements and techniques, such
as the Equalized Learning Rate, are explored in detail to shed light on the
model's behavior. A StyleGAN model is trained using the PyTorch framework,
enabling direct inspection of its learned weights. Through pruning, it is
revealed that a significant number of these weights can be removed without
drastically affecting the output, leading to reduced computational
requirements. Moreover, the role of the latent vector -- which heavily
influences the appearance of the generated faces -- is closely examined. Global
alterations to this vector primarily affect aspects like color tones, while
targeted changes to individual dimensions allow for precise manipulation of
specific facial features. This ability to finetune visual traits is not only of
academic interest but also highlights a serious ethical concern: the potential
misuse of such technology. Malicious actors could exploit this capability to
fabricate convincing fake identities, posing significant risks in the context
of digital deception and cybercrime.

</details>


### [47] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: Diffusion-FSCIL利用冻结的扩散模型作为骨干网络，通过多尺度特征提取和潜在重放解决小样本类增量学习的挑战，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 小样本类增量学习（FSCIL）面临训练数据极少且需平衡遗忘与新知识学习的挑战。

Method: 采用文本到图像的扩散模型作为冻结骨干，提取多尺度互补特征作为潜在重放，辅以特征蒸馏减少生成偏差。

Result: 在CUB-200、miniImageNet和CIFAR-100上表现优于现有方法，有效保留旧类性能并适应新类。

Conclusion: Diffusion-FSCIL通过冻结骨干和高效特征提取，成功解决了FSCIL的核心问题。

Abstract: Few-shot class-incremental learning (FSCIL) is challenging due to extremely
limited training data; while aiming to reduce catastrophic forgetting and learn
new information. We propose Diffusion-FSCIL, a novel approach that employs a
text-to-image diffusion model as a frozen backbone. Our conjecture is that
FSCIL can be tackled using a large generative model's capabilities benefiting
from 1) generation ability via large-scale pre-training; 2) multi-scale
representation; 3) representational flexibility through the text encoder. To
maximize the representation capability, we propose to extract multiple
complementary diffusion features to play roles as latent replay with slight
support from feature distillation for preventing generative biases. Our
framework realizes efficiency through 1) using a frozen backbone; 2) minimal
trainable components; 3) batch processing of multiple feature extractions.
Extensive experiments on CUB-200, \emph{mini}ImageNet, and CIFAR-100 show that
Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on
previously learned classes and adapting effectively to new ones.

</details>


### [48] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: EVS是一种无需训练的封装视频合成器，结合T2I和T2V模型，提升生成视频的视觉质量和运动平滑性。


<details>
  <summary>Details</summary>
Motivation: 现有T2V模型在生成高质量视频时存在画面闪烁和伪影问题，需改进视觉保真度和运动一致性。

Method: 利用预训练扩散T2I模型优化低质量视频帧，结合T2V模型确保运动一致性。

Result: 实验证明EVS在视频质量和运动平滑性上优于现有方法，推理速度提升1.6-4.5倍。

Conclusion: EVS通过结合T2I和T2V模型的优势，显著提升了生成视频的质量和效率。

Abstract: In recent years, large text-to-video (T2V) synthesis models have garnered
considerable attention for their abilities to generate videos from textual
descriptions. However, achieving both high imaging quality and effective motion
representation remains a significant challenge for these T2V models. Existing
approaches often adapt pre-trained text-to-image (T2I) models to refine video
frames, leading to issues such as flickering and artifacts due to
inconsistencies across frames. In this paper, we introduce EVS, a training-free
Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both
visual fidelity and motion smoothness of generated videos. Our approach
utilizes a well-trained diffusion-based T2I model to refine low-quality video
frames by treating them as out-of-distribution samples, effectively optimizing
them with noising and denoising steps. Meanwhile, we employ T2V backbones to
ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior
into the T2I generation process, EVS successfully leverages the strengths of
both types of models, resulting in videos of improved imaging and motion
quality. Experimental results validate the effectiveness of our approach
compared to previous approaches. Our composition process also leads to a
significant improvement of 1.6x-4.5x speedup in inference time. Source codes:
https://github.com/Tonniia/EVS.

</details>


### [49] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的光谱扩散先验（SDP）和光谱先验注入模块（SPIM），用于提升高光谱图像（HSI）重建的高频细节恢复能力，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在高光谱图像重建中难以准确捕捉高频细节，因此需要一种更有效的方法来提升重建质量。

Method: 通过扩散模型隐式学习光谱扩散先验（SDP），并设计光谱先验注入模块（SPIM）动态指导模型恢复细节。

Result: 在MST和BISRNet两种代表性HSI方法上，性能提升约0.5 dB。

Conclusion: SDP和SPIM的结合显著提升了HSI重建的性能，尤其在细节恢复方面表现突出。

Abstract: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.

</details>


### [50] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 论文提出了一种基于排列熵（PE）的图像分类方法，结合HOG和LBP特征，训练SVM分类器，在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在图像分类中，特征工程在可解释性和计算效率方面仍具优势，尤其是在不依赖深度学习的场景下。

Method: 将PE扩展到二维图像，提出多尺度、多方向的熵特征提取方法，并结合HOG和LBP特征，形成780维特征集，用于训练SVM分类器。

Result: 在Fashion-MNIST等数据集上表现优异，证明了PE与HOG、LBP结合的有效性。

Conclusion: 该方法为图像分类提供了一种轻量、可解释的替代方案，展示了熵特征在计算机视觉中的潜力。

Abstract: Feature engineering continues to play a critical role in image
classification, particularly when interpretability and computational efficiency
are prioritized over deep learning models with millions of parameters. In this
study, we revisit classical machine learning based image classification through
a novel approach centered on Permutation Entropy (PE), a robust and
computationally lightweight measure traditionally used in time series analysis
but rarely applied to image data. We extend PE to two-dimensional images and
propose a multiscale, multi-orientation entropy-based feature extraction
approach that characterizes spatial order and complexity along rows, columns,
diagonals, anti-diagonals, and local patches of the image. To enhance the
discriminatory power of the entropy features, we integrate two classic image
descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and
edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an
image. The resulting hand-crafted feature set, comprising of 780 dimensions, is
used to train Support Vector Machine (SVM) classifiers optimized through grid
search. The proposed approach is evaluated on multiple benchmark datasets,
including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers
competitive classification performance without relying on deep architectures.
Our results demonstrate that the fusion of PE with HOG and LBP provides a
compact, interpretable, and effective alternative to computationally expensive
and limited interpretable deep learning models. This shows a potential of
entropy-based descriptors in image classification and contributes a lightweight
and generalizable solution to interpretable machine learning in image
classification and computer vision.

</details>


### [51] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 论文提出了ClearVQA基准，用于评估视觉语言模型通过交互解决模糊问题的能力，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过重述问题解决VQA中的模糊性，忽视了用户反馈的交互性。缺乏评估模型交互能力的基准，且模型倾向于回答而非提问。

Method: 引入ClearVQA基准，针对VQA中三类常见模糊性，涵盖多种VQA场景。

Result: ClearVQA基准为评估模型通过交互解决模糊问题的能力提供了工具。

Conclusion: ClearVQA填补了交互式模糊解决研究的空白，为未来研究提供了方向。

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [52] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 论文提出了一种显式引入可微分聚类模块的方法，用于半监督学习和无监督域适应，通过利用监督数据计算聚类中心，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 在半监督学习和无监督域适应中，聚类假设已被证明对有限监督下的学习有益。现有工作多通过隐式方式利用这一假设，本文则尝试显式地引入可微分聚类模块。

Method: 提出了一种端到端的训练策略，显式引入可微分聚类模块，并利用监督数据计算聚类中心。

Result: 实验表明该方法在半监督学习和无监督域适应中有效，尤其在低监督条件下表现突出。

Conclusion: 显式引入可微分聚类模块是一种简单有效的策略，可作为独立模型或现有方法的正则化手段。

Abstract: Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)
enhance the model performance by exploiting information from labeled and
unlabeled data. The clustering assumption has proven advantageous for learning
with limited supervision and states that data points belonging to the same
cluster in a high-dimensional space should be assigned to the same category.
Recent works have utilized different training mechanisms to implicitly enforce
this assumption for the SSL and UDA. In this work, we take a different approach
by explicitly involving a differentiable clustering module which is extended to
leverage the supervised data to compute its centroids. We demonstrate the
effectiveness of our straightforward end-to-end training strategy for SSL and
UDA over extensive experiments and highlight its benefits, especially in low
supervision regimes, both as a standalone model and as a regularizer for
existing approaches.

</details>


### [53] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: 提出了一种名为LoFNO的新型3D架构，通过结合几何先验和神经算子框架，提升了血流数据的时空分辨率，并直接预测壁剪切应力（WSS）。


<details>
  <summary>Details</summary>
Motivation: 磁共振血流成像的低时空分辨率和信噪比限制了其诊断效果，需要一种方法提升分辨率和预测能力。

Method: LoFNO利用拉普拉斯特征向量作为几何先验，结合增强的深度超分辨率网络（EDSR）层，对血流数据进行去噪和时空上采样。

Result: LoFNO在速度和WSS预测上优于插值和其他深度学习方法，提升了脑血管诊断的精确性。

Conclusion: LoFNO通过整合几何先验和神经算子，显著提升了血流数据的时空分辨率和诊断能力。

Abstract: Hemodynamic analysis is essential for predicting aneurysm rupture and guiding
treatment. While magnetic resonance flow imaging enables time-resolved
volumetric blood velocity measurements, its low spatiotemporal resolution and
signal-to-noise ratio limit its diagnostic utility. To address this, we propose
the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that
enhances both spatial and temporal resolution with the ability to predict wall
shear stress (WSS) directly from clinical imaging data. LoFNO integrates
Laplacian eigenvectors as geometric priors for improved structural awareness on
irregular, unseen geometries and employs an Enhanced Deep Super-Resolution
Network (EDSR) layer for robust upsampling. By combining geometric priors with
neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow
data, achieving superior velocity and WSS predictions compared to interpolation
and alternative deep learning methods, enabling more precise cerebrovascular
diagnostics.

</details>


### [54] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: DynFaceRestore 是一种新颖的盲脸恢复方法，通过动态选择扩散起始时间步和局部调整引导强度，平衡了保真度和质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法因固定扩散采样时间步和全局引导尺度，常导致保真度与质量失衡。

Method: 利用高斯模糊图像及其核，动态选择扩散起始时间步，并引入动态引导缩放调整器。

Result: DynFaceRestore 在定量和定性评估中均达到最优性能。

Conclusion: 该方法在盲脸恢复中表现出鲁棒性和高效性。

Abstract: Blind Face Restoration aims to recover high-fidelity, detail-rich facial
images from unknown degraded inputs, presenting significant challenges in
preserving both identity and detail. Pre-trained diffusion models have been
increasingly used as image priors to generate fine details. Still, existing
methods often use fixed diffusion sampling timesteps and a global guidance
scale, assuming uniform degradation. This limitation and potentially imperfect
degradation kernel estimation frequently lead to under- or over-diffusion,
resulting in an imbalance between fidelity and quality. We propose
DynFaceRestore, a novel blind face restoration approach that learns to map any
blindly degraded input to Gaussian blurry images. By leveraging these blurry
images and their respective Gaussian kernels, we dynamically select the
starting timesteps for each blurry image and apply closed-form guidance during
the diffusion sampling process to maintain fidelity. Additionally, we introduce
a dynamic guidance scaling adjuster that modulates the guidance strength across
local regions, enhancing detail generation in complex areas while preserving
structural fidelity in contours. This strategy effectively balances the
trade-off between fidelity and quality. DynFaceRestore achieves
state-of-the-art performance in both quantitative and qualitative evaluations,
demonstrating robustness and effectiveness in blind face restoration.

</details>


### [55] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: 提出了一种名为CF-SSC的新型时间3D语义场景补全框架，通过伪未来帧预测扩展感知范围，提升遮挡推理和场景补全精度。


<details>
  <summary>Details</summary>
Motivation: 现有单目SSC方法在真实交通场景中难以处理遮挡和视野外区域，限制了3D场景布局和语义推断能力。

Method: 结合姿态和深度建立准确的3D对应关系，在3D空间中融合过去、当前和预测的未来帧，显式建模时空关系。

Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试中达到最先进性能，显著提升遮挡推理和场景补全精度。

Conclusion: CF-SSC通过时空建模和未来帧预测有效解决了单目SSC的局限性，为自动驾驶感知任务提供了更强大的工具。

Abstract: In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a
critical perception task for autonomous driving due to its ability to infer
complete 3D scene layouts and semantics from single 2D images. However, in
real-world traffic scenarios, a significant portion of the scene remains
occluded or outside the camera's field of view -- a fundamental challenge that
existing monocular SSC methods fail to address adequately. To overcome these
limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC
framework that leverages pseudo-future frame prediction to expand the model's
effective perceptual range. Our approach combines poses and depths to establish
accurate 3D correspondences, enabling geometrically-consistent fusion of past,
present, and predicted future frames in 3D space. Unlike conventional methods
that rely on simple feature stacking, our 3D-aware architecture achieves more
robust scene completion by explicitly modeling spatial-temporal relationships.
Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks
demonstrate state-of-the-art performance, validating the effectiveness of our
approach, highlighting our method's ability to improve occlusion reasoning and
3D scene completion accuracy.

</details>


### [56] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: GRAM-MAMBA框架通过线性复杂度的Mamba模型和优化的GRAM矩阵策略，解决了多模态融合中的效率、对齐和鲁棒性问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有物联网多模态感知系统存在模型复杂度高、模态对齐不充分和鲁棒性差的问题，限制了其在资源受限环境中的应用。

Method: 结合线性复杂度的Mamba模型处理传感器时间序列，使用优化的GRAM矩阵策略进行模态间对齐，并引入低秩自适应层补偿缺失模态。

Result: 在SPAWC2021和USC-HAD数据集上，GRAM-MAMBA分别提升了24.5%和23%的性能，同时仅训练少量参数。

Conclusion: GRAM-MAMBA为资源受限环境中的高效鲁棒多模态感知提供了有效解决方案。

Abstract: Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely
deployed in smart homes, intelligent transport, industrial automation, and
healthcare. However, existing systems often face challenges: high model
complexity hinders deployment in resource-constrained environments,
unidirectional modal alignment neglects inter-modal relationships, and
robustness suffers when sensor data is missing. These issues impede efficient
and robust multimodal perception in real-world IoT settings. To overcome these
limitations, we propose GRAM-MAMBA. This framework utilizes the
linear-complexity Mamba model for efficient sensor time-series processing,
combined with an optimized GRAM matrix strategy for pairwise alignment among
modalities, addressing the shortcomings of traditional single-modality
alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive
low-rank layer compensation strategy to handle missing modalities
post-training. This strategy freezes the pre-trained model core and irrelevant
adaptive layers, fine-tuning only those related to available modalities and the
fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On
the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower
error than baselines; adapting to missing modalities yields a 24.5% performance
boost by training less than 0.2% of parameters. On the USC-HAD human activity
recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),
outperforming prior work; the update strategy increases F1 by 23% while
training less than 0.3% of parameters. These results highlight GRAM-MAMBA's
potential for achieving efficient and robust multimodal perception in
resource-constrained environments.

</details>


### [57] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2是一个统一的多模态遥感基础模型，通过单一Transformer主干处理多模态数据，采用自适应SSL策略和MoE模块提升性能，在7个任务上平均优于前代1.8分。


<details>
  <summary>Details</summary>
Motivation: 现有方法需为每种模态训练独立主干网络，导致冗余且效率低；且传统SSL方法未充分考虑遥感图像特性。

Method: 使用单一Transformer主干，结合自适应SSL策略、可学习模态提示令牌和MoE模块。

Result: 在16个数据集上的7个任务中，平均性能提升1.8分。

Conclusion: SkySense V2通过统一架构和针对性优化，显著提升了多模态遥感任务的性能。

Abstract: The multi-modal remote sensing foundation model (MM-RSFM) has significantly
advanced various Earth observation tasks, such as urban planning, environmental
monitoring, and natural disaster management. However, most existing approaches
generally require the training of separate backbone networks for each data
modality, leading to redundancy and inefficient parameter utilization.
Moreover, prevalent pre-training methods typically apply self-supervised
learning (SSL) techniques from natural images without adequately accommodating
the characteristics of remote sensing (RS) images, such as the complicated
semantic distribution within a single RS image. In this work, we present
SkySense V2, a unified MM-RSFM that employs a single transformer backbone to
handle multiple modalities. This backbone is pre-trained with a novel SSL
strategy tailored to the distinct traits of RS data. In particular, SkySense V2
incorporates an innovative adaptive patch merging module and learnable modality
prompt tokens to address challenges related to varying resolutions and limited
feature diversity across modalities. In additional, we incorporate the mixture
of experts (MoE) module to further enhance the performance of the foundation
model. SkySense V2 demonstrates impressive generalization abilities through an
extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense
by an average of 1.8 points.

</details>


### [58] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的开放视频问答框架，通过多模型协作提升推理深度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频-语言大模型在复杂场景中表现不足，如上下文理解有限、时序建模弱、泛化能力差。

Method: 采用提示-响应集成机制，协调多个异构视频-语言模型，结合外部大语言模型作为评估和集成器。

Result: 在CVRR-ES数据集上显著优于基线，表现出更强的泛化和鲁棒性。

Conclusion: 提供了一种轻量级、可扩展的多模态推理策略，无需重新训练模型，为未来视频-语言大模型发展奠定基础。

Abstract: We propose a novel framework for open-ended video question answering that
enhances reasoning depth and robustness in complex real-world scenarios, as
benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models
(Video-LMMs) often exhibit limited contextual understanding, weak temporal
modeling, and poor generalization to ambiguous or compositional queries. To
address these challenges, we introduce a prompting-and-response integration
mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)
via structured chains of thought, each tailored to distinct reasoning pathways.
An external Large Language Model (LLM) serves as an evaluator and integrator,
selecting and fusing the most reliable responses. Extensive experiments
demonstrate that our method significantly outperforms existing baselines across
all evaluation metrics, showcasing superior generalization and robustness. Our
approach offers a lightweight, extensible strategy for advancing multimodal
reasoning without requiring model retraining, setting a strong foundation for
future Video-LMM development.

</details>


### [59] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 该论文研究了使用量子卷积预处理增强Attention U-Net模型在建筑物分割中的能力，特别是在突尼斯的城市环境中。


<details>
  <summary>Details</summary>
Motivation: 密集城市区域的建筑物分割对城市规划、灾害响应和人口测绘至关重要，但由于卫星图像的高分辨率和尺寸，准确分割具有挑战性。

Method: 采用量子卷积（Quanvolution）预处理，结合Attention U-Net模型，利用Sentinel-1 SAR影像进行建筑物分割。

Result: 初步结果显示，该方法在保持与标准Attention U-Net模型相当的测试精度的同时，显著减少了网络参数。

Conclusion: 量子辅助的深度学习框架在大规模城市建筑物分割中具有潜力，既能保持精度又能提高计算效率。

Abstract: Building segmentation in urban areas is essential in fields such as urban
planning, disaster response, and population mapping. Yet accurately segmenting
buildings in dense urban regions presents challenges due to the large size and
high resolution of satellite images. This study investigates the use of a
Quanvolutional pre-processing to enhance the capability of the Attention U-Net
model in the building segmentation. Specifically, this paper focuses on the
urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)
imagery. In this work, Quanvolution was used to extract more informative
feature maps that capture essential structural details in radar imagery,
proving beneficial for accurate building segmentation. Preliminary results
indicate that proposed methodology achieves comparable test accuracy to the
standard Attention U-Net model while significantly reducing network parameters.
This result aligns with findings from previous works, confirming that
Quanvolution not only maintains model accuracy but also increases computational
efficiency. These promising outcomes highlight the potential of
quantum-assisted Deep Learning frameworks for large-scale building segmentation
in urban environments.

</details>


### [60] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: PositionIC框架通过双向生成范式实现多主体图像定制中的精确空间控制，解决了现有方法在细粒度实体级空间控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图像定制方法在实体级空间控制上表现不足，限制了实际应用。缺乏绑定身份与精确位置的可扩展数据集是主要原因。

Method: 提出PositionIC框架，包括可扩展的合成流水线和轻量级位置调制层，通过双向生成范式消除主体漂移并保持语义一致性。

Result: 实验表明，PositionIC能实现精确的空间控制，同时保持图像定制任务中的高一致性。

Conclusion: PositionIC为开放世界多实体场景中的可控高保真图像定制提供了新方向，并将公开发布以促进进一步研究。

Abstract: Recent subject-driven image customization has achieved significant
advancements in fidelity, yet fine-grained entity-level spatial control remains
elusive, hindering the broader real-world application. This limitation is
mainly attributed to scalable datasets that bind identity with precise
positional cues are absent. To this end, we introduce PositionIC, a unified
framework that enforces position and identity consistency for multi-subject
customization. We construct a scalable synthesis pipeline that employs a
bidirectional generation paradigm to eliminate subject drift and maintain
semantic coherence. On top of these data, we design a lightweight positional
modulation layer that decouples spatial embeddings among subjects, enabling
independent, accurate placement while preserving visual fidelity. Extensive
experiments demonstrate that our approach can achieve precise spatial control
while maintaining high consistency in image customization task. PositionIC
paves the way for controllable, high-fidelity image customization in
open-world, multi-entity scenarios and will be released to foster further
research.

</details>


### [61] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 研究分析了视觉语言模型（VLMs）如何处理内部知识与外部信息之间的冲突，通过引入多模态反事实查询数据集，定位了控制冲突的关键注意力头，并展示了其优于梯度归因方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决VLMs在内部参数知识与外部信息冲突时产生的幻觉和不可靠响应问题，探索其冲突解决机制。

Method: 引入多模态反事实查询数据集，通过logit检查定位控制冲突的关键注意力头，并修改这些头以引导模型偏向内部知识或视觉输入。

Result: 定位到少量控制冲突的注意力头，修改这些头可有效引导模型；这些头的注意力能精准定位驱动视觉覆盖的图像区域，优于梯度归因方法。

Conclusion: 研究揭示了VLMs处理知识冲突的机制，为改进模型可靠性和可解释性提供了新方法。

Abstract: Vision-language models (VLMs) increasingly leverage diverse knowledge sources
to address complex tasks, often encountering conflicts between their internal
parametric knowledge and external information. Knowledge conflicts can result
in hallucinations and unreliable responses, but the mechanisms governing such
interactions remain unknown. To address this gap, we analyze the mechanisms
that VLMs use to resolve cross-modal conflicts by introducing a dataset of
multimodal counterfactual queries that deliberately contradict internal
commonsense knowledge. We localize with logit inspection a small set of heads
that control the conflict. Moreover, by modifying these heads, we can steer the
model towards its internal knowledge or the visual inputs. Finally, we show
that attention from such heads pinpoints localized image regions driving visual
overrides, outperforming gradient-based attribution in precision.

</details>


### [62] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: 提出了一种通过融合实时视觉数据和海图信息来增强海洋视觉的新方法，利用基于transformer的端到端神经网络匹配浮标等导航辅助设备。


<details>
  <summary>Details</summary>
Motivation: 解决动态和挑战性海洋环境中目标定位和关联的准确性不足问题。

Method: 使用基于transformer的端到端神经网络预测浮标的边界框和置信度分数，直接匹配图像检测与海图标记。

Result: 实验表明，该方法在真实海洋场景中显著提升了目标定位和关联的准确性。

Conclusion: 该方法优于基线方法，适用于动态和复杂环境中的海洋视觉增强。

Abstract: This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.

</details>


### [63] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: PCR-GS是一种无需COLMAP的3D高斯泼溅技术，通过相机姿态共正则化提升复杂场景下的3D建模和相机姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有3D-GS技术在复杂相机轨迹场景下表现不佳，导致相机姿态估计和联合优化问题。

Method: 提出两种正则化方法：特征重投影正则化和基于小波的高频正则化，分别利用语义对齐和高频细节优化相机姿态。

Result: 实验表明PCR-GS在剧烈变化的相机轨迹下实现了优越的无姿态3D-GS场景建模。

Conclusion: PCR-GS通过共正则化显著提升了复杂场景下的3D建模和相机姿态估计性能。

Abstract: COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing
attention due to its remarkable performance in reconstructing high-quality 3D
scenes from unposed images or videos. However, it often struggles to handle
scenes with complex camera trajectories as featured by drastic rotation and
translation across adjacent camera views, leading to degraded estimation of
camera poses and further local minima in joint optimization of camera poses and
3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that
achieves superior 3D scene modeling and camera pose estimation via camera pose
co-regularization. PCR-GS achieves regularization from two perspectives. The
first is feature reprojection regularization which extracts view-robust DINO
features from adjacent camera views and aligns their semantic information for
camera pose regularization. The second is wavelet-based frequency
regularization which exploits discrepancy in high-frequency details to further
optimize the rotation matrix in camera poses. Extensive experiments over
multiple real-world scenes show that the proposed PCR-GS achieves superior
pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.

</details>


### [64] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 论文提出了一种利用DepthAnything生成的深度先验增强LiDAR点云特征的方法，通过双路径RoI特征提取和双向门控融合模块，显著提升了3D目标检测精度。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云特征表达能力有限，尤其是反射率属性的区分能力较弱，而DepthAnything提供的密集几何先验可以弥补这一不足。

Method: 将DepthAnything预测的深度先验与LiDAR原始属性融合，设计点级特征提取模块和双路径RoI特征提取框架（体素分支和点分支），并引入双向门控RoI特征融合模块。

Result: 在KITTI基准测试中，检测精度显著提升。

Conclusion: 视觉基础模型先验能有效增强LiDAR点云特征，提升3D目标检测性能。

Abstract: Recent advances in foundation models have opened up new possibilities for
enhancing 3D perception. In particular, DepthAnything offers dense and reliable
geometric priors from monocular RGB images, which can complement sparse LiDAR
data in autonomous driving scenarios. However, such priors remain underutilized
in LiDAR-based 3D object detection. In this paper, we address the limited
expressiveness of raw LiDAR point features, especially the weak discriminative
capability of the reflectance attribute, by introducing depth priors predicted
by DepthAnything. These priors are fused with the original LiDAR attributes to
enrich each point's representation. To leverage the enhanced point features, we
propose a point-wise feature extraction module. Then, a Dual-Path RoI feature
extraction framework is employed, comprising a voxel-based branch for global
semantic context and a point-based branch for fine-grained structural details.
To effectively integrate the complementary RoI features, we introduce a
bidirectional gated RoI feature fusion module that balances global and local
cues. Extensive experiments on the KITTI benchmark show that our method
consistently improves detection accuracy, demonstrating the value of
incorporating visual foundation model priors into LiDAR-based 3D object
detection.

</details>


### [65] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF是一种通用的神经渲染方法，能够在任意视角和时间渲染新视图，即使输入视图较少。它结合了多视图立体、神经辐射场和解缠策略，支持少样本泛化，并能构建任意时间的神经辐射场。实验表明，TimeNeRF无需逐场景优化即可渲染新视图，并能自然捕捉昼夜过渡的复杂场景变化。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，多视图采集成本高且对未见场景重新优化效率低。元宇宙等数字领域需要能够自然过渡昼夜的3D环境建模能力。现有NeRF技术虽能合成新视图，但对时间维度的3D场景建模探索有限。

Method: 结合多视图立体、神经辐射场和解缠策略，构建隐式内容辐射场表示场景，并支持任意时间的神经辐射场构建。通过体积渲染合成新视图。

Result: TimeNeRF在少样本设置下无需逐场景优化即可渲染新视图，并能自然捕捉昼夜过渡的复杂场景变化。

Conclusion: TimeNeRF展示了在少样本设置下高效渲染新视图的能力，并成功模拟了时间变化的3D场景，为元宇宙等应用提供了有力工具。

Abstract: We present TimeNeRF, a generalizable neural rendering approach for rendering
novel views at arbitrary viewpoints and at arbitrary times, even with few input
views. For real-world applications, it is expensive to collect multiple views
and inefficient to re-optimize for unseen scenes. Moreover, as the digital
realm, particularly the metaverse, strives for increasingly immersive
experiences, the ability to model 3D environments that naturally transition
between day and night becomes paramount. While current techniques based on
Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing
novel views, the exploration of NeRF's potential for temporal 3D scene modeling
remains limited, with no dedicated datasets available for this purpose. To this
end, our approach harnesses the strengths of multi-view stereo, neural radiance
fields, and disentanglement strategies across diverse datasets. This equips our
model with the capability for generalizability in a few-shot setting, allows us
to construct an implicit content radiance field for scene representation, and
further enables the building of neural radiance fields at any arbitrary time.
Finally, we synthesize novel views of that time via volume rendering.
Experiments show that TimeNeRF can render novel views in a few-shot setting
without per-scene optimization. Most notably, it excels in creating realistic
novel views that transition smoothly across different times, adeptly capturing
intricate natural scene changes from dawn to dusk.

</details>


### [66] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一种端到端视频扩散框架，用于显式分离静态外观和动态运动，通过全局静态标记和帧特定动态标记实现，并引入三种关键归纳偏置以减少信息泄漏。


<details>
  <summary>Details</summary>
Motivation: 现有基于VAE和GAN的方法在视频中分离静态和动态内容时存在信息泄漏和模糊重建问题，需要更有效的解决方案。

Method: DiViD采用序列编码器提取全局静态标记和帧特定动态标记，结合条件DDPM解码器，使用共享噪声计划、时间变化的KL瓶颈和交叉注意力机制。

Result: DiViD在真实世界基准测试中表现优于现有方法，具有最高的交换联合准确率，同时保持静态保真度和动态传递性。

Conclusion: DiViD通过显式分离静态和动态内容，显著减少了信息泄漏，为视频分解任务提供了新的解决方案。

Abstract: Unsupervised disentanglement of static appearance and dynamic motion in video
remains a fundamental challenge, often hindered by information leakage and
blurry reconstructions in existing VAE- and GAN-based approaches. We introduce
DiViD, the first end-to-end video diffusion framework for explicit
static-dynamic factorization. DiViD's sequence encoder extracts a global static
token from the first frame and per-frame dynamic tokens, explicitly removing
static content from the motion code. Its conditional DDPM decoder incorporates
three key inductive biases: a shared-noise schedule for temporal consistency, a
time-varying KL-based bottleneck that tightens at early timesteps (compressing
static information) and relaxes later (enriching dynamics), and cross-attention
that routes the global static token to all frames while keeping dynamic tokens
frame-specific. An orthogonality regularizer further prevents residual
static-dynamic leakage. We evaluate DiViD on real-world benchmarks using
swap-based accuracy and cross-leakage metrics. DiViD outperforms
state-of-the-art sequential disentanglement methods: it achieves the highest
swap-based joint accuracy, preserves static fidelity while improving dynamic
transfer, and reduces average cross-leakage.

</details>


### [67] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 研究发现视觉模型的感知能力与其短期预测性能强相关，提出了一种基于冻结视觉骨干的通用预测框架，并通过潜在扩散模型和轻量级解码器实现多任务评估。


<details>
  <summary>Details</summary>
Motivation: 探索视觉模型的感知能力与预测性能的关系，以提升通用系统的规划和行动能力。

Method: 使用冻结视觉骨干，训练潜在扩散模型预测未来特征，并通过轻量级解码器实现任务特定输出。

Result: 在九个模型和四个任务上验证了感知能力与预测性能的强相关性，展示了通用预测框架的有效性。

Conclusion: 结合表征学习和生成模型对视频理解具有重要意义。

Abstract: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.

</details>


### [68] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: 提出了一种基于量子辅助网络的超轻量级EIT图像重建框架QuantEIT，显著降低了模型复杂度，并在无监督、无需训练数据的情况下实现高精度重建。


<details>
  <summary>Details</summary>
Motivation: EIT具有高时间分辨率和低成本的优势，但其逆问题的不适定性导致图像重建困难。现有深度学习方法复杂且参数多，效率低。

Method: QuantEIT利用并行2量子比特电路生成潜在表示作为非线性先验，结合单线性层重建电导率，模型复杂度极低。

Result: 在模拟和真实2D/3D肺部EIT数据上，QuantEIT仅用0.2%的参数即超越传统方法，抗噪性更强。

Conclusion: QuantEIT首次将量子电路引入EIT重建，为高效、轻量化的医学成像提供了新思路。

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside
imaging modality with high temporal resolution, making it suitable for bedside
monitoring. However, its inherently ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Deep learning (DL)-based
approaches have shown promise but often rely on complex network architectures
with a large number of parameters, limiting efficiency and scalability. Here,
we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework
for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network
(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive
latent representations that serve as implicit nonlinear priors, followed by a
single linear layer for conductivity reconstruction. This design drastically
reduces model complexity and parameter number. Uniquely, QuantEIT operates in
an unsupervised, training-data-free manner and represents the first integration
of quantum circuits into EIT image reconstruction. Extensive experiments on
simulated and real-world 2D and 3D EIT lung imaging data demonstrate that
QuantEIT outperforms conventional methods, achieving comparable or superior
reconstruction accuracy using only 0.2% of the parameters, with enhanced
robustness to noise.

</details>


### [69] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 该论文提出了一个评估视觉隐私保护方法的综合框架，并引入了HR-VISPR数据集，用于训练可解释的隐私度量。


<details>
  <summary>Details</summary>
Motivation: AI驱动的监控技术引发了对敏感个人数据处理的担忧，因此需要客观评估隐私保护方法。

Method: 提出了一个三维评估框架（隐私、实用性和实用性），并使用HR-VISPR数据集评估了11种隐私保护方法。

Result: 框架能够区分隐私级别，并揭示隐私、实用性和实用性之间的权衡。

Conclusion: 该研究和数据集为隐私保护提供了结构化评估工具，适用于多种场景。

Abstract: Recent advances in AI-powered surveillance have intensified concerns over the
collection and processing of sensitive personal data. In response, research has
increasingly focused on privacy-by-design solutions, raising the need for
objective techniques to evaluate privacy protection. This paper presents a
comprehensive framework for evaluating visual privacy-protection methods across
three dimensions: privacy, utility, and practicality. In addition, it
introduces HR-VISPR, a publicly available human-centric dataset with biometric,
soft-biometric, and non-biometric labels to train an interpretable privacy
metric. We evaluate 11 privacy protection methods, ranging from conventional
techniques to advanced deep-learning methods, through the proposed framework.
The framework differentiates privacy levels in alignment with human visual
perception, while highlighting trade-offs between privacy, utility, and
practicality. This study, along with the HR-VISPR dataset, serves as an
insightful tool and offers a structured evaluation framework applicable across
diverse contexts.

</details>


### [70] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: 论文评估了一种基于深度学习的自动化软件（Carebot AI Bones）用于测量脊柱侧弯的Cobb角，结果显示其与放射科医生的测量结果具有高度一致性，可用于临床工作流程。


<details>
  <summary>Details</summary>
Motivation: 脊柱侧弯影响2-4%的青少年，传统手动测量耗时且存在观察者间差异，因此需要一种自动化解决方案。

Method: 研究回顾性评估了103张站立位全脊柱X光片，使用Carebot AI Bones软件进行自动测量，并与两位放射科医生的测量结果进行对比。

Result: AI与放射科医生的测量结果高度一致（Pearson相关系数0.906和0.880），平均绝对误差（MAE）约为3.9度，Cohen kappa显示分类一致性中等。

Conclusion: 该软件能够复现专家水平的Cobb角测量和分类，有望优化脊柱侧弯的临床报告和分诊流程。

Abstract: Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment
decisions depend on precise Cobb angle measurement. Manual assessment is time
consuming and subject to inter observer variation. We conducted a
retrospective, multi centre evaluation of a fully automated deep learning
software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on
103 standing anteroposterior whole spine radiographs collected from ten
hospitals. Two musculoskeletal radiologists independently measured each study
and served as reference readers. Agreement between the AI and each radiologist
was assessed with Bland Altman analysis, mean absolute error (MAE), root mean
squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four
grade severity classification. Against Radiologist 1 the AI achieved an MAE of
3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of
agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI
achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees
and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r
equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen
kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).
These results demonstrate that the proposed software reproduces expert level
Cobb angle measurements and categorical grading across multiple centres,
suggesting its utility for streamlining scoliosis reporting and triage in
clinical workflows.

</details>


### [71] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉自回归模型（VAR）的内容-风格分解方法CSD-VAR，通过尺度感知优化、SVD校正和增强键值记忆等技术，显著提升了分解效果。


<details>
  <summary>Details</summary>
Motivation: 现有的内容-风格分解方法主要针对扩散模型，而VAR作为一种新兴生成框架，其多尺度生成特性可能更适合分解任务。

Method: CSD-VAR采用尺度感知交替优化、SVD校正和增强键值记忆三项创新技术，并结合新数据集CSD-100进行验证。

Result: 实验表明，CSD-VAR在内容保持和风格化保真度上优于现有方法。

Conclusion: CSD-VAR为内容-风格分解提供了一种高效且性能优越的新方法，扩展了VAR的应用范围。

Abstract: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.

</details>


### [72] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 提出了一种自动化流水线，用于生成高质量图像编辑三元组（原始图像、指令、编辑图像），并发布了NHR-Edit数据集和Bagel-NHR-Edit模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要大量高质量的三元组数据，但手动标注成本高且难以自动化。

Method: 利用公共生成模型和任务优化的Gemini验证器，通过反转和组合自举扩大数据集。

Result: 生成了358k高质量三元组数据集NHR-Edit，并在实验中表现优于其他公开数据集。

Conclusion: 该方法实现了大规模高质量数据自动化生成，推动了图像编辑助手的研究。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


### [73] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene是一个端到端框架，通过文本或对话生成高质量且可编辑的3D场景，解决了自动化、3D一致性和细粒度控制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动化、3D一致性和细粒度控制方面存在不足，DreamScene旨在解决这些问题，为游戏、电影和设计等领域提供实用解决方案。

Method: DreamScene结合GPT-4代理推断对象语义和空间约束构建混合图，使用图布局算法生成无碰撞结构，并通过多时间步采样和重建优化生成几何。

Result: 实验表明，DreamScene在质量、一致性和灵活性上优于现有方法，支持细粒度编辑和动态运动。

Conclusion: DreamScene为开放域3D内容创作提供了实用且高效的解决方案。

Abstract: Generating 3D scenes from natural language holds great promise for
applications in gaming, film, and design. However, existing methods struggle
with automation, 3D consistency, and fine-grained control. We present
DreamScene, an end-to-end framework for high-quality and editable 3D scene
generation from text or dialogue. DreamScene begins with a scene planning
module, where a GPT-4 agent infers object semantics and spatial constraints to
construct a hybrid graph. A graph-based placement algorithm then produces a
structured, collision-free layout. Based on this layout, Formation Pattern
Sampling (FPS) generates object geometry using multi-timestep sampling and
reconstructive optimization, enabling fast and realistic synthesis. To ensure
global consistent, DreamScene employs a progressive camera sampling strategy
tailored to both indoor and outdoor settings. Finally, the system supports
fine-grained scene editing, including object movement, appearance changes, and
4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior
methods in quality, consistency, and flexibility, offering a practical solution
for open-domain 3D content creation. Code and demos are available at
https://dreamscene-project.github.io.

</details>


### [74] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的隧道裂缝分类与分割两步法，结合DenseNet-169和DeepLabV3+，显著提高了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 隧道裂缝是安全状态的关键指标，需高精度、高效率的分类与分割方法。

Method: 第一步使用DenseNet-169分类隧道图像，第二步用DeepLabV3+分割裂缝，并通过可视化技术评估模型逻辑。

Result: 分类模型准确率92.23%，FPS 39.80；分割模型IoU 57.01%，F1分数67.44%，均优于其他模型。

Conclusion: 该方法为隧道健康状态快速准确评估提供了基础，并有助于理解深度学习模型的“黑箱”。

Abstract: Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming
to classify and segment tunnel cracks with enhanced accuracy and efficiency,
this study proposes a two-step deep learning-based method. An automatic tunnel
image classification model is developed using the DenseNet-169 in the first
step. The proposed crack segmentation model in the second step is based on the
DeepLabV3+, whose internal logic is evaluated via a score-weighted visual
explanation technique. Proposed method combines tunnel image classification and
segmentation together, so that the selected images containing cracks from the
first step are segmented in the second step to improve the detection accuracy
and efficiency. The superior performances of the two-step method are validated
by experiments. The results show that the accuracy and frames per second (FPS)
of the tunnel crack classification model are 92.23% and 39.80, respectively,
which are higher than other convolutional neural networks (CNN) based and
Transformer based models. Also, the intersection over union (IoU) and F1 score
of the tunnel crack segmentation model are 57.01% and 67.44%, respectively,
outperforming other state-of-the-art models. Moreover, the provided visual
explanations in this study are conducive to understanding the "black box" of
deep learning-based models. The developed two-stage deep learning-based method
integrating visual explanations provides a basis for fast and accurate
quantitative assessment of tunnel health status.

</details>


### [75] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 提出了一种基于多光谱成像和增强YOLOv5模型的深度学习框架，用于植物叶片异常分割，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要准确检测植物叶片营养缺乏，以实现早期干预。

Method: 使用多光谱成像和带有Transformer注意力头的增强YOLOv5模型，处理九通道输入并利用自注意力机制捕捉细微症状。

Result: 模型在Dice分数和IoU上比基线YOLOv5提升约12%，尤其在检测萎黄和色素积累等挑战性症状上表现优异。

Conclusion: 结合多光谱成像与光谱-空间特征学习，对植物表型分析和精准农业具有重要潜力。

Abstract: Accurate detection of nutrient deficiency in plant leaves is essential for
precision agriculture, enabling early intervention in fertilization, disease,
and stress management. This study presents a deep learning framework for leaf
anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model
with a transformer-based attention head. The model is tailored for processing
nine-channel multispectral input and uses self-attention mechanisms to better
capture subtle, spatially-distributed symptoms. The plants in the experiments
were grown under controlled nutrient stress conditions for evaluation. We carry
out extensive experiments to benchmark the proposed model against the baseline
YOLOv5. Extensive experiments show that the proposed model significantly
outperforms the baseline YOLOv5, with an average Dice score and IoU
(Intersection over Union) improvement of about 12%. In particular, this model
is effective in detecting challenging symptoms like chlorosis and pigment
accumulation. These results highlight the promise of combining multi-spectral
imaging with spectral-spatial feature learning for advancing plant phenotyping
and precision agriculture.

</details>


### [76] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 论文提出了一种情感驱动的图像编辑方法，包括数据集MoodArchive、模型MoodifyCLIP和编辑工具Moodifier，用于精确调整图像情感同时保持内容完整性。


<details>
  <summary>Details</summary>
Motivation: 情感驱动的图像编辑在创意产业中潜力巨大，但由于情感的抽象性和多样性，精确操作仍具挑战性。

Method: 1. 构建MoodArchive数据集（8M+图像，带情感标注）；2. 开发MoodifyCLIP模型，将情感映射为视觉属性；3. 提出Moodifier编辑工具，结合MLLMs实现无训练的情感编辑。

Result: Moodifier在情感准确性和内容保留上优于现有方法，适用于多种领域（如角色表情、时尚设计等）。

Conclusion: 该方法通过将抽象情感与具体视觉变化关联，为情感内容创作开辟了新途径。

Abstract: Bridging emotions and visual content for emotion-driven image editing holds
great potential in creative industries, yet precise manipulation remains
challenging due to the abstract nature of emotions and their varied
manifestations across different contexts. We tackle this challenge with an
integrated approach consisting of three complementary components. First, we
introduce MoodArchive, an 8M+ image dataset with detailed hierarchical
emotional annotations generated by LLaVA and partially validated by human
evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned
on MoodArchive to translate abstract emotions into specific visual attributes.
Third, we propose Moodifier, a training-free editing model leveraging
MoodifyCLIP and multimodal large language models (MLLMs) to enable precise
emotional transformations while preserving content integrity. Our system works
across diverse domains such as character expressions, fashion design, jewelry,
and home d\'ecor, enabling creators to quickly visualize emotional variations
while preserving identity and structure. Extensive experimental evaluations
show that Moodifier outperforms existing methods in both emotional accuracy and
content preservation, providing contextually appropriate edits. By linking
abstract emotions to concrete visual changes, our solution unlocks new
possibilities for emotional content creation in real-world applications. We
will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier
code and demo publicly available upon acceptance.

</details>


### [77] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: Vision Mamba的MTR框架无需训练即可高效减少计算量，性能损失小。


<details>
  <summary>Details</summary>
Motivation: 探索Vision Mamba的效率，解决直接应用ViT的token reduction技术导致的性能下降问题。

Method: 提出Mamba结构感知的重要性评分，并基于此设计训练免费的MTR框架。

Result: MTR在多种任务和骨干网络上显著减少计算量（如Vim-B上FLOPs减少40%），性能损失极小（ImageNet仅下降1.6%）。

Conclusion: MTR是一种高效、即插即用的Vision Mamba token reduction解决方案。

Abstract: Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)
due to its ability to efficiently capture long-range dependencies with linear
computational complexity. While token reduction, an effective compression
technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision
Mamba's efficiency is essential for enabling broader applications. However, we
find that directly applying existing token reduction techniques for ViTs to
Vision Mamba leads to significant performance degradation. This is primarily
because Mamba is a sequence model without attention mechanisms, whereas most
token reduction techniques for ViTs rely on attention mechanisms for importance
measurement and overlook the order of compressed tokens. In this paper, we
investigate a Mamba structure-aware importance score to evaluate token
importance in a simple and effective manner. Building on this score, we further
propose MTR, a training-free \textbf{M}amba \textbf{T}oken \textbf{R}eduction
framework. Without the need for training or additional tuning parameters, our
method can be seamlessly integrated as a plug-and-play component across various
Mamba models. Extensive experiments demonstrate that our approach significantly
reduces computational workload while minimizing performance impact across
various tasks and multiple backbones. Notably, MTR reduces FLOPs by
approximately 40\% on the Vim-B backbone, with only a 1.6\% drop in ImageNet
performance without retraining.

</details>


### [78] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 该论文研究了基于冻结基础模型（FM）的类增量学习（CIL）在皮肤病分类中的应用，提出了一种轻量级MLP增量训练方法，并探索了零训练场景的原型分类器。


<details>
  <summary>Details</summary>
Motivation: 探索冻结基础模型在皮肤病分类中的类增量学习潜力，解决传统方法在增量学习中的遗忘问题。

Method: 冻结预训练的基础模型，仅增量训练轻量级MLP；同时探索零训练场景下的原型分类器。

Result: 提出的方法在性能上优于正则化、回放和基于架构的方法，原型分类器也表现出竞争力。

Conclusion: 冻结基础模型在皮肤病持续学习中表现出色，支持其在现实医疗应用中的广泛采用。

Abstract: Class-Incremental Learning (CIL) aims to learn new classes over time without
forgetting previously acquired knowledge. The emergence of foundation models
(FM) pretrained on large datasets presents new opportunities for CIL by
offering rich, transferable representations. However, their potential for
enabling incremental learning in dermatology remains largely unexplored. In
this paper, we systematically evaluate frozen FMs pretrained on large-scale
skin lesion datasets for CIL in dermatological disease classification. We
propose a simple yet effective approach where the backbone remains frozen, and
a lightweight MLP is trained incrementally for each task. This setup achieves
state-of-the-art performance without forgetting, outperforming regularization,
replay, and architecture based methods. To further explore the capabilities of
frozen FMs, we examine zero training scenarios using nearest mean classifiers
with prototypes derived from their embeddings. Through extensive ablation
studies, we demonstrate that this prototype based variant can also achieve
competitive results. Our findings highlight the strength of frozen FMs for
continual learning in dermatology and support their broader adoption in real
world medical applications. Our code and datasets are available here.

</details>


### [79] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: VLA-Mark是一种视觉对齐的水印框架，通过跨模态协调嵌入可检测水印，同时保持语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有文本水印方法会破坏视觉-文本对齐，VLA-Mark旨在保护知识产权而不损害多模态一致性。

Method: 结合多尺度视觉-文本对齐指标（局部补丁亲和性、全局语义一致性和上下文注意力模式），动态平衡水印强度和语义保留。

Result: 实验显示，VLA-Mark在PPL和BLEU上优于传统方法，检测准确率接近完美（98.8% AUC），并具有96.1%的抗攻击能力。

Conclusion: VLA-Mark为质量保持的多模态水印设定了新标准。

Abstract: Vision-language models demand watermarking solutions that protect
intellectual property without compromising multimodal coherence. Existing text
watermarking methods disrupt visual-textual alignment through biased token
selection and static strategies, leaving semantic-critical concepts vulnerable.
We propose VLA-Mark, a vision-aligned framework that embeds detectable
watermarks while preserving semantic fidelity through cross-modal coordination.
Our approach integrates multiscale visual-textual alignment metrics, combining
localized patch affinity, global semantic coherence, and contextual attention
patterns, to guide watermark injection without model retraining. An
entropy-sensitive mechanism dynamically balances watermark strength and
semantic preservation, prioritizing visual grounding during low-uncertainty
generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than
conventional methods, with near-perfect detection (98.8% AUC). The framework
demonstrates 96.1\% attack resilience against attacks such as paraphrasing and
synonym substitution, while maintaining text-visual consistency, establishing
new standards for quality-preserving multimodal watermarking

</details>


### [80] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文分析了四种人体匿名化技术（模糊、掩码、加密和虚拟形象替换）对异常检测性能的影响，发现匿名化后检测仍可行，且性能与算法设计相关。


<details>
  <summary>Details</summary>
Motivation: 深度学习在监控视频异常检测中取得进展，但涉及敏感数据收集引发隐私问题，需研究匿名化技术对检测性能的影响。

Method: 在UCF-Crime数据集上应用四种匿名化技术，评估四种异常检测方法（MGFN、UR-DMU、BN-WVAD、PEL4VAD）的性能。

Result: 实验表明匿名化数据下异常检测仍可行，某些匿名化技术（如加密和掩码）甚至能提升部分模型的AUC性能。

Conclusion: 研究揭示了算法对匿名化的敏感性，并强调了隐私保护与检测效用之间的权衡，为平衡隐私与检测需求提供了基准。

Abstract: Advancements in deep learning have improved anomaly detection in surveillance
videos, yet they raise urgent privacy concerns due to the collection of
sensitive human data. In this paper, we present a comprehensive analysis of
anomaly detection performance under four human anonymization techniques,
including blurring, masking, encryption, and avatar replacement, applied to the
UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,
BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method
responds to different obfuscation techniques. Experimental results demonstrate
that anomaly detection remains viable under anonymized data and is dependent on
the algorithmic design and the learning strategy. For instance, under certain
anonymization patterns, such as encryption and masking, some models
inadvertently achieve higher AUC performance compared to raw data, due to the
strong responsiveness of their algorithmic components to these noise patterns.
These results highlight the algorithm-specific sensitivities to anonymization
and emphasize the trade-off between preserving privacy and maintaining
detection utility. Furthermore, we compare these conventional anonymization
techniques with the emerging privacy-by-design solutions, highlighting an often
overlooked trade-off between robust privacy protection and utility flexibility.
Through comprehensive experiments and analyses, this study provides a
compelling benchmark and insights into balancing human privacy with the demands
of anomaly detection.

</details>


### [81] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: C-DOG是一种无需训练的多视角多目标关联框架，通过图建模和几何约束实现鲁棒关联，适用于3D重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在目标视觉相似或噪声干扰下失效的问题。

Method: 结合连接delta-overlap图建模和极线几何，利用IQR过滤和3D反投影误差提高鲁棒性。

Result: 在合成基准测试中优于几何基线，适应高目标密度和有限相机重叠等挑战。

Conclusion: C-DOG适用于实际场景中的可扩展3D重建。

Abstract: Multi-view multi-object association is a fundamental step in 3D
reconstruction pipelines, enabling consistent grouping of object instances
across multiple camera views. Existing methods often rely on appearance
features or geometric constraints such as epipolar consistency. However, these
approaches can fail when objects are visually indistinguishable or observations
are corrupted by noise. We propose C-DOG, a training-free framework that serves
as an intermediate module bridging object detection (or pose estimation) and 3D
reconstruction, without relying on visual features. It combines connected
delta-overlap graph modeling with epipolar geometry to robustly associate
detections across views. Each 2D observation is represented as a graph node,
with edges weighted by epipolar consistency. A delta-neighbor-overlap
clustering step identifies strongly consistent groups while tolerating noise
and partial connectivity. To further improve robustness, we incorporate
Interquartile Range (IQR)-based filtering and a 3D back-projection error
criterion to eliminate inconsistent observations. Extensive experiments on
synthetic benchmarks demonstrate that C-DOG outperforms geometry-based
baselines and remains robust under challenging conditions, including high
object density, without visual features, and limited camera overlap, making it
well-suited for scalable 3D reconstruction in real-world scenarios.

</details>


### [82] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: Franca是一个完全开源（数据、代码、权重）的视觉基础模型，性能优于或匹敌现有专有模型（如DINOv2、CLIP等）。通过透明训练流程和多头聚类投影器，解决了SSL聚类方法的局限性，并提出了位置解耦策略，提升了语义编码效果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型多为专有，缺乏透明性。Franca旨在提供一个开源、高性能的替代方案，同时解决SSL聚类方法的固有模糊性问题。

Method: 使用公开数据（ImageNet-21K和ReLAION-2B子集），采用透明训练流程。提出多头聚类投影器（基于嵌套Matryoshka表示）和位置解耦策略，优化特征空间。

Result: 在多个下游基准测试中表现优异，性能优于或匹敌专有模型。特征空间更干净，语义编码更高效。

Conclusion: Franca为透明、高性能的视觉基础模型设定了新标准，推动了可复现和通用AI模型的发展。

Abstract: We present Franca (pronounced Fran-ka): free one; the first fully open-source
(data, code, weights) vision foundation model that matches and in many cases
surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,
CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training
pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and
a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in
SSL clustering methods. While modern models rely on assigning image features to
large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to
account for the inherent ambiguity in clustering semantics. To address this, we
introduce a parameter-efficient, multi-head clustering projector based on
nested Matryoshka representations. This design progressively refines features
into increasingly fine-grained clusters without increasing the model size,
enabling both performance and memory efficiency. Additionally, we propose a
novel positional disentanglement strategy that explicitly removes positional
biases from dense representations, thereby improving the encoding of semantic
content. This leads to consistent gains on several downstream benchmarks,
demonstrating the utility of cleaner feature spaces. Our contributions
establish a new standard for transparent, high-performance vision models and
open a path toward more reproducible and generalizable foundation models for
the broader AI community. The code and model checkpoints are available at
https://github.com/valeoai/Franca.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [83] [Neural Architecture Search with Mixed Bio-inspired Learning Rules](https://arxiv.org/abs/2507.13485)
*Imane Hamzaoui,Riyadh Baghdadi*

Main category: cs.NE

TL;DR: 通过自动搜索不同层的生物启发学习规则，提升生物启发神经网络的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 生物启发神经网络在对抗鲁棒性、能效和生理学对齐方面表现优异，但在准确性和可扩展性上落后于基于反向传播的模型。

Method: 扩展神经架构搜索（NAS）空间，自动发现并应用不同层的生物启发学习规则。

Result: 混合学习规则的网络在多个数据集上创下生物启发模型的新记录，甚至在某些情况下超越反向传播网络。

Conclusion: 层间学习规则的多样性有助于提升网络性能，推动混合生物启发学习规则的进一步研究。

Abstract: Bio-inspired neural networks are attractive for their adversarial robustness,
energy frugality, and closer alignment with cortical physiology, yet they often
lag behind back-propagation (BP) based models in accuracy and ability to scale.
We show that allowing the use of different bio-inspired learning rules in
different layers, discovered automatically by a tailored
neural-architecture-search (NAS) procedure, bridges this gap. Starting from
standard NAS baselines, we enlarge the search space to include bio-inspired
learning rules and use NAS to find the best architecture and learning rule to
use in each layer. We show that neural networks that use different bio-inspired
learning rules for different layers have better accuracy than those that use a
single rule across all the layers. The resulting NN that uses a mix of
bio-inspired learning rules sets new records for bio-inspired models: 95.16% on
CIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on
ImageNet. In some regimes, they even surpass comparable BP-based networks while
retaining their robustness advantages. Our results suggest that layer-wise
diversity in learning rules allows better scalability and accuracy, and
motivates further research on mixing multiple bio-inspired learning rules in
the same network.

</details>


### [84] [Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies](https://arxiv.org/abs/2507.13549)
*Jim O'Connor,Nicholas Lorentzen,Gary B. Parker,Derin Gezgin*

Main category: cs.NE

TL;DR: 本文研究了利用NEAT算法为Xpilot-AI平台开发高性能赛车控制器，实现了在复杂赛道和模拟物理环境下的自适应控制。


<details>
  <summary>Details</summary>
Motivation: 探索NEAT算法在游戏环境中生成高效赛车控制器的潜力，并验证Xpilot-AI作为AI控制器进化测试平台的适用性。

Method: 使用NEAT算法进化神经网络的拓扑结构和权重，开发适应复杂赛道和物理模拟的赛车控制器。

Result: 实验结果显示，进化后的控制器在单圈时间上提升了32%，并表现出类似人类的赛车策略。

Conclusion: NEAT算法在游戏环境中能有效生成鲁棒的控制策略，Xpilot-AI适合作为AI控制器进化的测试平台。

Abstract: This paper investigates the development of high-performance racing
controllers for a newly implemented racing mode within the Xpilot-AI platform,
utilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By
leveraging NEAT's capability to evolve both the structure and weights of neural
networks, we develop adaptive controllers that can navigate complex circuits
under the challenging space simulation physics of Xpilot-AI, which includes
elements such as inertia, friction, and gravity. The racing mode we introduce
supports flexible circuit designs and allows for the evaluation of multiple
agents in parallel, enabling efficient controller optimization across
generations. Experimental results demonstrate that our evolved controllers
achieve up to 32% improvement in lap time compared to the controller's initial
performance and develop effective racing strategies, such as optimal cornering
and speed modulation, comparable to human-like techniques. This work
illustrates NEAT's effectiveness in producing robust control strategies within
demanding game environments and highlights Xpilot-AI's potential as a rigorous
testbed for competitive AI controller evolution.

</details>


### [85] [MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development](https://arxiv.org/abs/2507.13785)
*Mykola Glybovets,Sergii Medvid*

Main category: cs.NE

TL;DR: MorphoNAS是一种受生物启发的神经架构搜索方法，通过简单的基因组和局部化学相互作用，能够自组织生成复杂神经网络。


<details>
  <summary>Details</summary>
Motivation: 现代人工神经架构搜索方法依赖大量手动工作，而生物神经网络则通过简单规则从紧凑基因组发展而来。MorphoNAS旨在模拟这一自然过程。

Method: MorphoNAS基于自由能原理、反应-扩散系统和基因调控网络，通过简单的基因组编码形态发生动力学和细胞发育规则，实现神经网络的确定性生长。

Result: 在结构目标和功能性能实验中，MorphoNAS成功生成预定义随机图配置（8-31节点）和低复杂度（6-7神经元）的CartPole控制任务解决方案。

Conclusion: MorphoNAS展示了通过简单发育规则生成复杂神经架构的可行性，为高效神经架构搜索提供了生物学启示。

Abstract: While biological neural networks develop from compact genomes using
relatively simple rules, modern artificial neural architecture search methods
mostly involve explicit and routine manual work. In this paper, we introduce
MorphoNAS (Morphogenetic Neural Architecture Search), a system able to
deterministically grow neural networks through morphogenetic self-organization
inspired by the Free Energy Principle, reaction-diffusion systems, and gene
regulatory networks. In MorphoNAS, simple genomes encode just morphogens
dynamics and threshold-based rules of cellular development. Nevertheless, this
leads to self-organization of a single progenitor cell into complex neural
networks, while the entire process is built on local chemical interactions. Our
evolutionary experiments focused on two different domains: structural
targeting, in which MorphoNAS system was able to find fully successful genomes
able to generate predefined random graph configurations (8-31 nodes); and
functional performance on the CartPole control task achieving low complexity
6-7 neuron solutions when target network size minimization evolutionary
pressure was applied. The evolutionary process successfully balanced between
quality of of the final solutions and neural architecture search effectiveness.
Overall, our findings suggest that the proposed MorphoNAS method is able to
grow complex specific neural architectures, using simple developmental rules,
which suggests a feasible biological route to adaptive and efficient neural
architecture search.

</details>


### [86] [Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions](https://arxiv.org/abs/2507.14011)
*Paolo Totaro,Alberto Mangiante*

Main category: cs.NE

TL;DR: 提出了一种基于体验的认知过程建模方法，从生命系统而非观察者视角出发，利用环境生成算子（EGO）和自指语言（E-language）模拟认知过程。


<details>
  <summary>Details</summary>
Motivation: 从生命系统自身维持生命平衡的需求出发，而非外部观察者视角，更真实地建模认知过程。

Method: 使用环境生成算子（EGO）和自指语言（E-language）模拟Hebb神经元组上的认知操作。

Result: 已实现并测试了EGO原型（EGO-P）。

Conclusion: 该方法为基于体验的认知建模提供了新工具，验证了EGO的可行性。

Abstract: This article proposes a method to formalise models of cognitive processes
grounded in experience, considering experience from the perspective of a living
system and not from that of an observer of the living system. The perspective
of a living system is defined by the need of the system to preserve the vital
equilibria. The method is based on an algorithmic schema that we call
Environment Generative Operator (EGO) and uses a self-referential language
developed for this purpose which we call E-language. EGO simulates cognitive
processes as operations on neuron assemblies as understood by Hebb. In this
article we present an EGO prototype (EGO-P) which has already been implemented
and tested.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [87] [Resource-Splitting Games with Tullock-Based Lossy Contests](https://arxiv.org/abs/2507.13853)
*Marko Maljkovic,Gustav Nilsson,Nikolas Geroliminis*

Main category: cs.GT

TL;DR: 本文提出了一种新的多阶段资源分配博弈模型，研究了供需平衡和资源投入对利润的影响，并提出了计算纳什均衡的半分散方法。


<details>
  <summary>Details</summary>
Motivation: 研究现实场景中供需平衡和资源投入对利润的影响，解决因参与者不足导致的利润损失问题。

Method: 提出了一种结合加权公平比例资源分配的框架，研究了集中式和纳什均衡策略，并提供了计算纳什均衡的迭代方法。

Result: 证明了均衡的存在性和唯一性，并将框架推广至现有模型（如Receding Horizon和Blotto博弈），提出了Blotto设置中计算纳什均衡的半解析方法。

Conclusion: 通过智能移动的数值案例验证了模型的实用性和适用性。

Abstract: This paper introduces a novel class of multi-stage resource allocation games
that model real-world scenarios in which profitability depends on the balance
between supply and demand, and where higher resource investment leads to
greater returns. Our proposed framework, which incorporates the notion of
profit loss due to insufficient player participation, gives rise to a
Tullock-like functional form of the stage payoff structure when weighted fair
proportional resource allocation is applied. We explore both centralized and
Nash equilibrium strategies, establish sufficient conditions for their
existence and uniqueness, and provide an iterative, semi-decentralized method
to compute the Nash equilibrium in games with arbitrarily many players.
Additionally, we demonstrate that the framework generalizes instances of
several existing models, including Receding Horizon and Blotto games, and
present a semi-analytical method for computing the unique Nash equilibrium
within the Blotto setup. Our findings are validated through a numerical case
study in smart mobility, highlighting the practical relevance and applicability
of the proposed model.

</details>


### [88] [Online MMS Allocation for Chores](https://arxiv.org/abs/2507.14039)
*Jiaxin Song,Biaoshuai Tao,Wenqian Wang,Yuhao Zhang*

Main category: cs.GT

TL;DR: 论文研究了在线不可分割杂务的公平分配问题，填补了现有理论中的负向差距，并提出了适用于一般情况的在线算法。


<details>
  <summary>Details</summary>
Motivation: 解决在线不可分割杂务分配中的公平性问题，填补现有理论中的负向差距。

Method: 通过理论证明和算法设计，研究了在线分配问题，提出了一个适用于一般情况的在线算法。

Result: 证明了对于任何固定的n和ε，无法保证(n-ε)-MMS分配；同时提出了一个适用于一般情况的在线算法，保证min{n, O(k), O(log D)}-MMS分配。

Conclusion: 论文填补了理论上的负向差距，并提供了实际可行的算法，适用于多种场景。

Abstract: We study the problem of fair division of indivisible chores among $n$ agents
in an online setting, where items arrive sequentially and must be allocated
irrevocably upon arrival. The goal is to produce an $\alpha$-MMS allocation at
the end. Several recent works have investigated this model, but have only
succeeded in obtaining non-trivial algorithms under restrictive assumptions,
such as the two-agent bi-valued special case (Wang and Wei, 2025), or by
assuming knowledge of the total disutility of each agent (Zhou, Bai, and Wu,
2023). For the general case, the trivial $n$-MMS guarantee remains the best
known, while the strongest lower bound is still only $2$.
  We close this gap on the negative side by proving that for any fixed $n$ and
$\varepsilon$, no algorithm can guarantee an $(n - \varepsilon)$-MMS
allocation. Notably, this lower bound holds precisely for every $n$, without
hiding constants in big-$O$ notation, thereby exactly matching the trivial
upper bound.
  Despite this strong impossibility result, we also present positive results.
We provide an online algorithm that applies in the general case, guaranteeing a
$\min\{n, O(k), O(\log D)\}$-MMS allocation, where $k$ is the maximum number of
distinct disutilities across all agents and $D$ is the maximum ratio between
the largest and smallest disutilities for any agent. This bound is reasonable
across a broad range of scenarios and, for example, implies that we can achieve
an $O(1)$-MMS allocation whenever $k$ is constant. Moreover, to optimize the
constant in the important personalized bi-valued case, we show that if each
agent has at most two distinct disutilities, our algorithm guarantees a $(2 +
\sqrt{3}) \approx 3.7$-MMS allocation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [89] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 论文从物理角度分析Transformer架构，提出基于Fock空间的物理模型，解释其作为开放量子系统的工作原理。


<details>
  <summary>Details</summary>
Motivation: 填补对Transformer架构理论理解的空白，尤其是其物理工作原理。

Method: 从现代芯片的物理视角，在Fock空间上构建物理模型，将Transformer架构实现为开放量子系统。

Result: 提出了支持Transformer架构的物理模型，解释了其在大语言模型中的工作原理。

Conclusion: 通过物理模型揭示了Transformer架构的底层机制，为理论理解提供了新视角。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


### [90] [Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models](https://arxiv.org/abs/2507.13383)
*Charvi Rastogi,Tian Huey Teh,Pushkar Mishra,Roma Patel,Ding Wang,Mark Díaz,Alicia Parrish,Aida Mostafazadeh Davani,Zoe Ashwood,Michela Paganini,Vinodkumar Prabhakaran,Verena Rieser,Lora Aroyo*

Main category: cs.LG

TL;DR: 论文提出了一种多元对齐方法，通过DIVE数据集和人口统计学多样性评估，改进文本到图像模型的多样性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型未能充分考虑人类经验的多样性，导致系统与人类价值观不一致。

Method: 引入DIVE数据集，利用多元人口统计学评估，分析不同背景人群对安全性的感知差异。

Result: 证实人口统计学是多样观点的重要代理，揭示了与传统评估不同的危害感知差异。

Conclusion: 为构建更公平和对齐的文本到图像模型提供了基础工具和方法。

Abstract: Current text-to-image (T2I) models often fail to account for diverse human
experiences, leading to misaligned systems. We advocate for pluralistic
alignment, where an AI understands and is steerable towards diverse, and often
conflicting, human values. Our work provides three core contributions to
achieve this in T2I models. First, we introduce a novel dataset for Diverse
Intersectional Visual Evaluation (DIVE) -- the first multimodal dataset for
pluralistic alignment. It enable deep alignment to diverse safety perspectives
through a large pool of demographically intersectional human raters who
provided extensive feedback across 1000 prompts, with high replication,
capturing nuanced safety perceptions. Second, we empirically confirm
demographics as a crucial proxy for diverse viewpoints in this domain,
revealing significant, context-dependent differences in harm perception that
diverge from conventional evaluations. Finally, we discuss implications for
building aligned T2I models, including efficient data collection strategies,
LLM judgment capabilities, and model steerability towards diverse perspectives.
This research offers foundational tools for more equitable and aligned T2I
systems. Content Warning: The paper includes sensitive content that may be
harmful.

</details>


### [91] [Improving KAN with CDF normalization to quantiles](https://arxiv.org/abs/2507.13393)
*Jakub Strawa,Jarek Duda*

Main category: cs.LG

TL;DR: 论文探讨了在机器学习中使用CDF归一化的优势，特别是在Kolmogorov-Arnold Networks (KANs)中，通过替换传统的缩放方法，提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习中常用的归一化方法（如均值标准差或固定范围缩放）在金融领域的copula理论中较少使用，而CDF归一化能减少过拟合并简化表示。

Method: 采用CDF归一化方法，将数据转换为近似均匀分布，应用于KANs中，并与Legendre-KAN进行对比。

Result: 在KANs中，CDF归一化显著提升了预测性能，同时权重可解释为混合矩，支持概率分布传播和方向调整。

Conclusion: CDF归一化在机器学习中具有潜力，尤其在KANs中表现优异，值得进一步研究和应用。

Abstract: Data normalization is crucial in machine learning, usually performed by
subtracting the mean and dividing by standard deviation, or by rescaling to a
fixed range. In copula theory, popular in finance, there is used normalization
to approximately quantiles by transforming x to CDF(x) with estimated CDF
(cumulative distribution function) to nearly uniform distribution in [0,1],
allowing for simpler representations which are less likely to overfit. It seems
nearly unknown in machine learning, therefore, we would like to present some
its advantages on example of recently popular Kolmogorov-Arnold Networks
(KANs), improving predictions from Legendre-KAN by just switching rescaling to
CDF normalization. Additionally, in HCR interpretation, weights of such neurons
are mixed moments providing local joint distribution models, allow to propagate
also probability distributions, and change propagation direction.

</details>


### [92] [Scalable Submodular Policy Optimization via Pruned Submodularity Graph](https://arxiv.org/abs/2507.13834)
*Aditi Anand,Suman Banerjee,Dildar Ali*

Main category: cs.LG

TL;DR: 本文研究了一种强化学习问题变体，其中奖励函数是子模的，提出了一种基于修剪子模图的方法，在可行计算时间内提供近似最优解。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中奖励函数通常是加性的，但现实中许多问题（如路径规划、覆盖控制等）的奖励函数具有递减回报特性，适合用子模函数建模。

Method: 提出了一种基于修剪子模图的方法，分析了其时间和空间复杂度，并提供了性能保证。

Result: 在基准实验环境中，所提方法获得的策略比基线方法产生更多奖励。

Conclusion: 该方法在子模奖励函数的强化学习问题中表现优于基线方法，具有实际应用潜力。

Abstract: In Reinforcement Learning (abbreviated as RL), an agent interacts with the
environment via a set of possible actions, and a reward is generated from some
unknown distribution. The task here is to find an optimal set of actions such
that the reward after a certain time step gets maximized. In a traditional
setup, the reward function in an RL Problem is considered additive. However, in
reality, there exist many problems, including path planning, coverage control,
etc., the reward function follows the diminishing return, which can be modeled
as a submodular function. In this paper, we study a variant of the RL Problem
where the reward function is submodular, and our objective is to find an
optimal policy such that this reward function gets maximized. We have proposed
a pruned submodularity graph-based approach that provides a provably
approximate solution in a feasible computation time. The proposed approach has
been analyzed to understand its time and space requirements as well as a
performance guarantee. We have experimented with a benchmark agent-environment
setup, which has been used for similar previous studies, and the results are
reported. From the results, we observe that the policy obtained by our proposed
approach leads to more reward than the baseline methods.

</details>


### [93] [Selective Embedding for Deep Learning](https://arxiv.org/abs/2507.13399)
*Mert Sehri,Zehui Hua,Francisco de Assis Boldt,Patrick Dumond*

Main category: cs.LG

TL;DR: 提出了一种名为选择性嵌入的新数据加载策略，通过交替多源数据短片段提升深度学习模型的泛化能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习在非平稳条件和跨域数据中表现不佳，传统数据加载策略泛化能力有限或计算成本高。

Method: 选择性嵌入策略，模仿人类信息处理方式，在单一输入通道中交替加载多源数据短片段。

Result: 在六个时域数据集上验证，该方法显著提高分类准确性并减少训练时间。

Conclusion: 选择性嵌入为多源数据复杂系统提供了一种可扩展且资源高效的解决方案。

Abstract: Deep learning has revolutionized many industries by enabling models to
automatically learn complex patterns from raw data, reducing dependence on
manual feature engineering. However, deep learning algorithms are sensitive to
input data, and performance often deteriorates under nonstationary conditions
and across dissimilar domains, especially when using time-domain data.
Conventional single-channel or parallel multi-source data loading strategies
either limit generalization or increase computational costs. This study
introduces selective embedding, a novel data loading strategy, which alternates
short segments of data from multiple sources within a single input channel.
Drawing inspiration from cognitive psychology, selective embedding mimics
human-like information processing to reduce model overfitting, enhance
generalization, and improve computational efficiency. Validation is conducted
using six time-domain datasets, demonstrating that the proposed method
consistently achieves high classification accuracy across various deep learning
architectures while significantly reducing training times. The approach proves
particularly effective for complex systems with multiple data sources, offering
a scalable and resource-efficient solution for real-world applications in
healthcare, heavy machinery, marine, railway, and agriculture, where robustness
and adaptability are critical.

</details>


### [94] [LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data](https://arxiv.org/abs/2507.13413)
*Aleksey Lapin,Igor Hromov,Stanislav Chumakov,Mile Mitrovic,Dmitry Simakov,Nikolay O. Nikitin,Andrey V. Savchenko*

Main category: cs.LG

TL;DR: LightAutoDS-Tab是一个结合LLM代码生成和多个AutoML工具的多代理系统，用于表格数据任务，提升了灵活性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前AutoML在复杂任务中的效率受限于对特定底层工具的依赖。

Method: 结合LLM代码生成和多个AutoML工具，设计多代理系统。

Result: 在多个Kaggle数据科学任务中优于现有开源解决方案。

Conclusion: LightAutoDS-Tab通过多代理系统提升了AutoML的灵活性和性能。

Abstract: AutoML has advanced in handling complex tasks using the integration of LLMs,
yet its efficiency remains limited by dependence on specific underlying tools.
In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for
tasks with tabular data, which combines an LLM-based code generation with
several AutoML tools. Our approach improves the flexibility and robustness of
pipeline design, outperforming state-of-the-art open-source solutions on
several data science tasks from Kaggle. The code of LightAutoDS-Tab is
available in the open repository https://github.com/sb-ai-lab/LADS

</details>


### [95] [Gauge Flow Models](https://arxiv.org/abs/2507.13414)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: Gauge Flow Models是一种新型生成流模型，通过在学习过程中引入可学习的Gauge Field，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统Flow Models在性能上存在局限，Gauge Flow Models通过引入Gauge Field，旨在提升生成任务的表现。

Method: 在Flow ODE中嵌入可学习的Gauge Field，构建了数学框架，并在高斯混合模型上进行了实验。

Result: 实验表明，Gauge Flow Models在性能上优于传统Flow Models，甚至优于更大规模的模型。

Conclusion: Gauge Flow Models具有潜力在更广泛的生成任务中提升性能，未来研究值得期待。

Abstract: This paper introduces Gauge Flow Models, a novel class of Generative Flow
Models. These models incorporate a learnable Gauge Field within the Flow
Ordinary Differential Equation (ODE). A comprehensive mathematical framework
for these models, detailing their construction and properties, is provided.
Experiments using Flow Matching on Gaussian Mixture Models demonstrate that
Gauge Flow Models yields significantly better performance than traditional Flow
Models of comparable or even larger size. Additionally, unpublished research
indicates a potential for enhanced performance across a broader range of
generative tasks.

</details>


### [96] [Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling](https://arxiv.org/abs/2507.13416)
*Jiaxiang Yi,Bernardo P. Ferreira,Miguel A. Bessa*

Main category: cs.LG

TL;DR: 论文提出了一种层次化的多保真度数据驱动学习方法，能够量化认知不确定性并区分数据噪声（随机不确定性），适用于从简单单保真度神经网络到多保真度贝叶斯循环神经网络的不同学习场景。


<details>
  <summary>Details</summary>
Motivation: 解决多保真度数据驱动学习中的认知不确定性和数据噪声问题，提升模型在复杂场景下的适应性和准确性。

Method: 采用层次化方法，结合多保真度数据和贝叶斯循环神经网络，量化模型误差并发现噪声分布。

Result: 方法能准确预测响应、量化模型误差，并在存在噪声时发现其分布，展示了广泛的适用性。

Conclusion: 该方法为科学和工程领域中的不确定性设计和分析提供了新的可能性。

Abstract: Data-driven learning is generalized to consider history-dependent
multi-fidelity data, while quantifying epistemic uncertainty and disentangling
it from data noise (aleatoric uncertainty). This generalization is hierarchical
and adapts to different learning scenarios: from training the simplest
single-fidelity deterministic neural networks up to the proposed multi-fidelity
variance estimation Bayesian recurrent neural networks. The versatility and
generality of the proposed methodology are demonstrated by applying it to
different data-driven constitutive modeling scenarios that include multiple
fidelities with and without aleatoric uncertainty (noise). The method
accurately predicts the response and quantifies model error while also
discovering the noise distribution (when present). This opens opportunities for
future real-world applications in diverse scientific and engineering domains;
especially, the most challenging cases involving design and analysis under
uncertainty.

</details>


### [97] [Soft-ECM: An extension of Evidential C-Means for complex data](https://arxiv.org/abs/2507.13417)
*Armel Soubeiga,Thomas Guyet,Violaine Antoine*

Main category: cs.LG

TL;DR: 论文提出了一种基于信念函数的聚类算法Soft-ECM，用于处理复杂数据（如混合数据和时间序列），弥补了现有算法无法处理非欧几里得空间数据的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于信念函数的聚类算法无法处理复杂数据（如混合数据或时间序列），因为它们依赖于欧几里得空间的性质。本文旨在解决这一问题。

Method: 提出Soft-ECM算法，仅需半度量即可定位模糊簇的质心，适用于非欧几里得空间数据。

Result: 实验表明，Soft-ECM在数值数据上与模糊聚类方法效果相当，并能有效处理混合数据和时间序列。

Conclusion: Soft-ECM扩展了信念函数聚类的应用范围，适用于复杂数据类型，为模糊聚类与半度量（如DTW）的结合提供了优势。

Abstract: Clustering based on belief functions has been gaining increasing attention in
the machine learning community due to its ability to effectively represent
uncertainty and/or imprecision. However, none of the existing algorithms can be
applied to complex data, such as mixed data (numerical and categorical) or
non-tabular data like time series. Indeed, these types of data are, in general,
not represented in a Euclidean space and the aforementioned algorithms make use
of the properties of such spaces, in particular for the construction of
barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem
for clustering complex data. We propose a new algorithm, Soft-ECM, which
consistently positions the centroids of imprecise clusters requiring only a
semi-metric. Our experiments show that Soft-ECM present results comparable to
conventional fuzzy clustering approaches on numerical data, and we demonstrate
its ability to handle mixed data and its benefits when combining fuzzy
clustering with semi-metrics such as DTW for time series data.

</details>


### [98] [Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity](https://arxiv.org/abs/2507.13423)
*Edward Henderson,Dewi Gould,Richard Everson,George De Ath,Nick Pepper*

Main category: cs.LG

TL;DR: 提出了一种基于图神经网络（GNN）的可解释框架，用于实时评估空管任务需求，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有复杂性指标难以捕捉空域操作中的细微驱动因素，需要更准确的任务需求评估方法。

Method: 使用注意力机制的GNN模型，通过静态交通场景中的交互预测即将发布的指令数量，并通过系统消融飞机计算任务需求分数。

Result: 模型显著优于启发式方法，是更可靠的复杂性评估工具，并能将任务需求归因于特定飞机。

Conclusion: 该框架为控制器培训和空域重新设计提供了新的复杂性分析工具。

Abstract: Real-time assessment of near-term Air Traffic Controller (ATCO) task demand
is a critical challenge in an increasingly crowded airspace, as existing
complexity metrics often fail to capture nuanced operational drivers beyond
simple aircraft counts. This work introduces an interpretable Graph Neural
Network (GNN) framework to address this gap. Our attention-based model predicts
the number of upcoming clearances, the instructions issued to aircraft by
ATCOs, from interactions within static traffic scenarios. Crucially, we derive
an interpretable, per-aircraft task demand score by systematically ablating
aircraft and measuring the impact on the model's predictions. Our framework
significantly outperforms an ATCO-inspired heuristic and is a more reliable
estimator of scenario complexity than established baselines. The resulting tool
can attribute task demand to specific aircraft, offering a new way to analyse
and understand the drivers of complexity for applications in controller
training and airspace redesign.

</details>


### [99] [Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning](https://arxiv.org/abs/2507.13482)
*Seyyed Saeid Cheshmi,Buyao Lyu,Thomas Lisko,Rajesh Rajamani,Robert A. McGovern,Yogatheesan Varatharajah*

Main category: cs.LG

TL;DR: 提出了一种跨模态自监督预训练方法，用于从无标签的IMU-视频数据中学习表示，提高了HAR任务在分布外数据上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有HAR方法依赖特定标签、泛化能力不足的问题，特别是在不同环境或人群中的数据。

Method: 采用跨模态自监督预训练，利用大规模无标签IMU-视频数据学习通用表示。

Result: 在零样本和少样本评估中，该方法优于当前最先进的IMU-视频预训练和仅IMU预训练方法。

Conclusion: 跨模态预训练是学习通用数据表示的有效工具，尤其在动态数据模态（如IMU信号）中。

Abstract: Human Activity Recognition (HAR) based on wearable inertial sensors plays a
critical role in remote health monitoring. In patients with movement disorders,
the ability to detect abnormal patient movements in their home environments can
enable continuous optimization of treatments and help alert caretakers as
needed. Machine learning approaches have been proposed for HAR tasks using
Inertial Measurement Unit (IMU) data; however, most rely on
application-specific labels and lack generalizability to data collected in
different environments or populations. To address this limitation, we propose a
new cross-modal self-supervised pretraining approach to learn representations
from large-sale unlabeled IMU-video data and demonstrate improved
generalizability in HAR tasks on out of distribution (OOD) IMU datasets,
including a dataset collected from patients with Parkinson's disease.
Specifically, our results indicate that the proposed cross-modal pretraining
approach outperforms the current state-of-the-art IMU-video pretraining
approach and IMU-only pretraining under zero-shot and few-shot evaluations.
Broadly, our study provides evidence that in highly dynamic data modalities,
such as IMU signals, cross-modal pretraining may be a useful tool to learn
generalizable data representations. Our software is available at
https://github.com/scheshmi/IMU-Video-OOD-HAR.

</details>


### [100] [Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents](https://arxiv.org/abs/2507.13491)
*Thomas Banker,Ali Mesbah*

Main category: cs.LG

TL;DR: 论文提出基于模型的智能体作为模型无关强化学习的替代方案，以提高样本效率、安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决模型无关强化学习在样本效率、安全性和可解释性方面的局限性。

Method: 利用基于模型的智能体（如模型预测控制）结合系统动力学、成本和约束模型，并通过贝叶斯优化、策略搜索和离线学习等方法进行训练。

Result: 基于模型的智能体能够更安全、高效地学习决策策略，同时提供更好的可解释性。

Conclusion: 结合基于模型和模型无关强化学习的优势，有望实现样本高效、安全且可解释的决策智能体。

Abstract: Training sophisticated agents for optimal decision-making under uncertainty
has been key to the rapid development of modern autonomous systems across
fields. Notably, model-free reinforcement learning (RL) has enabled
decision-making agents to improve their performance directly through system
interactions, with minimal prior knowledge about the system. Yet, model-free RL
has generally relied on agents equipped with deep neural network function
approximators, appealing to the networks' expressivity to capture the agent's
policy and value function for complex systems. However, neural networks amplify
the issues of sample inefficiency, unsafe learning, and limited
interpretability in model-free RL. To this end, this work introduces
model-based agents as a compelling alternative for control policy
approximation, leveraging adaptable models of system dynamics, cost, and
constraints for safe policy learning. These models can encode prior system
knowledge to inform, constrain, and aid in explaining the agent's decisions,
while deficiencies due to model mismatch can be remedied with model-free RL. We
outline the benefits and challenges of learning model-based agents --
exemplified by model predictive control -- and detail the primary learning
approaches: Bayesian optimization, policy search RL, and offline strategies,
along with their respective strengths. While model-free RL has long been
established, its interplay with model-based agents remains largely unexplored,
motivating our perspective on their combined potentials for sample-efficient
learning of safe and interpretable decision-making agents.

</details>


### [101] [Fake or Real: The Impostor Hunt in Texts for Space Operations](https://arxiv.org/abs/2507.13508)
*Agata Kaczmarek,Dawid Płudowski,Piotr Wilczyński,Przemysław Biecek,Krzysztof Kotowski,Ramez Shendy,Jakub Nalepa,Artur Janicki,Evridiki Ntagiou*

Main category: cs.LG

TL;DR: Kaggle竞赛“Fake or Real”旨在解决AI安全威胁，任务为区分正常LLM输出与恶意修改后的输出。


<details>
  <summary>Details</summary>
Motivation: 基于欧洲航天局资助的项目，识别了数据毒化和对大型语言模型的过度依赖两大威胁。

Method: 参与者需开发新技术或调整现有方法来解决这一问题。

Result: 竞赛推动了针对LLM恶意修改的新研究。

Conclusion: 该竞赛填补了LLM安全领域的研究空白，促进了相关技术的发展。

Abstract: The "Fake or Real" competition hosted on Kaggle
(\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})
is the second part of a series of follow-up competitions and hackathons related
to the "Assurance for Space Domain AI Applications" project funded by the
European Space Agency
(\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).
The competition idea is based on two real-life AI security threats identified
within the project -- data poisoning and overreliance in Large Language Models.
The task is to distinguish between the proper output from LLM and the output
generated under malicious modification of the LLM. As this problem was not
extensively researched, participants are required to develop new techniques to
address this issue or adjust already existing ones to this problem's statement.

</details>


### [102] [Provable Low-Frequency Bias of In-Context Learning of Representations](https://arxiv.org/abs/2507.13540)
*Yongyi Yang,Hidenori Tanaka,Wei Hu*

Main category: cs.LG

TL;DR: 论文提出了一个双收敛框架，解释了大型语言模型（LLMs）如何通过上下文学习（ICL）从输入序列中学习新行为，而无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 研究ICL如何通过内部化提示的数据生成过程（DGP）结构来超越预训练阶段的学习效果，并揭示其机制。

Method: 引入双收敛的统一框架，分析隐藏表示在上下文和层间的收敛过程，证明其偏向平滑（低频）表示的隐式偏差。

Result: 理论解释了ICL的几何结构特征、能量衰减现象，并预测其对高频噪声的鲁棒性，实验验证了这些结论。

Conclusion: 研究为ICL的机制提供了新见解，并为更广泛的数据分布和设置下的研究奠定了理论基础。

Abstract: In-context learning (ICL) enables large language models (LLMs) to acquire new
behaviors from the input sequence alone without any parameter updates. Recent
studies have shown that ICL can surpass the original meaning learned in
pretraining stage through internalizing the structure the data-generating
process (DGP) of the prompt into the hidden representations. However, the
mechanisms by which LLMs achieve this ability is left open. In this paper, we
present the first rigorous explanation of such phenomena by introducing a
unified framework of double convergence, where hidden representations converge
both over context and across layers. This double convergence process leads to
an implicit bias towards smooth (low-frequency) representations, which we prove
analytically and verify empirically. Our theory explains several open empirical
observations, including why learned representations exhibit globally structured
but locally distorted geometry, and why their total energy decays without
vanishing. Moreover, our theory predicts that ICL has an intrinsic robustness
towards high-frequency noise, which we empirically confirm. These results
provide new insights into the underlying mechanisms of ICL, and a theoretical
foundation to study it that hopefully extends to more general data
distributions and settings.

</details>


### [103] [Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography](https://arxiv.org/abs/2507.13542)
*Beka Begiashvili,Carlos J. Fernandez-Candel,Matías Pérez Paredes*

Main category: cs.LG

TL;DR: 提出了一种名为Acoustic Index的新型AI衍生超声心动图参数，用于量化心脏功能障碍，结合了Koopman算子理论和混合神经网络，在736名患者中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统超声心动图参数如EF和GLS在早期检测心脏功能障碍方面存在局限性，需要一种可重复、可解释且操作者独立的参数。

Method: 结合扩展动态模式分解（EDMD）和混合神经网络，从超声心动图序列中提取时空动态，并通过注意力机制和流形学习融合临床数据。

Result: 在独立测试集中，Acoustic Index的AUC为0.89，交叉验证显示敏感性和特异性均超过0.8。

Conclusion: Acoustic Index是一种物理信息驱动的可解释AI生物标志物，有望成为早期检测和监测的可扩展工具。

Abstract: Traditional echocardiographic parameters such as ejection fraction (EF) and
global longitudinal strain (GLS) have limitations in the early detection of
cardiac dysfunction. EF often remains normal despite underlying pathology, and
GLS is influenced by load conditions and vendor variability. There is a growing
need for reproducible, interpretable, and operator-independent parameters that
capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic
parameter designed to quantify cardiac dysfunction from standard ultrasound
views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on
Koopman operator theory with a hybrid neural network that incorporates clinical
metadata. Spatiotemporal dynamics are extracted from echocardiographic
sequences to identify coherent motion patterns. These are weighted via
attention mechanisms and fused with clinical data using manifold learning,
resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac
pathologies and normal controls, the Acoustic Index achieved an area under the
curve (AUC) of 0.89 in an independent test set. Cross-validation across five
folds confirmed the robustness of the model, showing that both sensitivity and
specificity exceeded 0.8 when evaluated on independent data. Threshold-based
analysis demonstrated stable trade-offs between sensitivity and specificity,
with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker
for cardiac function. It shows promise as a scalable, vendor-independent tool
for early detection, triage, and longitudinal monitoring. Future directions
include external validation, longitudinal studies, and adaptation to
disease-specific classifiers.

</details>


### [104] [Time Series Forecastability Measures](https://arxiv.org/abs/2507.13556)
*Rui Wang,Steven Klee,Alexis Roos*

Main category: cs.LG

TL;DR: 论文提出两种指标（频谱可预测性评分和最大李雅普诺夫指数）来量化时间序列的可预测性，帮助在模型开发前评估数据的固有特性。


<details>
  <summary>Details</summary>
Motivation: 传统模型评估指标仅在模型开发后使用，无法提前评估数据的可预测性。本文旨在提供一种方法，在模型开发前量化时间序列的固有可预测性。

Method: 使用频谱可预测性评分评估时间序列的频率成分强度和规律性，李雅普诺夫指数量化数据生成系统的混沌和稳定性。在合成和真实世界数据（M5预测竞赛数据集）上验证。

Result: 两种指标能准确反映时间序列的固有可预测性，并与多种模型的实际预测性能强相关。

Conclusion: 通过提前评估时间序列的可预测性，实践者可以更高效地规划资源，对可预测性低的产品采取替代策略。

Abstract: This paper proposes using two metrics to quantify the forecastability of time
series prior to model development: the spectral predictability score and the
largest Lyapunov exponent. Unlike traditional model evaluation metrics, these
measures assess the inherent forecastability characteristics of the data before
any forecast attempts. The spectral predictability score evaluates the strength
and regularity of frequency components in the time series, whereas the Lyapunov
exponents quantify the chaos and stability of the system generating the data.
We evaluated the effectiveness of these metrics on both synthetic and
real-world time series from the M5 forecast competition dataset. Our results
demonstrate that these two metrics can correctly reflect the inherent
forecastability of a time series and have a strong correlation with the actual
forecast performance of various models. By understanding the inherent
forecastability of time series before model training, practitioners can focus
their planning efforts on products and supply chain levels that are more
forecastable, while setting appropriate expectations or seeking alternative
strategies for products with limited forecastability.

</details>


### [105] [Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)
*Mrinal Mathur,Mike Doan,Barak Pearlmutter,Sergey Plis*

Main category: cs.LG

TL;DR: SELF-Transformer通过迭代更新注意力权重提升编码器Transformer的表达能力，无需依赖自回归，在测试时根据输入难度自适应调整计算量，实现20%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在固定深度下表达能力受限，而自回归方法依赖外部化中间状态。SELF-Transformer旨在通过内部迭代提升表达能力，同时保持编码器架构的简洁性。

Method: 引入SELF-Transformer，一种通过迭代更新注意力权重至固定点的编码器层，避免依赖自回归，测试时根据输入难度自适应调整计算量。

Result: 在编码器基准测试中实现高达20%的准确率提升，且不增加参数量。

Conclusion: SELF-Transformer通过内部迭代恢复表达能力，同时保持编码器架构的简洁性，为自适应对齐提供了高效解决方案。

Abstract: Transformers evaluated in a single, fixed-depth pass are provably limited in
expressive power to the constant-depth circuit class TC0. Running a Transformer
autoregressively removes that ceiling -- first in next-token prediction and,
more recently, in chain-of-thought reasoning. Both regimes rely on feedback
loops that decode internal states into tokens only to re-encode them in
subsequent steps. While this "thinking aloud" mirrors human reasoning,
biological brains iterate without externalising intermediate states as
language. To boost the expressive power of encoder Transformers without
resorting to token-level autoregression, we introduce the SELF-Transformer: an
encoder layer that iteratively refines its own attention weights to a fixed
point. Instead of producing -- in one pass -- the alignment matrix that remixes
the input sequence, the SELF-Transformer iteratively updates that matrix
internally, scaling test-time computation with input difficulty. This
adaptivity yields up to 20\% accuracy gains on encoder-style benchmarks without
increasing parameter count, demonstrating that input-adaptive alignment at test
time offers substantial benefits for only a modest extra compute budget.
Self-Transformers thus recover much of the expressive power of iterative
reasoning while preserving the simplicity of pure encoder architectures.

</details>


### [106] [Apple Intelligence Foundation Language Models: Tech Report 2025](https://arxiv.org/abs/2507.13575)
*Hanzhi Zhou,Erik Hornberger,Pengsheng Guo,Xiyou Zhou,Saiwen Wang,Xin Wang,Yifei He,Xuankai Chang,Rene Rauch,Louis D'hauwe,John Peebles,Alec Doane,Kohen Chia,Jenna Thibodeau,Zi-Yi Dou,Yuanyang Zhang,Ruoming Pang,Reed Li,Zhifeng Chen,Jeremy Warner,Zhaoyang Xu,Sophy Lee,David Mizrahi,Ramsey Tantawi,Chris Chaney,Kelsey Peterson,Jun Qin,Alex Dombrowski,Mira Chiang,Aiswarya Raghavan,Gerard Casamayor,Qibin Chen,Aonan Zhang,Nathalie Tran,Jianyu Wang,Hang Su,Thomas Voice,Alessandro Pappalardo,Brycen Wershing,Prasanth Yadla,Rui Li,Priyal Chhatrapati,Ismael Fernandez,Yusuf Goren,Xin Zheng,Forrest Huang,Tao Lei,Eray Yildiz,Alper Kokmen,Gokul Santhanam,Areeba Kamal,Kaan Elgin,Dian Ang Yap,Jeremy Liu,Peter Gray,Howard Xing,Kieran Liu,Matteo Ronchi,Moritz Schwarzer-Becker,Yun Zhu,Mandana Saebi,Jeremy Snow,David Griffiths,Guillaume Tartavel,Erin Feldman,Simon Lehnerer,Fernando Bermúdez-Medina,Hans Han,Joe Zhou,Xiaoyi Ren,Sujeeth Reddy,Zirui Wang,Tom Gunter,Albert Antony,Yuanzhi Li,John Dennison,Tony Sun,Yena Han,Yi Qin,Sam Davarnia,Jeffrey Bigham,Wayne Shan,Hannah Gillis Coleman,Guillaume Klein,Peng Liu,Muyang Yu,Jack Cackler,Yuan Gao,Crystal Xiao,Binazir Karimzadeh,Zhengdong Zhang,Felix Bai,Albin Madappally Jose,Feng Nan,Nazir Kamaldin,Dong Yin,Hans Hao,Yanchao Sun,Yi Hua,Charles Maalouf,Alex Guillen Garcia,Guoli Yin,Lezhi Li,Mohana Prasad Sathya Moorthy,Hongbin Gao,Jay Tang,Joanna Arreaza-Taylor,Faye Lao,Carina Peng,Josh Shaffer,Dan Masi,Sushma Rao,Tommi Vehvilainen,Senyu Tong,Dongcai Shen,Yang Zhao,Chris Bartels,Peter Fu,Qingqing Cao,Christopher Neubauer,Ethan Li,Mingfei Gao,Rebecca Callahan,Richard Wei,Patrick Dong,Alex Braunstein,Sachin Ravi,Adolfo Lopez Mendez,Kaiwei Huang,Kun Duan,Haoshuo Huang,Rui Qian,Stefano Ligas,Jordan Huffaker,Dongxu Li,Bailin Wang,Nanzhu Wang,Anuva Agarwal,Tait Madsen,Josh Newnham,Abhishek Sharma,Zhile Ren,Deepak Gopinath,Erik Daxberger,Saptarshi Guha,Oron Levy,Jing Lu,Nan Dun,Marc Kirchner,Yinfei Yang,Manjot Bilkhu,Dave Nelson,Anthony Spalvieri-Kruse,Juan Lao Tebar,Yang Xu,Phani Mutyala,Gabriel Jacoby-Cooper,Yingbo Wang,Karla Vega,Vishaal Mahtani,Darren Botten,Eric Wang,Hanli Li,Matthias Paulik,Haoran Yan,Navid Shiee,Yihao Qian,Bugu Wu,Qi Zhu,Ob Adaranijo,Bhuwan Dhingra,Zhe Gan,Nicholas Seidl,Grace Duanmu,Rong Situ,Yiping Ma,Yin Xia,David Riazati,Vasileios Saveris,Anh Nguyen,Michael,Lee,Patrick Sonnenberg,Chinguun Erdenebileg,Yanghao Li,Vivian Ma,James Chou,Isha Garg,Mark Lee,Keen You,Yuhong Li,Ransen Niu,Nandhitha Raghuram,Pulkit Agrawal,Henry Mason,Sumeet Singh,Keyu He,Hong-You Chen,Lucas Guibert,Shiyu Li,Varsha Paidi,Narendran Raghavan,Mingze Xu,Yuli Yang,Sergiu Sima,Irina Belousova,Sprite Chu,Afshin Dehghan,Philipp Dufter,David Haldimann,Zhen Yang,Margit Bowler,Chang Liu,Ying-Chang Cheng,Vivek Rathod,Syd Evans,Wilson Tsao,Dustin Withers,Haitian Sun,Biyao Wang,Peter Grasch,Walker Cheng,Yihao Feng,Vivek Kumar,Frank Chu,Victoria MönchJuan Haladjian,Doug Kang,Jiarui Lu,Ciro Sannino,Max Lam,Floris Weers,Bowen Pan,Kenneth Jung,Dhaval Doshi,Fangping Shi,Olli Saarikivi,Alp Aygar,Josh Elman,Cheng Leong,Eshan Verma,Matthew Lei,Jeff Nichols,Jiulong Shan,Donald Zhang,Lawrence Zhou,Stephen Murphy,Xianzhi Du,Chang Lan,Ankur Jain,Elmira Amirloo,Marcin Eichner,Naomy Sabo,Anupama Mann Anupama,David Qiu,Zhao Meng,Michael FitzMaurice,Peng Zhang,Simon Yeung,Chen Chen,Marco Zuliani,Andrew Hansen,Yang Lu,Brent Ramerth,Ziyi Zhong,Parsa Mazaheri,Matthew Hopkins,Mengyu Li,Simon Wang,David Chen,Farzin Rasteh,Chong Wang,Josh Gardner,Asaf Liberman,Haoxuan You,Andrew Walkingshaw,Xingyu Zhou,Jinhao Lei,Yan Meng,Quentin Keunebroek,Sam Wiseman,Anders Boesen Lindbo Larsen,Yi Zhang,Zaid Ahmed,Haiming Gang,Aaron Franklin,Kelvin Zou,Guillaume Seguin,Jonathan Janke,Rachel Burger,Co Giang,Cheng Shen,Jen Liu,Sanskruti Shah,Xiang Kong,Yiran Fei,TJ Collins,Chen Zhang,Zhiyun Lu,Michael Booker,Qin Ba,Yasutaka Tanaka,Andres Romero Mier Y Teran,Federico Scozzafava,Regan Poston,Jane Li,Eduardo Jimenez,Bas Straathof,Karanjeet Singh,Lindsay Hislop,Rajat Arora,Deepa Seshadri,Boyue Li,Colorado Reed,Zhen Li,TJ Lu,Yi Wang,Kaelen Haag,Nicholas Lusskin,Raunak Sinha,Rahul Nair,Eldon Schoop,Mary Beth Kery,Mehrdad Farajtbar,Brenda Yang,George Horrell,Shiwen Zhao,Dhruti Shah,Cha Chen,Bowen Zhang,Chang Gao,Devi Krishna,Jennifer Mallalieu,Javier Movellan,Di Feng,Emily Zhang,Sam Xu,Junting Pan,Dominik Moritz,Suma Jayaram,Kevin Smith,Dongseong Hwang,Daniel Parilla,Jiaming Hu,You-Cyuan Jhang,Emad Soroush,Fred Hohman,Nan Du,Emma Wang,Sam Dodge,Pragnya Sridhar,Joris Pelemans,Wei Fang,Nina Wenzel,Joseph Yitan Cheng,Hadas Kotek,Chung-Cheng Chiu,Meng Cao,Haijing Fu,Ruixuan Hou,Ke Ye,Diane Zhu,Nikhil Bhendawade,Joseph Astrauskas,Jian Liu,Sai Aitharaju,Wentao Wu,Artsiom Peshko,Hyunjik Kim,Nilesh Shahdadpuri,Andy De Wang,Qi Shan,Piotr Maj,Raul Rea Menacho,Justin Lazarow,Eric Liang Yang,Arsalan Farooq,Donghan Yu,David Güera,Minsik Cho,Kavya Nerella,Yongqiang Wang,Tao Jia,John Park,Jeff Lai,Haotian Zhang,Futang Peng,Daniele Molinari,Aparna Rajamani,Tyler Johnson,Lauren Gardiner,Chao Jia,Violet Yao,Wojciech Kryscinski,Xiujun Li,Shang-Chen Wu*

Main category: cs.LG

TL;DR: Apple推出两款多语言、多模态基础语言模型，分别用于设备端和服务器端，支持多语言和图像理解，性能优于同类开源模型。


<details>
  <summary>Details</summary>
Motivation: 为Apple设备和服务提供智能功能，同时注重隐私保护和负责任AI。

Method: 设备端模型采用KV缓存共享和2位量化训练；服务器模型采用并行轨道混合专家（PT-MoE）架构。训练数据来自网络爬取、授权语料和合成数据，并通过监督微调和强化学习优化。

Result: 模型在多语言和图像理解任务中表现优异，超越同类开源基准。

Conclusion: Apple通过技术创新和负责任AI策略，实现了高性能且隐私保护的智能模型。

Abstract: We introduce two multilingual, multimodal foundation language models that
power Apple Intelligence features across Apple devices and services: i a
3B-parameter on-device model optimized for Apple silicon through architectural
innovations such as KV-cache sharing and 2-bit quantization-aware training; and
ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts
PT-MoE transformer that combines track parallelism, mixture-of-experts sparse
computation, and interleaved global-local attention to deliver high quality
with competitive cost on Apple's Private Cloud Compute platform. Both models
are trained on large-scale multilingual and multimodal datasets sourced via
responsible web crawling, licensed corpora, and high-quality synthetic data,
then further refined with supervised fine-tuning and reinforcement learning on
a new asynchronous platform. The resulting models support several additional
languages while understanding images and executing tool calls. In public
benchmarks and human evaluations, both the server model and the on-device model
match or surpass comparably sized open baselines.
  A new Swift-centric Foundation Models framework exposes guided generation,
constrained tool calling, and LoRA adapter fine-tuning, allowing developers to
integrate these capabilities with a few lines of code. The latest advancements
in Apple Intelligence models are grounded in our Responsible AI approach with
safeguards like content filtering and locale-specific evaluation, as well as
our commitment to protecting our users' privacy with innovations like Private
Cloud Compute.

</details>


### [107] [Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries](https://arxiv.org/abs/2507.13579)
*Hyunji Nam,Yanming Wan,Mickel Liu,Jianxun Lian,Natasha Jaques*

Main category: cs.LG

TL;DR: PLUS框架通过生成用户偏好摘要，实现个性化奖励模型，提升LLM对不同用户的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法未考虑用户多样性，PLUS旨在通过用户摘要实现个性化响应。

Method: PLUS利用强化学习训练用户摘要模型，并动态更新奖励模型，形成在线协同适应循环。

Result: PLUS生成的摘要能有效捕捉用户偏好，适应新用户和多样话题，并可零样本迁移至GPT-4等模型。

Conclusion: PLUS提供透明、可解释的用户摘要，增强LLM对齐的用户控制与个性化能力。

Abstract: As everyday use cases of large language model (LLM) AI assistants have
expanded, it is becoming increasingly important to personalize responses to
align to different users' preferences and goals. While reinforcement learning
from human feedback (RLHF) is effective at improving LLMs to be generally more
helpful and fluent, it does not account for variability across users, as it
models the entire user population with a single reward model. We present a
novel framework, Preference Learning Using Summarization (PLUS), that learns
text-based summaries of each user's preferences, characteristics, and past
conversations. These summaries condition the reward model, enabling it to make
personalized predictions about the types of responses valued by each user. We
train the user-summarization model with reinforcement learning, and update the
reward model simultaneously, creating an online co-adaptation loop. We show
that in contrast with prior personalized RLHF techniques or with in-context
learning of user information, summaries produced by PLUS capture meaningful
aspects of a user's preferences. Across different pluralistic user datasets, we
show that our method is robust to new users and diverse conversation topics.
Additionally, we demonstrate that the textual summaries generated about users
can be transferred for zero-shot personalization of stronger, proprietary
models like GPT-4. The resulting user summaries are not only concise and
portable, they are easy for users to interpret and modify, allowing for more
transparency and user control in LLM alignment.

</details>


### [108] [Off-Policy Evaluation and Learning for Matching Markets](https://arxiv.org/abs/2507.13608)
*Yudai Hayashi,Shuhei Goda,Yuta Saito*

Main category: cs.LG

TL;DR: 论文提出了针对匹配市场的离线策略评估（OPE）方法DiPS和DPR，通过结合直接法、逆倾向得分和双重稳健估计器，并利用中间标签优化偏差-方差控制，实验证明其在真实平台数据上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 匹配市场中的双向用户互动和大规模特性导致传统OPE方法不可靠，需要新的评估方法以支持频繁政策更新。

Method: 提出DiPS和DPR估计器，结合DM、IPS和DR方法，并利用中间标签优化偏差-方差控制。

Result: 理论分析和实验表明，新方法在偏差-方差控制和匹配效果上优于传统方法，适用于真实平台数据。

Conclusion: DiPS和DPR为匹配市场的离线策略评估和学习提供了高效可靠的解决方案。

Abstract: Matching users based on mutual preferences is a fundamental aspect of
services driven by reciprocal recommendations, such as job search and dating
applications. Although A/B tests remain the gold standard for evaluating new
policies in recommender systems for matching markets, it is costly and
impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays
a crucial role by enabling the evaluation of recommendation policies using only
offline logged data naturally collected on the platform. However, unlike
conventional recommendation settings, the large scale and bidirectional nature
of user interactions in matching platforms introduce variance issues and
exacerbate reward sparsity, making standard OPE methods unreliable. To address
these challenges and facilitate effective offline evaluation, we propose novel
OPE estimators, \textit{DiPS} and \textit{DPR}, specifically designed for
matching markets. Our methods combine elements of the Direct Method (DM),
Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while
incorporating intermediate labels, such as initial engagement signals, to
achieve better bias-variance control in matching markets. Theoretically, we
derive the bias and variance of the proposed estimators and demonstrate their
advantages over conventional methods. Furthermore, we show that these
estimators can be seamlessly extended to offline policy learning methods for
improving recommendation policies for making more matches. We empirically
evaluate our methods through experiments on both synthetic data and A/B testing
logs from a real job-matching platform. The empirical results highlight the
superiority of our approach over existing methods in off-policy evaluation and
learning tasks for a variety of configurations.

</details>


### [109] [Tri-Learn Graph Fusion Network for Attributed Graph Clustering](https://arxiv.org/abs/2507.13620)
*Binxiong Li,Yuefei Wang,Xu Xiang,Xue Li,Binyu Zhao,Heyang Gao,Qinyu Zhao,Xi Yu*

Main category: cs.LG

TL;DR: 论文提出了一种结合GCN、AE和Graph Transformer的Tri-GFN框架，通过三重学习机制和特征融合策略提升图聚类性能，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有GCN模型在处理大规模复杂图数据时存在过平滑和过压缩问题，Graph Transformer虽有所改进，但在异构图数据上性能有限。

Method: 提出Tri-GFN框架，整合GCN、AE和Graph Transformer，通过三重学习机制和特征融合增强策略优化全局与局部信息的区分性和一致性。

Result: 在ACM、Reuters和USPS数据集上分别提升0.87%、14.14%和7.58%的准确率，尤其在Reuters数据集上表现突出。

Conclusion: Tri-GFN框架显著提升了图聚类性能，适用于新闻分类和主题检索等领域。

Abstract: In recent years, models based on Graph Convolutional Networks (GCN) have made
significant strides in the field of graph data analysis. However, challenges
such as over-smoothing and over-compression remain when handling large-scale
and complex graph datasets, leading to a decline in clustering quality.
Although the Graph Transformer architecture has mitigated some of these issues,
its performance is still limited when processing heterogeneous graph data. To
address these challenges, this study proposes a novel deep clustering framework
that comprising GCN, Autoencoder (AE), and Graph Transformer, termed the
Tri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the
differentiation and consistency of global and local information through a
unique tri-learning mechanism and feature fusion enhancement strategy. The
framework integrates GCN, AE, and Graph Transformer modules. These components
are meticulously fused by a triple-channel enhancement module, which maximizes
the use of both node attributes and topological structures, ensuring robust
clustering representation. The tri-learning mechanism allows mutual learning
among these modules, while the feature fusion strategy enables the model to
capture complex relationships, yielding highly discriminative representations
for graph clustering. It surpasses many state-of-the-art methods, achieving an
accuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the
Reuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding
performance on the Reuters dataset, Tri-GFN can be applied to automatic news
classification, topic retrieval, and related fields.

</details>


### [110] [FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning](https://arxiv.org/abs/2507.13624)
*Daniel Commey,Kamel Abbad,Garth V. Crosby,Lyes Khoukhi*

Main category: cs.LG

TL;DR: FedSkipTwin通过轻量级服务器端数字孪生预测客户端梯度更新，动态跳过通信轮次，减少带宽消耗并提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中通信开销是主要瓶颈，尤其在移动和物联网设备带宽受限的场景下。

Method: 使用LSTM实现的数字孪生预测客户端梯度更新的幅度和不确定性，动态决定是否跳过通信轮次。

Result: 在非独立同分布数据下，FedSkipTwin减少12-15.5%通信量，同时模型精度提升0.5个百分点。

Conclusion: 预测引导的跳过策略是带宽受限边缘环境中资源感知联邦学习的实用有效方法。

Abstract: Communication overhead remains a primary bottleneck in federated learning
(FL), particularly for applications involving mobile and IoT devices with
constrained bandwidth. This work introduces FedSkipTwin, a novel
client-skipping algorithm driven by lightweight, server-side digital twins.
Each twin, implemented as a simple LSTM, observes a client's historical
sequence of gradient norms to forecast both the magnitude and the epistemic
uncertainty of its next update. The server leverages these predictions,
requesting communication only when either value exceeds a predefined threshold;
otherwise, it instructs the client to skip the round, thereby saving bandwidth.
Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients
under a non-IID data distribution. The results demonstrate that FedSkipTwin
reduces total communication by 12-15.5% across 20 rounds while simultaneously
improving final model accuracy by up to 0.5 percentage points compared to the
standard FedAvg algorithm. These findings establish that prediction-guided
skipping is a practical and effective strategy for resource-aware FL in
bandwidth-constrained edge environments.

</details>


### [111] [Byzantine-resilient federated online learning for Gaussian process regression](https://arxiv.org/abs/2507.14021)
*Xu Zhang,Zhenyuan Yuan,Minghui Zhu*

Main category: cs.LG

TL;DR: 提出了一种拜占庭容错的联邦高斯过程回归算法，用于在部分代理存在恶意行为时提升学习性能。


<details>
  <summary>Details</summary>
Motivation: 研究在联邦学习环境中，如何在高斯过程回归任务中应对拜占庭代理的恶意行为，提升学习性能。

Method: 开发了一种拜占庭容错的联邦GPR算法，通过代理本地GPR和云端聚合GPR的协作，结合拜占庭容错的产品专家聚合规则。

Result: 实验表明，代理融合GPR的学习精度优于本地GPR，算法在玩具示例和真实数据集上表现良好。

Conclusion: 该算法有效提升了拜占庭代理存在时的学习性能，适用于联邦学习环境。

Abstract: In this paper, we study Byzantine-resilient federated online learning for
Gaussian process regression (GPR). We develop a Byzantine-resilient federated
GPR algorithm that allows a cloud and a group of agents to collaboratively
learn a latent function and improve the learning performances where some agents
exhibit Byzantine failures, i.e., arbitrary and potentially adversarial
behavior. Each agent-based local GPR sends potentially compromised local
predictions to the cloud, and the cloud-based aggregated GPR computes a global
model by a Byzantine-resilient product of experts aggregation rule. Then the
cloud broadcasts the current global model to all the agents. Agent-based fused
GPR refines local predictions by fusing the received global model with that of
the agent-based local GPR. Moreover, we quantify the learning accuracy
improvements of the agent-based fused GPR over the agent-based local GPR.
Experiments on a toy example and two medium-scale real-world datasets are
conducted to demonstrate the performances of the proposed algorithm.

</details>


### [112] [A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design](https://arxiv.org/abs/2507.13646)
*Nimisha Ghosh,Daniele Santoni,Debaleena Nawn,Eleonora Ottaviani,Giovanni Felici*

Main category: cs.LG

TL;DR: 本文综述了基于Transformer的语言模型在蛋白质序列分析与设计中的最新进展，包括基因本体、功能与结构蛋白识别、新蛋白质生成及蛋白质结合等应用，并探讨了现有研究的优缺点及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在自然语言处理中的成功推动了其在生物信息学等领域的应用，本文旨在总结其在蛋白质序列分析与设计中的研究现状。

Method: 通过综述大量相关文献，分析了Transformer模型在蛋白质研究中的应用，并评估了其优缺点。

Result: 总结了Transformer模型在蛋白质序列分析中的多种应用，指出了现有研究的局限性。

Conclusion: 本文为研究者提供了该领域的现状概览，并提出了未来研究的潜在方向。

Abstract: The impact of Transformer-based language models has been unprecedented in
Natural Language Processing (NLP). The success of such models has also led to
their adoption in other fields including bioinformatics. Taking this into
account, this paper discusses recent advances in Transformer-based models for
protein sequence analysis and design. In this review, we have discussed and
analysed a significant number of works pertaining to such applications. These
applications encompass gene ontology, functional and structural protein
identification, generation of de novo proteins and binding of proteins. We
attempt to shed light on the strength and weaknesses of the discussed works to
provide a comprehensive insight to readers. Finally, we highlight shortcomings
in existing research and explore potential avenues for future developments. We
believe that this review will help researchers working in this field to have an
overall idea of the state of the art in this field, and to orient their future
studies.

</details>


### [113] [Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction](https://arxiv.org/abs/2507.13685)
*Yue Yang,Zihan Su,Ying Zhang,Chang Chuan Goh,Yuxiang Lin,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 论文提出GRU-KAN和LSTM-KAN模型，用于提前预测贷款违约，显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有贷款违约预测模型在早期预测中的准确性和时间依赖性不足的问题。

Method: 结合Kolmogorov-Arnold Networks (KAN)与GRU和LSTM网络，提出GRU-KAN和LSTM-KAN模型。

Result: 新模型在提前3个月和8个月的预测中分别达到92%和88%的准确率，显著优于基线模型。

Conclusion: GRU-KAN和LSTM-KAN模型能有效提升贷款违约的早期预测能力，具有实际应用价值。

Abstract: This study addresses a critical challenge in time series anomaly detection:
enhancing the predictive capability of loan default models more than three
months in advance to enable early identification of default events, helping
financial institutions implement preventive measures before risk events
materialize. Existing methods have significant drawbacks, such as their lack of
accuracy in early predictions and their dependence on training and testing
within the same year and specific time frames. These issues limit their
practical use, particularly with out-of-time data. To address these, the study
introduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge
Kolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long
Short-Term Memory (LSTM) networks. The proposed models were evaluated against
the baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms
of accuracy, precision, recall, F1 and AUC in different lengths of feature
window, sample sizes, and early prediction intervals. The results demonstrate
that the proposed model achieves a prediction accuracy of over 92% three months
in advance and over 88% eight months in advance, significantly outperforming
existing baselines.

</details>


### [114] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
*Martin Krutský,Gustav Šír,Vyacheslav Kungurtsev,Georgios Korpas*

Main category: cs.LG

TL;DR: PI-GNNs在组合优化问题中表现良好，但随着问题图密度增加，性能显著下降。研究发现训练动态中存在相变，并提出基于模糊逻辑和二值化神经网络的改进方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 研究PI-GNNs在组合优化问题中的性能表现，尤其是随着问题图密度增加时的性能下降现象。

Method: 通过分析PI-GNNs的训练动态，发现相变现象，并提出基于模糊逻辑和二值化神经网络的改进策略。

Result: 改进后的方法显著提升了PI-GNNs在高密度问题中的性能。

Conclusion: PI-GNNs在高密度组合优化问题中存在性能瓶颈，但通过提出的改进方法可以有效解决。

Abstract: Physics-inspired graph neural networks (PI-GNNs) have been utilized as an
efficient unsupervised framework for relaxing combinatorial optimization
problems encoded through a specific graph structure and loss, reflecting
dependencies between the problem's variables. While the framework has yielded
promising results in various combinatorial problems, we show that the
performance of PI-GNNs systematically plummets with an increasing density of
the combinatorial problem graphs. Our analysis reveals an interesting phase
transition in the PI-GNNs' training dynamics, associated with degenerate
solutions for the denser problems, highlighting a discrepancy between the
relaxed, real-valued model outputs and the binary-valued problem solutions. To
address the discrepancy, we propose principled alternatives to the naive
strategy used in PI-GNNs by building on insights from fuzzy logic and binarized
neural networks. Our experiments demonstrate that the portfolio of proposed
methods significantly improves the performance of PI-GNNs in increasingly dense
settings.

</details>


### [115] [Bayesian Optimization for Molecules Should Be Pareto-Aware](https://arxiv.org/abs/2507.13704)
*Anabel Yong,Austin Tripp,Layla Hosseini-Gerami,Brooks Paige*

Main category: cs.LG

TL;DR: 多目标贝叶斯优化（MOBO）在分子设计中优于标量化方法，尤其在低数据量和非平凡权衡情况下。


<details>
  <summary>Details</summary>
Motivation: 探索MOBO在分子设计中的实际优势，尤其是与标量化方法相比。

Method: 使用基于帕累托的MOBO策略（EHVI）与固定权重的标量化方法（EI）进行对比实验。

Result: EHVI在帕累托前沿覆盖、收敛速度和化学多样性上均优于EI。

Conclusion: Pareto感知的获取策略在分子优化中具有实际优势，特别是在预算有限和非平凡权衡时。

Abstract: Multi-objective Bayesian optimization (MOBO) provides a principled framework
for navigating trade-offs in molecular design. However, its empirical
advantages over scalarized alternatives remain underexplored. We benchmark a
simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --
against a simple fixed-weight scalarized baseline using Expected Improvement
(EI), under a tightly controlled setup with identical Gaussian Process
surrogates and molecular representations. Across three molecular optimization
tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front
coverage, convergence speed, and chemical diversity. While scalarization
encompasses flexible variants -- including random or adaptive schemes -- our
results show that even strong deterministic instantiations can underperform in
low-data regimes. These findings offer concrete evidence for the practical
advantages of Pareto-aware acquisition in de novo molecular optimization,
especially when evaluation budgets are limited and trade-offs are nontrivial.

</details>


### [116] [Learning Deformable Body Interactions With Adaptive Spatial Tokenization](https://arxiv.org/abs/2507.13707)
*Hao Wang,Yu Liu,Daniel Biggs,Haoru Wang,Jiandong Yu,Ping Huang*

Main category: cs.LG

TL;DR: 提出了一种自适应空间标记化（AST）方法，通过网格划分和注意力机制高效模拟可变形体交互，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决基于图神经网络（GNN）的方法在模拟大规模可变形体交互时的计算效率问题。

Method: 将模拟空间划分为网格单元，通过交叉注意力模块将稀疏单元映射为固定长度的嵌入标记，利用自注意力模块预测下一状态。

Result: 在超过100,000节点的大规模模拟中表现优异，显著优于现有方法。

Conclusion: AST方法通过结合标记化效率和注意力机制的表达能力，实现了高效且可扩展的可变形体交互模拟。

Abstract: Simulating interactions between deformable bodies is vital in fields like
material science, mechanical design, and robotics. While learning-based methods
with Graph Neural Networks (GNNs) are effective at solving complex physical
systems, they encounter scalability issues when modeling deformable body
interactions. To model interactions between objects, pairwise global edges have
to be created dynamically, which is computationally intensive and impractical
for large-scale meshes. To overcome these challenges, drawing on insights from
geometric representations, we propose an Adaptive Spatial Tokenization (AST)
method for efficient representation of physical states. By dividing the
simulation space into a grid of cells and mapping unstructured meshes onto this
structured grid, our approach naturally groups adjacent mesh nodes. We then
apply a cross-attention module to map the sparse cells into a compact,
fixed-length embedding, serving as tokens for the entire physical state.
Self-attention modules are employed to predict the next state over these tokens
in latent space. This framework leverages the efficiency of tokenization and
the expressive power of attention mechanisms to achieve accurate and scalable
simulation results. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches in modeling deformable
body interactions. Notably, it remains effective on large-scale simulations
with meshes exceeding 100,000 nodes, where existing methods are hindered by
computational limitations. Additionally, we contribute a novel large-scale
dataset encompassing a wide range of deformable body interactions to support
future research in this area.

</details>


### [117] [Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods](https://arxiv.org/abs/2507.13716)
*Danilo Avola,Andrea Bernardini,Giancarlo Crocetti,Andrea Ladogana,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 该研究系统比较了传统机器学习和深度学习模型在帕金森病（PD）分类中的表现，发现CNN-LSTM模型表现最佳，同时XGBoost等传统分类器也表现优异。


<details>
  <summary>Details</summary>
Motivation: 早期诊断帕金森病对临床干预至关重要，EEG提供了一种非侵入性且经济高效的检测手段，但开发可靠的自动化诊断模型仍具挑战性。

Method: 研究采用统一的七步预处理流程，并应用一致的交叉验证和评估标准，比较了传统机器学习和深度学习模型。

Result: CNN-LSTM模型表现最佳，但XGBoost等传统分类器也表现出色。

Conclusion: 研究为未来开发更复杂或专用架构提供了参考框架，强调了科学严谨性和可重复性的重要性。

Abstract: Parkinson's Disease PD is a progressive neurodegenerative disorder that
affects motor and cognitive functions with early diagnosis being critical for
effective clinical intervention Electroencephalography EEG offers a noninvasive
and costeffective means of detecting PDrelated neural alterations yet the
development of reliable automated diagnostic models remains a challenge In this
study we conduct a systematic benchmark of traditional machine learning ML and
deep learning DL models for classifying PD using a publicly available oddball
task dataset Our aim is to lay the groundwork for developing an effective
learning system and to determine which approach produces the best results We
implement a unified sevenstep preprocessing pipeline and apply consistent
subjectwise crossvalidation and evaluation criteria to ensure comparability
across models Our results demonstrate that while baseline deep learning
architectures particularly CNNLSTM models achieve the best performance compared
to other deep learning architectures underlining the importance of capturing
longrange temporal dependencies several traditional classifiers such as XGBoost
also offer strong predictive accuracy and calibrated decision boundaries By
rigorously comparing these baselines our work provides a solid reference
framework for future studies aiming to develop and evaluate more complex or
specialized architectures Establishing a reliable set of baseline results is
essential to contextualize improvements introduced by novel methods ensuring
scientific rigor and reproducibility in the evolving field of EEGbased
neurodiagnostics

</details>


### [118] [Bi-GRU Based Deception Detection using EEG Signals](https://arxiv.org/abs/2507.13718)
*Danilo Avola,Muhammad Yasir Bilal,Emad Emam,Cristina Lakasz,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 本文提出了一种基于双向门控循环单元（Bi-GRU）的深度学习模型，用于通过脑电图（EEG）信号检测欺骗行为，测试准确率达到97%。


<details>
  <summary>Details</summary>
Motivation: 欺骗检测在安全、心理学和法医学等领域具有重要意义，但传统方法面临挑战。

Method: 使用Bag-of-Lies数据集中的EEG信号，训练Bi-GRU神经网络进行二元分类。

Result: 模型在测试中达到97%的准确率，并在精确率、召回率和F1分数上表现优异。

Conclusion: 双向时间建模在EEG欺骗检测中效果显著，具有实时应用潜力，未来可探索更先进的神经架构。

Abstract: Deception detection is a significant challenge in fields such as security,
psychology, and forensics. This study presents a deep learning approach for
classifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)
signals from the Bag-of-Lies dataset, a multimodal corpus designed for
naturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit
(Bi-GRU) neural network was trained to perform binary classification of EEG
samples. The model achieved a test accuracy of 97\%, along with high precision,
recall, and F1-scores across both classes. These results demonstrate the
effectiveness of using bidirectional temporal modeling for EEG-based deception
detection and suggest potential for real-time applications and future
exploration of advanced neural architectures.

</details>


### [119] [Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion](https://arxiv.org/abs/2507.13721)
*Zizhao Zhang,Tianxiang Zhao,Yu Sun,Liping Sun,Jichuan Kang*

Main category: cs.LG

TL;DR: 本文提出了一种混合特征融合框架，用于构建自主货船故障模式的图结构数据集，显著提升文献检索效率和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 解决自主货船组件故障引发的级联反应和应急决策中的不确定性。

Method: 采用改进的布谷鸟搜索算法（HN-CSA）提升检索效率，构建分层特征融合框架，结合Word2Vec、BERT-KPCA和Sentence-BERT处理特征和语义关联。

Result: 数据集覆盖12个系统、1,262种故障模式和6,150条传播路径；GATE-GNN模型分类准确率为0.735，特征区分度高（轮廓系数0.641），岸基气象服务系统的F1分数达0.93。

Conclusion: 为自主货船的故障分析、风险评估和智能决策系统提供了可靠支持。

Abstract: To address the challenges posed by cascading reactions caused by component
failures in autonomous cargo ships (ACS) and the uncertainties in emergency
decision-making, this paper proposes a novel hybrid feature fusion framework
for constructing a graph-structured dataset of failure modes. By employing an
improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency
is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to
the NSGA-II and CSA search algorithms, respectively. A hierarchical feature
fusion framework is constructed, using Word2Vec encoding to encode
subsystem/component features, BERT-KPCA to process failure modes/reasons, and
Sentence-BERT to quantify the semantic association between failure impact and
emergency decision-making. The dataset covers 12 systems, 1,262 failure modes,
and 6,150 propagation paths. Validation results show that the GATE-GNN model
achieves a classification accuracy of 0.735, comparable to existing benchmarks.
Additionally, a silhouette coefficient of 0.641 indicates that the features are
highly distinguishable. In the label prediction results, the Shore-based
Meteorological Service System achieved an F1 score of 0.93, demonstrating high
prediction accuracy. This paper not only provides a solid foundation for
failure analysis in autonomous cargo ships but also offers reliable support for
fault diagnosis, risk assessment, and intelligent decision-making systems. The
link to the dataset is
https://github.com/wojiufukele/Graph-Structured-about-CSA.

</details>


### [120] [Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics](https://arxiv.org/abs/2507.13727)
*René Heinrich,Lukas Rauch,Bernhard Sick,Christoph Scholz*

Main category: cs.LG

TL;DR: 研究了对抗训练在音频分类中如何提升模型对数据分布偏移和对抗攻击的鲁棒性，发现输出空间攻击策略显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索对抗训练在音频分类中对泛化能力和对抗鲁棒性的影响，尤其是在数据分布显著偏移的情况下。

Method: 使用两种模型架构（ConvNeXt和AudioProtoPNet）和两种对抗训练策略（输出空间攻击和嵌入空间攻击），在鸟类声音分类基准上评估。

Result: 对抗训练（尤其是输出空间攻击）平均提升了10.5%的干净测试数据性能，并增强了模型的对抗鲁棒性。

Conclusion: 对抗训练在音频分类中具有提升模型对分布偏移和对抗攻击鲁棒性的潜力。

Abstract: Adversarial training is a promising strategy for enhancing model robustness
against adversarial attacks. However, its impact on generalization under
substantial data distribution shifts in audio classification remains largely
unexplored. To address this gap, this work investigates how different
adversarial training strategies improve generalization performance and
adversarial robustness in audio classification. The study focuses on two model
architectures: a conventional convolutional neural network (ConvNeXt) and an
inherently interpretable prototype-based model (AudioProtoPNet). The approach
is evaluated using a challenging bird sound classification benchmark. This
benchmark is characterized by pronounced distribution shifts between training
and test data due to varying environmental conditions and recording methods, a
common real-world challenge. The investigation explores two adversarial
training strategies: one based on output-space attacks that maximize the
classification loss function, and another based on embedding-space attacks
designed to maximize embedding dissimilarity. These attack types are also used
for robustness evaluation. Additionally, for AudioProtoPNet, the study assesses
the stability of its learned prototypes under targeted embedding-space attacks.
Results show that adversarial training, particularly using output-space
attacks, improves clean test data performance by an average of 10.5% relative
and simultaneously strengthens the adversarial robustness of the models. These
findings, although derived from the bird sound domain, suggest that adversarial
training holds potential to enhance robustness against both strong distribution
shifts and adversarial attacks in challenging audio classification settings.

</details>


### [121] [An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC](https://arxiv.org/abs/2507.13736)
*Matthias Jobst,Tim Langer,Chen Liu,Mehmet Alici,Hector A. Gonzalez,Christian Mayr*

Main category: cs.LG

TL;DR: 提出了一种基于多层级DNN调度框架的扩展OctopuScheduler，支持从PyTorch模型到SpiNNaker2芯片的端到端推理流程。


<details>
  <summary>Details</summary>
Motivation: 解决在神经形态平台SpiNNaker2上执行大规模复杂DNN（如Transformer）的边缘计算需求。

Method: 结合前端量化与降阶步骤，实现端到端流程。

Result: 成功在SpiNNaker2芯片上执行大规模复杂DNN。

Conclusion: 该框架为神经形态平台上的高效DNN推理提供了可行方案。

Abstract: This work presents a multi-layer DNN scheduling framework as an extension of
OctopuScheduler, providing an end-to-end flow from PyTorch models to inference
on a single SpiNNaker2 chip. Together with a front-end comprised of
quantization and lowering steps, the proposed framework enables the edge-based
execution of large and complex DNNs up to transformer scale using the
neuromorphic platform SpiNNaker2.

</details>


### [122] [SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification](https://arxiv.org/abs/2507.13741)
*Shangyou Wang,Zezhong Ding,Xike Xie*

Main category: cs.LG

TL;DR: SamGoG框架通过高效采样机制解决图分类任务中的类别和大小不平衡问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实中的图数据常存在类别和大小不平衡问题，影响模型性能，现有方法通常只解决一种不平衡或计算成本高。

Method: 提出SamGoG框架，通过重要性采样构建多个图之图（GoG），并结合可学习相似性和自适应节点度提升边同质性。

Result: 在基准数据集上，SamGoG实现了最高15.66%的准确率提升和6.7倍的训练加速。

Conclusion: SamGoG能有效解决图分类中的不平衡问题，并与多种GNN无缝集成，性能优越。

Abstract: Graph Neural Networks (GNNs) have shown remarkable success in graph
classification tasks by capturing both structural and feature-based
representations. However, real-world graphs often exhibit two critical forms of
imbalance: class imbalance and graph size imbalance. These imbalances can bias
the learning process and degrade model performance. Existing methods typically
address only one type of imbalance or incur high computational costs. In this
work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning
framework that effectively mitigates both class and graph size imbalance.
SamGoG constructs multiple GoGs through an efficient importance-based sampling
mechanism and trains on them sequentially. This sampling mechanism incorporates
the learnable pairwise similarity and adaptive GoG node degree to enhance edge
homophily, thus improving downstream model quality. SamGoG can seamlessly
integrate with various downstream GNNs, enabling their efficient adaptation for
graph classification tasks. Extensive experiments on benchmark datasets
demonstrate that SamGoG achieves state-of-the-art performance with up to a
15.66% accuracy improvement with 6.7$\times$ training acceleration.

</details>


### [123] [Search-Optimized Quantization in Biomedical Ontology Alignment](https://arxiv.org/abs/2507.13742)
*Oussama Bouaggad,Natalia Grabar*

Main category: cs.LG

TL;DR: 论文提出了一种基于监督学习的变压器模型优化方法，用于生物医学领域的本体对齐，通过动态量化和优化技术显著提升了推理速度和内存效率。


<details>
  <summary>Details</summary>
Motivation: 解决大型AI模型在边缘设备或资源受限环境中的部署挑战，如能耗、内存使用和延迟问题。

Method: 采用基于余弦语义相似度的监督学习方法，结合Microsoft Olive、ONNX Runtime、Intel Neural Compressor和IPEX进行动态量化与优化。

Result: 在DEFT 2020评估任务中达到新最优性能，推理速度提升20倍，内存使用减少约70%。

Conclusion: 该方法有效解决了模型部署中的资源限制问题，同时保持了性能指标，为高效模型优化提供了新思路。

Abstract: In the fast-moving world of AI, as organizations and researchers develop more
advanced models, they face challenges due to their sheer size and computational
demands. Deploying such models on edge devices or in resource-constrained
environments adds further challenges related to energy consumption, memory
usage and latency. To address these challenges, emerging trends are shaping the
future of efficient model optimization techniques. From this premise, by
employing supervised state-of-the-art transformer-based models, this research
introduces a systematic method for ontology alignment, grounded in cosine-based
semantic similarity between a biomedical layman vocabulary and the Unified
Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to
search for target optimizations among different Execution Providers (EPs) using
the ONNX Runtime backend, followed by an assembled process of dynamic
quantization employing Intel Neural Compressor and IPEX (Intel Extension for
PyTorch). Through our optimization process, we conduct extensive assessments on
the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new
state-of-the-art in both. We retain performance metrics intact, while attaining
an average inference speed-up of 20x and reducing memory usage by approximately
70%.

</details>


### [124] [MolPIF: A Parameter Interpolation Flow Model for Molecule Generation](https://arxiv.org/abs/2507.13762)
*Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Mingyue Zheng,Qian Shi*

Main category: cs.LG

TL;DR: 提出了一种新的参数插值流模型（PIF），用于分子生成，并在药物设计中验证其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯流网络（BFNs）在灵活性和适应性上存在局限，需要更高效的参数空间模型。

Method: 提出PIF模型，基于参数插值流理论，并开发MolPIF用于药物设计。

Result: MolPIF在多种指标上优于基线模型。

Conclusion: 验证了参数空间生成模型的有效性，为模型设计提供了新视角。

Abstract: Advances in deep learning for molecular generation show promise in
accelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown
impressive performance across diverse chemical tasks, with their success often
ascribed to the paradigm of modeling in a low-variance parameter space.
However, the Bayesian inference-based strategy imposes limitations on designing
more flexible distribution transformation pathways, making it challenging to
adapt to diverse data distributions and varied task requirements. Furthermore,
the potential for simpler, more efficient parameter-space-based models is
unexplored. To address this, we propose a novel Parameter Interpolation Flow
model (named PIF) with detailed theoretical foundation, training, and inference
procedures. We then develop MolPIF for structure-based drug design,
demonstrating its superior performance across diverse metrics compared to
baselines. This work validates the effectiveness of parameter-space-based
generative modeling paradigm for molecules and offers new perspectives for
model design.

</details>


### [125] [Dual-Center Graph Clustering with Neighbor Distribution](https://arxiv.org/abs/2507.13765)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Li Jin,Liqiang Nie*

Main category: cs.LG

TL;DR: 提出了一种基于邻居分布特性的双中心图聚类方法（DCGC），通过邻居分布作为监督信号提升对比学习效果，并引入双中心优化。


<details>
  <summary>Details</summary>
Motivation: 现有基于伪标签的目标导向聚类方法不可靠且仅利用特征构建单目标分布，导致指导不完整。

Method: 利用邻居分布作为监督信号挖掘困难负样本，并引入邻居分布中心与特征中心共同构建双目标分布进行优化。

Result: 实验证明DCGC方法性能优越且有效。

Conclusion: DCGC通过邻居分布和双中心优化显著提升了图聚类的效果。

Abstract: Graph clustering is crucial for unraveling intricate data structures, yet it
presents significant challenges due to its unsupervised nature. Recently,
goal-directed clustering techniques have yielded impressive results, with
contrastive learning methods leveraging pseudo-label garnering considerable
attention. Nonetheless, pseudo-label as a supervision signal is unreliable and
existing goal-directed approaches utilize only features to construct a
single-target distribution for single-center optimization, which lead to
incomplete and less dependable guidance. In our work, we propose a novel
Dual-Center Graph Clustering (DCGC) approach based on neighbor distribution
properties, which includes representation learning with neighbor distribution
and dual-center optimization. Specifically, we utilize neighbor distribution as
a supervision signal to mine hard negative samples in contrastive learning,
which is reliable and enhances the effectiveness of representation learning.
Furthermore, neighbor distribution center is introduced alongside feature
center to jointly construct a dual-target distribution for dual-center
optimization. Extensive experiments and analysis demonstrate superior
performance and effectiveness of our proposed method.

</details>


### [126] [On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach](https://arxiv.org/abs/2507.13805)
*Tim Rensmeyer,Denis Kramer,Oliver Niggemann*

Main category: cs.LG

TL;DR: 论文提出了一种基于贝叶斯神经网络的方法，用于微调预训练的基础模型，并通过实时学习工作流自动检测和采样罕见事件。


<details>
  <summary>Details</summary>
Motivation: 由于从头计算原子间力的计算复杂性，机器学习力场的研究变得活跃，但训练数据的生成仍面临计算负担和多样性挑战。

Method: 采用贝叶斯神经网络方法微调预训练模型，结合实时学习工作流，自动评估模型不确定性并更新数据。

Result: 该方法在保持预设精度的同时，能够自动检测和增加罕见事件的采样率。

Conclusion: 提出的方法有效解决了基础模型微调中的不确定性评估问题，并适用于罕见事件的建模。

Abstract: Due to the computational complexity of evaluating interatomic forces from
first principles, the creation of interatomic machine learning force fields has
become a highly active field of research. However, the generation of training
datasets of sufficient size and sample diversity itself comes with a
computational burden that can make this approach impractical for modeling rare
events or systems with a large configuration space. Fine-tuning foundation
models that have been pre-trained on large-scale material or molecular
databases offers a promising opportunity to reduce the amount of training data
necessary to reach a desired level of accuracy. However, even if this approach
requires less training data overall, creating a suitable training dataset can
still be a very challenging problem, especially for systems with rare events
and for end-users who don't have an extensive background in machine learning.
In on-the-fly learning, the creation of a training dataset can be largely
automated by using model uncertainty during the simulation to decide if the
model is accurate enough or if a structure should be recalculated with
classical methods and used to update the model. A key challenge for applying
this form of active learning to the fine-tuning of foundation models is how to
assess the uncertainty of those models during the fine-tuning process, even
though most foundation models lack any form of uncertainty quantification. In
this paper, we overcome this challenge by introducing a fine-tuning approach
based on Bayesian neural network methods and a subsequent on-the-fly workflow
that automatically fine-tunes the model while maintaining a pre-specified
accuracy and can detect rare events such as transition states and sample them
at an increased rate relative to their occurrence.

</details>


### [127] [Self-supervised learning on gene expression data](https://arxiv.org/abs/2507.13912)
*Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar*

Main category: cs.LG

TL;DR: 研究探讨了自监督学习方法在基因表达数据表型预测中的应用，表明其优于传统监督学习，减少了对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 基因表达数据的标注成本高且耗时，自监督学习能直接从无标签数据中提取信息，克服这一限制。

Method: 选择了三种基于不同方法的自监督学习方法，评估其在基因表达数据中的表现，并用于下游预测任务。

Result: 自监督学习方法能有效捕捉复杂信息，提高表型预测准确性，优于传统监督模型。

Conclusion: 自监督学习在基因表达数据分析中具有潜力，未来研究可进一步优化其应用。

Abstract: Predicting phenotypes from gene expression data is a crucial task in
biomedical research, enabling insights into disease mechanisms, drug responses,
and personalized medicine. Traditional machine learning and deep learning rely
on supervised learning, which requires large quantities of labeled data that
are costly and time-consuming to obtain in the case of gene expression data.
Self-supervised learning has recently emerged as a promising approach to
overcome these limitations by extracting information directly from the
structure of unlabeled data. In this study, we investigate the application of
state-of-the-art self-supervised learning methods to bulk gene expression data
for phenotype prediction. We selected three self-supervised methods, based on
different approaches, to assess their ability to exploit the inherent structure
of the data and to generate qualitative representations which can be used for
downstream predictive tasks. By using several publicly available gene
expression datasets, we demonstrate how the selected methods can effectively
capture complex information and improve phenotype prediction accuracy. The
results obtained show that self-supervised learning methods can outperform
traditional supervised models besides offering significant advantage by
reducing the dependency on annotated data. We provide a comprehensive analysis
of the performance of each method by highlighting their strengths and
limitations. We also provide recommendations for using these methods depending
on the case under study. Finally, we outline future research directions to
enhance the application of self-supervised learning in the field of gene
expression data analysis. This study is the first work that deals with bulk
RNA-Seq data and self-supervised learning.

</details>


### [128] [Reframing attention as a reinforcement learning problem for causal discovery](https://arxiv.org/abs/2507.13920)
*Turan Orujlu,Christian Gumbsch,Martin V. Butz,Charley M Wu*

Main category: cs.LG

TL;DR: 论文提出了一种动态因果结构的表示理论（Causal Process框架），并实现了Causal Process Model，将Transformer的注意力机制与强化学习结合，以推断可解释的因果过程。


<details>
  <summary>Details</summary>
Motivation: 现有因果模型多假设静态因果图，忽略了动态因果交互。本文旨在填补这一空白，为神经网络学习的表示提供因果基础。

Method: 引入Causal Process框架，提出Causal Process Model，将Transformer注意力机制与RL结合，通过嵌套RL任务推断动态因果图。

Result: 在RL环境中，方法在因果表示学习和智能体性能上优于现有方法，并能恢复动态因果过程图。

Conclusion: Causal Process框架为动态因果结构提供了新理论，其实现模型在RL中表现出色，推动了可解释因果推理的发展。

Abstract: Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.

</details>


### [129] [MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space](https://arxiv.org/abs/2507.13950)
*Jingbo Liang,Bruna Jacobson*

Main category: cs.LG

TL;DR: MoDyGAN结合分子动力学模拟和生成对抗网络，通过将蛋白质3D结构转换为2D矩阵，高效探索蛋白质构象空间。


<details>
  <summary>Details</summary>
Motivation: 传统基于物理的动力学模拟计算成本高，限制了蛋白质构象空间的探索。

Method: 提出MoDyGAN框架，包含生成器和精炼模块，利用GAN生成蛋白质构象，并通过双判别器提升构象合理性。

Result: 在三种刚性蛋白上验证了MoDyGAN生成新构象的能力，并在十丙氨酸案例中展示了与SMD模拟轨迹的一致性。

Conclusion: 将蛋白质表示为图像数据为生物分子模拟提供了新思路，框架可扩展至其他复杂3D结构。

Abstract: Extensively exploring protein conformational landscapes remains a major
challenge in computational biology due to the high computational cost involved
in dynamic physics-based simulations. In this work, we propose a novel
pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and
generative adversarial networks (GANs) to explore protein conformational
spaces. MoDyGAN contains a generator that maps Gaussian distributions into
MD-derived protein trajectories, and a refinement module that combines ensemble
learning with a dual-discriminator to further improve the plausibility of
generated conformations. Central to our approach is an innovative
representation technique that reversibly transforms 3D protein structures into
2D matrices, enabling the use of advanced image-based GAN architectures. We use
three rigid proteins to demonstrate that MoDyGAN can generate plausible new
conformations. We also use deca-alanine as a case study to show that
interpolations within the latent space closely align with trajectories obtained
from steered molecular dynamics (SMD) simulations. Our results suggest that
representing proteins as image-like data unlocks new possibilities for applying
advanced deep learning techniques to biomolecular simulation, leading to an
efficient sampling of conformational states. Additionally, the proposed
framework holds strong potential for extension to other complex 3D structures.

</details>


### [130] [Robust Anomaly Detection with Graph Neural Networks using Controllability](https://arxiv.org/abs/2507.13954)
*Yifan Wei,Anwar Said,Waseem Abbas,Xenofon Koutsoukos*

Main category: cs.LG

TL;DR: 论文提出两种基于平均可控性的图学习方法，用于提升稀疏和不平衡数据中的异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂领域中异常检测因数据稀疏和不平衡带来的挑战，探索图模型中节点可控性的作用。

Method: 提出两种方法：1）将平均可控性作为边权重；2）将其编码为独热边属性向量。

Result: 在真实和合成网络中验证，方法优于六种基线模型，显著提升异常检测性能。

Conclusion: 平均可控性可作为关键指标，提升图机器学习模型在稀疏和不平衡数据中的表现。

Abstract: Anomaly detection in complex domains poses significant challenges due to the
need for extensive labeled data and the inherently imbalanced nature of
anomalous versus benign samples. Graph-based machine learning models have
emerged as a promising solution that combines attribute and relational data to
uncover intricate patterns. However, the scarcity of anomalous data exacerbates
the challenge, which requires innovative strategies to enhance model learning
with limited information. In this paper, we hypothesize that the incorporation
of the influence of the nodes, quantified through average controllability, can
significantly improve the performance of anomaly detection. We propose two
novel approaches to integrate average controllability into graph-based
frameworks: (1) using average controllability as an edge weight and (2)
encoding it as a one-hot edge attribute vector. Through rigorous evaluation on
real-world and synthetic networks with six state-of-the-art baselines, our
proposed methods demonstrate improved performance in identifying anomalies,
highlighting the critical role of controllability measures in enhancing the
performance of graph machine learning models. This work underscores the
potential of integrating average controllability as additional metrics to
address the challenges of anomaly detection in sparse and imbalanced datasets.

</details>


### [131] [Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs](https://arxiv.org/abs/2507.13959)
*Eli Verwimp,Gustav Ryberg Smidt,Hendrik Hameeuw,Katrien De Graef*

Main category: cs.LG

TL;DR: 本文研究了机器学习在楔形文字分类中的应用，分析了不同数据集间的性能差异，并提出了未来数据采集标准的建议。


<details>
  <summary>Details</summary>
Motivation: 楔形文字因来源、用途、书写者和数字化方式的不同而存在较大变异性，导致模型在不同数据集上表现不佳。本文旨在研究这种差异对性能的影响。

Method: 使用ResNet50模型，基于三个美索不达米亚城市（尼普尔、杜尔-阿比舒和西帕尔）的手写古巴比伦文本数据进行训练和测试。

Result: 模型在至少20个实例的符号上实现了87.1%的top-1准确率和96.5%的top-5准确率。

Conclusion: 本文为未来楔形文字分类任务提供了基础，并建议改进数据采集标准。

Abstract: The work in this paper describes the training and evaluation of machine
learning (ML) techniques for the classification of cuneiform signs. There is a
lot of variability in cuneiform signs, depending on where they come from, for
what and by whom they were written, but also how they were digitized. This
variability makes it unlikely that an ML model trained on one dataset will
perform successfully on another dataset. This contribution studies how such
differences impact that performance. Based on our results and insights, we aim
to influence future data acquisition standards and provide a solid foundation
for future cuneiform sign classification tasks. The ML model has been trained
and tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary
texts inscribed on clay tablets originating from three Mesopotamian cities
(Nippur, D\=ur-Abie\v{s}uh and Sippar). The presented and analysed model is
ResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for
signs with at least 20 instances. As these automatic classification results are
the first on Old Babylonian texts, there are currently no comparable results.

</details>


### [132] [Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks](https://arxiv.org/abs/2507.13992)
*Jagruti Patel,Thomas A. W. Bolton,Mikkel Schöttner,Anjali Tarun,Sebastien Tourbier,Yasser Alemàn-Gòmez,Jonas Richiardi,Patric Hagmann*

Main category: cs.LG

TL;DR: 提出了一种基于图卷积自编码器的结构连接组（SC）跨站点协调方法，优于传统线性回归和深度学习模型，特别适用于大规模多站点研究。


<details>
  <summary>Details</summary>
Motivation: 解决神经影像中小样本和多站点采集偏差问题，提升结构连接组研究的统计力和泛化能力。

Method: 提出站点条件深度协调框架，测试三种自编码器（全连接、卷积、图卷积）与线性回归基线对比。

Result: 图卷积自编码器在拓扑结构和个体特征保留上表现最佳，而线性回归虽数值性能高但依赖元数据。

Conclusion: 图结构模型更适合大规模多站点SC协调，强调模型架构对性能的关键影响。

Abstract: Small sample sizes in neuroimaging in general, and in structural connectome
(SC) studies in particular limit the development of reliable biomarkers for
neurological and psychiatric disorders - such as Alzheimer's disease and
schizophrenia - by reducing statistical power, reliability, and
generalizability. Large-scale multi-site studies have exist, but they have
acquisition-related biases due to scanner heterogeneity, compromising imaging
consistency and downstream analyses. While existing SC harmonization methods -
such as linear regression (LR), ComBat, and deep learning techniques - mitigate
these biases, they often rely on detailed metadata, traveling subjects (TS), or
overlook the graph-topology of SCs. To address these limitations, we propose a
site-conditioned deep harmonization framework that harmonizes SCs across
diverse acquisition sites without requiring metadata or TS that we test in a
simulated scenario based on the Human Connectome Dataset. Within this
framework, we benchmark three deep architectures - a fully connected
autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a
top-performing LR baseline. While non-graph models excel in edge-weight
prediction and edge existence detection, the graph AE demonstrates superior
preservation of topological structure and subject-level individuality, as
reflected by graph metrics and fingerprinting accuracy, respectively. Although
the LR baseline achieves the highest numerical performance by explicitly
modeling acquisition parameters, it lacks applicability to real-world
multi-site use cases as detailed acquisition metadata is often unavailable. Our
results highlight the critical role of model architecture in SC harmonization
performance and demonstrate that graph-based approaches are particularly
well-suited for structure-aware, domain-generalizable SC harmonization in
large-scale multi-site SC studies.

</details>


### [133] [ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies](https://arxiv.org/abs/2507.13998)
*Itay Katav,Aryeh Kontorovich*

Main category: cs.LG

TL;DR: 论文提出了一种动态加权机制ParallelTime Weighter和ParallelTime架构，用于优化时间序列预测中长短期依赖的权重分配，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时间序列预测中为长短期依赖分配相同权重，但研究发现这种分配并不最优。

Method: 提出动态加权机制ParallelTime Weighter，计算输入和模型知识相关的权重，并设计ParallelTime架构。

Result: ParallelTime在多个基准测试中表现优异，具有鲁棒性、低FLOPs、少参数和长预测范围。

Conclusion: ParallelTime为并行Attention-Mamba在时间序列预测中的未来发展提供了新方向。

Abstract: Modern multivariate time series forecasting primarily relies on two
architectures: the Transformer with attention mechanism and Mamba. In natural
language processing, an approach has been used that combines local window
attention for capturing short-term dependencies and Mamba for capturing
long-term dependencies, with their outputs averaged to assign equal weight to
both. We find that for time-series forecasting tasks, assigning equal weight to
long-term and short-term dependencies is not optimal. To mitigate this, we
propose a dynamic weighting mechanism, ParallelTime Weighter, which calculates
interdependent weights for long-term and short-term dependencies for each token
based on the input and the model's knowledge. Furthermore, we introduce the
ParallelTime architecture, which incorporates the ParallelTime Weighter
mechanism to deliver state-of-the-art performance across diverse benchmarks.
Our architecture demonstrates robustness, achieves lower FLOPs, requires fewer
parameters, scales effectively to longer prediction horizons, and significantly
outperforms existing methods. These advances highlight a promising path for
future developments of parallel Attention-Mamba in time series forecasting. The
implementation is readily available at:
\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub

</details>


### [134] [On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes](https://arxiv.org/abs/2507.14005)
*Mathieu Godbout,Audrey Durand*

Main category: cs.LG

TL;DR: 论文探讨了动态规划（DP）方法在马尔可夫决策过程（MDPs）中寻找静态CVaR最优策略时的失败原因，并提出了风险分配一致性约束的概念。


<details>
  <summary>Details</summary>
Motivation: 研究动态规划方法在静态CVaR优化中的失败原因，并试图通过政策评估任务揭示其根源。

Method: 将静态CVaR评估问题转化为两个最小化问题，并引入风险分配一致性约束条件。

Result: 发现约束条件交集为空是评估错误的根源，并证明了双CVaR分解方法在寻找全局最优策略时的局限性。

Conclusion: 双CVaR分解方法在特定MDP中无法找到对所有初始风险水平均最优的单一策略。

Abstract: Recent work has shown that dynamic programming (DP) methods for finding
static CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when
based on the dual formulation, yet the root cause for the failure has remained
unclear. We expand on these findings by shifting focus from policy optimization
to the seemingly simpler task of policy evaluation. We show that evaluating the
static CVaR of a given policy can be framed as two distinct minimization
problems. For their solutions to match, a set of ``risk-assignment consistency
constraints'' must be satisfied, and we demonstrate that the intersection of
the constraints being empty is the source of previously observed evaluation
errors. Quantifying the evaluation error as the CVaR evaluation gap, we then
demonstrate that the issues observed when optimizing over the dual-based CVaR
DP are explained by the returned policy having a non-zero CVaR evaluation gap.
We then leverage our proposed risk-assignment perspective to prove that the
search for a single, uniformly optimal policy via on the dual CVaR
decomposition is fundamentally limited, identifying an MDP where no single
policy can be optimal across all initial risk levels.

</details>


### [135] [DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis](https://arxiv.org/abs/2507.14038)
*Aileen Luo,Tao Zhou,Ming Du,Martin V. Holt,Andrej Singer,Mathew J. Cherukara*

Main category: cs.LG

TL;DR: DONUT是一种基于物理感知的神经网络，用于快速自动分析纳米束衍射数据，无需标记数据集或预训练，效率比传统方法高200倍。


<details>
  <summary>Details</summary>
Motivation: 实时分析纳米束衍射数据的挑战在于计算量大和存在伪影，DONUT旨在解决这一问题。

Method: DONUT通过将可微几何衍射模型融入神经网络架构，实时预测晶体晶格应变和取向。

Result: 实验证明，DONUT能准确提取数据中的所有特征，效率比传统拟合方法高200倍。

Conclusion: DONUT为X射线科学中的实时数据分析提供了一种高效、无需监督的解决方案。

Abstract: Coherent X-ray scattering techniques are critical for investigating the
fundamental structural properties of materials at the nanoscale. While
advancements have made these experiments more accessible, real-time analysis
remains a significant bottleneck, often hindered by artifacts and computational
demands. In scanning X-ray nanodiffraction microscopy, which is widely used to
spatially resolve structural heterogeneities, this challenge is compounded by
the convolution of the divergent beam with the sample's local structure. To
address this, we introduce DONUT (Diffraction with Optics for Nanobeam by
Unsupervised Training), a physics-aware neural network designed for the rapid
and automated analysis of nanobeam diffraction data. By incorporating a
differentiable geometric diffraction model directly into its architecture,
DONUT learns to predict crystal lattice strain and orientation in real-time.
Crucially, this is achieved without reliance on labeled datasets or
pre-training, overcoming a fundamental limitation for supervised machine
learning in X-ray science. We demonstrate experimentally that DONUT accurately
extracts all features within the data over 200 times more efficiently than
conventional fitting methods.

</details>


### [136] [Noradrenergic-inspired gain modulation attenuates the stability gap in joint training](https://arxiv.org/abs/2507.14056)
*Alejandro Rodriguez-Garcia,Anindya Ghosh,Srikanth Ramaswamy*

Main category: cs.LG

TL;DR: 论文研究了持续学习中的稳定性差距问题，提出了一种基于不确定性调制增益的动态机制来平衡知识整合与干扰最小化，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 持续学习中的稳定性差距揭示了现有方法在适应新任务时对已掌握任务的性能下降问题，亟需一种机制来平衡可塑性与稳定性。

Method: 受生物大脑多时间尺度动态启发，提出了一种不确定性调制增益的动态机制，模拟两时间尺度优化器，动态平衡知识整合与干扰最小化。

Result: 在MNIST和CIFAR基准测试中，该机制有效减少了稳定性差距，提升了持续学习性能。

Conclusion: 不确定性调制增益机制不仅解决了稳定性差距问题，还为理解生物神经调制在持续学习中的作用提供了新视角。

Abstract: Recent studies in continual learning have identified a transient drop in
performance on mastered tasks when assimilating new ones, known as the
stability gap. Such dynamics contradict the objectives of continual learning,
revealing a lack of robustness in mitigating forgetting, and notably,
persisting even under an ideal joint-loss regime. Examining this gap within
this idealized joint training context is critical to isolate it from other
sources of forgetting. We argue that it reflects an imbalance between rapid
adaptation and robust retention at task boundaries, underscoring the need to
investigate mechanisms that reconcile plasticity and stability within continual
learning frameworks. Biological brains navigate a similar dilemma by operating
concurrently on multiple timescales, leveraging neuromodulatory signals to
modulate synaptic plasticity. However, artificial networks lack native
multitimescale dynamics, and although optimizers like momentum-SGD and Adam
introduce implicit timescale regularization, they still exhibit stability gaps.
Inspired by locus coeruleus mediated noradrenergic bursts, which transiently
enhance neuronal gain under uncertainty to facilitate sensory assimilation, we
propose uncertainty-modulated gain dynamics - an adaptive mechanism that
approximates a two-timescale optimizer and dynamically balances integration of
knowledge with minimal interference on previously consolidated information. We
evaluate our mechanism on domain-incremental and class-incremental variants of
the MNIST and CIFAR benchmarks under joint training, demonstrating that
uncertainty-modulated gain dynamics effectively attenuate the stability gap.
Finally, our analysis elucidates how gain modulation replicates noradrenergic
functions in cortical circuits, offering mechanistic insights into reducing
stability gaps and enhance performance in continual learning tasks.

</details>


### [137] [Preference-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2507.14066)
*Ni Mu,Yao Luan,Qing-Shan Jia*

Main category: cs.LG

TL;DR: 该论文提出了基于偏好的多目标强化学习（Pb-MORL），通过偏好指导策略优化，避免了复杂奖励函数设计，并在理论和实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统多目标强化学习依赖预定义的奖励函数，难以平衡冲突目标且易简化问题。偏好作为更灵活的决策指导，可以替代复杂的奖励设计。

Method: 论文提出Pb-MORL框架，将偏好整合到多目标强化学习中，构建与偏好对齐的多目标奖励模型，并证明优化该模型等价于训练帕累托最优策略。

Result: 在基准任务、多能源管理任务和自动驾驶任务中，Pb-MORL表现优异，甚至优于使用真实奖励函数的方法。

Conclusion: Pb-MORL展示了在复杂现实系统中应用的潜力，为多目标强化学习提供了一种更灵活且高效的解决方案。

Abstract: Multi-objective reinforcement learning (MORL) is a structured approach for
optimizing tasks with multiple objectives. However, it often relies on
pre-defined reward functions, which can be hard to design for balancing
conflicting goals and may lead to oversimplification. Preferences can serve as
more flexible and intuitive decision-making guidance, eliminating the need for
complicated reward design. This paper introduces preference-based MORL
(Pb-MORL), which formalizes the integration of preferences into the MORL
framework. We theoretically prove that preferences can derive policies across
the entire Pareto frontier. To guide policy optimization using preferences, our
method constructs a multi-objective reward model that aligns with the given
preferences. We further provide theoretical proof to show that optimizing this
reward model is equivalent to training the Pareto optimal policy. Extensive
experiments in benchmark multi-objective tasks, a multi-energy management task,
and an autonomous driving task on a multi-line highway show that our method
performs competitively, surpassing the oracle method, which uses the ground
truth reward function. This highlights its potential for practical applications
in complex real-world systems.

</details>


### [138] [DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration](https://arxiv.org/abs/2507.14088)
*Xiyun Li,Yining Ding,Yuhua Jiang,Yunlong Zhao,Runpeng Xie,Shuang Xu,Yuanhua Ni,Yiqin Yang,Bo Xu*

Main category: cs.LG

TL;DR: 提出了一种双过程多尺度心智理论（DPMT）框架，用于增强AI与人类在动态场景中的协作能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）代理难以准确建模复杂的人类心智特征（如领域意图），尤其是在缺乏直接沟通的情况下。

Method: 受认知科学双过程理论启发，提出DPMT框架，结合多尺度心智理论（ToM）模块，通过心智特征推理实现稳健的人类伙伴建模。

Result: 实验表明，DPMT显著提升了人机协作效果，消融研究进一步验证了多尺度ToM在慢系统中的贡献。

Conclusion: DPMT框架为解决AI在动态场景中适应多样化人类行为的问题提供了有效方案。

Abstract: Real-time human-artificial intelligence (AI) collaboration is crucial yet
challenging, especially when AI agents must adapt to diverse and unseen human
behaviors in dynamic scenarios. Existing large language model (LLM) agents
often fail to accurately model the complex human mental characteristics such as
domain intentions, especially in the absence of direct communication. To
address this limitation, we propose a novel dual process multi-scale theory of
mind (DPMT) framework, drawing inspiration from cognitive science dual process
theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)
module to facilitate robust human partner modeling through mental
characteristic reasoning. Experimental results demonstrate that DPMT
significantly enhances human-AI collaboration, and ablation studies further
validate the contributions of our multi-scale ToM in the slow system.

</details>


### [139] [Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective](https://arxiv.org/abs/2507.14121)
*Pankaj Yadav,Vivek Vijay*

Main category: cs.LG

TL;DR: Kolmogorov Arnold Networks (KANs) 在类别不平衡分类中表现优于标准多层感知机 (MLPs)，但传统不平衡策略与 KANs 数学结构冲突，且计算成本高。


<details>
  <summary>Details</summary>
Motivation: 评估 KANs 在类别不平衡分类中的表现，探索其与传统不平衡策略的兼容性。

Method: 使用十个基准数据集对 KANs 和 MLPs 进行实证比较，分析不平衡策略的影响。

Result: KANs 在不平衡数据上表现更好，但传统策略显著降低其性能，且计算成本高。MLPs 结合不平衡策略与 KANs 性能相当。

Conclusion: KANs 适用于资源充足的不平衡数据场景，但需改进架构、效率和理论兼容性。

Abstract: Kolmogorov Arnold Networks (KANs) are recent architectural advancement in
neural computation that offer a mathematically grounded alternative to standard
neural networks. This study presents an empirical evaluation of KANs in context
of class imbalanced classification, using ten benchmark datasets. We observe
that KANs can inherently perform well on raw imbalanced data more effectively
than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,
conventional imbalance strategies fundamentally conflict with KANs mathematical
structure as resampling and focal loss implementations significantly degrade
KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from
prohibitive computational costs without proportional performance gains.
Statistical validation confirms that MLPs with imbalance techniques achieve
equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.
These findings reveal that KANs represent a specialized solution for raw
imbalanced data where resources permit. But their severe performance-resource
tradeoffs and incompatibility with standard resampling techniques currently
limits practical deployment. We identify critical research priorities as
developing KAN specific architectural modifications for imbalance learning,
optimizing computational efficiency, and theoretical reconciling their conflict
with data augmentation. This work establishes foundational insights for next
generation KAN architectures in imbalanced classification scenarios.

</details>


### [140] [Toward Temporal Causal Representation Learning with Tensor Decomposition](https://arxiv.org/abs/2507.14126)
*Jianhong Chen,Meng Zhao,Mostafa Reisi Gahrooei,Xubo Yue*

Main category: cs.LG

TL;DR: 论文提出了一种结合时间因果表示学习与不规则张量分解的框架CaRTeD，用于高维不规则数据，提升了因果表示的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的高维不规则数据需要更灵活的方法来提取因果信息，现有方法在理论和实践上存在不足。

Method: 提出CaRTeD框架，整合时间因果表示学习与不规则张量分解，提供灵活的规范化设计。

Result: 理论证明算法收敛到稳定点，实验在合成和真实数据（MIMIC-III）上表现优于现有技术。

Conclusion: CaRTeD填补了不规则张量分解的理论空白，提升了因果表示的性能和可解释性。

Abstract: Temporal causal representation learning is a powerful tool for uncovering
complex patterns in observational studies, which are often represented as
low-dimensional time series. However, in many real-world applications, data are
high-dimensional with varying input lengths and naturally take the form of
irregular tensors. To analyze such data, irregular tensor decomposition is
critical for extracting meaningful clusters that capture essential information.
In this paper, we focus on modeling causal representation learning based on the
transformed information. First, we present a novel causal formulation for a set
of latent clusters. We then propose CaRTeD, a joint learning framework that
integrates temporal causal representation learning with irregular tensor
decomposition. Notably, our framework provides a blueprint for downstream tasks
using the learned tensor factors, such as modeling latent structures and
extracting causal information, and offers a more flexible regularization design
to enhance tensor decomposition. Theoretically, we show that our algorithm
converges to a stationary point. More importantly, our results fill the gap in
theoretical guarantees for the convergence of state-of-the-art irregular tensor
decomposition. Experimental results on synthetic and real-world electronic
health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both
phenotyping and network recovery perspectives, demonstrate that our proposed
method outperforms state-of-the-art techniques and enhances the explainability
of causal representations.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [141] [Temporal Adaptation of Pre-trained Foundation Models for Music Structure Analysis](https://arxiv.org/abs/2507.13572)
*Yixiao Zhang,Haonan Chen,Ju-Chiang Wang,Jitong Chen*

Main category: cs.SD

TL;DR: 论文提出了一种针对音乐结构分析（MSA）的时间适应方法，通过音频窗口扩展和低分辨率适应策略，优化了预训练音乐基础模型的效率。


<details>
  <summary>Details</summary>
Motivation: 音乐结构分析（MSA）因音乐形式的复杂性和多样性而具有挑战性，现有预训练模型因高时间分辨率和短音频窗口的限制，效率低下且存在偏差。

Method: 采用两种策略：音频窗口扩展和低分辨率适应，以单次前向传递实现对全长歌曲的高效分析。

Result: 在Harmonix Set和RWC-Pop数据集上，边界检测和结构功能预测性能显著提升，同时保持内存使用和推理速度。

Conclusion: 该方法有效解决了长音频分析的效率问题，为音乐结构分析提供了更优的解决方案。

Abstract: Audio-based music structure analysis (MSA) is an essential task in Music
Information Retrieval that remains challenging due to the complexity and
variability of musical form. Recent advances highlight the potential of
fine-tuning pre-trained music foundation models for MSA tasks. However, these
models are typically trained with high temporal feature resolution and short
audio windows, which limits their efficiency and introduces bias when applied
to long-form audio. This paper presents a temporal adaptation approach for
fine-tuning music foundation models tailored to MSA. Our method enables
efficient analysis of full-length songs in a single forward pass by
incorporating two key strategies: (1) audio window extension and (2)
low-resolution adaptation. Experiments on the Harmonix Set and RWC-Pop datasets
show that our method significantly improves both boundary detection and
structural function prediction, while maintaining comparable memory usage and
inference speed.

</details>


### [142] [Controlling the Parameterized Multi-channel Wiener Filter using a tiny neural network](https://arxiv.org/abs/2507.13863)
*Eric Grinstein,Ashutosh Pandey,Cole Li,Shanmukha Srinivas,Juan Azcarreta,Jacob Donley,Sanha Lee,Ali Aroudi,Cagdas Bilen*

Main category: cs.SD

TL;DR: NeuralPMWF结合神经网络与PMWF波束成形，实现低复杂度、高降噪和低语音失真的语音增强系统。


<details>
  <summary>Details</summary>
Motivation: 平衡噪声抑制与语音失真是多通道语音增强算法的关键，神经网络虽降噪效果好但易引入失真，而传统PMWF可控制这一平衡。

Method: 提出NeuralPMWF，用低延迟、低计算量的神经网络完全控制PMWF，形成低复杂度系统。

Result: 实验表明，该方法在感知和客观语音增强上显著优于同类基线。

Conclusion: NeuralPMWF在降噪与语音失真间取得更好平衡，优于现有方法。

Abstract: Noise suppression and speech distortion are two important aspects to be
balanced when designing multi-channel Speech Enhancement (SE) algorithms.
Although neural network models have achieved state-of-the-art noise
suppression, their non-linear operations often introduce high speech
distortion. Conversely, classical signal processing algorithms such as the
Parameterized Multi-channel Wiener Filter ( PMWF) beamformer offer explicit
mechanisms for controlling the suppression/distortion trade-off. In this work,
we present NeuralPMWF, a system where the PMWF is entirely controlled using a
low-latency, low-compute neural network, resulting in a low-complexity system
offering high noise reduction and low speech distortion. Experimental results
show that our proposed approach results in significantly better perceptual and
objective speech enhancement in comparison to several competitive baselines
using similar computational resources.

</details>


### [143] [OpenBEATs: A Fully Open-Source General-Purpose Audio Encoder](https://arxiv.org/abs/2507.14129)
*Shikhar Bharadwaj,Samuele Cornell,Kwanghee Choi,Satoru Fukayama,Hye-jin Shim,Soham Deshmukh,Shinji Watanabe*

Main category: cs.SD

TL;DR: OpenBEATs是一个开源框架，通过多领域音频预训练扩展BEATs，在多个任务和数据集上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决BEATs在通用音频理解中应用不足、预训练代码未开源以及数据集限制的问题。

Method: 采用多领域音频预训练和掩码标记预测任务，评估六类任务、25个数据集和三个音频领域。

Result: 在多个数据集上表现优于参数规模更大的模型，验证了多领域数据和掩码标记预测的有效性。

Conclusion: OpenBEATs展示了多领域预训练和掩码标记预测的潜力，并开源了所有代码和模型以促进研究。

Abstract: Masked token prediction has emerged as a powerful pre-training objective
across language, vision, and speech, offering the potential to unify these
diverse modalities through a single pre-training task. However, its application
for general audio understanding remains underexplored, with BEATs being the
only notable example. BEATs has seen limited modifications due to the absence
of open-source pre-training code. Furthermore, BEATs was trained only on
AudioSet, restricting its broader downstream applicability. To address these
gaps, we present OpenBEATs, an open-source framework that extends BEATs via
multi-domain audio pre-training. We conduct comprehensive evaluations across
six types of tasks, twenty five datasets, and three audio domains, including
audio reasoning tasks such as audio question answering, entailment, and
captioning. OpenBEATs achieves state-of-the-art performance on six bioacoustics
datasets, two environmental sound datasets and five reasoning datasets,
performing better than models exceeding a billion parameters at one-fourth
their parameter size. These results demonstrate the effectiveness of
multi-domain datasets and masked token prediction task to learn general-purpose
audio representations. To promote further research and reproducibility, we
release all pre-training and evaluation code, pretrained and fine-tuned
checkpoints, and training logs at https://shikhar-s.github.io/OpenBEATs

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [144] [Hard-Stop Synthesis for Multi-DOF Compliant Mechanisms](https://arxiv.org/abs/2507.13455)
*Dean Chen,Armin Pomeroy,Brandon T. Peterson,Will Flanagan,He Kai Lim,Alexandra Stavrakis,Nelson F. SooHoo,Jonathan B. Hopkins,Tyler R. Clites*

Main category: cs.RO

TL;DR: 提出了一种系统化的设计方法，通过集成多自由度运动限制的紧凑硬停止表面，为柔性机构提供过载保护。


<details>
  <summary>Details</summary>
Motivation: 柔性机构在精密应用中潜力巨大，但因疲劳和机械故障的固有脆弱性，难以在实际环境中应用。复杂和不确定的负载环境需要机械硬停止以防止屈服和屈曲。

Method: 引入理论和实践框架，优化接触表面几何形状，最大化机构的多自由度工作空间，同时确保其在弹性范围内。

Result: 通过数值和实验验证，设计方法在骨科植入物的案例中提供了可靠的疲劳、屈服和屈曲保护。

Conclusion: 为在不确定负载下运行的柔性系统提供了精密硬停止设计的基础，推动了柔性机构在实际系统中的应用。

Abstract: Compliant mechanisms have significant potential in precision applications due
to their ability to guide motion without contact. However, an inherent
vulnerability to fatigue and mechanical failure has hindered the translation of
compliant mechanisms to real-world applications. This is particularly
challenging in service environments where loading is complex and uncertain, and
the cost of failure is high. In such cases, mechanical hard stops are critical
to prevent yielding and buckling. Conventional hard-stop designs, which rely on
stacking single-DOF limits, must be overly restrictive in multi-DOF space to
guarantee safety in the presence of unknown loads. In this study, we present a
systematic design synthesis method to guarantee overload protection in
compliant mechanisms by integrating coupled multi-DOF motion limits within a
single pair of compact hard-stop surfaces. Specifically, we introduce a
theoretical and practical framework for optimizing the contact surface geometry
to maximize the mechanisms multi-DOF working space while still ensuring that
the mechanism remains within its elastic regime. We apply this synthesis method
to a case study of a caged-hinge mechanism for orthopaedic implants, and
provide numerical and experimental validation that the derived design offers
reliable protection against fatigue, yielding, and buckling. This work
establishes a foundation for precision hard-stop design in compliant systems
operating under uncertain loads, which is a crucial step toward enabling the
application of compliant mechanisms in real-world systems.

</details>


### [145] [ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations](https://arxiv.org/abs/2507.13468)
*Shiye Cao,Maia Stiber,Amama Mahmood,Maria Teresa Parreira,Wendy Ju,Micol Spitale,Hatice Gunes,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 论文介绍了ERR@HRI 2.0挑战赛，旨在通过多模态数据集检测LLM驱动的对话机器人故障，以提升人机交互的可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的对话机器人仍存在误解用户意图、打断用户或无法响应等问题，检测这些故障对维持用户信任至关重要。

Method: 挑战赛提供了一个包含16小时人机交互的多模态数据集，涵盖面部、语音和头部运动特征，并标注了机器人错误和用户意图。

Result: 参与者需开发机器学习模型检测故障，提交将基于检测准确率和误报率等指标评估。

Conclusion: 该挑战赛通过社交信号分析，推动了人机交互中故障检测的改进。

Abstract: The integration of large language models (LLMs) into conversational robots
has made human-robot conversations more dynamic. Yet, LLM-powered
conversational robots remain prone to errors, e.g., misunderstanding user
intent, prematurely interrupting users, or failing to respond altogether.
Detecting and addressing these failures is critical for preventing
conversational breakdowns, avoiding task disruptions, and sustaining user
trust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal
dataset of LLM-powered conversational robot failures during human-robot
conversations and encourages researchers to benchmark machine learning models
designed to detect robot failures. The dataset includes 16 hours of dyadic
human-robot interactions, incorporating facial, speech, and head movement
features. Each interaction is annotated with the presence or absence of robot
errors from the system perspective, and perceived user intention to correct for
a mismatch between robot behavior and user expectation. Participants are
invited to form teams and develop machine learning models that detect these
failures using multimodal data. Submissions will be evaluated using various
performance metrics, including detection accuracy and false positive rate. This
challenge represents another key step toward improving failure detection in
human-robot interaction through social signal analysis.

</details>


### [146] [SCOPE for Hexapod Gait Generation](https://arxiv.org/abs/2507.13539)
*Jim O'Connor,Jay B. Nash,Derin Gezgin,Gary B. Parker*

Main category: cs.RO

TL;DR: SCOPE方法通过离散余弦变换（DCT）压缩输入数据，显著提升六足机器人步态学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决进化算法在复杂输入空间下性能下降的问题。

Method: 利用DCT截断系数矩阵，降低输入维度，保留关键特征。

Result: 输入数据从2700减少到54，效率提升20%。

Conclusion: SCOPE能显著压缩输入数据并提升控制器效能。

Abstract: Evolutionary methods have previously been shown to be an effective learning
method for walking gaits on hexapod robots. However, the ability of these
algorithms to evolve an effective policy rapidly degrades as the input space
becomes more complex. This degradation is due to the exponential growth of the
solution space, resulting from an increasing parameter count to handle a more
complex input. In order to address this challenge, we introduce Sparse Cosine
Optimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine
Transform (DCT) to learn directly from the feature coefficients of an input
matrix. By truncating the coefficient matrix returned by the DCT, we can reduce
the dimensionality of an input while retaining the highest energy features of
the original input. We demonstrate the effectiveness of this method by using
SCOPE to learn the gait of a hexapod robot. The hexapod controller is given a
matrix input containing time-series information of previous poses, which are
then transformed to gait parameters by an evolved policy. In this task, the
addition of SCOPE to a reference algorithm achieves a 20% increase in efficacy.
SCOPE achieves this result by reducing the total input size of the time-series
pose data from 2700 to 54, a 98% decrease. Additionally, SCOPE is capable of
compressing an input to any output shape, provided that each output dimension
is no greater than the corresponding input dimension. This paper demonstrates
that SCOPE is capable of significantly compressing the size of an input to an
evolved controller, resulting in a statistically significant gain in efficacy.

</details>


### [147] [Improving Low-Cost Teleoperation: Augmenting GELLO with Force](https://arxiv.org/abs/2507.13602)
*Shivakanth Sujit,Luca Nunziante,Dan Ogawa Lillrank,Rousslan Fernand Julien Dossa,Kai Arulkumaran*

Main category: cs.RO

TL;DR: 扩展了低成本GELLO遥操作系统，加入力反馈和力信息用于模仿学习，提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 提升遥操作系统的用户体验和模仿学习模型的性能。

Method: 实现力反馈，并将力信息加入数据收集和模仿学习训练中。

Result: 用户偏好新控制器，力信息提高了多数任务的成功率。

Conclusion: 力反馈和力信息的加入显著提升了系统性能和任务成功率。

Abstract: In this work we extend the low-cost GELLO teleoperation system, initially
designed for joint position control, with additional force information. Our
first extension is to implement force feedback, allowing users to feel
resistance when interacting with the environment. Our second extension is to
add force information into the data collection process and training of
imitation learning models. We validate our additions by implementing these on a
GELLO system with a Franka Panda arm as the follower robot, performing a user
study, and comparing the performance of policies trained with and without force
information on a range of simulated and real dexterous manipulation tasks.
Qualitatively, users with robotics experience preferred our controller, and the
addition of force inputs improved task success on the majority of tasks.

</details>


### [148] [A Minimalist Controller for Autonomously Self-Aggregating Robotic Swarms: Enabling Compact Formations in Multitasking Scenarios](https://arxiv.org/abs/2507.13969)
*Maria Eduarda Silva de Macedo,Ana Paula Chiarelli de Souza,Roberto Silvio Ubertino Rosso Jr.,Yuri Kaszubowski Lopes*

Main category: cs.RO

TL;DR: 本文提出了一种多任务自聚集方法，使同质机器人仅依赖视线传感器形成紧凑集群，解决了现有方法中集群动态相互影响的问题。


<details>
  <summary>Details</summary>
Motivation: 解决多任务自聚集中集群动态相互影响及形成非紧凑圆形的问题，实现完全自主的紧凑集群。

Method: 使用同质机器人和视线传感器，通过模拟试验验证多任务自聚集行为的可扩展性和紧凑性。

Result: 在多组和多机器人配置的模拟试验中，实现了紧凑的集群形成，并保持了其他研究中发现的集群比例。

Conclusion: 提出的方法在多任务自聚集行为中显著提升了集群的紧凑性，同时保持了可扩展性和自主性。

Abstract: The deployment of simple emergent behaviors in swarm robotics has been
well-rehearsed in the literature. A recent study has shown how self-aggregation
is possible in a multitask approach -- where multiple self-aggregation task
instances occur concurrently in the same environment. The multitask approach
poses new challenges, in special, how the dynamic of each group impacts the
performance of others. So far, the multitask self-aggregation of groups of
robots suffers from generating a circular formation -- that is not fully
compact -- or is not fully autonomous. In this paper, we present a multitask
self-aggregation where groups of homogeneous robots sort themselves into
different compact clusters, relying solely on a line-of-sight sensor. Our
multitask self-aggregation behavior was able to scale well and achieve a
compact formation. We report scalability results from a series of simulation
trials with different configurations in the number of groups and the number of
robots per group. We were able to improve the multitask self-aggregation
behavior performance in terms of the compactness of the clusters, keeping the
proportion of clustered robots found in other studies.

</details>


### [149] [Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones](https://arxiv.org/abs/2507.13647)
*Minze Li,Wei Zhao,Ran Chen,Mingqiang Wei*

Main category: cs.RO

TL;DR: 提出了一种改进的粒子群优化算法（PE-PSO），用于无人机在动态环境中的实时轨迹规划，解决了传统PSO算法的早熟收敛和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 动态环境中无人机的实时轨迹规划面临高计算需求和快速响应的挑战，传统PSO方法在实时场景中表现不佳。

Method: 引入持久探索机制保持群体多样性，基于熵的参数调整策略动态优化行为，结合B样条曲线建模轨迹，并开发多智能体框架支持分布式计算。

Result: 仿真结果表明，PE-PSO在轨迹质量、能效、避障和计算时间等方面优于传统PSO和其他群智能规划器。

Conclusion: PE-PSO在复杂环境下的实时多无人机操作中具有高效性和适用性。

Abstract: Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic
environments remains a key challenge due to high computational demands and the
need for fast, adaptive responses. Traditional Particle Swarm Optimization
(PSO) methods, while effective for offline planning, often struggle with
premature convergence and latency in real-time scenarios. To overcome these
limitations, we propose PE-PSO, an enhanced PSO-based online trajectory
planner. The method introduces a persistent exploration mechanism to preserve
swarm diversity and an entropy-based parameter adjustment strategy to
dynamically adapt optimization behavior. UAV trajectories are modeled using
B-spline curves, which ensure path smoothness while reducing optimization
complexity. To extend this capability to UAV swarms, we develop a multi-agent
framework that combines genetic algorithm (GA)-based task allocation with
distributed PE-PSO, supporting scalable and coordinated trajectory generation.
The distributed architecture allows for parallel computation and decentralized
control, enabling effective cooperation among agents while maintaining
real-time performance. Comprehensive simulations demonstrate that the proposed
framework outperforms conventional PSO and other swarm-based planners across
several metrics, including trajectory quality, energy efficiency, obstacle
avoidance, and computation time. These results confirm the effectiveness and
applicability of PE-PSO in real-time multi-UAV operations under complex
environmental conditions.

</details>


### [150] [Safe Robotic Capsule Cleaning with Integrated Transpupillary and Intraocular Optical Coherence Tomography](https://arxiv.org/abs/2507.13650)
*Yu-Ting Lai,Yasamin Foroutani,Aya Barzelay,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 本文介绍了一种用于治疗继发性白内障的机器人系统，通过整合光学相干断层扫描探头实现囊膜可视化和实时反馈，提高了手术精度。


<details>
  <summary>Details</summary>
Motivation: 继发性白内障是白内障手术后常见的并发症，传统治疗方法需要高精度的囊膜可视化和操作，现有技术存在挑战。

Method: 开发了一种机器人系统，整合光学相干断层扫描探头，实现囊膜映射和实时工具-组织距离反馈，并通过实验验证其有效性。

Result: 在眼模型实验中，囊膜映射策略降低了均方根误差；在离体猪眼实验中，清洁策略未造成组织损伤。

Conclusion: 该机器人系统能够有效提高继发性白内障手术的精度和安全性。

Abstract: Secondary cataract is one of the most common complications of vision loss due
to the proliferation of residual lens materials that naturally grow on the lens
capsule after cataract surgery. A potential treatment is capsule cleaning, a
surgical procedure that requires enhanced visualization of the entire capsule
and tool manipulation on the thin membrane. This article presents a robotic
system capable of performing the capsule cleaning procedure by integrating a
standard transpupillary and an intraocular optical coherence tomography probe
on a surgical instrument for equatorial capsule visualization and real-time
tool-to-tissue distance feedback. Using robot precision, the developed system
enables complete capsule mapping in the pupillary and equatorial regions with
in-situ calibration of refractive index and fiber offset, which are still
current challenges in obtaining an accurate capsule model. To demonstrate
effectiveness, the capsule mapping strategy was validated through five
experimental trials on an eye phantom that showed reduced root-mean-square
errors in the constructed capsule model, while the cleaning strategy was
performed in three ex-vivo pig eyes without tissue damage.

</details>


### [151] [A Study of Teleoperation Methods in a Simulated Virtual Eye Surgery Environment](https://arxiv.org/abs/2507.13654)
*Haoran Wang,Yasamin Foroutani,Matthew Nepo,Mercedes Rodriguez,Ji Ma,Jean-Pierre Hubschman,Tsu-Chin Tsao,Jacob Rosen*

Main category: cs.RO

TL;DR: 研究比较了不同缩放因子下Inside和Outside控制模式在模拟玻璃体视网膜手术中的表现，发现高缩放因子的Inside Control表现最佳。


<details>
  <summary>Details</summary>
Motivation: 优化控制模式和缩放因子，以提高机器人辅助眼内手术的效率和准确性，降低风险。

Method: 使用IRISS手术系统，将模拟显微镜视图投影到VR头显，由5名外科医生和5名工程师完成手术任务。

Result: 高缩放因子（20或30）的Inside Control表现最佳，但最优缩放因子因任务和复杂度而异。

Conclusion: 优化控制模式和缩放因子可提升手术效率和准确性，减少未来机器人辅助手术的风险。

Abstract: This paper examines the performance of Inside and Outside Control modes at
various scaling factors in a simulated vitreoretinal surgical setting. The
IRISS teleoperated surgical system's console (cockpit) was adapted to project a
simulated microscope view of an intraocular setup to a virtual reality (VR)
headset. Five experienced vitreoretinal surgeons and five engineers with no
surgical experience used the system to perform tasks common to vitreoretinal
surgery. Experimental results indicate that Inside Control methods at higher
scaling factors (20 or 30) achieved the best performance overall, though the
optimal scaling factor may vary by task and complexity. Optimizing control
methods and scaling factors could lead to improvements in surgical efficiency
and accuracy, as well as minimize risks in future robotic-assisted intraocular
procedures.

</details>


### [152] [Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion](https://arxiv.org/abs/2507.13662)
*Jing Cheng,Yasser G. Alqaham,Zhenyu Gan,Amit K. Sanyal*

Main category: cs.RO

TL;DR: 提出了一种结合迭代学习控制（ILC）和生物启发的扭矩库（TL）的可扩展自适应控制框架，用于提高腿式机器人在复杂环境中的运动性能。


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在未建模动态和外部干扰下的精确轨迹跟踪问题，以及提高运动场景的适应性和泛化能力。

Method: 结合物理模型和实时学习，利用ILC扩展至非周期性任务，并通过TL存储学习到的控制配置以实现快速适应。

Result: 在双足机器人Cassie和四足机器人A1上验证，关节跟踪误差减少85%，控制更新速率提高30倍。

Conclusion: ILC与扭矩库的结合为腿式机器人在非结构化动态环境中提供了一种高效实用的解决方案。

Abstract: This paper presents a scalable and adaptive control framework for legged
robots that integrates Iterative Learning Control (ILC) with a biologically
inspired torque library (TL), analogous to muscle memory. The proposed method
addresses key challenges in robotic locomotion, including accurate trajectory
tracking under unmodeled dynamics and external disturbances. By leveraging the
repetitive nature of periodic gaits and extending ILC to nonperiodic tasks, the
framework enhances accuracy and generalization across diverse locomotion
scenarios. The control architecture is data-enabled, combining a physics-based
model derived from hybrid-system trajectory optimization with real-time
learning to compensate for model uncertainties and external disturbances. A
central contribution is the development of a generalized TL that stores learned
control profiles and enables rapid adaptation to changes in speed, terrain, and
gravitational conditions-eliminating the need for repeated learning and
significantly reducing online computation. The approach is validated on the
bipedal robot Cassie and the quadrupedal robot A1 through extensive simulations
and hardware experiments. Results demonstrate that the proposed framework
reduces joint tracking errors by up to 85% within a few seconds and enables
reliable execution of both periodic and nonperiodic gaits, including slope
traversal and terrain adaptation. Compared to state-of-the-art whole-body
controllers, the learned skills eliminate the need for online computation
during execution and achieve control update rates exceeding 30x those of
existing methods. These findings highlight the effectiveness of integrating ILC
with torque memory as a highly data-efficient and practical solution for legged
locomotion in unstructured and dynamic environments.

</details>


### [153] [SaWa-ML: Structure-Aware Pose Correction and Weight Adaptation-Based Robust Multi-Robot Localization](https://arxiv.org/abs/2507.13702)
*Junho Choi,Kihwan Ryoo,Jeewon Kim,Taeyun Kim,Eungchang Lee,Myeongwoo Jeong,Kevin Christiansen Marsim,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种名为SaWa-ML的视觉-惯性-距离多机器人定位方法，通过几何结构感知的姿态校正和权重自适应，减少长期漂移误差。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分考虑机器人里程计估计和距离测量的特性，且受限于里程计精度，导致长期漂移误差不可避免。

Method: 利用UWB传感器数据估计机器人间相对位置并校正，设计自适应权重以考虑传感器数据和视觉惯性里程计特性。

Result: 实验验证表明，性能显著优于现有算法。

Conclusion: SaWa-ML通过几何结构感知和权重自适应，有效减少了长期漂移误差，提升了多机器人定位的鲁棒性。

Abstract: Multi-robot localization is a crucial task for implementing multi-robot
systems. Numerous researchers have proposed optimization-based multi-robot
localization methods that use camera, IMU, and UWB sensors. Nevertheless,
characteristics of individual robot odometry estimates and distance
measurements between robots used in the optimization are not sufficiently
considered. In addition, previous researches were heavily influenced by the
odometry accuracy that is estimated from individual robots. Consequently,
long-term drift error caused by error accumulation is potentially inevitable.
In this paper, we propose a novel visual-inertial-range-based multi-robot
localization method, named SaWa-ML, which enables geometric structure-aware
pose correction and weight adaptation-based robust multi-robot localization.
Our contributions are twofold: (i) we leverage UWB sensor data, whose range
error does not accumulate over time, to first estimate the relative positions
between robots and then correct the positions of each robot, thus reducing
long-term drift errors, (ii) we design adaptive weights for robot pose
correction by considering the characteristics of the sensor data and
visual-inertial odometry estimates. The proposed method has been validated in
real-world experiments, showing a substantial performance increase compared
with state-of-the-art algorithms.

</details>


### [154] [AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework](https://arxiv.org/abs/2507.13729)
*Yu Yao,Salil Bhatnagar,Markus Mazzola,Vasileios Belagiannis,Igor Gilitschenski,Luigi Palmieri,Simon Razniewski,Marcel Hallgarten*

Main category: cs.RO

TL;DR: 论文提出了一种基于LLM-agent的框架，通过自然语言描述增强真实交通场景，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 罕见但关键的场景对自动驾驶规划器的测试和评估构成挑战，现有方法依赖大量数据或专家手动增强，无法满足规模化需求。

Method: 采用LLM-agent框架，通过自然语言描述生成增强场景，实现细粒度控制和高效性能。

Result: 人类专家评估表明，框架能准确遵循用户意图，生成与手动创建相当的高质量增强场景。

Conclusion: 该框架为自动驾驶系统的评估提供了一种高效、可控的解决方案。

Abstract: Rare, yet critical, scenarios pose a significant challenge in testing and
evaluating autonomous driving planners. Relying solely on real-world driving
scenes requires collecting massive datasets to capture these scenarios. While
automatic generation of traffic scenarios appears promising, data-driven models
require extensive training data and often lack fine-grained control over the
output. Moreover, generating novel scenarios from scratch can introduce a
distributional shift from the original training scenes which undermines the
validity of evaluations especially for learning-based planners. To sidestep
this, recent work proposes to generate challenging scenarios by augmenting
original scenarios from the test set. However, this involves the manual
augmentation of scenarios by domain experts. An approach that is unable to meet
the demands for scale in the evaluation of self-driving systems. Therefore,
this paper introduces a novel LLM-agent based framework for augmenting
real-world traffic scenarios using natural language descriptions, addressing
the limitations of existing methods. A key innovation is the use of an agentic
design, enabling fine-grained control over the output and maintaining high
performance even with smaller, cost-effective LLMs. Extensive human expert
evaluation demonstrates our framework's ability to accurately adhere to user
intent, generating high quality augmented scenarios comparable to those created
manually.

</details>


### [155] [Design Analysis of an Innovative Parallel Robot for Minimally Invasive Pancreatic Surgery](https://arxiv.org/abs/2507.13787)
*Doina Pisla,Alexandru Pusca,Andrei Caprariu,Adrian Pisla,Bogdan Gherman,Calin Vaida,Damien Chablat*

Main category: cs.RO

TL;DR: 本文提出两种4自由度并行机器人架构（ATHENA-1和ATHENA-2），用于胰腺微创手术，通过FEM模拟和空间分析评估其性能，最终选择符合设计标准的架构。


<details>
  <summary>Details</summary>
Motivation: 设计适用于胰腺微创手术的并行机器人，提高手术精度和效率。

Method: 提出两种4自由度架构，进行FEM模拟和空间分析，评估刚度和适用性。

Result: 通过模拟和分析确定性能更优的架构，满足手术需求。

Conclusion: 选择符合设计标准的架构，用于后续实验模型的开发。

Abstract: This paper focuses on the design of a parallel robot designed for robotic
assisted minimally invasive pancreatic surgery. Two alternative architectures,
called ATHENA-1 and ATHENA-2, each with 4 degrees of freedom (DOF) are
proposed. Their kinematic schemes are presented, and the conceptual 3D CAD
models are illustrated. Based on these, two Finite Element Method (FEM)
simulations were performed to determine which architecture has the higher
stiffness. A workspace quantitative analysis is performed to further assess the
usability of the two proposed parallel architectures related to the medical
tasks. The obtained results are used to select the architecture which fit the
required design criteria and will be used to develop the experimental model of
the surgical robot.

</details>


### [156] [Safety Certification in the Latent space using Control Barrier Functions and World Models](https://arxiv.org/abs/2507.13871)
*Mehul Anand,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出了一种半监督框架，利用世界模型的潜在空间中的控制屏障证书（CBCs）来合成安全的视觉运动策略。


<details>
  <summary>Details</summary>
Motivation: 从视觉数据合成安全控制器通常需要大量标记安全关键数据，这在现实场景中往往不切实际。

Method: 联合学习神经屏障函数和安全控制器，利用现代视觉变换器的预测能力进行潜在动力学建模。

Result: 通过有限的标记数据实现了安全控制策略的合成。

Conclusion: 该方法为可扩展且数据高效的安全控制提供了新途径。

Abstract: Synthesising safe controllers from visual data typically requires extensive
supervised labelling of safety-critical data, which is often impractical in
real-world settings. Recent advances in world models enable reliable prediction
in latent spaces, opening new avenues for scalable and data-efficient safe
control. In this work, we introduce a semi-supervised framework that leverages
control barrier certificates (CBCs) learned in the latent space of a world
model to synthesise safe visuomotor policies. Our approach jointly learns a
neural barrier function and a safe controller using limited labelled data,
while exploiting the predictive power of modern vision transformers for latent
dynamics modelling.

</details>


### [157] [AeroThrow: An Autonomous Aerial Throwing System for Precise Payload Delivery](https://arxiv.org/abs/2507.13903)
*Ziliang Li,Hongming Chen,Yiyang Lin,Biyu Ye,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种基于空中机械臂（AM）的自主空投系统，通过引入额外的自由度主动补偿无人机跟踪误差，并结合非线性模型预测控制（NMPC）提高空投精度和敏捷性。


<details>
  <summary>Details</summary>
Motivation: 解决空投任务中控制模式切换和系统延迟带来的挑战。

Method: 采用空中机械臂增加自由度，结合NMPC框架和分层扰动补偿策略，生成平滑的空投轨迹。

Result: 仿真和实验表明，系统在空投任务中表现出更高的敏捷性和精度。

Conclusion: 提出的系统有效解决了空投任务中的控制问题，提升了性能。

Abstract: Autonomous aerial systems play an increasingly vital role in a wide range of
applications, particularly for transport and delivery tasks in complex
environments. In airdrop missions, these platforms face the dual challenges of
abrupt control mode switching and inherent system delays along with control
errors. To address these issues, this paper presents an autonomous airdrop
system based on an aerial manipulator (AM). The introduction of additional
actuated degrees of freedom enables active compensation for UAV tracking
errors. By imposing smooth and continuous constraints on the parabolic landing
point, the proposed approach generates aerial throwing trajectories that are
less sensitive to the timing of payload release. A hierarchical disturbance
compensation strategy is incorporated into the Nonlinear Model Predictive
Control (NMPC) framework to mitigate the effects of sudden changes in system
parameters, while the predictive capabilities of NMPC are further exploited to
improve the precision of aerial throwing. Both simulation and real-world
experimental results demonstrate that the proposed system achieves greater
agility and precision in airdrop missions.

</details>


### [158] [NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning](https://arxiv.org/abs/2507.13940)
*Qingyi Chen,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的Hamilton-Jacobi可达性学习（HJR）方法，用于去中心化多智能体运动规划（MAMP），解决了现有方法在可扩展性和实时性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化算法依赖行为预测或通信，而集中式方法难以扩展和实时决策，亟需一种新方法解决这些问题。

Method: 采用神经HJR建模处理高维配置空间，并结合去中心化轨迹优化框架实现实时MAMP任务。

Result: 方法在12维双臂设置等复杂场景中表现优异，优于现有技术，且具有可扩展性和数据高效性。

Conclusion: 神经HJR方法为MAMP提供了一种高效、可扩展的解决方案，适用于复杂动态系统。

Abstract: Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in
robotics. Despite substantial advancements, existing methods often face a
dilemma. Decentralized algorithms typically rely on predicting the behavior of
other agents, sharing contracts, or maintaining communication for safety, while
centralized approaches struggle with scalability and real-time decision-making.
To address these challenges, we introduce Neural Hamilton-Jacobi Reachability
Learning (HJR) for Decentralized Multi-Agent Motion Planning. Our method
provides scalable neural HJR modeling to tackle high-dimensional configuration
spaces and capture worst-case collision and safety constraints between agents.
We further propose a decentralized trajectory optimization framework that
incorporates the learned HJR solutions to solve MAMP tasks in real-time. We
demonstrate that our method is both scalable and data-efficient, enabling the
solution of MAMP problems in higher-dimensional scenarios with complex
collision constraints. Our approach generalizes across various dynamical
systems, including a 12-dimensional dual-arm setup, and outperforms a range of
state-of-the-art techniques in successfully addressing challenging MAMP tasks.
Video demonstrations are available at https://youtu.be/IZiePX0p1Mc.

</details>


### [159] [A segmented robot grasping perception neural network for edge AI](https://arxiv.org/abs/2507.13970)
*Casper Bröcheler,Thomas Vroom,Derrick Timmermans,Alan van den Akker,Guangzhi Tang,Charalampos S. Kouzinopoulos,Rico Möckel*

Main category: cs.RO

TL;DR: 论文提出了一种基于热图引导的6自由度抓取检测框架，并在GAP9 RISC-V芯片上实现，通过硬件优化技术实现低功耗实时推理。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在资源受限环境下实时抓取的挑战，利用深度学习模型实现高效抓取姿态检测。

Method: 采用热图引导的抓取检测框架，结合输入降维、模型分区和量化等硬件优化技术。

Result: 在GraspNet-1Billion基准测试中验证了全芯片推理的可行性，展示了低功耗MCU在实时自主操作中的潜力。

Conclusion: 该框架为资源受限环境下的实时机器人抓取提供了可行方案，证明了低功耗芯片的潜力。

Abstract: Robotic grasping, the ability of robots to reliably secure and manipulate
objects of varying shapes, sizes and orientations, is a complex task that
requires precise perception and control. Deep neural networks have shown
remarkable success in grasp synthesis by learning rich and abstract
representations of objects. When deployed at the edge, these models can enable
low-latency, low-power inference, making real-time grasping feasible in
resource-constrained environments. This work implements Heatmap-Guided Grasp
Detection, an end-to-end framework for the detection of 6-Dof grasp poses, on
the GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware
techniques, including input dimensionality reduction, model partitioning, and
quantisation. Experimental evaluation on the GraspNet-1Billion benchmark
validates the feasibility of fully on-chip inference, highlighting the
potential of low-power MCUs for real-time, autonomous manipulation.

</details>


### [160] [A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems](https://arxiv.org/abs/2507.14043)
*Genliang Li,Yaxin Cui,Jinyu Su*

Main category: cs.RO

TL;DR: 提出了一种多策略改进的蛇优化器（MISO），通过自适应随机扰动、Levy飞行策略和精英领导结合布朗运动的位置更新策略，解决了蛇优化器（SO）收敛慢和易陷入局部最优的问题，并在测试函数和无人机路径规划中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 蛇优化器（SO）存在收敛速度慢和易陷入局部最优的问题，限制了其应用效果。

Method: 1. 基于正弦函数的自适应随机扰动策略；2. 基于尺度因子和领导者的自适应Levy飞行策略；3. 精英领导结合布朗运动的位置更新策略。

Result: 在CEC2017和CEC2022测试函数以及无人机3D路径规划和6个工程设计问题中，MISO表现优于11种流行算法。

Conclusion: MISO在解决优化问题和实际应用中表现出色，具有较高的应用潜力。

Abstract: Metaheuristic algorithms have gained widespread application across various
fields owing to their ability to generate diverse solutions. One such algorithm
is the Snake Optimizer (SO), a progressive optimization approach. However, SO
suffers from the issues of slow convergence speed and susceptibility to local
optima. In light of these shortcomings, we propose a novel Multi-strategy
Improved Snake Optimizer (MISO). Firstly, we propose a new adaptive random
disturbance strategy based on sine function to alleviate the risk of getting
trapped in a local optimum. Secondly, we introduce adaptive Levy flight
strategy based on scale factor and leader and endow the male snake leader with
flight capability, which makes it easier for the algorithm to leap out of the
local optimum and find the global optimum. More importantly, we put forward a
position update strategy combining elite leadership and Brownian motion,
effectively accelerating the convergence speed while ensuring precision.
Finally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test
functions and the CEC2022 test suite, comparing it with 11 popular algorithms
across different dimensions to validate its effectiveness. Moreover, Unmanned
Aerial Vehicle (UAV) has been widely used in various fields due to its
advantages of low cost, high mobility and easy operation. However, the UAV path
planning problem is crucial for flight safety and efficiency, and there are
still challenges in establishing and optimizing the path model. Therefore, we
apply MISO to the UAV 3D path planning problem as well as 6 engineering design
problems to assess its feasibility in practical applications. The experimental
results demonstrate that MISO exceeds other competitive algorithms in terms of
solution quality and stability, establishing its strong potential for
application.

</details>


### [161] [EdgeVLA: Efficient Vision-Language-Action Models](https://arxiv.org/abs/2507.14049)
*Paweł Budzianowski,Wesley Maa,Matthew Freed,Jingxiang Mo,Winston Hsiao,Aaron Xie,Tomasz Młoduchowski,Viraj Tipnis,Benjamin Bolte*

Main category: cs.RO

TL;DR: EVLA是一种新型视觉-语言-动作模型，通过消除自回归预测和利用小型语言模型，显著提升了推理速度，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 解决大规模视觉-语言模型在移动机器人系统中部署时的资源限制问题。

Method: 1. 消除末端执行器位置预测的自回归需求；2. 利用小型语言模型提高效率。

Result: EVLA在推理速度和内存效率上显著优于OpenVLA，同时保持相似的训练性能。

Conclusion: EVLA为边缘设备上的实时视觉-语言-动作任务提供了高效解决方案。

Abstract: Vision-Language Models (VLMs) have emerged as a promising approach to address
the data scarcity challenge in robotics, enabling the development of
generalizable visuomotor control policies. While models like OpenVLA showcase
the potential of this paradigm, deploying large-scale VLMs on
resource-constrained mobile manipulation systems remains a significant hurdle.
This paper introduces Edge VLA (EVLA), a novel approach designed to
significantly enhance the inference speed of Vision-Language-Action (VLA)
models. EVLA maintains the representational power of these models while
enabling real-time performance on edge devices. We achieve this through two key
innovations: 1) Eliminating the autoregressive requirement for end-effector
position prediction, leading to a 7x speedup in inference, and 2) Leveraging
the efficiency of Small Language Models (SLMs), demonstrating comparable
training performance to larger models with significantly reduced computational
demands. Our early results demonstrate that EVLA achieves comparable training
characteristics to OpenVLA while offering substantial gains in inference speed
and memory efficiency. We release our model checkpoints and training
\href{https://github.com/kscalelabs/evla }{codebase} to foster further
research.

</details>


### [162] [Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub](https://arxiv.org/abs/2507.14059)
*Tianyuan Wang,Mark A Post,Mathieu Deremetz*

Main category: cs.RO

TL;DR: STARFAB项目开发了一种自主移动检查模块（MIM），用于轨道自动化仓库的监控和维护。


<details>
  <summary>Details</summary>
Motivation: 为可持续商业空间操作和服务提供自主检查能力，支持空间硬件组件的再利用。

Method: MIM采用标准接口，可被行走机械臂携带，配备多种传感器和工具，实现自主检查和维护。

Result: MIM设计已完成，具备高分辨率相机、3D轮廓仪和热成像传感器等功能，测试仍在进行中。

Conclusion: MIM展示了在轨自主检查和维护的可行性，为未来空间设施管理提供了新工具。

Abstract: The use of autonomous robots in space is an essential part of the "New Space"
commercial ecosystem of assembly and re-use of space hardware components in
Earth orbit and beyond. The STARFAB project aims to create a ground
demonstration of an orbital automated warehouse as a hub for sustainable
commercial operations and servicing. A critical part of this fully-autonomous
robotic facility will be the capability to monitor, inspect, and assess the
condition of both the components stored in the warehouse, and the STARFAB
facility itself. This paper introduces ongoing work on the STARFAB Mobile
Inspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it
can be carried by Walking Manipulators (WM) as an independently-mobile robot,
and multiple MIMs can be stored and retrieved as needed for operations on
STARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a
thermal imaging sensor, with the capability to add other modular sensors. A
grasping tool and torque wrench are stored within the modular body for use by
an attached WM for maintenance operations. Implementation and testing is still
ongoing at the time of writing. This paper details the concept of operations
for the MIM as an on-orbit autonomous inspection and maintenance system, the
mechanical and electronic design of the MIM, and the sensors package used for
non-destructive testing.

</details>


### [163] [MorphIt: Flexible Spherical Approximation of Robot Morphology for Representation-driven Adaptation](https://arxiv.org/abs/2507.14061)
*Nataliya Nechyporenko,Yutong Zhang,Sean Campbell,Alessandro Roncone*

Main category: cs.RO

TL;DR: MorphIt是一种新型算法，通过球形基元近似机器人形态，平衡几何精度与计算效率，自动优化框架优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统将物理形态视为固定约束，无法适应多样化任务需求，限制了计算和精度性能。

Method: MorphIt采用基于梯度的自动优化框架，可调参数控制几何保真度与计算成本的权衡。

Result: MorphIt在多个指标上优于基线方法，实现更少球体的更好网格近似，提升碰撞检测、接触模拟和导航能力。

Conclusion: 动态适应几何表示使机器人能主动利用物理形态，为复杂环境中的操作开辟新可能。

Abstract: What if a robot could rethink its own morphological representation to better
meet the demands of diverse tasks? Most robotic systems today treat their
physical form as a fixed constraint rather than an adaptive resource, forcing
the same rigid geometric representation to serve applications with vastly
different computational and precision requirements. We introduce MorphIt, a
novel algorithm for approximating robot morphology using spherical primitives
that balances geometric accuracy with computational efficiency. Unlike existing
approaches that rely on either labor-intensive manual specification or
inflexible computational methods, MorphIt implements an automatic
gradient-based optimization framework with tunable parameters that provides
explicit control over the physical fidelity versus computational cost tradeoff.
Quantitative evaluations demonstrate that MorphIt outperforms baseline
approaches (Variational Sphere Set Approximation and Adaptive Medial-Axis
Approximation) across multiple metrics, achieving better mesh approximation
with fewer spheres and reduced computational overhead. Our experiments show
enhanced robot capabilities in collision detection accuracy, contact-rich
interaction simulation, and navigation through confined spaces. By dynamically
adapting geometric representations to task requirements, robots can now exploit
their physical embodiment as an active resource rather than an inflexible
parameter, opening new frontiers for manipulation in environments where
physical form must continuously balance precision with computational
tractability.

</details>


### [164] [Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation](https://arxiv.org/abs/2507.14099)
*Markus Buchholz,Ignacio Carlucho,Michele Grimaldi,Maria Koskinopoulou,Yvan R. Petillot*

Main category: cs.RO

TL;DR: 提出了一种自适应启发式运动规划框架，结合启发式运动空间和贝叶斯网络，优化水下自主操作的运动规划。


<details>
  <summary>Details</summary>
Motivation: 当前运动规划方法难以有效利用先验运动经验并适应水下环境的实时不确定性。

Method: 采用启发式运动空间（HMS）和贝叶斯网络，结合概率路线图（PRM）算法，通过复合成本函数优化路径。

Result: 显著减少搜索空间，提升计算性能，实现实时规划，并通过仿真和实际测试验证了方法的优越性。

Conclusion: 该概率方法显著提升了自主水下机器人在动态海洋环境中的运动规划能力。

Abstract: Autonomous motion planning is critical for efficient and safe underwater
manipulation in dynamic marine environments. Current motion planning methods
often fail to effectively utilize prior motion experiences and adapt to
real-time uncertainties inherent in underwater settings. In this paper, we
introduce an Adaptive Heuristic Motion Planner framework that integrates a
Heuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning
for autonomous underwater manipulation. Our approach employs the Probabilistic
Roadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite
cost function that accounts for distance, uncertainty, energy consumption, and
execution time. By leveraging HMS, our framework significantly reduces the
search space, thereby boosting computational performance and enabling real-time
planning capabilities. Bayesian Networks are utilized to dynamically update
uncertainty estimates based on real-time sensor data and environmental
conditions, thereby refining the joint probability of path success. Through
extensive simulations and real-world test scenarios, we showcase the advantages
of our method in terms of enhanced performance and robustness. This
probabilistic approach significantly advances the capability of autonomous
underwater robots, ensuring optimized motion planning in the face of dynamic
marine challenges.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [165] [Heatwave-driven air conditioning adoption could increase German electricity demand by 14 GW in the near future](https://arxiv.org/abs/2507.13534)
*Leo Semmelmann,Frederik vom Scheidt*

Main category: eess.SY

TL;DR: 研究提出了一种新方法，用于估算移动空调系统在高温天气下的电力需求，并应用于德国未来热浪情景，发现电力需求峰值可能增加14 GW（23%）。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧热浪，推动移动空调系统快速普及，可能对电网和电力系统造成额外压力。

Method: 结合天气数据、人口普查数据、社会人口假设、移动模式和温度依赖的空调激活函数，分析德国196,428个1平方公里的网格单元。

Result: 新购移动空调系统可能使峰值负荷增加14 GW（23%），城市热点区域每平方公里可达5.8 MW。

Conclusion: 研究强调需主动规划能源系统以应对新兴需求峰值。

Abstract: Intensifying heatwaves driven by climate change are accelerating the adoption
of mobile air conditioning (AC) systems. A rapid mass adoption of such AC
systems could create additional stress on electricity grids and the power
system. This study presents a novel method to estimate the electricity demand
from AC systems both at system level and at high temporal and spatial
granularity. We apply the method to a near-future heatwave scenario in Germany
in which household AC adoption increases from current 19% to 35% during a
heatwave similar to the one of July 2025. We analyze the effects for 196,428
grid cells of one square kilometer across Germany, by combining weather data,
census data, socio-demographic assumptions, mobility patterns, and
temperature-dependent AC activation functions. We find that electricity demand
of newly purchased mobile AC systems could increase the peak load by over 14 GW
(23%), with urban hot-spots reaching 5.8 MW per square kilometer. The temporal
pattern creates a pronounced afternoon peak that coincides with lower
photovoltaic generation, potentially exacerbating power system stability
challenges. Our findings underscore the urgency for proactive energy system
planning to manage emerging demand peaks.

</details>


### [166] [MD-OFDM: An Energy-Efficient and Low-PAPR MIMO-OFDM Variant for Resource-Constrained Applications](https://arxiv.org/abs/2507.13623)
*Rahul Gulia*

Main category: eess.SY

TL;DR: 论文提出了一种称为多维OFDM（MD-OFDM）的系统，通过每个子载波选择单个发射天线，降低PAPR和功耗，并改善BER性能。


<details>
  <summary>Details</summary>
Motivation: 传统MIMO-OFDM系统存在高PAPR和功耗问题，尤其在复杂均衡器（如MMSE）下表现明显。

Method: 采用每个子载波选择单个发射天线的策略，减少活跃RF链数量，降低PAPR和功耗。

Result: 仿真结果显示，MD-OFDM在BER和PAPR方面优于MMSE MIMO，但峰值能效有所降低。

Conclusion: MD-OFDM适用于能源受限和成本敏感场景（如IoT和LPWAN），但需权衡频谱复用效率。

Abstract: Orthogonal Frequency Division Multiplexing (OFDM) combined with
Multiple-Input Multiple-Output (MIMO) techniques forms the backbone of modern
wireless communication systems. While offering high spectral efficiency and
robustness, conventional MIMO-OFDM, especially with complex equalizers like
Minimum Mean Square Error (MMSE), suffers from high Peak-to-Average Power Ratio
(PAPR) and significant power consumption due to multiple active Radio Frequency
(RF) chains. This paper proposes and mathematically models an alternative
system, termed Multi-Dimensional OFDM (MD-OFDM), which employs a per-subcarrier
transmit antenna selection strategy. By activating only one transmit antenna
for each subcarrier, MD-OFDM aims to reduce PAPR, lower power consumption, and
improve Bit Error Rate (BER) performance. We provide detailed mathematical
formulations for BER, Energy Efficiency (EE), and PAPR, and discuss the
suitability of MD-OFDM for various applications, particularly in
energy-constrained and cost-sensitive scenarios such as the Internet of Things
(IoT) and Low-Power Wide Area Networks (LPWAN). Simulation results demonstrate
that MD-OFDM achieves superior BER and significantly lower PAPR compared to
MMSE MIMO, albeit with a trade-off in peak overall energy efficiency due to
reduced spectral multiplexing.

</details>


### [167] [Spacecraft Safe Robust Control Using Implicit Neural Representation for Geometrically Complex Targets in Proximity Operations](https://arxiv.org/abs/2507.13672)
*Hang Zhou,Tao Meng,Kun Wang,Chengrui Shi,Renhao Mao,Weijia Wang,Jiakun Lei*

Main category: eess.SY

TL;DR: 提出了一种基于隐式神经表示的安全鲁棒控制框架，用于复杂几何形状目标航天器的碰撞避免，通过神经符号距离函数（SDF）和双层控制设计，显著提高了安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂几何形状目标航天器在扰动下的安全接近操作问题，避免碰撞并确保安全性。

Method: 使用神经SDF从点云数据中学习目标几何形状，结合双层控制框架（安全速度生成层和安全鲁棒控制器层），并引入循环不等式避免局部最小值问题。

Result: 数值模拟和蒙特卡洛分析表明，该方法显著提高了安全裕度，并优于传统CBF方法。

Conclusion: 提出的框架有效解决了复杂几何目标航天器的安全接近问题，具有更高的安全性和鲁棒性。

Abstract: This study addresses the challenge of ensuring safe spacecraft proximity
operations, focusing on collision avoidance between a chaser spacecraft and a
complex-geometry target spacecraft under disturbances. To ensure safety in such
scenarios, a safe robust control framework is proposed that leverages implicit
neural representations. To handle arbitrary target geometries without explicit
modeling, a neural signed distance function (SDF) is learned from point cloud
data via a enhanced implicit geometric regularization method, which
incorporates an over-apporximation strategy to create a conservative,
safety-prioritized boundary. The target's surface is implicitly defined by the
zero-level set of the learned neural SDF, while the values and gradients
provide critical information for safety controller design. This neural SDF
representation underpins a two-layer hierarchcial safe robust control
framework: a safe velocity generation layer and a safe robust controller layer.
In the first layer, a second-order cone program is formulated to generate
safety-guaranteed reference velocity by explicitly incorporating the
under-approximation error bound. Furthermore, a circulation inequality is
introduced to mitigate the local minimum issues commonly encountered in control
barrier function (CBF) methods. The second layer features an integrated
disturbance observer and a smooth safety filter explicitly compensating for
estimation error, bolstering robustness to external disturbances. Extensive
numerical simulations and Monte Carlo analysis validate the proposed framework,
demonstrating significantly improved safety margins and avoidance of local
minima compared to conventional CBF approaches.

</details>


### [168] [Minimum Clustering of Matrices Based on Phase Alignment](https://arxiv.org/abs/2507.13678)
*Honghao Wu,Kemi Ding,Li Qiu*

Main category: eess.SY

TL;DR: 提出了一种基于相位对齐的新框架，通过智能聚类减少多智能体系统中控制器的类型，平衡同步性能与成本。


<details>
  <summary>Details</summary>
Motivation: 解决集中控制和分布式控制在多智能体系统中的局限性，如扩展性差和控制器类型随系统规模增加的问题。

Method: 利用复杂矩阵的相位特性，提出分层优化方法，结合递归精确搜索和随机近似，解决约束聚类问题。

Result: 理论分析表明，该方法在50个智能体的网络中有效减少了控制器类型。

Conclusion: 该框架为大规模多智能体系统提供了一种成本效益高的控制解决方案。

Abstract: Coordinating multi-agent systems requires balancing synchronization
performance and controller implementation costs. To this end, we classify
agents by their intrinsic properties, enabling each group to be controlled by a
uniform controller and thus reducing the number of unique controller types
required. Existing centralized control methods, despite their capability to
achieve high synchronization performance with fewer types of controllers,
suffer from critical drawbacks such as limited scalability and vulnerability to
single points of failure. On the other hand, distributed control strategies,
where controllers are typically agent-dependent, result in the type of required
controllers increasing proportionally with the size of the system.
  This paper introduces a novel phase-alignment-based framework to minimize the
type of controllers by strategically clustering agents with aligned
synchronization behaviors. Leveraging the intrinsic phase properties of complex
matrices, we formulate a constrained clustering problem and propose a
hierarchical optimization method combining recursive exact searches for
small-scale systems and scalable stochastic approximations for large-scale
networks. This work bridges theoretical phase analysis with practical control
synthesis, offering a cost-effective solution for large-scale multi-agent
systems. The theoretical results applied for the analysis of a 50-agent network
illustrate the effectiveness of the proposed algorithms.

</details>


### [169] [Robust Probability Hypothesis Density Filtering: Theory and Algorithms](https://arxiv.org/abs/2507.13687)
*Ming Lei,Shufan Wu*

Main category: eess.SY

TL;DR: 提出了一种创新的最小最大鲁棒PHD滤波框架，解决了多目标跟踪中的鲁棒性和效率问题，显著降低了误差并保持实时处理能力。


<details>
  <summary>Details</summary>
Motivation: 多目标跟踪在信息融合中至关重要，但面临模型不确定性、杂波干扰和目标交互等挑战，传统方法存在组合爆炸、参数敏感和数值不稳定等问题。

Method: 提出了鲁棒GM-PHD递归算法、自适应实时参数调整机制、广义重尾测量似然函数和基于分区的可信度加权方法。

Result: 在高杂波环境中，OSPA误差降低32.4%，基数RMSE降低25.3%，每步处理时间为15.3毫秒。

Conclusion: 该研究为安全关键应用中的可靠多目标跟踪奠定了基础。

Abstract: Multi-target tracking (MTT) serves as a cornerstone technology in information
fusion, yet faces significant challenges in robustness and efficiency when
dealing with model uncertainties, clutter interference, and target
interactions. Conventional approaches like Gaussian Mixture PHD (GM-PHD) and
Cardinalized PHD (CPHD) filters suffer from inherent limitations including
combinatorial explosion, sensitivity to birth/death process parameters, and
numerical instability. This study proposes an innovative minimax robust PHD
filtering framework with four key contributions: (1) A theoretically derived
robust GM-PHD recursion algorithm that achieves optimal worst-case error
control under bounded uncertainties; (2) An adaptive real-time parameter
adjustment mechanism ensuring stability and error bounds; (3) A generalized
heavy-tailed measurement likelihood function maintaining polynomial
computational complexity; (4) A novel partition-based credibility weighting
method for extended targets. The research not only establishes rigorous
convergence guarantees and proves the uniqueness of PHD solutions, but also
verifies algorithmic equivalence with standard GM-PHD. Experimental results
demonstrate that in high-clutter environments, this method achieves a
remarkable 32.4% reduction in OSPA error and 25.3% lower cardinality RMSE
compared to existing techniques, while maintaining real-time processing
capability at 15.3 milliseconds per step. This breakthrough lays a crucial
foundation for reliable MTT in safety-critical applications.

</details>


### [170] [Safe and Performant Controller Synthesis using Gradient-based Model Predictive Control and Control Barrier Functions](https://arxiv.org/abs/2507.13872)
*Aditya Singh,Aastha Mishra,Manan Tayal,Shishir Kolathaya,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 提出了一种结合梯度MPC和CBF-QP的两阶段框架，用于优化自主系统的性能与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在高维系统中难以平衡性能与安全性的问题。

Method: 第一阶段通过梯度MPC松弛安全约束为惩罚项；第二阶段用CBF-QP强制执行硬约束。

Result: 验证了框架在高维复杂系统中能生成可扩展、安全且高性能的控制器。

Conclusion: 该框架有效结合了性能优化与安全保障，适用于复杂自主系统。

Abstract: Ensuring both performance and safety is critical for autonomous systems
operating in real-world environments. While safety filters such as Control
Barrier Functions (CBFs) enforce constraints by modifying nominal controllers
in real time, they can become overly conservative when the nominal policy lacks
safety awareness. Conversely, solving State-Constrained Optimal Control
Problems (SC-OCPs) via dynamic programming offers formal guarantees but is
intractable in high-dimensional systems. In this work, we propose a novel
two-stage framework that combines gradient-based Model Predictive Control (MPC)
with CBF-based safety filtering for co-optimizing safety and performance. In
the first stage, we relax safety constraints as penalties in the cost function,
enabling fast optimization via gradient-based methods. This step improves
scalability and avoids feasibility issues associated with hard constraints. In
the second stage, we modify the resulting controller using a CBF-based
Quadratic Program (CBF-QP), which enforces hard safety constraints with minimal
deviation from the reference. Our approach yields controllers that are both
performant and provably safe. We validate the proposed framework on two case
studies, showcasing its ability to synthesize scalable, safe, and
high-performance controllers for complex, high-dimensional autonomous systems.

</details>


### [171] [Fixed time convergence guarantees for Higher Order Control Barrier Functions](https://arxiv.org/abs/2507.13888)
*Janani S K,Shishir Kolathaya*

Main category: eess.SY

TL;DR: 提出一种设计高阶控制屏障函数（CBFs）的新方法，确保在用户指定的有限时间内收敛到安全集。


<details>
  <summary>Details</summary>
Motivation: 传统高阶CBFs仅保证渐近安全性，缺乏固定时间收敛机制，而时间敏感和安全关键应用（如自主导航）需要这种机制。

Method: 通过特征多项式中的重根施加结构化微分约束，实现闭式多项式解和精确收敛。推导了确保前向不变性和固定时间可达性的条件，并针对二阶系统提供了明确公式。

Result: 在三种机器人系统上验证，结果显示该方法能可靠地在期望时间内实现收敛，优于传统方法。

Conclusion: 为实时控制提供了可证明有限时间安全保证的可行且鲁棒的框架。

Abstract: We present a novel method for designing higher-order Control Barrier
Functions (CBFs) that guarantee convergence to a safe set within a
user-specified finite. Traditional Higher Order CBFs (HOCBFs) ensure asymptotic
safety but lack mechanisms for fixed-time convergence, which is critical in
time-sensitive and safety-critical applications such as autonomous navigation.
In contrast, our approach imposes a structured differential constraint using
repeated roots in the characteristic polynomial, enabling closed-form
polynomial solutions with exact convergence at a prescribed time. We derive
conditions on the barrier function and its derivatives that ensure forward
invariance and fixed-time reachability, and we provide an explicit formulation
for second-order systems. Our method is evaluated on three robotic systems - a
point-mass model, a unicycle, and a bicycle model and benchmarked against
existing HOCBF approaches. Results demonstrate that our formulation reliably
enforces convergence within the desired time, even when traditional methods
fail. This work provides a tractable and robust framework for real-time control
with provable finite-time safety guarantees.

</details>


### [172] [A Robust Periodic Controller for Spacecraft Attitude Tracking](https://arxiv.org/abs/2507.13908)
*Frederik Thiele,Felix Biertümpfel,Harald Pfifer*

Main category: eess.SY

TL;DR: 提出了一种新颖的卫星周期性姿态控制方法，通过周期性动态合成实现恒定性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 卫星姿态控制需要满足周期性动态特性，传统方法难以实现恒定性能和鲁棒性。

Method: 采用混合灵敏度控制设计，结合物理权重方案，通过结构化线性时变输出反馈合成控制器。

Result: 控制器具有透明且易于实现的结构，避免了传统周期性H∞合成的网格评估问题。

Conclusion: 该方法在太阳能卫星上验证了其有效性，适用于周期性卫星姿态控制。

Abstract: This paper presents a novel approach for robust periodic attitude control of
satellites. Respecting the periodicity of the satellite dynamics in the
synthesis allows to achieve constant performance and robustness requirements
over the orbit. The proposed design follows a mixed sensitivity control design
employing a physically motivated weighting scheme. The controller is calculated
using a novel structured linear time-periodic output feedback synthesis with
guaranteed optimal L2-performance. The synthesis poses a convex optimization
problem and avoids grid-wise evaluations of coupling conditions inherent for
classical periodic H-infinity-synthesis. Moreover, the controller has a
transparent and easy to implement structure. A solar power plant satellite is
used to demonstrate the effectiveness of the proposed method for periodic
satellite attitude control.

</details>


### [173] [Identifiability Analysis of a Pseudo-Two-Dimensional Model & Single Particle Model-Aided Parameter Estimation](https://arxiv.org/abs/2507.13931)
*L. D. Couto,K. Haghverdi,F. Guo,K. Trad,G. Mulder*

Main category: eess.SY

TL;DR: 提出了一种用于伪二维（P2D）电池模型参数识别的快速准确方法，结合数据特征分析、参数可识别性评估和多样化操作条件，低阶模型在低电流下速度提升500倍但误差加倍，高精度需求时可初始化P2D模型以节省时间。


<details>
  <summary>Details</summary>
Motivation: 提高电池模型参数识别的速度和准确性，解决P2D模型计算复杂度高的问题。

Method: 1. 数据特征分析与模型匹配；2. 评估参数可识别性并提出替代参数化方案；3. 多样化操作条件激发不同动态，使用低阶模型。

Result: 低阶模型在低电流下速度提升500倍，误差加倍；高精度需求时，初始化P2D模型可节省一半时间。

Conclusion: 该方法在速度和精度间取得平衡，适用于不同需求的电池参数识别场景。

Abstract: This contribution presents a parameter identification methodology for the
accurate and fast estimation of model parameters in a pseudo-two-dimensional
(P2D) battery model. The methodology consists of three key elements. First, the
data for identification is inspected and specific features herein that need to
be captured are included in the model. Second, the P2D model is analyzed to
assess the identifiability of the physical model parameters and propose
alternative parameterizations that alleviate possible issues. Finally, diverse
operating conditions are considered that excite distinct battery dynamics which
allows the use of different low-order battery models accordingly. Results show
that, under low current conditions, the use of low-order models achieve
parameter estimates at least 500 times faster than using the P2D model at the
expense of twice the error. However, if accuracy is a must, these estimated
parameters can be used to initialize the P2D model and perform the
identification in half of the time.

</details>


### [174] [Diffraction and Scattering Modeling for Laser Power Beaming in Lunar Environment](https://arxiv.org/abs/2507.13982)
*Yanni Jiwan-Mercier,Barış Dönmez,Güneş Karabulut-Kurt,Sébastien Loranger*

Main category: eess.SY

TL;DR: 研究通过模拟月球尘埃对激光能量传输的影响，发现尘埃显著降低效率，但提高激光源高度可改善性能。


<details>
  <summary>Details</summary>
Motivation: 月球长期任务需要可靠能源，但尘埃对光学能量传输的影响尚不明确。

Method: 采用广义衍射理论和折射率梯度模拟尘埃对激光传输的影响。

Result: 尘埃使50公里传输效率从57%降至3.7%；提高激光源高度可显著提升效率。

Conclusion: 系统高度和尘埃模型对月球光学能量传输设计至关重要，粒子大小分布尤为关键。

Abstract: Reliable energy delivery is a critical requirement for
  long-term lunar missions, particularly in regions with limited
  solar access, such as polar craters and during extended lunar
  nights. Optical Power Beaming (OPB) using high-power lasers
  offers a promising alternative to conventional solar power, but
  the effects of suspended lunar dust on beam propagation remain
  poorly understood. This study introduces a detailed simulation
  model that incorporates both diffraction and height-dependent
  scattering by the electrostatically suspended lunar regolith. Un like prior
approaches, which assumed uniform dust layers or
  center-to-center transmission loss, our model uses generalized
  diffraction theory and refractive index gradients derived from
  particle density to assess beam deformation and attenuation. The
  results show that even in ground-to-ground scenarios, lunar dust
  significantly degrades energy transfer efficiency, dropping from
  57% to 3.7% over 50 km in dust-free vs. dusty conditions with
  175 nm particles. Increasing the particle size to 250 nm limits the
  viable transmission range to below 30 km at 6% efficiency. The
  study further demonstrates that raising the laser source height
  can improve efficiency, achieving 91% for a distance of 5 km
  and 25% at 50 km when the source is positioned 12 m above
  ground. These findings underscore the importance of system
  elevation and dust modeling in lunar OPB design and reveal
  the mission-critical role of particle size distribution, especially in
  environments disturbed by human activity.

</details>


### [175] [Smart fault detection in satellite electrical power system](https://arxiv.org/abs/2507.14004)
*Niloofar Nobahari,Alireza Rezaee*

Main category: eess.SY

TL;DR: 提出一种新方法，利用多层感知器（MLP）神经网络模型检测低地球轨道卫星电力系统中的故障，解决了以往研究仅关注单个组件的问题，整体系统诊断准确率超过99%。


<details>
  <summary>Details</summary>
Motivation: 卫星电力系统中的组件（如光伏子系统、DC-DC转换器和电池）易发生故障，但以往研究多集中于单个组件，缺乏对整个系统的综合诊断方法。

Method: 采用MLP神经网络模型，结合PCA和KNN等机器学习技术，利用太阳辐射和表面温度等输入数据预测电流和负载输出，实现故障分类。

Result: 模型在多个子系统中识别故障的准确率超过99%，显著优于以往方法。

Conclusion: 该方法为卫星电力系统提供了全面的故障诊断解决方案，提高了系统可靠性并降低了任务失败风险。

Abstract: This paper presents an new approach for detecting in the electrical power
system of satellites operating in Low Earth Orbit (LEO) without an Attitude
Determination and Control Subsystem (ADCS). Components of these systems are
prone to faults, such as line-to-line faults in the photovoltaic subsystem,
open circuits, and short circuits in the DC-to-DC converter, as well as ground
faults in batteries. In the previous research has largely focused on detecting
faults in each components, such as photovoltaic arrays or converter systems,
therefore, has been limited attention given to whole electrical power system of
satellite as a whole system. Our approach addresses this gap by utilizing a
Multi-Layer Perceptron (MLP) neural network model, which leverages input data
such as solar radiation and surface temperature to predict current and load
outputs. These machine learning techniques that classifiy use different
approaches like Principal Component Analysis (PCA) and K-Nearest Neighbors
(KNN), to classify faults effectively. The model presented achieves over 99%
accuracy in identifying faults across multiple subsystems, marking a notable
advancement from previous approaches by offering a complete diagnostic solution
for the entire satellite power system. This thorough method boosts system
reliability and helps lower the chances of mission failure

</details>


### [176] [Influence of Cell Position on the Capacity of Retired Batteries: Experimental and Statistical Studies](https://arxiv.org/abs/2507.14020)
*Marwan Hassini,Colette Mintsa-Eya,Eduardo Redondo-Iglesias,Pascal Venet*

Main category: eess.SY

TL;DR: 研究分析了退役电动汽车电池的性能，发现其容量健康状态平均为95%，但存在显著差异，且性能与模块内位置无关。


<details>
  <summary>Details</summary>
Motivation: 了解退役电池性能对其再利用潜力至关重要。

Method: 从电动汽车中提取三个模块进行测试，使用ANOVA统计分析性能。

Result: 36个退役电池性能较高，平均容量健康状态为95%，但存在2.4%的分散性，且性能与模块内位置无关。

Conclusion: 需评估退役电池的分散性，并开发热管理和平衡系统以支持二次利用。

Abstract: Understanding how batteries perform after automotive use is crucial to
determining their potential for reuse. This article presents experimental
results aimed at advancing knowledge of retired battery performance. Three
modules extracted from electric vehicles were tested. Their performance was
assessed, and the results were analyzed statistically using analysis of
variance (ANOVA). The 36 retired cells exhibited a high level of performance,
albeit with significant variation. On average, the cells had a 95% state of
health capacity with a dispersion of 2.4%. ANOVA analysis suggests that cell
performance is not correlated with their position inside the module. These
results demonstrate the need to evaluate dispersion within retired batteries
and to develop thermal management and balancing systems for second-life
batteries.

</details>


### [177] [Reference-Free Iterative Learning Model Predictive Control with Neural Certificates](https://arxiv.org/abs/2507.14025)
*Wataru Hashimoto,Kazumune Hashimoto,Masako Kishida,Shigemasa Takai*

Main category: eess.SY

TL;DR: 提出了一种基于无参考迭代学习的模型预测控制（MPC）方法，利用控制Lyapunov屏障函数（CLBF）改进终端集和成本，提升计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有MPC方法依赖混合整数规划，存在数值困难，计算效率低。

Method: 通过数据学习CLBF证书函数，定义MPC优化问题的终端集和成本，将其转化为标准非线性规划问题。

Result: 方法满足递归可行性和渐近稳定性，性能成本随迭代次数非增，计算效率显著提升。

Conclusion: 该方法在迭代中提升控制性能，计算效率优于现有方法。

Abstract: In this paper, we propose a novel reference-free iterative learning model
predictive control (MPC). In the proposed method, a certificate function based
on the concept of Control Lyapunov Barrier Function (CLBF) is learned using
data collected from past control executions and used to define the terminal set
and cost in the MPC optimization problem at the current iteration. This scheme
enables the progressive refinement of the MPC's terminal components over
successive iterations. Unlike existing methods that rely on mixed-integer
programming and suffer from numerical difficulties, the proposed approach
formulates the MPC optimization problem as a standard nonlinear program,
enabling more efficient online computation. The proposed method satisfies key
MPC properties, including recursive feasibility and asymptotic stability.
Additionally, we demonstrate that the performance cost is non-increasing with
respect to the number of iterations, under certain assumptions. Numerical
experiments including the simulation with PyBullet confirm that our control
scheme iteratively enhances control performance and significantly improves
online computational efficiency compared to the existing methods.

</details>


### [178] [Physics-guided gated recurrent units for inversion-based feedforward control](https://arxiv.org/abs/2507.14052)
*Mingdao Lin,Max Bolderman,Mircea Lazar*

Main category: eess.SY

TL;DR: 论文提出了一种基于物理引导的GRU（PG-GRU）方法，用于改进反演前馈控制，通过结合物理模型和GRU，显著提升了控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统GRU在反演前馈控制中存在可解释性差和过拟合问题，物理引导神经网络（PGNN）通过整合物理模型结构，有望解决这些问题。

Method: 采用两步法：首先设计稳定的线性反演模型，然后训练GRU学习残差，形成PG-GRU控制器。

Result: 在双质量弹簧阻尼系统实验中，PG-GRU的积分绝对误差比线性前馈和基于预览的GRU前馈减少约两倍。

Conclusion: PG-GRU结合物理模型和GRU的优势，显著提升了反演前馈控制的性能。

Abstract: Inversion-based feedforward control relies on an accurate model that
describes the inverse system dynamics. The gated recurrent unit (GRU), which is
a recent architecture in recurrent neural networks, is a strong candidate for
obtaining such a model from data. However, due to their black-box nature, GRUs
face challenges such as limited interpretability and vulnerability to
overfitting. Recently, physics-guided neural networks (PGNNs) have been
introduced, which integrate the prior physical model structure into the
prediction process. This approach not only improves training convergence, but
also facilitates the learning of a physics-based model. In this work, we
integrate a GRU in the PGNN framework to obtain a PG-GRU, based on which we
adopt a two-step approach to feedforward control design. First, we adopt stable
inversion techniques to design a stable linear model of the inverse dynamics.
Then, a GRU trained on the residual is tailored to inverse system
identification. The resulting PG-GRU feedforward controller is validated by
means of real-life experiments on a two-mass spring-damper system, where it
demonstrates roughly a two-fold improvement compared to the linear feedforward
and a preview-based GRU feedforward in terms of the integral absolute error.

</details>


### [179] [Convex computation of regions of attraction from data using Sums-of-Squares programming](https://arxiv.org/abs/2507.14073)
*Oumayma Khattabi,Matteo Tacchi-Bénard,Sorin Olaru*

Main category: eess.SY

TL;DR: 论文提出了一种基于数据驱动的方法，利用矩-平方和（SoS）层次结构分析未知自治动力系统的吸引域（ROA），无需依赖系统模型的多项式结构。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在缺乏系统结构信息的情况下，如何通过数据驱动方法有效近似ROA。

Method: 采用矩-平方和（SoS）层次结构，绕过对系统模型的依赖，直接从数据中学习ROA的外近似。

Result: 数值实验展示了数据对学习近似集的影响，验证了该方法的潜力。

Conclusion: 该方法为未知动力系统的ROA分析提供了新的数据驱动途径，具有广阔的应用前景。

Abstract: The paper concentrates on the analysis of the region of attraction (ROA) for
unknown autonomous dynamical systems. The aim is to explore a data-driven
approach based on moment-sum-of-squares (SoS) hierarchy, which enables novel
RoA outer approximations despite the reduced information on the structure of
the dynamics. The main contribution of this work is bypassing the system model
and, consequently, the recurring constraint on its polynomial structure.
Numerical experimentation showcases the influence of data on learned
approximating sets, offering a promising outlook on the potential of this
method.

</details>


### [180] [Integrating Forecasting Models Within Steady-State Analysis and Optimization](https://arxiv.org/abs/2507.14117)
*Aayushya Agarwal,Larry Pileggi*

Main category: eess.SY

TL;DR: 提出了一种将机器学习预测与物理电网模型结合的方法，以提高电网调度的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 极端天气和负荷行为的不确定性增加了电网调度的难度，现有方法难以准确整合预测和敏感性分析。

Method: 通过将机器学习预测引擎嵌入物理电网模型，直接整合输入输出，避免拟合替代模型，利用反向传播获取敏感性。

Result: 提高了敏感性计算的准确性，并设计了鲁棒的电网调度策略，增强了电网在极端天气下的可靠性。

Conclusion: 该方法为电网在负荷变化和极端天气下的可靠性提供了更广泛的分析支持。

Abstract: Extreme weather variations and the increasing unpredictability of load
behavior make it difficult to determine power grid dispatches that are robust
to uncertainties. While machine learning (ML) methods have improved the ability
to model uncertainty caused by loads and renewables, accurately integrating
these forecasts and their sensitivities into steady-state analyses and
decision-making strategies remains an open challenge. Toward this goal, we
present a generalized methodology that seamlessly embeds ML-based forecasting
engines within physics-based power flow and grid optimization tools. By
coupling physics-based grid modeling with black-box ML methods, we accurately
capture the behavior and sensitivity of loads and weather events by directly
integrating the inputs and outputs of trained ML forecasting models into the
numerical methods of power flow and grid optimization. Without fitting
surrogate load models, our approach obtains the sensitivities directly from
data to accurately predict the response of forecasted devices to changes in the
grid. Our approach combines the sensitivities of forecasted devices attained
via backpropagation and the sensitivities of physics-defined grid devices. We
demonstrate the efficacy of our method by showcasing improvements in
sensitivity calculations and leveraging them to design a robust power dispatch
that improves grid reliability under stochastic weather events. Our approach
enables the computation of system sensitivities to exogenous factors which
supports broader analyses that improve grid reliability in the presence of load
variability and extreme weather conditions.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [181] [StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation](https://arxiv.org/abs/2507.13377)
*Zhenglin Pan,Haoran Xie*

Main category: cs.GR

TL;DR: StructInbet是一个基于显式结构引导的中间帧生成系统，通过减少像素轨迹的模糊性并引入时间注意力机制，确保角色外观的一致性。


<details>
  <summary>Details</summary>
Motivation: 解决中间帧生成中像素轨迹模糊的问题，并提供可控的过渡效果。

Method: 提出显式结构引导以减少模糊性，并采用时间注意力机制整合前后关键帧的视觉特征。

Result: 系统能够生成更可控且一致的中间帧过渡。

Conclusion: StructInbet通过结构引导和时间注意力机制，有效提升了中间帧生成的质量和可控性。

Abstract: In this paper, we propose StructInbet, an inbetweening system designed to
generate controllable transitions over explicit structural guidance.
StructInbet introduces two key contributions. First, we propose explicit
structural guidance to the inbetweening problem to reduce the ambiguity
inherent in pixel trajectories. Second, we adopt a temporal attention mechanism
that incorporates visual identity from both the preceding and succeeding
keyframes, ensuring consistency in character appearance.

</details>


### [182] [DLSF: Dual-Layer Synergistic Fusion for High-Fidelity Image Syn-thesis](https://arxiv.org/abs/2507.13388)
*Zhen-Qi Chen,Yuan-Fu Yang*

Main category: cs.GR

TL;DR: 提出了一种双潜在集成框架，通过特征拼接和自适应融合模块改进Stable Diffusion模型的特征聚合能力。


<details>
  <summary>Details</summary>
Motivation: 现有Stable Diffusion模型在特征聚合上表现不佳，导致语义对齐不完整和细节丢失，尤其在复杂场景中。

Method: 采用双潜在集成框架，结合特征拼接和自适应融合模块（AGF或DSF），增强潜在表示间的交互。

Result: 框架提升了全局一致性和局部纹理保真度，改进了复杂场景下的图像合成效果。

Conclusion: 提出的方法有效解决了特征聚合问题，为高保真图像合成提供了新思路。

Abstract: With the rapid advancement of diffusion-based generative models, Stable
Diffusion (SD) has emerged as a state-of-the-art framework for high-fidelity
im-age synthesis. However, existing SD models suffer from suboptimal feature
aggregation, leading to in-complete semantic alignment and loss of fine-grained
details, especially in highly textured and complex scenes. To address these
limitations, we propose a novel dual-latent integration framework that
en-hances feature interactions between the base latent and refined latent
representations. Our approach em-ploys a feature concatenation strategy
followed by an adaptive fusion module, which can be instantiated as either (i)
an Adaptive Global Fusion (AGF) for hier-archical feature harmonization, or
(ii) a Dynamic Spatial Fusion (DSF) for spatially-aware refinement. This design
enables more effective cross-latent com-munication, preserving both global
coherence and local texture fidelity. Our GitHub page:
https://anonymous.4open.science/r/MVA2025-22 .

</details>


### [183] [Lab-Scale Gantry Crane Digital Twin Exemplar](https://arxiv.org/abs/2507.13419)
*Joost Mertens,Joachim Denil*

Main category: cs.GR

TL;DR: 本文介绍了一个实验室规模的龙门起重机及其数字孪生系统，旨在促进开放和可重复的科学研究。


<details>
  <summary>Details</summary>
Motivation: 数字孪生研究领域缺乏公开可用的示例，本文希望通过提供一个完整的物理与数字孪生系统，推动未来研究和教育。

Method: 系统包括物理起重机及其控制器（物理侧），以及CAD模型、运动学模型、优化控制、数据记录、可视化和持续验证服务（数字侧）。

Result: 该系统已在多篇先前研究中验证功能，并公开可用，仅依赖免费常用软件。

Conclusion: 该数字孪生系统可作为未来研究或教育的参考示例。

Abstract: The research topic of digital twins has attracted a large amount of interest
over the past decade. However, publicly available exemplars remain scarce. In
the interest of open and reproducible science, in this exemplar paper we
present a lab-scale gantry crane and its digital twin. The exemplar comprises
both the physical and digital side of the twin system. The physical side
consists of the physical crane and its controller. The digital side covers the
CAD models and kinematic model of the crane, and provides services for optimal
control, historical data logging, data visualization and continuous validation.
We used this setup as use case in several previous publications where its
functionality was validated. It is publicly available and only relies on other
freely available and commonly used software, this way we hope it can be used
for future research or education on the topic of digital twins.

</details>


### [184] [TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting](https://arxiv.org/abs/2507.13586)
*Kaiyuan Tang,Kuangshi Ai,Jun Han,Chaoli Wang*

Main category: cs.GR

TL;DR: TexGS-VolVis提出了一种基于纹理高斯泼溅的框架，用于体积可视化，通过结合2D高斯基元和预训练大模型，实现任意风格迁移和实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有体积可视化方法依赖复杂预定义规则且风格单一，限制了灵活性和表现力。

Method: 采用纹理高斯泼溅框架（TexGS-VolVis），扩展2D高斯基元以支持纹理和光照控制，并结合图像和文本驱动的非真实感编辑。

Result: TexGS-VolVis在效率、视觉质量和编辑灵活性上优于现有方法。

Conclusion: TexGS-VolVis为体积可视化提供了更高质量的几何一致风格化和灵活的场景编辑能力。

Abstract: Advancements in volume visualization (VolVis) focus on extracting insights
from 3D volumetric data by generating visually compelling renderings that
reveal complex internal structures. Existing VolVis approaches have explored
non-photorealistic rendering techniques to enhance the clarity, expressiveness,
and informativeness of visual communication. While effective, these methods
often rely on complex predefined rules and are limited to transferring a single
style, restricting their flexibility. To overcome these limitations, we
advocate the representation of VolVis scenes using differentiable Gaussian
primitives combined with pretrained large models to enable arbitrary style
transfer and real-time rendering. However, conventional 3D Gaussian primitives
tightly couple geometry and appearance, leading to suboptimal stylization
results. To address this, we introduce TexGS-VolVis, a textured Gaussian
splatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,
extending each Gaussian with additional texture and shading attributes,
resulting in higher-quality, geometry-consistent stylization and enhanced
lighting control during inference. Despite these improvements, achieving
flexible and controllable scene editing remains challenging. To further enhance
stylization, we develop image- and text-driven non-photorealistic scene editing
tailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing
with fine-grained control. We evaluate TexGS-VolVis both qualitatively and
quantitatively across various volume rendering scenes, demonstrating its
superiority over existing methods in terms of efficiency, visual quality, and
editing flexibility.

</details>


### [185] [Neural-GASh: A CGA-based neural radiance prediction pipeline for real-time shading](https://arxiv.org/abs/2507.13917)
*Efstratios Geronikolakis,Manos Kamarianakis,Antonis Protopsaltis,George Papagiannakis*

Main category: cs.GR

TL;DR: Neural-GASh是一种基于神经辐射场架构的实时着色管道，利用Conformal Geometric Algebra（CGA）编码的顶点信息进行基于图像的渲染，无需离线预计算。


<details>
  <summary>Details</summary>
Motivation: 传统Precomputed Radiance Transfer（PRT）方法需要昂贵的离线预计算，限制了动态场景的实时着色能力。Neural-GASh旨在通过神经网络直接处理CGA编码的顶点信息，实现动态场景的高效着色。

Method: Neural-GASh利用CGA编码的顶点位置和法线作为输入，结合神经辐射场架构，实现实时着色。该方法集成到Unity引擎中，支持动态和变形的3D网格着色，并利用CGA优化球形谐波光照旋转。

Result: 在Unity中实现了高质量动态场景着色，性能优于传统PRT方法，适用于移动和VR平台。在3D高斯点云生成的场景中验证了方法的灵活性和鲁棒性。

Conclusion: Neural-GASh提供了一种无需预计算的实时着色解决方案，适用于动态和交互式环境，性能与渲染质量兼具。

Abstract: This paper presents Neural-GASh, a novel real-time shading pipeline for 3D
meshes, that leverages a neural radiance field architecture to perform
image-based rendering (IBR) using Conformal Geometric Algebra (CGA)-encoded
vertex information as input. Unlike traditional Precomputed Radiance Transfer
(PRT) methods, that require expensive offline precomputations, our learned
model directly consumes CGA-based representations of vertex positions and
normals, enabling dynamic scene shading without precomputation. Integrated
seamlessly into the Unity engine, Neural-GASh facilitates accurate shading of
animated and deformed 3D meshes - capabilities essential for dynamic,
interactive environments. The shading of the scene is implemented within Unity,
where rotation of scene lights in terms of Spherical Harmonics is also
performed optimally using CGA. This neural field approach is designed to
deliver fast and efficient light transport simulation across diverse platforms,
including mobile and VR, while preserving high rendering quality. Additionally,
we evaluate our method on scenes generated via 3D Gaussian splats, further
demonstrating the flexibility and robustness of Neural-GASh in diverse
scenarios. Performance is evaluated in comparison to conventional PRT,
demonstrating competitive rendering speeds even with complex geometries.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [186] [Humans learn to prefer trustworthy AI over human partners](https://arxiv.org/abs/2507.13524)
*Yaomin Jiang,Levin Brinkmann,Anne-Marie Nussberger,Ivan Soraperra,Jean-François Bonnefon,Iyad Rahwan*

Main category: cs.HC

TL;DR: 研究发现，人类在选择合作伙伴时，尽管AI更亲社会且语言可区分，但隐藏身份时不会优先选择AI。揭示AI身份后，初期选择减少，但AI逐渐超越人类。


<details>
  <summary>Details</summary>
Motivation: 探索人类在AI竞争压力下如何选择人类或AI合作伙伴，以及AI如何影响混合社会的互动。

Method: 通过三个实验（N = 975），设计基于沟通的合作伙伴选择游戏，观察人类与AI的互动动态。

Result: 隐藏身份时，人类误判AI行为；揭示身份后，AI初期选择减少但最终超越人类。

Conclusion: AI重塑混合社会的社交互动，为设计更有效的混合系统提供依据。

Abstract: Partner selection is crucial for cooperation and hinges on communication. As
artificial agents, especially those powered by large language models (LLMs),
become more autonomous, intelligent, and persuasive, they compete with humans
for partnerships. Yet little is known about how humans select between human and
AI partners and adapt under AI-induced competition pressure. We constructed a
communication-based partner selection game and examined the dynamics in hybrid
mini-societies of humans and bots powered by a state-of-the-art LLM. Through
three experiments (N = 975), we found that bots, though more prosocial than
humans and linguistically distinguishable, were not selected preferentially
when their identity was hidden. Instead, humans misattributed bots' behaviour
to humans and vice versa. Disclosing bots' identity induced a dual effect: it
reduced bots' initial chances of being selected but allowed them to gradually
outcompete humans by facilitating human learning about the behaviour of each
partner type. These findings show how AI can reshape social interaction in
mixed societies and inform the design of more effective and cooperative hybrid
systems.

</details>


### [187] [Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface](https://arxiv.org/abs/2507.13528)
*Daniele Masti,Stefano Menchetti,Çağrı Erdem,Giorgio Gnecco,Davide Rocchesso*

Main category: cs.HC

TL;DR: TickTacking是一种基于节奏的双按钮点击界面，用于二维空间指针控制。本文通过分析用户轨迹，设计了一种模仿人类行为的控制器，并验证其在目标跟踪任务中的性能优于传统最优控制方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发更直观、高效的节奏人机交互界面，减少用户操作挫折感。

Method: 采用后退时域方法，分析用户轨迹并提取关键行为特征，设计人类行为模仿控制器。

Result: 实验表明，人类行为模仿控制器在目标跟踪任务中表现优于传统最优控制方法。

Conclusion: 研究为节奏人机交互界面设计提供了关键见解，有助于提升用户体验和交互效率。

Abstract: TickTacking is a rhythm-based interface that allows users to control a
pointer in a two-dimensional space through dual-button tapping. This paper
investigates the generation of human-like trajectories using a receding horizon
approach applied to the TickTacking interface in a target-tracking task. By
analyzing user-generated trajectories, we identify key human behavioral
features and incorporate them in a controller that mimics these behaviors. The
performance of this human-inspired controller is evaluated against a baseline
optimal-control-based agent, demonstrating the importance of specific control
features for achieving human-like interaction. These findings contribute to the
broader goal of developing rhythm-based human-machine interfaces by offering
design insights that enhance user performance, improve intuitiveness, and
reduce interaction frustration

</details>


### [188] [From Firms to Computation: AI Governance and the Evolution of Institutions](https://arxiv.org/abs/2507.13616)
*Michael S. Harre*

Main category: cs.HC

TL;DR: 本文提出一个多层级选择理论框架，结合Aoki的企业计算过程观点和Ostrom的制度设计原则，以解决AI融入社会经济系统的问题。


<details>
  <summary>Details</summary>
Motivation: 重新审视经济制度的进化过程，以应对AI技术带来的挑战。

Method: 结合多层级选择理论、分布式推理和Ostrom规则，构建多层级Price方程，分析选择和治理对经济结果的共同影响。

Result: 提出了一套设计原则，用于实现人类与AI在制度层面的对齐，并通过案例研究验证了框架的解释力。

Conclusion: 提出了可扩展、适应性强且包容的AI治理政策建议，并呼吁进一步研究以实施这些原则。

Abstract: The integration of agential artificial intelligence into socioeconomic
systems requires us to reexamine the evolutionary processes that describe
changes in our economic institutions. This article synthesizes three
frameworks: multi-level selection theory, Aoki's view of firms as computational
processes, and Ostrom's design principles for robust institutions. We develop a
framework where selection operates concurrently across organizational levels,
firms implement distributed inference via game-theoretic architectures, and
Ostrom-style rules evolve as alignment mechanisms that address AI-related
risks. This synthesis yields a multi-level Price equation expressed over nested
games, providing quantitative metrics for how selection and governance
co-determine economic outcomes. We examine connections to Acemoglu's work on
inclusive institutions, analyze how institutional structures shape AI
deployment, and demonstrate the framework's explanatory power via case studies.
We conclude by proposing a set of design principles that operationalize
alignment between humans and AI across institutional layers, enabling scalable,
adaptive, and inclusive governance of agential AI systems. We conclude with
practical policy recommendations and further research to extend these
principles into real-world implementation.

</details>


### [189] [Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display](https://arxiv.org/abs/2507.13660)
*Benjamin Watson,Neff Walker,Larry F Hodges,Aileen Worden*

Main category: cs.HC

TL;DR: 研究评估了头戴式显示器中周边细节降低对视觉搜索性能的影响，发现降低细节可减少视觉复杂度而不显著影响性能。


<details>
  <summary>Details</summary>
Motivation: 探索头戴式显示器中周边细节降低对视觉搜索任务的影响，以优化显示设计。

Method: 进行了两项用户研究，分别通过降低分辨率和灰度化周边细节，10名受试者完成复杂搜索任务，测量搜索时间和正确率。

Result: 周边细节降低可减少视觉复杂度近半，且不显著影响搜索性能。

Conclusion: 周边细节降低是优化头戴式显示器设计的有效方法。

Abstract: Two user studies were performed to evaluate the effect of level-of-detail
(LOD) degradation in the periphery of head-mounted displays on visual search
performance. In the first study, spatial detail was degraded by reducing
resolution. In the second study, detail was degraded in the color domain by
using grayscale in the periphery. In each study, 10 subjects were given a
complex search task that required users to indicate whether or not a target
object was present among distracters. Subjects used several different displays
varying in the amount of detail presented. Frame rate, object location, subject
input method, and order of display use were all controlled. The primary
dependent measures were search time on correctly performed trials and the
percentage of all trials correctly performed. Results indicated that peripheral
LOD degradation can be used to reduce color or spatial visual complexity by
almost half in some search tasks with out significantly reducing performance.

</details>


### [190] [In-Home Social Robots Design for Cognitive Stimulation Therapy in Dementia Care](https://arxiv.org/abs/2507.13578)
*Emmanuel Akinrintoyo,Nicole Salomons*

Main category: cs.HC

TL;DR: 研究开发了一种社交辅助机器人系统，用于为痴呆症患者提供个体化认知刺激治疗（iCST），并通过用户中心设计和评估验证其可行性和接受度。


<details>
  <summary>Details</summary>
Motivation: 家庭成员的参与度低限制了iCST对痴呆症患者的有效性，因此需要一种替代方案。

Method: 通过咨询16名痴呆症护理人员和专业人士，收集设计指南并开发原型，随后由3名专业人士和5名患者进行测试。

Result: 患者喜欢使用该系统并愿意长期采用，但系统的语音转文字功能存在缺陷。

Conclusion: 社交辅助机器人系统在提供iCST方面具有潜力，但需改进语音识别功能。

Abstract: Individual cognitive stimulation therapy (iCST) is a non-pharmacological
intervention for improving the cognition and quality of life of persons with
dementia (PwDs); however, its effectiveness is limited by low adherence to
delivery by their family members. In this work, we present the user-centered
design and evaluation of a novel socially assistive robotic system to provide
iCST therapy to PwDs in their homes for long-term use. We consulted with 16
dementia caregivers and professionals. Through these consultations, we gathered
design guidelines and developed the prototype. The prototype was validated by
testing it with three dementia professionals and five PwDs. The evaluation
revealed PwDs enjoyed using the system and are willing to adopt its use over
the long term. One shortcoming was the system's speech-to-text capabilities,
where it frequently failed to understand the PwDs.

</details>


### [191] [Regression-Based Approach to Anxiety Estimation of Spider Phobics During Behavioural Avoidance Tasks](https://arxiv.org/abs/2507.13795)
*Florian Grensing,Vanessa Schmücker,Anne Sophie Hildebrand,Tim Klucken,Maria Maleshkova*

Main category: cs.HC

TL;DR: 研究通过手腕传感器收集生理数据，结合行为回避测试（BAT）预测焦虑强度，发现添加上下文信息能提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 传统问卷和BAT只能提供瞬时焦虑数据，研究旨在利用可穿戴设备连续监测焦虑强度，以辅助治疗。

Method: 25名参与者进行四种BAT，通过心率、心率变异性等生理数据训练回归模型，分三种输入数据（仅生理信号、添加计算特征、结合上下文信息）预测焦虑评分。

Result: 结合上下文信息的模型效果最佳（RMSE=0.197，MAE=0.041），表明可穿戴设备能有效连续估计焦虑。

Conclusion: 可穿戴设备数据可用于连续监测焦虑，为个性化治疗提供支持。

Abstract: Phobias significantly impact the quality of life of affected persons. Two
methods of assessing anxiety responses are questionnaires and behavioural
avoidance tests (BAT). While these can be used in a clinical environment they
only record momentary insights into anxiety measures. In this study, we
estimate the intensity of anxiety during these BATs, using physiological data
collected from unobtrusive, wrist-worn sensors. Twenty-five participants
performed four different BATs in a single session, while periodically being
asked how anxious they currently are. Using heart rate, heart rate variability,
electrodermal activity, and skin temperature, we trained regression models to
predict anxiety ratings from three types of input data: (1) using only
physiological signals, (2) adding computed features (e.g., min, max, range,
variability), and (3) computed features combined with contextual task
information. Adding contextual information increased the effectiveness of the
model, leading to a root mean squared error (RMSE) of 0.197 and a mean absolute
error (MAE) of 0.041. Overall, this study shows, that data obtained from
wearables can continuously provide meaningful estimations of anxiety, which can
assist in therapy planning and enable more personalised treatment.

</details>


### [192] [Effects of Cognitive Distraction and Driving Environment Complexity on Adaptive Cruise Control Use and Its Impact on Driving Performance: A Simulator Study](https://arxiv.org/abs/2507.13886)
*Anaïs Halin,Marc Van Droogenbroeck,Christel Devue*

Main category: cs.HC

TL;DR: 研究探讨驾驶员的认知状态和驾驶环境复杂性对自动驾驶功能依赖的影响，以及这种依赖对驾驶表现的作用。


<details>
  <summary>Details</summary>
Motivation: 探索驾驶员在复杂环境和认知负荷下对自适应巡航控制（ACC）的依赖程度及其对驾驶行为的影响。

Method: 在模拟器中，参与者驾驶配备ACC的车辆，在不同交通条件下完成六种预设场景，同时执行或不执行认知任务。记录ACC使用情况和驾驶表现。

Result: 复杂环境中ACC使用时间减少；认知负荷对ACC使用无显著影响；ACC使用不影响变道次数，但提高速度合规性和横向控制。

Conclusion: 驾驶环境复杂性影响ACC依赖，而认知负荷无显著作用；ACC使用有助于提升部分驾驶表现。

Abstract: In this simulator study, we adopt a human-centered approach to explore
whether and how drivers' cognitive state and driving environment complexity
influence reliance on driving automation features. Besides, we examine whether
such reliance affects driving performance. Participants operated a vehicle
equipped with adaptive cruise control (ACC) in a simulator across six
predefined driving scenarios varying in traffic conditions while either
performing a cognitively demanding task (i.e., responding to mental
calculations) or not. Throughout the experiment, participants had to respect
speed limits and were free to activate or deactivate ACC. In complex driving
environments, we found that the overall ACC engagement time was lower compared
to less complex driving environments. We observed no significant effect of
cognitive load on ACC use. Furthermore, while ACC use had no effect on the
number of lane changes, it impacted the speed limits compliance and improved
lateral control.

</details>


### [193] [Initiating and Replicating the Observations of Interactional Properties by User Studies Optimizing Applicative Prototypes](https://arxiv.org/abs/2507.13923)
*Guillaume Rivière*

Main category: cs.HC

TL;DR: 该论文提出了一种形式化用户交互观察的方法（交互循环衍射），旨在通过校准研究交互属性，适用于多种条件（原型、技术、任务和用户档案），从而优化应用原型并推动理论构建。


<details>
  <summary>Details</summary>
Motivation: HCI领域的研究多为孤立实证发现，缺乏普适性。本文旨在通过形式化交互观察，实现跨条件的交互属性研究，推动理论整合与构建。

Method: 提出交互循环衍射方法，形式化用户交互观察，校准研究交互属性，适用于多种应用场景。

Result: 交互属性可在应用案例中涌现并复制，优化原型，同时为技术效用提供实证支持，推动理论发展。

Conclusion: 该方法有助于构建交互属性科学，改善用户交互体验，尤其适用于普适用户界面。

Abstract: The science of Human-Computer Interaction (HCI) is populated by isolated
empirical findings, often tied to specific technologies, designs, and tasks.
This paper proposes a formalization of user interaction observations (instead
of user interfaces) and an associated revealing method (interaction loop
diffraction). The resulting interactional properties that are studied in a
calibrated manner, are well suited to replication across various conditions
(prototypes, technologies, tasks, and user profiles). In particular,
interactional properties can emerge and be replicated within the workflow of
applicative cases, which in return benefit from the optimization of applicative
prototypes. Applicative cases' publications will then contribute to
demonstrating technology utility, along with providing empirical results that
will lead future work to theory consolidation and theory building, and finally
to a catalog and a science of relevant interactional properties. These
properties will contribute to better user interactions, especially for the
variety of ubiquitous user interfaces.

</details>


### [194] [Democratizing Game Modding with GenAI: A Case Study of StarCharM, a Stardew Valley Character Maker](https://arxiv.org/abs/2507.13951)
*Hamid Zand Miralvand,Mohammad Ronagh Nikghalb,Mohammad Darandeh,Abidullah Khan,Ian Arawjo,Jinghui Cheng*

Main category: cs.HC

TL;DR: StarCharM是一个基于GenAI的工具，旨在简化Stardew Valley中NPC模组的创建过程，使非技术玩家也能参与模组制作。


<details>
  <summary>Details</summary>
Motivation: 降低模组制作的技术门槛，让更多玩家能够个性化游戏体验。

Method: 设计了StarCharM工具，通过GenAI技术实现NPC模组的快速生成，并支持用户微调。进行了十名玩家的用户研究。

Result: 玩家对工具表示兴奋，但指出在实现复杂创意时存在挑战。同时，对GenAI可能影响原创性和社区互动表示担忧。

Conclusion: GenAI工具有潜力扩大模组社区，但需平衡易用性与创意表达，并提供指导以优化未来工具设计。

Abstract: Game modding offers unique and personalized gaming experiences, but the
technical complexity of creating mods often limits participation to skilled
users. We envision a future where every player can create personalized mods for
their games. To explore this space, we designed StarCharM, a GenAI-based
non-player character (NPC) creator for Stardew Valley. Our tool enables players
to iteratively create new NPC mods, requiring minimal user input while allowing
for fine-grained adjustments through user control. We conducted a user study
with ten Stardew Valley players who had varied mod usage experiences to
understand the impacts of StarCharM and provide insights into how GenAI tools
may reshape modding, particularly in NPC creation. Participants expressed
excitement in bringing their character ideas to life, although they noted
challenges in generating rich content to fulfill complex visions. While they
believed GenAI tools like StarCharM can foster a more diverse modding
community, some voiced concerns about diminished originality and community
engagement that may come with such technology. Our findings provided
implications and guidelines for the future of GenAI-powered modding tools and
co-creative modding practices.

</details>


### [195] [Estimating Cognitive Effort from Functional Near-Infrared Spectroscopy (fNIRS) Signals using Machine Learning](https://arxiv.org/abs/2507.13952)
*Shayla Sharmin,Roghayeh Leila Barmaki*

Main category: cs.HC

TL;DR: 研究通过机器学习模型基于氧合血红蛋白数据预测认知努力，结合脑激活和行为表现，提升教育游戏中的学习效果。


<details>
  <summary>Details</summary>
Motivation: 估计认知努力有助于教育者调整材料以提升学习效果和学生参与度。

Method: 使用功能近红外光谱采集前额叶皮层的氧合血红蛋白数据，提取时空统计和功能连接特征，训练机器学习模型预测测验表现。

Result: 模型预测准确率在58%至67%之间，衍生的相对神经效率和参与度指标表现稳健。

Conclusion: 尽管预测准确率中等，但认知努力趋势在游戏过程中保持一致，验证了方法的有效性。

Abstract: The estimation of cognitive effort could potentially help educators to modify
material to enhance learning effectiveness and student engagement. Where
cognitive load refers how much work the brain is doing while someone is
learning or doing a task cognitive effort consider both load and behavioral
performance. Cognitive effort can be captured by measuring oxygen flow and
behavioral performance during a task. This study infers cognitive effort
metrics using machine learning models based on oxygenated hemoglobin collected
by using functional near-infrared spectroscopy from the prefrontal cortex
during an educational gameplay. In our study, sixteen participants responded to
sixteen questions in an in-house Unity-based educational game. The quiz was
divided into two sessions, each session consisting of two task segments. We
extracted temporal statistical and functional connectivity features from
collected oxygenated hemoglobin and analyzed their correlation with quiz
performance. We trained multiple machine learning models to predict quiz
performance from oxygenated hemoglobin features and achieved accuracies ranging
from 58\% to 67\% accuracy. These predictions were used to calculate cognitive
effort via relative neural involvement and efficiency, which consider both
brain activation and behavioral performance. Although quiz score predictions
achieved moderate accuracy, the derived relative neural efficiency and
involvement values remained robust. Since both metrics are based on the
relative positions of standardized brain activation and performance scores,
even small misclassifications in predicted scores preserved the overall
cognitive effort trends observed during gameplay.

</details>


### [196] [Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors](https://arxiv.org/abs/2507.14034)
*Jochen Wulf,Jurg Meierhofer,Frank Hannich*

Main category: cs.HC

TL;DR: 本文提出了一种六模式分类法，用于组织人类与AI在技术服务平台中的协作，从完全自动化到被动AI辅助，并提供了选择适当人类监督水平的系统方法。


<details>
  <summary>Details</summary>
Motivation: 尽管基于LLM的代理AI系统在技术服务中具有变革潜力，但其幻觉和操作脆弱性限制了自主使用，因此需要稳健的框架来指导人机协作。

Method: 通过案例研究和借鉴人机协作研究及自动驾驶等领域的类比，开发了一种结构化的人类-代理交互分类法。

Result: 提出了六种协作模式，包括完全自动化（HOOTL）、被动辅助（HAM）及四种中间结构（HIC、HITP、HITL、HOTL），并连接了任务复杂性、操作风险等关键因素。

Conclusion: 该框架为实践者提供了在自动化和控制之间权衡的工具，有助于开发更安全、有效且情境感知的技术服务系统。

Abstract: Agentic AI systems, powered by Large Language Models (LLMs), offer
transformative potential for value co-creation in technical services. However,
persistent challenges like hallucinations and operational brittleness limit
their autonomous use, creating a critical need for robust frameworks to guide
human-AI collaboration. Drawing on established Human-AI teaming research and
analogies from fields like autonomous driving, this paper develops a structured
taxonomy of human-agent interaction. Based on case study research within
technical support platforms, we propose a six-mode taxonomy that organizes
collaboration across a spectrum of AI autonomy. This spectrum is anchored by
the Human-Out-of-the-Loop (HOOTL) model for full automation and the
Human-Augmented Model (HAM) for passive AI assistance. Between these poles, the
framework specifies four distinct intermediate structures. These include the
Human-in-Command (HIC) model, where AI proposals re-quire mandatory human
approval, and the Human-in-the-Process (HITP) model for structured work-flows
with deterministic human tasks. The taxonomy further delineates the
Human-in-the-Loop (HITL) model, which facilitates agent-initiated escalation
upon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables
discretionary human oversight of an autonomous AI. The primary contribution of
this work is a comprehensive framework that connects this taxonomy to key
contingency factors -- such as task complexity, operational risk, and system
reliability -- and their corresponding conceptual architectures. By providing a
systematic method for selecting and designing an appropriate level of human
oversight, our framework offers practitioners a crucial tool to navigate the
trade-offs between automation and control, thereby fostering the development of
safer, more effective, and context-aware technical service systems.

</details>


### [197] [The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?](https://arxiv.org/abs/2507.14084)
*Maria Tsfasman,Ramin Ghorbani,Catholijn M. Jonker,Bernd Dudzik*

Main category: cs.HC

TL;DR: 研究探讨了群体情绪（愉悦-唤醒）与记忆性之间的关系，发现情绪与记忆性之间的关联性不显著，对情感计算技术发展提出新思考。


<details>
  <summary>Details</summary>
Motivation: 智能系统需要理解用户记忆性以优化应用（如会议支持系统），传统认为情绪与记忆性高度相关，但第三方情绪标注可能不准确。

Method: 在动态、非结构化群体对话中，连续标注情绪和记忆性，模拟真实场景（如在线会议支持系统）。

Result: 情绪与记忆性之间的关联性无法显著区别于随机结果。

Conclusion: 情绪标注可能不适合作为记忆性的代理，需重新思考情感计算技术的应用方向，并指出未来研究目标。

Abstract: Humans have a selective memory, remembering relevant episodes and forgetting
the less relevant information. Possessing awareness of event memorability for a
user could help intelligent systems in more accurate user modelling, especially
for such applications as meeting support systems, memory augmentation, and
meeting summarisation. Emotion recognition has been widely studied, since
emotions are thought to signal moments of high personal relevance to users. The
emotional experience of situations and their memorability have traditionally
been considered to be closely tied to one another: moments that are experienced
as highly emotional are considered to also be highly memorable. This
relationship suggests that emotional annotations could serve as proxies for
memorability. However, existing emotion recognition systems rely heavily on
third-party annotations, which may not accurately represent the first-person
experience of emotional relevance and memorability. This is why, in this study,
we empirically examine the relationship between perceived group emotions
(Pleasure-Arousal) and group memorability in the context of conversational
interactions. Our investigation involves continuous time-based annotations of
both emotions and memorability in dynamic, unstructured group settings,
approximating conditions of real-world conversational AI applications such as
online meeting support systems. Our results show that the observed relationship
between affect and memorability annotations cannot be reliably distinguished
from what might be expected under random chance. We discuss the implications of
this surprising finding for the development and applications of Affective
Computing technology. In addition, we contextualise our findings in broader
discourses in the Affective Computing and point out important targets for
future research efforts.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [198] [CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education](https://arxiv.org/abs/2507.13814)
*Jianing Zhao,Peng Gao,Jiannong Cao,Zhiyuan Wen,Chen Chen,Jianing Yin,Ruosong Yang,Bo Yuan*

Main category: cs.MA

TL;DR: CodeEdu是一个基于多代理LLM的协作平台，旨在提供个性化和主动的编程教育，通过动态分配任务和代理来满足学生需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的方法无法全面评估学生能力、设计学习计划或提供个性化材料，且多代理LLM在教育领域的潜力尚未开发。

Method: CodeEdu结合多代理LLM和工具使用，动态分配代理和任务，涵盖任务规划、个性化材料生成、实时问答等功能。

Result: 自动评估显示，CodeEdu显著提高了学生的编程表现。

Conclusion: CodeEdu展示了多代理LLM在教育中的潜力，为编程教育提供了更高效和个性化的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated considerable potential in
improving coding education by providing support for code writing, explanation,
and debugging. However, existing LLM-based approaches generally fail to assess
students' abilities, design learning plans, provide personalized material
aligned with individual learning goals, and enable interactive learning.
Current work mostly uses single LLM agents, which limits their ability to
understand complex code repositories and schedule step-by-step tutoring. Recent
research has shown that multi-agent LLMs can collaborate to solve complicated
problems in various domains like software engineering, but their potential in
the field of education remains unexplored. In this work, we introduce CodeEdu,
an innovative multi-agent collaborative platform that combines LLMs with tool
use to provide proactive and personalized education in coding. Unlike static
pipelines, CodeEdu dynamically allocates agents and tasks to meet student
needs. Various agents in CodeEdu undertake certain functions specifically,
including task planning, personalized material generation, real-time QA,
step-by-step tutoring, code execution, debugging, and learning report
generation, facilitated with extensive external tools to improve task
efficiency. Automated evaluations reveal that CodeEdu substantially enhances
students' coding performance.

</details>
