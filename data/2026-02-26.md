<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 8]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Cross domain Persistent Monitoring for Hybrid Aerial Underwater Vehicles](https://arxiv.org/abs/2602.21259)
*Ricardo B. Grando,Victor A. Kich,Alisson H. Kolling,Junior C. D. Jesus,Rodrigo S. Guerra,Paulo L. J. Drews-Jr*

Main category: cs.RO

TL;DR: 本文提出了一种结合深度强化学习和迁移学习的混合无人空中水下飞行器持续监测方法，使用统一的DRL架构处理空中和水下传感器数据，实现跨域适应性。


<details>
  <summary>Details</summary>
Motivation: 混合无人空中水下飞行器（HUAUVs）能够在空中和水下环境中运行，可用于检查、测绘、搜索和救援等应用，但由于空气和水域的不同动力学特性和约束，开发新方法面临重大挑战。

Method: 结合深度强化学习（DRL）和迁移学习，采用共享的DRL架构，使用激光雷达传感器数据（空中）和声纳数据（水下）进行训练，为两种环境创建统一策略。

Result: 该方法在考虑环境不确定性和多个移动目标动态的情况下，展示了有希望的结果，证明了跨域适应性的可行性。

Conclusion: 所提出的框架为基于深度强化学习的混合空中水下飞行器的可扩展自主持续监测解决方案奠定了基础。

Abstract: Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) have emerged as platforms capable of operating in both aerial and underwater environments, enabling applications such as inspection, mapping, search, and rescue in challenging scenarios. However, the development of novel methodologies poses significant challenges due to the distinct dynamics and constraints of the air and water domains. In this work, we present persistent monitoring tasks for HUAUVs by combining Deep Reinforcement Learning (DRL) and Transfer Learning to enable cross-domain adaptability. Our approach employs a shared DRL architecture trained on Lidar sensor data (on air) and Sonar data (underwater), demonstrating the feasibility of a unified policy for both environments. We further show that the methodology presents promising results, taking into account the uncertainty of the environment and the dynamics of multiple mobile targets. The proposed framework lays the groundwork for scalable autonomous persistent monitoring solutions based on DRL for hybrid aerial-underwater vehicles.

</details>


### [2] [Dual-Branch INS/GNSS Fusion with Inequality and Equality Constraints](https://arxiv.org/abs/2602.21266)
*Mor Levenhar,Itzik Klein*

Main category: cs.RO

TL;DR: 提出一种双分支信息辅助框架，融合等式和不等式运动约束，通过方差加权方案提高城市车辆导航精度，无需额外传感器或硬件。


<details>
  <summary>Details</summary>
Motivation: 城市环境中卫星信号频繁被遮挡，低成本惯性传感器在长时间信号中断时误差快速累积。现有非完整约束等方法对车辆运动施加刚性等式假设，在动态城市驾驶条件下可能被违反，限制了其鲁棒性。

Method: 提出双分支信息辅助框架，融合等式和不等式运动约束，通过方差加权方案集成到现有导航滤波器中。该方法只需软件修改，无需额外传感器或硬件。

Result: 在四个公开城市数据集上评估，总时长4.3小时。在GNSS完全可用时，垂直位置误差减少16.7%，高度精度提高50.1%；在GNSS不可用时，垂直漂移减少24.2%，高度精度提高20.2%。

Conclusion: 用物理驱动的不等式边界替代硬性运动等式假设是一种实用且免费的策略，可提高导航的弹性、连续性和漂移鲁棒性，无需依赖额外传感器、地图数据或学习模型。

Abstract: Reliable vehicle navigation in urban environments remains a challenging problem due to frequent satellite signal blockages caused by tall buildings and complex infrastructure. While fusing inertial reading with satellite positioning in an extended Kalman filter provides short-term navigation continuity, low-cost inertial sensors suffer from rapid error accumulation during prolonged outages. Existing information aiding approaches, such as the non-holonomic constraint, impose rigid equality assumptions on vehicle motion that may be violated under dynamic urban driving conditions, limiting their robustness precisely when aiding is most needed. In this paper, we propose a dual-branch information aiding framework that fuses equality and inequality motion constraints through a variance-weighted scheme, requiring only a software modification to an existing navigation filter with no additional sensors or hardware. The proposed method is evaluated on four publicly available urban datasets featuring various inertial sensors, road conditions, and dynamics, covering a total duration of 4.3 hours of recorded data. Under Full GNSS availability, the method reduces vertical position error by 16.7% and improves altitude accuracy by 50.1% over the standard non-holonomic constraint. Under GNSS-denied conditions, vertical drift is reduced by 24.2% and altitude accuracy improves by 20.2%. These results demonstrate that replacing hard motion equality assumptions with physically motivated inequality bounds is a practical and cost-free strategy for improving navigation resilience, continuity, and drift robustness without relying on additional sensors, map data, or learned models.

</details>


### [3] [Learning Deformable Object Manipulation Using Task-Level Iterative Learning Control](https://arxiv.org/abs/2602.21302)
*Krishna Suresh,Chris Atkeson*

Main category: cs.RO

TL;DR: 提出任务级迭代学习控制方法，用于动态操纵可变形物体（如绳索），在硬件上直接学习，无需大量演示数据或仿真，成功实现"飞行打结"任务。


<details>
  <summary>Details</summary>
Motivation: 可变形物体（如绳索）具有无限自由度且呈现欠驱动动力学特性，这对人类和机器人的动态操纵都构成挑战。现有方法通常需要大量演示数据或仿真，限制了实际应用。

Method: 提出任务级迭代学习控制方法：1）使用单个人类演示和简化绳索模型；2）在硬件上直接学习；3）每次迭代通过求解二次规划构建机器人和绳索的局部逆模型，将任务空间误差传播到动作更新中。

Result: 在7种不同类型的绳索上评估（包括链条、乳胶手术管、编织绳和绞合绳，厚度7-25mm，密度0.013-0.5 kg/m）：1）所有绳索在10次试验内达到100%成功率；2）方法能在约2-5次试验中成功在不同绳索类型间迁移。

Conclusion: 该方法通过任务级迭代学习控制，实现了可变形物体的动态操纵，减少了对外部数据或仿真的依赖，展示了在真实硬件上的高效学习和跨不同类型绳索的迁移能力。

Abstract: Dynamic manipulation of deformable objects is challenging for humans and robots because they have infinite degrees of freedom and exhibit underactuated dynamics. We introduce a Task-Level Iterative Learning Control method for dynamic manipulation of deformable objects. We demonstrate this method on a non-planar rope manipulation task called the flying knot. Using a single human demonstration and a simplified rope model, the method learns directly on hardware without reliance on large amounts of demonstration data or massive amounts of simulation. At each iteration, the algorithm constructs a local inverse model of the robot and rope by solving a quadratic program to propagate task-space errors into action updates. We evaluate performance across 7 different kinds of ropes, including chain, latex surgical tubing, and braided and twisted ropes, ranging in thicknesses of 7--25mm and densities of 0.013--0.5 kg/m. Learning achieves a 100\% success rate within 10 trials on all ropes. Furthermore, the method can successfully transfer between most rope types in approximately 2--5 trials. https://flying-knots.github.io

</details>


### [4] [Unified Complementarity-Based Contact Modeling and Planning for Soft Robots](https://arxiv.org/abs/2602.21316)
*Milad Azizkhani,Yue Chen*

Main category: cs.RO

TL;DR: 本文提出CUSP框架，通过三阶段条件化管道和运动学引导的预热策略，解决了软机器人接触建模和规划中的挑战，为软机器人接触建模、仿真和规划提供了统一基础。


<details>
  <summary>Details</summary>
Motivation: 软机器人需要安全、自适应的环境交互，这依赖于接触。然而，软机器人接触丰富的交互建模和规划面临挑战：身体上的密集接触候选导致冗余约束和秩不足的LCP，而高刚度和低摩擦之间的差异引入严重病态。现有方法依赖于特定问题的近似或基于惩罚的处理。

Method: 提出基于互补性的统一框架，包括：为离散化软机器人开发鲁棒的LCP模型；三阶段条件化管道（惯性秩选择去除冗余接触、Ruiz均衡纠正尺度差异和病态、法向块的轻量Tikhonov正则化）；基于相同公式的运动学引导预热策略，使用带互补约束的数学规划进行动态轨迹优化。

Result: 在接触丰富的球操作任务中展示了其有效性。CUSP框架为软机器人接触建模、仿真和规划提供了统一、物理一致的公式。

Conclusion: CUSP为统一软机器人接触建模、仿真和规划提供了新的基础，解决了现有方法在接触丰富交互中的局限性。

Abstract: Soft robots were introduced in large part to enable safe, adaptive interaction with the environment, and this interaction relies fundamentally on contact. However, modeling and planning contact-rich interactions for soft robots remain challenging: dense contact candidates along the body create redundant constraints and rank-deficient LCPs, while the disparity between high stiffness and low friction introduces severe ill-conditioning. Existing approaches rely on problem-specific approximations or penalty-based treatments. This letter presents a unified complementarity-based framework for soft-robot contact modeling and planning that brings contact modeling, manipulation, and planning into a unified, physically consistent formulation. We develop a robust Linear Complementarity Problem (LCP) model tailored to discretized soft robots and address these challenges with a three-stage conditioning pipeline: inertial rank selection to remove redundant contacts, Ruiz equilibration to correct scale disparity and ill-conditioning, and lightweight Tikhonov regularization on normal blocks. Building on the same formulation, we introduce a kinematically guided warm-start strategy that enables dynamic trajectory optimization through contact using Mathematical Programs with Complementarity Constraints (MPCC) and demonstrate its effectiveness on contact-rich ball manipulation tasks. In conclusion, CUSP provides a new foundation for unifying contact modeling, simulation, and planning in soft robotics.

</details>


### [5] [Autonomous Sea Turtle Robot for Marine Fieldwork](https://arxiv.org/abs/2602.21389)
*Zach J. Patterson,Emily Sologuren,Levi Cai,Daniel Kim,Alaa Maalouf,Pascal Spino,Daniela Rus*

Main category: cs.RO

TL;DR: 研究人员开发了一种海龟仿生自主水下机器人，结合了仿生运动与现场自主能力，能够在珊瑚礁等复杂环境中安全导航并追踪移动目标。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在海洋生态系统观测中具有巨大潜力，但在珊瑚礁等复杂栖息地中近距离操作面临挑战，包括安全导航、应对水流、变光照和有限传感等问题。现有仿生平台在可部署自主性方面仍有局限。

Method: 开发了海龟仿生自主水下机器人，集成了视觉驱动的控制堆栈，结合了深度-航向稳定控制、障碍物避让和目标中心控制，能够在复杂地形中追踪和交互移动物体。

Result: 在控制池实验和新英格兰水族馆活珊瑚礁展区验证了系统性能，展示了稳定操作和可靠追踪快速移动海洋动物及潜水员的能力。在脱缆实验中，障碍物避让成功率91%，并引入了低计算量的机载追踪模式。

Conclusion: 该研究为软硬混合仿生水下机器人提供了一条实用路径，使其能够在敏感生态系统中进行最小干扰的探索和近距离监测，首次实现了集新型硬件、控制和现场实验于一体的完整仿生机器人系统。

Abstract: Autonomous robots can transform how we observe marine ecosystems, but close-range operation in reefs and other cluttered habitats remains difficult. Vehicles must maneuver safely near animals and fragile structures while coping with currents, variable illumination and limited sensing. Previous approaches simplify these problems by leveraging soft materials and bioinspired swimming designs, but such platforms remain limited in terms of deployable autonomy. Here we present a sea turtle-inspired autonomous underwater robot that closed the gap between bioinspired locomotion and field-ready autonomy through a tightly integrated, vision-driven control stack. The robot combines robust depth-heading stabilization with obstacle avoidance and target-centric control, enabling it to track and interact with moving objects in complex terrain. We validate the robot in controlled pool experiments and in a live coral reef exhibit at the New England Aquarium, demonstrating stable operation and reliable tracking of fast-moving marine animals and human divers. To the best of our knowledge, this is the first integrated biomimetic robotic system, combining novel hardware, control, and field experiments, deployed to track and monitor real marine animals in their natural environment. During off-tether experiments, we demonstrate safe navigation around obstacles (91\% success rate in the aquarium exhibit) and introduce a low-compute onboard tracking mode. Together, these results establish a practical route toward soft-rigid hybrid, bioinspired underwater robots capable of minimally disruptive exploration and close-range monitoring in sensitive ecosystems.

</details>


### [6] [LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies](https://arxiv.org/abs/2602.21531)
*Yue Yang,Shuo Cheng,Yu Fang,Homanga Bharadhwaj,Mingyu Ding,Gedas Bertasius,Daniel Szafir*

Main category: cs.RO

TL;DR: LiLo-VLA是一个模块化框架，通过将运输与交互解耦来解决长时程操作任务，实现零样本泛化到新任务，在仿真和真实世界中都取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 通用机器人需要掌握长时程操作任务，这些任务涉及多个运动结构变化（如连接或分离物体）且在非结构化环境中进行。虽然视觉-语言-动作模型能够掌握多样的原子技能，但在组合这些技能时面临组合复杂性，并且由于环境敏感性容易产生级联失败。

Method: 提出LiLo-VLA模块化框架，将运输与交互解耦：一个到达模块处理全局运动，而一个交互模块采用以物体为中心的VLA处理孤立的目标物体，确保对无关视觉特征的鲁棒性和空间配置的不变性。这种模块化设计支持通过动态重规划和技能重用来实现鲁棒的失败恢复。

Result: 在包含两个挑战性套件（LIBERO-Long++和Ultra-Long）的21任务仿真基准测试中，LiLo-VLA实现了69%的平均成功率，比Pi0.5高出41%，比OpenVLA-OFT高出67%。在8个长时程任务的真实世界评估中，平均成功率达到85%。

Conclusion: LiLo-VLA通过模块化设计有效解决了长时程操作任务中的组合复杂性和级联失败问题，实现了零样本泛化能力，在仿真和真实环境中都表现出色，为通用机器人操作提供了有前景的解决方案。

Abstract: General-purpose robots must master long-horizon manipulation, defined as tasks involving multiple kinematic structure changes (e.g., attaching or detaching objects) in unstructured environments. While Vision-Language-Action (VLA) models offer the potential to master diverse atomic skills, they struggle with the combinatorial complexity of sequencing them and are prone to cascading failures due to environmental sensitivity. To address these challenges, we propose LiLo-VLA (Linked Local VLA), a modular framework capable of zero-shot generalization to novel long-horizon tasks without ever being trained on them. Our approach decouples transport from interaction: a Reaching Module handles global motion, while an Interaction Module employs an object-centric VLA to process isolated objects of interest, ensuring robustness against irrelevant visual features and invariance to spatial configurations. Crucially, this modularity facilitates robust failure recovery through dynamic replanning and skill reuse, effectively mitigating the cascading errors common in end-to-end approaches. We introduce a 21-task simulation benchmark consisting of two challenging suites: LIBERO-Long++ and Ultra-Long. In these simulations, LiLo-VLA achieves a 69% average success rate, outperforming Pi0.5 by 41% and OpenVLA-OFT by 67%. Furthermore, real-world evaluations across 8 long-horizon tasks demonstrate an average success rate of 85%. Project page: https://yy-gx.github.io/LiLo-VLA/.

</details>


### [7] [Self-Correcting VLA: Online Action Refinement via Sparse World Imagination](https://arxiv.org/abs/2602.21633)
*Chenyv Liu,Wentao Tan,Lei Zhu,Fengling Li,Jingjing Li,Guoli Yang,Heng Tao Shen*

Main category: cs.RO

TL;DR: SC-VLA模型通过稀疏世界想象和在线动作优化实现自我改进，在机器人操作任务中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型依赖统计先验，缺乏对物理动态的稳健理解；强化学习依赖外部奖励信号，与世界动作模型缺乏显式自我改进机制

Method: 设计稀疏世界想象模块，集成辅助预测头来预测当前任务进度和未来轨迹趋势；引入在线动作优化模块，基于预测的稀疏未来状态调整轨迹方向

Result: 在仿真基准和真实世界机器人操作任务中达到最先进性能，相比最佳基线减少16%步骤，成功率提高9%，真实世界实验提升14%

Conclusion: SC-VLA通过稀疏想象和内在引导的动作优化实现了自我改进，在机器人操作任务中表现出卓越性能

Abstract: Standard vision-language-action (VLA) models rely on fitting statistical data priors, limiting their robust understanding of underlying physical dynamics. Reinforcement learning enhances physical grounding through exploration yet typically relies on external reward signals that remain isolated from the agent's internal states. World action models have emerged as a promising paradigm that integrates imagination and control to enable predictive planning. However, they rely on implicit context modeling, lacking explicit mechanisms for self-improvement. To solve these problems, we propose Self-Correcting VLA (SC-VLA), which achieve self-improvement by intrinsically guiding action refinement through sparse imagination. We first design sparse world imagination by integrating auxiliary predictive heads to forecast current task progress and future trajectory trends, thereby constraining the policy to encode short-term physical evolution. Then we introduce the online action refinement module to reshape progress-dependent dense rewards, adjusting trajectory orientation based on the predicted sparse future states. Evaluations on challenging robot manipulation tasks from simulation benchmarks and real-world settings demonstrate that SC-VLA achieve state-of-the-art performance, yielding the highest task throughput with 16% fewer steps and a 9% higher success rate than the best-performing baselines, alongside a 14% gain in real-world experiments. Code is available at https://github.com/Kisaragi0/SC-VLA.

</details>


### [8] [World Guidance: World Modeling in Condition Space for Action Generation](https://arxiv.org/abs/2602.22010)
*Yue Su,Sijin Chen,Haixin Shi,Mingyu Liu,Zhengshen Zhang,Ningyuan Huang,Weiheng Zhong,Zhengbang Zhu,Yuxiao Liu,Xihui Liu*

Main category: cs.RO

TL;DR: WoG框架通过将未来观测映射为紧凑条件并注入动作推理流程，在保持高效可预测未来表示的同时保留细粒度信息，显著提升VLA模型的动作生成能力


<details>
  <summary>Details</summary>
Motivation: 现有方法难以平衡高效可预测的未来表示与指导精确动作生成所需的细粒度信息，需要一种新框架来改善VLA模型的动作生成能力

Method: 提出WoG框架，将未来观测映射为紧凑条件并注入动作推理流程，训练VLA模型同时预测这些压缩条件和未来动作，在条件空间内实现有效的世界建模

Result: 该方法不仅促进细粒度动作生成，还展现出优越的泛化能力，并能从大量人类操作视频中有效学习，在仿真和真实环境实验中显著优于基于未来预测的现有方法

Conclusion: WoG框架通过条件空间建模有效解决了未来观测表示中的平衡问题，为VLA模型的动作生成提供了更优的解决方案

Abstract: Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future representations and preserving sufficient fine-grained information to guide precise action generation. To address this limitation, we propose WoG (World Guidance), a framework that maps future observations into compact conditions by injecting them into the action inference pipeline. The VLA is then trained to simultaneously predict these compressed conditions alongside future actions, thereby achieving effective world modeling within the condition space for action inference. We demonstrate that modeling and predicting this condition space not only facilitates fine-grained action generation but also exhibits superior generalization capabilities. Moreover, it learns effectively from substantial human manipulation videos. Extensive experiments across both simulation and real-world environments validate that our method significantly outperforms existing methods based on future prediction. Project page is available at: https://selen-suyue.github.io/WoGNet/

</details>
