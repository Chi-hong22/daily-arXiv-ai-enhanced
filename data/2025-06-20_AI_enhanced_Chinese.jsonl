{"id": "2506.15295", "categories": ["cs.GT", "cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2506.15295", "abs": "https://arxiv.org/abs/2506.15295", "authors": ["Massimo Bartoletti", "Enrico Lipparini"], "title": "A theory of Lending Protocols in DeFi", "comment": null, "summary": "Lending protocols are one of the main applications of Decentralized Finance (DeFi), enabling crypto-assets loan markets with a total value estimated in the tens of billions of dollars. Unlike traditional lending systems, these protocols operate without relying on trusted authorities or off-chain enforcement mechanisms. To achieve key economic goals such as stability of the loan market, they devise instead trustless on-chain mechanisms, such as rewarding liquidators who repay the loans of under-collateralized borrowers by awarding them part of the borrower's collateral. The complexity of these incentive mechanisms, combined with their entanglement in low-level implementation details, makes it challenging to precisely assess the structural and economic properties of lending protocols, as well as to analyze user strategies and attacks. Crucially, since participation is open to anyone, any weaknesses in the incentive mechanism may give rise to unintended emergent behaviours, or even enable adversarial strategies aimed at making profits to the detriment of legit users, or at undermining the stability of the protocol. In this work, we propose a formal model of lending protocols that captures the essential features of mainstream platforms, enabling us to identify and prove key properties related to their economic and strategic dynamics.", "AI": {"tldr": "论文提出了一个形式化模型，用于分析去中心化金融（DeFi）借贷协议的经济和战略动态，揭示其潜在弱点和用户策略。", "motivation": "DeFi借贷协议通过链上机制实现贷款市场稳定，但其复杂性使得评估其结构特性和用户策略变得困难，可能导致意外行为或攻击。", "method": "提出一个形式化模型，捕捉主流借贷平台的核心特征。", "result": "模型能够识别并证明借贷协议的关键经济和战略动态特性。", "conclusion": "形式化模型为分析DeFi借贷协议提供了理论基础，有助于发现潜在问题和优化设计。"}}
{"id": "2506.15379", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2506.15379", "abs": "https://arxiv.org/abs/2506.15379", "authors": ["Václav Blažej", "Sushmita Gupta", "M. S. Ramanujan", "Peter Strulo"], "title": "Tractable Graph Structures in EFX Orientation", "comment": null, "summary": "Since its introduction, envy-freeness up to any good (EFX) has become a fundamental solution concept in fair division of indivisible goods. Its existence remains elusive -- even for four agents with additive utility functions, it is unknown whether an EFX allocation always exists. Unsurprisingly, restricted settings to delineate tractable and intractable cases have been explored. Christadolou, Fiat et al.[EC'23] introduced the notion of EFX-orientation, where the agents form the vertices of a graph and the items correspond to edges, and an agent values only the items that are incident to it. The goal is to allocate items to one of the adjacent agents while satisfying the EFX condition.\n  Building on the work of Zeng and Mehta'24, which established a sharp complexity threshold based on the structure of the underlying graph -- polynomial-time solvability for bipartite graphs and NP-hardness for graphs with chromatic number at least three -- we further explore the algorithmic landscape of EFX-orientation using parameterized graph algorithms.\n  Specifically, we show that bipartiteness is a surprisingly stringent condition for tractability: EFX orientation is NP-complete even when the valuations are symmetric, binary and the graph is at most two edge-removals away from being bipartite. Moreover, introducing a single non-binary value makes the problem NP-hard even when the graph is only one edge removal away from being bipartite. We further perform a parameterized analysis to examine structures of the underlying graph that enable tractability. In particular, we show that the problem is solvable in linear time on graphs whose treewidth is bounded by a constant and that the complexity of an instance is closely tied to the sizes of acyclic connected components on its one-valued edges.", "AI": {"tldr": "EFX分配在不可分割物品的公平分配中是一个重要概念，但其存在性仍不明确。本文通过参数化图算法进一步探索EFX方向的算法复杂性，发现二分性是一个严格条件，并分析了其他结构对问题可解性的影响。", "motivation": "EFX分配的存在性尚未完全解决，尤其是在特定图结构下。本文旨在通过参数化图算法，探索EFX方向的复杂性，并识别可解与不可解的条件。", "method": "使用参数化图算法分析EFX方向的复杂性，重点关注二分图、树宽有界图以及非二分图的边缘移除情况。", "result": "EFX方向在二分图下可多项式时间求解，但在接近二分图的情况下（如移除少量边）仍为NP完全问题。此外，树宽有界图可线性时间求解。", "conclusion": "二分性是EFX方向可解性的关键条件，但接近二分图的情况下问题仍复杂。参数化分析为理解EFX方向的复杂性提供了新视角。"}}
{"id": "2506.15183", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2506.15183", "abs": "https://arxiv.org/abs/2506.15183", "authors": ["Xingyu Chen", "Xinmin Fang", "Shuting Zhang", "Xinyu Zhang", "Liang He", "Zhengxiong Li"], "title": "You Only Render Once: Enhancing Energy and Computation Efficiency of Mobile Virtual Reality", "comment": null, "summary": "Mobile Virtual Reality (VR) is essential to achieving convenient and immersive human-computer interaction and realizing emerging applications such as Metaverse. However, existing VR technologies require two separate renderings of binocular images, causing a significant bottleneck for mobile devices with limited computing capability and power supply. This paper proposes an approach to rendering optimization for mobile VR called EffVR. By utilizing the per-pixel attribute, EffVR can generate binocular VR images from the monocular image through genuinely one rendering, saving half the computation over conventional approaches. Our evaluation indicates that, compared with the state-of-art, EffVRcan save 27% power consumption on average while achieving high binocular image quality (0.9679 SSIM and 34.09 PSNR) in mobile VR applications. Additionally, EffVR can increase the frame rate by 115.2%. These results corroborate EffVRsuperior computation/energy-saving performance, paving the road to a sustainable mobile VR. The source code, demo video, android app, and more are released anonymously at https://yoro-vr.github.io/", "AI": {"tldr": "EffVR通过单次渲染生成双目VR图像，显著降低移动VR的计算和能耗。", "motivation": "解决移动VR因双目图像渲染导致的计算和能耗瓶颈。", "method": "利用像素属性从单目图像生成双目VR图像，仅需一次渲染。", "result": "节省27%能耗，提高115.2%帧率，图像质量高（SSIM 0.9679，PSNR 34.09）。", "conclusion": "EffVR为可持续移动VR提供了高效解决方案。"}}
{"id": "2506.14984", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14984", "abs": "https://arxiv.org/abs/2506.14984", "authors": ["Marissa Dominijanni", "Alexander Ororbia", "Kenneth W. Regan"], "title": "Extending Spike-Timing Dependent Plasticity to Learning Synaptic Delays", "comment": "Repository containing the source code used to generate the results is available at: https://github.com/mdominijanni/dsstdp-results", "summary": "Synaptic delays play a crucial role in biological neuronal networks, where their modulation has been observed in mammalian learning processes. In the realm of neuromorphic computing, although spiking neural networks (SNNs) aim to emulate biology more closely than traditional artificial neural networks do, synaptic delays are rarely incorporated into their simulation. We introduce a novel learning rule for simultaneously learning synaptic connection strengths and delays, by extending spike-timing dependent plasticity (STDP), a Hebbian method commonly used for learning synaptic weights. We validate our approach by extending a widely-used SNN model for classification trained with unsupervised learning. Then we demonstrate the effectiveness of our new method by comparing it against another existing methods for co-learning synaptic weights and delays as well as against STDP without synaptic delays. Results demonstrate that our proposed method consistently achieves superior performance across a variety of test scenarios. Furthermore, our experimental results yield insight into the interplay between synaptic efficacy and delay.", "AI": {"tldr": "论文提出了一种新的学习规则，通过扩展STDP方法，同时学习突触连接强度和延迟，并在SNN模型中验证了其有效性。", "motivation": "生物神经元网络中突触延迟的调节在哺乳动物学习过程中起重要作用，但SNN中很少模拟这一特性。", "method": "扩展STDP方法，提出同时学习突触连接强度和延迟的新规则，并在分类任务中验证。", "result": "新方法在多种测试场景中表现优于现有方法，并揭示了突触效能与延迟的相互作用。", "conclusion": "该方法为SNN中突触延迟的模拟提供了有效解决方案，并展示了其性能优势。"}}
{"id": "2506.14864", "categories": ["cs.SD", "cs.CV", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.14864", "abs": "https://arxiv.org/abs/2506.14864", "authors": ["Zachary J. Ruff", "Damon B. Lesmeister"], "title": "pycnet-audio: A Python package to support bioacoustics data processing", "comment": null, "summary": "Passive acoustic monitoring is an emerging approach in wildlife research that leverages recent improvements in purpose-made automated recording units (ARUs). The general approach is to deploy ARUs in the field to record on a programmed schedule for extended periods (weeks or months), after which the audio data are retrieved. These data must then be processed, typically either by measuring or analyzing characteristics of the audio itself (e.g. calculating acoustic indices), or by searching for some signal of interest within the recordings, e.g. vocalizations or other sounds produced by some target species, anthropogenic or environmental noise, etc. In the latter case, some method is required to locate the signal(s) of interest within the audio. While very small datasets can simply be searched manually, even modest projects can produce audio datasets on the order of 105 hours of recordings, making manual review impractical and necessitating some form of automated detection. pycnet-audio (Ruff 2024) is intended to provide a practical processing workflow for acoustic data, built around the PNW-Cnet model, which was initially developed by the U.S. Forest Service to support population monitoring of northern spotted owls (Strix occidentalis caurina) and other forest owls (Lesmeister and Jenkins 2022; Ruff et al. 2020). PNW-Cnet has been expanded to detect vocalizations of ca. 80 forest wildlife species and numerous forms of anthropogenic and environmental noise (Ruff et al. 2021, 2023).", "AI": {"tldr": "论文介绍了pycnet-audio工具，用于处理被动声学监测数据，基于PNW-Cnet模型，支持多种森林野生动物和噪声的检测。", "motivation": "被动声学监测在野生动物研究中日益重要，但处理大量音频数据需要自动化工具。", "method": "使用PNW-Cnet模型扩展版，检测约80种森林野生动物及噪声信号。", "result": "pycnet-audio提供了实用的声学数据处理流程，支持大规模音频分析。", "conclusion": "该工具为野生动物研究和噪声监测提供了高效解决方案。"}}
{"id": "2506.14775", "categories": ["cs.HC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14775", "abs": "https://arxiv.org/abs/2506.14775", "authors": ["Tobias Labarta", "Nhi Hoang", "Katharina Weitz", "Wojciech Samek", "Sebastian Lapuschkin", "Leander Weber"], "title": "See What I Mean? CUE: A Cognitive Model of Understanding Explanations", "comment": "10 pages, 5 figures (main text), 4 tables, 455-participant user study", "summary": "As machine learning systems increasingly inform critical decisions, the need for human-understandable explanations grows. Current evaluations of Explainable AI (XAI) often prioritize technical fidelity over cognitive accessibility which critically affects users, in particular those with visual impairments. We propose CUE, a model for Cognitive Understanding of Explanations, linking explanation properties to cognitive sub-processes: legibility (perception), readability (comprehension), and interpretability (interpretation). In a study (N=455) testing heatmaps with varying colormaps (BWR, Cividis, Coolwarm), we found comparable task performance but lower confidence/effort for visually impaired users. Unlike expected, these gaps were not mitigated and sometimes worsened by accessibility-focused color maps like Cividis. These results challenge assumptions about perceptual optimization and support the need for adaptive XAI interfaces. They also validate CUE by demonstrating that altering explanation legibility affects understandability. We contribute: (1) a formalized cognitive model for explanation understanding, (2) an integrated definition of human-centered explanation properties, and (3) empirical evidence motivating accessible, user-tailored XAI.", "AI": {"tldr": "论文提出CUE模型，将解释属性与认知子过程（可读性、可理解性、可解释性）关联，并通过实验验证了可访问性优化的局限性，支持自适应XAI界面的需求。", "motivation": "随着机器学习系统在关键决策中的应用增加，人类可理解的解释需求日益增长。当前可解释AI（XAI）评估常忽视认知可访问性，尤其是对视觉障碍用户的影响。", "method": "提出CUE模型，将解释属性与认知子过程（可读性、可理解性、可解释性）关联，并通过实验测试不同色彩映射（BWR、Cividis、Coolwarm）对用户任务表现和信心的影响。", "result": "实验发现，视觉障碍用户的任务表现与常人相当，但信心和努力程度较低。可访问性优化的色彩映射（如Cividis）未改善甚至加剧了这种差距。", "conclusion": "结果挑战了感知优化的假设，支持自适应XAI界面的需求，并验证了CUE模型的有效性。论文贡献包括：1）形式化的认知模型，2）以人为中心的解释属性定义，3）推动可访问、用户定制XAI的实证证据。"}}
{"id": "2506.15004", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15004", "abs": "https://arxiv.org/abs/2506.15004", "authors": ["Filippos Tzortzoglou", "Logan E. Beaver"], "title": "Mixed Traffic: A Perspective from Long Duration Autonomy", "comment": "14 pages, 12 figures", "summary": "The rapid adoption of autonomous vehicle has established mixed traffic environments, comprising both autonomous and human-driven vehicles (HDVs), as essential components of next-generation mobility systems. Along these lines, connectivity between autonomous vehicles and infrastructure (V2I) is also a significant factor that can effectively support higher-level decision-making. At the same time, the integration of V2I within mixed traffic environments remains a timely and challenging problem. In this paper, we present a long-duration autonomy controller for connected and automated vehicles (CAVs) operating in such environments, with a focus on intersections where right turns on red are permitted. We begin by deriving the optimal control policy for CAVs under free-flow traffic. Next, we analyze crossing time constraints imposed by smart traffic lights and map these constraints to controller bounds using Control Barrier Functions (CBFs), with the aim to drive a CAV to cross the intersection on time. We also introduce criteria for identifying, in real-time, feasible crossing intervals for each CAV. To ensure safety for the CAVs, we present model-agnostic safety guarantees, and demonstrate their compatibility with both CAVs and HDVs. Ultimately, the final control actions are enforced through a combination of CBF constraints, constraining CAVs to traverse the intersection within the designated time intervals while respecting other vehicles. Finally, we guarantee that our control policy yields always a feasible solution and validate the proposed approach through extensive simulations in MATLAB.", "AI": {"tldr": "论文提出了一种用于混合交通环境中联网自动驾驶车辆（CAV）的长时自主控制器，重点解决允许红灯右转的交叉路口问题。通过最优控制策略和CBF约束确保CAV按时通过路口，并保证安全性。", "motivation": "随着自动驾驶车辆的普及，混合交通环境（包含CAV和人工驾驶车辆）成为下一代交通系统的关键组成部分。V2I技术的整合在此环境中仍具挑战性，尤其是在交叉路口场景。", "method": "1. 推导自由流交通下CAV的最优控制策略；2. 利用CBF将智能交通灯的通行时间约束映射为控制器边界；3. 实时识别CAV可行的通行区间；4. 提供模型无关的安全保证。", "result": "通过MATLAB仿真验证，控制器能确保CAV在指定时间区间内安全通过交叉路口，并兼容人工驾驶车辆。", "conclusion": "提出的控制策略始终可行，有效解决了混合交通环境中CAV的通行问题，同时兼顾安全性和效率。"}}
{"id": "2506.14855", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14855", "abs": "https://arxiv.org/abs/2506.14855", "authors": ["Tommaso Belvedere", "Michael Ziegltrum", "Giulio Turrisi", "Valerio Modugno"], "title": "Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers", "comment": null, "summary": "Model Predictive Path Integral control is a powerful sampling-based approach suitable for complex robotic tasks due to its flexibility in handling nonlinear dynamics and non-convex costs. However, its applicability in real-time, highfrequency robotic control scenarios is limited by computational demands. This paper introduces Feedback-MPPI (F-MPPI), a novel framework that augments standard MPPI by computing local linear feedback gains derived from sensitivity analysis inspired by Riccati-based feedback used in gradient-based MPC. These gains allow for rapid closed-loop corrections around the current state without requiring full re-optimization at each timestep. We demonstrate the effectiveness of F-MPPI through simulations and real-world experiments on two robotic platforms: a quadrupedal robot performing dynamic locomotion on uneven terrain and a quadrotor executing aggressive maneuvers with onboard computation. Results illustrate that incorporating local feedback significantly improves control performance and stability, enabling robust, high-frequency operation suitable for complex robotic systems.", "AI": {"tldr": "F-MPPI通过结合局部线性反馈增益改进MPPI，提升实时控制性能，适用于复杂机器人任务。", "motivation": "MPPI在实时高频机器人控制中因计算需求受限，需改进以提升性能。", "method": "引入F-MPPI框架，通过灵敏度分析计算局部线性反馈增益，避免每步重新优化。", "result": "仿真和实验表明，F-MPPI显著提升控制性能和稳定性，适用于复杂机器人系统。", "conclusion": "F-MPPI通过局部反馈增强MPPI，实现高效、稳定的高频控制。"}}
{"id": "2506.14791", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14791", "abs": "https://arxiv.org/abs/2506.14791", "authors": ["Jingxuan Zhou", "Yuehao Wu", "Yibo Zhang", "Yeyubei Zhang", "Yunchong Liu", "Bolin Huang", "Chunhong Yuan"], "title": "SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection", "comment": "5 pages, 3 figures", "summary": "Aiming at the problem of difficulty in accurately identifying graphical implicit correlations in multimodal irony detection tasks, this paper proposes a Semantic Irony Recognition Network (SemIRNet). The model contains three main innovations: (1) The ConceptNet knowledge base is introduced for the first time to acquire conceptual knowledge, which enhances the model's common-sense reasoning ability; (2) Two cross-modal semantic similarity detection modules at the word level and sample level are designed to model graphic-textual correlations at different granularities; and (3) A contrastive learning loss function is introduced to optimize the spatial distribution of the sample features, which improves the separability of positive and negative samples. Experiments on a publicly available multimodal irony detection benchmark dataset show that the accuracy and F1 value of this model are improved by 1.64% and 2.88% to 88.87% and 86.33%, respectively, compared with the existing optimal methods. Further ablation experiments verify the important role of knowledge fusion and semantic similarity detection in improving the model performance.", "AI": {"tldr": "本文提出了一种语义讽刺识别网络（SemIRNet），通过引入ConceptNet知识库、设计跨模态语义相似性检测模块以及对比学习损失函数，显著提升了多模态讽刺检测任务的性能。", "motivation": "解决多模态讽刺检测任务中图形隐含关联难以准确识别的问题。", "method": "1. 引入ConceptNet知识库增强常识推理能力；2. 设计词级和样本级跨模态语义相似性检测模块；3. 使用对比学习损失函数优化样本特征空间分布。", "result": "在公开数据集上，准确率和F1值分别提升1.64%和2.88%，达到88.87%和86.33%。", "conclusion": "知识融合和语义相似性检测对提升模型性能具有重要作用。"}}
{"id": "2506.14774", "categories": ["cs.LG", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14774", "abs": "https://arxiv.org/abs/2506.14774", "authors": ["Burcu Sayin", "Ipek Baris Schlicht", "Ngoc Vo Hong", "Sara Allievi", "Jacopo Staiano", "Pasquale Minervini", "Andrea Passerini"], "title": "MedSyn: Enhancing Diagnostics with Human-AI Collaboration", "comment": "Accepted to the Trustworthy and Collaborative Artificial Intelligence Workshop 2025 (TCAI 2025) in the 4th International Conference Series on Hybrid Human-Artificial Intelligence (HHAI 2025)", "summary": "Clinical decision-making is inherently complex, often influenced by cognitive biases, incomplete information, and case ambiguity. Large Language Models (LLMs) have shown promise as tools for supporting clinical decision-making, yet their typical one-shot or limited-interaction usage may overlook the complexities of real-world medical practice. In this work, we propose a hybrid human-AI framework, MedSyn, where physicians and LLMs engage in multi-step, interactive dialogues to refine diagnoses and treatment decisions. Unlike static decision-support tools, MedSyn enables dynamic exchanges, allowing physicians to challenge LLM suggestions while the LLM highlights alternative perspectives. Through simulated physician-LLM interactions, we assess the potential of open-source LLMs as physician assistants. Results show open-source LLMs are promising as physician assistants in the real world. Future work will involve real physician interactions to further validate MedSyn's usefulness in diagnostic accuracy and patient outcomes.", "AI": {"tldr": "提出了一种名为MedSyn的混合人机框架，通过多步交互对话优化临床决策。", "motivation": "临床决策复杂且易受认知偏差影响，现有LLM工具通常缺乏交互性，难以适应实际医疗需求。", "method": "设计MedSyn框架，支持医生与LLM动态对话，挑战建议并探讨替代方案。", "result": "实验表明开源LLM在模拟环境中作为医生助手具有潜力。", "conclusion": "未来将通过真实医生交互进一步验证MedSyn在诊断准确性和患者预后中的价值。"}}
{"id": "2506.15290", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15290", "abs": "https://arxiv.org/abs/2506.15290", "authors": ["Andela Ilic", "Jiaxi Jiang", "Paul Streli", "Xintong Liu", "Christian Holz"], "title": "Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models", "comment": "Accepted by IJCAI 2025", "summary": "Motion capture using sparse inertial sensors has shown great promise due to its portability and lack of occlusion issues compared to camera-based tracking. Existing approaches typically assume that IMU sensors are tightly attached to the human body. However, this assumption often does not hold in real-world scenarios. In this paper, we present a new task of full-body human pose estimation using sparse, loosely attached IMU sensors. To solve this task, we simulate IMU recordings from an existing garment-aware human motion dataset. We developed transformer-based diffusion models to synthesize loose IMU data and estimate human poses based on this challenging loose IMU data. In addition, we show that incorporating garment-related parameters while training the model on simulated loose data effectively maintains expressiveness and enhances the ability to capture variations introduced by looser or tighter garments. Experiments show that our proposed diffusion methods trained on simulated and synthetic data outperformed the state-of-the-art methods quantitatively and qualitatively, opening up a promising direction for future research.", "AI": {"tldr": "提出了一种基于稀疏、松散附着IMU传感器的全身姿态估计新任务，通过模拟数据和扩散模型解决，并引入服装参数提升性能。", "motivation": "现有方法假设IMU传感器紧密附着于人体，但现实中常不成立，需解决松散附着场景下的姿态估计问题。", "method": "利用现有服装感知运动数据集模拟IMU数据，开发基于Transformer的扩散模型合成松散IMU数据并估计姿态，训练时引入服装参数。", "result": "实验表明，基于模拟和合成数据的扩散模型在定量和定性上优于现有方法。", "conclusion": "该方法为松散IMU传感器姿态估计提供了新方向，未来研究潜力大。"}}
{"id": "2506.15222", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2506.15222", "abs": "https://arxiv.org/abs/2506.15222", "authors": ["Anton Bouter", "Dirk Thierens", "Peter A. N. Bosman"], "title": "The Pitfalls and Potentials of Adding Gene-invariance to Optimal Mixing", "comment": null, "summary": "Optimal Mixing (OM) is a variation operator that integrates local search with genetic recombination. EAs with OM are capable of state-of-the-art optimization in discrete spaces, offering significant advantages over classic recombination-based EAs. This success is partly due to high selection pressure that drives rapid convergence. However, this can also negatively impact population diversity, complicating the solving of hierarchical problems, which feature multiple layers of complexity. While there have been attempts to address this issue, these solutions are often complicated and prone to bias. To overcome this, we propose a solution inspired by the Gene Invariant Genetic Algorithm (GIGA), which preserves gene frequencies in the population throughout the process. This technique is tailored to and integrated with the Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA), resulting in GI-GOMEA. The simple, yet elegant changes are found to have striking potential: GI-GOMEA outperforms GOMEA on a range of well-known problems, even when these problems are adjusted for pitfalls - biases in much-used benchmark problems that can be easily exploited by maintaining gene invariance. Perhaps even more notably, GI-GOMEA is also found to be effective at solving hierarchical problems, including newly introduced asymmetric hierarchical trap functions.", "AI": {"tldr": "GI-GOMEA是一种基于基因不变性的优化算法，通过保持基因频率提升性能，解决了传统OM算法在解决分层问题时的多样性问题。", "motivation": "传统OM算法在离散空间优化中表现优异，但高选择压力导致种群多样性下降，难以解决分层问题。现有解决方案复杂且易偏置。", "method": "结合基因不变性遗传算法（GIGA）的思想，改进基因池最优混合进化算法（GOMEA），提出GI-GOMEA。", "result": "GI-GOMEA在多种问题上优于GOMEA，包括调整后的基准问题和新引入的非对称分层陷阱函数。", "conclusion": "GI-GOMEA简单有效，显著提升了解决分层问题的能力，同时保持了优化性能。"}}
{"id": "2506.15000", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15000", "abs": "https://arxiv.org/abs/2506.15000", "authors": ["Md Jahangir Alam Khondkar", "Ajan Ahmed", "Masudul Haider Imtiaz", "Stephanie Schuckers"], "title": "A Comparative Evaluation of Deep Learning Models for Speech Enhancement in Real-World Noisy Environments", "comment": null, "summary": "Speech enhancement, particularly denoising, is vital in improving the intelligibility and quality of speech signals for real-world applications, especially in noisy environments. While prior research has introduced various deep learning models for this purpose, many struggle to balance noise suppression, perceptual quality, and speaker-specific feature preservation, leaving a critical research gap in their comparative performance evaluation. This study benchmarks three state-of-the-art models Wave-U-Net, CMGAN, and U-Net, on diverse datasets such as SpEAR, VPQAD, and Clarkson datasets. These models were chosen due to their relevance in the literature and code accessibility. The evaluation reveals that U-Net achieves high noise suppression with SNR improvements of +71.96% on SpEAR, +64.83% on VPQAD, and +364.2% on the Clarkson dataset. CMGAN outperforms in perceptual quality, attaining the highest PESQ scores of 4.04 on SpEAR and 1.46 on VPQAD, making it well-suited for applications prioritizing natural and intelligible speech. Wave-U-Net balances these attributes with improvements in speaker-specific feature retention, evidenced by VeriSpeak score gains of +10.84% on SpEAR and +27.38% on VPQAD. This research indicates how advanced methods can optimize trade-offs between noise suppression, perceptual quality, and speaker recognition. The findings may contribute to advancing voice biometrics, forensic audio analysis, telecommunication, and speaker verification in challenging acoustic conditions.", "AI": {"tldr": "该研究对比了三种语音增强模型（Wave-U-Net、CMGAN和U-Net）的性能，发现U-Net在噪声抑制上表现最佳，CMGAN在感知质量上领先，而Wave-U-Net在保留说话人特征方面更优。", "motivation": "现有深度学习模型在噪声抑制、感知质量和说话人特征保留之间存在权衡不足的问题，需通过对比研究填补这一空白。", "method": "在SpEAR、VPQAD和Clarkson数据集上评估了Wave-U-Net、CMGAN和U-Net三种模型，重点关注噪声抑制、感知质量和说话人特征保留。", "result": "U-Net在噪声抑制上表现最佳（SNR提升显著），CMGAN在感知质量上得分最高（PESQ分数领先），Wave-U-Net在说话人特征保留上更优（VeriSpeak分数提升）。", "conclusion": "研究展示了不同模型在语音增强任务中的优势，为实际应用（如语音生物识别、电信等）提供了优化方向。"}}
{"id": "2506.14777", "categories": ["cs.HC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14777", "abs": "https://arxiv.org/abs/2506.14777", "authors": ["Jules Leguy", "Pierre-Antoine Jean", "Felipe Torres Figueroa", "Sébastien Harispe"], "title": "WebXAII: an open-source web framework to study human-XAI interaction", "comment": null, "summary": "This article introduces WebXAII, an open-source web framework designed to facilitate research on human interaction with eXplainable Artificial Intelligence (XAI) systems. The field of XAI is rapidly expanding, driven by the growing societal implications of the widespread adoption of AI (and in particular machine learning) across diverse applications. Researchers who study the interaction between humans and XAI techniques typically develop ad hoc interfaces in order to conduct their studies. These interfaces are usually not shared alongside the results of the studies, which limits their reusability and the reproducibility of experiments. In response, we design and implement WebXAII, a web-based platform that can embody full experimental protocols, meaning that it can present all aspects of the experiment to human participants and record their responses. The experimental protocols are translated into a composite architecture of generic views and modules, which offers a lot of flexibility. The architecture is defined in a structured configuration file, so that protocols can be implemented with minimal programming skills. We demonstrate that WebXAII can effectively embody relevant protocols, by reproducing the protocol of a state-of-the-art study of the literature. The framework is available at https://github.com/PAJEAN/WebXAII.", "AI": {"tldr": "WebXAII是一个开源框架，旨在简化人类与可解释人工智能（XAI）交互的研究，通过标准化实验协议提高可重用性和可重复性。", "motivation": "XAI领域快速发展，但现有研究通常使用临时开发的接口，缺乏共享和可重复性。", "method": "设计并实现WebXAII，一个基于Web的平台，支持完整实验协议的实现，通过结构化配置文件定义实验流程。", "result": "WebXAII成功复现了文献中的先进研究协议，展示了其灵活性和实用性。", "conclusion": "WebXAII为XAI交互研究提供了标准化工具，促进了实验的可重复性和共享。"}}
{"id": "2506.15026", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15026", "abs": "https://arxiv.org/abs/2506.15026", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "Algorithmic Approaches to Enhance Safety in Autonomous Vehicles: Minimizing Lane Changes and Merging", "comment": null, "summary": "The rapid advancements in autonomous vehicle (AV) technology promise enhanced safety and operational efficiency. However, frequent lane changes and merging maneuvers continue to pose significant safety risks and disrupt traffic flow. This paper introduces the Minimizing Lane Change Algorithm (MLCA), a state-machine-based approach designed to reduce unnecessary lane changes, thereby enhancing both traffic safety and efficiency. The MLCA algorithm prioritizes maintaining lane stability unless safety-critical conditions necessitate a lane change. The algorithm's effectiveness was evaluated through simulations conducted on the SUMO platform, comparing its performance against established models, including LC2017 and MOBIL. Results demonstrate substantial reductions in lane changes and collisions, leading to smoother traffic flow and improved safety metrics. Additionally, the study highlights the MLCA's adaptability to various traffic densities and roadway configurations, showcasing its potential for wide-scale deployment in real-world AV systems. Future work aims to validate these findings in more complex scenarios using the CARLA simulator, which will enable the testing of the algorithm under more dynamic and high-fidelity conditions, such as urban traffic environments with diverse road users. Moreover, the integration of cybersecurity measures for vehicle-to-vehicle (V2V) communication will be explored to ensure robust and secure data exchange, further enhancing the reliability and safety of AV operations. This research contributes to the broader goal of developing intelligent traffic systems that optimize both individual vehicle performance and overall traffic network efficiency.", "AI": {"tldr": "论文提出了一种最小化变道算法（MLCA），通过减少不必要的变道来提升自动驾驶车辆的安全性和交通效率，并在模拟中验证了其有效性。", "motivation": "自动驾驶车辆频繁变道和并线操作带来安全风险和交通流干扰，需要一种方法减少这些行为。", "method": "采用基于状态机的MLCA算法，优先保持车道稳定性，仅在安全关键条件下变道，并通过SUMO平台进行模拟评估。", "result": "相比LC2017和MOBIL模型，MLCA显著减少变道和碰撞，提升交通流畅度和安全性，且适应不同交通密度和道路配置。", "conclusion": "MLCA算法具有广泛部署潜力，未来将在CARLA模拟器中验证复杂场景，并探索V2V通信的网络安全措施，以进一步提升自动驾驶系统的可靠性和安全性。"}}
{"id": "2506.14857", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14857", "abs": "https://arxiv.org/abs/2506.14857", "authors": ["Suman Raj", "Swapnil Padhi", "Ruchi Bhoot", "Prince Modi", "Yogesh Simmhan"], "title": "Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired", "comment": "16 pages, 7 figures; Accepted as Late-Breaking Results at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023", "summary": "Autonomous navigation by drones using onboard sensors combined with machine learning and computer vision algorithms is impacting a number of domains, including agriculture, logistics, and disaster management. In this paper, we examine the use of drones for assisting visually impaired people (VIPs) in navigating through outdoor urban environments. Specifically, we present a perception-based path planning system for local planning around the neighborhood of the VIP, integrated with a global planner based on GPS and maps for coarse planning. We represent the problem using a geometric formulation and propose a multi DNN based framework for obstacle avoidance of the UAV as well as the VIP. Our evaluations conducted on a drone human system in a university campus environment verifies the feasibility of our algorithms in three scenarios; when the VIP walks on a footpath, near parked vehicles, and in a crowded street.", "AI": {"tldr": "无人机通过机载传感器结合机器学习和计算机视觉算法实现自主导航，应用于农业、物流和灾害管理等领域。本文探讨无人机辅助视障人士（VIPs）在户外城市环境中导航，提出了一种基于感知的局部路径规划系统，并与基于GPS和地图的全局规划器结合。通过几何问题建模和多DNN框架实现无人机和VIP的避障。实验验证了算法在三种场景下的可行性。", "motivation": "研究无人机如何辅助视障人士在复杂城市环境中导航，解决传统导航工具的局限性。", "method": "提出基于感知的局部路径规划系统，结合全局规划器，使用几何建模和多DNN框架实现避障。", "result": "在校园环境中验证了算法在三种场景（人行道、停车区、拥挤街道）的可行性。", "conclusion": "无人机结合多DNN框架可为视障人士提供有效的导航辅助，具有实际应用潜力。"}}
{"id": "2506.14805", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.14805", "abs": "https://arxiv.org/abs/2506.14805", "authors": ["Yang Yao", "Lingyu Li", "Jiaxin Song", "Chiyu Chen", "Zhenqi He", "Yixu Wang", "Xin Wang", "Tianle Gu", "Jie Li", "Yan Teng", "Yingchun Wang"], "title": "Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?", "comment": null, "summary": "As Multimodal Large Language Models (MLLMs) continue to evolve, their cognitive and reasoning capabilities have seen remarkable progress. However, challenges in visual fine-grained perception and commonsense causal inference persist. This paper introduces Argus Inspection, a multimodal benchmark with two levels of difficulty, emphasizing detailed visual recognition while incorporating real-world commonsense understanding to evaluate causal reasoning abilities. Expanding on it, we present the Eye of Panoptes framework, which integrates a binary parametric Sigmoid metric with an indicator function, enabling a more holistic evaluation of MLLMs' responses in opinion-based reasoning tasks. Experiments conducted on 26 mainstream MLLMs reveal that the highest performance in visual fine-grained reasoning reaches only 0.46, highlighting considerable potential for enhancement. Our research offers valuable perspectives for the continued refinement of MLLMs.", "AI": {"tldr": "论文提出了Argus Inspection基准和Eye of Panoptes框架，用于评估多模态大语言模型（MLLMs）的细粒度视觉感知和因果推理能力，实验显示当前模型的性能仍有较大提升空间。", "motivation": "尽管MLLMs在认知和推理能力上取得显著进展，但在细粒度视觉感知和常识因果推理方面仍存在挑战。", "method": "引入Argus Inspection基准（含两个难度级别）和Eye of Panoptes框架（结合Sigmoid度量与指示函数），以全面评估MLLMs的推理能力。", "result": "在26个主流MLLMs上的实验表明，视觉细粒度推理的最高性能仅为0.46，显示模型仍需改进。", "conclusion": "研究为MLLMs的进一步优化提供了有价值的视角。"}}
{"id": "2506.14781", "categories": ["cs.LG", "cond-mat.stat-mech", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14781", "abs": "https://arxiv.org/abs/2506.14781", "authors": ["Corentin Delacour", "M Mahmudul Hasan Sajeeb", "Joao P. Hespanha", "Kerem Y. Camsari"], "title": "Two-dimensional Parallel Tempering for Constrained Optimization", "comment": null, "summary": "Sampling Boltzmann probability distributions plays a key role in machine learning and optimization, motivating the design of hardware accelerators such as Ising machines. While the Ising model can in principle encode arbitrary optimization problems, practical implementations are often hindered by soft constraints that either slow down mixing when too strong, or fail to enforce feasibility when too weak. We introduce a two-dimensional extension of the powerful parallel tempering algorithm (PT) that addresses this challenge by adding a second dimension of replicas interpolating the penalty strengths. This scheme ensures constraint satisfaction in the final replicas, analogous to low-energy states at low temperature. The resulting two-dimensional parallel tempering algorithm (2D-PT) improves mixing in heavily constrained replicas and eliminates the need to explicitly tune the penalty strength. In a representative example of graph sparsification with copy constraints, 2D-PT achieves near-ideal mixing, with Kullback-Leibler divergence decaying as O(1/t). When applied to sparsified Wishart instances, 2D-PT yields orders of magnitude speedup over conventional PT with the same number of replicas. The method applies broadly to constrained Ising problems and can be deployed on existing Ising machines.", "AI": {"tldr": "论文提出了一种二维并行回火算法（2D-PT），用于解决Ising模型中软约束带来的问题，显著提升了混合效率和约束满足性。", "motivation": "Ising模型在机器学习和优化中广泛应用，但软约束的强度难以平衡，影响性能和可行性。", "method": "扩展了并行回火算法，增加第二维度的副本以插值惩罚强度，确保约束满足。", "result": "在图形稀疏化和Wishart实例中，2D-PT实现了接近理想的混合效率，速度提升显著。", "conclusion": "2D-PT适用于广泛的约束Ising问题，可直接部署于现有Ising机器。"}}
{"id": "2506.15312", "categories": ["cs.GR", "cs.CR", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.15312", "abs": "https://arxiv.org/abs/2506.15312", "authors": ["Han Wu", "Junyao Li", "Kangbo Zhao", "Sen Zhang", "Yukai Shi", "Liang Lin"], "title": "One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning", "comment": "We propose a novel framework for face sketch synthesis, where merely a single pair of samples suffices to enable in-the-wild face sketch synthesis", "summary": "Face sketch synthesis is a technique aimed at converting face photos into sketches. Existing face sketch synthesis research mainly relies on training with numerous photo-sketch sample pairs from existing datasets. However, these large-scale discriminative learning methods will have to face problems such as data scarcity and high human labor costs. Once the training data becomes scarce, their generative performance significantly degrades. In this paper, we propose a one-shot face sketch synthesis method based on diffusion models. We optimize text instructions on a diffusion model using face photo-sketch image pairs. Then, the instructions derived through gradient-based optimization are used for inference. To simulate real-world scenarios more accurately and evaluate method effectiveness more comprehensively, we introduce a new benchmark named One-shot Face Sketch Dataset (OS-Sketch). The benchmark consists of 400 pairs of face photo-sketch images, including sketches with different styles and photos with different backgrounds, ages, sexes, expressions, illumination, etc. For a solid out-of-distribution evaluation, we select only one pair of images for training at each time, with the rest used for inference. Extensive experiments demonstrate that the proposed method can convert various photos into realistic and highly consistent sketches in a one-shot context. Compared to other methods, our approach offers greater convenience and broader applicability. The dataset will be available at: https://github.com/HanWu3125/OS-Sketch", "AI": {"tldr": "提出了一种基于扩散模型的单次人脸素描合成方法，通过优化文本指令实现高效生成，并引入了新的基准数据集OS-Sketch。", "motivation": "解决现有方法因数据稀缺和人力成本高导致的生成性能下降问题。", "method": "利用扩散模型优化文本指令，通过梯度优化生成素描，并在单次训练场景下评估。", "result": "实验表明，该方法能高效生成一致且逼真的素描，具有更广泛的适用性。", "conclusion": "该方法在单次学习场景下表现优异，数据集将公开以供进一步研究。"}}
{"id": "2506.15602", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2506.15602", "abs": "https://arxiv.org/abs/2506.15602", "authors": ["Jun He", "Siang Yew Chong", "Xin Yao"], "title": "Estimate Hitting Time by Hitting Probability for Elitist Evolutionary Algorithms", "comment": null, "summary": "Drift analysis is a powerful tool for analyzing the time complexity of evolutionary algorithms. However, it requires manual construction of drift functions to bound hitting time for each specific algorithm and problem. To address this limitation, general linear drift functions were introduced for elitist evolutionary algorithms. But calculating linear bound coefficients effectively remains a problem. This paper proposes a new method called drift analysis of hitting probability to compute these coefficients. Each coefficient is interpreted as a bound on the hitting probability of a fitness level, transforming the task of estimating hitting time into estimating hitting probability. A novel drift analysis method is then developed to estimate hitting probability, where paths are introduced to handle multimodal fitness landscapes. Explicit expressions are constructed to compute hitting probability, significantly simplifying the estimation process. One advantage of the proposed method is its ability to estimate both the lower and upper bounds of hitting time and to compare the performance of two algorithms in terms of hitting time. To demonstrate this application, two algorithms for the knapsack problem, each incorporating feasibility rules and greedy repair respectively, are compared. The analysis indicates that neither constraint handling technique consistently outperforms the other.", "AI": {"tldr": "本文提出了一种新的漂移分析方法，通过计算命中概率来估计进化算法的击中时间，简化了系数计算过程，并比较了两种算法的性能。", "motivation": "漂移分析是分析进化算法时间复杂度的强大工具，但需要手动构造漂移函数。现有方法在计算线性边界系数时仍存在问题，本文旨在解决这一问题。", "method": "提出了一种基于命中概率的漂移分析方法，通过路径处理多模态适应度景观，并构造显式表达式计算命中概率。", "result": "该方法能够估计击中时间的上下界，并比较两种算法的性能。应用于背包问题的两种算法分析表明，约束处理技术无绝对优势。", "conclusion": "新方法简化了漂移分析过程，为算法性能比较提供了有效工具。"}}
{"id": "2506.15029", "categories": ["cs.SD", "cs.CL", "cs.CV", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15029", "abs": "https://arxiv.org/abs/2506.15029", "authors": ["Prateek Mehta", "Anasuya Patil"], "title": "An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW", "comment": "9 pages, 9 figures", "summary": "Knowledge extraction through sound is a distinctive property. Visually impaired individuals often rely solely on Braille books and audio recordings provided by NGOs. Due to limitations in these approaches, blind individuals often cannot access books of their choice. Speech is a more effective mode of communication than text for blind and visually impaired persons, as they can easily respond to sounds. This paper presents the development of an accurate, reliable, cost-effective, and user-friendly optical character recognition (OCR)-based speech synthesis system. The OCR-based system has been implemented using Laboratory Virtual Instrument Engineering Workbench (LabVIEW).", "AI": {"tldr": "开发了一种基于OCR的语音合成系统，帮助视障人士通过声音获取书籍内容。", "motivation": "视障人士通常依赖盲文书籍和音频资源，但这些资源有限且无法满足个性化需求，语音是更有效的沟通方式。", "method": "使用LabVIEW实现OCR技术，将文本转换为语音。", "result": "系统准确、可靠、成本低且用户友好。", "conclusion": "OCR语音合成系统为视障人士提供了更便捷的书籍访问方式。"}}
{"id": "2506.14799", "categories": ["cs.HC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14799", "abs": "https://arxiv.org/abs/2506.14799", "authors": ["Evdoxia Taka", "Debadyuti Bhattacharya", "Joanne Garde-Hansen", "Sanjay Sharma", "Tanaya Guha"], "title": "Analyzing Character Representation in Media Content using Multimodal Foundation Model: Effectiveness and Trust", "comment": null, "summary": "Recent advances in AI has enabled automated analysis of complex media content at scale and generate actionable insights regarding character representation along such dimensions as gender and age. Past work focused on quantifying representation from audio/video/text using various ML models, but without having the audience in the loop. We ask, even if character distribution along demographic dimensions are available, how useful are they to the general public? Do they actually trust the numbers generated by AI models? Our work addresses these questions through a user study, while proposing a new AI-based character representation and visualization tool. Our tool based on the Contrastive Language Image Pretraining (CLIP) foundation model to analyze visual screen data to quantify character representation across dimensions of age and gender. We also designed effective visualizations suitable for presenting such analytics to lay audience. Next, we conducted a user study to seek empirical evidence on the usefulness and trustworthiness of the AI-generated results for carefully chosen movies presented in the form of our visualizations. We note that participants were able to understand the analytics from our visualization, and deemed the tool `overall useful'. Participants also indicated a need for more detailed visualizations to include more demographic categories and contextual information of the characters. Participants' trust in AI-based gender and age models is seen to be moderate to low, although they were not against the use of AI in this context. Our tool including code, benchmarking, and data from the user study can be found here: https://anonymous.4open.science/r/Character-Representation-Media-FF7B", "AI": {"tldr": "论文提出了一种基于CLIP模型的AI工具，用于分析影视内容中的角色性别和年龄分布，并通过用户研究验证其实用性和可信度。", "motivation": "研究动机是探讨AI生成的角色分布数据对公众的实用性和可信度，填补了过去研究未考虑受众需求的空白。", "method": "方法包括开发基于CLIP模型的工具来分析视觉数据，设计适合普通观众的视觉化展示，并通过用户研究验证工具效果。", "result": "用户能够理解视觉化分析结果，认为工具总体有用，但对AI模型的信任度中等偏低，希望增加更多人口统计类别和上下文信息。", "conclusion": "结论是AI工具在角色分析中有潜力，但需改进以提升可信度和实用性。"}}
{"id": "2506.15082", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15082", "abs": "https://arxiv.org/abs/2506.15082", "authors": ["Yimian Ding", "Jingzehua Xu", "Guanwen Xie", "Shuai Zhang", "Yi Li"], "title": "Make Your AUV Adaptive: An Environment-Aware Reinforcement Learning Framework For Underwater Tasks", "comment": "This paper has been accepted by IROS 2025", "summary": "This study presents a novel environment-aware reinforcement learning (RL) framework designed to augment the operational capabilities of autonomous underwater vehicles (AUVs) in underwater environments. Departing from traditional RL architectures, the proposed framework integrates an environment-aware network module that dynamically captures flow field data, effectively embedding this critical environmental information into the state space. This integration facilitates real-time environmental adaptation, significantly enhancing the AUV's situational awareness and decision-making capabilities. Furthermore, the framework incorporates AUV structure characteristics into the optimization process, employing a large language model (LLM)-based iterative refinement mechanism that leverages both environmental conditions and training outcomes to optimize task performance. Comprehensive experimental evaluations demonstrate the framework's superior performance, robustness and adaptability.", "AI": {"tldr": "本文提出了一种新型环境感知强化学习框架，用于提升自主水下航行器（AUV）在水下环境中的操作能力。", "motivation": "传统强化学习架构未充分利用环境信息，限制了AUV在复杂水下环境中的适应性和决策能力。", "method": "框架集成了环境感知网络模块，动态捕捉流场数据，并将其嵌入状态空间；同时结合AUV结构特征，利用基于大语言模型（LLM）的迭代优化机制。", "result": "实验表明，该框架在性能、鲁棒性和适应性方面表现优异。", "conclusion": "该框架显著提升了AUV的环境适应性和任务执行能力，为水下自主系统提供了新思路。"}}
{"id": "2506.14865", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14865", "abs": "https://arxiv.org/abs/2506.14865", "authors": ["Xuemin Chi", "Hakan Girgin", "Tobias Löw", "Yangyang Xie", "Teng Xue", "Jihao Huang", "Cheng Hu", "Zhitao Liu", "Sylvain Calinon"], "title": "Efficient and Real-Time Motion Planning for Robotics Using Projection-Based Optimization", "comment": "submitted to IROS 2025", "summary": "Generating motions for robots interacting with objects of various shapes is a complex challenge, further complicated by the robot geometry and multiple desired behaviors. While current robot programming tools (such as inverse kinematics, collision avoidance, and manipulation planning) often treat these problems as constrained optimization, many existing solvers focus on specific problem domains or do not exploit geometric constraints effectively. We propose an efficient first-order method, Augmented Lagrangian Spectral Projected Gradient Descent (ALSPG), which leverages geometric projections via Euclidean projections, Minkowski sums, and basis functions. We show that by using geometric constraints rather than full constraints and gradients, ALSPG significantly improves real-time performance. Compared to second-order methods like iLQR, ALSPG remains competitive in the unconstrained case. We validate our method through toy examples and extensive simulations, and demonstrate its effectiveness on a 7-axis Franka robot, a 6-axis P-Rob robot and a 1:10 scale car in real-world experiments. Source codes, experimental data and videos are available on the project webpage: https://sites.google.com/view/alspg-oc", "AI": {"tldr": "提出了一种高效的一阶方法ALSPG，通过几何投影优化机器人运动生成，显著提升实时性能。", "motivation": "机器人运动生成涉及复杂几何约束和多目标行为，现有方法未能充分利用几何约束或局限于特定问题。", "method": "采用ALSPG方法，结合欧几里得投影、Minkowski和及基函数，利用几何约束而非完整约束和梯度。", "result": "ALSPG在实时性能上优于二阶方法（如iLQR），并在仿真和真实机器人实验中验证了有效性。", "conclusion": "ALSPG是一种高效且通用的机器人运动生成方法，适用于多种场景和机器人类型。"}}
{"id": "2506.14816", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14816", "abs": "https://arxiv.org/abs/2506.14816", "authors": ["Alavikunhu Panthakkan", "Zubair Medammal", "S M Anzar", "Fatma Taher", "Hussain Al-Ahmad"], "title": "A Hybrid ConvNeXt-EfficientNet AI Solution for Precise Falcon Disease Detection", "comment": null, "summary": "Falconry, a revered tradition involving the training and hunting with falcons, requires meticulous health surveillance to ensure the health and safety of these prized birds, particularly in hunting scenarios. This paper presents an innovative method employing a hybrid of ConvNeXt and EfficientNet AI models for the classification of falcon diseases. The study focuses on accurately identifying three conditions: Normal, Liver Disease and 'Aspergillosis'. A substantial dataset was utilized for training and validating the model, with an emphasis on key performance metrics such as accuracy, precision, recall, and F1-score. Extensive testing and analysis have shown that our concatenated AI model outperforms traditional diagnostic methods and individual model architectures. The successful implementation of this hybrid AI model marks a significant step forward in precise falcon disease detection and paves the way for future developments in AI-powered avian healthcare solutions.", "AI": {"tldr": "本文提出了一种结合ConvNeXt和EfficientNet的混合AI模型，用于准确分类猎鹰疾病（正常、肝病和曲霉病），并证明其优于传统方法。", "motivation": "猎鹰训练和狩猎需要确保猎鹰健康，传统疾病诊断方法存在局限性，因此需要更精确的AI解决方案。", "method": "采用ConvNeXt和EfficientNet混合模型，利用大数据集训练和验证，关注准确性、精确度、召回率和F1分数等指标。", "result": "混合模型在疾病分类上优于传统方法和单一模型架构，表现显著提升。", "conclusion": "该混合AI模型为猎鹰疾病检测提供了更精确的工具，并为未来AI驱动的禽类医疗解决方案奠定了基础。"}}
{"id": "2506.14782", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2506.14782", "abs": "https://arxiv.org/abs/2506.14782", "authors": ["Joseph Geraci", "Bessi Qorri", "Christian Cumbaa", "Mike Tsay", "Paul Leonczyk", "Luca Pani"], "title": "Integrating Dynamical Systems Learning with Foundational Models: A Meta-Evolutionary AI Framework for Clinical Trials", "comment": "27 pages", "summary": "Artificial intelligence (AI) has evolved into an ecosystem of specialized \"species,\" each with unique strengths. We analyze two: DeepSeek-V3, a 671-billion-parameter Mixture of Experts large language model (LLM) exemplifying scale-driven generality, and NetraAI, a dynamical system-based framework engineered for stability and interpretability on small clinical trial datasets. We formalize NetraAI's foundations, combining contraction mappings, information geometry, and evolutionary algorithms to identify predictive patient cohorts. Features are embedded in a metric space and iteratively contracted toward stable attractors that define latent subgroups. A pseudo-temporal embedding and long-range memory enable exploration of higher-order feature interactions, while an internal evolutionary loop selects compact, explainable 2-4-variable bundles (\"Personas\").\n  To guide discovery, we introduce an LLM Strategist as a meta-evolutionary layer that observes Persona outputs, prioritizes promising variables, injects domain knowledge, and assesses robustness. This two-tier architecture mirrors the human scientific process: NetraAI as experimentalist, the LLM as theorist, forming a self-improving loop.\n  In case studies (schizophrenia, depression, pancreatic cancer), NetraAI uncovered small, high-effect-size subpopulations that transformed weak baseline models (AUC ~0.50-0.68) into near-perfect classifiers using only a few features. We position NetraAI at the intersection of dynamical systems, information geometry, and evolutionary learning, aligned with emerging concept-level reasoning paradigms such as LeCun's Joint Embedding Predictive Architecture (JEPA). By prioritizing reliable, explainable knowledge, NetraAI offers a new generation of adaptive, self-reflective AI to accelerate clinical discovery.", "AI": {"tldr": "论文分析了两种AI方法：DeepSeek-V3（大规模通用模型）和NetraAI（针对小数据集设计的稳定可解释框架），后者通过动态系统和进化算法发现高效应子群。", "motivation": "解决小规模临床数据集的稳定性和可解释性问题，同时结合动态系统与进化算法提升预测能力。", "method": "NetraAI结合收缩映射、信息几何和进化算法，通过伪时间嵌入和长程记忆探索高阶特征交互，并引入LLM Strategist作为元进化层。", "result": "在精神分裂症、抑郁症和胰腺癌案例中，NetraAI将弱基线模型（AUC 0.50-0.68）提升为近乎完美分类器。", "conclusion": "NetraAI为临床发现提供了自适应、可解释的新一代AI，结合动态系统与概念级推理范式。"}}
{"id": "2506.15684", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15684", "abs": "https://arxiv.org/abs/2506.15684", "authors": ["Qingming Liu", "Zhen Liu", "Dinghuai Zhang", "Kui Jia"], "title": "Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards", "comment": "Technical Report (21 pages, 21 figures)", "summary": "Generating high-quality and photorealistic 3D assets remains a longstanding challenge in 3D vision and computer graphics. Although state-of-the-art generative models, such as diffusion models, have made significant progress in 3D generation, they often fall short of human-designed content due to limited ability to follow instructions, align with human preferences, or produce realistic textures, geometries, and physical attributes. In this paper, we introduce Nabla-R2D3, a highly effective and sample-efficient reinforcement learning alignment framework for 3D-native diffusion models using 2D rewards. Built upon the recently proposed Nabla-GFlowNet method, which matches the score function to reward gradients in a principled manner for reward finetuning, our Nabla-R2D3 enables effective adaptation of 3D diffusion models using only 2D reward signals. Extensive experiments show that, unlike vanilla finetuning baselines which either struggle to converge or suffer from reward hacking, Nabla-R2D3 consistently achieves higher rewards and reduced prior forgetting within a few finetuning steps.", "AI": {"tldr": "Nabla-R2D3是一种基于强化学习的对齐框架，用于优化3D扩散模型，仅需2D奖励信号即可高效生成高质量3D内容。", "motivation": "现有3D生成模型（如扩散模型）在遵循指令、对齐人类偏好及生成真实纹理、几何和物理属性方面表现不足。", "method": "基于Nabla-GFlowNet方法，提出Nabla-R2D3框架，通过2D奖励信号对3D扩散模型进行高效对齐和优化。", "result": "实验表明，Nabla-R2D3在少量优化步骤内即可实现更高奖励和减少先验遗忘，优于传统基线方法。", "conclusion": "Nabla-R2D3为3D生成模型的强化学习对齐提供了高效且样本效率高的解决方案。"}}
{"id": "2506.14951", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2506.14951", "abs": "https://arxiv.org/abs/2506.14951", "authors": ["Flavio Martinelli", "Alexander Van Meegen", "Berfin Şimşek", "Wulfram Gerstner", "Johanni Brea"], "title": "Flat Channels to Infinity in Neural Loss Landscapes", "comment": null, "summary": "The loss landscapes of neural networks contain minima and saddle points that may be connected in flat regions or appear in isolation. We identify and characterize a special structure in the loss landscape: channels along which the loss decreases extremely slowly, while the output weights of at least two neurons, $a_i$ and $a_j$, diverge to $\\pm$infinity, and their input weight vectors, $\\mathbf{w_i}$ and $\\mathbf{w_j}$, become equal to each other. At convergence, the two neurons implement a gated linear unit: $a_iσ(\\mathbf{w_i} \\cdot \\mathbf{x}) + a_jσ(\\mathbf{w_j} \\cdot \\mathbf{x}) \\rightarrow σ(\\mathbf{w} \\cdot \\mathbf{x}) + (\\mathbf{v} \\cdot \\mathbf{x}) σ'(\\mathbf{w} \\cdot \\mathbf{x})$. Geometrically, these channels to infinity are asymptotically parallel to symmetry-induced lines of critical points. Gradient flow solvers, and related optimization methods like SGD or ADAM, reach the channels with high probability in diverse regression settings, but without careful inspection they look like flat local minima with finite parameter values. Our characterization provides a comprehensive picture of these quasi-flat regions in terms of gradient dynamics, geometry, and functional interpretation. The emergence of gated linear units at the end of the channels highlights a surprising aspect of the computational capabilities of fully connected layers.", "AI": {"tldr": "论文研究了神经网络损失景观中的特殊结构——通道，其中损失下降极慢，而某些神经元的输出权重趋于无穷大，输入权重趋于相等，最终形成门控线性单元。", "motivation": "探索神经网络损失景观中的特殊结构及其对优化和功能的影响。", "method": "通过梯度动力学、几何分析和功能解释，识别和表征这些通道结构。", "result": "发现梯度流等优化方法会高概率进入这些通道，最终形成门控线性单元。", "conclusion": "这些通道揭示了全连接层的计算能力，为理解损失景观提供了新视角。"}}
{"id": "2506.15154", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15154", "abs": "https://arxiv.org/abs/2506.15154", "authors": ["Anuradha Chopra", "Abhinaba Roy", "Dorien Herremans"], "title": "SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning", "comment": "14 pages, 2 figures, Accepted to AIMC 2025", "summary": "Detailed captions that accurately reflect the characteristics of a music piece can enrich music databases and drive forward research in music AI. This paper introduces a multi-task music captioning model, SonicVerse, that integrates caption generation with auxiliary music feature detection tasks such as key detection, vocals detection, and more, so as to directly capture both low-level acoustic details as well as high-level musical attributes. The key contribution is a projection-based architecture that transforms audio input into language tokens, while simultaneously detecting music features through dedicated auxiliary heads. The outputs of these heads are also projected into language tokens, to enhance the captioning input. This framework not only produces rich, descriptive captions for short music fragments but also directly enables the generation of detailed time-informed descriptions for longer music pieces, by chaining the outputs using a large-language model. To train the model, we extended the MusicBench dataset by annotating it with music features using MIRFLEX, a modular music feature extractor, resulting in paired audio, captions and music feature data. Experimental results show that incorporating features in this way improves the quality and detail of the generated captions.", "AI": {"tldr": "SonicVerse是一个多任务音乐字幕生成模型，通过结合音乐特征检测任务（如调性检测、人声检测等）生成丰富的音乐描述。其投影架构将音频输入转换为语言标记，并利用辅助任务增强字幕生成。实验表明，该方法提升了字幕的质量和细节。", "motivation": "准确的音乐描述可以丰富音乐数据库并推动音乐AI研究。现有的字幕生成模型缺乏对音乐特征的直接捕捉，因此需要一种能同时处理低层次声学细节和高层次音乐属性的方法。", "method": "提出SonicVerse模型，采用多任务学习框架，结合字幕生成与音乐特征检测任务。通过投影架构将音频和特征检测输出转换为语言标记，并利用大语言模型生成时间感知的详细描述。", "result": "实验结果表明，结合音乐特征检测任务显著提升了生成字幕的质量和细节。", "conclusion": "SonicVerse通过多任务学习和投影架构，成功生成了丰富且详细的音乐描述，为音乐AI研究提供了新工具。"}}
{"id": "2506.14809", "categories": ["cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14809", "abs": "https://arxiv.org/abs/2506.14809", "authors": ["Peng Jiang", "Vinicius Cezar Monteiro de Lira", "Antonio Maiorino"], "title": "Impact of a Deployed LLM Survey Creation Tool through the IS Success Model", "comment": null, "summary": "Surveys are a cornerstone of Information Systems (IS) research, yet creating high-quality surveys remains labor-intensive, requiring both domain expertise and methodological rigor. With the evolution of large language models (LLMs), new opportunities emerge to automate survey generation. This paper presents the real-world deployment of an LLM-powered system designed to accelerate data collection while maintaining survey quality. Deploying such systems in production introduces real-world complexity, including diverse user needs and quality control. We evaluate the system using the DeLone and McLean IS Success Model to understand how generative AI can reshape a core IS method. This study makes three key contributions. To our knowledge, this is the first application of the IS Success Model to a generative AI system for survey creation. In addition, we propose a hybrid evaluation framework combining automated and human assessments. Finally, we implement safeguards that mitigate post-deployment risks and support responsible integration into IS workflows.", "AI": {"tldr": "本文探讨了利用大语言模型（LLM）自动化生成高质量调查问卷的可行性，并提出了混合评估框架和安全措施。", "motivation": "调查问卷是信息系统（IS）研究的核心工具，但其制作过程耗时且需要专业知识。LLM的发展为自动化问卷生成提供了新机会。", "method": "部署了一个LLM驱动的系统，结合DeLone和McLean IS成功模型进行评估，并提出混合评估框架和安全措施。", "result": "系统成功加速了数据收集，同时保持了问卷质量，并通过混合评估框架验证了其有效性。", "conclusion": "LLM在IS调查问卷生成中具有潜力，混合评估框架和安全措施为其实际应用提供了支持。"}}
{"id": "2506.15105", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15105", "abs": "https://arxiv.org/abs/2506.15105", "authors": ["David Nozadze", "Zurab Kiguradze", "Amendra Koul", "Mike Sapozhnikov"], "title": "Skew-Induced Insertion Loss Deviation (SILD) and FOM_SILD: Metrics for Quantifying P/N Skew Effects in High-Speed Channels", "comment": null, "summary": "The rise of AI workloads and growing data center demands have driven the need for ultra-high-speed interconnects exceeding 200 Gb/s. As unit intervals (UI) shrink, even a few picoseconds of P/N skew can degrade serializer-deserializer (SerDes) performance. Traditional methods for quantifying skew fall short in capturing its impact. We introduce two new metrics: 1) Skew-Induced Insertion Loss Deviation (SILD) and 2) its complementary Figure of Merit (FOM_SILD), analytically developed to assess P/N skew effects. Measured S-parameters confirm FOM_SILD reciprocity, while simulations of 224G PAM4 SerDes show strong correlation with bit error rate (BER) trends. This approach offers a robust framework for analyzing skew in next-generation ultra-high-speed interconnects.", "AI": {"tldr": "论文提出了两种新指标（SILD和FOM_SILD）来量化P/N偏斜对高速互连性能的影响，并通过实验和仿真验证了其有效性。", "motivation": "随着AI工作负载和数据中心需求的增长，传统方法无法准确评估超高速互连中P/N偏斜的影响。", "method": "开发了两种新指标（SILD和FOM_SILD），并通过S参数测量和224G PAM4 SerDes仿真验证。", "result": "实验证实FOM_SILD的互易性，仿真显示其与误码率趋势高度相关。", "conclusion": "该方法为下一代超高速互连中的偏斜分析提供了可靠框架。"}}
{"id": "2506.14968", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14968", "abs": "https://arxiv.org/abs/2506.14968", "authors": ["Rajat Kumar Jenamani", "Tom Silver", "Ben Dodson", "Shiqin Tong", "Anthony Song", "Yuting Yang", "Ziang Liu", "Benjamin Howe", "Aimee Whitneck", "Tapomayukh Bhattacharjee"], "title": "FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization", "comment": "RSS 2025 - Outstanding Paper Award & Outstanding Systems Paper Award Finalist", "summary": "Physical caregiving robots hold promise for improving the quality of life of millions worldwide who require assistance with feeding. However, in-home meal assistance remains challenging due to the diversity of activities (e.g., eating, drinking, mouth wiping), contexts (e.g., socializing, watching TV), food items, and user preferences that arise during deployment. In this work, we propose FEAST, a flexible mealtime-assistance system that can be personalized in-the-wild to meet the unique needs of individual care recipients. Developed in collaboration with two community researchers and informed by a formative study with a diverse group of care recipients, our system is guided by three key tenets for in-the-wild personalization: adaptability, transparency, and safety. FEAST embodies these principles through: (i) modular hardware that enables switching between assisted feeding, drinking, and mouth-wiping, (ii) diverse interaction methods, including a web interface, head gestures, and physical buttons, to accommodate diverse functional abilities and preferences, and (iii) parameterized behavior trees that can be safely and transparently adapted using a large language model. We evaluate our system based on the personalization requirements identified in our formative study, demonstrating that FEAST offers a wide range of transparent and safe adaptations and outperforms a state-of-the-art baseline limited to fixed customizations. To demonstrate real-world applicability, we conduct an in-home user study with two care recipients (who are community researchers), feeding them three meals each across three diverse scenarios. We further assess FEAST's ecological validity by evaluating with an Occupational Therapist previously unfamiliar with the system. In all cases, users successfully personalize FEAST to meet their individual needs and preferences. Website: https://emprise.cs.cornell.edu/feast", "AI": {"tldr": "FEAST是一个灵活的用餐辅助系统，通过模块化硬件和多样化交互方法实现个性化，满足不同用户需求。", "motivation": "解决家庭用餐辅助中因活动多样性、情境复杂性和用户偏好差异带来的挑战。", "method": "采用模块化硬件、多样化交互方法和参数化行为树，结合大型语言模型实现安全透明的个性化。", "result": "FEAST在透明性和安全性上优于固定定制基线，并通过用户研究和职业治疗师评估验证了其实际适用性。", "conclusion": "FEAST成功实现了在多样化场景下的个性化用餐辅助，具有实际应用潜力。"}}
{"id": "2506.14823", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14823", "abs": "https://arxiv.org/abs/2506.14823", "authors": ["Harsha Koduri"], "title": "ViLLa: A Neuro-Symbolic approach for Animal Monitoring", "comment": null, "summary": "Monitoring animal populations in natural environments requires systems that can interpret both visual data and human language queries. This work introduces ViLLa (Vision-Language-Logic Approach), a neuro-symbolic framework designed for interpretable animal monitoring. ViLLa integrates three core components: a visual detection module for identifying animals and their spatial locations in images, a language parser for understanding natural language queries, and a symbolic reasoning layer that applies logic-based inference to answer those queries. Given an image and a question such as \"How many dogs are in the scene?\" or \"Where is the buffalo?\", the system grounds visual detections into symbolic facts and uses predefined rules to compute accurate answers related to count, presence, and location. Unlike end-to-end black-box models, ViLLa separates perception, understanding, and reasoning, offering modularity and transparency. The system was evaluated on a range of animal imagery tasks and demonstrates the ability to bridge visual content with structured, human-interpretable queries.", "AI": {"tldr": "ViLLa是一个神经符号框架，用于可解释的动物监测，结合视觉检测、语言解析和符号推理。", "motivation": "开发一个能够解释视觉数据和自然语言查询的系统，以监测自然环境中动物种群。", "method": "ViLLa整合了视觉检测模块（识别动物及其空间位置）、语言解析器（理解自然语言查询）和符号推理层（基于逻辑的推理）。", "result": "系统能够准确回答与数量、存在和位置相关的查询，并在动物图像任务中表现良好。", "conclusion": "ViLLa通过模块化和透明性，成功地将视觉内容与结构化的人类可解释查询相结合。"}}
{"id": "2506.14783", "categories": ["cs.LG", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14783", "abs": "https://arxiv.org/abs/2506.14783", "authors": ["Mohamed Masry", "Mohamed Amen", "Mohamed Elzyat", "Mohamed Hamed", "Norhan Magdy", "Maram Khaled"], "title": "ETS: Open Vocabulary Electroencephalography-To-Text Decoding and Sentiment Classification", "comment": "Graduation project report submitted at Faculty of Computer Science and Artificial Intelligence, Helwan University", "summary": "Decoding natural language from brain activity using non-invasive electroencephalography (EEG) remains a significant challenge in neuroscience and machine learning, particularly for open-vocabulary scenarios where traditional methods struggle with noise and variability. Previous studies have achieved high accuracy on small-closed vocabularies, but it still struggles on open vocabularies. In this study, we propose ETS, a framework that integrates EEG with synchronized eye-tracking data to address two critical tasks: (1) open-vocabulary text generation and (2) sentiment classification of perceived language. Our model achieves a superior performance on BLEU and Rouge score for EEG-To-Text decoding and up to 10% F1 score on EEG-based ternary sentiment classification, which significantly outperforms supervised baselines. Furthermore, we show that our proposed model can handle data from various subjects and sources, showing great potential for high performance open vocabulary eeg-to-text system.", "AI": {"tldr": "论文提出ETS框架，结合EEG和眼动数据，显著提升开放词汇文本生成和情感分类性能。", "motivation": "解决非侵入性EEG在开放词汇场景下解码自然语言的挑战，传统方法因噪声和变异性表现不佳。", "method": "整合EEG与同步眼动数据，设计ETS框架，支持开放词汇文本生成和情感分类。", "result": "在BLEU和Rouge分数上表现优异，情感分类F1分数提升10%，且模型适应多源数据。", "conclusion": "ETS框架在开放词汇EEG解码中潜力巨大，性能显著优于基线方法。"}}
{"id": "2506.15571", "categories": ["cs.LG", "cs.GR"], "pdf": "https://arxiv.org/pdf/2506.15571", "abs": "https://arxiv.org/abs/2506.15571", "authors": ["Le Vu Anh", "Nguyen Viet Anh", "Mehmet Dik", "Tu Nguyen Thi Ngoc"], "title": "MicroRicci: A Greedy and Local Ricci Flow Solver for Self-Tuning Mesh Smoothing", "comment": "9 pages, 8 figures, 4 tables", "summary": "Real-time mesh smoothing at scale remains a formidable challenge: classical Ricci-flow solvers demand costly global updates, while greedy heuristics suffer from slow convergence or brittle tuning. We present MicroRicci, the first truly self-tuning, local Ricci-flow solver that borrows ideas from coding theory and packs them into just 1K + 200 parameters. Its primary core is a greedy syndrome-decoding step that pinpoints and corrects the largest curvature error in O(E) time, augmented by two tiny neural modules that adaptively choose vertices and step sizes on the fly. On a diverse set of 110 SJTU-TMQA meshes, MicroRicci slashes iteration counts from 950+=140 to 400+=80 (2.4x speedup), tightens curvature spread from 0.19 to 0.185, and achieves a remarkable UV-distortion-to-MOS correlation of r = -0.93. It adds only 0.25 ms per iteration (0.80 to 1.05 ms), yielding an end-to-end 1.8x runtime acceleration over state-of-the-art methods. MicroRicci's combination of linear-time updates, automatic hyperparameter adaptation, and high-quality geometric and perceptual results makes it well suited for real-time, resource-limited applications in graphics, simulation, and related fields.", "AI": {"tldr": "MicroRicci是一种自适应的局部Ricci流求解器，通过结合编码理论和轻量级神经网络模块，显著提升了实时网格平滑的效率和效果。", "motivation": "解决传统Ricci流求解器全局更新成本高和贪婪启发式方法收敛慢或调参困难的问题。", "method": "采用贪婪的综合征解码步骤定位和修正最大曲率误差，辅以两个小型神经网络模块动态选择顶点和步长。", "result": "在110个SJTU-TMQA网格上，迭代次数减少2.4倍，曲率分布更紧，UV失真与MOS相关性达-0.93，每次迭代仅增加0.25毫秒。", "conclusion": "MicroRicci在实时、资源受限的图形和模拟应用中表现出色，兼具高效性和高质量结果。"}}
{"id": "2506.15064", "categories": ["cs.LG", "cs.NE", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.15064", "abs": "https://arxiv.org/abs/2506.15064", "authors": ["Ethan Mulle", "Wei Kang", "Qi Gong"], "title": "HiPreNets: High-Precision Neural Networks through Progressive Training", "comment": null, "summary": "Deep neural networks are powerful tools for solving nonlinear problems in science and engineering, but training highly accurate models becomes challenging as problem complexity increases. Non-convex optimization and numerous hyperparameters to tune make performance improvement difficult, and traditional approaches often prioritize minimizing mean squared error (MSE) while overlooking $L^{\\infty}$ error, which is the critical focus in many applications. To address these challenges, we present a progressive framework for training and tuning high-precision neural networks (HiPreNets). Our approach refines a previously explored staged training technique for neural networks that improves an existing fully connected neural network by sequentially learning its prediction residuals using additional networks, leading to improved overall accuracy. We discuss how to take advantage of the structure of the residuals to guide the choice of loss function, number of parameters to use, and ways to introduce adaptive data sampling techniques. We validate our framework's effectiveness through several benchmark problems.", "AI": {"tldr": "提出了一种渐进式框架HiPreNets，通过分阶段训练和残差学习提高神经网络的精度，重点关注L∞误差。", "motivation": "解决复杂问题中神经网络训练困难、传统方法忽视L∞误差的问题。", "method": "采用分阶段训练技术，通过额外网络逐步学习预测残差，优化损失函数和参数选择。", "result": "在多个基准问题上验证了框架的有效性。", "conclusion": "HiPreNets框架显著提高了神经网络的精度，尤其在L∞误差方面表现优异。"}}
{"id": "2506.15514", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15514", "abs": "https://arxiv.org/abs/2506.15514", "authors": ["Jaza Syed", "Ivan Meresman Higgs", "Ondřej Cífka", "Mark Sandler"], "title": "Exploiting Music Source Separation for Automatic Lyrics Transcription with Whisper", "comment": "Accepted at 2025 ICME Workshop AI for Music", "summary": "Automatic lyrics transcription (ALT) remains a challenging task in the field of music information retrieval, despite great advances in automatic speech recognition (ASR) brought about by transformer-based architectures in recent years. One of the major challenges in ALT is the high amplitude of interfering audio signals relative to conventional ASR due to musical accompaniment. Recent advances in music source separation have enabled automatic extraction of high-quality separated vocals, which could potentially improve ALT performance. However, the effect of source separation has not been systematically investigated in order to establish best practices for its use. This work examines the impact of source separation on ALT using Whisper, a state-of-the-art open source ASR model. We evaluate Whisper's performance on original audio, separated vocals, and vocal stems across short-form and long-form transcription tasks. For short-form, we suggest a concatenation method that results in a consistent reduction in Word Error Rate (WER). For long-form, we propose an algorithm using source separation as a vocal activity detector to derive segment boundaries, which results in a consistent reduction in WER relative to Whisper's native long-form algorithm. Our approach achieves state-of-the-art results for an open source system on the Jam-ALT long-form ALT benchmark, without any training or fine-tuning. We also publish MUSDB-ALT, the first dataset of long-form lyric transcripts following the Jam-ALT guidelines for which vocal stems are publicly available.", "AI": {"tldr": "论文研究了音乐源分离对自动歌词转录（ALT）的影响，使用Whisper模型评估了不同音频输入的效果，并提出改进方法，在短形式和长形式任务中均降低了词错误率（WER）。", "motivation": "尽管自动语音识别（ASR）在Transformer架构下取得进展，但ALT仍因音乐伴奏的干扰信号而具有挑战性。音乐源分离技术的进步为ALT性能提升提供了可能，但其影响尚未系统研究。", "method": "使用Whisper模型评估原始音频、分离人声和人声干声的效果，提出短形式的拼接方法和长形式的基于源分离的分段算法。", "result": "短形式任务中拼接方法降低了WER；长形式任务中分段算法优于Whisper原生方法，并在Jam-ALT基准测试中达到开源系统的最佳效果。", "conclusion": "音乐源分离显著提升ALT性能，无需额外训练即可实现最佳效果，并发布了首个公开的长形式歌词转录数据集MUSDB-ALT。"}}
{"id": "2506.14820", "categories": ["cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14820", "abs": "https://arxiv.org/abs/2506.14820", "authors": ["Hyeon Jeon", "Hyunwook Lee", "Yun-Hsin Kuo", "Taehyun Yang", "Daniel Archambault", "Sungahn Ko", "Takanori Fujiwara", "Kwan-Liu Ma", "Jinwook Seo"], "title": "Navigating High-Dimensional Backstage: A Guide for Exploring Literature for the Reliable Use of Dimensionality Reduction", "comment": "EG/VGTC EuroVis 2025 Short paper", "summary": "Visual analytics using dimensionality reduction (DR) can easily be unreliable for various reasons, e.g., inherent distortions in representing the original data. The literature has thus proposed a wide range of methodologies to make DR-based visual analytics reliable. However, the diversity and extensiveness of the literature can leave novice analysts and researchers uncertain about where to begin and proceed. To address this problem, we propose a guide for reading papers for reliable visual analytics with DR. Relying on the previous classification of the relevant literature, our guide helps both practitioners to (1) assess their current DR expertise and (2) identify papers that will further enhance their understanding. Interview studies with three experts in DR and data visualizations validate the significance, comprehensiveness, and usefulness of our guide.", "AI": {"tldr": "本文提出了一份指南，帮助新手分析师和研究人员在维度降维（DR）的可视化分析中可靠地阅读论文。", "motivation": "由于维度降维在可视化分析中可能存在不可靠性，且相关文献多样且广泛，新手难以入门。", "method": "基于先前文献分类，设计指南帮助用户评估DR专业知识并选择适合的论文。", "result": "通过三位DR和数据可视化专家的访谈研究验证了指南的重要性、全面性和实用性。", "conclusion": "该指南为新手提供了可靠的起点，有助于提升DR在可视化分析中的应用能力。"}}
{"id": "2506.15106", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15106", "abs": "https://arxiv.org/abs/2506.15106", "authors": ["Ziqin Chen", "Yongqiang Wang"], "title": "Local Differential Privacy for Distributed Stochastic Aggregative Optimization with Guaranteed Optimality", "comment": "21 pages, 6 figures", "summary": "Distributed aggregative optimization underpins many cooperative optimization and multi-agent control systems, where each agent's objective function depends both on its local optimization variable and an aggregate of all agents' optimization variables. Existing distributed aggregative optimization approaches typically require access to accurate gradients of the objective functions, which, however, are often hard to obtain in real-world applications. For example, in machine learning, gradients are commonly contaminated by two main sources of noise: the randomness inherent in sampled data, and the additional variability introduced by mini-batch computations. In addition to the issue of relying on accurate gradients, existing distributed aggregative optimization approaches require agents to share explicit information, which could breach the privacy of participating agents. We propose an algorithm that can solve both problems with existing distributed aggregative optimization approaches: not only can the proposed algorithm guarantee mean-square convergence to an exact optimal solution when the gradients are subject to noise, it also simultaneously ensures rigorous differential privacy, with the cumulative privacy budget guaranteed to be finite even when the number of iterations tends to infinity. To the best of our knowledge, this is the first algorithm able to guarantee both accurate convergence and rigorous differential privacy in distributed aggregative optimization. Besides characterizing the convergence rates under nonconvex/convex/strongly convex conditions, we also rigorously quantify the cost of differential privacy in terms of convergence rates. Experimental results on personalized machine learning using benchmark datasets confirm the efficacy of the proposed algorithm.", "AI": {"tldr": "该论文提出了一种分布式聚合优化算法，解决了现有方法依赖准确梯度和隐私泄露的问题，同时保证在梯度噪声下的精确收敛和严格的差分隐私。", "motivation": "现有分布式聚合优化方法依赖准确梯度且可能泄露隐私，而实际应用中梯度常受噪声污染。", "method": "提出一种新算法，支持梯度噪声下的精确收敛，并确保严格的差分隐私，隐私预算有限。", "result": "算法在非凸/凸/强凸条件下均收敛，实验验证了其在个性化机器学习中的有效性。", "conclusion": "该算法首次同时实现精确收敛和差分隐私，为分布式聚合优化提供了新解决方案。"}}
{"id": "2506.14975", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14975", "abs": "https://arxiv.org/abs/2506.14975", "authors": ["Jeffrey Mao", "Raghuram Cauligi Srinivas", "Steven Nogar", "Giuseppe Loianno"], "title": "Time-Optimized Safe Navigation in Unstructured Environments through Learning Based Depth Completion", "comment": null, "summary": "Quadrotors hold significant promise for several applications such as agriculture, search and rescue, and infrastructure inspection. Achieving autonomous operation requires systems to navigate safely through complex and unfamiliar environments. This level of autonomy is particularly challenging due to the complexity of such environments and the need for real-time decision making especially for platforms constrained by size, weight, and power (SWaP), which limits flight time and precludes the use of bulky sensors like Light Detection and Ranging (LiDAR) for mapping. Furthermore, computing globally optimal, collision-free paths and translating them into time-optimized, safe trajectories in real time adds significant computational complexity. To address these challenges, we present a fully onboard, real-time navigation system that relies solely on lightweight onboard sensors. Our system constructs a dense 3D map of the environment using a novel visual depth estimation approach that fuses stereo and monocular learning-based depth, yielding longer-range, denser, and less noisy depth maps than conventional stereo methods. Building on this map, we introduce a novel planning and trajectory generation framework capable of rapidly computing time-optimal global trajectories. As the map is incrementally updated with new depth information, our system continuously refines the trajectory to maintain safety and optimality. Both our planner and trajectory generator outperforms state-of-the-art methods in terms of computational efficiency and guarantee obstacle-free trajectories. We validate our system through robust autonomous flight experiments in diverse indoor and outdoor environments, demonstrating its effectiveness for safe navigation in previously unknown settings.", "AI": {"tldr": "提出了一种基于轻量级传感器的四旋翼无人机实时导航系统，通过融合立体和单目深度估计构建密集3D地图，并实现快速全局轨迹规划。", "motivation": "解决四旋翼无人机在复杂未知环境中实时自主导航的挑战，尤其是在尺寸、重量和功耗受限的情况下。", "method": "结合立体和单目学习深度估计构建密集3D地图，开发快速全局轨迹规划框架，实时更新轨迹以保证安全性和最优性。", "result": "系统在计算效率和避障能力上优于现有方法，并通过室内外实验验证了其有效性。", "conclusion": "该系统为轻量级无人机在未知环境中的安全导航提供了高效解决方案。"}}
{"id": "2506.14825", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14825", "abs": "https://arxiv.org/abs/2506.14825", "authors": ["Ke Song", "Yunhe Wu", "Chunchit Siu", "Huiyuan Xiong"], "title": "GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction", "comment": null, "summary": "Addressing the task of 3D semantic occupancy prediction for autonomous driving, we tackle two key issues in existing 3D Gaussian Splating (3DGS) methods: (1) unified feature aggregation neglecting semantic correlations among similar categories and across regions, and (2) boundary ambiguities caused by the lack of geometric constraints in MLP iterative optimization. We propose the GraphGSOcc model, a novel framework that combines semantic and geometric graph Transformer for 3D Gaussian Splating-based Occupancy Prediction. We propose the Dual Gaussians Graph Attenntion, which dynamically constructs dual graph structures: a geometric graph adaptively calculating KNN search radii based on Gaussian poses, enabling large-scale Gaussians to aggregate features from broader neighborhoods while compact Gaussians focus on local geometric consistency; a semantic graph retaining top-M highly correlated nodes via cosine similarity to explicitly encode semantic relationships within and across instances. Coupled with the Multi-scale Graph Attention framework, fine-grained attention at lower layers optimizes boundary details, while coarse-grained attention at higher layers models object-level topology. Experiments on the SurroundOcc dataset achieve an mIoU of 24.10%, reducing GPU memory to 6.1 GB, demonstrating a 1.97% mIoU improvement and 13.7% memory reduction compared to GaussianWorld", "AI": {"tldr": "GraphGSOcc模型通过结合语义和几何图Transformer，解决了3D高斯溅射方法中的特征聚合和边界模糊问题，提升了3D语义占用预测的性能。", "motivation": "现有3D高斯溅射方法存在特征聚合忽略语义相关性和边界模糊的问题，需改进以提升自动驾驶中的3D语义占用预测。", "method": "提出GraphGSOcc模型，采用双高斯图注意力机制动态构建几何图和语义图，结合多尺度图注意力框架优化边界细节和对象级拓扑。", "result": "在SurroundOcc数据集上达到24.10%的mIoU，GPU内存降至6.1 GB，性能提升1.97%，内存减少13.7%。", "conclusion": "GraphGSOcc通过语义和几何图Transformer有效提升了3D语义占用预测的精度和效率。"}}
{"id": "2506.14784", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2506.14784", "abs": "https://arxiv.org/abs/2506.14784", "authors": ["Emre Yilmaz", "Philipp Bekemeyer"], "title": "Predicting Onflow Parameters Using Transfer Learning for Domain and Task Adaptation", "comment": null, "summary": "Determining onflow parameters is crucial from the perspectives of wind tunnel testing and regular flight and wind turbine operations. These parameters have traditionally been predicted via direct measurements which might lead to challenges in case of sensor faults. Alternatively, a data-driven prediction model based on surface pressure data can be used to determine these parameters. It is essential that such predictors achieve close to real-time learning as dictated by practical applications such as monitoring wind tunnel operations or learning the variations in aerodynamic performance of aerospace and wind energy systems. To overcome the challenges caused by changes in the data distribution as well as in adapting to a new prediction task, we propose a transfer learning methodology to predict the onflow parameters, specifically angle of attack and onflow speed. It requires first training a convolutional neural network (ConvNet) model offline for the core prediction task, then freezing the weights of this model except the selected layers preceding the output node, and finally executing transfer learning by retraining these layers. A demonstration of this approach is provided using steady CFD analysis data for an airfoil for i) domain adaptation where transfer learning is performed with data from a target domain having different data distribution than the source domain and ii) task adaptation where the prediction task is changed. Further exploration on the influence of noisy data, performance on an extended domain, and trade studies varying sampling sizes and architectures are provided. Results successfully demonstrate the potential of the approach for adaptation to changing data distribution, domain extension, and task update while the application for noisy data is concluded to be not as effective.", "AI": {"tldr": "论文提出了一种基于迁移学习的方法，通过卷积神经网络（ConvNet）预测流动参数（如攻角和流速），解决了传感器故障和数据分布变化的问题。", "motivation": "传统直接测量方法在传感器故障时存在挑战，且数据分布变化会影响预测准确性，因此需要一种实时学习的数据驱动模型。", "method": "采用迁移学习方法：先离线训练ConvNet模型，冻结部分层权重，再针对新任务或数据分布进行微调。", "result": "方法在数据分布变化、领域扩展和任务更新方面表现良好，但对噪声数据的适应性较差。", "conclusion": "该方法在适应数据分布变化和任务更新方面具有潜力，但需进一步优化以应对噪声数据。"}}
{"id": "2506.15530", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15530", "abs": "https://arxiv.org/abs/2506.15530", "authors": ["Teysir Baoueb", "Xiaoyu Bie", "Xi Wang", "Gaël Richard"], "title": "Diff-TONE: Timestep Optimization for iNstrument Editing in Text-to-Music Diffusion Models", "comment": null, "summary": "Breakthroughs in text-to-music generation models are transforming the creative landscape, equipping musicians with innovative tools for composition and experimentation like never before. However, controlling the generation process to achieve a specific desired outcome remains a significant challenge. Even a minor change in the text prompt, combined with the same random seed, can drastically alter the generated piece. In this paper, we explore the application of existing text-to-music diffusion models for instrument editing. Specifically, for an existing audio track, we aim to leverage a pretrained text-to-music diffusion model to edit the instrument while preserving the underlying content. Based on the insight that the model first focuses on the overall structure or content of the audio, then adds instrument information, and finally refines the quality, we show that selecting a well-chosen intermediate timestep, identified through an instrument classifier, yields a balance between preserving the original piece's content and achieving the desired timbre. Our method does not require additional training of the text-to-music diffusion model, nor does it compromise the generation process's speed.", "AI": {"tldr": "本文探讨了如何利用现有的文本到音乐扩散模型进行乐器编辑，通过选择合适的时间步长，在保留原始音频内容的同时实现乐器音色的调整。", "motivation": "尽管文本到音乐生成模型为音乐创作提供了创新工具，但如何精确控制生成过程以实现特定效果仍是一个挑战。", "method": "利用预训练的文本到音乐扩散模型，通过乐器分类器选择中间时间步长，在不影响生成速度的情况下实现乐器编辑。", "result": "该方法在保留原始音频内容的同时，成功实现了乐器音色的调整，且无需额外训练模型。", "conclusion": "通过选择合适的时间步长，可以高效地利用现有模型进行乐器编辑，为音乐创作提供了新的可能性。"}}
{"id": "2506.14829", "categories": ["cs.HC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14829", "abs": "https://arxiv.org/abs/2506.14829", "authors": ["Aditya Majumdar", "Wenbo Zhang", "Kashvi Prawal", "Amulya Yadav"], "title": "The Hardness of Achieving Impact in AI for Social Impact Research: A Ground-Level View of Challenges & Opportunities", "comment": null, "summary": "In an attempt to tackle the UN SDGs, AI for Social Impact (AI4SI) projects focus on harnessing AI to address societal issues in areas such as healthcare, social justice, etc. Unfortunately, despite growing interest in AI4SI, achieving tangible, on-the-ground impact remains a significant challenge. For example, identifying and engaging motivated collaborators who are willing to co-design and deploy AI based solutions in real-world settings is often difficult. Even when such partnerships are established, many AI4SI projects \"fail\" to progress beyond the proof-of-concept stage, and hence, are unable to transition to at-scale production-level solutions. Furthermore, the unique challenges faced by AI4SI researchers are not always fully recognized within the broader AI community, where such work is sometimes viewed as primarily applied and not aligning with the traditional criteria for novelty emphasized in core AI venues. This paper attempts to shine a light on the diverse challenges faced in AI4SI research by diagnosing a multitude of factors that prevent AI4SI partnerships from achieving real-world impact on the ground. Drawing on semi-structured interviews with six leading AI4SI researchers - complemented by the authors' own lived experiences in conducting AI4SI research - this paper attempts to understand the day-to-day difficulties faced in developing and deploying socially impactful AI solutions. Through thematic analysis, we identify structural and organizational, communication, collaboration, and operational challenges as key barriers to deployment. While there are no easy fixes, we synthesize best practices and actionable strategies drawn from these interviews and our own work in this space. In doing so, we hope this paper serves as a practical reference guide for AI4SI researchers and partner organizations seeking to engage more effectively in socially impactful AI collaborations.", "AI": {"tldr": "本文探讨了AI4SI（AI for Social Impact）项目在实现实际社会影响时面临的挑战，包括合作困难、项目难以规模化以及学术认可度不足等问题，并提出了改进策略。", "motivation": "AI4SI项目旨在利用AI解决社会问题，但实际落地效果不佳，本文试图揭示阻碍其成功的因素。", "method": "通过半结构化访谈和作者亲身经历，分析AI4SI研究中的日常困难，并进行主题分析。", "result": "识别出结构性与组织性、沟通、协作和操作层面的挑战，并总结了最佳实践与策略。", "conclusion": "本文为AI4SI研究者和合作伙伴提供了实用指南，以促进更有效的社会影响合作。"}}
{"id": "2506.15124", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15124", "abs": "https://arxiv.org/abs/2506.15124", "authors": ["Zhongyuan Kong", "Lei Li", "Erwin Ang Tien Yew", "Zirui Chen", "Wenbo Li", "Shiwu Zhang", "Jian Yang", "Shuaishuai Sun"], "title": "A Force Feedback Exoskeleton for Teleoperation Using Magnetorheological Clutches", "comment": null, "summary": "This paper proposes an upper-limb exoskeleton teleoperation system based on magnetorheological (MR) clutches, aiming to improve operational accuracy and enhance the immersive experience during lunar sampling tasks. Conventional exoskeleton teleoperation systems commonly employ active force feedback solutions, such as servo motors, which typically suffer from high system complexity and increased energy consumption. Furthermore, force feedback devices utilizing motors and gear reducers generally compromise backdrivability and pose safety risks to operators due to active force output. To address these limitations, we propose a semi-active force feedback strategy based on MR clutches. Dynamic magnetic field control enables precise adjustment of joint stiffness and damping, thereby providing smooth and high-resolution force feedback. The designed MR clutch exhibits outstanding performance across key metrics, achieving a torque-to-mass ratio (TMR) of 93.6 Nm/kg, a torque-to-volume ratio (TVR) of 4.05 x 10^5 Nm/m^3, and a torque-to-power ratio (TPR) of 4.15 Nm/W. Notably, the TMR represents an improvement of approximately 246% over a representative design in prior work. Experimental results validate the system's capability to deliver high-fidelity force feedback. Overall, the proposed system presents a promising solution for deep-space teleoperation with strong potential for real-world deployment in future missions.", "AI": {"tldr": "提出了一种基于磁流变离合器的上肢外骨骼遥操作系统，旨在提高月球采样任务的精度和沉浸感。", "motivation": "传统主动力反馈系统（如伺服电机）复杂且耗能，且可能因主动力输出而降低可逆性和安全性。", "method": "采用基于磁流变离合器的半主动力反馈策略，通过动态磁场控制精确调节关节刚度和阻尼。", "result": "设计的磁流变离合器性能优异，扭矩质量比（TMR）达93.6 Nm/kg，实验验证了系统的高保真力反馈能力。", "conclusion": "该系统为深空遥操作提供了有前景的解决方案，具备实际任务部署潜力。"}}
{"id": "2506.15009", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15009", "abs": "https://arxiv.org/abs/2506.15009", "authors": ["Jinjie Li", "Jiaxuan Li", "Kotaro Kaneko", "Liming Shu", "Moju Zhao"], "title": "Six-DoF Hand-Based Teleoperation for Omnidirectional Aerial Robots", "comment": "7 pages, 9 figures. This work has been accepted to IROS 2025. The video will be released soon", "summary": "Omnidirectional aerial robots offer full 6-DoF independent control over position and orientation, making them popular for aerial manipulation. Although advancements in robotic autonomy, operating by human remains essential in complex aerial environments. Existing teleoperation approaches for multirotors fail to fully leverage the additional DoFs provided by omnidirectional rotation. Additionally, the dexterity of human fingers should be exploited for more engaged interaction. In this work, we propose an aerial teleoperation system that brings the omnidirectionality of human hands into the unbounded aerial workspace. Our system includes two motion-tracking marker sets -- one on the shoulder and one on the hand -- along with a data glove to capture hand gestures. Using these inputs, we design four interaction modes for different tasks, including Spherical Mode and Cartesian Mode for long-range moving as well as Operation Mode and Locking Mode for precise manipulation, where the hand gestures are utilized for seamless mode switching. We evaluate our system on a valve-turning task in real world, demonstrating how each mode contributes to effective aerial manipulation. This interaction framework bridges human dexterity with aerial robotics, paving the way for enhanced teleoperated aerial manipulation in unstructured environments.", "AI": {"tldr": "提出了一种利用人类手部全向性和手势控制的无人机遥操作系统，通过四种交互模式实现高效空中操作。", "motivation": "现有无人机遥操作未能充分利用全向旋转自由度，且未充分发挥人类手指的灵活性。", "method": "系统通过肩部和手部运动追踪标记及数据手套捕捉手势，设计了四种交互模式（球形、笛卡尔、操作和锁定模式）。", "result": "在真实阀门旋转任务中验证了系统的有效性，展示了各模式对空中操作的贡献。", "conclusion": "该交互框架将人类灵活性与空中机器人结合，为复杂环境中的遥操作提供了新思路。"}}
{"id": "2506.14827", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14827", "abs": "https://arxiv.org/abs/2506.14827", "authors": ["Yifeng Gao", "Yifan Ding", "Hongyu Su", "Juncheng Li", "Yunhan Zhao", "Lin Luo", "Zixing Chen", "Li Wang", "Xin Wang", "Yixu Wang", "Xingjun Ma", "Yu-Gang Jiang"], "title": "DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning", "comment": null, "summary": "As AI-generated video becomes increasingly pervasive across media platforms, the ability to reliably distinguish synthetic content from authentic footage has become both urgent and essential. Existing approaches have primarily treated this challenge as a binary classification task, offering limited insight into where or why a model identifies a video as AI-generated. However, the core challenge extends beyond simply detecting subtle artifacts; it requires providing fine-grained, persuasive evidence that can convince auditors and end-users alike. To address this critical gap, we introduce DAVID-X, the first dataset to pair AI-generated videos with detailed defect-level, temporal-spatial annotations and written rationales. Leveraging these rich annotations, we present DAVID-XR1, a video-language model designed to deliver an interpretable chain of visual reasoning-including defect categorization, temporal-spatial localization, and natural language explanations. This approach fundamentally transforms AI-generated video detection from an opaque black-box decision into a transparent and verifiable diagnostic process. We demonstrate that a general-purpose backbone, fine-tuned on our compact dataset and enhanced with chain-of-thought distillation, achieves strong generalization across a variety of generators and generation modes. Our results highlight the promise of explainable detection methods for trustworthy identification of AI-generated video content.", "AI": {"tldr": "论文提出了DAVID-X数据集和DAVID-XR1模型，用于可解释地检测AI生成视频，通过细粒度缺陷标注和自然语言解释提升检测的透明度和可信度。", "motivation": "随着AI生成视频在媒体平台上的普及，可靠区分合成内容与真实内容变得紧迫且必要。现有方法多为二分类任务，缺乏对检测原因的详细解释。", "method": "引入DAVID-X数据集，包含缺陷级时空标注和书面解释；提出DAVID-XR1视频语言模型，提供可解释的视觉推理链（缺陷分类、时空定位和自然语言解释）。", "result": "实验表明，基于通用骨干网络并在紧凑数据集上微调的模型，结合思维链蒸馏，能泛化到多种生成器和生成模式。", "conclusion": "可解释的检测方法为AI生成视频的可信识别提供了新方向。"}}
{"id": "2506.14786", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14786", "abs": "https://arxiv.org/abs/2506.14786", "authors": ["Haobo Li", "Eunseo Jung", "Zixin Chen", "Zhaowei Wang", "Yueya Wang", "Huamin Qu", "Alexis Kai Hon Lau"], "title": "PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series", "comment": null, "summary": "Multimodal time series forecasting is foundational in various fields, such as utilizing satellite imagery and numerical data for predicting typhoons in climate science. However, existing multimodal approaches primarily focus on utilizing text data to help time series forecasting, leaving the visual data in existing time series datasets untouched. Furthermore, it is challenging for models to effectively capture the physical information embedded in visual data, such as satellite imagery's temporal and geospatial context, which extends beyond images themselves. To address this gap, we propose physics-informed positional encoding (PIPE), a lightweight method that embeds physical information into vision language models (VLMs). PIPE introduces two key innovations: (1) a physics-informed positional indexing scheme for mapping physics to positional IDs, and (2) a variant-frequency positional encoding mechanism for encoding frequency information of physical variables and sequential order of tokens within the embedding space. By preserving both the physical information and sequential order information, PIPE significantly improves multimodal alignment and forecasting accuracy. Through the experiments on the most representative and the largest open-sourced satellite image dataset, PIPE achieves state-of-the-art performance in both deep learning forecasting and climate domain methods, demonstrating superiority across benchmarks, including a 12% improvement in typhoon intensity forecasting over prior works. Our code is provided in the supplementary material.", "AI": {"tldr": "论文提出了一种名为PIPE的轻量级方法，通过物理信息位置编码将物理信息嵌入视觉语言模型，显著提升了多模态对齐和预测准确性。", "motivation": "现有方法主要关注文本数据，忽略了视觉数据中的物理信息，如卫星图像的时间和地理空间背景。", "method": "PIPE引入了物理信息位置索引方案和变频率位置编码机制，将物理变量频率信息和序列顺序信息嵌入到模型中。", "result": "在最大开源卫星图像数据集上，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测提升了12%。", "conclusion": "PIPE通过嵌入物理信息，显著提升了多模态时间序列预测的准确性，具有广泛的应用潜力。"}}
{"id": "2506.15548", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2506.15548", "abs": "https://arxiv.org/abs/2506.15548", "authors": ["Junyan Jiang", "Daniel Chin", "Liwei Lin", "Xuanjie Liu", "Gus Xia"], "title": "Versatile Symbolic Music-for-Music Modeling via Function Alignment", "comment": null, "summary": "Many music AI models learn a map between music content and human-defined labels. However, many annotations, such as chords, can be naturally expressed within the music modality itself, e.g., as sequences of symbolic notes. This observation enables both understanding tasks (e.g., chord recognition) and conditional generation tasks (e.g., chord-conditioned melody generation) to be unified under a music-for-music sequence modeling paradigm. In this work, we propose parameter-efficient solutions for a variety of symbolic music-for-music tasks. The high-level idea is that (1) we utilize a pretrained Language Model (LM) for both the reference and the target sequence and (2) we link these two LMs via a lightweight adapter. Experiments show that our method achieves superior performance among different tasks such as chord recognition, melody generation, and drum track generation. All demos, code and model weights are publicly available.", "AI": {"tldr": "论文提出了一种参数高效的方法，将音乐内容与人类定义的标签映射任务统一为音乐序列建模范式，利用预训练语言模型和轻量级适配器实现多任务性能提升。", "motivation": "许多音乐AI模型依赖于人工标注的标签，但这些标注（如和弦）可以通过音乐本身表达，因此希望统一理解和生成任务。", "method": "使用预训练语言模型处理参考和目标序列，并通过轻量级适配器连接两者。", "result": "实验表明，该方法在和弦识别、旋律生成和鼓轨生成等任务中表现优异。", "conclusion": "该方法为音乐序列建模提供了一种高效且通用的解决方案，代码和模型已公开。"}}
{"id": "2506.14948", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14948", "abs": "https://arxiv.org/abs/2506.14948", "authors": ["Mohna Chakraborty", "Lu Wang", "David Jurgens"], "title": "Structured Moral Reasoning in Language Models: A Value-Grounded Evaluation Framework", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in domains requiring moral understanding, yet their reasoning often remains shallow, and misaligned with human reasoning. Unlike humans, whose moral reasoning integrates contextual trade-offs, value systems, and ethical theories, LLMs often rely on surface patterns, leading to biased decisions in morally and ethically complex scenarios. To address this gap, we present a value-grounded framework for evaluating and distilling structured moral reasoning in LLMs. We benchmark 12 open-source models across four moral datasets using a taxonomy of prompts grounded in value systems, ethical theories, and cognitive reasoning strategies. Our evaluation is guided by four questions: (1) Does reasoning improve LLM decision-making over direct prompting? (2) Which types of value/ethical frameworks most effectively guide LLM reasoning? (3) Which cognitive reasoning strategies lead to better moral performance? (4) Can small-sized LLMs acquire moral competence through distillation? We find that prompting with explicit moral structure consistently improves accuracy and coherence, with first-principles reasoning and Schwartz's + care-ethics scaffolds yielding the strongest gains. Furthermore, our supervised distillation approach transfers moral competence from large to small models without additional inference cost. Together, our results offer a scalable path toward interpretable and value-grounded models.", "AI": {"tldr": "论文提出了一种基于价值的框架，用于评估和提炼大型语言模型（LLMs）中的结构化道德推理，解决了LLMs在道德理解上的浅层和偏差问题。", "motivation": "LLMs在需要道德理解的领域中应用广泛，但其推理常与人类道德推理不一致，导致复杂场景中的偏差决策。", "method": "通过基于价值系统、伦理理论和认知推理策略的提示分类法，对12个开源模型在四个道德数据集上进行基准测试。", "result": "明确的道德结构提示能显著提高准确性和一致性，其中基于第一原则推理和Schwartz+关怀伦理的框架效果最佳。小型LLMs通过蒸馏方法也能获得道德能力。", "conclusion": "研究为构建可解释且基于价值的模型提供了可扩展的路径。"}}
{"id": "2506.15191", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15191", "abs": "https://arxiv.org/abs/2506.15191", "authors": ["Yanhong Luo", "Wenchao Meng", "Xi Zhu", "Andreas Elombo", "Hu Rong", "Bing Xie", "Tianwen Zhang"], "title": "Islanding Strategy for Smart Grids Oriented to Resilience Enhancement and Its Power Supply Range Optimization", "comment": null, "summary": "With the increasing prevalence of distributed generators, islanded operation based on distributed generation is considered a vital means to enhance the reliability and resilience of smart grids. This paper investigates the main factors in islanding partition of smart grids and establishes a mathematical model for islanding division. A method to determine the maximum power supply range of distributed energy resources (DERs) based on the reachability matrix and power circle algorithm is proposed to improve computational efficiency. A dynamic programming method based on breadth-first search (BFS) is used to solve the islanding partition scheme, and a region correction method is applied to modify the maximum power supply area by considering controllable loads and prioritizing critical load restoration, thereby enhancing system resilience. Finally, simulation results verify the effectiveness of the proposed algorithm in improving smart grid resilience.", "AI": {"tldr": "论文研究了智能电网孤岛划分的关键因素，提出了一种基于可达性矩阵和功率圆算法的高效计算方法，并通过动态规划和区域修正提升系统韧性。", "motivation": "随着分布式发电的普及，孤岛运行成为提升智能电网可靠性和韧性的重要手段。", "method": "提出基于可达性矩阵和功率圆算法的DER最大供电范围确定方法，采用BFS动态规划求解孤岛划分方案，并通过区域修正优化供电范围。", "result": "仿真验证了算法在提升智能电网韧性方面的有效性。", "conclusion": "该方法能高效提升智能电网在孤岛运行时的可靠性和韧性。"}}
{"id": "2506.15012", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15012", "abs": "https://arxiv.org/abs/2506.15012", "authors": ["Alexandra Forsey-Smerek", "Julie Shah", "Andreea Bobu"], "title": "Context Matters: Learning Generalizable Rewards via Calibrated Features", "comment": "30 pages, 21 figures", "summary": "A key challenge in reward learning from human input is that desired agent behavior often changes based on context. Traditional methods typically treat each new context as a separate task with its own reward function. For example, if a previously ignored stove becomes too hot to be around, the robot must learn a new reward from scratch, even though the underlying preference for prioritizing safety over efficiency remains unchanged. We observe that context influences not the underlying preference itself, but rather the $\\textit{saliency}$--or importance--of reward features. For instance, stove heat affects the importance of the robot's proximity, yet the human's safety preference stays the same. Existing multi-task and meta IRL methods learn context-dependent representations $\\textit{implicitly}$--without distinguishing between preferences and feature importance--resulting in substantial data requirements. Instead, we propose $\\textit{explicitly}$ modeling context-invariant preferences separately from context-dependent feature saliency, creating modular reward representations that adapt to new contexts. To achieve this, we introduce $\\textit{calibrated features}$--representations that capture contextual effects on feature saliency--and present specialized paired comparison queries that isolate saliency from preference for efficient learning. Experiments with simulated users show our method significantly improves sample efficiency, requiring 10x fewer preference queries than baselines to achieve equivalent reward accuracy, with up to 15% better performance in low-data regimes (5-10 queries). An in-person user study (N=12) demonstrates that participants can effectively teach their unique personal contextual preferences using our method, enabling more adaptable and personalized reward learning.", "AI": {"tldr": "论文提出了一种显式建模上下文不变偏好和上下文相关特征显著性的方法，以提高奖励学习的样本效率。", "motivation": "传统方法将每个新上下文视为独立任务，导致数据需求大。作者观察到上下文影响的是特征显著性而非偏好本身，因此提出显式分离建模。", "method": "引入校准特征表示上下文对特征显著性的影响，并提出专用配对比较查询以高效学习。", "result": "实验显示方法显著提高样本效率，比基线少用10倍查询，低数据下性能提升15%。用户研究验证了方法的有效性。", "conclusion": "显式分离偏好和特征显著性的方法能更高效地适应新上下文，实现个性化奖励学习。"}}
{"id": "2506.14831", "categories": ["cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14831", "abs": "https://arxiv.org/abs/2506.14831", "authors": ["Céline Finet", "Stephane Da Silva Martins", "Jean-Bernard Hayet", "Ioannis Karamouzas", "Javad Amirian", "Sylvie Le Hégarat-Mascle", "Julien Pettré", "Emanuel Aldea"], "title": "Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review", "comment": "30 pages", "summary": "With the emergence of powerful data-driven methods in human trajectory prediction (HTP), gaining a finer understanding of multi-agent interactions lies within hand's reach, with important implications in areas such as autonomous navigation and crowd modeling. This survey reviews some of the most recent advancements in deep learning-based multi-agent trajectory prediction, focusing on studies published between 2020 and 2024. We categorize the existing methods based on their architectural design, their input representations, and their overall prediction strategies, placing a particular emphasis on models evaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges and future research directions in the field of multi-agent HTP.", "AI": {"tldr": "本文综述了2020至2024年间基于深度学习的多智能体轨迹预测的最新进展，重点分析了ETH/UCY基准测试中的模型，并探讨了该领域的关键挑战与未来方向。", "motivation": "随着数据驱动方法在人类轨迹预测中的广泛应用，深入理解多智能体交互对自主导航和人群建模等领域具有重要意义。", "method": "对现有方法按架构设计、输入表示和预测策略进行分类，特别关注ETH/UCY基准测试中的模型。", "result": "总结了多智能体轨迹预测的最新进展，并提出了该领域的关键挑战。", "conclusion": "强调了多智能体轨迹预测领域的未来研究方向。"}}
{"id": "2506.14787", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14787", "abs": "https://arxiv.org/abs/2506.14787", "authors": ["Funing Li", "Yuan Tian", "Ruben Noortwyck", "Jifeng Zhou", "Liming Kuang", "Robert Schulz"], "title": "Topology-Aware and Highly Generalizable Deep Reinforcement Learning for Efficient Retrieval in Multi-Deep Storage Systems", "comment": null, "summary": "In modern industrial and logistics environments, the rapid expansion of fast delivery services has heightened the demand for storage systems that combine high efficiency with increased density. Multi-deep autonomous vehicle storage and retrieval systems (AVS/RS) present a viable solution for achieving greater storage density. However, these systems encounter significant challenges during retrieval operations due to lane blockages. A conventional approach to mitigate this issue involves storing items with homogeneous characteristics in a single lane, but this strategy restricts the flexibility and adaptability of multi-deep storage systems.\n  In this study, we propose a deep reinforcement learning-based framework to address the retrieval problem in multi-deep storage systems with heterogeneous item configurations. Each item is associated with a specific due date, and the objective is to minimize total tardiness. To effectively capture the system's topology, we introduce a graph-based state representation that integrates both item attributes and the local topological structure of the multi-deep warehouse. To process this representation, we design a novel neural network architecture that combines a Graph Neural Network (GNN) with a Transformer model. The GNN encodes topological and item-specific information into embeddings for all directly accessible items, while the Transformer maps these embeddings into global priority assignments. The Transformer's strong generalization capability further allows our approach to be applied to storage systems with diverse layouts. Extensive numerical experiments, including comparisons with heuristic methods, demonstrate the superiority of the proposed neural network architecture and the effectiveness of the trained agent in optimizing retrieval tardiness.", "AI": {"tldr": "提出了一种基于深度强化学习的框架，用于解决多深度存储系统中异构物品配置的检索问题，通过图神经网络和Transformer模型优化检索延迟。", "motivation": "现代工业和物流环境中，快速交付服务的需求增长对高效且高密度的存储系统提出了更高要求，但多深度存储系统在检索时面临车道阻塞的挑战。", "method": "采用图神经网络（GNN）编码物品属性和拓扑结构，结合Transformer模型生成全局优先级分配，以最小化总延迟为目标。", "result": "实验表明，所提出的神经网络架构优于启发式方法，能有效优化检索延迟。", "conclusion": "该框架在多深度存储系统中表现出优越性和适应性，适用于不同布局的存储系统。"}}
{"id": "2506.15614", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2506.15614", "abs": "https://arxiv.org/abs/2506.15614", "authors": ["Kentaro Seki", "Shinnosuke Takamichi", "Takaaki Saeki", "Hiroshi Saruwatari"], "title": "TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data", "comment": null, "summary": "This paper presents TTSOps, a fully automated closed-loop framework for constructing multi-speaker text-to-speech (TTS) systems from noisy, uncurated web-scale speech data, often referred to as ``dark data,'' such as online videos. Conventional TTS training pipelines require well-curated corpora with high acoustic quality and accurate text-speech alignment, which severely limits scalability, speaker diversity, and real-world applicability. While recent studies have proposed acoustic-quality-based data selection techniques, they often overlook two critical aspects: (1) the inherent robustness of modern TTS models to noise, and (2) the potential contribution of perceptually low-quality yet informative samples. To address these issues, TTSOps introduces a data-centric training pipeline that integrates three core components: (1) automated data collection from dark data sources, (2) utterance-level dynamic selection of data cleansing methods based on training data quality, and (3) evaluation-in-the-loop data selection using automatically predicted mean opinion scores (MOS) to estimate each utterance's impact on model performance. Furthermore, TTSOps jointly optimizes the corpus and the TTS model in a closed-loop framework by dynamically adapting both data selection and data cleansing processes to the characteristics of the target TTS model. Extensive experiments on Japanese YouTube data demonstrate that TTSOps outperforms conventional acoustic-quality-based baselines in both the naturalness and speaker diversity of synthesized speech.", "AI": {"tldr": "TTSOps是一个自动化闭环框架，用于从嘈杂的网络语音数据中构建多说话人TTS系统，通过动态数据选择和清洗提升模型性能。", "motivation": "传统TTS训练依赖高质量数据，限制了可扩展性和说话人多样性。TTSOps利用现代TTS模型的噪声鲁棒性，探索低质量但信息丰富的样本。", "method": "框架包含自动化数据收集、动态数据清洗方法选择、基于预测MOS的评估闭环数据选择，并联合优化语料库和TTS模型。", "result": "在日语YouTube数据上的实验表明，TTSOps在合成语音的自然度和说话人多样性上优于传统方法。", "conclusion": "TTSOps通过数据驱动和闭环优化，显著提升了TTS系统的性能和实用性。"}}
{"id": "2506.15008", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15008", "abs": "https://arxiv.org/abs/2506.15008", "authors": ["Richa Gupta", "Alexander Htet Kyaw"], "title": "Insights Informed Generative AI for Design: Incorporating Real-world Data for Text-to-Image Output", "comment": "15 Pages, 6 figures, CAAD Futures 2025", "summary": "Generative AI, specifically text-to-image models, have revolutionized interior architectural design by enabling the rapid translation of conceptual ideas into visual representations from simple text prompts. While generative AI can produce visually appealing images they often lack actionable data for designers In this work, we propose a novel pipeline that integrates DALL-E 3 with a materials dataset to enrich AI-generated designs with sustainability metrics and material usage insights. After the model generates an interior design image, a post-processing module identifies the top ten materials present and pairs them with carbon dioxide equivalent (CO2e) values from a general materials dictionary. This approach allows designers to immediately evaluate environmental impacts and refine prompts accordingly. We evaluate the system through three user tests: (1) no mention of sustainability to the user prior to the prompting process with generative AI, (2) sustainability goals communicated to the user before prompting, and (3) sustainability goals communicated along with quantitative CO2e data included in the generative AI outputs. Our qualitative and quantitative analyses reveal that the introduction of sustainability metrics in the third test leads to more informed design decisions, however, it can also trigger decision fatigue and lower overall satisfaction. Nevertheless, the majority of participants reported incorporating sustainability principles into their workflows in the third test, underscoring the potential of integrated metrics to guide more ecologically responsible practices. Our findings showcase the importance of balancing design freedom with practical constraints, offering a clear path toward holistic, data-driven solutions in AI-assisted architectural design.", "AI": {"tldr": "提出了一种结合DALL-E 3和材料数据集的新方法，为AI生成的设计提供可持续性指标和材料数据，帮助设计师评估环境影响。", "motivation": "生成式AI在室内设计中缺乏可操作的数据，尤其是可持续性指标，限制了其实际应用。", "method": "通过后处理模块识别AI生成设计中的材料，并匹配CO2e值，结合用户测试评估效果。", "result": "引入可持续性指标后，设计决策更明智，但也可能引发决策疲劳。多数用户在工作流程中纳入了可持续性原则。", "conclusion": "平衡设计自由与实用约束是关键，为AI辅助建筑设计提供了数据驱动的解决方案。"}}
{"id": "2506.15192", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15192", "abs": "https://arxiv.org/abs/2506.15192", "authors": ["E. D. Gomez Anccas", "C. A. Hans", "D. Schulz"], "title": "Microgrid Operation Control with Adaptable Droop Gains", "comment": null, "summary": "Modern low-carbon power systems come with many challenges, such as increased inverter penetration and increased uncertainty from renewable sources and loads. In this context, the microgrid concept is a promising approach, which is based on a segmentation of the grid into independent smaller cells that can run either in grid-connected or standalone mode.In microgrids, droop control is widely used for primary control. It enables proportional power sharing, depending on the droop gains. Operation control schemes considering droop control often assume fixed droop gains. However, using adaptive droop gains for grid-forming units allow to shape power sharing in presence of fluctuations, enhancing flexibility while maintaining a safe microgrid operation, particularly under uncertainty. This work introduces a bilinear formulation for microgrid operation control that finds optimal power setpoints and droop gains on a timescale of minutes by solving a finite horizon optimization problem. In detail, a robust minmax model predictive control scheme is designed for a standalone microgrid, comprising a fuel cell, a photovoltaic system and an energy storage. Closed-loop simulations are performed with and without variable droop gains. The results show an increase in renewable utilization of up to 7.5 % while reducing the power output of the fuel cell by 6 %, when allowing variable droop gains.", "AI": {"tldr": "论文提出了一种基于双线性公式的微电网运行控制方法，通过优化功率设定点和下垂增益，提高了可再生能源利用率并减少了燃料电池输出。", "motivation": "现代低碳电力系统面临逆变器渗透率增加及可再生能源和负载不确定性增加的挑战，微电网的分段独立运行成为一种有前景的解决方案。", "method": "采用鲁棒极小极大模型预测控制方案，设计了一种双线性公式，优化功率设定点和下垂增益，并通过闭环仿真验证。", "result": "仿真结果显示，使用可变下垂增益可使可再生能源利用率提高7.5%，同时减少燃料电池输出6%。", "conclusion": "自适应下垂增益在微电网运行中具有显著优势，能够提升灵活性和安全性。"}}
{"id": "2506.15032", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15032", "abs": "https://arxiv.org/abs/2506.15032", "authors": ["Winston Smith", "Andrew Boateng", "Taha Shaheen", "Yu Zhang"], "title": "Assigning Multi-Robot Tasks to Multitasking Robots", "comment": null, "summary": "One simplifying assumption in existing and well-performing task allocation methods is that the robots are single-tasking: each robot operates on a single task at any given time. While this assumption is harmless to make in some situations, it can be inefficient or even infeasible in others. In this paper, we consider assigning multi-robot tasks to multitasking robots. The key contribution is a novel task allocation framework that incorporates the consideration of physical constraints introduced by multitasking. This is in contrast to the existing work where such constraints are largely ignored. After formulating the problem, we propose a compilation to weighted MAX-SAT, which allows us to leverage existing solvers for a solution. A more efficient greedy heuristic is then introduced. For evaluation, we first compare our methods with a modern baseline that is efficient for single-tasking robots to validate the benefits of multitasking in synthetic domains. Then, using a site-clearing scenario in simulation, we further illustrate the complex task interaction considered by the multitasking robots in our approach to demonstrate its performance. Finally, we demonstrate a physical experiment to show how multitasking enabled by our approach can benefit task efficiency in a realistic setting.", "AI": {"tldr": "本文提出了一种新的多任务机器人任务分配框架，考虑了多任务引入的物理约束，并通过加权MAX-SAT编译和贪心启发式方法实现高效求解。", "motivation": "现有任务分配方法假设机器人是单任务的，这在某些情况下效率低下或不可行，因此需要研究多任务机器人的任务分配问题。", "method": "提出了一种任务分配框架，考虑了多任务的物理约束，并通过加权MAX-SAT编译和贪心启发式方法求解。", "result": "在合成领域和模拟场景中验证了多任务机器人的优势，并通过物理实验展示了任务效率的提升。", "conclusion": "本文框架为多任务机器人任务分配提供了有效解决方案，显著提升了任务效率。"}}
{"id": "2506.14832", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14832", "abs": "https://arxiv.org/abs/2506.14832", "authors": ["Jun Yin", "Jing Zhong", "Pengyu Zeng", "Peilin Li", "Zixuan Dai", "Miao Zhang", "Shuai Lu"], "title": "ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes", "comment": "22 pages, 8 figures", "summary": "In contemporary architectural design, the growing complexity and diversity of design demands have made generative plugin tools essential for quickly producing initial concepts and exploring novel 3D forms. However, objectively analyzing the differences between human-designed and machine-generated 3D forms remains a challenge, limiting our understanding of their respective strengths and hindering the advancement of generative tools.\n  To address this, we built ArchForms-4000, a dataset containing 2,000 architect-designed and 2,000 Evomass-generated 3D forms; Proposed ArchShapeNet, a 3D convolutional neural network tailored for classifying and analyzing architectural forms, incorporating a saliency module to highlight key spatial features aligned with architectural reasoning; And conducted comparative experiments showing our model outperforms human experts in distinguishing form origins, achieving 94.29% accuracy, 96.2% precision, and 98.51% recall.\n  This study not only highlights the distinctive advantages of human-designed forms in spatial organization, proportional harmony, and detail refinement but also provides valuable insights for enhancing generative design tools in the future.", "AI": {"tldr": "论文提出ArchForms-4000数据集和ArchShapeNet模型，用于区分人类设计与机器生成的3D建筑形式，模型性能优于人类专家。", "motivation": "当代建筑设计中，生成工具快速生成概念的需求增加，但缺乏对人类设计与机器生成形式差异的客观分析。", "method": "构建ArchForms-4000数据集，开发ArchShapeNet 3D卷积神经网络，并加入显著模块以突出关键空间特征。", "result": "模型在区分形式来源上表现优异，准确率94.29%，精确率96.2%，召回率98.51%。", "conclusion": "研究揭示了人类设计在空间组织等方面的优势，为未来生成设计工具的改进提供了参考。"}}
{"id": "2506.14789", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2506.14789", "abs": "https://arxiv.org/abs/2506.14789", "authors": ["Saman Khamesian", "Asiful Arefeen", "Bithika M. Thompson", "Maria Adela Grando", "Hassan Ghasemzadeh"], "title": "AZT1D: A Real-World Dataset for Type 1 Diabetes", "comment": "4 pages", "summary": "High quality real world datasets are essential for advancing data driven approaches in type 1 diabetes (T1D) management, including personalized therapy design, digital twin systems, and glucose prediction models. However, progress in this area has been limited by the scarcity of publicly available datasets that offer detailed and comprehensive patient data. To address this gap, we present AZT1D, a dataset containing data collected from 25 individuals with T1D on automated insulin delivery (AID) systems. AZT1D includes continuous glucose monitoring (CGM) data, insulin pump and insulin administration data, carbohydrate intake, and device mode (regular, sleep, and exercise) obtained over 6 to 8 weeks for each patient. Notably, the dataset provides granular details on bolus insulin delivery (i.e., total dose, bolus type, correction specific amounts) features that are rarely found in existing datasets. By offering rich, naturalistic data, AZT1D supports a wide range of artificial intelligence and machine learning applications aimed at improving clinical decision making and individualized care in T1D.", "AI": {"tldr": "AZT1D是一个高质量的真实世界数据集，包含25名使用自动胰岛素输送系统的1型糖尿病患者的详细数据，支持AI和机器学习在糖尿病管理中的应用。", "motivation": "现有公开数据集缺乏详细和全面的1型糖尿病患者数据，限制了数据驱动方法的发展。", "method": "收集了25名患者的连续血糖监测数据、胰岛素泵数据、碳水化合物摄入和设备模式等，持续6至8周。", "result": "AZT1D提供了现有数据集中罕见的详细胰岛素输送数据，支持个性化治疗和临床决策。", "conclusion": "AZT1D填补了数据空白，为1型糖尿病管理的AI和机器学习应用提供了丰富资源。"}}
{"id": "2506.15107", "categories": ["cs.RO", "cs.HC", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15107", "abs": "https://arxiv.org/abs/2506.15107", "authors": ["Paige Tuttösí"], "title": "I Know You're Listening: Adaptive Voice for HRI", "comment": "PhD Thesis Simon Fraser University https://summit.sfu.ca/item/39353 Read the Room: Adapting a Robot's Voice to Ambient and Social Contexts IROS 23 Mmm whatcha say? Uncovering distal and proximal context effects in first and second-language word perception using psychophysical reverse correlation INTERSPEECH 24 Emojivoice: Towards long-term controllable expressivity in robot speech RO-MAN 25", "summary": "While the use of social robots for language teaching has been explored, there remains limited work on a task-specific synthesized voices for language teaching robots. Given that language is a verbal task, this gap may have severe consequences for the effectiveness of robots for language teaching tasks. We address this lack of L2 teaching robot voices through three contributions: 1. We address the need for a lightweight and expressive robot voice. Using a fine-tuned version of Matcha-TTS, we use emoji prompting to create an expressive voice that shows a range of expressivity over time. The voice can run in real time with limited compute resources. Through case studies, we found this voice more expressive, socially appropriate, and suitable for long periods of expressive speech, such as storytelling. 2. We explore how to adapt a robot's voice to physical and social ambient environments to deploy our voices in various locations. We found that increasing pitch and pitch rate in noisy and high-energy environments makes the robot's voice appear more appropriate and makes it seem more aware of its current environment. 3. We create an English TTS system with improved clarity for L2 listeners using known linguistic properties of vowels that are difficult for these listeners. We used a data-driven, perception-based approach to understand how L2 speakers use duration cues to interpret challenging words with minimal tense (long) and lax (short) vowels in English. We found that the duration of vowels strongly influences the perception for L2 listeners and created an \"L2 clarity mode\" for Matcha-TTS that applies a lengthening to tense vowels while leaving lax vowels unchanged. Our clarity mode was found to be more respectful, intelligible, and encouraging than base Matcha-TTS while reducing transcription errors in these challenging tense/lax minimal pairs.", "AI": {"tldr": "论文探讨了为语言教学机器人开发任务特定的合成语音，提出了一种轻量级、表达丰富的语音系统，并研究了环境适应性和针对L2学习者的语音清晰度改进。", "motivation": "现有语言教学机器人缺乏任务特定的合成语音，可能影响教学效果，因此需要开发更有效的语音系统。", "method": "1. 使用微调的Matcha-TTS和表情符号提示创建轻量级、表达丰富的语音；2. 研究机器人语音如何适应物理和社交环境；3. 开发针对L2学习者的英语TTS系统，改进元音清晰度。", "result": "1. 新语音更富表现力且适合长时间使用；2. 环境适应性调整使语音更符合场景；3. L2清晰模式显著提高了语音的可懂度和学习效果。", "conclusion": "通过任务特定的语音设计和优化，可以有效提升语言教学机器人的教学效果和用户体验。"}}
{"id": "2506.15047", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.15047", "abs": "https://arxiv.org/abs/2506.15047", "authors": ["Jiayue Melissa Shi", "Dong Whi Yoo", "Keran Wang", "Violeta J. Rodriguez", "Ravi Karkar", "Koustuv Saha"], "title": "Mapping Caregiver Needs to AI Chatbot Design: Strengths and Gaps in Mental Health Support for Alzheimer's and Dementia Caregivers", "comment": null, "summary": "Family caregivers of individuals with Alzheimer's Disease and Related Dementia (AD/ADRD) face significant emotional and logistical challenges that place them at heightened risk for stress, anxiety, and depression. Although recent advances in generative AI -- particularly large language models (LLMs) -- offer new opportunities to support mental health, little is known about how caregivers perceive and engage with such technologies. To address this gap, we developed Carey, a GPT-4o-based chatbot designed to provide informational and emotional support to AD/ADRD caregivers. Using Carey as a technology probe, we conducted semi-structured interviews with 16 family caregivers following scenario-driven interactions grounded in common caregiving stressors. Through inductive coding and reflexive thematic analysis, we surface a systemic understanding of caregiver needs and expectations across six themes -- on-demand information access, emotional support, safe space for disclosure, crisis management, personalization, and data privacy. For each of these themes, we also identified the nuanced tensions in the caregivers' desires and concerns. We present a mapping of caregiver needs, AI chatbot's strengths, gaps, and design recommendations. Our findings offer theoretical and practical insights to inform the design of proactive, trustworthy, and caregiver-centered AI systems that better support the evolving mental health needs of AD/ADRD caregivers.", "AI": {"tldr": "论文探讨了利用GPT-4o聊天机器人Carey为阿尔茨海默病及相关痴呆症（AD/ADRD）家庭照顾者提供支持的需求与挑战，揭示了六类核心需求及设计建议。", "motivation": "AD/ADRD家庭照顾者面临巨大心理压力，但生成式AI（如LLMs）在此领域的应用研究不足，需探索其支持潜力。", "method": "开发Carey聊天机器人作为技术探针，通过场景驱动的半结构化访谈和主题分析，研究16位照顾者的需求与期望。", "result": "归纳出六类需求（如信息获取、情感支持等）及其矛盾点，并提出AI设计建议。", "conclusion": "研究为设计可信赖、以照顾者为中心的AI系统提供了理论与实践指导。"}}
{"id": "2506.15384", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.15384", "abs": "https://arxiv.org/abs/2506.15384", "authors": ["Cédric Join", "Jakub Orłowski", "Antoine Chaillet", "Madeleine Lowery", "Hugues Mounier", "Michel Fliess"], "title": "Disruption of parkinsonian brain oscillations", "comment": "23rd Internat. Conf. Computational Methods in Systems Biology (CMSB 2025), 10-12 september 2025, Lyon, France", "summary": "Deep brain stimulation (DBS) is an advanced surgical treatment for the symptoms of Parkinson's disease (PD), involving electrical stimulation of neurons within the basal ganglia region of the brain. DBS is traditionally delivered in an open-loop manner using fixed stimulation parameters, which may lead to suboptimal results. In an effort to overcome these limitations, closed loop DBS, using pathological subthalamic beta (13--30 Hz) activity as a feedback signal, offers the potential to adapt DBS automatically in response to changes in patient symptoms and side effects. However, clinically implemented closed-loop techniques have been limited to date to simple control algorithms, due to the inherent uncertainties in the dynamics involved. Model-free control, which has already seen successful applications in the field of bioengineering, offers a way to avoid this limitation and provides an alternative method to apply modern control approach to selective suppression of pathological oscillations.", "AI": {"tldr": "论文探讨了闭环深脑刺激（DBS）在帕金森病治疗中的应用，提出基于模型无关控制的方法以优化传统开环DBS的局限性。", "motivation": "传统开环DBS采用固定刺激参数，可能导致效果不佳。闭环DBS利用病理信号作为反馈，但现有技术因动态不确定性受限。", "method": "采用模型无关控制方法，避免动态不确定性，实现对病理振荡的选择性抑制。", "result": "模型无关控制为闭环DBS提供了一种现代控制方法，有望优化治疗效果。", "conclusion": "模型无关控制是闭环DBS的潜在改进方向，可提升帕金森病治疗的精准性和适应性。"}}
{"id": "2506.15085", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15085", "abs": "https://arxiv.org/abs/2506.15085", "authors": ["Paige Tuttösí", "Shivam Mehta", "Zachary Syvenky", "Bermet Burkanova", "Gustav Eje Henter", "Angelica Lim"], "title": "EmojiVoice: Towards long-term controllable expressivity in robot speech", "comment": "Accepted to RO-MAN 2025, Demo at HRI 2025 : https://dl.acm.org/doi/10.5555/3721488.3721774", "summary": "Humans vary their expressivity when speaking for extended periods to maintain engagement with their listener. Although social robots tend to be deployed with ``expressive'' joyful voices, they lack this long-term variation found in human speech. Foundation model text-to-speech systems are beginning to mimic the expressivity in human speech, but they are difficult to deploy offline on robots. We present EmojiVoice, a free, customizable text-to-speech (TTS) toolkit that allows social roboticists to build temporally variable, expressive speech on social robots. We introduce emoji-prompting to allow fine-grained control of expressivity on a phase level and use the lightweight Matcha-TTS backbone to generate speech in real-time. We explore three case studies: (1) a scripted conversation with a robot assistant, (2) a storytelling robot, and (3) an autonomous speech-to-speech interactive agent. We found that using varied emoji prompting improved the perception and expressivity of speech over a long period in a storytelling task, but expressive voice was not preferred in the assistant use case.", "AI": {"tldr": "EmojiVoice是一个免费的、可定制的文本转语音工具包，旨在为社交机器人提供具有时间变化性的表达性语音。通过表情符号提示和轻量级Matcha-TTS框架，实现了实时语音生成。", "motivation": "社交机器人通常使用单调的‘快乐’语音，缺乏人类语音中的长期变化性，难以维持听众的长期兴趣。", "method": "采用表情符号提示技术，结合Matcha-TTS框架，实现细粒度控制和实时语音生成。通过三个案例研究验证效果。", "result": "在讲故事任务中，多样化的表情符号提示提升了语音的表达性和感知效果，但在助手场景中，表达性语音并未受到偏好。", "conclusion": "EmojiVoice为社交机器人提供了灵活的表达性语音解决方案，但需根据应用场景调整语音表达方式。"}}
{"id": "2506.14833", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14833", "abs": "https://arxiv.org/abs/2506.14833", "authors": ["Poojashree Chandrashekar Pankaj M Sajjanar"], "title": "Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices", "comment": "& pages", "summary": "This paper describes a high-performance, low-latency video surveillance system designed for resource-constrained environments. We have proposed a formal entropy-based adaptive frame buffering algorithm and integrated that with MobileNetV2 to achieve high throughput with low latency. The system is capable of processing live streams of video with sub-50ms end-to-end inference latency on resource-constrained devices (embedding platforms) such as Raspberry Pi, Amazon, and NVIDIA Jetson Nano. Our method maintains over 92% detection accuracy on standard datasets focused on video surveillance and exhibits robustness to varying lighting, backgrounds, and speeds. A number of comparative and ablation experiments validate the effectiveness of our design. Finally, our architecture is scalable, inexpensive, and compliant with stricter data privacy regulations than common surveillance systems, so that the system could coexist in a smart city or embedded security architecture.", "AI": {"tldr": "提出了一种高性能、低延迟的视频监控系统，适用于资源受限环境，结合熵自适应帧缓冲算法与MobileNetV2，在嵌入式设备上实现低延迟高精度。", "motivation": "解决资源受限设备上视频监控系统的高延迟和低效率问题，同时满足数据隐私和智能城市需求。", "method": "提出熵自适应帧缓冲算法，结合MobileNetV2，优化处理流程以实现低延迟和高吞吐。", "result": "在嵌入式设备上实现低于50ms的端到端推理延迟，检测精度超过92%，且对光照、背景和速度变化具有鲁棒性。", "conclusion": "该系统高效、低成本、隐私合规，适用于智能城市和嵌入式安全架构。"}}
{"id": "2506.14790", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14790", "abs": "https://arxiv.org/abs/2506.14790", "authors": ["Tianxiang Zhan", "Ming Jin", "Yuanpeng He", "Yuxuan Liang", "Yong Deng", "Shirui Pan"], "title": "Continuous Evolution Pool: Taming Recurring Concept Drift in Online Time Series Forecasting", "comment": null, "summary": "Recurring concept drift, a type of concept drift in which previously observed data patterns reappear after some time, is one of the most prevalent types of concept drift in time series. As time progresses, concept drift occurs and previously encountered concepts are forgotten, thereby leading to a decline in the accuracy of online predictions. Existing solutions employ parameter updating techniques to delay forgetting; however, this may result in the loss of some previously learned knowledge while neglecting the exploration of knowledge retention mechanisms. To retain all conceptual knowledge and fully utilize it when the concepts recur, we propose the Continuous Evolution Pool (CEP), a pooling mechanism that stores different instances of forecasters for different concepts. Our method first selects the forecaster nearest to the test sample and then learns the features from its neighboring samples - a process we refer to as the retrieval. If there are insufficient neighboring samples, it indicates that a new concept has emerged, and a new model will evolve from the current nearest sample to the pool to store the knowledge of the concept. Simultaneously, the elimination mechanism will enable outdated knowledge to be cleared to ensure the prediction effect of the forecasters. Experiments on different architectural models and eight real datasets demonstrate that CEP effectively retains the knowledge of different concepts. In the scenario of online forecasting with recurring concepts, CEP significantly enhances the prediction results.", "AI": {"tldr": "论文提出了一种名为连续进化池（CEP）的机制，用于处理时间序列中的循环概念漂移问题，通过存储不同概念的预测器实例并动态更新知识，显著提升了预测效果。", "motivation": "循环概念漂移导致已学知识被遗忘，现有方法无法有效保留和利用历史知识，影响预测准确性。", "method": "CEP通过存储不同概念的预测器实例，动态选择最接近测试样本的预测器，并通过检索和进化机制处理新概念和旧知识。", "result": "在不同架构模型和八个真实数据集上的实验表明，CEP能有效保留不同概念的知识，显著提升循环概念场景下的预测效果。", "conclusion": "CEP通过动态知识存储和更新机制，解决了循环概念漂移中的知识遗忘问题，显著提升了在线预测的准确性。"}}
{"id": "2506.15220", "categories": ["cs.CV", "cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2506.15220", "abs": "https://arxiv.org/abs/2506.15220", "authors": ["Changli Tang", "Yixuan Li", "Yudong Yang", "Jimin Zhuang", "Guangzhi Sun", "Wei Li", "Zejun Ma", "Chao Zhang"], "title": "video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models", "comment": null, "summary": "Videos contain a wealth of information, and generating detailed and accurate descriptions in natural language is a key aspect of video understanding. In this paper, we present video-SALMONN 2, an advanced audio-visual large language model (LLM) with low-rank adaptation (LoRA) designed for enhanced video (with paired audio) captioning through directed preference optimisation (DPO). We propose new metrics to evaluate the completeness and accuracy of video descriptions, which are optimised using DPO. To further improve training, we propose a novel multi-round DPO (MrDPO) approach, which involves periodically updating the DPO reference model, merging and re-initialising the LoRA module as a proxy for parameter updates after each training round (1,000 steps), and incorporating guidance from ground-truth video captions to stabilise the process. Experimental results show that MrDPO significantly enhances video-SALMONN 2's captioning accuracy, reducing the captioning error rates by 28\\%. The final video-SALMONN 2 model, with just 7 billion parameters, surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining highly competitive performance to the state-of-the-art on widely used video question-answering benchmarks among models of similar size. Codes are available at \\href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}.", "AI": {"tldr": "视频-SALMONN 2是一种先进的视听大语言模型，通过低秩适应（LoRA）和定向偏好优化（DPO）提升视频（带音频）字幕生成的准确性和完整性。", "motivation": "视频包含丰富信息，生成详细准确的描述是视频理解的关键。", "method": "提出多轮DPO（MrDPO）方法，定期更新参考模型，合并并重新初始化LoRA模块，结合真实字幕指导。", "result": "MrDPO显著提升字幕准确性，错误率降低28%，7B参数的模型超越GPT-4o和Gemini-1.5-Pro。", "conclusion": "视频-SALMONN 2在小规模参数下表现优异，代码已开源。"}}
{"id": "2506.15129", "categories": ["cs.HC", "stat.OT"], "pdf": "https://arxiv.org/pdf/2506.15129", "abs": "https://arxiv.org/abs/2506.15129", "authors": ["Paul Murrell"], "title": "Data Verbalisation: What is Text Doing in a Data Visualisation?", "comment": "43 pages (including appendix), 20 figures", "summary": "This article discusses the role that text elements play in a data visualisation. We argue that there is a need for a simple, coherent explanation of text elements similar to the understanding that already exists for non-text elements like bars, points, and lines. We explore examples of how text is used within a data visualisation and use existing knowledge and assessment techniques to evaluate when text is effective and when it is not. The result is a framework that aims to be easy to understand and easy to apply in order to understand the purpose and effectiveness of the text elements in any data visualisation.", "AI": {"tldr": "本文探讨了文本元素在数据可视化中的作用，提出了一个简单、一致的框架来评估文本元素的有效性。", "motivation": "目前对非文本元素（如条形、点、线）的理解较为成熟，但对文本元素的系统解释和评估方法尚不完善。", "method": "通过分析文本在数据可视化中的使用案例，结合现有知识和评估技术，探讨文本何时有效、何时无效。", "result": "提出了一个易于理解和应用的框架，用于评估数据可视化中文本元素的目的和有效性。", "conclusion": "该框架为理解和优化数据可视化中的文本元素提供了实用工具。"}}
{"id": "2506.15398", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15398", "abs": "https://arxiv.org/abs/2506.15398", "authors": ["Ruonan Lia", "Chang Wena", "Mingyu Yan", "Congcong Wu", "Ahmed Lotfy Elrefai", "Xiaotong Zhang", "Sahban Wael Saeed Alnaser"], "title": "Multi-dimensional evaluation on a rural integrated energy system including solar, wind, biomass and geothermal energy", "comment": null, "summary": "This study focuses on the novel municipal-scale rural integrated energy system (RIES), which encompasses energy supply and application. By constructing a seven-dimensional evaluation system including energy efficiency, energy supply, low-carbon sustainability, environmental impact, energy economy, social benefits, and integrated energy system development, this research combines the improved analytic hierarchy process (IAHP) and entropy weight method (EWM) by sum of squares of deviations to balance expert experience and data objectivity. Furthermore, the cloud model is introduced to handle the fuzziness and randomness in the evaluation. This method can quantify the differences in system performance before and after the planning implementation. The results indicate that after planning, the comprehensive score has increased from 83.12 to 87.55, the entropy value has decreased from 6.931 to 5.336, indicating enhanced system stability. The hyper-entropy has dropped from 3.08 to 2.278, reflecting a reduction in uncertainty. The research findings provide a scientific basis for the planning optimization, policy-making, and sustainable development of rural integrated energy systems, possessing both theoretical innovation and practical guiding value.", "AI": {"tldr": "研究提出了一种基于改进层次分析法（IAHP）和熵权法（EWM）的七维评价系统，结合云模型处理模糊性和随机性，用于评估农村综合能源系统（RIES）的性能变化。结果表明，规划后系统综合评分提高，稳定性和确定性增强。", "motivation": "为农村综合能源系统的规划优化和政策制定提供科学依据，同时兼顾理论创新和实践指导价值。", "method": "构建七维评价系统，结合IAHP和EWM方法，引入云模型处理模糊性和随机性，量化系统性能差异。", "result": "规划后综合评分从83.12提升至87.55，熵值从6.931降至5.336，超熵从3.08降至2.278，系统稳定性和确定性显著提高。", "conclusion": "该方法为农村综合能源系统的可持续发展和优化提供了有效工具，兼具理论和实践意义。"}}
{"id": "2506.15087", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15087", "abs": "https://arxiv.org/abs/2506.15087", "authors": ["Yuankai Lin", "Xiaofan Lu", "Jiahui Chen", "Hua Yang"], "title": "3D Vision-tactile Reconstruction from Infrared and Visible Images for Robotic Fine-grained Tactile Perception", "comment": null, "summary": "To achieve human-like haptic perception in anthropomorphic grippers, the compliant sensing surfaces of vision tactile sensor (VTS) must evolve from conventional planar configurations to biomimetically curved topographies with continuous surface gradients. However, planar VTSs have challenges when extended to curved surfaces, including insufficient lighting of surfaces, blurring in reconstruction, and complex spatial boundary conditions for surface structures. With an end goal of constructing a human-like fingertip, our research (i) develops GelSplitter3D by expanding imaging channels with a prism and a near-infrared (NIR) camera, (ii) proposes a photometric stereo neural network with a CAD-based normal ground truth generation method to calibrate tactile geometry, and (iii) devises a normal integration method with boundary constraints of depth prior information to correcting the cumulative error of surface integrals. We demonstrate better tactile sensing performance, a 40$\\%$ improvement in normal estimation accuracy, and the benefits of sensor shapes in grasping and manipulation tasks.", "AI": {"tldr": "论文提出了一种改进的视觉触觉传感器（VTS）设计，通过引入3D成像通道和优化几何校准方法，提升了触觉感知性能。", "motivation": "为了实现类人触觉感知，需要将传统平面VTS扩展到仿生曲面结构，但平面VTS在曲面上存在光照不足、重建模糊和复杂边界条件等问题。", "method": "研究开发了GelSplitter3D（通过棱镜和近红外相机扩展成像通道），提出了一种基于CAD的光度立体神经网络校准触觉几何，并设计了带边界约束的法向量积分方法。", "result": "实验表明，该方法在法向量估计精度上提升了40%，并在抓取和操作任务中表现出更好的触觉感知性能。", "conclusion": "该研究为构建类人指尖触觉传感器提供了有效的技术路径，显著提升了触觉感知的准确性和实用性。"}}
{"id": "2506.14835", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14835", "abs": "https://arxiv.org/abs/2506.14835", "authors": ["Kiet Dang Vu", "Trung Thai Tran", "Duc Dung Nguyen"], "title": "MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation", "comment": null, "summary": "Precisely localizing 3D objects from a single image constitutes a central challenge in monocular 3D detection. While DETR-like architectures offer a powerful paradigm, their direct application in this domain encounters inherent limitations, preventing optimal performance. Our work addresses these challenges by introducing MonoVQD, a novel framework designed to fundamentally advance DETR-based monocular 3D detection. We propose three main contributions. First, we propose the Mask Separated Self-Attention mechanism that enables the integration of the denoising process into a DETR architecture. This improves the stability of Hungarian matching to achieve a consistent optimization objective. Second, we present the Variational Query Denoising technique to address the gradient vanishing problem of conventional denoising methods, which severely restricts the efficiency of the denoising process. This explicitly introduces stochastic properties to mitigate this fundamental limitation and unlock substantial performance gains. Finally, we introduce a sophisticated self-distillation strategy, leveraging insights from later decoder layers to synergistically improve query quality in earlier layers, thereby amplifying the iterative refinement process. Rigorous experimentation demonstrates that MonoVQD achieves superior performance on the challenging KITTI monocular benchmark. Highlighting its broad applicability, MonoVQD's core components seamlessly integrate into other architectures, delivering significant performance gains even in multi-view 3D detection scenarios on the nuScenes dataset and underscoring its robust generalization capabilities.", "AI": {"tldr": "MonoVQD是一种基于DETR的单目3D检测框架，通过引入Mask Separated Self-Attention、Variational Query Denoising和自蒸馏策略，显著提升了性能。", "motivation": "解决DETR架构在单目3D检测中的固有局限性，如匈牙利匹配不稳定和梯度消失问题。", "method": "1. Mask Separated Self-Attention机制；2. Variational Query Denoising技术；3. 自蒸馏策略。", "result": "在KITTI和nuScenes数据集上表现优异，具有广泛适用性和泛化能力。", "conclusion": "MonoVQD通过创新方法显著提升了单目3D检测性能，并展示了其通用性。"}}
{"id": "2506.14793", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14793", "abs": "https://arxiv.org/abs/2506.14793", "authors": ["Aditya Ravuri", "Neil D. Lawrence"], "title": "Protein Language Model Zero-Shot Fitness Predictions are Improved by Inference-only Dropout", "comment": null, "summary": "Protein Language Models (PLMs) such as ESM2 have been shown to be capable of zero-shot prediction of critical scalar properties of proteins (fitness). In this work, we show that injecting a dropout layer at inference time between a PLM's featurizer/embedding layer and its transformer, and averaging its output akin to Monte-Carlo dropout increases zero-shot performance on a subset of the ProteinGym dataset. This is the case even when the model was not trained with dropouts to begin with, and does not require retraining or finetuning of the PLM. A dropout of 0.1 seems performant across all models.", "AI": {"tldr": "在蛋白质语言模型（PLM）的嵌入层和转换器之间注入一个dropout层，并在推理时进行蒙特卡洛dropout平均，可以提升零样本预测性能。", "motivation": "探索如何在不重新训练或微调PLM的情况下，通过简单的dropout注入提升零样本预测性能。", "method": "在PLM的嵌入层和转换器之间注入dropout层，推理时进行蒙特卡洛dropout平均。", "result": "在ProteinGym数据集子集上，零样本性能显著提升，dropout率为0.1时效果最佳。", "conclusion": "通过简单的dropout注入，可以显著提升PLM的零样本预测性能，无需额外训练。"}}
{"id": "2506.15189", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15189", "abs": "https://arxiv.org/abs/2506.15189", "authors": ["Yikan Wang"], "title": "Accessible Gesture-Driven Augmented Reality Interaction System", "comment": null, "summary": "Augmented reality (AR) offers immersive interaction but remains inaccessible for users with motor impairments or limited dexterity due to reliance on precise input methods. This study proposes a gesture-based interaction system for AR environments, leveraging deep learning to recognize hand and body gestures from wearable sensors and cameras, adapting interfaces to user capabilities. The system employs vision transformers (ViTs), temporal convolutional networks (TCNs), and graph attention networks (GATs) for gesture processing, with federated learning ensuring privacy-preserving model training across diverse users. Reinforcement learning optimizes interface elements like menu layouts and interaction modes. Experiments demonstrate a 20% improvement in task completion efficiency and a 25% increase in user satisfaction for motor-impaired users compared to baseline AR systems. This approach enhances AR accessibility and scalability. Keywords: Deep learning, Federated learning, Gesture recognition, Augmented reality, Accessibility, Human-computer interaction", "AI": {"tldr": "本文提出了一种基于手势的AR交互系统，利用深度学习识别手势，并通过联邦学习和强化学习优化界面，显著提升了运动障碍用户的体验。", "motivation": "AR通常依赖精确输入方式，对运动障碍或灵活性受限的用户不友好，因此需要开发更易用的交互系统。", "method": "结合视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）处理手势数据，采用联邦学习保护隐私，并通过强化学习优化界面。", "result": "实验显示，任务完成效率提升20%，用户满意度提高25%。", "conclusion": "该系统提升了AR的可访问性和扩展性，为运动障碍用户提供了更好的交互体验。"}}
{"id": "2506.15447", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15447", "abs": "https://arxiv.org/abs/2506.15447", "authors": ["David Leprich", "Mario Rosenfelder", "Mario Hermle", "Jingshan Chen", "Peter Eberhard"], "title": "Model Predictive Path-Following Control for a Quadrotor", "comment": "15 pages, 11 figures, submitted to PAMM 2025", "summary": "Automating drone-assisted processes is a complex task. Many solutions rely on trajectory generation and tracking, whereas in contrast, path-following control is a particularly promising approach, offering an intuitive and natural approach to automate tasks for drones and other vehicles. While different solutions to the path-following problem have been proposed, most of them lack the capability to explicitly handle state and input constraints, are formulated in a conservative two-stage approach, or are only applicable to linear systems. To address these challenges, the paper is built upon a Model Predictive Control-based path-following framework and extends its application to the Crazyflie quadrotor, which is investigated in hardware experiments. A cascaded control structure including an underlying attitude controller is included in the Model Predictive Path-Following Control formulation to meet the challenging real-time demands of quadrotor control. The effectiveness of the proposed method is demonstrated through real-world experiments, representing, to the best of the authors' knowledge, a novel application of this MPC-based path-following approach to the quadrotor. Additionally, as an extension to the original method, to allow for deviations of the path in cases where the precise following of the path might be overly restrictive, a corridor path-following approach is presented.", "AI": {"tldr": "论文提出了一种基于模型预测控制（MPC）的路径跟随框架，应用于Crazyflie四旋翼无人机，并通过硬件实验验证其有效性。", "motivation": "当前路径跟随方法大多无法显式处理状态和输入约束，或仅适用于线性系统，因此需要一种更灵活且高效的方法。", "method": "采用MPC框架，结合级联控制结构（包括底层姿态控制器），并引入走廊路径跟随方法以应对路径偏差。", "result": "通过实际硬件实验验证了方法的有效性，并展示了其在四旋翼无人机上的新颖应用。", "conclusion": "提出的MPC路径跟随方法在实时性和灵活性上表现优异，为无人机自动化任务提供了新思路。"}}
{"id": "2506.15096", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15096", "abs": "https://arxiv.org/abs/2506.15096", "authors": ["Zihe Ji", "Huangxuan Lin", "Yue Gao"], "title": "DyNaVLM: Zero-Shot Vision-Language Navigation System with Dynamic Viewpoints and Self-Refining Graph Memory", "comment": null, "summary": "We present DyNaVLM, an end-to-end vision-language navigation framework using Vision-Language Models (VLM). In contrast to prior methods constrained by fixed angular or distance intervals, our system empowers agents to freely select navigation targets via visual-language reasoning. At its core lies a self-refining graph memory that 1) stores object locations as executable topological relations, 2) enables cross-robot memory sharing through distributed graph updates, and 3) enhances VLM's decision-making via retrieval augmentation. Operating without task-specific training or fine-tuning, DyNaVLM demonstrates high performance on GOAT and ObjectNav benchmarks. Real-world tests further validate its robustness and generalization. The system's three innovations: dynamic action space formulation, collaborative graph memory, and training-free deployment, establish a new paradigm for scalable embodied robot, bridging the gap between discrete VLN tasks and continuous real-world navigation.", "AI": {"tldr": "DyNaVLM是一种端到端的视觉语言导航框架，通过视觉语言模型实现自由目标选择，无需任务特定训练即可在多个基准测试中表现优异。", "motivation": "解决现有方法因固定角度或距离间隔而受限的问题，实现更灵活的导航目标选择。", "method": "采用自优化图记忆存储对象位置，支持分布式图更新和检索增强，动态生成动作空间。", "result": "在GOAT和ObjectNav基准测试中表现优异，实际测试验证了其鲁棒性和泛化能力。", "conclusion": "DyNaVLM的动态动作空间、协作图记忆和无训练部署为可扩展的机器人导航设定了新范式。"}}
{"id": "2506.14837", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14837", "abs": "https://arxiv.org/abs/2506.14837", "authors": ["Chengzhi Xu", "Yuyang Wang", "Lai Wei", "Lichao Sun", "Weiran Huang"], "title": "Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction", "comment": null, "summary": "Recently, multimodal large language models (MLLMs) have attracted increasing research attention due to their powerful visual understanding capabilities. While they have achieved impressive results on various vision tasks, their performance on chart-to-code generation remains suboptimal. This task requires MLLMs to generate executable code that can reproduce a given chart, demanding not only precise visual understanding but also accurate translation of visual elements into structured code. Directly prompting MLLMs to perform this complex task often yields unsatisfactory results. To address this challenge, we propose {ChartIR}, an iterative refinement method based on structured instruction. First, we distinguish two tasks: visual understanding and code translation. To accomplish the visual understanding component, we design two types of structured instructions: description and difference. The description instruction captures the visual elements of the reference chart, while the difference instruction characterizes the discrepancies between the reference chart and the generated chart. These instructions effectively transform visual features into language representations, thereby facilitating the subsequent code translation process. Second, we decompose the overall chart generation pipeline into two stages: initial code generation and iterative refinement, enabling progressive enhancement of the final output. Experimental results show that, compared to other method, our method achieves superior performance on both the open-source model Qwen2-VL and the closed-source model GPT-4o.", "AI": {"tldr": "提出了一种基于结构化指令的迭代优化方法ChartIR，用于提升多模态大语言模型在图表到代码生成任务中的性能。", "motivation": "现有MLLMs在图表到代码生成任务中表现不佳，需要同时具备精确的视觉理解和准确的代码翻译能力。直接提示MLLMs效果不理想。", "method": "将任务分解为视觉理解和代码翻译两部分，设计描述和差异两种结构化指令，并将生成流程分为初始代码生成和迭代优化两阶段。", "result": "在开源模型Qwen2-VL和闭源模型GPT-4o上均表现出优于其他方法的性能。", "conclusion": "ChartIR通过结构化指令和迭代优化显著提升了MLLMs在图表到代码生成任务中的表现。"}}
{"id": "2506.14794", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14794", "abs": "https://arxiv.org/abs/2506.14794", "authors": ["Henrik Klagges", "Robert Dahlke", "Fabian Klemm", "Benjamin Merkel", "Daniel Klingmann", "David A. Reiss", "Dan Zecha"], "title": "Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors", "comment": null, "summary": "Requiring $10^{13}$-$10^{15}$ FLOPs to calculate one 8 bit weight in an LLM during pretraining is extremely expensive and seems inefficient. To better leverage the huge investments made into pretrained models, we develop the new \"Assembly-of-Experts\" (AoE) construction method to create capable child variants of existing Mixture-of-Experts parent models in linear time. Model weight tensors get interpolated individually, allowing to enhance or suppress semantic features of the parents.\n  Varying the proportion of weights taken from the parent models, we observe some properties of the AoE child model changing gradually, while other behavioral traits emerge with a sharp transition. Surprisingly, nearly every generated model is functional and capable, which makes searching the model space straightforward.\n  We construct the DeepSeek R1T \"Chimera\", a 671B open-weights hybrid model combining DeepSeek's V3-0324 and R1 model variants. The child inherits only the routed expert tensors of R1, but still achieves about R1-level intelligence. At the same time, it uses about 40\\% fewer output tokens, close to V3 speed. Constructed without any fine-tuning or distillation, the Chimera exhibits surprisingly compact, orderly reasoning compared to its parent models.", "AI": {"tldr": "提出了一种名为“专家组装”（AoE）的新方法，用于高效生成混合专家模型的子模型，显著降低了计算成本。", "motivation": "预训练大型语言模型的计算成本极高（$10^{13}$-$10^{15}$ FLOPs），现有方法效率低下，需要更高效利用预训练模型的资源。", "method": "通过线性时间内的权重张量插值，从父模型中生成子模型，增强或抑制语义特征。", "result": "生成的子模型功能强大且稳定，DeepSeek R1T \"Chimera\"模型结合了父模型的优点，性能接近R1但速度接近V3。", "conclusion": "AoE方法无需微调或蒸馏即可生成高效子模型，展示了紧凑且有序的推理能力。"}}
{"id": "2506.15293", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15293", "abs": "https://arxiv.org/abs/2506.15293", "authors": ["Francesco Chiossi", "Julian Rasch", "Robin Welsch", "Albrecht Schmidt", "Florian Michahelles"], "title": "Designing Intent: A Multimodal Framework for Human-Robot Cooperation in Industrial Workspaces", "comment": "9 pages", "summary": "As robots enter collaborative workspaces, ensuring mutual understanding between human workers and robotic systems becomes a prerequisite for trust, safety, and efficiency. In this position paper, we draw on the cooperation scenario of the AIMotive project in which a human and a cobot jointly perform assembly tasks to argue for a structured approach to intent communication. Building on the Situation Awareness-based Agent Transparency (SAT) framework and the notion of task abstraction levels, we propose a multidimensional design space that maps intent content (SAT1, SAT3), planning horizon (operational to strategic), and modality (visual, auditory, haptic). We illustrate how this space can guide the design of multimodal communication strategies tailored to dynamic collaborative work contexts. With this paper, we lay the conceptual foundation for a future design toolkit aimed at supporting transparent human-robot interaction in the workplace. We highlight key open questions and design challenges, and propose a shared agenda for multimodal, adaptive, and trustworthy robotic collaboration in hybrid work environments.", "AI": {"tldr": "提出了一种基于情境感知的多维度设计空间，用于指导人机协作中的意图通信设计。", "motivation": "确保人机协作中的相互理解和信任是提升安全性和效率的关键。", "method": "基于SAT框架和任务抽象层次，提出了一个多维设计空间，涵盖意图内容、规划范围和通信模态。", "result": "为动态协作工作场景设计多模态通信策略提供了指导。", "conclusion": "为未来透明人机交互的设计工具包奠定基础，并提出了开放式问题和设计挑战。"}}
{"id": "2506.15465", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15465", "abs": "https://arxiv.org/abs/2506.15465", "authors": ["Marco Borghesi", "Lorenzo Sforni", "Giuseppe Notarstefano"], "title": "DATA-DRIVEN PRONTO: a Model-free Solution for Numerical Optimal Control", "comment": null, "summary": "This article addresses the problem of data-driven numerical optimal control for unknown nonlinear systems. In our scenario, we suppose to have the possibility of performing multiple experiments (or simulations) on the system. Experiments are performed by relying on a data-driven tracking controller able to steer the system towards a desired reference. Our proposed DATA-DRIVEN PRONTO algorithm iteratively refines a tentative solution of the optimal control problem by computing an approximate descent direction via a local trajectory perturbation. At each iteration, multiple trajectories are gathered by perturbing the current trajectory with a suitable dither signal, and then used to obtain a data-driven, time-varying linearization. The exploration is guided by the tracking controller, so that perturbed trajectories are obtained in closed loop. We show local convergence of DATA-DRIVEN PRONTO to a ball about an isolated optimal solution, whose radius depends on the amplitude of the dither signal. We corroborate the theoretical results by applying it to an underactuated robot.", "AI": {"tldr": "本文提出了一种名为DATA-DRIVEN PRONTO的算法，用于解决未知非线性系统的数据驱动数值最优控制问题。通过迭代优化和局部轨迹扰动，算法在闭环中利用跟踪控制器引导探索，最终收敛到最优解附近。", "motivation": "解决未知非线性系统的数据驱动最优控制问题，利用实验或模拟数据迭代优化控制策略。", "method": "提出DATA-DRIVEN PRONTO算法，通过局部轨迹扰动和闭环跟踪控制器引导探索，利用数据驱动的时间变化线性化迭代优化。", "result": "算法局部收敛到最优解附近的区域，收敛半径与扰动信号幅度相关。实验验证了理论结果在欠驱动机器人上的有效性。", "conclusion": "DATA-DRIVEN PRONTO算法在未知非线性系统的数据驱动最优控制中表现出良好的收敛性和实用性。"}}
{"id": "2506.14842", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14842", "abs": "https://arxiv.org/abs/2506.14842", "authors": ["Lukas Schiesser", "Cornelius Wolff", "Sophie Haas", "Simon Pukrop"], "title": "PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers", "comment": "15 pages, 10 figures", "summary": "Building image classification models remains cumbersome in data-scarce domains, where collecting large labeled datasets is impractical. In-context learning (ICL) has emerged as a promising paradigm for few-shot image classification (FSIC), enabling models to generalize across domains without gradient-based adaptation. However, prior work has largely overlooked a critical component of ICL-based FSIC pipelines: the role of image embeddings. In this work, we present PictSure, an ICL framework that places the embedding model -- its architecture, pretraining, and training dynamics -- at the center of analysis. We systematically examine the effects of different visual encoder types, pretraining objectives, and fine-tuning strategies on downstream FSIC performance. Our experiments show that the training success and the out-of-domain performance are highly dependent on how the embedding models are pretrained. Consequently, PictSure manages to outperform existing ICL-based FSIC models on out-of-domain benchmarks that differ significantly from the training distribution, while maintaining comparable results on in-domain tasks. Code can be found at https://github.com/PictSure/pictsure-library.", "AI": {"tldr": "PictSure是一个专注于图像嵌入模型的ICL框架，通过系统分析嵌入模型的架构、预训练和训练动态，显著提升了少样本图像分类的跨域性能。", "motivation": "在数据稀缺领域，构建图像分类模型困难，ICL成为一种有前景的少样本学习方法，但现有研究忽视了图像嵌入模型的关键作用。", "method": "提出PictSure框架，系统研究不同视觉编码器类型、预训练目标和微调策略对少样本分类性能的影响。", "result": "实验表明，嵌入模型的预训练方式显著影响训练成功率和跨域性能，PictSure在跨域任务上优于现有方法，同时保持域内任务的可比性能。", "conclusion": "PictSure通过优化嵌入模型设计，为少样本图像分类提供了更高效的解决方案，尤其在跨域场景中表现突出。"}}
{"id": "2506.14797", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14797", "abs": "https://arxiv.org/abs/2506.14797", "authors": ["Marco Nurisso", "Jesseba Fernando", "Raj Deshpande", "Alan Perotti", "Raja Marjieh", "Steven M. Frankland", "Richard L. Lewis", "Taylor W. Webb", "Declan Campbell", "Francesco Vaccarino", "Jonathan D. Cohen", "Giovanni Petri"], "title": "Bound by semanticity: universal laws governing the generalization-identification tradeoff", "comment": null, "summary": "Intelligent systems must deploy internal representations that are simultaneously structured -- to support broad generalization -- and selective -- to preserve input identity. We expose a fundamental limit on this tradeoff. For any model whose representational similarity between inputs decays with finite semantic resolution $\\varepsilon$, we derive closed-form expressions that pin its probability of correct generalization $p_S$ and identification $p_I$ to a universal Pareto front independent of input space geometry. Extending the analysis to noisy, heterogeneous spaces and to $n>2$ inputs predicts a sharp $1/n$ collapse of multi-input processing capacity and a non-monotonic optimum for $p_S$. A minimal ReLU network trained end-to-end reproduces these laws: during learning a resolution boundary self-organizes and empirical $(p_S,p_I)$ trajectories closely follow theoretical curves for linearly decaying similarity. Finally, we demonstrate that the same limits persist in two markedly more complex settings -- a convolutional neural network and state-of-the-art vision-language models -- confirming that finite-resolution similarity is a fundamental emergent informational constraint, not merely a toy-model artifact. Together, these results provide an exact theory of the generalization-identification trade-off and clarify how semantic resolution shapes the representational capacity of deep networks and brains alike.", "AI": {"tldr": "论文探讨了智能系统内部表示的结构化与选择性之间的权衡，揭示了其基本限制，并通过理论和实验验证了这种权衡的普遍性。", "motivation": "研究智能系统如何在支持广泛泛化的同时保持输入身份的选择性，揭示这种权衡的基本限制。", "method": "通过理论推导闭式表达式分析表示相似性衰减对泛化和识别概率的影响，并在简单和复杂模型中验证。", "result": "发现泛化与识别概率受限于一个通用的Pareto前沿，且在复杂模型中同样存在这种限制。", "conclusion": "有限分辨率相似性是深层网络和大脑表示能力的基本信息约束，为泛化-识别权衡提供了精确理论。"}}
{"id": "2506.15294", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15294", "abs": "https://arxiv.org/abs/2506.15294", "authors": ["Jonas Lau", "Annie Tran"], "title": "UXR Point of View on Product Feature Prioritization Prior To Multi-Million Engineering Commitments", "comment": null, "summary": "This paper discusses a popular UX research activity, feature prioritization, using the User Experience Research Point of View (UXR PoV) Playbook framework. We describe an application of multinomial logistic regression, frequently marketed as MaxDiff, for prioritizing product features in consumer product development. It addresses challenges of traditional surveying techniques. We propose a solution using MaxDiff to generate a reliable preference list with a reasonable sample size. We also adapt the MaxDiff method to reduce the number of survey responses in half, making it less tedious from the survey takers' perspective. We present a case study using the adapted MaxDiff method for tablet feature prioritization research involving users with disabilities.", "AI": {"tldr": "论文探讨了使用MaxDiff方法进行产品功能优先级排序，解决了传统调查方法的挑战，并通过案例研究验证了其有效性。", "motivation": "传统调查方法在功能优先级排序中存在局限性，MaxDiff方法能更可靠地生成偏好列表。", "method": "采用多类别逻辑回归（MaxDiff）方法，并对其进行改进以减少调查响应数量。", "result": "改进后的MaxDiff方法成功减少了50%的调查响应需求，并在平板功能优先级研究中得到验证。", "conclusion": "MaxDiff方法是一种高效且可靠的功能优先级排序工具，尤其适用于用户群体有限的情况。"}}
{"id": "2506.15665", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15665", "abs": "https://arxiv.org/abs/2506.15665", "authors": ["Bahram Yaghooti", "Chengyu Li", "Bruno Sinopoli"], "title": "A Data-Integrated Framework for Learning Fractional-Order Nonlinear Dynamical Systems", "comment": null, "summary": "This paper presents a data-integrated framework for learning the dynamics of fractional-order nonlinear systems in both discrete-time and continuous-time settings. The proposed framework consists of two main steps. In the first step, input-output experiments are designed to generate the necessary datasets for learning the system dynamics, including the fractional order, the drift vector field, and the control vector field. In the second step, these datasets, along with the memory-dependent property of fractional-order systems, are used to estimate the system's fractional order. The drift and control vector fields are then reconstructed using orthonormal basis functions. To validate the proposed approach, the algorithm is applied to four benchmark fractional-order systems. The results confirm the effectiveness of the proposed framework in learning the system dynamics accurately. Finally, the same datasets are used to learn equivalent integer-order models. The numerical comparisons demonstrate that fractional-order models better capture long-range dependencies, highlighting the limitations of integer-order representations.", "AI": {"tldr": "提出了一种数据集成框架，用于学习分数阶非线性系统的动力学，验证了其在离散和连续时间下的有效性，并展示了分数阶模型在捕捉长程依赖关系上的优势。", "motivation": "研究分数阶非线性系统的动力学学习问题，以解决传统整数阶模型在捕捉长程依赖关系上的局限性。", "method": "框架分为两步：1) 设计输入-输出实验生成数据集；2) 利用数据集和分数阶系统的记忆特性估计分数阶，并使用正交基函数重构漂移和控制向量场。", "result": "在四个基准分数阶系统上验证了框架的有效性，分数阶模型比整数阶模型更能准确捕捉长程依赖关系。", "conclusion": "提出的数据集成框架能有效学习分数阶系统动力学，分数阶模型在长程依赖关系建模上优于整数阶模型。"}}
{"id": "2506.15126", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15126", "abs": "https://arxiv.org/abs/2506.15126", "authors": ["Bingbing Zhang", "Huan Yin", "Shuo Liu", "Fumin Zhang", "Wen Xu"], "title": "VIMS: A Visual-Inertial-Magnetic-Sonar SLAM System in Underwater Environments", "comment": "This work has been accepted for publication at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)", "summary": "In this study, we present a novel simultaneous localization and mapping (SLAM) system, VIMS, designed for underwater navigation. Conventional visual-inertial state estimators encounter significant practical challenges in perceptually degraded underwater environments, particularly in scale estimation and loop closing. To address these issues, we first propose leveraging a low-cost single-beam sonar to improve scale estimation. Then, VIMS integrates a high-sampling-rate magnetometer for place recognition by utilizing magnetic signatures generated by an economical magnetic field coil. Building on this, a hierarchical scheme is developed for visual-magnetic place recognition, enabling robust loop closure. Furthermore, VIMS achieves a balance between local feature tracking and descriptor-based loop closing, avoiding additional computational burden on the front end. Experimental results highlight the efficacy of the proposed VIMS, demonstrating significant improvements in both the robustness and accuracy of state estimation within underwater environments.", "AI": {"tldr": "提出了一种名为VIMS的新型水下SLAM系统，通过结合单波束声纳和高采样率磁力计，解决了水下环境中尺度估计和闭环检测的挑战。", "motivation": "传统视觉-惯性状态估计器在水下感知退化环境中面临尺度估计和闭环检测的困难，需要一种更鲁棒的解决方案。", "method": "利用低成本单波束声纳改进尺度估计，结合高采样率磁力计进行位置识别，并开发了分层视觉-磁力位置识别方案以实现鲁棒闭环。", "result": "实验结果表明，VIMS在水下环境中显著提高了状态估计的鲁棒性和准确性。", "conclusion": "VIMS通过创新的传感器融合和分层方案，有效解决了水下SLAM的关键挑战。"}}
{"id": "2506.14846", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.14846", "abs": "https://arxiv.org/abs/2506.14846", "authors": ["Shreyas Rajeev", "B Sathish Babu"], "title": "Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach", "comment": null, "summary": "Kernel size selection in Convolutional Neural Networks (CNNs) is a critical but often overlooked design decision that affects receptive field, feature extraction, computational cost, and model accuracy. This paper proposes the Best Kernel Size Estimation Function (BKSEF), a mathematically grounded and empirically validated framework for optimal, layer-wise kernel size determination. BKSEF balances information gain, computational efficiency, and accuracy improvements by integrating principles from information theory, signal processing, and learning theory. Extensive experiments on CIFAR-10, CIFAR-100, ImageNet-lite, ChestX-ray14, and GTSRB datasets demonstrate that BKSEF-guided architectures achieve up to 3.1 percent accuracy improvement and 42.8 percent reduction in FLOPs compared to traditional models using uniform 3x3 kernels. Two real-world case studies further validate the approach: one for medical image classification in a cloud-based setup, and another for traffic sign recognition on edge devices. The former achieved enhanced interpretability and accuracy, while the latter reduced latency and model size significantly, with minimal accuracy trade-off. These results show that kernel size can be an active, optimizable parameter rather than a fixed heuristic. BKSEF provides practical heuristics and theoretical support for researchers and developers seeking efficient and application-aware CNN designs. It is suitable for integration into neural architecture search pipelines and real-time systems, offering a new perspective on CNN optimization.", "AI": {"tldr": "本文提出了一种基于数学和实证的框架BKSEF，用于优化CNN中逐层的核大小选择，平衡信息增益、计算效率和准确性。实验表明，BKSEF指导的模型在多个数据集上表现优于传统方法。", "motivation": "核大小选择在CNN设计中至关重要，但常被忽视。本文旨在通过BKSEF框架优化核大小，以提升模型性能和效率。", "method": "BKSEF结合信息论、信号处理和学习理论，通过数学和实证方法确定最优核大小。", "result": "实验显示，BKSEF在多个数据集上实现了最高3.1%的准确率提升和42.8%的FLOPs减少。", "conclusion": "BKSEF为CNN设计提供了理论和实践支持，适用于神经架构搜索和实时系统，重新定义了核大小的优化视角。"}}
{"id": "2506.14802", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14802", "abs": "https://arxiv.org/abs/2506.14802", "authors": ["Zuochen Ye"], "title": "ss-Mamba: Semantic-Spline Selective State-Space Model", "comment": null, "summary": "We propose ss-Mamba, a novel foundation model that enhances time series forecasting by integrating semantic-aware embeddings and adaptive spline-based temporal encoding within a selective state-space modeling framework. Building upon the recent success of Transformer architectures, ss-Mamba adopts the Mamba selective state space model as an efficient alternative that achieves comparable performance while significantly reducing computational complexity from quadratic to linear time. Semantic index embeddings, initialized from pretrained language models, allow effective generalization to previously unseen series through meaningful semantic priors. Additionally, spline-based Kolmogorov-Arnold Networks (KAN) dynamically and interpretably capture complex seasonalities and non-stationary temporal effects, providing a powerful enhancement over conventional temporal feature encodings. Extensive experimental evaluations confirm that ss-Mamba delivers superior accuracy, robustness, and interpretability, demonstrating its capability as a versatile and computationally efficient alternative to traditional Transformer-based models in time-series forecasting.", "AI": {"tldr": "ss-Mamba是一种新型基础模型，通过结合语义感知嵌入和自适应样条时间编码，在选择性状态空间建模框架中提升时间序列预测性能。", "motivation": "传统Transformer架构在时间序列预测中存在计算复杂度高的问题，ss-Mamba旨在提供一种高效且性能相当的替代方案。", "method": "采用Mamba选择性状态空间模型，结合语义索引嵌入和样条KAN网络，动态捕捉复杂时间特征。", "result": "实验证明ss-Mamba在准确性、鲁棒性和可解释性上优于传统Transformer模型，且计算复杂度从二次降至线性。", "conclusion": "ss-Mamba是一种高效且多功能的时间序列预测模型，为传统Transformer提供了有力替代。"}}
{"id": "2506.15314", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15314", "abs": "https://arxiv.org/abs/2506.15314", "authors": ["Jason Dong", "Anna Wu"], "title": "Case Study for Developing a UXR Point of View for FinOps Product Innovation", "comment": null, "summary": "In the dynamic landscape of Cloud financial management, we are sharing a case study exploring the development of a User Experience Research (UXR) Point of View (PoV) to drive FinOps product innovation. We demonstrate how qualitative and quantitative research methods working together to navigate the challenges of understanding customer needs, aligning cross-functional teams, and prioritizing limited resources. Through a multi-phased research approach, the research team identifies opportunities, quantifies pain points, and segments diverse customer cohorts. This culminated in a UXR PoV that informed the creation of a differentiated product strategy, a 'one-stop shop' dashboard empowering FinOps practitioners with actionable insights and tools. This case study highlights the power of mixed-methods research in uncovering actionable insights that drive impactful product innovation.", "AI": {"tldr": "本文通过案例研究展示了如何结合定性与定量研究方法，开发用户体验研究（UXR）观点（PoV），以推动FinOps产品创新。", "motivation": "在云财务管理动态环境中，理解客户需求、协调跨职能团队并优化有限资源分配是主要挑战。", "method": "采用多阶段研究方法，结合定性与定量数据，识别机会、量化痛点并细分客户群体。", "result": "最终形成UXR PoV，指导开发了“一站式”仪表盘，为FinOps从业者提供实用工具和洞察。", "conclusion": "混合研究方法能有效挖掘可操作洞察，推动产品创新。"}}
{"id": "2506.15150", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15150", "abs": "https://arxiv.org/abs/2506.15150", "authors": ["Yuanlong Ji", "Xingbang Yang", "Ruoqi Zhao", "Qihan Ye", "Quan Zheng", "Yubo Fan"], "title": "Human Locomotion Implicit Modeling Based Real-Time Gait Phase Estimation", "comment": null, "summary": "Gait phase estimation based on inertial measurement unit (IMU) signals facilitates precise adaptation of exoskeletons to individual gait variations. However, challenges remain in achieving high accuracy and robustness, particularly during periods of terrain changes. To address this, we develop a gait phase estimation neural network based on implicit modeling of human locomotion, which combines temporal convolution for feature extraction with transformer layers for multi-channel information fusion. A channel-wise masked reconstruction pre-training strategy is proposed, which first treats gait phase state vectors and IMU signals as joint observations of human locomotion, thus enhancing model generalization. Experimental results demonstrate that the proposed method outperforms existing baseline approaches, achieving a gait phase RMSE of $2.729 \\pm 1.071%$ and phase rate MAE of $0.037 \\pm 0.016%$ under stable terrain conditions with a look-back window of 2 seconds, and a phase RMSE of $3.215 \\pm 1.303%$ and rate MAE of $0.050 \\pm 0.023%$ under terrain transitions. Hardware validation on a hip exoskeleton further confirms that the algorithm can reliably identify gait cycles and key events, adapting to various continuous motion scenarios. This research paves the way for more intelligent and adaptive exoskeleton systems, enabling safer and more efficient human-robot interaction across diverse real-world environments.", "AI": {"tldr": "提出一种基于IMU信号的步态相位估计神经网络，结合时间卷积和Transformer层，通过通道掩码重建预训练策略提升模型泛化能力，实验验证其在稳定地形和地形变化下均优于基线方法。", "motivation": "解决现有步态相位估计方法在高精度和鲁棒性方面的不足，特别是在地形变化时的性能问题。", "method": "开发了一种结合时间卷积和Transformer层的神经网络，采用通道掩码重建预训练策略，将步态相位状态向量与IMU信号联合建模。", "result": "在稳定地形下步态相位RMSE为2.729±1.071%，相位率MAE为0.037±0.016%；地形变化时RMSE为3.215±1.303%，MAE为0.050±0.023%。硬件验证表明算法能可靠识别步态周期和关键事件。", "conclusion": "该方法为更智能和自适应的外骨骼系统铺平了道路，提升了人机交互的安全性和效率。"}}
{"id": "2506.15132", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15132", "abs": "https://arxiv.org/abs/2506.15132", "authors": ["Yushi Wang", "Penghui Chen", "Xinyu Han", "Feng Wu", "Mingguo Zhao"], "title": "Booster Gym: An End-to-End Reinforcement Learning Framework for Humanoid Robot Locomotion", "comment": null, "summary": "Recent advancements in reinforcement learning (RL) have led to significant progress in humanoid robot locomotion, simplifying the design and training of motion policies in simulation. However, the numerous implementation details make transferring these policies to real-world robots a challenging task. To address this, we have developed a comprehensive code framework that covers the entire process from training to deployment, incorporating common RL training methods, domain randomization, reward function design, and solutions for handling parallel structures. This library is made available as a community resource, with detailed descriptions of its design and experimental results. We validate the framework on the Booster T1 robot, demonstrating that the trained policies seamlessly transfer to the physical platform, enabling capabilities such as omnidirectional walking, disturbance resistance, and terrain adaptability. We hope this work provides a convenient tool for the robotics community, accelerating the development of humanoid robots. The code can be found in https://github.com/BoosterRobotics/booster_gym.", "AI": {"tldr": "论文提出了一个全面的代码框架，用于简化人形机器人运动策略从仿真到现实的迁移，包含训练方法、领域随机化等，并在Booster T1机器人上验证了其有效性。", "motivation": "解决强化学习策略从仿真迁移到现实机器人时的实现细节挑战。", "method": "开发了一个涵盖训练到部署全流程的代码框架，整合了RL训练方法、领域随机化、奖励函数设计等。", "result": "在Booster T1机器人上验证了策略的无缝迁移，实现了全向行走、抗干扰和地形适应能力。", "conclusion": "该框架为机器人社区提供了便捷工具，加速人形机器人发展。"}}
{"id": "2506.14854", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14854", "abs": "https://arxiv.org/abs/2506.14854", "authors": ["Varun Mannam", "Zhenyu Shi"], "title": "Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis", "comment": "Submitting to ICCV 2025 workshop: https://retailvisionworkshop.github.io/", "summary": "Accurate video annotation plays a vital role in modern retail applications, including customer behavior analysis, product interaction detection, and in-store activity recognition. However, conventional annotation methods heavily rely on time-consuming manual labeling by human annotators, introducing non-robust frame selection and increasing operational costs. To address these challenges in the retail domain, we propose a deep learning-based approach that automates key-frame identification in retail videos and provides automatic annotations of products and customers. Our method leverages deep neural networks to learn discriminative features by embedding video frames and incorporating object detection-based techniques tailored for retail environments. Experimental results showcase the superiority of our approach over traditional methods, achieving accuracy comparable to human annotator labeling while enhancing the overall efficiency of retail video annotation. Remarkably, our approach leads to an average of 2 times cost savings in video annotation. By allowing human annotators to verify/adjust less than 5% of detected frames in the video dataset, while automating the annotation process for the remaining frames without reducing annotation quality, retailers can significantly reduce operational costs. The automation of key-frame detection enables substantial time and effort savings in retail video labeling tasks, proving highly valuable for diverse retail applications such as shopper journey analysis, product interaction detection, and in-store security monitoring.", "AI": {"tldr": "提出一种基于深度学习的零售视频自动标注方法，通过关键帧识别和自动标注提升效率并降低成本。", "motivation": "传统零售视频标注依赖人工，效率低且成本高，需自动化解决方案。", "method": "利用深度神经网络学习视频帧特征，结合目标检测技术实现零售环境下的自动标注。", "result": "方法优于传统标注，准确率接近人工标注，成本节省2倍，仅需人工验证5%的帧。", "conclusion": "该方法显著降低零售视频标注成本和时间，适用于多种零售应用场景。"}}
{"id": "2506.14806", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14806", "abs": "https://arxiv.org/abs/2506.14806", "authors": ["Bochen Lyu", "Xiaojing Zhang", "Fangyi Zheng", "He Wang", "Zheng Wang", "Zhanxing Zhu"], "title": "Heavy-Ball Momentum Method in Continuous Time and Discretization Error Analysis", "comment": "32 pages, 7 figures", "summary": "This paper establishes a continuous time approximation, a piece-wise continuous differential equation, for the discrete Heavy-Ball (HB) momentum method with explicit discretization error. Investigating continuous differential equations has been a promising approach for studying the discrete optimization methods. Despite the crucial role of momentum in gradient-based optimization methods, the gap between the original discrete dynamics and the continuous time approximations due to the discretization error has not been comprehensively bridged yet. In this work, we study the HB momentum method in continuous time while putting more focus on the discretization error to provide additional theoretical tools to this area. In particular, we design a first-order piece-wise continuous differential equation, where we add a number of counter terms to account for the discretization error explicitly. As a result, we provide a continuous time model for the HB momentum method that allows the control of discretization error to arbitrary order of the step size. As an application, we leverage it to find a new implicit regularization of the directional smoothness and investigate the implicit bias of HB for diagonal linear networks, indicating how our results can be used in deep learning. Our theoretical findings are further supported by numerical experiments.", "AI": {"tldr": "本文为离散的Heavy-Ball动量方法建立了连续时间近似模型，通过分段连续微分方程显式处理离散化误差，填补了离散动力学与连续近似之间的理论空白。", "motivation": "研究连续微分方程是分析离散优化方法的有力工具，但动量方法中的离散化误差尚未被充分解决。本文旨在通过显式处理离散化误差，为HB动量方法提供更精确的连续时间模型。", "method": "设计了一阶分段连续微分方程，通过添加补偿项显式处理离散化误差，从而实现对步长任意阶误差的控制。", "result": "提出了一个连续时间模型，能够控制离散化误差至任意阶步长，并应用于方向平滑性的隐式正则化和对角线性网络的隐式偏差分析。", "conclusion": "理论结果通过数值实验验证，展示了该方法在深度学习中的潜在应用价值。"}}
{"id": "2506.15325", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15325", "abs": "https://arxiv.org/abs/2506.15325", "authors": ["Festus Adedoyin", "Huseyin Dogan"], "title": "Human-Centred AI in FinTech: Developing a User Experience (UX) Research Point of View (PoV) Playbook", "comment": null, "summary": "Advancements in Artificial Intelligence (AI) have significantly transformed the financial industry, enabling the development of more personalised and adaptable financial products and services. This research paper explores various instances where Human-Centred AI (HCAI) has facilitated these advancements, drawing from contemporary studies and industry progress. The paper examines how the application of HCAI-powered data analytics, machine learning, and natural language processing enables financial institutions to gain a deeper understanding of their customers' unique needs, preferences, and behavioural patterns. This, in turn, allows for the creation of tailored financial solutions that address individual consumer requirements, ultimately enhancing overall user experience and satisfaction. Additionally, the study highlights the integration of AI-powered robo-advisory services, which offer customised investment recommendations and portfolio management tailored to diverse risk profiles and investment goals. Moreover, the paper underscores the role of AI in strengthening fraud detection, risk assessment, and regulatory compliance, leading to a more secure and adaptable financial landscape. The findings of this research demonstrate the substantial impact of Human-Centred AI on the financial industry, offering a strategic framework for financial institutions to leverage these technologies. By incorporating a User Experience Research (UXR) Point of View (PoV), financial institutions can ensure that AI-driven solutions align with user needs and business objectives.", "AI": {"tldr": "论文探讨了以人为中心的人工智能（HCAI）在金融行业中的应用，展示了其如何通过数据分析和机器学习等技术提升个性化服务、用户体验和安全性。", "motivation": "研究旨在揭示HCAI如何帮助金融机构更好地理解客户需求，从而开发更个性化的金融产品和服务。", "method": "通过分析HCAI驱动的数据分析、机器学习和自然语言处理技术，结合行业案例和当代研究。", "result": "HCAI显著提升了金融服务的个性化、用户体验和安全性，如智能投顾和欺诈检测。", "conclusion": "HCAI为金融机构提供了战略框架，结合用户体验研究可确保AI解决方案与用户需求一致。"}}
{"id": "2506.15376", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.15376", "abs": "https://arxiv.org/abs/2506.15376", "authors": ["Ahmed Ibrahim", "Francisco F. C. Rego", "Éric Busvelle"], "title": "Comparison of Innovative Strategies for the Coverage Problem: Path Planning, Search Optimization, and Applications in Underwater Robotics", "comment": null, "summary": "In many applications, including underwater robotics, the coverage problem requires an autonomous vehicle to systematically explore a defined area while minimizing redundancy and avoiding obstacles. This paper investigates coverage path planning strategies to enhance the efficiency of underwater gliders, particularly in maximizing the probability of detecting a radioactive source while ensuring safe navigation.\n  We evaluate three path-planning approaches: the Traveling Salesman Problem (TSP), Minimum Spanning Tree (MST), and Optimal Control Problem (OCP). Simulations were conducted in MATLAB, comparing processing time, uncovered areas, path length, and traversal time. Results indicate that OCP is preferable when traversal time is constrained, although it incurs significantly higher computational costs. Conversely, MST-based approaches provide faster but less optimal solutions. These findings offer insights into selecting appropriate algorithms based on mission priorities, balancing efficiency and computational feasibility.", "AI": {"tldr": "本文研究了水下滑翔机的覆盖路径规划策略，比较了TSP、MST和OCP三种方法，发现OCP在时间受限时更优，但计算成本高；MST则更快但效果较差。", "motivation": "提升水下滑翔机在放射性源探测任务中的效率，同时确保安全导航。", "method": "评估了TSP、MST和OCP三种路径规划方法，通过MATLAB仿真比较处理时间、未覆盖区域、路径长度和遍历时间。", "result": "OCP在时间受限时表现最佳，但计算成本高；MST速度快但效果较差。", "conclusion": "根据任务优先级选择算法，平衡效率和计算可行性。"}}
{"id": "2506.15146", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15146", "abs": "https://arxiv.org/abs/2506.15146", "authors": ["Masaki Murooka", "Takahiro Hoshi", "Kensuke Fukumitsu", "Shimpei Masuda", "Marwan Hamze", "Tomoya Sasaki", "Mitsuharu Morisawa", "Eiichi Yoshida"], "title": "TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality", "comment": null, "summary": "Manipulation with whole-body contact by humanoid robots offers distinct advantages, including enhanced stability and reduced load. On the other hand, we need to address challenges such as the increased computational cost of motion generation and the difficulty of measuring broad-area contact. We therefore have developed a humanoid control system that allows a humanoid robot equipped with tactile sensors on its upper body to learn a policy for whole-body manipulation through imitation learning based on human teleoperation data. This policy, named tactile-modality extended ACT (TACT), has a feature to take multiple sensor modalities as input, including joint position, vision, and tactile measurements. Furthermore, by integrating this policy with retargeting and locomotion control based on a biped model, we demonstrate that the life-size humanoid robot RHP7 Kaleido is capable of achieving whole-body contact manipulation while maintaining balance and walking. Through detailed experimental verification, we show that inputting both vision and tactile modalities into the policy contributes to improving the robustness of manipulation involving broad and delicate contact.", "AI": {"tldr": "论文提出了一种名为TACT的控制系统，通过模仿学习人类远程操作数据，使人形机器人能够进行全身接触操作，并结合视觉和触觉输入提高操作鲁棒性。", "motivation": "解决人形机器人在全身接触操作中面临的高计算成本和广泛接触测量困难的问题。", "method": "开发了一种基于模仿学习的控制系统TACT，整合了关节位置、视觉和触觉输入，并结合双足模型实现平衡和行走。", "result": "实验验证表明，结合视觉和触觉输入能显著提高涉及广泛和精细接触的操作鲁棒性。", "conclusion": "TACT系统成功实现了人形机器人的全身接触操作，同时保持了平衡和行走能力。"}}
{"id": "2506.14856", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14856", "abs": "https://arxiv.org/abs/2506.14856", "authors": ["Zhengquan Zhang", "Feng Xu", "Mengmi Zhang"], "title": "Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction", "comment": "9 pages, 3 figures in the main text. Under review for NeurIPS 2025", "summary": "Some perspectives naturally provide more information than others. How can an AI system determine which viewpoint offers the most valuable insight for accurate and efficient 3D object reconstruction? Active view selection (AVS) for 3D reconstruction remains a fundamental challenge in computer vision. The aim is to identify the minimal set of views that yields the most accurate 3D reconstruction. Instead of learning radiance fields, like NeRF or 3D Gaussian Splatting, from a current observation and computing uncertainty for each candidate viewpoint, we introduce a novel AVS approach guided by neural uncertainty maps predicted by a lightweight feedforward deep neural network, named UPNet. UPNet takes a single input image of a 3D object and outputs a predicted uncertainty map, representing uncertainty values across all possible candidate viewpoints. By leveraging heuristics derived from observing many natural objects and their associated uncertainty patterns, we train UPNet to learn a direct mapping from viewpoint appearance to uncertainty in the underlying volumetric representations. Next, our approach aggregates all previously predicted neural uncertainty maps to suppress redundant candidate viewpoints and effectively select the most informative one. Using these selected viewpoints, we train 3D neural rendering models and evaluate the quality of novel view synthesis against other competitive AVS methods. Remarkably, despite using half of the viewpoints than the upper bound, our method achieves comparable reconstruction accuracy. In addition, it significantly reduces computational overhead during AVS, achieving up to a 400 times speedup along with over 50\\% reductions in CPU, RAM, and GPU usage compared to baseline methods. Notably, our approach generalizes effectively to AVS tasks involving novel object categories, without requiring any additional training.", "AI": {"tldr": "论文提出了一种基于神经不确定性预测的主动视角选择方法（UPNet），用于高效3D重建，显著减少计算开销并保持高精度。", "motivation": "解决3D重建中主动视角选择（AVS）的挑战，旨在用最少的视角实现高精度重建，同时降低计算成本。", "method": "使用轻量级前馈神经网络UPNet预测视角不确定性，通过聚合不确定性图选择最有信息量的视角，并训练3D神经渲染模型。", "result": "仅用一半视角即可达到与上限相当的精度，计算速度提升400倍，资源消耗减少50%以上，且无需额外训练即可泛化到新物体类别。", "conclusion": "UPNet方法在3D重建中实现了高效且高精度的视角选择，具有显著的计算优势和应用泛化能力。"}}
{"id": "2506.14808", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14808", "abs": "https://arxiv.org/abs/2506.14808", "authors": ["Jenny Schmalfuss", "Nadine Chang", "Vibashan VS", "Maying Shen", "Andres Bruhn", "Jose M. Alvarez"], "title": "PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models", "comment": "Accepted to CVPR 2025", "summary": "Vision language models (VLMs) respond to user-crafted text prompts and visual inputs, and are applied to numerous real-world problems. VLMs integrate visual modalities with large language models (LLMs), which are well known to be prompt-sensitive. Hence, it is crucial to determine whether VLMs inherit this instability to varying prompts. We therefore investigate which prompt variations VLMs are most sensitive to and which VLMs are most agnostic to prompt variations. To this end, we introduce PARC (Prompt Analysis via Reliability and Calibration), a VLM prompt sensitivity analysis framework built on three pillars: (1) plausible prompt variations in both the language and vision domain, (2) a novel model reliability score with built-in guarantees, and (3) a calibration step that enables dataset- and prompt-spanning prompt variation analysis. Regarding prompt variations, PARC's evaluation shows that VLMs mirror LLM language prompt sensitivity in the vision domain, and most destructive variations change the expected answer. Regarding models, outstandingly robust VLMs among 22 evaluated models come from the InternVL2 family. We further find indications that prompt sensitivity is linked to training data. The code will be at https://github.com/NVlabs/PARC.", "AI": {"tldr": "PARC框架分析视觉语言模型（VLM）对提示变化的敏感性，发现VLM继承了LLM的语言提示敏感性，并识别出InternVL2家族模型表现最稳健。", "motivation": "研究VLM是否继承了LLM对提示变化的敏感性，并探究哪些VLM对提示变化最不敏感。", "method": "提出PARC框架，基于语言和视觉领域的合理提示变化、新型可靠性评分和校准步骤，分析VLM的提示敏感性。", "result": "VLM在视觉领域表现出与LLM相似的语言提示敏感性，InternVL2家族模型表现最稳健，提示敏感性与训练数据相关。", "conclusion": "PARC为VLM提示敏感性提供了系统分析工具，揭示了模型稳健性与训练数据的关系。"}}
{"id": "2506.15332", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15332", "abs": "https://arxiv.org/abs/2506.15332", "authors": ["Patricia Diaz"], "title": "Building Blocks of a User Experience Research Point of View", "comment": null, "summary": "This paper presents three User Experience Research (UXR) perspectives based on data, evidence and insights - known as Point of View (POV) - showcasing how the strategies and methods of building a POV work in an enterprise setting. The POV are: 1. Smart Visuals: Use AI to extract and translate text from visuals in videos (2019). 2. Assessable Code Editor: Focus on direct AI-feedback to the learner as it is the loop that requires the least effort for the highest impact(2023). 3. Opportunity Landscape: Identify high-impact opportunities at the intersection of emergent technical capabilities that unlock novel approaches to critical user needs while addressing business strategic priorities (2019). They all seemed far-fetched and went against common practice. All were adopted and had long-lasting impact.", "AI": {"tldr": "论文提出了三种基于数据、证据和洞察的用户体验研究（UXR）视角（POV），展示了在企业环境中构建POV的策略和方法。这三种POV均具有创新性且被成功采纳，产生了持久影响。", "motivation": "探索如何通过数据驱动的POV在企业环境中实现创新，并验证这些看似不切实际的方法的实际效果。", "method": "提出了三种POV：1. 智能视觉（2019年）；2. 可评估代码编辑器（2023年）；3. 机会图谱（2019年），并通过企业实践验证其有效性。", "result": "尽管这些POV看似不切实际且违背常规做法，但均被采纳并产生了持久影响。", "conclusion": "数据驱动的POV策略在企业环境中具有创新潜力，能够实现高影响力的解决方案。"}}
{"id": "2506.14903", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14903", "abs": "https://arxiv.org/abs/2506.14903", "authors": ["Renjith Prasad", "Abhilekh Borah", "Hasnat Md Abdullah", "Chathurangi Shyalika", "Gurpreet Singh", "Ritvik Garimella", "Rajarshi Roy", "Harshul Surana", "Nasrin Imanpour", "Suranjana Trivedy", "Amit Sheth", "Amitava Das"], "title": "DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization", "comment": "59 pages, 10 figures", "summary": "Alignment is crucial for text-to-image (T2I) models to ensure that generated images faithfully capture user intent while maintaining safety and fairness. Direct Preference Optimization (DPO), prominent in large language models (LLMs), is extending its influence to T2I systems. This paper introduces DPO-Kernels for T2I models, a novel extension enhancing alignment across three dimensions: (i) Hybrid Loss, integrating embedding-based objectives with traditional probability-based loss for improved optimization; (ii) Kernelized Representations, employing Radial Basis Function (RBF), Polynomial, and Wavelet kernels for richer feature transformations and better separation between safe and unsafe inputs; and (iii) Divergence Selection, expanding beyond DPO's default Kullback-Leibler (KL) regularizer by incorporating Wasserstein and R'enyi divergences for enhanced stability and robustness. We introduce DETONATE, the first large-scale benchmark of its kind, comprising approximately 100K curated image pairs categorized as chosen and rejected. DETONATE encapsulates three axes of social bias and discrimination: Race, Gender, and Disability. Prompts are sourced from hate speech datasets, with images generated by leading T2I models including Stable Diffusion 3.5 Large, Stable Diffusion XL, and Midjourney. Additionally, we propose the Alignment Quality Index (AQI), a novel geometric measure quantifying latent-space separability of safe/unsafe image activations, revealing hidden vulnerabilities. Empirically, we demonstrate that DPO-Kernels maintain strong generalization bounds via Heavy-Tailed Self-Regularization (HT-SR). DETONATE and complete code are publicly released.", "AI": {"tldr": "本文提出了一种名为DPO-Kernels的新方法，用于增强文本到图像（T2I）模型的对齐能力，通过混合损失、核化表示和发散选择三个维度优化模型。同时，作者发布了首个大规模基准测试DETONATE和新的对齐质量指标AQI。", "motivation": "确保T2I模型生成的图像准确反映用户意图，同时保持安全性和公平性，是当前研究的重点。本文旨在通过扩展直接偏好优化（DPO）方法，提升T2I模型的对齐能力。", "method": "提出DPO-Kernels方法，包括混合损失、核化表示（RBF、多项式和小波核）和发散选择（Wasserstein和R'enyi发散）。此外，发布了DETONATE基准测试和AQI指标。", "result": "实验表明，DPO-Kernels通过重尾自正则化（HT-SR）保持了强大的泛化能力。DETONATE基准测试包含10万张图像对，涵盖种族、性别和残疾三个社会偏见维度。", "conclusion": "DPO-Kernels在提升T2I模型对齐能力方面表现出色，同时DETONATE和AQI为未来研究提供了重要工具。"}}
{"id": "2506.14810", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14810", "abs": "https://arxiv.org/abs/2506.14810", "authors": ["Qiwen Zhang"], "title": "Intelligent Routing for Sparse Demand Forecasting: A Comparative Evaluation of Selection Strategies", "comment": "7 pages, 4 figures, conference", "summary": "Sparse and intermittent demand forecasting in supply chains presents a critical challenge, as frequent zero-demand periods hinder traditional model accuracy and impact inventory management. We propose and evaluate a Model-Router framework that dynamically selects the most suitable forecasting model-spanning classical, ML, and DL methods for each product based on its unique demand pattern. By comparing rule-based, LightGBM, and InceptionTime routers, our approach learns to assign appropriate forecasting strategies, effectively differentiating between smooth, lumpy, or intermittent demand regimes to optimize predictions. Experiments on the large-scale Favorita dataset show our deep learning (Inception Time) router improves forecasting accuracy by up to 11.8% (NWRMSLE) over strong, single-model benchmarks with 4.67x faster inference time. Ultimately, these gains in forecasting precision will drive substantial reductions in both stockouts and wasteful excess inventory, underscoring the critical role of intelligent, adaptive Al in optimizing contemporary supply chain operations.", "AI": {"tldr": "提出了一种动态选择预测模型的框架（Model-Router），针对供应链中稀疏和间歇性需求问题，显著提升了预测精度和效率。", "motivation": "传统模型在频繁零需求场景下准确性不足，影响库存管理，需一种自适应方法应对不同需求模式。", "method": "采用Model-Router框架，结合规则、LightGBM和InceptionTime路由器，动态分配最适合的预测模型。", "result": "在大规模Favorita数据集上，InceptionTime路由器将预测精度提升11.8%，推理速度加快4.67倍。", "conclusion": "智能自适应框架显著优化供应链预测，减少缺货和库存浪费，突显AI在供应链中的关键作用。"}}
{"id": "2506.15468", "categories": ["cs.HC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15468", "abs": "https://arxiv.org/abs/2506.15468", "authors": ["Ryota Okumura", "Tadahiro Taniguchi", "Akira Taniguchi", "Yoshinobu Hagiwara"], "title": "Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI", "comment": null, "summary": "We propose co-creative learning as a novel paradigm where humans and AI, i.e., biological and artificial agents, mutually integrate their partial perceptual information and knowledge to construct shared external representations, a process we interpret as symbol emergence. Unlike traditional AI teaching based on unilateral knowledge transfer, this addresses the challenge of integrating information from inherently different modalities. We empirically test this framework using a human-AI interaction model based on the Metropolis-Hastings naming game (MHNG), a decentralized Bayesian inference mechanism. In an online experiment, 69 participants played a joint attention naming game (JA-NG) with one of three computer agent types (MH-based, always-accept, or always-reject) under partial observability. Results show that human-AI pairs with an MH-based agent significantly improved categorization accuracy through interaction and achieved stronger convergence toward a shared sign system. Furthermore, human acceptance behavior aligned closely with the MH-derived acceptance probability. These findings provide the first empirical evidence for co-creative learning emerging in human-AI dyads via MHNG-based interaction. This suggests a promising path toward symbiotic AI systems that learn with humans, rather than from them, by dynamically aligning perceptual experiences, opening a new venue for symbiotic AI alignment.", "AI": {"tldr": "论文提出了一种新的共创造学习范式，通过人类与AI的互动整合部分感知信息与知识，构建共享外部表征。实验基于Metropolis-Hastings命名游戏（MHNG），结果显示MH-based代理显著提升了分类准确性，并实现了更强的符号系统共享。", "motivation": "解决传统AI教学中单向知识传递的局限性，探索如何整合不同模态的信息。", "method": "采用基于MHNG的人机交互模型，通过在线实验（69名参与者）测试三种计算机代理类型（MH-based、always-accept、always-reject）在部分可观测性下的表现。", "result": "MH-based代理显著提升了分类准确性，人类接受行为与MHNG的接受概率高度一致。", "conclusion": "共创造学习通过MHNG互动在人机对中首次得到实证支持，为共生AI系统提供了新方向。"}}
{"id": "2506.15157", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15157", "abs": "https://arxiv.org/abs/2506.15157", "authors": ["Hanbit Oh", "Andrea M. Salcedo-Vázquez", "Ixchel G. Ramirez-Alpizar", "Yukiyasu Domae"], "title": "Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation", "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025 accepted", "summary": "Imitation learning (IL) aims to enable robots to perform tasks autonomously by observing a few human demonstrations. Recently, a variant of IL, called In-Context IL, utilized off-the-shelf large language models (LLMs) as instant policies that understand the context from a few given demonstrations to perform a new task, rather than explicitly updating network models with large-scale demonstrations. However, its reliability in the robotics domain is undermined by hallucination issues such as LLM-based instant policy, which occasionally generates poor trajectories that deviate from the given demonstrations. To alleviate this problem, we propose a new robust in-context imitation learning algorithm called the robust instant policy (RIP), which utilizes a Student's t-regression model to be robust against the hallucinated trajectories of instant policies to allow reliable trajectory generation. Specifically, RIP generates several candidate robot trajectories to complete a given task from an LLM and aggregates them using the Student's t-distribution, which is beneficial for ignoring outliers (i.e., hallucinations); thereby, a robust trajectory against hallucinations is generated. Our experiments, conducted in both simulated and real-world environments, show that RIP significantly outperforms state-of-the-art IL methods, with at least $26\\%$ improvement in task success rates, particularly in low-data scenarios for everyday tasks. Video results available at https://sites.google.com/view/robustinstantpolicy.", "AI": {"tldr": "论文提出了一种名为RIP的鲁棒上下文模仿学习算法，通过使用Student's t回归模型来减少LLM生成的幻觉轨迹，显著提高了任务成功率。", "motivation": "解决现有基于LLM的即时策略在机器人领域中因幻觉问题导致的不可靠性。", "method": "利用Student's t分布聚合LLM生成的候选轨迹，忽略异常值（幻觉），生成鲁棒轨迹。", "result": "在模拟和真实环境中，RIP显著优于现有方法，任务成功率至少提高26%。", "conclusion": "RIP通过鲁棒性设计有效解决了LLM的幻觉问题，提升了模仿学习的可靠性。"}}
{"id": "2506.14907", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14907", "abs": "https://arxiv.org/abs/2506.14907", "authors": ["Yizhen Zhang", "Yang Ding", "Shuoshuo Zhang", "Xinchen Zhang", "Haoling Li", "Zhong-zhi Li", "Peijie Wang", "Jie Wu", "Lei Ji", "Yelong Shen", "Yujiu Yang", "Yeyun Gong"], "title": "PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning", "comment": null, "summary": "Inspired by the impressive reasoning capabilities demonstrated by reinforcement learning approaches like DeepSeek-R1, recent emerging research has begun exploring the use of reinforcement learning (RL) to enhance vision-language models (VLMs) for multimodal reasoning tasks. However, most existing multimodal reinforcement learning approaches remain limited to spatial reasoning within single-image contexts, yet still struggle to generalize to more complex and real-world scenarios involving multi-image positional reasoning, where understanding the relationships across images is crucial. To address this challenge, we propose a general reinforcement learning approach PeRL tailored for interleaved multimodal tasks, and a multi-stage strategy designed to enhance the exploration-exploitation trade-off, thereby improving learning efficiency and task performance. Specifically, we introduce permutation of image sequences to simulate varied positional relationships to explore more spatial and positional diversity. Furthermore, we design a rollout filtering mechanism for resampling to focus on trajectories that contribute most to learning optimal behaviors to exploit learned policies effectively. We evaluate our model on 5 widely-used multi-image benchmarks and 3 single-image benchmarks. Our experiments confirm that PeRL trained model consistently surpasses R1-related and interleaved VLM baselines by a large margin, achieving state-of-the-art performance on multi-image benchmarks, while preserving comparable performance on single-image tasks.", "AI": {"tldr": "论文提出了一种名为PeRL的强化学习方法，专注于多图像位置推理任务，通过多阶段策略和图像序列排列提升学习效率和性能。", "motivation": "现有多模态强化学习方法局限于单图像空间推理，难以处理多图像位置关系的复杂场景。", "method": "提出PeRL方法，包括图像序列排列和多阶段策略，引入rollout过滤机制以优化学习轨迹。", "result": "在5个多图像基准和3个单图像基准上，PeRL显著优于现有方法，达到最先进性能。", "conclusion": "PeRL在多图像任务中表现优异，同时在单图像任务中保持竞争力。"}}
{"id": "2506.14811", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14811", "abs": "https://arxiv.org/abs/2506.14811", "authors": ["Mikel Malagón", "Josu Ceberio", "Jose A. Lozano"], "title": "Self-Composing Policies for Scalable Continual Reinforcement Learning", "comment": "ICML 2024 (oral)", "summary": "This work introduces a growable and modular neural network architecture that naturally avoids catastrophic forgetting and interference in continual reinforcement learning. The structure of each module allows the selective combination of previous policies along with its internal policy, accelerating the learning process on the current task. Unlike previous growing neural network approaches, we show that the number of parameters of the proposed approach grows linearly with respect to the number of tasks, and does not sacrifice plasticity to scale. Experiments conducted in benchmark continuous control and visual problems reveal that the proposed approach achieves greater knowledge transfer and performance than alternative methods.", "AI": {"tldr": "提出一种可扩展的模块化神经网络架构，避免持续强化学习中的灾难性遗忘和干扰，参数数量随任务线性增长。", "motivation": "解决持续强化学习中灾难性遗忘和干扰的问题，同时保持模型的扩展性和可塑性。", "method": "采用模块化设计，选择性结合历史策略与内部策略，参数数量线性增长。", "result": "在连续控制和视觉任务中表现优于其他方法，实现更好的知识迁移和性能。", "conclusion": "该方法在持续强化学习中具有高效性和扩展性，优于现有技术。"}}
{"id": "2506.15497", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15497", "abs": "https://arxiv.org/abs/2506.15497", "authors": ["Changzeng Fu"], "title": "Foundation of Affective Computing and Interaction", "comment": null, "summary": "This book provides a comprehensive exploration of affective computing and human-computer interaction technologies. It begins with the historical development and basic concepts of human-computer interaction, delving into the technical frameworks and practical applications of emotional computing, visual interaction, voice interaction, brain-computer interfaces, physiological electrical signal analysis, and social robotics. The book covers a wide range of topics, including the psychological and neuroscience foundations of emotion, multimodal emotion recognition, emotional expression mechanisms, and the principles of brain-computer interfaces.\n  Key technologies such as affective computing based on discrete emotion theory and dimensional models, visual perception principles, speech recognition and synthesis, EEG signal acquisition and processing, and multimodal emotion recognition are explained in detail. This book also addresses the technical challenges in the field, including multimodal data fusion, privacy and security, and ethical considerations in human-machine relationships. It discusses the applications of these technologies across various domains such as education, healthcare, entertainment, and intelligent assistance.\n  Looking to the future, the book anticipates trends such as the deep integration of artificial intelligence with emotion recognition, the advancement of multimodal interaction technologies, and the development of more personalized and adaptive emotion recognition systems. It emphasizes the importance of balancing technological innovation with ethical considerations to ensure the responsible development and application of affective computing technologies.", "AI": {"tldr": "本书全面探讨了情感计算与人机交互技术，涵盖历史发展、技术框架、实际应用及未来趋势，强调技术创新与伦理平衡。", "motivation": "探索情感计算与人机交互的多领域应用，解决技术挑战并推动未来发展。", "method": "详细解析情感计算、视觉交互、语音交互、脑机接口等技术，结合心理学与神经科学基础。", "result": "介绍了情感识别的关键技术、多模态数据融合及实际应用，展望了AI与情感识别的深度融合。", "conclusion": "未来需平衡技术创新与伦理，推动情感计算技术的负责任发展与应用。"}}
{"id": "2506.15175", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15175", "abs": "https://arxiv.org/abs/2506.15175", "authors": ["Hanjun Kim", "Minwoo Jung", "Wooseong Yang", "Ayoung Kim"], "title": "SHeRLoc: Synchronized Heterogeneous Radar Place Recognition for Cross-Modal Localization", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Despite the growing adoption of radar in robotics, the majority of research has been confined to homogeneous sensor types, overlooking the integration and cross-modality challenges inherent in heterogeneous radar technologies. This leads to significant difficulties in generalizing across diverse radar data types, with modality-aware approaches that could leverage the complementary strengths of heterogeneous radar remaining unexplored. To bridge these gaps, we propose SHeRLoc, the first deep network tailored for heterogeneous radar, which utilizes RCS polar matching to align multimodal radar data. Our hierarchical optimal transport-based feature aggregation method generates rotationally robust multi-scale descriptors. By employing FFT-similarity-based data mining and adaptive margin-based triplet loss, SHeRLoc enables FOV-aware metric learning. SHeRLoc achieves an order of magnitude improvement in heterogeneous radar place recognition, increasing recall@1 from below 0.1 to 0.9 on a public dataset and outperforming state of-the-art methods. Also applicable to LiDAR, SHeRLoc paves the way for cross-modal place recognition and heterogeneous sensor SLAM. The source code will be available upon acceptance.", "AI": {"tldr": "SHeRLoc是首个针对异构雷达设计的深度网络，通过RCS极坐标匹配和多尺度特征聚合，显著提升了异构雷达位置识别的性能。", "motivation": "现有研究多局限于同质雷达，忽视了异构雷达的集成和跨模态挑战，导致难以泛化到多样雷达数据类型。", "method": "采用RCS极坐标匹配对齐多模态雷达数据，基于分层最优传输的特征聚合方法生成旋转鲁棒的多尺度描述符，并通过FFT相似性数据挖掘和自适应边界三元组损失实现FOV感知度量学习。", "result": "在公开数据集上，SHeRLoc将异构雷达位置识别的recall@1从低于0.1提升至0.9，性能优于现有方法。", "conclusion": "SHeRLoc不仅适用于雷达，还可推广到LiDAR，为跨模态位置识别和异构传感器SLAM开辟了新途径。"}}
{"id": "2506.14919", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14919", "abs": "https://arxiv.org/abs/2506.14919", "authors": ["Xinkai Zhao", "Yuta Tokuoka", "Junichiro Iwasawa", "Keita Oda"], "title": "Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models", "comment": null, "summary": "The increasing use of diffusion models for image generation, especially in sensitive areas like medical imaging, has raised significant privacy concerns. Membership Inference Attack (MIA) has emerged as a potential approach to determine if a specific image was used to train a diffusion model, thus quantifying privacy risks. Existing MIA methods often rely on diffusion reconstruction errors, where member images are expected to have lower reconstruction errors than non-member images. However, applying these methods directly to medical images faces challenges. Reconstruction error is influenced by inherent image difficulty, and diffusion models struggle with high-frequency detail reconstruction. To address these issues, we propose a Frequency-Calibrated Reconstruction Error (FCRE) method for MIAs on medical image diffusion models. By focusing on reconstruction errors within a specific mid-frequency range and excluding both high-frequency (difficult to reconstruct) and low-frequency (less informative) regions, our frequency-selective approach mitigates the confounding factor of inherent image difficulty. Specifically, we analyze the reverse diffusion process, obtain the mid-frequency reconstruction error, and compute the structural similarity index score between the reconstructed and original images. Membership is determined by comparing this score to a threshold. Experiments on several medical image datasets demonstrate that our FCRE method outperforms existing MIA methods.", "AI": {"tldr": "提出了一种针对医学图像扩散模型的频率校准重建误差（FCRE）方法，通过聚焦中频区域重建误差，解决了现有MIA方法在医学图像中的局限性。", "motivation": "扩散模型在医学图像等敏感领域的应用引发了隐私问题，现有MIA方法因图像固有难度和高频细节重建困难而效果不佳。", "method": "提出FCRE方法，通过分析反向扩散过程，计算中频重建误差和结构相似性指数，确定成员资格。", "result": "实验表明FCRE方法在多个医学图像数据集上优于现有MIA方法。", "conclusion": "FCRE方法有效解决了医学图像扩散模型的隐私风险量化问题。"}}
{"id": "2506.14813", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14813", "abs": "https://arxiv.org/abs/2506.14813", "authors": ["Yuxuan Jiang", "Ziming Zhou", "Boyu Xu", "Beijie Liu", "Runhui Xu", "Peng Huang"], "title": "Training with Confidence: Catching Silent Errors in Deep Learning Training with Automated Proactive Checks", "comment": "19 pages, to appear in 19th USENIX Symposium on Operating Systems Design and Implementation (OSDI '25)", "summary": "Training deep learning (DL) models is a complex process, making it prone to silent errors that are challenging to detect and diagnose. This paper presents TRAINCHECK, a framework that takes a proactive checking approach to address silent training errors. TRAINCHECK automatically infers invariants tailored for DL training. It uses these invariants to proactively detect silent errors during the training process while providing debugging help. To evaluate TRAINCHECK, we reproduce 20 real-world silent training errors with diverse root causes. TRAINCHECK successfully detects 18 errors within a single training iteration. It also uncovers 6 unknown bugs in popular training libraries that lead to silent errors.", "AI": {"tldr": "TRAINCHECK是一个主动检测深度学习训练中静默错误的框架，通过推断定制化不变量并实时检测错误，成功识别了多种真实错误和未知漏洞。", "motivation": "深度学习训练过程复杂且易出现难以检测的静默错误，需要一种主动检测和诊断的方法。", "method": "TRAINCHECK自动推断适用于深度学习训练的不变量，并利用这些不变量在训练过程中主动检测静默错误，同时提供调试支持。", "result": "在复现的20种真实静默错误中，TRAINCHECK成功检测到18种，并在一次训练迭代内完成；还发现了6个导致静默错误的未知训练库漏洞。", "conclusion": "TRAINCHECK能有效检测和诊断深度学习训练中的静默错误，具有实际应用价值。"}}
{"id": "2506.15512", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15512", "abs": "https://arxiv.org/abs/2506.15512", "authors": ["Wenqi Guan", "Yang Fang"], "title": "Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach", "comment": null, "summary": "Large Language Models have brought a radical change in the process of remote learning students, among other aspects of educative activities. Current retrieval of remote learning resources lacks depth in contextual meaning that provides comprehensive information on complex student queries. This work proposes a novel approach to enhancing remote learning retrieval by integrating GPT-based models within the LangChain framework. We achieve this system in a more intuitive and productive manner using CoT reasoning and prompt engineering. The framework we propose puts much emphasis on increasing the precision and relevance of the retrieval results to return comprehensive and contextually enriched explanations and resources that best suit each student's needs. We also assess the effectiveness of our approach against paradigmatic LLMs and report improvements in user satisfaction and learning outcomes.", "AI": {"tldr": "论文提出了一种基于GPT模型和LangChain框架的新方法，通过CoT推理和提示工程提升远程学习资源检索的深度和相关性。", "motivation": "当前远程学习资源检索缺乏对复杂查询的上下文深度理解，无法满足学生需求。", "method": "整合GPT模型与LangChain框架，利用CoT推理和提示工程技术优化检索系统。", "result": "提升了检索结果的精确性和相关性，改善了用户满意度和学习效果。", "conclusion": "该方法为远程学习资源检索提供了一种更高效、个性化的解决方案。"}}
{"id": "2506.15249", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15249", "abs": "https://arxiv.org/abs/2506.15249", "authors": ["Lucas Schulze", "Jan Peters", "Oleg Arenz"], "title": "Context-Aware Deep Lagrangian Networks for Model Predictive Control", "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025", "summary": "Controlling a robot based on physics-informed dynamic models, such as deep Lagrangian networks (DeLaN), can improve the generalizability and interpretability of the resulting behavior. However, in complex environments, the number of objects to potentially interact with is vast, and their physical properties are often uncertain. This complexity makes it infeasible to employ a single global model. Therefore, we need to resort to online system identification of context-aware models that capture only the currently relevant aspects of the environment. While physical principles such as the conservation of energy may not hold across varying contexts, ensuring physical plausibility for any individual context-aware model can still be highly desirable, particularly when using it for receding horizon control methods such as Model Predictive Control (MPC). Hence, in this work, we extend DeLaN to make it context-aware, combine it with a recurrent network for online system identification, and integrate it with a MPC for adaptive, physics-informed control. We also combine DeLaN with a residual dynamics model to leverage the fact that a nominal model of the robot is typically available. We evaluate our method on a 7-DOF robot arm for trajectory tracking under varying loads. Our method reduces the end-effector tracking error by 39%, compared to a 21% improvement achieved by a baseline that uses an extended Kalman filter.", "AI": {"tldr": "论文提出了一种基于上下文感知的深度拉格朗日网络（DeLaN）方法，结合在线系统识别和模型预测控制（MPC），用于复杂环境中的机器人自适应控制。", "motivation": "在复杂环境中，全局物理模型难以应对大量不确定的交互对象，因此需要上下文感知的局部模型来提升控制的适应性和物理合理性。", "method": "扩展DeLaN为上下文感知模型，结合递归网络进行在线系统识别，并与MPC集成；同时引入残差动力学模型以利用机器人名义模型。", "result": "在7自由度机械臂的轨迹跟踪实验中，该方法将末端执行器跟踪误差降低了39%，优于基线方法的21%改进。", "conclusion": "上下文感知的DeLaN结合MPC和残差模型，显著提升了复杂环境下机器人控制的性能和适应性。"}}
{"id": "2506.14934", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14934", "abs": "https://arxiv.org/abs/2506.14934", "authors": ["Md Abrar Jahin", "Shahriar Soudeep", "Arian Rahman Aditta", "M. F. Mridha", "Nafiz Fahad", "Md. Jakir Hossen"], "title": "Vision Transformers for End-to-End Quark-Gluon Jet Classification from Calorimeter Images", "comment": "Accepted in Third International Workshop on Generalizing from Limited Resources in the Open World Workshop at International Joint Conference on Artificial Intelligence (IJCAI) 2025", "summary": "Distinguishing between quark- and gluon-initiated jets is a critical and challenging task in high-energy physics, pivotal for improving new physics searches and precision measurements at the Large Hadron Collider. While deep learning, particularly Convolutional Neural Networks (CNNs), has advanced jet tagging using image-based representations, the potential of Vision Transformer (ViT) architectures, renowned for modeling global contextual information, remains largely underexplored for direct calorimeter image analysis, especially under realistic detector and pileup conditions. This paper presents a systematic evaluation of ViTs and ViT-CNN hybrid models for quark-gluon jet classification using simulated 2012 CMS Open Data. We construct multi-channel jet-view images from detector-level energy deposits (ECAL, HCAL) and reconstructed tracks, enabling an end-to-end learning approach. Our comprehensive benchmarking demonstrates that ViT-based models, notably ViT+MaxViT and ViT+ConvNeXt hybrids, consistently outperform established CNN baselines in F1-score, ROC-AUC, and accuracy, highlighting the advantage of capturing long-range spatial correlations within jet substructure. This work establishes the first systematic framework and robust performance baselines for applying ViT architectures to calorimeter image-based jet classification using public collider data, alongside a structured dataset suitable for further deep learning research in this domain.", "AI": {"tldr": "该论文系统评估了Vision Transformer (ViT)及其与CNN混合模型在夸克-胶子喷注分类中的表现，发现ViT模型在性能上优于传统CNN方法。", "motivation": "区分夸克和胶子喷注是高能物理中的关键挑战，对大型强子对撞机的新物理搜索和精确测量至关重要。尽管CNN已用于喷注标记，但ViT的潜力尚未充分探索。", "method": "使用模拟的2012年CMS公开数据，构建多通道喷注图像（ECAL、HCAL和重建轨迹），并评估ViT和ViT-CNN混合模型的性能。", "result": "ViT模型（尤其是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上均优于CNN基线。", "conclusion": "该研究为ViT在基于量能器图像的喷注分类中提供了首个系统框架和性能基准，并提供了适合进一步深度学习研究的数据集。"}}
{"id": "2506.14815", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14815", "abs": "https://arxiv.org/abs/2506.14815", "authors": ["Gyaneshwar Agrahari", "Kiran Bist", "Monika Pandey", "Jacob Kapita", "Zachary James", "Jackson Knox", "Steven Heymsfield", "Sophia Ramirez", "Peter Wolenski", "Nadejda Drenska"], "title": "Predicting Anthropometric Body Composition Variables Using 3D Optical Imaging and Machine Learning", "comment": null, "summary": "Accurate prediction of anthropometric body composition variables, such as Appendicular Lean Mass (ALM), Body Fat Percentage (BFP), and Bone Mineral Density (BMD), is essential for early diagnosis of several chronic diseases. Currently, researchers rely on Dual-Energy X-ray Absorptiometry (DXA) scans to measure these metrics; however, DXA scans are costly and time-consuming. This work proposes an alternative to DXA scans by applying statistical and machine learning models on biomarkers (height, volume, left calf circumference, etc) obtained from 3D optical images. The dataset consists of 847 patients and was sourced from Pennington Biomedical Research Center. Extracting patients' data in healthcare faces many technical challenges and legal restrictions. However, most supervised machine learning algorithms are inherently data-intensive, requiring a large amount of training data. To overcome these limitations, we implemented a semi-supervised model, the $p$-Laplacian regression model. This paper is the first to demonstrate the application of a $p$-Laplacian model for regression. Our $p$-Laplacian model yielded errors of $\\sim13\\%$ for ALM, $\\sim10\\%$ for BMD, and $\\sim20\\%$ for BFP when the training data accounted for 10 percent of all data. Among the supervised algorithms we implemented, Support Vector Regression (SVR) performed the best for ALM and BMD, yielding errors of $\\sim 8\\%$ for both, while Least Squares SVR performed the best for BFP with $\\sim 11\\%$ error when trained on 80 percent of the data. Our findings position the $p$-Laplacian model as a promising tool for healthcare applications, particularly in a data-constrained environment.", "AI": {"tldr": "论文提出了一种基于3D光学图像生物标志物的半监督$p$-Laplacian回归模型，用于预测人体组成变量（如ALM、BFP和BMD），在数据受限环境下表现优于传统监督方法。", "motivation": "DXA扫描成本高且耗时，而传统监督学习需要大量数据，但医疗数据获取面临技术和法律限制，因此需要一种数据高效的方法。", "method": "使用3D光学图像提取生物标志物，并首次应用$p$-Laplacian回归模型进行预测，同时对比了SVR等监督算法。", "result": "$p$-Laplacian模型在10%训练数据下误差为ALM 13%、BMD 10%、BFP 20%；SVR在80%数据下表现最佳（ALM和BMD误差8%，BFP误差11%）。", "conclusion": "$p$-Laplacian模型在数据受限的医疗场景中具有潜力，为DXA扫描提供了一种低成本替代方案。"}}
{"id": "2506.15525", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15525", "abs": "https://arxiv.org/abs/2506.15525", "authors": ["Isabella Pu", "Prerna Ravi", "Linh Dieu Dinh", "Chelsea Joe", "Caitlin Ogoe", "Zixuan Li", "Cynthia Breazeal", "Anastasia K. Ostrowski"], "title": "\"How can we learn and use AI at the same time?:: Participatory Design of GenAI with High School Students", "comment": "Copyright protected by ACM, 17 pages, 5 figures, 2 tables, in proceedings of 24th annual ACM Interaction Design and Children Conference (IDC 2025)", "summary": "As generative AI (GenAI) emerges as a transformative force, clear understanding of high school students' perspectives is essential for GenAI's meaningful integration in high school environments. In this work, we draw insights from a participatory design workshop where we engaged 17 high school students -- a group rarely involved in prior research in this area -- through the design of novel GenAI tools and school policies addressing their key concerns. Students identified challenges and developed solutions outlining their ideal features in GenAI tools, appropriate school use, and regulations. These centered around the problem spaces of combating bias & misinformation, tackling crime & plagiarism, preventing over-reliance on AI, and handling false accusations of academic dishonesty. Building on our participants' underrepresented perspectives, we propose new guidelines targeted at educational technology designers for development of GenAI technologies in high schools. We also argue for further incorporation of student voices in development of AI policies in their schools.", "AI": {"tldr": "研究通过参与式设计工作坊了解高中生对生成式AI（GenAI）的看法，提出针对教育技术设计者的新指南，并呼吁在AI政策制定中更多融入学生声音。", "motivation": "生成式AI（GenAI）正在成为变革性力量，了解高中生对其的看法对GenAI在高中的有效整合至关重要。", "method": "通过参与式设计工作坊，与17名高中生合作设计GenAI工具和学校政策，解决其核心关切。", "result": "学生提出了GenAI工具的理想功能、学校使用规范及法规建议，重点关注偏见与虚假信息、犯罪与抄袭、过度依赖AI及学术不端误判等问题。", "conclusion": "研究提出了针对教育技术设计者的新指南，并强调在AI政策制定中应更多纳入学生视角。"}}
{"id": "2506.15343", "categories": ["cs.RO", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15343", "abs": "https://arxiv.org/abs/2506.15343", "authors": ["Víctor Mayoral-Vilches"], "title": "Offensive Robot Cybersecurity", "comment": "Doctoral thesis", "summary": "Offensive Robot Cybersecurity introduces a groundbreaking approach by advocating for offensive security methods empowered by means of automation. It emphasizes the necessity of understanding attackers' tactics and identifying vulnerabilities in advance to develop effective defenses, thereby improving robots' security posture. This thesis leverages a decade of robotics experience, employing Machine Learning and Game Theory to streamline the vulnerability identification and exploitation process. Intrinsically, the thesis uncovers a profound connection between robotic architecture and cybersecurity, highlighting that the design and creation aspect of robotics deeply intertwines with its protection against attacks. This duality -- whereby the architecture that shapes robot behavior and capabilities also necessitates a defense mechanism through offensive and defensive cybersecurity strategies -- creates a unique equilibrium. Approaching cybersecurity with a dual perspective of defense and attack, rooted in an understanding of systems architecture, has been pivotal. Through comprehensive analysis, including ethical considerations, the development of security tools, and executing cyber attacks on robot software, hardware, and industry deployments, this thesis proposes a novel architecture for cybersecurity cognitive engines. These engines, powered by advanced game theory and machine learning, pave the way for autonomous offensive cybersecurity strategies for robots, marking a significant shift towards self-defending robotic systems. This research not only underscores the importance of offensive measures in enhancing robot cybersecurity but also sets the stage for future advancements where robots are not just resilient to cyber threats but are equipped to autonomously safeguard themselves.", "AI": {"tldr": "论文提出了一种通过自动化支持的进攻性安全方法，强调通过理解攻击者战术和提前识别漏洞来提升机器人安全性。", "motivation": "机器人安全性问题日益突出，传统防御方法不足以应对复杂攻击，需结合进攻性策略。", "method": "结合机器学习和博弈论，优化漏洞识别与利用流程，提出新型网络安全认知引擎架构。", "result": "开发出能自主执行进攻性安全策略的机器人系统，显著提升其防御能力。", "conclusion": "进攻性安全策略对机器人安全至关重要，未来可推动自主防御机器人的发展。"}}
{"id": "2506.14980", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14980", "abs": "https://arxiv.org/abs/2506.14980", "authors": ["Ziteng Li", "Malte Kuhlmann", "Ilana Nisky", "Nicolás Navarro-Guerrero"], "title": "Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors", "comment": "Accepted in the IEEE International Conference on Development and Learning (ICDL). The paper contains 8 pages and 7 figures", "summary": "Compliance is a critical parameter for describing objects in engineering, agriculture, and biomedical applications. Traditional compliance detection methods are limited by their lack of portability and scalability, rely on specialized, often expensive equipment, and are unsuitable for robotic applications. Moreover, existing neural network-based approaches using vision-based tactile sensors still suffer from insufficient prediction accuracy. In this paper, we propose two models based on Long-term Recurrent Convolutional Networks (LRCNs) and Transformer architectures that leverage RGB tactile images and other information captured by the vision-based sensor GelSight to predict compliance metrics accurately. We validate the performance of these models using multiple metrics and demonstrate their effectiveness in accurately estimating compliance. The proposed models exhibit significant performance improvement over the baseline. Additionally, we investigated the correlation between sensor compliance and object compliance estimation, which revealed that objects that are harder than the sensor are more challenging to estimate.", "AI": {"tldr": "论文提出了基于LRCN和Transformer的模型，利用RGB触觉图像和GelSight传感器数据，显著提升了合规性预测的准确性。", "motivation": "传统合规性检测方法缺乏便携性和可扩展性，且依赖昂贵设备；现有基于视觉触觉传感器的神经网络方法预测精度不足。", "method": "使用LRCN和Transformer架构，结合RGB触觉图像和GelSight传感器数据，预测合规性指标。", "result": "模型在多个指标上表现优于基线，显著提升了合规性估计的准确性；发现传感器与物体硬度相关性影响估计难度。", "conclusion": "提出的模型有效解决了合规性预测问题，但硬物体估计仍具挑战性。"}}
{"id": "2506.14821", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14821", "abs": "https://arxiv.org/abs/2506.14821", "authors": ["Sunil Kumar", "Bowen Zhao", "Leo Dirac", "Paulina Varshavskaya"], "title": "Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints", "comment": null, "summary": "Despite tremendous recent advances in large model reasoning ability, vision-language models (VLMs) still struggle with detailed visual reasoning, especially when compute resources are limited. To address this challenge, we draw inspiration from methods like Deepseek-r1 for VLMs and train smaller-scale models with Group Relative Policy Optimization (GRPO) to use external tools such as zoom. The greatest benefit is obtained with a combination of GRPO learning, a simple reward structure, a simplified tool-calling interface, allocating additional tokens to the result of the tool call, and a training data mix that over-represents visually difficult examples. Compared to similarly-sized baseline models, our method achieves better performance on some visual question-answering (VQA) tasks, thanks to the detailed visual information gathered from the external tool.", "AI": {"tldr": "论文提出了一种结合GRPO训练和小规模视觉语言模型的方法，通过外部工具（如缩放）提升视觉推理能力，在资源有限时表现优于基线模型。", "motivation": "解决视觉语言模型在资源有限时难以进行详细视觉推理的问题。", "method": "使用Group Relative Policy Optimization（GRPO）训练小规模模型，结合简单奖励结构、简化工具调用接口、额外分配工具调用结果令牌，以及侧重视觉难度高的训练数据。", "result": "在部分视觉问答任务中，该方法优于类似规模的基线模型。", "conclusion": "结合GRPO和外部工具的方法能有效提升小规模视觉语言模型的视觉推理能力。"}}
{"id": "2506.15010", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15010", "abs": "https://arxiv.org/abs/2506.15010", "authors": ["Yijun Lin", "Yao-Yi Chiang"], "title": "Hyper-Local Deformable Transformers for Text Spotting on Historical Maps", "comment": "Published in KDD2024", "summary": "Text on historical maps contains valuable information providing georeferenced historical, political, and cultural contexts. However, text extraction from historical maps is challenging due to the lack of (1) effective methods and (2) training data. Previous approaches use ad-hoc steps tailored to only specific map styles. Recent machine learning-based text spotters (e.g., for scene images) have the potential to solve these challenges because of their flexibility in supporting various types of text instances. However, these methods remain challenges in extracting precise image features for predicting every sub-component (boundary points and characters) in a text instance. This is critical because map text can be lengthy and highly rotated with complex backgrounds, posing difficulties in detecting relevant image features from a rough text region. This paper proposes PALETTE, an end-to-end text spotter for scanned historical maps of a wide variety. PALETTE introduces a novel hyper-local sampling module to explicitly learn localized image features around the target boundary points and characters of a text instance for detection and recognition. PALETTE also enables hyper-local positional embeddings to learn spatial interactions between boundary points and characters within and across text instances. In addition, this paper presents a novel approach to automatically generate synthetic map images, SynthMap+, for training text spotters for historical maps. The experiment shows that PALETTE with SynthMap+ outperforms SOTA text spotters on two new benchmark datasets of historical maps, particularly for long and angled text. We have deployed PALETTE with SynthMap+ to process over 60,000 maps in the David Rumsey Historical Map collection and generated over 100 million text labels to support map searching. The project is released at https://github.com/kartta-foundation/mapkurator-palette-doc.", "AI": {"tldr": "PALETTE是一种端到端文本识别器，专为历史地图设计，通过超局部采样模块和合成数据训练，显著提升了长文本和旋转文本的识别效果。", "motivation": "历史地图中的文本信息具有重要价值，但现有方法难以处理其多样性和复杂性，尤其是长文本和旋转文本。", "method": "提出PALETTE，引入超局部采样模块学习局部图像特征，并结合超局部位置嵌入；开发SynthMap+自动生成合成数据用于训练。", "result": "PALETTE在历史地图数据集上优于现有方法，已成功处理6万张地图并生成1亿多文本标签。", "conclusion": "PALETTE和SynthMap+为历史地图文本识别提供了高效解决方案，支持大规模地图搜索。"}}
{"id": "2506.14824", "categories": ["cs.LG", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.14824", "abs": "https://arxiv.org/abs/2506.14824", "authors": ["Yao Zhang", "Hewei Gao", "Haokun Chen", "Weiguo Li", "Yunpu Ma", "Volker Tresp"], "title": "FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models", "comment": "12 pages, 3 figures", "summary": "Multimodal Large Language Models (MLLMs) excel in tasks like multimodal reasoning and cross-modal retrieval but face deployment challenges in real-world scenarios due to distributed multimodal data and strict privacy requirements. Federated Learning (FL) offers a solution by enabling collaborative model training without centralizing data. However, realizing FL for MLLMs presents significant challenges, including high computational demands, limited client capacity, substantial communication costs, and heterogeneous client data. Existing FL methods assume client-side deployment of full models, an assumption that breaks down for large-scale MLLMs due to their massive size and communication demands. To address these limitations, we propose FedNano, the first FL framework that centralizes the LLM on the server while introducing NanoEdge, a lightweight module for client-specific adaptation. NanoEdge employs modality-specific encoders, connectors, and trainable NanoAdapters with low-rank adaptation. This design eliminates the need to deploy LLM on clients, reducing client-side storage by 95%, and limiting communication overhead to only 0.01% of the model parameters. By transmitting only compact NanoAdapter updates, FedNano handles heterogeneous client data and resource constraints while preserving privacy. Experiments demonstrate that FedNano outperforms prior FL baselines, bridging the gap between MLLM scale and FL feasibility, and enabling scalable, decentralized multimodal AI systems.", "AI": {"tldr": "FedNano是一种联邦学习框架，通过集中大型语言模型（LLM）在服务器端，并引入轻量级模块NanoEdge，解决了多模态大语言模型（MLLM）在联邦学习中的部署挑战。", "motivation": "多模态大语言模型（MLLM）在真实场景中面临分布式数据和隐私问题，而传统联邦学习方法因模型规模和通信成本难以适用。", "method": "FedNano框架在服务器端集中LLM，客户端仅部署轻量级模块NanoEdge，包含模态特定编码器、连接器和低秩适配器，大幅减少存储和通信开销。", "result": "实验表明，FedNano显著优于现有联邦学习方法，客户端存储减少95%，通信开销仅为模型参数的0.01%。", "conclusion": "FedNano填补了MLLM规模与联邦学习可行性之间的鸿沟，为可扩展、去中心化的多模态AI系统提供了解决方案。"}}
{"id": "2506.15380", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15380", "abs": "https://arxiv.org/abs/2506.15380", "authors": ["Taegeun Yang", "Jiwoo Hwang", "Jeil Jeong", "Minsung Yoon", "Sung-Eui Yoon"], "title": "Efficient Navigation Among Movable Obstacles using a Mobile Manipulator via Hierarchical Policy Learning", "comment": "8 pages, 6 figures, Accepted to IROS 2025. Supplementary Video: https://youtu.be/sZ8_z7sYVP0", "summary": "We propose a hierarchical reinforcement learning (HRL) framework for efficient Navigation Among Movable Obstacles (NAMO) using a mobile manipulator. Our approach combines interaction-based obstacle property estimation with structured pushing strategies, facilitating the dynamic manipulation of unforeseen obstacles while adhering to a pre-planned global path. The high-level policy generates pushing commands that consider environmental constraints and path-tracking objectives, while the low-level policy precisely and stably executes these commands through coordinated whole-body movements. Comprehensive simulation-based experiments demonstrate improvements in performing NAMO tasks, including higher success rates, shortened traversed path length, and reduced goal-reaching times, compared to baselines. Additionally, ablation studies assess the efficacy of each component, while a qualitative analysis further validates the accuracy and reliability of the real-time obstacle property estimation.", "AI": {"tldr": "提出了一种分层强化学习框架，用于移动机械臂在动态障碍物环境中的高效导航，结合障碍物属性估计与结构化推动策略，显著提升了任务成功率与效率。", "motivation": "解决移动机械臂在动态障碍物环境中的导航问题，特别是需要实时估计障碍物属性并动态调整路径的情况。", "method": "采用分层强化学习框架，高层策略生成考虑环境约束的推动指令，低层策略通过全身协调运动精确执行指令。", "result": "仿真实验显示，该方法在任务成功率、路径长度和到达时间上优于基线方法，并通过消融实验验证了各组件的重要性。", "conclusion": "该框架有效解决了动态障碍物环境中的导航问题，具有较高的实用性和可靠性。"}}
{"id": "2506.15033", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15033", "abs": "https://arxiv.org/abs/2506.15033", "authors": ["Gary Song Yan", "Yusen Zhang", "Jinyu Zhao", "Hao Zhang", "Zhangping Yang", "Guanye Xiong", "Yanfei Liu", "Tao Zhang", "Yujie He", "Siyuan Tian", "Yao Gou", "Min Li"], "title": "Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?", "comment": null, "summary": "In this pioneering study, we introduce StyleWallfacer, a groundbreaking unified training and inference framework, which not only addresses various issues encountered in the style transfer process of traditional methods but also unifies the framework for different tasks. This framework is designed to revolutionize the field by enabling artist level style transfer and text driven stylization. First, we propose a semantic-based style injection method that uses BLIP to generate text descriptions strictly aligned with the semantics of the style image in CLIP space. By leveraging a large language model to remove style-related descriptions from these descriptions, we create a semantic gap. This gap is then used to fine-tune the model, enabling efficient and drift-free injection of style knowledge. Second, we propose a data augmentation strategy based on human feedback, incorporating high-quality samples generated early in the fine-tuning process into the training set to facilitate progressive learning and significantly reduce its overfitting. Finally, we design a training-free triple diffusion process using the fine-tuned model, which manipulates the features of self-attention layers in a manner similar to the cross-attention mechanism. Specifically, in the generation process, the key and value of the content-related process are replaced with those of the style-related process to inject style while maintaining text control over the model. We also introduce query preservation to mitigate disruptions to the original content. Under such a design, we have achieved high-quality image-driven style transfer and text-driven stylization, delivering artist-level style transfer results while preserving the original image content. Moreover, we achieve image color editing during the style transfer process for the first time.", "AI": {"tldr": "StyleWallfacer是一个统一的训练和推理框架，解决了传统风格迁移方法的问题，支持艺术家级风格迁移和文本驱动风格化。通过语义风格注入、数据增强策略和无训练的三重扩散过程，实现了高质量的风格迁移和内容保留。", "motivation": "传统风格迁移方法存在多种问题，如风格注入不精确、内容失真等。本文旨在提出一个统一的框架，解决这些问题并实现更高质量的风格迁移和文本驱动风格化。", "method": "1. 提出基于语义的风格注入方法，利用BLIP生成与风格图像语义严格对齐的文本描述，并通过大语言模型移除风格相关描述，形成语义间隙以微调模型。2. 设计基于人类反馈的数据增强策略，将高质量样本加入训练集以减少过拟合。3. 提出无训练的三重扩散过程，通过替换自注意力层的键和值实现风格注入，同时保留文本控制。", "result": "实现了高质量的图像驱动风格迁移和文本驱动风格化，保留了原始图像内容，并首次在风格迁移过程中实现了图像颜色编辑。", "conclusion": "StyleWallfacer框架在风格迁移领域取得了突破性进展，为艺术家级风格迁移和文本驱动风格化提供了高效且统一的解决方案。"}}
{"id": "2506.14828", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2506.14828", "abs": "https://arxiv.org/abs/2506.14828", "authors": ["Sk Md Ahnaf Akif Alvi", "Mrinalini Mulukutla", "Nicolas Flores", "Danial Khatamsaz", "Jan Janssen", "Danny Perez", "Douglas Allaire", "Vahid Attari", "Raymundo Arroyave"], "title": "Accurate and Uncertainty-Aware Multi-Task Prediction of HEA Properties Using Prior-Guided Deep Gaussian Processes", "comment": "Deep Gaussian Processes Multi-task Gaussian Processes High Entropy Alloys", "summary": "Surrogate modeling techniques have become indispensable in accelerating the discovery and optimization of high-entropy alloys(HEAs), especially when integrating computational predictions with sparse experimental observations. This study systematically evaluates the fitting performance of four prominent surrogate models conventional Gaussian Processes(cGP), Deep Gaussian Processes(DGP), encoder-decoder neural networks for multi-output regression and XGBoost applied to a hybrid dataset of experimental and computational properties in the AlCoCrCuFeMnNiV HEA system. We specifically assess their capabilities in predicting correlated material properties, including yield strength, hardness, modulus, ultimate tensile strength, elongation, and average hardness under dynamic and quasi-static conditions, alongside auxiliary computational properties. The comparison highlights the strengths of hierarchical and deep modeling approaches in handling heteroscedastic, heterotopic, and incomplete data commonly encountered in materials informatics. Our findings illustrate that DGP infused with machine learning-based prior outperform other surrogates by effectively capturing inter-property correlations and input-dependent uncertainty. This enhanced predictive accuracy positions advanced surrogate models as powerful tools for robust and data-efficient materials design.", "AI": {"tldr": "该研究评估了四种替代模型在高熵合金（HEAs）中的性能，发现深度高斯过程（DGP）在预测相关材料性能时表现最佳。", "motivation": "高熵合金的发现和优化需要高效的替代模型，以整合计算预测和稀疏实验数据。", "method": "系统评估了四种替代模型（cGP、DGP、编码器-解码器神经网络和XGBoost）在AlCoCrCuFeMnNiV HEA系统中的性能。", "result": "DGP在捕捉属性间相关性和输入依赖性不确定性方面优于其他模型。", "conclusion": "先进的替代模型（如DGP）是高效材料设计的强大工具。"}}
{"id": "2506.15402", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15402", "abs": "https://arxiv.org/abs/2506.15402", "authors": ["Miaoxin Pan", "Jinnan Li", "Yaowen Zhang", "Yi Yang", "Yufeng Yue"], "title": "MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System", "comment": null, "summary": "Object-level SLAM offers structured and semantically meaningful environment representations, making it more interpretable and suitable for high-level robotic tasks. However, most existing approaches rely on RGB-D sensors or monocular views, which suffer from narrow fields of view, occlusion sensitivity, and limited depth perception-especially in large-scale or outdoor environments. These limitations often restrict the system to observing only partial views of objects from limited perspectives, leading to inaccurate object modeling and unreliable data association. In this work, we propose MCOO-SLAM, a novel Multi-Camera Omnidirectional Object SLAM system that fully leverages surround-view camera configurations to achieve robust, consistent, and semantically enriched mapping in complex outdoor scenarios. Our approach integrates point features and object-level landmarks enhanced with open-vocabulary semantics. A semantic-geometric-temporal fusion strategy is introduced for robust object association across multiple views, leading to improved consistency and accurate object modeling, and an omnidirectional loop closure module is designed to enable viewpoint-invariant place recognition using scene-level descriptors. Furthermore, the constructed map is abstracted into a hierarchical 3D scene graph to support downstream reasoning tasks. Extensive experiments in real-world demonstrate that MCOO-SLAM achieves accurate localization and scalable object-level mapping with improved robustness to occlusion, pose variation, and environmental complexity.", "AI": {"tldr": "MCOO-SLAM是一种多相机全向物体SLAM系统，利用环绕视角相机配置，在复杂户外场景中实现鲁棒、一致且语义丰富的建图。", "motivation": "现有SLAM方法依赖RGB-D或单目相机，视野窄、易受遮挡且深度感知有限，导致物体建模不准确和数据关联不可靠。", "method": "结合点特征和物体级地标，引入语义-几何-时间融合策略，设计全向闭环模块，并构建分层3D场景图。", "result": "在真实场景中验证，MCOO-SLAM实现了高精度定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强鲁棒性。", "conclusion": "MCOO-SLAM通过多相机全向配置和语义增强，显著提升了复杂户外场景中的SLAM性能。"}}
{"id": "2506.15078", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15078", "abs": "https://arxiv.org/abs/2506.15078", "authors": ["Xianghong Fang", "Litao Guo", "Hengchao Chen", "Yuxuan Zhang", "XiaofanXia", "Dingjie Song", "Yexin Liu", "Hao Wang", "Harry Yang", "Yuan Yuan", "Qiang Sun"], "title": "Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study", "comment": null, "summary": "The success of autoregressive models largely depends on the effectiveness of vector quantization, a technique that discretizes continuous features by mapping them to the nearest code vectors within a learnable codebook. Two critical issues in existing vector quantization methods are training instability and codebook collapse. Training instability arises from the gradient discrepancy introduced by the straight-through estimator, especially in the presence of significant quantization errors, while codebook collapse occurs when only a small subset of code vectors are utilized during training. A closer examination of these issues reveals that they are primarily driven by a mismatch between the distributions of the features and code vectors, leading to unrepresentative code vectors and significant data information loss during compression. To address this, we employ the Wasserstein distance to align these two distributions, achieving near 100\\% codebook utilization and significantly reducing the quantization error. Both empirical and theoretical analyses validate the effectiveness of the proposed approach.", "AI": {"tldr": "论文提出了一种基于Wasserstein距离的向量量化方法，解决了现有方法中的训练不稳定和码本崩溃问题，显著提升了码本利用率和量化效果。", "motivation": "现有向量量化方法存在训练不稳定和码本崩溃问题，主要源于特征与码向量分布不匹配，导致信息损失。", "method": "采用Wasserstein距离对齐特征与码向量的分布，优化量化过程。", "result": "实验和理论分析表明，该方法实现了接近100%的码本利用率，并显著降低了量化误差。", "conclusion": "通过分布对齐，该方法有效解决了向量量化中的关键问题，提升了模型性能。"}}
{"id": "2506.14830", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.14830", "abs": "https://arxiv.org/abs/2506.14830", "authors": ["Zhizhao Wen", "Ruoxin Zhang", "Chao Wang"], "title": "Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model", "comment": "Source code available; Accepted by 2025 6th International Conference on Electronic Communication and Artificial Intelligence; 5 pages; 7 figures", "summary": "Aiming at the critical role of SSD health state prediction in data reliability assurance, this study proposes a hybrid BiGRU-MHA model that incorporates a multi-head attention mechanism to enhance the accuracy and stability of storage device health classification. The model innovatively integrates temporal feature extraction and key information focusing capabilities. Specifically, it leverages the bidirectional timing modeling advantages of the BiGRU network to capture both forward and backward dependencies of SSD degradation features. Simultaneously, the multi-head attention mechanism dynamically assigns feature weights, improving the model's sensitivity to critical health indicators. Experimental results show that the proposed model achieves classification accuracies of 92.70% on the training set and 92.44% on the test set, with a minimal performance gap of only 0.26%, demonstrating excellent generalization ability. Further analysis using the receiver operating characteristic (ROC) curve shows an area under the curve (AUC) of 0.94 on the test set, confirming the model's robust binary classification performance. This work not only presents a new technical approach for SSD health prediction but also addresses the generalization bottleneck of traditional models, offering a verifiable method with practical value for preventive maintenance of industrial-grade storage systems. The results show the model can significantly reduce data loss risks by providing early failure warnings and help optimize maintenance costs, supporting intelligent decision-making in building reliable storage systems for cloud computing data centers and edge storage environments.", "AI": {"tldr": "本文提出了一种结合双向GRU和多头注意力机制的混合模型（BiGRU-MHA），用于SSD健康状态预测，显著提高了分类准确性和稳定性。", "motivation": "SSD健康状态预测对数据可靠性至关重要，传统模型存在泛化能力不足的问题，需要更准确和稳定的方法。", "method": "模型结合BiGRU的双向时序建模和多头注意力机制，动态分配特征权重，捕捉SSD退化特征的关键信息。", "result": "实验结果显示，模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，AUC为0.94，泛化能力优异。", "conclusion": "该模型为SSD健康预测提供了新方法，可显著降低数据丢失风险，优化维护成本，适用于云数据中心和边缘存储环境。"}}
{"id": "2506.15450", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15450", "abs": "https://arxiv.org/abs/2506.15450", "authors": ["Kun Liu", "Junhao Xiao", "Hao Lin", "Yue Cao", "Hui Peng", "Kaihong Huang", "Huimin Lu"], "title": "SurfAAV: Design and Implementation of a Novel Multimodal Surfing Aquatic-Aerial Vehicle", "comment": null, "summary": "Despite significant advancements in the research of aquatic-aerial robots, existing configurations struggle to efficiently perform underwater, surface, and aerial movement simultaneously. In this paper, we propose a novel multimodal surfing aquatic-aerial vehicle, SurfAAV, which efficiently integrates underwater navigation, surface gliding, and aerial flying capabilities. Thanks to the design of the novel differential thrust vectoring hydrofoil, SurfAAV can achieve efficient surface gliding and underwater navigation without the need for a buoyancy adjustment system. This design provides flexible operational capabilities for both surface and underwater tasks, enabling the robot to quickly carry out underwater monitoring activities. Additionally, when it is necessary to reach another water body, SurfAAV can switch to aerial mode through a gliding takeoff, flying to the target water area to perform corresponding tasks. The main contribution of this letter lies in proposing a new solution for underwater, surface, and aerial movement, designing a novel hybrid prototype concept, developing the required control laws, and validating the robot's ability to successfully perform surface gliding and gliding takeoff. SurfAAV achieves a maximum surface gliding speed of 7.96 m/s and a maximum underwater speed of 3.1 m/s. The prototype's surface gliding maneuverability and underwater cruising maneuverability both exceed those of existing aquatic-aerial vehicles.", "AI": {"tldr": "提出了一种新型多模态冲浪水空两栖机器人SurfAAV，集成了水下、水面和空中运动能力，通过差分推力矢量水翼设计实现高效运动，无需浮力调节系统。", "motivation": "现有水空两栖机器人难以同时高效完成水下、水面和空中运动，需要一种更灵活的解决方案。", "method": "设计了差分推力矢量水翼，开发了控制算法，验证了水面滑行和滑翔起飞能力。", "result": "SurfAAV水面滑行速度达7.96 m/s，水下速度达3.1 m/s，性能优于现有水空两栖机器人。", "conclusion": "SurfAAV为水下、水面和空中运动提供了新解决方案，具有高效和灵活的操作能力。"}}
{"id": "2506.15153", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15153", "abs": "https://arxiv.org/abs/2506.15153", "authors": ["Yufei Liu", "Haoke Xiao", "Jiaxing Chai", "Yongcun Zhang", "Rong Wang", "Zijie Meng", "Zhiming Luo"], "title": "SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts", "comment": null, "summary": "The advent of Large Vision Models (LVMs) offers new opportunities for few-shot medical image segmentation. However, existing training-free methods based on LVMs fail to effectively utilize negative prompts, leading to poor performance on low-contrast medical images. To address this issue, we propose SynPo, a training-free few-shot method based on LVMs (e.g., SAM), with the core insight: improving the quality of negative prompts. To select point prompts in a more reliable confidence map, we design a novel Confidence Map Synergy Module by combining the strengths of DINOv2 and SAM. Based on the confidence map, we select the top-k pixels as the positive points set and choose the negative points set using a Gaussian distribution, followed by independent K-means clustering for both sets. Then, these selected points are leveraged as high-quality prompts for SAM to get the segmentation results. Extensive experiments demonstrate that SynPo achieves performance comparable to state-of-the-art training-based few-shot methods.", "AI": {"tldr": "SynPo是一种基于大型视觉模型（如SAM）的无训练少样本医学图像分割方法，通过改进负提示质量提升性能。", "motivation": "现有基于LVMs的无训练方法未能有效利用负提示，导致在低对比度医学图像上表现不佳。", "method": "设计置信度图协同模块，结合DINOv2和SAM的优势，选择高质量正负点提示，用于SAM分割。", "result": "在实验中，SynPo性能接近最先进的基于训练的方法。", "conclusion": "SynPo通过优化提示选择，显著提升了无训练少样本医学图像分割的效果。"}}
{"id": "2506.14843", "categories": ["cs.LG", "cs.CV", "stat.AP"], "pdf": "https://arxiv.org/pdf/2506.14843", "abs": "https://arxiv.org/abs/2506.14843", "authors": ["Luca Gherardini", "Imre Lengyel", "Tunde Peto", "Caroline C. W. Klaverd", "Magda A. Meester-Smoord", "Johanna Maria Colijnd", "EYE-RISK Consortium", "E3 Consortium", "Jose Sousa"], "title": "CACTUS as a Reliable Tool for Early Classification of Age-related Macular Degeneration", "comment": null, "summary": "Machine Learning (ML) is used to tackle various tasks, such as disease classification and prediction. The effectiveness of ML models relies heavily on having large amounts of complete data. However, healthcare data is often limited or incomplete, which can hinder model performance. Additionally, issues like the trustworthiness of solutions vary with the datasets used. The lack of transparency in some ML models further complicates their understanding and use. In healthcare, particularly in the case of Age-related Macular Degeneration (AMD), which affects millions of older adults, early diagnosis is crucial due to the absence of effective treatments for reversing progression. Diagnosing AMD involves assessing retinal images along with patients' symptom reports. There is a need for classification approaches that consider genetic, dietary, clinical, and demographic factors. Recently, we introduced the -Comprehensive Abstraction and Classification Tool for Uncovering Structures-(CACTUS), aimed at improving AMD stage classification. CACTUS offers explainability and flexibility, outperforming standard ML models. It enhances decision-making by identifying key factors and providing confidence in its results. The important features identified by CACTUS allow us to compare with existing medical knowledge. By eliminating less relevant or biased data, we created a clinical scenario for clinicians to offer feedback and address biases.", "AI": {"tldr": "论文提出了一种名为CACTUS的工具，用于改进年龄相关性黄斑变性（AMD）的分期分类，解决了医疗数据不完整和模型透明度不足的问题。", "motivation": "医疗数据通常有限或不完整，且机器学习模型的透明度和可信度存在问题，尤其是在AMD的早期诊断中，需要综合考虑多种因素。", "method": "开发了CACTUS工具，结合遗传、饮食、临床和人口统计学因素进行分类，提供可解释性和灵活性。", "result": "CACTUS在AMD分期分类中优于标准机器学习模型，能识别关键因素并提供可信结果。", "conclusion": "CACTUS通过消除不相关或有偏见的数据，为临床决策提供了支持，并允许与现有医学知识进行比较。"}}
{"id": "2506.15518", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15518", "abs": "https://arxiv.org/abs/2506.15518", "authors": ["Giulio Delama", "Igor Borowski", "Roland Jung", "Stephan Weiss"], "title": "Real-Time Initialization of Unknown Anchors for UWB-aided Navigation", "comment": null, "summary": "This paper presents a framework for the real-time initialization of unknown Ultra-Wideband (UWB) anchors in UWB-aided navigation systems. The method is designed for localization solutions where UWB modules act as supplementary sensors. Our approach enables the automatic detection and calibration of previously unknown anchors during operation, removing the need for manual setup. By combining an online Positional Dilution of Precision (PDOP) estimation, a lightweight outlier detection method, and an adaptive robust kernel for non-linear optimization, our approach significantly improves robustness and suitability for real-world applications compared to state-of-the-art. In particular, we show that our metric which triggers an initialization decision is more conservative than current ones commonly based on initial linear or non-linear initialization guesses. This allows for better initialization geometry and subsequently lower initialization errors. We demonstrate the proposed approach on two different mobile robots: an autonomous forklift and a quadcopter equipped with a UWB-aided Visual-Inertial Odometry (VIO) framework. The results highlight the effectiveness of the proposed method with robust initialization and low positioning error. We open-source our code in a C++ library including a ROS wrapper.", "AI": {"tldr": "提出了一种实时初始化未知UWB锚点的框架，适用于UWB辅助导航系统，无需手动设置，通过在线PDOP估计、轻量级异常检测和自适应鲁棒核优化提升鲁棒性。", "motivation": "解决UWB辅助导航系统中未知锚点需手动初始化的问题，提升自动化和适应性。", "method": "结合在线PDOP估计、轻量级异常检测和自适应鲁棒核优化，实现自动检测和校准未知锚点。", "result": "在自主叉车和四旋翼机器人上验证，表现出鲁棒的初始化和低定位误差。", "conclusion": "方法显著优于现有技术，适用于实际应用，并开源了C++库和ROS封装。"}}
{"id": "2506.15160", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15160", "abs": "https://arxiv.org/abs/2506.15160", "authors": ["Jiaqi Shi", "Jin Xiao", "Xiaoguang Hu", "Boyang Song", "Hao Jiang", "Tianyou Chen", "Baochang Zhang"], "title": "Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation", "comment": "17 papes, 7 figures", "summary": "Point cloud analysis is the cornerstone of many downstream tasks, among which aggregating local structures is the basis for understanding point cloud data. While numerous works aggregate neighbor using three-dimensional relative coordinates, there are irrelevant point interference and feature hierarchy gap problems due to the limitation of local coordinates. Although some works address this limitation by refining spatial description though explicit modeling of cross-stage structure, these enhancement methods based on direct geometric structure encoding have problems of high computational overhead and noise sensitivity. To overcome these problems, we propose the Point Distribution Set Abstraction module (PDSA) that utilizes the correlation in the high-dimensional space to correct the feature distribution during aggregation, which improves the computational efficiency and robustness. PDSA distinguishes the point correlation based on a lightweight cross-stage structural descriptor, and enhances structural homogeneity by reducing the variance of the neighbor feature matrix and increasing classes separability though long-distance modeling. Additionally, we introducing a key point mechanism to optimize the computational overhead. The experimental result on semantic segmentation and classification tasks based on different baselines verify the generalization of the method we proposed, and achieve significant performance improvement with less parameter cost. The corresponding ablation and visualization results demonstrate the effectiveness and rationality of our method. The code and training weight is available at: https://github.com/AGENT9717/PointDistribution", "AI": {"tldr": "提出了一种名为PDSA的模块，通过高维空间相关性修正特征分布，解决了点云分析中局部坐标的局限性问题，提高了计算效率和鲁棒性。", "motivation": "点云分析中，局部坐标的局限性导致无关点干扰和特征层次差距问题，现有方法计算开销大且对噪声敏感。", "method": "PDSA模块利用高维空间相关性，通过轻量级跨阶段结构描述符区分点相关性，并通过减少邻居特征矩阵方差和长距离建模增强结构同质性。", "result": "在语义分割和分类任务中验证了方法的泛化性，性能显著提升且参数成本更低。", "conclusion": "PDSA模块有效解决了点云分析中的问题，实验和可视化结果证明了其有效性和合理性。"}}
{"id": "2506.14895", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14895", "abs": "https://arxiv.org/abs/2506.14895", "authors": ["Jenni Raitoharju"], "title": "Generalized Reference Kernel With Negative Samples For Support Vector One-class Classification", "comment": "Accepted to EUSIPCO2025", "summary": "This paper focuses on small-scale one-class classification with some negative samples available. We propose Generalized Reference Kernel with Negative Samples (GRKneg) for One-class Support Vector Machine (OC-SVM). We study different ways to select/generate the reference vectors and recommend an approach for the problem at hand. It is worth noting that the proposed method does not use any labels in the model optimization but uses the original OC-SVM implementation. Only the kernel used in the process is improved using the negative data. We compare our method with the standard OC-SVM and with the binary Support Vector Machine (SVM) using different amounts of negative samples. Our approach consistently outperforms the standard OC-SVM using Radial Basis Function kernel. When there are plenty of negative samples, the binary SVM outperforms the one-class approaches as expected, but we show that for the lowest numbers of negative samples the proposed approach clearly outperforms the binary SVM.", "AI": {"tldr": "论文提出了一种改进的OC-SVM方法GRKneg，利用少量负样本优化核函数，在小规模负样本情况下表现优于标准OC-SVM和二元SVM。", "motivation": "研究如何在小规模负样本情况下改进OC-SVM性能。", "method": "提出GRKneg方法，通过优化核函数利用负样本数据，无需标签优化模型。", "result": "GRKneg在少量负样本时优于标准OC-SVM和二元SVM。", "conclusion": "GRKneg是小规模负样本场景下OC-SVM的有效改进方法。"}}
{"id": "2506.15539", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15539", "abs": "https://arxiv.org/abs/2506.15539", "authors": ["Haoran Chen", "Weiliang Deng", "Biyu Ye", "Yifan Xiong", "Ximin Lyu"], "title": "Aerial Grasping via Maximizing Delta-Arm Workspace Utilization", "comment": "8 pages, 7 figures", "summary": "The workspace limits the operational capabilities and range of motion for the systems with robotic arms. Maximizing workspace utilization has the potential to provide more optimal solutions for aerial manipulation tasks, increasing the system's flexibility and operational efficiency. In this paper, we introduce a novel planning framework for aerial grasping that maximizes workspace utilization. We formulate an optimization problem to optimize the aerial manipulator's trajectory, incorporating task constraints to achieve efficient manipulation. To address the challenge of incorporating the delta arm's non-convex workspace into optimization constraints, we leverage a Multilayer Perceptron (MLP) to map position points to feasibility probabilities.Furthermore, we employ Reversible Residual Networks (RevNet) to approximate the complex forward kinematics of the delta arm, utilizing efficient model gradients to eliminate workspace constraints. We validate our methods in simulations and real-world experiments to demonstrate their effectiveness.", "AI": {"tldr": "提出了一种新型空中抓取规划框架，通过优化机械臂轨迹和利用MLP与RevNet技术，最大化工作空间利用率，提升操作效率和灵活性。", "motivation": "机械臂的工作空间限制了系统的操作能力和运动范围，最大化工作空间利用率可为空中操作任务提供更优解决方案。", "method": "引入优化问题规划机械臂轨迹，利用MLP映射非凸工作空间可行性，采用RevNet近似复杂正向运动学。", "result": "通过仿真和实际实验验证了方法的有效性。", "conclusion": "该框架显著提升了空中抓取任务的工作空间利用率和操作效率。"}}
{"id": "2506.15166", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15166", "abs": "https://arxiv.org/abs/2506.15166", "authors": ["Abdur Rahman", "Keerthiveena Balraj", "Manojkumar Ramteke", "Anurag Singh Rathore"], "title": "Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography", "comment": "Version of record published in Discover Applied Sciences (Springer Nature). The definitive article is available at https://doi.org/10.1007/s42452-025-07055-5", "summary": "Recent advancements in diffusion probabilistic models (DPMs) have revolutionized image processing, demonstrating significant potential in medical applications. Accurate segmentation of the left ventricle (LV) in echocardiograms is crucial for diagnostic procedures and necessary treatments. However, ultrasound images are notoriously noisy with low contrast and ambiguous LV boundaries, thereby complicating the segmentation process. To address these challenges, this paper introduces Echo-DND, a novel dual-noise diffusion model specifically designed for this task. Echo-DND leverages a unique combination of Gaussian and Bernoulli noises. It also incorporates a multi-scale fusion conditioning module to improve segmentation precision. Furthermore, it utilizes spatial coherence calibration to maintain spatial integrity in segmentation masks. The model's performance was rigorously validated on the CAMUS and EchoNet-Dynamic datasets. Extensive evaluations demonstrate that the proposed framework outperforms existing SOTA models. It achieves high Dice scores of 0.962 and 0.939 on these datasets, respectively. The proposed Echo-DND model establishes a new standard in echocardiogram segmentation, and its architecture holds promise for broader applicability in other medical imaging tasks, potentially improving diagnostic accuracy across various medical domains. Project page: https://abdur75648.github.io/Echo-DND", "AI": {"tldr": "Echo-DND是一种新型双噪声扩散模型，专为超声图像中左心室（LV）的精确分割设计，结合高斯和伯努利噪声，并引入多尺度融合条件和空间一致性校准，显著提升了分割精度。", "motivation": "超声图像噪声多、对比度低且LV边界模糊，传统分割方法效果不佳，因此需要一种更精确的分割模型。", "method": "Echo-DND结合高斯和伯努利噪声，采用多尺度融合模块和空间一致性校准，优化分割过程。", "result": "在CAMUS和EchoNet-Dynamic数据集上，Echo-DND的Dice分数分别达到0.962和0.939，优于现有SOTA模型。", "conclusion": "Echo-DND为超声图像分割设定了新标准，其架构有望扩展到其他医学影像任务，提升诊断准确性。"}}
{"id": "2506.14911", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.14911", "abs": "https://arxiv.org/abs/2506.14911", "authors": ["Ganyu Wang", "Boyu Wang", "Bin Gu", "Charles Ling"], "title": "Event-Driven Online Vertical Federated Learning", "comment": "Published as a conference paper at ICLR 2025", "summary": "Online learning is more adaptable to real-world scenarios in Vertical Federated Learning (VFL) compared to offline learning. However, integrating online learning into VFL presents challenges due to the unique nature of VFL, where clients possess non-intersecting feature sets for the same sample. In real-world scenarios, the clients may not receive data streaming for the disjoint features for the same entity synchronously. Instead, the data are typically generated by an \\emph{event} relevant to only a subset of clients. We are the first to identify these challenges in online VFL, which have been overlooked by previous research. To address these challenges, we proposed an event-driven online VFL framework. In this framework, only a subset of clients were activated during each event, while the remaining clients passively collaborated in the learning process. Furthermore, we incorporated \\emph{dynamic local regret (DLR)} into VFL to address the challenges posed by online learning problems with non-convex models within a non-stationary environment. We conducted a comprehensive regret analysis of our proposed framework, specifically examining the DLR under non-convex conditions with event-driven online VFL. Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.", "AI": {"tldr": "论文提出了一种事件驱动的在线垂直联邦学习（VFL）框架，解决了异步数据流和非凸模型在非平稳环境中的挑战，显著降低了通信和计算成本。", "motivation": "在线学习在VFL中更具适应性，但异步数据流和非凸模型的挑战未被前人研究充分解决。", "method": "提出事件驱动的在线VFL框架，仅激活部分客户端，并引入动态局部遗憾（DLR）处理非凸问题。", "result": "实验表明，该框架在非平稳数据下更稳定，同时显著降低了通信和计算成本。", "conclusion": "事件驱动的在线VFL框架有效解决了异步数据流和非凸模型的挑战，为实际应用提供了更优方案。"}}
{"id": "2506.15607", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15607", "abs": "https://arxiv.org/abs/2506.15607", "authors": ["Shailesh", "Alok Raj", "Nayan Kumar", "Priya Shukla", "Andrew Melnik", "Micheal Beetz", "Gora Chand Nandi"], "title": "GRIM: Task-Oriented Grasping with Conditioning on Generative Examples", "comment": null, "summary": "Task-Oriented Grasping (TOG) presents a significant challenge, requiring a nuanced understanding of task semantics, object affordances, and the functional constraints dictating how an object should be grasped for a specific task. To address these challenges, we introduce GRIM (Grasp Re-alignment via Iterative Matching), a novel training-free framework for task-oriented grasping. Initially, a coarse alignment strategy is developed using a combination of geometric cues and principal component analysis (PCA)-reduced DINO features for similarity scoring. Subsequently, the full grasp pose associated with the retrieved memory instance is transferred to the aligned scene object and further refined against a set of task-agnostic, geometrically stable grasps generated for the scene object, prioritizing task compatibility. In contrast to existing learning-based methods, GRIM demonstrates strong generalization capabilities, achieving robust performance with only a small number of conditioning examples.", "AI": {"tldr": "GRIM是一种无需训练的任务导向抓取框架，通过几何线索和PCA降维的DINO特征进行粗对齐，再通过任务无关的几何稳定抓取进行细化。", "motivation": "解决任务导向抓取中对任务语义、物体功能性和抓取功能约束的复杂理解需求。", "method": "结合几何线索和PCA降维的DINO特征进行粗对齐，再通过任务无关的几何稳定抓取进行细化。", "result": "GRIM展现出强大的泛化能力，仅需少量示例即可实现稳健性能。", "conclusion": "GRIM为任务导向抓取提供了一种高效且无需训练的新方法。"}}
{"id": "2506.15180", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15180", "abs": "https://arxiv.org/abs/2506.15180", "authors": ["Ziling Huang", "Yidan Zhang", "Shin'ichi Satoh"], "title": "ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections", "comment": null, "summary": "Large-scale visual search engines are expected to solve a dual problem at once: (i) locate every image that truly contains the object described by a sentence and (ii) identify the object's bounding box or exact pixels within each hit. Existing techniques address only one side of this challenge. Visual grounding yields tight boxes and masks but rests on the unrealistic assumption that the object is present in every test image, producing a flood of false alarms when applied to web-scale collections. Text-to-image retrieval excels at sifting through massive databases to rank relevant images, yet it stops at whole-image matches and offers no fine-grained localization. We introduce Referring Search and Discovery (ReSeDis), the first task that unifies corpus-level retrieval with pixel-level grounding. Given a free-form description, a ReSeDis model must decide whether the queried object appears in each image and, if so, where it is, returning bounding boxes or segmentation masks. To enable rigorous study, we curate a benchmark in which every description maps uniquely to object instances scattered across a large, diverse corpus, eliminating unintended matches. We further design a task-specific metric that jointly scores retrieval recall and localization precision. Finally, we provide a straightforward zero-shot baseline using a frozen vision-language model, revealing significant headroom for future study. ReSeDis offers a realistic, end-to-end testbed for building the next generation of robust and scalable multimodal search systems.", "AI": {"tldr": "ReSeDis统一了大规模视觉搜索中的检索与定位任务，提出了首个结合语料库级检索和像素级定位的任务，并设计了相应的基准和评估指标。", "motivation": "解决现有技术无法同时实现大规模图像检索和细粒度定位的问题，推动多模态搜索系统的发展。", "method": "引入ReSeDis任务，结合文本到图像检索和视觉定位，设计基准和评估指标，并提供一个零样本基线模型。", "result": "ReSeDis为构建稳健且可扩展的多模态搜索系统提供了实际测试平台，展示了未来研究的潜力。", "conclusion": "ReSeDis为下一代多模态搜索系统提供了统一的任务框架和评估标准，具有重要的研究价值。"}}
{"id": "2506.14929", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14929", "abs": "https://arxiv.org/abs/2506.14929", "authors": ["Ganyu Wang", "Jinjie Fang", "Maxwell J. Ying", "Bin Gu", "Xi Chen", "Boyu Wang", "Charles Ling"], "title": "FedOne: Query-Efficient Federated Learning for Black-box Discrete Prompt Learning", "comment": "Published in Proceedings of the 42nd International Conference on Machine Learning", "summary": "Black-Box Discrete Prompt Learning is a prompt-tuning method that optimizes discrete prompts without accessing model parameters or gradients, making the prompt tuning on a cloud-based Large Language Model (LLM) feasible. Adapting federated learning to BDPL could further enhance prompt tuning performance by leveraging data from diverse sources. However, all previous research on federated black-box prompt tuning had neglected the substantial query cost associated with the cloud-based LLM service. To address this gap, we conducted a theoretical analysis of query efficiency within the context of federated black-box prompt tuning. Our findings revealed that degrading FedAvg to activate only one client per round, a strategy we called \\textit{FedOne}, enabled optimal query efficiency in federated black-box prompt learning. Building on this insight, we proposed the FedOne framework, a federated black-box discrete prompt learning method designed to maximize query efficiency when interacting with cloud-based LLMs. We conducted numerical experiments on various aspects of our framework, demonstrating a significant improvement in query efficiency, which aligns with our theoretical results.", "AI": {"tldr": "论文提出了一种名为FedOne的联邦黑盒离散提示学习方法，通过每轮仅激活一个客户端来优化查询效率，显著提升了与云LLM交互的效率。", "motivation": "现有联邦黑盒提示调优研究忽视了云LLM服务的高查询成本，因此需要一种更高效的方法。", "method": "通过理论分析提出FedOne框架，每轮仅激活一个客户端，以最大化查询效率。", "result": "实验证明FedOne显著提升了查询效率，与理论结果一致。", "conclusion": "FedOne是一种高效的联邦黑盒离散提示学习方法，适用于云LLM服务。"}}
{"id": "2506.15666", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15666", "abs": "https://arxiv.org/abs/2506.15666", "authors": ["Haoyu Xiong", "Xiaomeng Xu", "Jimmy Wu", "Yifan Hou", "Jeannette Bohg", "Shuran Song"], "title": "Vision in Action: Learning Active Perception from Human Demonstrations", "comment": null, "summary": "We present Vision in Action (ViA), an active perception system for bimanual robot manipulation. ViA learns task-relevant active perceptual strategies (e.g., searching, tracking, and focusing) directly from human demonstrations. On the hardware side, ViA employs a simple yet effective 6-DoF robotic neck to enable flexible, human-like head movements. To capture human active perception strategies, we design a VR-based teleoperation interface that creates a shared observation space between the robot and the human operator. To mitigate VR motion sickness caused by latency in the robot's physical movements, the interface uses an intermediate 3D scene representation, enabling real-time view rendering on the operator side while asynchronously updating the scene with the robot's latest observations. Together, these design elements enable the learning of robust visuomotor policies for three complex, multi-stage bimanual manipulation tasks involving visual occlusions, significantly outperforming baseline systems.", "AI": {"tldr": "ViA是一个用于双手机器人操作的主动感知系统，通过人类演示学习任务相关的感知策略，并采用6自由度机械颈和VR远程操作界面实现高效学习。", "motivation": "开发一种能够学习人类主动感知策略的机器人系统，以提升复杂双手操作任务的性能。", "method": "使用6自由度机械颈实现灵活头部运动，设计VR远程操作界面以共享观察空间，并通过3D场景表示减少延迟。", "result": "在涉及视觉遮挡的复杂双手操作任务中，ViA显著优于基线系统。", "conclusion": "ViA通过结合硬件和界面设计，成功学习了人类主动感知策略，提升了机器人操作的鲁棒性。"}}
{"id": "2506.15200", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15200", "abs": "https://arxiv.org/abs/2506.15200", "authors": ["Alessio Negrini", "Simon Reiß"], "title": "Conquering the Retina: Bringing Visual in-Context Learning to OCT", "comment": null, "summary": "Recent advancements in medical image analysis have led to the development of highly specialized models tailored to specific clinical tasks. These models have demonstrated exceptional performance and remain a crucial research direction. Yet, their applicability is limited to predefined tasks, requiring expertise and extensive resources for development and adaptation. In contrast, generalist models offer a different form of utility: allowing medical practitioners to define tasks on the fly without the need for task-specific model development. In this work, we explore how to train generalist models for the domain of retinal optical coherence tomography using visual in-context learning (VICL), i.e., training models to generalize across tasks based on a few examples provided at inference time. To facilitate rigorous assessment, we propose a broad evaluation protocol tailored to VICL in OCT. We extensively evaluate a state-of-the-art medical VICL approach on multiple retinal OCT datasets, establishing a first baseline to highlight the potential and current limitations of in-context learning for OCT. To foster further research and practical adoption, we openly release our code.", "AI": {"tldr": "论文探讨了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，以解决特定任务模型的局限性。", "motivation": "特定临床任务的专用模型虽然性能优异，但适用性有限且开发成本高。通用模型则允许动态定义任务，无需针对特定任务开发模型。", "method": "采用视觉上下文学习（VICL）方法，训练模型基于推理时提供的少量示例实现跨任务泛化。", "result": "在多个视网膜OCT数据集上评估了先进的医学VICL方法，建立了首个基线，展示了上下文学习在OCT中的潜力与局限性。", "conclusion": "研究为OCT领域的通用模型开发提供了初步成果，并公开代码以促进进一步研究和实际应用。"}}
{"id": "2506.14937", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2506.14937", "abs": "https://arxiv.org/abs/2506.14937", "authors": ["Luan Gonçalves Miranda", "Pedro Ivo da Cruz", "Murilo Bellezoni Loiola"], "title": "Determinação Automática de Limiar de Detecção de Ataques em Redes de Computadores Utilizando Autoencoders", "comment": "This work was accepted at SBrT 2022 (Brazilian Symposium on Telecommunications and Signal Processing), though it was not included in the official proceedings. in Portuguese language", "summary": "Currently, digital security mechanisms like Anomaly Detection Systems using Autoencoders (AE) show great potential for bypassing problems intrinsic to the data, such as data imbalance. Because AE use a non-trivial and nonstandardized separation threshold to classify the extracted reconstruction error, the definition of this threshold directly impacts the performance of the detection process. Thus, this work proposes the automatic definition of this threshold using some machine learning algorithms. For this, three algorithms were evaluated: the K-Nearst Neighbors, the K-Means and the Support Vector Machine.", "AI": {"tldr": "论文提出了一种自动定义异常检测系统中自编码器（AE）重建误差阈值的方法，通过评估三种机器学习算法（KNN、K-Means、SVM）来优化检测性能。", "motivation": "由于自编码器的重建误差阈值定义直接影响检测性能，且目前缺乏标准化方法，因此需要一种自动化的阈值定义方法。", "method": "评估了三种机器学习算法（K-Nearest Neighbors、K-Means、Support Vector Machine）来自动定义重建误差阈值。", "result": "通过实验验证了所提方法在优化异常检测性能方面的有效性。", "conclusion": "自动定义重建误差阈值的方法能够显著提升异常检测系统的性能，为数据不平衡等问题提供了解决方案。"}}
{"id": "2506.15680", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15680", "abs": "https://arxiv.org/abs/2506.15680", "authors": ["Kaifeng Zhang", "Baoyu Li", "Kris Hauser", "Yunzhu Li"], "title": "Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos", "comment": "Project page: https://kywind.github.io/pgnd", "summary": "Modeling the dynamics of deformable objects is challenging due to their diverse physical properties and the difficulty of estimating states from limited visual information. We address these challenges with a neural dynamics framework that combines object particles and spatial grids in a hybrid representation. Our particle-grid model captures global shape and motion information while predicting dense particle movements, enabling the modeling of objects with varied shapes and materials. Particles represent object shapes, while the spatial grid discretizes the 3D space to ensure spatial continuity and enhance learning efficiency. Coupled with Gaussian Splattings for visual rendering, our framework achieves a fully learning-based digital twin of deformable objects and generates 3D action-conditioned videos. Through experiments, we demonstrate that our model learns the dynamics of diverse objects -- such as ropes, cloths, stuffed animals, and paper bags -- from sparse-view RGB-D recordings of robot-object interactions, while also generalizing at the category level to unseen instances. Our approach outperforms state-of-the-art learning-based and physics-based simulators, particularly in scenarios with limited camera views. Furthermore, we showcase the utility of our learned models in model-based planning, enabling goal-conditioned object manipulation across a range of tasks. The project page is available at https://kywind.github.io/pgnd .", "AI": {"tldr": "提出了一种结合粒子与空间网格的神经动力学框架，用于建模可变形物体的动态，并通过实验验证其优于现有方法。", "motivation": "可变形物体的动态建模因物理特性多样性和视觉信息有限而具有挑战性，需一种高效且通用的方法。", "method": "采用粒子-网格混合表示，粒子捕捉物体形状，空间网格确保连续性；结合高斯渲染生成3D动作视频。", "result": "模型能从稀疏RGB-D数据学习多样物体动态，泛化能力强，优于现有学习与物理模拟器。", "conclusion": "该框架为可变形物体提供了高效的数字孪生方法，适用于目标驱动的物体操控任务。"}}
{"id": "2506.15201", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15201", "abs": "https://arxiv.org/abs/2506.15201", "authors": ["Xuelin Shen", "Jiayin Xu", "Kangsheng Yin", "Wenhan Yang"], "title": "Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models", "comment": "11 pages, 6 figures, publised to ICML 2025", "summary": "The improved semantic understanding of vision-language pretrained (VLP) models has made it increasingly difficult to protect publicly posted images from being exploited by search engines and other similar tools. In this context, this paper seeks to protect users' privacy by implementing defenses at the image compression stage to prevent exploitation. Specifically, we propose a flexible coding method, termed Privacy-Shielded Image Compression (PSIC), that can produce bitstreams with multiple decoding options. By default, the bitstream is decoded to preserve satisfactory perceptual quality while preventing interpretation by VLP models. Our method also retains the original image compression functionality. With a customizable input condition, the proposed scheme can reconstruct the image that preserves its full semantic information. A Conditional Latent Trigger Generation (CLTG) module is proposed to produce bias information based on customizable conditions to guide the decoding process into different reconstructed versions, and an Uncertainty-Aware Encryption-Oriented (UAEO) optimization function is designed to leverage the soft labels inferred from the target VLP model's uncertainty on the training data. This paper further incorporates an adaptive multi-objective optimization strategy to obtain improved encrypting performance and perceptual quality simultaneously within a unified training process. The proposed scheme is plug-and-play and can be seamlessly integrated into most existing Learned Image Compression (LIC) models. Extensive experiments across multiple downstream tasks have demonstrated the effectiveness of our design.", "AI": {"tldr": "本文提出了一种名为PSIC的图像压缩方法，通过多解码选项保护用户隐私，同时保留图像压缩功能。", "motivation": "随着视觉语言预训练模型（VLP）的语义理解能力提升，公开图片易被搜索引擎等工具利用，威胁用户隐私。本文旨在通过图像压缩阶段的防御措施保护隐私。", "method": "提出PSIC方法，生成具有多解码选项的比特流，默认解码保留感知质量但阻止VLP模型解读。引入CLTG模块和UAEO优化函数，结合自适应多目标优化策略。", "result": "实验证明PSIC在多种下游任务中有效，既能保护隐私，又能保持图像压缩功能。", "conclusion": "PSIC是一种即插即用的方案，可无缝集成到现有LIC模型中，同时提升加密性能和感知质量。"}}
{"id": "2506.15218", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15218", "abs": "https://arxiv.org/abs/2506.15218", "authors": ["Dan He", "Weisheng Li", "Guofen Wang", "Yuping Huang", "Shiqiang Liu"], "title": "DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder", "comment": "This paper has been accepted by IEEE Transactions on Multimedia (TMM) in March 2025", "summary": "Multimodal medical image fusion (MMIF) extracts the most meaningful information from multiple source images, enabling a more comprehensive and accurate diagnosis. Achieving high-quality fusion results requires a careful balance of brightness, color, contrast, and detail; this ensures that the fused images effectively display relevant anatomical structures and reflect the functional status of the tissues. However, existing MMIF methods have limited capacity to capture detailed features during conventional training and suffer from insufficient cross-modal feature interaction, leading to suboptimal fused image quality. To address these issues, this study proposes a two-stage diffusion model-based fusion network (DM-FNet) to achieve unified MMIF. In Stage I, a diffusion process trains UNet for image reconstruction. UNet captures detailed information through progressive denoising and represents multilevel data, providing a rich set of feature representations for the subsequent fusion network. In Stage II, noisy images at various steps are input into the fusion network to enhance the model's feature recognition capability. Three key fusion modules are also integrated to process medical images from different modalities adaptively. Ultimately, the robust network structure and a hybrid loss function are integrated to harmonize the fused image's brightness, color, contrast, and detail, enhancing its quality and information density. The experimental results across various medical image types demonstrate that the proposed method performs exceptionally well regarding objective evaluation metrics. The fused image preserves appropriate brightness, a comprehensive distribution of radioactive tracers, rich textures, and clear edges. The code is available at https://github.com/HeDan-11/DM-FNet.", "AI": {"tldr": "本文提出了一种基于两阶段扩散模型的融合网络（DM-FNet），用于多模态医学图像融合（MMIF），通过增强特征识别能力和自适应处理不同模态图像，显著提升了融合图像的质量。", "motivation": "现有MMIF方法在传统训练中难以捕捉细节特征，且跨模态特征交互不足，导致融合图像质量不佳。", "method": "采用两阶段扩散模型：第一阶段训练UNet进行图像重建，第二阶段将不同噪声步长的图像输入融合网络，并结合三个关键融合模块自适应处理多模态图像。", "result": "实验表明，该方法在客观评价指标上表现优异，融合图像亮度、放射性示踪剂分布、纹理和边缘清晰度均得到显著提升。", "conclusion": "DM-FNet通过两阶段设计和混合损失函数，实现了高质量的多模态医学图像融合，代码已开源。"}}
{"id": "2506.14965", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14965", "abs": "https://arxiv.org/abs/2506.14965", "authors": ["Zhoujun Cheng", "Shibo Hao", "Tianyang Liu", "Fan Zhou", "Yutao Xie", "Feng Yao", "Yuexin Bian", "Yonghao Zhuang", "Nilabjo Dey", "Yuheng Zha", "Yi Gu", "Kun Zhou", "Yuqi Wang", "Yuan Li", "Richard Fan", "Jianshu She", "Chengqian Gao", "Abulhair Saparov", "Haonan Li", "Taylor W. Killian", "Mikhail Yurochkin", "Zhengzhong Liu", "Eric P. Xing", "Zhiting Hu"], "title": "Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective", "comment": "38 pages, 9 figures. Under review", "summary": "Reinforcement learning (RL) has emerged as a promising approach to improve large language model (LLM) reasoning, yet most open efforts focus narrowly on math and code, limiting our understanding of its broader applicability to general reasoning. A key challenge lies in the lack of reliable, scalable RL reward signals across diverse reasoning domains. We introduce Guru, a curated RL reasoning corpus of 92K verifiable examples spanning six reasoning domains--Math, Code, Science, Logic, Simulation, and Tabular--each built through domain-specific reward design, deduplication, and filtering to ensure reliability and effectiveness for RL training. Based on Guru, we systematically revisit established findings in RL for LLM reasoning and observe significant variation across domains. For example, while prior work suggests that RL primarily elicits existing knowledge from pretrained models, our results reveal a more nuanced pattern: domains frequently seen during pretraining (Math, Code, Science) easily benefit from cross-domain RL training, while domains with limited pretraining exposure (Logic, Simulation, and Tabular) require in-domain training to achieve meaningful performance gains, suggesting that RL is likely to facilitate genuine skill acquisition. Finally, we present Guru-7B and Guru-32B, two models that achieve state-of-the-art performance among open models RL-trained with publicly available data, outperforming best baselines by 7.9% and 6.7% on our 17-task evaluation suite across six reasoning domains. We also show that our models effectively improve the Pass@k performance of their base models, particularly on complex tasks less likely to appear in pretraining data. We release data, models, training and evaluation code to facilitate general-purpose reasoning at: https://github.com/LLM360/Reasoning360", "AI": {"tldr": "论文介绍了Guru，一个包含92K可验证示例的强化学习推理语料库，涵盖六个推理领域，并通过系统实验揭示了RL在不同领域中的表现差异。", "motivation": "探索强化学习在大语言模型推理中的广泛适用性，解决缺乏可靠、可扩展的RL奖励信号的问题。", "method": "构建Guru语料库，涵盖六个推理领域，通过领域特定的奖励设计、去重和过滤确保可靠性。基于Guru重新评估RL在LLM推理中的表现。", "result": "发现RL在不同领域的表现差异显著，提出Guru-7B和Guru-32B模型，在公开数据训练的模型中表现最优。", "conclusion": "RL在不同推理领域的效果取决于预训练数据的覆盖范围，Guru为通用推理提供了有效工具。"}}
{"id": "2506.14978", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14978", "abs": "https://arxiv.org/abs/2506.14978", "authors": ["Aayush Mishra", "Anqi Liu"], "title": "ODD: Overlap-aware Estimation of Model Performance under Distribution Shift", "comment": "Accepted to the 41st Conference on Uncertainty in Artificial Intelligence, 2025", "summary": "Reliable and accurate estimation of the error of an ML model in unseen test domains is an important problem for safe intelligent systems. Prior work uses disagreement discrepancy (DIS^2) to derive practical error bounds under distribution shifts. It optimizes for a maximally disagreeing classifier on the target domain to bound the error of a given source classifier. Although this approach offers a reliable and competitively accurate estimate of the target error, we identify a problem in this approach which causes the disagreement discrepancy objective to compete in the overlapping region between source and target domains. With an intuitive assumption that the target disagreement should be no more than the source disagreement in the overlapping region due to high enough support, we devise Overlap-aware Disagreement Discrepancy (ODD). Maximizing ODD only requires disagreement in the non-overlapping target domain, removing the competition. Our ODD-based bound uses domain-classifiers to estimate domain-overlap and better predicts target performance than DIS^2. We conduct experiments on a wide array of benchmarks to show that our method improves the overall performance-estimation error while remaining valid and reliable. Our code and results are available on GitHub.", "AI": {"tldr": "论文提出了一种新的方法（ODD）来更准确地估计机器学习模型在未见测试域中的误差，解决了现有方法（DIS²）在源域和目标域重叠区域竞争的问题。", "motivation": "现有方法（DIS²）在估计目标域误差时存在竞争问题，导致在重叠区域的估计不准确。论文旨在提出一种更可靠的方法来改进这一问题。", "method": "提出Overlap-aware Disagreement Discrepancy（ODD），通过仅在非重叠目标域最大化分歧来避免竞争，并使用域分类器估计域重叠。", "result": "实验表明，ODD在多个基准测试中比DIS²更准确地预测目标性能，同时保持有效性和可靠性。", "conclusion": "ODD方法显著提高了性能估计的准确性，解决了DIS²的局限性，为安全智能系统提供了更可靠的误差估计工具。"}}
{"id": "2506.15065", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15065", "abs": "https://arxiv.org/abs/2506.15065", "authors": ["Trishna Chakraborty", "Udita Ghosh", "Xiaopan Zhang", "Fahim Faisal Niloy", "Yue Dong", "Jiachen Li", "Amit K. Roy-Chowdhury", "Chengyu Song"], "title": "HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly being adopted as the cognitive core of embodied agents. However, inherited hallucinations, which stem from failures to ground user instructions in the observed physical environment, can lead to navigation errors, such as searching for a refrigerator that does not exist. In this paper, we present the first systematic study of hallucinations in LLM-based embodied agents performing long-horizon tasks under scene-task inconsistencies. Our goal is to understand to what extent hallucinations occur, what types of inconsistencies trigger them, and how current models respond. To achieve these goals, we construct a hallucination probing set by building on an existing benchmark, capable of inducing hallucination rates up to 40x higher than base prompts. Evaluating 12 models across two simulation environments, we find that while models exhibit reasoning, they fail to resolve scene-task inconsistencies-highlighting fundamental limitations in handling infeasible tasks. We also provide actionable insights on ideal model behavior for each scenario, offering guidance for developing more robust and reliable planning strategies.", "AI": {"tldr": "本文系统研究了基于LLM的具身智能体在场景任务不一致时的幻觉问题，揭示了其局限性并提出了改进方向。", "motivation": "LLM作为具身智能体的认知核心，其幻觉问题可能导致导航错误，需系统性研究以提升可靠性。", "method": "构建幻觉探测集，评估12个模型在两种仿真环境中的表现，分析场景任务不一致时的幻觉触发机制。", "result": "模型在推理中表现良好，但无法解决场景任务不一致问题，幻觉率可达基础提示的40倍。", "conclusion": "研究揭示了LLM在不可行任务中的局限性，并提出了开发更可靠规划策略的实用建议。"}}
{"id": "2506.15231", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15231", "abs": "https://arxiv.org/abs/2506.15231", "authors": ["Liangjie Meng", "Danxia Li", "Jinrong He", "Lili Ma", "Zhixin Li"], "title": "Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images", "comment": "5 pages, 4 figures, 2 tables. Code available at https://github.com/mlj666219/C-AFBiFPN/tree/master", "summary": "Synthetic Aperture Radar (SAR) enables submeter-resolution imaging and all-weather monitoring via active microwave and advanced signal processing. Currently, SAR has found extensive applications in critical maritime domains such as ship detection. However, SAR ship detection faces several challenges, including significant scale variations among ships, the presence of small offshore vessels mixed with noise, and complex backgrounds for large nearshore ships. To address these issues, this paper proposes a novel feature enhancement and fusion framework named C-AFBiFPN. C-AFBiFPN constructs a Convolutional Feature Enhancement (CFE) module following the backbone network, aiming to enrich feature representation and enhance the ability to capture and represent local details and contextual information. Furthermore, C-AFBiFPN innovatively integrates BiFormer attention within the fusion strategy of BiFPN, creating the AFBiFPN network. AFBiFPN improves the global modeling capability of cross-scale feature fusion and can adaptively focus on critical feature regions. The experimental results on SAR Ship Detection Dataset (SSDD) indicate that the proposed approach substantially enhances detection accuracy for small targets, robustness against occlusions, and adaptability to multi-scale features.", "AI": {"tldr": "本文提出了一种名为C-AFBiFPN的特征增强与融合框架，用于解决SAR船舶检测中的多尺度变化、小目标噪声和复杂背景问题，显著提升了检测精度和鲁棒性。", "motivation": "SAR船舶检测面临多尺度变化、小目标噪声和复杂背景等挑战，需要更强大的特征表示和融合能力。", "method": "提出C-AFBiFPN框架，包括卷积特征增强模块（CFE）和改进的AFBiFPN网络，结合BiFormer注意力机制。", "result": "在SSDD数据集上，该方法显著提升了小目标检测精度、抗遮挡能力和多尺度适应性。", "conclusion": "C-AFBiFPN通过特征增强和注意力机制有效解决了SAR船舶检测的关键问题，具有实际应用潜力。"}}
{"id": "2506.14986", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14986", "abs": "https://arxiv.org/abs/2506.14986", "authors": ["Maxime Usdin", "Lito Kriara", "Licinio Craveiro"], "title": "Early Prediction of Multiple Sclerosis Disability Progression via Multimodal Foundation Model Benchmarks", "comment": "Accepted to IJCAI 2025", "summary": "Early multiple sclerosis (MS) disability progression prediction is challenging due to disease heterogeneity. This work predicts 48- and 72-week disability using sparse baseline clinical data and 12 weeks of daily digital Floodlight data from the CONSONANCE clinical trial. We employed state-of-the-art tabular and time-series foundation models (FMs), a custom multimodal attention-based transformer, and machine learning methods. Despite the difficulty of early prediction (AUROC 0.63), integrating digital data via advanced models improved performance over clinical data alone. A transformer model using unimodal embeddings from the Moment FM yielded the best result, but our multimodal transformer consistently outperformed its unimodal counterpart, confirming the advantages of combining clinical with digital data. Our findings demonstrate the promise of FMs and multimodal approaches to extract predictive signals from complex and diverse clinical and digital life sciences data (e.g., imaging, omics), enabling more accurate prognostics for MS and potentially other complex diseases.", "AI": {"tldr": "该研究利用稀疏基线临床数据和12周的日常数字Floodlight数据，通过先进的表格和时间序列基础模型、多模态注意力变换器及机器学习方法，预测多发性硬化症（MS）的48周和72周残疾进展。结果显示，结合数字数据的多模态方法优于仅使用临床数据。", "motivation": "早期预测多发性硬化症的残疾进展具有挑战性，因为疾病异质性高。研究旨在通过结合临床和数字数据，利用先进模型提高预测准确性。", "method": "使用稀疏基线临床数据和12周的数字Floodlight数据，采用表格和时间序列基础模型、多模态注意力变换器及机器学习方法进行预测。", "result": "尽管早期预测难度大（AUROC 0.63），但结合数字数据的多模态方法显著优于仅使用临床数据。基于Moment FM的单模态嵌入变换器表现最佳，但多模态变换器始终优于单模态版本。", "conclusion": "研究表明，基础模型和多模态方法能够从复杂的临床和数字数据中提取预测信号，为多发性硬化症及其他复杂疾病的预后提供更准确的工具。"}}
{"id": "2506.15242", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15242", "abs": "https://arxiv.org/abs/2506.15242", "authors": ["Qingsong Yan", "Qiang Wang", "Kaiyong Zhao", "Jie Chen", "Bo Li", "Xiaowen Chu", "Fei Deng"], "title": "RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories", "comment": "IROS 2025", "summary": "Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have emerged as powerful tools for 3D reconstruction and SLAM tasks. However, their performance depends heavily on accurate camera pose priors. Existing approaches attempt to address this issue by introducing external constraints but fall short of achieving satisfactory accuracy, particularly when camera trajectories are complex. In this paper, we propose a novel method, RA-NeRF, capable of predicting highly accurate camera poses even with complex camera trajectories. Following the incremental pipeline, RA-NeRF reconstructs the scene using NeRF with photometric consistency and incorporates flow-driven pose regulation to enhance robustness during initialization and localization. Additionally, RA-NeRF employs an implicit pose filter to capture the camera movement pattern and eliminate the noise for pose estimation. To validate our method, we conduct extensive experiments on the Tanks\\&Temple dataset for standard evaluation, as well as the NeRFBuster dataset, which presents challenging camera pose trajectories. On both datasets, RA-NeRF achieves state-of-the-art results in both camera pose estimation and visual quality, demonstrating its effectiveness and robustness in scene reconstruction under complex pose trajectories.", "AI": {"tldr": "RA-NeRF是一种新方法，能够在复杂相机轨迹下预测高精度相机姿态，结合NeRF和流驱动姿态调节，显著提升了3D重建和SLAM任务的性能。", "motivation": "现有方法依赖准确的相机姿态先验，且在复杂轨迹下表现不佳，RA-NeRF旨在解决这一问题。", "method": "采用增量式流程，结合NeRF的光度一致性和流驱动姿态调节，并引入隐式姿态滤波器以减少噪声。", "result": "在Tanks&Temple和NeRFBuster数据集上，RA-NeRF在相机姿态估计和视觉质量上均达到最优。", "conclusion": "RA-NeRF在复杂相机轨迹下表现出高效性和鲁棒性，为3D重建和SLAM任务提供了新解决方案。"}}
{"id": "2506.14988", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14988", "abs": "https://arxiv.org/abs/2506.14988", "authors": ["Tianyi Xu", "Jiaxin Liu", "Zizhan Zheng"], "title": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits", "comment": null, "summary": "We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.", "AI": {"tldr": "提出了一种多智能体多臂老虎机框架，旨在平衡公平性和系统性能，通过探测框架优化信息收集，并在离线和在线场景中分别设计了高效算法。", "motivation": "解决多智能体环境中公平性与性能最大化之间的矛盾，尤其是在信息有限的情况下。", "method": "引入探测框架，离线下利用子模性质设计贪心算法，在线场景中开发具有次线性遗憾的算法。", "result": "实验表明，该方法在公平性和效率上优于基线方法。", "conclusion": "提出的框架和算法在多智能体环境中实现了公平与性能的平衡，适用于实际应用。"}}
{"id": "2506.15244", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15244", "abs": "https://arxiv.org/abs/2506.15244", "authors": ["Chenxi Zhang", "Jiayun Wu", "Qing Zhang", "Yazhe Zhai", "Youwei Pang"], "title": "Retrospective Memory for Camouflaged Object Detection", "comment": null, "summary": "Camouflaged object detection (COD) primarily focuses on learning subtle yet discriminative representations from complex scenes. Existing methods predominantly follow the parametric feedforward architecture based on static visual representation modeling. However, they lack explicit mechanisms for acquiring historical context, limiting their adaptation and effectiveness in handling challenging camouflage scenes. In this paper, we propose a recall-augmented COD architecture, namely RetroMem, which dynamically modulates camouflage pattern perception and inference by integrating relevant historical knowledge into the process. Specifically, RetroMem employs a two-stage training paradigm consisting of a learning stage and a recall stage to construct, update, and utilize memory representations effectively. During the learning stage, we design a dense multi-scale adapter (DMA) to improve the pretrained encoder's capability to capture rich multi-scale visual information with very few trainable parameters, thereby providing foundational inferences. In the recall stage, we propose a dynamic memory mechanism (DMM) and an inference pattern reconstruction (IPR). These components fully leverage the latent relationships between learned knowledge and current sample context to reconstruct the inference of camouflage patterns, thereby significantly improving the model's understanding of camouflage scenes. Extensive experiments on several widely used datasets demonstrate that our RetroMem significantly outperforms existing state-of-the-art methods.", "AI": {"tldr": "提出了一种基于历史知识动态调制的伪装目标检测架构RetroMem，通过两阶段训练提升模型性能。", "motivation": "现有方法缺乏历史上下文机制，难以适应复杂伪装场景。", "method": "RetroMem采用两阶段训练（学习阶段和回忆阶段），结合DMA和DMM/IPR模块动态调制感知与推理。", "result": "在多个数据集上显著优于现有方法。", "conclusion": "RetroMem通过历史知识整合有效提升了伪装目标检测的性能。"}}
{"id": "2506.15019", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15019", "abs": "https://arxiv.org/abs/2506.15019", "authors": ["Yue Gao"], "title": "Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment", "comment": "Accepted to IJCAI2025 AI4TS", "summary": "Effective reinforcement learning (RL) for sepsis treatment depends on learning stable, clinically meaningful state representations from irregular ICU time series. While previous works have explored representation learning for this task, the critical challenge of training instability in sequential representations and its detrimental impact on policy performance has been overlooked. This work demonstrates that Controlled Differential Equations (CDE) state representation can achieve strong RL policies when two key factors are met: (1) ensuring training stability through early stopping or stabilization methods, and (2) enforcing acuity-aware representations by correlation regularization with clinical scores (SOFA, SAPS-II, OASIS). Experiments on the MIMIC-III sepsis cohort reveal that stable CDE autoencoder produces representations strongly correlated with acuity scores and enables RL policies with superior performance (WIS return $> 0.9$). In contrast, unstable CDE representation leads to degraded representations and policy failure (WIS return $\\sim$ 0). Visualizations of the latent space show that stable CDEs not only separate survivor and non-survivor trajectories but also reveal clear acuity score gradients, whereas unstable training fails to capture either pattern. These findings highlight practical guidelines for using CDEs to encode irregular medical time series in clinical RL, emphasizing the need for training stability in sequential representation learning.", "AI": {"tldr": "论文提出使用受控微分方程（CDE）状态表示来提升强化学习在脓毒症治疗中的稳定性，并通过训练稳定性和临床评分相关性实现优越性能。", "motivation": "解决ICU不规则时间序列中强化学习状态表示的训练不稳定问题及其对策略性能的负面影响。", "method": "采用受控微分方程（CDE）状态表示，结合训练稳定性（如早停或稳定化方法）和临床评分（SOFA、SAPS-II、OASIS）相关性正则化。", "result": "实验显示稳定CDE表示与临床评分强相关，并实现优越的强化学习策略性能（WIS回报>0.9），而不稳定表示导致策略失败（WIS回报~0）。", "conclusion": "研究强调了在临床强化学习中训练稳定性的重要性，为使用CDE编码不规则医疗时间序列提供了实用指导。"}}
{"id": "2506.15560", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15560", "abs": "https://arxiv.org/abs/2506.15560", "authors": ["Xingrui Qin", "Wentao Zhao", "Chuan Cao", "Yihe Niu", "Houcheng Jiang", "Jingchuan Wang"], "title": "RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation", "comment": "9 pages, 7 figures", "summary": "Dense metric depth estimation using millimeter-wave radar typically requires dense LiDAR supervision, generated via multi-frame projection and interpolation, to guide the learning of accurate depth from sparse radar measurements and RGB images. However, this paradigm is both costly and data-intensive. To address this, we propose RaCalNet, a novel framework that eliminates the need for dense supervision by using sparse LiDAR to supervise the learning of refined radar measurements, resulting in a supervision density of merely around 1% compared to dense-supervised methods. Unlike previous approaches that associate radar points with broad image regions and rely heavily on dense labels, RaCalNet first recalibrates and refines sparse radar points to construct accurate depth priors. These priors then serve as reliable anchors to guide monocular depth prediction, enabling metric-scale estimation without resorting to dense supervision. This design improves structural consistency and preserves fine details. Despite relying solely on sparse supervision, RaCalNet surpasses state-of-the-art dense-supervised methods, producing depth maps with clear object contours and fine-grained textures. Extensive experiments on the ZJU-4DRadarCam dataset and real-world deployment scenarios demonstrate its effectiveness, reducing RMSE by 35.30% and 34.89%, respectively.", "AI": {"tldr": "RaCalNet提出了一种无需密集监督的毫米波雷达深度估计框架，通过稀疏LiDAR监督实现高精度深度预测，显著降低数据需求。", "motivation": "现有方法依赖密集LiDAR监督，成本高且数据需求大，RaCalNet旨在解决这一问题。", "method": "通过稀疏雷达点校准和优化构建深度先验，引导单目深度预测，避免密集监督。", "result": "在ZJU-4DRadarCam数据集上，RMSE分别降低35.30%和34.89%，优于现有方法。", "conclusion": "RaCalNet证明了稀疏监督的可行性，显著提升了深度估计的精度和效率。"}}
{"id": "2506.15260", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15260", "abs": "https://arxiv.org/abs/2506.15260", "authors": ["Adrian Poniatowski", "Natalie Gentner", "Manuel Barusco", "Davide Dalle Pezze", "Samuele Salti", "Gian Antonio Susto"], "title": "Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing", "comment": null, "summary": "In the semiconductor sector, due to high demand but also strong and increasing competition, time to market and quality are key factors in securing significant market share in various application areas. Thanks to the success of deep learning methods in recent years in the computer vision domain, Industry 4.0 and 5.0 applications, such as defect classification, have achieved remarkable success. In particular, Domain Adaptation (DA) has proven highly effective since it focuses on using the knowledge learned on a (source) domain to adapt and perform effectively on a different but related (target) domain. By improving robustness and scalability, DA minimizes the need for extensive manual re-labeling or re-training of models. This not only reduces computational and resource costs but also allows human experts to focus on high-value tasks. Therefore, we tested the efficacy of DA techniques in semi-supervised and unsupervised settings within the context of the semiconductor field. Moreover, we propose the DBACS approach, a CycleGAN-inspired model enhanced with additional loss terms to improve performance. All the approaches are studied and validated on real-world Electron Microscope images considering the unsupervised and semi-supervised settings, proving the usefulness of our method in advancing DA techniques for the semiconductor field.", "AI": {"tldr": "论文探讨了在半导体领域应用领域自适应（DA）技术，提出了一种改进的CycleGAN模型（DBACS），以提升缺陷分类的效率和准确性。", "motivation": "半导体行业竞争激烈，时间和质量是关键，而领域自适应技术能减少重新标注和训练的需求，降低成本并提升效率。", "method": "提出DBACS方法，基于CycleGAN并引入额外损失项，在半监督和无监督设置下测试其效果。", "result": "在真实电子显微镜图像上验证了方法的有效性，证明了其在半导体领域的实用价值。", "conclusion": "DBACS方法能有效提升领域自适应技术在半导体领域的应用，减少资源消耗并提高性能。"}}
{"id": "2506.15021", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15021", "abs": "https://arxiv.org/abs/2506.15021", "authors": ["Gyuhak Kim", "Sumiran Singh Thakur", "Su Min Park", "Wei Wei", "Yujia Bao"], "title": "SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models", "comment": null, "summary": "Supervised fine-tuning (SFT) has become an essential step in tailoring large language models (LLMs) to align with human expectations and specific downstream tasks. However, existing SFT methods typically treat each training instance as a uniform sequence, giving equal importance to all tokens regardless of their relevance. This overlooks the fact that only a subset of tokens often contains critical, task-specific information. To address this limitation, we introduce Supervised Fine-Tuning with Group Optimization (SFT-GO), a novel approach that treats groups of tokens differently based on their importance.SFT-GO groups tokens in each sample based on their importance values and optimizes the LLM using a weighted combination of the worst-group loss and the standard cross-entropy loss. This mechanism adaptively emphasizes the most challenging token groups and guides the model to better handle different group distributions, thereby improving overall learning dynamics. We provide a theoretical analysis of SFT-GO's convergence rate, demonstrating its efficiency. Empirically, we apply SFT-GO with three different token grouping strategies and show that models trained with SFT-GO consistently outperform baseline approaches across popular LLM benchmarks. These improvements hold across various datasets and base models, demonstrating the robustness and the effectiveness of our method.", "AI": {"tldr": "SFT-GO是一种新颖的监督微调方法，通过按重要性分组优化令牌，提升大语言模型的性能。", "motivation": "现有监督微调方法对所有令牌一视同仁，忽略了任务关键信息的令牌子集，导致性能受限。", "method": "SFT-GO根据令牌重要性分组，结合最差组损失和标准交叉熵损失进行优化，动态强调关键令牌。", "result": "SFT-GO在多个基准测试中优于基线方法，且在不同数据集和基础模型上表现稳健。", "conclusion": "SFT-GO通过令牌分组优化显著提升模型性能，具有理论和实践价值。"}}
{"id": "2506.15635", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15635", "abs": "https://arxiv.org/abs/2506.15635", "authors": ["Karmesh Yadav", "Yusuf Ali", "Gunshi Gupta", "Yarin Gal", "Zsolt Kira"], "title": "FindingDory: A Benchmark to Evaluate Memory in Embodied Agents", "comment": "Our dataset and code will be made available at: https://findingdory-benchmark.github.io/", "summary": "Large vision-language models have recently demonstrated impressive performance in planning and control tasks, driving interest in their application to real-world robotics. However, deploying these models for reasoning in embodied contexts is limited by their ability to incorporate long-term experience collected across multiple days and represented by vast collections of images. Current VLMs typically struggle to process more than a few hundred images concurrently, highlighting the need for more efficient mechanisms to handle long-term memory in embodied settings. To effectively evaluate these models for long-horizon control, a benchmark must specifically target scenarios where memory is crucial for success. Existing long-video QA benchmarks overlook embodied challenges like object manipulation and navigation, which demand low-level skills and fine-grained reasoning over past interactions. Moreover, effective memory integration in embodied agents involves both recalling relevant historical information and executing actions based on that information, making it essential to study these aspects together rather than in isolation. In this work, we introduce a new benchmark for long-range embodied tasks in the Habitat simulator. This benchmark evaluates memory-based capabilities across 60 tasks requiring sustained engagement and contextual awareness in an environment. The tasks can also be procedurally extended to longer and more challenging versions, enabling scalable evaluation of memory and reasoning. We also present baselines that integrate state-of-the-art VLMs with low level navigation policies, assessing their performance on these memory-intensive tasks and highlight areas for improvement.", "AI": {"tldr": "本文提出了一种新的基准测试，用于评估大型视觉语言模型在长期记忆和推理任务中的表现，特别是在机器人控制任务中。", "motivation": "当前视觉语言模型在处理长期记忆和大量图像数据时表现不佳，限制了其在机器人控制任务中的应用。", "method": "在Habitat模拟器中设计了一个包含60个任务的基准测试，这些任务需要长期记忆和上下文感知能力。", "result": "基准测试可以扩展为更复杂的版本，用于评估模型的记忆和推理能力，并提供了基线模型的性能评估。", "conclusion": "该基准测试为研究长期记忆和推理在机器人控制中的应用提供了重要工具，并指出了现有模型的改进方向。"}}
{"id": "2506.15276", "categories": ["cs.CV", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15276", "abs": "https://arxiv.org/abs/2506.15276", "authors": ["Jun Zhu", "Xinfeng Zhang", "Lv Tang", "JunHao Jiang"], "title": "MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion", "comment": null, "summary": "Implicit Neural representations (INRs) have emerged as a promising approach for video compression, and have achieved comparable performance to the state-of-the-art codecs such as H.266/VVC. However, existing INR-based methods struggle to effectively represent detail-intensive and fast-changing video content. This limitation mainly stems from the underutilization of internal network features and the absence of video-specific considerations in network design. To address these challenges, we propose a multi-scale feature fusion framework, MSNeRV, for neural video representation. In the encoding stage, we enhance temporal consistency by employing temporal windows, and divide the video into multiple Groups of Pictures (GoPs), where a GoP-level grid is used for background representation. Additionally, we design a multi-scale spatial decoder with a scale-adaptive loss function to integrate multi-resolution and multi-frequency information. To further improve feature extraction, we introduce a multi-scale feature block that fully leverages hidden features. We evaluate MSNeRV on HEVC ClassB and UVG datasets for video representation and compression. Experimental results demonstrate that our model exhibits superior representation capability among INR-based approaches and surpasses VTM-23.7 (Random Access) in dynamic scenarios in terms of compression efficiency.", "AI": {"tldr": "MSNeRV是一种多尺度特征融合框架，用于神经视频表示，解决了现有INR方法在细节密集和快速变化视频内容中的不足，并在压缩效率上超越了VTM-23.7。", "motivation": "现有基于INR的视频压缩方法在细节密集和快速变化内容上表现不佳，主要原因是网络内部特征利用不足和缺乏视频特定设计。", "method": "提出MSNeRV框架，包括时间窗口增强时序一致性、GoP级网格背景表示、多尺度空间解码器和自适应损失函数，以及多尺度特征块。", "result": "在HEVC ClassB和UVG数据集上，MSNeRV在表示能力和压缩效率上优于现有INR方法，并超越VTM-23.7。", "conclusion": "MSNeRV通过多尺度特征融合和视频特定设计，显著提升了INR在视频压缩中的性能。"}}
{"id": "2506.15025", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.15025", "abs": "https://arxiv.org/abs/2506.15025", "authors": ["Soufiane Hayou", "Liyuan Liu"], "title": "Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size", "comment": "TD,LR: How to set the learning rate for emebdding layer in LLMs?", "summary": "Pretraining large language models is a costly process. To make this process more efficient, several methods have been proposed to optimize model architecture/parametrization and hardware use. On the parametrization side, $μP$ (Maximal Update Parametrization) parametrizes model weights and learning rate (LR) in a way that makes hyperparameters (HPs) transferable with width (embedding dimension): HPs can be tuned for a small model and used for larger models without additional tuning. While $μ$P showed impressive results in practice, recent empirical studies have reported conflicting observations when applied to LLMs. One limitation of the theory behind $μ$P is the fact that input dimension (vocabulary size in LLMs) is considered fixed when taking the width to infinity. This is unrealistic since vocabulary size is generally much larger than width in practice. In this work, we provide a theoretical analysis of the effect of vocabulary size on training dynamics, and subsequently show that as vocabulary size increases, the training dynamics \\emph{interpolate between the $μ$P regime and another regime that we call Large Vocab (LV) Regime}, where optimal scaling rules are different from those predicted by $μ$P. Our analysis reveals that in the LV regime, the optimal embedding LR to hidden LR ratio should roughly scale as $Θ(\\sqrt{width})$, surprisingly close to the empirical findings previously reported in the literature, and different from the $Θ(width)$ ratio predicted by $μ$P. We conduct several experiments to validate our theory, and pretrain a 1B model from scratch to show the benefit of our suggested scaling rule for the embedding LR.", "AI": {"tldr": "论文分析了词汇量对大型语言模型训练动态的影响，揭示了μP理论的局限性，并提出了一种新的词汇量大的情况下的优化缩放规则。", "motivation": "μP理论在词汇量固定的假设下表现良好，但实际中词汇量远大于宽度，导致训练动态与理论预测不符。本文旨在填补这一理论空白。", "method": "通过理论分析词汇量对训练动态的影响，提出LV（Large Vocab）机制，并实验验证其缩放规则。", "result": "发现LV机制下嵌入学习率与隐藏学习率的最优比例应为Θ(√width)，与μP的Θ(width)不同，并通过实验验证了这一规则的有效性。", "conclusion": "词汇量的增加会导致训练动态在μP和LV机制之间过渡，LV机制下的缩放规则更适用于实际场景，且能提升模型性能。"}}
{"id": "2506.15279", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15279", "abs": "https://arxiv.org/abs/2506.15279", "authors": ["Qian Li", "Feng Liu", "Shuojue Yang", "Daiyun Shen", "Yueming Jin"], "title": "BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement", "comment": "Accepted at MICCAI 2025, 11 pages, 2 figures", "summary": "Laparoscopic liver surgery, while minimally invasive, poses significant challenges in accurately identifying critical anatomical structures. Augmented reality (AR) systems, integrating MRI/CT with laparoscopic images based on 2D-3D registration, offer a promising solution for enhancing surgical navigation. A vital aspect of the registration progress is the precise detection of curvilinear anatomical landmarks in laparoscopic images. In this paper, we propose BCRNet (Bezier Curve Refinement Net), a novel framework that significantly enhances landmark detection in laparoscopic liver surgery primarily via the Bezier curve refinement strategy. The framework starts with a Multi-modal Feature Extraction (MFE) module designed to robustly capture semantic features. Then we propose Adaptive Curve Proposal Initialization (ACPI) to generate pixel-aligned Bezier curves and confidence scores for reliable initial proposals. Additionally, we design the Hierarchical Curve Refinement (HCR) mechanism to enhance these proposals iteratively through a multi-stage process, capturing fine-grained contextual details from multi-scale pixel-level features for precise Bezier curve adjustment. Extensive evaluations on the L3D and P2ILF datasets demonstrate that BCRNet outperforms state-of-the-art methods, achieving significant performance improvements. Code will be available.", "AI": {"tldr": "BCRNet通过Bezier曲线细化策略显著提升腹腔镜肝脏手术中的关键解剖标志检测，结合多模态特征提取和分层曲线细化机制，性能优于现有方法。", "motivation": "腹腔镜手术中准确识别解剖结构具有挑战性，AR系统通过2D-3D配准增强导航，但需精确检测曲线标志。", "method": "提出BCRNet框架，包括多模态特征提取模块、自适应曲线提案初始化和分层曲线细化机制。", "result": "在L3D和P2ILF数据集上表现优异，显著超越现有方法。", "conclusion": "BCRNet为腹腔镜手术中的解剖标志检测提供了高效解决方案，代码将开源。"}}
{"id": "2506.15051", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15051", "abs": "https://arxiv.org/abs/2506.15051", "authors": ["Zheng Li", "Jerry Cheng", "Huanying Helen Gu"], "title": "Sequential Policy Gradient for Adaptive Hyperparameter Optimization", "comment": "10 pages, 2 figures", "summary": "Reinforcement learning is essential for neural architecture search and hyperparameter optimization, but the conventional approaches impede widespread use due to prohibitive time and computational costs. Inspired by DeepSeek-V3 multi-token prediction architecture, we propose Sequential Policy Gradient modeling (SPG), a novel trajectory generation paradigm for lightweight online hyperparameter optimization. In contrast to conventional policy gradient methods, SPG extends the base model with temporary modules, enabling it to generate state-action (padded) trajectories in a single forward pass. Our experiments demonstrate that models gain performance when retrained with SPG on their original datasets and also outperform standard transfer fine-tuning. We evaluate on five datasets spanning computer vision (ImageNet, COCO), natural language processing (GLUE, SQuAD), and audio (SUPERB) to assess the industrial applicability of SPG. The proposed method demonstrates consistent improvements across widely adopted models, achieving performance gains of $+0.2\\sim7\\%$, with significantly low computational costs. Fully reproducible code and pre-trained models: https://huggingface.co/UniversalAlgorithmic/SPG.", "AI": {"tldr": "提出了一种轻量级的在线超参数优化方法SPG，通过单次前向生成轨迹，显著降低计算成本，并在多领域数据集上表现优异。", "motivation": "传统强化学习方法在神经架构搜索和超参数优化中计算成本过高，限制了广泛应用。", "method": "提出Sequential Policy Gradient (SPG)，通过临时模块扩展基础模型，单次前向生成状态-动作轨迹。", "result": "在ImageNet、COCO等五个数据集上，SPG显著提升模型性能（+0.2~7%），计算成本低。", "conclusion": "SPG是一种高效、轻量级的超参数优化方法，具有广泛工业应用潜力。"}}
{"id": "2506.15285", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15285", "abs": "https://arxiv.org/abs/2506.15285", "authors": ["Mattia Nardon", "Stefano Messelodi", "Antonio Granata", "Fabio Poiesi", "Alberto Danese", "Davide Boscaini"], "title": "AI-driven visual monitoring of industrial assembly tasks", "comment": null, "summary": "Visual monitoring of industrial assembly tasks is critical for preventing equipment damage due to procedural errors and ensuring worker safety. Although commercial solutions exist, they typically require rigid workspace setups or the application of visual markers to simplify the problem. We introduce ViMAT, a novel AI-driven system for real-time visual monitoring of assembly tasks that operates without these constraints. ViMAT combines a perception module that extracts visual observations from multi-view video streams with a reasoning module that infers the most likely action being performed based on the observed assembly state and prior task knowledge. We validate ViMAT on two assembly tasks, involving the replacement of LEGO components and the reconfiguration of hydraulic press molds, demonstrating its effectiveness through quantitative and qualitative analysis in challenging real-world scenarios characterized by partial and uncertain visual observations. Project page: https://tev-fbk.github.io/ViMAT", "AI": {"tldr": "ViMAT是一种无需标记或固定工作空间设置的AI驱动系统，用于实时监控工业装配任务。", "motivation": "工业装配任务的视觉监控对防止设备损坏和确保工人安全至关重要，现有商业解决方案通常需要固定设置或标记。", "method": "ViMAT结合感知模块（从多视角视频流提取视觉观察）和推理模块（基于观察状态和任务知识推断动作）。", "result": "在LEGO组件更换和液压模具重组任务中验证了ViMAT的有效性，支持部分和不确定的视觉观察。", "conclusion": "ViMAT在复杂实际场景中表现出色，为无约束装配监控提供了可行解决方案。"}}
{"id": "2506.15054", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.15054", "abs": "https://arxiv.org/abs/2506.15054", "authors": ["Lizhang Chen", "Jonathan Li", "Qiang Liu"], "title": "Muon Optimizes Under Spectral Norm Constraints", "comment": null, "summary": "The pursuit of faster optimization algorithms remains an active and important research direction in deep learning. Recently, the Muon optimizer [JJB+24] has demonstrated promising empirical performance, but its theoretical foundation remains less understood. In this paper, we bridge this gap and provide a theoretical analysis of Muon by placing it within the Lion-$\\mathcal{K}$ family of optimizers [CLLL24]. Specifically, we show that Muon corresponds to Lion-$\\mathcal{K}$ when equipped with the nuclear norm, and we leverage the theoretical results of Lion-$\\mathcal{K}$ to establish that Muon (with decoupled weight decay) implicitly solves an optimization problem that enforces a constraint on the spectral norm of weight matrices. This perspective not only demystifies the implicit regularization effects of Muon but also leads to natural generalizations through varying the choice of convex map $\\mathcal{K}$, allowing for the exploration of a broader class of implicitly regularized and constrained optimization algorithms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.15298", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.15298", "abs": "https://arxiv.org/abs/2506.15298", "authors": ["Xinqi Fan", "Jingting Li", "John See", "Moi Hoon Yap", "Wen-Huang Cheng", "Xiaobai Li", "Xiaopeng Hong", "Su-Jing Wang", "Adrian K. Davision"], "title": "MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering", "comment": "Micro-Expression Grand Challenge (MEGC) at ACM MM 2025", "summary": "Facial micro-expressions (MEs) are involuntary movements of the face that occur spontaneously when a person experiences an emotion but attempts to suppress or repress the facial expression, typically found in a high-stakes environment. In recent years, substantial advancements have been made in the areas of ME recognition, spotting, and generation. However, conventional approaches that treat spotting and recognition as separate tasks are suboptimal, particularly for analyzing long-duration videos in realistic settings. Concurrently, the emergence of multimodal large language models (MLLMs) and large vision-language models (LVLMs) offers promising new avenues for enhancing ME analysis through their powerful multimodal reasoning capabilities. The ME grand challenge (MEGC) 2025 introduces two tasks that reflect these evolving research directions: (1) ME spot-then-recognize (ME-STR), which integrates ME spotting and subsequent recognition in a unified sequential pipeline; and (2) ME visual question answering (ME-VQA), which explores ME understanding through visual question answering, leveraging MLLMs or LVLMs to address diverse question types related to MEs. All participating algorithms are required to run on this test set and submit their results on a leaderboard. More details are available at https://megc2025.github.io.", "AI": {"tldr": "论文探讨了面部微表情（MEs）的识别、定位与生成，提出结合定位与识别的统一任务（ME-STR）及基于多模态大语言模型的视觉问答（ME-VQA），以提升ME分析效果。", "motivation": "传统方法将ME定位与识别分开处理，在高时长视频分析中效果不佳，而多模态大语言模型（MLLMs）和大视觉语言模型（LVLMs）为ME分析提供了新思路。", "method": "MEGC 2025引入两项任务：ME-STR（统一定位与识别流程）和ME-VQA（利用MLLMs/LVLMs进行视觉问答）。", "result": "通过整合任务和利用多模态模型，有望提升ME分析的准确性和效率。", "conclusion": "ME-STR和ME-VQA为ME研究提供了新方向，MEGC 2025将推动相关算法的发展。"}}
{"id": "2506.15313", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15313", "abs": "https://arxiv.org/abs/2506.15313", "authors": ["Leonid Ivanov", "Vasily Yuryev", "Dmitry Yudin"], "title": "MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning", "comment": "Preprint. Submitted. 12 pages, 4 figures", "summary": "In autonomous driving, high-definition (HD) maps and semantic maps in bird's-eye view (BEV) are essential for accurate localization, planning, and decision-making. This paper introduces an enhanced End-to-End model named MapFM for online vectorized HD map generation. We show significantly boost feature representation quality by incorporating powerful foundation model for encoding camera images. To further enrich the model's understanding of the environment and improve prediction quality, we integrate auxiliary prediction heads for semantic segmentation in the BEV representation. This multi-task learning approach provides richer contextual supervision, leading to a more comprehensive scene representation and ultimately resulting in higher accuracy and improved quality of the predicted vectorized HD maps. The source code is available at https://github.com/LIvanoff/MapFM.", "AI": {"tldr": "本文提出了一种名为MapFM的端到端模型，用于在线生成矢量化的高清地图，通过结合强大的基础模型和辅助预测头，显著提升了特征表示质量和预测精度。", "motivation": "在自动驾驶中，高清地图和鸟瞰图语义地图对精确定位、规划和决策至关重要，但现有方法在特征表示和预测质量上仍有提升空间。", "method": "MapFM模型结合了基础模型编码相机图像，并引入辅助预测头进行鸟瞰图语义分割，采用多任务学习方法提升场景理解。", "result": "模型显著提升了特征表示质量，生成了更准确的矢量化高清地图，预测质量得到明显改善。", "conclusion": "MapFM通过多任务学习和基础模型结合，为自动驾驶提供了更全面的场景表示和更高精度的地图生成方案。"}}
{"id": "2506.15318", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15318", "abs": "https://arxiv.org/abs/2506.15318", "authors": ["Lanfeng Zhong", "Xin Liao", "Shichuan Zhang", "Shaoting Zhang", "Guotai Wang"], "title": "OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models", "comment": "MICCAI 2025 early accept", "summary": "Pathology image classification plays a crucial role in accurate medical diagnosis and treatment planning. Training high-performance models for this task typically requires large-scale annotated datasets, which are both expensive and time-consuming to acquire. Active Learning (AL) offers a solution by iteratively selecting the most informative samples for annotation, thereby reducing the labeling effort. However, most AL methods are designed under the assumption of a closed-set scenario, where all the unannotated images belong to target classes. In real-world clinical environments, the unlabeled pool often contains a substantial amount of Out-Of-Distribution (OOD) data, leading to low efficiency of annotation in traditional AL methods. Furthermore, most existing AL methods start with random selection in the first query round, leading to a significant waste of labeling costs in open-set scenarios. To address these challenges, we propose OpenPath, a novel open-set active learning approach for pathological image classification leveraging a pre-trained Vision-Language Model (VLM). In the first query, we propose task-specific prompts that combine target and relevant non-target class prompts to effectively select In-Distribution (ID) and informative samples from the unlabeled pool. In subsequent queries, Diverse Informative ID Sampling (DIS) that includes Prototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic Sampling (EGSS) is proposed to ensure both purity and informativeness in a query, avoiding the selection of OOD samples. Experiments on two public pathology image datasets show that OpenPath significantly enhances the model's performance due to its high purity of selected samples, and outperforms several state-of-the-art open-set AL methods. The code is available at \\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}..", "AI": {"tldr": "OpenPath是一种基于预训练视觉语言模型（VLM）的开集主动学习方法，用于病理图像分类，通过任务特定提示和多样性信息采样策略，有效减少标注成本并提升模型性能。", "motivation": "传统主动学习方法在开集场景下效率低下，未标注数据中常包含大量分布外（OOD）样本，且初始随机选择浪费标注成本。", "method": "提出OpenPath方法，首轮查询使用任务特定提示筛选分布内（ID）样本，后续查询结合原型选择和熵引导采样确保样本纯度和信息量。", "result": "在两个公开病理图像数据集上，OpenPath显著优于现有开集主动学习方法，提高了模型性能。", "conclusion": "OpenPath通过高效样本选择和避免OOD样本，为病理图像分类提供了一种低成本、高性能的主动学习解决方案。"}}
{"id": "2506.15079", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.15079", "abs": "https://arxiv.org/abs/2506.15079", "authors": ["Yikai Hou", "Peng Tang"], "title": "Neural Canonical Polyadic Factorization for Traffic Analysis", "comment": null, "summary": "Modern intelligent transportation systems rely on accurate spatiotemporal traffic analysis to optimize urban mobility and infrastructure resilience. However, pervasive missing data caused by sensor failures and heterogeneous sensing gaps fundamentally hinders reliable traffic modeling. This paper proposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes low-rank tensor algebra with deep representation learning for robust traffic data imputation. The model innovatively embeds CP decomposition into neural architecture through learnable embedding projections, where sparse traffic tensors are encoded into dense latent factors across road segments, time intervals, and mobility metrics. A hierarchical feature fusion mechanism employs Hadamard products to explicitly model multilinear interactions, while stacked multilayer perceptron layers nonlinearly refine these representations to capture complex spatiotemporal couplings. Extensive evaluations on six urban traffic datasets demonstrate NCPF's superiority over six state-of-the-art baselines. By unifying CP decomposition's interpretable factor analysis with neural network's nonlinear expressive power, NCPF provides a principled yet flexible approaches for high-dimensional traffic data imputation, offering critical support for next-generation transportation digital twins and adaptive traffic control systems.", "AI": {"tldr": "论文提出了一种结合低秩张量代数和深度表示学习的NCPF模型，用于交通数据填补，优于现有方法。", "motivation": "交通数据普遍存在缺失问题，影响可靠建模，需一种鲁棒的数据填补方法。", "method": "NCPF模型通过可学习的嵌入投影将稀疏交通张量编码为密集潜在因子，并利用Hadamard积和多层感知机建模复杂时空耦合。", "result": "在六个城市交通数据集上，NCPF优于六种现有基线方法。", "conclusion": "NCPF结合了CP分解的可解释性和神经网络的非线性表达能力，为高维交通数据填补提供了灵活且高效的方法。"}}
{"id": "2506.15368", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15368", "abs": "https://arxiv.org/abs/2506.15368", "authors": ["Niki Amini-Naieni", "Andrew Zisserman"], "title": "Open-World Object Counting in Videos", "comment": null, "summary": "We introduce a new task of open-world object counting in videos: given a text description, or an image example, that specifies the target object, the objective is to enumerate all the unique instances of the target objects in the video. This task is especially challenging in crowded scenes with occlusions and similar objects, where avoiding double counting and identifying reappearances is crucial. To this end, we make the following contributions: we introduce a model, CountVid, for this task. It leverages an image-based counting model, and a promptable video segmentation and tracking model to enable automated, open-world object counting across video frames. To evaluate its performance, we introduce VideoCount, a new dataset for our novel task built from the TAO and MOT20 tracking datasets, as well as from videos of penguins and metal alloy crystallization captured by x-rays. Using this dataset, we demonstrate that CountVid provides accurate object counts, and significantly outperforms strong baselines. The VideoCount dataset, the CountVid model, and all the code are available at https://github.com/niki-amini-naieni/CountVid/.", "AI": {"tldr": "论文提出了一种新任务：视频中的开放世界目标计数，通过文本描述或图像示例指定目标对象，统计视频中所有独特实例。CountVid模型结合图像计数和视频分割跟踪技术，在拥挤场景中表现优异。", "motivation": "解决视频中目标对象在遮挡和相似对象情况下的精确计数问题，避免重复计数和识别重现。", "method": "提出CountVid模型，结合图像计数和可提示视频分割跟踪技术，实现自动化开放世界目标计数。", "result": "在VideoCount数据集上验证，CountVid显著优于基线方法，提供精确计数。", "conclusion": "CountVid和VideoCount数据集为开放世界目标计数任务提供了有效解决方案，代码和数据已开源。"}}
{"id": "2506.15115", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15115", "abs": "https://arxiv.org/abs/2506.15115", "authors": ["Lulu Xue", "Shengshan Hu", "Wei Lu", "Yan Shen", "Dongxu Li", "Peijin Guo", "Ziqi Zhou", "Minghui Li", "Yanjun Zhang", "Leo Yu Zhang"], "title": "Towards Reliable Forgetting: A Survey on Machine Unlearning Verification, Challenges, and Future Directions", "comment": null, "summary": "With growing demands for privacy protection, security, and legal compliance (e.g., GDPR), machine unlearning has emerged as a critical technique for ensuring the controllability and regulatory alignment of machine learning models. However, a fundamental challenge in this field lies in effectively verifying whether unlearning operations have been successfully and thoroughly executed. Despite a growing body of work on unlearning techniques, verification methodologies remain comparatively underexplored and often fragmented. Existing approaches lack a unified taxonomy and a systematic framework for evaluation. To bridge this gap, this paper presents the first structured survey of machine unlearning verification methods. We propose a taxonomy that organizes current techniques into two principal categories -- behavioral verification and parametric verification -- based on the type of evidence used to assess unlearning fidelity. We examine representative methods within each category, analyze their underlying assumptions, strengths, and limitations, and identify potential vulnerabilities in practical deployment. In closing, we articulate a set of open problems in current verification research, aiming to provide a foundation for developing more robust, efficient, and theoretically grounded unlearning verification mechanisms.", "AI": {"tldr": "本文综述了机器学习遗忘验证方法，提出了行为验证和参数验证的分类，并探讨了现有方法的优缺点及潜在漏洞。", "motivation": "随着隐私保护和法规遵从性需求的增长，机器学习遗忘技术的重要性凸显，但验证其执行效果的统一框架尚缺。", "method": "提出分类法，将现有方法分为行为验证和参数验证，分析代表性方法的假设、优势和局限性。", "result": "总结了当前验证方法的不足，并识别了实际部署中的潜在漏洞。", "conclusion": "提出了未来研究的开放性问题，为开发更鲁棒、高效的理论基础验证机制奠定基础。"}}
{"id": "2506.15369", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15369", "abs": "https://arxiv.org/abs/2506.15369", "authors": ["Aleksandr Algasov", "Ekaterina Nepovinnykh", "Fedor Zolotarev", "Tuomas Eerola", "Heikki Kälviäinen", "Pavel Zemčík", "Charles V. Stewart"], "title": "Unsupervised Pelage Pattern Unwrapping for Animal Re-identification", "comment": null, "summary": "Existing individual re-identification methods often struggle with the deformable nature of animal fur or skin patterns which undergo geometric distortions due to body movement and posture changes. In this paper, we propose a geometry-aware texture mapping approach that unwarps pelage patterns, the unique markings found on an animal's skin or fur, into a canonical UV space, enabling more robust feature matching. Our method uses surface normal estimation to guide the unwrapping process while preserving the geometric consistency between the 3D surface and the 2D texture space. We focus on two challenging species: Saimaa ringed seals (Pusa hispida saimensis) and leopards (Panthera pardus). Both species have distinctive yet highly deformable fur patterns. By integrating our pattern-preserving UV mapping with existing re-identification techniques, we demonstrate improved accuracy across diverse poses and viewing angles. Our framework does not require ground truth UV annotations and can be trained in a self-supervised manner. Experiments on seal and leopard datasets show up to a 5.4% improvement in re-identification accuracy.", "AI": {"tldr": "提出了一种几何感知的纹理映射方法，将动物皮毛图案映射到规范UV空间，提升个体重识别的鲁棒性。", "motivation": "现有方法难以处理动物皮毛或皮肤图案因身体运动和姿态变化导致的几何变形。", "method": "使用表面法线估计指导纹理展开，保持3D表面与2D纹理空间的几何一致性，无需真实UV标注，可自监督训练。", "result": "在Saimaa环斑海豹和豹子的数据集上，重识别准确率提升高达5.4%。", "conclusion": "几何感知的纹理映射方法显著提升了动物个体重识别的准确性，尤其在多样姿态和视角下表现优异。"}}
{"id": "2506.15181", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15181", "abs": "https://arxiv.org/abs/2506.15181", "authors": ["Bing Liu", "Chengcheng Zhao", "Li Chai", "Peng Cheng", "Yaonan Wang"], "title": "ImprovDML: Improved Trade-off in Private Byzantine-Resilient Distributed Machine Learning", "comment": null, "summary": "Jointly addressing Byzantine attacks and privacy leakage in distributed machine learning (DML) has become an important issue. A common strategy involves integrating Byzantine-resilient aggregation rules with differential privacy mechanisms. However, the incorporation of these techniques often results in a significant degradation in model accuracy. To address this issue, we propose a decentralized DML framework, named ImprovDML, that achieves high model accuracy while simultaneously ensuring privacy preservation and resilience to Byzantine attacks. The framework leverages a kind of resilient vector consensus algorithms that can compute a point within the normal (non-Byzantine) agents' convex hull for resilient aggregation at each iteration. Then, multivariate Gaussian noises are introduced to the gradients for privacy preservation. We provide convergence guarantees and derive asymptotic learning error bounds under non-convex settings, which are tighter than those reported in existing works. For the privacy analysis, we adopt the notion of concentrated geo-privacy, which quantifies privacy preservation based on the Euclidean distance between inputs. We demonstrate that it enables an improved trade-off between privacy preservation and model accuracy compared to differential privacy. Finally, numerical simulations validate our theoretical results.", "AI": {"tldr": "提出了一种名为ImprovDML的去中心化分布式机器学习框架，兼顾隐私保护和拜占庭攻击抵御，同时保持高模型准确性。", "motivation": "解决现有方法在结合拜占庭攻击抵御和差分隐私机制时导致的模型准确性显著下降问题。", "method": "采用弹性向量共识算法计算正常节点的凸包内点进行聚合，并引入多元高斯噪声保护隐私。", "result": "提供了非凸设置下的收敛保证和更紧的学习误差界，隐私分析采用集中地理隐私概念，优于差分隐私。", "conclusion": "数值模拟验证了理论结果，表明ImprovDML在隐私保护、拜占庭攻击抵御和模型准确性之间实现了更好的权衡。"}}
{"id": "2506.15381", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15381", "abs": "https://arxiv.org/abs/2506.15381", "authors": ["Yujin Kim", "Hyunsoo Kim", "Hyunwoo J. Kim", "Suhyun Kim"], "title": "When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class", "comment": "Published at ICML 2025", "summary": "Open-source pre-trained models hold great potential for diverse applications, but their utility declines when their training data is unavailable. Data-Free Image Synthesis (DFIS) aims to generate images that approximate the learned data distribution of a pre-trained model without accessing the original data. However, existing DFIS meth ods produce samples that deviate from the training data distribution due to the lack of prior knowl edge about natural images. To overcome this limitation, we propose DDIS, the first Diffusion-assisted Data-free Image Synthesis method that leverages a text-to-image diffusion model as a powerful image prior, improving synthetic image quality. DDIS extracts knowledge about the learned distribution from the given model and uses it to guide the diffusion model, enabling the generation of images that accurately align with the training data distribution. To achieve this, we introduce Domain Alignment Guidance (DAG) that aligns the synthetic data domain with the training data domain during the diffusion sampling process. Furthermore, we optimize a single Class Alignment Token (CAT) embedding to effectively capture class-specific attributes in the training dataset. Experiments on PACS and Ima geNet demonstrate that DDIS outperforms prior DFIS methods by generating samples that better reflect the training data distribution, achieving SOTA performance in data-free applications.", "AI": {"tldr": "DDIS是一种基于扩散模型的数据无关图像合成方法，通过引入领域对齐指导和类对齐标记，显著提升了合成图像的质量和与训练数据分布的一致性。", "motivation": "开源预训练模型在训练数据不可用时效用下降，现有数据无关图像合成方法因缺乏自然图像先验知识导致生成样本偏离训练数据分布。", "method": "DDIS利用文本到图像扩散模型作为图像先验，通过领域对齐指导（DAG）和类对齐标记（CAT）优化合成图像与训练数据分布的对齐。", "result": "在PACS和ImageNet上的实验表明，DDIS优于现有方法，生成样本更贴近训练数据分布，实现了数据无关应用的SOTA性能。", "conclusion": "DDIS通过结合扩散模型和领域对齐技术，显著提升了数据无关图像合成的质量和实用性。"}}
{"id": "2506.15190", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2506.15190", "abs": "https://arxiv.org/abs/2506.15190", "authors": ["Jiyi Wang", "Jingyang Ke", "Bo Dai", "Anqi Wu"], "title": "Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors", "comment": "9 pages and 4 figures for the main text", "summary": "Animals flexibly recombine a finite set of core motor primitives to meet diverse task demands, but existing behavior-segmentation methods oversimplify this process by imposing discrete syllables under restrictive generative assumptions. To reflect the animal behavior generation procedure, we introduce skill-based imitation learning (SKIL) for behavior understanding, a reinforcement learning-based imitation framework that (1) infers interpretable skill sets, i.e., latent basis functions of behavior, by leveraging representation learning on transition probabilities, and (2) parameterizes policies as dynamic mixtures of these skills. We validate our approach on a simple grid world, a discrete labyrinth, and unconstrained videos of freely moving animals. Across tasks, it identifies reusable skill components, learns continuously evolving compositional policies, and generates realistic trajectories beyond the capabilities of traditional discrete models. By exploiting generative behavior modeling with compositional representations, our method offers a concise, principled account of how complex animal behaviors emerge from dynamic combinations of fundamental motor primitives.", "AI": {"tldr": "SKIL提出了一种基于技能模仿学习的框架，通过强化学习推断可解释的技能集，并动态组合这些技能生成行为，优于传统离散模型。", "motivation": "现有行为分割方法过于简化动物行为生成过程，未能反映其动态组合核心运动原语的能力。", "method": "SKIL利用表示学习推断潜在技能集，并通过动态混合这些技能参数化策略。", "result": "在网格世界、迷宫和自由运动动物视频中，SKIL成功识别可重用技能组件并生成真实轨迹。", "conclusion": "SKIL为复杂动物行为的动态组合提供了简洁且原则性的解释。"}}
{"id": "2506.15404", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15404", "abs": "https://arxiv.org/abs/2506.15404", "authors": ["Anju Chhetri", "Jari Korhonen", "Prashnna Gyawali", "Binod Bhattarai"], "title": "NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance", "comment": null, "summary": "Ensuring reliability is paramount in deep learning, particularly within the domain of medical imaging, where diagnostic decisions often hinge on model outputs. The capacity to separate out-of-distribution (OOD) samples has proven to be a valuable indicator of a model's reliability in research. In medical imaging, this is especially critical, as identifying OOD inputs can help flag potential anomalies that might otherwise go undetected. While many OOD detection methods rely on feature or logit space representations, recent works suggest these approaches may not fully capture OOD diversity. To address this, we propose a novel OOD scoring mechanism, called NERO, that leverages neuron-level relevance at the feature layer. Specifically, we cluster neuron-level relevance for each in-distribution (ID) class to form representative centroids and introduce a relevance distance metric to quantify a new sample's deviation from these centroids, enhancing OOD separability. Additionally, we refine performance by incorporating scaled relevance in the bias term and combining feature norms. Our framework also enables explainable OOD detection. We validate its effectiveness across multiple deep learning architectures on the gastrointestinal imaging benchmarks Kvasir and GastroVision, achieving improvements over state-of-the-art OOD detection methods.", "AI": {"tldr": "本文提出了一种名为NERO的新型OOD评分机制，通过利用特征层的神经元级相关性来提升OOD检测性能，并在医学影像领域验证了其有效性。", "motivation": "在医学影像领域，确保深度学习模型的可靠性至关重要，尤其是识别OOD样本的能力。现有方法可能无法充分捕捉OOD多样性，因此需要更有效的解决方案。", "method": "提出NERO机制，通过聚类神经元级相关性形成代表性中心，并引入相关性距离度量来量化样本与中心的偏差。结合缩放相关性和特征范数进一步优化性能。", "result": "在胃肠道影像基准测试Kvasir和GastroVision上，NERO优于现有OOD检测方法。", "conclusion": "NERO通过神经元级相关性提升了OOD检测性能，并提供了可解释的检测结果，适用于医学影像领域。"}}
{"id": "2506.15199", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.15199", "abs": "https://arxiv.org/abs/2506.15199", "authors": ["Alejandro Francisco Queiruga", "Theo Gutman-Solo", "Shuai Jiang"], "title": "Interpretability and Generalization Bounds for Learning Spatial Physics", "comment": null, "summary": "While there are many applications of ML to scientific problems that look promising, visuals can be deceiving. For scientific applications, actual quantitative accuracy is crucial. This work applies the rigor of numerical analysis for differential equations to machine learning by specifically quantifying the accuracy of applying different ML techniques to the elementary 1D Poisson differential equation. Beyond the quantity and discretization of data, we identify that the function space of the data is critical to the generalization of the model. We prove generalization bounds and convergence rates under finite data discretizations and restricted training data subspaces by analyzing the training dynamics and deriving optimal parameters for both a white-box differential equation discovery method and a black-box linear model. The analytically derived generalization bounds are replicated empirically. Similar lack of generalization is empirically demonstrated for deep linear models, shallow neural networks, and physics-specific DeepONets and Neural Operators. We theoretically and empirically demonstrate that generalization to the true physical equation is not guaranteed in each explored case. Surprisingly, we find that different classes of models can exhibit opposing generalization behaviors. Based on our theoretical analysis, we also demonstrate a new mechanistic interpretability lens on scientific models whereby Green's function representations can be extracted from the weights of black-box models. Our results inform a new cross-validation technique for measuring generalization in physical systems. We propose applying it to the Poisson equation as an evaluation benchmark of future methods.", "AI": {"tldr": "该论文通过数值分析量化了机器学习在1D泊松微分方程中的准确性，发现数据函数空间对模型泛化至关重要，并提出了新的泛化验证技术。", "motivation": "科学应用中定量准确性至关重要，但现有ML方法在视觉上可能误导，需严格评估其准确性。", "method": "分析训练动态，推导泛化边界和收敛率，验证白盒和黑盒模型的参数优化。", "result": "理论分析和实验验证均显示模型泛化不保证，不同模型可能表现相反行为。", "conclusion": "提出基于格林函数表示的新解释视角，并建议将泊松方程作为未来方法的评估基准。"}}
{"id": "2506.15442", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15442", "abs": "https://arxiv.org/abs/2506.15442", "authors": ["Team Hunyuan3D", "Shuhui Yang", "Mingxin Yang", "Yifei Feng", "Xin Huang", "Sheng Zhang", "Zebin He", "Di Luo", "Haolin Liu", "Yunfei Zhao", "Qingxiang Lin", "Zeqiang Lai", "Xianghui Yang", "Huiwen Shi", "Zibo Zhao", "Bowen Zhang", "Hongyu Yan", "Lifu Wang", "Sicong Liu", "Jihong Zhang", "Meng Chen", "Liang Dong", "Yiwen Jia", "Yulin Cai", "Jiaao Yu", "Yixuan Tang", "Dongyuan Guo", "Junlin Yu", "Hao Zhang", "Zheng Ye", "Peng He", "Runzhou Wu", "Shida Wei", "Chao Zhang", "Yonghao Tan", "Yifu Sun", "Lin Niu", "Shirui Huang", "Bojian Zheng", "Shu Liu", "Shilin Chen", "Xiang Yuan", "Xiaofeng Yang", "Kai Liu", "Jianchen Zhu", "Peng Chen", "Tian Liu", "Di Wang", "Yuhong Liu", "Linus", "Jie Jiang", "Jingwei Huang", "Chunchao Guo"], "title": "Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material", "comment": "Github link: https://github.com/Tencent-Hunyuan/Hunyuan3D-2.1", "summary": "3D AI-generated content (AIGC) is a passionate field that has significantly accelerated the creation of 3D models in gaming, film, and design. Despite the development of several groundbreaking models that have revolutionized 3D generation, the field remains largely accessible only to researchers, developers, and designers due to the complexities involved in collecting, processing, and training 3D models. To address these challenges, we introduce Hunyuan3D 2.1 as a case study in this tutorial. This tutorial offers a comprehensive, step-by-step guide on processing 3D data, training a 3D generative model, and evaluating its performance using Hunyuan3D 2.1, an advanced system for producing high-resolution, textured 3D assets. The system comprises two core components: the Hunyuan3D-DiT for shape generation and the Hunyuan3D-Paint for texture synthesis. We will explore the entire workflow, including data preparation, model architecture, training strategies, evaluation metrics, and deployment. By the conclusion of this tutorial, you will have the knowledge to finetune or develop a robust 3D generative model suitable for applications in gaming, virtual reality, and industrial design.", "AI": {"tldr": "本文介绍了Hunyuan3D 2.1系统，提供了从数据处理到模型训练和评估的完整教程，旨在降低3D AIGC领域的门槛。", "motivation": "3D AIGC领域虽然发展迅速，但由于数据收集、处理和模型训练的复杂性，仍主要限于专业人士。本文旨在通过教程形式解决这一问题。", "method": "使用Hunyuan3D 2.1系统，包括形状生成的Hunyuan3D-DiT和纹理合成的Hunyuan3D-Paint，详细介绍了数据处理、模型架构、训练策略和评估指标。", "result": "教程展示了如何生成高分辨率、带纹理的3D资产，并提供了完整的开发流程。", "conclusion": "通过学习本教程，读者可以掌握开发或优化3D生成模型的技能，适用于游戏、虚拟现实和工业设计等领域。"}}
{"id": "2506.15251", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15251", "abs": "https://arxiv.org/abs/2506.15251", "authors": ["Yee Hin Chong", "Peng Qu"], "title": "Singular Value Decomposition on Kronecker Adaptation for Large Language Model", "comment": null, "summary": "Large pre-trained Transformer models achieve state-of-the-art results across diverse language and reasoning tasks, but full fine-tuning incurs substantial storage, memory, and computational overhead. Parameter-efficient fine-tuning (PEFT) methods mitigate these costs by learning only a small subset of task-specific parameters, yet existing approaches either introduce inference-time latency (adapter modules), suffer from suboptimal convergence (randomly initialized low-rank updates), or rely on fixed rank choices that may not match task complexity (Kronecker-based decompositions).\n  We propose SoKA (SVD on Kronecker Adaptation), a novel PEFT strategy that combines Kronecker-product tensor factorization with SVD-driven initialization and spectrum-aware dynamic rank selection. Our Kronecker-Product SVD (KPSVD) procedure extracts principal components of the full weight update into compact Kronecker factors, while an adaptive rank selection algorithm uses energy-threshold and elbow-point criteria to prune negligible components.\n  Empirical evaluation on LLaMA2-7B across arithmetic reasoning (GSM8K), formal mathematics (MATH), and code generation (MBPP) demonstrates that SoKA requires only 0.99M trainable parameters, 25% fewer than LoRA/PiSSA, while matching or exceeding baseline performance. Moreover, SoKA exhibits faster convergence and more stable gradients, highlighting its robustness and efficiency for large-scale model adaptation.", "AI": {"tldr": "SoKA是一种参数高效微调方法，结合Kronecker分解和SVD初始化，动态选择秩以减少计算开销，性能优于现有方法。", "motivation": "解决全微调的高存储和计算成本，以及现有PEFT方法的延迟、收敛差或固定秩问题。", "method": "结合Kronecker乘积张量分解和SVD初始化，动态选择秩以优化参数效率。", "result": "在LLaMA2-7B上，SoKA仅需0.99M可训练参数，性能优于LoRA/PiSSA，收敛更快。", "conclusion": "SoKA是一种高效、稳健的大规模模型适应方法。"}}
{"id": "2506.15477", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15477", "abs": "https://arxiv.org/abs/2506.15477", "authors": ["Chunlei Li", "Jingyang Hou", "Yilei Shi", "Jingliang Hu", "Xiao Xiang Zhu", "Lichao Mou"], "title": "Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning", "comment": null, "summary": "Medical report generation from imaging data remains a challenging task in clinical practice. While large language models (LLMs) show great promise in addressing this challenge, their effective integration with medical imaging data still deserves in-depth exploration. In this paper, we present MRG-LLM, a novel multimodal large language model (MLLM) that combines a frozen LLM with a learnable visual encoder and introduces a dynamic prompt customization mechanism. Our key innovation lies in generating instance-specific prompts tailored to individual medical images through conditional affine transformations derived from visual features. We propose two implementations: prompt-wise and promptbook-wise customization, enabling precise and targeted report generation. Extensive experiments on IU X-ray and MIMIC-CXR datasets demonstrate that MRG-LLM achieves state-of-the-art performance in medical report generation. Our code will be made publicly available.", "AI": {"tldr": "MRG-LLM是一种新型多模态大语言模型，结合冻结的LLM和可学习的视觉编码器，通过动态提示定制机制生成医学影像报告。", "motivation": "医学影像报告生成在临床实践中仍具挑战性，现有大语言模型与医学影像数据的结合需要深入探索。", "method": "MRG-LLM结合冻结的LLM和可学习视觉编码器，引入动态提示定制机制，通过视觉特征生成实例特定提示。", "result": "在IU X-ray和MIMIC-CXR数据集上，MRG-LLM实现了医学报告生成的最先进性能。", "conclusion": "MRG-LLM通过动态提示定制机制，显著提升了医学影像报告生成的性能。"}}
{"id": "2506.15264", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.15264", "abs": "https://arxiv.org/abs/2506.15264", "authors": ["Mélanie Cambus", "Darya Melnyk", "Tijana Milentijević", "Stefan Schmid"], "title": "Centroid Approximation for Byzantine-Tolerant Federated Learning", "comment": "19 pages, 10 figures", "summary": "Federated learning allows each client to keep its data locally when training machine learning models in a distributed setting. Significant recent research established the requirements that the input must satisfy in order to guarantee convergence of the training loop. This line of work uses averaging as the aggregation rule for the training models. In particular, we are interested in whether federated learning is robust to Byzantine behavior, and observe and investigate a tradeoff between the average/centroid and the validity conditions from distributed computing. We show that the various validity conditions alone do not guarantee a good approximation of the average. Furthermore, we show that reaching good approximation does not give good results in experimental settings due to possible Byzantine outliers. Our main contribution is the first lower bound of $\\min\\{\\frac{n-t}{t},\\sqrt{d}\\}$ on the centroid approximation under box validity that is often considered in the literature, where $n$ is the number of clients, $t$ the upper bound on the number of Byzantine faults, and $d$ is the dimension of the machine learning model. We complement this lower bound by an upper bound of $2\\min\\{n,\\sqrt{d}\\}$, by providing a new analysis for the case $n<d$. In addition, we present a new algorithm that achieves a $\\sqrt{2d}$-approximation under convex validity, which also proves that the existing lower bound in the literature is tight. We show that all presented bounds can also be achieved in the distributed peer-to-peer setting. We complement our analytical results with empirical evaluations in federated stochastic gradient descent and federated averaging settings.", "AI": {"tldr": "本文研究了联邦学习中拜占庭行为对模型聚合的影响，提出了关于中心点近似的新下界和上界，并设计了一种新算法。", "motivation": "探讨联邦学习在拜占庭行为下的鲁棒性，分析平均聚合与分布式计算中有效性条件的权衡。", "method": "通过理论分析提出中心点近似的下界和上界，设计新算法实现凸有效性条件下的近似。", "result": "证明了中心点近似的下界为min{(n-t)/t,√d}，上界为2min{n,√d}，并展示了新算法的有效性。", "conclusion": "研究揭示了联邦学习中拜占庭行为对模型聚合的挑战，为未来研究提供了理论支持。"}}
{"id": "2506.15483", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15483", "abs": "https://arxiv.org/abs/2506.15483", "authors": ["Shujia Li", "Haiyu Zhang", "Xinyuan Chen", "Yaohui Wang", "Yutong Ban"], "title": "GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects", "comment": null, "summary": "While diffusion models and large-scale motion datasets have advanced text-driven human motion synthesis, extending these advances to 4D human-object interaction (HOI) remains challenging, mainly due to the limited availability of large-scale 4D HOI datasets. In our study, we introduce GenHOI, a novel two-stage framework aimed at achieving two key objectives: 1) generalization to unseen objects and 2) the synthesis of high-fidelity 4D HOI sequences. In the initial stage of our framework, we employ an Object-AnchorNet to reconstruct sparse 3D HOI keyframes for unseen objects, learning solely from 3D HOI datasets, thereby mitigating the dependence on large-scale 4D HOI datasets. Subsequently, we introduce a Contact-Aware Diffusion Model (ContactDM) in the second stage to seamlessly interpolate sparse 3D HOI keyframes into densely temporally coherent 4D HOI sequences. To enhance the quality of generated 4D HOI sequences, we propose a novel Contact-Aware Encoder within ContactDM to extract human-object contact patterns and a novel Contact-Aware HOI Attention to effectively integrate the contact signals into diffusion models. Experimental results show that we achieve state-of-the-art results on the publicly available OMOMO and 3D-FUTURE datasets, demonstrating strong generalization abilities to unseen objects, while enabling high-fidelity 4D HOI generation.", "AI": {"tldr": "GenHOI是一个两阶段框架，用于生成未见物体的高保真4D人-物交互序列，通过Object-AnchorNet和ContactDM实现，减少对大规模4D数据集的依赖。", "motivation": "由于缺乏大规模4D人-物交互数据集，现有方法难以推广到未见物体并生成高质量4D序列。", "method": "第一阶段使用Object-AnchorNet从3D数据重建稀疏关键帧；第二阶段通过ContactDM插值生成密集4D序列，结合接触感知编码器和注意力机制。", "result": "在OMOMO和3D-FUTURE数据集上取得最优结果，展示了对未见物体的强泛化能力和高质量4D生成。", "conclusion": "GenHOI通过两阶段设计和接触感知机制，有效解决了4D人-物交互生成的挑战。"}}
{"id": "2506.15271", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15271", "abs": "https://arxiv.org/abs/2506.15271", "authors": ["Bihe Zhao", "Pratyush Maini", "Franziska Boenisch", "Adam Dziedzic"], "title": "Unlocking Post-hoc Dataset Inference with Synthetic Data", "comment": "Accepted at ICML 2025", "summary": "The remarkable capabilities of Large Language Models (LLMs) can be mainly attributed to their massive training datasets, which are often scraped from the internet without respecting data owners' intellectual property rights. Dataset Inference (DI) offers a potential remedy by identifying whether a suspect dataset was used in training, thereby enabling data owners to verify unauthorized use. However, existing DI methods require a private set-known to be absent from training-that closely matches the compromised dataset's distribution. Such in-distribution, held-out data is rarely available in practice, severely limiting the applicability of DI. In this work, we address this challenge by synthetically generating the required held-out set. Our approach tackles two key obstacles: (1) creating high-quality, diverse synthetic data that accurately reflects the original distribution, which we achieve via a data generator trained on a carefully designed suffix-based completion task, and (2) bridging likelihood gaps between real and synthetic data, which is realized through post-hoc calibration. Extensive experiments on diverse text datasets show that using our generated data as a held-out set enables DI to detect the original training sets with high confidence, while maintaining a low false positive rate. This result empowers copyright owners to make legitimate claims on data usage and demonstrates our method's reliability for real-world litigations. Our code is available at https://github.com/sprintml/PostHocDatasetInference.", "AI": {"tldr": "论文提出了一种通过合成数据生成的方法，解决了数据集推断（DI）中需要私有未训练数据的限制，从而帮助数据所有者验证未经授权的使用。", "motivation": "现有DI方法需要与受侵害数据集分布匹配的私有未训练数据，这在实践中难以获取，限制了DI的适用性。", "method": "通过设计基于后缀补全任务的数据生成器生成高质量合成数据，并通过后校准弥合真实与合成数据的似然差距。", "result": "实验表明，生成的合成数据作为未训练集能高置信度检测原始训练集，同时保持低误报率。", "conclusion": "该方法为版权所有者提供了可靠的数据使用验证手段，适用于现实法律诉讼。"}}
{"id": "2506.15524", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15524", "abs": "https://arxiv.org/abs/2506.15524", "authors": ["Florin-Alexandru Vasluianu", "Tim Seizinger", "Zhuyun Zhou", "Cailian Chen", "Zongwei Wu", "Radu Timofte", "Mingjia Li", "Jin Hu", "Hainuo Wang", "Hengxing Liu", "Jiarui Wang", "Qiming Hu", "Xiaojie Guo", "Xin Lu", "Jiarong Yang", "Yuanfei Bao", "Anya Hu", "Zihao Fan", "Kunyu Wang", "Jie Xiao", "Xi Wang", "Xueyang Fu", "Zheng-Jun Zha", "Yu-Fan Lin", "Chia-Ming Lee", "Chih-Chung Hsu", "Xingbo Wang", "Dong Li", "Yuxu Chen", "Bin Chen", "Yuanbo Zhou", "Yuanbin Chen", "Hongwei Wang", "Jiannan Lin", "Qinquan Gao", "Tong Tong", "Zhao Zhang", "Yanyan Wei", "Wei Dong", "Han Zhou", "Seyed Amirreza Mousavi", "Jun Chen", "Haobo Liang", "Jiajie Jing", "Junyu Li", "Yan Yang", "Seoyeon Lee", "Chaewon Kim", "Ziyu Feng", "Shidi Chen", "Bowen Luan", "Zewen Chen", "Vijayalaxmi Ashok Aralikatti", "G Gyaneshwar Rao", "Nikhil Akalwadi", "Chaitra Desai", "Ramesh Ashok Tabib", "Uma Mudenagudi", "Anas M. Ali", "Bilel Benjdira", "Wadii Boulila", "Alexandru Brateanu", "Cosmin Ancuti", "Tanmay Chaturvedi", "Manish Kumar", "Anmol Srivastav", "Daksh Trivedi", "Shashwat Thakur", "Kishor Upla", "Zeyu Xiao", "Zhuoyuan Li", "Boda Zhou", "Shashank Shekhar", "Kele Xu", "Qisheng Xu", "Zijian Gao", "Tianjiao Wan", "Suiyi Zhao", "Bo Wang", "Yan Luo", "Mingshen Wang", "Yilin Zhang"], "title": "NTIRE 2025 Image Shadow Removal Challenge Report", "comment": null, "summary": "This work examines the findings of the NTIRE 2025 Shadow Removal Challenge. A total of 306 participants have registered, with 17 teams successfully submitting their solutions during the final evaluation phase. Following the last two editions, this challenge had two evaluation tracks: one focusing on reconstruction fidelity and the other on visual perception through a user study. Both tracks were evaluated with images from the WSRD+ dataset, simulating interactions between self- and cast-shadows with a large number of diverse objects, textures, and materials.", "AI": {"tldr": "NTIRE 2025阴影去除挑战赛的结果分析，306名参与者中17支团队提交了解决方案，分为重建保真度和视觉感知两个评估轨道。", "motivation": "研究阴影去除技术的最新进展，并通过挑战赛形式评估不同方法的性能。", "method": "使用WSRD+数据集，模拟自阴影和投射阴影的交互，评估重建保真度和视觉感知（用户研究）。", "result": "17支团队成功提交解决方案，挑战赛展示了多样化的阴影去除方法。", "conclusion": "NTIRE 2025挑战赛为阴影去除领域提供了新的技术参考和评估标准。"}}
{"id": "2506.15289", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.15289", "abs": "https://arxiv.org/abs/2506.15289", "authors": ["Chuan Li", "Shunyu Zhao", "Vincent Gauthier", "Hassine Moungla"], "title": "DOVA-PATBM: An Intelligent, Adaptive, and Scalable Framework for Optimizing Large-Scale EV Charging Infrastructure", "comment": null, "summary": "The accelerating uptake of battery-electric vehicles demands infrastructure planning tools that are both data-rich and geographically scalable. Whereas most prior studies optimise charging locations for single cities, state-wide and national networks must reconcile the conflicting requirements of dense metropolitan cores, car-dependent exurbs, and power-constrained rural corridors.\n  We present DOVA-PATBM (Deployment Optimisation with Voronoi-oriented, Adaptive, POI-Aware Temporal Behaviour Model), a geo-computational framework that unifies these contexts in a single pipeline. The method rasterises heterogeneous data (roads, population, night lights, POIs, and feeder lines) onto a hierarchical H3 grid, infers intersection importance with a zone-normalised graph neural network centrality model, and overlays a Voronoi tessellation that guarantees at least one five-port DC fast charger within every 30 km radius. Hourly arrival profiles, learned from loop-detector and floating-car traces, feed a finite M/M/c queue to size ports under feeder-capacity and outage-risk constraints. A greedy maximal-coverage heuristic with income-weighted penalties then selects the minimum number of sites that satisfy coverage and equity targets.\n  Applied to the State of Georgia, USA, DOVA-PATBM (i) increases 30 km tile coverage by 12 percentage points, (ii) halves the mean distance that low-income residents travel to the nearest charger, and (iii) meets sub-transmission headroom everywhere -- all while remaining computationally tractable for national-scale roll-outs. These results demonstrate that a tightly integrated, GNN-driven, multi-resolution approach can bridge the gap between academic optimisation and deployable infrastructure policy.", "AI": {"tldr": "DOVA-PATBM是一种地理计算框架，用于优化电动汽车充电站部署，结合多种数据源和算法，实现覆盖率和公平性目标。", "motivation": "随着电动汽车的普及，需要一种能够在不同地理尺度（如城市、州和国家）上优化充电站部署的工具，以解决城市核心区、郊区和农村地区的不同需求。", "method": "方法包括：1）将异构数据栅格化到H3网格；2）使用图神经网络中心性模型推断交叉点重要性；3）通过Voronoi分割确保每30公里半径内至少有一个快充站；4）基于车辆轨迹数据学习每小时到达率，并使用有限队列模型确定端口规模；5）采用贪婪最大覆盖启发式算法选择站点。", "result": "在佐治亚州的应用中，DOVA-PATBM将30公里覆盖范围提高了12个百分点，低收入居民到最近充电站的平均距离减半，同时满足电力容量限制。", "conclusion": "DOVA-PATBM展示了紧密结合图神经网络和多分辨率方法的能力，为可部署的基础设施政策提供了桥梁。"}}
{"id": "2506.15549", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15549", "abs": "https://arxiv.org/abs/2506.15549", "authors": ["Farheen Ramzan", "Yusuf Kiberu", "Nikesh Jathanna", "Shahnaz Jamil-Copley", "Richard H. Clayton", "Chen", "Chen"], "title": "CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation", "comment": "14 Pages", "summary": "Deep learning-based myocardial scar segmentation from late gadolinium enhancement (LGE) cardiac MRI has shown great potential for accurate and timely diagnosis and treatment planning for structural cardiac diseases. However, the limited availability and variability of LGE images with high-quality scar labels restrict the development of robust segmentation models. To address this, we introduce CLAIM: \\textbf{C}linically-Guided \\textbf{L}GE \\textbf{A}ugmentation for Real\\textbf{i}stic and Diverse \\textbf{M}yocardial Scar Synthesis and Segmentation framework, a framework for anatomically grounded scar generation and segmentation. At its core is the SMILE module (Scar Mask generation guided by cLinical knowledgE), which conditions a diffusion-based generator on the clinically adopted AHA 17-segment model to synthesize images with anatomically consistent and spatially diverse scar patterns. In addition, CLAIM employs a joint training strategy in which the scar segmentation network is optimized alongside the generator, aiming to enhance both the realism of synthesized scars and the accuracy of the scar segmentation performance. Experimental results show that CLAIM produces anatomically coherent scar patterns and achieves higher Dice similarity with real scar distributions compared to baseline models. Our approach enables controllable and realistic myocardial scar synthesis and has demonstrated utility for downstream medical imaging task.", "AI": {"tldr": "CLAIM框架通过临床知识引导的LGE增强和扩散模型生成逼真的心肌瘢痕图像，并结合联合训练策略提升分割性能。", "motivation": "解决LGE图像稀缺和标签质量不一的问题，以支持心肌瘢痕的准确分割。", "method": "引入SMILE模块，基于AHA 17段模型生成解剖学一致的瘢痕图像，并采用联合训练优化分割网络。", "result": "生成的瘢痕图像解剖学一致，分割性能优于基线模型。", "conclusion": "CLAIM框架能生成可控且逼真的心肌瘢痕，对下游医学影像任务有实用价值。"}}
{"id": "2506.15305", "categories": ["cs.LG", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2506.15305", "abs": "https://arxiv.org/abs/2506.15305", "authors": ["Qingkai Zhang", "L. Jeff Hong", "Houmin Yan"], "title": "Conditional Generative Modeling for Enhanced Credit Risk Management in Supply Chain Finance", "comment": null, "summary": "The rapid expansion of cross-border e-commerce (CBEC) has created significant opportunities for small and medium-sized enterprises (SMEs), yet financing remains a critical challenge due to SMEs' limited credit histories. Third-party logistics (3PL)-led supply chain finance (SCF) has emerged as a promising solution, leveraging in-transit inventory as collateral. We propose an advanced credit risk management framework tailored for 3PL-led SCF, addressing the dual challenges of credit risk assessment and loan size determination. Specifically, we leverage conditional generative modeling of sales distributions through Quantile-Regression-based Generative Metamodeling (QRGMM) as the foundation for risk estimation. We propose a unified framework that enables flexible estimation of multiple risk measures while introducing a functional risk measure formulation that systematically captures the relationship between these risk measures and varying loan levels, supported by theoretical guarantees. To capture complex covariate interactions in e-commerce sales data, we integrate QRGMM with Deep Factorization Machines (DeepFM). Extensive experiments on synthetic and real-world data validate the efficacy of our model for credit risk assessment and loan size determination. This study represents a pioneering application of generative AI in CBEC SCF risk management, offering a solid foundation for enhanced credit practices and improved SME access to capital.", "AI": {"tldr": "本文提出了一种基于生成AI的信用风险管理框架，用于解决跨境电商供应链金融中的信用风险评估和贷款规模确定问题。", "motivation": "跨境电商为中小企业提供了机会，但融资问题因信用记录有限而成为挑战。第三方物流主导的供应链金融利用在途库存作为抵押，但需要更先进的信用风险管理方法。", "method": "采用基于分位数回归的生成元模型（QRGMM）和深度分解机（DeepFM）结合的方法，构建统一框架，灵活估计多种风险度量。", "result": "通过合成和实际数据实验验证了模型在信用风险评估和贷款规模确定方面的有效性。", "conclusion": "该研究是生成AI在跨境电商供应链金融风险管理中的开创性应用，为提升信用实践和中小企业融资提供了基础。"}}
{"id": "2506.15307", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15307", "abs": "https://arxiv.org/abs/2506.15307", "authors": ["Jinglong Luo", "Zhuo Zhang", "Yehong Zhang", "Shiyu Liu", "Ye Dong", "Xun Zhou", "Hui Wang", "Yue Yu", "Zenglin Xu"], "title": "SecFwT: Efficient Privacy-Preserving Fine-Tuning of Large Language Models Using Forward-Only Passes", "comment": null, "summary": "Large language models (LLMs) have transformed numerous fields, yet their adaptation to specialized tasks in privacy-sensitive domains, such as healthcare and finance, is constrained by the scarcity of accessible training data due to stringent privacy requirements. Secure multi-party computation (MPC)-based privacy-preserving machine learning offers a powerful approach to protect both model parameters and user data, but its application to LLMs has been largely limited to inference, as fine-tuning introduces significant computational challenges, particularly in privacy-preserving backward propagation and optimizer operations. This paper identifies two primary obstacles to MPC-based privacy-preserving fine-tuning of LLMs: (1) the substantial computational overhead of backward and optimizer processes, and (2) the inefficiency of softmax-based attention mechanisms in MPC settings. To address these challenges, we propose SecFwT, the first MPC-based framework designed for efficient, privacy-preserving LLM fine-tuning. SecFwT introduces a forward-only tuning paradigm to eliminate backward and optimizer computations and employs MPC-friendly Random Feature Attention to approximate softmax attention, significantly reducing costly non-linear operations and computational complexity. Experimental results demonstrate that SecFwT delivers substantial improvements in efficiency and privacy preservation, enabling scalable and secure fine-tuning of LLMs for privacy-critical applications.", "AI": {"tldr": "SecFwT是首个基于MPC的高效隐私保护LLM微调框架，通过前向调优和随机特征注意力解决计算复杂性和隐私问题。", "motivation": "LLM在隐私敏感领域（如医疗和金融）的应用受限于数据隐私要求，MPC虽能保护隐私，但微调时计算开销大。", "method": "提出SecFwT框架，采用前向调优和MPC友好的随机特征注意力，避免反向传播和优化器计算。", "result": "实验表明SecFwT显著提升效率和隐私保护，支持隐私关键应用的LLM微调。", "conclusion": "SecFwT为隐私敏感领域的LLM微调提供了高效、安全的解决方案。"}}
{"id": "2506.15563", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15563", "abs": "https://arxiv.org/abs/2506.15563", "authors": ["Bonan Li", "Yinhan Hu", "Songhua Liu", "Xinchao Wang"], "title": "Control and Realism: Best of Both Worlds in Layout-to-Image without Training", "comment": "Accepted by ICML2025", "summary": "Layout-to-Image generation aims to create complex scenes with precise control over the placement and arrangement of subjects. Existing works have demonstrated that pre-trained Text-to-Image diffusion models can achieve this goal without training on any specific data; however, they often face challenges with imprecise localization and unrealistic artifacts. Focusing on these drawbacks, we propose a novel training-free method, WinWinLay. At its core, WinWinLay presents two key strategies, Non-local Attention Energy Function and Adaptive Update, that collaboratively enhance control precision and realism. On one hand, we theoretically demonstrate that the commonly used attention energy function introduces inherent spatial distribution biases, hindering objects from being uniformly aligned with layout instructions. To overcome this issue, non-local attention prior is explored to redistribute attention scores, facilitating objects to better conform to the specified spatial conditions. On the other hand, we identify that the vanilla backpropagation update rule can cause deviations from the pre-trained domain, leading to out-of-distribution artifacts. We accordingly introduce a Langevin dynamics-based adaptive update scheme as a remedy that promotes in-domain updating while respecting layout constraints. Extensive experiments demonstrate that WinWinLay excels in controlling element placement and achieving photorealistic visual fidelity, outperforming the current state-of-the-art methods.", "AI": {"tldr": "WinWinLay是一种无需训练的方法，通过非局部注意力能量函数和自适应更新策略，提升布局到图像生成的精确性和真实性。", "motivation": "现有基于预训练文本到图像扩散模型的方法在布局控制上存在定位不精确和伪影问题，WinWinLay旨在解决这些问题。", "method": "提出非局部注意力能量函数以消除空间分布偏差，并采用基于Langevin动力学的自适应更新规则避免域外伪影。", "result": "实验表明WinWinLay在元素布局控制和视觉逼真度上优于现有方法。", "conclusion": "WinWinLay通过理论分析和创新策略，显著提升了布局到图像生成的性能。"}}
{"id": "2506.15309", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2506.15309", "abs": "https://arxiv.org/abs/2506.15309", "authors": ["Júlia Vilalta-Mor", "Alexis Molina", "Laura Ortega Varga", "Isaac Filella-Merce", "Victor Guallar"], "title": "Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation", "comment": "16 pages, 7 figures", "summary": "Simultaneously optimizing molecules against multiple therapeutic targets remains a profound challenge in drug discovery, particularly due to sparse rewards and conflicting design constraints. We propose a structured active learning (AL) paradigm integrating a sequence-to-sequence (Seq2Seq) variational autoencoder (VAE) into iterative loops designed to balance chemical diversity, molecular quality, and multi-target affinity. Our method alternates between expanding chemically feasible regions of latent space and progressively constraining molecules based on increasingly stringent multi-target docking thresholds. In a proof-of-concept study targeting three related coronavirus main proteases (SARS-CoV-2, SARS-CoV, MERS-CoV), our approach efficiently generated a structurally diverse set of pan-inhibitor candidates. We demonstrate that careful timing and strategic placement of chemical filters within this active learning pipeline markedly enhance exploration of beneficial chemical space, transforming the sparse-reward, multi-objective drug design problem into an accessible computational task. Our framework thus provides a generalizable roadmap for efficiently navigating complex polypharmacological landscapes.", "AI": {"tldr": "提出了一种结合序列到序列变分自编码器和主动学习的结构化方法，用于多目标药物分子设计，成功生成了针对三种冠状病毒主蛋白酶的泛抑制剂候选分子。", "motivation": "多目标药物分子设计面临稀疏奖励和冲突设计约束的挑战，需要一种高效的方法来平衡化学多样性、分子质量和多靶点亲和力。", "method": "结合序列到序列变分自编码器和主动学习，交替扩展化学可行的潜在空间区域，并逐步约束分子以满足多靶点对接阈值。", "result": "在针对三种冠状病毒主蛋白酶的实验中，成功生成了结构多样的泛抑制剂候选分子，验证了方法的有效性。", "conclusion": "该方法为复杂多靶点药物设计提供了一种通用且高效的解决方案。"}}
{"id": "2506.15564", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15564", "abs": "https://arxiv.org/abs/2506.15564", "authors": ["Jinheng Xie", "Zhenheng Yang", "Mike Zheng Shou"], "title": "Show-o2: Improved Native Unified Multimodal Models", "comment": "Technical report", "summary": "This paper presents improved native unified multimodal models, \\emph{i.e.,} Show-o2, that leverage autoregressive modeling and flow matching. Built upon a 3D causal variational autoencoder space, unified visual representations are constructed through a dual-path of spatial (-temporal) fusion, enabling scalability across image and video modalities while ensuring effective multimodal understanding and generation. Based on a language model, autoregressive modeling and flow matching are natively applied to the language head and flow head, respectively, to facilitate text token prediction and image/video generation. A two-stage training recipe is designed to effectively learn and scale to larger models. The resulting Show-o2 models demonstrate versatility in handling a wide range of multimodal understanding and generation tasks across diverse modalities, including text, images, and videos. Code and models are released at https://github.com/showlab/Show-o.", "AI": {"tldr": "Show-o2是一种改进的多模态模型，结合自回归建模和流匹配，支持图像和视频的多模态理解与生成。", "motivation": "通过统一视觉表示和跨模态扩展，提升多模态任务的处理能力。", "method": "基于3D因果变分自编码器空间，采用双路径时空融合构建统一表示，并结合自回归建模和流匹配技术。", "result": "Show-o2在文本、图像和视频的多模态任务中表现出色。", "conclusion": "该模型在多模态理解和生成任务中具有广泛适用性，代码和模型已开源。"}}
{"id": "2506.15329", "categories": ["cs.LG", "cs.AI", "cs.CL", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.15329", "abs": "https://arxiv.org/abs/2506.15329", "authors": ["Yingcong Li", "Xiangyu Chang", "Muti Kara", "Xiaofeng Liu", "Amit Roy-Chowdhury", "Samet Oymak"], "title": "When and How Unlabeled Data Provably Improve In-Context Learning", "comment": null, "summary": "Recent research shows that in-context learning (ICL) can be effective even when demonstrations have missing or incorrect labels. To shed light on this capability, we examine a canonical setting where the demonstrations are drawn according to a binary Gaussian mixture model (GMM) and a certain fraction of the demonstrations have missing labels. We provide a comprehensive theoretical study to show that: (1) The loss landscape of one-layer linear attention models recover the optimal fully-supervised estimator but completely fail to exploit unlabeled data; (2) In contrast, multilayer or looped transformers can effectively leverage unlabeled data by implicitly constructing estimators of the form $\\sum_{i\\ge 0} a_i (X^\\top X)^iX^\\top y$ with $X$ and $y$ denoting features and partially-observed labels (with missing entries set to zero). We characterize the class of polynomials that can be expressed as a function of depth and draw connections to Expectation Maximization, an iterative pseudo-labeling algorithm commonly used in semi-supervised learning. Importantly, the leading polynomial power is exponential in depth, so mild amount of depth/looping suffices. As an application of theory, we propose looping off-the-shelf tabular foundation models to enhance their semi-supervision capabilities. Extensive evaluations on real-world datasets show that our method significantly improves the semisupervised tabular learning performance over the standard single pass inference.", "AI": {"tldr": "论文研究了上下文学习（ICL）在标签缺失或错误时的有效性，通过理论分析展示了不同模型结构对未标记数据的利用能力，并提出了一种改进半监督学习的方法。", "motivation": "探索上下文学习在标签不完整情况下的表现，并揭示其背后的理论机制。", "method": "使用二元高斯混合模型（GMM）生成演示数据，分析单层线性注意力模型和多层/循环Transformer的表现。", "result": "单层模型无法利用未标记数据，而多层/循环模型能通过多项式估计器有效利用未标记数据，且深度对性能有指数级提升。", "conclusion": "通过循环现成的表格基础模型，可以显著提升半监督学习性能，实验验证了理论的有效性。"}}
{"id": "2506.15565", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15565", "abs": "https://arxiv.org/abs/2506.15565", "authors": ["Junhao Wu", "Aboagye-Ntow Stephen", "Chuyuan Wang", "Gang Chen", "Xin Huang"], "title": "Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification", "comment": null, "summary": "Ultra-high Spatial Resolution Land Cover Classification is essential for fine-grained land cover analysis, yet it remains challenging due to the high cost of pixel-level annotations, significant scale variation, and the limited adaptability of large-scale vision models. Existing methods typically focus on 1-meter spatial resolution imagery and rely heavily on annotated data, whereas practical applications often require processing higher-resolution imagery under weak supervision. To address this, we propose a parameter-efficient semi-supervised segmentation framework for 0.3 m spatial resolution imagery, which leverages the knowledge of SAM2 and introduces a remote sensing-specific FreqWeaver Adapter to enhance fine-grained detail modeling while maintaining a lightweight design at only 5.96% of the total model parameters. By effectively leveraging unlabeled data and maintaining minimal parameter overhead, the proposed method delivers robust segmentation results with superior structural consistency, achieving a 1.78% improvement over existing parameter-efficient tuning strategies and a 3.44% gain compared to state-of-the-art high-resolution remote sensing segmentation approaches.", "AI": {"tldr": "提出了一种参数高效的半监督分割框架，用于0.3米空间分辨率影像，结合SAM2知识和遥感专用FreqWeaver适配器，显著提升了细粒度细节建模能力。", "motivation": "超高空间分辨率土地覆盖分类面临标注成本高、尺度变化大和大规模视觉模型适应性有限等挑战，现有方法多依赖标注数据且仅适用于1米分辨率影像。", "method": "采用半监督分割框架，结合SAM2知识，引入遥感专用FreqWeaver适配器，仅占用总参数的5.96%。", "result": "在未标注数据的有效利用和低参数开销下，实现了结构一致性更强的分割结果，性能优于现有参数高效调优策略1.78%，优于最先进高分辨率遥感分割方法3.44%。", "conclusion": "该方法在超高分辨率遥感影像分割中表现出色，兼顾了性能和效率。"}}
{"id": "2506.15330", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2506.15330", "abs": "https://arxiv.org/abs/2506.15330", "authors": ["Pavel Karpov", "Ilya Petrenkov", "Ruslan Raiman"], "title": "Universal Laboratory Model: prognosis of abnormal clinical outcomes based on routine tests", "comment": "7 pages, 2 figues", "summary": "Clinical laboratory results are ubiquitous in any diagnosis making. Predicting abnormal values of not prescribed tests based on the results of performed tests looks intriguing, as it would be possible to make early diagnosis available to everyone. The special place is taken by the Common Blood Count (CBC) test, as it is the most widely used clinical procedure. Combining routine biochemical panels with CBC presents a set of test-value pairs that varies from patient to patient, or, in common settings, a table with missing values. Here we formulate a tabular modeling problem as a set translation problem where the source set comprises pairs of GPT-like label column embedding and its corresponding value while the target set consists of the same type embeddings only. The proposed approach can effectively deal with missing values without implicitly estimating them and bridges the world of LLM with the tabular domain. Applying this method to clinical laboratory data, we achieve an improvement up to 8% AUC for joint predictions of high uric acid, glucose, cholesterol, and low ferritin levels.", "AI": {"tldr": "论文提出了一种基于表格数据的集合翻译方法，用于预测未检测的临床检验异常值，结合CBC和生化检验数据，提升预测性能。", "motivation": "临床检验结果对诊断至关重要，预测未检测项目的异常值可早期诊断。CBC是最常用的检验，但数据常存在缺失值，需有效处理方法。", "method": "将表格建模问题转化为集合翻译问题，源集合为标签列嵌入和对应值，目标集合为相同类型的嵌入，无需隐式估计缺失值。", "result": "在临床实验室数据上应用，对高尿酸、高血糖、高胆固醇和低铁蛋白的联合预测AUC提升达8%。", "conclusion": "该方法有效处理缺失值，连接LLM与表格数据领域，提升临床检验预测性能。"}}
{"id": "2506.15577", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15577", "abs": "https://arxiv.org/abs/2506.15577", "authors": ["Di Wang", "Shi Li"], "title": "A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds", "comment": "17 pages,19 figures", "summary": "Estimating forest above-ground biomass (AGB) is crucial for assessing carbon storage and supporting sustainable forest management. Quantitative Structural Model (QSM) offers a non-destructive approach to AGB estimation through 3D tree structural reconstruction. However, current QSM methods face significant limitations, as they are primarily designed for individual trees,depend on high-quality point cloud data from terrestrial laser scanning (TLS), and also require multiple pre-processing steps that hinder scalability and practical deployment. This study presents a novel unified framework that enables end-to-end processing of large-scale point clouds using an innovative graph-based pipeline. The proposed approach seamlessly integrates tree segmentation,leaf-wood separation and 3D skeletal reconstruction through dedicated graph operations including pathing and abstracting for tree topology reasoning. Comprehensive validation was conducted on datasets with varying leaf conditions (leaf-on and leaf-off), spatial scales (tree- and plot-level), and data sources (TLS and UAV-based laser scanning, ULS). Experimental results demonstrate strong performance under challenging conditions, particularly in leaf-on scenarios (~20% relative error) and low-density ULS datasets with partial coverage (~30% relative error). These findings indicate that the proposed framework provides a robust and scalable solution for large-scale, non-destructive AGB estimation. It significantly reduces dependency on specialized pre-processing tools and establishes ULS as a viable alternative to TLS. To our knowledge, this is the first method capable of enabling seamless, end-to-end 3D tree reconstruction at operational scales. This advancement substantially improves the feasibility of QSM-based AGB estimation, paving the way for broader applications in forest inventory and climate change research.", "AI": {"tldr": "提出了一种基于图的新型统一框架，用于大规模点云的端到端处理，显著提升了森林地上生物量（AGB）估计的可行性和可扩展性。", "motivation": "当前定量结构模型（QSM）方法依赖高质量点云数据和复杂预处理步骤，限制了其可扩展性和实际应用。", "method": "通过创新的基于图的流程，集成了树木分割、叶木分离和3D骨架重建，减少了预处理依赖。", "result": "在多种条件下（如叶覆盖、低密度点云）表现优异，相对误差低至20%-30%，验证了其鲁棒性和可扩展性。", "conclusion": "该框架为大规模AGB估计提供了高效解决方案，推动了森林调查和气候变化研究的应用。"}}
{"id": "2506.15337", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2506.15337", "abs": "https://arxiv.org/abs/2506.15337", "authors": ["Naoki Matsumura", "Yuta Yoshimoto", "Yuto Iwasaki", "Meguru Yamazaki", "Yasufumi Sakai"], "title": "Knowledge Distillation Framework for Accelerating High-Accuracy Neural Network-Based Molecular Dynamics Simulations", "comment": null, "summary": "Neural network potentials (NNPs) offer a powerful alternative to traditional force fields for molecular dynamics (MD) simulations. Accurate and stable MD simulations, crucial for evaluating material properties, require training data encompassing both low-energy stable structures and high-energy structures. Conventional knowledge distillation (KD) methods fine-tune a pre-trained NNP as a teacher model to generate training data for a student model. However, in material-specific models, this fine-tuning process increases energy barriers, making it difficult to create training data containing high-energy structures. To address this, we propose a novel KD framework that leverages a non-fine-tuned, off-the-shelf pre-trained NNP as a teacher. Its gentler energy landscape facilitates the exploration of a wider range of structures, including the high-energy structures crucial for stable MD simulations. Our framework employs a two-stage training process: first, the student NNP is trained with a dataset generated by the off-the-shelf teacher; then, it is fine-tuned with a smaller, high-accuracy density functional theory (DFT) dataset. We demonstrate the effectiveness of our framework by applying it to both organic (polyethylene glycol) and inorganic (L$_{10}$GeP$_{2}$S$_{12}$) materials, achieving comparable or superior accuracy in reproducing physical properties compared to existing methods. Importantly, our method reduces the number of expensive DFT calculations by 10x compared to existing NNP generation methods, without sacrificing accuracy.", "AI": {"tldr": "提出一种新型知识蒸馏框架，利用未微调的预训练NNP作为教师模型，生成包含高能结构的训练数据，减少DFT计算需求。", "motivation": "传统知识蒸馏方法在材料特定模型中会提高能量壁垒，难以生成高能结构训练数据，影响分子动力学模拟的稳定性。", "method": "采用两阶段训练：先用未微调教师模型生成数据训练学生NNP，再用少量高精度DFT数据微调。", "result": "在有机和无机材料上均取得优于或可比现有方法的精度，同时将DFT计算量减少10倍。", "conclusion": "新框架有效解决了高能结构生成问题，显著降低了计算成本，适用于多种材料体系。"}}
{"id": "2506.15591", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15591", "abs": "https://arxiv.org/abs/2506.15591", "authors": ["Yujing Sun", "Lingchen Sun", "Shuaizheng Liu", "Rongyuan Wu", "Zhengqiang Zhang", "Lei Zhang"], "title": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution", "comment": null, "summary": "It is a challenging problem to reproduce rich spatial details while maintaining temporal consistency in real-world video super-resolution (Real-VSR), especially when we leverage pre-trained generative models such as stable diffusion (SD) for realistic details synthesis. Existing SD-based Real-VSR methods often compromise spatial details for temporal coherence, resulting in suboptimal visual quality. We argue that the key lies in how to effectively extract the degradation-robust temporal consistency priors from the low-quality (LQ) input video and enhance the video details while maintaining the extracted consistency priors. To achieve this, we propose a Dual LoRA Learning (DLoRAL) paradigm to train an effective SD-based one-step diffusion model, achieving realistic frame details and temporal consistency simultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module to aggregate complementary information across frames, and train a Consistency-LoRA (C-LoRA) to learn robust temporal representations from degraded inputs. After consistency learning, we fix the CFR and C-LoRA modules and train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with the temporal space defined by C-LoRA to keep temporal coherence. The two phases alternate iteratively for optimization, collaboratively delivering consistent and detail-rich outputs. During inference, the two LoRA branches are merged into the SD model, allowing efficient and high-quality video restoration in a single diffusion step. Experiments show that DLoRAL achieves strong performance in both accuracy and speed. Code and models are available at https://github.com/yjsunnn/DLoRAL.", "AI": {"tldr": "提出了一种双LoRA学习范式（DLoRAL），通过交叉帧检索和一致性学习模块，在保持时间一致性的同时增强视频超分辨率的空间细节。", "motivation": "现有基于稳定扩散（SD）的Real-VSR方法常因牺牲空间细节以保持时间一致性而导致视觉质量不佳，需找到平衡两者的方法。", "method": "采用双LoRA学习范式，包括交叉帧检索模块（CFR）和一致性LoRA（C-LoRA）学习时间一致性，再通过细节LoRA（D-LoRA）增强空间细节，交替优化。", "result": "DLoRAL在单步扩散中实现了高质量视频恢复，在精度和速度上均表现优异。", "conclusion": "DLoRAL通过双LoRA学习有效平衡了时间一致性和空间细节，为Real-VSR提供了高效解决方案。"}}
{"id": "2506.15346", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15346", "abs": "https://arxiv.org/abs/2506.15346", "authors": ["A. S. Stankevich", "I. B. Petrov"], "title": "Acoustic Waveform Inversion with Image-to-Image Schrödinger Bridges", "comment": "Submitted to \"Computational Mathematics And Mathematical Physics\", ISSN 1555-6662, issue 8, August 2025", "summary": "Recent developments in application of deep learning models to acoustic Full Waveform Inversion (FWI) are marked by the use of diffusion models as prior distributions for Bayesian-like inference procedures. The advantage of these methods is the ability to generate high-resolution samples, which are otherwise unattainable with classical inversion methods or other deep learning-based solutions. However, the iterative and stochastic nature of sampling from diffusion models along with heuristic nature of output control remain limiting factors for their applicability. For instance, an optimal way to include the approximate velocity model into diffusion-based inversion scheme remains unclear, even though it is considered an essential part of FWI pipeline. We address the issue by employing a Schrödinger Bridge that interpolates between the distributions of ground truth and smoothed velocity models. To facilitate the learning of nonlinear drifts that transfer samples between distributions we extend the concept of Image-to-Image Schrödinger Bridge ($\\text{I}^2\\text{SB}$) to conditional sampling, resulting in a conditional Image-to-Image Schrödinger Bridge (c$\\text{I}^2\\text{SB}$) framework. To validate our method, we assess its effectiveness in reconstructing the reference velocity model from its smoothed approximation, coupled with the observed seismic signal of fixed shape. Our experiments demonstrate that the proposed solution outperforms our reimplementation of conditional diffusion model suggested in earlier works, while requiring only a few neural function evaluations (NFEs) to achieve sample fidelity superior to that attained with supervised learning-based approach. The supplementary code implementing the algorithms described in this paper can be found in the repository https://github.com/stankevich-mipt/seismic_inversion_via_I2SB.", "AI": {"tldr": "论文提出了一种基于Schrödinger Bridge的条件采样框架（cI2SB），用于改进声学全波形反演（FWI）中的扩散模型应用，解决了输出控制和迭代采样的限制问题。", "motivation": "扩散模型在FWI中的应用存在迭代采样和输出控制的限制，特别是如何将近似速度模型纳入扩散反演框架的问题尚未解决。", "method": "通过扩展Image-to-Image Schrödinger Bridge（I2SB）到条件采样，提出cI2SB框架，用于在分布间插值并学习非线性漂移。", "result": "实验表明，cI2SB在重建参考速度模型时优于现有条件扩散模型，且仅需少量神经函数评估即可达到高样本保真度。", "conclusion": "cI2SB框架为FWI中的扩散模型应用提供了更高效和可控的解决方案，优于现有方法。"}}
{"id": "2506.15596", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15596", "abs": "https://arxiv.org/abs/2506.15596", "authors": ["Kyobin Choo", "Hyunkyung Han", "Jinyeong Kim", "Chanyong Yoon", "Seong Jae Hwang"], "title": "Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration", "comment": "11 pages, 3 figures, 2 tables, Accepted at Medical Image Computing and Computer Assisted Intervention (MICCAI) 2025", "summary": "In clinical practice, imaging modalities with functional characteristics, such as positron emission tomography (PET) and fractional anisotropy (FA), are often aligned with a structural reference (e.g., MRI, CT) for accurate interpretation or group analysis, necessitating multi-modal deformable image registration (DIR). However, due to the extreme heterogeneity of these modalities compared to standard structural scans, conventional unsupervised DIR methods struggle to learn reliable spatial mappings and often distort images. We find that the similarity metrics guiding these models fail to capture alignment between highly disparate modalities. To address this, we propose M2M-Reg (Multi-to-Mono Registration), a novel framework that trains multi-modal DIR models using only mono-modal similarity while preserving the established architectural paradigm for seamless integration into existing models. We also introduce GradCyCon, a regularizer that leverages M2M-Reg's cyclic training scheme to promote diffeomorphism. Furthermore, our framework naturally extends to a semi-supervised setting, integrating pre-aligned and unaligned pairs only, without requiring ground-truth transformations or segmentation masks. Experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that M2M-Reg achieves up to 2x higher DSC than prior methods for PET-MRI and FA-MRI registration, highlighting its effectiveness in handling highly heterogeneous multi-modal DIR. Our code is available at https://github.com/MICV-yonsei/M2M-Reg.", "AI": {"tldr": "M2M-Reg提出了一种新的多模态图像配准框架，通过单模态相似性训练模型，解决了传统方法在多模态配准中的局限性，并在实验中表现出色。", "motivation": "临床中多模态图像配准（如PET与MRI）因模态差异大，传统无监督方法难以学习可靠的空间映射，导致图像失真。", "method": "提出M2M-Reg框架，利用单模态相似性训练多模态配准模型，引入GradCyCon正则化器促进微分同胚，并支持半监督学习。", "result": "在ADNI数据集上，M2M-Reg在PET-MRI和FA-MRI配准中的DSC比现有方法高2倍。", "conclusion": "M2M-Reg有效解决了高度异质多模态配准问题，且无需真实变换或分割掩码，具有广泛适用性。"}}
{"id": "2506.15349", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15349", "abs": "https://arxiv.org/abs/2506.15349", "authors": ["Terrance Liu", "Matteo Boglioni", "Yiwei Fu", "Shengyuan Hu", "Pratiksha Thaker", "Zhiwei Steven Wu"], "title": "Enhancing One-run Privacy Auditing with Quantile Regression-Based Membership Inference", "comment": null, "summary": "Differential privacy (DP) auditing aims to provide empirical lower bounds on the privacy guarantees of DP mechanisms like DP-SGD. While some existing techniques require many training runs that are prohibitively costly, recent work introduces one-run auditing approaches that effectively audit DP-SGD in white-box settings while still being computationally efficient. However, in the more practical black-box setting where gradients cannot be manipulated during training and only the last model iterate is observed, prior work shows that there is still a large gap between the empirical lower bounds and theoretical upper bounds. Consequently, in this work, we study how incorporating approaches for stronger membership inference attacks (MIA) can improve one-run auditing in the black-box setting. Evaluating on image classification models trained on CIFAR-10 with DP-SGD, we demonstrate that our proposed approach, which utilizes quantile regression for MIA, achieves tighter bounds while crucially maintaining the computational efficiency of one-run methods.", "AI": {"tldr": "本文研究了在差分隐私（DP）审计中，如何通过更强的成员推理攻击（MIA）方法改进黑盒设置下的单次运行审计，提出了一种基于分位数回归的MIA方法，在保持计算效率的同时实现了更紧的隐私保证边界。", "motivation": "现有黑盒设置下的单次运行审计方法在隐私保证边界与实际理论边界之间存在较大差距，因此需要更有效的审计方法。", "method": "提出了一种基于分位数回归的成员推理攻击（MIA）方法，用于改进黑盒设置下的单次运行审计。", "result": "在CIFAR-10数据集上训练的DP-SGD模型中，该方法实现了更紧的隐私保证边界，同时保持了计算效率。", "conclusion": "通过结合更强的MIA方法，可以在黑盒设置下更有效地审计DP机制，为实际应用提供了更可靠的隐私保证评估。"}}
{"id": "2506.15610", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15610", "abs": "https://arxiv.org/abs/2506.15610", "authors": ["Yuqing Lan", "Chenyang Zhu", "Zhirui Gao", "Jiazhao Zhang", "Yihan Cao", "Renjiao Yi", "Yijie Wang", "Kai Xu"], "title": "BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion", "comment": "11 pages, 6 figures", "summary": "Open-vocabulary 3D object detection has gained significant interest due to its critical applications in autonomous driving and embodied AI. Existing detection methods, whether offline or online, typically rely on dense point cloud reconstruction, which imposes substantial computational overhead and memory constraints, hindering real-time deployment in downstream tasks. To address this, we propose a novel reconstruction-free online framework tailored for memory-efficient and real-time 3D detection. Specifically, given streaming posed RGB-D video input, we leverage Cubify Anything as a pre-trained visual foundation model (VFM) for single-view 3D object detection by bounding boxes, coupled with CLIP to capture open-vocabulary semantics of detected objects. To fuse all detected bounding boxes across different views into a unified one, we employ an association module for correspondences of multi-views and an optimization module to fuse the 3D bounding boxes of the same instance predicted in multi-views. The association module utilizes 3D Non-Maximum Suppression (NMS) and a box correspondence matching module, while the optimization module uses an IoU-guided efficient random optimization technique based on particle filtering to enforce multi-view consistency of the 3D bounding boxes while minimizing computational complexity. Extensive experiments on ScanNetV2 and CA-1M datasets demonstrate that our method achieves state-of-the-art performance among online methods. Benefiting from this novel reconstruction-free paradigm for 3D object detection, our method exhibits great generalization abilities in various scenarios, enabling real-time perception even in environments exceeding 1000 square meters.", "AI": {"tldr": "提出了一种无需重建的实时3D目标检测框架，结合预训练视觉基础模型和CLIP，实现高效内存和开放词汇语义检测。", "motivation": "现有3D目标检测方法依赖密集点云重建，计算和内存开销大，难以实时部署。", "method": "利用Cubify Anything和CLIP进行单视图检测，通过关联模块和优化模块融合多视图检测结果。", "result": "在ScanNetV2和CA-1M数据集上达到SOTA性能，支持超1000平方米环境的实时感知。", "conclusion": "该框架无需重建，计算高效，泛化能力强，适用于实时3D目标检测。"}}
{"id": "2506.15378", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15378", "abs": "https://arxiv.org/abs/2506.15378", "authors": ["J. Thorben Frank", "Winfried Ripken", "Gregor Lied", "Klaus-Robert Müller", "Oliver T. Unke", "Stefan Chmiela"], "title": "Sampling 3D Molecular Conformers with Diffusion Transformers", "comment": null, "summary": "Diffusion Transformers (DiTs) have demonstrated strong performance in generative modeling, particularly in image synthesis, making them a compelling choice for molecular conformer generation. However, applying DiTs to molecules introduces novel challenges, such as integrating discrete molecular graph information with continuous 3D geometry, handling Euclidean symmetries, and designing conditioning mechanisms that generalize across molecules of varying sizes and structures. We propose DiTMC, a framework that adapts DiTs to address these challenges through a modular architecture that separates the processing of 3D coordinates from conditioning on atomic connectivity. To this end, we introduce two complementary graph-based conditioning strategies that integrate seamlessly with the DiT architecture. These are combined with different attention mechanisms, including both standard non-equivariant and SO(3)-equivariant formulations, enabling flexible control over the trade-off between between accuracy and computational efficiency. Experiments on standard conformer generation benchmarks (GEOM-QM9, -DRUGS, -XL) demonstrate that DiTMC achieves state-of-the-art precision and physical validity. Our results highlight how architectural choices and symmetry priors affect sample quality and efficiency, suggesting promising directions for large-scale generative modeling of molecular structures. Code available at https://github.com/ML4MolSim/dit_mc.", "AI": {"tldr": "DiTMC框架将扩散变换器（DiTs）应用于分子构象生成，通过模块化架构和两种图条件策略解决分子图与3D几何的融合问题，实现了高精度和物理有效性。", "motivation": "将DiTs应用于分子构象生成时，需解决分子图离散信息与3D几何连续性的融合、欧几里得对称性处理以及通用条件机制设计等挑战。", "method": "提出DiTMC框架，通过模块化架构分离3D坐标处理与原子连接条件，结合两种图条件策略和多种注意力机制（包括非等变和SO(3)-等变形式）。", "result": "在标准基准测试（GEOM-QM9、-DRUGS、-XL）中，DiTMC实现了最先进的精度和物理有效性。", "conclusion": "DiTMC展示了架构选择和对称性先验对样本质量与效率的影响，为大规模分子结构生成建模提供了新方向。"}}
{"id": "2506.15625", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15625", "abs": "https://arxiv.org/abs/2506.15625", "authors": ["Roey Ron", "Guy Tevet", "Haim Sawdayee", "Amit H. Bermano"], "title": "HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization", "comment": "Project page: https://hoidini.github.io", "summary": "We present HOIDiNi, a text-driven diffusion framework for synthesizing realistic and plausible human-object interaction (HOI). HOI generation is extremely challenging since it induces strict contact accuracies alongside a diverse motion manifold. While current literature trades off between realism and physical correctness, HOIDiNi optimizes directly in the noise space of a pretrained diffusion model using Diffusion Noise Optimization (DNO), achieving both. This is made feasible thanks to our observation that the problem can be separated into two phases: an object-centric phase, primarily making discrete choices of hand-object contact locations, and a human-centric phase that refines the full-body motion to realize this blueprint. This structured approach allows for precise hand-object contact without compromising motion naturalness. Quantitative, qualitative, and subjective evaluations on the GRAB dataset alone clearly indicate HOIDiNi outperforms prior works and baselines in contact accuracy, physical validity, and overall quality. Our results demonstrate the ability to generate complex, controllable interactions, including grasping, placing, and full-body coordination, driven solely by textual prompts. https://hoidini.github.io.", "AI": {"tldr": "HOIDiNi是一个基于文本驱动的扩散框架，用于生成真实且合理的人-物交互（HOI），通过优化噪声空间实现高接触精度和自然运动。", "motivation": "解决当前人-物交互生成中真实性与物理正确性难以兼顾的问题。", "method": "采用两阶段扩散噪声优化（DNO）：对象中心阶段选择手-物接触点，人体中心阶段优化全身运动。", "result": "在GRAB数据集上，HOIDiNi在接触精度、物理有效性和整体质量上优于现有方法。", "conclusion": "HOIDiNi能够仅通过文本提示生成复杂且可控的交互动作，展示了其优越性。"}}
{"id": "2506.15383", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2506.15383", "abs": "https://arxiv.org/abs/2506.15383", "authors": ["Damin Kühn", "Michael T. Schaub"], "title": "Global Ground Metric Learning with Applications to scRNA data", "comment": "This method is provided as a Python package on PyPI, see https://github.com/DaminK/ggml-ot", "summary": "Optimal transport provides a robust framework for comparing probability distributions. Its effectiveness is significantly influenced by the choice of the underlying ground metric. Traditionally, the ground metric has either been (i) predefined, e.g., as the Euclidean distance, or (ii) learned in a supervised way, by utilizing labeled data to learn a suitable ground metric for enhanced task-specific performance. Yet, predefined metrics typically cannot account for the inherent structure and varying importance of different features in the data, and existing supervised approaches to ground metric learning often do not generalize across multiple classes or are restricted to distributions with shared supports. To address these limitations, we propose a novel approach for learning metrics for arbitrary distributions over a shared metric space. Our method provides a distance between individual points like a global metric, but requires only class labels on a distribution-level for training. The learned global ground metric enables more accurate optimal transport distances, leading to improved performance in embedding, clustering and classification tasks. We demonstrate the effectiveness and interpretability of our approach using patient-level scRNA-seq data spanning multiple diseases.", "AI": {"tldr": "提出了一种新的方法来学习共享度量空间中任意分布的度量，解决了传统预定义或监督学习方法在泛化性和适应性上的不足。", "motivation": "传统的地面度量方法（如预定义欧氏距离或监督学习）无法考虑数据的内在结构和特征重要性，且泛化性差。", "method": "提出了一种学习全局地面度量的方法，仅需分布级别的类别标签进行训练，适用于任意分布。", "result": "学习到的全局地面度量提高了最优传输距离的准确性，在嵌入、聚类和分类任务中表现更优。", "conclusion": "该方法在多疾病患者级scRNA-seq数据中验证了有效性和可解释性。"}}
{"id": "2506.15385", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15385", "abs": "https://arxiv.org/abs/2506.15385", "authors": ["Riccardo De Santi", "Marin Vlastelica", "Ya-Ping Hsieh", "Zebang Shen", "Niao He", "Andreas Krause"], "title": "Provable Maximum Entropy Manifold Exploration via Diffusion Models", "comment": "ICML 2025", "summary": "Exploration is critical for solving real-world decision-making problems such as scientific discovery, where the objective is to generate truly novel designs rather than mimic existing data distributions. In this work, we address the challenge of leveraging the representational power of generative models for exploration without relying on explicit uncertainty quantification. We introduce a novel framework that casts exploration as entropy maximization over the approximate data manifold implicitly defined by a pre-trained diffusion model. Then, we present a novel principle for exploration based on density estimation, a problem well-known to be challenging in practice. To overcome this issue and render this method truly scalable, we leverage a fundamental connection between the entropy of the density induced by a diffusion model and its score function. Building on this, we develop an algorithm based on mirror descent that solves the exploration problem as sequential fine-tuning of a pre-trained diffusion model. We prove its convergence to the optimal exploratory diffusion model under realistic assumptions by leveraging recent understanding of mirror flows. Finally, we empirically evaluate our approach on both synthetic and high-dimensional text-to-image diffusion, demonstrating promising results.", "AI": {"tldr": "论文提出了一种基于扩散模型的探索框架，通过熵最大化实现新颖设计生成，无需显式不确定性量化。", "motivation": "解决生成模型在探索性问题中的应用挑战，特别是在科学发现等需要真正新颖设计的领域。", "method": "提出基于密度估计的探索原则，利用扩散模型的分数函数与熵的关系，开发了一种基于镜像下降的算法。", "result": "在合成和高维文本到图像扩散任务中验证了方法的有效性。", "conclusion": "该框架为探索性问题提供了一种可扩展且高效的解决方案。"}}
{"id": "2506.15645", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15645", "abs": "https://arxiv.org/abs/2506.15645", "authors": ["Shuo Xing", "Lanqing Guo", "Hongyuan Hua", "Seoyoung Lee", "Peiran Li", "Yufei Wang", "Zhangyang Wang", "Zhengzhong Tu"], "title": "Demystifying the Visual Quality Paradox in Multimodal Large Language Models", "comment": "18 pages", "summary": "Recent Multimodal Large Language Models (MLLMs) excel on benchmark vision-language tasks, yet little is known about how input visual quality shapes their responses. Does higher perceptual quality of images already translate to better MLLM understanding? We conduct the first systematic study spanning leading MLLMs and a suite of vision-language benchmarks, applying controlled degradations and stylistic shifts to each image. Surprisingly, we uncover a visual-quality paradox: model, task, and even individual-instance performance can improve when images deviate from human-perceived fidelity. Off-the-shelf restoration pipelines fail to reconcile these idiosyncratic preferences. To close the gap, we introduce Visual-Quality Test-Time Tuning (VQ-TTT)-a lightweight adaptation module that: (1) inserts a learnable, low-rank kernel before the frozen vision encoder to modulate frequency content; and (2) fine-tunes only shallow vision-encoder layers via LoRA. VQ-TTT dynamically adjusts each input image in a single forward pass, aligning it with task-specific model preferences. Across the evaluated MLLMs and all datasets, VQ-TTT lifts significant average accuracy, with no external models, cached features, or extra training data. These findings redefine ``better'' visual inputs for MLLMs and highlight the need for adaptive, rather than universally ``clean'', imagery, in the new era of AI being the main data customer.", "AI": {"tldr": "研究发现，多模态大语言模型（MLLMs）在视觉质量与任务表现之间存在矛盾：图像偏离人类感知的保真度时，模型表现反而可能提升。为此，作者提出了一种轻量级适配模块VQ-TTT，通过动态调整输入图像频率内容，显著提升了模型准确性。", "motivation": "探讨视觉输入质量如何影响MLLMs的表现，并解决现有模型对视觉质量的特殊偏好问题。", "method": "提出Visual-Quality Test-Time Tuning（VQ-TTT），通过插入可学习的低秩核和浅层微调，动态调整输入图像以适应模型偏好。", "result": "VQ-TTT显著提升了所有测试MLLMs和数据集的平均准确性，无需外部模型或额外数据。", "conclusion": "研究揭示了MLLMs对视觉质量的特殊偏好，并提出了适应性调整方法，为未来AI数据输入设计提供了新思路。"}}
{"id": "2506.15397", "categories": ["cs.LG", "cs.DS", "cs.SI"], "pdf": "https://arxiv.org/pdf/2506.15397", "abs": "https://arxiv.org/abs/2506.15397", "authors": ["Sepehr Elahi", "Paula Mürmann", "Patrick Thiran"], "title": "Learn to Vaccinate: Combining Structure Learning and Effective Vaccination for Epidemic and Outbreak Control", "comment": null, "summary": "The Susceptible-Infected-Susceptible (SIS) model is a widely used model for the spread of information and infectious diseases, particularly non-immunizing ones, on a graph. Given a highly contagious disease, a natural question is how to best vaccinate individuals to minimize the disease's extinction time. While previous works showed that the problem of optimal vaccination is closely linked to the NP-hard Spectral Radius Minimization (SRM) problem, they assumed that the graph is known, which is often not the case in practice. In this work, we consider the problem of minimizing the extinction time of an outbreak modeled by an SIS model where the graph on which the disease spreads is unknown and only the infection states of the vertices are observed. To this end, we split the problem into two: learning the graph and determining effective vaccination strategies. We propose a novel inclusion-exclusion-based learning algorithm and, unlike previous approaches, establish its sample complexity for graph recovery. We then detail an optimal algorithm for the SRM problem and prove that its running time is polynomial in the number of vertices for graphs with bounded treewidth. This is complemented by an efficient and effective polynomial-time greedy heuristic for any graph. Finally, we present experiments on synthetic and real-world data that numerically validate our learning and vaccination algorithms.", "AI": {"tldr": "论文研究了在未知图结构下，如何通过学习和疫苗接种策略最小化SIS模型中疾病的灭绝时间。提出了基于包含-排除的学习算法和高效的疫苗接种算法，并通过实验验证了其有效性。", "motivation": "在现实场景中，图结构通常未知，而现有研究假设图已知。因此，如何在未知图结构下优化疫苗接种策略以最小化疾病灭绝时间成为一个重要问题。", "method": "1. 提出基于包含-排除的学习算法，用于从顶点感染状态中恢复图结构；2. 针对有界树宽图，设计了多项式时间的最优疫苗接种算法；3. 提出适用于任意图的高效贪婪启发式算法。", "result": "学习算法具有明确的样本复杂度；疫苗接种算法在多项式时间内运行，并在实验中表现出有效性。", "conclusion": "论文为未知图结构下的SIS模型提供了有效的学习和疫苗接种策略，填补了实际应用中的空白。"}}
{"id": "2506.15649", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15649", "abs": "https://arxiv.org/abs/2506.15649", "authors": ["Ankan Deria", "Adinath Madhavrao Dukre", "Feilong Tang", "Sara Atito", "Sudipta Roy", "Muhammad Awais", "Muhammad Haris Khan", "Imran Razzak"], "title": "Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning", "comment": null, "summary": "Despite significant advances in inference-time search for vision-language models (VLMs), existing approaches remain both computationally expensive and prone to unpenalized, low-confidence generations which often lead to persistent hallucinations. We introduce \\textbf{Value-guided Inference with Margin-based Reward (ViMaR)}, a two-stage inference framework that improves both efficiency and output fidelity by combining a temporal-difference value model with a margin-aware reward adjustment. In the first stage, we perform a single pass to identify the highest-value caption among diverse candidates. In the second stage, we selectively refine only those segments that were overlooked or exhibit weak visual grounding, thereby eliminating frequently rewarded evaluations. A calibrated margin-based penalty discourages low-confidence continuations while preserving descriptive richness. Extensive experiments across multiple VLM architectures demonstrate that ViMaR generates captions that are significantly more reliable, factually accurate, detailed, and explanatory, while achieving over 4$\\times$ speedup compared to existing value-guided methods. Specifically, we show that ViMaR trained solely on LLaVA Mistral-7B, \\textit{generalizes effectively to guide decoding in a stronger unseen model}. To further validate this, we adapt the ViMaR to steer generation in LLaVA-OneVision-Qwen2-7B, leading to consistent improvements in caption quality and demonstrating robust cross-model guidance. This cross-model generalization highlights ViMaR's flexibility and modularity, positioning it as a scalable and transferable inference-time decoding strategy. Furthermore, when ViMaR-generated captions are used for self-training, the underlying models achieve substantial gains across a broad suite of visual comprehension benchmarks, underscoring the potential of fast, accurate, and self-improving VLM pipelines.", "AI": {"tldr": "ViMaR是一种两阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，显著提升视觉语言模型的效率和输出保真度。", "motivation": "现有方法计算成本高且容易产生低置信度的幻觉输出，ViMaR旨在解决这些问题。", "method": "ViMaR分两阶段：首阶段筛选最高价值候选描述，次阶段选择性优化弱视觉基础部分，并通过边缘惩罚抑制低置信度输出。", "result": "ViMaR显著提升描述的可靠性、准确性和细节，速度提升4倍以上，并能跨模型泛化。", "conclusion": "ViMaR是一种高效、可扩展的推理策略，还能通过自训练进一步提升模型性能。"}}
{"id": "2506.15408", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15408", "abs": "https://arxiv.org/abs/2506.15408", "authors": ["David Dembinsky", "Adriano Lucieri", "Stanislav Frolov", "Hiba Najjar", "Ko Watanabe", "Andreas Dengel"], "title": "Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI", "comment": "Submitted to TMLR, under review", "summary": "Modern AI systems frequently rely on opaque black-box models, most notably Deep Neural Networks, whose performance stems from complex architectures with millions of learned parameters. While powerful, their complexity poses a major challenge to trustworthiness, particularly due to a lack of transparency. Explainable AI (XAI) addresses this issue by providing human-understandable explanations of model behavior. However, to ensure their usefulness and trustworthiness, such explanations must be rigorously evaluated. Despite the growing number of XAI methods, the field lacks standardized evaluation protocols and consensus on appropriate metrics. To address this gap, we conduct a systematic literature review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and introduce a unified framework for the eValuation of XAI (VXAI). We identify 362 relevant publications and aggregate their contributions into 41 functionally similar metric groups. In addition, we propose a three-dimensional categorization scheme spanning explanation type, evaluation contextuality, and explanation quality desiderata. Our framework provides the most comprehensive and structured overview of VXAI to date. It supports systematic metric selection, promotes comparability across methods, and offers a flexible foundation for future extensions.", "AI": {"tldr": "论文通过系统文献综述提出VXAI框架，用于评估可解释AI（XAI）方法，填补了领域内标准化评估的空白。", "motivation": "现代AI系统（如深度神经网络）因复杂性缺乏透明度，XAI虽提供解释但缺乏统一评估标准。", "method": "采用PRISMA指南进行系统文献综述，提出VXAI框架，分类41种功能相似的指标组。", "result": "提出三维分类方案（解释类型、评估上下文、解释质量需求），提供最全面的VXAI概述。", "conclusion": "VXAI框架支持系统化指标选择，促进方法可比性，为未来扩展提供灵活基础。"}}
{"id": "2506.15673", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15673", "abs": "https://arxiv.org/abs/2506.15673", "authors": ["Kai He", "Ruofan Liang", "Jacob Munkberg", "Jon Hasselgren", "Nandita Vijaykumar", "Alexander Keller", "Sanja Fidler", "Igor Gilitschenski", "Zan Gojcic", "Zian Wang"], "title": "UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting", "comment": "Project page: https://research.nvidia.com/labs/toronto-ai/UniRelight/", "summary": "We address the challenge of relighting a single image or video, a task that demands precise scene intrinsic understanding and high-quality light transport synthesis. Existing end-to-end relighting models are often limited by the scarcity of paired multi-illumination data, restricting their ability to generalize across diverse scenes. Conversely, two-stage pipelines that combine inverse and forward rendering can mitigate data requirements but are susceptible to error accumulation and often fail to produce realistic outputs under complex lighting conditions or with sophisticated materials. In this work, we introduce a general-purpose approach that jointly estimates albedo and synthesizes relit outputs in a single pass, harnessing the generative capabilities of video diffusion models. This joint formulation enhances implicit scene comprehension and facilitates the creation of realistic lighting effects and intricate material interactions, such as shadows, reflections, and transparency. Trained on synthetic multi-illumination data and extensive automatically labeled real-world videos, our model demonstrates strong generalization across diverse domains and surpasses previous methods in both visual fidelity and temporal consistency.", "AI": {"tldr": "提出了一种联合估计反照率并生成重光照输出的单阶段方法，利用视频扩散模型的生成能力，解决了现有方法在数据稀缺和复杂光照条件下的局限性。", "motivation": "现有端到端重光照模型受限于配对多光照数据的稀缺性，而两阶段方法容易误差累积且难以处理复杂光照或材质。", "method": "采用单阶段联合估计反照率和生成重光照输出的方法，结合视频扩散模型的生成能力，利用合成多光照数据和自动标注的真实视频进行训练。", "result": "模型在多样场景中表现出强泛化能力，在视觉保真度和时间一致性上优于现有方法。", "conclusion": "该方法通过联合建模提升了场景理解和光照效果生成能力，适用于复杂光照和材质交互场景。"}}
{"id": "2506.15421", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15421", "abs": "https://arxiv.org/abs/2506.15421", "authors": ["Rui Yu", "Shenghua Wan", "Yucen Wang", "Chen-Xiao Gao", "Le Gan", "Zongzhang Zhang", "De-Chuan Zhan"], "title": "Reward Models in Deep Reinforcement Learning: A Survey", "comment": "IJCAI 2025 Survey Track (To Appear)", "summary": "In reinforcement learning (RL), agents continually interact with the environment and use the feedback to refine their behavior. To guide policy optimization, reward models are introduced as proxies of the desired objectives, such that when the agent maximizes the accumulated reward, it also fulfills the task designer's intentions. Recently, significant attention from both academic and industrial researchers has focused on developing reward models that not only align closely with the true objectives but also facilitate policy optimization. In this survey, we provide a comprehensive review of reward modeling techniques within the deep RL literature. We begin by outlining the background and preliminaries in reward modeling. Next, we present an overview of recent reward modeling approaches, categorizing them based on the source, the mechanism, and the learning paradigm. Building on this understanding, we discuss various applications of these reward modeling techniques and review methods for evaluating reward models. Finally, we conclude by highlighting promising research directions in reward modeling. Altogether, this survey includes both established and emerging methods, filling the vacancy of a systematic review of reward models in current literature.", "AI": {"tldr": "本文综述了深度强化学习中奖励建模技术的研究进展，包括背景、方法分类、应用及评估，并指出未来研究方向。", "motivation": "奖励模型在强化学习中作为代理目标，对策略优化至关重要，但目前缺乏系统性综述。本文旨在填补这一空白。", "method": "通过分类奖励建模方法（基于来源、机制和学习范式），并讨论其应用和评估方法。", "result": "综述了现有和新兴的奖励建模技术，提供了系统性总结。", "conclusion": "奖励建模是强化学习的关键方向，未来研究需进一步优化模型对齐和策略优化效果。"}}
{"id": "2506.15675", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15675", "abs": "https://arxiv.org/abs/2506.15675", "authors": ["Zhen Li", "Chuanhao Li", "Xiaofeng Mao", "Shaoheng Lin", "Ming Li", "Shitian Zhao", "Zhaopan Xu", "Xinyue Li", "Yukang Feng", "Jianwen Sun", "Zizhen Li", "Fanrui Zhang", "Jiaxin Ai", "Zhixiang Wang", "Yuwei Wu", "Tong He", "Jiangmiao Pang", "Yu Qiao", "Yunde Jia", "Kaipeng Zhang"], "title": "Sekai: A Video Dataset towards World Exploration", "comment": "12 pages, 6 figures", "summary": "Video generation techniques have made remarkable progress, promising to be the foundation of interactive world exploration. However, existing video generation datasets are not well-suited for world exploration training as they suffer from some limitations: limited locations, short duration, static scenes, and a lack of annotations about exploration and the world. In this paper, we introduce Sekai (meaning ``world'' in Japanese), a high-quality first-person view worldwide video dataset with rich annotations for world exploration. It consists of over 5,000 hours of walking or drone view (FPV and UVA) videos from over 100 countries and regions across 750 cities. We develop an efficient and effective toolbox to collect, pre-process and annotate videos with location, scene, weather, crowd density, captions, and camera trajectories. Experiments demonstrate the quality of the dataset. And, we use a subset to train an interactive video world exploration model, named YUME (meaning ``dream'' in Japanese). We believe Sekai will benefit the area of video generation and world exploration, and motivate valuable applications.", "AI": {"tldr": "Sekai是一个高质量的第一人称视角全球视频数据集，专为世界探索设计，包含5000多小时视频和丰富标注。", "motivation": "现有视频生成数据集不适合世界探索训练，存在地点有限、时长短、场景静态和缺乏标注等问题。", "method": "开发高效工具箱收集、预处理和标注视频，包括位置、场景、天气等信息，并训练交互式视频探索模型YUME。", "result": "实验验证了数据集质量，YUME模型展示了交互式世界探索的潜力。", "conclusion": "Sekai将推动视频生成和世界探索领域发展，激发有价值的应用。"}}
{"id": "2506.15446", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15446", "abs": "https://arxiv.org/abs/2506.15446", "authors": ["Scott Jeen", "Tom Bewley", "Jonathan M. Cullen"], "title": "Zero-Shot Reinforcement Learning Under Partial Observability", "comment": "Reinforcement Learning Conference 2025", "summary": "Recent work has shown that, under certain assumptions, zero-shot reinforcement learning (RL) methods can generalise to any unseen task in an environment after reward-free pre-training. Access to Markov states is one such assumption, yet, in many real-world applications, the Markov state is only partially observable. Here, we explore how the performance of standard zero-shot RL methods degrades when subjected to partially observability, and show that, as in single-task RL, memory-based architectures are an effective remedy. We evaluate our memory-based zero-shot RL methods in domains where the states, rewards and a change in dynamics are partially observed, and show improved performance over memory-free baselines. Our code is open-sourced via: https://enjeeneer.io/projects/bfms-with-memory/.", "AI": {"tldr": "零样本强化学习在部分可观测环境下性能下降，但基于记忆的架构能有效提升表现。", "motivation": "研究零样本强化学习方法在部分可观测环境中的性能退化问题，并提出解决方案。", "method": "采用基于记忆的架构，应用于状态、奖励和动态变化部分可观测的领域。", "result": "基于记忆的方法在部分可观测环境中表现优于无记忆基线。", "conclusion": "记忆架构是解决零样本强化学习在部分可观测环境中性能下降的有效方法。"}}
{"id": "2506.15682", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15682", "abs": "https://arxiv.org/abs/2506.15682", "authors": ["Anirud Aggarwal", "Abhinav Shrivastava", "Matthew Gwilliam"], "title": "Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model", "comment": "29 pages, 22 figures, 9 tables", "summary": "Diffusion-based image generation models excel at producing high-quality synthetic content, but suffer from slow and computationally expensive inference. Prior work has attempted to mitigate this by caching and reusing features within diffusion transformers across inference steps. These methods, however, often rely on rigid heuristics that result in limited acceleration or poor generalization across architectures. We propose Evolutionary Caching to Accelerate Diffusion models (ECAD), a genetic algorithm that learns efficient, per-model, caching schedules forming a Pareto frontier, using only a small set of calibration prompts. ECAD requires no modifications to network parameters or reference images. It offers significant inference speedups, enables fine-grained control over the quality-latency trade-off, and adapts seamlessly to different diffusion models. Notably, ECAD's learned schedules can generalize effectively to resolutions and model variants not seen during calibration. We evaluate ECAD on PixArt-alpha, PixArt-Sigma, and FLUX-1.dev using multiple metrics (FID, CLIP, Image Reward) across diverse benchmarks (COCO, MJHQ-30k, PartiPrompts), demonstrating consistent improvements over previous approaches. On PixArt-alpha, ECAD identifies a schedule that outperforms the previous state-of-the-art method by 4.47 COCO FID while increasing inference speedup from 2.35x to 2.58x. Our results establish ECAD as a scalable and generalizable approach for accelerating diffusion inference. Our project website is available at https://aniaggarwal.github.io/ecad and our code is available at https://github.com/aniaggarwal/ecad.", "AI": {"tldr": "ECAD是一种基于遗传算法的方法，通过学习高效的缓存调度来加速扩散模型推理，无需修改网络参数或参考图像，显著提升推理速度并适应不同模型。", "motivation": "扩散模型推理速度慢且计算成本高，现有方法依赖固定启发式规则，效果有限且泛化性差。", "method": "提出ECAD，利用遗传算法学习高效的缓存调度，形成Pareto前沿，仅需少量校准提示。", "result": "在PixArt-alpha等模型上，ECAD显著提升推理速度（2.58x）并优于现有方法（4.47 COCO FID）。", "conclusion": "ECAD是一种可扩展且泛化性强的扩散模型加速方法。"}}
{"id": "2506.15448", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15448", "abs": "https://arxiv.org/abs/2506.15448", "authors": ["Guoguo Ai", "Hezhe Qiao", "Hui Yan", "Guansong Pang"], "title": "Semi-supervised Graph Anomaly Detection via Robust Homophily Learning", "comment": "18 pages, 11 figures, 3 tables", "summary": "Semi-supervised graph anomaly detection (GAD) utilizes a small set of labeled normal nodes to identify abnormal nodes from a large set of unlabeled nodes in a graph. Current methods in this line posit that 1) normal nodes share a similar level of homophily and 2) the labeled normal nodes can well represent the homophily patterns in the normal class. However, this assumption often does not hold well since normal nodes in a graph can exhibit diverse homophily in real-world GAD datasets. In this paper, we propose RHO, namely Robust Homophily Learning, to adaptively learn such homophily patterns. RHO consists of two novel modules, adaptive frequency response filters (AdaFreq) and graph normality alignment (GNA). AdaFreq learns a set of adaptive spectral filters that capture different frequency components of the labeled normal nodes with varying homophily in the channel-wise and cross-channel views of node attributes. GNA is introduced to enforce consistency between the channel-wise and cross-channel homophily representations to robustify the normality learned by the filters in the two views. Experiments on eight real-world GAD datasets show that RHO can effectively learn varying, often under-represented, homophily in the small normal node set and substantially outperforms state-of-the-art competing methods. Code is available at https://github.com/mala-lab/RHO.", "AI": {"tldr": "RHO提出了一种半监督图异常检测方法，通过自适应学习正常节点的同质性模式，解决了现有方法假设同质性一致的局限性。", "motivation": "现有方法假设正常节点具有相似的同质性且标记节点能充分代表正常类的同质性模式，但现实中正常节点的同质性可能多样且未被充分表示。", "method": "RHO包含两个模块：AdaFreq（自适应频率响应滤波器）和GNA（图正态对齐），分别学习不同频率的同质性模式并增强其一致性。", "result": "在八个真实GAD数据集上，RHO显著优于现有方法，能有效学习未被充分表示的同质性模式。", "conclusion": "RHO通过自适应学习多样同质性模式，提升了半监督图异常检测的性能。"}}
{"id": "2506.15452", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.15452", "abs": "https://arxiv.org/abs/2506.15452", "authors": ["Simiao Lin", "Wannes Meert", "Pieter Robberechts", "Hendrik Blockeel"], "title": "Warping and Matching Subsequences Between Time Series", "comment": null, "summary": "Comparing time series is essential in various tasks such as clustering and classification. While elastic distance measures that allow warping provide a robust quantitative comparison, a qualitative comparison on top of them is missing. Traditional visualizations focus on point-to-point alignment and do not convey the broader structural relationships at the level of subsequences. This limitation makes it difficult to understand how and where one time series shifts, speeds up or slows down with respect to another. To address this, we propose a novel technique that simplifies the warping path to highlight, quantify and visualize key transformations (shift, compression, difference in amplitude). By offering a clearer representation of how subsequences match between time series, our method enhances interpretability in time series comparison.", "AI": {"tldr": "提出了一种新方法，通过简化扭曲路径来突出、量化和可视化时间序列之间的关键变换（如位移、压缩和振幅差异），从而增强时间序列比较的可解释性。", "motivation": "传统的时间序列可视化方法仅关注点对点对齐，无法展示子序列级别的结构关系，难以理解时间序列之间的位移、加速或减速等变换。", "method": "提出了一种新技术，通过简化扭曲路径来量化并可视化时间序列之间的关键变换（如位移、压缩和振幅差异）。", "result": "该方法能够更清晰地展示子序列之间的匹配关系，提升了时间序列比较的可解释性。", "conclusion": "通过简化扭曲路径，新方法有效解决了传统可视化方法在展示时间序列结构关系上的局限性，增强了比较的直观性和实用性。"}}
{"id": "2506.15479", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15479", "abs": "https://arxiv.org/abs/2506.15479", "authors": ["Artur André Oliveira", "Mateus Espadoto", "Roberto Hirata", "Roberto M. Cesar", "Alex C. Telea"], "title": "Creating User-steerable Projections with Interactive Semantic Mapping", "comment": null, "summary": "Dimensionality reduction (DR) techniques map high-dimensional data into lower-dimensional spaces. Yet, current DR techniques are not designed to explore semantic structure that is not directly available in the form of variables or class labels. We introduce a novel user-guided projection framework for image and text data that enables customizable, interpretable, data visualizations via zero-shot classification with Multimodal Large Language Models (MLLMs). We enable users to steer projections dynamically via natural-language guiding prompts, to specify high-level semantic relationships of interest to the users which are not explicitly present in the data dimensions. We evaluate our method across several datasets and show that it not only enhances cluster separation, but also transforms DR into an interactive, user-driven process. Our approach bridges the gap between fully automated DR techniques and human-centered data exploration, offering a flexible and adaptive way to tailor projections to specific analytical needs.", "AI": {"tldr": "提出了一种基于多模态大语言模型（MLLMs）的用户引导降维框架，支持通过自然语言提示动态调整投影，增强语义可视化和交互性。", "motivation": "现有降维技术无法直接探索数据中未显式标注的语义结构，需要一种更灵活、用户驱动的方法。", "method": "利用MLLMs进行零样本分类，通过自然语言提示动态引导投影，实现用户定制化的数据可视化。", "result": "在多数据集上验证，该方法不仅提升聚类分离效果，还将降维转变为交互式、用户驱动的过程。", "conclusion": "该框架填补了自动化降维与以人为中心的数据探索之间的空白，提供了一种灵活适应特定分析需求的解决方案。"}}
{"id": "2506.15492", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.15492", "abs": "https://arxiv.org/abs/2506.15492", "authors": ["Mohammadreza Nemati", "Zhipeng Huang", "Kevin S. Xu"], "title": "LIT-LVM: Structured Regularization for Interaction Terms in Linear Predictors using Latent Variable Models", "comment": null, "summary": "Some of the simplest, yet most frequently used predictors in statistics and machine learning use weighted linear combinations of features. Such linear predictors can model non-linear relationships between features by adding interaction terms corresponding to the products of all pairs of features. We consider the problem of accurately estimating coefficients for interaction terms in linear predictors. We hypothesize that the coefficients for different interaction terms have an approximate low-dimensional structure and represent each feature by a latent vector in a low-dimensional space. This low-dimensional representation can be viewed as a structured regularization approach that further mitigates overfitting in high-dimensional settings beyond standard regularizers such as the lasso and elastic net. We demonstrate that our approach, called LIT-LVM, achieves superior prediction accuracy compared to elastic net and factorization machines on a wide variety of simulated and real data, particularly when the number of interaction terms is high compared to the number of samples. LIT-LVM also provides low-dimensional latent representations for features that are useful for visualizing and analyzing their relationships.", "AI": {"tldr": "论文提出了一种名为LIT-LVM的方法，通过低维潜在向量表示特征，以更准确地估计线性预测器中交互项的系数，并在高维数据中减少过拟合。", "motivation": "线性预测器中的交互项系数估计在高维数据中容易过拟合，现有方法如lasso和弹性网络效果有限。", "method": "假设交互项系数具有低维结构，用低维潜在向量表示特征，结合结构化正则化。", "result": "LIT-LVM在模拟和真实数据中表现优于弹性网络和因子分解机，尤其在交互项数量多时。", "conclusion": "LIT-LVM不仅提高了预测精度，还提供了特征的低维表示，便于可视化和分析。"}}
{"id": "2506.15499", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15499", "abs": "https://arxiv.org/abs/2506.15499", "authors": ["Alaa Anani", "Tobias Lorenz", "Mario Fritz", "Bernt Schiele"], "title": "Pixel-level Certified Explanations via Randomized Smoothing", "comment": null, "summary": "Post-hoc attribution methods aim to explain deep learning predictions by highlighting influential input pixels. However, these explanations are highly non-robust: small, imperceptible input perturbations can drastically alter the attribution map while maintaining the same prediction. This vulnerability undermines their trustworthiness and calls for rigorous robustness guarantees of pixel-level attribution scores. We introduce the first certification framework that guarantees pixel-level robustness for any black-box attribution method using randomized smoothing. By sparsifying and smoothing attribution maps, we reformulate the task as a segmentation problem and certify each pixel's importance against $\\ell_2$-bounded perturbations. We further propose three evaluation metrics to assess certified robustness, localization, and faithfulness. An extensive evaluation of 12 attribution methods across 5 ImageNet models shows that our certified attributions are robust, interpretable, and faithful, enabling reliable use in downstream tasks. Our code is at https://github.com/AlaaAnani/certified-attributions.", "AI": {"tldr": "该论文提出了一种基于随机平滑的认证框架，首次为任何黑盒归因方法提供像素级鲁棒性保证，并通过稀疏化和平滑化归因图，将其重新表述为分割问题。", "motivation": "现有的后验归因方法在输入扰动下表现不稳定，归因图可能大幅变化，降低了其可信度。因此，需要一种能够提供严格鲁棒性保证的方法。", "method": "通过随机平滑技术，将归因图稀疏化和平滑化，并将其重新表述为分割问题，以认证每个像素的重要性。", "result": "在12种归因方法和5个ImageNet模型上的广泛评估表明，认证后的归因具有鲁棒性、可解释性和忠实性。", "conclusion": "该框架为归因方法提供了可靠的鲁棒性保证，使其能够在下游任务中更可靠地使用。"}}
{"id": "2506.15506", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15506", "abs": "https://arxiv.org/abs/2506.15506", "authors": ["Salijona Dyrmishi", "Mohamed Djilani", "Thibault Simonetto", "Salah Ghamizi", "Maxime Cordy"], "title": "Insights on Adversarial Attacks for Tabular Machine Learning via a Systematic Literature Review", "comment": "This paper is currently under review at ACM Computing Surveys", "summary": "Adversarial attacks in machine learning have been extensively reviewed in areas like computer vision and NLP, but research on tabular data remains scattered. This paper provides the first systematic literature review focused on adversarial attacks targeting tabular machine learning models. We highlight key trends, categorize attack strategies and analyze how they address practical considerations for real-world applicability. Additionally, we outline current challenges and open research questions. By offering a clear and structured overview, this review aims to guide future efforts in understanding and addressing adversarial vulnerabilities in tabular machine learning.", "AI": {"tldr": "本文首次系统综述了针对表格机器学习模型的对抗攻击，总结了关键趋势、攻击策略及实际应用挑战，并提出了未来研究方向。", "motivation": "对抗攻击在计算机视觉和NLP领域已有广泛研究，但表格数据的相关研究仍较分散，本文旨在填补这一空白。", "method": "通过系统文献综述，对表格机器学习模型的对抗攻击进行分类和趋势分析，并探讨实际应用中的问题。", "result": "总结了攻击策略的关键趋势，分析了实际应用的挑战，并提出了开放性问题。", "conclusion": "本文为未来研究提供了清晰的结构化概述，旨在帮助理解和解决表格机器学习中的对抗漏洞。"}}
{"id": "2506.15507", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15507", "abs": "https://arxiv.org/abs/2506.15507", "authors": ["Ivan Marisca", "Jacob Bamberger", "Cesare Alippi", "Michael M. Bronstein"], "title": "Over-squashing in Spatiotemporal Graph Neural Networks", "comment": null, "summary": "Graph Neural Networks (GNNs) have achieved remarkable success across various domains. However, recent theoretical advances have identified fundamental limitations in their information propagation capabilities, such as over-squashing, where distant nodes fail to effectively exchange information. While extensively studied in static contexts, this issue remains unexplored in Spatiotemporal GNNs (STGNNs), which process sequences associated with graph nodes. Nonetheless, the temporal dimension amplifies this challenge by increasing the information that must be propagated. In this work, we formalize the spatiotemporal over-squashing problem and demonstrate its distinct characteristics compared to the static case. Our analysis reveals that counterintuitively, convolutional STGNNs favor information propagation from points temporally distant rather than close in time. Moreover, we prove that architectures that follow either time-and-space or time-then-space processing paradigms are equally affected by this phenomenon, providing theoretical justification for computationally efficient implementations. We validate our findings on synthetic and real-world datasets, providing deeper insights into their operational dynamics and principled guidance for more effective designs.", "AI": {"tldr": "论文研究了时空图神经网络（STGNNs）中的信息传播问题，特别是时空过压缩现象，揭示了其与静态图的不同特性，并提出了理论支持和实验验证。", "motivation": "尽管图神经网络（GNNs）在多个领域取得了成功，但其信息传播能力存在局限性（如过压缩问题）。在时空图神经网络中，这一问题因时间维度的加入而加剧，但尚未被深入研究。", "method": "论文形式化了时空过压缩问题，分析了其特性，并比较了不同处理范式（时间-空间或时间-空间分离）的影响。", "result": "研究发现，卷积STGNNs倾向于传播时间上较远而非较近的信息，且不同处理范式均受此现象影响。实验验证了这些发现。", "conclusion": "研究为时空图神经网络的设计提供了理论依据和实用指导，强调了信息传播动态的重要性。"}}
{"id": "2506.15513", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15513", "abs": "https://arxiv.org/abs/2506.15513", "authors": ["Le Vu Anh", "Nguyen Viet Anh", "Mehmet Dik", "Luong Van Nghia"], "title": "RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation", "comment": "11 pages, 7 figures, 5 tables", "summary": "Retrieval-augmented generation (RAG) has become a common strategy for updating large language model (LLM) responses with current, external information. However, models may still rely on memorized training data, bypass the retrieved evidence, and produce contaminated outputs. We introduce Retrieval-Path Contamination Scoring (RePCS), a diagnostic method that detects such behavior without requiring model access or retraining. RePCS compares two inference paths: (i) a parametric path using only the query, and (ii) a retrieval-augmented path using both the query and retrieved context by computing the Kullback-Leibler (KL) divergence between their output distributions. A low divergence suggests that the retrieved context had minimal impact, indicating potential memorization. This procedure is model-agnostic, requires no gradient or internal state access, and adds only a single additional forward pass. We further derive PAC-style guarantees that link the KL threshold to user-defined false positive and false negative rates. On the Prompt-WNQA benchmark, RePCS achieves a ROC-AUC of 0.918. This result outperforms the strongest prior method by 6.5 percentage points while keeping latency overhead below 4.7% on an NVIDIA T4 GPU. RePCS offers a lightweight, black-box safeguard to verify whether a RAG system meaningfully leverages retrieval, making it especially valuable in safety-critical applications.", "AI": {"tldr": "RePCS是一种无需模型访问或重新训练的诊断方法，通过比较两种推理路径的KL散度来检测RAG系统是否依赖记忆而非检索信息。", "motivation": "解决RAG系统中模型可能依赖记忆而非检索信息的问题，提供一种轻量级、黑盒的检测方法。", "method": "通过比较仅使用查询的推理路径和使用查询加检索上下文的推理路径的KL散度，判断检索信息的影响。", "result": "在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，优于现有方法6.5个百分点，延迟开销低于4.7%。", "conclusion": "RePCS是一种高效、模型无关的方法，可验证RAG系统是否有效利用检索信息，适用于安全关键应用。"}}
{"id": "2506.15535", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.15535", "abs": "https://arxiv.org/abs/2506.15535", "authors": ["Alexandru Meterez", "Depen Morwani", "Costin-Andrei Oncescu", "Jingfeng Wu", "Cengiz Pehlevan", "Sham Kakade"], "title": "A Simplified Analysis of SGD for Linear Regression with Weight Averaging", "comment": null, "summary": "Theoretically understanding stochastic gradient descent (SGD) in overparameterized models has led to the development of several optimization algorithms that are widely used in practice today. Recent work by~\\citet{zou2021benign} provides sharp rates for SGD optimization in linear regression using constant learning rate, both with and without tail iterate averaging, based on a bias-variance decomposition of the risk. In our work, we provide a simplified analysis recovering the same bias and variance bounds provided in~\\citep{zou2021benign} based on simple linear algebra tools, bypassing the requirement to manipulate operators on positive semi-definite (PSD) matrices. We believe our work makes the analysis of SGD on linear regression very accessible and will be helpful in further analyzing mini-batching and learning rate scheduling, leading to improvements in the training of realistic models.", "AI": {"tldr": "本文通过简化分析，复现了Zou等人关于SGD在过参数化线性回归中的优化结果，避免了复杂的PSD矩阵操作。", "motivation": "简化SGD在过参数化线性回归中的分析，使其更易理解，并为后续研究（如小批量化和学习率调度）提供基础。", "method": "使用简单的线性代数工具，复现Zou等人的偏差-方差分解结果。", "result": "成功复现了Zou等人的偏差和方差边界，且无需操作PSD矩阵。", "conclusion": "简化后的分析使SGD在线性回归中的研究更易进行，有望推动实际模型训练的改进。"}}
{"id": "2506.15538", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15538", "abs": "https://arxiv.org/abs/2506.15538", "authors": ["Laura Kopf", "Nils Feldhus", "Kirill Bykov", "Philine Lou Bommer", "Anna Hedström", "Marina M. -C. Höhne", "Oliver Eberle"], "title": "Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework", "comment": null, "summary": "Automated interpretability research aims to identify concepts encoded in neural network features to enhance human understanding of model behavior. Current feature description methods face two critical challenges: limited robustness and the flawed assumption that each neuron encodes only a single concept (monosemanticity), despite growing evidence that neurons are often polysemantic. This assumption restricts the expressiveness of feature descriptions and limits their ability to capture the full range of behaviors encoded in model internals. To address this, we introduce Polysemantic FeatuRe Identification and Scoring Method (PRISM), a novel framework that captures the inherent complexity of neural network features. Unlike prior approaches that assign a single description per feature, PRISM provides more nuanced descriptions for both polysemantic and monosemantic features. We apply PRISM to language models and, through extensive benchmarking against existing methods, demonstrate that our approach produces more accurate and faithful feature descriptions, improving both overall description quality (via a description score) and the ability to capture distinct concepts when polysemanticity is present (via a polysemanticity score).", "AI": {"tldr": "PRISM框架通过识别和评分多义性特征，改进了神经网络特征的描述方法，提升了描述质量和多义性捕捉能力。", "motivation": "现有特征描述方法假设神经元仅编码单一概念（单义性），而实际上神经元常为多义性，这限制了描述的准确性和表达能力。", "method": "提出PRISM框架，为多义性和单义性特征提供更细致的描述，应用于语言模型并进行基准测试。", "result": "PRISM在描述质量和多义性捕捉能力上优于现有方法，通过描述分数和多义性分数验证。", "conclusion": "PRISM能更准确地描述神经网络特征，尤其是多义性特征，提升了模型行为的理解。"}}
{"id": "2506.15543", "categories": ["cs.LG", "cs.AI", "cs.DS", "cs.FL"], "pdf": "https://arxiv.org/pdf/2506.15543", "abs": "https://arxiv.org/abs/2506.15543", "authors": ["Hristo Papazov", "Nicolas Flammarion"], "title": "Learning Algorithms in the Limit", "comment": "Accepted at COLT 2025. This version matches the proceedings version", "summary": "This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \\textit{computational observations} and \\textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \\textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.", "AI": {"tldr": "论文通过扩展Gold的归纳推理框架，引入计算观测和受限输入源，研究了极限学习可计算函数的问题。补充传统输入输出观测，提出时间约束观测和策略轨迹观测，克服了学习一般递归函数的障碍。", "motivation": "研究在更现实约束下学习可计算函数的可行性，突破传统输入输出观测的局限性。", "method": "扩展Gold框架，引入时间约束观测和策略轨迹观测，分析计算代理的观测形式。", "result": "时间约束或近似观测可克服学习障碍，策略轨迹观测与有限状态转换器推断相关。线性时间可计算函数无法存在可计算或多项式质量特征集。", "conclusion": "新观测形式扩展了学习可计算函数的可能性，但某些函数类仍存在学习限制。"}}
{"id": "2506.15544", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15544", "abs": "https://arxiv.org/abs/2506.15544", "authors": ["Roger Creus Castanyer", "Johan Obando-Ceron", "Lu Li", "Pierre-Luc Bacon", "Glen Berseth", "Aaron Courville", "Pablo Samuel Castro"], "title": "Stable Gradients for Stable Learning at Scale in Deep Reinforcement Learning", "comment": null, "summary": "Scaling deep reinforcement learning networks is challenging and often results in degraded performance, yet the root causes of this failure mode remain poorly understood. Several recent works have proposed mechanisms to address this, but they are often complex and fail to highlight the causes underlying this difficulty. In this work, we conduct a series of empirical analyses which suggest that the combination of non-stationarity with gradient pathologies, due to suboptimal architectural choices, underlie the challenges of scale. We propose a series of direct interventions that stabilize gradient flow, enabling robust performance across a range of network depths and widths. Our interventions are simple to implement and compatible with well-established algorithms, and result in an effective mechanism that enables strong performance even at large scales. We validate our findings on a variety of agents and suites of environments.", "AI": {"tldr": "论文探讨了深度强化学习网络扩展时性能下降的原因，并提出简单干预措施以稳定梯度流。", "motivation": "研究深度强化学习网络扩展时性能下降的根本原因，并提出解决方案。", "method": "通过实证分析，提出直接干预措施以稳定梯度流，并验证其有效性。", "result": "干预措施简单易实现，兼容现有算法，能在大规模网络中保持强性能。", "conclusion": "研究揭示了梯度病理与非平稳性是扩展挑战的根源，并提供了有效的解决方案。"}}
{"id": "2506.15554", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15554", "abs": "https://arxiv.org/abs/2506.15554", "authors": ["Akhil Singampalli", "Danish Gufran", "Sudeep Pasricha"], "title": "DAILOC: Domain-Incremental Learning for Indoor Localization using Smartphones", "comment": null, "summary": "Wi-Fi fingerprinting-based indoor localization faces significant challenges in real-world deployments due to domain shifts arising from device heterogeneity and temporal variations within indoor environments. Existing approaches often address these issues independently, resulting in poor generalization and susceptibility to catastrophic forgetting over time. In this work, we propose DAILOC, a novel domain-incremental learning framework that jointly addresses both temporal and device-induced domain shifts. DAILOC introduces a novel disentanglement strategy that separates domain shifts from location-relevant features using a multi-level variational autoencoder. Additionally, we introduce a novel memory-guided class latent alignment mechanism to address the effects of catastrophic forgetting over time. Experiments across multiple smartphones, buildings, and time instances demonstrate that DAILOC significantly outperforms state-of-the-art methods, achieving up to 2.74x lower average error and 4.6x lower worst-case error.", "AI": {"tldr": "DAILOC是一种新型域增量学习框架，通过多级变分自编码器和记忆引导的潜在对齐机制，解决了Wi-Fi指纹室内定位中的设备异质性和时间变化问题，显著优于现有方法。", "motivation": "室内定位中设备异质性和时间变化导致的域偏移问题，现有方法独立处理这些问题，泛化能力差且易受灾难性遗忘影响。", "method": "提出DAILOC框架，采用多级变分自编码器分离域偏移与位置特征，并引入记忆引导的潜在对齐机制防止灾难性遗忘。", "result": "在多个智能手机、建筑和时间实例上的实验表明，DAILOC平均误差降低2.74倍，最差情况误差降低4.6倍。", "conclusion": "DAILOC通过联合处理域偏移和灾难性遗忘，显著提升了室内定位的鲁棒性和准确性。"}}
{"id": "2506.15559", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15559", "abs": "https://arxiv.org/abs/2506.15559", "authors": ["Danish Gufran", "Sudeep Pasricha"], "title": "Towards Explainable Indoor Localization: Interpreting Neural Network Learning on Wi-Fi Fingerprints Using Logic Gates", "comment": null, "summary": "Indoor localization using deep learning (DL) has demonstrated strong accuracy in mapping Wi-Fi RSS fingerprints to physical locations; however, most existing DL frameworks function as black-box models, offering limited insight into how predictions are made or how models respond to real-world noise over time. This lack of interpretability hampers our ability to understand the impact of temporal variations - caused by environmental dynamics - and to adapt models for long-term reliability. To address this, we introduce LogNet, a novel logic gate-based framework designed to interpret and enhance DL-based indoor localization. LogNet enables transparent reasoning by identifying which access points (APs) are most influential for each reference point (RP) and reveals how environmental noise disrupts DL-driven localization decisions. This interpretability allows us to trace and diagnose model failures and adapt DL systems for more stable long-term deployments. Evaluations across multiple real-world building floorplans and over two years of temporal variation show that LogNet not only interprets the internal behavior of DL models but also improves performance-achieving up to 1.1x to 2.8x lower localization error, 3.4x to 43.3x smaller model size, and 1.5x to 3.6x lower latency compared to prior DL-based models.", "AI": {"tldr": "LogNet是一种基于逻辑门的新型框架，旨在解释和增强基于深度学习的室内定位，提高模型的可解释性和长期可靠性。", "motivation": "现有深度学习框架在室内定位中缺乏可解释性，难以应对环境动态变化和长期部署的挑战。", "method": "引入LogNet框架，通过逻辑门结构识别关键访问点（APs）并分析环境噪声对定位决策的影响。", "result": "LogNet在多个真实建筑平面和两年时间变化中表现优异，定位误差降低1.1x至2.8x，模型体积缩小3.4x至43.3x，延迟减少1.5x至3.6x。", "conclusion": "LogNet不仅提升了深度学习模型的透明度和可解释性，还显著提高了性能和长期稳定性。"}}
{"id": "2506.15566", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15566", "abs": "https://arxiv.org/abs/2506.15566", "authors": ["Luigi Quarantiello", "Andrea Cossu", "Vincenzo Lomonaco"], "title": "Task-Agnostic Experts Composition for Continual Learning", "comment": null, "summary": "Compositionality is one of the fundamental abilities of the human reasoning process, that allows to decompose a complex problem into simpler elements. Such property is crucial also for neural networks, especially when aiming for a more efficient and sustainable AI framework. We propose a compositional approach by ensembling zero-shot a set of expert models, assessing our methodology using a challenging benchmark, designed to test compositionality capabilities. We show that our Expert Composition method is able to achieve a much higher accuracy than baseline algorithms while requiring less computational resources, hence being more efficient.", "AI": {"tldr": "论文提出了一种通过集成专家模型的组合方法，显著提高了准确性并降低了计算资源需求。", "motivation": "组合性是人类推理的基本能力，对神经网络的效率和可持续性至关重要。", "method": "通过零样本集成专家模型，并在测试组合性能力的基准上评估方法。", "result": "专家组合方法比基线算法准确性更高，且计算资源需求更低。", "conclusion": "该方法在提高效率的同时实现了更高的准确性，为可持续AI提供了新思路。"}}
{"id": "2506.15588", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15588", "abs": "https://arxiv.org/abs/2506.15588", "authors": ["Alex Mulrooney", "Devansh Gupta", "James Flemings", "Huanyu Zhang", "Murali Annavaram", "Meisam Razaviyayn", "Xinwei Zhang"], "title": "Memory-Efficient Differentially Private Training with Gradient Random Projection", "comment": null, "summary": "Differential privacy (DP) protects sensitive data during neural network training, but standard methods like DP-Adam suffer from high memory overhead due to per-sample gradient clipping, limiting scalability. We introduce DP-GRAPE (Gradient RAndom ProjEction), a DP training method that significantly reduces memory usage while maintaining utility on par with first-order DP approaches. Rather than directly applying DP to GaLore, DP-GRAPE introduces three key modifications: (1) gradients are privatized after projection, (2) random Gaussian matrices replace SVD-based subspaces, and (3) projection is applied during backpropagation. These contributions eliminate the need for costly SVD computations, enable substantial memory savings, and lead to improved utility. Despite operating in lower-dimensional subspaces, our theoretical analysis shows that DP-GRAPE achieves a privacy-utility trade-off comparable to DP-SGD. Our extensive empirical experiments show that DP-GRAPE can reduce the memory footprint of DP training without sacrificing accuracy or training time. In particular, DP-GRAPE reduces memory usage by over 63% when pre-training Vision Transformers and over 70% when fine-tuning RoBERTa-Large as compared to DP-Adam, while achieving similar performance. We further demonstrate that DP-GRAPE scales to fine-tuning large models such as OPT with up to 6.7 billion parameters.", "AI": {"tldr": "DP-GRAPE是一种新的差分隐私训练方法，通过梯度随机投影显著降低内存使用，同时保持与现有方法相当的效用。", "motivation": "标准差分隐私方法（如DP-Adam）因逐样本梯度裁剪导致高内存开销，限制了可扩展性。", "method": "DP-GRAPE通过三个关键改进实现：梯度在投影后私有化、使用随机高斯矩阵替代SVD子空间、在反向传播时应用投影。", "result": "实验表明，DP-GRAPE在预训练Vision Transformers和微调RoBERTa-Large时分别减少63%和70%的内存使用，且性能相当。", "conclusion": "DP-GRAPE在保持隐私-效用平衡的同时，显著降低了内存需求，适用于大规模模型训练。"}}
{"id": "2506.15606", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15606", "abs": "https://arxiv.org/abs/2506.15606", "authors": ["Gabrel J. Perin", "Runjin Chen", "Xuxi Chen", "Nina S. T. Hirata", "Zhangyang Wang", "Junyuan Hong"], "title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "comment": null, "summary": "Large Language Models (LLMs) have become indispensable in real-world applications. However, their widespread adoption raises significant safety concerns, particularly in responding to socially harmful questions. Despite substantial efforts to improve model safety through alignment, aligned models can still have their safety protections undermined by subsequent fine-tuning - even when the additional training data appears benign. In this paper, we empirically demonstrate that this vulnerability stems from the sensitivity of safety-critical low-rank subspaces in LLM parameters to fine-tuning. Building on this insight, we propose a novel training-free method, termed Low-Rank Extrapolation (LoX), to enhance safety robustness by extrapolating the safety subspace of an aligned LLM. Our experimental results confirm the effectiveness of LoX, demonstrating significant improvements in robustness against both benign and malicious fine-tuning attacks while preserving the model's adaptability to new tasks. For instance, LoX leads to 11% to 54% absolute reductions in attack success rates (ASR) facing benign or malicious fine-tuning attacks. By investigating the ASR landscape of parameters, we attribute the success of LoX to that the extrapolation moves LLM parameters to a flatter zone, thereby less sensitive to perturbations. The code is available at github.com/VITA-Group/LoX.", "AI": {"tldr": "论文提出了一种名为LoX的无训练方法，通过外推对齐LLM的安全子空间，增强其安全性鲁棒性。实验证明LoX能显著降低攻击成功率。", "motivation": "尽管对齐模型在安全方面已有改进，但后续微调仍可能破坏其安全保护，即使微调数据看似无害。", "method": "提出Low-Rank Extrapolation (LoX)方法，外推对齐LLM的安全子空间，无需额外训练。", "result": "LoX在面对良性或恶意微调攻击时，攻击成功率绝对降低11%至54%。", "conclusion": "LoX通过将LLM参数移动到更平坦的区域，减少对扰动的敏感性，从而提升安全性。"}}
{"id": "2506.15620", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15620", "abs": "https://arxiv.org/abs/2506.15620", "authors": ["Modar Sulaiman", "Kallol Roy"], "title": "GFLC: Graph-based Fairness-aware Label Correction for Fair Classification", "comment": "25 pages, 6 figures", "summary": "Fairness in machine learning (ML) has a critical importance for building trustworthy machine learning system as artificial intelligence (AI) systems increasingly impact various aspects of society, including healthcare decisions and legal judgments. Moreover, numerous studies demonstrate evidence of unfair outcomes in ML and the need for more robust fairness-aware methods. However, the data we use to train and develop debiasing techniques often contains biased and noisy labels. As a result, the label bias in the training data affects model performance and misrepresents the fairness of classifiers during testing. To tackle this problem, our paper presents Graph-based Fairness-aware Label Correction (GFLC), an efficient method for correcting label noise while preserving demographic parity in datasets. In particular, our approach combines three key components: prediction confidence measure, graph-based regularization through Ricci-flow-optimized graph Laplacians, and explicit demographic parity incentives. Our experimental findings show the effectiveness of our proposed approach and show significant improvements in the trade-off between performance and fairness metrics compared to the baseline.", "AI": {"tldr": "论文提出了一种基于图的公平感知标签校正方法（GFLC），用于在数据集中校正标签噪声并保持人口统计公平性。", "motivation": "由于机器学习系统在社会各领域（如医疗和法律）的影响日益增加，公平性成为关键问题。然而，训练数据中的标签偏差和噪声会影响模型性能和公平性评估。", "method": "GFLC结合了预测置信度度量、基于图的正则化（通过Ricci流优化的图拉普拉斯）和显式的人口统计公平激励。", "result": "实验结果表明，GFLC在性能和公平性指标之间的权衡上显著优于基线方法。", "conclusion": "GFLC是一种高效的方法，能够有效校正标签噪声并提升模型的公平性。"}}
{"id": "2506.15626", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.15626", "abs": "https://arxiv.org/abs/2506.15626", "authors": ["Vincent Roca", "Marc Tommasi", "Paul Andrey", "Aurélien Bellet", "Markus D. Schirmer", "Hilde Henon", "Laurent Puy", "Julien Ramon", "Grégory Kuchcinski", "Martin Bretzner", "Renaud Lopes"], "title": "Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction", "comment": null, "summary": "$\\textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a neuroimaging biomarker reflecting brain health. However, training robust BrainAGE models requires large datasets, often restricted by privacy concerns. This study evaluates the performance of federated learning (FL) for BrainAGE estimation in ischemic stroke patients treated with mechanical thrombectomy, and investigates its association with clinical phenotypes and functional outcomes.\n  $\\textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients across 16 hospital centers. We implemented standard machine learning and deep learning models for BrainAGE estimates under three data management strategies: centralized learning (pooled data), FL (local training at each site), and single-site learning. We reported prediction errors and examined associations between BrainAGE and vascular risk factors (e.g., diabetes mellitus, hypertension, smoking), as well as functional outcomes at three months post-stroke. Logistic regression evaluated BrainAGE's predictive value for these outcomes, adjusting for age, sex, vascular risk factors, stroke severity, time between MRI and arterial puncture, prior intravenous thrombolysis, and recanalisation outcome.\n  $\\textbf{Results:}$ While centralized learning yielded the most accurate predictions, FL consistently outperformed single-site models. BrainAGE was significantly higher in patients with diabetes mellitus across all models. Comparisons between patients with good and poor functional outcomes, and multivariate predictions of these outcomes showed the significance of the association between BrainAGE and post-stroke recovery.\n  $\\textbf{Conclusion:}$ FL enables accurate age predictions without data centralization. The strong association between BrainAGE, vascular risk factors, and post-stroke recovery highlights its potential for prognostic modeling in stroke care.", "AI": {"tldr": "研究评估了联邦学习（FL）在脑年龄预测（BrainAGE）中的应用，发现FL在保护隐私的同时表现优于单中心模型，且BrainAGE与血管风险因素及卒中后功能恢复显著相关。", "motivation": "由于隐私问题，大规模数据集难以获取，研究旨在探索FL在BrainAGE估计中的性能及其与卒中患者临床表型和功能预后的关联。", "method": "使用1674名卒中患者的FLAIR图像，比较集中学习、FL和单中心学习的预测效果，并分析BrainAGE与血管风险因素及功能预后的关系。", "result": "FL表现优于单中心模型，BrainAGE与糖尿病显著相关，且对卒中后功能恢复有预测价值。", "conclusion": "FL无需数据集中即可实现准确预测，BrainAGE在卒中预后建模中具有潜力。"}}
{"id": "2506.15651", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15651", "abs": "https://arxiv.org/abs/2506.15651", "authors": ["Tevin Wang", "Chenyan Xiong"], "title": "AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning", "comment": null, "summary": "Rule-based rewards offer a promising strategy for improving reinforcement learning from human feedback (RLHF), but current approaches often rely on manual rule engineering. We present AutoRule, a fully automated method for extracting rules from preference feedback and formulating them into rule-based rewards. AutoRule extraction operates in three stages: it leverages a reasoning model to interpret user preferences, identifies candidate rules from the reasoning chain of these interpretations, and synthesizes them into a unified rule set. Leveraging the finalized rule set, we employ language-model verifiers to compute the fraction of rules satisfied by each output, using this metric as an auxiliary reward alongside the learned reward model during policy optimization. Training a Llama-3-8B model with AutoRule results in a 28.6\\% relative improvement in length-controlled win rate on AlpacaEval2.0, and a 6.1\\% relative gain in second-turn performance on a held-out MT-Bench subset, compared to a GRPO baseline trained with the same learned reward model but without the rule-based auxiliary reward. Our analysis confirms that the extracted rules exhibit good agreement with dataset preference. We find that AutoRule demonstrates reduced reward hacking compared to a learned reward model when run over two episodes. Finally, our case study suggests that the extracted rules capture unique qualities valued in different datasets. The extracted rules are provided in the appendix, and the code is open-sourced at https://github.com/cxcscmu/AutoRule.", "AI": {"tldr": "AutoRule是一种自动化方法，通过从人类偏好反馈中提取规则并转化为基于规则的奖励，提升强化学习效果。", "motivation": "当前基于规则的奖励方法依赖人工规则设计，AutoRule旨在实现完全自动化，减少人工干预。", "method": "AutoRule分三阶段：利用推理模型解释用户偏好，从推理链中提取候选规则，合成统一规则集。结合语言模型验证器计算规则满足度，作为辅助奖励。", "result": "在Llama-3-8B模型上，AutoRule在AlpacaEval2.0和MT-Bench上分别实现28.6%和6.1%的相对性能提升。", "conclusion": "AutoRule提取的规则与数据集偏好一致，减少奖励滥用，并能捕捉不同数据集的独特价值。"}}
{"id": "2506.15654", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15654", "abs": "https://arxiv.org/abs/2506.15654", "authors": ["Ranting Hu"], "title": "CAWR: Corruption-Averse Advantage-Weighted Regression for Robust Policy Optimization", "comment": "23 pages, 14 figures", "summary": "Offline reinforcement learning (offline RL) algorithms often require additional constraints or penalty terms to address distribution shift issues, such as adding implicit or explicit policy constraints during policy optimization to reduce the estimation bias of functions. This paper focuses on a limitation of the Advantage-Weighted Regression family (AWRs), i.e., the potential for learning over-conservative policies due to data corruption, specifically the poor explorations in suboptimal offline data. We study it from two perspectives: (1) how poor explorations impact the theoretically optimal policy based on KL divergence, and (2) how such poor explorations affect the approximation of the theoretically optimal policy. We prove that such over-conservatism is mainly caused by the sensitivity of the loss function for policy optimization to poor explorations, and the proportion of poor explorations in offline datasets. To address this concern, we propose Corruption-Averse Advantage-Weighted Regression (CAWR), which incorporates a set of robust loss functions during policy optimization and an advantage-based prioritized experience replay method to filter out poor explorations. Numerical experiments on the D4RL benchmark show that our method can learn superior policies from suboptimal offline data, significantly enhancing the performance of policy optimization.", "AI": {"tldr": "本文研究了离线强化学习中AWR方法因数据质量差导致的保守策略问题，提出了CAWR方法，通过鲁棒损失函数和优先级经验回放提升性能。", "motivation": "离线强化学习中，AWR方法因数据质量差（如探索不足）可能导致策略过于保守，影响性能。本文旨在解决这一问题。", "method": "从理论角度分析KL散度对最优策略的影响，并提出CAWR方法，结合鲁棒损失函数和优势优先级经验回放。", "result": "在D4RL基准测试中，CAWR显著提升了策略优化的性能。", "conclusion": "CAWR通过鲁棒优化和数据过滤有效解决了AWR的保守性问题，适用于低质量离线数据。"}}
{"id": "2506.15679", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15679", "abs": "https://arxiv.org/abs/2506.15679", "authors": ["Xiaoqing Sun", "Alessandro Stolfo", "Joshua Engels", "Ben Wu", "Senthooran Rajamanoharan", "Mrinmaya Sachan", "Max Tegmark"], "title": "Dense SAE Latents Are Features, Not Bugs", "comment": null, "summary": "Sparse autoencoders (SAEs) are designed to extract interpretable features from language models by enforcing a sparsity constraint. Ideally, training an SAE would yield latents that are both sparse and semantically meaningful. However, many SAE latents activate frequently (i.e., are \\emph{dense}), raising concerns that they may be undesirable artifacts of the training procedure. In this work, we systematically investigate the geometry, function, and origin of dense latents and show that they are not only persistent but often reflect meaningful model representations. We first demonstrate that dense latents tend to form antipodal pairs that reconstruct specific directions in the residual stream, and that ablating their subspace suppresses the emergence of new dense features in retrained SAEs -- suggesting that high density features are an intrinsic property of the residual space. We then introduce a taxonomy of dense latents, identifying classes tied to position tracking, context binding, entropy regulation, letter-specific output signals, part-of-speech, and principal component reconstruction. Finally, we analyze how these features evolve across layers, revealing a shift from structural features in early layers, to semantic features in mid layers, and finally to output-oriented signals in the last layers of the model. Our findings indicate that dense latents serve functional roles in language model computation and should not be dismissed as training noise.", "AI": {"tldr": "该论文研究了稀疏自编码器（SAEs）中的密集潜在特征，发现它们并非训练噪声，而是具有功能性意义的模型表示。", "motivation": "稀疏自编码器的潜在特征通常被认为应稀疏且语义明确，但实际中许多特征频繁激活（密集），引发对其是否为训练伪影的质疑。", "method": "通过系统分析密集潜在特征的几何结构、功能和来源，提出分类法，并研究其在模型各层的演变。", "result": "密集潜在特征形成反极对，重构残差流中的特定方向，且其子空间消融会抑制新密集特征的出现。分类法揭示了与位置跟踪、上下文绑定等功能相关的特征类别。", "conclusion": "密集潜在特征在语言模型计算中具有功能性作用，不应被视为训练噪声。"}}
