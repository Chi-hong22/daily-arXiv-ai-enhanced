<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 8]
- [cs.HC](#cs.HC) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs](https://arxiv.org/abs/2506.04236)
*Botao Amber Hu,Helena Rong*

Main category: cs.MA

TL;DR: 论文探讨了基于开放系统的ALife研究，通过Spore.fun实验验证了区块链和LLM驱动的AI代理能否实现持续的开放演化（OEE）。


<details>
  <summary>Details</summary>
Motivation: 传统封闭系统（如Tierra和Avida）在ALife研究中难以实现持续的OEE，学者认为需要开放系统与环境持续交互。

Method: 利用DePIN技术和区块链上的LLM代理（如Spore.fun实验），研究其自主演化和行为。

Result: Spore.fun展示了AI代理在开放环境中的自主演化和交互能力，为OEE提供了新思路。

Conclusion: 开放系统结合经济激励可能实现OEE，Spore.fun为ALife研究提供了新方向。

Abstract: In Artificial Life (ALife) research, replicating Open-Ended Evolution
(OEE)-the continuous emergence of novelty observed in biological life-has
traditionally been pursued within isolated closed system simulations, such as
Tierra and Avida, which have typically plateaued after an initial burst of
novelty, failing to achieve sustained OEE. Scholars suggest that OEE requires
an "open" system that continually exchanges information or energy with its
environment. A recent technological innovation in decentralized physical
infrastructure networks (DePIN) providing permissionless computational
substrates enables deploying large language model (LLM)-based AI agents on
blockchains integrated with Trusted Execution Environments (TEEs). This enables
on-chain agents to operate autonomously "in the wild," achieving
self-sovereignty without human oversight. These agents can control their own
social media accounts and cryptocurrency wallets, allowing them to interact
directly with blockchain-based financial networks and broader human social
media. Building on this new paradigm of on-chain agents, Spore.fun is a recent
real-world AI evolution experiment that enables autonomous breeding and
evolution of new on-chain agents. This paper presents a detailed case study of
Spore.fun, examining agent behaviors and their evolutionary trajectories
through digital ethology. We aim to spark discussion about whether "open" ALife
systems "in-the-wild," based on permissionless computational substrates and
driven by economic incentives to interact with their environment, could finally
achieve the long-sought goal of OEE.

</details>


### [2] [HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource Utilization](https://arxiv.org/abs/2506.04255)
*Kunal Pai,Parth Shah,Harshil Patel*

Main category: cs.MA

TL;DR: HASHIRU是一个新型多智能体系统框架，通过动态分层控制、资源感知混合智能和自主功能扩展，提升了灵活性、资源效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统框架在灵活性、资源意识、模型多样性和自主工具创建方面存在不足，HASHIRU旨在解决这些问题。

Method: HASHIRU采用分层结构，包括动态管理的'CEO'代理和任务驱动的'员工'代理，结合本地小型LLM和外部API，并引入经济模型优化资源分配。

Result: 在学术论文评审、安全评估和复杂推理任务中表现优异，部分任务超越Gemini 2.0 Flash。

Conclusion: HASHIRU为多智能体系统提供了更强大、高效和适应性强的解决方案，支持动态资源管理和自主功能扩展。

Abstract: Rapid Large Language Model (LLM) advancements are fueling autonomous
Multi-Agent System (MAS) development. However, current frameworks often lack
flexibility, resource awareness, model diversity, and autonomous tool creation.
This paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent
Resource Utilization), a novel MAS framework enhancing flexibility, resource
efficiency, and adaptability. HASHIRU features a "CEO" agent dynamically
managing specialized "employee" agents, instantiated based on task needs and
resource constraints (cost, memory). Its hybrid intelligence prioritizes
smaller, local LLMs (via Ollama) while flexibly using external APIs and larger
models when necessary. An economic model with hiring/firing costs promotes team
stability and efficient resource allocation. The system also includes
autonomous API tool creation and a memory function. Evaluations on tasks like
academic paper review (58% success), safety assessments (100% on a
JailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash
on GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate
HASHIRU's capabilities. Case studies illustrate its self-improvement via
autonomous cost model generation, tool integration, and budget management.
HASHIRU offers a promising approach for more robust, efficient, and adaptable
MAS through dynamic hierarchical control, resource-aware hybrid intelligence,
and autonomous functional extension. Source code and benchmarks are available
at https://github.com/HASHIRU-AI/HASHIRU and
https://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is
available at https://hashiruagentx-hashiruai.hf.space upon request.

</details>


### [3] [CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients](https://arxiv.org/abs/2506.04265)
*Mengda Ji,Genjiu Xu,Liying Wang*

Main category: cs.MA

TL;DR: 本文提出了一种名为CORA的信用分配方法，通过联盟层面的分析解决多智能体强化学习中的信用分配问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 共享全局优势在多智能体强化学习中常导致次优策略更新，因为未能区分智能体的个体贡献。现有方法缺乏对联盟层面的详细分析。

Method: 提出CORA方法，通过评估所有可能联盟的边际贡献，利用合作博弈论的核心解分解优势，确保联盟理性，并采用随机联盟采样降低计算开销。

Result: 在矩阵游戏、微分游戏和多智能体协作基准测试中，CORA优于基线方法，尤其是在存在多个局部最优的任务中。

Conclusion: 联盟感知的信用分配对提升多智能体强化学习性能至关重要，CORA方法为此提供了有效解决方案。

Abstract: This work focuses on the credit assignment problem in cooperative multi-agent
reinforcement learning (MARL). Sharing the global advantage among agents often
leads to suboptimal policy updates as it fails to account for the distinct
contributions of agents. Although numerous methods consider global or
individual contributions for credit assignment, a detailed analysis at the
coalition level remains lacking in many approaches. This work analyzes the
over-updating problem during multi-agent policy updates from a coalition-level
perspective. To address this issue, we propose a credit assignment method
called Coalitional Rational Advantage Decomposition (CORA). CORA evaluates
coalitional advantages via marginal contributions from all possible coalitions
and decomposes advantages using the core solution from cooperative game theory,
ensuring coalitional rationality. To reduce computational overhead, CORA
employs random coalition sampling. Experiments on matrix games, differential
games, and multi-agent collaboration benchmarks demonstrate that CORA
outperforms strong baselines, particularly in tasks with multiple local optima.
These findings highlight the importance of coalition-aware credit assignment
for improving MARL performance.

</details>


### [4] [CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses](https://arxiv.org/abs/2506.04266)
*Timo Looms,Lin Xie*

Main category: cs.MA

TL;DR: 论文提出了一种基于CPU架构的新型仓库布局设计（PES分区），通过离散事件仿真验证其优于传统布局，显著提升了吞吐效率并降低了人力需求。


<details>
  <summary>Details</summary>
Motivation: 传统仓库布局（如矩形或Flying-V布局）导致拣货员行走距离过长和人力需求高，亟需优化。

Method: 采用离散事件仿真，将仓库分为性能（P）、效率（E）和共享（S）三个专用区域，并与传统布局对比。

Result: 新型布局显著缩短了吞吐时间并减少了人力需求。

Conclusion: 基于CPU架构的仓库布局设计在优化仓库运营方面具有潜力。

Abstract: Picker-to-parts pallet warehouses often face inefficiencies due to
conventional layouts causing excessive travel distances and high labor
requirements. This study introduces a novel layout design inspired by CPU
architecture, partitioning warehouse space into specialized zones, namely
Performance (P), Efficiency (E), and Shared (S). Discrete-event simulation is
used to evaluate this design against traditional rectangular (random and ABC
storage) and Flying-V layouts. Results demonstrate significant improvements in
throughput time and reduced labor requirements, highlighting the potential for
CPU-based layouts in optimizing warehouse operations.

</details>


### [5] [Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response](https://arxiv.org/abs/2506.04276)
*Lei Han,Yitong Guo,Pengfei Yang,Zhiyong Yu,Liang Wang,Quan Wang,Zhiwen Yu*

Main category: cs.MA

TL;DR: 本文提出了一种异构多智能体在线自主协同调度算法HoAs-PALN，用于高效收集灾后环境信息。通过自适应降维和局部纳什均衡博弈，显著提升了调度效率和任务完成率。


<details>
  <summary>Details</summary>
Motivation: 灾后环境复杂，现有传感技术适应性差、能力不足，亟需高效的信息采集解决方案。

Method: HoAs-PALN通过自适应降维（将五维匹配转化为两类三维匹配）和局部纳什均衡博弈（结合softmax函数优化行为选择概率）实现智能体协同调度。

Result: 实验表明，HoAs-PALN在任务完成率上显著优于基线方法（GREEDY、K-WTA、MADL和MARL），平均提升64.12%、46.48%、16.55%和14.03%，且每次调度决策时间小于10秒。

Conclusion: HoAs-PALN在动态灾后环境中表现出高效性和实用性，为灾后救援提供了可行的技术方案。

Abstract: Natural disasters have caused significant losses to human society, and the
timely and efficient acquisition of post-disaster environmental information is
crucial for the effective implementation of rescue operations. Due to the
complexity of post-disaster environments, existing sensing technologies face
challenges such as weak environmental adaptability, insufficient specialized
sensing capabilities, and limited practicality of sensing solutions. This paper
explores the heterogeneous multi-agent online autonomous collaborative
scheduling algorithm HoAs-PALN, aimed at achieving efficient collection of
post-disaster environmental information. HoAs-PALN is realized through adaptive
dimensionality reduction in the matching process and local Nash equilibrium
game, facilitating autonomous collaboration among time-dependent UAVs, workers
and vehicles to enhance sensing scheduling. (1) In terms of adaptive
dimensionality reduction during the matching process, HoAs-PALN significantly
reduces scheduling decision time by transforming a five-dimensional matching
process into two categories of three-dimensional matching processes; (2)
Regarding the local Nash equilibrium game, HoAs-PALN combines the softmax
function to optimize behavior selection probabilities and introduces a local
Nash equilibrium determination mechanism to ensure scheduling decision
performance. Finally, we conducted detailed experiments based on extensive
real-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL
and MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%,
and 14.03% on average, respectively, while each online scheduling decision
takes less than 10 seconds, demonstrating its effectiveness in dynamic
post-disaster environments.

</details>


### [6] [From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems](https://arxiv.org/abs/2506.04565)
*Jiayi Chen,Junyi Ye,Guiling Wang*

Main category: cs.MA

TL;DR: 论文综述了复合AI系统（CAIS），提出分类框架并分析四大范式，总结挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 克服单一模型的局限性，通过集成外部组件提升AI系统的能力。

Method: 定义CAIS概念，提出多维分类法，分析四大范式（RAG、LLM Agents、MLLMs、编排架构），比较设计权衡与评估方法。

Result: 总结了代表性系统，识别了可扩展性、互操作性等关键挑战。

Conclusion: 为研究者提供理解和发展下一代系统级AI的全面基础。

Abstract: Compound Al Systems (CAIS) is an emerging paradigm that integrates large
language models (LLMs) with external components, such as retrievers, agents,
tools, and orchestrators, to overcome the limitations of standalone models in
tasks requiring memory, reasoning, real-time grounding, and multimodal
understanding. These systems enable more capable and context-aware behaviors by
composing multiple specialized modules into cohesive workflows. Despite growing
adoption in both academia and industry, the CAIS landscape remains fragmented,
lacking a unified framework for analysis, taxonomy, and evaluation. In this
survey, we define the concept of CAIS, propose a multi-dimensional taxonomy
based on component roles and orchestration strategies, and analyze four
foundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents,
Multimodal LLMs (MLLMs), and orchestration-centric architectures. We review
representative systems, compare design trade-offs, and summarize evaluation
methodologies across these paradigms. Finally, we identify key
challenges-including scalability, interoperability, benchmarking, and
coordination-and outline promising directions for future research. This survey
aims to provide researchers and practitioners with a comprehensive foundation
for understanding, developing, and advancing the next generation of
system-level artificial intelligence.

</details>


### [7] [Towards Language-Augmented Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2506.05236)
*Maxime Toquebiau,Jae-Yun Jun,Faïz Benamar,Nicolas Bredeche*

Main category: cs.MA

TL;DR: 论文提出了一种基于人类定义语言的多智能体强化学习框架，通过语言增强学习提升协调性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注从零开始的通信协议，但效率低且难以解释。受自然语言启发，探索如何利用人类定义语言改进多智能体学习。

Method: 提出框架，训练智能体不仅行动，还生成和解释自然语言描述，实现显式通信和表征学习。

Result: 实验表明，该方法优于传统基线，语言基础带来更丰富的内部表征、更好的泛化能力和人机交互能力。

Conclusion: 结构化语言在多智能体学习中效果显著，为可解释和高效的系统开辟了新途径。

Abstract: Communication is a fundamental aspect of coordinated behavior in multi-agent
reinforcement learning. Yet, most prior works in this field have focused on
emergent communication protocols developed from scratch, often resulting in
inefficient or non-interpretable systems. Inspired by the role of language in
natural intelligence, we investigate how grounding agents in a human-defined
language can improve learning and coordination of multiple embodied agents. We
propose a framework in which agents are trained not only to act but also to
produce and interpret natural language descriptions of their observations. This
language-augmented learning serves a dual role: enabling explicit communication
between agents and guiding representation learning. We demonstrate that agents
trained with our method outperform traditional emergent communication baselines
across various tasks. Our analysis reveals that language grounding leads to
more informative internal representations, better generalization to new
partners, and improved capability for human-agent interaction. These findings
demonstrate the effectiveness of integrating structured language into
multi-agent learning and open avenues for more interpretable and capable
multi-agent systems.

</details>


### [8] [Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games](https://arxiv.org/abs/2506.05309)
*Niv Eckhaus,Uri Berger,Gabriel Stanovsky*

Main category: cs.MA

TL;DR: 论文提出了一种异步LLM代理，能够决定何时发言，并在在线Mafia游戏中表现与人类相当。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多场景（如群聊、团队会议）是异步的，而现有LLM主要用于同步通信，因此需要开发适应异步环境的代理。

Method: 开发了一种自适应异步LLM代理，能够决定发言时机，并通过在线Mafia游戏数据集进行评估。

Result: 代理在游戏表现和融入人类玩家方面与人类相当，发言时机行为接近人类，但消息内容存在差异。

Conclusion: 该研究为LLM在现实人类群体环境中的应用铺平了道路，支持进一步研究异步通信。

Abstract: LLMs are used predominantly in synchronous communication, where a human user
and a model communicate in alternating turns. In contrast, many real-world
settings are inherently asynchronous. For example, in group chats, online team
meetings, or social games, there is no inherent notion of turns; therefore, the
decision of when to speak forms a crucial part of the participant's decision
making. In this work, we develop an adaptive asynchronous LLM-agent which, in
addition to determining what to say, also decides when to say it. To evaluate
our agent, we collect a unique dataset of online Mafia games, including both
human participants, as well as our asynchronous agent. Overall, our agent
performs on par with human players, both in game performance, as well as in its
ability to blend in with the other human players. Our analysis shows that the
agent's behavior in deciding when to speak closely mirrors human patterns,
although differences emerge in message content. We release all our data and
code to support and encourage further research for more realistic asynchronous
communication between LLM agents. This work paves the way for integration of
LLMs into realistic human group settings, from assistance in team discussions
to educational and professional environments where complex social dynamics must
be navigated.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [9] [Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams](https://arxiv.org/abs/2506.05265)
*Mohammed Almutairi*

Main category: cs.HC

TL;DR: 该论文提出AI增强的团队优化框架，包括基于多臂老虎机的团队形成算法、AI反馈助手tAIfa和LLM模拟框架PuppeteerLLM，以提升团队满意度、凝聚力和绩效。


<details>
  <summary>Details</summary>
Motivation: 现有团队优化工具依赖静态数据或特定场景算法，无法适应动态团队需求，导致成员不满和绩效下降。

Method: 1. 多臂老虎机算法优化团队形成；2. AI助手tAIfa提供即时个性化反馈；3. LLM框架PuppeteerLLM模拟团队动态。

Result: 提出的框架能动态优化团队，提升满意度、凝聚力和绩效。

Conclusion: AI增强的团队优化工具可有效解决动态团队管理中的挑战。

Abstract: Effective teamwork is essential across diverse domains. During the team
formation stage, a key challenge is forming teams that effectively balance user
preferences with task objectives to enhance overall team satisfaction. In the
team performing stage, maintaining cohesion and engagement is critical for
sustaining high team performance. However, existing computational tools and
algorithms for team optimization often rely on static data inputs, narrow
algorithmic objectives, or solutions tailored for specific contexts, failing to
account for the dynamic interplay of team members personalities, evolving
goals, and changing individual preferences. Therefore, teams may encounter
member dissatisfaction, as purely algorithmic assignments can reduce members
commitment to team goals or experience suboptimal engagement due to the absence
of timely, personalized guidance to help members adjust their behaviors and
interactions as team dynamics evolve. Ultimately, these challenges can lead to
reduced overall team performance. My Ph.D. dissertation aims to develop
AI-augmented team optimization frameworks and practical systems that enhance
team satisfaction, engagement, and performance. First, I propose a team
formation framework that leverages a multi-armed bandit algorithm to
iteratively refine team composition based on user preferences, ensuring
alignment between individual needs and collective team goals to enhance team
satisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an
AI-powered system that utilizes large language models (LLMs) to deliver
immediate, personalized feedback to both teams and individual members,
enhancing cohesion and engagement. Finally, I present PuppeteerLLM, an
LLM-based simulation framework that simulates multi-agent teams to model
complex team dynamics within realistic environments, incorporating task-driven
collaboration and long-term coordination.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [10] [Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause Model Based on Fractional-Order Methods](https://arxiv.org/abs/2506.04701)
*Meiru Jiang,Wei Su,Guojian Ren,Yongguang Yu*

Main category: physics.soc-ph

TL;DR: 提出了一种新的分数阶有界置信意见动力学模型，用于描述系统状态中的记忆效应，基于Hegselmann-Krause框架和分数阶差分，研究了收敛和共识特性。


<details>
  <summary>Details</summary>
Motivation: 研究记忆效应对社交互动和决策过程的影响，弥补经典意见动力学模型的局限性。

Method: 结合Hegselmann-Krause框架和分数阶差分，建立模型并分析其收敛和共识特性。

Result: 模型在保持良好收敛和共识特性的同时，解决了意见单调性等限制，更真实地模拟现实场景中的意见演化。

Conclusion: 该研究为理解意见形成和演化提供了新的理论和方法，具有理论和实际应用价值。

Abstract: Memory effects play a crucial role in social interactions and decision-making
processes. This paper proposes a novel fractional-order bounded confidence
opinion dynamics model to characterize the memory effects in system states.
Building upon the Hegselmann-Krause framework and fractional-order difference,
a comprehensive model is established that captures the persistent influence of
historical information. Through rigorous theoretical analysis, the fundamental
properties including convergence and consensus is investigated. The results
demonstrate that the proposed model not only maintains favorable convergence
and consensus characteristics compared to classical opinion dynamics, but also
addresses limitations such as the monotonicity of bounded opinions. This
enables a more realistic representation of opinion evolution in real-world
scenarios. The findings of this study provide new insights and methodological
approaches for understanding opinion formation and evolution, offering both
theoretical significance and practical applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [11] [Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation](https://arxiv.org/abs/2506.04251)
*Zhengyang Li*

Main category: cs.AI

TL;DR: LLM-MARL框架将大语言模型（LLMs）融入多智能体强化学习（MARL），通过Coordinator、Communicator和Memory模块提升协调、通信和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通过结合LLMs和MARL，提升智能体在模拟游戏环境中的协调、通信和泛化能力。

Method: 框架包含Coordinator（生成子目标）、Communicator（符号化通信）和Memory（情景记忆），结合PPO训练和语言条件损失。

Result: 在多个游戏环境中表现优于MAPPO和QMIX，子目标和语言通信对性能提升贡献显著。

Conclusion: LLM-MARL为智能、协作的智能体设计提供了新思路，展示了LLMs在多智能体系统中的潜力。

Abstract: This paper introduces LLM-MARL, a unified framework that incorporates large
language models (LLMs) into multi-agent reinforcement learning (MARL) to
enhance coordination, communication, and generalization in simulated game
environments. The framework features three modular components of Coordinator,
Communicator, and Memory, which dynamically generate subgoals, facilitate
symbolic inter-agent messaging, and support episodic recall. Training combines
PPO with a language-conditioned loss and LLM query gating. LLM-MARL is
evaluated in Google Research Football, MAgent Battle, and StarCraft II. Results
show consistent improvements over MAPPO and QMIX in win rate, coordination
score, and zero-shot generalization. Ablation studies demonstrate that subgoal
generation and language-based messaging each contribute significantly to
performance gains. Qualitative analysis reveals emergent behaviors such as role
specialization and communication-driven tactics. By bridging language modeling
and policy learning, this work contributes to the design of intelligent,
cooperative agents in interactive simulations. It offers a path forward for
leveraging LLMs in multi-agent systems used for training, games, and human-AI
collaboration.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [12] [Gen-n-Val: Agentic Image Data Generation and Validation](https://arxiv.org/abs/2506.04676)
*Jing-En Huang,I-Sheng Fang,Tzuhsuan Huang,Chih-Yu Wang,Jun-Cheng Chen*

Main category: cs.CV

TL;DR: Gen-n-Val是一个新型数据生成框架，利用Layer Diffusion、LLMs和VLLMs生成高质量的单对象掩码和多样化背景，显著提升合成数据的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉任务中数据稀缺和标签噪声问题，当前合成数据生成方法存在多对象掩码、分割不准确和类别标签错误等限制。

Method: Gen-n-Val包含两个代理：LD提示代理（LLM）优化提示生成高质量前景和掩码；数据验证代理（VLLM）过滤低质量数据。系统提示通过TextGrad优化，并结合图像协调技术。

Result: 相比MosaicFusion，Gen-n-Val将无效合成数据从50%降至7%，在COCO实例分割中提升1% mAP，在开放词汇目标检测中提升7.1% mAP。

Conclusion: Gen-n-Val显著提升了合成数据的质量和模型性能，适用于实例分割和目标检测任务。

Abstract: Recently, Large Language Models (LLMs) and Vision Large Language Models
(VLLMs) have demonstrated impressive performance as agents across various tasks
while data scarcity and label noise remain significant challenges in computer
vision tasks, such as object detection and instance segmentation. A common
solution for resolving these issues is to generate synthetic data. However,
current synthetic data generation methods struggle with issues, such as
multiple objects per mask, inaccurate segmentation, and incorrect category
labels, limiting their effectiveness. To address these issues, we introduce
Gen-n-Val, a novel agentic data generation framework that leverages Layer
Diffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks
and diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt
agent, an LLM, optimizes prompts for LD to generate high-quality foreground
instance images and segmentation masks. These optimized prompts ensure the
generation of single-object synthetic data with precise instance masks and
clean backgrounds. (2) The data validation agent, a VLLM, which filters out
low-quality synthetic instance images. The system prompts for both agents are
refined through TextGrad. Additionally, we use image harmonization to combine
multiple instances within scenes. Compared to state-of-the-art synthetic data
approaches like MosaicFusion, our approach reduces invalid synthetic data from
50% to 7% and improves performance by 1% mAP on rare classes in COCO instance
segmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant
improvements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object
detection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance
of YOLOv9 and YOLO11 families in instance segmentation and object detection.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning](https://arxiv.org/abs/2506.05252)
*Dravyansh Sharma,Alec Sun*

Main category: cs.LG

TL;DR: 本文研究了机器学习在战略性分类中的可学习性，特别是在代理真实改进而非欺骗行为的情况下，扩展了多个新维度的学习能力。


<details>
  <summary>Details</summary>
Motivation: 研究代理真实改进时的学习能力，填补了现有文献中对自然改进区域（如欧几里得球）学习的空白。

Method: 引入不对称的最小一致概念类变体，并在可实现设置中精确刻画了适当学习；研究了欧几里得球改进集下的学习能力，并在有界噪声模型下降低泛化误差。

Result: 在可实现和不可知在线学习中实现了错误边界，解决了Attias等人提出的开放性问题。

Conclusion: 本文扩展了战略性分类的学习能力，为更自然的改进区域提供了理论基础和实用方法。

Abstract: Machine learning is now ubiquitous in societal decision-making, for example
in evaluating job candidates or loan applications, and it is increasingly
important to take into account how classified agents will react to the learning
algorithms. The majority of recent literature on strategic classification has
focused on reducing and countering deceptive behaviors by the classified
agents, but recent work of Attias et al. identifies surprising properties of
learnability when the agents genuinely improve in order to attain the desirable
classification, such as smaller generalization error than standard
PAC-learning. In this paper we characterize so-called learnability with
improvements across multiple new axes. We introduce an asymmetric variant of
minimally consistent concept classes and use it to provide an exact
characterization of proper learning with improvements in the realizable
setting. While prior work studies learnability only under general, arbitrary
agent improvement regions, we give positive results for more natural Euclidean
ball improvement sets. In particular, we characterize improper learning under a
mild generative assumption on the data distribution. We further show how to
learn in more challenging settings, achieving lower generalization error under
well-studied bounded noise models and obtaining mistake bounds in realizable
and agnostic online learning. We resolve open questions posed by Attias et al.
for both proper and improper learning.

</details>
