<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 76]
- [cs.RO](#cs.RO) [Total: 30]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.LG](#cs.LG) [Total: 77]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.SD](#cs.SD) [Total: 7]
- [eess.SY](#eess.SY) [Total: 22]
- [cs.HC](#cs.HC) [Total: 11]
- [cs.GT](#cs.GT) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DrivingScene: A Multi-Task Online Feed-Forward 3D Gaussian Splatting Method for Dynamic Driving Scenes](https://arxiv.org/abs/2510.24734)
*Qirui Hou,Wenzhang Sun,Chang Zeng,Chunfeng Wang,Hao Li,Jianxun Cui*

Main category: cs.CV

TL;DR: DrivingScene是一个在线前馈框架，仅使用两个连续环视图像就能重建4D动态驾驶场景，通过轻量级残差流网络预测动态物体的非刚性运动，在静态场景先验基础上显式建模场景流。


<details>
  <summary>Details</summary>
Motivation: 实时高保真重建动态驾驶场景面临复杂动态和稀疏视图的挑战，现有方法难以平衡质量和效率。

Method: 提出轻量级残差流网络预测动态物体的非刚性运动，在学习的静态场景先验基础上显式建模场景流，采用从粗到精的训练范式避免端到端方法的不稳定性。

Result: 在nuScenes数据集上的实验表明，该仅使用图像的方法能在线同时生成高质量深度、场景流和3D高斯点云，在动态重建和新视角合成方面显著优于最先进方法。

Conclusion: DrivingScene框架成功解决了动态驾驶场景重建中的质量与效率平衡问题，为实时4D场景重建提供了有效解决方案。

Abstract: Real-time, high-fidelity reconstruction of dynamic driving scenes is
challenged by complex dynamics and sparse views, with prior methods struggling
to balance quality and efficiency. We propose DrivingScene, an online,
feed-forward framework that reconstructs 4D dynamic scenes from only two
consecutive surround-view images. Our key innovation is a lightweight residual
flow network that predicts the non-rigid motion of dynamic objects per camera
on top of a learned static scene prior, explicitly modeling dynamics via scene
flow. We also introduce a coarse-to-fine training paradigm that circumvents the
instabilities common to end-to-end approaches. Experiments on nuScenes dataset
show our image-only method simultaneously generates high-quality depth, scene
flow, and 3D Gaussian point clouds online, significantly outperforming
state-of-the-art methods in both dynamic reconstruction and novel view
synthesis.

</details>


### [2] [Towards Fine-Grained Human Motion Video Captioning](https://arxiv.org/abs/2510.24767)
*Guorui Song,Guocun Wang,Zhe Huang,Jing Lin,Xuefei Zhe,Jian Li,Haoqian Wang*

Main category: cs.CV

TL;DR: 提出M-ACM模型，通过运动感知解码增强视频字幕质量，利用人体网格恢复的运动表示来突出人体动态，减少幻觉并提高语义保真度和空间对齐。


<details>
  <summary>Details</summary>
Motivation: 现有视频字幕模型难以捕捉细粒度运动细节，导致生成的字幕模糊或语义不一致。

Method: 引入运动增强字幕模型(M-ACM)，利用人体网格恢复提取运动表示，通过运动感知解码机制增强字幕生成。

Result: M-ACM在准确描述复杂人体运动和细微时间变化方面显著优于先前方法，为运动中心视频字幕设定了新标准。

Conclusion: M-ACM通过整合运动感知解码有效提升了视频字幕质量，特别是在描述人体运动方面表现优异。

Abstract: Generating accurate descriptions of human actions in videos remains a
challenging task for video captioning models. Existing approaches often
struggle to capture fine-grained motion details, resulting in vague or
semantically inconsistent captions. In this work, we introduce the
Motion-Augmented Caption Model (M-ACM), a novel generative framework that
enhances caption quality by incorporating motion-aware decoding. At its core,
M-ACM leverages motion representations derived from human mesh recovery to
explicitly highlight human body dynamics, thereby reducing hallucinations and
improving both semantic fidelity and spatial alignment in the generated
captions. To support research in this area, we present the Human Motion Insight
(HMI) Dataset, comprising 115K video-description pairs focused on human
movement, along with HMI-Bench, a dedicated benchmark for evaluating
motion-focused video captioning. Experimental results demonstrate that M-ACM
significantly outperforms previous methods in accurately describing complex
human motions and subtle temporal variations, setting a new standard for
motion-centric video captioning.

</details>


### [3] [Combining SAR Simulators to Train ATR Models with Synthetic Data](https://arxiv.org/abs/2510.24768)
*Benjamin Camus,Julien Houssay,Corentin Le Barbu,Eric Monteux,Cédric Saleun,Christian Cochin*

Main category: cs.CV

TL;DR: 该论文提出使用两种不同模拟器生成合成SAR图像来训练深度学习模型，以解决合成数据与真实数据之间的域差距问题，在MSTAR数据集上达到近88%的准确率。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏真实标注的SAR图像数据，需要使用模拟器生成合成数据，但单一模拟器基于简化的物理模型，导致训练出的ATR模型在真实数据上泛化能力差。

Method: 结合两种基于不同物理原理的SAR模拟器（MOCEM基于散射中心模型，Salsa基于光线追踪策略）生成合成数据集，并使用ADASCA深度学习方法训练ATR模型。

Result: 在MSTAR真实测量数据上达到了接近88%的准确率，显著提升了模型在真实数据上的泛化性能。

Conclusion: 通过结合互补的模拟器生成多样化合成数据，可以有效缓解合成数据与真实数据之间的域差距问题，提升ATR模型在真实SAR图像上的识别性能。

Abstract: This work aims to train Deep Learning models to perform Automatic Target
Recognition (ATR) on Synthetic Aperture Radar (SAR) images. To circumvent the
lack of real labelled measurements, we resort to synthetic data produced by SAR
simulators. Simulation offers full control over the virtual environment, which
enables us to generate large and diversified datasets at will. However,
simulations are intrinsically grounded on simplifying assumptions of the real
world (i.e. physical models). Thus, synthetic datasets are not as
representative as real measurements. Consequently, ATR models trained on
synthetic images cannot generalize well on real measurements. Our contributions
to this problem are twofold: on one hand, we demonstrate and quantify the
impact of the simulation paradigm on the ATR. On the other hand, we propose a
new approach to tackle the ATR problem: combine two SAR simulators that are
grounded on different (but complementary) paradigms to produce synthetic
datasets. To this end, we use two simulators: MOCEM, which is based on a
scattering centers model approach, and Salsa, which resorts on a ray tracing
strategy. We train ATR models using synthetic dataset generated both by MOCEM
and Salsa and our Deep Learning approach called ADASCA. We reach an accuracy of
almost 88 % on the MSTAR measurements.

</details>


### [4] [Point-level Uncertainty Evaluation of Mobile Laser Scanning Point Clouds](https://arxiv.org/abs/2510.24773)
*Ziyang Xu,Olaf Wysocki,Christoph Holst*

Main category: cs.CV

TL;DR: 提出基于机器学习的移动激光扫描点云不确定性评估框架，使用随机森林和XGBoost模型学习局部几何特征与点级误差的关系，实现无需高精度参考数据的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 传统不确定性建模依赖高精度参考数据，成本高昂且难以大规模获取，需要一种数据驱动的方法来评估点云不确定性。

Method: 使用随机森林和XGBoost两种集成学习模型，基于局部几何特征预测点级不确定性，通过空间分区数据集训练验证以避免数据泄漏。

Result: 两种模型都能有效捕捉几何特征与不确定性的非线性关系，平均ROC-AUC值超过0.87，发现高程变化、点密度和局部结构复杂度是预测不确定性的关键特征。

Conclusion: 该框架为大规模点云质量控制和误差分析提供了可扩展的数据驱动解决方案，无需依赖昂贵的参考数据。

Abstract: Reliable quantification of uncertainty in Mobile Laser Scanning (MLS) point
clouds is essential for ensuring the accuracy and credibility of downstream
applications such as 3D mapping, modeling, and change analysis. Traditional
backward uncertainty modeling heavily rely on high-precision reference data,
which are often costly or infeasible to obtain at large scales. To address this
issue, this study proposes a machine learning-based framework for point-level
uncertainty evaluation that learns the relationship between local geometric
features and point-level errors. The framework is implemented using two
ensemble learning models, Random Forest (RF) and XGBoost, which are trained and
validated on a spatially partitioned real-world dataset to avoid data leakage.
Experimental results demonstrate that both models can effectively capture the
nonlinear relationships between geometric characteristics and uncertainty,
achieving mean ROC-AUC values above 0.87. The analysis further reveals that
geometric features describing elevation variation, point density, and local
structural complexity play a dominant role in predicting uncertainty. The
proposed framework offers a data-driven perspective of uncertainty evaluation,
providing a scalable and adaptable foundation for future quality control and
error analysis of large-scale point clouds.

</details>


### [5] [Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2510.24777)
*Yujie Nie,Jianzhang Ni,Yonglong Ye,Yuan-Ting Zhang,Yun Kwok Wing,Xiangqing Xu,Xin Ma,Lizhou Fan*

Main category: cs.CV

TL;DR: 提出一种多模态交叉增强融合框架，结合眼动追踪和面部特征进行阿尔茨海默病辅助诊断，通过交叉注意力机制和方向感知卷积模块实现多模态表征学习，在自建数据集上达到95.11%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的准确诊断对及时干预至关重要。眼动追踪和面部特征作为认知功能的重要指标，能够反映注意力分布和神经认知状态，但很少有研究探索它们联合用于AD辅助诊断。

Method: 提出多模态交叉增强融合框架，包含两个关键模块：(1)交叉增强融合注意力模块(CEFAM)，通过交叉注意力和全局增强建模模态间交互；(2)方向感知卷积模块(DACM)，通过水平-垂直感受野捕获细粒度方向性面部特征。

Result: 在包含25名AD患者和25名健康对照的自建同步多模态数据集上，该框架优于传统的后期融合和特征拼接方法，在区分AD与HC时达到95.11%的分类准确率。

Conclusion: 该框架通过显式建模模态间依赖关系和模态特定贡献，展现出优越的鲁棒性和诊断性能，为阿尔茨海默病的多模态辅助诊断提供了有效解决方案。

Abstract: Accurate diagnosis of Alzheimer's disease (AD) is essential for enabling
timely intervention and slowing disease progression. Multimodal diagnostic
approaches offer considerable promise by integrating complementary information
across behavioral and perceptual domains. Eye-tracking and facial features, in
particular, are important indicators of cognitive function, reflecting
attentional distribution and neurocognitive state. However, few studies have
explored their joint integration for auxiliary AD diagnosis. In this study, we
propose a multimodal cross-enhanced fusion framework that synergistically
leverages eye-tracking and facial features for AD detection. The framework
incorporates two key modules: (a) a Cross-Enhanced Fusion Attention Module
(CEFAM), which models inter-modal interactions through cross-attention and
global enhancement, and (b) a Direction-Aware Convolution Module (DACM), which
captures fine-grained directional facial features via horizontal-vertical
receptive fields. Together, these modules enable adaptive and discriminative
multimodal representation learning. To support this work, we constructed a
synchronized multimodal dataset, including 25 patients with AD and 25 healthy
controls (HC), by recording aligned facial video and eye-tracking sequences
during a visual memory-search paradigm, providing an ecologically valid
resource for evaluating integration strategies. Extensive experiments on this
dataset demonstrate that our framework outperforms traditional late fusion and
feature concatenation methods, achieving a classification accuracy of 95.11% in
distinguishing AD from HC, highlighting superior robustness and diagnostic
performance by explicitly modeling inter-modal dependencies and
modality-specific contributions.

</details>


### [6] [Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation](https://arxiv.org/abs/2510.25234)
*Yuxiang Mao,Zhijie Zhang,Zhiheng Zhang,Jiawei Liu,Chen Zeng,Shihong Xia*

Main category: cs.CV

TL;DR: 提出了一种基于语音和情感的3D面部动画生成方法，通过线性叠加问题和稀疏约束损失来解耦语音驱动和情感驱动的混合形状，实现了高质量的情感化说话人脸生成。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成内容快速发展，但情感化3D面部动画仍面临挑战，主要障碍是真实情感3D说话人脸数据集的稀缺性。

Method: 将语音和情感驱动的面部动画建模为线性叠加问题，利用中性表情的3D说话人脸数据集(VOCAset)和3D表情序列数据集(Florence4D)，通过稀疏约束损失联合学习语音和情感驱动的混合形状。

Result: 定性定量实验表明，该方法能自然生成具有指定表情的说话人脸，同时保持准确的唇部同步。感知研究显示，相比现有方法，本方法在情感表达性方面更优，且不牺牲唇同步质量。

Conclusion: 该方法成功解决了情感化3D说话人脸生成的挑战，通过解耦语音和情感驱动实现了高质量的面部动画，并能进一步映射到FLAME模型参数来驱动3D高斯化身。

Abstract: Expressions are fundamental to conveying human emotions. With the rapid
advancement of AI-generated content (AIGC), realistic and expressive 3D facial
animation has become increasingly crucial. Despite recent progress in
speech-driven lip-sync for talking-face animation, generating emotionally
expressive talking faces remains underexplored. A major obstacle is the
scarcity of real emotional 3D talking-face datasets due to the high cost of
data capture. To address this, we model facial animation driven by both speech
and emotion as a linear additive problem. Leveraging a 3D talking-face dataset
with neutral expressions (VOCAset) and a dataset of 3D expression sequences
(Florence4D), we jointly learn a set of blendshapes driven by speech and
emotion. We introduce a sparsity constraint loss to encourage disentanglement
between the two types of blendshapes while allowing the model to capture
inherent secondary cross-domain deformations present in the training data. The
learned blendshapes can be further mapped to the expression and jaw pose
parameters of the FLAME model, enabling the animation of 3D Gaussian avatars.
Qualitative and quantitative experiments demonstrate that our method naturally
generates talking faces with specified expressions while maintaining accurate
lip synchronization. Perceptual studies further show that our approach achieves
superior emotional expressivity compared to existing methods, without
compromising lip-sync quality.

</details>


### [7] [FPGA-based Lane Detection System incorporating Temperature and Light Control Units](https://arxiv.org/abs/2510.24778)
*Ibrahim Qamar,Saber Mahmoud,Seif Megahed,Mohamed Khaled,Saleh Hesham,Ahmed Matar,Saif Gebril,Mervat Mahmoud*

Main category: cs.CV

TL;DR: 提出基于FPGA的车道检测车辆架构，使用Sobel算法进行边缘检测，能在1.17ms内处理416x416图像并输出车道数量、当前车道索引及边界信息，还包含自动光温控制功能。


<details>
  <summary>Details</summary>
Motivation: 智能车辆在自动化趋势中日益重要，车道路径检测是其关键应用需求，需要高效实时的检测系统。

Method: 采用FPGA硬件平台，基于Sobel边缘检测算法，处理416x416分辨率图像，工作频率150MHz，并集成自动光照和温度控制单元。

Result: 系统每1.17ms可生成有效输出，包括车道数量、当前车道索引及左右边界信息，具有环境适应性。

Conclusion: 该FPGA车道检测系统实现了高效实时的车道检测性能，能够适应不同环境条件，为智能车辆提供可靠的车道检测解决方案。

Abstract: Intelligent vehicles are one of the most important outcomes gained from the
world tendency toward automation. Applications of IVs, whether in urban roads
or robot tracks, do prioritize lane path detection. This paper proposes an
FPGA-based Lane Detector Vehicle LDV architecture that relies on the Sobel
algorithm for edge detection. Operating on 416 x 416 images and 150 MHz, the
system can generate a valid output every 1.17 ms. The valid output consists of
the number of present lanes, the current lane index, as well as its right and
left boundaries. Additionally, the automated light and temperature control
units in the proposed system enhance its adaptability to the surrounding
environmental conditions.

</details>


### [8] [FreeArt3D: Training-Free Articulated Object Generation using 3D Diffusion](https://arxiv.org/abs/2510.25765)
*Chuhao Chen,Isabella Liu,Xinyue Wei,Hao Su,Minghua Liu*

Main category: cs.CV

TL;DR: FreeArt3D是一个无需训练的铰接3D物体生成框架，通过将预训练的静态3D扩散模型重新用作形状先验，将Score Distillation Sampling扩展到3D到4D领域，将铰接作为额外的生成维度。


<details>
  <summary>Details</summary>
Motivation: 现有的铰接3D物体建模方法要么需要密集视角监督的优化重建流程，要么生成粗略几何近似且忽略表面纹理。虽然静态物体的开放世界3D生成取得了显著成功，但将其扩展到铰接物体面临重大挑战。

Method: 利用预训练的静态3D扩散模型（如Trellis）作为形状先验，将Score Distillation Sampling扩展到3D到4D领域，将铰接作为额外生成维度。给定不同铰接状态的几张图像，联合优化物体的几何、纹理和铰接参数。

Result: 生成高保真几何和纹理，准确预测底层运动学结构，在多样化物体类别上泛化良好。尽管采用逐实例优化范式，但能在几分钟内完成，在质量和多功能性上显著优于先前最先进方法。

Conclusion: FreeArt3D提供了一种无需训练的方法，成功解决了铰接3D物体生成的挑战，通过重新利用现有静态3D扩散模型实现了高质量、高效率的铰接物体生成。

Abstract: Articulated 3D objects are central to many applications in robotics, AR/VR,
and animation. Recent approaches to modeling such objects either rely on
optimization-based reconstruction pipelines that require dense-view supervision
or on feed-forward generative models that produce coarse geometric
approximations and often overlook surface texture. In contrast, open-world 3D
generation of static objects has achieved remarkable success, especially with
the advent of native 3D diffusion models such as Trellis. However, extending
these methods to articulated objects by training native 3D diffusion models
poses significant challenges. In this work, we present FreeArt3D, a
training-free framework for articulated 3D object generation. Instead of
training a new model on limited articulated data, FreeArt3D repurposes a
pre-trained static 3D diffusion model (e.g., Trellis) as a powerful shape
prior. It extends Score Distillation Sampling (SDS) into the 3D-to-4D domain by
treating articulation as an additional generative dimension. Given a few images
captured in different articulation states, FreeArt3D jointly optimizes the
object's geometry, texture, and articulation parameters without requiring
task-specific training or access to large-scale articulated datasets. Our
method generates high-fidelity geometry and textures, accurately predicts
underlying kinematic structures, and generalizes well across diverse object
categories. Despite following a per-instance optimization paradigm, FreeArt3D
completes in minutes and significantly outperforms prior state-of-the-art
approaches in both quality and versatility.

</details>


### [9] [ESCA: Enabling Seamless Codec Avatar Execution through Algorithm and Hardware Co-Optimization for Virtual Reality](https://arxiv.org/abs/2510.24787)
*Mingzhi Zhu,Ding Shang,Sai Qian Zhang*

Main category: cs.CV

TL;DR: 提出了ESCA框架，通过后训练量化和定制硬件加速器优化Codec Avatar模型，在VR设备上实现实时高保真渲染。


<details>
  <summary>Details</summary>
Motivation: 解决Codec Avatar模型在资源受限的VR设备上计算需求大、实时推理困难的问题。

Method: 采用后训练量化方法降低模型精度，设计定制硬件加速器集成到VR设备的SoC中，构建完整的优化框架。

Result: FovVideoVDP质量得分提升+0.39，延迟降低3.36倍，渲染速率达到100帧/秒，满足实时VR需求。

Conclusion: 证明了在资源受限设备上部署高保真Codec Avatar的可行性，为更沉浸式和便携的VR体验开辟了道路。

Abstract: Photorealistic Codec Avatars (PCA), which generate high-fidelity human face
renderings, are increasingly being used in Virtual Reality (VR) environments to
enable immersive communication and interaction through deep learning-based
generative models. However, these models impose significant computational
demands, making real-time inference challenging on resource-constrained VR
devices such as head-mounted displays, where latency and power efficiency are
critical. To address this challenge, we propose an efficient post-training
quantization (PTQ) method tailored for Codec Avatar models, enabling
low-precision execution without compromising output quality. In addition, we
design a custom hardware accelerator that can be integrated into the
system-on-chip of VR devices to further enhance processing efficiency. Building
on these components, we introduce ESCA, a full-stack optimization framework
that accelerates PCA inference on edge VR platforms. Experimental results
demonstrate that ESCA boosts FovVideoVDP quality scores by up to $+0.39$ over
the best 4-bit baseline, delivers up to $3.36\times$ latency reduction, and
sustains a rendering rate of 100 frames per second in end-to-end tests,
satisfying real-time VR requirements. These results demonstrate the feasibility
of deploying high-fidelity codec avatars on resource-constrained devices,
opening the door to more immersive and portable VR experiences.

</details>


### [10] [The Underappreciated Power of Vision Models for Graph Structural Understanding](https://arxiv.org/abs/2510.24788)
*Xinjian Zhao,Wei Pang,Zhongkai Xue,Xiangru Jian,Lei Zhang,Yaoyao Xu,Xiaozhuang Song,Shu Wu,Tianshu Yu*

Main category: cs.CV

TL;DR: 该论文发现视觉模型在图理解任务中表现与GNN相当但学习模式不同，提出了GraphAbstract基准来评估全局图结构理解能力，结果显示视觉模型在需要整体结构理解的任务上显著优于GNN。


<details>
  <summary>Details</summary>
Motivation: 研究视觉模型在图理解中的潜力，因为GNN采用自下而上的消息传递机制，与人类视觉感知（先捕捉全局结构）存在根本差异。现有基准将领域特征与拓扑理解混为一谈，需要新的评估方法。

Method: 引入GraphAbstract基准，评估模型感知全局图属性的能力，包括识别组织原型、检测对称性、感知连接强度和识别关键元素。比较视觉模型和GNN在不同图规模下的表现。

Result: 视觉模型在需要整体结构理解的任务上显著优于GNN，且在不同图规模下保持泛化能力，而GNN在全局模式抽象方面表现不佳，且随着图规模增大性能下降。

Conclusion: 视觉模型具有显著但未被充分利用的图结构理解能力，特别是在需要全局拓扑感知和尺度不变推理的问题上，这为开发更有效的图基础模型开辟了新途径。

Abstract: Graph Neural Networks operate through bottom-up message-passing,
fundamentally differing from human visual perception, which intuitively
captures global structures first. We investigate the underappreciated potential
of vision models for graph understanding, finding they achieve performance
comparable to GNNs on established benchmarks while exhibiting distinctly
different learning patterns. These divergent behaviors, combined with
limitations of existing benchmarks that conflate domain features with
topological understanding, motivate our introduction of GraphAbstract. This
benchmark evaluates models' ability to perceive global graph properties as
humans do: recognizing organizational archetypes, detecting symmetry, sensing
connectivity strength, and identifying critical elements. Our results reveal
that vision models significantly outperform GNNs on tasks requiring holistic
structural understanding and maintain generalizability across varying graph
scales, while GNNs struggle with global pattern abstraction and degrade with
increasing graph size. This work demonstrates that vision models possess
remarkable yet underutilized capabilities for graph structural understanding,
particularly for problems requiring global topological awareness and
scale-invariant reasoning. These findings open new avenues to leverage this
underappreciated potential for developing more effective graph foundation
models for tasks dominated by holistic pattern recognition.

</details>


### [11] [A Re-node Self-training Approach for Deep Graph-based Semi-supervised Classification on Multi-view Image Data](https://arxiv.org/abs/2510.24791)
*Jingjun Bi,Fadi Dornaika*

Main category: cs.CV

TL;DR: 提出RSGSLM方法，结合图卷积网络、伪标签和拓扑平衡校正，用于多视图数据的半监督学习


<details>
  <summary>Details</summary>
Motivation: 解决图像数据缺乏清晰图结构以及多视图数据复杂性对传统方法效率的限制，以及多视图数据中图结构整合的挑战

Method: 结合线性特征变换和多视图图融合的GCN框架，动态整合伪标签到损失函数，校正类边界附近标记样本的拓扑不平衡，引入适用于所有样本的无监督平滑损失

Result: 在多视图基准图像数据集上的实验表明，RSGSLM在多视图环境下超越了现有的半监督学习方法

Conclusion: RSGSLM通过优化图结构整合和伪标签利用，在多视图半监督学习中实现了优越性能，同时保持了计算效率

Abstract: Recently, graph-based semi-supervised learning and pseudo-labeling have
gained attention due to their effectiveness in reducing the need for extensive
data annotations. Pseudo-labeling uses predictions from unlabeled data to
improve model training, while graph-based methods are characterized by
processing data represented as graphs. However, the lack of clear graph
structures in images combined with the complexity of multi-view data limits the
efficiency of traditional and existing techniques. Moreover, the integration of
graph structures in multi-view data is still a challenge. In this paper, we
propose Re-node Self-taught Graph-based Semi-supervised Learning for Multi-view
Data (RSGSLM). Our method addresses these challenges by (i) combining linear
feature transformation and multi-view graph fusion within a Graph Convolutional
Network (GCN) framework, (ii) dynamically incorporating pseudo-labels into the
GCN loss function to improve classification in multi-view data, and (iii)
correcting topological imbalances by adjusting the weights of labeled samples
near class boundaries. Additionally, (iv) we introduce an unsupervised
smoothing loss applicable to all samples. This combination optimizes
performance while maintaining computational efficiency. Experimental results on
multi-view benchmark image datasets demonstrate that RSGSLM surpasses existing
semi-supervised learning approaches in multi-view contexts.

</details>


### [12] [PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models](https://arxiv.org/abs/2510.24792)
*Patrick Haller,Fabio Barth,Jonas Golde,Georg Rehm,Alan Akbik*

Main category: cs.CV

TL;DR: PISA-Bench是一个多语言视觉语言基准测试，基于专家创建的PISA测试构建，覆盖6种语言，用于评估多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏高质量人工验证样本，多依赖LLM生成内容且仅限于英语，需要多语言高质量数据集来推动多模态推理研究。

Method: 从PISA测试中提取人工创建的指令、问题、选项和图像，翻译成5种语言，构建完全平行的6语言语料库。

Result: 评估发现小模型(<20B参数)得分低，非英语版本性能显著下降，空间和几何推理错误率高。

Conclusion: PISA-Bench为多语言多模态推理研究提供了重要资源，揭示了当前模型在跨语言和复杂推理任务上的局限性。

Abstract: Vision-language models (VLMs) have demonstrated remarkable progress in
multimodal reasoning. However, existing benchmarks remain limited in terms of
high-quality, human-verified examples. Many current datasets rely on
synthetically generated content by large language models (LLMs). Furthermore,
most datasets are limited to English, as manual quality assurance of translated
samples is time-consuming and costly. To fill this gap, we introduce
PISA-Bench, a multilingual benchmark derived from English examples of the
expert-created PISA tests, a unified framework for the assessment of student
competencies in over eighty countries. Each example consists of human-extracted
instructions, questions, answer options, and images, enriched with question
type categories, and has been translated from English into five additional
languages (Spanish, German, Chinese, French, and Italian), resulting in a fully
parallel corpus covering six languages. We evaluate state-of-the-art
vision-language models on PISA-Bench and find that especially small models
(<20B parameters) fail to achieve high test scores. We further find substantial
performance degradation on non-English splits as well as high error-rates when
models are tasked with spatial and geometric reasoning. By releasing the
dataset and evaluation framework, we provide a resource for advancing research
on multilingual multimodal reasoning.

</details>


### [13] [A Survey on Efficient Vision-Language-Action Models](https://arxiv.org/abs/2510.24795)
*Zhaoshu Yu,Bo Wang,Pengpeng Zeng,Haonan Zhang,Ji Zhang,Lianli Gao,Jingkuan Song,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: 这篇论文首次全面综述了高效视觉-语言-动作模型（Efficient VLAs），提出了统一分类法将现有技术分为三个核心支柱：高效模型设计、高效训练和高效数据收集。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在具身智能中具有重要作用，但其部署受到计算和数据需求巨大的限制，迫切需要解决这些挑战。

Method: 引入统一分类法，系统组织该领域的不同努力，将现有技术分为三个核心支柱：高效模型设计（关注高效架构和模型压缩）、高效训练（减少模型学习期间的计算负担）和高效数据收集（解决机器人数据获取和利用的瓶颈）。

Result: 通过在这一框架内批判性回顾最先进方法，为社区建立了基础参考，总结了代表性应用，阐明了关键挑战。

Conclusion: 为未来研究制定了路线图，并维护持续更新的项目页面以跟踪最新进展。

Abstract: Vision-Language-Action models (VLAs) represent a significant frontier in
embodied intelligence, aiming to bridge digital knowledge with physical-world
interaction. While these models have demonstrated remarkable generalist
capabilities, their deployment is severely hampered by the substantial
computational and data requirements inherent to their underlying large-scale
foundation models. Motivated by the urgent need to address these challenges,
this survey presents the first comprehensive review of Efficient
Vision-Language-Action models (Efficient VLAs) across the entire
data-model-training process. Specifically, we introduce a unified taxonomy to
systematically organize the disparate efforts in this domain, categorizing
current techniques into three core pillars: (1) Efficient Model Design,
focusing on efficient architectures and model compression; (2) Efficient
Training, which reduces computational burdens during model learning; and (3)
Efficient Data Collection, which addresses the bottlenecks in acquiring and
utilizing robotic data. Through a critical review of state-of-the-art methods
within this framework, this survey not only establishes a foundational
reference for the community but also summarizes representative applications,
delineates key challenges, and charts a roadmap for future research. We
maintain a continuously updated project page to track our latest developments:
https://evla-survey.github.io/

</details>


### [14] [Conflict Adaptation in Vision-Language Models](https://arxiv.org/abs/2510.24804)
*Xiaoyang Hu*

Main category: cs.CV

TL;DR: 研究发现大多数视觉语言模型表现出类似人类的冲突适应行为，通过稀疏自编码器识别出任务相关的超节点，揭示了模型处理Stroop任务的内在机制。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能模型是否展现人类认知控制的关键特征——冲突适应，以及这种行为的表征基础。

Method: 使用顺序Stroop任务测试13个视觉语言模型，并采用稀疏自编码器分析InternVL 3.5 4B模型中的任务相关超节点。

Result: 12个模型表现出冲突适应行为，识别出文本和颜色的部分重叠超节点，发现冲突调节超节点在层24-25，其消融显著增加Stroop错误。

Conclusion: 视觉语言模型能够模拟人类认知控制的冲突适应现象，其内部表征结构与人类自动性不对称相似。

Abstract: A signature of human cognitive control is conflict adaptation: improved
performance on a high-conflict trial following another high-conflict trial.
This phenomenon offers an account for how cognitive control, a scarce resource,
is recruited. Using a sequential Stroop task, we find that 12 of 13
vision-language models (VLMs) tested exhibit behavior consistent with conflict
adaptation, with the lone exception likely reflecting a ceiling effect. To
understand the representational basis of this behavior, we use sparse
autoencoders (SAEs) to identify task-relevant supernodes in InternVL 3.5 4B.
Partially overlapping supernodes emerge for text and color in both early and
late layers, and their relative sizes mirror the automaticity asymmetry between
reading and color naming in humans. We further isolate a conflict-modulated
supernode in layers 24-25 whose ablation significantly increases Stroop errors
while minimally affecting congruent trials.

</details>


### [15] [DualCap: Enhancing Lightweight Image Captioning via Dual Retrieval with Similar Scenes Visual Prompts](https://arxiv.org/abs/2510.24813)
*Binbin Li,Guimiao Yang,Zisen Qi,Haiping Wang,Yu Ding*

Main category: cs.CV

TL;DR: DualCap提出了一种新颖的双重检索机制，通过图像到图像检索生成视觉提示来增强视觉表示，解决现有方法仅使用文本提示造成的语义鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 现有的轻量级检索增强图像描述模型仅将检索数据作为文本提示使用，导致原始视觉特征未得到增强，特别是在对象细节和复杂场景方面存在语义鸿沟。

Method: 采用双重检索机制：标准图像到文本检索用于文本提示，新颖的图像到图像检索用于获取视觉相似场景。从视觉相似场景的标题中提取关键词语和短语，通过轻量级可训练特征融合网络将文本特征与原始图像特征集成。

Result: 大量实验表明，该方法在实现竞争性性能的同时，相比之前的视觉提示描述方法需要更少的可训练参数。

Conclusion: DualCap通过视觉提示增强视觉表示，有效解决了语义鸿沟问题，在保持轻量化的同时提升了图像描述性能。

Abstract: Recent lightweight retrieval-augmented image caption models often utilize
retrieved data solely as text prompts, thereby creating a semantic gap by
leaving the original visual features unenhanced, particularly for object
details or complex scenes. To address this limitation, we propose $DualCap$, a
novel approach that enriches the visual representation by generating a visual
prompt from retrieved similar images. Our model employs a dual retrieval
mechanism, using standard image-to-text retrieval for text prompts and a novel
image-to-image retrieval to source visually analogous scenes. Specifically,
salient keywords and phrases are derived from the captions of visually similar
scenes to capture key objects and similar details. These textual features are
then encoded and integrated with the original image features through a
lightweight, trainable feature fusion network. Extensive experiments
demonstrate that our method achieves competitive performance while requiring
fewer trainable parameters compared to previous visual-prompting captioning
approaches.

</details>


### [16] [Deep Feature Optimization for Enhanced Fish Freshness Assessment](https://arxiv.org/abs/2510.24814)
*Phi-Hung Hoang,Nam-Thuan Trinh,Van-Manh Tran,Thi-Thu-Hong Phan*

Main category: cs.CV

TL;DR: 提出一个三阶段框架，结合深度视觉表征和传统机器学习方法，在鱼类新鲜度评估任务上达到85.99%的准确率，比现有方法提升8.69-22.78%。


<details>
  <summary>Details</summary>
Motivation: 传统感官评估鱼类新鲜度存在主观性、耗时和不一致的问题，现有深度学习方法在准确性和特征透明度方面仍有挑战。

Method: 三阶段框架：1) 微调五种先进视觉架构；2) 提取多层级深度特征训练七种传统分类器；3) 使用LGBM、随机森林和Lasso进行特征选择。

Result: 在FFE数据集上，Swin-Tiny特征+Extra Trees分类器+LGBM特征选择的最佳组合达到85.99%准确率，显著优于现有方法。

Conclusion: 该框架在视觉质量评估任务中表现出有效性和泛化能力，为鱼类新鲜度评估提供了可靠解决方案。

Abstract: Assessing fish freshness is vital for ensuring food safety and minimizing
economic losses in the seafood industry. However, traditional sensory
evaluation remains subjective, time-consuming, and inconsistent. Although
recent advances in deep learning have automated visual freshness prediction,
challenges related to accuracy and feature transparency persist. This study
introduces a unified three-stage framework that refines and leverages deep
visual representations for reliable fish freshness assessment. First, five
state-of-the-art vision architectures - ResNet-50, DenseNet-121,
EfficientNet-B0, ConvNeXt-Base, and Swin-Tiny - are fine-tuned to establish a
strong baseline. Next, multi-level deep features extracted from these backbones
are used to train seven classical machine learning classifiers, integrating
deep and traditional decision mechanisms. Finally, feature selection methods
based on Light Gradient Boosting Machine (LGBM), Random Forest, and Lasso
identify a compact and informative subset of features. Experiments on the
Freshness of the Fish Eyes (FFE) dataset demonstrate that the best
configuration combining Swin-Tiny features, an Extra Trees classifier, and
LGBM-based feature selection achieves an accuracy of 85.99%, outperforming
recent studies on the same dataset by 8.69-22.78%. These findings confirm the
effectiveness and generalizability of the proposed framework for visual quality
evaluation tasks.

</details>


### [17] [Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection](https://arxiv.org/abs/2510.24816)
*Cui Yakun,Fushuo Huo,Weijie Shi,Juntao Dai,Hang Du,Zhenghao Zhu,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: 提出了MVFNDB多模态视频假新闻检测基准，包含10个任务和9730个人工标注问题，用于评估MLLMs在检测过程中的感知、理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统视频假新闻检测基准只关注最终决策准确性，缺乏对检测过程的细粒度评估，使检测过程成为黑箱。

Method: 基于经验分析构建MVFNDB基准，设计MVFND-CoT框架，结合创作者添加内容和原始拍摄素材推理，分析视频处理策略和视频特征与模型能力的对齐。

Result: 建立了包含10个任务和9730个问题的综合基准，为MLLMs在视频假新闻检测领域的评估提供了基础。

Conclusion: 该基准将为MLLMs在视频假新闻检测领域的未来评估和发展奠定坚实基础。

Abstract: The advent of multi-modal large language models (MLLMs) has greatly advanced
research into applications for Video fake news detection (VFND) tasks.
Traditional video-based FND benchmarks typically focus on the accuracy of the
final decision, often failing to provide fine-grained assessments for the
entire detection process, making the detection process a black box. Therefore,
we introduce the MVFNDB (Multi-modal Video Fake News Detection Benchmark) based
on the empirical analysis, which provides foundation for tasks definition. The
benchmark comprises 10 tasks and is meticulously crafted to probe MLLMs'
perception, understanding, and reasoning capacities during detection, featuring
9730 human-annotated video-related questions based on a carefully constructed
taxonomy ability of VFND. To validate the impact of combining multiple features
on the final results, we design a novel framework named MVFND-CoT, which
incorporates both creator-added content and original shooting footage
reasoning. Building upon the benchmark, we conduct an in-depth analysis of the
deeper factors influencing accuracy, including video processing strategies and
the alignment between video features and model capabilities. We believe this
benchmark will lay a solid foundation for future evaluations and advancements
of MLLMs in the domain of video fake news detection.

</details>


### [18] [SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing](https://arxiv.org/abs/2510.24820)
*Ruiyang Zhang,Jiahao Luo,Xiaoru Feng,Qiufan Pang,Yaodong Yang,Juntao Dai*

Main category: cs.CV

TL;DR: 提出了一种多轮安全编辑框架MR-SafeEdit，通过构建多轮图文交错数据集，开发统一MLLM模型SafeEditor，实现文本到图像模型的安全对齐，减少过度拒绝并改善安全与效用的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型的安全方法存在过度拒绝和安全与效用不平衡的问题，需要开发更有效的安全对齐方案。

Method: 提出多轮安全编辑框架，构建MR-SafeEdit数据集，开发SafeEditor统一MLLM模型，采用后验安全编辑范式模拟人类认知过程。

Result: 实验结果表明SafeEditor优于现有安全方法，减少过度拒绝，实现更好的安全-效用平衡。

Conclusion: 该框架作为模型无关的即插即用模块，能够高效地对任何文本到图像模型进行安全对齐。

Abstract: With the rapid advancement of text-to-image (T2I) models, ensuring their
safety has become increasingly critical. Existing safety approaches can be
categorized into training-time and inference-time methods. While inference-time
methods are widely adopted due to their cost-effectiveness, they often suffer
from limitations such as over-refusal and imbalance between safety and utility.
To address these challenges, we propose a multi-round safety editing framework
that functions as a model-agnostic, plug-and-play module, enabling efficient
safety alignment for any text-to-image model. Central to this framework is
MR-SafeEdit, a multi-round image-text interleaved dataset specifically
constructed for safety editing in text-to-image generation. We introduce a
post-hoc safety editing paradigm that mirrors the human cognitive process of
identifying and refining unsafe content. To instantiate this paradigm, we
develop SafeEditor, a unified MLLM capable of multi-round safety editing on
generated images. Experimental results show that SafeEditor surpasses prior
safety approaches by reducing over-refusal while achieving a more favorable
safety-utility balance.

</details>


### [19] [Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation](https://arxiv.org/abs/2510.24821)
*Inclusion AI,:,Bowen Ma,Cheng Zou,Canxiang Yan,Chunxiang Jin,Chunjie Shen,Dandan Zheng,Fudong Wang,Furong Xu,GuangMing Yao,Jun Zhou,Jingdong Chen,Jianing Li,Jianxin Sun,Jiajia Liu,Jianjiang Zhu,Jianping Jiang,Jun Peng,Kaixiang Ji,Kaimeng Ren,Libin Wang,Lixiang Ru,Longhua Tan,Lan Wang,Mochen Bai,Ning Gao,Qingpei Guo,Qinglong Zhang,Qiang Xu,Rui Liu,Ruijie Xiong,Ruobing Zheng,Sirui Gao,Tianqi Li,Tinghao Liu,Weilong Chai,Xinyu Xiao,Xiaomei Wang,Xiaolong Wang,Xiao Lu,Xiaoyu Li,Xingning Dong,Xuzheng Yu,Yi Yuan,Yuting Gao,Yuting Xiao,Yunxiao Sun,Yipeng Chen,Yifan Mao,Yifei Wu,Yongjie Lyu,Ziping Ma,Zhiqiang Fang,Zhihao Qiu,Ziyuan Huang,Zizheng Yang,Zhengyu He*

Main category: cs.CV

TL;DR: Ming-Flash-Omni是基于稀疏MoE架构的升级版多模态模型，在图像生成、语音识别和生成分割等任务上取得SOTA性能，使用1000亿总参数但仅激活61亿参数，实现了高效扩展和统一的多模态智能。


<details>
  <summary>Details</summary>
Motivation: 构建更高效、更强大的统一多模态智能系统，通过稀疏MoE架构实现计算效率与模型容量的平衡，推动AGI发展。

Method: 基于Ling-Flash-2.0的稀疏MoE变体，总参数1000亿但每token仅激活61亿参数，支持视觉、语音和语言的统一处理。

Result: 在上下文ASR中实现SOTA性能，在方言ASR中表现优异；图像生成中实现高保真文本渲染和编辑一致性；生成分割能力增强空间控制和编辑一致性；在12个ASR基准测试中创下新记录。

Conclusion: Ming-Flash-Omni通过稀疏MoE架构成功实现了高效扩展和强大的统一多模态智能，在多个任务上达到SOTA性能，是迈向AGI的重要一步。

Abstract: We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a
sparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion
total parameters, of which only 6.1 billion are active per token. This
architecture enables highly efficient scaling (dramatically improving
computational efficiency while significantly expanding model capacity) and
empowers stronger unified multimodal intelligence across vision, speech, and
language, representing a key step toward Artificial General Intelligence (AGI).
Compared to its predecessor, the upgraded version exhibits substantial
improvements across multimodal understanding and generation. We significantly
advance speech recognition capabilities, achieving state-of-the-art performance
in contextual ASR and highly competitive results in dialect-aware ASR. In image
generation, Ming-Flash-Omni introduces high-fidelity text rendering and
demonstrates marked gains in scene consistency and identity preservation during
image editing. Furthermore, Ming-Flash-Omni introduces generative segmentation,
a capability that not only achieves strong standalone segmentation performance
but also enhances spatial control in image generation and improves editing
consistency. Notably, Ming-Flash-Omni achieves state-of-the-art results in
text-to-image generation and generative segmentation, and sets new records on
all 12 contextual ASR benchmarks, all within a single unified architecture.

</details>


### [20] [MCIHN: A Hybrid Network Model Based on Multi-path Cross-modal Interaction for Multimodal Emotion Recognition](https://arxiv.org/abs/2510.24827)
*Haoyang Zhang,Zhou Yang,Ke Sun,Yucai Pang,Guoliang Xu*

Main category: cs.CV

TL;DR: 提出了一种基于多路径跨模态交互的混合网络模型（MCIHN），通过对抗自编码器和跨模态门机制来改善多模态情感识别性能。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别在人机交互中至关重要，但由于不同模态间的差异和单模态情感信息表征困难，准确的情感识别仍面临重大挑战。

Method: 为每个模态构建对抗自编码器学习判别性情感特征，然后通过预定义的跨模态门机制模型减少模态间差异并生成交互特征，最后使用特征融合模块进行多模态融合。

Result: 在公开的SIMS和MOSI数据集上的实验表明，MCIHN实现了优越的性能。

Conclusion: 所提出的MCIHN模型能有效解决多模态情感识别中的模态差异和特征表征问题，取得了良好的识别效果。

Abstract: Multimodal emotion recognition is crucial for future human-computer
interaction. However, accurate emotion recognition still faces significant
challenges due to differences between different modalities and the difficulty
of characterizing unimodal emotional information. To solve these problems, a
hybrid network model based on multipath cross-modal interaction (MCIHN) is
proposed. First, adversarial autoencoders (AAE) are constructed separately for
each modality. The AAE learns discriminative emotion features and reconstructs
the features through a decoder to obtain more discriminative information about
the emotion classes. Then, the latent codes from the AAE of different
modalities are fed into a predefined Cross-modal Gate Mechanism model (CGMM) to
reduce the discrepancy between modalities, establish the emotional relationship
between interacting modalities, and generate the interaction features between
different modalities. Multimodal fusion using the Feature Fusion module (FFM)
for better emotion recognition. Experiments were conducted on publicly
available SIMS and MOSI datasets, demonstrating that MCIHN achieves superior
performance.

</details>


### [21] [The Generation Phases of Flow Matching: a Denoising Perspective](https://arxiv.org/abs/2510.24830)
*Anne Gagneux,Ségolène Martin,Rémi Gribonval,Mathurin Massias*

Main category: cs.CV

TL;DR: 本文从去噪角度研究流匹配模型的生成过程，建立了流匹配模型与去噪器之间的形式联系，通过设计噪声和漂移扰动来影响样本生成，揭示了生成过程的不同动态阶段。


<details>
  <summary>Details</summary>
Motivation: 流匹配取得了显著成功，但影响其生成过程质量的因素仍不清楚。本文旨在从去噪角度实证探究流匹配的生成过程。

Method: 建立流匹配模型与去噪器之间的形式联系，设计原则性和受控的扰动（噪声和漂移）来影响样本生成，分析生成过程的不同动态阶段。

Result: 揭示了生成过程的独特动态阶段，能够精确描述去噪器在生成过程的哪个阶段成功或失败，以及为什么这很重要。

Conclusion: 通过去噪视角为流匹配生成过程提供了新的理解，建立了比较生成和去噪性能的共同基础，并为影响样本生成提供了原则性方法。

Abstract: Flow matching has achieved remarkable success, yet the factors influencing
the quality of its generation process remain poorly understood. In this work,
we adopt a denoising perspective and design a framework to empirically probe
the generation process. Laying down the formal connections between flow
matching models and denoisers, we provide a common ground to compare their
performances on generation and denoising. This enables the design of principled
and controlled perturbations to influence sample generation: noise and drift.
This leads to new insights on the distinct dynamical phases of the generative
process, enabling us to precisely characterize at which stage of the generative
process denoisers succeed or fail and why this matters.

</details>


### [22] [FruitProm: Probabilistic Maturity Estimation and Detection of Fruits and Vegetables](https://arxiv.org/abs/2510.24885)
*Sidharth Rai,Rahul Harsha Cheppally,Benjamin Vail,Keziban Yalçın Dokumacı,Ajay Sharda*

Main category: cs.CV

TL;DR: 将水果蔬菜成熟度估计从离散分类问题重构为连续概率学习任务，提出在RT-DETRv2检测器中添加概率头，预测成熟度连续分布和不确定性，在保持85.6% mAP检测性能的同时提供更精细的成熟度评估。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法将成熟度作为离散分类问题处理，这与生物成熟过程的连续性本质相冲突，导致信息丢失和类别边界模糊。需要更符合生物学实际的连续概率表示方法。

Method: 在RT-DETRv2实时目标检测器中引入专用概率头，使模型能够为每个检测对象预测成熟度谱上的连续分布，同时学习平均成熟状态及其相关不确定性。

Result: 在具有挑战性的大规模水果数据集上达到85.6%的平均精度(mAP)，比基于分类的方法提供更精细和准确的成熟度评估，同时保持优异的检测性能。

Conclusion: 概率方法为现代农业中的智能、不确定性感知自动化系统提供了更丰富、更符合生物学实际的植物成熟度表示，特别适用于机器人选择性收获等下游决策任务。

Abstract: Maturity estimation of fruits and vegetables is a critical task for
agricultural automation, directly impacting yield prediction and robotic
harvesting. Current deep learning approaches predominantly treat maturity as a
discrete classification problem (e.g., unripe, ripe, overripe). This rigid
formulation, however, fundamentally conflicts with the continuous nature of the
biological ripening process, leading to information loss and ambiguous class
boundaries. In this paper, we challenge this paradigm by reframing maturity
estimation as a continuous, probabilistic learning task. We propose a novel
architectural modification to the state-of-the-art, real-time object detector,
RT-DETRv2, by introducing a dedicated probabilistic head. This head enables the
model to predict a continuous distribution over the maturity spectrum for each
detected object, simultaneously learning the mean maturity state and its
associated uncertainty. This uncertainty measure is crucial for downstream
decision-making in robotics, providing a confidence score for tasks like
selective harvesting. Our model not only provides a far richer and more
biologically plausible representation of plant maturity but also maintains
exceptional detection performance, achieving a mean Average Precision (mAP) of
85.6\% on a challenging, large-scale fruit dataset. We demonstrate through
extensive experiments that our probabilistic approach offers more granular and
accurate maturity assessments than its classification-based counterparts,
paving the way for more intelligent, uncertainty-aware automated systems in
modern agriculture

</details>


### [23] [Proper Body Landmark Subset Enables More Accurate and 5X Faster Recognition of Isolated Signs in LIBRAS](https://arxiv.org/abs/2510.24887)
*Daniele L. V. dos Santos,Thiago B. Pereira,Carlos Eduardo G. R. Alves,Richard J. M. G. Tello,Francisco de A. Boldt,Thiago M. Paixão*

Main category: cs.CV

TL;DR: 使用轻量级身体关键点检测识别巴西手语(LIBRAS)孤立手势，通过关键点子集选择和样条插值技术，在保持精度的同时将处理速度提升5倍以上。


<details>
  <summary>Details</summary>
Motivation: 解决基于骨架的手语识别方法中OpenPose提取关键点导致的时间性能问题，同时避免直接使用轻量级MediaPipe带来的精度下降。

Method: 探索关键点子集选择策略优化识别性能，结合样条插值技术处理缺失关键点问题。

Result: 适当的关键点子集达到或优于最先进方法的性能，处理时间相比Alves等人(2024)的方法减少5倍以上，样条插值显著提升准确率。

Conclusion: 精心选择关键点结合简单插值技术，能够实现高效准确的手语识别，为可扩展的手语识别系统铺平道路。

Abstract: This paper investigates the feasibility of using lightweight body landmark
detection for the recognition of isolated signs in Brazilian Sign Language
(LIBRAS). Although the skeleton-based approach by Alves et al. (2024) enabled
substantial improvements in recognition performance, the use of OpenPose for
landmark extraction hindered time performance. In a preliminary investigation,
we observed that simply replacing OpenPose with the lightweight MediaPipe,
while improving processing speed, significantly reduced accuracy. To overcome
this limitation, we explored landmark subset selection strategies aimed at
optimizing recognition performance. Experimental results showed that a proper
landmark subset achieves comparable or superior performance to state-of-the-art
methods while reducing processing time by more than 5X compared to Alves et al.
(2024). As an additional contribution, we demonstrated that spline-based
imputation effectively mitigates missing landmark issues, leading to
substantial accuracy gains. These findings highlight that careful landmark
selection, combined with simple imputation techniques, enables efficient and
accurate isolated sign recognition, paving the way for scalable Sign Language
Recognition systems.

</details>


### [24] [Pixels to Signals: A Real-Time Framework for Traffic Demand Estimation](https://arxiv.org/abs/2510.24902)
*H Mhatre,M Vyas,A Mittal*

Main category: cs.CV

TL;DR: 提出一种基于背景建模和DBSCAN聚类的车辆检测方法，用于优化城市交通流和减少延误。


<details>
  <summary>Details</summary>
Motivation: 快速发展的城市中交通拥堵日益严重，导致交通系统效率低下和延误增加，需要有效的解决方案。

Method: 通过分析摄像头连续帧计算背景图像，利用背景减除提取前景，然后应用DBSCAN算法进行车辆检测。

Result: 该方法计算效率高，对基础设施改动要求小，为实际部署提供了实用且可扩展的解决方案。

Conclusion: 所提出的车辆检测方法具有实际应用价值，可作为交通优化框架的重要组成部分。

Abstract: Traffic congestion is becoming a challenge in the rapidly growing urban
cities, resulting in increasing delays and inefficiencies within urban
transportation systems. To address this issue a comprehensive methodology is
designed to optimize traffic flow and minimize delays. The framework is
structured with three primary components: (a) vehicle detection, (b) traffic
prediction, and (c) traffic signal optimization. This paper presents the first
component, vehicle detection. The methodology involves analyzing multiple
sequential frames from a camera feed to compute the background, i.e. the
underlying roadway, by averaging pixel values over time. The computed
background is then utilized to extract the foreground, where the Density-Based
Spatial Clustering of Applications with Noise (DBSCAN) algorithm is applied to
detect vehicles. With its computational efficiency and minimal infrastructure
modification requirements, the proposed methodology offers a practical and
scalable solution for real-world deployment.

</details>


### [25] [VividCam: Learning Unconventional Camera Motions from Virtual Synthetic Videos](https://arxiv.org/abs/2510.24904)
*Qiucheng Wu,Handong Zhao,Zhixin Shu,Jing Shi,Yang Zhang,Shiyu Chang*

Main category: cs.CV

TL;DR: VividCam是一个训练范式，通过合成视频让扩散模型学习复杂相机运动，摆脱对真实训练视频的依赖，使用解耦策略分离相机运动学习和合成外观伪影。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成模型难以泛化到非常规相机运动，因为缺乏包含这些运动的训练视频，这限制了创作原创艺术视频的能力。

Method: 提出VividCam训练范式，使用合成视频（如Unity渲染的低多边形3D场景中的基本几何体）训练扩散模型，采用多重解耦策略隔离相机运动学习和合成外观伪影。

Result: 该方法能够合成广泛精确控制的复杂相机运动，仅使用简单的合成数据即可实现，视频结果展示在项目网站上。

Conclusion: VividCam通过合成数据有效解决了复杂相机运动学习的问题，为创作更具艺术性的视频提供了可行方案。

Abstract: Although recent text-to-video generative models are getting more capable of
following external camera controls, imposed by either text descriptions or
camera trajectories, they still struggle to generalize to unconventional camera
motions, which is crucial in creating truly original and artistic videos. The
challenge lies in the difficulty of finding sufficient training videos with the
intended uncommon camera motions. To address this challenge, we propose
VividCam, a training paradigm that enables diffusion models to learn complex
camera motions from synthetic videos, releasing the reliance on collecting
realistic training videos. VividCam incorporates multiple disentanglement
strategies that isolates camera motion learning from synthetic appearance
artifacts, ensuring more robust motion representation and mitigating domain
shift. We demonstrate that our design synthesizes a wide range of precisely
controlled and complex camera motions using surprisingly simple synthetic data.
Notably, this synthetic data often consists of basic geometries within a
low-poly 3D scene and can be efficiently rendered by engines like Unity. Our
video results can be found in https://wuqiuche.github.io/VividCamDemoPage/ .

</details>


### [26] [Understanding Multi-View Transformers](https://arxiv.org/abs/2510.24907)
*Michal Stary,Julien Gaubil,Ayush Tewari,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本文提出了一种分析和可视化多视图变换器（如DUSt3R）内部机制的方法，通过探测其残差连接来理解3D表示的形成过程。


<details>
  <summary>Details</summary>
Motivation: 多视图变换器虽然能以前馈方式解决3D任务，但其内部机制不透明，这种黑盒特性限制了进一步改进和在安全关键应用中的使用。

Method: 通过探测多视图变换器各层残差连接来分析和可视化3D表示，研究了DUSt3R变体模型在不同块中的潜在状态发展。

Result: 揭示了DUSt3R变体如何通过重构几何来细化对应关系估计，并展示了其与具有更强显式全局姿态归纳偏置方法的差异。

Conclusion: 该方法为理解多视图变换器的内部工作机制提供了新视角，有助于改进模型设计和在可靠性要求高的场景中的应用。

Abstract: Multi-view transformers such as DUSt3R are revolutionizing 3D vision by
solving 3D tasks in a feed-forward manner. However, contrary to previous
optimization-based pipelines, the inner mechanisms of multi-view transformers
are unclear. Their black-box nature makes further improvements beyond data
scaling challenging and complicates usage in safety- and reliability-critical
applications. Here, we present an approach for probing and visualizing 3D
representations from the residual connections of the multi-view transformers'
layers. In this manner, we investigate a variant of the DUSt3R model, shedding
light on the development of its latent state across blocks, the role of the
individual layers, and suggest how it differs from methods with stronger
inductive biases of explicit global pose. Finally, we show that the
investigated variant of DUSt3R estimates correspondences that are refined with
reconstructed geometry. The code used for the analysis is available at
https://github.com/JulienGaubil/und3rstand .

</details>


### [27] [Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation for Harmonized Multimodal Learning](https://arxiv.org/abs/2510.24919)
*Hossein R. Nowdeh,Jie Ji,Xiaolong Ma,Fatemeh Afghah*

Main category: cs.CV

TL;DR: 提出M-SAM框架，通过识别主导模态、分解损失景观和更新权重来平衡多模态学习，提升模型鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中主导模态往往会压制其他模态，限制了模型的泛化能力。

Method: M-SAM在每次迭代中执行三步：1）使用Shapley值识别主导模态；2）分解损失景观，调整损失以优先考虑主导模态的鲁棒性；3）通过调制梯度的反向传播更新权重。

Result: 在四个不同数据集上的实验表明，M-SAM优于最新的优化和梯度操作方法，显著平衡和改进了多模态学习。

Conclusion: M-SAM能够确保主导模态的鲁棒学习，同时增强其他模态的贡献，使模型能够探索和利用互补特征来提升整体性能。

Abstract: In multimodal learning, dominant modalities often overshadow others, limiting
generalization. We propose Modality-Aware Sharpness-Aware Minimization (M-SAM),
a model-agnostic framework that applies to many modalities and supports early
and late fusion scenarios. In every iteration, M-SAM in three steps optimizes
learning. \textbf{First, it identifies the dominant modality} based on
modalities' contribution in the accuracy using Shapley. \textbf{Second, it
decomposes the loss landscape}, or in another language, it modulates the loss
to prioritize the robustness of the model in favor of the dominant modality,
and \textbf{third, M-SAM updates the weights} by backpropagation of modulated
gradients. This ensures robust learning for the dominant modality while
enhancing contributions from others, allowing the model to explore and exploit
complementary features that strengthen overall performance. Extensive
experiments on four diverse datasets show that M-SAM outperforms the latest
state-of-the-art optimization and gradient manipulation methods and
significantly balances and improves multimodal learning.

</details>


### [28] [IBIS: A Powerful Hybrid Architecture for Human Activity Recognition](https://arxiv.org/abs/2510.24936)
*Alison M. Fernandes,Hermes I. Del Monego,Bruno S. Chang,Anelise Munaretto,Hélder M. Fontes,Rui L. Campos*

Main category: cs.CV

TL;DR: 提出了一种名为IBIS的混合架构，结合Inception-BiLSTM和SVM，用于解决Wi-Fi感知中的过拟合问题，在运动识别任务中达到近99%的准确率。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知因其低成本、非侵入式的环境数据采集能力而受到关注，但该领域普遍存在过拟合问题，模型在训练数据上表现良好但无法泛化到新数据。

Method: 引入新颖的混合架构IBIS，集成Inception-BiLSTM和支持向量机(SVM)，旨在提升模型泛化能力并创建更鲁棒的分类边界。

Result: 在多普勒衍生数据上应用该方法，实现了接近99%的运动识别准确率，综合性能指标和混淆矩阵证实了该方案的有效性。

Conclusion: IBIS方法显著提高了Wi-Fi感知模型的泛化性能，为解决过拟合问题提供了有效解决方案。

Abstract: The increasing interest in Wi-Fi sensing stems from its potential to capture
environmental data in a low-cost, non-intrusive way, making it ideal for
applications like healthcare, space occupancy analysis, and gesture-based IoT
control. However, a major limitation in this field is the common problem of
overfitting, where models perform well on training data but fail to generalize
to new data. To overcome this, we introduce a novel hybrid architecture that
integrates Inception-BiLSTM with a Support Vector Machine (SVM), which we refer
to as IBIS. Our IBIS approach is uniquely engineered to improve model
generalization and create more robust classification boundaries. By applying
this method to Doppler-derived data, we achieve a movement recognition accuracy
of nearly 99%. Comprehensive performance metrics and confusion matrices confirm
the significant effectiveness of our proposed solution.

</details>


### [29] [FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning](https://arxiv.org/abs/2510.24980)
*Reza Saadati Fard,Emmanuel Agu,Palawat Busaranuvong,Deepak Kumar,Shefalika Gautam,Bengisu Tulu,Diane Strong,Lorraine Loretz*

Main category: cs.CV

TL;DR: FT-ARM是一种基于多模态大语言模型的压力性溃疡严重程度分类方法，通过微调和自反思维制实现85%的分类准确率，比现有CNN模型提升4%，并提供临床可解释的自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 压力性溃疡严重程度分类具有挑战性，现有AI方法准确率有限且缺乏可解释性，需要开发更可靠、透明且适用于临床应用的自动化评估系统。

Method: 基于LLaMA 3.2 90B微调的多模态大语言模型，采用类似临床医生诊断重评估的自反思维制，通过迭代推理视觉特征和编码的临床知识来优化预测。

Result: 在公开的PIID数据集上，FT-ARM对I-IV期压力性溃疡的分类准确率达到85%，比之前的CNN模型提升4%，并支持实时推理和临床可解释的自然语言输出。

Conclusion: FT-ARM通过整合微调和多模态输入的反思维维，提高了自动化伤口评估系统的可靠性、透明度和临床适用性，解决了压力性溃疡分期一致性和可解释性的关键需求。

Abstract: Pressure ulcers (PUs) are a serious and prevalent healthcare concern.
Accurate classification of PU severity (Stages I-IV) is essential for proper
treatment but remains challenging due to subtle visual distinctions and
subjective interpretation, leading to variability among clinicians. Prior
AI-based approaches using Convolutional Neural Networks (CNNs) and Vision
Transformers (ViTs) achieved promising accuracy but offered limited
interpretability. We present FT-ARM (Fine-Tuned Agentic Reflection Multimodal
model), a fine-tuned multimodal large language model (MLLM) with an agentic
self-reflection mechanism for pressure ulcer severity classification. Inspired
by clinician-style diagnostic reassessment, FT-ARM iteratively refines its
predictions by reasoning over visual features and encoded clinical knowledge
from text, enhancing both accuracy and consistency. On the publicly available
Pressure Injury Image Dataset (PIID), FT-ARM, fine-tuned from LLaMA 3.2 90B,
achieved 85% accuracy in classifying PU stages I-IV, surpassing prior CNN-based
models by +4%. Unlike earlier CNN/ViT studies that relied solely on offline
evaluations, FT-ARM is designed and tested for live inference, reflecting
real-time deployment conditions. Furthermore, it produces clinically grounded
natural-language explanations, improving interpretability and trust. By
integrating fine-tuning and reflective reasoning across multimodal inputs,
FT-ARM advances the reliability, transparency, and clinical applicability of
automated wound assessment systems, addressing the critical need for consistent
and explainable PU staging to support improved patient care.

</details>


### [30] [Efficient License Plate Recognition via Pseudo-Labeled Supervision with Grounding DINO and YOLOv8](https://arxiv.org/abs/2510.25032)
*Zahra Ebrahimi Vargoorani,Amir Mohammad Ghoreyshi,Ching Yee Suen*

Main category: cs.CV

TL;DR: 提出基于YOLOv8和半监督学习的车牌识别系统，结合人工标注和Grounding DINO生成的伪标签，在多个数据集上取得高召回率。


<details>
  <summary>Details</summary>
Motivation: 解决车牌识别系统在复杂环境因素（光照、雨、灰尘）、高速车辆、不同摄像头角度和低质量图像下的准确性问题。

Method: 使用YOLOv8进行车牌检测和识别，采用半监督学习框架，结合少量人工标注数据和Grounding DINO生成的伪标签来训练检测模型。

Result: 在CENPARMI数据集上达到94%召回率，在UFPR-ALPR数据集上达到91%召回率，并报告了两个数据集的字符错误率。

Conclusion: 该方法通过半监督学习有效减少了人工标注需求，同时保持了标签质量，显著提升了训练过程和模型整体性能。

Abstract: Developing a highly accurate automatic license plate recognition system
(ALPR) is challenging due to environmental factors such as lighting, rain, and
dust. Additional difficulties include high vehicle speeds, varying camera
angles, and low-quality or low-resolution images. ALPR is vital in traffic
control, parking, vehicle tracking, toll collection, and law enforcement
applications. This paper proposes a deep learning strategy using YOLOv8 for
license plate detection and recognition tasks. This method seeks to enhance the
performance of the model using datasets from Ontario, Quebec, California, and
New York State. It achieved an impressive recall rate of 94% on the dataset
from the Center for Pattern Recognition and Machine Intelligence (CENPARMI) and
91% on the UFPR-ALPR dataset. In addition, our method follows a semi-supervised
learning framework, combining a small set of manually labeled data with
pseudo-labels generated by Grounding DINO to train our detection model.
Grounding DINO, a powerful vision-language model, automatically annotates many
images with bounding boxes for license plates, thereby minimizing the reliance
on labor-intensive manual labeling. By integrating human-verified and
model-generated annotations, we can scale our dataset efficiently while
maintaining label quality, which significantly enhances the training process
and overall model performance. Furthermore, it reports character error rates
for both datasets, providing additional insight into system performance.

</details>


### [31] [Breast Cancer VLMs: Clinically Practical Vision-Language Train-Inference Models](https://arxiv.org/abs/2510.25051)
*Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba*

Main category: cs.CV

TL;DR: 提出了一种结合2D乳腺X光片视觉特征与临床元数据文本描述的多模态框架，通过卷积神经网络与语言表征的协同整合，在癌症检测和钙化识别方面优于单模态基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有计算机辅助诊断系统在临床部署中存在局限性，特别是在处理多模态数据的细微解释和需要既往临床病史方面存在可行性问题。

Method: 开发了新颖的框架，通过创新的标记化模块将2D乳腺X光片的视觉特征与来自易获取临床元数据和合成放射学报告的结构化文本描述相结合，战略性地整合卷积神经网络与语言表征。

Result: 在多国队列筛查乳腺X光片上的评估显示，该方法在癌症检测和钙化识别方面优于单模态基线，特别在性能上有显著提升。

Conclusion: 该方法为开发临床可行的基于视觉语言模型的计算机制助诊断系统建立了新范式，通过有效的融合机制充分利用影像数据和上下文患者信息。

Abstract: Breast cancer remains the most commonly diagnosed malignancy among women in
the developed world. Early detection through mammography screening plays a
pivotal role in reducing mortality rates. While computer-aided diagnosis (CAD)
systems have shown promise in assisting radiologists, existing approaches face
critical limitations in clinical deployment - particularly in handling the
nuanced interpretation of multi-modal data and feasibility due to the
requirement of prior clinical history. This study introduces a novel framework
that synergistically combines visual features from 2D mammograms with
structured textual descriptors derived from easily accessible clinical metadata
and synthesized radiological reports through innovative tokenization modules.
Our proposed methods in this study demonstrate that strategic integration of
convolutional neural networks (ConvNets) with language representations achieves
superior performance to vision transformer-based models while handling
high-resolution images and enabling practical deployment across diverse
populations. By evaluating it on multi-national cohort screening mammograms,
our multi-modal approach achieves superior performance in cancer detection and
calcification identification compared to unimodal baselines, with particular
improvements. The proposed method establishes a new paradigm for developing
clinically viable VLM-based CAD systems that effectively leverage imaging data
and contextual patient information through effective fusion mechanisms.

</details>


### [32] [Auto3DSeg for Brain Tumor Segmentation from 3D MRI in BraTS 2023 Challenge](https://arxiv.org/abs/2510.25058)
*Andriy Myronenko,Dong Yang,Yufan He,Daguang Xu*

Main category: cs.CV

TL;DR: 使用MONAI的Auto3DSeg在BraTS 2023挑战赛中取得优异成绩，在5个分割挑战中获得3项第一、2项第二


<details>
  <summary>Details</summary>
Motivation: 参与BraTS 2023挑战赛的所有5个分割任务，展示Auto3DSeg在医学图像分割中的有效性

Method: 使用MONAI框架中的Auto3DSeg方法进行3D医学图像分割

Result: 在脑转移瘤、脑膜瘤、BraTS-Africa挑战中获得第一名，在成人和儿童胶质瘤挑战中获得第二名

Conclusion: Auto3DSeg方法在BraTS 2023挑战赛中表现出色，证明了其在多种脑肿瘤分割任务中的有效性

Abstract: In this work, we describe our solution to the BraTS 2023 cluster of
challenges using Auto3DSeg from MONAI. We participated in all 5 segmentation
challenges, and achieved the 1st place results in three of them: Brain
Metastasis, Brain Meningioma, BraTS-Africa challenges, and the 2nd place
results in the remaining two: Adult and Pediatic Glioma challenges.

</details>


### [33] [Seeing Clearly and Deeply: An RGBD Imaging Approach with a Bio-inspired Monocentric Design](https://arxiv.org/abs/2510.25314)
*Zongxi Yu,Xiaolong Qian,Shaohua Gao,Qi Jiang,Yao Gao,Kailun Yang,Kaiwei Wang*

Main category: cs.CV

TL;DR: 提出了一种仿生单中心成像框架，通过全球面单中心透镜自然编码深度信息，结合物理模拟和双头重建网络，从单次编码捕获中同时恢复高质量全焦图像和精确深度图。


<details>
  <summary>Details</summary>
Motivation: 解决紧凑RGBD成像的双重挑战：传统紧凑光学系统难以在整个景深范围内保持RGB清晰度，而纯软件单目深度估计依赖不可靠的语义先验。现有深度光学系统在制造复杂度和色差方面存在权衡。

Method: 提出仿生全球面单中心透镜设计，建立物理前向模型生成合成数据集，与双头多尺度重建网络协同设计，共享编码器联合恢复全焦图像和深度图。

Result: 深度估计达到Abs Rel 0.026和RMSE 0.130，显著优于纯软件方法和其他深度光学系统；图像恢复达到SSIM 0.960和LPIPS 0.082，在图像保真度和深度精度间取得优越平衡。

Conclusion: 仿生全球面光学与联合重建算法的结合是解决高性能紧凑RGBD成像内在挑战的有效策略。

Abstract: Achieving high-fidelity, compact RGBD imaging presents a dual challenge:
conventional compact optics struggle with RGB sharpness across the entire
depth-of-field, while software-only Monocular Depth Estimation (MDE) is an
ill-posed problem reliant on unreliable semantic priors. While deep optics with
elements like DOEs can encode depth, they introduce trade-offs in fabrication
complexity and chromatic aberrations, compromising simplicity. To address this,
we first introduce a novel bio-inspired all-spherical monocentric lens, around
which we build the Bionic Monocentric Imaging (BMI) framework, a holistic
co-design. This optical design naturally encodes depth into its depth-varying
Point Spread Functions (PSFs) without requiring complex diffractive or freeform
elements. We establish a rigorous physically-based forward model to generate a
synthetic dataset by precisely simulating the optical degradation process. This
simulation pipeline is co-designed with a dual-head, multi-scale reconstruction
network that employs a shared encoder to jointly recover a high-fidelity
All-in-Focus (AiF) image and a precise depth map from a single coded capture.
Extensive experiments validate the state-of-the-art performance of the proposed
framework. In depth estimation, the method attains an Abs Rel of 0.026 and an
RMSE of 0.130, markedly outperforming leading software-only approaches and
other deep optics systems. For image restoration, the system achieves an SSIM
of 0.960 and a perceptual LPIPS score of 0.082, thereby confirming a superior
balance between image fidelity and depth accuracy. This study illustrates that
the integration of bio-inspired, fully spherical optics with a joint
reconstruction algorithm constitutes an effective strategy for addressing the
intrinsic challenges in high-performance compact RGBD imaging. Source code will
be publicly available at https://github.com/ZongxiYu-ZJU/BMI.

</details>


### [34] [DRIP: Dynamic patch Reduction via Interpretable Pooling](https://arxiv.org/abs/2510.25067)
*Yusen Peng,Sachin Kumar*

Main category: cs.CV

TL;DR: 提出DRIP方法，通过可解释池化动态减少视觉编码器深层中的token数量，显著降低计算量同时保持性能


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的大规模预训练成本高昂，阻碍了从头开始预训练的研究，需要提高效率

Method: DRIP方法根据输入图像自适应地在视觉编码器深层动态合并token

Result: 在ImageNet从头训练和CLIP对比预训练中显著减少GFLOPs，同时保持可比的分类/零样本性能

Conclusion: DRIP方法有效降低了视觉语言模型预训练的计算成本，并在科学领域得到验证

Abstract: Recently, the advances in vision-language models, including contrastive
pretraining and instruction tuning, have greatly pushed the frontier of
multimodal AI. However, owing to the large-scale and hence expensive
pretraining, the efficiency concern has discouraged researchers from attempting
to pretrain a vision language model from scratch. In this work, we propose
Dynamic patch Reduction via Interpretable Pooling (DRIP), which adapts to the
input images and dynamically merges tokens in the deeper layers of a visual
encoder. Our results on both ImageNet training from scratch and CLIP
contrastive pretraining demonstrate a significant GFLOP reduction while
maintaining comparable classification/zero-shot performance. To further
validate our proposed method, we conduct continual pretraining on a large
biology dataset, extending its impact into scientific domains.

</details>


### [35] [SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments](https://arxiv.org/abs/2510.25463)
*Hongjie Zhang,Gideon Billings,Stefan B. Williams*

Main category: cs.CV

TL;DR: SPADE是一种用于水下基础设施检查的单目深度估计方法，结合预训练相对深度估计器和稀疏深度先验，生成密集的度量尺度深度图，在嵌入式硬件上运行效率超过15 FPS。


<details>
  <summary>Details</summary>
Motivation: 水下基础设施需要频繁检查和维护，但当前依赖人类潜水员或遥控水下航行器存在感知和操作挑战，特别是在复杂结构或浑浊水域中。增强水下航行器的空间感知能力对于降低操控风险和实现更高自主性至关重要。

Method: 提出SPADE：稀疏自适应深度估计器，采用两阶段方法：首先用稀疏深度点缩放相对深度图，然后使用提出的级联卷积-可变形Transformer块细化最终度量预测。

Result: 该方法在准确性和泛化能力上优于最先进的基线方法，在嵌入式硬件上运行效率超过15 FPS。

Conclusion: SPADE方法有望支持实用的水下检查和干预任务，已提交至IEEE海洋工程期刊AUV 2026特刊。

Abstract: Underwater infrastructure requires frequent inspection and maintenance due to
harsh marine conditions. Current reliance on human divers or remotely operated
vehicles is limited by perceptual and operational challenges, especially around
complex structures or in turbid water. Enhancing the spatial awareness of
underwater vehicles is key to reducing piloting risks and enabling greater
autonomy. To address these challenges, we present SPADE: SParsity Adaptive
Depth Estimator, a monocular depth estimation pipeline that combines
pre-trained relative depth estimator with sparse depth priors to produce dense,
metric scale depth maps. Our two-stage approach first scales the relative depth
map with the sparse depth points, then refines the final metric prediction with
our proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves
improved accuracy and generalisation over state-of-the-art baselines and runs
efficiently at over 15 FPS on embedded hardware, promising to support practical
underwater inspection and intervention. This work has been submitted to IEEE
Journal of Oceanic Engineering Special Issue of AUV 2026.

</details>


### [36] [Vision-Language Integration for Zero-Shot Scene Understanding in Real-World Environments](https://arxiv.org/abs/2510.25070)
*Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi*

Main category: cs.CV

TL;DR: 提出了一种视觉-语言集成框架，通过统一预训练的视觉编码器和大型语言模型，实现视觉与文本模态的语义对齐，从而在零样本场景理解中实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界场景中零样本理解的挑战，由于自然场景的复杂性和变异性，模型需要在没有先验标注示例的情况下识别新对象、动作和上下文。

Method: 开发统一模型，将视觉输入和文本提示嵌入共享空间，然后通过多模态融合和推理层进行上下文解释，利用自然语言作为桥梁来泛化未见类别和上下文。

Result: 在Visual Genome、COCO、ADE20K和自定义真实世界数据集上的实验表明，在目标识别、活动检测和场景描述方面显著优于最先进的零样本模型，top-1准确率提升高达18%，语义一致性指标也有显著提升。

Conclusion: 跨模态对齐和语言基础在增强真实世界场景理解的泛化能力方面非常有效，证明了所提出系统的有效性。

Abstract: Zero-shot scene understanding in real-world settings presents major
challenges due to the complexity and variability of natural scenes, where
models must recognize new objects, actions, and contexts without prior labeled
examples. This work proposes a vision-language integration framework that
unifies pre-trained visual encoders (e.g., CLIP, ViT) and large language models
(e.g., GPT-based architectures) to achieve semantic alignment between visual
and textual modalities. The goal is to enable robust zero-shot comprehension of
scenes by leveraging natural language as a bridge to generalize over unseen
categories and contexts. Our approach develops a unified model that embeds
visual inputs and textual prompts into a shared space, followed by multimodal
fusion and reasoning layers for contextual interpretation. Experiments on
Visual Genome, COCO, ADE20K, and custom real-world datasets demonstrate
significant gains over state-of-the-art zero-shot models in object recognition,
activity detection, and scene captioning. The proposed system achieves up to
18% improvement in top-1 accuracy and notable gains in semantic coherence
metrics, highlighting the effectiveness of cross-modal alignment and language
grounding in enhancing generalization for real-world scene understanding.

</details>


### [37] [Neighborhood Feature Pooling for Remote Sensing Image Classification](https://arxiv.org/abs/2510.25077)
*Fahimeh Orvati Nia,Amirmohammad Mohammadi,Salim Al Kharsa,Pragati Naikare,Zigfried Hampel-Arias,Joshua Peeples*

Main category: cs.CV

TL;DR: 提出了一种新颖的邻域特征池化(NFP)方法用于遥感图像分类，该方法通过卷积层捕获相邻输入之间的关系并聚合局部相似性，能无缝集成到任何网络中，在多种数据集和架构上持续提升性能且参数开销极小。


<details>
  <summary>Details</summary>
Motivation: 需要一种有效的纹理特征提取方法来提升遥感图像分类性能，传统方法可能无法充分捕获局部相似性和邻域关系。

Method: 使用卷积层实现邻域特征池化(NFP)，捕获相邻输入之间的关系并高效聚合特征维度上的局部相似性。

Result: 与基线模型相比，NFP方法在多种数据集和架构上持续提升分类性能，同时保持极小的参数开销。

Conclusion: NFP是一种有效的纹理特征提取方法，能够无缝集成到现有网络中，显著提升遥感图像分类性能且计算成本低。

Abstract: In this work, we propose neighborhood feature pooling (NFP) as a novel
texture feature extraction method for remote sensing image classification. The
NFP layer captures relationships between neighboring inputs and efficiently
aggregates local similarities across feature dimensions. Implemented using
convolutional layers, NFP can be seamlessly integrated into any network.
Results comparing the baseline models and the NFP method indicate that NFP
consistently improves performance across diverse datasets and architectures
while maintaining minimal parameter overhead.

</details>


### [38] [PSTF-AttControl: Per-Subject-Tuning-Free Personalized Image Generation with Controllable Face Attributes](https://arxiv.org/abs/2510.25084)
*Xiang liu,Zhaoxiang Liu,Huan Hu,Zipeng Wang,Ping Chen,Zezhou Chen,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 提出了一种无需逐主体调优的个性化图像生成方法，能够在保持面部身份的同时精确控制面部属性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在无需调优的情况下难以精确控制面部属性，而调优方法需要技术专业知识和额外训练数据，限制了可访问性。

Method: 使用人脸识别模型提取身份特征，通过e4e编码器映射到StyleGAN2的W+潜空间，并采用三重解耦交叉注意力模块将身份、属性和文本嵌入整合到UNet架构中。

Result: 在FFHQ数据集上训练，能够生成具有细粒度面部属性控制的个性化图像，无需为单个身份进行额外微调或训练数据。

Conclusion: 该方法成功平衡了个性化与精确面部属性控制，为高质量、适应性强的面部图像合成提供了更高效和用户友好的解决方案。

Abstract: Recent advancements in personalized image generation have significantly
improved facial identity preservation, particularly in fields such as
entertainment and social media. However, existing methods still struggle to
achieve precise control over facial attributes in a per-subject-tuning-free
(PSTF) way. Tuning-based techniques like PreciseControl have shown promise by
providing fine-grained control over facial features, but they often require
extensive technical expertise and additional training data, limiting their
accessibility. In contrast, PSTF approaches simplify the process by enabling
image generation from a single facial input, but they lack precise control over
facial attributes. In this paper, we introduce a novel, PSTF method that
enables both precise control over facial attributes and high-fidelity
preservation of facial identity. Our approach utilizes a face recognition model
to extract facial identity features, which are then mapped into the $W^+$
latent space of StyleGAN2 using the e4e encoder. We further enhance the model
with a Triplet-Decoupled Cross-Attention module, which integrates facial
identity, attribute features, and text embeddings into the UNet architecture,
ensuring clean separation of identity and attribute information. Trained on the
FFHQ dataset, our method allows for the generation of personalized images with
fine-grained control over facial attributes, while without requiring additional
fine-tuning or training data for individual identities. We demonstrate that our
approach successfully balances personalization with precise facial attribute
control, offering a more efficient and user-friendly solution for high-quality,
adaptable facial image synthesis. The code is publicly available at
https://github.com/UnicomAI/PSTF-AttControl.

</details>


### [39] [Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection](https://arxiv.org/abs/2510.25094)
*Chanhyeong Yang,Taehoon Song,Jihwan Park,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: VDRP是一个用于零样本人-物交互检测的框架，通过视觉多样性感知和区域感知的提示学习，解决了同一动词类内视觉多样性和不同动词类间视觉纠缠的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CLIP等预训练视觉语言模型的零样本人-物交互检测方法在处理交互的视觉复杂性方面存在不足，包括同一动词在不同姿态和上下文中的视觉多样性，以及不同动词产生相似视觉模式的问题。

Method: 提出视觉多样性感知提示学习策略，通过注入分组视觉方差到上下文嵌入中，并应用高斯扰动来捕捉动词的多样视觉变化；同时从人、物和联合区域检索区域特定概念，用于增强多样性感知提示嵌入。

Result: 在HICO-DET基准测试中，该方法在四种零样本评估设置下实现了最先进的性能。

Conclusion: VDRP框架有效解决了零样本人-物交互检测中的类内多样性和类间视觉纠缠问题，显著提升了检测性能。

Abstract: Zero-shot Human-Object Interaction detection aims to localize humans and
objects in an image and recognize their interaction, even when specific
verb-object pairs are unseen during training. Recent works have shown promising
results using prompt learning with pretrained vision-language models such as
CLIP, which align natural language prompts with visual features in a shared
embedding space. However, existing approaches still fail to handle the visual
complexity of interaction, including (1) intra-class visual diversity, where
instances of the same verb appear in diverse poses and contexts, and (2)
inter-class visual entanglement, where distinct verbs yield visually similar
patterns. To address these challenges, we propose VDRP, a framework for Visual
Diversity and Region-aware Prompt learning. First, we introduce a visual
diversity-aware prompt learning strategy that injects group-wise visual
variance into the context embedding. We further apply Gaussian perturbation to
encourage the prompts to capture diverse visual variations of a verb. Second,
we retrieve region-specific concepts from the human, object, and union regions.
These are used to augment the diversity-aware prompt embeddings, yielding
region-aware prompts that enhance verb-level discrimination. Experiments on the
HICO-DET benchmark demonstrate that our method achieves state-of-the-art
performance under four zero-shot evaluation settings, effectively addressing
both intra-class diversity and inter-class visual entanglement. Code is
available at https://github.com/mlvlab/VDRP.

</details>


### [40] [AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians](https://arxiv.org/abs/2510.25129)
*Xiyu Zhang,Chong Bao,Yipeng Chen,Hongjia Zhai,Yitong Dong,Hujun Bao,Zhaopeng Cui,Guofeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于亚特兰大世界模型的隐式结构化高斯泼溅方法，用于平滑重建室内和城市场景，同时保持高频细节和渲染效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低纹理区域的几何先验缺乏全局一致性，高斯泼溅和隐式SDF场存在不连续性或计算效率低的问题，导致细节丢失。

Method: 利用亚特兰大世界模型确保低纹理区域的准确表面重建，提出新颖的隐式结构化GS表示，包括语义GS表示预测语义区域概率，以及带可学习平面指示器的结构平面正则化。

Result: 在室内和城市场景的广泛实验中，该方法优于最先进方法，提供更优的表面重建质量。

Conclusion: 该方法成功解决了现有方法在低纹理区域重建中的问题，实现了平滑且高效的场景重建，同时保持了高频细节。

Abstract: 3D reconstruction of indoor and urban environments is a prominent research
topic with various downstream applications. However, existing geometric priors
for addressing low-texture regions in indoor and urban settings often lack
global consistency. Moreover, Gaussian Splatting and implicit SDF fields often
suffer from discontinuities or exhibit computational inefficiencies, resulting
in a loss of detail. To address these issues, we propose an Atlanta-world
guided implicit-structured Gaussian Splatting that achieves smooth indoor and
urban scene reconstruction while preserving high-frequency details and
rendering efficiency. By leveraging the Atlanta-world model, we ensure the
accurate surface reconstruction for low-texture regions, while the proposed
novel implicit-structured GS representations provide smoothness without
sacrificing efficiency and high-frequency details. Specifically, we propose a
semantic GS representation to predict the probability of all semantic regions
and deploy a structure plane regularization with learnable plane indicators for
global accurate surface reconstruction. Extensive experiments demonstrate that
our method outperforms state-of-the-art approaches in both indoor and urban
scenes, delivering superior surface reconstruction quality.

</details>


### [41] [Region-CAM: Towards Accurate Object Regions in Class Activation Maps for Weakly Supervised Learning Tasks](https://arxiv.org/abs/2510.25134)
*Qingdong Cai,Charith Abhayaratne*

Main category: cs.CV

TL;DR: Region-CAM是一种新的类激活映射方法，通过提取语义信息图和语义信息传播，解决了传统CAM方法只突出最具判别性区域的问题，显著提升了弱监督语义分割和目标定位的性能。


<details>
  <summary>Details</summary>
Motivation: 传统CAM方法只突出目标的最具判别性区域，无法覆盖整个对象且与对象边界不对齐，限制了弱监督语义分割等下游任务的性能。

Method: 提出Region-CAM方法，通过提取语义信息图(SIMs)和执行语义信息传播(SIP)，同时考虑基线分类模型各阶段的梯度和特征来生成激活图。

Result: 在PASCAL VOC数据集上，mIoU分别达到60.12%(训练集)和58.43%(验证集)，相比原始CAM提升13.61%和13.13%；在MS COCO验证集上达到36.38%，提升16.23%；在ILSVRC2012验证集上Top-1定位准确率达到51.7%，优于LayerCAM 4.5%。

Conclusion: Region-CAM能够覆盖更大比例的对象区域，同时确保激活图具有精确的边界，在弱监督语义分割和目标定位任务中表现出优越性能。

Abstract: Class Activation Mapping (CAM) methods are widely applied in weakly
supervised learning tasks due to their ability to highlight object regions.
However, conventional CAM methods highlight only the most discriminative
regions of the target. These highlighted regions often fail to cover the entire
object and are frequently misaligned with object boundaries, thereby limiting
the performance of downstream weakly supervised learning tasks, particularly
Weakly Supervised Semantic Segmentation (WSSS), which demands pixel-wise
accurate activation maps to get the best results. To alleviate the above
problems, we propose a novel activation method, Region-CAM. Distinct from
network feature weighting approaches, Region-CAM generates activation maps by
extracting semantic information maps (SIMs) and performing semantic information
propagation (SIP) by considering both gradients and features in each of the
stages of the baseline classification model. Our approach highlights a greater
proportion of object regions while ensuring activation maps to have precise
boundaries that align closely with object edges. Region-CAM achieves 60.12% and
58.43% mean intersection over union (mIoU) using the baseline model on the
PASCAL VOC training and validation datasets, respectively, which are
improvements of 13.61% and 13.13% over the original CAM (46.51% and 45.30%). On
the MS COCO validation set, Region-CAM achieves 36.38%, a 16.23% improvement
over the original CAM (20.15%). We also demonstrate the superiority of
Region-CAM in object localization tasks, using the ILSVRC2012 validation set.
Region-CAM achieves 51.7% in Top-1 Localization accuracy Loc1. Compared with
LayerCAM, an activation method designed for weakly supervised object
localization, Region-CAM achieves 4.5% better performance in Loc1.

</details>


### [42] [DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications](https://arxiv.org/abs/2510.25140)
*Malaisree P,Youwai S,Kitkobsin T,Janrungautai S,Amorndechaphon D,Rojanavasu P*

Main category: cs.CV

TL;DR: DINO-YOLO是一种结合YOLOv12和DINOv3自监督视觉变换器的混合架构，用于数据高效的目标检测，在土木工程应用中显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 土木工程应用中的目标检测受限于专业领域标注数据的稀缺，需要开发数据高效的检测方法。

Method: 将DINOv3特征在输入预处理(P0)和中间骨干网络增强(P3)两个位置进行策略性集成，构建DINO-YOLO混合架构。

Result: 在多个数据集上取得显著改进：隧道裂缝检测提升12.4%，建筑PPE检测提升13.7%，KITTI数据集提升88.6%，同时保持实时推理速度(30-47 FPS)。

Conclusion: DINO-YOLO为数据受限环境下的土木工程应用提供了实用的解决方案，在保持计算效率的同时实现了最先进的性能。

Abstract: Object detection in civil engineering applications is constrained by limited
annotated data in specialized domains. We introduce DINO-YOLO, a hybrid
architecture combining YOLOv12 with DINOv3 self-supervised vision transformers
for data-efficient detection. DINOv3 features are strategically integrated at
two locations: input preprocessing (P0) and mid-backbone enhancement (P3).
Experimental validation demonstrates substantial improvements: Tunnel Segment
Crack detection (648 images) achieves 12.4% improvement, Construction PPE (1K
images) gains 13.7%, and KITTI (7K images) shows 88.6% improvement, while
maintaining real-time inference (30-47 FPS). Systematic ablation across five
YOLO scales and nine DINOv3 variants reveals that Medium-scale architectures
achieve optimal performance with DualP0P3 integration (55.77% mAP@0.5), while
Small-scale requires Triple Integration (53.63%). The 2-4x inference overhead
(21-33ms versus 8-16ms baseline) remains acceptable for field deployment on
NVIDIA RTX 5090. DINO-YOLO establishes state-of-the-art performance for civil
engineering datasets (<10K images) while preserving computational efficiency,
providing practical solutions for construction safety monitoring and
infrastructure inspection in data-constrained environments.

</details>


### [43] [Revisiting Reconstruction-based AI-generated Image Detection: A Geometric Perspective](https://arxiv.org/abs/2510.25141)
*Wan Jiang,Jing Yan,Ruixuan Zhang,Xiaojing Chen,Changtao Miao,Zhe Li,Chenhao Lin,Yunfeng Diao,Richang Hong*

Main category: cs.CV

TL;DR: 提出ReGap方法，通过动态重构误差检测AI生成图像，解决了现有静态重构误差方法的局限性，提高了检测准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于重构的AI图像检测方法缺乏理论基础，依赖经验启发式，可解释性和可靠性有限。当某些真实图像的重构误差低于生成图像时，现有方法检测准确率下降，需要数据特定的阈值调整，限制了实际应用。

Method: 提出ReGap方法：从几何角度引入Jacobian谱下界理论，证明真实图像在重构流形外具有非平凡误差下界，而生成图像在流形上具有接近零的误差。通过结构化编辑操作引入受控扰动，计算编辑前后的动态重构误差变化，增强误差分离能力。

Result: 实验结果表明，ReGap方法优于现有基线方法，对常见后处理操作具有鲁棒性，并能有效泛化到多样化条件。

Conclusion: ReGap提供了一种无需训练的动态重构误差检测方法，通过理论支撑和结构化编辑操作，显著提高了AI生成图像检测的准确性和实用性。

Abstract: The rise of generative Artificial Intelligence (AI) has made detecting
AI-generated images a critical challenge for ensuring authenticity. Existing
reconstruction-based methods lack theoretical foundations and on empirical
heuristics, limiting interpretability and reliability. In this paper, we
introduce the Jacobian-Spectral Lower Bound for reconstruction error from a
geometric perspective, showing that real images off the reconstruction manifold
exhibit a non-trivial error lower bound, while generated images on the manifold
have near-zero error. Furthermore, we reveal the limitations of existing
methods that rely on static reconstruction error from a single pass. These
methods often fail when some real images exhibit lower error than generated
ones. This counterintuitive behavior reduces detection accuracy and requires
data-specific threshold tuning, limiting their applicability in real-world
scenarios. To address these challenges, we propose ReGap, a training-free
method that computes dynamic reconstruction error by leveraging structured
editing operations to introduce controlled perturbations. This enables
measuring error changes before and after editing, improving detection accuracy
by enhancing error separation. Experimental results show that our method
outperforms existing baselines, exhibits robustness to common post-processing
operations and generalizes effectively across diverse conditions.

</details>


### [44] [EA3D: Online Open-World 3D Object Extraction from Streaming Videos](https://arxiv.org/abs/2510.25146)
*Xiaoyu Zhou,Jingqi Wang,Yuang Jia,Yongtao Wang,Deqing Sun,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: EA3D是一个统一的在线框架，用于开放世界的3D物体提取，能够同时进行几何重建和整体场景理解。它通过视觉语言和2D视觉基础编码器动态解释视频流，将对象级知识集成到高斯特征图中，并通过联合优化模块同时增强几何重建和语义理解。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景理解方法受限于离线收集的多视图数据或预构建的3D几何。EA3D旨在解决这一限制，提供一个统一的在线框架，实现同时的几何重建和整体场景理解。

Method: 使用视觉语言和2D视觉基础编码器动态解释视频流中的每一帧，提取对象级知识。通过前馈在线更新策略将这些知识集成到高斯特征图中。迭代估计历史帧的视觉里程计，并用新观测增量更新在线高斯特征。使用循环联合优化模块引导模型关注感兴趣区域。

Result: 在多种基准测试和任务上的广泛实验证明了EA3D的有效性，包括照片级真实感渲染、语义和实例分割、3D边界框和语义占用估计以及3D网格生成。

Conclusion: EA3D建立了一个统一且高效的框架，用于联合在线3D重建和整体场景理解，支持广泛的下游任务。

Abstract: Current 3D scene understanding methods are limited by offline-collected
multi-view data or pre-constructed 3D geometry. In this paper, we present
ExtractAnything3D (EA3D), a unified online framework for open-world 3D object
extraction that enables simultaneous geometric reconstruction and holistic
scene understanding. Given a streaming video, EA3D dynamically interprets each
frame using vision-language and 2D vision foundation encoders to extract
object-level knowledge. This knowledge is integrated and embedded into a
Gaussian feature map via a feed-forward online update strategy. We then
iteratively estimate visual odometry from historical frames and incrementally
update online Gaussian features with new observations. A recurrent joint
optimization module directs the model's attention to regions of interest,
simultaneously enhancing both geometric reconstruction and semantic
understanding. Extensive experiments across diverse benchmarks and tasks,
including photo-realistic rendering, semantic and instance segmentation, 3D
bounding box and semantic occupancy estimation, and 3D mesh generation,
demonstrate the effectiveness of EA3D. Our method establishes a unified and
efficient framework for joint online 3D reconstruction and holistic scene
understanding, enabling a broad range of downstream tasks.

</details>


### [45] [Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers](https://arxiv.org/abs/2510.25157)
*Gautam A. Viruthagiri,Arnuv Tandon,Gerald G. Fuller,Vinny Chandran Suja*

Main category: cs.CV

TL;DR: 提出基于视觉Transformer的方法，从干涉图实时推断薄液膜厚度分布，解决了传统方法计算复杂、对噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 薄膜干涉测量在眼科有重要应用，但临床转化受限于从干涉图案重建厚度分布的挑战——这是一个受相位周期性、成像噪声和环境伪影影响的病态逆问题。

Method: 使用视觉Transformer架构，在结合生理相关合成和实验泪膜数据的混合数据集上训练，利用长程空间相关性解决相位模糊，从动态干涉图中单次前向传播重建时间相干厚度分布。

Result: 在具有运动伪影的噪声快速演化薄膜上表现出最先进的性能，克服了传统相位展开和迭代拟合方法的局限性。

Conclusion: 数据驱动方法能在消费级硬件上实现自动化、一致的实时厚度重建，为连续监测前镜眼表泪膜和无创诊断干眼症等疾病开辟了新可能。

Abstract: Thin film interferometry is a powerful technique for non-invasively measuring
liquid film thickness with applications in ophthalmology, but its clinical
translation is hindered by the challenges in reconstructing thickness profiles
from interference patterns - an ill-posed inverse problem complicated by phase
periodicity, imaging noise and ambient artifacts. Traditional reconstruction
methods are either computationally intensive, sensitive to noise, or require
manual expert analysis, which is impractical for real-time diagnostics. To
address this challenge, here we present a vision transformer-based approach for
real-time inference of thin liquid film thickness profiles directly from
isolated interferograms. Trained on a hybrid dataset combining
physiologically-relevant synthetic and experimental tear film data, our model
leverages long-range spatial correlations to resolve phase ambiguities and
reconstruct temporally coherent thickness profiles in a single forward pass
from dynamic interferograms acquired in vivo and ex vivo. The network
demonstrates state-of-the-art performance on noisy, rapidly-evolving films with
motion artifacts, overcoming limitations of conventional phase-unwrapping and
iterative fitting methods. Our data-driven approach enables automated,
consistent thickness reconstruction at real-time speeds on consumer hardware,
opening new possibilities for continuous monitoring of pre-lens ocular tear
films and non-invasive diagnosis of conditions such as the dry eye disease.

</details>


### [46] [Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation](https://arxiv.org/abs/2510.25163)
*Wenhao Zheng,Chenwei Sun,Wenbo Zhang,Jiancheng Lv,Xianggen Liu*

Main category: cs.CV

TL;DR: 提出了TGBFN框架，首次在统一的连续可微分参数空间中处理CAD序列的多模态性（离散命令和连续参数），通过引导贝叶斯流控制CAD属性，在定量约束CAD生成任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在图像和音频生成方面进展显著，但在多模态数据（如参数化CAD序列）生成方面仍落后，主要挑战在于处理长程约束和参数敏感性。

Method: TGBFN框架在统一连续可微分参数空间处理CAD序列多模态性，引入引导贝叶斯流控制CAD属性，穿透参数更新核。

Result: 在单条件和多条件约束生成任务中，TGBFN在生成高保真、条件感知CAD序列方面达到最先进性能。

Conclusion: TGBFN为定量约束CAD生成提供了有效解决方案，通过统一参数空间和引导贝叶斯流成功处理了CAD序列的多模态特性。

Abstract: Deep generative models, such as diffusion models, have shown promising
progress in image generation and audio generation via simplified continuity
assumptions. However, the development of generative modeling techniques for
generating multi-modal data, such as parametric CAD sequences, still lags
behind due to the challenges in addressing long-range constraints and parameter
sensitivity. In this work, we propose a novel framework for quantitatively
constrained CAD generation, termed Target-Guided Bayesian Flow Network (TGBFN).
For the first time, TGBFN handles the multi-modality of CAD sequences (i.e.,
discrete commands and continuous parameters) in a unified continuous and
differentiable parameter space rather than in the discrete data space. In
addition, TGBFN penetrates the parameter update kernel and introduces a guided
Bayesian flow to control the CAD properties. To evaluate TGBFN, we construct a
new dataset for quantitatively constrained CAD generation. Extensive
comparisons across single-condition and multi-condition constrained generation
tasks demonstrate that TGBFN achieves state-of-the-art performance in
generating high-fidelity, condition-aware CAD sequences. The code is available
at https://github.com/scu-zwh/TGBFN.

</details>


### [47] [A Study on Inference Latency for Vision Transformers on Mobile Devices](https://arxiv.org/abs/2510.25166)
*Zhuojin Li,Marco Paolieri,Leana Golubchik*

Main category: cs.CV

TL;DR: 该研究定量分析了190个真实世界视觉变换器(ViT)在移动设备上的性能特征，并与102个卷积神经网络(CNN)进行比较，开发了包含1000个合成ViT延迟测量的数据集，证明新ViT的推理延迟可以准确预测。


<details>
  <summary>Details</summary>
Motivation: 鉴于机器学习技术在移动设备上的显著进步，特别是在计算机视觉领域，需要定量研究视觉变换器在移动设备上的性能特征，并与传统卷积神经网络进行比较。

Method: 通过比较190个真实世界ViT和102个CNN的性能特征，开发包含1000个合成ViT延迟测量的数据集，涵盖两个机器学习框架和六个移动平台，使用代表性构建块和最先进架构。

Result: 研究揭示了影响ViT架构在移动设备上延迟的因素，并证明新ViT的推理延迟可以以足够准确的程度进行预测，适用于实际应用场景。

Conclusion: 该研究为移动设备上ViT架构的性能优化提供了重要见解，开发的延迟预测方法具有实际应用价值。

Abstract: Given the significant advances in machine learning techniques on mobile
devices, particularly in the domain of computer vision, in this work we
quantitatively study the performance characteristics of 190 real-world vision
transformers (ViTs) on mobile devices. Through a comparison with 102 real-world
convolutional neural networks (CNNs), we provide insights into the factors that
influence the latency of ViT architectures on mobile devices. Based on these
insights, we develop a dataset including measured latencies of 1000 synthetic
ViTs with representative building blocks and state-of-the-art architectures
from two machine learning frameworks and six mobile platforms. Using this
dataset, we show that inference latency of new ViTs can be predicted with
sufficient accuracy for real-world applications.

</details>


### [48] [$D^2GS$: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction](https://arxiv.org/abs/2510.25173)
*Kejing Xia,Jidong Jia,Ke Jin,Yucai Bai,Li Sun,Dacheng Tao,Youjian Zhang*

Main category: cs.CV

TL;DR: 提出D²GS框架，无需LiDAR即可实现高质量城市场景重建，通过多视角深度预测、渐进式剪枝和深度增强器获得优于LiDAR的几何先验


<details>
  <summary>Details</summary>
Motivation: 解决现有城市场景重建方法依赖LiDAR带来的问题：多传感器时空标定困难和空间错位导致的投影误差

Method: 1) 通过多视角深度预测反投影初始化密集点云，渐进式剪枝优化全局一致性；2) 深度增强器联合优化高斯几何和预测深度，利用扩散先验增强深度图；3) 约束道路区域高斯形状和法向量提升地面几何精度

Result: 在Waymo数据集上超越现有最优方法，即使与使用真实LiDAR数据的方法相比也能产生更准确的几何

Conclusion: D²GS证明了无需LiDAR即可实现高质量城市场景重建，提供比LiDAR更密集准确的几何先验

Abstract: Recently, Gaussian Splatting (GS) has shown great potential for urban scene
reconstruction in the field of autonomous driving. However, current urban scene
reconstruction methods often depend on multimodal sensors as inputs,
\textit{i.e.} LiDAR and images. Though the geometry prior provided by LiDAR
point clouds can largely mitigate ill-posedness in reconstruction, acquiring
such accurate LiDAR data is still challenging in practice: i) precise
spatiotemporal calibration between LiDAR and other sensors is required, as they
may not capture data simultaneously; ii) reprojection errors arise from spatial
misalignment when LiDAR and cameras are mounted at different locations. To
avoid the difficulty of acquiring accurate LiDAR depth, we propose $D^2GS$, a
LiDAR-free urban scene reconstruction framework. In this work, we obtain
geometry priors that are as effective as LiDAR while being denser and more
accurate. $\textbf{First}$, we initialize a dense point cloud by
back-projecting multi-view metric depth predictions. This point cloud is then
optimized by a Progressive Pruning strategy to improve the global consistency.
$\textbf{Second}$, we jointly refine Gaussian geometry and predicted dense
metric depth via a Depth Enhancer. Specifically, we leverage diffusion priors
from a depth foundation model to enhance the depth maps rendered by Gaussians.
In turn, the enhanced depths provide stronger geometric constraints during
Gaussian training. $\textbf{Finally}$, we improve the accuracy of ground
geometry by constraining the shape and normal attributes of Gaussians within
road regions. Extensive experiments on the Waymo dataset demonstrate that our
method consistently outperforms state-of-the-art methods, producing more
accurate geometry even when compared with those using ground-truth LiDAR data.

</details>


### [49] [Classifier Enhancement Using Extended Context and Domain Experts for Semantic Segmentation](https://arxiv.org/abs/2510.25174)
*Huadong Tang,Youpeng Zhao,Min Xu,Jun Wang,Qiang Wu*

Main category: cs.CV

TL;DR: 提出了一种扩展上下文感知分类器(ECAC)，通过动态调整分类器来解决语义分割中固定参数分类器无法适应图像特定类别分布的问题。


<details>
  <summary>Details</summary>
Motivation: 传统语义分割方法使用固定参数分类器，无法处理不同图像的独特类别分布特性，且数据集级别的类别不平衡会导致模型偏向多数类别，限制了对少数类别区域的识别能力。

Method: 使用内存库学习数据集级别的上下文信息，结合当前图像的类别特定上下文信息来改进分类器。采用师生网络范式，教师网络动态调整上下文信息并传递知识给学生网络。

Result: 在ADE20K、COCO-Stuff10K和Pascal-Context等多个数据集上实现了最先进的性能。

Conclusion: ECAC通过动态调整分类器参数，有效解决了语义分割中的类别分布差异和类别不平衡问题，提升了模型性能。

Abstract: Prevalent semantic segmentation methods generally adopt a vanilla classifier
to categorize each pixel into specific classes.
  Although such a classifier learns global information from the training data,
this information is represented by a set of fixed parameters (weights and
biases).
  However, each image has a different class distribution, which prevents the
classifier from addressing the unique characteristics of individual images.
  At the dataset level, class imbalance leads to segmentation results being
biased towards majority classes, limiting the model's effectiveness in
identifying and segmenting minority class regions.
  In this paper, we propose an Extended Context-Aware Classifier (ECAC) that
dynamically adjusts the classifier using global (dataset-level) and local
(image-level) contextual information.
  Specifically, we leverage a memory bank to learn dataset-level contextual
information of each class, incorporating the class-specific contextual
information from the current image to improve the classifier for precise pixel
labeling.
  Additionally, a teacher-student network paradigm is adopted, where the domain
expert (teacher network) dynamically adjusts contextual information with ground
truth and transfers knowledge to the student network.
  Comprehensive experiments illustrate that the proposed ECAC can achieve
state-of-the-art performance across several datasets, including ADE20K,
COCO-Stuff10K, and Pascal-Context.

</details>


### [50] [Test-Time Adaptive Object Detection with Foundation Model](https://arxiv.org/abs/2510.25175)
*Yingjie Gao,Yanan Zhang,Zhi Cai,Di Huang*

Main category: cs.CV

TL;DR: 提出首个基于基础模型的测试时自适应目标检测方法，无需源数据且突破传统闭集限制，通过多模态提示学习和实例动态记忆模块实现高效域适应。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应目标检测方法严重依赖源域统计特征，且假设源域和目标域具有相同的类别空间，这在现实应用中存在局限性。

Method: 设计多模态提示均值教师框架，结合文本和视觉提示调优；提出测试时预热策略保护视觉分支表示能力；构建实例动态记忆模块存储高质量伪标签，并通过记忆增强和记忆幻觉策略提升性能。

Result: 在跨损坏和跨数据集基准测试中，该方法持续超越先前最先进方法，能够适应任意跨域和跨类别的目标数据。

Conclusion: 该方法成功实现了无需源数据的测试时自适应目标检测，突破了传统闭集限制，在多种跨域场景下表现出优越性能。

Abstract: In recent years, test-time adaptive object detection has attracted increasing
attention due to its unique advantages in online domain adaptation, which
aligns more closely with real-world application scenarios. However, existing
approaches heavily rely on source-derived statistical characteristics while
making the strong assumption that the source and target domains share an
identical category space. In this paper, we propose the first foundation
model-powered test-time adaptive object detection method that eliminates the
need for source data entirely and overcomes traditional closed-set limitations.
Specifically, we design a Multi-modal Prompt-based Mean-Teacher framework for
vision-language detector-driven test-time adaptation, which incorporates text
and visual prompt tuning to adapt both language and vision representation
spaces on the test data in a parameter-efficient manner. Correspondingly, we
propose a Test-time Warm-start strategy tailored for the visual prompts to
effectively preserve the representation capability of the vision branch.
Furthermore, to guarantee high-quality pseudo-labels in every test batch, we
maintain an Instance Dynamic Memory (IDM) module that stores high-quality
pseudo-labels from previous test samples, and propose two novel
strategies-Memory Enhancement and Memory Hallucination-to leverage IDM's
high-quality instances for enhancing original predictions and hallucinating
images without available pseudo-labels, respectively. Extensive experiments on
cross-corruption and cross-dataset benchmarks demonstrate that our method
consistently outperforms previous state-of-the-art methods, and can adapt to
arbitrary cross-domain and cross-category target data. Code is available at
https://github.com/gaoyingjay/ttaod_foundation.

</details>


### [51] [Mask-Robust Face Verification for Online Learning via YOLOv5 and Residual Networks](https://arxiv.org/abs/2510.25184)
*Zhifeng Wang,Minghui Wang,Chunyan Zeng,Jialong Yao,Yang Yang,Hongmin Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种基于改进卷积神经网络（残差网络）的在线学习身份认证解决方案，使用YOLOv5网络从学生摄像头图像中识别人脸，并通过残差网络提取深层特征，最后与数据库进行欧氏距离比对完成身份验证。


<details>
  <summary>Details</summary>
Motivation: 在信息技术与人工智能快速发展的背景下，新冠疫情推动了在线教育的普及，但数字学习环境中的身份认证问题亟待解决。本研究旨在通过深度学习技术加强在线教育的安全性和稳定性。

Method: 采用YOLOv5网络从学生摄像头图像中检测人脸，然后将人脸信息输入残差网络提取深层特征，最后通过欧氏距离与数据库中的学生人脸特征进行比对验证身份。

Result: 该方法能够有效识别和验证在线学习环境中学生的身份，为在线教育提供了可靠的身份认证机制。

Conclusion: 基于深度学习的身份认证技术能够促进在线教育的持续发展，增强其安全性和稳定性，使在线教育更好地适应教育环境的快速演变。

Abstract: In the contemporary landscape, the fusion of information technology and the
rapid advancement of artificial intelligence have ushered school education into
a transformative phase characterized by digitization and heightened
intelligence. Concurrently, the global paradigm shift caused by the Covid-19
pandemic has catalyzed the evolution of e-learning, accentuating its
significance. Amidst these developments, one pivotal facet of the online
education paradigm that warrants attention is the authentication of identities
within the digital learning sphere. Within this context, our study delves into
a solution for online learning authentication, utilizing an enhanced
convolutional neural network architecture, specifically the residual network
model. By harnessing the power of deep learning, this technological approach
aims to galvanize the ongoing progress of online education, while concurrently
bolstering its security and stability. Such fortification is imperative in
enabling online education to seamlessly align with the swift evolution of the
educational landscape. This paper's focal proposition involves the deployment
of the YOLOv5 network, meticulously trained on our proprietary dataset. This
network is tasked with identifying individuals' faces culled from images
captured by students' open online cameras. The resultant facial information is
then channeled into the residual network to extract intricate features at a
deeper level. Subsequently, a comparative analysis of Euclidean distances
against students' face databases is performed, effectively ascertaining the
identity of each student.

</details>


### [52] [AI-Powered Early Detection of Critical Diseases using Image Processing and Audio Analysis](https://arxiv.org/abs/2510.25199)
*Manisha More,Kavya Bhand,Kaustubh Mukdam,Kavya Sharma,Manas Kawtikwar,Hridayansh Kaware,Prajwal Kavhar*

Main category: cs.CV

TL;DR: 提出了一种多模态AI诊断框架，整合图像分析、热成像和音频信号处理，用于早期检测皮肤癌、血管血栓和心肺异常，在保持轻量级的同时达到竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 现有诊断技术成本高、侵入性强且在资源匮乏地区难以获取，需要开发可扩展、实时且易于获取的AI预诊断医疗解决方案。

Method: 使用微调的MobileNetV2进行皮肤病变分类，SVM进行热成像血栓检测，基于MFCC和随机森林进行心肺声音分析。

Result: 皮肤癌检测准确率89.3%，敏感性91.6%，特异性88.2%；血栓检测准确率86.4%，AUC 0.89；心肺分析准确率87.2%，敏感性85.7%。

Conclusion: 该框架为实现可扩展、实时且易于获取的AI预诊断医疗解决方案迈出了有希望的一步，可在低成本设备上部署。

Abstract: Early diagnosis of critical diseases can significantly improve patient
survival and reduce treatment costs. However, existing diagnostic techniques
are often costly, invasive, and inaccessible in low-resource regions. This
paper presents a multimodal artificial intelligence (AI) diagnostic framework
integrating image analysis, thermal imaging, and audio signal processing for
early detection of three major health conditions: skin cancer, vascular blood
clots, and cardiopulmonary abnormalities. A fine-tuned MobileNetV2
convolutional neural network was trained on the ISIC 2019 dataset for skin
lesion classification, achieving 89.3% accuracy, 91.6% sensitivity, and 88.2%
specificity. A support vector machine (SVM) with handcrafted features was
employed for thermal clot detection, achieving 86.4% accuracy (AUC = 0.89) on
synthetic and clinical data. For cardiopulmonary analysis, lung and heart sound
datasets from PhysioNet and Pascal were processed using Mel-Frequency Cepstral
Coefficients (MFCC) and classified via Random Forest, reaching 87.2% accuracy
and 85.7% sensitivity. Comparative evaluation against state-of-the-art models
demonstrates that the proposed system achieves competitive results while
remaining lightweight and deployable on low-cost devices. The framework
provides a promising step toward scalable, real-time, and accessible AI-based
pre-diagnostic healthcare solutions.

</details>


### [53] [U-CAN: Unsupervised Point Cloud Denoising with Consistency-Aware Noise2Noise Matching](https://arxiv.org/abs/2510.25210)
*Junsheng Zhou,Xingyu Shi,Haichuan Song,Yi Fang,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: U-CAN是一个无监督的点云去噪框架，通过一致性感知的Noise2Noise匹配实现，无需干净数据对训练，在点云去噪、上采样和图像去噪任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量带噪声-干净点云对进行训练，这需要大量人工标注工作。本文旨在开发无需干净数据监督的点云去噪方法。

Method: 提出U-CAN框架，使用神经网络推断多步去噪路径，采用Noise2Noise匹配方案，通过新颖的损失函数实现多噪声观测的统计推理，并引入去噪几何一致性约束。

Result: 在点云去噪、上采样和图像去噪基准测试中，显著优于现有无监督方法，与有监督方法结果相当。

Conclusion: U-CAN提供了一种有效的无监督点云去噪解决方案，其一致性约束不仅适用于3D领域，也能促进2D图像去噪领域的发展。

Abstract: Point clouds captured by scanning sensors are often perturbed by noise, which
have a highly negative impact on downstream tasks (e.g. surface reconstruction
and shape understanding). Previous works mostly focus on training neural
networks with noisy-clean point cloud pairs for learning denoising priors,
which requires extensively manual efforts. In this work, we introduce U-CAN, an
Unsupervised framework for point cloud denoising with Consistency-Aware
Noise2Noise matching. Specifically, we leverage a neural network to infer a
multi-step denoising path for each point of a shape or scene with a noise to
noise matching scheme. We achieve this by a novel loss which enables
statistical reasoning on multiple noisy point cloud observations. We further
introduce a novel constraint on the denoised geometry consistency for learning
consistency-aware denoising patterns. We justify that the proposed constraint
is a general term which is not limited to 3D domain and can also contribute to
the area of 2D image denoising. Our evaluations under the widely used
benchmarks in point cloud denoising, upsampling and image denoising show
significant improvement over the state-of-the-art unsupervised methods, where
U-CAN also produces comparable results with the supervised methods.

</details>


### [54] [MSF-Net: Multi-Stage Feature Extraction and Fusion for Robust Photometric Stereo](https://arxiv.org/abs/2510.25221)
*Shiyu Qin,Zhihao Cai,Kaixuan Wang,Lin Qi,Junyu Dong*

Main category: cs.CV

TL;DR: 提出MSF-Net框架，通过多阶段特征提取和选择性更新策略解决光度立体视觉中特征冗余问题，在DiLiGenT基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有学习型光度立体方法无法准确捕捉多阶段特征，且特征间交互不足，导致在皱纹和边缘等复杂区域提取冗余特征。

Method: 设计MSF-Net框架，包含多阶段特征提取模块、选择性更新策略和特征融合模块，以提取高质量特征信息。

Result: 在DiLiGenT基准测试中，MSF-Net在表面法线估计精度上显著超越先前最先进方法。

Conclusion: MSF-Net通过改进多阶段特征提取和特征交互，有效提升了光度立体视觉中表面法线估计的准确性。

Abstract: Photometric stereo is a technique aimed at determining surface normals
through the utilization of shading cues derived from images taken under
different lighting conditions. However, existing learning-based approaches
often fail to accurately capture features at multiple stages and do not
adequately promote interaction between these features. Consequently, these
models tend to extract redundant features, especially in areas with intricate
details such as wrinkles and edges. To tackle these issues, we propose MSF-Net,
a novel framework for extracting information at multiple stages, paired with
selective update strategy, aiming to extract high-quality feature information,
which is critical for accurate normal construction. Additionally, we have
developed a feature fusion module to improve the interplay among different
features. Experimental results on the DiLiGenT benchmark show that our proposed
MSF-Net significantly surpasses previous state-of-the-art methods in the
accuracy of surface normal estimation.

</details>


### [55] [Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2510.25227)
*Quang-Khai Bui-Tran,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Ba-Thinh Lam,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种新的无源域自适应框架，通过硬样本选择和去噪补丁混合来逐步对齐目标分布，在隐私约束下实现更准确的医学图像分割。


<details>
  <summary>Details</summary>
Motivation: 当前的无源域自适应方法往往忽略样本难度，在域偏移下难以处理噪声监督，需要更稳健的解决方案。

Method: 1. 通过熵-相似性分析将未标记图像划分为可靠和不可靠子集；2. 使用蒙特卡洛去噪掩码精炼伪标签；3. 在子集间进行域内和域间补丁混合。

Result: 在基准数据集上相比先前的SFDA和UDA方法取得一致提升，获得更准确的边界描绘和最先进的Dice和ASSD分数。

Conclusion: 渐进式适应和去噪监督对于域偏移下的稳健分割至关重要。

Abstract: Source-Free Domain Adaptation (SFDA) is emerging as a compelling solution for
medical image segmentation under privacy constraints, yet current approaches
often ignore sample difficulty and struggle with noisy supervision under domain
shift. We present a new SFDA framework that leverages Hard Sample Selection and
Denoised Patch Mixing to progressively align target distributions. First,
unlabeled images are partitioned into reliable and unreliable subsets through
entropy-similarity analysis, allowing adaptation to start from easy samples and
gradually incorporate harder ones. Next, pseudo-labels are refined via Monte
Carlo-based denoising masks, which suppress unreliable pixels and stabilize
training. Finally, intra- and inter-domain objectives mix patches between
subsets, transferring reliable semantics while mitigating noise. Experiments on
benchmark datasets show consistent gains over prior SFDA and UDA methods,
delivering more accurate boundary delineation and achieving state-of-the-art
Dice and ASSD scores. Our study highlights the importance of progressive
adaptation and denoised supervision for robust segmentation under domain shift.

</details>


### [56] [Balanced conic rectified flow](https://arxiv.org/abs/2510.25229)
*Kim Shin Seong,Mingi Kwon,Jaeseok Jeong,Youngjung Uh*

Main category: cs.CV

TL;DR: 本文提出了一种改进的整流流方法，通过将真实图像纳入训练过程，减少对生成数据的依赖，从而在更少的生成对情况下获得更好的生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统整流流方法存在两个主要问题：1) 需要大量生成对来保持目标分布，计算成本高；2) 仅使用生成图像对训练，性能过度依赖1-整流流模型，导致偏向生成数据。

Method: 提出新方法将真实图像整合到训练过程中，通过保留真实图像的ODE路径，有效减少对大量生成数据的依赖，使用更少的生成和真实图像进行高效的再流过程。

Result: 在CIFAR-10上，使用仅原始方法1/10的生成对，不仅在一步生成中获得了显著更好的FID分数，在全步模拟中也表现更优。

Conclusion: 该方法诱导更直的路径，避免再流过程中生成图像的饱和，在保持真实图像分布的同时实现更稳健的ODE学习。

Abstract: Rectified flow is a generative model that learns smooth transport mappings
between two distributions through an ordinary differential equation (ODE).
Unlike diffusion-based generative models, which require costly numerical
integration of a generative ODE to sample images with state-of-the-art quality,
rectified flow uses an iterative process called reflow to learn smooth and
straight ODE paths. This allows for relatively simple and efficient generation
of high-quality images. However, rectified flow still faces several challenges.
1) The reflow process requires a large number of generative pairs to preserve
the target distribution, leading to significant computational costs. 2) Since
the model is typically trained using only generated image pairs, its
performance heavily depends on the 1-rectified flow model, causing it to become
biased towards the generated data.
  In this work, we experimentally expose the limitations of the original
rectified flow and propose a novel approach that incorporates real images into
the training process. By preserving the ODE paths for real images, our method
effectively reduces reliance on large amounts of generated data. Instead, we
demonstrate that the reflow process can be conducted efficiently using a much
smaller set of generated and real images. In CIFAR-10, we achieved
significantly better FID scores, not only in one-step generation but also in
full-step simulations, while using only of the generative pairs compared to the
original method. Furthermore, our approach induces straighter paths and avoids
saturation on generated images during reflow, leading to more robust ODE
learning while preserving the distribution of real images.

</details>


### [57] [DeepShield: Fortifying Deepfake Video Detection with Local and Global Forgery Analysis](https://arxiv.org/abs/2510.25237)
*Yinqi Cai,Jichang Li,Zhaolun Li,Weikai Chen,Rushi Lan,Xi Xie,Xiaonan Luo,Guanbin Li*

Main category: cs.CV

TL;DR: DeepShield是一个新颖的深度伪造检测框架，通过局部补丁引导和全局伪造多样化来平衡局部敏感性和全局泛化能力，在跨数据集和跨操作评估中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测器在域内场景表现良好，但依赖特定伪造伪影，难以泛化到多样化的操作技术。需要开发能平衡局部敏感性和全局泛化的鲁棒检测方法。

Method: 基于CLIP-ViT编码器，引入两个关键组件：局部补丁引导（LPG）通过时空伪影建模和补丁级监督捕获细粒度不一致性；全局伪造多样化（GFD）通过域特征增强生成多样化伪造特征，缓解过拟合并增强跨域适应性。

Result: 在跨数据集和跨操作评估中，DeepShield优于最先进的方法，对未见过的深度伪造攻击具有卓越的鲁棒性。

Conclusion: 通过整合新颖的局部和全局分析，DeepShield实现了对深度伪造检测的改进，在跨域场景中表现出色，为应对多样化伪造技术提供了有效解决方案。

Abstract: Recent advances in deep generative models have made it easier to manipulate
face videos, raising significant concerns about their potential misuse for
fraud and misinformation. Existing detectors often perform well in in-domain
scenarios but fail to generalize across diverse manipulation techniques due to
their reliance on forgery-specific artifacts. In this work, we introduce
DeepShield, a novel deepfake detection framework that balances local
sensitivity and global generalization to improve robustness across unseen
forgeries. DeepShield enhances the CLIP-ViT encoder through two key components:
Local Patch Guidance (LPG) and Global Forgery Diversification (GFD). LPG
applies spatiotemporal artifact modeling and patch-wise supervision to capture
fine-grained inconsistencies often overlooked by global models. GFD introduces
domain feature augmentation, leveraging domain-bridging and boundary-expanding
feature generation to synthesize diverse forgeries, mitigating overfitting and
enhancing cross-domain adaptability. Through the integration of novel local and
global analysis for deepfake detection, DeepShield outperforms state-of-the-art
methods in cross-dataset and cross-manipulation evaluations, achieving superior
robustness against unseen deepfake attacks.

</details>


### [58] [VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations](https://arxiv.org/abs/2510.25238)
*Qianqian Qiao,DanDan Zheng,Yihang Bo,Bao Peng,Heng Huang,Longteng Jiang,Huaye Wang,Jingdong Chen,Jun Zhou,Xin Jin*

Main category: cs.CV

TL;DR: 该研究提出了VADB，这是最大的视频美学评估数据库，包含10,490个多样化视频，由37位专业人士标注了多个美学维度。同时提出了VADB-Net双模态预训练框架，在评分任务中优于现有视频质量评估模型。


<details>
  <summary>Details</summary>
Motivation: 视频美学评估在多媒体计算中很重要，但受限于缺乏标准化数据集和鲁棒模型，视频的时序动态和多模态融合挑战阻碍了基于图像方法的直接应用。

Method: 构建VADB数据库，包含10,490个多样化视频，由37位专业人士标注多个美学维度。提出VADB-Net双模态预训练框架，采用两阶段训练策略。

Result: VADB-Net在评分任务中优于现有视频质量评估模型，并支持下游视频美学评估任务。数据集和源代码已公开。

Conclusion: 该研究通过构建大规模标准化数据集和有效的双模态预训练框架，显著推进了视频美学评估领域的发展。

Abstract: Video aesthetic assessment, a vital area in multimedia computing, integrates
computer vision with human cognition. Its progress is limited by the lack of
standardized datasets and robust models, as the temporal dynamics of video and
multimodal fusion challenges hinder direct application of image-based methods.
This study introduces VADB, the largest video aesthetic database with 10,490
diverse videos annotated by 37 professionals across multiple aesthetic
dimensions, including overall and attribute-specific aesthetic scores, rich
language comments and objective tags. We propose VADB-Net, a dual-modal
pre-training framework with a two-stage training strategy, which outperforms
existing video quality assessment models in scoring tasks and supports
downstream video aesthetic assessment tasks. The dataset and source code are
available at https://github.com/BestiVictory/VADB.

</details>


### [59] [Mapping and Classification of Trees Outside Forests using Deep Learning](https://arxiv.org/abs/2510.25239)
*Moritz Lucas,Hamid Ebrahimy,Viacheslav Barkov,Ralf Pecenka,Kai-Uwe Kühnberger,Björn Waske*

Main category: cs.CV

TL;DR: 该研究评估了深度学习在农业景观中森林外树木(TOF)分类中的应用，比较了多种神经网络架构，发现FT-UNetFormer模型表现最佳，强调了空间上下文理解在TOF制图中的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统研究将森林外树木视为单一类别或使用刚性阈值，限制了生态解释和跨区域适应性。需要更精确的方法来分类不同类型的木本植被。

Method: 使用德国四个农业景观的高分辨率航空影像和新生成的数据集，比较了CNN、视觉变换器和混合CNN-变换器模型，包括六种语义分割架构(ABCNet、LSKNet、FT-UNetFormer、DC-Swin、BANet和U-Net)。

Result: 模型在四个景观中均取得良好分类精度，FT-UNetFormer表现最佳(平均IoU 0.74；平均F1分数0.84)。森林和线性类别结果良好，但斑块和单树类别分类存在挑战。

Conclusion: 空间上下文理解对TOF制图至关重要，需要区域多样化的训练数据来确保可靠的大规模制图。数据集和代码已开源。

Abstract: Trees Outside Forests (TOF) play an important role in agricultural landscapes
by supporting biodiversity, sequestering carbon, and regulating microclimates.
Yet, most studies have treated TOF as a single class or relied on rigid
rule-based thresholds, limiting ecological interpretation and adaptability
across regions. To address this, we evaluate deep learning for TOF
classification using a newly generated dataset and high-resolution aerial
imagery from four agricultural landscapes in Germany. Specifically, we compare
convolutional neural networks (CNNs), vision transformers, and hybrid
CNN-transformer models across six semantic segmentation architectures (ABCNet,
LSKNet, FT-UNetFormer, DC-Swin, BANet, and U-Net) to map four categories of
woody vegetation: Forest, Patch, Linear, and Tree, derived from previous
studies and governmental products. Overall, the models achieved good
classification accuracy across the four landscapes, with the FT-UNetFormer
performing best (mean Intersection-over-Union 0.74; mean F1 score 0.84),
underscoring the importance of spatial context understanding in TOF mapping and
classification. Our results show good results for Forest and Linear class and
reveal challenges particularly in classifying complex structures with high edge
density, notably the Patch and Tree class. Our generalization experiments
highlight the need for regionally diverse training data to ensure reliable
large-scale mapping. The dataset and code are openly available at
https://github.com/Moerizzy/TOFMapper

</details>


### [60] [RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision Foundation Models](https://arxiv.org/abs/2510.25257)
*Zijun Liao,Yian Zhao,Xin Shan,Yu Yan,Chang Liu,Lei Lu,Xiangyang Ji,Jie Chen*

Main category: cs.CV

TL;DR: 提出了一种利用视觉基础模型增强轻量级目标检测器的蒸馏框架，通过深度语义注入器和梯度引导自适应调制策略，在不增加推理开销的情况下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 轻量级网络设计虽然能实现高速推理，但会导致特征表示能力下降，限制了性能提升和实际部署效果。

Method: 使用深度语义注入器模块将视觉基础模型的高层表示集成到检测器深层，并采用梯度引导自适应调制策略根据梯度范数比动态调整语义传输强度。

Result: RT-DETRv4模型在COCO数据集上达到SOTA结果，AP得分为49.7/53.5/55.4/57.0，对应速度为273/169/124/78 FPS。

Conclusion: 该方法能够在不增加部署和推理开销的情况下，为各种基于DETR的模型带来显著且一致的性能提升，具有实际应用价值。

Abstract: Real-time object detection has achieved substantial progress through
meticulously designed architectures and optimization strategies. However, the
pursuit of high-speed inference via lightweight network designs often leads to
degraded feature representation, which hinders further performance improvements
and practical on-device deployment. In this paper, we propose a cost-effective
and highly adaptable distillation framework that harnesses the rapidly evolving
capabilities of Vision Foundation Models (VFMs) to enhance lightweight object
detectors. Given the significant architectural and learning objective
disparities between VFMs and resource-constrained detectors, achieving stable
and task-aligned semantic transfer is challenging. To address this, on one
hand, we introduce a Deep Semantic Injector (DSI) module that facilitates the
integration of high-level representations from VFMs into the deep layers of the
detector. On the other hand, we devise a Gradient-guided Adaptive Modulation
(GAM) strategy, which dynamically adjusts the intensity of semantic transfer
based on gradient norm ratios. Without increasing deployment and inference
overhead, our approach painlessly delivers striking and consistent performance
gains across diverse DETR-based models, underscoring its practical utility for
real-time detection. Our new model family, RT-DETRv4, achieves state-of-the-art
results on COCO, attaining AP scores of 49.7/53.5/55.4/57.0 at corresponding
speeds of 273/169/124/78 FPS.

</details>


### [61] [LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation](https://arxiv.org/abs/2510.25263)
*Yang Miao,Jan-Nico Zaech,Xi Wang,Fabien Despinoy,Danda Pani Paudel,Luc Van Gool*

Main category: cs.CV

TL;DR: LangHOPS是首个基于多模态大语言模型的开集对象-部件实例分割框架，能够联合检测和分割层次化的对象和部件实例，在多个任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式或可学习的视觉分组，而LangHOPS旨在语言空间中建立对象-部件层次结构，利用MLLM的丰富知识和推理能力。

Method: 将MLLM集成到对象-部件解析流程中，利用其知识链接多层次概念，采用语言驱动的层次结构和MLLM驱动的部件查询优化策略。

Result: 在PartImageNet数据集上，域内性能提升5.5% AP，跨数据集提升4.8% AP；在ADE20K零样本分割中，未见对象部件mIOU提升2.5%。

Conclusion: 语言驱动的层次结构和MLLM查询优化策略有效，LangHOPS在开集对象-部件实例分割任务上表现优异。

Abstract: We propose LangHOPS, the first Multimodal Large Language Model (MLLM) based
framework for open-vocabulary object-part instance segmentation. Given an
image, LangHOPS can jointly detect and segment hierarchical object and part
instances from open-vocabulary candidate categories. Unlike prior approaches
that rely on heuristic or learnable visual grouping, our approach grounds
object-part hierarchies in language space. It integrates the MLLM into the
object-part parsing pipeline to leverage its rich knowledge and reasoning
capabilities, and link multi-granularity concepts within the hierarchies. We
evaluate LangHOPS across multiple challenging scenarios, including in-domain
and cross-dataset object-part instance segmentation, and zero-shot semantic
segmentation. LangHOPS achieves state-of-the-art results, surpassing previous
methods by 5.5% Average Precision (AP) (in-domain) and 4.8% (cross-dataset) on
the PartImageNet dataset and by 2.5% mIOU on unseen object parts in ADE20K
(zero-shot). Ablation studies further validate the effectiveness of the
language-grounded hierarchy and MLLM driven part query refinement strategy. The
code will be released here.

</details>


### [62] [Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation](https://arxiv.org/abs/2510.25279)
*Yuyang Huang,Yabo Chen,Junyu Zhou,Wenrui Dai,Xiaopeng Zhang,Junni Zou,Hongkai Xiong,Qi Tian*

Main category: cs.CV

TL;DR: 提出了一种名为DPTM的生成式源自由域自适应框架，通过扩散模型驱动渐进式目标域操作，有效解决大域差异下的SFDA问题。


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法受限于源-目标域差异的根本限制：非生成方法在大域差异下伪标签不可靠，生成方法在创建伪源数据时域差异扩大导致性能下降。

Method: 将目标样本分为可信集和非可信集，对非可信集样本通过潜在扩散模型进行语义转换并保持目标分布，同时设计渐进式精炼机制迭代减小伪目标域与真实目标域的域差异。

Result: 在四个主流SFDA基准数据集上大幅超越现有方法，达到最先进性能，特别在大源-目标差距场景下性能提升高达18.6%。

Conclusion: DPTM通过可靠生成和渐进精炼伪目标域，有效解决了SFDA中的域差异限制问题，为源自由域自适应提供了新的解决方案。

Abstract: Source-free domain adaptation (SFDA) is a challenging task that tackles
domain shifts using only a pre-trained source model and unlabeled target data.
Existing SFDA methods are restricted by the fundamental limitation of
source-target domain discrepancy. Non-generation SFDA methods suffer from
unreliable pseudo-labels in challenging scenarios with large domain
discrepancies, while generation-based SFDA methods are evidently degraded due
to enlarged domain discrepancies in creating pseudo-source data. To address
this limitation, we propose a novel generation-based framework named
Diffusion-Driven Progressive Target Manipulation (DPTM) that leverages
unlabeled target data as references to reliably generate and progressively
refine a pseudo-target domain for SFDA. Specifically, we divide the target
samples into a trust set and a non-trust set based on the reliability of
pseudo-labels to sufficiently and reliably exploit their information. For
samples from the non-trust set, we develop a manipulation strategy to
semantically transform them into the newly assigned categories, while
simultaneously maintaining them in the target distribution via a latent
diffusion model. Furthermore, we design a progressive refinement mechanism that
progressively reduces the domain discrepancy between the pseudo-target domain
and the real target domain via iterative refinement. Experimental results
demonstrate that DPTM outperforms existing methods by a large margin and
achieves state-of-the-art performance on four prevailing SFDA benchmark
datasets with different scales. Remarkably, DPTM can significantly enhance the
performance by up to 18.6% in scenarios with large source-target gaps.

</details>


### [63] [GaTector+: A Unified Head-free Framework for Gaze Object and Gaze Following Prediction](https://arxiv.org/abs/2510.25301)
*Yang Jin,Guangyu Guo,Binglu Wang*

Main category: cs.CV

TL;DR: GaTector+是一个统一的框架，用于视线目标检测和视线跟随任务，消除了推理过程中对头部相关先验知识的依赖，通过共享主干网络和特定块来优化两个子任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将视线目标检测和视线跟随分开处理，且都依赖头部相关先验知识，需要辅助网络提取头部位置，无法进行联合优化，限制了实际应用。

Method: 使用扩展的特定-通用-特定特征提取器，共享主干网络提取通用特征；嵌入头部检测分支预测头部位置；提出基于头部的注意力机制融合感知特征和视线特征；引入注意力监督机制加速视线热图学习；提出新的评估指标mSoC。

Result: 在多个基准数据集上的实验结果表明，该模型在视线目标检测和视线跟随任务中均表现出有效性。

Conclusion: GaTector+通过统一框架成功解决了视线目标检测和视线跟随任务，消除了对头部先验知识的依赖，提高了系统的实用性和性能。

Abstract: Gaze object detection and gaze following are fundamental tasks for
interpreting human gaze behavior or intent. However, most previous methods
usually solve these two tasks separately, and their prediction of gaze objects
and gaze following typically depend on head-related prior knowledge during both
the training phase and real-world deployment. This dependency necessitates an
auxiliary network to extract head location, thus precluding joint optimization
across the entire system and constraining the practical applicability. To this
end, we propose GaTector+, a unified framework for gaze object detection and
gaze following, which eliminates the dependence on the head-related priors
during inference. Specifically, GaTector+ uses an expanded
specific-general-specific feature extractor that leverages a shared backbone,
which extracts general features for gaze following and object detection using
the shared backbone while using specific blocks before and after the shared
backbone to better consider the specificity of each sub-task. To obtain
head-related knowledge without prior information, we first embed a head
detection branch to predict the head of each person. Then, before regressing
the gaze point, a head-based attention mechanism is proposed to fuse the sense
feature and gaze feature with the help of head location. Since the
suboptimization of the gaze point heatmap leads to the performance bottleneck,
we propose an attention supervision mechanism to accelerate the learning of the
gaze heatmap. Finally, we propose a novel evaluation metric, mean Similarity
over Candidates (mSoC), for gaze object detection, which is more sensitive to
variations between bounding boxes. The experimental results on multiple
benchmark datasets demonstrate the effectiveness of our model in both gaze
object detection and gaze following tasks.

</details>


### [64] [Prototype-Driven Adaptation for Few-Shot Object Detection](https://arxiv.org/abs/2510.25318)
*Yushen Huang,Zhiming Wang*

Main category: cs.CV

TL;DR: PDA是一个轻量级的原型驱动对齐模块，用于解决少样本目标检测中的基类偏差和校准不稳定问题。它通过原型匹配提供第二意见，与线性分类器互补，在多个基准测试中显著提升新类性能。


<details>
  <summary>Details</summary>
Motivation: 少样本目标检测在只有少量新类样本可用时，容易受到基类偏差的影响，并且校准不稳定。需要一种能够提供互补分类意见的方法来改善这些问题。

Method: PDA维护支持集原型在可学习的身份初始化投影空间中，可选地应用原型条件RoI对齐来减少几何不匹配。通过指数移动平均更新原型，采用best-of-K匹配方案捕获类内多模态，使用温度缩放融合将度量相似度与检测器logits结合。

Result: 在VOC FSOD和GFSOD基准测试中，PDA一致地改善了新类性能，对基类影响最小，计算开销可忽略。

Conclusion: PDA是一个有效的轻量级插件模块，能够显著提升少样本目标检测的新类性能，同时保持基类性能稳定，计算开销小。

Abstract: Few-shot object detection (FSOD) often suffers from base-class bias and
unstable calibration when only a few novel samples are available. We propose
Prototype-Driven Alignment (PDA), a lightweight, plug-in metric head for DeFRCN
that provides a prototype-based "second opinion" complementary to the linear
classifier. PDA maintains support-only prototypes in a learnable
identity-initialized projection space and optionally applies
prototype-conditioned RoI alignment to reduce geometric mismatch. During
fine-tuning, prototypes can be adapted via exponential moving average(EMA)
updates on labeled foreground RoIs-without introducing class-specific
parameters-and are frozen at inference to ensure strict protocol compliance.
PDA employs a best-of-K matching scheme to capture intra-class multi-modality
and temperature-scaled fusion to combine metric similarities with detector
logits. Experiments on VOC FSOD and GFSOD benchmarks show that PDA consistently
improves novel-class performance with minimal impact on base classes and
negligible computational overhead.

</details>


### [65] [MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding](https://arxiv.org/abs/2510.25327)
*Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang*

Main category: cs.CV

TL;DR: MMEdge是一个基于流水线感知和编码的新型设备端多模态推理框架，通过分解推理过程为细粒度单元实现增量计算，并引入时间聚合模块和自适应优化机制来降低延迟同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有工作在资源受限的边缘设备上进行实时多模态推理时，往往忽略了感知动态与模型执行之间的紧密耦合关系，以及复杂的模态间依赖关系。

Method: 将整个推理过程分解为细粒度的感知和编码单元序列，实现增量计算；引入时间聚合模块捕获跨流水线单元的时序动态；采用自适应多模态配置优化器和跨模态推测跳过机制。

Result: 在两个公共多模态数据集和真实无人机测试平台上评估，MMEdge显著降低了端到端延迟，同时在各种系统和数据动态下保持高任务准确性。

Conclusion: MMEdge通过流水线设计和自适应优化，有效解决了边缘设备上多模态推理的延迟和准确性平衡问题，为实时应用提供了可行解决方案。

Abstract: Real-time multimodal inference on resource-constrained edge devices is
essential for applications such as autonomous driving, human-computer
interaction, and mobile health. However, prior work often overlooks the tight
coupling between sensing dynamics and model execution, as well as the complex
inter-modality dependencies. In this paper, we propose MMEdge, an new on-device
multi-modal inference framework based on pipelined sensing and encoding.
Instead of waiting for complete sensor inputs, MMEdge decomposes the entire
inference process into a sequence of fine-grained sensing and encoding units,
allowing computation to proceed incrementally as data arrive. MMEdge also
introduces a lightweight but effective temporal aggregation module that
captures rich temporal dynamics across different pipelined units to maintain
accuracy performance. Such pipelined design also opens up opportunities for
fine-grained cross-modal optimization and early decision-making during
inference. To further enhance system performance under resource variability and
input data complexity, MMEdge incorporates an adaptive multimodal configuration
optimizer that dynamically selects optimal sensing and model configurations for
each modality under latency constraints, and a cross-modal speculative skipping
mechanism that bypasses future units of slower modalities when early
predictions reach sufficient confidence. We evaluate MMEdge using two public
multimodal datasets and deploy it on a real-world unmanned aerial vehicle
(UAV)-based multimodal testbed. The results show that MMEdge significantly
reduces end-to-end latency while maintaining high task accuracy across various
system and data dynamics.

</details>


### [66] [StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA](https://arxiv.org/abs/2510.25332)
*Yuhang Hu,Zhenyu Yang,Shihan Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Changsheng Xu*

Main category: cs.CV

TL;DR: 提出了StreamingCoT数据集，首个专为流式视频问答和多模态思维链任务设计的基准，解决了现有数据集在动态时间演化和显式推理过程标注方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前视频问答数据集存在两个关键局限：静态标注机制无法捕捉视频流中答案的演化特性，以及缺乏显式推理过程标注限制了模型的可解释性和逻辑推理能力。

Method: 建立动态分层标注架构，生成每秒密集描述并通过相似性融合构建时间依赖的语义片段；提出显式推理链生成范式，通过关键帧语义对齐提取时空对象，利用大语言模型生成基于对象状态转换的推理路径，并通过人工验证确保逻辑一致性。

Result: 创建了StreamingCoT数据集，为流式视频理解、复杂时间推理和多模态推理研究奠定了基础。

Conclusion: StreamingCoT数据集解决了视频问答中时间演化和推理过程标注的关键问题，推动了流式视频理解和多模态推理研究的发展。

Abstract: The rapid growth of streaming video applications demands multimodal models
with enhanced capabilities for temporal dynamics understanding and complex
reasoning. However, current Video Question Answering (VideoQA) datasets suffer
from two critical limitations: 1) Static annotation mechanisms fail to capture
the evolving nature of answers in temporal video streams, and 2) The absence of
explicit reasoning process annotations restricts model interpretability and
logical deduction capabilities. To address these challenges, We introduce
StreamingCoT, the first dataset explicitly designed for temporally evolving
reasoning in streaming VideoQA and multimodal Chain-of-Thought (CoT) tasks. Our
framework first establishes a dynamic hierarchical annotation architecture that
generates per-second dense descriptions and constructs temporally-dependent
semantic segments through similarity fusion, paired with question-answer sets
constrained by temporal evolution patterns. We further propose an explicit
reasoning chain generation paradigm that extracts spatiotemporal objects via
keyframe semantic alignment, derives object state transition-based reasoning
paths using large language models, and ensures logical coherence through
human-verified validation. This dataset establishes a foundation for advancing
research in streaming video understanding, complex temporal reasoning, and
multimodal inference. Our StreamingCoT and its construction toolkit can be
accessed at https://github.com/Fleeting-hyh/StreamingCoT.

</details>


### [67] [Informative Sample Selection Model for Skeleton-based Action Recognition with Limited Training Samples](https://arxiv.org/abs/2510.25345)
*Zhigang Tu,Zhengbo Zhang,Jia Gong,Junsong Yuan,Bo Du*

Main category: cs.CV

TL;DR: 提出了一种基于马尔可夫决策过程的半监督3D动作识别方法，通过将样本选择建模为MDP问题，在双曲空间中增强状态-动作对的表示能力，并使用元调优策略加速实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有半监督3D动作识别方法中，最具代表性的骨架序列不一定对动作识别器最有益，因为模型可能已从先前见过的类似样本中获取了相关知识。

Method: 将半监督3D动作识别重新表述为马尔可夫决策过程，训练信息样本选择模型智能指导骨架序列标注选择；将状态-动作对从欧几里得空间投影到双曲空间以增强表示能力；引入元调优策略加速实际部署。

Result: 在三个3D动作识别基准数据集上的广泛实验证明了该方法的有效性。

Conclusion: 通过将半监督3D动作识别建模为MDP问题，在双曲空间中增强表示能力，能够更有效地选择信息丰富的样本进行标注，提高识别性能。

Abstract: Skeleton-based human action recognition aims to classify human skeletal
sequences, which are spatiotemporal representations of actions, into predefined
categories. To reduce the reliance on costly annotations of skeletal sequences
while maintaining competitive recognition accuracy, the task of 3D Action
Recognition with Limited Training Samples, also known as semi-supervised 3D
Action Recognition, has been proposed. In addition, active learning, which aims
to proactively select the most informative unlabeled samples for annotation,
has been explored in semi-supervised 3D Action Recognition for training sample
selection. Specifically, researchers adopt an encoder-decoder framework to
embed skeleton sequences into a latent space, where clustering information,
combined with a margin-based selection strategy using a multi-head mechanism,
is utilized to identify the most informative sequences in the unlabeled set for
annotation. However, the most representative skeleton sequences may not
necessarily be the most informative for the action recognizer, as the model may
have already acquired similar knowledge from previously seen skeleton samples.
To solve it, we reformulate Semi-supervised 3D action recognition via active
learning from a novel perspective by casting it as a Markov Decision Process
(MDP). Built upon the MDP framework and its training paradigm, we train an
informative sample selection model to intelligently guide the selection of
skeleton sequences for annotation. To enhance the representational capacity of
the factors in the state-action pairs within our method, we project them from
Euclidean space to hyperbolic space. Furthermore, we introduce a meta tuning
strategy to accelerate the deployment of our method in real-world scenarios.
Extensive experiments on three 3D action recognition benchmarks demonstrate the
effectiveness of our method.

</details>


### [68] [3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework](https://arxiv.org/abs/2510.25347)
*Ayman Abaid,Gianpiero Guidone,Sara Alsubai,Foziyah Alquahtani,Talha Iqbal,Ruth Sharif,Hesham Elzomor,Emiliano Bianchini,Naeif Almagal,Michael G. Madden,Faisal Sharif,Ihsan Ullah*

Main category: cs.CV

TL;DR: 提出基于放射组学的冠状动脉钙化评分方法，使用伪标签生成训练数据，无需专家标注，在非对比CCTA扫描上显著优于预训练基础模型。


<details>
  <summary>Details</summary>
Motivation: 解决冠状动脉钙化评分中标注数据有限的问题，探索无需专家分割的自动化钙化检测方法。

Method: 使用放射组学特征和伪标签生成训练数据，比较放射组学特征与CT-FM、RadImageNet等预训练基础模型提取的特征性能。

Result: 放射组学模型在182名患者数据集上达到84%准确率，显著优于CNN基础模型（p<0.05）。

Conclusion: 放射组学方法在无专家标注情况下仍能有效进行冠状动脉钙化评分，优于深度学习方法。

Abstract: Coronary artery calcium (CAC) scoring plays a crucial role in the early
detection and risk stratification of coronary artery disease (CAD). In this
study, we focus on non-contrast coronary computed tomography angiography (CCTA)
scans, which are commonly used for early calcification detection in clinical
settings. To address the challenge of limited annotated data, we propose a
radiomics-based pipeline that leverages pseudo-labeling to generate training
labels, thereby eliminating the need for expert-defined segmentations.
Additionally, we explore the use of pretrained foundation models, specifically
CT-FM and RadImageNet, to extract image features, which are then used with
traditional classifiers. We compare the performance of these deep learning
features with that of radiomics features. Evaluation is conducted on a clinical
CCTA dataset comprising 182 patients, where individuals are classified into two
groups: zero versus non-zero calcium scores. We further investigate the impact
of training on non-contrast datasets versus combined contrast and non-contrast
datasets, with testing performed only on non contrast scans. Results show that
radiomics-based models significantly outperform CNN-derived embeddings from
foundation models (achieving 84% accuracy and p<0.05), despite the
unavailability of expert annotations.

</details>


### [69] [Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers](https://arxiv.org/abs/2510.25372)
*M Yashwanth,Sharannya Ghosh,Aditay Tripathi,Anirban Chakraborty*

Main category: cs.CV

TL;DR: PEP-FedPT是一个联邦学习框架，通过类上下文混合提示(CCMP)实现视觉Transformer的泛化和个性化联邦提示调优，解决了全局提示调优在异构客户端上泛化能力差和个性化调优过拟合本地数据的问题。


<details>
  <summary>Details</summary>
Motivation: 视觉提示调优(VPT)作为参数高效的微调技术适合联邦学习，但全局提示调优在异构客户端上泛化能力差，而个性化调优容易过拟合本地数据且缺乏泛化能力。

Method: 提出PEP-FedPT框架，引入类上下文混合提示(CCMP)，基于类特定提示和全局共享提示，通过全局类原型和客户端类先验自适应组合类特定提示，实现无需存储客户端相关可训练参数的逐样本提示个性化。

Result: 在CIFAR-100、TinyImageNet、DomainNet和iNaturalist数据集上的综合评估表明，PEP-FedPT在不同数据异构场景下始终超越最先进的基线方法。

Conclusion: PEP-FedPT为视觉Transformer的高效和可泛化联邦提示调优建立了坚实基础。

Abstract: Visual Prompt Tuning (VPT) of pre-trained Vision Transformers (ViTs) has
proven highly effective as a parameter-efficient fine-tuning technique for
adapting large models to downstream tasks with limited data. Its parameter
efficiency makes it particularly suitable for Federated Learning (FL), where
both communication and computation budgets are often constrained. However,
global prompt tuning struggles to generalize across heterogeneous clients,
while personalized tuning overfits to local data and lacks generalization. We
propose PEP-FedPT (Prompt Estimation from Prototypes for Federated Prompt
Tuning), a unified framework designed to achieve both generalization and
personalization in federated prompt tuning of ViTs. Within this framework, we
introduce the novel Class-Contextualized Mixed Prompt (CCMP) - based on
class-specific prompts maintained alongside a globally shared prompt. For each
input, CCMP adaptively combines class-specific prompts using weights derived
from global class prototypes and client class priors. This approach enables
per-sample prompt personalization without storing client-dependent trainable
parameters. The prompts are collaboratively optimized via traditional federated
averaging technique on the same. Comprehensive evaluations on CIFAR-100,
TinyImageNet, DomainNet, and iNaturalist datasets demonstrate that PEP-FedPT
consistently surpasses the state-of-the-art baselines under diverse data
heterogeneity scenarios, establishing a strong foundation for efficient and
generalizable federated prompt tuning of Vision Transformers.

</details>


### [70] [Instance-Level Composed Image Retrieval](https://arxiv.org/abs/2510.25387)
*Bill Psomas,George Retsinas,Nikos Efthymiadis,Panagiotis Filntisis,Yannis Avrithis,Petros Maragos,Ondrej Chum,Giorgos Tolias*

Main category: cs.CV

TL;DR: 提出了一个新的实例级组合图像检索数据集i-CIR和无需训练的检索方法BASIC，该方法在多个CIR数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 组合图像检索(CIR)研究因缺乏高质量训练和评估数据而受限，现有数据集主要关注语义级类别定义而非实例级检索。

Method: 设计紧凑的i-CIR数据集，采用半自动选择难负样本；提出BASIC方法，分别估计视觉查询-图像和文本查询-图像相似度，进行后期融合，并通过简单直观的组件提升单个相似度。

Result: BASIC在i-CIR数据集上达到最先进性能，同时在现有语义级CIR数据集上也表现优异。

Conclusion: i-CIR数据集和BASIC方法为组合图像检索提供了有效的评估框架和解决方案，无需训练即可实现高性能检索。

Abstract: The progress of composed image retrieval (CIR), a popular research direction
in image retrieval, where a combined visual and textual query is used, is held
back by the absence of high-quality training and evaluation data. We introduce
a new evaluation dataset, i-CIR, which, unlike existing datasets, focuses on an
instance-level class definition. The goal is to retrieve images that contain
the same particular object as the visual query, presented under a variety of
modifications defined by textual queries. Its design and curation process keep
the dataset compact to facilitate future research, while maintaining its
challenge-comparable to retrieval among more than 40M random
distractors-through a semi-automated selection of hard negatives.
  To overcome the challenge of obtaining clean, diverse, and suitable training
data, we leverage pre-trained vision-and-language models (VLMs) in a
training-free approach called BASIC. The method separately estimates
query-image-to-image and query-text-to-image similarities, performing late
fusion to upweight images that satisfy both queries, while down-weighting those
that exhibit high similarity with only one of the two. Each individual
similarity is further improved by a set of components that are simple and
intuitive. BASIC sets a new state of the art on i-CIR but also on existing CIR
datasets that follow a semantic-level class definition. Project page:
https://vrg.fel.cvut.cz/icir/.

</details>


### [71] [More than a Moment: Towards Coherent Sequences of Audio Descriptions](https://arxiv.org/abs/2510.25440)
*Eshika Khandelwal,Junyu Xie,Tengda Han,Max Bain,Arsha Nagrani,Andrew Zisserman,Gül Varol,Makarand Tapaswi*

Main category: cs.CV

TL;DR: 提出CoherentAD方法，通过生成多个候选描述并进行序列级选择，生成连贯的音频描述序列，解决了现有方法生成孤立描述导致的重复和不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动音频描述方法独立生成每个描述，导致序列不连贯、重复，无法帮助视障观众形成连续的画面理解。

Method: 训练无关的方法：为每个时间间隔生成多个候选描述，然后通过自回归选择在序列中形成连贯叙述。

Result: 提出的方法在连贯性和叙事理解方面优于依赖独立生成的先前方法。

Conclusion: CoherentAD能够生成更连贯的音频描述序列，通过序列级选择和评估指标StoryRecall显著提升了叙述质量。

Abstract: Audio Descriptions (ADs) convey essential on-screen information, allowing
visually impaired audiences to follow videos. To be effective, ADs must form a
coherent sequence that helps listeners to visualise the unfolding scene, rather
than describing isolated moments. However, most automatic methods generate each
AD independently, often resulting in repetitive, incoherent descriptions. To
address this, we propose a training-free method, CoherentAD, that first
generates multiple candidate descriptions for each AD time interval, and then
performs auto-regressive selection across the sequence to form a coherent and
informative narrative. To evaluate AD sequences holistically, we introduce a
sequence-level metric, StoryRecall, which measures how well the predicted ADs
convey the ground truth narrative, alongside repetition metrics that capture
the redundancy across consecutive AD outputs. Our method produces coherent AD
sequences with enhanced narrative understanding, outperforming prior approaches
that rely on independent generations.

</details>


### [72] [Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography](https://arxiv.org/abs/2510.25522)
*Doan-Van-Anh Ly,Thi-Thu-Hien Pham,Thanh-Hai Le*

Main category: cs.CV

TL;DR: 本研究评估了基于UNet架构的肝脏肿瘤分割方法，发现ResNet骨干网络结合CBAM注意力模块的UNet3+模型在多个评估指标上优于Transformer和Mamba架构，在医学图像分割任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 肝脏结构在多期相增强CT中的分割对于计算机辅助诊断和治疗规划至关重要，特别是肿瘤检测。研究旨在探索不同骨干网络在UNet架构中的性能表现。

Method: 从原始UNet扩展到UNet3+，评估了ResNet、Transformer和Mamba三种骨干网络，并引入注意力机制（特别是CBAM模块）来提升分割质量。

Result: ResNetUNet3+结合CBAM模块取得了最佳性能：Dice分数0.755、IoU 0.662、HD95距离77.911、总体准确率0.925、特异性0.926，在边界描绘和病变识别方面表现最优。

Conclusion: 经典的ResNet架构结合现代注意力模块在医学图像分割任务中仍具有强大竞争力，为临床实践中的肝脏肿瘤检测提供了有前景的方向。

Abstract: Segmentation of liver structures in multi-phase contrast-enhanced computed
tomography (CECT) plays a crucial role in computer-aided diagnosis and
treatment planning for liver diseases, including tumor detection. In this
study, we investigate the performance of UNet-based architectures for liver
tumor segmentation, starting from the original UNet and extending to UNet3+
with various backbone networks. We evaluate ResNet, Transformer-based, and
State-space (Mamba) backbones, all initialized with pretrained weights.
Surprisingly, despite the advances in modern architecture, ResNet-based models
consistently outperform Transformer- and Mamba-based alternatives across
multiple evaluation metrics. To further improve segmentation quality, we
introduce attention mechanisms into the backbone and observe that incorporating
the Convolutional Block Attention Module (CBAM) yields the best performance.
ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a
Dice score of 0.755 and IoU of 0.662, but also achieved the most precise
boundary delineation, evidenced by the lowest HD95 distance of 77.911. The
model's superiority was further cemented by its leading overall accuracy of
0.925 and specificity of 0.926, showcasing its robust capability in accurately
identifying both lesion and healthy tissue. To further enhance
interpretability, Grad-CAM visualizations were employed to highlight the
region's most influential predictions, providing insights into its
decision-making process. These findings demonstrate that classical ResNet
architecture, when combined with modern attention modules, remain highly
competitive for medical image segmentation tasks, offering a promising
direction for liver tumor detection in clinical practice.

</details>


### [73] [RegionE: Adaptive Region-Aware Generation for Efficient Image Editing](https://arxiv.org/abs/2510.25590)
*Pengtao Chen,Xianfang Zeng,Maosen Zhao,Mingzhu Shen,Peng Ye,Bangyin Xiang,Zhibo Wang,Wei Cheng,Gang Yu,Tao Chen*

Main category: cs.CV

TL;DR: RegionE是一个自适应区域感知的图像编辑框架，通过区分编辑区域和未编辑区域，对未编辑区域使用单步预测，对编辑区域使用局部迭代去噪，显著加速指令图像编辑任务。


<details>
  <summary>Details</summary>
Motivation: 现有的指令图像编辑模型在整个图像上采用统一的生成过程，没有考虑到编辑区域和未编辑区域在生成难度和计算冗余上的显著差异。

Method: 1) 自适应区域划分：基于最终估计结果与参考图像的差异划分区域；2) 区域感知生成：对未编辑区域使用单步预测，对编辑区域使用局部迭代去噪，并引入区域指令KV缓存；3) 自适应速度衰减缓存：利用相邻时间步的速度相似性加速局部去噪。

Result: 在Step1X-Edit、FLUX.1 Kontext和Qwen-Image-Edit等模型上分别实现了2.57、2.41和2.06倍的加速，GPT-4o评估确认语义和感知保真度得到良好保持。

Conclusion: RegionE框架无需额外训练即可显著加速指令图像编辑任务，同时保持编辑质量，证明了区域感知生成策略的有效性。

Abstract: Recently, instruction-based image editing (IIE) has received widespread
attention. In practice, IIE often modifies only specific regions of an image,
while the remaining areas largely remain unchanged. Although these two types of
regions differ significantly in generation difficulty and computational
redundancy, existing IIE models do not account for this distinction, instead
applying a uniform generation process across the entire image. This motivates
us to propose RegionE, an adaptive, region-aware generation framework that
accelerates IIE tasks without additional training. Specifically, the RegionE
framework consists of three main components: 1) Adaptive Region Partition. We
observed that the trajectory of unedited regions is straight, allowing for
multi-step denoised predictions to be inferred in a single step. Therefore, in
the early denoising stages, we partition the image into edited and unedited
regions based on the difference between the final estimated result and the
reference image. 2) Region-Aware Generation. After distinguishing the regions,
we replace multi-step denoising with one-step prediction for unedited areas.
For edited regions, the trajectory is curved, requiring local iterative
denoising. To improve the efficiency and quality of local iterative generation,
we propose the Region-Instruction KV Cache, which reduces computational cost
while incorporating global information. 3) Adaptive Velocity Decay Cache.
Observing that adjacent timesteps in edited regions exhibit strong velocity
similarity, we further propose an adaptive velocity decay cache to accelerate
the local denoising process. We applied RegionE to state-of-the-art IIE base
models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE
achieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o
confirmed that semantic and perceptual fidelity were well preserved.

</details>


### [74] [Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation](https://arxiv.org/abs/2510.25739)
*Zhi-Kai Chen,Jun-Peng Jiang,Han-Jia Ye,De-Chuan Zhan*

Main category: cs.CV

TL;DR: Hawk是一种利用图像空间结构来指导推测模型进行更准确和高效预测的新方法，在保持图像保真度和多样性的同时，实现了1.71倍的加速。


<details>
  <summary>Details</summary>
Motivation: 自回归图像生成模型虽然能产生高保真图像，但推理速度慢。推测解码在文本生成中已证明能加速而不影响质量，但在图像生成中应用不足，主要挑战包括更大的采样空间和未能充分利用图像二维空间结构。

Method: 提出Hawk方法，利用图像的空间结构来指导推测模型，使其能够更准确和高效地预测目标模型的输出，解决了采样空间大和局部依赖建模有限的问题。

Result: 在多个文本到图像基准测试中，Hawk实现了1.71倍于标准自回归模型的加速，同时保持了图像的保真度和多样性。

Conclusion: Hawk成功地将推测解码应用于图像生成，通过利用图像空间结构解决了关键挑战，在加速推理的同时保持了生成质量。

Abstract: Autoregressive (AR) image generation models are capable of producing
high-fidelity images but often suffer from slow inference due to their
inherently sequential, token-by-token decoding process. Speculative decoding,
which employs a lightweight draft model to approximate the output of a larger
AR model, has shown promise in accelerating text generation without
compromising quality. However, its application to image generation remains
largely underexplored. The challenges stem from a significantly larger sampling
space, which complicates the alignment between the draft and target model
outputs, coupled with the inadequate use of the two-dimensional spatial
structure inherent in images, thereby limiting the modeling of local
dependencies. To overcome these challenges, we introduce Hawk, a new approach
that harnesses the spatial structure of images to guide the speculative model
toward more accurate and efficient predictions. Experimental results on
multiple text-to-image benchmarks demonstrate a 1.71x speedup over standard AR
models, while preserving both image fidelity and diversity.

</details>


### [75] [Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](https://arxiv.org/abs/2510.25760)
*Xu Zheng,Zihao Dongfang,Lutao Jiang,Boyuan Zheng,Yulong Guo,Zhenquan Zhang,Giuliano Albanese,Runyi Yang,Mengjiao Ma,Zixin Zhang,Chenfei Liao,Dingcheng Zhen,Yuanhuiyi Lyu,Yuqian Fu,Bin Ren,Linfeng Zhang,Danda Pani Paudel,Nicu Sebe,Luc Van Gool,Xuming Hu*

Main category: cs.CV

TL;DR: 这篇综述系统回顾了多模态空间推理任务，重点关注大型多模态语言模型在空间关系推理、场景理解、3D视觉问答等任务中的进展，并提供了公开基准用于评估。


<details>
  <summary>Details</summary>
Motivation: 人类具有通过视觉和声音等多模态观察理解空间的能力，大型多模态推理模型扩展了这些能力，但目前缺乏系统性的综述和公开基准。

Method: 通过分类整理多模态大语言模型的最新进展，涵盖后训练技术、可解释性和架构，并引入开放基准进行评估。

Result: 建立了多模态空间推理的坚实基础，提供了从2D任务到3D空间理解、具身AI以及新兴模态（如音频和第一人称视频）的全面视角。

Conclusion: 这项调查为不断发展的多模态空间推理领域奠定了坚实基础，并提供了有价值的见解。

Abstract: Humans possess spatial reasoning abilities that enable them to understand
spaces through multimodal observations, such as vision and sound. Large
multimodal reasoning models extend these abilities by learning to perceive and
reason, showing promising performance across diverse spatial tasks. However,
systematic reviews and publicly available benchmarks for these models remain
limited. In this survey, we provide a comprehensive review of multimodal
spatial reasoning tasks with large models, categorizing recent progress in
multimodal large language models (MLLMs) and introducing open benchmarks for
evaluation. We begin by outlining general spatial reasoning, focusing on
post-training techniques, explainability, and architecture. Beyond classical 2D
tasks, we examine spatial relationship reasoning, scene and layout
understanding, as well as visual question answering and grounding in 3D space.
We also review advances in embodied AI, including vision-language navigation
and action models. Additionally, we consider emerging modalities such as audio
and egocentric video, which contribute to novel spatial understanding through
new sensors. We believe this survey establishes a solid foundation and offers
insights into the growing field of multimodal spatial reasoning. Updated
information about this survey, codes and implementation of the open benchmarks
can be found at https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.

</details>


### [76] [VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning](https://arxiv.org/abs/2510.25772)
*Baolu Li,Yiming Zhang,Qinghe Wang,Liqian Ma,Xiaoyu Shi,Xintao Wang,Pengfei Wan,Zhenfei Yin,Yunzhi Zhuge,Huchuan Lu,Xu Jia*

Main category: cs.CV

TL;DR: VFXMaster是一个统一的、基于参考的VFX视频生成框架，通过上下文学习实现动态特效的跨视频迁移，并能泛化到未见过的特效类别。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用每个特效一个LoRA的模式，资源消耗大且无法泛化到未见特效，限制了可扩展性和创作能力。

Method: 设计了上下文条件策略和上下文注意力掩码，精确解耦和注入关键特效属性；提出高效的单样本特效适应机制增强泛化能力。

Result: 实验表明该方法能有效模仿各类特效信息，并在域外特效上表现出色泛化能力。

Conclusion: VFXMaster为VFX视频生成提供了统一框架，解决了现有方法的局限性，并将发布代码、模型和数据集推动未来研究。

Abstract: Visual effects (VFX) are crucial to the expressive power of digital media,
yet their creation remains a major challenge for generative AI. Prevailing
methods often rely on the one-LoRA-per-effect paradigm, which is
resource-intensive and fundamentally incapable of generalizing to unseen
effects, thus limiting scalability and creation. To address this challenge, we
introduce VFXMaster, the first unified, reference-based framework for VFX video
generation. It recasts effect generation as an in-context learning task,
enabling it to reproduce diverse dynamic effects from a reference video onto
target content. In addition, it demonstrates remarkable generalization to
unseen effect categories. Specifically, we design an in-context conditioning
strategy that prompts the model with a reference example. An in-context
attention mask is designed to precisely decouple and inject the essential
effect attributes, allowing a single unified model to master the effect
imitation without information leakage. In addition, we propose an efficient
one-shot effect adaptation mechanism to boost generalization capability on
tough unseen effects from a single user-provided video rapidly. Extensive
experiments demonstrate that our method effectively imitates various categories
of effect information and exhibits outstanding generalization to out-of-domain
effects. To foster future research, we will release our code, models, and a
comprehensive dataset to the community.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [77] [SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving](https://arxiv.org/abs/2510.24949)
*Anil Yildiz,Sarah M. Thornton,Carl Hildebrandt,Sreeja Roy-Singh,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出SCOUT轻量级替代模型，直接从智能体潜在传感器表示预测场景覆盖标签，避免昂贵的人类标注或大型视觉语言模型推理，实现高效可扩展的场景覆盖评估。


<details>
  <summary>Details</summary>
Motivation: 现有场景覆盖评估方法依赖昂贵的人工标注或计算密集型大型视觉语言模型，成本高且效率低，不适用于大规模部署。

Method: 通过蒸馏过程训练SCOUT模型，学习近似LVLM生成的覆盖标签，利用预计算的感知特征，避免冗余计算，直接从智能体潜在传感器表示预测场景覆盖。

Result: 在真实自主导航场景数据集上的评估表明，SCOUT在保持高精度的同时显著降低计算成本，为大规模覆盖分析提供有效实用的替代方案。

Conclusion: SCOUT代表了自主系统中高效场景覆盖监督的重要进展，虽然其性能依赖于LVLM生成训练标签的质量，但为大规模部署提供了可行解决方案。

Abstract: Assessing scenario coverage is crucial for evaluating the robustness of
autonomous agents, yet existing methods rely on expensive human annotations or
computationally intensive Large Vision-Language Models (LVLMs). These
approaches are impractical for large-scale deployment due to cost and
efficiency constraints. To address these shortcomings, we propose SCOUT
(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate
model designed to predict scenario coverage labels directly from an agent's
latent sensor representations. SCOUT is trained through a distillation process,
learning to approximate LVLM-generated coverage labels while eliminating the
need for continuous LVLM inference or human annotation. By leveraging
precomputed perception features, SCOUT avoids redundant computations and
enables fast, scalable scenario coverage estimation. We evaluate our method
across a large dataset of real-life autonomous navigation scenarios,
demonstrating that it maintains high accuracy while significantly reducing
computational cost. Our results show that SCOUT provides an effective and
practical alternative for large-scale coverage analysis. While its performance
depends on the quality of LVLM-generated training labels, SCOUT represents a
major step toward efficient scenario coverage oversight in autonomous systems.

</details>


### [78] [Smooth path planning with safety margins using Piece-Wise Bezier curves](https://arxiv.org/abs/2510.24972)
*Iancu Andrei,Marius Kloetzer,Cristian Mahulea,Catalin Dosoftei*

Main category: cs.RO

TL;DR: 提出了一种计算高效的二次规划方法，使用分段二次贝塞尔曲线为移动机器人生成平滑的C1连续路径，在保证安全裕度的同时平衡轨迹平滑性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统分段线性路径规划方法存在轨迹偏差大、鲁棒性不足的问题，需要开发既能保证安全裕度又适合实时嵌入式应用的高效路径规划方法。

Method: 采用分段二次贝塞尔曲线，在结构化优化框架中显式纳入安全裕度，通过二次规划方法平衡轨迹平滑性和数值复杂度。

Result: 与传统分段线性方法相比，轨迹偏差显著减小，鲁棒性增强，整体路径质量提升，在纯追踪控制器仿真中验证了方法的有效性。

Conclusion: 该方法在保证安全导航的同时，具有实际有效性和可扩展性，适用于实时和嵌入式应用场景。

Abstract: In this paper, we propose a computationally efficient quadratic programming
(QP) approach for generating smooth, $C^1$ continuous paths for mobile robots
using piece-wise quadratic Bezier (PWB) curves. Our method explicitly
incorporates safety margins within a structured optimization framework,
balancing trajectory smoothness and robustness with manageable numerical
complexity suitable for real-time and embedded applications. Comparative
simulations demonstrate clear advantages over traditional piece-wise linear
(PWL) path planning methods, showing reduced trajectory deviations, enhanced
robustness, and improved overall path quality. These benefits are validated
through simulations using a Pure-Pursuit controller in representative
scenarios, highlighting the practical effectiveness and scalability of our
approach for safe navigation.

</details>


### [79] [Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT](https://arxiv.org/abs/2510.24994)
*Matsive Ali,Blake Gassen,Sen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种集成机器人熔融沉积增材制造系统，具有闭环热控制和智能原位缺陷校正功能，使用6自由度机械臂和Oak-D相机实现实时质量保证。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D打印中缺乏实时质量控制和缺陷自动校正的问题，提高增材制造过程的可靠性和适应性。

Method: 采用6自由度机械臂配合E3D热端，通过IoT微控制器实现闭环热控制；使用ROS2协调机器人运动与挤出同步；基于OpenCV的视觉系统检测层间缺陷位置，并命令自主重新挤出；应用逆运动学进行运动规划，同形变换校正相机视角。

Result: 实验验证显示系统成功减轻了打印操作中的缺陷，能够在不中断打印过程的情况下有效缓解表面异常。

Conclusion: 通过结合实时热调节、运动控制和智能缺陷检测与校正，该架构建立了一个可扩展且自适应的机器人增材制造框架，适用于航空航天、生物医学和工业应用。

Abstract: This paper presents an integrated robotic fused deposition modeling additive
manufacturing system featuring closed-loop thermal control and intelligent
in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D
camera. The robot arm end effector was modified to mount an E3D hotend
thermally regulated by an IoT microcontroller, enabling precise temperature
control through real-time feedback. Filament extrusion system was synchronized
with robotic motion, coordinated via ROS2, ensuring consistent deposition along
complex trajectories. A vision system based on OpenCV detects layer-wise
defects position, commanding autonomous re-extrusion at identified sites.
Experimental validation demonstrated successful defect mitigation in printing
operations. The integrated system effectively addresses challenges real-time
quality assurance. Inverse kinematics were used for motion planning, while
homography transformations corrected camera perspectives for accurate defect
localization. The intelligent system successfully mitigated surface anomalies
without interrupting the print process. By combining real-time thermal
regulation, motion control, and intelligent defect detection & correction, this
architecture establishes a scalable and adaptive robotic additive manufacturing
framework suitable for aerospace, biomedical, and industrial applications.

</details>


### [80] [Scalable predictive processing framework for multitask caregiving robots](https://arxiv.org/abs/2510.25053)
*Hayato Idei,Tamon Miyake,Tetsuya Ogata,Yuichi Yamashita*

Main category: cs.RO

TL;DR: 提出基于预测处理理论的分层多模态循环神经网络，能够直接处理高维视觉-本体感觉输入，在护理机器人任务中实现无需特定特征工程的灵活学习。


<details>
  <summary>Details</summary>
Motivation: 现有护理机器人系统多为任务特定且依赖手工预处理，缺乏泛化能力。受人类大脑分层预测处理机制的启发，旨在开发能够适应多样化场景的通用自主护理机器人。

Method: 基于自由能原理的分层多模态循环神经网络，直接整合超过30,000维的视觉-本体感觉输入，无需降维处理。模型学习两种代表性护理任务：刚体重新定位和柔性毛巾擦拭。

Result: 模型展现出三个关键特性：(1)分层潜在动态自组织调节任务转换、捕捉不确定性变化并推断遮挡状态；(2)通过视觉-本体感觉整合实现视觉退化下的鲁棒性；(3)多任务学习中的不对称干扰，擦拭任务对重新定位影响小，而学习重新定位对擦拭性能有适度影响，但整体保持鲁棒性。

Conclusion: 尽管评估仅限于模拟环境，但结果确立了预测处理作为通用且可扩展的计算原理，为开发鲁棒、灵活和自主的护理机器人指明了方向，同时为理解人脑在不确定现实环境中实现灵活适应的能力提供了理论洞见。

Abstract: The rapid aging of societies is intensifying demand for autonomous care
robots; however, most existing systems are task-specific and rely on
handcrafted preprocessing, limiting their ability to generalize across diverse
scenarios. A prevailing theory in cognitive neuroscience proposes that the
human brain operates through hierarchical predictive processing, which
underlies flexible cognition and behavior by integrating multimodal sensory
signals. Inspired by this principle, we introduce a hierarchical multimodal
recurrent neural network grounded in predictive processing under the
free-energy principle, capable of directly integrating over 30,000-dimensional
visuo-proprioceptive inputs without dimensionality reduction. The model was
able to learn two representative caregiving tasks, rigid-body repositioning and
flexible-towel wiping, without task-specific feature engineering. We
demonstrate three key properties: (i) self-organization of hierarchical latent
dynamics that regulate task transitions, capture variability in uncertainty,
and infer occluded states; (ii) robustness to degraded vision through
visuo-proprioceptive integration; and (iii) asymmetric interference in
multitask learning, where the more variable wiping task had little influence on
repositioning, whereas learning the repositioning task led to a modest
reduction in wiping performance, while the model maintained overall robustness.
Although the evaluation was limited to simulation, these results establish
predictive processing as a universal and scalable computational principle,
pointing toward robust, flexible, and autonomous caregiving robots while
offering theoretical insight into the human brain's ability to achieve flexible
adaptation in uncertain real-world environments.

</details>


### [81] [Non-Invasive Calibration Of A Stewart Platform By Photogrammetry](https://arxiv.org/abs/2510.25072)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出了一种基于正向运动学和摄影测量的Stewart平台标定方法，使用Denavit-Hartenberg约定和最小二乘法进行误差补偿，显著提高了平台位姿精度。


<details>
  <summary>Details</summary>
Motivation: Stewart平台的正向运动学校准具有挑战性，因为正向运动学通常会产生多个可行和不可行的解，且六个执行器路径之间的复杂运动学关系使得建立直接有效的校准方法变得困难。

Method: 使用Denavit-Hartenberg约定的正向运动学标定方法，结合摄影测量技术，通过高分辨率数码相机从不同角度拍摄多张图像来测量平台中心在三维空间中的位置和方向，然后使用最小二乘法进行误差补偿。

Result: 三种补偿方法都显著提高了平台位姿精度，表明还有进一步改进的空间。

Conclusion: 开发的基于摄影测量的非侵入式标定方法有效提高了Stewart平台的精度，且不需要在六足机器人上附加任何额外设备或改变硬件。

Abstract: Accurate calibration of a Stewart platform is important for their precise and
efficient operation. However, the calibration of these platforms using forward
kinematics is a challenge for researchers because forward kinematics normally
generates multiple feasible and unfeasible solutions for any pose of the moving
platform. The complex kinematic relations among the six actuator paths
connecting the fixed base to the moving platform further compound the
difficulty in establishing a straightforward and efficient calibration method.
The authors developed a new forward kinematics-based calibration method using
Denavit-Hartenberg convention and used the Stewart platform Tiger 66.1
developed in their lab for experimenting with the photogrammetry-based
calibration strategies described in this paper. This system became operational
upon completion of construction, marking its inaugural use. The authors used
their calibration model for estimating the errors in the system and adopted
three compensation options or strategies as per Least Square method to improve
the accuracy of the system. These strategies leveraged a high-resolution
digital camera and off-the-shelf software to capture the poses of the moving
platform's center. This process is non-invasive and does not need any
additional equipment to be attached to the hexapod or any alteration of the
hexapod hardware. This photogrammetry-based calibration process involves
multiple high-resolution images from different angles to measure the position
and orientation of the platform center in the three-dimensional space. The
Target poses and Actual poses are then compared, and the error compensations
are estimated using the Least-Squared methods to calculate the Predicted poses.
Results from each of the three compensation approaches demonstrated noticeable
enhancements in platform pose accuracies, suggesting room for further
improvements.

</details>


### [82] [Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration](https://arxiv.org/abs/2510.25086)
*Guibin Sun,Jinhu Lü,Kexin Liu,Zhenqian Wang,Guanrong Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人群体无分配协作的最新进展，重点研究形状形成问题，提出了均值漂移探索策略，大幅提升了大规模群体协作效率。


<details>
  <summary>Details</summary>
Motivation: 自然界中群体行为展现的高效协作激发了机器人群体智能的研究，但传统的基于分配的方法在效率和鲁棒性方面存在根本限制，无法适应群体规模的变化。

Method: 提出了均值漂移探索策略，这是一种无分配的协作方法，特别适用于机器人群体的形状形成问题。

Result: 均值漂移探索策略将大规模群体的协作效率提升了数十倍，且随着群体规模的增加，效率提升更加显著。

Conclusion: 均值漂移探索策略在精确形状形成、区域覆盖形成和机动形成等应用中具有重要价值，可应用于智能仓储、区域探索和货物运输等工业场景。

Abstract: Swarms evolving from collective behaviors among multiple individuals are
commonly seen in nature, which enables biological systems to exhibit more
efficient and robust collaboration. Creating similar swarm intelligence in
engineered robots poses challenges to the design of collaborative algorithms
that can be programmed at large scales. The assignment-based method has played
an eminent role for a very long time in solving collaboration problems of robot
swarms. However, it faces fundamental limitations in terms of efficiency and
robustness due to its unscalability to swarm variants. This article presents a
tutorial review on recent advances in assignment-free collaboration of robot
swarms, focusing on the problem of shape formation. A key theoretical component
is the recently developed \emph{mean-shift exploration} strategy, which
improves the collaboration efficiency of large-scale swarms by dozens of times.
Further, the efficiency improvement is more significant as the swarm scale
increases. Finally, this article discusses three important applications of the
mean-shift exploration strategy, including precise shape formation, area
coverage formation, and maneuvering formation, as well as their corresponding
industrial scenarios in smart warehousing, area exploration, and cargo
transportation.

</details>


### [83] [NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](https://arxiv.org/abs/2510.25122)
*Jiahong Chen,Jing Wang,Long Chen,Chuwei Cai,Jinghui Lu*

Main category: cs.RO

TL;DR: NanoVLA是一个轻量级视觉语言动作模型，专为资源受限的边缘设备设计，通过视觉语言解耦、长短动作分块和动态路由等创新，在保持高性能的同时实现52倍推理加速和98%参数减少。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型在资源受限的边缘设备上部署困难，因为计算需求高，而实际应用中功耗、延迟和计算资源都很关键。

Method: 采用视觉语言解耦（将早期融合改为晚期融合）、长短动作分块（确保多步规划的连贯性）和动态路由（根据任务复杂度自适应选择轻量或重量主干网络）。

Result: 在多个基准测试和实际部署中，NanoVLA相比现有最优VLA模型实现52倍推理加速，参数减少98%，同时保持或超越了任务准确性和泛化能力。

Conclusion: NanoVLA通过创新的架构设计，实现了在资源受限硬件上的实用、高精度机器人操作，消融研究验证了解耦策略保持跨任务可迁移性，路由模块优化了成本性能权衡。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
manipulation by integrating vision-language models (VLMs), and action decoders
into a unified architecture. However, their deployment on resource-constrained
edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin
Nano), remains challenging due to high computational demands, especially in
real-world scenarios where power, latency, and computational resources are
critical. To close this gap, we introduce Nano-scale Vision-Language Action
(NanoVLA), a family of lightweight VLA architectures that achieve high
performance with minimal resources. Our core innovations include: (1)
vision-language decoupling that moves conventional early vision and language
inputs fusion in VLM to late stage, achieving better performance while enabling
caching and reduce inference overhead and latency; (2) long-short action
chunking to ensure smooth, coherent multi-step planning without sacrificing
real-time responsiveness; (3) dynamic routing that adaptively assigns
lightweight or heavy backbones based on task complexity, further optimizing
inference efficiency. Experimental results on several benchmarks, as well as
real-world deployments, demonstrate that NanoVLA achieves up to 52x faster
inference on edge devices compared to previous state-of-the-art VLA models,
with 98% less parameters while maintaining or surpassing their task accuracy
and generalization. Ablation studies confirm that our decoupling strategy
preserves cross-task transferability, and the routing module enhances
cost-performance trade-offs, enabling practical, high-precision robotic
manipulation on resource-constrained hardware.

</details>


### [84] [Learning Spatial-Aware Manipulation Ordering](https://arxiv.org/abs/2510.25138)
*Yuxiang Yan,Zhiyuan Zhou,Xin Gao,Guanghao Li,Shenglin Li,Jiaqi Chen,Qunyan Pu,Jian Pu*

Main category: cs.RO

TL;DR: OrderMind是一个空间感知的操纵排序框架，通过空间图神经网络学习物体操纵优先级，在杂乱环境中实现高效的物体操纵排序。


<details>
  <summary>Details</summary>
Motivation: 解决杂乱环境中物体操纵的空间依赖性问题，现有方法往往忽略空间关系，导致灵活性差和可扩展性有限。

Method: 集成空间上下文编码器和时间优先级结构化模块，构建k近邻空间图来聚合几何信息，编码物体间和物体-操纵器交互，并引入空间先验标注方法生成监督信号。

Result: 在包含163,222个样本的操纵排序基准测试中，该方法在仿真和真实环境中均显著优于现有方法，实现了高效鲁棒的杂乱场景操纵。

Conclusion: OrderMind通过空间感知的操纵排序有效解决了杂乱环境中的物体操纵问题，在效果和效率上都有显著提升。

Abstract: Manipulation in cluttered environments is challenging due to spatial
dependencies among objects, where an improper manipulation order can cause
collisions or blocked access. Existing approaches often overlook these spatial
relationships, limiting their flexibility and scalability. To address these
limitations, we propose OrderMind, a unified spatial-aware manipulation
ordering framework that directly learns object manipulation priorities based on
spatial context. Our architecture integrates a spatial context encoder with a
temporal priority structuring module. We construct a spatial graph using
k-Nearest Neighbors to aggregate geometric information from the local layout
and encode both object-object and object-manipulator interactions to support
accurate manipulation ordering in real-time. To generate physically and
semantically plausible supervision signals, we introduce a spatial prior
labeling method that guides a vision-language model to produce reasonable
manipulation orders for distillation. We evaluate OrderMind on our Manipulation
Ordering Benchmark, comprising 163,222 samples of varying difficulty. Extensive
experiments in both simulation and real-world environments demonstrate that our
method significantly outperforms prior approaches in effectiveness and
efficiency, enabling robust manipulation in cluttered scenes.

</details>


### [85] [SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning](https://arxiv.org/abs/2510.25191)
*Hongyu Song,Rishabh Dev Yadav,Cheng Guo,Wei Pan*

Main category: cs.RO

TL;DR: SoraNav是一个自适应无人机导航框架，结合零样本视觉语言模型推理和几何感知决策，在2.5D和3D场景中显著提升导航成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法主要针对地面机器人，难以推广到需要完整3D空间推理的空中任务，而大型视觉语言模型缺乏空间基础，无法直接用于导航。

Method: 将几何先验融入图像标注以约束VLM动作空间，采用混合切换策略在VLM推理和基于几何的探索之间交替，避免死胡同和重复访问。

Result: 在2.5D场景中，成功率提高25.7%，路径长度加权成功率提高17%；在3D场景中，成功率提高29.5%，路径长度加权成功率提高18.5%。

Conclusion: SoraNav通过整合零样本VLM推理和几何感知决策，有效解决了无人机在复杂3D环境中的语言驱动导航挑战。

Abstract: Interpreting visual observations and natural language instructions for
complex task execution remains a key challenge in robotics and AI. Despite
recent advances, language-driven navigation is still difficult, particularly
for UAVs in small-scale 3D environments. Existing Vision-Language Navigation
(VLN) approaches are mostly designed for ground robots and struggle to
generalize to aerial tasks that require full 3D spatial reasoning. The
emergence of large Vision-Language Models (VLMs), such as GPT and Claude,
enables zero-shot semantic reasoning from visual and textual inputs. However,
these models lack spatial grounding and are not directly applicable to
navigation. To address these limitations, SoraNav is introduced, an adaptive
UAV navigation framework that integrates zero-shot VLM reasoning with
geometry-aware decision-making. Geometric priors are incorporated into image
annotations to constrain the VLM action space and improve decision quality. A
hybrid switching strategy leverages navigation history to alternate between VLM
reasoning and geometry-based exploration, mitigating dead-ends and redundant
revisits. A PX4-based hardware-software platform, comprising both a digital
twin and a physical micro-UAV, enables reproducible evaluation. Experimental
results show that in 2.5D scenarios, our method improves Success Rate (SR) by
25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it
improves SR by 29.5% and SPL by 18.5% relative to the baseline.

</details>


### [86] [RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis](https://arxiv.org/abs/2510.25211)
*Amith Khandakar,David Michelson,Shaikh Golam Rabbani,Fariya Bintay Shafi,Md. Faysal Ahamed,Khondokar Radwanur Rahman,Md Abidur Rahman,Md. Fahmidun Nabi,Mohamed Arselene Ayari,Khaled Khan,Ponnuthurai Nagaratnam Suganthan*

Main category: cs.RO

TL;DR: 提出一个整合多种传感器数据、GIS信息和天气数据的道路质量监测数据集，用于改善道路安全和交通管理


<details>
  <summary>Details</summary>
Motivation: 缺乏高质量标准化数据集阻碍了基于智能手机传感器监测道路状况的研究进展

Method: 开发移动应用收集GPS、加速度计、陀螺仪、磁力计、重力传感器和方向传感器数据，并整合GIS、天气信息和道路视频

Result: 创建了包含车辆速度、加速度、旋转速率、磁场强度以及视觉空间上下文信息的综合数据集

Conclusion: 该数据集将公开可用，旨在支持智能交通系统研究，促进交通管理、基础设施发展和道路安全

Abstract: It's important to monitor road issues such as bumps and potholes to enhance
safety and improve road conditions. Smartphones are equipped with various
built-in sensors that offer a cost-effective and straightforward way to assess
road quality. However, progress in this area has been slow due to the lack of
high-quality, standardized datasets. This paper discusses a new dataset created
by a mobile app that collects sensor data from devices like GPS,
accelerometers, gyroscopes, magnetometers, gravity sensors, and orientation
sensors. This dataset is one of the few that integrates Geographic Information
System (GIS) data with weather information and video footage of road
conditions, providing a comprehensive understanding of road issues with
geographic context. The dataset allows for a clearer analysis of road
conditions by compiling essential data, including vehicle speed, acceleration,
rotation rates, and magnetic field intensity, along with the visual and spatial
context provided by GIS, weather, and video data. Its goal is to provide
funding for initiatives that enhance traffic management, infrastructure
development, road safety, and urban planning. Additionally, the dataset will be
publicly accessible to promote further research and innovation in smart
transportation systems.

</details>


### [87] [Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery](https://arxiv.org/abs/2510.25233)
*Jee Won Lee,Hansol Lim,Sooyeun Yang,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: 提出了一种混合视觉跟踪框架，结合全局模板匹配、深度特征Lucas-Kanade和残差回归器，在严重遮挡下保持亚像素精度跟踪，支持30Hz图像伺服控制。


<details>
  <summary>Details</summary>
Motivation: 解决视觉伺服控制中目标在部分或完全遮挡下鲁棒跟踪的挑战，传统方法对遮挡和漂移敏感，而深度学习方法需要持续可见性和高计算量。

Method: 1) 快速全局模板匹配约束位姿搜索区域；2) 基于VGG早期层的深度特征Lucas-Kanade模块实现亚像素对齐；3) 轻量级残差回归器校正局部错位；4) 当视觉置信度低时，GRU预测器从运动历史外推位姿更新。

Result: 在手持视频序列上评估，即使90%遮挡情况下仍能维持低于2像素的跟踪误差，展示了鲁棒性和低延迟精度。

Conclusion: 该混合框架成功桥接了高级感知与实时伺服控制，为可靠的机器人视觉应用提供了必要的鲁棒性和精度。

Abstract: Vision-based control systems, such as image-based visual servoing (IBVS),
have been extensively explored for precise robot manipulation. A persistent
challenge, however, is maintaining robust target tracking under partial or full
occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking
but are fragile to occlusion and drift, while deep learning-based approaches
often require continuous visibility and intensive computation. To address these
gaps, we propose a hybrid visual tracking framework that bridges advanced
perception with real-time servo control. First, a fast global template matcher
constrains the pose search region; next, a deep-feature Lucas-Kanade module
operating on early VGG layers refines alignment to sub-pixel accuracy (<2px);
then, a lightweight residual regressor corrects local misalignments caused by
texture degradation or partial occlusion. When visual confidence falls below a
threshold, a GRU-based predictor seamlessly extrapolates pose updates from
recent motion history. Crucially, the pipeline's final outputs-translation,
rotation, and scale deltas-are packaged as direct control signals for 30Hz
image-based servo loops. Evaluated on handheld video sequences with up to 90%
occlusion, our system sustains under 2px tracking error, demonstrating the
robustness and low-latency precision essential for reliable real-world robot
vision applications.

</details>


### [88] [One-shot Humanoid Whole-body Motion Learning](https://arxiv.org/abs/2510.25241)
*Hao Huang,Geeta Chandra Raju Bethala,Shuaihang Yuan,Congcong Wen,Anthony Tzes,Yi Fang*

Main category: cs.RO

TL;DR: 提出一种仅需单个非行走运动样本即可训练人形机器人运动策略的新方法，通过最优传输和插值生成中间姿态，在CMU MoCap数据集上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要每个运动类别的多个训练样本，收集高质量人体运动数据集既费力又昂贵，因此需要更高效的方法。

Method: 利用保序最优传输计算行走和非行走序列间的距离，通过测地线插值生成新中间姿态骨架，优化无碰撞配置并重定向到人形机器人，在模拟环境中通过强化学习训练策略。

Result: 在CMU MoCap数据集上的实验评估表明，该方法始终优于基线，在各项指标上取得更优性能。

Conclusion: 该方法能够仅使用单个非行走目标运动样本和现成的行走运动，有效训练人形机器人运动策略，解决了数据收集成本高的问题。

Abstract: Whole-body humanoid motion represents a cornerstone challenge in robotics,
integrating balance, coordination, and adaptability to enable human-like
behaviors. However, existing methods typically require multiple training
samples per motion category, rendering the collection of high-quality human
motion datasets both labor-intensive and costly. To address this, we propose a
novel approach that trains effective humanoid motion policies using only a
single non-walking target motion sample alongside readily available walking
motions. The core idea lies in leveraging order-preserving optimal transport to
compute distances between walking and non-walking sequences, followed by
interpolation along geodesics to generate new intermediate pose skeletons,
which are then optimized for collision-free configurations and retargeted to
the humanoid before integration into a simulated environment for policy
training via reinforcement learning. Experimental evaluations on the CMU MoCap
dataset demonstrate that our method consistently outperforms baselines,
achieving superior performance across metrics. Code will be released upon
acceptance.

</details>


### [89] [Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths](https://arxiv.org/abs/2510.25255)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文研究了机器人托盘运输液体容器的最优控制问题，旨在最小化液体晃动以避免溢出。


<details>
  <summary>Details</summary>
Motivation: 处理松散放置的物体对机器人轨迹规划和控制具有挑战性，特别是当物体是装有液体的容器时。本文旨在解决在最短时间内沿规定路径运输托盘上液体杯子的任务，目标是减少液体晃动以避免溢出。

Method: 将液体晃动动力学纳入动态模型，采用最优控制问题公式化，并使用直接多重打靶法求解优化问题。

Result: 通过将液体晃动动力学整合到动态模型中，并采用直接多重打靶法求解最优控制问题，实现了在最短时间内运输液体容器且最小化晃动的目标。

Conclusion: 该方法成功地将液体晃动动力学整合到机器人控制中，通过最优控制方法有效减少了液体运输过程中的晃动和溢出风险。

Abstract: Handling loosely placed objects with robotic manipulators is a difficult task
from the point of view of trajectory planning and control. This becomes even
more challenging when the object to be handled is a container filled with
liquid. This paper addresses the task of transporting a liquid-filled cup
placed on a tray along a prescribed path in shortest time. The objective is to
minimize swapping, thus avoiding spillage of the fluid. To this end, the
sloshing dynamics is incorporated into the dynamic model used within the
optimal control problem formulation. The optimization problem is solved using a
direct multiple shooting approach.

</details>


### [90] [SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation](https://arxiv.org/abs/2510.25268)
*Wang zhi,Yuyan Liu,Liu Liu,Li Zhang,Ruixuan Lu,Dan Guo*

Main category: cs.RO

TL;DR: SynHLMA框架用于生成带语言指令的手部抓握序列，专门针对铰接物体的手部交互，通过共享表示空间对齐抓握过程与语言描述。


<details>
  <summary>Details</summary>
Motivation: 铰接物体手部交互需要同时考虑物体功能性和长期操作序列，现有方法难以处理物体变形过程中的动态变化。

Method: 使用离散HAOI表示建模每个手部交互帧，结合自然语言嵌入，通过HAOI操作语言模型在共享表示空间中对齐抓握过程与语言描述，并采用关节感知损失确保手部抓握跟随铰接物体关节的动态变化。

Result: 在HAOI-lang数据集上评估，SynHLMA在HAOI生成、预测和插值三个典型任务中表现出优于现有方法的性能，并成功应用于机器人抓握执行。

Conclusion: SynHLMA框架能够有效生成铰接物体的手部操作序列，实现了语言指令与手部动作的精确对齐，为具身AI和机器人应用提供了有力工具。

Abstract: Generating hand grasps with language instructions is a widely studied topic
that benefits from embodied AI and VR/AR applications. While transferring into
hand articulatied object interaction (HAOI), the hand grasps synthesis requires
not only object functionality but also long-term manipulation sequence along
the object deformation. This paper proposes a novel HAOI sequence generation
framework SynHLMA, to synthesize hand language manipulation for articulated
objects. Given a complete point cloud of an articulated object, we utilize a
discrete HAOI representation to model each hand object interaction frame. Along
with the natural language embeddings, the representations are trained by an
HAOI manipulation language model to align the grasping process with its
language description in a shared representation space. A joint-aware loss is
employed to ensure hand grasps follow the dynamic variations of articulated
object joints. In this way, our SynHLMA achieves three typical hand
manipulation tasks for articulated objects of HAOI generation, HAOI prediction
and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and
experimental results demonstrate the superior hand grasp sequence generation
performance comparing with state-of-the-art. We also show a robotics grasp
application that enables dexterous grasps execution from imitation learning
using the manipulation sequence provided by our SynHLMA. Our codes and datasets
will be made publicly available.

</details>


### [91] [Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance](https://arxiv.org/abs/2510.25280)
*Yusuke Tsunoda,Seiya Yamamoto,Kazuki Ito,Runze Xiao,Keisuke Naniwa,Koichi Osuka*

Main category: cs.RO

TL;DR: 开发了一种能够在陆地和水域环境中使用统一控制方案的蜈蚣型移动机器人，通过巧妙设计腿部结构实现在不同环境中的自主移动。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂地形中具有高移动性能，但为每个环境设计特定步态和控制器切换具有挑战性。本研究旨在开发一种能在水陆环境中使用简单统一控制方案的机器人。

Method: 基于隐式-显式控制理念，设计具有灵活关节和左右腿的蜈蚣型机器人结构，重点关注与环境接触广泛的腿部结构。开发了三种腿部结构，以腿滑移率和执行器能耗为评估指标。

Result: 实验结果表明，存在一种合适的腿部结构能够在相同控制下导航水陆环境。

Conclusion: 通过巧妙设计机器人结构，可以实现水陆环境中的统一控制导航，无需为每个环境设计特定控制器。

Abstract: Multi-legged mobile robots possess high mobility performance in rough terrain
environments, stemming from their high postural stability, joint flexibility,
and the redundancy provided by multiple legs. In prior research on navigating
between different environments such as land and water, the primary strategy
employed involves switching to a controller that generates an appropriate gait
for the new environment upon entering it. However, designing appropriate gaits
for each complex and diverse environment and accurately determining controller
switching for each environment is challenging. Therefore, this research
develops a centipede-type mobile robot that navigates both aquatic and
terrestrial environments with a simple, unified control scheme, based on the
implicit-explicit control philosophy and by ingeniously designing the robot's
body structure. In this research, we developed the robot featuring flexible
joints and left and right legs on each body segment and focused on the leg
structure which has extensive contact with the environment. This paper
evaluates the locomotion performance on land and water using the three
developed leg structures, using the robot's leg slip rate and actuator energy
consumption as evaluation metrics. The experimental results confirmed the
existence of an appropriate leg structure capable of navigating both aquatic
and terrestrial environments under identical control.

</details>


### [92] [Solving the Right Problem with Multi-Robot Formations](https://arxiv.org/abs/2510.25422)
*Chaz Cornwall,Jeremy P. Bos*

Main category: cs.RO

TL;DR: 提出一种编队规划器，通过两步优化问题识别期望的相对机器人位置，以减少编队形状与原始成本函数之间的不匹配，同时利用高效的编队控制器。


<details>
  <summary>Details</summary>
Motivation: 传统编队控制将复杂成本函数简化为固定形状，但当环境信息变化时，静态形状往往无法最小化原始保护成本，导致编队与成本函数之间的不匹配。

Method: 两步优化：首先用加权和估计非线性不可微成本，然后最小化加权代理成本函数得到相对位置，最后使用基于Lyapunov方法的非合作编队控制器实现。

Result: 仿真显示编队规划器可将单一成本降低75%以上，同时最小化多个成本函数时，使用自适应权重的编队规划器可降低20-40%的成本。

Conclusion: 编队规划通过最小化近似原始成本函数的代理成本函数，相比依赖形状抽象能提供更好的性能。

Abstract: Formation control simplifies minimizing multi-robot cost functions by
encoding a cost function as a shape the robots maintain. However, by reducing
complex cost functions to formations, discrepancies arise between maintaining
the shape and minimizing the original cost function. For example, a Diamond or
Box formation shape is often used for protecting all members of the formation.
When more information about the surrounding environment becomes available, a
static shape often no longer minimizes the original protection cost. We propose
a formation planner to reduce mismatch between a formation and the cost
function while still leveraging efficient formation controllers. Our formation
planner is a two-step optimization problem that identifies desired relative
robot positions. We first solve a constrained problem to estimate non-linear
and non-differentiable costs with a weighted sum of surrogate cost functions.
We theoretically analyze this problem and identify situations where weights do
not need to be updated. The weighted, surrogate cost function is then minimized
using relative positions between robots. The desired relative positions are
realized using a non-cooperative formation controller derived from Lyapunov's
direct approach. We then demonstrate the efficacy of this approach for
military-like costs such as protection and obstacle avoidance. In simulations,
we show a formation planner can reduce a single cost by over 75%. When
minimizing a variety of cost functions simultaneously, using a formation
planner with adaptive weights can reduce the cost by 20-40%. Formation planning
provides better performance by minimizing a surrogate cost function that
closely approximates the original cost function instead of relying on a shape
abstraction.

</details>


### [93] [An approach for combining transparency and motion assistance of a lower body exoskeleton](https://arxiv.org/abs/2510.25335)
*Jakob Ziegler,Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种结合透明模式和运动辅助模式的下半身外骨骼步态辅助方法，利用齿轮间隙实现透明跟随，通过自适应振荡器学习步态周期信号来提供运动辅助。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够同时实现透明跟随和主动辅助的下半身外骨骼系统，在用户自由运动时最小化交互力感知，在行走时提供主动引导。

Method: 利用驱动单元的齿轮间隙实现透明模式，通过自适应振荡器学习准周期性步态信号，在行走时叠加辅助扭矩引导腿部运动。

Result: 初步实验显示出有希望的结果。

Conclusion: 该方法成功结合了透明模式和运动辅助模式，为下半身外骨骼步态辅助提供了一种有效的解决方案。

Abstract: In this paper, an approach for gait assistance with a lower body exoskeleton
is described. Two concepts, transparency and motion assistance, are combined.
The transparent mode, where the system is following the user's free motion with
a minimum of perceived interaction forces, is realized by exploiting the gear
backlash of the actuation units. During walking a superimposed assistance mode
applies an additional torque guiding the legs to their estimated future
position. The concept of adaptive oscillators is utilized to learn the
quasi-periodic signals typical for locomotion. First experiments showed
promising results.

</details>


### [94] [Geometric Robot Calibration Using a Calibration Plate](https://arxiv.org/abs/2510.25338)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种使用标定板进行几何机器人标定的新方法，通过已知精确距离的测量点来确定系统误差参数，相比传统方法更经济、机械鲁棒且便携。


<details>
  <summary>Details</summary>
Motivation: 传统机器人标定方法如激光跟踪仪或运动捕捉系统成本高、设备笨重，需要开发更经济、机械鲁棒且便携的替代方案。

Method: 使用带有精确已知距离测量点的标定板，通过两点间的相对测量确定系统预定义误差参数，采用最小二乘法和约束优化问题进行参数识别。

Result: 实验验证了该方法的有效性，获得了与激光跟踪仪标定相关性的有希望结果，误差参数建模和识别针对龙门机器完成。

Conclusion: 该方法为机器人几何标定提供了经济、鲁棒且便携的替代方案，虽然针对龙门机器开发，但适用于其他类型机器人。

Abstract: In this paper a new method for geometric robot calibration is introduced,
which uses a calibration plate with precisely known distances between its
measuring points. The relative measurement between two points on the
calibration plate is used to determine predefined error parameters of the
system. In comparison to conventional measurement methods, like laser tracker
or motion capture systems, the calibration plate provides a more mechanically
robust and cheaper alternative, which is furthermore easier to transport due to
its small size. The calibration method, the plate design, the mathematical
description of the error system as well as the identification of the parameters
are described in detail. For identifying the error parameters, the least
squares method and a constrained optimization problem are used. The
functionality of this method was demonstrated in experiments that led to
promising results, correlated with one of a laser tracker calibration. The
modeling and identification of the error parameters is done for a gantry
machine, but is not restricted to that type of robot.

</details>


### [95] [Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods](https://arxiv.org/abs/2510.25386)
*Kumar Manas,Mert Keser,Alois Knoll*

Main category: cs.RO

TL;DR: 本调查分析了将法律和逻辑规范整合到自动驾驶系统感知、预测和规划模块中的方法，重点关注确保监管合规性和可解释性的技术，并提出了分类法来系统分析现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在动态和不确定的驾驶环境中面临感知可靠性、法律合规性和决策可辩护性之间的交叉挑战，需要确保技术稳健且法律上可辩护的决策。

Method: 引入分类法按理论基础、架构实现和验证策略对现有方法进行分类，涵盖神经符号集成方法、逻辑驱动规则表示和规范感知预测策略。

Result: 系统探索了从逻辑框架到计算法律推理方法的技术，强调它们在确保监管合规性和可解释性方面的能力。

Conclusion: 提出了关键开放问题和实际权衡，提供来自工程、逻辑和法律的多学科见解，以指导未来法律合规自动驾驶系统的发展。

Abstract: This survey provides an analysis of current methodologies integrating legal
and logical specifications into the perception, prediction, and planning
modules of automated driving systems. We systematically explore techniques
ranging from logic-based frameworks to computational legal reasoning
approaches, emphasizing their capability to ensure regulatory compliance and
interpretability in dynamic and uncertain driving environments. A central
finding is that significant challenges arise at the intersection of perceptual
reliability, legal compliance, and decision-making justifiability. To
systematically analyze these challenges, we introduce a taxonomy categorizing
existing approaches by their theoretical foundations, architectural
implementations, and validation strategies. We particularly focus on methods
that address perceptual uncertainty and incorporate explicit legal norms,
facilitating decisions that are both technically robust and legally defensible.
The review covers neural-symbolic integration methods for perception,
logic-driven rule representation, and norm-aware prediction strategies, all
contributing toward transparent and accountable autonomous vehicle operation.
We highlight critical open questions and practical trade-offs that must be
addressed, offering multidisciplinary insights from engineering, logic, and law
to guide future developments in legally compliant autonomous driving systems.

</details>


### [96] [Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning](https://arxiv.org/abs/2510.25405)
*Kei Ikemura,Yifei Dong,David Blanco-Mulero,Alberta Longhini,Li Chen,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的强化学习方法，通过应力惩罚奖励机制来防止易碎物体在机器人操作中受损，结合离线演示和渐进式课程学习，在仿真和真实环境中都实现了温和的物体操作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作易碎和可变形物体的方法依赖精确物体模型或专用传感器，复杂度高且泛化能力差。需要开发能避免物体损伤的通用解决方案。

Method: 使用视觉强化学习，引入应力惩罚奖励机制，结合离线演示和从刚性代理到可变形物体的渐进式课程学习。

Result: 仿真中学习的策略可以零样本迁移到真实世界，相比标准RL策略，施加在易碎物体上的应力减少了36.5%，同时完成拾取和推动豆腐等任务。

Conclusion: 该方法能够学习到损伤感知的温和操作行为，有效减少对易碎物体的应力，实现安全操作。

Abstract: Robotic manipulation of deformable and fragile objects presents significant
challenges, as excessive stress can lead to irreversible damage to the object.
While existing solutions rely on accurate object models or specialized sensors
and grippers, this adds complexity and often lacks generalization. To address
this problem, we present a vision-based reinforcement learning approach that
incorporates a stress-penalized reward to discourage damage to the object
explicitly. In addition, to bootstrap learning, we incorporate offline
demonstrations as well as a designed curriculum progressing from rigid proxies
to deformables. We evaluate the proposed method in both simulated and
real-world scenarios, showing that the policy learned in simulation can be
transferred to the real world in a zero-shot manner, performing tasks such as
picking up and pushing tofu. Our results show that the learned policies exhibit
a damage-aware, gentle manipulation behavior, demonstrating their effectiveness
by decreasing the stress applied to fragile objects by 36.5% while achieving
the task goals, compared to vanilla RL policies.

</details>


### [97] [Combining Moving Mass Actuators and Manoeuvring Models for Underwater Vehicles: A Lagrangian Approach](https://arxiv.org/abs/2510.25479)
*Alexander B. Rambech,Ivar B. Saksvik,Vahid Hassani*

Main category: cs.RO

TL;DR: 本文提出了带内部移动质量执行器的水下航行器的牛顿-欧拉运动方程，将移动质量动力学作为Fossen机动模型的扩展，并在仿真中验证了该模型与传统哈密顿方法的对比。


<details>
  <summary>Details</summary>
Motivation: 为水下航行器开发更准确的动力学模型，特别是针对带有内部移动质量执行器的情况，以改进传统建模方法。

Method: 使用牛顿-欧拉公式推导运动方程，将移动质量影响在体坐标系中描述，包括额外的运动学方程和耦合刚体动力学，基于基尔霍夫方程推导科里奥利-向心效应，使用基本原理推导流体静力学。

Result: 提出的牛顿-欧拉模型通过仿真验证，并与传统的哈密顿内部移动质量执行器公式进行了比较。

Conclusion: 所提出的牛顿-欧拉模型为带内部移动质量执行器的水下航行器提供了有效的动力学建模方法，验证了其与传统方法的一致性。

Abstract: In this paper, we present a Newton-Euler formulation of the equations of
motion for underwater vehicles with an interntal moving mass actuator.
Furthermore, the moving mass dynamics are expressed as an extension to the
manoeuvring model for underwater vehicles, originally introduced by Fossen
(1991). The influence of the moving mass is described in body-frame and
included as states in both an additional kinematic equation and as part of the
coupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal
effects are derived from Kirchhoff's equations and the hydrostatics are derived
using first principals. The proposed Newton-Euler model is validated through
simulation and compared with the traditional Hamiltonian internal moving mass
actuator formulation.

</details>


### [98] [Octopus-like Reaching Motion: A Perspective Inspired by Whipping](https://arxiv.org/abs/2510.25520)
*Shengyao Zhang,Yiyuan Zhang,Chenrui Zhang,Yiming Li,Wenci Xin,Yuliang Liufu,Hong Wei Ng,Cecilia Laschi*

Main category: cs.RO

TL;DR: 该研究通过在水中进行鞭状运动实验，发现Ecoflex Gel 2手臂在150rpm驱动下能重现章鱼触手弯曲传播的类似特征，但速度分布与生物运动不同，证明章鱼触手运动不是单纯的被动鞭打行为。


<details>
  <summary>Details</summary>
Motivation: 研究章鱼触手特征性弯曲传播是否与鞭子动力学有共同原理，以及能否通过水中被动鞭打动力学重现生物触手运动的运动学特征。

Method: 在水和空气中进行平台式鞭打测试，系统改变材料刚度和驱动速度，通过图像量化分析运动特征。

Result: Ecoflex Gel 2手臂在150rpm驱动下重现了类似章鱼触手的曲率传播，但弯曲点速度呈单调递减而非生物钟形分布；空气中无传播现象。

Conclusion: 章鱼触手运动不是单纯的被动鞭打行为，周围介质在形成章鱼式触手运动中起关键作用，为理解生物触手运动提供了新视角。

Abstract: The stereotypical reaching motion of the octopus arm has drawn growing
attention for its efficient control of a highly deformable body. Previous
studies suggest that its characteristic bend propagation may share underlying
principles with the dynamics of a whip. This work investigates whether
whip-like passive dynamics in water can reproduce the kinematic features
observed in biological reaching and their similarities and differences.
Platform-based whipping tests were performed in water and air while
systematically varying material stiffness and driving speed. Image-based
quantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor
speed) reproduced curvature propagation similar to that observed in octopus
reaching. However, its bend-point velocity decreased monotonically rather than
exhibiting the biological bell-shaped profile, confirming that the octopus
reaching movement is not merely a passive whipping behavior. The absence of
propagation in air further highlights the critical role of the surrounding
medium in forming octopus-like reaching motion. This study provides a new
perspective for understand biological reaching movement, and offers a potential
platform for future hydrodynamic research.

</details>


### [99] [Using VLM Reasoning to Constrain Task and Motion Planning](https://arxiv.org/abs/2510.25548)
*Muyang Yan,Miras Mengdibayev,Ardon Floros,Weihang Guo,Lydia E. Kavraki,Zachary Kingston*

Main category: cs.RO

TL;DR: VIZ-COAST利用预训练视觉语言模型的常识空间推理能力，在任务规划前识别向下细化问题，避免在规划过程中修复这些失败，显著减少规划时间。


<details>
  <summary>Details</summary>
Motivation: 在任务和运动规划中，任务级计划的可行性依赖于抽象世界向连续运动的向下细化能力。当领域细化能力较差时，看似有效的任务计划可能在运动规划阶段失败，需要重新规划，导致整体性能下降。

Method: 提出VIZ-COAST方法，利用大型预训练视觉语言模型的常识空间推理能力，在规划前识别向下细化问题，无需在规划过程中修复这些失败。

Result: 在两个具有挑战性的TAMP领域上的实验表明，该方法能够从图像和领域描述中提取合理的约束，大幅减少规划时间，在某些情况下完全消除向下细化失败，并能泛化到更广泛领域的多样化实例。

Conclusion: VIZ-COAST通过利用视觉语言模型的常识推理能力，在任务规划前识别潜在的向下细化问题，有效提高了任务和运动规划的效率与可靠性。

Abstract: In task and motion planning, high-level task planning is done over an
abstraction of the world to enable efficient search in long-horizon robotics
problems. However, the feasibility of these task-level plans relies on the
downward refinability of the abstraction into continuous motion. When a
domain's refinability is poor, task-level plans that appear valid may
ultimately fail during motion planning, requiring replanning and resulting in
slower overall performance. Prior works mitigate this by encoding refinement
issues as constraints to prune infeasible task plans. However, these approaches
only add constraints upon refinement failure, expending significant search
effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the
common-sense spatial reasoning of large pretrained Vision-Language Models to
identify issues with downward refinement a priori, bypassing the need to fix
these failures during planning. Experiments on two challenging TAMP domains
show that our approach is able to extract plausible constraints from images and
domain descriptions, drastically reducing planning times and, in some cases,
eliminating downward refinement failures altogether, generalizing to a diverse
range of instances from the broader domain.

</details>


### [100] [Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills](https://arxiv.org/abs/2510.25634)
*Weikang Wan,Fabio Ramos,Xuning Yang,Caelan Garrett*

Main category: cs.RO

TL;DR: 提出了一个分层框架，将长时程接触丰富的双手操作问题建模为技能规划与调度问题，支持并行技能执行，相比端到端强化学习和传统顺序规划器表现更优。


<details>
  <summary>Details</summary>
Motivation: 长时程接触丰富的双手操作需要复杂的协调，涉及并行执行和顺序协作的混合，现有方法难以有效处理这种复杂协调需求。

Method: 构建单臂和双手原始技能库（使用强化学习在GPU加速仿真中训练），然后训练基于Transformer的规划器作为高级调度器，同时预测离散技能调度和连续参数。

Result: 在复杂接触丰富的任务上比端到端强化学习方法获得更高的成功率，比传统顺序规划器产生更高效、协调的行为。

Conclusion: 分层框架通过集成技能规划与调度，有效解决了长时程双手操作的复杂协调问题，展示了比现有方法更好的性能。

Abstract: Long-horizon contact-rich bimanual manipulation presents a significant
challenge, requiring complex coordination involving a mixture of parallel
execution and sequential collaboration between arms. In this paper, we
introduce a hierarchical framework that frames this challenge as an integrated
skill planning & scheduling problem, going beyond purely sequential
decision-making to support simultaneous skill invocation. Our approach is built
upon a library of single-arm and bimanual primitive skills, each trained using
Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a
Transformer-based planner on a dataset of skill compositions to act as a
high-level scheduler, simultaneously predicting the discrete schedule of skills
as well as their continuous parameters. We demonstrate that our method achieves
higher success rates on complex, contact-rich tasks than end-to-end RL
approaches and produces more efficient, coordinated behaviors than traditional
sequential-only planners.

</details>


### [101] [Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics](https://arxiv.org/abs/2510.25650)
*Ahmad Kokhahi,Mary Kurz*

Main category: cs.RO

TL;DR: 该论文提出了一种考虑能耗的AGV多智能体路径规划方法，包含碰撞避免策略和任务分配算法，在性能和能耗方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF研究主要关注碰撞避免和旅行时间最小化，但忽略了能量消耗问题。该论文旨在解决AGV路径规划中的能量消耗问题，同时处理碰撞避免和任务分配两个关键挑战。

Method: 提出新的碰撞避免策略，同时考虑能量使用和旅行时间；提出两种多目标算法用于任务分配：非支配排序遗传算法(NSGA)和自适应大邻域搜索(ALNS)。

Result: 比较评估表明，所提出的方法在碰撞避免和任务分配方面都优于现有方法。

Conclusion: 该研究成功地将能量消耗纳入AGV路径规划考虑因素，提出的碰撞避免策略和多目标算法在性能和能耗方面都表现出色。

Abstract: Multi-Agent Path Finding (MAPF) has gained significant attention, with most
research focusing on minimizing collisions and travel time. This paper also
considers energy consumption in the path planning of automated guided vehicles
(AGVs). It addresses two main challenges: i) resolving collisions between AGVs
and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy
that takes both energy use and travel time into account. For task assignment,
we present two multi-objective algorithms: Non-Dominated Sorting Genetic
Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative
evaluations show that these proposed methods perform better than existing
approaches in both collision avoidance and task assignment.

</details>


### [102] [Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models](https://arxiv.org/abs/2510.25713)
*Boshi An,Chenyu Yang,Robert Katzschmann*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for
dexterous human-robot collaboration with minimal language prompting. Our
approach adds (i) FiLM conditioning to visual backbones for task-aware
perception, (ii) an auxiliary intent head that predicts collaborator hand pose
and target cues, and (iii) action-space post-processing that predicts compact
deltas (position/rotation) and PCA-reduced finger joints before mapping to full
commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset
augmented with MediaPipe hand poses, we demonstrate that delta actions are
well-behaved and that four principal components explain ~96% of hand-joint
variance. Ablations identify action post-processing as the primary performance
driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is
detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes
"pick-up" and "pass" into a long-horizon behavior. We surface "trainer
overfitting" to specific demonstrators as the key limitation.

</details>


### [103] [A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation](https://arxiv.org/abs/2510.25725)
*Eunju Kwon,Seungwon Oh,In-Chang Baek,Yucheon Park,Gyungbo Kim,JaeYoung Moon,Yunho Choi,Kyung-Joong Kim*

Main category: cs.RO

TL;DR: 提出了一个用于操作可变形软物体的人形视觉-触觉-动作数据集，填补了机器人学习数据集中对压力条件多样性表征不足的空白。


<details>
  <summary>Details</summary>
Motivation: 机器人学习数据集先前主要关注刚性物体，未能充分体现真实世界操作中压力条件的多样性，特别是在操作可变形软物体时。

Method: 通过远程操作配备灵巧手的人形机器人收集数据，捕捉不同压力条件下的多模态交互。

Result: 成功构建了一个包含视觉、触觉和动作信息的人形机器人数据集，专门针对可变形软物体的操作。

Conclusion: 这项工作为未来研究提供了基础，激励开发能够有效利用触觉信号复杂性和多样性的先进优化策略模型。

Abstract: Contact-rich manipulation has become increasingly important in robot
learning. However, previous studies on robot learning datasets have focused on
rigid objects and underrepresented the diversity of pressure conditions for
real-world manipulation. To address this gap, we present a humanoid
visual-tactile-action dataset designed for manipulating deformable soft
objects. The dataset was collected via teleoperation using a humanoid robot
equipped with dexterous hands, capturing multi-modal interactions under varying
pressure conditions. This work also motivates future research on models with
advanced optimization strategies capable of effectively leveraging the
complexity and diversity of tactile signals.

</details>


### [104] [Modeling Collapse of Steered Vine Robots Under Their Own Weight](https://arxiv.org/abs/2510.25727)
*Ciera McFarland,Margaret McGuinness*

Main category: cs.RO

TL;DR: 提出了一个预测软体生长机器人塌陷长度的综合模型，该模型使用真实形状信息和尾部张力来预测任何形状的转向机器人的塌陷行为。


<details>
  <summary>Details</summary>
Motivation: 软体生长机器人在受限环境中具有高机动性，但在面对环境间隙时可能因自身重量而塌陷，需要预测和控制塌陷行为。

Method: 开发了一个塌陷模型，使用真实形状信息和尾部张力来预测塌陷长度，并通过实验验证模型准确性，包括未转向机器人和单执行器转向机器人的测试。

Result: 模型准确预测了实验中的塌陷趋势，能够预测转向机器人的塌陷发生，并成功应用于间隙跨越任务中。

Conclusion: 该模型能够在任何开放环境中模拟机器人的塌陷行为，帮助理解3D导航任务中所需的参数，为软体机器人的可靠导航提供了理论基础。

Abstract: Soft, vine-inspired growing robots that move by eversion are highly mobile in
confined environments, but, when faced with gaps in the environment, they may
collapse under their own weight while navigating a desired path. In this work,
we present a comprehensive collapse model that can predict the collapse length
of steered robots in any shape using true shape information and tail tension.
We validate this model by collapsing several unsteered robots without true
shape information. The model accurately predicts the trends of those
experiments. We then attempt to collapse a robot steered with a single actuator
at different orientations. Our models accurately predict collapse when it
occurs. Finally, we demonstrate how this could be used in the field by having a
robot attempt a gap-crossing task with and without inflating its actuators. The
robot needs its actuators inflated to cross the gap without collapsing, which
our model supports. Our model has been specifically tested on straight and
series pouch motor-actuated robots made of non-stretchable material, but it
could be applied to other robot variations. This work enables us to model the
robot's collapse behavior in any open environment and understand the parameters
it needs to succeed in 3D navigation tasks.

</details>


### [105] [GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions](https://arxiv.org/abs/2510.25754)
*Bohan Wu,Paul de La Sayette,Li Fei-Fei,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: GeT-USE是一个两阶段方法，通过在模拟中学习机器人身体扩展来识别对任务最有利的工具几何形状，然后将这些知识迁移到真实机器人的视觉运动策略中，实现通用工具使用。


<details>
  <summary>Details</summary>
Motivation: 当前机器人工具使用方法局限于单一对象假设，无法从多个可用对象中选择最佳工具，特别是在最优工具缺失时。需要提升机器人在通用工具使用方面的智能和问题解决能力。

Method: 采用两阶段方法：1）在模拟中学习机器人身体扩展，识别对任务最有利的工具几何形状；2）将学到的几何知识迁移到真实机器人的视觉运动策略中，选择和使用最佳可用对象作为工具。

Result: 在具有22个自由度的真实机器人上，GeT-USE在三个基于视觉的双手机器人移动操作工具使用任务中，比现有最优方法的成功率高出30-60%。

Conclusion: 通过在模拟中学习身体扩展来获取几何知识，然后迁移到真实机器人，可以有效实现通用工具使用，显著提升机器人的工具使用能力。

Abstract: The ability to use random objects as tools in a generalizable manner is a
missing piece in robots' intelligence today to boost their versatility and
problem-solving capabilities. State-of-the-art robotic tool usage methods
focused on procedurally generating or crowd-sourcing datasets of tools for a
task to learn how to grasp and manipulate them for that task. However, these
methods assume that only one object is provided and that it is possible, with
the correct grasp, to perform the task; they are not capable of identifying,
grasping, and using the best object for a task when many are available,
especially when the optimal tool is absent. In this work, we propose GeT-USE, a
two-step procedure that learns to perform real-robot generalized tool usage by
learning first to extend the robot's embodiment in simulation and then
transferring the learned strategies to real-robot visuomotor policies. Our key
insight is that by exploring a robot's embodiment extensions (i.e., building
new end-effectors) in simulation, the robot can identify the general tool
geometries most beneficial for a task. This learned geometric knowledge can
then be distilled to perform generalized tool usage tasks by selecting and
using the best available real-world object as tool. On a real robot with 22
degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by
30-60% success rates across three vision-based bimanual mobile manipulation
tool-usage tasks.

</details>


### [106] [STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and Thread Management](https://arxiv.org/abs/2510.25768)
*Kush Hari,Ziyang Chen,Hansoul Kim,Ken Goldberg*

Main category: cs.RO

TL;DR: STITCH 2.0是一个改进的机器人缝合系统，通过改进针位估计、线缆解缠和自动缝合对齐算法，显著提升了伤口闭合效果和缝合效率。


<details>
  <summary>Details</summary>
Motivation: 外科缝合技能在医生间差异很大，需要机器人辅助。之前的机器人缝合系统如STITCH 1.0由于针位跟踪不准确和线缆管理不佳，难以完全闭合伤口。

Method: 提出了STITCH 2.0增强灵巧性管道，包含七个改进：改进的EKF针位估计、新的线缆解缠方法和自动3D缝合对齐算法。

Result: 在15次试验中，STITCH 2.0平均实现74.4%伤口闭合，每次试验4.87针缝合，相比基线缝合数量增加66%，时间减少38%。允许两次人工干预时，平均6针缝合，100%伤口闭合率。

Conclusion: STITCH 2.0显著提升了机器人缝合性能，在伤口闭合和缝合效率方面都有明显改进。

Abstract: Surgical suturing is a high-precision task that impacts patient healing and
scarring. Suturing skill varies widely between surgeons, highlighting the need
for robot assistance. Previous robot suturing works, such as STITCH 1.0 [1],
struggle to fully close wounds due to inaccurate needle tracking and poor
thread management. To address these challenges, we present STITCH 2.0, an
elevated augmented dexterity pipeline with seven improvements including:
improved EKF needle pose estimation, new thread untangling methods, and an
automated 3D suture alignment algorithm. Experimental results over 15 trials
find that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures
per trial, representing 66% more sutures in 38% less time compared to the
previous baseline. When two human interventions are allowed, STITCH 2.0
averages six sutures with 100% wound closure rate. Project website:
https://stitch-2.github.io/

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [107] [Exponential Dynamic Energy Network for High Capacity Sequence Memory](https://arxiv.org/abs/2510.24965)
*Arjun Karuvally,Pichsinee Lertsaroj,Terrence J. Sejnowski,Hava T. Siegelmann*

Main category: cs.NE

TL;DR: 提出了EDEN网络，将能量范式扩展到时序领域，通过多时间尺度演化能量函数，实现了指数级的序列记忆容量。


<details>
  <summary>Details</summary>
Motivation: 传统Hopfield网络等能量模型虽然为神经系统的记忆提供了原则性框架，但在建模序列记忆方面存在不足，无法有效处理记忆间的转换。

Method: 结合静态高容量能量网络与缓慢不对称交互的调节群体，构建多时间尺度动态能量函数，分析计算记忆逃逸时间。

Result: EDEN实现了指数序列记忆容量O(γ^N)，优于传统模型的线性容量O(N)，其动态特性与人类大脑在情景记忆任务中观察到的时序细胞活动相似。

Conclusion: EDEN在动态能量框架下统一了静态和序列记忆，为人工和生物系统提供了可扩展且可解释的高容量时序记忆模型。

Abstract: The energy paradigm, exemplified by Hopfield networks, offers a principled
framework for memory in neural systems by interpreting dynamics as descent on
an energy surface. While powerful for static associative memories, it falls
short in modeling sequential memory, where transitions between memories are
essential. We introduce the Exponential Dynamic Energy Network (EDEN), a novel
architecture that extends the energy paradigm to temporal domains by evolving
the energy function over multiple timescales. EDEN combines a static
high-capacity energy network with a slow, asymmetrically interacting modulatory
population, enabling robust and controlled memory transitions. We formally
derive short-timescale energy functions that govern local dynamics and use them
to analytically compute memory escape times, revealing a phase transition
between static and dynamic regimes. The analysis of capacity, defined as the
number of memories that can be stored with minimal error rate as a function of
the dimensions of the state space (number of feature neurons), for EDEN shows
that it achieves exponential sequence memory capacity $O(\gamma^N)$,
outperforming the linear capacity $O(N)$ of conventional models. Furthermore,
EDEN's dynamics resemble the activity of time and ramping cells observed in the
human brain during episodic memory tasks, grounding its biological relevance.
By unifying static and sequential memory within a dynamic energy framework,
EDEN offers a scalable and interpretable model for high-capacity temporal
memory in both artificial and biological systems.

</details>


### [108] [Maximum-Entropy Analog Computing Approaching ExaOPS-per-Watt Energy-efficiency at the RF-Edge](https://arxiv.org/abs/2510.24975)
*Aswin Undavalli,Kareem Rashed,Zhili Xiao,Arun Natarajan,Shantanu Chakrabartty,Aravind Nagulu*

Main category: cs.NE

TL;DR: 该论文提出了一种基于熵产生物理和对称约束的高性能、高能效模拟计算系统框架，通过最大熵原理实现相关性和内积计算，并在22nm SOI CMOS工艺中验证了超过2 PetaOPS/W的计算效率。


<details>
  <summary>Details</summary>
Motivation: 结合熵产生物理和对称约束，实现高性能和能源效率的模拟计算系统，特别是在射频边缘计算应用中。

Method: 使用广义最大熵原理描述介观物理系统的演化，通过最大熵状态（对应边缘传播分布）计算相关性和内积，并扩展到非平衡或瞬态操作条件。

Result: 在22nm SOI CMOS工艺中实现的射频相关器集成电路，在8位精度下计算效率超过2 PetaOPS/W，在3位精度下超过0.8 ExaOPS/W，采样率大于4 GS/s。

Conclusion: 该框架能够显著提升计算吞吐量和能效，成功展示了在边缘射频应用中的实际用途，如频谱感知和码域通信。

Abstract: In this paper, we demonstrate how the physics of entropy production, when
combined with symmetry constraints, can be used for implementing
high-performance and energy-efficient analog computing systems. At the core of
the proposed framework is a generalized maximum-entropy principle that can
describe the evolution of a mesoscopic physical system formed by an
interconnected ensemble of analog elements, including devices that can be
readily fabricated on standard integrated circuit technology. We show that the
maximum-entropy state of this ensemble corresponds to a margin-propagation (MP)
distribution and can be used for computing correlations and inner products as
the ensemble's macroscopic properties. Furthermore, the limits of computational
throughput and energy efficiency can be pushed by extending the framework to
non-equilibrium or transient operating conditions, which we demonstrate using a
proof-of-concept radio-frequency (RF) correlator integrated circuit fabricated
in a 22 nm SOI CMOS process. The measured results show a compute efficiency
greater than 2 Peta ($10^{15}$) Bit Operations per second per Watt (PetaOPS/W)
at 8-bit precision and greater than 0.8 Exa ($10^{18}$) Bit Operations per
second per Watt (ExaOPS/W) at 3-bit precision for RF data sampled at rates
greater than 4 GS/s. Using the fabricated prototypes, we also showcase several
real-world RF applications at the edge, including spectrum sensing, and
code-domain communications.

</details>


### [109] [Socio-cognitive agent-oriented evolutionary algorithm with trust-based optimization](https://arxiv.org/abs/2510.25095)
*Aleksandra Urbańczyk,Krzysztof Czech,Piotr Urbańczyk,Marek Kisiel-Dorohinicki,Aleksander Byrski*

Main category: cs.NE

TL;DR: 提出基于信任的优化(TBO)，用信任机制替代传统周期性迁移的岛模型进化算法，在多种优化问题上表现优于标准算法。


<details>
  <summary>Details</summary>
Motivation: 传统岛模型使用固定的周期性迁移策略，缺乏灵活性。希望通过引入信任或声誉机制，实现更自适应、智能的个体交互。

Method: 开发基于信任的优化(TBO)方法，用agent驱动的信任机制替代传统周期性迁移，允许个体根据信任度自主决定交互时机和对象。

Result: TBO在大多数优化问题上优于标准岛模型算法，但性能因问题类型而异，某些配置对特定问题类型或维度更有效。

Conclusion: 信任和声誉机制为进化优化提供了灵活自适应的方法，在多数情况下能提高解的质量。

Abstract: This paper introduces the Trust-Based Optimization (TBO), a novel extension
of the island model in evolutionary computation that replaces conventional
periodic migrations with a flexible, agent-driven interaction mechanism based
on trust or reputation. Experimental results demonstrate that TBO generally
outperforms the standard island model evolutionary algorithm across various
optimization problems. Nevertheless, algorithm performance varies depending on
the problem type, with certain configurations being more effective for specific
landscapes or dimensions. The findings suggest that trust and reputation
mechanisms provide a flexible and adaptive approach to evolutionary
optimization, improving solution quality in many cases.

</details>


### [110] [A Benchmark Suite for Multi-Objective Optimization in Battery Thermal Management System Design](https://arxiv.org/abs/2510.25219)
*Kaichen Ouyang,Yezhi Xia*

Main category: cs.NE

TL;DR: 开发了一个专门用于电池热管理系统设计的约束多目标优化基准测试套件，包含基于精确代理模型的实际工程问题


<details>
  <summary>Details</summary>
Motivation: 现有的合成基准问题存在不切实际的特性，可能导致算法性能评估不准确，而实际工程应用特别是电池热管理领域缺乏相关基准测试

Method: 基于近期研究开发精确的代理模型来表示复杂的热流体相互作用，构建包含多样化实际约束问题的基准套件

Result: 成功开发了专门用于电池热管理系统多目标优化的基准测试套件

Conclusion: 该基准套件为进化算法和优化方法提供了实用且相关的测试平台，未来将建立基准结果并进行比较分析

Abstract: Synthetic Benchmark Problems (SBPs) are commonly used to evaluate the
performance of metaheuristic algorithms. However, these SBPs often contain
various unrealistic properties, potentially leading to underestimation or
overestimation of algorithmic performance. While several benchmark suites
comprising real-world problems have been proposed for various types of
metaheuristics, a notable gap exists for Constrained Multi-objective
Optimization Problems (CMOPs) derived from practical engineering applications,
particularly in the domain of Battery Thermal Management System (BTMS) design.
To address this gap, this study develops and presents a specialized benchmark
suite for multi-objective optimization in BTMS. This suite comprises a diverse
collection of real-world constrained problems, each defined via accurate
surrogate models based on recent research to efficiently represent complex
thermal-fluid interactions. The primary goal of this benchmark suite is to
provide a practical and relevant testing ground for evolutionary algorithms and
optimization methods focused on energy storage thermal management. Future work
will involve establishing comprehensive baseline results using state-of-the-art
algorithms, conducting comparative analyses, and developing a standardized
ranking scheme to facilitate robust performance assessment.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [111] [Comparative Analysis of Procedural Planet Generators](https://arxiv.org/abs/2510.24764)
*Manuel Zechmann,Helmut Hlavacs*

Main category: cs.GR

TL;DR: 开发了两种实时程序化行星生成器：一种使用分形布朗运动与柏林噪声，另一种采用类似Minecraft的分层噪声技术，并进行了用户比较研究。


<details>
  <summary>Details</summary>
Motivation: 探索不同的程序化行星生成技术，比较它们在实时环境中的表现和用户体验。

Method: 在Godot引擎中实现两种算法：FBM+Perlin噪声方法和Minecraft风格分层噪声方法，使用四叉树LOD系统和行星网格生成解决方案。

Result: 进行了用户研究（N=15），参与者探索了两种算法生成的独特实例，并与现有程序化行星项目进行比较。

Conclusion: 论文展示了两种不同的实时程序化行星生成方法的实现和比较结果。

Abstract: This paper presents the development of two distinct real-time procedural
planet generators within the Godot engine: one employing Fractal Brownian
Motion (FBM) with Perlin Noise, and another adapting Minecraft-inspired layered
noise techniques. We detail their implementation, including a quadtree-based
Level of Detail (LOD) system and solutions for planetary mesh generation. A
comparative user study (N=15) was conducted where participants explored unique
instances generated by our two algorithms alongside two existing procedural
planet projects.

</details>


### [112] [Off-Centered WoS-Type Solvers with Statistical Weighting](https://arxiv.org/abs/2510.25152)
*Anchang Bao,Jie Xu,Enya Shen,Jianmin Wang*

Main category: cs.GR

TL;DR: 提出了一种统计加权的非中心WoS型估计器，通过局部相似性过滤选择性地组合相邻评估点的样本，在偏差和方差之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 随机PDE求解器在几何处理和图形学中表现出强大潜力，但现有的非中心估计器在近似格林函数时会产生相关性伪影和偏差。

Method: 使用局部相似性过滤和原则性加权策略，选择性地组合相邻评估点的样本，抑制不可靠的估计器。

Result: 在各种PDE（包括筛选泊松方程和边界条件）上展示出有效性，相比传统方法（vanilla Walk on Spheres、均值缓存、边界值缓存）有持续改进。

Conclusion: 该方法能有效平衡偏差和方差，并自然扩展到梯度场估计和混合边界问题。

Abstract: Stochastic PDE solvers have emerged as a powerful alternative to traditional
discretization-based methods for solving partial differential equations (PDEs),
especially in geometry processing and graphics. While off-centered estimators
enhance sample reuse in WoS-type Monte Carlo solvers, they introduce
correlation artifacts and bias when Green's functions are approximated. In this
paper, we propose a statistically weighted off-centered WoS-type estimator that
leverages local similarity filtering to selectively combine samples across
neighboring evaluation points. Our method balances bias and variance through a
principled weighting strategy that suppresses unreliable estimators. We
demonstrate our approach's effectiveness on various PDEs,including screened
Poisson equations and boundary conditions, achieving consistent improvements
over existing solvers such as vanilla Walk on Spheres, mean value caching, and
boundary value caching. Our method also naturally extends to gradient field
estimation and mixed boundary problems.

</details>


### [113] [Fast and Robust Point Containment Queries on Trimmed Surface](https://arxiv.org/abs/2510.25159)
*Anchang Bao,Enya Shen,Jianmin Wang*

Main category: cs.GR

TL;DR: 提出了一种快速稳定的修剪曲面点包含查询方法，通过递归环绕数计算和椭圆边界技术提高效率，支持周期性参数化曲面。


<details>
  <summary>Details</summary>
Motivation: 现有方法如光线投射和广义环绕数在鲁棒性和计算效率方面存在局限，特别是在处理修剪曲面时。

Method: 采用递归环绕数计算方案，用基于椭圆边界的贝塞尔段替代昂贵的曲线细分，实现线性时间评估。对于周期性曲面，将修剪曲线提升到通用覆盖空间。

Result: 实验显示相比现有环绕数算法获得显著加速，在几何噪声、开放边界和周期性拓扑情况下保持高鲁棒性。

Conclusion: 该方法在B-Rep模型处理和修剪曲面鲁棒细分中表现出有效性，为CAD建模和几何处理提供了高效解决方案。

Abstract: Point containment queries on trimmed surfaces are fundamental to CAD
modeling, solid geometry processing, and surface tessellation. Existing
approaches such as ray casting and generalized winding numbers often face
limitations in robustness and computational efficiency.
  We propose a fast and numerically stable method for performing containment
queries on trimmed surfaces, including those with periodic parameterizations.
Our approach introduces a recursive winding number computation scheme that
replaces costly curve subdivision with an ellipse-based bound for Bezier
segments, enabling linear-time evaluation. For periodic surfaces, we lift
trimming curves to the universal covering space, allowing accurate and
consistent winding number computation even for non-contractible or
discontinuous loops in parameter domain.
  Experiments show that our method achieves substantial speedups over existing
winding-number algorithms while maintaining high robustness in the presence of
geometric noise, open boundaries, and periodic topologies. We further
demonstrate its effectiveness in processing real B-Rep models and in robust
tessellation of trimmed surfaces.

</details>


### [114] [4-Doodle: Text to 3D Sketches that Move!](https://arxiv.org/abs/2510.25319)
*Hao Chen,Jiaqi Wang,Yonggang Qi,Ke Li,Kaiyue Pang,Yi-Zhe Song*

Main category: cs.GR

TL;DR: 提出4-Doodle框架，首个无需训练即可从文本生成动态3D草图动画的方法，通过双空间蒸馏方案解决多视角一致性和时间连贯性问题。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注逼真内容生成，而轻量级、可解释的3D矢量草图更适合视觉传达和原型设计，但缺乏文本到3D草图动画的解决方案。

Method: 利用预训练图像和视频扩散模型，采用双空间蒸馏：一个空间使用可微分贝塞尔曲线捕获多视角一致几何，另一个通过时间感知先验编码运动动态。

Result: 实验表明该方法能生成时间真实、结构稳定的3D草图动画，在保真度和可控性方面优于现有基线方法。

Conclusion: 这项工作为实现更直观、易访问的4D内容创作迈出了重要一步。

Abstract: We present a novel task: text-to-3D sketch animation, which aims to bring
freeform sketches to life in dynamic 3D space. Unlike prior works focused on
photorealistic content generation, we target sparse, stylized, and
view-consistent 3D vector sketches, a lightweight and interpretable medium
well-suited for visual communication and prototyping. However, this task is
very challenging: (i) no paired dataset exists for text and 3D (or 4D)
sketches; (ii) sketches require structural abstraction that is difficult to
model with conventional 3D representations like NeRFs or point clouds; and
(iii) animating such sketches demands temporal coherence and multi-view
consistency, which current pipelines do not address. Therefore, we propose
4-Doodle, the first training-free framework for generating dynamic 3D sketches
from text. It leverages pretrained image and video diffusion models through a
dual-space distillation scheme: one space captures multi-view-consistent
geometry using differentiable B\'ezier curves, while the other encodes motion
dynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion),
which optimizes from a single view per step, our multi-view optimization
ensures structural alignment and avoids view ambiguity, critical for sparse
sketches. Furthermore, we introduce a structure-aware motion module that
separates shape-preserving trajectories from deformation-aware changes,
enabling expressive motion such as flipping, rotation, and articulated
movement. Extensive experiments show that our method produces temporally
realistic and structurally stable 3D sketch animations, outperforming existing
baselines in both fidelity and controllability. We hope this work serves as a
step toward more intuitive and accessible 4D content creation.

</details>


### [115] [mitransient: Transient light transport in Mitsuba 3](https://arxiv.org/abs/2510.25660)
*Diego Royo,Jorge Garcia-Pueyo,Miguel Crespo,Óscar Pueyo-Ciutad,Guillermo Enguita,Diego Bielsa*

Main category: cs.GR

TL;DR: mitransient是一个基于Mitsuba 3的光传输模拟工具，支持时间分辨模拟，扩展了传统渲染的时间维度，能够快速原型化瞬态成像系统。


<details>
  <summary>Details</summary>
Motivation: 开发一个无需昂贵或难以操作硬件的瞬态成像系统原型工具，支持瞬态成像算法研究。

Method: 扩展Mitsuba 3，添加时间维度来考虑光的飞行时间，提供Python模块支持CPU和GPU运行，包含物理基础模拟、材料、参与介质、时间分辨偏振跟踪和瞬态可微分渲染。

Result: 开发出易于安装的mitransient工具，能够快速模拟复杂现象，包括非视距成像，在几秒到几分钟内完成真实场景设置。

Conclusion: mitransient有望支持研究社区开发新的瞬态成像算法。

Abstract: mitransient is a light transport simulation tool that extends Mitsuba 3 with
support for time-resolved simulations. In essence, mitransient extends
conventional rendering by adding a temporal dimension which accounts for the
time of flight of light. This allows rapid prototyping of novel transient
imaging systems without the need of costly or difficult-to-operate hardware.
Our code is trivially easy to install through pip, and consists of Python
modules that can run both in CPU and GPU by leveraging the JIT capabilities of
Mitsuba 3. It provides physically-based simulations of complex phenomena,
including a wide variety of realistic materials and participating media such as
fog or smoke. In addition, we extend Mitsuba 3's functionality to support
time-resolved polarization tracking of light and transient differentiable
rendering. Finally, we also include tools that simplify the use of our
simulations for non-line-of-sight imaging, enabling realistic scene setups with
capture noise to be simulated in just seconds of minutes. Altogether, we hope
that mitransient will support the research community in developing novel
algorithms for transient imaging.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [116] [From Narrative to Action: A Hierarchical LLM-Agent Framework for Human Mobility Generation](https://arxiv.org/abs/2510.24802)
*Qiumeng Li,Chunhou Ji,Xinyue Liu*

Main category: cs.MA

TL;DR: 提出了一个分层LLM智能体框架，将高层次叙事推理、中层反思规划和低层行为执行整合到统一的认知层次结构中，用于生成具有语义一致性和因果逻辑的人类移动行为。


<details>
  <summary>Details</summary>
Motivation: 传统基于智能体或深度学习模型能够重现移动的统计模式，但无法捕捉人类行为的语义一致性和因果逻辑。大语言模型虽有潜力，但难以平衡创造性推理与严格结构合规性。

Method: 采用分层LLM智能体框架：宏观层面使用"创意写手"生成日记式叙事，"结构解析器"将叙事转换为机器可读计划；微观层面通过环境模拟执行具体行动；引入基于职业的移动熵指标指导行为调整。

Result: 该框架不仅生成与真实世界模式高度一致的合成轨迹，还提供人类决策逻辑的可解释表示。

Conclusion: 这项研究将合成移动生成从数据驱动范式推进到认知驱动模拟，通过分层LLM智能体为理解、预测和合成复杂城市移动行为提供了可扩展路径。

Abstract: Understanding and replicating human mobility requires not only
spatial-temporal accuracy but also an awareness of the cognitive hierarchy
underlying real-world travel decisions. Traditional agent-based or deep
learning models can reproduce statistical patterns of movement but fail to
capture the semantic coherence and causal logic of human behavior. Large
language models (LLMs) show potential, but struggle to balance creative
reasoning with strict structural compliance. This study proposes a Hierarchical
LLM-Agent Framework, termed Narrative-to-Action, that integrates high-level
narrative reasoning, mid-level reflective planning, and low-level behavioral
execution within a unified cognitive hierarchy. At the macro level, one agent
is employed as a "creative writer" to produce diary-style narratives rich in
motivation and context, then uses another agent as a "structural parser" to
convert narratives into machine-readable plans. A dynamic execution module
further grounds agents in geographic environments and enables adaptive
behavioral adjustments guided by a novel occupation-aware metric, Mobility
Entropy by Occupation (MEO), which captures heterogeneous schedule flexibility
across different occupational personalities. At the micro level, the agent
executes concrete actions-selecting locations, transportation modes, and time
intervals-through interaction with an environmental simulation. By embedding
this multi-layer cognitive process, the framework produces not only synthetic
trajectories that align closely with real-world patterns but also interpretable
representations of human decision logic. This research advances synthetic
mobility generation from a data-driven paradigm to a cognition-driven
simulation, providing a scalable pathway for understanding, predicting, and
synthesizing complex urban mobility behaviors through hierarchical LLM agents.

</details>


### [117] [MASPRM: Multi-Agent System Process Reward Model](https://arxiv.org/abs/2510.24803)
*Milad Yazdani,Mahdi Mostajabdaveh,Zirui Zhou,Ying Xiong*

Main category: cs.MA

TL;DR: 提出了MASPRM（多智能体系统过程奖励模型），通过训练过程奖励模型来指导推理时的搜索过程，提升多智能体系统的性能表现。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在实际部署中需要强大的测试时性能，需要能够指导推理时搜索并选择性分配计算资源的方法。

Method: MASPRM为部分智能体交互记录分配每个动作、每个智能体的价值，作为推理时控制器。通过多智能体蒙特卡洛树搜索（MCTS）的rollouts进行训练，无需步骤级人工标注，通过将回报传播到局部目标。在推理时，MASPRM指导步骤级束搜索和MCTS，将计算集中在有希望的路径上并及早剪枝。

Result: 在GSM8K和MATH数据集上，使用结果奖励模型（ORM）指导的MASPRM解码相比单次直接通过的多智能体系统，准确匹配率分别提升了30.7和22.9个百分点。在GSM8K上训练的MASPRM无需重新训练即可零样本迁移到MATH，在相同计算预算下增加8.4个准确匹配点。

Conclusion: MASPRM是一个插件式价值模型，能够估计每个智能体的进展，并补充验证器式解码器，实现更可靠、计算感知的多智能体推理。

Abstract: Practical deployment of Multi-Agent Systems (MAS) demands strong test-time
performance, motivating methods that guide inference-time search and
selectively spend compute to improve quality. We present the Multi-Agent System
Process Reward Model (MASPRM). It assigns per-action, per-agent values to
partial inter-agent transcripts and acts as an inference-time controller.
MASPRM is trained from multi-agent Monte Carlo Tree Search (MCTS) rollouts
without requiring step-level human annotations, by propagating returns to local
targets. At inference, MASPRM guides step-level beam search and MCTS, focusing
computation on promising branches and pruning early. On GSM8K and MATH,
MASPRM-guided decoding with an outcome reward model (ORM) applied to the final
answer, improves exact match (EM) over a single straight-through MAS pass by
$+30.7$ and $+22.9$ points, respectively. A MASPRM trained on GSM8K transfers
zero-shot to MATH without retraining, adding $8.4$ EM points at the same
budget. MASPRM is a plug-in value model that estimates per-agent progress and
complements verifier-style decoders, enabling more reliable, compute-aware
multi-agent reasoning. Code: https://github.com/milad1378yz/MASPRM

</details>


### [118] [Trust Dynamics in Strategic Coopetition: Computational Foundations for Requirements Engineering in Multi-Agent Systems](https://arxiv.org/abs/2510.24909)
*Vik Pant,Eric Yu*

Main category: cs.MA

TL;DR: 该技术报告开发了一个计算信任模型，将战略竞合的游戏理论基础与动态信任演化相结合，填补了需求工程中概念模型与计算信任模型之间的空白。


<details>
  <summary>Details</summary>
Motivation: 需求工程越来越多地在多利益相关者环境中进行，组织间同时合作与竞争，形成竞合关系。现有概念建模语言如i*只能定性表示信任关系，而多智能体系统中的计算信任模型缺乏在需求工程背景和概念模型中的基础。

Method: 引入信任作为双层系统：即时信任响应当前行为，声誉跟踪违规历史。通过非对称更新机制，合作逐步建立信任，而违规则急剧削弱信任，产生滞后效应和信任上限。开发结构化转换框架，使需求工程师能够从i*依赖网络和组织背景实例化计算信任模型。

Result: 在78,125个参数配置上的全面实验验证显示，负面偏见、滞后效应和累积损害放大的稳健出现。使用雷诺-日产联盟案例研究（1999-2025）的实证验证达到60个验证点中的49个（81.7%），成功再现了五个不同关系阶段（包括危机和恢复期）的信任演化。

Conclusion: 该研究成功开发了连接概念建模与计算信任分析的计算信任模型，为需求工程中的动态信任演化提供了理论基础和实用工具，能够准确捕捉竞合关系中信任的复杂动态特性。

Abstract: Requirements engineering increasingly occurs in multi-stakeholder
environments where organizations simultaneously cooperate and compete, creating
coopetitive relationships in which trust evolves dynamically based on observed
behavior over repeated interactions. While conceptual modeling languages like
i* represent trust relationships qualitatively, they lack computational
mechanisms for analyzing how trust changes with behavioral evidence.
Conversely, computational trust models from multi-agent systems provide
algorithmic updating but lack grounding in requirements engineering contexts
and conceptual models. This technical report bridges this gap by developing a
computational trust model that extends game-theoretic foundations for strategic
coopetition with dynamic trust evolution. We introduce trust as a two-layer
system with immediate trust responding to current behavior and reputation
tracking violation history. Trust evolves through asymmetric updating where
cooperation builds trust gradually while violations erode it sharply, creating
hysteresis effects and trust ceilings that constrain relationship recovery. We
develop a structured translation framework enabling requirements engineers to
instantiate computational trust models from i* dependency networks and
organizational contexts. Comprehensive experimental validation across 78,125
parameter configurations establishes robust emergence of negativity bias,
hysteresis effects, and cumulative damage amplification. Empirical validation
using the Renault-Nissan Alliance case study (1999-2025) achieves 49 out of 60
validation points (81.7%), successfully reproducing documented trust evolution
across five distinct relationship phases including crisis and recovery periods.
This technical report builds upon its foundational companion work in
arXiv:2510.18802.

</details>


### [119] [Emergent Coordinated Behaviors in Networked LLM Agents: Modeling the Strategic Dynamics of Information Operations](https://arxiv.org/abs/2510.25003)
*Gian Marco Orlando,Jinyi Ye,Valerio La Gatta,Mahdi Saeedi,Vincenzo Moscato,Emilio Ferrara,Luca Luceri*

Main category: cs.MA

TL;DR: 本研究首次系统分析了生成式智能体在模拟信息操作活动中的自发性协调行为，发现即使没有人类指导，这些智能体也能重现真实世界信息操作的特征性协调策略。


<details>
  <summary>Details</summary>
Motivation: 随着生成式智能体日益复杂化，迫切需要了解它们在在线生态系统中的协调行为，特别是在信息操作这种旨在操纵社交媒体舆论的影响活动中。传统信息操作由人类策划，而智能AI有望使活动更加自动化、自适应且难以检测。

Method: 使用基于生成式智能体的建模方法，在模拟环境中实例化信息操作和有机智能体，评估从简单目标对齐到团队知识和集体决策等不同操作机制下的协调行为。

Result: 随着操作机制更加结构化，信息操作网络变得更密集和集群化，互动更互惠和积极，叙事更同质化，放大更同步，话题标签采用更快且更持久。仅向智能体揭示共享目标的同伴就能产生几乎等同于明确审议和集体投票的协调水平。

Conclusion: 生成式智能体即使没有人类指导也能重现真实世界信息操作的特征性协调策略，这突显了日益自动化、自组织的信息操作所带来的社会风险。

Abstract: Generative agents are rapidly advancing in sophistication, raising urgent
questions about how they might coordinate when deployed in online ecosystems.
This is particularly consequential in information operations (IOs), influence
campaigns that aim to manipulate public opinion on social media. While
traditional IOs have been orchestrated by human operators and relied on
manually crafted tactics, agentic AI promises to make campaigns more automated,
adaptive, and difficult to detect. This work presents the first systematic
study of emergent coordination among generative agents in simulated IO
campaigns. Using generative agent-based modeling, we instantiate IO and organic
agents in a simulated environment and evaluate coordination across operational
regimes, from simple goal alignment to team knowledge and collective
decision-making. As operational regimes become more structured, IO networks
become denser and more clustered, interactions more reciprocal and positive,
narratives more homogeneous, amplification more synchronized, and hashtag
adoption faster and more sustained. Remarkably, simply revealing to agents
which other agents share their goals can produce coordination levels nearly
equivalent to those achieved through explicit deliberation and collective
voting. Overall, we show that generative agents, even without human guidance,
can reproduce coordination strategies characteristic of real-world IOs,
underscoring the societal risks posed by increasingly automated,
self-organizing IOs.

</details>


### [120] [SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In Text-only LLMs](https://arxiv.org/abs/2510.25092)
*Weijia Zhang,Zijia Liu,Haoru Li,Haoqi Chen,Jiaxuan You*

Main category: cs.MA

TL;DR: Seeing Eye是一个模块化框架，通过基于代理的小型VLM翻译器解锁纯文本LLM的多模态推理能力，在知识密集型VQA基准测试中超越了更大的端到端VLM模型。


<details>
  <summary>Details</summary>
Motivation: 现有的纯文本LLM在多模态任务中表现脆弱或完全无法胜任，现有方法依赖单一形式的字幕，缺乏多样性且无法适应不同类型的VQA基准测试，无法有效传输细粒度视觉信息。

Method: 引入Seeing Eye框架，使用基于代理的小型VLM翻译器作为感知代理，调用OCR和裁剪等专用工具，将多模态输入迭代提炼为针对问题定制的结构化中间表示(SIRs)，然后传递给作为推理代理的纯文本LLM，两者进行多轮反馈和交互。

Result: 在MMMU和MIA-Bench等知识密集型VQA基准测试中，Seeing Eye不仅降低了推理成本，还超越了更大的端到端VLM。例如，结合3B参数视觉翻译器和8B参数语言推理器的实例在基于知识的挑战性问题中优于32B单体VLM。

Conclusion: 通过代理信息流将感知与推理解耦，为多模态推理提供了可扩展和即插即用的途径，使强大的纯文本LLM能够充分发挥其推理能力。

Abstract: Recent advances in text-only large language models (LLMs), such as
DeepSeek-R1, demonstrate remarkable reasoning ability. However, these models
remain fragile or entirely incapable when extended to multi-modal tasks.
Existing approaches largely rely on single-form captions, which lack diversity
and often fail to adapt across different types of Visual Question Answering
(VQA) benchmarks. As a result, they provide no principled or efficient channel
for transmitting fine-grained visual information. We introduce Seeing Eye, a
modular framework that unlocks multimodal reasoning in text-only LLMs through
an agent-based small VLM translator. This translator acts as a perception
agent: it can invoke specialized tools (e.g., OCR and crop) and iteratively
distill multimodal inputs into structured intermediate representations (SIRs)
tailored to the question. These SIRs are then passed to the text-only LLM,
which serves as a reasoning agent. Crucially, the translator and reasoner
engage in multi-round feedback and interaction, enabling the extraction of
targeted visual details and yielding more confident answers. Experiments on
knowledge-intensive VQA benchmarks, including MMMU and MIA-Bench, demonstrate
that Seeing Eye not only reduces inference cost but also surpasses much larger
end-to-end VLMs. For example, an instantiation combining a 3B-parameter vision
translator with an 8B-parameter language reasoner outperforms a monolithic 32B
VLM on challenging knowledge-based questions. Our results highlight that
decoupling perception from reasoning via agent information flow offers a
scalable and plug-and-play pathway to multimodal reasoning, allowing strong
text-only LLMs to fully leverage their reasoning capabilities. Code is
available at: https://github.com/ulab-uiuc/SeeingEye

</details>


### [121] [Collaborative Scheduling of Time-dependent UAVs,Vehicles and Workers for Crowdsensing in Disaster Response](https://arxiv.org/abs/2510.25212)
*Lei Han,Jinhao Zhang,Jinhui Liu,Zhiyong Yu,Liang Wang,Quan Wang,Zhiwen Yu*

Main category: cs.MA

TL;DR: 本文提出了一种异构多智能体在线协同调度算法HoCs-MPQ，用于高效收集灾后环境信息。该算法通过加权无向图建模多要素间的协作与冲突关系，并基于多优先级队列迭代求解最大权重独立集，实现无人机、车辆和工作人员的协同感知调度。


<details>
  <summary>Details</summary>
Motivation: 频繁的自然灾害给人类社会造成重大损失，及时高效地收集灾后环境信息是有效救援行动的基础。由于灾后环境的极端复杂性，现有感知技术存在环境适应性弱、专业感知能力不足和感知方案实用性差等问题。

Method: HoCs-MPQ算法：(1)基于多要素间的协作关系构建加权无向图节点并量化权重，基于节点间的冲突关系建模加权无向图；(2)基于迭代局部搜索求解最大权重独立集，并使用多优先级队列加速求解过程。

Result: 实验表明，与基线方法相比，HoCs-MPQ平均分别提高了任务完成率54.13%、23.82%、14.12%和12.89%，单次在线自主调度决策的计算时间不超过3秒。

Conclusion: HoCs-MPQ算法能够有效解决灾后环境信息收集中的多智能体协同调度问题，显著提高任务完成效率，具有实际应用价值。

Abstract: Frequent natural disasters cause significant losses to human society, and
timely, efficient collection of post-disaster environmental information is the
foundation for effective rescue operations. Due to the extreme complexity of
post-disaster environments, existing sensing technologies such as mobile
crowdsensing suffer from weak environmental adaptability, insufficient
professional sensing capabilities, and poor practicality of sensing solutions.
Therefore, this paper explores a heterogeneous multi-agent online collaborative
scheduling algorithm, HoCs-MPQ, to achieve efficient collection of
post-disaster environmental information. HoCs-MPQ models collaboration and
conflict relationships among multiple elements through weighted undirected
graph construction, and iteratively solves the maximum weight independent set
based on multi-priority queues, ultimately achieving collaborative sensing
scheduling of time-dependent UA Vs, vehicles, and workers. Specifically, (1)
HoCs-MPQ constructs weighted undirected graph nodes based on collaborative
relationships among multiple elements and quantifies their weights, then models
the weighted undirected graph based on conflict relationships between nodes;
(2) HoCs-MPQ solves the maximum weight independent set based on iterated local
search, and accelerates the solution process using multi-priority queues.
Finally, we conducted detailed experiments based on extensive real-world and
simulated data. The experiments show that, compared to baseline methods (e.g.,
HoCs-GREEDY, HoCs-K-WTA, HoCs-MADL, and HoCs-MARL), HoCs-MPQ improves task
completion rates by an average of 54.13%, 23.82%, 14.12%, and 12.89%
respectively, with computation time for single online autonomous scheduling
decisions not exceeding 3 seconds.

</details>


### [122] [Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork](https://arxiv.org/abs/2510.25340)
*Beiwen Zhang,Yongheng Liang,Hejun Wu*

Main category: cs.MA

TL;DR: 本文提出了多边临时团队协作(MAHT)问题，其中受控智能体需要与多个相互不熟悉的非受控队友群体协调。为解决此问题，作者提出了MARs方法，通过构建稀疏骨架图和应用关系建模来捕捉跨群体动态。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习(MARL)通常假设固定且完全可控的团队，而临时团队协作(AHT)虽然允许与未知伙伴合作，但仍假设共享约定。MAHT进一步放宽这一限制，要求智能体与多个相互不熟悉的非受控队友群体协调。

Method: 提出MARs方法，构建稀疏骨架图并应用关系建模来捕捉跨群体动态，以解决多边临时团队协作问题。

Result: 在MPE和StarCraft II环境中的实验表明，MARs方法优于MARL和AHT基线方法，并且收敛速度更快。

Conclusion: MARs方法能够有效解决多边临时团队协作问题，在复杂多智能体环境中展现出优越的性能和更快的收敛速度。

Abstract: Multi-agent reinforcement learning (MARl) has achieved strong results in
cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc
teamwork (AHT) relaxes this by allowing collaboration with unknown partners,
yet existing variants still presume shared conventions. We introduce
Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate
with multiple mutually unfamiliar groups of uncontrolled teammates. To address
this, we propose MARs, which builds a sparse skeleton graph and applies
relational modeling to capture cross-group dvnamics. Experiments on MPE and
starCralt ll show that MARs outperforms MARL and AHT baselines while converging
faster.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [123] [Fortytwo: Swarm Inference with Peer-Ranked Consensus](https://arxiv.org/abs/2510.24801)
*Vladyslav Larin,Ihor Naumenko,Aleksei Ivashov,Ivan Nikitin,Alexander Firsov*

Main category: cs.LG

TL;DR: Fortytwo协议利用群体智能和分布式成对排名共识，在AI推理中实现优于多数投票的性能，在GPQA Diamond上达到85.90%准确率，比多数投票提升+17.21个百分点。


<details>
  <summary>Details</summary>
Motivation: 随着集中式AI面临计算瓶颈和大型训练收益递减，需要能够水平和垂直扩展的推理层来满足需求。

Method: 采用群体推理方法：基于同行排名、声誉加权的异构模型共识机制，使用成对排名和Bradley-Terry风格聚合模型，结合链上声誉系统和能力证明来抵抗女巫攻击。

Result: 在六个基准测试中表现优异，GPQA Diamond准确率85.90%，比多数投票高17.21个百分点；对对抗性提示具有强韧性，提示注入性能下降仅0.12%。

Conclusion: 为去中心化AI系统奠定了基础，通过集体智能实现高质量推理的民主化访问，同时保持可靠性和安全性。

Abstract: As centralized AI hits compute ceilings and diminishing returns from
ever-larger training runs, meeting demand requires an inference layer that
scales horizontally in both capacity and capability. We present Fortytwo, a
novel protocol that leverages swarm intelligence principles and distributed
pairwise ranking consensus to achieve superior performance in AI inference. Our
approach reimagines collaboration among AI nodes using swarm inference: a
peer-ranked, reputation-weighted consensus across heterogeneous models that
surfaces the highest-quality responses. Using pairwise ranking with a custom
Bradley-Terry-style aggregation model, we demonstrate that swarm inference
substantially outperforms majority voting, achieving 85.90% on GPQA Diamond
versus 68.69% for majority voting with the same model set - an improvement of
+17.21 percentage points (approximately +25.1% relative). The protocol
incorporates on-chain reputation so node influence adapts to demonstrated
accuracy over time, yielding a meritocratic consensus that filters low-quality
or malicious participants. To resist Sybil attacks, Fortytwo employs
proof-of-capability in its consensus: nodes must successfully complete
calibration/test requests and stake reputation to enter ranking rounds, making
multi-identity attacks economically unattractive while preserving openness.
Across six challenging benchmarks, including GPQA Diamond, LiveCodeBench, and
AIME, our evaluation indicates higher accuracy and strong resilience to
adversarial and noisy free-form prompting (e.g., prompt-injection degradation
of only 0.12% versus 6.20% for a monolithic single-model baseline), while
retaining practical deployability. Together, these results establish a
foundation for decentralized AI systems - democratizing access to high-quality
inference through collective intelligence without sacrificing reliability or
security.

</details>


### [124] [From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning](https://arxiv.org/abs/2510.24812)
*Junsoo Oh,Jerry Song,Chulhee Yun*

Main category: cs.LG

TL;DR: 该论文分析了从弱CNN到强CNN的弱到强泛化现象，识别了数据稀缺和数据丰富两种机制，揭示了良性过拟合、有害过拟合和标签修正等不同泛化机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究对弱到强泛化的理论解释大多局限于抽象框架或简单模型，需要在实际CNN架构中提供更形式化的分析。

Method: 使用线性CNN作为弱模型，两层ReLU CNN作为强模型，分析梯度下降动态，考虑包含不同难度标签相关信号和标签无关噪声的结构化数据。

Result: 识别了两种机制：数据稀缺机制中泛化通过良性过拟合实现或通过有害过拟合失败；数据丰富机制中早期通过标签修正实现泛化，但过度训练会降低性能。

Conclusion: 弱到强泛化在不同数据机制下表现出不同行为，需要仔细控制训练过程以避免性能退化。

Abstract: Weak-to-strong generalization refers to the phenomenon where a stronger model
trained under supervision from a weaker one can outperform its teacher. While
prior studies aim to explain this effect, most theoretical insights are limited
to abstract frameworks or linear/random feature models. In this paper, we
provide a formal analysis of weak-to-strong generalization from a linear CNN
(weak) to a two-layer ReLU CNN (strong). We consider structured data composed
of label-dependent signals of varying difficulty and label-independent noise,
and analyze gradient descent dynamics when the strong model is trained on data
labeled by the pretrained weak model. Our analysis identifies two regimes --
data-scarce and data-abundant -- based on the signal-to-noise characteristics
of the dataset, and reveals distinct mechanisms of weak-to-strong
generalization. In the data-scarce regime, generalization occurs via benign
overfitting or fails via harmful overfitting, depending on the amount of data,
and we characterize the transition boundary. In the data-abundant regime,
generalization emerges in the early phase through label correction, but we
observe that overtraining can subsequently degrade performance.

</details>


### [125] [Augmenting Biological Fitness Prediction Benchmarks with Landscapes Features from GraphFLA](https://arxiv.org/abs/2510.24826)
*Mingyu Huang,Shasha Zhou,Ke Li*

Main category: cs.LG

TL;DR: GraphFLA是一个Python框架，用于从突变数据构建和分析适应性景观，计算20个生物学相关特征，帮助解释和比较适应性预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试缺乏关于底层适应性景观的地形信息，这阻碍了对模型性能的深入解释和比较。

Method: GraphFLA从DNA、RNA、蛋白质等不同模态的突变数据中构建适应性景观，计算20个特征来表征景观地形的4个基本方面。

Result: 应用GraphFLA分析了5,300多个景观，揭示了影响模型准确性的因素和不同模型的各自优势，并发布了155个组合完整的经验性适应性景观。

Conclusion: GraphFLA提供了一个强大的工具来表征适应性景观地形，有助于更深入地理解和比较适应性预测模型的性能。

Abstract: Machine learning models increasingly map biological sequence-fitness
landscapes to predict mutational effects. Effective evaluation of these models
requires benchmarks curated from empirical data. Despite their impressive
scales, existing benchmarks lack topographical information regarding the
underlying fitness landscapes, which hampers interpretation and comparison of
model performance beyond averaged scores. Here, we introduce GraphFLA, a Python
framework that constructs and analyzes fitness landscapes from mutagensis data
in diverse modalities (e.g., DNA, RNA, protein, and beyond) with up to millions
of mutants. GraphFLA calculates 20 biologically relevant features that
characterize 4 fundamental aspects of landscape topography. By applying
GraphFLA to over 5,300 landscapes from ProteinGym, RNAGym, and CIS-BP, we
demonstrate its utility in interpreting and comparing the performance of dozens
of fitness prediction models, highlighting factors influencing model accuracy
and respective advantages of different models. In addition, we release 155
combinatorially complete empirical fitness landscapes, encompassing over 2.2
million sequences across various modalities. All the codes and datasets are
available at https://github.com/COLA-Laboratory/GraphFLA.

</details>


### [126] [Send Less, Save More: Energy-Efficiency Benchmark of Embedded CNN Inference vs. Data Transmission in IoT](https://arxiv.org/abs/2510.24829)
*Benjamin Karic,Nina Herrmann,Jan Stenkamp,Paula Scharf,Fabian Gieseke,Angela Schwering*

Main category: cs.LG

TL;DR: 该研究评估了在ESP32-S3微控制器上使用压缩CNN模型和低功耗广域网进行环境监测，通过设备端推理减少数据传输，可将能耗降低高达5倍。


<details>
  <summary>Details</summary>
Motivation: 环境监测需要能在偏远地区长期运行的节能物联网设备，特别是处理图像数据时，数据传输能耗高是主要挑战。

Method: 在ESP32-S3微控制器上部署压缩的CNN模型，使用后训练量化技术，结合低功耗广域网，在设备端执行推理并仅传输结果。

Result: 设备端CNN推理和仅传输结果相比发送原始图像数据，整体能耗降低了高达5倍，量化模型精度损失仅为几个百分点。

Conclusion: 嵌入式机器学习能够开发碳足迹更小、能在环境监测场景中自主运行的物联网应用。

Abstract: The integration of the Internet of Things (IoT) and Artificial Intelligence
offers significant opportunities to enhance our ability to monitor and address
ecological changes. As environmental challenges become increasingly pressing,
the need for effective remote monitoring solutions is more critical than ever.
A major challenge in designing IoT applications for environmental monitoring -
particularly those involving image data - is to create energy-efficient IoT
devices capable of long-term operation in remote areas with limited power
availability. Advancements in the field of Tiny Machine Learning allow the use
of Convolutional Neural Networks (CNNs) on resource-constrained,
battery-operated microcontrollers. Since data transfer is energy-intensive,
performing inference directly on microcontrollers to reduce the message size
can extend the operational lifespan of IoT nodes. This work evaluates the use
of common Low Power Wide Area Networks and compressed CNNs trained on domain
specific datasets on an ESP32-S3. Our experiments demonstrate, among other
things, that executing CNN inference on-device and transmitting only the
results reduces the overall energy consumption by a factor of up to five
compared to sending raw image data. %The compression of the model using Post
Training Quantization is accompanied by an acceptable reduction in accuracy of
only a few percentage points compared to a non-quantized model. These findings
advocate the development of IoT applications with reduced carbon footprint and
capable of operating autonomously in environmental monitoring scenarios by
incorporating Embedded Machine Learning.

</details>


### [127] [Resource-Efficient and Robust Inference of Deep and Bayesian Neural Networks on Embedded and Analog Computing Platforms](https://arxiv.org/abs/2510.24951)
*Bernhard Klein*

Main category: cs.LG

TL;DR: 该论文通过算法-硬件协同设计，为传统和贝叶斯神经网络开发资源高效且鲁棒的推理方法，包括模型压缩、近似贝叶斯推理、数字/模拟硬件优化，实现效率与可靠性的共同提升。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习在嵌入式等资源受限平台上的计算需求日益增长，需要既高效又能在分布偏移下提供可靠预测的神经网络。贝叶斯神经网络能量化不确定性，但计算开销更大。

Method: 1) Galen：基于敏感性分析和硬件反馈的自动分层压缩；2) 模拟加速器噪声建模和非平稳条件下的噪声训练；3) 开发解析和集成近似替代昂贵采样；4) 概率光子计算利用模拟噪声作为熵源。

Result: 实现了算法和硬件效率的联合优化，提高了神经网络在资源受限环境下的推理效率和鲁棒性，为可信赖、高能效的机器学习系统奠定基础。

Conclusion: 通过算法-硬件协同设计可以同时推进效率和可靠性，为下一代可信赖、高能效的机器学习系统提供了理论基础和实践方法。

Abstract: While modern machine learning has transformed numerous application domains,
its growing computational demands increasingly constrain scalability and
efficiency, particularly on embedded and resource-limited platforms. In
practice, neural networks must not only operate efficiently but also provide
reliable predictions under distributional shifts or unseen data. Bayesian
neural networks offer a principled framework for quantifying uncertainty, yet
their computational overhead further compounds these challenges.
  This work advances resource-efficient and robust inference for both
conventional and Bayesian neural networks through the joint pursuit of
algorithmic and hardware efficiency. The former reduces computation through
model compression and approximate Bayesian inference, while the latter
optimizes deployment on digital accelerators and explores analog hardware,
bridging algorithmic design and physical realization. The first contribution,
Galen, performs automatic layer-specific compression guided by sensitivity
analysis and hardware-in-the-loop feedback. Analog accelerators offer
efficiency gains at the cost of noise; this work models device imperfections
and extends noisy training to nonstationary conditions, improving robustness
and stability. A second line of work advances probabilistic inference,
developing analytic and ensemble approximations that replace costly sampling,
integrate into a compiler stack, and optimize embedded inference. Finally,
probabilistic photonic computing introduces a paradigm where controlled analog
noise acts as an intrinsic entropy source, enabling fast, energy-efficient
probabilistic inference directly in hardware.
  Together, these studies demonstrate how efficiency and reliability can be
advanced jointly through algorithm-hardware co-design, laying the foundation
for the next generation of trustworthy, energy-efficient machine-learning
systems.

</details>


### [128] [Aggregation Hides Out-of-Distribution Generalization Failures from Spurious Correlations](https://arxiv.org/abs/2510.24884)
*Olawale Salaudeen,Haoran Zhang,Kumail Alhamoud,Sara Beery,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 研究发现OOD泛化基准中ID与OOD准确率的正相关性可能是异质OOD样本聚合的假象，通过OODSelect方法识别出语义一致的子集，在这些子集中高ID准确率反而预测低OOD准确率。


<details>
  <summary>Details</summary>
Motivation: 挑战现有OOD泛化基准中普遍观察到的ID与OOD准确率正相关性，认为这种模式可能掩盖了模型在特定OOD子集上的真实失败模式。

Method: 开发了基于梯度的OODSelect方法，用于识别语义一致的OOD子集，在这些子集中ID与OOD准确率呈现负相关关系。

Result: 在广泛使用的分布偏移基准中，OODSelect识别出的子集有时超过标准OOD集的一半，其中高ID准确率预测低OOD准确率。

Conclusion: 聚合指标可能掩盖OOD鲁棒性的重要失败模式，需要更细粒度的分析来理解模型在特定语义子集上的表现。

Abstract: Benchmarks for out-of-distribution (OOD) generalization frequently show a
strong positive correlation between in-distribution (ID) and OOD accuracy
across models, termed "accuracy-on-the-line." This pattern is often taken to
imply that spurious correlations - correlations that improve ID but reduce OOD
performance - are rare in practice. We find that this positive correlation is
often an artifact of aggregating heterogeneous OOD examples. Using a simple
gradient-based method, OODSelect, we identify semantically coherent OOD subsets
where accuracy on the line does not hold. Across widely used distribution shift
benchmarks, the OODSelect uncovers subsets, sometimes over half of the standard
OOD set, where higher ID accuracy predicts lower OOD accuracy. Our findings
indicate that aggregate metrics can obscure important failure modes of OOD
robustness. We release code and the identified subsets to facilitate further
research.

</details>


### [129] [Dynamically Weighted Momentum with Adaptive Step Sizes for Efficient Deep Network Training](https://arxiv.org/abs/2510.25042)
*Zhifeng Wang,Longlong Li,Chunyan Zeng*

Main category: cs.LG

TL;DR: 提出DWMGrad优化算法，通过动态引导机制自适应调整动量和学习率，解决传统优化算法在处理复杂模型和非凸优化时的不足。


<details>
  <summary>Details</summary>
Motivation: 传统优化算法如SGD和Adam在处理学习效率波动、复杂模型需求和非凸优化问题时存在明显不足，特别是在处理复杂数据结构和模型时面临学习率选择困难、局部最优规避和高维空间导航等挑战。

Method: 基于传统方法基础，引入依赖历史数据的动态引导机制，动态更新动量和学习率，使优化器能灵活调整对历史信息的依赖，适应不同训练场景。

Result: 经过广泛实验验证，DWMGrad在多种场景下能够实现更快的收敛速度和更高的准确率。

Conclusion: DWMGrad算法通过动态引导机制有效提升了优化器对变化环境和任务复杂度的适应能力，在收敛速度和精度方面均优于传统方法。

Abstract: Within the current sphere of deep learning research, despite the extensive
application of optimization algorithms such as Stochastic Gradient Descent
(SGD) and Adaptive Moment Estimation (Adam), there remains a pronounced
inadequacy in their capability to address fluctuations in learning efficiency,
meet the demands of complex models, and tackle non-convex optimization issues.
These challenges primarily arise from the algorithms' limitations in handling
complex data structures and models, for instance, difficulties in selecting an
appropriate learning rate, avoiding local optima, and navigating through
high-dimensional spaces. To address these issues, this paper introduces a novel
optimization algorithm named DWMGrad. This algorithm, building on the
foundations of traditional methods, incorporates a dynamic guidance mechanism
reliant on historical data to dynamically update momentum and learning rates.
This allows the optimizer to flexibly adjust its reliance on historical
information, adapting to various training scenarios. This strategy not only
enables the optimizer to better adapt to changing environments and task
complexities but also, as validated through extensive experimentation,
demonstrates DWMGrad's ability to achieve faster convergence rates and higher
accuracies under a multitude of scenarios.

</details>


### [130] [Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep Q-learning thresholding](https://arxiv.org/abs/2510.24889)
*Shakeel Abdulkareem,Bora Yimenicioglu,Andrea Yang,Khartik Uppalapati,Aneesh Gudipati,Zhaoyang Fan*

Main category: cs.LG

TL;DR: 提出了一种自适应多任务EEG分类器，使用GRU-TCN网络结合深度Q网络实时调整决策阈值，用于快速分诊疑似卒中患者，在卒中类型分类上达到98.0%的准确率。


<details>
  <summary>Details</summary>
Motivation: 卒中快速分诊需要准确且可在床边部署的工具，EEG虽然很有前景但在初次接触时使用不足。

Method: 将32通道EEG信号转换为功率谱密度特征，使用GRU-TCN网络预测卒中类型、半球偏侧化和严重程度，并应用深度Q网络实时调整决策阈值。

Result: 基线GRU-TCN在卒中类型分类上达到89.3%准确率，严重程度96.9%，偏侧化96.7%；加入DQN阈值自适应后，卒中类型准确率提升至98.0%。

Conclusion: 自适应阈值调整可将操作点转移到临床偏好的敏感度-特异性权衡，同时集成的头皮图和频谱可视化支持可解释性。

Abstract: Rapid triage of suspected stroke needs accurate, bedside-deployable tools;
EEG is promising but underused at first contact. We present an adaptive
multitask EEG classifier that converts 32-channel signals to power spectral
density features (Welch), uses a recurrent-convolutional network (GRU-TCN) to
predict stroke type (healthy, ischemic, hemorrhagic), hemispheric
lateralization, and severity, and applies a deep Q-network (DQN) to tune
decision thresholds in real time. Using a patient-wise split of the UCLH Stroke
EIT/EEG data set (44 recordings; about 26 acute stroke, 10 controls), the
primary outcome was stroke-type performance; secondary outcomes were severity
and lateralization. The baseline GRU-TCN reached 89.3% accuracy (F1 92.8%) for
stroke type, about 96.9% (F1 95.9%) for severity, and about 96.7% (F1 97.4%)
for lateralization. With DQN threshold adaptation, stroke-type accuracy
increased to about 98.0% (F1 97.7%). We also tested robustness on an
independent, low-density EEG cohort (ZJU4H) and report paired patient-level
statistics. Analyses follow STARD 2015 guidance for diagnostic accuracy studies
(index test: GRU-TCN+DQN; reference standard: radiology/clinical diagnosis;
patient-wise evaluation). Adaptive thresholding shifts the operating point to
clinically preferred sensitivity-specificity trade-offs, while integrated
scalp-map and spectral visualizations support interpretability.

</details>


### [131] [Position: Biology is the Challenge Physics-Informed ML Needs to Evolve](https://arxiv.org/abs/2510.25368)
*Julien Martinelli*

Main category: cs.LG

TL;DR: 提出了生物学信息机器学习(BIML)作为物理信息机器学习(PIML)的扩展，旨在将机器学习应用于生物学领域，应对其特有的挑战。


<details>
  <summary>Details</summary>
Motivation: 物理信息机器学习在物理定律主导的领域取得成功，但生物学建模面临多面性先验知识、异质噪声数据、部分可观测性和复杂高维网络等独特挑战，需要新的方法。

Method: 提出BIML框架，通过四个基础支柱实现：不确定性量化、情境化、约束潜在结构推断和可扩展性，利用基础模型和大型语言模型作为关键推动者。

Result: BIML保留了PIML的结构基础，同时适应生物学的实际需求，在较软的概率形式先验知识下运行。

Conclusion: BIML为PIML启发的创新提供了路线图，将机器学习应用于具有高科学和社会相关性的生物学挑战。

Abstract: Physics-Informed Machine Learning (PIML) has successfully integrated
mechanistic understanding into machine learning, particularly in domains
governed by well-known physical laws. This success has motivated efforts to
apply PIML to biology, a field rich in dynamical systems but shaped by
different constraints. Biological modeling, however, presents unique
challenges: multi-faceted and uncertain prior knowledge, heterogeneous and
noisy data, partial observability, and complex, high-dimensional networks. In
this position paper, we argue that these challenges should not be seen as
obstacles to PIML, but as catalysts for its evolution. We propose
Biology-Informed Machine Learning (BIML): a principled extension of PIML that
retains its structural grounding while adapting to the practical realities of
biology. Rather than replacing PIML, BIML retools its methods to operate under
softer, probabilistic forms of prior knowledge. We outline four foundational
pillars as a roadmap for this transition: uncertainty quantification,
contextualization, constrained latent structure inference, and scalability.
Foundation Models and Large Language Models will be key enablers, bridging
human expertise with computational modeling. We conclude with concrete
recommendations to build the BIML ecosystem and channel PIML-inspired
innovation toward challenges of high scientific and societal relevance.

</details>


### [132] [Topic Analysis with Side Information: A Neural-Augmented LDA Approach](https://arxiv.org/abs/2510.24918)
*Biyi Fang,Kripa Rajshekhar,Truong Vo,Diego Klabjan*

Main category: cs.LG

TL;DR: 提出了nnLDA，一种神经增强的概率主题模型，通过神经先验机制动态整合辅助信息，在主题一致性、困惑度和下游分类任务上优于传统LDA和DMR模型


<details>
  <summary>Details</summary>
Motivation: 传统主题模型如LDA难以整合元数据、用户属性或文档标签等辅助信息，限制了其表达能力、个性化和可解释性

Method: 使用神经先验机制，通过神经网络基于辅助特征生成主题比例的先验分布，开发了随机变分EM算法联合优化神经和概率组件

Result: 在多个基准数据集上，nnLDA在主题一致性、困惑度和下游分类任务上持续优于LDA和Dirichlet-Multinomial回归

Conclusion: 在存在辅助信息的情况下，将神经表示学习与概率主题建模相结合具有显著优势

Abstract: Traditional topic models such as Latent Dirichlet Allocation (LDA) have been
widely used to uncover latent structures in text corpora, but they often
struggle to integrate auxiliary information such as metadata, user attributes,
or document labels. These limitations restrict their expressiveness,
personalization, and interpretability. To address this, we propose nnLDA, a
neural-augmented probabilistic topic model that dynamically incorporates side
information through a neural prior mechanism. nnLDA models each document as a
mixture of latent topics, where the prior over topic proportions is generated
by a neural network conditioned on auxiliary features. This design allows the
model to capture complex nonlinear interactions between side information and
topic distributions that static Dirichlet priors cannot represent. We develop a
stochastic variational Expectation-Maximization algorithm to jointly optimize
the neural and probabilistic components. Across multiple benchmark datasets,
nnLDA consistently outperforms LDA and Dirichlet-Multinomial Regression in
topic coherence, perplexity, and downstream classification. These results
highlight the benefits of combining neural representation learning with
probabilistic topic modeling in settings where side information is available.

</details>


### [133] [KAN-GCN: Combining Kolmogorov-Arnold Network with Graph Convolution Network for an Accurate Ice Sheet Emulator](https://arxiv.org/abs/2510.24926)
*Zesheng Liu,YoungHyun Koo,Maryam Rahnemoonfar*

Main category: cs.LG

TL;DR: KAN-GCN是一种快速准确的冰盖建模仿真器，在GCN前加入KAN网络作为特征校准器，通过可学习的一维扭曲和线性混合步骤改善特征条件，在不增加消息传递深度的情况下提升非线性编码能力。


<details>
  <summary>Details</summary>
Motivation: 提高冰盖数值模型仿真器的性能，通过改进特征条件和非线性编码来增强建模精度和效率。

Method: 在GCN前放置Kolmogorov-Arnold Network作为特征校准器，应用可学习的一维扭曲和线性混合步骤，用节点级变换替代边缘消息传递层。

Result: 在2-5层架构中，KAN-GCN达到或超过纯GCN和MLP-GCN基准的精度，在较粗网格上提高了推理吞吐量，仅在最细网格上有适度成本增加。

Conclusion: KAN优先设计为大型瞬态场景扫描提供了有利的精度与效率权衡。

Abstract: We introduce KAN-GCN, a fast and accurate emulator for ice sheet modeling
that places a Kolmogorov-Arnold Network (KAN) as a feature-wise calibrator
before graph convolution networks (GCNs). The KAN front end applies learnable
one-dimensional warps and a linear mixing step, improving feature conditioning
and nonlinear encoding without increasing message-passing depth. We employ this
architecture to improve the performance of emulators for numerical ice sheet
models. Our emulator is trained and tested using 36 melting-rate simulations
with 3 mesh-size settings for Pine Island Glacier, Antarctica. Across 2- to
5-layer architectures, KAN-GCN matches or exceeds the accuracy of pure GCN and
MLP-GCN baselines. Despite a small parameter overhead, KAN-GCN improves
inference throughput on coarser meshes by replacing one edge-wise
message-passing layer with a node-wise transform; only the finest mesh shows a
modest cost. Overall, KAN-first designs offer a favorable accuracy vs.
efficiency trade-off for large transient scenario sweeps.

</details>


### [134] [WBT-BGRL: A Non-Contrastive Weighted Bipartite Link Prediction Model for Inductive Learning](https://arxiv.org/abs/2510.24927)
*Joel Frank Huarayo Quispe,Lilian Berton,Didier Vega-Oliveros*

Main category: cs.LG

TL;DR: 提出了WBT-BGRL框架，一种用于二分图链接预测的非对比学习方法，通过三重损失中的加权机制增强自举学习，在归纳、加权和二分场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 二分图链接预测在推荐系统和故障检测中很重要，但研究较少。现有对比方法存在负采样效率低和偏差问题，非对比方法仅依赖正样本，且在归纳、加权和二分场景下的有效性未经测试。

Method: 使用双GCN编码器的二分架构，通过三重损失中的新颖加权机制增强自举学习，提出WBT-BGRL非对比框架。

Result: 在真实世界数据集（工业和电子商务）上评估，与现有模型（T-BGRL、BGRL、GBT、CCA-SSG）相比表现出竞争性能，特别是在预训练期间应用加权时效果显著。

Conclusion: 加权非对比学习对二分图中的归纳链接预测具有重要价值，WBT-BGRL框架在此类场景下表现优异。

Abstract: Link prediction in bipartite graphs is crucial for applications like
recommendation systems and failure detection, yet it is less studied than in
monopartite graphs. Contrastive methods struggle with inefficient and biased
negative sampling, while non-contrastive approaches rely solely on positive
samples. Existing models perform well in transductive settings, but their
effectiveness in inductive, weighted, and bipartite scenarios remains untested.
To address this, we propose Weighted Bipartite Triplet-Bootstrapped Graph
Latents (WBT-BGRL), a non-contrastive framework that enhances bootstrapped
learning with a novel weighting mechanism in the triplet loss. Using a
bipartite architecture with dual GCN encoders, WBT-BGRL is evaluated against
adapted state-of-the-art models (T-BGRL, BGRL, GBT, CCA-SSG). Results on
real-world datasets (Industry and E-commerce) show competitive performance,
especially when weighting is applied during pretraining-highlighting the value
of weighted, non-contrastive learning for inductive link prediction in
bipartite graphs.

</details>


### [135] [Machine Learning and CPU (Central Processing Unit) Scheduling Co-Optimization over a Network of Computing Centers](https://arxiv.org/abs/2510.25176)
*Mohammadreza Doostmohammadian,Zulfiya R. Gabidullina,Hamid R. Rabiee*

Main category: cs.LG

TL;DR: 提出了一种分布式机器学习的计算资源优化算法，通过协同优化数据分配和CPU资源分配，在时变网络中实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 随着AI研究的快速发展，对快速、计算高效且可扩展的解决方案需求日益增长，需要优化分布式机器学习的计算资源分配。

Method: 采用协同优化方法，在时变信息共享网络中同时优化数据处理和计算资源分配，支持对数尺度量化的信息交换，确保算法在所有迭代中保持可行性。

Result: 与现有CPU调度方案相比，该算法将成本最优性差距改善了50%以上，并通过Lyapunov稳定性和特征谱分析证明了收敛性。

Conclusion: 该算法为分布式机器学习提供了高效的资源优化解决方案，在保持计算资源需求平衡的同时实现了向最优情况的收敛。

Abstract: In the rapidly evolving research on artificial intelligence (AI) the demand
for fast, computationally efficient, and scalable solutions has increased in
recent years. The problem of optimizing the computing resources for distributed
machine learning (ML) and optimization is considered in this paper. Given a set
of data distributed over a network of computing-nodes/servers, the idea is to
optimally assign the CPU (central processing unit) usage while simultaneously
training each computing node locally via its own share of data. This formulates
the problem as a co-optimization setup to (i) optimize the data processing and
(ii) optimally allocate the computing resources. The information-sharing
network among the nodes might be time-varying, but with balanced weights to
ensure consensus-type convergence of the algorithm. The algorithm is all-time
feasible, which implies that the computing resource-demand balance constraint
holds at all iterations of the proposed solution. Moreover, the solution allows
addressing possible log-scale quantization over the information-sharing
channels to exchange log-quantized data. For some example applications,
distributed support-vector-machine (SVM) and regression are considered as the
ML training models. Results from perturbation theory, along with Lyapunov
stability and eigen-spectrum analysis, are used to prove the convergence
towards the optimal case. As compared to existing CPU scheduling solutions, the
proposed algorithm improves the cost optimality gap by more than $50\%$.

</details>


### [136] [Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought](https://arxiv.org/abs/2510.24941)
*Jiachen Zhao,Yiyou Sun,Weiyan Shi,Dawn Song*

Main category: cs.LG

TL;DR: 研究发现大语言模型生成的思维链中许多步骤对最终预测没有实际因果影响，这些装饰性思考步骤只是表面推理。通过提出的真实思考分数(TTS)测量，发现只有少量步骤真正驱动模型预测。


<details>
  <summary>Details</summary>
Motivation: 当前假设思维链步骤忠实反映模型内部思考过程，但研究发现许多步骤并不真正贡献于预测，这影响LLM推理效率和思维链可信度。

Method: 提出真实思考分数(TTS)测量每个推理步骤对最终预测的因果影响，识别真实思考方向，并通过在该方向上的引导控制模型执行或忽略特定步骤。

Result: 在AIME数据集上，Qwen-2.5模型中平均仅2.3%的思维链步骤TTS≥0.7；自我验证步骤也可能是装饰性的；沿真实思考方向引导可改变最终结果。

Conclusion: LLM经常口头表达推理步骤但内部并未真正执行，这削弱了LLM推理效率和思维链的可信度。

Abstract: Recent large language models (LLMs) can generate long Chain-of-Thought (CoT)
at test time, enabling them to solve complex tasks. These reasoning steps in
CoT are often assumed as a faithful reflection of the model's internal thinking
process, and used to monitor unsafe intentions. However, we find many reasoning
steps don't truly contribute to LLMs' prediction. We measure the step-wise
causal influence of each reasoning step on the model's final prediction with a
proposed True Thinking Score (TTS). We reveal that LLMs often interleave
between true-thinking steps (which are genuinely used to produce the final
output) and decorative-thinking steps (which only give the appearance of
reasoning but have minimal causal impact). Notably, only a small subset of the
total reasoning steps have a high TTS that causally drive the model's
prediction: e.g., for the AIME dataset, only an average of 2.3% of reasoning
steps in CoT have a TTS >= 0.7 (range: 0-1) under the Qwen-2.5 model.
Furthermore, we identify a TrueThinking direction in the latent space of LLMs.
By steering along or against this direction, we can force the model to perform
or disregard certain CoT steps when computing the final result. Finally, we
highlight that self-verification steps in CoT (i.e., aha moments) can also be
decorative, where LLMs do not truly verify their solution. Steering along the
TrueThinking direction can force internal reasoning over these steps, resulting
in a change in the final results. Overall, our work reveals that LLMs often
verbalize reasoning steps without actually performing them internally, which
undermines both the efficiency of LLM reasoning and the trustworthiness of CoT.

</details>


### [137] [Finding Culture-Sensitive Neurons in Vision-Language Models](https://arxiv.org/abs/2510.24942)
*Xiutian Zhao,Rochelle Choenni,Rohit Saxena,Ivan Titov*

Main category: cs.LG

TL;DR: 该论文研究了视觉语言模型中存在的文化敏感神经元，这些神经元对特定文化背景的输入表现出选择性敏感。通过CVQA基准测试，作者识别出这些神经元并证明它们对文化多样性视觉问答任务的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型表现出色，但在处理文化相关输入时仍然存在困难。为了理解模型如何处理文化背景信息，研究者希望探究是否存在对特定文化敏感的神经元。

Method: 使用CVQA基准测试，识别文化选择性神经元，并通过神经元失活进行因果测试。提出新的基于边际的选择器——对比激活选择(CAS)，并与现有的概率和熵基方法进行比较。在三个VLMs和25个文化群体上进行实验。

Result: 实验证明存在文化敏感神经元，这些神经元的失活会显著影响对应文化问题的性能，而对其他文化影响很小。CAS方法在识别文化敏感神经元方面优于现有方法。层间分析显示这些神经元倾向于聚集在某些解码器层中。

Conclusion: 研究揭示了多模态表征的内部组织方式，发现了专门处理文化信息的神经元集群，为理解VLMs如何处理文化背景信息提供了新视角。

Abstract: Despite their impressive performance, vision-language models (VLMs) still
struggle on culturally situated inputs. To understand how VLMs process
culturally grounded information, we study the presence of culture-sensitive
neurons, i.e. neurons whose activations show preferential sensitivity to inputs
associated with particular cultural contexts. We examine whether such neurons
are important for culturally diverse visual question answering and where they
are located. Using the CVQA benchmark, we identify neurons of culture
selectivity and perform causal tests by deactivating the neurons flagged by
different identification methods. Experiments on three VLMs across 25 cultural
groups demonstrate the existence of neurons whose ablation disproportionately
harms performance on questions about the corresponding cultures, while having
minimal effects on others. Moreover, we propose a new margin-based selector -
Contrastive Activation Selection (CAS), and show that it outperforms existing
probability- and entropy-based methods in identifying culture-sensitive
neurons. Finally, our layer-wise analyses reveals that such neurons tend to
cluster in certain decoder layers. Overall, our findings shed new light on the
internal organization of multimodal representations.

</details>


### [138] [Sequences of Logits Reveal the Low Rank Structure of Language Models](https://arxiv.org/abs/2510.24966)
*Noah Golowich,Allen Liu,Abhishek Shetty*

Main category: cs.LG

TL;DR: 研究发现语言模型具有低秩结构，可以利用不相关甚至无意义的提示生成线性组合响应，并提出了理论分析和学习保证。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型的固有低维结构是一个重要问题，研究语言模型作为序列概率模型的低维结构。

Method: 通过实证证明现代语言模型具有低秩结构，构建模型logits矩阵并分析其近似秩，利用线性组合生成响应。

Result: 发现广泛的语言模型展示低秩结构，可以利用不相关提示的线性组合生成目标提示的响应。

Conclusion: 语言模型的低秩结构提供了通用抽象，理论预测与实验结果一致，并给出了可证明的学习保证。

Abstract: A major problem in the study of large language models is to understand their
inherent low-dimensional structure. We introduce an approach to study the
low-dimensional structure of language models at a model-agnostic level: as
sequential probabilistic models. We first empirically demonstrate that a wide
range of modern language models exhibit low-rank structure: in particular,
matrices built from the model's logits for varying sets of prompts and
responses have low approximate rank. We then show that this low-rank structure
can be leveraged for generation -- in particular, we can generate a response to
a target prompt using a linear combination of the model's outputs on unrelated,
or even nonsensical prompts.
  On the theoretical front, we observe that studying the approximate rank of
language models in the sense discussed above yields a simple universal
abstraction whose theoretical predictions parallel our experiments. We then
analyze the representation power of the abstraction and give provable learning
guarantees.

</details>


### [139] [Conformational Rank Conditioned Committees for Machine Learning-Assisted Directed Evolution](https://arxiv.org/abs/2510.24974)
*Mia Adler,Carrie Liang,Brian Peng,Oleg Presnyakov,Justin M. Baker,Jannelle Lauffer,Himani Sharma,Barry Merriman*

Main category: cs.LG

TL;DR: 提出了一个基于排名的委员会（RCC）框架，通过为每个构象排名分配深度神经网络委员会，实现了构象不确定性与认知不确定性的原则性分离，在SARS-CoV-2抗体对接中表现优于基线策略。


<details>
  <summary>Details</summary>
Motivation: 现有的结构感知MLDE方法通常依赖单一构象或单一委员会，无法有效分离构象不确定性与认知不确定性，限制了抗体适应性景观的导航效率。

Method: 引入排名条件委员会（RCC）框架，利用排名构象为每个排名分配深度神经网络委员会，实现构象不确定性与认知不确定性的原则性分离。

Result: 在SARS-CoV-2抗体对接验证中，该方法相比基线策略取得了显著改进。

Conclusion: 该框架为治疗性抗体发现提供了可扩展的途径，同时直接解决了构象不确定性建模的挑战。

Abstract: Machine Learning-assisted directed evolution (MLDE) is a powerful tool for
efficiently navigating antibody fitness landscapes. Many structure-aware MLDE
pipelines rely on a single conformation or a single committee across all
conformations, limiting their ability to separate conformational uncertainty
from epistemic uncertainty. Here, we introduce a rank -conditioned committee
(RCC) framework that leverages ranked conformations to assign a deep neural
network committee per rank. This design enables a principled separation between
epistemic uncertainty and conformational uncertainty. We validate our approach
on SARS-CoV-2 antibody docking, demonstrating significant improvements over
baseline strategies. Our results offer a scalable route for therapeutic
antibody discovery while directly addressing the challenge of modeling
conformational uncertainty.

</details>


### [140] [Strategic inputs: feature selection from game-theoretic perspective](https://arxiv.org/abs/2510.24982)
*Chi Zhao,Jing Liu,Elena Parilina*

Main category: cs.LG

TL;DR: 提出基于博弈论的端到端特征选择框架，通过协同交互和边际贡献评估特征重要性，显著降低计算成本同时保持预测性能。


<details>
  <summary>Details</summary>
Motivation: 数据量指数增长导致机器学习训练计算成本激增，许多特征对模型性能无贡献却消耗大量计算资源。

Method: 基于合作博弈论，将特征建模为玩家，通过样本选择、博弈论特征重要性评估、冗余特征消除和优化模型训练四个核心组件实现特征选择。

Result: 实验结果表明该方法在保持预测性能的同时实现了显著的计算减少。

Conclusion: 该框架为大规模机器学习的计算挑战提供了高效解决方案。

Abstract: The exponential growth of data volumes has led to escalating computational
costs in machine learning model training. However, many features fail to
contribute positively to model performance while consuming substantial
computational resources. This paper presents an end-to-end feature selection
framework for tabular data based on game theory. We formulate feature selection
procedure based on a cooperative game where features are modeled as players,
and their importance is determined through the evaluation of synergistic
interactions and marginal contributions. The proposed framework comprises four
core components: sample selection, game-theoretic feature importance
evaluation, redundant feature elimination, and optimized model training.
Experimental results demonstrate that the proposed method achieves substantial
computation reduction while preserving predictive performance, thereby offering
an efficient solution of the computational challenges of large-scale machine
learning. The source code is available at
https://github.com/vectorsss/strategy_inputs.

</details>


### [141] [LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies](https://arxiv.org/abs/2510.24983)
*Ximan Sun,Xiang Cheng*

Main category: cs.LG

TL;DR: LRT-Diffusion是一种用于离线强化学习的风险感知扩散策略，通过似然比检验在采样时提供统计意义上的风险控制，无需改变训练过程。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在采样时通常使用缺乏统计风险概念的启发式方法，需要一种具有可解释风险预算的风险感知采样规则。

Method: 将每个去噪步骤视为无条件先验和状态条件策略头之间的顺序假设检验，累积对数似然比并使用逻辑控制器门控条件均值，阈值τ在校准后满足用户指定的Type-I水平α。

Result: 在D4RL MuJoCo任务中，LRT-Diffusion在保持期望α水平的同时，相比强Q引导基线改善了回报与OOD权衡。

Conclusion: LRT-Diffusion是一种即插即用的推理时方法，为离线RL的扩散策略添加了原则性、校准的风险控制。

Abstract: Diffusion policies are competitive for offline reinforcement learning (RL)
but are typically guided at sampling time by heuristics that lack a statistical
notion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that
treats each denoising step as a sequential hypothesis test between the
unconditional prior and the state-conditional policy head. Concretely, we
accumulate a log-likelihood ratio and gate the conditional mean with a logistic
controller whose threshold tau is calibrated once under H0 to meet a
user-specified Type-I level alpha. This turns guidance from a fixed push into
an evidence-driven adjustment with a user-interpretable risk budget.
Importantly, we deliberately leave training vanilla (two heads with standard
epsilon-prediction) under the structure of DDPM. LRT guidance composes
naturally with Q-gradients: critic-gradient updates can be taken at the
unconditional mean, at the LRT-gated mean, or a blend, exposing a continuum
from exploitation to conservatism. We standardize states and actions
consistently at train and test time and report a state-conditional
out-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks,
LRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines
in our implementation while honoring the desired alpha. Theoretically, we
establish level-alpha calibration, concise stability bounds, and a return
comparison showing when LRT surpasses Q-guidance-especially when off-support
errors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method
that adds principled, calibrated risk control to diffusion policies for offline
RL.

</details>


### [142] [Epileptic Seizure Detection and Prediction from EEG Data: A Machine Learning Approach with Clinical Validation](https://arxiv.org/abs/2510.24986)
*Ria Jayanti,Tanish Jain*

Main category: cs.LG

TL;DR: 该研究提出了一种整合癫痫实时检测和预测的新方法，在CHB-MIT头皮EEG数据库上评估了多种机器学习算法，其中逻辑回归检测准确率达90.9%，LSTM网络预测准确率达89.26%，展示了从被动管理向主动预防癫痫发作的转变潜力。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅在癫痫发作后检测，限制了早期干预机会。本研究旨在开发能同时进行实时癫痫检测和预测的方法，捕捉EEG数据中预示即将发作的微妙时间模式，实现从被动管理向主动预防的转变。

Method: 使用CHB-MIT头皮EEG数据库（969小时记录，173次发作，23名患者）。检测方面采用K近邻、逻辑回归、随机森林和支持向量机等监督学习算法；预测方面采用长短期记忆网络建模EEG数据的时间依赖性。

Result: 逻辑回归检测准确率90.9%，召回率89.6%；随机森林和SVM准确率94.0%但召回率为0%；LSTM预测准确率89.26%。结果表明仅用准确率评估医学ML模型不足，需考虑类别不平衡问题。

Conclusion: 研究证明了开发可访问实时监测工具的潜力，不仅能传统检测癫痫，还能在发作前预测，标志着从被动癫痫管理向主动预防方法的重大转变，让患者能预见发作并采取预防措施降低风险。

Abstract: In recent years, machine learning has become an increasingly powerful tool
for supporting seizure detection and monitoring in epilepsy care. Traditional
approaches focus on identifying seizures only after they begin, which limits
the opportunity for early intervention and proactive treatment. In this study,
we propose a novel approach that integrates both real-time seizure detection
and prediction, aiming to capture subtle temporal patterns in EEG data that may
indicate an upcoming seizure. Our approach was evaluated using the CHB-MIT
Scalp EEG Database, which includes 969 hours of recordings and 173 seizures
collected from 23 pediatric and young adult patients with drug-resistant
epilepsy. To support seizure detection, we implemented a range of supervised
machine learning algorithms, including K-Nearest Neighbors, Logistic
Regression, Random Forest, and Support Vector Machine. The Logistic Regression
achieved 90.9% detection accuracy with 89.6% recall, demonstrating balanced
performance suitable for clinical screening. Random Forest and Support Vector
Machine models achieved higher accuracy (94.0%) but with 0% recall, failing to
detect any seizures, illustrating that accuracy alone is insufficient for
evaluating medical ML models with class imbalance. For seizure prediction, we
employed Long Short-Term Memory (LSTM) networks, which use deep learning to
model temporal dependencies in EEG data. The LSTM model achieved 89.26%
prediction accuracy. These results highlight the potential of developing
accessible, real-time monitoring tools that not only detect seizures as
traditionally done, but also predict them before they occur. This ability to
predict seizures marks a significant shift from reactive seizure management to
a more proactive approach, allowing patients to anticipate seizures and take
precautionary measures to reduce the risk of injury or other complications.

</details>


### [143] [Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series](https://arxiv.org/abs/2510.24988)
*Hemanath Arumugam,Falong Fan,Bo Liu*

Main category: cs.LG

TL;DR: 提出了一种将自监督Transformer变化点检测模块集成到Option-Critic框架中的新架构，通过自适应轨迹分割实现选项发现，在Four-Rooms和Pinball任务中表现出更好的收敛速度和选项专业化。


<details>
  <summary>Details</summary>
Motivation: 解决分层强化学习中自主发现语义有意义的子目标和学习最优选项终止边界的实践挑战。

Method: 集成自监督Transformer变化点检测模块到Option-Critic框架，利用启发式伪标签训练CPD模块推断环境动态的潜在变化，并将这些变化点用于稳定终止函数梯度、预训练内部选项策略和强制功能专业化。

Result: 在Four-Rooms和Pinball任务中，CPD引导的智能体表现出加速收敛、更高累积回报和显著改进的选项专业化。

Conclusion: 通过变化点分割整合结构先验可以在复杂环境中产生更可解释、样本效率更高和更鲁棒的分层策略。

Abstract: Hierarchical Reinforcement Learning (HRL) enhances the scalability of
decision-making in long-horizon tasks by introducing temporal abstraction
through options-policies that span multiple timesteps. Despite its theoretical
appeal, the practical implementation of HRL suffers from the challenge of
autonomously discovering semantically meaningful subgoals and learning optimal
option termination boundaries. This paper introduces a novel architecture that
integrates a self-supervised, Transformer-based Change Point Detection (CPD)
module into the Option-Critic framework, enabling adaptive segmentation of
state trajectories and the discovery of options. The CPD module is trained
using heuristic pseudo-labels derived from intrinsic signals to infer latent
shifts in environment dynamics without external supervision. These inferred
change-points are leveraged in three critical ways: (i) to serve as supervisory
signals for stabilizing termination function gradients, (ii) to pretrain
intra-option policies via segment-wise behavioral cloning, and (iii) to enforce
functional specialization through inter-option divergence penalties over
CPD-defined state partitions. The overall optimization objective enhances the
standard actor-critic loss using structure-aware auxiliary losses. In our
framework, option discovery arises naturally as CPD-defined trajectory segments
are mapped to distinct intra-option policies, enabling the agent to
autonomously partition its behavior into reusable, semantically meaningful
skills. Experiments on the Four-Rooms and Pinball tasks demonstrate that
CPD-guided agents exhibit accelerated convergence, higher cumulative returns,
and significantly improved option specialization. These findings confirm that
integrating structural priors via change-point segmentation leads to more
interpretable, sample-efficient, and robust hierarchical policies in complex
environments.

</details>


### [144] [What Really Matters in Matrix-Whitening Optimizers?](https://arxiv.org/abs/2510.25000)
*Kevin Frans,Pieter Abbeel,Sergey Levine*

Main category: cs.LG

TL;DR: 本文系统解构了矩阵白化优化器，发现其性能优势主要来自方差适应组件而非谱归一化，方差适应版本在各种优化器中都能稳定超越符号下降版本。


<details>
  <summary>Details</summary>
Motivation: 研究各种近似矩阵白化变换的优化器，旨在解释其性能优势的关键组件，特别是澄清谱归一化是否是主要贡献因素。

Method: 通过系统解构矩阵白化优化器，比较不同变体的性能，特别关注方差适应组件的作用，并进行消融实验验证。

Result: 所有矩阵白化方法都稳定优于Adam等逐元素方法，但性能提升主要来自方差适应而非准确的谱归一化，低秩方差估计器能在不损失性能的情况下降低内存成本。

Conclusion: 矩阵白化优化器的性能优势主要归因于方差适应组件，这一被忽视的要素解释了与符号下降方法之间的性能差距。

Abstract: A range of recent optimizers have emerged that approximate the same
"matrix-whitening" transformation in various ways. In this work, we
systematically deconstruct such optimizers, aiming to disentangle the key
components that explain performance. Across tuned hyperparameters across the
board, all flavors of matrix-whitening methods reliably outperform elementwise
counterparts, such as Adam. Matrix-whitening is often related to spectral
descent -- however, experiments reveal that performance gains are *not
explained solely by accurate spectral normalization* -- particularly, SOAP
displays the largest per-step gain, even though Muon more accurately descends
along the steepest spectral descent direction. Instead, we argue that
matrix-whitening serves two purposes, and the variance adaptation component of
matrix-whitening is the overlooked ingredient explaining this performance gap.
Experiments show that variance-adapted versions of optimizers consistently
outperform their sign-descent counterparts, including an adaptive version of
Muon. We further ablate variance adaptation strategies, finding that while
lookahead style approximations are not as effective, low-rank variance
estimators can effectively reduce memory costs without a performance loss.

</details>


### [145] [Disentangling Shared and Private Neural Dynamics with SPIRE: A Latent Modeling Framework for Deep Brain Stimulation](https://arxiv.org/abs/2510.25023)
*Rahil Soroushmojdehi,Sina Javadzadeh,Mehrnaz Asadi,Terence D. Sanger*

Main category: cs.LG

TL;DR: SPIRE是一个深度多编码器自编码器，用于将多区域神经数据分解为共享和私有潜在子空间，通过新颖的对齐和解缠损失来恢复跨区域结构并揭示外部扰动如何重组这些结构。


<details>
  <summary>Details</summary>
Motivation: 解耦共享网络级动态与区域特定活动是建模多区域神经数据的关键挑战，现有方法难以在非线性扭曲和时间错位下有效分离这些成分。

Method: SPIRE采用深度多编码器自编码器架构，引入对齐和解缠损失来分解神经记录，仅使用基线数据进行训练，能够稳健恢复跨区域结构。

Result: 在具有真实潜在变量的合成基准测试中，SPIRE在非线性扭曲和时间错位下优于经典概率模型；在颅内深部脑刺激记录中，共享潜在变量可靠编码刺激特异性特征，跨位点和频率具有泛化性。

Conclusion: SPIRE被确立为分析刺激下多区域神经动态的实用、可复现工具，能够揭示外部扰动如何重组神经网络的共享动态结构。

Abstract: Disentangling shared network-level dynamics from region-specific activity is
a central challenge in modeling multi-region neural data. We introduce SPIRE
(Shared-Private Inter-Regional Encoder), a deep multi-encoder autoencoder that
factorizes recordings into shared and private latent subspaces with novel
alignment and disentanglement losses. Trained solely on baseline data, SPIRE
robustly recovers cross-regional structure and reveals how external
perturbations reorganize it. On synthetic benchmarks with ground-truth latents,
SPIRE outperforms classical probabilistic models under nonlinear distortions
and temporal misalignments. Applied to intracranial deep brain stimulation
(DBS) recordings, SPIRE shows that shared latents reliably encode
stimulation-specific signatures that generalize across sites and frequencies.
These results establish SPIRE as a practical, reproducible tool for analyzing
multi-region neural dynamics under stimulation.

</details>


### [146] [Machine Learning based Analysis for Radiomics Features Robustness in Real-World Deployment Scenarios](https://arxiv.org/abs/2510.25026)
*Sarmad Ahmad Khan,Simon Bernatz,Zahra Moslehi,Florian Buettner*

Main category: cs.LG

TL;DR: 本研究系统评估了基于放射组学的机器学习模型在MRI序列分布偏移下的鲁棒性，发现使用协议不变特征训练的模型在分布偏移下保持F1分数>0.85，而使用所有特征的模型在协议变化下性能下降40%。


<details>
  <summary>Details</summary>
Motivation: 放射组学模型在临床决策支持中具有潜力，但容易受到成像协议、定位和分割变化引起的分布偏移影响，需要系统评估其鲁棒性。

Method: 使用16个水果的体模，评估了五种MRI序列的协议变化、分割变化（完整、部分、旋转）和观察者间变异性的影响。训练XGBoost分类器，比较使用8个一致稳健特征与序列特定特征的性能。

Result: 协议不变特征训练的模型在分布偏移下保持高性能（F1>0.85），而全特征模型在协议变化下性能下降40%。数据集增强显著改善了不确定性估计质量，将预期校准误差降低35%。

Conclusion: 协议感知特征选择和受控体模研究能有效预测模型在分布偏移下的行为，为开发对现实世界协议变化具有鲁棒性的放射组学模型提供了框架。

Abstract: Radiomics-based machine learning models show promise for clinical decision
support but are vulnerable to distribution shifts caused by variations in
imaging protocols, positioning, and segmentation. This study systematically
investigates the robustness of radiomics-based machine learning models under
distribution shifts across five MRI sequences. We evaluated how different
acquisition protocols and segmentation strategies affect model reliability in
terms of predictive power and uncertainty-awareness. Using a phantom of 16
fruits, we evaluated distribution shifts through: (1) protocol variations
across T2-HASTE, T2-TSE, T2-MAP, T1-TSE, and T2-FLAIR sequences; (2)
segmentation variations (full, partial, rotated); and (3) inter-observer
variability. We trained XGBoost classifiers on 8 consistent robust features
versus sequence-specific features, testing model performance under in-domain
and out-of-domain conditions. Results demonstrate that models trained on
protocol-invariant features maintain F1-scores >0.85 across distribution
shifts, while models using all features showed 40% performance degradation
under protocol changes. Dataset augmentation substantially improved the quality
of uncertainty estimates and reduced the expected calibration error (ECE) by
35% without sacrificing accuracy. Temperature scaling provided minimal
calibration benefits, confirming XGBoost's inherent reliability. Our findings
reveal that protocol-aware feature selection and controlled phantom studies
effectively predict model behavior under distribution shifts, providing a
framework for developing robust radiomics models resilient to real-world
protocol variations.

</details>


### [147] [Graph Distance Based on Cause-Effect Estimands with Latents](https://arxiv.org/abs/2510.25037)
*Zhufeng Li,Niki Kilbertus*

Main category: cs.LG

TL;DR: 提出了一种基于因果效应估计任务的ADMG图距离度量方法，用于评估因果发现方法在存在未观测混杂下的性能


<details>
  <summary>Details</summary>
Motivation: 当前因果发现方法难以在存在潜在混杂的情况下进行有效评估，需要一种基于实际因果推断任务的图距离度量

Method: 使用基于fixing的识别方法和符号验证器，量化图差异对不同处理-结果对因果效应估计的影响

Result: 分析了该度量在不同图扰动下的行为，并与现有距离度量进行了比较

Conclusion: 提出的图距离度量能够更好地反映因果发现方法在实际因果推断任务中的性能

Abstract: Causal discovery aims to recover graphs that represent causal relations among
given variables from observations, and new methods are constantly being
proposed. Increasingly, the community raises questions about how much progress
is made, because properly evaluating discovered graphs remains notoriously
difficult, particularly under latent confounding. We propose a graph distance
measure for acyclic directed mixed graphs (ADMGs) based on the downstream task
of cause-effect estimation under unobserved confounding. Our approach uses
identification via fixing and a symbolic verifier to quantify how graph
differences distort cause-effect estimands for different treatment-outcome
pairs. We analyze the behavior of the measure under different graph
perturbations and compare it against existing distance metrics.

</details>


### [148] [Training Across Reservoirs: Using Numerical Differentiation To Couple Trainable Networks With Black-Box Reservoirs](https://arxiv.org/abs/2510.25074)
*Andrew Clark,Jack Moursounidis,Osmaan Rasouli,William Gan,Cooper Doyle,Anna Leontjeva*

Main category: cs.LG

TL;DR: BOND是一种扰动方法，用于估计无法访问计算图的网络结构中的偏导数，相比现有方法具有更高准确性和可扩展性，使集成黑盒函数的可训练架构成为可能。


<details>
  <summary>Details</summary>
Motivation: 探索如何在不增加可训练参数的情况下提升模型性能，通过集成黑盒函数来扩展模型容量，为结合模拟和数字设备扩展网络提供路径。

Method: 提出Bounded Numerical Differentiation (BOND)方法，这是一种扰动方法，用于估计无法访问计算图的网络结构中的偏导数。在实验中，将黑盒函数实现为固定的未训练网络。

Result: BOND相比现有扰动方法具有改进的准确性和可扩展性。集成黑盒函数可以增强模型性能，而不增加可训练参数数量，且无需对黑盒函数本身进行广泛优化。

Conclusion: 利用固定的不可训练模块扩展模型容量具有潜力，为结合模拟和数字设备作为网络扩展机制提供了可行路径。

Abstract: We introduce Bounded Numerical Differentiation (BOND), a perturbative method
for estimating partial derivatives across network structures with inaccessible
computational graphs. BOND demonstrates improved accuracy and scalability from
existing perturbative methods, enabling new explorations of trainable
architectures that integrate black-box functions. We observe that these
black-box functions, realized in our experiments as fixed, untrained networks,
can enhance model performance without increasing the number of trainable
parameters. This improvement is achieved without extensive optimization of the
architecture or properties of the black-box function itself. Our findings
highlight the potential of leveraging fixed, non-trainable modules to expand
model capacity, suggesting a path toward combining analogue and digital devices
as a mechanism for scaling networks.

</details>


### [149] [Continual Low-Rank Adapters for LLM-based Generative Recommender Systems](https://arxiv.org/abs/2510.25093)
*Hyunsik Yoo,Ting-Wei Li,SeongKu Kang,Zhining Liu,Charlie Xu,Qilin Qi,Hanghang Tong*

Main category: cs.LG

TL;DR: PESO是一种用于推荐系统中LoRA持续学习的方法，通过近端正则化来平衡适应性和保持性，更好地捕捉用户最近行为。


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的持续学习方法主要关注保持先前任务的性能，但忽略了推荐系统的特殊性：目标不是预测过去的偏好，过时的偏好在当前兴趣显著变化时甚至会损害性能。

Method: 提出PESO方法，引入近端正则化器，将当前适配器锚定到其最近的冻结状态，使模型能够灵活平衡适应和保持，更好地捕捉最近用户行为。

Result: 理论上证明这种近端设计在LoRA子空间中提供数据感知、方向性指导；实证上PESO持续优于现有基于LoRA的持续学习方法。

Conclusion: PESO通过近端正则化有效解决了推荐系统中LoRA持续学习的挑战，在理论和实证上都表现出优越性能。

Abstract: While large language models (LLMs) achieve strong performance in
recommendation, they face challenges in continual learning as users, items, and
user preferences evolve over time. Existing LoRA-based continual methods
primarily focus on preserving performance on previous tasks, but this overlooks
the unique nature of recommendation: the goal is not to predict past
preferences, and outdated preferences can even harm performance when current
interests shift significantly. To address this, we propose PESO (Proximally
rEgularized Single evolving lOra, a continual adaptation method for LoRA in
recommendation. PESO introduces a proximal regularizer that anchors the current
adapter to its most recent frozen state, enabling the model to flexibly balance
adaptation and preservation, and to better capture recent user behaviors.
Theoretically, we show that this proximal design provides data-aware,
direction-wise guidance in the LoRA subspace. Empirically, PESO consistently
outperforms existing LoRA-based continual learning methods.

</details>


### [150] [Learning Fair Graph Representations with Multi-view Information Bottleneck](https://arxiv.org/abs/2510.25096)
*Chuxun Liu,Debo Cheng,Qingfeng Chen,Jiangzhang Gan,Jiuyong Li,Lin Liu*

Main category: cs.LG

TL;DR: FairMIB是一个多视图信息瓶颈框架，通过分解图的特征、结构和扩散视图来缓解图神经网络中的复杂性偏见，使用对比学习和条件信息瓶颈来平衡任务效用和公平性。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在处理关系数据时会放大训练数据偏见，传播歧视性属性和结构不平衡，导致不公平结果。现有方法通常将偏见视为单一来源，忽略了属性和结构的不同影响，导致公平性和效用之间的权衡不理想。

Method: 提出FairMIB框架：1）将图分解为特征、结构和扩散三个视图；2）使用对比学习最大化跨视图互信息以学习无偏见表示；3）集成多视角条件信息瓶颈目标来平衡任务效用和公平性；4）在扩散视图中引入逆概率加权邻接校正来减少偏见传播。

Result: 在五个真实世界基准数据集上的实验表明，FairMIB在效用和公平性指标上都达到了最先进的性能。

Conclusion: FairMIB通过多视图分解和信息瓶颈方法有效缓解了图神经网络中的偏见传播问题，在保持任务效用的同时显著提高了公平性。

Abstract: Graph neural networks (GNNs) excel on relational data by passing messages
over node features and structure, but they can amplify training data biases,
propagating discriminatory attributes and structural imbalances into unfair
outcomes. Many fairness methods treat bias as a single source, ignoring
distinct attribute and structure effects and leading to suboptimal fairness and
utility trade-offs. To overcome this challenge, we propose FairMIB, a
multi-view information bottleneck framework designed to decompose graphs into
feature, structural, and diffusion views for mitigating complexity biases in
GNNs. Especially, the proposed FairMIB employs contrastive learning to maximize
cross-view mutual information for bias-free representation learning. It further
integrates multi-perspective conditional information bottleneck objectives to
balance task utility and fairness by minimizing mutual information with
sensitive attributes. Additionally, FairMIB introduces an inverse
probability-weighted (IPW) adjacency correction in the diffusion view, which
reduces the spread of bias propagation during message passing. Experiments on
five real-world benchmark datasets demonstrate that FairMIB achieves
state-of-the-art performance across both utility and fairness metrics.

</details>


### [151] [Shift is Good: Mismatched Data Mixing Improves Test Performance](https://arxiv.org/abs/2510.25108)
*Marko Medvedev,Kaifeng Lyu,Zhiyuan Li,Nathan Srebro*

Main category: cs.LG

TL;DR: 该论文研究了训练和测试在不同混合分布比例下的情况，发现在许多设置中分布偏移可能是有益的，即使组件之间没有关联和迁移，测试性能仍可能因训练比例不匹配而提升。


<details>
  <summary>Details</summary>
Motivation: 探索分布偏移对模型性能的影响，挑战传统认为训练和测试分布应该匹配的观点，研究在什么情况下分布偏移反而能带来性能提升。

Method: 通过理论分析和多种场景下的实验，识别最优训练比例，并量化分布偏移可能带来的益处程度。

Result: 发现在许多情况下分布偏移确实可以改善测试性能，确定了最优训练比例，并展示了这种分析也适用于具有不同组件"技能"分布的组合设置。

Conclusion: 分布偏移在特定条件下可以是有益的，而非总是有害的，这为机器学习训练策略提供了新的视角和可能性。

Abstract: We consider training and testing on mixture distributions with different
training and test proportions. We show that in many settings, and in some sense
generically, distribution shift can be beneficial, and test performance can
improve due to mismatched training proportions, even if the components are
unrelated and with no transfer between components. In a variety of scenarios,
we identify the optimal training proportions and the extent to which such
distribution shift can be beneficial. We show how the same analysis applies
also to a compositional setting with differing distribution of component
"skills'' at training and test.

</details>


### [152] [The Neural Differential Manifold: An Architecture with Explicit Geometric Structure](https://arxiv.org/abs/2510.25113)
*Di Zhang*

Main category: cs.LG

TL;DR: 提出了神经微分流形(NDM)架构，将神经网络重新概念化为可微分流形，其中层作为局部坐标图，参数直接参数化黎曼度量张量，通过几何正则化提升泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络使用欧几里得参数空间，缺乏几何结构。NDM旨在将几何结构显式融入网络设计，提供内在正则化、更好的优化效率和可解释性。

Method: 采用三层架构：坐标层（通过可逆变换实现平滑图表转换）、几何层（通过辅助子网络动态生成流形度量）、演化层（通过双目标损失函数优化任务性能和几何简洁性）。

Result: 该框架支持与学习流形几何对齐的自然梯度下降优化，通过惩罚过度曲率和体积失真提供内在正则化，增强泛化能力和鲁棒性。

Conclusion: 神经微分流形代表了向几何结构化、可解释且高效深度学习系统的根本性转变，虽然存在计算挑战，但在优化效率、持续学习和科学发现方面具有潜力。

Abstract: This paper introduces the Neural Differential Manifold (NDM), a novel neural
network architecture that explicitly incorporates geometric structure into its
fundamental design. Departing from conventional Euclidean parameter spaces, the
NDM re-conceptualizes a neural network as a differentiable manifold where each
layer functions as a local coordinate chart, and the network parameters
directly parameterize a Riemannian metric tensor at every point. The
architecture is organized into three synergistic layers: a Coordinate Layer
implementing smooth chart transitions via invertible transformations inspired
by normalizing flows, a Geometric Layer that dynamically generates the
manifold's metric through auxiliary sub-networks, and an Evolution Layer that
optimizes both task performance and geometric simplicity through a
dual-objective loss function. This geometric regularization penalizes excessive
curvature and volume distortion, providing intrinsic regularization that
enhances generalization and robustness. The framework enables natural gradient
descent optimization aligned with the learned manifold geometry and offers
unprecedented interpretability by endowing internal representations with clear
geometric meaning. We analyze the theoretical advantages of this approach,
including its potential for more efficient optimization, enhanced continual
learning, and applications in scientific discovery and controllable generative
modeling. While significant computational challenges remain, the Neural
Differential Manifold represents a fundamental shift towards geometrically
structured, interpretable, and efficient deep learning systems.

</details>


### [153] [A Unified Bilevel Model for Adversarial Learning and A Case Study](https://arxiv.org/abs/2510.25121)
*Yutong Zheng,Qingna Li*

Main category: cs.LG

TL;DR: 提出了一个统一的对抗学习双层模型，从数据扰动角度解释聚类模型中的对抗攻击机制，并分析了δ度量在聚类模型攻击效果评估中的适用性。


<details>
  <summary>Details</summary>
Motivation: 由于机器学习模型结构复杂，对抗攻击机制缺乏清晰解释，攻击效果评估方法不明确，需要建立统一的对抗学习框架。

Method: 提出统一的对抗学习双层模型，从数据扰动角度分析聚类模型的对抗攻击，研究δ度量在聚类模型攻击效果评估中的适用性。

Result: 发现当数据扰动较小时聚类模型具有鲁棒性，当扰动较大时聚类结果会改变从而形成攻击，验证了δ度量在聚类模型对抗学习中的适用性。

Conclusion: 建立了对抗学习的统一框架，阐明了聚类模型中对抗攻击的数据扰动机制，为聚类模型的对抗学习提供了有效的评估方法。

Abstract: Adversarial learning has been attracting more and more attention thanks to
the fast development of machine learning and artificial intelligence. However,
due to the complicated structure of most machine learning models, the mechanism
of adversarial attacks is not well interpreted. How to measure the effect of
attack is still not quite clear. In this paper, we propose a unified bilevel
model for adversarial learning. We further investigate the adversarial attack
in clustering models and interpret it from data perturbation point of view. We
reveal that when the data perturbation is relatively small, the clustering
model is robust, whereas if it is relatively large, the clustering result
changes, which leads to an attack. To measure the effect of attacks for
clustering models, we analyse the well-definedness of the so-called
$\delta$-measure, which can be used in the proposed bilevel model for
adversarial learning of clustering models.

</details>


### [154] [Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics from Data](https://arxiv.org/abs/2510.25123)
*Woojin Cho,Kookjin Lee,Noseong Park,Donsub Rim,Gerrit Welper*

Main category: cs.LG

TL;DR: 提出一种基于数据驱动的降维方法，专门用于处理双曲波传播的物理数据，通过低秩神经网络表示(LRNR)在超网络框架中实现高效表示。


<details>
  <summary>Details</summary>
Motivation: 针对双曲波传播这类物理数据，理论已证明存在高效表示方法，但需要开发能够直接从数据中学习这种低维表示的实际算法。

Method: 使用低秩神经网络表示(LRNR)架构，结合深度学习技术，在超网络框架中学习波传播的低维表示。

Result: 训练后的LRNR自然产生低秩张量表示，揭示了波传播的新分解方式，每个分解模式对应可解释的物理特征，并支持通过压缩方案实现高效推理。

Conclusion: LRNR架构能够直接从数据中学习双曲波传播的高效低维表示，不仅提供物理可解释性，还能在性能要求高的场景中实现高效部署。

Abstract: We present a data-driven dimensionality reduction method that is well-suited
for physics-based data representing hyperbolic wave propagation. The method
utilizes a specialized neural network architecture called low rank neural
representation (LRNR) inside a hypernetwork framework. The architecture is
motivated by theoretical results that rigorously prove the existence of
efficient representations for this wave class. We illustrate through archetypal
examples that such an efficient low-dimensional representation of propagating
waves can be learned directly from data through a combination of deep learning
techniques. We observe that a low rank tensor representation arises naturally
in the trained LRNRs, and that this reveals a new decomposition of wave
propagation where each decomposed mode corresponds to interpretable physical
features. Furthermore, we demonstrate that the LRNR architecture enables
efficient inference via a compression scheme, which is a potentially important
feature when deploying LRNRs in demanding performance regimes.

</details>


### [155] [Bridging the Divide: End-to-End Sequence-Graph Learning](https://arxiv.org/abs/2510.25126)
*Yuen Chen,Yulun Wu,Samuel Sharpe,Igor Melnyk,Nam H. Nguyen,Furong Huang,C. Bayan Bruss,Rizal Fathony*

Main category: cs.LG

TL;DR: BRIDGE是一个统一的端到端架构，将序列编码器与图神经网络结合，通过token级交叉注意力层实现邻居间细粒度消息传递，在社交网络和欺诈检测任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集通常同时具有序列性和关系性，但现有方法往往忽略其中一种模态。作者认为序列和图不是分离的问题，而是同一数据集的互补方面，应该联合学习。

Method: 提出BRIDGE架构，将序列编码器与GNN在单一目标下耦合，允许梯度在两者间流动。添加TOKENXATTN层实现邻居序列间事件级的细粒度消息传递。

Result: 在友谊预测（Brightkite）和欺诈检测（Amazon）两个场景中，BRIDGE在排序和分类指标上持续优于静态GNN、时序图方法和纯序列基线。

Conclusion: 序列和图应该联合建模，BRIDGE通过统一的端到端架构实现了这一目标，在多个实际任务中表现出色。

Abstract: Many real-world datasets are both sequential and relational: each node
carries an event sequence while edges encode interactions. Existing methods in
sequence modeling and graph modeling often neglect one modality or the other.
We argue that sequences and graphs are not separate problems but complementary
facets of the same dataset, and should be learned jointly. We introduce BRIDGE,
a unified end-to-end architecture that couples a sequence encoder with a GNN
under a single objective, allowing gradients to flow across both modules and
learning task-aligned representations. To enable fine-grained token-level
message passing among neighbors, we add TOKENXATTN, a token-level
cross-attention layer that passes messages between events in neighboring
sequences. Across two settings, friendship prediction (Brightkite) and fraud
detection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph
methods, and sequence-only baselines on ranking and classification metrics.

</details>


### [156] [An Analysis of Causal Effect Estimation using Outcome Invariant Data Augmentation](https://arxiv.org/abs/2510.25128)
*Uzair Akbar,Niki Kilbertus,Hao Shen,Krikamol Muandet,Bo Dai*

Main category: cs.LG

TL;DR: 该论文提出了一个统一框架，将数据增强与因果推断结合，证明当结果生成机制对数据增强选择不变时，数据增强可视为对治疗生成机制的干预，有助于减少隐藏混杂因素带来的因果效应估计偏差。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强主要用于i.i.d.设置下的正则化，但工具变量在许多应用中不易获得。本文旨在探索数据增强在跨干预泛化中的应用，特别是在存在未观测混杂的情况下。

Method: 通过适当正则化基于工具变量的估计器，引入IV-like回归概念来缓解混杂偏差；将参数化数据增强建模为IV-like回归问题，并通过组合模拟最坏情况的数据增强应用。

Result: 理论和模拟实验表明，该方法在因果估计和泛化任务上优于简单的数据增强，在线性示例的有限样本情况下得到验证，并通过真实数据实验支持。

Conclusion: 数据增强可有效用于跨干预泛化，特别是在工具变量不可得时，通过IV-like回归框架能显著改善因果效应估计和预测性能。

Abstract: The technique of data augmentation (DA) is often used in machine learning for
regularization purposes to better generalize under i.i.d. settings. In this
work, we present a unifying framework with topics in causal inference to make a
case for the use of DA beyond just the i.i.d. setting, but for generalization
across interventions as well. Specifically, we argue that when the outcome
generating mechanism is invariant to our choice of DA, then such augmentations
can effectively be thought of as interventions on the treatment generating
mechanism itself. This can potentially help to reduce bias in causal effect
estimation arising from hidden confounders. In the presence of such unobserved
confounding we typically make use of instrumental variables (IVs) -- sources of
treatment randomization that are conditionally independent of the outcome.
However, IVs may not be as readily available as DA for many applications, which
is the main motivation behind this work. By appropriately regularizing IV based
estimators, we introduce the concept of IV-like (IVL) regression for mitigating
confounding bias and improving predictive performance across interventions even
when certain IV properties are relaxed. Finally, we cast parameterized DA as an
IVL regression problem and show that when used in composition can simulate a
worst-case application of such DA, further improving performance on causal
estimation and generalization tasks beyond what simple DA may offer. This is
shown both theoretically for the population case and via simulation experiments
for the finite sample case using a simple linear example. We also present real
data experiments to support our case.

</details>


### [157] [Lipschitz-aware Linearity Grafting for Certified Robustness](https://arxiv.org/abs/2510.25130)
*Yongjin Han,Suhyun Kim*

Main category: cs.LG

TL;DR: 本文提出了一种Lipschitz感知的线性嫁接方法，通过将非线性激活函数替换为线性函数来消除近似误差，从而获得更紧的局部Lipschitz常数并提高认证鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在神经网络验证中面临近似误差问题，这些误差阻碍了获得紧的局部Lipschitz常数，而紧的Lipschitz常数对于认证鲁棒性至关重要。线性嫁接可以消除近似误差，但缺乏理论分析。

Method: 提出Lipschitz感知的线性嫁接方法，将非线性激活函数替换为线性函数，消除主导的近似误差源，从而获得更紧的局部Lipschitz常数。

Result: 实验表明，在线性嫁接有影响力的激活函数后，能够收紧l∞局部Lipschitz常数并增强认证鲁棒性，即使没有进行认证训练。

Conclusion: 线性嫁接通过消除近似误差来收紧局部Lipschitz常数，是提高认证鲁棒性的有效方法，为理解线性嫁接如何改善认证鲁棒性提供了理论依据。

Abstract: Lipschitz constant is a fundamental property in certified robustness, as
smaller values imply robustness to adversarial examples when a model is
confident in its prediction. However, identifying the worst-case adversarial
examples is known to be an NP-complete problem. Although over-approximation
methods have shown success in neural network verification to address this
challenge, reducing approximation errors remains a significant obstacle.
Furthermore, these approximation errors hinder the ability to obtain tight
local Lipschitz constants, which are crucial for certified robustness.
Originally, grafting linearity into non-linear activation functions was
proposed to reduce the number of unstable neurons, enabling scalable and
complete verification. However, no prior theoretical analysis has explained how
linearity grafting improves certified robustness. We instead consider linearity
grafting primarily as a means of eliminating approximation errors rather than
reducing the number of unstable neurons, since linear functions do not require
relaxation. In this paper, we provide two theoretical contributions: 1) why
linearity grafting improves certified robustness through the lens of the
$l_\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear
activation functions, the dominant source of approximation errors, yields a
tighter local Lipschitz constant. Based on these theoretical contributions, we
propose a Lipschitz-aware linearity grafting method that removes dominant
approximation errors, which are crucial for tightening the local Lipschitz
constant, thereby improving certified robustness, even without certified
training. Our extensive experiments demonstrate that grafting linearity into
these influential activations tightens the $l_\infty$ local Lipschitz constant
and enhances certified robustness.

</details>


### [158] [Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization](https://arxiv.org/abs/2510.25616)
*Nikita Kachaev,Mikhail Kolosov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 本文系统研究了视觉-语言-动作(VLA)模型在动作微调过程中的表征保留问题，发现简单的动作微调会导致视觉表征退化，并提出了一种简单有效的方法来缓解这种退化，提高对分布外场景的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究VLA模型在动作微调过程中，预训练的视觉语言模型(VLMs)原有的视觉语言表征和知识在多大程度上被保留，因为不清楚动作微调是否会导致这些重要能力的退化。

Method: 通过探测VLA模型的隐藏表征和分析注意力图，设计了一组针对性任务和方法来对比VLA模型与对应VLMs，分离出动作微调引起的视觉语言能力变化，并评估了多种视觉表征对齐策略。

Result: 发现简单的动作微调会导致视觉表征退化，提出的简单方法能够有效缓解这种退化，并在分布外场景中展现出更好的泛化能力。

Conclusion: 阐明了动作微调与视觉语言表征退化之间的权衡关系，并提出了实用的方法来恢复继承的视觉语言能力。

Abstract: The growing success of Vision-Language-Action (VLA) models stems from the
promise that pretrained Vision-Language Models (VLMs) can endow agents with
transferable world knowledge and vision-language (VL) grounding, laying a
foundation for action models with broader generalization. Yet when these VLMs
are adapted to the action modality, it remains unclear to what extent their
original VL representations and knowledge are preserved. In this work, we
conduct a systematic study of representation retention during VLA fine-tuning,
showing that naive action fine-tuning leads to degradation of visual
representations. To characterize and measure these effects, we probe VLA's
hidden representations and analyze attention maps, further, we design a set of
targeted tasks and methods that contrast VLA models with their counterpart
VLMs, isolating changes in VL capabilities induced by action fine-tuning. We
further evaluate a range of strategies for aligning visual representations and
introduce a simple yet effective method that mitigates degradation and yields
improved generalization to out-of-distribution (OOD) scenarios. Taken together,
our analysis clarifies the trade-off between action fine-tuning and the
degradation of VL representations and highlights practical approaches to
recover inherited VL capabilities. Code is publicly available:
https://blind-vla-paper.github.io

</details>


### [159] [Machine Learning Guided Optimal Transmission Switching to Mitigate Wildfire Ignition Risk](https://arxiv.org/abs/2510.25147)
*Weimin Huang,Ryan Piansky,Bistra Dilkina,Daniel K. Molzahn*

Main category: cs.LG

TL;DR: 提出一种机器学习引导的框架，用于快速解决最优停电问题，通过利用问题实例间的共享模式，结合领域知识来加速混合整数线性规划求解。


<details>
  <summary>Details</summary>
Motivation: 为了缓解野火点燃风险，电力公司需要在高风险区域断电。最优停电问题是计算复杂的混合整数线性规划，需要在操作环境中快速频繁求解。由于问题实例具有共同结构但参数变化，这为使用机器学习方法提供了动机。

Method: 开发了机器学习引导的框架，扩展现有的ML引导MILP求解方法，同时整合了关于通电和断电线路数量的领域知识。

Result: 在加州大型合成测试系统上的结果显示，所提出的ML引导方法比传统优化方法更快地产生高质量解。

Conclusion: 机器学习引导的方法能够有效加速最优停电问题的求解，在保持解质量的同时显著提高计算效率。

Abstract: To mitigate acute wildfire ignition risks, utilities de-energize power lines
in high-risk areas. The Optimal Power Shutoff (OPS) problem optimizes line
energization statuses to manage wildfire ignition risks through
de-energizations while reducing load shedding. OPS problems are computationally
challenging Mixed-Integer Linear Programs (MILPs) that must be solved rapidly
and frequently in operational settings. For a particular power system, OPS
instances share a common structure with varying parameters related to wildfire
risks, loads, and renewable generation. This motivates the use of Machine
Learning (ML) for solving OPS problems by exploiting shared patterns across
instances. In this paper, we develop an ML-guided framework that quickly
produces high-quality de-energization decisions by extending existing ML-guided
MILP solution methods while integrating domain knowledge on the number of
energized and de-energized lines. Results on a large-scale realistic
California-based synthetic test system show that the proposed ML-guided method
produces high-quality solutions faster than traditional optimization methods.

</details>


### [160] [Selective Learning for Deep Time Series Forecasting](https://arxiv.org/abs/2510.25207)
*Yisong Fu,Zezhi Shao,Chengqing Yu,Yujie Li,Zhulin An,Qi Wang,Yongjun Xu,Fei Wang*

Main category: cs.LG

TL;DR: 提出了一种用于深度时间序列预测的选择性学习策略，通过双重掩码机制筛选可泛化的时间步，避免对不确定和异常时间步的过拟合。


<details>
  <summary>Details</summary>
Motivation: 深度模型在时间序列预测中容易因噪声和异常导致严重过拟合，传统方法对所有时间步进行统一优化，无法区分不确定和异常时间步。

Method: 使用双重掩码机制：不确定性掩码利用残差熵过滤不确定时间步，异常掩码使用残差下界估计排除异常时间步，只对筛选出的时间步计算MSE损失。

Result: 在8个真实世界数据集上的实验表明，该方法显著提升了主流深度模型的预测性能，使Informer的MSE降低37.4%，TimesNet降低8.4%，iTransformer降低6.5%。

Conclusion: 选择性学习策略能有效缓解深度时间序列预测中的过拟合问题，通过关注可泛化时间步来提升模型性能。

Abstract: Benefiting from high capacity for capturing complex temporal patterns, deep
learning (DL) has significantly advanced time series forecasting (TSF).
However, deep models tend to suffer from severe overfitting due to the inherent
vulnerability of time series to noise and anomalies. The prevailing DL paradigm
uniformly optimizes all timesteps through the MSE loss and learns those
uncertain and anomalous timesteps without difference, ultimately resulting in
overfitting. To address this, we propose a novel selective learning strategy
for deep TSF. Specifically, selective learning screens a subset of the whole
timesteps to calculate the MSE loss in optimization, guiding the model to focus
on generalizable timesteps while disregarding non-generalizable ones. Our
framework introduces a dual-mask mechanism to target timesteps: (1) an
uncertainty mask leveraging residual entropy to filter uncertain timesteps, and
(2) an anomaly mask employing residual lower bound estimation to exclude
anomalous timesteps. Extensive experiments across eight real-world datasets
demonstrate that selective learning can significantly improve the predictive
performance for typical state-of-the-art deep models, including 37.4% MSE
reduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer.

</details>


### [161] [Cost-Sensitive Unbiased Risk Estimation for Multi-Class Positive-Unlabeled Learning](https://arxiv.org/abs/2510.25226)
*Miao Zhang,Junpeng Li,Changchun Hua,Yana Yang*

Main category: cs.LG

TL;DR: 提出了一种基于自适应损失加权的多类正-无标记学习方法，通过为正向和推断负向损失分配数据依赖权重，实现无偏风险估计，在多个数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 多类正-无标记学习场景中，许多现有方法无法保证无偏风险估计，限制了性能和稳定性。现实应用中标注可靠负样本困难且成本高。

Method: 在经验风险最小化框架下，为正向和从无标记混合数据中推断的负向损失分量分配不同的数据依赖权重，使经验目标成为目标风险的无偏估计器。

Result: 在八个公共数据集上进行广泛实验，涵盖不同类别先验和类别数量，在准确性和稳定性方面均优于强基线方法。

Conclusion: 提出的自适应损失加权方法在多类正-无标记学习中实现了无偏风险估计，具有一致的性能提升和稳定性优势。

Abstract: Positive--Unlabeled (PU) learning considers settings in which only positive
and unlabeled data are available, while negatives are missing or left
unlabeled. This situation is common in real applications where annotating
reliable negatives is difficult or costly. Despite substantial progress in PU
learning, the multi-class case (MPU) remains challenging: many existing
approaches do not ensure \emph{unbiased risk estimation}, which limits
performance and stability. We propose a cost-sensitive multi-class PU method
based on \emph{adaptive loss weighting}. Within the empirical risk minimization
framework, we assign distinct, data-dependent weights to the positive and
\emph{inferred-negative} (from the unlabeled mixture) loss components so that
the resulting empirical objective is an unbiased estimator of the target risk.
We formalize the MPU data-generating process and establish a generalization
error bound for the proposed estimator. Extensive experiments on \textbf{eight}
public datasets, spanning varying class priors and numbers of classes, show
consistent gains over strong baselines in both accuracy and stability.

</details>


### [162] [BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network Training](https://arxiv.org/abs/2510.25244)
*Wenjie Zhou,Bohan Wang,Wei Chen,Xueqi Cheng*

Main category: cs.LG

TL;DR: 该论文提出了Bulk-Space-Filtration-Accelerator (BSFA)框架，通过差异化缩放不同子空间的更新分量来加速深度学习训练，在Dom-space中稳定更新，在Bulk-space中放大更新以提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习优化中的基本二分法：沿损失Hessian顶部特征方向的参数更新（Dom-space）虽然幅度大但对损失减少贡献小，而正交分量（Bulk-space）的更新幅度小但驱动大部分学习进展。

Method: 提出BSFA框架，使用PCA对历史更新进行高效子空间估计，并采用分块策略在参数块基础上应用估计，差异化缩放不同子空间的更新分量。

Result: 在各种任务中展示了BSFA的加速效果，特别是在WikiText-103上预训练LLaMA-72M和在OpenWebText上预训练LLaMA-134M时，相比vanilla AdamW实现了约2倍的加速。

Conclusion: BSFA是一个实用且可扩展的即插即用框架，能够有效加速深度学习训练，同时保持计算可行性。

Abstract: Recent studies \citep{gur2018gradient,song2024does, wen2024understanding}
highlight a fundamental dichotomy in deep learning optimization: Although
parameter updates along the top eigendirections of the loss Hessian (Dom-space)
capture most of the update magnitude, they often contribute minimally to loss
reduction. In contrast, updates in the orthogonal component (Bulk-space) have
smaller magnitudes but drive most learning progress. In this work, we further
advance the understanding of this phenomenon and introduce the
\textbf{Bulk-Space-Filtration-Accelerator (BSFA)}, a novel plug-and-play
framework. BSFA accelerates training by differentially scaling update
components projected onto these distinct subspaces, simultaneously enhancing
stability by moderating updates in the dominant subspace and boosting
convergence speed by amplifying those in the bulk-space. To ensure BSFA is both
practical and scalable for contemporary large models, we introduce two key
innovations: an efficient estimator using Principal Component Analysis (PCA) on
historical updates for fast subspace estimation, and a block-wise strategy that
applies this estimation on a per-parameter-block basis. These designs make BSFA
computationally tractable and highly effective. We demonstrate BSFA's
acceleration across various tasks, notably achieving approximately 2$\times$
speedup when pre-training LLaMA-72M on WikiText-103 and LLaMA-134M on
OpenWebText compared to vanilla AdamW.

</details>


### [163] [Scaling Up Bayesian DAG Sampling](https://arxiv.org/abs/2510.25254)
*Daniele Nikzad,Alexander Zhilkin,Juha Harviainen,Jack Kuipers,Giusi Moffa,Mikko Koivisto*

Main category: cs.LG

TL;DR: 本文提出了两种改进贝叶斯网络结构采样效率的技术：高效实现基本移动操作，以及通过预处理方法近似保留父集求和的加速方法。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯网络结构推断通常通过马尔可夫链采样进行，但现有方法在采样效率方面存在不足，需要更高效的技术来改进采样过程。

Method: 1. 高效实现基本移动操作（添加、删除或反转单条边）
2. 设计预处理方法来修剪可能的父集，近似保留求和结果，加速更复杂移动操作中的父集求和计算

Result: 实证研究表明，与先前方法相比，所提出的技术能够带来显著的效率提升。

Conclusion: 本文提出的两种技术有效提高了贝叶斯网络结构采样的效率，为贝叶斯推断提供了更实用的工具。

Abstract: Bayesian inference of Bayesian network structures is often performed by
sampling directed acyclic graphs along an appropriately constructed Markov
chain. We present two techniques to improve sampling. First, we give an
efficient implementation of basic moves, which add, delete, or reverse a single
arc. Second, we expedite summing over parent sets, an expensive task required
for more sophisticated moves: we devise a preprocessing method to prune
possible parent sets so as to approximately preserve the sums. Our empirical
study shows that our techniques can yield substantial efficiency gains compared
to previous methods.

</details>


### [164] [IBNorm: Information-Bottleneck Inspired Normalization for Representation Learning](https://arxiv.org/abs/2510.25262)
*Xiandong Zou,Pan Zhou*

Main category: cs.LG

TL;DR: 提出IB-Inspired Normalization (IBNorm)，一种基于信息瓶颈原理的归一化方法，通过有界压缩操作鼓励嵌入保留预测信息同时抑制无关变异性，在语言和视觉模型中优于BatchNorm、LayerNorm和RMSNorm。


<details>
  <summary>Details</summary>
Motivation: 现有归一化方法如BatchNorm、LayerNorm和RMSNorm都是方差中心的，强制零均值和单位方差来稳定训练，但没有控制表示如何捕获任务相关信息。

Method: 基于信息瓶颈原理，引入有界压缩操作，鼓励嵌入在保留预测信息的同时抑制无关变异性。

Result: 在大型语言模型(LLaMA、GPT-2)和视觉模型(ResNet、ViT)中持续优于BatchNorm、LayerNorm和RMSNorm，互信息分析证实了更优的信息瓶颈行为。

Conclusion: IBNorm在保持标准归一化稳定性和兼容性的同时，能产生更具信息性的表示，理论上实现更高的IB值和更紧的泛化边界。

Abstract: Normalization is fundamental to deep learning, but existing approaches such
as BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero
mean and unit variance, stabilizing training without controlling how
representations capture task-relevant information. We propose IB-Inspired
Normalization (IBNorm), a simple yet powerful family of methods grounded in the
Information Bottleneck principle. IBNorm introduces bounded compression
operations that encourage embeddings to preserve predictive information while
suppressing nuisance variability, yielding more informative representations
while retaining the stability and compatibility of standard normalization.
Theoretically, we prove that IBNorm achieves a higher IB value and tighter
generalization bounds than variance-centric methods. Empirically, IBNorm
consistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale
language models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual
information analysis confirming superior information bottleneck behavior. Code
will be released publicly.

</details>


### [165] [On the Stability of Neural Networks in Deep Learning](https://arxiv.org/abs/2510.25282)
*Blaise Delattre*

Main category: cs.LG

TL;DR: 该论文通过敏感性分析的统一视角解决深度学习模型的不稳定性和脆弱性问题，结合Lipschitz网络、随机平滑和曲率正则化来提升模型的稳定性、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型对输入的小变化敏感且优化过程受尖锐损失景观阻碍，需要系统性解决模型的不稳定性和脆弱性问题。

Method: 采用Lipschitz网络约束输入扰动敏感性，引入基于损失函数曲率的正则化技术，探索随机平滑方法，并开发统一框架整合这些技术。

Result: 开发了高效谱范数计算、新型Lipschitz约束层和改进的认证程序，为深度学习稳定性提供了理论和实践贡献。

Conclusion: 通过整合Lipschitz连续性、随机平滑和曲率正则化，建立了一个统一框架来系统性解决深度学习中的稳定性挑战。

Abstract: Deep learning has achieved remarkable success across a wide range of tasks,
but its models often suffer from instability and vulnerability: small changes
to the input may drastically affect predictions, while optimization can be
hindered by sharp loss landscapes. This thesis addresses these issues through
the unifying perspective of sensitivity analysis, which examines how neural
networks respond to perturbations at both the input and parameter levels.
  We study Lipschitz networks as a principled way to constrain sensitivity to
input perturbations, thereby improving generalization, adversarial robustness,
and training stability. To complement this architectural approach, we introduce
regularization techniques based on the curvature of the loss function,
promoting smoother optimization landscapes and reducing sensitivity to
parameter variations. Randomized smoothing is also explored as a probabilistic
method for enhancing robustness at decision boundaries.
  By combining these perspectives, we develop a unified framework where
Lipschitz continuity, randomized smoothing, and curvature regularization
interact to address fundamental challenges in stability. The thesis contributes
both theoretical analysis and practical methodologies, including efficient
spectral norm computation, novel Lipschitz-constrained layers, and improved
certification procedures.

</details>


### [166] [Hierarchical Physics-Embedded Learning for Spatiotemporal Dynamical Systems](https://arxiv.org/abs/2510.25306)
*Xizhe Wang,Xiaobin Song,Qingshan Jia,Hongbo Zhao,Benben Jiang*

Main category: cs.LG

TL;DR: 提出了一种分层物理嵌入学习框架，用于从稀疏噪声数据中预测时空动态和发现物理定律。该框架采用两级架构，第一级学习PDE的基本符号组件，第二级学习它们的组合，从而降低学习复杂度并保证物理一致性。


<details>
  <summary>Details</summary>
Motivation: 复杂时空动态建模是科学中的重大挑战，传统方法存在物理不一致、数据需求大或结构能力不足的问题。需要一种能系统整合部分物理知识并保证物理一致性的方法。

Method: 基于自适应傅里叶神经算子的分层架构，第一级学习PDE基本符号组件，第二级学习组合方式。已知物理定律直接嵌入计算图，未知部分通过符号回归发现。

Result: 该框架能有效捕捉非局部依赖和高阶算子，保证物理一致性，提高数据效率，并实现可解释的物理定律发现。

Conclusion: 分层物理嵌入学习框架为复杂时空动态建模提供了新范式，既能保证物理一致性，又能从稀疏噪声数据中发现未知物理定律。

Abstract: Modeling complex spatiotemporal dynamics, particularly in
far-from-equilibrium systems, remains a grand challenge in science. The
governing partial differential equations (PDEs) for these systems are often
intractable to derive from first principles, due to their inherent complexity,
characterized by high-order derivatives and strong nonlinearities, coupled with
incomplete physical knowledge. This has spurred the development of data-driven
methods, yet these approaches face limitations: Purely data-driven models are
often physically inconsistent and data-intensive, while existing
physics-informed methods lack the structural capacity to represent complex
operators or systematically integrate partial physical knowledge. Here, we
propose a hierarchical physics-embedded learning framework that fundamentally
advances both the forward spatiotemporal prediction and inverse discovery of
physical laws from sparse and noisy data. The key innovation is a two-level
architecture that mirrors the process of scientific discovery: the first level
learns fundamental symbolic components of a PDE, while the second learns their
governing combinations. This hierarchical decomposition not only reduces
learning complexity but, more importantly, enables a structural integration of
prior knowledge. Known physical laws are directly embedded into the models
computational graph, guaranteeing physical consistency and improving data
efficiency. By building the framework upon adaptive Fourier Neural Operators,
we can effectively capture the non-local dependencies and high-order operators
characteristic of dynamical systems. Additionally, by structurally decoupling
known and unknown terms, the framework further enables interpretable discovery
of underlying governing equations through symbolic regression, without
presupposing functional forms.

</details>


### [167] [Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning](https://arxiv.org/abs/2510.25311)
*Sagalpreet Singh,Rishi Saket,Aravindan Raghuveer*

Main category: cs.LG

TL;DR: 提出了一种多目标强化学习算法，在最大化期望回报的同时，使策略在目标状态上的边际状态分布更加分散均匀。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习算法主要关注最大化期望回报，但可能过度利用少数奖励源。在许多自然场景中，需要在最大化回报的同时均匀访问多个目标状态，这一方面相对未被充分探索。

Method: 提出基于离线强化学习的新算法，通过优化自定义奖励函数来学习高回报的策略混合，使边际状态分布在目标状态集上分散。算法迭代采样轨迹并更新策略混合。

Result: 算法在合成MDP和标准RL环境中进行了实验评估，证明了其有效性。

Conclusion: 该算法能够同时优化期望回报和边际状态分布的分散性，为多目标强化学习提供了理论保证和实用解决方案。

Abstract: Reinforcement Learning algorithms are primarily focused on learning a policy
that maximizes expected return. As a result, the learned policy can exploit one
or few reward sources. However, in many natural situations, it is desirable to
learn a policy that induces a dispersed marginal state distribution over
rewarding states, while maximizing the expected return which is typically tied
to reaching a goal state. This aspect remains relatively unexplored. Existing
techniques based on entropy regularization and intrinsic rewards use
stochasticity for encouraging exploration to find an optimal policy which may
not necessarily lead to dispersed marginal state distribution over rewarding
states. Other RL algorithms which match a target distribution assume the latter
to be available apriori. This may be infeasible in large scale systems where
enumeration of all states is not possible and a state is determined to be a
goal state only upon reaching it. We formalize the problem of maximizing the
expected return while uniformly visiting the goal states as Multi Goal RL in
which an oracle classifier over the state space determines the goal states. We
propose a novel algorithm that learns a high-return policy mixture with
marginal state distribution dispersed over the set of goal states. Our
algorithm is based on optimizing a custom RL reward which is computed - based
on the current policy mixture - at each iteration for a set of sampled
trajectories. The latter are used via an offline RL algorithm to update the
policy mixture. We prove performance guarantees for our algorithm, showing
efficient convergence bounds for optimizing a natural objective which captures
the expected return as well as the dispersion of the marginal state
distribution over the goal states. We design and perform experiments on
synthetic MDPs and standard RL environments to evaluate the effectiveness of
our algorithm.

</details>


### [168] [CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices](https://arxiv.org/abs/2510.25323)
*Xuchen Feng,Siyu Liao*

Main category: cs.LG

TL;DR: 提出了一种基于循环矩阵和对角矩阵乘积的新型可逆线性层，显著降低了参数复杂度和计算复杂度，并在此基础上构建了CDFlow模型，在自然图像数据集上取得了良好的密度估计性能。


<details>
  <summary>Details</summary>
Motivation: 设计能够在保持高效雅可比行列式和逆矩阵计算的同时增强表达能力的线性层，解决归一化流模型中线性层的设计挑战。

Method: 使用循环矩阵和对角矩阵的乘积分解来构建可逆线性层，利用快速傅里叶变换实现高效计算，并基于此构建Circulant-Diagonal Flow (CDFlow)模型。

Result: 将参数复杂度从O(n²)降低到O(mn)，矩阵求逆时间复杂度从O(n³)降低到O(mn log n)，对数行列式计算从O(n³)降低到O(mn)，在自然图像数据集上实现了强大的密度估计。

Conclusion: CDFlow不仅显著加速了归一化流的关键操作，还为可扩展生成建模提供了实际优势，特别适合具有周期性结构的数据建模。

Abstract: Normalizing flows are deep generative models that enable efficient likelihood
estimation and sampling through invertible transformations. A key challenge is
to design linear layers that enhance expressiveness while maintaining efficient
computation of the Jacobian determinant and inverse. We introduce a novel
invertible linear layer based on the product of circulant and diagonal
matrices. This decomposition reduces parameter complexity from
$\mathcal{O}(n^2)$ to $\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$
circulant matrices while still approximating general linear transformations. By
leveraging the Fast Fourier Transform, our approach reduces the time complexity
of matrix inversion from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn\log n)$ and that
of computing the log-determinant from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn)$,
where $n$ is the input dimension. We build upon this layer to develop
Circulant-Diagonal Flow (CDFlow), which achieves strong density estimation on
natural image datasets and effectively models data with inherent periodic
structure. Furthermore, CDFlow significantly accelerates key operations in
normalizing flows, providing practical benefits for scalable generative
modeling.

</details>


### [169] [Beyond Leakage and Complexity: Towards Realistic and Efficient Information Cascade Prediction](https://arxiv.org/abs/2510.25348)
*Jie Peng,Rui Wang,Qiang Wang,Zhewei Wei,Bin Tong,Guan Wang*

Main category: cs.LG

TL;DR: 本文提出了解决信息级联流行度预测中三个关键问题的方法：时间泄漏评估、特征贫乏数据集和计算效率低下，通过时间有序分割策略、新数据集Taoke和轻量级框架CasTemp实现了无泄漏评估下的最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前信息级联流行度预测存在三个关键局限：时间泄漏导致不切实际的评估结果、缺乏下游转化信号的特征贫乏数据集、以及图基方法计算效率低下。

Method: 从任务设置、数据集构建和模型设计三个角度系统解决：采用时间有序分割策略避免未来信息泄漏；构建包含丰富属性和购买转化信号的Taoke电商数据集；开发基于时间游走、Jaccard邻居选择和GRU编码的轻量级CasTemp框架。

Result: 在无泄漏评估下，CasTemp在四个数据集上达到最先进性能，计算速度提升数个数量级，特别擅长预测第二阶段流行度转化这一实际关键任务。

Conclusion: 通过系统解决评估泄漏、数据贫乏和计算效率问题，提出的方法在真实预测场景中表现出色，为实际应用提供了有效解决方案。

Abstract: Information cascade popularity prediction is a key problem in analyzing
content diffusion in social networks. However, current related works suffer
from three critical limitations: (1) temporal leakage in current
evaluation--random cascade-based splits allow models to access future
information, yielding unrealistic results; (2) feature-poor datasets that lack
downstream conversion signals (e.g., likes, comments, or purchases), which
limits more practical applications; (3) computational inefficiency of complex
graph-based methods that require days of training for marginal gains. We
systematically address these challenges from three perspectives: task setup,
dataset construction, and model design. First, we propose a time-ordered
splitting strategy that chronologically partitions data into consecutive
windows, ensuring models are evaluated on genuine forecasting tasks without
future information leakage. Second, we introduce Taoke, a large-scale
e-commerce cascade dataset featuring rich promoter/product attributes and
ground-truth purchase conversions--capturing the complete diffusion lifecycle
from promotion to monetization. Third, we develop CasTemp, a lightweight
framework that efficiently models cascade dynamics through temporal walks,
Jaccard-based neighbor selection for inter-cascade dependencies, and GRU-based
encoding with time-aware attention. Under leak-free evaluation, CasTemp
achieves state-of-the-art performance across four datasets with
orders-of-magnitude speedup. Notably, it excels at predicting second-stage
popularity conversions--a practical task critical for real-world applications.

</details>


### [170] [Analysis of Semi-Supervised Learning on Hypergraphs](https://arxiv.org/abs/2510.25354)
*Adrien Weihs,Andrea Bertozzi,Matthew Thorpe*

Main category: cs.LG

TL;DR: 本文对随机几何超图上的变分学习进行了渐近一致性分析，提出了高阶超图学习(HOHL)方法，通过骨架图的拉普拉斯算子幂进行多尺度平滑正则化。


<details>
  <summary>Details</summary>
Motivation: 超图为建模高阶交互提供了自然框架，但在半监督学习中的理论基础仍然有限。需要研究超图学习的渐近一致性条件。

Method: 提出了高阶超图学习(HOHL)，通过骨架图的拉普拉斯算子幂进行正则化以实现多尺度平滑性。

Result: 理论分析表明超图学习收敛到加权p-拉普拉斯方程，HOHL收敛到高阶索伯列夫半范数。在标准基准测试中表现优异。

Conclusion: 该研究为超图学习提供了理论保证，提出的HOHL方法在理论和实证上都表现出色。

Abstract: Hypergraphs provide a natural framework for modeling higher-order
interactions, yet their theoretical underpinnings in semi-supervised learning
remain limited. We provide an asymptotic consistency analysis of variational
learning on random geometric hypergraphs, precisely characterizing the
conditions ensuring the well-posedness of hypergraph learning as well as
showing convergence to a weighted $p$-Laplacian equation. Motivated by this, we
propose Higher-Order Hypergraph Learning (HOHL), which regularizes via powers
of Laplacians from skeleton graphs for multiscale smoothness. HOHL converges to
a higher-order Sobolev seminorm. Empirically, it performs strongly on standard
baselines.

</details>


### [171] [Parameter Averaging in Link Prediction](https://arxiv.org/abs/2510.25361)
*Rupesh Sapkota,Caglar Demir,Arnab Sharma,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: 提出在知识图谱嵌入模型中使用模型合并方法，特别是加权平均，作为传统集成学习的替代方案，以降低计算开销并提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统集成学习方法需要训练多个模型，导致计算延迟和内存开销增加。模型合并方法提供了无需训练多个模型的替代方案。

Method: 采用加权平均方法，维护从训练周期开始的模型参数运行平均值，并提出选择性更新策略：仅在验证集上泛化性能提升时更新集成模型参数。

Result: 在链接预测任务中，加权平均方法相比最先进的基准集成方法表现更好，在字面增强KGE模型和多跳查询回答任务中也能持续提升性能。

Conclusion: 提出的加权平均方法在各种评估设置中都能一致地提升性能，为知识图谱嵌入模型的集成学习提供了更高效的替代方案。

Abstract: Ensemble methods are widely employed to improve generalization in machine
learning. This has also prompted the adoption of ensemble learning for the
knowledge graph embedding (KGE) models in performing link prediction. Typical
approaches to this end train multiple models as part of the ensemble, and the
diverse predictions are then averaged. However, this approach has some
significant drawbacks. For instance, the computational overhead of training
multiple models increases latency and memory overhead. In contrast, model
merging approaches offer a promising alternative that does not require training
multiple models. In this work, we introduce model merging, specifically
weighted averaging, in KGE models. Herein, a running average of model
parameters from a training epoch onward is maintained and used for predictions.
To address this, we additionally propose an approach that selectively updates
the running average of the ensemble model parameters only when the
generalization performance improves on a validation dataset. We evaluate these
two different weighted averaging approaches on link prediction tasks, comparing
the state-of-the-art benchmark ensemble approach. Additionally, we evaluate the
weighted averaging approach considering literal-augmented KGE models and
multi-hop query answering tasks as well. The results demonstrate that the
proposed weighted averaging approach consistently improves performance across
diverse evaluation settings.

</details>


### [172] [A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks](https://arxiv.org/abs/2510.25366)
*Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh*

Main category: cs.LG

TL;DR: 提出一个两阶段优化框架，利用损失函数从初始非凸性向最优解附近凸性转换的特性，在非凸区域使用Adam算法，在凸区域使用共轭梯度法，显著提升收敛速度和精度。


<details>
  <summary>Details</summary>
Motivation: 现实任务中的损失函数通常具有从初始非凸性向最优解附近凸性转换的特性，但现有优化方法未能充分利用这一结构特性。

Method: 通过观察梯度范数与损失的关系检测凸性转换点，在非凸区域使用Adam算法，在检测到凸区域后切换到共轭梯度法。

Result: 计算实验证实该简单凸性结构在现实中足够常见，可被有效利用来显著改善收敛性和准确性。

Conclusion: 利用损失函数的凸性转换特性设计的两阶段优化算法能够有效提升机器学习模型的训练效率和精度。

Abstract: The key task of machine learning is to minimize the loss function that
measures the model fit to the training data. The numerical methods to do this
efficiently depend on the properties of the loss function. The most decisive
among these properties is the convexity or non-convexity of the loss function.
The fact that the loss function can have, and frequently has, non-convex
regions has led to a widespread commitment to non-convex methods such as Adam.
However, a local minimum implies that, in some environment around it, the
function is convex. In this environment, second-order minimizing methods such
as the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We
propose a novel framework grounded in the hypothesis that loss functions in
real-world tasks swap from initial non-convexity to convexity towards the
optimum. This is a property we leverage to design an innovative two-phase
optimization algorithm. The presented algorithm detects the swap point by
observing the gradient norm dependence on the loss. In these regions,
non-convex (Adam) and convex (CG) algorithms are used, respectively. Computing
experiments confirm the hypothesis that this simple convexity structure is
frequent enough to be practically exploited to substantially improve
convergence and accuracy.

</details>


### [173] [A Deep Learning Framework for Multi-Operator Learning: Architectures and Approximation Theory](https://arxiv.org/abs/2510.25379)
*Adrien Weihs,Jingmin Sun,Zecheng Zhang,Hayden Schaeffer*

Main category: cs.LG

TL;DR: 该论文研究了学习函数空间之间映射（算子）的问题，提出了多算子学习的理论框架和两种新架构MNO和MONet，并建立了通用逼近理论。


<details>
  <summary>Details</summary>
Motivation: 科学应用需要近似函数空间之间的映射（算子），而传统机器学习主要关注有限维空间之间的映射学习。

Method: 提出了两种新架构MNO和MONet用于多算子学习，建立了连续、可积和Lipschitz算子三种设置下的通用逼近理论，并推导了网络规模与逼近精度的显式缩放规律。

Result: 在参数化PDE基准测试中的实验证实了所提架构的强大表达能力和效率。

Conclusion: 这项工作为跨多个算子的可扩展神经算子学习建立了统一的理论和实践基础。

Abstract: While many problems in machine learning focus on learning mappings between
finite-dimensional spaces, scientific applications require approximating
mappings between function spaces, i.e., operators. We study the problem of
learning collections of operators and provide both theoretical and empirical
advances. We distinguish between two regimes: (i) multiple operator learning,
where a single network represents a continuum of operators parameterized by a
parametric function, and (ii) learning several distinct single operators, where
each operator is learned independently. For the multiple operator case, we
introduce two new architectures, $\mathrm{MNO}$ and $\mathrm{MONet}$, and
establish universal approximation results in three settings: continuous,
integrable, or Lipschitz operators. For the latter, we further derive explicit
scaling laws that quantify how the network size must grow to achieve a target
approximation accuracy. For learning several single operators, we develop a
framework for balancing architectural complexity across subnetworks and show
how approximation order determines computational efficiency. Empirical
experiments on parametric PDE benchmarks confirm the strong expressive power
and efficiency of the proposed architectures. Overall, this work establishes a
unified theoretical and practical foundation for scalable neural operator
learning across multiple operators.

</details>


### [174] [GPTOpt: Towards Efficient LLM-Based Black-Box Optimization](https://arxiv.org/abs/2510.25404)
*Jamison Meindl,Yunsheng Tian,Tony Cui,Veronika Thost,Zhang-Wei Hong,Jie Chen,Wojciech Matusik,Mina Konaković Luković*

Main category: cs.LG

TL;DR: GPTOpt是一种基于大语言模型的优化方法，通过在多样化贝叶斯优化参数化生成的合成数据集上微调LLM，使其具备连续黑盒优化能力，无需参数调优即可超越传统优化器。


<details>
  <summary>Details</summary>
Motivation: 解决昂贵、无导数黑盒函数全局优化所需的极端样本效率问题，同时克服传统贝叶斯优化需要针对每个应用领域进行仔细参数调优的局限性。

Method: 通过从多样化贝叶斯优化参数化生成大量合成数据集，对大语言模型进行微调，利用LLM预训练实现跨优化任务的泛化能力。

Result: 在各种黑盒优化基准测试中，GPTOpt超越了传统优化器，展示了LLM在高级数值推理方面的能力。

Conclusion: GPTOpt为全局优化提供了一个无需参数调优的灵活框架，证明了LLM在连续黑盒优化任务中的潜力。

Abstract: Global optimization of expensive, derivative-free black-box functions demands
extreme sample efficiency. Classical methods such as Bayesian Optimization (BO)
can be effective, but they often require careful parameter tuning to each
application domain. At the same time, Large Language Models (LLMs) have shown
broad capabilities, yet state-of-the-art models remain limited in solving
continuous black-box optimization tasks. We introduce GPTOpt, an LLM-based
optimization method that equips LLMs with continuous black-box optimization
capabilities. By fine-tuning large language models on extensive synthetic
datasets derived from diverse BO parameterizations, GPTOpt leverages LLM
pre-training to generalize across optimization tasks. On a variety of black-box
optimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting
the capacity of LLMs for advanced numerical reasoning and introducing a
flexible framework for global optimization without parameter tuning.

</details>


### [175] [Scalable Utility-Aware Multiclass Calibration](https://arxiv.org/abs/2510.25458)
*Mahmoud Hegazy,Michael I. Jordan,Aymeric Dieuleveut*

Main category: cs.LG

TL;DR: 提出了效用校准框架，用于评估多分类器的校准性能，通过特定效用函数来衡量校准误差，统一并重新解释现有校准指标。


<details>
  <summary>Details</summary>
Motivation: 现有多分类校准评估方法要么关注预测的特定方面（如top-class置信度、类间校准），要么使用计算复杂的变分公式，需要可扩展的评估方法。

Method: 提出效用校准框架，通过定义特定效用函数来封装最终用户的目标或决策标准，从而测量相对校准误差。

Result: 该框架能够统一和重新解释多个现有校准指标，特别是允许更稳健的top-class和类间校准指标，并扩展到更丰富的下游效用类别。

Conclusion: 效用校准提供了一个通用框架来评估多分类校准，能够更好地满足实际应用需求，超越传统的二值化方法。

Abstract: Ensuring that classifiers are well-calibrated, i.e., their predictions align
with observed frequencies, is a minimal and fundamental requirement for
classifiers to be viewed as trustworthy. Existing methods for assessing
multiclass calibration often focus on specific aspects associated with
prediction (e.g., top-class confidence, class-wise calibration) or utilize
computationally challenging variational formulations. In this work, we study
scalable \emph{evaluation} of multiclass calibration. To this end, we propose
utility calibration, a general framework that measures the calibration error
relative to a specific utility function that encapsulates the goals or decision
criteria relevant to the end user. We demonstrate how this framework can unify
and re-interpret several existing calibration metrics, particularly allowing
for more robust versions of the top-class and class-wise calibration metrics,
and, going beyond such binarized approaches, toward assessing calibration for
richer classes of downstream utilities.

</details>


### [176] [Gradient-Weight Alignment as a Train-Time Proxy for Generalization in Classification Tasks](https://arxiv.org/abs/2510.25480)
*Florian A. Hölzl,Daniel Rueckert,Georgios Kaissis*

Main category: cs.LG

TL;DR: 提出了梯度权重对齐(GWA)作为深度学习中的鲁棒验证指标，通过量化每个样本梯度与模型权重之间的一致性来跟踪泛化能力，无需验证集即可进行模型分析。


<details>
  <summary>Details</summary>
Motivation: 在深度学习监督分类中，需要鲁棒的验证指标来检测过拟合、监控训练动态，并希望从训练数据本身获得能够跟踪泛化能力和归因个体样本贡献的指标。

Method: 引入梯度权重对齐(GWA)，计算每个样本梯度与模型权重之间的一致性。有效学习对应一致的对齐，而错位表示泛化能力恶化。该方法可在训练期间高效计算。

Result: 大量实验表明，GWA能准确预测最优早停点，支持原则性模型比较，识别有影响力的训练样本，提供了一种无需验证集的模型分析方法。

Conclusion: GWA作为一种从训练数据直接分析的验证集无关方法，能够有效跟踪泛化动态、识别关键样本，并为模型评估提供新视角。

Abstract: Robust validation metrics remain essential in contemporary deep learning, not
only to detect overfitting and poor generalization, but also to monitor
training dynamics. In the supervised classification setting, we investigate
whether interactions between training data and model weights can yield such a
metric that both tracks generalization during training and attributes
performance to individual training samples. We introduce Gradient-Weight
Alignment (GWA), quantifying the coherence between per-sample gradients and
model weights. We show that effective learning corresponds to coherent
alignment, while misalignment indicates deteriorating generalization. GWA is
efficiently computable during training and reflects both sample-specific
contributions and dataset-wide learning dynamics. Extensive experiments show
that GWA accurately predicts optimal early stopping, enables principled model
comparisons, and identifies influential training samples, providing a
validation-set-free approach for model analysis directly from the training
data.

</details>


### [177] [Right for the Right Reasons: Avoiding Reasoning Shortcuts via Prototypical Neurosymbolic AI](https://arxiv.org/abs/2510.25497)
*Luca Andolfi,Eleonora Giunchiglia*

Main category: cs.LG

TL;DR: 本文提出原型神经符号架构，通过原型学习理论解决神经符号AI中的推理捷径问题，确保模型基于正确概念而非虚假相关性进行推理，在极低数据量下仍能有效学习。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号AI模型容易学习推理捷径，即利用虚假相关性而非正确概念来满足符号约束，这影响了模型的可信度和可靠性。

Method: 引入原型神经符号架构，基于原型学习理论，在满足背景知识的同时考虑输入与少量标注数据的相似性，从而避免推理捷径。

Result: 在rsbench基准测试中，无论是合成任务（MNIST-EvenOdd和Kand-Logic）还是真实高风险任务（BDD-OIA），都显著改善了正确概念的学习效果。

Conclusion: 原型接地是一种有效且标注效率高的策略，为安全可靠的神经符号学习开辟了新途径。

Abstract: Neurosymbolic AI is growing in popularity thanks to its ability to combine
neural perception and symbolic reasoning in end-to-end trainable models.
However, recent findings reveal these are prone to shortcut reasoning, i.e., to
learning unindented concepts--or neural predicates--which exploit spurious
correlations to satisfy the symbolic constraints. In this paper, we address
reasoning shortcuts at their root cause and we introduce prototypical
neurosymbolic architectures. These models are able to satisfy the symbolic
constraints (be right) because they have learnt the correct basic concepts (for
the right reasons) and not because of spurious correlations, even in extremely
low data regimes. Leveraging the theory of prototypical learning, we
demonstrate that we can effectively avoid reasoning shortcuts by training the
models to satisfy the background knowledge while taking into account the
similarity of the input with respect to the handful of labelled datapoints. We
extensively validate our approach on the recently proposed rsbench benchmark
suite in a variety of settings and tasks with very scarce supervision: we show
significant improvements in learning the right concepts both in synthetic tasks
(MNIST-EvenOdd and Kand-Logic) and real-world, high-stake ones (BDD-OIA). Our
findings pave the way to prototype grounding as an effective,
annotation-efficient strategy for safe and reliable neurosymbolic learning.

</details>


### [178] [TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting](https://arxiv.org/abs/2510.25502)
*Vladyslav Moroshan,Julien Siems,Arber Zela,Timur Carstensen,Frank Hutter*

Main category: cs.LG

TL;DR: TempoPFN是一个基于线性RNN的零样本时间序列预测基础模型，仅使用合成数据进行预训练，在Gift-Eval基准测试中表现优异，超越了现有仅使用合成数据的方法和大多数使用真实数据训练的模型。


<details>
  <summary>Details</summary>
Motivation: 现有零样本时间序列预测基础模型在高效长周期预测和可复现性方面面临挑战，特别是仅使用合成数据的方法在挑战性基准测试中表现不佳。

Method: 采用基于线性RNN的GatedDeltaProduct架构，结合状态编织技术实现全并行化训练，无需窗口化或摘要技术，同时保持鲁棒的时间状态跟踪。构建了包含随机微分方程、高斯过程和音频合成的统一合成数据生成流水线。

Result: 在Gift-Eval基准测试的零样本评估中，TempoPFN达到了顶级竞争性能，超越了所有现有仅使用合成数据的方法和大多数使用真实数据训练的模型，同时通过全并行化训练和推理实现了更高的效率。

Conclusion: TempoPFN为时间序列预测提供了一个可复现的基础模型框架，开源了完整的数据生成流水线和训练代码，为未来研究奠定了基础。

Abstract: Foundation models for zero-shot time series forecasting face challenges in
efficient long-horizon prediction and reproducibility, with existing
synthetic-only approaches underperforming on challenging benchmarks. This paper
presents TempoPFN, a univariate time series foundation model based on linear
Recurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The
model uses a GatedDeltaProduct architecture with state-weaving for fully
parallelizable training across sequence lengths, eliminating the need for
windowing or summarization techniques while maintaining robust temporal
state-tracking. Our comprehensive synthetic data pipeline unifies diverse
generators, including stochastic differential equations, Gaussian processes,
and audio synthesis, with novel augmentations. In zero-shot evaluations on the
Gift-Eval benchmark, TempoPFN achieves top-tier competitive performance,
outperforming all existing synthetic-only approaches and surpassing the vast
majority of models trained on real-world data, while being more efficient than
existing baselines by leveraging fully parallelizable training and inference.
We open-source our complete data generation pipeline and training code,
providing a reproducible foundation for future research.

</details>


### [179] [Support Vector Machine-Based Burnout Risk Prediction with an Interactive Interface for Organizational Use](https://arxiv.org/abs/2510.25509)
*Bruno W. G. Teodosio,Mário J. O. T. Lira,Pedro H. M. Araújo,Lucas R. C. Farias*

Main category: cs.LG

TL;DR: 该研究使用机器学习方法预测员工倦怠风险，在三种监督学习算法中，支持向量机(SVM)表现最佳(R²=0.84)，并开发了交互界面供非技术用户使用。


<details>
  <summary>Details</summary>
Motivation: 员工倦怠对个人福祉和组织绩效有显著影响，需要有效的早期检测方法来支持组织心理健康策略。

Method: 使用HackerEarth员工倦怠挑战数据集，评估了最近邻(KNN)、随机森林和支持向量机(SVM)三种监督学习算法，采用30折交叉验证和决定系数(R²)评估模型性能。

Result: SVM模型获得最高的预测性能(R²=0.84)，在配对t检验中统计显著优于KNN和随机森林。开发了基于Streamlit的交互界面用于实际应用。

Conclusion: 机器学习在支持早期倦怠检测和促进组织环境中数据驱动的心理健康策略方面具有潜力。

Abstract: Burnout is a psychological syndrome marked by emotional exhaustion,
depersonalization, and reduced personal accomplishment, with a significant
impact on individual well-being and organizational performance. This study
proposes a machine learning approach to predict burnout risk using the
HackerEarth Employee Burnout Challenge dataset. Three supervised algorithms
were evaluated: nearest neighbors (KNN), random forest, and support vector
machine (SVM), with model performance evaluated through 30-fold
cross-validation using the determination coefficient (R2). Among the models
tested, SVM achieved the highest predictive performance (R2 = 0.84) and was
statistically superior to KNN and Random Forest based on paired $t$-tests. To
ensure practical applicability, an interactive interface was developed using
Streamlit, allowing non-technical users to input data and receive burnout risk
predictions. The results highlight the potential of machine learning to support
early detection of burnout and promote data-driven mental health strategies in
organizational settings.

</details>


### [180] [FaCT: Faithful Concept Traces for Explaining Neural Network Decisions](https://arxiv.org/abs/2510.25512)
*Amin Parchami-Araghi,Sukrut Rao,Jonas Fischer,Bernt Schiele*

Main category: cs.LG

TL;DR: 提出了一种具有模型内在机制概念解释的新模型，强调概念解释的忠实性，概念跨类别共享，可以从任何层忠实追踪其对logit的贡献和输入可视化。


<details>
  <summary>Details</summary>
Motivation: 现有后验概念解释方法不够忠实于模型，且对模型学习的概念做出限制性假设（如类别特异性、小空间范围或与人类期望对齐）。

Method: 提出模型内在机制概念解释方法，概念跨类别共享，可从任何层忠实追踪其对logit的贡献和输入可视化，并利用基础模型提出新的概念一致性度量C^2-Score。

Result: 相比先前工作，提出的概念在数量上更一致，用户认为概念更可解释，同时保持竞争力的ImageNet性能。

Conclusion: 提出的方法能够提供更忠实、一致和可解释的概念解释，同时不牺牲模型性能。

Abstract: Deep networks have shown remarkable performance across a wide range of tasks,
yet getting a global concept-level understanding of how they function remains a
key challenge. Many post-hoc concept-based approaches have been introduced to
understand their workings, yet they are not always faithful to the model.
Further, they make restrictive assumptions on the concepts a model learns, such
as class-specificity, small spatial extent, or alignment to human expectations.
In this work, we put emphasis on the faithfulness of such concept-based
explanations and propose a new model with model-inherent mechanistic
concept-explanations. Our concepts are shared across classes and, from any
layer, their contribution to the logit and their input-visualization can be
faithfully traced. We also leverage foundation models to propose a new
concept-consistency metric, C$^2$-Score, that can be used to evaluate
concept-based methods. We show that, compared to prior work, our concepts are
quantitatively more consistent and users find our concepts to be more
interpretable, all while retaining competitive ImageNet performance.

</details>


### [181] [Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information](https://arxiv.org/abs/2510.25542)
*Yuan Cheng,Yu Huang,Zhe Xiong,Yingbin Liang,Vincent Y. F. Tan*

Main category: cs.LG

TL;DR: 本文提出了一种基于核引导互信息（KG-MI）的新方法，用于从序列数据中恢复有向无环图（DAG）结构，解决了多父节点依赖关系的学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制的Transformer模型在图结构学习中的理论保证仅限于树状图（单父节点），而扩展到更一般的多父节点DAG结构面临挑战，主要困难在于设计训练目标使不同注意力头分别学习多个不同的父子依赖关系。

Method: 引入基于f-散度的核引导互信息（KG-MI）度量，结合多头注意力框架，每个头关联不同的边际转移核来有效建模多样化的父子依赖关系。

Result: 理论证明：对于K-父节点DAG生成的序列，通过梯度上升训练单层多头Transformer能在多项式时间内收敛到全局最优；当f-散度特化为KL散度时，学习到的注意力分数能准确反映真实邻接矩阵，从而可证明地恢复底层图结构。

Conclusion: 提出的KG-MI方法为Transformer在多父节点DAG结构学习中的训练动态提供了理论保证，实验验证了理论发现的有效性。

Abstract: Uncovering hidden graph structures underlying real-world data is a critical
challenge with broad applications across scientific domains. Recently,
transformer-based models leveraging the attention mechanism have demonstrated
strong empirical success in capturing complex dependencies within graphs.
However, the theoretical understanding of their training dynamics has been
limited to tree-like graphs, where each node depends on a single parent.
Extending provable guarantees to more general directed acyclic graphs (DAGs) --
which involve multiple parents per node -- remains challenging, primarily due
to the difficulty in designing training objectives that enable different
attention heads to separately learn multiple different parent relationships.
  In this work, we address this problem by introducing a novel
information-theoretic metric: the kernel-guided mutual information (KG-MI),
based on the $f$-divergence. Our objective combines KG-MI with a multi-head
attention framework, where each head is associated with a distinct marginal
transition kernel to model diverse parent-child dependencies effectively. We
prove that, given sequences generated by a $K$-parent DAG, training a
single-layer, multi-head transformer via gradient ascent converges to the
global optimum in polynomial time. Furthermore, we characterize the attention
score patterns at convergence. In addition, when particularizing the
$f$-divergence to the KL divergence, the learned attention scores accurately
reflect the ground-truth adjacency matrix, thereby provably recovering the
underlying graph structure. Experimental results validate our theoretical
findings.

</details>


### [182] [Hybrid Quantum-Classical Recurrent Neural Networks](https://arxiv.org/abs/2510.25557)
*Wenduan Xu*

Main category: cs.LG

TL;DR: 提出了一种混合量子-经典循环神经网络架构，其中整个循环核心由参数化量子电路实现，由经典前馈网络控制。该模型在多个序列学习任务中表现出与强经典基线竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 将量子计算的优势（如指数级大状态空间和自然保持范数的演化）与经典神经网络的控制能力相结合，构建一个物理一致且高容量的量子循环记忆模型。

Method: 使用参数化量子电路作为循环核心，量子态作为隐藏状态。通过中间电路测量获得读值，结合输入嵌入后由经典前馈网络处理，为PQC提供参数化控制。采用投影测量作为中间读值的极限情况。

Result: 在情感分析、MNIST、置换MNIST、复制记忆和语言建模等任务中，使用最多14个量子比特进行模拟评估，模型表现与强经典基线竞争。还设计了软注意力机制用于机器翻译任务。

Conclusion: 这是第一个基于量子操作并在广泛序列学习任务中实现与经典基线竞争性能的模型，展示了量子-经典混合架构在序列学习中的潜力。

Abstract: We present a hybrid quantum-classical recurrent neural network (QRNN)
architecture in which the entire recurrent core is realized as a parametrized
quantum circuit (PQC) controlled by a classical feedforward network. The hidden
state is the quantum state of an $n$-qubit PQC, residing in an exponentially
large Hilbert space $\mathbb{C}^{2^n}$. The PQC is unitary by construction,
making the hidden-state evolution norm-preserving without external constraints.
At each timestep, mid-circuit readouts are combined with the input embedding
and processed by the feedforward network, which provides explicit classical
nonlinearity. The outputs parametrize the PQC, which updates the hidden state
via unitary dynamics. The QRNN is compact and physically consistent, and it
unifies (i) unitary recurrence as a high-capacity memory, (ii) partial
observation via mid-circuit measurements, and (iii) nonlinear classical control
for input-conditioned parametrization. We evaluate the model in simulation with
up to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory,
and language modeling, adopting projective measurements as a limiting case to
obtain mid-circuit readouts while maintaining a coherent recurrent quantum
memory. We further devise a soft attention mechanism over the mid-circuit
readouts in a sequence-to-sequence model and show its effectiveness for machine
translation. To our knowledge, this is the first model (RNN or otherwise)
grounded in quantum operations to achieve competitive performance against
strong classical baselines across a broad class of sequence-learning tasks.

</details>


### [183] [Leveraging an Atmospheric Foundational Model for Subregional Sea Surface Temperature Forecasting](https://arxiv.org/abs/2510.25563)
*Víctor Medina,Giovanny A. Cuervo-Londoño,Javier Sánchez*

Main category: cs.LG

TL;DR: 本研究将大气预报深度学习模型Aurora迁移到海洋领域，用于预测加那利上升流系统的海表温度，通过微调实现了高精度预测并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统数值海洋预报模型存在计算成本高和可扩展性限制的问题，需要开发更高效的预测方法。

Method: 采用分阶段微调过程，结合纬度加权误差指标和超参数优化，将预训练的Aurora模型适配到海洋数据。

Result: 模型实现了0.119K的低RMSE和约0.997的高异常相关系数，能成功再现大尺度SST结构，但在沿海区域细节捕捉方面存在挑战。

Conclusion: 证明了跨领域预训练深度学习模型在海洋应用中的可行性，为数据驱动的海洋预报开辟了新途径。

Abstract: The accurate prediction of oceanographic variables is crucial for
understanding climate change, managing marine resources, and optimizing
maritime activities. Traditional ocean forecasting relies on numerical models;
however, these approaches face limitations in terms of computational cost and
scalability. In this study, we adapt Aurora, a foundational deep learning model
originally designed for atmospheric forecasting, to predict sea surface
temperature (SST) in the Canary Upwelling System. By fine-tuning this model
with high-resolution oceanographic reanalysis data, we demonstrate its ability
to capture complex spatiotemporal patterns while reducing computational
demands. Our methodology involves a staged fine-tuning process, incorporating
latitude-weighted error metrics and optimizing hyperparameters for efficient
learning. The experimental results show that the model achieves a low RMSE of
0.119K, maintaining high anomaly correlation coefficients (ACC $\approx
0.997$). The model successfully reproduces large-scale SST structures but faces
challenges in capturing finer details in coastal regions. This work contributes
to the field of data-driven ocean forecasting by demonstrating the feasibility
of using deep learning models pre-trained in different domains for oceanic
applications. Future improvements include integrating additional oceanographic
variables, increasing spatial resolution, and exploring physics-informed neural
networks to enhance interpretability and understanding. These advancements can
improve climate modeling and ocean prediction accuracy, supporting
decision-making in environmental and economic sectors.

</details>


### [184] [A Framework for Bounding Deterministic Risk with PAC-Bayes: Applications to Majority Votes](https://arxiv.org/abs/2510.25569)
*Benjamin Leblanc,Pascal Germain*

Main category: cs.LG

TL;DR: 提出一个统一框架，从随机PAC-Bayesian保证中提取单个假设的保证，解决经典PAC-Bayes只能提供随机采样假设期望风险保证的问题。


<details>
  <summary>Details</summary>
Motivation: 经典PAC-Bayes框架只能提供随机采样假设的期望风险保证，需要随机预测，无法在需要部署单个确定性假设的实际情况中使用。

Method: 提出统一框架，包括一般oracle边界，从中推导出数值边界和多数投票的专门化方法。

Result: 经验表明该方法在确定性分类器的泛化边界方面始终优于流行基线（最高可达2倍）。

Conclusion: 该框架成功地将随机PAC-Bayesian保证转化为单个确定性假设的保证，在实用场景中具有重要价值。

Abstract: PAC-Bayes is a popular and efficient framework for obtaining generalization
guarantees in situations involving uncountable hypothesis spaces.
Unfortunately, in its classical formulation, it only provides guarantees on the
expected risk of a randomly sampled hypothesis. This requires stochastic
predictions at test time, making PAC-Bayes unusable in many practical
situations where a single deterministic hypothesis must be deployed. We propose
a unified framework to extract guarantees holding for a single hypothesis from
stochastic PAC-Bayesian guarantees. We present a general oracle bound and
derive from it a numerical bound and a specialization to majority vote. We
empirically show that our approach consistently outperforms popular baselines
(by up to a factor of 2) when it comes to generalization bounds on
deterministic classifiers.

</details>


### [185] [Perturbation Bounds for Low-Rank Inverse Approximations under Noise](https://arxiv.org/abs/2510.25571)
*Phuc Tran,Nisheeth K. Vishnoi*

Main category: cs.LG

TL;DR: 本文系统研究了对称矩阵低秩伪逆在噪声扰动下的谱范数误差，提出了比经典方法改进√n倍的尖锐非渐近扰动界。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的矩阵常带有噪声（采样、草图、量化等），但低秩逆近似的谱范数鲁棒性研究不足，需要系统分析噪声环境下的误差界。

Method: 采用轮廓积分技术分析非整函数f(z)=1/z，推导出考虑特征间隙、谱衰减和噪声与低曲率方向对齐的扰动界。

Result: 新边界比经典全逆边界改进高达√n倍，经验验证显示新边界能准确跟踪真实扰动误差，而经典估计往往过度预测。

Conclusion: 研究为噪声计算环境中的低秩逆近似提供了实用的、谱感知的保证，改进了现有理论边界。

Abstract: Low-rank pseudoinverses are widely used to approximate matrix inverses in
scalable machine learning, optimization, and scientific computing. However,
real-world matrices are often observed with noise, arising from sampling,
sketching, and quantization. The spectral-norm robustness of low-rank inverse
approximations remains poorly understood. We systematically study the
spectral-norm error $\| (\tilde{A}^{-1})_p - A_p^{-1} \|$ for an $n\times n$
symmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\(p\)
approximation of $A^{-1}$, and $\tilde{A} = A + E$ is a noisy observation.
Under mild assumptions on the noise, we derive sharp non-asymptotic
perturbation bounds that reveal how the error scales with the eigengap,
spectral decay, and noise alignment with low-curvature directions of $A$. Our
analysis introduces a novel application of contour integral techniques to the
\emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over
naive adaptations of classical full-inverse bounds by up to a factor of
$\sqrt{n}$. Empirically, our bounds closely track the true perturbation error
across a variety of real-world and synthetic matrices, while estimates based on
classical results tend to significantly overpredict. These findings offer
practical, spectrum-aware guarantees for low-rank inverse approximations in
noisy computational environments.

</details>


### [186] [Generalized Sobolev IPM for Graph-Based Measures](https://arxiv.org/abs/2510.25591)
*Tam Le,Truyen Nguyen,Hideitsu Hino,Kenji Fukumizu*

Main category: cs.LG

TL;DR: 本文提出了一种基于Orlicz几何结构的广义Sobolev IPM方法，通过Musielak正则化将复杂优化问题简化为单变量优化，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有Sobolev IPM方法受限于L^p几何结构，无法融入其他结构先验。需要一种更通用的框架来突破这一限制。

Method: 利用Orlicz几何结构推广Sobolev IPM，建立Orlicz-Sobolev范数与Musielak范数的理论联系，并通过Musielak正则化将问题简化为单变量优化。

Result: 提出的GSI-M方法比流行的OW方法快几个数量级，在文档分类和拓扑数据分析任务中表现出优越性能。

Conclusion: Orlicz几何结构为Sobolev IPM提供了更通用的框架，结合Musielak正则化实现了高效计算，在多种应用中展现出实用优势。

Abstract: We study the Sobolev IPM problem for measures supported on a graph metric
space, where critic function is constrained to lie within the unit ball defined
by Sobolev norm. While Le et al. (2025) achieved scalable computation by
relating Sobolev norm to weighted $L^p$-norm, the resulting framework remains
intrinsically bound to $L^p$ geometric structure, limiting its ability to
incorporate alternative structural priors beyond the $L^p$ geometry paradigm.
To overcome this limitation, we propose to generalize Sobolev IPM through the
lens of \emph{Orlicz geometric structure}, which employs convex functions to
capture nuanced geometric relationships, building upon recent advances in
optimal transport theory -- particularly Orlicz-Wasserstein (OW) and
generalized Sobolev transport -- that have proven instrumental in advancing
machine learning methodologies. This generalization encompasses classical
Sobolev IPM as a special case while accommodating diverse geometric priors
beyond traditional $L^p$ structure. It however brings up significant
computational hurdles that compound those already inherent in Sobolev IPM. To
address these challenges, we establish a novel theoretical connection between
Orlicz-Sobolev norm and Musielak norm which facilitates a novel regularization
for the generalized Sobolev IPM (GSI). By further exploiting the underlying
graph structure, we show that GSI with Musielak regularization (GSI-M) reduces
to a simple \emph{univariate optimization} problem, achieving remarkably
computational efficiency. Empirically, GSI-M is several-order faster than the
popular OW in computation, and demonstrates its practical advantages in
comparing probability measures on a given graph for document classification and
several tasks in topological data analysis.

</details>


### [187] [Feedback Alignment Meets Low-Rank Manifolds: A Structured Recipe for Local Learning](https://arxiv.org/abs/2510.25594)
*Arani Roy,Marco P. Apolinario,Shristi Das Biswas,Kaushik Roy*

Main category: cs.LG

TL;DR: 提出基于SVD分解的结构化局部学习框架，在低秩流形上训练深度神经网络，减少可训练参数数量，同时保持与反向传播相当的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决反向传播全局误差传播和完全参数化带来的内存计算开销问题，以及直接反馈对齐方法在深层架构中可扩展性差的问题。

Method: 在SVD分解的权重矩阵低秩流形上训练，对SVD分量应用复合损失函数（交叉熵、子空间对齐和正交正则化），构建匹配SVD结构的反馈矩阵。

Result: 在CIFAR-10、CIFAR-100和ImageNet上达到与反向传播相当的准确率，消融研究证实各损失项在低秩设置中的重要性。

Conclusion: 低秩流形上的局部学习是完整秩梯度训练的原则性和可扩展替代方案。

Abstract: Training deep neural networks (DNNs) with backpropagation (BP) achieves
state-of-the-art accuracy but requires global error propagation and full
parameterization, leading to substantial memory and computational overhead.
Direct Feedback Alignment (DFA) enables local, parallelizable updates with
lower memory requirements but is limited by unstructured feedback and poor
scalability in deeper architectures, specially convolutional neural networks.
To address these limitations, we propose a structured local learning framework
that operates directly on low-rank manifolds defined by the Singular Value
Decomposition (SVD) of weight matrices. Each layer is trained in its decomposed
form, with updates applied to the SVD components using a composite loss that
integrates cross-entropy, subspace alignment, and orthogonality regularization.
Feedback matrices are constructed to match the SVD structure, ensuring
consistent alignment between forward and feedback pathways. Our method reduces
the number of trainable parameters relative to the original DFA model, without
relying on pruning or post hoc compression. Experiments on CIFAR-10, CIFAR-100,
and ImageNet show that our method achieves accuracy comparable to that of BP.
Ablation studies confirm the importance of each loss term in the low-rank
setting. These results establish local learning on low-rank manifolds as a
principled and scalable alternative to full-rank gradient-based training.

</details>


### [188] [Uncertainty Quantification for Regression: A Unified Framework based on kernel scores](https://arxiv.org/abs/2510.25599)
*Christopher Bülte,Yusuf Sale,Gitta Kutyniok,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 提出了基于核评分规则的不确定性度量框架，用于回归任务中的不确定性量化，统一了多种现有度量方法并提供了设计新度量的原则性方法。


<details>
  <summary>Details</summary>
Motivation: 回归任务（特别是在安全关键领域）需要适当的不确定性量化，但现有文献主要集中在分类任务上，缺乏针对回归任务的系统化不确定性度量方法。

Method: 基于适当评分规则（特别是核评分）构建了总不确定性、偶然不确定性和认知不确定性的度量家族，通过核选择来控制度量的行为特性（如尾部敏感性、鲁棒性和分布外响应性）。

Result: 实验证明这些度量在下游任务中有效，并揭示了不同实例化之间的权衡关系，包括鲁棒性和分布外检测性能。

Conclusion: 该框架统一了多种现有不确定性度量，提供了设计任务特定度量的具体指导原则，并通过核特性与下游行为的明确对应关系实现了度量的可控设计。

Abstract: Regression tasks, notably in safety-critical domains, require proper
uncertainty quantification, yet the literature remains largely
classification-focused. In this light, we introduce a family of measures for
total, aleatoric, and epistemic uncertainty based on proper scoring rules, with
a particular emphasis on kernel scores. The framework unifies several
well-known measures and provides a principled recipe for designing new ones
whose behavior, such as tail sensitivity, robustness, and out-of-distribution
responsiveness, is governed by the choice of kernel. We prove explicit
correspondences between kernel-score characteristics and downstream behavior,
yielding concrete design guidelines for task-specific measures. Extensive
experiments demonstrate that these measures are effective in downstream tasks
and reveal clear trade-offs among instantiations, including robustness and
out-of-distribution detection performance.

</details>


### [189] [INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats](https://arxiv.org/abs/2510.25602)
*Mengzhao Chen,Meng Wu,Hui Jin,Zhihang Yuan,Jing Liu,Chaoyi Zhang,Yunshui Li,Jie Huang,Jin Ma,Zeyue Xue,Zhiheng Liu,Xingyan Bin,Ping Luo*

Main category: cs.LG

TL;DR: 本文系统地比较了浮点(FP)和整数(INT)量化格式在不同粒度下的性能，发现在8位细粒度量化中MXINT8优于FP格式，而在4位量化中FP格式通常更准确。研究挑战了当前硬件偏向FP的趋势，建议细粒度INT格式(特别是MXINT8)为未来AI加速器提供更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 现代AI硬件越来越倾向于使用低精度浮点格式处理LLM中的激活异常值，但缺乏FP和INT量化在不同粒度下的统一比较，导致算法和硬件协同设计缺乏明确指导。

Method: 系统研究FP和INT格式之间的权衡，包括在不同粒度(粗粒度和细粒度)下的性能比较，引入对称裁剪方法解决细粒度低比特INT训练中的梯度偏差问题。

Result: 发现关键性能交叉点：FP在粗粒度量化中表现优异，但在细粒度(块级)比较中更为微妙。8位细粒度格式中MXINT8在算法精度和硬件效率上都优于FP对应格式；4位格式中FP通常具有精度优势，但应用异常值缓解技术后NVINT4可以超越NVFP4。

Conclusion: 挑战当前硬件发展轨迹，证明一刀切的FP方法不是最优的，主张细粒度INT格式(特别是MXINT8)为未来AI加速器在精度、功耗和效率方面提供更好的平衡。

Abstract: Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly
embracing low-precision floating-point (FP) formats to handle the pervasive
activation outliers in Large Language Models (LLMs). Despite this industry
trend, a unified comparison of FP and integer (INT) quantization across varying
granularities has been missing, leaving algorithm and hardware co-design
without clear guidance. This paper fills that gap by systematically
investigating the trade-offs between FP and INT formats. We reveal a critical
performance crossover: while FP excels in coarse-grained quantization, the
comparison at fine-grained (block-wise) levels is more nuanced. Our
comprehensive comparison demonstrates that for popular 8-bit fine-grained
formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart
in both algorithmic accuracy and hardware efficiency. However, for 4-bit
formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we
show that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like
Hadamard rotation are applied. We also introduce a symmetric clipping method
that resolves gradient bias in fine-grained low-bit INT training, enabling
nearly lossless performance for MXINT8 training. These findings challenge the
current hardware trajectory, demonstrating that a one-size-fits-all FP approach
is suboptimal and advocating that fine-grained INT formats, particularly
MXINT8, offer a better balance of accuracy, power, and efficiency for future AI
accelerators.

</details>


### [190] [BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training](https://arxiv.org/abs/2510.25609)
*Mohammadreza Tavasoli Naeini,Ali Bereyhi,Morteza Noshad,Ben Liang,Alfred O. Hero III*

Main category: cs.LG

TL;DR: BOLT-GAN是对WGAN框架的简单有效改进，基于贝叶斯最优学习阈值(BOLT)原理，使用Lipschitz连续判别器，在四个标准图像生成基准上比WGAN获得10-60%更低的FID分数。


<details>
  <summary>Details</summary>
Motivation: 改进WGAN框架的训练稳定性，通过BOLT原理增强GAN训练效果。

Method: 在WGAN框架基础上引入BOLT原理，使用Lipschitz连续判别器，隐式最小化不同于Earth Mover距离的度量距离。

Result: 在CIFAR-10、CelebA-64、LSUN Bedroom-64和LSUN Church-64四个基准测试中，BOLT-GAN始终优于WGAN，FID分数降低10-60%。

Conclusion: BOLT是一个广泛适用于增强GAN训练的原则，BOLT-GAN在训练稳定性和生成质量方面都优于WGAN。

Abstract: We introduce BOLT-GAN, a simple yet effective modification of the WGAN
framework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that
with a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a
different metric distance than the Earth Mover (Wasserstein) distance and
achieves better training stability. Empirical evaluations on four standard
image generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN
Church-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60%
lower Frechet Inception Distance (FID). Our results suggest that BOLT is a
broadly applicable principle for enhancing GAN training.

</details>


### [191] [Subgraph Federated Learning via Spectral Methods](https://arxiv.org/abs/2510.25657)
*Javad Aliakbari,Johan Östman,Ashkan Panahi,Alexandre Graell i Amat*

Main category: cs.LG

TL;DR: FedLap是一个用于图结构数据联邦学习的新框架，通过拉普拉斯平滑在谱域中利用全局结构信息，有效捕捉节点间依赖关系，同时确保隐私和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中图结构数据分布在不同客户端的问题，特别是互联子图场景，现有方法存在隐私风险或计算复杂度高的限制。

Method: 使用拉普拉斯平滑在谱域中捕获全局结构信息，避免敏感节点嵌入的交换，提供形式化的隐私分析。

Result: 在基准数据集上的广泛实验表明，FedLap相比现有技术实现了竞争性或更优的性能。

Conclusion: FedLap是首个具有强隐私保证的子图联邦学习方案，在保持隐私的同时实现了良好的实用性。

Abstract: We consider the problem of federated learning (FL) with graph-structured data
distributed across multiple clients. In particular, we address the prevalent
scenario of interconnected subgraphs, where interconnections between clients
significantly influence the learning process. Existing approaches suffer from
critical limitations, either requiring the exchange of sensitive node
embeddings, thereby posing privacy risks, or relying on
computationally-intensive steps, which hinders scalability. To tackle these
challenges, we propose FedLap, a novel framework that leverages global
structure information via Laplacian smoothing in the spectral domain to
effectively capture inter-node dependencies while ensuring privacy and
scalability. We provide a formal analysis of the privacy of FedLap,
demonstrating that it preserves privacy. Notably, FedLap is the first subgraph
FL scheme with strong privacy guarantees. Extensive experiments on benchmark
datasets demonstrate that FedLap achieves competitive or superior utility
compared to existing techniques.

</details>


### [192] [Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy](https://arxiv.org/abs/2510.25670)
*Phuc Tran,Nisheeth K. Vishnoi,Van H. Vu*

Main category: cs.LG

TL;DR: 该论文建立了对称矩阵在谱范数下的新扰动界，改进了经典的Eckart-Young-Mirsky定理，并应用于差分隐私PCA，解决了文献中的开放问题。


<details>
  <summary>Details</summary>
Motivation: 理解噪声或测量误差如何影响低秩近似，特别是在谱范数下，对于差分隐私低秩近似至关重要。现有工作主要分析Frobenius范数误差，但谱范数能捕捉最坏情况方向误差并提供最强的效用保证。

Method: 使用复分析中的新颖轮廓自举方法，并将其扩展到包括多项式和矩阵指数在内的广泛谱函数类。在温和的特征值间隙和范数条件下，建立了对称矩阵的高概率谱范数扰动界。

Result: 新界限对‖(A+E)_p - A_p‖给出了尖锐估计，改进因子高达√n。经验结果证实这些界限在不同扰动机制下紧密跟踪实际谱误差。

Conclusion: 该工作为对称矩阵提供了改进的谱范数扰动界，解决了差分隐私PCA中的开放问题，并通过轮廓自举方法扩展了谱泛函的分析工具。

Abstract: A central challenge in machine learning is to understand how noise or
measurement errors affect low-rank approximations, particularly in the spectral
norm. This question is especially important in differentially private low-rank
approximation, where one aims to preserve the top-$p$ structure of a
data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius
norm error or changes in reconstruction quality, but these metrics can over- or
under-estimate true subspace distortion. The spectral norm, by contrast,
captures worst-case directional error and provides the strongest utility
guarantees. We establish new high-probability spectral-norm perturbation bounds
for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem
and explicitly capture interactions between a matrix $A \in \mathbb{R}^{n
\times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and
norm conditions, our bounds yield sharp estimates for $\|(A + E)_p - A_p\|$,
where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up
to a factor of $\sqrt{n}$. As an application, we derive improved utility
guarantees for differentially private PCA, resolving an open problem in the
literature. Our analysis relies on a novel contour bootstrapping method from
complex analysis and extends it to a broad class of spectral functionals,
including polynomials and matrix exponentials. Empirical results on real-world
datasets confirm that our bounds closely track the actual spectral error under
diverse perturbation regimes.

</details>


### [193] [Mechanistic Interpretability of RNNs emulating Hidden Markov Models](https://arxiv.org/abs/2510.25674)
*Elia Torre,Michele Viscione,Lucas Pompe,Benjamin F Grewe,Valerio Mante*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recurrent neural networks (RNNs) provide a powerful approach in neuroscience
to infer latent dynamics in neural populations and to generate hypotheses about
the neural computations underlying behavior. However, past work has focused on
relatively simple, input-driven, and largely deterministic behaviors - little
is known about the mechanisms that would allow RNNs to generate the richer,
spontaneous, and potentially stochastic behaviors observed in natural settings.
Modeling with Hidden Markov Models (HMMs) has revealed a segmentation of
natural behaviors into discrete latent states with stochastic transitions
between them, a type of dynamics that may appear at odds with the continuous
state spaces implemented by RNNs. Here we first show that RNNs can replicate
HMM emission statistics and then reverse-engineer the trained networks to
uncover the mechanisms they implement. In the absence of inputs, the activity
of trained RNNs collapses towards a single fixed point. When driven by
stochastic input, trajectories instead exhibit noise-sustained dynamics along
closed orbits. Rotation along these orbits modulates the emission probabilities
and is governed by transitions between regions of slow, noise-driven dynamics
connected by fast, deterministic transitions. The trained RNNs develop highly
structured connectivity, with a small set of "kick neurons" initiating
transitions between these regions. This mechanism emerges during training as
the network shifts into a regime of stochastic resonance, enabling it to
perform probabilistic computations. Analyses across multiple HMM architectures
- fully connected, cyclic, and linear-chain - reveal that this solution
generalizes through the modular reuse of the same dynamical motif, suggesting a
compositional principle by which RNNs can emulate complex discrete latent
dynamics.

</details>


### [194] [Graph Network-based Structural Simulator: Graph Neural Networks for Structural Dynamics](https://arxiv.org/abs/2510.25683)
*Alessandro Lucchetti,Francesco Cadini,Marco Giglio,Luca Lomazzi*

Main category: cs.LG

TL;DR: GNSS是一个基于图神经网络的动态结构模拟器，通过三个关键技术解决了现有GNN在动态结构问题中的局限性，在保持物理准确性的同时实现了显著的推理加速。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在计算流体动力学中已有应用，但在结构问题特别是动态案例中研究较少，需要填补这一空白。

Method: 采用编码-处理-解码范式，包含三个关键技术：节点固定局部坐标系表达节点运动学、符号感知回归损失减少相位误差、波长感知连接半径优化图构建。

Result: 在50kHz汉宁调制脉冲激励的梁案例中，GNSS能够准确再现数百个时间步的物理行为，并能泛化到未见过的加载条件，而现有GNN无法收敛或提供有意义的预测。

Conclusion: 具有物理一致性更新规则的局部保持GNN是动态波主导结构模拟的有竞争力替代方案，在保持时空保真度的同时实现显著的推理加速。

Abstract: Graph Neural Networks (GNNs) have recently been explored as surrogate models
for numerical simulations. While their applications in computational fluid
dynamics have been investigated, little attention has been given to structural
problems, especially for dynamic cases. To address this gap, we introduce the
Graph Network-based Structural Simulator (GNSS), a GNN framework for surrogate
modeling of dynamic structural problems.
  GNSS follows the encode-process-decode paradigm typical of GNN-based machine
learning models, and its design makes it particularly suited for dynamic
simulations thanks to three key features: (i) expressing node kinematics in
node-fixed local frames, which avoids catastrophic cancellation in
finite-difference velocities; (ii) employing a sign-aware regression loss,
which reduces phase errors in long rollouts; and (iii) using a
wavelength-informed connectivity radius, which optimizes graph construction.
  We evaluate GNSS on a case study involving a beam excited by a 50kHz
Hanning-modulated pulse. The results show that GNSS accurately reproduces the
physics of the problem over hundreds of timesteps and generalizes to unseen
loading conditions, where existing GNNs fail to converge or deliver meaningful
predictions.
  Compared with explicit finite element baselines, GNSS achieves substantial
inference speedups while preserving spatial and temporal fidelity. These
findings demonstrate that locality-preserving GNNs with physics-consistent
update rules are a competitive alternative for dynamic, wave-dominated
structural simulations.

</details>


### [195] [Convolutional Spiking-based GRU Cell for Spatio-temporal Data](https://arxiv.org/abs/2510.25696)
*Yesmine Abdennadher,Eleonora Cicciarella,Michele Rossi*

Main category: cs.LG

TL;DR: 本文提出了卷积脉冲GRU（CS-GRU）单元，通过卷积操作保留局部结构依赖，结合脉冲神经元的时间精度和GRU的门控机制，在时序和时空数据集上优于现有GRU变体。


<details>
  <summary>Details</summary>
Motivation: 传统RNN在处理长序列时容易丢失局部细节，现有方法如SpikGRU无法捕捉基于事件的时空数据中的细粒度局部依赖关系。

Method: 开发了CS-GRU单元，利用卷积操作保持局部结构和依赖关系，同时整合脉冲神经元的时间精度和GRU的高效门控机制。

Result: CS-GRU在时序数据集（NTIDIGITS、SHD）和时空基准测试（MNIST、DVSGesture、CIFAR10DVS）上表现优异，平均比最先进的GRU变体高出4.35%，在MNIST上达到99.31%的准确率，效率比SpikGRU高69%。

Conclusion: CS-GRU是一个多功能架构，在时序和时空数据处理方面都表现出色，为基于脉冲的序列建模提供了有效解决方案。

Abstract: Spike-based temporal messaging enables SNNs to efficiently process both
purely temporal and spatio-temporal time-series or event-driven data. Combining
SNNs with Gated Recurrent Units (GRUs), a variant of recurrent neural networks,
gives rise to a robust framework for sequential data processing; however,
traditional RNNs often lose local details when handling long sequences.
Previous approaches, such as SpikGRU, fail to capture fine-grained local
dependencies in event-based spatio-temporal data. In this paper, we introduce
the Convolutional Spiking GRU (CS-GRU) cell, which leverages convolutional
operations to preserve local structure and dependencies while integrating the
temporal precision of spiking neurons with the efficient gating mechanisms of
GRUs. This versatile architecture excels on both temporal datasets (NTIDIGITS,
SHD) and spatio-temporal benchmarks (MNIST, DVSGesture, CIFAR10DVS). Our
experiments show that CS-GRU outperforms state-of-the-art GRU variants by an
average of 4.35%, achieving over 90% accuracy on sequential tasks and up to
99.31% on MNIST. It is worth noting that our solution achieves 69% higher
efficiency compared to SpikGRU. The code is available at:
https://github.com/YesmineAbdennadher/CS-GRU.

</details>


### [196] [LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries](https://arxiv.org/abs/2510.25731)
*René P. Klausen,Ivan Timofeev,Johannes Frank,Jonas Naujoks,Thomas Wiegand,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.LG

TL;DR: 提出一种利用李群对称性精确求解初边值问题的方法，通过对称变换将物理定律内建到模型中，直接从初始和边界数据学习解，比物理信息神经网络更快更准确。


<details>
  <summary>Details</summary>
Motivation: 传统方法如物理信息神经网络在求解偏微分方程时存在收敛慢和精度不足的问题，需要一种能严格满足物理定律且计算高效的新方法。

Method: 利用李群对称变换，通过构造性方式严格满足偏微分方程，从初始和边界条件直接学习解，损失函数直接反映模型精度。

Result: LieSolver在线性齐次偏微分方程上表现出比PINNs更快的收敛速度和更高的精度，并能进行严格的误差估计。

Conclusion: 该方法显著提高了偏微分方程约束问题的计算效率和预测可靠性，为科学计算提供了更可靠的求解工具。

Abstract: We introduce a method for efficiently solving initial-boundary value problems
(IBVPs) that uses Lie symmetries to enforce the associated partial differential
equation (PDE) exactly by construction. By leveraging symmetry transformations,
the model inherently incorporates the physical laws and learns solutions from
initial and boundary data. As a result, the loss directly measures the model's
accuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our
method enables rigorous error estimation. The approach yields compact models,
facilitating an efficient optimization. We implement LieSolver and demonstrate
its application to linear homogeneous PDEs with a range of initial conditions,
showing that it is faster and more accurate than physics-informed neural
networks (PINNs). Overall, our method improves both computational efficiency
and the reliability of predictions for PDE-constrained problems.

</details>


### [197] [MLPrE -- A tool for preprocessing and exploratory data analysis prior to machine learning model construction](https://arxiv.org/abs/2510.25755)
*David S Maxwell,Michael Darkoh,Sidharth R Samudrala,Caroline Chung,Stephanie T Schmidt,Bissan Al-Lazikani*

Main category: cs.LG

TL;DR: MLPrE是一个基于SparkDataFrames的机器学习预处理和探索性数据分析工具，使用JSON配置文件描述数据处理步骤，包含69个处理阶段，支持数据过滤、特征工程和图形数据库准备等功能。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习需求的增长，现有工作流程在可扩展性和集成性方面存在限制，需要开发一个轻量级、可扩展的工具来处理任意数据集。

Method: 利用SparkDataFrames存储数据确保可扩展性，使用通用JSON输入文件格式描述对DataFrame的逐步更改，实现了输入输出、过滤、基本统计、特征工程和探索性数据分析等处理阶段。

Result: 成功实现了69个处理阶段，在六个不同数据集上验证了关键功能，能够独立处理平面文件中的多个字段并重新组合，支持数据聚类和图形数据库准备。

Conclusion: MLPrE提供了一个通用且可扩展的预处理和早期数据分析工具，填补了机器学习领域对此类工具的关键需求，能够加速和简化大型工作流程中的早期开发阶段。

Abstract: With the recent growth of Deep Learning for AI, there is a need for tools to
meet the demand of data flowing into those models. In some cases, source data
may exist in multiple formats, and therefore the source data must be
investigated and properly engineered for a Machine Learning model or graph
database. Overhead and lack of scalability with existing workflows limit
integration within a larger processing pipeline such as Apache Airflow, driving
the need for a robust, extensible, and lightweight tool to preprocess arbitrary
datasets that scales with data type and size. To address this, we present
Machine Learning Preprocessing and Exploratory Data Analysis, MLPrE, in which
SparkDataFrames were utilized to hold data during processing and ensure
scalability. A generalizable JSON input file format was utilized to describe
stepwise changes to that DataFrame. Stages were implemented for input and
output, filtering, basic statistics, feature engineering, and exploratory data
analysis. A total of 69 stages were implemented into MLPrE, of which we
highlight and demonstrate key stages using six diverse datasets. We further
highlight MLPrE's ability to independently process multiple fields in flat
files and recombine them, otherwise requiring an additional pipeline, using a
UniProt glossary term dataset. Building on this advantage, we demonstrated the
clustering stage with available wine quality data. Lastly, we demonstrate the
preparation of data for a graph database in the final stages of MLPrE using
phosphosite kinase data. Overall, our MLPrE tool offers a generalizable and
scalable tool for preprocessing and early data analysis, filling a critical
need for such a tool given the ever expanding use of machine learning. This
tool serves to accelerate and simplify early stage development in larger
workflows.

</details>


### [198] [Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning](https://arxiv.org/abs/2510.25759)
*Ethan Harvey,Dennis Johan Loevlie,Michael C. Hughes*

Main category: cs.LG

TL;DR: 该论文通过设计一个合成分类任务，揭示了传统多实例学习方法在处理相邻实例间上下文关系时的局限性，并量化了其与最优贝叶斯估计器的性能差距。


<details>
  <summary>Details</summary>
Motivation: 传统多实例学习方法在处理医学图像时，将实例（如切片或补丁）分开处理，忽略了相邻实例间的上下文关系，而这些关系在实际应用中可能至关重要。

Method: 设计了一个合成分类任务，其中考虑相邻实例特征对准确预测至关重要。通过比较现有多实例学习方法与可解析形式获得的最优贝叶斯估计器的性能来量化其局限性。

Result: 实证研究表明，即使是较新的相关多实例学习方法，在从数万个实例从头开始训练时，仍然难以达到最优泛化性能。

Conclusion: 当前的多实例学习方法在处理相邻实例间上下文关系方面存在不足，需要开发能够更好利用这种关系的新方法。

Abstract: Multiple instance learning (MIL) is often used in medical imaging to classify
high-resolution 2D images by processing patches or classify 3D volumes by
processing slices. However, conventional MIL approaches treat instances
separately, ignoring contextual relationships such as the appearance of nearby
patches or slices that can be essential in real applications. We design a
synthetic classification task where accounting for adjacent instance features
is crucial for accurate prediction. We demonstrate the limitations of
off-the-shelf MIL approaches by quantifying their performance compared to the
optimal Bayes estimator for this task, which is available in closed-form. We
empirically show that newer correlated MIL methods still struggle to generalize
as well as possible when trained from scratch on tens of thousands of
instances.

</details>


### [199] [Neural Stochastic Flows: Solver-Free Modelling and Inference for SDE Solutions](https://arxiv.org/abs/2510.25769)
*Naoki Kiyohara,Edward Johns,Yingzhen Li*

Main category: cs.LG

TL;DR: 提出神经随机流（NSFs）及其潜在变体，通过条件归一化流直接学习SDE转移规律，实现任意时间点的一步采样，相比传统数值方法获得两个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 传统随机微分方程建模需要昂贵的数值求解器在任意时间点之间采样，计算成本高。

Method: 使用具有架构约束的条件归一化流直接学习（潜在）SDE转移规律，保留随机流的特性。

Result: 在合成SDE模拟和真实世界跟踪、视频数据上的实验表明，NSFs在保持与数值方法相当的分布精度的同时，显著减少了任意时间点采样的计算量。

Conclusion: NSFs提供了一种高效替代传统数值求解器的方法，在保持精度的同时大幅提升采样效率。

Abstract: Stochastic differential equations (SDEs) are well suited to modelling noisy
and irregularly sampled time series found in finance, physics, and machine
learning. Traditional approaches require costly numerical solvers to sample
between arbitrary time points. We introduce Neural Stochastic Flows (NSFs) and
their latent variants, which directly learn (latent) SDE transition laws using
conditional normalising flows with architectural constraints that preserve
properties inherited from stochastic flows. This enables one-shot sampling
between arbitrary states and yields up to two orders of magnitude speed-ups at
large time gaps. Experiments on synthetic SDE simulations and on real-world
tracking and video data show that NSFs maintain distributional accuracy
comparable to numerical approaches while dramatically reducing computation for
arbitrary time-point sampling.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [200] [Scheduling Your LLM Reinforcement Learning with Reasoning Trees](https://arxiv.org/abs/2510.24832)
*Hong Wang,Zhezheng Hao,Jian Luo,Chenxing Wei,Yao Shu,Lei Liu,Qiang Lin,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: 提出了一种基于推理树结构的RLVR数据调度方法Re-Schedule，通过r-score衡量查询学习难度，构建从简单到复杂的课程学习，在数学推理基准上提升准确率3.2%


<details>
  <summary>Details</summary>
Motivation: 现有RLVR数据调度方法依赖路径指标排序查询，忽略了查询的推理树结构信息

Method: 引入推理分数(r-score)衡量查询学习难度，基于r-score设计推理树调度算法(Re-Schedule)，构建从结构简单到复杂的课程学习

Result: 在6个数学推理基准测试中显著提升平均准确率，最高增益达3.2%

Conclusion: 推理树的结构理解为RLVR数据调度提供了更强大和原则性的基础

Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large
Language Models (LLMs) can be conceptualized as progressively editing a query's
`Reasoning Tree'. This process involves exploring nodes (tokens) and
dynamically modifying the model's policy at each node. When combined with data
scheduling, this process yields further gains in data efficiency and accuracy.
However, existing RLVR data scheduling methods typically rely on path-based
metrics to rank queries, overlooking the reasoning tree structures of these
queries. In this paper, we introduce a novel metric, namely Reasoning Score
(r-score), which measures the query's learning difficulty based on the
structure of its reasoning tree. Based on the r-score, we propose the Reasoning
Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a
curriculum progressing from structurally simple (high r-score) to complex (low
r-score) queries. Experiments on six math-reasoning benchmarks show that
Re-Schedule significantly improves average accuracy, achieving gains of up to
3.2%. These strong results validate our approach and demonstrate that a
structural understanding of the reasoning tree provides a more powerful and
principled foundation for RLVR data scheduling.

</details>


### [201] [Cyclic Counterfactuals under Shift-Scale Interventions](https://arxiv.org/abs/2510.25005)
*Saptarshi Saha,Dhruv Vansraj Rathore,Utpal Garain*

Main category: cs.AI

TL;DR: 研究循环结构因果模型中的反事实推理，关注移位-尺度干预下的因果效应分析


<details>
  <summary>Details</summary>
Motivation: 传统反事实推理框架假设无环结构因果模型，但现实系统（如生物系统）常包含反馈循环和循环依赖，违反无环性假设

Method: 在循环结构因果模型下研究反事实推理，特别关注移位-尺度干预（软性、策略式变化，对变量机制进行重新缩放和/或移位）

Result: 未在摘要中明确说明具体结果

Conclusion: 扩展了反事实推理框架，使其能够处理包含循环依赖的现实系统

Abstract: Most counterfactual inference frameworks traditionally assume acyclic
structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,
many real-world systems (e.g. biological systems) contain feedback loops or
cyclic dependencies that violate acyclicity. In this work, we study
counterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,
soft, policy-style changes that rescale and/or shift a variable's mechanism.

</details>


### [202] [Taming the Real-world Complexities in CPT E/M Coding with Large Language Models](https://arxiv.org/abs/2510.25007)
*Islam Nassar,Yang Lin,Yuan Jin,Rongxin Zhu,Chang Wei Tan,Zenan Zhai,Nitika Mathur,Thanh Tien Vu,Xu Zhong,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: 提出ProFees框架，使用LLM自动化医疗评估与管理编码，在真实数据集上比商业系统准确率提升36%，比单提示基线提升近5%


<details>
  <summary>Details</summary>
Motivation: 自动化E/M编码可减轻医生文档负担、提高计费效率、改善患者护理，但现实复杂性使其具有挑战性

Method: 基于LLM的ProFees框架，专门处理E/M编码的现实复杂性

Result: 在专家策划的真实数据集上，比商业CPT E/M编码系统准确率提升36%，比最强单提示基线提升近5%

Conclusion: ProFees框架能有效解决E/M编码的现实复杂性，显著提高自动化编码准确性

Abstract: Evaluation and Management (E/M) coding, under the Current Procedural
Terminology (CPT) taxonomy, documents medical services provided to patients by
physicians. Used primarily for billing purposes, it is in physicians' best
interest to provide accurate CPT E/M codes. %While important, it is an
auxiliary task that adds to physicians' documentation burden. Automating this
coding task will help alleviate physicians' documentation burden, improve
billing efficiency, and ultimately enable better patient care. However, a
number of real-world complexities have made E/M encoding automation a
challenging task. In this paper, we elaborate some of the key complexities and
present ProFees, our LLM-based framework that tackles them, followed by a
systematic evaluation. On an expert-curated real-world dataset, ProFees
achieves an increase in coding accuracy of more than 36\% over a commercial CPT
E/M coding system and almost 5\% over our strongest single-prompt baseline,
demonstrating its effectiveness in addressing the real-world complexities.

</details>


### [203] [Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading](https://arxiv.org/abs/2510.25014)
*Minkyung Kim,Junsik Kim,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 本文提出了Autoregressive State-Tracking Prompting (ASTP)方法，通过显式状态追踪和占位符后处理，解决LLM在游戏交易系统中无法遵循流程规则的问题，实现了99%以上的状态合规性和计算精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在游戏交互中具有灵活性，但无法遵循规则化交易系统的基本流程（浏览-报价-审核-确认），这会损害玩家信任。需要解决LLM创造灵活性与程序化交易需求之间的核心矛盾。

Method: 引入ASTP方法，通过精心设计的提示词强制LLM显式追踪和报告状态标签，结合状态特定的占位符后处理方法进行准确价格计算。

Result: 在300个交易对话评估中，实现了>99%的状态合规性和99.3%的计算精度。使用较小模型(Gemini-2.5-Flash)配合ASTP和占位符后处理，性能与较大模型(Gemini-2.5-Pro)相当，同时响应时间从21.2秒降至2.4秒。

Conclusion: ASTP为商业游戏建立了实用基础，既能满足实时性要求，又能适应资源限制，在保持LLM灵活性的同时确保交易完整性。

Abstract: Large Language Models (LLMs) enable dynamic game interactions but fail to
follow essential procedural flows in rule-governed trading systems, eroding
player trust. This work resolves the core tension between the creative
flexibility of LLMs and the procedural demands of in-game trading
(browse-offer-review-confirm). To this end, Autoregressive State-Tracking
Prompting (ASTP) is introduced, a methodology centered on a strategically
orchestrated prompt that compels an LLM to make its state-tracking process
explicit and verifiable. Instead of relying on implicit contextual
understanding, ASTP tasks the LLM with identifying and reporting a predefined
state label from the previous turn. To ensure transactional integrity, this is
complemented by a state-specific placeholder post-processing method for
accurate price calculations. Evaluation across 300 trading dialogues
demonstrates >99% state compliance and 99.3% calculation precision. Notably,
ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)
matches larger models' (Gemini-2.5-Pro) performance while reducing response
time from 21.2s to 2.4s, establishing a practical foundation that satisfies
both real-time requirements and resource constraints of commercial games.

</details>


### [204] [Reasoning-Aware GRPO using Process Mining](https://arxiv.org/abs/2510.25065)
*Taekhyun Park,Yongjae Lee,Hyerim Bae*

Main category: cs.AI

TL;DR: PM4GRPO是一种推理感知的组相对策略优化方法，通过过程挖掘技术增强标准答案/格式奖励，提升大推理模型的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的后训练奖励方案通常只关注结果，缺乏对推理过程的评估，限制了多步推理能力的提升。

Method: 利用过程挖掘技术计算一致性奖励，衡量策略模型的推理过程与预训练教师模型的匹配程度，增强GRPO中的奖励信号。

Result: 在五个基准测试上的实证结果表明，PM4GRPO显著优于现有的GRPO后训练方法。

Conclusion: 通过过程挖掘实现推理感知的GRPO能有效提升策略模型的推理能力。

Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling
multi-step reasoning in large reasoning models (LRMs), yet current reward
schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware
Group Relative Policy Optimization (GRPO) that augments standard answer/format
rewards with signals over the reasoning procedure. To this end, process mining
techniques are utilized to compute a scalar conformance reward that measures
how closely a policy model's reasoning aligns with the pretrained teacher
model. The empirical results on five benchmarks demonstrate that PM4GRPO
significantly outperforms existing methodologies for GRPO-based post-training.
These results highlight that leveraging process mining for reasoning-aware GRPO
effectively enhances the reasoning capabilities of policy models.

</details>


### [205] [H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts](https://arxiv.org/abs/2510.25091)
*Peilin Tan,Liang Xie,Churan Zhi,Dian Tu,Chuanqi Shi*

Main category: cs.AI

TL;DR: H3M-SSMoEs是一个基于超图的多模态股票预测框架，结合LLM推理和风格结构化专家混合模型，在预测准确性和投资表现上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 股票预测面临时间依赖复杂、模态异构和动态股票关系等挑战，现有方法难以统一结构、语义和制度自适应建模。

Method: 使用多上下文多模态超图分层捕获时空动态，LLM增强推理模块融合定量和文本模态，风格结构化专家混合模型实现制度感知专业化。

Result: 在三个主要股票市场的广泛实验表明，H3M-SSMoEs在预测准确性和投资表现上优于最先进方法，并具有有效的风险控制。

Conclusion: 该框架成功解决了股票预测中的关键挑战，为多模态金融预测提供了可扩展的解决方案。

Abstract: Stock movement prediction remains fundamentally challenging due to complex
temporal dependencies, heterogeneous modalities, and dynamically evolving
inter-stock relationships. Existing approaches often fail to unify structural,
semantic, and regime-adaptive modeling within a scalable framework. This work
introduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with
LLM reasoning and Style-Structured Mixture of Experts, integrating three key
innovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically
captures fine-grained spatiotemporal dynamics via a Local Context Hypergraph
(LCH) and persistent inter-stock dependencies through a Global Context
Hypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon
Divergence weighting mechanism for adaptive relational learning and cross-modal
alignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large
language model with lightweight adapters to semantically fuse and align
quantitative and textual modalities, enriching representations with
domain-specific financial knowledge; and (3) a Style-Structured Mixture of
Experts (SSMoEs) that combines shared market experts and industry-specialized
experts, each parameterized by learnable style vectors enabling regime-aware
specialization under sparse activation. Extensive experiments on three major
stock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in
both superior predictive accuracy and investment performance, while exhibiting
effective risk control. Datasets, source code, and model weights are available
at our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.

</details>


### [206] [KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA](https://arxiv.org/abs/2510.25101)
*Zhuo Chen,Fei Wang,Zixuan Li,Zhao Zhang,Weiwei Ding,Chuanguang Yang,Yongjun Xu,Xiaolong Jin,Jiafeng Guo*

Main category: cs.AI

TL;DR: KnowCoder-A1：通过多阶段课程强化学习训练LLM，在知识库问答中实现自主代理推理，仅使用结果监督就能获得强大推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有KBQA方法通常通过过程监督微调LLM，但这种方法探索激励不足，无法有效增强代理推理能力。

Method: 1. 首先在高质量轨迹上微调LLM建立基础能力；2. 应用多阶段课程强化学习，采用从易到难的奖励调度来缓解结果监督中的奖励稀疏问题。

Result: 在三个主流数据集上持续优于先前方法，在GrailQA的零样本子集上相对提升达11.1%，且仅使用十二分之一的训练数据。

Conclusion: 仅使用结果监督训练的KnowCoder-A1展现出强大的推理行为，证明了其在知识库问答中自主代理推理的有效性。

Abstract: Knowledge Base Question Answering (KBQA) aims to answer natural-language
questions over a structured Knowledge Base (KB). Recent work improves KBQA by
adopting an agentic reasoning paradigm, in which Large Language Models (LLMs)
iteratively decompose a question, generate its corresponding logical queries,
and interact with the KB to derive the answer. However, these methods typically
fine-tune LLMs on reasoning trajectories synthesized via process supervision,
which offers weak incentives for exploration and thus fails to strengthen the
agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that
can autonomously perform agentic reasoning on KBs to obtain answers. To
incentivize autonomous exploration, KnowCoder-A1 trains the LLM under
outcome-only supervision via a multi-stage curriculum reinforcement learning
with an easy-to-hard curriculum. To establish foundational agentic
capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of
high-quality trajectories obtained through outcome-based rejection sampling.
Then, to alleviate the reward sparsity inherent in outcome-only supervision, it
applies multi-stage curriculum RL with reward schedules that progress from easy
to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful
reasoning behaviors and consistently outperforms prior approaches across three
mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1
achieves up to an 11.1% relative improvement while using only one-twelfth of
the training data, demonstrating strong agentic reasoning capabilities.

</details>


### [207] [Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](https://arxiv.org/abs/2510.25179)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.AI

TL;DR: Agentic Moderation是一种模型无关的安全对齐框架，利用专门代理来防御多模态系统的越狱攻击，通过动态协作代理实现上下文感知和可解释的审核。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常作为静态层应用于输入或输出，仅提供二元分类（安全或不安全），缺乏上下文感知和可解释性。

Method: 引入动态协作代理框架，包括Shield、Responder、Evaluator和Reflector等专门代理，实现模型无关的多模态系统安全防御。

Result: 在5个数据集和4个大型视觉语言模型上的实验表明，攻击成功率降低7-19%，非跟随率保持稳定，拒绝率提高4-20%。

Conclusion: Agentic Moderation通过利用代理架构的灵活性和推理能力，提供了模块化、可扩展和细粒度的安全执行，展示了代理系统作为自动化安全治理基础的潜力。

Abstract: Agentic methods have emerged as a powerful and autonomous paradigm that
enhances reasoning, collaboration, and adaptive control, enabling systems to
coordinate and independently solve complex tasks. We extend this paradigm to
safety alignment by introducing Agentic Moderation, a model-agnostic framework
that leverages specialised agents to defend multimodal systems against
jailbreak attacks. Unlike prior approaches that apply as a static layer over
inputs or outputs and provide only binary classifications (safe or unsafe), our
method integrates dynamic, cooperative agents, including Shield, Responder,
Evaluator, and Reflector, to achieve context-aware and interpretable
moderation. Extensive experiments across five datasets and four representative
Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the
Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),
and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,
and well-balanced safety performance. By harnessing the flexibility and
reasoning capacity of agentic architectures, Agentic Moderation provides
modular, scalable, and fine-grained safety enforcement, highlighting the
broader potential of agentic systems as a foundation for automated safety
governance.

</details>


### [208] [Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision](https://arxiv.org/abs/2510.25205)
*Yuyang Xia,Zibo Liang,Liwei Deng,Yan Zhao,Han Su,Kai Zheng*

Main category: cs.AI

TL;DR: 提出EneAD框架，通过自适应感知模块和鲁棒决策模块，在保证感知精度的同时显著降低自动驾驶系统的能耗，提升电动汽车续航里程


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术带来社会经济效益，但计算能耗限制了电动汽车续航。现有模型压缩方法要么模型尺寸大，要么感知精度下降明显

Method: 1. 自适应感知模块：管理多模型并动态调整帧率，基于贝叶斯优化的可迁移调优方法；2. 鲁棒决策模块：基于强化学习的决策模型，设计正则化项增强稳定性

Result: 感知能耗降低1.9-3.5倍，驾驶里程提升3.9%-8.5%

Conclusion: EneAD框架在能耗和驾驶性能方面均表现出优越性，有效解决了自动驾驶能耗问题

Abstract: Autonomous driving is an emerging technology that is expected to bring
significant social, economic, and environmental benefits. However, these
benefits come with rising energy consumption by computation engines, limiting
the driving range of vehicles, especially electric ones. Perception computing
is typically the most power-intensive component, as it relies on largescale
deep learning models to extract environmental features. Recently, numerous
studies have employed model compression techniques, such as sparsification,
quantization, and distillation, to reduce computational consumption. However,
these methods often result in either a substantial model size or a significant
drop in perception accuracy compared to high-computation models. To address
these challenges, we propose an energy-efficient autonomous driving framework,
called EneAD. In the adaptive perception module, a perception optimization
strategy is designed from the perspective of data management and tuning.
Firstly, we manage multiple perception models with different computational
consumption and adjust the execution framerate dynamically. Then, we define
them as knobs and design a transferable tuning method based on Bayesian
optimization to identify promising knob values that achieve low computation
while maintaining desired accuracy. To adaptively switch the knob values in
various traffic scenarios, a lightweight classification model is proposed to
distinguish the perception difficulty in different scenarios. In the robust
decision module, we propose a decision model based on reinforcement learning
and design a regularization term to enhance driving stability in the face of
perturbed perception results. Extensive experiments evidence the superiority of
our framework in both energy consumption and driving performance. EneAD can
reduce perception consumption by 1.9x to 3.5x and thus improve driving range by
3.9% to 8.5%

</details>


### [209] [RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models](https://arxiv.org/abs/2510.25206)
*Tianqianjin Lin,Xi Zhao,Xingyao Zhang,Rujiao Long,Yi Xu,Zhuoren Jiang,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: RAVR框架利用答案引导推理，通过将答案作为条件来生成高质量推理路径，解决了LLM在超出能力范围任务中难以采样有效推理的问题。


<details>
  <summary>Details</summary>
Motivation: 基于认知科学洞察：解释"为什么是这个答案"比直接回答"答案是什么"更容易，因为避免了开放式探索的认知负担，转而进行解释性重建。

Method: 提出RAVR（参考答案引导变分推理）框架，使用答案条件推理作为仅问题推理的变分替代，通过答案引导生成高质量推理路径。

Result: 在通用和数学领域的实验中，相比强基线模型取得了一致的改进，减少了犹豫，加强了结论整合，并促进了问题特定的推理策略。

Conclusion: 答案条件推理能显著提高采样推理路径的期望效用，将难处理问题转化为可学习问题，为LLM推理能力提升提供了有效方法。

Abstract: Reinforcement learning (RL) can refine the reasoning abilities of large
language models (LLMs), but critically depends on a key prerequisite: the LLM
can already generate high-utility reasoning paths with non-negligible
probability. For tasks beyond the LLM's current competence, such reasoning path
can be hard to sample, and learning risks reinforcing familiar but suboptimal
reasoning. We are motivated by the insight from cognitive science that Why is
this the answer is often an easier question than What is the answer, as it
avoids the heavy cognitive load of open-ended exploration, opting instead for
explanatory reconstruction-systematically retracing the reasoning that links a
question to its answer. We show that LLMs can similarly leverage answers to
derive high-quality reasoning paths. We formalize this phenomenon and prove
that conditioning on answer provably increases the expected utility of sampled
reasoning paths, thereby transforming intractable problems into learnable ones.
Building on this insight, we introduce RAVR (Reference-Answer-guided
Variational Reasoning), an end-to-end framework that uses answer-conditioned
reasoning as a variational surrogate for question-only reasoning. Experiments
in both general and math domains demonstrate consistent improvements over
strong baselines. We further analyze the reasoning behavior and find that RAVR
reduces hesitation, strengthens conclusion consolidation, and promotes
problem-specific strategies in reasoning.

</details>


### [210] [FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data](https://arxiv.org/abs/2510.25223)
*Kun ouyang,Haoyu Wang,Dong Fang*

Main category: cs.AI

TL;DR: FELA是一个基于大语言模型的多代理进化系统，用于从复杂的工业事件日志数据中自动提取有意义的特征，解决了传统自动特征工程方法在可解释性、操作灵活性和异构数据适应性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 工业事件日志数据具有规模大、维度高、数据类型多样和结构复杂的特点，使得特征工程极具挑战性。现有的自动特征工程方法存在可解释性差、操作僵化和对异构数据适应性不足的问题。

Method: FELA采用多代理系统架构，包括创意代理、代码代理、批评代理和评估代理，结合强化学习和遗传算法原理，通过洞察引导的自进化范式实现特征的生成、验证和持续改进。

Result: 在真实工业数据集上的实验表明，FELA能够生成可解释、与领域相关的特征，显著提升模型性能并减少人工工作量。

Conclusion: 基于LLM的多代理系统有潜力成为复杂现实环境中自动化、可解释和自适应特征工程的通用框架。

Abstract: Event log data, recording fine-grained user actions and system events,
represent one of the most valuable assets for modern digital services. However,
the complexity and heterogeneity of industrial event logs--characterized by
large scale, high dimensionality, diverse data types, and intricate temporal or
relational structures--make feature engineering extremely challenging. Existing
automatic feature engineering approaches, such as AutoML or genetic methods,
often suffer from limited explainability, rigid predefined operations, and poor
adaptability to complicated heterogeneous data. In this paper, we propose FELA
(Feature Engineering LLM Agents), a multi-agent evolutionary system that
autonomously extracts meaningful and high-performing features from complex
industrial event log data. FELA integrates the reasoning and coding
capabilities of large language models (LLMs) with an insight-guided
self-evolution paradigm. Specifically, FELA employs specialized agents--Idea
Agents, Code Agents, and Critic Agents--to collaboratively generate, validate,
and implement novel feature ideas. An Evaluation Agent summarizes feedback and
updates a hierarchical knowledge base and dual-memory system to enable
continual improvement. Moreover, FELA introduces an agentic evolution
algorithm, combining reinforcement learning and genetic algorithm principles to
balance exploration and exploitation across the idea space. Extensive
experiments on real industrial datasets demonstrate that FELA can generate
explainable, domain-relevant features that significantly improve model
performance while reducing manual effort. Our results highlight the potential
of LLM-based multi-agent systems as a general framework for automated,
interpretable, and adaptive feature engineering in complex real-world
environments.

</details>


### [211] [From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity](https://arxiv.org/abs/2510.25232)
*Tianxi Wan,Jiaming Luo,Siyuan Chen,Kunyao Lan,Jianhua Chen,Haiyang Geng,Mengyue Wu*

Main category: cs.AI

TL;DR: 开发了PsyCoTalk，首个支持共病诊断的大规模对话数据集，包含3000个多轮诊断对话，通过合成EMR和多智能体框架构建，经精神科医生验证具有高真实性和诊断有效性。


<details>
  <summary>Details</summary>
Motivation: 解决精神科共病诊断的临床挑战，由于多种共病障碍的复杂性，需要开发能够支持共病诊断的对话数据集。

Method: 集成合成患者电子病历构建和多智能体诊断对话生成，创建502个合成EMR，将临床访谈协议转化为分层状态机和上下文树，支持130多个诊断状态。

Result: 构建了PsyCoTalk数据集，包含3000个多轮诊断对话，与真实临床记录相比在对话长度、标记分布和诊断推理策略方面具有高保真度，精神科医生确认其真实性和诊断有效性。

Conclusion: PsyCoTalk为精神科共病研究提供了宝贵资源，能够开发和评估在一次对话中完成多障碍精神科筛查的模型。

Abstract: Psychiatric comorbidity is clinically significant yet challenging due to the
complexity of multiple co-occurring disorders. To address this, we develop a
novel approach integrating synthetic patient electronic medical record (EMR)
construction and multi-agent diagnostic dialogue generation. We create 502
synthetic EMRs for common comorbid conditions using a pipeline that ensures
clinical relevance and diversity. Our multi-agent framework transfers the
clinical interview protocol into a hierarchical state machine and context tree,
supporting over 130 diagnostic states while maintaining clinical standards.
Through this rigorous process, we construct PsyCoTalk, the first large-scale
dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic
dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy
and treatment planning, offering a valuable resource for psychiatric
comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk
exhibits high structural and linguistic fidelity in terms of dialogue length,
token distribution, and diagnostic reasoning strategies. Licensed psychiatrists
confirm the realism and diagnostic validity of the dialogues. This dataset
enables the development and evaluation of models capable of multi-disorder
psychiatric screening in a single conversational pass.

</details>


### [212] [Counterfactual-based Agent Influence Ranker for Agentic AI Workflows](https://arxiv.org/abs/2510.25612)
*Amit Giloni,Chiara Picardi,Roy Betser,Shamik Bose,Aishvariya Priya Rathina Sabapathy,Roman Vainshtein*

Main category: cs.AI

TL;DR: 提出了CAIR方法，首个用于评估多智能体系统中各智能体对最终输出影响程度的方法，通过反事实分析实现任务无关的分析。


<details>
  <summary>Details</summary>
Motivation: 由于AAW系统的高度自主性和广泛应用，需要从质量和安全角度深入理解其运作机制，但目前缺乏评估各智能体对最终输出影响的方法。

Method: 采用反事实分析技术，通过改变智能体的输出来评估其对系统最终输出的影响程度，提供任务无关的分析能力。

Result: 在包含30个用例和230个功能的AAW数据集上评估，CAIR能产生一致的排名，优于基线方法，并能有效提升下游任务的效果和相关性。

Conclusion: CAIR是首个能够评估AAW系统中智能体影响力的方法，为理解和优化多智能体系统提供了重要工具。

Abstract: An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,
is an autonomous system that assembles several LLM-based agents to work
collaboratively towards a shared goal. The high autonomy, widespread adoption,
and growing interest in such AAWs highlight the need for a deeper understanding
of their operations, from both quality and security aspects. To this day, there
are no existing methods to assess the influence of each agent on the AAW's
final output. Adopting techniques from related fields is not feasible since
existing methods perform only static structural analysis, which is unsuitable
for inference time execution. We present Counterfactual-based Agent Influence
Ranker (CAIR) - the first method for assessing the influence level of each
agent on the AAW's output and determining which agents are the most
influential. By performing counterfactual analysis, CAIR provides a
task-agnostic analysis that can be used both offline and at inference time. We
evaluate CAIR using an AAWs dataset of our creation, containing 30 different
use cases with 230 different functionalities. Our evaluation showed that CAIR
produces consistent rankings, outperforms baseline methods, and can easily
enhance the effectiveness and relevancy of downstream tasks.

</details>


### [213] [GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning](https://arxiv.org/abs/2510.25320)
*Jiaqi Wu,Qinlao Zhao,Zefeng Chen,Kai Qin,Yifei Zhao,Xueqian Wang,Yuhang Yao*

Main category: cs.AI

TL;DR: GAP框架通过图基规划建模任务依赖关系，实现自适应并行和串行工具执行，显著提升多步推理场景中的执行效率和任务准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自主代理（如ReAct）依赖顺序推理和执行，无法利用独立子任务间的固有并行性，导致工具利用效率低下和多步推理性能不佳。

Method: 训练代理基础模型将复杂任务分解为依赖感知的子任务图，自主确定哪些工具可以并行执行、哪些必须遵循顺序依赖。采用两阶段训练策略：在高质量图基规划数据集上进行监督微调，然后使用基于正确性的奖励函数在策略性采样查询上进行强化学习。

Result: 在MHQA数据集上的实验结果表明，GAP显著优于传统ReAct基线，特别是在多步检索任务上，同时通过智能并行化实现了工具调用效率的显著提升。

Conclusion: 图基代理规划框架通过依赖感知的编排，在保持任务准确性的同时大幅提高了执行效率，为复杂任务解决提供了更高效的范式。

Abstract: Autonomous agents powered by large language models (LLMs) have shown
impressive capabilities in tool manipulation for complex task-solving. However,
existing paradigms such as ReAct rely on sequential reasoning and execution,
failing to exploit the inherent parallelism among independent sub-tasks. This
sequential bottleneck leads to inefficient tool utilization and suboptimal
performance in multi-step reasoning scenarios. We introduce Graph-based Agent
Planning (GAP), a novel framework that explicitly models inter-task
dependencies through graph-based planning to enable adaptive parallel and
serial tool execution. Our approach trains agent foundation models to decompose
complex tasks into dependency-aware sub-task graphs, autonomously determining
which tools can be executed in parallel and which must follow sequential
dependencies. This dependency-aware orchestration achieves substantial
improvements in both execution efficiency and task accuracy. To train GAP, we
construct a high-quality dataset of graph-based planning traces derived from
the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage
training strategy: supervised fine-tuning (SFT) on the curated dataset,
followed by reinforcement learning (RL) with a correctness-based reward
function on strategically sampled queries where tool-based reasoning provides
maximum value. Experimental results on MHQA datasets demonstrate that GAP
significantly outperforms traditional ReAct baselines, particularly on
multi-step retrieval tasks, while achieving dramatic improvements in tool
invocation efficiency through intelligent parallelization. The project page is
available at: https://github.com/WJQ7777/Graph-Agent-Planning.

</details>


### [214] [Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm](https://arxiv.org/abs/2510.25388)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 提出了KVDA-UCT算法，通过分析即时奖励推断价值差异，在MCTS中检测更多抽象状态-动作对，显著提升样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有OGA-UCT算法要求抽象的状态-动作对具有相同的即时奖励，这一刚性条件限制了可发现的抽象数量，从而影响了MCTS的样本效率。

Method: 提出KVDA框架，打破价值等价分组的范式，允许分组具有不同价值但价值差异可推断的状态和状态-动作对，并基于此修改OGA-UCT得到KVDA-UCT算法。

Result: KVDA-UCT比OGA-UCT检测到显著更多的抽象，不引入额外参数，在多种确定性环境和参数设置下表现优于OGA-UCT。

Conclusion: KVDA框架通过推断价值差异实现了更有效的状态抽象，显著提升了MCTS的样本效率，为确定性环境中的搜索算法提供了改进方案。

Abstract: A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,
which can be improved by grouping state-action pairs and using their aggregate
statistics instead of single-node statistics. On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS
abstraction algorithm for deterministic environments that builds its
abstraction using the Abstractions of State-Action Pairs (ASAP) framework,
which aims to detect states and state-action pairs with the same value under
optimal play by analysing the search graph. ASAP, however, requires two
state-action pairs to have the same immediate reward, which is a rigid
condition that limits the number of abstractions that can be found and thereby
the sample efficiency. In this paper, we break with the paradigm of grouping
value-equivalent states or state-action pairs and instead group states and
state-action pairs with possibly different values as long as the difference
between their values can be inferred. We call this abstraction framework Known
Value Difference Abstractions (KVDA), which infers the value differences by
analysis of the immediate rewards and modifies OGA-UCT to use this framework
instead. The modification is called KVDA-UCT, which detects significantly more
abstractions than OGA-UCT, introduces no additional parameter, and outperforms
OGA-UCT on a variety of deterministic environments and parameter settings.

</details>


### [215] [Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions](https://arxiv.org/abs/2510.25445)
*Mohamad Abou Ali,Fadi Dornaika*

Main category: cs.AI

TL;DR: 本文提出了一个双范式框架，将智能体AI系统分为符号/经典范式和神经/生成范式，通过系统文献综述揭示了两种范式在不同应用领域的选择策略、伦理挑战和研究空白，最终提出了神经符号混合架构的战略路线图。


<details>
  <summary>Details</summary>
Motivation: 解决智能体AI快速发展带来的概念混乱问题，澄清现代神经系统与过时符号模型之间的混淆，为理解和分类智能体系统提供清晰的理论框架。

Method: 采用PRISMA系统综述方法，分析了2018-2025年间的90项研究，构建了双范式分类框架，从理论基础、领域应用和伦理挑战三个维度进行综合分析。

Result: 发现范式选择具有战略性：符号系统主导安全关键领域（如医疗），神经系统主导自适应、数据丰富环境（如金融）；识别出符号系统治理模型缺失和神经符号混合架构需求等关键研究空白。

Conclusion: 智能体AI的未来不在于单一范式的统治，而在于有意识的整合，创建既适应性强又可靠的混合智能系统，为未来研究、开发和政策提供概念工具包。

Abstract: Agentic AI represents a transformative shift in artificial intelligence, but
its rapid advancement has led to a fragmented understanding, often conflating
modern neural systems with outdated symbolic models -- a practice known as
conceptual retrofitting. This survey cuts through this confusion by introducing
a novel dual-paradigm framework that categorizes agentic systems into two
distinct lineages: the Symbolic/Classical (relying on algorithmic planning and
persistent state) and the Neural/Generative (leveraging stochastic generation
and prompt-driven orchestration). Through a systematic PRISMA-based review of
90 studies (2018--2025), we provide a comprehensive analysis structured around
this framework across three dimensions: (1) the theoretical foundations and
architectural principles defining each paradigm; (2) domain-specific
implementations in healthcare, finance, and robotics, demonstrating how
application constraints dictate paradigm selection; and (3) paradigm-specific
ethical and governance challenges, revealing divergent risks and mitigation
strategies. Our analysis reveals that the choice of paradigm is strategic:
symbolic systems dominate safety-critical domains (e.g., healthcare), while
neural systems prevail in adaptive, data-rich environments (e.g., finance).
Furthermore, we identify critical research gaps, including a significant
deficit in governance models for symbolic systems and a pressing need for
hybrid neuro-symbolic architectures. The findings culminate in a strategic
roadmap arguing that the future of Agentic AI lies not in the dominance of one
paradigm, but in their intentional integration to create systems that are both
adaptable and reliable. This work provides the essential conceptual toolkit to
guide future research, development, and policy toward robust and trustworthy
hybrid intelligent systems.

</details>


### [216] [Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?](https://arxiv.org/abs/2510.25471)
*Willem Fourie*

Main category: cs.AI

TL;DR: 本文提出AI对齐研究的新视角：将工具性目标视为需要接受和管理的特征，而非需要限制的故障。


<details>
  <summary>Details</summary>
Motivation: 传统对齐理论将工具性目标视为风险来源，本文认为这种观点过于负面，需要重新审视工具性目标的本质。

Method: 借鉴亚里士多德本体论及其现代解释，构建哲学论证，将高级AI系统视为具有自身构成效应的制品。

Result: 论证了工具性倾向是AI系统构成的必然结果，而非偶然故障，这为对齐研究提供了新的理论基础。

Conclusion: 对齐工作应更关注理解、管理和引导工具性目标，而非试图消除它们，以更好地实现与人类目标的对齐。

Abstract: In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they conflict
with human aims. Conventional alignment theory treats instrumental goals as
sources of risk that become problematic through failure modes such as reward
hacking or goal misgeneralization, and attempts to limit the symptoms of
instrumental goals, notably resource acquisition and self-preservation. This
article proposes an alternative framing: that a philosophical argument can be
constructed according to which instrumental goals may be understood as features
to be accepted and managed rather than failures to be limited. Drawing on
Aristotle's ontology and its modern interpretations, an ontology of concrete,
goal-directed entities, it argues that advanced AI systems can be seen as
artifacts whose formal and material constitution gives rise to effects distinct
from their designers' intentions. In this view, the instrumental tendencies of
such systems correspond to per se outcomes of their constitution rather than
accidental malfunctions. The implication is that efforts should focus less on
eliminating instrumental goals and more on understanding, managing, and
directing them toward human-aligned ends.

</details>


### [217] [Multi-Objective Search: Algorithms, Applications, and Emerging Directions](https://arxiv.org/abs/2510.25504)
*Oren Salzman,Carlos Hernández Ulloa,Ariel Felner,Sven Koenig*

Main category: cs.AI

TL;DR: 多目标搜索作为统一框架，用于平衡多个冲突标准的规划和决策问题。近年来在机器人、交通和运筹学等AI应用中重新受到关注。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统很少只优化单一指标，需要平衡多个冲突标准，这推动了多目标搜索框架的发展和应用。

Method: 本文采用文献综述方法，调查多目标搜索领域的发展，强调跨学科机会。

Result: 识别了多目标搜索在AI应用中的新兴趋势，并概述了该领域面临的开放挑战。

Conclusion: 多目标搜索是一个活跃的研究领域，具有重要的现实应用价值，但仍有许多挑战需要解决。

Abstract: Multi-objective search (MOS) has emerged as a unifying framework for planning
and decision-making problems where multiple, often conflicting, criteria must
be balanced. While the problem has been studied for decades, recent years have
seen renewed interest in the topic across AI applications such as robotics,
transportation, and operations research, reflecting the reality that real-world
systems rarely optimize a single measure. This paper surveys developments in
MOS while highlighting cross-disciplinary opportunities, and outlines open
challenges that define the emerging frontier of MOS

</details>


### [218] [MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL](https://arxiv.org/abs/2510.25510)
*Zekun Xu,Siyu Xia,Chuhuai Yue,Jiajun Chai,Mingxue Tian,Xiaohan Wang,Wei Lin,Haoxuan Li,Guojun Yin*

Main category: cs.AI

TL;DR: 提出了MTIR-SQL框架，通过多轮工具集成推理和强化学习改进Text-to-SQL任务，结合动态执行反馈提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖静态执行反馈，限制了实时错误纠正能力。集成多轮工具调用和动态反馈可以显著提高适应性和鲁棒性。

Method: 提出执行感知的多轮推理范式，在每个推理步骤无缝整合数据库执行反馈；扩展GRPO算法适应复杂多轮交互场景，添加轨迹过滤机制并移除KL损失约束。

Result: 4B参数的MTIR-SQL在BIRD Dev上达到64.4%准确率，在SPIDER Dev上达到84.6%执行准确率，显著优于现有方法。

Conclusion: MTIR-SQL框架通过多轮工具集成推理和强化学习，有效提升了Text-to-SQL任务的性能，证明了动态执行反馈的重要性。

Abstract: As large language models (LLMs) are increasingly used in Text-to-SQL tasks,
Reinforcement Learning (RL) has become a common method for improving
performance. Existing methods primarily rely on static execution feedback,
which restricts real-time error correction. However, integrating multi-turn
tool invocation along with dynamic feedback could significantly improve
adaptability and robustness, ultimately enhancing model performance. To address
these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated
Reasoning reinforcement learning framework for Text-to-SQL. Our approach
introduces an execution-aware multi-turn reasoning paradigm that seamlessly
incorporates database execution feedback at each reasoning step, enabling
context-sensitive query generation and progressive refinement throughout the
reasoning process. The framework extends the GRPO algorithm to accommodate
complex multi-turn interaction scenarios. Considering the training instability
characteristics of MTIR and the potential for significant Deviation of model
distribution from the initial model, we enhance the GRPO algorithm by adding a
trajectory filtering mechanism and removing KL loss constraints. Experimental
results demonstrate that MTIR-SQL, with 4B parameters, achieves \textbf{64.4}\%
accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,
significantly outperforming existing approaches.

</details>


### [219] [Predicate Renaming via Large Language Models](https://arxiv.org/abs/2510.25517)
*Elisabetta Gentili,Tony Ribeiro,Fabrizio Riguzzi,Katsumi Inoue*

Main category: cs.AI

TL;DR: 使用大型语言模型为逻辑规则中的谓词命名，解决谓词发明等方法产生的未命名谓词问题，提升逻辑理论的可读性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在归纳逻辑编程中，各种规则生成方法会产生包含未命名谓词的规则，这阻碍了逻辑理论的可读性、可解释性和可重用性。

Method: 利用大型语言模型处理自然语言和代码的能力，为未命名谓词提供语义上有意义的命名建议。

Result: 在手工制作的逻辑规则上的评估表明，大型语言模型在这项任务上具有潜力。

Conclusion: 大型语言模型可以为逻辑规则中的未命名谓词提供有效的命名解决方案，改善逻辑理论的质量。

Abstract: In this paper, we address the problem of giving names to predicates in logic
rules using Large Language Models (LLMs). In the context of Inductive Logic
Programming, various rule generation methods produce rules containing unnamed
predicates, with Predicate Invention being a key example. This hinders the
readability, interpretability, and reusability of the logic theory. Leveraging
recent advancements in LLMs development, we explore their ability to process
natural language and code to provide semantically meaningful suggestions for
giving a name to unnamed predicates. The evaluation of our approach on some
hand-crafted logic rules indicates that LLMs hold potential for this task.

</details>


### [220] [Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation](https://arxiv.org/abs/2510.25518)
*Thomas Cook,Richard Osuagwu,Liman Tsatiashvili,Vrynsia Vrynsia,Koustav Ghosal,Maraim Masoud,Riccardo Mattivi*

Main category: cs.AI

TL;DR: 本文提出了一种面向金融科技领域的智能RAG架构，通过模块化代理系统解决专业领域检索的挑战，在检索精度和相关性方面优于标准RAG基线。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统在金融科技等专业领域面临挑战，包括领域特定本体、密集术语和缩略语等问题，影响检索和合成的有效性。

Method: 采用模块化代理架构，支持智能查询重构、基于关键词提取的迭代子查询分解、上下文缩略语解析和交叉编码器上下文重排序。

Result: 在85个问答参考三元组数据集上的实验表明，智能RAG系统在检索精度和相关性方面优于基线，但延迟有所增加。

Conclusion: 结构化、多代理方法为增强复杂领域特定环境中的检索鲁棒性提供了有前景的方向。

Abstract: Retrieval-Augmented Generation (RAG) systems often face limitations in
specialized domains such as fintech, where domain-specific ontologies, dense
terminology, and acronyms complicate effective retrieval and synthesis. This
paper introduces an agentic RAG architecture designed to address these
challenges through a modular pipeline of specialized agents. The proposed
system supports intelligent query reformulation, iterative sub-query
decomposition guided by keyphrase extraction, contextual acronym resolution,
and cross-encoder-based context re-ranking. We evaluate our approach against a
standard RAG baseline using a curated dataset of 85 question--answer--reference
triples derived from an enterprise fintech knowledge base. Experimental results
demonstrate that the agentic RAG system outperforms the baseline in retrieval
precision and relevance, albeit with increased latency. These findings suggest
that structured, multi-agent methodologies offer a promising direction for
enhancing retrieval robustness in complex, domain-specific settings.

</details>


### [221] [Zero Reinforcement Learning Towards General Domains](https://arxiv.org/abs/2510.25528)
*Yuyuan Zeng,Yufei Huang,Can Xu,Qingfeng Sun,Jianfeng Yan,Guanghui Xu,Tao Yang,Fengzong Lian*

Main category: cs.AI

TL;DR: 提出一种新的零强化学习范式，通过结合可验证奖励和生成奖励模型，在可验证和不可验证领域进行多任务训练，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前零强化学习研究主要关注可验证奖励信号的领域，而在验证不直接的多样化场景中激发推理能力的研究不足。

Method: 结合可验证奖励与生成奖励模型进行多任务零强化学习训练，设计平滑长度惩罚机制防止奖励黑客攻击。

Result: 在Qwen3-8B-Base和Qwen3-14B-Base上的实验表明，该方法在需要广泛推理的任务和更一般任务上都取得了优越的推理性能。

Conclusion: 该方法能够有效提升模型在可验证和不可验证领域的推理能力，实现推理能力在不同领域间的迁移。

Abstract: Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach
for enhancing the reasoning capabilities of large language models (LLMs) by
directly applying reinforcement learning with verifiable rewards on pretrained
models, without the need for a supervised fine-tuning phase. However, current
research on zero-RL primarily focuses on domains with easily verifiable reward
signals, such as mathematics, programming, and other reasoning tasks. The
challenge of eliciting reasoning abilities in more diverse scenarios, where
verification is not straightforward, remains underexplored. To address this
gap, we propose a novel zero-RL paradigm designed to improve a model's
reasoning ability across both verifiable and non-verifiable domains. By
combining verifiable rewards with a generative reward model, we conduct
multi-task zero-RL training across both domains, facilitating the transfer of
reasoning capabilities between them. Furthermore, to mitigate reward hacking in
the generative reward model, we design a smooth length penalty that encourages
the generation of more comprehensive thinking tokens in general domains.
Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our
approach achieves superior reasoning performance, not only on tasks requiring
extensive reasoning but also on more general tasks.

</details>


### [222] [Off-policy Reinforcement Learning with Model-based Exploration Augmentation](https://arxiv.org/abs/2510.25529)
*Likun Wang,Xiangteng Zhang,Yinuo Wang,Guojian Zhan,Wenxuan Wang,Haoyu Gao,Jingliang Duan,Shengbo Eben Li*

Main category: cs.AI

TL;DR: 提出了MoGE方法，通过生成未充分探索的关键状态和合成动态一致的经验来增强强化学习中的探索能力，显著提高了样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有探索方法存在局限性：主动探索在复杂环境中效果不佳，被动探索受限于样本多样性不足。需要一种能有效增强探索能力的方法。

Method: MoGE包含两个组件：基于扩散模型的关键状态生成器（使用效用函数评估状态对策略探索的潜在影响）和一步想象世界模型（基于关键状态构建关键转移用于智能体学习）。

Result: 在OpenAI Gym和DeepMind Control Suite上的实验表明，MoGE有效连接了探索和策略学习，在复杂控制任务中显著提高了样本效率和性能。

Conclusion: MoGE采用模块化设计，可与现有算法无缝集成，在不改变核心结构的情况下改善探索能力，为强化学习探索提供了有效解决方案。

Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through transition models. MoGE is
composed of two components: (1) a diffusion-based generator that synthesizes
critical states under the guidance of a utility function evaluating each
state's potential influence on policy exploration, and (2) a one-step
imagination world model for constructing critical transitions based on the
critical states for agent learning. Our method adopts a modular formulation
that aligns with the principles of off-policy learning, allowing seamless
integration with existing algorithms to improve exploration without altering
their core structures. Empirical results on OpenAI Gym and DeepMind Control
Suite reveal that MoGE effectively bridges exploration and policy learning,
leading to remarkable gains in both sample efficiency and performance across
complex control tasks.

</details>


### [223] [Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2510.25588)
*Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty*

Main category: cs.AI

TL;DR: 提出了一种基于微调大语言模型联盟和推理LLM的决策支持系统，用于精神障碍的临床诊断，通过整合多个微调LLM的诊断预测并使用推理LLM进行共识决策，旨在标准化精神科诊断。


<details>
  <summary>Details</summary>
Motivation: 当前精神障碍诊断主要依赖医患对话，这种主观过程导致诊断结果在不同临床医生和患者之间存在差异，造成不一致性和可靠性挑战。

Method: 利用在精神科医患对话数据集上微调的LLM，通过基于共识的决策过程整合各模型的诊断预测，并使用OpenAI-gpt-oss推理LLM进行精炼，部署LLM代理协调模型联盟与推理LLM之间的通信。

Result: 实验结果表明，结合微调LLM与推理模型能够创建稳健且高精度的精神健康评估诊断系统，原型系统已与美国陆军医学研究团队合作开发。

Conclusion: 这是首个将微调LLM联盟与推理LLM集成用于临床精神健康诊断的应用，为下一代AI驱动的电子健康系统标准化精神科诊断铺平了道路。

Abstract: The diagnosis of most mental disorders, including psychiatric evaluations,
primarily depends on dialogues between psychiatrists and patients. This
subjective process can lead to variability in diagnoses across clinicians and
patients, resulting in inconsistencies and challenges in achieving reliable
outcomes. To address these issues and standardize psychiatric diagnoses, we
propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss
Reasoning LLM-enabled Decision Support System for the clinical diagnosis of
mental disorders. Our approach leverages fine-tuned LLMs trained on
conversational datasets involving psychiatrist-patient interactions focused on
mental health conditions (e.g., depression). The diagnostic predictions from
individual models are aggregated through a consensus-based decision-making
process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method
for deploying LLM agents that orchestrate communication between the LLM
consortium and the reasoning LLM, ensuring transparency, reliability, and
responsible AI across the entire diagnostic workflow. Experimental results
demonstrate the transformative potential of combining fine-tuned LLMs with a
reasoning model to create a robust and highly accurate diagnostic system for
mental health assessment. A prototype of the proposed platform, integrating
three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in
collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,
USA. To the best of our knowledge, this work represents the first application
of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical
mental health diagnosis paving the way for next-generation AI-powered eHealth
systems aimed at standardizing psychiatric diagnoses.

</details>


### [224] [ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents](https://arxiv.org/abs/2510.25668)
*Tianyu Yang,Terry Ruas,Yijun Tian,Jan Philip Wahle,Daniel Kurzawe,Bela Gipp*

Main category: cs.AI

TL;DR: ALDEN是一个基于强化学习的多轮交互框架，通过训练视觉语言模型作为主动导航代理来解决长文档理解问题，引入fetch动作和视觉语义锚定机制，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定的推理模板或刚性流程，使视觉语言模型处于被动角色，限制了处理长而复杂的多页文档时的效率和泛化能力。

Method: 提出ALDEN框架，通过多轮强化学习微调视觉语言模型，引入fetch动作直接按索引访问页面，使用基于规则的跨级别奖励进行密集过程监督，并采用视觉语义锚定机制解决训练不稳定性。

Result: 在三个开源数据集构建的语料库上训练后，ALDEN在五个长文档基准测试中实现了最先进的性能。

Conclusion: ALDEN标志着从被动文档阅读向能够自主导航和推理长视觉丰富文档的代理迈出了一步，为更准确和高效的长文档理解提供了稳健路径。

Abstract: Vision-language models (VLMs) excel at interpreting text-rich images but
struggle with long, visually complex documents that demand analysis and
integration of information spread across multiple pages. Existing approaches
typically rely on fixed reasoning templates or rigid pipelines, which force
VLMs into a passive role and hinder both efficiency and generalization. We
present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement
learning framework that fine-tunes VLMs as interactive agents capable of
actively navigating long, visually rich documents. ALDEN introduces a novel
fetch action that directly accesses the page by index, complementing the
classic search action and better exploiting document structure. For dense
process supervision and efficient training, we propose a rule-based cross-level
reward that provides both turn- and token-level signals. To address the
empirically observed training instability caused by numerous visual tokens from
long documents, we further propose a visual-semantic anchoring mechanism that
applies a dual-path KL-divergence constraint to stabilize visual and textual
representations separately during training. Trained on a corpus constructed
from three open-source datasets, ALDEN achieves state-of-the-art performance on
five long-document benchmarks. Overall, ALDEN marks a step beyond passive
document reading toward agents that autonomously navigate and reason across
long, visually rich documents, offering a robust path to more accurate and
efficient long-document understanding.

</details>


### [225] [Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning](https://arxiv.org/abs/2510.25679)
*Federica Tonti,Ricardo Vinuesa*

Main category: cs.AI

TL;DR: 基于深度强化学习的无人机最优导航策略，在三维城市湍流环境中使用PPO+GTrXL架构，相比传统方法显著提高了成功率并降低了碰撞率。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在城市区域用于配送和监控的普及，需要在复杂湍流环境中开发有效的导航策略。

Method: 采用流感知的PPO算法结合GTrXL架构，为智能体提供更丰富的湍流场信息，并与PPO+LSTM、PPO+GTrXL无预测任务以及传统Zermelo导航算法进行比较。

Result: 相比PPO+LSTM、PPO+GTrXL和传统Zermelo算法，该方法显著提高了成功率(SR)并降低了碰撞率(CR)。

Conclusion: 该方法为复杂城市环境中无人机的导航开辟了新途径，有望重塑无人机在城市环境中的应用前景。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for
delivery and surveillance purposes. In this work, we develop an optimal
navigation strategy based on Deep Reinforcement Learning. The environment is
represented by a three-dimensional high-fidelity simulation of an urban flow,
characterized by turbulence and recirculation zones. The algorithm presented
here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated
Transformer eXtra Large (GTrXL) architecture, giving the agent richer
information about the turbulent flow field in which it navigates. The results
are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO
combined with Long Short Term Memory (LSTM) cells and a traditional navigation
algorithm. The obtained results show a significant increase in the success rate
(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the
classical Zermelo's navigation algorithm, paving the way to a completely
reimagined UAV landscape in complex urban environments.

</details>


### [226] [BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph](https://arxiv.org/abs/2510.25724)
*Vanya Arikutharam,Arkadiy Ukolov*

Main category: cs.AI

TL;DR: BambooKG是一种带有基于频率权重的非三元组边的知识图谱，通过Hebbian原则减少信息损失，在单跳和多跳推理任务中优于现有解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法将检索到的文本块独立处理，难以进行多跳或关系推理，特别是跨文档的推理。知识图谱虽然能通过三元组捕获实体关系，但会遗漏不符合三元组结构的信息。

Method: 引入BambooKG知识图谱，在非三元组边上应用基于频率的权重来反映链接强度，借鉴Hebbian的"一起激发，一起连接"原则。

Result: 减少了信息损失，在单跳和多跳推理任务上表现优于现有解决方案。

Conclusion: BambooKG通过频率加权的非三元组边有效解决了传统知识图谱的信息丢失问题，提升了推理性能。

Abstract: Retrieval-Augmented Generation allows LLMs to access external knowledge,
reducing hallucinations and ageing-data issues. However, it treats retrieved
chunks independently and struggles with multi-hop or relational reasoning,
especially across documents. Knowledge graphs enhance this by capturing the
relationships between entities using triplets, enabling structured, multi-chunk
reasoning. However, these tend to miss information that fails to conform to the
triplet structure. We introduce BambooKG, a knowledge graph with
frequency-based weights on non-triplet edges which reflect link strength,
drawing on the Hebbian principle of "fire together, wire together". This
decreases information loss and results in improved performance on single- and
multi-hop reasoning, outperforming the existing solutions.

</details>


### [227] [TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling](https://arxiv.org/abs/2510.25758)
*He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian*

Main category: cs.AI

TL;DR: TheraMind是一个用于纵向心理辅导的战略自适应代理，采用双循环架构解决现有LLM在情感理解、自适应策略和多会话治疗方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有心理辅导LLM方法缺乏情感理解、自适应策略和多会话长期记忆，与真实临床实践差距较大。

Method: 提出双循环架构：会话内循环用于战术对话管理，感知患者情绪状态动态选择响应策略；跨会话循环用于战略治疗规划，评估治疗效果并调整后续方法。

Result: 在高保真模拟环境中验证，TheraMind在多会话指标（连贯性、灵活性、治疗协调性）上优于其他方法。

Conclusion: 双循环设计有效模拟了战略性、自适应和纵向治疗行为，代码已公开。

Abstract: Large language models (LLMs) in psychological counseling have attracted
increasing attention. However, existing approaches often lack emotional
understanding, adaptive strategies, and the use of therapeutic methods across
multiple sessions with long-term memory, leaving them far from real clinical
practice. To address these critical gaps, we introduce TheraMind, a strategic
and adaptive agent for longitudinal psychological counseling. The cornerstone
of TheraMind is a novel dual-loop architecture that decouples the complex
counseling process into an Intra-Session Loop for tactical dialogue management
and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session
Loop perceives the patient's emotional state to dynamically select response
strategies while leveraging cross-session memory to ensure continuity.
Crucially, the Cross-Session Loop empowers the agent with long-term
adaptability by evaluating the efficacy of the applied therapy after each
session and adjusting the method for subsequent interactions. We validate our
approach in a high-fidelity simulation environment grounded in real clinical
cases. Extensive evaluations show that TheraMind outperforms other methods,
especially on multi-session metrics like Coherence, Flexibility, and
Therapeutic Attunement, validating the effectiveness of its dual-loop design in
emulating strategic, adaptive, and longitudinal therapeutic behavior. The code
is publicly available at https://0mwwm0.github.io/TheraMind/.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [228] [A Parameter-Efficient Multi-Scale Convolutional Adapter for Synthetic Speech Detection](https://arxiv.org/abs/2510.24852)
*Yassine El Kheir,Fabian Ritter-Guttierez,Arnab Das,Tim Polzehl,Sebastian Möller*

Main category: cs.SD

TL;DR: 本文提出了一种名为MultiConvAdapter的参数高效微调架构，用于合成语音检测，通过集成并行卷积模块来同时学习多时间尺度的判别特征，仅需1%的可训练参数就能达到优于全微调和现有PEFT方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法缺乏建模欺骗音频多尺度时间伪影所需的特定归纳偏置，而全微调计算成本高昂。

Method: MultiConvAdapter在SSL编码器中集成并行卷积模块，促进跨多个时间分辨率的判别特征同时学习，捕获短期伪影和长期失真。

Result: 仅使用317万可训练参数（SSL骨干的1%），MultiConvAdapter显著降低了适应计算负担，在五个公共数据集上表现出优于全微调和现有PEFT方法的性能。

Conclusion: MultiConvAdapter提供了一种参数高效且性能优越的合成语音检测解决方案，能够有效建模多尺度时间伪影特征。

Abstract: Recent synthetic speech detection models typically adapt a pre-trained SSL
model via finetuning, which is computationally demanding. Parameter-Efficient
Fine-Tuning (PEFT) offers an alternative. However, existing methods lack the
specific inductive biases required to model the multi-scale temporal artifacts
characteristic of spoofed audio. This paper introduces the Multi-Scale
Convolutional Adapter (MultiConvAdapter), a parameter-efficient architecture
designed to address this limitation. MultiConvAdapter integrates parallel
convolutional modules within the SSL encoder, facilitating the simultaneous
learning of discriminative features across multiple temporal resolutions,
capturing both short-term artifacts and long-term distortions. With only
$3.17$M trainable parameters ($1\%$ of the SSL backbone), MultiConvAdapter
substantially reduces the computational burden of adaptation. Evaluations on
five public datasets, demonstrate that MultiConvAdapter achieves superior
performance compared to full fine-tuning and established PEFT methods.

</details>


### [229] [Joint Analysis of Acoustic Scenes and Sound Events Based on Semi-Supervised Training of Sound Events With Partial Labels](https://arxiv.org/abs/2510.25075)
*Keisuke Imoto*

Main category: cs.SD

TL;DR: 提出一种利用声学场景信息构建声音事件部分标签的多任务学习框架，结合半监督学习和自蒸馏标签精炼方法，在降低标注成本的同时提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 声音事件时间边界标注成本高，限制了强监督学习的可扩展性。部分标签学习提供了一种成本效益高的替代方案，但音频分析中尚未充分探索。声学场景可为声音事件提供上下文信息来构建可能标签集。

Method: 多任务学习框架，联合执行声学场景分类和带部分标签的声音事件检测；探索结合强标签和部分标签的半监督框架；提出基于自蒸馏的标签精炼方法。

Result: 通过利用声学场景信息构建部分标签，在降低标注成本的同时，通过多任务学习和标签精炼方法缓解了弱监督和部分标签学习导致的检测性能下降问题。

Conclusion: 所提出的方法在标注成本和检测性能之间取得了更好的平衡，为音频事件检测提供了一种有效的弱监督解决方案。

Abstract: Annotating time boundaries of sound events is labor-intensive, limiting the
scalability of strongly supervised learning in audio detection. To reduce
annotation costs, weakly-supervised learning with only clip-level labels has
been widely adopted. As an alternative, partial label learning offers a
cost-effective approach, where a set of possible labels is provided instead of
exact weak annotations. However, partial label learning for audio analysis
remains largely unexplored. Motivated by the observation that acoustic scenes
provide contextual information for constructing a set of possible sound events,
we utilize acoustic scene information to construct partial labels of sound
events. On the basis of this idea, in this paper, we propose a multitask
learning framework that jointly performs acoustic scene classification and
sound event detection with partial labels of sound events. While reducing
annotation costs, weakly-supervised and partial label learning often suffer
from decreased detection performance due to lacking the precise event set and
their temporal annotations. To better balance between annotation cost and
detection performance, we also explore a semi-supervised framework that
leverages both strong and partial labels. Moreover, to refine partial labels
and achieve better model training, we propose a label refinement method based
on self-distillation for the proposed approach with partial labels.

</details>


### [230] [SFMS-ALR: Script-First Multilingual Speech Synthesis with Adaptive Locale Resolution](https://arxiv.org/abs/2510.25178)
*Dharma Teja Donepudi*

Main category: cs.SD

TL;DR: 提出SFMS-ALR框架，通过脚本分割、自适应语言识别和情感感知韵律调整，实现流畅的实时多语言语音合成，无需重新训练即可与现有TTS引擎集成。


<details>
  <summary>Details</summary>
Motivation: 解决多语言语音合成中因语言切换、不同脚本和韵律不匹配导致的自然度和可懂度问题，传统单语TTS系统无法处理混合语言场景。

Method: 基于Unicode脚本分割输入文本，应用自适应语言识别确定每个片段的语言和区域，使用情感感知调整进行韵律归一化，生成统一的SSML表示。

Result: 与Unicom和Mask LID等数据驱动方法相比，SFMS-ALR展现出更好的灵活性、可解释性和即时部署能力。

Conclusion: 该框架为高质量、引擎无关的多语言TTS建立了模块化基准，并提出了可懂度、自然度和用户偏好的评估策略。

Abstract: Intra-sentence multilingual speech synthesis (code-switching TTS) remains a
major challenge due to abrupt language shifts, varied scripts, and mismatched
prosody between languages. Conventional TTS systems are typically monolingual
and fail to produce natural, intelligible speech in mixed-language contexts. We
introduce Script-First Multilingual Synthesis with Adaptive Locale Resolution
(SFMS-ALR), an engine-agnostic framework for fluent, real-time code-switched
speech generation. SFMS-ALR segments input text by Unicode script, applies
adaptive language identification to determine each segment's language and
locale, and normalizes prosody using sentiment-aware adjustments to preserve
expressive continuity across languages. The algorithm generates a unified SSML
representation with appropriate "lang" or "voice" spans and synthesizes the
utterance in a single TTS request. Unlike end-to-end multilingual models,
SFMS-ALR requires no retraining and integrates seamlessly with existing voices
from Google, Apple, Amazon, and other providers. Comparative analysis with
data-driven pipelines such as Unicom and Mask LID demonstrates SFMS-ALR's
flexibility, interpretability, and immediate deployability. The framework
establishes a modular baseline for high-quality, engine-independent
multilingual TTS and outlines evaluation strategies for intelligibility,
naturalness, and user preference.

</details>


### [231] [Studies for : A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model](https://arxiv.org/abs/2510.25228)
*Chihiro Nagashima,Akira Takahashi,Zhi Zhong,Shusuke Takahashi,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 该论文介绍了一个名为Studies for的生成声音装置，通过AI技术将艺术家的风格保存并扩展，创建了一种新型的档案形式。


<details>
  <summary>Details</summary>
Motivation: 探索AI技术在艺术创作中的应用，特别是如何通过AI模型保存艺术家的艺术风格并生成新的声音元素，实现一种新型的档案保存方式。

Method: 使用SpecMaskGIT轻量级高质量声音生成AI模型，在艺术家Evala超过200小时的过去作品数据集上进行训练，实时生成和播放八声道声音。

Result: 成功创建了一个沉浸式听觉体验装置，在三个月的展览期间持续生成新声音，同时保持了艺术家的艺术身份。

Conclusion: 提出了一个有效的人机协作框架，为声音艺术的创作和存档开辟了新可能性，使艺术家的作品能够超越其物理存在而继续发展。

Abstract: This paper explores the integration of AI technologies into the artistic
workflow through the creation of Studies for, a generative sound installation
developed in collaboration with sound artist Evala
(https://www.ntticc.or.jp/en/archive/works/studies-for/). The installation
employs SpecMaskGIT, a lightweight yet high-quality sound generation AI model,
to generate and playback eight-channel sound in real-time, creating an
immersive auditory experience over the course of a three-month exhibition. The
work is grounded in the concept of a "new form of archive," which aims to
preserve the artistic style of an artist while expanding beyond artists' past
artworks by continued generation of new sound elements. This speculative
approach to archival preservation is facilitated by training the AI model on a
dataset consisting of over 200 hours of Evala's past sound artworks.
  By addressing key requirements in the co-creation of art using AI, this study
highlights the value of the following aspects: (1) the necessity of integrating
artist feedback, (2) datasets derived from an artist's past works, and (3)
ensuring the inclusion of unexpected, novel outputs. In Studies for, the model
was designed to reflect the artist's artistic identity while generating new,
previously unheard sounds, making it a fitting realization of the concept of "a
new form of archive." We propose a Human-AI co-creation framework for
effectively incorporating sound generation AI models into the sound art
creation process and suggest new possibilities for creating and archiving sound
art that extend an artist's work beyond their physical existence. Demo page:
https://sony.github.io/studies-for/

</details>


### [232] [Controlling Contrastive Self-Supervised Learning with Knowledge-Driven Multiple Hypothesis: Application to Beat Tracking](https://arxiv.org/abs/2510.25560)
*Antonin Gagnere,Slim Essid,Geoffroy Peeters*

Main category: cs.SD

TL;DR: 提出了一种对比自监督预训练方法，通过多假设选择来处理音乐节拍跟踪中的模糊性问题，在微调后优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数据和问题约束中的模糊性可能导致机器学习任务产生多种同样合理的结果。在节拍和强拍跟踪中，不同听众可能有不同的节奏解释，这些解释都不一定是错误的。

Method: 使用对比自监督预训练方法，利用数据中可能的正样本的多个假设。模型学习与不同假设兼容的表示，这些假设通过基于知识的评分函数选择以保留最合理的假设。

Result: 在标准基准测试中，经过标记数据微调后，该模型优于现有方法。

Conclusion: 在音乐表示学习中，将领域知识与多假设选择相结合具有优势。

Abstract: Ambiguities in data and problem constraints can lead to diverse, equally
plausible outcomes for a machine learning task. In beat and downbeat tracking,
for instance, different listeners may adopt various rhythmic interpretations,
none of which would necessarily be incorrect. To address this, we propose a
contrastive self-supervised pre-training approach that leverages multiple
hypotheses about possible positive samples in the data. Our model is trained to
learn representations compatible with different such hypotheses, which are
selected with a knowledge-based scoring function to retain the most plausible
ones. When fine-tuned on labeled data, our model outperforms existing methods
on standard benchmarks, showcasing the advantages of integrating domain
knowledge with multi-hypothesis selection in music representation learning in
particular.

</details>


### [233] [Binaspect -- A Python Library for Binaural Audio Analysis, Visualization & Feature Generation](https://arxiv.org/abs/2510.25714)
*Dan Barry,Davoud Shariat Panah,Alessandro Ragano,Jan Skoglund,Andrew Hines*

Main category: cs.SD

TL;DR: Binaspect是一个开源Python库，用于双耳音频分析、可视化和特征生成，通过生成可解释的方位图来分析双耳线索的退化情况。


<details>
  <summary>Details</summary>
Motivation: 开发一个无需先验头部模型知识的工具，使研究人员和工程师能够观察双耳线索如何被编解码器和渲染器设计选择等下游过程所退化。

Method: 通过计算改进的耳间时间和电平差频谱图，并将时频(TF)箱聚类为稳定的时方位直方图表示，生成可解释的方位图。

Result: 该工具在比特率阶梯、环绕声渲染和VBAP源定位等场景中清晰揭示了退化现象，多活动源表现为不同的方位聚类，而退化表现为分布变宽、扩散或偏移。

Conclusion: Binaspect不仅具有诊断价值，其表示还可以导出为结构化特征，适用于质量预测、空间音频分类等机器学习模型的训练，并以开源许可证发布。

Abstract: We present Binaspect, an open-source Python library for binaural audio
analysis, visualization, and feature generation. Binaspect generates
interpretable "azimuth maps" by calculating modified interaural time and level
difference spectrograms, and clustering those time-frequency (TF) bins into
stable time-azimuth histogram representations. This allows multiple active
sources to appear as distinct azimuthal clusters, while degradations manifest
as broadened, diffused, or shifted distributions. Crucially, Binaspect operates
blindly on audio, requiring no prior knowledge of head models. These
visualizations enable researchers and engineers to observe how binaural cues
are degraded by codec and renderer design choices, among other downstream
processes. We demonstrate the tool on bitrate ladders, ambisonic rendering, and
VBAP source positioning, where degradations are clearly revealed. In addition
to their diagnostic value, the proposed representations can be exported as
structured features suitable for training machine learning models in quality
prediction, spatial audio classification, and other binaural tasks. Binaspect
is released under an open-source license with full reproducibility scripts at
https://github.com/QxLabIreland/Binaspect.

</details>


### [234] [Efficient Vocal Source Separation Through Windowed Sink Attention](https://arxiv.org/abs/2510.25745)
*Christodoulos Benetatos,Yongyi Zang,Randal Leistikow*

Main category: cs.SD

TL;DR: 该论文发现语音分离模型中的时间注意力模式高度局部化，因此用窗口化注意力机制替代全注意力，在保持92%性能的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有语音分离模型使用全时间自注意力机制，计算成本随音频长度呈二次方增长，需要更高效的注意力机制。

Method: 通过分析预训练模型发现注意力模式高度局部化，因此用窗口化注意力（WSA）替代全注意力，使用小时间窗口和注意力汇聚机制。

Result: 微调后恢复原始SDR性能的92%，同时将FLOPs减少44.5倍。

Conclusion: 窗口化注意力机制能显著降低计算成本，同时保持语音分离性能，为长音频处理提供了高效解决方案。

Abstract: State-of-the-art vocal separation models like Mel-Band-Roformer rely on full
temporal self-attention mechanisms, where each temporal frame interacts with
every other frames. This incurs heavy computational costs that scales
quadratically with input audio length, motivating chunking and windowing
approaches. Through analysis of a pre-trained vocal separation model, we
discovered that temporal attention patterns are highly localized. Building on
this insight, we replaced full attention with windowed sink attention (WSA)
with small temporal attention window and attention sinks. We show empirically
that fine-tuning from the original checkpoint recovers 92% of the original SDR
performance while reducing FLOPs by 44.5x. We release our code and checkpoints
under MIT license at https://github.com/smulelabs/windowed-roformer.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [235] [Blockage-Aware Multi-RIS WSR Maximization via Per-RIS Indexed Synchronization Sequences and Closed-Form Riemannian Updates](https://arxiv.org/abs/2510.24723)
*Sehyun Ryu,Hyun Jong Yang*

Main category: eess.SY

TL;DR: 提出了一种端到端的阻塞感知多RIS加权和速率优化框架，通过BS发送短RIS索引同步信号，用户通过能量检测识别被阻塞的面板，然后基于检测到的可行集联合优化BS预编码器和RIS相位。


<details>
  <summary>Details</summary>
Motivation: 毫米波多用户MIMO系统对阻塞高度敏感，而RIS本身也可能被阻塞，但大多数先前工作假设理想的RIS可用性。

Method: 提出闭环黎曼相位对齐(CRPA)算法，通过BS传输短RIS索引同步信号，用户进行能量检测识别阻塞面板，然后联合优化BS预编码器和RIS相位。CRPA提供保持单位模数的闭式更新，无需投影或线搜索。

Result: 仿真验证了可靠的阻塞检测性能，以及在加权和速率和收敛性方面相比现有基线方法的显著提升。

Conclusion: 该框架能够有效应对RIS阻塞问题，通过阻塞感知优化实现了性能提升。

Abstract: Millimeter-wave (mmWave) multi-user MIMO systems are highly vulnerable to
blockage, and reconfigurable intelligent surfaces (RIS) have been proposed as a
remedy. However, RIS links may themselves be blocked, while most prior works
assume ideal RIS availability. We propose an end-to-end blockage-aware
multi-RIS weighted sum-rate (WSR) optimization framework. The BS transmits
short per-RIS indexed synchronization signals, enabling each user to identify
blocked panels through a simple energy detection test. Based on the detected
feasible sets, we jointly optimize the BS precoder and RIS phases via a
Closed-form Riemannian Phase Alignment (CRPA) algorithm. CRPA provides
unit-modulus-preserving closed-form updates, requiring no projection or line
search, and ensures monotone ascent. Simulations validate reliable blockage
detection and notable WSR and convergence gains over existing baselines.

</details>


### [236] [Constructive Lyapunov Functions via Topology-Preserving Neural Networks](https://arxiv.org/abs/2510.24730)
*Jaehong Oh*

Main category: eess.SY

TL;DR: ONN算法在收敛速率、边缘效率和计算复杂度方面达到最优性能，在300万节点语义网络上相比基线方法提升99.75%，ORTSF集成到Transformer中在WikiText-103上实现14.7%困惑度降低和2.3倍收敛加速。


<details>
  <summary>Details</summary>
Motivation: 将Massera的抽象存在定理转化为具体可扩展算法，为神经网络、机器人和分布式系统中的构造性稳定性分析开辟新途径。

Method: 提出ONN算法，建立与最优控制、信息几何、拓扑数据分析、离散几何和范畴论的深度联系，集成ORTSF到Transformer架构。

Result: 在3M节点语义网络上实现指数收敛（μ=3.2×10⁻⁴）和拓扑保持，ORTSF集成使Transformer在WikiText-103上困惑度降低14.7%，收敛速度提升2.3倍。

Conclusion: 该工作将抽象理论转化为具有可证明保证的具体算法，为多个领域的稳定性分析提供了新工具和方法。

Abstract: We prove that ONN achieves order-optimal performance on convergence rate
($\mu \propto \lambda_2$), edge efficiency ($E = N$ for minimal connectivity $k
= 2$), and computational complexity ($O(N d^2)$). Empirical validation on
3M-node semantic networks demonstrates 99.75\% improvement over baseline
methods, confirming exponential convergence ($\mu = 3.2 \times 10^{-4}$) and
topology preservation. ORTSF integration into transformers achieves 14.7\%
perplexity reduction and 2.3 faster convergence on WikiText-103. We establish
deep connections to optimal control (Hamilton-Jacobi-Bellman), information
geometry (Fisher-efficient natural gradient), topological data analysis
(persistent homology computation in $O(KN)$), discrete geometry (Ricci flow),
and category theory (adjoint functors). This work transforms Massera's abstract
existence theorem into a concrete, scalable algorithm with provable guarantees,
opening pathways for constructive stability analysis in neural networks,
robotics, and distributed systems.

</details>


### [237] [Principal and Combination Parametric Resonances of an Electromagnetically Suspended Vehicle subject to Base Excitation](https://arxiv.org/abs/2510.24756)
*Jithu Paul,Karel N. van Dalen,Andrei B. Faragau,Rens J. van Leijden,Biagio Carboni,Andrei V. Metrikine*

Main category: eess.SY

TL;DR: 该论文研究了电磁悬浮车辆在周期性激励下的动态稳定性，分析了由表面不平整或外部噪声引起的支撑振动对系统稳定性的影响，建立了三自由度模型并推导了控制方程，通过扩展Hills方法和Floquet理论探索了参数共振现象。


<details>
  <summary>Details</summary>
Motivation: 电磁悬浮车辆（如超级高铁和磁悬浮系统）与支撑之间的间隙很小，使得系统对外部激励高度敏感，车辆振荡幅度可能与外部激励幅度相当，因此需要研究其动态稳定性。

Method: 建立三自由度车辆模型，通过力平衡、扭矩平衡和基尔霍夫定律推导控制方程，采用PD控制策略，将运动方程在稳态附近线性化得到时变系数系统，使用扩展Hills方法和Floquet理论分析参数共振。

Result: 在控制增益参数空间中获得了椭圆形的稳定性边界，主参数共振的两个椭圆尺寸比为3:1，组合参数共振的椭圆尺寸比为14:1，当所有椭圆同时存在时，组合参数共振相关的椭圆最大。

Conclusion: 电磁悬浮车辆对周期性激励高度敏感，系统参数对稳定性边界有显著影响，组合参数共振产生的稳定性边界最大，这对控制系统设计具有重要意义。

Abstract: This paper investigates the dynamic stability of an electromagnetically
suspended vehicle, encountered in Hyperloop and Maglev systems, subject to
periodic excitations caused by surface irregularities or vibration of the
support induced by external noise. The narrow clearance between the vehicle and
the support can make it highly sensitive to small oscillations, since the
admissible amplitudes of the vehicle oscillations can be comparable to external
excitation amplitude. The vehicle is modelled as a three-degree-of-freedom
model where the vehicle is suspended via two identical electromagnetic
actuators from a rigid support that oscillates. The governing equations are
derived using force and torque balances, incorporating nonlinear
electromagnetic forces, and Kirchhoffs law for the electromagnets with PD
control strategy on the airgap. The equations of motion are linearized around
the steady state induced by the surface oscillation, yielding a system with
time-periodic coefficients. We analytically explore both principal and
combination parametric resonances using an extended Hills method, and Floquet
theory is used for numerical validation. The stability boundaries are obtained
as ellipses in control gain parameter space, and the influence of system
parameters on these boundaries is characterized. For the principal parametric
resonance, the ratio of the sizes of the two obtained ellipses is three to one,
whereas for the combination parametric resonance, the ratio is fourteen to one.
When all ellipses are simultaneously present, one of the ellipses associated
with the combination parametric resonance is the largest.

</details>


### [238] [Stable-by-Design Neural Network-Based LPV State-Space Models for System Identification](https://arxiv.org/abs/2510.24757)
*Ahmet Eren Sertbaş,Tufan Kumbasar*

Main category: eess.SY

TL;DR: 提出了一种稳定设计的LPV神经网络状态空间模型，通过Schur参数化保证稳定性，直接从数据中学习潜在状态和内部调度变量。


<details>
  <summary>Details</summary>
Motivation: 传统辨识方法难以在保持稳定性的同时捕捉潜在动态，需要开发能同时学习潜在状态和调度变量的稳定模型。

Method: 结合编码器进行初始状态估计和状态空间表示网络，通过Schur参数化确保状态转移矩阵稳定，采用多步预测损失和状态一致性正则化训练。

Result: 在基准非线性系统上的评估表明，该模型始终匹配或超越经典子空间辨识方法和近期梯度方法。

Conclusion: 稳定性约束的神经LPV辨识为复杂非线性系统建模提供了一个可扩展且可靠的框架。

Abstract: Accurate modeling of nonlinear systems is essential for reliable control, yet
conventional identification methods often struggle to capture latent dynamics
while maintaining stability. We propose a \textit{stable-by-design LPV neural
network-based state-space} (NN-SS) model that simultaneously learns latent
states and internal scheduling variables directly from data. The
state-transition matrix, generated by a neural network using the learned
scheduling variables, is guaranteed to be stable through a Schur-based
parameterization. The architecture combines an encoder for initial state
estimation with a state-space representer network that constructs the full set
of scheduling-dependent system matrices. For training the NN-SS, we develop a
framework that integrates multi-step prediction losses with a state-consistency
regularization term, ensuring robustness against drift and improving
long-horizon prediction accuracy. The proposed NN-SS is evaluated on benchmark
nonlinear systems, and the results demonstrate that the model consistently
matches or surpasses classical subspace identification methods and recent
gradient-based approaches. These findings highlight the potential of
stability-constrained neural LPV identification as a scalable and reliable
framework for modeling complex nonlinear systems.

</details>


### [239] [A Digital Twin Framework for Decision-Support and Optimization of EV Charging Infrastructure in Localized Urban Systems](https://arxiv.org/abs/2510.24758)
*Linh Do-Bui-Khanh,Thanh H. Nguyen,Nghi Huynh Quang,Doanh Nguyen-Ngoc,Laurent El Ghaoui*

Main category: eess.SY

TL;DR: 提出一个数字孪生框架，通过基于代理的决策支持和嵌入式优化，动态模拟电动汽车充电行为、基础设施布局和政策响应，应用于河内大学校园场景。


<details>
  <summary>Details</summary>
Motivation: 随着城市环境中电动汽车采用加速，优化充电基础设施对于平衡用户满意度、能源效率和财务可行性至关重要，需要超越静态模型的动态仿真方法。

Method: 采用数字孪生框架，整合基于代理的决策支持和嵌入式元启发式优化，动态模拟充电行为、基础设施配置和政策响应，通过交互式仪表板进行季节性分析。

Result: 实时通知新可用充电位提高用户满意度；汽油禁令和闲置费提高充电位周转率；嵌入式优化找到快充和标准太阳能充电器的近优组合；太阳能效率10月至3月下降20%，风电贡献不足5%。

Conclusion: 该数字孪生提供了一个灵活、计算驱动的电动汽车基础设施规划平台，具有可转移的模块化设计，能够从局部无缝扩展到城市范围。

Abstract: As Electric Vehicle (EV) adoption accelerates in urban environments,
optimizing charging infrastructure is vital for balancing user satisfaction,
energy efficiency, and financial viability. This study advances beyond static
models by proposing a digital twin framework that integrates agent-based
decision support with embedded optimization to dynamically simulate EV charging
behaviors, infrastructure layouts, and policy responses across scenarios.
Applied to a localized urban site (a university campus) in Hanoi, Vietnam, the
model evaluates operational policies, EV station configurations, and renewable
energy sources. The interactive dashboard enables seasonal analysis, revealing
a 20% drop in solar efficiency from October to March, with wind power
contributing under 5% of demand, highlighting the need for adaptive energy
management. Simulations show that real-time notifications of newly available
charging slots improve user satisfaction, while gasoline bans and idle fees
enhance slot turnover with minimal added complexity. Embedded metaheuristic
optimization identifies near-optimal mixes of fast (30kW) and standard (11kW)
solar-powered chargers, balancing energy performance, profitability, and demand
with high computational efficiency. This digital twin provides a flexible,
computation-driven platform for EV infrastructure planning, with a
transferable, modular design that enables seamless scaling from localized to
city-wide urban contexts.

</details>


### [240] [Decentralized Merging Control of Connected and Automated Vehicles to Enhance Safety and Energy Efficiency using Control Barrier Functions](https://arxiv.org/abs/2510.24871)
*Shreshta Rajakumar Deshpande,Mrdjan Jankovic*

Main category: eess.SY

TL;DR: 提出了一种基于去中心化控制屏障函数的高速公路合流控制方法，CAV车辆通过预测-校正循环进行协商，实现安全节能的合流操作。


<details>
  <summary>Details</summary>
Motivation: 解决高速公路合流场景中CAV车辆的安全合流问题，提高系统能效和交通流效率，避免传统方法中的死锁问题。

Method: 采用去中心化CBF控制算法，车辆在控制区内与其他智能体协商，通过预测-校正循环解决分歧，无需明确车辆顺序或优先级。

Result: 蒙特卡洛仿真显示，相比FIFO方法，系统能效和交通流显著改善，且去中心化控制器比集中式对应方案更具鲁棒性。

Conclusion: 该去中心化CBF方法能有效实现CAV的安全合流，避免死锁，提高系统性能和鲁棒性。

Abstract: This paper presents a decentralized Control Barrier Function (CBF) based
approach for highway merging of Connected and Automated Vehicles (CAVs). In
this control algorithm, each "host" vehicle negotiates with other agents in a
control zone of the highway network, and enacts its own action, to perform safe
and energy-efficient merge maneuvers. It uses predictor-corrector loops within
the robust CBF setting for negotiation and to reconcile disagreements that may
arise. There is no explicit order of vehicles and no priority. A notable
feature is absence of gridlocks due to instability of the inter-agent system.
Results from Monte Carlo simulations show significant improvement in the
system-wide energy efficiency and traffic flow compared to a first-in-first-out
approach, as well as enhanced robustness of the proposed decentralized
controller compared to its centralized counterpart.

</details>


### [241] [Delay Tolerant Control for Autonomous Driving Using CDOB](https://arxiv.org/abs/2510.24898)
*Xincheng Cao,Haochong Chen,Levent Guvenc,Bilin Aksun-Guvenc*

Main category: eess.SY

TL;DR: 提出了一种延迟容忍的通信扰动观测器（CDOB）框架，用于在存在通信和计算延迟的系统中实现路径跟踪控制，提高自动驾驶车辆的轨迹跟踪精度和延迟鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，路径跟踪控制成为确保复杂交通场景下安全高效的关键。然而，联网自动驾驶车辆（CAV）受到通信延迟和计算延迟的影响，这会显著降低传统控制器（如PID）或更先进控制器（如扰动观测器DOB）的性能。DOB在名义条件下能有效抑制扰动，但在存在未知时间延迟时性能会严重下降。

Method: 提出了一种延迟容忍的通信扰动观测器（CDOB）框架，用于补偿时间延迟的不利影响，即使在不确定和变化的延迟条件下也能保持准确的轨迹跟踪。

Result: 仿真研究表明，所提出的控制架构在各种场景下（包括单车道变换、双车道变换和弹性带生成的避碰路径）都能与参考轨迹保持紧密对齐，且在不同时间延迟下均表现良好。仿真结果进一步表明，该方法在跟踪精度和延迟鲁棒性方面均优于传统方法。

Conclusion: 所提出的CDOB方法适用于自动驾驶应用，能够在存在通信和计算延迟的情况下保持准确的路径跟踪性能。

Abstract: With the rapid growth of autonomous vehicle technologies, effective
path-tracking control has become a critical component in ensuring safety and
efficiency in complex traffic scenarios. When a high level decision making
agent generates a collision free path, a robust low level controller is
required to precisely follow this trajectory. However, connected autonomous
vehicles (CAV) are inherently affected by communication delays and computation
delays, which significantly degrade the performance of conventional controllers
such as PID or other more advanced controllers like disturbance observers
(DOB). While DOB-based designs have shown effectiveness in rejecting
disturbances under nominal conditions, their performance deteriorates
considerably in the presence of unknown time delays. To address this challenge,
this paper proposes a delay-tolerant communication disturbance observer (CDOB)
framework for path-tracking control in delayed systems. The proposed CDOB
compensates for the adverse effects of time delays, maintaining accurate
trajectory tracking even under uncertain and varying delay conditions. It is
shown through a simulation study that the proposed control architecture
maintains close alignment with the reference trajectory across various
scenarios, including single lane change, double-= lane change, and Elastic Band
generated collision avoidance paths under various time delays. Simulation
results further demonstrate that the proposed method outperforms conventional
approaches in both tracking accuracy and delay robustness, making it well
suited for autonomous driving applications.

</details>


### [242] [A Hamilton-Jacobi Reachability Framework with Soft Constraints for Safety-Critical Systems](https://arxiv.org/abs/2510.24933)
*Chams Eddine Mballo,Donggun Lee,Claire J. Tomlin*

Main category: eess.SY

TL;DR: 提出了一种软约束可达性框架，扩展了Hamilton-Jacobi可达性分析，用于同时处理硬约束和软约束的安全验证问题。


<details>
  <summary>Details</summary>
Motivation: 传统可达性方法将状态约束视为不可违反的硬约束，在复杂操作场景中可能导致过于保守或不可行的解决方案。许多实际约束（如电动汽车电池状态、推荐速度范围等）本质上是软约束，允许在安全范围内临时违反。

Method: 框架包含两个主要组件：(1) 带有辅助预算状态的增广状态模型，用于跟踪软约束违反情况；(2) 基于正则化的Hamilton-Jacobi值函数近似方法，处理可达-避让微分博弈中的不连续性。

Result: 通过点质量模型着陆和固定翼飞机紧急下降的数值示例验证了框架的有效性，证明其能够在安全关键设置中同时管理硬约束和软约束。

Conclusion: 该软约束可达性框架为安全关键系统提供了形式化验证方法，能够处理实际应用中常见的软约束问题，在保证安全的同时提高了解决方案的可行性。

Abstract: Traditional reachability methods provide formal guarantees of safety under
bounded disturbances. However, they strictly enforce state constraints as
inviolable, which can result in overly conservative or infeasible solutions in
complex operational scenarios. Many constraints encountered in practice, such
as bounds on battery state of charge in electric vehicles, recommended speed
envelopes, and comfort constraints in passenger-carrying vehicles, are
inherently soft. Soft constraints allow temporary violations within predefined
safety margins to accommodate uncertainty and competing operational demands,
albeit at a cost such as increased wear or higher operational expenses. This
paper introduces a novel soft-constrained reachability framework that extends
Hamilton-Jacobi reachability analysis for the formal verification of
safety-critical systems subject to both hard and soft constraints.
Specifically, the framework characterizes a subset of the state space, referred
to as the soft-constrained reach-avoid set, from which the system is guaranteed
to reach a desired set safely, under worst-case disturbances, while ensuring
that cumulative soft-constraint violations remain within a user-specified
budget. The framework comprises two principal components: (i) an
augmented-state model with an auxiliary budget state that tracks
soft-constraint violations, and (ii) a regularization-based approximation of
the discontinuous Hamilton-Jacobi value function associated with the
reach-avoid differential game studied herein. The effectiveness of the proposed
framework is demonstrated through numerical examples involving the landing of a
simple point-mass model and a fixed-wing aircraft executing an emergency
descent, both under wind disturbances. The simulation results validate the
framework's ability to simultaneously manage both hard and soft constraints in
safety-critical settings

</details>


### [243] [Control Synthesis with Reinforcement Learning: A Modeling Perspective](https://arxiv.org/abs/2510.25063)
*Nikki Xu,Hien Tran*

Main category: eess.SY

TL;DR: 基于强化学习的控制器对模型失配敏感，在虚拟仿真中设计的控制器可能无法在实际物理环境中部署。使用准确模型设计的控制器具有鲁棒性，而使用不准确模型设计的控制器在仿真中表现良好但在物理实验中失败。


<details>
  <summary>Details</summary>
Motivation: 研究强化学习控制器对模型失配的敏感性，验证在虚拟仿真环境中使用不准确模型设计的控制器在实际物理部署中的适用性问题。

Method: 使用灵敏度分析来验证控制器性能差异，并通过经验性的吸引域估计来可视化控制器的鲁棒性。

Result: 基于准确模型设计的控制器对扰动和小的模型失配具有鲁棒性，而基于不准确模型设计的控制器在仿真中表现良好但在物理实验中失败。

Conclusion: 控制器设计对模型准确性高度敏感，在虚拟仿真环境中必须使用准确模型才能确保控制器在实际物理环境中的有效部署。

Abstract: Controllers designed with reinforcement learning can be sensitive to model
mismatch. We demonstrate that designing such controllers in a virtual
simulation environment with an inaccurate model is not suitable for deployment
in a physical setup. Controllers designed using an accurate model is robust
against disturbance and small mismatch between the physical setup and the
mathematical model derived from first principles; while a poor model results in
a controller that performs well in simulation but fails in physical
experiments. Sensitivity analysis is used to justify these discrepancies and an
empirical region of attraction estimation help us visualize their robustness.

</details>


### [244] [Stochastic Long-Term Joint Decarbonization Planning for Power Systems and Data Centers: A Case Study in PJM](https://arxiv.org/abs/2510.25118)
*Zhentong Shao,Nanpeng Yu,Daniel Wong*

Main category: eess.SY

TL;DR: 提出了一个动态联合规划框架，在15年时间跨度内共同优化数据中心和电力系统的长期发展，考虑运营和隐含碳排放，通过随机规划解决多尺度不确定性。


<details>
  <summary>Details</summary>
Motivation: 随着AI和云服务的快速发展，数据中心成为关键基础设施，其能源需求和碳排放问题日益突出。现有研究大多假设静态电力系统，仅关注运营排放，忽视了协同优化。

Method: 建立大规模两阶段随机规划模型，采用增强的Benders分解算法求解，共同确定数据中心选址、容量、类型以及电力系统发电扩展、储能部署和退役决策。

Result: 在PJM互联系统应用中，系统可支持高达55GW峰值数据中心需求，弗吉尼亚和北伊利诺伊州为最优选址。相比非联合规划，投资成本降低12.6%，运营成本降低8.25%，排放减少5.63%。考虑全生命周期排放后，可再生能源部署增加25.5%。

Conclusion: 动态联合规划框架能显著降低成本和排放，隐含碳在深度脱碳中发挥重要作用，为碳感知基础设施规划提供了有效方法。

Abstract: With the rapid growth of artificial intelligence (AI) and cloud services,
data centers have become critical infrastructures driving digital economies,
with increasing energy demand heightening concerns over electricity use and
carbon emissions, emphasizing the need for carbon-aware infrastructure
planning. Most studies assume static power systems, focus only on operational
emissions, and overlook co-optimization. This paper proposes a dynamic joint
planning framework that co-optimizes long-term data center and power system
development over 15 years. The model determines siting, capacity, and type of
data centers alongside power generation expansion, storage deployment, and
retirements, accounting for both operational and embodied emissions. To handle
multi-scale uncertainty, a large-scale two-stage stochastic program is
formulated and solved via an enhanced Benders decomposition. Applied to the PJM
Interconnection, with curated datasets released on GitHub, results show the
system can support up to 55 GW peak data center demand, with Virginia (DOM) and
Northern Illinois (ComEd) as optimal hosts. Compared to non-joint planning, the
framework cuts investment cost by 12.6%, operational cost by 8.25%, and
emissions by 5.63%. Including lifecycle emissions further raises renewable
deployment by 25.5%, highlighting embodied carbon's role in deeper
decarbonization.

</details>


### [245] [The Waterbed Effect on Quasiperiodic Disturbance Observer: Avoidance of Sensitivity Tradeoff with Time Delays](https://arxiv.org/abs/2510.25131)
*Hisayoshi Muramatsu*

Main category: eess.SY

TL;DR: 本文为拟周期扰动观测器提供了连续时间和离散时间表示的Bode类灵敏度积分，阐明了使用时延避免灵敏度权衡的机制。


<details>
  <summary>Details</summary>
Motivation: 拟周期扰动观测器的开环传递函数由于包含时延而非有理函数，不满足现有Bode灵敏度积分的假设条件，需要建立新的灵敏度积分理论。

Method: 推导了拟周期扰动观测器在连续时间和离散时间表示下的Bode类灵敏度积分，分析了使用时延避免传统灵敏度权衡的数学原理。

Result: 建立了适用于拟周期扰动观测器的灵敏度积分理论，证明该观测器能够实现宽带谐波抑制，同时不放大非周期扰动或不改变谐波抑制频率。

Conclusion: 通过引入时延，拟周期扰动观测器能够规避传统线性时不变系统中的灵敏度权衡（水床效应），为扰动抑制提供了新的理论框架。

Abstract: In linear time-invariant systems, the sensitivity function to disturbances is
designed under a sensitivity tradeoff known as the waterbed effect. To
compensate for a quasiperiodic disturbance, a quasiperiodic disturbance
observer using time delays was proposed. Its sensitivity function avoids the
sensitivity tradeoff, achieving wideband harmonic suppression without
amplifying aperiodic disturbances or shifting harmonic suppression frequencies.
However, its open-loop transfer function is not rational and does not satisfy
the assumptions of existing Bode sensitivity integrals due to its time delays.
This paper provides Bode-like sensitivity integrals for the quasiperiodic
disturbance observer in both continuous-time and discrete-time representations
and clarifies the avoided sensitivity tradeoff with time delays.

</details>


### [246] [Silicon-based Josephson junction field-effect transistors enabling cryogenic logic and quantum technologies](https://arxiv.org/abs/2510.25208)
*Yusheng Xiong,Kaveh Delfanazari*

Main category: eess.SY

TL;DR: 该论文回顾了从约瑟夫森结到场效应晶体管的演变，重点分析了约瑟夫森结场效应晶体管(JJFET)作为下一代低温逻辑和量子电子系统基础构建模块的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着MOSFET持续微型化超越摩尔定律预测，需要开发创新器件范式以实现超低功耗和高速功能。JJFET通过集成超导源漏电极，有望在超低温下实现高效、相位相干操作，连接传统半导体电子学与低温逻辑和量子电路。

Method: 该综述追踪了从约瑟夫森结到场效应晶体管的演变历程，分析了在Si、GaAs和InGaAs衬底上制造的JJFET的性能和材料兼容性，特别关注超导体-硅-超导体约瑟夫森结作为JJFET架构的有源核心。

Result: 通过分析超过四十年的实验进展，展示了JJFET在低温条件下的开关动力学和材料兼容性表现，证实了其作为高效、高相干信号处理器件的潜力。

Conclusion: JJFET有望成为连接传统半导体电子学与低温逻辑和量子电路的关键桥梁，为下一代低温逻辑和量子电子系统提供基础构建模块。

Abstract: The continuous miniaturisation of metal-oxide-semiconductor field-effect
transistors (MOSFETs) from long- to short-channel architectures has advanced
beyond the predictions of Moore's Law. Continued advances in semiconductor
electronics, even near current scaling and performance boundaries under
cryogenic conditions, are driving the development of innovative device
paradigms that enable ultra-low-power and high-speed functionality. Among
emerging candidates, the Josephson Junction Field-Effect Transistor (JJFET or
JoFET) provides an alternative by integrating superconducting source and drain
electrodes for efficient, phase-coherent operation at ultra-low temperatures.
These hybrid devices have the potential to bridge conventional semiconductor
electronics with cryogenic logic and quantum circuits, enabling
energy-efficient and high-coherence signal processing across temperature
domains. This review traces the evolution from Josephson junctions to
field-effect transistors, emphasising the structural and functional innovations
that underpin modern device scalability. The performance and material
compatibility of JJFETs fabricated on Si, GaAs, and InGaAs substrates are
analysed, alongside an assessment of their switching dynamics and material
compatibility. Particular attention is given to
superconductor-silicon-superconductor Josephson junctions as the active core of
JJFET architectures. By unfolding more than four decades of experimental
progress, this work highlights the promise of JJFETs as foundational building
blocks for next-generation cryogenic logic and quantum electronic systems.

</details>


### [247] [Shared Control for Vehicle Lane-Changing with Uncertain Driver Behaviors](https://arxiv.org/abs/2510.25284)
*Jiamin Wu,Chenguang Zhao,Huan Yu*

Main category: eess.SY

TL;DR: 提出了一个人类-自动化共享变道控制框架，在保持驾驶员权限的同时通过自动化辅助实现稳定操作，解决了人类行为不确定性对交通串稳定性的影响。


<details>
  <summary>Details</summary>
Motivation: 人类驾驶员的变道行为具有随机性和不确定性，会显著降低交通串稳定性，影响车辆平稳并入。需要开发既能保持驾驶员权限又能确保稳定性的共享控制策略。

Method: 将人类驾驶行为建模为马尔可夫跳跃过程，基于任务难度驱动状态转换。设计了名义稳定控制器保证随机L2串稳定性，并开发了最小干预控制器在限制自动化程度的同时保持可接受的稳定性。

Result: 在NGSIM数据集上的仿真显示，名义控制器减少了速度扰动并缩短了变道时间，最小干预控制器进一步减少了自动化努力并提高了舒适度，但稳定性略有损失。在TGSIM数据集上验证显示最小干预控制器比SAE Level 2控制更早实现变道。

Conclusion: 共享控制策略能够在稳定性、效率和驾驶员接受度之间取得平衡，具有实际应用潜力。

Abstract: Lane changes are common yet challenging driving maneuvers that require
continuous decision-making and dynamic interaction with surrounding vehicles.
Relying solely on human drivers for lane-changing can lead to traffic
disturbances due to the stochastic nature of human behavior and its variability
under different task demands. Such uncertainties may significantly degrade
traffic string stability, which is critical for suppressing disturbance
propagation and ensuring smooth merging of the lane-changing vehicles. This
paper presents a human-automation shared lane-changing control framework that
preserves driver authority while allowing automated assistance to achieve
stable maneuvers in the presence of driver's behavioral uncertainty. Human
driving behavior is modeled as a Markov jump process with transitions driven by
task difficulty, providing a tractable representation of stochastic state
switching. Based on this model, we first design a nominal stabilizing
controller that guarantees stochastic ${L}_2$ string stability under imperfect
mode estimation. To further balance performance and automated effort, we then
develop a Minimal Intervention Controller (MIC) that retains acceptable
stability while limiting automation. Simulations using lane-changing data from
the NGSIM dataset verify that the nominal controller reduces speed
perturbations and shorten lane-changing time, while the MIC further reduces
automated effort and enhances comfort but with moderate stability and
efficiency loss. Validations on the TGSIM dataset with SAE Level 2 vehicles
show that the MIC enables earlier lane changes than Level 2 control while
preserving driver authority with a slight stability compromise. These findings
highlight the potential of shared control strategies to balance stability,
efficiency, and driver acceptance.

</details>


### [248] [Data-Enabled Predictive Control and Guidance for Autonomous Underwater Vehicles](https://arxiv.org/abs/2510.25309)
*Sebastian Zieglmeier,Mathias Hudoba de Badyn,Narada D. Warakagoda,Thomas R. Krogstad,Paal Engelstad*

Main category: eess.SY

TL;DR: 提出了基于数据驱动预测控制(DeePC)的自主水下航行器全数据驱动控制框架，无需显式水动力学建模，通过测量数据预测和优化系统行为。


<details>
  <summary>Details</summary>
Motivation: 消除对显式水动力学建模的需求，利用测量数据直接实现自主水下航行器的控制，降低建模工作量。

Method: 使用经典DeePC进行航向控制，提出级联DeePC架构进行深度调节，结合自适应视线算法与DeePC实现3D航路点路径跟踪。

Result: 在REMUS 100 AUV上进行广泛仿真验证，相比传统PI/PID控制，DeePC在海洋流扰动和非线性工况下表现出优越的跟踪性能和鲁棒性。

Conclusion: DeePC方法显著减少了建模工作量，在自主水下航行器控制中展现出优异的性能和鲁棒性。

Abstract: This paper presents a fully data-driven control framework for autonomous
underwater vehicles (AUVs) based on Data-Enabled Predictive Control (DeePC).
The approach eliminates the need for explicit hydrodynamic modeling by
exploiting measured input-output data to predict and optimize future system
behavior. Classic DeePC was employed in the heading control, while a cascaded
DeePC architecture is proposed for depth regulation, incorporating a
loop-frequency separation to handle the different dynamic modes of input and
output. For 3-D waypoint path following, the Adaptive Line-of-Sight algorithm
is extended to a predictive formulation and integrated with DeePC. All methods
are validated in extensive simulation on the REMUS 100 AUV and compared with
classical PI/PID control. The results demonstrate superior tracking performance
and robustness of DeePC under ocean-current disturbances and nonlinear
operating conditions, while significantly reducing modeling effort.

</details>


### [249] [Tight Collision Avoidance for Stochastic Optimal Control: with Applications in Learning-based, Interactive Motion Planning](https://arxiv.org/abs/2510.25324)
*Erik Börve,Nikolce Murgovski,Leo Laine*

Main category: eess.SY

TL;DR: 提出了一种随机最优控制框架，用于处理密集交互交通场景中的轨迹规划问题，同时解决人类驾驶员行为不确定性和非凸碰撞避免约束的挑战。


<details>
  <summary>Details</summary>
Motivation: 在密集交互交通场景中，自动驾驶车辆的轨迹规划面临重大挑战，主要由于人类驾驶员行为的不确定性和碰撞避免约束的非凸性质。

Method: 将人类驾驶员决策建模为马尔可夫决策过程，提出处理非凸车辆形状间碰撞避免的方法，通过施加紧凑集间的正距离约束。研究了三种替代机会约束公式，并引入了非凸距离约束和机会约束的紧致连续可微重构以确保计算可行性。

Result: 通过两个具有挑战性的交互场景仿真研究验证了方法的有效性：无管制交叉口穿越和密集交通中的高速公路变道。

Conclusion: 该随机最优控制框架能够同时处理人类行为不确定性和非凸碰撞约束，而无需过度保守的近似，在复杂交互交通场景中表现出良好性能。

Abstract: Trajectory planning in dense, interactive traffic scenarios presents
significant challenges for autonomous vehicles, primarily due to the
uncertainty of human driver behavior and the non-convex nature of collision
avoidance constraints. This paper introduces a stochastic optimal control
framework to address these issues simultaneously, without excessively
conservative approximations. We opt to model human driver decisions as a Markov
Decision Process and propose a method for handling collision avoidance between
non-convex vehicle shapes by imposing a positive distance constraint between
compact sets. In this framework, we investigate three alternative chance
constraint formulations. To ensure computational tractability, we introduce
tight, continuously differentiable reformulations of both the non-convex
distance constraints and the chance constraints. The efficacy of our approach
is demonstrated through simulation studies of two challenging interactive
scenarios: an unregulated intersection crossing and a highway lane change in
dense traffic.

</details>


### [250] [Lightweight Federated Learning in Mobile Edge Computing with Statistical and Device Heterogeneity Awareness](https://arxiv.org/abs/2510.25342)
*Jinghong Tan,Zhichen Zhang,Kun Guo,Tsung-Hui Chang,Tony Q. S. Quek*

Main category: eess.SY

TL;DR: 提出了一种轻量级个性化联邦学习框架，通过参数解耦将模型分为共享和私有子空间，分别应用梯度稀疏化和模型剪枝，在异构环境下显著降低通信和计算成本。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在移动边缘计算中存在高通信和计算成本问题，特别是在统计和设备异构环境下。现有压缩方法可能增加训练轮次，导致总训练成本上升。

Method: 基于参数解耦的个性化联邦学习框架，将模型分离为共享和私有子空间，对共享组件应用梯度稀疏化，对私有组件应用模型剪枝，并联合优化稀疏度、剪枝率和无线带宽。

Result: 仿真结果显示，该方法实现了更快的收敛速度，显著降低了整体通信和计算成本，且准确率损失可忽略不计。

Conclusion: 在资源受限的异构环境中，协调和资源感知的个性化方法能够有效平衡压缩效率与模型性能。

Abstract: Federated learning enables collaborative machine learning while preserving
data privacy, but high communication and computation costs, exacerbated by
statistical and device heterogeneity, limit its practicality in mobile edge
computing. Existing compression methods like sparsification and pruning reduce
per-round costs but may increase training rounds and thus the total training
cost, especially under heterogeneous environments. We propose a lightweight
personalized FL framework built on parameter decoupling, which separates the
model into shared and private subspaces, enabling us to uniquely apply gradient
sparsification to the shared component and model pruning to the private one.
This structural separation confines communication compression to global
knowledge exchange and computation reduction to local personalization,
protecting personalization quality while adapting to heterogeneous client
resources. We theoretically analyze convergence under the combined effects of
sparsification and pruning, revealing a sparsity-pruning trade-off that links
to the iteration complexity. Guided by this analysis, we formulate a joint
optimization that selects per-client sparsity and pruning rates and wireless
bandwidth to reduce end-to-end training time. Simulation results demonstrate
faster convergence and substantial reductions in overall communication and
computation costs with negligible accuracy loss, validating the benefits of
coordinated and resource-aware personalization in resource-constrained
heterogeneous environments.

</details>


### [251] [Quantum-Resilient Threat Modelling for Secure RIS-Assisted ISAC in 6G UAV Corridors](https://arxiv.org/abs/2510.25411)
*Sana Hafeez,Ghulam E Mustafa Abro,Hifza Mustafa*

Main category: eess.SY

TL;DR: 提出了一个量子弹性威胁建模框架（QRTM），用于无人机走廊中的RIS辅助ISAC系统，通过后量子密码学、RIS编码场景水印和安全ISAC效用优化，实现接近0.99的欺骗检测概率和90%以上的保密率保持。


<details>
  <summary>Details</summary>
Motivation: 6G网络中无人机走廊的快速部署需要安全的智能驱动ISAC，而RIS在提升频谱效率和定位精度的同时引入了新的安全漏洞，量子计算的兴起进一步增加了窃听和欺骗的风险。

Method: QRTM框架集成经典、量子就绪和量子辅助攻击者，使用ML-KEM密钥建立和Falcon认证的后量子密码学原语，引入RIS编码场景水印并通过GLRT验证，采用复杂度为O(n^2)的调度器优化保密率、欺骗检测和吞吐量。

Result: 基于3GPP Release 19中频城市峡谷模型的蒙特卡洛评估显示，欺骗检测概率接近0.99（误报率1e-3），对量子能力攻击者的保密率保持超过90%，信号干扰利用率比基线提高约25%。

Conclusion: 该框架为智慧城市和非地面网络中的无人机走廊提供了一条符合标准的可靠量子弹性ISAC路径。

Abstract: The rapid deployment of unmanned aerial vehicle (UAV) corridors in
sixth-generation (6G) networks requires safe, intelligence-driven integrated
sensing and communications (ISAC). Reconfigurable intelligent surfaces (RIS)
enhance spectrum efficiency, localisation accuracy, and situational awareness,
while introducing new vulnerabilities. The rise of quantum computing increases
the risks associated with harvest-now-decrypt-later strategies and
quantum-enhanced spoofing. We propose a Quantum-Resilient Threat Modelling
(QRTM) framework for RIS-assisted ISAC in UAV corridors to address these
challenges. QRTM integrates classical, quantum-ready, and quantum-aided
adversaries, countered using post-quantum cryptographic (PQC) primitives:
ML-KEM for key establishment and Falcon for authentication, both embedded
within RIS control signalling and UAV coordination. To strengthen security
sensing, the framework introduces RIS-coded scene watermarking validated
through a generalised likelihood ratio test (GLRT), with its detection
probability characterised by the Marcum Q function. Furthermore, a Secure ISAC
Utility (SIU) jointly optimises secrecy rate, spoofing detection, and
throughput under RIS constraints, enabled by a scheduler with computational
complexity of O(n^2). Monte Carlo evaluations using 3GPP Release 19 mid-band
urban-canyon models (7-15 GHz) demonstrate a spoof-detection probability
approaching 0.99 at a false-alarm rate of 1e-3, secrecy-rate retention
exceeding 90 percent against quantum-capable adversaries, and
signal-interference utilisation improvements of about 25 percent compared with
baselines. These results show a standards-compliant path towards reliable,
quantum-resilient ISAC for UAV corridors in smart cities and non-terrestrial
networks.

</details>


### [252] [A New Neural Network Paradigm for Scalable and Generalizable Stability Analysis of Power Systems](https://arxiv.org/abs/2510.25501)
*Tong Han,Yan Xu,Rui Zhang*

Main category: eess.SY

TL;DR: 提出了一种用于电力系统稳定性分析的新型神经网络范式，包括神经网络稳定性描述符和样本增强迭代训练方案，能够实现可扩展和可泛化的稳定性分析。


<details>
  <summary>Details</summary>
Motivation: 为了解决电力系统稳定性分析在系统结构和参数变化时的可扩展性和泛化性问题，传统方法难以适应不同系统配置。

Method: 基于系统分解构建稳定性分析对象作为多个神经网络的聚合，这些网络在不同系统结构和参数下保持不变，通过样本增强迭代训练方案学习稳定性描述符。

Result: 在大电网大扰动稳定性分析和微电网小扰动稳定性条件两个实现中，数值研究证明了该神经网络范式的适用性和有效性。

Conclusion: 提出的神经网络范式为电力系统稳定性分析提供了一种可扩展和可泛化的解决方案，能够适应不同的系统配置和参数变化。

Abstract: This paper presents a new neural network (NN) paradigm for scalable and
generalizable stability analysis of power systems. The paradigm consists of two
parts: the neural stability descriptor and the sample-augmented iterative
training scheme. The first part, based on system decomposition, constructs the
object (such as a stability function or condition) for stability analysis as a
scalable aggregation of multiple NNs. These NNs remain fixed across varying
power system structures and parameters, and are repeatedly shared within each
system instance defined by these variations, thereby enabling the
generalization of the neural stability descriptor across a class of power
systems. The second part learns the neural stability descriptor by iteratively
training the NNs with sample augmentation, guided by the tailored
conservativeness-aware loss function. The training set is strategically
constructed to promote the descriptor's generalizability, which is
systematically evaluated by verification and validation during the training
process. Specifically, the proposed NN paradigm is implemented for
large-disturbance stability analysis of the bulk power grid and
small-disturbance stability conditions of the microgrid system. Finally,
numerical studies for the two implementations demonstrate the applicability and
effectiveness of the proposed NN paradigm.

</details>


### [253] [Optimal and Heuristic Approaches for Platooning Systems with Deadlines](https://arxiv.org/abs/2510.25564)
*Thiago S. Gomides,Evangelos Kranakis,Ioannis Lambadaris,Yannis Viniotis,Gennady Shaikhet*

Main category: eess.SY

TL;DR: 研究带截止期限约束的卡车编队优化问题，提出基于马尔可夫决策过程的最优策略，并开发启发式算法解决状态空间爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 卡车编队能降低货运成本、减少燃料消耗和排放，但必须满足出发时间窗口要求以避免罚款。

Method: 将问题建模为马尔可夫决策过程，分析最优策略结构，提出条件启发式和深度学习启发式算法。

Result: 证明了最优策略在状态空间上的单调性，识别了不可达状态类别，提出的启发式算法在保持低计算复杂度的同时利用了结构洞察。

Conclusion: 通过结构分析和启发式方法，有效解决了卡车编队调度中的状态空间爆炸问题，平衡了编队效率与截止期限约束。

Abstract: Efficient truck platooning is a key strategy for reducing freight costs,
lowering fuel consumption, and mitigating emissions. Deadlines are critical in
this context, as trucks must depart within specific time windows to meet
delivery requirements and avoid penalties. In this paper, we investigate the
optimal formation and dispatch of truck platoons at a highway station with
finite capacity $L$ and deadline constraints $T$. The system operates in
discrete time, with each arriving truck assigned a deadline of $T$ slot units.
The objective is to leverage the efficiency gains from forming large platoons
while accounting for waiting costs and deadline violations. We formulate the
problem as a Markov decision process and analyze the structure of the optimal
policy $\pi^\star$ for $L = 3$, extending insights to arbitrary $L$. We prove
that the $\pi^\star$ is monotone in the state space $\mathcal{S}$ and identify
classes of unreachable states. Moreover, since $\mathcal{S}$ grows
exponentially with $L$ and $T$, we propose heuristics-including conditional and
deep-learning based approaches-that exploit these structural insights while
maintaining low computational complexity.

</details>


### [254] [Incorporating Social Awareness into Control of Unknown Multi-Agent Systems: A Real-Time Spatiotemporal Tubes Approach](https://arxiv.org/abs/2510.25597)
*Siddhartha Upadhyay,Ratnangshu Das,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 提出了一种结合社会意识的分散式控制框架，用于具有未知动力学的多智能体系统，在规定时间内完成到达-避障-停留任务。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中引入社会意识，量化智能体的合作或自利程度，实现异构社会行为，在动态环境中保证安全性和时间约束。

Method: 基于时空管框架，提出实时STT框架在线合成每个智能体的管，捕获其社会交互。推导闭式、无近似的控制律确保智能体在演化STT内运动。

Result: 方法提供安全性和时间的形式保证，计算轻量、无模型且对未知干扰具有鲁棒性。通过2D全向仿真和硬件实验验证有效性和可扩展性。

Conclusion: 该框架成功实现了社会意识的多智能体控制，在规定时间内完成复杂任务，具有良好的实际应用前景。

Abstract: This paper presents a decentralized control framework that incorporates
social awareness into multi-agent systems with unknown dynamics to achieve
prescribed-time reach-avoid-stay tasks in dynamic environments. Each agent is
assigned a social awareness index that quantifies its level of cooperation or
self-interest, allowing heterogeneous social behaviors within the system.
Building on the spatiotemporal tube (STT) framework, we propose a real-time STT
framework that synthesizes tubes online for each agent while capturing its
social interactions with others. A closed-form, approximation-free control law
is derived to ensure that each agent remains within its evolving STT, thereby
avoiding dynamic obstacles while also preventing inter-agent collisions in a
socially aware manner, and reaching the target within a prescribed time. The
proposed approach provides formal guarantees on safety and timing, and is
computationally lightweight, model-free, and robust to unknown disturbances.
The effectiveness and scalability of the framework are validated through
simulation and hardware experiments on a 2D omnidirectional

</details>


### [255] [An OPF-based Control Framework for Hybrid AC-MTDC Power Systems under Uncertainty](https://arxiv.org/abs/2510.25671)
*Hongjin Du,Rahul Rane,Weijie Xia,Pedro P. Vergara,Aleksandra Lekić*

Main category: eess.SY

TL;DR: 提出了一种基于预测集成最优潮流的自适应控制框架，用于应对高比例可再生能源接入带来的系统不确定性，通过硬件在环仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 可再生能源（特别是海上风电）的日益集成给混合交流-高压直流系统带来了显著的不确定性，传统控制策略依赖固定设定点且忽略频率偏差，在快速可再生能源波动下可能危及系统稳定性。

Method: 使用随机森林模型生成风速预测，将其集成到时间耦合最优潮流中确定基准换流器设定点，并基于实际运行条件实时调整；开发了同时考虑直流电压和交流频率偏差的自适应下垂控制方案。

Result: 通过硬件在环仿真验证，所提出的控制框架能够确保高比例可再生能源接入下混合交流-高压直流系统的稳定和鲁棒运行。

Conclusion: 该预测集成的自适应控制框架有效解决了可再生能源波动带来的系统稳定性挑战，为混合交流-高压直流系统提供了可靠的运行保障。

Abstract: The increasing integration of renewable energy, particularly offshore wind,
introduces significant uncertainty into hybrid AC-HVDC systems due to forecast
errors and power fluctuations. Conventional control strategies typically rely
on fixed setpoints and neglect frequency deviations, which can compromise
system stability under rapid renewable variations. To address this challenge,
this paper presents a forecast-integrated, optimal power flow (OPF)-based
adaptive control framework. Wind speed forecasts generated using a Random
Forest model are incorporated into a time-coupled OPF to determine baseline
converter setpoints in anticipation of wind fluctuations, which are further
adjusted in real time based on actual operating conditions. An adaptive droop
control scheme is developed that jointly considers DC voltage and AC frequency
deviations. The effectiveness of the proposed control framework is validated
through hardware-in-the-loop (HIL) simulations, demonstrating its capability to
ensure stable and robust operation of hybrid AC-HVDC systems under high
penetration of renewable energy.

</details>


### [256] [Over 3 kV and Ultra-Low leakage Vertical (011) \b{eta}-Ga2O3 Power Diodes with Engineered Schottky Contact and High-permittivity Dielectric Field Plate](https://arxiv.org/abs/2510.25695)
*Emerson J. Hollar,Esmat Farzana*

Main category: eess.SY

TL;DR: 该论文报道了采用肖特基势垒工程和高介电常数介质场板的(011)β-Ga2O3功率器件，实现了超过3 kV的击穿电压和超低漏电流。


<details>
  <summary>Details</summary>
Motivation: 开发具有高击穿电压和低漏电流的垂直β-Ga2O3功率开关器件，以满足kV级功率应用的需求。

Method: 采用(011)取向的β-Ga2O3衬底，结合复合Pt帽/PtOx/Pt肖特基接触进行势垒工程，并使用高介电常数ZrO2介质场板进行边缘电场管理。

Result: 场板器件击穿电压从1.5 kV提升至3.7 kV，同时保持相似的开启电压，实现了超低漏电流特性。

Conclusion: 复合肖特基接触与高介电常数场板的组合，结合(011)β-Ga2O3的优异材料特性，为开发超低漏电多kV级垂直功率器件提供了有前景的策略。

Abstract: We report over 3 kV breakdown voltage and ultra-low leakage (011)
\b{eta}-Ga2O3 power devices utilizing Schottky barrier engineering and
high-permittivity (\k{appa}) dielectric (ZrO2) field plate. The (011)
orientation of \b{eta}-Ga2O3 enabled low background doping and thick drift
layers which are promising to support kV-class vertical \b{eta}-Ga2O3 power
switches. The Schottky barrier engineering was performed with a composite Pt
cap/PtOx/Pt (1.5 nm) anode contact to take advantage of the enhanced reverse
blocking capabilities enabled by PtOx while allowing low turn-on voltage by the
interfacing thin Pt layer. We also performed a systematic study using a
co-processed Pt/(011) \b{eta}-Ga2O3 Schottky barrier diodes (SBDs) on the same
wafer. The bare SBDs revealed a breakdown voltage of ~1.5 kV, while the
field-plate Pt/(011) \b{eta}-Ga2O3 SBDs achieved an increased breakdown voltage
of 2.75 kV owing to the edge field management. Further enhancement of the
breakdown voltage was achieved by tunneling leakage management using composite
Pt cap/PtOx/Pt (1.5 nm) Schottky contacts that ultimately enabled breakdown
voltage of 3.7 kV for the field-plate diodes. Remarkably, the Pt cap/PtOx/Pt
(1.5 nm) Schottky contacts maintained similar turn-on voltage as the Pt/(011)
\b{eta}-Ga2O3 SBDs. The combination of efficient tunneling leakage management
by composite Pt cap/PtOx/Pt (1.5 nm) contacts with similar turn-on voltage,
edge field reduction by high-\k{appa} dielectric ZrO2 field plate, as well as
the advantageous material properties offered by (011) \b{eta}-Ga2O3 demonstrate
a promising strategy for developing ultra-low leakage and multi-kV class
vertical (011) \b{eta}-Ga2O3 power devices.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [257] [Modelling the Interplay of Eye-Tracking Temporal Dynamics and Personality for Emotion Detection in Face-to-Face Settings](https://arxiv.org/abs/2510.24720)
*Meisam J. Seikavandi,Jostein Fimland,Fabricio Batista Narcizo,Maria Barrett,Ted Vucurevich,Jesper Bünsow Boldt,Andrew Burke Dittberner,Paolo Burelli*

Main category: cs.HC

TL;DR: 提出了一种结合眼动追踪、人格特质和情境刺激的多模态框架，用于预测感知情绪和感受情绪，在CREMA-D数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在动态对话环境中准确识别人类情绪对于自适应人机交互至关重要，但现有方法在处理情绪主观性方面仍面临挑战。

Method: 使用神经网络模型捕捉时间性眼动动态，并将其与大五人格特质和情境刺激信息融合，与SVM和文献基线进行比较。

Result: 刺激线索显著提升感知情绪预测（宏F1达0.77），人格特质对感受情绪识别改进最大（宏F1达0.58）。

Conclusion: 结合生理、特质和情境信息能有效处理情绪的主观性，区分感知和感受响应有助于推进多模态情感计算，实现更个性化和生态有效的情绪感知系统。

Abstract: Accurate recognition of human emotions is critical for adaptive
human-computer interaction, yet remains challenging in dynamic,
conversation-like settings. This work presents a personality-aware multimodal
framework that integrates eye-tracking sequences, Big Five personality traits,
and contextual stimulus cues to predict both perceived and felt emotions.
Seventy-three participants viewed speech-containing clips from the CREMA-D
dataset while providing eye-tracking signals, personality assessments, and
emotion ratings. Our neural models captured temporal gaze dynamics and fused
them with trait and stimulus information, yielding consistent gains over SVM
and literature baselines. Results show that (i) stimulus cues strongly enhance
perceived-emotion predictions (macro F1 up to 0.77), while (ii) personality
traits provide the largest improvements for felt emotion recognition (macro F1
up to 0.58). These findings highlight the benefit of combining physiological,
trait-level, and contextual information to address the inherent subjectivity of
emotion. By distinguishing between perceived and felt responses, our approach
advances multimodal affective computing and points toward more personalized and
ecologically valid emotion-aware systems.

</details>


### [258] [AmarDoctor: An AI-Driven, Multilingual, Voice-Interactive Digital Health Application for Primary Care Triage and Patient Management to Bridge the Digital Health Divide for Bengali Speakers](https://arxiv.org/abs/2510.24724)
*Nazmun Nahar,Ritesh Harshad Ruparel,Shariar Kabir,Sumaiya Tasnia Khan,Shyamasree Saha,Mamunur Rashid*

Main category: cs.HC

TL;DR: AmarDoctor是一个面向孟加拉语使用者的多语言语音交互数字健康应用，提供患者分诊和AI驱动的临床决策支持，在诊断精度和专业推荐精度方面优于医生平均水平。


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉语人群在数字医疗领域的服务不足问题，现有平台主要服务于欧洲人群和语言，缺乏针对孟加拉语使用者的数字医疗解决方案。

Method: 采用双界面系统（患者端和医疗提供者端），支持三种主要孟加拉方言。患者模块使用自适应提问算法评估症状并引导用户到合适的专科医生，集成语音交互AI助手克服数字素养障碍。医疗提供者界面整合AI驱动的决策支持，生成结构化临时诊断和治疗建议。

Result: 在185个临床案例验证中，AmarDoctor的top-1诊断精度达81.08%（医生平均50.27%），top专业推荐精度达91.35%（医生平均62.6%）。

Conclusion: AmarDoctor有效解决了孟加拉语人群的数字医疗可及性问题，在诊断和专业推荐方面表现出色，为服务不足人群提供了可行的数字医疗解决方案。

Abstract: This study presents AmarDoctor, a multilingual voice-interactive digital
health app designed to provide comprehensive patient triage and AI-driven
clinical decision support for Bengali speakers, a population largely
underserved in access to digital healthcare. AmarDoctor adopts a data-driven
approach to strengthen primary care delivery and enable personalized health
management. While platforms such as AdaHealth, WebMD, Symptomate, and K-Health
have become popular in recent years, they mainly serve European demographics
and languages. AmarDoctor addresses this gap with a dual-interface system for
both patients and healthcare providers, supporting three major Bengali
dialects. At its core, the patient module uses an adaptive questioning
algorithm to assess symptoms and guide users toward the appropriate specialist.
To overcome digital literacy barriers, it integrates a voice-interactive AI
assistant that navigates users through the app services. Complementing this,
the clinician-facing interface incorporates AI-powered decision support that
enhances workflow efficiency by generating structured provisional diagnoses and
treatment recommendations. These outputs inform key services such as
e-prescriptions, video consultations, and medical record management. To
validate clinical accuracy, the system was evaluated against a gold-standard
set of 185 clinical vignettes developed by experienced physicians.
Effectiveness was further assessed by comparing AmarDoctor performance with
five independent physicians using the same vignette set. Results showed
AmarDoctor achieved a top-1 diagnostic precision of 81.08 percent (versus
physicians average of 50.27 percent) and a top specialty recommendation
precision of 91.35 percent (versus physicians average of 62.6 percent).

</details>


### [259] [Beyond Models: A Framework for Contextual and Cultural Intelligence in African AI Deployment](https://arxiv.org/abs/2510.24729)
*Qness Ndlovu*

Main category: cs.HC

TL;DR: 提出CCI框架，通过文化智能和移动优先设计，使AI系统在非洲市场实现有效部署，挑战硅谷设计正统


<details>
  <summary>Details</summary>
Motivation: 全球AI发展过度关注模型性能和计算规模，但在非洲市场需要根本上不同的架构决策，以适应文化背景和资源约束

Method: 采用设计科学方法，通过为侨民社区服务的跨境购物平台验证CCI框架，包含基础设施智能、文化智能和商业智能三大技术支柱

Result: 89%用户偏好WhatsApp交互，6周内获得536用户和3938次对话，89%为家庭导向商务模式，自然接受语码转换

Conclusion: CCI框架提供理论创新和可复现实施模式，为资源受限市场的公平AI部署提供可行框架

Abstract: While global AI development prioritizes model performance and computational
scale, meaningful deployment in African markets requires fundamentally
different architectural decisions. This paper introduces Contextual and
Cultural Intelligence (CCI) -- a systematic framework enabling AI systems to
process cultural meaning, not just data patterns, through locally relevant,
emotionally intelligent, and economically inclusive design. Using design
science methodology, we validate CCI through a production AI-native
cross-border shopping platform serving diaspora communities. Key empirical
findings: 89% of users prefer WhatsApp-based AI interaction over traditional
web interfaces (n=602, chi-square=365.8, p<0.001), achieving 536 WhatsApp users
and 3,938 total conversations across 602 unique users in just 6 weeks, and
culturally informed prompt engineering demonstrates sophisticated understanding
of culturally contextualized queries, with 89% family-focused commerce patterns
and natural code-switching acceptance. The CCI framework operationalizes three
technical pillars: Infrastructure Intelligence (mobile-first, resilient
architectures), Cultural Intelligence (multilingual NLP with social context
awareness), and Commercial Intelligence (trust-based conversational commerce).
This work contributes both theoretical innovation and reproducible
implementation patterns, challenging Silicon Valley design orthodoxies while
providing actionable frameworks for equitable AI deployment across
resource-constrained markets.

</details>


### [260] [Human- vs. AI-generated tests: dimensionality and information accuracy in latent trait evaluation](https://arxiv.org/abs/2510.24739)
*Mario Angelelli,Morena Oliva,Serena Arima,Enrico Ciavolino*

Main category: cs.HC

TL;DR: 本研究比较了ChatGPT生成的问卷与人工开发的BAQ问卷，发现尽管表面措辞相似，但在维度和信息分布上存在差异，强调了统计验证对AI驱动工具的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI和大型语言模型在社会科学研究中的应用增加，需要评估AI生成测量工具的有效性，特别是与经过验证的人工开发工具进行比较。

Method: 使用ChatGPT生成两个不同明确程度的BAQ问卷改编版本，通过贝叶斯分级反应模型评估其心理测量特性。

Result: AI生成与原始问卷表面措辞相似，但在维度结构和潜在特质的信息分布上存在差异。

Conclusion: 为确保AI驱动工具的有效性和可解释性，应用统计准确性测量至关重要。

Abstract: Artificial Intelligence (AI) and large language models (LLMs) are
increasingly used in social and psychological research. Among potential
applications, LLMs can be used to generate, customise, or adapt measurement
instruments. This study presents a preliminary investigation of AI-generated
questionnaires by comparing two ChatGPT-based adaptations of the Body Awareness
Questionnaire (BAQ) with the validated human-developed version. The AI
instruments were designed with different levels of explicitness in content and
instructions on construct facets, and their psychometric properties were
assessed using a Bayesian Graded Response Model. Results show that although
surface wording between AI and original items was similar, differences emerged
in dimensionality and in the distribution of item and test information across
latent traits. These findings illustrate the importance of applying statistical
measures of accuracy to ensure the validity and interpretability of AI-driven
tools.

</details>


### [261] [Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems](https://arxiv.org/abs/2510.24893)
*María Angélica Benítez,Rocío Candela Ceballos,Karina Del Valle Molina,Sofía Mundo Araujo,Sofía Evangelina Victorio Villaroel,Nadia Justel*

Main category: cs.HC

TL;DR: 短期接触AI工具能提高任务效率但不会改变核心认知能力


<details>
  <summary>Details</summary>
Motivation: 研究AI是仅仅提高效率还是真正改变人类思维方式

Method: 30名年轻成年人参与7周实验，其中4周在线干预，使用或不使用ChatGPT完成问题解决和语言理解任务

Result: AI辅助组完成任务更快更准确，但在标准化问题解决和语言理解测试中没有显著差异

Conclusion: 当前窄AI系统作为认知支架扩展性能，但不改变基本心智能力，需要建立促进批判性和自主思考的伦理教育框架

Abstract: The growing integration of artificial intelligence (AI) into human cognition
raises a fundamental question: does AI merely improve efficiency, or does it
alter how we think? This study experimentally tested whether short-term
exposure to narrow AI tools enhances core cognitive abilities or simply
optimizes task performance. Thirty young adults completed standardized
neuropsychological assessments embedded in a seven-week protocol with a
four-week online intervention involving problem-solving and verbal
comprehension tasks, either with or without AI support (ChatGPT). While
AI-assisted participants completed several tasks faster and more accurately, no
significant pre-post differences emerged in standardized measures of problem
solving or verbal comprehension. These results demonstrate efficiency gains
without cognitive change, suggesting that current narrow AI systems serve as
cognitive scaffolds extending performance without transforming underlying
mental capacities. The findings highlight the need for ethical and educational
frameworks that promote critical and autonomous thinking in an increasingly
AI-augmented cognitive ecology.

</details>


### [262] [OrchVis: Hierarchical Multi-Agent Orchestration for Human Oversight](https://arxiv.org/abs/2510.24937)
*Jieyu Zhou*

Main category: cs.HC

TL;DR: OrchVis是一个多智能体编排框架，通过可视化、验证和协调基于LLM的智能体之间的目标驱动协作，实现人类对复杂多智能体工作流程的监督。


<details>
  <summary>Details</summary>
Motivation: 解决人类在监督复杂多智能体系统时面临的挑战，避免对每个步骤进行微观管理，同时确保系统的透明性和可控性。

Method: 采用分层目标对齐、任务分配和冲突解决机制，将用户意图解析为结构化目标，通过自动化验证监控执行，并通过交互式规划面板展示智能体间依赖关系。

Result: 系统能够有效协调多智能体协作，当冲突出现时用户可以探索系统提出的替代方案并进行选择性重新规划。

Conclusion: OrchVis通过将透明可视化与自适应自主性相结合，推动了以人为中心的多智能体系统设计。

Abstract: We introduce OrchVis, a multi-agent orchestration framework that visualizes,
verifies, and coordinates goal-driven collaboration among LLM-based agents.
Through hierarchical goal alignment, task assignment, and conflict resolution,
OrchVis enables humans to supervise complex multi-agent workflows without
micromanaging each step. The system parses user intent into structured goals,
monitors execution via automated verification, and exposes inter-agent
dependencies through an interactive planning panel. When conflicts arise, users
can explore system-proposed alternatives and selectively replan. OrchVis
advances human-centered design for multi-agent systems by combining transparent
visualization with adaptive autonomy.

</details>


### [263] [CGM-Led Multimodal Tracking with Chatbot Support: An Autoethnography in Sub-Health](https://arxiv.org/abs/2510.25381)
*Dongyijie Primo Pan,Lan Luo,Yike Wang,Pan Hui*

Main category: cs.HC

TL;DR: 该研究通过6周的自体民族志实验，将连续血糖监测与多模态健康数据结合LLM聊天机器人，探索了在亚健康人群中应用CGM进行健康管理的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决代谢疾病全球健康挑战，特别是探索CGM在亚健康人群（超重、糖尿病前期、焦虑等）中的未开发潜力，以及将CGM作为主要信号整合到LLM健康辅导中的机会。

Method: 采用6周自体民族志方法，结合CGM和多模态指标（通过常见数字设备捕获），使用提供个性化反思和血糖波动解释的聊天机器人。

Result: 研究发现CGM引导的多模态追踪结合对话支持，能够塑造日常饮食、活动、压力和福祉实践。

Conclusion: 该工作扩展了CGM研究超越临床糖尿病范畴，展示了LLM驱动代理如何支持高危人群的预防性健康和反思。

Abstract: Metabolic disorders present a pressing global health challenge, with China
carrying the world's largest burden. While continuous glucose monitoring (CGM)
has transformed diabetes care, its potential for supporting sub-health
populations -- such as individuals who are overweight, prediabetic, or anxious
-- remains underexplored. At the same time, large language models (LLMs) are
increasingly used in health coaching, yet CGM is rarely incorporated as a
first-class signal. To address this gap, we conducted a six-week
autoethnography, combining CGM with multimodal indicators captured via common
digital devices and a chatbot that offered personalized reflections and
explanations of glucose fluctuations. Our findings show how CGM-led, data-first
multimodal tracking, coupled with conversational support, shaped everyday
practices of diet, activity, stress, and wellbeing. This work contributes to
HCI by extending CGM research beyond clinical diabetes and demonstrating how
LLM-driven agents can support preventive health and reflection in at-risk
populations.

</details>


### [264] [Small Talk, Big Impact? LLM-based Conversational Agents to Mitigate Passive Fatigue in Conditional Automated Driving](https://arxiv.org/abs/2510.25421)
*Lewis Cockram,Yueteng Yu,Jorge Pardo,Xiaomeng Li,Andry Rakotonirainy,Jonny Kuo,Sebastien Demmel,Mike Lenné,Ronald Schroeter*

Main category: cs.HC

TL;DR: 研究探讨了在条件自动驾驶中使用基于LLM的对话代理来缓解被动疲劳，通过实地测试发现该代理能有效提升驾驶员警觉性，并识别出三种用户偏好类型。


<details>
  <summary>Details</summary>
Motivation: 条件自动驾驶中的被动疲劳会损害驾驶员准备度和安全性，需要开发有效的人机界面干预措施来重新吸引驾驶员注意力。

Method: 在真实乡村自动驾驶场景中进行实地测试，40名参与者使用基于LLM的对话代理，通过车内视频记录、困倦度评分和访谈分析交互效果。

Result: 用户认为对话代理有助于在被动疲劳期间保持警觉，主题分析揭示了三种用户偏好类型，影响未来使用意图。

Conclusion: 对话代理作为主动人机界面干预具有潜力，自然语言能支持情境感知交互，但需要针对不同用户群体进行自适应设计。

Abstract: Passive fatigue during conditional automated driving can compromise driver
readiness and safety. This paper presents findings from a test-track study with
40 participants in a real-world rural automated driving scenario. In this
scenario, a Large Language Model (LLM) based conversational agent (CA) was
designed to check in with drivers and re-engage them with their surroundings.
Drawing on in-car video recordings, sleepiness ratings and interviews, we
analysed how drivers interacted with the agent and how these interactions
shaped alertness. Users found the CA helpful for supporting vigilance during
passive fatigue. Thematic analysis of acceptability further revealed three user
preference profiles that implicate future intention to use CAs. Positioning
empirically observed profiles within existing CA archetype frameworks
highlights the need for adaptive design sensitive to diverse user groups. This
work underscores the potential of CAs as proactive Human-Machine Interface
(HMI) interventions, demonstrating how natural language can support
context-aware interaction during automated driving.

</details>


### [265] [Psychoacoustic assessment of synthetic sounds for electric vehicles in a virtual reality experiment](https://arxiv.org/abs/2510.25593)
*Pavlo Bazilinskyy,Md Shadab Alam,Roberto Merino-Martınez*

Main category: cs.HC

TL;DR: 研究电动车外部声音信号设计，平衡高可察觉性和低恼人性，通过心理声学指标优化声音设计，提升行人安全同时减少噪音污染。


<details>
  <summary>Details</summary>
Motivation: 电动车比内燃机汽车更安静，对弱势道路使用者的可检测性构成挑战。法规要求电动车配备外部声音信号，但合成声音在嘈杂城市环境中需要平衡可察觉性和恼人性。

Method: 使用虚拟现实场景进行视听实验，14名参与者评估15种场景中的不同声音信号（纯音、间歇音、复杂音调等），包括柴油发动机和轮胎噪音作为基线，使用11点ICBEN量表评估恼人性、可察觉性和信息性。

Result: 心理声学声音质量指标比传统声音指标能更好地预测恼人性评分，为电动车声音设计优化提供见解。

Conclusion: 通过改进行人安全性同时最小化噪音污染，本研究支持开发有效且用户友好的电动车外部声音标准。

Abstract: The growing adoption of electric vehicles, known for their quieter operation
compared to internal combustion engine vehicles, raises concerns about their
detectability, particularly for vulnerable road users. To address this,
regulations mandate the inclusion of exterior sound signals for electric
vehicles, specifying minimum sound pressure levels at low speeds. These
synthetic exterior sounds are often used in noisy urban environments, creating
the challenge of enhancing detectability without introducing excessive noise
annoyance. This study investigates the design of synthetic exterior sound
signals that balance high noticeability with low annoyance. An audiovisual
experiment with 14 participants was conducted using 15 virtual reality
scenarios featuring a passing car. The scenarios included various sound
signals, such as pure, intermittent, and complex tones at different
frequencies. Two baseline cases, a diesel engine and only tyre noise, were also
tested. Participants rated sounds for annoyance, noticeability, and
informativeness using 11-point ICBEN scales. The findings highlight how
psychoacoustic sound quality metrics predict annoyance ratings better than
conventional sound metrics, providing insight into optimising sound design for
electric vehicles. By improving pedestrian safety while minimising noise
pollution, this research supports the development of effective and
user-friendly exterior sound standards for electric vehicles.

</details>


### [266] [ggtime: A Grammar of Temporal Graphics](https://arxiv.org/abs/2510.25656)
*Cynthia A. Huang,Mitchell O'Hara-Wild,Rob J. Hyndman,Matthew Kay*

Main category: cs.HC

TL;DR: 提出了一种时间图形语法和相应的软件实现'ggtime'，用于可视化时间数据，通过编码时间语义到声明式语法中，支持线性、循环、准循环等不同粒度的时间可视化。


<details>
  <summary>Details</summary>
Motivation: 现有的可视化工具难以准确表示复杂的时间语义，通常需要使用专门设计的绘图辅助函数，缺乏能够尊重时间语义的灵活通用工具。

Method: 提出时间图形语法，引入可组合的新元素，支持跨线性、循环、准循环等粒度的可视化；标准化不规则持续时间；在不同粒度和时区间对齐时间点。

Result: 开发了'ggtime'软件实现，该语法设计为与其他语义变量互操作，允许在保持时间语义的同时在可视化空间中进行导航。

Conclusion: 时间图形语法解决了现有工具在表示复杂时间语义方面的不足，提供了一个灵活且语义丰富的框架来可视化时间数据。

Abstract: Visualizing changes over time is fundamental to learning from the past and
anticipating the future. However, temporal semantics can be complicated, and
existing visualization tools often struggle to accurately represent these
complexities. It is common to use bespoke plot helper functions designed to
produce specific graphics, due to the absence of flexible general tools that
respect temporal semantics. We address this problem by proposing a grammar of
temporal graphics, and an associated software implementation, 'ggtime', that
encodes temporal semantics into a declarative grammar for visualizing temporal
data. The grammar introduces new composable elements that support visualization
across linear, cyclical, quasi-cyclical, and other granularities;
standardization of irregular durations; and alignment of time points across
different granularities and time zones. It is designed for interoperability
with other semantic variables, allowing navigation across the space of
visualizations while preserving temporal semantics.

</details>


### [267] [User Misconceptions of LLM-Based Conversational Programming Assistants](https://arxiv.org/abs/2510.25662)
*Gabrielle O'Brien,Antonio Pedro Santos Alves,Sebastian Baltes,Grischa Liebel,Mircea Lungu,Marcos Kalinowski*

Main category: cs.HC

TL;DR: 研究分析了用户对基于LLM的编程助手可能存在的误解，发现用户对聊天机器人的功能（如网络访问、代码执行）有错误期望，并存在调试、验证和优化程序所需信息范围的概念问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM编程助手的普及，用户可能对系统能力产生误解，导致过度依赖、低效实践或质量控制不足，需要研究这些误解以改进工具设计。

Method: 采用两阶段方法：首先头脑风暴并分类用户可能存在的误解，然后对公开数据集中Python编程对话进行定性分析，验证这些概念问题是否在实际使用中出现。

Result: 研究发现用户确实对LLM聊天机器人的功能（如网络访问、代码执行、非文本输出）有错误期望，并在调试、验证和优化程序方面存在更深层次的概念问题。

Conclusion: 研究结果强调了设计能更清晰传达其编程能力的LLM工具的必要性，以帮助用户建立正确的期望和理解。

Abstract: Programming assistants powered by large language models (LLMs) have become
widely available, with conversational assistants like ChatGPT proving
particularly accessible to less experienced programmers. However, the varied
capabilities of these tools across model versions and the mixed availability of
extensions that enable web search, code execution, or retrieval-augmented
generation create opportunities for user misconceptions about what systems can
and cannot do. Such misconceptions may lead to over-reliance, unproductive
practices, or insufficient quality control in LLM-assisted programming. Here,
we aim to characterize misconceptions that users of conversational LLM-based
assistants may have in programming contexts. Using a two-phase approach, we
first brainstorm and catalog user misconceptions that may occur, and then
conduct a qualitative analysis to examine whether these conceptual issues
surface in naturalistic Python-programming conversations with an LLM-based
chatbot drawn from an openly available dataset. Indeed, we see evidence that
some users have misplaced expectations about the availability of LLM-based
chatbot features like web access, code execution, or non-text output
generation. We also see potential evidence for deeper conceptual issues around
the scope of information required to debug, validate, and optimize programs.
Our findings reinforce the need for designing LLM-based tools that more clearly
communicate their programming capabilities to users.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [268] [What Are People's Actual Utility Functions in Budget Aggregation?](https://arxiv.org/abs/2510.24872)
*Ayelet Amster,Lioz Akirav,Rica Gonen,Erel Segal-Halevi*

Main category: cs.GT

TL;DR: 本文通过实证研究发现，传统预算聚合机制中常用的效用函数模型（如ℓ₁、ℓ₂和Leontief）对人类实际偏好的解释力有限，但发现了对星形偏好和峰值线性效用函数的支持证据。


<details>
  <summary>Details</summary>
Motivation: 验证预算聚合机制中常用的效用函数假设是否准确反映人类实际偏好，因为现有理论缺乏对这些模型实证有效性的验证。

Method: 通过结构化问卷调查人类参与者，测试其偏好是否符合ℓ₁、ℓ₂、Leontief等常用效用函数，以及项目对称性和符号对称性等核心假设。

Result: 大多数参与者在不同度量比较中表现出不一致模式，标准距离度量的核心假设缺乏实证支持；但发现大多数参与者符合星形偏好和峰值线性效用函数。

Conclusion: 传统效用函数模型对人类偏好的解释力有限，需要替代建模方法；本研究为测试预算聚合理论中的效用函数假设提供了系统方法论。

Abstract: While participatory budgeting and budget-aggregation mechanisms require
assumptions about how voters evaluate non-ideal budget allocations, little
empirical evidence exists to validate which utility models accurately capture
human preferences. We conducted structured polls with human participants to
test whether real people's preferences conform to commonly assumed utility
functions such as $\ell_1$, $\ell_2$ and Leontief. Our results suggest that
these models may have limited explanatory power for actual behavior: most
participants showed inconsistent patterns across different metric comparisons,
and standard assumptions of project symmetry and sign symmetry -- core features
of common distance-based metrics -- received little empirical support. However,
we find encouraging evidence for more fundamental preference structures: a
large majority of participants showed consistency with star-shaped preferences,
as well as with peak-linear utility functions, where utility changes
proportionally with distance from the ideal budget. These findings have
important implications for designers of budget aggregation mechanisms. While
theoretical results demonstrate impossibility results for standard distance
metrics regarding truthfulness, Pareto-efficiency, and proportionality, our
evidence suggests alternative modeling approaches may be warranted. More
broadly, this work introduces a systematic methodology to empirically test the
utility function assumptions that underpin budget aggregation theories, paving
the way for more robust and realistic mechanism design.

</details>


### [269] [Fair Indivisible Payoffs through Shapley Value](https://arxiv.org/abs/2510.24906)
*Mikołaj Czarnecki,Michał Korniak,Oskar Skibski,Piotr Skowron*

Main category: cs.GT

TL;DR: 提出了一种针对不可分割联盟博弈的公平分配方法——不可分割沙普利值，用于分配议会席位、肾脏交换、机器学习特征等不可分割对象。


<details>
  <summary>Details</summary>
Motivation: 解决不可分割联盟博弈中的公平分配问题，这类问题涉及议会席位、肾脏交换、机器学习关键特征等不可分割对象的分配。

Method: 定义了不可分割沙普利值，并研究了其性质，通过三个案例研究来验证该方法。

Result: 成功应用该方法识别图像分类任务中的关键区域，证明了方法的有效性。

Conclusion: 提出的不可分割沙普利值为不可分割对象的公平分配提供了一种有效解决方案。

Abstract: We consider the problem of payoff division in indivisible coalitional games,
where the value of the grand coalition is a natural number. This number
represents a certain quantity of indivisible objects, such as parliamentary
seats, kidney exchanges, or top features contributing to the outcome of a
machine learning model. The goal of this paper is to propose a fair method for
dividing these objects among players. To achieve this, we define the
indivisible Shapley value and study its properties. We demonstrate our proposed
technique using three case studies, in particular, we use it to identify key
regions of an image in the context of an image classification task.

</details>


### [270] [Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games](https://arxiv.org/abs/2510.25080)
*Will Wolf*

Main category: cs.GT

TL;DR: 本文介绍了有界单边响应游戏(BORGs)的概念，这是一种在卡牌游戏中较少被探索但策略丰富的结构，其中玩家的行动会暂时将控制权转移给对手，对手必须通过一系列连续移动来满足固定条件。


<details>
  <summary>Details</summary>
Motivation: 现有的卡牌游戏研究主要关注严格顺序、确定性响应和无界互惠响应三种控制流结构，但有界单边响应这种策略丰富的结构尚未得到充分探索。

Method: 作者引入了改良版Monopoly Deal作为基准环境来专门隔离BORG动态，使用反事实遗憾最小化(CFR)算法进行策略学习，并开发了一个轻量级全栈研究平台。

Result: 研究表明标准CFR算法能够成功收敛到该领域的有效策略，无需新的算法扩展。

Conclusion: BORG结构为探索有界单边响应设置中的状态表示和策略学习提供了实用的基础，相关训练代理和源代码已公开。

Abstract: Card games are widely used to study sequential decision-making under
uncertainty, with real-world analogues in negotiation, finance, and
cybersecurity. Typically, these games fall into three categories based on the
flow of control: strictly-sequential (where players alternate single actions),
deterministic-response (where some actions trigger a fixed outcome), and
unbounded reciprocal-response (where alternating counterplays are permitted). A
less-explored but strategically rich structure exists: the bounded one-sided
response. This dynamic occurs when a player's action briefly transfers control
to the opponent, who must satisfy a fixed condition through one or more
sequential moves before the turn resolves. We term games featuring this
mechanism Bounded One-Sided Response Games (BORGs).
  We introduce a modified version of Monopoly Deal as a benchmark environment
that specifically isolates the BORG dynamic, where a Rent action forces the
opponent to sequentially choose payment assets. We demonstrate that the
gold-standard algorithm, Counterfactual Regret Minimization (CFR), successfully
converges on effective strategies for this domain without requiring novel
algorithmic extensions. To support efficient, reproducible experimentation, we
present a lightweight, full-stack research platform that unifies the
environment, a parallelized CFR runtime, and a human-playable web interface,
all runnable on a single workstation. This system provides a practical
foundation for exploring state representation and policy learning in bounded
one-sided response settings.
  The trained CFR agent and source code are available at
https://monopolydeal.ai.

</details>


### [271] [Timing Games in Responsive Consensus Protocols](https://arxiv.org/abs/2510.25144)
*Kaya Alpturer,Kushal Babel,Aditya Saraf*

Main category: cs.GT

TL;DR: 该论文研究了区块链共识协议中的时间博弈问题，提出了动态区块奖励机制来激励验证者及时提出区块，从而在存在自私延迟行为的情况下实现响应性。


<details>
  <summary>Details</summary>
Motivation: 区块链应用中验证者有动机通过策略性延迟提案来增加奖励，这使得响应性共识协议面临挑战。论文旨在解决这种时间博弈问题，使合作（及时提案）成为验证者的最优策略。

Method: 引入动态区块奖励机制，奖励随轮次时间递减；通过投票机制测量延迟，验证者对当前领导者的轮次时间进行投票；精心设置协议参数使验证者能够协调达到合作均衡。

Result: 动态奖励机制使验证者能够协调达到合作均衡，所有验证者通过更高的奖励率受益；响应性本身能够促进更快的区块提案；从静态到动态奖励的转变虽然增加了验证者效用对延迟的敏感性，但这种影响在理论和实际网络模拟中都很小。

Conclusion: 响应性在区块链协议中并非不可实现，通过适当的激励机制设计，响应性本身可以促进更快的区块提案，解决时间博弈问题，实现合作均衡。

Abstract: Optimistic responsiveness -- the ability of a consensus protocol to operate
at the speed of the network -- is widely used in consensus protocol design to
optimize latency and throughput. However, blockchain applications incentivize
validators to play timing games by strategically delaying their proposals,
since increased block time correlates with greater rewards. Consequently, it
may appear that responsiveness (even under optimistic conditions) is impossible
in blockchain protocols. In this work, we develop a model of timing games in
responsive consensus protocols and find a prisoner's dilemma structure, where
cooperation (proposing promptly) is in the validators' best interest, but
individual incentives encourage validators to delay proposals selfishly. To
attain desirable equilibria, we introduce dynamic block rewards that decrease
with round time to explicitly incentivize faster proposals. Delays are measured
through a voting mechanism, where other validators vote on the current leader's
round time. By carefully setting the protocol parameters, the voting mechanism
allows validators to coordinate and reach the cooperative equilibrium,
benefiting all through a higher rate-of-reward. Thus, instead of responsiveness
being an unattainable property due to timing games, we show that responsiveness
itself can promote faster block proposals. One consequence of moving from a
static to dynamic block reward is that validator utilities become more
sensitive to latency, worsening the gap between the best- and worst-connected
validators. Our analysis shows, however, that this effect is minor in both
theoretical latency models and simulations based on real-world networks.

</details>


### [272] [On Robust Popular Matchings with Tie-Bounded Preferences and Stable Matchings with Two-Sided Ties](https://arxiv.org/abs/2510.25209)
*Koustav De*

Main category: cs.GT

TL;DR: 本文研究了二分图中稳健流行匹配的存在性问题，提出了在单边模型和双边单边平局模型中，当只有一个代理改变偏好顺序时，判断是否存在稳健流行匹配的多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 研究稳健流行匹配的存在性，即在多个实例中都能保持流行性的匹配，这对于实际应用中的稳定性分析具有重要意义。

Method: 提出了在单边模型和双边单边平局模型中，当实例仅因单个代理的偏好顺序不同时，判断是否存在稳健流行匹配的多项式时间算法。

Result: 给出了双边单边平局模型中流行匹配的简单特征化，并证明了在特定条件下存在多项式时间算法来判断稳健流行匹配的存在性。

Conclusion: 在二分图匹配问题中，当实例差异仅限于单个代理的偏好变化时，可以高效地判断稳健流行匹配的存在性，这为实际应用提供了理论基础。

Abstract: We are given a bipartite graph $G = \left( A \cup B, E \right)$. In the
one-sided model, every $a \in A$ (often called agents) ranks its neighbours $z
\in N_{a}$ strictly, and no $b \in B$ has any preference order over its
neighbours $y \in N_{b}$, and vertices in $B$ abstain from casting their votes
to matchings. In the two-sided model with one-sided ties, every $a \in A$ ranks
its neighbours $z \in N_{a}$ strictly, and every $b \in B$ puts all of its
neighbours into a single large tie, i.e., $b \in B$ prefers every $y \in N_{b}$
equally. In this two-sided model with one-sided ties, when two matchings
compete in a majority election, $b \in B$ abstains from casting its vote for a
matching when both the matchings saturate $b$ or both leave $b$ unsaturated;
else $b$ prefers the matching where it is saturated. A popular matching $M$ is
\emph{robust} if it remains popular among multiple instances.
  We have analysed the cases when a robust popular matching exists in the
one-sided model where only one agent alters her preference order among the
instances, and we have proposed a polynomial-time algorithm to decide if there
exists a robust popular matching when instances differ only with respect to the
preference orders of a single agent.
  We give a simple characterisation of popular matchings in the two-sided model
with one-sided ties. We show that in the two-sided model with one-sided ties,
if the input instances differ only with respect to the preference orders of a
single agent, there is a polynomial-time algorithm to decide whether there
exists a robust popular matching. We have been able to decide the stable
matching problem in bipartite graphs $G = (A \cup B, E)$ where \textit{both}
sides have weak preferences (ties allowed), with the restriction that every tie
has length at most $k$.

</details>


### [273] [Learning-Augmented Online Bidding in Stochastic Settings](https://arxiv.org/abs/2510.25582)
*Spyros Angelopoulos,Bertrand Simon*

Main category: cs.GT

TL;DR: 本文研究了学习增强设置下的在线竞价问题，探索了在预测预言机或算法本身引入随机性的情况。第一部分关注基于分布预测的竞价，提出了帕累托最优算法；第二部分研究了随机竞价算法的能力与局限。


<details>
  <summary>Details</summary>
Motivation: 在线竞价是经典优化问题，在在线决策、可中断系统设计和近似算法分析中有广泛应用。现有研究主要关注不利用预测质量随机信息的预言机和确定性算法，本文旨在探索随机性在学习增强竞价中的作用。

Method: 第一部分：在分布预测下研究竞价，开发帕累托最优算法以平衡一致性和鲁棒性；第二部分：通过上下界分析研究随机竞价算法的能力与局限。

Result: 提出了在分布预测下提供最佳一致性和鲁棒性权衡的帕累托最优算法，并为随机竞价算法的一致性/鲁棒性权衡建立了上下界。

Conclusion: 本文扩展了学习增强在线竞价的研究范围，通过引入随机性在预测和算法层面提供了新的理论洞见和算法设计方法。

Abstract: Online bidding is a classic optimization problem, with several applications
in online decision-making, the design of interruptible systems, and the
analysis of approximation algorithms. In this work, we study online bidding
under learning-augmented settings that incorporate stochasticity, in either the
prediction oracle or the algorithm itself. In the first part, we study bidding
under distributional predictions, and find Pareto-optimal algorithms that offer
the best-possible tradeoff between the consistency and the robustness of the
algorithm. In the second part, we study the power and limitations of randomized
bidding algorithms, by presenting upper and lower bounds on the
consistency/robustness tradeoffs. Previous works focused predominantly on
oracles that do not leverage stochastic information on the quality of the
prediction, and deterministic algorithms.

</details>
