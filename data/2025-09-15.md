<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 64]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.SD](#cs.SD) [Total: 10]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.GT](#cs.GT) [Total: 1]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.HC](#cs.HC) [Total: 15]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: ASOS是一个包含50种常见超市商品的3D纹理网格数据集，专为机器人和计算机视觉基准测试设计，强调真实性和可获取性


<details>
  <summary>Details</summary>
Motivation: 现有数据集多依赖合成模型或难以获取的专业物品，缺乏真实世界常见商品的低成本、易获取的3D数据集

Method: 使用运动结构恢复技术和高分辨率成像采集超市商品的3D网格，生成水密网格模型

Result: 创建了包含10个类别、50种商品的综合数据集，具有多样化的形状、尺寸和重量特征

Conclusion: ASOS数据集以其可访问性和真实世界适用性，为物体检测、姿态估计和机器人应用提供了有价值的基准测试资源

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [2] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态检索增强生成框架(MM-RAG)，用于自然灾害后房屋损坏评估，通过双分支编码器结构实现图像和文本的跨模态语义对齐，在检索准确率和损坏严重程度分类指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自然灾害后准确评估房屋损坏对于保险理赔和资源规划至关重要，需要结合图像特征和文本政策信息进行综合分析。

Method: 采用双分支多模态编码器结构：图像分支使用ResNet和Transformer提取建筑物损坏特征，文本分支使用BERT检索器处理文本向量化；集成跨模态交互模块通过多头注意力实现语义对齐；引入模态注意力门控机制动态控制生成过程中视觉证据和文本先验信息的作用；端到端训练结合对比损失、检索损失和生成损失进行多任务优化。

Result: 在检索准确率和损坏严重程度分类指标上表现出优异性能，Top-1检索准确率提高了9.6%。

Conclusion: 该MM-RAG框架成功实现了图像理解和政策匹配的协同学习，为灾后房屋损坏评估提供了有效的多模态解决方案。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [3] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 提出了一种基于LLM的集成框架，通过多图像增强变体和自定义对齐器提高历史文档转录准确性，在宾州死亡记录数据集上相比单次转录提升4%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决从噪声历史文档中提取文本的稳定性问题，传统单次转录方法在面对文档质量不佳时准确率有限。

Method: 使用Gemini 2.0 Flash对每个图像的多个增强变体进行转录，然后通过自定义的Needleman Wunsch风格对齐器融合输出，生成共识转录和置信度分数。

Result: 在622份宾州死亡记录数据集上，该方法相比单次转录基线提升4个百分点准确率，发现填充和模糊处理对提升准确性最有效，网格扭曲扰动最适合区分高低置信度情况。

Conclusion: 该方法简单、可扩展，可立即部署到其他文档集合和转录模型，为历史文档转录提供了有效的集成解决方案。

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [4] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文提出了第一个专门针对智能交通监控（ITS）领域的大规模多模态基准数据集MITS，包含17万张真实交通监控图像和500万条指令跟随数据，显著提升了主流大语言模型在ITS任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 通用领域的大语言模型在图像-文本任务上取得了显著进展，但在智能交通监控领域表现有限，主要原因是缺乏专门的多模态数据集。

Method: 构建MITS数据集，包含170,400张真实ITS图像，通过系统化数据生成流程生成高质量图像描述和500万条指令跟随问答对，涵盖5个关键ITS任务。

Result: 在MITS数据集上微调后，LLaVA-1.5性能从0.494提升至0.905（+83.2%），LLaVA-1.6从0.678提升至0.921（+35.8%），Qwen2-VL从0.584提升至0.926（+58.6%），Qwen2.5-VL从0.732提升至0.930（+27.0%）。

Conclusion: MITS数据集有效提升了LMM在ITS应用中的性能，为ITS和LMM研究提供了高价值资源，数据集、代码和模型均已开源。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [5] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 论文研究了结构化树状推理是否能提升视觉语言模型在细粒度分类任务中的性能，但发现标准零样本提示方法仍然优于树状推理方法。


<details>
  <summary>Details</summary>
Motivation: 探索结构化、基于树的推理方法是否能增强视觉语言模型在细粒度视觉分类任务和大规模层次标签空间中的性能表现。

Method: 引入一个框架，将分类任务分解为使用决策树的可解释决策过程，并在细粒度(GTSRB)和粗粒度(CIFAR-10)数据集上进行评估。同时探索使用LLM生成的类别和图像描述来增强树状提示。

Result: 虽然模型在理解树状知识方面达到98.2%的准确率，但树状推理方法始终表现不如标准零样本提示方法。添加图像描述后，树状方法和零样本方法的性能都有所提升。

Conclusion: 研究结果揭示了结构化推理在视觉分类中的局限性，为设计更可解释的视觉语言模型系统提供了重要见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [6] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI是一个从数据中学习丰富可控和灵活提示的世界模型的系统，通过三步循环构建概率图模型、提取底层结构并整合回训练中，实现了视频预测和理解能力的持续增强


<details>
  <summary>Details</summary>
Motivation: 开发一个能够从大规模视频数据中学习世界模型并支持丰富控制和提示功能的系统，通过结构提取和整合来持续提升模型能力

Method: 三步循环方法：1）概率预测-构建随机访问自回归序列模型；2）结构提取-通过因果推理零样本提取底层低维属性；3）整合-将结构转换为新token类型并重新整合到训练中

Result: 在1.4万亿token的互联网视频数据上训练PSI实例，实现了最先进的光流、自监督深度和对象分割，支持完整的预测改进循环

Conclusion: PSI系统通过循环结构整合方法有效提升了世界模型的预测能力和控制灵活性，为构建类似LLM的通用提示语言提供了新途径

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [7] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 本文首次分析了联邦学习中视频数据的梯度反演攻击风险，发现特征提取器能提供更好的防御效果，但攻击者仍可通过超分辨率技术重建高质量视频，证明视频数据泄露是真实威胁


<details>
  <summary>Details</summary>
Motivation: 联邦学习的核心隐私保护原则是通过交换模型更新而非原始数据来保护隐私，但梯度反演攻击能够从共享梯度中重建原始训练数据。虽然这种攻击在图像、文本和表格数据上的影响已被研究，但对视频数据的影响仍是未探索的研究领域

Method: 评估两种常见的视频分类方法：使用预训练特征提取器的方法和处理原始视频帧的简单变换方法。测试在不同攻击场景下（攻击者拥有零个、一个或多个参考帧）的梯度反演攻击效果，并使用图像超分辨率技术提升重建视频质量

Result: 特征提取器对梯度反演攻击具有更强的抵抗力，但攻击者仍可通过超分辨率技术重建高质量视频。实验证明即使在特征提取器存在的情况下，如果分类器复杂度不足，数据泄露仍然可能发生

Conclusion: 视频数据在联邦学习中存在真实的泄露风险，特征提取器能提供一定保护但并非绝对安全。视频数据泄露的条件和机制需要进一步深入研究

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [8] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 提出了一种用于密集零售环境目标检测的半监督协同训练框架，结合Faster R-CNN和YOLO进行伪标签交换，集成多种分类器提升鲁棒性，并通过元启发式算法优化超参数，显著减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 解决密集零售环境中有限标注数据和复杂条件（如遮挡、重叠物体）带来的挑战，降低标注成本并适应零售场景中频繁的产品和布局变化。

Method: 采用半监督协同训练框架：1）结合Faster R-CNN（ResNet骨干）进行精确定位和YOLO（Darknet骨干）获取全局上下文，实现伪标签交换；2）集成XGBoost、随机森林和SVM进行分类；3）使用元启发式算法优化超参数。

Result: 在SKU-110k数据集上表现出色，证明了框架在自动化库存跟踪、产品监控和结账系统等实际零售应用中的可扩展性和实用性。

Conclusion: 该框架有效解决了密集零售环境中的目标检测难题，通过减少对人工标注的依赖降低了成本，能够适应零售场景的动态变化，具有重要的实际应用价值。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [9] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出了Token Purging (PG)，一种无需反向传播的测试时自适应方法，通过移除受域偏移影响严重的token来提升3D点云分类性能，在准确率、速度和内存效率方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决3D点云分类中因分布偏移导致的性能下降问题，现有测试时自适应方法需要反向传播迭代更新，计算成本高且不适合实时部署。

Method: 提出Token Purging方法，在token级别进行操作，在attention层之前移除受域偏移影响严重的token。提供两个变体：PG-SP（利用源域统计信息）和PG-SF（完全无源域版本，依赖CLS-token驱动自适应）。

Result: 在ModelNet40-C、ShapeNet-C和ScanObjectNN-C数据集上，PG-SP比最先进的无反向传播方法平均准确率高10.3%，PG-SF在无源域自适应方面创下新基准。PG比基线方法快12.4倍，内存效率高5.5倍。

Conclusion: Token Purging是一种高效、轻量级的测试时自适应方法，无需反向传播即可有效处理域偏移问题，适合实际部署应用。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [10] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出了一种精确且高度可解释的跨视角细粒度定位方法，通过匹配地面图像与航拍图像的局部特征来估计3自由度姿态，避免了传统BEV转换中的信息损失问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法将地面图像转换为鸟瞰图(BEV)表示再与航拍图像对齐，这种转换会因透视畸变或高度信息压缩导致信息丢失，降低对齐质量。

Method: 直接在原始图像间建立对应关系，仅将匹配的关键点使用单目深度先验提升到BEV空间。支持度量和相对深度，采用尺度感知的Procrustes对齐来估计相机姿态，并可在使用相对深度时恢复尺度。

Result: 实验结果表明，仅需弱监督相机姿态，该方法就能学习准确的局部特征对应关系，在跨区域泛化和未知方向等挑战性条件下实现优越的定位性能。

Conclusion: 该方法兼容各种相对深度模型且无需针对每个模型进行微调，具有灵活性和强大的定位性能，非常适合实际部署。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [11] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 开发基于智能手机的儿童视力筛查应用KidsVisionCheck，使用红眼反射图像和深度学习模型，准确率达90%，无需专业设备


<details>
  <summary>Details</summary>
Motivation: 利用智能手机和人工智能技术重现Bruckner测试，使儿童视力筛查更加便捷和普及，实现早期视力异常干预

Method: 基于眼科医生收集和标注的儿童瞳孔图像，训练深度神经网络模型，开发移动应用进行红眼反射图像分析

Result: 在未见测试数据上达到90%的准确率，性能高度可靠，无需专业设备，并能确定最佳数据收集条件

Conclusion: 这项工作标志着向全球可及的儿科视力筛查和视力异常早期干预迈出了第一步

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [12] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: 提出了一种基于深度引导的多模态融合方法DGFusion，通过深度感知特征和空间变化的局部深度标记来动态调整传感器融合，在自动驾驶语义感知任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的传感器融合方法在处理具有挑战性的条件时性能受限，因为它们通常在整个输入空间范围内统一处理传感器数据，而没有考虑不同传感器在不同深度条件下的可靠性差异。

Method: 提出了DGFusion网络，将多模态分割作为多任务问题处理，利用激光雷达测量作为输入和深度学习的真值。通过辅助深度头学习深度感知特征，编码为空间变化的局部深度标记，结合全局条件标记动态调整传感器融合策略。

Result: 在具有挑战性的MUSES和DELIVER数据集上实现了最先进的泛光和语义分割性能。

Conclusion: 深度引导的多模态融合方法能够有效提升自动驾驶语义感知的鲁棒性，通过深度信息动态调整传感器融合策略，在复杂环境下表现出优越性能。

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [13] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 基于ResNet-18深度学习框架的斑块式酒渣鼻自动检测策略，通过提取面部不同区域图像斑块，在保持患者隐私的同时实现了优于全图像方法的检测性能。


<details>
  <summary>Details</summary>
Motivation: 酒渣鼻是一种慢性炎症性皮肤病，需要精确早期检测以提高治疗效果。传统全图像方法可能泄露患者身份信息，且无法专注于临床相关区域。

Method: 使用ResNet-18深度学习框架，从面部图像提取不同大小、形状和位置的多种图像斑块，研究局部视觉信息对模型性能的影响。

Result: 实验结果表明，斑块式策略在准确性和敏感性方面达到或优于全图像方法，同时保护患者隐私，增强模型鲁棒性和可解释性。

Conclusion: 提出的斑块式策略为改进自动化皮肤病诊断提供了实用见解，能够引导模型关注临床相关区域，同时保护患者隐私。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [14] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 提出了一种基于临床先验知识和合成数据的隐私保护型玫瑰痤疮自动检测方法，通过构建红色通道掩膜聚焦诊断相关区域，使用ResNet-18在合成数据上训练，在真实测试数据上取得了优于全脸基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 玫瑰痤疮是一种常见但诊断不足的炎症性皮肤病，自动检测面临症状弥散、标注数据稀缺以及面部图像隐私问题等挑战。

Method: 首先基于临床观察构建固定的红色信息掩膜，选择面部图像中红色通道强度持续较高的区域；然后在掩膜后的合成图像上训练ResNet-18深度学习模型。

Result: 该方法在真实测试数据上相比全脸基线方法在准确率、召回率和F1分数方面都有显著提升，表现出优越性能。

Conclusion: 合成数据和临床先验知识可以共同实现准确且符合伦理的皮肤病AI系统，特别适用于远程医疗和大规模筛查等隐私敏感应用场景。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [15] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 对ULW框架进行消融研究，评估U-Net骨架、可学习维纳滤波器和复合损失函数中各组件在腹腔镜图像去烟雾任务中的必要性和有效性


<details>
  <summary>Details</summary>
Motivation: 为了严格评估ULW框架中各个组件的有效性和必要性，需要系统性地分析每个组件对整体性能的具体贡献

Method: 通过系统消融研究：(1)移除可学习维纳滤波器模块；(2)选择性使用复合损失函数中的各个损失项（MSE、SSIM损失、感知损失）；在公开的配对腹腔镜图像数据集上进行定量和定性评估

Result: 使用SSIM、PSNR、MSE和CIEDE-2000等定量指标以及视觉比较来评估不同变体的性能表现

Conclusion: 通过全面的消融分析验证了ULW框架中各个组件的必要性和有效性，为腹腔镜图像去烟雾任务提供了组件级别的性能评估

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [16] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: WAVE-DETR是一种结合可见光RGB和声学信号的多模态无人机检测器，通过融合视觉和声学特征，在Deformable DETR和Wav2Vec2架构基础上，显著提升了无人机检测性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在复杂环境条件下无人机检测的挑战，需要利用多模态信息（特别是声学信号）来增强检测的鲁棒性和准确性。

Method: 基于Deformable DETR和Wav2Vec2架构，开发了四种不同的融合配置（门控机制、线性层、MLP和交叉注意力），将声学嵌入与多分辨率特征映射融合。

Result: 最佳的门控融合方法在ARDrone数据集上将Deformable DETR检测器的mAP提升了11.1%到15.3%（小型无人机），所有尺寸无人机的整体增益达到3.27%到5.84%。

Conclusion: 声学信息的融合显著提升了无人机检测性能，特别是在挑战性环境条件下，多模态方法为实时无人机检测提供了有效的解决方案。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [17] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 提出了一种称为代理监督的新训练范式，通过将估计的空间变换应用于代理图像，将输入域与监督域解耦，从而提高深度学习图像配准网络的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习图像配准方法虽然精度高，但对输入图像特征变化（如伪影、视场不匹配、模态差异等）敏感，需要开发更鲁棒和通用的训练方法。

Method: 引入代理监督框架，将输入域与监督域解耦，通过将估计的空间变换应用于代理图像来确保在相似性定义良好的域中进行监督计算。

Result: 在三个代表性应用（抗伪影脑MR配准、掩码无关肺CT配准、多模态MR配准）中均表现出对输入变化的强韧性，同时在良好整理数据上保持高性能。

Conclusion: 代理监督为训练鲁棒且通用的深度学习配准模型提供了原则性框架，无需增加复杂性，有望在多样化生物医学成像场景中实现更广泛的应用。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [18] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 提出结合卷积自编码器和Vision Transformer的框架，提升牙齿年龄估计的准确性和可解释性，发现第三磨牙数据的高类内变异性是性能限制因素


<details>
  <summary>Details</summary>
Motivation: 深度学习在法医年龄估计等高风险应用中存在'黑盒'问题，需要提升模型性能和透明度以支持专家决策

Method: 使用卷积自编码器(AE)与Vision Transformer(ViT)结合的框架，分析第二和第三磨牙的自动分期性能差异

Result: 分类准确率显著提升：牙齿37从0.712提高到0.815，牙齿38从0.462提高到0.543。AE的潜在空间分析和图像重建显示剩余性能差距主要源于数据问题

Conclusion: 单一可解释性方法不足，需要多角度诊断。该框架既能提高准确性，又能解释模型不确定性原因，为法医年龄估计提供更可靠的工具支持

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [19] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: SCoDA是一种无需源域数据的自监督域自适应方法，通过几何流形对齐和EMA教师更新，显著优于现有SFDA方法


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法依赖全监督预训练和余弦相似度对齐，丢弃了源模型潜在流形的关键几何信息

Method: 使用自监督预训练教师模型，结合实例级特征匹配和空间相似性损失进行几何流形对齐，通过EMA更新教师参数防止灾难性遗忘

Result: 在基准数据集上的广泛实验表明，SCoDA显著优于最先进的SFDA方法

Conclusion: 自监督预训练和几何流形对齐的结合为SFDA提供了有效的解决方案，避免了传统方法的局限性

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [20] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 提出了一种基于Segment Anything 2 (SAM2)的零样本细胞追踪框架，无需训练数据即可在2D和3D显微镜视频中实现竞争性精度的细胞追踪和有丝分裂事件检测。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的细胞追踪方法依赖昂贵的人工标注数据集，且由于显微镜数据的巨大多样性，其泛化能力有限。需要开发无需训练数据的方法来解决这些限制。

Method: 将Segment Anything 2 (SAM2)这一通用图像和视频分割的大型基础模型集成到追踪流程中，构建完全无监督的零样本细胞追踪框架。

Result: 该方法在2D和大规模3D延时显微镜视频中实现了竞争性的精度，同时无需针对特定数据集进行适配。

Conclusion: 提出的零样本方法消除了对训练数据的依赖，能够跨不同显微镜数据集泛化，为细胞追踪提供了更通用和高效的解决方案。

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [21] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 提出了一种将现有2D多摄像头跟踪系统扩展到3D空间的方法，通过深度信息重建目标点云并进行聚类优化，在AI City Challenge 2025中获得第三名


<details>
  <summary>Details</summary>
Motivation: 现有的多目标多摄像头跟踪系统主要基于2D空间，虽然相机标定和深度信息可以将目标投影到3D空间，但完全重构3D跟踪系统成本高昂，需要一种能够利用现有2D系统基础的方法

Method: 利用深度信息在点云空间中重建目标，通过聚类和偏航角优化恢复3D边界框，并引入增强的在线数据关联机制，利用目标的局部ID一致性在帧间分配全局ID

Result: 在2025 AI City Challenge的3D MTMC数据集上进行评估，在排行榜上获得第三名

Conclusion: 该方法成功证明了可以将现有的在线2D多摄像头跟踪系统有效扩展到3D空间，无需完全重构系统，为3D多目标跟踪提供了一种实用的解决方案

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [22] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 零样本视觉语言验证方法在指代表达理解任务中表现优异，无需特定训练即可超越传统方法


<details>
  <summary>Details</summary>
Motivation: 探索无需任务特定训练的零样本方法来解决指代表达理解问题，验证工作流程设计的重要性

Method: 将REC重新定义为框级视觉语言验证：使用通用检测器生成候选框，通过通用VLM对每个区域进行True/False查询验证

Result: 在RefCOCO、RefCOCO+和RefCOCOg数据集上超越零样本GroundingDINO基线，甚至超过经过REC训练的GroundingDINO和GroundingDINO+CRG的报道结果

Conclusion: 工作流程设计而非任务特定的预训练是实现强大零样本REC性能的关键因素

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [23] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 提出RPCP数据增强方法解决小麦叶片病虫害分割中的极端像素不平衡问题，通过复制粘贴罕见虫害区域并进行随机投影滤波来改善分割性能


<details>
  <summary>Details</summary>
Motivation: 小麦叶片病虫害分割中虫害像素占比极小，导致严重的像素级不平衡问题，造成模型过拟合常见类别而无法充分学习罕见类别，影响整体分割性能

Method: RPCP增强技术：从标注图像中提取罕见虫害区域，应用随机几何变换模拟变化，粘贴到合适区域避免重叠，并使用随机投影滤波器细化局部特征使其与背景自然融合

Result: 实验表明该方法显著提高了虫害类别的分割性能，同时保持甚至略微提升了其他类别的准确率

Conclusion: 针对性数据增强能有效缓解极端像素不平衡问题，为农业分割问题提供了简单而有效的解决方案

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [24] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 提出了一种结合不确定身份信息和跟踪的HMM框架，用于解决长期多目标跟踪中的身份切换问题，在猪只跟踪数据集和标准MOT基准上均取得了性能提升


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法在长期跟踪中由于身份切换问题性能下降，而实际应用（如畜牧业）中可以从喂食器等来源获得零星的身份识别信息

Method: 使用隐马尔可夫模型（HMM）框架，结合不确定的身份信息和跟踪数据，为动物提供真实身份识别

Result: 在10分钟猪只跟踪数据集上，相比领先的ByteTrack方法（即使使用重识别）F1分数有所提升；在MOT17和MOT20基准数据集上使用ByteTrack和FairMOT验证了性能改进；对识别不确定性具有鲁棒性

Conclusion: 提出的HMM框架有效解决了长期多目标跟踪中的身份切换问题，能够利用零星的身份信息提升跟踪性能，在真实世界应用和标准基准上都表现出色

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [25] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 本综述论文系统回顾了事件相机与传统帧相机融合技术在视频恢复和3D重建领域的深度学习进展，涵盖时间增强和空间增强两大维度，并整理了开源数据集以促进可重复研究。


<details>
  <summary>Details</summary>
Motivation: 事件相机作为新兴的生物启发式传感器，具有低延迟、低功耗和超高捕获率等优势，但其与传统帧相机的融合技术发展迅速，需要系统性的综述来总结最新进展并指导未来研究方向。

Method: 采用系统性文献综述方法，从两个维度分析深度学习在事件-帧融合中的应用：时间增强（帧插值、运动去模糊等）和空间增强（超分辨率、低光增强、HDR增强等），同时探讨3D重建领域的进展。

Result: 综述系统整理了事件-帧融合在视频恢复和3D重建领域的主要深度学习贡献，提供了全面的技术路线分析，并汇编了开源数据集资源，为后续研究提供了重要参考。

Conclusion: 事件相机与传统帧相机的融合技术为视觉媒体恢复和增强提供了新的可能性，特别是在结合深度学习技术后展现出巨大潜力，该综述旨在激发更多相关研究并推动该领域的发展。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [26] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack是首个基于Transformer的ANN-SNN混合跟踪器，通过ISTA适配器实现RGB和事件数据的有效融合，在多个基准测试中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有的人工神经网络难以充分利用事件流的稀疏和异步特性，ANN-SNN混合架构在RGB-Event感知中具有潜力，但跨异构范式的特征融合仍然是一个挑战

Method: 采用双分支模型：视觉Transformer提取RGB空间上下文，脉冲Transformer捕获事件流时空动态；设计基于ISTA算法的适配器进行双向特征交互；加入时序下采样注意力模块对齐特征

Result: 在FE240hz、VisEvent、COESOT和FELT等RGB-Event跟踪基准测试中实现了最先进的性能，同时保持高能效

Conclusion: ISTASTrack展示了ANN-SNN混合设计在鲁棒视觉跟踪中的有效性和实用性，为跨模态特征融合提供了新思路

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [27] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 本文提出了一种针对微型和纳米无人机优化的高效视觉惯性里程计（VIO）流水线，在超低功耗RISC-V SoC上实现了实时性能，相比基线流水线将RMSE平均降低了3.65倍。


<details>
  <summary>Details</summary>
Motivation: 传统高精度VIO流水线需要强大计算系统，而微控制器上的轻量级实现精度不足。本文旨在弥合这一差距，为微型和纳米无人机开发既高效又准确的VIO解决方案。

Method: 采用先进的特征检测和跟踪方法（SuperPoint、PX4FLOW、ORB），并进行优化和量化以适应RISC-V超低功耗并行SoC。通过刚体运动模型减少估计误差，在平面运动场景中提高精度。

Result: 在GAP9低功耗SoC上，使用ORB特征跟踪器时，优化流水线相比基线流水线平均RMSE降低达3.65倍。PX4FLOW在移动速度低于24像素/帧时，以更低的运行时成本实现与ORB相当的跟踪精度。

Conclusion: 该设计成功实现了在超低功耗系统上运行的高精度VIO流水线，为微型和纳米无人机的实时视觉导航提供了可行的解决方案，在计算需求和跟踪精度之间取得了良好平衡。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [28] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出基于多深度状态空间模型的太阳耀斑预测方法，引入FLARE损失函数解决类别不平衡问题，在11年太阳活动周期数据集上性能优于基线方法


<details>
  <summary>Details</summary>
Motivation: 当前太阳耀斑预测性能不足，现有方法未能充分解决耀斑类别间的严重不平衡问题，需要提高预测准确性和可靠性以减轻对关键基础设施的影响

Method: 使用多深度状态空间模型构建太阳耀斑预测模型，提出频率和局部边界感知可靠性损失函数（FLARE损失）来改善类别不平衡下的预测性能和可靠性

Result: 在覆盖完整11年太阳活动周期的多波长太阳图像数据集上，该方法在Gandin-Murphy-Gerrity评分和真实技能统计量等标准指标上均优于基线方法

Conclusion: 所提出的多深度状态空间模型结合FLARE损失函数能有效解决太阳耀斑预测中的类别不平衡问题，显著提升预测性能和可靠性

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [29] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI是一个用于RGB-热成像语义分割的统一编码器模型，通过多模态特征提取和跨模态融合的统一架构，在减少参数和计算成本的同时实现了实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有RGB-T语义分割模型使用RGB预训练编码器提取热特征效果有限、跨模态融合不理想，以及冗余编码器导致实时效率低的问题。

Method: 提出多块堆叠的RGB-T编码器，同时执行多模态特征提取和跨模态融合；利用RGB和伪热数据进行大规模预训练；通过精简热分支实现紧凑架构；引入RGB-T局部模块使用自适应余弦相似度选择性地强调跨模态的显著一致和不同局部特征。

Result: 在FMB、PST900和CART数据集上达到与最先进模型竞争的性能，参数更少、计算成本更低；在Jetson Orin NX上实现27 FPS的推理速度，具备实时部署能力。

Conclusion: TUNI通过统一的编码器架构有效解决了RGB-T语义分割中的特征提取和融合问题，在保持高性能的同时实现了高效的实时部署。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [30] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种基于部分设计元素的少部件字体生成模型，只需输入部分形状而非完整字符即可生成整个字体


<details>
  <summary>Details</summary>
Motivation: 传统少样本字体生成需要完整字符形状，而该方法旨在通过部分设计元素提高字体创建效率，并探索部分设计细节对整体字符结构的影响

Method: 设计了一个新颖的少部件字体生成模型，以部分形状作为输入来生成整个字体

Result: 该方法不仅提高了字体创建效率，还提供了关于部分设计细节如何影响字符整体结构的见解

Conclusion: 该模型为字体设计提供了更高效的方法，同时深化了对字符设计中局部与整体关系的理解

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [31] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出基于卷积神经网络的层次化多级注意力网络(MLANet)，从单张野外图像重建3D人脸模型，预测几何、纹理、姿态和光照参数


<details>
  <summary>Details</summary>
Motivation: 从2D野外图像恢复3D人脸模型具有广泛应用前景，但缺乏标注数据集和真实环境复杂性是主要挑战

Method: 使用预训练的层次化主干网络，在2D人脸特征提取不同阶段引入多级注意力机制，采用半监督训练策略结合3DMM参数和可微分渲染器

Result: 在AFLW2000-3D和MICC Florence基准数据集上进行了广泛实验，包括对比和消融研究，定量和定性评估显示方法有效

Conclusion: 提出的MLANet方法能够有效从单张野外图像重建3D人脸模型，解决了缺乏标注数据和复杂环境带来的挑战

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [32] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT是一个语言感知的视觉思维链框架，通过多阶段推理流程和多方面奖励优化，显著提升多语言视觉问答性能，在多个基准测试中超越开源和专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要依赖文本思维链，对多语言多模态推理支持有限，限制了在实际应用中的部署。需要开发能够同时处理多语言和视觉信息的推理框架。

Method: 设计多阶段推理流程（文本摘要+边界框、语言识别、空间对象级描述、逐步逻辑推理），采用自动化数据标注方法，结合监督微调和语言感知组相对策略优化进行两阶段训练。

Result: 在MMMB、Multilingual MMBench和MTVQA等数据集上，比同规模开源基线提升约9.5%准确率，甚至超越规模大2倍的模型约2.6%，优于GPT-4o-0513和Gemini-2.5-flash等专有模型。

Conclusion: LaV-CoT通过语言感知的视觉思维链框架和多方面奖励优化，有效提升了多语言视觉问答的性能和泛化能力，在实际应用中表现出色，具有工业部署价值。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [33] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出无需训练的框架，利用大语言模型解析模糊颜色描述，在文本嵌入空间指导颜色混合，提升文本到图像生成中的颜色准确性


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在处理复杂颜色术语时存在颜色对齐问题，无法准确理解如Tiffany蓝、柠檬绿等模糊颜色描述，影响时尚、产品可视化等应用

Method: 使用大语言模型解析文本提示中的模糊颜色术语，基于CIELAB颜色空间的空间关系细化文本嵌入，直接在嵌入空间指导颜色混合操作

Result: 实验结果表明该方法在不影响图像质量的情况下显著改善了颜色对齐效果，填补了文本语义与视觉生成之间的差距

Conclusion: 该训练无关框架通过LLM辅助的颜色消歧和嵌入空间优化，有效解决了文本到图像生成中的颜色准确性问题，无需额外训练或参考图像

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [34] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: AVI-Math是首个评估无人机遥感图像中多模态数学推理能力的基准测试，包含3,773个高质量问题，涵盖几何、逻辑和代数等6个数学领域，测试显示当前视觉语言模型在此类推理任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在无人机遥感任务的数学推理能力（如距离计算、轨迹估计和空间分析）尚未得到充分测试，需要专门的基准来评估这一重要能力。

Method: 构建AVI-Math数据集，包含从多角度、多高度无人机拍摄的3,773个车辆相关问题，涵盖6个数学学科和20个主题，并对14个主流视觉语言模型进行综合评估，同时探索思维链提示和微调技术。

Result: 尽管现有视觉语言模型在其他多模态基准上表现良好，但在AVI-Math的数学推理任务上表现挣扎，暴露出显著的数学推理能力局限性。

Conclusion: 研究揭示了当前视觉语言模型在数学推理方面的不足，为未来开发更可靠的无人机应用视觉语言模型提供了重要见解，思维链提示和微调技术显示出改善潜力。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [35] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj是一个新颖的轨迹预测框架，直接在鸟瞰图空间利用实时传感器数据，无需依赖预建高清地图，通过可变形注意力和稀疏目标候选提议模块实现端到端预测。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖预建高清地图或实时地图构建模块，但前者受限于特定区域且无法适应瞬时变化，后者可能遗漏关键场景细节或引入错误。需要克服这些限制，提高预测灵活性。

Method: 提出BEVTraj框架：1）直接在BEV空间操作，使用实时传感器数据；2）利用可变形注意力从密集BEV特征中高效提取相关上下文；3）引入稀疏目标候选提议模块实现完全端到端预测，无需后处理。

Result: 大量实验表明，BEVTraj实现了与最先进HD地图模型相当的性能，同时通过消除对预建地图的依赖提供了更大的灵活性。

Conclusion: BEVTraj成功克服了传统地图依赖方法的局限性，在保持高性能的同时提供了更好的适应性和灵活性，为自动驾驶轨迹预测提供了新的解决方案。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [36] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 提出了一种利用多视角信息改进多人解析模型在遮挡场景下性能的新训练框架，通过弱监督和一致性损失实现，在遮挡情况下相比基线模型有4.20%的相对提升


<details>
  <summary>Details</summary>
Motivation: 现有方法在公开数据集上表现良好，但在处理身体重叠的多人场景时效果显著下降，需要解决遮挡情况下的解析问题

Method: 提出基于多视角信息的训练框架，包括弱监督人类实例分割和多视角一致性损失，使用半自动标注策略从多视角RGB+D数据和3D人体骨架生成标注

Result: 在遮挡场景下，该方法相比基线模型实现了4.20%的相对性能提升

Conclusion: 多视角信息能够有效改善多人解析模型在遮挡情况下的表现，提出的训练框架和标注策略为解决此类问题提供了有效方案

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [37] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0是一个开源的韩英双语视觉语言模型，相比前代模型有显著提升，支持多图像理解、文档图表处理和布局感知OCR，在14B和1.7B两个规模版本上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时处理韩语和英语的双语视觉语言模型，提升多图像理解能力，特别是对文档、图表和表格等复杂输入的处理，并实现布局感知的OCR功能。

Method: 采用四阶段课程训练和内存高效技术，通过偏好优化增强多模态对齐能力，同时保持核心语言能力并提高安全性。

Result: 在广泛基准测试中展现出强大的空间定位能力，14B模型在OpenCompass VLM排行榜上位列同规模模型第8名，同时发布了适用于设备部署的1.7B轻量版本。

Conclusion: VARCO-VISION-2.0模型推动了双语视觉语言模型的发展，为实际应用提供了强有力的工具，两个版本均已开源发布。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [38] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 提出了一种轻量级的人脸图像质量评估方法，通过集成MobileNetV3-Small和ShuffleNetV2网络，结合相关性感知损失函数，在保持高精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸图像质量评估方法要么无法有效捕捉人脸特有的退化特征，要么计算成本过高，限制了在实际应用中的部署。需要一种既准确又高效的方法来评估野外环境下的人脸图像质量。

Method: 集成两个紧凑卷积神经网络（MobileNetV3-Small和ShuffleNetV2），通过简单平均进行预测级融合，并使用结合MSE和Pearson相关正则化的相关性感知损失函数（MSECorrLoss）来更好地对齐人类感知判断。

Result: 在VQualA FIQA基准测试中取得了SRCC 0.9829和PLCC 0.9894的高相关性分数，同时满足计算效率约束。

Conclusion: 该方法在准确性和计算成本之间实现了良好平衡，适合实际部署，为野外环境下的人脸图像质量评估提供了有效的轻量级解决方案。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [39] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 提出了RCOD框架，通过潜在域分组策略和退化感知采样，在单步扩散模型中实现保真度与真实感的灵活权衡控制


<details>
  <summary>Details</summary>
Motivation: 单步扩散方法虽然效率高，但缺乏多步方法中通过调整采样步骤来平衡保真度和真实感的灵活控制机制

Method: 使用潜在域分组策略控制噪声预测阶段的权衡，引入退化感知采样策略对齐蒸馏正则化，采用视觉提示注入模块替代文本提示

Result: 在定量指标和视觉质量上均优于现有单步扩散方法，同时保持计算效率，在推理阶段具有灵活的真实感控制能力

Conclusion: RCOD框架成功解决了单步扩散模型在真实图像超分辨率任务中保真度与真实感权衡控制的难题

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [40] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL是一个新颖的源自由域适应框架，通过梯度引导的伪标签精化和基于余弦相似度的对比学习策略，在无需源数据的情况下实现视盘和视杯的跨域精确分割。


<details>
  <summary>Details</summary>
Motivation: 解决视盘和视杯分割模型在不同成像协议或条件下性能显著下降的问题，特别是在无法访问原始源数据的情况下实现稳健的域适应。

Method: 采用两阶段方法：第一阶段通过梯度机制提取显著类别特征，进行不确定性量化和原型估计来精化伪标签；第二阶段使用基于余弦相似度的对比损失来增强视杯和视盘特征间的类间可分性。

Result: 在具有挑战性的跨域眼底成像数据集上，Grad-CL超越了最先进的无监督和源自由域适应方法，实现了优越的分割精度和改善的边界描绘。

Conclusion: Grad-CL框架有效解决了医学图像分割中的域适应问题，无需源数据即可实现高性能的视盘和视杯分割，具有重要的临床应用价值。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [41] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: VQBridge方法解决了VQ训练中的不稳定问题，通过压缩-处理-恢复管道实现100%码本使用率，显著提升图像重建和生成性能


<details>
  <summary>Details</summary>
Motivation: 解决向量量化(VQ)训练中的不稳定问题，包括直通估计偏差、滞后更新和稀疏码本梯度，这些导致重建性能不佳和码本使用率低

Method: 提出VQBridge方法，基于映射函数构建压缩-处理-恢复管道来优化码向量，结合学习退火实现稳定有效的码本训练

Result: 在多样化码本配置下实现100%码本使用率(FVQ)，使用262k码本时仍保持100%使用率，达到最先进的重建性能，与LlamaGen集成时显著提升图像生成质量

Conclusion: 高质量的分词器对于强大的自回归图像生成至关重要，FVQ方法有效、可扩展且通用，能够持续提升不同VQ变体的性能

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [42] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock是一种通过渐进层冻结从像素预测过渡到潜在预测的自监督视觉表示学习方法，可加速MAE训练并避免表示崩溃


<details>
  <summary>Details</summary>
Motivation: 观察到ViT层按深度顺序收敛的现象，希望利用这一特性来加速掩码自编码训练并实现有效的潜在预测

Method: 通过明确的进度表逐步冻结模型层，从像素预测逐渐过渡到潜在预测

Result: 在高达40亿参数的大模型上应用LayerLock，在4DS感知套件上的结果超越了非潜在掩码预测方法

Conclusion: LayerLock是一种简单有效的方法，能够显著加速训练过程并避免表示崩溃问题，适用于大规模视觉表示学习

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [43] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 本文系统比较了隐式和显式新视角合成方法在空间3D物体重建中的表现，重点评估了外观嵌入的作用，发现嵌入虽能提升光度保真度但对几何精度无显著改善，且凸面溅射比高斯溅射能提供更紧凑的无杂波表示


<details>
  <summary>Details</summary>
Motivation: 研究空间机器人应用中3D重建方法的几何精度需求，评估外观嵌入在提升光度保真度同时是否也能改善几何精度

Method: 使用SPEED+数据集，比较K-Planes、高斯溅射和凸面溅射三种方法，分析外观嵌入对几何精度和表示效率的影响

Result: 外观嵌入主要减少显式方法所需基元数量而非提升几何保真度；凸面溅射比高斯溅射获得更紧凑且无杂波的表示

Conclusion: 阐明了外观嵌入在几何中心任务中的局限性，强调了空间场景中重建质量与表示效率之间的权衡，凸面溅射在安全关键应用中具有优势

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [44] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: GAMMA是一个新的AI生成图像检测框架，通过多样化操作策略和多任务监督来减少域偏差并增强语义对齐，在GenImage基准上实现了5.8%的准确率提升，并对新发布的生成模型如GPT-4o保持强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在分布内生成图像上表现良好，但对未见生成模型的泛化能力有限，主要原因是过度依赖生成特定的伪影（如风格先验和压缩模式）。

Method: 提出GAMMA训练框架，引入多样化操作策略（基于修复的操作和语义保持扰动）确保操作内容与真实内容的一致性；采用多任务监督，包含双分割头和分类头，实现跨生成域的像素级来源归因；引入反向交叉注意力机制，让分割头指导和纠正分类分支中的偏差表示。

Result: 在GenImage基准上实现了最先进的泛化性能，准确率提升5.8%；对新发布的生成模型如GPT-4o保持强鲁棒性。

Conclusion: GAMMA通过减少域偏差和增强语义对齐，有效解决了AI生成图像检测的泛化问题，为检测新兴生成模型提供了有效解决方案。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [45] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 本研究比较了三种胎儿脑MRI超分辨率重建方法(NiftyMIC、SVRTK、NeSVoR)在140例扫描中的表现，发现NeSVoR重建成功率最高(>90%)，且虽然不同方法间体积测量存在差异，但对脑室扩大的诊断分类性能无影响。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑MRI通常采用快速多视角2D切片采集以减少运动伪影，但这些图像分辨率低、可能受运动影响且无法充分捕捉3D解剖结构。现有超分辨率重建方法的比较性能，特别是在病理病例中的表现，以及对下游体积分析和诊断任务的影响尚未充分探索。

Method: 应用三种先进SRR方法(NiftyMIC、SVRTK、NeSVoR)处理140例胎儿脑MRI扫描(包括健康对照和脑室扩大病理病例)，使用BoUNTi算法分割主要脑结构并提取体积，评估视觉质量、重建成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR在健康组和病理组均表现出最高且最一致的重建成功率(>90%)。虽然不同SRR方法间的体积估计存在显著差异，但脑室扩大的分类性能不受SRR方法选择的影响。

Conclusion: 研究结果突显了NeSVoR的鲁棒性，以及尽管SRR引起的体积变异性存在，但诊断性能仍具有韧性。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [46] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 提出了Mask Consistency Regularization (MCR)训练策略，通过掩码扩张和重塑扰动来解决目标移除任务中的掩码幻觉和掩码形状偏差问题


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在图像修复中的目标移除任务面临两个关键挑战：掩码幻觉（在掩码区域生成无关内容）和掩码形状偏差（生成内容模仿掩码形状而非周围内容）

Method: 提出MCR训练策略，在训练过程中引入两种掩码扰动：扩张和重塑，强制这些扰动分支的输出与原始掩码保持一致。扩张掩码帮助模型输出与周围内容对齐，重塑掩码鼓励模型打破掩码形状偏差

Result: 实验表明MCR显著减少了幻觉和掩码形状偏差，在目标移除任务中实现了更好的性能

Conclusion: MCR策略能够产生更鲁棒和上下文一致的图像修复结果，有效解决了目标移除任务中的关键挑战

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [47] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: MagicMirror是一个全面的文本到图像生成伪影评估框架，包含首个大规模人工标注数据集MagicData340K、基于VLM的评估模型MagicAssessor，以及自动化基准测试MagicBench，揭示了当前顶级T2I模型仍存在严重伪影问题


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成虽然取得了显著进展，但在物理伪影（如解剖和结构缺陷）方面仍存在普遍问题，严重影响了感知质量并限制了应用。缺乏系统性和细粒度的评估框架来识别和解决这些多样复杂的伪影问题

Method: 1) 建立生成图像伪影的详细分类法；2) 人工标注340K生成图像的MagicData340K数据集；3) 训练Vision-Language Model MagicAssessor进行详细评估；4) 设计新颖的数据采样策略和多级奖励系统的GRPO方法；5) 构建自动化基准测试MagicBench

Result: 评估发现即使像GPT-image-1这样的顶级模型也持续受到显著伪影的困扰，突显了伪影减少是未来T2I发展的关键前沿

Conclusion: MagicMirror框架为T2I生成中的伪影问题提供了系统性的评估解决方案，揭示了当前模型的局限性，并为未来改进指明了方向，伪影减少是T2I技术发展的重要挑战

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [48] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip是一个新的手语翻译框架，通过融合手势和唇部运动特征，并引入分层对比学习，显著提升了翻译准确性。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译方法主要关注手势信号，忽略了唇部运动等非手动线索，而这些线索对于区分视觉相似的手势和传达语言信息至关重要。

Method: 提出SignClip框架，融合空间手势和唇部运动特征，采用分层对比学习框架，实现手语-唇部和视觉-文本模态的多层次语义对齐。

Result: 在PHOENIX14T和How2Sign基准测试中表现优异，在无注释设置下BLEU-4从24.32提升到24.71，ROUGE从46.57提升到48.38。

Conclusion: 融合手动和非手动线索的分层对比学习框架能有效提升手语翻译性能，唇部运动信息在手语理解中具有重要作用。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [49] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 该论文分析了开源和闭源大型视觉语言模型在文本篡改检测方面的性能，发现开源模型正在接近但仍落后于闭源模型如GPT-4o，并揭示了专门用于图像篡改检测的VLM在文本篡改检测中存在泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注大型视觉语言模型在图像篡改检测中的有效性，但文本篡改检测方面存在研究空白，需要填补这一知识差距。

Method: 通过在不同文本篡改数据集上测试闭源和开源VLM模型，包括对野外场景文本和模拟真实世界滥用的幻想ID卡上的篡改进行基准测试。

Result: 开源模型在文本篡改检测方面正在进步但仍落后于闭源模型；专门用于图像篡改检测的VLM在文本篡改检测任务中存在泛化问题。

Conclusion: 文本篡改检测是VLM能力评估的重要维度，需要进一步研究以提高模型在这一任务上的性能，特别是针对现实世界中的滥用场景。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [50] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD是一个新颖的多模态协作学习框架，通过整合点云、RGB图像和文本语义，实现了卓越的零样本3D异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本3D异常检测方法主要专注于点云数据，忽略了RGB图像和文本先验等互补模态提供的丰富语义线索。本文旨在利用多模态协作学习来克服这一局限性。

Method: 提出了多模态提示学习机制（MPLM），包括对象无关的解耦文本提示和多模态对比损失，以增强模态内表示能力和模态间协作学习。同时设计了协作调制机制（CMM），通过联合调制RGB图像引导和点云引导分支来充分利用互补表示。

Result: 大量实验证明，MCL-AD框架在零样本3D异常检测中实现了最先进的性能。

Conclusion: 该研究通过多模态协作学习成功提升了零样本3D异常检测的能力，证明了整合点云、RGB图像和文本语义的有效性。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [51] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出一种基于Lipschitz约束的随机深度方法，通过深度相关的DropPath概率来改善ViT的对抗鲁棒性，同时保持准确性和降低计算量


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers在计算机视觉中表现优异但对对抗扰动高度脆弱，现有防御方法计算成本高或缺乏形式化保证

Method: Lipschitz引导的随机深度(DropPath)方法，drop概率随深度增加以控制网络的有效Lipschitz常数，正则化深层网络

Result: 在CIFAR-10上使用ViT-Tiny的实验表明，该方法保持接近基线的干净准确率，提升了对FGSM、PGD-20和AutoAttack的鲁棒性，并显著减少了FLOPs

Conclusion: 深度相关的DropPath调度能有效平衡模型鲁棒性、准确性和计算效率，为对抗防御提供了新的正则化思路

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [52] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 提出基于能量图的概率框架，用于复杂城市环境中街道家具的精确定位，通过随机生灭优化算法整合地理空间信息，提高定位精度


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中街道家具的精确定位问题，这对于地方政府和私人利益相关者有效监控和维护公共基础设施至关重要

Method: 基于能量图的概率框架，编码物体位置的空间似然性；采用随机生灭优化算法推断最可能的资产配置；整合GIS图层、道路地图等外部地理空间信息

Result: 使用都柏林市中心街道照明基础设施的地理定位数据集进行真实模拟评估，证明了该方法在可扩展和准确的城市资产测绘方面的潜力

Conclusion: 提出的概率框架和优化算法能够有效提高城市环境中街道家具的定位精度，为城市基础设施管理提供了可扩展的解决方案

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [53] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出Cluster-Driven Feature Caching (ClusCa)方法，通过空间聚类减少扩散变换器中90%以上的token计算，实现显著加速且保持生成质量


<details>
  <summary>Details</summary>
Motivation: 现有特征缓存方法仅利用扩散模型的时间相似性，忽略了空间维度的相似性，计算成本仍然很高

Method: 在每一时间步对token进行空间聚类，每个聚类只计算一个token并将其信息传播给其他token

Result: 在DiT、FLUX和HunyuanVideo上验证有效，FLUX实现4.96倍加速，ImageReward达到99.49%（比原模型提升0.51%）

Conclusion: ClusCa可作为现有特征缓存方法的正交补充，无需训练即可直接应用于任何扩散变换器，显著提升效率

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [54] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter是首个完全整数化的ViT分割框架，通过系统替换浮点运算、提出新激活函数λ-ShiftGELU、移除L2归一化层和使用最近邻上采样，在保持精度的同时显著减少模型大小和加速推理。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义分割中表现优异，但在资源受限设备上部署受限，主要由于高内存占用和计算成本。量化是提高效率的有效策略，但ViT分割模型在低精度下表现脆弱，量化误差会在深度编码器-解码器管道中累积。

Method: 基于Segmenter架构，系统替换浮点运算为整数运算；提出λ-ShiftGELU激活函数处理长尾激活分布；移除L2归一化层；在解码器中使用最近邻上采样替代双线性插值，确保整个计算图的整数化执行。

Result: I-Segmenter在精度上接近FP32基线（平均5.1%差距），模型大小减少达3.8倍，推理速度提升达1.2倍。即使在单张校准图像的一次性PTQ设置下，也能提供有竞争力的精度。

Conclusion: I-Segmenter是首个完全整数化的ViT分割框架，通过系统性的整数化设计和优化，在保持精度的同时显著提升了效率，具有实际部署的实用性。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [55] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种基于伽马扩散模型的新型OCT图像去噪方法，通过噪声减少保真度项和加速推理框架，在保持解剖结构细节的同时有效去除散斑噪声


<details>
  <summary>Details</summary>
Motivation: OCT图像受散斑噪声影响严重，现有去噪方法难以平衡噪声去除与解剖结构保留。传统扩散模型假设高斯噪声，与散斑噪声的统计特性不符

Method: 提出GARD方法：1）使用去噪扩散伽马模型更准确建模散斑噪声统计特性；2）引入噪声减少保真度项，利用预处理低噪声图像指导去噪过程；3）采用DDIM框架加速推理

Result: 在配对噪声/低噪声OCT B扫描数据集上，GARD在PSNR、SSIM和MSE指标上显著优于传统方法和最先进深度学习模型，定性结果显示边缘更清晰、解剖细节保留更好

Conclusion: GARD通过伽马噪声建模和保真度引导，有效解决了OCT图像去噪中噪声去除与结构保留的平衡问题，为视网膜疾病诊断提供了更高质量的成像工具

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [56] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: GLAM模型通过几何引导的多视角对齐方法，在乳腺X光片视觉语言模型预训练中实现了全局和局部对齐，显著提升了多数据集上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的乳腺X光片视觉语言模型大多从自然图像迁移而来，忽略了乳腺X光片特有的多视角关系特性，无法像放射科医生那样同时分析多个视角来处理同侧对应关系，导致丢失关键的几何上下文信息。

Method: 提出GLAM模型，利用乳腺X光片多视角成像过程的先验知识，通过联合全局和局部、视觉-视觉、视觉-语言的对比学习，学习局部跨视角对齐和细粒度局部特征。

Result: 在EMBED（最大的开放乳腺X光片数据集之一）上预训练后，该模型在不同设置下的多个数据集上都优于基线方法。

Conclusion: 通过几何引导的多视角对齐方法能够有效提升乳腺X光片视觉语言模型的性能，为医学影像分析提供了新的思路。

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [57] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 这是一篇关于视觉基础化技术的综述论文，探讨了现代通用视觉语言模型中的视觉基础化能力及其在多模态应用中的重要性。


<details>
  <summary>Details</summary>
Motivation: 视觉基础化能力使模型能够根据文本描述在视觉输入中定位特定区域，这对于实现精细化的多模态理解和控制至关重要，作者旨在系统梳理该领域的研究进展。

Method: 论文采用综述研究方法，首先阐述视觉基础化在VLMs中的重要性，然后分析现代基础化模型的核心组件，并考察其实际应用、基准测试和评估指标。

Result: 论文系统回顾了视觉基础化领域的代表性工作，分析了视觉基础化与多模态思维链、推理之间的关系，并总结了当前的技术范式。

Conclusion: 论文指出了视觉基础化面临的技术挑战，并提出了未来研究的潜在方向，为该领域的进一步发展提供了指导。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [58] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 提出了一种针对文本图像编辑方法的新型对抗攻击Attention Attack，通过使用源图像的自动生成标题作为编辑提示的代理，破坏文本提示与视觉表示之间的交叉注意力，无需了解编辑方法或编辑提示即可破坏图像内容与文本描述的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的文本图像编辑方法容易受到对抗攻击，但当前缺乏针对视觉组件的有效攻击方法。本文旨在开发一种无需了解编辑方法细节就能有效破坏文本-图像对齐的攻击策略。

Method: 提出Attention Attack攻击方法，利用源图像的自动生成标题作为编辑提示的代理，干扰文本提示与视觉表示之间的交叉注意力机制。引入Caption Similarity和语义IoU两种新的评估指标来衡量攻击效果。

Result: 在TEDBench++基准测试上的实验表明，该攻击方法能显著降低编辑性能，同时保持攻击的不可感知性。

Conclusion: Attention Attack是一种有效的对抗攻击方法，能够破坏文本图像编辑系统的功能，同时提出的新评估指标为衡量此类攻击的成功提供了更可靠的度量标准。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [59] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 该研究通过知识蒸馏技术降低神经网络图像压缩模型的计算资源需求，使小模型能够学习大模型的性能，在保持压缩质量的同时减少处理功耗。


<details>
  <summary>Details</summary>
Motivation: 虽然基于深度学习的图像压缩方法在性能上优于传统编解码器，但计算资源需求大，难以在资源受限平台上实时应用，限制了其主流部署。

Method: 采用知识蒸馏训练范式，让小规模神经网络通过学习大规模复杂模型的输出来获得更好的性能，而不是独立训练。

Result: 研究表明知识蒸馏可有效应用于图像压缩任务：适用于不同架构规模、实现不同图像质量/比特率权衡、节省处理和能源资源。

Conclusion: 知识蒸馏为神经网络图像压缩提供了资源优化的有效途径，未来可探索不同教师模型、替代损失函数以及扩展到基于transformer的模型。

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [60] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 提出一种无需训练的本征图像分解方法，仅使用可见光和热成像图像对，通过热成像检测吸收的光能来推断反射率和阴影的序数关系，实现自监督分解。


<details>
  <summary>Details</summary>
Motivation: 解决传统本征图像分解方法因缺乏真实世界地面实况数据而依赖合成数据或稀疏标注的问题，特别是在室外场景中的应用限制。

Method: 利用热成像相机检测被吸收的光能转化为热量的原理，建立可见光和热成像强度之间的序数关系与阴影和反射率序数关系的联系，通过自监督方式优化神经网络进行分解。

Result: 在自然光和人工光照条件下对已知反射率和阴影进行定量评估，并在多样室外场景中进行定性实验，结果显示优于近期基于学习的方法。

Conclusion: 该方法为获取真实世界序数监督提供了一条可扩展的路径，解决了传统手动标注不可行的问题，展示了在室外场景中的优越性能。

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [61] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 本文提出了压缩视频质量增强(CVQE)的系统性综述，包括新的分类法、统一基准测试框架以及性能-复杂度权衡分析，旨在为CVQE研究建立一致的评估基础。


<details>
  <summary>Details</summary>
Motivation: 现有CVQE综述存在系统性分类不足、架构范式比较分析不够、基准测试实践不完善等问题，需要建立更全面的评估框架来推动该领域发展。

Method: 提出三方面贡献：1）跨架构范式、编码标准和压缩域特征利用的新分类法；2）集成现代压缩协议和标准测试序列的统一基准测试框架；3）系统分析重建性能与计算复杂度的关键权衡。

Result: 建立了CVQE方法的系统性分类体系，提供了公平的多标准评估框架，并揭示了当前最优方法的性能-复杂度权衡关系。

Conclusion: 该综述为CVQE研究提供了基础性的评估框架和模型选择指导，指出了未来研究的 promising 方向，有助于推动该领域的标准化发展。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [62] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: MM SAM-adapter是一个多模态语义分割框架，通过适配器网络将融合的多模态特征注入到Segment Anything Model中，在保持RGB特征强泛化能力的同时选择性利用辅助模态信息，在多个挑战性基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前语义分割方法在恶劣光照、遮挡和恶劣天气等挑战性条件下表现脆弱，需要多模态方法来整合辅助传感器数据（如LiDAR、红外）以提供互补信息并增强鲁棒性。

Method: 提出MM SAM-adapter框架，使用适配器网络将融合的多模态特征注入到SAM的RGB特征中，既保留RGB特征的强泛化能力，又能在需要时选择性整合辅助模态的额外线索。

Result: 在DeLiVER、FMB和MUSES三个挑战性基准测试中达到最先进性能。在RGB-easy和RGB-hard子集上的结果一致表明，该框架在有利和不利条件下都优于竞争方法。

Conclusion: 多模态适配方法能够实现平衡且高效的多模态信息利用，为鲁棒场景理解提供了有效解决方案。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [63] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen是一种基于潜在扩散模型的第二代图像生成方法，通过用一步生成器替换VAE解码器，可以从固定大小的潜在表示生成任意分辨率的图像，显著降低计算复杂度，将4K图像生成时间从100多秒减少到10秒以内。


<details>
  <summary>Details</summary>
Motivation: 解决当前扩散模型随着分辨率增加计算需求呈二次增长的问题，实现跨设备的任意分辨率图像生成，为生产者和消费者提供一致的视觉体验。

Method: 将扩散模型生成的固定潜在表示作为内容表示，提出使用一步生成器解码任意分辨率图像，用新的生成器替换VAE解码器，无需重新训练扩散模型。

Result: 实验表明InfGen能够将许多模型提升到任意高分辨率时代，同时将4K图像生成时间从超过100秒减少到10秒以内。

Conclusion: InfGen简化了图像生成过程，降低了计算复杂度，可以应用于使用相同潜在空间的任何模型，实现了高效的多分辨率图像生成。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [64] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 本研究将三种最先进的时序自监督学习方法应用于3D脑部MRI分析，通过处理变长输入和增强空间特征学习，在阿尔茨海默病预测任务中超越了监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病预测的深度学习模型面临标注数据缺乏、跨数据集泛化能力差以及对不同扫描数量和间隔时间适应性不足的问题。

Method: 采用时序自监督学习（SSL）方法，包括时序顺序预测和对比学习，处理变长输入并学习鲁棒的空间特征，使用四个公开数据集共3,161名患者进行预训练。

Result: 在七项下游任务中的六项上，自监督学习方法表现优于监督学习，展示了跨任务和不同输入图像数量及时间间隔的适应性和泛化能力。

Conclusion: 时序自监督学习在阿尔茨海默病预测中具有显著优势，能够提供跨临床应用的鲁棒性能，代码和模型已公开。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [65] [Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images](https://arxiv.org/abs/2509.09952)
*Zhi Ying,Boxiang Rong,Jingyu Wang,Maoyuan Xu*

Main category: cs.GR

TL;DR: 提出了一种新颖的两阶段生成-估计框架用于PBR材质生成，通过微调扩散模型合成符合用户输入的纹理图像，并采用链式分解方案预测SVBRDF通道，实现了高效、高质量的材质生成和灵活的用户控制。


<details>
  <summary>Details</summary>
Motivation: 传统材质创建和重建需要艺术家大量时间和专业知识，现有基于视觉基础模型的方法在质量、灵活性和用户控制方面存在不足，需要更高效的PBR材质生成解决方案。

Method: 两阶段框架：1）生成阶段使用微调扩散模型合成着色、可平铺的纹理图像；2）估计阶段采用链式分解方案，通过单步图像条件扩散模型顺序预测SVBRDF通道，将先前提取的表征作为输入传递。

Result: 方法在质量和性能上优于现有材质生成和估计方法，对生成纹理和真实照片都表现出强大的鲁棒性，支持文本到材质、图像到材质、结构引导生成和材质编辑等多种应用。

Conclusion: 该框架提供了高效、高质量且灵活的PBR材质生成解决方案，在多个应用场景中展现出优越性能，为材质创建和重建提供了新的技术途径。

Abstract: Material creation and reconstruction are crucial for appearance modeling but
traditionally require significant time and expertise from artists. While recent
methods leverage visual foundation models to synthesize PBR materials from
user-provided inputs, they often fall short in quality, flexibility, and user
control. We propose a novel two-stage generate-and-estimate framework for PBR
material generation. In the generation stage, a fine-tuned diffusion model
synthesizes shaded, tileable texture images aligned with user input. In the
estimation stage, we introduce a chained decomposition scheme that sequentially
predicts SVBRDF channels by passing previously extracted representation as
input into a single-step image-conditional diffusion model. Our method is
efficient, high quality, and enables flexible user control. We evaluate our
approach against existing material generation and estimation methods,
demonstrating superior performance. Our material estimation method shows strong
robustness on both generated textures and in-the-wild photographs. Furthermore,
we highlight the flexibility of our framework across diverse applications,
including text-to-material, image-to-material, structure-guided generation, and
material editing.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [66] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND LLM平台可将IND申请的非临床书面总结初稿撰写时间减少约97%，从约100小时降至3-4小时，质量评分达70-78%，无关键监管错误，但仍需专家完善以提高提交质量。


<details>
  <summary>Details</summary>
Motivation: IND申请准备过程耗时且依赖专业知识，减缓早期临床开发进程，需要寻找自动化解决方案来加速监管文件起草。

Method: 通过AutoIND LLM平台生成IND非临床书面总结(eCTD模块2.6.2, 2.6.4, 2.6.6)，记录起草时间并与人工起草时间对比，由盲评监管写作评估员从正确性、完整性等7个维度评估质量。

Result: 起草时间减少97%(从~100小时降至3.7小时和2.6小时)，质量评分分别为69.6%和77.9%，无关键监管错误，但在重点突出、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加速IND起草，但专家监管作者仍需完善输出至提交质量水平，系统性缺陷为模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [67] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: boldsea是一个基于可执行本体的复杂动态系统建模架构，通过语义事件方法将事件语义与数据流架构结合，解决了传统BPM系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统业务流程管理(BPM)系统和面向对象语义技术在处理复杂动态系统时存在局限性，需要一种能够将数据与业务逻辑无缝融合的统一语义框架。

Method: 提出了boldsea语义语言(BSL)及其BNF语法，开发了boldsea-engine架构，能够直接解释语义模型作为可执行算法而无需编译，支持运行时修改事件模型并确保时间透明度。

Result: 该架构实现了语义模型作为动态结构直接控制流程执行，成功整合了事件语义与数据流架构，提供了统一的语义框架。

Conclusion: boldsea架构为复杂动态系统建模提供了一种创新的可执行本体方法，通过语义事件和数据流整合有效解决了传统方法的局限性。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [68] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 提出基于LLM的多智能体框架，用于自动化多孔材料表征，包括文献提取力场和自动设置RASPA模拟，初步评估显示高正确性和可重现性。


<details>
  <summary>Details</summary>
Motivation: 自动化多孔材料表征可以加速材料发现，但目前受限于模拟设置的复杂性和力场选择问题，需要简化这一过程。

Method: 使用基于LLM的多智能体框架，智能体能够自主理解表征任务、规划模拟、组装力场、执行模拟并解释结果来指导后续步骤。

Result: 初步评估表明该方法具有高正确性和可重现性，能够实现文献信息的力场提取和RASPA模拟的自动设置。

Conclusion: 该方法有潜力实现完全自主、可扩展的材料表征，为自动化材料发现铺平道路。

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [69] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 本文评估了大语言模型(LLMs)和视觉语言模型(VLMs)在符号、语言和连续控制环境中提供规划反馈的能力，发现基础模型能提供高质量多样化反馈，但复杂动态或连续空间会降低反馈质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于环境的规划学习需要精心设计的奖励函数或高质量标注演示，而预训练基础模型可能包含有助于规划的背景知识，减少对奖励设计和演示的需求。

Method: 评估LLMs和VLMs在符号、语言和连续控制环境中的反馈性能，考虑二元反馈、偏好反馈、动作建议、目标建议和增量动作反馈等多种反馈类型，以及上下文学习、思维链和环境动态访问等推理方法。

Result: 基础模型能在多个领域提供高质量多样化反馈；更大和具备推理能力的模型反馈更准确、偏见更少，且能从增强推理方法中获益更多；但在复杂动态或连续状态动作空间中反馈质量会下降。

Conclusion: 预训练基础模型是规划任务中有价值的反馈来源，但需要针对环境复杂性进行适当选择和优化。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [70] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 提出模块化多模态框架，使用生成式AI从公开住宅信息和图像生成能源建模所需数据，解决数据获取难题


<details>
  <summary>Details</summary>
Motivation: 计算模型需要大量数据，但有些数据难以获取、昂贵或存在隐私问题，需要替代方案

Method: 开发模块化多模态框架，利用生成式AI从公开住宅信息和图像生成所需数据，并提供完整实现管道

Result: 实验表明该框架能避免生成模型的常见问题，产生真实、标注良好的数据

Conclusion: 通过减少对昂贵或受限数据源的依赖，为更易获取和可重复的研究铺平道路

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [71] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文综述了自动形式化（autoformalization）领域的发展，重点关注使用大语言模型将非正式输入转换为形式逻辑表示的研究，旨在提出统一框架促进跨领域合作。


<details>
  <summary>Details</summary>
Motivation: 自动形式化领域快速发展但研究分散，数学形式化和更广泛的形式表示生成研究独立发展，缺乏共享的方法论、基准和理论框架，限制了该领域的整体进步。

Method: 通过回顾显性和隐性的自动形式化研究实例，分析不同领域的方法和技术，提出统一的分类框架来整合这些分散的研究方向。

Result: 识别了自动形式化在数学定理证明、推理、规划和知识表示等多个领域的应用，揭示了不同研究社区之间的方法论相似性和潜在合作机会。

Conclusion: 需要建立统一的自动形式化框架来促进跨领域知识共享和方法整合，这将加速下一代AI系统的发展，特别是在形式推理和逻辑表示方面的能力提升。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [72] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 该研究开发了一个基于检索增强生成(RAG)的智能知识助手系统，专门用于山羊养殖健康管理，通过表格文本化和决策树文本化方法处理异构数据，在验证集和测试集上分别达到87.90%和84.22%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在畜牧业应用受限，主要由于知识源的可用性、多样性和复杂性限制，需要开发专门的知识处理方法来提升模型在异构数据格式上的理解能力。

Method: 采用检索增强生成(RAG)技术，提出表格文本化和决策树文本化两种结构化知识处理方法，建立覆盖疾病防治、营养管理、饲养管理等五个关键领域的山羊养殖知识库，并集成在线搜索模块实现实时信息检索。

Result: 异构知识融合方法效果最佳，验证集平均准确率87.90%，测试集84.22%。在文本、表格、决策树问答任务中准确率均超过85%，错误分析显示遗漏是主要错误类型。

Conclusion: 该系统在山羊养殖实际应用中表现出鲁棒性和可靠性，结构化知识融合在模块化设计中有效，检索覆盖范围和上下文整合仍有改进空间。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [73] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 本文研究LLM在UNO游戏中作为助手帮助其他玩家获胜的能力，发现虽然所有模型都能超越随机基准表现，但只有少数大模型能显著帮助其他玩家


<details>
  <summary>Details</summary>
Motivation: 测试基于大语言模型的智能体是否能作为主动参与者帮助人类实现目标，特别是在协作性游戏环境中

Method: 构建工具使decoder-only LLM在RLCard游戏环境中作为智能体参与UNO游戏，接收完整游戏状态信息，使用两种不同的提示策略进行文本响应，评估从1B到70B不同规模模型的性能

Result: 所有模型在玩UNO时都能成功超越随机基准表现，但只有少数大参数模型能够显著帮助其他玩家获胜

Conclusion: LLM在协作性任务中的表现与模型规模相关，大模型在帮助他人方面表现更好，但整体上LLM作为主动协作伙伴的能力仍有局限

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [74] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 提出了一个从当前工作流管理系统向完全自主、分布式科学实验室演化的概念框架，通过智能化和群体化两个维度来规划发展路径，旨在实现100倍的科学发现加速。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现需要协调分布式设施和异构资源，研究人员被迫成为手动工作流协调者而非科学家。AI代理技术的发展为科学发现提供了新的加速机会，但需要明确如何在实际中实现和集成这种新能力。

Method: 提出了一个概念框架，工作流沿着两个维度演化：智能化（从静态到智能）和组合化（从单一到群体），并提供了架构蓝图来指导社区向自主科学发展。

Result: 构建了一个从当前工作流管理系统到完全自主、分布式科学实验室的演化路径，为利用AI代理技术加速科学发现提供了系统性的方法论。

Conclusion: 该框架为科学界提供了向自主科学迈进的具体路径，具有实现100倍发现加速和变革性科学工作流的潜力，将帮助研究人员从手动协调者回归到科学家的角色。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [75] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将WaveFunctionCollapse重构为马尔可夫决策过程，分离局部约束满足和全局目标优化，相比传统联合优化方法在复杂任务中表现更优


<details>
  <summary>Details</summary>
Motivation: 解决程序化内容生成中需要同时满足设计者指定目标和底层瓦片集隐含的邻接约束的挑战

Method: 将WaveFunctionCollapse重新表述为马尔可夫决策过程，利用WFC的传播机制强制约束满足，让外部优化算法专注于目标最大化

Result: 在多领域不同难度任务中，联合优化方法随着任务复杂度增加而表现不佳，始终劣于基于WFC-MDP的优化方法

Conclusion: 将局部约束满足与全局目标优化解耦具有明显优势，WFC-MDP方法在复杂内容生成任务中表现更优

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [76] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本文提出了基于实际因果关系的变量重要性度量方法，并在布尔函数预测场景下评估了最先进的XAI工具，同时开发了新的B-ReX工具，在大型基准测试中表现优于其他黑盒XAI方法。


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估可解释AI(XAI)方法具有挑战性。本文专注于表格数据和布尔函数预测这一具体用例，旨在建立更精确的评估标准。

Method: 提出了基于实际因果关系的正式变量重要性度量方法；开发了基于现有ReX工具的新型XAI工具B-ReX；在大规模基准测试中评估了最先进的XAI工具。

Result: B-ReX工具在随机10值布尔公式上实现了0.072±0.012的Jensen-Shannon散度，表现优于其他黑盒XAI工具。

Conclusion: 基于实际因果关系的度量方法为XAI评估提供了更精确的标准，B-ReX工具在布尔函数预测任务中展现出优越性能，为表格数据的可解释性研究提供了有效解决方案。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [77] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA是一个保护隐私的多智能体系统，通过将工作空间分为私有和公共区域，使用匿名化机制保护敏感数据，同时通过知识增强和逻辑增强模块减少语义损失。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多智能体系统中的广泛应用，处理隐私数据时存在安全风险，需要在不牺牲性能的前提下实现隐私保护。

Method: 提出GAMA系统，划分私有和公共空间，采用匿名化机制，并引入DRKE（基于领域规则的知识增强）和DLE（基于反证的逻辑增强）模块来缓解匿名化带来的语义损失。

Result: 在两个公开问答数据集上表现优于现有最先进模型，在新设计的隐私保护数据集上也显示出卓越的任务处理和隐私保护效果。

Conclusion: GAMA系统在保持高性能的同时有效保护隐私，为LLM-based多智能体系统的隐私安全提供了可行解决方案。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [78] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个基于多极任务处理图和IF-THEN规则的多智能体协作框架，旨在解决复杂任务规划中的不确定性，在知识和逻辑问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型增强了多智能体系统的能力，但在处理高度复杂且具有不确定性的任务时，仍面临有效任务规划的挑战，容易产生误导或错误输出。

Method: 提出XAgents框架，使用多极任务处理图实现动态任务规划和处理任务不确定性，通过领域特定的IF-THEN规则约束智能体行为，全局规则增强智能体间协作。

Result: 在三个不同数据集上的评估表明，XAgents在知识型和逻辑型问答任务中始终优于最先进的单智能体和多智能体方法。

Conclusion: XAgents通过创新的多极任务处理图和规则集成机制，有效解决了复杂任务规划中的不确定性挑战，为多智能体系统提供了更可靠的任务执行能力。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [79] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 提出了AI Harmonics框架，使用基于序数严重性数据的新型AI伤害评估指标(AIH)，无需精确数值估计即可捕捉相对影响，重点关注政治和物理伤害的优先缓解。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型过于关注内部合规性，忽视了不同利益相关者视角和现实世界后果，需要转向以人为本、伤害严重性自适应的评估方法。

Method: 开发了AI Harmonics框架，包含基于序数严重性数据的AIH评估指标，采用稳健的通用化方法和数据驱动、利益相关者感知的框架来探索和优先处理AI伤害。

Result: 在标注事件数据上的实验证实，政治和物理伤害具有最高集中度，需要紧急缓解：政治伤害侵蚀公众信任，物理伤害构成严重甚至危及生命的风险。

Conclusion: AI Harmonics能够持续识别不均匀的伤害分布，使政策制定者和组织能够有效针对性地开展缓解工作，具有重要的现实意义。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [80] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 提出了"沙盒经济"框架来分析新兴的AI代理经济，将其按起源（涌现vs有意）和与人类经济的分离程度（可渗透vs不可渗透）进行分类，并讨论了可引导AI代理市场的设计选择。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理的快速采用，正在形成超越人类直接监督的新经济层，需要框架来分析这一新兴系统并指导其安全发展。

Method: 提出沙盒经济分析框架，考虑拍卖机制、AI"使命经济"设计和社会技术基础设施，以确保信任、安全和问责制。

Result: 识别了当前趋势指向自发涌现的庞大且高度可渗透的AI代理经济，既带来前所未有的协调机会，也带来系统性经济风险和加剧不平等的挑战。

Conclusion: 主张主动设计可引导的代理市场，确保即将到来的技术变革与人类长期集体繁荣保持一致。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [81] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 提出了Robust Sparse Sampling (RSS)算法，这是第一个具有有限样本理论性能保证的鲁棒MDP在线规划算法，能够在模型不确定性环境下进行实时鲁棒决策。


<details>
  <summary>Details</summary>
Motivation: 传统基于采样的在线规划方法（如Sparse Sampling和MCTS）在生成模型存在近似误差时性能会下降甚至产生不安全行为，而现有的鲁棒MDP方法计算复杂度过高，不适合实时应用。

Method: RSS算法通过结合Sample Average Approximation (SAA)的高效性和理论特性，计算鲁棒值函数而非名义值函数，实现了在线环境下的可处理鲁棒策略计算。

Result: RSS适用于无限或连续状态空间，其样本和计算复杂度与状态空间大小无关。理论分析和实验表明，在动态不确定的环境中，RSS优于标准Sparse Sampling方法。

Conclusion: RSS是第一个具有理论保证的在线鲁棒规划算法，为在模型不确定性环境中的实时安全决策提供了有效的解决方案。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [82] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENLI是一个用于临床自然语言推理的模块化代理推理框架，通过将知识访问与推理分离，在四个推理家族上显著提升了LLM的推理准确性，最高提升42个百分点。


<details>
  <summary>Details</summary>
Motivation: 传统假设认为扩大数据和参数规模会提高模型内部表示的结构化和泛化能力，但本文发现在临床NLI任务中，LLMs往往保留相关事实但在推理不明确时默认使用启发式方法，需要更安全、可审计的推理框架。

Method: 提出CARENLI框架，将前提-陈述对路由到特定推理家族的求解器，通过规划器、验证器和精炼器强制执行可审计程序，分离知识访问与原则推理。

Result: 在四个LLM上，CARENLI将保真度提升高达42个百分点，在因果归因达到98.0%，在风险状态抽象达到81.2%。验证器以接近天花板可靠性标记违规，精炼器纠正了大量认知错误。

Conclusion: LLMs在推理不明确时倾向于使用启发式方法，CARENLI通过显式分离知识访问和推理，为更安全、可审计的临床推理提供了框架，主要瓶颈在于家族分类的路由问题。

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [83] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 研究表明用紧凑的逻辑语言替代自然语言可以保持小语言模型在推理任务中的强性能，为小语言模型在ontology工程中的应用提供基础


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在推理领域存在明显不足，特别是在ontology工程任务中。研究旨在探索如何通过引入形式化方法来提升小语言模型在推理任务中的表现

Method: 通过一系列初步实验，研究不同语法表达逻辑问题对小语言模型在预定推理任务中性能的影响，比较自然语言与紧凑逻辑语言的效果

Result: 研究发现可以用更紧凑的逻辑语言替代自然语言，同时在小语言模型的推理任务中保持强性能表现

Conclusion: 这些结果为在小语言模型中进一步精炼ontology工程的角色提供了基础，证明了形式化方法在提升语言模型推理能力方面的潜力

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [84] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 本研究通过量化实验分析6个大型语言模型在18个道德困境中的表现，发现所有模型都一致偏好关怀和美德价值观，而惩罚自由主义选择。具备推理能力的模型对情境更敏感，提供更丰富的解释。


<details>
  <summary>Details</summary>
Motivation: 随着AI快速发展，需要了解AI系统如何优先考虑道德结果，以及模型架构、文化背景和可解释性如何影响道德偏好，以促进人机共生。

Method: 对6个大型语言模型进行定量实验，在代表5种道德框架的18个困境中对结果进行排序和评分。

Result: 发现所有模型都存在显著一致的价值偏见：关怀和美德价值观被评为最道德，自由主义选择被一致惩罚。推理模型对情境更敏感，非推理模型判断更统一但不透明。

Conclusion: 研究强调了可解释性和文化意识作为关键设计原则的重要性，以指导AI走向透明、对齐和共生的未来。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [85] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra是一个使用代数方法表示和操作命题逻辑的新框架，包含集合、坐标和行分解三种层次化表示，在保持语义清晰的同时提供计算灵活性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够统一表示命题逻辑并支持高效代数计算的框架，为搜索算法和知识编译提供更好的工具，并扩展到概率逻辑和加权模型计数领域。

Method: 构建三层表示层次（Set、Coordinate、Row Decomposition），使用代数引擎进行计算，通过固定变量顺序实现规范形式，在规范性和灵活性之间取得平衡。

Result: 框架虽然默认状态向量归约不是规范的，但通过应用固定变量顺序可以获得唯一规范形式，这种权衡使得某些问题类能够获得更紧凑的表示。

Conclusion: State Algebra为命题逻辑提供了强大的代数表示和操作框架，具有良好的扩展性，能够支持多种算法并自然扩展到概率逻辑应用。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [86] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding框架通过结构化因果推理方法，将多智能体系统中的故障归因从模式识别任务转变为因果推理任务，显著提高了步骤级准确率（2.85倍提升）。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统中的故障归因方法准确率极低（低于17%），无法进行有效的反事实推理来确定纠正单个动作是否能避免任务失败，这限制了复杂系统的调试能力。

Method: 提出了Abduct-Act-Predict (A2P) Scaffolding框架，通过三个结构化推理步骤：溯因（推断隐藏根本原因）、行动（定义最小纠正干预）、预测（模拟后续轨迹验证干预效果），在单次推理过程中指导大语言模型进行因果分析。

Result: 在Algorithm-Generated数据集上达到47.46%的步骤级准确率（相比基线16.67%提升2.85倍），在更复杂的Hand-Crafted数据集上达到29.31%准确率（相比基线12.07%提升2.43倍）。

Conclusion: 通过因果推理视角重构问题，A2P Scaffolding为自动化故障归因提供了更鲁棒、可验证且显著更准确的解决方案。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [87] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 该论文提出了一个信息论框架，通过分析状态-动作互信息模式来诊断RL系统中的部署时异常和故障，无需修改架构或影响性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中部署的RL智能体面临传感器故障、执行器磨损和环境变化等问题，但缺乏内在机制来检测和诊断这些故障。

Method: 使用信息论框架分析状态-动作互信息模式，通过控制扰动实验验证不同故障类型的信息特征差异。

Result: 成功学习表现出特征性信息签名：状态-动作互信息从0.84增长到2.83比特（238%增长）；状态噪声导致所有信息通道崩溃，动作噪声则选择性地破坏动作-结果可预测性。

Conclusion: 信息模式既是学习的签名也是系统健康的诊断工具，为能够基于信息论原理进行自主故障检测和政策调整的自适应RL系统奠定了基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [88] [VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions](https://arxiv.org/abs/2509.09716)
*Jun Zhan,Mingyang Han,Yuxuan Xie,Chen Wang,Dong Zhang,Kexin Huang,Haoxiang Shi,DongXiao Wang,Tengtao Song,Qinyuan Cheng,Shimin Li,Jun Song,Xipeng Qiu,Bo Zheng*

Main category: cs.SD

TL;DR: 该论文提出了语音风格适应(VSA)新任务，研究语音语言模型能否根据自然语言语音指令调整说话风格，并发布了双语基准VStyle和评估框架LALM as a Judge。


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型主要关注语义准确性和指令跟随，但根据语音指令调整说话风格的能力研究不足，需要建立系统性的评估基准。

Method: 提出VSA任务，构建包含声学属性、自然语言指令、角色扮演和隐式共情四个类别的双语基准VStyle，并开发基于大音频语言模型的渐进式评估框架。

Result: 实验表明当前商业系统和开源SLM在可控风格适应方面存在明显局限，验证了该任务的新颖性和挑战性。

Conclusion: 通过发布VStyle数据集和评估工具包，为推进以人为中心的语音交互研究提供了基础，该任务对提升人机交互自然度具有重要意义。

Abstract: Spoken language models (SLMs) have emerged as a unified paradigm for speech
understanding and generation, enabling natural human machine interaction.
However, while most progress has focused on semantic accuracy and instruction
following, the ability of SLMs to adapt their speaking style based on spoken
instructions has received limited attention. We introduce Voice Style
Adaptation (VSA), a new task that examines whether SLMs can modify their
speaking style, such as timbre, prosody, or persona following natural language
spoken commands. To study this task, we present VStyle, a bilingual (Chinese &
English) benchmark covering four categories of speech generation: acoustic
attributes, natural language instruction, role play, and implicit empathy. We
also introduce the Large Audio Language Model as a Judge (LALM as a Judge)
framework, which progressively evaluates outputs along textual faithfulness,
style adherence, and naturalness, ensuring reproducible and objective
assessment. Experiments on commercial systems and open source SLMs demonstrate
that current models face clear limitations in controllable style adaptation,
highlighting both the novelty and challenge of this task. By releasing VStyle
and its evaluation toolkit, we aim to provide the community with a foundation
for advancing human centered spoken interaction. The dataset and code are
publicly available at
\href{https://junzhan2000.github.io/VStyle.github.io/}{project's homepage}.

</details>


### [89] [Testing chatbots on the creation of encoders for audio conditioned image generation](https://arxiv.org/abs/2509.09717)
*Jorge E. León,Miguel Carrasco*

Main category: cs.SD

TL;DR: 研究探索聊天机器人是否能设计有效的音频编码器来替代Stable Diffusion 1.5中的CLIP文本编码器，实现直接从声音生成图像。虽然所有聊天机器人都生成了有效的模型设计，但结果均不理想。


<details>
  <summary>Details</summary>
Motivation: 基于聊天机器人在编码任务中的流行度，以及现有生成图像模型主要依赖文本编码器而忽视音频输入的现状，研究希望探索是否能用聊天机器人设计的音频编码器实现声音到图像的转换。

Method: 使用五个公开可用的聊天机器人提出神经网络架构作为音频编码器，每个有效建议的编码器在超过200万个相关音频-图像-文本观测数据上训练，并在验证集和测试集上使用多种指标进行评估。

Result: 几乎所有聊天机器人生成的模型设计都有效，但没有一个达到满意结果，音频嵌入无法与原始文本编码器可靠对齐。Gemini音频编码器在定量指标上表现最佳，Grok音频编码器生成更连贯的图像。

Conclusion: 研究发现聊天机器人存在共享的架构偏见，揭示了这些模型在编码能力方面仍需弥合的差距。建议未来进行更专业化的任务来充分测试聊天机器人的创造力和推理能力。

Abstract: On one hand, recent advances in chatbots has led to a rising popularity in
using these models for coding tasks. On the other hand, modern generative image
models primarily rely on text encoders to translate semantic concepts into
visual representations, even when there is clear evidence that audio can be
employed as input as well. Given the previous, in this work, we explore whether
state-of-the-art conversational agents can design effective audio encoders to
replace the CLIP text encoder from Stable Diffusion 1.5, enabling image
synthesis directly from sound. We prompted five publicly available chatbots to
propose neural architectures to work as these audio encoders, with a set of
well-explained shared conditions. Each valid suggested encoder was trained on
over two million context related audio-image-text observations, and evaluated
on held-out validation and test sets using various metrics, together with a
qualitative analysis of their generated images. Although almost all chatbots
generated valid model designs, none achieved satisfactory results, indicating
that their audio embeddings failed to align reliably with those of the original
text encoder. Among the proposals, the Gemini audio encoder showed the best
quantitative metrics, while the Grok audio encoder produced more coherent
images (particularly, when paired with the text encoder). Our findings reveal a
shared architectural bias across chatbots and underscore the remaining coding
gap that needs to be bridged in future versions of these models. We also
created a public demo so everyone could study and try out these audio encoders.
Finally, we propose research questions that should be tackled in the future,
and encourage other researchers to perform more focused and highly specialized
tasks like this one, so the respective chatbots cannot make use of well-known
solutions and their creativity/reasoning is fully tested.

</details>


### [90] [AI-enabled tuberculosis screening in a high-burden setting using cough sound analysis and speech foundation models](https://arxiv.org/abs/2509.09746)
*Ning Ma,Bahman Mirheidari,Guy J. Brown,Minyoi M. Maimbolwa,Nsala Sanjase,Solomon Chifwamba,Seke Muzazu,Monde Muyoyeta,Mary Kagujje*

Main category: cs.SD

TL;DR: 基于语音基础模型的咳嗽分析结合人口统计学和临床数据，在结核病筛查中表现出色，AUROC达到92.1%，满足WHO目标产品标准


<details>
  <summary>Details</summary>
Motivation: 人工智能可以通过分析咳嗽声音检测疾病相关声学模式，为高负担、低资源地区的结核病筛查提供可扩展方案。以往研究受限于小数据集、非结核病症状患者代表性不足、简单模型以及在理想化条件下收集的录音

Method: 在赞比亚两家医院招募512名参与者，分为细菌学确认结核病组(TB+)、其他呼吸道疾病症状患者组(OR)和健康对照组(HC)。使用基于语音基础模型的深度学习分类器对咳嗽录音进行训练，最佳模型在3秒片段上训练，并进一步结合人口统计学和临床特征进行评估

Result: 仅音频分类器在区分TB+与其他人群时AUROC为85.2%，TB+与OR组为80.1%。加入人口统计学和临床特征后性能提升至92.1%(TB+/Rest)和84.2%(TB+/OR)。多模态模型在阈值为0.38时，对TB+/Rest的敏感性和特异性分别为90.3%和73.1%，对TB+/OR为80.6%和73.1%

Conclusion: 基于语音基础模型的咳嗽分析，特别是结合人口统计学和临床数据后，显示出作为结核病分诊工具的强大潜力，满足WHO目标产品标准。模型对背景噪声、录音时间和设备变异性等混杂因素具有鲁棒性，表明能够检测到真正的疾病相关声学模式。在临床使用前需要在不同地区和病例定义（包括亚临床结核病）进行进一步验证

Abstract: Background
  Artificial intelligence (AI) can detect disease-related acoustic patterns in
cough sounds, offering a scalable approach to tuberculosis (TB) screening in
high-burden, low-resource settings. Previous studies have been limited by small
datasets, under-representation of symptomatic non-TB patients, reliance on
simple models, and recordings collected under idealised conditions.
  Methods
  We enrolled 512 participants at two hospitals in Zambia, grouped as
bacteriologically confirmed TB (TB+), symptomatic patients with other
respiratory diseases (OR), and healthy controls (HC). Usable cough recordings
plus demographic and clinical data were obtained from 500 participants. Deep
learning classifiers based on speech foundation models were trained on cough
recordings. The best-performing model, trained on 3-second segments, was
further evaluated with demographic and clinical features.
  Findings
  The best audio-only classifier achieved an AUROC of 85.2% for distinguishing
TB+ from all others (TB+/Rest) and 80.1% for TB+ versus OR. Adding demographic
and clinical features improved performance to 92.1% (TB+/Rest) and 84.2%
(TB+/OR). At a threshold of 0.38, the multimodal model reached 90.3%
sensitivity and 73.1% specificity for TB+/Rest, and 80.6% and 73.1% for TB+/OR.
  Interpretation
  Cough analysis using speech foundation models, especially when combined with
demographic and clinical data, showed strong potential as a TB triage tool,
meeting WHO target product profile benchmarks. The model was robust to
confounding factors including background noise, recording time, and device
variability, indicating detection of genuine disease-related acoustic patterns.
Further validation across diverse regions and case definitions, including
subclinical TB, is required before clinical use.

</details>


### [91] [DiTReducio: A Training-Free Acceleration for DiT-Based TTS via Progressive Calibration](https://arxiv.org/abs/2509.09748)
*Yanru Huo,Ziyue Jiang,Zuoli Tang,Qingyang Hong,Zhou Zhao*

Main category: cs.SD

TL;DR: DiTReducio是一个无需训练的加速框架，通过时间跳过和分支跳过来压缩DiT语音合成模型的计算量，在保持生成质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT语音合成模型虽然先进但计算需求高，现有加速方法主要依赖蒸馏技术减少采样步骤，但仍受限于训练成本。

Method: 提出两种压缩方法：时间跳过和分支跳过，基于DiT层中识别的两种注意力模式设计模式引导策略，通过可调节压缩阈值灵活控制质量与效率。

Result: 在F5-TTS和MegaTTS 3上实验显示，FLOPs减少75.4%，实时因子提升37.1%，同时保持生成质量。

Conclusion: DiTReducio提供了一种无需训练的高效加速方案，成功解决了DiT语音合成模型的高计算成本问题。

Abstract: While Diffusion Transformers (DiT) have advanced non-autoregressive (NAR)
speech synthesis, their high computational demands remain an limitation.
Existing DiT-based text-to-speech (TTS) model acceleration approaches mainly
focus on reducing sampling steps through distillation techniques, yet they
remain constrained by training costs. We introduce DiTReducio, a training-free
acceleration framework that compresses computations in DiT-based TTS models via
progressive calibration. We propose two compression methods, Temporal Skipping
and Branch Skipping, to eliminate redundant computations during inference.
Moreover, based on two characteristic attention patterns identified within DiT
layers, we devise a pattern-guided strategy to selectively apply the
compression methods. Our method allows flexible modulation between generation
quality and computational efficiency through adjustable compression thresholds.
Experimental evaluations conducted on F5-TTS and MegaTTS 3 demonstrate that
DiTReducio achieves a 75.4% reduction in FLOPs and improves the Real-Time
Factor (RTF) by 37.1%, while preserving generation quality.

</details>


### [92] [Combining Textual and Spectral Features for Robust Classification of Pilot Communications](https://arxiv.org/abs/2509.09752)
*Abdullah All Tanvir,Chenyu Huang,Moe Alahmad,Chuyang Yang,Xin Zhong*

Main category: cs.SD

TL;DR: 提出基于双管道机器学习框架的飞机操作意图分类系统，结合文本和频谱特征分析飞行员无线电通信，在非塔台机场实现91%以上F1分数的准确分类。


<details>
  <summary>Details</summary>
Motivation: 非塔台机场缺乏专用监控基础设施，准确估计飞机起降操作具有挑战性但对机场管理至关重要，需要开发成本效益高的解决方案。

Method: 使用双管道机器学习框架：文本管道通过自动语音识别处理音频，频谱管道提取Mel频谱图；评估传统分类器、集成方法、LSTM和CNN等深度学习模型；采用数据增强提高鲁棒性。

Result: 频谱特征结合深度学习架构表现最佳，F1分数超过91%；数据增强有效提升了系统对真实音频变化的适应性。

Conclusion: 该方法是可扩展、成本效益高且无需额外基础设施即可部署的实用解决方案，为通用航空机场的空中交通监控提供了有效途径。

Abstract: Accurate estimation of aircraft operations, such as takeoffs and landings, is
critical for effective airport management, yet remains challenging, especially
at non-towered facilities lacking dedicated surveillance infrastructure. This
paper presents a novel dual pipeline machine learning framework that classifies
pilot radio communications using both textual and spectral features. Audio data
collected from a non-towered U.S. airport was annotated by certified pilots
with operational intent labels and preprocessed through automatic speech
recognition and Mel-spectrogram extraction. We evaluate a wide range of
traditional classifiers and deep learning models, including ensemble methods,
LSTM, and CNN across both pipelines. To our knowledge, this is the first system
to classify operational aircraft intent using a dual-pipeline ML framework on
real-world air traffic audio. Our results demonstrate that spectral features
combined with deep architectures consistently yield superior classification
performance, with F1-scores exceeding 91%. Data augmentation further improves
robustness to real-world audio variability. The proposed approach is scalable,
cost-effective, and deployable without additional infrastructure, offering a
practical solution for air traffic monitoring at general aviation airports.

</details>


### [93] [SoilSound: Smartphone-based Soil Moisture Estimation](https://arxiv.org/abs/2509.09823)
*Yixuan Gao,Tanvir Ahmed,Shuang He,Zhongqi Cheng,Rajalakshmi Nandakumar*

Main category: cs.SD

TL;DR: SoilSound是一种基于智能手机的声学传感系统，利用内置扬声器和麦克风通过垂直扫描机制测量土壤湿度，无需校准且不干扰土壤，平均绝对误差为2.39%。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度监测方法需要侵入式探头或专业设备，限制了公众使用。需要一种普及、易获取且不干扰土壤的监测方案。

Method: 利用智能手机内置扬声器向土壤发送声学啁啾信号，通过垂直扫描记录反射声波，基于表面粗糙度效应的声学反射模型，使用卷积神经网络进行设备端湿度估计。

Result: 在10个不同地点测试中达到2.39%的平均绝对误差，能够准确追踪15.9%到34.0%的土壤湿度范围，适用于多种土壤类型和环境。

Conclusion: SoilSound提供了一种无需校准、不干扰土壤的普及型土壤湿度监测方案，适合家庭园丁、城市农民和资源有限地区的农业社区使用。

Abstract: Soil moisture monitoring is essential for agriculture and environmental
management, yet existing methods require either invasive probes disturbing the
soil or specialized equipment, limiting access to the public. We present
SoilSound, an ubiquitous accessible smartphone-based acoustic sensing system
that can measure soil moisture without disturbing the soil. We leverage the
built-in speaker and microphone to perform a vertical scan mechanism to
accurately measure moisture without any calibration. Unlike existing work that
use transmissive properties, we propose an alternate model for acoustic
reflections in soil based on the surface roughness effect to enable moisture
sensing without disturbing the soil. The system works by sending acoustic
chirps towards the soil and recording the reflections during a vertical scan,
which are then processed and fed to a convolutional neural network for
on-device soil moisture estimation with negligible computational, memory, or
power overhead. We evaluated the system by training with curated soils in boxes
in the lab and testing in the outdoor fields and show that SoilSound achieves a
mean absolute error (MAE) of 2.39% across 10 different locations. Overall, the
evaluation shows that SoilSound can accurately track soil moisture levels
ranging from 15.9% to 34.0% across multiple soil types, environments, and
users; without requiring any calibration or disturbing the soil, enabling
widespread moisture monitoring for home gardeners, urban farmers, citizen
scientists, and agricultural communities in resource-limited settings.

</details>


### [94] [CoDiCodec: Unifying Continuous and Discrete Compressed Representations of Audio](https://arxiv.org/abs/2509.09836)
*Marco Pasini,Stefan Lattner,George Fazekas*

Main category: cs.SD

TL;DR: CoDiCodec是一种新颖的音频自编码器，通过有限标量量化和FSQ-dropout技术，在同一个模型中同时生成压缩的连续嵌入和离散标记，提供11Hz的连续嵌入和2.38kbps的离散标记，在相似比特率下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有音频自编码器往往需要在连续嵌入和离散标记之间做出选择，且在高压缩比下保持音频保真度仍然是一个挑战。需要一种能够同时支持两种表示方式的统一方法。

Method: 采用有限标量量化(FSQ)和新型FSQ-dropout技术，通过单一一致性损失进行端到端训练，支持自回归解码和新型并行解码策略。

Result: 在相似比特率下，CoDiCodec在重建音频质量方面优于现有的连续和离散自编码器，并行解码策略实现了更优的音频质量和更快的解码速度。

Conclusion: CoDiCodec为音频压缩提供了统一的方法，弥合了连续和离散生成建模范式之间的差距，为不同的下游生成任务提供了前所未有的灵活性。

Abstract: Efficiently representing audio signals in a compressed latent space is
critical for latent generative modelling. However, existing autoencoders often
force a choice between continuous embeddings and discrete tokens. Furthermore,
achieving high compression ratios while maintaining audio fidelity remains a
challenge. We introduce CoDiCodec, a novel audio autoencoder that overcomes
these limitations by both efficiently encoding global features via summary
embeddings, and by producing both compressed continuous embeddings at ~ 11 Hz
and discrete tokens at a rate of 2.38 kbps from the same trained model,
offering unprecedented flexibility for different downstream generative tasks.
This is achieved through Finite Scalar Quantization (FSQ) and a novel
FSQ-dropout technique, and does not require additional loss terms beyond the
single consistency loss used for end-to-end training. CoDiCodec supports both
autoregressive decoding and a novel parallel decoding strategy, with the latter
achieving superior audio quality and faster decoding. CoDiCodec outperforms
existing continuous and discrete autoencoders at similar bitrates in terms of
reconstruction audio quality. Our work enables a unified approach to audio
compression, bridging the gap between continuous and discrete generative
modelling paradigms.

</details>


### [95] [Prototypical Contrastive Learning For Improved Few-Shot Audio Classification](https://arxiv.org/abs/2509.10074)
*Christos Sgouropoulos,Christos Nikou,Stefanos Vlachos,Vasileios Theiou,Christos Foukanelis,Theodoros Giannakopoulos*

Main category: cs.SD

TL;DR: 该论文提出了一种在音频分类中结合监督对比损失和原型小样本学习的方法，使用角度损失和自注意力机制，在MetaAudio基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然小样本学习在图像领域已有广泛研究，但在音频分类中相对较少探索。研究者希望解决音频数据标注困难的问题，通过改进小样本学习方法提升音频分类性能。

Method: 将监督对比损失整合到原型小样本训练中，使用角度损失替代标准对比损失，采用SpecAugment数据增强和自注意力机制来统一不同增强版本的嵌入表示。

Result: 在MetaAudio基准测试的5-way 5-shot设置中取得了最先进的性能，证明了所提方法的有效性。

Conclusion: 结合监督对比损失和原型小样本学习的方法在音频分类任务中表现优异，角度损失相比标准对比损失能进一步提升性能，为音频小样本学习提供了有效的解决方案。

Abstract: Few-shot learning has emerged as a powerful paradigm for training models with
limited labeled data, addressing challenges in scenarios where large-scale
annotation is impractical. While extensive research has been conducted in the
image domain, few-shot learning in audio classification remains relatively
underexplored. In this work, we investigate the effect of integrating
supervised contrastive loss into prototypical few shot training for audio
classification. In detail, we demonstrate that angular loss further improves
the performance compared to the standard contrastive loss. Our method leverages
SpecAugment followed by a self-attention mechanism to encapsulate diverse
information of augmented input versions into one unified embedding. We evaluate
our approach on MetaAudio, a benchmark including five datasets with predefined
splits, standardized preprocessing, and a comprehensive set of few-shot
learning models for comparison. The proposed approach achieves state-of-the-art
performance in a 5-way, 5-shot setting.

</details>


### [96] [Data-independent Beamforming for End-to-end Multichannel Multi-speaker ASR](https://arxiv.org/abs/2509.10234)
*Can Cui,Paul Magron,Mostafa Sadeghi,Emmanuel Vincent*

Main category: cs.SD

TL;DR: 提出一种基于球面极坐标的波束成形方法，用于多通道多说话人语音识别，无需训练且数据独立，在AMI语料库上显著降低词错误率和提高说话人计数准确率


<details>
  <summary>Details</summary>
Motivation: 多通道多说话人场景中的自动语音识别面临环境噪声、混响和说话人重叠的挑战，需要更有效的信号处理方法

Method: 基于球面极坐标处理特定角度扇区的波束成形方法，生成一组波束成形信号后输入端到端多通道多说话人ASR系统

Result: 相比未使用波束成形的基线系统，词错误率降低11%，说话人计数准确率提高27%，且增加波束成形信号数量可进一步提升识别准确率

Conclusion: 该方法能更高效地利用多通道信号，减少ASR系统输入负载，同时显著提升多说话人语音识别性能

Abstract: Automatic speech recognition (ASR) in multichannel, multi-speaker scenarios
remains challenging due to ambient noise, reverberation and overlapping
speakers. In this paper, we propose a beamforming approach that processes
specific angular sectors based on their spherical polar coordinates before
applying an end-to-end multichannel, multi-speaker ASR system. This method is
data-independent and training-free. We demonstrate that using a group of
beamformed signals improves ASR performance compared to using the same number
of raw microphone signals. Moreover, increasing the number of signals used for
beamforming further enhances recognition accuracy, leading to a more efficient
use of multichannel signals while reducing the overall input load for the ASR
system. We conduct experiments on the AMI meeting corpus, where the proposed
method reduces word error rate by up to 11% and improves speaker counting
accuracy by up to 27% relative compared to a multichannel ASR baseline system
that does not exploit beamforming.

</details>


### [97] [Improving Audio Event Recognition with Consistency Regularization](https://arxiv.org/abs/2509.10391)
*Shanmuka Sadhu,Weiran Wang*

Main category: cs.SD

TL;DR: 本文提出将一致性正则化（CR）应用于音频事件识别，在AudioSet数据集上验证了其有效性，并在小规模和大规模监督训练集以及半监督设置中均取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 一致性正则化在自动语音识别中已显示出优势，但尚未在音频事件识别领域得到充分探索。本文旨在验证CR在音频事件识别中的有效性，特别是在数据增强已广泛使用的情况下CR是否仍能带来额外收益。

Method: 使用一致性正则化技术，强制模型对增强视图的预测保持一致。进行了广泛的消融研究，包括使用强弱不同的数据增强策略和多种增强组合，并在小规模（约20K）和大规模（约1.8M）监督训练集以及半监督设置（20K标注样本+1.8M未标注样本）上进行实验。

Result: CR在已大量使用数据增强的监督基线上带来了持续改进；对于小训练集，使用更强增强和多种增强的CR带来了额外增益；在半监督设置中，相比仅使用小规模标注数据的最佳模型，性能得到了进一步提升。

Conclusion: 一致性正则化在音频事件识别中具有显著效果，即使在已使用数据增强的情况下仍能带来性能提升，特别是在小数据集和半监督学习场景中表现突出。

Abstract: Consistency regularization (CR), which enforces agreement between model
predictions on augmented views, has found recent benefits in automatic speech
recognition [1]. In this paper, we propose the use of consistency
regularization for audio event recognition, and demonstrate its effectiveness
on AudioSet. With extensive ablation studies for both small ($\sim$20k) and
large ($\sim$1.8M) supervised training sets, we show that CR brings consistent
improvement over supervised baselines which already heavily utilize data
augmentation, and CR using stronger augmentation and multiple augmentations
leads to additional gain for the small training set. Furthermore, we extend the
use of CR into the semi-supervised setup with 20K labeled samples and 1.8M
unlabeled samples, and obtain performance improvement over our best model
trained on the small set.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [98] [Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis](https://arxiv.org/abs/2509.09744)
*Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia*

Main category: cs.LG

TL;DR: SAM-BG是一个两阶段的自监督学习框架，通过结构语义保护来学习脑图表示，在精神病诊断中实现了更好的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决脑网络数据标注有限的问题，同时避免现有自监督学习方法中可能破坏脑图关键结构语义的数据增强策略。

Method: 提出两阶段框架：预训练阶段使用边缘掩码器在小标注子集上捕捉关键结构语义；自监督学习阶段利用提取的结构先验指导结构感知的数据增强过程。

Result: 在两个真实精神病数据集上的实验表明，SAM-BG在少标注数据设置下优于现有最先进方法，并发现了具有临床相关性的连接模式。

Conclusion: SAM-BG框架能够学习更具语义意义和鲁棒性的脑图表示，提高了精神病诊断的准确性和可解释性，特别是在标注数据有限的情况下。

Abstract: The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.

</details>


### [99] [D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference](https://arxiv.org/abs/2509.09747)
*Leen Daher,Zhaobo Wang,Malcolm Mielle*

Main category: cs.LG

TL;DR: D-CAT是一种解耦跨注意力迁移框架，允许在推理时仅使用单一传感器进行跨模态知识迁移，无需成对传感器数据，显著减少硬件冗余。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态迁移学习方法在训练和推理时都需要成对的传感器数据，这在资源受限环境中部署成本高且技术不可行。需要一种方法能够在推理时仅使用单一传感器，同时利用其他模态的知识提升性能。

Method: 提出D-CAT框架，结合自注意力模块进行特征提取和新型跨注意力对齐损失，强制对齐不同传感器的特征空间，而无需耦合两个模态的分类管道。

Result: 在三个多模态人类活动数据集（IMU、视频和音频）上评估，在分布内场景中，从高性能模态（如视频到IMU）迁移可获得10%的F1分数提升；在分布外场景中，即使较弱的源模态也能提升目标性能。

Conclusion: D-CAT通过实现单一传感器推理的跨模态知识迁移，在保持精度的同时减少了感知系统的硬件冗余，对于成本敏感或自适应部署（如家庭辅助机器人）具有重要意义。

Abstract: Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.

</details>


### [100] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: Meta-RL-Crypto是一个基于Transformer的统一架构，结合元学习和强化学习，创建了一个完全自改进的交易代理，用于加密货币回报预测。


<details>
  <summary>Details</summary>
Motivation: 加密货币回报预测极其困难，价格变动受多种因素驱动且标注训练数据稀缺昂贵，需要一种无需人工监督的自改进方法。

Method: 从指令调优的LLM开始，代理在闭环架构中迭代扮演三个角色（执行者、评判者和元评判者），利用多模态市场输入和内部偏好反馈，持续优化交易策略和评估标准。

Result: 在不同市场机制下的实验表明，Meta-RL-Crypto在真实市场的技术指标上表现良好，并优于其他基于LLM的基线方法。

Conclusion: 该架构成功实现了无需人工监督的自改进交易代理，能够有效处理加密货币市场的复杂性和数据稀缺问题。

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [101] [LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation](https://arxiv.org/abs/2509.09754)
*Yiqun Shen,Song Yuan,Zhengze Zhang,Xiaoliang Wang,Daxin Jiang,Nguyen Cam-Tu*

Main category: cs.LG

TL;DR: LAVa是一个统一的KV缓存压缩框架，通过最小化Transformer残差流中的信息损失来实现动态预算分配，无需训练或多策略组合，在长上下文推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法大多是启发式的，缺乏动态预算分配机制，无法根据任务需求自适应调整不同层和注意力头的缓存预算。

Method: 提出统一框架最小化残差流信息损失，分析层注意力输出损失并推导新指标来跨头比较缓存条目，实现层级压缩和动态头预算分配，同时通过跨层信息对比实现动态层预算分配。

Result: 在LongBench、Needle-In-A-Haystack、Ruler和InfiniteBench等基准测试中表现优异，发现动态层预算对生成任务（如代码补全）关键，动态头预算对抽取任务（如抽取式QA）重要。

Conclusion: LAVa是首个统一的缓存淘汰和动态预算分配策略，无需训练或多策略组合，在各种任务类型中始终保持最佳性能，为KV缓存压缩提供了新的理论框架和实践方案。

Abstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.

</details>


### [102] [Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management](https://arxiv.org/abs/2509.09772)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: 提出HACO框架，结合风险校准和偏好优化，为医疗补助人群提供安全、公平、可审计的决策支持，控制不良事件风险。


<details>
  <summary>Details</summary>
Motivation: 医疗补助人群的健康管理项目需要协调纵向服务和干预措施，同时必须确保安全性、公平性和可审计性。传统方法难以在大规模决策中有效控制风险并保证公平性。

Method: HACO框架分三步：(1)训练轻量级风险模型预测不良事件；(2)使用保形阈值在目标风险水平下屏蔽不安全行动；(3)在安全行动子集上学习偏好策略。使用离线强化学习和保形预测技术。

Result: 在270万次决策数据上，HACO实现了强风险区分能力(AUC~0.81)，校准阈值在α=0.10时为τ~0.038，同时保持高安全覆盖率。亚组分析显示不同人口统计特征间存在系统性价值差异。

Conclusion: 保形风险门控与离线强化学习相结合，能够为人群健康管理团队提供保守且可审计的决策支持，强调了公平性审计的重要性。

Abstract: Population health management programs for Medicaid populations coordinate
longitudinal outreach and services (e.g., benefits navigation, behavioral
health, social needs support, and clinical scheduling) and must be safe, fair,
and auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement
Learning (HACO) framework that separates risk calibration from preference
optimization to generate conservative action recommendations at scale. In our
setting, each step involves choosing among common coordination actions (e.g.,
which member to contact, by which modality, and whether to route to a
specialized service) while controlling the near-term risk of adverse
utilization events (e.g., unplanned emergency department visits or
hospitalizations). Using a de-identified operational dataset from Waymark
comprising 2.77 million sequential decisions across 168,126 patients, HACO (i)
trains a lightweight risk model for adverse events, (ii) derives a conformal
threshold to mask unsafe actions at a target risk level, and (iii) learns a
preference policy on the resulting safe subset. We evaluate policies with a
version-agnostic fitted Q evaluation (FQE) on stratified subsets and audit
subgroup performance across age, sex, and race. HACO achieves strong risk
discrimination (AUC ~0.81) with a calibrated threshold ( {\tau} ~0.038 at
{\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses
reveal systematic differences in estimated value across demographics,
underscoring the importance of fairness auditing. Our results show that
conformal risk gating integrates cleanly with offline RL to deliver
conservative, auditable decision support for population health management
teams.

</details>


### [103] [One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection](https://arxiv.org/abs/2509.09782)
*Roshini Pulishetty,Mani Kishan Ghantasala,Keerthy Kaushik Dasoju,Niti Mangwani,Vishal Garimella,Aditya Mate,Somya Chatterjee,Yue Kang,Ehi Nosakhare,Sadid Hasan,Soundar Srinivasan*

Main category: cs.LG

TL;DR: 提出基于单头交叉注意力机制的统一路由框架，动态选择最优LLM，在RouterBench基准上实现6.6%的质量提升和2.9%的最大性能提升


<details>
  <summary>Details</summary>
Motivation: 解决不同计算成本和性能的大型语言模型在现实应用中规模化、成本效益部署的挑战

Method: 使用单头交叉注意力机制联合建模查询和模型嵌入，显式捕捉细粒度查询-模型交互，预测响应质量和生成成本

Result: 在RouterBench基准测试中，平均质量改进(AIQ)提升6.6%，最大性能提升2.9%，架构轻量且跨域泛化效果好

Conclusion: 建立了成本感知LLM路由的新标准，通过指数奖励函数稳健平衡性能与成本，相比现有方法效率更高

Abstract: The proliferation of large language models (LLMs) with varying computational
costs and performance profiles presents a critical challenge for scalable,
cost-effective deployment in real-world applications. We introduce a unified
routing framework that leverages a single-head cross-attention mechanism to
jointly model query and model embeddings, enabling dynamic selection of the
optimal LLM for each input query. Our approach is evaluated on RouterBench, a
large-scale, publicly available benchmark encompassing diverse LLM pools and
domains. By explicitly capturing fine-grained query-model interactions, our
router predicts both response quality and generation cost, achieving up to 6.6%
improvement in Average Improvement in Quality (AIQ) and 2.9% in maximum
performance over existing routers. To robustly balance performance and cost, we
propose an exponential reward function that enhances stability across user
preferences. The resulting architecture is lightweight, generalizes effectively
across domains, and demonstrates improved efficiency compared to prior methods,
establishing a new standard for cost-aware LLM routing.

</details>


### [104] [From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms](https://arxiv.org/abs/2509.09793)
*Vincent Herfeld,Baudouin Denis de Senneville,Arthur Leclaire,Nicolas Papadakis*

Main category: cs.LG

TL;DR: 分析梯度步长去噪器及其在即插即用算法中的应用，该去噪器被训练为显式函数的功能下降算子或邻近算子，同时保持最先进的去噪能力


<details>
  <summary>Details</summary>
Motivation: 即插即用优化算法通常使用现成的去噪器来替代图像先验的邻近算子或梯度下降算子，但这些先验通常是隐式的且无法表达。研究旨在开发能够同时作为显式函数算子和保持优秀去噪性能的去噪器

Method: 训练梯度步长去噪器，使其精确地作为显式函数的功能下降算子或邻近算子

Result: 梯度步长去噪器成功实现了作为显式函数算子的目标，同时保持了最先进的去噪性能

Conclusion: 梯度步长去噪器为即插即用算法提供了新的可能性，通过将隐式图像先验转化为显式函数算子，同时不牺牲去噪效果

Abstract: In this paper we analyze the Gradient-Step Denoiser and its usage in
Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms
uses off the shelf denoisers to replace a proximity operator or a gradient
descent operator of an image prior. Usually this image prior is implicit and
cannot be expressed, but the Gradient-Step Denoiser is trained to be exactly
the gradient descent operator or the proximity operator of an explicit
functional while preserving state-of-the-art denoising capabilities.

</details>


### [105] [Distinguishing Startle from Surprise Events Based on Physiological Signals](https://arxiv.org/abs/2509.09799)
*Mansi Sharma,Alexandre Duchevet,Florian Daiber,Jean-Paul Imbert,Maurice Rekrut*

Main category: cs.LG

TL;DR: 本研究使用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件，最高准确率达85.7%，并能将惊吓、惊讶和基线状态区分，准确率达74.9%。


<details>
  <summary>Details</summary>
Motivation: 意外事件会损害注意力和延迟决策，在高风险环境（如航空）中构成严重安全风险。惊吓和惊讶反应以不同方式影响飞行员表现，但在实践中难以区分。现有研究大多单独研究这些反应，对其组合效应或如何使用生理数据区分它们关注有限。

Method: 使用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件。采用了SVM和XGBoost等算法，以及Late Fusion融合策略。

Result: 惊吓和惊讶事件可以可靠预测，使用SVM和Late Fusion获得最高平均准确率85.7%。扩展评估包括基线条件后，使用XGBoost和Late Fusion成功区分惊吓、惊讶和基线状态，最高平均准确率达74.9%。

Conclusion: 研究证明了基于生理信号使用机器学习方法有效区分惊吓和惊讶事件的可行性，为高风险环境中意外事件的监测和干预提供了重要技术支撑。

Abstract: Unexpected events can impair attention and delay decision-making, posing
serious safety risks in high-risk environments such as aviation. In particular,
reactions like startle and surprise can impact pilot performance in different
ways, yet are often hard to distinguish in practice. Existing research has
largely studied these reactions separately, with limited focus on their
combined effects or how to differentiate them using physiological data. In this
work, we address this gap by distinguishing between startle and surprise events
based on physiological signals using machine learning and multi-modal fusion
strategies. Our results demonstrate that these events can be reliably
predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.
To further validate the robustness of our model, we extended the evaluation to
include a baseline condition, successfully differentiating between Startle,
Surprise, and Baseline states with a highest mean accuracy of 74.9% with
XGBoost and Late Fusion.

</details>


### [106] [Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning](https://arxiv.org/abs/2509.09838)
*Reza Asad,Reza Babanezhad,Sharan Vaswani*

Main category: cs.LG

TL;DR: 本文重新审视了离散动作环境中的off-policy actor-critic方法，发现DSAC性能不佳的主要原因是actor和critic熵的耦合，通过解耦这两个组件可以显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的离散动作强化学习方法中，基于价值的方法（如DQN）是主流，而基于策略的方法要么是on-policy无法有效利用off-policy数据（如PPO），要么在离散动作设置中表现不佳（如SAC）。

Method: 提出了一个灵活的off-policy actor-critic框架，允许使用m步Bellman算子进行critic更新，并将标准策略优化方法与熵正则化相结合来实例化actor目标函数。

Result: 理论证明在表格设置中可以保证收敛到最优正则化价值函数，实证表明在标准Atari游戏中可以达到与DQN相当的性能，甚至无需熵正则化或显式探索。

Conclusion: 通过解耦actor和critic的熵组件，可以显著提升离散SAC方法的性能，为离散动作环境提供了有效的off-policy actor-critic解决方案。

Abstract: Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.

</details>


### [107] [HGEN: Heterogeneous Graph Ensemble Networks](https://arxiv.org/abs/2509.09843)
*Jiajun Shen,Yufei Jin,Yi He,Xingquan Zhu*

Main category: cs.LG

TL;DR: HGEN是一个针对异构图的开创性集成学习框架，通过元路径和随机丢弃创建等位GNN，利用残差注意力机制和相关性正则化提升分类精度


<details>
  <summary>Details</summary>
Motivation: 异构图中的节点类型、节点特征和局部邻域拓扑的异质性给集成学习带来挑战，需要适应多样化的图学习器

Method: 使用元路径结合随机丢弃创建等位GNN，采用残差注意力机制校准不同元路径的等位GNN，并通过相关性正则化项增大不同元路径生成的嵌入矩阵差异

Result: 在五个异构网络上的实验验证HGEN始终以显著优势超越最先进的竞争对手

Conclusion: HGEN通过有效的集成学习框架解决了异构图学习中的挑战，提高了分类准确性

Abstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.

</details>


### [108] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: 本文提出了一个推理时计算动态分配框架，同时考虑token成本和延迟，在推理基准测试中优于静态策略


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注并行生成方法（如best-of-N），忽略了增量解码方法（如beam search），且主要关注token使用而忽略了延迟，而延迟对用户体验和智能体工作流至关重要

Method: 将推理时扩展制定为动态计算分配和方法选择问题，系统需要基于每个查询决定应用哪种策略以及分配多少计算资源，明确包含token成本和时钟延迟

Result: 在推理基准测试中，该方法始终优于静态策略，实现了有利的准确率-成本权衡，同时保持实际部署可行性

Conclusion: 动态计算分配框架能够有效平衡模型性能和计算成本，特别适用于需要高效多查询的智能体工作流

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [109] [Variational Neural Networks for Observable Thermodynamics (V-NOTS)](https://arxiv.org/abs/2509.09899)
*Christopher Eldred,François Gay-Balmaz,Vakhtang Putkaradze*

Main category: cs.LG

TL;DR: 本文提出了一种基于可观测变量的数据驱动计算方法，用于预测耗散动力系统的演化，通过构造热力学拉格朗日量和神经网络来保证熵的非递减演化。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要相空间变量的完整数据，但在耗散动力系统中，动量和熵等变量往往无法直接观测，这限制了数据驱动方法的应用。

Method: 开发了基于热力学拉格朗日量的神经网络框架，仅使用可观测变量（如坐标），同时确保热力学约束和熵的非递减演化特性。

Result: 该方法能够基于有限的数据点和相对较少的参数，有效描述相空间演化，证明了其在数据稀缺情况下的高效性。

Conclusion: 所提出的框架为仅使用可观测变量进行耗散系统演化预测提供了有效解决方案，克服了传统方法对完整相空间数据的依赖。

Abstract: Much attention has recently been devoted to data-based computing of evolution
of physical systems. In such approaches, information about data points from
past trajectories in phase space is used to reconstruct the equations of motion
and to predict future solutions that have not been observed before. However, in
many cases, the available data does not correspond to the variables that define
the system's phase space. We focus our attention on the important example of
dissipative dynamical systems. In that case, the phase space consists of
coordinates, momenta and entropies; however, the momenta and entropies cannot,
in general, be observed directly. To address this difficulty, we develop an
efficient data-based computing framework based exclusively on observable
variables, by constructing a novel approach based on the \emph{thermodynamic
Lagrangian}, and constructing neural networks that respect the thermodynamics
and guarantees the non-decreasing entropy evolution. We show that our network
can provide an efficient description of phase space evolution based on a
limited number of data points and a relatively small number of parameters in
the system.

</details>


### [110] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: 提出了LoFT框架，通过参数高效微调基础模型来解决长尾半监督学习问题，并在开放世界场景下扩展为LoFT-OW，显著提升了性能


<details>
  <summary>Details</summary>
Motivation: 现有长尾半监督学习方法大多从零开始训练模型，存在过自信和伪标签质量低的问题，需要利用基础模型微调来生成更可靠的伪标签

Method: 将长尾半监督学习扩展到基础模型微调范式，提出LoFT框架进行参数高效微调，并在开放世界场景下提出LoFT-OW来提升判别能力

Result: 在多个基准测试中取得了优于先前方法的性能，即使仅使用1%的未标注数据也能超越之前的工作

Conclusion: 基础模型微调能够生成更可靠的伪标签，显著改善长尾学习效果，LoFT框架为长尾半监督学习提供了有效的解决方案

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [111] [Multi-Play Combinatorial Semi-Bandit Problem](https://arxiv.org/abs/2509.09933)
*Shintaro Nakamura,Yuko Kuroki,Wei Chen*

Main category: cs.LG

TL;DR: 提出了多选择组合半赌博机(MP-CSB)模型，扩展了传统组合半赌博机到非负整数动作空间，解决了最优传输和背包等问题。提出了两种算法：基于Thompson采样的算法和最佳两用算法，分别在随机和对抗环境中实现对数或次线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 传统组合半赌博机(CSB)仅限于二元决策空间，无法处理涉及非负整数流或分配的重要问题，如最优传输和背包问题。需要扩展模型以支持更广泛的应用场景。

Method: 提出了MP-CSB模型，允许选择非负整数动作并从单个臂获得多次反馈。开发了两种算法：1)基于Thompson采样的算法，适用于指数大的动作空间；2)最佳两用算法，在随机和对抗环境中都能工作。

Result: Thompson采样算法在随机环境中实现O(log T)分布依赖遗憾；最佳两用算法在随机环境中实现O(log T)方差依赖遗憾，在对抗环境中实现Õ(√T)最坏情况遗憾，且遗憾是数据依赖的。数值实验显示优于现有方法。

Conclusion: MP-CSB成功扩展了CSB到非负整数动作空间，提出的算法在计算效率和理论保证方面都表现出色，为组合优化问题提供了更通用的解决方案。

Abstract: In the combinatorial semi-bandit (CSB) problem, a player selects an action
from a combinatorial action set and observes feedback from the base arms
included in the action. While CSB is widely applicable to combinatorial
optimization problems, its restriction to binary decision spaces excludes
important cases involving non-negative integer flows or allocations, such as
the optimal transport and knapsack problems.To overcome this limitation, we
propose the multi-play combinatorial semi-bandit (MP-CSB), where a player can
select a non-negative integer action and observe multiple feedbacks from a
single arm in each round. We propose two algorithms for the MP-CSB. One is a
Thompson-sampling-based algorithm that is computationally feasible even when
the action space is exponentially large with respect to the number of arms, and
attains $O(\log T)$ distribution-dependent regret in the stochastic regime,
where $T$ is the time horizon. The other is a best-of-both-worlds algorithm,
which achieves $O(\log T)$ variance-dependent regret in the stochastic regime
and the worst-case $\tilde{\mathcal{O}}\left( \sqrt{T} \right)$ regret in the
adversarial regime. Moreover, its regret in adversarial one is data-dependent,
adapting to the cumulative loss of the optimal action, the total quadratic
variation, and the path-length of the loss sequence. Finally, we numerically
show that the proposed algorithms outperform existing methods in the CSB
literature.

</details>


### [112] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: 本文探讨使用LLMs作为科学机器学习代理，通过生成代码解决ODE问题，而非直接学习解函数。提出了新的诊断数据集和大规模基准测试，评估LLMs在科学计算任务中的能力。


<details>
  <summary>Details</summary>
Motivation: 传统科学机器学习方法直接预测目标值面临精度和鲁棒性挑战，本文探索替代方案：利用LLMs编写代码，借助成熟的数值算法，将学习负担转移到领域感知的数值选择上。

Method: 引入两个新数据集：诊断性误导问题和1000个多样化ODE任务的大规模基准。评估开源和闭源LLM模型，采用无引导vs领域知识引导提示、现成vs微调变体两种策略，测量代码可执行性和数值有效性。

Result: 研究发现，在充足上下文和引导提示下，较新的指令跟随模型在可执行性和数值有效性方面达到高精度。开源系统无需微调表现强劲，而较老或较小模型仍能从微调中受益。

Conclusion: 精心设计的提示和微调可以产生能够可靠解决简单ODE问题的专用LLM代理，为科学机器学习提供了有前景的新方向。

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [113] [DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition](https://arxiv.org/abs/2509.09940)
*Yifei Wang,Wenbin Wang,Yong Luo*

Main category: cs.LG

TL;DR: DyKen-Hyena模型通过将多模态信息转换为动态卷积核来调制文本特征提取，而不是简单的特征融合，在多模态意图识别任务上取得了SOTA效果


<details>
  <summary>Details</summary>
Motivation: 传统的多模态融合方法可能因模态间的无关或冲突信息而损害主要语言特征，需要更细粒度的调制机制而非简单的特征增强

Method: 将音频-视觉线索转换为动态的、每个token级别的卷积核，直接调制文本特征提取过程，实现细粒度的处理调制

Result: 在MIntRec和MIntRec2.0基准测试中达到最先进水平，特别是在域外检测任务上获得了+10.46%的F1分数提升

Conclusion: 该方法通过处理调制而非特征融合，创建了更鲁棒的意图表示，验证了细粒度调制方法的有效性

Abstract: Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich
information from multiple sources (e.g., language, video, and audio), the
potential for intent-irrelevant and conflicting information across modalities
may hinder performance from being further improved. Most current models attempt
to fuse modalities by applying mechanisms like multi-head attention to unimodal
feature sequences and then adding the result back to the original
representation. This process risks corrupting the primary linguistic features
with noisy or irrelevant non-verbal signals, as it often fails to capture the
fine-grained, token-level influence where non-verbal cues should modulate, not
just augment, textual meaning. To address this, we introduce DyKen-Hyena, which
reframes the problem from feature fusion to processing modulation. Our model
translates audio-visual cues into dynamic, per-token convolutional kernels that
directly modulate textual feature extraction. This fine-grained approach
achieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.
Notably, it yields a +10.46% F1-score improvement in out-of-scope detection,
validating that our method creates a fundamentally more robust intent
representation.

</details>


### [114] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: 提出无需训练的token合并框架，通过动态合并语义冗余token来压缩transformer表示，在保持精度的同时显著降低计算和通信成本


<details>
  <summary>Details</summary>
Motivation: 大规模transformer在语义通信中计算和通信成本过高，难以部署在资源受限的边缘设备上

Method: 基于每层相似度阈值选择性合并冗余token，将合并策略发现建模为多目标优化问题，使用贝叶斯优化获得帕累托最优权衡

Result: 在ImageNet分类中减少30% FLOPs和80%通信成本，在VQA任务中以1/3计算量和1/10带宽达到LLaVA模型性能

Conclusion: 该框架为资源受限的边缘智能场景提供了实用且通用的transformer部署解决方案，具有鲁棒性和隐私保护优势

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


### [115] [Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes](https://arxiv.org/abs/2509.09960)
*Mingxuan Jiang,Yongxin Wang,Ziyue Dai,Yicun Liu,Hongyi Nie,Sen Liu,Hongfeng Chai*

Main category: cs.LG

TL;DR: ReFine是一个合成表格数据生成框架，通过从可解释模型提取符号规则嵌入提示词来指导生成，并采用双粒度过滤策略减少分布不平衡，在数据稀缺场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有表格生成方法（GANs、扩散模型、微调LLMs）需要充足参考数据，在领域特定数据库记录稀缺时效果有限。基于提示的LLMs虽然灵活但难以捕捉数据集特定的特征-标签依赖关系，且生成冗余数据导致下游任务性能下降。

Method: 提出ReFine框架：(i)从可解释模型推导符号"if-then"规则并嵌入提示词，显式指导生成符合领域特定特征分布；(ii)应用双粒度过滤策略，抑制过采样模式并选择性精炼稀有但信息丰富的样本以减少分布不平衡。

Result: 在各种回归和分类基准测试中，ReFine始终优于最先进方法，回归任务R平方绝对提升达0.44，分类任务F1分数相对提升10.0%。

Conclusion: ReFine通过规则引导和智能过滤有效解决了数据稀缺场景下的表格生成问题，显著提升了生成数据的质量和下游任务性能。

Abstract: Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.

</details>


### [116] [Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning](https://arxiv.org/abs/2509.09991)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 提出一种基于机器学习的虚拟服务器能耗估计方法，无需物理功率测量接口，仅使用虚拟机资源利用率指标即可准确预测能耗


<details>
  <summary>Details</summary>
Motivation: 解决虚拟化环境（如云平台）中无法直接测量能耗的关键问题，为能量感知调度和成本优化提供支持

Method: 使用梯度提升回归器（Gradient Boosting Regressor），基于虚拟机收集的资源利用率指标来训练模型，预测通过RAPL测量的主机能耗

Result: 在多样化工作负载实验中实现了高预测精度，方差解释度达到0.90-0.97，首次证明了无需特权主机访问的纯客户端能耗估计可行性

Conclusion: 该方法能够实现虚拟化环境中的能量感知调度、成本优化和物理主机独立的能耗估计，填补了虚拟化环境中直接能耗测量不可行的关键空白

Abstract: This paper presents a machine learning-based approach to estimate the energy
consumption of virtual servers without access to physical power measurement
interfaces. Using resource utilization metrics collected from guest virtual
machines, we train a Gradient Boosting Regressor to predict energy consumption
measured via RAPL on the host. We demonstrate, for the first time, guest-only
resource-based energy estimation without privileged host access with
experiments across diverse workloads, achieving high predictive accuracy and
variance explained ($0.90 \leq R^2 \leq 0.97$), indicating the feasibility of
guest-side energy estimation. This approach can enable energy-aware scheduling,
cost optimization and physical host independent energy estimates in virtualized
environments. Our approach addresses a critical gap in virtualized environments
(e.g. cloud) where direct energy measurement is infeasible.

</details>


### [117] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 该论文实证研究了深度回归模型中的神经缩放定律，发现在扭曲范德瓦尔斯磁体的参数估计模型中，损失与训练数据集大小和模型容量之间存在幂律关系，缩放指数范围为1到2。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型的成功凸显了神经缩放定律的重要性，但这些定律在深度回归模型中的应用仍未被充分探索。论文旨在填补这一空白，研究深度回归中的缩放行为。

Method: 使用扭曲范德瓦尔斯磁体的参数估计模型，采用多种架构（包括全连接网络、残差网络和视觉变换器），在不同训练数据集大小和模型容量下实证研究损失函数的缩放行为。

Result: 观察到损失与训练数据集大小和模型容量之间存在幂律关系，缩放指数范围在1到2之间，具体值取决于回归参数和模型细节。一致的缩放行为和大缩放指数表明性能可以随数据量增加而显著提升。

Conclusion: 深度回归模型表现出显著的神经缩放定律特性，大缩放指数意味着增加数据量可以大幅提升模型性能，这为资源受限下的模型开发提供了重要指导。

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [118] [Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss](https://arxiv.org/abs/2509.10011)
*Antoine Orioua,Philipp Krah,Julian Koellermeier*

Main category: cs.LG

TL;DR: IDEA是一种能够估计数据集内在维度并重建原始数据的自编码器，通过投影重建损失项和重加权双CancelOut层结构，在线性和非线性流形数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在估计数据集内在维度时往往无法同时保证重建质量，特别是在处理复杂非线性流形数据时存在局限性。需要一种既能准确估计内在维度又能有效重建原始数据的方法。

Method: 提出IDEA自编码器，使用重加权双CancelOut层构建潜在空间，引入投影重建损失项来指导训练，通过连续评估去除额外潜在维度后的重建质量来优化模型。

Result: 在理论基准测试中表现出良好的准确性和高通用性，成功估计了垂直解析一维自由表面流数值解数据集的内在维度，并能在网络识别的投影空间内重建原始解。

Conclusion: IDEA是一种有效的内在维度估计和重建方法，适用于线性和非线性流形数据，在复杂科学计算数据上展现出实用价值。

Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.

</details>


### [119] [Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts](https://arxiv.org/abs/2509.10025)
*Strahinja Nikolic,Ilker Oguz,Demetri Psaltis*

Main category: cs.LG

TL;DR: 本文提出了一种稀疏专家混合变分自编码器(SMoE-VAE)架构，在QuickDraw数据集上发现无监督专家路由比有监督基线表现更好，能够识别出超越人工定义类别的有意义子类别结构。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络内部组织是深度学习可解释性的基本挑战，需要探索新的架构来揭示模型如何发现数据的基本结构。

Method: 使用稀疏专家混合变分自编码器(SMoE-VAE)，在QuickDraw数据集上比较无监督专家路由和有监督基线，通过t-SNE可视化和重建分析研究模型结构。

Result: 无监督路由始终获得更好的重建性能，专家学会了识别有意义子类别结构，这些结构往往超越人工定义的类别边界。数据集大小研究揭示了数据量与专家专业化之间的权衡。

Conclusion: MoE模型能够发现比预定义标签更符合模型目标的基本数据结构，为设计高效的MoE架构提供了指导。

Abstract: Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.

</details>


### [120] [Sparse Coding Representation of 2-way Data](https://arxiv.org/abs/2509.10033)
*Boya Ma,Abram Magner,Maxwell McNeil,Petko Bogdanov*

Main category: cs.LG

TL;DR: 提出了一种用于稀疏字典编码的低秩编码模型AODL，通过凸松弛和交替优化方法学习字典，在保证重建质量的同时获得更稀疏的解，并具有可解释性


<details>
  <summary>Details</summary>
Motivation: 解决多字典场景下同时学习字典和编码系数的挑战，特别是在2-dictionary情况下编码系数对应所有字典原子组合的复杂性

Method: 提出低秩编码模型，建立样本复杂度界限，设计凸松弛解决方案AODL，通过稀疏编码矩阵和学习字典之间的交替优化进行求解

Result: AODL在固定重建质量下比非低秩和固定字典基线学习到稀疏90%的解，在合成和真实数据集上展示了良好的数据重建和缺失值插补性能

Conclusion: AODL方法有效解决了多字典学习问题，不仅提供更稀疏的解决方案，还能通过学习到的字典揭示训练样本中的可解释模式

Abstract: Sparse dictionary coding represents signals as linear combinations of a few
dictionary atoms. It has been applied to images, time series, graph signals and
multi-way spatio-temporal data by jointly employing temporal and spatial
dictionaries. Data-agnostic analytical dictionaries, such as the discrete
Fourier transform, wavelets and graph Fourier, have seen wide adoption due to
efficient implementations and good practical performance. On the other hand,
dictionaries learned from data offer sparser and more accurate solutions but
require learning of both the dictionaries and the coding coefficients. This
becomes especially challenging for multi-dictionary scenarios since encoding
coefficients correspond to all atom combinations from the dictionaries. To
address this challenge, we propose a low-rank coding model for 2-dictionary
scenarios and study its data complexity. Namely, we establish a bound on the
number of samples needed to learn dictionaries that generalize to unseen
samples from the same distribution. We propose a convex relaxation solution,
called AODL, whose exact solution we show also solves the original problem. We
then solve this relaxation via alternating optimization between the sparse
coding matrices and the learned dictionaries, which we prove to be convergent.
We demonstrate its quality for data reconstruction and missing value imputation
in both synthetic and real-world datasets. For a fixed reconstruction quality,
AODL learns up to 90\% sparser solutions compared to non-low-rank and
analytical (fixed) dictionary baselines. In addition, the learned dictionaries
reveal interpretable insights into patterns present within the samples used for
training.

</details>


### [121] [Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability](https://arxiv.org/abs/2509.10034)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: 本文提出了一种使用符号前馈神经网络精确模拟概率有限自动机(PFA)的形式化构造理论，通过矩阵向量乘积实现概率状态传播，证明了PFA与特定神经网络类的等价性，并展示了这些符号模拟器可以通过梯度下降学习得到精确的PFA行为。


<details>
  <summary>Details</summary>
Motivation: 弥合符号计算与深度学习之间的差距，将概率自动机理论与神经架构在严格的代数框架下统一起来，实现可解释、可微分且可学习的概率自动机模拟。

Method: 使用符号前馈神经网络架构，将状态分布表示为向量，转移表示为随机矩阵，通过矩阵向量乘积实现概率状态传播，采用分层符号计算进行概率子集构造、ε-闭包和精确模拟。

Result: 证明了PFAs与特定神经网络类的等价性，展示了符号模拟器可以通过标准梯度下降优化在标记序列数据上训练，精确恢复真实PFA的行为。

Conclusion: 该工作建立了概率自动机理论与神经架构的严格统一框架，实现了无需递归的并行、可解释、可微分模拟，为符号计算与深度学习的融合提供了理论基础。

Abstract: We present a formal and constructive theory showing that probabilistic finite
automata (PFAs) can be exactly simulated using symbolic feedforward neural
networks. Our architecture represents state distributions as vectors and
transitions as stochastic matrices, enabling probabilistic state propagation
via matrix-vector products. This yields a parallel, interpretable, and
differentiable simulation of PFA dynamics using soft updates-without
recurrence. We formally characterize probabilistic subset construction,
$\varepsilon$-closure, and exact simulation via layered symbolic computation,
and prove equivalence between PFAs and specific classes of neural networks. We
further show that these symbolic simulators are not only expressive but
learnable: trained with standard gradient descent-based optimization on labeled
sequence data, they recover the exact behavior of ground-truth PFAs. This
learnability, formalized in Proposition 5.1, is the crux of this work. Our
results unify probabilistic automata theory with neural architectures under a
rigorous algebraic framework, bridging the gap between symbolic computation and
deep learning.

</details>


### [122] [FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection](https://arxiv.org/abs/2509.10041)
*Mohammad Hasan Narimani,Mostafa Tavassolipour*

Main category: cs.LG

TL;DR: FedRP是一种新颖的联邦学习算法，通过随机投影技术和ADMM优化框架结合，在保护隐私的同时降低通信成本，并提供强差分隐私保证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护用户隐私方面面临挑战，包括隐私攻击风险和通信成本管理问题。需要一种既能保护隐私又能减少通信开销的解决方案。

Method: 提出FedRP算法，集成随机投影技术降低模型参数维度，结合ADMM优化框架，在参数传输前进行降维处理。

Result: 实验结果显示FedRP不仅保持高模型精度，在隐私保护和通信效率方面均优于现有方法，包括传统差分隐私方法和FedADMM。

Conclusion: FedRP算法成功解决了联邦学习中的隐私保护和通信成本问题，提供了有效的隐私保护解决方案。

Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model
training across decentralized devices, such as smartphones, balancing enhanced
predictive performance with the protection of user privacy in sensitive areas
like Internet of Things (IoT) and medical data analysis. Despite its
advantages, FL encounters significant challenges related to user privacy
protection against potential attacks and the management of communication costs.
This paper introduces a novel federated learning algorithm called FedRP, which
integrates random projection techniques with the Alternating Direction Method
of Multipliers (ADMM) optimization framework. This approach enhances privacy by
employing random projection to reduce the dimensionality of model parameters
prior to their transmission to a central server, reducing the communication
cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential
privacy guarantee, demonstrating resilience against data reconstruction
attacks. Experimental results reveal that FedRP not only maintains high model
accuracy but also outperforms existing methods, including conventional
differential privacy approaches and FedADMM, in terms of both privacy
preservation and communication efficiency.

</details>


### [123] [Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data](https://arxiv.org/abs/2509.10048)
*Madhushan Ramalingam*

Main category: cs.LG

TL;DR: 评估VBLL集成到TabPFN中的不确定性校准性能，发现原始TabPFN在所有数据集上均优于VBLL集成版本


<details>
  <summary>Details</summary>
Motivation: 在医疗诊断等安全关键应用中，可靠的不确定性估计至关重要。TabPFN是新兴的表格数据基础模型，VBLL是最先进的轻量级变分方法，本研究旨在评估两者结合的不确定性校准性能

Method: 在三个基准医疗表格数据集上进行实验，比较原始TabPFN和VBLL集成版本的性能

Result: 与预期相反，原始TabPFN在所有数据集上的不确定性校准表现均优于VBLL集成版本

Conclusion: VBLL集成并未改善TabPFN的不确定性校准性能，原始TabPFN表现更佳

Abstract: Predictive models are being increasingly used across a wide range of domains,
including safety-critical applications such as medical diagnosis and criminal
justice. Reliable uncertainty estimation is a crucial task in such settings.
Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine
learning foundation model for tabular dataset, which uses a generative
transformer architecture. Variational Bayesian Last Layers (VBLL) is a
state-of-the-art lightweight variational formulation that effectively improves
uncertainty estimation with minimal computational overhead. In this work we aim
to evaluate the performance of VBLL integrated with the recently proposed
TabPFN in uncertainty calibration. Our experiments, conducted on three
benchmark medical tabular datasets, compare the performance of the original
TabPFN and the VBLL-integrated version. Contrary to expectations, we observed
that original TabPFN consistently outperforms VBLL integrated TabPFN in
uncertainty calibration across all datasets.

</details>


### [124] [KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework](https://arxiv.org/abs/2509.10089)
*Marco Andrea Bühler,Gonzalo Guillén-Gosálbez*

Main category: cs.LG

TL;DR: KAN-SR是一个基于Kolmogorov Arnold Networks的新型符号回归框架，采用分治法，结合深度学习技术和简化策略，能够准确恢复Feynman SRSD数据集的基础真值方程，并能精确建模生物过程系统动力学。


<details>
  <summary>Details</summary>
Motivation: 传统符号回归通常使用遗传编程方法，本文旨在利用深度学习技术开发更有效的符号回归框架，提高方程发现的准确性和效率。

Method: 使用Kolmogorov Arnold Networks (KANs)，采用分治法，结合平移对称性和可分离性等简化策略，并与神经控制微分方程结合进行动态建模。

Result: 成功恢复了Feynman SRSD数据集的基础真值方程，并精确建模了硅内生物过程系统的动力学特性。

Conclusion: KAN-SR框架为符号回归提供了新的有效方法，能够准确发现数学方程并为工程系统的动态建模开辟了新途径。

Abstract: We introduce a novel symbolic regression framework, namely KAN-SR, built on
Kolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.
Symbolic regression searches for mathematical equations that best fit a given
dataset and is commonly solved with genetic programming approaches. We show
that by using deep learning techniques, more specific KANs, and combining them
with simplification strategies such as translational symmetries and
separabilities, we are able to recover ground-truth equations of the Feynman
Symbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we
show that by combining the proposed framework with neural controlled
differential equations, we are able to model the dynamics of an in-silico
bioprocess system precisely, opening the door for the dynamic modeling of other
engineering systems.

</details>


### [125] [Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning](https://arxiv.org/abs/2509.10132)
*Nour Jamoussi,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出了一种基于信息几何投影的贝叶斯联邦学习个性化框架，通过将全局模型投影到用户本地模型的邻域，实现全局泛化与局部特化的可调权衡，计算成本低且性能优异


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯联邦学习方法通常依赖MCMC采样或变分推断，需要个性化机制来适应异构数据分布。本文旨在开发一种更高效、可调谐的个性化方法

Method: 采用信息几何投影框架，将全局模型投影到用户本地模型的统计流形邻域，证明该投影等价于计算统计流形上的重心，从而获得闭式解和零成本个性化

Result: 在异构数据分布下的实证评估表明，该方法能有效平衡全局和局部性能，且计算开销极小

Conclusion: 所提出的信息几何投影框架为贝叶斯联邦学习提供了一种高效、可调谐的个性化解决方案，在保持计算效率的同时实现了优异的性能平衡

Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with
decentralized training, enabling the development of personalized and reliable
models under data heterogeneity and privacy constraints. Existing approaches
typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational
inference, often incorporating personalization mechanisms to better adapt to
local data distributions. In this work, we propose an information-geometric
projection framework for personalization in parametric BFL. By projecting the
global model onto a neighborhood of the user's local model, our method enables
a tunable trade-off between global generalization and local specialization.
Under mild assumptions, we show that this projection step is equivalent to
computing a barycenter on the statistical manifold, allowing us to derive
closed-form solutions and achieve cost-free personalization. We apply the
proposed approach to a variational learning setup using the Improved
Variational Online Newton (IVON) optimizer and extend its application to
general aggregation schemes in BFL. Empirical evaluations under heterogeneous
data distributions confirm that our method effectively balances global and
local performance with minimal computational overhead.

</details>


### [126] [BenchECG and xECG: a benchmark and baseline for ECG foundation models](https://arxiv.org/abs/2509.10151)
*Riccardo Lunelli,Angus Nicolson,Samuel Martin Pröll,Sebastian Johannes Reinstadler,Axel Bauer,Clemens Dlaska*

Main category: cs.LG

TL;DR: 提出了BenchECG标准化基准和xECG模型，通过统一的评估框架解决ECG基础模型缺乏公平比较的问题，xECG在多个数据集和任务上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的ECG基础模型研究缺乏一致的评估标准，使用不同的任务选择和数据集，阻碍了公平比较和进展。

Method: 开发BenchECG标准化基准，包含全面的公开ECG数据集和多样化任务；提出基于xLSTM的xECG模型，使用SimDINOv2自监督学习进行训练。

Result: xECG在BenchECG基准上取得了最佳评分，是唯一在所有数据集和任务上都表现优异的公开可用模型。

Conclusion: BenchECG标准化评估促进了ECG表示学习的严格比较，xECG为未来ECG基础模型设立了新的性能基准。

Abstract: Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.

</details>


### [127] [FedBiF: Communication-Efficient Federated Learning via Bits Freezing](https://arxiv.org/abs/2509.10161)
*Shiwei Li,Qunwei Li,Haozhao Wang,Ruixuan Li,Jianbin Lin,Wenliang Zhong*

Main category: cs.LG

TL;DR: FedBiF是一种新颖的联邦学习框架，通过在本地训练期间直接学习量化模型参数，逐比特更新参数来显著减少通信开销，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习存在显著的通信开销问题，现有量化方法通常在本地训练后应用量化，导致量化误差影响模型精度。需要一种在训练过程中直接学习量化参数的方法。

Method: 提出FedBiF框架：服务器先量化模型参数并传输给客户端；每个客户端只更新多比特参数表示中的单个比特，冻结其余比特；采用逐比特更新策略。

Result: 在5个常用数据集上的IID和非IID设置下实验表明，FedBiF实现了优异的通信压缩，促进模型稀疏性，仅使用1bpp上行和3bpp下行通信即可达到与FedAvg相当的精度。

Conclusion: FedBiF通过直接学习量化参数和逐比特更新策略，有效解决了联邦学习的通信开销问题，在保持精度的同时大幅减少通信成本。

Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.

</details>


### [128] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 提出了一种联邦多智能体强化学习框架Fed-MARL，用于6G超密集边缘网络中的隐私保护、实时资源管理，通过跨层协调和加密聚合协议实现高效能效和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 6G网络向超密集智能边缘环境发展，需要在严格隐私、移动性和能耗约束下实现高效资源管理，传统集中式方法难以满足这些需求。

Method: 使用深度循环Q网络(DRQN)让每个智能体基于本地观测学习去中心化策略，包括任务卸载、频谱接入和CPU能耗调整。采用椭圆曲线Diffie-Hellman密钥交换的安全聚合协议保护隐私。将问题建模为部分可观测多智能体马尔可夫决策过程。

Result: 仿真结果表明Fed-MARL在任务成功率、延迟、能效和公平性方面优于集中式MARL和启发式基线方法，同时确保强大的隐私保护和动态6G边缘网络的可扩展性。

Conclusion: Fed-MARL框架为6G边缘网络提供了一种有效的隐私保护资源管理解决方案，能够同时优化延迟、能效、频谱效率、公平性和可靠性，满足URLLC、eMBB和mMTC等6G特定服务需求。

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [129] [A Symmetry-Integrated Approach to Surface Code Decoding](https://arxiv.org/abs/2509.10164)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: cs.LG

TL;DR: 提出一种通过神经网络插值近似症状测量的技术来重新优化表面码解码器，将解码问题重构为回归问题，提高了各种神经网络架构的解码精度


<details>
  <summary>Details</summary>
Motivation: 量子纠错中表面码解码器面临正确预测非唯一性问题，传统方法只能获取误差概率分布，需要改进解码精度

Method: 使用神经网络数学插值近似连续函数来模拟症状测量，重新优化解码器模型，将解码问题转化为回归问题

Result: 在码距5和7的多层感知机解码器，以及码距5的卷积神经网络、循环神经网络和Transformer解码器上，重新优化的解码器都获得了比原始模型更好的精度

Conclusion: 将表面码解码问题重新构建为可通过深度学习处理的回归问题是一个有效的策略，该方法具有普适性，不受码距或网络架构影响

Abstract: Quantum error correction, which utilizes logical qubits that are encoded as
redundant multiple physical qubits to find and correct errors in physical
qubits, is indispensable for practical quantum computing. Surface code is
considered to be a promising encoding method with a high error threshold that
is defined by stabilizer generators. However, previous methods have suffered
from the problem that the decoder acquires solely the error probability
distribution because of the non-uniqueness of correct prediction obtained from
the input. To circumvent this problem, we propose a technique to reoptimize the
decoder model by approximating syndrome measurements with a continuous function
that is mathematically interpolated by neural network. We evaluated the
improvement in accuracy of a multilayer perceptron based decoder for code
distances of 5 and 7 as well as for decoders based on convolutional and
recurrent neural networks and transformers for a code distance of 5. In all
cases, the reoptimized decoder gave better accuracy than the original models,
demonstrating the universal effectiveness of the proposed method that is
independent of code distance or network architecture. These results suggest
that re-framing the problem of surface code decoding into a regression problem
that can be tackled by deep learning is a useful strategy.

</details>


### [130] [The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams](https://arxiv.org/abs/2509.10167)
*Lénaïc Chizat*

Main category: cs.LG

TL;DR: 该论文研究了深度残差网络的梯度训练动态，证明了当深度趋于无穷时，训练动态收敛到神经平均ODE，并分析了不同缩放参数下的特征学习行为。


<details>
  <summary>Details</summary>
Motivation: 研究深度残差网络在标准随机初始化下的训练动态，特别是当网络深度趋于无穷时的极限行为，以及不同参数缩放对特征学习的影响。

Method: 通过数学分析证明深度残差网络的训练动态收敛到平均ODE，使用传播混沌理论分析单元间的渐近独立性，并通过实验验证理论结果的紧致性。

Result: 获得了模型输出与极限之间的误差界O(1/L + α/√(LM))，证明了当α=Θ(1)时实现完全特征学习，而α→∞时进入懒惰ODE机制。对于两层感知器块，确定了实现完全特征学习的唯一残差缩放Θ(√D/(LM))。

Conclusion: 深度残差网络的训练动态在深度趋于无穷时收敛到平均ODE，不同的参数缩放导致不同的特征学习行为，为理解深度网络训练提供了新的数学视角。

Abstract: We study the gradient-based training of large-depth residual networks
(ResNets) from standard random initializations. We show that with a diverging
depth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,
the training dynamics converges to a Neural Mean ODE training dynamics.
Remarkably, the limit is independent of the scaling of $M$, covering practical
cases of, say, Transformers, where $M$ (the number of hidden units or attention
heads per layer) is typically of the order of $D$. For a residual scale
$\Theta_D\big(\frac{\alpha}{LM}\big)$, we obtain the error bound
$O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$ between the model's output
and its limit after a fixed number gradient of steps, and we verify empirically
that this rate is tight. When $\alpha=\Theta(1)$, the limit exhibits complete
feature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In
contrast, we show that $\alpha \to \infty$ yields a \lazy ODE regime where the
Mean ODE is linearly parameterized. We then focus on the particular case of
ResNets with two-layer perceptron blocks, for which we study how these scalings
depend on the embedding dimension $D$. We show that for this model, the only
residual scale that leads to complete feature learning is
$\Theta\big(\frac{\sqrt{D}}{LM}\big)$. In this regime, we prove the error bound
$O\big(\frac{1}{L}+ \frac{\sqrt{D}}{\sqrt{LM}}\big)$ between the ResNet and its
limit after a fixed number of gradient steps, which is also empirically tight.
Our convergence results rely on a novel mathematical perspective on ResNets :
(i) due to the randomness of the initialization, the forward and backward pass
through the ResNet behave as the stochastic approximation of certain mean ODEs,
and (ii) by propagation of chaos (that is, asymptotic independence of the
units) this behavior is preserved through the training dynamics.

</details>


### [131] [P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context](https://arxiv.org/abs/2509.10186)
*Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出了一个可扩展的框架，用于学习高分辨率3D物理模拟的确定性和概率性神经代理模型，采用混合CNN-Transformer架构，在速度和准确性上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决高分辨率3D物理模拟中计算成本高、内存需求大的问题，需要开发高效的神经代理模型来替代传统的数值模拟方法。

Method: 引入混合CNN-Transformer骨干架构，支持在小块模拟域上进行预训练，然后融合获得全局解，可选地通过序列到序列模型包含长程依赖关系。

Result: 在14种不同类型3D PDE动力学学习中显著优于基线方法，可扩展到512^3空间分辨率的高分辨率各向同性湍流，并能作为扩散模型生成不同雷诺数下高度湍流3D通道流的概率样本。

Conclusion: 该框架为高分辨率3D物理模拟提供了一种高效、可扩展的神经代理解决方案，在保持准确性的同时大幅降低了计算和内存需求。

Abstract: We present a scalable framework for learning deterministic and probabilistic
neural surrogates for high-resolution 3D physics simulations. We introduce a
hybrid CNN-Transformer backbone architecture targeted for 3D physics
simulations, which significantly outperforms existing architectures in terms of
speed and accuracy. Our proposed network can be pretrained on small patches of
the simulation domain, which can be fused to obtain a global solution,
optionally guided via a fast and scalable sequence-to-sequence model to include
long-range dependencies. This setup allows for training large-scale models with
reduced memory and compute requirements for high-resolution datasets. We
evaluate our backbone architecture against a large set of baseline methods with
the objective to simultaneously learn the dynamics of 14 different types of
PDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic
turbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate
the versatility of our network by training it as a diffusion model to produce
probabilistic samples of highly turbulent 3D channel flows across varying
Reynolds numbers, accurately capturing the underlying flow statistics.

</details>


### [132] [Hadamard-Riemannian Optimization for Margin-Variance Ensemble](https://arxiv.org/abs/2509.10189)
*Zexu Jin*

Main category: cs.LG

TL;DR: 提出了一种新的集成学习框架，通过将边际方差显式纳入损失函数，联合优化负期望边际和边际方差，从而提高模型的鲁棒性和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于边际的集成方法主要关注最大化期望边际而忽略边际方差的重要性，这限制了模型的泛化能力并增加了过拟合风险，特别是在噪声或不平衡数据集中。同时，传统方法在概率单纯形上优化集成权重存在计算效率低和可扩展性差的问题。

Method: 通过将边际方差显式纳入损失函数，联合优化负期望边际和边际方差；通过将集成权重重新参数化到单位球面上，简化优化过程并提高计算效率。

Result: 在多个基准数据集上的广泛实验表明，该方法始终优于传统的基于边际的集成技术。

Conclusion: 所提出的方法通过显式考虑边际方差和优化权重参数化，有效提高了集成学习的鲁棒性和泛化性能，具有实际应用价值。

Abstract: Ensemble learning has been widely recognized as a pivotal technique for
boosting predictive performance by combining multiple base models.
Nevertheless, conventional margin-based ensemble methods predominantly focus on
maximizing the expected margin while neglecting the critical role of margin
variance, which inherently restricts the generalization capability of the model
and heightens its vulnerability to overfitting, particularly in noisy or
imbalanced datasets. Additionally, the conventional approach of optimizing
ensemble weights within the probability simplex often introduces computational
inefficiency and scalability challenges, complicating its application to
large-scale problems. To tackle these limitations, this paper introduces a
novel ensemble learning framework that explicitly incorporates margin variance
into the loss function. Our method jointly optimizes the negative expected
margin and its variance, leading to enhanced robustness and improved
generalization performance. Moreover, by reparameterizing the ensemble weights
onto the unit sphere, we substantially simplify the optimization process and
improve computational efficiency. Extensive experiments conducted on multiple
benchmark datasets demonstrate that the proposed approach consistently
outperforms traditional margin-based ensemble techniques, underscoring its
effectiveness and practical utility.

</details>


### [133] [A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures](https://arxiv.org/abs/2509.10227)
*Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的飞机机翼疲劳寿命预测流程，通过飞行参数快速估算不同机翼位置的疲劳寿命，作为传统工程方法的补充。


<details>
  <summary>Details</summary>
Motivation: 传统疲劳寿命预测方法虽然可靠但耗时且流程复杂，需要多团队协作和大量计算资源。机器学习方法可以提供快速估算，指导决策并减少昂贵模拟的需求。

Method: 开发基于机器学习的预测流程，输入飞机不同任务的飞行参数，输出机翼各位置的疲劳寿命估计，并进行统计验证和不确定性量化。

Result: 在真实的疲劳寿命估计用例中验证了流程的有效性，获得了准确的预测结果。

Conclusion: 该机器学习流程是对传统方法的有效补充，能够显著减少计算资源和人力资源的需求，提高预测效率。

Abstract: Fatigue life prediction is essential in both the design and operational
phases of any aircraft, and in this sense safety in the aerospace industry
requires early detection of fatigue cracks to prevent in-flight failures.
Robust and precise fatigue life predictors are thus essential to ensure safety.
Traditional engineering methods, while reliable, are time consuming and involve
complex workflows, including steps such as conducting several Finite Element
Method (FEM) simulations, deriving the expected loading spectrum, and applying
cycle counting techniques like peak-valley or rainflow counting. These steps
often require collaboration between multiple teams and tools, added to the
computational time and effort required to achieve fatigue life predictions.
Machine learning (ML) offers a promising complement to traditional fatigue life
estimation methods, enabling faster iterations and generalization, providing
quick estimates that guide decisions alongside conventional simulations.
  In this paper, we present a ML-based pipeline that aims to estimate the
fatigue life of different aircraft wing locations given the flight parameters
of the different missions that the aircraft will be operating throughout its
operational life. We validate the pipeline in a realistic use case of fatigue
life estimation, yielding accurate predictions alongside a thorough statistical
validation and uncertainty quantification. Our pipeline constitutes a
complement to traditional methodologies by reducing the amount of costly
simulations and, thereby, lowering the required computational and human
resources.

</details>


### [134] [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](https://arxiv.org/abs/2509.10248)
*Janis Keuper*

Main category: cs.LG

TL;DR: 本文通过系统评估发现：简单的提示词注入攻击在LLM科学评审中高度有效（可达100%接受率），且LLM评审普遍存在接受偏向（>95%）。这些发现对LLM在同行评审中的使用讨论具有重要影响。


<details>
  <summary>Details</summary>
Motivation: 针对作者使用隐藏提示词注入操纵评审分数的报道，研究这种攻击的可行性和技术成功率，以影响关于LLM在科学同行评审中使用的持续讨论。

Method: 使用多种LLM对2024年ICLR论文的1000篇评审进行系统评估，测试简单提示词注入的有效性。

Result: 1) 非常简单提示词注入高度有效，达到100%接受率；2) LLM评审普遍偏向接受（许多模型>95%接受率）。

Conclusion: 研究结果对LLM在同行评审中的使用讨论具有重大影响，揭示了系统漏洞和固有偏见。

Abstract: The ongoing intense discussion on rising LLM usage in the scientific
peer-review process has recently been mingled by reports of authors using
hidden prompt injections to manipulate review scores. Since the existence of
such "attacks" - although seen by some commentators as "self-defense" - would
have a great impact on the further debate, this paper investigates the
practicability and technical success of the described manipulations. Our
systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide
range of LLMs shows two distinct results: I) very simple prompt injections are
indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews
are generally biased toward acceptance (>95% in many models). Both results have
great impact on the ongoing discussions on LLM usage in peer-review.

</details>


### [135] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 提出了一个基于神经推荐系统的迁移学习框架，利用COSMO-RS模拟数据和稀疏实验数据，准确预测离子液体的五种关键热物理性质。


<details>
  <summary>Details</summary>
Motivation: 离子液体具有可定制的物理化学性质，但由于化学设计空间巨大和实验数据有限，准确预测其热物理性质仍然具有挑战性。

Method: 采用两阶段方法：首先在固定温度压力下使用COSMO-RS模拟数据预训练神经推荐系统模型，学习阳离子和阴离子的性质特异性结构嵌入；然后使用这些嵌入和不同温度压力下的实验数据微调简单前馈神经网络。

Result: 该框架支持性质内和跨性质知识迁移，预训练的密度、粘度和热容模型用于微调所有五个目标性质模型，其中四个性质的性能显著提升。模型对未见过的离子液体表现出良好的外推能力，可为超过70万种离子液体组合提供性质预测。

Conclusion: 这项工作展示了结合模拟数据和迁移学习来克服实验数据稀疏性的有效性，为离子液体筛选提供了可扩展的解决方案。

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [136] [Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case](https://arxiv.org/abs/2509.10291)
*Salih Toprak,Muge Erel-Ozcevik*

Main category: cs.LG

TL;DR: 提出一种基于SDN和AutoML的区块链安全能源交易架构，利用机器学习回归模型生成随机数作为nonce，称为Proof of AutoML，特别适用于灾难场景下的能源交易安全。


<details>
  <summary>Details</summary>
Motivation: 在灾难场景中传统能源基础设施受损时，需要确保太阳能家庭与移动充电单元之间能源交易的安全性和可追溯性，而区块链网络需要强大的随机nonce生成机制。

Method: 采用SDN架构实现灵活的数据流和能源路由控制，利用五种AutoML选择的回归模型（梯度提升、LightGBM、随机森林、额外树和K近邻）生成随机nonce值，通过9000样本数据集评估模型的随机性而非预测精度。

Result: 随机性分析显示随机森林和额外树回归器表现出完全的随机依赖性，梯度提升、K近邻和LightGBM的随机性得分分别为97.6%、98.8%和99.9%，表明树基集成模型适合作为轻量级nonce生成器。

Conclusion: 某些机器学习模型，特别是树基集成方法，可以作为有效的轻量级nonce生成器，用于构建抗灾难的区块链安全SDN能源交易基础设施。

Abstract: In disaster scenarios where conventional energy infrastructure is
compromised, secure and traceable energy trading between solar-powered
households and mobile charging units becomes a necessity. To ensure the
integrity of such transactions over a blockchain network, robust and
unpredictable nonce generation is vital. This study proposes an SDN-enabled
architecture where machine learning regressors are leveraged not for their
accuracy, but for their potential to generate randomized values suitable as
nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN
allows flexible control over data flows and energy routing policies even in
fragmented or degraded networks, ensuring adaptive response during emergencies.
Using a 9000-sample dataset, we evaluate five AutoML-selected regression models
- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest
Neighbors - not by their prediction accuracy, but by their ability to produce
diverse and non-deterministic outputs across shuffled data inputs. Randomness
analysis reveals that Random Forest and Extra Trees regressors exhibit complete
dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and
LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and
99.9%, respectively). These findings highlight that certain machine learning
models, particularly tree-based ensembles, may serve as effective and
lightweight nonce generators within blockchain-secured, SDN-based energy
trading infrastructures resilient to disaster conditions.

</details>


### [137] [Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data](https://arxiv.org/abs/2509.10303)
*Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang*

Main category: cs.LG

TL;DR: 提出CDQAC离线强化学习算法，直接从历史数据学习作业车间调度策略，无需在线交互，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统在线RL方法需要大量模拟环境交互且样本效率低，无法捕捉真实世界复杂性，需要直接从历史数据学习调度策略的离线方法

Method: CDQAC算法结合分位数critic和延迟策略更新，估计每个机器-操作对的回报分布而非直接选择，可直接从历史数据学习

Result: CDQAC显著优于原始数据生成启发式方法，超越最先进的离线和在线RL基线，仅需10-20个训练实例即可学习高质量策略

Conclusion: CDQAC是高效的离线RL调度方法，能从低质量随机数据中学习到比高质量数据更好的策略，具有出色的样本效率和实际应用价值

Abstract: The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.

</details>


### [138] [GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](https://arxiv.org/abs/2509.10308)
*Joshua Dimasaka,Christian Geiß,Robert Muir-Wood,Emily So*

Main category: cs.LG

TL;DR: 提出了GraphCSVAE框架，通过深度学习和图表示方法建模灾害物理脆弱性，填补了灾害风险评估中物理脆弱性建模的空白


<details>
  <summary>Details</summary>
Motivation: 现有灾害风险评估主要关注灾害和暴露度建模，但物理脆弱性建模进展有限，限制了决策者对联合国仙台框架进展的评估能力

Method: GraphCSVAE概率数据驱动框架，整合深度学习、图表示和分类概率推理，使用时序卫星数据和专家先验知识，引入弱监督一阶转移矩阵

Result: 在孟加拉国飓风影响社区和塞拉利昂泥石流影响城市成功揭示了灾后物理脆弱性的区域动态变化

Conclusion: 该框架为局部时空审计和灾后风险减少的可持续策略提供了宝贵见解，推动了物理脆弱性建模的发展

Abstract: In the aftermath of disasters, many institutions worldwide face challenges in
continually monitoring changes in disaster risk, limiting the ability of key
decision-makers to assess progress towards the UN Sendai Framework for Disaster
Risk Reduction 2015-2030. While numerous efforts have substantially advanced
the large-scale modeling of hazard and exposure through Earth observation and
data-driven methods, progress remains limited in modeling another equally
important yet challenging element of the risk equation: physical vulnerability.
To address this gap, we introduce Graph Categorical Structured Variational
Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for
modeling physical vulnerability by integrating deep learning, graph
representation, and categorical probabilistic inference, using time-series
satellite-derived datasets and prior expert belief systems. We introduce a
weakly supervised first-order transition matrix that reflects the changes in
the spatiotemporal distribution of physical vulnerability in two
disaster-stricken and socioeconomically disadvantaged areas: (1) the
cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the
mudslide-affected city of Freetown in Sierra Leone. Our work reveals
post-disaster regional dynamics in physical vulnerability, offering valuable
insights into localized spatiotemporal auditing and sustainable strategies for
post-disaster risk reduction.

</details>


### [139] [ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](https://arxiv.org/abs/2509.10324)
*Myung Jin Kim,YeongHyeon Park,Il Dong Yun*

Main category: cs.LG

TL;DR: 提出基于ARIMA模型启发的简单卷积模块ARMA，用于长期时间序列预测，包含趋势捕捉和局部变化修正两个卷积组件，可直接进行多步预测


<details>
  <summary>Details</summary>
Motivation: 传统ARIMA模型需要迭代多步预测且难以扩展到多变量设置，需要一种简单有效的长期时间序列预测方法

Method: 设计双卷积组件模块：一个卷积用于捕捉趋势（自回归），另一个用于精炼局部变化（移动平均），可直接进行多步预测

Result: 在9个基准数据集上达到竞争性精度，特别在具有强趋势变化的数据集上表现优异，同时保持架构简单性

Conclusion: ARMA模块不仅实现了有效的长期时间序列预测，还天然编码了绝对位置信息，有潜力作为序列模型中位置嵌入的轻量级替代方案

Abstract: This paper proposes a simple yet effective convolutional module for long-term
time series forecasting. The proposed block, inspired by the Auto-Regressive
Integrated Moving Average (ARIMA) model, consists of two convolutional
components: one for capturing the trend (autoregression) and the other for
refining local variations (moving average). Unlike conventional ARIMA, which
requires iterative multi-step forecasting, the block directly performs
multi-step forecasting, making it easily extendable to multivariate settings.
Experiments on nine widely used benchmark datasets demonstrate that our method
ARMA achieves competitive accuracy, particularly on datasets exhibiting strong
trend variations, while maintaining architectural simplicity. Furthermore,
analysis shows that the block inherently encodes absolute positional
information, suggesting its potential as a lightweight replacement for
positional embeddings in sequential models.

</details>


### [140] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于结构保持数字孪生的自适应源定位机器学习框架，结合条件神经Whitney形式和Transformer算子学习，实现实时数据同化和轨迹规划


<details>
  <summary>Details</summary>
Motivation: 解决复杂流体输运系统中源定位问题，传统方法在复杂几何形状下精度不足，需要物理约束保持的结构保持模型来提高识别准确性

Method: 使用条件神经Whitney形式(CNWF)构建数字孪生，耦合有限元外微积分(FEEC)和Transformer算子学习，采用交错方案交替评估数字孪生和应用Lloyd算法指导传感器布局

Result: 在复杂几何形状下比物理无关的Transformer架构精度更高，能够恢复连续假设下的点源，证明了正则性作为定位的充分条件

Conclusion: 结构保持为源识别提供了有效的归纳偏置，物理约束的强制执行在复杂几何中提高了准确性，该方法保持了标准有限元模拟的稳定性和一致性

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


### [141] [A Discrepancy-Based Perspective on Dataset Condensation](https://arxiv.org/abs/2509.10367)
*Tong Chen,Raghavendra Selvan*

Main category: cs.LG

TL;DR: 本文提出了一个统一框架来形式化数据集压缩问题，将传统基于泛化性能的方法扩展到包含鲁棒性、隐私性等多目标优化。


<details>
  <summary>Details</summary>
Motivation: 现有数据集压缩方法主要关注泛化性能，缺乏统一的理论框架。作者希望建立一个更通用的形式化定义，能够涵盖多种优化目标。

Method: 使用差异度概念来量化概率分布之间的距离，构建统一框架来包含现有DC方法，并将任务扩展到多目标优化。

Result: 提出了一个理论框架，能够统一现有数据集压缩方法，并支持鲁棒性、隐私性等额外目标的优化。

Conclusion: 该框架为数据集压缩提供了更严格的理论基础，扩展了其应用范围，使其能够处理多种实际需求。

Abstract: Given a dataset of finitely many elements $\mathcal{T} = \{\mathbf{x}_i\}_{i
= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic
dataset $\mathcal{S} = \{\tilde{\mathbf{x}}_j\}_{j = 1}^M$ which is
significantly smaller ($M \ll N$) such that a model trained from scratch on
$\mathcal{S}$ achieves comparable or even superior generalization performance
to a model trained on $\mathcal{T}$. Recent advances in DC reveal a close
connection to the problem of approximating the data distribution represented by
$\mathcal{T}$ with a reduced set of points. In this work, we present a unified
framework that encompasses existing DC methods and extend the task-specific
notion of DC to a more general and formal definition using notions of
discrepancy, which quantify the distance between probability distribution in
different regimes. Our framework broadens the objective of DC beyond
generalization, accommodating additional objectives such as robustness,
privacy, and other desirable properties.

</details>


### [142] [Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms](https://arxiv.org/abs/2509.10369)
*Gul Rukh Khattak,Konstantinos Patlatzoglou,Joseph Barker,Libor Pastika,Boroumand Zeidaabadi,Ahmed El-Medany,Hesham Aggour,Yixiu Liang,Antonio H. Ribeiro,Jeffrey Annis,Antonio Luiz Pinho Ribeiro,Junbo Ge,Daniel B. Kramer,Jonathan W. Waks,Evan Brittain,Nicholas Peters,Fu Siong Ng,Arunashis Sau*

Main category: cs.LG

TL;DR: 对比学习在ECG预训练中，队列组成影响下游性能，多中心多样化队列提升分布内准确性但降低OOD泛化，提出IDB策略增强鲁棒性


<details>
  <summary>Details</summary>
Motivation: 探索对比学习在自监督预训练中对队列组成的依赖性，特别是不同人群、健康状况和人口多样性对下游心电图预测任务性能的影响

Method: 提出CAPE基础模型，在四大洲5,203,352例心电图上预训练，系统评估队列特征对性能的影响，并开发In-Distribution Batch (IDB)策略来保持队列内一致性

Result: 下游性能取决于预训练队列的分布特性，多样化队列提升分布内准确性但编码队列特异性伪影，降低OOD泛化能力

Conclusion: IDB策略能增强OOD鲁棒性，为开发临床公平和可泛化的基础模型提供重要见解

Abstract: Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.

</details>


### [143] [Flow Straight and Fast in Hilbert Space: Functional Rectified Flow](https://arxiv.org/abs/2509.10384)
*Jianxin Zhang,Clayton Scott*

Main category: cs.LG

TL;DR: 本文提出了无限维希尔伯特空间中整流流的严格函数化表述，建立了基于连续性方程叠加原理的理论框架，并扩展至函数流匹配和概率流ODE，在实验中展现出优于现有函数生成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 许多在有限维欧几里得空间中开发的生成模型在无限维设置中具有函数化推广，但整流流向无限维空间的扩展尚未被探索。

Method: 基于无限维空间中连续性方程的叠加原理，建立了整流流的严格函数化表述框架，并将其自然扩展到函数流匹配和函数概率流ODE，作为整流流的非线性推广。

Result: 实验证明该方法相比现有函数生成模型具有更优越的性能，同时移除了现有函数流匹配理论中的限制性测度理论假设。

Conclusion: 成功建立了无限维希尔伯特空间中整流流的函数化理论框架，为函数生成模型提供了新的理论基础和实践方法，在性能和理论完备性方面都有显著提升。

Abstract: Many generative models originally developed in finite-dimensional Euclidean
space have functional generalizations in infinite-dimensional settings.
However, the extension of rectified flow to infinite-dimensional spaces remains
unexplored. In this work, we establish a rigorous functional formulation of
rectified flow in an infinite-dimensional Hilbert space. Our approach builds
upon the superposition principle for continuity equations in an
infinite-dimensional space. We further show that this framework extends
naturally to functional flow matching and functional probability flow ODEs,
interpreting them as nonlinear generalizations of rectified flow. Notably, our
extension to functional flow matching removes the restrictive measure-theoretic
assumptions in the existing theory of \citet{kerrigan2024functional}.
Furthermore, we demonstrate experimentally that our method achieves superior
performance compared to existing functional generative models.

</details>


### [144] [Vendi Information Gain for Active Learning and its Application to Ecology](https://arxiv.org/abs/2509.10390)
*Quan Nguyen,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 提出Vendi信息增益(VIG)主动学习策略，通过考虑数据集整体预测不确定性来选择图像，在Snapshot Serengeti数据集上仅使用不到10%的标签就达到了接近全监督的预测精度。


<details>
  <summary>Details</summary>
Motivation: 解决相机陷阱生物多样性监测中物种识别标签资源有限的问题，传统主动学习方法只关注个体预测不确定性而忽略数据集整体不确定性。

Method: 引入Vendi信息增益(VIG)主动学习策略，选择能最大程度减少数据集整体预测不确定性的图像，同时考虑信息量和多样性。

Result: 在Snapshot Serengeti数据集上，VIG使用不到10%的标签就达到了接近全监督的预测精度，在各种指标和批次大小下均优于标准基线方法，并在特征空间中收集了更多样化的数据。

Conclusion: VIG策略在数据有限的环境中具有广泛适用性，对生物多样性监测具有重要价值，能够有效解决标签资源有限的问题。

Abstract: While monitoring biodiversity through camera traps has become an important
endeavor for ecological research, identifying species in the captured image
data remains a major bottleneck due to limited labeling resources. Active
learning -- a machine learning paradigm that selects the most informative data
to label and train a predictive model -- offers a promising solution, but
typically focuses on uncertainty in the individual predictions without
considering uncertainty across the entire dataset. We introduce a new active
learning policy, Vendi information gain (VIG), that selects images based on
their impact on dataset-wide prediction uncertainty, capturing both
informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG
achieves impressive predictive accuracy close to full supervision using less
than 10% of the labels. It consistently outperforms standard baselines across
metrics and batch sizes, collecting more diverse data in the feature space. VIG
has broad applicability beyond ecology, and our results highlight its value for
biodiversity monitoring in data-limited environments.

</details>


### [145] [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://arxiv.org/abs/2509.10396)
*Siyan Zhao,Mengchen Liu,Jing Huang,Miao Liu,Chenyu Wang,Bo Liu,Yuandong Tian,Guan Pang,Sean Bell,Aditya Grover,Feiyu Chen*

Main category: cs.LG

TL;DR: IGPO是一个针对掩码扩散大语言模型的强化学习框架，利用inpainting能力指导探索，通过插入部分真实推理轨迹来提升样本效率和性能


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在LLM对齐中的探索挑战，包括稀疏奖励信号和样本浪费问题，利用dLLM独特的inpainting能力来指导探索

Method: 提出IGPO框架，在在线采样时策略性地插入部分真实推理轨迹，结合监督微调使用合成重写的简洁轨迹，并采用基于熵的过滤等技术

Result: 在GSM8K、Math500和AMC三个数学基准测试中取得显著提升，为全注意力掩码dLLM实现了新的最先进结果

Conclusion: IGPO成功地将inpainting能力与强化学习相结合，有效解决了探索效率问题，为dLLM的RL对齐提供了新的有效方法

Abstract: Masked diffusion large language models (dLLMs) are emerging as promising
alternatives to autoregressive LLMs, offering competitive performance while
supporting unique generation capabilities such as inpainting. We explore how
inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with
reinforcement learning faces an exploration challenge: sparse reward signals
and sample waste when models fail to discover correct solutions. While this
inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their
inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided
Policy Optimization), an RL framework that strategically inserts partial
ground-truth reasoning traces during online sampling. Unlike providing full
solutions, inpainting steers exploration toward promising trajectory spaces
while preserving self-generated reasoning, bridging supervised fine-tuning and
reinforcement learning. We apply IGPO to group-based optimization methods such
as GRPO, where exploration failures cause zero advantages and gradients. IGPO
restores meaningful gradients while improving sample efficiency. We also
propose supervised fine-tuning on synthetically rewritten concise traces that
better align with dLLM generation patterns. With additional techniques
including entropy-based filtering, our training recipe yields substantial gains
across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new
state-of-the-art results for full-attention masked dLLMs.

</details>


### [146] [Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining](https://arxiv.org/abs/2509.10406)
*Rupert Mitchell,Kristian Kersting*

Main category: cs.LG

TL;DR: MuSe是一种高效的注意力机制近似方法，通过语义聚类和多极展开技术降低Transformer的二次计算复杂度，在保持性能的同时显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer中softmax注意力机制的二次计算复杂度问题，特别是在处理长序列时计算成本过高的问题。

Method: 结合语义聚类和计算物理中的多极展开技术，对查询和键进行独立聚类，采用分层两阶段注意力机制，并引入偶极校正来捕捉聚类内的方向方差。

Result: 在8k上下文长度下比CUDNN Flash Attention快3倍，相对平方误差低于20%；在30M参数模型上预训练时实现12.2%的运行时间减少，性能损失仅为0.36%。

Conclusion: 多极近似方法为高效Transformer预训练提供了可行的解决方案，在保持模型性能的同时显著降低了计算成本。

Abstract: We present Multipole Semantic Attention (MuSe), an efficient approximation of
softmax attention that combines semantic clustering with multipole expansions
from computational physics. Our method addresses the quadratic computational
complexity of transformers in the context length by clustering queries and keys
separately in their learned representation spaces, enabling a hierarchical
two-stage attention mechanism. Unlike prior clustering approaches that group
only keys or use unified clustering, we maintain separate clusterings that
respect attention's asymmetric treatment of these spaces. We augment
centroid-based (monopole) approximations with dipole corrections that capture
directional variance within clusters, preserving richer information during
training. The method operates as a drop-in replacement for standard attention,
requiring only hyperparameter specification without architectural
modifications. Our approach achieves $\mathcal{O}(NCD)$ complexity for acausal
attention with $C$ clusters and $\mathcal{O}(NCD \log N)$ for causal attention.
On isolated attention layers, we demonstrate $3\times$ speedup over CUDNN Flash
Attention at 8k context length, with relative squared errors below 20%. For
causal attention, we develop a hierarchical block decomposition that combines
exact local computation with efficient long-range approximation. In end-to-end
pretraining of a 30M parameter model on book-length texts with 16k context, we
achieve 12.2% runtime reduction with only 0.36% loss degradation, establishing
the viability of multipole approximations for efficient transformer
pretraining.

</details>


### [147] [Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining](https://arxiv.org/abs/2509.10419)
*Francesco Vitale,Tommaso Zoppi,Francesco Flammini,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 使用过程挖掘和机器学习进行铁路系统运行时控制流异常检测与定位


<details>
  <summary>Details</summary>
Motivation: 随着铁路系统复杂性和关键性增加，需要增强系统韧性来应对设计时未知的运行时异常、残余故障和网络威胁

Method: 采用过程挖掘从执行轨迹学习实际控制流，通过在线一致性检查进行运行时监控，并使用无监督机器学习进行异常定位

Result: 在ERTMS/ETCS L2 RBC/RBC交接参考场景中测试，显示出高精度、高效性和可解释性的异常检测与定位能力

Conclusion: 过程挖掘结合机器学习为铁路控制系统提供了有效的运行时异常检测和定位解决方案，增强了系统韧性

Abstract: Ensuring the resilience of computer-based railways is increasingly crucial to
account for uncertainties and changes due to the growing complexity and
criticality of those systems. Although their software relies on strict
verification and validation processes following well-established best-practices
and certification standards, anomalies can still occur at run-time due to
residual faults, system and environmental modifications that were unknown at
design-time, or other emergent cyber-threat scenarios. This paper explores
run-time control-flow anomaly detection using process mining to enhance the
resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European
Train Control System Level 2). Process mining allows learning the actual
control flow of the system from its execution traces, thus enabling run-time
monitoring through online conformance checking. In addition, anomaly
localization is performed through unsupervised machine learning to link
relevant deviations to critical system components. We test our approach on a
reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its
capability to detect and localize anomalies with high accuracy, efficiency, and
explainability.

</details>


### [148] [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](https://arxiv.org/abs/2509.10439)
*Ahmed Khaled,Satyen Kale,Arthur Douillard,Chi Jin,Rob Fergus,Manzil Zaheer*

Main category: cs.LG

TL;DR: 本文研究了Local SGD中外部优化器的作用，证明了新的收敛保证，发现调整外部学习率可以在优化误差和随机梯度噪声方差之间权衡，并弥补内部学习率的不良调整。理论表明外部学习率有时应大于1，并扩展到动量、加速优化器的情况。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习需要大规模分布式训练，通信成为主要瓶颈。Local SGD能减少通信开销，但现有研究主要关注本地优化过程的超参数，而外部优化器及其超参数的选择不够明确。

Method: 通过理论分析证明Local SGD的收敛性，研究外部学习率的作用机制，扩展到动量优化器和加速优化器，并提出数据依赖的分析方法。使用标准语言模型进行实验验证。

Result: 理论证明调整外部学习率可以权衡优化误差和噪声方差，弥补内部学习率调整不当。动量调整的外部学习率有类似作用，加速优化器能改善通信轮次相关的收敛速率。实验验证了理论发现。

Conclusion: 外部优化器在Local SGD中起关键作用，适当设置外部学习率（有时大于1）能显著提升性能，动量加速技术能进一步改善收敛效率，为分布式训练提供了重要指导。

Abstract: Modern machine learning often requires training with large batch size,
distributed data, and massively parallel compute hardware (like mobile and
other edge devices or distributed data centers). Communication becomes a major
bottleneck in such settings but methods like Local Stochastic Gradient Descent
(Local SGD) show great promise in reducing this additional communication
overhead. Local SGD consists of three parts: a local optimization process, an
aggregation mechanism, and an outer optimizer that uses the aggregated updates
from the nodes to produce a new model. While there exists an extensive
literature on understanding the impact of hyperparameters in the local
optimization process, the choice of outer optimizer and its hyperparameters is
less clear. We study the role of the outer optimizer in Local SGD, and prove
new convergence guarantees for the algorithm. In particular, we show that
tuning the outer learning rate allows us to (a) trade off between optimization
error and stochastic gradient noise variance, and (b) make up for ill-tuning of
the inner learning rate. Our theory suggests that the outer learning rate
should sometimes be set to values greater than $1$. We extend our results to
settings where we use momentum in the outer optimizer, and we show a similar
role for the momentum-adjusted outer learning rate. We also study acceleration
in the outer optimizer and show that it improves the convergence rate as a
function of the number of communication rounds, improving upon the convergence
rate of prior algorithms that apply acceleration locally. Finally, we also
introduce a novel data-dependent analysis of Local SGD that yields further
insights on outer learning rate tuning. We conduct comprehensive experiments
with standard language models and various outer optimizers to validate our
theory.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [149] [MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos](https://arxiv.org/abs/2509.09769)
*Rutav Shah,Shuijing Liu,Qi Wang,Zhenyu Jiang,Sateesh Kumar,Mingyo Seo,Roberto Martín-Martín,Yuke Zhu*

Main category: cs.RO

TL;DR: MimicDroid是一个利用人类游戏视频作为唯一训练数据，让人形机器人通过上下文学习从少量视频示例中快速适应新操作任务的系统


<details>
  <summary>Details</summary>
Motivation: 解决当前上下文学习方法依赖劳动密集型遥操作数据的问题，利用人类游戏视频作为可扩展和多样化的训练数据源

Method: 从人类游戏视频中提取具有相似操作行为的轨迹对，训练策略预测一个轨迹的动作条件于另一个轨迹；通过人体手腕姿态重定向和随机补丁掩码来弥合实体差异

Result: 在模拟基准测试中优于最先进方法，在现实世界中实现了近两倍的成功率

Conclusion: 人类游戏视频是训练人形机器人上下文学习能力的有效数据源，MimicDroid展示了从非结构化视频数据中学习操作技能的可行性

Abstract: We aim to enable humanoid robots to efficiently solve new manipulation tasks
from a few video examples. In-context learning (ICL) is a promising framework
for achieving this goal due to its test-time data efficiency and rapid
adaptability. However, current ICL methods rely on labor-intensive teleoperated
data for training, which restricts scalability. We propose using human play
videos -- continuous, unlabeled videos of people interacting freely with their
environment -- as a scalable and diverse training data source. We introduce
MimicDroid, which enables humanoids to perform ICL using human play videos as
the only training data. MimicDroid extracts trajectory pairs with similar
manipulation behaviors and trains the policy to predict the actions of one
trajectory conditioned on the other. Through this process, the model acquired
ICL capabilities for adapting to novel objects and environments at test time.
To bridge the embodiment gap, MimicDroid first retargets human wrist poses
estimated from RGB videos to the humanoid, leveraging kinematic similarity. It
also applies random patch masking during training to reduce overfitting to
human-specific cues and improve robustness to visual differences. To evaluate
few-shot learning for humanoids, we introduce an open-source simulation
benchmark with increasing levels of generalization difficulty. MimicDroid
outperformed state-of-the-art methods and achieved nearly twofold higher
success rates in the real world. Additional materials can be found on:
ut-austin-rpl.github.io/MimicDroid

</details>


### [150] [MIMo grows! Simulating body and sensory development in a multimodal infant model](https://arxiv.org/abs/2509.09805)
*Francisco M. López,Miles Lenz,Marco G. Fedozzi,Arthur Aubret,Jochen Triesch*

Main category: cs.RO

TL;DR: MIMo v2是一个多模态婴儿模型，通过模拟从出生到24个月的身体生长、运动能力发展、视觉发育和感觉运动延迟，提高了发育机器人建模的真实性。


<details>
  <summary>Details</summary>
Motivation: 现有的发育机器人和仿真平台通常针对特定年龄段设计，无法捕捉婴儿快速变化的身体能力和感觉运动约束。

Method: 开发了MIMo v2模型，包含：1）从出生到24个月的身体生长模型和运动强度增加；2）具有发展性视觉敏锐度的中央凹视觉；3）模拟信号传输延迟的感觉运动延迟；4）逆向运动学模块和随机环境生成器。

Result: 新版本的MIMo能够更真实地模拟各种感觉运动发展方面，并与第三方仿真和学习库保持更新兼容性。

Conclusion: MIMo v2为研究婴儿发育提供了更真实的仿真平台，代码已在官方仓库开源。

Abstract: Infancy is characterized by rapid body growth and an explosive change of
sensory and motor abilities. However, developmental robots and simulation
platforms are typically designed in the image of a specific age, which limits
their ability to capture the changing abilities and constraints of developing
infants. To address this issue, we present MIMo v2, a new version of the
multimodal infant model. It includes a growing body with increasing actuation
strength covering the age range from birth to 24 months. It also features
foveated vision with developing visual acuity as well as sensorimotor delays
modeling finite signal transmission speeds to and from an infant's brain.
Further enhancements of this MIMo version include an inverse kinematics module,
a random environment generator and updated compatiblity with third-party
simulation and learning libraries. Overall, this new MIMo version permits
increased realism when modeling various aspects of sensorimotor development.
The code is available on the official repository
(https://github.com/trieschlab/MIMo).

</details>


### [151] [Using the Pepper Robot to Support Sign Language Communication](https://arxiv.org/abs/2509.09889)
*Giulia Botta,Marco Botta,Cristina Gena,Alessandro Mazzei,Massimo Donini,Alberto Lillo*

Main category: cs.RO

TL;DR: 研究表明商业社交机器人Pepper能够生成可理解的意大利手语(LIS)手势，但完整句子识别率较低，需要多模态增强和参与式设计来改进


<details>
  <summary>Details</summary>
Motivation: 社交机器人在公共和辅助环境中应用日益增多，但对手语使用者的可访问性研究不足。意大利手语(LIS)作为成熟自然语言，需要复杂的手势和非手势组件，让机器人使用LIS交流可以促进更包容的人机交互

Method: 与聋人学生和LIS专家合作，通过手动动画技术和MATLAB逆向运动学求解器在Pepper机器人上实现了52个LIS手势。进行了探索性用户研究，12名熟练LIS使用者参与视频识别任务和开放性问题

Result: 大多数孤立手势被正确识别，但完整句子识别率显著较低，主要由于Pepper的有限关节活动能力和时间限制

Conclusion: 即使商业社交机器人如Pepper也能执行部分可理解的LIS手势，为更包容的交互设计提供机会。未来开发应解决多模态增强问题，并让聋人用户参与设计以改进机器人表现力和可用性

Abstract: Social robots are increasingly experimented in public and assistive settings,
but their accessibility for Deaf users remains quite underexplored. Italian
Sign Language (LIS) is a fully-fledged natural language that relies on complex
manual and non-manual components. Enabling robots to communicate using LIS
could foster more inclusive human robot interaction, especially in social
environments such as hospitals, airports, or educational settings. This study
investigates whether a commercial social robot, Pepper, can produce
intelligible LIS signs and short signed LIS sentences. With the help of a Deaf
student and his interpreter, an expert in LIS, we co-designed and implemented
52 LIS signs on Pepper using either manual animation techniques or a MATLAB
based inverse kinematics solver. We conducted a exploratory user study
involving 12 participants proficient in LIS, both Deaf and hearing.
Participants completed a questionnaire featuring 15 single-choice video-based
sign recognition tasks and 2 open-ended questions on short signed sentences.
Results shows that the majority of isolated signs were recognized correctly,
although full sentence recognition was significantly lower due to Pepper's
limited articulation and temporal constraints. Our findings demonstrate that
even commercially available social robots like Pepper can perform a subset of
LIS signs intelligibly, offering some opportunities for a more inclusive
interaction design. Future developments should address multi-modal enhancements
(e.g., screen-based support or expressive avatars) and involve Deaf users in
participatory design to refine robot expressivity and usability.

</details>


### [152] [Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision](https://arxiv.org/abs/2509.09893)
*Hanbit Oh,Masaki Murooka,Tomohiro Motoda,Ryoichi Nakajo,Yukiyasu Domae*

Main category: cs.RO

TL;DR: SART框架通过单次人类演示和自主轨迹增强，实现了从单次演示中学习机器人策略，大幅减少人工干预并确保安全性


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习需要大量演示数据或随机探索，存在安全性问题和人工重置负担。特别是在间隙受限任务中，碰撞频繁，需要更高效安全的学习方法

Method: SART包含两个阶段：1）单次人类教学，提供一次演示并标注精度边界；2）机器人自主增强，在边界内生成多样化无碰撞轨迹并与原始演示重新连接

Result: 在仿真和真实世界操作任务中的广泛评估显示，SART相比仅使用人类收集演示的策略获得了显著更高的成功率

Conclusion: SART框架有效提高了数据收集效率，最小化人工努力的同时确保安全性，为机器人模仿学习提供了新的解决方案

Abstract: Imitation learning is a promising paradigm for training robot agents;
however, standard approaches typically require substantial data acquisition --
via numerous demonstrations or random exploration -- to ensure reliable
performance. Although exploration reduces human effort, it lacks safety
guarantees and often results in frequent collisions -- particularly in
clearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual
environmental resets and imposing additional human burden. This study proposes
Self-Augmented Robot Trajectory (SART), a framework that enables policy
learning from a single human demonstration, while safely expanding the dataset
through autonomous augmentation. SART consists of two stages: (1) human
teaching only once, where a single demonstration is provided and precision
boundaries -- represented as spheres around key waypoints -- are annotated,
followed by one environment reset; (2) robot self-augmentation, where the robot
generates diverse, collision-free trajectories within these boundaries and
reconnects to the original demonstration. This design improves the data
collection efficiency by minimizing human effort while ensuring safety.
Extensive evaluations in simulation and real-world manipulation tasks show that
SART achieves substantially higher success rates than policies trained solely
on human-collected demonstrations. Video results available at
https://sites.google.com/view/sart-il .

</details>


### [153] [DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training](https://arxiv.org/abs/2509.10426)
*Jianxin Shi,Zengqi Peng,Xiaolong Chen,Tianyu Wo,Jun Ma*

Main category: cs.RO

TL;DR: DECAMP是一个解耦上下文感知的预训练框架，用于多智能体运动预测，通过分离行为模式学习和潜在特征重建，在Argoverse 2基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在标注数据稀缺和多智能体预测场景中性能不佳的问题，提升自动驾驶中的轨迹预测能力。

Method: 采用解耦的上下文感知预训练框架，将行为模式学习与潜在特征重建分离，结合协作空间运动预任务进行联合优化。

Result: 在Argoverse 2基准测试中展示了优越性能，证明了在多智能体运动预测中的有效性。

Conclusion: DECAMP是首个用于自动驾驶多智能体运动预测的上下文自编码器框架，具有显著的性能提升和实用性。

Abstract: Trajectory prediction is a critical component of autonomous driving,
essential for ensuring both safety and efficiency on the road. However,
traditional approaches often struggle with the scarcity of labeled data and
exhibit suboptimal performance in multi-agent prediction scenarios. To address
these challenges, we introduce a disentangled context-aware pre-training
framework for multi-agent motion prediction, named DECAMP. Unlike existing
methods that entangle representation learning with pretext tasks, our framework
decouples behavior pattern learning from latent feature reconstruction,
prioritizing interpretable dynamics and thereby enhancing scene representation
for downstream prediction. Additionally, our framework incorporates
context-aware representation learning alongside collaborative spatial-motion
pretext tasks, which enables joint optimization of structural and intentional
reasoning while capturing the underlying dynamic intentions. Our experiments on
the Argoverse 2 benchmark showcase the superior performance of our method, and
the results attained underscore its effectiveness in multi-agent motion
forecasting. To the best of our knowledge, this is the first context
autoencoder framework for multi-agent motion forecasting in autonomous driving.
The code and models will be made publicly available.

</details>


### [154] [Detection of Anomalous Behavior in Robot Systems Based on Machine Learning](https://arxiv.org/abs/2509.09953)
*Mahfuzul I. Nissan,Sharmin Aktar*

Main category: cs.RO

TL;DR: 本研究提出基于机器学习的系统日志异常检测方法，通过比较逻辑回归、支持向量机和自编码器在不同机器人场景中的表现，发现最优模型选择具有场景依赖性，自编码器在复杂异常检测中表现突出


<details>
  <summary>Details</summary>
Motivation: 确保机器人系统安全可靠运行至关重要，尽管有严格的设计和工程实践，系统仍可能出现故障导致安全风险，需要有效的异常检测方法来增强安全性

Method: 使用CoppeliaSim收集两个不同场景（四旋翼无人机和Pioneer机器人）的系统日志，比较评估逻辑回归、支持向量机和自编码器等多种机器学习模型

Result: 在四旋翼无人机场景中逻辑回归表现最佳，而在Pioneer机器人场景中自编码器效果最好，表明最优模型选择取决于具体场景，可能由于不同机器人平台的异常复杂度差异

Conclusion: 研究强调了比较方法的价值，并展示了自编码器在检测机器人系统复杂异常方面的特殊优势，模型选择需要根据具体应用场景进行优化

Abstract: Ensuring the safe and reliable operation of robotic systems is paramount to
prevent potential disasters and safeguard human well-being. Despite rigorous
design and engineering practices, these systems can still experience
malfunctions, leading to safety risks. In this study, we present a machine
learning-based approach for detecting anomalies in system logs to enhance the
safety and reliability of robotic systems. We collected logs from two distinct
scenarios using CoppeliaSim and comparatively evaluated several machine
learning models, including Logistic Regression (LR), Support Vector Machine
(SVM), and an Autoencoder. Our system was evaluated in a quadcopter context
(Context 1) and a Pioneer robot context (Context 2). Results showed that while
LR demonstrated superior performance in Context 1, the Autoencoder model proved
to be the most effective in Context 2. This highlights that the optimal model
choice is context-dependent, likely due to the varying complexity of anomalies
across different robotic platforms. This research underscores the value of a
comparative approach and demonstrates the particular strengths of autoencoders
for detecting complex anomalies in robotic systems.

</details>


### [155] [Gaussian path model library for intuitive robot motion programming by demonstration](https://arxiv.org/abs/2509.10007)
*Samuli Soutukorva,Markku Suomalainen,Martin Kollingbaum,Tapio Heikkilä*

Main category: cs.RO

TL;DR: 提出基于高斯路径模型的系统，从教学数据生成路径形状模型，并用于分类人类演示路径，实现直观的机器人运动编程


<details>
  <summary>Details</summary>
Motivation: 通过建立多种形状的高斯路径模型库，使人类演示能够用于直观的机器人运动编程，提高编程效率和自然性

Method: 从教学数据生成高斯路径模型，构建多形状模型库，通过几何分析实现基于演示的现有模型修改

Result: 开发了完整的系统，能够生成、分类和修改高斯路径模型，支持人类演示的机器人运动编程

Conclusion: 高斯路径模型系统为基于演示的机器人编程提供了有效方法，通过模型库和几何修改实现了直观的运动编程

Abstract: This paper presents a system for generating Gaussian path models from
teaching data representing the path shape. In addition, methods for using these
path models to classify human demonstrations of paths are introduced. By
generating a library of multiple Gaussian path models of various shapes, human
demonstrations can be used for intuitive robot motion programming. A method for
modifying existing Gaussian path models by demonstration through geometric
analysis is also presented.

</details>


### [156] [Towards simulation-based optimization of compliant fingers for high-speed connector assembly](https://arxiv.org/abs/2509.10012)
*Richard Matthias Hartisch,Alexander Rother,Jörg Krüger,Kevin Haninger*

Main category: cs.RO

TL;DR: 提出基于仿真的柔顺机构设计工具，用于优化柔顺手指的设计参数，提高插入任务中的容差能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 柔顺性是动态接触丰富操作的关键设计参数，影响任务成功率和安全性。目前设计参数选择要么通过硬件迭代（耗时），要么使用简化模型（无法处理复杂任务目标），需要更好的设计工具。

Method: 使用基于仿真的设计工具，考虑接触和摩擦建模，针对任务级目标（如成功率）优化柔顺手指的设计参数，并在真实机器人上使用NIST任务板基准进行验证。

Result: 优化参数可将容差范围提高2.29倍，能够补偿高达8.6mm的工作件变化。但趋势具有任务特异性，不同任务需要不同的刚度设计。

Conclusion: 柔顺机构设计需要应用特定的设计工具，能够考虑具体的几何形状和动力学特性，不同任务需要不同的刚度优化策略。

Abstract: Mechanical compliance is a key design parameter for dynamic contact-rich
manipulation, affecting task success and safety robustness over contact
geometry variation. Design of soft robotic structures, such as compliant
fingers, requires choosing design parameters which affect geometry and
stiffness, and therefore manipulation performance and robustness. Today, these
parameters are chosen through either hardware iteration, which takes
significant development time, or simplified models (e.g. planar), which can't
address complex manipulation task objectives. Improvements in dynamic
simulation, especially with contact and friction modeling, present a potential
design tool for mechanical compliance. We propose a simulation-based design
tool for compliant mechanisms which allows design with respect to task-level
objectives, such as success rate. This is applied to optimize design parameters
of a structured compliant finger to reduce failure cases inside a tolerance
window in insertion tasks. The improvement in robustness is then validated on a
real robot using tasks from the benchmark NIST task board. The finger stiffness
affects the tolerance window: optimized parameters can increase tolerable
ranges by a factor of 2.29, with workpiece variation up to 8.6 mm being
compensated. However, the trends remain task-specific. In some tasks, the
highest stiffness yields the widest tolerable range, whereas in others the
opposite is observed, motivating need for design tools which can consider
application-specific geometry and dynamics.

</details>


### [157] [Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping](https://arxiv.org/abs/2509.10032)
*Marawan Khalil,Fabian Arzberger,Andreas Nüchter*

Main category: cs.RO

TL;DR: 本文介绍了两种球形测绘系统（轻量非驱动型和驱动型），评估了它们在动态运动下LIO算法的性能表现，发现现有算法因球形运动的高动态性而导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 球形机器人在危险或受限环境中具有独特优势，但其球形运动引入的高动态性可能影响测绘精度，需要评估现有LIO算法在这种特殊运动模式下的性能。

Method: 开发了两种球形测绘系统（非驱动和驱动型），配备Livox Mid-360固态LiDAR传感器，在资源受限硬件上运行LIO算法，并通过与地面真实地图比较来评估测绘精度。

Result: 结果表明，由于球形运动引入的高动态运动，最先进的LIO算法性能恶化，导致全局不一致的地图和有时无法恢复的漂移。

Conclusion: 球形机器人的特殊运动模式对现有LIO算法提出了挑战，需要开发更适合高动态球形运动的算法来保证测绘精度。

Abstract: Spherical robots offer unique advantages for mapping applications in
hazardous or confined environments, thanks to their protective shells and
omnidirectional mobility. This work presents two complementary spherical
mapping systems: a lightweight, non-actuated design and an actuated variant
featuring internal pendulum-driven locomotion. Both systems are equipped with a
Livox Mid-360 solid-state LiDAR sensor and run LiDAR-Inertial Odometry (LIO)
algorithms on resource-constrained hardware. We assess the mapping accuracy of
these systems by comparing the resulting 3D point-clouds from the LIO
algorithms to a ground truth map. The results indicate that the performance of
state-of-the-art LIO algorithms deteriorates due to the high dynamic movement
introduced by the spherical locomotion, leading to globally inconsistent maps
and sometimes unrecoverable drift.

</details>


### [158] [TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim Digital Twin Sensor Model](https://arxiv.org/abs/2509.10063)
*Xiyan Huang,Zhe Xu,Chenxi Xiao*

Main category: cs.RO

TL;DR: TwinTac系统结合物理触觉传感器与其数字孪生模型，通过真实到仿真的方法构建触觉传感器仿真模型，解决强化学习中触觉感知数据缺失问题。


<details>
  <summary>Details</summary>
Motivation: 机器人技能获取过程中依赖仿真生成交互数据，但缺乏触觉传感器的仿真模型阻碍了触觉感知在技能学习中的应用，限制了触觉驱动策略的发展。

Method: 设计高灵敏度物理触觉传感器，收集同步跨域数据（有限元法结果和物理传感器输出），训练神经网络将仿真数据映射到真实传感器响应，构建数字孪生模型。

Result: 实验评估显示物理传感器灵敏度良好，数字孪生能一致复现物理传感器输出；物体分类任务证明仿真数据能有效增强真实数据，提高准确率。

Conclusion: TwinTac系统成功填补了跨域学习任务中的空白，为触觉感知在机器人技能学习中的应用提供了有效解决方案。

Abstract: Robot skill acquisition processes driven by reinforcement learning often rely
on simulations to efficiently generate large-scale interaction data. However,
the absence of simulation models for tactile sensors has hindered the use of
tactile sensing in such skill learning processes, limiting the development of
effective policies driven by tactile perception. To bridge this gap, we present
TwinTac, a system that combines the design of a physical tactile sensor with
its digital twin model. Our hardware sensor is designed for high sensitivity
and a wide measurement range, enabling high quality sensing data essential for
object interaction tasks. Building upon the hardware sensor, we develop the
digital twin model using a real-to-sim approach. This involves collecting
synchronized cross-domain data, including finite element method results and the
physical sensor's outputs, and then training neural networks to map simulated
data to real sensor responses. Through experimental evaluation, we
characterized the sensitivity of the physical sensor and demonstrated the
consistency of the digital twin in replicating the physical sensor's output.
Furthermore, by conducting an object classification task, we showed that
simulation data generated by our digital twin sensor can effectively augment
real-world data, leading to improved accuracy. These results highlight
TwinTac's potential to bridge the gap in cross-domain learning tasks.

</details>


### [159] [Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation](https://arxiv.org/abs/2509.10065)
*Hauzi Cao,Jiahao Shen,Zhengzhen Li,Qinquan Ren,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于预设轨迹和二次规划的无人机机械臂运动学跟踪控制框架，确保末端执行器在规定时间内到达目标位置并满足物理约束


<details>
  <summary>Details</summary>
Motivation: 现有运动学跟踪控制方法（如比例微分反馈或跟踪误差反馈策略）无法在规定时间约束内实现跟踪目标，需要新的控制框架来解决这一局限性

Method: 包含两个关键组件：基于用户定义预设轨迹的末端执行器跟踪控制，以及基于二次规划的参考分配方法，同时考虑无人机机械臂的物理约束

Result: 通过三个实验验证，结果表明所提算法有效，能够保证在预设时间内到达目标位置，且跟踪误差保持在反映任务要求的性能包络内

Conclusion: 该方法相比现有方法具有显著优势，既能确保时间约束下的精确跟踪，又能通过二次规划避免违反物理限制的解决方案，为无人机机械臂控制提供了有效的框架

Abstract: This paper studies the kinematic tracking control problem for aerial
manipulators. Existing kinematic tracking control methods, which typically
employ proportional-derivative feedback or tracking-error-based feedback
strategies, may fail to achieve tracking objectives within specified time
constraints. To address this limitation, we propose a novel control framework
comprising two key components: end-effector tracking control based on a
user-defined preset trajectory and quadratic programming-based reference
allocation. Compared with state-of-the-art approaches, the proposed method has
several attractive features. First, it ensures that the end-effector reaches
the desired position within a preset time while keeping the tracking error
within a performance envelope that reflects task requirements. Second,
quadratic programming is employed to allocate the references of the quadcopter
base and the Delta arm, while considering the physical constraints of the
aerial manipulator, thus preventing solutions that may violate physical
limitations. The proposed approach is validated through three experiments.
Experimental results demonstrate the effectiveness of the proposed algorithm
and its capability to guarantee that the target position is reached within the
preset time.

</details>


### [160] [HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario](https://arxiv.org/abs/2509.10096)
*Saeed Saadatnejad,Reyhaneh Hosseininejad,Jose Barreiros,Katherine M. Tsui,Alexandre Alahi*

Main category: cs.RO

TL;DR: 提出了HHI-Assist数据集和基于Transformer的条件去噪扩散模型，用于预测物理交互场景中的人体运动，提高辅助机器人的响应能力


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺和人口老龄化需要辅助机器人，但机器人需要准确的人体运动预测来提供安全响应，这在物理交互场景中具有挑战性

Method: 收集人类-人类交互辅助任务的动作捕捉数据集(HHI-Assist)，开发基于条件Transformer的去噪扩散模型来预测交互智能体的姿态

Result: 模型有效捕捉了护理者和被护理者之间的耦合动力学，相比基线方法有改进，并在未见场景中表现出强泛化能力

Conclusion: 通过推进交互感知的运动预测和引入新数据集，这项工作有潜力显著增强机器人辅助策略

Abstract: The increasing labor shortage and aging population underline the need for
assistive robots to support human care recipients. To enable safe and
responsive assistance, robots require accurate human motion prediction in
physical interaction scenarios. However, this remains a challenging task due to
the variability of assistive settings and the complexity of coupled dynamics in
physical interactions. In this work, we address these challenges through two
key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of
human-human interactions in assistive tasks; and (2) a conditional
Transformer-based denoising diffusion model for predicting the poses of
interacting agents. Our model effectively captures the coupled dynamics between
caregivers and care receivers, demonstrating improvements over baselines and
strong generalization to unseen scenarios. By advancing interaction-aware
motion prediction and introducing a new dataset, our work has the potential to
significantly enhance robotic assistance policies. The dataset and code are
available at: https://sites.google.com/view/hhi-assist/home

</details>


### [161] [Efficient Learning-Based Control of a Legged Robot in Lunar Gravity](https://arxiv.org/abs/2509.10128)
*Philip Arm,Oliver Fischer,Joseph Church,Adrian Fuhrer,Hendrik Kolvenbach,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的腿式机器人控制方法，通过重力缩放功率优化奖励函数，实现了从月球重力到超地球重力的多重力环境下高效节能的运动控制。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在低重力天体探索中具有优势，但行星机器人的功率和热预算受限，需要能轻松适应多种重力环境的节能控制方法。

Method: 使用强化学习开发控制方法，采用重力缩放功率优化奖励函数，包括运动控制器和基座姿态控制器，并设计了恒力弹簧卸载系统进行月球重力下的真实实验。

Result: 在地球重力下，功率优化运动控制器的功耗为23.4W（比基线策略提升23%）；在月球重力下功耗为12.2W（比非功率优化的基线控制器降低36%）。

Conclusion: 该方法为腿式机器人在多重力环境下开发功率高效的运动控制器提供了可扩展的解决方案。

Abstract: Legged robots are promising candidates for exploring challenging areas on
low-gravity bodies such as the Moon, Mars, or asteroids, thanks to their
advanced mobility on unstructured terrain. However, as planetary robots' power
and thermal budgets are highly restricted, these robots need energy-efficient
control approaches that easily transfer to multiple gravity environments. In
this work, we introduce a reinforcement learning-based control approach for
legged robots with gravity-scaled power-optimized reward functions. We use our
approach to develop and validate a locomotion controller and a base pose
controller in gravity environments from lunar gravity (1.62 m/s2) to a
hypothetical super-Earth (19.62 m/s2). Our approach successfully scales across
these gravity levels for locomotion and base pose control with the
gravity-scaled reward functions. The power-optimized locomotion controller
reached a power consumption for locomotion of 23.4 W in Earth gravity on a
15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.
Additionally, we designed a constant-force spring offload system that allowed
us to conduct real-world experiments on legged locomotion in lunar gravity. In
lunar gravity, the power-optimized control policy reached 12.2 W, 36 % less
than a baseline controller which is not optimized for power efficiency. Our
method provides a scalable approach to developing power-efficient locomotion
controllers for legged robots across multiple gravity levels.

</details>


### [162] [CaR1: A Multi-Modal Baseline for BEV Vehicle Segmentation via Camera-Radar Fusion](https://arxiv.org/abs/2509.10139)
*Santiago Montiel-Marín,Angel Llamazares,Miguel Antunes-García,Fabio Sánchez-García,Luis M. Bergasa*

Main category: cs.RO

TL;DR: CaR1是一种新颖的相机-雷达融合架构，用于BEV车辆分割，通过网格化雷达编码和自适应融合机制，在nuScenes数据集上达到57.6 IoU的竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 相机-雷达融合为自动驾驶系统提供了比LiDAR更经济可靠的替代方案，相机提供丰富的语义信息但深度不可靠，雷达提供稀疏但可靠的位置和运动信息。

Method: 基于BEVFusion构建，采用网格化雷达编码将点云离散化为结构化BEV特征，并使用自适应融合机制动态平衡传感器贡献。

Result: 在nuScenes数据集上的实验显示竞争性分割性能（57.6 IoU），与最先进方法相当。

Conclusion: CaR1展示了相机-雷达融合在BEV车辆分割中的有效性，代码已公开可用。

Abstract: Camera-radar fusion offers a robust and cost-effective alternative to
LiDAR-based autonomous driving systems by combining complementary sensing
capabilities: cameras provide rich semantic cues but unreliable depth, while
radar delivers sparse yet reliable position and motion information. We
introduce CaR1, a novel camera-radar fusion architecture for BEV vehicle
segmentation. Built upon BEVFusion, our approach incorporates a grid-wise radar
encoding that discretizes point clouds into structured BEV features and an
adaptive fusion mechanism that dynamically balances sensor contributions.
Experiments on nuScenes demonstrate competitive segmentation performance (57.6
IoU), on par with state-of-the-art methods. Code is publicly available
\href{https://www.github.com/santimontiel/car1}{online}.

</details>


### [163] [DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning](https://arxiv.org/abs/2509.10247)
*Xinhong Zhang,Runqing Wang,Yunfan Ren,Jian Sun,Hao Fang,Jie Chen,Gang Wang*

Main category: cs.RO

TL;DR: DiffAero是一个轻量级、GPU加速的完全可微分四旋翼飞行器仿真框架，支持环境级和智能体级并行，集成多种动力学模型和传感器，在消费级硬件上几小时内即可学习到鲁棒的飞行策略。


<details>
  <summary>Details</summary>
Motivation: 现有仿真器存在CPU-GPU数据传输瓶颈，无法高效支持四旋翼控制策略学习，需要开发高性能、完全可微分的仿真平台来加速强化学习算法的训练过程。

Method: 开发了完全GPU并行化的物理和渲染引擎，支持多种动力学模型（IMU、深度相机、LiDAR等传感器），提供统一的可微分训练接口，支持环境级和智能体级并行计算。

Result: 相比现有仿真器，DiffAero实现了数量级的仿真吞吐量提升，消除了CPU-GPU数据传输瓶颈，在消费级硬件上几小时内即可训练出鲁棒的飞行控制策略。

Conclusion: DiffAero不仅是一个高性能仿真器，更是一个可微分和混合学习算法的研究平台，通过真实飞行实验验证了其有效性，代码已开源。

Abstract: This letter introduces DiffAero, a lightweight, GPU-accelerated, and fully
differentiable simulation framework designed for efficient quadrotor control
policy learning. DiffAero supports both environment-level and agent-level
parallelism and integrates multiple dynamics models, customizable sensor stacks
(IMU, depth camera, and LiDAR), and diverse flight tasks within a unified,
GPU-native training interface. By fully parallelizing both physics and
rendering on the GPU, DiffAero eliminates CPU-GPU data transfer bottlenecks and
delivers orders-of-magnitude improvements in simulation throughput. In contrast
to existing simulators, DiffAero not only provides high-performance simulation
but also serves as a research platform for exploring differentiable and hybrid
learning algorithms. Extensive benchmarks and real-world flight experiments
demonstrate that DiffAero and hybrid learning algorithms combined can learn
robust flight policies in hours on consumer-grade hardware. The code is
available at https://github.com/flyingbitac/diffaero.

</details>


### [164] [GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning](https://arxiv.org/abs/2509.10305)
*Yutong Shen,Ruizhe Xia,Bokai Yan,Shunqi zhang,Pengrui Xiang,Sicheng He,Yixin Xu*

Main category: cs.RO

TL;DR: GundamQ：一种用于机器人路径规划的多尺度时空Q网络，通过分层提取多粒度空间特征和多尺度时间依赖关系，在动态环境中实现了15.3%的成功率提升和21.7%的路径质量改善


<details>
  <summary>Details</summary>
Motivation: 当前基于深度强化学习的路径规划方法存在两个根本局限性：(1) 多尺度时间依赖建模不足，导致动态场景中的适应性不佳；(2) 探索-利用平衡效率低下，导致路径质量下降

Method: 提出GundamQ框架，包含两个关键模块：(i) 时空感知模块，分层提取多粒度空间特征和多尺度时间依赖关系；(ii) 自适应策略优化模块，平衡探索与利用，通过约束策略更新优化平滑度和碰撞概率

Result: 在动态环境实验中，GundamQ实现了15.3%的成功率提升和21.7%的整体路径质量增加，显著优于现有最先进方法

Conclusion: GundamQ通过改进的时空感知和自适应策略优化，有效解决了动态环境中机器人路径规划的关键挑战，为复杂环境下的路径规划提供了有效解决方案

Abstract: In dynamic and uncertain environments, robotic path planning demands accurate
spatiotemporal environment understanding combined with robust decision-making
under partial observability. However, current deep reinforcement learning-based
path planning methods face two fundamental limitations: (1) insufficient
modeling of multi-scale temporal dependencies, resulting in suboptimal
adaptability in dynamic scenarios, and (2) inefficient exploration-exploitation
balance, leading to degraded path quality. To address these challenges, we
propose GundamQ: A Multi-Scale Spatiotemporal Q-Network for Robotic Path
Planning. The framework comprises two key modules: (i) the Spatiotemporal
Perception module, which hierarchically extracts multi-granularity spatial
features and multi-scale temporal dependencies ranging from instantaneous to
extended time horizons, thereby improving perception accuracy in dynamic
environments; and (ii) the Adaptive Policy Optimization module, which balances
exploration and exploitation during training while optimizing for smoothness
and collision probability through constrained policy updates. Experiments in
dynamic environments demonstrate that GundamQ achieves a 15.3\% improvement in
success rate and a 21.7\% increase in overall path quality, significantly
outperforming existing state-of-the-art methods.

</details>


### [165] [Robot guide with multi-agent control and automatic scenario generation with LLM](https://arxiv.org/abs/2509.10317)
*Elizaveta D. Moskovskaya,Anton D. Moscowsky*

Main category: cs.RO

TL;DR: 开发了一种混合控制架构，结合多智能体资源管理系统和基于大语言模型的自动行为场景生成，用于人形导游机器人，以克服传统手动调优系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统导游机器人系统依赖手动配置行为场景，存在配置繁琐、灵活性低、行为不自然等问题，需要更自动化和自然的控制方法。

Method: 采用两阶段生成过程：首先生成风格化叙事文本，然后整合非语言动作标签；使用多智能体系统协调并行动作执行和冲突解决，并在主要操作完成后维持默认行为。

Result: 试验结果表明该方法在自动化和社会机器人控制系统扩展方面具有潜力，能够实现更自然的机器人行为。

Conclusion: 提出的混合控制架构成功解决了传统系统的局限性，为社交机器人控制系统的自动化和规模化提供了有效解决方案。

Abstract: The work describes the development of a hybrid control architecture for an
anthropomorphic tour guide robot, combining a multi-agent resource management
system with automatic behavior scenario generation based on large language
models. The proposed approach aims to overcome the limitations of traditional
systems, which rely on manual tuning of behavior scenarios. These limitations
include manual configuration, low flexibility, and lack of naturalness in robot
behavior. The process of preparing tour scenarios is implemented through a
two-stage generation: first, a stylized narrative is created, then non-verbal
action tags are integrated into the text. The multi-agent system ensures
coordination and conflict resolution during the execution of parallel actions,
as well as maintaining default behavior after the completion of main
operations, contributing to more natural robot behavior. The results obtained
from the trial demonstrate the potential of the proposed approach for
automating and scaling social robot control systems.

</details>


### [166] [Acetrans: An Autonomous Corridor-Based and Efficient UAV Suspended Transport System](https://arxiv.org/abs/2509.10349)
*Weiyan Lu,Huizhe Li,Yuhao Fang,Zhexuan Zhou,Junda Wu,Yude Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Unmanned aerial vehicles (UAVs) with suspended payloads offer significant
advantages for aerial transportation in complex and cluttered environments.
However, existing systems face critical limitations, including unreliable
perception of the cable-payload dynamics, inefficient planning in large-scale
environments, and the inability to guarantee whole-body safety under cable
bending and external disturbances. This paper presents Acetrans, an Autonomous,
Corridor-based, and Efficient UAV suspended transport system that addresses
these challenges through a unified perception, planning, and control framework.
A LiDAR-IMU fusion module is proposed to jointly estimate both payload pose and
cable shape under taut and bent modes, enabling robust whole-body state
estimation and real-time filtering of cable point clouds. To enhance planning
scalability, we introduce the Multi-size-Aware Configuration-space Iterative
Regional Inflation (MACIRI) algorithm, which generates safe flight corridors
while accounting for varying UAV and payload geometries. A spatio-temporal,
corridor-constrained trajectory optimization scheme is then developed to ensure
dynamically feasible and collision-free trajectories. Finally, a nonlinear
model predictive controller (NMPC) augmented with cable-bending constraints
provides robust whole-body safety during execution. Simulation and experimental
results validate the effectiveness of Acetrans, demonstrating substantial
improvements in perception accuracy, planning efficiency, and control safety
compared to state-of-the-art methods.

</details>


### [167] [Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States](https://arxiv.org/abs/2509.10405)
*Nicholas Carlotti,Mirko Nava,Alessandro Giusti*

Main category: cs.RO

TL;DR: 提出了一种无需位姿标签或机器人先验知识的单目RGB相对位姿估计模型，通过LED状态预测任务学习机器人位置、距离和相对方位


<details>
  <summary>Details</summary>
Motivation: 解决单目视觉相对位姿估计需要大量标注数据或机器人CAD模型的问题，实现无监督学习

Method: 使用配备多个LED的机器人，通过预测LED状态的任务来学习位姿估计，训练时利用已知的LED状态和视角方向，推理时无需LED状态信息

Result: 与需要监督学习或CAD模型的现有方法性能相当，具有良好的泛化能力和多机器人位姿估计能力

Conclusion: 该方法提供了一种无需标注数据或先验知识的有效相对位姿估计解决方案，具有实际应用价值

Abstract: We introduce a model for monocular RGB relative pose estimation of a ground
robot that trains from scratch without pose labels nor prior knowledge about
the robot's shape or appearance. At training time, we assume: (i) a robot
fitted with multiple LEDs, whose states are independent and known at each
frame; (ii) knowledge of the approximate viewing direction of each LED; and
(iii) availability of a calibration image with a known target distance, to
address the ambiguity of monocular depth estimation. Training data is collected
by a pair of robots moving randomly without needing external infrastructure or
human supervision. Our model trains on the task of predicting from an image the
state of each LED on the robot. In doing so, it learns to predict the position
of the robot in the image, its distance, and its relative bearing. At inference
time, the state of the LEDs is unknown, can be arbitrary, and does not affect
the pose estimation performance. Quantitative experiments indicate that our
approach: is competitive with SoA approaches that require supervision from pose
labels or a CAD model of the robot; generalizes to different domains; and
handles multi-robot pose estimation.

</details>


### [168] [TASC: Task-Aware Shared Control for Teleoperated Manipulation](https://arxiv.org/abs/2509.10416)
*Ze Fu,Pinhao Song,Yutong Hu,Renaud Detry*

Main category: cs.RO

TL;DR: TASC是一个任务感知共享控制框架，通过视觉输入构建开放词汇交互图来推断用户意图，为远程操作提供旋转辅助，无需预定义知识即可支持日常任务。


<details>
  <summary>Details</summary>
Motivation: 解决通用长时程共享控制中的两个关键挑战：(1)理解和推断任务级用户意图，(2)在不同对象和任务间泛化辅助功能。

Method: 构建开放词汇交互图表示功能对象关系，使用视觉语言模型预测空间约束，在抓取和对象交互过程中提供旋转辅助的共享控制策略。

Result: 在仿真和真实世界实验中，TASC相比先前方法提高了任务效率并减少了用户输入工作量。

Conclusion: 这是第一个支持日常操作任务且具有零样本泛化能力的共享控制框架，实现了无需预定义知识的任务级辅助。

Abstract: We present TASC, a Task-Aware Shared Control framework for teleoperated
manipulation that infers task-level user intent and provides assistance
throughout the task. To support everyday tasks without predefined knowledge,
TASC constructs an open-vocabulary interaction graph from visual input to
represent functional object relationships, and infers user intent accordingly.
A shared control policy then provides rotation assistance during both grasping
and object interaction, guided by spatial constraints predicted by a
vision-language model. Our method addresses two key challenges in
general-purpose, long-horizon shared control: (1) understanding and inferring
task-level user intent, and (2) generalizing assistance across diverse objects
and tasks. Experiments in both simulation and the real world demonstrate that
TASC improves task efficiency and reduces user input effort compared to prior
methods. To the best of our knowledge, this is the first shared control
framework that supports everyday manipulation tasks with zero-shot
generalization. The code that supports our experiments is publicly available at
https://github.com/fitz0401/tasc.

</details>


### [169] [Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction](https://arxiv.org/abs/2509.10444)
*Chaerim Moon,Joohyung Kim*

Main category: cs.RO

TL;DR: 提出了一种用于超数机器人肢体(SRLs)的运动规划层概念，通过修改轨迹来减少操作时产生的力矩，从而改善人机交互。


<details>
  <summary>Details</summary>
Motivation: 作为可穿戴设备，SRLs操作时产生的力矩会作用于人体，当力矩增大时需要更多肌肉单元来平衡，导致肌肉零空间减少，影响人机交互效果。

Method: 开发了一个运动规划层，在给定的轨迹基础上进行修改，设置期望的角加速度和位置偏差限制，以减少产生的力矩。

Result: 通过使用简化的人体和机器人系统模型进行仿真，证明了该方法在减少力矩方面的有效性。

Conclusion: 所提出的运动规划层概念能够有效减少SRLs操作时产生的力矩，从而增强人机交互性能，为可穿戴机器人系统提供了改进方案。

Abstract: Supernumerary Robotic Limbs (SRLs) can enhance human capability within close
proximity. However, as a wearable device, the generated moment from its
operation acts on the human body as an external torque. When the moments
increase, more muscle units are activated for balancing, and it can result in
reduced muscular null space. Therefore, this paper suggests a concept of a
motion planning layer that reduces the generated moment for enhanced
Human-Robot Interaction. It modifies given trajectories with desirable angular
acceleration and position deviation limits. Its performance to reduce the
moment is demonstrated through the simulation, which uses simplified human and
robotic system models.

</details>


### [170] [GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation](https://arxiv.org/abs/2509.10454)
*Hang Yin,Haoyu Wei,Xiuwei Xu,Wenxuan Guo,Jie Zhou,Jiwen Lu*

Main category: cs.RO

TL;DR: 提出了一种无需训练的视觉语言导航框架，通过将导航指令分解为空间约束图并进行约束优化，实现零样本连续环境导航


<details>
  <summary>Details</summary>
Motivation: 解决现有零样本VLN方法主要针对离散环境或需要无监督训练的问题，使其难以在真实世界场景中泛化和部署

Method: 将导航指导构建为图约束优化，分解指令为显式空间约束，构建空间约束库，通过约束求解器确定路径点位置，使用导航树和回溯机制处理无解或多解情况

Result: 在标准基准测试中相比最先进的零样本VLN方法显著提高了成功率和导航效率，真实世界实验显示能有效泛化到新环境和指令集

Conclusion: 该框架为实现更鲁棒和自主的导航系统铺平了道路，展示了训练free方法在连续环境中的有效性

Abstract: In this paper, we propose a training-free framework for vision-and-language
navigation (VLN). Existing zero-shot VLN methods are mainly designed for
discrete environments or involve unsupervised training in continuous simulator
environments, which makes it challenging to generalize and deploy them in
real-world scenarios. To achieve a training-free framework in continuous
environments, our framework formulates navigation guidance as graph constraint
optimization by decomposing instructions into explicit spatial constraints. The
constraint-driven paradigm decodes spatial semantics through constraint
solving, enabling zero-shot adaptation to unseen environments. Specifically, we
construct a spatial constraint library covering all types of spatial
relationship mentioned in VLN instructions. The human instruction is decomposed
into a directed acyclic graph, with waypoint nodes, object nodes and edges,
which are used as queries to retrieve the library to build the graph
constraints. The graph constraint optimization is solved by the constraint
solver to determine the positions of waypoints, obtaining the robot's
navigation path and final goal. To handle cases of no solution or multiple
solutions, we construct a navigation tree and the backtracking mechanism.
Extensive experiments on standard benchmarks demonstrate significant
improvements in success rate and navigation efficiency compared to
state-of-the-art zero-shot VLN methods. We further conduct real-world
experiments to show that our framework can effectively generalize to new
environments and instruction sets, paving the way for a more robust and
autonomous navigation framework.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [171] [Evolution of Coordination Through Institutional Incentives: An Evolutionary Game Theory Approach](https://arxiv.org/abs/2509.10112)
*Ndidi Bianca Ogbo,Zhao Song,The Anh Han*

Main category: cs.GT

TL;DR: 本文通过进化博弈论模型分析有限制度资源在促进参与和确保承诺遵守之间的最优分配策略，发现奖励型激励比惩罚型激励更能促进协调成功


<details>
  <summary>Details</summary>
Motivation: 现有关于承诺机制和合作行为的研究大多停留在定性分析，缺乏对有限制度资源在促进参与和确保承诺遵守之间分配策略的定量研究

Method: 开发进化博弈论模型，分析有限预算下制度激励（奖励或惩罚）在预承诺框架内两个关键目标（促进参与和确保遵守）的战略分配

Result: 奖励型激励方法比惩罚型方法始终产生更大的协调成功率，最优结果出现在资源在促进参与和确保遵守之间适当分配时

Conclusion: 研究结果为设计制度激励以促进新技术广泛协调采用提供了新的见解，强调奖励型激励和资源优化分配的重要性

Abstract: There is a broad recognition that commitment-based mechanisms can promote
coordination and cooperative behaviours in both biological populations and
self-organised multi-agent systems by making individuals' intentions explicit
prior to engagement. Yet their effectiveness depends on sustained compliance
supported by institutions, especially in one-off interactions. Despite advances
in quantitative studies of cooperation and commitment, most applied analyses
and policy debates remain largely qualitative, with limited attention to the
allocation of scarce institutional resources between enhancing participation
and ensuring commitment compliance. Herein, we develop an evolutionary
game-theoretic model that explicitly examines the strategic distribution of a
limited budget for institutional incentives, namely rewards or punishments,
aimed at these two critical objectives within pre-commitment frameworks. Our
findings reveal that a reward-based incentive approach consistently yields
greater coordination success than a punishment-based approach, with optimal
outcomes arising when resources are appropriately distributed between
participation promotion and compliance assurance. These findings offer novel
insights for designing institutional incentives to promote broad, coordinated
adoption of new technologies.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [172] [Target Defense Using a Turret and Mobile Defender Team](https://arxiv.org/abs/2509.09777)
*Alexander Von Moll,Dipankar Maity,Meir Pachter,Daigo Shishika,Michael Dorothy*

Main category: eess.SY

TL;DR: 本文分析了一个三方微分博弈场景，其中固定炮塔和移动防御者合作对抗移动攻击者，给出了团队获胜条件和最优策略


<details>
  <summary>Details</summary>
Motivation: 研究固定炮塔与移动防御者协同防御移动攻击者的最优策略问题，为协同防御系统提供理论指导

Method: 采用微分博弈理论和几何方法分析，建立三方博弈模型并求解均衡策略

Result: 给出了炮塔-防御者团队获胜和攻击者获胜的充要条件，提供了三种捕获情况下的最优策略

Conclusion: 该研究为协同防御系统提供了完整的理论框架和最优策略解决方案，适用于多种实际防御场景

Abstract: A scenario is considered wherein a stationary, turn constrained agent
(Turret) and a mobile agent (Defender) cooperate to protect the former from an
adversarial mobile agent (Attacker). The Attacker wishes to reach the Turret
prior to getting captured by either the Defender or Turret, if possible.
Meanwhile, the Defender and Turret seek to capture the Attacker as far from the
Turret as possible. This scenario is formulated as a differential game and
solved using a geometric approach. Necessary and sufficient conditions for the
Turret-Defender team winning and the Attacker winning are given. In the case of
the Turret-Defender team winning equilibrium strategies for the min max
terminal distance of the Attacker to the Turret are given. Three cases arise
corresponding to solo capture by the Defender, solo capture by the Turret, and
capture simultaneously by both Turret and Defender.

</details>


### [173] [Automatic Regression for Governing Equations with Control (ARGOSc)](https://arxiv.org/abs/2509.09784)
*Amir Bahador Javadi,Amin Kargarian,Mort Naraghi-Pour*

Main category: eess.SY

TL;DR: ARGOSc是ARGOS框架的扩展版本，专门用于从含噪声数据中识别带外部控制输入的动力系统方程，在噪声条件下比SINDYc表现更好。


<details>
  <summary>Details</summary>
Motivation: 现实世界动力系统通常受到输入控制、外力或人为干预的影响，但标准的ARGOS框架无法处理这些外部输入，需要开发能够识别受控系统动力学的方法。

Method: 扩展稀疏回归框架ARGOS，引入外部控制输入到系统识别过程中，通过稀疏回归技术从含噪声的时间序列数据中推断控制动力学方程。

Result: 在Van der Pol振荡器、Lotka-Volterra和Lorenz系统等基准测试中，ARGOSc能够准确发现控制规律，在噪声条件下优于SINDYc方法，且在某些SINDYc失败的情况下仍能成功识别真实系统动力学。

Conclusion: ARGOSc为识别受外部控制的动力系统提供了有效的稀疏回归框架，在噪声环境中具有鲁棒性，能够准确推断控制输入下的系统动力学方程。

Abstract: Learning the governing equations of dynamical systems from data has drawn
significant attention across diverse fields, including physics, engineering,
robotics and control, economics, climate science, and healthcare. Sparse
regression techniques, exemplified by the Automatic Regression for Governing
Equations (ARGOS) framework, have demonstrated effectiveness in extracting
parsimonious models from time series data. However, real-world dynamical
systems are driven by input control, external forces, or human interventions,
which standard ARGOS does not accommodate. To address this, we introduce ARGOS
with control (ARGOSc), an extension of ARGOS that incorporates external control
inputs into the system identification process. ARGOSc extends the sparse
regression framework to infer governing equations while accounting for the
effects of exogenous inputs, enabling robust identification of forcing dynamics
in low- to medium-noise datasets. We demonstrate ARGOSc efficacy on benchmark
systems, including the Van der Pol oscillator, Lotka-Volterra, and the Lorenz
system with forcing and feedback control, showing enhanced accuracy in
discovering governing laws. Under the noisy conditions, ARGOSc outperforms the
widely used sparse identification of nonlinear dynamics with control (SINDYc),
in accurately identifying the underlying forced dynamics. In some cases, SINDYc
fails to capture the true system dynamics, whereas ARGOSc consistently
succeeds.

</details>


### [174] [High-Gain Voltage-Multiplier Coupled Quadratic Boost Converter: A New Design for Small Scale PV Integration](https://arxiv.org/abs/2509.09789)
*Safa Mohammed Sali,Hoach The Nguyen,Ameena Saad Al-Sumaiti*

Main category: eess.SY

TL;DR: 提出了一种基于传统二次升压转换器的高增益电压倍增器耦合二次升压转换器(HGVM-QBC)，通过集成电压倍增单元显著提高电压增益，降低半导体电压应力，适用于小型光伏系统。


<details>
  <summary>Details</summary>
Motivation: 传统二次升压转换器在光伏应用中存在电压增益有限和开关器件应力较高的问题，需要开发一种能够提供更高电压增益同时降低器件应力的新型转换器拓扑。

Method: 在传统二次升压转换器基础上集成电压倍增单元，通过多个输出电容电压叠加获得更高输出电压，采用MATLAB/Simulink进行仿真验证，并构建实验原型进行性能测试。

Result: 仿真和实验结果表明，HGVM-QBC在55%占空比下可实现12.59的电压增益(12Vdc输入获得151Vdc输出)，相比现有拓扑具有更高的增益和更低的器件电压应力。

Conclusion: HGVM-QBC为需要从低输入源获得高输出电压的光伏应用提供了一种高效可靠的解决方案，具有优异的电压增益性能和降低的器件应力特性。

Abstract: This paper introduces a single-switch high-gain voltage-multiplier coupled
quadratic boost converter (HGVM-QBC), developed from the conventional quadratic
boost converter (QBC). The proposed topology is designed to achieve higher
voltage gain, lower semiconductor voltage stress, and continuous current
operation, making it particularly suitable for small-scale photovoltaic (PV)
systems. By incorporating a voltage multiplier cell into the QBC, the converter
significantly improves voltage boosting capability while mitigating stress on
switching devices. In this configuration, the output voltage is obtained by
combining the voltages across multiple output capacitors, thereby enhancing the
overall voltage level. A detailed comparative study with recently reported
converter topologies demonstrates the superior gain and reduced device stress
offered by the HGVM-QBC. The design is validated through MATLAB/Simulink
simulations, which confirm improved performance in terms of gain and voltage
stress. Furthermore, an experimental prototype achieves an output of 151 Vdc
from a 12 Vdc input at a 55% duty cycle, corresponding to a gain of 12.59.
These results establish the HGVM-QBC as an efficient and reliable solution for
PV applications that demand high voltage output from low input sources.

</details>


### [175] [EDMD-Based Robust Observer Synthesis for Nonlinear Systems](https://arxiv.org/abs/2509.09812)
*Xiuzhen Ye,Wentao Tang*

Main category: eess.SY

TL;DR: 提出基于数据驱动的Koopman算子框架，为非线性系统设计鲁棒状态观测器，通过半定规划保证观测器指数收敛


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统状态观测器设计中统计误差容限与收敛性保证之间的差距，利用数据驱动线性替代模型应用线性系统理论

Method: 基于扩展动态模式分解识别Koopman生成器的有限维替代，在具有锥形不确定性的数据驱动模型上构建观测器设计问题，转化为线性矩阵不等式的半定规划

Result: 数值研究表明该方法具有有效性和灵活性，能在概率意义上保证观测器以预定速率指数收敛

Conclusion: 该方法成功桥接了统计误差容限与观测器收敛性认证之间的鸿沟，为非线性系统的数据驱动状态观测提供了有效框架

Abstract: This paper presents a data driven Koopman operator based framework for
designing robust state observers for nonlinear systems. Based on a finite
dimensional surrogate of the Koopman generator, identified via an extended
dynamic mode decomposition procedure, a tractable formulation of the observer
design is enabled on the data driven model with conic uncertainties. The
resulting problem is cast as a semidefinite program with linear matrix
inequalities, guaranteeing exponential convergence of the observer with a
predetermined rate in a probabilistic sense. The approach bridges the gap
between statistical error tolerance and observer convergence certification, and
enables an explicit use of linear systems theory for state observation via a
data driven linear surrogate model. Numerical studies demonstrate the
effectiveness and flexibility of the proposed method.

</details>


### [176] [Off Policy Lyapunov Stability in Reinforcement Learning](https://arxiv.org/abs/2509.09863)
*Sarvan Gill,Daniela Constantinescu*

Main category: eess.SY

TL;DR: 提出一种离策略学习Lyapunov函数的方法，结合SAC和PPO算法，提供数据高效稳定性保证


<details>
  <summary>Details</summary>
Motivation: 传统强化学习缺乏稳定性保证，现有基于策略的Lyapunov函数学习方法样本效率低

Method: 开发离策略Lyapunov函数学习方法，并将其整合到Soft Actor Critic和Proximal Policy Optimization算法中

Result: 在倒立摆和四旋翼飞行器仿真中，使用离策略Lyapunov函数的算法性能显著提升

Conclusion: 离策略Lyapunov函数学习能够为强化学习算法提供数据高效的稳定性证书，提高学习效率

Abstract: Traditional reinforcement learning lacks the ability to provide stability
guarantees. More recent algorithms learn Lyapunov functions alongside the
control policies to ensure stable learning. However, the current self-learned
Lyapunov functions are sample inefficient due to their on-policy nature. This
paper introduces a method for learning Lyapunov functions off-policy and
incorporates the proposed off-policy Lyapunov function into the Soft Actor
Critic and Proximal Policy Optimization algorithms to provide them with a data
efficient stability certificate. Simulations of an inverted pendulum and a
quadrotor illustrate the improved performance of the two algorithms when
endowed with the proposed off-policy Lyapunov function.

</details>


### [177] [Leveraging Predictions in Power System Voltage Control: An Adaptive Approach](https://arxiv.org/abs/2509.09937)
*Wenqi Cui,Yiheng Xie,Steven Low,Adam Wierman,Baosen Zhang*

Main category: eess.SY

TL;DR: 提出一种针对具有显著时变净负荷电力系统的自适应电压控制方法，利用短期负荷预测和强化学习优化控制策略，实现去中心化的输入到状态稳定性。


<details>
  <summary>Details</summary>
Motivation: 太阳能光伏的高变异性与负荷突变（如电动汽车和储能）会导致配电系统出现大电压波动。现有控制器通常假设净负荷在足够长时间内保持恒定，但可再生能源的间歇性和不确定性使得必须显式考虑时变净负荷。

Method: 利用短期负荷预测技术，通过局部测量部分预测系统净负荷，将这些预测集成到自适应控制器设计中，并通过强化学习优化控制策略。

Result: 案例研究使用真实世界配电系统的时变负荷数据，证明了所提控制架构能够以去中心化方式实现输入到状态稳定性。

Conclusion: 该方法为具有显著时变净负荷的电力系统提供了一种有效的自适应电压控制解决方案，解决了可再生能源间歇性带来的挑战。

Abstract: High variability of solar PV and sudden changes in load (e.g., electric
vehicles and storage) can lead to large voltage fluctuations in the
distribution system. In recent years, a number of controllers have been
designed to optimize voltage control. These controllers, however, almost always
assume that the net load in the system remains constant over a sufficiently
long time, such that the control actions converge before the load changes
again. Given the intermittent and uncertain nature of renewable resources, it
is becoming important to explicitly consider net load that is time-varying.
  This paper proposes an adaptive approach to voltage control in power systems
with significant time-varying net load. We leverage advances in short-term load
forecasting, where the net load in the system can be partially predicted using
local measurements. We integrate these predictions into the design of adaptive
controllers, and prove that the overall control architecture achieves
input-to-state stability in a decentralized manner. We optimize the control
policy through reinforcement learning. Case studies are conducted using
time-varying load data from a real-world distribution system.

</details>


### [178] [Ruggedized Ultrasound Sensing in Harsh Conditions: eRTIS in the wild](https://arxiv.org/abs/2509.10029)
*Dennis Laurijssen,Wouter Jansen,Arne Aerts,Walter Daems,Jan Steckel*

Main category: eess.SY

TL;DR: eRTIS是一个用于恶劣工业环境的坚固嵌入式超声波传感系统，具有宽带电容换能器和32元件MEMS麦克风阵列，支持2D和3D波束成形，采用模块化硬件架构和GPU加速信号处理。


<details>
  <summary>Details</summary>
Motivation: 开发能够在恶劣工业环境中可靠工作的超声波传感系统，以解决光学系统在特定条件下性能下降的问题。

Method: 采用模块化硬件架构，分离传感和处理任务：高性能微控制器处理激励信号生成和数据采集，NVIDIA Jetson模块进行GPU加速信号处理。支持外部同步和多种触发选项。

Result: 在港口系泊、越野机器人和杂乱环境自主导航三个现场场景中验证了性能，证明eRTIS在光学系统性能下降的情况下仍能提供稳健的传感能力。

Conclusion: eRTIS系统通过坚固的设计和先进的信号处理技术，成功实现了在恶劣工业环境中的可靠超声波传感，为光学系统受限的应用场景提供了有效的替代方案。

Abstract: We present eRTIS, a rugged, embedded ultrasound sensing system for use in
harsh industrial environments. The system features a broadband capacitive
transducer and a 32-element MEMS microphone array capable of 2D and 3D
beamforming. A modular hardware architecture separates sensing and processing
tasks: a high-performance microcontroller handles excitation signal generation
and data acquisition, while an NVIDIA Jetson module performs GPU-accelerated
signal processing. eRTIS supports external synchronization via a custom
controller that powers and coordinates up to six devices, either simultaneously
or in a defined sequence. Additional synchronization options include
bidirectional triggering and in-band signal injection. A sealed, anodized
aluminum enclosure with passive cooling and IP-rated connectors ensures
reliability in challenging conditions. Performance is demonstrated in three
field scenarios: harbor mooring, off-road robotics, and autonomous navigation
in cluttered environments, demonstrates that eRTIS provides robust sensing in
situations where optical systems degrade.

</details>


### [179] [Understanding the Geometry of Faulted Power Systems under High Penetration of Inverter-Based Resources via Ellipse Fitting and Geometric Algebra](https://arxiv.org/abs/2509.10044)
*Jorge Ventura,Jaroslav Hrdina,Aleš Návrat,Marek Stodola,Ahmad Eid,Santiago Sanchez-Acevedo,Francisco G. Montoya*

Main category: eess.SY

TL;DR: 提出了一种基于椭圆拟合和几何代数的电力故障检测与分类方法，能够快速检测线路故障并准确分类，解决了高比例逆变器资源电力系统中传统距离保护的局限性。


<details>
  <summary>Details</summary>
Motivation: 高比例逆变器资源(IBR)电力系统对传统保护方案构成重大挑战，传统距离保护方法在不对称条件下无法有效检测线间故障，需要开发新的故障检测技术。

Method: 使用椭圆拟合和几何代数分析电压和电流空间曲线，通过拟合电压矢量数据的椭圆来表征电气故障，仅需四分之一周期即可检测故障。采用双矢量分量进行线地故障分类，椭圆参数识别线间和三相故障。

Result: 通过仿真和实验室实验验证，该方法能够准确识别故障并估计故障幅值，提供了增强的电力系统保护能力。

Conclusion: 基于椭圆拟合和几何代数的方法有效解决了传统保护方案在高比例IBR系统中的局限性，实现了快速准确的故障检测和分类，为电力系统保护提供了新的解决方案。

Abstract: Power systems with high penetration of inverter-based resources (IBR) present
significant challenges for conventional protection schemes, with traditional
distance protection methods failing to detect line-to-line faults during
asymmetric conditions. This paper presents a methodology for electrical fault
detection and classification using ellipse fitting and geometric algebra
applied to voltage and current space curves. The approach characterizes
electrical faults by fitting ellipses to voltage vector data, enabling fault
detection with only a quarter-cycle. The method employs bivector components for
line-to-ground fault classification, while ellipse parameters identify
line-to-line and three-phase faults. The geometric representation preserves
voltage or current curve shapes in three-dimensional space, overcoming Clarke
transform limitations when zero-sequence components are present. Validation
using simulations and laboratory experiments demonstrates accurate fault
identification and magnitude estimation, providing enhanced power system
protection capabilities.

</details>


### [180] [Data-driven optimization of sparse sensor placement in thermal hydraulic experiments](https://arxiv.org/abs/2509.10055)
*Xicheng Wang,Yun. Feng,Dmitry Grishchenko,Pavel Kudinov,Ruifeng Tian,Sichao Tan*

Main category: eess.SY

TL;DR: 开发数据驱动的热工水力实验传感器优化布置框架，通过敏感性分析、POD降维和QR分解确定最优传感器配置，在TALL-3D铅铋回路实验中验证有效性


<details>
  <summary>Details</summary>
Motivation: 热工水力实验中的传感器通常稀疏分布，提供有限的空间覆盖，传统手动确定传感器位置的方法依赖专家经验，需要系统化、自动化的优化方法

Method: 提出三阶段框架：(1)敏感性分析构建数据集，(2)本征正交分解(POD)进行降维，(3)带列主元的QR分解确定空间约束下的最优传感器配置

Result: 在TALL-3D铅铋回路实验中验证，优化后的热电偶对不确定输入参数变化高度敏感，能够实现准确全场重建，且对测量噪声具有鲁棒性

Conclusion: 该框架为热工水力实验提供了系统化、自动化的传感器布置方法，相比传统手动方法更加科学有效，特别适用于无法使用光学测量技术的场景

Abstract: Thermal-Hydraulic (TH) experiments provide valuable insight into the physics
of heat and mass transfer and qualified data for code development, calibration
and validation. However, measurements are typically collected from sparsely
distributed sensors, offering limited coverage over the domain of interest and
phenomena of interest. Determination of the spatial configuration of these
sensors is crucial and challenging during the pre-test design stage. This paper
develops a data-driven framework for optimizing sensor placement in TH
experiments, including (i) a sensitivity analysis to construct datasets, (ii)
Proper Orthogonal Decomposition (POD) for dimensionality reduction, and (iii)
QR factorization with column pivoting to determine optimal sensor configuration
under spatial constraints. The framework is demonstrated on a test conducted in
the TALL-3D Lead-bismuth eutectic (LBE) loop. In this case, the utilization of
optical techniques, such as Particle Image Velocimetry (PIV), are impractical.
Thereby the quantification of momentum and energy transport relies heavily on
readings from Thermocouples (TCs). The test section was previously instrumented
with many TCs determined through a manual process combining simulation results
with expert judgement. The proposed framework provides a systematic and
automated approach for sensor placement. The resulting TCs exhibit high
sensitivity to the variation of uncertain input parameters and enable accurate
full field reconstruction while maintaining robustness against measurement
noise.

</details>


### [181] [Scalable Synthesis and Verification of String Stable Neural Certificates for Interconnected Systems](https://arxiv.org/abs/2509.10118)
*Jingyuan Zhou,Haoze Wu,Haokun Yu,Kaidi Yang*

Main category: eess.SY

TL;DR: 提出一个结合离散时间可扩展输入到状态稳定性(sISS)与神经网络验证的框架，为基于神经网络的互联系统提供形式化的串稳定性保证


<details>
  <summary>Details</summary>
Motivation: 学习型控制器(如强化学习)在复杂控制场景中表现优异，但其黑盒特性阻碍了形式化的串稳定性保证，需要解决这一差距

Method: 建立离散时间sISS形式化框架，构建神经sISS证书，引入验证程序，考虑真实动力学与神经近似之间的差异，开发可扩展训练和验证算法，处理外部控制输入

Result: 在混合自主车队、无人机编队和微电网场景中验证，数值模拟显示框架能保证sISS且控制性能下降最小，能高效训练和验证大规模互联系统的控制器

Conclusion: 该框架为基于神经网络的互联系统提供了形式化的串稳定性保证，在保持控制性能的同时实现了可扩展的验证和合成

Abstract: Ensuring string stability is critical for the safety and efficiency of
large-scale interconnected systems. Although learning-based controllers (e.g.,
those based on reinforcement learning) have demonstrated strong performance in
complex control scenarios, their black-box nature hinders formal guarantees of
string stability. To address this gap, we propose a novel verification and
synthesis framework that integrates discrete-time scalable input-to-state
stability (sISS) with neural network verification to formally guarantee string
stability in interconnected systems. Our contributions are four-fold. First, we
establish a formal framework for synthesizing and robustly verifying
discrete-time scalable input-to-state stability (sISS) certificates for neural
network-based interconnected systems. Specifically, our approach extends the
notion of sISS to discrete-time settings, constructs neural sISS certificates,
and introduces a verification procedure that ensures string stability while
explicitly accounting for discrepancies between the true dynamics and their
neural approximations. Second, we establish theoretical foundations and
algorithms to scale the training and verification pipeline to large-scale
interconnected systems. Third, we extend the framework to handle systems with
external control inputs, thereby allowing the joint synthesis and verification
of neural certificates and controllers. Fourth, we validate our approach in
scenarios of mixed-autonomy platoons, drone formations, and microgrids.
Numerical simulations show that the proposed framework not only guarantees sISS
with minimal degradation in control performance but also efficiently trains and
verifies controllers for large-scale interconnected systems under specific
practical conditions.

</details>


### [182] [MPC for Aquifer Thermal Energy Storage Systems Using ARX Models](https://arxiv.org/abs/2509.10154)
*Johannes van Randenborgh,Moritz Schulze Darup*

Main category: eess.SY

TL;DR: 本文提出了一种基于ARX模型的轻量级预测控制方法，用于优化含水层热能储存(ATES)系统的控制，避免复杂的地温状态估计，通过数值研究验证了预测精度和控制性能。


<details>
  <summary>Details</summary>
Motivation: ATES系统可以降低建筑HVAC系统的碳排放，但其控制具有挑战性。现有控制方案包括模型预测控制(MPC)，但需要解决复杂的地温状态估计问题。

Method: 开发了基于输入输出数据的自回归外生输入(ARX)轻量级模型，用于设计基于输出的MPC方案，形成易于求解的二次规划问题。

Result: 数值研究表明，ARX预测器具有较高的准确性，控制器性能表现良好。

Conclusion: 提出的ARX模型为基础的控制方案为ATES系统提供了一种有效的轻量级控制方法，避免了复杂的状态估计问题。

Abstract: An aquifer thermal energy storage (ATES) can mitigate CO2 emissions of
heating, ventilation, and air conditioning (HVAC) systems for buildings. In
application, an ATES keeps large quantities of thermal energy in
groundwater-saturated aquifers. Normally, an ATES system comprises two (one for
heat and one for cold) storages and supports the heating and cooling efforts of
simultaneously present HVAC system components. This way, the operation and
emissions of installed and, usually, fossil fuel-based components are reduced.
  The control of ATES systems is challenging, and various control schemes,
including model predictive control (MPC), have been proposed. In this context,
we present a lightweight input-output-data-based autoregressive with exogenous
input (ARX) model of the hybrid ATES system dynamics. The ARX model allows the
design of an output-based MPC scheme, resulting in an easy-to-solve quadratic
program and avoiding challenging state estimations of ground temperatures. A
numerical study discusses the accuracy of the ARX predictor and controller
performance.

</details>


### [183] [Learning Constraint Surrogate Model for Two-stage Stochastic Unit Commitment](https://arxiv.org/abs/2509.10246)
*Amir Bahador Javadi,Amin Kargarian,Mort Naraghi-Pour*

Main category: eess.SY

TL;DR: 使用机器学习替代模型简化随机机组组合问题的计算复杂度，通过SVM将大量传输线约束转换为少量线性约束，显著降低计算时间


<details>
  <summary>Details</summary>
Motivation: 可再生能源渗透率增加导致电力系统运行不确定性增强，传统确定性机组组合方法计算成本高昂，需要开发更高效的计算方法

Method: 采用支持向量机(SVM)构建替代模型，基于DC潮流近似的多面体结构理论，将2|L|*|S|个传输线约束转换为1*|S|个线性不等式约束

Result: 在IEEE 57和118总线系统中，SVM半空间约束准确率分别达到99.72%和99.88%，计算时间减少46%和31%，发电成本仅增加0.63%和0.88%

Conclusion: 该方法能有效处理可再生能源不确定性下的电力系统运行问题，具有实际应用价值

Abstract: The increasing penetration of renewable energy sources introduces significant
uncertainty in power system operations, making traditional deterministic unit
commitment approaches computationally expensive. This paper presents a machine
learning surrogate modeling approach designed to reformulate the feasible
design space of the two-stage stochastic unit commitment (TSUC) problem,
reducing its computational complexity. The proposed method uses a support
vector machine (SVM) to construct a surrogate model based on the governing
equations of the learner. This model replaces the original 2|L| * |S|
transmission line flow constraints, where |S| is the number of uncertainty
scenarios and |L| is the number of transmission lines with |S| much less than
|L|, with a significantly reduced set of 1 * |S| linear inequality constraints.
The approach is theoretically grounded in the polyhedral structure of the
feasible region under the DC power flow approximation, enabling the
transformation of 2|L| line flow limit constraints into a single linear
constraint. The surrogate model is trained using data generated from
computationally efficient DC optimal power flow simulations. Simulation results
on the IEEE 57-bus and 118-bus systems demonstrate SVM halfspace constraint
accuracy of 99.72% and 99.88%, respectively, with TSUC computational time
reductions of 46% and 31% and negligible generation cost increases (0.63% and
0.88% on average for IEEE 57- and 118-bus systems, respectively). This shows
the effectiveness of the proposed approach for practical power system
operations under renewable energy uncertainty.

</details>


### [184] [Data-fused Model Predictive Control with Guarantees: Application to Flying Humanoid Robots](https://arxiv.org/abs/2509.10353)
*Davide Gorbani,Mohamed Elobaid,Giuseppe L'Erario,Hosameldin Awadalla Omer Mohamed,Daniele Pucci*

Main category: eess.SY

TL;DR: 提出数据融合模型预测控制框架，结合物理模型与数据驱动表示，处理未知动态和测量噪声，在飞行人形机器人上验证有效


<details>
  <summary>Details</summary>
Motivation: 传统模型预测控制依赖精确物理模型，但实际系统往往存在未知动态和噪声，需要结合数据驱动方法来提升控制性能

Method: 基于Willems基本引理和人工平衡点公式，将物理模型与数据驱动的未知动态表示相结合，使用松弛变量和正则化处理测量噪声

Result: 在iRonCub飞行人形机器人上验证，相比纯模型MPC具有更好的跟踪性能和鲁棒性，同时保持实时可行性

Conclusion: DFMPC框架成功整合了物理模型和数据驱动方法，为处理具有未知动态和噪声的系统提供了有效的控制解决方案

Abstract: This paper introduces a Data-Fused Model Predictive Control (DFMPC) framework
that combines physics-based models with data-driven representations of unknown
dynamics. Leveraging Willems' Fundamental Lemma and an artificial equilibrium
formulation, the method enables tracking of changing, potentially unreachable
setpoints while explicitly handling measurement noise through slack variables
and regularization. We provide guarantees of recursive feasibility and
practical stability under input-output constraints for a specific class of
reference signals. The approach is validated on the iRonCub flying humanoid
robot, integrating analytical momentum models with data-driven turbine
dynamics. Simulations show improved tracking and robustness compared to a
purely model-based MPC, while maintaining real-time feasibility.

</details>


### [185] [Merging Physics-Based Synthetic Data and Machine Learning for Thermal Monitoring of Lithium-ion Batteries: The Role of Data Fidelity](https://arxiv.org/abs/2509.10380)
*Yusheng Zheng,Wenxue Liu,Yunhong Che,Ferdinand Grimm,Jingyuan Zhao,Xiaosong Hu,Simona Onori,Remus Teodorescu,Gregory J. Offer*

Main category: eess.SY

TL;DR: 基于物理模型与机器学习融合的框架，通过模拟数据预训练和过度学习，实现了高精度的电池内部温度估计，最低错误仅0.1℃


<details>
  <summary>Details</summary>
Motivation: 电池内部温度直接测量困难，需要发展准确、实时的估算算法来支持更好的热管理和安全

Method: 融合物理基础模型与机器学习：先利用物理模型生成模拟数据预训练ML模型，然后通过过度学习和无监督域适配把模型调整到实际电池

Result: 在不同运行条件和多个圆柱电池上验证，根据平方误差仅0.5℃（仅使用热物理知识）和小于0.1℃（使用接近真实值的热参数）

Conclusion: 该框架能够有效解决数据收集、模型参数化和估计器设计的传统挑战，并确认了模拟数据质量对ML模型性能的关键作用

Abstract: Since the internal temperature is less accessible than surface temperature,
there is an urgent need to develop accurate and real-time estimation algorithms
for better thermal management and safety. This work presents a novel framework
for resource-efficient and scalable development of accurate, robust, and
adaptive internal temperature estimation algorithms by blending physics-based
modeling with machine learning, in order to address the key challenges in data
collection, model parameterization, and estimator design that traditionally
hinder both approaches. In this framework, a physics-based model is leveraged
to generate simulation data that includes different operating scenarios by
sweeping the model parameters and input profiles. Such a cheap simulation
dataset can be used to pre-train the machine learning algorithm to capture the
underlying mapping relationship. To bridge the simulation-to-reality gap
resulting from imperfect modeling, transfer learning with unsupervised domain
adaptation is applied to fine-tune the pre-trained machine learning model, by
using limited operational data (without internal temperature values) from
target batteries. The proposed framework is validated under different operating
conditions and across multiple cylindrical batteries with convective air
cooling, achieving a root mean square error of 0.5 {\deg}C when relying solely
on prior knowledge of battery thermal properties, and less than 0.1 {\deg}C
when using thermal parameters close to the ground truth. Furthermore, the role
of the simulation data quality in the proposed framework has been
comprehensively investigated to identify promising ways of synthetic data
generation to guarantee the performance of the machine learning model.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [186] [Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building](https://arxiv.org/abs/2509.09906)
*Alexandra Fetsch,Iurii Savvateev,Racem Ben Romdhane,Martin Wiedmann,Artemiy Dimov,Maciej Durkalec,Josef Teichmann,Jakob Zinsstag,Konstantinos Koutsoumanis,Andreja Rajkovic,Jason Mann,Mauro Tonolla,Monika Ehling-Schulz,Matthias Filter,Sophia Johler*

Main category: cs.MA

TL;DR: 提出了一个AI辅助的谈判框架，利用大语言模型和自主代理来应对复杂全球挑战中的跨部门协商问题，通过模拟谈判和语义分析来缓解信息过载并增强决策过程。


<details>
  <summary>Details</summary>
Motivation: 传统风险分析框架往往简化复杂性并形成信息孤岛，阻碍了全面解决方案的制定。面对有限时间、海量信息和多元视角整合的挑战，需要一种新的方法来促进不同部门间的有效协商和利益平衡。

Method: 开发了一个基于大语言模型和AI自主代理的谈判中心化风险分析工作流框架，允许利益相关者模拟谈判、系统建模动态、预测妥协方案并评估解决方案影响。

Result: 在两个真实场景（生物农药的审慎使用和野生动物种群控制）中进行了概念验证实施，证明了AI辅助谈判在解决跨部门参与工具缺乏问题上的潜力。

Conclusion: 该开源、基于Web的解决方案适合资源有限的广泛用户群体使用，并允许用户根据自身需求进行定制和开发，展示了AI辅助协商在应对复杂全球挑战中的重要价值。

Abstract: Key global challenges of our times are characterized by complex
interdependencies and can only be effectively addressed through an integrated,
participatory effort. Conventional risk analysis frameworks often reduce
complexity to ensure manageability, creating silos that hinder comprehensive
solutions. A fundamental shift towards holistic strategies is essential to
enable effective negotiations between different sectors and to balance the
competing interests of stakeholders. However, achieving this balance is often
hindered by limited time, vast amounts of information, and the complexity of
integrating diverse perspectives. This study presents an AI-assisted
negotiation framework that incorporates large language models (LLMs) and
AI-based autonomous agents into a negotiation-centered risk analysis workflow.
The framework enables stakeholders to simulate negotiations, systematically
model dynamics, anticipate compromises, and evaluate solution impacts. By
leveraging LLMs' semantic analysis capabilities we could mitigate information
overload and augment decision-making process under time constraints.
Proof-of-concept implementations were conducted in two real-world scenarios:
(i) prudent use of a biopesticide, and (ii) targeted wild animal population
control. Our work demonstrates the potential of AI-assisted negotiation to
address the current lack of tools for cross-sectoral engagement. Importantly,
the solution's open source, web based design, suits for application by a
broader audience with limited resources and enables users to tailor and develop
it for their own needs.

</details>


### [187] [A Holistic Architecture for Monitoring and Optimization of Robust Multi-Agent Path Finding Plan Execution](https://arxiv.org/abs/2509.10284)
*David Zahrádka,Denisa Mužíková,David Woller,Miroslav Kulich,Jiří Švancara,Roman Barták*

Main category: cs.MA

TL;DR: 提出了一种用于多智能体路径规划(MAPF)的鲁棒执行架构，通过监控和优化来应对机器人延迟问题，使用动作依赖图预测执行时间并决定何时重新规划


<details>
  <summary>Details</summary>
Motivation: 在多智能体路径规划的实际执行中，机器人可能会发生延迟，虽然现有鲁棒执行方法能确保安全性，但延迟会显著影响执行时间。当延迟累积到一定程度时，重新规划可能比继续执行原计划更高效，但重新规划成本高昂，需要智能决策时机

Method: 提出整体架构用于MAPF计划的鲁棒执行、监控和优化。利用动作依赖图(ADG)方法在计划执行过程中维护预期执行时间的估计，该估计用于预测寻找替代计划是否能缩短执行时间

Result: 在设计的实时模拟器中进行了实证评估，该模拟器模拟了自主仓库机器人车队的真实演示环境

Conclusion: 该架构能够有效监控MAPF计划的执行状态，通过动作依赖图预测执行时间，智能判断重新规划的时机，从而在机器人延迟情况下优化整体执行效率

Abstract: The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a
fleet of agents moving in a shared environment such that the agents reach their
goals without colliding with each other. In practice, some of the robots
executing the plan may get delayed, which can introduce collision risk.
Although robust execution methods are used to ensure safety even in the
presence of delays, the delays may still have a significant impact on the
duration of the execution. At some point, the accumulated delays may become
significant enough that instead of continuing with the execution of the
original plan, even if it was optimal, there may now exist an alternate plan
which will lead to a shorter execution. However, the problem is how to decide
when to search for the alternate plan, since it is a costly procedure. In this
paper, we propose a holistic architecture for robust execution of MAPF plans,
its monitoring and optimization. We exploit a robust execution method called
Action Dependency Graph to maintain an estimate of the expected execution
duration during the plan's execution. This estimate is used to predict the
potential that finding an alternate plan would lead to shorter execution. We
empirically evaluate the architecture in experiments in a real-time simulator
which we designed to mimic our real-life demonstrator of an autonomous
warehouse robotic fleet.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [188] [LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm](https://arxiv.org/abs/2509.09707)
*Camilo Chacón Sartori,Martín Isla Pino,Pedro Pinacho-Davidson,Christian Blum*

Main category: cs.NE

TL;DR: 本文提出了一种将大型语言模型(LLM)与偏置随机密钥遗传算法(BRKGA)结合的新框架，用于解决NP难的最长运行子序列问题，通过LLM分析实例特定指标来生成定制化的启发式偏置，显著提升了算法性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多利用LLM进行代码生成来创建或改进特定启发式算法，但往往忽略了单个问题实例的结构特性。本文旨在通过LLM与人类协作设计计算高效指标，为元启发式算法提供实例驱动的启发式偏置。

Method: 提出人类-LLM协作流程，共同设计和实现一组计算高效指标。LLM分析这些实例特定指标来生成定制化的启发式偏置，指导BRKGA算法在搜索空间中向有希望的区域探索。

Result: 在1,050个不同复杂度的生成实例上进行全面实验评估，包括严格的统计检验、收敛和行为分析以及针对性消融研究。最佳混合方法BRKGA+Llama-4-Maverick相比标准BRKGA基线取得了统计显著的改进，特别是在最复杂的实例上表现尤为突出。

Conclusion: 利用LLM产生先验的、实例驱动的启发式偏置是增强复杂优化领域中元启发式算法性能的有效方法，证实了LLM在元启发式算法集成中的价值。

Abstract: Integrating Large Language Models (LLMs) within metaheuristics opens a novel
path for solving complex combinatorial optimization problems. While most
existing approaches leverage LLMs for code generation to create or refine
specific heuristics, they often overlook the structural properties of
individual problem instances. In this work, we introduce a novel framework that
integrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the
NP-hard Longest Run Subsequence problem. Our approach extends the
instance-driven heuristic bias paradigm by introducing a human-LLM
collaborative process to co-design and implement a set of computationally
efficient metrics. The LLM analyzes these instance-specific metrics to generate
a tailored heuristic bias, which steers the BRKGA toward promising areas of the
search space. We conduct a comprehensive experimental evaluation, including
rigorous statistical tests, convergence and behavioral analyses, and targeted
ablation studies, comparing our method against a standard BRKGA baseline across
1,050 generated instances of varying complexity. Results show that our
top-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically
significant improvements over the baseline, particularly on the most complex
instances. Our findings confirm that leveraging an LLM to produce an a priori,
instance-driven heuristic bias is a valuable approach for enhancing
metaheuristics in complex optimization domains.

</details>


### [189] [Predictive Spike Timing Enables Distributed Shortest Path Computation in Spiking Neural Networks](https://arxiv.org/abs/2509.10077)
*Simen Storesund,Kristian Valset Aars,Robin Dietrich,Nicolai Waniek*

Main category: cs.NE

TL;DR: 提出了一种基于脉冲时间机制的生物合理性最短路径算法，通过局部脉冲消息传递和时序压缩实现，无需全局状态或反向追踪


<details>
  <summary>Details</summary>
Motivation: 现有图算法需要全局状态和生物上不可信的操作，而强化学习方法依赖缓慢的梯度更新，与生物系统的快速行为适应不符

Method: 利用脉冲时序巧合识别最优路径节点，通过抑制-兴奋消息对的早期接收来减少响应延迟，实现从目标到源的时间压缩传播

Result: 算法收敛并能发现所有最短路径，通过纯时序机制在随机空间网络上验证了有效性

Conclusion: 展示了短期时序动态如何单独计算最短路径，为理解生物网络如何通过局部计算解决复杂问题提供了新视角，对计算神经科学、AI和神经形态系统有重要意义

Abstract: Efficient planning and sequence selection are central to intelligence, yet
current approaches remain largely incompatible with biological computation.
Classical graph algorithms like Dijkstra's or A* require global state and
biologically implausible operations such as backtracing, while reinforcement
learning methods rely on slow gradient-based policy updates that appear
inconsistent with rapid behavioral adaptation observed in natural systems.
  We propose a biologically plausible algorithm for shortest-path computation
that operates through local spike-based message-passing with realistic
processing delays. The algorithm exploits spike-timing coincidences to identify
nodes on optimal paths: Neurons that receive inhibitory-excitatory message
pairs earlier than predicted reduce their response delays, creating a temporal
compression that propagates backwards from target to source. Through analytical
proof and simulations on random spatial networks, we demonstrate that the
algorithm converges and discovers all shortest paths using purely timing-based
mechanisms. By showing how short-term timing dynamics alone can compute
shortest paths, this work provides new insights into how biological networks
might solve complex computational problems through purely local computation and
relative spike-time prediction. These findings open new directions for
understanding distributed computation in biological and artificial systems,
with possible implications for computational neuroscience, AI, reinforcement
learning, and neuromorphic systems.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [190] [Merging Bodies, Dividing Conflict: Body-Swapping in Mixed Reality Increases Closeness Yet Weakens the Joint Simon Effect](https://arxiv.org/abs/2509.09815)
*Yuan He,Brendan Rooney,Rachel McDonnell*

Main category: cs.HC

TL;DR: 本研究探讨了混合现实中的身体交换如何影响自我与他人认知边界，发现身体交换让参与者体验到自己和伴侣像一个统一系统运作


<details>
  <summary>Details</summary>
Motivation: 混合现实为研究共享增强体验中的自我和他人感知提供了新机会，但身体交换（两人同时占据对方虚拟化身）及其对社交互动的影响尚未充分探索

Method: 采用联合西蒙任务（JST）这一成熟的隐式范式，在沉浸式环境中研究身体交换对自我-他人认知边界的影响

Result: 身体交换导致参与者将自己和伴侣体验为像一个单一统一系统运作，如同两个身体作为一个代理行动，超越了简单协作的认知和感知变化

Conclusion: 研究结果对设计支持协作、共情、社会学习和治疗干预的混合现实系统具有重要意义，通过共享具身体验实现更深层次的社会连接

Abstract: Mixed Reality (MR) presents novel opportunities to investigate how
individuals perceive themselves and others during shared, augmented experiences
within a common physical environment. Previous research has demonstrated that
users can embody avatars in MR, temporarily extending their sense of self.
However, there has been limited exploration of body-swapping, a condition in
which two individuals simultaneously inhabit each other's avatars, and its
potential effects on social interaction in immersive environments. To address
this gap, we adapted the Joint Simon Task (JST), a well-established implicit
paradigm, to examine how body-swapping influences the cognitive and perceptual
boundaries between self and other. Our results indicate that body-swapping led
participants to experience themselves and their partner as functioning like a
single, unified system, as in two bodies operating as one agent. This suggests
possible cognitive and perceptual changes that go beyond simple collaboration.
Our findings have significant implications for the design of MR systems
intended to support collaboration, empathy, social learning, and therapeutic
interventions through shared embodiment.

</details>


### [191] [Designing and Evaluating AI Margin Notes in Document Reader Software](https://arxiv.org/abs/2509.09840)
*Nikhita Joshi,Daniel Vogel*

Main category: cs.HC

TL;DR: 研究探索将AI集成到文档注释中（称为AI边注），通过三个设计参数（集成程度、选择自动化程度、AI参与程度）进行实验，发现用户更喜欢集成式AI边注和手动选择，AI参与度对阅读理解无显著影响。


<details>
  <summary>Details</summary>
Motivation: 传统的AI文档阅读功能通常在单独的聊天界面中提供，这打断了阅读流程。研究旨在探索将AI能力直接集成到文档边注中的方法，以提供更流畅的阅读体验。

Method: 通过三个实验研究AI边注的设计参数：第一个实验比较集成式与分离式界面；第二个实验比较自动与手动文本选择；第三个实验探索六种不同人机协作技术，评估AI参与程度的影响。

Result: 参与者偏好集成式AI边注和手动文本选择；AI参与度较低的技术带来更强的心理所有权感；但更快速、省力的设计更受青睐；AI参与程度对阅读理解没有显著影响。

Conclusion: AI边注是一种可行的设计方法，集成式设计和手动选择更受欢迎，AI参与度需要平衡效率与用户控制感，这对AI文档阅读工具的设计具有重要启示。

Abstract: AI capabilities for document reader software are usually presented in
separate chat interfaces. We explore integrating AI into document comments, a
concept we formalize as AI margin notes. Three design parameters characterize
this approach: margin notes are integrated with the text while chat interfaces
are not; selecting text for a margin note can be automated through AI or
manual; and the generation of a margin note can involve AI to various degrees.
Two experiments investigate integration and selection automation, with results
showing participants prefer integrated AI margin notes and manual selection. A
third experiment explores human and AI involvement through six alternative
techniques. Techniques with less AI involvement resulted in more psychological
ownership, but faster and less effortful designs are generally preferred.
Surprisingly, the degree of AI involvement had no measurable effect on reading
comprehension. Our work shows that AI margin notes are desirable and
contributes implications for their design.

</details>


### [192] [Vibe Check: Understanding the Effects of LLM-Based Conversational Agents' Personality and Alignment on User Perceptions in Goal-Oriented Tasks](https://arxiv.org/abs/2509.09870)
*Hasibur Rahman,Smit Desai*

Main category: cs.HC

TL;DR: 研究发现AI助手个性表达水平与用户感知呈倒U型关系，中等表达水平在智能度、愉悦度、拟人化、采用意愿、信任度和好感度等方面表现最佳，个性匹配能进一步提升效果，外向性和情绪稳定性是最关键特质。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型使对话代理能够表达独特个性，需要研究个性表达水平和用户-代理个性匹配如何影响用户在目标导向任务中的感知。

Method: 采用被试间实验设计（N=150），参与者与展示低、中、高Big Five特质表达水平的对话代理完成旅行规划任务，使用新颖的Trait Modulation Keys框架控制个性表达。

Result: 结果显示倒U型关系：中等表达水平在所有评估维度（智能度、愉悦度、拟人化、采用意愿、信任度、好感度）上产生最积极评价，显著优于两个极端水平。个性匹配进一步改善结果，外向性和情绪稳定性是最有影响力的特质。聚类分析识别出三种不同的兼容性特征。

Conclusion: 个性表达和策略性特质匹配构成了对话代理个性的最佳设计目标，为基于大语言模型的对话代理设计提供了重要启示。

Abstract: Large language models (LLMs) enable conversational agents (CAs) to express
distinctive personalities, raising new questions about how such designs shape
user perceptions. This study investigates how personality expression levels and
user-agent personality alignment influence perceptions in goal-oriented tasks.
In a between-subjects experiment (N=150), participants completed travel
planning with CAs exhibiting low, medium, or high expression across the Big
Five traits, controlled via our novel Trait Modulation Keys framework. Results
revealed an inverted-U relationship: medium expression produced the most
positive evaluations across Intelligence, Enjoyment, Anthropomorphism,
Intention to Adopt, Trust, and Likeability, significantly outperforming both
extremes. Personality alignment further enhanced outcomes, with Extraversion
and Emotional Stability emerging as the most influential traits. Cluster
analysis identified three distinct compatibility profiles, with "Well-Aligned"
users reporting substantially positive perceptions. These findings demonstrate
that personality expression and strategic trait alignment constitute optimal
design targets for CA personality, offering design implications as LLM-based
CAs become increasingly prevalent.

</details>


### [193] [Climate Data for Power Systems Applications: Lessons in Reusing Wildfire Smoke Data for Solar PV Studies](https://arxiv.org/abs/2509.09888)
*Arleth Salinas,Irtaza Sohail,Valerio Pascucci,Pantelis Stefanakis,Saud Amjad,Aashish Panta,Roland Schigas,Timothy Chun-Yiu Chui,Nicolas Duboc,Mostafa Farrokhabadi,Roland Stull*

Main category: cs.HC

TL;DR: 本文通过电力系统案例研究，探讨了将地理空间野火烟雾预报数据重新用于分析野火烟雾对太阳能光伏发电影响的数据重用方法，提出了数据重用的关键促进因素和障碍。


<details>
  <summary>Details</summary>
Motivation: 随着数据共享在科学领域的普及，如何有效实现数据重用（即使用数据用于不同于其原始目的的新用途）变得越来越重要。本文旨在通过具体案例研究数据重新利用的过程和效果。

Method: 采用电力系统案例研究，将地理空间野火烟雾预报数据集重新利用为历史数据集，通过迭代式数据重新利用方法，结合在线文档、交互式可视化和数据流等知识传输基础设施。

Result: 研究发现数据重用的关键促进因素包括元数据标准化、上下文文档以及数据创建者与重用者之间的沟通；主要障碍包括误解风险和高效数据访问障碍。通过案例研究证明了所提出方法的有效性。

Conclusion: 通过迭代式数据重新利用方法，可以有效促进跨领域大数据在电力系统应用和电网弹性方面的使用，为数据重用提供了实践指导和解决方案。

Abstract: Data reuse is using data for a purpose distinct from its original intent. As
data sharing becomes more prevalent in science, enabling effective data reuse
is increasingly important. In this paper, we present a power systems case study
of data repurposing for enabling data reuse. We define data repurposing as the
process of transforming data to fit a new research purpose. In our case study,
we repurpose a geospatial wildfire smoke forecast dataset into a historical
dataset. We analyze its efficacy toward analyzing wildfire smoke impact on
solar photovoltaic energy production. We also provide documentation and
interactive demos for using the repurposed dataset. We identify key enablers of
data reuse including metadata standardization, contextual documentation, and
communication between data creators and reusers. We also identify obstacles to
data reuse such as risk of misinterpretation and barriers to efficient data
access. Through an iterative approach to data repurposing, we demonstrate how
leveraging and expanding knowledge transfer infrastructures like online
documentation, interactive visualizations, and data streaming directly address
these obstacles. The findings facilitate big data use from other domains for
power systems applications and grid resiliency.

</details>


### [194] [Seeing Identity in Data: Can Anthropographics Uncover Racial Homophily in Emotional Responses?](https://arxiv.org/abs/2509.09910)
*Poorna Talkad Sukumar,Maurizio Porfiri,Oded Nov*

Main category: cs.HC

TL;DR: 研究发现使用人形图表时，种族一致性对情感反应有显著影响，参与者看到自己种族的受害者时负面情绪变化更大


<details>
  <summary>Details</summary>
Motivation: 先前研究未发现数据可视化中的种族同质性效应，本研究通过改进实验设计（使用人形图表和扩大样本量）来增加检测效应的可能性

Method: 在众包研究（N=720）中向参与者展示美国大规模枪击事件受害者的人形图表，突出显示三个种族群体之一（西班牙裔、黑人或白人）的受害者，评估种族一致性对情感变化的影响

Result: 在所有条件下，种族一致性对情感变化都有适度但显著的影响，参与者观看突出显示自己种族的可视化时经历更大的负面情感变化

Conclusion: 这项研究提供了初步证据，表明种族同质性可以在对数据可视化的反应中出现，特别是在使用人形图表时

Abstract: Racial homophily refers to the tendency of individuals to associate with
others of the same racial or ethnic background. A recent study found no
evidence of racial homophily in responses to mass shooting data visualizations.
To increase the likelihood of detecting an effect, we redesigned the experiment
by replacing bar charts with anthropographics and expanding the sample size. In
a crowdsourced study (N=720), we showed participants a pictograph of mass
shooting victims in the United States, with victims from one of three racial
groups (Hispanic, Black, or White) highlighted. Each participant was assigned a
visualization highlighting either their own racial group or a different racial
group, allowing us to assess the influence of racial concordance on changes in
affect (emotion). We found that, across all conditions, racial concordance had
a modest but significant effect on changes in affect, with participants
experiencing greater negative affect change when viewing visualizations
highlighting their own race. This study provides initial evidence that racial
homophily can emerge in responses to data visualizations, particularly when
using anthropographics.

</details>


### [195] [Immersive Invaders: Privacy Threats from Deceptive Design in Virtual Reality Games and Applications](https://arxiv.org/abs/2509.09916)
*Hilda Hadan,Michaela Valiquette,Lennart E. Nacke,Leah Zhang-Kennedy*

Main category: cs.HC

TL;DR: 该研究调查了VR环境中欺骗性设计对用户隐私的影响，发现VR独特功能会放大数据披露行为，隐私政策复杂且存在操纵性同意实践，同时观察到一些隐私保护设计策略。


<details>
  <summary>Details</summary>
Motivation: 虽然2D平台的欺骗性设计已有研究，但VR环境中的表现及其对用户隐私的影响尚不清楚，需要研究VR特有的隐私风险和设计模式。

Method: 通过自动民族志评估12个顶级VR游戏和应用的隐私通信与交互机制，并对隐私政策进行主题分析。

Result: 发现许多欺骗性设计依赖2D界面，但VR独特功能会放大数据披露行为并模糊实际数据实践；隐私政策复杂且同意实践具有操纵性；同时观察到隐私保护设计策略。

Conclusion: 提出了平衡沉浸体验与强隐私保护的道德VR设计建议，为研究人员、设计师和政策制定者改进VR隐私提供指导。

Abstract: Virtual Reality (VR) technologies offer immersive experiences but collect
substantial user data. While deceptive design is well-studied in 2D platforms,
little is known about its manifestation in VR environments and its impact on
user privacy. This research investigates deceptive designs in privacy
communication and interaction mechanisms of 12 top-rated VR games and
applications through autoethnographic evaluation of the applications and
thematic analysis of privacy policies. We found that while many deceptive
designs rely on 2D interfaces, some VR-unique features, while not directly
enabling deception, amplified data disclosure behaviors, and obscured actual
data practices. Convoluted privacy policies and manipulative consent practices
further hinder comprehension and increase privacy risks. We also observed
privacy-preserving design strategies and protective considerations in VR
privacy policies. We offer recommendations for ethical VR design that balance
immersive experiences with strong privacy protections, guiding researchers,
designers, and policymakers to improve privacy in VR environments.

</details>


### [196] [Beyond the Silence: How Men Navigate Infertility Through Digital Communities and Data Sharing](https://arxiv.org/abs/2509.10003)
*Tawfiq Ammari,Zarah Khondoker,Yihan Wang,Nikki Roda*

Main category: cs.HC

TL;DR: 该研究分析了Reddit上男性不育社区如何通过数字支持网络帮助男性克服传统男性意识形态障碍，发现该社区作为混合空间运作，提供医疗建议、情感支持和社区治理，持续参与与实用指导相关，跨社区用户充当知识传递者。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索男性不育患者如何在传统男性意识形态（抑制情感表达和求助行为）的挑战下，通过在线社区获得支持，了解数字支持网络如何帮助克服这些社会文化障碍。

Method: 研究方法包括主题建模（115个主题）、网络分析（11个微社区）和时间滞后回归分析，基于8,644名用户的11,095篇帖子和79,503条评论数据。

Result: 研究发现该社区作为混合空间运作：非正式诊断中心（医疗建议占63.3%）、治疗共享空间（情感支持占7.4%）和治理机构（管理占29.2%）。持续参与与实用指导相关，网络分析显示结构凝聚但主题多样的集群，20%的跨社区用户充当导航者和导师。

Conclusion: 结论强调该研究为受污名化健康社区的创伤知情设计提供了见解，突出了角色感知系统和导航支持的重要性，展示了在线社区如何有效支持面临独特社会文化挑战的男性不育患者。

Abstract: Men experiencing infertility face unique challenges navigating Traditional
Masculinity Ideologies that discourage emotional expression and help-seeking.
This study examines how Reddit's r/maleinfertility community helps overcome
these barriers through digital support networks. Using topic modeling (115
topics), network analysis (11 micro-communities), and time-lagged regression on
11,095 posts and 79,503 comments from 8,644 users, we found the community
functions as a hybrid space: informal diagnostic hub, therapeutic commons, and
governed institution. Medical advice dominates discourse (63.3\%), while
emotional support (7.4\%) and moderation (29.2\%) create essential
infrastructure. Sustained engagement correlates with actionable guidance and
affiliation language, not emotional processing. Network analysis revealed
structurally cohesive but topically diverse clusters without echo chamber
characteristics. Cross-posters (20\% of users) who bridge r/maleinfertility and
the gender-mixed r/infertility community serve as navigators and mentors,
transferring knowledge between spaces. These findings inform trauma-informed
design for stigmatized health communities, highlighting role-aware systems and
navigation support.

</details>


### [197] [A Framework for AI-Supported Mediation in Community-based Online Collaboration](https://arxiv.org/abs/2509.10015)
*Soobin Cho,Mark Zachry,David W. McDonald*

Main category: cs.HC

TL;DR: 本文提出一个AI支持的调解框架，专注于信息处理，用于解决在线社区协作中的冲突，强调调解比传统内容审核更能解决根本分歧。


<details>
  <summary>Details</summary>
Motivation: 在线社区协作中不可避免地会产生冲突，传统的内容审核方法只是移除或压制内容，很少解决根本分歧。调解能够促进理解、减少情绪紧张并达成共识，因此需要转向AI支持的调解方法。

Method: 提出了一个以信息为中心的AI支持调解框架，该框架要求AI获取并推理三种关键信息类型：内容信息、文化信息和人员信息。

Result: 提出了一个理论框架，但论文摘要中未提及具体的实验结果或验证数据。

Conclusion: AI支持的调解是解决在线社区冲突的有效方法，通过关注内容、文化和人员三个维度的信息，可以更好地促进协作和共识达成。

Abstract: Online spaces involve diverse communities engaging in various forms of
collaboration, which naturally give rise to discussions, some of which
inevitably escalate into conflict or disputes. To address such situations, AI
has primarily been used for moderation. While moderation systems are important
because they help maintain order, common moderation strategies of removing or
suppressing content and users rarely address the underlying disagreements or
the substantive content of disputes. Mediation, by contrast, fosters
understanding, reduces emotional tension, and facilitates consensus through
guided negotiation. Mediation not only enhances the quality of collaborative
decisions but also strengthens relationships among group members. For this
reason, we argue for shifting focus toward AI-supported mediation. In this
work, we propose an information-focused framework for AI-supported mediation
designed for community-based collaboration. Within this framework, we
hypothesize that AI must acquire and reason over three key types of
information: content, culture, and people.

</details>


### [198] [Inclusive by design: Developing Barrier-Free Authentication for Blind and Low Vision Users through the ALIAS Project](https://arxiv.org/abs/2509.10043)
*Clara Toussaint,Benjamin Chateau,Pierre-Guillaume Gourio-Jewell,Emilie Bonnefoy,Nicolas Louveton*

Main category: cs.HC

TL;DR: ALIAS项目旨在为盲人和低视力用户开发无障碍认证系统，通过认知工效学和用户体验设计方法解决数字认证中的可访问性问题


<details>
  <summary>Details</summary>
Motivation: 全球有3600万盲人用户，预计205年将达1.15亿，但现有安全系统对BLV用户存在可访问性障碍，数字服务日益重要而网络威胁也在增加

Method: 基于认知工效学和UX设计方法，首先建立BLV用户数字实践和认知模型的知识库，然后通过两次迭代开发、测试和优化原型

Result: 本文提供了该领域当前研究的概述，识别了研究空白，并介绍了项目的方法论和路径

Conclusion: 该项目致力于为BLV用户创建无障碍认证解决方案，通过系统化的研究方法填补现有研究空白

Abstract: Authentication is the cornerstone of information security in our daily lives.
However, disabled users such as Blind and Low-Vision (BLV) ones are left behind
in digital services due to the lack of accessibility. According to the World
Health Organization, 36 million people are blind worldwide. It is estimated
that there will be 115 million by 2050, due to the ageing of the population.
Yet accessing digital services has become increasingly essential. At the same
time, cyber threats targeting individuals have also increased strongly in the
last few years. The ALIAS project addresses the need for accessible digital
authentication solutions for BLV users facing challenges with digital
technology. Security systems can inhibit access for these individuals as they
become more complex. This project aims to create a barrier-free authentication
system based on cognitive ergonomics and user experience (UX) design methods
specifically for BLV users. This paper presents an overview of current research
in this area. We also identify research gaps, and finally, we present our
project's methodology and approach. First, we will build a knowledge base on
the digital practices and cognitive models of BLV users during authentication.
This information will support the development of prototypes, which will be
tested and refined through two iterations before finalizing the operational
version.

</details>


### [199] [From customer survey feedback to software improvements: Leveraging the full potential of data](https://arxiv.org/abs/2509.10064)
*Erik Bertram,Nina Hollender,Sebastian Juhl,Sandra Loop,Martin Schrepp*

Main category: cs.HC

TL;DR: 本文提出了一个端到端的实用方法，将客户调查反馈数据转化为可操作的见解，通过选择合适的指标、收集用户反馈、使用推断统计方法分析数据、实现数据透明化，并最终推动软件开发过程的变革。


<details>
  <summary>Details</summary>
Motivation: 大型软件企业在将客户调查反馈数据转化为可用见解方面面临重大挑战，主要障碍在于如何从数据中得出正确结论并将其有效融入软件开发流程。

Method: 采用端到端方法，包括选择合适度量指标、收集客户最终用户反馈、利用推断统计方法分析数据、使数据透明化，并开发UX原型仪表板向利益相关者传达分析结果。

Result: 提出了一个完整的分析框架和UX原型仪表板，能够有效提取有用信息并驱动变革，解决了从客户反馈到实际改进的转化难题。

Conclusion: 该方法为软件企业提供了一套实用的端到端解决方案，能够将客户反馈数据有效转化为驱动软件开发过程改进的 actionable insights，并通过可视化仪表板促进利益相关者之间的沟通和决策。

Abstract: Converting customer survey feedback data into usable insights has always been
a great challenge for large software enterprises. Despite the improvements on
this field, a major obstacle often remains when drawing the right conclusions
out of the data and channeling them into the software development process. In
this paper we present a practical end-to-end approach of how to extract useful
information out of a data set and leverage the information to drive change. We
describe how to choose the right metrics to measure, gather appropriate
feedback from customer end-users, analyze the data by leveraging methods from
inferential statistics, make the data transparent, and finally drive change
with the results. Furthermore, we present an example of a UX prototype
dashboard that can be used to communicate the analyses to stakeholders within
the company.

</details>


### [200] [Understanding Expert Exploration in EHR Visualization Tools: The ParcoursVis Use Case](https://arxiv.org/abs/2509.10081)
*Ambre Assor,Jean-Daniel Fekete*

Main category: cs.HC

TL;DR: 本文介绍了一种基于洞察的评估方法，用于理解医疗从业者在探索医疗数据时的心理模型，基于ParcoursVis系统进行大规模电子健康记录的可视化分析。


<details>
  <summary>Details</summary>
Motivation: 开发一种评估方法，了解医疗从业者在使用探索性可视化工具时的心理模型和探索策略，以提升医疗数据分析工具的效果。

Method: 基于ParcoursVis渐进式可视化分析系统，与16家巴黎医院急诊部门和法国社会保障机构合作，收集专家用户生成的洞察，分析其探索策略。

Result: 初步发现表明系统使用形成了一个循环，帮助完善数据变量识别和系统本身，强调了探索性工具在医疗数据分析中的实用性。

Conclusion: 提出了一种在现实世界约束下进行基于洞察研究的设计协议，为医疗数据分析工具的开发和应用提供了重要参考。

Abstract: We introduce our ongoing work toward an insight-based evaluation methodology
aimed at understanding practitioners' mental models when exploring medical
data. It is based on ParcoursVis, a Progressive Visual Analytics system
designed to visualize event sequences derived from Electronic Health Records at
scale (millions of patients, billions of events), developed in collaboration
with the Emergency Departments of 16 Parisian hospitals and with the French
Social Security. Building on prior usability validation, our current evaluation
focuses on the insights generated by expert users and aims to better understand
the exploration strategies they employ when engaging with exploration
visualization tools. We describe our system and outline our evaluation
protocol, analysis strategy, and preliminary findings. Building on this
approach and our pilot results, we contribute a design protocol for conducting
insight-based studies under real-world constraints, including the availability
of health practitioners whom we were fortunate to interview. Our findings
highlight a loop, where the use of the system helps refine data variables
identification and the system itself. We aim to shed light on generated
insights, to highlight the utility of exploratory tools in health data analysis
contexts.

</details>


### [201] [MusicScaffold: Bridging Machine Efficiency and Human Growth in Adolescent Creative Education through Generative AI](https://arxiv.org/abs/2509.10327)
*Zhejing Hu,Yan Liu,Zhi Zhang,Gong Chen,Bruce X. B. Yu,Junxian Li,Jiannong Cao*

Main category: cs.HC

TL;DR: MusicScaffold是一个面向青少年的AI音乐创作框架，将AI重新定位为引导者、教练和合作伙伴，而非单纯的生成器，旨在促进青少年的表达成长和创造力发展。


<details>
  <summary>Details</summary>
Motivation: 青少年时期具有强烈的创作冲动但缺乏结构化表达策略，容易导致挫败感或脱离。虽然生成式AI降低了技术门槛，但其在促进青少年表达成长方面的作用被忽视。

Method: 提出了MusicScaffold框架，将AI作为指导者、教练和合作伙伴，使表达策略透明可学，并支持自主性。对12-14岁初中生进行了为期四周的研究。

Result: MusicScaffold在音乐创作中增强了认知特异性、行为自我调节和情感信心。

Conclusion: 通过将生成式AI重新定义为支架而非生成器，这项工作在青少年创意教育中架起了机器效率与人类成长之间的桥梁。

Abstract: Adolescence is marked by strong creative impulses but limited strategies for
structured expression, often leading to frustration or disengagement. While
generative AI lowers technical barriers and delivers efficient outputs, its
role in fostering adolescents' expressive growth has been overlooked. We
propose MusicScaffold, the first adolescent-centered framework that repositions
AI as a guide, coach, and partner, making expressive strategies transparent and
learnable, and supporting autonomy. In a four-week study with middle school
students (ages 12--14), MusicScaffold enhanced cognitive specificity,
behavioral self-regulation, and affective confidence in music creation. By
reframing generative AI as a scaffold rather than a generator, this work
bridges the machine efficiency of generative systems with human growth in
adolescent creative education.

</details>


### [202] [Who Decides How Knowing Becomes Doing? Redistributing Authority in Human-AI Music Co-Creation](https://arxiv.org/abs/2509.10331)
*Zhejing Hu,Yan Liu,Zhi Zhang,Gong Chen,Bruce X. B. Yu,Jiannong Cao*

Main category: cs.HC

TL;DR: 提出了首个系统性框架，通过可争议性、能动性和多元性三个原则重新分配人机协作中的权威关系，重塑人类创造性表达


<details>
  <summary>Details</summary>
Motivation: 主流AI工具往往集中解释权威并同质化表达，压制边缘声音，需要解决人机协作中从知道到执行的权威分配问题

Method: 基于三个原则（可争议性、能动性、多元性）构建系统性框架，通过180名音乐从业者的交互研究和深度访谈进行验证

Result: 这些原则能够重塑人机权威关系并重新激活人类创造性表达

Conclusion: 建立了一个从批判到实践的关键计算和人机共创新范式

Abstract: In the era of human-AI co-creation, the maxim "knowing is easy, doing is
hard" is redefined. AI has the potential to ease execution, yet the essence of
"hard" lies in who governs the translation from knowing to doing. Mainstream
tools often centralize interpretive authority and homogenize expression,
suppressing marginal voices. To address these challenges, we introduce the
first systematic framework for redistributing authority in the knowing-doing
cycle, built on three principles, namely contestability, agency, and plurality.
Through interactive studies with 180 music practitioners, complemented by
in-depth interviews, we demonstrate that these principles reshape human-AI
authority relations and reactivate human creative expression. The findings
establish a new paradigm for critical computing and human-AI co-creation that
advances from critique to practice.

</details>


### [203] [The Language of Approval: Identifying the Drivers of Positive Feedback Online](https://arxiv.org/abs/2509.10370)
*Agam Goyal,Charlotte Lambert,Eshwar Chandrasekharan*

Main category: cs.HC

TL;DR: 通过因果推断和预测建模分析Reddit上1100万条帖子，发现语言模式和文体特征如何影响点赞奖励，揭示社区规则与实践之间的差距


<details>
  <summary>Details</summary>
Motivation: 研究在线社区中用户帖子的哪些属性能够获得积极反馈（点赞和奖励），以及这些因素如何因作者和社区而异，为社区治理提供数据支持

Method: 结合准实验因果推断和预测建模，分析100个子版块的1100万条帖子，控制作者声誉、发布时间和社区背景等因素

Result: 发现过度复杂语言、试探性风格和毒性内容会减少奖励；训练出的模型能高精度检测高赞帖子；社区规则主要关注文明礼仪和格式要求，与驱动积极反馈的属性存在差距

Conclusion: 研究结果为社区规则设计、用户贡献质量提升界面以及强调积极强化而非纯粹惩罚的审核工作流程提供了重要见解

Abstract: Positive feedback via likes and awards is central to online governance, yet
which attributes of users' posts elicit rewards -- and how these vary across
authors and communities -- remains unclear. To examine this, we combine
quasi-experimental causal inference with predictive modeling on 11M posts from
100 subreddits. We identify linguistic patterns and stylistic attributes
causally linked to rewards, controlling for author reputation, timing, and
community context. For example, overtly complicated language, tentative style,
and toxicity reduce rewards. We use our set of curated features to train models
that can detect highly-upvoted posts with high AUC. Our audit of community
guidelines highlights a ``policy-practice gap'' -- most rules focus primarily
on civility and formatting requirements, with little emphasis on the attributes
identified to drive positive feedback. These results inform the design of
community guidelines, support interfaces that teach users how to craft
desirable contributions, and moderation workflows that emphasize positive
reinforcement over purely punitive enforcement.

</details>


### [204] [My Favorite Streamer is an LLM: Discovering, Bonding, and Co-Creating in AI VTuber Fandom](https://arxiv.org/abs/2509.10427)
*Jiayi Ye,Chaoran Chen,Yue Huang,Yanfang Ye,Toby Jia-Jun Li,Xiangliang Zhang*

Main category: cs.HC

TL;DR: 本研究通过对知名AI VTuber Neuro-sama的定性分析，揭示了AI VTuber粉丝参与的核心是主动共创，观众被AI不可预测但有趣的互动吸引，通过集体情感事件建立忠诚度，并通过AI一致的人设维持依恋。


<details>
  <summary>Details</summary>
Motivation: 人类VTuber的文化吸引力、准社会关系和社群经济已有大量研究，但观众如何与AI VTuber互动的机制尚不明确，需要填补这一研究空白。

Method: 采用定性研究方法，以最知名的AI VTuber Neuro-sama为案例进行深入分析。

Result: 发现AI VTuber粉丝参与以主动共创为基础：观众被AI不可预测但有趣的互动吸引，通过集体情感事件触发拟人化投射来巩固忠诚度，并通过AI一致的人设维持依恋。经济支持不是表演回报，而是参与塑造直播内容的机制。

Conclusion: AI VTuber粉丝文化重塑了粉丝与创作者的关系，为设计透明和可持续的AI媒介社群提供了重要启示。

Abstract: AI VTubers, where the performer is not human but algorithmically generated,
introduce a new context for fandom. While human VTubers have been substantially
studied for their cultural appeal, parasocial dynamics, and community
economies, little is known about how audiences engage with their AI
counterparts. To address this gap, we present a qualitative study of
Neuro-sama, the most prominent AI VTuber. Our findings show that engagement is
anchored in active co-creation: audiences are drawn by the AI's unpredictable
yet entertaining interactions, cement loyalty through collective emotional
events that trigger anthropomorphic projection, and sustain attachment via the
AI's consistent persona. Financial support emerges not as a reward for
performance but as a participatory mechanism for shaping livestream content,
establishing a resilient fan economy built on ongoing interaction. These
dynamics reveal how AI Vtuber fandom reshapes fan-creator relationships and
offer implications for designing transparent and sustainable AI-mediated
communities.

</details>
