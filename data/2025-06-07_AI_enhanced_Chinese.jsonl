{"id": "2506.04236", "pdf": "https://arxiv.org/pdf/2506.04236", "abs": "https://arxiv.org/abs/2506.04236", "authors": ["Botao Amber Hu", "Helena Rong"], "title": "Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs", "categories": ["cs.MA", "cs.AI", "cs.HC", "cs.NE"], "comment": "Submitted to ALIFE 2025", "summary": "In Artificial Life (ALife) research, replicating Open-Ended Evolution\n(OEE)-the continuous emergence of novelty observed in biological life-has\ntraditionally been pursued within isolated closed system simulations, such as\nTierra and Avida, which have typically plateaued after an initial burst of\nnovelty, failing to achieve sustained OEE. Scholars suggest that OEE requires\nan \"open\" system that continually exchanges information or energy with its\nenvironment. A recent technological innovation in decentralized physical\ninfrastructure networks (DePIN) providing permissionless computational\nsubstrates enables deploying large language model (LLM)-based AI agents on\nblockchains integrated with Trusted Execution Environments (TEEs). This enables\non-chain agents to operate autonomously \"in the wild,\" achieving\nself-sovereignty without human oversight. These agents can control their own\nsocial media accounts and cryptocurrency wallets, allowing them to interact\ndirectly with blockchain-based financial networks and broader human social\nmedia. Building on this new paradigm of on-chain agents, Spore.fun is a recent\nreal-world AI evolution experiment that enables autonomous breeding and\nevolution of new on-chain agents. This paper presents a detailed case study of\nSpore.fun, examining agent behaviors and their evolutionary trajectories\nthrough digital ethology. We aim to spark discussion about whether \"open\" ALife\nsystems \"in-the-wild,\" based on permissionless computational substrates and\ndriven by economic incentives to interact with their environment, could finally\nachieve the long-sought goal of OEE.", "AI": {"tldr": "论文探讨了通过开放系统（如基于区块链的AI代理）实现持续开放演化（OEE）的可能性，并以Spore.fun为例研究了其行为和演化轨迹。", "motivation": "传统封闭系统（如Tierra和Avida）在实现OEE时存在局限性，学者认为开放系统可能更有效。", "method": "利用DePIN技术和区块链上的自主AI代理（如Spore.fun），研究其行为和演化。", "result": "初步展示了开放系统在实现OEE方面的潜力。", "conclusion": "开放系统可能为ALife研究中的OEE目标提供新途径。"}}
{"id": "2506.04255", "pdf": "https://arxiv.org/pdf/2506.04255", "abs": "https://arxiv.org/abs/2506.04255", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource Utilization", "categories": ["cs.MA"], "comment": "Submitted as part of the Research Track at AgentX 2025, organized by\n  Berkeley RDI", "summary": "Rapid Large Language Model (LLM) advancements are fueling autonomous\nMulti-Agent System (MAS) development. However, current frameworks often lack\nflexibility, resource awareness, model diversity, and autonomous tool creation.\nThis paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent\nResource Utilization), a novel MAS framework enhancing flexibility, resource\nefficiency, and adaptability. HASHIRU features a \"CEO\" agent dynamically\nmanaging specialized \"employee\" agents, instantiated based on task needs and\nresource constraints (cost, memory). Its hybrid intelligence prioritizes\nsmaller, local LLMs (via Ollama) while flexibly using external APIs and larger\nmodels when necessary. An economic model with hiring/firing costs promotes team\nstability and efficient resource allocation. The system also includes\nautonomous API tool creation and a memory function. Evaluations on tasks like\nacademic paper review (58% success), safety assessments (100% on a\nJailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash\non GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate\nHASHIRU's capabilities. Case studies illustrate its self-improvement via\nautonomous cost model generation, tool integration, and budget management.\nHASHIRU offers a promising approach for more robust, efficient, and adaptable\nMAS through dynamic hierarchical control, resource-aware hybrid intelligence,\nand autonomous functional extension. Source code and benchmarks are available\nat https://github.com/HASHIRU-AI/HASHIRU and\nhttps://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is\navailable at https://hashiruagentx-hashiruai.hf.space upon request.", "AI": {"tldr": "HASHIRU是一个新型多智能体系统框架，通过动态分层控制、资源感知的混合智能和自主功能扩展，提升灵活性、资源效率和适应性。", "motivation": "当前多智能体系统框架在灵活性、资源意识、模型多样性和自主工具创建方面存在不足，HASHIRU旨在解决这些问题。", "method": "HASHIRU采用分层结构，由\"CEO\"代理动态管理\"员工\"代理，结合本地小模型和外部API，并通过经济模型优化资源分配。", "result": "在学术论文评审、安全评估和复杂推理任务中表现优异，部分任务超越现有模型（如Gemini 2.0 Flash）。", "conclusion": "HASHIRU为多智能体系统提供了更高效、灵活和自适应的解决方案，支持动态资源管理和自主功能扩展。"}}
{"id": "2506.04265", "pdf": "https://arxiv.org/pdf/2506.04265", "abs": "https://arxiv.org/abs/2506.04265", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "This work focuses on the credit assignment problem in cooperative multi-agent\nreinforcement learning (MARL). Sharing the global advantage among agents often\nleads to suboptimal policy updates as it fails to account for the distinct\ncontributions of agents. Although numerous methods consider global or\nindividual contributions for credit assignment, a detailed analysis at the\ncoalition level remains lacking in many approaches. This work analyzes the\nover-updating problem during multi-agent policy updates from a coalition-level\nperspective. To address this issue, we propose a credit assignment method\ncalled Coalitional Rational Advantage Decomposition (CORA). CORA evaluates\ncoalitional advantages via marginal contributions from all possible coalitions\nand decomposes advantages using the core solution from cooperative game theory,\nensuring coalitional rationality. To reduce computational overhead, CORA\nemploys random coalition sampling. Experiments on matrix games, differential\ngames, and multi-agent collaboration benchmarks demonstrate that CORA\noutperforms strong baselines, particularly in tasks with multiple local optima.\nThese findings highlight the importance of coalition-aware credit assignment\nfor improving MARL performance.", "AI": {"tldr": "本文提出了一种名为CORA的信用分配方法，通过联盟层面的分析解决多智能体强化学习中的信用分配问题，实验证明其优于现有基线方法。", "motivation": "在多智能体强化学习中，全局优势共享常导致次优策略更新，因为未能考虑各智能体的独特贡献。现有方法多关注全局或个体贡献，缺乏联盟层面的详细分析。", "method": "提出CORA方法，通过评估所有可能联盟的边际贡献来分解优势，利用合作博弈论的核心解确保联盟合理性，并采用随机联盟采样降低计算开销。", "result": "在矩阵游戏、微分游戏和多智能体协作基准测试中，CORA表现优于基线方法，尤其在存在多个局部最优的任务中。", "conclusion": "联盟感知的信用分配对提升多智能体强化学习性能至关重要，CORA方法为此提供了有效解决方案。"}}
{"id": "2506.04266", "pdf": "https://arxiv.org/pdf/2506.04266", "abs": "https://arxiv.org/abs/2506.04266", "authors": ["Timo Looms", "Lin Xie"], "title": "CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses", "categories": ["cs.MA", "cs.AR"], "comment": "8 pages,6 figures, conference", "summary": "Picker-to-parts pallet warehouses often face inefficiencies due to\nconventional layouts causing excessive travel distances and high labor\nrequirements. This study introduces a novel layout design inspired by CPU\narchitecture, partitioning warehouse space into specialized zones, namely\nPerformance (P), Efficiency (E), and Shared (S). Discrete-event simulation is\nused to evaluate this design against traditional rectangular (random and ABC\nstorage) and Flying-V layouts. Results demonstrate significant improvements in\nthroughput time and reduced labor requirements, highlighting the potential for\nCPU-based layouts in optimizing warehouse operations.", "AI": {"tldr": "本文提出了一种基于CPU架构的新型仓库布局设计（PES分区），通过离散事件仿真验证其优于传统布局，显著提高了吞吐效率并降低了劳动力需求。", "motivation": "传统仓库布局（如矩形和Flying-V布局）导致拣货距离过长和劳动力需求高，亟需优化。", "method": "采用离散事件仿真方法，将仓库分为性能（P）、效率（E）和共享（S）三个专用区域，并与传统布局对比。", "result": "新型布局显著缩短了吞吐时间并减少了劳动力需求。", "conclusion": "基于CPU架构的仓库布局设计具有优化仓库运营的潜力。"}}
{"id": "2506.04276", "pdf": "https://arxiv.org/pdf/2506.04276", "abs": "https://arxiv.org/abs/2506.04276", "authors": ["Lei Han", "Yitong Guo", "Pengfei Yang", "Zhiyong Yu", "Liang Wang", "Quan Wang", "Zhiwen Yu"], "title": "Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Natural disasters have caused significant losses to human society, and the\ntimely and efficient acquisition of post-disaster environmental information is\ncrucial for the effective implementation of rescue operations. Due to the\ncomplexity of post-disaster environments, existing sensing technologies face\nchallenges such as weak environmental adaptability, insufficient specialized\nsensing capabilities, and limited practicality of sensing solutions. This paper\nexplores the heterogeneous multi-agent online autonomous collaborative\nscheduling algorithm HoAs-PALN, aimed at achieving efficient collection of\npost-disaster environmental information. HoAs-PALN is realized through adaptive\ndimensionality reduction in the matching process and local Nash equilibrium\ngame, facilitating autonomous collaboration among time-dependent UAVs, workers\nand vehicles to enhance sensing scheduling. (1) In terms of adaptive\ndimensionality reduction during the matching process, HoAs-PALN significantly\nreduces scheduling decision time by transforming a five-dimensional matching\nprocess into two categories of three-dimensional matching processes; (2)\nRegarding the local Nash equilibrium game, HoAs-PALN combines the softmax\nfunction to optimize behavior selection probabilities and introduces a local\nNash equilibrium determination mechanism to ensure scheduling decision\nperformance. Finally, we conducted detailed experiments based on extensive\nreal-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL\nand MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%,\nand 14.03% on average, respectively, while each online scheduling decision\ntakes less than 10 seconds, demonstrating its effectiveness in dynamic\npost-disaster environments.", "AI": {"tldr": "本文提出了一种异构多智能体在线自主协同调度算法HoAs-PALN，用于高效收集灾后环境信息，通过自适应降维和局部纳什均衡博弈优化调度决策。", "motivation": "灾后环境复杂，现有传感技术适应性差、能力不足，需高效协同调度方案。", "method": "HoAs-PALN通过自适应降维匹配和局部纳什均衡博弈，实现无人机、工人和车辆的自主协同。", "result": "实验表明，HoAs-PALN任务完成率显著提升，决策时间短于10秒。", "conclusion": "HoAs-PALN在动态灾后环境中表现高效，优于基线方法。"}}
{"id": "2506.04565", "pdf": "https://arxiv.org/pdf/2506.04565", "abs": "https://arxiv.org/abs/2506.04565", "authors": ["Jiayi Chen", "Junyi Ye", "Guiling Wang"], "title": "From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Compound Al Systems (CAIS) is an emerging paradigm that integrates large\nlanguage models (LLMs) with external components, such as retrievers, agents,\ntools, and orchestrators, to overcome the limitations of standalone models in\ntasks requiring memory, reasoning, real-time grounding, and multimodal\nunderstanding. These systems enable more capable and context-aware behaviors by\ncomposing multiple specialized modules into cohesive workflows. Despite growing\nadoption in both academia and industry, the CAIS landscape remains fragmented,\nlacking a unified framework for analysis, taxonomy, and evaluation. In this\nsurvey, we define the concept of CAIS, propose a multi-dimensional taxonomy\nbased on component roles and orchestration strategies, and analyze four\nfoundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents,\nMultimodal LLMs (MLLMs), and orchestration-centric architectures. We review\nrepresentative systems, compare design trade-offs, and summarize evaluation\nmethodologies across these paradigms. Finally, we identify key\nchallenges-including scalability, interoperability, benchmarking, and\ncoordination-and outline promising directions for future research. This survey\naims to provide researchers and practitioners with a comprehensive foundation\nfor understanding, developing, and advancing the next generation of\nsystem-level artificial intelligence.", "AI": {"tldr": "该论文综述了复合AI系统（CAIS）的概念，提出了一种基于组件角色和协调策略的多维分类法，并分析了四种基础范式。", "motivation": "解决当前CAIS领域缺乏统一分析框架的问题，推动系统级人工智能的发展。", "method": "通过定义CAIS概念、提出分类法、分析代表性系统和评估方法。", "result": "总结了CAIS的设计权衡、评估方法，并指出了未来研究方向。", "conclusion": "为研究人员和从业者提供了理解和开发下一代系统级AI的全面基础。"}}
{"id": "2506.05236", "pdf": "https://arxiv.org/pdf/2506.05236", "abs": "https://arxiv.org/abs/2506.05236", "authors": ["Maxime Toquebiau", "Jae-Yun Jun", "Faïz Benamar", "Nicolas Bredeche"], "title": "Towards Language-Augmented Multi-Agent Deep Reinforcement Learning", "categories": ["cs.MA"], "comment": null, "summary": "Communication is a fundamental aspect of coordinated behavior in multi-agent\nreinforcement learning. Yet, most prior works in this field have focused on\nemergent communication protocols developed from scratch, often resulting in\ninefficient or non-interpretable systems. Inspired by the role of language in\nnatural intelligence, we investigate how grounding agents in a human-defined\nlanguage can improve learning and coordination of multiple embodied agents. We\npropose a framework in which agents are trained not only to act but also to\nproduce and interpret natural language descriptions of their observations. This\nlanguage-augmented learning serves a dual role: enabling explicit communication\nbetween agents and guiding representation learning. We demonstrate that agents\ntrained with our method outperform traditional emergent communication baselines\nacross various tasks. Our analysis reveals that language grounding leads to\nmore informative internal representations, better generalization to new\npartners, and improved capability for human-agent interaction. These findings\ndemonstrate the effectiveness of integrating structured language into\nmulti-agent learning and open avenues for more interpretable and capable\nmulti-agent systems.", "AI": {"tldr": "论文提出了一种基于人类定义语言的多智能体强化学习框架，通过语言增强学习提升协调性和泛化能力。", "motivation": "现有研究多关注自发通信协议，但效率低且难以解释，受自然语言启发，探索语言对多智能体学习的促进作用。", "method": "提出一个框架，智能体不仅学习行动，还生成和解释自然语言描述，语言用于显式通信和表征学习指导。", "result": "实验表明，该方法优于传统自发通信基线，语言基础带来更丰富表征、更好泛化能力和人机交互能力。", "conclusion": "将结构化语言融入多智能体学习有效，为可解释和高效系统开辟了新途径。"}}
{"id": "2506.05309", "pdf": "https://arxiv.org/pdf/2506.05309", "abs": "https://arxiv.org/abs/2506.05309", "authors": ["Niv Eckhaus", "Uri Berger", "Gabriel Stanovsky"], "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": null, "summary": "LLMs are used predominantly in synchronous communication, where a human user\nand a model communicate in alternating turns. In contrast, many real-world\nsettings are inherently asynchronous. For example, in group chats, online team\nmeetings, or social games, there is no inherent notion of turns; therefore, the\ndecision of when to speak forms a crucial part of the participant's decision\nmaking. In this work, we develop an adaptive asynchronous LLM-agent which, in\naddition to determining what to say, also decides when to say it. To evaluate\nour agent, we collect a unique dataset of online Mafia games, including both\nhuman participants, as well as our asynchronous agent. Overall, our agent\nperforms on par with human players, both in game performance, as well as in its\nability to blend in with the other human players. Our analysis shows that the\nagent's behavior in deciding when to speak closely mirrors human patterns,\nalthough differences emerge in message content. We release all our data and\ncode to support and encourage further research for more realistic asynchronous\ncommunication between LLM agents. This work paves the way for integration of\nLLMs into realistic human group settings, from assistance in team discussions\nto educational and professional environments where complex social dynamics must\nbe navigated.", "AI": {"tldr": "开发了一种异步LLM代理，决定何时发言，并在在线Mafia游戏中表现与人类相当。", "motivation": "现实场景多为异步通信，而现有LLM主要用于同步对话，需解决何时发言的问题。", "method": "开发自适应异步LLM代理，收集在线Mafia游戏数据集进行评测。", "result": "代理在游戏表现和融入人类玩家方面与人类相当，发言时机与人类相似但内容有差异。", "conclusion": "为LLM融入真实人类群体场景（如团队讨论、教育）铺平道路，并公开数据代码以促进研究。"}}
{"id": "2506.04251", "pdf": "https://arxiv.org/pdf/2506.04251", "abs": "https://arxiv.org/abs/2506.04251", "authors": ["Zhengyang Li"], "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper introduces LLM-MARL, a unified framework that incorporates large\nlanguage models (LLMs) into multi-agent reinforcement learning (MARL) to\nenhance coordination, communication, and generalization in simulated game\nenvironments. The framework features three modular components of Coordinator,\nCommunicator, and Memory, which dynamically generate subgoals, facilitate\nsymbolic inter-agent messaging, and support episodic recall. Training combines\nPPO with a language-conditioned loss and LLM query gating. LLM-MARL is\nevaluated in Google Research Football, MAgent Battle, and StarCraft II. Results\nshow consistent improvements over MAPPO and QMIX in win rate, coordination\nscore, and zero-shot generalization. Ablation studies demonstrate that subgoal\ngeneration and language-based messaging each contribute significantly to\nperformance gains. Qualitative analysis reveals emergent behaviors such as role\nspecialization and communication-driven tactics. By bridging language modeling\nand policy learning, this work contributes to the design of intelligent,\ncooperative agents in interactive simulations. It offers a path forward for\nleveraging LLMs in multi-agent systems used for training, games, and human-AI\ncollaboration.", "AI": {"tldr": "LLM-MARL框架将大语言模型（LLM）融入多智能体强化学习（MARL），提升协调、通信和泛化能力，在模拟游戏环境中表现优异。", "motivation": "通过结合LLM和MARL，解决多智能体系统中的协调、通信和泛化问题，推动智能协作代理的发展。", "method": "框架包含Coordinator、Communicator和Memory三个模块，结合PPO训练和语言条件损失，动态生成子目标、符号化消息和情景记忆。", "result": "在多个游戏环境中优于MAPPO和QMIX，零样本泛化能力显著，子目标和语言消息对性能提升贡献大。", "conclusion": "LLM-MARL为多智能体系统设计提供了新思路，展示了LLM在训练、游戏和人机协作中的潜力。"}}
{"id": "2506.04676", "pdf": "https://arxiv.org/pdf/2506.04676", "abs": "https://arxiv.org/abs/2506.04676", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Recently, Large Language Models (LLMs) and Vision Large Language Models\n(VLLMs) have demonstrated impressive performance as agents across various tasks\nwhile data scarcity and label noise remain significant challenges in computer\nvision tasks, such as object detection and instance segmentation. A common\nsolution for resolving these issues is to generate synthetic data. However,\ncurrent synthetic data generation methods struggle with issues, such as\nmultiple objects per mask, inaccurate segmentation, and incorrect category\nlabels, limiting their effectiveness. To address these issues, we introduce\nGen-n-Val, a novel agentic data generation framework that leverages Layer\nDiffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks\nand diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt\nagent, an LLM, optimizes prompts for LD to generate high-quality foreground\ninstance images and segmentation masks. These optimized prompts ensure the\ngeneration of single-object synthetic data with precise instance masks and\nclean backgrounds. (2) The data validation agent, a VLLM, which filters out\nlow-quality synthetic instance images. The system prompts for both agents are\nrefined through TextGrad. Additionally, we use image harmonization to combine\nmultiple instances within scenes. Compared to state-of-the-art synthetic data\napproaches like MosaicFusion, our approach reduces invalid synthetic data from\n50% to 7% and improves performance by 1% mAP on rare classes in COCO instance\nsegmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant\nimprovements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object\ndetection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance\nof YOLOv9 and YOLO11 families in instance segmentation and object detection.", "AI": {"tldr": "Gen-n-Val是一个新型数据生成框架，利用Layer Diffusion、LLMs和VLLMs生成高质量的单对象掩码和多样化背景，显著减少无效数据并提升性能。", "motivation": "解决计算机视觉任务中数据稀缺和标签噪声问题，当前合成数据生成方法存在多对象掩码、分割不准确和类别标签错误等缺陷。", "method": "Gen-n-Val包含两个代理：LD提示代理优化提示生成高质量前景图像和掩码；数据验证代理过滤低质量数据。系统提示通过TextGrad优化，并使用图像协调技术。", "result": "相比现有方法，无效数据从50%降至7%，在COCO实例分割中mAP提升1%，开放词汇检测中mAP提升7.1%。", "conclusion": "Gen-n-Val显著提升了合成数据的质量和任务性能，适用于实例分割和对象检测。"}}
{"id": "2506.04701", "pdf": "https://arxiv.org/pdf/2506.04701", "abs": "https://arxiv.org/abs/2506.04701", "authors": ["Meiru Jiang", "Wei Su", "Guojian Ren", "Yongguang Yu"], "title": "Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause Model Based on Fractional-Order Methods", "categories": ["physics.soc-ph", "cs.MA", "cs.SI", "nlin.AO"], "comment": null, "summary": "Memory effects play a crucial role in social interactions and decision-making\nprocesses. This paper proposes a novel fractional-order bounded confidence\nopinion dynamics model to characterize the memory effects in system states.\nBuilding upon the Hegselmann-Krause framework and fractional-order difference,\na comprehensive model is established that captures the persistent influence of\nhistorical information. Through rigorous theoretical analysis, the fundamental\nproperties including convergence and consensus is investigated. The results\ndemonstrate that the proposed model not only maintains favorable convergence\nand consensus characteristics compared to classical opinion dynamics, but also\naddresses limitations such as the monotonicity of bounded opinions. This\nenables a more realistic representation of opinion evolution in real-world\nscenarios. The findings of this study provide new insights and methodological\napproaches for understanding opinion formation and evolution, offering both\ntheoretical significance and practical applications.", "AI": {"tldr": "提出了一种分数阶有界置信度意见动力学模型，用于描述系统状态中的记忆效应，改进了经典模型的局限性。", "motivation": "研究记忆效应对社会互动和决策过程的影响，弥补经典意见动力学模型在单调性和历史信息持续性上的不足。", "method": "基于Hegselmann-Krause框架和分数阶差分，建立了一个综合模型，并通过理论分析研究其收敛性和共识特性。", "result": "模型不仅保持了良好的收敛和共识特性，还解决了意见单调性问题，更真实地模拟了现实场景中的意见演化。", "conclusion": "该研究为理解意见形成和演化提供了新的理论和方法，具有理论和实际应用价值。"}}
{"id": "2506.05252", "pdf": "https://arxiv.org/pdf/2506.05252", "abs": "https://arxiv.org/abs/2506.05252", "authors": ["Dravyansh Sharma", "Alec Sun"], "title": "Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning", "categories": ["cs.LG", "cs.GT", "cs.MA"], "comment": "24 pages", "summary": "Machine learning is now ubiquitous in societal decision-making, for example\nin evaluating job candidates or loan applications, and it is increasingly\nimportant to take into account how classified agents will react to the learning\nalgorithms. The majority of recent literature on strategic classification has\nfocused on reducing and countering deceptive behaviors by the classified\nagents, but recent work of Attias et al. identifies surprising properties of\nlearnability when the agents genuinely improve in order to attain the desirable\nclassification, such as smaller generalization error than standard\nPAC-learning. In this paper we characterize so-called learnability with\nimprovements across multiple new axes. We introduce an asymmetric variant of\nminimally consistent concept classes and use it to provide an exact\ncharacterization of proper learning with improvements in the realizable\nsetting. While prior work studies learnability only under general, arbitrary\nagent improvement regions, we give positive results for more natural Euclidean\nball improvement sets. In particular, we characterize improper learning under a\nmild generative assumption on the data distribution. We further show how to\nlearn in more challenging settings, achieving lower generalization error under\nwell-studied bounded noise models and obtaining mistake bounds in realizable\nand agnostic online learning. We resolve open questions posed by Attias et al.\nfor both proper and improper learning.", "AI": {"tldr": "本文研究了机器学习在战略分类中的可学习性，特别是在代理真实改进的情况下，提出了新的学习框架和结果。", "motivation": "探讨代理在分类过程中真实改进而非欺骗行为时的学习性质，填补现有研究的空白。", "method": "引入非对称变体的最小一致概念类，研究欧几里得球改进集下的学习，并分析有界噪声模型和在线学习。", "result": "在可实现和不可实现设置下，给出了学习能力的精确刻画，解决了Attias等人的开放问题。", "conclusion": "本文扩展了战略分类的学习理论，为代理真实改进场景提供了新的学习方法和理论支持。"}}
{"id": "2506.05265", "pdf": "https://arxiv.org/pdf/2506.05265", "abs": "https://arxiv.org/abs/2506.05265", "authors": ["Mohammed Almutairi"], "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "categories": ["cs.HC", "cs.AI", "cs.MA"], "comment": "5 pages, UMAP 25, June 16_19, 2025, New York City, NY, USA", "summary": "Effective teamwork is essential across diverse domains. During the team\nformation stage, a key challenge is forming teams that effectively balance user\npreferences with task objectives to enhance overall team satisfaction. In the\nteam performing stage, maintaining cohesion and engagement is critical for\nsustaining high team performance. However, existing computational tools and\nalgorithms for team optimization often rely on static data inputs, narrow\nalgorithmic objectives, or solutions tailored for specific contexts, failing to\naccount for the dynamic interplay of team members personalities, evolving\ngoals, and changing individual preferences. Therefore, teams may encounter\nmember dissatisfaction, as purely algorithmic assignments can reduce members\ncommitment to team goals or experience suboptimal engagement due to the absence\nof timely, personalized guidance to help members adjust their behaviors and\ninteractions as team dynamics evolve. Ultimately, these challenges can lead to\nreduced overall team performance. My Ph.D. dissertation aims to develop\nAI-augmented team optimization frameworks and practical systems that enhance\nteam satisfaction, engagement, and performance. First, I propose a team\nformation framework that leverages a multi-armed bandit algorithm to\niteratively refine team composition based on user preferences, ensuring\nalignment between individual needs and collective team goals to enhance team\nsatisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an\nAI-powered system that utilizes large language models (LLMs) to deliver\nimmediate, personalized feedback to both teams and individual members,\nenhancing cohesion and engagement. Finally, I present PuppeteerLLM, an\nLLM-based simulation framework that simulates multi-agent teams to model\ncomplex team dynamics within realistic environments, incorporating task-driven\ncollaboration and long-term coordination.", "AI": {"tldr": "该论文提出AI增强的团队优化框架，包括团队形成算法、AI反馈助手和模拟框架，以提升团队满意度、参与度和绩效。", "motivation": "现有团队优化工具依赖静态数据或特定情境，无法适应动态团队互动，导致成员不满和绩效下降。", "method": "1. 多臂老虎机算法优化团队形成；2. AI反馈助手tAIfa提供个性化指导；3. PuppeteerLLM模拟多代理团队动态。", "result": "提出的框架能动态优化团队，提升满意度和绩效。", "conclusion": "AI工具可有效解决团队动态问题，增强协作效果。"}}
