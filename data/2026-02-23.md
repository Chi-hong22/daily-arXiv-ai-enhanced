<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Nested Training for Mutual Adaptation in Human-AI Teaming](https://arxiv.org/abs/2602.17737)
*Upasana Biswas,Durgesh Kalwar,Subbarao Kambhampati,Sarath Sreedharan*

Main category: cs.RO

TL;DR: 该研究提出了一种基于I-POMDP框架的嵌套训练方法，用于解决人机协作中的相互适应问题，避免训练中产生隐式协调策略，提高机器人对新伙伴的适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用静态训练伙伴无法捕捉人类的适应性行为，而同时学习的多智能体系统容易收敛到仅适用于特定伙伴的隐式协调策略，导致无法泛化到新的人类伙伴。

Method: 将人机协作建模为交互式部分可观测马尔可夫决策过程（I-POMDP），将人类适应行为作为状态的一部分。采用嵌套训练机制，每个层级的智能体与下一层级的适应性智能体进行训练，避免训练伙伴自身学习产生隐式协调。

Result: 在Overcooked领域的多回合必需合作设置中训练，与多种人机协作基线智能体比较。评估结果显示，该方法训练的智能体在面对未见过的适应性伙伴时，不仅任务性能更高，而且在团队交互中表现出显著更强的适应性。

Conclusion: 提出的I-POMDP框架和嵌套训练方法能够有效捕捉人类适应性行为，避免隐式协调策略的产生，使智能体能够更好地泛化到新的适应性伙伴，提升人机协作的相互适应能力。

Abstract: Mutual adaptation is a central challenge in human--AI teaming, as humans naturally adjust their strategies in response to a robot's policy. Existing approaches aim to improve diversity in training partners to approximate human behavior, but these partners are static and fail to capture adaptive behavior of humans. Exposing robots to adaptive behaviors is critical, yet when both agents learn simultaneously in a multi-agent setting, they often converge to opaque implicit coordination strategies that only work with the agents they were co-trained with. Such agents fail to generalize when paired with new partners. In order to capture the adaptive behavior of humans, we model the human-robot teaming scenario as an Interactive Partially Observable Markov Decision Process (I-POMDP), explicitly modeling human adaptation as part of the state. We propose a nested training regime to approximately learn the solution to a finite-level I-POMDP. In this framework, agents at each level are trained against adaptive agents from the level below. This ensures that the ego agent is exposed to adaptive behavior during training while avoiding the emergence of implicit coordination strategies, since the training partners are not themselves learning. We train our method in a multi-episode, required cooperation setup in the Overcooked domain, comparing it against several baseline agents designed for human-robot teaming. We evaluate the performance of our agent when paired with adaptive partners that were not seen during training. Our results demonstrate that our agent not only achieves higher task performance with these adaptive partners but also exhibits significantly greater adaptability during team interactions.

</details>


### [2] [WHED: A Wearable Hand Exoskeleton for Natural, High-Quality Demonstration Collection](https://arxiv.org/abs/2602.17908)
*Mingzhang Zhu,Alvin Zhu,Jose Victor S. H. Ramos,Beom Jun Kim,Yike Shi,Yufeng Wu,Ruochen Hou,Quanyou Wang,Eric Song,Tony Fan,Yuchen Cui,Dennis W. Hong*

Main category: cs.RO

TL;DR: WHED是一种可穿戴手部外骨骼系统，用于在真实环境中捕捉人类手部操作演示，解决了多指手演示数据收集的难题。


<details>
  <summary>Details</summary>
Motivation: 由于遮挡、复杂手部运动学和接触丰富的交互，收集自然、高保真的人类多指手操作演示数据仍然很困难，这限制了灵巧操作的可扩展学习。

Method: 开发了WHED可穿戴手部外骨骼系统，采用可穿戴优先设计原则和自由移动拇指耦合机制，结合连杆驱动手指接口、改进的被动手部本体感知传感以及板载传感/电源模块。

Result: 在代表性抓取和操作序列上展示了可行性，包括精确捏取和全手包裹抓取，并显示了收集的演示与回放执行之间的定性一致性。

Conclusion: WHED系统为在真实环境中捕捉人类手部操作演示提供了一种有效的解决方案，有助于解决灵巧操作学习中的数据收集瓶颈问题。

Abstract: Scalable learning of dexterous manipulation remains bottlenecked by the difficulty of collecting natural, high-fidelity human demonstrations of multi-finger hands due to occlusion, complex hand kinematics, and contact-rich interactions. We present WHED, a wearable hand-exoskeleton system designed for in-the-wild demonstration capture, guided by two principles: wearability-first operation for extended use and a pose-tolerant, free-to-move thumb coupling that preserves natural thumb behaviors while maintaining a consistent mapping to the target robot thumb degrees of freedom. WHED integrates a linkage-driven finger interface with passive fit accommodation, a modified passive hand with robust proprioceptive sensing, and an onboard sensing/power module. We also provide an end-to-end data pipeline that synchronizes joint encoders, AR-based end-effector pose, and wrist-mounted visual observations, and supports post-processing for time alignment and replay. We demonstrate feasibility on representative grasping and manipulation sequences spanning precision pinch and full-hand enclosure grasps, and show qualitative consistency between collected demonstrations and replayed executions.

</details>


### [3] [Latent Diffeomorphic Co-Design of End-Effectors for Deformable and Fragile Object Manipulation](https://arxiv.org/abs/2602.17921)
*Kei Ikemura,Yifei Dong,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 首个同时优化末端执行器形态和控制的协同设计框架，用于可变形和易碎物体操作，在食品操作任务中验证有效性


<details>
  <summary>Details</summary>
Motivation: 可变形和易碎物体的操作是机器人学中的基本挑战，现有方法通常单独优化末端执行器设计或控制策略，限制了可实现性能

Method: 提出协同设计框架：1) 潜在微分同胚形状参数化实现可表达且可处理的几何优化；2) 应力感知的双层协同设计管道耦合形态和控制优化；3) 特权到点云策略蒸馏方案实现零样本真实世界部署

Result: 在具有挑战性的食品操作任务（包括抓取和推动果冻、舀取鱼片）中进行仿真和真实世界实验，证明了所提方法的有效性

Conclusion: 该协同设计框架通过联合优化末端执行器形态和操作控制，成功解决了可变形和易碎物体的操作挑战

Abstract: Manipulating deformable and fragile objects remains a fundamental challenge in robotics due to complex contact dynamics and strict requirements on object integrity. Existing approaches typically optimize either end-effector design or control strategies in isolation, limiting achievable performance. In this work, we present the first co-design framework that jointly optimizes end-effector morphology and manipulation control for deformable and fragile object manipulation. We introduce (1) a latent diffeomorphic shape parameterization enabling expressive yet tractable end-effector geometry optimization, (2) a stress-aware bi-level co-design pipeline coupling morphology and control optimization, and (3) a privileged-to-pointcloud policy distillation scheme for zero-shot real-world deployment. We evaluate our approach on challenging food manipulation tasks, including grasping and pushing jelly and scooping fillets. Simulation and real-world experiments demonstrate the effectiveness of the proposed method.

</details>


### [4] [Homotopic information gain for sparse active target tracking](https://arxiv.org/abs/2602.17926)
*Jennifer Wakulicz,Ki Myung Brian Lee,Teresa Vidal-Calleja,Robert Fitch*

Main category: cs.RO

TL;DR: 提出了一种基于同伦信息增益的主动目标跟踪规划方法，通过最大化目标高层运动信息来减少测量次数并提高轨迹估计精度


<details>
  <summary>Details</summary>
Motivation: 在多模态运动模型中，信息增益的概念常常定义不明确，需要一种能够有效处理目标高层运动信息的规划方法

Method: 引入同伦信息增益作为测量预期高层轨迹信息的度量，证明它是度量或低层信息增益的下界，并在环境中稀疏分布；规划感知轨迹以最大化同伦信息

Result: 与度量信息方法相比，最大化同伦信息的规划方法能够以更少的测量次数获得高度准确的轨迹估计，在真实和模拟行人数据上得到验证

Conclusion: 同伦信息增益为多模态运动模型下的主动目标跟踪提供了一种有效的规划框架，通过关注目标的高层运动模式，能够在减少测量成本的同时提高跟踪精度

Abstract: The problem of planning sensing trajectories for a mobile robot to collect observations of a target and predict its future trajectory is known as active target tracking. Enabled by probabilistic motion models, one may solve this problem by exploring the belief space of all trajectory predictions given future sensing actions to maximise information gain. However, for multi-modal motion models the notion of information gain is often ill-defined. This paper proposes a planning approach designed around maximising information regarding the target's homotopy class, or high-level motion. We introduce homotopic information gain, a measure of the expected high-level trajectory information given by a measurement. We show that homotopic information gain is a lower bound for metric or low-level information gain, and is as sparsely distributed in the environment as obstacles are. Planning sensing trajectories to maximise homotopic information results in highly accurate trajectory estimates with fewer measurements than a metric information approach, as supported by our empirical evaluation on real and simulated pedestrian data.

</details>


### [5] [Quasi-Periodic Gaussian Process Predictive Iterative Learning Control](https://arxiv.org/abs/2602.18014)
*Unnati Nigam,Radhendushka Srivastava,Faezeh Marzbanrad,Michael Burke*

Main category: cs.RO

TL;DR: 该研究将准周期高斯过程（QPGP）集成到预测性迭代学习控制（ILC）框架中，用于建模和预测重复运动任务中的干扰和漂移，实现了更快的收敛速度和更低的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 重复运动任务在机器人中很常见，但由于环境变化和机器人磨损，性能会随时间下降。传统的迭代学习控制（ILC）使用先前迭代的信息来补偿预期误差，但需要更高效的方法来处理时间变化的干扰和计算复杂度问题。

Method: 采用准周期高斯过程（QPGPs）的预测性ILC框架，利用QPGP的结构方程公式化，将计算复杂度从$\mathcal{O}(i^2p^3)$降低到$\mathcal{O}(p^3)$，其中$p$是单次迭代中的点数，$i$是总迭代次数。该方法支持参数估计而不损失信息，使连续GP学习在控制回路中计算可行。

Result: 在三个任务上进行基准测试：自动驾驶车辆轨迹跟踪、三连杆机器人操纵器和真实世界的Stretch机器人实验。在所有情况下，该方法比标准ILC和传统GP-based预测性ILC收敛更快，在注入和自然干扰下保持鲁棒性，同时降低了计算成本。

Conclusion: 提出的QPGP-based预测性ILC方法在多种重复动态系统中具有实用性，实现了更快的收敛速度、更好的鲁棒性和更低的计算复杂度，特别适用于大规模迭代场景。

Abstract: Repetitive motion tasks are common in robotics, but performance can degrade over time due to environmental changes and robot wear and tear. Iterative learning control (ILC) improves performance by using information from previous iterations to compensate for expected errors in future iterations. This work incorporates the use of Quasi-Periodic Gaussian Processes (QPGPs) into a predictive ILC framework to model and forecast disturbances and drift across iterations. Using a recent structural equation formulation of QPGPs, the proposed approach enables efficient inference with complexity $\mathcal{O}(p^3)$ instead of $\mathcal{O}(i^2p^3)$, where $p$ denotes the number of points within an iteration and $i$ represents the total number of iterations, specially for larger $i$. This formulation also enables parameter estimation without loss of information, making continual GP learning computationally feasible within the control loop. By predicting next-iteration error profiles rather than relying only on past errors, the controller achieves faster convergence and maintains this under time-varying disturbances. We benchmark the method against both standard ILC and conventional Gaussian Process (GP)-based predictive ILC on three tasks, autonomous vehicle trajectory tracking, a three-link robotic manipulator, and a real-world Stretch robot experiment. Across all cases, the proposed approach converges faster and remains robust under injected and natural disturbances while reducing computational cost. This highlights its practicality across a range of repetitive dynamical systems.

</details>


### [6] [EgoPush: Learning End-to-End Egocentric Multi-Object Rearrangement for Mobile Robots](https://arxiv.org/abs/2602.18071)
*Boyuan An,Zhexiong Wang,Yipeng Wang,Jiaqi Li,Sihang Li,Jing Zhang,Chen Feng*

Main category: cs.RO

TL;DR: EgoPush是一个用于移动机器人长时程多物体非抓取重排的框架，使用单目自我中心摄像头，通过物体中心潜在空间编码相对空间关系，无需全局状态估计，实现了从特权RL教师到纯视觉学生策略的蒸馏。


<details>
  <summary>Details</summary>
Motivation: 受人类在杂乱环境中通过自我中心感知重排物体的能力启发，研究移动机器人在不使用全局坐标的情况下进行长时程多物体非抓取重排，解决动态场景中全局状态估计失败的问题。

Method: 设计物体中心潜在空间编码物体间相对空间关系而非绝对位姿；使用特权RL教师从稀疏关键点联合学习潜在状态和移动动作，然后蒸馏到纯视觉学生策略；限制教师观察为视觉可访问线索以减少监督差距；使用时间衰减的阶段局部完成奖励分解长时程任务。

Result: 大量仿真实验显示EgoPush在成功率上显著优于端到端RL基线，消融研究验证了每个设计选择的有效性；进一步展示了在真实世界移动平台上零样本仿真到真实环境的迁移能力。

Conclusion: EgoPush框架成功实现了移动机器人基于自我中心感知的长时程多物体非抓取重排，无需全局状态估计，通过特权教师到视觉学生的蒸馏策略和主动感知行为，实现了有效的零样本仿真到真实环境迁移。

Abstract: Humans can rearrange objects in cluttered environments using egocentric perception, navigating occlusions without global coordinates. Inspired by this capability, we study long-horizon multi-object non-prehensile rearrangement for mobile robots using a single egocentric camera. We introduce EgoPush, a policy learning framework that enables egocentric, perception-driven rearrangement without relying on explicit global state estimation that often fails in dynamic scenes. EgoPush designs an object-centric latent space to encode relative spatial relations among objects, rather than absolute poses. This design enables a privileged reinforcement-learning (RL) teacher to jointly learn latent states and mobile actions from sparse keypoints, which is then distilled into a purely visual student policy. To reduce the supervision gap between the omniscient teacher and the partially observed student, we restrict the teacher's observations to visually accessible cues. This induces active perception behaviors that are recoverable from the student's viewpoint. To address long-horizon credit assignment, we decompose rearrangement into stage-level subproblems using temporally decayed, stage-local completion rewards. Extensive simulation experiments demonstrate that EgoPush significantly outperforms end-to-end RL baselines in success rate, with ablation studies validating each design choice. We further demonstrate zero-shot sim-to-real transfer on a mobile platform in the real world. Code and videos are available at https://ai4ce.github.io/EgoPush/.

</details>


### [7] [Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning](https://arxiv.org/abs/2602.18097)
*Aarati Andrea Noronha,Jean Oh*

Main category: cs.RO

TL;DR: 提出一个结合Hamilton-Jacobi可达性分析与深度Q学习的框架，使自动驾驶车辆能与骑行者安全高效交互，通过安全度量作为强化学习奖励信号，并建模骑行者的潜在响应。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要与骑行者安全交互，但现有方法难以同时保证安全性和时间效率。需要一种能平衡安全保证和最优导航的框架。

Method: 整合Hamilton-Jacobi可达性分析与深度Q学习：1) 通过求解时间相关Hamilton-Jacobi-Bellman不等式计算安全度量值函数；2) 将安全度量作为结构化奖励信号融入强化学习框架；3) 建模骑行者对车辆的潜在响应，用扰动输入反映人类舒适度和行为适应。

Result: 通过仿真评估，并与人类驾驶行为和现有最先进方法进行比较，验证了所提框架的有效性。

Conclusion: 提出的框架成功实现了自动驾驶车辆与骑行者交互中安全性和时间效率的平衡，通过结合形式化安全分析和强化学习，并考虑人类行为因素，提升了交互性能。

Abstract: In this paper, we present a framework for enabling autonomous vehicles to interact with cyclists in a manner that balances safety and optimality. The approach integrates Hamilton-Jacobi reachability analysis with deep Q-learning to jointly address safety guarantees and time-efficient navigation. A value function is computed as the solution to a time-dependent Hamilton-Jacobi-Bellman inequality, providing a quantitative measure of safety for each system state. This safety metric is incorporated as a structured reward signal within a reinforcement learning framework. The method further models the cyclist's latent response to the vehicle, allowing disturbance inputs to reflect human comfort and behavioral adaptation. The proposed framework is evaluated through simulation and comparison with human driving behavior and an existing state-of-the-art method.

</details>


### [8] [GrandTour: A Legged Robotics Dataset in the Wild for Multi-Modal Perception and State Estimation](https://arxiv.org/abs/2602.18164)
*Jonas Frey,Turcan Tuna,Frank Fu,Katharine Patterson,Tianao Xu,Maurice Fallon,Cesar Cadena,Marco Hutter*

Main category: cs.RO

TL;DR: GrandTour是一个大规模多模态四足机器人数据集，包含各种室内外环境，提供同步的激光雷达、相机、本体感知等传感器数据和高精度地面真值轨迹，支持SLAM、状态估计和多模态学习研究。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏大规模公开的四足机器人数据集来开发和评估复杂大规模环境下的状态估计、感知和导航算法，这限制了自主四足机器人在实际应用中的发展。

Method: 使用ANYbotics ANYmal-D四足机器人配备多模态传感器载荷，在多种具有挑战性的室内外环境中收集数据，包括高山、森林、拆除建筑和城市区域等不同测试场地。

Result: 创建了GrandTour数据集，提供时间同步的旋转激光雷达、多个互补特性的RGB相机、本体感知传感器、立体深度相机数据，以及基于卫星RTK-GNSS和全站仪的高精度地面真值轨迹。

Conclusion: GrandTour是目前最大的开源四足机器人数据集，支持SLAM、高精度状态估计和多模态学习研究，为传感器融合算法的严格评估和新方法开发提供了重要资源。

Abstract: Accurate state estimation and multi-modal perception are prerequisites for autonomous legged robots in complex, large-scale environments. To date, no large-scale public legged-robot dataset captures the real-world conditions needed to develop and benchmark algorithms for legged-robot state estimation, perception, and navigation. To address this, we introduce the GrandTour dataset, a multi-modal legged-robotics dataset collected across challenging outdoor and indoor environments, featuring an ANYbotics ANYmal-D quadruped equipped with the \boxi multi-modal sensor payload. GrandTour spans a broad range of environments and operational scenarios across distinct test sites, ranging from alpine scenery and forests to demolished buildings and urban areas, and covers a wide variation in scale, complexity, illumination, and weather conditions. The dataset provides time-synchronized sensor data from spinning LiDARs, multiple RGB cameras with complementary characteristics, proprioceptive sensors, and stereo depth cameras. Moreover, it includes high-precision ground-truth trajectories from satellite-based RTK-GNSS and a Leica Geosystems total station. This dataset supports research in SLAM, high-precision state estimation, and multi-modal learning, enabling rigorous evaluation and development of new approaches to sensor fusion in legged robotic systems. With its extensive scope, GrandTour represents the largest open-access legged-robotics dataset to date. The dataset is available at https://grand-tour.leggedrobotics.com, on HuggingFace (ROS-independent), and in ROS formats, along with tools and demo resources.

</details>


### [9] [Have We Mastered Scale in Deep Monocular Visual SLAM? The ScaleMaster Dataset and Benchmark](https://arxiv.org/abs/2602.18174)
*Hyoseok Ju,Bokeon Suh,Giseop Kim*

Main category: cs.RO

TL;DR: ScaleMaster数据集是首个专门评估大规模室内环境中尺度一致性的基准，揭示了现有深度单目视觉SLAM系统在真实场景中的严重尺度漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度单目视觉SLAM系统在尺度一致性方面的鲁棒性尚未充分探索，现有基准仅限于房间尺度或结构简单场景，无法解决大规模室内环境中的尺度漂移和尺度模糊问题。

Method: 提出ScaleMaster数据集，专门设计用于评估多楼层结构、长轨迹、重复视图和低纹理区域等挑战性场景下的尺度一致性。系统分析了最先进深度单目视觉SLAM系统的脆弱性，并提供定量和定性评估，包括使用Chamfer距离等指标进行直接地图到地图质量评估。

Result: 结果显示，尽管现有深度单目视觉SLAM系统在现有基准上表现良好，但在真实大规模室内环境中存在严重的尺度相关失败。通过发布ScaleMaster数据集和基线结果，为未来研究建立基础。

Conclusion: 需要开发尺度一致且可靠的视觉SLAM系统，ScaleMaster数据集填补了现有基准的空白，为评估和改进大规模室内环境中的尺度一致性提供了重要工具。

Abstract: Recent advances in deep monocular visual Simultaneous Localization and Mapping (SLAM) have achieved impressive accuracy and dense reconstruction capabilities, yet their robustness to scale inconsistency in large-scale indoor environments remains largely unexplored. Existing benchmarks are limited to room-scale or structurally simple settings, leaving critical issues of intra-session scale drift and inter-session scale ambiguity insufficiently addressed. To fill this gap, we introduce the ScaleMaster Dataset, the first benchmark explicitly designed to evaluate scale consistency under challenging scenarios such as multi-floor structures, long trajectories, repetitive views, and low-texture regions. We systematically analyze the vulnerability of state-of-the-art deep monocular visual SLAM systems to scale inconsistency, providing both quantitative and qualitative evaluations. Crucially, our analysis extends beyond traditional trajectory metrics to include a direct map-to-map quality assessment using metrics like Chamfer distance against high-fidelity 3D ground truth. Our results reveal that while recent deep monocular visual SLAM systems demonstrate strong performance on existing benchmarks, they suffer from severe scale-related failures in realistic, large-scale indoor environments. By releasing the ScaleMaster dataset and baseline results, we aim to establish a foundation for future research toward developing scale-consistent and reliable visual SLAM systems.

</details>


### [10] [Design and Characterization of a Dual-DOF Soft Shoulder Exosuit with Volume-Optimized Pneumatic Actuator](https://arxiv.org/abs/2602.18212)
*Rui Chen,Domenico Chiaradia,Daniele Leonardis,Antonio Frisoli*

Main category: cs.RO

TL;DR: 该研究开发了一种体积优化的纺锤形角度执行器(SSAA)，用于便携式气动软肩外骨骼，在减少35.7%体积的同时保持94.2%扭矩输出并提升35.2%动态响应。基于此开发了双自由度纺织肩外骨骼，在健康用户中实现了高达63.7%的肌肉活动减少。


<details>
  <summary>Details</summary>
Motivation: 便携式气动2自由度软肩外骨骼系统研究不足，面临扭矩输出与动态响应之间的基本权衡，且需要多个执行器支持复杂的肩部运动。现有设计在体积、性能和动态响应之间存在矛盾。

Method: 1) 开发体积优化的纺锤形角度执行器(SSAA)几何结构；2) 基于SSAA开发弯曲外展执行器(CAA)；3) 基于囊袋电机原理开发水平内收执行器(HAA)；4) 将两者集成到390克的双自由度纺织肩外骨骼中；5) 对10名健康参与者进行用户研究，测量肌电活动减少情况。

Result: SSAA相比均匀圆柱设计减少35.7%体积(357mL vs 555mL)，保持94.2%扭矩输出，动态响应提升35.2%。外骨骼在肩外展任务中实现高达59%的肌肉活动减少，在屈曲任务中单执行器和双执行器配置分别实现高达63.7%的肌电活动减少。但健康用户在屈曲任务中增加CAA的增量效益有限，仅在胸大肌观察到统计学显著额外减少。

Conclusion: 该研究通过体积优化的执行器设计解决了便携式气动肩外骨骼的扭矩-响应权衡问题，开发的双自由度纺织外骨骼能有效减少肩部肌肉活动。研究结果为多自由度外骨骼系统的设计提供了指导，特别是在执行器配置优化方面。

Abstract: Portable pneumatic systems for 2 degree-of-freedom (DOF) soft shoulder exosuits remain underexplored, and face fundamental trade-offs between torque output and dynamic response that are further compounded by the need for multiple actuators to support complex shoulder movement. This work addresses these constraints through a volume-optimized spindle-shaped angled actuator (SSAA) geometry: by reducing actuator volume by 35.7% (357mL vs. 555mL), the SSAA maintains 94.2% of output torque while achieving 35.2% faster dynamic response compared to uniform cylindrical designs. Building on the SSAA, we develop a curved abduction actuator (CAA) based on the SSAA geometry and a horizontal adduction actuator (HAA) based on the pouch motor principle, integrating both into a dual-DOF textile-based shoulder exosuit (390 g). The exosuit delivers multi-modal assistance spanning shoulder abduction, flexion, and horizontal adduction, depending on the actuation.
  User studies with 10 healthy participants reveal that the exosuit substantially reduces electromyographic (EMG) activity across both shoulder abduction and flexion tasks. For abduction with HAA only, the exosuit achieved up to 59% muscle activity reduction across seven muscles. For flexion, both the single-actuator configuration (HAA only) and the dual-actuator configuration (HAA,+,CAA) reduced EMG activity by up to 63.7% compared to no assistance. However, the incremental benefit of adding the CAA to existing HAA support was limited in healthy users during flexion, with statistically significant additional reductions observed only in pectoralis major. These experimental findings characterize actuator contributions in healthy users and provide design guidance for multi-DOF exosuit systems.

</details>


### [11] [RoEL: Robust Event-based 3D Line Reconstruction](https://arxiv.org/abs/2602.18258)
*Gwangtak Bae,Jaeho Shin,Seunggu Kang,Junho Kim,Ayoung Kim,Young Min Kim*

Main category: cs.RO

TL;DR: 提出一种基于事件相机的稳健线特征提取与跟踪方法，通过多时间切片观测补偿事件数据中的噪声，利用几何代价函数优化3D线地图和相机位姿，适用于多模态场景。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动时主要检测物体边界或纹理边缘，产生亮度变化线。虽然线特征可以作为稳健的中间表示，但其稀疏性可能导致微小估计误差下的性能急剧下降。现有方法较少利用线特征来补偿事件传感器的严重域差异和不可预测的噪声特性。

Method: 1) 提出稳定提取各种外观线特征轨迹的方法，通过观察事件多个时间切片的多重表示来补偿事件数据中的潜在干扰；2) 提出几何代价函数，可以消除投影畸变和深度模糊，优化3D线地图和相机位姿；3) 3D线地图高度紧凑，可适配任何能检测和提取线结构或其投影的观测数据。

Result: 该方法在多个数据集上显著提升了事件相机建图和位姿细化的性能，并能灵活应用于多模态场景。结果表明，所提出的基于线特征的公式化方法是事件感知模块实际部署的稳健有效方法。

Conclusion: 基于线特征的表示方法为事件相机提供了稳健的感知框架，能够有效处理事件数据的域差异和噪声特性，在多模态应用中具有良好适应性。

Abstract: Event cameras in motion tend to detect object boundaries or texture edges, which produce lines of brightness changes, especially in man-made environments. While lines can constitute a robust intermediate representation that is consistently observed, the sparse nature of lines may lead to drastic deterioration with minor estimation errors. Only a few previous works, often accompanied by additional sensors, utilize lines to compensate for the severe domain discrepancies of event sensors along with unpredictable noise characteristics. We propose a method that can stably extract tracks of varying appearances of lines using a clever algorithmic process that observes multiple representations from various time slices of events, compensating for potential adversaries within the event data. We then propose geometric cost functions that can refine the 3D line maps and camera poses, eliminating projective distortions and depth ambiguities. The 3D line maps are highly compact and can be equipped with our proposed cost function, which can be adapted for any observations that can detect and extract line structures or projections of them, including 3D point cloud maps or image observations. We demonstrate that our formulation is powerful enough to exhibit a significant performance boost in event-based mapping and pose refinement across diverse datasets, and can be flexibly applied to multimodal scenarios. Our results confirm that the proposed line-based formulation is a robust and effective approach for the practical deployment of event-based perceptual modules. Project page: https://gwangtak.github.io/roel/

</details>


### [12] [Role-Adaptive Collaborative Formation Planning for Team of Quadruped Robots in Cluttered Environments](https://arxiv.org/abs/2602.18260)
*Magnus Norén,Marios-Nektarios Stamatopoulos,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出了一种基于角色自适应领导者-跟随者的四足机器人编队规划控制框架，能够在复杂环境中实现灵活、无碰撞的导航


<details>
  <summary>Details</summary>
Motivation: 传统方法采用固定领导者或刚性编队角色，在复杂环境中缺乏灵活性，难以实现安全高效的编队导航

Method: 整合动态角色分配和部分目标规划，采用虚拟弹簧阻尼系统确保编队稳定性，结合新型避障层自适应调整速度，使用FM2算法进行全局和局部路径规划

Result: 通过仿真和实物实验验证，展示了平滑协调、自适应角色切换以及在复杂非结构化环境中的鲁棒编队维护能力

Conclusion: 该框架成功实现了四足机器人在复杂环境中的灵活、安全编队导航，为多机器人系统在现实世界应用提供了有效解决方案

Abstract: This paper presents a role-adaptive Leader-Follower-based formation planning and control framework for teams of quadruped robots operating in cluttered environments. Unlike conventional methods with fixed leaders or rigid formation roles, the proposed approach integrates dynamic role assignment and partial goal planning, enabling flexible, collision-free navigation in complex scenarios. Formation stability and inter-robot safety are ensured through a virtual spring-damper system coupled with a novel obstacle avoidance layer that adaptively adjusts each agent's velocity. A dynamic look-ahead reference generator further enhances flexibility, allowing temporary formation deformation to maneuver around obstacles while maintaining goal-directed motion. The Fast Marching Square (FM2) algorithm provides the global path for the leader and local paths for the followers as the planning backbone. The framework is validated through extensive simulations and real-world experiments with teams of quadruped robots. Results demonstrate smooth coordination, adaptive role switching, and robust formation maintenance in complex, unstructured environments. A video featuring the simulation and physical experiments along with their associated visualizations can be found at https://youtu.be/scq37Tua9W4.

</details>


### [13] [Tendon-Driven Reciprocating and Non-Reciprocating Motion via Snapping Metabeams](https://arxiv.org/abs/2602.18330)
*Mohsen Jafarpour,Ayberk Yüksek,Shahab Eshghi,Stanislav Gorb,Edoardo Milana*

Main category: cs.RO

TL;DR: 研究开发了基于螺旋形超梁的肌腱驱动机构，利用非线性失稳实现快速几何转变，用于软体机器人中的往复和非往复运动


<details>
  <summary>Details</summary>
Motivation: 利用非线性失稳的快速几何转变特性，为软体机器人系统提供高效的运动生成方式

Method: 采用PLA材料通过熔融沉积成型制造螺旋形超梁结构，通过肌腱驱动机制，在不同边界条件下测试非线性行为

Result: 仅通过调整边界约束即可调节机械特性（临界力和稳定性）；螺旋几何允许大变形；集成到游泳机器人中实现两种驱动模式，非往复运动达到约81mm/s的推进效率

Conclusion: 几何驱动的失稳结构在软体机器人系统中具有高效、可编程驱动的潜力

Abstract: Snapping beams enable rapid geometric transitions through nonlinear instability, offering an efficient means of generating motion in soft robotic systems. In this study, a tendon-driven mechanism consisting of spiral-based metabeams was developed to exploit this principle for producing both reciprocating and non-reciprocating motion. The snapping structures were fabricated using fused deposition modeling with polylactic acid (PLA) and experimentally tested under different boundary conditions to analyze their nonlinear behavior. The results show that the mechanical characteristics, including critical forces and stability, can be tuned solely by adjusting the boundary constraints. The spiral geometry allows large reversible deformation even when made from a relatively stiff material such as PLA, providing a straightforward design concept for controllable snapping behavior. The developed mechanism was further integrated into a swimming robot, where tendon-driven fins exhibited two distinct actuation modes: reciprocating and non-reciprocating motion. The latter enabled efficient propulsion, producing a forward displacement of about 32 mm per 0.4 s cycle ($\approx$ 81 mm/s, equivalent to 0.4 body lengths per second). This study highlights the potential of geometry-driven snapping structures for efficient and programmable actuation in soft robotic systems.

</details>


### [14] [Downwash-aware Configuration Optimization for Modular Aerial Systems](https://arxiv.org/abs/2602.18344)
*Mengguang Li,Heinz Koeppl*

Main category: cs.RO

TL;DR: 提出一个为同质模块化空中系统生成和优化选择任务特定装配配置的框架，明确强制执行模块间下洗流的边界约束。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注平面布局且常忽略空气动力干扰，需要解决模块化空中系统在考虑下洗流约束下的最优配置问题。

Method: 首先大规模枚举非同构连接拓扑；其次通过求解非线性规划来检查可行性，并在执行器限制和下洗流约束下选择最小化控制输入的配置。

Result: 在基于物理的仿真中评估了该框架，并在真实世界实验中进行了演示验证。

Conclusion: 该框架能够有效生成和选择满足下洗流约束的最优模块化空中系统配置，在仿真和实验中均得到验证。

Abstract: This work proposes a framework that generates and optimally selects task-specific assembly configurations for a large group of homogeneous modular aerial systems, explicitly enforcing bounds on inter-module downwash. Prior work largely focuses on planar layouts and often ignores aerodynamic interference. In contrast, firstly we enumerate non-isomorphic connection topologies at scale; secondly, we solve a nonlinear program to check feasibility and select the configuration that minimizes control input subject to actuation limits and downwash constraints. We evaluate the framework in physics-based simulation and demonstrate it in real-world experiments.

</details>


### [15] [Zero-shot Interactive Perception](https://arxiv.org/abs/2602.18374)
*Venkatesh Sripada,Frank Guerin,Amir Ghalamzan*

Main category: cs.RO

TL;DR: ZS-IP是一个零样本交互感知框架，结合多策略操作（推和抓）与记忆驱动的视觉语言模型，通过物理交互解决复杂场景中的语义查询问题。


<details>
  <summary>Details</summary>
Motivation: 在部分可观察的复杂场景中，机器人需要通过物理交互来提取隐藏信息、解决遮挡和模糊性问题，这对交互感知提出了更高要求。

Method: ZS-IP包含三个核心组件：增强观察模块（结合传统关键点和新颖的pushlines视觉增强）、记忆引导动作模块（通过上下文查找强化语义推理）、机器人控制器（基于VLM输出执行推、拉或抓取操作）。

Result: 在7-DOF Franka Panda机械臂上的实验表明，ZS-IP在推任务中显著优于被动和基于视点的感知技术（如MOKA），同时保持非目标元素的完整性。

Conclusion: ZS-IP框架通过结合多策略操作和记忆驱动的VLM，有效提升了机器人在复杂场景中的交互感知能力，特别是在推操作任务中表现出色。

Abstract: Interactive perception (IP) enables robots to extract hidden information in their workspace and execute manipulation plans by physically interacting with objects and altering the state of the environment -- crucial for resolving occlusions and ambiguity in complex, partially observable scenarios. We present Zero-Shot IP (ZS-IP), a novel framework that couples multi-strategy manipulation (pushing and grasping) with a memory-driven Vision Language Model (VLM) to guide robotic interactions and resolve semantic queries. ZS-IP integrates three key components: (1) an Enhanced Observation (EO) module that augments the VLM's visual perception with both conventional keypoints and our proposed pushlines -- a novel 2D visual augmentation tailored to pushing actions, (2) a memory-guided action module that reinforces semantic reasoning through context lookup, and (3) a robotic controller that executes pushing, pulling, or grasping based on VLM output. Unlike grid-based augmentations optimized for pick-and-place, pushlines capture affordances for contact-rich actions, substantially improving pushing performance. We evaluate ZS-IP on a 7-DOF Franka Panda arm across diverse scenes with varying occlusions and task complexities. Our experiments demonstrate that ZS-IP outperforms passive and viewpoint-based perception techniques such as Mark-Based Visual Prompting (MOKA), particularly in pushing tasks, while preserving the integrity of non-target elements.

</details>


### [16] [Ori-Sense: origami capacitive sensing for soft robotic applications](https://arxiv.org/abs/2602.18379)
*Hugo de Souza Oliveira,Xin Li,Mohsen Jafarpour,Edoardo Milana*

Main category: cs.RO

TL;DR: Ori-Sense是一种基于倒置Kresling折纸结构的柔性电容传感器，可将扭转变形转化为电容变化，为软体机器人提供本体感知反馈。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够将机械变形直接转换为电信号的集成式柔性传感器，为软体机器人系统提供可靠的本体感知能力，解决传统刚性传感器与软体系统兼容性差的问题。

Method: 采用可溶芯模塑技术制造单块硅胶结构，嵌入导电TPU电极形成集成软电容器；通过机械测试评估刚度特性，有限元模拟验证应力分布，并进行电学测试测量电容变化与扭转角度的相关性。

Result: 传感器表现出低刚度和最小阻抗，扭矩值在±15mm轴向位移时低于0.01N·mm，30度扭转压缩时达0.03N·mm；电容调制可达30%，与扭转角度直接相关，在5mm轴向变形时最大灵敏度为S_theta~0.0067pF/度。

Conclusion: Ori-Sense成功实现了将扭转变形转换为可测量电容变化的柔性传感器设计，验证了其在软体机器人系统中提供可靠本体感知反馈的可行性，为集成式柔性传感系统提供了新思路。

Abstract: This work introduces Ori-Sense, a compliant capacitive sensor inspired by the inverted Kresling origami pattern. The device translates torsional deformation into measurable capacitance changes, enabling proprioceptive feedback for soft robotic systems. Using dissolvable-core molding, we fabricated a monolithic silicone structure with embedded conductive TPU electrodes, forming an integrated soft capacitor. Mechanical characterization revealed low stiffness and minimal impedance, with torque values below 0.01 N mm for axial displacements between -15 mm and 15 mm, and up to 0.03 N mm at 30 degrees twist under compression. Finite-element simulations confirmed localized stresses along fold lines and validated the measured torque-rotation response. Electrical tests showed consistent capacitance modulation up to 30%, directly correlated with the twist angle, and maximal sensitivity of S_theta ~ 0.0067 pF/deg at 5 mm of axial deformation.

</details>


### [17] [Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO](https://arxiv.org/abs/2602.18386)
*Mohamed Elgouhary,Amr S. El-Wakeel*

Main category: cs.RO

TL;DR: 使用强化学习实时调整纯追踪算法的关键参数（前瞻距离和转向增益），在自动驾驶赛车中显著提升路径跟踪性能


<details>
  <summary>Details</summary>
Motivation: 纯追踪算法在自动驾驶赛车中广泛使用，但其性能高度依赖于前瞻距离和转向增益等关键参数的选择。传统的基于速度的调整方法效果有限，且难以在不同赛道和速度配置间迁移。

Method: 提出强化学习方法，使用近端策略优化（PPO）在线联合选择前瞻距离Ld和转向增益g。策略观察紧凑状态特征（速度和曲率信息），在每个控制步骤输出(Ld, g)。在F1TENTH Gym中训练，部署在ROS 2栈中，直接驱动纯追踪算法（带轻微平滑）。

Result: 在仿真和实车测试中，提出的RL-PP控制器（联合选择Ld和g）在单圈时间、路径跟踪精度和转向平滑度方面一致优于固定前瞻距离PP、速度自适应PP、仅调整前瞻距离的RL变体，甚至超过了运动学MPC轨迹跟踪器。

Conclusion: 策略引导的参数调优能够可靠地改进基于几何的经典控制方法，证明了强化学习在优化传统控制算法参数方面的有效性。

Abstract: Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.

</details>


### [18] [How Fast Can I Run My VLA? Demystifying VLA Inference Performance with VLA-Perf](https://arxiv.org/abs/2602.18397)
*Wenqi Jiang,Jason Clemons,Karu Sankaralingam,Christos Kozyrakis*

Main category: cs.RO

TL;DR: VLA-Perf：首个系统分析视觉-语言-动作模型推理性能的框架，为实时机器人部署提供设计指导


<details>
  <summary>Details</summary>
Motivation: VLA模型在具身AI任务中表现出色，但实际机器人部署需要满足严格的实时推理要求。目前VLA推理性能研究不足，因为模型架构和推理系统的组合空间巨大，缺乏系统分析工具。

Method: 提出VLA-Perf分析性能模型，能够分析任意VLA模型与推理系统组合的推理性能。使用该工具首次系统研究VLA推理性能景观，从模型设计和部署两个维度进行分析。

Result: 通过全面评估提炼出15个关键要点，包括模型缩放、架构选择、长上下文视频输入、异步推理、双系统模型流水线等对性能的影响，以及设备端、边缘服务器、云端部署的权衡分析。

Conclusion: VLA-Perf为未来VLA模型和推理系统的设计提供了实用指导，帮助在实时机器人应用中平衡性能与效率。

Abstract: Vision-Language-Action (VLA) models have recently demonstrated impressive capabilities across various embodied AI tasks. While deploying VLA models on real-world robots imposes strict real-time inference constraints, the inference performance landscape of VLA remains poorly understood due to the large combinatorial space of model architectures and inference systems. In this paper, we ask a fundamental research question: How should we design future VLA models and systems to support real-time inference? To address this question, we first introduce VLA-Perf, an analytical performance model that can analyze inference performance for arbitrary combinations of VLA models and inference systems. Using VLA-Perf, we conduct the first systematic study of the VLA inference performance landscape. From a model-design perspective, we examine how inference performance is affected by model scaling, model architectural choices, long-context video inputs, asynchronous inference, and dual-system model pipelines. From the deployment perspective, we analyze where VLA inference should be executed -- on-device, on edge servers, or in the cloud -- and how hardware capability and network performance jointly determine end-to-end latency. By distilling 15 key takeaways from our comprehensive evaluation, we hope this work can provide practical guidance for the design of future VLA models and inference systems.

</details>
