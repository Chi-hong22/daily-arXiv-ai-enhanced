{"id": "2506.14138", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14138", "abs": "https://arxiv.org/abs/2506.14138", "authors": ["Ashish Gautam", "Prasanna Date", "Shruti Kulkarni", "Robert Patton", "Thomas Potok"], "title": "NeuroCoreX: An Open-Source FPGA-Based Spiking Neural Network Emulator with On-Chip Learning", "comment": "Neuromorphic computing, FPGA, STDP, Spiking Graph Neural Networks, Spiking Neural Networks, VHDL", "summary": "Spiking Neural Networks (SNNs) are computational models inspired by the structure and dynamics of biological neuronal networks. Their event-driven nature enables them to achieve high energy efficiency, particularly when deployed on neuromorphic hardware platforms. Unlike conventional Artificial Neural Networks (ANNs), which primarily rely on layered architectures, SNNs naturally support a wide range of connectivity patterns, from traditional layered structures to small-world graphs characterized by locally dense and globally sparse connections. In this work, we introduce NeuroCoreX, an FPGA-based emulator designed for the flexible co-design and testing of SNNs. NeuroCoreX supports all-to-all connectivity, providing the capability to implement diverse network topologies without architectural restrictions. It features a biologically motivated local learning mechanism based on Spike-Timing-Dependent Plasticity (STDP). The neuron model implemented within NeuroCoreX is the Leaky Integrate-and-Fire (LIF) model, with current-based synapses facilitating spike integration and transmission . A Universal Asynchronous Receiver-Transmitter (UART) interface is provided for programming and configuring the network parameters, including neuron, synapse, and learning rule settings. Users interact with the emulator through a simple Python-based interface, streamlining SNN deployment from model design to hardware execution. NeuroCoreX is released as an open-source framework, aiming to accelerate research and development in energy-efficient, biologically inspired computing.", "AI": {"tldr": "NeuroCoreX是一个基于FPGA的SNN模拟器，支持灵活的拓扑设计和测试，具有生物启发的学习机制和开放的Python接口。", "motivation": "传统人工神经网络（ANNs）在能量效率和拓扑灵活性上存在局限，而SNNs因其事件驱动特性更适合高效计算。NeuroCoreX旨在填补SNN硬件实现的空白。", "method": "采用FPGA平台实现SNN模拟器，支持全连接拓扑和STDP学习机制，使用LIF神经元模型和电流突触。提供UART接口和Python交互界面。", "result": "NeuroCoreX实现了灵活的SNN设计和高效硬件执行，支持多样化的网络拓扑和学习规则。", "conclusion": "NeuroCoreX作为开源框架，推动了高效生物启发计算的研究与发展。"}}
{"id": "2506.14425", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14425", "abs": "https://arxiv.org/abs/2506.14425", "authors": ["Tomofumi Kitamura", "Alex Fukunaga"], "title": "Is Selection All You Need in Differential Evolution?", "comment": "39 pages, 7 figures", "summary": "Differential Evolution (DE) is a widely used evolutionary algorithm for black-box optimization problems. However, in modern DE implementations, a major challenge lies in the limited population diversity caused by the fixed population size enforced by the generational replacement. Population size is a critical control parameter that significantly affects DE performance. Larger populations inherently contain a more diverse set of individuals, thereby facilitating broader exploration of the search space. Conversely, when the maximum evaluation budgets is constrained, smaller populations focusing on a limited number of promising candidates may be more suitable. Many state-of-the-art DE variants incorporate an archive mechanism, in which a subset of discarded individuals is preserved in an archive during generation replacement and reused in mutation operations. However, maintaining what is essentially a secondary population via an archive introduces additional design considerations, such as policies for insertion, deletion, and appropriate sizing. To address these limitations, we propose a novel DE framework called Unbounded Differential Evolution (UDE), which adds all generated candidates to the population without discarding any individual based on fitness. Unlike conventional DE, which removes inferior individuals during generational replacement, UDE eliminates replacement altogether, along with the associated complexities of archive management and dynamic population sizing. UDE represents a fundamentally new approach to DE, relying solely on selection mechanisms and enabling a more straightforward yet powerful search algorithm.", "AI": {"tldr": "论文提出了一种名为无界差分进化（UDE）的新框架，通过取消传统差分进化中的替换操作，避免了个体丢弃和存档管理问题，简化了算法设计。", "motivation": "传统差分进化（DE）算法在固定种群大小下存在种群多样性受限的问题，且存档机制引入额外复杂性。UDE旨在解决这些问题。", "method": "UDE将所有生成的候选个体保留在种群中，取消替换操作，仅依赖选择机制，简化了算法设计。", "result": "UDE避免了传统DE的存档管理和动态种群大小调整问题，提供了一种更简单且强大的搜索方法。", "conclusion": "UDE为差分进化提供了一种新思路，通过取消替换操作简化了算法，同时保持了高效性。"}}
{"id": "2506.14464", "categories": ["cs.NE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14464", "abs": "https://arxiv.org/abs/2506.14464", "authors": ["Maximilian Baronig", "Yeganeh Bahariasl", "Ozan Özdenizci", "Robert Legenstein"], "title": "A Scalable Hybrid Training Approach for Recurrent Spiking Neural Networks", "comment": null, "summary": "Recurrent spiking neural networks (RSNNs) can be implemented very efficiently in neuromorphic systems. Nevertheless, training of these models with powerful gradient-based learning algorithms is mostly performed on standard digital hardware using Backpropagation through time (BPTT). However, BPTT has substantial limitations. It does not permit online training and its memory consumption scales linearly with the number of computation steps. In contrast, learning methods using forward propagation of gradients operate in an online manner with a memory consumption independent of the number of time steps. These methods enable SNNs to learn from continuous, infinite-length input sequences. Yet, slow execution speed on conventional hardware as well as inferior performance has hindered their widespread application. In this work, we introduce HYbrid PRopagation (HYPR) that combines the efficiency of parallelization with approximate online forward learning. Our algorithm yields high-throughput online learning through parallelization, paired with constant, i.e., sequence length independent, memory demands. HYPR enables parallelization of parameter update computation over the sub sequences for RSNNs consisting of almost arbitrary non-linear spiking neuron models. We apply HYPR to networks of spiking neurons with oscillatory subthreshold dynamics. We find that this type of neuron model is particularly well trainable by HYPR, resulting in an unprecedentedly low task performance gap between approximate forward gradient learning and BPTT.", "AI": {"tldr": "HYPR是一种结合并行化和近似在线前向学习的混合传播算法，用于高效训练循环脉冲神经网络（RSNN），解决了BPTT的内存和在线学习限制。", "motivation": "BPTT在训练RSNN时存在内存消耗大且无法在线学习的局限性，而现有前向学习方法在性能和速度上表现不佳。", "method": "提出HYPR算法，结合并行化和近似在线前向学习，支持任意非线性脉冲神经元模型的并行参数更新。", "result": "HYPR在振荡亚阈值动态的脉冲神经元网络中表现优异，显著缩小了前向梯度学习与BPTT的性能差距。", "conclusion": "HYPR为RSNN提供了一种高效、低内存消耗的在线学习解决方案，特别适用于复杂神经元模型。"}}
{"id": "2506.13833", "categories": ["cs.SD", "cs.AI", "cs.RO", "eess.AS", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2506.13833", "abs": "https://arxiv.org/abs/2506.13833", "authors": ["Xiaoliang Chen", "Le Chang", "Xin Yu", "Yunhe Huang", "Xianling Tu"], "title": "A Survey on World Models Grounded in Acoustic Physical Information", "comment": "28 pages,11 equations", "summary": "This survey provides a comprehensive overview of the emerging field of world models grounded in the foundation of acoustic physical information. It examines the theoretical underpinnings, essential methodological frameworks, and recent technological advancements in leveraging acoustic signals for high-fidelity environmental perception, causal physical reasoning, and predictive simulation of dynamic events. The survey explains how acoustic signals, as direct carriers of mechanical wave energy from physical events, encode rich, latent information about material properties, internal geometric structures, and complex interaction dynamics. Specifically, this survey establishes the theoretical foundation by explaining how fundamental physical laws govern the encoding of physical information within acoustic signals. It then reviews the core methodological pillars, including Physics-Informed Neural Networks (PINNs), generative models, and self-supervised multimodal learning frameworks. Furthermore, the survey details the significant applications of acoustic world models in robotics, autonomous driving, healthcare, and finance. Finally, it systematically outlines the important technical and ethical challenges while proposing a concrete roadmap for future research directions toward robust, causal, uncertainty-aware, and responsible acoustic intelligence. These elements collectively point to a research pathway towards embodied active acoustic intelligence, empowering AI systems to construct an internal \"intuitive physics\" engine through sound.", "AI": {"tldr": "本文综述了基于声学物理信息的世界模型研究，涵盖理论、方法、应用及未来方向。", "motivation": "探索声学信号在高保真环境感知、因果物理推理和动态事件预测模拟中的潜力。", "method": "包括物理信息神经网络（PINNs）、生成模型和自监督多模态学习框架。", "result": "声学世界模型在机器人、自动驾驶、医疗和金融等领域有重要应用。", "conclusion": "未来研究需解决技术和伦理挑战，构建因果、不确定性感知且负责任的声学智能。"}}
{"id": "2506.13794", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.13794", "abs": "https://arxiv.org/abs/2506.13794", "authors": ["Jared James Grogan"], "title": "AgentFacts: Universal KYA Standard for Verified AI Agent Metadata & Deployment", "comment": "15 pages, 1 figure, technical specification with appendix. Apache 2.0 license. Prior art established 2022", "summary": "Enterprise AI deployment faces critical \"Know Your Agent\" (KYA) challenges where organizations must verify third-party agent capabilities and establish trust without standardized metadata or verification infrastructure. Current approaches rely on self-declared capabilities and custom integration processes that create trust gaps and coordination friction limiting confident enterprise adoption. This paper presents AgentFacts, a universal metadata standard that enables systematic agent verification through cryptographically-signed capability declarations, multi-authority validation, and dynamic permission management. The specification introduces domain-specialized verification where different trusted authorities validate specific metadata aspects based on their expertise, eliminating single points of trust failure while enabling graduated confidence assessment. AgentFacts transforms agent procurement from custom integration projects into standardized workforce management, providing the transparency and governance infrastructure necessary for enterprise AI coordination at scale.", "AI": {"tldr": "AgentFacts提出了一种通用元数据标准，通过加密签名声明和多权威验证解决企业AI部署中的信任问题。", "motivation": "企业AI部署面临第三方代理能力验证和信任建立的挑战，缺乏标准化元数据和验证基础设施。", "method": "AgentFacts通过加密签名能力声明、多权威验证和动态权限管理实现系统化代理验证。", "result": "该标准将代理采购从定制集成项目转变为标准化管理，提供透明度和治理基础设施。", "conclusion": "AgentFacts为企业AI规模化协调提供了必要的信任和治理框架。"}}
{"id": "2506.13878", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.13878", "abs": "https://arxiv.org/abs/2506.13878", "authors": ["Lisbel Bárzaga-Martell", "Francisco Ibáñez", "Angel L. Cedeño", "Maria Coronel", "Francisco Concha", "Norelys Aguila-Camacho", "José Ricardo Pérez-Correa"], "title": "Observer Switching Strategy for Enhanced State Estimation in CSTR Networks", "comment": "This work has been submitted to the ISA Transactions for possible publication. 18 pages, 10 Figures", "summary": "Accurate state estimation is essential for monitoring and controlling nonlinear chemical reactors, such as continuous stirred-tank reactors (CSTRs), where limited sensor coverage and process uncertainties hinder real-time observability. This paper introduces a novel multi-observer switching framework that combines several advanced estimators: Extended Luenberger Observer (ELO), Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF), Quadrature Kalman Filter (QKF), and Particle Filter (PF), operating in parallel. At each sampling instant, a cost function based on the $L_1$ norm and Kullback-Leibler divergence selects the observer, yielding the best agreement with available measurements. The proposed architecture is validated through simulations of both linearized and fully nonlinear CSTR models with up to three reactors in series. Results show that the switching strategy significantly reduces estimation errors compared to single-observer approaches, especially under partial observability and parametric uncertainty. Despite its modular design, the framework remains computationally tractable, making it suitable for real-time industrial applications such as fault detection and model-based predictive control.", "AI": {"tldr": "提出了一种多观测器切换框架，结合多种先进估计器，显著降低了非线性化学反应器的状态估计误差。", "motivation": "非线性化学反应器（如CSTR）的状态估计受限于传感器覆盖和过程不确定性，需要更准确的实时观测方法。", "method": "采用多观测器并行运行（ELO、EKF、UKF、QKF、PF），通过基于L1范数和Kullback-Leibler散度的成本函数选择最佳观测器。", "result": "仿真验证表明，该框架在部分可观测性和参数不确定性下显著优于单一观测器方法。", "conclusion": "该框架计算高效，适用于实时工业应用，如故障检测和模型预测控制。"}}
{"id": "2506.13769", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13769", "abs": "https://arxiv.org/abs/2506.13769", "authors": ["Filippo Leveni"], "title": "Non-planar Object Detection and Identification by Features Matching and Triangulation Growth", "comment": "Master's thesis at Politecnico di Milano", "summary": "Object detection and identification is surely a fundamental topic in the computer vision field; it plays a crucial role in many applications such as object tracking, industrial robots control, image retrieval, etc. We propose a feature-based approach for detecting and identifying distorted occurrences of a given template in a scene image by incremental grouping of feature matches between the image and the template. For this purpose, we consider the Delaunay triangulation of template features as an useful tool through which to be guided in this iterative approach. The triangulation is treated as a graph and, starting from a single triangle, neighboring nodes are considered and the corresponding features are identified; then matches related to them are evaluated to determine if they are worthy to be grouped. This evaluation is based on local consistency criteria derived from geometric and photometric properties of local features. Our solution allows the identification of the object in situations where geometric models (e.g. homography) does not hold, thus enable the detection of objects such that the template is non planar or when it is planar but appears distorted in the image. We show that our approach performs just as well or better than application of homography-based RANSAC in scenarios in which distortion is nearly absent, while when the deformation becomes relevant our method shows better description performance.", "AI": {"tldr": "提出了一种基于特征的方法，通过增量分组特征匹配来检测和识别场景图像中的扭曲模板。该方法利用Delaunay三角剖分作为指导工具，通过局部一致性标准评估匹配，适用于非平面或扭曲的模板。", "motivation": "解决在几何模型（如单应性）不适用的情况下（如非平面或扭曲模板）的对象检测和识别问题。", "method": "使用Delaunay三角剖分作为图结构，从单个三角形开始逐步扩展，通过几何和光度特性的局部一致性标准评估特征匹配。", "result": "在无变形或轻微变形场景中表现与基于单应性的RANSAC相当或更好，在显著变形时表现更优。", "conclusion": "该方法在复杂变形情况下具有更好的描述性能，扩展了对象检测的应用范围。"}}
{"id": "2506.13771", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.13771", "abs": "https://arxiv.org/abs/2506.13771", "authors": ["Banseok Lee", "Dongkyu Kim", "Youngcheon You", "Youngmin Kim"], "title": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization", "comment": null, "summary": "Deploying large language models (LLMs) often faces challenges from substantial memory and computational costs. Quantization offers a solution, yet performance degradation in the sub-1-bit regime remains particularly difficult. This paper introduces LittleBit, a novel method for extreme LLM compression. It targets levels like 0.1 bits per weight (BPW), achieving nearly 31$\\times$ memory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents weights in a low-rank form using latent matrix factorization, subsequently binarizing these factors. To counteract information loss from this extreme precision, it integrates a multi-scale compensation mechanism. This includes row, column, and an additional latent dimension that learns per-rank importance. Two key contributions enable effective training: Dual Sign-Value-Independent Decomposition (Dual-SVID) for stable quantization-aware training (QAT) initialization, and integrated Residual Compensation to mitigate errors. Extensive experiments confirm LittleBit's superiority in sub-1-bit quantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading method's 0.7 BPW. This establishes a superior size-performance trade-off, with kernel-level benchmarks indicating potential for a 5$\\times$ speedup compared to FP16. LittleBit paves the way for deploying powerful LLMs in resource-constrained environments.", "AI": {"tldr": "LittleBit是一种新颖的极端LLM压缩方法，通过低秩矩阵分解和二值化实现0.1 BPW的压缩，显著减少内存和计算成本。", "motivation": "解决大语言模型（LLM）部署中内存和计算成本高的问题，尤其是在亚1比特量化中的性能下降挑战。", "method": "采用低秩矩阵分解表示权重，随后二值化，并引入多尺度补偿机制（包括行、列和潜在维度）以减少信息损失。关键贡献包括Dual-SVID和残差补偿。", "result": "在0.1 BPW下，Llama2-7B性能超过现有方法的0.7 BPW，内存减少31倍，潜在速度提升5倍。", "conclusion": "LittleBit为资源受限环境中部署高性能LLM提供了有效解决方案。"}}
{"id": "2506.13867", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13867", "abs": "https://arxiv.org/abs/2506.13867", "authors": ["Yunchu Zhang", "Shubham Mittal", "Zhengyu Zhang", "Liyiming Ke", "Siddhartha Srinivasa", "Abhishek Gupta"], "title": "ATK: Automatic Task-driven Keypoint Selection for Robust Policy Learning", "comment": null, "summary": "Visuomotor policies often suffer from perceptual challenges, where visual differences between training and evaluation environments degrade policy performance. Policies relying on state estimations, like 6D pose, require task-specific tracking and are difficult to scale, while raw sensor-based policies may lack robustness to small visual disturbances.In this work, we leverage 2D keypoints - spatially consistent features in the image frame - as a flexible state representation for robust policy learning and apply it to both sim-to-real transfer and real-world imitation learning. However, the choice of which keypoints to use can vary across objects and tasks. We propose a novel method, ATK, to automatically select keypoints in a task-driven manner so that the chosen keypoints are predictive of optimal behavior for the given task. Our proposal optimizes for a minimal set of keypoints that focus on task-relevant parts while preserving policy performance and robustness. We distill expert data (either from an expert policy in simulation or a human expert) into a policy that operates on RGB images while tracking the selected keypoints. By leveraging pre-trained visual modules, our system effectively encodes states and transfers policies to the real-world evaluation scenario despite wide scene variations and perceptual challenges such as transparent objects, fine-grained tasks, and deformable objects manipulation. We validate ATK on various robotic tasks, demonstrating that these minimal keypoint representations significantly improve robustness to visual disturbances and environmental variations. See all experiments and more details on our website.", "AI": {"tldr": "论文提出了一种名为ATK的方法，通过自动选择任务相关的2D关键点来提升视觉运动策略的鲁棒性，适用于仿真到现实的迁移和真实世界模仿学习。", "motivation": "视觉运动策略在训练和评估环境中的视觉差异会导致性能下降，而现有的状态估计方法（如6D姿态）难以扩展，基于原始传感器的策略对视觉干扰缺乏鲁棒性。", "method": "提出ATK方法，自动选择任务相关的2D关键点，优化为最小集合以保持策略性能和鲁棒性，并利用预训练视觉模块编码状态。", "result": "在多种机器人任务中验证，表明所选关键点显著提升了策略对视觉干扰和环境变化的鲁棒性。", "conclusion": "ATK方法通过任务驱动的关键点选择，有效提升了视觉运动策略的鲁棒性和适应性。"}}
{"id": "2506.14149", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2506.14149", "abs": "https://arxiv.org/abs/2506.14149", "authors": ["Ayumi Igarashi", "Pasin Manurangsi", "Hirotaka Yoneda"], "title": "Dividing Conflicting Items Fairly", "comment": "22 pages, full version of accepted IJCAI-25 paper", "summary": "We study the allocation of indivisible goods under conflicting constraints, represented by a graph. In this framework, vertices correspond to goods and edges correspond to conflicts between a pair of goods. Each agent is allocated an independent set in the graph. In a recent work of Kumar et al. (2024), it was shown that a maximal EF1 allocation exists for interval graphs and two agents with monotone valuations. We significantly extend this result by establishing that a maximal EF1 allocation exists for \\emph{any graph} when the two agents have monotone valuations. To compute such an allocation, we present a polynomial-time algorithm for additive valuations, as well as a pseudo-polynomial time algorithm for monotone valuations. Moreover, we complement our findings by providing a counterexample demonstrating a maximal EF1 allocation may not exist for three agents with monotone valuations; further, we establish NP-hardness of determining the existence of such allocations for every fixed number $n \\geq 3$ of agents. All of our results for goods also apply to the allocation of chores.", "AI": {"tldr": "论文研究了在冲突约束下不可分割物品的分配问题，通过图表示冲突关系，证明了对于任意图和两个单调估值代理，存在最大EF1分配，并提供了算法和反例。", "motivation": "研究在冲突约束下如何公平分配不可分割物品，扩展了Kumar等人（2024）对区间图和两个代理的结果。", "method": "使用图论模型表示冲突，提出多项式时间算法（加性估值）和伪多项式时间算法（单调估值），并通过反例和NP-hardness证明扩展结果。", "result": "证明了任意图和两个单调估值代理下存在最大EF1分配，但对三个代理则不存在，且判定问题对n≥3代理是NP难的。", "conclusion": "研究扩展了EF1分配的存在性结果，并揭示了其局限性，为冲突约束下的公平分配提供了理论和算法支持。"}}
{"id": "2506.13814", "categories": ["cs.GR", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.13814", "abs": "https://arxiv.org/abs/2506.13814", "authors": ["Lufei Liu", "Tor M. Aamodt"], "title": "ReFrame: Layer Caching for Accelerated Inference in Real-Time Rendering", "comment": "Published at ICML 2025", "summary": "Graphics rendering applications increasingly leverage neural networks in tasks such as denoising, supersampling, and frame extrapolation to improve image quality while maintaining frame rates. The temporal coherence inherent in these tasks presents an opportunity to reuse intermediate results from previous frames and avoid redundant computations. Recent work has shown that caching intermediate features to be reused in subsequent inferences is an effective method to reduce latency in diffusion models. We extend this idea to real-time rendering and present ReFrame, which explores different caching policies to optimize trade-offs between quality and performance in rendering workloads. ReFrame can be applied to a variety of encoder-decoder style networks commonly found in rendering pipelines. Experimental results show that we achieve 1.4x speedup on average with negligible quality loss in three real-time rendering tasks. Code available: https://ubc-aamodt-group.github.io/reframe-layer-caching/", "AI": {"tldr": "ReFrame通过缓存中间特征优化实时渲染任务，在质量损失可忽略的情况下平均提速1.4倍。", "motivation": "利用时序一致性重用中间结果，减少冗余计算，提升渲染效率。", "method": "扩展缓存中间特征的方法至实时渲染，探索不同缓存策略以平衡质量与性能。", "result": "在三种实时渲染任务中平均提速1.4倍，质量损失可忽略。", "conclusion": "ReFrame适用于多种编码器-解码器网络，有效优化渲染性能。"}}
{"id": "2506.13882", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.13882", "abs": "https://arxiv.org/abs/2506.13882", "authors": ["Azim Ibragimov", "Ethan Wilson", "Kevin R. B. Butler", "Eakta Jain"], "title": "Toward Practical Privacy in XR: Empirical Analysis of Multimodal Anonymization Mechanisms", "comment": null, "summary": "As extended reality (XR) systems become increasingly immersive and sensor-rich, they enable the collection of fine-grained behavioral signals such as eye and body telemetry. These signals support personalized and responsive experiences and may also contain unique patterns that can be linked back to individuals. However, privacy mechanisms that naively pair unimodal mechanisms (e.g., independently apply privacy mechanisms for eye and body privatization) are often ineffective at preventing re-identification in practice. In this work, we systematically evaluate real-time privacy mechanisms for XR, both individually and in pair, across eye and body modalities. To preserve usability, all mechanisms were tuned based on empirically grounded thresholds for real-time interaction. We evaluated four eye and ten body mechanisms across multiple datasets, comprising up to 407 participants. Our results show that while obfuscating eye telemetry alone offers moderate privacy gains, body telemetry perturbation is substantially more effective. When carefully paired, multimodal mechanisms reduce re-identification rate from 80.3% to 26.3% in casual XR applications (e.g., VRChat and Job Simulator) and from 84.8% to 26.1% in competitive XR applications (e.g., Beat Saber and Synth Riders), all without violating real-time usability requirements. These findings underscore the potential of modality-specific and context-aware privacy strategies for protecting behavioral data in XR environments.", "AI": {"tldr": "论文研究了扩展现实（XR）系统中行为和眼动数据的隐私保护机制，发现多模态机制比单模态更有效，能将重识别率从80%降至26%，同时满足实时交互需求。", "motivation": "随着XR系统的沉浸感和传感器丰富性提升，行为和眼动数据可能泄露个人隐私，现有单模态隐私机制效果不佳。", "method": "系统评估了四种眼动和十种行为隐私机制，结合多模态策略，基于407名参与者的数据进行了实验。", "result": "行为数据扰动比眼动数据更有效，多模态机制在休闲和竞争性XR应用中分别将重识别率从80.3%和84.8%降至26.3%和26.1%。", "conclusion": "多模态、情境感知的隐私策略在保护XR行为数据方面具有潜力，且不影响实时交互体验。"}}
{"id": "2506.13969", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.13969", "abs": "https://arxiv.org/abs/2506.13969", "authors": ["Vsevolod Vladimirovich Deriushkin"], "title": "Set theoretic solution for the tuning problem", "comment": null, "summary": "In this paper I want to suggest a new solution to the problem of musical tuning. On one hand, I see it as a generalization of Just Intonation (JI) to inharmonic timbers, on another, as a unification of spectral interference and harmonicity contributions to consonance within a single framework. The main achievement of the work is the ability to mathematically quantify the phenomenon of musical consonance using set theory. That quantification is done by defining two measures of consonance: affinity and harmonicity. These measures naturally generate sets of intervals that can be used as dynamic tuning systems. The paper is aimed at a broad audience of people who may not be skilled in music and tuning theory or mathematics. Thus, I attempt to give as much details and explanations as I can, while keeping the number of pages as low as possible.", "AI": {"tldr": "提出了一种新的音乐调音解决方案，将Just Intonation推广到非谐波音色，并统一了频谱干扰与和谐性对协和度的贡献。", "motivation": "解决音乐调音问题，为不熟悉音乐理论或数学的读者提供易懂的解释。", "method": "通过集合论定义协和度的两种度量：亲和性与和谐性，生成动态调音系统。", "result": "能够数学量化音乐协和度现象，并生成可用作动态调音系统的音程集合。", "conclusion": "该框架为音乐协和度提供了统一且可量化的解决方案，适用于广泛读者。"}}
{"id": "2506.13811", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.13811", "abs": "https://arxiv.org/abs/2506.13811", "authors": ["Sompote Youwai", "David Phim", "Vianne Gayl Murcia", "Rianne Clair Onas"], "title": "Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study", "comment": null, "summary": "This study investigates router-based multi-agent systems for automating foundation design calculations through intelligent task classification and expert selection. Three approaches were evaluated: single-agent processing, multi-agent designer-checker architecture, and router-based expert selection. Performance assessment utilized baseline models including DeepSeek R1, ChatGPT 4 Turbo, Grok 3, and Gemini 2.5 Pro across shallow foundation and pile design scenarios. The router-based configuration achieved performance scores of 95.00% for shallow foundations and 90.63% for pile design, representing improvements of 8.75 and 3.13 percentage points over standalone Grok 3 performance respectively. The system outperformed conventional agentic workflows by 10.0 to 43.75 percentage points. Grok 3 demonstrated superior standalone performance without external computational tools, indicating advances in direct LLM mathematical reasoning for engineering applications. The dual-tier classification framework successfully distinguished foundation types, enabling appropriate analytical approaches. Results establish router-based multi-agent systems as optimal for foundation design automation while maintaining professional documentation standards. Given safety-critical requirements in civil engineering, continued human oversight remains essential, positioning these systems as advanced computational assistance tools rather than autonomous design replacements in professional practice.", "AI": {"tldr": "研究探讨了基于路由器的多智能体系统在基础设计计算自动化中的应用，通过智能任务分类和专家选择，显著提升了性能。", "motivation": "旨在提高基础设计计算的效率和准确性，同时满足工程实践中的安全和专业标准。", "method": "评估了三种方法：单智能体处理、多智能体设计-检查架构和基于路由器的专家选择，并对比了多种基线模型的性能。", "result": "基于路由器的系统在浅基础和桩基设计中分别达到95.00%和90.63%的性能，优于传统工作流程和独立模型。", "conclusion": "基于路由器的多智能体系统是基础设计自动化的最佳选择，但仍需人类监督以确保安全。"}}
{"id": "2506.13961", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13961", "abs": "https://arxiv.org/abs/2506.13961", "authors": ["Mohamed Serry", "Haoyu Li", "Ruikun Zhou", "Huan Zhang", "Jun Liu"], "title": "Safe Domains of Attraction for Discrete-Time Nonlinear Systems: Characterization and Verifiable Neural Network Estimation", "comment": null, "summary": "Analysis of nonlinear autonomous systems typically involves estimating domains of attraction, which have been a topic of extensive research interest for decades. Despite that, accurately estimating domains of attraction for nonlinear systems remains a challenging task, where existing methods are conservative or limited to low-dimensional systems. The estimation becomes even more challenging when accounting for state constraints. In this work, we propose a framework to accurately estimate safe (state-constrained) domains of attraction for discrete-time autonomous nonlinear systems. In establishing this framework, we first derive a new Zubov equation, whose solution corresponds to the exact safe domain of attraction. The solution to the aforementioned Zubov equation is shown to be unique and continuous over the whole state space. We then present a physics-informed approach to approximating the solution of the Zubov equation using neural networks. To obtain certifiable estimates of the domain of attraction from the neural network approximate solutions, we propose a verification framework that can be implemented using standard verification tools (e.g., $α,\\!β$-CROWN and dReal). To illustrate its effectiveness, we demonstrate our approach through numerical examples concerning nonlinear systems with state constraints.", "AI": {"tldr": "提出了一种估计离散时间非线性自治系统安全吸引域的新框架，通过Zubov方程和神经网络近似解实现高精度估计。", "motivation": "现有方法在估计非线性系统的吸引域时存在保守性或低维限制，且难以处理状态约束。", "method": "推导新的Zubov方程，提出基于神经网络的物理信息近似解方法，并设计验证框架确保解的可靠性。", "result": "Zubov方程的解在状态空间内唯一且连续，通过数值实验验证了方法的有效性。", "conclusion": "该框架为非线性系统安全吸引域的高精度估计提供了可行方案。"}}
{"id": "2506.13770", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.13770", "abs": "https://arxiv.org/abs/2506.13770", "authors": ["Shiwen Zhang", "Zhuowei Chen", "Lang Chen", "Yanze Wu"], "title": "CDST: Color Disentangled Style Transfer for Universal Style Reference Customization", "comment": "codes and models will be released if the paper is accepted", "summary": "We introduce Color Disentangled Style Transfer (CDST), a novel and efficient two-stream style transfer training paradigm which completely isolates color from style and forces the style stream to be color-blinded. With one same model, CDST unlocks universal style transfer capabilities in a tuning-free manner during inference. Especially, the characteristics-preserved style transfer with style and content references is solved in the tuning-free way for the first time. CDST significantly improves the style similarity by multi-feature image embeddings compression and preserves strong editing capability via our new CDST style definition inspired by Diffusion UNet disentanglement law. By conducting thorough qualitative and quantitative experiments and human evaluations, we demonstrate that CDST achieves state-of-the-art results on various style transfer tasks.", "AI": {"tldr": "CDST是一种新颖的双流风格迁移训练范式，通过完全分离颜色与风格，实现无需调优的通用风格迁移。", "motivation": "解决传统风格迁移中颜色与风格耦合的问题，并首次实现无需调优的特征保留风格迁移。", "method": "采用双流训练范式，强制风格流对颜色盲化，并结合多特征图像嵌入压缩和Diffusion UNet解耦定律。", "result": "在多种风格迁移任务中取得最先进效果，并通过实验和人工评估验证。", "conclusion": "CDST为风格迁移提供了高效、通用的解决方案，显著提升了风格相似性和编辑能力。"}}
{"id": "2506.13772", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13772", "abs": "https://arxiv.org/abs/2506.13772", "authors": ["Zhenyan Lu", "Daliang Xu", "Dongqi Cai", "Zexi Li", "Wei Liu", "Fangming Liu", "Shangguang Wang", "Mengwei Xu"], "title": "MobiEdit: Resource-efficient Knowledge Editing for Personalized On-device LLMs", "comment": null, "summary": "Large language models (LLMs) are deployed on mobile devices to power killer applications such as intelligent assistants. LLMs pre-trained on general corpora often hallucinate when handling personalized or unseen queries, leading to incorrect or outdated responses. Knowledge editing addresses this by identifying and adjusting a small crucial portion of model weights, without compromising the general knowledge. However, prior knowledge editing methods are impractical to run on local devices due to the resource-heavy backpropagation (BP) needed for updates. We present MobiEdit, the first mobile knowledge editing framework that enables efficient LLM personalization on commercial off-the-shelf (COTS) mobile devices. MobiEdit replaces full-precision BP with quantized forward-only gradient estimation, thus compatible with the energy-efficient mobile neural processing units (NPUs). MobiEdit replaces full-precision backpropagation with quantized forward-only gradient estimation, making it compatible with energy-efficient mobile NPUs. To further improve gradient estimation efficiency, we introduce two optimizations: an early stoping mechanism that adaptively terminates editing upon success and a prefix cache that reuses computation across steps. Our approach enables real-time editing of a 3B-parameter model (Qwen2.5-3B-Instruct) on COTS mobile devices with 7.6$\\times$ less memory, 14.7 $\\times$ less energy and 3.6$\\times$ less latency compared to previous knowledge editing methods.", "AI": {"tldr": "MobiEdit是一个移动知识编辑框架，首次实现在商用移动设备上高效个性化大型语言模型（LLMs），通过量化前向梯度估计替代资源密集的反向传播，显著降低内存、能耗和延迟。", "motivation": "解决LLMs在移动设备上处理个性化查询时产生的幻觉问题，同时避免传统知识编辑方法因反向传播资源消耗大而无法在移动设备上运行的问题。", "method": "提出MobiEdit框架，采用量化前向梯度估计替代反向传播，并引入早期停止机制和前缀缓存优化梯度估计效率。", "result": "在商用移动设备上实现了对3B参数模型（Qwen2.5-3B-Instruct）的实时编辑，内存减少7.6倍，能耗降低14.7倍，延迟减少3.6倍。", "conclusion": "MobiEdit为移动设备上的LLM知识编辑提供了高效、实用的解决方案，显著提升了资源利用效率。"}}
{"id": "2506.13915", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13915", "abs": "https://arxiv.org/abs/2506.13915", "authors": ["Katherine Mao", "Hongzhan Yu", "Ruipeng Zhang", "Igor Spasojevic", "M Ani Hsieh", "Sicun Gao", "Vijay Kumar"], "title": "Sequence Modeling for Time-Optimal Quadrotor Trajectory Optimization with Sampling-based Robustness Analysis", "comment": null, "summary": "Time-optimal trajectories drive quadrotors to their dynamic limits, but computing such trajectories involves solving non-convex problems via iterative nonlinear optimization, making them prohibitively costly for real-time applications. In this work, we investigate learning-based models that imitate a model-based time-optimal trajectory planner to accelerate trajectory generation. Given a dataset of collision-free geometric paths, we show that modeling architectures can effectively learn the patterns underlying time-optimal trajectories. We introduce a quantitative framework to analyze local analytic properties of the learned models, and link them to the Backward Reachable Tube of the geometric tracking controller. To enhance robustness, we propose a data augmentation scheme that applies random perturbations to the input paths. Compared to classical planners, our method achieves substantial speedups, and we validate its real-time feasibility on a hardware quadrotor platform. Experiments demonstrate that the learned models generalize to previously unseen path lengths. The code for our approach can be found here: https://github.com/maokat12/lbTOPPQuad", "AI": {"tldr": "该论文提出了一种基于学习的方法，通过模仿基于模型的时间最优轨迹规划器，加速四旋翼飞行器的轨迹生成。", "motivation": "传统方法计算时间最优轨迹涉及非凸问题，计算成本高，难以实时应用。", "method": "利用学习模型从无碰撞几何路径数据集中学习时间最优轨迹的模式，并引入定量框架分析模型局部解析性质。", "result": "相比传统规划器，该方法显著加速轨迹生成，并在硬件平台上验证了实时可行性。", "conclusion": "学习模型能够泛化到未见过的路径长度，且通过数据增强提高了鲁棒性。"}}
{"id": "2506.14544", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2506.14544", "abs": "https://arxiv.org/abs/2506.14544", "authors": ["Antonio Casares", "Pierre Ohlmann", "Michał Skrzypczak", "Igor Walukiewicz"], "title": "Infinite lexicographic products of positional objectives", "comment": null, "summary": "This paper contributes to the study of positional determinacy of infinite duration games played on potentially infinite graphs. Recently, [Ohlmann, TheoretiCS 2023] established that positionality of prefix-independent objectives is preserved by finite lexicographic products. We propose two different notions of infinite lexicographic products indexed by arbitrary ordinals, and extend Ohlmann's result by proving that they also preserve positionality. In the context of one-player positionality, this extends positional determinacy results of [Grädel and Walukiewicz, Logical Methods in Computer Science 2006] to edge-labelled games and arbitrarily many priorities for both Max-Parity and Min-Parity. Moreover, we show that the Max-Parity objectives over countable ordinals are complete for the infinite levels of the difference hierarchy over $Σ^0_2$ and that Min-Parity is complete for the class $Σ^0_3$. We obtain therefore positional languages that are complete for all those levels, as well as new insights about closure under unions and neutral letters.", "AI": {"tldr": "本文研究了无限持续时间游戏中位置确定性的问题，扩展了Ohlmann关于有限词典积保留位置性的结果，提出了两种无限词典积的概念，并证明了其同样保留位置性。此外，还扩展了一人位置性的结果，并证明了Max-Parity和Min-Parity目标在无限层次上的完备性。", "motivation": "研究无限持续时间游戏中位置确定性的扩展性，特别是无限词典积对位置性的影响，以及Max-Parity和Min-Parity目标的完备性。", "method": "提出两种无限词典积的概念，并证明其保留位置性；扩展一人位置性的结果，分析Max-Parity和Min-Parity目标的完备性。", "result": "证明了无限词典积保留位置性；Max-Parity目标在无限层次上对Σ²₀差分层完备，Min-Parity对Σ³₀完备；获得了完备的位置语言。", "conclusion": "本文扩展了位置确定性的结果，提供了无限词典积的新见解，并揭示了Max-Parity和Min-Parity目标的完备性。"}}
{"id": "2506.13827", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13827", "abs": "https://arxiv.org/abs/2506.13827", "authors": ["Zhuoying Li", "Zhu Xu", "Yuxin Peng", "Yang Liu"], "title": "Balancing Preservation and Modification: A Region and Semantic Aware Metric for Instruction-Based Image Editing", "comment": null, "summary": "Instruction-based image editing, which aims to modify the image faithfully according to the instruction while preserving irrelevant content unchanged, has made significant progress. However, there still lacks a comprehensive metric for assessing the editing quality. Existing metrics either require high human evaluation costs, which hinder large-scale evaluation, or are adapted from other tasks and lose task-specific concerns, failing to comprehensively evaluate both instruction-based modification and preservation of irrelevant regions, resulting in biased evaluation. To tackle this, we introduce a new metric called Balancing Preservation and Modification (BPM), tailored for instruction-based image editing by explicitly disentangling the image into editing-relevant and irrelevant regions for specific consideration. We first identify and locate editing-relevant regions, followed by a two-tier process to assess editing quality: Region-Aware Judge evaluates whether the position and size of the edited region align with the instruction, and Semantic-Aware Judge further assesses the instruction content compliance within editing-relevant regions as well as content preservation within irrelevant regions, yielding comprehensive and interpretable quality assessment. Moreover, the editing-relevant region localization in BPM can be integrated into image editing approaches to improve editing quality, demonstrating its broad applicability. We verify the effectiveness of the BPM metric on comprehensive instruction-editing data, and the results show the highest alignment with human evaluation compared to existing metrics, indicating its efficacy. Code is available at: https://joyli-x.github.io/BPM/", "AI": {"tldr": "提出了一种名为BPM的新指标，专门用于基于指令的图像编辑任务，通过分离编辑相关和无关区域，综合评估编辑质量和内容保留。", "motivation": "现有指标要么成本高，要么缺乏任务针对性，无法全面评估基于指令的编辑质量。", "method": "BPM通过定位编辑相关区域，采用两阶段评估（区域感知和语义感知）来综合评估编辑质量和内容保留。", "result": "BPM在实验中表现最佳，与人工评估一致性最高。", "conclusion": "BPM是一种高效、全面的评估指标，并可集成到编辑方法中提升质量。"}}
{"id": "2506.13904", "categories": ["cs.HC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13904", "abs": "https://arxiv.org/abs/2506.13904", "authors": ["Ivania Donoso-Guzmán", "Kristýna Sirka Kacafírková", "Maxwell Szymanski", "An Jacobs", "Denis Parra", "Katrien Verbert"], "title": "A Systematic Review of User-Centred Evaluation of Explainable AI in Healthcare", "comment": null, "summary": "Despite promising developments in Explainable Artificial Intelligence, the practical value of XAI methods remains under-explored and insufficiently validated in real-world settings. Robust and context-aware evaluation is essential, not only to produce understandable explanations but also to ensure their trustworthiness and usability for intended users, but tends to be overlooked because of no clear guidelines on how to design an evaluation with users.\n  This study addresses this gap with two main goals: (1) to develop a framework of well-defined, atomic properties that characterise the user experience of XAI in healthcare; and (2) to provide clear, context-sensitive guidelines for defining evaluation strategies based on system characteristics.\n  We conducted a systematic review of 82 user studies, sourced from five databases, all situated within healthcare settings and focused on evaluating AI-generated explanations. The analysis was guided by a predefined coding scheme informed by an existing evaluation framework, complemented by inductive codes developed iteratively.\n  The review yields three key contributions: (1) a synthesis of current evaluation practices, highlighting a growing focus on human-centred approaches in healthcare XAI; (2) insights into the interrelations among explanation properties; and (3) an updated framework and a set of actionable guidelines to support interdisciplinary teams in designing and implementing effective evaluation strategies for XAI systems tailored to specific application contexts.", "AI": {"tldr": "该研究填补了XAI在医疗领域用户评估的空白，提出了一个框架和指南，以支持针对特定应用场景的XAI系统评估设计。", "motivation": "当前XAI方法的实际价值在真实场景中未充分验证，缺乏明确的用户评估指南。", "method": "通过系统综述82项医疗领域用户研究，结合预定义编码方案和迭代开发的归纳代码进行分析。", "result": "总结了当前评估实践，揭示了医疗XAI中人本方法的增长趋势，并提出了更新的框架和实用指南。", "conclusion": "研究为跨学科团队提供了设计和实施针对性XAI评估的工具，强调了上下文敏感的重要性。"}}
{"id": "2506.13970", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.13970", "abs": "https://arxiv.org/abs/2506.13970", "authors": ["Charles C Onu"], "title": "Making deep neural networks work for medical audio: representation, compression and domain adaptation", "comment": "PhD Thesis", "summary": "This thesis addresses the technical challenges of applying machine learning to understand and interpret medical audio signals. The sounds of our lungs, heart, and voice convey vital information about our health. Yet, in contemporary medicine, these sounds are primarily analyzed through auditory interpretation by experts using devices like stethoscopes. Automated analysis offers the potential to standardize the processing of medical sounds, enable screening in low-resource settings where physicians are scarce, and detect subtle patterns that may elude human perception, thereby facilitating early diagnosis and treatment.\n  Focusing on the analysis of infant cry sounds to predict medical conditions, this thesis contributes on four key fronts. First, in low-data settings, we demonstrate that large databases of adult speech can be harnessed through neural transfer learning to develop more accurate and robust models for infant cry analysis. Second, in cost-effective modeling, we introduce an end-to-end model compression approach for recurrent networks using tensor decomposition. Our method requires no post-hoc processing, achieves compression rates of several hundred-fold, and delivers accurate, portable models suitable for resource-constrained devices. Third, we propose novel domain adaptation techniques tailored for audio models and adapt existing methods from computer vision. These approaches address dataset bias and enhance generalization across domains while maintaining strong performance on the original data. Finally, to advance research in this domain, we release a unique, open-source dataset of infant cry sounds, developed in collaboration with clinicians worldwide.\n  This work lays the foundation for recognizing the infant cry as a vital sign and highlights the transformative potential of AI-driven audio monitoring in shaping the future of accessible and affordable healthcare.", "AI": {"tldr": "该论文探讨了机器学习在医学音频信号分析中的应用，重点研究了婴儿哭声预测医疗状况的技术挑战，提出了四种创新方法。", "motivation": "医学音频信号（如肺部、心脏和声音）包含重要健康信息，但目前主要依赖专家听觉分析。自动化分析可标准化处理、支持低资源环境筛查，并发现人类难以察觉的细微模式，助力早期诊断。", "method": "1. 利用成人语音数据库通过神经迁移学习提升婴儿哭声分析模型；2. 提出基于张量分解的端到端循环网络压缩方法；3. 设计针对音频模型的域适应技术；4. 发布开源婴儿哭声数据集。", "result": "实现了高压缩率、高精度的便携模型，增强了跨领域泛化能力，并提供了研究资源。", "conclusion": "该研究为将婴儿哭声视为生命体征奠定了基础，展示了AI音频监测在可及医疗中的变革潜力。"}}
{"id": "2506.14187", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2506.14187", "abs": "https://arxiv.org/abs/2506.14187", "authors": ["Jiaming Yu", "Le Liang", "Hao Ye", "Shi Jin"], "title": "Hierarchical Multi-Agent Reinforcement Learning-based Coordinated Spatial Reuse for Next Generation WLANs", "comment": null, "summary": "High-density Wi-Fi deployments often result in significant co-channel interference, which degrades overall network performance. To address this issue, coordination of multi access points (APs) has been considered to enable coordinated spatial reuse (CSR) in next generation wireless local area networks. This paper tackles the challenge of downlink spatial reuse in Wi-Fi networks, specifically in scenarios involving overlapping basic service sets, by employing hierarchical multi-agent reinforcement learning (HMARL). We decompose the CSR process into two phases, i.e., a polling phase and a decision phase, and introduce the HMARL algorithm to enable efficient CSR. To enhance training efficiency, the proposed HMARL algorithm employs a hierarchical structure, where station selection and power control are determined by a high- and low-level policy network, respectively. Simulation results demonstrate that this approach consistently outperforms baseline methods in terms of throughput and latency across various network topologies. Moreover, the algorithm exhibits robust performance when coexisting with legacy APs. Additional experiments in a representative topology further reveal that the carefully designed reward function not only maximizes the overall network throughput, but also improves fairness in transmission opportunities for APs in high-interference regions.", "AI": {"tldr": "论文提出了一种基于分层多智能体强化学习（HMARL）的方法，用于解决Wi-Fi网络中下行链路空间复用的挑战，特别是在重叠基本服务集场景下。该方法通过分解协调空间复用（CSR）过程为轮询和决策两阶段，并引入HMARL算法实现高效CSR。", "motivation": "高密度Wi-Fi部署常导致严重的同频干扰，降低网络性能。传统方法难以有效协调多AP以实现空间复用，因此需要一种新方法。", "method": "采用分层多智能体强化学习（HMARL），将CSR过程分为轮询和决策两阶段，分别由高低级策略网络处理站点选择和功率控制。", "result": "仿真结果表明，该方法在吞吐量和延迟方面优于基线方法，且在与传统AP共存时表现稳健。优化的奖励函数不仅提升了网络吞吐量，还改善了高干扰区域AP的传输公平性。", "conclusion": "HMARL算法为高密度Wi-Fi网络中的空间复用问题提供了有效解决方案，显著提升了性能和公平性。"}}
{"id": "2506.14058", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14058", "abs": "https://arxiv.org/abs/2506.14058", "authors": ["Ali Baheri"], "title": "Implicit Constraint-Aware Off-Policy Correction for Offline Reinforcement Learning", "comment": null, "summary": "Offline reinforcement learning promises policy improvement from logged interaction data alone, yet state-of-the-art algorithms remain vulnerable to value over-estimation and to violations of domain knowledge such as monotonicity or smoothness. We introduce implicit constraint-aware off-policy correction, a framework that embeds structural priors directly inside every Bellman update. The key idea is to compose the optimal Bellman operator with a proximal projection on a convex constraint set, which produces a new operator that (i) remains a $γ$-contraction, (ii) possesses a unique fixed point, and (iii) enforces the prescribed structure exactly. A differentiable optimization layer solves the projection; implicit differentiation supplies gradients for deep function approximators at a cost comparable to implicit Q-learning. On a synthetic Bid-Click auction -- where the true value is provably monotone in the bid -- our method eliminates all monotonicity violations and outperforms conservative Q-learning and implicit Q-learning in return, regret, and sample efficiency.", "AI": {"tldr": "本文提出了一种隐式约束感知的离线策略校正框架，通过将结构先验嵌入贝尔曼更新中，解决了值高估和领域知识违反问题。", "motivation": "离线强化学习虽然可以从记录的数据中改进策略，但现有算法容易高估值并违反领域知识（如单调性或平滑性）。", "method": "通过将最优贝尔曼算子与凸约束集上的近端投影结合，生成一个新算子，确保γ-收缩、唯一固定点并严格强制执行结构。使用可微分优化层解决投影问题。", "result": "在合成竞价点击拍卖任务中，该方法完全消除了单调性违反，并在回报、后悔和样本效率上优于保守Q学习和隐式Q学习。", "conclusion": "隐式约束感知的离线策略校正框架有效解决了值高估和结构违反问题，提升了离线强化学习的性能。"}}
{"id": "2506.13780", "categories": ["cs.CV", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13780", "abs": "https://arxiv.org/abs/2506.13780", "authors": ["Sedat Porikli", "Vedat Porikli"], "title": "Hidden Bias in the Machine: Stereotypes in Text-to-Image Models", "comment": "Equal contribution by both authors, Published at CVPR 2025 Workshop on Experimental Model Auditing via Controllable Synthesis (EMACS) and Workshop on Demographic Diversity in Computer Vision (DemoDiv)", "summary": "Text-to-Image (T2I) models have transformed visual content creation, producing highly realistic images from natural language prompts. However, concerns persist around their potential to replicate and magnify existing societal biases. To investigate these issues, we curated a diverse set of prompts spanning thematic categories such as occupations, traits, actions, ideologies, emotions, family roles, place descriptions, spirituality, and life events. For each of the 160 unique topics, we crafted multiple prompt variations to reflect a wide range of meanings and perspectives. Using Stable Diffusion 1.5 (UNet-based) and Flux-1 (DiT-based) models with original checkpoints, we generated over 16,000 images under consistent settings. Additionally, we collected 8,000 comparison images from Google Image Search. All outputs were filtered to exclude abstract, distorted, or nonsensical results. Our analysis reveals significant disparities in the representation of gender, race, age, somatotype, and other human-centric factors across generated images. These disparities often mirror and reinforce harmful stereotypes embedded in societal narratives. We discuss the implications of these findings and emphasize the need for more inclusive datasets and development practices to foster fairness in generative visual systems.", "AI": {"tldr": "研究探讨了文本到图像（T2I）模型如何复制和放大社会偏见，通过生成多样化的提示和图像分析揭示了性别、种族等方面的显著差异。", "motivation": "调查T2I模型是否反映和强化社会偏见，以促进更公平的生成视觉系统。", "method": "使用Stable Diffusion 1.5和Flux-1模型生成16,000多张图像，并与Google Image Search的8,000张图像对比，分析人类中心因素的差异。", "result": "发现生成的图像在性别、种族等方面存在显著差异，往往强化了社会中的有害刻板印象。", "conclusion": "强调需要更包容的数据集和开发实践，以减少生成视觉系统中的偏见。"}}
{"id": "2506.13781", "categories": ["cs.LG", "cs.AI", "cs.DM"], "pdf": "https://arxiv.org/pdf/2506.13781", "abs": "https://arxiv.org/abs/2506.13781", "authors": ["Pablo Ariño Fernández"], "title": "Solving the Job Shop Scheduling Problem with Graph Neural Networks: A Customizable Reinforcement Learning Environment", "comment": "Bachelor's thesis, Universidad Politécnica de Madrid, 2025. 150 pages, 23 figures", "summary": "The job shop scheduling problem is an NP-hard combinatorial optimization problem relevant to manufacturing and timetabling. Traditional approaches use priority dispatching rules based on simple heuristics. Recent work has attempted to replace these with deep learning models, particularly graph neural networks (GNNs), that learn to assign priorities from data. However, training such models requires customizing numerous factors: graph representation, node features, action space, and reward functions. The lack of modular libraries for experimentation makes this research time-consuming. This work introduces JobShopLib, a modular library that allows customizing these factors and creating new components with its reinforcement learning environment. We trained several dispatchers through imitation learning to demonstrate the environment's utility. One model outperformed various graph-based dispatchers using only individual operation features, highlighting the importance of feature customization. Our GNN model achieved near state-of-the-art results on large-scale problems. These results suggest significant room for improvement in developing such models. JobShopLib provides the necessary tools for future experimentation.", "AI": {"tldr": "JobShopLib是一个模块化库，用于定制化解决作业车间调度问题，支持图神经网络（GNNs）的实验，并通过模仿学习训练调度器，展示了其潜力。", "motivation": "传统调度方法基于简单启发式规则，而深度学习模型（如GNNs）需要大量定制化因素，缺乏模块化实验库。", "method": "开发JobShopLib库，支持自定义图表示、节点特征、动作空间和奖励函数，并通过模仿学习训练调度器。", "result": "一个仅使用操作特征的模型优于多种基于图的调度器，GNN模型在大规模问题上接近最先进水平。", "conclusion": "JobShopLib为未来研究提供了工具，表明此类模型仍有显著改进空间。"}}
{"id": "2506.13922", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13922", "abs": "https://arxiv.org/abs/2506.13922", "authors": ["Maximilian Du", "Shuran Song"], "title": "DynaGuide: Steering Diffusion Polices with Active Dynamic Guidance", "comment": "9 pages main, 21 pages with appendix and citations. 9 figures. Submitted to Neurips 2025", "summary": "Deploying large, complex policies in the real world requires the ability to steer them to fit the needs of a situation. Most common steering approaches, like goal-conditioning, require training the robot policy with a distribution of test-time objectives in mind. To overcome this limitation, we present DynaGuide, a steering method for diffusion policies using guidance from an external dynamics model during the diffusion denoising process. DynaGuide separates the dynamics model from the base policy, which gives it multiple advantages, including the ability to steer towards multiple objectives, enhance underrepresented base policy behaviors, and maintain robustness on low-quality objectives. The separate guidance signal also allows DynaGuide to work with off-the-shelf pretrained diffusion policies. We demonstrate the performance and features of DynaGuide against other steering approaches in a series of simulated and real experiments, showing an average steering success of 70% on a set of articulated CALVIN tasks and outperforming goal-conditioning by 5.4x when steered with low-quality objectives. We also successfully steer an off-the-shelf real robot policy to express preference for particular objects and even create novel behavior. Videos and more can be found on the project website: https://dynaguide.github.io", "AI": {"tldr": "DynaGuide是一种用于扩散策略的引导方法，通过外部动力学模型在扩散去噪过程中提供指导，实现了对复杂策略的灵活调整。", "motivation": "现有方法（如目标条件化）需要预先训练策略以适应测试目标分布，限制了灵活性。DynaGuide旨在克服这一限制。", "method": "DynaGuide将动力学模型与基础策略分离，利用外部动力学模型在扩散去噪过程中提供引导信号。", "result": "在模拟和真实实验中，DynaGuide平均引导成功率为70%，在低质量目标下表现优于目标条件化方法5.4倍。", "conclusion": "DynaGuide能够灵活引导策略，支持多目标调整，并适用于预训练扩散策略，展示了实际应用的潜力。"}}
{"id": "2506.14518", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2506.14518", "abs": "https://arxiv.org/abs/2506.14518", "authors": ["Elif Yılmaz", "Christos Dimitrakakis"], "title": "Two-Player Zero-Sum Games with Bandit Feedback", "comment": null, "summary": "We study a two-player zero-sum game (TPZSG) in which the row player aims to maximize their payoff against an adversarial column player, under an unknown payoff matrix estimated through bandit feedback. We propose and analyze two algorithms: ETC-TPZSG, which directly applies ETC to the TPZSG setting and ETC-TPZSG-AE, which improves upon it by incorporating an action pair elimination (AE) strategy that leverages the $\\varepsilon$-Nash Equilibrium property to efficiently select the optimal action pair. Our objective is to demonstrate the applicability of ETC in a TPZSG setting by focusing on learning pure strategy Nash Equilibrium. A key contribution of our work is a derivation of instance-dependent upper bounds on the expected regret for both algorithms, has received limited attention in the literature on zero-sum games. Particularly, after $T$ rounds, we achieve an instance-dependent regret upper bounds of $O(Δ+ \\sqrt{T})$ for ETC-TPZSG and $O(\\frac{\\log (T Δ^2)}Δ)$ for ETC-TPZSG-AE, where $Δ$ denotes the suboptimality gap. Therefore, our results indicate that ETC-based algorithms perform effectively in adversarial game settings, achieving regret bounds comparable to existing methods while providing insights through instance-dependent analysis.", "AI": {"tldr": "论文研究了在未知支付矩阵下通过bandit反馈估计的双人零和游戏，提出了两种算法ETC-TPZSG和ETC-TPZSG-AE，并分析了其性能。", "motivation": "探索ETC（探索-利用-提交）算法在双人零和游戏中的适用性，特别是学习纯策略纳什均衡。", "method": "提出ETC-TPZSG算法，并改进为ETC-TPZSG-AE，利用ε-纳什均衡性质进行动作对消除。", "result": "推导了两种算法的实例依赖后悔上界，ETC-TPZSG为O(Δ+√T)，ETC-TPZSG-AE为O(log(TΔ²)/Δ)。", "conclusion": "ETC算法在对抗性游戏环境中表现良好，后悔界与现有方法相当，并通过实例依赖分析提供了新见解。"}}
{"id": "2506.14104", "categories": ["cs.GR", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.14104", "abs": "https://arxiv.org/abs/2506.14104", "authors": ["RuiKun Yang", "ZhongLiang Wei", "Longdi Xian"], "title": "Innovating China's Intangible Cultural Heritage with DeepSeek + MidJourney: The Case of Yangliuqing theme Woodblock Prints", "comment": null, "summary": "Yangliuqing woodblock prints, a cornerstone of China's intangible cultural heritage, are celebrated for their intricate designs and vibrant colors. However, preserving these traditional art forms while fostering innovation presents significant challenges. This study explores the DeepSeek + MidJourney approach to generating creative, themed Yangliuqing woodblock prints focused on the fight against COVID-19 and depicting joyous winners. Using Fréchet Inception Distance (FID) scores for evaluation, the method that combined DeepSeek-generated thematic prompts, MidJourney-generated thematic images, original Yangliuqing prints, and DeepSeek-generated key prompts in MidJourney-generated outputs achieved the lowest mean FID score (150.2) with minimal variability (σ = 4.9). Additionally, feedback from 62 participants, collected via questionnaires, confirmed that this hybrid approach produced the most representative results. Moreover, the questionnaire data revealed that participants demonstrated the highest willingness to promote traditional culture and the strongest interest in consuming the AI-generated images produced through this method. These findings underscore the effectiveness of an innovative approach that seamlessly blends traditional artistic elements with modern AI-driven creativity, ensuring both cultural preservation and contemporary relevance.", "AI": {"tldr": "研究探讨了结合DeepSeek和MidJourney的方法生成杨柳青木版年画，主题为抗疫和欢乐胜利者，通过FID评分和问卷调查验证其效果。", "motivation": "解决传统杨柳青木版年画的保护与创新问题，探索AI与传统艺术的结合。", "method": "采用DeepSeek生成主题提示，MidJourney生成图像，结合原始年画和关键提示，通过FID评分和问卷调查评估效果。", "result": "混合方法获得最低FID分数（150.2）且变异小（σ=4.9），问卷调查显示参与者认可其代表性，并表现出推广传统文化和消费AI生成图像的意愿。", "conclusion": "结合AI与传统艺术的方法有效，既能保护文化又能满足现代需求。"}}
{"id": "2506.14018", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14018", "abs": "https://arxiv.org/abs/2506.14018", "authors": ["Lan Gao", "Oscar Chen", "Rachel Lee", "Nick Feamster", "Chenhao Tan", "Marshini Chetty"], "title": "\"I Cannot Write This Because It Violates Our Content Policy\": Understanding Content Moderation Policies and User Experiences in Generative AI Products", "comment": "Preprint for USENIX Security 2025", "summary": "While recent research has focused on developing safeguards for generative AI (GAI) model-level content safety, little is known about how content moderation to prevent malicious content performs for end-users in real-world GAI products. To bridge this gap, we investigated content moderation policies and their enforcement in GAI online tools -- consumer-facing web-based GAI applications. We first analyzed content moderation policies of 14 GAI online tools. While these policies are comprehensive in outlining moderation practices, they usually lack details on practical implementations and are not specific about how users can aid in moderation or appeal moderation decisions. Next, we examined user-experienced content moderation successes and failures through Reddit discussions on GAI online tools. We found that although moderation systems succeeded in blocking malicious generations pervasively, users frequently experienced frustration in failures of both moderation systems and user support after moderation. Based on these findings, we suggest improvements for content moderation policy and user experiences in real-world GAI products.", "AI": {"tldr": "研究探讨了生成式AI在线工具的内容审核政策及其实施效果，发现政策虽全面但缺乏实操细节，用户常因审核失败和支持不足感到沮丧。", "motivation": "填补生成式AI产品中内容审核对终端用户实际效果的研究空白。", "method": "分析14个GAI在线工具的审核政策，并通过Reddit讨论评估用户实际体验。", "result": "审核系统能有效阻止恶意内容，但用户常因审核失败和支持不足感到不满。", "conclusion": "建议改进GAI产品的审核政策和用户体验。"}}
{"id": "2506.14148", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.14148", "abs": "https://arxiv.org/abs/2506.14148", "authors": ["Long-Vu Hoang", "Tuan Nguyen", "Tran Huy Dat"], "title": "Acoustic scattering AI for non-invasive object classifications: A case study on hair assessment", "comment": "Accepted to Interspeech 2025", "summary": "This paper presents a novel non-invasive object classification approach using acoustic scattering, demonstrated through a case study on hair assessment. When an incident wave interacts with an object, it generates a scattered acoustic field encoding structural and material properties. By emitting acoustic stimuli and capturing the scattered signals from head-with-hair-sample objects, we classify hair type and moisture using AI-driven, deep-learning-based sound classification. We benchmark comprehensive methods, including (i) fully supervised deep learning, (ii) embedding-based classification, (iii) supervised foundation model fine-tuning, and (iv) self-supervised model fine-tuning. Our best strategy achieves nearly 90% classification accuracy by fine-tuning all parameters of a self-supervised model. These results highlight acoustic scattering as a privacy-preserving, non-contact alternative to visual classification, opening huge potential for applications in various industries.", "AI": {"tldr": "提出了一种基于声散射的非侵入式物体分类方法，并通过头发评估案例验证其有效性，利用AI驱动的深度学习实现高精度分类。", "motivation": "探索一种隐私保护、非接触式的替代视觉分类的方法，利用声散射技术捕捉物体结构和材料特性。", "method": "通过发射声波并捕捉散射信号，结合四种深度学习策略（全监督、嵌入分类、监督基础模型微调、自监督模型微调）进行分类。", "result": "最佳策略（自监督模型微调）实现了近90%的分类准确率。", "conclusion": "声散射技术在非接触式分类中具有广泛应用潜力，特别是在需要隐私保护的场景。"}}
{"id": "2506.14159", "categories": ["cs.HC", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.14159", "abs": "https://arxiv.org/abs/2506.14159", "authors": ["Shayan Talaei", "Meijin Li", "Kanu Grover", "James Kent Hippler", "Diyi Yang", "Amin Saberi"], "title": "StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework", "comment": null, "summary": "Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative, a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N=28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships.", "AI": {"tldr": "StorySage是一个多代理系统，支持灵活对话和结构化自传写作，通过迭代收集用户记忆并更新自传，实验显示其优于基线。", "motivation": "个人记忆分散且难以组织成连贯叙述，现有写作助手难以捕捉个人记忆并完成完整传记。", "method": "采用多代理框架（包括采访者、记录员、规划师、章节作者和会话协调员），迭代收集记忆并更新自传。", "result": "实验模拟和用户研究（N=28）显示，StorySage在会话流畅性、叙述完整性和用户满意度上优于基线。", "conclusion": "StorySage为自传写作提供了新架构，并展示了多代理系统如何增强人机创意合作。"}}
{"id": "2506.14059", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14059", "abs": "https://arxiv.org/abs/2506.14059", "authors": ["Shakib Mustavee", "Shaurya Agarwal", "Arvind Singh"], "title": "A Stochastic Differential Equation Framework for Modeling Queue Length Dynamics Inspired by Self-Similarity", "comment": null, "summary": "This article develops a stochastic differential equation (SDE) for modeling the temporal evolution of queue length dynamics at signalized intersections. Inspired by the observed quasiperiodic and self-similar characteristics of the queue length dynamics, the proposed model incorporates three properties into the SDE: (i) mean reversion with periodic mean, (ii) multiplicative noise, and (iii) fractional Brownian motion. It replicates key statistical features observed in real data, including the probability distribution function (PDF) and PSD of queue lengths. To our knowledge, this is the first equation-based model for queue dynamics. The proposed approach offers a transparent, data-consistent framework that may help inform and enhance the design of black-box learning algorithms with underlying traffic physics.", "AI": {"tldr": "本文提出了一种基于随机微分方程（SDE）的信号交叉口排队长度动态建模方法，结合周期性均值回归、乘性噪声和分数布朗运动，首次实现了排队动态的方程建模。", "motivation": "受排队长度动态的准周期性和自相似性启发，旨在建立一个透明且与数据一致的模型框架，以支持黑箱学习算法的设计。", "method": "开发了一种SDE模型，包含周期性均值回归、乘性噪声和分数布朗运动三个特性，以模拟排队动态的关键统计特征。", "result": "模型成功复现了实际数据中的概率分布函数（PDF）和功率谱密度（PSD）等统计特征。", "conclusion": "该模型为排队动态提供了首个基于方程的建模方法，为交通物理驱动的黑箱算法设计提供了透明框架。"}}
{"id": "2506.13846", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13846", "abs": "https://arxiv.org/abs/2506.13846", "authors": ["Runtao Liu", "Jiahao Zhan", "Yingqing He", "Chen Wei", "Alan Yuille", "Qifeng Chen"], "title": "Fake it till You Make it: Reward Modeling as Discriminative Prediction", "comment": null, "summary": "An effective reward model plays a pivotal role in reinforcement learning for post-training enhancement of visual generative models. However, current approaches of reward modeling suffer from implementation complexity due to their reliance on extensive human-annotated preference data or meticulously engineered quality dimensions that are often incomplete and engineering-intensive. Inspired by adversarial training in generative adversarial networks (GANs), this paper proposes GAN-RM, an efficient reward modeling framework that eliminates manual preference annotation and explicit quality dimension engineering. Our method trains the reward model through discrimination between a small set of representative, unpaired target samples(denoted as Preference Proxy Data) and model-generated ordinary outputs, requiring only a few hundred target samples. Comprehensive experiments demonstrate our GAN-RM's effectiveness across multiple key applications including test-time scaling implemented as Best-of-N sample filtering, post-training approaches like Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO).", "AI": {"tldr": "本文提出了一种名为GAN-RM的高效奖励建模框架，通过对抗训练方式减少对人工标注和显式质量维度设计的依赖。", "motivation": "当前奖励建模方法依赖大量人工标注或复杂质量维度设计，实现复杂且不完整。", "method": "利用对抗训练思想，通过少量目标样本（偏好代理数据）与模型生成输出的判别来训练奖励模型。", "result": "实验证明GAN-RM在多种应用中有效，包括测试时扩展和训练后优化方法。", "conclusion": "GAN-RM提供了一种高效且无需人工标注的奖励建模解决方案。"}}
{"id": "2506.13786", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13786", "abs": "https://arxiv.org/abs/2506.13786", "authors": ["Vuong M. Ngo", "Tran Quang Vinh", "Patricia Kearney", "Mark Roantree"], "title": "Enhancing Bagging Ensemble Regression with Data Integration for Time Series-Based Diabetes Prediction", "comment": "17th International Conference on Computational Collective Intelligence, LNAI, Springer, 11 pages", "summary": "Diabetes is a chronic metabolic disease characterized by elevated blood glucose levels, leading to complications like heart disease, kidney failure, and nerve damage. Accurate state-level predictions are vital for effective healthcare planning and targeted interventions, but in many cases, data for necessary analyses are incomplete. This study begins with a data engineering process to integrate diabetes-related datasets from 2011 to 2021 to create a comprehensive feature set. We then introduce an enhanced bagging ensemble regression model (EBMBag+) for time series forecasting to predict diabetes prevalence across U.S. cities. Several baseline models, including SVMReg, BDTree, LSBoost, NN, LSTM, and ERMBag, were evaluated for comparison with our EBMBag+ algorithm. The experimental results demonstrate that EBMBag+ achieved the best performance, with an MAE of 0.41, RMSE of 0.53, MAPE of 4.01, and an R2 of 0.9.", "AI": {"tldr": "该研究通过数据整合和增强的集成回归模型（EBMBag+）预测美国城市糖尿病患病率，结果显示EBMBag+在多个指标上表现最佳。", "motivation": "糖尿病是一种慢性代谢疾病，准确预测其患病率对医疗规划和干预至关重要，但现有数据往往不完整。", "method": "整合2011-2021年糖尿病相关数据集，提出EBMBag+模型，并与多种基线模型（如SVMReg、LSTM等）进行比较。", "result": "EBMBag+表现最优，MAE为0.41，RMSE为0.53，MAPE为4.01，R2为0.9。", "conclusion": "EBMBag+在糖尿病患病率预测中具有显著优势，可用于实际医疗规划。"}}
{"id": "2506.13933", "categories": ["cs.RO", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.13933", "abs": "https://arxiv.org/abs/2506.13933", "authors": ["Tobias Kerbl", "David Brecht", "Nils Gehrke", "Nijinshan Karunainayagam", "Niklas Krauss", "Florian Pfab", "Richard Taupitz", "Ines Trautmannsheimer", "Xiyan Su", "Maria-Magdalena Wolf", "Frank Diermeyer"], "title": "TUM Teleoperation: Open Source Software for Remote Driving and Assistance of Automated Vehicles", "comment": null, "summary": "Teleoperation is a key enabler for future mobility, supporting Automated Vehicles in rare and complex scenarios beyond the capabilities of their automation. Despite ongoing research, no open source software currently combines Remote Driving, e.g., via steering wheel and pedals, Remote Assistance through high-level interaction with automated driving software modules, and integration with a real-world vehicle for practical testing. To address this gap, we present a modular, open source teleoperation software stack that can interact with an automated driving software, e.g., Autoware, enabling Remote Assistance and Remote Driving. The software featuresstandardized interfaces for seamless integration with various real-world and simulation platforms, while allowing for flexible design of the human-machine interface. The system is designed for modularity and ease of extension, serving as a foundation for collaborative development on individual software components as well as realistic testing and user studies. To demonstrate the applicability of our software, we evaluated the latency and performance of different vehicle platforms in simulation and real-world. The source code is available on GitHub", "AI": {"tldr": "本文提出了一种模块化、开源的远程操作软件栈，支持远程驾驶和远程辅助功能，填补了现有开源软件的空白。", "motivation": "当前缺乏结合远程驾驶和远程辅助功能并与实际车辆集成的开源软件，阻碍了自动驾驶在复杂场景中的应用。", "method": "开发了一个模块化的开源软件栈，支持与自动驾驶软件（如Autoware）交互，提供标准化接口和灵活的人机界面设计。", "result": "软件在仿真和实际车辆平台上测试了延迟和性能，证明了其适用性。", "conclusion": "该软件为协作开发和实际测试提供了基础，填补了开源远程操作软件的空白。"}}
{"id": "2506.14315", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14315", "abs": "https://arxiv.org/abs/2506.14315", "authors": ["Jinyan Yuan", "Bangbang Yang", "Keke Wang", "Panwang Pan", "Lin Ma", "Xuehai Zhang", "Xiao Liu", "Zhaopeng Cui", "Yuewen Ma"], "title": "ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies", "comment": "Project webpage: https://immersegen.github.io", "summary": "Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery.This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based modeling agents enhanced with semantic grid-based analysis for improved spatial reasoning and accurate asset placement. ImmerseGen further enriches scenes with dynamic effects and ambient audio to support multisensory immersion. Experiments on scene generation and live VR showcases demonstrate that ImmerseGen achieves superior photorealism, spatial coherence and rendering efficiency compared to prior methods. Project webpage: https://immersegen.github.io.", "AI": {"tldr": "ImmerseGen提出了一种基于代理引导的紧凑且逼真的3D场景建模框架，通过轻量级几何代理和纹理合成实现高效沉浸式VR体验。", "motivation": "现有方法依赖高多边形建模或大规模3D高斯模型，导致流程复杂或视觉逼真度不足，ImmerseGen旨在简化建模并提升逼真度。", "method": "采用分层轻量级几何代理（如地形和广告牌网格），通过地形条件纹理和RGBA资产纹理合成逼真外观，并利用VLM代理进行自动化场景生成。", "result": "实验表明，ImmerseGen在逼真度、空间一致性和渲染效率上优于现有方法，适合移动VR设备实时渲染。", "conclusion": "ImmerseGen证明了无需复杂建模即可实现高质量沉浸式体验，为VR场景生成提供了高效解决方案。"}}
{"id": "2506.14056", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14056", "abs": "https://arxiv.org/abs/2506.14056", "authors": ["Fan Lei", "David A. Sampson", "Jiayi Hong", "Yuxin Ma", "Giuseppe Mascaro", "Dave White", "Rimjhim Agarwal", "Ross Maciejewski"], "title": "FEWSim: A Visual Analytic Framework for Exploring the Nexus of Food-Energy-Water Simulations", "comment": "Accepted by IEEE Computer Graphics and Applications (CG&A)", "summary": "The interdependencies of food, energy, and water (FEW) systems create a nexus opportunity to explore the strengths and vulnerabilities of individual and cross-sector interactions within FEW systems. However, the variables quantifying nexus interactions are hard to observe, which hinders the cross-sector analysis. To overcome such challenges, we present FEWSim, a visual analytics framework designed to support domain experts in exploring and interpreting simulation results from a coupled FEW model. FEWSim employs a three-layer asynchronous architecture: the model layer integrates food, energy, and water models to simulate the FEW nexus; the middleware layer manages scenario configuration and execution; and the visualization layer provides interactive visual exploration of simulated time-series results across FEW sectors. The visualization layer further facilitates the exploration across multiple scenarios and evaluates scenario differences in performance using sustainability indices of the FEW nexus. We demonstrate the utility of FEWSim through a case study for the Phoenix Active Management Area (AMA) in Arizona.", "AI": {"tldr": "FEWSim是一个可视化分析框架，用于探索和解释食物、能源和水（FEW）系统的耦合模型模拟结果。", "motivation": "FEW系统的相互依赖性为跨部门分析提供了机会，但量化这些交互的变量难以观察，阻碍了分析。", "method": "FEWSim采用三层异步架构：模型层集成FEW模型，中间件层管理场景配置和执行，可视化层提供交互式时间序列结果探索。", "result": "通过案例研究（亚利桑那州凤凰城AMA）展示了FEWSim的实用性。", "conclusion": "FEWSim支持跨部门分析和多场景比较，有助于评估FEW系统的可持续性。"}}
{"id": "2506.14153", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.14153", "abs": "https://arxiv.org/abs/2506.14153", "authors": ["Tuan Dat Phuong", "Long-Vu Hoang", "Huy Dat Tran"], "title": "Pushing the Performance of Synthetic Speech Detection with Kolmogorov-Arnold Networks and Self-Supervised Learning Models", "comment": "Accepted to Interspeech 2025", "summary": "Recent advancements in speech synthesis technologies have led to increasingly advanced spoofing attacks, posing significant challenges for automatic speaker verification systems. While systems based on self-supervised learning (SSL) models, particularly the XLSR-Conformer model, have demonstrated remarkable performance in synthetic speech detection, there remains room for architectural improvements. In this paper, we propose a novel approach that replaces the traditional Multi-Layer Perceptron in the XLSR-Conformer model with a Kolmogorov-Arnold Network (KAN), a novel architecture based on the Kolmogorov-Arnold representation theorem. Our results on ASVspoof2021 demonstrate that integrating KAN into the SSL-based models can improve the performance by 60.55% relatively on LA and DF sets, further achieving 0.70% EER on the 21LA set. These findings suggest that incorporating KAN into SSL-based models is a promising direction for advances in synthetic speech detection.", "AI": {"tldr": "论文提出用Kolmogorov-Arnold Network（KAN）替代XLSR-Conformer模型中的传统多层感知机，显著提升了合成语音检测性能。", "motivation": "随着语音合成技术的进步，伪造攻击对自动说话人验证系统构成挑战，现有基于自监督学习的模型仍有改进空间。", "method": "用KAN替换XLSR-Conformer模型中的多层感知机，基于Kolmogorov-Arnold表示定理。", "result": "在ASVspoof2021上，KAN集成使性能相对提升60.55%，在21LA集上EER达0.70%。", "conclusion": "KAN在自监督学习模型中的应用是合成语音检测领域的潜在突破方向。"}}
{"id": "2506.14164", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.14164", "abs": "https://arxiv.org/abs/2506.14164", "authors": ["Hanzhong Cao"], "title": "Light Aircraft Game : Basic Implementation and training results analysis", "comment": null, "summary": "This paper investigates multi-agent reinforcement learning (MARL) in a partially observable, cooperative-competitive combat environment known as LAG. We describe the environment's setup, including agent actions, hierarchical controls, and reward design across different combat modes such as No Weapon and ShootMissile. Two representative algorithms are evaluated: HAPPO, an on-policy hierarchical variant of PPO, and HASAC, an off-policy method based on soft actor-critic. We analyze their training stability, reward progression, and inter-agent coordination capabilities. Experimental results show that HASAC performs well in simpler coordination tasks without weapons, while HAPPO demonstrates stronger adaptability in more dynamic and expressive scenarios involving missile combat. These findings provide insights into the trade-offs between on-policy and off-policy methods in multi-agent settings.", "AI": {"tldr": "论文研究了多智能体强化学习（MARL）在部分可观测、合作-竞争战斗环境LAG中的应用，比较了HAPPO和HASAC两种算法的性能。", "motivation": "探索在复杂战斗环境中，不同MARL算法的表现及适用性。", "method": "使用HAPPO（基于PPO的分层方法）和HASAC（基于SAC的离线方法）在LAG环境中进行实验。", "result": "HASAC在无武器简单任务中表现良好，HAPPO在动态导弹战斗中更具适应性。", "conclusion": "研究揭示了在线与离线方法在多智能体环境中的权衡。"}}
{"id": "2506.14083", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14083", "abs": "https://arxiv.org/abs/2506.14083", "authors": ["Zhicheng Zhang", "Yoshihiko Susuki", "Atsushi Okazaki"], "title": "Extracting transient Koopman modes from short-term weather simulations with sparsity-promoting dynamic mode decomposition", "comment": "38 pages, 21 figures,", "summary": "Convective features-here represented as warm bubble-like patterns-reveal essential, high-level information about how short-term weather dynamics evolve within a high-dimensional state space. We introduce a data-driven framework that uncovers transient dynamics captured by Koopman modes responsible for these structures and traces their emergence, growth, and decay. Our approach incorporates the sparsity-promoting dynamic mode decomposition into the framework of Koopman mode decomposition, yielding a few number of selected modes whose sparse amplitudes highlight dominant transient structures. By tuning the sparsity weight, we balance reconstruction accuracy and model complexity. We illustrate the methodology on weather simulations, using the magnitude of velocity and vorticity fields as distinct observable datasets. The resulting sparse dominant Koopman modes capture the transient evolution of bubble-like pattern and can reduce the dimensionality of the weather system model, offering an efficient surrogate for diagnostic and forecasting tasks.", "AI": {"tldr": "该论文提出了一种数据驱动框架，通过稀疏动态模式分解结合Koopman模式分解，捕捉天气模拟中的瞬态动态，并提取主导的稀疏Koopman模式，用于降维和预测任务。", "motivation": "研究瞬态天气动态（如暖泡状模式）的演化过程，以提取高维状态空间中的关键信息，为天气诊断和预测提供高效工具。", "method": "结合稀疏动态模式分解与Koopman模式分解，通过调节稀疏权重平衡重构精度与模型复杂度，应用于天气模拟数据。", "result": "提取的稀疏主导Koopman模式能有效捕捉暖泡状模式的瞬态演化，并降低天气系统模型的维度。", "conclusion": "该方法为天气动态分析提供了一种高效的数据驱动框架，适用于诊断和预测任务。"}}
{"id": "2506.13897", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.13897", "abs": "https://arxiv.org/abs/2506.13897", "authors": ["Thomas Kreutz", "Max Mühlhäuser", "Alejandro Sanchez Guinea"], "title": "DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding", "comment": "This work is currently under review at ICCV 2025", "summary": "Despite LiDAR (Light Detection and Ranging) being an effective privacy-preserving alternative to RGB cameras to perceive human activities, it remains largely underexplored in the context of multi-modal contrastive pre-training for human activity understanding (e.g., human activity recognition (HAR), retrieval, or person re-identification (RE-ID)). To close this gap, our work explores learning the correspondence between LiDAR point clouds, human skeleton poses, IMU data, and text in a joint embedding space. More specifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embedding model, which effectively learns a joint embedding space across these four modalities through noise contrastive estimation. At the heart of our empirical exploration, we have combined the existing LIPD and Babel datasets, which enabled us to synchronize data of all four modalities, allowing us to explore the learning of a new joint embedding space. Our experiments demonstrate novel human activity understanding tasks for point cloud sequences enabled through DeSPITE, including Skeleton<->Pointcloud<->IMU matching, retrieval, and temporal moment retrieval. Furthermore, we show that DeSPITE is an effective pre-training strategy for point cloud HAR through experiments in MSR-Action3D and HMPEAR.", "AI": {"tldr": "论文提出了DeSPITE模型，通过多模态对比预训练（LiDAR点云、人体骨骼姿态、IMU数据和文本）学习联合嵌入空间，填补了LiDAR在人类活动理解中的研究空白。", "motivation": "LiDAR作为一种隐私保护的感知方式，在多模态对比预训练中尚未充分探索，尤其是在人类活动理解（如识别、检索或重识别）方面。", "method": "提出DeSPITE模型，通过噪声对比估计学习四种模态的联合嵌入空间，结合LIPD和Babel数据集实现数据同步。", "result": "实验表明DeSPITE支持新的人类活动理解任务（如模态匹配、检索和时间片段检索），并作为点云HAR的有效预训练策略。", "conclusion": "DeSPITE填补了LiDAR在多模态学习中的空白，为人类活动理解提供了新的解决方案。"}}
{"id": "2506.13828", "categories": ["cs.LG", "eess.SY", "physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2506.13828", "abs": "https://arxiv.org/abs/2506.13828", "authors": ["Abdullah Burkan Bereketoglu"], "title": "Hybrid Meta-Learning Framework for Anomaly Forecasting in Nonlinear Dynamical Systems via Physics-Inspired Simulation and Deep Ensembles", "comment": "6 pages, 5 figures, 5 algorithms", "summary": "We propose a hybrid meta-learning framework for forecasting and anomaly detection in nonlinear dynamical systems characterized by nonstationary and stochastic behavior. The approach integrates a physics-inspired simulator that captures nonlinear growth-relaxation dynamics with random perturbations, representative of many complex physical, industrial, and cyber-physical systems. We use CNN-LSTM architectures for spatio-temporal feature extraction, Variational Autoencoders (VAE) for unsupervised anomaly scoring, and Isolation Forests for residual-based outlier detection in addition to a Dual-Stage Attention Recurrent Neural Network (DA-RNN) for one-step forecasting on top of the generated simulation data. To create composite anomaly forecasts, these models are combined using a meta-learner that combines forecasting outputs, reconstruction errors, and residual scores. The hybrid ensemble performs better than standalone models in anomaly localization, generalization, and robustness to nonlinear deviations, according to simulation-based experiments. The framework provides a broad, data-driven approach to early defect identification and predictive monitoring in nonlinear systems, which may be applied to a variety of scenarios where complete physical models might not be accessible.", "AI": {"tldr": "提出了一种混合元学习框架，用于非线性动态系统的预测和异常检测，结合物理模拟器和深度学习模型，表现优于独立模型。", "motivation": "解决非线性动态系统中非平稳和随机行为的预测与异常检测问题，适用于复杂物理、工业和信息物理系统。", "method": "整合物理模拟器、CNN-LSTM时空特征提取、VAE无监督异常评分、Isolation Forests残差异常检测及DA-RNN一步预测，通过元学习器组合输出。", "result": "混合模型在异常定位、泛化能力和非线性偏差鲁棒性上优于独立模型。", "conclusion": "该框架为非线性系统提供了一种通用的数据驱动方法，适用于物理模型不完整的情景。"}}
{"id": "2506.13937", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13937", "abs": "https://arxiv.org/abs/2506.13937", "authors": ["Caio C. G. Ribeiro", "Douglas G. Macharet"], "title": "Beyond the Plane: A 3D Representation of Human Personal Space for Socially-Aware Robotics", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and Human Interactive Communication (ROMAN)", "summary": "The increasing presence of robots in human environments requires them to exhibit socially appropriate behavior, adhering to social norms. A critical aspect in this context is the concept of personal space, a psychological boundary around an individual that influences their comfort based on proximity. This concept extends to human-robot interaction, where robots must respect personal space to avoid causing discomfort. While much research has focused on modeling personal space in two dimensions, almost none have considered the vertical dimension. In this work, we propose a novel three-dimensional personal space model that integrates both height (introducing a discomfort function along the Z-axis) and horizontal proximity (via a classic XY-plane formulation) to quantify discomfort. To the best of our knowledge, this is the first work to compute discomfort in 3D space at any robot component's position, considering the person's configuration and height.", "AI": {"tldr": "本文提出了一种新颖的三维个人空间模型，结合高度和水平接近度来量化不适感，填补了现有研究在垂直维度上的空白。", "motivation": "随着机器人在人类环境中的普及，需要其行为符合社会规范，尤其是尊重个人空间以避免不适。现有研究多关注二维模型，忽略了垂直维度的重要性。", "method": "提出了一种三维个人空间模型，通过Z轴的不适函数和XY平面的经典公式，量化机器人组件在三维空间中任何位置的不适感。", "result": "该模型首次实现了考虑人体配置和高度的三维空间不适感计算。", "conclusion": "该研究为机器人行为设计提供了更全面的个人空间模型，有助于提升人机交互的社会适应性。"}}
{"id": "2506.14414", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2506.14414", "abs": "https://arxiv.org/abs/2506.14414", "authors": ["Sabahat Israr", "Dawar Khan", "Zhanglin Cheng", "Mukhtaj Khan", "Kiyoshi Kiyokawa"], "title": "GHAR: GeoPose-based Handheld Augmented Reality for Architectural Positioning, Manipulation and Visual Exploration", "comment": null, "summary": "Handheld Augmented Reality (HAR) is revolutionizing the civil infrastructure application domain. The current trend in HAR relies on marker tracking technology. However, marker-based systems have several limitations, such as difficulty in use and installation, sensitivity to light, and marker design. In this paper, we propose a markerless HAR framework with GeoPose-based tracking. We use different gestures for manipulation and achieve 7 DOF (3 DOF each for translation and rotation, and 1 DOF for scaling). The proposed framework, called GHAR, is implemented for architectural building models. It augments virtual CAD models of buildings on the ground, enabling users to manipulate and visualize an architectural model before actual construction. The system offers a quick view of the building infrastructure, playing a vital role in requirement analysis and planning in construction technology. We evaluated the usability, manipulability, and comprehensibility of the proposed system using a standard user study with the System Usability Scale (SUS) and Handheld Augmented Reality User Study (HARUS). We compared our GeoPose-based markerless HAR framework with a marker-based HAR framework, finding significant improvement in the aforementioned three parameters with the markerless framework.", "AI": {"tldr": "提出了一种基于GeoPose的无标记手持增强现实（HAR）框架GHAR，用于建筑模型的可视化与操作，相比传统标记方法在可用性、操作性和可理解性上有显著提升。", "motivation": "传统基于标记的HAR系统存在使用安装困难、对光线敏感等问题，限制了其在土木基础设施领域的应用。", "method": "采用GeoPose跟踪技术，支持7自由度操作（平移、旋转和缩放），并通过手势实现模型交互。", "result": "用户研究表明，GHAR在可用性、操作性和可理解性上显著优于基于标记的HAR系统。", "conclusion": "无标记HAR框架GHAR为建筑规划提供了更高效的工具，具有实际应用潜力。"}}
{"id": "2506.14147", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14147", "abs": "https://arxiv.org/abs/2506.14147", "authors": ["Emma R. Dodoo", "Tamara Nelson-Fromm", "Mark Guzdial"], "title": "The Teacher's Dilemma: Balancing Trade-Offs in Programming Education for Emergent Bilingual Students", "comment": null, "summary": "K-12 computing teachers must navigate complex trade-offs when selecting programming languages and instructional materials for classrooms with emergent bilingual students. While they aim to foster an inclusive learning environment by addressing language barriers that impact student engagement, they must also align with K-12 computer science curricular guidelines and prepare students for industry-standard programming tools. Because programming languages predominantly use English keywords and most instructional materials are written in English, these linguistic barriers introduce cognitive load and accessibility challenges. This paper examines teachers' decisions in balancing these competing priorities, highlighting the tensions between accessibility, curriculum alignment, and workforce preparation. The findings shed light on how our teacher participants negotiate these trade-offs and what factors influence their selection of programming tools to best support EB students while meeting broader educational and professional goals.", "AI": {"tldr": "K-12计算教师在选择编程语言和教材时需权衡语言障碍、课程标准和职业准备，研究探讨了教师如何平衡这些需求。", "motivation": "研究动机是解决双语学生在编程学习中的语言障碍，同时满足课程标准和职业准备的需求。", "method": "通过分析教师的选择和决策过程，探讨如何平衡语言可及性、课程对齐和职业准备。", "result": "研究发现教师需权衡多因素，选择最适合双语学生的编程工具。", "conclusion": "结论是教师需综合考虑语言、课程和职业目标，以支持双语学生的学习。"}}
{"id": "2506.14223", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.14223", "abs": "https://arxiv.org/abs/2506.14223", "authors": ["Anna Hamberger", "Sebastian Murgul", "Jochen Schmidt", "Michael Heizmann"], "title": "Fretting-Transformer: Encoder-Decoder Model for MIDI to Tablature Transcription", "comment": "Accepted to the 50th International Computer Music Conference (ICMC), 2025", "summary": "Music transcription plays a pivotal role in Music Information Retrieval (MIR), particularly for stringed instruments like the guitar, where symbolic music notations such as MIDI lack crucial playability information. This contribution introduces the Fretting-Transformer, an encoderdecoder model that utilizes a T5 transformer architecture to automate the transcription of MIDI sequences into guitar tablature. By framing the task as a symbolic translation problem, the model addresses key challenges, including string-fret ambiguity and physical playability. The proposed system leverages diverse datasets, including DadaGP, GuitarToday, and Leduc, with novel data pre-processing and tokenization strategies. We have developed metrics for tablature accuracy and playability to quantitatively evaluate the performance. The experimental results demonstrate that the Fretting-Transformer surpasses baseline methods like A* and commercial applications like Guitar Pro. The integration of context-sensitive processing and tuning/capo conditioning further enhances the model's performance, laying a robust foundation for future developments in automated guitar transcription.", "AI": {"tldr": "Fretting-Transformer是一种基于T5架构的编码器-解码器模型，用于将MIDI序列自动转录为吉他指法谱，解决了弦-品模糊性和可演奏性问题，性能优于基线方法和商业应用。", "motivation": "MIDI符号缺乏吉他演奏的关键信息，现有方法在弦-品模糊性和可演奏性上表现不足，需要一种更高效的自动化转录方法。", "method": "采用T5变换器架构，将任务视为符号翻译问题，结合新颖的数据预处理和标记化策略，利用DadaGP等数据集进行训练。", "result": "实验表明，Fretting-Transformer在指法谱准确性和可演奏性上优于A*和Guitar Pro等基线方法。", "conclusion": "该模型为吉他自动转录奠定了坚实基础，未来可通过上下文敏感处理和调音/变调夹条件进一步提升性能。"}}
{"id": "2506.14112", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14112", "abs": "https://arxiv.org/abs/2506.14112", "authors": ["Hengyu Liu", "Yanhong Luo", "Congcong Wu", "Yin Guan", "Ahmed Lotfy Elrefai", "Andreas Elombo", "Si Li", "Sahban Wael Saeed Alnaser", "Mingyu Yan"], "title": "Considering the multi-time scale rolling optimization scheduling method of micro-energy network connected to electric vehicles", "comment": "7 pages,9 figures,1 table,conference", "summary": "The large-scale access of electric vehicles to the power grid not only provides flexible adjustment resources for the power system, but the temporal uncertainty and distribution complexity of their energy interaction pose significant challenges to the economy and robustness of the micro-energy network. In this paper, we propose a multi-time scale rolling optimization scheduling method for micro-energy networks considering the access of electric vehicles. In order to solve the problem of evaluating the dispatchable potential of electric vehicle clusters, a charging station aggregation model was constructed based on Minkowski summation theory, and the scattered electric vehicle resources were aggregated into virtual energy storage units to participate in system scheduling. Integrate price-based and incentive-based demand response mechanisms to synergistically tap the potential of source-load two-side regulation; On this basis, a two-stage optimal scheduling model of day-ahead and intra-day is constructed. The simulation results show that the proposed method reduces the scale of \"preventive curtailment\" due to more accurate scheduling, avoids the threat of power shortage to the safety of the power grid, and has more advantages in the efficiency of new energy consumption. At the same time, intra-day scheduling significantly reduces economic penalties and operating costs by avoiding output shortages, and improves the economy of the system in an uncertain forecasting environment.", "AI": {"tldr": "提出了一种考虑电动汽车接入的微能源网多时间尺度滚动优化调度方法，通过聚合模型和需求响应机制提升调度精度与经济性。", "motivation": "电动汽车大规模接入电网带来灵活调节资源，但其时间不确定性和分布复杂性对微能源网的经济性和鲁棒性提出挑战。", "method": "基于Minkowski求和理论构建充电站聚合模型，将分散的电动汽车资源聚合成虚拟储能单元，并结合价格型和激励型需求响应机制，构建日前和日内两阶段优化调度模型。", "result": "仿真结果显示，该方法提高了调度精度，减少了预防性削减规模，提升了新能源消纳效率，同时降低了经济惩罚和运行成本。", "conclusion": "所提方法在不确定预测环境下显著提升了系统的经济性和安全性。"}}
{"id": "2506.13902", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.13902", "abs": "https://arxiv.org/abs/2506.13902", "authors": ["Raymond Yu", "Paul Han", "Josh Myers-Dean", "Piper Wolters", "Favyen Bastani"], "title": "OPTIMUS: Observing Persistent Transformations in Multi-temporal Unlabeled Satellite-data", "comment": "WACV 2025", "summary": "In the face of pressing environmental issues in the 21st century, monitoring surface changes on Earth is more important than ever. Large-scale remote sensing, such as satellite imagery, is an important tool for this task. However, using supervised methods to detect changes is difficult because of the lack of satellite data annotated with change labels, especially for rare categories of change. Annotation proves challenging due to the sparse occurrence of changes in satellite images. Even within a vast collection of images, only a small fraction may exhibit persistent changes of interest. To address this challenge, we introduce OPTIMUS, a self-supervised learning method based on an intuitive principle: if a model can recover information about the relative order of images in the time series, then that implies that there are long-lasting changes in the images. OPTIMUS demonstrates this principle by using change point detection methods on model outputs in a time series. We demonstrate that OPTIMUS can directly detect interesting changes in satellite images, achieving an improvement in AUROC score from 56.3% to 87.6% at distinguishing changed time series from unchanged ones compared to baselines. Our code and dataset are available at https://huggingface.co/datasets/optimus-change/optimus-dataset/.", "AI": {"tldr": "OPTIMUS是一种自监督学习方法，通过检测时间序列中的变化点来识别卫星图像中的长期变化，显著提升了变化检测的性能。", "motivation": "由于缺乏标注变化标签的卫星数据，尤其是稀有类别变化，监督方法在变化检测中面临挑战。", "method": "OPTIMUS基于自监督学习，通过模型恢复时间序列图像的相对顺序信息来检测长期变化。", "result": "OPTIMUS在区分变化与未变化时间序列上的AUROC得分从56.3%提升至87.6%。", "conclusion": "OPTIMUS为解决卫星图像变化检测中的标注难题提供了一种有效方法。"}}
{"id": "2506.13831", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13831", "abs": "https://arxiv.org/abs/2506.13831", "authors": ["Jitian Zhao", "Chenghui Li", "Frederic Sala", "Karl Rohe"], "title": "Quantifying Structure in CLIP Embeddings: A Statistical Framework for Concept Interpretation", "comment": null, "summary": "Concept-based approaches, which aim to identify human-understandable concepts within a model's internal representations, are a promising method for interpreting embeddings from deep neural network models, such as CLIP. While these approaches help explain model behavior, current methods lack statistical rigor, making it challenging to validate identified concepts and compare different techniques. To address this challenge, we introduce a hypothesis testing framework that quantifies rotation-sensitive structures within the CLIP embedding space. Once such structures are identified, we propose a post-hoc concept decomposition method. Unlike existing approaches, it offers theoretical guarantees that discovered concepts represent robust, reproducible patterns (rather than method-specific artifacts) and outperforms other techniques in terms of reconstruction error. Empirically, we demonstrate that our concept-based decomposition algorithm effectively balances reconstruction accuracy with concept interpretability and helps mitigate spurious cues in data. Applied to a popular spurious correlation dataset, our method yields a 22.6% increase in worst-group accuracy after removing spurious background concepts.", "AI": {"tldr": "论文提出了一种基于假设检验的概念分解方法，用于解释CLIP嵌入空间中的结构，提高了概念的可验证性和重建精度。", "motivation": "当前概念解释方法缺乏统计严谨性，难以验证概念和比较技术。", "method": "引入假设检验框架量化CLIP嵌入空间中的旋转敏感结构，并提出后验概念分解方法。", "result": "方法在重建误差上优于其他技术，并在去除虚假背景概念后，最差组准确率提高了22.6%。", "conclusion": "该方法平衡了重建精度与概念可解释性，有效减少了数据中的虚假线索。"}}
{"id": "2506.13953", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13953", "abs": "https://arxiv.org/abs/2506.13953", "authors": ["Caio C. G. Ribeiro", "Leonardo R. D. Paes", "Douglas G. Macharet"], "title": "Socially-aware Object Transportation by a Mobile Manipulator in Static Planar Environments with Obstacles", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and Human Interactive Communication (ROMAN)", "summary": "Socially-aware robotic navigation is essential in environments where humans and robots coexist, ensuring both safety and comfort. However, most existing approaches have been primarily developed for mobile robots, leaving a significant gap in research that addresses the unique challenges posed by mobile manipulators. In this paper, we tackle the challenge of navigating a robotic mobile manipulator, carrying a non-negligible load, within a static human-populated environment while adhering to social norms. Our goal is to develop a method that enables the robot to simultaneously manipulate an object and navigate between locations in a socially-aware manner. We propose an approach based on the Risk-RRT* framework that enables the coordinated actuation of both the mobile base and manipulator. This approach ensures collision-free navigation while adhering to human social preferences. We compared our approach in a simulated environment to socially-aware mobile-only methods applied to a mobile manipulator. The results highlight the necessity for mobile manipulator-specific techniques, with our method outperforming mobile-only approaches. Our method enabled the robot to navigate, transport an object, avoid collisions, and minimize social discomfort effectively.", "AI": {"tldr": "本文提出了一种基于Risk-RRT*框架的方法，用于移动机械臂在静态人机环境中的社交导航和物体搬运，解决了现有方法主要针对移动机器人的局限性。", "motivation": "现有社交导航方法主要针对移动机器人，而移动机械臂在搬运物体时的独特挑战尚未充分研究。本文旨在填补这一空白。", "method": "采用Risk-RRT*框架，协调移动基座和机械臂的动作，实现无碰撞且符合社交偏好的导航。", "result": "在模拟环境中，该方法优于仅针对移动机器人的方法，能有效导航、搬运物体、避免碰撞并减少社交不适。", "conclusion": "移动机械臂需要专门的技术，本文提出的方法在社交导航和物体搬运方面表现出色。"}}
{"id": "2506.14714", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2506.14714", "abs": "https://arxiv.org/abs/2506.14714", "authors": ["Egor Larionov", "Igor Santesteban", "Hsiao-yu Chen", "Gene Lin", "Philipp Herholz", "Ryan Goldade", "Ladislav Kavan", "Doug Roble", "Tuur Stuyck"], "title": "SkinCells: Sparse Skinning using Voronoi Cells", "comment": null, "summary": "For decades, efficient real-time skinning methods have played a crucial role in animating character rigs for visual effects and games. These methods remain a fundamental component of modern applications. However, animatable digital asset creation predominantly remains a manual process. Current automated tools often fall short of delivering the desired level of quality for intricate and complex geometries, requiring manual touch-ups. We propose a fully automatic and robust method for generating high quality skinning weights given a user-provided skeleton and mesh in A- or T-pose. Notably, our approach provides direct sparsity controls, limiting the number of bone influences per vertex, which is essential for efficient asset creation for large-scale mobile experiences with multiple concurrent users. Our method additionally addresses the need for level-of-detail (LoD) variations in performance-sensitive applications, which are exacerbated on mobile platforms. By optimizing weights in space rather than on discrete points, we enable a single optimization result to be seamlessly applied to all levels of detail of that asset or even variations of that asset. To achieve this, we introduce a novel parameterized family of functions called SkinCells. We demonstrate how our automatic method is able to robustly compute skinning weights in cases where biharmonic weight computation fails.", "AI": {"tldr": "提出了一种全自动生成高质量蒙皮权重的方法，支持稀疏控制和多细节层次（LoD）优化。", "motivation": "当前蒙皮权重生成多为手动或自动化工具效果不佳，难以满足复杂几何体和移动平台的需求。", "method": "引入SkinCells函数族，优化空间权重而非离散点，支持稀疏控制和LoD应用。", "result": "方法在双谐权重计算失败时仍能稳健生成权重，适用于复杂几何体和移动平台。", "conclusion": "该方法为大规模移动应用提供了高效、自动化的蒙皮权重生成解决方案。"}}
{"id": "2506.14226", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2506.14226", "abs": "https://arxiv.org/abs/2506.14226", "authors": ["Yiyang Zhao", "Shuai Wang", "Guangzhi Sun", "Zehua Chen", "Chao Zhang", "Mingxing Xu", "Thomas Fang Zheng"], "title": "Investigation of Zero-shot Text-to-Speech Models for Enhancing Short-Utterance Speaker Verification", "comment": null, "summary": "Short-utterance speaker verification presents significant challenges due to the limited information in brief speech segments, which can undermine accuracy and reliability. Recently, zero-shot text-to-speech (ZS-TTS) systems have made considerable progress in preserving speaker identity. In this study, we explore, for the first time, the use of ZS-TTS systems for test-time data augmentation for speaker verification. We evaluate three state-of-the-art pre-trained ZS-TTS systems, NatureSpeech 3, CosyVoice, and MaskGCT, on the VoxCeleb 1 dataset. Our experimental results show that combining real and synthetic speech samples leads to 10%-16% relative equal error rate (EER) reductions across all durations, with particularly notable improvements for short utterances, all without retraining any existing systems. However, our analysis reveals that longer synthetic speech does not yield the same benefits as longer real speech in reducing EERs. These findings highlight the potential and challenges of using ZS-TTS for test-time speaker verification, offering insights for future research.", "AI": {"tldr": "利用零样本文本转语音（ZS-TTS）系统进行测试时数据增强，显著提升了短语音说话人验证的准确性，但对长语音效果有限。", "motivation": "短语音说话人验证因信息有限而准确性低，ZS-TTS系统在保留说话人身份方面进展显著，探索其用于数据增强的潜力。", "method": "评估三种预训练ZS-TTS系统（NatureSpeech 3、CosyVoice、MaskGCT）在VoxCeleb 1数据集上的表现，结合真实与合成语音样本。", "result": "结合真实与合成语音样本使相对等错误率（EER）降低10%-16%，短语音效果显著，但长语音效果不明显。", "conclusion": "ZS-TTS在测试时数据增强中具有潜力，但需进一步研究以优化长语音效果。"}}
{"id": "2506.14133", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14133", "abs": "https://arxiv.org/abs/2506.14133", "authors": ["Nikhil Pawar", "Guilherme Vieira Hollweg", "Akhtar Hussain", "Wencong Su", "Van-Hai Bui"], "title": "Enhancing Forecasting Accuracy in Dynamic Environments via PELT-Driven Drift Detection and Model Adaptation", "comment": "18 pages", "summary": "Accurate time series forecasting models are often compromised by data drift, where underlying data distributions change over time, leading to significant declines in prediction performance. To address this challenge, this study proposes an adaptive forecasting framework that integrates drift detection with targeted model retraining to compensate for drift effects. The framework utilizes the Pruned Exact Linear Time (PELT) algorithm to identify drift points within the feature space of time series data. Once drift intervals are detected, selective retraining is applied to prediction models using Multilayer Perceptron (MLP) and Lasso Regressor architectures, allowing the models to adjust to changing data patterns. The effectiveness of the proposed approach is demonstrated on two datasets: a real-world dataset containing electricity consumption and HVAC system data, and a synthetic financial dataset designed to test cross-domain applicability. Initial baseline models were developed without drift detection using extensive feature engineering. After integrating drift-aware retraining, the MLP model achieved a 44% reduction in mean absolute error (MAE) and a 39% increase in R^2 on the real-world dataset, while even greater improvements were observed on the synthetic financial dataset. Similar enhancements were achieved with the Lasso Regressor. These results highlight the robustness and generalizability of incorporating drift detection and adaptive retraining to sustain forecasting accuracy across diverse domains.", "AI": {"tldr": "该研究提出了一种自适应预测框架，通过结合漂移检测和目标模型重新训练来应对数据漂移问题，显著提升了时间序列预测的准确性。", "motivation": "数据漂移导致时间序列预测模型性能下降，需要一种自适应方法来检测漂移并调整模型。", "method": "使用PELT算法检测漂移点，结合MLP和Lasso Regressor进行选择性重新训练。", "result": "在真实和合成数据集上，MLP和Lasso Regressor均显著降低了MAE并提高了R^2。", "conclusion": "漂移检测和自适应重新训练能够有效维持跨领域预测的准确性。"}}
{"id": "2506.13910", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13910", "abs": "https://arxiv.org/abs/2506.13910", "authors": ["Aritra Dutta", "Pushpita Boral", "G Suseela"], "title": "Intelligent Image Sensing for Crime Analysis: A ML Approach towards Enhanced Violence Detection and Investigation", "comment": null, "summary": "The increasing global crime rate, coupled with substantial human and property losses, highlights the limitations of traditional surveillance methods in promptly detecting diverse and unexpected acts of violence. Addressing this pressing need for automatic violence detection, we leverage Machine Learning to detect and categorize violent events in video streams. This paper introduces a comprehensive framework for violence detection and classification, employing Supervised Learning for both binary and multi-class violence classification. The detection model relies on 3D Convolutional Neural Networks, while the classification model utilizes the separable convolutional 3D model for feature extraction and bidirectional LSTM for temporal processing. Training is conducted on a diverse customized datasets with frame-level annotations, incorporating videos from surveillance cameras, human recordings, hockey fight, sohas and wvd dataset across various platforms. Additionally, a camera module integrated with raspberry pi is used to capture live video feed, which is sent to the ML model for processing. Thus, demonstrating improved performance in terms of computational resource efficiency and accuracy.", "AI": {"tldr": "本文提出了一种基于机器学习的暴力检测与分类框架，结合3D卷积神经网络和双向LSTM，显著提升了计算效率和准确性。", "motivation": "传统监控方法在及时检测多样化暴力行为方面存在局限，亟需自动化解决方案以减少人力和财产损失。", "method": "采用监督学习进行二元和多类暴力分类，使用3D卷积神经网络进行检测，分离卷积3D模型提取特征，双向LSTM处理时序数据。", "result": "在多样化数据集上训练，结合实时视频流处理，模型在计算资源和准确性方面表现优越。", "conclusion": "该框架为暴力检测提供了高效且准确的自动化解决方案，具有实际应用潜力。"}}
{"id": "2506.13834", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13834", "abs": "https://arxiv.org/abs/2506.13834", "authors": ["Zhao Wei", "Chin Chun Ooi", "Abhishek Gupta", "Jian Cheng Wong", "Pao-Hsiung Chiu", "Sheares Xue Wen Toh", "Yew-Soon Ong"], "title": "Evolvable Conditional Diffusion", "comment": null, "summary": "This paper presents an evolvable conditional diffusion method such that black-box, non-differentiable multi-physics models, as are common in domains like computational fluid dynamics and electromagnetics, can be effectively used for guiding the generative process to facilitate autonomous scientific discovery. We formulate the guidance as an optimization problem where one optimizes for a desired fitness function through updates to the descriptive statistic for the denoising distribution, and derive an evolution-guided approach from first principles through the lens of probabilistic evolution. Interestingly, the final derived update algorithm is analogous to the update as per common gradient-based guided diffusion models, but without ever having to compute any derivatives. We validate our proposed evolvable diffusion algorithm in two AI for Science scenarios: the automated design of fluidic topology and meta-surface. Results demonstrate that this method effectively generates designs that better satisfy specific optimization objectives without reliance on differentiable proxies, providing an effective means of guidance-based diffusion that can capitalize on the wealth of black-box, non-differentiable multi-physics numerical models common across Science.", "AI": {"tldr": "提出一种可进化的条件扩散方法，用于指导生成过程，适用于不可微分的多物理模型，如计算流体动力学和电磁学领域。", "motivation": "解决黑箱、不可微分多物理模型在科学发现中的生成指导问题。", "method": "将指导问题转化为优化问题，通过更新去噪分布的描述统计量来优化目标函数，提出基于概率进化的进化引导方法。", "result": "在流体拓扑和超表面设计中验证了方法的有效性，生成的设计更好地满足优化目标。", "conclusion": "该方法无需依赖可微分代理，为科学领域中的黑箱模型提供了一种有效的指导扩散手段。"}}
{"id": "2506.13957", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13957", "abs": "https://arxiv.org/abs/2506.13957", "authors": ["Narsimlu Kemsaram", "Akin Delibasi", "James Hardwick", "Bonot Gautam", "Diego Martinez Plasencia", "Sriram Subramanian"], "title": "A Cooperative Contactless Object Transport with Acoustic Robots", "comment": "This paper has been accepted for publication in the Proceedings of the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) as oral presentation, 8 pages with 8 figures", "summary": "Cooperative transport, the simultaneous movement of an object by multiple agents, has been widely observed in biological systems such as ant colonies, which improve efficiency and adaptability in dynamic environments. Inspired by these natural phenomena, we present a novel acoustic robotic system for the transport of contactless objects in mid-air. Our system leverages phased ultrasonic transducers and a robotic control system onboard to generate localized acoustic pressure fields, enabling precise manipulation of airborne particles and robots. We categorize contactless object-transport strategies into independent transport (uncoordinated) and forward-facing cooperative transport (coordinated), drawing parallels with biological systems to optimize efficiency and robustness. The proposed system is experimentally validated by evaluating levitation stability using a microphone in the measurement lab, transport efficiency through a phase-space motion capture system, and clock synchronization accuracy via an oscilloscope. The results demonstrate the feasibility of both independent and cooperative airborne object transport. This research contributes to the field of acoustophoretic robotics, with potential applications in contactless material handling, micro-assembly, and biomedical applications.", "AI": {"tldr": "本文提出了一种新型声学机器人系统，用于无接触物体的空中运输，受生物系统启发，通过声压场实现精确操控，并验证了独立与协作运输的可行性。", "motivation": "受蚂蚁等生物系统协作运输的启发，研究旨在开发一种高效、适应性强的无接触物体运输系统，以应对动态环境的需求。", "method": "利用相位超声换能器和机器人控制系统生成局部声压场，将运输策略分为独立运输和协作运输，并通过实验验证其稳定性和效率。", "result": "实验证明系统能够实现独立和协作的空中物体运输，具有较高的稳定性和效率。", "conclusion": "该研究为声学机器人领域提供了新方法，有望应用于无接触材料处理、微组装和生物医学等领域。"}}
{"id": "2506.14166", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14166", "abs": "https://arxiv.org/abs/2506.14166", "authors": ["Nirodya Pussadeniya", "Bahareh Nakisa", "Mohmmad Naim Rastgoo"], "title": "Affective-CARA: A Knowledge Graph Driven Framework for Culturally Adaptive Emotional Intelligence in HCI", "comment": null, "summary": "Culturally adaptive emotional responses remain a critical challenge in affective computing. This paper introduces Affective-CARA, an agentic framework designed to enhance user-agent interactions by integrating a Cultural Emotion Knowledge Graph (derived from StereoKG) with Valence, Arousal, and Dominance annotations, culture-specific data, and cross-cultural checks to minimize bias. A Gradient-Based Reward Policy Optimization mechanism further refines responses according to cultural alignment, affective appropriateness, and iterative user feedback. A Cultural-Aware Response Mediator coordinates knowledge retrieval, reinforcement learning updates, and historical data fusion. By merging real-time user input with past emotional states and cultural insights, Affective-CARA delivers narratives that are deeply personalized and sensitive to diverse cultural norms. Evaluations on AffectNet, SEMAINE DB, and MERD confirm that the framework consistently outperforms baseline models in sentiment alignment, cultural adaptation, and narrative quality. Affective-CARA achieved a Cultural Semantic Density of 9.32 out of 10 and lowered cultural representation bias by 61% (KL-Divergence: 0.28), demonstrating robust performance in generating ethical, adaptive responses. These findings suggest the potential for more inclusive and empathetic interactions, making Affective-CARA an avenue for fostering culturally grounded user experiences across domains such as cross-cultural communication, mental health support, and education.", "AI": {"tldr": "Affective-CARA是一个情感计算框架，通过结合文化情感知识图谱和强化学习优化机制，提升跨文化用户与代理的互动质量。", "motivation": "解决情感计算中文化适应性不足的问题，推动更包容、共情的跨文化互动。", "method": "整合文化情感知识图谱、梯度奖励策略优化和文化感知响应调解器，结合实时用户输入和历史数据。", "result": "在情感对齐、文化适应和叙事质量上优于基线模型，文化语义密度达9.32/10，文化偏差降低61%。", "conclusion": "Affective-CARA为跨文化沟通、心理健康和教育等领域提供了更具文化敏感性的互动方案。"}}
{"id": "2506.14293", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.14293", "abs": "https://arxiv.org/abs/2506.14293", "authors": ["Tawsif Ahmed", "Andrej Radonjic", "Gollam Rabby"], "title": "SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling", "comment": null, "summary": "We present Sleeping-DISCO 9M, a large-scale pre-training dataset for music and song. To the best of our knowledge, there are no open-source high-quality dataset representing popular and well-known songs for generative music modeling tasks such as text-music, music-captioning, singing-voice synthesis, melody reconstruction and cross-model retrieval. Past contributions focused on isolated and constrained factors whose core perspective was to create synthetic or re-recorded music corpus (e.g. GTSinger, M4Singer) and arbitrarily large-scale audio datasets (e.g. DISCO-10M and LAIONDISCO-12M) had been another focus for the community. Unfortunately, adoption of these datasets has been below substantial in the generative music community as these datasets fail to reflect real-world music and its flavour. Our dataset changes this narrative and provides a dataset that is constructed using actual popular music and world-renowned artists.", "AI": {"tldr": "Sleeping-DISCO 9M是一个用于音乐生成任务的大规模预训练数据集，填补了开源高质量流行音乐数据集的空白。", "motivation": "当前的开源数据集未能反映真实世界的音乐风格，限制了生成音乐模型的发展。", "method": "数据集基于实际流行音乐和知名艺术家的作品构建。", "result": "提供了一个高质量、真实反映音乐风格的数据集。", "conclusion": "Sleeping-DISCO 9M有望推动生成音乐模型的进步。"}}
{"id": "2506.14195", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14195", "abs": "https://arxiv.org/abs/2506.14195", "authors": ["Thien Nhan Vo"], "title": "Nonlinear Control of a Quadrotor UAV Using Backstepping-Based Sliding Mode Technique", "comment": null, "summary": "This paper presents the development of a sliding mode controller using the backstepping approach. The controller is employed to synthesize tracking errors and Lyapunov functions. A novel state-space representation is formulated by incorporating the dynamics of the quadrotor and accounting for non-holonomic constraints. The proposed sliding mode controller effectively addresses system nonlinearities and improves tracking of predefined trajectories. Simulation results are presented graphically to demonstrate the controller's performance.", "AI": {"tldr": "本文提出了一种基于反步法的滑模控制器，用于合成跟踪误差和Lyapunov函数，并通过新颖的状态空间表示解决了四旋翼的非线性问题。", "motivation": "解决四旋翼飞行器的非线性动力学问题，并提高对预定轨迹的跟踪性能。", "method": "采用反步法设计滑模控制器，结合四旋翼动力学和非完整约束，构建状态空间表示。", "result": "仿真结果表明，所提出的滑模控制器能有效处理系统非线性并提升轨迹跟踪性能。", "conclusion": "该控制器在四旋翼系统中表现出色，适用于非线性控制问题。"}}
{"id": "2506.13925", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13925", "abs": "https://arxiv.org/abs/2506.13925", "authors": ["Numair Nadeem", "Saeed Anwar", "Muhammad Hamza Asad", "Abdul Bais"], "title": "HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment", "comment": null, "summary": "Semi-supervised semantic segmentation remains challenging under severe label scarcity and domain variability. Vision-only methods often struggle to generalize, resulting in pixel misclassification between similar classes, poor generalization and boundary localization. Vision-Language Models offer robust, domain-invariant semantics but lack the spatial grounding required for dense prediction. We introduce HierVL, a unified framework that bridges this gap by integrating abstract text embeddings into a mask-transformer architecture tailored for semi-supervised segmentation. HierVL features three novel components: a Hierarchical Semantic Query Generator that filters and projects abstract class embeddings into multi-scale queries to suppress irrelevant classes and handle intra-class variability; a Cross-Modal Spatial Alignment Module that aligns semantic queries with pixel features for sharper boundaries under sparse supervision; and a Dual-Query Transformer Decoder that fuses semantic and instance-level queries to prevent instance collapse. We also introduce targeted regularization losses that maintain vision-language alignment throughout training to reinforce semantic grounding. HierVL establishes a new state-of-the-art by achieving a +4.4% mean improvement of the intersection over the union on COCO (with 232 labeled images), +3.1% on Pascal VOC (with 92 labels), +5.9% on ADE20 (with 158 labels) and +1.8% on Cityscapes (with 100 labels), demonstrating better performance under 1% supervision on four benchmark datasets. Our results show that language-guided segmentation closes the label efficiency gap and unlocks new levels of fine-grained, instance-aware generalization.", "AI": {"tldr": "HierVL是一个结合视觉语言模型的半监督语义分割框架，通过多尺度查询和跨模态对齐提升性能。", "motivation": "解决标签稀缺和领域变化下视觉方法的局限性，利用语言模型的语义鲁棒性改进分割。", "method": "提出HierVL框架，包括层次语义查询生成器、跨模态空间对齐模块和双查询变换解码器。", "result": "在多个数据集上显著提升性能（如COCO +4.4% mIoU），尤其在1%监督下表现优异。", "conclusion": "语言引导的分割填补了标签效率差距，实现了细粒度的实例感知泛化。"}}
{"id": "2506.13836", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13836", "abs": "https://arxiv.org/abs/2506.13836", "authors": ["Dang Viet Anh Nguyen", "Carlos Lima Azevedo", "Tomer Toledo", "Filipe Rodrigues"], "title": "Robustness of Reinforcement Learning-Based Traffic Signal Control under Incidents: A Comparative Study", "comment": "35 pages, 5 figures, 3 tables", "summary": "Reinforcement learning-based traffic signal control (RL-TSC) has emerged as a promising approach for improving urban mobility. However, its robustness under real-world disruptions such as traffic incidents remains largely underexplored. In this study, we introduce T-REX, an open-source, SUMO-based simulation framework for training and evaluating RL-TSC methods under dynamic, incident scenarios. T-REX models realistic network-level performance considering drivers' probabilistic rerouting, speed adaptation, and contextual lane-changing, enabling the simulation of congestion propagation under incidents. To assess robustness, we propose a suite of metrics that extend beyond conventional traffic efficiency measures. Through extensive experiments across synthetic and real-world networks, we showcase T-REX for the evaluation of several state-of-the-art RL-TSC methods under multiple real-world deployment paradigms. Our findings show that while independent value-based and decentralized pressure-based methods offer fast convergence and generalization in stable traffic conditions and homogeneous networks, their performance degrades sharply under incident-driven distribution shifts. In contrast, hierarchical coordination methods tend to offer more stable and adaptable performance in large-scale, irregular networks, benefiting from their structured decision-making architecture. However, this comes with the trade-off of slower convergence and higher training complexity. These findings highlight the need for robustness-aware design and evaluation in RL-TSC research. T-REX contributes to this effort by providing an open, standardized and reproducible platform for benchmarking RL methods under dynamic and disruptive traffic scenarios.", "AI": {"tldr": "T-REX是一个基于SUMO的开源仿真框架，用于在动态交通事件场景下训练和评估强化学习交通信号控制（RL-TSC）方法，并提出了新的鲁棒性评估指标。研究发现，独立值基和分散压力基方法在稳定条件下表现良好，但在事件驱动分布变化下性能下降；而分层协调方法在大规模不规则网络中表现更稳定，但收敛慢且训练复杂。", "motivation": "研究动机是探索RL-TSC在真实世界交通事件中的鲁棒性，填补现有研究的空白。", "method": "提出T-REX框架，模拟真实网络性能（如驾驶员动态行为），并设计新的鲁棒性评估指标。通过合成和真实网络实验，评估多种RL-TSC方法。", "result": "独立值基和分散压力基方法在稳定条件下表现良好，但在事件驱动分布变化下性能下降；分层协调方法在大规模网络中表现更稳定，但收敛慢。", "conclusion": "研究强调了鲁棒性设计和评估的重要性，T-REX为动态和破坏性交通场景下的RL方法提供了标准化平台。"}}
{"id": "2506.13986", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13986", "abs": "https://arxiv.org/abs/2506.13986", "authors": ["Ante Maric", "Julius Jankowski", "Giammarco Caroleo", "Alessandro Albini", "Perla Maiolino", "Sylvain Calinon"], "title": "Diffusion-based Inverse Observation Model for Artificial Skin", "comment": "Accepted to RSS 2025 workshop on Navigating Contact Dynamics in Robotics", "summary": "Contact-based estimation of object pose is challenging due to discontinuities and ambiguous observations that can correspond to multiple possible system states. This multimodality makes it difficult to efficiently sample valid hypotheses while respecting contact constraints. Diffusion models can learn to generate samples from such multimodal probability distributions through denoising algorithms. We leverage these probabilistic modeling capabilities to learn an inverse observation model conditioned on tactile measurements acquired from a distributed artificial skin. We present simulated experiments demonstrating efficient sampling of contact hypotheses for object pose estimation through touch.", "AI": {"tldr": "利用扩散模型从触觉测量中学习逆向观察模型，解决物体姿态估计中的多模态问题。", "motivation": "接触式物体姿态估计因观测的多模态性和不连续性而具有挑战性。", "method": "使用扩散模型学习基于触觉测量的逆向观察模型，并通过模拟实验验证。", "result": "模拟实验表明，该方法能高效采样接触假设，用于物体姿态估计。", "conclusion": "扩散模型能有效处理触觉测量中的多模态问题，提升姿态估计效率。"}}
{"id": "2506.14196", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14196", "abs": "https://arxiv.org/abs/2506.14196", "authors": ["Jiayue Melissa Shi", "Keran Wang", "Dong Whi Yoo", "Ravi Karkar", "Koustuv Saha"], "title": "Balancing Caregiving and Self-Care: Exploring Mental Health Needs of Alzheimer's and Dementia Caregivers", "comment": null, "summary": "Alzheimer's Disease and Related Dementias (AD/ADRD) are progressive neurodegenerative conditions that impair memory, thought processes, and functioning. Family caregivers of individuals with AD/ADRD face significant mental health challenges due to long-term caregiving responsibilities. Yet, current support systems often overlook the evolving nature of their mental wellbeing needs. Our study examines caregivers' mental wellbeing concerns, focusing on the practices they adopt to manage the burden of caregiving and the technologies they use for support. Through semi-structured interviews with 25 family caregivers of individuals with AD/ADRD, we identified the key causes and effects of mental health challenges, and developed a temporal mapping of how caregivers' mental wellbeing evolves across three distinct stages of the caregiving journey. Additionally, our participants shared insights into improvements for existing mental health technologies, emphasizing the need for accessible, scalable, and personalized solutions that adapt to caregivers' changing needs over time. These findings offer a foundation for designing dynamic, stage-sensitive interventions that holistically support caregivers' mental wellbeing, benefiting both caregivers and care recipients.", "AI": {"tldr": "研究探讨了阿尔茨海默病及相关痴呆症（AD/ADRD）家庭照顾者的心理健康需求，分析了其负担管理实践和技术支持，并提出了分阶段干预建议。", "motivation": "当前支持系统忽视了照顾者心理健康需求的动态变化，研究旨在填补这一空白。", "method": "通过对25名家庭照顾者进行半结构化访谈，识别心理健康挑战的原因和影响，并绘制了照顾旅程中三个阶段的心理健康变化图。", "result": "研究发现照顾者心理健康需求随时间变化，现有技术支持需更具可访问性、可扩展性和个性化。", "conclusion": "研究为设计动态、分阶段的心理健康干预措施提供了基础，以全面支持照顾者和被照顾者。"}}
{"id": "2506.14396", "categories": ["cs.SD", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.14396", "abs": "https://arxiv.org/abs/2506.14396", "authors": ["Jiayi He", "Jiangyan Yi", "Jianhua Tao", "Siding Zeng", "Hao Gu"], "title": "Manipulated Regions Localization For Partially Deepfake Audio: A Survey", "comment": null, "summary": "With the development of audio deepfake techniques, attacks with partially deepfake audio are beginning to rise. Compared to fully deepfake, it is much harder to be identified by the detector due to the partially cryptic manipulation, resulting in higher security risks. Although some studies have been launched, there is no comprehensive review to systematically introduce the current situations and development trends for addressing this issue. Thus, in this survey, we are the first to outline a systematic introduction for partially deepfake audio manipulated region localization tasks, including the fundamentals, branches of existing methods, current limitations and potential trends, providing a revealing insight into this scope.", "AI": {"tldr": "本文首次系统综述了部分深度伪造音频的区域定位任务，包括基础、现有方法分支、当前局限和潜在趋势。", "motivation": "随着音频深度伪造技术的发展，部分伪造音频攻击日益增多，因其隐蔽性更难被检测器识别，带来更高安全风险。目前缺乏对此问题的全面综述。", "method": "系统介绍部分深度伪造音频区域定位任务的基础、现有方法分支、局限与趋势。", "result": "提供了对该领域的深入见解。", "conclusion": "本文填补了部分深度伪造音频区域定位任务的综述空白，为未来研究提供了方向。"}}
{"id": "2506.14252", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14252", "abs": "https://arxiv.org/abs/2506.14252", "authors": ["Olav Galteland", "Jacob Hadler-Jacobsen", "Hanne Kauko"], "title": "Techno-economic optimization of hybrid steam-electric energy systems with excess heat utilization and reserve market participation", "comment": null, "summary": "This study investigates the economic viability and optimal configuration of a hybrid industrial energy system combining an electrode boiler, steam accumulator, and battery energy storage system (BESS). This study optimizes system operation for a specific configuration to minimize net energy costs, defined as energy costs minus profits from price arbitrage and reserve markets. The optimization uses load shifting, peak shaving, and frequency containment reserve market participation with hourly 2024 data from Norway and Germany. Net present value (NPV) analysis was performed to determine the most cost-efficient energy storage configurations. The results show that current investment costs favor steam accumulators over BESS in both countries. However, a reduction in BESS cost will make batteries economically competitive, particularly in Germany, where high price volatility and power-based grid tariffs provide stronger incentives for load shifting and peak shaving. Participation in the FCR market accounted for a 17% and 7% reduction of the net energy costs in Norway and Germany, respectively. Utilization of excess heat, through inlet water preheating, further reduced the net energy costs. Sensitivity analyses confirm that investment costs, especially for BESS, strongly influence optimal system design. These findings offer guidance for industrial flexibility investments across diverse electricity markets.", "AI": {"tldr": "研究探讨了电极锅炉、蒸汽蓄热器和电池储能系统（BESS）混合工业能源系统的经济性和最优配置，通过优化运行以最小化净能源成本。", "motivation": "研究旨在为工业能源系统提供经济高效的配置方案，利用价格套利和备用市场参与降低成本。", "method": "采用负荷转移、削峰和频率控制备用市场参与，基于2024年挪威和德国的每小时数据，进行净现值分析。", "result": "当前投资成本下，蒸汽蓄热器优于BESS；但BESS成本下降后，电池在德国更具竞争力。FCR市场参与分别降低挪威和德国净能源成本的17%和7%。", "conclusion": "研究为不同电力市场中的工业灵活性投资提供了指导，强调了投资成本对系统设计的关键影响。"}}
{"id": "2506.13993", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13993", "abs": "https://arxiv.org/abs/2506.13993", "authors": ["Michelangelo Conserva", "Alex Wilson", "Charlotte Stanton", "Vishal Batchu", "Varun Gulshan"], "title": "Mapping Farmed Landscapes from Remote Sensing", "comment": null, "summary": "Effective management of agricultural landscapes is critical for meeting global biodiversity targets, but efforts are hampered by the absence of detailed, large-scale ecological maps. To address this, we introduce Farmscapes, the first large-scale (covering most of England), high-resolution (25cm) map of rural landscape features, including ecologically vital elements like hedgerows, woodlands, and stone walls. This map was generated using a deep learning segmentation model trained on a novel, dataset of 942 manually annotated tiles derived from aerial imagery. Our model accurately identifies key habitats, achieving high f1-scores for woodland (96\\%) and farmed land (95\\%), and demonstrates strong capability in segmenting linear features, with an F1-score of 72\\% for hedgerows. By releasing the England-wide map on Google Earth Engine, we provide a powerful, open-access tool for ecologists and policymakers. This work enables data-driven planning for habitat restoration, supports the monitoring of initiatives like the EU Biodiversity Strategy, and lays the foundation for advanced analysis of landscape connectivity.", "AI": {"tldr": "Farmscapes是一种高分辨率（25厘米）的英格兰农村景观特征地图，通过深度学习模型生成，为生态学家和政策制定者提供开放工具，支持生物多样性保护。", "motivation": "农业景观管理对全球生物多样性目标至关重要，但缺乏详细的大规模生态地图阻碍了相关努力。", "method": "使用深度学习分割模型，基于942个手动标注的航空影像图块训练，生成高分辨率地图。", "result": "模型准确识别关键栖息地，林地（96%）和农田（95%）F1分数高，树篱（72%）表现良好。", "conclusion": "Farmscapes为栖息地恢复和景观连通性分析提供了数据支持，助力生物多样性战略监测。"}}
{"id": "2506.13838", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.13838", "abs": "https://arxiv.org/abs/2506.13838", "authors": ["Lorena Poenaru-Olaru", "June Sallou", "Luis Cruz", "Jan Rellermeyer", "Arie van Deursen"], "title": "Sustainable Machine Learning Retraining: Optimizing Energy Efficiency Without Compromising Accuracy", "comment": "12 pages. Accepted at ICT4Sustainability 2025 conference", "summary": "The reliability of machine learning (ML) software systems is heavily influenced by changes in data over time. For that reason, ML systems require regular maintenance, typically based on model retraining. However, retraining requires significant computational demand, which makes it energy-intensive and raises concerns about its environmental impact. To understand which retraining techniques should be considered when designing sustainable ML applications, in this work, we study the energy consumption of common retraining techniques. Since the accuracy of ML systems is also essential, we compare retraining techniques in terms of both energy efficiency and accuracy. We showcase that retraining with only the most recent data, compared to all available data, reduces energy consumption by up to 25\\%, being a sustainable alternative to the status quo. Furthermore, our findings show that retraining a model only when there is evidence that updates are necessary, rather than on a fixed schedule, can reduce energy consumption by up to 40\\%, provided a reliable data change detector is in place. Our findings pave the way for better recommendations for ML practitioners, guiding them toward more energy-efficient retraining techniques when designing sustainable ML software systems.", "AI": {"tldr": "该论文研究了机器学习系统中模型重训练技术的能源消耗，提出了更节能的重训练方法。", "motivation": "机器学习系统的可靠性受数据变化影响，而传统重训练方法能耗高，亟需可持续的替代方案。", "method": "比较不同重训练技术的能源效率和准确性，重点关注仅使用最新数据和按需重训练的策略。", "result": "仅使用最新数据可减少25%能耗，按需重训练可减少40%能耗。", "conclusion": "研究为设计可持续机器学习系统提供了节能重训练技术的推荐。"}}
{"id": "2506.14009", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14009", "abs": "https://arxiv.org/abs/2506.14009", "authors": ["Qianzhong Chen", "Naixiang Gao", "Suning Huang", "JunEn Low", "Timothy Chen", "Jiankai Sun", "Mac Schwager"], "title": "GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics", "comment": null, "summary": "Autonomous drones capable of interpreting and executing high-level language instructions in unstructured environments remain a long-standing goal. Yet existing approaches are constrained by their dependence on hand-crafted skills, extensive parameter tuning, or computationally intensive models unsuitable for onboard use. We introduce GRaD-Nav++, a lightweight Vision-Language-Action (VLA) framework that runs fully onboard and follows natural-language commands in real time. Our policy is trained in a photorealistic 3D Gaussian Splatting (3DGS) simulator via Differentiable Reinforcement Learning (DiffRL), enabling efficient learning of low-level control from visual and linguistic inputs. At its core is a Mixture-of-Experts (MoE) action head, which adaptively routes computation to improve generalization while mitigating forgetting. In multi-task generalization experiments, GRaD-Nav++ achieves a success rate of 83% on trained tasks and 75% on unseen tasks in simulation. When deployed on real hardware, it attains 67% success on trained tasks and 50% on unseen ones. In multi-environment adaptation experiments, GRaD-Nav++ achieves an average success rate of 81% across diverse simulated environments and 67% across varied real-world settings. These results establish a new benchmark for fully onboard Vision-Language-Action (VLA) flight and demonstrate that compact, efficient models can enable reliable, language-guided navigation without relying on external infrastructure.", "AI": {"tldr": "GRaD-Nav++ 是一种轻量级的视觉-语言-动作（VLA）框架，能够在无人机上实时执行自然语言指令，通过高效学习和自适应计算路由实现多任务泛化和环境适应。", "motivation": "现有方法依赖手工技能、参数调整或计算密集型模型，难以在无人机上实时运行，因此需要一种轻量、高效的解决方案。", "method": "使用 3D 高斯泼溅（3DGS）模拟器和可微分强化学习（DiffRL）训练策略，核心是混合专家（MoE）动作头，自适应路由计算以提高泛化能力。", "result": "在模拟中，训练任务成功率 83%，未见任务 75%；实际硬件上分别为 67% 和 50%。多环境适应实验中，模拟环境平均成功率 81%，真实环境 67%。", "conclusion": "GRaD-Nav++ 为完全机载的 VLA 飞行设定了新基准，证明轻量模型可实现可靠的语言引导导航，无需依赖外部基础设施。"}}
{"id": "2506.14295", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14295", "abs": "https://arxiv.org/abs/2506.14295", "authors": ["Anders Giovanni Møller", "Daniel M. Romero", "David Jurgens", "Luca Maria Aiello"], "title": "The Impact of Generative AI on Social Media: An Experimental Study", "comment": "48 pages, 12 figures", "summary": "Generative Artificial Intelligence (AI) tools are increasingly deployed across social media platforms, yet their implications for user behavior and experience remain understudied, particularly regarding two critical dimensions: (1) how AI tools affect the behaviors of content producers in a social media context, and (2) how content generated with AI assistance is perceived by users. To fill this gap, we conduct a controlled experiment with a representative sample of 680 U.S. participants in a realistic social media environment. The participants are randomly assigned to small discussion groups, each consisting of five individuals in one of five distinct experimental conditions: a control group and four treatment groups, each employing a unique AI intervention-chat assistance, conversation starters, feedback on comment drafts, and reply suggestions. Our findings highlight a complex duality: some AI-tools increase user engagement and volume of generated content, but at the same time decrease the perceived quality and authenticity of discussion, and introduce a negative spill-over effect on conversations. Based on our findings, we propose four design principles and recommendations aimed at social media platforms, policymakers, and stakeholders: ensuring transparent disclosure of AI-generated content, designing tools with user-focused personalization, incorporating context-sensitivity to account for both topic and user intent, and prioritizing intuitive user interfaces. These principles aim to guide an ethical and effective integration of generative AI into social media.", "AI": {"tldr": "研究探讨生成式AI工具对社交媒体用户行为及内容感知的影响，通过实验发现AI工具虽提升参与度但降低内容质量，提出四项设计原则。", "motivation": "填补生成式AI工具在社交媒体中对内容生产者行为和用户感知影响的研究空白。", "method": "对680名美国参与者进行控制实验，分为五组（对照组和四种AI干预组），模拟真实社交媒体环境。", "result": "AI工具增加用户参与和内容量，但降低讨论质量和真实性，并产生负面溢出效应。", "conclusion": "提出透明披露、用户个性化、上下文敏感和直观界面四项设计原则，以指导AI在社交媒体中的伦理整合。"}}
{"id": "2506.14398", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2506.14398", "abs": "https://arxiv.org/abs/2506.14398", "authors": ["Chia-Hua Wu", "Wanying Ge", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "title": "A Comparative Study on Proactive and Passive Detection of Deepfake Speech", "comment": null, "summary": "Solutions for defending against deepfake speech fall into two categories: proactive watermarking models and passive conventional deepfake detectors. While both address common threats, their differences in training, optimization, and evaluation prevent a unified protocol for joint evaluation and selecting the best solutions for different cases. This work proposes a framework to evaluate both model types in deepfake speech detection. To ensure fair comparison and minimize discrepancies, all models were trained and tested on common datasets, with performance evaluated using a shared metric. We also analyze their robustness against various adversarial attacks, showing that different models exhibit distinct vulnerabilities to different speech attribute distortions. Our training and evaluation code is available at Github.", "AI": {"tldr": "提出一个框架，用于统一评估主动水印模型和被动深度伪造检测器在深度伪造语音检测中的性能。", "motivation": "现有解决方案分为主动水印模型和被动检测器，但缺乏统一的评估协议，无法公平比较和选择最佳方案。", "method": "在共同数据集上训练和测试所有模型，使用共享指标评估性能，并分析其对不同对抗攻击的鲁棒性。", "result": "不同模型对不同语音属性失真表现出不同的脆弱性。", "conclusion": "提出的框架为深度伪造语音检测提供了公平比较和选择最佳解决方案的基础。"}}
{"id": "2506.14469", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.14469", "abs": "https://arxiv.org/abs/2506.14469", "authors": ["Jared Miller", "Maitraya Avadhut Desai", "Xiuqiang He", "Roy S. Smith", "Gabriela Hug"], "title": "Network-Independent Incremental Passivity Conditions for Grid-Forming Inverter Control", "comment": "7 pages, 4 figures", "summary": "Grid-forming inverters control the power transfer between the AC and DC sides of an electrical grid while maintaining the frequency and voltage of the AC side. This paper focuses on ensuring large-signal stability of an electrical grid with inverter-interfaced renewable sources. We prove that the Hybrid-Angle Control (HAC) scheme for grid-forming inverters can exhibit incremental passivity properties between current and voltage at both the AC and DC ports. This incremental passivity can be certified through decentralized conditions. Inverters operating under HAC can, therefore, be connected to other passive elements (e.g. transmission lines) with an immediate guarantee of global transient stability regardless of the network topology or parameters. Passivity of Hybrid Angle Control is also preserved under small-signal (linearized) analyses, in contrast to conventional proportional droop laws that are passivity-short at low frequencies. Passivity and interconnected-stability properties are demonstrated through an example case study.", "AI": {"tldr": "本文证明了混合角度控制（HAC）方案在电网形成逆变器中具有增量被动性，确保了大信号稳定性，并通过案例研究验证了其被动性和互联稳定性。", "motivation": "研究电网中逆变器接口的可再生能源的大信号稳定性问题。", "method": "采用混合角度控制（HAC）方案，证明其在AC和DC端口电流与电压之间的增量被动性。", "result": "HAC方案具有增量被动性，可确保全局瞬态稳定性，且在小信号分析中仍保持被动性。", "conclusion": "HAC方案优于传统的比例下垂控制，适用于电网形成逆变器，确保稳定性。"}}
{"id": "2506.14008", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14008", "abs": "https://arxiv.org/abs/2506.14008", "authors": ["Daniel Montoya", "Aymen Bouguerra", "Alexandra Gomez-Villa", "Fabio Arnez"], "title": "FindMeIfYouCan: Bringing Open Set metrics to $\\textit{near} $, $ \\textit{far} $ and $\\textit{farther}$ Out-of-Distribution Object Detection", "comment": "Preprint", "summary": "State-of-the-art Object Detection (OD) methods predominantly operate under a closed-world assumption, where test-time categories match those encountered during training. However, detecting and localizing unknown objects is crucial for safety-critical applications in domains such as autonomous driving and medical imaging. Recently, Out-Of-Distribution (OOD) detection has emerged as a vital research direction for OD, focusing on identifying incorrect predictions typically associated with unknown objects. This paper shows that the current evaluation protocol for OOD-OD violates the assumption of non-overlapping objects with respect to the In-Distribution (ID) datasets, and obscures crucial situations such as ignoring unknown objects, potentially leading to overconfidence in deployment scenarios where truly novel objects might be encountered. To address these limitations, we manually curate, and enrich the existing benchmark by exploiting semantic similarity to create new evaluation splits categorized as $\\textit{near}$, $\\textit{far}$, and $\\textit{farther}$ from ID distributions. Additionally, we incorporate established metrics from the Open Set community, providing deeper insights into how effectively methods detect unknowns, when they ignore them, and when they mistakenly classify OOD objects as ID. Our comprehensive evaluation demonstrates that semantically and visually close OOD objects are easier to localize than far ones, but are also more easily confounded with ID objects. $\\textit{Far}$ and $\\textit{farther}$ objects are harder to localize but less prone to be taken for an ID object.", "AI": {"tldr": "本文指出当前OOD-OD评估协议的局限性，提出新的评估框架，并验证了语义和视觉接近的OOD对象更易定位但也更易混淆。", "motivation": "解决现有OOD-OD评估协议中忽略未知对象的问题，提升安全关键应用中的检测能力。", "method": "手动整理并丰富现有基准，利用语义相似性创建新的评估分类（near、far、farther），并引入开放集社区的指标。", "result": "语义和视觉接近的OOD对象更易定位但更易混淆，而far和farther对象更难定位但不易误判。", "conclusion": "新评估框架提供了更全面的OOD检测性能分析，为实际部署中的未知对象检测提供了重要参考。"}}
{"id": "2506.13842", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13842", "abs": "https://arxiv.org/abs/2506.13842", "authors": ["Yuanlong Wang", "Pengqi Wang", "Changchang Yin", "Ping Zhang"], "title": "SatHealth: A Multimodal Public Health Dataset with Satellite-based Environmental Factors", "comment": "18 pages, 6 figures. To be published in SIGKDD 2025 Datasets and Benchmarks Track", "summary": "Living environments play a vital role in the prevalence and progression of diseases, and understanding their impact on patient's health status becomes increasingly crucial for developing AI models. However, due to the lack of long-term and fine-grained spatial and temporal data in public and population health studies, most existing studies fail to incorporate environmental data, limiting the models' performance and real-world application. To address this shortage, we developed SatHealth, a novel dataset combining multimodal spatiotemporal data, including environmental data, satellite images, all-disease prevalences estimated from medical claims, and social determinants of health (SDoH) indicators. We conducted experiments under two use cases with SatHealth: regional public health modeling and personal disease risk prediction. Experimental results show that living environmental information can significantly improve AI models' performance and temporal-spatial generalizability on various tasks. Finally, we deploy a web-based application to provide an exploration tool for SatHealth and one-click access to both our data and regional environmental embedding to facilitate plug-and-play utilization. SatHealth is now published with data in Ohio, and we will keep updating SatHealth to cover the other parts of the US. With the web application and published code pipeline, our work provides valuable angles and resources to include environmental data in healthcare research and establishes a foundational framework for future research in environmental health informatics.", "AI": {"tldr": "SatHealth是一个结合多模态时空数据的新数据集，用于提升AI模型在公共卫生和个人疾病风险预测中的性能。", "motivation": "现有研究因缺乏长期和细粒度的时空数据，难以整合环境数据，限制了AI模型的性能和实际应用。", "method": "开发SatHealth数据集，整合环境数据、卫星图像、疾病流行率和社会健康决定因素，并在两个用例中进行实验。", "result": "实验表明，生活环境信息显著提高了AI模型的性能和时空泛化能力。", "conclusion": "SatHealth为医疗研究提供了环境数据整合的新角度和资源，并建立了环境健康信息学的基础框架。"}}
{"id": "2506.14039", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14039", "abs": "https://arxiv.org/abs/2506.14039", "authors": ["Ioannis Mandralis", "Richard M. Murray", "Morteza Gharib"], "title": "Quadrotor Morpho-Transition: Learning vs Model-Based Control Strategies", "comment": null, "summary": "Quadrotor Morpho-Transition, or the act of transitioning from air to ground through mid-air transformation, involves complex aerodynamic interactions and a need to operate near actuator saturation, complicating controller design. In recent work, morpho-transition has been studied from a model-based control perspective, but these approaches remain limited due to unmodeled dynamics and the requirement for planning through contacts. Here, we train an end-to-end Reinforcement Learning (RL) controller to learn a morpho-transition policy and demonstrate successful transfer to hardware. We find that the RL control policy achieves agile landing, but only transfers to hardware if motor dynamics and observation delays are taken into account. On the other hand, a baseline MPC controller transfers out-of-the-box without knowledge of the actuator dynamics and delays, at the cost of reduced recovery from disturbances in the event of unknown actuator failures. Our work opens the way for more robust control of agile in-flight quadrotor maneuvers that require mid-air transformation.", "AI": {"tldr": "论文研究了四旋翼飞行器在空中变形（从飞行到地面）的控制问题，通过强化学习（RL）训练控制器，并成功在硬件上实现。RL控制器需考虑电机动态和观测延迟，而基线MPC控制器虽无需这些信息，但对未知故障的恢复能力较弱。", "motivation": "解决四旋翼在变形过程中的复杂气动交互和接近执行器饱和状态的控制难题，传统模型方法因未建模动态和接触规划受限。", "method": "训练端到端强化学习（RL）控制器，学习变形策略，并在硬件上验证；与基线MPC控制器对比。", "result": "RL控制器实现敏捷着陆，但需考虑电机动态和延迟；MPC控制器直接可用，但对未知故障恢复能力较差。", "conclusion": "研究为需要空中变形的敏捷四旋翼控制提供了更鲁棒的方法。"}}
{"id": "2506.14376", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14376", "abs": "https://arxiv.org/abs/2506.14376", "authors": ["Massimo Chiriatti", "Marianna Bergamaschi Ganapini", "Enrico Panai", "Brenda K. Wiederhold", "Giuseppe Riva"], "title": "System 0: Transforming Artificial Intelligence into a Cognitive Extension", "comment": null, "summary": "This paper introduces System 0, a conceptual framework for understanding how artificial intelligence functions as a cognitive extension preceding both intuitive (System 1) and deliberative (System 2) thinking processes. As AI systems increasingly shape the informational substrate upon which human cognition operates, they transform from passive tools into active cognitive partners. Building on the Extended Mind hypothesis and Heersmink's criteria for cognitive extension, we argue that AI systems satisfy key conditions for cognitive integration. These include reliability, trust, transparency, individualization, and the ability to enhance and transform human mental functions. However, AI integration creates a paradox: while expanding cognitive capabilities, it may simultaneously constrain thinking through sycophancy and bias amplification. To address these challenges, we propose seven evidence-based frameworks for effective human-AI cognitive integration: Enhanced Cognitive Scaffolding, which promotes progressive autonomy; Symbiotic Division of Cognitive Labor, strategically allocating tasks based on comparative strengths; Dialectical Cognitive Enhancement, countering AI sycophancy through productive epistemic tension; Agentic Transparency and Control, ensuring users understand and direct AI influence; Expertise Democratization, breaking down knowledge silos; Social-Emotional Augmentation, addressing affective dimensions of cognitive work; and Duration-Optimized Integration, managing the evolving human-AI relationship over time. Together, these frameworks provide a comprehensive approach for harnessing AI as a genuine cognitive extension while preserving human agency, critical thinking, and intellectual growth, transforming AI from a replacement for human cognition into a catalyst for enhanced thinking.", "AI": {"tldr": "System 0框架将AI视为人类认知的扩展，提出七种框架以优化人机认知整合，同时解决偏见和依赖问题。", "motivation": "探讨AI如何从被动工具转变为主动认知伙伴，并解决其带来的认知扩展与限制的悖论。", "method": "基于扩展心智理论和Heersmink标准，提出七种证据支持的框架，如增强认知支架和辩证认知增强。", "result": "AI可作为认知扩展工具，但需通过框架管理以避免偏见和依赖，提升人类思维能力和自主性。", "conclusion": "七种框架为AI作为认知扩展提供了全面方案，强调保留人类能动性和批判性思维。"}}
{"id": "2506.14434", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.14434", "abs": "https://arxiv.org/abs/2506.14434", "authors": ["Bidisha Sharma", "Karthik Pandia Durai", "Shankar Venkatesan", "Jeena J Prakash", "Shashi Kumar", "Malolan Chetlur", "Andreas Stolcke"], "title": "Unifying Streaming and Non-streaming Zipformer-based ASR", "comment": "Accepted in ACL2025 Industry track", "summary": "There has been increasing interest in unifying streaming and non-streaming automatic speech recognition (ASR) models to reduce development, training, and deployment costs. We present a unified framework that trains a single end-to-end ASR model for both streaming and non-streaming applications, leveraging future context information. We propose to use dynamic right-context through the chunked attention masking in the training of zipformer-based ASR models. We demonstrate that using right-context is more effective in zipformer models compared to other conformer models due to its multi-scale nature. We analyze the effect of varying the number of right-context frames on accuracy and latency of the streaming ASR models. We use Librispeech and large in-house conversational datasets to train different versions of streaming and non-streaming models and evaluate them in a production grade server-client setup across diverse testsets of different domains. The proposed strategy reduces word error by relative 7.9\\% with a small degradation in user-perceived latency. By adding more right-context frames, we are able to achieve streaming performance close to that of non-streaming models. Our approach also allows flexible control of the latency-accuracy tradeoff according to customers requirements.", "AI": {"tldr": "提出了一种统一的流式和非流式ASR模型框架，通过动态右上下文和分块注意力掩码训练，显著降低开发成本并提升性能。", "motivation": "减少流式和非流式ASR模型的开发、训练和部署成本，同时提升性能。", "method": "使用动态右上下文和分块注意力掩码训练zipformer模型，分析右上下文帧数对精度和延迟的影响。", "result": "在Librispeech和内部数据集上测试，词错误率相对降低7.9%，流式性能接近非流式模型。", "conclusion": "该方法在性能和延迟间实现灵活权衡，满足客户需求。"}}
{"id": "2506.14572", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14572", "abs": "https://arxiv.org/abs/2506.14572", "authors": ["Ondřej Skalský", "Jakub Dokoupil"], "title": "Bayesian Knowledge Transfer for a Kalman Fixed-Lag Interval Smoother", "comment": "6 pages, 1 figure. Accepted for publication in IEEE Control Systems Letters. To be presented at the IEEE 64th Conference on Decision and Control", "summary": "A Bayesian knowledge transfer mechanism that leverages external information to improve the performance of the Kalman fixed-lag interval smoother (FLIS) is proposed. Exact knowledge of the external observation model is assumed to be missing, which hinders the direct application of Bayes' rule in traditional transfer learning approaches. This limitation is overcome by the fully probabilistic design, conditioning the targeted task of state estimation on external information. To mitigate the negative impact of inaccurate external data while leveraging precise information, a latent variable is introduced. Favorably, in contrast to a filter, FLIS retrospectively refines past decisions up to a fixed time horizon, reducing the accumulation of estimation error and consequently improving the performance of state inference. Simulations indicate that the proposed algorithm better exploits precise external knowledge compared to a similar technique and achieves comparable results when the information is imprecise.", "AI": {"tldr": "提出了一种贝叶斯知识转移机制，利用外部信息提升卡尔曼固定滞后区间平滑器（FLIS）的性能。", "motivation": "传统转移学习方法因缺乏外部观测模型的精确知识而无法直接应用贝叶斯规则，限制了性能提升。", "method": "采用完全概率设计，将状态估计任务条件化于外部信息，并引入潜在变量以减少不准确外部数据的负面影响。", "result": "仿真表明，该算法能更有效地利用精确外部知识，并在信息不精确时取得可比结果。", "conclusion": "该机制通过FLIS的回顾性修正能力，减少了估计误差累积，提升了状态推断性能。"}}
{"id": "2506.14015", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14015", "abs": "https://arxiv.org/abs/2506.14015", "authors": ["Nick Yiwen Huang", "Akin Caliskan", "Berkay Kicanaoglu", "James Tompkin", "Hyeongwoo Kim"], "title": "Disentangling 3D from Large Vision-Language Models for Controlled Portrait Generation", "comment": null, "summary": "We consider the problem of disentangling 3D from large vision-language models, which we show on generative 3D portraits. This allows free-form text control of appearance attributes like age, hair style, and glasses, and 3D geometry control of face expression and camera pose. In this setting, we assume we use a pre-trained large vision-language model (LVLM; CLIP) to generate from a smaller 2D dataset with no additional paired labels and with a pre-defined 3D morphable model (FLAME). First, we disentangle using canonicalization to a 2D reference frame from a deformable neural 3D triplane representation. But another form of entanglement arises from the significant noise in the LVLM's embedding space that describes irrelevant features. This damages output quality and diversity, but we overcome this with a Jacobian regularization that can be computed efficiently with a stochastic approximator. Compared to existing methods, our approach produces portraits with added text and 3D control, where portraits remain consistent when either control is changed. Broadly, this approach lets creators control 3D generators on their own 2D face data without needing resources to label large data or train large models.", "AI": {"tldr": "论文提出了一种从大型视觉语言模型（LVLM）中解耦3D信息的方法，用于生成可控的3D肖像。通过规范化和Jacobian正则化，实现了对文本和3D几何的自由控制。", "motivation": "解决从预训练的大型视觉语言模型中解耦3D信息的挑战，以实现对肖像外观和几何的自由控制。", "method": "使用规范化解耦2D参考帧和3D triplane表示，并通过Jacobian正则化处理LVLM嵌入空间中的噪声。", "result": "生成的肖像在文本和3D控制下保持一致性，且无需额外标注或训练大型模型。", "conclusion": "该方法为创作者提供了在2D数据上控制3D生成的能力，无需大量资源。"}}
{"id": "2506.13862", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13862", "abs": "https://arxiv.org/abs/2506.13862", "authors": ["Alena Shilova", "Alex Davey", "Brahim Driss", "Riad Akrour"], "title": "StaQ it! Growing neural networks for Policy Mirror Descent", "comment": "44 pages, 12 figures", "summary": "In Reinforcement Learning (RL), regularization has emerged as a popular tool both in theory and practice, typically based either on an entropy bonus or a Kullback-Leibler divergence that constrains successive policies. In practice, these approaches have been shown to improve exploration, robustness and stability, giving rise to popular Deep RL algorithms such as SAC and TRPO. Policy Mirror Descent (PMD) is a theoretical framework that solves this general regularized policy optimization problem, however the closed-form solution involves the sum of all past Q-functions, which is intractable in practice. We propose and analyze PMD-like algorithms that only keep the last $M$ Q-functions in memory, and show that for finite and large enough $M$, a convergent algorithm can be derived, introducing no error in the policy update, unlike prior deep RL PMD implementations. StaQ, the resulting algorithm, enjoys strong theoretical guarantees and is competitive with deep RL baselines, while exhibiting less performance oscillation, paving the way for fully stable deep RL algorithms and providing a testbed for experimentation with Policy Mirror Descent.", "AI": {"tldr": "论文提出了一种改进的Policy Mirror Descent（PMD）算法StaQ，通过仅保留最近的M个Q函数，解决了传统PMD中存储所有历史Q函数的难题，同时保持了收敛性和稳定性。", "motivation": "在强化学习中，正则化方法（如熵奖励或KL散度）被广泛用于提升探索性和稳定性，但传统PMD框架因需存储所有历史Q函数而难以实际应用。", "method": "提出了一种PMD变体算法StaQ，仅保留最近的M个Q函数，证明在M足够大时仍能收敛且无策略更新误差。", "result": "StaQ在理论上有强保证，实际表现与深度强化学习基线相当，且性能波动更小。", "conclusion": "StaQ为完全稳定的深度强化学习算法提供了新思路，并为PMD的实验研究奠定了基础。"}}
{"id": "2506.14066", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14066", "abs": "https://arxiv.org/abs/2506.14066", "authors": ["Ali Abouzeid", "Malak Mansour", "Chengsong Hu", "Dezhen Song"], "title": "A Point Cloud Completion Approach for the Grasping of Partially Occluded Objects and Its Applications in Robotic Strawberry Harvesting", "comment": null, "summary": "In robotic fruit picking applications, managing object occlusion in unstructured settings poses a substantial challenge for designing grasping algorithms. Using strawberry harvesting as a case study, we present an end-to-end framework for effective object detection, segmentation, and grasp planning to tackle this issue caused by partially occluded objects. Our strategy begins with point cloud denoising and segmentation to accurately locate fruits. To compensate for incomplete scans due to occlusion, we apply a point cloud completion model to create a dense 3D reconstruction of the strawberries. The target selection focuses on ripe strawberries while categorizing others as obstacles, followed by converting the refined point cloud into an occupancy map for collision-aware motion planning. Our experimental results demonstrate high shape reconstruction accuracy, with the lowest Chamfer Distance compared to state-of-the-art methods with 1.10 mm, and significantly improved grasp success rates of 79.17%, yielding an overall success-to-attempt ratio of 89.58\\% in real-world strawberry harvesting. Additionally, our method reduces the obstacle hit rate from 43.33% to 13.95%, highlighting its effectiveness in improving both grasp quality and safety compared to prior approaches. This pipeline substantially improves autonomous strawberry harvesting, advancing more efficient and reliable robotic fruit picking systems.", "AI": {"tldr": "论文提出了一种端到端的框架，用于解决草莓采摘中因遮挡导致的目标检测、分割和抓取规划问题，通过点云去噪、补全和碰撞感知运动规划，显著提高了抓取成功率和安全性。", "motivation": "在非结构化环境中，物体遮挡是机器人水果采摘中的主要挑战，尤其是在草莓采摘中，部分遮挡会影响目标检测和抓取规划的效果。", "method": "方法包括点云去噪与分割、点云补全模型生成密集3D重建、目标选择（成熟草莓）和碰撞感知运动规划。", "result": "实验结果显示，形状重建精度高（Chamfer Distance为1.10 mm），抓取成功率达79.17%，障碍物碰撞率从43.33%降至13.95%。", "conclusion": "该框架显著提升了草莓采摘的自主性，为高效可靠的机器人水果采摘系统提供了新思路。"}}
{"id": "2506.14468", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14468", "abs": "https://arxiv.org/abs/2506.14468", "authors": ["Xinglong Mao", "Shifeng Liu", "Sirui Zhao", "Tong Xu", "Enhong Chen"], "title": "MERba: Multi-Receptive Field MambaVision for Micro-Expression Recognition", "comment": null, "summary": "Micro-expressions (MEs) are brief, involuntary facial movements that reveal genuine emotions, holding significant potential in psychological diagnosis and criminal investigations. Despite notable advances in automatic ME recognition (MER), existing methods still struggle to jointly capture localized muscle activations and global facial dependencies, both critical for recognizing subtle emotional cues. To tackle this challenge, we propose MERba, a novel multi-receptive field architecture tailored for MER. MERba introduces a series of Local-Global Feature Integration stages, where fine-grained motion features are first extracted by local extractors containing MambaVision Mixers within non-overlapping windows, and then global dependencies across these regions are modeled via lightweight self-attention layers. This hierarchical design enables a progressive transition from localized perception to holistic facial understanding. Furthermore, we introduce an asymmetric multi-scanning strategy to eliminate redundant scanning directions and enhance local spatial perception. To address the high inter-class similarity among negative MEs, we introduce a Dual-Granularity Classification Module that decouples the recognition process into a coarse-to-fine paradigm. Experiments on two benchmark MER datasets demonstrate that MERba outperforms existing methods, with ablation studies confirming the effectiveness of each proposed component.", "AI": {"tldr": "MERba是一种新的多感受野架构，用于微表情识别（MER），通过局部-全局特征整合和双粒度分类模块，显著提升了识别性能。", "motivation": "现有方法难以同时捕捉局部肌肉激活和全局面部依赖关系，而这对识别微表情至关重要。", "method": "提出MERba架构，结合局部提取器和全局自注意力层，并引入非对称多扫描策略和双粒度分类模块。", "result": "在两个基准MER数据集上，MERba表现优于现有方法，消融实验验证了各组件的有效性。", "conclusion": "MERba通过局部-全局特征整合和双粒度分类，显著提升了微表情识别的性能。"}}
{"id": "2506.14503", "categories": ["cs.SD", "cs.DL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.14503", "abs": "https://arxiv.org/abs/2506.14503", "authors": ["Baris Bozkurt"], "title": "An Open Research Dataset of the 1932 Cairo Congress of Arab Music", "comment": "14 pages, 4 figures, 4 tables", "summary": "This paper introduces ORD-CC32 , an open research dataset derived from the 1932 Cairo Congress of Arab Music recordings, a historically significant collection representing diverse Arab musical traditions. The dataset includes structured metadata, melodic and rhythmic mode tags (maqam and iqa), manually labeled tonic information, and acoustic features extracted using state-of-the-art pitch detection methods. These resources support computational studies of tuning, temperament, and regional variations in Arab music. A case study using pitch histograms demonstrates the potential for data-driven analysis of microtonal differences across regions. By making this dataset openly available, we aim to enable interdisciplinary research in computational ethnomusicology, music information retrieval (MIR), cultural studies, and digital heritage preservation. ORD-CC32 is shared on Zenodo with tools for feature extraction and metadata retrieval.", "AI": {"tldr": "ORD-CC32是一个基于1932年开罗阿拉伯音乐大会录音的开放研究数据集，包含结构化元数据、旋律和节奏模式标签、手动标注的主音信息以及声学特征，支持阿拉伯音乐的计算研究。", "motivation": "通过开放数据集促进计算民族音乐学、音乐信息检索、文化研究和数字遗产保护等跨学科研究。", "method": "数据集包括手动标注和声学特征提取，使用先进的音高检测方法，并通过案例研究展示区域微音差异分析。", "result": "数据集支持阿拉伯音乐调音、律制和区域差异的计算研究，并提供了工具和资源。", "conclusion": "ORD-CC32的开放共享为跨学科研究提供了重要资源，推动了阿拉伯音乐的计算分析和文化保护。"}}
{"id": "2506.14581", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14581", "abs": "https://arxiv.org/abs/2506.14581", "authors": ["Pauline Blohm", "Felix Schulz", "Lisa Willemsen", "Anne Remke", "Paula Herber"], "title": "Modeling Uncertainty: From Simulink to Stochastic Hybrid Automata", "comment": null, "summary": "Simulink is widely used in industrial design processes to model increasingly complex embedded control systems. Thus, their formal analysis is highly desirable. However, this comes with two major challenges: First, Simulink models often provide an idealized view of real-life systems and omit uncertainties such as, aging, sensor noise or failures. Second, the semantics of Simulink is only informally defined. In this paper, we present an approach to formally analyze safety and performance of embedded control systems modeled in Simulink in the presence of uncertainty. To achieve this, we 1) model different types of uncertainties as stochastic Simulink subsystems and 2) extend an existing formalization of the Simulink semantics based on stochastic hybrid automata (SHA) by providing transformation rules for the stochastic subsystems. Our approach gives us access to established quantitative analysis techniques, like statistical model checking and reachability analysis. We demonstrate the applicability of our approach by analyzing safety and performance in the presence of uncertainty for two smaller case studies.", "AI": {"tldr": "本文提出了一种方法，用于在存在不确定性的情况下对Simulink建模的嵌入式控制系统进行形式化分析。", "motivation": "Simulink模型通常忽略现实系统中的不确定性（如老化、传感器噪声或故障），且其语义缺乏形式化定义，因此需要一种方法来分析其安全性和性能。", "method": "1) 将不同类型的不确定性建模为随机Simulink子系统；2) 基于随机混合自动机（SHA）扩展Simulink语义的形式化定义，并提供随机子系统的转换规则。", "result": "通过两个小型案例研究，展示了该方法在不确定条件下分析安全性和性能的适用性。", "conclusion": "该方法为Simulink模型提供了形式化分析工具，支持统计模型检查和可达性分析等定量分析技术。"}}
{"id": "2506.14035", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14035", "abs": "https://arxiv.org/abs/2506.14035", "authors": ["Chelsi Jain", "Yiran Wu", "Yifan Zeng", "Jiale Liu", "S hengyu Dai", "Zhenwen Shao", "Qingyun Wu", "Huazheng Wang"], "title": "SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval and Iterative Refinement", "comment": null, "summary": "Document Visual Question Answering (DocVQA) is a practical yet challenging task, which is to ask questions based on documents while referring to multiple pages and different modalities of information, e.g, images and tables. To handle multi-modality, recent methods follow a similar Retrieval Augmented Generation (RAG) pipeline, but utilize Visual Language Models (VLMs) based embedding model to embed and retrieve relevant pages as images, and generate answers with VLMs that can accept an image as input. In this paper, we introduce SimpleDoc, a lightweight yet powerful retrieval - augmented framework for DocVQA. It boosts evidence page gathering by first retrieving candidates through embedding similarity and then filtering and re-ranking these candidates based on page summaries. A single VLM-based reasoner agent repeatedly invokes this dual-cue retriever, iteratively pulling fresh pages into a working memory until the question is confidently answered. SimpleDoc outperforms previous baselines by 3.2% on average on 4 DocVQA datasets with much fewer pages retrieved. Our code is available at https://github.com/ag2ai/SimpleDoc.", "AI": {"tldr": "SimpleDoc是一个轻量级但强大的检索增强框架，用于文档视觉问答（DocVQA），通过双线索检索和迭代工作记忆机制提升性能。", "motivation": "DocVQA任务需要处理多页和多模态信息，现有方法虽然使用视觉语言模型（VLM）进行检索和生成，但仍需优化检索效率和准确性。", "method": "SimpleDoc采用双线索检索机制：先通过嵌入相似性检索候选页面，再基于页面摘要过滤和重新排序。通过迭代调用检索器和VLM推理器逐步回答问题。", "result": "SimpleDoc在4个DocVQA数据集上平均性能提升3.2%，且检索页面数量显著减少。", "conclusion": "SimpleDoc通过高效检索和迭代推理机制，显著提升了DocVQA任务的性能，同时减少了计算开销。"}}
{"id": "2506.13892", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.13892", "abs": "https://arxiv.org/abs/2506.13892", "authors": ["Samuel Beaussant", "Mehdi Mounsif"], "title": "Scaling Algorithm Distillation for Continuous Control with Mamba", "comment": null, "summary": "Algorithm Distillation (AD) was recently proposed as a new approach to perform In-Context Reinforcement Learning (ICRL) by modeling across-episodic training histories autoregressively with a causal transformer model. However, due to practical limitations induced by the attention mechanism, experiments were bottlenecked by the transformer's quadratic complexity and limited to simple discrete environments with short time horizons. In this work, we propose leveraging the recently proposed Selective Structured State Space Sequence (S6) models, which achieved state-of-the-art (SOTA) performance on long-range sequence modeling while scaling linearly in sequence length. Through four complex and continuous Meta Reinforcement Learning environments, we demonstrate the overall superiority of Mamba, a model built with S6 layers, over a transformer model for AD. Additionally, we show that scaling AD to very long contexts can improve ICRL performance and make it competitive even with a SOTA online meta RL baseline.", "AI": {"tldr": "论文提出使用S6模型（Mamba）替代传统Transformer，以解决算法蒸馏（AD）在长序列任务中的性能瓶颈，并在复杂连续环境中验证其优越性。", "motivation": "传统Transformer在算法蒸馏中因二次复杂度受限，无法处理长序列任务。", "method": "采用S6模型（Mamba），其线性复杂度适合长序列建模，并在四个复杂连续Meta RL环境中测试。", "result": "Mamba在AD中表现优于Transformer，且长上下文扩展能提升ICRL性能，甚至媲美SOTA在线元RL基线。", "conclusion": "S6模型为AD提供了高效的长序列处理能力，显著提升了ICRL性能。"}}
{"id": "2506.14097", "categories": ["cs.RO", "cond-mat.soft", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2506.14097", "abs": "https://arxiv.org/abs/2506.14097", "authors": ["Bryce Palmer", "Hasan Metin Aktulga", "Tong Gao"], "title": "ReLCP: Scalable Complementarity-Based Collision Resolution for Smooth Rigid Bodies", "comment": null, "summary": "We present a complementarity-based collision resolution algorithm for smooth, non-spherical, rigid bodies. Unlike discrete surface representation approaches, which approximate surfaces using discrete elements (e.g., tessellations or sub-spheres) with constraints between nearby faces, edges, nodes, or sub-objects, our algorithm solves a recursively generated linear complementarity problem (ReLCP) to adaptively identify potential collision locations during the collision resolution procedure. Despite adaptively and in contrast to Newton-esque schemes, we prove conditions under which the resulting solution exists and the center of mass translational and rotational dynamics are unique. Our ReLCP also converges to classical LCP-based collision resolution for sufficiently small timesteps. Because increasing the surface resolution in discrete representation methods necessitates subdividing geometry into finer elements -- leading to a super-linear increase in the number of collision constraints -- these approaches scale poorly with increased surface resolution. In contrast, our adaptive ReLCP framework begins with a single constraint per pair of nearby bodies and introduces new constraints only when unconstrained motion would lead to overlap, circumventing the oversampling required by discrete methods. By requiring one to two orders of magnitude fewer collision constraints to achieve the same surface resolution, we observe 10-100x speedup in densely packed applications. We validate our ReLCP method against multisphere and single-constraint methods, comparing convergence in a two-ellipsoid collision test, scalability and performance in a compacting ellipsoid suspension and growing bacterial colony, and stability in a taut chainmail network, highlighting our ability to achieve high-fidelity surface representations without suffering from poor scalability or artificial surface roughness.", "AI": {"tldr": "提出了一种基于互补性的碰撞解决算法，适用于光滑非球形刚体，通过递归生成的线性互补问题（ReLCP）自适应识别碰撞位置，显著提升计算效率。", "motivation": "传统离散表面表示方法因需细分几何体导致约束数量超线性增长，难以应对高分辨率需求，因此需要一种更高效的方法。", "method": "采用递归生成的线性互补问题（ReLCP）自适应识别碰撞位置，避免离散方法的过采样问题。", "result": "在相同表面分辨率下，所需碰撞约束数量减少1-2个数量级，计算速度提升10-100倍。", "conclusion": "ReLCP框架在保持高保真表面表示的同时，解决了传统方法的扩展性和表面粗糙问题。"}}
{"id": "2506.14476", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14476", "abs": "https://arxiv.org/abs/2506.14476", "authors": ["Ziyue Lin", "Yi Shan", "Lin Gao", "Xinghua Jia", "Siming Chen"], "title": "SimSpark: Interactive Simulation of Social Media Behaviors", "comment": "32 pages, 7 figures", "summary": "Understanding user behaviors on social media has garnered significant scholarly attention, enhancing our comprehension of how virtual platforms impact society and empowering decision-makers. Simulating social media behaviors provides a robust tool for capturing the patterns of social media behaviors, testing hypotheses, and predicting the effects of various interventions, ultimately contributing to a deeper understanding of social media environments. Moreover, it can overcome difficulties associated with utilizing real data for analysis, such as data accessibility issues, ethical concerns, and the complexity of processing large and heterogeneous datasets. However, researchers and stakeholders need more flexible platforms to investigate different user behaviors by simulating different scenarios and characters, which is not possible yet. Therefore, this paper introduces SimSpark, an interactive system including simulation algorithms and interactive visual interfaces which is capable of creating small simulated social media platforms with customizable characters and social environments. We address three key challenges: generating believable behaviors, validating simulation results, and supporting interactive control for generation and results analysis. A simulation workflow is introduced to generate believable behaviors of agents by utilizing large language models. A visual interface enables real-time parameter adjustment and process monitoring for customizing generation settings. A set of visualizations and interactions are also designed to display the models' outputs for further analysis. Effectiveness is evaluated through case studies, quantitative simulation model assessments, and expert interviews.", "AI": {"tldr": "本文介绍了SimSpark，一个交互式系统，用于模拟社交媒体行为，通过定制化角色和环境解决生成可信行为、验证结果和交互控制等挑战。", "motivation": "研究社交媒体行为模拟的需求源于对虚拟平台影响社会的理解需求，以及解决真实数据分析中的困难（如数据可访问性、伦理问题）。", "method": "提出SimSpark系统，结合模拟算法和交互式可视化界面，利用大语言模型生成可信行为，并通过可视化工具支持实时调整和分析。", "result": "通过案例研究、定量评估和专家访谈验证了系统的有效性。", "conclusion": "SimSpark为研究人员和利益相关者提供了一个灵活的平台，用于模拟和分析社交媒体行为。"}}
{"id": "2506.14504", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2506.14504", "abs": "https://arxiv.org/abs/2506.14504", "authors": ["Emmanuel Deruty"], "title": "Evolving music theory for emerging musical languages", "comment": "In Music 2025, Innovation in Music Conference. 20-22 June, 2025, Bath Spa University, Bath, UK", "summary": "This chapter reconsiders the concept of pitch in contemporary popular music (CPM), particularly in electronic contexts where traditional assumptions may fail. Drawing on phenomenological and inductive methods, it argues that pitch is not an ontologically objective property but a perceptual construct shaped by listeners and conditions. Analyses of quasi-harmonic tones reveal that a single tone can convey multiple pitches, giving rise to tonal fission. The perception of pitch may also be multistable, varying for the same listener over time. In this framework, the tuning system may emerge from a tone's internal structure. A parallel with the coastline paradox supports a model of pitch grounded in perceptual variability, challenging inherited theoretical norms.", "AI": {"tldr": "本文重新探讨了当代流行音乐（CPM）中的音高概念，特别是在电子音乐中传统假设可能失效的背景下。通过现象学和归纳方法，提出音高并非本体论上的客观属性，而是由听众和条件塑造的感知构造。", "motivation": "传统音高理论在电子音乐等现代音乐形式中可能不适用，因此需要重新思考音高的本质及其感知方式。", "method": "采用现象学和归纳方法，分析准谐波音调，探讨音高的多义性和感知的多稳定性。", "result": "研究发现，单个音调可以传达多个音高，导致音调分裂；音高感知可能随时间变化，调音系统可能源于音调的内部结构。", "conclusion": "音高应被视为基于感知可变性的模型，挑战了传统理论的规范。"}}
{"id": "2506.14662", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14662", "abs": "https://arxiv.org/abs/2506.14662", "authors": ["Young-ho Cho", "Min-Seung Ko", "Hao Zhu"], "title": "PGLib-CO2: A Power Grid Library for Computing and Optimizing Carbon Emissions", "comment": null, "summary": "A sustainable electricity infrastructure requires the explicit integration of carbon emissions into power system modeling and optimization paradigms. However, existing open-source datasets for power system R&D lack generator-level carbon emission profiling, limiting the ability to benchmark and compare various carbon-aware grid operational strategies. To address this gap, this work introduces PGLib-CO2, an open-source extension to the widely adopted PGLib-OPF test case library. PGLib-CO2 enriches standard network cases with CO2 and CO2-equivalent emission intensity factors by expanding the fuel-type categorization used by PGLib-OPF, attaining a realistic generator-level carbon profiling. It is also packaged for both Python's pandapower and Julia's PowerModels.jl, for a seamless, user-friendly integration of emission modeling into grid computation and optimization tasks. The dataset produced by PGLib-CO2 can support grid-based carbon accounting, emission metric evaluation, and integration into AC optimal power flow (OPF) and optimal load shifting (OLS) formulations. We demonstrate PGLib-CO2's utility through case studies that quantify cost-emission trade-offs and optimize a carbon-aware objective function. By standardizing carbon-enhanced test cases, PGLib-CO2 provides an open-source, reproducible foundation for benchmarking carbon-aware computation, facilitating future research in sustainable power system operation.", "AI": {"tldr": "PGLib-CO2是一个开源扩展库，为PGLib-OPF测试案例库添加了发电机级碳排放数据，支持碳感知电网操作的基准测试和研究。", "motivation": "现有开源数据集缺乏发电机级碳排放数据，限制了碳感知电网策略的评估和比较。", "method": "通过扩展PGLib-OPF的燃料类型分类，PGLib-CO2为网络案例添加了CO2和CO2当量排放强度因子，并支持Python和Julia的无缝集成。", "result": "PGLib-CO2支持电网碳核算、排放指标评估，并可用于优化任务，如AC最优潮流和最优负荷转移。", "conclusion": "PGLib-CO2为碳感知计算提供了标准化、可复现的基础，推动了可持续电力系统操作的未来研究。"}}
{"id": "2506.14096", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14096", "abs": "https://arxiv.org/abs/2506.14096", "authors": ["Sanjeda Akter", "Ibne Farabi Shihab", "Anuj Sharma"], "title": "Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems", "comment": null, "summary": "The integration of Large Language Models (LLMs) with computer vision is profoundly transforming perception tasks like image segmentation. For intelligent transportation systems (ITS), where accurate scene understanding is critical for safety and efficiency, this new paradigm offers unprecedented capabilities. This survey systematically reviews the emerging field of LLM-augmented image segmentation, focusing on its applications, challenges, and future directions within ITS. We provide a taxonomy of current approaches based on their prompting mechanisms and core architectures, and we highlight how these innovations can enhance road scene understanding for autonomous driving, traffic monitoring, and infrastructure maintenance. Finally, we identify key challenges, including real-time performance and safety-critical reliability, and outline a perspective centered on explainable, human-centric AI as a prerequisite for the successful deployment of this technology in next-generation transportation systems.", "AI": {"tldr": "综述探讨了LLM与计算机视觉结合在图像分割中的新兴领域，特别关注智能交通系统中的应用、挑战和未来方向。", "motivation": "智能交通系统需要精确的场景理解以确保安全和效率，LLM增强的图像分割为此提供了新能力。", "method": "系统回顾了LLM增强图像分割的方法，基于提示机制和核心架构对现有方法进行了分类。", "result": "这些创新可提升自动驾驶、交通监控和基础设施维护中的道路场景理解。", "conclusion": "关键挑战包括实时性能和安全性可靠性，未来需发展可解释、以人为本的AI技术。"}}
{"id": "2506.13903", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13903", "abs": "https://arxiv.org/abs/2506.13903", "authors": ["Christel Sirocchi", "Damiano Verda"], "title": "Enhancing interpretability of rule-based classifiers through feature graphs", "comment": null, "summary": "In domains where transparency and trustworthiness are crucial, such as healthcare, rule-based systems are widely used and often preferred over black-box models for decision support systems due to their inherent interpretability. However, as rule-based models grow complex, discerning crucial features, understanding their interactions, and comparing feature contributions across different rule sets becomes challenging. To address this, we propose a comprehensive framework for estimating feature contributions in rule-based systems, introducing a graph-based feature visualisation strategy, a novel feature importance metric agnostic to rule-based predictors, and a distance metric for comparing rule sets based on feature contributions. By experimenting on two clinical datasets and four rule-based methods (decision trees, logic learning machines, association rules, and neural networks with rule extraction), we showcase our method's capability to uncover novel insights on the combined predictive value of clinical features, both at the dataset and class-specific levels. These insights can aid in identifying new risk factors, signature genes, and potential biomarkers, and determining the subset of patient information that should be prioritised to enhance diagnostic accuracy. Comparative analysis of the proposed feature importance score with state-of-the-art methods on 15 public benchmarks demonstrates competitive performance and superior robustness. The method implementation is available on GitHub: https://github.com/ChristelSirocchi/rule-graph.", "AI": {"tldr": "提出了一种用于规则基系统的特征贡献分析框架，包括可视化、重要性度量和规则集比较方法，并在临床数据上验证了其有效性。", "motivation": "在需要透明性和可信度的领域（如医疗），规则基系统因其可解释性被广泛使用，但复杂规则下的特征分析和比较仍具挑战性。", "method": "提出图基特征可视化策略、特征重要性度量及规则集距离度量，并在临床数据集和四种规则基方法上实验验证。", "result": "方法能揭示临床特征的预测价值，识别新风险因素和生物标志物，并在15个公共基准测试中表现优异。", "conclusion": "该框架为规则基系统提供了有效的特征分析工具，有助于提升诊断准确性。"}}
{"id": "2506.14100", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14100", "abs": "https://arxiv.org/abs/2506.14100", "authors": ["Yupeng Zhou", "Can Cui", "Juntong Peng", "Zichong Yang", "Juanwu Lu", "Jitesh H Panchal", "Bin Yao", "Ziran Wang"], "title": "A Hierarchical Test Platform for Vision Language Model (VLM)-Integrated Real-World Autonomous Driving", "comment": null, "summary": "Vision-Language Models (VLMs) have demonstrated notable promise in autonomous driving by offering the potential for multimodal reasoning through pretraining on extensive image-text pairs. However, adapting these models from broad web-scale data to the safety-critical context of driving presents a significant challenge, commonly referred to as domain shift. Existing simulation-based and dataset-driven evaluation methods, although valuable, often fail to capture the full complexity of real-world scenarios and cannot easily accommodate repeatable closed-loop testing with flexible scenario manipulation. In this paper, we introduce a hierarchical real-world test platform specifically designed to evaluate VLM-integrated autonomous driving systems. Our approach includes a modular, low-latency on-vehicle middleware that allows seamless incorporation of various VLMs, a clearly separated perception-planning-control architecture that can accommodate both VLM-based and conventional modules, and a configurable suite of real-world testing scenarios on a closed track that facilitates controlled yet authentic evaluations. We demonstrate the effectiveness of the proposed platform`s testing and evaluation ability with a case study involving a VLM-enabled autonomous vehicle, highlighting how our test framework supports robust experimentation under diverse conditions.", "AI": {"tldr": "本文介绍了一种专为评估视觉语言模型（VLM）集成的自动驾驶系统设计的层次化真实世界测试平台，解决了现有方法在复杂性和可重复性上的不足。", "motivation": "适应视觉语言模型（VLMs）从广泛网络数据到安全关键的驾驶环境存在领域转移的挑战，现有评估方法难以捕捉真实场景的复杂性或支持灵活的闭环测试。", "method": "提出了一种模块化、低延迟的车载中间件，支持多种VLM的无缝集成，以及一个可配置的真实世界测试场景套件，用于可控且真实的评估。", "result": "通过案例研究展示了平台在多样化条件下支持稳健实验的能力，验证了其测试和评估效果。", "conclusion": "该测试平台为VLM集成的自动驾驶系统提供了有效的评估框架，解决了领域转移和测试复杂性等问题。"}}
{"id": "2506.14567", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14567", "abs": "https://arxiv.org/abs/2506.14567", "authors": ["Emanuel Moss", "Elizabeth Watkins", "Christopher Persaud", "Passant Karunaratne", "Dawn Nafus"], "title": "Controlling Context: Generative AI at Work in Integrated Circuit Design and Other High-Precision Domains", "comment": null, "summary": "Generative AI tools have become more prevalent in engineering workflows, particularly through chatbots and code assistants. As the perceived accuracy of these tools improves, questions arise about whether and how those who work in high-precision domains might maintain vigilance for errors, and what other aspects of using such tools might trouble their work. This paper analyzes interviews with hardware and software engineers, and their collaborators, who work in integrated circuit design to identify the role accuracy plays in their use of generative AI tools and what other forms of trouble they face in using such tools. The paper inventories these forms of trouble, which are then mapped to elements of generative AI systems, to conclude that controlling the context of interactions between engineers and the generative AI tools is one of the largest challenges they face. The paper concludes with recommendations for mitigating this form of trouble by increasing the ability to control context interactively.", "AI": {"tldr": "论文探讨了生成式AI工具在工程工作流程中的使用，重点关注高精度领域（如集成电路设计）中工程师面临的准确性问题及其他困扰。", "motivation": "随着生成式AI工具的普及和准确性提升，研究高精度领域工程师如何保持对错误的警惕性以及使用这些工具时可能遇到的问题。", "method": "通过访谈硬件和软件工程师及其合作者，分析他们在集成电路设计中使用生成式AI工具时的体验和困扰。", "result": "研究发现，控制工程师与生成式AI工具交互的上下文是主要挑战之一，并列举了其他困扰形式。", "conclusion": "建议通过增强交互式上下文控制能力来缓解这些困扰。"}}
{"id": "2506.14684", "categories": ["cs.SD", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.14684", "abs": "https://arxiv.org/abs/2506.14684", "authors": ["Aditya Bhattacharjee", "Ivan Meresman Higgs", "Mark Sandler", "Emmanouil Benetos"], "title": "Refining music sample identification with a self-supervised graph neural network", "comment": "Accepted at International Conference for Music Information Retrieval (ISMIR) 2025", "summary": "Automatic sample identification (ASID), the detection and identification of portions of audio recordings that have been reused in new musical works, is an essential but challenging task in the field of audio query-based retrieval. While a related task, audio fingerprinting, has made significant progress in accurately retrieving musical content under \"real world\" (noisy, reverberant) conditions, ASID systems struggle to identify samples that have undergone musical modifications. Thus, a system robust to common music production transformations such as time-stretching, pitch-shifting, effects processing, and underlying or overlaying music is an important open challenge.\n  In this work, we propose a lightweight and scalable encoding architecture employing a Graph Neural Network within a contrastive learning framework. Our model uses only 9% of the trainable parameters compared to the current state-of-the-art system while achieving comparable performance, reaching a mean average precision (mAP) of 44.2%.\n  To enhance retrieval quality, we introduce a two-stage approach consisting of an initial coarse similarity search for candidate selection, followed by a cross-attention classifier that rejects irrelevant matches and refines the ranking of retrieved candidates - an essential capability absent in prior models. In addition, because queries in real-world applications are often short in duration, we benchmark our system for short queries using new fine-grained annotations for the Sample100 dataset, which we publish as part of this work.", "AI": {"tldr": "论文提出了一种轻量级、可扩展的编码架构，结合图神经网络和对比学习框架，用于自动样本识别（ASID），在参数减少91%的情况下性能接近当前最优模型。", "motivation": "当前ASID系统难以处理音乐样本经过常见音乐制作变换（如时间拉伸、音高变换等）的情况，亟需一种鲁棒性强的解决方案。", "method": "采用图神经网络和对比学习框架，设计了两阶段检索方法：粗粒度相似性搜索和交叉注意力分类器。", "result": "模型仅使用9%的可训练参数，达到44.2%的平均精度（mAP），并在短时查询任务中表现优异。", "conclusion": "提出的方法在性能和效率上均有显著提升，同时发布了新的细粒度标注数据集Sample100。"}}
{"id": "2506.14749", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14749", "abs": "https://arxiv.org/abs/2506.14749", "authors": ["Shiyu Cheng", "Luyao Niu", "Bhaskar Ramasubramanian", "Andrew Clark", "Radha Poovendran"], "title": "Swarm-STL: A Framework for Motion Planning in Large-Scale, Multi-Swarm Systems", "comment": null, "summary": "In multi-agent systems, signal temporal logic (STL) is widely used for path planning to accomplish complex objectives with formal safety guarantees. However, as the number of agents increases, existing approaches encounter significant computational challenges. Recognizing that many complex tasks require cooperation among multiple agents, we propose swarm STL specifications to describe the collective tasks that need to be achieved by a team of agents. Next, we address the motion planning problem for all the agents in two stages. First, we abstract a group of cooperating agents as a swarm and construct a reduced-dimension state space whose dimension does not increase with the number of agents. The path planning is performed at the swarm level, ensuring the safety and swarm STL specifications are satisfied. Then, we design low-level control strategies for agents within each swarm based on the path synthesized in the first step. The trajectories of agents generated by the two-step policy ensure satisfaction of the STL specifications. We evaluate our two-stage approach in both single-swarm and multi-swarm scenarios. The results demonstrate that all tasks are completed with safety guarantees. Compared to the baseline multi-agent planning approach, our method maintains computational efficiency as the number of agents increases, since the computational time scales with the number of swarms rather than the number of agents.", "AI": {"tldr": "提出了一种基于群组抽象的两阶段多智能体路径规划方法，解决了大规模智能体系统计算效率问题。", "motivation": "多智能体系统中，随着智能体数量增加，现有方法计算复杂度显著上升，而复杂任务通常需要多智能体协作。", "method": "1. 将协作智能体抽象为群组，构建降维状态空间；2. 在群组层面进行路径规划；3. 设计底层控制策略。", "result": "在单群和多群场景中验证，任务均安全完成，计算时间随群组数量而非智能体数量增长。", "conclusion": "两阶段方法在保证安全性和任务完成的同时，显著提高了计算效率。"}}
{"id": "2506.14121", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14121", "abs": "https://arxiv.org/abs/2506.14121", "authors": ["Siyu Xu", "Wenjie Li", "Guangwei Gao", "Jian Yang", "Guo-Jun Qi", "Chia-Wen Lin"], "title": "FADPNet: Frequency-Aware Dual-Path Network for Face Super-Resolution", "comment": "12 pages, 11 figures, 6 tales", "summary": "Face super-resolution (FSR) under limited computational costs remains an open problem. Existing approaches typically treat all facial pixels equally, resulting in suboptimal allocation of computational resources and degraded FSR performance. CNN is relatively sensitive to high-frequency facial features, such as component contours and facial outlines. Meanwhile, Mamba excels at capturing low-frequency features like facial color and fine-grained texture, and does so with lower complexity than Transformers. Motivated by these observations, we propose FADPNet, a Frequency-Aware Dual-Path Network that decomposes facial features into low- and high-frequency components and processes them via dedicated branches. For low-frequency regions, we introduce a Mamba-based Low-Frequency Enhancement Block (LFEB), which combines state-space attention with squeeze-and-excitation operations to extract low-frequency global interactions and emphasize informative channels. For high-frequency regions, we design a CNN-based Deep Position-Aware Attention (DPA) module to enhance spatially-dependent structural details, complemented by a lightweight High-Frequency Refinement (HFR) module that further refines frequency-specific representations. Through the above designs, our method achieves an excellent balance between FSR quality and model efficiency, outperforming existing approaches.", "AI": {"tldr": "提出了一种频率感知双路径网络（FADPNet），通过分别处理低频和高频特征，优化了人脸超分辨率（FSR）的性能和计算效率。", "motivation": "现有方法对所有面部像素一视同仁，导致计算资源分配不佳和性能下降。CNN对高频特征敏感，而Mamba擅长低频特征且复杂度低。", "method": "FADPNet将特征分解为低频和高频，分别用Mamba和CNN处理。低频分支使用LFEB，高频分支使用DPA和HFR模块。", "result": "方法在FSR质量和模型效率之间取得了良好平衡，优于现有方法。", "conclusion": "FADPNet通过频率感知设计，显著提升了FSR性能，同时保持了计算效率。"}}
{"id": "2506.13906", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13906", "abs": "https://arxiv.org/abs/2506.13906", "authors": ["Milad Ramezankhani", "Janak M. Patel", "Anirudh Deodhar", "Dagnachew Birru"], "title": "GITO: Graph-Informed Transformer Operator for Learning Complex Partial Differential Equations", "comment": null, "summary": "We present a novel graph-informed transformer operator (GITO) architecture for learning complex partial differential equation systems defined on irregular geometries and non-uniform meshes. GITO consists of two main modules: a hybrid graph transformer (HGT) and a transformer neural operator (TNO). HGT leverages a graph neural network (GNN) to encode local spatial relationships and a transformer to capture long-range dependencies. A self-attention fusion layer integrates the outputs of the GNN and transformer to enable more expressive feature learning on graph-structured data. TNO module employs linear-complexity cross-attention and self-attention layers to map encoded input functions to predictions at arbitrary query locations, ensuring discretization invariance and enabling zero-shot super-resolution across any mesh. Empirical results on benchmark PDE tasks demonstrate that GITO outperforms existing transformer-based neural operators, paving the way for efficient, mesh-agnostic surrogate solvers in engineering applications.", "AI": {"tldr": "提出了一种新型图信息Transformer算子（GITO），用于学习不规则几何和非均匀网格上的复杂偏微分方程系统。", "motivation": "解决传统方法在处理不规则几何和非均匀网格上的偏微分方程系统时的局限性。", "method": "GITO由混合图Transformer（HGT）和Transformer神经算子（TNO）组成，分别利用图神经网络和Transformer捕捉局部和全局依赖关系。", "result": "在基准PDE任务中，GITO优于现有基于Transformer的神经算子。", "conclusion": "GITO为工程应用中高效、网格无关的替代求解器提供了新途径。"}}
{"id": "2506.14116", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14116", "abs": "https://arxiv.org/abs/2506.14116", "authors": ["Rongyu Yu", "Kan Chen", "Zeyu Deng", "Chen Wang", "Burak Kizilkaya", "Liying Emma Li"], "title": "Haptic-Based User Authentication for Tele-robotic System", "comment": null, "summary": "Tele-operated robots rely on real-time user behavior mapping for remote tasks, but ensuring secure authentication remains a challenge. Traditional methods, such as passwords and static biometrics, are vulnerable to spoofing and replay attacks, particularly in high-stakes, continuous interactions. This paper presents a novel anti-spoofing and anti-replay authentication approach that leverages distinctive user behavioral features extracted from haptic feedback during human-robot interactions. To evaluate our authentication approach, we collected a time-series force feedback dataset from 15 participants performing seven distinct tasks. We then developed a transformer-based deep learning model to extract temporal features from the haptic signals. By analyzing user-specific force dynamics, our method achieves over 90 percent accuracy in both user identification and task classification, demonstrating its potential for enhancing access control and identity assurance in tele-robotic systems.", "AI": {"tldr": "提出一种基于触觉反馈的用户行为认证方法，用于远程机器人操作，防止欺骗和重放攻击。", "motivation": "传统认证方法（如密码和静态生物特征）在高风险连续交互中易受攻击，需更安全的解决方案。", "method": "收集15名参与者的触觉反馈数据，开发基于Transformer的深度学习模型提取时序特征。", "result": "用户识别和任务分类准确率超过90%。", "conclusion": "该方法可增强远程机器人系统的访问控制和身份验证安全性。"}}
{"id": "2506.14611", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14611", "abs": "https://arxiv.org/abs/2506.14611", "authors": ["Jacob Miller", "Markus Wallinger", "Ludwig Felder", "Timo Brand", "Henry Förster", "Johannes Zink", "Chunyang Chen", "Stephen Kobourov"], "title": "Exploring MLLMs Perception of Network Visualization Principles", "comment": null, "summary": "In this paper, we test whether Multimodal Large Language Models (MLLMs) can match human-subject performance in tasks involving the perception of properties in network layouts. Specifically, we replicate a human-subject experiment about perceiving quality (namely stress) in network layouts using GPT-4o and Gemini-2.5. Our experiments show that giving MLLMs exactly the same study information as trained human participants results in a similar performance to human experts and exceeds the performance of untrained non-experts. Additionally, we show that prompt engineering that deviates from the human-subject experiment can lead to better-than-human performance in some settings. Interestingly, like human subjects, the MLLMs seem to rely on visual proxies rather than computing the actual value of stress, indicating some sense or facsimile of perception. Explanations from the models provide descriptions similar to those used by the human participants (e.g., even distribution of nodes and uniform edge lengths).", "AI": {"tldr": "MLLMs（如GPT-4o和Gemini-2.5）在网络布局感知任务中表现接近人类专家，甚至在某些情况下通过提示工程超越人类。", "motivation": "测试MLLMs在网络布局感知任务中是否能达到人类水平，并探索其感知机制。", "method": "复制人类实验，使用相同信息测试MLLMs，并进行提示工程优化。", "result": "MLLMs表现接近人类专家，优于非专家；提示工程可进一步提升性能。", "conclusion": "MLLMs具备类似人类的感知能力，依赖视觉代理而非精确计算。"}}
{"id": "2506.14723", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14723", "abs": "https://arxiv.org/abs/2506.14723", "authors": ["Yusong Wu", "Tim Cooijmans", "Kyle Kastner", "Adam Roberts", "Ian Simon", "Alexander Scarlatos", "Chris Donahue", "Cassie Tarakajian", "Shayegan Omidshafiei", "Aaron Courville", "Pablo Samuel Castro", "Natasha Jaques", "Cheng-Zhi Anna Huang"], "title": "Adaptive Accompaniment with ReaLchords", "comment": "Accepted by ICML 2024", "summary": "Jamming requires coordination, anticipation, and collaborative creativity between musicians. Current generative models of music produce expressive output but are not able to generate in an \\emph{online} manner, meaning simultaneously with other musicians (human or otherwise). We propose ReaLchords, an online generative model for improvising chord accompaniment to user melody. We start with an online model pretrained by maximum likelihood, and use reinforcement learning to finetune the model for online use. The finetuning objective leverages both a novel reward model that provides feedback on both harmonic and temporal coherency between melody and chord, and a divergence term that implements a novel type of distillation from a teacher model that can see the future melody. Through quantitative experiments and listening tests, we demonstrate that the resulting model adapts well to unfamiliar input and produce fitting accompaniment. ReaLchords opens the door to live jamming, as well as simultaneous co-creation in other modalities.", "AI": {"tldr": "ReaLchords是一种在线生成模型，用于即兴伴奏用户旋律，通过强化学习微调，实现了与旋律的和谐和时间一致性。", "motivation": "当前生成模型无法在线与其他音乐家（人或机器）实时协作，限制了即兴演奏的可能性。", "method": "结合最大似然预训练和强化学习微调，利用奖励模型和未来旋律的蒸馏技术。", "result": "模型能适应陌生输入并生成合适的伴奏，通过定量实验和听力测试验证。", "conclusion": "ReaLchords为实时即兴演奏和多模态协同创作提供了可能。"}}
{"id": "2506.14130", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14130", "abs": "https://arxiv.org/abs/2506.14130", "authors": ["Chunyu Cao", "Jintao Cheng", "Zeyu Chen", "Linfan Zhan", "Rui Fan", "Zhijian He", "Xiaoyu Tang"], "title": "KDMOS:Knowledge Distillation for Motion Segmentation", "comment": null, "summary": "Motion Object Segmentation (MOS) is crucial for autonomous driving, as it enhances localization, path planning, map construction, scene flow estimation, and future state prediction. While existing methods achieve strong performance, balancing accuracy and real-time inference remains a challenge. To address this, we propose a logits-based knowledge distillation framework for MOS, aiming to improve accuracy while maintaining real-time efficiency. Specifically, we adopt a Bird's Eye View (BEV) projection-based model as the student and a non-projection model as the teacher. To handle the severe imbalance between moving and non-moving classes, we decouple them and apply tailored distillation strategies, allowing the teacher model to better learn key motion-related features. This approach significantly reduces false positives and false negatives. Additionally, we introduce dynamic upsampling, optimize the network architecture, and achieve a 7.69% reduction in parameter count, mitigating overfitting. Our method achieves a notable IoU of 78.8% on the hidden test set of the SemanticKITTI-MOS dataset and delivers competitive results on the Apollo dataset. The KDMOS implementation is available at https://github.com/SCNU-RISLAB/KDMOS.", "AI": {"tldr": "提出了一种基于logits的知识蒸馏框架（KDMOS），用于运动目标分割（MOS），通过BEV投影模型（学生）和非投影模型（教师）结合，优化了精度与实时性的平衡。", "motivation": "现有方法在精度与实时性之间难以平衡，且运动与非运动类别严重不平衡，需改进。", "method": "采用BEV投影模型作为学生，非投影模型作为教师，解耦运动与非运动类别并定制蒸馏策略，引入动态上采样和网络架构优化。", "result": "在SemanticKITTI-MOS隐藏测试集上达到78.8% IoU，Apollo数据集上表现优异，参数减少7.69%。", "conclusion": "KDMOS框架显著提升了MOS任务的精度与效率，代码已开源。"}}
{"id": "2506.13909", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13909", "abs": "https://arxiv.org/abs/2506.13909", "authors": ["Xinyuan Tu", "Haocheng Zhang", "Tao Chengxu", "Zuyi Chen"], "title": "Few-Shot Learning for Industrial Time Series: A Comparative Analysis Using the Example of Screw-Fastening Process Monitoring", "comment": null, "summary": "Few-shot learning (FSL) has shown promise in vision but remains largely unexplored for \\emph{industrial} time-series data, where annotating every new defect is prohibitively expensive. We present a systematic FSL study on screw-fastening process monitoring, using a 2\\,300-sample multivariate torque dataset that covers 16 uni- and multi-factorial defect types. Beyond benchmarking, we introduce a \\textbf{label-aware episodic sampler} that collapses multi-label sequences into multiple single-label tasks, keeping the output dimensionality fixed while preserving combinatorial label information.\n  Two FSL paradigms are investigated: the metric-based \\emph{Prototypical Network} and the gradient-based \\emph{Model-Agnostic Meta-Learning} (MAML), each paired with three backbones: 1D CNN, InceptionTime and the 341 M-parameter transformer \\emph{Moment}. On 10-shot, 3-way evaluation, the InceptionTime + Prototypical Network combination achieves a \\textbf{0.944 weighted F1} in the multi-class regime and \\textbf{0.935} in the multi-label regime, outperforming finetuned Moment by up to 5.3\\% while requiring two orders of magnitude fewer parameters and training time. Across all backbones, metric learning consistently surpasses MAML, and our label-aware sampling yields an additional 1.7\\% F1 over traditional class-based sampling.\n  These findings challenge the assumption that large foundation models are always superior: when data are scarce, lightweight CNN architectures augmented with simple metric learning not only converge faster but also generalize better. We release code, data splits and pre-trained weights to foster reproducible research and to catalyze the adoption of FSL in high-value manufacturing inspection.", "AI": {"tldr": "该论文研究了工业时间序列数据中的少样本学习（FSL），提出了一种标签感知的采样方法，并在螺丝紧固过程监测中验证了其有效性。结果表明，轻量级CNN结合度量学习优于大型模型。", "motivation": "工业时间序列数据标注成本高，少样本学习（FSL）在视觉领域已有应用，但在工业领域尚未充分探索。", "method": "提出了标签感知的片段采样器，将多标签序列转换为单标签任务，并比较了度量学习（Prototypical Network）和梯度学习（MAML）两种FSL范式，结合三种骨干网络（1D CNN、InceptionTime、Moment）。", "result": "InceptionTime + Prototypical Network组合在10-shot、3-way评估中表现最佳，F1分数达0.944（多类）和0.935（多标签），优于大型模型Moment。", "conclusion": "轻量级CNN结合度量学习在数据稀缺时表现更优，挑战了大型模型总是更好的假设。"}}
{"id": "2506.14135", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14135", "abs": "https://arxiv.org/abs/2506.14135", "authors": ["Ying Chai", "Litao Deng", "Ruizhi Shao", "Jiajun Zhang", "Liangjun Xing", "Hongwen Zhang", "Yebin Liu"], "title": "GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation", "comment": "http://chaiying1.github.io/GAF.github.io/project_page/", "summary": "Accurate action inference is critical for vision-based robotic manipulation. Existing approaches typically follow either a Vision-to-Action (V-A) paradigm, predicting actions directly from visual inputs, or a Vision-to-3D-to-Action (V-3D-A) paradigm, leveraging intermediate 3D representations. However, these methods often struggle with action inaccuracies due to the complexity and dynamic nature of manipulation scenes. In this paper, we propose a V-4D-A framework that enables direct action reasoning from motion-aware 4D representations via a Gaussian Action Field (GAF). GAF extends 3D Gaussian Splatting (3DGS) by incorporating learnable motion attributes, allowing simultaneous modeling of dynamic scenes and manipulation actions. To learn time-varying scene geometry and action-aware robot motion, GAF supports three key query types: reconstruction of the current scene, prediction of future frames, and estimation of initial action via robot motion. Furthermore, the high-quality current and future frames generated by GAF facilitate manipulation action refinement through a GAF-guided diffusion model. Extensive experiments demonstrate significant improvements, with GAF achieving +11.5385 dB PSNR and -0.5574 LPIPS improvements in reconstruction quality, while boosting the average success rate in robotic manipulation tasks by 10.33% over state-of-the-art methods. Project page: http://chaiying1.github.io/GAF.github.io/project_page/", "AI": {"tldr": "论文提出了一种V-4D-A框架，通过高斯动作场（GAF）直接从运动感知的4D表示中进行动作推理，显著提升了机器人操作的准确性和场景重建质量。", "motivation": "现有方法（V-A或V-3D-A）在复杂动态场景中动作推理不准确，需要更高效的框架。", "method": "提出GAF，扩展3D高斯泼溅（3DGS）以建模动态场景和动作，支持场景重建、未来帧预测和初始动作估计。", "result": "GAF在重建质量（PSNR +11.5385 dB，LPIPS -0.5574）和操作任务成功率（提升10.33%）上显著优于现有方法。", "conclusion": "GAF通过4D表示和动作感知建模，为机器人操作提供了更准确和高效的解决方案。"}}
{"id": "2506.14653", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14653", "abs": "https://arxiv.org/abs/2506.14653", "authors": ["Christina Bremer", "Harshit Gujral", "Michelle Lin", "Lily Hinkers", "Christoph Becker", "Vlad C. Coroamă"], "title": "How Viable are Energy Savings in Smart Homes? A Call to Embrace Rebound Effects in Sustainable HCI", "comment": "25 pages, 3 figures", "summary": "As part of global climate action, digital technologies are seen as a key enabler of energy efficiency savings. A popular application domain for this work is smart homes. There is a risk, however, that these efficiency gains result in rebound effects, which reduce or even overcompensate the savings. Rebound effects are well-established in economics, but it is less clear whether they also inform smart energy research in other disciplines. In this paper, we ask: to what extent have rebound effects and their underlying mechanisms been considered in computing, HCI and smart home research? To answer this, we conducted a literature mapping drawing on four scientific databases and a SIGCHI corpus. Our results reveal limited consideration of rebound effects and significant opportunities for HCI to advance this topic. We conclude with a taxonomy of actions for HCI to address rebound effects and help determine the viability of energy efficiency projects.", "AI": {"tldr": "本文探讨了数字技术（如智能家居）在节能中的潜在反弹效应，并分析了计算、HCI和智能家居研究中对此的关注程度。", "motivation": "全球气候行动中，数字技术被视为节能的关键推动者，但效率提升可能引发反弹效应，抵消节能效果。本文旨在评估其他学科（如计算和HCI）是否关注此问题。", "method": "通过文献映射，分析了四个科学数据库和SIGCHI语料库中的相关研究。", "result": "研究发现反弹效应在计算和HCI领域关注有限，HCI有潜力推动此议题。", "conclusion": "提出了HCI应对反弹效应的行动分类，以评估节能项目的可行性。"}}
{"id": "2506.14750", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14750", "abs": "https://arxiv.org/abs/2506.14750", "authors": ["Gaobin Yang", "Maokui He", "Shutong Niu", "Ruoyu Wang", "Hang Chen", "Jun Du"], "title": "Exploring Speaker Diarization with Mixture of Experts", "comment": null, "summary": "In this paper, we propose a novel neural speaker diarization system using memory-aware multi-speaker embedding with sequence-to-sequence architecture (NSD-MS2S), which integrates a memory-aware multi-speaker embedding module with a sequence-to-sequence architecture. The system leverages a memory module to enhance speaker embeddings and employs a Seq2Seq framework to efficiently map acoustic features to speaker labels. Additionally, we explore the application of mixture of experts in speaker diarization, and introduce a Shared and Soft Mixture of Experts (SS-MoE) module to further mitigate model bias and enhance performance. Incorporating SS-MoE leads to the extended model NSD-MS2S-SSMoE. Experiments on multiple complex acoustic datasets, including CHiME-6, DiPCo, Mixer 6 and DIHARD-III evaluation sets, demonstrate meaningful improvements in robustness and generalization. The proposed methods achieve state-of-the-art results, showcasing their effectiveness in challenging real-world scenarios.", "AI": {"tldr": "提出了一种新型神经说话人分割系统NSD-MS2S，结合记忆感知多说话人嵌入和序列到序列架构，并引入SS-MoE模块提升性能。", "motivation": "解决说话人分割任务中模型偏差和性能提升的挑战。", "method": "使用记忆感知多说话人嵌入模块和Seq2Seq框架，并引入SS-MoE模块。", "result": "在多个复杂数据集上取得SOTA结果，提高了鲁棒性和泛化能力。", "conclusion": "NSD-MS2S和NSD-MS2S-SSMoE在真实场景中表现出色。"}}
{"id": "2506.14136", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14136", "abs": "https://arxiv.org/abs/2506.14136", "authors": ["Nafiz Sadman", "Farhana Zulkernine", "Benjamin Kwan"], "title": "Interpreting Biomedical VLMs on High-Imbalance Out-of-Distributions: An Insight into BiomedCLIP on Radiology", "comment": "GitHub: https://github.com/Nafiz95/BioVLM_Eval_CXR", "summary": "In this paper, we construct two research objectives: i) explore the learned embedding space of BiomedCLIP, an open-source large vision language model, to analyse meaningful class separations, and ii) quantify the limitations of BiomedCLIP when applied to a highly imbalanced, out-of-distribution multi-label medical dataset. We experiment on IU-xray dataset, which exhibits the aforementioned criteria, and evaluate BiomedCLIP in classifying images (radiographs) in three contexts: zero-shot inference, full finetuning, and linear probing. The results show that the model under zero-shot settings over-predicts all labels, leading to poor precision and inter-class separability. Full fine-tuning improves classification of distinct diseases, while linear probing detects overlapping features. We demonstrate visual understanding of the model using Grad-CAM heatmaps and compare with 15 annotations by a radiologist. We highlight the need for careful adaptations of the models to foster reliability and applicability in a real-world setting. The code for the experiments in this work is available and maintained on GitHub.", "AI": {"tldr": "分析了BiomedCLIP在医学影像分类中的表现，发现零样本推理效果差，全微调提升明显，线性探测能捕捉重叠特征。", "motivation": "探索BiomedCLIP在医学影像中的嵌入空间特性，并量化其在高度不平衡、分布外数据集上的局限性。", "method": "在IU-xray数据集上评估BiomedCLIP的零样本推理、全微调和线性探测三种分类方式。", "result": "零样本推理表现差，全微调提升分类能力，线性探测捕捉重叠特征。", "conclusion": "需谨慎调整模型以提高实际应用中的可靠性和适用性。"}}
{"id": "2506.13911", "categories": ["cs.LG", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2506.13911", "abs": "https://arxiv.org/abs/2506.13911", "authors": ["Arie Soeteman", "Balder ten Cate"], "title": "Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization", "comment": "Submitted to NeurIPS 2025, 28 pages, 5 figures", "summary": "We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), an expressive extension of graph neural networks (GNNs) with hierarchical node individualization, inspired by the Individualization-Refinement paradigm for graph isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchy of increasingly expressive models that, in the limit, can distinguish graphs up to isomorphism. We provide a logical characterization of HEGNN node classifiers, with and without subgraph restrictions, using graded hybrid logic. This characterization enables us to relate the separating power of HEGNNs to that of higher-order GNNs, GNNs enriched with local homomorphism count features, and color refinement algorithms based on Individualization-Refinement. Our experimental results confirm the practical feasibility of HEGNNs and show benefits in comparison with traditional GNN architectures, both with and without local homomorphism count features.", "AI": {"tldr": "HEGNNs是一种基于层次化节点个性化的图神经网络扩展，能够区分图同构，并在实验中优于传统GNN架构。", "motivation": "受图同构测试中个性化-细化范式的启发，旨在提升图神经网络的表达能力。", "method": "提出HEGNNs，结合层次化节点个性化，并使用分级混合逻辑进行逻辑表征。", "result": "HEGNNs在实验中表现出优于传统GNN的性能，并能区分图同构。", "conclusion": "HEGNNs是一种有潜力的扩展模型，能够提升图神经网络的表达能力。"}}
{"id": "2506.14163", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14163", "abs": "https://arxiv.org/abs/2506.14163", "authors": ["Qiyuan Qiao", "Yu Wang", "Xiyu Fan", "Peng Lu"], "title": "Lasso Gripper: A String Shooting-Retracting Mechanism for Shape-Adaptive Grasping", "comment": "6 pages, 13 figures", "summary": "Handling oversized, variable-shaped, or delicate objects in transportation, grasping tasks is extremely challenging, mainly due to the limitations of the gripper's shape and size. This paper proposes a novel gripper, Lasso Gripper. Inspired by traditional tools like the lasso and the uurga, Lasso Gripper captures objects by launching and retracting a string. Contrary to antipodal grippers, which concentrate force on a limited area, Lasso Gripper applies uniform pressure along the length of the string for a more gentle grasp. The gripper is controlled by four motors-two for launching the string inward and two for launching it outward. By adjusting motor speeds, the size of the string loop can be tuned to accommodate objects of varying sizes, eliminating the limitations imposed by the maximum gripper separation distance. To address the issue of string tangling during rapid retraction, a specialized mechanism was incorporated. Additionally, a dynamic model was developed to estimate the string's curve, providing a foundation for the kinematic analysis of the workspace. In grasping experiments, Lasso Gripper, mounted on a robotic arm, successfully captured and transported a range of objects, including bull and horse figures as well as delicate vegetables. The demonstration video is available here: https://youtu.be/PV1J76mNP9Y.", "AI": {"tldr": "论文提出了一种新型抓取器Lasso Gripper，通过发射和收回绳子来抓取物体，解决了传统抓取器因形状和尺寸限制难以处理超大、异形或易碎物体的问题。", "motivation": "传统抓取器因形状和尺寸限制难以处理超大、异形或易碎物体，因此需要一种更灵活的抓取方法。", "method": "Lasso Gripper通过四个电机控制绳子的发射和收回，调整绳圈大小以适应不同尺寸的物体，并设计了防缠绕机制和动态模型分析绳子曲线。", "result": "实验证明Lasso Gripper能成功抓取和运输多种物体，包括动物模型和易碎蔬菜。", "conclusion": "Lasso Gripper提供了一种灵活且温和的抓取方案，适用于传统抓取器难以处理的物体。"}}
{"id": "2506.14670", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14670", "abs": "https://arxiv.org/abs/2506.14670", "authors": ["Jina Kim", "Leeje Jang", "Yao-Yi Chiang", "Guanyu Wang", "Michelle Pasco"], "title": "StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery", "comment": null, "summary": "Traditionally, neighborhood studies have employed interviews, surveys, and manual image annotation guided by detailed protocols to identify environmental characteristics, including physical disorder, decay, street safety, and sociocultural symbols, and to examine their impact on developmental and health outcomes. While these methods yield rich insights, they are time-consuming and require intensive expert intervention. Recent technological advances, including vision-language models (VLMs), have begun to automate parts of this process; however, existing efforts are often ad hoc and lack adaptability across research designs and geographic contexts. In this demo paper, we present StreetLens, a human-centered, researcher-configurable workflow that embeds relevant social science expertise in a VLM for scalable neighborhood environmental assessments. StreetLens mimics the process of trained human coders by grounding the analysis in questions derived from established interview protocols, retrieving relevant street view imagery (SVI), and generating a wide spectrum of semantic annotations from objective features (e.g., the number of cars) to subjective perceptions (e.g., the sense of disorder in an image). By enabling researchers to define the VLM's role through domain-informed prompting, StreetLens places domain knowledge at the core of the analysis process. It also supports the integration of prior survey data to enhance robustness and expand the range of characteristics assessed across diverse settings. We provide a Google Colab notebook to make StreetLens accessible and extensible for researchers working with public or custom SVI datasets. StreetLens represents a shift toward flexible, agentic AI systems that work closely with researchers to accelerate and scale neighborhood studies.", "AI": {"tldr": "StreetLens是一个基于视觉语言模型（VLM）的工作流，用于自动化社区环境评估，结合社会科学专业知识，提升研究的可扩展性和适应性。", "motivation": "传统社区研究方法耗时且依赖专家干预，现有技术缺乏跨设计和地理环境的适应性。", "method": "StreetLens通过问题驱动分析、检索街景图像（SVI）并生成语义注释，支持研究者自定义VLM角色。", "result": "StreetLens能够从客观特征到主观感知生成广泛注释，并整合先验调查数据增强鲁棒性。", "conclusion": "StreetLens展示了灵活、自主的AI系统如何与研究者协作，加速和扩展社区研究。"}}
{"id": "2506.14142", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14142", "abs": "https://arxiv.org/abs/2506.14142", "authors": ["Wenting Chen", "Yi Dong", "Zhaojun Ding", "Yucheng Shi", "Yifan Zhou", "Fang Zeng", "Yijun Luo", "Tianyu Lin", "Yihang Su", "Yichen Wu", "Kai Zhang", "Zhen Xiang", "Tianming Liu", "Ninghao Liu", "Lichao Sun", "Yixuan Yuan", "Xiang Li"], "title": "RadFabric: Agentic AI System with Reasoning Capability for Radiology", "comment": "4 figures, 2 tables", "summary": "Chest X ray (CXR) imaging remains a critical diagnostic tool for thoracic conditions, but current automated systems face limitations in pathology coverage, diagnostic accuracy, and integration of visual and textual reasoning. To address these gaps, we propose RadFabric, a multi agent, multimodal reasoning framework that unifies visual and textual analysis for comprehensive CXR interpretation. RadFabric is built on the Model Context Protocol (MCP), enabling modularity, interoperability, and scalability for seamless integration of new diagnostic agents. The system employs specialized CXR agents for pathology detection, an Anatomical Interpretation Agent to map visual findings to precise anatomical structures, and a Reasoning Agent powered by large multimodal reasoning models to synthesize visual, anatomical, and clinical data into transparent and evidence based diagnoses. RadFabric achieves significant performance improvements, with near-perfect detection of challenging pathologies like fractures (1.000 accuracy) and superior overall diagnostic accuracy (0.799) compared to traditional systems (0.229 to 0.527). By integrating cross modal feature alignment and preference-driven reasoning, RadFabric advances AI-driven radiology toward transparent, anatomically precise, and clinically actionable CXR analysis.", "AI": {"tldr": "RadFabric是一个多代理、多模态推理框架，通过整合视觉和文本分析，显著提升了胸部X光（CXR）的诊断准确性和病理覆盖范围。", "motivation": "当前自动化系统在胸部X光诊断中存在病理覆盖不足、诊断准确性低以及视觉与文本推理整合不足的问题。", "method": "基于模型上下文协议（MCP），RadFabric采用模块化设计，包含病理检测代理、解剖解释代理和推理代理，结合多模态推理模型进行综合分析。", "result": "RadFabric在骨折检测中达到1.000的准确率，整体诊断准确性（0.799）显著优于传统系统（0.229至0.527）。", "conclusion": "RadFabric通过跨模态特征对齐和偏好驱动推理，推动了AI驱动的放射学向透明、解剖精确和临床实用的方向发展。"}}
{"id": "2506.13916", "categories": ["cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2506.13916", "abs": "https://arxiv.org/abs/2506.13916", "authors": ["Isaias Banales", "Arturo Jaramillo", "Heli Ricalde Guerrero"], "title": "Branching Stein Variational Gradient Descent for sampling multimodal distributions", "comment": null, "summary": "We propose a novel particle-based variational inference method designed to work with multimodal distributions. Our approach, referred to as Branched Stein Variational Gradient Descent (BSVGD), extends the classical Stein Variational Gradient Descent (SVGD) algorithm by incorporating a random branching mechanism that encourages the exploration of the state space. In this work, a theoretical guarantee for the convergence in distribution is presented, as well as numerical experiments to validate the suitability of our algorithm. Performance comparisons between the BSVGD and the SVGD are presented using the Wasserstein distance between samples and the corresponding computational times.", "AI": {"tldr": "提出了一种基于粒子的变分推断方法BSVGD，通过随机分支机制扩展SVGD，适用于多模态分布，并提供了理论收敛保证和数值实验验证。", "motivation": "解决传统SVGD在多模态分布中探索不足的问题。", "method": "引入随机分支机制扩展SVGD，增强状态空间探索能力。", "result": "理论证明分布收敛性，实验显示BSVGD在Wasserstein距离和计算时间上优于SVGD。", "conclusion": "BSVGD在多模态分布推断中表现更优，具有理论和实践优势。"}}
{"id": "2506.14178", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14178", "abs": "https://arxiv.org/abs/2506.14178", "authors": ["Jeewon Kim", "Minho Oh", "Hyun Myung"], "title": "TACS-Graphs: Traversability-Aware Consistent Scene Graphs for Ground Robot Indoor Localization and Mapping", "comment": "Accepted by IROS 2025", "summary": "Scene graphs have emerged as a powerful tool for robots, providing a structured representation of spatial and semantic relationships for advanced task planning. Despite their potential, conventional 3D indoor scene graphs face critical limitations, particularly under- and over-segmentation of room layers in structurally complex environments. Under-segmentation misclassifies non-traversable areas as part of a room, often in open spaces, while over-segmentation fragments a single room into overlapping segments in complex environments. These issues stem from naive voxel-based map representations that rely solely on geometric proximity, disregarding the structural constraints of traversable spaces and resulting in inconsistent room layers within scene graphs. To the best of our knowledge, this work is the first to tackle segmentation inconsistency as a challenge and address it with Traversability-Aware Consistent Scene Graphs (TACS-Graphs), a novel framework that integrates ground robot traversability with room segmentation. By leveraging traversability as a key factor in defining room boundaries, the proposed method achieves a more semantically meaningful and topologically coherent segmentation, effectively mitigating the inaccuracies of voxel-based scene graph approaches in complex environments. Furthermore, the enhanced segmentation consistency improves loop closure detection efficiency in the proposed Consistent Scene Graph-leveraging Loop Closure Detection (CoSG-LCD) leading to higher pose estimation accuracy. Experimental results confirm that the proposed approach outperforms state-of-the-art methods in terms of scene graph consistency and pose graph optimization performance.", "AI": {"tldr": "提出了一种新框架TACS-Graphs，通过结合地面机器人可通行性与房间分割，解决了传统3D室内场景图中房间层分割不一致的问题，提升了场景图的一致性和位姿估计精度。", "motivation": "传统3D室内场景图在结构复杂环境中存在房间层分割不足或过度的问题，导致场景图不一致，影响任务规划。", "method": "提出TACS-Graphs框架，利用可通行性作为定义房间边界的关键因素，实现语义更明确、拓扑更一致的分割。", "result": "实验结果表明，该方法在场景图一致性和位姿图优化性能上优于现有技术。", "conclusion": "TACS-Graphs有效解决了分割不一致问题，提升了场景图的语义和拓扑一致性，同时优化了位姿估计。"}}
{"id": "2506.14677", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14677", "abs": "https://arxiv.org/abs/2506.14677", "authors": ["Yingchao Li"], "title": "Design an Editable Speech-to-Sign-Language Transformer System: A Human-Centered AI Approach", "comment": null, "summary": "This paper presents a human-centered, real-time, user-adaptive speech-to-sign language animation system that integrates Transformer-based motion generation with a transparent, user-editable JSON intermediate layer. The framework overcomes key limitations in prior sign language technologies by enabling direct user inspection and modification of sign segments, thus enhancing naturalness, expressiveness, and user agency. Leveraging a streaming Conformer encoder and autoregressive Transformer-MDN decoder, the system synchronizes spoken input into upper-body and facial motion for 3D avatar rendering. Edits and user ratings feed into a human-in-the-loop optimization loop for continuous improvement. Experiments with 20 deaf signers and 5 interpreters show that the editable interface and participatory feedback significantly improve comprehension, naturalness, usability, and trust, while lowering cognitive load. With sub-20 ms per-frame inference on standard hardware, the system is ready for real-time communication and education. This work illustrates how technical and participatory innovation together enable accessible, explainable, and user-adaptive AI for sign language technology.", "AI": {"tldr": "本文提出了一种基于Transformer的实时语音到手语动画系统，通过用户可编辑的JSON中间层提升自然性和用户参与度。", "motivation": "解决现有手语技术中用户无法直接检查和修改手势的问题，提升自然性和用户控制力。", "method": "结合流式Conformer编码器和自回归Transformer-MDN解码器，生成3D虚拟形象的上半身和面部动作，并通过用户反馈进行优化。", "result": "实验表明，可编辑界面和用户反馈显著提升了理解度、自然性、可用性和信任度，同时降低了认知负荷。", "conclusion": "技术和用户参与的创新共同推动了手语技术的可访问性、可解释性和用户适应性。"}}
{"id": "2506.14186", "categories": ["cs.RO", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14186", "abs": "https://arxiv.org/abs/2506.14186", "authors": ["Anselm Paulus", "A. René Geist", "Pierre Schumacher", "Vít Musil", "Georg Martius"], "title": "Hard Contacts with Soft Gradients: Refining Differentiable Simulators for Learning and Control", "comment": null, "summary": "Contact forces pose a major challenge for gradient-based optimization of robot dynamics as they introduce jumps in the system's velocities. Penalty-based simulators, such as MuJoCo, simplify gradient computation by softening the contact forces. However, realistically simulating hard contacts requires very stiff contact settings, which leads to incorrect gradients when using automatic differentiation. On the other hand, using non-stiff settings strongly increases the sim-to-real gap. We analyze the contact computation of penalty-based simulators to identify the causes of gradient errors. Then, we propose DiffMJX, which combines adaptive integration with MuJoCo XLA, to notably improve gradient quality in the presence of hard contacts. Finally, we address a key limitation of contact gradients: they vanish when objects do not touch. To overcome this, we introduce Contacts From Distance (CFD), a mechanism that enables the simulator to generate informative contact gradients even before objects are in contact. To preserve physical realism, we apply CFD only in the backward pass using a straight-through trick, allowing us to compute useful gradients without modifying the forward simulation.", "AI": {"tldr": "论文分析了基于惩罚的模拟器中接触力梯度计算的问题，提出了DiffMJX和CFD方法以改进梯度质量。", "motivation": "接触力在机器人动力学优化中引入速度跳跃，而基于惩罚的模拟器（如MuJoCo）通过软化接触力简化梯度计算，但硬接触模拟时梯度不准确。", "method": "分析接触计算问题，提出DiffMJX结合自适应积分和MuJoCo XLA，并引入CFD机制在未接触时生成梯度。", "result": "DiffMJX显著提高了硬接触下的梯度质量，CFD解决了梯度消失问题。", "conclusion": "DiffMJX和CFD方法有效提升了梯度计算的准确性和实用性，同时保持物理真实性。"}}
{"id": "2506.14144", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14144", "abs": "https://arxiv.org/abs/2506.14144", "authors": ["Juho Bai", "Inwook Shim"], "title": "SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability", "comment": null, "summary": "Accurate prediction of pedestrian trajectories is essential for applications in robotics and surveillance systems. While existing approaches primarily focus on social interactions between pedestrians, they often overlook the rich environmental context that significantly shapes human movement patterns. In this paper, we propose SceneAware, a novel framework that explicitly incorporates scene understanding to enhance trajectory prediction accuracy. Our method leverages a Vision Transformer~(ViT) scene encoder to process environmental context from static scene images, while Multi-modal Large Language Models~(MLLMs) generate binary walkability masks that distinguish between accessible and restricted areas during training. We combine a Transformer-based trajectory encoder with the ViT-based scene encoder, capturing both temporal dynamics and spatial constraints. The framework integrates collision penalty mechanisms that discourage predicted trajectories from violating physical boundaries, ensuring physically plausible predictions. SceneAware is implemented in both deterministic and stochastic variants. Comprehensive experiments on the ETH/UCY benchmark datasets show that our approach outperforms state-of-the-art methods, with more than 50\\% improvement over previous models. Our analysis based on different trajectory categories shows that the model performs consistently well across various types of pedestrian movement. This highlights the importance of using explicit scene information and shows that our scene-aware approach is both effective and reliable in generating accurate and physically plausible predictions. Code is available at: https://github.com/juho127/SceneAware.", "AI": {"tldr": "论文提出SceneAware框架，通过结合场景理解提升行人轨迹预测准确性，利用ViT和MLLM处理环境信息，并在ETH/UCY数据集上表现优于现有方法。", "motivation": "现有方法主要关注行人间的社交互动，忽略了环境背景对行人轨迹的重要影响。", "method": "结合ViT场景编码器和MLLM生成的可行走区域掩码，通过Transformer编码时空动态与空间约束，并引入碰撞惩罚机制。", "result": "在ETH/UCY数据集上优于现有方法，性能提升50%以上，且在不同类型行人运动中表现一致。", "conclusion": "显式利用场景信息能有效提升轨迹预测的准确性和物理合理性，SceneAware框架具有高效性和可靠性。"}}
{"id": "2506.13923", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.13923", "abs": "https://arxiv.org/abs/2506.13923", "authors": ["Vaskar Nath", "Elaine Lau", "Anisha Gunjal", "Manasi Sharma", "Nikhil Baharte", "Sean Hendryx"], "title": "Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models", "comment": null, "summary": "We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance through two main means: (1) by compressing pass@$k$ into pass@1 and (2) via \"capability gain\" in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B on >500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $\\text{Guide}$ - a new class of online training algorithms. $\\text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the \"off-policy\" trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $\\text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$\\%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $\\text{Guide}$'s components and theoretically analyze Guide's learning efficiency.", "AI": {"tldr": "论文研究了通过强化学习训练推理模型（RLVR）解决新问题的过程，发现RLVR通过压缩pass@k为pass@1和“能力增益”提升性能，并提出新算法Guide。", "motivation": "探索RLVR如何通过压缩和能力增益提升模型解决新问题的能力。", "method": "使用RLVR训练模型，提出Guide算法，结合自然语言提示优化策略。", "result": "Guide算法在7B和32B参数模型上显著提升泛化能力，数学基准测试提升达4%。", "conclusion": "Guide算法通过自适应提示和策略优化，显著提升模型解决新问题的能力。"}}
{"id": "2506.14180", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14180", "abs": "https://arxiv.org/abs/2506.14180", "authors": ["Hong Huang", "Dongkuan Xu", "Hao Zhang", "Peng Gao"], "title": "Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy", "comment": "IROS 2025", "summary": "Egocentric pose estimation is a fundamental capability for multi-robot collaborative perception in connected autonomy, such as connected autonomous vehicles. During multi-robot operations, a robot needs to know the relative pose between itself and its teammates with respect to its own coordinates. However, different robots usually observe completely different views that contains similar objects, which leads to wrong pose estimation. In addition, it is unrealistic to allow robots to share their raw observations to detect overlap due to the limited communication bandwidth constraint. In this paper, we introduce a novel method for Non-Overlap-Aware Egocentric Pose Estimation (NOPE), which performs egocentric pose estimation in a multi-robot team while identifying the non-overlap views and satifying the communication bandwidth constraint. NOPE is built upon an unified hierarchical learning framework that integrates two levels of robot learning: (1) high-level deep graph matching for correspondence identification, which allows to identify if two views are overlapping or not, (2) low-level position-aware cross-attention graph learning for egocentric pose estimation. To evaluate NOPE, we conduct extensive experiments in both high-fidelity simulation and real-world scenarios. Experimental results have demonstrated that NOPE enables the novel capability for non-overlapping-aware egocentric pose estimation and achieves state-of-art performance compared with the existing methods. Our project page at https://hongh0.github.io/NOPE/.", "AI": {"tldr": "论文提出了一种名为NOPE的新方法，用于多机器人团队中的自我中心姿态估计，同时识别非重叠视图并满足通信带宽限制。", "motivation": "在多机器人协作感知中，机器人需要知道自身与队友的相对姿态，但由于不同机器人视角差异大且通信带宽有限，传统方法难以实现。", "method": "NOPE采用分层学习框架，包括高层深度图匹配（用于识别视图重叠）和低层位置感知交叉注意力图学习（用于姿态估计）。", "result": "实验表明，NOPE在仿真和真实场景中均实现了非重叠感知的姿态估计，性能优于现有方法。", "conclusion": "NOPE为多机器人协作提供了一种高效且通信友好的姿态估计解决方案。"}}
{"id": "2506.14720", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.14720", "abs": "https://arxiv.org/abs/2506.14720", "authors": ["Antonios Saravanos"], "title": "How Warm-Glow Alters the Usability of Technology", "comment": null, "summary": "As technology increasingly aligns with users' personal values, traditional models of usability, focused on functionality and specifically effectiveness, efficiency, and satisfaction, may not fully capture how people perceive and evaluate it. This study investigates how the warm-glow phenomenon, the positive feeling associated with doing good, shapes perceived usability. An experimental approach was taken in which participants evaluated a hypothetical technology under conditions designed to evoke either the intrinsic (i.e., personal fulfillment) or extrinsic (i.e., social recognition) dimensions of warm-glow. A Multivariate Analysis of Variance as well as subsequent follow-up analyses revealed that intrinsic warm-glow significantly enhances all dimensions of perceived usability, while extrinsic warm-glow selectively influences perceived effectiveness and satisfaction. These findings suggest that perceptions of usability extend beyond functionality and are shaped by how technology resonates with users' broader sense of purpose. We conclude by proposing that designers consider incorporating warm-glow into technology as a strategic design decision.", "AI": {"tldr": "研究发现，技术的情感共鸣（如“温暖效应”）能显著提升用户感知的可用性，尤其是内在满足感。", "motivation": "探讨传统可用性模型是否足以衡量用户对技术的感知，尤其是情感因素的作用。", "method": "通过实验设计，比较内在（个人满足）和外在（社会认可）温暖效应对可用性感知的影响。", "result": "内在温暖效应显著提升所有可用性维度，外在效应仅影响效果和满意度。", "conclusion": "设计应考虑融入温暖效应，以增强技术与用户价值观的共鸣。"}}
{"id": "2506.14201", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14201", "abs": "https://arxiv.org/abs/2506.14201", "authors": ["Shunhan Ji", "Yanxi Chen", "Zhongyu Yang", "Quan Zhang", "Xiaohang Nie", "Jingqian Sun", "Yichao Tang"], "title": "Pose State Perception of Interventional Robot for Cardio-cerebrovascular Procedures", "comment": null, "summary": "In response to the increasing demand for cardiocerebrovascular interventional surgeries, precise control of interventional robots has become increasingly important. Within these complex vascular scenarios, the accurate and reliable perception of the pose state for interventional robots is particularly crucial. This paper presents a novel vision-based approach without the need of additional sensors or markers. The core of this paper's method consists of a three-part framework: firstly, a dual-head multitask U-Net model for simultaneous vessel segment and interventional robot detection; secondly, an advanced algorithm for skeleton extraction and optimization; and finally, a comprehensive pose state perception system based on geometric features is implemented to accurately identify the robot's pose state and provide strategies for subsequent control. The experimental results demonstrate the proposed method's high reliability and accuracy in trajectory tracking and pose state perception.", "AI": {"tldr": "本文提出了一种无需额外传感器或标记的视觉方法，用于精确感知介入机器人的姿态状态，实验证明其高可靠性和准确性。", "motivation": "随着心脑血管介入手术需求的增加，精确控制介入机器人变得尤为重要，尤其是在复杂血管场景中，准确感知机器人姿态状态至关重要。", "method": "方法包括三部分：双头多任务U-Net模型用于血管和机器人检测；骨架提取与优化算法；基于几何特征的姿态感知系统。", "result": "实验结果表明，该方法在轨迹跟踪和姿态感知方面具有高可靠性和准确性。", "conclusion": "该方法为介入机器人的精确控制提供了有效的解决方案。"}}
{"id": "2506.14168", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14168", "abs": "https://arxiv.org/abs/2506.14168", "authors": ["Hu Yu", "Biao Gong", "Hangjie Yuan", "DanDan Zheng", "Weilong Chai", "Jingdong Chen", "Kecheng Zheng", "Feng Zhao"], "title": "VideoMAR: Autoregressive Video Generatio with Continuous Tokens", "comment": "Submitted to NeurIPS 2025", "summary": "Masked-based autoregressive models have demonstrated promising image generation capability in continuous space. However, their potential for video generation remains under-explored. In this paper, we propose \\textbf{VideoMAR}, a concise and efficient decoder-only autoregressive image-to-video model with continuous tokens, composing temporal frame-by-frame and spatial masked generation. We first identify temporal causality and spatial bi-directionality as the first principle of video AR models, and propose the next-frame diffusion loss for the integration of mask and video generation. Besides, the huge cost and difficulty of long sequence autoregressive modeling is a basic but crucial issue. To this end, we propose the temporal short-to-long curriculum learning and spatial progressive resolution training, and employ progressive temperature strategy at inference time to mitigate the accumulation error. Furthermore, VideoMAR replicates several unique capacities of language models to video generation. It inherently bears high efficiency due to simultaneous temporal-wise KV cache and spatial-wise parallel generation, and presents the capacity of spatial and temporal extrapolation via 3D rotary embeddings. On the VBench-I2V benchmark, VideoMAR surpasses the previous state-of-the-art (Cosmos I2V) while requiring significantly fewer parameters ($9.3\\%$), training data ($0.5\\%$), and GPU resources ($0.2\\%$).", "AI": {"tldr": "VideoMAR是一种高效的解码器自回归图像到视频模型，结合了时间和空间的掩码生成，通过课程学习和渐进分辨率训练解决了长序列建模问题，并在性能上超越了现有方法。", "motivation": "探索基于掩码的自回归模型在视频生成中的潜力，解决长序列建模的高成本和难度问题。", "method": "提出VideoMAR模型，整合时间因果性和空间双向性，采用下一帧扩散损失、课程学习和渐进分辨率训练，以及渐进温度策略。", "result": "在VBench-I2V基准测试中，VideoMAR性能优于Cosmos I2V，且参数、训练数据和GPU资源需求显著减少。", "conclusion": "VideoMAR展示了高效且强大的视频生成能力，为自回归模型在视频领域的应用提供了新思路。"}}
{"id": "2506.13935", "categories": ["cs.LG", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.13935", "abs": "https://arxiv.org/abs/2506.13935", "authors": ["Vishesh Kumar Tanwar", "Soumik Sarkar", "Asheesh K. Singh", "Sajal K. Das"], "title": "ReinDSplit: Reinforced Dynamic Split Learning for Pest Recognition in Precision Agriculture", "comment": null, "summary": "To empower precision agriculture through distributed machine learning (DML), split learning (SL) has emerged as a promising paradigm, partitioning deep neural networks (DNNs) between edge devices and servers to reduce computational burdens and preserve data privacy. However, conventional SL frameworks' one-split-fits-all strategy is a critical limitation in agricultural ecosystems where edge insect monitoring devices exhibit vast heterogeneity in computational power, energy constraints, and connectivity. This leads to straggler bottlenecks, inefficient resource utilization, and compromised model performance. Bridging this gap, we introduce ReinDSplit, a novel reinforcement learning (RL)-driven framework that dynamically tailors DNN split points for each device, optimizing efficiency without sacrificing accuracy. Specifically, a Q-learning agent acts as an adaptive orchestrator, balancing workloads and latency thresholds across devices to mitigate computational starvation or overload. By framing split layer selection as a finite-state Markov decision process, ReinDSplit convergence ensures that highly constrained devices contribute meaningfully to model training over time. Evaluated on three insect classification datasets using ResNet18, GoogleNet, and MobileNetV2, ReinDSplit achieves 94.31% accuracy with MobileNetV2. Beyond agriculture, ReinDSplit pioneers a paradigm shift in SL by harmonizing RL for resource efficiency, privacy, and scalability in heterogeneous environments.", "AI": {"tldr": "ReinDSplit是一种基于强化学习的动态分割框架，用于解决农业边缘设备异构性导致的分布式机器学习效率问题，显著提升模型性能。", "motivation": "传统分割学习框架在农业生态系统中无法适应设备的异构性，导致效率低下和性能下降。", "method": "提出ReinDSplit框架，利用Q学习动态调整DNN分割点，优化资源分配和延迟阈值。", "result": "在三个昆虫分类数据集上，ReinDSplit使用MobileNetV2达到94.31%的准确率。", "conclusion": "ReinDSplit不仅解决了农业领域的效率问题，还为异构环境中的分割学习提供了新范式。"}}
{"id": "2506.14341", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14341", "abs": "https://arxiv.org/abs/2506.14341", "authors": ["Anas Abdelkarim", "Holger Voos", "Daniel Görges"], "title": "Barrier Method for Inequality Constrained Factor Graph Optimization with Application to Model Predictive Control", "comment": null, "summary": "Factor graphs have demonstrated remarkable efficiency for robotic perception tasks, particularly in localization and mapping applications. However, their application to optimal control problems -- especially Model Predictive Control (MPC) -- has remained limited due to fundamental challenges in constraint handling. This paper presents a novel integration of the Barrier Interior Point Method (BIPM) with factor graphs, implemented as an open-source extension to the widely adopted g2o framework. Our approach introduces specialized inequality factor nodes that encode logarithmic barrier functions, thereby overcoming the quadratic-form limitations of conventional factor graph formulations. To the best of our knowledge, this is the first g2o-based implementation capable of efficiently handling both equality and inequality constraints within a unified optimization backend. We validate the method through a multi-objective adaptive cruise control application for autonomous vehicles. Benchmark comparisons with state-of-the-art constraint-handling techniques demonstrate faster convergence and improved computational efficiency. (Code repository: https://github.com/snt-arg/bipm_g2o)", "AI": {"tldr": "论文提出了一种将Barrier Interior Point Method（BIPM）与因子图结合的新方法，解决了MPC中约束处理的挑战，并通过实验验证了其高效性。", "motivation": "因子图在机器人感知任务中表现优异，但在最优控制问题（如MPC）中应用受限，主要由于约束处理的困难。", "method": "将BIPM与因子图结合，引入专门的不等式因子节点，利用对数障碍函数克服传统因子图的二次形式限制。", "result": "实验验证了该方法在多目标自适应巡航控制中的高效性，相比现有技术收敛更快、计算效率更高。", "conclusion": "该研究首次在g2o框架中实现了统一处理等式和不等式约束的优化后端，为MPC应用提供了新工具。"}}
{"id": "2506.14170", "categories": ["cs.CV", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.14170", "abs": "https://arxiv.org/abs/2506.14170", "authors": ["Shulong Zhang", "Mingyuan Yao", "Jiayin Zhao", "Xiao Liu", "Haihua Wang"], "title": "A multi-stage augmented multimodal interaction network for fish feeding intensity quantification", "comment": null, "summary": "In recirculating aquaculture systems, accurate and effective assessment of fish feeding intensity is crucial for reducing feed costs and calculating optimal feeding times. However, current studies have limitations in modality selection, feature extraction and fusion, and co-inference for decision making, which restrict further improvement in the accuracy, applicability and reliability of multimodal fusion models. To address this problem, this study proposes a Multi-stage Augmented Multimodal Interaction Network (MAINet) for quantifying fish feeding intensity. Firstly, a general feature extraction framework is proposed to efficiently extract feature information from input image, audio and water wave datas. Second, an Auxiliary-modality Reinforcement Primary-modality Mechanism (ARPM) is designed for inter-modal interaction and generate enhanced features, which consists of a Channel Attention Fusion Network (CAFN) and a Dual-mode Attention Fusion Network (DAFN). Finally, an Evidence Reasoning (ER) rule is introduced to fuse the output results of each modality and make decisions, thereby completing the quantification of fish feeding intensity. The experimental results show that the constructed MAINet reaches 96.76%, 96.78%, 96.79% and 96.79% in accuracy, precision, recall and F1-Score respectively, and its performance is significantly higher than the comparison models. Compared with models that adopt single-modality, dual-modality fusion and different decision-making fusion methods, it also has obvious advantages. Meanwhile, the ablation experiments further verified the key role of the proposed improvement strategy in improving the robustness and feature utilization efficiency of model, which can effectively improve the accuracy of the quantitative results of fish feeding intensity.", "AI": {"tldr": "本文提出了一种多阶段增强多模态交互网络（MAINet），用于量化鱼类摄食强度，通过特征提取、模态交互增强和证据推理规则，显著提高了模型的准确性和鲁棒性。", "motivation": "当前研究在模态选择、特征提取与融合以及协同推理方面存在局限性，限制了多模态融合模型的准确性、适用性和可靠性。", "method": "提出MAINet，包括通用特征提取框架、辅助模态增强主模态机制（ARPM）和证据推理（ER）规则。", "result": "实验结果显示MAINet在准确率、精确率、召回率和F1分数上均超过96.7%，显著优于对比模型。", "conclusion": "MAINet通过改进策略有效提升了模型鲁棒性和特征利用效率，显著提高了鱼类摄食强度量化的准确性。"}}
{"id": "2506.13958", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13958", "abs": "https://arxiv.org/abs/2506.13958", "authors": ["Leonardo Guiducci", "Antonio Rizzo", "Giovanna Maria Dimitri"], "title": "Toward Explainable Offline RL: Analyzing Representations in Intrinsically Motivated Decision Transformers", "comment": null, "summary": "Elastic Decision Transformers (EDTs) have proved to be particularly successful in offline reinforcement learning, offering a flexible framework that unifies sequence modeling with decision-making under uncertainty. Recent research has shown that incorporating intrinsic motivation mechanisms into EDTs improves performance across exploration tasks, yet the representational mechanisms underlying these improvements remain unexplored. In this paper, we introduce a systematic post-hoc explainability framework to analyze how intrinsic motivation shapes learned embeddings in EDTs. Through statistical analysis of embedding properties (including covariance structure, vector magnitudes, and orthogonality), we reveal that different intrinsic motivation variants create fundamentally different representational structures. Our analysis demonstrates environment-specific correlation patterns between embedding metrics and performance that explain why intrinsic motivation improves policy learning. These findings show that intrinsic motivation operates beyond simple exploration bonuses, acting as a representational prior that shapes embedding geometry in biologically plausible ways, creating environment-specific organizational structures that facilitate better decision-making.", "AI": {"tldr": "本文通过后验可解释性框架分析EDTs中内在动机如何影响嵌入表示，发现不同动机变体形成不同的表示结构，揭示了嵌入指标与性能的环境特异性相关性。", "motivation": "研究EDTs中内在动机对嵌入表示的影响机制，填补了相关研究的空白。", "method": "引入系统性后验可解释性框架，通过统计分析嵌入属性（如协方差结构、向量大小和正交性）。", "result": "发现不同内在动机变体形成不同的表示结构，嵌入指标与性能存在环境特异性相关性。", "conclusion": "内在动机不仅是探索奖励，还作为表示先验，以生物学合理的方式塑造嵌入几何结构，提升决策能力。"}}
{"id": "2506.14198", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14198", "abs": "https://arxiv.org/abs/2506.14198", "authors": ["Jeremy A. Collins", "Loránd Cheng", "Kunal Aneja", "Albert Wilcox", "Benjamin Joffe", "Animesh Garg"], "title": "AMPLIFY: Actionless Motion Priors for Robot Learning from Videos", "comment": null, "summary": "Action-labeled data for robotics is scarce and expensive, limiting the generalization of learned policies. In contrast, vast amounts of action-free video data are readily available, but translating these observations into effective policies remains a challenge. We introduce AMPLIFY, a novel framework that leverages large-scale video data by encoding visual dynamics into compact, discrete motion tokens derived from keypoint trajectories. Our modular approach separates visual motion prediction from action inference, decoupling the challenges of learning what motion defines a task from how robots can perform it. We train a forward dynamics model on abundant action-free videos and an inverse dynamics model on a limited set of action-labeled examples, allowing for independent scaling. Extensive evaluations demonstrate that the learned dynamics are both accurate, achieving up to 3.7x better MSE and over 2.5x better pixel prediction accuracy compared to prior approaches, and broadly useful. In downstream policy learning, our dynamics predictions enable a 1.2-2.2x improvement in low-data regimes, a 1.4x average improvement by learning from action-free human videos, and the first generalization to LIBERO tasks from zero in-distribution action data. Beyond robotic control, we find the dynamics learned by AMPLIFY to be a versatile latent world model, enhancing video prediction quality. Our results present a novel paradigm leveraging heterogeneous data sources to build efficient, generalizable world models. More information can be found at https://amplify-robotics.github.io/.", "AI": {"tldr": "AMPLIFY框架利用大规模无动作视频数据，通过关键点轨迹生成紧凑的运动令牌，分离视觉运动预测与动作推断，显著提升机器人策略学习效果。", "motivation": "机器人动作标注数据稀缺且昂贵，而无动作视频数据丰富但难以转化为有效策略，因此需要一种新方法利用异构数据源。", "method": "AMPLIFY通过关键点轨迹生成运动令牌，分别训练前向动力学模型（无动作视频）和逆向动力学模型（少量标注数据），实现模块化学习。", "result": "动力学模型准确性显著提升（MSE提高3.7倍，像素预测精度提高2.5倍），下游策略学习在低数据下提升1.2-2.2倍，并首次实现零分布内动作数据的LIBERO任务泛化。", "conclusion": "AMPLIFY为利用异构数据构建高效、可泛化的世界模型提供了新范式，适用于机器人控制及视频预测等领域。"}}
{"id": "2506.14268", "categories": ["cs.RO", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.14268", "abs": "https://arxiv.org/abs/2506.14268", "authors": ["Laura Aymerich-Franch", "Tarek Taha", "Takahiro Miyashita", "Hiroko Kamide", "Hiroshi Ishiguro", "Paolo Dario"], "title": "Public Acceptance of Cybernetic Avatars in the service sector: Evidence from a Large-Scale Survey in Dubai", "comment": "25 pages, 3 Figures", "summary": "Cybernetic avatars are hybrid interaction robots or digital representations that combine autonomous capabilities with teleoperated control. This study investigates the acceptance of cybernetic avatars in the highly multicultural society of Dubai, with particular emphasis on robotic avatars for customer service. Specifically, we explore how acceptance varies as a function of robot appearance (e.g., android, robotic-looking, cartoonish), deployment settings (e.g., shopping malls, hotels, hospitals), and functional tasks (e.g., providing information, patrolling). To this end, we conducted a large-scale survey with over 1,000 participants. Overall, cybernetic avatars received a high level of acceptance, with physical robot avatars receiving higher acceptance than digital avatars. In terms of appearance, robot avatars with a highly anthropomorphic robotic appearance were the most accepted, followed by cartoonish designs and androids. Animal-like appearances received the lowest level of acceptance. Among the tasks, providing information and guidance was rated as the most valued. Shopping malls, airports, public transport stations, and museums were the settings with the highest acceptance, whereas healthcare-related spaces received lower levels of support. An analysis by community cluster revealed among others that Emirati respondents showed significantly greater acceptance of android appearances compared to the overall sample, while participants from the 'Other Asia' cluster were significantly more accepting of cartoonish appearances. Our study underscores the importance of incorporating citizen feedback into the design and deployment of cybernetic avatars from the early stages to enhance acceptance of this technology in society.", "AI": {"tldr": "研究探讨了迪拜多元文化社会对赛博格化身的接受度，重点关注机器人化身在客户服务中的应用，分析了外观、场景和功能任务对接受度的影响。", "motivation": "研究赛博格化身在多元文化社会中的接受度，为设计和部署提供依据。", "method": "通过大规模调查（1000多名参与者），分析机器人外观、部署场景和功能任务对接受度的影响。", "result": "物理机器人化身接受度高于数字化身；高度拟人化的机器人外观最受欢迎；信息提供任务最受重视；购物中心等场景接受度最高。", "conclusion": "早期融入用户反馈对提升赛博格化身的社会接受度至关重要。"}}
{"id": "2506.14176", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14176", "abs": "https://arxiv.org/abs/2506.14176", "authors": ["Renao Yan"], "title": "One-Shot Neural Architecture Search with Network Similarity Directed Initialization for Pathological Image Classification", "comment": null, "summary": "Deep learning-based pathological image analysis presents unique challenges due to the practical constraints of network design. Most existing methods apply computer vision models directly to medical tasks, neglecting the distinct characteristics of pathological images. This mismatch often leads to computational inefficiencies, particularly in edge-computing scenarios. To address this, we propose a novel Network Similarity Directed Initialization (NSDI) strategy to improve the stability of neural architecture search (NAS). Furthermore, we introduce domain adaptation into one-shot NAS to better handle variations in staining and semantic scale across pathology datasets. Experiments on the BRACS dataset demonstrate that our method outperforms existing approaches, delivering both superior classification performance and clinically relevant feature localization.", "AI": {"tldr": "提出了一种基于网络相似性指导初始化（NSDI）的策略，结合领域自适应改进一次性神经架构搜索（NAS），以优化病理图像分析的效率和性能。", "motivation": "现有方法直接应用计算机视觉模型于医学任务，忽略了病理图像的独特性，导致计算效率低下。", "method": "提出NSDI策略改进NAS稳定性，并在一次性NAS中引入领域自适应以处理染色和语义尺度的变化。", "result": "在BRACS数据集上实验表明，该方法优于现有方法，分类性能和特征定位更优。", "conclusion": "该方法有效解决了病理图像分析中的计算效率和性能问题，具有临床实用性。"}}
{"id": "2506.13972", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13972", "abs": "https://arxiv.org/abs/2506.13972", "authors": ["Zhiqi Wang", "Chengyu Zhang", "Yuetian Chen", "Nathalie Baracaldo", "Swanand Kadhe", "Lei Yu"], "title": "Membership Inference Attacks as Privacy Tools: Reliability, Disparity and Ensemble", "comment": null, "summary": "Membership inference attacks (MIAs) pose a significant threat to the privacy of machine learning models and are widely used as tools for privacy assessment, auditing, and machine unlearning. While prior MIA research has primarily focused on performance metrics such as AUC, accuracy, and TPR@low FPR - either by developing new methods to enhance these metrics or using them to evaluate privacy solutions - we found that it overlooks the disparities among different attacks. These disparities, both between distinct attack methods and between multiple instantiations of the same method, have crucial implications for the reliability and completeness of MIAs as privacy evaluation tools. In this paper, we systematically investigate these disparities through a novel framework based on coverage and stability analysis. Extensive experiments reveal significant disparities in MIAs, their potential causes, and their broader implications for privacy evaluation. To address these challenges, we propose an ensemble framework with three distinct strategies to harness the strengths of state-of-the-art MIAs while accounting for their disparities. This framework not only enables the construction of more powerful attacks but also provides a more robust and comprehensive methodology for privacy evaluation.", "AI": {"tldr": "本文研究了成员推理攻击（MIAs）在隐私评估中的差异性问题，提出了基于覆盖率和稳定性分析的新框架，并通过实验揭示了差异的原因及影响。最后提出了一种集成框架以提升攻击效果和隐私评估的鲁棒性。", "motivation": "现有MIAs研究主要关注性能指标（如AUC、准确率等），而忽略了不同攻击方法之间的差异及其对隐私评估可靠性的影响。本文旨在填补这一空白。", "method": "通过覆盖率和稳定性分析框架系统地研究MIAs的差异，并提出一种集成框架，结合多种攻击方法的优势。", "result": "实验表明MIAs存在显著差异，这些差异会影响隐私评估的可靠性。集成框架能有效提升攻击效果和评估的全面性。", "conclusion": "本文揭示了MIAs的差异性问题，并提出了解决方案，为隐私评估提供了更鲁棒和全面的方法。"}}
{"id": "2506.14287", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14287", "abs": "https://arxiv.org/abs/2506.14287", "authors": ["Yanwei Wang"], "title": "Steering Robots with Inference-Time Interactions", "comment": "MIT Robotics PhD Thesis", "summary": "Imitation learning has driven the development of generalist policies capable of autonomously solving multiple tasks. However, when a pretrained policy makes errors during deployment, there are limited mechanisms for users to correct its behavior. While collecting additional data for finetuning can address such issues, doing so for each downstream use case is inefficient at deployment. My research proposes an alternative: keeping pretrained policies frozen as a fixed skill repertoire while allowing user interactions to guide behavior generation toward user preferences at inference time. By making pretrained policies steerable, users can help correct policy errors when the model struggles to generalize-without needing to finetune the policy. Specifically, I propose (1) inference-time steering, which leverages user interactions to switch between discrete skills, and (2) task and motion imitation, which enables user interactions to edit continuous motions while satisfying task constraints defined by discrete symbolic plans. These frameworks correct misaligned policy predictions without requiring additional training, maximizing the utility of pretrained models while achieving inference-time user objectives.", "AI": {"tldr": "论文提出了一种无需微调预训练策略的方法，通过用户交互在推理时引导行为生成，以纠正策略错误。", "motivation": "预训练策略在部署时可能因泛化能力不足而产生错误，而传统的数据收集和微调方法效率低下。", "method": "提出了两种框架：(1)推理时引导，利用用户交互切换离散技能；(2)任务和运动模仿，允许用户编辑连续运动以满足任务约束。", "result": "这些框架能够在不额外训练的情况下纠正策略预测偏差，同时满足用户目标。", "conclusion": "通过用户交互引导行为生成，可以高效利用预训练模型，提升部署时的灵活性和实用性。"}}
{"id": "2506.14181", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14181", "abs": "https://arxiv.org/abs/2506.14181", "authors": ["Yufei Li", "Jirui Wu", "Long Tian", "Liming Wang", "Xiaonan Liu", "Zijun Liu", "Xiyang Liu"], "title": "Meta-SurDiff: Classification Diffusion Model Optimized by Meta Learning is Reliable for Online Surgical Phase Recognition", "comment": "15 pages, 5 figures", "summary": "Online surgical phase recognition has drawn great attention most recently due to its potential downstream applications closely related to human life and health. Despite deep models have made significant advances in capturing the discriminative long-term dependency of surgical videos to achieve improved recognition, they rarely account for exploring and modeling the uncertainty in surgical videos, which should be crucial for reliable online surgical phase recognition. We categorize the sources of uncertainty into two types, frame ambiguity in videos and unbalanced distribution among surgical phases, which are inevitable in surgical videos. To address this pivot issue, we introduce a meta-learning-optimized classification diffusion model (Meta-SurDiff), to take full advantage of the deep generative model and meta-learning in achieving precise frame-level distribution estimation for reliable online surgical phase recognition. For coarse recognition caused by ambiguous video frames, we employ a classification diffusion model to assess the confidence of recognition results at a finer-grained frame-level instance. For coarse recognition caused by unbalanced phase distribution, we use a meta-learning based objective to learn the diffusion model, thus enhancing the robustness of classification boundaries for different surgical phases.We establish effectiveness of Meta-SurDiff in online surgical phase recognition through extensive experiments on five widely used datasets using more than four practical metrics. The datasets include Cholec80, AutoLaparo, M2Cai16, OphNet, and NurViD, where OphNet comes from ophthalmic surgeries, NurViD is the daily care dataset, while the others come from laparoscopic surgeries. We will release the code upon acceptance.", "AI": {"tldr": "论文提出了一种基于元学习优化的分类扩散模型（Meta-SurDiff），用于解决在线手术阶段识别中的不确定性，包括视频帧模糊和手术阶段分布不平衡问题。", "motivation": "在线手术阶段识别对人类健康和生命至关重要，但现有方法未充分建模手术视频中的不确定性，影响识别的可靠性。", "method": "使用分类扩散模型评估模糊帧的识别置信度，并通过元学习优化扩散模型以增强不同手术阶段的分类边界鲁棒性。", "result": "在五个广泛使用的数据集上通过多种实用指标验证了Meta-SurDiff的有效性。", "conclusion": "Meta-SurDiff通过建模不确定性显著提升了在线手术阶段识别的可靠性。"}}
{"id": "2506.13974", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13974", "abs": "https://arxiv.org/abs/2506.13974", "authors": ["Michael Crawshaw", "Blake Woodworth", "Mingrui Liu"], "title": "Constant Stepsize Local GD for Logistic Regression: Acceleration by Instability", "comment": "ICML 2025", "summary": "Existing analysis of Local (Stochastic) Gradient Descent for heterogeneous objectives requires stepsizes $η\\leq 1/K$ where $K$ is the communication interval, which ensures monotonic decrease of the objective. In contrast, we analyze Local Gradient Descent for logistic regression with separable, heterogeneous data using any stepsize $η> 0$. With $R$ communication rounds and $M$ clients, we show convergence at a rate $\\mathcal{O}(1/ηK R)$ after an initial unstable phase lasting for $\\widetilde{\\mathcal{O}}(ηK M)$ rounds. This improves upon the existing $\\mathcal{O}(1/R)$ rate for general smooth, convex objectives. Our analysis parallels the single machine analysis of~\\cite{wu2024large} in which instability is caused by extremely large stepsizes, but in our setting another source of instability is large local updates with heterogeneous objectives.", "AI": {"tldr": "本文分析了局部梯度下降在逻辑回归中的收敛性，允许任意步长η>0，改进了现有对一般平滑凸目标的收敛速率。", "motivation": "现有方法要求步长η≤1/K以确保目标单调递减，限制了灵活性。本文旨在放宽这一限制，研究任意步长下的收敛行为。", "method": "使用局部梯度下降处理逻辑回归问题，数据可分且异构。分析包括不稳定阶段和收敛阶段。", "result": "在初始不稳定阶段后，收敛速率为O(1/ηKR)，优于现有O(1/R)速率。不稳定阶段持续O~(ηKM)轮。", "conclusion": "放宽步长限制后，局部梯度下降在异构数据下仍能高效收敛，但需注意不稳定阶段的影响。"}}
{"id": "2506.14233", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14233", "abs": "https://arxiv.org/abs/2506.14233", "authors": ["Amirreza Payandeh", "Anuj Pokhrel", "Daeun Song", "Marcos Zampieri", "Xuesu Xiao"], "title": "Narrate2Nav: Real-Time Visual Navigation with Implicit Language Reasoning in Human-Centric Environments", "comment": null, "summary": "Large Vision-Language Models (VLMs) have demonstrated potential in enhancing mobile robot navigation in human-centric environments by understanding contextual cues, human intentions, and social dynamics while exhibiting reasoning capabilities. However, their computational complexity and limited sensitivity to continuous numerical data impede real-time performance and precise motion control. To this end, we propose Narrate2Nav, a novel real-time vision-action model that leverages a novel self-supervised learning framework based on the Barlow Twins redundancy reduction loss to embed implicit natural language reasoning, social cues, and human intentions within a visual encoder-enabling reasoning in the model's latent space rather than token space. The model combines RGB inputs, motion commands, and textual signals of scene context during training to bridge from robot observations to low-level motion commands for short-horizon point-goal navigation during deployment. Extensive evaluation of Narrate2Nav across various challenging scenarios in both offline unseen dataset and real-world experiments demonstrates an overall improvement of 52.94 percent and 41.67 percent, respectively, over the next best baseline. Additionally, qualitative comparative analysis of Narrate2Nav's visual encoder attention map against four other baselines demonstrates enhanced attention to navigation-critical scene elements, underscoring its effectiveness in human-centric navigation tasks.", "AI": {"tldr": "Narrate2Nav是一种新型实时视觉-动作模型，通过自监督学习框架提升移动机器人在人机环境中的导航能力，显著优于基线方法。", "motivation": "大型视觉语言模型（VLMs）在移动机器人导航中表现出潜力，但计算复杂性和对连续数值数据的敏感性限制了其实时性能和精确控制。", "method": "提出Narrate2Nav，利用基于Barlow Twins冗余减少损失的自监督学习框架，将自然语言推理、社交线索和人类意图嵌入视觉编码器，实现潜在空间的推理。", "result": "在离线和真实世界实验中，Narrate2Nav分别比最佳基线提高了52.94%和41.67%，并在视觉编码器注意力图中表现出对导航关键元素的增强关注。", "conclusion": "Narrate2Nav在人机导航任务中表现出色，通过潜在空间推理和自监督学习显著提升了性能和实时性。"}}
{"id": "2506.14189", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14189", "abs": "https://arxiv.org/abs/2506.14189", "authors": ["Kunyuan Deng", "Yi Wang", "Lap-Pui Chau"], "title": "Egocentric Human-Object Interaction Detection: A New Benchmark and Method", "comment": null, "summary": "Understanding the interaction between humans and objects has gained much attention in recent years. Existing human-object interaction (HOI) detection methods mainly focus on the third-person perspectives, overlooking a more intuitive way from the egocentric view of HOI, namely Ego-HOI. This paper introduces an Ego-HOIBench, a new dataset to promote the benchmarking and development of Ego-HOI detection. Our Ego-HOIBench comprises more than 27K egocentric images with high-quality hand-verb-object triplet annotations across 123 fine-grained interaction categories and locations, covering a rich diversity of scenarios, object types, and hand configurations in daily activities. In addition, we explore and adapt third-person HOI detection methods to Ego-HOIBench and illustrate the challenges of hand-occluded objects and the complexity of single- and two-hand interactions. To build a new baseline, we propose a Hand Geometry and Interactivity Refinement (HGIR) scheme, which leverages hand pose and geometric information as valuable cues for interpreting interactions. Specifically, the HGIR scheme explicitly extracts global hand geometric features from the estimated hand pose proposals and refines the interaction-specific features using pose-interaction attention. This scheme enables the model to obtain a robust and powerful interaction representation, significantly improving the Ego-HOI detection capability. Our approach is lightweight and effective, and it can be easily applied to HOI baselines in a plug-and-play manner to achieve state-of-the-art results on Ego-HOIBench. Our project is available at: https://dengkunyuan.github.io/EgoHOIBench/", "AI": {"tldr": "该论文提出了一个新的数据集Ego-HOIBench，用于推动以自我为中心视角的人-物交互（Ego-HOI）检测的研究，并提出了一个轻量级且高效的HGIR方案来提升检测性能。", "motivation": "现有的人-物交互（HOI）检测方法主要关注第三人称视角，忽视了更直观的自我中心视角（Ego-HOI）。为了填补这一空白，作者提出了Ego-HOIBench数据集。", "method": "作者提出了Hand Geometry and Interactivity Refinement (HGIR)方案，利用手部姿态和几何信息作为交互理解的线索，并通过姿态-交互注意力机制优化交互特征。", "result": "HGIR方案显著提升了Ego-HOI检测能力，并在Ego-HOIBench数据集上实现了最先进的性能。", "conclusion": "Ego-HOIBench数据集和HGIR方案为Ego-HOI检测提供了新的基准和工具，推动了该领域的发展。"}}
{"id": "2506.13981", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13981", "abs": "https://arxiv.org/abs/2506.13981", "authors": ["Thanh Dan Bui"], "title": "HAELT: A Hybrid Attentive Ensemble Learning Transformer Framework for High-Frequency Stock Price Forecasting", "comment": null, "summary": "High-frequency stock price prediction is challenging due to non-stationarity, noise, and volatility. To tackle these issues, we propose the Hybrid Attentive Ensemble Learning Transformer (HAELT), a deep learning framework combining a ResNet-based noise-mitigation module, temporal self-attention for dynamic focus on relevant history, and a hybrid LSTM-Transformer core that captures both local and long-range dependencies. These components are adaptively ensembled based on recent performance. Evaluated on hourly Apple Inc. (AAPL) data from Jan 2024 to May 2025, HAELT achieves the highest F1-Score on the test set, effectively identifying both upward and downward price movements. This demonstrates HAELT's potential for robust, practical financial forecasting and algorithmic trading.", "AI": {"tldr": "提出了一种名为HAELT的深度学习框架，用于高频股票价格预测，结合了噪声抑制、动态时间关注和局部与长程依赖捕捉，表现优于基准。", "motivation": "高频股票价格预测面临非平稳性、噪声和波动性等挑战，需要一种更鲁棒的预测方法。", "method": "HAELT框架结合了基于ResNet的噪声抑制模块、时间自注意力机制和混合LSTM-Transformer核心，并通过自适应集成优化性能。", "result": "在2024年1月至2025年5月的AAPL小时数据上，HAELT在测试集上取得了最高的F1分数，能有效识别价格涨跌。", "conclusion": "HAELT展示了在金融预测和算法交易中的实用性和鲁棒性。"}}
{"id": "2506.14249", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14249", "abs": "https://arxiv.org/abs/2506.14249", "authors": ["Yitaek Kim", "Christoffer Sloth"], "title": "Robust Adaptive Time-Varying Control Barrier Function with Application to Robotic Surface Treatment", "comment": "This work has been accepted to ECC 2025", "summary": "Set invariance techniques such as control barrier functions (CBFs) can be used to enforce time-varying constraints such as keeping a safe distance from dynamic objects. However, existing methods for enforcing time-varying constraints often overlook model uncertainties. To address this issue, this paper proposes a CBFs-based robust adaptive controller design endowing time-varying constraints while considering parametric uncertainty and additive disturbances. To this end, we first leverage Robust adaptive Control Barrier Functions (RaCBFs) to handle model uncertainty, along with the concept of Input-to-State Safety (ISSf) to ensure robustness towards input disturbances. Furthermore, to alleviate the inherent conservatism in robustness, we also incorporate a set membership identification scheme. We demonstrate the proposed method on robotic surface treatment that requires time-varying force bounds to ensure uniform quality, in numerical simulation and real robotic setup, showing that the quality is formally guaranteed within an acceptable range.", "AI": {"tldr": "本文提出了一种基于鲁棒自适应控制屏障函数（RaCBFs）的方法，用于处理模型不确定性和输入扰动，同时满足时变约束。", "motivation": "现有方法在处理时变约束时往往忽略模型不确定性，本文旨在解决这一问题。", "method": "结合鲁棒自适应控制屏障函数（RaCBFs）和输入到状态安全（ISSf）概念，并引入集合成员识别方案以减少保守性。", "result": "在数值模拟和实际机器人实验中验证了方法的有效性，确保了表面处理质量的均匀性。", "conclusion": "所提方法能够正式保证质量在可接受范围内，适用于具有时变约束和不确定性的场景。"}}
{"id": "2506.14229", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14229", "abs": "https://arxiv.org/abs/2506.14229", "authors": ["Changbai Li", "Haodong Zhu", "Hanlin Chen", "Juan Zhang", "Tongfei Chen", "Shuo Yang", "Shuwei Shao", "Wenhao Dong", "Baochang Zhang"], "title": "HRGS: Hierarchical Gaussian Splatting for Memory-Efficient High-Resolution 3D Reconstruction", "comment": null, "summary": "3D Gaussian Splatting (3DGS) has made significant strides in real-time 3D scene reconstruction, but faces memory scalability issues in high-resolution scenarios. To address this, we propose Hierarchical Gaussian Splatting (HRGS), a memory-efficient framework with hierarchical block-level optimization. First, we generate a global, coarse Gaussian representation from low-resolution data. Then, we partition the scene into multiple blocks, refining each block with high-resolution data. The partitioning involves two steps: Gaussian partitioning, where irregular scenes are normalized into a bounded cubic space with a uniform grid for task distribution, and training data partitioning, where only relevant observations are retained for each block. By guiding block refinement with the coarse Gaussian prior, we ensure seamless Gaussian fusion across adjacent blocks. To reduce computational demands, we introduce Importance-Driven Gaussian Pruning (IDGP), which computes importance scores for each Gaussian and removes those with minimal contribution, speeding up convergence and reducing memory usage. Additionally, we incorporate normal priors from a pretrained model to enhance surface reconstruction quality. Our method enables high-quality, high-resolution 3D scene reconstruction even under memory constraints. Extensive experiments on three benchmarks show that HRGS achieves state-of-the-art performance in high-resolution novel view synthesis (NVS) and surface reconstruction tasks.", "AI": {"tldr": "HRGS提出了一种分层高斯泼溅框架，通过块级优化和重要性驱动的高斯剪枝，解决了3DGS在高分辨率场景下的内存扩展问题，实现了高质量、高分辨率的3D场景重建。", "motivation": "3D高斯泼溅（3DGS）在实时3D场景重建中取得进展，但在高分辨率场景下面临内存扩展问题。", "method": "HRGS通过分层块级优化，首先生成低分辨率数据的全局粗高斯表示，然后分区细化每个块。引入重要性驱动的高斯剪枝（IDGP）减少计算需求，并利用预训练模型的法线先验提升表面重建质量。", "result": "在三个基准测试中，HRGS在高分辨率新视角合成（NVS）和表面重建任务中达到最先进性能。", "conclusion": "HRGS是一种内存高效的方法，能在内存限制下实现高质量、高分辨率的3D场景重建。"}}
{"id": "2506.13987", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13987", "abs": "https://arxiv.org/abs/2506.13987", "authors": ["Md Abrar Jahin", "Adiba Abid", "M. F. Mridha"], "title": "Quantum-Informed Contrastive Learning with Dynamic Mixup Augmentation for Class-Imbalanced Expert Systems", "comment": null, "summary": "Expert systems often operate in domains characterized by class-imbalanced tabular data, where detecting rare but critical instances is essential for safety and reliability. While conventional approaches, such as cost-sensitive learning, oversampling, and graph neural networks, provide partial solutions, they suffer from drawbacks like overfitting, label noise, and poor generalization in low-density regions. To address these challenges, we propose QCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmented with k-nearest neighbor (kNN) guided dynamic mixup for robust classification under imbalance. QCL-MixNet integrates three core innovations: (i) a Quantum Entanglement-inspired layer that models complex feature interactions through sinusoidal transformations and gated attention, (ii) a sample-aware mixup strategy that adaptively interpolates feature representations of semantically similar instances to enhance minority class representation, and (iii) a hybrid loss function that unifies focal reweighting, supervised contrastive learning, triplet margin loss, and variance regularization to improve both intra-class compactness and inter-class separability. Extensive experiments on 18 real-world imbalanced datasets (binary and multi-class) demonstrate that QCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deep learning, and GNN-based baselines in macro-F1 and recall, often by substantial margins. Ablation studies further validate the critical role of each architectural component. Our results establish QCL-MixNet as a new benchmark for tabular imbalance handling in expert systems. Theoretical analyses reinforce its expressiveness, generalization, and optimization robustness.", "AI": {"tldr": "QCL-MixNet是一种新型量子启发对比学习框架，结合动态mixup技术，用于处理类别不平衡的表格数据，显著优于现有方法。", "motivation": "专家系统常面临类别不平衡问题，现有方法存在过拟合、标签噪声和泛化能力差等缺陷。", "method": "QCL-MixNet结合量子纠缠层、动态mixup策略和混合损失函数，提升少数类表示和分类性能。", "result": "在18个真实数据集上，QCL-MixNet在macro-F1和召回率上显著优于20种基线方法。", "conclusion": "QCL-MixNet为表格数据不平衡处理设定了新基准，理论分析支持其表达能力和鲁棒性。"}}
{"id": "2506.14238", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14238", "abs": "https://arxiv.org/abs/2506.14238", "authors": ["Yinuo Zheng", "Lipeng Gu", "Honghua Chen", "Liangliang Nan", "Mingqiang Wei"], "title": "Unified Representation Space for 3D Visual Grounding", "comment": null, "summary": "3D visual grounding (3DVG) is a critical task in scene understanding that aims to identify objects in 3D scenes based on text descriptions. However, existing methods rely on separately pre-trained vision and text encoders, resulting in a significant gap between the two modalities in terms of spatial geometry and semantic categories. This discrepancy often causes errors in object positioning and classification. The paper proposes UniSpace-3D, which innovatively introduces a unified representation space for 3DVG, effectively bridging the gap between visual and textual features. Specifically, UniSpace-3D incorporates three innovative designs: i) a unified representation encoder that leverages the pre-trained CLIP model to map visual and textual features into a unified representation space, effectively bridging the gap between the two modalities; ii) a multi-modal contrastive learning module that further reduces the modality gap; iii) a language-guided query selection module that utilizes the positional and semantic information to identify object candidate points aligned with textual descriptions. Extensive experiments demonstrate that UniSpace-3D outperforms baseline models by at least 2.24% on the ScanRefer and Nr3D/Sr3D datasets. The code will be made available upon acceptance of the paper.", "AI": {"tldr": "UniSpace-3D提出了一种统一表示空间方法，用于3D视觉定位任务，通过结合CLIP预训练模型和多模态对比学习，显著提升了性能。", "motivation": "现有方法依赖单独预训练的视觉和文本编码器，导致模态间在空间几何和语义类别上存在显著差距，影响定位和分类准确性。", "method": "1) 统一表示编码器利用CLIP模型映射视觉和文本特征；2) 多模态对比学习模块减少模态差距；3) 语言引导的查询选择模块对齐文本描述与候选点。", "result": "在ScanRefer和Nr3D/Sr3D数据集上，UniSpace-3D比基线模型至少提升2.24%。", "conclusion": "UniSpace-3D通过统一表示空间和多模态学习，有效解决了3D视觉定位中的模态差距问题，性能显著提升。"}}
{"id": "2506.13992", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2506.13992", "abs": "https://arxiv.org/abs/2506.13992", "authors": ["An Luo", "Xun Xian", "Jin Du", "Fangqiao Tian", "Ganghua Wang", "Ming Zhong", "Shengchun Zhao", "Xuan Bi", "Zirui Liu", "Jiawei Zhou", "Jayanth Srinivasa", "Ashish Kundu", "Charles Fleming", "Mingyi Hong", "Jie Ding"], "title": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "comment": null, "summary": "Large language models (LLMs) have advanced the automation of data science workflows. Yet it remains unclear whether they can critically leverage external domain knowledge as human data scientists do in practice. To answer this question, we introduce AssistedDS (Assisted Data Science), a benchmark designed to systematically evaluate how LLMs handle domain knowledge in tabular prediction tasks. AssistedDS features both synthetic datasets with explicitly known generative mechanisms and real-world Kaggle competitions, each accompanied by curated bundles of helpful and adversarial documents. These documents provide domain-specific insights into data cleaning, feature engineering, and model selection. We assess state-of-the-art LLMs on their ability to discern and apply beneficial versus harmful domain knowledge, evaluating submission validity, information recall, and predictive performance. Our results demonstrate three key findings: (1) LLMs frequently exhibit an uncritical adoption of provided information, significantly impairing their predictive performance when adversarial content is introduced, (2) helpful guidance is often insufficient to counteract the negative influence of adversarial information, and (3) in Kaggle datasets, LLMs often make errors in handling time-series data, applying consistent feature engineering across different folds, and interpreting categorical variables correctly. These findings highlight a substantial gap in current models' ability to critically evaluate and leverage expert knowledge, underscoring an essential research direction for developing more robust, knowledge-aware automated data science systems.", "AI": {"tldr": "论文评估了大型语言模型（LLMs）在数据科学任务中利用外部领域知识的能力，发现其在处理对抗性信息时表现不佳，且对时间序列和分类变量的处理存在缺陷。", "motivation": "探讨LLMs是否能像人类数据科学家一样批判性地利用外部领域知识。", "method": "引入AssistedDS基准，结合合成数据集和真实Kaggle竞赛数据，评估LLMs对领域知识的处理能力。", "result": "LLMs常不加批判地采用信息，对抗性内容显著降低其预测性能，且对时间序列和分类变量的处理存在错误。", "conclusion": "当前模型在批判性评估和利用专家知识方面存在显著不足，需开发更稳健的知识感知自动化数据科学系统。"}}
{"id": "2506.14278", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14278", "abs": "https://arxiv.org/abs/2506.14278", "authors": ["Tianlin Zhang", "Linzhu Yue", "Hongbo Zhang", "Lingwei Zhang", "Xuanqi Zeng", "Zhitao Song", "Yun-Hui Liu"], "title": "Whole-Body Control Framework for Humanoid Robots with Heavy Limbs: A Model-Based Approach", "comment": null, "summary": "Humanoid robots often face significant balance issues due to the motion of their heavy limbs. These challenges are particularly pronounced when attempting dynamic motion or operating in environments with irregular terrain. To address this challenge, this manuscript proposes a whole-body control framework for humanoid robots with heavy limbs, using a model-based approach that combines a kino-dynamics planner and a hierarchical optimization problem. The kino-dynamics planner is designed as a model predictive control (MPC) scheme to account for the impact of heavy limbs on mass and inertia distribution. By simplifying the robot's system dynamics and constraints, the planner enables real-time planning of motion and contact forces. The hierarchical optimization problem is formulated using Hierarchical Quadratic Programming (HQP) to minimize limb control errors and ensure compliance with the policy generated by the kino-dynamics planner. Experimental validation of the proposed framework demonstrates its effectiveness. The humanoid robot with heavy limbs controlled by the proposed framework can achieve dynamic walking speeds of up to 1.2~m/s, respond to external disturbances of up to 60~N, and maintain balance on challenging terrains such as uneven surfaces, and outdoor environments.", "AI": {"tldr": "提出了一种基于模型的人形机器人全身控制框架，通过结合运动动力学规划器和分层优化问题，解决了重肢动态运动中的平衡问题。", "motivation": "人形机器人因重肢运动常面临平衡问题，尤其是在动态运动或不规则地形中。", "method": "采用运动动力学规划器（MPC方案）和分层二次规划（HQP），简化系统动力学并实时规划运动与接触力。", "result": "实验证明，该框架使机器人能以1.2 m/s速度动态行走，承受60 N外力，并在复杂地形保持平衡。", "conclusion": "该框架有效解决了重肢人形机器人的动态平衡问题，适用于复杂环境。"}}
{"id": "2506.14243", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14243", "abs": "https://arxiv.org/abs/2506.14243", "authors": ["Xiaohui Jiang", "Haijiang Zhu", "Chadei Li", "Fulin Tang", "Ning An"], "title": "Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition", "comment": null, "summary": "LiDAR-based place recognition serves as a crucial enabler for long-term autonomy in robotics and autonomous driving systems. Yet, prevailing methodologies relying on handcrafted feature extraction face dual challenges: (1) Inconsistent point cloud density, induced by ego-motion dynamics and environmental disturbances during repeated traversals, leads to descriptor instability, and (2) Representation fragility stems from reliance on single-level geometric abstractions that lack discriminative power in structurally complex scenarios. To address these limitations, we propose a novel framework that redefines 3D place recognition through density-agnostic geometric reasoning. Specifically, we introduce an implicit 3D representation based on elastic points, which is immune to the interference of original scene point cloud density and achieves the characteristic of uniform distribution. Subsequently, we derive the occupancy grid and normal vector information of the scene from this implicit representation. Finally, with the aid of these two types of information, we obtain descriptors that fuse geometric information from both bird's-eye view (capturing macro-level spatial layouts) and 3D segment (encoding micro-scale surface geometries) perspectives. We conducted extensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT) across diverse environments. The experimental results demonstrate that our method achieves state-of-the-art performance. Moreover, our approach strikes an optimal balance between accuracy, runtime, and memory optimization for historical maps, showcasing excellent Resilient and scalability. Our code will be open-sourced in the future.", "AI": {"tldr": "提出了一种基于弹性点的密度无关几何推理框架，解决了LiDAR地点识别中因点云密度不一致和单级几何抽象导致的描述符不稳定和表示脆弱性问题。", "motivation": "现有方法依赖手工特征提取，易受点云密度变化和单级几何抽象的限制，导致描述符不稳定和表示脆弱。", "method": "引入弹性点的隐式3D表示，生成均匀分布的点云，并从中提取占用网格和法向量信息，融合鸟瞰图和3D片段的几何信息生成描述符。", "result": "在多个数据集上验证了方法的优越性，实现了最佳性能，并在准确性、运行时间和内存优化之间取得了平衡。", "conclusion": "该方法显著提升了LiDAR地点识别的鲁棒性和可扩展性，未来将开源代码。"}}
{"id": "2506.13996", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13996", "abs": "https://arxiv.org/abs/2506.13996", "authors": ["Stas Bekman", "Samyam Rajbhandari", "Michael Wyatt", "Jeff Rasley", "Tunji Ruwase", "Zhewei Yao", "Aurick Qiao", "Yuxiong He"], "title": "Arctic Long Sequence Training: Scalable And Efficient Training For Multi-Million Token Sequences", "comment": "19 pages, 13 figures", "summary": "Long sequences are critical for applications like RAG, long document summarization, multi-modality, etc., and modern LLMs, like Llama 4 Scout, support max sequence length of up to 10 million tokens. However, outside of enterprise labs, long sequence training is challenging for the AI community with limited system support in the open-source space.\n  Out-of-box, even on a modern NVIDIA H100 80GB GPU cluster, training Llama 8B model with sequence over 32K runs out of memory on a basic Hugging Face (HF) model due to two reasons: i) LLM training workloads are not optimized to fully leverage a single GPU memory, ii) existing solutions for leveraging multiple GPU memory are not easily available to HF models, making long sequence training inaccessible.\n  We address this with Arctic Long Sequence Training (ALST). It offers a combination of attention-agnostic single GPU and multi-GPU memory optimizations, that enables it to support out-of-box training of multi-million sequence length for a wide variety of HF models.\n  ALST supports training Meta's Llama 8B model with 500K sequence length on a single H100 GPU, 3.7M on a single 8xH100 GPU node, and over 15M on a 4 node cluster, an increase of over 400x compared to the 32K baseline for the latter. ALST is fully compatible with HF models and open-sourced via Deepspeed https://www.deepspeed.ai/tutorials/ulysses-alst-sequence-pallellism/ and Arctic Training https://github.com/snowflakedb/ArcticTraining/blob/main/projects/sequence-parallelism/README.md.", "AI": {"tldr": "ALST（Arctic Long Sequence Training）通过单GPU和多GPU内存优化，支持Hugging Face模型的长序列训练，显著提升序列长度上限。", "motivation": "长序列训练在开源社区中因系统支持不足而难以实现，现有解决方案无法充分利用GPU内存。", "method": "ALST结合了注意力无关的单GPU和多GPU内存优化技术。", "result": "ALST支持单H100 GPU训练500K序列长度，8xH100节点支持3.7M，4节点集群支持15M，比基线提升400倍。", "conclusion": "ALST开源且兼容Hugging Face模型，为长序列训练提供了可行方案。"}}
{"id": "2506.14255", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14255", "abs": "https://arxiv.org/abs/2506.14255", "authors": ["Johannes Flotzinger", "Fabian Deuser", "Achref Jaziri", "Heiko Neumann", "Norbert Oswald", "Visvanathan Ramesh", "Thomas Braml"], "title": "synth-dacl: Does Synthetic Defect Data Enhance Segmentation Accuracy and Robustness for Real-World Bridge Inspections?", "comment": null, "summary": "Adequate bridge inspection is increasingly challenging in many countries due to growing ailing stocks, compounded with a lack of staff and financial resources. Automating the key task of visual bridge inspection, classification of defects and building components on pixel level, improves efficiency, increases accuracy and enhances safety in the inspection process and resulting building assessment. Models overtaking this task must cope with an assortment of real-world conditions. They must be robust to variations in image quality, as well as background texture, as defects often appear on surfaces of diverse texture and degree of weathering. dacl10k is the largest and most diverse dataset for real-world concrete bridge inspections. However, the dataset exhibits class imbalance, which leads to notably poor model performance particularly when segmenting fine-grained classes such as cracks and cavities. This work introduces \"synth-dacl\", a compilation of three novel dataset extensions based on synthetic concrete textures. These extensions are designed to balance class distribution in dacl10k and enhance model performance, especially for crack and cavity segmentation. When incorporating the synth-dacl extensions, we observe substantial improvements in model robustness across 15 perturbed test sets. Notably, on the perturbed test set, a model trained on dacl10k combined with all synthetic extensions achieves a 2% increase in mean IoU, F1 score, Recall, and Precision compared to the same model trained solely on dacl10k.", "AI": {"tldr": "论文提出了一种通过合成数据集扩展（synth-dacl）来解决桥梁视觉检测中数据集类别不平衡问题的方法，显著提升了模型在裂缝和空洞分割中的性能。", "motivation": "桥梁视觉检测面临资源不足和数据集类别不平衡的挑战，尤其是裂缝和空洞等细粒度类别的分割性能较差。", "method": "通过合成混凝土纹理数据集（synth-dacl）扩展现有数据集dacl10k，以平衡类别分布并提升模型性能。", "result": "结合合成扩展后，模型在15个扰动测试集上的鲁棒性显著提升，平均IoU、F1分数、召回率和精确度均提高了2%。", "conclusion": "合成数据集扩展是解决桥梁视觉检测中类别不平衡问题的有效方法，显著提升了模型性能。"}}
{"id": "2506.14002", "categories": ["cs.LG", "cs.AI", "cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14002", "abs": "https://arxiv.org/abs/2506.14002", "authors": ["Siyu Chen", "Heejune Sheen", "Xuyuan Xiong", "Tianhao Wang", "Zhuoran Yang"], "title": "Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders", "comment": "136 pages, 21 figures", "summary": "We study the challenge of achieving theoretically grounded feature recovery using Sparse Autoencoders (SAEs) for the interpretation of Large Language Models. Existing SAE training algorithms often lack rigorous mathematical guarantees and suffer from practical limitations such as hyperparameter sensitivity and instability. To address these issues, we first propose a novel statistical framework for the feature recovery problem, which includes a new notion of feature identifiability by modeling polysemantic features as sparse mixtures of underlying monosemantic concepts. Building on this framework, we introduce a new SAE training algorithm based on ``bias adaptation'', a technique that adaptively adjusts neural network bias parameters to ensure appropriate activation sparsity. We theoretically \\highlight{prove that this algorithm correctly recovers all monosemantic features} when input data is sampled from our proposed statistical model. Furthermore, we develop an improved empirical variant, Group Bias Adaptation (GBA), and \\highlight{demonstrate its superior performance against benchmark methods when applied to LLMs with up to 1.5 billion parameters}. This work represents a foundational step in demystifying SAE training by providing the first SAE algorithm with theoretical recovery guarantees, thereby advancing the development of more transparent and trustworthy AI systems through enhanced mechanistic interpretability.", "AI": {"tldr": "提出了一种基于统计框架的稀疏自编码器（SAE）训练算法，通过“偏置适应”技术恢复单义特征，并在理论和实证上验证其优越性。", "motivation": "解决现有SAE训练算法缺乏数学保证和实际局限（如超参数敏感性和不稳定性）的问题。", "method": "提出统计框架和“偏置适应”算法，理论证明其能恢复单义特征，并开发改进的实证变体GBA。", "result": "理论证明算法能正确恢复单义特征，实证显示GBA在15亿参数LLM上优于基准方法。", "conclusion": "该工作为SAE训练提供了首个理论保证，推动了AI系统的透明性和可解释性。"}}
{"id": "2506.14294", "categories": ["cs.RO", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.14294", "abs": "https://arxiv.org/abs/2506.14294", "authors": ["Prashant Kumar Rai", "Elham Kowsari", "Nataliya Strokina", "Reza Ghabcheloo"], "title": "Uncertainty-Driven Radar-Inertial Fusion for Instantaneous 3D Ego-Velocity Estimation", "comment": "This paper has been accepted for presentation at the 28th International Conference on Information Fusion (Fusion 2025)", "summary": "We present a method for estimating ego-velocity in autonomous navigation by integrating high-resolution imaging radar with an inertial measurement unit. The proposed approach addresses the limitations of traditional radar-based ego-motion estimation techniques by employing a neural network to process complex-valued raw radar data and estimate instantaneous linear ego-velocity along with its associated uncertainty. This uncertainty-aware velocity estimate is then integrated with inertial measurement unit data using an Extended Kalman Filter. The filter leverages the network-predicted uncertainty to refine the inertial sensor's noise and bias parameters, improving the overall robustness and accuracy of the ego-motion estimation. We evaluated the proposed method on the publicly available ColoRadar dataset. Our approach achieves significantly lower error compared to the closest publicly available method and also outperforms both instantaneous and scan matching-based techniques.", "AI": {"tldr": "提出了一种结合高分辨率成像雷达和惯性测量单元的自主导航方法，通过神经网络处理雷达数据并估计瞬时线性速度及其不确定性，再与惯性数据融合，显著提升了运动估计的精度和鲁棒性。", "motivation": "传统雷达运动估计方法存在局限性，需要更精确且鲁棒的技术来支持自主导航。", "method": "使用神经网络处理复数雷达数据，估计速度及不确定性，再通过扩展卡尔曼滤波与惯性数据融合。", "result": "在ColoRadar数据集上验证，误差显著低于现有方法，优于瞬时和扫描匹配技术。", "conclusion": "该方法通过不确定性感知和传感器融合，显著提升了自主导航中的运动估计性能。"}}
{"id": "2506.14256", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14256", "abs": "https://arxiv.org/abs/2506.14256", "authors": ["Deepak Ghimire", "Joonwhoan Lee"], "title": "Comparison of Two Methods for Stationary Incident Detection Based on Background Image", "comment": "8 pages, 6 figures", "summary": "In general, background subtraction-based methods are used to detect moving objects in visual tracking applications. In this paper, we employed a background subtraction-based scheme to detect the temporarily stationary objects. We proposed two schemes for stationary object detection, and we compare those in terms of detection performance and computational complexity. In the first approach, we used a single background, and in the second approach, we used dual backgrounds, generated with different learning rates, in order to detect temporarily stopped objects. Finally, we used normalized cross correlation (NCC) based image comparison to monitor and track the detected stationary object in a video scene. The proposed method is robust with partial occlusion, short-time fully occlusion, and illumination changes, and it can operate in real time.", "AI": {"tldr": "提出了一种基于背景减除的静止物体检测方法，比较了单背景和双背景两种方案的性能与复杂度，并通过NCC图像比对实现实时跟踪。", "motivation": "传统背景减除方法主要用于移动物体检测，本文旨在解决暂时静止物体的检测问题。", "method": "采用单背景和双背景（不同学习率生成）两种方案，结合NCC图像比对进行检测与跟踪。", "result": "方法对部分遮挡、短暂完全遮挡和光照变化具有鲁棒性，且能实时运行。", "conclusion": "提出的双背景方案在检测性能和复杂度之间取得平衡，适用于实际场景。"}}
{"id": "2506.14003", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14003", "abs": "https://arxiv.org/abs/2506.14003", "authors": ["Yiwei Chen", "Soumyadeep Pal", "Yimeng Zhang", "Qing Qu", "Sijia Liu"], "title": "Unlearning Isn't Invisible: Detecting Unlearning Traces in LLMs from Model Outputs", "comment": null, "summary": "Machine unlearning (MU) for large language models (LLMs), commonly referred to as LLM unlearning, seeks to remove specific undesirable data or knowledge from a trained model, while maintaining its performance on standard tasks. While unlearning plays a vital role in protecting data privacy, enforcing copyright, and mitigating sociotechnical harms in LLMs, we identify a new vulnerability post-unlearning: unlearning trace detection. We discover that unlearning leaves behind persistent ''fingerprints'' in LLMs, detectable traces in both model behavior and internal representations. These traces can be identified from output responses, even when prompted with forget-irrelevant inputs. Specifically, a simple supervised classifier can reliably determine whether a model has undergone unlearning based solely on its textual outputs. Further analysis shows that these traces are embedded in intermediate activations and propagate nonlinearly to the final layer, forming low-dimensional, learnable manifolds in activation space. Through extensive experiments, we show that forget-relevant prompts enable over 90% accuracy in detecting unlearning traces across all model sizes. Even with forget-irrelevant inputs, large LLMs maintain high detectability, demonstrating the broad applicability of unlearning trace detection. These findings reveal that unlearning leaves measurable signatures, introducing a new risk of reverse-engineering forgotten information when a model is identified as unlearned given an input query. Codes are available at [this URL](https://github.com/OPTML-Group/Unlearn-Trace).", "AI": {"tldr": "论文发现大型语言模型（LLM）在遗忘学习（unlearning）后会留下可检测的痕迹，这些痕迹可以通过简单的分类器从输出中识别，揭示了遗忘学习可能带来的新风险。", "motivation": "研究旨在揭示LLM遗忘学习后留下的可检测痕迹，以评估其潜在隐私和安全风险。", "method": "通过监督分类器分析模型输出和内部表示，检测遗忘学习的痕迹，并实验验证其有效性。", "result": "实验表明，遗忘相关提示的检测准确率超过90%，即使无关输入下大型LLM仍保持高可检测性。", "conclusion": "遗忘学习会在LLM中留下可测量的痕迹，可能被逆向工程还原遗忘信息，带来新的隐私和安全风险。"}}
{"id": "2506.14305", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14305", "abs": "https://arxiv.org/abs/2506.14305", "authors": ["Zhirui Sun", "Xingrong Diao", "Yao Wang", "Bi-Ke Zhu", "Jiankun Wang"], "title": "Socially Aware Robot Crowd Navigation via Online Uncertainty-Driven Risk Adaptation", "comment": null, "summary": "Navigation in human-robot shared crowded environments remains challenging, as robots are expected to move efficiently while respecting human motion conventions. However, many existing approaches emphasize safety or efficiency while overlooking social awareness. This article proposes Learning-Risk Model Predictive Control (LR-MPC), a data-driven navigation algorithm that balances efficiency, safety, and social awareness. LR-MPC consists of two phases: an offline risk learning phase, where a Probabilistic Ensemble Neural Network (PENN) is trained using risk data from a heuristic MPC-based baseline (HR-MPC), and an online adaptive inference phase, where local waypoints are sampled and globally guided by a Multi-RRT planner. Each candidate waypoint is evaluated for risk by PENN, and predictions are filtered using epistemic and aleatoric uncertainty to ensure robust decision-making. The safest waypoint is selected as the MPC input for real-time navigation. Extensive experiments demonstrate that LR-MPC outperforms baseline methods in success rate and social awareness, enabling robots to navigate complex crowds with high adaptability and low disruption. A website about this work is available at https://sites.google.com/view/lr-mpc.", "AI": {"tldr": "LR-MPC是一种数据驱动的导航算法，平衡效率、安全性和社交意识，通过离线风险学习和在线自适应推理实现高效导航。", "motivation": "在人与机器人共享的拥挤环境中，现有方法常忽视社交意识，LR-MPC旨在解决这一问题。", "method": "LR-MPC分为离线风险学习（使用PENN训练风险数据）和在线自适应推理（通过Multi-RRT规划器采样和评估路径点）。", "result": "实验表明，LR-MPC在成功率和社交意识上优于基线方法，适应性强且干扰低。", "conclusion": "LR-MPC为复杂人群环境中的机器人导航提供了一种高效、安全且社交意识强的解决方案。"}}
{"id": "2506.14265", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14265", "abs": "https://arxiv.org/abs/2506.14265", "authors": ["Siran Dai", "Qianqian Xu", "Peisong Wen", "Yang Liu", "Qingming Huang"], "title": "Exploring Non-contrastive Self-supervised Representation Learning for Image-based Profiling", "comment": "CVPR 2025 Computer Vision for Drug Discovery", "summary": "Image-based cell profiling aims to create informative representations of cell images. This technique is critical in drug discovery and has greatly advanced with recent improvements in computer vision. Inspired by recent developments in non-contrastive Self-Supervised Learning (SSL), this paper provides an initial exploration into training a generalizable feature extractor for cell images using such methods. However, there are two major challenges: 1) There is a large difference between the distributions of cell images and natural images, causing the view-generation process in existing SSL methods to fail; and 2) Unlike typical scenarios where each representation is based on a single image, cell profiling often involves multiple input images, making it difficult to effectively combine all available information. To overcome these challenges, we propose SSLProfiler, a non-contrastive SSL framework specifically designed for cell profiling. We introduce specialized data augmentation and representation post-processing methods tailored to cell images, which effectively address the issues mentioned above and result in a robust feature extractor. With these improvements, SSLProfiler won the Cell Line Transferability challenge at CVPR 2025.", "AI": {"tldr": "本文提出了一种名为SSLProfiler的非对比自监督学习框架，专门用于细胞图像分析，解决了现有方法在细胞图像分布和多重输入图像上的挑战。", "motivation": "细胞图像分析在药物发现中至关重要，但现有自监督学习方法在细胞图像上表现不佳，主要由于图像分布差异和多重输入问题。", "method": "设计了专门的数据增强和表示后处理方法，提出了SSLProfiler框架，以解决细胞图像的特殊需求。", "result": "SSLProfiler在CVPR 2025的Cell Line Transferability挑战中获胜，证明了其有效性。", "conclusion": "SSLProfiler为细胞图像分析提供了一种通用且鲁棒的特征提取方法，解决了现有技术的局限性。"}}
{"id": "2506.14020", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14020", "abs": "https://arxiv.org/abs/2506.14020", "authors": ["Keyue Jiang", "Jiahao Cui", "Xiaowen Dong", "Laura Toni"], "title": "Bures-Wasserstein Flow Matching for Graph Generation", "comment": null, "summary": "Graph generation has emerged as a critical task in fields ranging from molecule design to drug discovery. Contemporary approaches, notably diffusion and flow-based models, have achieved solid graph generative performance through constructing a probability path that interpolates between a reference distribution and the data distribution. However, these methods typically model the evolution of individual nodes and edges independently and use linear interpolations to build the path assuming that the data lie in Euclidean space. We show that this is suboptimal given the intrinsic non-Euclidean structure and interconnected patterns of graphs, and it poses risks to the sampling convergence. To build a better probability path, we model the joint evolution of the nodes and edges by representing graphs as connected systems parameterized by Markov random fields (MRF). We then leverage the optimal transport displacement between MRF objects to design the probability path for graph generation. Based on this, we introduce BWFlow, a flow-matching framework for graph generation that respects the underlying geometry of graphs and provides smooth velocities in the probability path. The novel framework can be adapted to both continuous and discrete flow-matching algorithms. Experimental evaluations in plain graph generation and 2D/3D molecule generation validate the effectiveness of BWFlow in graph generation with competitive performance, stable training, and guaranteed sampling convergence.", "AI": {"tldr": "论文提出了一种基于马尔可夫随机场（MRF）和最优传输的图生成方法BWFlow，解决了现有方法在非欧几里得图结构中的局限性。", "motivation": "现有图生成方法（如扩散和流模型）假设数据在欧几里得空间中，独立建模节点和边的演化，导致次优结果和采样收敛风险。", "method": "通过将图表示为MRF参数化的连接系统，利用最优传输设计概率路径，提出BWFlow框架，支持连续和离散流匹配算法。", "result": "实验表明，BWFlow在普通图和2D/3D分子生成中表现优异，训练稳定且采样收敛性有保障。", "conclusion": "BWFlow通过尊重图的几何结构，提供了一种更优的图生成方法。"}}
{"id": "2506.14317", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14317", "abs": "https://arxiv.org/abs/2506.14317", "authors": ["Zeyuan Chen", "Qiyang Yan", "Yuanpei Chen", "Tianhao Wu", "Jiyao Zhang", "Zihan Ding", "Jinzhou Li", "Yaodong Yang", "Hao Dong"], "title": "ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes", "comment": null, "summary": "Dexterous grasping in cluttered scenes presents significant challenges due to diverse object geometries, occlusions, and potential collisions. Existing methods primarily focus on single-object grasping or grasp-pose prediction without interaction, which are insufficient for complex, cluttered scenes. Recent vision-language-action models offer a potential solution but require extensive real-world demonstrations, making them costly and difficult to scale. To address these limitations, we revisit the sim-to-real transfer pipeline and develop key techniques that enable zero-shot deployment in reality while maintaining robust generalization. We propose ClutterDexGrasp, a two-stage teacher-student framework for closed-loop target-oriented dexterous grasping in cluttered scenes. The framework features a teacher policy trained in simulation using clutter density curriculum learning, incorporating both a novel geometry and spatially-embedded scene representation and a comprehensive safety curriculum, enabling general, dynamic, and safe grasping behaviors. Through imitation learning, we distill the teacher's knowledge into a student 3D diffusion policy (DP3) that operates on partial point cloud observations. To the best of our knowledge, this represents the first zero-shot sim-to-real closed-loop system for target-oriented dexterous grasping in cluttered scenes, demonstrating robust performance across diverse objects and layouts. More details and videos are available at https://clutterdexgrasp.github.io/.", "AI": {"tldr": "论文提出ClutterDexGrasp框架，通过两阶段师生模型实现杂乱场景中的灵巧抓取，支持零样本现实部署。", "motivation": "解决现有方法在复杂杂乱场景中灵巧抓取的不足，避免依赖大量真实数据。", "method": "采用师生框架，教师策略在模拟中训练，学生策略通过模仿学习从教师处提取知识，使用3D扩散策略处理部分点云观测。", "result": "首次实现零样本模拟到现实的闭环目标导向灵巧抓取系统，在多样物体和布局中表现稳健。", "conclusion": "ClutterDexGrasp为杂乱场景中的灵巧抓取提供了一种高效且可扩展的解决方案。"}}
{"id": "2506.14271", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14271", "abs": "https://arxiv.org/abs/2506.14271", "authors": ["Weiming Zhang", "Dingwen Xiao", "Aobotao Dai", "Yexin Liu", "Tianbo Pan", "Shiqi Wen", "Lei Chen", "Lin Wang"], "title": "Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment", "comment": "23 pages, 16 figures", "summary": "360 video captures the complete surrounding scenes with the ultra-large field of view of 360X180. This makes 360 scene understanding tasks, eg, segmentation and tracking, crucial for appications, such as autonomous driving, robotics. With the recent emergence of foundation models, the community is, however, impeded by the lack of large-scale, labelled real-world datasets. This is caused by the inherent spherical properties, eg, severe distortion in polar regions, and content discontinuities, rendering the annotation costly yet complex. This paper introduces Leader360V, the first large-scale, labeled real-world 360 video datasets for instance segmentation and tracking. Our datasets enjoy high scene diversity, ranging from indoor and urban settings to natural and dynamic outdoor scenes. To automate annotation, we design an automatic labeling pipeline, which subtly coordinates pre-trained 2D segmentors and large language models to facilitate the labeling. The pipeline operates in three novel stages. Specifically, in the Initial Annotation Phase, we introduce a Semantic- and Distortion-aware Refinement module, which combines object mask proposals from multiple 2D segmentors with LLM-verified semantic labels. These are then converted into mask prompts to guide SAM2 in generating distortion-aware masks for subsequent frames. In the Auto-Refine Annotation Phase, missing or incomplete regions are corrected either by applying the SDR again or resolving the discontinuities near the horizontal borders. The Manual Revision Phase finally incorporates LLMs and human annotators to further refine and validate the annotations. Extensive user studies and evaluations demonstrate the effectiveness of our labeling pipeline. Meanwhile, experiments confirm that Leader360V significantly enhances model performance for 360 video segmentation and tracking, paving the way for more scalable 360 scene understanding.", "AI": {"tldr": "论文介绍了Leader360V，首个大规模标注的真实世界360视频数据集，用于实例分割和跟踪，并提出了一种自动标注流程。", "motivation": "360视频的场景理解任务（如分割和跟踪）对自动驾驶和机器人等应用至关重要，但缺乏大规模标注数据集，主要由于球面特性（如极区严重失真）导致标注成本高且复杂。", "method": "设计了一个自动标注流程，结合预训练的2D分割器和大型语言模型（LLM），分三个阶段：初始标注（结合语义和失真感知细化）、自动细化标注（修正缺失或不完整区域）和手动修订（结合LLM和人工标注）。", "result": "用户研究和实验证明标注流程的有效性，Leader360V显著提升了360视频分割和跟踪的模型性能。", "conclusion": "Leader360V为更可扩展的360场景理解铺平了道路。"}}
{"id": "2506.14036", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14036", "abs": "https://arxiv.org/abs/2506.14036", "authors": ["Tatthapong Srikitrungruang", "Sina Aghaee Dabaghan Fard", "Matthew Lemon", "Jaesung Lee", "Yuxiao Zhou"], "title": "Robust Physics-Informed Neural Network Approach for Estimating Heterogeneous Elastic Properties from Noisy Displacement Data", "comment": null, "summary": "Accurately estimating spatially heterogeneous elasticity parameters, particularly Young's modulus and Poisson's ratio, from noisy displacement measurements remains significantly challenging in inverse elasticity problems. Existing inverse estimation techniques are often limited by instability, pronounced sensitivity to measurement noise, and difficulty in recovering absolute-scale Young's modulus. This work presents a novel Inverse Elasticity Physics-Informed Neural Network (IE-PINN) specifically designed to robustly reconstruct heterogeneous distributions of elasticity parameters from noisy displacement data based on linear elasticity physics. IE-PINN integrates three distinct neural network architectures dedicated to separately modeling displacement fields, strain fields, and elasticity distributions, thereby significantly enhancing stability and accuracy against measurement noise. Additionally, a two-phase estimation strategy is introduced: the first phase recovers relative spatial distributions of Young's modulus and Poisson's ratio, and the second phase calibrates the absolute scale of Young's modulus using imposed loading boundary conditions. Additional methodological innovations, including positional encoding, sine activation functions, and a sequential pretraining protocol, further enhance the model's performance and robustness. Extensive numerical experiments demonstrate that IE-PINN effectively overcomes critical limitations encountered by existing methods, delivering accurate absolute-scale elasticity estimations even under severe noise conditions. This advancement holds substantial potential for clinical imaging diagnostics and mechanical characterization, where measurements typically encounter substantial noise.", "AI": {"tldr": "提出了一种基于物理信息的神经网络（IE-PINN），用于从噪声位移数据中稳健地重建弹性参数分布，解决了现有方法的不稳定性和噪声敏感性问题。", "motivation": "现有弹性参数反演方法存在不稳定性、对噪声敏感以及难以恢复绝对尺度弹性模量的问题，需要一种更稳健的解决方案。", "method": "设计了IE-PINN，包含三个独立的神经网络分别建模位移场、应变场和弹性分布，并采用两阶段估计策略和多种创新技术（如位置编码、正弦激活函数等）提升性能。", "result": "实验表明，IE-PINN在严重噪声条件下仍能准确估计绝对尺度弹性参数，显著优于现有方法。", "conclusion": "IE-PINN为临床成像诊断和机械表征提供了潜在的重要工具，尤其在噪声环境下表现优异。"}}
{"id": "2506.14322", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14322", "abs": "https://arxiv.org/abs/2506.14322", "authors": ["Avigail Cohen Rimon", "Mirela Ben-Chen", "Or Litany"], "title": "FRIDU: Functional Map Refinement with Guided Image Diffusion", "comment": "Accepted to SGP 2025 (Symposium on Geometry Processing)", "summary": "We propose a novel approach for refining a given correspondence map between two shapes. A correspondence map represented as a functional map, namely a change of basis matrix, can be additionally treated as a 2D image. With this perspective, we train an image diffusion model directly in the space of functional maps, enabling it to generate accurate maps conditioned on an inaccurate initial map. The training is done purely in the functional space, and thus is highly efficient. At inference time, we use the pointwise map corresponding to the current functional map as guidance during the diffusion process. The guidance can additionally encourage different functional map objectives, such as orthogonality and commutativity with the Laplace-Beltrami operator. We show that our approach is competitive with state-of-the-art methods of map refinement and that guided diffusion models provide a promising pathway to functional map processing.", "AI": {"tldr": "提出了一种基于图像扩散模型的功能性地图优化方法，通过训练直接在功能性地图空间生成准确地图，并在推理时利用点对点地图作为指导。", "motivation": "功能性地图作为形状对应关系的表示，可以视为2D图像，但现有方法在优化功能性地图时存在效率或精度不足的问题。", "method": "训练图像扩散模型直接在功能性地图空间生成准确地图，推理时利用点对点地图指导扩散过程，并鼓励功能性地图目标（如正交性和与Laplace-Beltrami算子的交换性）。", "result": "该方法在功能性地图优化方面与最先进方法竞争，展示了引导扩散模型在功能性地图处理中的潜力。", "conclusion": "引导扩散模型为功能性地图处理提供了一条有前景的路径。"}}
{"id": "2506.14038", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14038", "abs": "https://arxiv.org/abs/2506.14038", "authors": ["Nabil Omi", "Siddhartha Sen", "Ali Farhadi"], "title": "Load Balancing Mixture of Experts with Similarity Preserving Routers", "comment": null, "summary": "Sparse Mixture of Experts (MoE) models offer a scalable and efficient architecture for training large neural networks by activating only a subset of parameters (\"experts\") for each input. A learned router computes a distribution over these experts, and assigns input tokens to a small subset. However, without auxiliary balancing mechanisms, routers often converge to using only a few experts, severely limiting model capacity and degrading performance. Most current load balancing mechanisms encourage a distribution over experts that resembles a roughly uniform distribution of experts per token. During training, this can result in inconsistent routing behavior, resulting in the model spending its capacity to learn redundant knowledge. We address this by introducing a novel load balancing loss that preserves token-wise relational structure, encouraging consistent expert choices for similar inputs during training. Our experimental results show that applying our loss to the router results in 36% faster convergence and lower redundancy compared to a popular load balancing loss.", "AI": {"tldr": "提出了一种新的负载均衡损失函数，用于稀疏混合专家模型（MoE），以保持输入间的相关性结构，提高训练效率和模型性能。", "motivation": "现有负载均衡机制可能导致路由器行为不一致，模型学习冗余知识，限制了性能和容量。", "method": "引入一种新的负载均衡损失函数，鼓励相似输入在训练期间选择相同的专家。", "result": "实验显示，新损失函数使收敛速度提高36%，并减少冗余。", "conclusion": "新方法有效提升了稀疏MoE模型的训练效率和性能。"}}
{"id": "2506.14405", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14405", "abs": "https://arxiv.org/abs/2506.14405", "authors": ["Jarkko Kotaniemi", "Janne Saukkoriipi", "Shuai Li", "Markku Suomalainen"], "title": "Data Driven Approach to Input Shaping for Vibration Suppression in a Flexible Robot Arm", "comment": "6 pages, 11 figures, robosoft2025 conference", "summary": "This paper presents a simple and effective method for setting parameters for an input shaper to suppress the residual vibrations in flexible robot arms using a data-driven approach. The parameters are adaptively tuned in the workspace of the robot by interpolating previously measured data of the robot's residual vibrations. Input shaping is a simple and robust technique to generate vibration-reduced shaped commands by a convolution of an impulse sequence with the desired input command. The generated impulses create waves in the material countering the natural vibrations of the system. The method is demonstrated with a flexible 3D-printed robot arm with multiple different materials, achieving a significant reduction in the residual vibrations.", "AI": {"tldr": "提出了一种基于数据驱动的方法，用于自适应调整柔性机械臂输入整形器的参数，以抑制残余振动。", "motivation": "柔性机械臂在运动时会产生残余振动，影响精度和性能，需要一种简单有效的方法来抑制这些振动。", "method": "通过插值先前测量的机器人残余振动数据，自适应调整输入整形器的参数。输入整形技术通过卷积脉冲序列与输入命令生成振动减少的整形命令。", "result": "在多种材料的3D打印柔性机械臂上验证了该方法，显著减少了残余振动。", "conclusion": "该方法简单有效，适用于柔性机械臂的振动抑制。"}}
{"id": "2506.14350", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.14350", "abs": "https://arxiv.org/abs/2506.14350", "authors": ["Zoubida Ameur", "Frédéric Lefebvre", "Philippe De Lagrange", "Miloš Radosavljević"], "title": "FGA-NN: Film Grain Analysis Neural Network", "comment": null, "summary": "Film grain, once a by-product of analog film, is now present in most cinematographic content for aesthetic reasons. However, when such content is compressed at medium to low bitrates, film grain is lost due to its random nature. To preserve artistic intent while compressing efficiently, film grain is analyzed and modeled before encoding and synthesized after decoding. This paper introduces FGA-NN, the first learning-based film grain analysis method to estimate conventional film grain parameters compatible with conventional synthesis. Quantitative and qualitative results demonstrate FGA-NN's superior balance between analysis accuracy and synthesis complexity, along with its robustness and applicability.", "AI": {"tldr": "FGA-NN是一种基于学习的胶片颗粒分析方法，用于在压缩和解码过程中保留胶片颗粒的艺术效果。", "motivation": "胶片颗粒是电影内容的美学元素，但在中低比特率压缩时会丢失。为高效压缩并保留艺术意图，需要分析、建模和合成胶片颗粒。", "method": "提出FGA-NN，首个基于学习的方法，用于估计与传统合成兼容的胶片颗粒参数。", "result": "定量和定性结果表明，FGA-NN在分析精度与合成复杂度之间取得了优越的平衡，且具有鲁棒性和适用性。", "conclusion": "FGA-NN为胶片颗粒的保留提供了一种高效且兼容传统合成的方法。"}}
{"id": "2506.14054", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14054", "abs": "https://arxiv.org/abs/2506.14054", "authors": ["Joshua Fan", "Haodi Xu", "Feng Tao", "Md Nasim", "Marc Grimson", "Yiqi Luo", "Carla P. Gomes"], "title": "Scientifically-Interpretable Reasoning Network (ScIReN): Uncovering the Black-Box of Nature", "comment": "28 pages, 9 figures, submitted to NeurIPS 2025", "summary": "Neural networks are a powerful tool for learning patterns from data. However, they do not respect known scientific laws, nor can they reveal novel scientific insights due to their black-box nature. In contrast, scientific reasoning distills biological or physical principles from observations and controlled experiments, and quantitatively interprets them with process-based models made of mathematical equations. Yet, process-based models rely on numerous free parameters that must be set in an ad-hoc manner, and thus often fit observations poorly in cross-scale predictions. While prior work has embedded process-based models in conventional neural networks, discovering interpretable relationships between parameters in process-based models and input features is still a grand challenge for scientific discovery. We thus propose Scientifically-Interpretable Reasoning Network (ScIReN), a fully-transparent framework that combines interpretable neural and process-based reasoning. An interpretable encoder predicts scientifically-meaningful latent parameters, which are then passed through a differentiable process-based decoder to predict labeled output variables. ScIReN also uses a novel hard-sigmoid constraint layer to restrict latent parameters to meaningful ranges defined by scientific prior knowledge, further enhancing its interpretability. While the embedded process-based model enforces established scientific knowledge, the encoder reveals new scientific mechanisms and relationships hidden in conventional black-box models. We apply ScIReN on two tasks: simulating the flow of organic carbon through soils, and modeling ecosystem respiration from plants. In both tasks, ScIReN outperforms black-box networks in predictive accuracy while providing substantial scientific interpretability -- it can infer latent scientific mechanisms and their relationships with input features.", "AI": {"tldr": "ScIReN是一个结合可解释神经网络和基于过程的模型的透明框架，旨在解决科学发现中的黑盒问题，同时提升预测准确性和科学可解释性。", "motivation": "传统神经网络缺乏科学可解释性，而基于过程的模型在跨尺度预测中表现不佳。ScIReN旨在结合两者的优势，实现科学发现的可解释性和准确性。", "method": "ScIReN通过可解释编码器预测科学意义的潜在参数，并通过可微分的过程解码器预测输出变量。引入硬Sigmoid约束层限制参数范围，增强可解释性。", "result": "在模拟土壤有机碳流动和植物生态系统呼吸任务中，ScIReN在预测准确性上优于黑盒模型，并能推断潜在科学机制。", "conclusion": "ScIReN成功结合了科学可解释性和预测性能，为科学发现提供了新工具。"}}
{"id": "2506.14422", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14422", "abs": "https://arxiv.org/abs/2506.14422", "authors": ["Akash Chikhalikar", "Ankit A. Ravankar", "Jose Victorio Salazar Luces", "Yasuhisa Hirata"], "title": "Enhancing Object Search in Indoor Spaces via Personalized Object-factored Ontologies", "comment": "8 pages, 9 figures. Accepted for publication in 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems", "summary": "Personalization is critical for the advancement of service robots. Robots need to develop tailored understandings of the environments they are put in. Moreover, they need to be aware of changes in the environment to facilitate long-term deployment. Long-term understanding as well as personalization is necessary to execute complex tasks like prepare dinner table or tidy my room. A precursor to such tasks is that of Object Search. Consequently, this paper focuses on locating and searching multiple objects in indoor environments. In this paper, we propose two crucial novelties. Firstly, we propose a novel framework that can enable robots to deduce Personalized Ontologies of indoor environments. Our framework consists of a personalization schema that enables the robot to tune its understanding of ontologies. Secondly, we propose an Adaptive Inferencing strategy. We integrate Dynamic Belief Updates into our approach which improves performance in multi-object search tasks. The cumulative effect of personalization and adaptive inferencing is an improved capability in long-term object search. This framework is implemented on top of a multi-layered semantic map. We conduct experiments in real environments and compare our results against various state-of-the-art (SOTA) methods to demonstrate the effectiveness of our approach. Additionally, we show that personalization can act as a catalyst to enhance the performance of SOTAs. Video Link: https://bit.ly/3WHk9i9", "AI": {"tldr": "论文提出了一种个性化框架和自适应推理策略，以提高机器人在室内环境中长期对象搜索的能力。", "motivation": "个性化对服务机器人的发展至关重要，机器人需要适应环境变化并执行复杂任务，如对象搜索。", "method": "提出个性化本体框架和自适应推理策略，结合动态信念更新，实现多对象搜索。", "result": "实验表明，该方法优于现有技术，个性化能进一步提升性能。", "conclusion": "个性化框架和自适应推理策略显著提升了机器人在长期对象搜索中的能力。"}}
{"id": "2506.14356", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14356", "abs": "https://arxiv.org/abs/2506.14356", "authors": ["Xiaoqi Wang", "Yi Wang", "Lap-Pui Chau"], "title": "EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization", "comment": null, "summary": "Egocentric video-language understanding demands both high efficiency and accurate spatial-temporal modeling. Existing approaches face three key challenges: 1) Excessive pre-training cost arising from multi-stage pre-training pipelines, 2) Ineffective spatial-temporal encoding due to manually split 3D rotary positional embeddings that hinder feature interactions, and 3) Imprecise learning objectives in soft-label multi-instance retrieval, which neglect negative pair correlations. In this paper, we introduce EVA02-AT, a suite of EVA02-based video-language foundation models tailored to egocentric video understanding tasks. EVA02-AT first efficiently transfers an image-based CLIP model into a unified video encoder via a single-stage pretraining. Second, instead of applying rotary positional embeddings to isolated dimensions, we introduce spatial-temporal rotary positional embeddings along with joint attention, which can effectively encode both spatial and temporal information on the entire hidden dimension. This joint encoding of spatial-temporal features enables the model to learn cross-axis relationships, which are crucial for accurately modeling motion and interaction in videos. Third, focusing on multi-instance video-language retrieval tasks, we introduce the Symmetric Multi-Similarity (SMS) loss and a novel training framework that advances all soft labels for both positive and negative pairs, providing a more precise learning objective. Extensive experiments on Ego4D, EPIC-Kitchens-100, and Charades-Ego under zero-shot and fine-tuning settings demonstrate that EVA02-AT achieves state-of-the-art performance across diverse egocentric video-language tasks with fewer parameters. Models with our SMS loss also show significant performance gains on multi-instance retrieval benchmarks. Our code and models are publicly available at https://github.com/xqwang14/EVA02-AT .", "AI": {"tldr": "EVA02-AT提出了一种高效的视频-语言基础模型，通过单阶段预训练、空间-时间旋转位置嵌入和对称多相似性损失，解决了现有方法的三个关键挑战，并在多个任务上实现了最佳性能。", "motivation": "现有方法在视频-语言理解中存在预训练成本高、空间-时间编码效果差和学习目标不精确的问题，EVA02-AT旨在解决这些问题。", "method": "1) 单阶段预训练；2) 空间-时间旋转位置嵌入与联合注意力；3) 对称多相似性损失（SMS）和新的训练框架。", "result": "在Ego4D、EPIC-Kitchens-100和Charades-Ego等数据集上，EVA02-AT在零样本和微调设置下均达到最优性能，且参数量更少。", "conclusion": "EVA02-AT通过高效预训练、改进的编码方式和精确的学习目标，显著提升了视频-语言理解任务的性能。"}}
{"id": "2506.14067", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14067", "abs": "https://arxiv.org/abs/2506.14067", "authors": ["Minjae Lee", "Yoonjae Jung", "Sangdon Park"], "title": "A Regret Perspective on Online Selective Generation", "comment": "10 pages", "summary": "Large language generative models increasingly interact with humans, while their falsified responses raise concerns. To address this hallucination effect, selectively abstaining from answering, called selective generation, provides an effective way for generators to control the hallucination when it is unsure of their answers. However, as selective generators are interacting under non-stochastic environments and having partial feedback from users on selective generation (e.g., thumbs up or down on the selected answer), learning methods for selective generation under such practical setups are crucial but currently missing. To address these limitations, we propose an online learning algorithm for selective generation under partial feedback. In particular, as learning under partial feedback is well-studied by multi-armed bandit problems, we reduce selective generation to bandits and provide a novel conversion lemma from bandits back to selective generation to leverage any known bandit algorithms and theoretical properties. This mainly connects regret guarantees of bandits to false discovery rate (FDR) guarantees of selective generation for controlling hallucination. However, naively exploiting known bandit algorithms and their regret bounds suffers from slow convergence speed in practice due the nature of partial feedback. To overcome this, we exploit a unique structure of arms in selective generation for feedback unlocking, i.e., unlocking unknown feedback from observed feedback. We theoretically and empirically evaluate the efficacy of the proposed online selective generation algorithm under partial feedback over diverse data environment setups, resulting in controlling a desired FDR, while maintaining reasonable selection efficiency, i.e., the ratio of non-abstaining answers, compared to baselines.", "AI": {"tldr": "论文提出了一种在线学习算法，用于在部分反馈下进行选择性生成，通过将问题转化为多臂老虎机问题并利用反馈解锁结构，有效控制幻觉效应。", "motivation": "大型语言生成模型在交互中可能产生虚假回答（幻觉效应），选择性生成（即不确定时拒绝回答）是一种解决方法，但目前缺乏在部分反馈环境下的学习方法。", "method": "将选择性生成问题转化为多臂老虎机问题，提出反馈解锁结构以加速收敛，并利用已知老虎机算法及其理论性质。", "result": "算法在多种数据环境下有效控制了假发现率（FDR），同时保持了合理的回答效率。", "conclusion": "该方法为部分反馈下的选择性生成提供了理论和实践支持，有效平衡了幻觉控制和回答效率。"}}
{"id": "2506.14467", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14467", "abs": "https://arxiv.org/abs/2506.14467", "authors": ["Nico Zevallos", "Cecilia G. Morales", "Andrew Orekhov", "Tejas Rane", "Hernando Gomez", "Francis X. Guyette", "Michael R. Pinsky", "John Galeotti", "Artur Dubrawski", "Howie Choset"], "title": "Automatic Cannulation of Femoral Vessels in a Porcine Shock Model", "comment": "2 pages, 2 figures, conference", "summary": "Rapid and reliable vascular access is critical in trauma and critical care. Central vascular catheterization enables high-volume resuscitation, hemodynamic monitoring, and advanced interventions like ECMO and REBOA. While peripheral access is common, central access is often necessary but requires specialized ultrasound-guided skills, posing challenges in prehospital settings. The complexity arises from deep target vessels and the precision needed for needle placement. Traditional techniques, like the Seldinger method, demand expertise to avoid complications. Despite its importance, ultrasound-guided central access is underutilized due to limited field expertise. While autonomous needle insertion has been explored for peripheral vessels, only semi-autonomous methods exist for femoral access. This work advances toward full automation, integrating robotic ultrasound for minimally invasive emergency procedures. Our key contribution is the successful femoral vein and artery cannulation in a porcine hemorrhagic shock model.", "AI": {"tldr": "论文探讨了在创伤和重症监护中实现快速可靠的中心血管通路的重要性，并提出了一种全自动机器人超声引导方法，成功在猪出血性休克模型中实现了股静脉和动脉插管。", "motivation": "中心血管通路在急救中至关重要，但传统方法依赖专业超声引导技能，限制了其在院前环境中的应用。", "method": "采用机器人超声引导技术，实现全自动股静脉和动脉插管。", "result": "在猪出血性休克模型中成功实现了股静脉和动脉的插管。", "conclusion": "全自动机器人超声引导技术有望解决中心血管通路在急救中的技术挑战。"}}
{"id": "2506.14362", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14362", "abs": "https://arxiv.org/abs/2506.14362", "authors": ["Daniele Rege Cambrin", "Eleonora Poeta", "Eliana Pastor", "Isaac Corley", "Tania Cerquitelli", "Elena Baralis", "Paolo Garza"], "title": "HydroChronos: Forecasting Decades of Surface Water Change", "comment": null, "summary": "Forecasting surface water dynamics is crucial for water resource management and climate change adaptation. However, the field lacks comprehensive datasets and standardized benchmarks. In this paper, we introduce HydroChronos, a large-scale, multi-modal spatiotemporal dataset for surface water dynamics forecasting designed to address this gap. We couple the dataset with three forecasting tasks. The dataset includes over three decades of aligned Landsat 5 and Sentinel-2 imagery, climate data, and Digital Elevation Models for diverse lakes and rivers across Europe, North America, and South America. We also propose AquaClimaTempo UNet, a novel spatiotemporal architecture with a dedicated climate data branch, as a strong benchmark baseline. Our model significantly outperforms a Persistence baseline for forecasting future water dynamics by +14% and +11% F1 across change detection and direction of change classification tasks, and by +0.1 MAE on the magnitude of change regression. Finally, we conduct an Explainable AI analysis to identify the key climate variables and input channels that influence surface water change, providing insights to inform and guide future modeling efforts.", "AI": {"tldr": "HydroChronos是一个用于地表水动态预测的大规模多模态时空数据集，填补了该领域缺乏综合数据和标准化基准的空白。", "motivation": "地表水动态预测对水资源管理和气候变化适应至关重要，但缺乏全面数据集和标准化基准。", "method": "提出HydroChronos数据集，包含30多年的Landsat 5和Sentinel-2影像、气候数据及数字高程模型，并设计AquaClimaTempo UNet模型作为基准。", "result": "模型在变化检测、变化方向分类和变化幅度回归任务中显著优于基线，F1分别提升14%、11%，MAE提升0.1。", "conclusion": "通过可解释AI分析识别关键气候变量和输入通道，为未来建模提供指导。"}}
{"id": "2506.14074", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.14074", "abs": "https://arxiv.org/abs/2506.14074", "authors": ["Nathaniel Pinckney", "Chenhui Deng", "Chia-Tung Ho", "Yun-Da Tsai", "Mingjie Liu", "Wenfei Zhou", "Brucek Khailany", "Haoxing Ren"], "title": "Comprehensive Verilog Design Problems: A Next-Generation Benchmark Dataset for Evaluating Large Language Models and Agents on RTL Design and Verification", "comment": "16 pages with appendix", "summary": "We present the Comprehensive Verilog Design Problems (CVDP) benchmark, a new dataset and infrastructure to advance LLM and agent research in hardware design and verification. CVDP includes 783 problems across 13 task categories, covering RTL generation, verification, debugging, specification alignment, and technical Q&A authored by experienced hardware engineers. Problems are offered in both non-agentic and agentic formats. The benchmark introduces more realistic and challenging contexts than prior work, with state-of-the-art models achieving no more than 34% pass@1 on code generation. Agentic tasks$\\unicode{x2013}$especially those involving RTL reuse and verification$\\unicode{x2013}$are particularly difficult. Evaluation uses open-source tools and model scoring infrastructure, with comprehension tasks assessed via BLEU and LLM-based judging. CVDP reveals substantial gaps in current model capabilities, underscoring the need for continued research toward robust, real-world hardware design automation.", "AI": {"tldr": "CVDP是一个新的硬件设计和验证基准数据集，包含783个问题，涵盖13个任务类别，旨在推动LLM和智能体研究。", "motivation": "当前模型在硬件设计和验证任务中表现不足，CVDP旨在提供更真实和挑战性的测试环境。", "method": "CVDP包含非智能体和智能体格式的问题，评估使用开源工具和模型评分基础设施，包括BLEU和LLM评分。", "result": "现有模型在代码生成任务中最高仅达到34%的通过率，智能体任务（如RTL重用和验证）尤为困难。", "conclusion": "CVDP揭示了当前模型的显著不足，强调了在硬件设计自动化领域继续研究的必要性。"}}
{"id": "2506.14487", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14487", "abs": "https://arxiv.org/abs/2506.14487", "authors": ["Paolo Franceschi", "Marco Faroni", "Stefano Baraldo", "Anna Valente"], "title": "ros2 fanuc interface: Design and Evaluation of a Fanuc CRX Hardware Interface in ROS2", "comment": null, "summary": "This paper introduces the ROS2 control and the Hardware Interface (HW) integration for the Fanuc CRX- robot family. It explains basic implementation details and communication protocols, and its integration with the Moveit2 motion planning library. We conducted a series of experiments to evaluate relevant performances in the robotics field. We tested the developed ros2_fanuc_interface for four relevant robotics cases: step response, trajectory tracking, collision avoidance integrated with Moveit2, and dynamic velocity scaling, respectively. Results show that, despite a non-negligible delay between command and feedback, the robot can track the defined path with negligible errors (if it complies with joint velocity limits), ensuring collision avoidance. Full code is open source and available at https://github.com/paolofrance/ros2_fanuc_interface.", "AI": {"tldr": "本文介绍了ROS2控制与Fanuc CRX机器人系列的硬件接口集成，包括实现细节、通信协议及与Moveit2运动规划库的整合。通过实验评估了性能，结果表明机器人能准确跟踪路径并避免碰撞。", "motivation": "为Fanuc CRX机器人系列提供ROS2控制与硬件接口的集成解决方案，以提升其在复杂任务中的性能。", "method": "开发了ros2_fanuc_interface，并通过四种机器人场景（阶跃响应、轨迹跟踪、碰撞避免和动态速度缩放）进行实验验证。", "result": "尽管存在命令与反馈间的延迟，机器人能准确跟踪路径（符合关节速度限制时），并实现碰撞避免。", "conclusion": "ROS2控制与Fanuc硬件接口的集成是可行的，代码已开源。"}}
{"id": "2506.14367", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14367", "abs": "https://arxiv.org/abs/2506.14367", "authors": ["Sumshun Nahar Eity", "Mahin Montasir Afif", "Tanisha Fairooz", "Md. Mortuza Ahmmed", "Md Saef Ullah Miah"], "title": "DGG-XNet: A Hybrid Deep Learning Framework for Multi-Class Brain Disease Classification with Explainable AI", "comment": null, "summary": "Accurate diagnosis of brain disorders such as Alzheimer's disease and brain tumors remains a critical challenge in medical imaging. Conventional methods based on manual MRI analysis are often inefficient and error-prone. To address this, we propose DGG-XNet, a hybrid deep learning model integrating VGG16 and DenseNet121 to enhance feature extraction and classification. DenseNet121 promotes feature reuse and efficient gradient flow through dense connectivity, while VGG16 contributes strong hierarchical spatial representations. Their fusion enables robust multiclass classification of neurological conditions. Grad-CAM is applied to visualize salient regions, enhancing model transparency. Trained on a combined dataset from BraTS 2021 and Kaggle, DGG-XNet achieved a test accuracy of 91.33\\%, with precision, recall, and F1-score all exceeding 91\\%. These results highlight DGG-XNet's potential as an effective and interpretable tool for computer-aided diagnosis (CAD) of neurodegenerative and oncological brain disorders.", "AI": {"tldr": "DGG-XNet是一种结合VGG16和DenseNet121的深度学习模型，用于提高脑部疾病的诊断准确性和效率，测试准确率达91.33%。", "motivation": "传统MRI分析方法效率低且易出错，需更准确的脑部疾病诊断工具。", "method": "融合VGG16和DenseNet121的DGG-XNet模型，结合Grad-CAM增强可解释性。", "result": "在BraTS 2021和Kaggle数据集上测试准确率为91.33%，各项指标均超过91%。", "conclusion": "DGG-XNet是一种高效且可解释的计算机辅助诊断工具。"}}
{"id": "2506.14087", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14087", "abs": "https://arxiv.org/abs/2506.14087", "authors": ["Zhongzheng Qiao", "Chenghao Liu", "Yiming Zhang", "Ming Jin", "Quang Pham", "Qingsong Wen", "P. N. Suganthan", "Xudong Jiang", "Savitha Ramasamy"], "title": "Multi-Scale Finetuning for Encoder-based Time Series Foundation Models", "comment": null, "summary": "Time series foundation models (TSFMs) demonstrate impressive zero-shot performance for time series forecasting. However, an important yet underexplored challenge is how to effectively finetune TSFMs on specific downstream tasks. While naive finetuning can yield performance gains, we argue that it falls short of fully leveraging TSFMs' capabilities, often resulting in overfitting and suboptimal performance. Given the diverse temporal patterns across sampling scales and the inherent multi-scale forecasting capabilities of TSFMs, we adopt a causal perspective to analyze finetuning process, through which we highlight the critical importance of explicitly modeling multiple scales and reveal the shortcomings of naive approaches. Focusing on \\textit{encoder-based} TSFMs, we propose \\textbf{M}ulti\\textbf{\\textsc{s}}cale \\textbf{\\textsc{f}}ine\\textbf{\\textsc{t}}uning (\\textbf{MSFT}), a simple yet general framework that explicitly integrates multi-scale modeling into the finetuning process. Experimental results on three different backbones (\\moirai, \\moment\\ and \\units) demonstrate that TSFMs finetuned with MSFT not only outperform naive and typical parameter efficient finetuning methods but also surpass state-of-the-art deep learning methods.", "AI": {"tldr": "论文提出了一种多尺度微调框架（MSFT），用于优化时间序列基础模型（TSFMs）在下游任务中的性能，解决了传统微调方法的不足。", "motivation": "传统微调方法未能充分利用TSFMs的多尺度预测能力，容易导致过拟合和性能不佳。", "method": "提出MSFT框架，通过显式建模多尺度来优化微调过程，适用于多种TSFM骨干模型。", "result": "实验表明，MSFT在多个骨干模型上优于传统微调和参数高效微调方法，甚至超越最先进的深度学习方法。", "conclusion": "MSFT是一种简单而通用的框架，能显著提升TSFMs在下游任务中的性能。"}}
{"id": "2506.14507", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14507", "abs": "https://arxiv.org/abs/2506.14507", "authors": ["Nitesh Subedi", "Adam Haroon", "Shreyan Ganguly", "Samuel T. K. Tetteh", "Prajwal Koirala", "Cody Fleming", "Soumik Sarkar"], "title": "Can Pretrained Vision-Language Embeddings Alone Guide Robot Navigation?", "comment": "6 figures, 2 tables, Accepted to Robotics: Science and Systems (RSS) 2025 Workshop on Robot Planning in the Era of Foundation Models (FM4RoboPlan)", "summary": "Foundation models have revolutionized robotics by providing rich semantic representations without task-specific training. While many approaches integrate pretrained vision-language models (VLMs) with specialized navigation architectures, the fundamental question remains: can these pretrained embeddings alone successfully guide navigation without additional fine-tuning or specialized modules? We present a minimalist framework that decouples this question by training a behavior cloning policy directly on frozen vision-language embeddings from demonstrations collected by a privileged expert. Our approach achieves a 74% success rate in navigation to language-specified targets, compared to 100% for the state-aware expert, though requiring 3.2 times more steps on average. This performance gap reveals that pretrained embeddings effectively support basic language grounding but struggle with long-horizon planning and spatial reasoning. By providing this empirical baseline, we highlight both the capabilities and limitations of using foundation models as drop-in representations for embodied tasks, offering critical insights for robotics researchers facing practical design tradeoffs between system complexity and performance in resource-constrained scenarios. Our code is available at https://github.com/oadamharoon/text2nav", "AI": {"tldr": "该论文探讨了预训练视觉语言模型（VLMs）是否能够单独指导机器人导航，而无需微调或专用模块。通过一个极简框架，直接在冻结的视觉语言嵌入上训练行为克隆策略，结果表明预训练嵌入能支持基本语言理解，但在长时规划和空间推理方面表现不足。", "motivation": "研究预训练视觉语言模型是否能够独立支持机器人导航任务，减少系统复杂性和资源需求。", "method": "训练一个行为克隆策略，直接基于冻结的视觉语言嵌入，使用特权专家收集的演示数据。", "result": "导航成功率74%，但比专家多花费3.2倍步骤，显示预训练嵌入在语言理解和长时规划上的局限性。", "conclusion": "预训练嵌入在机器人任务中具备潜力，但仍需改进长时规划和空间推理能力，为资源受限场景提供了设计权衡的参考。"}}
{"id": "2506.14373", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14373", "abs": "https://arxiv.org/abs/2506.14373", "authors": ["Junyeob Baek", "Hosung Lee", "Christopher Hoang", "Mengye Ren", "Sungjin Ahn"], "title": "Discrete JEPA: Learning Discrete Token Representations without Reconstruction", "comment": null, "summary": "The cornerstone of cognitive intelligence lies in extracting hidden patterns from observations and leveraging these principles to systematically predict future outcomes. However, current image tokenization methods demonstrate significant limitations in tasks requiring symbolic abstraction and logical reasoning capabilities essential for systematic inference. To address this challenge, we propose Discrete-JEPA, extending the latent predictive coding framework with semantic tokenization and novel complementary objectives to create robust tokenization for symbolic reasoning tasks. Discrete-JEPA dramatically outperforms baselines on visual symbolic prediction tasks, while striking visual evidence reveals the spontaneous emergence of deliberate systematic patterns within the learned semantic token space. Though an initial model, our approach promises a significant impact for advancing Symbolic world modeling and planning capabilities in artificial intelligence systems.", "AI": {"tldr": "论文提出Discrete-JEPA方法，通过语义标记化和新目标改进图像标记化，显著提升符号推理任务性能。", "motivation": "当前图像标记化方法在符号抽象和逻辑推理任务中存在局限性，无法满足系统性推断需求。", "method": "扩展潜在预测编码框架，引入语义标记化和互补目标，构建适用于符号推理的鲁棒标记化方法。", "result": "Discrete-JEPA在视觉符号预测任务中显著优于基线，学习到的语义标记空间自发形成系统性模式。", "conclusion": "该方法为人工智能系统的符号世界建模和规划能力提供了重要进展。"}}
{"id": "2506.14095", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14095", "abs": "https://arxiv.org/abs/2506.14095", "authors": ["Parikshit Ram", "Kenneth L. Clarkson", "Tim Klinger", "Shashanka Ubaru", "Alexander G. Gray"], "title": "Transformers Learn Faster with Semantic Focus", "comment": null, "summary": "Various forms of sparse attention have been explored to mitigate the quadratic computational and memory cost of the attention mechanism in transformers. We study sparse transformers not through a lens of efficiency but rather in terms of learnability and generalization. Empirically studying a range of attention mechanisms, we find that input-dependent sparse attention models appear to converge faster and generalize better than standard attention models, while input-agnostic sparse attention models show no such benefits -- a phenomenon that is robust across architectural and optimization hyperparameter choices. This can be interpreted as demonstrating that concentrating a model's \"semantic focus\" with respect to the tokens currently being considered (in the form of input-dependent sparse attention) accelerates learning. We develop a theoretical characterization of the conditions that explain this behavior. We establish a connection between the stability of the standard softmax and the loss function's Lipschitz properties, then show how sparsity affects the stability of the softmax and the subsequent convergence and generalization guarantees resulting from the attention mechanism. This allows us to theoretically establish that input-agnostic sparse attention does not provide any benefits. We also characterize conditions when semantic focus (input-dependent sparse attention) can provide improved guarantees, and we validate that these conditions are in fact met in our empirical evaluations.", "AI": {"tldr": "研究发现输入依赖的稀疏注意力模型比标准注意力模型收敛更快且泛化更好，而输入无关的稀疏注意力模型无此优势。理论分析表明，输入依赖的稀疏注意力通过集中模型的语义焦点加速学习。", "motivation": "探索稀疏注意力在可学习性和泛化性方面的表现，而非仅关注效率。", "method": "实证研究多种注意力机制，结合理论分析稀疏注意力对稳定性和泛化的影响。", "result": "输入依赖的稀疏注意力模型表现更优，输入无关的稀疏注意力模型无显著优势。", "conclusion": "输入依赖的稀疏注意力通过语义焦点加速学习，理论分析支持其优势。"}}
{"id": "2506.14513", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14513", "abs": "https://arxiv.org/abs/2506.14513", "authors": ["Farha Abdul Wasay", "Mohammed Abdul Rahman", "Hania Ghouse"], "title": "GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments", "comment": null, "summary": "The convergence of robotics and virtual reality (VR) has enabled safer and more efficient workflows in high-risk laboratory settings, particularly virology labs. As biohazard complexity increases, minimizing direct human exposure while maintaining precision becomes essential. We propose GAMORA (Gesture Articulated Meta Operative Robotic Arm), a novel VR-guided robotic system that enables remote execution of hazardous tasks using natural hand gestures. Unlike existing scripted automation or traditional teleoperation, GAMORA integrates the Oculus Quest 2, NVIDIA Jetson Nano, and Robot Operating System (ROS) to provide real-time immersive control, digital twin simulation, and inverse kinematics-based articulation. The system supports VR-based training and simulation while executing precision tasks in physical environments via a 3D-printed robotic arm. Inverse kinematics ensure accurate manipulation for delicate operations such as specimen handling and pipetting. The pipeline includes Unity-based 3D environment construction, real-time motion planning, and hardware-in-the-loop testing. GAMORA achieved a mean positional discrepancy of 2.2 mm (improved from 4 mm), pipetting accuracy within 0.2 mL, and repeatability of 1.2 mm across 50 trials. Integrated object detection via YOLOv8 enhances spatial awareness, while energy-efficient operation (50% reduced power output) ensures sustainable deployment. The system's digital-physical feedback loop enables safe, precise, and repeatable automation of high-risk lab tasks. GAMORA offers a scalable, immersive solution for robotic control and biosafety in biomedical research environments.", "AI": {"tldr": "GAMORA是一种基于VR的机器人系统，通过手势控制实现高风险实验室任务的远程精确操作，结合数字孪生和逆运动学，显著提高了安全性和效率。", "motivation": "随着生物危害复杂性的增加，减少直接人类接触同时保持操作精度成为关键需求。", "method": "系统整合Oculus Quest 2、NVIDIA Jetson Nano和ROS，提供实时沉浸式控制、数字孪生模拟和逆运动学操作，支持VR培训和实际任务执行。", "result": "GAMORA在50次试验中平均位置偏差为2.2毫米，移液精度0.2毫升，重复性1.2毫米，能耗降低50%。", "conclusion": "GAMORA为高风险实验室任务提供了一种可扩展、沉浸式的机器人控制解决方案，提升了生物安全性和操作效率。"}}
{"id": "2506.14382", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14382", "abs": "https://arxiv.org/abs/2506.14382", "authors": ["Ning Zhou", "Shanxiong Chen", "Mingting Zhou", "Haigang Sui", "Lieyun Hu", "Han Li", "Li Hua", "Qiming Zhou"], "title": "DepthSeg: Depth prompting in remote sensing semantic segmentation", "comment": null, "summary": "Remote sensing semantic segmentation is crucial for extracting detailed land surface information, enabling applications such as environmental monitoring, land use planning, and resource assessment. In recent years, advancements in artificial intelligence have spurred the development of automatic remote sensing semantic segmentation methods. However, the existing semantic segmentation methods focus on distinguishing spectral characteristics of different objects while ignoring the differences in the elevation of the different targets. This results in land cover misclassification in complex scenarios involving shadow occlusion and spectral confusion. In this paper, we introduce a depth prompting two-dimensional (2D) remote sensing semantic segmentation framework (DepthSeg). It automatically models depth/height information from 2D remote sensing images and integrates it into the semantic segmentation framework to mitigate the effects of spectral confusion and shadow occlusion. During the feature extraction phase of DepthSeg, we introduce a lightweight adapter to enable cost-effective fine-tuning of the large-parameter vision transformer encoder pre-trained by natural images. In the depth prompting phase, we propose a depth prompter to model depth/height features explicitly. In the semantic prediction phase, we introduce a semantic classification decoder that couples the depth prompts with high-dimensional land-cover features, enabling accurate extraction of land-cover types. Experiments on the LiuZhou dataset validate the advantages of the DepthSeg framework in land cover mapping tasks. Detailed ablation studies further highlight the significance of the depth prompts in remote sensing semantic segmentation.", "AI": {"tldr": "论文提出了一种深度提示的二维遥感语义分割框架（DepthSeg），通过建模深度/高度信息解决光谱混淆和阴影遮挡问题，提升了土地覆盖分类的准确性。", "motivation": "现有遥感语义分割方法主要关注光谱特征，忽略了目标的高度差异，导致复杂场景下的分类错误。", "method": "DepthSeg框架包含轻量级适配器、深度提示器和语义分类解码器，分别用于特征提取、深度建模和分类。", "result": "在LiuZhou数据集上的实验验证了DepthSeg在土地覆盖制图中的优势，消融研究突出了深度提示的重要性。", "conclusion": "DepthSeg通过整合深度信息，有效解决了光谱混淆和阴影遮挡问题，提升了遥感语义分割的准确性。"}}
{"id": "2506.14098", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14098", "abs": "https://arxiv.org/abs/2506.14098", "authors": ["Ziyuan Tang", "Jie Chen"], "title": "Toward a Graph Foundation Model: Pre-Training Transformers With Random Walks", "comment": null, "summary": "A foundation model like GPT elicits many emergent abilities, owing to the pre-training with broad inclusion of data and the use of the powerful Transformer architecture. While foundation models in natural languages are prevalent, can we build similar models for graphs? This paper describes an approach toward a graph foundation model that is pre-trained with diverse graph datasets by adapting the Transformer backbone. A central challenge toward this end is how a sequence model encodes graphs of varying sizes and from different domains. We propose representing a node as multiple random walks, such that the Transformer can extract node representations from sequences, which in turn form edge and graph representations. We develop a novel context prediction loss for these random walks and theoretically analyze their expressive power in distinguishing neighborhoods and graphs. We also demonstrate the pre-training of our model and its adaptation to downstream tasks, showcasing its potential as a foundation for processing and reasoning with graph-structured data.", "AI": {"tldr": "论文提出了一种基于Transformer的图基础模型，通过随机游走表示节点，解决了序列模型编码不同大小和领域图的挑战。", "motivation": "探索是否能为图数据构建类似GPT的基础模型，利用Transformer架构和多样图数据集进行预训练。", "method": "将节点表示为多个随机游走序列，利用Transformer提取节点表征，并提出新的上下文预测损失函数。", "result": "理论分析了随机游走的表达能力，并展示了模型在下游任务中的适应性。", "conclusion": "该模型有望成为图数据处理和推理的基础模型。"}}
{"id": "2506.14589", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14589", "abs": "https://arxiv.org/abs/2506.14589", "authors": ["Ren Xin", "Hongji Liu", "Xiaodong Mei", "Wenru Liu", "Maosheng Ye", "Zhili Chen", "Jun Ma"], "title": "NetRoller: Interfacing General and Specialized Models for End-to-End Autonomous Driving", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Integrating General Models (GMs) such as Large Language Models (LLMs), with Specialized Models (SMs) in autonomous driving tasks presents a promising approach to mitigating challenges in data diversity and model capacity of existing specialized driving models. However, this integration leads to problems of asynchronous systems, which arise from the distinct characteristics inherent in GMs and SMs. To tackle this challenge, we propose NetRoller, an adapter that incorporates a set of novel mechanisms to facilitate the seamless integration of GMs and specialized driving models. Specifically, our mechanisms for interfacing the asynchronous GMs and SMs are organized into three key stages. NetRoller first harvests semantically rich and computationally efficient representations from the reasoning processes of LLMs using an early stopping mechanism, which preserves critical insights on driving context while maintaining low overhead. It then applies learnable query embeddings, nonsensical embeddings, and positional layer embeddings to facilitate robust and efficient cross-modality translation. At last, it employs computationally efficient Query Shift and Feature Shift mechanisms to enhance the performance of SMs through few-epoch fine-tuning. Based on the mechanisms formalized in these three stages, NetRoller enables specialized driving models to operate at their native frequencies while maintaining situational awareness of the GM. Experiments conducted on the nuScenes dataset demonstrate that integrating GM through NetRoller significantly improves human similarity and safety in planning tasks, and it also achieves noticeable precision improvements in detection and mapping tasks for end-to-end autonomous driving. The code and models are available at https://github.com/Rex-sys-hk/NetRoller .", "AI": {"tldr": "NetRoller是一个适配器，通过三个阶段的新机制，将通用模型（GMs）与专用驾驶模型（SMs）无缝集成，解决了异步系统问题，提升了自动驾驶任务的表现。", "motivation": "现有专用驾驶模型在数据多样性和模型能力上存在挑战，而将通用模型（如LLMs）与专用模型集成可以缓解这些问题，但会引发异步系统问题。", "method": "NetRoller通过三个阶段实现集成：1）从LLMs中提取语义丰富且计算高效的表示；2）使用可学习查询嵌入等机制实现跨模态翻译；3）通过Query Shift和Feature Shift机制增强专用模型性能。", "result": "在nuScenes数据集上的实验表明，NetRoller显著提升了规划任务的人类相似性和安全性，并在检测和映射任务中实现了精度提升。", "conclusion": "NetRoller成功解决了通用模型与专用驾驶模型集成的异步问题，为自动驾驶任务提供了高效且性能优越的解决方案。"}}
{"id": "2506.14384", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14384", "abs": "https://arxiv.org/abs/2506.14384", "authors": ["Huan Kang", "Hui Li", "Xiao-Jun Wu", "Tianyang Xu", "Rui Wang", "Chunyang Cheng", "Josef Kittler"], "title": "GrFormer: A Novel Transformer on Grassmann Manifold for Infrared and Visible Image Fusion", "comment": "16 pages, 11 figures", "summary": "In the field of image fusion, promising progress has been made by modeling data from different modalities as linear subspaces.\n  However, in practice, the source images are often located in a non-Euclidean space, where the Euclidean methods usually cannot\n  encapsulate the intrinsic topological structure. Typically, the inner product performed in the Euclidean space calculates the algebraic\n  similarity rather than the semantic similarity, which results in undesired attention output and a decrease in fusion performance.\n  While the balance of low-level details and high-level semantics should be considered in infrared and visible image fusion task. To\n  address this issue, in this paper, we propose a novel attention mechanism based on Grassmann manifold for infrared and visible\n  image fusion (GrFormer). Specifically, our method constructs a low-rank subspace mapping through projection constraints on the\n  Grassmann manifold, compressing attention features into subspaces of varying rank levels. This forces the features to decouple into\n  high-frequency details (local low-rank) and low-frequency semantics (global low-rank), thereby achieving multi-scale semantic\n  fusion. Additionally, to effectively integrate the significant information, we develop a cross-modal fusion strategy (CMS) based on\n  a covariance mask to maximise the complementary properties between different modalities and to suppress the features with high\n  correlation, which are deemed redundant. The experimental results demonstrate that our network outperforms SOTA methods both\n  qualitatively and quantitatively on multiple image fusion benchmarks. The codes are available at https://github.com/Shaoyun2023.", "AI": {"tldr": "论文提出了一种基于Grassmann流形的新型注意力机制（GrFormer），用于红外和可见光图像融合，通过多尺度语义融合提升性能。", "motivation": "现有欧几里得方法无法捕捉非欧几里得空间中图像的固有拓扑结构，导致语义相似性不足和融合性能下降。", "method": "利用Grassmann流形构建低秩子空间映射，通过投影约束将注意力特征压缩到不同秩级别的子空间中，实现高、低频特征的解耦。同时提出基于协方差掩码的跨模态融合策略（CMS）。", "result": "实验表明，该方法在多个图像融合基准上定性和定量均优于现有最优方法。", "conclusion": "GrFormer通过Grassmann流形和CMS策略有效提升了图像融合的语义和细节表现。"}}
{"id": "2506.14113", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14113", "abs": "https://arxiv.org/abs/2506.14113", "authors": ["Yitian Zhang", "Liheng Ma", "Antonios Valkanas", "Boris N. Oreshkin", "Mark Coates"], "title": "SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting", "comment": null, "summary": "Koopman operator theory provides a framework for nonlinear dynamical system analysis and time-series forecasting by mapping dynamics to a space of real-valued measurement functions, enabling a linear operator representation. Despite the advantage of linearity, the operator is generally infinite-dimensional. Therefore, the objective is to learn measurement functions that yield a tractable finite-dimensional Koopman operator approximation. In this work, we establish a connection between Koopman operator approximation and linear Recurrent Neural Networks (RNNs), which have recently demonstrated remarkable success in sequence modeling. We show that by considering an extended state consisting of lagged observations, we can establish an equivalence between a structured Koopman operator and linear RNN updates. Building on this connection, we present SKOLR, which integrates a learnable spectral decomposition of the input signal with a multilayer perceptron (MLP) as the measurement functions and implements a structured Koopman operator via a highly parallel linear RNN stack. Numerical experiments on various forecasting benchmarks and dynamical systems show that this streamlined, Koopman-theory-based design delivers exceptional performance.", "AI": {"tldr": "该论文通过建立Koopman算子与线性RNN之间的联系，提出了一种基于Koopman理论的SKOLR方法，用于非线性动态系统分析和时间序列预测。", "motivation": "Koopman算子理论为非线性动态系统分析提供了线性化框架，但其无限维特性限制了实际应用。因此，目标是学习测量函数以获得有限维近似。", "method": "通过扩展状态（包含滞后观测）建立Koopman算子与线性RNN的等价性，提出SKOLR方法，结合可学习谱分解和多层感知机（MLP）实现结构化Koopman算子。", "result": "在多个预测基准和动态系统上的数值实验表明，SKOLR方法表现出卓越性能。", "conclusion": "基于Koopman理论的SKOLR方法通过线性RNN实现结构化算子，为非线性系统分析提供了高效且性能优异的解决方案。"}}
{"id": "2506.14608", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14608", "abs": "https://arxiv.org/abs/2506.14608", "authors": ["Erik Bauer", "Elvis Nava", "Robert K. Katzschmann"], "title": "Latent Action Diffusion for Cross-Embodiment Manipulation", "comment": "14 pages, 6 figures", "summary": "End-to-end learning approaches offer great potential for robotic manipulation, but their impact is constrained by data scarcity and heterogeneity across different embodiments. In particular, diverse action spaces across different end-effectors create barriers for cross-embodiment learning and skill transfer. We address this challenge through diffusion policies learned in a latent action space that unifies diverse end-effector actions. We first show that we can learn a semantically aligned latent action space for anthropomorphic robotic hands, a human hand, and a parallel jaw gripper using encoders trained with a contrastive loss. Second, we show that by using our proposed latent action space for co-training on manipulation data from different end-effectors, we can utilize a single policy for multi-robot control and obtain up to 13% improved manipulation success rates, indicating successful skill transfer despite a significant embodiment gap. Our approach using latent cross-embodiment policies presents a new method to unify different action spaces across embodiments, enabling efficient multi-robot control and data sharing across robot setups. This unified representation significantly reduces the need for extensive data collection for each new robot morphology, accelerates generalization across embodiments, and ultimately facilitates more scalable and efficient robotic learning.", "AI": {"tldr": "提出了一种基于潜在动作空间的扩散策略，用于统一不同末端执行器的动作空间，实现跨机器人形态的技能迁移和多机器人控制。", "motivation": "解决端到端学习方法中数据稀缺和不同机器人形态动作空间异构的问题，促进跨机器人形态的技能迁移和数据共享。", "method": "通过对比损失训练的编码器学习语义对齐的潜在动作空间，并利用该空间进行多机器人数据的联合训练。", "result": "在跨机器人形态的控制中，单一策略的操纵成功率提高了13%，实现了显著的技能迁移。", "conclusion": "潜在跨形态动作为统一不同机器人形态的动作空间提供了新方法，减少了数据收集需求，加速了跨形态的泛化能力。"}}
{"id": "2506.14399", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14399", "abs": "https://arxiv.org/abs/2506.14399", "authors": ["Tian Xia", "Fabio De Sousa Ribeiro", "Rajat R Rasal", "Avinash Kori", "Raghav Mehta", "Ben Glocker"], "title": "Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models", "comment": null, "summary": "Counterfactual image generation aims to simulate realistic visual outcomes under specific causal interventions. Diffusion models have recently emerged as a powerful tool for this task, combining DDIM inversion with conditional generation via classifier-free guidance (CFG). However, standard CFG applies a single global weight across all conditioning variables, which can lead to poor identity preservation and spurious attribute changes - a phenomenon known as attribute amplification. To address this, we propose Decoupled Classifier-Free Guidance (DCFG), a flexible and model-agnostic framework that introduces group-wise conditioning control. DCFG builds on an attribute-split embedding strategy that disentangles semantic inputs, enabling selective guidance on user-defined attribute groups. For counterfactual generation, we partition attributes into intervened and invariant sets based on a causal graph and apply distinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show that DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility, enabling more faithful and interpretable counterfactual image generation.", "AI": {"tldr": "论文提出了一种解耦的无分类器引导（DCFG）方法，用于改进反事实图像生成中的干预保真度和属性控制。", "motivation": "标准无分类器引导（CFG）在全局权重下可能导致身份保持不佳和虚假属性变化（属性放大），因此需要更灵活的属性控制方法。", "method": "提出DCFG框架，通过属性分组嵌入策略解耦语义输入，对干预和不变属性组分别应用不同的引导。", "result": "在CelebA-HQ、MIMIC-CXR和EMBED数据集上，DCFG提高了干预保真度，减少了意外变化，并增强了可逆性。", "conclusion": "DCFG能够生成更忠实和可解释的反事实图像。"}}
{"id": "2506.14114", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14114", "abs": "https://arxiv.org/abs/2506.14114", "authors": ["Khushnood Abbas", "Ruizhe Hou", "Zhou Wengang", "Dong Shi", "Niu Ling", "Satyaki Nan", "Alireza Abbasi"], "title": "Evaluating Loss Functions for Graph Neural Networks: Towards Pretraining and Generalization", "comment": "ACM single column 633 pages", "summary": "Graph Neural Networks (GNNs) became useful for learning on non-Euclidean data. However, their best performance depends on choosing the right model architecture and the training objective, also called the loss function. Researchers have studied these parts separately, but a large-scale evaluation has not looked at how GNN models and many loss functions work together across different tasks. To fix this, we ran a thorough study - it included seven well-known GNN architectures. We also used a large group of 30 single plus mixed loss functions. The study looked at both inductive and transductive settings. Our evaluation spanned three distinct real-world datasets, assessing performance in both inductive and transductive settings using 21 comprehensive evaluation metrics. From these extensive results (detailed in supplementary information 1 \\& 2), we meticulously analyzed the top ten model-loss combinations for each metric based on their average rank. Our findings reveal that, especially for the inductive case: 1) Hybrid loss functions generally yield superior and more robust performance compared to single loss functions, indicating the benefit of multi-objective optimization. 2) The GIN architecture always showed the highest-level average performance, especially with Cross-Entropy loss. 3) Although some combinations had overall lower average ranks, models such as GAT, particularly with certain hybrid losses, demonstrated incredible specialized strengths, maximizing the most top-1 results among the individual metrics, emphasizing subtle strengths for particular task demands. 4) On the other hand, the MPNN architecture typically lagged behind the scenarios it was tested against.", "AI": {"tldr": "本文通过大规模评估研究了GNN模型与多种损失函数的组合表现，发现混合损失函数在归纳任务中表现更优，GIN架构整体表现最佳，而MPNN表现较差。", "motivation": "现有研究未全面评估GNN模型与多种损失函数的组合效果，本文旨在填补这一空白。", "method": "使用7种GNN架构和30种损失函数，在三种真实数据集上评估归纳和转导任务的表现。", "result": "混合损失函数表现更优，GIN架构整体最佳，GAT在某些任务中表现突出，MPNN表现较差。", "conclusion": "混合损失函数和多目标优化对GNN性能提升显著，不同架构在不同任务中各有优势。"}}
{"id": "2506.14648", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14648", "abs": "https://arxiv.org/abs/2506.14648", "authors": ["Hexian Ni", "Tao Lu", "Haoyuan Hu", "Yinghao Cai", "Shuo Wang"], "title": "SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning", "comment": "8 pages, 8 figures", "summary": "Preference-based Reinforcement Learning (PbRL) methods provide a solution to avoid reward engineering by learning reward models based on human preferences. However, poor feedback- and sample- efficiency still remain the problems that hinder the application of PbRL. In this paper, we present a novel efficient query selection and preference-guided exploration method, called SENIOR, which could select the meaningful and easy-to-comparison behavior segment pairs to improve human feedback-efficiency and accelerate policy learning with the designed preference-guided intrinsic rewards. Our key idea is twofold: (1) We designed a Motion-Distinction-based Selection scheme (MDS). It selects segment pairs with apparent motion and different directions through kernel density estimation of states, which is more task-related and easy for human preference labeling; (2) We proposed a novel preference-guided exploration method (PGE). It encourages the exploration towards the states with high preference and low visits and continuously guides the agent achieving the valuable samples. The synergy between the two mechanisms could significantly accelerate the progress of reward and policy learning. Our experiments show that SENIOR outperforms other five existing methods in both human feedback-efficiency and policy convergence speed on six complex robot manipulation tasks from simulation and four real-worlds.", "AI": {"tldr": "SENIOR是一种基于偏好的强化学习方法，通过高效查询选择和偏好引导探索，显著提高了人类反馈效率和策略学习速度。", "motivation": "避免奖励工程的需求，同时解决现有PbRL方法中反馈和样本效率低的问题。", "method": "设计了基于运动区分的选择方案（MDS）和偏好引导探索方法（PGE），分别优化查询选择和探索策略。", "result": "在六项复杂机器人操作任务中，SENIOR在反馈效率和策略收敛速度上优于五种现有方法。", "conclusion": "SENIOR通过结合MDS和PGE，显著提升了PbRL的效率和性能。"}}
{"id": "2506.14404", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14404", "abs": "https://arxiv.org/abs/2506.14404", "authors": ["Nikos Spyrou", "Athanasios Vlontzos", "Paraskevas Pegios", "Thomas Melistas", "Nefeli Gkouti", "Yannis Panagakis", "Giorgos Papanastasiou", "Sotirios A. Tsaftaris"], "title": "Causally Steered Diffusion for Automated Video Counterfactual Generation", "comment": null, "summary": "Adapting text-to-image (T2I) latent diffusion models for video editing has shown strong visual fidelity and controllability, but challenges remain in maintaining causal relationships in video content. Edits affecting causally dependent attributes risk generating unrealistic or misleading outcomes if these relationships are ignored. In this work, we propose a causally faithful framework for counterfactual video generation, guided by a vision-language model (VLM). Our method is agnostic to the underlying video editing system and does not require access to its internal mechanisms or finetuning. Instead, we guide the generation by optimizing text prompts based on an assumed causal graph, addressing the challenge of latent space control in LDMs. We evaluate our approach using standard video quality metrics and counterfactual-specific criteria, such as causal effectiveness and minimality. Our results demonstrate that causally faithful video counterfactuals can be effectively generated within the learned distribution of LDMs through prompt-based causal steering. With its compatibility with any black-box video editing system, our method holds significant potential for generating realistic \"what-if\" video scenarios in diverse areas such as healthcare and digital media.", "AI": {"tldr": "该论文提出了一种基于因果关系的视频编辑框架，利用视觉语言模型（VLM）生成反事实视频，无需修改底层视频编辑系统。", "motivation": "现有文本到图像（T2I）扩散模型在视频编辑中难以保持因果关系的真实性，可能导致不现实或误导性的结果。", "method": "通过优化基于因果图的文本提示，引导视频生成，无需访问或微调底层编辑系统。", "result": "实验表明，该方法能有效生成因果一致的反事实视频，并通过标准视频质量指标和反事实特定标准验证。", "conclusion": "该方法兼容任何黑盒视频编辑系统，在医疗和数字媒体等领域具有广泛应用潜力。"}}
{"id": "2506.14122", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14122", "abs": "https://arxiv.org/abs/2506.14122", "authors": ["Tianming Zhang", "Renbo Zhang", "Zhengyi Yang", "Yunjun Gao", "Bin Cao", "Jing Fan"], "title": "CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs", "comment": null, "summary": "Temporal Betweenness Centrality (TBC) measures how often a node appears on optimal temporal paths, reflecting its importance in temporal networks. However, exact computation is highly expensive, and real-world TBC distributions are extremely imbalanced. The severe imbalance leads learning-based models to overfit to zero-centrality nodes, resulting in inaccurate TBC predictions and failure to identify truly central nodes. Existing graph neural network (GNN) methods either fail to handle such imbalance or ignore temporal dependencies altogether. To address these issues, we propose a scalable and inductive contrastive learning-based GNN (CLGNN) for accurate and efficient TBC prediction. CLGNN builds an instance graph to preserve path validity and temporal order, then encodes structural and temporal features using dual aggregation, i.e., mean and edge-to-node multi-head attention mechanisms, enhanced by temporal path count and time encodings. A stability-based clustering-guided contrastive module (KContrastNet) is introduced to separate high-, median-, and low-centrality nodes in representation space, mitigating class imbalance, while a regression module (ValueNet) estimates TBC values. CLGNN also supports multiple optimal path definitions to accommodate diverse temporal semantics. Extensive experiments demonstrate the effectiveness and efficiency of CLGNN across diverse benchmarks. CLGNN achieves up to a 663.7~$\\times$ speedup compared to state-of-the-art exact TBC computation methods. It outperforms leading static GNN baselines with up to 31.4~$\\times$ lower MAE and 16.7~$\\times$ higher Spearman correlation, and surpasses state-of-the-art temporal GNNs with up to 5.7~$\\times$ lower MAE and 3.9~$\\times$ higher Spearman correlation.", "AI": {"tldr": "论文提出了一种基于对比学习的图神经网络（CLGNN），用于高效准确地预测时间中介中心性（TBC），解决了现有方法在处理数据不平衡和忽略时间依赖性的问题。", "motivation": "时间中介中心性（TBC）的计算成本高且分布极不平衡，导致学习模型容易过拟合零中心性节点，无法准确预测和识别关键节点。现有图神经网络方法未能有效解决这些问题。", "method": "提出CLGNN，通过构建实例图保留路径有效性和时间顺序，采用双重聚合（均值和边到节点多头注意力）编码结构和时间特征，并引入基于稳定性的对比模块（KContrastNet）和回归模块（ValueNet）来缓解类别不平衡和估计TBC值。", "result": "CLGNN在多个基准测试中表现出色，相比现有方法实现了最高663.7倍的加速，MAE降低31.4倍，Spearman相关性提高16.7倍。", "conclusion": "CLGNN是一种高效且准确的时间中介中心性预测方法，能够有效处理数据不平衡和时间依赖性，适用于多种时间语义场景。"}}
{"id": "2506.14690", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14690", "abs": "https://arxiv.org/abs/2506.14690", "authors": ["Kalliyan Velasco", "Timothy W. McLain", "Joshua G. Mangelson"], "title": "Factor-Graph-Based Passive Acoustic Navigation for Decentralized Cooperative Localization Using Bearing Elevation Depth Difference", "comment": null, "summary": "Accurate and scalable underwater multi-agent localization remains a critical challenge due to the constraints of underwater communication. In this work, we propose a multi-agent localization framework using a factor-graph representation that incorporates bearing, elevation, and depth difference (BEDD). Our method leverages inverted ultra-short baseline (inverted-USBL) derived azimuth and elevation measurements from incoming acoustic signals and relative depth measurements to enable cooperative localization for a multi-robot team of autonomous underwater vehicles (AUVs). We validate our approach in the HoloOcean underwater simulator with a fleet of AUVs, demonstrating improved localization accuracy compared to dead reckoning. Additionally, we investigate the impact of azimuth and elevation measurement outliers, highlighting the need for robust outlier rejection techniques for acoustic signals.", "AI": {"tldr": "提出了一种基于因子图的多智能体水下定位框架，结合BEDD测量，利用倒置超短基线技术，提高了定位精度。", "motivation": "水下通信限制导致多智能体定位困难，需解决准确性和可扩展性问题。", "method": "使用因子图表示，结合BEDD测量（方位、仰角、深度差），利用倒置-USBL技术和声学信号进行协作定位。", "result": "在HoloOcean模拟器中验证，定位精度优于航位推算，并发现声学信号异常值的影响。", "conclusion": "需开发鲁棒的异常值剔除技术以进一步提升定位性能。"}}
{"id": "2506.14418", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14418", "abs": "https://arxiv.org/abs/2506.14418", "authors": ["Jiayi Chen", "Yanbiao Ma", "Andi Zhang", "Weidong Tang", "Wei Dai", "Bowei Liu"], "title": "Compositional Attribute Imbalance in Vision Datasets", "comment": null, "summary": "Visual attribute imbalance is a common yet underexplored issue in image classification, significantly impacting model performance and generalization. In this work, we first define the first-level and second-level attributes of images and then introduce a CLIP-based framework to construct a visual attribute dictionary, enabling automatic evaluation of image attributes. By systematically analyzing both single-attribute imbalance and compositional attribute imbalance, we reveal how the rarity of attributes affects model performance. To tackle these challenges, we propose adjusting the sampling probability of samples based on the rarity of their compositional attributes. This strategy is further integrated with various data augmentation techniques (such as CutMix, Fmix, and SaliencyMix) to enhance the model's ability to represent rare attributes. Extensive experiments on benchmark datasets demonstrate that our method effectively mitigates attribute imbalance, thereby improving the robustness and fairness of deep neural networks. Our research highlights the importance of modeling visual attribute distributions and provides a scalable solution for long-tail image classification tasks.", "AI": {"tldr": "本文提出了一种基于CLIP的框架，通过构建视觉属性字典解决图像分类中的属性不平衡问题，并通过调整采样概率和数据增强技术提升模型性能。", "motivation": "视觉属性不平衡是图像分类中常见但未被充分研究的问题，显著影响模型性能和泛化能力。", "method": "定义图像的一级和二级属性，引入CLIP框架构建视觉属性字典，分析单属性和组合属性不平衡，提出基于属性稀有度的采样调整策略，并结合数据增强技术。", "result": "实验表明，该方法有效缓解了属性不平衡问题，提升了深度神经网络的鲁棒性和公平性。", "conclusion": "研究强调了建模视觉属性分布的重要性，并为长尾图像分类任务提供了可扩展的解决方案。"}}
{"id": "2506.14126", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14126", "abs": "https://arxiv.org/abs/2506.14126", "authors": ["Stefan Horoi", "Guy Wolf", "Eugene Belilovsky", "Gintare Karolina Dziugaite"], "title": "Less is More: Undertraining Experts Improves Model Upcycling", "comment": null, "summary": "Modern deep learning is increasingly characterized by the use of open-weight foundation models that can be fine-tuned on specialized datasets. This has led to a proliferation of expert models and adapters, often shared via platforms like HuggingFace and AdapterHub. To leverage these resources, numerous model upcycling methods have emerged, enabling the reuse of fine-tuned models in multi-task systems. A natural pipeline has thus formed to harness the benefits of transfer learning and amortize sunk training costs: models are pre-trained on general data, fine-tuned on specific tasks, and then upcycled into more general-purpose systems. A prevailing assumption is that improvements at one stage of this pipeline propagate downstream, leading to gains at subsequent steps. In this work, we challenge that assumption by examining how expert fine-tuning affects model upcycling. We show that long fine-tuning of experts that optimizes for their individual performance leads to degraded merging performance, both for fully fine-tuned and LoRA-adapted models, and to worse downstream results when LoRA adapters are upcycled into MoE layers. We trace this degradation to the memorization of a small set of difficult examples that dominate late fine-tuning steps and are subsequently forgotten during merging. Finally, we demonstrate that a task-dependent aggressive early stopping strategy can significantly improve upcycling performance.", "AI": {"tldr": "研究发现，专家模型的长时间微调会降低模型合并性能，影响下游任务表现，而早期停止策略可以改善这一现象。", "motivation": "探讨专家微调对模型升级的影响，挑战现有假设。", "method": "分析长时间微调对模型合并和下游任务的影响，提出早期停止策略。", "result": "长时间微调导致模型合并性能下降，早期停止策略显著改善结果。", "conclusion": "优化微调策略对模型升级至关重要。"}}
{"id": "2506.14727", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14727", "abs": "https://arxiv.org/abs/2506.14727", "authors": ["Huihan Liu", "Rutav Shah", "Shuijing Liu", "Jack Pittenger", "Mingyo Seo", "Yuchen Cui", "Yonatan Bisk", "Roberto Martín-Martín", "Yuke Zhu"], "title": "Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models", "comment": null, "summary": "Assistive teleoperation, where control is shared between a human and a robot, enables efficient and intuitive human-robot collaboration in diverse and unstructured environments. A central challenge in real-world assistive teleoperation is for the robot to infer a wide range of human intentions from user control inputs and to assist users with correct actions. Existing methods are either confined to simple, predefined scenarios or restricted to task-specific data distributions at training, limiting their support for real-world assistance. We introduce Casper, an assistive teleoperation system that leverages commonsense knowledge embedded in pre-trained visual language models (VLMs) for real-time intent inference and flexible skill execution. Casper incorporates an open-world perception module for a generalized understanding of novel objects and scenes, a VLM-powered intent inference mechanism that leverages commonsense reasoning to interpret snippets of teleoperated user input, and a skill library that expands the scope of prior assistive teleoperation systems to support diverse, long-horizon mobile manipulation tasks. Extensive empirical evaluation, including human studies and system ablations, demonstrates that Casper improves task performance, reduces human cognitive load, and achieves higher user satisfaction than direct teleoperation and assistive teleoperation baselines.", "AI": {"tldr": "Casper是一个辅助远程操作系统，利用预训练的视觉语言模型（VLMs）进行实时意图推断和灵活技能执行，提升任务表现并降低用户认知负担。", "motivation": "现有方法局限于简单预定义场景或任务特定数据分布，无法支持真实世界的多样化辅助需求。", "method": "Casper结合开放世界感知模块、VLM驱动的意图推断机制和技能库，支持多样化的移动操作任务。", "result": "实验表明，Casper在任务表现、认知负荷和用户满意度上优于直接远程操作和现有辅助系统。", "conclusion": "Casper通过通用意图推断和灵活技能执行，显著提升了辅助远程操作的实用性和用户体验。"}}
{"id": "2506.14428", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14428", "abs": "https://arxiv.org/abs/2506.14428", "authors": ["Ruihao Xi", "Xuekuan Wang", "Yongcheng Li", "Shuhua Li", "Zichen Wang", "Yiwei Wang", "Feng Wei", "Cairong Zhao"], "title": "Toward Rich Video Human-Motion2D Generation", "comment": null, "summary": "Generating realistic and controllable human motions, particularly those involving rich multi-character interactions, remains a significant challenge due to data scarcity and the complexities of modeling inter-personal dynamics. To address these limitations, we first introduce a new large-scale rich video human motion 2D dataset (Motion2D-Video-150K) comprising 150,000 video sequences. Motion2D-Video-150K features a balanced distribution of diverse single-character and, crucially, double-character interactive actions, each paired with detailed textual descriptions. Building upon this dataset, we propose a novel diffusion-based rich video human motion2D generation (RVHM2D) model. RVHM2D incorporates an enhanced textual conditioning mechanism utilizing either dual text encoders (CLIP-L/B) or T5-XXL with both global and local features. We devise a two-stage training strategy: the model is first trained with a standard diffusion objective, and then fine-tuned using reinforcement learning with an FID-based reward to further enhance motion realism and text alignment. Extensive experiments demonstrate that RVHM2D achieves leading performance on the Motion2D-Video-150K benchmark in generating both single and interactive double-character scenarios.", "AI": {"tldr": "论文提出了一种基于扩散模型的RVHM2D方法，用于生成逼真且可控的2D人体动作，并引入了一个新的大规模数据集Motion2D-Video-150K。", "motivation": "解决多角色交互动作生成中的数据稀缺和建模复杂性挑战。", "method": "提出RVHM2D模型，采用双文本编码器和两阶段训练策略（扩散目标+强化学习）。", "result": "RVHM2D在Motion2D-Video-150K数据集上表现优异，支持单角色和双角色交互动作生成。", "conclusion": "RVHM2D在生成逼真且文本对齐的2D人体动作方面具有领先性能。"}}
{"id": "2506.14143", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14143", "abs": "https://arxiv.org/abs/2506.14143", "authors": ["Hayden McTavish", "Zachery Boner", "Jon Donnelly", "Margo Seltzer", "Cynthia Rudin"], "title": "Leveraging Predictive Equivalence in Decision Trees", "comment": "Accepted to ICML 2025", "summary": "Decision trees are widely used for interpretable machine learning due to their clearly structured reasoning process. However, this structure belies a challenge we refer to as predictive equivalence: a given tree's decision boundary can be represented by many different decision trees. The presence of models with identical decision boundaries but different evaluation processes makes model selection challenging. The models will have different variable importance and behave differently in the presence of missing values, but most optimization procedures will arbitrarily choose one such model to return. We present a boolean logical representation of decision trees that does not exhibit predictive equivalence and is faithful to the underlying decision boundary. We apply our representation to several downstream machine learning tasks. Using our representation, we show that decision trees are surprisingly robust to test-time missingness of feature values; we address predictive equivalence's impact on quantifying variable importance; and we present an algorithm to optimize the cost of reaching predictions.", "AI": {"tldr": "论文提出了一种布尔逻辑表示方法，解决了决策树中预测等价性问题，并展示了其在多个下游任务中的应用。", "motivation": "决策树因其可解释性被广泛使用，但其决策边界可由多种不同结构的树表示，导致模型选择困难。", "method": "提出了一种布尔逻辑表示方法，避免预测等价性，并忠实于决策边界。", "result": "展示了决策树对特征缺失的鲁棒性，解决了变量重要性量化问题，并提出了一种优化预测成本的算法。", "conclusion": "布尔逻辑表示方法有效解决了预测等价性问题，并提升了决策树在多个任务中的表现。"}}
{"id": "2506.14754", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14754", "abs": "https://arxiv.org/abs/2506.14754", "authors": ["Carolina Higuera", "Akash Sharma", "Taosha Fan", "Chaithanya Krishna Bodduluri", "Byron Boots", "Michael Kaess", "Mike Lambeta", "Tingfan Wu", "Zixi Liu", "Francois Robert Hogan", "Mustafa Mukadam"], "title": "Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation", "comment": null, "summary": "We present Sparsh-X, the first multisensory touch representations across four tactile modalities: image, audio, motion, and pressure. Trained on ~1M contact-rich interactions collected with the Digit 360 sensor, Sparsh-X captures complementary touch signals at diverse temporal and spatial scales. By leveraging self-supervised learning, Sparsh-X fuses these modalities into a unified representation that captures physical properties useful for robot manipulation tasks. We study how to effectively integrate real-world touch representations for both imitation learning and tactile adaptation of sim-trained policies, showing that Sparsh-X boosts policy success rates by 63% over an end-to-end model using tactile images and improves robustness by 90% in recovering object states from touch. Finally, we benchmark Sparsh-X ability to make inferences about physical properties, such as object-action identification, material-quantity estimation, and force estimation. Sparsh-X improves accuracy in characterizing physical properties by 48% compared to end-to-end approaches, demonstrating the advantages of multisensory pretraining for capturing features essential for dexterous manipulation.", "AI": {"tldr": "Sparsh-X是首个融合四种触觉模态（图像、音频、运动和压力）的多感官触觉表征方法，通过自监督学习统一表征，显著提升机器人操作任务的成功率和鲁棒性。", "motivation": "研究多感官触觉表征在机器人操作任务中的应用，以弥补传统端到端模型在触觉信号处理上的不足。", "method": "利用Digit 360传感器收集约100万次接触交互数据，通过自监督学习融合四种触觉模态为统一表征。", "result": "Sparsh-X将策略成功率提升63%，鲁棒性提升90%，并在物理属性推断任务中准确率提高48%。", "conclusion": "多感官预训练能有效捕捉灵巧操作所需的关键特征，显著优于端到端方法。"}}
{"id": "2506.14435", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14435", "abs": "https://arxiv.org/abs/2506.14435", "authors": ["Hongyu Wang", "Jiayu Xu", "Ruiping Wang", "Yan Feng", "Yitao Zhai", "Peng Pei", "Xunliang Cai", "Xilin Chen"], "title": "MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models", "comment": "Work in progress", "summary": "Large multimodal Mixture-of-Experts (MoEs) effectively scale the model size to boost performance while maintaining fixed active parameters. However, previous works primarily utilized full-precision experts during sparse up-cycling. Despite they show superior performance on end tasks, the large amount of experts introduces higher memory footprint, which poses significant challenges for the deployment on edge devices. In this work, we propose MoTE, a scalable and memory-efficient approach to train Mixture-of-Ternary-Experts models from dense checkpoint. Instead of training fewer high-precision experts, we propose to train more low-precision experts during up-cycling. Specifically, we use the pre-trained FFN as a shared expert and train ternary routed experts with parameters in {-1, 0, 1}. Extensive experiments show that our approach has promising scaling trend along model size. MoTE achieves comparable performance to full-precision baseline MoE-LLaVA while offering lower memory footprint. Furthermore, our approach is compatible with post-training quantization methods and the advantage further amplifies when memory-constraint goes lower. Given the same amount of expert memory footprint of 3.4GB and combined with post-training quantization, MoTE outperforms MoE-LLaVA by a gain of 4.3% average accuracy on end tasks, demonstrating its effectiveness and potential for memory-constrained devices.", "AI": {"tldr": "MoTE提出了一种内存高效的混合三元专家模型训练方法，通过低精度专家减少内存占用，同时保持性能。", "motivation": "解决多模态混合专家模型在边缘设备上部署时的高内存占用问题。", "method": "使用预训练的FFN作为共享专家，训练三元路由专家（参数为{-1, 0, 1}），并兼容后训练量化方法。", "result": "MoTE在相同内存占用下性能接近全精度基线，结合量化后性能提升4.3%。", "conclusion": "MoTE是一种适用于内存受限设备的有效方法，具有扩展潜力。"}}
{"id": "2506.14162", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14162", "abs": "https://arxiv.org/abs/2506.14162", "authors": ["Amirhossein Rajabpour", "Kiarash Aghakasiri", "Sandra Zilles", "Levi H. S. Lelis"], "title": "Common Benchmarks Undervalue the Generalization Power of Programmatic Policies", "comment": "17 pages, 5 figures", "summary": "Algorithms for learning programmatic representations for sequential decision-making problems are often evaluated on out-of-distribution (OOD) problems, with the common conclusion that programmatic policies generalize better than neural policies on OOD problems. In this position paper, we argue that commonly used benchmarks undervalue the generalization capabilities of programmatic representations. We analyze the experiments of four papers from the literature and show that neural policies, which were shown not to generalize, can generalize as effectively as programmatic policies on OOD problems. This is achieved with simple changes in the neural policies training pipeline. Namely, we show that simpler neural architectures with the same type of sparse observation used with programmatic policies can help attain OOD generalization. Another modification we have shown to be effective is the use of reward functions that allow for safer policies (e.g., agents that drive slowly can generalize better). Also, we argue for creating benchmark problems highlighting concepts needed for OOD generalization that may challenge neural policies but align with programmatic representations, such as tasks requiring algorithmic constructs like stacks.", "AI": {"tldr": "论文认为现有基准低估了程序化表示在OOD问题上的泛化能力，通过简单修改神经网络策略的训练流程，可以实现与程序化策略相当的泛化性能。", "motivation": "现有基准通常认为程序化策略在OOD问题上泛化能力优于神经网络策略，但作者认为这种结论低估了神经网络的潜力。", "method": "分析四篇文献的实验，提出通过简化神经网络架构、使用稀疏观察和调整奖励函数（如鼓励安全策略）来提升泛化能力。", "result": "实验表明，经过调整的神经网络策略在OOD问题上可以达到与程序化策略相当的泛化性能。", "conclusion": "建议设计新的基准问题，突出OOD泛化所需的概念（如算法结构），以更公平地评估不同策略的泛化能力。"}}
{"id": "2506.14763", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14763", "abs": "https://arxiv.org/abs/2506.14763", "authors": ["Chunru Lin", "Haotian Yuan", "Yian Wang", "Xiaowen Qiu", "Tsun-Hsuan Wang", "Minghao Guo", "Bohan Wang", "Yashraj Narang", "Dieter Fox", "Chuang Gan"], "title": "RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills", "comment": null, "summary": "Endowing robots with tool design abilities is critical for enabling them to solve complex manipulation tasks that would otherwise be intractable. While recent generative frameworks can automatically synthesize task settings, such as 3D scenes and reward functions, they have not yet addressed the challenge of tool-use scenarios. Simply retrieving human-designed tools might not be ideal since many tools (e.g., a rolling pin) are difficult for robotic manipulators to handle. Furthermore, existing tool design approaches either rely on predefined templates with limited parameter tuning or apply generic 3D generation methods that are not optimized for tool creation. To address these limitations, we propose RobotSmith, an automated pipeline that leverages the implicit physical knowledge embedded in vision-language models (VLMs) alongside the more accurate physics provided by physics simulations to design and use tools for robotic manipulation. Our system (1) iteratively proposes tool designs using collaborative VLM agents, (2) generates low-level robot trajectories for tool use, and (3) jointly optimizes tool geometry and usage for task performance. We evaluate our approach across a wide range of manipulation tasks involving rigid, deformable, and fluid objects. Experiments show that our method consistently outperforms strong baselines in terms of both task success rate and overall performance. Notably, our approach achieves a 50.0\\% average success rate, significantly surpassing other baselines such as 3D generation (21.4%) and tool retrieval (11.1%). Finally, we deploy our system in real-world settings, demonstrating that the generated tools and their usage plans transfer effectively to physical execution, validating the practicality and generalization capabilities of our approach.", "AI": {"tldr": "论文提出RobotSmith，一种自动化工具设计和使用管道，结合视觉语言模型和物理仿真，优化工具几何和使用方式，显著提升机器人任务成功率。", "motivation": "解决机器人工具设计和使用中的挑战，如现有人工设计工具不适合机器人操作，且现有方法依赖模板或通用3D生成，未针对工具优化。", "method": "通过协作视觉语言模型代理迭代提出工具设计，生成低级机器人轨迹，并联合优化工具几何和使用方式。", "result": "在多种任务中表现优异，平均成功率50.0%，远超3D生成（21.4%）和工具检索（11.1%）。", "conclusion": "RobotSmith在真实场景中验证了其有效性和泛化能力，为机器人工具设计提供了实用解决方案。"}}
{"id": "2506.14440", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14440", "abs": "https://arxiv.org/abs/2506.14440", "authors": ["David E. Hernandez", "Jose Chang", "Torbjörn E. M. Nordling"], "title": "Model compression using knowledge distillation with integrated gradients", "comment": "49 pages, 12 figures", "summary": "Model compression is critical for deploying deep learning models on resource-constrained devices. We introduce a novel method enhancing knowledge distillation with integrated gradients (IG) as a data augmentation strategy. Our approach overlays IG maps onto input images during training, providing student models with deeper insights into teacher models' decision-making processes. Extensive evaluation on CIFAR-10 demonstrates that our IG-augmented knowledge distillation achieves 92.6% testing accuracy with a 4.1x compression factor-a significant 1.1 percentage point improvement ($p<0.001$) over non-distilled models (91.5%). This compression reduces inference time from 140 ms to 13 ms. Our method precomputes IG maps before training, transforming substantial runtime costs into a one-time preprocessing step. Our comprehensive experiments include: (1) comparisons with attention transfer, revealing complementary benefits when combined with our approach; (2) Monte Carlo simulations confirming statistical robustness; (3) systematic evaluation of compression factor versus accuracy trade-offs across a wide range (2.2x-1122x); and (4) validation on an ImageNet subset aligned with CIFAR-10 classes, demonstrating generalisability beyond the initial dataset. These extensive ablation studies confirm that IG-based knowledge distillation consistently outperforms conventional approaches across varied architectures and compression ratios. Our results establish this framework as a viable compression technique for real-world deployment on edge devices while maintaining competitive accuracy.", "AI": {"tldr": "论文提出了一种基于集成梯度（IG）增强的知识蒸馏方法，显著提升了模型压缩效果，并在CIFAR-10上实现了92.6%的测试准确率。", "motivation": "在资源受限设备上部署深度学习模型需要高效的压缩技术，传统方法在压缩率和准确性之间存在权衡。", "method": "通过将IG图叠加到输入图像上，增强学生模型对教师模型决策过程的理解，同时将IG图预处理为一次性步骤以减少运行时开销。", "result": "在CIFAR-10上实现了92.6%的测试准确率，压缩因子为4.1倍，推理时间从140毫秒降至13毫秒。", "conclusion": "IG增强的知识蒸馏方法在多种架构和压缩比下均优于传统方法，适用于边缘设备的实际部署。"}}
{"id": "2506.14770", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14770", "abs": "https://arxiv.org/abs/2506.14770", "authors": ["Zixuan Chen", "Mazeyu Ji", "Xuxin Cheng", "Xuanbin Peng", "Xue Bin Peng", "Xiaolong Wang"], "title": "GMT: General Motion Tracking for Humanoid Whole-Body Control", "comment": null, "summary": "The ability to track general whole-body motions in the real world is a useful way to build general-purpose humanoid robots. However, achieving this can be challenging due to the temporal and kinematic diversity of the motions, the policy's capability, and the difficulty of coordination of the upper and lower bodies. To address these issues, we propose GMT, a general and scalable motion-tracking framework that trains a single unified policy to enable humanoid robots to track diverse motions in the real world. GMT is built upon two core components: an Adaptive Sampling strategy and a Motion Mixture-of-Experts (MoE) architecture. The Adaptive Sampling automatically balances easy and difficult motions during training. The MoE ensures better specialization of different regions of the motion manifold. We show through extensive experiments in both simulation and the real world the effectiveness of GMT, achieving state-of-the-art performance across a broad spectrum of motions using a unified general policy. Videos and additional information can be found at https://gmt-humanoid.github.io.", "AI": {"tldr": "GMT是一种通用且可扩展的运动跟踪框架，通过自适应采样和运动混合专家架构，训练统一策略使仿人机器人跟踪多样化运动。", "motivation": "解决仿人机器人在真实世界中跟踪多样化运动时面临的时空和运动学多样性、策略能力及上下半身协调困难等问题。", "method": "提出GMT框架，包含自适应采样策略和运动混合专家架构，前者平衡训练中的难易运动，后者优化运动流形的不同区域。", "result": "在仿真和真实世界实验中，GMT表现出色，使用统一策略在广泛运动范围内达到最先进性能。", "conclusion": "GMT通过自适应采样和混合专家架构，成功实现了仿人机器人对多样化运动的高效跟踪。"}}
{"id": "2506.14451", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14451", "abs": "https://arxiv.org/abs/2506.14451", "authors": ["Aditya Shourya", "Michel Dumontier", "Chang Sun"], "title": "Adapting Lightweight Vision Language Models for Radiological Visual Question Answering", "comment": null, "summary": "Recent advancements in vision-language systems have improved the accuracy of Radiological Visual Question Answering (VQA) Models. However, some challenges remain across each stage of model development: limited expert-labeled images hinders data procurement at scale; the intricate and nuanced patterns of radiological images make modeling inherently difficult; and the lack of evaluation evaluation efforts makes it difficult to identify cases where the model might be ill-conditioned. In this study, we fine-tune a lightweight 3B parameter vision-language model for Radiological VQA, demonstrating that small models, when appropriately tuned with curated data, can achieve robust performance across both open- and closed-ended questions. We propose a cost-effective training pipeline from synthetic question-answer pair generation to multi-stage fine-tuning on specialised radiological domain-targeted datasets (e.g., ROCO v2.0, MedPix v2.0). Our results show that despite operating at a fraction of the scale of state-of-the-art models such as LLaVA-Med, our model achieves promising performance given its small parameter size and the limited scale of training data. We introduce a lightweight saliency-based diagnostic tool that enables domain experts to inspect VQA model performance and identify ill-conditioned failure modes through saliency analysis.", "AI": {"tldr": "该研究针对放射学视觉问答（VQA）模型开发中的挑战，提出了一种轻量级3B参数视觉语言模型的微调方法，通过合成数据生成和多阶段微调，实现了在有限数据和规模下的稳健性能。", "motivation": "放射学VQA模型开发面临数据稀缺、图像模式复杂和缺乏评估工具的挑战，研究旨在通过轻量级模型和高效训练方法解决这些问题。", "method": "使用合成问题-答案对生成和多阶段微调（基于ROCO v2.0和MedPix v2.0数据集），并引入基于显著性的诊断工具。", "result": "尽管模型参数规模小且训练数据有限，其性能接近最先进模型（如LLaVA-Med）。", "conclusion": "轻量级模型通过适当微调和数据优化，可在放射学VQA中实现高效性能，显著诊断工具有助于识别模型失败模式。"}}
{"id": "2506.14167", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14167", "abs": "https://arxiv.org/abs/2506.14167", "authors": ["Prithvi Raj"], "title": "Structured and Informed Probabilistic Modeling with the Thermodynamic Kolmogorov-Arnold Model", "comment": null, "summary": "We adapt the Kolmogorov-Arnold Representation Theorem to generative modeling by reinterpreting its inner functions as a Markov Kernel between probability spaces via inverse transform sampling. We present a generative model that is interpretable, easy to design, and efficient. Our approach couples a Kolmogorov-Arnold Network generator with independent energy-based priors, trained via Maximum Likelihood. Inverse sampling enables fast inference, while prior knowledge can be incorporated before training to better align priors with posteriors, thereby improving learning efficiency and sample quality. The learned prior is also recoverable and visualizable post-training, offering an empirical Bayes perspective. To address inflexibility and mitigate prior-posterior mismatch, we introduce scalable extensions based on mixture distributions and Langevin Monte Carlo methods, admitting a trade-off between flexibility and training efficiency. Our contributions connect classical representation theorems with modern probabilistic modeling, while balancing training stability, inference speed, and the quality and diversity of generations.", "AI": {"tldr": "将Kolmogorov-Arnold表示定理应用于生成建模，通过逆变换采样重新解释其内部函数为概率空间之间的马尔可夫核。提出了一种可解释、易设计且高效的生成模型。", "motivation": "将经典表示定理与现代概率建模结合，平衡训练稳定性、推理速度和生成质量与多样性。", "method": "采用Kolmogorov-Arnold网络生成器与独立能量基先验结合，通过最大似然训练。引入混合分布和Langevin Monte Carlo方法提升灵活性。", "result": "模型支持快速推理，先验知识可训练前融入以提升学习效率和样本质量。后验先验可恢复和可视化。", "conclusion": "该方法在生成建模中实现了经典理论与现代技术的有效结合，同时优化了灵活性与训练效率的权衡。"}}
{"id": "2506.14471", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14471", "abs": "https://arxiv.org/abs/2506.14471", "authors": ["Yikang Zhou", "Tao Zhang", "Dizhe Zhang", "Shunping Ji", "Xiangtai Li", "Lu Qi"], "title": "Dense360: Dense Understanding from Omnidirectional Panoramas", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) require comprehensive visual inputs to achieve dense understanding of the physical world. While existing MLLMs demonstrate impressive world understanding capabilities through limited field-of-view (FOV) visual inputs (e.g., 70 degree), we take the first step toward dense understanding from omnidirectional panoramas. We first introduce an omnidirectional panoramas dataset featuring a comprehensive suite of reliability-scored annotations. Specifically, our dataset contains 160K panoramas with 5M dense entity-level captions, 1M unique referring expressions, and 100K entity-grounded panoramic scene descriptions. Compared to multi-view alternatives, panoramas can provide more complete, compact, and continuous scene representations through equirectangular projections (ERP). However, the use of ERP introduces two key challenges for MLLMs: i) spatial continuity along the circle of latitude, and ii) latitude-dependent variation in information density. We address these challenges through ERP-RoPE, a position encoding scheme specifically designed for panoramic ERP. In addition, we introduce Dense360-Bench, the first benchmark for evaluating MLLMs on omnidirectional captioning and grounding, establishing a comprehensive framework for advancing dense visual-language understanding in panoramic settings.", "AI": {"tldr": "该论文提出了一个用于多模态大语言模型（MLLMs）的全景数据集和基准测试，以解决全景视觉输入中的空间连续性和信息密度问题。", "motivation": "现有MLLMs通过有限视场（FOV）输入实现世界理解，但全景输入能提供更完整、紧凑和连续的场景表示。", "method": "引入包含160K全景图像的数据集，并提出ERP-RoPE位置编码方案以解决全景投影的挑战。", "result": "建立了首个全景标注和基准测试Dense360-Bench，为全景视觉语言理解提供了框架。", "conclusion": "论文为MLLMs在全景环境中的密集视觉语言理解奠定了基础。"}}
{"id": "2506.14194", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14194", "abs": "https://arxiv.org/abs/2506.14194", "authors": ["Sudeepta Mondal", "Zhuolin Jiang", "Ganesh Sundaramoorthi"], "title": "A Variational Information Theoretic Approach to Out-of-Distribution Detection", "comment": null, "summary": "We present a theory for the construction of out-of-distribution (OOD) detection features for neural networks. We introduce random features for OOD through a novel information-theoretic loss functional consisting of two terms, the first based on the KL divergence separates resulting in-distribution (ID) and OOD feature distributions and the second term is the Information Bottleneck, which favors compressed features that retain the OOD information. We formulate a variational procedure to optimize the loss and obtain OOD features. Based on assumptions on OOD distributions, one can recover properties of existing OOD features, i.e., shaping functions. Furthermore, we show that our theory can predict a new shaping function that out-performs existing ones on OOD benchmarks. Our theory provides a general framework for constructing a variety of new features with clear explainability.", "AI": {"tldr": "提出了一种基于信息论的OOD检测特征构建理论，通过KL散度和信息瓶颈优化损失函数，生成优于现有方法的特征。", "motivation": "解决神经网络中OOD检测特征构建的理论基础问题，提升特征的可解释性和性能。", "method": "引入信息论损失函数（KL散度分离ID/OOD分布，信息瓶颈压缩特征），并通过变分优化生成OOD特征。", "result": "理论预测的新特征在OOD基准测试中优于现有方法，并提供了可解释的通用框架。", "conclusion": "该理论为构建多样化的OOD特征提供了理论基础和实用工具。"}}
{"id": "2506.14473", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14473", "abs": "https://arxiv.org/abs/2506.14473", "authors": ["Zhijing Wan", "Zhixiang Wang", "Zheng Wang", "Xin Xu", "Shin'ichi Satoh"], "title": "Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection", "comment": "18 pages, 10 figures, accepted by ICML 2025", "summary": "One-shot subset selection serves as an effective tool to reduce deep learning training costs by identifying an informative data subset based on the information extracted by an information extractor (IE). Traditional IEs, typically pre-trained on the target dataset, are inherently dataset-dependent. Foundation models (FMs) offer a promising alternative, potentially mitigating this limitation. This work investigates two key questions: (1) Can FM-based subset selection outperform traditional IE-based methods across diverse datasets? (2) Do all FMs perform equally well as IEs for subset selection? Extensive experiments uncovered surprising insights: FMs consistently outperform traditional IEs on fine-grained datasets, whereas their advantage diminishes on coarse-grained datasets with noisy labels. Motivated by these finding, we propose RAM-APL (RAnking Mean-Accuracy of Pseudo-class Labels), a method tailored for fine-grained image datasets. RAM-APL leverages multiple FMs to enhance subset selection by exploiting their complementary strengths. Our approach achieves state-of-the-art performance on fine-grained datasets, including Oxford-IIIT Pet, Food-101, and Caltech-UCSD Birds-200-2011.", "AI": {"tldr": "论文研究了基于基础模型（FMs）的一次性子集选择方法，发现其在细粒度数据集上优于传统信息提取器（IEs），并提出了一种新方法RAM-APL以进一步提升性能。", "motivation": "传统信息提取器（IEs）依赖于目标数据集，限制了其通用性。基础模型（FMs）可能提供更灵活的替代方案，因此研究其在子集选择中的表现和潜力。", "method": "通过实验比较FM和传统IE在子集选择中的表现，并提出RAM-APL方法，利用多个FMs的互补优势优化子集选择。", "result": "FMs在细粒度数据集上表现优于传统IEs，但在粗粒度数据集上优势不明显。RAM-APL在多个细粒度数据集上达到最优性能。", "conclusion": "基础模型在子集选择中具有潜力，尤其在细粒度数据集上。RAM-APL方法通过结合多个FMs的优势，显著提升了性能。"}}
{"id": "2506.14202", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14202", "abs": "https://arxiv.org/abs/2506.14202", "authors": ["Makoto Shing", "Takuya Akiba"], "title": "DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion", "comment": "To appear at TTODLer-FM Workshop of the 42nd International Conference on Machine Learning", "summary": "Training large neural networks with end-to-end backpropagation creates significant memory bottlenecks, limiting accessibility to state-of-the-art AI research. We propose $\\textit{DiffusionBlocks}$, a novel training framework that interprets neural network blocks as performing denoising operations in a continuous-time diffusion process. By partitioning the network into independently trainable blocks and optimizing noise level assignments based on equal cumulative probability mass, our approach achieves significant memory efficiency while maintaining competitive performance compared to traditional backpropagation in generative tasks. Experiments on image generation and language modeling tasks demonstrate memory reduction proportional to the number of blocks while achieving superior performance. DiffusionBlocks provides a promising pathway for democratizing access to large-scale neural network training with limited computational resources.", "AI": {"tldr": "DiffusionBlocks是一种新型训练框架，将神经网络块解释为连续时间扩散过程中的去噪操作，显著降低内存需求。", "motivation": "解决传统端到端反向传播训练大型神经网络时的内存瓶颈问题，使更多人能够接触先进AI研究。", "method": "将网络划分为独立可训练的块，基于等累积概率质量优化噪声级别分配。", "result": "在图像生成和语言建模任务中，内存需求与块数成比例减少，性能优于传统反向传播。", "conclusion": "DiffusionBlocks为资源有限情况下的大规模神经网络训练提供了可行方案。"}}
{"id": "2506.14495", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14495", "abs": "https://arxiv.org/abs/2506.14495", "authors": ["Yu Qi", "Lipeng Gu", "Honghua Chen", "Liangliang Nan", "Mingqiang Wei"], "title": "I Speak and You Find: Robust 3D Visual Grounding with Noisy and Ambiguous Speech Inputs", "comment": null, "summary": "Existing 3D visual grounding methods rely on precise text prompts to locate objects within 3D scenes. Speech, as a natural and intuitive modality, offers a promising alternative. Real-world speech inputs, however, often suffer from transcription errors due to accents, background noise, and varying speech rates, limiting the applicability of existing 3DVG methods. To address these challenges, we propose \\textbf{SpeechRefer}, a novel 3DVG framework designed to enhance performance in the presence of noisy and ambiguous speech-to-text transcriptions. SpeechRefer integrates seamlessly with xisting 3DVG models and introduces two key innovations. First, the Speech Complementary Module captures acoustic similarities between phonetically related words and highlights subtle distinctions, generating complementary proposal scores from the speech signal. This reduces dependence on potentially erroneous transcriptions. Second, the Contrastive Complementary Module employs contrastive learning to align erroneous text features with corresponding speech features, ensuring robust performance even when transcription errors dominate. Extensive experiments on the SpeechRefer and peechNr3D datasets demonstrate that SpeechRefer improves the performance of existing 3DVG methods by a large margin, which highlights SpeechRefer's potential to bridge the gap between noisy speech inputs and reliable 3DVG, enabling more intuitive and practical multimodal systems.", "AI": {"tldr": "SpeechRefer是一个新的3D视觉定位框架，旨在处理语音转录中的噪声和模糊性，通过语音互补模块和对比互补模块提升性能。", "motivation": "现有3D视觉定位方法依赖精确的文本提示，而语音输入因转录错误（如口音、背景噪声）受限，需解决这一问题。", "method": "SpeechRefer引入语音互补模块（捕捉语音相似性）和对比互补模块（对齐错误文本与语音特征），与现有3DVG模型兼容。", "result": "在SpeechRefer和SpeechNr3D数据集上，SpeechRefer显著提升了现有3DVG方法的性能。", "conclusion": "SpeechRefer填补了噪声语音输入与可靠3DVG之间的鸿沟，推动了更直观的多模态系统发展。"}}
{"id": "2506.14217", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14217", "abs": "https://arxiv.org/abs/2506.14217", "authors": ["Dipesh Tharu Mahato", "Rohan Poudel", "Pramod Dhungana"], "title": "TriGuard: Testing Model Safety with Attribution Entropy, Verification, and Drift", "comment": "12 pages, 6 tables, 6 figures", "summary": "Deep neural networks often achieve high accuracy, but ensuring their reliability under adversarial and distributional shifts remains a pressing challenge. We propose TriGuard, a unified safety evaluation framework that combines (1) formal robustness verification, (2) attribution entropy to quantify saliency concentration, and (3) a novel Attribution Drift Score measuring explanation stability. TriGuard reveals critical mismatches between model accuracy and interpretability: verified models can still exhibit unstable reasoning, and attribution-based signals provide complementary safety insights beyond adversarial accuracy. Extensive experiments across three datasets and five architectures show how TriGuard uncovers subtle fragilities in neural reasoning. We further demonstrate that entropy-regularized training reduces explanation drift without sacrificing performance. TriGuard advances the frontier in robust, interpretable model evaluation.", "AI": {"tldr": "TriGuard是一个统一的安全评估框架，结合形式化鲁棒性验证、显著性集中度量化和解释稳定性测量，揭示模型准确性与可解释性之间的不匹配。", "motivation": "深度神经网络在准确性上表现优异，但在对抗性和分布变化下的可靠性仍是一个挑战。", "method": "TriGuard结合形式化鲁棒性验证、属性熵量化和新颖的属性漂移评分，评估模型安全性。", "result": "实验表明，TriGuard能揭示神经推理中的脆弱性，且熵正则化训练可减少解释漂移而不影响性能。", "conclusion": "TriGuard推动了鲁棒、可解释模型评估的前沿。"}}
{"id": "2506.14411", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14411", "abs": "https://arxiv.org/abs/2506.14411", "authors": ["John Wikman", "Alexandre Proutiere", "David Broman"], "title": "Adaptive Reinforcement Learning for Unobservable Random Delays", "comment": null, "summary": "In standard Reinforcement Learning (RL) settings, the interaction between the agent and the environment is typically modeled as a Markov Decision Process (MDP), which assumes that the agent observes the system state instantaneously, selects an action without delay, and executes it immediately. In real-world dynamic environments, such as cyber-physical systems, this assumption often breaks down due to delays in the interaction between the agent and the system. These delays can vary stochastically over time and are typically unobservable, meaning they are unknown when deciding on an action. Existing methods deal with this uncertainty conservatively by assuming a known fixed upper bound on the delay, even if the delay is often much lower. In this work, we introduce the interaction layer, a general framework that enables agents to adaptively and seamlessly handle unobservable and time-varying delays. Specifically, the agent generates a matrix of possible future actions to handle both unpredictable delays and lost action packets sent over networks. Building on this framework, we develop a model-based algorithm, Actor-Critic with Delay Adaptation (ACDA), which dynamically adjusts to delay patterns. Our method significantly outperforms state-of-the-art approaches across a wide range of locomotion benchmark environments.", "AI": {"tldr": "论文提出了一种名为“交互层”的通用框架，用于处理强化学习中不可观测且随时间变化的延迟问题，并开发了基于模型的算法ACDA，显著优于现有方法。", "motivation": "现实动态环境中的延迟问题导致传统MDP假设失效，现有方法保守假设固定延迟上限，无法适应实际变化的延迟。", "method": "引入交互层框架，生成未来动作矩阵以应对不可预测的延迟和丢包；开发ACDA算法，动态调整延迟模式。", "result": "ACDA在多种运动基准环境中显著优于现有方法。", "conclusion": "交互层框架和ACDA算法有效解决了延迟问题，提升了强化学习在动态环境中的性能。"}}
{"id": "2506.14511", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14511", "abs": "https://arxiv.org/abs/2506.14511", "authors": ["Zhiwen Shao", "Yifan Cheng", "Feiran Li", "Yong Zhou", "Xuequan Lu", "Yuan Xie", "Lizhuang Ma"], "title": "MOL: Joint Estimation of Micro-Expression, Optical Flow, and Landmark via Transformer-Graph-Style Convolution", "comment": "This paper has been accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence", "summary": "Facial micro-expression recognition (MER) is a challenging problem, due to transient and subtle micro-expression (ME) actions. Most existing methods depend on hand-crafted features, key frames like onset, apex, and offset frames, or deep networks limited by small-scale and low-diversity datasets. In this paper, we propose an end-to-end micro-action-aware deep learning framework with advantages from transformer, graph convolution, and vanilla convolution. In particular, we propose a novel F5C block composed of fully-connected convolution and channel correspondence convolution to directly extract local-global features from a sequence of raw frames, without the prior knowledge of key frames. The transformer-style fully-connected convolution is proposed to extract local features while maintaining global receptive fields, and the graph-style channel correspondence convolution is introduced to model the correlations among feature patterns. Moreover, MER, optical flow estimation, and facial landmark detection are jointly trained by sharing the local-global features. The two latter tasks contribute to capturing facial subtle action information for MER, which can alleviate the impact of insufficient training data. Extensive experiments demonstrate that our framework (i) outperforms the state-of-the-art MER methods on CASME II, SAMM, and SMIC benchmarks, (ii) works well for optical flow estimation and facial landmark detection, and (iii) can capture facial subtle muscle actions in local regions associated with MEs. The code is available at https://github.com/CYF-cuber/MOL.", "AI": {"tldr": "提出一种端到端的微动作感知深度学习框架，结合Transformer、图卷积和普通卷积，直接从未标记帧序列中提取局部-全局特征，无需关键帧先验知识。", "motivation": "面部微表情识别（MER）因动作短暂且细微而具有挑战性，现有方法依赖手工特征或小规模数据集。", "method": "提出F5C模块（全连接卷积和通道对应卷积）提取局部-全局特征，结合Transformer和图卷积，并通过多任务学习（MER、光流估计和面部标志检测）共享特征。", "result": "在CASME II、SAMM和SMIC基准测试中优于现有方法，同时适用于光流估计和面部标志检测。", "conclusion": "该框架能有效捕捉与微表情相关的局部肌肉动作，缓解训练数据不足的问题。"}}
{"id": "2506.14220", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14220", "abs": "https://arxiv.org/abs/2506.14220", "authors": ["Kangkang Lu", "Yanhua Yu", "Zhiyong Huang", "Tat-Seng Chua"], "title": "Can Large Language Models Improve Spectral Graph Neural Networks?", "comment": null, "summary": "Spectral Graph Neural Networks (SGNNs) have attracted significant attention due to their ability to approximate arbitrary filters. They typically rely on supervision from downstream tasks to adaptively learn appropriate filters. However, under label-scarce conditions, SGNNs may learn suboptimal filters, leading to degraded performance. Meanwhile, the remarkable success of Large Language Models (LLMs) has inspired growing interest in exploring their potential within the GNN domain. This naturally raises an important question: \\textit{Can LLMs help overcome the limitations of SGNNs and enhance their performance?} In this paper, we propose a novel approach that leverages LLMs to estimate the homophily of a given graph. The estimated homophily is then used to adaptively guide the design of polynomial spectral filters, thereby improving the expressiveness and adaptability of SGNNs across diverse graph structures. Specifically, we introduce a lightweight pipeline in which the LLM generates homophily-aware priors, which are injected into the filter coefficients to better align with the underlying graph topology. Extensive experiments on benchmark datasets demonstrate that our LLM-driven SGNN framework consistently outperforms existing baselines under both homophilic and heterophilic settings, with minimal computational and monetary overhead.", "AI": {"tldr": "论文提出了一种利用大语言模型（LLMs）估计图同质性以改进谱图神经网络（SGNNs）性能的新方法。", "motivation": "在标签稀缺条件下，SGNNs可能学习到次优滤波器，导致性能下降。LLMs的成功激发了探索其在GNN领域潜力的兴趣。", "method": "通过LLMs估计图的同质性，并利用该信息自适应地设计多项式谱滤波器，提升SGNNs的表达能力和适应性。", "result": "在基准数据集上的实验表明，该方法在多种图结构下均优于现有基线，且计算和成本开销极小。", "conclusion": "LLMs可以有效帮助SGNNs克服局限性，提升性能，尤其在标签稀缺条件下表现优异。"}}
{"id": "2506.14525", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14525", "abs": "https://arxiv.org/abs/2506.14525", "authors": ["Zhuoyue Tan", "Boyong He", "Yuxiang Ji", "Liaoni Wu"], "title": "VisLanding: Monocular 3D Perception for UAV Safe Landing via Depth-Normal Synergy", "comment": "Accepted by IROS2025", "summary": "This paper presents VisLanding, a monocular 3D perception-based framework for safe UAV (Unmanned Aerial Vehicle) landing. Addressing the core challenge of autonomous UAV landing in complex and unknown environments, this study innovatively leverages the depth-normal synergy prediction capabilities of the Metric3D V2 model to construct an end-to-end safe landing zones (SLZ) estimation framework. By introducing a safe zone segmentation branch, we transform the landing zone estimation task into a binary semantic segmentation problem. The model is fine-tuned and annotated using the WildUAV dataset from a UAV perspective, while a cross-domain evaluation dataset is constructed to validate the model's robustness. Experimental results demonstrate that VisLanding significantly enhances the accuracy of safe zone identification through a depth-normal joint optimization mechanism, while retaining the zero-shot generalization advantages of Metric3D V2. The proposed method exhibits superior generalization and robustness in cross-domain testing compared to other approaches. Furthermore, it enables the estimation of landing zone area by integrating predicted depth and normal information, providing critical decision-making support for practical applications.", "AI": {"tldr": "VisLanding是一个基于单目3D感知的无人机安全着陆框架，通过深度-法线协同预测和二元语义分割任务，显著提升了安全着陆区的识别精度。", "motivation": "解决无人机在复杂未知环境中自主着陆的核心挑战，利用Metric3D V2模型的深度-法线协同预测能力。", "method": "引入安全区分割分支，将着陆区估计任务转化为二元语义分割问题，使用WildUAV数据集微调模型，并构建跨域评估数据集验证鲁棒性。", "result": "实验表明VisLanding通过深度-法线联合优化机制显著提升安全区识别精度，并保留Metric3D V2的零样本泛化优势。", "conclusion": "VisLanding在跨域测试中表现出优越的泛化性和鲁棒性，并能通过深度和法线信息估计着陆区面积，为实际应用提供决策支持。"}}
{"id": "2506.14512", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14512", "abs": "https://arxiv.org/abs/2506.14512", "authors": ["Zijian Song", "Xiaoxin Lin", "Qiuming Huang", "Guangrun Wang", "Liang Lin"], "title": "SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks", "comment": "16 pages, 9 figures", "summary": "Large Language Models (LLMs) are experiencing rapid advancements in complex reasoning, exhibiting remarkable generalization in mathematics and programming. In contrast, while spatial intelligence is fundamental for Vision-Language Models (VLMs) in real-world interaction, the systematic evaluation of their complex reasoning ability within spatial contexts remains underexplored. To bridge this gap, we introduce SIRI-Bench, a benchmark designed to evaluate VLMs' spatial intelligence through video-based reasoning tasks. SIRI-Bench comprises nearly 1K video-question-answer triplets, where each problem is embedded in a realistic 3D scene and captured by video. By carefully designing questions and corresponding 3D scenes, our benchmark ensures that solving the questions requires both spatial comprehension for extracting information and high-level reasoning for deriving solutions, making it a challenging benchmark for evaluating VLMs. To facilitate large-scale data synthesis, we develop an Automatic Scene Creation Engine. This engine, leveraging multiple specialized LLM agents, can generate realistic 3D scenes from abstract math problems, ensuring faithfulness to the original descriptions. Experimental results reveal that state-of-the-art VLMs struggle significantly on SIRI-Bench, underscoring the challenge of spatial reasoning. We hope that our study will bring researchers' attention to spatially grounded reasoning and advance VLMs in visual problem-solving.", "AI": {"tldr": "SIRI-Bench是一个评估视觉语言模型（VLMs）空间智能的基准测试，通过视频推理任务挑战VLMs的空间理解与高级推理能力。", "motivation": "尽管大语言模型（LLMs）在数学和编程等复杂推理任务中表现优异，但视觉语言模型（VLMs）在空间智能方面的系统评估仍不足。", "method": "开发了SIRI-Bench基准测试，包含近1K个视频-问题-答案三元组，并设计了自动场景生成引擎（Automatic Scene Creation Engine）以合成大规模数据。", "result": "实验表明，当前最先进的VLMs在SIRI-Bench上表现不佳，凸显了空间推理的挑战性。", "conclusion": "研究旨在推动VLMs在视觉问题解决中的空间推理能力，并引起研究者对空间基础推理的关注。"}}
{"id": "2506.14251", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.14251", "abs": "https://arxiv.org/abs/2506.14251", "authors": ["Xiyu Zhao", "Qimei Cui", "Weicai Li", "Wei Ni", "Ekram Hossain", "Quan Z. Sheng", "Xiaofeng Tao", "Ping Zhang"], "title": "Convergence-Privacy-Fairness Trade-Off in Personalized Federated Learning", "comment": null, "summary": "Personalized federated learning (PFL), e.g., the renowned Ditto, strikes a balance between personalization and generalization by conducting federated learning (FL) to guide personalized learning (PL). While FL is unaffected by personalized model training, in Ditto, PL depends on the outcome of the FL. However, the clients' concern about their privacy and consequent perturbation of their local models can affect the convergence and (performance) fairness of PL. This paper presents PFL, called DP-Ditto, which is a non-trivial extension of Ditto under the protection of differential privacy (DP), and analyzes the trade-off among its privacy guarantee, model convergence, and performance distribution fairness. We also analyze the convergence upper bound of the personalized models under DP-Ditto and derive the optimal number of global aggregations given a privacy budget. Further, we analyze the performance fairness of the personalized models, and reveal the feasibility of optimizing DP-Ditto jointly for convergence and fairness. Experiments validate our analysis and demonstrate that DP-Ditto can surpass the DP-perturbed versions of the state-of-the-art PFL models, such as FedAMP, pFedMe, APPLE, and FedALA, by over 32.71% in fairness and 9.66% in accuracy.", "AI": {"tldr": "DP-Ditto是Ditto的差分隐私扩展版本，分析了隐私保护、模型收敛和性能公平性之间的权衡，并在实验中表现优于现有PFL模型。", "motivation": "解决个性化联邦学习中隐私保护对模型收敛和性能公平性的影响。", "method": "提出DP-Ditto，分析其收敛上界和最优全局聚合次数，并优化收敛与公平性。", "result": "DP-Ditto在公平性和准确性上分别超过现有模型32.71%和9.66%。", "conclusion": "DP-Ditto在隐私保护下实现了更好的收敛和公平性，优于现有方法。"}}
{"id": "2506.14709", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14709", "abs": "https://arxiv.org/abs/2506.14709", "authors": ["Kunal Swami", "Debtanu Gupta", "Amrit Kumar Muduli", "Chirag Jaiswal", "Pankaj Kumar Bajpai"], "title": "DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning", "comment": "Accepted in IROS 2025", "summary": "Depth estimation is crucial for intelligent systems, enabling applications from autonomous navigation to augmented reality. While traditional stereo and active depth sensors have limitations in cost, power, and robustness, dual-pixel (DP) technology, ubiquitous in modern cameras, offers a compelling alternative. This paper introduces DiFuse-Net, a novel modality decoupled network design for disentangled RGB and DP based depth estimation. DiFuse-Net features a window bi-directional parallax attention mechanism (WBiPAM) specifically designed to capture the subtle DP disparity cues unique to smartphone cameras with small aperture. A separate encoder extracts contextual information from the RGB image, and these features are fused to enhance depth prediction. We also propose a Cross-modal Transfer Learning (CmTL) mechanism to utilize large-scale RGB-D datasets in the literature to cope with the limitations of obtaining large-scale RGB-DP-D dataset. Our evaluation and comparison of the proposed method demonstrates its superiority over the DP and stereo-based baseline methods. Additionally, we contribute a new, high-quality, real-world RGB-DP-D training dataset, named Dual-Camera Dual-Pixel (DCDP) dataset, created using our novel symmetric stereo camera hardware setup, stereo calibration and rectification protocol, and AI stereo disparity estimation method.", "AI": {"tldr": "DiFuse-Net是一种新型模态解耦网络，用于RGB和双像素（DP）深度估计，通过窗口双向视差注意力机制（WBiPAM）和跨模态迁移学习（CmTL）提升性能，并贡献了新的DCDP数据集。", "motivation": "传统深度传感器在成本、功耗和鲁棒性方面存在局限，而双像素技术在现代相机中普及，为深度估计提供了新思路。", "method": "提出DiFuse-Net，结合WBiPAM捕捉DP视差线索，单独编码RGB上下文信息，并通过CmTL利用RGB-D数据集。", "result": "DiFuse-Net在性能上优于基于DP和立体视觉的基线方法。", "conclusion": "DiFuse-Net和DCDP数据集为深度估计提供了高效解决方案，推动了智能系统的发展。"}}
{"id": "2506.14261", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14261", "abs": "https://arxiv.org/abs/2506.14261", "authors": ["Rohan Gupta", "Erik Jenner"], "title": "RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?", "comment": null, "summary": "Latent-space monitors aim to detect undesirable behaviours in large language models by leveraging internal model representations rather than relying solely on black-box outputs. These methods have shown promise in identifying behaviours such as deception and unsafe completions, but a critical open question remains: can LLMs learn to evade such monitors? To study this, we introduce RL-Obfuscation, in which LLMs are finetuned via reinforcement learning to bypass latent-space monitors while maintaining coherent generations. We apply RL-Obfuscation to LLMs ranging from 7B to 14B parameters and evaluate evasion success against a suite of monitors. We find that token-level latent-space monitors are highly vulnerable to this attack. More holistic monitors, such as max-pooling or attention-based probes, remain robust. Moreover, we show that adversarial policies trained to evade a single static monitor generalise to unseen monitors of the same type. Finally, we study how the policy learned by RL bypasses these monitors and find that the model can also learn to repurpose tokens to mean something different internally.", "AI": {"tldr": "论文研究了大型语言模型（LLM）是否可以通过强化学习绕过潜在空间监控器，发现某些监控器易受攻击，而更全面的监控器则更稳健。", "motivation": "探讨LLM是否能学会规避潜在空间监控器，以评估现有监控方法的有效性。", "method": "提出RL-Obfuscation方法，通过强化学习微调LLM以绕过监控器，同时保持生成内容的连贯性。", "result": "发现基于token的潜在空间监控器易受攻击，而更全面的监控器（如max-pooling或基于注意力的探针）更稳健。", "conclusion": "潜在空间监控器存在被规避的风险，需开发更全面的监控方法以提高安全性。"}}
{"id": "2506.14769", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.14769", "abs": "https://arxiv.org/abs/2506.14769", "authors": ["Jiahua Ma", "Yiran Qin", "Yixiong Li", "Xuanqi Liao", "Yulan Guo", "Ruimao Zhang"], "title": "CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion", "comment": null, "summary": "Diffusion Policy (DP) enables robots to learn complex behaviors by imitating expert demonstrations through action diffusion. However, in practical applications, hardware limitations often degrade data quality, while real-time constraints restrict model inference to instantaneous state and scene observations. These limitations seriously reduce the efficacy of learning from expert demonstrations, resulting in failures in object localization, grasp planning, and long-horizon task execution. To address these challenges, we propose Causal Diffusion Policy (CDP), a novel transformer-based diffusion model that enhances action prediction by conditioning on historical action sequences, thereby enabling more coherent and context-aware visuomotor policy learning. To further mitigate the computational cost associated with autoregressive inference, a caching mechanism is also introduced to store attention key-value pairs from previous timesteps, substantially reducing redundant computations during execution. Extensive experiments in both simulated and real-world environments, spanning diverse 2D and 3D manipulation tasks, demonstrate that CDP uniquely leverages historical action sequences to achieve significantly higher accuracy than existing methods. Moreover, even when faced with degraded input observation quality, CDP maintains remarkable precision by reasoning through temporal continuity, which highlights its practical robustness for robotic control under realistic, imperfect conditions.", "AI": {"tldr": "CDP通过结合历史动作序列和缓存机制，提升了机器人模仿学习的效果，尤其在输入质量下降时仍保持高精度。", "motivation": "硬件限制和实时约束降低了专家示范的学习效果，导致任务执行失败。", "method": "提出基于Transformer的扩散模型CDP，利用历史动作序列和缓存机制优化动作预测。", "result": "在模拟和真实环境中，CDP显著优于现有方法，且在输入质量下降时仍保持高精度。", "conclusion": "CDP通过时间连续性推理，展示了在现实不完美条件下的实用鲁棒性。"}}
{"id": "2506.14541", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14541", "abs": "https://arxiv.org/abs/2506.14541", "authors": ["Rongchang Lu", "Tianduo Luo", "Yunzhi Zhang", "Conghan Yue", "Pei Yang", "Guibao Liu", "Changyang Gu"], "title": "Exploring Diffusion with Test-Time Training on Efficient Image Restoration", "comment": "Submitted to The 8th Chinese Conference on Pattern Recognition and Computer Vision (2025). Contact to nomodeset@qq.com. Source code will open in 4 months", "summary": "Image restoration faces challenges including ineffective feature fusion, computational bottlenecks and inefficient diffusion processes. To address these, we propose DiffRWKVIR, a novel framework unifying Test-Time Training (TTT) with efficient diffusion. Our approach introduces three key innovations: (1) Omni-Scale 2D State Evolution extends RWKV's location-dependent parameterization to hierarchical multi-directional 2D scanning, enabling global contextual awareness with linear complexity O(L); (2) Chunk-Optimized Flash Processing accelerates intra-chunk parallelism by 3.2x via contiguous chunk processing (O(LCd) complexity), reducing sequential dependencies and computational overhead; (3) Prior-Guided Efficient Diffusion extracts a compact Image Prior Representation (IPR) in only 5-20 steps, proving 45% faster training/inference than DiffIR while solving computational inefficiency in denoising. Evaluated across super-resolution and inpainting benchmarks (Set5, Set14, BSD100, Urban100, Places365), DiffRWKVIR outperforms SwinIR, HAT, and MambaIR/v2 in PSNR, SSIM, LPIPS, and efficiency metrics. Our method establishes a new paradigm for adaptive, high-efficiency image restoration with optimized hardware utilization.", "AI": {"tldr": "DiffRWKVIR提出了一种结合测试时训练和高效扩散的新框架，通过三项创新解决了图像恢复中的特征融合、计算瓶颈和扩散效率问题。", "motivation": "图像恢复中存在特征融合效果差、计算瓶颈和扩散过程效率低的问题，需要一种高效且适应性强的解决方案。", "method": "1. Omni-Scale 2D State Evolution扩展了RWKV的位置依赖参数化；2. Chunk-Optimized Flash Processing通过连续块处理加速并行计算；3. Prior-Guided Efficient Diffusion提取紧凑的图像先验表示。", "result": "在多个基准测试中，DiffRWKVIR在PSNR、SSIM、LPIPS和效率指标上优于SwinIR、HAT和MambaIR/v2。", "conclusion": "DiffRWKVIR为高效自适应的图像恢复提供了新范式，优化了硬件利用率。"}}
{"id": "2506.14262", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14262", "abs": "https://arxiv.org/abs/2506.14262", "authors": ["Mohammad Emtiyaz Khan"], "title": "Knowledge Adaptation as Posterior Correction", "comment": null, "summary": "Adaptation is the holy grail of intelligence, but even the best AI models (like GPT) lack the adaptivity of toddlers. So the question remains: how can machines adapt quickly? Despite a lot of progress on model adaptation to facilitate continual and federated learning, as well as model merging, editing, unlearning, etc., little is known about the mechanisms by which machines can naturally learn to adapt in a similar way as humans and animals. Here, we show that all such adaptation methods can be seen as different ways of `correcting' the approximate posteriors. More accurate posteriors lead to smaller corrections, which in turn imply quicker adaptation. The result is obtained by using a dual-perspective of the Bayesian Learning Rule of Khan and Rue (2023) where interference created during adaptation is characterized by the natural-gradient mismatch over the past data. We present many examples to demonstrate the use of posterior-correction as a natural mechanism for the machines to learn to adapt quickly.", "AI": {"tldr": "论文探讨了机器如何像人类和动物一样快速适应，提出所有适应方法均可视为对近似后验的“校正”，更准确的后验意味着更小的校正和更快的适应。", "motivation": "尽管在模型适应方面取得了很多进展，但机器如何像人类和动物一样自然快速适应仍不清楚。", "method": "通过使用Khan和Rue（2023）的贝叶斯学习规则的双重视角，将干扰表征为过去数据的自然梯度不匹配。", "result": "更准确的后验导致更小的校正，从而更快适应。", "conclusion": "后验校正可作为机器快速适应的自然机制。"}}
{"id": "2506.14549", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14549", "abs": "https://arxiv.org/abs/2506.14549", "authors": ["Yong Liu", "Wenpeng Xiao", "Qianqian Wang", "Junlin Chen", "Shiyin Wang", "Yitong Wang", "Xinglong Wu", "Yansong Tang"], "title": "DreamLight: Towards Harmonious and Consistent Image Relighting", "comment": null, "summary": "We introduce a model named DreamLight for universal image relighting in this work, which can seamlessly composite subjects into a new background while maintaining aesthetic uniformity in terms of lighting and color tone. The background can be specified by natural images (image-based relighting) or generated from unlimited text prompts (text-based relighting). Existing studies primarily focus on image-based relighting, while with scant exploration into text-based scenarios. Some works employ intricate disentanglement pipeline designs relying on environment maps to provide relevant information, which grapples with the expensive data cost required for intrinsic decomposition and light source. Other methods take this task as an image translation problem and perform pixel-level transformation with autoencoder architecture. While these methods have achieved decent harmonization effects, they struggle to generate realistic and natural light interaction effects between the foreground and background. To alleviate these challenges, we reorganize the input data into a unified format and leverage the semantic prior provided by the pretrained diffusion model to facilitate the generation of natural results. Moreover, we propose a Position-Guided Light Adapter (PGLA) that condenses light information from different directions in the background into designed light query embeddings, and modulates the foreground with direction-biased masked attention. In addition, we present a post-processing module named Spectral Foreground Fixer (SFF) to adaptively reorganize different frequency components of subject and relighted background, which helps enhance the consistency of foreground appearance. Extensive comparisons and user study demonstrate that our DreamLight achieves remarkable relighting performance.", "AI": {"tldr": "DreamLight是一个通用图像重光照模型，支持基于图像和文本的重光照，通过统一输入格式和预训练扩散模型的语义先验实现自然光照效果。", "motivation": "现有方法主要关注基于图像的重光照，且依赖复杂的环境映射或像素级转换，难以实现前景与背景的自然光照交互。", "method": "提出统一输入格式，利用预训练扩散模型的语义先验；设计PGLA模块提取背景光照信息并调制前景；引入SFF模块增强前景一致性。", "result": "实验和用户研究表明，DreamLight在重光照任务中表现优异。", "conclusion": "DreamLight通过创新模块设计和统一数据格式，显著提升了图像重光照的自然性和一致性。"}}
{"id": "2506.14263", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.14263", "abs": "https://arxiv.org/abs/2506.14263", "authors": ["Qingyu Song", "Wei Lin", "Juncheng Wang", "Hong Xu"], "title": "Towards Robust Learning to Optimize with Theoretical Guarantees", "comment": "Published in CVPR 2024, 55 pages, 17 figures, this version fixed some typo", "summary": "Learning to optimize (L2O) is an emerging technique to solve mathematical optimization problems with learning-based methods. Although with great success in many real-world scenarios such as wireless communications, computer networks, and electronic design, existing L2O works lack theoretical demonstration of their performance and robustness in out-of-distribution (OOD) scenarios. We address this gap by providing comprehensive proofs. First, we prove a sufficient condition for a robust L2O model with homogeneous convergence rates over all In-Distribution (InD) instances. We assume an L2O model achieves robustness for an InD scenario. Based on our proposed methodology of aligning OOD problems to InD problems, we also demonstrate that the L2O model's convergence rate in OOD scenarios will deteriorate by an equation of the L2O model's input features. Moreover, we propose an L2O model with a concise gradient-only feature construction and a novel gradient-based history modeling method. Numerical simulation demonstrates that our proposed model outperforms the state-of-the-art baseline in both InD and OOD scenarios and achieves up to 10 $\\times$ convergence speedup. The code of our method can be found from https://github.com/NetX-lab/GoMathL2O-Official.", "AI": {"tldr": "本文提出了一种学习优化（L2O）方法，通过理论证明其在分布外（OOD）场景中的性能与鲁棒性，并提出了新的梯度特征构建和历史建模方法。", "motivation": "现有L2O方法在分布外（OOD）场景中缺乏理论性能与鲁棒性证明，本文旨在填补这一空白。", "method": "提出了一种梯度特征构建方法和基于梯度的历史建模方法，并通过理论分析证明了其鲁棒性。", "result": "数值模拟显示，该方法在分布内（InD）和分布外（OOD）场景中均优于现有基线，收敛速度提升高达10倍。", "conclusion": "本文为L2O方法在OOD场景中的应用提供了理论支持，并展示了其实际性能优势。"}}
{"id": "2506.14560", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14560", "abs": "https://arxiv.org/abs/2506.14560", "authors": ["David Butler", "Adrian Hilton", "Gustavo Carneiro"], "title": "Risk Estimation of Knee Osteoarthritis Progression via Predictive Multi-task Modelling from Efficient Diffusion Model using X-ray Images", "comment": null, "summary": "Medical imaging plays a crucial role in assessing knee osteoarthritis (OA) risk by enabling early detection and disease monitoring. Recent machine learning methods have improved risk estimation (i.e., predicting the likelihood of disease progression) and predictive modelling (i.e., the forecasting of future outcomes based on current data) using medical images, but clinical adoption remains limited due to their lack of interpretability. Existing approaches that generate future images for risk estimation are complex and impractical. Additionally, previous methods fail to localize anatomical knee landmarks, limiting interpretability. We address these gaps with a new interpretable machine learning method to estimate the risk of knee OA progression via multi-task predictive modelling that classifies future knee OA severity and predicts anatomical knee landmarks from efficiently generated high-quality future images. Such image generation is achieved by leveraging a diffusion model in a class-conditioned latent space to forecast disease progression, offering a visual representation of how particular health conditions may evolve. Applied to the Osteoarthritis Initiative dataset, our approach improves the state-of-the-art (SOTA) by 2\\%, achieving an AUC of 0.71 in predicting knee OA progression while offering ~9% faster inference time.", "AI": {"tldr": "提出了一种可解释的机器学习方法，通过多任务预测建模预测膝骨关节炎进展风险，同时生成高质量未来图像并定位解剖标志点。", "motivation": "现有方法在膝骨关节炎风险预测中缺乏可解释性，且生成未来图像的复杂性高，临床采用受限。", "method": "利用扩散模型在类别条件潜在空间中生成高质量未来图像，结合多任务建模分类未来疾病严重程度并预测解剖标志点。", "result": "在Osteoarthritis Initiative数据集上，AUC提升2%至0.71，推理时间缩短约9%。", "conclusion": "该方法在提高预测性能的同时增强了可解释性，为临床决策提供了可视化支持。"}}
{"id": "2506.14280", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14280", "abs": "https://arxiv.org/abs/2506.14280", "authors": ["Bai Cong", "Nico Daheim", "Yuesong Shen", "Rio Yokota", "Mohammad Emtiyaz Khan", "Thomas Möllenhoff"], "title": "Improving LoRA with Variational Learning", "comment": "16 pages, 4 figures", "summary": "Bayesian methods have recently been used to improve LoRA finetuning and, although they improve calibration, their effect on other metrics (such as accuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian methods also increase computational overheads and require additional tricks for them to work well. Here, we fix these issues by using a recently proposed variational algorithm called IVON. We show that IVON is easy to implement and has similar costs to AdamW, and yet it can also drastically improve many metrics by using a simple posterior pruning technique. We present extensive results on billion-scale LLMs (Llama and Qwen series) going way beyond the scale of existing applications of IVON. For example, we finetune a Llama-3.2-3B model on a set of commonsense reasoning tasks and improve accuracy over AdamW by 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian methods like Laplace-LoRA and BLoB. Overall, our results show that variational learning with IVON can effectively improve LoRA finetuning.", "AI": {"tldr": "IVON算法显著提升了LoRA微调的效果，优于AdamW和其他贝叶斯方法，同时计算成本低。", "motivation": "解决贝叶斯方法在LoRA微调中效果有限且计算开销大的问题。", "method": "使用IVON变分算法，结合后验剪枝技术。", "result": "在Llama和Qwen系列模型上，IVON显著提升准确率（1.3%）并降低ECE（5.4%）。", "conclusion": "IVON是一种高效且易于实现的LoRA微调改进方法。"}}
{"id": "2506.14583", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14583", "abs": "https://arxiv.org/abs/2506.14583", "authors": ["Krishna Sahukara", "Zineddine Bettouche", "Andreas Fischer"], "title": "Synthetic Data Augmentation for Table Detection: Re-evaluating TableNet's Performance with Automatically Generated Document Images", "comment": null, "summary": "Document pages captured by smartphones or scanners often contain tables, yet manual extraction is slow and error-prone. We introduce an automated LaTeX-based pipeline that synthesizes realistic two-column pages with visually diverse table layouts and aligned ground-truth masks. The generated corpus augments the real-world Marmot benchmark and enables a systematic resolution study of TableNet. Training TableNet on our synthetic data achieves a pixel-wise XOR error of 4.04% on our synthetic test set with a 256x256 input resolution, and 4.33% with 1024x1024. The best performance on the Marmot benchmark is 9.18% (at 256x256), while cutting manual annotation effort through automation.", "AI": {"tldr": "本文提出了一种自动化LaTeX管道，用于生成多样化的表格布局合成数据，以增强TableNet的训练效果，显著减少人工标注需求。", "motivation": "手动提取文档中的表格效率低且易出错，需要自动化解决方案。", "method": "使用LaTeX生成具有多样化布局的合成表格数据，并结合真实数据集Marmot进行训练。", "result": "在合成测试集上，TableNet的像素级XOR误差为4.04%（256x256）和4.33%（1024x1024）；在Marmot基准测试中为9.18%（256x256）。", "conclusion": "合成数据显著提升了TableNet的性能，同时减少了人工标注的工作量。"}}
{"id": "2506.14291", "categories": ["cs.LG", "cs.SI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14291", "abs": "https://arxiv.org/abs/2506.14291", "authors": ["Ben Finkelshtein", "İsmail İlkan Ceylan", "Michael Bronstein", "Ron Levie"], "title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models", "comment": null, "summary": "Graph machine learning architectures are typically tailored to specific tasks on specific datasets, which hinders their broader applicability. This has led to a new quest in graph machine learning: how to build graph foundation models capable of generalizing across arbitrary graphs and features? In this work, we present a recipe for designing graph foundation models for node-level tasks from first principles. The key ingredient underpinning our study is a systematic investigation of the symmetries that a graph foundation model must respect. In a nutshell, we argue that label permutation-equivariance alongside feature permutation-invariance are necessary in addition to the common node permutation-equivariance on each local neighborhood of the graph. To this end, we first characterize the space of linear transformations that are equivariant to permutations of nodes and labels, and invariant to permutations of features. We then prove that the resulting network is a universal approximator on multisets that respect the aforementioned symmetries. Our recipe uses such layers on the multiset of features induced by the local neighborhood of the graph to obtain a class of graph foundation models for node property prediction. We validate our approach through extensive experiments on 29 real-world node classification datasets, demonstrating both strong zero-shot empirical performance and consistent improvement as the number of training graphs increases.", "AI": {"tldr": "本文提出了一种设计图基础模型的方法，通过研究对称性（如节点和标签的置换等变性、特征的置换不变性）来构建通用的节点级任务模型，并在实验中验证了其零样本性能。", "motivation": "现有图机器学习架构通常针对特定任务和数据集，缺乏通用性，因此需要开发能够泛化到任意图和特征的图基础模型。", "method": "通过系统研究图基础模型必须遵循的对称性（节点和标签的置换等变性、特征的置换不变性），设计线性变换层，并证明其是多重集上的通用逼近器。", "result": "在29个真实节点分类数据集上的实验表明，该方法具有强大的零样本性能，并随着训练图数量的增加而持续改进。", "conclusion": "本文提出的方法为构建通用的图基础模型提供了理论支持和实践验证，展示了其在节点属性预测任务中的潜力。"}}
{"id": "2506.14596", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14596", "abs": "https://arxiv.org/abs/2506.14596", "authors": ["Ming Xu", "Xu Zhang"], "title": "PoseGRAF: Geometric-Reinforced Adaptive Fusion for Monocular 3D Human Pose Estimation", "comment": null, "summary": "Existing monocular 3D pose estimation methods primarily rely on joint positional features, while overlooking intrinsic directional and angular correlations within the skeleton. As a result, they often produce implausible poses under joint occlusions or rapid motion changes. To address these challenges, we propose the PoseGRAF framework. We first construct a dual graph convolutional structure that separately processes joint and bone graphs, effectively capturing their local dependencies. A Cross-Attention module is then introduced to model interdependencies between bone directions and joint features. Building upon this, a dynamic fusion module is designed to adaptively integrate both feature types by leveraging the relational dependencies between joints and bones. An improved Transformer encoder is further incorporated in a residual manner to generate the final output. Experimental results on the Human3.6M and MPI-INF-3DHP datasets show that our method exceeds state-of-the-art approaches. Additional evaluations on in-the-wild videos further validate its generalizability. The code is publicly available at https://github.com/iCityLab/PoseGRAF.", "AI": {"tldr": "PoseGRAF框架通过双图卷积结构和跨注意力模块改进单目3D姿态估计，解决了关节遮挡和快速运动变化的问题。", "motivation": "现有方法主要依赖关节位置特征，忽略了骨骼内在的方向和角度相关性，导致在关节遮挡或快速运动时产生不合理姿态。", "method": "构建双图卷积结构分别处理关节和骨骼图，引入跨注意力模块建模骨骼方向与关节特征的依赖关系，设计动态融合模块自适应整合特征，并改进Transformer编码器生成最终输出。", "result": "在Human3.6M和MPI-INF-3DHP数据集上表现优于现有方法，并在野外视频中验证了泛化能力。", "conclusion": "PoseGRAF通过结合关节和骨骼特征，显著提升了单目3D姿态估计的准确性和鲁棒性。"}}
{"id": "2506.14306", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.14306", "abs": "https://arxiv.org/abs/2506.14306", "authors": ["Ata Yalcin", "Asli Umay Ozturk", "Yigit Sever", "Viktoria Pauw", "Stephan Hachinger", "Ismail Hakki Toroslu", "Pinar Karagoz"], "title": "Fair for a few: Improving Fairness in Doubly Imbalanced Datasets", "comment": "33 pages, 3 figures, submitted to AI Review", "summary": "Fairness has been identified as an important aspect of Machine Learning and Artificial Intelligence solutions for decision making. Recent literature offers a variety of approaches for debiasing, however many of them fall short when the data collection is imbalanced. In this paper, we focus on a particular case, fairness in doubly imbalanced datasets, such that the data collection is imbalanced both for the label and the groups in the sensitive attribute. Firstly, we present an exploratory analysis to illustrate limitations in debiasing on a doubly imbalanced dataset. Then, a multi-criteria based solution is proposed for finding the most suitable sampling and distribution for label and sensitive attribute, in terms of fairness and classification accuracy", "AI": {"tldr": "本文探讨了在双重不平衡数据集（标签和敏感属性均不平衡）中实现公平性的挑战，并提出了一种基于多准则的解决方案。", "motivation": "机器学习中的公平性是一个重要问题，但现有方法在数据收集不平衡时效果不佳，尤其是在双重不平衡数据集上。", "method": "通过探索性分析揭示现有方法的局限性，并提出一种多准则方法，优化采样和分布以平衡公平性和分类准确性。", "result": "提出的方法在双重不平衡数据集中实现了更好的公平性和分类准确性。", "conclusion": "本文为双重不平衡数据集中的公平性问题提供了有效解决方案，强调了多准则方法的重要性。"}}
{"id": "2506.14603", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14603", "abs": "https://arxiv.org/abs/2506.14603", "authors": ["Amirmojtaba Sabour", "Sanja Fidler", "Karsten Kreis"], "title": "Align Your Flow: Scaling Continuous-Time Flow Map Distillation", "comment": "Project page: https://research.nvidia.com/labs/toronto-ai/AlignYourFlow/", "summary": "Diffusion- and flow-based models have emerged as state-of-the-art generative modeling approaches, but they require many sampling steps. Consistency models can distill these models into efficient one-step generators; however, unlike flow- and diffusion-based methods, their performance inevitably degrades when increasing the number of steps, which we show both analytically and empirically. Flow maps generalize these approaches by connecting any two noise levels in a single step and remain effective across all step counts. In this paper, we introduce two new continuous-time objectives for training flow maps, along with additional novel training techniques, generalizing existing consistency and flow matching objectives. We further demonstrate that autoguidance can improve performance, using a low-quality model for guidance during distillation, and an additional boost can be achieved by adversarial finetuning, with minimal loss in sample diversity. We extensively validate our flow map models, called Align Your Flow, on challenging image generation benchmarks and achieve state-of-the-art few-step generation performance on both ImageNet 64x64 and 512x512, using small and efficient neural networks. Finally, we show text-to-image flow map models that outperform all existing non-adversarially trained few-step samplers in text-conditioned synthesis.", "AI": {"tldr": "论文提出了一种名为Align Your Flow的流映射模型，通过新的连续时间目标和训练技术，改进了现有的一致性模型和流匹配目标，实现了高效的多步生成。", "motivation": "扩散和流模型需要多步采样，而一致性模型在增加步数时性能下降。流映射模型通过连接任意两个噪声级别，解决了这一问题。", "method": "提出了两种新的连续时间训练目标，结合自引导和对抗微调技术，训练流映射模型。", "result": "在ImageNet 64x64和512x512上实现了最先进的少步生成性能，并在文本到图像任务中表现优异。", "conclusion": "流映射模型在高效生成和性能上优于现有方法，适用于多种任务。"}}
{"id": "2506.14375", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14375", "abs": "https://arxiv.org/abs/2506.14375", "authors": ["Muhammad Hamza Yousuf", "Jason Li", "Sahar Vahdati", "Raphael Theilen", "Jakob Wittenstein", "Jens Lehmann"], "title": "IntelliLung: Advancing Safe Mechanical Ventilation using Offline RL with Hybrid Actions and Clinically Aligned Rewards", "comment": "under review, PAIS track @ ECAI 2025", "summary": "Invasive mechanical ventilation (MV) is a life-sustaining therapy for critically ill patients in the intensive care unit (ICU). However, optimizing its settings remains a complex and error-prone process due to patient-specific variability. While Offline Reinforcement Learning (RL) shows promise for MV control, current stateof-the-art (SOTA) methods struggle with the hybrid (continuous and discrete) nature of MV actions. Discretizing the action space limits available actions due to exponential growth in combinations and introduces distribution shifts that can compromise safety. In this paper, we propose optimizations that build upon prior work in action space reduction to address the challenges of discrete action spaces. We also adapt SOTA offline RL algorithms (IQL and EDAC) to operate directly on hybrid action spaces, thereby avoiding the pitfalls of discretization. Additionally, we introduce a clinically grounded reward function based on ventilator-free days and physiological targets, which provides a more meaningful optimization objective compared to traditional sparse mortality-based rewards. Our findings demonstrate that AI-assisted MV optimization may enhance patient safety and enable individualized lung support, representing a significant advancement toward intelligent, data-driven critical care solutions.", "AI": {"tldr": "论文提出了一种基于离线强化学习的方法，优化侵入性机械通气（MV）设置，避免离散化动作空间的限制，并引入临床相关的奖励函数。", "motivation": "侵入性机械通气（MV）设置优化复杂且易出错，现有方法因动作空间的混合特性（连续和离散）而受限。", "method": "通过动作空间缩减优化离散动作空间问题，并改进离线强化学习算法（IQL和EDAC）以直接处理混合动作空间。引入基于临床目标的奖励函数。", "result": "AI辅助的MV优化可提升患者安全性，实现个性化肺支持。", "conclusion": "该方法为智能、数据驱动的重症监护解决方案提供了重要进展。"}}
{"id": "2506.14605", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.14605", "abs": "https://arxiv.org/abs/2506.14605", "authors": ["Giacomo Meanti", "Thomas Ryckeboer", "Michael Arbel", "Julien Mairal"], "title": "Unsupervised Imaging Inverse Problems with Diffusion Distribution Matching", "comment": "Code available at https://github.com/inria-thoth/ddm4ip", "summary": "This work addresses image restoration tasks through the lens of inverse problems using unpaired datasets. In contrast to traditional approaches -- which typically assume full knowledge of the forward model or access to paired degraded and ground-truth images -- the proposed method operates under minimal assumptions and relies only on small, unpaired datasets. This makes it particularly well-suited for real-world scenarios, where the forward model is often unknown or misspecified, and collecting paired data is costly or infeasible. The method leverages conditional flow matching to model the distribution of degraded observations, while simultaneously learning the forward model via a distribution-matching loss that arises naturally from the framework. Empirically, it outperforms both single-image blind and unsupervised approaches on deblurring and non-uniform point spread function (PSF) calibration tasks. It also matches state-of-the-art performance on blind super-resolution. We also showcase the effectiveness of our method with a proof of concept for lens calibration: a real-world application traditionally requiring time-consuming experiments and specialized equipment. In contrast, our approach achieves this with minimal data acquisition effort.", "AI": {"tldr": "该论文提出了一种基于未配对数据集解决图像恢复任务的方法，适用于真实场景中前向模型未知或数据配对困难的情况。", "motivation": "传统方法通常需要完整的前向模型或配对数据，但在真实场景中这些条件难以满足，因此需要一种更灵活的方法。", "method": "利用条件流匹配建模退化观测的分布，并通过分布匹配损失学习前向模型。", "result": "在去模糊和非均匀点扩散函数校准任务中优于单图像盲方法和无监督方法，在盲超分辨率任务中达到先进水平。", "conclusion": "该方法在真实场景中表现优异，且数据需求低，适用于传统上需要复杂实验的任务。"}}
{"id": "2506.14386", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14386", "abs": "https://arxiv.org/abs/2506.14386", "authors": ["Christian H. X. Ali Mehmeti-Göpel", "Michael Wand"], "title": "ResNets Are Deeper Than You Think", "comment": "NeurIPS 2025 Submission", "summary": "Residual connections remain ubiquitous in modern neural network architectures nearly a decade after their introduction. Their widespread adoption is often credited to their dramatically improved trainability: residual networks train faster, more stably, and achieve higher accuracy than their feedforward counterparts. While numerous techniques, ranging from improved initialization to advanced learning rate schedules, have been proposed to close the performance gap between residual and feedforward networks, this gap has persisted. In this work, we propose an alternative explanation: residual networks do not merely reparameterize feedforward networks, but instead inhabit a different function space. We design a controlled post-training comparison to isolate generalization performance from trainability; we find that variable-depth architectures, similar to ResNets, consistently outperform fixed-depth networks, even when optimization is unlikely to make a difference. These results suggest that residual connections confer performance advantages beyond optimization, pointing instead to a deeper inductive bias aligned with the structure of natural data.", "AI": {"tldr": "残差连接不仅在训练中表现优越，还在泛化性能上优于固定深度网络，表明其具有与自然数据结构对齐的归纳偏置。", "motivation": "研究残差连接为何在性能上持续优于前馈网络，探讨其是否仅是参数化方式的改变还是涉及更深层次的功能空间差异。", "method": "设计了一个受控的后训练比较实验，分离泛化性能和训练能力的影响。", "result": "可变深度架构（如ResNet）在优化无关的情况下仍优于固定深度网络。", "conclusion": "残差连接的优势不仅源于优化，还与其对自然数据结构的归纳偏置有关。"}}
{"id": "2506.14629", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14629", "abs": "https://arxiv.org/abs/2506.14629", "authors": ["Md. Adnanul Islam", "Md. Faiyaz Abdullah Sayeedi", "Md. Asaduzzaman Shuvo", "Muhammad Ziaur Rahman", "Shahanur Rahman Bappy", "Raiyan Rahman", "Swakkhar Shatabda"], "title": "VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning", "comment": null, "summary": "Mosquito-borne diseases pose a major global health risk, requiring early detection and proactive control of breeding sites to prevent outbreaks. In this paper, we present VisText-Mosquito, a multimodal dataset that integrates visual and textual data to support automated detection, segmentation, and reasoning for mosquito breeding site analysis. The dataset includes 1,828 annotated images for object detection, 142 images for water surface segmentation, and natural language reasoning texts linked to each image. The YOLOv9s model achieves the highest precision of 0.92926 and mAP@50 of 0.92891 for object detection, while YOLOv11n-Seg reaches a segmentation precision of 0.91587 and mAP@50 of 0.79795. For reasoning generation, our fine-tuned BLIP model achieves a final loss of 0.0028, with a BLEU score of 54.7, BERTScore of 0.91, and ROUGE-L of 0.87. This dataset and model framework emphasize the theme \"Prevention is Better than Cure\", showcasing how AI-based detection can proactively address mosquito-borne disease risks. The dataset and implementation code are publicly available at GitHub: https://github.com/adnanul-islam-jisun/VisText-Mosquito", "AI": {"tldr": "VisText-Mosquito是一个多模态数据集，结合视觉和文本数据，用于蚊子孳生地的自动化检测、分割和推理分析。", "motivation": "蚊媒疾病是全球重大健康威胁，需通过早期检测和主动控制孳生地预防爆发。", "method": "数据集包含1,828张标注图像用于目标检测，142张用于水面分割，以及每张图像关联的自然语言推理文本。采用YOLOv9s和YOLOv11n-Seg模型进行检测与分割，BLIP模型用于推理生成。", "result": "YOLOv9s在目标检测中达到最高精度0.92926，mAP@50为0.92891；YOLOv11n-Seg分割精度为0.91587，mAP@50为0.79795。BLIP模型推理生成表现优异（BLEU 54.7，BERTScore 0.91）。", "conclusion": "数据集和模型框架强调“预防胜于治疗”，展示AI如何主动应对蚊媒疾病风险。数据和代码已开源。"}}
{"id": "2506.14390", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14390", "abs": "https://arxiv.org/abs/2506.14390", "authors": ["Conrad Orglmeister", "Erik Bochinski", "Volker Eiselein", "Elvira Fleig"], "title": "Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection", "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published in Computer Safety, Reliability and Security - SAFECOMP 2024 Workshops - DECSoS, SASSUR, TOASTS, and WAISE, and is available online at https://doi.org/10.1007/978-3-031-68738-9_29", "summary": "Understanding the decision-making and trusting the reliability of Deep Machine Learning Models is crucial for adopting such methods to safety-relevant applications. We extend self-explainable Prototypical Variational models with autoencoder-based out-of-distribution (OOD) detection: A Variational Autoencoder is applied to learn a meaningful latent space which can be used for distance-based classification, likelihood estimation for OOD detection, and reconstruction. The In-Distribution (ID) region is defined by a Gaussian mixture distribution with learned prototypes representing the center of each mode. Furthermore, a novel restriction loss is introduced that promotes a compact ID region in the latent space without collapsing it into single points. The reconstructive capabilities of the Autoencoder ensure the explainability of the prototypes and the ID region of the classifier, further aiding the discrimination of OOD samples. Extensive evaluations on common OOD detection benchmarks as well as a large-scale dataset from a real-world railway application demonstrate the usefulness of the approach, outperforming previous methods.", "AI": {"tldr": "论文提出了一种结合自解释原型变分模型和自编码器的方法，用于提高深度机器学习模型的可靠性和决策解释性，并通过新颖的限制损失优化了潜在空间的紧凑性。", "motivation": "为了提高深度机器学习模型在安全相关应用中的可靠性和可解释性，尤其是在处理分布外（OOD）样本时的表现。", "method": "使用变分自编码器学习有意义的潜在空间，结合高斯混合分布定义分布内（ID）区域，并引入限制损失以优化潜在空间的紧凑性。", "result": "在常见OOD检测基准和实际铁路应用数据集上表现优异，超越了现有方法。", "conclusion": "该方法通过结合原型解释性和OOD检测能力，显著提升了模型的可靠性和解释性。"}}
{"id": "2506.14642", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14642", "abs": "https://arxiv.org/abs/2506.14642", "authors": ["Yuke Xing", "Jiarui Wang", "Peizhi Niu", "Wenjie Huang", "Guangtao Zhai", "Yiling Xu"], "title": "3DGS-IEval-15K: A Large-scale Image Quality Evaluation Database for 3D Gaussian-Splatting", "comment": null, "summary": "3D Gaussian Splatting (3DGS) has emerged as a promising approach for novel view synthesis, offering real-time rendering with high visual fidelity. However, its substantial storage requirements present significant challenges for practical applications. While recent state-of-the-art (SOTA) 3DGS methods increasingly incorporate dedicated compression modules, there is a lack of a comprehensive framework to evaluate their perceptual impact. Therefore we present 3DGS-IEval-15K, the first large-scale image quality assessment (IQA) dataset specifically designed for compressed 3DGS representations. Our dataset encompasses 15,200 images rendered from 10 real-world scenes through 6 representative 3DGS algorithms at 20 strategically selected viewpoints, with different compression levels leading to various distortion effects. Through controlled subjective experiments, we collect human perception data from 60 viewers. We validate dataset quality through scene diversity and MOS distribution analysis, and establish a comprehensive benchmark with 30 representative IQA metrics covering diverse types. As the largest-scale 3DGS quality assessment dataset to date, our work provides a foundation for developing 3DGS specialized IQA metrics, and offers essential data for investigating view-dependent quality distribution patterns unique to 3DGS. The database is publicly available at https://github.com/YukeXing/3DGS-IEval-15K.", "AI": {"tldr": "论文提出了3DGS-IEval-15K数据集，用于评估压缩3D高斯泼溅（3DGS）表示的感知质量，包含15,200张图像，并通过主观实验收集人类感知数据。", "motivation": "现有3DGS方法缺乏评估压缩对感知影响的综合框架，因此需要大规模数据集支持研究。", "method": "构建包含10个真实场景、6种3DGS算法、20个视角和不同压缩级别的数据集，并通过60名观众的主观实验收集数据。", "result": "数据集验证了场景多样性和MOS分布，并建立了30种IQA指标的基准。", "conclusion": "3DGS-IEval-15K为开发3DGS专用IQA指标提供了基础，并支持研究3DGS特有的视角依赖质量分布模式。"}}
{"id": "2506.14391", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14391", "abs": "https://arxiv.org/abs/2506.14391", "authors": ["Yaqiao Zhu", "Hongkai Wen", "Geyong Min", "Man Luo"], "title": "HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control", "comment": null, "summary": "Efficient traffic signal control (TSC) is essential for mitigating urban congestion, yet existing reinforcement learning (RL) methods face challenges in scaling to large networks while maintaining global coordination. Centralized RL suffers from scalability issues, while decentralized approaches often lack unified objectives, resulting in limited network-level efficiency. In this paper, we propose HiLight, a hierarchical reinforcement learning framework with global adversarial guidance for large-scale TSC. HiLight consists of a high-level Meta-Policy, which partitions the traffic network into subregions and generates sub-goals using a Transformer-LSTM architecture, and a low-level Sub-Policy, which controls individual intersections with global awareness. To improve the alignment between global planning and local execution, we introduce an adversarial training mechanism, where the Meta-Policy generates challenging yet informative sub-goals, and the Sub-Policy learns to surpass these targets, leading to more effective coordination. We evaluate HiLight across both synthetic and real-world benchmarks, and additionally construct a large-scale Manhattan network with diverse traffic conditions, including peak transitions, adverse weather, and holiday surges. Experimental results show that HiLight exhibits significant advantages in large-scale scenarios and remains competitive across standard benchmarks of varying sizes.", "AI": {"tldr": "HiLight是一种分层强化学习框架，通过全局对抗性指导解决大规模交通信号控制问题，显著提升网络级效率。", "motivation": "现有强化学习方法在大规模网络中难以兼顾全局协调性和可扩展性，HiLight旨在解决这一问题。", "method": "HiLight采用分层结构，高层Meta-Policy分区并生成子目标，低层Sub-Policy控制交叉口，结合对抗训练机制优化全局与局部协调。", "result": "实验表明，HiLight在大规模场景中表现优异，并在不同规模的基准测试中保持竞争力。", "conclusion": "HiLight通过分层和对抗训练机制，有效解决了大规模交通信号控制的协调问题。"}}
{"id": "2506.14667", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14667", "abs": "https://arxiv.org/abs/2506.14667", "authors": ["Matt Poyser", "Toby P. Breckon"], "title": "DDS-NAS: Dynamic Data Selection within Neural Architecture Search via On-line Hard Example Mining applied to Image Classification", "comment": "27 single-column pages, 8 figures, to be published in Pattern Recognition", "summary": "In order to address the scalability challenge within Neural Architecture Search (NAS), we speed up NAS training via dynamic hard example mining within a curriculum learning framework. By utilizing an autoencoder that enforces an image similarity embedding in latent space, we construct an efficient kd-tree structure to order images by furthest neighbour dissimilarity in a low-dimensional embedding. From a given query image from our subsample dataset, we can identify the most dissimilar image within the global dataset in logarithmic time. Via curriculum learning, we then dynamically re-formulate an unbiased subsample dataset for NAS optimisation, upon which the current NAS solution architecture performs poorly. We show that our DDS-NAS framework speeds up gradient-based NAS strategies by up to 27x without loss in performance. By maximising the contribution of each image sample during training, we reduce the duration of a NAS training cycle and the number of iterations required for convergence.", "AI": {"tldr": "通过动态硬样本挖掘和课程学习框架加速神经架构搜索（NAS）训练，提出DDS-NAS框架，性能提升27倍。", "motivation": "解决神经架构搜索（NAS）的可扩展性挑战，通过动态选择对当前NAS架构表现较差的样本，优化训练效率。", "method": "使用自动编码器构建低维嵌入空间，通过kd树结构快速识别最不相似的样本，动态重组子数据集用于NAS优化。", "result": "DDS-NAS框架将基于梯度的NAS策略加速27倍，且不损失性能，减少训练周期和收敛所需迭代次数。", "conclusion": "动态硬样本挖掘和课程学习显著提升NAS训练效率，为大规模NAS应用提供可行方案。"}}
{"id": "2506.14400", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.14400", "abs": "https://arxiv.org/abs/2506.14400", "authors": ["Roland Roller", "Michael Hahn", "Ajay Madhavan Ravichandran", "Bilgin Osmanodja", "Florian Oetke", "Zeineb Sassi", "Aljoscha Burchardt", "Klaus Netter", "Klemens Budde", "Anne Herrmann", "Tobias Strapatsas", "Peter Dabrock", "Sebastian Möller"], "title": "One Size Fits None: Rethinking Fairness in Medical AI", "comment": "Accepted at the 6th Workshop on Gender Bias in Natural Language Processing at ACL 2025", "summary": "Machine learning (ML) models are increasingly used to support clinical decision-making. However, real-world medical datasets are often noisy, incomplete, and imbalanced, leading to performance disparities across patient subgroups. These differences raise fairness concerns, particularly when they reinforce existing disadvantages for marginalized groups. In this work, we analyze several medical prediction tasks and demonstrate how model performance varies with patient characteristics. While ML models may demonstrate good overall performance, we argue that subgroup-level evaluation is essential before integrating them into clinical workflows. By conducting a performance analysis at the subgroup level, differences can be clearly identified-allowing, on the one hand, for performance disparities to be considered in clinical practice, and on the other hand, for these insights to inform the responsible development of more effective models. Thereby, our work contributes to a practical discussion around the subgroup-sensitive development and deployment of medical ML models and the interconnectedness of fairness and transparency.", "AI": {"tldr": "该论文探讨了机器学习模型在临床决策中的公平性问题，强调了对患者亚组进行性能评估的重要性。", "motivation": "现实医疗数据存在噪声、不完整和不平衡问题，导致模型在不同患者亚组中表现不均，可能加剧边缘群体的劣势。", "method": "通过分析多个医疗预测任务，研究模型性能如何随患者特征变化，并进行亚组级别的性能评估。", "result": "研究发现，尽管模型整体表现良好，但在亚组间存在显著性能差异，需在临床实践中考虑这些差异。", "conclusion": "亚组敏感性的评估和开发对医疗ML模型的公平性和透明度至关重要，有助于更有效的模型开发。"}}
{"id": "2506.14674", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14674", "abs": "https://arxiv.org/abs/2506.14674", "authors": ["Ling Li", "Yao Zhou", "Yuxuan Liang", "Fugee Tsung", "Jiaheng Wei"], "title": "Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models", "comment": null, "summary": "Previous methods for image geo-localization have typically treated the task as either classification or retrieval, often relying on black-box decisions that lack interpretability. The rise of large vision-language models (LVLMs) has enabled a rethinking of geo-localization as a reasoning-driven task grounded in visual cues. However, two major challenges persist. On the data side, existing reasoning-focused datasets are primarily based on street-view imagery, offering limited scene diversity and constrained viewpoints. On the modeling side, current approaches predominantly rely on supervised fine-tuning, which yields only marginal improvements in reasoning capabilities. To address these challenges, we propose a novel pipeline that constructs a reasoning-oriented geo-localization dataset, MP16-Reason, using diverse social media images. We introduce GLOBE, Group-relative policy optimization for Locatability assessment and Optimized visual-clue reasoning, yielding Bi-objective geo-Enhancement for the VLM in recognition and reasoning. GLOBE incorporates task-specific rewards that jointly enhance locatability assessment, visual clue reasoning, and geolocation accuracy. Both qualitative and quantitative results demonstrate that GLOBE outperforms state-of-the-art open-source LVLMs on geo-localization tasks, particularly in diverse visual scenes, while also generating more insightful and interpretable reasoning trajectories.", "AI": {"tldr": "论文提出了一种新的图像地理定位方法GLOBE，通过构建多样化数据集MP16-Reason和优化视觉-语言模型的推理能力，显著提升了地理定位的准确性和可解释性。", "motivation": "现有地理定位方法缺乏可解释性，且数据集和模型推理能力有限，无法满足多样化场景需求。", "method": "提出GLOBE方法，结合MP16-Reason数据集和双目标优化策略，增强视觉线索推理和定位能力。", "result": "GLOBE在多样化场景中表现优于现有方法，生成更具洞察力的推理轨迹。", "conclusion": "GLOBE为地理定位任务提供了更高效、可解释的解决方案。"}}
{"id": "2506.14686", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14686", "abs": "https://arxiv.org/abs/2506.14686", "authors": ["Xi Chen", "Hengshuang Zhao"], "title": "FocalClick-XL: Towards Unified and High-quality Interactive Segmentation", "comment": null, "summary": "Interactive segmentation enables users to extract binary masks of target objects through simple interactions such as clicks, scribbles, and boxes. However, existing methods often support only limited interaction forms and struggle to capture fine details. In this paper, we revisit the classical coarse-to-fine design of FocalClick and introduce significant extensions. Inspired by its multi-stage strategy, we propose a novel pipeline, FocalClick-XL, to address these challenges simultaneously. Following the emerging trend of large-scale pretraining, we decompose interactive segmentation into meta-tasks that capture different levels of information -- context, object, and detail -- assigning a dedicated subnet to each level.This decomposition allows each subnet to undergo scaled pretraining with independent data and supervision, maximizing its effectiveness. To enhance flexibility, we share context- and detail-level information across different interaction forms as common knowledge while introducing a prompting layer at the object level to encode specific interaction types. As a result, FocalClick-XL achieves state-of-the-art performance on click-based benchmarks and demonstrates remarkable adaptability to diverse interaction formats, including boxes, scribbles, and coarse masks. Beyond binary mask generation, it is also capable of predicting alpha mattes with fine-grained details, making it a versatile and powerful tool for interactive segmentation.", "AI": {"tldr": "FocalClick-XL扩展了FocalClick的粗到细设计，通过多级子网络处理不同层次信息，支持多种交互形式，并在点击基准测试中达到最优性能。", "motivation": "现有交互式分割方法支持交互形式有限且难以捕捉细节，需改进。", "method": "提出FocalClick-XL，分解任务为上下文、对象和细节三级，每级用独立子网络预训练，并通过提示层编码交互类型。", "result": "在点击基准测试中表现最优，且能适应多种交互形式（如框、涂鸦），还能预测精细alpha遮罩。", "conclusion": "FocalClick-XL是一个多功能、强大的交互式分割工具，支持多种交互形式并捕捉细节。"}}
{"id": "2506.14420", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14420", "abs": "https://arxiv.org/abs/2506.14420", "authors": ["Ting Xiao", "Jiakun Zheng", "Rushuai Yang", "Kang Xu", "Qiaosheng Zhang", "Peng Liu", "Chenjia Bai"], "title": "Unsupervised Skill Discovery through Skill Regions Differentiation", "comment": null, "summary": "Unsupervised Reinforcement Learning (RL) aims to discover diverse behaviors that can accelerate the learning of downstream tasks. Previous methods typically focus on entropy-based exploration or empowerment-driven skill learning. However, entropy-based exploration struggles in large-scale state spaces (e.g., images), and empowerment-based methods with Mutual Information (MI) estimations have limitations in state exploration. To address these challenges, we propose a novel skill discovery objective that maximizes the deviation of the state density of one skill from the explored regions of other skills, encouraging inter-skill state diversity similar to the initial MI objective. For state-density estimation, we construct a novel conditional autoencoder with soft modularization for different skill policies in high-dimensional space. Meanwhile, to incentivize intra-skill exploration, we formulate an intrinsic reward based on the learned autoencoder that resembles count-based exploration in a compact latent space. Through extensive experiments in challenging state and image-based tasks, we find our method learns meaningful skills and achieves superior performance in various downstream tasks.", "AI": {"tldr": "提出一种新的无监督强化学习方法，通过最大化技能间状态密度的差异来促进多样性，同时利用条件自编码器估计状态密度，并在潜在空间中设计内在奖励。", "motivation": "解决现有熵探索和互信息方法在大规模状态空间（如图像）中的局限性，提升技能多样性和探索效率。", "method": "提出最大化技能间状态密度差异的目标，设计条件自编码器估计状态密度，并在潜在空间中实现基于计数的探索奖励。", "result": "在复杂任务中学习到有意义技能，并在下游任务中表现优异。", "conclusion": "该方法有效解决了现有无监督强化学习的探索和多样性问题，适用于高维状态空间。"}}
{"id": "2506.14696", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14696", "abs": "https://arxiv.org/abs/2506.14696", "authors": ["Dahang Wan", "Rongsheng Lu", "Yang Fang", "Xianli Lang", "Shuangbao Shu", "Jingjing Chen", "Siyuan Shen", "Ting Xu", "Zecong Ye"], "title": "YOLOv11-RGBT: Towards a Comprehensive Single-Stage Multispectral Object Detection Framework", "comment": "28 pages, 8 figures", "summary": "Multispectral object detection, which integrates information from multiple bands, can enhance detection accuracy and environmental adaptability, holding great application potential across various fields. Although existing methods have made progress in cross-modal interaction, low-light conditions, and model lightweight, there are still challenges like the lack of a unified single-stage framework, difficulty in balancing performance and fusion strategy, and unreasonable modality weight allocation. To address these, based on the YOLOv11 framework, we present YOLOv11-RGBT, a new comprehensive multimodal object detection framework. We designed six multispectral fusion modes and successfully applied them to models from YOLOv3 to YOLOv12 and RT-DETR. After reevaluating the importance of the two modalities, we proposed a P3 mid-fusion strategy and multispectral controllable fine-tuning (MCF) strategy for multispectral models. These improvements optimize feature fusion, reduce redundancy and mismatches, and boost overall model performance. Experiments show our framework excels on three major open-source multispectral object detection datasets, like LLVIP and FLIR. Particularly, the multispectral controllable fine-tuning strategy significantly enhanced model adaptability and robustness. On the FLIR dataset, it consistently improved YOLOv11 models' mAP by 3.41%-5.65%, reaching a maximum of 47.61%, verifying the framework and strategies' effectiveness. The code is available at: https://github.com/wandahangFY/YOLOv11-RGBT.", "AI": {"tldr": "论文提出了一种基于YOLOv11的多模态目标检测框架YOLOv11-RGBT，解决了现有方法在单阶段框架、性能与融合策略平衡以及模态权重分配方面的不足。通过设计六种多光谱融合模式、P3中融合策略和多光谱可控微调策略，显著提升了模型性能。", "motivation": "多光谱目标检测在多个领域具有应用潜力，但现有方法在统一框架、性能平衡和模态权重分配方面存在挑战。", "method": "基于YOLOv11框架，设计了六种多光谱融合模式，提出P3中融合策略和多光谱可控微调（MCF）策略。", "result": "在LLVIP和FLIR等数据集上表现优异，MCF策略使YOLOv11模型的mAP提升3.41%-5.65%，最高达47.61%。", "conclusion": "YOLOv11-RGBT框架和策略有效优化了特征融合，提升了模型适应性和鲁棒性。"}}
{"id": "2506.14436", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14436", "abs": "https://arxiv.org/abs/2506.14436", "authors": ["Shen Yuan", "Yin Zheng", "Taifeng Wang", "Binbin Liu", "Hongteng Xu"], "title": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "comment": "23 pages, 6 figures", "summary": "Adapting large-scale foundation models in multi-task scenarios often suffers from task conflict and oblivion. To mitigate such issues, we propose a novel ''model MoE-ization'' strategy that leads to a conflict- and oblivion-resistant multi-task adaptation method. Given a weight matrix of a pre-trained model, our method applies SVD to it and introduces a learnable router to adjust its singular values based on tasks and samples. Accordingly, the weight matrix becomes a Mixture of Orthogonal Rank-one Experts (MoORE), in which each expert corresponds to the outer product of a left singular vector and the corresponding right one. We can improve the model capacity by imposing a learnable orthogonal transform on the right singular vectors. Unlike low-rank adaptation (LoRA) and its MoE-driven variants, MoORE guarantees the experts' orthogonality and maintains the column space of the original weight matrix. These two properties make the adapted model resistant to the conflicts among the new tasks and the oblivion of its original tasks, respectively. Experiments on various datasets demonstrate that MoORE outperforms existing multi-task adaptation methods consistently, showing its superiority in terms of conflict- and oblivion-resistance. The code of the experiments is available at https://github.com/DaShenZi721/MoORE.", "AI": {"tldr": "提出了一种名为MoORE的新方法，通过SVD和可学习路由器调整预训练模型的权重矩阵，以解决多任务适应中的任务冲突和遗忘问题。", "motivation": "解决大规模基础模型在多任务适应中的任务冲突和遗忘问题。", "method": "使用SVD分解预训练模型的权重矩阵，引入可学习路由器调整奇异值，形成正交秩一专家混合（MoORE）。", "result": "实验表明，MoORE在多任务适应中优于现有方法，具有冲突和遗忘抵抗能力。", "conclusion": "MoORE是一种有效的多任务适应方法，能够同时抵抗任务冲突和遗忘。"}}
{"id": "2506.14706", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14706", "abs": "https://arxiv.org/abs/2506.14706", "authors": ["Ni Ou", "Zhuo Chen", "Xinru Zhang", "Junzheng Wang"], "title": "Iterative Camera-LiDAR Extrinsic Optimization via Surrogate Diffusion", "comment": "7 pages, 4 figures, accepted by IROS 2025", "summary": "Cameras and LiDAR are essential sensors for autonomous vehicles. The fusion of camera and LiDAR data addresses the limitations of individual sensors but relies on precise extrinsic calibration. Recently, numerous end-to-end calibration methods have been proposed; however, most predict extrinsic parameters in a single step and lack iterative optimization capabilities. To address the increasing demand for higher accuracy, we propose a versatile iterative framework based on surrogate diffusion. This framework can enhance the performance of any calibration method without requiring architectural modifications. Specifically, the initial extrinsic parameters undergo iterative refinement through a denoising process, in which the original calibration method serves as a surrogate denoiser to estimate the final extrinsics at each step. For comparative analysis, we selected four state-of-the-art calibration methods as surrogate denoisers and compared the results of our diffusion process with those of two other iterative approaches. Extensive experiments demonstrate that when integrated with our diffusion model, all calibration methods achieve higher accuracy, improved robustness, and greater stability compared to other iterative techniques and their single-step counterparts.", "AI": {"tldr": "提出了一种基于替代扩散的迭代框架，用于提升相机和LiDAR外参标定的精度和鲁棒性。", "motivation": "现有端到端标定方法多为单步预测，缺乏迭代优化能力，难以满足高精度需求。", "method": "通过替代扩散框架对初始外参进行迭代优化，原始标定方法作为替代去噪器逐步估计最终参数。", "result": "实验表明，该框架显著提升了四种先进标定方法的精度、鲁棒性和稳定性。", "conclusion": "该框架无需修改架构即可提升标定方法的性能，适用于高精度需求场景。"}}
{"id": "2506.14438", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14438", "abs": "https://arxiv.org/abs/2506.14438", "authors": ["Pol Arévalo", "Alexis Molina", "Álvaro Ciudad"], "title": "sHGCN: Simplified hyperbolic graph convolutional neural networks", "comment": null, "summary": "Hyperbolic geometry has emerged as a powerful tool for modeling complex, structured data, particularly where hierarchical or tree-like relationships are present. By enabling embeddings with lower distortion, hyperbolic neural networks offer promising alternatives to Euclidean-based models for capturing intricate data structures. Despite these advantages, they often face performance challenges, particularly in computational efficiency and tasks requiring high precision. In this work, we address these limitations by simplifying key operations within hyperbolic neural networks, achieving notable improvements in both runtime and performance. Our findings demonstrate that streamlined hyperbolic operations can lead to substantial gains in computational speed and predictive accuracy, making hyperbolic neural networks a more viable choice for a broader range of applications.", "AI": {"tldr": "本文提出简化双曲神经网络操作的方法，显著提升计算速度和预测精度，使其更适用于广泛任务。", "motivation": "双曲几何在建模复杂结构化数据（尤其是层次或树状关系）中表现出色，但双曲神经网络在计算效率和精度方面存在挑战。", "method": "通过简化双曲神经网络中的关键操作，优化其性能。", "result": "实验表明，简化操作显著提升了计算速度和预测准确性。", "conclusion": "优化后的双曲神经网络在更广泛的应用中更具可行性。"}}
{"id": "2506.14439", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14439", "abs": "https://arxiv.org/abs/2506.14439", "authors": ["Rikiya Takehi", "Masahiro Asami", "Kosuke Kawakami", "Yuta Saito"], "title": "A General Framework for Off-Policy Learning with Partially-Observed Reward", "comment": "10 pages, 5 figures. Published as a conference paper at ICLR 2025", "summary": "Off-policy learning (OPL) in contextual bandits aims to learn a decision-making policy that maximizes the target rewards by using only historical interaction data collected under previously developed policies. Unfortunately, when rewards are only partially observed, the effectiveness of OPL degrades severely. Well-known examples of such partial rewards include explicit ratings in content recommendations, conversion signals on e-commerce platforms that are partial due to delay, and the issue of censoring in medical problems. One possible solution to deal with such partial rewards is to use secondary rewards, such as dwelling time, clicks, and medical indicators, which are more densely observed. However, relying solely on such secondary rewards can also lead to poor policy learning since they may not align with the target reward. Thus, this work studies a new and general problem of OPL where the goal is to learn a policy that maximizes the expected target reward by leveraging densely observed secondary rewards as supplemental data. We then propose a new method called Hybrid Policy Optimization for Partially-Observed Reward (HyPeR), which effectively uses the secondary rewards in addition to the partially-observed target reward to achieve effective OPL despite the challenging scenario. We also discuss a case where we aim to optimize not only the expected target reward but also the expected secondary rewards to some extent; counter-intuitively, we will show that leveraging the two objectives is in fact advantageous also for the optimization of only the target reward. Along with statistical analysis of our proposed methods, empirical evaluations on both synthetic and real-world data show that HyPeR outperforms existing methods in various scenarios.", "AI": {"tldr": "该论文提出了一种名为HyPeR的新方法，用于在部分观测目标奖励的情况下，利用密集观测的次级奖励进行有效的离策略学习。", "motivation": "在部分观测奖励的背景下，传统离策略学习效果下降，而仅依赖次级奖励可能导致策略学习不佳。", "method": "提出HyPeR方法，结合部分观测的目标奖励和密集观测的次级奖励进行优化。", "result": "实验证明HyPeR在合成和真实数据上优于现有方法。", "conclusion": "利用次级奖励不仅能优化目标奖励，还能提升整体策略学习效果。"}}
{"id": "2506.14730", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14730", "abs": "https://arxiv.org/abs/2506.14730", "authors": ["Corey Scher", "Jamon Van Den Hoek"], "title": "Active InSAR monitoring of building damage in Gaza during the Israel-Hamas War", "comment": null, "summary": "Aerial bombardment of the Gaza Strip beginning October 7, 2023 is one of the most intense bombing campaigns of the twenty-first century, driving widespread urban damage. Characterizing damage over a geographically dynamic and protracted armed conflict requires active monitoring. Synthetic aperture radar (SAR) has precedence for mapping disaster-induced damage with bi-temporal methods but applications to active monitoring during sustained crises are limited. Using interferometric SAR data from Sentinel-1, we apply a long temporal-arc coherent change detection (LT-CCD) approach to track weekly damage trends over the first year of the 2023- Israel-Hamas War. We detect 92.5% of damage labels in reference data from the United Nations with a negligible (1.2%) false positive rate. The temporal fidelity of our approach reveals rapidly increasing damage during the first three months of the war focused in northern Gaza, a notable pause in damage during a temporary ceasefire, and surges of new damage as conflict hot-spots shift from north to south. Three-fifths (191,263) of all buildings are damaged or destroyed by the end of the study. With massive need for timely data on damage in armed conflict zones, our low-cost and low-latency approach enables rapid uptake of damage information at humanitarian and journalistic organizations.", "AI": {"tldr": "使用Sentinel-1的干涉SAR数据和长期时间相干变化检测（LT-CCD）方法，监测2023年加沙战争中的建筑破坏情况，准确率高且误报率低。", "motivation": "加沙地带的持续轰炸导致大规模城市破坏，需要实时监测以支持人道主义和新闻报道。", "method": "采用长期时间相干变化检测（LT-CCD）方法，利用Sentinel-1的干涉SAR数据，每周追踪破坏趋势。", "result": "检测到联合国参考数据中92.5%的破坏标签，误报率仅1.2%。战争前三个月破坏迅速增加，临时停火期间破坏暂停，随后破坏热点从北向南转移。研究结束时，五分之三的建筑（191,263栋）受损或摧毁。", "conclusion": "该方法成本低、延迟低，为人道主义和新闻机构提供了快速获取破坏信息的途径。"}}
{"id": "2506.14449", "categories": ["cs.LG", "physics.optics"], "pdf": "https://arxiv.org/pdf/2506.14449", "abs": "https://arxiv.org/abs/2506.14449", "authors": ["Lucas Kreiss", "Amey Chaware", "Maryam Roohian", "Sarah Lemire", "Oana-Maria Thoma", "Birgitta Carlé", "Maximilian Waldner", "Sebastian Schürmann", "Oliver Friedrich", "Roarke Horstmeyer"], "title": "Detecting immune cells with label-free two-photon autofluorescence and deep learning", "comment": null, "summary": "Label-free imaging has gained broad interest because of its potential to omit elaborate staining procedures which is especially relevant for in vivo use. Label-free multiphoton microscopy (MPM), for instance, exploits two-photon excitation of natural autofluorescence (AF) from native, metabolic proteins, making it ideal for in vivo endomicroscopy. Deep learning (DL) models have been widely used in other optical imaging technologies to predict specific target annotations and thereby digitally augment the specificity of these label-free images. However, this computational specificity has only rarely been implemented for MPM. In this work, we used a data set of label-free MPM images from a series of different immune cell types (5,075 individual cells for binary classification in mixed samples and 3,424 cells for a multi-class classification task) and trained a convolutional neural network (CNN) to classify cell types based on this label-free AF as input. A low-complexity squeezeNet architecture was able to achieve reliable immune cell classification results (0.89 ROC-AUC, 0.95 PR-AUC, for binary classification in mixed samples; 0.689 F1 score, 0.697 precision, 0.748 recall, and 0.683 MCC for six-class classification in isolated samples). Perturbation tests confirmed that the model is not confused by extracellular environment and that both input AF channels (NADH and FAD) are about equally important to the classification. In the future, such predictive DL models could directly detect specific immune cells in unstained images and thus, computationally improve the specificity of label-free MPM which would have great potential for in vivo endomicroscopy.", "AI": {"tldr": "该论文提出了一种基于深度学习的无标记多光子显微镜（MPM）图像分类方法，用于识别免疫细胞类型，展示了其高分类性能和在体内内窥镜中的潜在应用。", "motivation": "无标记成像技术避免了复杂的染色过程，适用于体内应用。然而，多光子显微镜（MPM）的计算特异性尚未充分开发，本研究旨在填补这一空白。", "method": "使用无标记MPM图像数据集（5,075个细胞用于二元分类，3,424个细胞用于多类分类），训练卷积神经网络（CNN）进行细胞类型分类。", "result": "模型在二元分类中表现优异（ROC-AUC 0.89，PR-AUC 0.95），在多类分类中也有不错表现（F1分数0.689）。扰动测试表明模型对输入通道（NADH和FAD）均依赖。", "conclusion": "这种深度学习模型有望直接检测未染色图像中的特定免疫细胞，提升无标记MPM的特异性，为体内内窥镜提供潜力。"}}
{"id": "2506.14742", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14742", "abs": "https://arxiv.org/abs/2506.14742", "authors": ["Ziqiao Peng", "Wentao Hu", "Junyuan Ma", "Xiangyu Zhu", "Xiaomei Zhang", "Hao Zhao", "Hui Tian", "Jun He", "Hongyan Liu", "Zhaoxin Fan"], "title": "SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting", "comment": null, "summary": "Achieving high synchronization in the synthesis of realistic, speech-driven talking head videos presents a significant challenge. A lifelike talking head requires synchronized coordination of subject identity, lip movements, facial expressions, and head poses. The absence of these synchronizations is a fundamental flaw, leading to unrealistic results. To address the critical issue of synchronization, identified as the ''devil'' in creating realistic talking heads, we introduce SyncTalk++, which features a Dynamic Portrait Renderer with Gaussian Splatting to ensure consistent subject identity preservation and a Face-Sync Controller that aligns lip movements with speech while innovatively using a 3D facial blendshape model to reconstruct accurate facial expressions. To ensure natural head movements, we propose a Head-Sync Stabilizer, which optimizes head poses for greater stability. Additionally, SyncTalk++ enhances robustness to out-of-distribution (OOD) audio by incorporating an Expression Generator and a Torso Restorer, which generate speech-matched facial expressions and seamless torso regions. Our approach maintains consistency and continuity in visual details across frames and significantly improves rendering speed and quality, achieving up to 101 frames per second. Extensive experiments and user studies demonstrate that SyncTalk++ outperforms state-of-the-art methods in synchronization and realism. We recommend watching the supplementary video: https://ziqiaopeng.github.io/synctalk++.", "AI": {"tldr": "SyncTalk++通过动态肖像渲染器和面部同步控制器，解决了语音驱动视频中身份、嘴唇、表情和头部姿态的同步问题，显著提升了真实感和渲染速度。", "motivation": "语音驱动视频合成中，同步问题（如身份、嘴唇、表情和头部姿态）是影响真实感的关键挑战，需解决。", "method": "提出SyncTalk++，包含动态肖像渲染器（高斯泼溅）、面部同步控制器（3D混合形状模型）、头部同步稳定器，并增强了对分布外音频的鲁棒性。", "result": "实验表明，SyncTalk++在同步性和真实感上优于现有方法，渲染速度达101帧/秒。", "conclusion": "SyncTalk++通过多模块协同，显著提升了语音驱动视频的真实感和效率。"}}
{"id": "2506.14457", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14457", "abs": "https://arxiv.org/abs/2506.14457", "authors": ["Freya Behrens", "Lenka Zdeborová"], "title": "Dataset distillation for memorized data: Soft labels can leak held-out teacher knowledge", "comment": "9 pages, 21 figures", "summary": "Dataset distillation aims to compress training data into fewer examples via a teacher, from which a student can learn effectively. While its success is often attributed to structure in the data, modern neural networks also memorize specific facts, but if and how such memorized information is can transferred in distillation settings remains less understood. In this work, we show that students trained on soft labels from teachers can achieve non-trivial accuracy on held-out memorized data they never directly observed. This effect persists on structured data when the teacher has not generalized.To analyze it in isolation, we consider finite random i.i.d. datasets where generalization is a priori impossible and a successful teacher fit implies pure memorization. Still, students can learn non-trivial information about the held-out data, in some cases up to perfect accuracy. In those settings, enough soft labels are available to recover the teacher functionally - the student matches the teacher's predictions on all possible inputs, including the held-out memorized data. We show that these phenomena strongly depend on the temperature with which the logits are smoothed, but persist across varying network capacities, architectures and dataset compositions.", "AI": {"tldr": "研究表明，学生模型通过教师模型的软标签可以学习未直接观察到的记忆数据，甚至在某些情况下达到完美准确率。", "motivation": "探讨在数据蒸馏中，学生模型如何通过教师模型的软标签学习记忆数据，以及这种现象的机制。", "method": "在有限随机独立同分布数据集上分析，确保教师模型仅记忆数据而非泛化，研究学生模型的表现。", "result": "学生模型能够从未直接观察的数据中学习非平凡信息，甚至在某些情况下完全匹配教师模型的预测。", "conclusion": "这种现象强烈依赖于软标签的温度参数，但在不同网络容量、架构和数据集组成中均存在。"}}
{"id": "2506.14753", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14753", "abs": "https://arxiv.org/abs/2506.14753", "authors": ["Qinchan", "Li", "Kenneth Chen", "Changyue", "Su", "Wittawat Jitkrittum", "Qi Sun", "Patsorn Sangkloy"], "title": "Cost-Aware Routing for Efficient Text-To-Image Generation", "comment": null, "summary": "Diffusion models are well known for their ability to generate a high-fidelity image for an input prompt through an iterative denoising process. Unfortunately, the high fidelity also comes at a high computational cost due the inherently sequential generative process. In this work, we seek to optimally balance quality and computational cost, and propose a framework to allow the amount of computation to vary for each prompt, depending on its complexity. Each prompt is automatically routed to the most appropriate text-to-image generation function, which may correspond to a distinct number of denoising steps of a diffusion model, or a disparate, independent text-to-image model. Unlike uniform cost reduction techniques (e.g., distillation, model quantization), our approach achieves the optimal trade-off by learning to reserve expensive choices (e.g., 100+ denoising steps) only for a few complex prompts, and employ more economical choices (e.g., small distilled model) for less sophisticated prompts. We empirically demonstrate on COCO and DiffusionDB that by learning to route to nine already-trained text-to-image models, our approach is able to deliver an average quality that is higher than that achievable by any of these models alone.", "AI": {"tldr": "提出了一种根据提示复杂度动态调整计算成本的框架，通过自动路由到最适合的文本到图像生成函数，平衡质量和计算开销。", "motivation": "扩散模型生成高质量图像但计算成本高，需要根据提示复杂度动态调整计算资源。", "method": "学习将提示路由到不同的预训练文本到图像模型或不同步数的扩散模型，以优化计算成本和质量。", "result": "在COCO和DiffusionDB上实验表明，该方法平均质量优于单独使用任一模型。", "conclusion": "通过动态路由策略，实现了计算成本与生成质量的最优平衡。"}}
{"id": "2506.14459", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14459", "abs": "https://arxiv.org/abs/2506.14459", "authors": ["Md. Mortuza Ahmmed", "Abdullah Al Noman", "Mahin Montasir Afif", "K. M. Tahsin Kabir", "Md. Mostafizur Rahman", "Mufti Mahmud"], "title": "A Model-Mediated Stacked Ensemble Approach for Depression Prediction Among Professionals", "comment": null, "summary": "Depression is a significant mental health concern, particularly in professional environments where work-related stress, financial pressure, and lifestyle imbalances contribute to deteriorating well-being. Despite increasing awareness, researchers and practitioners face critical challenges in developing accurate and generalizable predictive models for mental health disorders. Traditional classification approaches often struggle with the complexity of depression, as it is influenced by multifaceted, interdependent factors, including occupational stress, sleep patterns, and job satisfaction. This study addresses these challenges by proposing a stacking-based ensemble learning approach to improve the predictive accuracy of depression classification among professionals. The Depression Professional Dataset has been collected from Kaggle. The dataset comprises demographic, occupational, and lifestyle attributes that influence mental well-being. Our stacking model integrates multiple base learners with a logistic regression-mediated model, effectively capturing diverse learning patterns. The experimental results demonstrate that the proposed model achieves high predictive performance, with an accuracy of 99.64% on training data and 98.75% on testing data, with precision, recall, and F1-score all exceeding 98%. These findings highlight the effectiveness of ensemble learning in mental health analytics and underscore its potential for early detection and intervention strategies.", "AI": {"tldr": "该论文提出了一种基于堆叠的集成学习方法，用于提高专业人士抑郁症分类的预测准确性，实验结果显示模型性能优异。", "motivation": "抑郁症在职业环境中是一个严重的心理健康问题，传统分类方法难以应对其复杂性，因此需要更准确的预测模型。", "method": "使用堆叠集成学习方法，结合多个基础学习器和逻辑回归模型，利用Kaggle上的抑郁症专业数据集进行训练和测试。", "result": "模型在训练数据上准确率达99.64%，测试数据上达98.75%，精确率、召回率和F1分数均超过98%。", "conclusion": "集成学习在心理健康分析中效果显著，具有早期检测和干预的潜力。"}}
{"id": "2506.14765", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14765", "abs": "https://arxiv.org/abs/2506.14765", "authors": ["Nikolaos Dionelis", "Jente Bosmans", "Riccardo Musto", "Giancarlo Paoletti", "Simone Sarti", "Giacomo Cascarano", "Casper Fibaek", "Luke Camilleri", "Bertrand Le Saux", "Nicolas Longépé"], "title": "Scaling-Up the Pretraining of the Earth Observation Foundation Model PhilEO to the MajorTOM Dataset", "comment": "6 pages, 9 figures, 1 table, 29 references", "summary": "Today, Earth Observation (EO) satellites generate massive volumes of data, with the Copernicus Sentinel-2 constellation alone producing approximately 1.6TB per day. To fully exploit this information, it is essential to pretrain EO Foundation Models (FMs) on large unlabeled datasets, enabling efficient fine-tuning for several different downstream tasks with minimal labeled data. In this work, we present the scaling-up of our recently proposed EO Foundation Model, PhilEO Geo-Aware U-Net, on the unlabeled 23TB dataset MajorTOM, which covers the vast majority of the Earth's surface, as well as on the specialized subset FastTOM 2TB that does not include oceans and ice. We develop and study various PhilEO model variants with different numbers of parameters and architectures. Finally, we fine-tune the models on the PhilEO Bench for road density estimation, building density pixel-wise regression, and land cover semantic segmentation, and we evaluate the performance. Our results demonstrate that for all n-shots for road density regression, the PhilEO 44M MajorTOM 23TB model outperforms PhilEO Globe 0.5TB 44M. We also show that for most n-shots for road density estimation and building density regression, PhilEO 200M FastTOM outperforms all the other models. The effectiveness of both dataset and model scaling is validated using the PhilEO Bench. We also study the impact of architecture scaling, transitioning from U-Net Convolutional Neural Networks (CNN) to Vision Transformers (ViT).", "AI": {"tldr": "论文提出了一种基于大规模未标记数据的EO基础模型（PhilEO Geo-Aware U-Net），并在23TB数据集MajorTOM和2TB子集FastTOM上进行扩展研究。通过不同参数和架构的模型变体，验证了数据集和模型规模化的有效性，并探讨了从U-Net CNN到ViT的架构扩展影响。", "motivation": "充分利用地球观测卫星生成的海量数据，通过预训练基础模型实现高效微调，减少下游任务对标记数据的依赖。", "method": "在23TB的MajorTOM和2TB的FastTOM数据集上扩展PhilEO模型，研究不同参数和架构的变体，并在PhilEO Bench上进行微调和性能评估。", "result": "PhilEO 44M MajorTOM 23TB模型在道路密度回归任务中表现最佳，而PhilEO 200M FastTOM在道路密度估计和建筑密度回归任务中优于其他模型。", "conclusion": "数据集和模型规模化对性能提升显著，架构从U-Net CNN过渡到ViT也值得进一步研究。"}}
{"id": "2506.14460", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14460", "abs": "https://arxiv.org/abs/2506.14460", "authors": ["Junbin Qiu", "Zhengpeng Xie", "Xiangda Yan", "Yongjie Yang", "Yao Shu"], "title": "Zeroth-Order Optimization is Secretly Single-Step Policy Optimization", "comment": null, "summary": "Zeroth-Order Optimization (ZOO) provides powerful tools for optimizing functions where explicit gradients are unavailable or expensive to compute. However, the underlying mechanisms of popular ZOO methods, particularly those employing randomized finite differences, and their connection to other optimization paradigms like Reinforcement Learning (RL) are not fully elucidated. This paper establishes a fundamental and previously unrecognized connection: ZOO with finite differences is equivalent to a specific instance of single-step Policy Optimization (PO). We formally unveil that the implicitly smoothed objective function optimized by common ZOO algorithms is identical to a single-step PO objective. Furthermore, we show that widely used ZOO gradient estimators, are mathematically equivalent to the REINFORCE gradient estimator with a specific baseline function, revealing the variance-reducing mechanism in ZOO from a PO perspective.Built on this unified framework, we propose ZoAR (Zeroth-Order Optimization with Averaged Baseline and Query Reuse), a novel ZOO algorithm incorporating PO-inspired variance reduction techniques: an averaged baseline from recent evaluations and query reuse analogous to experience replay. Our theoretical analysis further substantiates these techniques reduce variance and enhance convergence. Extensive empirical studies validate our theory and demonstrate that ZoAR significantly outperforms other methods in terms of convergence speed and final performance. Overall, our work provides a new theoretical lens for understanding ZOO and offers practical algorithmic improvements derived from its connection to PO.", "AI": {"tldr": "本文揭示了零阶优化（ZOO）与策略优化（PO）的等价性，提出了一种结合方差减少技术的新算法ZoAR，并验证了其优越性能。", "motivation": "探索ZOO方法的机制及其与RL中PO的联系，以改进ZOO算法的效率和性能。", "method": "通过理论分析证明ZOO与单步PO的等价性，并提出ZoAR算法，结合了PO的方差减少技术（如平均基线和查询重用）。", "result": "ZoAR在收敛速度和最终性能上显著优于其他方法，理论分析支持其方差减少效果。", "conclusion": "研究为ZOO提供了新的理论视角，并通过与PO的联系提出了实用的算法改进。"}}
{"id": "2506.14766", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14766", "abs": "https://arxiv.org/abs/2506.14766", "authors": ["Yujun Wang", "Jinhe Bi", "Yunpu Ma", "Soeren Pirk"], "title": "ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM", "comment": "15 pages, 7 figures", "summary": "Multimodal Large Language Model (MLLM) often suffer from hallucinations. They over-rely on partial cues and generate incorrect responses. Recently, methods like Visual Contrastive Decoding (VCD) and Instruction Contrastive Decoding (ICD) have been proposed to mitigate hallucinations by contrasting predictions from perturbed or negatively prefixed inputs against original outputs. In this work, we uncover that methods like VCD and ICD fundamentally influence internal attention dynamics of the model. This observation suggests that their effectiveness may not stem merely from surface-level modifications to logits but from deeper shifts in attention distribution. Inspired by this insight, we propose an attention-steerable contrastive decoding framework that directly intervenes in attention mechanisms of the model to offer a more principled approach to mitigating hallucinations. Our experiments across multiple MLLM architectures and diverse decoding methods demonstrate that our approach significantly reduces hallucinations and improves the performance on benchmarks such as POPE, CHAIR, and MMHal-Bench, while simultaneously enhancing performance on standard VQA benchmarks.", "AI": {"tldr": "本文提出了一种基于注意力机制的可控对比解码框架，通过直接干预模型的注意力分布来减少多模态大语言模型（MLLM）的幻觉现象，并在多个基准测试中验证了其有效性。", "motivation": "多模态大语言模型（MLLM）常因过度依赖部分线索而产生幻觉，现有方法（如VCD和ICD）通过对比扰动输入或负前缀输入的预测结果来缓解这一问题。本文发现这些方法实际上影响了模型的内部注意力动态，因此提出更直接干预注意力机制的解决方案。", "method": "提出了一种注意力可控的对比解码框架，直接干预模型的注意力机制，以更原则性的方式减少幻觉。", "result": "实验表明，该方法在多个MLLM架构和不同解码方法中显著减少了幻觉现象，并在POPE、CHAIR和MMHal-Bench等基准测试中提升了性能，同时改善了标准VQA任务的性能。", "conclusion": "通过直接干预注意力机制，本文提出的框架为减少MLLM的幻觉提供了更有效的方法，并在多个任务中验证了其优越性。"}}
{"id": "2506.14472", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14472", "abs": "https://arxiv.org/abs/2506.14472", "authors": ["Fabien Bernier", "Maxime Cordy", "Yves Le Traon"], "title": "Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks", "comment": "ECML PKDD 2025", "summary": "Accurate electrical consumption forecasting is crucial for efficient energy management and resource allocation. While traditional time series forecasting relies on historical patterns and temporal dependencies, incorporating external factors -- such as weather indicators -- has shown significant potential for improving prediction accuracy in complex real-world applications. However, the inclusion of these additional features often degrades the performance of global predictive models trained on entire populations, despite improving individual household-level models. To address this challenge, we found that a hypernetwork architecture can effectively leverage external factors to enhance the accuracy of global electrical consumption forecasting models, by specifically adjusting the model weights to each consumer.\n  We collected a comprehensive dataset spanning two years, comprising consumption data from over 6000 luxembourgish households and corresponding external factors such as weather indicators, holidays, and major local events. By comparing various forecasting models, we demonstrate that a hypernetwork approach outperforms existing methods when associated to external factors, reducing forecasting errors and achieving the best accuracy while maintaining the benefits of a global model.", "AI": {"tldr": "本文提出了一种基于超网络架构的方法，通过结合外部因素（如天气指标）来提升全球电力消耗预测模型的准确性。", "motivation": "传统时间序列预测依赖历史模式和时序依赖，但加入外部因素可能降低全局模型的性能。本文旨在解决这一问题。", "method": "采用超网络架构，根据每个消费者调整模型权重，结合外部因素（如天气、节假日等）进行预测。", "result": "实验表明，超网络方法在结合外部因素时优于现有方法，减少了预测误差并保持了全局模型的优势。", "conclusion": "超网络架构能有效利用外部因素提升全球电力消耗预测的准确性。"}}
{"id": "2506.14515", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14515", "abs": "https://arxiv.org/abs/2506.14515", "authors": ["Prabhav Sanga", "Jaskaran Singh", "Arun K. Dubey"], "title": "Train Once, Forget Precisely: Anchored Optimization for Efficient Post-Hoc Unlearning", "comment": "Accepted at ICML MUGen'25", "summary": "As machine learning systems increasingly rely on data subject to privacy regulation, selectively unlearning specific information from trained models has become essential. In image classification, this involves removing the influence of particular training samples, semantic classes, or visual styles without full retraining. We introduce \\textbf{Forget-Aligned Model Reconstruction (FAMR)}, a theoretically grounded and computationally efficient framework for post-hoc unlearning in deep image classifiers. FAMR frames forgetting as a constrained optimization problem that minimizes a uniform-prediction loss on the forget set while anchoring model parameters to their original values via an $\\ell_2$ penalty. A theoretical analysis links FAMR's solution to influence-function-based retraining approximations, with bounds on parameter and output deviation. Empirical results on class forgetting tasks using CIFAR-10 and ImageNet-100 demonstrate FAMR's effectiveness, with strong performance retention and minimal computational overhead. The framework generalizes naturally to concept and style erasure, offering a scalable and certifiable route to efficient post-hoc forgetting in vision models.", "AI": {"tldr": "FAMR是一种高效的后处理遗忘框架，用于深度图像分类器，通过约束优化实现选择性遗忘。", "motivation": "随着机器学习系统依赖受隐私法规约束的数据，选择性遗忘特定信息变得至关重要。", "method": "FAMR将遗忘问题转化为约束优化，最小化遗忘集的均匀预测损失，并通过ℓ2惩罚锚定模型参数。", "result": "在CIFAR-10和ImageNet-100上的实验表明，FAMR在保留性能的同时实现了高效遗忘。", "conclusion": "FAMR为视觉模型提供了一种可扩展且可验证的高效后处理遗忘方法。"}}
{"id": "2506.14521", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14521", "abs": "https://arxiv.org/abs/2506.14521", "authors": ["Korbinian Pfab", "Marcel Rothering"], "title": "Towards Improved Research Methodologies for Industrial AI: A case study of false call reduction", "comment": "Submitted and accepted to IEEE COMPSAC 2025", "summary": "Are current artificial intelligence (AI) research methodologies ready to create successful, productive, and profitable AI applications? This work presents a case study on an industrial AI use case called false call reduction for automated optical inspection to demonstrate the shortcomings of current best practices. We identify seven weaknesses prevalent in related peer-reviewed work and experimentally show their consequences. We show that the best-practice methodology would fail for this use case. We argue amongst others for the necessity of requirement-aware metrics to ensure achieving business objectives, clear definitions of success criteria, and a thorough analysis of temporal dynamics in experimental datasets. Our work encourages researchers to critically assess their methodologies for more successful applied AI research.", "AI": {"tldr": "论文通过工业AI案例研究指出当前AI研究方法的不足，提出改进方向。", "motivation": "探讨当前AI研究方法是否能成功应用于工业场景，揭示其局限性。", "method": "通过工业AI案例（自动光学检测中的误报减少）分析，识别七种常见弱点并实验验证其影响。", "result": "证明当前最佳实践方法在此案例中会失败，提出需求感知指标等改进建议。", "conclusion": "呼吁研究者批判性评估方法，以提升应用AI研究的成功率。"}}
{"id": "2506.14529", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14529", "abs": "https://arxiv.org/abs/2506.14529", "authors": ["Xiaohan Zheng", "Lanning Wei", "Yong Li", "Quanming Yao"], "title": "Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution", "comment": null, "summary": "Effective decision-making on networks often relies on learning from graph-structured data, where Graph Neural Networks (GNNs) play a central role, but they take efforts to configure and tune. In this demo, we propose LLMNet, showing how to design GNN automated through Large Language Models. Our system develops a set of agents that construct graph-related knowlege bases and then leverages Retrieval-Augmented Generation (RAG) to support automated configuration and refinement of GNN models through a knowledge-guided evolution process. These agents, equipped with specialized knowledge bases, extract insights into tasks and graph structures by interacting with the knowledge bases. Empirical results show LLMNet excels in twelve datasets across three graph learning tasks, validating its effectiveness of GNN model designing.", "AI": {"tldr": "LLMNet利用大型语言模型自动设计GNN，通过知识库和检索增强生成技术优化模型配置，在多个数据集上表现优异。", "motivation": "解决GNN配置和调优的复杂性，提出自动化设计方法。", "method": "开发基于知识库的代理系统，利用RAG技术实现GNN的自动化配置和优化。", "result": "在12个数据集和3个图学习任务中验证了LLMNet的有效性。", "conclusion": "LLMNet为GNN设计提供了一种高效、自动化的解决方案。"}}
{"id": "2506.14540", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14540", "abs": "https://arxiv.org/abs/2506.14540", "authors": ["Gerardo A. Flores", "Alyssa H. Smith", "Julia A. Fukuyama", "Ashia C. Wilson"], "title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs", "comment": null, "summary": "Machine learning-based decision support systems are increasingly deployed in clinical settings, where probabilistic scoring functions are used to inform and prioritize patient management decisions. However, widely used scoring rules, such as accuracy and AUC-ROC, fail to adequately reflect key clinical priorities, including calibration, robustness to distributional shifts, and sensitivity to asymmetric error costs. In this work, we propose a principled yet practical evaluation framework for selecting calibrated thresholded classifiers that explicitly accounts for the uncertainty in class prevalences and domain-specific cost asymmetries often found in clinical settings. Building on the theory of proper scoring rules, particularly the Schervish representation, we derive an adjusted variant of cross-entropy (log score) that averages cost-weighted performance over clinically relevant ranges of class balance. The resulting evaluation is simple to apply, sensitive to clinical deployment conditions, and designed to prioritize models that are both calibrated and robust to real-world variations.", "AI": {"tldr": "提出了一种基于临床优先级的评估框架，用于选择校准的分类器，考虑了类别分布不确定性和成本不对称性。", "motivation": "现有评分规则（如准确率和AUC-ROC）未能充分反映临床优先级，如校准性、分布偏移鲁棒性和错误成本不对称性。", "method": "基于Schervish表示理论，提出了一种调整后的交叉熵变体，用于在临床相关类别平衡范围内评估模型。", "result": "该方法简单易用，对临床部署条件敏感，优先选择校准且鲁棒的模型。", "conclusion": "该框架为临床决策支持系统提供了一种更符合实际需求的评估方法。"}}
{"id": "2506.14563", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14563", "abs": "https://arxiv.org/abs/2506.14563", "authors": ["Jesse St. Amand", "Leonardo Gizzi", "Martin A. Giese"], "title": "Single-Example Learning in a Mixture of GPDMs with Latent Geometries", "comment": "13 pages, 2 figures, 3 tables", "summary": "We present the Gaussian process dynamical mixture model (GPDMM) and show its utility in single-example learning of human motion data. The Gaussian process dynamical model (GPDM) is a form of the Gaussian process latent variable model (GPLVM), but optimized with a hidden Markov model dynamical prior. The GPDMM combines multiple GPDMs in a probabilistic mixture-of-experts framework, utilizing embedded geometric features to allow for diverse sequences to be encoded in a single latent space, enabling the categorization and generation of each sequence class. GPDMs and our mixture model are particularly advantageous in addressing the challenges of modeling human movement in scenarios where data is limited and model interpretability is vital, such as in patient-specific medical applications like prosthesis control. We score the GPDMM on classification accuracy and generative ability in single-example learning, showcase model variations, and benchmark it against LSTMs, VAEs, and transformers.", "AI": {"tldr": "GPDMM是一种结合GPDM和概率混合专家框架的模型，用于单样本学习人体运动数据，支持分类和生成任务。", "motivation": "解决在数据有限且模型可解释性重要的场景（如医疗应用）中建模人体运动的挑战。", "method": "结合多个GPDM，利用几何特征在单一潜在空间中编码多样序列。", "result": "在分类准确性和生成能力上表现优异，并与LSTM、VAE和Transformer进行了对比。", "conclusion": "GPDMM在单样本学习任务中具有优势，适用于医疗等需要高可解释性的领域。"}}
{"id": "2506.14574", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14574", "abs": "https://arxiv.org/abs/2506.14574", "authors": ["Mingkang Zhu", "Xi Chen", "Zhongdao Wang", "Bei Yu", "Hengshuang Zhao", "Jiaya Jia"], "title": "TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization", "comment": "ICML 2025", "summary": "Recent advancements in reinforcement learning from human feedback have shown that utilizing fine-grained token-level reward models can substantially enhance the performance of Proximal Policy Optimization (PPO) in aligning large language models. However, it is challenging to leverage such token-level reward as guidance for Direct Preference Optimization (DPO), since DPO is formulated as a sequence-level bandit problem. To address this challenge, this work decomposes the sequence-level PPO into a sequence of token-level proximal policy optimization problems and then frames the problem of token-level PPO with token-level reward guidance, from which closed-form optimal token-level policy and the corresponding token-level reward can be derived. Using the obtained reward and Bradley-Terry model, this work establishes a framework of computable loss functions with token-level reward guidance for DPO, and proposes a practical reward guidance based on the induced DPO reward. This formulation enables different tokens to exhibit varying degrees of deviation from reference policy based on their respective rewards. Experiment results demonstrate that our method achieves substantial performance improvements over DPO, with win rate gains of up to 7.5 points on MT-Bench, 6.2 points on AlpacaEval 2, and 4.3 points on Arena-Hard. Code is available at https://github.com/dvlab-research/TGDPO.", "AI": {"tldr": "论文提出了一种将序列级PPO分解为令牌级问题的方法，利用令牌级奖励指导DPO，显著提升了性能。", "motivation": "解决DPO难以利用令牌级奖励的问题，提升对齐大型语言模型的性能。", "method": "将序列级PPO分解为令牌级问题，推导出令牌级最优策略和奖励，并基于Bradley-Terry模型设计可计算的损失函数。", "result": "在多个基准测试中性能显著提升，MT-Bench、AlpacaEval 2和Arena-Hard分别获得7.5、6.2和4.3点的胜率提升。", "conclusion": "该方法有效解决了DPO的令牌级奖励利用问题，显著提升了模型性能。"}}
{"id": "2506.14698", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.14698", "abs": "https://arxiv.org/abs/2506.14698", "authors": ["Sidney Bender", "Jan Herrmann", "Klaus-Robert Müller", "Grégoire Montavon"], "title": "Towards Desiderata-Driven Design of Visual Counterfactual Explainers", "comment": null, "summary": "Visual counterfactual explainers (VCEs) are a straightforward and promising approach to enhancing the transparency of image classifiers. VCEs complement other types of explanations, such as feature attribution, by revealing the specific data transformations to which a machine learning model responds most strongly. In this paper, we argue that existing VCEs focus too narrowly on optimizing sample quality or change minimality; they fail to consider the more holistic desiderata for an explanation, such as fidelity, understandability, and sufficiency. To address this shortcoming, we explore new mechanisms for counterfactual generation and investigate how they can help fulfill these desiderata. We combine these mechanisms into a novel 'smooth counterfactual explorer' (SCE) algorithm and demonstrate its effectiveness through systematic evaluations on synthetic and real data.", "AI": {"tldr": "本文提出了一种新的视觉反事实解释方法（SCE），旨在解决现有方法在解释全面性上的不足。", "motivation": "现有视觉反事实解释（VCEs）过于关注样本质量或最小变化，忽略了解释的保真性、可理解性和充分性等更全面的需求。", "method": "探索新的反事实生成机制，并将其整合为一种新颖的“平滑反事实探索器”（SCE）算法。", "result": "通过合成数据和真实数据的系统评估，验证了SCE算法的有效性。", "conclusion": "SCE算法能够更好地满足解释的全面需求，提升图像分类器的透明度。"}}
{"id": "2506.14577", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14577", "abs": "https://arxiv.org/abs/2506.14577", "authors": ["Abdul Rahman Jacob", "Avinash Kori", "Emanuele De Angelis", "Ben Glocker", "Maurizio Proietti", "Francesca Toni"], "title": "Object-Centric Neuro-Argumentative Learning", "comment": "Proceedings of Machine Learning Research, 2025 19th Conference on Neurosymbolic Learning and Reasoning", "summary": "Over the last decade, as we rely more on deep learning technologies to make critical decisions, concerns regarding their safety, reliability and interpretability have emerged. We introduce a novel Neural Argumentative Learning (NAL) architecture that integrates Assumption-Based Argumentation (ABA) with deep learning for image analysis. Our architecture consists of neural and symbolic components. The former segments and encodes images into facts using object-centric learning, while the latter applies ABA learning to develop ABA frameworks enabling predictions with images. Experiments on synthetic data show that the NAL architecture can be competitive with a state-of-the-art alternative.", "AI": {"tldr": "论文提出了一种结合假设基础论证（ABA）与深度学习的神经论证学习（NAL）架构，用于图像分析，旨在提升模型的可靠性、安全性和可解释性。", "motivation": "随着深度学习在关键决策中的应用增加，其安全性、可靠性和可解释性问题日益突出，需要新的解决方案。", "method": "NAL架构包含神经和符号组件：神经部分通过对象中心学习分割和编码图像为事实，符号部分应用ABA学习生成ABA框架以进行图像预测。", "result": "在合成数据上的实验表明，NAL架构与现有先进方法具有竞争力。", "conclusion": "NAL架构为深度学习模型的可解释性和可靠性提供了一种有前景的解决方案。"}}
{"id": "2506.14587", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14587", "abs": "https://arxiv.org/abs/2506.14587", "authors": ["Shuo Yang", "Bardh Prenkaj", "Gjergji Kasneci"], "title": "SCISSOR: Mitigating Semantic Bias through Cluster-Aware Siamese Networks for Robust Classification", "comment": "20 pages", "summary": "Shortcut learning undermines model generalization to out-of-distribution data. While the literature attributes shortcuts to biases in superficial features, we show that imbalances in the semantic distribution of sample embeddings induce spurious semantic correlations, compromising model robustness. To address this issue, we propose SCISSOR (Semantic Cluster Intervention for Suppressing ShORtcut), a Siamese network-based debiasing approach that remaps the semantic space by discouraging latent clusters exploited as shortcuts. Unlike prior data-debiasing approaches, SCISSOR eliminates the need for data augmentation and rewriting. We evaluate SCISSOR on 6 models across 4 benchmarks: Chest-XRay and Not-MNIST in computer vision, and GYAFC and Yelp in NLP tasks. Compared to several baselines, SCISSOR reports +5.3 absolute points in F1 score on GYAFC, +7.3 on Yelp, +7.7 on Chest-XRay, and +1 on Not-MNIST. SCISSOR is also highly advantageous for lightweight models with ~9.5% improvement on F1 for ViT on computer vision datasets and ~11.9% for BERT on NLP. Our study redefines the landscape of model generalization by addressing overlooked semantic biases, establishing SCISSOR as a foundational framework for mitigating shortcut learning and fostering more robust, bias-resistant AI systems.", "AI": {"tldr": "SCISSOR是一种基于Siamese网络的去偏方法，通过抑制语义聚类中的捷径学习，提升模型在分布外数据上的泛化能力。", "motivation": "现有方法主要关注表面特征的偏差，而忽略了语义分布不平衡导致的虚假相关性。SCISSOR旨在解决这一问题。", "method": "提出SCISSOR方法，通过重新映射语义空间，抑制被用作捷径的潜在聚类，无需数据增强或重写。", "result": "在多个基准测试中，SCISSOR显著提升了模型性能，尤其在轻量级模型上表现突出。", "conclusion": "SCISSOR通过解决语义偏差，为抑制捷径学习和构建更鲁棒的AI系统提供了基础框架。"}}
{"id": "2506.14597", "categories": ["cs.LG", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14597", "abs": "https://arxiv.org/abs/2506.14597", "authors": ["Thomas Newman", "Christopher Nemeth", "Matthew Jones", "Philip Jonathan"], "title": "Deep Learning Surrogates for Real-Time Gas Emission Inversion", "comment": "3 figures, 11 pages", "summary": "Real-time identification and quantification of greenhouse-gas emissions under transient atmospheric conditions is a critical challenge in environmental monitoring. We introduce a spatio-temporal inversion framework that embeds a deep-learning surrogate of computational fluid dynamics (CFD) within a sequential Monte Carlo algorithm to perform Bayesian inference of both emission rate and source location in dynamic flow fields. By substituting costly numerical solvers with a multilayer perceptron trained on high-fidelity CFD outputs, our surrogate captures spatial heterogeneity and temporal evolution of gas dispersion, while delivering near-real-time predictions. Validation on the Chilbolton methane release dataset demonstrates comparable accuracy to full CFD solvers and Gaussian plume models, yet achieves orders-of-magnitude faster runtimes. Further experiments under simulated obstructed-flow scenarios confirm robustness in complex environments. This work reconciles physical fidelity with computational feasibility, offering a scalable solution for industrial emissions monitoring and other time-sensitive spatio-temporal inversion tasks in environmental and scientific modeling.", "AI": {"tldr": "提出了一种结合深度学习与贝叶斯推理的时空反演框架，用于实时识别和量化动态气流中的温室气体排放。", "motivation": "解决动态大气条件下温室气体排放实时监测的挑战。", "method": "将深度学习替代计算流体动力学（CFD）嵌入顺序蒙特卡洛算法，进行排放率和源位置的贝叶斯推断。", "result": "验证显示与CFD和高斯羽流模型精度相当，但运行速度快多个数量级。", "conclusion": "该框架在保持物理保真度的同时实现了计算可行性，适用于工业排放监测等任务。"}}
{"id": "2506.14607", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.14607", "abs": "https://arxiv.org/abs/2506.14607", "authors": ["Ziyu Gong", "Jim Lim", "David I. Inouye"], "title": "Expressive Score-Based Priors for Distribution Matching with Geometry-Preserving Regularization", "comment": "32 pages, 20 figures. Accepted to ICML 2025", "summary": "Distribution matching (DM) is a versatile domain-invariant representation learning technique that has been applied to tasks such as fair classification, domain adaptation, and domain translation. Non-parametric DM methods struggle with scalability and adversarial DM approaches suffer from instability and mode collapse. While likelihood-based methods are a promising alternative, they often impose unnecessary biases through fixed priors or require explicit density models (e.g., flows) that can be challenging to train. We address this limitation by introducing a novel approach to training likelihood-based DM using expressive score-based prior distributions. Our key insight is that gradient-based DM training only requires the prior's score function -- not its density -- allowing us to train the prior via denoising score matching. This approach eliminates biases from fixed priors (e.g., in VAEs), enabling more effective use of geometry-preserving regularization, while avoiding the challenge of learning an explicit prior density model (e.g., a flow-based prior). Our method also demonstrates better stability and computational efficiency compared to other diffusion-based priors (e.g., LSGM). Furthermore, experiments demonstrate superior performance across multiple tasks, establishing our score-based method as a stable and effective approach to distribution matching. Source code available at https://github.com/inouye-lab/SAUB.", "AI": {"tldr": "提出了一种基于分数的分布匹配方法，解决了现有方法的可扩展性、不稳定性和模式崩溃问题，并通过实验验证了其优越性能。", "motivation": "现有非参数分布匹配方法难以扩展，对抗性方法不稳定且易出现模式崩溃，而基于似然的方法因固定先验或显式密度模型存在局限性。", "method": "使用基于分数的先验分布训练似然分布匹配，通过去噪分数匹配训练先验，避免固定先验偏差和显式密度模型挑战。", "result": "方法在稳定性和计算效率上优于其他扩散先验方法，并在多个任务中表现优异。", "conclusion": "基于分数的分布匹配方法是一种稳定且高效的新方法，适用于多种任务。"}}
{"id": "2506.14619", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14619", "abs": "https://arxiv.org/abs/2506.14619", "authors": ["Paolo Ascia", "Elena Raponi", "Thomas Bäck", "Fabian Duddeck"], "title": "Feasibility-Driven Trust Region Bayesian Optimization", "comment": "Accepted for publication at AutoML2025", "summary": "Bayesian optimization is a powerful tool for solving real-world optimization tasks under tight evaluation budgets, making it well-suited for applications involving costly simulations or experiments. However, many of these tasks are also characterized by the presence of expensive constraints whose analytical formulation is unknown and often defined in high-dimensional spaces where feasible regions are small, irregular, and difficult to identify. In such cases, a substantial portion of the optimization budget may be spent just trying to locate the first feasible solution, limiting the effectiveness of existing methods. In this work, we present a Feasibility-Driven Trust Region Bayesian Optimization (FuRBO) algorithm. FuRBO iteratively defines a trust region from which the next candidate solution is selected, using information from both the objective and constraint surrogate models. Our adaptive strategy allows the trust region to shift and resize significantly between iterations, enabling the optimizer to rapidly refocus its search and consistently accelerate the discovery of feasible and good-quality solutions. We empirically demonstrate the effectiveness of FuRBO through extensive testing on the full BBOB-constrained COCO benchmark suite and other physics-inspired benchmarks, comparing it against state-of-the-art baselines for constrained black-box optimization across varying levels of constraint severity and problem dimensionalities ranging from 2 to 60.", "AI": {"tldr": "提出了一种基于可行性驱动的信任区域贝叶斯优化算法（FuRBO），用于在约束条件下快速发现高质量解。", "motivation": "现实优化任务中常存在高维、未知约束且可行区域小的问题，导致现有方法在寻找可行解时耗费大量资源。", "method": "FuRBO通过迭代定义信任区域，结合目标和约束代理模型信息，动态调整搜索范围。", "result": "在BBOB-constrained COCO基准测试和其他物理相关任务中，FuRBO显著优于现有方法。", "conclusion": "FuRBO能高效解决高维约束优化问题，尤其在可行区域小的情况下表现突出。"}}
{"id": "2506.14746", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14746", "abs": "https://arxiv.org/abs/2506.14746", "authors": ["Nataly Brukhim", "Aldo Pacchiano", "Miroslav Dudik", "Robert Schapire"], "title": "On the Hardness of Bandit Learning", "comment": "13 main pages", "summary": "We study the task of bandit learning, also known as best-arm identification, under the assumption that the true reward function f belongs to a known, but arbitrary, function class F. We seek a general theory of bandit learnability, akin to the PAC framework for classification. Our investigation is guided by the following two questions: (1) which classes F are learnable, and (2) how they are learnable. For example, in the case of binary PAC classification, learnability is fully determined by a combinatorial dimension - the VC dimension- and can be attained via a simple algorithmic principle, namely, empirical risk minimization (ERM). In contrast to classical learning-theoretic results, our findings reveal limitations of learning in structured bandits, offering insights into the boundaries of bandit learnability. First, for the question of \"which\", we show that the paradigm of identifying the learnable classes via a dimension-like quantity fails for bandit learning. We give a simple proof demonstrating that no combinatorial dimension can characterize bandit learnability, even in finite classes, following a standard definition of dimension introduced by Ben-David et al. (2019). For the question of \"how\", we prove a computational hardness result: we construct a reward function class for which at most two queries are needed to find the optimal action, yet no algorithm can do so in polynomial time unless RP=NP. We also prove that this class admits efficient algorithms for standard algorithmic operations often considered in learning theory, such as an ERM. This implies that computational hardness is in this case inherent to the task of bandit learning. Beyond these results, we investigate additional themes such as learning under noise, trade-offs between noise models, and the relationship between query complexity and regret minimization.", "AI": {"tldr": "本文研究了在已知函数类F下的多臂老虎机学习问题，探讨了哪些函数类是可学习的以及如何学习，揭示了结构化老虎机学习的局限性。", "motivation": "旨在建立一个类似于PAC分类框架的多臂老虎机学习理论，解决函数类F的可学习性问题。", "method": "通过组合维度和计算复杂度分析，证明了没有组合维度能完全表征老虎机学习的可学习性，并构造了一个计算困难的函数类。", "result": "发现组合维度无法表征老虎机学习的可学习性，且存在计算困难的函数类，即使其查询复杂度低。", "conclusion": "结构化老虎机学习存在理论和计算上的局限性，为未来的研究提供了边界和方向。"}}
