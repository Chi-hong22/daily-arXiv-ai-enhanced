<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 94]
- [cs.NE](#cs.NE) [Total: 5]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.RO](#cs.RO) [Total: 30]
- [cs.LG](#cs.LG) [Total: 59]
- [eess.SY](#eess.SY) [Total: 10]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.SD](#cs.SD) [Total: 6]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.HC](#cs.HC) [Total: 27]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

TL;DR: 提出一种基于潜在噪声自编码器的隐私增强机制，保护用户视线数据隐私，同时保持数据可用性。


<details>
  <summary>Details</summary>
Motivation: 保护用户视线数据隐私，防止未经同意的跨会话重识别，同时确保数据在良性任务中的可用性。

Method: 使用潜在噪声自编码器处理视线信号，平衡隐私与效用。

Result: 显著降低生物识别可能性，同时效用损失最小，保留生理合理的视线模式。

Conclusion: 该机制在视线系统中有效保护隐私，同时保持数据实用性。

Abstract: We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [2] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

TL;DR: 本文综述了基于多模态大语言模型（MLLMs）的视频时序定位（VTG）研究，分析了其功能角色、训练范式及视频特征处理技术，并总结了当前局限性与未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在视频时序定位中表现优异，但相关综述稀缺，本文旨在填补这一空白。

Method: 通过三维分类法系统分析VTG-MLLMs：功能角色、训练范式和视频特征处理技术。

Result: 总结了现有研究的实证发现，并讨论了基准数据集和评估协议。

Conclusion: 指出了当前研究的局限性，并提出了未来研究方向。

Abstract: The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [3] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: VSF是一种通过翻转负提示的注意力值符号来动态抑制不需要内容的方法，适用于少步扩散和流匹配图像生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CFG、NASA和NAG）在负提示引导方面存在不足，VSF旨在以低计算开销高效解决这一问题。

Method: VSF通过翻转负提示的注意力值符号动态抑制不需要的内容，兼容多种架构（如MMDiT和基于交叉注意力的模型）。

Result: 实验表明，VSF在少步和非少步模型中均显著优于现有方法，同时保持图像质量。

Conclusion: VSF是一种高效且性能优越的负提示引导方法，适用于多种图像生成任务。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [4] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

TL;DR: ViPE是一种高效视频处理引擎，用于从无约束视频中估计相机参数和深度图，性能优于现有基线，并用于标注大规模视频数据集。


<details>
  <summary>Details</summary>
Motivation: 解决从野外视频中获取一致且精确的3D注释的挑战，支持多种场景和相机模型。

Method: ViPE通过估计相机内参、相机运动和密集深度图来处理视频，适用于动态自拍、电影镜头等多种场景。

Result: 在TUM/KITTI序列上性能提升18%/50%，运行速度为3-5FPS，并标注了包含100K互联网视频、1M AI生成视频和2K全景视频的大规模数据集。

Conclusion: ViPE及其标注数据集的开源旨在加速空间AI系统的发展。

Abstract: Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [5] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

TL;DR: 论文提出了一种基于相机姿态自动编码器（PAE）的相对姿态回归（RPR）方法，用于改进单图像绝对姿态回归（APR）的定位精度，无需额外存储图像或姿态数据。


<details>
  <summary>Details</summary>
Motivation: 现代零售环境中，精确的相机定位对提升客户体验、优化库存管理和实现自主操作至关重要。现有APR方法虽有效，但结合视觉和空间场景先验的方法通常更精确。

Method: 扩展PAE至RPR任务，并提出一种新的重定位方案，利用PAE-based RPR优化APR预测，无需额外数据存储。通过对比实验验证其有效性。

Result: 在室内基准测试中，PAE-based RPR显著提升了APR的定位精度，且仅需30%的训练数据即可达到竞争性能，大幅降低数据收集负担。

Conclusion: 该方法为零售环境中的相机定位提供了一种高效且数据需求低的解决方案，具有实际应用潜力。

Abstract: Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [6] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

TL;DR: HQ-OV3D框架通过跨模态几何一致性和基于DDIM的去噪机制，生成高质量伪标签，显著提升开放词汇3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统封闭集3D检测无法满足开放世界应用需求，现有开放词汇方法忽略几何质量。

Method: 提出HQ-OV3D框架，包含IMCV提案生成器和ACA去噪器，利用几何一致性和标注类先验优化伪标签。

Result: 相比现有方法，mAP提升7.37%。

Conclusion: HQ-OV3D可作为独立检测器或插件伪标签生成器，提升开放词汇检测性能。

Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [7] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

TL;DR: 提出了一种基于稀疏3D语义高斯泼溅的协作3D语义占用预测方法，解决了现有方法的高通信成本或依赖深度估计的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉方法在3D语义占用预测中依赖密集3D体素或2D平面特征，导致高通信成本或额外监督需求，限制了协作场景的适用性。

Method: 通过共享和融合中间高斯基元，实现跨代理融合、几何与语义联合编码，以及稀疏对象中心消息传递。

Result: 在mIoU和IoU上分别优于单代理感知和基线协作方法，通信量减少时仍保持性能优势。

Conclusion: 该方法在协作感知中表现出高效性和鲁棒性，适用于通信资源有限的环境。

Abstract: Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [8] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

TL;DR: 论文提出了一种新的面部超分辨率方法IDFSR，通过解耦和拟合身份信息，解决了极端退化场景下身份一致性和真实感恢复的挑战。


<details>
  <summary>Details</summary>
Motivation: 在极端退化场景下（如放大倍数>8倍），传统方法难以恢复真实且身份一致的面部图像，容易产生幻觉效果。

Method: IDFSR采用三种关键设计：1）掩码低分辨率图像中的面部区域；2）对齐参考图像以提供风格指导；3）利用真实图像提取的身份嵌入进行细粒度建模。

Result: 实验表明，IDFSR在极端退化条件下显著优于现有方法，尤其在身份一致性方面表现突出。

Conclusion: IDFSR通过解耦和拟合身份信息，有效提升了极端退化场景下的面部超分辨率性能。

Abstract: In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [9] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

TL;DR: 论文探讨了利用深度学习自动分类越南常见木材种类，ShuffleNetV2模型在性能和效率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统木材分类方法耗时且依赖专家知识，深度学习可提供高效自动化解决方案。

Method: 构建自定义图像数据集，评估五种卷积神经网络架构。

Result: ShuffleNetV2平均准确率达99.29%，F1分数99.35%。

Conclusion: 轻量级深度学习模型适用于资源受限环境的高精度木材分类。

Abstract: Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [10] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

TL;DR: NIRMAL Pooling是一种新型的CNN池化层，结合自适应最大池化和非线性激活函数，在图像分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 改进传统池化方法，提升CNN在图像分类任务中的鲁棒性和特征表达能力。

Method: 动态调整池化参数，结合ReLU激活函数，应用于MNIST Digits、MNIST Fashion和CIFAR-10数据集。

Result: 在MNIST Digits、MNIST Fashion和CIFAR-10上分别达到99.25%、91.59%和70.49%的准确率，优于传统最大池化。

Conclusion: NIRMAL Pooling为图像识别任务提供了更灵活可靠的池化方法，性能显著提升。

Abstract: This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [11] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

TL;DR: 论文研究了Artcodes的检测问题，提出了一种新的特征描述符（形状方向直方图）来识别拓扑结构相似的物体，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着智能手机和VR/AR技术的普及，环境中虚拟与现实结合的物体增多，识别这些物体是触发后续交互的第一步。Artcodes是一种兼具人类可读性和机器可读性的装饰标记，但其拓扑结构复杂，检测具有挑战性。

Method: 提出了一种新的特征描述符——形状方向直方图，用于描述Artcodes的通用拓扑结构，并构建了Artcode检测系统。

Result: 实验结果表明，该特征描述符能有效表示拓扑结构，检测系统性能良好。

Conclusion: 尽管是初步尝试，但该研究为拓扑物体检测开辟了新方向，具有潜在的应用前景。

Abstract: The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [12] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

TL;DR: 该研究提出了一种量化干纺织增强材料在压实过程中嵌套行为的框架，使用低分辨率CT扫描和3D-UNet进行语义分割，并通过两点相关函数分析空间结构，结果与显微图像验证一致。


<details>
  <summary>Details</summary>
Motivation: 理解纺织增强复合材料的多尺度结构对预测其机械性能（如刚度、渗透性和损伤容限）至关重要，而嵌套行为是影响这些性能的关键因素。

Method: 通过低分辨率CT扫描进行原位压实实验，使用3D-UNet对材料进行语义分割，并通过两点相关函数分析空间结构。

Result: 模型在语义分割中达到平均IoU为0.822和F1分数为0.902，空间结构分析结果与显微图像验证一致。

Conclusion: 该方法为从工业相关CT数据中提取关键几何特征提供了可靠途径，并为复合材料预成型体的逆向建模和基于描述符的结构分析奠定了基础。

Abstract: A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [13] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: iWatchRoad是一个端到端系统，用于自动检测坑洼、GPS标记和实时地图绘制，适用于印度多样化的道路环境。


<details>
  <summary>Details</summary>
Motivation: 印度道路上的坑洼对安全和车辆寿命构成威胁，需要高效且经济的解决方案。

Method: 利用自注释数据集和YOLO模型进行实时坑洼检测，结合OCR模块提取时间戳并与GPS同步，数据通过OSM可视化。

Result: 系统在复杂条件下提高了检测准确性，并生成政府可用的道路评估数据。

Conclusion: iWatchRoad是一种成本低、硬件高效且可扩展的解决方案，适用于发展中国家的道路管理。

Abstract: Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>


### [14] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

TL;DR: 本文提出了一种名为增量补丁生成（IPG）的方法，用于高效生成对抗性补丁，比现有方法效率提升11.1倍，同时保持攻击性能。


<details>
  <summary>Details</summary>
Motivation: 对抗性补丁对AI模型的鲁棒性构成挑战，尤其是在计算机视觉任务中。

Method: IPG方法通过实验和消融研究（如YOLO特征分布可视化和对抗训练结果）验证其有效性。

Result: IPG生成的补丁能覆盖更广泛的模型漏洞，并可作为构建鲁棒模型的知识基础。

Conclusion: IPG在对抗性补丁防御和实际应用（如自动驾驶、医疗影像）中具有潜力。

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [15] [MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text](https://arxiv.org/abs/2508.10947)
*Ronghao Xu,Zhen Huang,Yangbo Wei,Xiaoqian Zhou,Zikang Xu,Ting Liu,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: MedAtlas是一个新的医学多模态基准框架，旨在评估大型语言模型在真实医学推理任务中的表现，填补现有医学基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态基准通常局限于单图像、单轮任务，无法捕捉临床实践中的多模态交互和纵向特性。

Method: MedAtlas支持多轮对话、多模态医学图像交互、多任务集成和高临床保真度，包含四种核心任务，并引入新的评估指标。

Result: 基准测试显示现有多模态模型在多阶段临床推理中存在显著性能差距。

Conclusion: MedAtlas为开发稳健可信的医学AI提供了一个具有挑战性的评估平台。

Abstract: Artificial intelligence has demonstrated significant potential in clinical
decision-making; however, developing models capable of adapting to diverse
real-world scenarios and performing complex diagnostic reasoning remains a
major challenge. Existing medical multi-modal benchmarks are typically limited
to single-image, single-turn tasks, lacking multi-modal medical image
integration and failing to capture the longitudinal and multi-modal interactive
nature inherent to clinical practice. To address this gap, we introduce
MedAtlas, a novel benchmark framework designed to evaluate large language
models on realistic medical reasoning tasks. MedAtlas is characterized by four
key features: multi-turn dialogue, multi-modal medical image interaction,
multi-task integration, and high clinical fidelity. It supports four core
tasks: open-ended multi-turn question answering, closed-ended multi-turn
question answering, multi-image joint reasoning, and comprehensive disease
diagnosis. Each case is derived from real diagnostic workflows and incorporates
temporal interactions between textual medical histories and multiple imaging
modalities, including CT, MRI, PET, ultrasound, and X-ray, requiring models to
perform deep integrative reasoning across images and clinical texts. MedAtlas
provides expert-annotated gold standards for all tasks. Furthermore, we propose
two novel evaluation metrics: Round Chain Accuracy and Error Propagation
Resistance. Benchmark results with existing multi-modal models reveal
substantial performance gaps in multi-stage clinical reasoning. MedAtlas
establishes a challenging evaluation platform to advance the development of
robust and trustworthy medical AI.

</details>


### [16] [From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement](https://arxiv.org/abs/2508.10950)
*Xinyi Wang,Michael Barnett,Frederique Boonstra,Yael Barnett,Mariano Cabezas,Arkiev D'Souza,Matthew C. Kiernan,Kain Kyle,Meng Law,Lynette Masters,Zihao Tang,Stephen Tisch,Sicong Tu,Anneke Van Der Walt,Dongang Wang,Fernando Calamante,Weidong Cai,Chenyu Wang*

Main category: cs.CV

TL;DR: FastFOD-Net是一种优化的深度学习框架，用于提升扩散MRI中的纤维取向分布（FOD）质量，并在健康对照和多种神经系统疾病中验证其性能。


<details>
  <summary>Details</summary>
Motivation: 解决临床单壳低角度分辨率MRI数据生成可靠FOD的挑战，并推动深度学习在扩散MRI增强中的临床应用。

Method: 采用加速端到端深度学习框架FastFOD-Net，提升FOD性能并优化训练/推理效率。

Result: FastFOD-Net在临床评估中表现优异，速度比前代快60倍，适用于疾病区分和连接组分析。

Conclusion: FastFOD-Net有望加速临床神经科学研究，降低测量误差，并增强深度学习在扩散MRI中的临床信任。

Abstract: Fiber orientation distribution (FOD) is an advanced diffusion MRI modeling
technique that represents complex white matter fiber configurations, and a key
step for subsequent brain tractography and connectome analysis. Its reliability
and accuracy, however, heavily rely on the quality of the MRI acquisition and
the subsequent estimation of the FODs at each voxel. Generating reliable FODs
from widely available clinical protocols with single-shell and
low-angular-resolution acquisitions remains challenging but could potentially
be addressed with recent advances in deep learning-based enhancement
techniques. Despite advancements, existing methods have predominantly been
assessed on healthy subjects, which have proved to be a major hurdle for their
clinical adoption. In this work, we validate a newly optimized enhancement
framework, FastFOD-Net, across healthy controls and six neurological disorders.
This accelerated end-to-end deep learning framework enhancing FODs with
superior performance and delivering training/inference efficiency for clinical
use ($60\times$ faster comparing to its predecessor). With the most
comprehensive clinical evaluation to date, our work demonstrates the potential
of FastFOD-Net in accelerating clinical neuroscience research, empowering
diffusion MRI analysis for disease differentiation, improving interpretability
in connectome applications, and reducing measurement errors to lower sample
size requirements. Critically, this work will facilitate the more widespread
adoption of, and build clinical trust in, deep learning based methods for
diffusion MRI enhancement. Specifically, FastFOD-Net enables robust analysis of
real-world, clinical diffusion MRI data, comparable to that achievable with
high-quality research acquisitions.

</details>


### [17] [Empowering Multimodal LLMs with External Tools: A Comprehensive Survey](https://arxiv.org/abs/2508.10955)
*Wenbin An,Jiahao Nie,Yaqiang Wu,Feng Tian,Shijian Lu,Qinghua Zheng*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）通过结合外部工具提升性能，本文综述了工具在数据获取、任务性能、模型评估及未来方向的作用。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在多模态任务中表现优异，但数据质量、复杂任务表现和评估不足限制了其可靠性。受人类利用外部工具的启发，本文探讨如何通过工具增强MLLMs。

Method: 从四个维度分析外部工具的作用：高质量数据获取、任务性能提升、模型评估改进及未来发展方向。

Result: 外部工具在提升MLLMs能力方面具有潜力，尤其在数据、任务和评估方面。

Conclusion: 外部工具是推动MLLMs发展的关键，未来需进一步探索其应用和局限性。

Abstract: By integrating the perception capabilities of multimodal encoders with the
generative power of Large Language Models (LLMs), Multimodal Large Language
Models (MLLMs), exemplified by GPT-4V, have achieved great success in various
multimodal tasks, pointing toward a promising pathway to artificial general
intelligence. Despite this progress, the limited quality of multimodal data,
poor performance on many complex downstream tasks, and inadequate evaluation
protocols continue to hinder the reliability and broader applicability of MLLMs
across diverse domains. Inspired by the human ability to leverage external
tools for enhanced reasoning and problem-solving, augmenting MLLMs with
external tools (e.g., APIs, expert models, and knowledge bases) offers a
promising strategy to overcome these challenges. In this paper, we present a
comprehensive survey on leveraging external tools to enhance MLLM performance.
Our discussion is structured along four key dimensions about external tools:
(1) how they can facilitate the acquisition and annotation of high-quality
multimodal data; (2) how they can assist in improving MLLM performance on
challenging downstream tasks; (3) how they enable comprehensive and accurate
evaluation of MLLMs; (4) the current limitations and future directions of
tool-augmented MLLMs. Through this survey, we aim to underscore the
transformative potential of external tools in advancing MLLM capabilities,
offering a forward-looking perspective on their development and applications.
The project page of this paper is publicly available
athttps://github.com/Lackel/Awesome-Tools-for-MLLMs.

</details>


### [18] [ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks](https://arxiv.org/abs/2508.10956)
*Abhishek Kolari,Mohammadhossein Khojasteh,Yifan Jiang,Floris den Hengst,Filip Ilievski*

Main category: cs.CV

TL;DR: 论文提出了ORBIT，一个多层次的视觉问答（VQA）基准测试，用于评估视觉语言模型（VLMs）在对象属性推理上的表现。实验显示现有VLMs在复杂推理和真实图像上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前VQA基准测试在对象属性推理上存在局限性，缺乏多样性和复杂性，无法全面评估VLMs的能力。

Method: 提出ORBIT基准测试，包含360张图像和1,080个计数问题，涵盖三种图像类型、三种推理复杂度和四种对象属性维度。

Result: 在零样本设置下，12种先进VLMs表现显著低于人类，最佳模型准确率仅40%，尤其在真实图像和复杂推理上表现较差。

Conclusion: ORBIT揭示了VLMs在对象属性推理上的不足，呼吁开发更可扩展的基准测试和更强推理能力的模型。

Abstract: While vision-language models (VLMs) have made remarkable progress on many
popular visual question answering (VQA) benchmarks, it remains unclear whether
they abstract and reason over depicted objects. Inspired by human object
categorisation, object property reasoning involves identifying and recognising
low-level details and higher-level abstractions. While current VQA benchmarks
consider a limited set of object property attributes like size, they typically
blend perception and reasoning, and lack representativeness in terms of
reasoning and image categories. To this end, we introduce a systematic
evaluation framework with images of three representative types, three reasoning
levels of increasing complexity, and four object property dimensions driven by
prior work on commonsense reasoning. We develop a procedure to instantiate this
benchmark into ORBIT, a multi-level reasoning VQA benchmark for object
properties comprising 360 images paired with a total of 1,080 count-based
questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings
reveal significant limitations compared to humans, with the best-performing
model only reaching 40\% accuracy. VLMs struggle particularly with realistic
(photographic) images, counterfactual reasoning about physical and functional
properties, and higher counts. ORBIT points to the need to develop methods for
scalable benchmarking, generalize annotation guidelines, and explore additional
reasoning VLMs. We make the ORBIT benchmark and the experimental code available
to support such endeavors.

</details>


### [19] [CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving](https://arxiv.org/abs/2508.10962)
*Jiarong Li,Imad Ali Shah,Diarmaid Geever,Fiachra Collins,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 论文提出了一种基于高光谱成像（HSI）的方法，通过选择信息量最大的波段来增强对易受伤害道路使用者（VRU）的感知能力，减少视觉模糊问题。


<details>
  <summary>Details</summary>
Motivation: 解决因RGB图像中的同色异谱现象导致的VRU感知困难，提升自动驾驶系统的安全性。

Method: 结合信息论技术和图像质量指标，选择最具信息量的HSI波段，并重建伪彩色图像进行对比。

Result: 选定的HSI波段在多个指标上显著优于RGB，提升了VRU与背景的区分度。

Conclusion: 该方法为ADAS和AD系统提供了更优的感知输入，有助于提高道路安全性。

Abstract: Protecting Vulnerable Road Users (VRU) is a critical safety challenge for
automotive perception systems, particularly under visual ambiguity caused by
metamerism, a phenomenon where distinct materials appear similar in RGB
imagery. This work investigates hyperspectral imaging (HSI) to overcome this
limitation by capturing unique material signatures beyond the visible spectrum,
especially in the Near-Infrared (NIR). To manage the inherent
high-dimensionality of HSI data, we propose a band selection strategy that
integrates information theory techniques (joint mutual information
maximization, correlation analysis) with a novel application of an image
quality metric (contrast signal-to-noise ratio) to identify the most spectrally
informative bands. Using the Hyperspectral City V2 (H-City) dataset, we
identify three informative bands (497 nm, 607 nm, and 895 nm, $\pm$27 nm) and
reconstruct pseudo-color images for comparison with co-registered RGB.
Quantitative results demonstrate increased dissimilarity and perceptual
separability of VRU from the background. The selected HSI bands yield
improvements of 70.24%, 528.46%, 1206.83%, and 246.62% for dissimilarity
(Euclidean, SAM, $T^2$) and perception (CIE $\Delta E$) metrics, consistently
outperforming RGB and confirming a marked reduction in metameric confusion. By
providing a spectrally optimized input, our method enhances VRU separability,
establishing a robust foundation for downstream perception tasks in Advanced
Driver Assistance Systems (ADAS) and Autonomous Driving (AD), ultimately
contributing to improved road safety.

</details>


### [20] [EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963)
*Zixiang Yang,Yue Ma,Yinhan Zhang,Shanhui Mo,Dongrui Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: EVCtrl是一种轻量级控制适配器，通过时空双缓存策略减少冗余计算，显著提升图像和视频生成效率。


<details>
  <summary>Details</summary>
Motivation: 当前ControlNet在可控生成中存在计算冗余和延迟问题，尤其在视频生成中表现明显。

Method: 提出时空双缓存策略：空间上分区处理控制信号，时间上选择性跳过冗余去噪步骤。

Result: 在多个基准测试中，EVCtrl实现了2倍以上的速度提升，且生成质量几乎无损。

Conclusion: EVCtrl无需重新训练模型即可高效实现可控生成，具有广泛适用性。

Abstract: Visual generation includes both image and video generation, training
probabilistic models to create coherent, diverse, and semantically faithful
content from scratch. While early research focused on unconditional sampling,
practitioners now demand controllable generation that allows precise
specification of layout, pose, motion, or style. While ControlNet grants
precise spatial-temporal control, its auxiliary branch markedly increases
latency and introduces redundant computation in both uncontrolled regions and
denoising steps, especially for video. To address this problem, we introduce
EVCtrl, a lightweight, plug-and-play control adapter that slashes overhead
without retraining the model. Specifically, we propose a spatio-temporal dual
caching strategy for sparse control information. For spatial redundancy, we
first profile how each layer of DiT-ControlNet responds to fine-grained
control, then partition the network into global and local functional zones. A
locality-aware cache focuses computation on the local zones that truly need the
control signal, skipping the bulk of redundant computation in global regions.
For temporal redundancy, we selectively omit unnecessary denoising steps to
improve efficiency. Extensive experiments on CogVideo-Controlnet,
Wan2.1-Controlnet, and Flux demonstrate that our method is effective in image
and video control generation without the need for training. For example, it
achieves 2.16 and 2.05 times speedups on CogVideo-Controlnet and
Wan2.1-Controlnet, respectively, with almost no degradation in generation
quality.Codes are available in the supplementary materials.

</details>


### [21] [Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision](https://arxiv.org/abs/2508.10972)
*Rosiana Natalie,Wenqian Xu,Ruei-Che Chang,Rada Mihalcea,Anhong Guo*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型（VLMs）在模拟低视力人群视觉感知方面的能力，发现提供视觉信息和示例图像响应的组合能显著提高模拟准确性。


<details>
  <summary>Details</summary>
Motivation: 探索VLMs在无障碍领域的模拟能力，填补了此前研究的空白。

Method: 通过调查40名低视力参与者收集数据，构建VLM模拟代理，评估其与参与者原始回答的一致性。

Result: 仅提供视觉信息或示例图像响应时一致性较低（0.59），组合两者显著提高一致性（0.70）。单一示例结合开放和选择题响应效果最佳。

Conclusion: VLMs在模拟低视力人群视觉感知时需结合视觉信息和示例响应，单一示例已足够，额外示例无显著提升。

Abstract: Advances in vision language models (VLMs) have enabled the simulation of
general human behavior through their reasoning and problem solving
capabilities. However, prior research has not investigated such simulation
capabilities in the accessibility domain. In this paper, we evaluate the extent
to which VLMs can simulate the vision perception of low vision individuals when
interpreting images. We first compile a benchmark dataset through a survey
study with 40 low vision participants, collecting their brief and detailed
vision information and both open-ended and multiple-choice image perception and
recognition responses to up to 25 images. Using these responses, we construct
prompts for VLMs (GPT-4o) to create simulated agents of each participant,
varying the included information on vision information and example image
responses. We evaluate the agreement between VLM-generated responses and
participants' original answers. Our results indicate that VLMs tend to infer
beyond the specified vision ability when given minimal prompts, resulting in
low agreement (0.59). The agreement between the agent' and participants'
responses remains low when only either the vision information (0.59) or example
image responses (0.59) are provided, whereas a combination of both
significantly increase the agreement (0.70, p < 0.0001). Notably, a single
example combining both open-ended and multiple-choice responses, offers
significant performance improvements over either alone (p < 0.0001), while
additional examples provided minimal benefits (p > 0.05).

</details>


### [22] [Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?](https://arxiv.org/abs/2508.11011)
*Xuezheng Chen,Zhengbo Zou*

Main category: cs.CV

TL;DR: 论文提出ConstructionSite 10k数据集，包含10,000张建筑工地图像，用于评估和微调视觉语言模型（VLMs）在建筑安全检查中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开放数据集来全面评估和优化VLMs在建筑安全检查中的应用，现有数据集规模小且监督性强，限制了模型的泛化能力。

Method: 构建包含图像描述、安全违规视觉问答（VQA）和建筑元素视觉定位三个任务的标注数据集，并评估现有VLMs的零样本和少样本表现。

Result: 实验显示现有VLMs在零样本和少样本设置下具有显著泛化能力，但仍需额外训练以适应实际工地场景。

Conclusion: ConstructionSite 10k为研究者提供了训练和评估VLMs的基准，推动了建筑安全检查技术的发展。

Abstract: Construction safety inspections typically involve a human inspector
identifying safety concerns on-site. With the rise of powerful Vision Language
Models (VLMs), researchers are exploring their use for tasks such as detecting
safety rule violations from on-site images. However, there is a lack of open
datasets to comprehensively evaluate and further fine-tune VLMs in construction
safety inspection. Current applications of VLMs use small, supervised datasets,
limiting their applicability in tasks they are not directly trained for. In
this paper, we propose the ConstructionSite 10k, featuring 10,000 construction
site images with annotations for three inter-connected tasks, including image
captioning, safety rule violation visual question answering (VQA), and
construction element visual grounding. Our subsequent evaluation of current
state-of-the-art large pre-trained VLMs shows notable generalization abilities
in zero-shot and few-shot settings, while additional training is needed to make
them applicable to actual construction sites. This dataset allows researchers
to train and evaluate their own VLMs with new architectures and techniques,
providing a valuable benchmark for construction safety inspection.

</details>


### [23] [Can Multi-modal (reasoning) LLMs detect document manipulation?](https://arxiv.org/abs/2508.11021)
*Zisheng Liang,Kidus Zewde,Rudra Pratap Singh,Disha Patil,Zexi Chen,Jiayu Xue,Yao Yao,Yifei Chen,Qinzhe Liu,Simiao Ren*

Main category: cs.CV

TL;DR: 研究评估了多模态大语言模型在检测伪造文档中的表现，发现部分模型在零样本泛化能力上优于传统方法，但模型大小与检测准确性关联有限。


<details>
  <summary>Details</summary>
Motivation: 伪造文档对依赖安全文档的行业构成威胁，需要高效检测机制。

Method: 通过提示优化和模型推理分析，评估多模态大语言模型在检测伪造文档中的表现。

Result: 部分多模态大语言模型在零样本泛化能力上优于传统方法，但模型大小与准确性关联不大。

Conclusion: 多模态大语言模型在文档伪造检测中具有潜力，未来需关注任务特定优化和可扩展策略。

Abstract: Document fraud poses a significant threat to industries reliant on secure and
verifiable documentation, necessitating robust detection mechanisms. This study
investigates the efficacy of state-of-the-art multi-modal large language models
(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,
Grok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and
3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against
each other and prior work on document fraud detection techniques using a
standard dataset with real transactional documents. Through prompt optimization
and detailed analysis of the models' reasoning processes, we evaluate their
ability to identify subtle indicators of fraud, such as tampered text,
misaligned formatting, and inconsistent transactional sums. Our results reveal
that top-performing multi-modal LLMs demonstrate superior zero-shot
generalization, outperforming conventional methods on out-of-distribution
datasets, while several vision LLMs exhibit inconsistent or subpar performance.
Notably, model size and advanced reasoning capabilities show limited
correlation with detection accuracy, suggesting task-specific fine-tuning is
critical. This study underscores the potential of multi-modal LLMs in enhancing
document fraud detection systems and provides a foundation for future research
into interpretable and scalable fraud mitigation strategies.

</details>


### [24] [MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation](https://arxiv.org/abs/2508.11032)
*Yanwu Yang,Guinan Su,Jiesi Hu,Francesco Sammarco,Jonas Geiping,Thomas Wolfers*

Main category: cs.CV

TL;DR: MedSAMix是一种无需训练的方法，通过整合通用模型（如SAM）和专用模型（如MedSAM）的优势，提升医学图像分割的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中数据异质性、标注稀缺和分布偏移等问题，提升模型在广泛任务中的泛化性能。

Method: 提出零阶优化方法自动发现最优层合并方案，并开发两种优化机制以适应不同临床需求。

Result: 在25个医学分割任务中，MedSAMix显著提升了性能，专用任务和多任务评估分别提高了6.67%和4.37%。

Conclusion: MedSAMix通过模型合并有效减少偏差，提升了医学图像分割的准确性和泛化能力。

Abstract: Universal medical image segmentation models have emerged as a promising
paradigm due to their strong generalizability across diverse tasks, showing
great potential for a wide range of clinical applications. This potential has
been partly driven by the success of general-purpose vision models such as the
Segment Anything Model (SAM), which has inspired the development of various
fine-tuned variants for medical segmentation tasks. However, fine-tuned
variants like MedSAM are trained on comparatively limited medical imaging data
that often suffers from heterogeneity, scarce annotations, and distributional
shifts. These challenges limit their ability to generalize across a wide range
of medical segmentation tasks. In this regard, we propose MedSAMix, a
training-free model merging method that integrates the strengths of both
generalist models (e.g., SAM) and specialist models (e.g., MedSAM) for medical
image segmentation. In contrast to traditional model merging approaches that
rely on manual configuration and often result in suboptimal outcomes, we
propose a zero-order optimization method to automatically discover optimal
layer-wise merging solutions. Furthermore, for clinical applications, we
develop two regimes to meet the demand of domain-specificity and
generalizability in different scenarios by single-task optimization and
multi-objective optimization respectively. Extensive evaluations on 25 medical
segmentation tasks demonstrate that MedSAMix effectively mitigates model bias
and consistently improves performance in both domain-specific accuracy and
generalization, achieving improvements of 6.67% on specialized tasks and 4.37%
on multi-task evaluations.

</details>


### [25] [Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset](https://arxiv.org/abs/2508.11058)
*Wentao Mo,Qingchao Chen,Yuxin Peng,Siyuan Huang,Yang Liu*

Main category: cs.CV

TL;DR: 论文提出MV-ScanQA数据集和TripAlign预训练语料库，以解决现有3D视觉语言数据集的局限性，并开发了LEGO方法，在多个任务上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉语言数据集缺乏多视角推理和丰富上下文对齐，限制了模型对远距离多对象场景的深度理解。

Method: 引入MV-ScanQA数据集测试多视角推理，提出TripAlign预训练语料库进行2D-3D-语言对齐，并开发LEGO方法迁移2D预训练知识到3D领域。

Result: LEGO在MV-ScanQA和现有3D密集描述与问答任务上均达到最优性能。

Conclusion: MV-ScanQA和TripAlign为3D视觉语言学习提供了更丰富的多视角和多对象对齐支持，LEGO方法展示了其有效性。

Abstract: The advancement of 3D vision-language (3D VL) learning is hindered by several
limitations in existing 3D VL datasets: they rarely necessitate reasoning
beyond a close range of objects in single viewpoint, and annotations often link
instructions to single objects, missing richer contextual alignments between
multiple objects. This significantly curtails the development of models capable
of deep, multi-view 3D scene understanding over distant objects. To address
these challenges, we introduce MV-ScanQA, a novel 3D question answering dataset
where 68% of questions explicitly require integrating information from multiple
views (compared to less than 7% in existing datasets), thereby rigorously
testing multi-view compositional reasoning. To facilitate the training of
models for such demanding scenarios, we present TripAlign dataset, a
large-scale and low-cost 2D-3D-language pre-training corpus containing 1M <2D
view, set of 3D objects, text> triplets that explicitly aligns groups of
contextually related objects with text, providing richer, view-grounded
multi-object multimodal alignment signals than previous single-object
annotations. We further develop LEGO, a baseline method for the multi-view
reasoning challenge in MV-ScanQA, transferring knowledge from pre-trained 2D
LVLMs to 3D domain with TripAlign. Empirically, LEGO pre-trained on TripAlign
achieves state-of-the-art performance not only on the proposed MV-ScanQA, but
also on existing benchmarks for 3D dense captioning and question answering.
Datasets and code are available at
https://matthewdm0816.github.io/tripalign-mvscanqa.

</details>


### [26] [Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts](https://arxiv.org/abs/2508.11063)
*Lucas W. Remedios,Chloe Choe,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

TL;DR: 研究通过AI分析3D临床影像，揭示不同BMI人群中腹部结构与2型糖尿病的关联。


<details>
  <summary>Details</summary>
Motivation: 尽管BMI是2型糖尿病的已知风险因素，但瘦人和肥胖者中糖尿病的分布差异表明，详细的身体组成可能揭示腹部表型与糖尿病的关系。

Method: 利用AI从3D临床影像中提取腹部结构的详细测量数据，通过随机森林分类和SHAP分析，识别与糖尿病风险或保护相关的身体组成特征。

Result: 随机森林模型的AUC为0.72-0.74，发现脂肪性骨骼肌、年龄、内脏和皮下脂肪增加、胰腺较小或脂肪堆积是跨BMI组的共同糖尿病特征。

Conclusion: 腹部结构对2型糖尿病的影响在不同体重类别中可能一致。

Abstract: Purpose: Although elevated BMI is a well-known risk factor for type 2
diabetes, the disease's presence in some lean adults and absence in others with
obesity suggests that detailed body composition may uncover abdominal
phenotypes of type 2 diabetes. With AI, we can now extract detailed
measurements of size, shape, and fat content from abdominal structures in 3D
clinical imaging at scale. This creates an opportunity to empirically define
body composition signatures linked to type 2 diabetes risk and protection using
large-scale clinical data. Approach: To uncover BMI-specific diabetic abdominal
patterns from clinical CT, we applied our design four times: once on the full
cohort (n = 1,728) and once on lean (n = 497), overweight (n = 611), and obese
(n = 620) subgroups separately. Briefly, our experimental design transforms
abdominal scans into collections of explainable measurements through
segmentation, classifies type 2 diabetes through a cross-validated random
forest, measures how features contribute to model-estimated risk or protection
through SHAP analysis, groups scans by shared model decision patterns
(clustering from SHAP) and links back to anatomical differences
(classification). Results: The random-forests achieved mean AUCs of 0.72-0.74.
There were shared type 2 diabetes signatures in each group; fatty skeletal
muscle, older age, greater visceral and subcutaneous fat, and a smaller or
fat-laden pancreas. Univariate logistic regression confirmed the direction of
14-18 of the top 20 predictors within each subgroup (p < 0.05). Conclusions:
Our findings suggest that abdominal drivers of type 2 diabetes may be
consistent across weight classes.

</details>


### [27] [HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing](https://arxiv.org/abs/2508.11106)
*Xinjie Gao,Bi'an Du,Wei Hu*

Main category: cs.CV

TL;DR: HierOctFusion是一种基于八叉树的多尺度扩散模型，通过分层特征交互和跨注意力机制生成精细的3D结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D对象视为整体，忽略了语义部分层次结构，且高分辨率建模计算成本高。

Method: 提出HierOctFusion模型，结合分层特征交互和跨注意力机制，利用带部分标注的3D数据集进行训练。

Result: 实验表明，HierOctFusion在形状质量和效率上优于现有方法。

Conclusion: 分层生成和部分感知机制显著提升了3D内容生成的效果。

Abstract: 3D content generation remains a fundamental yet challenging task due to the
inherent structural complexity of 3D data. While recent octree-based diffusion
models offer a promising balance between efficiency and quality through
hierarchical generation, they often overlook two key insights: 1) existing
methods typically model 3D objects as holistic entities, ignoring their
semantic part hierarchies and limiting generalization; and 2) holistic
high-resolution modeling is computationally expensive, whereas real-world
objects are inherently sparse and hierarchical, making them well-suited for
layered generation. Motivated by these observations, we propose HierOctFusion,
a part-aware multi-scale octree diffusion model that enhances hierarchical
feature interaction for generating fine-grained and sparse object structures.
Furthermore, we introduce a cross-attention conditioning mechanism that injects
part-level information into the generation process, enabling semantic features
to propagate effectively across hierarchical levels from parts to the whole.
Additionally, we construct a 3D dataset with part category annotations using a
pre-trained segmentation model to facilitate training and evaluation.
Experiments demonstrate that HierOctFusion achieves superior shape quality and
efficiency compared to prior methods.

</details>


### [28] [UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring](https://arxiv.org/abs/2508.11115)
*Haotang Li,Zhenyu Qi,Sen He,Kebin Peng,Sheng Tan,Yili Ren,Tomas Cerny,Jiyue Zhao,Zi Wang*

Main category: cs.CV

TL;DR: UWB-PostureGuard是一种基于超宽带（UWB）的隐私保护坐姿监测系统，通过非接触式监测改善长时间电脑使用的健康问题。


<details>
  <summary>Details</summary>
Motivation: 长时间电脑使用导致不良坐姿成为公共健康问题，传统监测方法存在隐私和舒适性问题。

Method: 利用商用UWB设备，通过特征工程提取坐姿特征，开发PoseGBDT模型捕捉时间依赖性。

Result: 在10名参与者和19种姿势的测试中，系统达到99.11%的准确率，且对环境变量具有鲁棒性。

Conclusion: UWB-PostureGuard提供了一种低成本、可扩展且隐私保护的移动健康解决方案，改善生活质量。

Abstract: Improper sitting posture during prolonged computer use has become a
significant public health concern. Traditional posture monitoring solutions
face substantial barriers, including privacy concerns with camera-based systems
and user discomfort with wearable sensors. This paper presents
UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that
advances mobile technologies for preventive health management through
continuous, contactless monitoring of ergonomic sitting posture. Our system
leverages commercial UWB devices, utilizing comprehensive feature engineering
to extract multiple ergonomic sitting posture features. We develop PoseGBDT to
effectively capture temporal dependencies in posture patterns, addressing
limitations of traditional frame-wise classification approaches. Extensive
real-world evaluation across 10 participants and 19 distinct postures
demonstrates exceptional performance, achieving 99.11% accuracy while
maintaining robustness against environmental variables such as clothing
thickness, additional devices, and furniture configurations. Our system
provides a scalable, privacy-preserving mobile health solution on existing
platforms for proactive ergonomic management, improving quality of life at low
costs.

</details>


### [29] [Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation](https://arxiv.org/abs/2508.11134)
*Bing Liu,Le Wang,Hao Liu,Mingming Liu*

Main category: cs.CV

TL;DR: 提出了一种基于残差的双向扩散模型（RBDM），实现有雾和无雾图像之间的双向转换，仅需15步采样即可完成。


<details>
  <summary>Details</summary>
Motivation: 现有深度去雾方法仅关注去雾，缺乏有雾和无雾图像之间的双向转换能力。

Method: 设计双马尔可夫链处理残差，通过扰动图像和预测噪声学习条件分布，并引入统一评分函数降低计算成本。

Result: 在合成和真实数据集上表现优于或至少与现有最佳方法相当。

Conclusion: RBDM成功实现了高效、尺寸无关的双向转换，性能优越。

Abstract: Current deep dehazing methods only focus on removing haze from hazy images,
lacking the capability to translate between hazy and haze-free images. To
address this issue, we propose a residual-based efficient bidirectional
diffusion model (RBDM) that can model the conditional distributions for both
dehazing and haze generation. Firstly, we devise dual Markov chains that can
effectively shift the residuals and facilitate bidirectional smooth transitions
between them. Secondly, the RBDM perturbs the hazy and haze-free images at
individual timesteps and predicts the noise in the perturbed data to
simultaneously learn the conditional distributions. Finally, to enhance
performance on relatively small datasets and reduce computational costs, our
method introduces a unified score function learned on image patches instead of
entire images. Our RBDM successfully implements size-agnostic bidirectional
transitions between haze-free and hazy images with only 15 sampling steps.
Extensive experiments demonstrate that the proposed method achieves superior or
at least comparable performance to state-of-the-art methods on both synthetic
and real-world datasets.

</details>


### [30] [A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations](https://arxiv.org/abs/2508.11141)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.CV

TL;DR: 本文提出了一种基于对比学习的跨模态谣言检测方法（MICC），通过多尺度图像与文本的关联分析，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有谣言检测方法常忽略图像内容及多尺度上下文关系，导致关键信息丢失。

Method: 设计了SCLIP编码器生成统一语义嵌入，引入跨模态多尺度对齐模块，并通过尺度感知融合网络整合特征。

Result: 在两个真实数据集上验证，性能显著优于现有方法。

Conclusion: MICC方法有效且具有实际应用潜力。

Abstract: Existing rumor detection methods often neglect the content within images as
well as the inherent relationships between contexts and images across different
visual scales, thereby resulting in the loss of critical information pertinent
to rumor identification. To address these issues, this paper presents a novel
cross-modal rumor detection scheme based on contrastive learning, namely the
Multi-scale Image and Context Correlation exploration algorithm (MICC).
Specifically, we design an SCLIP encoder to generate unified semantic
embeddings for text and multi-scale image patches through contrastive
pretraining, enabling their relevance to be measured via dot-product
similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is
introduced to identify image regions most relevant to the textual semantics,
guided by mutual information maximization and the information bottleneck
principle, through a Top-K selection strategy based on a cross-modal relevance
matrix constructed between the text and multi-scale image patches. Moreover, a
scale-aware fusion network is designed to integrate the highly correlated
multi-scale image features with global text features by assigning adaptive
weights to image regions based on their semantic importance and cross-modal
relevance. The proposed methodology has been extensively evaluated on two
real-world datasets. The experimental results demonstrate that it achieves a
substantial performance improvement over existing state-of-the-art approaches
in rumor detection, highlighting its effectiveness and potential for practical
applications.

</details>


### [31] [LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction](https://arxiv.org/abs/2508.11153)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

TL;DR: LEARN是一个布局感知的扩散框架，用于生成STEM教育中教学对齐的插图，通过布局条件生成和视觉语义训练，支持中高层次的推理。


<details>
  <summary>Details</summary>
Motivation: 解决STEM教育中抽象科学概念的可视化问题，减少认知负荷，提升学习效果。

Method: 利用BookCover数据集，结合布局条件生成、对比视觉语义训练和提示调制。

Result: 生成连贯的视觉序列，支持Bloom分类法的推理，减少认知负荷。

Conclusion: LEARN为教育领域的生成AI提供了新方向，未来可扩展为多模态系统。

Abstract: LEARN is a layout-aware diffusion framework designed to generate
pedagogically aligned illustrations for STEM education. It leverages a curated
BookCover dataset that provides narrative layouts and structured visual cues,
enabling the model to depict abstract and sequential scientific concepts with
strong semantic alignment. Through layout-conditioned generation, contrastive
visual-semantic training, and prompt modulation, LEARN produces coherent visual
sequences that support mid-to-high-level reasoning in line with Bloom's
taxonomy while reducing extraneous cognitive load as emphasized by Cognitive
Load Theory. By fostering spatially organized and story-driven narratives, the
framework counters fragmented attention often induced by short-form media and
promotes sustained conceptual focus. Beyond static diagrams, LEARN demonstrates
potential for integration with multimodal systems and curriculum-linked
knowledge graphs to create adaptive, exploratory educational content. As the
first generative approach to unify layout-based storytelling, semantic
structure learning, and cognitive scaffolding, LEARN represents a novel
direction for generative AI in education. The code and dataset will be released
to facilitate future research and practical deployment.

</details>


### [32] [Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models](https://arxiv.org/abs/2508.11165)
*Bing Liu,Le Wang,Mingming Liu,Hao Liu,Rui Yao,Yong Zhou,Peng Liu,Tongqiang Xia*

Main category: cs.CV

TL;DR: 提出了一种基于EM-B3DM的半监督图像去雾方法，通过两阶段学习方案解决真实世界雾霾图像的去雾问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理真实世界中的厚雾场景，主要原因是缺乏真实配对数据和鲁棒先验。

Method: 采用EM算法和双向布朗桥扩散模型（B3DM）的两阶段学习方案，结合细节增强的RDC模块。

Result: 在合成和真实数据集上表现优于或至少与最先进方法相当。

Conclusion: EM-B3DM是一种高效的去雾方法，尤其适用于真实世界场景。

Abstract: Existing dehazing methods deal with real-world haze images with difficulty,
especially scenes with thick haze. One of the main reasons is the lack of
real-world paired data and robust priors. To avoid the costly collection of
paired hazy and clear images, we propose an efficient semi-supervised image
dehazing method via Expectation-Maximization and Bidirectional Brownian Bridge
Diffusion Models (EM-B3DM) with a two-stage learning scheme. In the first
stage, we employ the EM algorithm to decouple the joint distribution of paired
hazy and clear images into two conditional distributions, which are then
modeled using a unified Brownian Bridge diffusion model to directly capture the
structural and content-related correlations between hazy and clear images. In
the second stage, we leverage the pre-trained model and large-scale unpaired
hazy and clear images to further improve the performance of image dehazing.
Additionally, we introduce a detail-enhanced Residual Difference Convolution
block (RDC) to capture gradient-level information, significantly enhancing the
model's representation capability. Extensive experiments demonstrate that our
EM-B3DM achieves superior or at least comparable performance to
state-of-the-art methods on both synthetic and real-world datasets.

</details>


### [33] [VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images](https://arxiv.org/abs/2508.11167)
*Jianhong Han,Yupei Wang,Liang Chen*

Main category: cs.CV

TL;DR: VG-DETR是一种基于半监督框架的源自由目标检测方法，通过整合视觉基础模型（VFM）来提升伪标签质量，并在遥感图像中实现跨域适应。


<details>
  <summary>Details</summary>
Motivation: 解决源自由目标检测（SFOD）中因伪标签噪声导致的训练崩溃问题，尤其是在遥感图像中密集对象和复杂背景的挑战下。

Method: 提出VG-DETR，结合VFM的语义先验进行伪标签挖掘，并通过双级对齐方法增强特征表示。

Result: 实验表明VG-DETR在源自由遥感检测任务中表现优异。

Conclusion: VG-DETR通过VFM的整合和双级对齐，显著提升了伪标签质量和检测性能。

Abstract: Unsupervised domain adaptation methods have been widely explored to bridge
domain gaps. However, in real-world remote-sensing scenarios, privacy and
transmission constraints often preclude access to source domain data, which
limits their practical applicability. Recently, Source-Free Object Detection
(SFOD) has emerged as a promising alternative, aiming at cross-domain
adaptation without relying on source data, primarily through a self-training
paradigm. Despite its potential, SFOD frequently suffers from training collapse
caused by noisy pseudo-labels, especially in remote sensing imagery with dense
objects and complex backgrounds. Considering that limited target domain
annotations are often feasible in practice, we propose a Vision
foundation-Guided DEtection TRansformer (VG-DETR), built upon a semi-supervised
framework for SFOD in remote sensing images. VG-DETR integrates a Vision
Foundation Model (VFM) into the training pipeline in a "free lunch" manner,
leveraging a small amount of labeled target data to mitigate pseudo-label noise
while improving the detector's feature-extraction capability. Specifically, we
introduce a VFM-guided pseudo-label mining strategy that leverages the VFM's
semantic priors to further assess the reliability of the generated
pseudo-labels. By recovering potentially correct predictions from
low-confidence outputs, our strategy improves pseudo-label quality and
quantity. In addition, a dual-level VFM-guided alignment method is proposed,
which aligns detector features with VFM embeddings at both the instance and
image levels. Through contrastive learning among fine-grained prototypes and
similarity matching between feature maps, this dual-level alignment further
enhances the robustness of feature representations against domain gaps.
Extensive experiments demonstrate that VG-DETR achieves superior performance in
source-free remote sensing detection tasks.

</details>


### [34] [Better Supervised Fine-tuning for VQA: Integer-Only Loss](https://arxiv.org/abs/2508.11170)
*Baihong Qian,Haotian Fan,Wenjie Liao,Yunqiu Wang,Tao Li,Junhui Cui*

Main category: cs.CV

TL;DR: 提出了一种名为IOVQA的整数标签微调方法，显著提升了视觉语言模型在视频质量评估任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频质量评估中存在结果不精确和损失计算效率低的问题，限制了模型对关键指标的关注。

Method: 通过限制输出为整数范围[10,50]，并引入目标掩码策略，仅暴露标签的前两位整数计算损失，优化模型学习。

Result: 实验表明，该方法显著提升了模型在VQA任务中的准确性和一致性，在VQualA 2025挑战赛中排名第三。

Conclusion: 整数标签微调在优化视觉语言模型的定量评估任务中具有显著效果。

Abstract: With the rapid advancement of vision language models(VLM), their ability to
assess visual content based on specific criteria and dimensions has become
increasingly critical for applications such as video-theme consistency
assessment and visual quality scoring. However, existing methods often suffer
from imprecise results and inefficient loss calculation, which limit the focus
of the model on key evaluation indicators. To address this, we propose
IOVQA(Integer-only VQA), a novel fine-tuning approach tailored for VLMs to
enhance their performance in video quality assessment tasks. The key innovation
of IOVQA lies in its label construction and its targeted loss calculation
mechanism. Specifically, during dataset curation, we constrain the model's
output to integers within the range of [10,50], ensuring numerical stability,
and convert decimal Overall_MOS to integer before using them as labels. We also
introduce a target-mask strategy: when computing the loss, only the first
two-digit-integer of the label is unmasked, forcing the model to learn the
critical components of the numerical evaluation. After fine-tuning the
Qwen2.5-VL model using the constructed dataset, experimental results
demonstrate that the proposed method significantly improves the model's
accuracy and consistency in the VQA task, ranking 3rd in VQualA 2025
GenAI-Bench AIGC Video Quality Assessment Challenge -- Track I. Our work
highlights the effectiveness of merely leaving integer labels during
fine-tuning, providing an effective idea for optimizing VLMs in quantitative
evaluation scenarios.

</details>


### [35] [Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery](https://arxiv.org/abs/2508.11173)
*Ruobing Jiang,Yang Liu,Haobing Liu,Yanwei Yu,Chunyang Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为IDOD的方法，用于连续类别发现（CCD），解决了现有方法在新类别发现与分类之间的矛盾，同时减少了错误积累和存储占用。


<details>
  <summary>Details</summary>
Motivation: 现有CCD方法难以平衡新类别发现与分类任务，且容易积累错误并占用较多存储空间。

Method: IDOD包含三个模块：独立多样性增强模块、联合新类别发现模块和正交性连续增量模块，分别用于避免特征单一化、减少错误积累和降低存储开销。

Result: 在细粒度数据集上，IDOD表现优于现有方法。

Conclusion: IDOD有效解决了CCD中的关键问题，并在实验中取得了显著优势。

Abstract: Continuous category discovery (CCD) aims to automatically discover novel
categories in continuously arriving unlabeled data. This is a challenging
problem considering that there is no number of categories and labels in the
newly arrived data, while also needing to mitigate catastrophic forgetting.
Most CCD methods cannot handle the contradiction between novel class discovery
and classification well. They are also prone to accumulate errors in the
process of gradually discovering novel classes. Moreover, most of them use
knowledge distillation and data replay to prevent forgetting, occupying more
storage space. To address these limitations, we propose Independence-based
Diversity and Orthogonality-based Discrimination (IDOD). IDOD mainly includes
independent enrichment of diversity module, joint discovery of novelty module,
and continuous increment by orthogonality module. In independent enrichment,
the backbone is trained separately using contrastive loss to avoid it focusing
only on features for classification. Joint discovery transforms multi-stage
novel class discovery into single-stage, reducing error accumulation impact.
Continuous increment by orthogonality module generates mutually orthogonal
prototypes for classification and prevents forgetting with lower space overhead
via representative representation replay. Experimental results show that on
challenging fine-grained datasets, our method outperforms the state-of-the-art
methods.

</details>


### [36] [Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning](https://arxiv.org/abs/2508.11176)
*Yumiao Zhao,Bo Jiang,Yuhe Ding,Xiao Wang,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: 论文提出了一种名为LatHAdapter的新型适配器方法，通过利用下游数据的潜在语义层次结构，在双曲空间中更好地对齐视觉和文本表示，从而提升少样本分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有适配器方法在视觉和文本模态对齐时依赖显式空间邻近性，无法捕捉类别与图像样本间的一对多关联，且难以处理未知类别。

Method: LatHAdapter引入可学习的属性提示作为桥梁，将类别、属性和图像投影到双曲空间，并通过层次正则化学习潜在语义层次结构。

Result: 在四个少样本任务上的实验表明，LatHAdapter优于其他微调方法，尤其在已知类别的适应和未知类别的泛化上表现突出。

Conclusion: LatHAdapter通过建模潜在语义层次结构，有效解决了现有适配器方法的局限性，显著提升了少样本分类任务的性能。

Abstract: Adapter-based approaches have garnered attention for fine-tuning pre-trained
Vision-Language Models (VLMs) on few-shot classification tasks. These methods
strive to develop a lightweight module that better aligns visual and (category)
textual representations, thereby enhancing performance on downstream few-shot
learning tasks. However, existing adapters generally learn/align (category)
textual-visual modalities via explicit spatial proximity in the underlying
embedding space, which i) fails to capture the inherent one-to-many
associations between categories and image samples and ii) struggles to
establish accurate associations between the unknown categories and images. To
address these issues, inspired by recent works on hyperbolic learning, we
develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs
on downstream few-shot classification tasks. The core of LatHAdapter is to
exploit the latent semantic hierarchy of downstream training data and employ it
to provide richer, fine-grained guidance for the adapter learning process.
Specifically, LatHAdapter first introduces some learnable `attribute' prompts
as the bridge to align categories and images. Then, it projects the categories,
attribute prompts, and images within each batch in a hyperbolic space, and
employs hierarchical regularization to learn the latent semantic hierarchy of
them, thereby fully modeling the inherent one-to-many associations among
categories, learnable attributes, and image samples. Extensive experiments on
four challenging few-shot tasks show that the proposed LatHAdapter consistently
outperforms many other fine-tuning approaches, particularly in adapting known
classes and generalizing to unknown classes.

</details>


### [37] [Versatile Video Tokenization with Generative 2D Gaussian Splatting](https://arxiv.org/abs/2508.11183)
*Zhenghao Chen,Zicong Chen,Lei Liu,Yiming Wu,Dong Xu*

Main category: cs.CV

TL;DR: GVT是一种基于生成式2D高斯分布的视频标记化方法，通过空间自适应和时间分离策略提升视频处理的通用性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有视频标记化方法在空间和时间维度上存在冗余和通用性不足的问题，GVT旨在通过生成式高斯分布和静态动态分离策略解决这些问题。

Method: GVT采用Spatio-Temporal Gaussian Embedding（STGE）机制生成2D高斯分布，并通过Gaussian Set Partitioning（GSP）策略分离静态和动态内容。

Result: GVT在视频重建、动作识别和压缩任务中表现优异，优于基线方法MAGVIT-v2。

Conclusion: GVT通过生成式高斯分布和时空分离策略，显著提升了视频标记化的通用性和性能。

Abstract: Video tokenization procedure is critical for a wide range of video processing
tasks. Most existing approaches directly transform video into fixed-grid and
patch-wise tokens, which exhibit limited versatility. Spatially, uniformly
allocating a fixed number of tokens often leads to over-encoding in
low-information regions. Temporally, reducing redundancy remains challenging
without explicitly distinguishing between static and dynamic content. In this
work, we propose the Gaussian Video Transformer (GVT), a versatile video
tokenizer built upon a generative 2D Gaussian Splatting (2DGS) strategy. We
first extract latent rigid features from a video clip and represent them with a
set of 2D Gaussians generated by our proposed Spatio-Temporal Gaussian
Embedding (STGE) mechanism in a feed-forward manner. Such generative 2D
Gaussians not only enhance spatial adaptability by assigning higher (resp.,
lower) rendering weights to regions with higher (resp., lower) information
content during rasterization, but also improve generalization by avoiding
per-video optimization.To enhance the temporal versatility, we introduce a
Gaussian Set Partitioning (GSP) strategy that separates the 2D Gaussians into
static and dynamic sets, which explicitly model static content shared across
different time-steps and dynamic content specific to each time-step, enabling a
compact representation.We primarily evaluate GVT on the video reconstruction,
while also assessing its performance on action recognition and compression
using the UCF101, Kinetics, and DAVIS datasets. Extensive experiments
demonstrate that GVT achieves a state-of-the-art video reconstruction quality,
outperforms the baseline MAGVIT-v2 in action recognition, and delivers
comparable compression performance.

</details>


### [38] [CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector](https://arxiv.org/abs/2508.11185)
*Abhinav Kumar,Yuliang Guo,Zhihao Zhang,Xinyu Huang,Liu Ren,Xiaoming Liu*

Main category: cs.CV

TL;DR: 论文研究了单目3D目标检测器在不同相机高度下的性能问题，提出了一种新方法CHARM3R，显著提升了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测器在相机高度变化时性能下降，特别是深度估计问题突出。

Method: 通过系统分析相机高度变化对深度估计的影响，提出结合回归和基于地面的深度估计的CHARM3R模型。

Result: CHARM3R在CARLA数据集上提升了45%以上的泛化性能，达到SOTA水平。

Conclusion: CHARM3R有效解决了相机高度变化带来的性能问题，为单目3D检测提供了新思路。

Abstract: Monocular 3D object detectors, while effective on data from one ego camera
height, struggle with unseen or out-of-distribution camera heights. Existing
methods often rely on Plucker embeddings, image transformations or data
augmentation. This paper takes a step towards this understudied problem by
first investigating the impact of camera height variations on state-of-the-art
(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset
with multiple camera heights, we observe that depth estimation is a primary
factor influencing performance under height variations. We mathematically prove
and also empirically observe consistent negative and positive trends in mean
depth error of regressed and ground-based depth models, respectively, under
camera height changes. To mitigate this, we propose Camera Height Robust
Monocular 3D Detector (CHARM3R), which averages both depth estimates within the
model. CHARM3R improves generalization to unseen camera heights by more than
$45\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at
https://github.com/abhi1kumar/CHARM3R

</details>


### [39] [Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark](https://arxiv.org/abs/2508.11192)
*Lavisha Aggarwal,Vikas Bahirwani,Lin Li,Andrea Colaco*

Main category: cs.CV

TL;DR: 论文提出了一种自动将单人教学视频转化为任务指导对话的方法，并构建了大规模数据集HowToDIV，用于多步骤任务辅助的对话研究。


<details>
  <summary>Details</summary>
Motivation: 现实世界中复杂任务需要专家知识，但缺乏基于对话和视频的任务辅助数据集。

Method: 利用大语言模型自动将单人教学视频转化为两人对话，并与视频片段对齐。

Result: 构建了包含507个对话、6636个问答对和24小时视频的HowToDIV数据集，并提供了基准性能。

Conclusion: 该方法为任务辅助对话研究提供了高效的数据生成方案，并推动了未来研究。

Abstract: Many everyday tasks ranging from fixing appliances, cooking recipes to car
maintenance require expert knowledge, especially when tasks are complex and
multi-step. Despite growing interest in AI agents, there is a scarcity of
dialogue-video datasets grounded for real world task assistance. In this paper,
we propose a simple yet effective approach that transforms single-person
instructional videos into task-guidance two-person dialogues, aligned with fine
grained steps and video-clips. Our fully automatic approach, powered by large
language models, offers an efficient alternative to the substantial cost and
effort required for human-assisted data collection. Using this technique, we
build HowToDIV, a large-scale dataset containing 507 conversations, 6636
question-answer pairs and 24 hours of videoclips across diverse tasks in
cooking, mechanics, and planting. Each session includes multi-turn conversation
where an expert teaches a novice user how to perform a task step by step, while
observing user's surrounding through a camera and microphone equipped wearable
device. We establish the baseline benchmark performance on HowToDIV dataset
through Gemma-3 model for future research on this new task of dialogues for
procedural-task assistance.

</details>


### [40] [UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning](https://arxiv.org/abs/2508.11196)
*Jiajin Guan,Haibo Mei,Bonan Zhang,Dan Liu,Yuanshuang Fu,Yue Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级视觉语言模型UAV-VL-R1，专为无人机航拍图像设计，通过混合训练方法提升性能，并在新数据集HRVQA-VL上验证效果。


<details>
  <summary>Details</summary>
Motivation: 通用视觉语言模型在无人机航拍图像上性能下降，因其高分辨率、复杂语义和实时性要求。

Method: 采用监督微调（SFT）和多阶段强化学习（RL）的混合方法，结合GRPO算法提升推理能力。

Result: UAV-VL-R1在零样本任务上比基线模型Qwen2-VL-2B-Instruct准确率高48.17%，且内存占用低。

Conclusion: UAV-VL-R1在航拍图像任务中表现出色，适合资源受限的无人机平台实时部署。

Abstract: Recent advances in vision-language models (VLMs) have demonstrated strong
generalization in natural image tasks. However, their performance often
degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features
high resolution, complex spatial semantics, and strict real-time constraints.
These challenges limit the applicability of general-purpose VLMs to structured
aerial reasoning tasks. To address these challenges, we propose UAV-VL-R1, a
lightweight VLM explicitly designed for aerial visual reasoning. It is trained
using a hybrid method that combines supervised fine-tuning (SFT) and
multi-stage reinforcement learning (RL). We leverage the group relative policy
optimization (GRPO) algorithm to promote structured and interpretable reasoning
through rule-guided rewards and intra-group policy alignment. To support model
training and evaluation, we introduce a high-resolution visual question
answering dataset named HRVQA-VL, which consists of 50,019 annotated samples
covering eight UAV-relevant reasoning tasks, including object counting,
transportation recognition, and spatial scene inference. Experimental results
show that UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the
Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which
is 36x larger, on multiple tasks. Ablation studies reveal that while SFT
improves semantic alignment, it may reduce reasoning diversity in mathematical
tasks. GRPO-based RL compensates for this limitation by enhancing logical
flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires
only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with
INT8, supporting real-time deployment on resource-constrained UAV platforms.

</details>


### [41] [A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network](https://arxiv.org/abs/2508.11212)
*Zhangjian Ji,Wenjin Zhang,Shaotong Qiao,Kai Feng,Yuhua Qian*

Main category: cs.CV

TL;DR: 提出了一种新颖的从粗到细的两阶段知识蒸馏框架，用于轻量级人体姿态估计，通过挖掘关节结构信息和渐进式图卷积网络提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态估计方法计算资源消耗大，传统知识蒸馏未充分利用关节上下文信息，需开发更高效的轻量级方法。

Method: 两阶段知识蒸馏：第一阶段通过关节结构损失传递高级语义知识；第二阶段利用渐进式图卷积网络（IGP-GCN）细化姿态。

Result: 在COCO和CrowdPose数据集上表现优异，尤其在复杂场景的CrowdPose上改进显著。

Conclusion: 提出的框架通过结构信息和渐进式训练，实现了轻量且高精度的人体姿态估计。

Abstract: Human pose estimation has been widely applied in the human-centric
understanding and generation, but most existing state-of-the-art human pose
estimation methods require heavy computational resources for accurate
predictions. In order to obtain an accurate, robust yet lightweight human pose
estimator, one feasible way is to transfer pose knowledge from a powerful
teacher model to a less-parameterized student model by knowledge distillation.
However, the traditional knowledge distillation framework does not fully
explore the contextual information among human joints. Thus, in this paper, we
propose a novel coarse-to-fine two-stage knowledge distillation framework for
human pose estimation. In the first-stage distillation, we introduce the human
joints structure loss to mine the structural information among human joints so
as to transfer high-level semantic knowledge from the teacher model to the
student model. In the second-stage distillation, we utilize an Image-Guided
Progressive Graph Convolutional Network (IGP-GCN) to refine the initial human
pose obtained from the first-stage distillation and supervise the training of
the IGP-GCN in the progressive way by the final output pose of teacher model.
The extensive experiments on the benchmark dataset: COCO keypoint and CrowdPose
datasets, show that our proposed method performs favorably against lots of the
existing state-of-the-art human pose estimation methods, especially for the
more complex CrowdPose dataset, the performance improvement of our model is
more significant.

</details>


### [42] [A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving](https://arxiv.org/abs/2508.11218)
*Jialin Li,Shuqi Wu,Ning Wang*

Main category: cs.CV

TL;DR: 提出了一种轻量级不确定性模态建模（UMM）框架，用于解决多模态行人重识别中的不确定性和缺失模态问题，结合CLIP的视觉-语言对齐能力，实现了高效的多模态输入融合。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等资源受限环境中，传统行人重识别方法难以应对不确定或缺失的输入模态（如RGB、红外、草图或文本描述），而预训练模型的计算开销又限制了实际部署。

Method: UMM框架包含多模态令牌映射器、合成模态增强策略和跨模态线索交互学习器，结合CLIP的视觉-语言对齐能力，实现统一特征表示和互补信息提取。

Result: 实验表明，UMM在不确定模态条件下具有强鲁棒性、泛化能力和计算效率。

Conclusion: UMM为自动驾驶场景中的行人重识别提供了一种可扩展且实用的解决方案。

Abstract: Re-Identification (ReID) is a critical technology in intelligent perception
systems, especially within autonomous driving, where onboard cameras must
identify pedestrians across views and time in real-time to support safe
navigation and trajectory prediction. However, the presence of uncertain or
missing input modalities--such as RGB, infrared, sketches, or textual
descriptions--poses significant challenges to conventional ReID approaches.
While large-scale pre-trained models offer strong multimodal semantic modeling
capabilities, their computational overhead limits practical deployment in
resource-constrained environments. To address these challenges, we propose a
lightweight Uncertainty Modal Modeling (UMM) framework, which integrates a
multimodal token mapper, synthetic modality augmentation strategy, and
cross-modal cue interactive learner. Together, these components enable unified
feature representation, mitigate the impact of missing modalities, and extract
complementary information across different data types. Additionally, UMM
leverages CLIP's vision-language alignment ability to fuse multimodal inputs
efficiently without extensive finetuning. Experimental results demonstrate that
UMM achieves strong robustness, generalization, and computational efficiency
under uncertain modality conditions, offering a scalable and practical solution
for pedestrian re-identification in autonomous driving scenarios.

</details>


### [43] [FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation](https://arxiv.org/abs/2508.11255)
*MengChao Wang,Qiang Wang,Fan Jiang,Mu Xu*

Main category: cs.CV

TL;DR: 论文提出了一种多模态奖励模型Talking-Critic和一个大规模多维偏好数据集Talking-NSQ，并开发了TLPO框架，以优化音频驱动肖像动画的多维偏好对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多维偏好（如运动自然度、唇同步准确性和视觉质量）上难以优化，且缺乏大规模高质量标注数据集。

Method: 引入Talking-Critic学习人类对齐的奖励函数，构建Talking-NSQ数据集，并提出TLPO框架，通过分专家模块和跨时间步层融合优化偏好。

Result: Talking-Critic在人类偏好评分上显著优于现有方法，TLPO在唇同步、运动自然度和视觉质量上均有显著提升。

Conclusion: TLPO框架有效解决了多维偏好优化问题，为音频驱动肖像动画提供了更高质量的结果。

Abstract: Recent advances in audio-driven portrait animation have demonstrated
impressive capabilities. However, existing methods struggle to align with
fine-grained human preferences across multiple dimensions, such as motion
naturalness, lip-sync accuracy, and visual quality. This is due to the
difficulty of optimizing among competing preference objectives, which often
conflict with one another, and the scarcity of large-scale, high-quality
datasets with multidimensional preference annotations. To address these, we
first introduce Talking-Critic, a multimodal reward model that learns
human-aligned reward functions to quantify how well generated videos satisfy
multidimensional expectations. Leveraging this model, we curate Talking-NSQ, a
large-scale multidimensional human preference dataset containing 410K
preference pairs. Finally, we propose Timestep-Layer adaptive multi-expert
Preference Optimization (TLPO), a novel framework for aligning diffusion-based
portrait animation models with fine-grained, multidimensional preferences. TLPO
decouples preferences into specialized expert modules, which are then fused
across timesteps and network layers, enabling comprehensive, fine-grained
enhancement across all dimensions without mutual interference. Experiments
demonstrate that Talking-Critic significantly outperforms existing methods in
aligning with human preference ratings. Meanwhile, TLPO achieves substantial
improvements over baseline models in lip-sync accuracy, motion naturalness, and
visual quality, exhibiting superior performance in both qualitative and
quantitative evaluations. Ours project page:
https://fantasy-amap.github.io/fantasy-talking2/

</details>


### [44] [Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception](https://arxiv.org/abs/2508.11256)
*Junjie Wang,Keyu Chen,Yulin Li,Bin Chen,Hengshuang Zhao,Xiaojuan Qi,Zhuotao Tian*

Main category: cs.CV

TL;DR: DeCLIP通过解耦CLIP的自注意力模块，分别提取内容和上下文特征，结合视觉基础模型和扩散模型增强特征，显著提升了开放词汇密集感知任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集视觉感知任务依赖预定义类别，限制了实际应用；CLIP在开放词汇任务中表现有限，因其局部特征表示不足。

Method: 提出DeCLIP框架，解耦CLIP的自注意力模块，分别优化内容和上下文特征，利用视觉基础模型和扩散模型增强特征。

Result: DeCLIP在2D检测、分割、3D实例分割、视频实例分割和6D物体姿态估计等任务中均达到最先进性能。

Conclusion: DeCLIP为开放词汇密集感知任务提供了坚实基础，显著提升了性能。

Abstract: Dense visual perception tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense perception often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. \revise{The context features are enhanced by jointly distilling
semantic correlations from Vision Foundation Models (VFMs) and object integrity
cues from diffusion models, thereby enhancing spatial consistency. In parallel,
the content features are aligned with image crop representations and
constrained by region correlations from VFMs to improve local discriminability.
Extensive experiments demonstrate that DeCLIP establishes a solid foundation
for open-vocabulary dense perception, consistently achieving state-of-the-art
performance across a broad spectrum of tasks, including 2D detection and
segmentation, 3D instance segmentation, video instance segmentation, and 6D
object pose estimation.} Code is available at
https://github.com/xiaomoguhz/DeCLIP

</details>


### [45] [Vision-Language Models display a strong gender bias](https://arxiv.org/abs/2508.11262)
*Aiswarya Konavoor,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CV

TL;DR: 研究探讨了视觉语言模型（VLM）中性别关联问题，通过对比分析图像与文本嵌入的相似性，揭示了模型潜在的性别偏见。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在共享表示空间中对齐图像和文本，但可能隐含社会刻板印象，标准准确性指标难以察觉。本研究旨在验证模型是否存在性别关联偏见。

Method: 使用220张人脸照片（按性别分组）和150条描述职业与活动的语句，计算图像与文本嵌入的余弦相似性差异，并通过自举法和标签交换零模型评估性别关联。

Result: 建立了语句和类别层面的性别关联图谱，提供了不确定性估计和性别偏见评估框架，揭示了模型中的性别偏见。

Conclusion: 研究为视觉语言模型的性别偏见提供了量化分析工具，强调了模型设计中需关注社会偏见问题。

Abstract: Vision-language models (VLM) align images and text in a shared representation
space that is useful for retrieval and zero-shot transfer. Yet, this alignment
can encode and amplify social stereotypes in subtle ways that are not obvious
from standard accuracy metrics. In this study, we test whether the contrastive
vision-language encoder exhibits gender-linked associations when it places
embeddings of face images near embeddings of short phrases that describe
occupations and activities. We assemble a dataset of 220 face photographs split
by perceived binary gender and a set of 150 unique statements distributed
across six categories covering emotional labor, cognitive labor, domestic
labor, technical labor, professional roles, and physical labor. We compute
unit-norm image embeddings for every face and unit-norm text embeddings for
every statement, then define a statement-level association score as the
difference between the mean cosine similarity to the male set and the mean
cosine similarity to the female set, where positive values indicate stronger
association with the male set and negative values indicate stronger association
with the female set. We attach bootstrap confidence intervals by resampling
images within each gender group, aggregate by category with a separate
bootstrap over statements, and run a label-swap null model that estimates the
level of mean absolute association we would expect if no gender structure were
present. The outcome is a statement-wise and category-wise map of gender
associations in a contrastive vision-language space, accompanied by
uncertainty, simple sanity checks, and a robust gender bias evaluation
framework.

</details>


### [46] [Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds](https://arxiv.org/abs/2508.11265)
*Pei He,Lingling Li,Licheng Jiao,Ronghua Shang,Fang Liu,Shuang Wang,Xu Liu,Wenping Ma*

Main category: cs.CV

TL;DR: 提出了一种类别级几何学习框架，通过感知点云特征的细粒度几何属性，提升3D语义分割的领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法通过增强点云数据分布缓解领域偏移，但忽略了类别级分布和对齐，导致模型泛化能力不足。

Method: 提出类别级几何嵌入（CGE）感知几何属性，并结合几何一致学习（GCL）模拟潜在3D分布和对齐几何嵌入。

Result: 实验表明，该方法在领域泛化点云分割任务中具有竞争力的准确率。

Conclusion: 通过类别级几何学习和几何对齐，显著提升了3D分割模型的泛化能力。

Abstract: Domain generalization in 3D segmentation is a critical challenge in deploying
models to unseen environments. Current methods mitigate the domain shift by
augmenting the data distribution of point clouds. However, the model learns
global geometric patterns in point clouds while ignoring the category-level
distribution and alignment. In this paper, a category-level geometry learning
framework is proposed to explore the domain-invariant geometric features for
domain generalized 3D semantic segmentation. Specifically, Category-level
Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric
properties of point cloud features, which constructs the geometric properties
of each class and couples geometric embedding to semantic learning. Secondly,
Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D
distribution and align the category-level geometric embeddings, allowing the
model to focus on the geometric invariant information to improve
generalization. Experimental results verify the effectiveness of the proposed
method, which has very competitive segmentation accuracy compared with the
state-of-the-art domain generalized point cloud methods.

</details>


### [47] [Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering](https://arxiv.org/abs/2508.11272)
*Jun Li,Kai Li,Shaoguo Liu,Tingting Gao*

Main category: cs.CV

TL;DR: 提出了一种名为PMTFR的框架，通过金字塔匹配模型和无训练细化方法提升组合图像检索（CIR）性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在组合图像检索中需要额外训练排序模型或依赖复杂提示设计的问题。

Method: 使用金字塔修补器模块增强视觉信息理解，并结合表示工程技术从CoT数据中提取表示注入LVLMs。

Result: 在CIR基准测试中表现优于现有方法。

Conclusion: PMTFR框架在监督CIR任务中取得了显著效果，代码将公开。

Abstract: Composed Image Retrieval (CIR) presents a significant challenge as it
requires jointly understanding a reference image and a modified textual
instruction to find relevant target images. Some existing methods attempt to
use a two-stage approach to further refine retrieval results. However, this
often requires additional training of a ranking model. Despite the success of
Chain-of-Thought (CoT) techniques in reducing training costs for language
models, their application in CIR tasks remains limited -- compressing visual
information into text or relying on elaborate prompt designs. Besides, existing
works only utilize it for zero-shot CIR, as it is challenging to achieve
satisfactory results in supervised CIR with a well-trained model. In this work,
we proposed a framework that includes the Pyramid Matching Model with
Training-Free Refinement (PMTFR) to address these challenges. Through a simple
but effective module called Pyramid Patcher, we enhanced the Pyramid Matching
Model's understanding of visual information at different granularities.
Inspired by representation engineering, we extracted representations from COT
data and injected them into the LVLMs. This approach allowed us to obtain
refined retrieval scores in the Training-Free Refinement paradigm without
relying on explicit textual reasoning, further enhancing performance. Extensive
experiments on CIR benchmarks demonstrate that PMTFR surpasses state-of-the-art
methods in supervised CIR tasks. The code will be made public.

</details>


### [48] [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)
*Matthew Lyle Olson,Musashi Hinck,Neale Ratzlaff,Changbai Li,Phillip Howard,Vasudev Lal,Shao-Yen Tseng*

Main category: cs.CV

TL;DR: 稀疏自编码器（SAEs）在视觉模型中的应用评估显示，其能提取语义特征、提升泛化能力并实现可控生成。


<details>
  <summary>Details</summary>
Motivation: 尽管SAEs在语言模型中广泛应用，但在视觉领域的研究较少，本文旨在填补这一空白。

Method: 通过多种视觉任务（如视觉嵌入模型、多模态LLMs和扩散模型）评估SAEs的表征能力。

Result: SAEs提取的特征具有语义意义，能提升分布外泛化能力，并实现可控生成。

Conclusion: SAEs在视觉模型中具有提升可解释性、泛化能力和可控性的潜力。

Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.

</details>


### [49] [Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction](https://arxiv.org/abs/2508.11282)
*Muzammil Khan,Enzo Kerkhof,Matteo Fusaglia,Koert Kuhlmann,Theo Ruers,Françoise J. Siepel*

Main category: cs.CV

TL;DR: 提出了一种统一的单目内窥镜组织重建框架，结合尺度感知深度预测和时间约束的感知细化，解决了深度模糊和组织变形等问题。


<details>
  <summary>Details</summary>
Motivation: 单目内窥镜姿态估计和组织重建面临深度模糊、组织变形、运动不一致等挑战，需提升导航和空间感知能力。

Method: 框架包含MAPIS-Depth模块（结合Depth Pro和Depth Anything进行深度预测）和WEMA-RTDL模块（优化旋转和平移），并通过RAFT和LPIPS进行时间细化。

Result: 在HEVD和SCARED数据集上的评估表明，该框架优于现有方法。

Conclusion: 该框架通过深度预测和时间细化，显著提升了单目内窥镜的组织重建效果。

Abstract: Accurate endoscope pose estimation and 3D tissue surface reconstruction
significantly enhances monocular minimally invasive surgical procedures by
enabling accurate navigation and improved spatial awareness. However, monocular
endoscope pose estimation and tissue reconstruction face persistent challenges,
including depth ambiguity, physiological tissue deformation, inconsistent
endoscope motion, limited texture fidelity, and a restricted field of view. To
overcome these limitations, a unified framework for monocular endoscopic tissue
reconstruction that integrates scale-aware depth prediction with
temporally-constrained perceptual refinement is presented. This framework
incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust
initialisation and Depth Anything for efficient per-frame depth prediction, in
conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth
estimates. These estimates are temporally refined by computing pixel
correspondences using RAFT and adaptively blending flow-warped frames based on
LPIPS perceptual similarity, thereby reducing artefacts arising from
physiological tissue deformation and motion. To ensure accurate registration of
the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module
is integrated, optimising both rotation and translation. Finally, truncated
signed distance function-based volumetric fusion and marching cubes are applied
to extract a comprehensive 3D surface mesh. Evaluations on HEVD and SCARED,
with ablation and comparative analyses, demonstrate the framework's robustness
and superiority over state-of-the-art methods.

</details>


### [50] [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](https://arxiv.org/abs/2508.11284)
*Yilin Mi,Qixin Yan,Zheng-Peng Duan,Chunle Guo,Hubery Yin,Hao Liu,Chen Li,Chongyi Li*

Main category: cs.CV

TL;DR: TimeMachine是一种基于扩散模型的框架，用于精确编辑面部年龄同时保持身份特征不变，通过注入高精度年龄信息和轻量级模块提升编辑准确性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在面部年龄编辑中难以同时实现细粒度编辑和身份特征保留，因此需要一种新方法来解决这一问题。

Method: 提出TimeMachine框架，利用多交叉注意力模块分离年龄和身份特征，并引入Age Classifier Guidance模块在潜在空间预测年龄。构建HFFA数据集支持训练。

Result: 实验表明TimeMachine在细粒度年龄编辑和身份一致性保持方面达到最先进性能。

Conclusion: TimeMachine通过新颖的设计解决了年龄编辑中的关键问题，同时提供了高质量的数据集支持。

Abstract: With the advancement of generative models, facial image editing has made
significant progress. However, achieving fine-grained age editing while
preserving personal identity remains a challenging task.In this paper, we
propose TimeMachine, a novel diffusion-based framework that achieves accurate
age editing while keeping identity features unchanged. To enable fine-grained
age editing, we inject high-precision age information into the multi-cross
attention module, which explicitly separates age-related and identity-related
features. This design facilitates more accurate disentanglement of age
attributes, thereby allowing precise and controllable manipulation of facial
aging.Furthermore, we propose an Age Classifier Guidance (ACG) module that
predicts age directly in the latent space, instead of performing denoising
image reconstruction during training. By employing a lightweight module to
incorporate age constraints, this design enhances age editing accuracy by
modest increasing training cost. Additionally, to address the lack of
large-scale, high-quality facial age datasets, we construct a HFFA dataset
(High-quality Fine-grained Facial-Age dataset) which contains one million
high-resolution images labeled with identity and facial attributes.
Experimental results demonstrate that TimeMachine achieves state-of-the-art
performance in fine-grained age editing while preserving identity consistency.

</details>


### [51] [Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study](https://arxiv.org/abs/2508.11301)
*Jiarong Li,Imad Ali Shah,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 论文研究了高光谱成像（HSI）在行人分割中的潜力，通过对比RGB和两种降维方法（PCA和CSNR-JMIM），发现CSNR-JMIM在性能上优于RGB。


<details>
  <summary>Details</summary>
Motivation: RGB成像中行人与背景的视觉不可区分性导致行人分割存在安全隐患，高光谱成像可能提供更好的解决方案。

Method: 使用H-City数据集，比较RGB与两种HSI降维方法（PCA和CSNR-JMIM），并评估三种语义分割模型（U-Net、DeepLabV3+和SegFormer）。

Result: CSNR-JMIM在行人分割中平均IoU提升1.44%，F1-score提升2.18%；骑行者分割也有类似提升。

Conclusion: 研究表明，通过优化HSI波段选择，可以显著提升行人分割性能，对安全关键型汽车应用具有潜力。

Abstract: Pedestrian segmentation in automotive perception systems faces critical
safety challenges due to metamerism in RGB imaging, where pedestrians and
backgrounds appear visually indistinguishable.. This study investigates the
potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation
in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We
compared standard RGB against two dimensionality-reduction approaches by
converting 128-channel HSI data into three-channel representations: Principal
Component Analysis (PCA) and optimal band selection using Contrast
Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM).
Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and
SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements
of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian
segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25%
F1-score improvements. These improved performance results from enhanced
spectral discrimination of optimally selected HSI bands effectively reducing
false positives. This study demonstrates robust pedestrian segmentation through
optimal HSI band selection, showing significant potential for safety-critical
automotive applications.

</details>


### [52] [Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval](https://arxiv.org/abs/2508.11313)
*Weijia Liu,Jiuxin Cao,Bo Miao,Zhiheng Fu,Xuelin Zhu,Jiawei Ge,Bo Liu,Mehwish Nasim,Ajmal Mian*

Main category: cs.CV

TL;DR: 提出了一种去噪再检索的范式（DRNet），通过过滤无关视频片段提升多模态对齐和检索准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法编码所有视频片段（包括无关内容）会干扰多模态对齐和优化效果。

Method: 采用Text-Conditioned Denoising（TCD）模块动态识别噪声片段并生成噪声掩码，结合Text-Reconstruction Feedback（TRF）模块对齐文本嵌入。

Result: 在Charades-STA和QVHighlights数据集上表现优于现有方法。

Conclusion: 去噪再检索范式可提升视频时刻检索性能，且能无缝集成到其他先进模型中。

Abstract: Current text-driven Video Moment Retrieval (VMR) methods encode all video
clips, including irrelevant ones, disrupting multimodal alignment and hindering
optimization. To this end, we propose a denoise-then-retrieve paradigm that
explicitly filters text-irrelevant clips from videos and then retrieves the
target moment using purified multimodal representations. Following this
paradigm, we introduce the Denoise-then-Retrieve Network (DRNet), comprising
Text-Conditioned Denoising (TCD) and Text-Reconstruction Feedback (TRF)
modules. TCD integrates cross-attention and structured state space blocks to
dynamically identify noisy clips and produce a noise mask to purify multimodal
video representations. TRF further distills a single query embedding from
purified video representations and aligns it with the text embedding, serving
as auxiliary supervision for denoising during training. Finally, we perform
conditional retrieval using text embeddings on purified video representations
for accurate VMR. Experiments on Charades-STA and QVHighlights demonstrate that
our approach surpasses state-of-the-art methods on all metrics. Furthermore,
our denoise-then-retrieve paradigm is adaptable and can be seamlessly
integrated into advanced VMR models to boost performance.

</details>


### [53] [Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/abs/2508.11317)
*Yuchen Zhou,Jiayu Tang,Shuo Yang,Xiaoyan Xiao,Yuqin Dai,Wenhao Yang,Chao Gou,Xiaobo Xia,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 论文提出了LogicBench基准测试和LogicCLIP框架，以提升视觉语言模型（VLMs）的逻辑理解能力，填补现有模型在逻辑推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）在逻辑理解方面存在显著不足，导致实际应用中的可靠性受限。

Method: 通过LogicBench（包含50,000多个视觉语言对）评估现有VLMs，并提出LogicCLIP框架，结合逻辑感知数据生成和多目标对比学习策略。

Result: LogicCLIP在所有LogicBench领域显著提升逻辑理解能力，同时保持通用视觉语言任务的竞争力。

Conclusion: LogicBench和LogicCLIP为提升VLMs的逻辑能力提供了重要资源，且逻辑增强不影响通用性能。

Abstract: Vision-Language Models (VLMs), exemplified by CLIP, have emerged as
foundational for multimodal intelligence. However, their capacity for logical
understanding remains significantly underexplored, resulting in critical
''logical blindspots'' that limit their reliability in practical applications.
To systematically diagnose this, we introduce LogicBench, a comprehensive
benchmark with over 50,000 vision-language pairs across 9 logical categories
and 4 diverse scenarios: images, videos, anomaly detection, and medical
diagnostics. Our evaluation reveals that existing VLMs, even the
state-of-the-art ones, fall at over 40 accuracy points below human performance,
particularly in challenging tasks like Causality and Conditionality,
highlighting their reliance on surface semantics over critical logical
structures. To bridge this gap, we propose LogicCLIP, a novel training
framework designed to boost VLMs' logical sensitivity through advancements in
both data generation and optimization objectives. LogicCLIP utilizes
logic-aware data generation and a contrastive learning strategy that combines
coarse-grained alignment, a fine-grained multiple-choice objective, and a novel
logical structure-aware objective. Extensive experiments demonstrate
LogicCLIP's substantial improvements in logical comprehension across all
LogicBench domains, significantly outperforming baselines. Moreover, LogicCLIP
retains, and often surpasses, competitive performance on general
vision-language benchmarks, demonstrating that the enhanced logical
understanding does not come at the expense of general alignment. We believe
that LogicBench and LogicCLIP will be important resources for advancing VLM
logical capabilities.

</details>


### [54] [Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking](https://arxiv.org/abs/2508.11323)
*Haonan Zhang,Xinyao Wang,Boxi Wu,Tu Zheng,Wang Yunhua,Zheng Yang*

Main category: cs.CV

TL;DR: 论文提出了一种基于空间线索一致性的3D多目标跟踪方法DSC-Track，通过动态场景线索一致性提升跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于单目标运动建模的方法在拥挤环境或检测不准确时表现不佳，忽略了物体间的几何关系。现有几何感知方法易受无关物体干扰，导致特征模糊和错误关联。

Method: 设计了基于点对特征（PPF）的时空编码器，结合线索一致性变换模块和对齐特征表示，动态更新机制保留关键时空信息。

Result: 在nuScenes和Waymo数据集上验证了方法的有效性，nuScenes验证集和测试集的AMOTA分别达到73.2%和70.3%。

Conclusion: DSC-Track通过关注稳定的空间模式，显著提升了复杂场景下的3D多目标跟踪性能。

Abstract: 3D multi-object tracking is a critical and challenging task in the field of
autonomous driving. A common paradigm relies on modeling individual object
motion, e.g., Kalman filters, to predict trajectories. While effective in
simple scenarios, this approach often struggles in crowded environments or with
inaccurate detections, as it overlooks the rich geometric relationships between
objects. This highlights the need to leverage spatial cues. However, existing
geometry-aware methods can be susceptible to interference from irrelevant
objects, leading to ambiguous features and incorrect associations. To address
this, we propose focusing on cue-consistency: identifying and matching stable
spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency
Tracker (DSC-Track) to implement this principle. Firstly, we design a unified
spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative
trajectory embeddings while suppressing interference. Secondly, our
cue-consistency transformer module explicitly aligns consistent feature
representations between historical tracks and current detections. Finally, a
dynamic update mechanism preserves salient spatiotemporal information for
stable online tracking. Extensive experiments on the nuScenes and Waymo Open
Datasets validate the effectiveness and robustness of our approach. On the
nuScenes benchmark, for instance, our method achieves state-of-the-art
performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets,
respectively.

</details>


### [55] [Noise Matters: Optimizing Matching Noise for Diffusion Classifiers](https://arxiv.org/abs/2508.11330)
*Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为NoOp的噪声优化方法，用于解决扩散分类器（DC）中的噪声不稳定性问题，通过学习匹配的噪声提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散分类器（DC）在利用生成模型进行分类时，因随机噪声的不稳定性导致性能波动，需大量噪声采样以稳定结果，降低了分类速度。

Method: 提出NoOp方法，通过频率匹配和空间匹配原则优化噪声：1）优化数据集特定噪声；2）训练Meta-Network生成图像特定噪声偏移。

Result: 实验表明，NoOp能有效提升DC的分类性能，减少噪声不稳定性。

Conclusion: NoOp通过学习匹配噪声，显著提升了扩散分类器的稳定性和效率。

Abstract: Although today's pretrained discriminative vision-language models (e.g.,
CLIP) have demonstrated strong perception abilities, such as zero-shot image
classification, they also suffer from the bag-of-words problem and spurious
bias. To mitigate these problems, some pioneering studies leverage powerful
generative models (e.g., pretrained diffusion models) to realize generalizable
image classification, dubbed Diffusion Classifier (DC). Specifically, by
randomly sampling a Gaussian noise, DC utilizes the differences of denoising
effects with different category conditions to classify categories.
Unfortunately, an inherent and notorious weakness of existing DCs is noise
instability: different random sampled noises lead to significant performance
changes. To achieve stable classification performance, existing DCs always
ensemble the results of hundreds of sampled noises, which significantly reduces
the classification speed. To this end, we firstly explore the role of noise in
DC, and conclude that: there are some ``good noises'' that can relieve the
instability. Meanwhile, we argue that these good noises should meet two
principles: Frequency Matching and Spatial Matching. Regarding both principles,
we propose a novel Noise Optimization method to learn matching (i.e., good)
noise for DCs: NoOp. For frequency matching, NoOp first optimizes a
dataset-specific noise: Given a dataset and a timestep t, optimize one randomly
initialized parameterized noise. For Spatial Matching, NoOp trains a
Meta-Network that adopts an image as input and outputs image-specific noise
offset. The sum of optimized noise and noise offset will be used in DC to
replace random noise. Extensive ablations on various datasets demonstrated the
effectiveness of NoOp.

</details>


### [56] [GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition](https://arxiv.org/abs/2508.11334)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Md Jawadul Hasan,Tze Hui Liew*

Main category: cs.CV

TL;DR: GANDiff FR是一个合成框架，通过精确控制人口统计和环境因素来测量、解释和减少偏见，结合StyleGAN3和扩散模型实现细粒度属性控制。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在公平性审计中缺乏可重复性和细粒度控制的问题。

Method: 结合StyleGAN3的身份保留生成和扩散模型的属性控制，生成10,000张平衡的人脸图像，并通过自动检测和人工验证其真实性。

Result: AdaFace将组间TPR差异减少60%，光照占剩余偏见的42%，合成数据在跨数据集评估中表现良好（r=0.85）。

Conclusion: GANDiff FR为公平性审计提供了可重复的标准，尽管计算开销较高，但能生成更多属性变体，支持透明和可扩展的偏见评估。

Abstract: We introduce GANDiff FR, the first synthetic framework that precisely
controls demographic and environmental factors to measure, explain, and reduce
bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based
identity-preserving generation with diffusion-based attribute control, enabling
fine-grained manipulation of pose around 30 degrees, illumination (four
directions), and expression (five levels) under ceteris paribus conditions. We
synthesize 10,000 demographically balanced faces across five cohorts validated
for realism via automated detection (98.2%) and human review (89%) to isolate
and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under
matched operating points shows AdaFace reduces inter-group TPR disparity by 60%
(2.5% vs. 6.3%), with illumination accounting for 42% of residual bias.
Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong
synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead
relative to pure GANs, GANDiff FR yields three times more attribute-conditioned
variants, establishing a reproducible, regulation-aligned (EU AI Act) standard
for fairness auditing. Code and data are released to support transparent,
scalable bias evaluation.

</details>


### [57] [Index-Aligned Query Distillation for Transformer-based Incremental Object Detection](https://arxiv.org/abs/2508.11339)
*Mingxiao Ma,Shunyao Zhu,Guoliang Kang*

Main category: cs.CV

TL;DR: 论文提出了一种名为IAQD的新蒸馏方法，用于解决基于Transformer的增量目标检测中的知识遗忘问题，通过索引对齐的查询蒸馏，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 在基于Transformer的增量目标检测中，传统方法使用匈牙利匹配进行知识蒸馏，但会导致知识遗忘。本文旨在解决这一问题。

Method: 提出Index-Aligned Query Distillation (IAQD)，通过索引对齐的查询蒸馏，避免知识遗忘，同时不影响新类别的学习。

Result: 实验表明，IAQD有效缓解了知识遗忘，并在多个基准测试中达到最先进性能。

Conclusion: IAQD是一种有效的蒸馏方法，为基于Transformer的增量目标检测提供了新的解决方案。

Abstract: Incremental object detection (IOD) aims to continuously expand the capability
of a model to detect novel categories while preserving its performance on
previously learned ones. When adopting a transformer-based detection model to
perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning
the detection performance on previously learned categories may severely
degenerate. Previous typical methods mainly rely on knowledge distillation (KD)
to mitigate the catastrophic knowledge forgetting of transformer-based
detection models. Specifically, they utilize Hungarian Matching to build a
correspondence between the queries of the last-phase and current-phase
detection models and align the classifier and regressor outputs between matched
queries to avoid knowledge forgetting. However, we observe that in IOD task,
Hungarian Matching is not a good choice. With Hungarian Matching, the query of
the current-phase model may match different queries of the last-phase model at
different iterations during KD. As a result, the knowledge encoded in each
query may be reshaped towards new categories, leading to the forgetting of
previously encoded knowledge of old categories. Based on our observations, we
propose a new distillation approach named Index-Aligned Query Distillation
(IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD
establishes a correspondence between queries of the previous and current phase
models that have the same index. Moreover, we perform index-aligned
distillation only on partial queries which are critical for the detection of
previous categories. In this way, IAQD largely preserves the previous semantic
and spatial encoding capabilities without interfering with the learning of new
categories. Extensive experiments on representative benchmarks demonstrate that
IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art
performance.

</details>


### [58] [Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification](https://arxiv.org/abs/2508.11340)
*Yuanlin Liu,Zhihan Zhou,Mingqiang Wei,Youyi Song*

Main category: cs.CV

TL;DR: 提出了一种名为“主动标记”的方法，通过减少人工标注成本构建代表性训练数据集，用于高效宫颈细胞分类。


<details>
  <summary>Details</summary>
Motivation: 现有自动分类方法需要大量代表性训练数据，人工成本高昂，因此需要一种更经济高效的方法。

Method: 利用分类器对未标记宫颈细胞图像的不确定性，选择最有价值的图像进行标注。

Result: 新算法显著提高了训练数据集的代表性，同时降低了人工成本。

Conclusion: 该方法为数据高效的宫颈细胞分类开辟了新途径。

Abstract: Information on the number and category of cervical cells is crucial for the
diagnosis of cervical cancer. However, existing classification methods capable
of automatically measuring this information require the training dataset to be
representative, which consumes an expensive or even unaffordable human cost. We
herein propose active labeling that enables us to construct a representative
training dataset using a much smaller human cost for data-efficient cervical
cell classification. This cost-effective method efficiently leverages the
classifier's uncertainty on the unlabeled cervical cell images to accurately
select images that are most beneficial to label. With a fast estimation of the
uncertainty, this new algorithm exhibits its validity and effectiveness in
enhancing the representative ability of the constructed training dataset. The
extensive empirical results confirm its efficacy again in navigating the usage
of human cost, opening the avenue for data-efficient cervical cell
classification.

</details>


### [59] [Semantically Guided Adversarial Testing of Vision Models Using Language Models](https://arxiv.org/abs/2508.11341)
*Katarzyna Filus,Jorge M. Cruz-Duarte*

Main category: cs.CV

TL;DR: 论文提出了一种基于语义引导的对抗目标选择框架，利用跨模态知识转移提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击的目标标签选择方法缺乏解释性、可重复性或灵活性，因此需要一种更优的方法。

Method: 利用预训练的语言和视觉语言模型（如BERT、TinyLLAMA和CLIP）作为相似性来源，选择与真实标签最相关和最不相关的标签。

Result: 实验表明，该方法优于静态语义资源（如WordNet），尤其在远距离类别关系上表现更佳。

Conclusion: 预训练模型适合构建可解释、标准化和可扩展的对抗基准。

Abstract: In targeted adversarial attacks on vision models, the selection of the target
label is a critical yet often overlooked determinant of attack success. This
target label corresponds to the class that the attacker aims to force the model
to predict. Now, existing strategies typically rely on randomness, model
predictions, or static semantic resources, limiting interpretability,
reproducibility, or flexibility. This paper then proposes a semantics-guided
framework for adversarial target selection using the cross-modal knowledge
transfer from pretrained language and vision-language models. We evaluate
several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity
sources to select the most and least semantically related labels with respect
to the ground truth, forming best- and worst-case adversarial scenarios. Our
experiments on three vision models and five attack methods reveal that these
models consistently render practical adversarial targets and surpass static
lexical databases, such as WordNet, particularly for distant class
relationships. We also observe that static testing of target labels offers a
preliminary assessment of the effectiveness of similarity sources, \textit{a
priori} testing. Our results corroborate the suitability of pretrained models
for constructing interpretable, standardized, and scalable adversarial
benchmarks across architectures and datasets.

</details>


### [60] [HOID-R1: Reinforcement Learning for Open-World Human-Object Interaction Detection Reasoning with Multimodal Large Language Model](https://arxiv.org/abs/2508.11350)
*Zhenhao Zhang,Hanqing Wang,Xiangyu Zeng,Ziyu Cheng,Jiaxin Liu,Haoyu Yan,Zhirui Liu,Kaiyang Ji,Tianxiang Gui,Ke Hu,Kangyi Chen,Yahao Fan,Mokai Pan*

Main category: cs.CV

TL;DR: HOID-R1是一个结合链式思维（CoT）引导的监督微调（SFT）和组相对策略优化（GRPO）的HOI检测框架，通过强化学习提升3D空间理解能力，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇HOI检测方法依赖大语言模型，忽视了3D空间理解能力，HOID-R1旨在弥补这一不足。

Method: 结合SFT和GRPO，引入CoT引导推理和MLLM监督机制，优化多模态对齐。

Result: 在HOI检测基准上达到最优性能，并在开放世界泛化中超越现有方法。

Conclusion: HOID-R1通过整合推理和强化学习，显著提升了HOI检测的准确性和泛化能力。

Abstract: Understanding and recognizing human-object interaction (HOI) is a pivotal
application in AR/VR and robotics. Recent open-vocabulary HOI detection
approaches depend exclusively on large language models for richer textual
prompts, neglecting their inherent 3D spatial understanding capabilities. To
address this shortcoming, we introduce HOID-R1, the first HOI detection
framework that integrates chain-of-thought (CoT) guided supervised fine-tuning
(SFT) with group relative policy optimization (GRPO) within a reinforcement
learning (RL) paradigm. Specifically, we initially apply SFT to imbue the model
with essential reasoning capabilities, forcing the model to articulate its
thought process in the output. Subsequently, we integrate GRPO to leverage
multi-reward signals for policy optimization, thereby enhancing alignment
across diverse modalities. To mitigate hallucinations in the CoT reasoning, we
introduce an "MLLM-as-a-judge" mechanism that supervises the CoT outputs,
further improving generalization. Extensive experiments show that HOID-R1
achieves state-of-the-art performance on HOI detection benchmarks and
outperforms existing methods in open-world generalization to novel scenarios.

</details>


### [61] [Leveraging the RETFound foundation model for optic disc segmentation in retinal images](https://arxiv.org/abs/2508.11354)
*Zhenyi Zhao,Muthu Rama Krishnan Mookiah,Emanuele Trucco*

Main category: cs.CV

TL;DR: RETFound首次被用于视盘分割任务，表现优异，仅需少量任务示例即可超越现有分割网络。


<details>
  <summary>Details</summary>
Motivation: 探索RETFound在视盘分割任务中的应用潜力，验证基础模型在特定任务中的表现。

Method: 在RETFound基础上训练一个轻量级头部，使用少量任务示例进行微调。

Result: 在多个公开和私有数据集上达到约96%的Dice分数，表现优于现有分割网络。

Conclusion: RETFound在视盘分割任务中表现出色，为基础模型在特定任务中的应用提供了有力支持。

Abstract: RETFound is a well-known foundation model (FM) developed for fundus camera
and optical coherence tomography images. It has shown promising performance
across multiple datasets in diagnosing diseases, both eye-specific and
systemic, from retinal images. However, to our best knowledge, it has not been
used for other tasks. We present the first adaptation of RETFound for optic
disc segmentation, a ubiquitous and foundational task in retinal image
analysis. The resulting segmentation system outperforms state-of-the-art,
segmentation-specific baseline networks after training a head with only a very
modest number of task-specific examples. We report and discuss results with
four public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private
dataset, GoDARTS, achieving about 96% Dice consistently across all datasets.
Overall, our method obtains excellent performance in internal verification,
domain generalization and domain adaptation, and exceeds most of the
state-of-the-art baseline results. We discuss the results in the framework of
the debate about FMs as alternatives to task-specific architectures. The code
is available at: [link to be added after the paper is accepted]

</details>


### [62] [Does the Skeleton-Recall Loss Really Work?](https://arxiv.org/abs/2508.11374)
*Devansh Arora,Nitin Kumar,Sukrit Gupta*

Main category: cs.CV

TL;DR: 论文分析了Skeleton Recall Loss（SRL）在图像分割中的表现，发现其并未超越传统基线模型。


<details>
  <summary>Details</summary>
Motivation: 探讨拓扑保持损失函数（如SRL）在细管状结构分割中的实际效果，验证其是否如声称的优于传统方法。

Method: 对SRL的梯度进行理论分析，并在多个管状数据集上比较其与传统模型的性能。

Result: SRL的表现未超过传统基线模型，理论和实验均支持这一结论。

Conclusion: 拓扑损失函数在复杂管状结构分割中存在局限性，为未来研究提供了重要参考。

Abstract: Image segmentation is an important and widely performed task in computer
vision. Accomplishing effective image segmentation in diverse settings often
requires custom model architectures and loss functions. A set of models that
specialize in segmenting thin tubular structures are topology
preservation-based loss functions. These models often utilize a pixel
skeletonization process claimed to generate more precise segmentation masks of
thin tubes and better capture the structures that other models often miss. One
such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite
{kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark
tubular datasets. In this work, we performed a theoretical analysis of the
gradients for the SRL loss. Upon comparing the performance of the proposed
method on some of the tubular datasets (used in the original work, along with
some additional datasets), we found that the performance of SRL-based
segmentation models did not exceed traditional baseline models. By providing
both a theoretical explanation and empirical evidence, this work critically
evaluates the limitations of topology-based loss functions, offering valuable
insights for researchers aiming to develop more effective segmentation models
for complex tubular structures.

</details>


### [63] [Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition](https://arxiv.org/abs/2508.11376)
*Durgesh Mishra,Rishabh Uikey*

Main category: cs.CV

TL;DR: 提出了一种结合实例级嵌入蒸馏和关系相似性蒸馏的统一知识蒸馏框架，用于优化人脸识别模型，在多个基准数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法在捕获细粒度实例细节和复杂关系结构方面表现不佳，导致性能不理想。

Method: 提出两种新损失函数：实例级嵌入蒸馏（动态硬挖掘策略）和关系相似性蒸馏（记忆库机制和样本挖掘策略）。

Result: 在多个基准数据集上优于现有蒸馏方法，学生模型甚至能超越教师模型的准确性。

Conclusion: 统一框架实现了更全面的蒸馏过程，提升了模型性能。

Abstract: Knowledge Distillation is crucial for optimizing face recognition models for
deployment in computationally limited settings, such as edge devices.
Traditional KD methods, such as Raw L2 Feature Distillation or Feature
Consistency loss, often fail to capture both fine-grained instance-level
details and complex relational structures, leading to suboptimal performance.
We propose a unified approach that integrates two novel loss functions,
Instance-Level Embedding Distillation and Relation-Based Pairwise Similarity
Distillation. Instance-Level Embedding Distillation focuses on aligning
individual feature embeddings by leveraging a dynamic hard mining strategy,
thereby enhancing learning from challenging examples. Relation-Based Pairwise
Similarity Distillation captures relational information through pairwise
similarity relationships, employing a memory bank mechanism and a sample mining
strategy. This unified framework ensures both effective instance-level
alignment and preservation of geometric relationships between samples, leading
to a more comprehensive distillation process. Our unified framework outperforms
state-of-the-art distillation methods across multiple benchmark face
recognition datasets, as demonstrated by extensive experimental evaluations.
Interestingly, when using strong teacher networks compared to the student, our
unified KD enables the student to even surpass the teacher's accuracy.

</details>


### [64] [G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration](https://arxiv.org/abs/2508.11379)
*Ramil Khafizov,Artem Komarichev,Ruslan Rakhimov,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: G-CUT3R是一种新颖的3D场景重建方法，通过整合先验信息改进了CUT3R模型，利用辅助数据（如深度、相机校准或位置）提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖输入图像，而G-CUT3R利用现实中常见的辅助数据，以更灵活的方式提升3D重建效果。

Method: 对CUT3R进行轻量级修改，为每种辅助数据设计专用编码器，通过零卷积与RGB图像特征融合。

Result: 在多个基准测试中表现显著优于现有方法，有效利用先验信息并兼容不同输入模态。

Conclusion: G-CUT3R通过整合先验信息，显著提升了3D场景重建的性能和灵活性。

Abstract: We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene
reconstruction that enhances the CUT3R model by integrating prior information.
Unlike existing feed-forward methods that rely solely on input images, our
method leverages auxiliary data, such as depth, camera calibrations, or camera
positions, commonly available in real-world scenarios. We propose a lightweight
modification to CUT3R, incorporating a dedicated encoder for each modality to
extract features, which are fused with RGB image tokens via zero convolution.
This flexible design enables seamless integration of any combination of prior
information during inference. Evaluated across multiple benchmarks, including
3D reconstruction and other multi-view tasks, our approach demonstrates
significant performance improvements, showing its ability to effectively
utilize available priors while maintaining compatibility with varying input
modalities.

</details>


### [65] [RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator](https://arxiv.org/abs/2508.11409)
*Zhiming Liu,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: RMFAT是一种轻量级循环框架，用于高效恢复受大气湍流影响的视频，显著降低计算负担并提升实时性能。


<details>
  <summary>Details</summary>
Motivation: 大气湍流导致视频质量下降，现有方法计算成本高，难以实时部署。

Method: 采用轻量级循环框架，仅需两帧输入，结合多尺度特征编码和解码模块。

Result: 在清晰度恢复和推理速度上均优于现有方法，SSIM提升9%，运行时间减少四倍。

Conclusion: RMFAT适合实时大气湍流抑制任务，兼具高效性和性能优势。

Abstract: Atmospheric turbulence severely degrades video quality by introducing
distortions such as geometric warping, blur, and temporal flickering, posing
significant challenges to both visual clarity and temporal consistency. Current
state-of-the-art methods are based on transformer and 3D architectures and
require multi-frame input, but their large computational cost and memory usage
limit real-time deployment, especially in resource-constrained scenarios. In
this work, we propose RMFAT: Recurrent Multi-scale Feature Atmospheric
Turbulence Mitigator, designed for efficient and temporally consistent video
restoration under AT conditions. RMFAT adopts a lightweight recurrent framework
that restores each frame using only two inputs at a time, significantly
reducing temporal window size and computational burden. It further integrates
multi-scale feature encoding and decoding with temporal warping modules at both
encoder and decoder stages to enhance spatial detail and temporal coherence.
Extensive experiments on synthetic and real-world atmospheric turbulence
datasets demonstrate that RMFAT not only outperforms existing methods in terms
of clarity restoration (with nearly a 9\% improvement in SSIM) but also
achieves significantly improved inference speed (more than a fourfold reduction
in runtime), making it particularly suitable for real-time atmospheric
turbulence suppression tasks.

</details>


### [66] [SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models](https://arxiv.org/abs/2508.11411)
*Fabian H. Reith,Jannik Franzen,Dinesh R. Palli,J. Lorenz Rumberger,Dagmar Kainmueller*

Main category: cs.CV

TL;DR: SelfAdapt是一种无需标签的自适应方法，用于改进预训练的细胞分割模型，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管通用模型（如Cellpose）在多样细胞数据上表现优异，但在与训练数据不同的领域中效果下降。监督微调需要标注数据，但标注数据可能不易获取。

Method: 基于师生增强一致性训练，引入L2-SP正则化和无标签停止标准。

Result: 在LiveCell和TissueNet数据集上，AP0.5相对基线Cellpose提升高达29.64%。

Conclusion: SelfAdapt是一种高效的无监督自适应方法，可进一步提升模型性能，并已集成到Cellpose框架中。

Abstract: Deep neural networks have become the go-to method for biomedical instance
segmentation. Generalist models like Cellpose demonstrate state-of-the-art
performance across diverse cellular data, though their effectiveness often
degrades on domains that differ from their training data. While supervised
fine-tuning can address this limitation, it requires annotated data that may
not be readily available. We propose SelfAdapt, a method that enables the
adaptation of pre-trained cell segmentation models without the need for labels.
Our approach builds upon student-teacher augmentation consistency training,
introducing L2-SP regularization and label-free stopping criteria. We evaluate
our method on the LiveCell and TissueNet datasets, demonstrating relative
improvements in AP0.5 of up to 29.64% over baseline Cellpose. Additionally, we
show that our unsupervised adaptation can further improve models that were
previously fine-tuned with supervision. We release SelfAdapt as an easy-to-use
extension of the Cellpose framework. The code for our method is publicly
available at https: //github.com/Kainmueller-Lab/self_adapt.

</details>


### [67] [Training-free Dimensionality Reduction via Feature Truncation: Enhancing Efficiency in Privacy-preserving Multi-Biometric Systems](https://arxiv.org/abs/2508.11419)
*Florian Bayer,Maximilian Russo,Christian Rathgeb*

Main category: cs.CV

TL;DR: 该论文研究了多模态生物特征模板尺寸缩减对性能的影响，通过融合不同模态的特征向量，在保持生物识别准确性的同时，显著减少了模板尺寸。


<details>
  <summary>Details</summary>
Motivation: 生物特征识别广泛应用，但模板的隐私和安全性是关键问题。多模态融合可提升安全性，但传统方法计算量大，尤其是在同态加密下。

Method: 利用深度神经网络提取特征，并在虚拟多模态生物特征数据库上进行实验，评估了维度缩减对加密处理效率的影响。

Result: 通过融合多模态特征向量，模板尺寸减少了67%，且等错误率（EER）未下降。

Conclusion: 多模态特征融合在保持安全性和准确性的同时，显著提升了加密处理的效率。

Abstract: Biometric recognition is widely used, making the privacy and security of
extracted templates a critical concern. Biometric Template Protection schemes,
especially those utilizing Homomorphic Encryption, introduce significant
computational challenges due to increased workload. Recent advances in deep
neural networks have enabled state-of-the-art feature extraction for face,
fingerprint, and iris modalities. The ubiquity and affordability of biometric
sensors further facilitate multi-modal fusion, which can enhance security by
combining features from different modalities. This work investigates the
biometric performance of reduced multi-biometric template sizes. Experiments
are conducted on an in-house virtual multi-biometric database, derived from
DNN-extracted features for face, fingerprint, and iris, using the FRGC, MCYT,
and CASIA databases. The evaluated approaches are (i) explainable and
straightforward to implement under encryption, (ii) training-free, and (iii)
capable of generalization. Dimensionality reduction of feature vectors leads to
fewer operations in the Homomorphic Encryption (HE) domain, enabling more
efficient encrypted processing while maintaining biometric accuracy and
security at a level equivalent to or exceeding single-biometric recognition.
Our results demonstrate that, by fusing feature vectors from multiple
modalities, template size can be reduced by 67 % with no loss in Equal Error
Rate (EER) compared to the best-performing single modality.

</details>


### [68] [ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving](https://arxiv.org/abs/2508.11428)
*Jingyu Li,Bozhou Zhang,Xin Jin,Jiankang Deng,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: ImagiDrive整合视觉语言模型（VLM）和驾驶世界模型（DWM），通过统一的想象-规划循环提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需结合多模态上下文理解和精准预测，但现有VLMs和DWMs的互补优势尚未充分整合。

Method: 提出ImagiDrive框架，结合VLM驾驶代理和DWM场景想象器，引入早期停止机制和轨迹选择策略。

Result: 在nuScenes和NAVSIM数据集上验证了其鲁棒性和优越性。

Conclusion: ImagiDrive为自动驾驶提供了一种高效且准确的集成解决方案。

Abstract: Autonomous driving requires rich contextual comprehension and precise
predictive reasoning to navigate dynamic and complex environments safely.
Vision-Language Models (VLMs) and Driving World Models (DWMs) have
independently emerged as powerful recipes addressing different aspects of this
challenge. VLMs provide interpretability and robust action prediction through
their ability to understand multi-modal context, while DWMs excel in generating
detailed and plausible future driving scenarios essential for proactive
planning. Integrating VLMs with DWMs is an intuitive, promising, yet
understudied strategy to exploit the complementary strengths of accurate
behavioral prediction and realistic scene generation. Nevertheless, this
integration presents notable challenges, particularly in effectively connecting
action-level decisions with high-fidelity pixel-level predictions and
maintaining computational efficiency. In this paper, we propose ImagiDrive, a
novel end-to-end autonomous driving framework that integrates a VLM-based
driving agent with a DWM-based scene imaginer to form a unified
imagination-and-planning loop. The driving agent predicts initial driving
trajectories based on multi-modal inputs, guiding the scene imaginer to
generate corresponding future scenarios. These imagined scenarios are
subsequently utilized to iteratively refine the driving agent's planning
decisions. To address efficiency and predictive accuracy challenges inherent in
this integration, we introduce an early stopping mechanism and a trajectory
selection strategy. Extensive experimental validation on the nuScenes and
NAVSIM datasets demonstrates the robustness and superiority of ImagiDrive over
previous alternatives under both open-loop and closed-loop conditions.

</details>


### [69] [Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting](https://arxiv.org/abs/2508.11431)
*Simona Kocour,Assia Benbihi,Torsten Sattler*

Main category: cs.CV

TL;DR: 论文提出了一种评估3D高斯泼溅中物体移除后语义残留的基准和框架，并发布了Remove360数据集，揭示了当前技术在真实场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究物体移除后语义信息的残留对隐私保护和可编辑场景表示的重要性。

Method: 引入新基准和评估框架，使用Remove360数据集进行实验，分析语义残留情况。

Result: 实验表明当前方法在视觉几何缺失时仍能保留语义信息，但存在局限性。

Conclusion: 当前3D物体移除技术需改进以应对真实世界的复杂性，Remove360为未来研究提供了资源。

Abstract: Understanding what semantic information persists after object removal is
critical for privacy-preserving 3D reconstruction and editable scene
representations. In this work, we introduce a novel benchmark and evaluation
framework to measure semantic residuals, the unintended semantic traces left
behind, after object removal in 3D Gaussian Splatting. We conduct experiments
across a diverse set of indoor and outdoor scenes, showing that current methods
can preserve semantic information despite the absence of visual geometry. We
also release Remove360, a dataset of pre/post-removal RGB images and
object-level masks captured in real-world environments. While prior datasets
have focused on isolated object instances, Remove360 covers a broader and more
complex range of indoor and outdoor scenes, enabling evaluation of object
removal in the context of full-scene representations. Given ground truth images
of a scene before and after object removal, we assess whether we can truly
eliminate semantic presence, and if downstream models can still infer what was
removed. Our findings reveal critical limitations in current 3D object removal
techniques and underscore the need for more robust solutions capable of
handling real-world complexity. The evaluation framework is available at
github.com/spatial-intelligence-ai/Remove360.git. Data are available at
huggingface.co/datasets/simkoc/Remove360.

</details>


### [70] [MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation](https://arxiv.org/abs/2508.11433)
*Qian Liang,Yujia Wu,Kuncheng Li,Jiwei Wei,Shiyuan He,Jinyu Guo,Ning Xie*

Main category: cs.CV

TL;DR: MM-R1框架通过跨模态思维链（X-CoT）策略，解决了统一MLLMs在个性化图像生成中的挑战，无需针对每个新主题进行数据密集型微调。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs方法通常需要针对每个新主题进行数据密集型微调，限制了其扩展性。MM-R1旨在通过跨模态推理策略，释放统一MLLMs的潜力。

Method: MM-R1结合了视觉推理和生成过程：(1)通过用户提供的图像和上下文线索理解主题概念；(2)基于提取的主题表示和用户提示生成个性化图像。采用GRPO优化推理能力。

Result: 实验表明，MM-R1能够以零样本方式生成高主题保真度和强文本对齐的个性化图像。

Conclusion: MM-R1成功释放了统一MLLMs在个性化图像生成中的潜力，解决了现有方法的扩展性问题。

Abstract: Multimodal Large Language Models (MLLMs) with unified architectures excel
across a wide range of vision-language tasks, yet aligning them with
personalized image generation remains a significant challenge. Existing methods
for MLLMs are frequently subject-specific, demanding a data-intensive
fine-tuning process for every new subject, which limits their scalability. In
this paper, we introduce MM-R1, a framework that integrates a cross-modal
Chain-of-Thought (X-CoT) reasoning strategy to unlock the inherent potential of
unified MLLMs for personalized image generation. Specifically, we structure
personalization as an integrated visual reasoning and generation process: (1)
grounding subject concepts by interpreting and understanding user-provided
images and contextual cues, and (2) generating personalized images conditioned
on both the extracted subject representations and user prompts. To further
enhance the reasoning capability, we adopt Grouped Reward Proximal Policy
Optimization (GRPO) to explicitly align the generation. Experiments demonstrate
that MM-R1 unleashes the personalization capability of unified MLLMs to
generate images with high subject fidelity and strong text alignment in a
zero-shot manner.

</details>


### [71] [Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation](https://arxiv.org/abs/2508.11446)
*Daniel Airinei,Elena Burceanu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 提出了一种基于视觉输入的室内导航深度学习方法，无需特殊传感器或地图知识，仅通过移动设备图像预测目标方向。


<details>
  <summary>Details</summary>
Motivation: 室内导航因GPS信号差而困难，现有解决方案复杂且难以部署。

Method: 采用基于图路径生成的新方法，结合可解释数据增强和课程学习，实现高效、自动化的数据收集与训练。

Result: 创建了一个大型购物中心视频数据集，并开发了易于使用的Android应用。

Conclusion: 该方法仅依赖视觉输入，简化了部署，适合实际应用。

Abstract: Indoor navigation is a difficult task, as it generally comes with poor GPS
access, forcing solutions to rely on other sources of information. While
significant progress continues to be made in this area, deployment to
production applications is still lacking, given the complexity and additional
requirements of current solutions. Here, we introduce an efficient, real-time
and easily deployable deep learning approach, based on visual input only, that
can predict the direction towards a target from images captured by a mobile
device. Our technical approach, based on a novel graph-based path generation
method, combined with explainable data augmentation and curriculum learning,
includes contributions that make the process of data collection, annotation and
training, as automatic as possible, efficient and robust. On the practical
side, we introduce a novel largescale dataset, with video footage inside a
relatively large shopping mall, in which each frame is annotated with the
correct next direction towards different specific target destinations.
Different from current methods, ours relies solely on vision, avoiding the need
of special sensors, additional markers placed along the path, knowledge of the
scene map or internet access. We also created an easy to use application for
Android, which we plan to make publicly available. We make all our data and
code available along with visual demos on our project site

</details>


### [72] [Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2508.11464)
*Xiaoya Zhu,Yibing Nan,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文探讨了基于Swin Transformer V2-B分类网络的Deepfake图像检测方法，通过数据增强和样本生成提升模型泛化能力，并取得优异成果。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，Deepfake技术既是机遇也是挑战，亟需有效检测方法以应对数字安全问题。

Method: 采用Swin Transformer V2-B分类网络，结合在线数据增强和离线样本生成技术，提升训练样本多样性和模型泛化能力。

Result: 在Deepfake图像检测竞赛中获得了卓越奖项。

Conclusion: 该方法在Deepfake检测任务中表现出色，验证了其有效性。

Abstract: With the rapid development of technology in the field of AI, deepfake
technology has emerged as a double-edged sword. It has not only created a large
amount of AI-generated content but also posed unprecedented challenges to
digital security. The task of the competition is to determine whether a face
image is a Deepfake image and output its probability score of being a Deepfake
image. In the image track competition, our approach is based on the Swin
Transformer V2-B classification network. And online data augmentation and
offline sample generation methods are employed to enrich the diversity of
training samples and increase the generalization ability of the model. Finally,
we got the award of excellence in Deepfake image detection.

</details>


### [73] [Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models](https://arxiv.org/abs/2508.11499)
*Erez Meoded*

Main category: cs.CV

TL;DR: 该研究针对16世纪拉丁手稿，通过TrOCR模型结合图像预处理和数据增强技术，显著提升了手写文本识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决历史手写文本识别中因转录稀缺、语言变异和多样书写风格导致的数字化困难。

Method: 应用TrOCR模型，结合图像预处理和四种新型数据增强方法，并评估集成学习策略。

Result: 最佳单模型增强方法（Elastic）CER为1.86，集成方法CER为1.60，相对改进50%。

Conclusion: 领域特定的数据增强和集成策略能显著提升历史手稿的识别性能。

Abstract: Historical handwritten text recognition (HTR) is essential for unlocking the
cultural and scholarly value of archival documents, yet digitization is often
hindered by scarce transcriptions, linguistic variation, and highly diverse
handwriting styles. In this study, we apply TrOCR, a state-of-the-art
transformer-based HTR model, to 16th-century Latin manuscripts authored by
Rudolf Gwalther. We investigate targeted image preprocessing and a broad suite
of data augmentation techniques, introducing four novel augmentation methods
designed specifically for historical handwriting characteristics. We also
evaluate ensemble learning approaches to leverage the complementary strengths
of augmentation-trained models. On the Gwalther dataset, our best single-model
augmentation (Elastic) achieves a Character Error Rate (CER) of 1.86, while a
top-5 voting ensemble achieves a CER of 1.60 - representing a 50% relative
improvement over the best reported TrOCR_BASE result and a 42% improvement over
the previous state of the art. These results highlight the impact of
domain-specific augmentations and ensemble strategies in advancing HTR
performance for historical manuscripts.

</details>


### [74] [CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation](https://arxiv.org/abs/2508.11469)
*Hongjin Fang,Daniel Reisenbüchler,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: CoFi是一种用于电子显微镜图像中肾小球基底膜分割的粗到细少样本学习管道，显著减少标注负担并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 传统监督深度学习方法需要大量标注，而少样本学习难以捕捉精细结构细节，因此需要一种高效且准确的分割方法。

Method: CoFi通过轻量级神经网络生成粗分割掩码，再利用形态学修剪生成高质量点提示，引导SAM细化分割。

Result: Dice系数达74.54%，推理速度为1.9 FPS，显著减轻标注和计算负担。

Conclusion: CoFi高效且准确，适用于研究和临床肾病理学应用。

Abstract: Accurate segmentation of the glomerular basement membrane (GBM) in electron
microscopy (EM) images is fundamental for quantifying membrane thickness and
supporting the diagnosis of various kidney diseases. While supervised deep
learning approaches achieve high segmentation accuracy, their reliance on
extensive pixel-level annotation renders them impractical for clinical
workflows. Few-shot learning can reduce this annotation burden but often
struggles to capture the fine structural details necessary for GBM analysis. In
this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot
segmentation pipeline designed for GBM delineation in EM images. CoFi first
trains a lightweight neural network using only three annotated images to
produce an initial coarse segmentation mask. This mask is then automatically
processed to generate high-quality point prompts with morphology-aware pruning,
which are subsequently used to guide SAM in refining the segmentation. The
proposed method achieved exceptional GBM segmentation performance, with a Dice
coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that
CoFi not only alleviates the annotation and computational burdens associated
with conventional methods, but also achieves accurate and reliable segmentation
results. The pipeline's speed and annotation efficiency make it well-suited for
research and hold strong potential for clinical applications in renal
pathology. The pipeline is publicly available at:
https://github.com/ddrrnn123/CoFi.

</details>


### [75] [TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations](https://arxiv.org/abs/2508.11478)
*Xinyi Yin,Wenbo Yuan,Xuecheng Wu,Liangyu Fu,Danlei Huang*

Main category: cs.CV

TL;DR: TACR-YOLO是一种针对特殊场景下异常行为检测（AHBD）的实时框架，通过引入坐标注意力模块、任务感知注意力模块和强化颈部网络，解决了小物体检测、任务冲突和多尺度融合等问题，并在PABD数据集上取得了91.92%的mAP。


<details>
  <summary>Details</summary>
Motivation: 特殊场景下的异常行为检测（AHBD）需求日益增长，但现有YOLO方法在小物体检测、任务冲突和多尺度融合方面存在不足。

Method: 提出TACR-YOLO框架，包括坐标注意力模块（增强小物体检测）、任务感知注意力模块（解决分类-回归冲突）和强化颈部网络（优化多尺度融合），并采用K-means聚类优化锚框和DIoU-Loss改进边界框回归。

Result: 在PABD数据集（8,529样本）上，TACR-YOLO达到91.92% mAP，速度和鲁棒性表现优异。

Conclusion: TACR-YOLO为特殊场景下的异常行为检测提供了新思路，推动了该领域的进展。

Abstract: Abnormal Human Behavior Detection (AHBD) under special scenarios is becoming
increasingly crucial. While YOLO-based detection methods excel in real-time
tasks, they remain hindered by challenges including small objects, task
conflicts, and multi-scale fusion in AHBD. To tackle them, we propose
TACR-YOLO, a new real-time framework for AHBD. We introduce a Coordinate
Attention Module to enhance small object detection, a Task-Aware Attention
Module to deal with classification-regression conflicts, and a Strengthen Neck
Network for refined multi-scale fusion, respectively. In addition, we optimize
Anchor Box sizes using K-means clustering and deploy DIoU-Loss to improve
bounding box regression. The Personnel Anomalous Behavior Detection (PABD)
dataset, which includes 8,529 samples across four behavior categories, is also
presented. Extensive experimental results indicate that TACR-YOLO achieves
91.92% mAP on PABD, with competitive speed and robustness. Ablation studies
highlight the contribution of each improvement. This work provides new insights
for abnormal behavior detection under special scenarios, advancing its
progress.

</details>


### [76] [An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture](https://arxiv.org/abs/2508.11532)
*Jingsong Xia,Yue Yin,Xiuhan Li*

Main category: cs.CV

TL;DR: 提出了一种基于改进ConvNeXt-Tiny架构的医学图像分类方法，通过结构优化和损失函数设计提升性能并降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境下高效高精度医学图像分类的挑战。

Method: 引入双全局池化特征融合策略和轻量级通道注意力模块SEVector，结合特征平滑损失函数。

Result: 在CPU条件下，10个训练周期内测试集分类准确率达89.10%，损失值稳定收敛。

Conclusion: 该方法在资源受限环境下有效提升医学图像分类性能，为模型部署提供可行方案。

Abstract: Intelligent analysis of medical imaging plays a crucial role in assisting
clinical diagnosis. However, achieving efficient and high-accuracy image
classification in resource-constrained computational environments remains
challenging. This study proposes a medical image classification method based on
an improved ConvNeXt-Tiny architecture. Through structural optimization and
loss function design, the proposed method enhances feature extraction
capability and classification performance while reducing computational
complexity. Specifically, the method introduces a dual global pooling (Global
Average Pooling and Global Max Pooling) feature fusion strategy into the
ConvNeXt-Tiny backbone to simultaneously preserve global statistical features
and salient response information. A lightweight channel attention module,
termed Squeeze-and-Excitation Vector (SEVector), is designed to improve the
adaptive allocation of channel weights while minimizing parameter overhead.
Additionally, a Feature Smoothing Loss is incorporated into the loss function
to enhance intra-class feature consistency and suppress intra-class variance.
Under CPU-only conditions (8 threads), the method achieves a maximum
classification accuracy of 89.10% on the test set within 10 training epochs,
exhibiting a stable convergence trend in loss values. Experimental results
demonstrate that the proposed method effectively improves medical image
classification performance in resource-limited settings, providing a feasible
and efficient solution for the deployment and promotion of medical imaging
analysis models.

</details>


### [77] [OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring](https://arxiv.org/abs/2508.11482)
*Ruoxin Xiong,Yanyu Wang,Jiannan Cai,Kaijian Liu,Yuansheng Zhu,Pingbo Tang,Nora El-Gohary*

Main category: cs.CV

TL;DR: 本文系统回顾了建筑行业中用于AI和ML应用的视觉数据集，提出了一个分类框架并创建了开源目录OpenConstruction，同时指出了现有数据集的不足并提出了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 建筑行业对高质量、领域特定的视觉数据集需求日益增长，但现有资源在规模、模态、标注质量和代表性上差异较大，缺乏系统性分类和评估。

Method: 通过广泛搜索学术数据库和开放数据平台，收集了51个公开视觉数据集（2005-2024年），并采用结构化数据模式进行分类。

Result: 创建了开源目录OpenConstruction，分类了数据集的基本信息、模态、标注框架和应用领域，并指出了当前数据集的局限性。

Conclusion: 提出了基于FAIR原则的未来数据基础设施路线图，支持建筑行业数据驱动解决方案的发展。

Abstract: The construction industry increasingly relies on visual data to support
Artificial Intelligence (AI) and Machine Learning (ML) applications for site
monitoring. High-quality, domain-specific datasets, comprising images, videos,
and point clouds, capture site geometry and spatiotemporal dynamics, including
the location and interaction of objects, workers, and materials. However,
despite growing interest in leveraging visual datasets, existing resources vary
widely in sizes, data modalities, annotation quality, and representativeness of
real-world construction conditions. A systematic review to categorize their
data characteristics and application contexts is still lacking, limiting the
community's ability to fully understand the dataset landscape, identify
critical gaps, and guide future directions toward more effective, reliable, and
scalable AI applications in construction. To address this gap, this study
conducts an extensive search of academic databases and open-data platforms,
yielding 51 publicly available visual datasets that span the 2005-2024 period.
These datasets are categorized using a structured data schema covering (i) data
fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and
point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv)
downstream application domains (e.g., progress tracking). This study
synthesizes these findings into an open-source catalog, OpenConstruction,
supporting data-driven method development. Furthermore, the study discusses
several critical limitations in the existing construction dataset landscape and
presents a roadmap for future data infrastructure anchored in the Findability,
Accessibility, Interoperability, and Reusability (FAIR) principles. By
reviewing the current landscape and outlining strategic priorities, this study
supports the advancement of data-centric solutions in the construction sector.

</details>


### [78] [CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models](https://arxiv.org/abs/2508.11484)
*Xiaoxue Wu,Bingjie Gao,Yu Qiao,Yaohui Wang,Xinyuan Chen*

Main category: cs.CV

TL;DR: CineTrans是一个新颖的框架，用于生成具有电影风格过渡的多镜头视频，通过注意力映射和掩码控制机制实现稳定过渡。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在多镜头过渡方面表现不佳，限制了生成视频的多样性。

Method: 构建Cine250K数据集，利用扩散模型的注意力映射设计掩码控制机制，实现训练无关的过渡控制。

Result: CineTrans在多镜头视频生成中表现优于基线模型，过渡更稳定且符合电影风格。

Conclusion: CineTrans为多镜头视频生成提供了有效解决方案，并通过新指标验证了其优越性。

Abstract: Despite significant advances in video synthesis, research into multi-shot
video generation remains in its infancy. Even with scaled-up models and massive
datasets, the shot transition capabilities remain rudimentary and unstable,
largely confining generated videos to single-shot sequences. In this work, we
introduce CineTrans, a novel framework for generating coherent multi-shot
videos with cinematic, film-style transitions. To facilitate insights into the
film editing style, we construct a multi-shot video-text dataset Cine250K with
detailed shot annotations. Furthermore, our analysis of existing video
diffusion models uncovers a correspondence between attention maps in the
diffusion model and shot boundaries, which we leverage to design a mask-based
control mechanism that enables transitions at arbitrary positions and transfers
effectively in a training-free setting. After fine-tuning on our dataset with
the mask mechanism, CineTrans produces cinematic multi-shot sequences while
adhering to the film editing style, avoiding unstable transitions or naive
concatenations. Finally, we propose specialized evaluation metrics for
transition control, temporal consistency and overall quality, and demonstrate
through extensive experiments that CineTrans significantly outperforms existing
baselines across all criteria.

</details>


### [79] [Automated Building Heritage Assessment Using Street-Level Imagery](https://arxiv.org/abs/2508.11486)
*Kristina Dabrock,Tim Johansson,Anna Donarelli,Mikael Mangold,Noah Pflugradt,Jann Michael Weinand,Jochen Linßen*

Main category: cs.CV

TL;DR: 利用GPT和机器学习模型结合建筑登记数据，识别建筑的文化遗产价值，支持节能改造。


<details>
  <summary>Details</summary>
Motivation: 量化建筑节能措施（如围护结构改造）需要详细数据，同时需保护文化遗产。传统方法成本高、耗时长，AI工具可提高效率。

Method: 使用GPT从建筑立面图像中提取文化遗产价值特征，结合建筑登记数据训练机器学习模型，分类建筑类型。

Result: 验证显示，结合GPT和登记数据的模型F1得分为0.71，仅用GPT数据的得分为0.60。

Conclusion: 该方法可提高数据库质量，支持节能改造中文化遗产价值的综合考虑。

Abstract: Detailed data is required to quantify energy conservation measures in
buildings, such as envelop retrofits, without compromising cultural heritage.
Novel artificial intelligence tools may improve efficiency in identifying
heritage values in buildings compared to costly and time-consuming traditional
inventories. In this study, the large language model GPT was used to detect
various aspects of cultural heritage value in fa\c{c}ade images. Using this
data and building register data as features, machine learning models were
trained to classify multi-family and non-residential buildings in Stockholm,
Sweden. Validation against an expert-created inventory shows a macro F1-score
of 0.71 using a combination of register data and features retrieved from GPT,
and a score of 0.60 using only GPT-derived data. The presented methodology can
contribute to a higher-quality database and thus support careful energy
efficiency measures and integrated consideration of heritage value in
large-scale energetic refurbishment scenarios.

</details>


### [80] [Controlling Multimodal LLMs via Reward-guided Decoding](https://arxiv.org/abs/2508.11616)
*Oscar Mañas,Pierluca D'Oro,Koustuv Sinha,Adriana Romero-Soriano,Michal Drozdzal,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: 本文提出了一种通过奖励引导解码的方法，用于控制多模态大语言模型（MLLMs）的视觉定位能力，实现了对对象精度和召回率的动态调控。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs的广泛应用，如何根据用户需求灵活调整其性能成为关键问题。本文旨在通过控制解码过程提升MLLMs的视觉定位能力。

Method: 构建两个独立的奖励模型，分别控制对象精度和召回率，并通过动态调整奖励函数权重和解码搜索范围，实现对MLLM推理过程的灵活控制。

Result: 在标准对象幻觉基准测试中，该方法显著优于现有幻觉缓解方法，同时提供了对MLLM推理的高度可控性。

Conclusion: 该方法为MLLMs的适应性调整提供了有效工具，尤其在视觉定位任务中表现出色。

Abstract: As Multimodal Large Language Models (MLLMs) gain widespread applicability, it
is becoming increasingly desirable to adapt them for diverse user needs. In
this paper, we study the adaptation of MLLMs through controlled decoding. To
achieve this, we introduce the first method for reward-guided decoding of MLLMs
and demonstrate its application in improving their visual grounding. Our method
involves building reward models for visual grounding and using them to guide
the MLLM's decoding process. Concretely, we build two separate reward models to
independently control the degree of object precision and recall in the model's
output. Our approach enables on-the-fly controllability of an MLLM's inference
process in two ways: first, by giving control over the relative importance of
each reward function during decoding, allowing a user to dynamically trade off
object precision for recall in image captioning tasks; second, by giving
control over the breadth of the search during decoding, allowing the user to
control the trade-off between the amount of test-time compute and the degree of
visual grounding. We evaluate our method on standard object hallucination
benchmarks, showing that it provides significant controllability over MLLM
inference, while consistently outperforming existing hallucination mitigation
methods.

</details>


### [81] [Perception in Plan: Coupled Perception and Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.11488)
*Bozhou Zhang,Jingyu Li,Nan Song,Li Zhang*

Main category: cs.CV

TL;DR: VeteranAD提出了一种感知与规划耦合的端到端自动驾驶框架，通过将感知融入规划过程，实现目标导向的感知，提升规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用感知-规划分离的范式，限制了规划性能。本文旨在通过感知与规划的紧密耦合，实现更精准的自动驾驶行为。

Method: 设计了感知-规划一体化框架VeteranAD，利用多模式锚定轨迹作为规划先验，引导感知模块针对性采集交通元素，并采用自回归策略逐步预测轨迹。

Result: 在NAVSIM和Bench2Drive数据集上，VeteranAD实现了最先进的性能。

Conclusion: VeteranAD通过感知与规划的深度融合，显著提升了端到端自动驾驶的准确性和可靠性。

Abstract: End-to-end autonomous driving has achieved remarkable advancements in recent
years. Existing methods primarily follow a perception-planning paradigm, where
perception and planning are executed sequentially within a fully differentiable
framework for planning-oriented optimization. We further advance this paradigm
through a perception-in-plan framework design, which integrates perception into
the planning process. This design facilitates targeted perception guided by
evolving planning objectives over time, ultimately enhancing planning
performance. Building on this insight, we introduce VeteranAD, a coupled
perception and planning framework for end-to-end autonomous driving. By
incorporating multi-mode anchored trajectories as planning priors, the
perception module is specifically designed to gather traffic elements along
these trajectories, enabling comprehensive and targeted perception. Planning
trajectories are then generated based on both the perception results and the
planning priors. To make perception fully serve planning, we adopt an
autoregressive strategy that progressively predicts future trajectories while
focusing on relevant regions for targeted perception at each step. With this
simple yet effective design, VeteranAD fully unleashes the potential of
planning-oriented end-to-end methods, leading to more accurate and reliable
driving behavior. Extensive experiments on the NAVSIM and Bench2Drive datasets
demonstrate that our VeteranAD achieves state-of-the-art performance.

</details>


### [82] [Hierarchical Graph Feature Enhancement with Adaptive Frequency Modulation for Visual Recognition](https://arxiv.org/abs/2508.11497)
*Feiyue Zhao,Zhichao Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为HGFE的框架，通过将图推理融入CNN，增强结构感知和特征表示，提升视觉识别任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统CNN依赖规则网格结构，难以建模复杂拓扑关系和非局部语义，HGFE旨在解决这一局限。

Method: HGFE构建了两种互补的图结构：局部空间依赖的窗口内图卷积和全局语义关系的窗口间超节点交互，并引入自适应频率调制模块。

Result: 在多个数据集（如CIFAR-100、PASCAL VOC等）上验证了HGFE在结构表示和识别性能上的有效性。

Conclusion: HGFE是一种轻量级、端到端可训练的模块，可无缝集成到标准CNN中，显著提升视觉任务性能。

Abstract: Convolutional neural networks (CNNs) have
  demonstrated strong performance in visual recognition tasks,
  but their inherent reliance on regular grid structures limits
  their capacity to model complex topological relationships and
  non-local semantics within images. To address this limita tion, we propose
the hierarchical graph feature enhancement
  (HGFE), a novel framework that integrates graph-based rea soning into CNNs to
enhance both structural awareness and
  feature representation. HGFE builds two complementary levels
  of graph structures: intra-window graph convolution to cap ture local spatial
dependencies and inter-window supernode
  interactions to model global semantic relationships. Moreover,
  we introduce an adaptive frequency modulation module that
  dynamically balances low-frequency and high-frequency signal
  propagation, preserving critical edge and texture information
  while mitigating over-smoothing. The proposed HGFE module
  is lightweight, end-to-end trainable, and can be seamlessly
  integrated into standard CNN backbone networks. Extensive
  experiments on CIFAR-100 (classification), PASCAL VOC,
  and VisDrone (detection), as well as CrackSeg and CarParts
  (segmentation), validated the effectiveness of the HGFE in
  improving structural representation and enhancing overall
  recognition performance.

</details>


### [83] [AIM: Amending Inherent Interpretability via Self-Supervised Masking](https://arxiv.org/abs/2508.11502)
*Eyad Alshami,Shashank Agnihotri,Bernt Schiele,Margret Keuper*

Main category: cs.CV

TL;DR: AIM方法通过自监督掩码增强DNN对真实特征的使用，提升模型性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决DNN依赖虚假特征的问题，无需额外标注即可提升模型对真实特征的利用。

Method: 利用多阶段编码特征引导自监督掩码过程，训练高性能且可解释的模型。

Result: 在多个数据集上验证，AIM显著提升可解释性（EPG分数）和准确性。

Conclusion: AIM有效促进真实特征的使用，提升泛化能力和人机对齐的可解释性。

Abstract: It has been observed that deep neural networks (DNNs) often use both genuine
as well as spurious features. In this work, we propose "Amending Inherent
Interpretability via Self-Supervised Masking" (AIM), a simple yet interestingly
effective method that promotes the network's utilization of genuine features
over spurious alternatives without requiring additional annotations. In
particular, AIM uses features at multiple encoding stages to guide a
self-supervised, sample-specific feature-masking process. As a result, AIM
enables the training of well-performing and inherently interpretable models
that faithfully summarize the decision process. We validate AIM across a
diverse range of challenging datasets that test both out-of-distribution
generalization and fine-grained visual understanding. These include
general-purpose classification benchmarks such as ImageNet100, HardImageNet,
and ImageWoof, as well as fine-grained classification datasets such as
Waterbirds, TravelingBirds, and CUB-200. AIM demonstrates significant dual
benefits: interpretability improvements, as measured by the Energy Pointing
Game (EPG) score, and accuracy gains over strong baselines. These consistent
gains across domains and architectures provide compelling evidence that AIM
promotes the use of genuine and meaningful features that directly contribute to
improved generalization and human-aligned interpretability.

</details>


### [84] [A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11](https://arxiv.org/abs/2508.11517)
*Shaoze Huang,Qi Liu,Chao Chen,Yuhang Chen*

Main category: cs.CV

TL;DR: 提出YOLOv11-KW-TA-FP模型，通过动态卷积、三重注意力机制和FP-IoU损失函数优化，显著提升混凝土裂缝检测性能。


<details>
  <summary>Details</summary>
Motivation: 快速发展的长三角地区交通基础设施老化问题突出，传统检测方法效率低，现有深度学习模型对小目标裂缝检测效果不佳。

Method: 基于YOLOv11n架构，集成动态KernelWarehouse卷积、三重注意力机制和FP-IoU损失函数的三阶段优化框架。

Result: 模型精度达91.3%，召回率76.6%，mAP@50为86.4%，在数据稀缺和噪声干扰下表现稳定。

Conclusion: 该模型为自动化基础设施检测提供了高效计算机视觉解决方案，具有显著工程实用价值。

Abstract: Accelerated aging of transportation infrastructure in the rapidly developing
Yangtze River Delta region necessitates efficient concrete crack detection, as
crack deterioration critically compromises structural integrity and regional
economic growth. To overcome the limitations of inefficient manual inspection
and the suboptimal performance of existing deep learning models, particularly
for small-target crack detection within complex backgrounds, this paper
proposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection and
segmentation model based on the YOLOv11n architecture. The proposed model
integrates a three-stage optimization framework: (1) Embedding dynamic
KernelWarehouse convolution (KWConv) within the backbone network to enhance
feature representation through a dynamic kernel sharing mechanism; (2)
Incorporating a triple attention mechanism (TA) into the feature pyramid to
strengthen channel-spatial interaction modeling; and (3) Designing an FP-IoU
loss function to facilitate adaptive bounding box regression penalization.
Experimental validation demonstrates that the enhanced model achieves
significant performance improvements over the baseline, attaining 91.3%
precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm the
synergistic efficacy of the proposed modules. Furthermore, robustness tests
indicate stable performance under conditions of data scarcity and noise
interference. This research delivers an efficient computer vision solution for
automated infrastructure inspection, exhibiting substantial practical
engineering value.

</details>


### [85] [Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction](https://arxiv.org/abs/2508.11531)
*Shilei Wang,Gong Cheng,Pujian Lai,Dong Gao,Junwei Han*

Main category: cs.CV

TL;DR: 论文提出了一种多状态跟踪器（MST），通过轻量级的状态特定增强（SSE）和跨状态交互（CSI）模块，提升了特征表示能力，同时保持低计算开销，显著提高了跟踪的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有高效跟踪器因降低计算复杂度和模型参数而牺牲了特征表示能力，限制了其在复杂环境中的跟踪准确性。

Method: MST采用多状态生成（MSG）生成多状态特征，通过SSE进行目标特定增强，并通过CSI模块实现状态间的交互和特征聚合。

Result: 实验表明，MST在多个数据集上优于现有高效跟踪器，显著提升了跟踪准确性和鲁棒性，计算开销仅为0.1 GFLOPs和0.66 M参数。

Conclusion: MST通过轻量级设计有效提升了特征表示能力，在复杂环境中表现出色，是高效跟踪领域的重要进展。

Abstract: Efficient trackers achieve faster runtime by reducing computational
complexity and model parameters. However, this efficiency often compromises the
expense of weakened feature representation capacity, thus limiting their
ability to accurately capture target states using single-layer features. To
overcome this limitation, we propose Multi-State Tracker (MST), which utilizes
highly lightweight state-specific enhancement (SSE) to perform specialized
enhancement on multi-state features produced by multi-state generation (MSG)
and aggregates them in an interactive and adaptive manner using cross-state
interaction (CSI). This design greatly enhances feature representation while
incurring minimal computational overhead, leading to improved tracking
robustness in complex environments. Specifically, the MSG generates multiple
state representations at multiple stages during feature extraction, while SSE
refines them to highlight target-specific features. The CSI module facilitates
information exchange between these states and ensures the integration of
complementary features. Notably, the introduced SSE and CSI modules adopt a
highly lightweight hidden state adaptation-based state space duality (HSA-SSD)
design, incurring only 0.1 GFLOPs in computation and 0.66 M in parameters.
Experimental results demonstrate that MST outperforms all previous efficient
trackers across multiple datasets, significantly improving tracking accuracy
and robustness. In particular, it shows excellent runtime performance, with an
AO score improvement of 4.5\% over the previous SOTA efficient tracker HCAT on
the GOT-10K dataset. The code is available at https://github.com/wsumel/MST.

</details>


### [86] [Reinforcing Video Reasoning Segmentation to Think Before It Segments](https://arxiv.org/abs/2508.11538)
*Sitong Gong,Lu Zhang,Yunzhi Zhuge,Xu Jia,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: Veason-R1是一种专用于视频推理分割的LVLM，通过GRPO和CoT初始化训练，显著提升了时空推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理时缺乏可解释性且性能不佳，需改进时空推理能力。

Method: 采用GRPO和CoT初始化训练，结合高质量CoT数据，优化推理链。

Result: 在多个基准测试中表现最优，显著超越现有方法（如ReVOS和ReasonVOS）。

Conclusion: Veason-R1通过结构化推理和高效探索，实现了高性能和鲁棒性。

Abstract: Video reasoning segmentation (VRS) endeavors to delineate referred objects in
videos guided by implicit instructions that encapsulate human intent and
temporal logic. Previous approaches leverage large vision language models
(LVLMs) to encode object semantics into <SEG> tokens for mask prediction.
However, this paradigm suffers from limited interpretability during inference
and suboptimal performance due to inadequate spatiotemporal reasoning. Drawing
inspiration from seminal breakthroughs in reinforcement learning, we introduce
Veason-R1, a specialized LVLM for VRS that emphasizes structured reasoning in
segmentation. Veason-R1 is trained through Group Relative Policy Optimization
(GRPO) augmented with Chain-of-Thought (CoT) initialization. To begin with, we
curate high-quality CoT training data to instill structured reasoning
trajectories, bridging video-level semantics and frame-level spatial grounding,
yielding the supervised fine-tuned model Veason-SFT. Subsequently, GRPO
fine-tuning encourages efficient exploration of the reasoning space by
optimizing reasoning chains. To this end, we incorporate a holistic reward
mechanism that synergistically enhances spatial alignment and temporal
consistency, bolstering keyframe localization and fine-grained grounding.
Comprehensive empirical evaluations demonstrate that Veason-R1 achieves
state-of-the-art performance on multiple benchmarks, surpassing prior art by
significant margins (e.g., +1.3 J &F in ReVOS and +10.0 J &F in ReasonVOS),
while exhibiting robustness to hallucinations (+8.8 R). Our code and model
weights will be available at Veason-R1.

</details>


### [87] [Training-Free Anomaly Generation via Dual-Attention Enhancement in Diffusion Model](https://arxiv.org/abs/2508.11550)
*Zuo Zuo,Jiahao Dong,Yanyun Qu,Zongze Wu*

Main category: cs.CV

TL;DR: 提出了一种基于Stable Diffusion的无训练异常生成框架AAG，通过改进交叉注意力机制（CAE）和自注意力机制（SAE），实现了高保真且自然的异常图像生成。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测面临数据稀缺问题，现有异常生成方法保真度不足或需额外训练数据。

Method: AAG利用Stable Diffusion的生成能力，结合CAE和SAE机制，通过文本提示和掩码生成特定区域的异常图像。

Result: 在MVTec AD和VisA数据集上验证了AAG的有效性，生成的异常图像提升了下游异常检测任务的性能。

Conclusion: AAG为工业异常检测提供了一种高效、无需训练的异常生成解决方案。

Abstract: Industrial anomaly detection (AD) plays a significant role in manufacturing
where a long-standing challenge is data scarcity. A growing body of works have
emerged to address insufficient anomaly data via anomaly generation. However,
these anomaly generation methods suffer from lack of fidelity or need to be
trained with extra data. To this end, we propose a training-free anomaly
generation framework dubbed AAG, which is based on Stable Diffusion (SD)'s
strong generation ability for effective anomaly image generation. Given a
normal image, mask and a simple text prompt, AAG can generate realistic and
natural anomalies in the specific regions and simultaneously keep contents in
other regions unchanged. In particular, we propose Cross-Attention Enhancement
(CAE) to re-engineer the cross-attention mechanism within Stable Diffusion
based on the given mask. CAE increases the similarity between visual tokens in
specific regions and text embeddings, which guides these generated visual
tokens in accordance with the text description. Besides, generated anomalies
need to be more natural and plausible with object in given image. We propose
Self-Attention Enhancement (SAE) which improves similarity between each normal
visual token and anomaly visual tokens. SAE ensures that generated anomalies
are coherent with original pattern. Extensive experiments on MVTec AD and VisA
datasets demonstrate effectiveness of AAG in anomaly generation and its
utility. Furthermore, anomaly images generated by AAG can bolster performance
of various downstream anomaly inspection tasks.

</details>


### [88] [TrajSV: A Trajectory-based Model for Sports Video Representations and Applications](https://arxiv.org/abs/2508.11569)
*Zheng Wang,Shihao Xu,Wei Shi*

Main category: cs.CV

TL;DR: TrajSV是一个基于轨迹的框架，解决了体育分析中的数据不可用、缺乏有效轨迹框架和标签不足的问题，通过三个模块实现无监督学习，并在体育视频检索、动作识别和视频字幕任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 体育分析领域存在数据不可用、缺乏有效轨迹框架和标签不足的问题，需要一种新的方法来解决这些挑战。

Method: TrajSV包含数据预处理、Clip Representation Network (CRNet)和Video Representation Network (VRNet)三个模块，利用轨迹增强的Transformer和无监督的三重对比损失优化表示。

Result: 在三种体育视频数据集上，TrajSV在视频检索中提升近70%，动作识别中9/17类别达到最优，视频字幕提升近20%。

Conclusion: TrajSV通过无监督学习显著提升了体育视频分析任务的性能，并展示了实际部署的潜力。

Abstract: Sports analytics has received significant attention from both academia and
industry in recent years. Despite the growing interest and efforts in this
field, several issues remain unresolved, including (1) data unavailability, (2)
lack of an effective trajectory-based framework, and (3) requirement for
sufficient supervision labels. In this paper, we present TrajSV, a
trajectory-based framework that addresses various issues in existing studies.
TrajSV comprises three components: data preprocessing, Clip Representation
Network (CRNet), and Video Representation Network (VRNet). The data
preprocessing module extracts player and ball trajectories from sports
broadcast videos. CRNet utilizes a trajectory-enhanced Transformer module to
learn clip representations based on these trajectories. Additionally, VRNet
learns video representations by aggregating clip representations and visual
features with an encoder-decoder architecture. Finally, a triple contrastive
loss is introduced to optimize both video and clip representations in an
unsupervised manner. The experiments are conducted on three broadcast video
datasets to verify the effectiveness of TrajSV for three types of sports (i.e.,
soccer, basketball, and volleyball) with three downstream applications (i.e.,
sports video retrieval, action spotting, and video captioning). The results
demonstrate that TrajSV achieves state-of-the-art performance in sports video
retrieval, showcasing a nearly 70% improvement. It outperforms baselines in
action spotting, achieving state-of-the-art results in 9 out of 17 action
categories, and demonstrates a nearly 20% improvement in video captioning.
Additionally, we introduce a deployed system along with the three applications
based on TrajSV.

</details>


### [89] [Causality Matters: How Temporal Information Emerges in Video Language Models](https://arxiv.org/abs/2508.11576)
*Yumeng Shi,Quanyu Long,Yin Wu,Wenya Wang*

Main category: cs.CV

TL;DR: 研究发现，视频语言模型（VideoLMs）中，时间理解主要依赖于帧间注意力机制，而非传统的位置编码（PEs）。通过分析，提出了两种效率优化策略。


<details>
  <summary>Details</summary>
Motivation: 探索视频语言模型中时间理解的机制，挑战传统依赖位置编码的观点。

Method: 通过移除或修改PEs、反转帧序列等实验，分析时间信息的整合路径，并提出跨模态注意力阶段化和时间退出机制。

Result: 发现时间信息通过帧间注意力逐步合成，最终整合到查询令牌中；提出的优化策略在实验中表现有效。

Conclusion: 时间理解源于帧间注意力机制，而非PEs；提出的策略为未来模型优化提供了新方向。

Abstract: Video language models (VideoLMs) have made significant progress in multimodal
understanding. However, temporal understanding, which involves identifying
event order, duration, and relationships across time, still remains a core
challenge. Prior works emphasize positional encodings (PEs) as a key mechanism
for encoding temporal structure. Surprisingly, we find that removing or
modifying PEs in video inputs yields minimal degradation in the performance of
temporal understanding. In contrast, reversing the frame sequence while
preserving the original PEs causes a substantial drop. To explain this
behavior, we conduct substantial analysis experiments to trace how temporal
information is integrated within the model. We uncover a causal information
pathway: temporal cues are progressively synthesized through inter-frame
attention, aggregated in the final frame, and subsequently integrated into the
query tokens. This emergent mechanism shows that temporal reasoning emerges
from inter-visual token interactions under the constraints of causal attention,
which implicitly encodes temporal structure. Based on these insights, we
propose two efficiency-oriented strategies: staged cross-modal attention and a
temporal exit mechanism for early token truncation. Experiments on two
benchmarks validate the effectiveness of both approaches. To the best of our
knowledge, this is the first work to systematically investigate video temporal
understanding in VideoLMs, offering insights for future model improvement.

</details>


### [90] [DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring](https://arxiv.org/abs/2508.11591)
*Durga Joshi,Chandi Witharana,Robert Fahey,Thomas Worthley,Zhe Zhu,Diego Cerrai*

Main category: cs.CV

TL;DR: 提出了一种低成本、可重复的框架，利用车载摄像头视频数据实时评估和定位路边植被与基础设施。


<details>
  <summary>Details</summary>
Motivation: 传统遥感方法（如LiDAR）成本高且不实时，需要一种快速、经济的替代方案。

Method: 结合单目深度估计、深度误差校正和几何三角测量，生成精确的空间和结构数据。

Result: 深度校正模型表现优异（R2 = 0.92），定位误差低（2.83 m），高度估计误差较小（树木2.09 m，杆0.88 m）。

Conclusion: 该框架为城市植被和基础设施监测提供了实时、经济的解决方案，适用于公用事业公司和城市规划者。

Abstract: Our study introduces a novel, low-cost, and reproducible framework for
real-time, object-level structural assessment and geolocation of roadside
vegetation and infrastructure with commonly available but underutilized
dashboard camera (dashcam) video data. We developed an end-to-end pipeline that
combines monocular depth estimation, depth error correction, and geometric
triangulation to generate accurate spatial and structural data from
street-level video streams from vehicle-mounted dashcams. Depth maps were first
estimated using a state-of-the-art monocular depth model, then refined via a
gradient-boosted regression framework to correct underestimations, particularly
for distant objects. The depth correction model achieved strong predictive
performance (R2 = 0.92, MAE = 0.31 on transformed scale), significantly
reducing bias beyond 15 m. Further, object locations were estimated using
GPS-based triangulation, while object heights were calculated using pin hole
camera geometry. Our method was evaluated under varying conditions of camera
placement and vehicle speed. Low-speed vehicle with inside camera gave the
highest accuracy, with mean geolocation error of 2.83 m, and mean absolute
error (MAE) in height estimation of 2.09 m for trees and 0.88 m for poles. To
the best of our knowledge, it is the first framework to combine monocular depth
modeling, triangulated GPS-based geolocation, and real-time structural
assessment for urban vegetation and infrastructure using consumer-grade video
data. Our approach complements conventional RS methods, such as LiDAR and image
by offering a fast, real-time, and cost-effective solution for object-level
monitoring of vegetation risks and infrastructure exposure, making it
especially valuable for utility companies, and urban planners aiming for
scalable and frequent assessments in dynamic urban environments.

</details>


### [91] [CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion](https://arxiv.org/abs/2508.11603)
*Zhe Zhu,Honghua Chen,Peng Li,Mingqiang Wei*

Main category: cs.CV

TL;DR: CoreEditor提出了一种新的文本驱动3D编辑框架，通过引入对应约束注意力机制和语义相似性，解决了多视图一致性问题，并提供了选择性编辑功能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本驱动3D编辑中难以保持多视图一致性，导致编辑效果不足和细节模糊。

Method: CoreEditor采用对应约束注意力机制，结合几何对齐和语义相似性，实现多视图一致性编辑，并提供选择性编辑流程。

Result: 实验表明，CoreEditor能够生成高质量、3D一致的编辑结果，细节更清晰，显著优于现有方法。

Conclusion: CoreEditor通过创新的注意力机制和选择性编辑，显著提升了文本驱动3D编辑的效果和用户体验。

Abstract: Text-driven 3D editing seeks to modify 3D scenes according to textual
descriptions, and most existing approaches tackle this by adapting pre-trained
2D image editors to multi-view inputs. However, without explicit control over
multi-view information exchange, they often fail to maintain cross-view
consistency, leading to insufficient edits and blurry details. We introduce
CoreEditor, a novel framework for consistent text-to-3D editing. The key
innovation is a correspondence-constrained attention mechanism that enforces
precise interactions between pixels expected to remain consistent throughout
the diffusion denoising process. Beyond relying solely on geometric alignment,
we further incorporate semantic similarity estimated during denoising, enabling
more reliable correspondence modeling and robust multi-view editing. In
addition, we design a selective editing pipeline that allows users to choose
preferred results from multiple candidates, offering greater flexibility and
user control. Extensive experiments show that CoreEditor produces high-quality,
3D-consistent edits with sharper details, significantly outperforming prior
methods.

</details>


### [92] [LoRAtorio: An intrinsic approach to LoRA Skill Composition](https://arxiv.org/abs/2508.11624)
*Niki Foteinopoulou,Ignas Budvytis,Stephan Liwicki*

Main category: cs.CV

TL;DR: LoRAtorio是一种无需训练的多LoRA组合框架，通过利用模型内在行为，解决了现有方法在开放环境中组合多个LoRA适配器的难题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在组合多个LoRA适配器时表现不佳，尤其是在开放环境中，无法预先知道所需技能的数量和性质。

Method: LoRAtorio在潜在空间中划分空间块，计算每个块的预测噪声与基础模型的余弦相似度，构建空间感知权重矩阵，指导LoRA输出的加权聚合。

Result: LoRAtorio在ClipScore上提升了1.3%，在GPT-4V成对评估中胜率为72.43%，并在多个潜在扩散模型中表现出色。

Conclusion: LoRAtorio通过动态模块选择和空间感知权重矩阵，实现了多LoRA组合的最先进性能。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted technique in
text-to-image diffusion models, enabling the personalisation of visual concepts
such as characters, styles, and objects. However, existing approaches struggle
to effectively compose multiple LoRA adapters, particularly in open-ended
settings where the number and nature of required skills are not known in
advance. In this work, we present LoRAtorio, a novel train-free framework for
multi-LoRA composition that leverages intrinsic model behaviour. Our method is
motivated by two key observations: (1) LoRA adapters trained on narrow domains
produce denoised outputs that diverge from the base model, and (2) when
operating out-of-distribution, LoRA outputs show behaviour closer to the base
model than when conditioned in distribution. The balance between these two
observations allows for exceptional performance in the single LoRA scenario,
which nevertheless deteriorates when multiple LoRAs are loaded. Our method
operates in the latent space by dividing it into spatial patches and computing
cosine similarity between each patch's predicted noise and that of the base
model. These similarities are used to construct a spatially-aware weight
matrix, which guides a weighted aggregation of LoRA outputs. To address domain
drift, we further propose a modification to classifier-free guidance that
incorporates the base model's unconditional score into the composition. We
extend this formulation to a dynamic module selection setting, enabling
inference-time selection of relevant LoRA adapters from a large pool. LoRAtorio
achieves state-of-the-art performance, showing up to a 1.3% improvement in
ClipScore and a 72.43% win rate in GPT-4V pairwise evaluations, and generalises
effectively to multiple latent diffusion models.

</details>


### [93] [Is ChatGPT-5 Ready for Mammogram VQA?](https://arxiv.org/abs/2508.11628)
*Qiang Li,Shansong Wang,Mingzhe Hu,Mojtaba Safari,Zachary Eidex,Xiaofeng Yang*

Main category: cs.CV

TL;DR: GPT-5在乳腺X光片视觉问答（VQA）任务中表现优于GPT-4o，但仍不及人类专家和领域专用模型。


<details>
  <summary>Details</summary>
Motivation: 评估GPT-5和GPT-4o在乳腺X光片VQA任务中的表现，探索通用大语言模型（LLMs）在临床影像辅助中的潜力。

Method: 在四个公开乳腺X光片数据集（EMBED、InBreast、CMMD、CBIS-DDSM）上测试GPT-5和GPT-4o，任务包括BI-RADS评估、异常检测和恶性分类。

Result: GPT-5在多个任务中表现最佳，但敏感性和特异性低于人类专家。例如，在EMBED数据集上，恶性分类准确率为52.8%。

Conclusion: GPT-5在乳腺X光片VQA任务中展现出潜力，但仍需领域适应和优化才能用于高风险的临床影像应用。

Abstract: Mammogram visual question answering (VQA) integrates image interpretation
with clinical reasoning and has potential to support breast cancer screening.
We systematically evaluated the GPT-5 family and GPT-4o model on four public
mammography datasets (EMBED, InBreast, CMMD, CBIS-DDSM) for BI-RADS assessment,
abnormality detection, and malignancy classification tasks. GPT-5 consistently
was the best performing model but lagged behind both human experts and
domain-specific fine-tuned models. On EMBED, GPT-5 achieved the highest scores
among GPT variants in density (56.8%), distortion (52.5%), mass (64.5%),
calcification (63.5%), and malignancy (52.8%) classification. On InBreast, it
attained 36.9% BI-RADS accuracy, 45.9% abnormality detection, and 35.0%
malignancy classification. On CMMD, GPT-5 reached 32.3% abnormality detection
and 55.0% malignancy accuracy. On CBIS-DDSM, it achieved 69.3% BI-RADS
accuracy, 66.0% abnormality detection, and 58.2% malignancy accuracy. Compared
with human expert estimations, GPT-5 exhibited lower sensitivity (63.5%) and
specificity (52.3%). While GPT-5 exhibits promising capabilities for screening
tasks, its performance remains insufficient for high-stakes clinical imaging
applications without targeted domain adaptation and optimization. However, the
tremendous improvements in performance from GPT-4o to GPT-5 show a promising
trend in the potential for general large language models (LLMs) to assist with
mammography VQA tasks.

</details>


### [94] [Thyme: Think Beyond Images](https://arxiv.org/abs/2508.11630)
*Yi-Fan Zhang,Xingyu Lu,Shukang Yin,Chaoyou Fu,Wei Chen,Xiao Hu,Bin Wen,Kaiyu Jiang,Changyi Liu,Tianke Zhang,Haonan Fan,Kaibing Chen,Jiankang Chen,Haojie Ding,Kaiyu Tang,Zhang Zhang,Liang Wang,Fan Yang,Tingting Gao,Guorui Zhou*

Main category: cs.CV

TL;DR: 论文提出Thyme框架，通过生成和执行代码增强多模态大语言模型（MLLMs）的图像处理和推理能力，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源模型在图像处理和逻辑推理能力上不如专有模型，Thyme旨在填补这一空白。

Method: 采用两阶段训练策略：先通过SFT学习代码生成，再用RL优化决策，并提出GRPO-ATS算法平衡推理与代码执行。

Result: 在近20个基准测试中，Thyme表现优异，尤其在复杂推理和高分辨率感知任务中。

Conclusion: Thyme为MLLMs提供了一种超越传统图像思维的新范式，展示了代码生成与执行的潜力。

Abstract: Following OpenAI's introduction of the ``thinking with images'' concept,
recent efforts have explored stimulating the use of visual information in the
reasoning process to enhance model performance in perception and reasoning
tasks. However, to the best of our knowledge, no open-source work currently
offers a feature set as rich as proprietary models (O3), which can perform
diverse image manipulations and simultaneously enhance logical reasoning
capabilities through code. In this paper, we make a preliminary attempt in this
direction by introducing Thyme (Think Beyond Images), a novel paradigm for
enabling MLLMs to transcend existing ``think with images'' approaches by
autonomously generating and executing diverse image processing and
computational operations via executable code. This approach not only
facilitates a rich, on-the-fly set of image manipulations (e.g., cropping,
rotation, contrast enhancement) but also allows for mathematical computations,
all while maintaining high autonomy in deciding when and how to apply these
operations. We activate this capability through a two-stage training strategy:
an initial SFT on a curated dataset of 500K samples to teach code generation,
followed by a RL phase to refine decision-making. For the RL stage, we manually
collect and design high-resolution question-answer pairs to increase the
learning difficulty, and we propose GRPO-ATS (Group Relative Policy
Optimization with Adaptive Temperature Sampling), an algorithm that applies
distinct temperatures to text and code generation to balance reasoning
exploration with code execution precision. We conduct extensive experimental
analysis and ablation studies. Comprehensive evaluations on nearly 20
benchmarks show that Thyme yields significant and consistent performance gains,
particularly in challenging high-resolution perception and complex reasoning
tasks.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [95] [SDSNN: A Single-Timestep Spiking Neural Network with Self-Dropping Neuron and Bayesian Optimization](https://arxiv.org/abs/2508.10913)
*Changqing Xu,Buxuan Song,Yi Liu,Xinfang Liao,Wenbin Zheng,Yintang Yang*

Main category: cs.NE

TL;DR: 提出了一种单时间步的脉冲神经网络（SNN），通过优化脉冲生成和时间参数，在减少计算能耗的同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统多时间步SNN在边缘计算场景中因高延迟和高能耗受限，需改进。

Method: 设计了自丢弃神经元机制和贝叶斯优化时间参数，实现单时间步高效推理。

Result: 在多个数据集上，单时间步SNN在保持或超越传统SNN精度的同时，显著降低能耗。

Conclusion: 单时间步SNN在边缘计算中具有高效节能的潜力。

Abstract: Spiking Neural Networks (SNNs), as an emerging biologically inspired
computational model, demonstrate significant energy efficiency advantages due
to their event-driven information processing mechanism. Compared to traditional
Artificial Neural Networks (ANNs), SNNs transmit information through discrete
spike signals, which substantially reduces computational energy consumption
through their sparse encoding approach. However, the multi-timestep computation
model significantly increases inference latency and energy, limiting the
applicability of SNNs in edge computing scenarios. We propose a single-timestep
SNN, which enhances accuracy and reduces computational energy consumption in a
single timestep by optimizing spike generation and temporal parameters. We
design a Self-Dropping Neuron mechanism, which enhances information-carrying
capacity through dynamic threshold adjustment and selective spike suppression.
Furthermore, we employ Bayesian optimization to globally search for time
parameters and obtain an efficient inference mode with a single time step.
Experimental results on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets
demonstrate that, compared to traditional multi-timestep SNNs employing the
Leaky Integrate-and-Fire (LIF) model, our method achieves classification
accuracies of 93.72%, 92.20%, and 69.45%, respectively, using only
single-timestep spikes, while maintaining comparable or even superior accuracy.
Additionally, it reduces energy consumption by 56%, 21%, and 22%, respectively.

</details>


### [96] [Insect-Wing Structured Microfluidic System for Reservoir Computing](https://arxiv.org/abs/2508.10915)
*Jacob Clouse,Thomas Ramsey,Samitha Somathilaka,Nicholas Kleinsasser,Sangjin Ryu,Sasitharan Balasubramaniam*

Main category: cs.NE

TL;DR: 研究提出了一种基于蜻蜓翅膀启发的微流体芯片的混合储层计算系统，用于高效、低功耗的计算。


<details>
  <summary>Details</summary>
Motivation: 随着对高效和自适应计算需求的增长，自然启发的架构为传统电子设计提供了有前景的替代方案。微流体平台在电子设备不适用的环境中表现出低功耗和高弹性的潜力。

Method: 系统采用三个染料入口通道和三个摄像头监测区域，将离散空间模式转换为动态颜色输出信号，并通过可训练的输出层进行分类。

Result: 实验结果显示，即使在粗分辨率和有限训练数据下，分类准确率仍可达91%。

Conclusion: 该研究证明了微流体储层计算的可行性，为未来低功耗计算提供了新思路。

Abstract: As the demand for more efficient and adaptive computing grows,
nature-inspired architectures offer promising alternatives to conventional
electronic designs. Microfluidic platforms, drawing on biological forms and
fluid dynamics, present a compelling foundation for low-power, high-resilience
computing in environments where electronics are unsuitable. This study explores
a hybrid reservoir computing system based on a dragonfly-wing inspired
microfluidic chip, which encodes temporal input patterns as fluid interactions
within the micro channel network.
  The system operates with three dye-based inlet channels and three
camera-monitored detection areas, transforming discrete spatial patterns into
dynamic color output signals. These reservoir output signals are then modified
and passed to a simple and trainable readout layer for pattern classification.
Using a combination of raw reservoir outputs and synthetically generated
outputs, we evaluated system performance, system clarity, and data efficiency.
The results demonstrate consistent classification accuracies up to $91\%$, even
with coarse resolution and limited training data, highlighting the viability of
the microfluidic reservoir computing.

</details>


### [97] [Use of a genetic algorithm to find solutions to introductory physics problems](https://arxiv.org/abs/2508.10920)
*Tom Bensky,Justin Kopcinski*

Main category: cs.NE

TL;DR: 使用遗传算法（GA）逐步解决入门物理问题，通过最小化方程中已知与未知数的差异来生成解。


<details>
  <summary>Details</summary>
Motivation: 帮助学生通过生成合适的方程序列解决物理问题，提高学习效率。

Method: 利用GA生成方程序列，通过提问学生获取已知量信息，优化方程差异。

Result: 该方法能有效指导解决一维运动学问题，并讨论了可解释性。

Conclusion: GA为物理问题求解提供了新思路，适合教学辅助。

Abstract: In this work, we show how a genetic algorithm (GA) can be used to find
step-by-step solutions to introductory physics problems. Our perspective is
that the underlying task for this is one of finding a sequence of equations
that will lead to the needed answer. Here a GA is used to find an appropriate
equation sequence by minimizing a fitness function that measures the difference
between the number of unknowns versus knowns in a set of equations. Information
about knowns comes from the GA posing questions to the student about what
quantities exist in the text of their problem. The questions are generated from
enumerations pulled from the chromosomes that drive the GA. Equations with
smaller known vs. unknown differences are considered more fit and are used to
produce intermediate results that feed less fit equations. We show that this
technique can guide a student to an answer to any introductory physics problem
involving one-dimensional kinematics. Interpretability findings are discussed.

</details>


### [98] [SO-PIFRNN: Self-optimization physics-informed Fourier-features randomized neural network for solving partial differential equations](https://arxiv.org/abs/2508.10921)
*Jiale Linghu,Weifeng Gao,Hao Dong,Yufeng Nie*

Main category: cs.NE

TL;DR: 提出了一种自优化物理信息傅里叶特征随机神经网络（SO-PIFRNN）框架，通过超参数优化机制显著提高PDE数值求解精度。


<details>
  <summary>Details</summary>
Motivation: 提高偏微分方程（PDE）数值求解的精度和效率，特别是在多尺度、高维和非线性问题中。

Method: 采用双层优化架构：外层使用多策略协作粒子群优化（MSC-PSO）算法优化超参数，内层通过最小二乘法确定神经网络输出层权重。创新点包括傅里叶基函数激活机制、新型导数神经网络方法和混合优化策略。

Result: 通过一系列数值实验验证了SO-PIFRNN在多尺度、高阶、高维和非线性方程中的有效性，表现出优越的逼近精度和频率捕捉能力。

Conclusion: SO-PIFRNN框架在PDE数值求解中具有显著优势，为复杂问题提供了高效且精确的解决方案。

Abstract: This study proposes a self-optimization physics-informed Fourier-features
randomized neural network (SO-PIFRNN) framework, which significantly improves
the numerical solving accuracy of PDEs through hyperparameter optimization
mechanism. The framework employs a bi-level optimization architecture: the
outer-level optimization utilizes a multi-strategy collaborated particle swarm
optimization (MSC-PSO) algorithm to search for optimal hyperparameters of
physics-informed Fourier-features randomized neural network, while the
inner-level optimization determines the output layer weights of the neural
network via the least squares method. The core innovation of this study is
embodied in the following three aspects: First, the Fourier basis function
activation mechanism is introduced in the hidden layer of neural network, which
significantly enhances the ability of the network to capture multi-frequency
components of the solution. Secondly, a novel derivative neural network method
is proposed, which improves the calculation accuracy and efficiency of PIFRNN
method. Finally, the MSC-PSO algorithm of the hybrid optimization strategy is
designed to improve the global search ability and convergence accuracy through
the synergistic effect of dynamic parameter adjustment, elitist and mutation
strategies. Through a series of numerical experiments, including multiscale
equations in complex regions, high-order equations, high-dimensional equations
and nonlinear equations, the validity of SO-PIFRNN is verified. The
experimental results affirm that SO-PIFRNN exhibits superior approximation
accuracy and frequency capture capability.

</details>


### [99] [Allee Synaptic Plasticity and Memory](https://arxiv.org/abs/2508.10929)
*Eddy Kwessi*

Main category: cs.NE

TL;DR: 论文研究了基于Allee效应的非线性可塑性模型，强调其生物启发的权重稳定机制、增强的抗噪能力及突触调节的临界阈值，展示了其在记忆保留和模式检索中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在噪声敏感性和突触权重无界增长方面存在不足，需要更稳健的解决方案。

Method: 提出Allee-based非线性可塑性模型，并扩展时间依赖动态（如资格迹和振荡输入）以提升性能。

Result: 模型在记忆容量和检索可靠性上优于经典模型（如Hebbian和Oja规则），且在动态环境中表现更稳健。

Conclusion: 该研究为神经适应建模提供了稳健框架，对人工智能和神经科学有重要启示。

Abstract: Neural plasticity is fundamental to memory storage and retrieval in
biological systems, yet existing models often fall short in addressing noise
sensitivity and unbounded synaptic weight growth. This paper investigates the
Allee-based nonlinear plasticity model, emphasizing its biologically inspired
weight stabilization mechanisms, enhanced noise robustness, and critical
thresholds for synaptic regulation. We analyze its performance in memory
retention and pattern retrieval, demonstrating increased capacity and
reliability compared to classical models like Hebbian and Oja's rules. To
address temporal limitations, we extend the model by integrating time-dependent
dynamics, including eligibility traces and oscillatory inputs, resulting in
improved retrieval accuracy and resilience in dynamic environments. This work
bridges theoretical insights with practical implications, offering a robust
framework for modeling neural adaptation and informing advances in artificial
intelligence and neuroscience.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [100] [Can We Tell if ChatGPT is a Parasite? Studying Human-AI Symbiosis with Game Theory](https://arxiv.org/abs/2508.11359)
*Jiejun Hu-Bolz,James Stovold*

Main category: cs.GT

TL;DR: 研究探讨人类与生成式AI系统是否可以通过信息驱动的交互融合为单一个体，通过三玩家随机博弈模型和信息论方法证明其可行性。


<details>
  <summary>Details</summary>
Motivation: 探索人类与AI系统的共生关系，尤其是生成式AI是否可能成为信息寄生虫。

Method: 使用三玩家随机博弈模型和信息论度量（熵、互信息、转移熵）分析交互。

Result: 模型显示人类与生成式AI能够形成聚合个体，验证了Krakauer等人的理论。

Conclusion: 研究为人类与AI的共生关系提供了理论支持，并引发对AI是否依赖人类信息的思考。

Abstract: This work asks whether a human interacting with a generative AI system can
merge into a single individual through iterative, information-driven
interactions. We model the interactions between a human, a generative AI
system, and the human's wider environment as a three-player stochastic game. We
use information-theoretic measures (entropy, mutual information, and transfer
entropy) to show that our modelled human and generative AI are able to form an
aggregate individual in the sense of Krakauer et al. (2020). The model we
present is able to answer interesting questions around the symbiotic nature of
humans and AI systems, including whether LLM-driven chatbots are acting as
parasites, feeding on the information provided by humans.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [101] [Developing and Validating a High-Throughput Robotic System for the Accelerated Development of Porous Membranes](https://arxiv.org/abs/2508.10973)
*Hongchen Wang,Sima Zeinali Danalou,Jiahao Zhu,Kenneth Sulimro,Chaewon Lim,Smita Basak,Aimee Tai,Usan Siriwardana,Jason Hattrick-Simpers,Jay Werber*

Main category: cs.RO

TL;DR: 提出了一种全自动平台，用于通过非溶剂诱导相分离（NIPS）制备和表征多孔聚合物膜，提高了实验效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统多孔聚合物膜的开发过程耗时且依赖试错，需要更高效、可重复的方法。

Method: 集成自动化溶液制备、刮涂、浸没控制和压缩测试，精确控制参数如聚合物浓度和环境湿度。

Result: 系统成功验证了聚合物浓度和湿度对膜性能的影响，如刚度和均匀性。

Conclusion: 该自动化平台为数据驱动的多孔膜优化提供了可扩展且可重复的基础。

Abstract: The development of porous polymeric membranes remains a labor-intensive
process, often requiring extensive trial and error to identify optimal
fabrication parameters. In this study, we present a fully automated platform
for membrane fabrication and characterization via nonsolvent-induced phase
separation (NIPS). The system integrates automated solution preparation, blade
casting, controlled immersion, and compression testing, allowing precise
control over fabrication parameters such as polymer concentration and ambient
humidity. The modular design allows parallel processing and reproducible
handling of samples, reducing experimental time and increasing consistency.
Compression testing is introduced as a sensitive mechanical characterization
method for estimating membrane stiffness and as a proxy to infer porosity and
intra-sample uniformity through automated analysis of stress-strain curves. As
a proof of concept to demonstrate the effectiveness of the system, NIPS was
carried out with polysulfone, the green solvent PolarClean, and water as the
polymer, solvent, and nonsolvent, respectively. Experiments conducted with the
automated system reproduced expected effects of polymer concentration and
ambient humidity on membrane properties, namely increased stiffness and
uniformity with increasing polymer concentration and humidity variations in
pore morphology and mechanical response. The developed automated platform
supports high-throughput experimentation and is well-suited for integration
into self-driving laboratory workflows, offering a scalable and reproducible
foundation for data-driven optimization of porous polymeric membranes through
NIPS.

</details>


### [102] [Robust Online Calibration for UWB-Aided Visual-Inertial Navigation with Bias Correction](https://arxiv.org/abs/2508.10999)
*Yizhi Zhou,Jie Xu,Jiawei Xia,Zechen Hu,Weizi Li,Xuan Wang*

Main category: cs.RO

TL;DR: 提出了一种新型鲁棒的在线校准框架，用于UWB辅助的视觉惯性导航系统中的UWB锚点校准，解决了现有方法对机器人定位误差和初始猜测敏感的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有UWB锚点校准方法假设机器人定位准确且对初始猜测敏感，限制了实际应用。本文旨在解决这些问题。

Method: 通过显式考虑机器人定位不确定性，提出基于Schmidt Kalman Filter（SKF）的紧密耦合在线优化方法。

Result: 仿真和实际实验验证了该方法在准确性和鲁棒性上的改进。

Conclusion: 该方法显著提升了UWB锚点校准的鲁棒性和实用性。

Abstract: This paper presents a novel robust online calibration framework for
Ultra-Wideband (UWB) anchors in UWB-aided Visual-Inertial Navigation Systems
(VINS). Accurate anchor positioning, a process known as calibration, is crucial
for integrating UWB ranging measurements into state estimation. While several
prior works have demonstrated satisfactory results by using robot-aided systems
to autonomously calibrate UWB systems, there are still some limitations: 1)
these approaches assume accurate robot localization during the initialization
step, ignoring localization errors that can compromise calibration robustness,
and 2) the calibration results are highly sensitive to the initial guess of the
UWB anchors' positions, reducing the practical applicability of these methods
in real-world scenarios. Our approach addresses these challenges by explicitly
incorporating the impact of robot localization uncertainties into the
calibration process, ensuring robust initialization. To further enhance the
robustness of the calibration results against initialization errors, we propose
a tightly-coupled Schmidt Kalman Filter (SKF)-based online refinement method,
making the system suitable for practical applications. Simulations and
real-world experiments validate the improved accuracy and robustness of our
approach.

</details>


### [103] [3D FlowMatch Actor: Unified 3D Policy for Single- and Dual-Arm Manipulation](https://arxiv.org/abs/2508.11002)
*Nikolaos Gkanatsios,Jiahe Xu,Matthew Bronars,Arsalan Mousavian,Tsung-Wei Ke,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 3D FlowMatch Actor (3DFA) 是一种结合流匹配和3D预训练视觉场景表示的机器人操作策略架构，显著提升了训练和推理速度，并在多个基准测试中取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 旨在通过结合流匹配和3D视觉表示，提高机器人操作策略的学习效率和性能，同时减少对运动规划的依赖。

Method: 利用3D相对注意力机制和流匹配技术，结合系统级和架构优化，实现快速训练和推理。

Result: 在PerAct2基准测试中性能提升41.4%，训练和推理速度提高30倍，并在74个RLBench任务中取得最佳表现。

Conclusion: 3DFA通过创新的设计和优化，显著提升了机器人操作策略的效率和性能，为实际应用提供了强大支持。

Abstract: We present 3D FlowMatch Actor (3DFA), a 3D policy architecture for robot
manipulation that combines flow matching for trajectory prediction with 3D
pretrained visual scene representations for learning from demonstration. 3DFA
leverages 3D relative attention between action and visual tokens during action
denoising, building on prior work in 3D diffusion-based single-arm policy
learning. Through a combination of flow matching and targeted system-level and
architectural optimizations, 3DFA achieves over 30x faster training and
inference than previous 3D diffusion-based policies, without sacrificing
performance. On the bimanual PerAct2 benchmark, it establishes a new state of
the art, outperforming the next-best method by an absolute margin of 41.4%. In
extensive real-world evaluations, it surpasses strong baselines with up to
1000x more parameters and significantly more pretraining. In unimanual
settings, it sets a new state of the art on 74 RLBench tasks by directly
predicting dense end-effector trajectories, eliminating the need for motion
planning. Comprehensive ablation studies underscore the importance of our
design choices for both policy effectiveness and efficiency.

</details>


### [104] [GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning](https://arxiv.org/abs/2508.11049)
*Kelin Yu,Sheng Zhang,Harshit Soora,Furong Huang,Heng Huang,Pratap Tokekar,Ruohan Gao*

Main category: cs.RO

TL;DR: GenFlowRL通过从多样化的跨体现数据集中学习生成的流来提取形状奖励，从而学习通用且鲁棒的策略。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频生成模型在机器人学习中依赖生成数据质量、缺乏环境反馈以及大规模数据集收集困难的问题。

Method: 提出GenFlowRL，利用生成的流提取低维、以对象为中心的特征，并从中学习形状奖励。

Result: 在10个操作任务的仿真和现实跨体现评估中，GenFlowRL表现优异。

Conclusion: GenFlowRL能有效利用生成的对象中心流特征，在多样化场景中实现高性能。

Abstract: Recent advances have shown that video generation models can enhance robot
learning by deriving effective robot actions through inverse dynamics. However,
these methods heavily depend on the quality of generated data and struggle with
fine-grained manipulation due to the lack of environment feedback. While
video-based reinforcement learning improves policy robustness, it remains
constrained by the uncertainty of video generation and the challenges of
collecting large-scale robot datasets for training diffusion models. To address
these limitations, we propose GenFlowRL, which derives shaped rewards from
generated flow trained from diverse cross-embodiment datasets. This enables
learning generalizable and robust policies from diverse demonstrations using
low-dimensional, object-centric features. Experiments on 10 manipulation tasks,
both in simulation and real-world cross-embodiment evaluations, demonstrate
that GenFlowRL effectively leverages manipulation features extracted from
generated object-centric flow, consistently achieving superior performance
across diverse and challenging scenarios. Our Project Page:
https://colinyu1.github.io/genflowrl

</details>


### [105] [Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance](https://arxiv.org/abs/2508.11093)
*Cesar Alan Contreras,Manolis Chiou,Alireza Rastegarpanah,Michal Szulik,Rustam Stolkin*

Main category: cs.RO

TL;DR: GUIDER框架通过结合视觉语言模型（VLM）和纯文本语言模型（LLM）增强语义先验，以过滤任务提示相关的对象和位置，实现人机协作中的意图推断和目标选择。


<details>
  <summary>Details</summary>
Motivation: 提升机器人快速推断用户意图、提供透明推理并协助用户达成目标的能力。

Method: 结合VLM和LLM形成语义先验，利用YOLO和Segment Anything Model进行视觉处理，通过评分机制筛选相关目标，动态调整导航和操作层。

Result: 机器人能够根据意图变化自主导航并抓取目标对象。

Conclusion: 未来将在Isaac Sim中评估系统实时性，进一步优化协作能力。

Abstract: Human-robot collaboration requires robots to quickly infer user intent,
provide transparent reasoning, and assist users in achieving their goals. Our
recent work introduced GUIDER, our framework for inferring navigation and
manipulation intents. We propose augmenting GUIDER with a vision-language model
(VLM) and a text-only language model (LLM) to form a semantic prior that
filters objects and locations based on the mission prompt. A vision pipeline
(YOLO for object detection and the Segment Anything Model for instance
segmentation) feeds candidate object crops into the VLM, which scores their
relevance given an operator prompt; in addition, the list of detected object
labels is ranked by a text-only LLM. These scores weight the existing
navigation and manipulation layers of GUIDER, selecting context-relevant
targets while suppressing unrelated objects. Once the combined belief exceeds a
threshold, autonomy changes occur, enabling the robot to navigate to the
desired area and retrieve the desired object, while adapting to any changes in
the operator's intent. Future work will evaluate the system on Isaac Sim using
a Franka Emika arm on a Ridgeback base, with a focus on real-time assistance.

</details>


### [106] [Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective](https://arxiv.org/abs/2508.11117)
*Xuning Yang,Clemens Eppner,Jonathan Tremblay,Dieter Fox,Stan Birchfield,Fabio Ramos*

Main category: cs.RO

TL;DR: 论文讨论了为通用机器人操作策略设计基准的挑战和需求，提出了高视觉保真度模拟、任务复杂性逐步增加和性能对齐量化的方法。


<details>
  <summary>Details</summary>
Motivation: 机器人技术是现实世界问题，但现有基准在评估通用策略和仿真到现实转移方面滞后。

Method: 1) 使用高视觉保真度模拟；2) 逐步增加任务复杂性和扰动；3) 量化仿真与现实性能对齐。

Result: 提出了改进仿真到现实转移的基准设计方法。

Conclusion: 通过高保真模拟和系统性评估，可提升通用机器人操作策略的现实应用效果。

Abstract: Current vision-based robotics simulation benchmarks have significantly
advanced robotic manipulation research. However, robotics is fundamentally a
real-world problem, and evaluation for real-world applications has lagged
behind in evaluating generalist policies. In this paper, we discuss challenges
and desiderata in designing benchmarks for generalist robotic manipulation
policies for the goal of sim-to-real policy transfer. We propose 1) utilizing
high visual-fidelity simulation for improved sim-to-real transfer, 2)
evaluating policies by systematically increasing task complexity and scenario
perturbation to assess robustness, and 3) quantifying performance alignment
between real-world performance and its simulation counterparts.

</details>


### [107] [Geometry-Aware Predictive Safety Filters on Humanoids: From Poisson Safety Functions to CBF Constrained MPC](https://arxiv.org/abs/2508.11129)
*Ryan M. Bena,Gilbert Bahati,Blake Werner,Ryan K. Cosner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种基于控制屏障函数（CBFs）的非线性模型预测控制（MPC）算法，用于在线轨迹生成，结合几何感知的安全约束，适用于动态环境中的腿式机器人导航。


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在非结构化和动态变化环境中导航时的安全轨迹规划问题。

Method: 利用泊松安全函数从感知数据中数值合成CBF约束，并将静态Dirichlet问题重新表述为参数化移动边界值问题，同时使用Minkowski集合操作考虑机器人几何形状。

Result: 在多种安全关键场景中实现了实时预测安全过滤器，验证了泊松安全函数的通用性和CBF约束MPC控制器的优势。

Conclusion: 该方法为动态环境中的机器人导航提供了一种高效且安全的解决方案。

Abstract: Autonomous navigation through unstructured and dynamically-changing
environments is a complex task that continues to present many challenges for
modern roboticists. In particular, legged robots typically possess manipulable
asymmetric geometries which must be considered during safety-critical
trajectory planning. This work proposes a predictive safety filter: a nonlinear
model predictive control (MPC) algorithm for online trajectory generation with
geometry-aware safety constraints based on control barrier functions (CBFs).
Critically, our method leverages Poisson safety functions to numerically
synthesize CBF constraints directly from perception data. We extend the
theoretical framework for Poisson safety functions to incorporate temporal
changes in the domain by reformulating the static Dirichlet problem for
Poisson's equation as a parameterized moving boundary value problem.
Furthermore, we employ Minkowski set operations to lift the domain into a
configuration space that accounts for robot geometry. Finally, we implement our
real-time predictive safety filter on humanoid and quadruped robots in various
safety-critical scenarios. The results highlight the versatility of Poisson
safety functions, as well as the benefit of CBF constrained model predictive
safety-critical controllers.

</details>


### [108] [Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward](https://arxiv.org/abs/2508.11143)
*Jiarui Yang,Bin Zhu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: AC3（Actor-Critic for Continuous Chunks）是一种新型强化学习框架，专注于稳定且高效地学习连续动作序列，解决了稀疏奖励下长时程机器人操作任务的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在稀疏奖励的长时程机器人操作任务中表现不佳，直接学习连续动作块存在稳定性和数据效率的挑战。

Method: AC3通过非对称更新规则训练演员（仅从成功轨迹学习），并使用n步回报和自监督模块稳定评论家的更新。

Result: 在BiGym和RLBench的25个任务中，AC3仅需少量演示和简单模型结构即取得较高成功率。

Conclusion: AC3的设计有效解决了稀疏奖励和长时程任务中的学习问题，验证了其优越性。

Abstract: Existing reinforcement learning (RL) methods struggle with long-horizon
robotic manipulation tasks, particularly those involving sparse rewards. While
action chunking is a promising paradigm for robotic manipulation, using RL to
directly learn continuous action chunks in a stable and data-efficient manner
remains a critical challenge. This paper introduces AC3 (Actor-Critic for
Continuous Chunks), a novel RL framework that learns to generate
high-dimensional, continuous action sequences. To make this learning process
stable and data-efficient, AC3 incorporates targeted stabilization mechanisms
for both the actor and the critic. First, to ensure reliable policy
improvement, the actor is trained with an asymmetric update rule, learning
exclusively from successful trajectories. Second, to enable effective value
learning despite sparse rewards, the critic's update is stabilized using
intra-chunk $n$-step returns and further enriched by a self-supervised module
providing intrinsic rewards at anchor points aligned with each action chunk. We
conducted extensive experiments on 25 tasks from the BiGym and RLBench
benchmarks. Results show that by using only a few demonstrations and a simple
model architecture, AC3 achieves superior success rates on most tasks,
validating its effective design.

</details>


### [109] [Visuomotor Grasping with World Models for Surgical Robots](https://arxiv.org/abs/2508.11200)
*Hongbin Lin,Bin Li,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 论文提出GASv2框架，通过视觉运动学习实现手术场景中的通用抓取，解决了模拟到现实转移、单摄像头输入和对象无关性等挑战，实验显示65%的成功率。


<details>
  <summary>Details</summary>
Motivation: 自动化手术抓取可减轻外科医生负担，提升效率和安全，但现有方法泛化性差且难以处理变形对象。视觉运动学习虽有潜力，但在手术环境中面临低信噪比、高精度要求和复杂环境等挑战。

Method: 提出GASv2框架，结合世界模型架构和手术感知管道，使用混合控制系统确保安全执行。通过域随机化在模拟中训练策略，并在真实手术场景中部署。

Result: 实验显示策略在模拟和真实手术场景中均达到65%的成功率，能泛化到未见对象和夹具，并适应多种干扰。

Conclusion: GASv2展示了视觉运动学习在手术抓取中的高性能、泛化性和鲁棒性，为自动化手术提供了可行方案。

Abstract: Grasping is a fundamental task in robot-assisted surgery (RAS), and
automating it can reduce surgeon workload while enhancing efficiency, safety,
and consistency beyond teleoperated systems. Most prior approaches rely on
explicit object pose tracking or handcrafted visual features, limiting their
generalization to novel objects, robustness to visual disturbances, and the
ability to handle deformable objects. Visuomotor learning offers a promising
alternative, but deploying it in RAS presents unique challenges, such as low
signal-to-noise ratio in visual observations, demands for high safety and
millimeter-level precision, as well as the complex surgical environment. This
paper addresses three key challenges: (i) sim-to-real transfer of visuomotor
policies to ex vivo surgical scenes, (ii) visuomotor learning using only a
single stereo camera pair -- the standard RAS setup, and (iii) object-agnostic
grasping with a single policy that generalizes to diverse, unseen surgical
objects without retraining or task-specific models. We introduce Grasp Anything
for Surgery V2 (GASv2), a visuomotor learning framework for surgical grasping.
GASv2 leverages a world-model-based architecture and a surgical perception
pipeline for visual observations, combined with a hybrid control system for
safe execution. We train the policy in simulation using domain randomization
for sim-to-real transfer and deploy it on a real robot in both phantom-based
and ex vivo surgical settings, using only a single pair of endoscopic cameras.
Extensive experiments show our policy achieves a 65% success rate in both
settings, generalizes to unseen objects and grippers, and adapts to diverse
disturbances, demonstrating strong performance, generality, and robustness.

</details>


### [110] [Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation](https://arxiv.org/abs/2508.11204)
*Hongbin Lin,Juan Rojas,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 论文提出了一种基于非等距对称性的数据增强方法（MEA），结合离线强化学习，提高了机器人视觉运动学习的采样效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要局限于等距对称性，限制了采样效率的提升。本文探索非等距对称性，以更灵活的方式利用任务对称性。

Method: 提出了一种新的部分可观测马尔可夫决策过程（POMDP）模型，结合非等距对称性结构，并设计了多群等变性增强（MEA）方法。同时，引入了一种基于体素的视觉表示方法。

Result: 在仿真和真实机器人实验中，该方法在两个操作领域均表现出高效性。

Conclusion: 非等距对称性和MEA方法显著提升了采样效率，为机器人视觉运动学习提供了新思路。

Abstract: Sampling efficiency is critical for deploying visuomotor learning in
real-world robotic manipulation. While task symmetry has emerged as a promising
inductive bias to improve efficiency, most prior work is limited to isometric
symmetries -- applying the same group transformation to all task objects across
all timesteps. In this work, we explore non-isometric symmetries, applying
multiple independent group transformations across spatial and temporal
dimensions to relax these constraints. We introduce a novel formulation of the
partially observable Markov decision process (POMDP) that incorporates the
non-isometric symmetry structures, and propose a simple yet effective data
augmentation method, Multi-Group Equivariance Augmentation (MEA). We integrate
MEA with offline reinforcement learning to enhance sampling efficiency, and
introduce a voxel-based visual representation that preserves translational
equivariance. Extensive simulation and real-robot experiments across two
manipulation domains demonstrate the effectiveness of our approach.

</details>


### [111] [Embodied Edge Intelligence Meets Near Field Communication: Concept, Design, and Verification](https://arxiv.org/abs/2508.11232)
*Guoliang Li,Xibin Jin,Yujie Wan,Chenxuan Liu,Tong Zhang,Shuai Wang,Chengzhong Xu*

Main category: cs.RO

TL;DR: 该论文提出了一种结合边缘智能（EEI）和近场通信（NFC）的新范式NEEI，以解决大型模型在实时推理中的计算需求，并优化通信效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 实现具身人工智能面临大型模型的高计算需求挑战，EEI通过边缘计算提供支持，但需要更高的频谱效率、通信安全和减少干扰。NFC因其硬件基础成为理想解决方案。

Method: 提出NEEI范式，结合EEI和NFC，并设计联合优化方法，包括EEI辅助NFC的无线电友好规划和NFC辅助EEI的视导波束聚焦。

Result: 实验结果表明，所提技术在资源效率和性能上优于多种基准方法。

Conclusion: NEEI为解决具身AI的计算和通信需求提供了新方向，未来可通过协同导航进一步优化资源效率。

Abstract: Realizing embodied artificial intelligence is challenging due to the huge
computation demands of large models (LMs). To support LMs while ensuring
real-time inference, embodied edge intelligence (EEI) is a promising paradigm,
which leverages an LM edge to provide computing powers in close proximity to
embodied robots. Due to embodied data exchange, EEI requires higher spectral
efficiency, enhanced communication security, and reduced inter-user
interference. To meet these requirements, near-field communication (NFC), which
leverages extremely large antenna arrays as its hardware foundation, is an
ideal solution. Therefore, this paper advocates the integration of EEI and NFC,
resulting in a near-field EEI (NEEI) paradigm. However, NEEI also introduces
new challenges that cannot be adequately addressed by isolated EEI or NFC
designs, creating research opportunities for joint optimization of both
functionalities. To this end, we propose radio-friendly embodied planning for
EEI-assisted NFC scenarios and view-guided beam-focusing for NFC-assisted EEI
scenarios. We also elaborate how to realize resource-efficient NEEI through
opportunistic collaborative navigation. Experimental results are provided to
confirm the superiority of the proposed techniques compared with various
benchmarks.

</details>


### [112] [Tactile Robotics: An Outlook](https://arxiv.org/abs/2508.11261)
*Shan Luo,Nathan F. Lepora,Wenzhen Yuan,Kaspar Althoefer,Gordon Cheng,Ravinder Dahiya*

Main category: cs.RO

TL;DR: 机器人触觉感知技术的发展及其在多个领域的应用前景。


<details>
  <summary>Details</summary>
Motivation: 为机器人提供类似生物系统的触觉感知能力，以支持与人类的紧密互动。

Method: 开发多种触觉传感器技术（如压阻、压电、电容、磁性和光学传感器），并结合仿真工具和多模态集成。

Result: 触觉感知技术取得进展，支持更有效的物理交互，并在多个领域具有应用潜力。

Conclusion: 需采取整体方法解决当前挑战，以推动触觉机器人技术的进一步发展。

Abstract: Robotics research has long sought to give robots the ability to perceive the
physical world through touch in an analogous manner to many biological systems.
Developing such tactile capabilities is important for numerous emerging
applications that require robots to co-exist and interact closely with humans.
Consequently, there has been growing interest in tactile sensing, leading to
the development of various technologies, including piezoresistive and
piezoelectric sensors, capacitive sensors, magnetic sensors, and optical
tactile sensors. These diverse approaches utilise different transduction
methods and materials to equip robots with distributed sensing capabilities,
enabling more effective physical interactions. These advances have been
supported in recent years by simulation tools that generate large-scale tactile
datasets to support sensor designs and algorithms to interpret and improve the
utility of tactile data. The integration of tactile sensing with other
modalities, such as vision, as well as with action strategies for active
tactile perception highlights the growing scope of this field. To further the
transformative progress in tactile robotics, a holistic approach is essential.
In this outlook article, we examine several challenges associated with the
current state of the art in tactile robotics and explore potential solutions to
inspire innovations across multiple domains, including manufacturing,
healthcare, recycling and agriculture.

</details>


### [113] [Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation](https://arxiv.org/abs/2508.11275)
*Masaki Murooka,Iori Kumagai,Mitsuharu Morisawa,Fumio Kanehiro*

Main category: cs.RO

TL;DR: 提出了一种可微分可达性地图的新方法，用于降低人形机器人运动生成的算力成本。


<details>
  <summary>Details</summary>
Motivation: 减少人形机器人运动生成的计算成本。

Method: 学习可微分可达性地图，并将其作为约束条件用于连续优化运动规划。

Result: 高效解决了多种运动规划问题，包括步态规划、多接触运动规划和操作-移动规划。

Conclusion: 可微分可达性地图是一种有效的工具，可用于人形机器人的连续优化运动规划。

Abstract: To reduce the computational cost of humanoid motion generation, we introduce
a new approach to representing robot kinematic reachability: the differentiable
reachability map. This map is a scalar-valued function defined in the task
space that takes positive values only in regions reachable by the robot's
end-effector. A key feature of this representation is that it is continuous and
differentiable with respect to task-space coordinates, enabling its direct use
as constraints in continuous optimization for humanoid motion planning. We
describe a method to learn such differentiable reachability maps from a set of
end-effector poses generated using a robot's kinematic model, using either a
neural network or a support vector machine as the learning model. By
incorporating the learned reachability map as a constraint, we formulate
humanoid motion generation as a continuous optimization problem. We demonstrate
that the proposed approach efficiently solves various motion planning problems,
including footstep planning, multi-contact motion planning, and
loco-manipulation planning for humanoid robots.

</details>


### [114] [Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agent](https://arxiv.org/abs/2508.11286)
*Che Rin Yu,Daewon Chae,Dabin Seo,Sangwon Lee,Hyeongwoo Im,Jinkyu Kim*

Main category: cs.RO

TL;DR: 论文提出了一种主动重规划框架，通过比较当前场景图与参考场景图，在子任务边界检测并修正潜在失败，提升机器人任务成功率。


<details>
  <summary>Details</summary>
Motivation: 人类能根据环境状态调整行为，而自主机器人常因缺乏适应性导致失败。现有方法多为被动响应，主动重规划依赖人工规则。本文旨在解决这一问题。

Method: 构建当前RGB-D观测的场景图与成功演示的参考图对比，在子任务边界检测不匹配时，启动轻量推理模块调整计划。

Result: 在AI2-THOR模拟器中，该方法能提前检测语义和空间不匹配，显著提高任务成功率和鲁棒性。

Conclusion: 主动重规划框架能有效预防执行失败，提升机器人自主性。

Abstract: When humans perform everyday tasks, we naturally adjust our actions based on
the current state of the environment. For instance, if we intend to put
something into a drawer but notice it is closed, we open it first. However,
many autonomous robots lack this adaptive awareness. They often follow
pre-planned actions that may overlook subtle yet critical changes in the scene,
which can result in actions being executed under outdated assumptions and
eventual failure. While replanning is critical for robust autonomy, most
existing methods respond only after failures occur, when recovery may be
inefficient or infeasible. While proactive replanning holds promise for
preventing failures in advance, current solutions often rely on manually
designed rules and extensive supervision. In this work, we present a proactive
replanning framework that detects and corrects failures at subtask boundaries
by comparing scene graphs constructed from current RGB-D observations against
reference graphs extracted from successful demonstrations. When the current
scene fails to align with reference trajectories, a lightweight reasoning
module is activated to diagnose the mismatch and adjust the plan. Experiments
in the AI2-THOR simulator demonstrate that our approach detects semantic and
spatial mismatches before execution failures occur, significantly improving
task success and robustness.

</details>


### [115] [A Comparative Study of Floating-Base Space Parameterizations for Agile Whole-Body Motion Planning](https://arxiv.org/abs/2508.11520)
*Evangelos Tsiatsianas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: 本文比较了不同浮动基参数化方法对敏捷运动轨迹优化的影响，并提出了一种基于SE(3)切空间的新方法。


<details>
  <summary>Details</summary>
Motivation: 解决敏捷运动生成中浮动基参数化选择缺乏明确指导的问题。

Method: 系统比较常见参数化方法，并引入基于SE(3)切空间的新方法。

Result: 新方法无需专用流形优化技术，可直接使用成熟数值求解器。

Conclusion: 研究为敏捷运动生成中的浮动基表示选择提供了实用指导。

Abstract: Automatically generating agile whole-body motions for legged and humanoid
robots remains a fundamental challenge in robotics. While numerous trajectory
optimization approaches have been proposed, there is no clear guideline on how
the choice of floating-base space parameterization affects performance,
especially for agile behaviors involving complex contact dynamics. In this
paper, we present a comparative study of different parameterizations for direct
transcription-based trajectory optimization of agile motions in legged systems.
We systematically evaluate several common choices under identical optimization
settings to ensure a fair comparison. Furthermore, we introduce a novel
formulation based on the tangent space of SE(3) for representing the robot's
floating-base pose, which, to our knowledge, has not received attention from
the literature. This approach enables the use of mature off-the-shelf numerical
solvers without requiring specialized manifold optimization techniques. We hope
that our experiments and analysis will provide meaningful insights for
selecting the appropriate floating-based representation for agile whole-body
motion generation.

</details>


### [116] [A Recursive Total Least Squares Solution for Bearing-Only Target Motion Analysis and Circumnavigation](https://arxiv.org/abs/2508.11289)
*Lin Li,Xueming Liu,Zhoujingzi Qiu,Tianjiang Hu,Qingrui Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种基于递归总最小二乘法（RTLS）的在线目标定位与跟踪方法，解决了仅方位目标运动分析（TMA）中的非线性问题和观测性不足问题。


<details>
  <summary>Details</summary>
Motivation: 仅方位TMA因测量模型的非线性和缺乏距离信息导致观测性和估计器收敛性差，需要改进。

Method: 采用RTLS方法减少位置估计偏差，并提出环绕控制器提升系统观测性和估计器收敛性。

Result: 仿真和实验表明，该方法在准确性和稳定性上优于现有方法。

Conclusion: RTLS方法在仅方位TMA中表现优越，具有实际应用潜力。

Abstract: Bearing-only Target Motion Analysis (TMA) is a promising technique for
passive tracking in various applications as a bearing angle is easy to measure.
Despite its advantages, bearing-only TMA is challenging due to the nonlinearity
of the bearing measurement model and the lack of range information, which
impairs observability and estimator convergence. This paper addresses these
issues by proposing a Recursive Total Least Squares (RTLS) method for online
target localization and tracking using mobile observers. The RTLS approach,
inspired by previous results on Total Least Squares (TLS), mitigates biases in
position estimation and improves computational efficiency compared to
pseudo-linear Kalman filter (PLKF) methods. Additionally, we propose a
circumnavigation controller to enhance system observability and estimator
convergence by guiding the mobile observer in orbit around the target.
Extensive simulations and experiments are performed to demonstrate the
effectiveness and robustness of the proposed method. The proposed algorithm is
also compared with the state-of-the-art approaches, which confirms its superior
performance in terms of both accuracy and stability.

</details>


### [117] [Towards Fully Onboard State Estimation and Trajectory Tracking for UAVs with Suspended Payloads](https://arxiv.org/abs/2508.11547)
*Martin Jiroušek,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 提出一种仅使用无人机标准传感器（RTK-GNSS和IMU）的框架，用于估计和控制悬挂负载的位置，性能接近真实测量，且硬件需求低。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖额外硬件（如运动捕捉系统或仪器化负载）的问题，实现低成本、易部署的负载跟踪方案。

Method: 结合线性卡尔曼滤波、模型预测轮廓控制规划和增量模型预测控制器，建模无人机与负载的耦合动力学。

Result: 仿真显示性能接近真实测量（退化<6%），对负载参数变化鲁棒；野外实验验证了实用性和可靠性。

Conclusion: 该框架在仅使用现成硬件的情况下，实现了高效负载跟踪，适用于实际户外环境。

Abstract: This paper addresses the problem of tracking the position of a
cable-suspended payload carried by an unmanned aerial vehicle, with a focus on
real-world deployment and minimal hardware requirements. In contrast to many
existing approaches that rely on motion-capture systems, additional onboard
cameras, or instrumented payloads, we propose a framework that uses only
standard onboard sensors--specifically, real-time kinematic global navigation
satellite system measurements and data from the onboard inertial measurement
unit--to estimate and control the payload's position. The system models the
full coupled dynamics of the aerial vehicle and payload, and integrates a
linear Kalman filter for state estimation, a model predictive contouring
control planner, and an incremental model predictive controller. The control
architecture is designed to remain effective despite sensing limitations and
estimation uncertainty. Extensive simulations demonstrate that the proposed
system achieves performance comparable to control based on ground-truth
measurements, with only minor degradation (< 6%). The system also shows strong
robustness to variations in payload parameters. Field experiments further
validate the framework, confirming its practical applicability and reliable
performance in outdoor environments using only off-the-shelf aerial vehicle
hardware.

</details>


### [118] [Pedestrian Dead Reckoning using Invariant Extended Kalman Filter](https://arxiv.org/abs/2508.11396)
*Jingran Zhang,Zhengzhang Yan,Yiming Chen,Zeqiang He,Jiahao Chen*

Main category: cs.RO

TL;DR: 本文提出了一种在GPS缺失环境下用于双足机器人的低成本惯性行人航位推算方法，通过伪测量改进IMU预测，并展示了InEKF优于EKF的实验结果。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失环境下双足机器人的定位问题，提供一种成本效益高的惯性行人航位推算方法。

Method: 利用IMU在支撑脚时的伪测量改进预测，采用基于矩阵李群的InEKF理论，并与标准EKF进行对比实验。

Result: 实验表明InEKF在运动捕捉、大规模多楼层行走及双足机器人实验中表现优于EKF，且参数调节更简单。

Conclusion: InEKF方法在双足机器人定位中具有可行性和优越性，适用于实际机器人系统。

Abstract: This paper presents a cost-effective inertial pedestrian dead reckoning
method for the bipedal robot in the GPS-denied environment. Each time when the
inertial measurement unit (IMU) is on the stance foot, a stationary
pseudo-measurement can be executed to provide innovation to the IMU measurement
based prediction. The matrix Lie group based theoretical development of the
adopted invariant extended Kalman filter (InEKF) is set forth for tutorial
purpose. Three experiments are conducted to compare between InEKF and standard
EKF, including motion capture benchmark experiment, large-scale multi-floor
walking experiment, and bipedal robot experiment, as an effort to show our
method's feasibility in real-world robot system. In addition, a sensitivity
analysis is included to show that InEKF is much easier to tune than EKF.

</details>


### [119] [Nominal Evaluation Of Automatic Multi-Sections Control Potential In Comparison To A Simpler One- Or Two-Sections Alternative With Predictive Spray Switching](https://arxiv.org/abs/2508.11573)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 论文比较了自动多段控制（ASC）与简化的一或两段控制方法，后者通过预测性喷洒切换实现低成本、无传感器的喷洒优化。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在复杂农业喷洒条件下，是否存在比传统ASC更简单、低成本的替代方案。

Method: 方法包括比较三种不同分段设置（48段、2段和单段控制）以及两种路径规划和切换逻辑，并在10个实际农田场景中评估。

Result: 结果表明，简化方法在路径长度、重叠控制和成本效益方面表现良好，适合手动驾驶且无需传感器。

Conclusion: 结论是简化方法在满足喷洒需求的同时，提供了低成本、无传感器的可行替代方案。

Abstract: Automatic Section Control (ASC) is a long-standing trend for spraying in
agriculture. It promises to minimise spray overlap areas. The core idea is to
(i) switch off spray nozzles on areas that have already been sprayed, and (ii)
to dynamically adjust nozzle flow rates along the boom bar that holds the spray
nozzles when velocities of boom sections vary during turn maneuvers. ASC is not
possible without sensors, in particular for accurate positioning data. Spraying
and the movement of modern wide boom bars are highly dynamic processes. In
addition, many uncertainty factors have an effect such as cross wind drift,
boom height, nozzle clogging in open-field conditions, and so forth. In view of
this complexity, the natural question arises if a simpler alternative exist.
Therefore, an Automatic Multi-Sections Control method is compared to a proposed
simpler one- or two-sections alternative that uses predictive spray switching.
The comparison is provided under nominal conditions. Agricultural spraying is
intrinsically linked to area coverage path planning and spray switching logic.
Combinations of two area coverage path planning and switching logics as well as
three sections-setups are compared. The three sections-setups differ by
controlling 48 sections, 2 sections or controlling all nozzles uniformly with
the same control signal as one single section. Methods are evaluated on 10
diverse real-world field examples, including non-convex field contours,
freeform mainfield lanes and multiple obstacle areas. A preferred method is
suggested that (i) minimises area coverage pathlength, (ii) offers intermediate
overlap, (iii) is suitable for manual driving by following a pre-planned
predictive spray switching logic for an area coverage path plan, and (iv) and
in contrast to ASC can be implemented sensor-free and therefore at low cost.

</details>


### [120] [An Exploratory Study on Crack Detection in Concrete through Human-Robot Collaboration](https://arxiv.org/abs/2508.11404)
*Junyeon Kim,Tianshu Ruan,Cesar Alan Contreras,Manolis Chiou*

Main category: cs.RO

TL;DR: AI和机器人技术用于核设施结构检测，通过人机协作提高检测精度并减少人工负担。


<details>
  <summary>Details</summary>
Motivation: 传统人工检测存在安全风险、认知负担高和准确性不足的问题，AI和机器人技术提供更安全高效的解决方案。

Method: 研究将AI辅助视觉裂纹检测集成到移动Jackal机器人平台，探索人机协作的效果。

Result: 实验表明，人机协作提高了检测精度并减少了操作员的工作负担。

Conclusion: AI辅助的人机协作在核设施检测中优于传统人工方法。

Abstract: Structural inspection in nuclear facilities is vital for maintaining
operational safety and integrity. Traditional methods of manual inspection pose
significant challenges, including safety risks, high cognitive demands, and
potential inaccuracies due to human limitations. Recent advancements in
Artificial Intelligence (AI) and robotic technologies have opened new
possibilities for safer, more efficient, and accurate inspection methodologies.
Specifically, Human-Robot Collaboration (HRC), leveraging robotic platforms
equipped with advanced detection algorithms, promises significant improvements
in inspection outcomes and reductions in human workload. This study explores
the effectiveness of AI-assisted visual crack detection integrated into a
mobile Jackal robot platform. The experiment results indicate that HRC enhances
inspection accuracy and reduces operator workload, resulting in potential
superior performance outcomes compared to traditional manual methods.

</details>


### [121] [Open, Reproducible and Trustworthy Robot-Based Experiments with Virtual Labs and Digital-Twin-Based Execution Tracing](https://arxiv.org/abs/2508.11406)
*Benjamin Alt,Mareike Picklum,Sorin Arion,Franklin Kenghagho Kenfack,Michael Beetz*

Main category: cs.RO

TL;DR: 论文提出了一种语义执行追踪框架和AICOR VRB平台，旨在实现透明、可复现的机器人自主科学实验。


<details>
  <summary>Details</summary>
Motivation: 为实现机器人科学实验的透明性、可重复性和开放性，作者提出了新的工具。

Method: 开发了语义执行追踪框架和AICOR VRB平台，结合确定性执行和语义记忆。

Result: 工具支持机器人任务的共享、复制和验证，为自主科学发现奠定基础。

Conclusion: 这些工具有助于推动机器人参与科学研究的可重复性和透明性。

Abstract: We envision a future in which autonomous robots conduct scientific
experiments in ways that are not only precise and repeatable, but also open,
trustworthy, and transparent. To realize this vision, we present two key
contributions: a semantic execution tracing framework that logs sensor data
together with semantically annotated robot belief states, ensuring that
automated experimentation is transparent and replicable; and the AICOR Virtual
Research Building (VRB), a cloud-based platform for sharing, replicating, and
validating robot task executions at scale. Together, these tools enable
reproducible, robot-driven science by integrating deterministic execution,
semantic memory, and open knowledge representation, laying the foundation for
autonomous systems to participate in scientific discovery.

</details>


### [122] [EvoPSF: Online Evolution of Autonomous Driving Models via Planning-State Feedback](https://arxiv.org/abs/2508.11453)
*Jiayue Jin,Lang Qian,Jingyu Zhang,Chuanyu Ju,Liang Song*

Main category: cs.RO

TL;DR: 提出了一种基于规划状态反馈的在线进化框架EvoPSF，通过利用规划器不确定性触发针对性模型更新，提升自动驾驶系统对新环境的适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统多为离线训练，缺乏在线适应机制，导致在真实场景中泛化能力不足。

Method: 利用规划器不确定性作为触发信号，通过自监督损失对关键对象进行针对性模型更新。

Result: 在nuScenes数据集上验证，EvoPSF显著提升了规划性能，尤其在挑战性条件下表现更优。

Conclusion: EvoPSF通过在线进化机制有效提升了自动驾驶系统的适应性和规划准确性。

Abstract: Recent years have witnessed remarkable progress in autonomous driving, with
systems evolving from modular pipelines to end-to-end architectures. However,
most existing methods are trained offline and lack mechanisms to adapt to new
environments during deployment. As a result, their generalization ability
diminishes when faced with unseen variations in real-world driving scenarios.
In this paper, we break away from the conventional "train once, deploy forever"
paradigm and propose EvoPSF, a novel online Evolution framework for autonomous
driving based on Planning-State Feedback. We argue that planning failures are
primarily caused by inaccurate object-level motion predictions, and such
failures are often reflected in the form of increased planner uncertainty. To
address this, we treat planner uncertainty as a trigger for online evolution,
using it as a diagnostic signal to initiate targeted model updates. Rather than
performing blind updates, we leverage the planner's agent-agent attention to
identify the specific objects that the ego vehicle attends to most, which are
primarily responsible for the planning failures. For these critical objects, we
compute a targeted self-supervised loss by comparing their predicted waypoints
from the prediction module with their actual future positions, selected from
the perception module's outputs with high confidence scores. This loss is then
backpropagated to adapt the model online. As a result, our method improves the
model's robustness to environmental changes, leads to more precise motion
predictions, and therefore enables more accurate and stable planning behaviors.
Experiments on both cross-region and corrupted variants of the nuScenes dataset
demonstrate that EvoPSF consistently improves planning performance under
challenging conditions.

</details>


### [123] [OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation](https://arxiv.org/abs/2508.11479)
*Tatiana Zemskova,Aleksei Staroverov,Dmitry Yudin,Aleksandr Panov*

Main category: cs.RO

TL;DR: OVSegDT是一种轻量级Transformer策略，通过语义分支和熵自适应损失调制解决了开放词汇目标导航中的过拟合和碰撞问题，显著提升了泛化性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端策略在小规模模拟数据集上过拟合，泛化能力差且行为不安全（频繁碰撞）。

Method: OVSegDT包含语义分支（目标二值掩码编码器和辅助分割损失函数）和熵自适应损失调制（动态平衡模仿与强化信号）。

Result: 训练样本复杂度降低33%，碰撞次数减少一半，在未见类别上性能与已见类别相当（40.1% SR，20.9% SPL）。

Conclusion: OVSegDT在无需深度、里程计或大型视觉语言模型的情况下，实现了开放词汇目标导航的先进性能。

Abstract: Open-vocabulary Object Goal Navigation requires an embodied agent to reach
objects described by free-form language, including categories never seen during
training. Existing end-to-end policies overfit small simulator datasets,
achieving high success on training scenes but failing to generalize and
exhibiting unsafe behaviour (frequent collisions). We introduce OVSegDT, a
lightweight transformer policy that tackles these issues with two synergistic
components. The first component is the semantic branch, which includes an
encoder for the target binary mask and an auxiliary segmentation loss function,
grounding the textual goal and providing precise spatial cues. The second
component consists of a proposed Entropy-Adaptive Loss Modulation, a per-sample
scheduler that continuously balances imitation and reinforcement signals
according to the policy entropy, eliminating brittle manual phase switches.
These additions cut the sample complexity of training by 33%, and reduce
collision count in two times while keeping inference cost low (130M parameters,
RGB-only input). On HM3D-OVON, our model matches the performance on unseen
categories to that on seen ones and establishes state-of-the-art results (40.1%
SR, 20.9% SPL on val unseen) without depth, odometry, or large vision-language
models. Code is available at https://github.com/CognitiveAISystems/OVSegDT.

</details>


### [124] [i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping](https://arxiv.org/abs/2508.11485)
*Hailiang Tang,Tisheng Zhang,Liqiang Wang,Xin Ding,Man Yuan,Zhiyu Xiang,Jujin Chen,Yuhan Bian,Shuangyan Liu,Yuqing Wang,Guan Wang,Xiaoji Niu*

Main category: cs.RO

TL;DR: i2Nav-Robot是一个大规模多传感器融合数据集，旨在解决现有UGV数据集在传感器配置、时间同步和场景多样性方面的不足，支持室内外导航与建图研究。


<details>
  <summary>Details</summary>
Motivation: 现有UGV数据集在传感器配置、时间同步、地面真实性和场景多样性方面存在不足，限制了导航与建图技术的发展。

Method: 集成多模态传感器（如固态LiDAR、4D雷达、立体相机等），通过硬件同步和离线校准确保时间同步，构建包含多样场景的十大规模序列。

Result: 数据集总长度约17060米，提供厘米级精度的地面真实数据，经十多种开源多传感器融合系统验证，数据质量优越。

Conclusion: i2Nav-Robot为UGV导航与建图研究提供了高质量、多样化的多传感器数据集，填补了现有空白。

Abstract: Accurate and reliable navigation is crucial for autonomous unmanned ground
vehicle (UGV). However, current UGV datasets fall short in meeting the demands
for advancing navigation and mapping techniques due to limitations in sensor
configuration, time synchronization, ground truth, and scenario diversity. To
address these challenges, we present i2Nav-Robot, a large-scale dataset
designed for multi-sensor fusion navigation and mapping in indoor-outdoor
environments. We integrate multi-modal sensors, including the newest front-view
and 360-degree solid-state LiDARs, 4-dimensional (4D) radar, stereo cameras,
odometer, global navigation satellite system (GNSS) receiver, and inertial
measurement units (IMU) on an omnidirectional wheeled robot. Accurate
timestamps are obtained through both online hardware synchronization and
offline calibration for all sensors. The dataset comprises ten larger-scale
sequences covering diverse UGV operating scenarios, such as outdoor streets,
and indoor parking lots, with a total length of about 17060 meters.
High-frequency ground truth, with centimeter-level accuracy for position, is
derived from post-processing integrated navigation methods using a
navigation-grade IMU. The proposed i2Nav-Robot dataset is evaluated by more
than ten open-sourced multi-sensor fusion systems, and it has proven to have
superior data quality.

</details>


### [125] [Relative Position Matters: Trajectory Prediction and Planning with Polar Representation](https://arxiv.org/abs/2508.11492)
*Bozhou Zhang,Nan Song,Bingzhao Gao,Li Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种基于极坐标的轨迹预测与规划方法Polaris，解决了传统笛卡尔坐标系在建模动态环境中车辆与周围元素关系时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在笛卡尔坐标系中编码地图和车辆位置，但未能有效捕捉不同交通元素基于距离和方向的动态影响。

Method: 采用极坐标系表示位置（半径和角度），提出Polaris方法，通过专用模块建模距离和方向变化，捕捉相对关系。

Result: 在Argoverse 2和nuPlan基准测试中，Polaris实现了最先进的性能。

Conclusion: 极坐标表示能更直观地建模空间变化和相对关系，显著提升轨迹预测与规划的效果。

Abstract: Trajectory prediction and planning in autonomous driving are highly
challenging due to the complexity of predicting surrounding agents' movements
and planning the ego agent's actions in dynamic environments. Existing methods
encode map and agent positions and decode future trajectories in Cartesian
coordinates. However, modeling the relationships between the ego vehicle and
surrounding traffic elements in Cartesian space can be suboptimal, as it does
not naturally capture the varying influence of different elements based on
their relative distances and directions. To address this limitation, we adopt
the Polar coordinate system, where positions are represented by radius and
angle. This representation provides a more intuitive and effective way to model
spatial changes and relative relationships, especially in terms of distance and
directional influence. Based on this insight, we propose Polaris, a novel
method that operates entirely in Polar coordinates, distinguishing itself from
conventional Cartesian-based approaches. By leveraging the Polar
representation, this method explicitly models distance and direction variations
and captures relative relationships through dedicated encoding and refinement
modules, enabling more structured and spatially aware trajectory prediction and
planning. Extensive experiments on the challenging prediction (Argoverse 2) and
planning benchmarks (nuPlan) demonstrate that Polaris achieves state-of-the-art
performance.

</details>


### [126] [Swarm-in-Blocks: Simplifying Drone Swarm Programming with Block-Based Language](https://arxiv.org/abs/2508.11498)
*Agnes Bressan de Almeida,Joao Aires Correa Fernandes Marsicano*

Main category: cs.RO

TL;DR: Swarm in Blocks 2.0是一个基于块编程的高阶接口，简化了无人机群编程，适用于教育和实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着无人机群在配送、农业和监控等领域的应用增加，管理复杂性也随之上升，尤其是对初学者而言。Atena团队开发此工具，旨在降低ROS和编程知识门槛。

Method: 基于Clover平台，通过组装代码块实现循环和条件结构等功能。

Result: Swarm in Blocks 2.0进一步优化了平台，使其更用户友好，同时扩展了编程教育机会。

Conclusion: 该工具成功简化了无人机群管理，并为编程教育提供了新途径。

Abstract: Swarm in Blocks, originally developed for CopterHack 2022, is a high-level
interface that simplifies drone swarm programming using a block-based language.
Building on the Clover platform, this tool enables users to create
functionalities like loops and conditional structures by assembling code
blocks. In 2023, we introduced Swarm in Blocks 2.0, further refining the
platform to address the complexities of swarm management in a user-friendly
way. As drone swarm applications grow in areas like delivery, agriculture, and
surveillance, the challenge of managing them, especially for beginners, has
also increased. The Atena team developed this interface to make swarm handling
accessible without requiring extensive knowledge of ROS or programming. The
block-based approach not only simplifies swarm control but also expands
educational opportunities in programming.

</details>


### [127] [Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media](https://arxiv.org/abs/2508.11503)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 论文提出了一种从仿真到现实的框架，用于开发可靠的自主导航控制器，通过大规模并行仿真训练强化学习代理，并在真实环境中验证其性能。


<details>
  <summary>Details</summary>
Motivation: 解决在遥远行星表面非结构化地形中可靠自主导航的问题，克服仿真到现实的差距，特别是轮子与颗粒介质交互的复杂动力学。

Method: 利用大规模并行仿真训练强化学习代理，生成随机化物理环境，并将策略零样本转移到真实轮式漫游车。

Result: 实验表明，通过程序多样性训练的代理在零样本性能上优于静态场景训练的代理，同时分析了高保真粒子物理微调的权衡。

Conclusion: 研究为创建可靠的基于学习的导航系统提供了验证的工作流程，是部署自主机器人于太空探索的关键一步。

Abstract: Reliable autonomous navigation across the unstructured terrains of distant
planetary surfaces is a critical enabler for future space exploration. However,
the deployment of learning-based controllers is hindered by the inherent
sim-to-real gap, particularly for the complex dynamics of wheel interactions
with granular media. This work presents a complete sim-to-real framework for
developing and validating robust control policies for dynamic waypoint tracking
on such challenging surfaces. We leverage massively parallel simulation to
train reinforcement learning agents across a vast distribution of procedurally
generated environments with randomized physics. These policies are then
transferred zero-shot to a physical wheeled rover operating in a lunar-analogue
facility. Our experiments systematically compare multiple reinforcement
learning algorithms and action smoothing filters to identify the most effective
combinations for real-world deployment. Crucially, we provide strong empirical
evidence that agents trained with procedural diversity achieve superior
zero-shot performance compared to those trained on static scenarios. We also
analyze the trade-offs of fine-tuning with high-fidelity particle physics,
which offers minor gains in low-speed precision at a significant computational
cost. Together, these contributions establish a validated workflow for creating
reliable learning-based navigation systems, marking a critical step towards
deploying autonomous robots in the final frontier.

</details>


### [128] [MultiPark: Multimodal Parking Transformer with Next-Segment Prediction](https://arxiv.org/abs/2508.11537)
*Han Zheng,Zikang Zhou,Guli Zhang,Zhepei Wang,Kaixuan Wang,Peiliang Li,Shaojie Shen,Ming Yang,Tong Qin*

Main category: cs.RO

TL;DR: MultiPark是一种基于自回归变换器的多模态停车方法，解决了现有模仿学习在停车行为中的多模态性和因果混淆问题。


<details>
  <summary>Details</summary>
Motivation: 在高度受限空间中准确安全停车是一个关键挑战，现有模仿学习方法未能捕捉停车行为的多模态性且存在因果混淆问题。

Method: 提出MultiPark，采用数据高效的下一段预测范式处理急转弯路径，设计可学习的停车查询分解为齿轮、纵向和横向组件，并行解码多种停车行为。

Result: 在真实数据集上评估，MultiPark实现了最先进的性能，并在实际车辆上验证了其鲁棒性。

Conclusion: MultiPark通过多模态设计和因果混淆缓解，显著提升了复杂停车场景下的性能。

Abstract: Parking accurately and safely in highly constrained spaces remains a critical
challenge. Unlike structured driving environments, parking requires executing
complex maneuvers such as frequent gear shifts and steering saturation. Recent
attempts to employ imitation learning (IL) for parking have achieved promising
results. However, existing works ignore the multimodal nature of parking
behavior in lane-free open space, failing to derive multiple plausible
solutions under the same situation. Notably, IL-based methods encompass
inherent causal confusion, so enabling a neural network to generalize across
diverse parking scenarios is particularly difficult. To address these
challenges, we propose MultiPark, an autoregressive transformer for multimodal
parking. To handle paths filled with abrupt turning points, we introduce a
data-efficient next-segment prediction paradigm, enabling spatial
generalization and temporal extrapolation. Furthermore, we design learnable
parking queries factorized into gear, longitudinal, and lateral components,
parallelly decoding diverse parking behaviors. To mitigate causal confusion in
IL, our method employs target-centric pose and ego-centric collision as
outcome-oriented loss across all modalities beyond pure imitation loss.
Evaluations on real-world datasets demonstrate that MultiPark achieves
state-of-the-art performance across various scenarios. We deploy MultiPark on a
production vehicle, further confirming our approach's robustness in real-world
parking environments.

</details>


### [129] [Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks](https://arxiv.org/abs/2508.11584)
*Jakub Łucki,Jonathan Becktor,Georgios Georgakis,Robert Royce,Shehryar Khattak*

Main category: cs.RO

TL;DR: VPEngine是一个模块化框架，通过共享基础模型提取的图像表示，实现多任务并行处理，减少计算冗余，提高GPU利用率，并在NVIDIA Jetson Orin AGX上实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的机器人平台上部署多个机器学习模型会导致计算冗余、内存占用大和集成复杂，VPEngine旨在解决这些问题。

Method: VPEngine采用共享基础模型（如DINOv2）提取图像表示，并通过并行任务专用模型头实现多任务处理，结合CUDA MPS优化GPU利用率。

Result: 在深度、目标检测和语义分割任务中，VPEngine比顺序执行快3倍，并保持恒定内存占用，实时性能达50 Hz以上。

Conclusion: VPEngine通过高效共享计算资源，为机器人视觉多任务处理提供了可扩展且易用的解决方案。

Abstract: Deploying multiple machine learning models on resource-constrained robotic
platforms for different perception tasks often results in redundant
computations, large memory footprints, and complex integration challenges. In
response, this work presents Visual Perception Engine (VPEngine), a modular
framework designed to enable efficient GPU usage for visual multitasking while
maintaining extensibility and developer accessibility. Our framework
architecture leverages a shared foundation model backbone that extracts image
representations, which are efficiently shared, without any unnecessary GPU-CPU
memory transfers, across multiple specialized task-specific model heads running
in parallel. This design eliminates the computational redundancy inherent in
feature extraction component when deploying traditional sequential models while
enabling dynamic task prioritization based on application demands. We
demonstrate our framework's capabilities through an example implementation
using DINOv2 as the foundation model with multiple task (depth, object
detection and semantic segmentation) heads, achieving up to 3x speedup compared
to sequential execution. Building on CUDA Multi-Process Service (MPS), VPEngine
offers efficient GPU utilization and maintains a constant memory footprint
while allowing per-task inference frequencies to be adjusted dynamically during
runtime. The framework is written in Python and is open source with ROS2 C++
(Humble) bindings for ease of use by the robotics community across diverse
robotic platforms. Our example implementation demonstrates end-to-end real-time
performance at $\geq$50 Hz on NVIDIA Jetson Orin AGX for TensorRT optimized
models.

</details>


### [130] [Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation](https://arxiv.org/abs/2508.11588)
*Benjamin Walt,Jordan Westphal,Girish Krishnan*

Main category: cs.RO

TL;DR: 论文研究了农业抓取状态的分类方法，通过集成多种传感器并比较两种分类模型，发现随机森林模型在实验室和实际环境中表现优异，显著提升了抓取状态的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 农业环境的复杂性和果实附着特性要求精确的抓取状态识别，以提高收获效率和可靠性。

Method: 研究集成了IMU、红外反射、张力、触觉传感器和RGB相机，并比较了随机森林和LSTM模型的性能。

Result: 随机森林模型在实验室和实际测试中实现了100%的抓取状态识别准确率，IMU和张力传感器组合效果最佳。

Conclusion: 该研究为农业收获提供了高效的抓取状态分类方法，显著提升了操作的可靠性和效率。

Abstract: Effective and efficient agricultural manipulation and harvesting depend on
accurately understanding the current state of the grasp. The agricultural
environment presents unique challenges due to its complexity, clutter, and
occlusion. Additionally, fruit is physically attached to the plant, requiring
precise separation during harvesting. Selecting appropriate sensors and
modeling techniques is critical for obtaining reliable feedback and correctly
identifying grasp states. This work investigates a set of key sensors, namely
inertial measurement units (IMUs), infrared (IR) reflectance, tension, tactile
sensors, and RGB cameras, integrated into a compliant gripper to classify grasp
states. We evaluate the individual contribution of each sensor and compare the
performance of two widely used classification models: Random Forest and Long
Short-Term Memory (LSTM) networks. Our results demonstrate that a Random Forest
classifier, trained in a controlled lab environment and tested on real cherry
tomato plants, achieved 100% accuracy in identifying slip, grasp failure, and
successful picks, marking a substantial improvement over baseline performance.
Furthermore, we identify a minimal viable sensor combination, namely IMU and
tension sensors that effectively classifies grasp states. This classifier
enables the planning of corrective actions based on real-time feedback, thereby
enhancing the efficiency and reliability of fruit harvesting operations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [131] [A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification](https://arxiv.org/abs/2508.10926)
*DongSeong-Yoon*

Main category: cs.LG

TL;DR: 论文提出了一种基于合作博弈的多准则投票集成方法，以克服现有方法仅考虑单一评价标准的局限性，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有投票集成方法仅考虑单一评价标准，无法充分利用分类器的多种先验信息，限制了性能提升。

Method: 通过合作博弈在多准则情境下进行决策，同时考虑分类器的多种先验信息，实现合理的权重分配。

Result: 在Open-ML-CC18数据集上的实验表明，该方法优于其他权重分配方法。

Conclusion: 提出的多准则投票集成方法能更全面地利用信息，显著提升模型性能。

Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in
many fields, but there are several limitations that need to be overcome,
including overfitting/underfitting, class imbalance, and the limitations of
representation (hypothesis space) due to the characteristics of different
models. As a method to overcome these problems, ensemble, commonly known as
model combining, is being extensively used in the field of machine learning.
Among ensemble learning methods, voting ensembles have been studied with
various weighting methods, showing performance improvements. However, the
existing methods that reflect the pre-information of classifiers in weights
consider only one evaluation criterion, which limits the reflection of various
information that should be considered in a model realistically. Therefore, this
paper proposes a method of making decisions considering various information
through cooperative games in multi-criteria situations. Using this method,
various types of information known beforehand in classifiers can be
simultaneously considered and reflected, leading to appropriate weight
distribution and performance improvement. The machine learning algorithms were
applied to the Open-ML-CC18 dataset and compared with existing ensemble
weighting methods. The experimental results showed superior performance
compared to other weighting methods.

</details>


### [132] [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)
*Shruthan Radhakrishna,Soham Parikh,Gopal Sarda,Anil Turkkan,Quaizar Vohra,Raymond Li,Dhruv Jhamb,Kelechi Ogueji,Aanjaneya Shukla,Oluwanifemi Bamgbose,Toby Liang,Luke Kumar,Oleksiy Ostapenko,Shiva Krishna Reddy Malay,Aman Tiwari,Tara Bogavelli,Vikas Yadav,Jash Mehta,Saloni Mittal,Akshay Kalkunte,Pulkit Pattnaik,Khalil Slimi,Anirudh Sreeram,Jishnu Nair,Akintunde Oladipo,Shashank Maiya,Khyati Mahajan,Rishabh Maheshwary,Masoud Hashemi,Sai Rajeswar Mudumba,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sebastien Paquet,Sagar Davasam,Srinivas Sunkara*

Main category: cs.LG

TL;DR: Apriel-Nemotron-15B-Thinker是一个15B参数的模型，性能媲美32B参数模型，但内存占用减半。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在内存和计算成本上的限制，使其更适合企业应用。

Method: 采用四阶段训练流程：基础模型扩展、持续预训练、监督微调和GRPO强化学习。

Result: 在多种基准测试中表现与32B参数模型相当或更好，且内存占用仅为一半。

Conclusion: Apriel-Nemotron-15B-Thinker在性能和效率上取得了平衡，适合企业场景。

Abstract: While large language models (LLMs) have achieved remarkable reasoning
capabilities across domains like code, math and other enterprise tasks, their
significant memory and computational costs often preclude their use in
practical enterprise settings. To this end, we introduce
Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow
Apriel SLM series that achieves performance against medium sized
state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while
maintaining only half the memory footprint of those alternatives.
Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline
including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised
Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive
evaluations across a diverse suite of benchmarks consistently demonstrate that
our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its
32-billion parameter counterparts, despite being less than half their size.

</details>


### [133] [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)
*Gyutae Oh,Jitae Shin*

Main category: cs.LG

TL;DR: 论文提出了一种基于提示的持续学习方法（PCL），用于解决医疗领域数据共享受限的问题，通过统一提示池和最小扩展策略，显著提升了分类准确率和F1分数。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的数据共享受到伦理、社会和制度限制，传统集中式学习难以实现，而持续学习在医疗领域的应用尚未充分探索。

Method: 采用基于提示的持续学习方法，通过扩展和冻结部分提示池，结合新的正则化项，平衡知识保留与适应能力。

Result: 在三个糖尿病视网膜病变数据集上，PCL方法比现有技术分类准确率提高至少10%，F1分数提高9分，同时降低推理成本。

Conclusion: PCL方法为医疗AI的可持续发展提供了新思路，有望推动实时诊断、患者监测和远程医疗应用。

Abstract: Modern AI models achieve state-of-the-art performance with large-scale,
high-quality datasets; however, ethical, social, and institutional constraints
in the medical domain severely restrict data sharing, rendering centralized
learning nearly impossible. Each institution must incrementally update models
using only local data. Traditional training overfits new samples and suffers
from catastrophic forgetting, losing previously acquired knowledge. Medical
data distributions also shift due to varying diagnostic equipment and
demographics. Although continual learning (CL) has advanced, most methods
address natural images, leaving medical-domain-specific CL underexplored. We
propose a prompt-based continual learning (PCL) approach featuring a unified
prompt pool with a minimal expansion strategy: by expanding and freezing a
subset of prompts, our method reduces computational overhead, and a novel
regularization term balances retention and adaptation. Experiments on three
diabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy
Detection show our model improves final classification accuracy by at least 10%
and F1-score by 9 points over state-of-the-art approaches while lowering
inference cost. We anticipate this study will drive sustainable medical AI
advances, enabling real-time diagnosis, patient monitoring, and telemedicine
applications in distributed healthcare. Code will be released upon acceptance

</details>


### [134] [Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis](https://arxiv.org/abs/2508.10967)
*Xinyi Li,Sai Wang,Yutian Lin,Yu Wu,Yi Yang*

Main category: cs.LG

TL;DR: Retro-Expert是一个可解释的逆合成框架，结合大语言模型和专用模型，通过强化学习生成基于化学逻辑的解释，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有逆合成模型依赖静态模式匹配，缺乏逻辑决策能力，导致黑箱决策。

Method: Retro-Expert通过专用模型浅层推理构建决策空间，大语言模型关键推理生成预测和解释路径，强化学习优化决策策略。

Result: 实验表明Retro-Expert在多项指标上优于现有模型，并提供专家认可的解释。

Conclusion: Retro-Expert填补了AI预测与化学实际应用之间的鸿沟，具有可解释性和高性能。

Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a
given product molecule, which is a fundamental task in chemical synthesis.
However, existing models rely on static pattern-matching paradigm, which limits
their ability to perform effective logic decision-making, leading to black-box
decision-making. Building on this, we propose Retro-Expert, an interpretable
retrosynthesis framework that performs collaborative reasoning by combining the
complementary reasoning strengths of Large Language Models and specialized
models via reinforcement learning. It outputs natural language explanations
grounded in chemical logic through three components: (1) specialized models
perform shallow reasoning to construct high-quality chemical decision space,
(2) LLM-driven critical reasoning to generate predictions and corresponding
interpretable reasoning path, and (3) reinforcement learning optimizing
interpretable decision policy. Experiments show that Retro-Expert not only
surpasses both LLM-based and specialized models across different metrics but
also provides expert-aligned explanations that bridge the gap between AI
predictions and actionable chemical insights.

</details>


### [135] [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)
*Pratyush Maini,Vineeth Dorna,Parth Doshi,Aldo Carranza,Fan Pan,Jack Urbanek,Paul Burstein,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Charvi Bannur,Christina Baek,Darren Teh,David Schwab,Haakon Mongstad,Haoli Yin,Josh Wills,Kaleigh Mentzer,Luke Merrick,Ricardo Monti,Rishabh Adiga,Siddharth Joshi,Spandan Das,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: BeyondWeb是一个合成数据生成框架，显著提升预训练性能，优于现有合成数据集，并提供关于合成数据优化的关键见解。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练中数据量的扩展效果有限，合成数据成为提升性能的新方向，但其质量影响因素尚不明确。

Method: 开发BeyondWeb框架，生成高质量合成数据，并与现有数据集（如Cosmopedia和Nemotron-Synth）进行对比。

Result: BeyondWeb在14项基准测试中平均优于Cosmopedia和Nemotron-Synth，训练速度更快，小模型表现优于大模型。

Conclusion: 生成高质量合成数据需多因素联合优化，BeyondWeb展示了其潜力，但需科学方法和实践经验支持。

Abstract: Recent advances in large language model (LLM) pretraining have shown that
simply scaling data quantity eventually leads to diminishing returns, hitting a
data wall. In response, the use of synthetic data for pretraining has emerged
as a promising paradigm for pushing the frontier of performance. Despite this,
the factors affecting synthetic data quality remain poorly understood. In this
work, we introduce BeyondWeb, a synthetic data generation framework that
produces high-quality synthetic data for pretraining. BeyondWeb significantly
extends the capabilities of traditional web-scale datasets, outperforming
state-of-the-art synthetic pretraining datasets such as Cosmopedia and
Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1
percentage points (pp) and 2.6pp, respectively, when averaged across a suite of
14 benchmark evaluations. It delivers up to 7.7x faster training than open web
data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for
180B tokens on BeyondWeb outperforms an 8B model trained for the same token
budget on Cosmopedia. We also present several insights from BeyondWeb on
synthetic data for pretraining: what drives its benefits, which data to
rephrase and how, and the impact of model size and family on data quality.
Overall, our work shows that there's no silver bullet for generating
high-quality synthetic pretraining data. The best outcomes require jointly
optimizing many factors, a challenging task that requires rigorous science and
practical expertise. Naive approaches can yield modest improvements,
potentially at great cost, while well-executed methods can yield transformative
improvements, as exemplified by BeyondWeb.

</details>


### [136] [Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.10993)
*Basile Lewandowski,Robert Birke,Lydia Y. Chen*

Main category: cs.LG

TL;DR: 本文提出了首个模型选择框架M&C，帮助用户高效选择预训练的文本到图像（T2I）模型，而无需对所有模型进行微调。


<details>
  <summary>Details</summary>
Motivation: 公共预训练T2I模型促进了模型的民主化，但用户面临如何选择最适合目标数据域的模型的挑战。

Method: M&C框架基于匹配图，包含模型和数据集节点，以及模型-数据和数据-数据对的边，通过图嵌入特征预测最佳微调模型。

Result: 在10个T2I模型和32个数据集上的评估显示，M&C在61.3%的情况下成功预测最佳模型，其余情况下选择接近最优模型。

Conclusion: M&C为预训练T2I模型的模型选择提供了有效解决方案，显著提升了效率。

Abstract: Text-to-image (T2I) models based on diffusion and transformer architectures
advance rapidly. They are often pretrained on large corpora, and openly shared
on a model platform, such as HuggingFace. Users can then build up AI
applications, e.g., generating media contents, by adopting pretrained T2I
models and fine-tuning them on the target dataset. While public pretrained T2I
models facilitate the democratization of the models, users face a new
challenge: which model can be best fine-tuned based on the target data domain?
Model selection is well addressed in classification tasks, but little is known
in (pretrained) T2I models and their performance indication on the target
domain. In this paper, we propose the first model selection framework, M&C,
which enables users to efficiently choose a pretrained T2I model from a model
platform without exhaustively fine-tuning them all on the target dataset. The
core of M&C is a matching graph, which consists of: (i) nodes of available
models and profiled datasets, and (ii) edges of model-data and data-data pairs
capturing the fine-tuning performance and data similarity, respectively. We
then build a model that, based on the inputs of model/data feature, and,
critically, the graph embedding feature, extracted from the matching graph,
predicts the model achieving the best quality after fine-tuning for the target
domain. We evaluate M&C on choosing across ten T2I models for 32 datasets
against three baselines. Our results show that M&C successfully predicts the
best model for fine-tuning in 61.3% of the cases and a closely performing model
for the rest.

</details>


### [137] [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)
*Qingbin Li,Rongkun Xue,Jie Wang,Ming Zhou,Zhi Li,Xiaofeng Ji,Yongqi Wang,Miao Liu,Zheming Yang,Minghui Qiu,Jing Yang*

Main category: cs.LG

TL;DR: CURE框架通过两阶段方法（高熵关键令牌再生和静态初始状态采样）解决RLVR中的熵崩溃问题，提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR中静态初始状态采样导致的低多样性和熵崩溃问题，以增强模型的持续性能提升。

Method: 提出CURE框架，第一阶段通过高熵关键令牌再生优化轨迹，第二阶段继续使用静态初始状态采样强化利用。

Result: 在Qwen-2.5-Math-7B上，CURE在六个数学基准测试中性能提升5%，同时保持高熵水平。

Conclusion: CURE通过平衡探索与利用，显著提升了RLVR的性能和熵稳定性。

Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/CURE-Project/CURE.

</details>


### [138] [Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis](https://arxiv.org/abs/2508.11020)
*Aakash Kumar,Emanuele Natale*

Main category: cs.LG

TL;DR: 论文通过量化设置扩展了强彩票假设（SLTH），证明了在有限精度网络中，目标离散神经网络可以被精确表示，并给出了初始网络过参数化的最优界限。


<details>
  <summary>Details</summary>
Motivation: 量化是提高神经网络效率的关键技术，但理论理解有限。现有研究主要在连续设置下探讨SLTH，无法直接应用于量化设置。

Method: 基于Borgs等人的数分割问题研究，推导了量化设置下的随机子集和问题新理论结果，并扩展SLTH框架到有限精度网络。

Result: 在量化设置下，目标离散神经网络可以被精确表示，并证明了初始网络过参数化的最优界限。

Conclusion: 研究填补了量化神经网络理论理解的空白，为高效网络设计提供了理论支持。

Abstract: Quantization is an essential technique for making neural networks more
efficient, yet our theoretical understanding of it remains limited. Previous
works demonstrated that extremely low-precision networks, such as binary
networks, can be constructed by pruning large, randomly-initialized networks,
and showed that the ratio between the size of the original and the pruned
networks is at most polylogarithmic.
  The specific pruning method they employed inspired a line of theoretical work
known as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights
from the Random Subset Sum Problem. However, these results primarily address
the continuous setting and cannot be applied to extend SLTH results to the
quantized setting.
  In this work, we build on foundational results by Borgs et al. on the Number
Partitioning Problem to derive new theoretical results for the Random Subset
Sum Problem in a quantized setting.
  Using these results, we then extend the SLTH framework to finite-precision
networks. While prior work on SLTH showed that pruning allows approximation of
a certain class of neural networks, we demonstrate that, in the quantized
setting, the analogous class of target discrete neural networks can be
represented exactly, and we prove optimal bounds on the necessary
overparameterization of the initial network as a function of the precision of
the target network.

</details>


### [139] [Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks](https://arxiv.org/abs/2508.11025)
*Laura Lützow,Michael Eichelbeck,Mykel J. Kochenderfer,Matthias Althoff*

Main category: cs.LG

TL;DR: 论文提出了一种名为zono-conformal prediction的新方法，通过构建预测zonotopes来解决传统方法计算成本高和数据需求大的问题，并在多维度输出中捕捉依赖关系。


<details>
  <summary>Details</summary>
Motivation: 传统方法计算成本高、数据需求大，且无法有效捕捉多维度输出的依赖关系。

Method: 引入zono-conformal prediction，通过线性程序构建预测zonotopes，适用于非线性基础预测器（如神经网络）。

Result: zono-conformal predictors比传统方法更高效且保守性更低，同时在测试数据上实现了相似的覆盖率。

Conclusion: zono-conformal prediction是一种高效且数据利用率高的不确定性量化方法，适用于回归和分类任务。

Abstract: Conformal prediction is a popular uncertainty quantification method that
augments a base predictor with prediction sets with statistically valid
coverage guarantees. However, current methods are often computationally
expensive and data-intensive, as they require constructing an uncertainty model
before calibration. Moreover, existing approaches typically represent the
prediction sets with intervals, which limits their ability to capture
dependencies in multi-dimensional outputs. We address these limitations by
introducing zono-conformal prediction, a novel approach inspired by interval
predictor models and reachset-conformant identification that constructs
prediction zonotopes with assured coverage. By placing zonotopic uncertainty
sets directly into the model of the base predictor, zono-conformal predictors
can be identified via a single, data-efficient linear program. While we can
apply zono-conformal prediction to arbitrary nonlinear base predictors, we
focus on feed-forward neural networks in this work. Aside from regression
tasks, we also construct optimal zono-conformal predictors in classification
settings where the output of an uncertain predictor is a set of possible
classes. We provide probabilistic coverage guarantees and present methods for
detecting outliers in the identification data. In extensive numerical
experiments, we show that zono-conformal predictors are less conservative than
interval predictor models and standard conformal prediction methods, while
achieving a similar coverage over the test data.

</details>


### [140] [Learning with Confidence](https://arxiv.org/abs/2508.11037)
*Oliver Ethan Richardson*

Main category: cs.LG

TL;DR: 本文探讨了学习或更新信念中的“信心”概念，区分了它与概率或似然的差异，并提出了两种测量信心的标准方法。


<details>
  <summary>Details</summary>
Motivation: 研究信心的概念及其在信念更新中的作用，以澄清它与概率或似然的混淆。

Method: 通过形式化公理化定义信心学习，提出两种连续测量方法，并证明其普适性。在附加假设下，进一步用向量场和损失函数表示信心学习。

Result: 证明了信心可以用连续方法表示，并推导出基于向量场和损失函数的紧凑表示。

Conclusion: 信心是信念更新中的独立概念，贝叶斯规则是其特例。

Abstract: We characterize a notion of confidence that arises in learning or updating
beliefs: the amount of trust one has in incoming information and its impact on
the belief state. This learner's confidence can be used alongside (and is
easily mistaken for) probability or likelihood, but it is fundamentally a
different concept -- one that captures many familiar concepts in the
literature, including learning rates and number of training epochs, Shafer's
weight of evidence, and Kalman gain. We formally axiomatize what it means to
learn with confidence, give two canonical ways of measuring confidence on a
continuum, and prove that confidence can always be represented in this way.
Under additional assumptions, we derive more compact representations of
confidence-based learning in terms of vector fields and loss functions. These
representations induce an extended language of compound "parallel"
observations. We characterize Bayes Rule as the special case of an optimizing
learner whose loss representation is a linear expectation.

</details>


### [141] [Conditional Independence Estimates for the Generalized Nonparanormal](https://arxiv.org/abs/2508.11050)
*Ujas Shah,Manuel Lladser,Rebecca Morrison*

Main category: cs.LG

TL;DR: 对于非高斯分布，本文提出了一种广义非正态分布（广义非正态正态），并证明其精度矩阵仍能推断条件独立结构。同时提供了一种高效算法来恢复这种结构。


<details>
  <summary>Details</summary>
Motivation: 研究非高斯分布中如何通过精度矩阵推断变量间的条件独立结构，扩展高斯分布的理论。

Method: 提出广义非正态正态分布，并开发一种计算高效的算法，利用精度矩阵恢复条件独立结构。

Result: 通过合成实验和真实数据验证了算法的有效性。

Conclusion: 广义非正态正态分布为分析非高斯数据的条件独立结构提供了新工具，算法高效且实用。

Abstract: For general non-Gaussian distributions, the covariance and precision matrices
do not encode the independence structure of the variables, as they do for the
multivariate Gaussian. This paper builds on previous work to show that for a
class of non-Gaussian distributions -- those derived from diagonal
transformations of a Gaussian -- information about the conditional independence
structure can still be inferred from the precision matrix, provided the data
meet certain criteria, analogous to the Gaussian case. We call such
transformations of the Gaussian as the generalized nonparanormal. The functions
that define these transformations are, in a broad sense, arbitrary. We also
provide a simple and computationally efficient algorithm that leverages this
theory to recover conditional independence structure from the generalized
nonparanormal data. The effectiveness of the proposed algorithm is demonstrated
via synthetic experiments and applications to real-world data.

</details>


### [142] [SHLIME: Foiling adversarial attacks fooling SHAP and LIME](https://arxiv.org/abs/2508.11053)
*Sam Chauhan,Estelle Duguet,Karthik Ramakrishnan,Hugh Van Deventer,Jack Kruger,Ranjan Subbaraman*

Main category: cs.LG

TL;DR: 该论文研究了LIME和SHAP等事后解释方法在对抗性操纵下的脆弱性，并提出了一种模块化测试框架来评估增强和集成方法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 揭示LIME和SHAP方法可能掩盖模型偏见的漏洞，并探索提高其鲁棒性的策略。

Method: 复制COMPAS实验验证基线，引入模块化测试框架评估集成解释方法在不同分类器上的表现。

Result: 发现某些集成配置能显著提高偏见检测能力。

Conclusion: 这些改进方法有助于提升高风险机器学习系统的透明度。

Abstract: Post hoc explanation methods, such as LIME and SHAP, provide interpretable
insights into black-box classifiers and are increasingly used to assess model
biases and generalizability. However, these methods are vulnerable to
adversarial manipulation, potentially concealing harmful biases. Building on
the work of Slack et al. (2020), we investigate the susceptibility of LIME and
SHAP to biased models and evaluate strategies for improving robustness. We
first replicate the original COMPAS experiment to validate prior findings and
establish a baseline. We then introduce a modular testing framework enabling
systematic evaluation of augmented and ensemble explanation approaches across
classifiers of varying performance. Using this framework, we assess multiple
LIME/SHAP ensemble configurations on out-of-distribution models, comparing
their resistance to bias concealment against the original methods. Our results
identify configurations that substantially improve bias detection, highlighting
their potential for enhancing transparency in the deployment of high-stakes
machine learning systems.

</details>


### [143] [Abundance-Aware Set Transformer for Microbiome Sample Embedding](https://arxiv.org/abs/2508.11075)
*Hyunwoo Yoo,Gail Rosen*

Main category: cs.LG

TL;DR: 提出了一种基于丰度感知的Set Transformer方法，用于构建微生物组样本的固定大小嵌入表示，优于传统平均池化和未加权方法。


<details>
  <summary>Details</summary>
Motivation: 现有微生物组样本表示方法多依赖简单的序列嵌入平均，忽略了分类群丰度的生物学重要性。

Method: 通过按相对丰度加权序列嵌入，提出丰度感知的Set Transformer变体，不改变模型架构，利用自注意力聚合。

Result: 在真实微生物组分类任务中表现优于平均池化和未加权Set Transformer，某些情况下达到完美性能。

Conclusion: 丰度感知聚合方法为微生物组表示提供了更稳健且生物学合理的解决方案。

Abstract: Microbiome sample representation to input into LLMs is essential for
downstream tasks such as phenotype prediction and environmental classification.
While prior studies have explored embedding-based representations of each
microbiome sample, most rely on simple averaging over sequence embeddings,
often overlooking the biological importance of taxa abundance. In this work, we
propose an abundance-aware variant of the Set Transformer to construct
fixed-size sample-level embeddings by weighting sequence embeddings according
to their relative abundance. Without modifying the model architecture, we
replicate embedding vectors proportional to their abundance and apply
self-attention-based aggregation. Our method outperforms average pooling and
unweighted Set Transformers on real-world microbiome classification tasks,
achieving perfect performance in some cases. These results demonstrate the
utility of abundance-aware aggregation for robust and biologically informed
microbiome representation. To the best of our knowledge, this is one of the
first approaches to integrate sequence-level abundance into Transformer-based
sample embeddings.

</details>


### [144] [Robust Convolution Neural ODEs via Contractivity-promoting regularization](https://arxiv.org/abs/2508.11432)
*Muhammad Zakwan,Liang Xu,Giancarlo Ferrari-Trecate*

Main category: cs.LG

TL;DR: 论文提出了一种通过收缩理论提升卷积神经常微分方程（NODEs）鲁棒性的方法，通过正则化项或权重正则化实现，并在MNIST和FashionMNIST数据集上验证了效果。


<details>
  <summary>Details</summary>
Motivation: 神经网络对输入噪声和对抗攻击脆弱，需要提升其鲁棒性。

Method: 利用收缩理论，通过正则化项或权重正则化使NODEs具有收缩性，从而增强鲁棒性。

Result: 在MNIST和FashionMNIST数据集上，该方法有效提升了模型对噪声和攻击的鲁棒性。

Conclusion: 通过收缩理论和正则化方法，可以显著提升NODEs的鲁棒性。

Abstract: Neural networks can be fragile to input noise and adversarial attacks.
  In this work, we consider Convolutional Neural Ordinary Differential
Equations (NODEs), a family of continuous-depth neural networks represented by
dynamical systems, and propose to use contraction theory to improve their
robustness.
  For a contractive dynamical system two trajectories starting from different
initial conditions converge to each other exponentially fast.
  Contractive Convolutional NODEs can enjoy increased robustness as slight
perturbations of the features do not cause a significant change in the output.
  Contractivity can be induced during training by using a regularization term
involving the Jacobian of the system dynamics.
  To reduce the computational burden, we show that it can also be promoted
using carefully selected weight regularization terms for a class of NODEs with
slope-restricted activation functions.
  The performance of the proposed regularizers is illustrated through benchmark
image classification tasks on MNIST and FashionMNIST datasets, where images are
corrupted by different kinds of noise and attacks.

</details>


### [145] [A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora](https://arxiv.org/abs/2508.11084)
*Thanasis Schoinas,Ghulam Qadir*

Main category: cs.LG

TL;DR: 本文提出了一种针对即时消息的分类方法，通过数据管理和特征选择结合逻辑回归，提供经济高效的预测编码解决方案。


<details>
  <summary>Details</summary>
Motivation: 即时消息因其非正式性和短小篇幅，给文档分类带来挑战，需经济高效的解决方案。

Method: 采用数据管理工作流将消息分组为日聊，结合特征选择和逻辑回归分类器，并通过降维提升性能。

Result: 在Instant Bloomberg数据集上测试，方法表现良好，同时展示了成本节约效果。

Conclusion: 该方法为即时消息分类提供了经济高效的解决方案，并通过降维优化了性能。

Abstract: Predictive coding, the term used in the legal industry for document
classification using machine learning, presents additional challenges when the
dataset comprises instant messages, due to their informal nature and smaller
sizes. In this paper, we exploit a data management workflow to group messages
into day chats, followed by feature selection and a logistic regression
classifier to provide an economically feasible predictive coding solution. We
also improve the solution's baseline model performance by dimensionality
reduction, with focus on quantitative features. We test our methodology on an
Instant Bloomberg dataset, rich in quantitative information. In parallel, we
provide an example of the cost savings of our approach.

</details>


### [146] [Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation](https://arxiv.org/abs/2508.11086)
*Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song*

Main category: cs.LG

TL;DR: 提出了一种基于相对优势的去偏框架，通过比较观看时间与用户和物品组的参考分布，生成基于分位数的偏好信号，显著提升了推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 原始观看时间受视频时长、流行度和用户行为等混杂因素影响，可能导致推荐模型偏差。

Method: 采用两阶段架构，分离分布估计与偏好学习，并引入分布嵌入参数化观看时间分位数。

Result: 离线和在线实验显示，该方法在推荐准确性和鲁棒性上优于现有基线方法。

Conclusion: 提出的框架有效解决了观看时间偏差问题，提升了推荐系统的性能。

Abstract: Watch time is widely used as a proxy for user satisfaction in video
recommendation platforms. However, raw watch times are influenced by
confounding factors such as video duration, popularity, and individual user
behaviors, potentially distorting preference signals and resulting in biased
recommendation models. We propose a novel relative advantage debiasing
framework that corrects watch time by comparing it to empirically derived
reference distributions conditioned on user and item groups. This approach
yields a quantile-based preference signal and introduces a two-stage
architecture that explicitly separates distribution estimation from preference
learning. Additionally, we present distributional embeddings to efficiently
parameterize watch-time quantiles without requiring online sampling or storage
of historical data. Both offline and online experiments demonstrate significant
improvements in recommendation accuracy and robustness compared to existing
baseline methods.

</details>


### [147] [Compressive Meta-Learning](https://arxiv.org/abs/2508.11090)
*Daniel Mas Montserrat,David Bonet,Maria Perera,Xavier Giró-i-Nieto,Alexander G. Ioannidis*

Main category: cs.LG

TL;DR: 本文提出了一种基于元学习的压缩学习框架，通过神经网络优化编码和解码过程，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着数据集规模的快速扩大，需要快速高效的参数学习技术。现有压缩学习方法未能利用数据的底层结构。

Method: 使用神经网络元学习压缩学习的编码和解码阶段，提出Compressive Meta-Learning框架。

Result: 该框架在多个应用中（如压缩PCA、压缩岭回归等）表现优于现有方法。

Conclusion: Compressive Meta-Learning框架为高效、隐私友好的学习提供了新方向。

Abstract: The rapid expansion in the size of new datasets has created a need for fast
and efficient parameter-learning techniques. Compressive learning is a
framework that enables efficient processing by using random, non-linear
features to project large-scale databases onto compact, information-preserving
representations whose dimensionality is independent of the number of samples
and can be easily stored, transferred, and processed. These database-level
summaries are then used to decode parameters of interest from the underlying
data distribution without requiring access to the original samples, offering an
efficient and privacy-friendly learning framework. However, both the encoding
and decoding techniques are typically randomized and data-independent, failing
to exploit the underlying structure of the data. In this work, we propose a
framework that meta-learns both the encoding and decoding stages of compressive
learning methods by using neural networks that provide faster and more accurate
systems than the current state-of-the-art approaches. To demonstrate the
potential of the presented Compressive Meta-Learning framework, we explore
multiple applications -- including neural network-based compressive PCA,
compressive ridge regression, compressive k-means, and autoencoders.

</details>


### [148] [Predictive Multimodal Modeling of Diagnoses and Treatments in EHR](https://arxiv.org/abs/2508.11092)
*Cindy Shih-Ting Huang,Clarence Boon Liang Ng,Marek Rei*

Main category: cs.LG

TL;DR: 提出了一种多模态系统，用于早期预测ICD编码，融合临床记录和表格数据，通过预训练编码器和跨模态注意力优化表示，并引入加权时间损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 早期预测ICD编码有助于识别健康风险、优化治疗和资源分配，但现有研究多关注出院后分类，缺乏对住院初期的预测模型。

Method: 提出多模态系统，融合临床记录和表格数据，使用预训练编码器、特征池化和跨模态注意力学习最优表示，并设计加权时间损失函数。

Result: 实验表明，该方法优于当前最先进系统，提升了早期预测性能。

Conclusion: 多模态融合和加权时间损失策略有效提升了ICD编码的早期预测能力。

Abstract: While the ICD code assignment problem has been widely studied, most works
have focused on post-discharge document classification. Models for early
forecasting of this information could be used for identifying health risks,
suggesting effective treatments, or optimizing resource allocation. To address
the challenge of predictive modeling using the limited information at the
beginning of a patient stay, we propose a multimodal system to fuse clinical
notes and tabular events captured in electronic health records. The model
integrates pre-trained encoders, feature pooling, and cross-modal attention to
learn optimal representations across modalities and balance their presence at
every temporal point. Moreover, we present a weighted temporal loss that
adjusts its contribution at each point in time. Experiments show that these
strategies enhance the early prediction model, outperforming the current
state-of-the-art systems.

</details>


### [149] [Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation](https://arxiv.org/abs/2508.11105)
*Sajjad Saed,Babak Teimourpour*

Main category: cs.LG

TL;DR: FGAT框架通过图神经网络和注意力机制，结合视觉与文本特征，同时建模服装兼容性和用户偏好，显著提升时尚推荐系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 时尚行业快速扩张，用户难以在电商平台找到兼容商品，现有研究常忽视物品与用户偏好的复杂交互。

Method: FGAT构建用户、搭配和物品的三层层次图，利用图注意力机制动态加权节点重要性，整合多模态特征。

Result: 在POG数据集上，FGAT在精度、HR、召回率等指标上优于基线模型HFGN。

Conclusion: 多模态特征与层次图结构及注意力机制的结合显著提升了个性化时尚推荐的准确性和效率。

Abstract: The rapid expansion of the fashion industry and the growing variety of
products have made it challenging for users to find compatible items on
e-commerce platforms. Effective fashion recommendation systems are crucial for
filtering irrelevant items and suggesting suitable ones. However,
simultaneously addressing outfit compatibility and personalized recommendations
remains a significant challenge, as these aspects are often treated
independently in existing studies, often overlooking the complex interactions
between items and user preferences. This research introduces a new framework
named FGAT, inspired by the HFGN model, which leverages graph neural networks
and graph attention mechanisms to tackle this issue. The proposed framework
constructs a three-tier hierarchical graph of users, outfits, and items,
integrating visual and textual features to simultaneously model outfit
compatibility and user preferences. A graph attention mechanism dynamically
weights node importance during representation propagation, enabling the capture
of key interactions and generating precise representations for both user
preferences and outfit compatibility. Evaluated on the POG dataset, FGAT
outperforms baseline models such as HFGN, achieving improved results in
precision, HR, recall, NDCG, and accuracy.These results demonstrate that
combining multimodal visual-textual features with a hierarchical graph
structure and attention mechanisms significantly enhances the accuracy and
efficiency of personalized fashion recommendation systems.

</details>


### [150] [Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees](https://arxiv.org/abs/2508.11112)
*Jianhao Ma,Lin Xiao*

Main category: cs.LG

TL;DR: 论文研究了分段仿射正则化（PAR）在监督学习中的理论和应用，证明了在过参数化情况下，PAR正则化损失函数的临界点具有高度量化特性，并提供了多种PAR的闭式近端映射及求解方法，同时分析了PAR在统计上的保证。


<details>
  <summary>Details</summary>
Motivation: 解决离散或量化变量优化问题的组合复杂性，提供基于连续优化的灵活建模和计算框架。

Method: 研究了PAR的理论基础，包括临界点量化特性、闭式近端映射及求解方法（如近端梯度法、ADMM），并分析了PAR在统计上的保证。

Result: 在过参数化情况下，PAR正则化损失函数的临界点具有高度量化特性；提供了多种PAR的闭式近端映射及求解方法；PAR能近似经典正则化并获得统计保证。

Conclusion: PAR为量化问题提供了灵活且理论支持的方法，适用于多种优化场景，并能保持统计性能。

Abstract: Optimization problems over discrete or quantized variables are very
challenging in general due to the combinatorial nature of their search space.
Piecewise-affine regularization (PAR) provides a flexible modeling and
computational framework for quantization based on continuous optimization. In
this work, we focus on the setting of supervised learning and investigate the
theoretical foundations of PAR from optimization and statistical perspectives.
First, we show that in the overparameterized regime, where the number of
parameters exceeds the number of samples, every critical point of the
PAR-regularized loss function exhibits a high degree of quantization. Second,
we derive closed-form proximal mappings for various (convex, quasi-convex, and
non-convex) PARs and show how to solve PAR-regularized problems using the
proximal gradient method, its accelerated variant, and the Alternating
Direction Method of Multipliers. Third, we study statistical guarantees of
PAR-regularized linear regression problems; specifically, we can approximate
classical formulations of $\ell_1$-, squared $\ell_2$-, and nonconvex
regularizations using PAR and obtain similar statistical guarantees with
quantized solutions.

</details>


### [151] [CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets](https://arxiv.org/abs/2508.11144)
*Gauri Jain,Dominik Rothenhäusler,Kirk Bansak,Elisabeth Paulson*

Main category: cs.LG

TL;DR: 论文提出了一种名为CTRL的元学习方法，旨在解决多源数据中的分布偏移和样本量差异问题，同时提升整体准确性和保持源间异质性。


<details>
  <summary>Details</summary>
Motivation: 在多源数据（如不同地理位置或群体）的机器学习任务中，需要确保预测不仅整体准确，还能在各源内可靠并保留源间差异。例如，难民安置项目需要针对小规模源生成差异化预测。

Method: CTRL结合了跨域残差学习和自适应池化/聚类技术，通过元学习方法平衡数据数量与质量的权衡。

Result: 在5个大规模数据集（包括瑞士国家庇护计划数据）上，CTRL在多个关键指标上优于其他先进基准方法。

Conclusion: CTRL有效解决了多源数据中的挑战，显著提升了预测性能，适用于需要差异化预测的实际应用场景。

Abstract: Machine learning (ML) tasks often utilize large-scale data that is drawn from
several distinct sources, such as different locations, treatment arms, or
groups. In such settings, practitioners often desire predictions that not only
exhibit good overall accuracy, but also remain reliable within each source and
preserve the differences that matter across sources. For instance, several
asylum and refugee resettlement programs now use ML-based employment
predictions to guide where newly arriving families are placed within a host
country, which requires generating informative and differentiated predictions
for many and often small source locations. However, this task is made
challenging by several common characteristics of the data in these settings:
the presence of numerous distinct data sources, distributional shifts between
them, and substantial variation in sample sizes across sources. This paper
introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method
that combines the strengths of cross-domain residual learning and adaptive
pooling/clustering in order to simultaneously improve overall accuracy and
preserve source-level heterogeneity. We provide theoretical results that
clarify how our objective navigates the trade-off between data quantity and
data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5
large-scale datasets. This includes a dataset from the national asylum program
in Switzerland, where the algorithmic geographic assignment of asylum seekers
is currently being piloted. CTRL consistently outperforms the benchmarks across
several key metrics and when using a range of different base learners.

</details>


### [152] [Towards the Next-generation Bayesian Network Classifiers](https://arxiv.org/abs/2508.11145)
*Huan Zhang,Daokun Zhang,Kexin Meng,Geoffrey I. Webb*

Main category: cs.LG

TL;DR: 提出了一种基于分布表示学习的高阶贝叶斯网络分类器NeuralKDB，通过神经网络架构学习特征值的分布表示，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯网络分类器因参数爆炸和数据稀疏性问题，难以建模高阶特征依赖，限制了其在复杂数据中的表现。

Method: 通过分布表示学习捕捉特征间的语义相关性，设计神经网络架构NeuralKDB，并基于随机梯度下降算法训练模型。

Result: 在60个UCI数据集上的实验表明，NeuralKDB在高阶特征依赖建模上表现优异，显著优于传统贝叶斯网络分类器及其他竞争方法。

Conclusion: NeuralKDB通过分布表示学习有效解决了传统贝叶斯网络分类器的局限性，为高阶特征依赖建模提供了新思路。

Abstract: Bayesian network classifiers provide a feasible solution to tabular data
classification, with a number of merits like high time and memory efficiency,
and great explainability. However, due to the parameter explosion and data
sparsity issues, Bayesian network classifiers are restricted to low-order
feature dependency modeling, making them struggle in extrapolating the
occurrence probabilities of complex real-world data. In this paper, we propose
a novel paradigm to design high-order Bayesian network classifiers, by learning
distributional representations for feature values, as what has been done in
word embedding and graph representation learning. The learned distributional
representations are encoded with the semantic relatedness between different
features through their observed co-occurrence patterns in training data, which
then serve as a hallmark to extrapolate the occurrence probabilities of new
test samples. As a classifier design realization, we remake the K-dependence
Bayesian classifier (KDB) by extending it into a neural version, i.e.,
NeuralKDB, where a novel neural network architecture is designed to learn
distributional representations of feature values and parameterize the
conditional probabilities between interdependent features. A stochastic
gradient descent based algorithm is designed to train the NeuralKDB model
efficiently. Extensive classification experiments on 60 UCI datasets
demonstrate that the proposed NeuralKDB classifier excels in capturing
high-order feature dependencies and significantly outperforms the conventional
Bayesian network classifiers, as well as other competitive classifiers,
including two neural network based classifiers without distributional
representation learning.

</details>


### [153] [Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning](https://arxiv.org/abs/2508.11159)
*Heqiang Wang,Weihong Yang,Xiaoxiong Zhong,Jia Zhou,Fangming Liu,Weizhe Zhang*

Main category: cs.LG

TL;DR: 论文研究了物联网（IoT）中多模态数据的不平衡问题，提出了一种名为QQR的算法来优化多模态在线联邦学习（MMO-FL）的性能。


<details>
  <summary>Details</summary>
Motivation: 随着边缘智能的发展，IoT设备需要处理异构多模态数据，但设备不稳定导致数据模态的数量和质量不平衡（QQI），影响了学习效果。

Method: 提出了Modality Quantity and Quality Rebalanced (QQR)算法，通过原型学习在训练过程中动态调整模态不平衡。

Result: 在两种真实多模态数据集上的实验表明，QQR算法在模态不平衡条件下优于基准方法。

Conclusion: QQR算法有效解决了MMO-FL中的模态不平衡问题，提升了学习性能。

Abstract: The Internet of Things (IoT) ecosystem produces massive volumes of multimodal
data from diverse sources, including sensors, cameras, and microphones. With
advances in edge intelligence, IoT devices have evolved from simple data
acquisition units into computationally capable nodes, enabling localized
processing of heterogeneous multimodal data. This evolution necessitates
distributed learning paradigms that can efficiently handle such data.
Furthermore, the continuous nature of data generation and the limited storage
capacity of edge devices demand an online learning framework. Multimodal Online
Federated Learning (MMO-FL) has emerged as a promising approach to meet these
requirements. However, MMO-FL faces new challenges due to the inherent
instability of IoT devices, which often results in modality quantity and
quality imbalance (QQI) during data collection. In this work, we systematically
investigate the impact of QQI within the MMO-FL framework and present a
comprehensive theoretical analysis quantifying how both types of imbalance
degrade learning performance. To address these challenges, we propose the
Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning
based method designed to operate in parallel with the training process.
Extensive experiments on two real-world multimodal datasets show that the
proposed QQR algorithm consistently outperforms benchmarks under modality
imbalance conditions with promising learning performance.

</details>


### [154] [A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels](https://arxiv.org/abs/2508.11180)
*Yiyang Shen,Weiran Wang*

Main category: cs.LG

TL;DR: 提出了一种半监督生成模型，结合信息瓶颈原则和跨视图互信息最大化，解决了多视图学习中的缺失视图和标签问题。


<details>
  <summary>Details</summary>
Motivation: 多视图学习常面临缺失视图和标签的问题，现有方法无法充分利用无标签数据。

Method: 提出半监督生成模型，结合信息瓶颈原则和跨视图互信息最大化，利用有标签和无标签数据。

Result: 在图像和多组学数据上表现优于现有方法，预测和填补性能更优。

Conclusion: 该方法有效解决了多视图学习中的缺失问题，提升了性能。

Abstract: Multi-view learning is widely applied to real-life datasets, such as multiple
omics biological data, but it often suffers from both missing views and missing
labels. Prior probabilistic approaches addressed the missing view problem by
using a product-of-experts scheme to aggregate representations from present
views and achieved superior performance over deterministic classifiers, using
the information bottleneck (IB) principle. However, the IB framework is
inherently fully supervised and cannot leverage unlabeled data. In this work,
we propose a semi-supervised generative model that utilizes both labeled and
unlabeled samples in a unified framework. Our method maximizes the likelihood
of unlabeled samples to learn a latent space shared with the IB on labeled
data. We also perform cross-view mutual information maximization in the latent
space to enhance the extraction of shared information across views. Compared to
existing approaches, our model achieves better predictive and imputation
performance on both image and multi-omics data with missing views and limited
labeled samples.

</details>


### [155] [Quantum-Boosted High-Fidelity Deep Learning](https://arxiv.org/abs/2508.11190)
*Feng-ao Wang,Shaobo Chen,Yao Xuan,Junwei Liu,Qi Gao,Hongdong Zhu,Junjie Hou,Lixin Yuan,Jinyu Cheng,Chenxin Yi,Hai Wei,Yin Ma,Tao Xu,Kai Wen,Yixue Li*

Main category: cs.LG

TL;DR: 论文提出了一种混合量子-经典架构QBM-VAE，利用量子处理器高效采样Boltzmann分布，解决了传统高斯先验在复杂生物数据中的局限性，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习依赖高斯先验，无法准确捕捉复杂非高斯数据（如生物数据），而Boltzmann分布虽更优但计算困难。量子方法因硬件限制未成功应用。

Method: 提出QBM-VAE，结合量子处理器采样Boltzmann分布作为先验，构建深度生成模型。

Result: 在百万级单细胞数据集上，QBM-VAE优于传统高斯模型（如VAE、SCVI），在数据整合、细胞分类和轨迹推断等任务中表现更优。

Conclusion: QBM-VAE展示了量子优势在深度学习中的实际应用，为混合量子AI模型开发提供了可转移的蓝图。

Abstract: A fundamental limitation of probabilistic deep learning is its predominant
reliance on Gaussian priors. This simplistic assumption prevents models from
accurately capturing the complex, non-Gaussian landscapes of natural data,
particularly in demanding domains like complex biological data, severely
hindering the fidelity of the model for scientific discovery. The
physically-grounded Boltzmann distribution offers a more expressive
alternative, but it is computationally intractable on classical computers. To
date, quantum approaches have been hampered by the insufficient qubit scale and
operational stability required for the iterative demands of deep learning.
Here, we bridge this gap by introducing the Quantum Boltzmann
Machine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable
hybrid quantum-classical architecture. Our framework leverages a quantum
processor for efficient sampling from the Boltzmann distribution, enabling its
use as a powerful prior within a deep generative model. Applied to
million-scale single-cell datasets from multiple sources, the QBM-VAE generates
a latent space that better preserves complex biological structures,
consistently outperforming conventional Gaussian-based deep learning models
like VAE and SCVI in essential tasks such as omics data integration, cell-type
classification, and trajectory inference. It also provides a typical example of
introducing a physics priori into deep learning to drive the model to acquire
scientific discovery capabilities that breaks through data limitations. This
work provides the demonstration of a practical quantum advantage in deep
learning on a large-scale scientific problem and offers a transferable
blueprint for developing hybrid quantum AI models.

</details>


### [156] [Meta-learning Structure-Preserving Dynamics](https://arxiv.org/abs/2508.11205)
*Cheng Jing,Uvini Balasuriya Mudiyanselage,Woojin Cho,Minju Jo,Anthony Gruber,Kookjin Lee*

Main category: cs.LG

TL;DR: 论文提出了一种基于调制的元学习框架，用于结构保持的动态系统建模，解决了传统方法需要固定系统配置和昂贵重新训练的问题。


<details>
  <summary>Details</summary>
Motivation: 传统结构保持的动态建模方法需要固定系统配置和显式参数知识，限制了其在多查询或参数变化场景中的应用。元学习提供了一种解决方案，但现有方法存在训练不稳定或泛化能力有限的问题。

Method: 引入了一种基于调制的元学习框架，通过紧凑的潜在表示直接调节结构保持模型，避免了对灰盒系统知识和显式优化的依赖。

Result: 实验表明，该方法在少样本学习场景中实现了准确预测，同时保持了动态稳定性和泛化性能。

Conclusion: 该框架为参数化动态系统提供了可扩展和泛化的学习能力，克服了传统方法的局限性。

Abstract: Structure-preserving approaches to dynamics modeling have demonstrated great
potential for modeling physical systems due to their strong inductive biases
that enforce conservation laws and dissipative behavior. However, the resulting
models are typically trained for fixed system configurations, requiring
explicit knowledge of system parameters as well as costly retraining for each
new set of parameters -- a major limitation in many-query or parameter-varying
scenarios. Meta-learning offers a potential solution, but existing approaches
like optimization-based meta-learning often suffer from training instability or
limited generalization capability. Inspired by ideas from computer vision, we
introduce a modulation-based meta-learning framework that directly conditions
structure-preserving models on compact latent representations of potentially
unknown system parameters, avoiding the need for gray-box system knowledge and
explicit optimization during adaptation. Through the application of novel
modulation strategies to parametric energy-conserving and dissipative systems,
we enable scalable and generalizable learning across parametric families of
dynamical systems. Experiments on standard benchmark problems demonstrate that
our approach achieves accurate predictions in few-shot learning settings,
without compromising on the essential physical constraints necessary for
dynamical stability and effective generalization performance across parameter
space.

</details>


### [157] [Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning](https://arxiv.org/abs/2508.11210)
*Minghui Sun,Matthew M. Engelhard,Benjamin A. Goldstein*

Main category: cs.LG

TL;DR: 论文提出了一种名为Borrowing From the Future (BFF)的对比多模态框架，旨在通过利用后期数据提升早期儿科风险评估的预测性能。


<details>
  <summary>Details</summary>
Motivation: 尽管后期预测通常更精确，但临床需要尽早进行可靠的风险评估。

Method: BFF将每个时间窗口视为独立模态，利用后期数据隐式监督早期学习。

Result: 在两个真实儿科预测任务中验证，BFF显著提升了早期风险评估的准确性。

Conclusion: BFF框架为早期儿科风险评估提供了一种有效的解决方案。

Abstract: Risk assessments for a pediatric population are often conducted across
multiple stages. For example, clinicians may evaluate risks prenatally, at
birth, and during Well-Child visits. Although predictions made at later stages
typically achieve higher precision, it is clinically desirable to make reliable
risk assessments as early as possible. Therefore, this study focuses on
improving prediction performance in early-stage risk assessments. Our solution,
\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal
framework that treats each time window as a distinct modality. In BFF, a model
is trained on all available data throughout the time while performing a risk
assessment using up-to-date information. This contrastive framework allows the
model to ``borrow'' informative signals from later stages (e.g., Well-Child
visits) to implicitly supervise the learning at earlier stages (e.g.,
prenatal/birth stages). We validate BFF on two real-world pediatric outcome
prediction tasks, demonstrating consistent improvements in early risk
assessments. The code is available at https://github.com/scotsun/bff.

</details>


### [158] [How Causal Abstraction Underpins Computational Explanation](https://arxiv.org/abs/2508.11214)
*Atticus Geiger,Jacqueline Harding,Thomas Icard*

Main category: cs.LG

TL;DR: 论文探讨了如何通过因果抽象理论解释认知行为中的计算与表示问题，并结合深度学习中的神经网络讨论了哲学与机器学习的联系。


<details>
  <summary>Details</summary>
Motivation: 研究旨在明确系统如何实现特定计算，并探讨表示在其中的作用。

Method: 采用因果抽象理论作为分析框架，结合深度学习中的案例进行说明。

Result: 提出了基于因果抽象的计算实现理论，并分析了表示在其中的角色。

Conclusion: 认为这些问题最好与泛化和预测结合研究，为认知行为与机器学习的交叉领域提供了新视角。

Abstract: Explanations of cognitive behavior often appeal to computations over
representations. What does it take for a system to implement a given
computation over suitable representational vehicles within that system? We
argue that the language of causality -- and specifically the theory of causal
abstraction -- provides a fruitful lens on this topic. Drawing on current
discussions in deep learning with artificial neural networks, we illustrate how
classical themes in the philosophy of computation and cognition resurface in
contemporary machine learning. We offer an account of computational
implementation grounded in causal abstraction, and examine the role for
representation in the resulting picture. We argue that these issues are most
profitably explored in connection with generalization and prediction.

</details>


### [159] [Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM](https://arxiv.org/abs/2508.11215)
*Zicheng Guo,Shuqi Wu,Meixing Zhu,He Guandi*

Main category: cs.LG

TL;DR: 提出了一种基于CNN-LSTM混合架构的PM2.5预测模型，结合空间和时间特征，在实验数据上表现优于传统方法，但计算资源需求高。


<details>
  <summary>Details</summary>
Motivation: 全球气候变化加剧，PM2.5浓度预测对环境保护和公共健康至关重要。

Method: 使用CNN提取局部空间特征，LSTM建模时间序列依赖，基于北京工业区2010-2015年多变量数据集预测6小时平均PM2.5浓度。

Result: 模型RMSE为5.236，优于传统时间序列模型，但计算资源需求高。

Conclusion: 模型在现实应用中有潜力，但需优化计算效率和多元天气因素处理能力，未来将扩展支持更复杂任务。

Abstract: With the intensification of global climate change, accurate prediction of air
quality indicators, especially PM2.5 concentration, has become increasingly
important in fields such as environmental protection, public health, and urban
management. To address this, we propose an air quality PM2.5 index prediction
model based on a hybrid CNN-LSTM architecture. The model effectively combines
Convolutional Neural Networks (CNN) for local spatial feature extraction and
Long Short-Term Memory (LSTM) networks for modeling temporal dependencies in
time series data. Using a multivariate dataset collected from an industrial
area in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5
concentration, temperature, dew point, pressure, wind direction, wind speed,
and precipitation -- the model predicts the average PM2.5 concentration over
6-hour intervals. Experimental results show that the model achieves a root mean
square error (RMSE) of 5.236, outperforming traditional time series models in
both accuracy and generalization. This demonstrates its strong potential in
real-world applications such as air pollution early warning systems. However,
due to the complexity of multivariate inputs, the model demands high
computational resources, and its ability to handle diverse atmospheric factors
still requires optimization. Future work will focus on enhancing scalability
and expanding support for more complex multivariate weather prediction tasks.

</details>


### [160] [Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories](https://arxiv.org/abs/2508.11235)
*William Alemanni,Arianna Burzacchi,Davide Colombi,Elena Giarratano*

Main category: cs.LG

TL;DR: 本文提出了一种改进的交互式投票地图匹配算法，用于高效处理不同采样率的轨迹数据，旨在高精度重建GPS轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决GPS轨迹数据因采样率不同或数据质量差而导致的重建精度问题。

Method: 扩展原算法，集成轨迹插补，采用距离限制的交互式投票策略降低计算复杂度，并改进以处理道路网络中的缺失数据。

Result: 算法保留了原核心优势，同时显著提升了在多样化现实场景中的适用性。

Conclusion: 改进后的算法能够高效、准确地处理不同质量的GPS轨迹数据，适用于OpenStreetMap覆盖的任何地理区域。

Abstract: This paper presents an enhanced version of the Interactive Voting-Based Map
Matching algorithm, designed to efficiently process trajectories with varying
sampling rates. The main aim is to reconstruct GPS trajectories with high
accuracy, independent of input data quality. Building upon the original
algorithm, developed exclusively for aligning GPS signals to road networks, we
extend its capabilities by integrating trajectory imputation. Our improvements
also include the implementation of a distance-bounded interactive voting
strategy to reduce computational complexity, as well as modifications to
address missing data in the road network. Furthermore, we incorporate a
custom-built asset derived from OpenStreetMap, enabling this approach to be
smoothly applied in any geographic region covered by OpenStreetMap's road
network. These advancements preserve the core strengths of the original
algorithm while significantly extending its applicability to diverse real-world
scenarios.

</details>


### [161] [Graph Neural Diffusion via Generalized Opinion Dynamics](https://arxiv.org/abs/2508.11249)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: GODNF框架解决了现有扩散GNN的局限性，通过统一多种意见动态模型，实现了高效、可解释的消息传播。


<details>
  <summary>Details</summary>
Motivation: 现有扩散GNN存在适应性差、深度受限和理论理解不足的问题。

Method: 提出GODNF框架，结合节点行为建模和动态邻居影响，支持异构扩散和时序动态。

Result: 理论分析证明其收敛能力，实验验证其在节点分类和影响力估计任务中的优越性。

Conclusion: GODNF为扩散GNN提供了更灵活、高效和可解释的解决方案。

Abstract: There has been a growing interest in developing diffusion-based Graph Neural
Networks (GNNs), building on the connections between message passing mechanisms
in GNNs and physical diffusion processes. However, existing methods suffer from
three critical limitations: (1) they rely on homogeneous diffusion with static
dynamics, limiting adaptability to diverse graph structures; (2) their depth is
constrained by computational overhead and diminishing interpretability; and (3)
theoretical understanding of their convergence behavior remains limited. To
address these challenges, we propose GODNF, a Generalized Opinion Dynamics
Neural Framework, which unifies multiple opinion dynamics models into a
principled, trainable diffusion mechanism. Our framework captures heterogeneous
diffusion patterns and temporal dynamics via node-specific behavior modeling
and dynamic neighborhood influence, while ensuring efficient and interpretable
message propagation even at deep layers. We provide a rigorous theoretical
analysis demonstrating GODNF's ability to model diverse convergence
configurations. Extensive empirical evaluations of node classification and
influence estimation tasks confirm GODNF's superiority over state-of-the-art
GNNs.

</details>


### [162] [Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing](https://arxiv.org/abs/2508.11258)
*Ruicheng Xian,Yuxuan Wan,Han Zhao*

Main category: cs.LG

TL;DR: 论文提出了一种通过提示从封闭权重LLM中提取公平分类器的框架，解决了传统方法在零样本或少样本学习场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM能力的提升，其在高风险领域的应用需求增加，但现有公平性方法无法适用于封闭权重LLM（如GPT-4）。

Method: 将LLM视为特征提取器，通过设计的提示获取概率预测特征，再训练轻量级公平分类器。

Result: 在五个数据集上验证了框架的优越性，尤其在数据效率和公平性-准确性权衡方面表现突出。

Conclusion: 该框架为封闭权重LLM的公平分类提供了高效且实用的解决方案。

Abstract: Instruction fine-tuned large language models (LLMs) enable a simple zero-shot
or few-shot prompting paradigm, also known as in-context learning, for building
prediction models. This convenience, combined with continued advances in LLM
capability, has the potential to drive their adoption across a broad range of
domains, including high-stakes applications where group fairness -- preventing
disparate impacts across demographic groups -- is essential. The majority of
existing approaches to enforcing group fairness on LLM-based classifiers rely
on traditional fair algorithms applied via model fine-tuning or head-tuning on
final-layer embeddings, but they are no longer applicable to closed-weight LLMs
under the in-context learning setting, which include some of the most capable
commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we
propose a framework for deriving fair classifiers from closed-weight LLMs via
prompting: the LLM is treated as a feature extractor, and features are elicited
from its probabilistic predictions (e.g., token log probabilities) using
prompts strategically designed for the specified fairness criterion to obtain
sufficient statistics for fair classification; a fair algorithm is then applied
to these features to train a lightweight fair classifier in a post-hoc manner.
Experiments on five datasets, including three tabular ones, demonstrate strong
accuracy-fairness tradeoffs for the classifiers derived by our framework from
both open-weight and closed-weight LLMs; in particular, our framework is
data-efficient and outperforms fair classifiers trained on LLM embeddings
(i.e., head-tuning) or from scratch on raw tabular features.

</details>


### [163] [Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble](https://arxiv.org/abs/2508.11279)
*Jihang Wang,Dongcheng Zhao,Ruolin Chen,Qian Zhang,Yi Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种名为RTE的训练框架，通过时间集成方法提升SNN的对抗鲁棒性，解决了时间子网络的脆弱性和对抗漏洞跨时间传播的问题。


<details>
  <summary>Details</summary>
Motivation: SNN在能效和类脑计算方面具有潜力，但其对抗扰动的脆弱性尚未被充分理解。

Method: 提出RTE框架，通过统一损失函数和随机采样策略优化时间子网络的鲁棒性，并减少对抗扰动的跨时间传播。

Result: 实验表明RTE在多个基准测试中优于现有方法，且能重塑SNN的内部鲁棒性景观。

Conclusion: 研究强调了时间结构在对抗学习中的重要性，为构建鲁棒的SNN模型提供了理论基础。

Abstract: Spiking Neural Networks (SNNs) offer a promising direction for
energy-efficient and brain-inspired computing, yet their vulnerability to
adversarial perturbations remains poorly understood. In this work, we revisit
the adversarial robustness of SNNs through the lens of temporal ensembling,
treating the network as a collection of evolving sub-networks across discrete
timesteps. This formulation uncovers two critical but underexplored
challenges-the fragility of individual temporal sub-networks and the tendency
for adversarial vulnerabilities to transfer across time. To overcome these
limitations, we propose Robust Temporal self-Ensemble (RTE), a training
framework that improves the robustness of each sub-network while reducing the
temporal transferability of adversarial perturbations. RTE integrates both
objectives into a unified loss and employs a stochastic sampling strategy for
efficient optimization. Extensive experiments across multiple benchmarks
demonstrate that RTE consistently outperforms existing training methods in
robust-accuracy trade-off. Additional analyses reveal that RTE reshapes the
internal robustness landscape of SNNs, leading to more resilient and temporally
diversified decision boundaries. Our study highlights the importance of
temporal structure in adversarial learning and offers a principled foundation
for building robust spiking models.

</details>


### [164] [Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning](https://arxiv.org/abs/2508.11328)
*Haitong Luo,Suhang Wang,Weiyao Zhang,Ruiqi Meng,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: 论文提出HS-GPPT模型，通过频谱对齐优化图预训练与提示调优，解决现有方法在异质性图上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖同质性低频知识，无法处理真实图中多样化的频谱分布，导致知识迁移效果不佳。

Method: 提出HS-GPPT框架，结合混合频谱滤波器主干和局部-全局对比学习，设计提示图以实现频谱对齐。

Result: 实验验证了模型在转导和归纳学习中的有效性。

Conclusion: HS-GPPT通过频谱对齐显著提升了知识迁移效果，适用于不同同质性图。

Abstract: Graph ``pre-training and prompt-tuning'' aligns downstream tasks with
pre-trained objectives to enable efficient knowledge transfer under limited
supervision. However, existing methods rely on homophily-based low-frequency
knowledge, failing to handle diverse spectral distributions in real-world
graphs with varying homophily. Our theoretical analysis reveals a spectral
specificity principle: optimal knowledge transfer requires alignment between
pre-trained spectral filters and the intrinsic spectrum of downstream graphs.
Under limited supervision, large spectral gaps between pre-training and
downstream tasks impede effective adaptation. To bridge this gap, we propose
the HS-GPPT model, a novel framework that ensures spectral alignment throughout
both pre-training and prompt-tuning. We utilize a hybrid spectral filter
backbone and local-global contrastive learning to acquire abundant spectral
knowledge. Then we design prompt graphs to align the spectral distribution with
pretexts, facilitating spectral knowledge transfer across homophily and
heterophily. Extensive experiments validate the effectiveness under both
transductive and inductive learning settings. Our code is available at
https://anonymous.4open.science/r/HS-GPPT-62D2/.

</details>


### [165] [RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading](https://arxiv.org/abs/2508.11338)
*Prathamesh Devadiga,Yashmitha Shailesh*

Main category: cs.LG

TL;DR: RegimeNAS是一种新颖的可微分架构搜索框架，专为提升加密货币交易性能而设计，通过显式集成市场状态感知，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决静态深度学习模型在高度动态金融环境中的局限性，提升交易模型的适应性和性能。

Method: 采用贝叶斯搜索空间、动态激活的神经模块（波动、趋势、范围块）和多目标损失函数，结合市场状态识别。

Result: 在真实加密货币数据上，RegimeNAS显著优于现有基准，平均绝对误差降低80.3%，收敛速度更快（9 vs. 50+ epochs）。

Conclusion: 研究强调了将领域知识（如市场状态）直接嵌入NAS过程的重要性，以开发适应性强且稳健的金融模型。

Abstract: We introduce RegimeNAS, a novel differentiable architecture search framework
specifically designed to enhance cryptocurrency trading performance by
explicitly integrating market regime awareness. Addressing the limitations of
static deep learning models in highly dynamic financial environments, RegimeNAS
features three core innovations: (1) a theoretically grounded Bayesian search
space optimizing architectures with provable convergence properties; (2)
specialized, dynamically activated neural modules (Volatility, Trend, and Range
blocks) tailored for distinct market conditions; and (3) a multi-objective loss
function incorporating market-specific penalties (e.g., volatility matching,
transition smoothness) alongside mathematically enforced Lipschitz stability
constraints. Regime identification leverages multi-head attention across
multiple timeframes for improved accuracy and uncertainty estimation. Rigorous
empirical evaluation on extensive real-world cryptocurrency data demonstrates
that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving
an 80.3% Mean Absolute Error reduction compared to the best traditional
recurrent baseline and converging substantially faster (9 vs. 50+ epochs).
Ablation studies and regime-specific analysis confirm the critical contribution
of each component, particularly the regime-aware adaptation mechanism. This
work underscores the imperative of embedding domain-specific knowledge, such as
market regimes, directly within the NAS process to develop robust and adaptive
models for challenging financial applications.

</details>


### [166] [Conformal Prediction Meets Long-tail Classification](https://arxiv.org/abs/2508.11345)
*Shuqi Liu,Jianguo Huang,Luke Ong*

Main category: cs.LG

TL;DR: 论文提出了一种Tail-Aware Conformal Prediction (TACP)方法，通过利用长尾标签分布结构，减少尾部类别的覆盖率不足问题，并进一步提出soft TACP (sTACP)以优化覆盖率平衡。


<details>
  <summary>Details</summary>
Motivation: 现有CP方法在长尾标签分布下，尾部类别的覆盖率不足，影响预测集的可靠性。

Method: 提出TACP方法，利用长尾结构缩小头尾类别覆盖率差距；进一步引入sTACP，通过重加权机制优化覆盖率平衡。

Result: 理论分析显示TACP能显著缩小头尾覆盖率差距；实验验证了方法的有效性。

Conclusion: TACP和sTACP能有效改善长尾分布下的覆盖率不平衡问题，提升预测集的可靠性。

Abstract: Conformal Prediction (CP) is a popular method for uncertainty quantification
that converts a pretrained model's point prediction into a prediction set, with
the set size reflecting the model's confidence. Although existing CP methods
are guaranteed to achieve marginal coverage, they often exhibit imbalanced
coverage across classes under long-tail label distributions, tending to over
cover the head classes at the expense of under covering the remaining tail
classes. This under coverage is particularly concerning, as it undermines the
reliability of the prediction sets for minority classes, even with coverage
ensured on average. In this paper, we propose the Tail-Aware Conformal
Prediction (TACP) method to mitigate the under coverage of the tail classes by
utilizing the long-tail structure and narrowing the head-tail coverage gap.
Theoretical analysis shows that it consistently achieves a smaller head-tail
coverage gap than standard methods. To further improve coverage balance across
all classes, we introduce an extension of TACP: soft TACP (sTACP) via a
reweighting mechanism. The proposed framework can be combined with various
non-conformity scores, and experiments on multiple long-tail benchmark datasets
demonstrate the effectiveness of our methods.

</details>


### [167] [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)
*Xiaohan Bi,Binhang Qi,Hailong Sun,Xiang Gao,Yue Yu,Xiaojun Liang*

Main category: cs.LG

TL;DR: NeMo提出了一种可扩展且通用的模块化训练方法，适用于Transformer和CNN模型，显著提升了模块分类精度并减少了模块大小。


<details>
  <summary>Details</summary>
Motivation: 随着DNN模型在现代软件系统中的广泛应用，训练成本高昂成为挑战。现有模块化方法局限于小规模CNN模型，难以应对多样化的DNN和大规模Transformer模型。

Method: NeMo在神经元级别操作，采用对比学习方法和复合损失函数，适用于各种架构。

Result: 实验表明，NeMo在模块分类精度上平均提升1.72%，模块大小减少58.10%，适用于CNN和Transformer模型。

Conclusion: NeMo为可扩展和通用的DNN模块化提供了有效解决方案，具有实际应用潜力。

Abstract: With the growing incorporation of deep neural network (DNN) models into
modern software systems, the prohibitive construction costs have become a
significant challenge. Model reuse has been widely applied to reduce training
costs, but indiscriminately reusing entire models may incur significant
inference overhead. Consequently, DNN modularization has gained attention,
enabling module reuse by decomposing DNN models. The emerging
modularizing-while-training (MwT) paradigm, which incorporates modularization
into training, outperforms modularizing-after-training approaches. However,
existing MwT methods focus on small-scale CNN models at the convolutional
kernel level and struggle with diverse DNNs and large-scale models,
particularly Transformer-based models. To address these limitations, we propose
NeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron
level fundamental component common to all DNNs-ensuring applicability to
Transformers and various architectures. We design a contrastive learning-based
modular training method with an effective composite loss function, enabling
scalability to large-scale models. Comprehensive experiments on two
Transformer-based models and four CNN models across two classification datasets
demonstrate NeMo's superiority over state-of-the-art MwT methods. Results show
average gains of 1.72% in module classification accuracy and 58.10% reduction
in module size, demonstrating efficacy across both CNN and large-scale
Transformer-based models. A case study on open-source projects shows NeMo's
potential benefits in practical scenarios, offering a promising approach for
scalable and generalizable DNN modularization.

</details>


### [168] [A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts](https://arxiv.org/abs/2508.11349)
*Angela John,Selvyn Allotey,Till Koebe,Alexandra Tyukavina,Ingmar Weber*

Main category: cs.LG

TL;DR: 研究通过卫星图像和二级数据验证全球造林项目的有效性，提出LDIS指标评估数据完整性。


<details>
  <summary>Details</summary>
Motivation: 应对自愿碳市场中数据可靠性和项目完整性的质疑。

Method: 整合主数据和卫星图像，开发LDIS指标评估种植地位置数据完整性。

Result: 79%的种植地至少一项LDIS指标不合格，15%项目缺乏可读地理数据。

Conclusion: 数据集提升碳市场透明度，并为计算机视觉任务提供训练数据。

Abstract: Afforestation and reforestation are popular strategies for mitigating climate
change by enhancing carbon sequestration. However, the effectiveness of these
efforts is often self-reported by project developers, or certified through
processes with limited external validation. This leads to concerns about data
reliability and project integrity. In response to increasing scrutiny of
voluntary carbon markets, this study presents a dataset on global afforestation
and reforestation efforts compiled from primary (meta-)information and
augmented with time-series satellite imagery and other secondary data. Our
dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.
Since any remote sensing-based validation effort relies on the integrity of a
planting site's geographic boundary, this dataset introduces a standardized
assessment of the provided site-level location information, which we summarize
in one easy-to-communicate key indicator: LDIS -- the Location Data Integrity
Score. We find that approximately 79\% of the georeferenced planting sites
monitored fail on at least 1 out of 10 LDIS indicators, while 15\% of the
monitored projects lack machine-readable georeferenced data in the first place.
In addition to enhancing accountability in the voluntary carbon market, the
presented dataset also holds value as training data for e.g. computer
vision-related tasks with millions of linked Sentinel-2 and Planetscope
satellite images.

</details>


### [169] [Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning](https://arxiv.org/abs/2508.11353)
*Han Zhou,Hongpeng Yin,Xuanhong Deng,Yuyu Huang,Hao Ren*

Main category: cs.LG

TL;DR: 论文提出了一种名为HGD的梯度下降算法，通过平衡不同类别的梯度范数，解决不平衡数据流学习问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据流常存在类别不平衡问题，现有方法如重采样或重加权效果有限，需通过训练修改解决。

Method: 提出HGD算法，无需数据缓冲区或额外参数，通过平衡梯度范数优化模型。

Result: 理论分析显示HGD具有次线性遗憾界，实验验证其在多种不平衡数据流场景中的高效性。

Conclusion: HGD是一种高效且通用的不平衡数据流学习方法。

Abstract: Many real-world data are sequentially collected over time and often exhibit
skewed class distributions, resulting in imbalanced data streams. While
existing approaches have explored several strategies, such as resampling and
reweighting, for imbalanced data stream learning, our work distinguishes itself
by addressing the imbalance problem through training modification, particularly
focusing on gradient descent techniques. We introduce the harmonized gradient
descent (HGD) algorithm, which aims to equalize the norms of gradients across
different classes. By ensuring the gradient norm balance, HGD mitigates
under-fitting for minor classes and achieves balanced online learning. Notably,
HGD operates in a streamlined implementation process, requiring no data-buffer,
extra parameters, or prior knowledge, making it applicable to any learning
models utilizing gradient descent for optimization. Theoretical analysis, based
on a few common and mild assumptions, shows that HGD achieves a satisfied
sub-linear regret bound. The proposed algorithm are compared with the commonly
used online imbalance learning methods under several imbalanced data stream
scenarios. Extensive experimental evaluations demonstrate the efficiency and
effectiveness of HGD in learning imbalanced data streams.

</details>


### [170] [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)
*Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu,TingTing Gao*

Main category: cs.LG

TL;DR: 论文提出了一种基于熵的机制，通过两种策略（ETMR和EAR）优化测试时强化学习的探索-利用平衡，显著提升了模型在无监督场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂推理任务中表现优异，但其依赖标注数据且无监督适应性有限，测试时强化学习（TTRL）虽能自优化，但面临高推理成本和早期估计偏差等问题。

Method: 引入熵基机制，包括ETMR（熵分叉树多数展开）和EAR（熵基优势重塑），以优化探索-利用平衡。

Result: 在AIME 2024基准测试中，Llama3.1-8B模型的Pass at 1指标相对提升68%，同时仅消耗60%的展开令牌预算。

Conclusion: 该方法有效平衡了推理效率、多样性和估计稳健性，推动了无监督强化学习在开放域推理任务中的应用。

Abstract: Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.

</details>


### [171] [PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding](https://arxiv.org/abs/2508.11357)
*Changhong Jing,Yan Liu,Shuqiang Wang,Bruce X. B. Yu,Gong Chen,Zhejing Hu,Zhi Zhang,Yanyan Shen*

Main category: cs.LG

TL;DR: PTSM框架通过双分支掩码机制和正交子空间分解，实现跨被试EEG解码，无需特定校准即可达到零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 解决跨被试EEG解码中因被试间差异和共享表征稀缺导致的挑战。

Method: 采用双分支掩码机制学习个性化和共享时空模式，结合信息论约束分解潜在嵌入。

Result: 在跨被试运动想象数据集上表现优异，优于现有方法。

Conclusion: PTSM通过解耦神经表征，实现个性化和可迁移的解码。

Abstract: Cross-subject electroencephalography (EEG) decoding remains a fundamental
challenge in brain-computer interface (BCI) research due to substantial
inter-subject variability and the scarcity of subject-invariant
representations. This paper proposed PTSM (Physiology-aware and Task-invariant
Spatio-temporal Modeling), a novel framework for interpretable and robust EEG
decoding across unseen subjects. PTSM employs a dual-branch masking mechanism
that independently learns personalized and shared spatio-temporal patterns,
enabling the model to preserve individual-specific neural characteristics while
extracting task-relevant, population-shared features. The masks are factorized
across temporal and spatial dimensions, allowing fine-grained modulation of
dynamic EEG patterns with low computational overhead. To further address
representational entanglement, PTSM enforces information-theoretic constraints
that decompose latent embeddings into orthogonal task-related and
subject-related subspaces. The model is trained end-to-end via a
multi-objective loss integrating classification, contrastive, and
disentanglement objectives. Extensive experiments on cross-subject motor
imagery datasets demonstrate that PTSM achieves strong zero-shot
generalization, outperforming state-of-the-art baselines without
subject-specific calibration. Results highlight the efficacy of disentangled
neural representations for achieving both personalized and transferable
decoding in non-stationary neurophysiological settings.

</details>


### [172] [Fusing Rewards and Preferences in Reinforcement Learning](https://arxiv.org/abs/2508.11363)
*Sadegh Khorasani,Saber Salehkaleybar,Negar Kiyavash,Matthias Grossglauser*

Main category: cs.LG

TL;DR: DFA是一种强化学习算法，结合个体奖励和成对偏好，直接利用策略的对数概率建模偏好概率，避免单独奖励建模步骤。实验表明DFA在控制环境中表现优于或匹配SAC，且训练更稳定。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法通常依赖个体奖励，而人类偏好数据可能提供更丰富的反馈信息。DFA旨在融合这两种反馈形式，提升学习效率和性能。

Method: DFA通过策略的对数概率直接建模偏好概率，支持人类标注或在线合成的偏好数据。基于Bradley-Terry模型，最小化偏好损失可恢复SAC策略。

Result: DFA在六种控制环境中表现优于或匹配SAC，训练更稳定。在半合成偏好数据下，DFA在随机GridWorld中超越RLHF基线，接近真实奖励的性能。

Conclusion: DFA通过融合奖励和偏好反馈，提供了一种高效且稳定的强化学习方法，尤其在偏好数据可用时表现优异。

Abstract: We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that
fuses both individual rewards and pairwise preferences (if available) into a
single update rule. DFA uses the policy's log-probabilities directly to model
the preference probability, avoiding a separate reward-modeling step.
Preferences can be provided by human-annotators (at state-level or
trajectory-level) or be synthesized online from Q-values stored in an
off-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing
DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)
policy. Our simulation results show that DFA trained on generated preferences
matches or exceeds SAC on six control environments and demonstrates a more
stable training process. With only a semi-synthetic preference dataset under
Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement
learning from human feedback (RLHF) baselines in a stochastic GridWorld and
approaches the performance of an oracle with true rewards.

</details>


### [173] [Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization](https://arxiv.org/abs/2508.11365)
*Jayanta Mandi,Ali İrfan Mahmutoğulları,Senne Berden,Tias Guns*

Main category: cs.LG

TL;DR: 决策聚焦学习（DFL）通过优化问题参数预测直接最小化决策后悔值，但梯度方法在LP问题中常为零。现有方法通过平滑或替代损失解决，本文提出即使使用可微优化层，替代损失仍更优，实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 解决梯度方法在LP问题中梯度为零的问题，提升决策质量。

Method: 提出即使使用可微优化层，仍最小化替代损失，并结合DYS-Net高效计算。

Result: 替代损失方法在后悔值和训练时间上均优于现有方法。

Conclusion: 替代损失结合可微优化层是DFL的有效方法，显著提升效率与效果。

Abstract: Decision-focused learning (DFL) trains a machine learning (ML) model to
predict parameters of an optimization problem, to directly minimize decision
regret, i.e., maximize decision quality. Gradient-based DFL requires computing
the derivative of the solution to the optimization problem with respect to the
predicted parameters. However, for many optimization problems, such as linear
programs (LPs), the gradient of the regret with respect to the predicted
parameters is zero almost everywhere. Existing gradient-based DFL approaches
for LPs try to circumvent this issue in one of two ways: (a) smoothing the LP
into a differentiable optimization problem by adding a quadratic regularizer
and then minimizing the regret directly or (b) minimizing surrogate losses that
have informative (sub)gradients. In this paper, we show that the former
approach still results in zero gradients, because even after smoothing the
regret remains constant across large regions of the parameter space. To address
this, we propose minimizing surrogate losses -- even when a differentiable
optimization layer is used and regret can be minimized directly. Our
experiments demonstrate that minimizing surrogate losses allows differentiable
optimization layers to achieve regret comparable to or better than
surrogate-loss based DFL methods. Further, we demonstrate that this also holds
for DYS-Net, a recently proposed differentiable optimization technique for LPs,
that computes approximate solutions and gradients through operations that can
be performed using feedforward neural network layers. Because DYS-Net executes
the forward and the backward pass very efficiently, by minimizing surrogate
losses using DYS-Net, we are able to attain regret on par with the
state-of-the-art while reducing training time by a significant margin.

</details>


### [174] [A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting](https://arxiv.org/abs/2508.11390)
*Michael Banf,Dominik Filipiak,Max Schattauer,Liliya Imasheva*

Main category: cs.LG

TL;DR: 论文提出了一种基于Forman-Ricci曲率的结构提升策略，用于解决图神经网络中长距离信息传递的失真问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的复杂系统（如社交或生物网络）需要更高阶的拓扑结构来表示，而传统图神经网络难以有效处理这些结构。

Method: 利用Forman-Ricci曲率定义边基网络特性，将数据从基本图形式提升为更高阶拓扑结构，再应用图神经网络进行学习。

Result: 该方法揭示了图的局部和全局特性（如网络骨干），并通过超边建模信息流，缓解了长距离信息传递中的过压缩问题。

Conclusion: 通过几何和拓扑深度学习的提升策略，有效改善了图神经网络在高阶结构数据上的表现。

Abstract: Graph Neural Networks are highly effective at learning from relational data,
leveraging node and edge features while maintaining the symmetries inherent to
graph structures. However, many real-world systems, such as social or
biological networks, exhibit complex interactions that are more naturally
represented by higher-order topological domains. The emerging field of
Geometric and Topological Deep Learning addresses this challenge by introducing
methods that utilize and benefit from higher-order structures. Central to TDL
is the concept of lifting, which transforms data representations from basic
graph forms to more expressive topologies before the application of GNN models
for learning. In this work, we propose a structural lifting strategy using
Forman-Ricci curvature, which defines an edge-based network characteristic
based on Riemannian geometry. Curvature reveals local and global properties of
a graph, such as a network's backbones, i.e. coarse, structure-preserving graph
geometries that form connections between major communities - most suitably
represented as hyperedges to model information flows between clusters across
large distances in the network. To this end, our approach provides a remedy to
the problem of information distortion in message passing across long distances
and graph bottlenecks - a phenomenon known in graph learning as over-squashing.

</details>


### [175] [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)
*Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: CHORD框架通过动态权重统一SFT和RL，避免破坏模型模式并减少过拟合，实验证明其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法整合SFT和RL时可能破坏模型模式并过拟合专家数据，需一种更稳定的统一方法。

Method: 提出CHORD框架，将SFT作为动态加权辅助目标融入RL过程，采用全局系数和令牌级权重函数。

Result: 实验表明CHORD实现了稳定高效的学习过程，显著优于基线方法。

Conclusion: CHORD成功协调了离策略专家数据与在策略探索，为相关研究提供了新思路。

Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two
prominent post-training paradigms for refining the capabilities and aligning
the behavior of Large Language Models (LLMs). Existing approaches that
integrate SFT and RL often face the risk of disrupting established model
patterns and inducing overfitting to expert data. To address this, we present a
novel investigation into the unified view of SFT and RL through an off-policy
versus on-policy lens. We propose CHORD, a framework for the Controllable
Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic
Weighting, which reframes SFT not as a separate stage but as a dynamically
weighted auxiliary objective within the on-policy RL process. Based on an
analysis of off-policy expert data's influence at both holistic and granular
levels, we incorporate a dual-control mechanism in CHORD. Specifically, the
framework first employs a global coefficient to holistically guide the
transition from off-policy imitation to on-policy exploration, and then applies
a token-wise weighting function that enables granular learning from expert
tokens, which preserves on-policy exploration and mitigates disruption from
off-policy data. We conduct extensive experiments on widely used benchmarks,
providing empirical evidence that CHORD achieves a stable and efficient
learning process. By effectively harmonizing off-policy expert data with
on-policy exploration, CHORD demonstrates significant improvements over
baselines. We release the implementation at
https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to
inspire further research.

</details>


### [176] [Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space](https://arxiv.org/abs/2508.11424)
*Yinghua Yao,Yuangang Pan,Xixian Chen*

Main category: cs.LG

TL;DR: LEAD是一种基于共享潜在空间的抗体序列-结构协同设计框架，通过优化潜在代码提升开发性能，显著减少查询成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在原始数据空间中优化抗体CDR区域效率低下，导致高昂的评估成本。

Method: 提出LEAD框架，在共享潜在空间中协同优化序列和结构，并设计黑盒引导策略以处理非可微分属性评估器。

Result: LEAD在单目标和多目标优化中表现优异，查询消耗减少一半，性能超越基线方法。

Conclusion: LEAD通过潜在空间优化和黑盒策略，显著提升了抗体设计的效率和性能。

Abstract: Advancements in deep generative models have enabled the joint modeling of
antibody sequence and structure, given the antigen-antibody complex as context.
However, existing approaches for optimizing complementarity-determining regions
(CDRs) to improve developability properties operate in the raw data space,
leading to excessively costly evaluations due to the inefficient search
process. To address this, we propose LatEnt blAck-box Design (LEAD), a
sequence-structure co-design framework that optimizes both sequence and
structure within their shared latent space. Optimizing shared latent codes can
not only break through the limitations of existing methods, but also ensure
synchronization of different modality designs. Particularly, we design a
black-box guidance strategy to accommodate real-world scenarios where many
property evaluators are non-differentiable. Experimental results demonstrate
that our LEAD achieves superior optimization performance for both single and
multi-property objectives. Notably, LEAD reduces query consumption by a half
while surpassing baseline methods in property optimization. The code is
available at https://github.com/EvaFlower/LatEnt-blAck-box-Design.

</details>


### [177] [Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity](https://arxiv.org/abs/2508.11436)
*Mayssa Soussia,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

TL;DR: 论文提出了一种名为mCOCO的新框架，用于生成连接性脑模板（CBT），解决了现有方法在可解释性、计算成本和认知能力建模方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有CBT学习方法（如机器学习和图神经网络）存在黑盒性质、高计算成本及忽视认知能力的问题。

Method: mCOCO利用储层计算（RC）从BOLD信号中学习群体级功能CBT，并通过多感官输入增强认知能力。

Result: mCOCO在中心性、区分性、拓扑合理性和多感官记忆保留方面显著优于基于GNN的CBT。

Conclusion: mCOCO为功能连接研究提供了一种高效且可解释的新方法，同时整合了认知能力建模。

Abstract: The generation of connectional brain templates (CBTs) has recently garnered
significant attention for its potential to identify unique connectivity
patterns shared across individuals. However, existing methods for CBT learning
such as conventional machine learning and graph neural networks (GNNs) are
hindered by several limitations. These include: (i) poor interpretability due
to their black-box nature, (ii) high computational cost, and (iii) an exclusive
focus on structure and topology, overlooking the cognitive capacity of the
generated CBT. To address these challenges, we introduce mCOCO (multi-sensory
COgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)
to learn population-level functional CBT from BOLD
(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow
for tracking state changes over time, enhancing interpretability and enabling
the modeling of brain-like dynamics, as demonstrated in prior literature. By
integrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO
captures not only structure and topology but also how brain regions process
information and adapt to cognitive tasks such as sensory processing, all in a
computationally efficient manner. Our mCOCO framework consists of two phases:
(1) mapping BOLD signals into the reservoir to derive individual functional
connectomes, which are then aggregated into a group-level CBT - an approach, to
the best of our knowledge, not previously explored in functional connectivity
studies - and (2) incorporating multi-sensory inputs through a cognitive
reservoir, endowing the CBT with cognitive traits. Extensive evaluations show
that our mCOCO-based template significantly outperforms GNN-based CBT in terms
of centeredness, discriminativeness, topological soundness, and multi-sensory
memory retention. Our source code is available at
https://github.com/basiralab/mCOCO.

</details>


### [178] [Informative Post-Hoc Explanations Only Exist for Simple Functions](https://arxiv.org/abs/2508.11441)
*Eric Günther,Balázs Szabados,Robi Bhattacharjee,Sebastian Bordt,Ulrike von Luxburg*

Main category: cs.LG

TL;DR: 论文提出了一种基于学习理论的框架，用于定义解释算法是否提供决策函数信息，并证明许多流行算法在复杂模型下不具信息性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于验证局部后解释算法是否能真正揭示复杂机器学习模型的行为，并填补理论保证的空白。

Method: 通过引入一个基于学习理论的框架，定义“信息性解释”为减少可能决策函数空间的复杂性。

Result: 结果显示许多流行解释算法（如梯度解释、SHAP等）在复杂模型下不具信息性，并提出了修改条件。

Conclusion: 结论指出该分析对AI审计、监管和高风险应用具有重要实践意义。

Abstract: Many researchers have suggested that local post-hoc explanation algorithms
can be used to gain insights into the behavior of complex machine learning
models. However, theoretical guarantees about such algorithms only exist for
simple decision functions, and it is unclear whether and under which
assumptions similar results might exist for complex models. In this paper, we
introduce a general, learning-theory-based framework for what it means for an
explanation to provide information about a decision function. We call an
explanation informative if it serves to reduce the complexity of the space of
plausible decision functions. With this approach, we show that many popular
explanation algorithms are not informative when applied to complex decision
functions, providing a rigorous mathematical rejection of the idea that it
should be possible to explain any model. We then derive conditions under which
different explanation algorithms become informative. These are often stronger
than what one might expect. For example, gradient explanations and
counterfactual explanations are non-informative with respect to the space of
differentiable functions, and SHAP and anchor explanations are not informative
with respect to the space of decision trees. Based on these results, we discuss
how explanation algorithms can be modified to become informative. While the
proposed analysis of explanation algorithms is mathematical, we argue that it
holds strong implications for the practical applicability of these algorithms,
particularly for auditing, regulation, and high-risk applications of AI.

</details>


### [179] [Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models](https://arxiv.org/abs/2508.11460)
*Aurora Grefsrud,Nello Blaser,Trygve Buanes*

Main category: cs.LG

TL;DR: 本文研究了六种概率机器学习算法在分类概率和不确定性估计中的表现，发现深度学习算法在分布外数据上的不确定性估计存在不足。


<details>
  <summary>Details</summary>
Motivation: 随着数据模型复杂度增加（如深度学习），不确定性量化变得困难，需要验证不同算法的表现。

Method: 采用近似贝叶斯推断框架，在合成分类数据集上测试六种算法（包括神经网络集成、证据深度学习等）。

Result: 所有算法校准良好，但深度学习算法在分布外数据上的不确定性估计不一致。

Conclusion: 研究为开发新的不确定性估计方法提供了参考，凸显了深度学习算法在分布外数据上的局限性。

Abstract: Rigorous statistical methods, including parameter estimation with
accompanying uncertainties, underpin the validity of scientific discovery,
especially in the natural sciences. With increasingly complex data models such
as deep learning techniques, uncertainty quantification has become exceedingly
difficult and a plethora of techniques have been proposed. In this case study,
we use the unifying framework of approximate Bayesian inference combined with
empirical tests on carefully created synthetic classification datasets to
investigate qualitative properties of six different probabilistic machine
learning algorithms for class probability and uncertainty estimation: (i) a
neural network ensemble, (ii) neural network ensemble with conflictual loss,
(iii) evidential deep learning, (iv) a single neural network with Monte Carlo
Dropout, (v) Gaussian process classification and (vi) a Dirichlet process
mixture model. We check if the algorithms produce uncertainty estimates which
reflect commonly desired properties, such as being well calibrated and
exhibiting an increase in uncertainty for out-of-distribution data points. Our
results indicate that all algorithms are well calibrated, but none of the deep
learning based algorithms provide uncertainties that consistently reflect lack
of experimental evidence for out-of-distribution data points. We hope our study
may serve as a clarifying example for researchers developing new methods of
uncertainty estimation for scientific data-driven modeling.

</details>


### [180] [Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection](https://arxiv.org/abs/2508.11504)
*Andrea Castellani,Zacharias Papadovasilakis,Giorgos Papoutsoglou,Mary Cole,Brian Bautsch,Tobias Rodemann,Ioannis Tsamardinos,Angela Harden*

Main category: cs.LG

TL;DR: 该研究通过AutoML和可解释AI方法，分析了俄亥俄州6年间的车祸数据，识别出17个关键风险因素，为减少严重车祸提供了数据支持。


<details>
  <summary>Details</summary>
Motivation: 全球范围内，车祸是导致伤亡的主要原因之一，需要数据驱动的方法来理解和减轻车祸严重性。

Method: 使用JADBio AutoML平台构建预测模型，结合SHAP解释模型输出，识别关键风险因素。

Result: 最终模型在训练集和测试集上的AUC-ROC分别为85.6%和84.9%，识别出17个最具影响力的特征。

Conclusion: 研究提供了一个可扩展的框架，支持通过数据驱动的干预措施和交通政策实现Vision Zero目标。

Abstract: Motor vehicle crashes remain a leading cause of injury and death worldwide,
necessitating data-driven approaches to understand and mitigate crash severity.
This study introduces a curated dataset of more than 3 million people involved
in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3
million vehicle-level records for predictive analysis. The primary contribution
is a transparent and reproducible methodology that combines Automated Machine
Learning (AutoML) and explainable artificial intelligence (AI) to identify and
interpret key risk factors associated with severe crashes. Using the JADBio
AutoML platform, predictive models were constructed to distinguish between
severe and non-severe crash outcomes. The models underwent rigorous feature
selection across stratified training subsets, and their outputs were
interpreted using SHapley Additive exPlanations (SHAP) to quantify the
contribution of individual features. A final Ridge Logistic Regression model
achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test
set, with 17 features consistently identified as the most influential
predictors. Key features spanned demographic, environmental, vehicle, human,
and operational categories, including location type, posted speed, minimum
occupant age, and pre-crash action. Notably, certain traditionally emphasized
factors, such as alcohol or drug impairment, were less influential in the final
model compared to environmental and contextual variables. Emphasizing
methodological rigor and interpretability over mere predictive performance,
this study offers a scalable framework to support Vision Zero with aligned
interventions and advanced data-informed traffic safety policy.

</details>


### [181] [Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies](https://arxiv.org/abs/2508.11513)
*Fanzhen Liu,Xiaoxiao Ma,Jian Yang,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Quan Z. Sheng,Jia Wu*

Main category: cs.LG

TL;DR: GraphOracle是一种新型自解释图神经网络框架，旨在生成和评估类级解释，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提升图神经网络（GNN）的可解释性，确保其安全公平部署，现有方法仅关注实例级解释，缺乏类级解释的验证。

Method: GraphOracle联合学习GNN分类器和稀疏子图，通过掩码评估策略验证图-子图-预测依赖关系。

Result: GraphOracle在忠实性、可解释性和可扩展性上优于ProtGNN和PGIB，避免了计算瓶颈。

Conclusion: GraphOracle为GNN提供了高效、可扩展的类级自解释解决方案。

Abstract: Enhancing the interpretability of graph neural networks (GNNs) is crucial to
ensure their safe and fair deployment. Recent work has introduced
self-explainable GNNs that generate explanations as part of training, improving
both faithfulness and efficiency. Some of these models, such as ProtGNN and
PGIB, learn class-specific prototypes, offering a potential pathway toward
class-level explanations. However, their evaluations focus solely on
instance-level explanations, leaving open the question of whether these
prototypes meaningfully generalize across instances of the same class. In this
paper, we introduce GraphOracle, a novel self-explainable GNN framework
designed to generate and evaluate class-level explanations for GNNs. Our model
jointly learns a GNN classifier and a set of structured, sparse subgraphs that
are discriminative for each class. We propose a novel integrated training that
captures graph$\unicode{x2013}$subgraph$\unicode{x2013}$prediction dependencies
efficiently and faithfully, validated through a masking-based evaluation
strategy. This strategy enables us to retroactively assess whether prior
methods like ProtGNN and PGIB deliver effective class-level explanations. Our
results show that they do not. In contrast, GraphOracle achieves superior
fidelity, explainability, and scalability across a range of graph
classification tasks. We further demonstrate that GraphOracle avoids the
computational bottlenecks of previous methods$\unicode{x2014}$like Monte Carlo
Tree Search$\unicode{x2014}$by using entropy-regularized subgraph selection and
lightweight random walk extraction, enabling faster and more scalable training.
These findings position GraphOracle as a practical and principled solution for
faithful class-level self-explainability in GNNs.

</details>


### [182] [DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality](https://arxiv.org/abs/2508.11514)
*Qitong Chu,Yufeng Yue,Danya Yao,Huaxin Pei*

Main category: cs.LG

TL;DR: 提出了一种双空间引导的测试框架，通过协调场景参数空间和智能体行为空间，生成兼顾多样性和关键性的测试场景。


<details>
  <summary>Details</summary>
Motivation: 动态环境中决策智能体的部署增加，对安全验证的需求上升，现有方法在平衡多样性和关键性方面存在挑战。

Method: 采用分层表示框架结合降维和多维子空间评估，在参数空间中定位关键子空间，并通过局部扰动和全局探索优化场景生成；在行为空间中利用交互数据量化行为关键性/多样性，支持生成模式切换。

Result: 实验表明，该框架在五种决策智能体上平均提高了56.23%的关键场景生成效率，并在新指标下表现出更高的多样性。

Conclusion: 双空间引导框架有效解决了高维场景空间中的局部最优问题，显著提升了测试场景的多样性和关键性。

Abstract: The growing deployment of decision-making agents in dynamic environments
increases the demand for safety verification. While critical testing scenario
generation has emerged as an appealing verification methodology, effectively
balancing diversity and criticality remains a key challenge for existing
methods, particularly due to local optima entrapment in high-dimensional
scenario spaces. To address this limitation, we propose a dual-space guided
testing framework that coordinates scenario parameter space and agent behavior
space, aiming to generate testing scenarios considering diversity and
criticality. Specifically, in the scenario parameter space, a hierarchical
representation framework combines dimensionality reduction and
multi-dimensional subspace evaluation to efficiently localize diverse and
critical subspaces. This guides dynamic coordination between two generation
modes: local perturbation and global exploration, optimizing critical scenario
quantity and diversity. Complementarily, in the agent behavior space,
agent-environment interaction data are leveraged to quantify behavioral
criticality/diversity and adaptively support generation mode switching, forming
a closed feedback loop that continuously enhances scenario characterization and
exploration within the parameter space. Experiments show our framework improves
critical scenario generation by an average of 56.23\% and demonstrates greater
diversity under novel parameter-behavior co-driven metrics when tested on five
decision-making agents, outperforming state-of-the-art baselines.

</details>


### [183] [Finite-Width Neural Tangent Kernels from Feynman Diagrams](https://arxiv.org/abs/2508.11522)
*Max Guillen,Philipp Misof,Jan E. Gerken*

Main category: cs.LG

TL;DR: 论文提出了一种用费曼图计算有限宽度修正的方法，以解决无限宽度下NTK无法捕捉训练动态的问题。


<details>
  <summary>Details</summary>
Motivation: 无限宽度下的NTK无法体现训练中的关键特性（如NTK演化或特征学习），而有限宽度效应需通过修正高斯统计量来引入。

Method: 引入费曼图计算有限宽度修正，简化代数操作，并支持任意统计量的层间递归关系计算。

Result: 扩展了深度网络的稳定性结果，证明了ReLU等尺度不变非线性在NTK Gram矩阵对角线上无有限宽度修正。

Conclusion: 通过数值实验验证了方法的可行性，为有限宽度下的NTK分析提供了新工具。

Abstract: Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,
non-linear neural networks. In the infinite-width limit, NTKs can easily be
computed for most common architectures, yielding full analytic control over the
training dynamics. However, at infinite width, important properties of training
such as NTK evolution or feature learning are absent. Nevertheless, finite
width effects can be included by computing corrections to the Gaussian
statistics at infinite width. We introduce Feynman diagrams for computing
finite-width corrections to NTK statistics. These dramatically simplify the
necessary algebraic manipulations and enable the computation of layer-wise
recursive relations for arbitrary statistics involving preactivations, NTKs and
certain higher-derivative tensors (dNTK and ddNTK) required to predict the
training dynamics at leading order. We demonstrate the feasibility of our
framework by extending stability results for deep networks from preactivations
to NTKs and proving the absence of finite-width corrections for scale-invariant
nonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We
validate our results with numerical experiments.

</details>


### [184] [Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2508.11528)
*Juhi Soni,Markus Lange-Hegermann,Stefan Windmann*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息扩散模型的无监督异常检测方法，用于多元时间序列数据。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在时间序列领域的预测、填补、生成和异常检测中表现出色，但如何结合物理信息提升性能仍需探索。

Method: 在扩散模型训练中使用加权物理信息损失，通过静态权重调度学习物理依赖的时间分布。

Result: 实验表明，物理信息训练提高了异常检测的F1分数，生成数据多样性和对数似然性更好，优于基线方法和现有物理信息模型。

Conclusion: 该方法在合成和真实数据集上表现优异，尤其在合成数据集和部分真实数据集上超越现有方法。

Abstract: We propose an unsupervised anomaly detection approach based on a
physics-informed diffusion model for multivariate time series data. Over the
past years, diffusion model has demonstrated its effectiveness in forecasting,
imputation, generation, and anomaly detection in the time series domain. In
this paper, we present a new approach for learning the physics-dependent
temporal distribution of multivariate time series data using a weighted
physics-informed loss during diffusion model training. A weighted
physics-informed loss is constructed using a static weight schedule. This
approach enables a diffusion model to accurately approximate underlying data
distribution, which can influence the unsupervised anomaly detection
performance. Our experiments on synthetic and real-world datasets show that
physics-informed training improves the F1 score in anomaly detection; it
generates better data diversity and log-likelihood. Our model outperforms
baseline approaches, additionally, it surpasses prior physics-informed work and
purely data-driven diffusion models on a synthetic dataset and one real-world
dataset while remaining competitive on others.

</details>


### [185] [A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow](https://arxiv.org/abs/2508.11529)
*George Paterakis,Andrea Castellani,George Papoutsoglou,Tobias Rodemann,Ioannis Tsamardinos*

Main category: cs.LG

TL;DR: 论文提出了一种名为HXAI的框架，旨在通过嵌入解释性到数据分析的每个阶段，解决AI模型的“黑箱”问题，并满足不同用户的需求。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型的解释性方法仅关注单个预测，忽略了上下游决策和质量检查，导致用户对AI的信任不足。

Method: HXAI框架整合了数据分析的六个组件，并通过问题库和用户调查，结合理论研究和实证研究，设计清晰、可操作的解释。

Result: HXAI提供了一个全面的分类法，减少了术语歧义，并展示了如何利用大型语言模型生成针对不同利益相关者的解释。

Conclusion: HXAI通过跨学科整合和实际项目经验，提出了一种端到端的透明、可信和负责任的AI部署视角。

Abstract: Artificial intelligence is reshaping science and industry, yet many users
still regard its models as opaque "black boxes". Conventional explainable
artificial-intelligence methods clarify individual predictions but overlook the
upstream decisions and downstream quality checks that determine whether
insights can be trusted. In this work, we present Holistic Explainable
Artificial Intelligence (HXAI), a user-centric framework that embeds
explanation into every stage of the data-analysis workflow and tailors those
explanations to users. HXAI unifies six components (data, analysis set-up,
learning process, model output, model quality, communication channel) into a
single taxonomy and aligns each component with the needs of domain experts,
data analysts and data scientists. A 112-item question bank covers these needs;
our survey of contemporary tools highlights critical coverage gaps. Grounded in
theories of human explanation, principles from human-computer interaction and
findings from empirical user studies, HXAI identifies the characteristics that
make explanations clear, actionable and cognitively manageable. A comprehensive
taxonomy operationalises these insights, reducing terminological ambiguity and
enabling rigorous coverage analysis of existing toolchains. We further
demonstrate how AI agents that embed large-language models can orchestrate
diverse explanation techniques, translating technical artifacts into
stakeholder-specific narratives that bridge the gap between AI developers and
domain experts. Departing from traditional surveys or perspective articles,
this work melds concepts from multiple disciplines, lessons from real-world
projects and a critical synthesis of the literature to advance a novel,
end-to-end viewpoint on transparency, trustworthiness and responsible AI
deployment.

</details>


### [186] [DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning](https://arxiv.org/abs/2508.11530)
*Lianshuai Guo,Zhongzheng Yuan,Xunkai Li,Yinlin Zhu,Meixia Qu,Wenyu Wang*

Main category: cs.LG

TL;DR: DFed-SST是一种去中心化的联邦图学习框架，通过自适应通信机制解决现有方法在局部子图拓扑信息处理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化联邦学习（DFL）优化策略未能处理局部子图的独特拓扑信息，而联邦图学习（FGL）多为集中式，无法发挥去中心化优势。

Method: 提出DFed-SST框架，采用双拓扑自适应通信机制，动态优化客户端间通信拓扑。

Result: 在八个真实数据集上，DFed-SST平均准确率比基线方法提高3.26%。

Conclusion: DFed-SST有效解决了异构性下的模型聚合问题，性能显著优于现有方法。

Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed
paradigm that circumvents the single-point-of-failure and communication
bottleneck risks of centralized architectures. However, a significant challenge
arises as existing DFL optimization strategies, primarily designed for tasks
such as computer vision, fail to address the unique topological information
inherent in the local subgraph. Notably, while Federated Graph Learning (FGL)
is tailored for graph data, it is predominantly implemented in a centralized
server-client model, failing to leverage the benefits of decentralization.To
bridge this gap, we propose DFed-SST, a decentralized federated graph learning
framework with adaptive communication. The core of our method is a
dual-topology adaptive communication mechanism that leverages the unique
topological features of each client's local subgraph to dynamically construct
and optimize the inter-client communication topology. This allows our framework
to guide model aggregation efficiently in the face of heterogeneity. Extensive
experiments on eight real-world datasets consistently demonstrate the
superiority of DFed-SST, achieving 3.26% improvement in average accuracy over
baseline methods.

</details>


### [187] [Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](https://arxiv.org/abs/2508.11542)
*Nicole Aretz,Karen Willcox*

Main category: cs.LG

TL;DR: 本文提出了一种数据驱动的嵌套算子推断方法（OpInf），用于从高维动态系统的快照数据中学习物理信息降阶模型（ROM）。该方法通过利用降阶空间中的层次结构，优先考虑主导模式的相互作用，从而在标准OpInf基础上显著降低误差。


<details>
  <summary>Details</summary>
Motivation: 高维动态系统的建模和仿真通常计算成本高昂，而传统的降阶模型方法在精度和效率上存在局限，因此需要一种更高效且精确的方法。

Method: 提出嵌套OpInf方法，利用降阶空间的层次结构迭代构建初始猜测，优先处理主导模式，并支持动态基和模型形式的更新。

Result: 在立方热传导问题中，嵌套OpInf的误差比标准OpInf小四倍；在格陵兰冰盖的大规模参数化模型中，平均误差为3%，计算加速因子超过19,000。

Conclusion: 嵌套OpInf方法显著提高了降阶模型的精度和计算效率，适用于动态基和模型更新的复杂场景。

Abstract: This paper presents a data-driven, nested Operator Inference (OpInf) approach
for learning physics-informed reduced-order models (ROMs) from snapshot data of
high-dimensional dynamical systems. The approach exploits the inherent
hierarchy within the reduced space to iteratively construct initial guesses for
the OpInf learning problem that prioritize the interactions of the dominant
modes. The initial guess computed for any target reduced dimension corresponds
to a ROM with provably smaller or equal snapshot reconstruction error than with
standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from
previously learned models, enabling versatile application scenarios involving
dynamic basis and model form updates. We demonstrate the performance of our
algorithm on a cubic heat conduction problem, with nested OpInf achieving a
four times smaller error than standard OpInf at a comparable offline time.
Further, we apply nested OpInf to a large-scale, parameterized model of the
Greenland ice sheet where, despite model form approximation errors, it learns a
ROM with, on average, 3% error and computational speed-up factor above 19,000.

</details>


### [188] [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)
*Jinghui Wang,Shaojie Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Xiaojiang Zhang,Minglei Zhang,Jiarong Zhang,Wenhao Zhuang,Yuchen Cao,Wankang Bao,Haimo Li,Zheng Lin,Huiming Wang,Haoyang Huang,Zongxian Feng,Zizheng Zhan,Ken Deng,Wen Xiang,Huaixi Tang,Kun Wu,Mengtong Li,Mengfei Xie,Junyi Peng,Haotian Zhang,Bin Chen,Bing Yu*

Main category: cs.LG

TL;DR: SeamlessFlow是一个基于服务器的强化学习框架，解决了工业规模RL中的两个核心挑战：解耦RL训练与复杂代理执行流程，以及最大化GPU利用率。


<details>
  <summary>Details</summary>
Motivation: 工业规模RL中，训练与代理执行的耦合以及GPU资源利用率低是主要问题。

Method: SeamlessFlow通过数据平面解耦训练与代理，并引入标签驱动调度和时空复用管道优化资源利用。

Result: 框架实现了稳定性和高性能，适用于多代理和复杂RL任务。

Conclusion: SeamlessFlow为大规模RL部署提供了高效且稳定的解决方案。

Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL)
framework that addresses two core challenges in industrial scale RL: (1)
decoupling RL training from the complex execution flow of agents; (2)
maximizing GPU utilization with minimal idle time while preserving the
stability and scalability required for large-scale deployments. First,
SeamlessFlow introduces a data plane that decouples the RL trainer from
diverse, complex agent implementations while sustaining high throughput. A
central trajectory manager maintains complete interaction histories and
supports partial rollout, allowing rollout to pause for weight updates and
resume seamlessly, keeping agents unaware of service interruptions. Second, we
propose a tag driven scheduling paradigm that abstracts hardware into
capability tagged resources, unifying colocated and disaggregated
architectures. Based on this, SeamlessFlow introduces a spatiotemporal
multiplexing pipeline that dynamically reassigns idle training nodes to rollout
in a train rollout separated setup, eliminating pipeline bubbles and fully
exploiting heterogeneous cluster resources. By combining these innovations,
SeamlessFlow delivers both stability and high performance, making it well
suited for multi agent, long horizon, and other complex RL tasks.

</details>


### [189] [Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective](https://arxiv.org/abs/2508.11618)
*Jungang Chen,Seyyed A. Hosseini*

Main category: cs.LG

TL;DR: 论文探讨了碳捕集与封存（CCS）项目中多利益相关者的合作问题，提出了一种基于马尔可夫博弈的框架，结合多智能体强化学习，以优化管理策略。


<details>
  <summary>Details</summary>
Motivation: CCS项目涉及多方利益相关者，各自目标不同且地质条件复杂，独立优化难以实现，需研究合作模式的有效性。

Method: 采用马尔可夫博弈框架和多智能体强化学习，结合安全约束，利用E2C框架的替代模型降低计算成本。

Result: 提出的框架能有效优化多利益相关者参与的CO2封存管理策略。

Conclusion: 合作模式在CCS项目中至关重要，提出的方法为多利益相关者协作提供了定量分析工具。

Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array
of stakeholders or players from public, private, and regulatory sectors, each
with different objectives and responsibilities. Given the complexity, scale,
and long-term nature of CCS operations, determining whether individual
stakeholders can independently maximize their interests or whether
collaborative coalition agreements are needed remains a central question for
effective CCS project planning and management. CCS projects are often
implemented in geologically connected sites, where shared geological features
such as pressure space and reservoir pore capacity can lead to competitive
behavior among stakeholders. Furthermore, CO2 storage sites are often located
in geologically mature basins that previously served as sites for hydrocarbon
extraction or wastewater disposal in order to leverage existing
infrastructures, which makes unilateral optimization even more complicated and
unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively
investigate how different coalition structures affect the goals of
stakeholders. We frame this multi-stakeholder multi-site problem as a
multi-agent reinforcement learning problem with safety constraints. Our
approach enables agents to learn optimal strategies while compliant with safety
regulations. We present an example where multiple operators are injecting CO2
into their respective project areas in a geologically connected basin. To
address the high computational cost of repeated simulations of high-fidelity
models, a previously developed surrogate model based on the Embed-to-Control
(E2C) framework is employed. Our results demonstrate the effectiveness of the
proposed framework in addressing optimal management of CO2 storage when
multiple stakeholders with various objectives and goals are involved.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [190] [Overview of Complex System Design](https://arxiv.org/abs/2508.11026)
*John W. Sheppard*

Main category: eess.SY

TL;DR: 本章介绍了系统工程，重点关注复杂集成系统的实现及其复杂性管理。


<details>
  <summary>Details</summary>
Motivation: 探讨如何定义和理解系统，以及如何实现和管理复杂集成系统。

Method: 通过定义系统、分析集成需求、探讨复杂性及其管理方法，以及描述系统从概念到部署的全生命周期。

Result: 提出了系统的多维度定义和复杂性衡量标准，并强调了实现复杂系统的全生命周期管理。

Conclusion: 系统工程的核心在于理解和管理复杂集成系统，以实现其从概念到部署的全过程。

Abstract: This chapter serves as an introduction to systems engineering focused on the
broad issues surrounding realizing complex integrated systems. What is a
system? We pose a number of possible definitions and perspectives, but leave
open the opportunity to consider the system from the target context where it
will be used. Once we have a system in mind, we acknowledge the fact that this
system needs to integrate a variety of pieces, components, subsystems, in order
for it to accomplish its task. Therefore, we concern ourselves at the
boundaries and interfaces of different technologies and disciplines to
determine how best to achieve that integration. Next we raise the specter that
this integrated system is complex. Complexity can be defined in a number of
ways. For one, the sheer number of subsystems or components can be a measure of
complexity. We could also consider the functions being performed by the system
and how those functions interact with one another. Further, we could consider
computational aspects such as the time or memory that may be needed to
accomplish one or more tasks. The extent to which new behaviors might emerge
from the system can also be regarded as an element of complexity. In the end,
complexity is that characteristic of a system that defines the associated
challenges along the life of the system, so we are concerned with how to manage
that complexity. Finally, realization refers to the process by which our
complex integrated system moves from concept to deployment and subsequent
support. It refers to the entire design, development, manufacture, deployment,
operation, and support life cycle. Of particular note here, however, is that we
focus on systems that, by their very nature, are complex. In other words, we
are interested in large, complicated, interacting beasts that are intended to
perform difficult tasks and meet a wide variety of end-user needs.

</details>


### [191] [Risk-Based Prognostics and Health Management](https://arxiv.org/abs/2508.11031)
*John W. Sheppard*

Main category: eess.SY

TL;DR: 本文提出了一种基于风险的方法，将风险评估与故障预测更紧密地结合，使用连续时间贝叶斯网络作为建模框架，并介绍了相关技术和实际应用。


<details>
  <summary>Details</summary>
Motivation: 解决风险评估与故障预测分离的问题，提供更紧密的耦合方法。

Method: 采用连续时间贝叶斯网络作为建模框架，介绍从数据推导模型的技术。

Result: 展示了该方法在决策支持和性能后勤等实际任务中的应用。

Conclusion: 本文旨在概述基于风险的预测的最新进展，并希望作为教程帮助他人采用这些技术。

Abstract: It is often the case that risk assessment and prognostics are viewed as
related but separate tasks. This chapter describes a risk-based approach to
prognostics that seeks to provide a tighter coupling between risk assessment
and fault prediction. We show how this can be achieved using the
continuous-time Bayesian network as the underlying modeling framework.
Furthermore, we provide an overview of the techniques that are available to
derive these models from data and show how they might be used in practice to
achieve tasks like decision support and performance-based logistics. This work
is intended to provide an overview of the recent developments related to
risk-based prognostics, and we hope that it will serve as a tutorial of sorts
that will assist others in adopting these techniques.

</details>


### [192] [A Neural Column-and-Constraint Generation Method for Solving Two-Stage Stochastic Unit Commitment](https://arxiv.org/abs/2508.11071)
*Zhentong Shao,Jingtao Qin,Nanpeng Yu*

Main category: eess.SY

TL;DR: 提出了一种基于神经网络的列与约束生成方法（Neural CCG），显著加速了两阶段随机机组组合问题的求解。


<details>
  <summary>Details</summary>
Motivation: 传统分解算法（如列与约束生成）在大规模实时应用中计算成本过高，难以应对高比例间歇性可再生能源带来的不确定性。

Method: 通过神经网络学习运行场景和第一阶段决策的高层特征，近似第二阶段问题，嵌入CCG框架以替代重复子问题求解。

Result: 在IEEE 118节点系统中，Neural CCG比传统CCG和商业求解器快130.1倍，最优性差距均值低于0.096%。

Conclusion: Neural CCG展示了在电力系统中可扩展随机优化的强大潜力。

Abstract: Two-stage stochastic unit commitment (2S-SUC) problems have been widely
adopted to manage the uncertainties introduced by high penetrations of
intermittent renewable energy resources. While decomposition-based algorithms
such as column-and-constraint generation has been proposed to solve these
problems, they remain computationally prohibitive for large-scale, real-time
applications. In this paper, we introduce a Neural Column-and-Constraint
Generation (Neural CCG) method to significantly accelerate the solution of
2S-SUC problems. The proposed approach integrates a neural network that
approximates the second-stage recourse problem by learning from high-level
features of operational scenarios and the first-stage commitment decisions.
This neural estimator is embedded within the CCG framework, replacing repeated
subproblem solving with rapid neural evaluations. We validate the effectiveness
of the proposed method on the IEEE 118-bus system. Compared to the original CCG
and a state-of-the-art commercial solver, Neural CCG achieves up to
130.1$\times$ speedup while maintaining a mean optimality gap below 0.096\%,
demonstrating its strong potential for scalable stochastic optimization in
power system.

</details>


### [193] [Managing Risks from Large Digital Loads Using Coordinated Grid-Forming Storage Network](https://arxiv.org/abs/2508.11080)
*Soumya Kundu,Kaustav Chatterjee,Ramij R. Hossain,Sai Pushpak Nandanoori,Veronica Adetola*

Main category: eess.SY

TL;DR: 论文探讨了如何通过协调电网中的储能单元来稳定AI数据中心带来的电力波动，避免昂贵的电网升级。


<details>
  <summary>Details</summary>
Motivation: AI数据中心的快速增长导致电力需求波动加剧，威胁电网稳定性，传统方法成本高或效果有限。

Method: 采用双层协调控制策略，结合快速本地控制和慢速协调控制，比较分布式储能与集中式储能的方案。

Result: 研究表明，协调储能单元可以有效管理AI数据中心的电力波动，无需大规模电网升级。

Conclusion: 通过智能协调储能，可以经济高效地解决AI数据中心对电网的挑战。

Abstract: Anticipated rapid growth of large digital load, driven by artificial
intelligence (AI) data centers, is poised to increase uncertainty and large
fluctuations in consumption, threatening the stability, reliability, and
security of the energy infrastructure. Conventional measures taken by grid
planners and operators to ensure stable and reliable integration of new
resources are either cost-prohibitive (e.g., transmission upgrades) or
ill-equipped (e.g., generation control) to resolve the unique challenges
brought on by AI Data Centers (e.g., extreme load transients). In this work, we
explore the feasibility of coordinating and managing available flexibility in
the grid, in terms of grid-forming storage units, to ensure stable and reliable
integration of AI Data Centers without the need for costly grid upgrades.
Recently developed bi-layered coordinated control strategies -- involving
fast-acting, local, autonomous, control at the storage to maintain transient
safety in voltage and frequency at the point-of-interconnection, and a slower,
coordinated (consensus) control to restore normal operating condition in the
grid -- are used in the case studies. A comparison is drawn between broadly two
scenarios: a network of coordinated, smaller, distributed storage vs. larger
storage installations collocated with large digital loads. IEEE 68-bus network
is used for the case studies, with large digital load profiles drawn from the
MIT Supercloud Dataset.

</details>


### [194] [Direct data-driven interpolation and approximation of linear parameter-varying system trajectories](https://arxiv.org/abs/2508.11332)
*Chris Verhoek,Ivan Markovsky,Roland Tóth*

Main category: eess.SY

TL;DR: 提出了一种数据驱动的算法，用于估计线性参数变化（LPV）系统中轨迹缺失值的插值问题，适用于移位仿射LPV系统。


<details>
  <summary>Details</summary>
Motivation: 解决LPV系统中轨迹缺失值的估计问题，特别是在数据生成系统未通过参数模型明确给出的情况下。

Method: 提出了一个直接数据驱动的算法，给出了解的存在性和唯一性条件。

Result: 通过质量-弹簧-阻尼系统的示例验证了算法的适用性。

Conclusion: 该方法为LPV系统中缺失值的插值提供了一种有效的解决方案。

Abstract: We consider the problem of estimating missing values in trajectories of
linear parameter-varying (LPV) systems. We solve this interpolation problem for
the class of shifted-affine LPV systems. Conditions for the existence and
uniqueness of solutions are given and a direct data-driven algorithm for its
computation is presented, i.e., the data-generating system is not given by a
parametric model but is implicitly specified by data. We illustrate the
applicability of the proposed solution on illustrative examples of a
mass-spring-damper system with exogenous and endogenous parameter variation.

</details>


### [195] [System Synchronization Based on Complex Frequency](https://arxiv.org/abs/2508.11381)
*Yusen Wei,Lan Tang*

Main category: eess.SY

TL;DR: 本文提出了一种基于复频率同步的理论-仿真分析框架，用于解决高比例可再生能源导致的惯性下降问题，统一了频率和电压的动态耦合行为分析。


<details>
  <summary>Details</summary>
Motivation: 高比例可再生能源导致电力系统惯性下降，传统仅依赖频率一致性的同步准则不足以描述频率和电压在暂态过程中的耦合行为。

Method: 详细介绍了复频率同步的基本概念和理论基础，推导了局部和全局动态同步准则，并引入了广义惯性概念。

Result: 通过IEEE 9节点系统的数值案例验证了所提理论和准则的有效性，并展示了关键指标的可视化流程。

Conclusion: 复频率同步理论为低惯性电力系统的稳态和暂态分析提供了新视角，广义惯性概念统一了频率和电压的惯性支持。

Abstract: In response to the inertia decline caused by high penetration of renewable
generation, traditional synchronization criteria that rely solely on frequency
consistency are increasingly inadequate for characterizing the coupled behavior
of frequency and voltage dynamics during power-system transients. This paper
focuses on the theory of complex-frequency synchronization and develops a
theory-simulation analysis framework that offers a new perspective for
steady-state and transient analysis of low-inertia power systems. First, the
fundamental concepts and theoretical foundations of complex-frequency
synchronization are presented in detail. Second, local and global dynamic
synchronization criteria are derived and the concept of generalized inertia is
introduced, which unifies the conventional inertial support to frequency with
the inertia-like support of voltage, thereby providing an accurate measure of
region-level coupled support strength for voltage and frequency. Finally,
numerical case studies on the IEEE 9-bus system validate the effectiveness of
the proposed theoretical methods and criteria, and demonstrate a visualization
workflow for key indicators such as disturbance impact zones and
generalized-inertia regions.

</details>


### [196] [Principles of Physiological Closed-Loop Controllers in Neuromodulation](https://arxiv.org/abs/2508.11422)
*Victoria S. Marks,Joram vanRheede,Dean Karantonis,Rosana Esteller,David Dinsmoor,John Fleming,Barrett Larson,Lane Desborough,Peter Single,Robert Raike,Pierre-Francois DHaese,Dario J. Englot,Scott Lempka,Richard North,Lawrence Poree,Marom Bikson,Tim J. Denison*

Main category: eess.SY

TL;DR: 本文提出了一个通用框架，用于映射当前和计划的神经调控生理闭环控制器（PCLCs），整合了FDA的技术指南、反馈/前馈生物标志物分类及控制系统理论，并阐述了风险管理及其应用。


<details>
  <summary>Details</summary>
Motivation: 随着神经调控设备闭环功能的增加，设计复杂性带来了更高的风险管理需求和优化效益的特殊考虑。本文旨在为PCLCs领域提供标准化指导。

Method: 创建了一个通用框架，整合FDA指南、生物标志物分类和控制系统理论，并应用于三种技术示例。

Result: 提供了一个系统化的框架，用于PCLCs的开发、测试和实施，以降低风险。

Conclusion: 本文为神经调控PCLCs领域提供了标准化命名和系统化开发指南，有助于降低风险并推动技术发展。

Abstract: As neurostimulation devices increasingly incorporate closed-loop
functionality, the greater design complexity brings additional requirements for
risk management and special considerations to optimise benefit. This manuscript
creates a common framework upon which all current and planned
neuromodulation-based physiological closed-loop controllers (PCLCs) can be
mapped including integration of the Technical Considerations of Medical Devices
with Physiologic Closed-Loop Control Technology guidance published in 2023 by
the United States Food and Drug Administration (FDA), a classification of
feedback (reactive) and feedforward (predictive) biomarkers, and control
systems theory. We explain risk management in the context of this framework and
illustrate its applications for three exemplary technologies. This manuscript
serves as guidance to the emerging field of PCLCs in neuromodulation,
mitigating risk through standardized nomenclature and a systematic outline for
rigorous device development, testing, and implementation.

</details>


### [197] [Integrating Uncertainties for Koopman-Based Stabilization](https://arxiv.org/abs/2508.11533)
*Yicheng Lin,Bingxian Wu,Nan Bai,Zhiyong Sun,Yunxiao Ren,Chuanze Chen,Zhisheng Duan*

Main category: eess.SY

TL;DR: 本文提出了一个统一的框架，通过Koopman算子解决数据驱动控制中的鲁棒稳定问题，全面考虑了投影误差、估计误差和过程扰动三种不确定性。


<details>
  <summary>Details</summary>
Motivation: Koopman算子在数据驱动控制中应用广泛，但其理论基础尚不完善，本文旨在填补这一空白。

Method: 研究了直接和间接数据驱动控制方法。直接方法通过LMI设计提升状态反馈控制器；间接方法通过可转化为LMI的非线性矩阵不等式设计反馈控制器。

Result: 数值模拟验证了两种方法的有效性，展示了其理论和实用价值。

Conclusion: 本文为数据驱动控制提供了鲁棒稳定的统一框架，具有重要的理论和实践意义。

Abstract: Over the past decades, the Koopman operator has been widely applied in
data-driven control, yet its theoretical foundations remain underexplored. This
paper establishes a unified framework to address the robust stabilization
problem in data-driven control via the Koopman operator, fully accounting for
three uncertainties: projection error, estimation error, and process
disturbance. It comprehensively investigates both direct and indirect
data-driven control approaches, facilitating flexible methodology selection for
analysis and control. For the direct approach, considering process
disturbances, the lifted-state feedback controller, designed via a linear
matrix inequality (LMI), robustly stabilizes all lifted bilinear systems
consistent with noisy data. For the indirect approach requiring system
identification, the feedback controller, designed using a nonlinear matrix
inequality convertible to an LMI, ensures closed-loop stability under
worst-case process disturbances. Numerical simulations via cross-validation
validate the effectiveness of both approaches, highlighting their theoretical
significance and practical utility.

</details>


### [198] [Identification of Sub/Super-Synchronous Control Interaction Paths Using Dissipative Energy Flow](https://arxiv.org/abs/2508.11561)
*Kaustav Chatterjee,Sameer Nekkalapu,Sayak Mukherjee,Ramij Raja Hossain,Marcelo Elizondo*

Main category: eess.SY

TL;DR: 论文扩展了耗散能量流（DEF）方法，用于识别多频率下的SSCI源和动态交互路径，通过dq框架和动态相量实现。


<details>
  <summary>Details</summary>
Motivation: SSCI涉及多频率和复杂路径，传统模型方法难以识别振荡源和能量流路径。

Method: 使用三相电压和电流测量，在dq框架中通过动态相量计算模式特定的DEF。

Result: 在电磁暂态案例中，DEF能区分频率相关的源和汇角色，同一资源在不同频率下可能既是源又是汇。

Conclusion: DEF为IBR丰富电网中的SSCI诊断提供了基于物理且自动化友好的工具。

Abstract: Sub- and super-synchronous control interactions (SSCIs) are oscillations
arising from adverse interactions between inverter-based resource (IBR)
controls and the power network. SSCIs often involve multiple frequencies and
propagate through complex, interconnected paths, making it difficult for
model-based approaches to identify both the sources and the paths of
oscillatory energy flow. This paper extends the Dissipative Energy Flow (DEF)
method, originally developed for low-frequency electromechanical oscillations,
to identify SSCI sources and dynamic interaction paths across multiple
frequencies using three-phase voltage and current measurements. The approach
operates in the dq frame using dynamic phasors, enabling mode-specific DEF
computation from bandpass-filtered signals. An electromagnetic transient (EMT)
case study on a meshed network with synchronous generator and type-3 wind farm
resources under series-compensated conditions demonstrates the method's
capability to distinguish frequency-dependent source and sink roles, including
cases where the same resource acts as a source at one frequency and a sink at
another. The results show DEF can provide a physics-based and
automation-friendly tool for SSCI diagnosis in IBR-rich grids.

</details>


### [199] [Two-Impulse Trajectory Design in Two-Body Systems With Riemannian Geometry](https://arxiv.org/abs/2508.11612)
*Samuel G. Gessow,James Tseng,Eden Zafran,Brett T. Lopez*

Main category: eess.SY

TL;DR: 提出了一种利用黎曼几何生成受限二体系统中脉冲轨迹的新方法，将轨迹优化问题转化为几何问题，通过雅可比度量计算测地线，从而找到燃料最优转移轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法对初始猜测敏感且难以处理复杂系统（如含J2扰动的系统），因此需要一种更通用且高效的方法。

Method: 定义雅可比度量将动力学嵌入度量中，通过采样候选能量变化并计算测地线来寻找最优轨迹，避免了优化方法的局限性。

Result: 在开普勒系统和含J2扰动的系统中，该方法在最小ΔV问题上表现优于或等同于现有方法，且能处理复杂扰动。

Conclusion: 该方法具有通用性和高效性，能够处理复杂系统，为轨迹优化提供了新思路。

Abstract: This work presents a new method for generating impulsive trajectories in
restricted two-body systems by leveraging Riemannian geometry. The proposed
method transforms the standard trajectory optimization problem into a purely
geometric one that involves computing a set of geodesics for a suitable
Riemannian metric. This transformation is achieved by defining a metric,
specifically the Jacobi metric, that embeds the dynamics directly into the
metric, so any geodesic of the metric is also a dynamically feasible
trajectory. The method finds the fuel-optimal transfer trajectory by sampling
candidate energy ($\Delta V$) changes for different points on the current and
desired orbit, and efficiently computing and evaluating each candidate
geodesic, which are equivalent to candidate orbit transfer trajectories via the
Jacobi metric. The method bypasses the known issues of optimization-based
methods, e.g., sensitivity to the initial guess, and can be applied to more
complex two-body systems. The approach is demonstrated on the minimum-$\Delta
V$ two-impulse phase-free orbit transfer problem, first on a Keplerian system
and second on a system with a modeled $J_2$ perturbation. The proposed method
is shown to meet or exceed the state-of-the-art methods in the minimum-$\Delta
V$ problem in the Keplerian system. The generality and versatility of the
approach is demonstrated by seamlessly including the $J_2$ perturbation, a case
that many existing methods cannot handle. Numerical simulations and performance
comparisons showcase the effectiveness of the approach.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [200] [LayoutRectifier: An Optimization-based Post-processing for Graphic Design Layout Generation](https://arxiv.org/abs/2508.11177)
*I-Chao Shen,Ariel Shamir,Takeo Igarashi*

Main category: cs.GR

TL;DR: 论文提出了一种基于优化的方法LayoutRectifier，用于修正自动生成的图形设计布局中的缺陷，如不对齐、重叠和不符合的包含关系。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法生成的布局常存在缺陷，影响设计质量，因此需要一种无需额外训练的优化方法来修正这些缺陷。

Method: 采用两阶段优化：首先利用网格系统通过离散搜索减少不对齐；其次引入新的盒子包含函数调整元素位置和大小，避免重叠并满足包含需求。

Result: 在内容无关和内容感知的布局生成任务中，LayoutRectifier生成了更高质量的布局，更适合下游设计任务。

Conclusion: LayoutRectifier有效补充了基于学习的布局生成方法，无需额外训练即可显著提升布局质量。

Abstract: Recent deep learning methods can generate diverse graphic design layouts
efficiently. However, these methods often create layouts with flaws, such as
misalignment, unwanted overlaps, and unsatisfied containment. To tackle this
issue, we propose an optimization-based method called LayoutRectifier, which
gracefully rectifies auto-generated graphic design layouts to reduce these
flaws while minimizing deviation from the generated layout. The core of our
method is a two-stage optimization. First, we utilize grid systems, which
professional designers commonly use to organize elements, to mitigate
misalignments through discrete search. Second, we introduce a novel box
containment function designed to adjust the positions and sizes of the layout
elements, preventing unwanted overlapping and promoting desired containment. We
evaluate our method on content-agnostic and content-aware layout generation
tasks and achieve better-quality layouts that are more suitable for downstream
graphic design tasks. Our method complements learning-based layout generation
methods and does not require additional training.

</details>


### [201] [StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation](https://arxiv.org/abs/2508.11203)
*Seungmi Lee,Kwan Yun,Junyong Noh*

Main category: cs.GR

TL;DR: StyleMM是一个基于文本描述的3D风格化变形模型框架，通过扩散模型生成风格化图像并保留原始面部属性，实现高质量的3D风格转换。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D风格化中难以同时保持面部属性和风格多样性，StyleMM旨在解决这一问题。

Method: 结合预训练的网格变形网络和纹理生成器，利用扩散模型生成风格化目标图像，并通过图像训练实现3D风格转换。

Result: 在面部多样性和风格化能力上优于现有方法，支持对形状、表情和纹理的显式控制。

Conclusion: StyleMM提供了一种高效且可控的3D风格化生成方法，适用于多样化的应用场景。

Abstract: We introduce StyleMM, a novel framework that can construct a stylized 3D
Morphable Model (3DMM) based on user-defined text descriptions specifying a
target style. Building upon a pre-trained mesh deformation network and a
texture generator for original 3DMM-based realistic human faces, our approach
fine-tunes these models using stylized facial images generated via text-guided
image-to-image (i2i) translation with a diffusion model, which serve as
stylization targets for the rendered mesh. To prevent undesired changes in
identity, facial alignment, or expressions during i2i translation, we introduce
a stylization method that explicitly preserves the facial attributes of the
source image. By maintaining these critical attributes during image
stylization, the proposed approach ensures consistent 3D style transfer across
the 3DMM parameter space through image-based training. Once trained, StyleMM
enables feed-forward generation of stylized face meshes with explicit control
over shape, expression, and texture parameters, producing meshes with
consistent vertex connectivity and animatability. Quantitative and qualitative
evaluations demonstrate that our approach outperforms state-of-the-art methods
in terms of identity-level facial diversity and stylization capability. The
code and videos are available at
[kwanyun.github.io/stylemm_page](kwanyun.github.io/stylemm_page).

</details>


### [202] [SPG: Style-Prompting Guidance for Style-Specific Content Creation](https://arxiv.org/abs/2508.11476)
*Qian Liang,Zichong Chen,Yang Zhou,Hui Huang*

Main category: cs.GR

TL;DR: 提出了Style-Prompting Guidance (SPG)，一种新的采样策略，用于生成特定风格的图像，通过构建风格噪声向量并利用其与无条件噪声的偏差来引导扩散过程。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的文本到图像扩散模型在生成与文本提示对齐的图像方面表现优异，但控制输出图像的视觉风格仍具挑战性。

Method: SPG通过构建风格噪声向量并利用其方向偏差引导扩散过程，结合Classifier-Free Guidance (CFG)实现语义保真和风格一致性。

Result: 实验证明SPG在风格生成方面具有高效性和通用性，优于现有方法。

Conclusion: SPG是一种简单、鲁棒且兼容性强的风格控制方法，适用于多种可控框架。

Abstract: Although recent text-to-image (T2I) diffusion models excel at aligning
generated images with textual prompts, controlling the visual style of the
output remains a challenging task. In this work, we propose Style-Prompting
Guidance (SPG), a novel sampling strategy for style-specific image generation.
SPG constructs a style noise vector and leverages its directional deviation
from unconditional noise to guide the diffusion process toward the target style
distribution. By integrating SPG with Classifier-Free Guidance (CFG), our
method achieves both semantic fidelity and style consistency. SPG is simple,
robust, and compatible with controllable frameworks like ControlNet and
IPAdapter, making it practical and widely applicable. Extensive experiments
demonstrate the effectiveness and generality of our approach compared to
state-of-the-art methods. Code is available at
https://github.com/Rumbling281441/SPG.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [203] [Perturbed Public Voices (P$^{2}$V): A Dataset for Robust Audio Deepfake Detection](https://arxiv.org/abs/2508.10949)
*Chongyang Gao,Marco Postiglione,Isabel Gortner,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.SD

TL;DR: 当前音频深度伪造检测器不可靠，P$^{2}$V数据集揭示其漏洞，并提出新基准。


<details>
  <summary>Details</summary>
Motivation: 现有检测器在真实世界中表现不佳，需更鲁棒的数据集和方法。

Method: 引入P$^{2}$V数据集，包含身份一致文本、环境噪声和先进语音克隆技术。

Result: 现有检测器在P$^{2}$V上性能下降43%，对抗扰动和克隆技术进一步降低检测能力。

Conclusion: P$^{2}$V为音频深度伪造检测提供了新基准，并展示了鲁棒性。

Abstract: Current audio deepfake detectors cannot be trusted. While they excel on
controlled benchmarks, they fail when tested in the real world. We introduce
Perturbed Public Voices (P$^{2}$V), an IRB-approved dataset capturing three
critical aspects of malicious deepfakes: (1) identity-consistent transcripts
via LLMs, (2) environmental and adversarial noise, and (3) state-of-the-art
voice cloning (2020-2025). Experiments reveal alarming vulnerabilities of 22
recent audio deepfake detectors: models trained on current datasets lose 43%
performance when tested on P$^{2}$V, with performance measured as the mean of
F1 score on deepfake audio, AUC, and 1-EER. Simple adversarial perturbations
induce up to 16% performance degradation, while advanced cloning techniques
reduce detectability by 20-30%. In contrast, P$^{2}$V-trained models maintain
robustness against these attacks while generalizing to existing datasets,
establishing a new benchmark for robust audio deepfake detection. P$^{2}$V will
be publicly released upon acceptance by a conference/journal.

</details>


### [204] [LD-LAudio-V1: Video-to-Long-Form-Audio Generation Extension with Dual Lightweight Adapters](https://arxiv.org/abs/2508.11074)
*Haomin Zhang,Kristin Qi,Shuxin Yang,Zihao Chen,Chaofan Ding,Xinhan Di*

Main category: cs.SD

TL;DR: 论文提出LD-LAudio-V1模型，通过双轻量适配器实现长视频音频生成，并发布高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长视频音频生成中的局限性，如短片段生成或依赖噪声数据。

Method: 扩展现有视频到音频模型，引入双轻量适配器，并发布干净标注的数据集。

Result: 显著减少拼接伪影和时间不一致性，多项指标显著提升。

Conclusion: LD-LAudio-V1在长视频音频生成中表现优异，数据集促进进一步研究。

Abstract: Generating high-quality and temporally synchronized audio from video content
is essential for video editing and post-production tasks, enabling the creation
of semantically aligned audio for silent videos. However, most existing
approaches focus on short-form audio generation for video segments under 10
seconds or rely on noisy datasets for long-form video-to-audio zsynthesis. To
address these limitations, we introduce LD-LAudio-V1, an extension of
state-of-the-art video-to-audio models and it incorporates dual lightweight
adapters to enable long-form audio generation. In addition, we release a clean
and human-annotated video-to-audio dataset that contains pure sound effects
without noise or artifacts. Our method significantly reduces splicing artifacts
and temporal inconsistencies while maintaining computational efficiency.
Compared to direct fine-tuning with short training videos, LD-LAudio-V1
achieves significant improvements across multiple metrics: $FD_{\text{passt}}$
450.00 $\rightarrow$ 327.29 (+27.27%), $FD_{\text{panns}}$ 34.88 $\rightarrow$
22.68 (+34.98%), $FD_{\text{vgg}}$ 3.75 $\rightarrow$ 1.28 (+65.87%),
$KL_{\text{panns}}$ 2.49 $\rightarrow$ 2.07 (+16.87%), $KL_{\text{passt}}$ 1.78
$\rightarrow$ 1.53 (+14.04%), $IS_{\text{panns}}$ 4.17 $\rightarrow$ 4.30
(+3.12%), $IB_{\text{score}}$ 0.25 $\rightarrow$ 0.28 (+12.00%),
$Energy\Delta10\text{ms}$ 0.3013 $\rightarrow$ 0.1349 (+55.23%),
$Energy\Delta10\text{ms(vs.GT)}$ 0.0531 $\rightarrow$ 0.0288 (+45.76%), and
$Sem.\,Rel.$ 2.73 $\rightarrow$ 3.28 (+20.15%). Our dataset aims to facilitate
further research in long-form video-to-audio generation and is available at
https://github.com/deepreasonings/long-form-video2audio.

</details>


### [205] [Benchmarking Prosody Encoding in Discrete Speech Tokens](https://arxiv.org/abs/2508.11224)
*Kentaro Onda,Satoru Fukayama,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.SD

TL;DR: 研究分析了自监督学习离散标记在语音语言模型中捕捉韵律信息的能力，并提出了设计离散标记的实用指南。


<details>
  <summary>Details</summary>
Motivation: 离散标记通常与语言模型或下游任务分离学习，导致离散化选择（如聚类数量）需启发式决定，且缺乏对韵律信息捕捉的研究。

Method: 通过分析离散标记对人工修改韵律的敏感性，评估其韵律编码能力。

Result: 研究提供了离散标记设计的具体建议。

Conclusion: 该研究填补了离散标记在韵律信息捕捉方面的研究空白，并为实际应用提供了指导。

Abstract: Recently, discrete tokens derived from self-supervised learning (SSL) models
via k-means clustering have been actively studied as pseudo-text in speech
language models and as efficient intermediate representations for various
tasks. However, these discrete tokens are typically learned in advance,
separately from the training of language models or downstream tasks. As a
result, choices related to discretization, such as the SSL model used or the
number of clusters, must be made heuristically. In particular, speech language
models are expected to understand and generate responses that reflect not only
the semantic content but also prosodic features. Yet, there has been limited
research on the ability of discrete tokens to capture prosodic information. To
address this gap, this study conducts a comprehensive analysis focusing on
prosodic encoding based on their sensitivity to the artificially modified
prosody, aiming to provide practical guidelines for designing discrete tokens.

</details>


### [206] [Mitigating Category Imbalance: Fosafer System for the Multimodal Emotion and Intent Joint Understanding Challenge](https://arxiv.org/abs/2508.11362)
*Honghong Wang,Yankai Wang,Dejun Zhang,Jing Deng,Rong Zheng*

Main category: cs.SD

TL;DR: Fosafer方法通过多模态数据增强、加权焦点对比损失和模态丢弃策略，解决了情感与意图联合识别中的类别不平衡问题，并在挑战赛中取得第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 解决多模态情感与意图联合识别中的类别不平衡问题，并提升对少数类和语义相似样本的识别能力。

Method: 采用多模态数据增强技术、加权焦点对比损失、Hubert模型微调、模态丢弃策略和多数投票法。

Result: 在Track 2 Mandarin挑战赛中取得第二名的成绩。

Conclusion: Fosafer方法有效解决了类别不平衡问题，提升了联合识别性能。

Abstract: This paper presents Fosafer approach to the Track 2 Mandarin in the
Multimodal Emotion and Intent Joint Understandingchallenge, which focuses on
achieving joint recognition of emotion and intent in Mandarin, despite the
issue of category imbalance. To alleviate this issue, we use a variety of data
augmentation techniques across text, video, and audio modalities. Additionally,
we introduce the SampleWeighted Focal Contrastive loss, designed to address the
challenges of recognizing minority class samples and those that are
semantically similar but difficult to distinguish. Moreover, we fine-tune the
Hubert model to adapt the emotion and intent joint recognition. To mitigate
modal competition, we introduce a modal dropout strategy. For the final
predictions, a plurality voting approach is used to determine the results. The
experimental results demonstrate the effectiveness of our method, which
achieves the second-best performance in the Track 2 Mandarin challenge.

</details>


### [207] [Speech Emotion Recognition Using Fine-Tuned DWFormer:A Study on Track 1 of the IERPChallenge 2024](https://arxiv.org/abs/2508.11371)
*Honghong Wang,Xupeng Jia,Jing Deng,Rong Zheng*

Main category: cs.SD

TL;DR: 该论文介绍了Fosafer团队在IERP Challenge 2024 Track 1中的工作，通过结合数据增强和分数融合策略，优化了预训练的语音情感识别模型DWFormer，最终获得第一名。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别模型主要关注离散情感标签预测的精度，而忽略了人格特质对情感表达的影响。IERP Challenge 2024将人格特质纳入研究，以探索更全面的情感识别方法。

Method: 团队在Track 1中仅使用音频特征，通过数据增强和分数融合策略对预训练模型DWFormer进行微调。

Result: 该方法在比赛中取得了第一名。

Conclusion: 结合人格特质和数据增强策略可以显著提升情感识别模型的性能。

Abstract: The field of artificial intelligence has a strong interest in the topic of
emotion recognition. The majority of extant emotion recognition models are
oriented towards enhancing the precision of discrete emotion label prediction.
Given the direct relationship between human personality and emotion, as well as
the significant inter-individual differences in subjective emotional
expression, the IERP Challenge 2024 incorporates personality traits into
emotion recognition research. This paper presents the Fosafer submissions to
the Track 1 of the IERP Challenge 2024. This task primarily concerns the
recognition of emotions in audio, while also providing text and audio features.
In Track 1, we utilized exclusively audio-based features and fine-tuned a
pre-trained speech emotion recognition model, DWFormer, through the integration
of data augmentation and score fusion strategies, thereby achieving the first
place among the participating teams.

</details>


### [208] [Pretrained Conformers for Audio Fingerprinting and Retrieval](https://arxiv.org/abs/2508.11609)
*Kemal Altwlkany,Elmedin Selmanovic,Sead Delalic*

Main category: cs.SD

TL;DR: 本文提出了一种基于自监督对比学习的Conformer编码器，用于生成音频片段的独特嵌入，在音频检索任务中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 利用Conformer在语音处理中的优势，结合自监督对比学习，提升音频片段嵌入的生成能力，以应对未见过数据的泛化问题。

Method: 采用自监督对比学习框架训练Conformer编码器，生成短音频片段的嵌入，并通过公开数据集进行训练和测试。

Result: 模型在音频检索任务中表现优异，仅需3秒音频即可生成嵌入，且对时间错位和其他音频失真（如噪声、混响）具有强鲁棒性。

Conclusion: 该方法在音频检索任务中实现了最先进性能，模型公开且结果易于复现。

Abstract: Conformers have shown great results in speech processing due to their ability
to capture both local and global interactions. In this work, we utilize a
self-supervised contrastive learning framework to train conformer-based
encoders that are capable of generating unique embeddings for small segments of
audio, generalizing well to previously unseen data. We achieve state-of-the-art
results for audio retrieval tasks while using only 3 seconds of audio to
generate embeddings. Our models are almost completely immune to temporal
misalignments and achieve state-of-the-art results in cases of other audio
distortions such as noise, reverb or extreme temporal stretching. Code and
models are made publicly available and the results are easy to reproduce as we
train and test using popular and freely available datasets of different sizes.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [209] [Allen: Rethinking MAS Design through Step-Level Policy Autonomy](https://arxiv.org/abs/2508.11294)
*Qiangong Zhou,Zhiting Wang,Mingyou Yao,Zongyang Liu*

Main category: cs.MA

TL;DR: Allen是一个新型多智能体系统（MAS），旨在提升策略自主性并平衡协作效率、任务监督和人工监督。


<details>
  <summary>Details</summary>
Motivation: 解决当前MAS设计中策略自主性不足和协作结构可控性之间的平衡问题。

Method: 重新定义MAS的基本执行单元，构建四层状态架构（任务、阶段、智能体、步骤）以实现拓扑优化和可控进度。

Result: Allen实现了前所未有的策略自主性，并在协作结构的可控性上取得了平衡。

Conclusion: Allen为复杂网络拓扑中的MAS设计提供了新的解决方案，代码已开源。

Abstract: We introduce a new Multi-Agent System (MAS) - Allen, designed to address two
core challenges in current MAS design: (1) improve system's policy autonomy,
empowering agents to dynamically adapt their behavioral strategies, and (2)
achieving the trade-off between collaborative efficiency, task supervision, and
human oversight in complex network topologies.
  Our core insight is to redefine the basic execution unit in the MAS, allowing
agents to autonomously form different patterns by combining these units. We
have constructed a four-tier state architecture (Task, Stage, Agent, Step) to
constrain system behavior from both task-oriented and execution-oriented
perspectives. This achieves a unification of topological optimization and
controllable progress.
  Allen grants unprecedented Policy Autonomy, while making a trade-off for the
controllability of the collaborative structure. The project code has been open
source at: https://github.com/motern88/Allen

</details>


### [210] [Defending a City from Multi-Drone Attacks: A Sequential Stackelberg Security Games Approach](https://arxiv.org/abs/2508.11380)
*Dolev Mutzari,Tonmoay Deb,Cristian Molinaro,Andrea Pugliese,V. S. Subrahmanian,Sarit Kraus*

Main category: cs.MA

TL;DR: 论文提出了一种名为S2D2的高效算法，用于防御多无人机攻击，通过混合顺序防御策略提升防御效果。


<details>
  <summary>Details</summary>
Motivation: 针对城市面临的多无人机攻击威胁，需要开发一种高效的防御策略以减少潜在损害。

Method: 将问题建模为Sequential Stackelberg Security Game，开发了S2D2算法，生成防御策略。

Result: 在80个真实城市数据上的实验表明，S2D2优于基于贪心启发式的方法，并在特定假设下输出近似SSE。

Conclusion: S2D2算法在防御多无人机攻击中表现出色，为城市安全提供了有效解决方案。

Abstract: To counter an imminent multi-drone attack on a city, defenders have deployed
drones across the city. These drones must intercept/eliminate the threat, thus
reducing potential damage from the attack. We model this as a Sequential
Stackelberg Security Game, where the defender first commits to a mixed
sequential defense strategy, and the attacker then best responds. We develop an
efficient algorithm called S2D2, which outputs a defense strategy. We
demonstrate the efficacy of S2D2 in extensive experiments on data from 80 real
cities, improving the performance of the defender in comparison to greedy
heuristics based on prior works. We prove that under some reasonable
assumptions about the city structure, S2D2 outputs an approximate Strong
Stackelberg Equilibrium (SSE) with a convenient structure.

</details>


### [211] [Tapas are free! Training-Free Adaptation of Programmatic Agents via LLM-Guided Program Synthesis in Dynamic Environments](https://arxiv.org/abs/2508.11425)
*Jinwei Hu,Yi Dong,Youcheng Sun,Xiaowei Huang*

Main category: cs.MA

TL;DR: TAPA框架利用大型语言模型（LLM）动态生成和调整符号化程序，实现自主代理在安全关键应用中的高性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决自主代理在动态环境中适应性问题，避免性能与可靠性下降。

Method: 通过LLM作为智能调节器，分解高层动作为逻辑基元，动态生成和优化符号化程序。

Result: 在网络安全和群体智能领域实验中，TAPA表现优异，如DDoS防御中实现77.7%网络正常运行时间。

Conclusion: TAPA推动了自主系统设计从策略适应到动态动作适应的范式转变。

Abstract: Autonomous agents in safety-critical applications must continuously adapt to
dynamic conditions without compromising performance and reliability. This work
introduces TAPA (Training-free Adaptation of Programmatic Agents), a novel
framework that positions large language models (LLMs) as intelligent moderators
of the symbolic action space. Unlike prior programmatic agents that typically
generate a monolithic policy program or rely on fixed symbolic action sets,
TAPA synthesizes and adapts modular programs for individual high-level actions,
referred to as logical primitives. By decoupling strategic intent from
execution, TAPA enables meta-agents to operate over an abstract, interpretable
action space while the LLM dynamically generates, composes, and refines
symbolic programs tailored to each primitive. Extensive experiments across
cybersecurity and swarm intelligence domains validate TAPA's effectiveness. In
autonomous DDoS defense scenarios, TAPA achieves 77.7% network uptime while
maintaining near-perfect detection accuracy in unknown dynamic environments. In
swarm intelligence formation control under environmental and adversarial
disturbances, TAPA consistently preserves consensus at runtime where baseline
methods fail completely. This work promotes a paradigm shift for autonomous
system design in evolving environments, from policy adaptation to dynamic
action adaptation.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [212] [How do Data Journalists Design Maps to Tell Stories?](https://arxiv.org/abs/2508.10903)
*Arlindo Gomes,Emilly Brito,Luis Morais,Nivan Ferreira*

Main category: cs.HC

TL;DR: 研究探讨了新闻地图的设计空间和编辑团队的制作过程，通过分析462个新闻地图和采访数据记者，提出了包含八个维度的设计空间，并识别了常见的设计理由和实践中的不足。


<details>
  <summary>Details</summary>
Motivation: 新闻地图在传达空间背景和叙事中至关重要，但设计面临多重挑战，如美学、受众数据素养、时间限制和技术能力。研究旨在深入理解新闻地图的设计过程。

Method: 收集并分析了462个新闻地图，创建了包含八个维度的设计空间；通过半结构化访谈四位数据记者，识别设计理由和实践差距。

Result: 提出了新闻地图的设计空间，并验证了其外部有效性；揭示了编辑团队的常见设计理由和当前实践的不足。

Conclusion: 研究为新闻地图的设计和研究提供了实证数据，有助于改进新闻地图的制作和设计实践。

Abstract: Maps are essential to news media as they provide a familiar way to convey
spatial context and present engaging narratives. However, the design of
journalistic maps may be challenging, as editorial teams need to balance
multiple aspects, such as aesthetics, the audience's expected data literacy,
tight publication deadlines, and the team's technical skills. Data journalists
often come from multiple areas and lack a cartography, data visualization, and
data science background, limiting their competence in creating maps. While
previous studies have examined spatial visualizations in data stories, this
research seeks to gain a deeper understanding of the map design process
employed by news outlets. To achieve this, we strive to answer two specific
research questions: what is the design space of journalistic maps? and how do
editorial teams produce journalistic map articles? To answer the first one, we
collected and analyzed a large corpus of 462 journalistic maps used in news
articles from five major news outlets published over three months. As a result,
we created a design space comprised of eight dimensions that involved both
properties describing the articles' aspects and the visual/interactive features
of maps. We approach the second research question via semi-structured
interviews with four data journalists who create data-driven articles daily.
Through these interviews, we identified the most common design rationales made
by editorial teams and potential gaps in current practices. We also collected
the practitioners' feedback on our design space to externally validate it. With
these results, we aim to provide researchers and journalists with empirical
data to design and study journalistic maps.

</details>


### [213] [Designing for Engaging Communication Between Parents and Young Adult Children Through Shared Music Experiences](https://arxiv.org/abs/2508.10907)
*Euihyeok Lee,Souneil Park,Jin Yu,Seungchul Lee,Seungwoo Kang*

Main category: cs.HC

TL;DR: 该论文通过音乐促进异地生活的父母与成年子女的社交互动，开发了DJ-Fam应用，显著提升了沟通频率和多样性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在利用音乐增强父母与成年子女的日常互动，弥补因异地生活导致的沟通不足。

Method: 通过调查现有沟通需求及音乐互动体验，开发了DJ-Fam应用，并在韩国7个家庭中进行了为期4周的部署研究。

Result: DJ-Fam显著增加了沟通频率，拓宽了沟通渠道和话题，参与者满意度高。

Conclusion: DJ-Fam通过音乐有效促进了父母与子女的互动，改善了彼此的理解和关系。

Abstract: This paper aims to foster social interaction between parents and young adult
children living apart via music. Our approach transforms their music-listening
moment into an opportunity to listen to the other's favorite songs and enrich
interaction in their daily lives. To this end, we explore the current practice
and needs of parent-child communication and the experience and perception of
music-mediated interaction. Based on the findings, we developed DJ-Fam, a
mobile application that enables parents and children to listen to their
favorite songs and use them as conversation starters to foster parent-child
interaction. From our deployment study with seven families over four weeks in
South Korea, we show the potential of DJ-Fam to influence parent-child
interaction and their mutual understanding and relationship positively.
Specifically, DJ-Fam considerably increases the frequency of communication and
diversifies the communication channels and topics, all of which are
satisfactory to the participants.

</details>


### [214] [Uncovering Latent Connections in Indigenous Heritage: Semantic Pipelines for Cultural Preservation in Brazil](https://arxiv.org/abs/2508.10911)
*Luis Vitor Zerkowski,Nina S. T. Hirata*

Main category: cs.HC

TL;DR: 论文探讨了如何利用人工智能技术提升巴西原住民文化遗产的在线可访问性和互动性，通过视觉和文本语义分析增强用户体验。


<details>
  <summary>Details</summary>
Motivation: 原住民社区在文化传承中面临系统性边缘化和城市发展的挑战，需要技术手段支持文化遗产的保护与传播。

Method: 开发了两种语义分析管道（视觉和文本），并将其整合为交互式可视化工具，支持基于相似性、时间和地理的探索。

Result: 系统提升了文化遗产的访问和解读能力，支持策展任务和公众参与，揭示了藏品间的潜在联系。

Conclusion: 研究表明AI可以以伦理方式为文化保护实践做出贡献。

Abstract: Indigenous communities face ongoing challenges in preserving their cultural
heritage, particularly in the face of systemic marginalization and urban
development. In Brazil, the Museu Nacional dos Povos Indigenas through the
Tainacan platform hosts the country's largest online collection of Indigenous
objects and iconographies, providing a critical resource for cultural
engagement. Using publicly available data from this repository, we present a
data-driven initiative that applies artificial intelligence to enhance
accessibility, interpretation, and exploration. We develop two semantic
pipelines: a visual pipeline that models image-based similarity and a textual
pipeline that captures semantic relationships from item descriptions. These
embedding spaces are projected into two dimensions and integrated into an
interactive visualization tool we also developed. In addition to
similarity-based navigation, users can explore the collection through temporal
and geographic lenses, enabling both semantic and contextualized perspectives.
The system supports curatorial tasks, aids public engagement, and reveals
latent connections within the collection. This work demonstrates how AI can
ethically contribute to cultural preservation practices.

</details>


### [215] [Generation and Evaluation in the Human Invention Process through the Lens of Game Design](https://arxiv.org/abs/2508.10914)
*Katherine M. Collins,Graham Todd,Cedegao E. Zhang,Adrian Weller,Julian Togelius,Junyi Chu,Lionel Wong,Thomas L. Griffiths,Joshua B. Tenenbaum*

Main category: cs.HC

TL;DR: 研究探讨人类如何通过游戏设计创造新规则和问题，分析早期游戏设计中的认知机制，发现基于模型的质量评估是关键。


<details>
  <summary>Details</summary>
Motivation: 探索人类如何创造性地打破规则、设计新问题，以及如何评估这些创新。

Method: 分析450多个由新手设计的游戏，研究基于关联提议和模型评估的认知机制。

Result: 发现生成游戏的最佳描述是结合群体水平游戏质量评估的模型。

Conclusion: 人类创新不仅依赖提议，还依赖评估，研究为开放式创新提供了计算工具。

Abstract: The human ability to learn rules and solve problems has been a central
concern of cognitive science research since the field's earliest days. But we
do not just follow rules and solve problems given to us by others: we modify
those rules, create new problems, and set new goals and tasks for ourselves and
others. Arguably, even more than rule following and problem solving, human
intelligence is about creatively breaking and stretching the rules, changing
the game, and inventing new problems worth thinking about. Creating a good rule
or a good problem depends not just on the ideas one can think up but on how one
evaluates such proposals. Here, we study invention through the lens of game
design. We focus particularly on the early stages of novice, "everyday" game
creation, where the stakes are low. We draw on a dataset of over 450 human
created games, created by participants who saw an initial seed set of
two-player grid-based strategy games. We consider two different cognitive
mechanisms that may be at work during the early processes of intuitive game
invention: an associative proposal based on previous games one has seen and
compute-bounded model-based evaluation that an everyday game creator may use to
refine their initial draft proposals. In our preliminary work, we conduct a
model-based analysis of how people invented new games based on prior experience
and find that generated games are best described by a model which incorporates
model-based estimates of game quality at a population level. Our work points to
how human invention is based not only on what people propose, but how they
evaluate and offers a computational toolkit to scale empirical studies of
model-based simulation in open-ended human innovation.

</details>


### [216] [Multimodal Quantitative Measures for Multiparty Behaviour Evaluation](https://arxiv.org/abs/2508.10916)
*Ojas Shirekar,Wim Pouw,Chenxu Hao,Vrushank Phadnis,Thabo Beeler,Chirag Raman*

Main category: cs.HC

TL;DR: 论文提出了一种评估多参与者社交行为的框架，通过三个维度（同步性、时间对齐和结构相似性）分析骨骼运动数据，并验证了其敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标忽略了多参与者互动中的上下文协调动态，需要一种更全面的评估方法。

Method: 采用跨重复量化分析、多尺度经验模态分解和软动态时间规整三种方法，结合理论驱动的扰动验证指标敏感性。

Result: 实验显示，不同扰动对指标有可预测的影响，且感知研究支持了骨骼数据的有效性。

Conclusion: 该框架为评估和优化社交智能代理提供了可靠工具，代码已开源。

Abstract: Digital humans are emerging as autonomous agents in multiparty interactions,
yet existing evaluation metrics largely ignore contextual coordination
dynamics. We introduce a unified, intervention-driven framework for objective
assessment of multiparty social behaviour in skeletal motion data, spanning
three complementary dimensions: (1) synchrony via Cross-Recurrence
Quantification Analysis, (2) temporal alignment via Multiscale Empirical Mode
Decompositionbased Beat Consistency, and (3) structural similarity via Soft
Dynamic Time Warping. We validate metric sensitivity through three
theory-driven perturbations -- gesture kinematic dampening, uniform
speech-gesture delays, and prosodic pitch-variance reduction-applied to
$\approx 145$ 30-second thin slices of group interactions from the DnD dataset.
Mixed-effects analyses reveal predictable, joint-independent shifts: dampening
increases CRQA determinism and reduces beat consistency, delays weaken
cross-participant coupling, and pitch flattening elevates F0 Soft-DTW costs. A
complementary perception study ($N=27$) compares judgments of full-video and
skeleton-only renderings to quantify representation effects. Our three measures
deliver orthogonal insights into spatial structure, timing alignment, and
behavioural variability. Thereby forming a robust toolkit for evaluating and
refining socially intelligent agents. Code available on
\href{https://github.com/tapri-lab/gig-interveners}{GitHub}.

</details>


### [217] [Managing the unexpected: Operator behavioural data and its value in predicting correct alarm responses](https://arxiv.org/abs/2508.10917)
*Chidera W. Amazu,Joseph Mietkiewicz,Ammar N. Abbas,Gabriele Baldissone,Davide Fissore,Micaela Demichela,Anders L. Madsen,Maria Chiara Leva*

Main category: cs.HC

TL;DR: 研究探讨了利用实时数据和操作员系统交互数据预测操作员行为及响应结果，避免侵入性生理测量工具的使用。


<details>
  <summary>Details</summary>
Motivation: 通过非侵入性方法获取操作员行为和认知状态，提升对关键警报响应场景的理解。

Method: 使用甲醛生产厂模拟器和四种人机实验配置，结合逐步逻辑回归和贝叶斯网络模型分析数据。

Result: 发现了一些预测性指标，可作为警报响应场景中系统性能的先兆或预测因子。

Conclusion: 实时获取的行为指标有助于决策者预测结果并提供及时支持。

Abstract: Data from psychophysiological measures can offer new insight into control
room operators' behaviour, cognition, and mental workload status. This can be
particularly helpful when combined with appraisal of capacity to respond to
possible critical plant conditions (i.e. critical alarms response scenarios).
However, wearable physiological measurement tools such as eye tracking and EEG
caps can be perceived as intrusive and not suitable for usage in daily
operations. Therefore, this article examines the potential of using real-time
data from process and operator-system interactions during abnormal scenarios
that can be recorded and retrieved from the distributed control system's
historian or process log, and their capacity to provide insight into operator
behavior and predict their response outcomes, without intruding on daily tasks.
Data for this study were obtained from a design of experiment using a
formaldehyde production plant simulator and four human-in-the-loop experimental
support configurations. A comparison between the different configurations in
terms of both behaviour and performance is presented in this paper. A step-wise
logistic regression and a Bayesian network models were used to achieve this
objective. The results identified some predictive metrics and the paper discuss
their value as precursor or predictor of overall system performance in alarm
response scenarios. Knowledge of relevant and predictive behavioural metrics
accessible in real time can better equip decision-makers to predict outcomes
and provide timely support measures for operators.

</details>


### [218] [Human-AI collaboration or obedient and often clueless AI in instruct, serve, repeat dynamics?](https://arxiv.org/abs/2508.10919)
*Mohammed Saqr,Kamila Misiejuk,Sonsoles López-Pernas*

Main category: cs.HC

TL;DR: 研究探讨了人类与AI在解决复杂问题时的互动模式，发现当前LLM更倾向于指令遵循而非认知协作，缺乏协同效应。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注语言学习，而忽视了在认知需求任务中人类与AI协作的动态与演变。

Method: 通过定性编码、转移网络分析、序列分析等方法分析学生与AI的互动模式。

Result: 发现互动以指令性模式为主，缺乏协同，且问题复杂度与学生成绩无显著关联。

Conclusion: 当前LLM设计更偏向指令遵循，需优化以实现认知协作。

Abstract: While research on human-AI collaboration exists, it mainly examined language
learning and used traditional counting methods with little attention to
evolution and dynamics of collaboration on cognitively demanding tasks. This
study examines human-AI interactions while solving a complex problem.
Student-AI interactions were qualitatively coded and analyzed with transition
network analysis, sequence analysis and partial correlation networks as well as
comparison of frequencies using chi-square and Person-residual shaded Mosaic
plots to map interaction patterns, their evolution, and their relationship to
problem complexity and student performance. Findings reveal a dominant
Instructive pattern with interactions characterized by iterative ordering
rather than collaborative negotiation. Oftentimes, students engaged in long
threads that showed misalignment between their prompts and AI output that
exemplified a lack of synergy that challenges the prevailing assumptions about
LLMs as collaborative partners. We also found no significant correlations
between assignment complexity, prompt length, and student grades suggesting a
lack of cognitive depth, or effect of problem difficulty. Our study indicates
that the current LLMs, optimized for instruction-following rather than
cognitive partnership, compound their capability to act as cognitively
stimulating or aligned collaborators. Implications for designing AI systems
that prioritize cognitive alignment and collaboration are discussed.

</details>


### [219] [GhostObjects: Instructing Robots by Manipulating Spatially Aligned Virtual Twins in Augmented Reality](https://arxiv.org/abs/2508.11022)
*Lauren W. Wang,Parastoo Abtahi*

Main category: cs.HC

TL;DR: 通过AR中的GhostObjects实现人机交互，用户可直接操作虚拟对象来精确指定任务目标。


<details>
  <summary>Details</summary>
Motivation: 虽然机器人自主能力增强，但个性化指令仍需人机交互，传统方法如PbD或遥操作不够灵活。

Method: 利用AR中的GhostObjects（物理对象的虚拟孪生体），用户可直接操作虚拟对象以指定任务目标和空间参数。

Result: 支持多对象选择和默认位置回位等功能，实现超越简单抓取的任务。

Conclusion: GhostObjects提供了一种更直观、灵活的人机交互方式。

Abstract: Robots are increasingly capable of autonomous operations, yet human
interaction remains essential for issuing personalized instructions. Instead of
directly controlling robots through Programming by Demonstration (PbD) or
teleoperation, we propose giving instructions by interacting with
GhostObjects-world-aligned, life-size virtual twins of physical objects-in
augmented reality (AR). By direct manipulation of GhostObjects, users can
precisely specify physical goals and spatial parameters, with features
including real-world lasso selection of multiple objects and snapping back to
default positions, enabling tasks beyond simple pick-and-place.

</details>


### [220] [FACET:Teacher-Centred LLM-Based Multi-Agent Systems-Towards Personalized Educational Worksheets](https://arxiv.org/abs/2508.11401)
*Jana Gonnermann-Müller,Jennifer Haase,Konstantin Fackeldey,Sebastian Pokutta*

Main category: cs.HC

TL;DR: FACET框架是一个基于多智能体LLM的系统，旨在为教师生成个性化的课堂材料，整合认知和动机维度。


<details>
  <summary>Details</summary>
Motivation: 学生群体的异质性给数学教育带来挑战，现有AI工具多关注成绩，忽视教学需求。

Method: FACET包含三个智能体：模拟学习者、调整教学内容和评估质量，测试采用八年级数学课程和教师反馈。

Result: 系统稳定性高，生成材料与学习者档案匹配，教师反馈肯定任务结构和适用性。

Conclusion: 多智能体LLM架构在个性化教学中潜力巨大，未来可扩展至更丰富学习者档案和实际课堂测试。

Abstract: The increasing heterogeneity of student populations poses significant
challenges for teachers, particularly in mathematics education, where
cognitive, motivational, and emotional differences strongly influence learning
outcomes. While AI-driven personalization tools have emerged, most remain
performance-focused, offering limited support for teachers and neglecting
broader pedagogical needs. This paper presents the FACET framework, a
teacher-facing, large language model (LLM)-based multi-agent system designed to
generate individualized classroom materials that integrate both cognitive and
motivational dimensions of learner profiles. The framework comprises three
specialized agents: (1) learner agents that simulate diverse profiles
incorporating topic proficiency and intrinsic motivation, (2) a teacher agent
that adapts instructional content according to didactical principles, and (3)
an evaluator agent that provides automated quality assurance. We tested the
system using authentic grade 8 mathematics curriculum content and evaluated its
feasibility through a) automated agent-based assessment of output quality and
b) exploratory feedback from K-12 in-service teachers. Results from ten
internal evaluations highlighted high stability and alignment between generated
materials and learner profiles, and teacher feedback particularly highlighted
structure and suitability of tasks. The findings demonstrate the potential of
multi-agent LLM architectures to provide scalable, context-aware
personalization in heterogeneous classroom settings, and outline directions for
extending the framework to richer learner profiles and real-world classroom
trials.

</details>


### [221] [Families' Vision of Generative AI Agents for Household Safety Against Digital and Physical Threats](https://arxiv.org/abs/2508.11030)
*Zikai Wen,Lanjing Liu,Yaxing Yao*

Main category: cs.HC

TL;DR: 研究探讨了家庭如何通过多个人工智能代理（AI agents）提升家庭安全，发现家庭倾向于将安全任务分配给不同角色代理，并提出隐私保护设计原则。


<details>
  <summary>Details</summary>
Motivation: 随着家庭在数字和物理环境中面临的安全挑战日益复杂，生成式AI（GenAI）为通过多代理系统支持家庭安全提供了新机会。

Method: 通过两阶段定性研究（个人访谈和协作会议）与13对亲子家庭探讨了他们对GenAI的构想及AI代理在家庭生活中的应用。

Result: 家庭倾向于将安全任务分配给多个代理（如家庭经理、私人导师、家庭治疗师），并强调隐私边界、信任差异和家庭沟通的重要性。

Conclusion: 提出基于隐私保护原则的多代理系统设计，以平衡家庭环境中的安全、隐私和自主性。

Abstract: As families face increasingly complex safety challenges in digital and
physical environments, generative AI (GenAI) presents new opportunities to
support household safety through multiple specialized AI agents. Through a
two-phase qualitative study consisting of individual interviews and
collaborative sessions with 13 parent-child dyads, we explored families'
conceptualizations of GenAI and their envisioned use of AI agents in daily
family life. Our findings reveal that families preferred to distribute
safety-related support across multiple AI agents, each embodying a familiar
caregiving role: a household manager coordinating routine tasks and mitigating
risks such as digital fraud and home accidents; a private tutor providing
personalized educational support, including safety education; and a family
therapist offering emotional support to address sensitive safety issues such as
cyberbullying and digital harassment. Families emphasized the need for
agent-specific privacy boundaries, recognized generational differences in trust
toward AI agents, and stressed the importance of maintaining open family
communication alongside the assistance of AI agents. Based on these findings,
we propose a multi-agent system design featuring four privacy-preserving
principles: memory segregation, conversational consent, selective data sharing,
and progressive memory management to help balance safety, privacy, and autonomy
within family contexts.

</details>


### [222] [AI That Helps Us Help Each Other: A Proactive System for Scaffolding Mentor-Novice Collaboration in Entrepreneurship Coaching](https://arxiv.org/abs/2508.11052)
*Evey Jiaxin Huang,Matthew Easterday,Elizabeth Gerber*

Main category: cs.HC

TL;DR: 论文提出了一种结合人类导师与AI的创业辅导系统，通过认知模型和大型语言模型支持新手和导师的思考，提升会议质量和情感共鸣。


<details>
  <summary>Details</summary>
Motivation: 解决新手创业者在开放性问题中面临的认知挑战，以及导师因时间和精力有限难以提供个性化支持的问题。

Method: 开发了一个结合领域特定认知模型和大型语言模型（LLM）的人机协作系统，主动提出问题并支持会议规划。

Result: 系统提升了新手的元认知能力，帮助导师制定情感共鸣策略，并改善了会议的深度和专注度，但也揭示了AI信任和误诊等问题。

Conclusion: 提出了支持元认知和人机协作的设计原则，适用于医疗、教育等复杂领域。

Abstract: Entrepreneurship requires navigating open-ended, ill-defined problems:
identifying risks, challenging assumptions, and making strategic decisions
under deep uncertainty. Novice founders often struggle with these metacognitive
demands, while mentors face limited time and visibility to provide tailored
support. We present a human-AI coaching system that combines a domain-specific
cognitive model of entrepreneurial risk with a large language model (LLM) to
proactively scaffold both novice and mentor thinking. The system proactively
poses diagnostic questions that challenge novices' thinking and helps both
novices and mentors plan for more focused and emotionally attuned meetings.
Critically, mentors can inspect and modify the underlying cognitive model,
shaping the logic of the system to reflect their evolving needs. Through an
exploratory field deployment, we found that using the system supported novice
metacognition, helped mentors plan emotionally attuned strategies, and improved
meeting depth, intentionality, and focus--while also surfaced key tensions
around trust, misdiagnosis, and expectations of AI. We contribute design
principles for proactive AI systems that scaffold metacognition and human-human
collaboration in complex, ill-defined domains, offering implications for
similar domains like healthcare, education, and knowledge work.

</details>


### [223] [Stories and Systems: Educational Interactive Storytelling to Teach Media Literacy and Systemic Thinking](https://arxiv.org/abs/2508.11059)
*Christian Roth,Rahmin Bender-Salazar,Breanne Pitt*

Main category: cs.HC

TL;DR: 本文探讨了交互式数字叙事（IDNs）如何帮助学习者培养解决复杂社会问题（如气候变化、疫情和社会不平等）所需的关键素养，并提出了CLASS框架以指导其设计和应用。


<details>
  <summary>Details</summary>
Motivation: 数字技术虽然提供了广泛的叙事和数据访问，但也导致了错误信息和问题简化的问题。IDNs通过非线性互动故事促进深度理解和参与。

Method: 提出了Systemic Learning IDNs和CLASS框架，结合系统思维、设计思维和叙事，支持学习者培养好奇心、批判性思维和协作解决问题的能力。

Result: 通过两个案例（商业叙事模拟和教育原型）的比较分析，验证了CLASS框架的实用性，并提出了未来设计和实施的建议。

Conclusion: IDNs结合叙事、系统映射和参与式设计，可以成为复杂世界中变革性、系统导向学习的强大工具。

Abstract: This paper explores how Interactive Digital Narratives (IDNs) can support
learners in developing the critical literacies needed to address complex
societal challenges, so-called wicked problems, such as climate change,
pandemics, and social inequality. While digital technologies offer broad access
to narratives and data, they also contribute to misinformation and the
oversimplification of interconnected issues. IDNs enable learners to navigate
nonlinear, interactive stories, fostering deeper understanding and engagement.
We introduce Systemic Learning IDNs: interactive narrative experiences
explicitly designed to help learners explore and reflect on complex systems and
interdependencies. To guide their creation and use, we propose the CLASS
framework, a structured model that integrates systems thinking, design
thinking, and storytelling. This transdisciplinary approach supports learners
in developing curiosity, critical thinking, and collaborative problem-solving.
Focusing on the classroom context, we apply CLASS to two cases, one commercial
narrative simulation and one educational prototype, offering a comparative
analysis and practical recommendations for future design and implementation. By
combining narrative, systems mapping, and participatory design, this paper
highlights how IDNs can become powerful tools for transformative,
systems-oriented learning in an increasingly complex world.

</details>


### [224] [Human-in-the-Loop Systems for Adaptive Learning Using Generative AI](https://arxiv.org/abs/2508.11062)
*Bhavishya Tarun,Haoze Du,Dinesh Kannan,Edward F. Gehringer*

Main category: cs.HC

TL;DR: 论文提出了一种基于人机协作（HITL）的方法，利用生成式AI增强个性化学习，通过学生反馈实时调整AI生成的内容，提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统AI学习工具缺乏动态反馈机制，无法根据学生需求实时调整内容。本文旨在通过学生驱动的反馈循环，优化AI生成的学习材料，提高学习效果和参与度。

Method: 采用预定义反馈标签和提示工程技术，结合检索增强生成（RAG）系统，实时调整AI生成的学习内容。

Result: 初步研究表明，该方法在STEM教育中显著提升了学生的学习成果和自信心，优于传统AI工具。

Conclusion: 通过迭代优化和实时反馈，AI可以构建动态、个性化的学习环境，提升教育效果。

Abstract: A Human-in-the-Loop (HITL) approach leverages generative AI to enhance
personalized learning by directly integrating student feedback into
AI-generated solutions. Students critique and modify AI responses using
predefined feedback tags, fostering deeper engagement and understanding. This
empowers students to actively shape their learning, with AI serving as an
adaptive partner. The system uses a tagging technique and prompt engineering to
personalize content, informing a Retrieval-Augmented Generation (RAG) system to
retrieve relevant educational material and adjust explanations in real time.
This builds on existing research in adaptive learning, demonstrating how
student-driven feedback loops can modify AI-generated responses for improved
student retention and engagement, particularly in STEM education. Preliminary
findings from a study with STEM students indicate improved learning outcomes
and confidence compared to traditional AI tools. This work highlights AI's
potential to create dynamic, feedback-driven, and personalized learning
environments through iterative refinement.

</details>


### [225] [DriveSimQuest: A VR Driving Simulator and Research Platform on Meta Quest with Unity](https://arxiv.org/abs/2508.11072)
*Nishanth Chidambaram,Weichen Liu,Manas Satish Bedmutha,Nadir Weibel,Chen Chen*

Main category: cs.HC

TL;DR: DriveSimQuest是一个基于Meta Quest Pro和Unity的VR驾驶模拟器，能够实时捕捉多种行为信号，为研究驾驶行为和设计辅助系统提供便捷平台。


<details>
  <summary>Details</summary>
Motivation: 现有VR驾驶模拟器通常仅追踪眼部动作，且设备笨重、架构复杂，限制了交互研究和实践。

Method: 基于Meta Quest Pro和Unity构建，实时捕捉视线、面部表情、手部活动和全身姿态。

Result: 提供了一个易于部署的平台，支持研究驾驶者的情感状态和行为。

Conclusion: DriveSimQuest为设计未来情境感知驾驶辅助系统提供了初步工具。

Abstract: Using head-mounted Virtual Reality (VR) displays to simulate driving is
critical to studying driving behavior and designing driver assistance systems.
But existing VR driving simulators are often limited to tracking only eye
movements. The bulky outside-in tracking setup and Unreal-based architecture
also present significant engineering challenges for interaction researchers and
practitioners. We present DriveSimQuest, a VR driving simulator and research
platform built on the Meta Quest Pro and Unity, capable of capturing rich
behavioral signals such as gaze, facial expressions, hand activities, and
full-body gestures in real-time. DriveSimQuest offers a preliminary,
easy-to-deploy platform that supports researchers and practitioners in studying
drivers' affective states and behaviors, and in designing future context-aware
driving assistance systems.

</details>


### [226] [Toward Needs-Conscious Design: Co-Designing a Human-Centered Framework for AI-Mediated Communication](https://arxiv.org/abs/2508.11149)
*Robert Wolfe,Aayushi Dangol,JaeWon Kim,Alexis Hiniker*

Main category: cs.HC

TL;DR: 论文提出了一种以需求为中心的设计框架（Needs-Conscious Design），基于非暴力沟通（NVC）原则，通过访谈和日记研究，定义了设计的三大支柱，并探讨了AI中介沟通中的“共情迷雾”问题。


<details>
  <summary>Details</summary>
Motivation: 旨在通过AI中介沟通促进人际关系，而非替代或模糊人类连接。

Method: 通过访谈NVC培训师（N=14）和日记研究及共同设计（N=13）来理解NVC如何指导设计。

Result: 定义了设计的三大支柱（Intentionality, Presence, Receptiveness to Needs），提出了设计概念，并识别了“共情迷雾”问题。

Conclusion: Needs-Conscious Design为利用AI促进人际连接提供了基础，并提出了基于同意的设计指导问题。

Abstract: We introduce Needs-Conscious Design, a human-centered framework for
AI-mediated communication that builds on the principles of Nonviolent
Communication (NVC). We conducted an interview study with N=14 certified NVC
trainers and a diary study and co-design with N=13 lay users of online
communication technologies to understand how NVC might inform design that
centers human relationships. We define three pillars of Needs-Conscious Design:
Intentionality, Presence, and Receptiveness to Needs. Drawing on participant
co-designs, we provide design concepts and illustrative examples for each of
these pillars. We further describe a problematic emergent property of
AI-mediated communication identified by participants, which we call Empathy
Fog, and which is characterized by uncertainty over how much empathy,
attention, and effort a user has actually invested via an AI-facilitated online
interaction. Finally, because even well-intentioned designs may alter user
behavior and process emotional data, we provide guiding questions for
consentful Needs-Conscious Design, applying an affirmative consent framework
used in social media contexts. Needs-Conscious Design offers a foundation for
leveraging AI to facilitate human connection, rather than replacing or
obscuring it.

</details>


### [227] [From Misunderstandings to Learning Opportunities: Leveraging Generative AI in Discussion Forums to Support Student Learning](https://arxiv.org/abs/2508.11150)
*Stanislav Pozdniakov,Jonathan Brazil,Oleksandra Poquet,Stephan Krusche,Santiago Berrezueta-Guzman,Shazia Sadiq,Hassan Khosravi*

Main category: cs.HC

TL;DR: 论文探讨了如何利用大语言模型（LLMs）和检索增强生成（RAG）技术解决大规模课堂讨论论坛中学生常见误解的识别与处理问题，并提出了Misunderstanding to Mastery（M2M）方法。


<details>
  <summary>Details</summary>
Motivation: 在大规模课堂讨论论坛中，学生生成的内容量巨大，如何有效识别常见误解并为教师提供可操作的见解是主要挑战。

Method: 结合LLMs和RAG技术，提出M2M方法，并通过三个计算机科学课程的1355名学生和2878条帖子进行验证。

Result: 教师认为该方法在识别误解和生成可操作见解方面具有潜力，但也提出了对更细粒度分组、清晰指标、资源验证和数据匿名性伦理问题的需求。

Conclusion: M2M方法在大规模课堂讨论中显示出实用价值，但需进一步优化和解决伦理问题。

Abstract: In the contemporary educational landscape, particularly in large classroom
settings, discussion forums have become a crucial tool for promoting
interaction and addressing student queries. These forums foster a collaborative
learning environment where students engage with both the teaching team and
their peers. However, the sheer volume of content generated in these forums
poses two significant interconnected challenges: How can we effectively
identify common misunderstandings that arise in student discussions? And once
identified, how can instructors use these insights to address them effectively?
This paper explores the approach to integrating large language models (LLMs)
and Retrieval-Augmented Generation (RAG) to tackle these challenges. We then
demonstrate the approach Misunderstanding to Mastery (M2M) with authentic data
from three computer science courses, involving 1355 students with 2878 unique
posts, followed by an evaluation with five instructors teaching these courses.
Results show that instructors found the approach promising and valuable for
teaching, effectively identifying misunderstandings and generating actionable
insights. Instructors highlighted the need for more fine-grained groupings,
clearer metrics, validation of the created resources, and ethical
considerations around data anonymity.

</details>


### [228] [Is General-Purpose AI Reasoning Sensitive to Data-Induced Cognitive Biases? Dynamic Benchmarking on Typical Software Engineering Dilemmas](https://arxiv.org/abs/2508.11278)
*Francesco Sovrano,Gabriele Dominici,Rita Sevastjanova,Alessandra Stramiglio,Alberto Bacchelli*

Main category: cs.HC

TL;DR: 该论文提出了一个动态基准框架，用于评估通用人工智能（GPAI）在软件工程工作流中因数据诱导的认知偏差。研究发现GPAI系统普遍依赖浅层语言启发式而非深度推理，表现出明显的认知偏差。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究GPAI系统是否因训练数据中的人类认知偏差而表现出类似偏差，从而在软件工程中引发潜在风险。

Method: 方法包括开发动态基准框架，通过16个手工任务和基于GPAI的任务变体生成管道，测试GPAI系统对认知偏差的敏感性。

Result: 结果显示，主流GPAI系统（如GPT、LLaMA、DeepSeek）均表现出认知偏差（5.9%至35%），且偏差敏感性随任务复杂度增加而显著上升（最高49%）。

Conclusion: 结论指出GPAI系统的认知偏差在复杂任务中尤为显著，对实际软件工程部署构成严重风险。

Abstract: Human cognitive biases in software engineering can lead to costly errors.
While general-purpose AI (GPAI) systems may help mitigate these biases due to
their non-human nature, their training on human-generated data raises a
critical question: Do GPAI systems themselves exhibit cognitive biases?
  To investigate this, we present the first dynamic benchmarking framework to
evaluate data-induced cognitive biases in GPAI within software engineering
workflows. Starting with a seed set of 16 hand-crafted realistic tasks, each
featuring one of 8 cognitive biases (e.g., anchoring, framing) and
corresponding unbiased variants, we test whether bias-inducing linguistic cues
unrelated to task logic can lead GPAI systems from correct to incorrect
conclusions.
  To scale the benchmark and ensure realism, we develop an on-demand
augmentation pipeline relying on GPAI systems to generate task variants that
preserve bias-inducing cues while varying surface details. This pipeline
ensures correctness (88--99% on average, according to human evaluation),
promotes diversity, and controls reasoning complexity by leveraging
Prolog-based reasoning and LLM-as-a-judge validation. It also verifies that the
embedded biases are both harmful and undetectable by logic-based, unbiased
reasoners.
  We evaluate leading GPAI systems (GPT, LLaMA, DeepSeek) and find a consistent
tendency to rely on shallow linguistic heuristics over deep reasoning. All
systems exhibit cognitive biases (ranging from 5.9% to 35% across types), with
bias sensitivity increasing sharply with task complexity (up to 49%),
highlighting critical risks in real-world software engineering deployments.

</details>


### [229] [GulliVR: A Walking-Oriented Technique for Navigation in Virtual Reality Games Based on Virtual Body Resizing](https://arxiv.org/abs/2508.11304)
*Andrey Krekhov,Sebastian Cmentowski,Katharina Emmerich,Maic Masuch,Jens Krüger*

Main category: cs.HC

TL;DR: 论文提出了一种通过将玩家变为“巨人”来增强虚拟现实游戏中物理行走体验的导航方法，相比传统的传送技术，显著提升了玩家的存在感和行走距离。


<details>
  <summary>Details</summary>
Motivation: 解决虚拟现实游戏中因物理空间限制而无法自然行走的问题，同时避免传送技术导致的玩家静止现象。

Method: 通过动态调整玩家的视角高度（模拟“巨人”行走），使玩家在有限物理空间内覆盖更大的虚拟距离，同时减少晕动症。

Result: 实验表明，该方法比传统传送技术显著提升了玩家的存在感和实际行走距离。

Conclusion: 该方法为虚拟现实游戏设计提供了一种新的导航隐喻，并提出了相关的游戏设计建议。

Abstract: Virtual reality games are often centered around our feeling of "being there".
That presence can be significantly enhanced by supporting physical walking.
Although modern virtual reality systems enable room-scale motions, the size of
our living rooms is not enough to explore vast virtual environments. Developers
bypass that limitation by adding virtual navigation such as teleportation.
Although such techniques are intended (or designed) to extend but not replace
natural walking, what we often observe are nonmoving players beaming to a
location that is one real step ahead. Our navigation metaphor emphasizes
physical walking by promoting players into giants on demand to cover large
distances. In contrast to flying, our technique proportionally increases the
modeled eye distance, preventing cybersickness and creating the feeling of
being in a miniature world. Our evaluations underpin a significantly increased
presence and walking distance compared to the teleportation approach. Finally,
we derive a set of game design implications related to the integration of our
technique.

</details>


### [230] [Outpace Reality: A Novel Augmented-Walking Technique for Virtual Reality Games](https://arxiv.org/abs/2508.11314)
*Sebastian Cmentowski,Fabian Kievelitz,Jens Krüger*

Main category: cs.HC

TL;DR: 提出了一种新型虚拟现实游戏行走增强方法，通过虚拟隧道减少视觉流动引起的晕动症，同时保持真实感和身体活动。


<details>
  <summary>Details</summary>
Motivation: 解决虚拟环境与物理行走空间不匹配的问题，同时避免因视觉流动增加导致的晕动症。

Method: 使用虚拟隧道技术，外部显示完整距离，内部仅需短距离行走，隧道隐藏加速视觉流动，通过窗口展示实际加速运动。

Result: 评估表明该方法避免了晕动症，增强了身体活动并保持了临场感。

Conclusion: 讨论了该行走技术的设计考虑和局限性。

Abstract: The size of most virtual environments exceeds the tracking space available
for physical walking. One solution to this disparity is to extend the available
walking range by augmenting users' actual movements. However, the resulting
increase in visual flow can easily cause cybersickness. Therefore, we present a
novel augmented-walking approach for virtual reality games. Our core concept is
a virtual tunnel that spans the entire travel distance when viewed from the
outside. However, its interior is only a fraction as long, allowing users to
cover the distance by real walking. Whereas the tunnel hides the visual flow
from the applied movement acceleration, windows on the tunnel's walls still
reveal the actual expedited motion. Our evaluation reveals that our approach
avoids cybersickness while enhancing physical activity and preserving presence.
We finish our paper with a discussion of the design considerations and
limitations of our proposed locomotion technique.

</details>


### [231] [The User-first Approach to AI Ethics: Preferences for Ethical Principles in AI Systems across Cultures and Contexts](https://arxiv.org/abs/2508.11327)
*Benjamin J. Carroll,Jianlong Zhou,Paul F. Burke,Sabine Ammon*

Main category: cs.HC

TL;DR: 论文通过离散选择实验量化了用户对11项AI伦理原则的偏好，发现隐私、公正与公平、透明度最受重视，但偏好因文化和应用场景而异。


<details>
  <summary>Details</summary>
Motivation: 探讨用户对AI伦理原则的实际重视程度，填补现有文献中用户视角的空白。

Method: 在四个国家进行离散选择实验，量化用户对11项伦理原则的偏好，并采用潜在类别分析识别用户群体。

Result: 用户偏好隐私、公正与公平、透明度，但存在文化和场景差异；识别出四类用户群体，最大群体为伦理疏离型。

Conclusion: 研究为AI伦理的实践提供了用户视角的实证依据，支持文化和场景定制化伦理设计，并呼吁加强监管机制。

Abstract: As AI systems increasingly permeate everyday life, designers and developers
face mounting pressure to balance innovation with ethical design choices. To
date, the operationalisation of AI ethics has predominantly depended on
frameworks that prescribe which ethical principles should be embedded within AI
systems. However, the extent to which users value these principles remains
largely unexplored in the existing literature. In a discrete choice experiment
conducted in four countries, we quantify user preferences for 11 ethical
principles. Our findings indicate that, while users generally prioritise
privacy, justice & fairness, and transparency, their preferences exhibit
significant variation based on culture and application context. Latent class
analysis further revealed four distinct user cohorts, the largest of which is
ethically disengaged and defers to regulatory oversight. Our findings offer (1)
empirical evidence of uneven user prioritisation of AI ethics principles, (2)
actionable guidance for operationalising ethics tailored to culture and
context, (3) support for the development of robust regulatory mechanisms, and
(4) a foundation for advancing a user-centred approach to AI ethics, motivated
independently from abstract moral theory.

</details>


### [232] [Towards Smart Workplaces: Understanding Mood-Influencing Factors of the Physical Workspace in Collaborative Group Settings](https://arxiv.org/abs/2508.11335)
*Tzu-Hui Wu,Sebastian Cmentowski,Yunyin Lou,Jun Hu,Regina Bernhaupt*

Main category: cs.HC

TL;DR: 研究探讨了物理工作空间如何影响团队情绪，并探索了智能情绪感知技术的潜力。


<details>
  <summary>Details</summary>
Motivation: 团队情绪对工作体验、团队表现和创造力至关重要，但维持积极氛围具有挑战性。智能技术可能帮助调节情绪，但相关研究较少。

Method: 通过定性用户研究（8个工作小组，共26名参与者）探索物理工作空间对团队情绪的影响及员工对智能技术的看法。

Result: 研究发现影响团队情绪的关键因素，以及参与者对支持性技术的期望（如保护隐私和自主性）。

Conclusion: 研究强调了适应性工作空间的潜力，并指出需要以人为本的技术干预以提升团队福祉。

Abstract: Group mood plays a crucial role in shaping workspace experiences, influencing
group dynamics, team performance, and creativity. The perceived group mood
depends on many, often subconscious, aspects such as individual emotional
states or group life, which make it challenging to maintain a positive
atmosphere. Intelligent technology could support mood regulation in physical
office environments, for example, as adaptive ambient lighting for mood
regulation. However, little is known about the relationship between the
physical workspace and group mood dynamics. To address this knowledge gap, we
conducted a qualitative user study (N=8 workgroups and overall 26 participants)
to explore how the physical workspace shapes group mood experiences and
investigate employees' perspectives on intelligent mood-aware technologies. Our
findings reveal key factors influencing group mood, and participants'
expectations for supportive technology to preserve privacy and autonomy. Our
work highlights the potential of adaptive and responsive workspaces while also
emphasizing the need for human-centered, technology-driven interventions that
benefit group well-being.

</details>


### [233] [Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling and Explainable Mental Disorder Diagnosis](https://arxiv.org/abs/2508.11398)
*Mithat Can Ozgun,Jiahuan Pei,Koen Hindriks,Lucia Donatelli,Qingzhi Liu,Xin Sun,Junxiao Wang*

Main category: cs.HC

TL;DR: DSM5AgentFlow是一个基于LLM的代理工作流，用于自主生成DSM-5 Level-1诊断问卷，填补了现有方法在心理健康诊断中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在心理健康诊断等专业领域表现不佳，且缺乏主动询问能力和多轮对话理解，无法与专家临床推理对齐。

Method: 通过模拟治疗师-客户对话，生成透明、逐步的障碍预测，提供可解释的结果。

Result: 实验评估了LLM在对话真实性、诊断准确性和可解释性三个关键维度的表现，数据集和实现已开源。

Conclusion: DSM5AgentFlow作为心理健康诊断的补充工具，符合伦理和法律标准，提供了可信赖的结果。

Abstract: LLM-based agents have emerged as transformative tools capable of executing
complex tasks through iterative planning and action, achieving significant
advancements in understanding and addressing user needs. Yet, their
effectiveness remains limited in specialized domains such as mental health
diagnosis, where they underperform compared to general applications. Current
approaches to integrating diagnostic capabilities into LLMs rely on scarce,
highly sensitive mental health datasets, which are challenging to acquire.
These methods also fail to emulate clinicians' proactive inquiry skills, lack
multi-turn conversational comprehension, and struggle to align outputs with
expert clinical reasoning. To address these gaps, we propose DSM5AgentFlow, the
first LLM-based agent workflow designed to autonomously generate DSM-5 Level-1
diagnostic questionnaires. By simulating therapist-client dialogues with
specific client profiles, the framework delivers transparent, step-by-step
disorder predictions, producing explainable and trustworthy results. This
workflow serves as a complementary tool for mental health diagnosis, ensuring
adherence to ethical and legal standards. Through comprehensive experiments, we
evaluate leading LLMs across three critical dimensions: conversational realism,
diagnostic accuracy, and explainability. Our datasets and implementations are
fully open-sourced.

</details>


### [234] [Towards Embodied Conversational Agents for Reducing Oral Exam Anxiety in Extended Reality](https://arxiv.org/abs/2508.11412)
*Jens Grubert,Yvonne Sedelmaier,Dieter Landes*

Main category: cs.HC

TL;DR: 探讨利用XR环境中的ECAs和LLMs帮助学生准备口试，缓解焦虑并提升表现。


<details>
  <summary>Details</summary>
Motivation: 口试是高等教育中普遍但心理压力大的评估方式，学生焦虑影响表现。

Method: 提出结合逼真ECAs和实时LLMs的系统概念，支持安全、自适应、可重复的口试模拟。

Result: 讨论了该系统的潜在优势和挑战。

Conclusion: XR环境中的ECAs和LLMs有望为学生提供有效的口试准备支持。

Abstract: Oral examinations are a prevalent but psychologically demanding form of
assessment in higher education. Many students experience intense anxiety, which
can impair cognitive performance and hinder academic success. This position
paper explores the potential of embodied conversational agents (ECAs) in
extended reality (XR) environments to support students preparing for oral
exams. We propose a system concept that integrates photorealistic ECAs with
real-time capable large language models (LLMs) to enable psychologically safe,
adaptive, and repeatable rehearsal of oral examination scenarios. We also
discuss the potential benefits and challenges of such an envisioned system.

</details>


### [235] [ReachVox: Clutter-free Reachability Visualization for Robot Motion Planning in Virtual Reality](https://arxiv.org/abs/2508.11426)
*Steffen Hauck,Diar Abdlkarim,John Dudley,Per Ola Kristensson,Eyal Ofek,Jens Grubert*

Main category: cs.HC

TL;DR: 研究探讨了ReachVox（一种简洁的可达性编码）在VR中远程操作者与机械臂协作中的作用，并通过用户研究验证其效果。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，机器人运动路径的规划和理解是主要挑战，需要适应性强的方法。

Method: 提出ReachVox编码，通过用户研究（n=20）比较其与点式可达性检查的效果。

Result: 研究表明ReachVox可视化在协作中具有优势。

Conclusion: ReachVox为动态环境中的人机协作提供了一种有效的可视化工具。

Abstract: Human-Robot-Collaboration can enhance workflows by leveraging the mutual
strengths of human operators and robots. Planning and understanding robot
movements remain major challenges in this domain. This problem is prevalent in
dynamic environments that might need constant robot motion path adaptation. In
this paper, we investigate whether a minimalistic encoding of the reachability
of a point near an object of interest, which we call ReachVox, can aid the
collaboration between a remote operator and a robotic arm in VR. Through a user
study (n=20), we indicate the strength of the visualization relative to a
point-based reachability check-up.

</details>


### [236] [Grand Challenge: Mediating Between Confirmatory and Exploratory Research Cultures in Health Sciences and Visual Analytics](https://arxiv.org/abs/2508.11544)
*Viktor von Wyl,Jürgen Bernard*

Main category: cs.HC

TL;DR: 论文探讨了健康科学与可视化分析研究合作中的障碍，提出了七个研究需求和行动，以促进跨学科合作。


<details>
  <summary>Details</summary>
Motivation: 健康科学与可视化分析研究因方法差异导致合作困难，需解决术语、数据准备、验证标准等问题。

Method: 识别七个研究需求和行动，包括指南、质量基准、框架、工作流程、术语工具、桥梁角色和文化适应。

Result: 提出了一个包含文化、标准和流程三方面的框架，以支持可靠、可重复且临床相关的数据方法。

Conclusion: 通过解决文化和流程差异，可以促进跨学科合作，推动数据驱动的研究发展。

Abstract: Collaboration between health science and visual analytics research is often
hindered by different, sometimes incompatible approaches to research design.
Health science often follows hypothesis-driven protocols, registered in
advance, and focuses on reproducibility and risk mitigation. Visual analytics,
in contrast, relies on iterative data exploration, prioritizing insight
generation and analytic refinement through user interaction. These differences
create challenges in interdisciplinary projects, including misaligned
terminology, unrealistic expectations about data readiness, divergent
validation norms, or conflicting explainability requirements. To address these
persistent tensions, we identify seven research needs and actions: (1)
guidelines for broader community adoption, (2) agreement on quality and
validation benchmarks, (3) frameworks for aligning research tasks, (4)
integrated workflows combining confirmatory and exploratory stages, (5) tools
for harmonizing terminology across disciplines, (6) dedicated bridging roles
for transdisciplinary work, and (7) cultural adaptation and mutual recognition.
We organize these needs in a framework with three areas: culture, standards,
and processes. They can constitute a research agenda for developing reliable,
reproducible, and clinically relevant data-centric methods.

</details>


### [237] [Adaptive Cardio Load Targets for Improving Fitness and Performance](https://arxiv.org/abs/2508.11613)
*Justin Phillips,Daniel Roggen,Cathy Speed,Robert Harle*

Main category: cs.HC

TL;DR: Cardio Load (CL) 是 Google 2024 年推出的心血管工作量衡量指标，基于心率储备，结合活动强度和时长，提供个性化周目标。


<details>
  <summary>Details</summary>
Motivation: 通过用户反馈和内部研究，引入自适应和个性化目标，以更精准衡量用户的心血管训练负荷。

Method: 基于心率储备计算 CL，并结合活动和时长，设定每周个性化目标。

Result: CL 可用于性能测量，与 Active Zone Minutes (AZMs) 互补，前者关注健康指南，后者关注性能。

Conclusion: CL 通过活动和日常行为累积，用户可通过全天小活动提升 CL 分数，功能将于 2025 年 9 月在 Fitbit 公测版上线。

Abstract: Cardio Load, introduced by Google in 2024, is a measure of cardiovascular
work (also known as training load) resulting from all the user's activities
across the day. It is based on heart rate reserve and captures both activity
intensity and duration. Thanks to feedback from users and internal research, we
introduce adaptive and personalized targets which will be set weekly. This
feature will be available in the Public Preview of the Fitbit app after
September 2025. This white paper provides a comprehensive overview of Cardio
Load (CL) and how weekly CL targets are established, with examples shown to
illustrate the effect of varying CL on the weekly target. We compare Cardio
Load and Active Zone Minutes (AZMs), highlighting their distinct purposes, i.e.
AZMs for health guidelines and CL for performance measurement. We highlight
that CL is accumulated both during active workouts and incidental daily
activities, so users are able top-up their CL score with small bouts of
activity across the day.

</details>


### [238] [Grab-n-Go: On-the-Go Microgesture Recognition with Objects in Hand](https://arxiv.org/abs/2508.11620)
*Chi-Jung Lee,Jiaxin Li,Tianhong Catherine Yu,Ruidong Zhang,Vipin Gunda,François Guimbretière,Cheng Zhang*

Main category: cs.HC

TL;DR: Grab-n-Go是一种利用主动声学传感识别手持物体时细微手势的可穿戴设备，通过深度学习框架实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 随着计算设备融入日常生活，需要一种即使手被占用也能实现直观交互的方法。

Method: 使用单手腕带同时捕捉手势、握持姿势和物体几何信息，结合深度学习识别30种微手势。

Result: 在10名参与者和25种日常物体的用户研究中，平均识别准确率达92.0%。

Conclusion: Grab-n-Go展示了无需修改现有物体即可实现无缝交互的潜力。

Abstract: As computing devices become increasingly integrated into daily life, there is
a growing need for intuitive, always-available interaction methods, even when
users' hands are occupied. In this paper, we introduce Grab-n-Go, the first
wearable device that leverages active acoustic sensing to recognize subtle hand
microgestures while holding various objects. Unlike prior systems that focus
solely on free-hand gestures or basic hand-object activity recognition,
Grab-n-Go simultaneously captures information about hand microgestures,
grasping poses, and object geometries using a single wristband, enabling the
recognition of fine-grained hand movements occurring within activities
involving occupied hands. A deep learning framework processes these complex
signals to identify 30 distinct microgestures, with 6 microgestures for each of
the 5 grasping poses. In a user study with 10 participants and 25 everyday
objects, Grab-n-Go achieved an average recognition accuracy of 92.0%. A
follow-up study further validated Grab-n-Go's robustness against 10 more
challenging, deformable objects. These results underscore the potential of
Grab-n-Go to provide seamless, unobtrusive interactions without requiring
modifications to existing objects. The complete dataset, comprising data from
18 participants performing 30 microgestures with 35 distinct objects, is
publicly available at https://github.com/cjlisalee/Grab-n-Go_Data with the DOI:
https://doi.org/10.7298/7kbd-vv75.

</details>
