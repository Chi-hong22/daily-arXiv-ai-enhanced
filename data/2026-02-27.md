<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 16]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [SODA-CitrON: Static Object Data Association by Clustering Multi-Modal Sensor Detections Online](https://arxiv.org/abs/2602.22243)
*Jan Nausner,Kilian Wohlleben,Michael Hubner*

Main category: cs.RO

TL;DR: 提出SODA-CitrON方法，通过在线聚类多模态传感器检测来解决静态物体数据关联问题，同时估计位置并维护未知数量物体的持续跟踪。


<details>
  <summary>Details</summary>
Motivation: 静态物体从异构传感器检测中的在线融合和跟踪是机器人、自主系统和环境映射中的基本问题。传统方法如JPDA适合动态目标，但对间歇观测、具有异构不确定性的静态物体效果不佳，因为运动模型对杂波的区分能力有限。

Method: 提出SODA-CitrON方法，这是一种无监督机器学习方法，通过在线聚类多模态传感器检测来处理静态物体数据关联。方法完全在线运行，处理时间不相关和多传感器测量，具有最坏情况对数线性复杂度，并提供完全可解释的输出。

Result: 在不同蒙特卡洛模拟场景中评估，与贝叶斯滤波、DBSTREAM聚类和JPDA等最先进方法比较。结果显示SODA-CitrON在研究的静态物体映射场景中，在F1分数、位置RMSE、MOTP和MOTA指标上持续优于对比方法。

Conclusion: SODA-CitrON方法有效解决了静态物体数据关联问题，在性能指标上优于现有方法，具有在线运行、处理异构传感器数据、可解释性强等优势。

Abstract: The online fusion and tracking of static objects from heterogeneous sensor detections is a fundamental problem in robotics, autonomous systems, and environmental mapping. Although classical data association approaches such as JPDA are well suited for dynamic targets, they are less effective for static objects observed intermittently and with heterogeneous uncertainties, where motion models provide minimal discriminative with respect to clutter. In this paper, we propose a novel method for static object data association by clustering multi-modal sensor detections online (SODA-CitrON), while simultaneously estimating positions and maintaining persistent tracks for an unknown number of objects. The proposed unsupervised machine learning approach operates in a fully online manner and handles temporally uncorrelated and multi-sensor measurements. Additionally, it has a worst-case loglinear complexity in the number of sensor detections while providing full output explainability. We evaluate the proposed approach in different Monte Carlo simulation scenarios and compare it against state-of-the-art methods, including Bayesian filtering, DBSTREAM clustering, and JPDA. The results demonstrate that SODA-CitrON consistently outperforms the compared methods in terms of F1 score, position RMSE, MOTP, and MOTA in the static object mapping scenarios studied.

</details>


### [2] [Hierarchical Trajectory Planning of Floating-Base Multi-Link Robot for Maneuvering in Confined Environments](https://arxiv.org/abs/2602.22459)
*Yicheng Chen,Jinjie Li,Haokun Liu,Zicheng Luo,Kotaro Kaneko,Moju Zhao*

Main category: cs.RO

TL;DR: 提出了一种用于浮动基多连杆机器人的分层轨迹规划框架，结合全局引导和配置感知的局部优化，直接从点云数据生成连续、无碰撞、动态可行的轨迹。


<details>
  <summary>Details</summary>
Motivation: 浮动基多连杆机器人在飞行中可以改变形态，适合在受限环境中应用，但轨迹规划面临高维、约束丰富的挑战，需要同时处理避障、运动学限制和动态可行性。

Method: 分层规划框架：1) 利用机器人的双重特性（根连杆作为刚体引导，关节提供灵活性）生成全局锚点状态，将规划问题分解为可处理段；2) 设计局部轨迹规划器，并行优化各段，使用可微目标函数和约束，系统确保运动学可行性并避免控制奇点；3) 实现直接处理点云数据的完整系统，无需手工障碍物模型。

Result: 通过大量仿真和真实世界实验验证，该框架使关节式空中机器人能够利用其形态实现刚体机器人无法完成的机动。这是首个在真实机器人上演示的浮动基多连杆机器人规划框架，能够直接从原始点云输入生成连续、无碰撞、动态可行的轨迹。

Conclusion: 该分层轨迹规划框架成功解决了浮动基多连杆机器人在高维约束空间中的轨迹规划难题，通过全局引导与局部优化的结合，实现了直接从点云数据生成可行轨迹的能力，为受限环境中的自主应用提供了有效解决方案。

Abstract: Floating-base multi-link robots can change their shape during flight, making them well-suited for applications in confined environments such as autonomous inspection and search and rescue. However, trajectory planning for such systems remains an open challenge because the problem lies in a high-dimensional, constraint-rich space where collision avoidance must be addressed together with kinematic limits and dynamic feasibility. This work introduces a hierarchical trajectory planning framework that integrates global guidance with configuration-aware local optimization. First, we exploit the dual nature of these robots - the root link as a rigid body for guidance and the articulated joints for flexibility - to generate global anchor states that decompose the planning problem into tractable segments. Second, we design a local trajectory planner that optimizes each segment in parallel with differentiable objectives and constraints, systematically enforcing kinematic feasibility and maintaining dynamic feasibility by avoiding control singularities. Third, we implement a complete system that directly processes point-cloud data, eliminating the need for handcrafted obstacle models. Extensive simulations and real-world experiments confirm that this framework enables an articulated aerial robot to exploit its morphology for maneuvering that rigid robots cannot achieve. To the best of our knowledge, this is the first planning framework for floating-base multi-link robots that has been demonstrated on a real robot to generate continuous, collision-free, and dynamically feasible trajectories directly from raw point-cloud inputs, without relying on handcrafted obstacle models.

</details>


### [3] [EgoAVFlow: Robot Policy Learning with Active Vision from Human Egocentric Videos via 3D Flow](https://arxiv.org/abs/2602.22461)
*Daesol Cho,Youngseok Jang,Danfei Xu,Sehoon Ha*

Main category: cs.RO

TL;DR: EgoAVFlow：从第一人称视频学习机器人操作和主动视觉，通过共享3D流表示实现几何可见性推理，无需机器人演示即可迁移


<details>
  <summary>Details</summary>
Motivation: 第一人称人类视频提供了可扩展的操作演示来源，但将其部署到机器人上需要主动视角控制以维持任务关键可见性，而人类视角模仿由于人类特定先验往往无法提供这种控制

Method: 使用扩散模型预测机器人动作、未来3D流和相机轨迹，并通过基于预测运动和场景几何计算的可见性感知奖励，在测试时通过奖励最大化去噪来优化视角

Result: 在主动变化视角的真实世界实验中，EgoAVFlow始终优于先前基于人类演示的基线方法，展示了有效的可见性维护和无需机器人演示的鲁棒操作

Conclusion: EgoAVFlow通过学习共享3D流表示，成功实现了从第一人称视频到机器人的操作和主动视觉迁移，解决了人类视角模仿中的可见性维护问题

Abstract: Egocentric human videos provide a scalable source of manipulation demonstrations; however, deploying them on robots requires active viewpoint control to maintain task-critical visibility, which human viewpoint imitation often fails to provide due to human-specific priors. We propose EgoAVFlow, which learns manipulation and active vision from egocentric videos through a shared 3D flow representation that supports geometric visibility reasoning and transfers without robot demonstrations. EgoAVFlow uses diffusion models to predict robot actions, future 3D flow, and camera trajectories, and refines viewpoints at test time with reward-maximizing denoising under a visibility-aware reward computed from predicted motion and scene geometry. Real-world experiments under actively changing viewpoints show that EgoAVFlow consistently outperforms prior human-demo-based baselines, demonstrating effective visibility maintenance and robust manipulation without robot demonstrations.

</details>


### [4] [When to Act, Ask, or Learn: Uncertainty-Aware Policy Steering](https://arxiv.org/abs/2602.22474)
*Jessie Yuan,Yilin Wu,Andrea Bajcsy*

Main category: cs.RO

TL;DR: UPS是一个不确定性感知的策略引导框架，通过校准的视觉语言模型验证器来区分自信、模糊和无能场景，选择执行高置信度动作、澄清任务模糊性或请求干预，并利用残差学习持续改进预训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有策略引导框架通常假设视觉语言模型校准良好，但实际上VLM的过度自信判断会降低引导性能，特别是在任务规范存在高层语义不确定性和预训练策略存在低层动作不确定性或无能力的情况下。

Method: 提出不确定性感知策略引导框架，联合推理语义任务不确定性和低层动作可行性，选择不确定性解决策略；利用共形预测校准VLM和预训练基础策略的组合；通过残差学习在部署期间收集干预来改进预训练策略。

Result: 在仿真和硬件实验中，UPS能够区分自信、模糊和无能场景，相比未校准基线和先前的人机门控持续学习方法，最小化了昂贵的用户干预。

Conclusion: UPS框架通过校准的验证器有效处理策略引导中的不确定性，实现持续学习但只需最少的人类反馈，提升了机器人行为适应能力。

Abstract: Policy steering is an emerging way to adapt robot behaviors at deployment-time: a learned verifier analyzes low-level action samples proposed by a pre-trained policy (e.g., diffusion policy) and selects only those aligned with the task. While Vision-Language Models (VLMs) are promising general-purpose verifiers due to their reasoning capabilities, existing frameworks often assume these models are well-calibrated. In practice, the overconfident judgment from VLM can degrade the steering performance under both high-level semantic uncertainty in task specifications and low-level action uncertainty or incapability of the pre-trained policy. We propose uncertainty-aware policy steering (UPS), a framework that jointly reasons about semantic task uncertainty and low-level action feasibility, and selects an uncertainty resolution strategy: execute a high-confidence action, clarify task ambiguity via natural language queries, or ask for action interventions to correct the low-level policy when it is deemed incapable at the task. We leverage conformal prediction to calibrate the composition of the VLM and the pre-trained base policy, providing statistical assurances that the verifier selects the correct strategy. After collecting interventions during deployment, we employ residual learning to improve the capability of the pre-trained policy, enabling the system to learn continually but with minimal expensive human feedback. We demonstrate our framework through experiments in simulation and on hardware, showing that UPS can disentangle confident, ambiguous, and incapable scenarios and minimizes expensive user interventions compared to uncalibrated baselines and prior human- or robot-gated continual learning approaches. Videos can be found at https://jessie-yuan.github.io/ups/

</details>


### [5] [SignVLA: A Gloss-Free Vision-Language-Action Framework for Real-Time Sign Language-Guided Robotic Manipulation](https://arxiv.org/abs/2602.22514)
*Xinyu Tan,Ningwei Bai,Harry Gardener,Zhengyang Zhong,Luoyu Zhang,Liuhaichen Yang,Zhekai Duan,Monkgogi Galeitsiwe,Zezhi Tang*

Main category: cs.RO

TL;DR: 首个基于手语驱动的视觉-语言-动作框架，采用无注释词范式，直接将视觉手语手势映射为语义指令，实现直观包容的人机交互。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖注释词作为中间监督，存在标注成本高和信息损失问题。需要更自然、可扩展的多模态交互方式，特别是在安全关键的环境中实现可靠、可解释的机器人控制。

Method: 采用无注释词范式，直接映射视觉手势到语义指令。专注于实时字母级指拼接口，通过几何归一化、时间平滑和词汇精炼将连续手势流转换为连贯语言命令。支持未来集成基于Transformer的无注释词手语模型。

Result: 实验结果表明，该系统在不同交互场景下能够有效地将手语指令转化为精确的机器人动作，实现了稳健、低延迟的通信通道。

Conclusion: 该框架展示了推进可访问、可扩展和多模态具身智能的潜力，为包容性人机交互提供了新的技术路径。

Abstract: We present, to our knowledge, the first sign language-driven Vision-Language-Action (VLA) framework for intuitive and inclusive human-robot interaction. Unlike conventional approaches that rely on gloss annotations as intermediate supervision, the proposed system adopts a gloss-free paradigm and directly maps visual sign gestures to semantic instructions. This design reduces annotation cost and avoids the information loss introduced by gloss representations, enabling more natural and scalable multimodal interaction.
  In this work, we focus on a real-time alphabet-level finger-spelling interface that provides a robust and low-latency communication channel for robotic control. Compared with large-scale continuous sign language recognition, alphabet-level interaction offers improved reliability, interpretability, and deployment feasibility in safety-critical embodied environments. The proposed pipeline transforms continuous gesture streams into coherent language commands through geometric normalization, temporal smoothing, and lexical refinement, ensuring stable and consistent interaction.
  Furthermore, the framework is designed to support future integration of transformer-based gloss-free sign language models, enabling scalable word-level and sentence-level semantic understanding. Experimental results demonstrate the effectiveness of the proposed system in grounding sign-derived instructions into precise robotic actions under diverse interaction scenarios. These results highlight the potential of the framework to advance accessible, scalable, and multimodal embodied intelligence.

</details>


### [6] [Metamorphic Testing of Vision-Language Action-Enabled Robots](https://arxiv.org/abs/2602.22579)
*Pablo Valle,Sergio Segura,Shaukat Ali,Aitor Arrieta*

Main category: cs.RO

TL;DR: 本文探讨了在视觉-语言-动作（VLA）机器人任务控制器中应用蜕变测试来缓解测试预言问题，提出了两种蜕变关系模式和五种蜕变关系，并通过实证研究验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: VLA模型面临测试预言问题的挑战：一方面需要为每个指令提示定义测试预言，这复杂且难以泛化；另一方面现有测试预言通常只评估任务正确性，而无法评估任务执行质量。本文旨在探索蜕变测试是否能缓解这一测试预言问题。

Method: 提出了两种蜕变关系模式和五种蜕变关系，用于评估测试输入变化对VLA机器人原始轨迹的影响。通过涉及5个VLA模型、2个模拟机器人和4个机器人任务的实证研究来验证方法有效性。

Result: 实证研究表明，蜕变测试能有效缓解测试预言问题，自动检测多种类型的故障（包括但不限于未完成任务）。更重要的是，所提出的蜕变关系具有泛化性，使该方法适用于不同的VLA模型、机器人和任务，即使在缺乏测试预言的情况下也能应用。

Conclusion: 蜕变测试能够有效缓解VLA机器人任务控制器中的测试预言问题，提出的蜕变关系具有泛化性，为VLA系统的测试提供了新的有效方法。

Abstract: Vision-Language-Action (VLA) models are multimodal robotic task controllers that, given an instruction and visual inputs, produce a sequence of low-level control actions (or motor commands) enabling a robot to execute the requested task in the physical environment. These systems face the test oracle problem from multiple perspectives. On the one hand, a test oracle must be defined for each instruction prompt, which is a complex and non-generalizable approach. On the other hand, current state-of-the-art oracles typically capture symbolic representations of the world (e.g., robot and object states), enabling the correctness evaluation of a task, but fail to assess other critical aspects, such as the quality with which VLA-enabled robots perform a task. In this paper, we explore whether Metamorphic Testing (MT) can alleviate the test oracle problem in this context. To do so, we propose two metamorphic relation patterns and five metamorphic relations to assess whether changes to the test inputs impact the original trajectory of the VLA-enabled robots. An empirical study involving five VLA models, two simulated robots, and four robotic tasks shows that MT can effectively alleviate the test oracle problem by automatically detecting diverse types of failures, including, but not limited to, uncompleted tasks. More importantly, the proposed MRs are generalizable, making the proposed approach applicable across different VLA models, robots, and tasks, even in the absence of test oracles.

</details>


### [7] [Designing Robots for Families: In-Situ Prototyping for Contextual Reminders on Family Routines](https://arxiv.org/abs/2602.22628)
*Michael F. Xu,Enhui Zhao,Yawen Zhang,Joseph E. Michaelis,Sarah Sebo,Bilge Mutlu*

Main category: cs.RO

TL;DR: 研究探索如何通过支持家庭日常惯例来促进机器人在家庭环境中的可持续融入，通过协同设计、原型开发和家庭部署研究，发现机器人提醒功能受到欢迎但也引发家庭动态的复杂性。


<details>
  <summary>Details</summary>
Motivation: 机器人越来越多地进入家庭生活，但成功融入家庭日常仍面临挑战。研究旨在探索家庭日常惯例作为理解机器人如何在家庭环境中找到可持续角色的关键切入点。

Method: 与10个家庭协同设计机器人交互和行为，制定支持他们选择惯例的计划，考虑时间、参与者、位置和环境活动等情境因素。然后设计、原型化并部署移动社交机器人进行为期四天的家庭用户研究。

Result: 家庭欢迎机器人的提醒功能，父母尤其欣赏某些提醒任务的转移。同时，访谈揭示了围绕时间安排、权威性和家庭动态的紧张关系，突显了将机器人整合到家庭中超越简单提醒任务的复杂性。

Conclusion: 基于研究发现，提出了机器人促进情境提醒的设计启示，并讨论了为家庭环境设计机器人时更广泛的考虑因素，强调需要超越功能支持来理解家庭动态的复杂性。

Abstract: Robots are increasingly entering the daily lives of families, yet their successful integration into domestic life remains a challenge. We explore family routines as a critical entry point for understanding how robots might find a sustainable role in everyday family settings. Together with each of the ten families, we co-designed robot interactions and behaviors, and a plan for the robot to support their chosen routines, accounting for contextual factors such as timing, participants, locations, and the activities in the environment. We then designed, prototyped, and deployed a mobile social robot as a four-day, in-home user study. Families welcomed the robot's reminders, with parents especially appreciating the offloading of some reminding tasks. At the same time, interviews revealed tensions around timing, authority, and family dynamics, highlighting the complexity of integrating robots into households beyond the immediate task of reminders. Based on these insights, we offer design implications for robot-facilitated contextual reminders and discuss broader considerations for designing robots for family settings.

</details>


### [8] [Does the testing environment matter? Carsickness across on-road, test-track, and driving simulator conditions](https://arxiv.org/abs/2602.22671)
*Georgios Papaioannou,Barys Shyrokau*

Main category: cs.RO

TL;DR: 该研究比较了道路、测试跑道和驾驶模拟器三种环境中晕车症状的差异，发现模拟器由于无法重现低频运动，产生的晕车症状显著低于真实环境。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆的发展，晕车问题受到广泛关注，但缺乏标准化的晕车测量方法使得不同研究环境间的比较变得困难。现有研究最多只比较两种环境，缺乏多环境对比。

Method: 28名参与者在基于运动的驾驶模拟器中执行非驾驶任务，使用痛苦量表实时报告晕车症状，实验后使用晕车评估问卷。同时测量加速度、客观指标和主观晕车评分，并与道路和测试跑道环境进行比较。

Result: 模拟器环境中的晕车评分显著低于道路和测试跑道条件，主要原因是模拟器的工作范围有限，无法重现低频（<0.5 Hz）运动，而这些低频运动是诱发晕车的最主要因素。

Conclusion: 驾驶模拟器在重现真实晕车体验方面存在局限性，特别是在低频运动再现方面。这为基于模拟器的晕车研究有效性提供了重要参考，强调了考虑环境差异对晕车研究结果的影响。

Abstract: Carsickness has gained significant attention with the rise of automated vehicles, prompting extensive research across on-road, test-track, and driving simulator environments to understand its occurrence and develop mitigation strategies. However, the lack of carsickness standardization complicates comparisons across studies and environments. Previous works demonstrate measurement validity between two setups at most (e.g., on-road vs. driving simulator), leaving gaps in multi-environment comparisons. This study investigates the recreation of an on-road motion sickness exposure - previously replicated on a test track - using a motion-based driving simulator. Twenty-eight participants performed an eyes-off-road non-driving task while reporting motion sickness using the Misery Scale during the experiment and the Motion Sickness Assessment Questionnaire afterward. Psychological factors known to influence motion sickness were also assessed. The results present subjective and objective measurements for motion sickness across the considered environments. In this paper, acceleration measurements, objective metrics and subjective motion sickness ratings across environments are compared, highlighting key differences in sickness occurrence for simulator-based research validity. Significantly lower motion sickness scores are reported in the simulator compared to on-road and test-track conditions, due to its limited working envelope to reproduce low-frequency (<0.5 Hz) motions, which are the most provocative for motion sickness.

</details>


### [9] [SCOPE: Skeleton Graph-Based Computation-Efficient Framework for Autonomous UAV Exploration](https://arxiv.org/abs/2602.22707)
*Kai Li,Shengtao Zheng,Linkun Xiu,Yuze Sheng,Xiao-Ping Zhang,Dongyue Huang,Xinlei Chen*

Main category: cs.RO

TL;DR: SCOPE框架通过增量构建实时骨架图和隐式未知区域分析，实现高效自主探索，在保持与全局规划器相当性能的同时，计算成本平均降低86.9%


<details>
  <summary>Details</summary>
Motivation: 当前自主探索方法依赖频繁的全局优化，导致高计算延迟和轨迹振荡，特别是在资源受限的边缘设备上。需要解决这些限制以实现高效的空间推理和规划。

Method: 提出SCOPE框架：1) 增量构建实时骨架图；2) 引入隐式未知区域分析进行高效空间推理；3) 采用分层按需规划策略：近端规划器生成高频局部轨迹，区域序列规划器仅在必要时激活以优化全局访问顺序。

Result: 仿真对比评估显示，SCOPE实现了与最先进全局规划器相当的探索性能，同时计算成本平均降低86.9%。真实世界实验进一步验证了系统的鲁棒性和低延迟。

Conclusion: SCOPE框架通过创新的骨架图构建和分层规划策略，有效解决了自主探索中的计算延迟和轨迹振荡问题，为资源受限环境下的高效机器人探索提供了可行方案。

Abstract: Autonomous exploration in unknown environments is key for mobile robots, helping them perceive, map, and make decisions in complex areas. However, current methods often rely on frequent global optimization, suffering from high computational latency and trajectory oscillation, especially on resource-constrained edge devices. To address these limitations, we propose SCOPE, a novel framework that incrementally constructs a real-time skeletal graph and introduces Implicit Unknown Region Analysis for efficient spatial reasoning. The planning layer adopts a hierarchical on-demand strategy: the Proximal Planner generates smooth, high-frequency local trajectories, while the Region-Sequence Planner is activated only when necessary to optimize global visitation order. Comparative evaluations in simulation demonstrate that SCOPE achieves competitive exploration performance comparable to state-of-the-art global planners, while reducing computational cost by an average of 86.9%. Real-world experiments further validate the system's robustness and low latency in practical scenarios.

</details>


### [10] [Robust Helicopter Ship Deck Landing With Guaranteed Timing Using Shrinking-Horizon Model Predictive Control](https://arxiv.org/abs/2602.22714)
*Philipp Schitz,Paolo Mercorelli,Johann C. Dauer*

Main category: cs.RO

TL;DR: 基于收缩时域模型预测控制的直升机在移动甲板自主着陆算法，实现毫秒级计算时间的高精度着陆


<details>
  <summary>Details</summary>
Motivation: 开发能够在强风等干扰条件下，在移动船舶甲板上实现高精度、满足时间窗口约束的直升机自主着陆算法

Method: 采用收缩时域模型预测控制（SHMPC）结合着陆控制器，设计包含扰动反馈的辅助控制器，从全非线性直升机动力学中提取合适的规划模型

Result: 仿真显示所有机动都能在强风条件下实现高着陆精度，满足时间和操作约束，最大计算时间在毫秒范围内

Conclusion: 该方法能保证在初始优化问题可行的情况下，给定目标位置和时间，实现具有合适终端条件的安全着陆，具有高扰动抑制性能

Abstract: We present a runtime efficient algorithm for autonomous helicopter landings on moving ship decks based on Shrinking-Horizon Model Predictive Control (SHMPC). First, a suitable planning model capturing the relevant aspects of the full nonlinear helicopter dynamics is derived. Next, we use the SHMPC together with a touchdown controller stage to ensure a pre-specified maneuver time and an associated landing time window despite the presence of disturbances. A high disturbance rejection performance is achieved by designing an ancillary controller with disturbance feedback. Thus, given a target position and time, a safe landing with suitable terminal conditions is be guaranteed if the initial optimization problem is feasible. The efficacy of our approach is shown in simulation where all maneuvers achieve a high landing precision in strong winds while satisfying timing and operational constraints with maximum computation times in the millisecond range.

</details>


### [11] [Sapling-NeRF: Geo-Localised Sapling Reconstruction in Forests for Ecological Monitoring](https://arxiv.org/abs/2602.22731)
*Miguel Ángel Muñoz-Bañón,Nived Chebrolu,Sruthi M. Krishna Moorthy,Yifu Tao,Fernando Torres,Roberto Salguero-Gómez,Maurice Fallon*

Main category: cs.RO

TL;DR: 提出融合NeRF、LiDAR SLAM和GNSS的三级表示管道，实现幼苗的重复性地理定位生态监测，相比传统TLS能更精确地捕获细尺度结构特征。


<details>
  <summary>Details</summary>
Motivation: 现有3D传感方法（TLS、MLS、传统摄影测量）难以捕获幼苗的细尺度结构特征，如细枝、密叶，且缺乏长期监测所需的尺度一致性。隐式3D重建方法（NeRF、3DGS）虽前景好，但无法恢复真实场景尺度且缺乏精确地理定位能力。

Method: 提出三级表示管道：(1) GNSS实现粗略地球坐标系定位；(2) LiDAR SLAM提供厘米级精确定位与重建；(3) NeRF实现对象中心的幼苗密集重建。融合三种技术实现可重复的定量评估和长期监测。

Result: 在英国Wytham Woods和芬兰Evo森林样地的实验中，相比TLS，该方法能更精确地捕获幼苗的茎高、分枝模式和叶木比。成功测量了0.5-2米高幼苗的精确茎骨架和叶片分布。

Conclusion: 该管道为生态学家提供了更丰富的结构和定量数据，支持森林动态分析，实现了幼苗的重复性地理定位生态监测，解决了现有方法的尺度一致性和地理定位难题。

Abstract: Saplings are key indicators of forest regeneration and overall forest health. However, their fine-scale architectural traits are difficult to capture with existing 3D sensing methods, which make quantitative evaluation difficult. Terrestrial Laser Scanners (TLS), Mobile Laser Scanners (MLS), or traditional photogrammetry approaches poorly reconstruct thin branches, dense foliage, and lack the scale consistency needed for long-term monitoring. Implicit 3D reconstruction methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) are promising alternatives, but cannot recover the true scale of a scene and lack any means to be accurately geo-localised. In this paper, we present a pipeline which fuses NeRF, LiDAR SLAM, and GNSS to enable repeatable, geo-localised ecological monitoring of saplings. Our system proposes a three-level representation: (i) coarse Earth-frame localisation using GNSS, (ii) LiDAR-based SLAM for centimetre-accurate localisation and reconstruction, and (iii) NeRF-derived object-centric dense reconstruction of individual saplings. This approach enables repeatable quantitative evaluation and long-term monitoring of sapling traits. Our experiments in forest plots in Wytham Woods (Oxford, UK) and Evo (Finland) show that stem height, branching patterns, and leaf-to-wood ratios can be captured with increased accuracy as compared to TLS. We demonstrate that accurate stem skeletons and leaf distributions can be measured for saplings with heights between 0.5m and 2m in situ, giving ecologists access to richer structural and quantitative data for analysing forest dynamics.

</details>


### [12] [Pixel2Catch: Multi-Agent Sim-to-Real Transfer for Agile Manipulation with a Single RGB Camera](https://arxiv.org/abs/2602.22733)
*Seongyong Kim,Junhyeon Cho,Kang-Won Lee,Soo-Chul Lim*

Main category: cs.RO

TL;DR: 提出一种基于单张RGB图像像素级视觉信息识别物体运动的新方法，配合异构多智能体强化学习框架，实现机器人抓取抛掷物体的能力


<details>
  <summary>Details</summary>
Motivation: 机器人抓取抛掷物体需要实时感知物体运动并生成控制动作，传统方法需要显式估计3D位置，计算复杂且耗时

Method: 1. 从单张RGB图像提取像素级视觉信息识别物体运动；2. 设计异构多智能体强化学习框架，将机械臂和多指手定义为具有不同角色的独立智能体；3. 使用角色特定的观测和奖励进行协同训练

Result: 学习到的策略成功从仿真环境迁移到现实世界，实现了机器人抓取抛掷物体的能力

Conclusion: 基于像素级视觉信息的物体运动识别方法结合异构多智能体强化学习框架，能够有效解决高自由度机器人系统的抓取抛掷任务，并实现从仿真到现实的迁移

Abstract: To catch a thrown object, a robot must be able to perceive the object's motion and generate control actions in a timely manner. Rather than explicitly estimating the object's 3D position, this work focuses on a novel approach that recognizes object motion using pixel-level visual information extracted from a single RGB image. Such visual cues capture changes in the object's position and scale, allowing the policy to reason about the object's motion. Furthermore, to achieve stable learning in a high-DoF system composed of a robot arm equipped with a multi-fingered hand, we design a heterogeneous multi-agent reinforcement learning framework that defines the arm and hand as independent agents with distinct roles. Each agent is trained cooperatively using role-specific observations and rewards, and the learned policies are successfully transferred from simulation to the real world.

</details>


### [13] [Unleashing the Potential of Diffusion Models for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.22801)
*Yinan Zheng,Tianyi Tan,Bin Huang,Enguang Liu,Ruiming Liang,Jianlin Zhang,Jianwei Cui,Guang Chen,Kun Ma,Hangjun Ye,Long Chen,Ya-Qin Zhang,Xianyuan Zhan,Jingjing Liu*

Main category: cs.RO

TL;DR: 本文系统研究了扩散模型在端到端自动驾驶规划中的应用，基于大量真实车辆数据和道路测试，提出了Hyper Diffusion Planner框架，在真实世界测试中实现了10倍性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人决策任务中越来越受欢迎，但在自动驾驶领域的应用和评估仍局限于仿真或实验室环境。扩散模型在大规模复杂真实世界场景（如端到端自动驾驶）中的潜力尚未充分探索。

Method: 基于大量真实车辆数据和道路测试，系统研究扩散模型作为端到端自动驾驶规划器的潜力。通过全面控制研究，识别影响规划性能的关键因素（扩散损失空间、轨迹表示、数据缩放），并提出有效的强化学习后训练策略来增强安全性。

Result: 提出的Hyper Diffusion Planner框架在真实车辆平台上部署，在6个城市驾驶场景和200公里真实世界测试中评估，相比基础模型实现了10倍的性能提升。

Conclusion: 扩散模型经过适当设计和训练后，可以作为有效且可扩展的端到端自动驾驶规划器，应对复杂的真实世界自动驾驶任务。

Abstract: Diffusion models have become a popular choice for decision-making tasks in robotics, and more recently, are also being considered for solving autonomous driving tasks. However, their applications and evaluations in autonomous driving remain limited to simulation-based or laboratory settings. The full strength of diffusion models for large-scale, complex real-world settings, such as End-to-End Autonomous Driving (E2E AD), remains underexplored. In this study, we conducted a systematic and large-scale investigation to unleash the potential of the diffusion models as planners for E2E AD, based on a tremendous amount of real-vehicle data and road testing. Through comprehensive and carefully controlled studies, we identify key insights into the diffusion loss space, trajectory representation, and data scaling that significantly impact E2E planning performance. Moreover, we also provide an effective reinforcement learning post-training strategy to further enhance the safety of the learned planner. The resulting diffusion-based learning framework, Hyper Diffusion Planner} (HDP), is deployed on a real-vehicle platform and evaluated across 6 urban driving scenarios and 200 km of real-world testing, achieving a notable 10x performance improvement over the base model. Our work demonstrates that diffusion models, when properly designed and trained, can serve as effective and scalable E2E AD planners for complex, real-world autonomous driving tasks.

</details>


### [14] [LeRobot: An Open-Source Library for End-to-End Robot Learning](https://arxiv.org/abs/2602.22818)
*Remi Cadene,Simon Aliberts,Francesco Capuano,Michel Aractingi,Adil Zouitine,Pepijn Kooijmans,Jade Choghari,Martino Russi,Caroline Pascal,Steven Palma,Mustafa Shukor,Jess Moss,Alexander Soare,Dana Aubakirova,Quentin Lhoest,Quentin Gallouédec,Thomas Wolf*

Main category: cs.RO

TL;DR: lerobot是一个开源机器人学习库，整合了整个机器人学习栈，从底层电机控制到大规模数据集收集、存储和流式处理，旨在降低机器人学习门槛并促进可复现研究。


<details>
  <summary>Details</summary>
Motivation: 机器人学习领域虽然因机器学习技术、廉价遥操作系统和开放数据集而快速发展，但现有工具往往碎片化、闭源且只针对特定子组件，阻碍了领域发展。

Method: 开发了一个开源库lerobot，整合整个机器人学习栈：支持底层中间件通信、大规模数据集管理、多种最先进算法实现，以及通用异步推理栈。强调可扩展学习而非手工技术。

Result: 创建了一个专注于真实机器人应用、支持可访问硬件平台、可扩展到新机器人形态的库，为研究人员和从业者提供了可复现、最先进的机器人学习平台。

Conclusion: lerobot通过其可访问性、可扩展性和开放性，降低了机器人学习的入门门槛，为可复现的机器人学习研究提供了统一平台。

Abstract: Robotics is undergoing a significant transformation powered by advances in high-level control techniques based on machine learning, giving rise to the field of robot learning. Recent progress in robot learning has been accelerated by the increasing availability of affordable teleoperation systems, large-scale openly available datasets, and scalable learning-based methods. However, development in the field of robot learning is often slowed by fragmented, closed-source tools designed to only address specific sub-components within the robotics stack. In this paper, we present \texttt{lerobot}, an open-source library that integrates across the entire robot learning stack, from low-level middleware communication for motor controls to large-scale dataset collection, storage and streaming. The library is designed with a strong focus on real-world robotics, supporting accessible hardware platforms while remaining extensible to new embodiments. It also supports efficient implementations for various state-of-the-art robot learning algorithms from multiple prominent paradigms, as well as a generalized asynchronous inference stack. Unlike traditional pipelines which heavily rely on hand-crafted techniques, \texttt{lerobot} emphasizes scalable learning approaches that improve directly with more data and compute. Designed for accessibility, scalability, and openness, \texttt{lerobot} lowers the barrier to entry for researchers and practitioners to robotics while providing a platform for reproducible, state-of-the-art robot learning.

</details>


### [15] [Performance and Experimental Analysis of Strain-based Models for Continuum Robots](https://arxiv.org/abs/2602.22854)
*Annika Delucchi,Vincenzo Di Paola,Andreas Müller,and Matteo Zoppi*

Main category: cs.RO

TL;DR: 该研究提出了一种评估连续体机器人应变模型性能的方法，通过实验验证了基于三阶应变插值方法的形状重建能力，并与几何变量应变方法进行比较。


<details>
  <summary>Details</summary>
Motivation: 目前应变模型在机器人领域广泛应用，但缺乏统一的性能评估标准。随着连续体机器人原型开发的增加，需要评估这些模型的适用性并进行全面的性能评估。

Method: 采用三阶应变插值方法研究形状重建能力，分析其对单个和组合变形效应的捕捉能力。通过机械臂移动细杆末端并利用摄像头记录配置，使用反射标记提取形状，无需应变计或力传感器。

Result: 实验显示模型预测与观测形状吻合良好，平均误差为杆长的0.58%，每个配置的平均计算时间为0.32秒，优于现有模型。

Conclusion: 该研究为连续体机器人应变模型提供了有效的性能评估框架，验证了三阶应变插值方法在实际应用中的准确性和计算效率。

Abstract: Although strain-based models have been widely adopted in robotics, no comparison beyond the uniform bending test is commonly recognized to assess their performance. In addition, the increasing effort in prototyping continuum robots highlights the need to assess the applicability of these models and the necessity of comprehensive performance evaluation. To address this gap, this work investigates the shape reconstruction abilities of a third-order strain interpolation method, examining its ability to capture both individual and combined deformation effects. These results are compared and discussed against the Geometric-Variable Strain approach. Subsequently, simulation results are experimentally verified by reshaping a slender rod while recording the resulting configurations using cameras. The rod configuration is imposed using a manipulator displacing one of its tips and extracted through reflective markers, without the aid of any other external sensor -- i.e. strain gauges or wrench sensors placed along the rod. The experiments demonstrate good agreement between the model predictions and observed shapes, with average error of 0.58% of the rod length and average computational time of 0.32s per configuration, outperforming existing models.

</details>


### [16] [DySL-VLA: Efficient Vision-Language-Action Model Inference via Dynamic-Static Layer-Skipping for Robot Manipulation](https://arxiv.org/abs/2602.22896)
*Zebin Yang,Yijiahao Qi,Tong Xie,Bo Yu,Shaoshan Liu,Meng Li*

Main category: cs.RO

TL;DR: DySL-VLA：一种动态跳过VLA模型层的框架，根据动作重要性自适应调整计算量，在保持性能的同时显著提升效率


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型在机器人任务中表现出色，但计算成本高阻碍了实时应用。研究发现任务中的动作重要性不同：关键步骤需要高精度，而不重要步骤可容忍更多变化。

Method: 提出DySL-VLA框架，将VLA层分为信息层（始终执行）和增量层（可选择性跳过）。设计了先验-后验跳过指导机制决定何时启动层跳过，并采用跳过感知的两阶段知识蒸馏算法训练标准VLA转换为DySL-VLA。

Result: 在Calvin数据集上，DySL-VLA相比Deer-VLA实现了2.1%的成功长度提升，同时可训练参数减少85.7倍，在同等精度下相比RoboFlamingo基线提供3.75倍加速。

Conclusion: DySL-VLA通过动态跳过VLA层有效解决了计算成本问题，在保持性能的同时显著提升效率，为实时机器人应用提供了可行方案。

Abstract: Vision-Language-Action (VLA) models have shown remarkable success in robotic tasks like manipulation by fusing a language model's reasoning with a vision model's 3D understanding. However, their high computational cost remains a major obstacle for real-world applications that require real-time performance. We observe that the actions within a task have varying levels of importance: critical steps demand high precision, while less important ones can tolerate more variance. Leveraging this insight, we propose DySL-VLA, a novel framework that addresses computational cost by dynamically skipping VLA layers based on each action's importance. DySL-VLA categorizes its layers into two types: informative layers, which are consistently executed, and incremental layers, which can be selectively skipped. To intelligently skip layers without sacrificing accuracy, we invent a prior-post skipping guidance mechanism to determine when to initiate layer-skipping. We also propose a skip-aware two-stage knowledge distillation algorithm to efficiently train a standard VLA into a DySL-VLA. Our experiments indicate that DySL-VLA achieves 2.1% improvement in success length over Deer-VLA on the Calvin dataset, while simultaneously reducing trainable parameters by a factor of 85.7 and providing a 3.75x speedup relative to the RoboFlamingo baseline at iso-accuracy. Our code is available on https://github.com/PKU-SEC-Lab/DYSL_VLA.

</details>
